Proceedings of the SIGDIAL 2013 Conference, pages 148?150,Metz, France, 22-24 August 2013. c?2013 Association for Computational LinguisticsDemonstration of an Always-On Companion forIsolated Older AdultsCandace SidnerWorcester Polytechnic InstituteWorcester, MA, USAsidner@wpi.eduTimothy BickmoreNortheastern UniversityBoston, MA, USAbickmore@ccs.neu.eduCharles RichWorcester Polytechnic InstituteWorcester, MA, USABarbara Barry, Lazlo RingNortheastern UniversityBoston, MA, USAMorteza Behrooz, Mohammad ShayganfarWorcester Polytechnic InstituteWorcester, MA, USAAbstractWe summarize the status of an ongoingproject to develop and evaluate a compan-ion for isolated older adults.
Four keyscientific issues in the project are: em-bodiment, interaction paradigm, engage-ment and relationship.
The system ar-chitecture is extensible and handles real-time behaviors.
The system supports mul-tiple activities, including discussing theweather, playing cards, telling stories, ex-ercise coaching and video conferencing.
Alive, working demo system will be pre-sented at the meeting.1 IntroductionThe Always-On project1 is a four-year effort, cur-rently in its third year, supported by the U.S. Na-tional Science Foundation at Worcester Polytech-nic Institute and Northeastern University.
The goalof the project is to create a relational agent thatwill provide social support to reduce the isolationof healthy, but isolated older adults.
The agent is?always on,?
which is to say that it is continuouslyavailable and aware (using a camera and infraredmotion sensor) when the user is in its presence andcan initiate interaction with the user, rather than,for example requiring the user login to begin in-teraction.
Our goal is for the agent to be a natural,human-like presence that ?resides?
in the user?sdwelling for an extended period of time.
Begin-ning in the fall of 2013, we will be placing ouragents with about a number of users for a month-long, 4 arm, evaluation/comparison study.1http://www.cs.wpi.edu/?rich/alwaysSome%reply!Another%reply%Something%else%Me%too!
!I?ve%got%great%%cards%Some%reply!Another%reply%Something%else%Some%reply!Another%reply%Something%else%Just%%play!%I?ve%got%terrible%cards!%Figure 1: Virtual agent interface ?
?Karen?Our project focuses on four key scientific is-sues:?
the embodiment of the agent,?
the interaction paradigm,?
the engagement between the user and theagent, and?
the nature of the social relationship betweenthe user and the agent.1.1 EmbodimentWe are experimenting with two forms of agent em-bodiment.
Our main study will employ the vir-tual agent Karen, shown in Figure 1, that comesfrom the work of Bickmore et al(Bickmore etal., 2005).
Karen is a human-like agent animatedfrom a cartoon-shaded 3D model.
She is shownin Figure 1 playing a social game of cards withuser.
Notice that user input is via a touch-screenmenu.
Also, the speech bubble does not appear148in the actual interface, which uses text-to-speechgeneration.We are also planning an exploratory study sub-stituting the Reeti2 robot, shown in Figure 2,for Karen, but otherwise keeping the rest of thesystem (i.e., the menus, text-to-speech and otherscreen graphics) as much the same as possible.One big difference we expect is that the effect offace tracking with the robotic agent will be muchstronger than with Karen.
On the other hand, be-cause Reeti is not as human-like as Karen, it ispossible that it will not be as well accepted overallas Karen.1.2 Interaction ParadigmThe main interaction paradigm in our system isconversation, and in particular, dialog.
The agentmakes its contributions to the dialog using speech,and the user chooses his/her contribution from amenu of utterances provided on the touch screen.Dialogs evolve around various activities and canextend for quite a long time (up to five or ten min-utes) if the user chooses to continue the conversa-tion.
Dialog models can be created using whateversystem that the system designer chooses.
In ourwork, we use models that are scripting formats,a Java state machine model based on adjacencypairs or created with the dialog tool Disco (Richand Sidner, 2012).
This variety of models makesour system more flexible for system designers.The agent is not designed to accept speech inputfor several reasons:?
lack of voice models for older adults;?
no reliable means to circumscribe the collec-tion of utterances that the system could un-derstand;?
the wide range of activities to talk about withthe agent results in a huge number of utter-ance structures, semantic structures and pos-sible intentions.
We doubt there are existingspeech-to-utterance semantics systems avail-able to support such a plethora of choiceswith high reliability.
As our project is notabout spoken language understanding, weopted not to take on this burden.Some of the activities between user and agentinvolve additional on-screen graphics, such as the2http://www.reeti.frcard game shown in Figure 1, or a Week-At-A-GlanceTM style planning calendar.
When playingcards together, the user is allowed to directly ma-nipulate the cards on-screen.
For the calendar,the user may only do deictic gestures.
All otherinformation is handled through dialog.
We havethus eschewed other traditional GUI methods us-ing icons, pull-down lists, etc., in favor of usingspeech and menu dialog interaction whenever pos-sible.
The other exception, like direct manipula-tion of cards on-screen, is a virtual keyboard toallow typing in of proper names of people andplaces.
Our motivation for this design choice isto reinforce the relationship between the user andthe agent, and to simplify the interaction in com-parison to standard GUIs.1.3 EngagementOur system continu-Figure 2: Roboticinterface ?
?Reeti?ously maintains a modelof the state of engage-ment (Sidner et al 2005)between the user and theagent.
For example, whenthe agent senses nearbymotion (via infrared) fol-lowed by the appearanceof a face in its visionsystem, it decides that theuser is initiating engagement.
Disengagementcan come about at the natural conclusion ofthe conversation or when the user leaves for anunexpected reason, e.g., to answer a ringing doorbell.
Because our agent cannot understand soundsin the environment, it may not know why the userhas disengaged, but it does have simple strategiesfor dealing with unexpected interruptions.
Gen-erally, the agent does not initiate disengagement,although it may attempt to hurry the conclusionof a session if some event in the user?s calendar isabout to start.Since the user and agent have conversationsover an extended period of time, it is natural toconsider that they have some kind of social re-lationship (Bickmore and Schulman, 2012; Kiddand Breazeal, 2007).
To reason about this rela-tionship, we have implemented a planning system(Coon et al 2013) that decides which activitiesare appropriate to suggest to the user each timethey interact (in what we call a session).
This plan-ning system uses a relationship model based on149the closeness between the agent and user.
Theircloseness increases as they do activities together.Closeness decreases when the user and agent donot interact for a period of time, such as a fewdays.Each available activity has a required closenessin order to be undertaken.
Only those activitieswhose required closeness is less than or equal tothe current closeness between the user and agentwill be suggested for the current session.
Activi-ties that, although suggested, do not actually occur(due to user choice or other reasons) are reportedto the relationship planning system for planningthe next session.2 Activities for User and AgentWe will demonstrate our operational system with aseveral of the activities that the user and agent cando together.
In total, we will have more than tendifferent activities including: discuss the weather,learn about the activities to do with the agent, playa social game of cards, talk about family/friends,tell a life story to the agent, promote exercise,promote nutrition, hear a humorous tale from theagent, get health tips from the agent, speak witha friend/family member via SkypeTM (with all thedetails of SKYPE managed by the agent), andmanage a personal calendar for the user.A typical interaction with the agent might startwith some greetings (specific to the time of day)and then some discussion of the weather.
Theweather discussion can be as short as today?sweather forecast or extend to the next day, weatherin other cities, and weather where friends or fam-ily live.
At the user?s choice, weather might be fol-lowed by a social game of cards where the agent?sand user?s hands in the game and the way the gameis played out are commented upon.
If the userand agent are somewhat well acquainted, there-after might follow discussion of the user?s familyand friends.
For each person that agent has learnedabout, the agent might ask:Figure 3 shows an excerpt from a menu-basedinteraction in our currently running system.
Fol-lowing ths discussion of family and friends theuser might opt to end the conversation or continuewith other activities such as the calendaring sys-tem, hearing some health tips from the agent, andso on.Agent: So how is Mary doing??
I don?t want to talk about her today.?
I?m done talking about my family and friends.?
Overall pretty good.?
Not so great.
?UserAgent: Oh, what?s wrong??
She is ill.?
She had an accident.?
She lost a family member.
?User?
She is pretty lonely.?
She is postponing a visit to me.Agent: That?s very sad.Figure 3: Example menu-based interaction.AcknowledgmentsThis work is supported in part by the National Sci-ence Foundation under award IIS-1012083.
Anyopinions, findings, and conclusions or recommen-dations expressed in this material are those of theauthors and do not necessarily reflect the views ofthe National Science Foundation.ReferencesT.
Bickmore and D. Schulman.
2012.
Empirical val-idation of an accomodation theory-based model ofuser-agent relationship.
In Proc.
Int.
Conf.
on Intel-ligent Virtual Agents, Santa Cruz, CA.T.
Bickmore, L. Caruso, K. Clough-Gorr, andT.
Heeren.
2005.
?It?s just like you talk to a friend?
?Relational agents for older adults.
Interacting withComputers, 17(6):711?735.W.
Coon, C. Rich, and C. Sidner.
2013.
Activity plan-ning for long-term relationships.
In Proc.
Int.
Conf.on Intelligent Virtual Agents, Edinburgh, UK.C.D.
Kidd and C. Breazeal.
2007.
A robotic weightloss coach.
In Proc.
22nd National Conference onArtificial Intelligence, Vancouver, Canada.C.
Rich and C. L. Sidner.
2012.
Using collaborativediscourse theory to partially automate dialogue treeauthoring.
In Proc.
Int.
Conf.
on Intelligent VirtualAgents, Santa Cruz, CA, September.C.
L. Sidner, C. Lee, C. Kidd, N. Lesh, and C. Rich.2005.
Explorations in engagement for humans androbots.
Artificial Intelligence, 166(1-2):104?164.150
