Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 121?124,Columbus, Ohio, USA, June 2008. c?2008 Association for Computational LinguisticsUsing Automatically Transcribed Dialogs to Learn User Models in a SpokenDialog SystemUmar SyedDepartment of Computer SciencePrinceton UniversityPrinceton, NJ 08540, USAusyed@cs.princeton.eduJason D. WilliamsShannon LaboratoryAT&T Labs ?
ResearchFlorham Park, NJ 07932, USAjdw@research.att.comAbstractWe use an EM algorithm to learn user mod-els in a spoken dialog system.
Our methodrequires automatically transcribed (with ASR)dialog corpora, plus a model of transcriptionerrors, but does not otherwise need any man-ual transcription effort.
We tested our methodon a voice-controlled telephone directory ap-plication, and show that our learned modelsbetter replicate the true distribution of user ac-tions than those trained by simpler methodsand are very similar to user models estimatedfrom manually transcribed dialogs.1 Introduction and BackgroundWhen designing a dialog manager for a spoken dia-log system, we would ideally like to try different di-alog management strategies on the actual user pop-ulation that will be using the system, and select theone that works best.
However, users are typically un-willing to endure this kind of experimentation.
Thenext-best approach is to build a model of user behav-ior.
That way we can experiment with the model asmuch as we like without troubling actual users.Of course, for these experiments to be useful,a high-quality user model is needed.
The usualmethod of building a user model is to estimate itfrom transcribed corpora of human-computer di-alogs.
However, manually transcribing dialogs isexpensive, and consequently these corpora are usu-ally small and sparse.
In this work, we propose amethod of building user models that does not oper-ate on manually transcribed dialogs, but instead usesdialogs that have been transcribed by an automaticspeech recognition (ASR) engine.
Since this pro-cess is error-prone, we cannot assume that the tran-scripts will accurately reflect the users?
true actionsand internal states.
To handle this uncertainty, weemploy an EM algorithm that treats this informationas unobserved data.
Although this approach doesnot directly employ manually transcribed dialogs,it does require a confusion model for the ASR en-gine, which is estimated from manually transcribeddialogs.
The key benefit is that the number of manu-ally transcribed dialogs required to estimate an ASRconfusion model is much smaller, and is fixed withrespect to the complexity of the user model.Many works have estimated user models fromtranscribed data (Georgila et al, 2006; Levin et al,2000; Pietquin, 2004; Schatzmann et al, 2007).
Ourwork is novel in that we do not assume we have ac-cess to the correct transcriptions at all, but ratherhave a model of how errors are made.
EM has pre-viously been applied to estimation of user models:(Schatzmann et al, 2007) cast the user?s internalstate as a complex hidden variable and estimate itstransitions using the true user actions with EM.
Ourwork employs EM to infer the model of user actions,not the model of user goal evolution.2 MethodBefore we can estimate a user model, we must definea larger model of human-computer dialogs, of whichthe user model is just one component.
In this sectionwe give a general description of our dialog model;in Section 3 we instantiate the model for a voice-controlled telephone directory.We adopt a probabilistic dialog model (similar121to (Williams and Young, 2007)), depicted schemat-ically as a graphical model in Figure 1.
Follow-ing the convention for graphical models, we usedirected edges to denote conditional dependenciesamong the variables.
In our dialog model, a dia-log transcript x consists of an alternating sequenceof system actions and observed user actions: x =(S0, A?0, S1, A?1, .
.
.).
Here St denotes the systemaction, and A?t the output of the ASR engine whenapplied to the true user action At.A dialog transcript x is generated by our model asfollows: At each time t, the system action is St andthe unobserved user state is Ut.
The user state indi-cates the user?s hidden goal and relevant dialog his-tory which, due to ASR confusions, is known withcertainty only to the user.
Conditioned on (St, Ut),the user draws an unobserved action At from a dis-tribution Pr(At | St, Ut; ?)
parameterized by an un-known parameter ?.
For each user action At, theASR engine produces a hypothesis A?t of what theuser said, drawn from a distribution Pr(A?t | At),which is the ASR confusion model.
The user stateUt is updated to Ut+1 according to a deterministicdistribution Pr(Ut+1 | St+1, Ut, At, A?t).
The sys-tem outputs the next system action St+1 accordingto its dialog management policy.
Concretely, the val-ues of St, Ut, At and A?t are all assumed to belongto finite sets, and so all the conditional distributionsin our model are multinomials.
Hence ?
is a vec-tor that parameterizes the user model according toPr(At = a | St = s, Ut = u; ?)
= ?asu.The problem we are interested in is estimating ?given the set of dialog transcripts X , Pr(A?t | At)and Pr(Ut+1 | St+1, Ut, At, A?t).
Here, we assumethat Pr(A?t | At) is relatively straightforward to es-timate: for example, ASR models that rely a simpleconfusion rate and uniform substitutions (which canbe estimated from small number of transcriptions)have been used to train dialog systems which out-perform traditional systems (Thomson et al, 2007).Further, Pr(Ut+1 | St+1, Ut, At, A?t) is often deter-ministic and tracks dialog history relevant to actionselection ?
for example, whether the system cor-rectly or incorrectly confirms a slot value.
Here weassume that it can be easily hand-crafted.Formally, given a set of dialog transcripts X , ourgoal is find a set of parameters ??
that maximizes theA?tGFED@ABCAtGFED@ABCUt ONMLHIJKUt+1St St+1OOOO??OO!
!DDDDDDDDDDDDDDDDD((QQQQQQQQQQQQ//OOFigure 1: A probabilistic graphical model of a human-computer dialog.
The boxed variables are observed; thecircled variables are unobserved.log-likelihood of the observed data, i.e.,??
= arg max?log Pr(X | ?
)Unfortunately, directly computing ??
in this equa-tion is intractable.
However, we can efficiently ap-proximate ??
via an expectation-maximization (EM)procedure (Dempster et al, 1977).
For a dialog tran-script x, let y be the corresponding sequence of un-observed values: y = (U0, A0, U1, A1, .
.
.).
LetY be the set of all sequences of unobserved valuescorresponding to the data set X .
Given an estimate?
(t?1), a new estimate ?
(t) is produced by?
(t) = arg max?EY[log Pr(X ,Y | ?)???
X , ?
(t?1)]The expectation in this equation is taken over allpossible values for Y .
Both the expectation and itsmaximization are easy to compute.
This is becauseour dialog model has a chain-like structure thatclosely resembles an Hidden Markov Model, so aforward-backward procedure can be employed (Ra-biner, 1990).
Under fairly mild conditions, the se-quence ?
(0), ?
(1), .
.
.
converges to a stationary pointestimate of ??
that is usually a local maximum.3 Target ApplicationTo test the method, we applied it to a voice-controlled telephone directory.
This system is cur-rently in use in a large company with many thou-sands of employees.
Users call the directory systemand provide the name of a callee they wish to beconnected to.
The system then requests additional122information from the user, such as the callee?s lo-cation and type of phone (office, cell).
Here is asmall fragment of a typical dialog with the system:S0 = First and last name?A0 = ?John Doe?
[A?0 = Jane Roe ]S1 = Jane Roe.
Office or cell?A1 = ?No, no, John Doe?
[A?1 = No ]S2 = First and last name?.
.
.Because the telephone directory has many names,the number of possible values for At, A?t, and Stis potentially very large.
To control the size of themodel, we first assumed that the user?s intendedcallee does not change during the call, which allowsus to group many user actions together into genericplaceholders e.g.
At = FirstNameLastName.After doing this, there were a total of 13 possiblevalues for At and A?t, and 14 values for St.The user state consists of three bits: one bit indi-cating whether the system has correctly recognizedthe callee?s name, one bit indicating whether thesystem has correctly recognized the callee?s ?phonetype?
(office or cell), and one bit indicating whetherthe user has said the callee?s geographic location(needed for disambiguation when several differentpeople share the same name).
The deterministic dis-tribution Pr(Ut+1 | St+1, Ut, At, A?t) simply updatesthe user state after each dialog turn in the obviousway.
For example, the ?name is correct?
bit of Ut+1is set to 0 when St+1 is a confirmation of a namewhich doesn?t match At.Recall that the user model is a multinomial distri-bution Pr(At | St, Ut; ?)
parameterized by a vector?.
Based on the number user actions, system actions,and user states, ?
is a vector of (13?
1)?
14?
8 =1344 unknown parameters for our target application.4 ExperimentsWe conducted two sets of experiments on the tele-phone directory application, one using simulateddata, and the other using dialogs collected from ac-tual users.
Both sets of experiments assumed that allthe distributions in Figure 1, except the user model,are known.
The ASR confusion model was esti-mated by transcribing 50 randomly chosen dialogsfrom the training set in Section 4.2 and calculat-ing the frequency with which the ASR engine rec-ognized A?t such that A?t 6= At.
The probabilitiesPr(A?t |At) were then constructed by assuming that,when the ASR engine makes an error recognizing auser action, it substitutes another randomly chosenaction.4.1 Simulated DataRecall that, in our parameterization, the user modelis Pr(At = a | St = s, Ut = u; ?)
= ?asu.
Soin this set of experiments, we chose a reasonable,hand-crafted value for ?, and then generated syn-thetic dialogs by following the probabilistic processdepicted in Figure 1.
In this way, we were able tocreate synthetic training sets of varying sizes, as wellas a test set of 1000 dialogs.
Each generated dialogd in each training/test set consisted of a sequence ofvalues for all the observed and unobserved variables:d = (S0, U0, A0, A?0, .
.
.
).For a training/test set D, let KDasu be the numberof times t, in all the dialogs in D, that At = a, St =s, and Ut = u.
Similarly, let K?Das be the number oftimes t that A?t = a and St = s.For each training set D, we estimated ?
using thefollowing three methods:1.
Manual: Let ?
be the maximum likelihoodestimate using manually transcribed data, i.e.,?asu = KDasuPa KDasu.2.
Automatic: Let ?
be the maximum likelihoodestimate using automatically transcribed data,i.e., ?asu = eKDasPaeKDas.
This approach ignorestranscription errors and assumes that user be-havior depends only on the observed data.3.
EM: Let ?
be the estimate produced by the EMalgorithm described in Section 2, which usesthe automatically transcribed data and the ASRconfusion model.Now let D be the test set.
We evaluated each usermodel by calculating the normalized log-likelihoodof the model with respect to the true user actions inD:`(?)
=?a,s,u KDasu log ?asu|D|`(?)
is essentially a measure of how well the usermodel parameterized by ?
replicates the distribution123of user actions in the test set.
The normalization isto allow for easier comparison across data sets ofdiffering sizes.We repeated this entire process (generating train-ing and test sets, estimating and evaluating usermodels) 50 times.
The results presented in Figure2 are the average of those 50 runs.
They are alsocompared to the normalized log-likelihood of the?Truth?, which is the actual parameter ?
used to gen-erated the data.The EM method has to estimate a larger numberof parameters than the Automatic method (1344 vs.168).
But as Figure 2 shows, after observing enoughdialogs, the EM method is able to leverage the hid-den user state to learn a better model of user behav-ior, with an average normalized log-likelihood thatfalls about halfway between that of the models pro-duced by the Automatic and Manual methods.0 500 1000 1500?8?7?6?5?4?3Number of dialogs in training setNormalizedlog?likelihoodTruthManualEMAutomaticFigure 2: Normalized log-likelihood of each modeltype with respect to the test set vs. size of trainingset.
Each data point is the average of 50 runs.
For thelargest training set, the EM models had higher normal-ized log-likelihood than the Automatic models in 48 outof 50 runs.4.2 Real DataWe tested the three estimation methods from the pre-vious section on a data set of 461 real dialogs, whichwe split into a training set of 315 dialogs and a testset of 146 dialogs.
All the dialogs were both man-ually and automatically transcribed, so that each ofthe three methods was applicable.
The normalizedlog-likelihood of each user model, with respect toboth the training and test set, is given in Table 1.Since the output of the EM method depends on arandom choice of starting point ?
(0), those resultswere averaged over 50 runs.Training Set `(?)
Test Set `(?
)Manual -2.87 -3.73EM -3.90 -4.33Automatic -4.60 -5.80Table 1: Normalized log-likelihood of each model typewith respect to the training set and the test set.
TheEM values are the average of 50 runs.
The EM modelshad higher normalized log-likelihood than the Automaticmodel in 50 out of 50 runs.5 ConclusionWe have shown that user models can be estimatedfrom automatically transcribed dialog corpora bymodeling dialogs within a probabilistic frameworkthat accounts for transcription errors in a principledway.
This method may lead to many interesting fu-ture applications, such as continuous learning of auser model while the dialog system is on-line, en-abling automatic adaptation.ReferencesAP Dempster, NM Laird, and DB Rubin.
1977.
Maxi-mum likelihood from incomplete data via the em algo-rithm.
J. Royal Stat.
Soc., 39:1?38.K Georgila, J Henderson, and O Lemon.
2006.
Usersimulation for spoken dialogue systems: Learning andevaluation.
In Proc ICSLP, Pittsburgh, USA.E Levin, R Pieraccini, and W Eckert.
2000.
A stochas-tic model of human-machine interaction for learningdialogue strategies.
IEEE Trans on Speech and AudioProcessing, 8(1):11?23.O Pietquin.
2004.
A framework for unsupervised learn-ing of dialogue strategies.
Ph.D. thesis, Faculty of En-gineering, Mons (TCTS Lab), Belgium.LR Rabiner, 1990.
A tutorial on hidden Markov modelsand selected applications in speech recognition, pages267?296.
Morgan Kaufmann Publishers, Inc.J Schatzmann, B Thomson, and SJ Young.
2007.
Sta-tistical user simulation with a hidden agenda.
In ProcSIGDial, Antwerp, pages 273?282.B Thomson, J Schatzmann, K Welhammer, H Ye, andSJ Young.
2007.
Training a real-world POMDP-baseddialog system.
In Proc NAACL-HLT Workshop Bridg-ing the Gap: Academic and Industrial Research in Di-alog Technologies, Rochester, New York, USA, pages9?17.JD Williams and SJ Young.
2007.
Partially observableMarkov decision processes for spoken dialog systems.Computer Speech and Language, 21(2):393?422.124
