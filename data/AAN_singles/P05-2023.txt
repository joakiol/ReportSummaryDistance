Proceedings of the ACL Student Research Workshop, pages 133?138,Ann Arbor, Michigan, June 2005. c?2005 Association for Computational LinguisticsAn Unsupervised System for Identifying English Inclusions in German TextBeatrice AlexSchool of InformaticsUniversity of EdinburghEdinburgh, EH8 9LW, UKv1balex@inf.ed.ac.ukAbstractWe present an unsupervised system thatexploits linguistic knowledge resources,namely English and German lexicaldatabases and the World Wide Web, toidentify English inclusions in Germantext.
We describe experiments with thissystem and the corpus which was devel-oped for this task.
We report the classifi-cation results of our system and comparethem to the performance of a trained ma-chine learner in a series of in- and cross-domain experiments.1 IntroductionThe recognition of foreign words and foreign namedentities (NEs) in otherwise mono-lingual text is be-yond the capability of many existing approaches andis only starting to be addressed.
This language mix-ing phenomenon is prevalent in German where thenumber of anglicisms has increased considerably.We have developed an unsupervised and highlyefficient system that identifies English inclusionsin German text by means of a computationally in-expensive lookup procedure.
By unsupervised wemean that the system does not require any anno-tated training data and only relies on lexicons andthe Web.
Our system allows linguists and lexicogra-phers to observe language changes over time, and toinvestigate the use and frequency of foreign wordsin a given language and domain.
The output alsorepresents valuable information for a number of ap-plications, including polyglot text-to-speech (TTS)synthesis and machine translation (MT).We will first explain the issue of foreign inclu-sions in German text in greater detail with exam-ples in Section 2.
Sections 3 and 4 describe the datawe used and the architecture of our system.
In Sec-tion 5, we provide an evaluation of the system out-put and compare the results with those of a series ofin- and cross-domain machine learning experimentsoutlined in Section 6.
We conclude and outline fu-ture work in Section 7.2 MotivationIn natural language, new inclusions typically fallinto two major categories, foreign words and propernouns.
They cause substantial problems for NLP ap-plications because they are hard to process and infi-nite in number.
It is difficult to predict which for-eign words will enter a language, let alne create anexhaustive gazetteer of them.
In German, there isfrequent exposure to documents containing Englishexpressions in business, science and technology, ad-vertising and other sectors.
A look at current head-lines confirms the existence of this phenomenon:(1) ?Security-Tool verhindert, dass Hacker u?berGoogle Sicherheitslu?cken finden?1Security tool prevents hackers from findingsecurity holes via Google.An automatic classifier of foreign inclusions wouldprove valuable for linguists and lexicographers who1Published in Computerwelt on 10/01/2005:http://www.computerwelt.at133study this language-mixing phenomenon becauselexical resources need to be updated and reflect thistrend.
As foreign inclusions carry critical content interms of pronunciation and semantics, their correctrecognition will also provide vital knowledge in ap-plications such as polyglot TTS synthesis or MT.3 DataOur corpus is made up of a random selection ofonline German newspaper articles published in theFrankfurter Allgemeine Zeitung between 2001 and2004 in the domains of (1) internet & telecomms,(2) space travel and (3) European Union.
These do-mains were chosen to examine the different use andfrequency of English inclusions in German texts ofa more technological, scientific and political nature.With approximately 16,000 tokens per domain, theoverall corpus comprises of 48,000 tokens (Table 1).We created a manually annotated gold standardusing an annotation tool based on NITE XML (Car-letta et al, 2003).
We annotated two classes wherebyEnglish words and abbreviations that expand to En-glish terms were classed as ?English?
(EN) and allother tokens as ?Outside?
(O).2 Table 1 presents thenumber of English inclusions annotated in each goldstandard set and illustrates that English inclusionsare very sparse in the EU domain (49 tokens) butconsiderably frequent in the documents in the inter-net and space travel domains (963 and 485 tokens,respectively).
The type-token ratio (TTR) signalsthat the English inclusions in the space travel dataare less diverse than those in the internet data.Domain Tokens Types TTRInternet Total 15919 4152 0.26English 963 283 0.29Space Total 16066 3938 0.25English 485 73 0.15EU Total 16028 4048 0.25English 49 30 0.61Table 1: English token and type statistics and type-token-ratios (TTR) in the gold standard2We did not annotate English inclusions if part of URLs(www.stepstone.de), mixed-lingual unhyphenated compounds(Shuttleflug) or with German inflections (Receivern) as furthermorphological analysis is required to recognise them.
Our aimis to address these issues in future work.4 System DescriptionOur system is a UNIX pipeline which convertsHTML documents to XML and applies a set of mod-ules to add linguistic markup and to classify nounsas German or English.
The pipeline is composed ofa pre-processing module for tokenisation and POS-tagging as well as a lexicon lookup and Googlelookup module for identifying English inclusions.4.1 Pre-processing ModuleIn the pre-processing module, the downloaded Webdocuments are firstly cleaned up using Tidy3 toremove HTML markup and any non-textual in-formation and then converted into XML.
Subse-quently, two rule-based grammars which we devel-oped specifically for German are used to tokenise theXML documents.
The grammar rules are appliedwith lxtransduce4, a transducer which adds orrewrites XML markup on the basis of the rules pro-vided.
Lxtransduce is an updated version offsgmatch, the core program of LT TTT (Groveret al, 2000).
The tokenised text is then POS-taggedusing TnT trained on the German newspaper corpusNegra (Brants, 2000).4.2 Lexicon Lookup ModuleFor the initial lookup, we used CELEX, a lexicaldatabase of English, German and Dutch containingfull and inflected word forms as well as correspond-ing lemmas.
CELEX lookup was only performedfor tokens which TnT tagged as nouns (NN), for-eign material (FM) or named entities (NE) sinceanglicisms representing other parts of speech arerelatively infrequent in German (Yeandle, 2001).Tokens were looked up twice, in the German andthe English database and parts of hyphenated com-pounds were checked individually.
To identify cap-italised English tokens, the lookup in the Englishdatabase was made case-insensitive.
We also madethe lexicon lookup sensitive to POS tags to reduceclassification errors.
Tokens were found either onlyin the German lexicon (1), only in the English lexi-con (2) in both (3) or in neither lexicon (4).
(1) The majority of tokens found exclusively in3http://tidy.sourceforge.net4http://www.ltg.ed.ac.uk/?richard/lxtransduce.html134the German lexicon are actual German words.
Theremaining are English words with German case in-flection such as Computern.
The word Computeris used so frequently in German that it already ap-pears in lexicons and dictionaries.
To detect the baselanguage of the latter, a second lookup can be per-formed checking whether the lemma of the tokenalso occurs in the English lexicon.
(2) Tokens found exclusively in the English lexi-con such as Software or News are generally Englishwords and do not overlap with German lexicon en-tries.
These tokens are clear instances of foreign in-clusions and consequently tagged as English.
(3) Tokens which are found in both lexicons arewords with the same orthographic characteristics inboth languages.
These are words without inflec-tional endings or words ending in s signalling ei-ther the German genitive singular or the German andEnglish plural forms of that token, e.g.
Computers.The majority of these lexical items have the sameor similar semantics in both languages and representassimilated loans and cognates where the languageorigin is not always immediately apparent.
Onlya small subgroup of them are clearly English loanwords (e.g.
Monster).
Some tokens found in bothlexicons are interlingual homographs with differentsemantics in the two languages, e.g.
Rat (council vs.rat).
Deeper semantic analysis is required to classifythe language of such homographs which we taggedas German by default.
(4) All tokens found in neither lexicon are submit-ted to the Google lookup module.4.3 Google Lookup ModuleThe Google lookup module exploits the World WideWeb, a continuously expanding resource with docu-ments in a multiplicity of languages.
Although thebulk of information available on the Web is in En-glish, the number of texts written in languages otherthan English has increased rapidly in recent years(Crystal, 2001; Grefenstette and Nioche, 2000).The exploitation of the Web as a linguistic cor-pus is developing into a growing trend in compu-tational linguistics.
The sheer size of the Web andthe continuous addition of new material in differentlanguages make it a valuable pool of information interms of language in use.
The Web has already beenused successfully for a series of NLP tasks such asMT (Grefenstette, 1999), word sense disambigua-tion (Agirre and Martinez, 2000), synonym recogni-tion (Turney, 2001), anaphora resolution (Modjeskaet al, 2003) and determining frequencies for unseenbi-grams (Keller and Lapata, 2003).The Google lookup module obtains the numberof hits for two searches per token, one on GermanWeb pages and one on English ones, an advancedlanguage preference offered by Google.
Each tokenis classified as either German or English based onthe search that returns the higher normalised scoreof the number of hits.
This score is determined byweighting the number of raw hits by the size of theWeb corpus for that language.
We determine the lat-ter following a method proposed by Grefenstette andNiochi (2000) by using the frequencies of a series ofrepresentative tokens within a standard corpus in alanguage to determine the size of the Web corpusfor that language.
We assume that a German word ismore frequently used in German text than in Englishand vice versa.
As illustrated in Table 2, the Ger-man word Anbieter (provider) has a considerablyhigher weighted frequency in German Web docu-ments (DE).
Conversely, the English word provideroccurs more often in English Web documents (EN).If both searches return zero hits, the token is classi-fied as German by default.
Word queries that returnzero or a low number of hits can also be indicativeof new expressions that have entered a language.Google lookup was only performed for the tokensfound in neither lexicon in order to keep computa-tional cost to a minimum.
Moreover, a preliminaryexperiment showed that the lexicon lookup is al-ready sufficiently accurate for tokens contained ex-clusively in the German or English databases.
Cur-rent Google search options are also limited in thatqueries cannot be treated case- or POS-sensitively.Consequently, interlingual homographs would oftenmistakenly be classified as English.Language DE ENHits Raw Normalised Raw NormalisedAnbieter 3.05 0.002398 0.04 0.000014Provider 0.98 0.000760 6.42 0.002284Table 2: Raw counts (in million) and normalisedcounts of two Google lookup examples1355 Evaluation of the Lookup SystemWe evaluated the system?s performance for all to-kens against the gold standard.
While the accuraciesin Table 3 represent the percentage of all correctlytagged tokens, the F-scores refer to the English to-kens and are calculated giving equal weight to preci-sion (P) and recall (R) as  	.The system yields relatively high F-scores of 72.4and 73.1 for the internet and space travel data butonly a low F-score of 38.6 for the EU data.
The lat-ter is due to the sparseness of English inclusions inthat domain (Table 1).
Although recall for this datais comparable to that of the other two domains, thenumber of false positives is high, causing low pre-cision and F-score.
As the system does not look upone-character tokens, we implemented further post-processing to classify individual characters as En-glish if followed by a hyphen and an English inclu-sion.
This improves the F-score by 4.8 for the inter-net data to 77.2 and by 0.6 for the space travel data to73.7 as both data sets contain words like E-Mail orE-Business.
Post-processing does not decrease theEU score.
This indicates that domain-specific post-processing can improve performance.Baseline accuracies when assuming that all to-kens are German are also listed in Table 3.
As F-scores are calculated based on the English tokensin the gold standard, we cannot report comparablebaseline F-scores.
Unsurprisingly, the baseline ac-curacies are relatively high as most tokens in a Ger-man text are German and the amount of foreign ma-terial is relatively small.
The added classification ofEnglish inclusions yielded highly statistical signif-icant improvements (p  0.001) over the baseline of3.5% for the internet data and 1.5% for the spacetravel data.
When classifying English inclusions inthe EU data, accuracy decreased slightly by 0.3%.Table 3 also shows the performance of TextCat,an n-gram-based text categorisation algorithm ofCavnar and Trenkle (1994).
While this languageidenfication tool requires no lexicons, its F-scoresare low for all 3 domains and very poor for the EUdata.
This confirms that the identification of Englishinclusions is more difficult for this domain, coincid-ing with the result of the lookup system.
The lowscores also prove that such language identification isunsuitable for token-based language classification.Domain Method Accuracy F-scoreInternet Baseline 94.0% -Lookup 97.1% 72.4Lookup + post 97.5% 77.2TextCat 92.2% 31.0Space Baseline 97.0% -Lookup 98.5% 73.1Lookup + post 98.5% 73.7TextCat 93.8% 26.7EU Baseline 99.7% -Lookup 99.4% 38.6Lookup + post 99.4% 38.6TextCat 96.4% 4.7Table 3: Lookup results (with and without post-processing) compared to TextCat and baseline6 Machine Learning ExperimentsThe recognition of foreign inclusions bears greatsimilarity to classification tasks such as named en-tity recognition (NER), for which various machinelearning techniques have proved successful.
Wewere therefore interested in determining the perfor-mance of a trained classifier for our task.
We ex-perimented with a conditional Markov model taggerthat performed well on language-independent NER(Klein et al, 2003) and the identification of gene andprotein names (Finkel et al, 2005).6.1 In-domain ExperimentsWe performed several 10-fold cross-validation ex-periments with different feature sets.
They are re-ferred to as in-domain (ID) experiments as the taggeris trained and tested on data from the same domain(Table 4).
In the first experiment (ID1), we use thetagger?s standard feature set including words, char-acter sub-strings, word shapes, POS-tags, abbrevi-ations and NE tags (Finkel et al, 2005).
The re-sulting F-scores are high for the internet and spacetravel data (84.3 and 91.4) but are extremely low forthe EU data (13.3) due to the sparseness of Englishinclusions in that data set.
ID2 involves the samesetup as ID1 but eliminating all features relying onthe POS-tags.
The tagger performs similarly wellfor the internet and space travel data but improvesby 8 points to an F-score of 21.3 for the EU data.This can be attributed to the fact that the POS-tagger136does not perform with perfect accuracy particularlyon data containing foreign inclusions.
Providing thetagger with this information is therefore not neces-sarily useful for this task, especially when the datais sparse.
Nevertheless, there is a big discrepancybetween the F-score for the EU data and those of theother two data sets.
ID3 and ID4 are set up as ID1and ID2 but incorporating the output of the lookupsystem as a gazetteer feature.
The tagger benefitsconsiderably from this lookup feature and yields bet-ter F-scores for all three domains in ID3 (internet:90.6, space travel: 93.7, EU: 44.4).Table 4 also compares the best F-scores producedwith the tagger?s own feature set (ID2) to the bestresults of the lookup system and the baseline.
Whilethe tagger performs much better for the internetand the space travel data, it requires hand-annotatedtraining data.
The lookup system, on the other hand,is essentially unsupervised and therefore much moreportable to new domains.
Given the necessary lexi-cons, it can easily be run over new text and text in adifferent language or domain without further cost.6.2 Cross-domain ExperimentsThe tagger achieved surprisingly high F-scores forthe internet and space travel data, considering thesmall training data set of around 700 sentences usedfor each ID experiment described above.
Althoughboth domains contain a large number of English in-clusions, their type-token ratio amounts to 0.29 inthe internet data and 0.15 in the space travel data(Table 1), signalling that English inclusions are fre-quently repeated in both domains.
As a result, thelikelihood of the tagger encountering an unknowninclusion in the test data is relatively small.To examine the tagger?s performance on a new do-main containing more unknown inclusions, we rantwo cross-domain (CD) experiments: CD1, train-ing on the internet and testing on the space traveldata, and CD2, training on the space travel and test-ing on the internet data.
We chose these two do-main pairs to ensure that both the training and testdata contain a relatively large number of English in-clusions.
Table 5 shows that the F-scores for bothCD experiments are much lower than those obtainedwhen training and testing the tagger on documentsfrom the same domain.
In experiment CD1, the F-score only amounts to 54.2 while the percentage ofDomain Accuracy F-scoreInternet ID1 98.4% 84.3ID2 98.3% 84.3ID3 98.9% 90.6ID4 98.9% 90.8Best Lookup 97.5% 77.2Baseline 94.0% -Space ID1 99.5% 91.4ID2 99.5% 91.3ID3 99.6% 93.7ID4 99.6% 92.8Best Lookup 98.5% 73.7Baseline 97.0% -EU ID1 99.7% 13.3ID2 99.7% 21.3ID3 99.8% 44.4ID4 99.8% 44.4Best Lookup 99.4% 38.6Baseline 99.7% -Table 4: Accuracies and F-scores for ID experimentsAccuracy F-score UTTCD1 97.9% 54.2 81.9%Best Lookup 98.5% 73.7 -Baseline 97.0% - -CD2 94.6% 22.2 93.9%Best Lookup 97.5% 77.2 -Baseline 94.0% - -Table 5: Accuracies, F-scores and percentages ofunknown target types (UTT) for cross-domain ex-periments compared to best lookup and baselineunknown target types in the space travel test data is81.9%.
The F-score is even lower in the second ex-periment at 22.2 which can be attributed to the factthat the percentage of unknown target types in theinternet test data is higher still at 93.9%.These results indicate that the tagger?s high per-formance in the ID experiments is largely due to thefact that the English inclusions in the test data areknown, i.e.
the tagger learns a lexicon.
It is there-fore more complex to train a machine learning clas-sifier to perform well on new data with more andmore new anglicisms entering German over time.The amount of unknown tokens will increase con-stantly unless new annotated training data is added.1377 Conclusions and Future WorkWe have presented an unsupervised system that ex-ploits linguistic knowledge resources including lex-icons and the Web to classify English inclusions inGerman text on different domains.
Our system canbe applied to new texts and domains with little com-putational cost and extended to new languages aslong as lexical resources are available.
Its main ad-vantage is that no annotated training data is required.The evaluation showed that our system performswell on non-sparse data sets.
While being out-performed by a machine learner which requiresa trained model and therefore manually annotateddata, the output of our system increases the per-formance of the learner when incorporating this in-formation as an additional feature.
Combining sta-tistical approaches with methods that use linguisticknowledge resources can therefore be advantageous.The low results obtained in the CD experimentsindicate however that the machine learner merelylearns a lexicon of the English inclusions encoun-tered in the training data and is unable to classifymany unknown inclusions in the test data.
TheGoogle lookup module implemented in our systemrepresents a first attempt to overcome this problemas the information on the Web never remains staticand at least to some extent reflects language in use.The current system tracks full English wordforms.
In future work, we aim to extend it to iden-tify English inclusions within mixed-lingual tokens.These are words containing morphemes from dif-ferent languages, e.g.
English words with Germaninflection (Receivern) or mixed-lingual compounds(Shuttleflug).
We will also test the hypothesis thatautomatic classification of English inclusions canimprove text-to-speech synthesis quality.AcknowledgementsThanks go to Claire Grover and Frank Keller fortheir input.
This research is supported by grantsfrom the University of Edinburgh, Scottish Enter-prise Edinburgh-Stanford Link (R36759) and ESRC.ReferencesEneko Agirre and David Martinez.
2000.
Exploring au-tomatic word sense disambiguation with decision listsand the Web.
In Proceedings of the Semantic Annota-tion and Intelligent Annotation workshop, COLING.Thorsten Brants.
2000.
TnT ?
a statistical part-of-speechtagger.
In Proceedings of the 6th Applied Natural Lan-guage Processing Conference.Jean Carletta, Stefan Evert, Ulrich Heid, Jonathan Kil-gour, Judy Robertson, and Holgar Voormann.
2003.The NITE XML toolkit: flexible annotation for multi-modal language data.
Behavior Research Methods, In-struments, and Computers, 35(3):353?363.William B. Cavnar and John M. Trenkle.
1994.
N-gram-based text categorization.
In Proceedings of the 3rdAnnual Symposium on Document Analysis and Infor-mation Retrieval.David Crystal.
2001.
Language and the Internet.
Cam-bridge University Press.Jenny Finkel, Shipra Dingare, Christopher Manning,Malvina Nissim, Beatrice Alex, and Claire Grover.2005.
Exploring the boundaries: Gene and proteinidentification in biomedical text.
BMC Bioinformat-ics.
In press.Gregory Grefenstette and Julien Nioche.
2000.
Estima-tion of English and non-English language use on theWWW.
In Proceedings of RIAO 2000.Gregory Grefenstette.
1999.
The WWW as a resourcefor example-based machine translation tasks.
In Pro-ceedings of ASLIB?99 Translating and the Computer.Claire Grover, Colin Matheson, Andrei Mikheev, andMoens Marc.
2000.
LT TTT - a flexible tokenisationtool.
In Proceedings of the 2nd International Confer-ence on Language Resources and Evaluation.Frank Keller and Mirella Lapata.
2003.
Using the Web toobtain frequencies for unseen bigrams.
ComputationalLinguistics, 29(3):458?484.Dan Klein, Joseph Smarr, Huy Nguyen, and Christo-pher D. Manning.
2003.
Named entity recognitionwith character-level models.
In Proceedings of the 7thConference on Natural Language Learning.Natalia Modjeska, Katja Markert, and Malvina Nissim.2003.
Using the Web in machine learning for other-anaphora resolution.
In Proceedings of the Conferenceon Empirical Methods in Natural Language Process-ing.Peter D. Turney.
2001.
Mining the Web for synonyms:PMI-IR versus LSA on TOEFL.
In Proceedings of the12th European Conference on Machine Learning.David Yeandle.
2001.
Types of borrowing of Anglo-American computing terminology in German.
InMarie C. Davies, John L. Flood, and David N. Yean-dle, editors, Proper Words in Proper Places: Studiesin Lexicology and Lexicography in Honour of WilliamJervis Jones, pages 334?360.
Stuttgarter Arbeiten zurGermanistik 400, Stuttgart, Germany.138
