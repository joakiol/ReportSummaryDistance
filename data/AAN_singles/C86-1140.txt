TItE ROLE OF SEMANTIC PROCESSINGIN AN AUTOMATIC SPEECH UNDERSTANDING SYSTEMAstrid Brietzmann and Ute EhrlichLehrstuhl fuer Informatik 5 (Mustererkennung)Universitaet Erlangen-NuernbergMartensstr.
3, 8520 Erlangen, F. R. GermanyAbstract We present the semantics component of a speechunderstanding and dialogue system that is developed at ourinstitute.
Due to pronunciation variabilities and vagueness ofthe word recognition process, semantics in a speechunderstanding system has to resolve additional problems.
Itsmain task is not only to build up a representation structure forthe meaning of an utterance, as in a system for written input,semantic knowledge is also employed to decide betweenalternative word hypotheses, to judge the plausibility ofsyntactic structures, and to guide the word recognition processby expectations resulting from partial analyses.1.
In t roduct ionUnderstanding spoken utterances requires more than mere wordrecognition.
It is based on a number of meaning aspects,covering the range from textual interpretation of a sentence upto the revelation of the speaker's intention in the context of aspecial dialogue situation.
In the speech understanding anddialogue system EVAR /4/,  task-independent semantic analysis,domain-dependent pragmatic analysis, and dialogue-specificaspects are implemented in three separate modules /2/.Semantic analysis comprises those aspects that can be studied atthe isolated sentence, independent from its actual use in thedialogue.
The semantics module disregards communicativeaspects of an utterance as well as its situational and thematiccontext.
Thus, semantic onsistency of words and constituentsand underlying relational structure of the sentence are the mainpoints of interest in this stage of analysis.
Semantic knowledgeconsists of lexical meanings of words and selectional restrictionsbetween them.
The analysis of the functional structure is basedon the principles of case and valency theory.2.
Va lenc ies  and  case  theoryThe theoretical background for the analysis of functionalrelations in a sentence is given by valency and case theory /5,3/.
The main idea is that the syntactic and the semanticstructure of a sentence are essentially determined by its headverb.
The property to call for a certain number and kind ofcomplementary noun groups or prepositional groups that arenecessary to build up an adequate sentence is called valency.The morpho-syntactic and semantic descriptions of thecomplements constitute a verb frame with slots to be filled upby actual phrases.
This valency frame is augmented by caselabels circumscribing the functional role of the expected phrase.To give an example, the verb "suchen" (to look for) has the caseslots:AGENT: noun group (nominative), ANIMATE, obligatoryOBJECT: noun group (accusative), obligatoryLOCATION: adverbial group, PLACE, facultative.The lexical knowledge base provides caseframe ntries for allverbal and nominal items with valency properties.
Mostly,meaning alternatives correspond to different caseframes.
We usea relatively detailed case system with about 30 cases.For use within the semantics module, a preprocessor transformsthe dictionary entries to a network representation f concepts.The network scheme is influenced by the formalism ofStructured Inheritance Networks /1/ and is described in /2/.
Itis used for knowledge representation i  all semantic andpragmatic modules in the system.Similar to the frame theoretic approach, the underlyingassumption i case theory is that words evoke certain contextualexpectations to the hearer, based on his personal experiencesand his knowledge on stereotypic situations.
In our system, thisassumption is adopted in that we use case descriptions not onlyfor verifying syntactic hypotheses, but also for syntactic andsemantic predictions about the rest of the sentence.
Tiffs top-down aspect plays an essential role not only in the semanticcomponent but in the whole recognition process.3.
Semantic reason ing  in EVARIn our speech understanding system, the semantic analysis asdefined above comprises the following tasks:- resolution of lexical ambiguities- interpretation of constituents with respect to their semanticfeatures- choice between alternative syntactic hypotheses and betweenalternative interpretations of constituents- revelation of semantic anomalies due to recognition errors- representation f the case structure- inference of expectations on the rest of the sentence.These problems are solved by three fundamental operations ofthe semantics module: local interpretation by unification ofsemantic features, contextual interpretation by case frameanalysis, and top-down hypotheses.3.1 Local interpretation f constituentsOne of the main tasks of the module consists in mappingsyntactic structures (hypotheses) to caseframe instances.
As thismapping essentially relies on semantic features, the features of aphrase have to be determined first.
On the one hand, this meansresolution of lexical ambiguities, on the other hand, this processsupports the choice between alternative word and structuralhypotheses.
The principle is to reduce lexical ambiguities byselectionaI features of the phrase heads that constraindependent words and phrases.
To determine the features of aphrase, all meaning alternatives of its constituents are unifiedand tested for compatibility.
The test yields a rating that is thehigher, the more constituents are compatible with the nucleusclass.
Of all possible feature combinations, the one with thehighest consistency is chosen.
The semantic onsistency ratingof a group can also be regarded as a measure for the plausibilityof a syntactic hypothesis.
As low semantic ratings may resultfrom grouping wrong word hypotheses, a search for alternativeword and constituent hypotheses may be reasonable in an areawith bad semantic onsistency.The combinatoric onstraints of words are expressed in thedictionary by the feature SELECTION.
The system of semanticclasses (features) is organized in a conceptual hierarchy, thus,with a given class selected by the phrase head all its subclassesare accepted as compatible.
The system presently used consistsof about 110 semantic features and is represented as a concepthierarchy in the network formalism.5963.2  Contextua l  in te rpreta t ionWhen constituents are locally interpreted, they are matched tothe caseframes of some verbal groups in order to decide whichconstituents fit together and to represent their functionalrelationships.
Usually there are different verb frames for averb corresponding to its alternative meanings.
The assumptionis that the frame for the intended meaning will be the one thatcan fill most of its case slots.The mapping of a semantically interpreted phrase structure to aeaseframe is accomplished by three different matchingfunctions.
The syntax module produces syntactic structurehypotheses that are represented as network instances.
Due tocompeting and erroneous word hypotheses and structuralambiguities there will be competing syntactic structures as well.Every syntactic hypothesis has a score to reflect its reliabilityand importance.
Depending on whether a complete andspanning sentence hypothesis could be found, one of twomatching functions is selected: Frame Sentence Match takes agood scoring sentence hypothesis, the immediate constituents ofwhich have already been interpreted, and tries to match them tocases in the alternative frames of tile head verb.
Matchingcriteria are the constituent type that is required for a certaincase and the selectional restrictions imposed by the verb.The second version (Frame Constituents Match) has beenimplemented in order to cope with only partially recognizedsentence structures, ie.
with isolated constituents.
It is expectedthat complete (and completely recognized) sentences more likelytend to be the exception in spoken dialogue, and that it isadvantageous to envolve semantic interpretation as soon aspossible.
In this case, the frames of the best scoring verbalgroups are matched to the best scoring constituent hypotheses.For every successful configuration of a frame and fillingconstituents a frame instance is constructed with case attributesfilled by the fitting constituents.The matching process yields plausibility scores for theembedding of constituents into all alternative caseframes thatmay represent different meanings of the (assumed) head verb.The score is a function of different factors: the number ofobligatory slots that could be filled, reliability scores from theother modules, consistency ratings of the constituents,fulfilment of selectional restrictions, the relative length of thetime intervall (in the speech signal) not covered by thehypothesis.The valency structure providing only a minimum framework fora sentence, a third interpretation function is needed to evaluatethe functional relations of additional modifiers not constrainedby valency.
It mainly rests on the semantic properties of the'functional words', that is prepositions and conjunctions, and ofadverbs.
Their semantic classes (eg.
CAUSE, DIRECTION,SINCE) characterize the relation of prepositional nd adverbialgroups and subordinate clauses to the main clause.3.3 Top-down analysisMotivation The analysis o far can only be successful if a verbwas uttered by the user that was also recognized with asatisfying certainty by the word recognition module.
This is avery hard restriction for the user (to avoid for example llipticalconstructions without an explicit articulation of a justmentioned verb) as also for the word recognition of the system.The special problem with spoken natural language is that youwill never have the really uttered string of word hypotheseswhich covers the whole speech signal and is furtherlnoresyntactic orrect.
On the other hand it is likely that with all thegenerated word hypotheses there would be many possibilities ofchaining some of them to such a string.
So the system willneither find out if a word was uttered that isn't known to it northat an ellipsis was uttered.
That could be found only in writtenlanguage, for example by cmnmunicating with the user by aterminal.
But analyzing spoken utterances in a dialogue therewould always be wrong alternatives to the unknown or missingword or the missing syntactic onstituent.This fact implies that it isn't possible to restrict the user to acertain range of speech, for example to formulate only completesentences containing at least a subject and a verb.
Whether anyof such given restricting rules are violated is ahnost impossibleto discover.Besides this 'technical' point of view our system should 'behave'like a normal human commnnication partner, ie.
it should beable to handle all formulations that are normally used in aninformation dialogue between two human partners.Example:UI: When does the next train leave for Itamburg?SI: (there leaves one) At 12:15 hours.U2: And (is there another one) a little bit later?$2: That is the last (train to Hamburg) for today.Such elliptical sentence structures (in which not only the verb ispossibly missing but also a noun group such as in $2) preventunnecessary redundancy and effect the conversation becomingmore natural and fluent.Top-down Hypotheses of Verbs In addition to the formerdescribed Frame Constituent Match, a kind of bottom-upanalysis, a method is developed to analyze a spoken utterancewithout beginning with the verb of the sentence.
Also thismethod is based on the valency theory (see above).
Here we tryto conclude from a set of constituent hypotheses produced bythe syntax module to a set of possible verbframes containingslots for some of the found constituents which should not becompeting with regard to the speech signal.Therefore it was necessary to organize the database containingthe verbframes in a way that the actants (represented asattributes of the concept verb in a semantic network) of theverb (the concept) could be attained not only by seeking theverb and its information, but also in a direct way withoutknowing the affiliated concept.In German constituents have four selective features that can beused to restrict the number of the possible candidates for anattribute:the type of the constituent (for example noun group orprepositional group)- semantic lass which the constituent can be an instance of- if the constituent is a prepositional or adverbial group thepreposition respectively the semantic lass of the prepositionof the group- the case of the noun of the constituent (if any noun ispresent).For generating top-down hypotheses of verbs the last featurewill not be used, because in German the endings whichdetermine the case of a noun are all similar and so are theinflected word-forms of one lexeme.
It is supposed (and partlyshown by experiments) that the recognition and distinction ofsuch word-forms is not reliable enough to base the furtheranalysis on it.
It would better serve for the verification of so farfound syntactic and semantic hypotheses.597Example:Bedeutung = a9'/" ~ ~_ ~.
:\[ ~ ,~t/ Hum g Con~ Bedeufunn= LOt ~1 \ ?~/ Kosus = TRA ~ r - ~  7 res f r  ?
~ resfr ~ '/ J_J N.ff- "\ /%%~ I11i i Eonstituent type: PNG or ADVGin Hamburg \[ Bedoutung (mooning of ~he noun): LOCation?
.
-~Re lo f ion  \[mooning of proposition): DIRection or PLAce"ankommenl 1" corresponds to "arrive" in the meaning of "Thetrain arrives at Hamburg."
"umsteigenl 1" corresponds to"change" in the meaning of "I changed the train in Hamburg.
"The prepositional group (PNG) "in Hamburg" can be interpretedas the LOCATION attribute of "ankommenl 1" or of"umsteigen I 1".Another problem with the lexicon is that it mustn't containlexemes for many applications in order to reduce thepossibilities of 'correct' verbframes, Although the semanticsmodule in EVAR should be independent of a specific taskdomain it is not realistic to permit always all meanings of thewhole lexicon for the semantic analysis.
Therefore it is intendedto use for the first step of analysis only a part of the lexiconwhich is locally determined by the pragmatic module and thedialogue module, dependent on the dialogue context and theexpectations for the next dialogue step.
Both modules togetherhave the 'knowledge' about the world, as far as it is needed, thespecific domain and the linguistic and situative context of thedialogue.For the so far accomplished experiments two different verblexicons were used.
They were generated in a heuristic waylimitating the whole range of our domain independent lexiconto a more or less restricted task domain.
This was done prior tothe analysis because up to now the pragmatic module is notrealized.
One of these lexicons contains only verbs that are usedin our application 'Intercity Train 'Information',Other Top-down Hypotheses There are other possibilities too togenerate top-down hypotheses in the semantics module:- We try to reduce the number of the word hypotheses by firstseeking semantically compatible word groups (they need notto be adjacent, but must not be competing).
With this methodthe head verb and also descriptions for the syntacticrealization of its attributes can be predicted.- Another type o?
top-down hypotheses could be generated byseeking missing ie.
not yet instantiated attributes of averbframe, eg.
"The train leaves )'or Hamburg.
"- Sometimes the meaning of a sentence does not bear on thehead verb but on a noun in that sentence, for example "Isthere a good connection from Munich to Hamburg tomorrowmorning."
In such cases it regards a nounframe instead of averbframe assuming that the head verb is performative like"ask", "excuse" and "must" or could be combined with nearlyevery noun like "have", "be" and "become".- There is always the possibility to limitate the range of thespeech signal for the top-down hypotheses: They only have tobe sought where the so far found hypotheses are not.
Inaddition information about word order in German sentencescould often be used to restrict he possible range for a certainsentence part further.4.
Out lookExperiments with the so far implemented semantics moduleindicate that without considering the dialogue context thesemantic analysis will produce too many hypotheses.
Thereforeit will be necessary to take account of it with the furtherdevelopments by making pragmatic predictions about thefollowing user utterances.With 'knowledge of the world', a special user model whichdescribes all assumptions about the user and his intentions, anda memory about the course of the dialogue it is possible topredict the semantic and syntactic structure of the next userutterance, and also the words which can appear in tiffsstructure.t~eferences/1/: R.J.Brachman: A STRUCTURAL PARADIGM FORREPRESENTING KNOWLEDGE.
BBN Pep.
No 3605.
Revisedversion of Ph.D. Thesis, Harvard Uuiversity.
1978./2/: A.Brietzmann: SEMANTISCHE UND PRAGMATISCHEANALYSE IM ERLANGER SPRACHERKENZqUNGSPROJEKT.Dissertation.
Arbeitsberichte des Instituts fner MathematlscheMasctfinen und Datenverarbeitung (IMMD), Band 17(5),Erlangen.
1984./3/: C.J.FiUmore: The grammar of hitting and breaking.
WORKINGPAPERS IN LINGUISTICS 1, The Ohio State University RFProject 2218-c, Report 1.
In READINGS IN ENGLISHTRANSFORMATIONAL GRAIVlMAR, R.A.Jacobs &P.S.Rosenbaum (eds.).
Waltham, Mass.1967./4/: H.Niemann, A.Brietzmann, R.Muehlfeld, P.Regel, E.G.Schukat:The Speech Understanding and Dialog System EVAR.
In: NEWSYSTEMS AND ARCItlTEC'IIJRF~S FOR AUTOMATIC SPEECHRECOGNITION AND SYNTHESIS, R.de Mori & C.Y.Suen (eds.
).NATO ASI Series FI6.
Berlin etc: Springer.271-302.1985./5/: L.Tesniere: ELEMENTS DE SYNTAXE STRUCTURALE.
2ndedition.
Paris.
1966.This research was supported by the German Ministry of Research andTechnology B/riFt (in part by the joint project speech understandingin cooperation with Siemens AG, Muenchen).598
