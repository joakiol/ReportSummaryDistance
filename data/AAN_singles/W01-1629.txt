Spoken Dialogue Control Based on a Turn-minimizationCriterion Depending on the Speech Recognition AccuracyYASUDA Norihito and DOHSAKA Kohji and AIKAWA KiyoakiNTT Communication Science Laboratories3-1 Morinosato-Wakamiya, Atsugi, Kanagawa, 243-0198 Japan{yasuda, dohsaka}@atom.brl.ntt.co.jp, aik@idea.brl.ntt.co.jpAbstractThis paper proposes a new dialoguecontrol method for spoken dialoguesystems.
The method configures adialogue plan so as to minimize theestimated number of turns to com-plete the dialogue.
The number ofturns is estimated depending on thecurrent speech recognition accuracyand probability distribution of thetrue user?s request.
The proposedmethod reduces the number of turnsto complete the task at almost anyrecognition accuracy.1 IntroductionA spoken dialogue system determines userrequests from user utterances.
Spoken di-alogue systems, however, can?t determine auser?s request only from an initial utterance,because there is a limitation to automaticspeech recognition and recognition errors areunavoidable.
Thus, most spoken dialogue sys-tems confirm a user?s utterance or demand theinformation that is lacking in order to deter-mine user?s request.
Such dialogues for con-firmation or demand between the system andthe user are called ?confirmation dialogues?.Long confirmation dialogues are annoying, somore efficient confirmation is desirable.
Tomeasure the efficiency of the dialogue, we usethe number of turns (exchanges), where ofcourse, the fewer number of turns is better.In practical applications, the system canaccepts multiple types of user requests like?making a new appointment?, ?changing aschedule?, and ?inquiring about a schedule?.If the user request type is different, the re-quired information for determining the userrequest is also different.
Sometimes the userrequest type is ambiguous due to recognitionerrors, and various types of user requests arepossible.
In such a case, it is important forthe system to choose the type of user requestit will confirm at first, since it will be uselessto confirm items that are required for unlikelytype of request.The recognition accuracy affects the effi-ciency in other cases.
For example, if thereare multiple items to be confirmed, intu-itively, it seems efficient to confirm all of themat once.
However, the system must includecandidates for all attributes in recognition vo-cabulary, which cause more recognition er-rors.
Moreover, even though there is only onemisrecognized item in confirmed items, theuser might just say coldly ?No?, and the sys-tem cannot know that what are correct items.Several efficient dialogue control methodshave been proposed (Niimi and Kobayashi,1996; Litman et al, 2000).
But there is noprevious works that take into account mul-tiple types of user requests and recognitionaccuracy during confirmation, which changeswhat to be confirmed without domain-specificrules or training.To prevent needlessly long confirmation di-alogues even if the system can accepts mul-tiple types of user request, our method esti-mates the expected number of turns to a cer-tain use request type and the approximatedprobability distribution of user request types.The expected number of turns can be derivedfrom the required vocabulary for confirmationand base recognition accuracy under certainvocabulary size.2 MethodOverview First, we describe about a sys-tem to which we assume this method will beapplied.
The system has belief state whichis represented by the set of attributes, theirvalues, and the certainty of the values.
Thecertainty is in [0 .. 1], and the certainty forthe determined value is 1.
That is, if theuser replies ?Yes?
to the confirmation, thesystem changes the certainty for that value to1.
In practice, we can use the score from therecognition engine as this certainty.
The sys-tem changes the recognition vocabulary ac-cording to the attributes to be confirmed ateach confirmation.
At any given time, thesystem either confirms or demands some at-tribute(s); it doesn?t confirm and demand atthe same time.
Any values required in orderto determine the user request are explicitly-confirmed without exception.
Words that areirrelevant to the present confirmation are ex-cluded from the recognition vocabulary.
Thesystem knows the base recognition accuracyunder a certain vocabulary size, which is usedto estimate the recognition accuracy.Our method can be divided roughly intofive parts; the first three parts are used toobtain the expected number of turns, grantingthat the user request type are already known,the fourth part is used to approximate theprobability distribution of the user request,and the last part is used to decide the nextaction to be taken by the system.The system needs to know only three sortsof information: 1) the vocabulary for eachattribute; 2) the meaning constraints amongwords like ?If the family name of the personis Yasuda, then his department must be ac-counting?
; and 3) the required informationfor each type of user request like ?To can-cel an appointment; the day and the time arerequired?.
No other domain-specific rules ortraining are necessary.Guessing the Recognition AccuracyHere we consider how to estimate the recogni-tion accuracy during confirmation from con-firmation target.
Once attributes for confir-mation are decided, the recognition vocabu-lary will consist of the words accepted by theattributes and general words for moving thedialogue along that are at least necessary toprogress the dialogue such as ?Yes?, ?No?,etc.
We call the recognition accuracy at thistime the ?attribute recognition accuracy?.We adopt the rule of thumb that the recog-nition error rate is in proportion to the squareroot of vocabulary size (Rosenfeld, 1996; Nak-agawa and Ida, 1998).
Thus, the approxi-mated attribute recognition accuracy can bederived from the number of words acceptedby the attributes.Note that the attribute recognition accu-racy can?t be estimated beforehand, becausethe candidates for some attributes are dynam-ically change, as a result of the meaning con-straints among words; if the value of one at-tribute is fixed, then candidates for other at-tributes will be limited to values that satisfythe constraints.
Besides, the degree of lim-itation varies with the values.
The relationbetween the user?s family name and depart-ment is such an example.Turn Estimation to Determine SomeAttributes Next we consider how to esti-mate the expected number of turns for de-termining some attributes using the approxi-mated attribute recognition accuracy.We assume that the user?s reply to the con-firmation must contain the intention that cor-responds to ?Yes?
or ?No?, and the inten-tion must be transmitted to the system with-out fail.
Then, the expected number of turnsto complete confirming for some attributes isequal to the expected number of turns in thecase that the confirmation is incorrect (i.e.misrecognized).
Therefore, we can derive thenumber of expected turns to complete con-firming Tc and demanding Td for some at-tributes by the following expression:Tc =??t=1tr(1?
r)t?1 = 1rTd = Tc + 1 = 1 +1rwhere r denotes the attribute recognition ac-curacy for attributes that are to be confirmed.Turn Estimation to a Certain User Re-quest Type Here we estimate the expectednumber of turns, granting that the type ofuser request is already known.If the user request type is fixed, the re-quired attributes for that type are also fixed.By comparing the belief state with these at-tributes, we can represent the required actionsto determine the user request by a set of pairsmade up of attributes and actions for the at-tribute (confirmation or demand).
Once thisset of pairs is given, we can choose the optimalplan, because we can estimate the expectedturns of any permutations of any partitionsof this set.
The expected number of turnsfor this optiomal plan is used as the expectednumber of turns for a given user request type.Probability Distribution of User Re-quest Types Here, we consider how to es-timate the relevance between the belief stateand each user request types.As it is hard to obtain the actual probabil-ity distribution, we define the degree of rele-vance between the belief state and each userrequest type as an approximation.Let ai, vi, ci be the i-th attribute, the valueof ai, and the certainty of vi respectively.
Wedefine the relevance Rel(S, Rj) between thebelief state S and the user request type Rj asfor any vi which can be acceptedby Rj:Rel(S, Rj) =1NGj?
ciMviwhere NRjdenotes the number of required at-tributes in user request type Rj, and Mvide-notes the number of user requests that acceptthe value vi.Choosing the Next Action Even if thereis a highly possible user request type, choos-ing confirmation plan for it is not always best,if the expected number of turns for that re-quest is very large.
In such case, confirm-ing another type of request that is easily con-firmed and medium possibility may better.We assume that when the user request typeguessed by the system is not the real user re-quest type, the number of turns required toknow that the guess is incorrect is equal tothe number of turns when the guess is correctand finish confirming the contents.Let pRibe the probability of user requesttype Ri, and tRibe the expected number ofturns to user request type Ri.From permutations of request types,our method chooses the optimal ordera(1), a(2), .
.
.
, a(n) such that the expressionpRa(1)tRa(1)+ pRa(2)(tRa(1)+ tRa(2)) + .
.
.
+pRa(n)(tRa(1)+ .
.
.+ tRa(n)) is minimal.
Thenour method chooses the action that appearsfirst in the optimal plan for request type Ra(1)as the next action.3 ExperimentsWe evaluated the proposed method by simula-tion.
In the simulation, the system conversedwith a simulated user program.
Simulationwith a simulated user enables rapid prototyp-ing and evaluation (Eckert et al, 1998).
Theconversation was not done by exchanging spo-ken language, but by exchanging attribute-value pairs.Simulated User Program The simulateduser program works in the following steps:1.
Select a request.
The request neverchanges throughout the dialogue2.
Tell the system the request or a subset ofthe request3.
Respond Yes or No if the system confirms4.
Give corrections at random if confirma-tion contains errors5.
Respond to the demand from the system6.
Tell the system that there is no infor-mation if the system refers to attributeswith which the user is not concernedSpecification of Test Task We prepareda fictitious task for simulation.
This task ac-cepts six types of user demand.
There aresix attributes, and two of them have meaningdependence like the family name and depart-ment.
The numbers of persons, family names,and departments are 3000, 1000, 300 respec-tively.2468101214160.65 0.7 0.75 0.8 0.85 0.9 0.95 1meannumber of turnsrecognition rate under 500 words vocaburalyOur methodNaive methodFigure 1: Average number of turns to com-plete a dialogue0204060801000.65 0.7 0.75 0.8 0.85 0.9 0.95 1varianceofthenumber of turnsrecognition rate under 500 words vocaburalyOur methodNaive methodFigure 2: Variance of the number of turns tocomplete a dialogueComparison with a Naive Method Forcomparison, we prepared a naive confirmationdialogue control method, with the followingspecifications:1.
If the user request can be fixed uniquelyand there are unbound attributes re-quired for that request, demand those at-tributes one by one.2.
If there are values that are not confirmed,confirm them one by one.3.
If the user request type can?t be fixed yet,demand a value for an attribute in theorder of the number of user request typesthat require that attribute.Experimental Results Figures 1 and 2show the average number of turns and its vari-ance out of 1000 diaglogue.
We can see fromthese figures that our method can completedialogues in shorter turns than other methodsunder various levels of recognition accuracy.In addition, the variance is small in almostevery range, which illustrates the stability ofour method.4 ConclusionA new dialogue control method is proposed.The method takes into consideration the ex-pected number of turns based on the guessedrecognition accuracy and the approximatedprobability distribution of user requests.We don?t have to write domain-specificrules manually by using this method.
We canthus easily transfer domain of the system.We evaluated our method by simulation.The result shows that it can complete di-alogues in shorter turns than conventionalmethods under various recognition accuracy.AcknowledgementsWe thank Ken?ichiro Ishii, Norihiro Hagita,and all our colleagues in the Dialogue Un-derstanding Research Group for useful discus-sions.ReferencesWieland Eckert, Esther Levin, and Roberto Pier-accini.
1998.
Automatic evaluation of spokendialogue systems.
In TWLT13: Formal seman-tics and pragmatics of dialogue.Diane J. Litman, Michael S. Kearns, and Mari-lyn A. Walker.
2000.
Automatic optimizationof dialogue management.
In COLING.Seiichi Nakagawa and Masaki Ida.
1998.
Anew measure of task complexity for continuousspeech recognition.
IEICE, J81-D-II(7):1491?1500(in Japanese).Yasuhisa Niimi and Yutaka Kobayashi.
1996.
Di-alog control stragey based on the reliability ofspeech recognition.
In International Confer-ence on Spoken Language Processing, pages 25?30.R.
Rosenfeld.
1996.
A maximum entropy ap-proach to adaptive statistical language model-ing.
Computer, Speech and Language, 10:187?228.
