A Computational Treatment of Lexical Rulesin HPSG as Covariation in Lexical EntriesW.
Detmar Meurers*University of TiibingenGuido MinnenUniversity of TiibingenThis paper proposes anew computational treatment of lexical rules as used in the HPSG frame-work.
A compiler is described which translates a set of lexical rules and their interaction into adefinite clause encoding, which is called by the base lexical entries in the lexicon.
This way, thedisjunctive possibilities arising from lexical rule application are encoded as systematic covariationin the specification of lexical entries.
The compiler ensures the automatic transfer of propertiesnot changed by a lexical rule.
Program transformation techniques are used to advance the en-coding.
The final output of the compiler constitutes an efficient computational counterpart of thelinguistic generalizations captured by lexical rules and allows on-the-fly application of lexicalrules.1.
IntroductionIn the paradigm of HPSG, lexical rules have become one of the key mechanisms usedin current linguistic analysis.
Computationally, lexical rules have mainly been dealtwith in two ways: On the one hand, lexical rules are used to expand out the fulllexicon at compile-time.
On the other hand, lexical rules are encoded as unary phrasestructure rules.
Both of these computational treatments of lexical rules, however, havesignificant shortcomings with respect o lexical rules as used in HPSG.A computational treatment expanding out the lexicon cannot be used for the in-creasing number of HPSG analyses that propose lexical rules that would result in aninfinite lexicon.
Most current HPSG analyses of Dutch, German, Italian, and Frenchfall into that category.
1 Furthermore, since lexical rules in such an approach only servein a precompilation step, the generalizations captured by the lexical rules cannot beused at run-time.
Finally, all such treatments of lexical rules currently available pre-suppose a fully explicit notation of lexical rule specifications that transfer propertiesnot changed by the lexical rules to the newly created lexical entry.
This conflicts withthe standard assumption made in HPSG that only the properties changed by a lexicalrule need be mentioned.
As shown in Meurers (1994) this is a well-motivated conven-tion since it avoids splitting up lexical rules to transfer the specifications that must bepreserved for different lexical entries.?
The authors are listed alphabetically.
SFB 340, Kleine Wilhelmstr.
113, D-72074 Tiibingen, Germany.email: {dm,minnen}@sfs.nphil.uni-tuebingen.de URL: http://www.sfs.nphil.uni-tuebingen.de/sfb/b4home.html1 This is, for example, the case for all proposals working with verbal exical entries that raise thearguments of a verbal complement (Hinrichs and Nakazawa 1989) that also use lexical rules such asthe Complement Extraction Lexical Rule (Pollard and Sag 1994) or the Complement CliticizationLexical Rule (Miller and Sag 1993) to operate on those raised elements.
Also an analysis treatingadjunct extraction via lexical rules (van Noord and Bouma 1994) results in an infinite lexicon.
(~) 1997 Association for Computational LinguisticsComputational Linguistics Volume 23, Number 4Treatments of lexical rules as unary phrase structure rules also require their fullyexplicit specification, which entails the last problem mentioned above.
In addition,computationally treating lexical rules on a par with phrase structure rules fails totake computational advantage of their specific properties.
For example, the interactionof lexical rules is explored at run-time, even though the possible interaction can bedetermined at compile-time given the information available in the lexical rules andthe base lexical entries.
2Based on the research results reported in Meurers and Minnen (1995, 1996), wepropose a new computational treatment of lexical rules that overcomes these short-comings and results in a more efficient processing of lexical rules as used in HPSG.We developed a compiler that takes as its input a set of lexical rules, deduces the nec-essary transfer of properties not changed by the individual lexical rules, and encodesthe set of lexical rules and their interaction i to definite relations constraining lexicalentries.
Each lexical entry is automatically extended with a definite clause encoding ofthe lexical rule applications which the entry can undergo.
The definite clauses therebyintroduce what we refer to as systematic covariation in lexical entries.Definite relations are a convenient way of encoding the interaction of lexical rules,as they readily support various program transformations to improve the encoding: Weshow that the definite relations produced by the compiler can be refined by programtransformation techniques to increase fficiency.
The resulting encoding allows theexecution of lexical rules on-the-fly, i.e., coroutined with other constraints at sometime after lexical lookup.
The computational treatment of lexical rules proposed canbe seen as an extension to the principled method discussed by G6tz and Meurers(1995, 1996, 1997b) for encoding the main building block of HPSG grammars--theimplicative constraints--as  logic program.The structure of the paper is as follows: We start with a brief introduction of theformal background on which our approach is based in Section 2.
We then describe(Section 3) how lexical rules and their interaction can be encoded in a definite clauseencoding that expresses systematic covariation in lexical entries.
We show how theencoding of lexical rule interaction can be improved by specializing it for differentword classes and, in Section 4, focus on an improvement of this specialization stepby means of program transformation techniques.
A further improvement relevant toon-the-fly application of lexical rules is presented in Section 5.
In Section 6, we dis-cuss implementation results and illustrate the efficiency of the proposed encoding.
Acomparison with other computational approaches to lexical rules (Section 7) and someconcluding remarks (Section 8) end the paper.2.
BackgroundIn this section we introduce the formal setup of HPSG grammars that we assume anddiscuss two ways to formalize a lexical rule mechanism and their consequences for acomputational treatment.2.1 A Formal Setup for HPSG GrammarsAn HPSG grammar formally consists of two parts (Pollard and Sag 1994): The signaturedefines the ontology of linguistic objects, and the theory, i.e., the usually implicativeconstraints encoding the grammatical principles, describes the subset of those linguistic2 This is not to say that a special precompilation treatment along those lines would not be profitable forphrase structure ules.
In fact, such a proposal ismade by Torisawa nd Tsuji (1996).544Meurers and Minnen Covariation Approach to HPSG Lexical Rulesobjects that are grammatical.
The constraints constituting the theory are expressionsof a formal language that define the set of grammatical objects, in the sense that everygrammatical object is described by every principle in the theory.The signature consists of the type hierarchy defining which types of objects ex-ist and the appropriateness conditions pecifying which objects have which featuresdefined on them to represent their properties.
3 A signature is interpreted as follows:Every object is assigned exactly one most specific type, and in case a feature is ap-propriate for some object of a certain type, then it is appropriate for all objects of thistype.
4A logic that provides the formal architecture required by Pollard and Sag (1994)was defined by King (1989, 1994).
The formal language of King allows the expressionof grammatical principles using type assignments to refer to the type of an objectand path equalities to require the (token) identity of objects.
These atomic expressionscan be combined using conjunction, disjunction, and negation.
The expressions areinterpreted by a set-theoretical semantics.2.2 Lexical Rules in HPSGWhile the setup of King provides a clear formal basis for basic HPSG grammars,nothing is said about how special inguistic mechanisms like lexical rules fit into thisformal setup.
Two formalizations of lexical rules as used by HPSG linguists have beenproposed, the meta-level lexical rules (MLRs; Calcagno 1995; Calcagno and Pollard1995) and the .description-level l xical rules (DLRs; Meurers 1995).
52.2.1 Meta-Level Lexical Rules.
The MLR approach sees lexical rules in the moretraditional sense as relations between lexical entries, i.e., descriptions of word objects.The set of lexical entries constituting the lexicon is closed under the application oflexical rules, which results in a (possibly infinite) set of lexical entries.
In order to begrammatical, every word object occurring in a sentence has to be described by one ofthe descriptions in this expanded lexicon set.
In the MLR setup, lexical rules are thusexternal to the rest of the theory, they only serve to provide an expanded lexicon set.Licensing grammatical words is then done by this set--the lexical rules play no directrole.
Externalizing the lexicon and lexical rule application from the theory in such away has an interesting consequence, namely that the lexical entries serving as inputto a lexical rule are not tested for grammaticality.A computational treatment of lexical rules that expands out the lexicon at compile-time closely resembles the MLR interpretation of lexical rules.
The work on MLRs cantherefore be seen as providing a semantics for such a computational treatment.
It alsoallows a clear view of its restrictions: First, no restrictions on lexical entries servingas input to a lexical rule can be enforced that cannot be executed on the basis ofthe information present in the lexical entry alone, 6and second, grammars includinglexical rules that, under the MLR formalization, result in an infinite lexicon, can only3 The terminology used in the literature varies.
Types are also referred to as sorts, appropriatenessconditions as feature declarations, and features as attributes.
To avoid confusion, we will only use theterminology introduced in the text.4 This interpretation f the signature is sometimes referred to as closed world (Gerdemann and King1994; Gerdemann 1995).5 An in-depth discussion including a comparison of both approaches i provided in Calcagno, Meurers,and Pollard (in preparation).6 The Partial-VP Topicalization Lexical Rule proposed by Hinrichs and Nakazawa (1994, 10) is alinguistic example.
The in-specification of this lexical rule makes use of an append relation to constrainthe valence attribute of the auxiliaries erving as its input.
In the lexicon, however, the complements ofan auxiliary are uninstantiated because it raises the arguments of its verbal complement.545Computational Linguistics Volume 23, Number 4simple-word ---* LE1 v .
.
?
V LEnderived-word ~ (\[IN LRl-in\] A LRl-out) V .
.
.
V (\[IN LRm-in\] A LRm-oUt)Figure 1The extended lexicon under the DLR approach.partially be dealt with, for example, by using a depth bound on lexical rule applicationto ensure that a finite number of lexical entries is obtained.
72.2.2 Description-Level Lexical Rules.
The DLR approach formalizes lexical rulesas relations between word objects.
Lexical rules under this approach are part of thetheory, just like any other constraint of the grammar, and they relate the word objectslicensed by the base lexical entries to another set of well-formed word objects.
Thus,under the DLR approach, no new lexical entries are created, but the theory itself isextended in order to include lexical rules.
One possibility for extending the theory isto introduce two subtypes of word, i.e., simple-word and derived-word, and define anadditional feature IN with appropriate value word for objects of type derived-word.
Theprinciples encoding the extended lexicon in such an approach are shown in Figure 1.Each basic lexical entry is a disjunct LE in an implicative constraint on simple-word.This disjunction thus constitutes the base lexicon.
The disjuncts in the constraint onderived-word, on the other hand, encode the lexical rules.
The in-specification of alexical rule specifies the IN feature, the out-specification, the derived word itself.
Notethat the value of the IN feature is of type word and thus also has to satisfy either abase lexical entry or an out-specification f a lexical rule.
While this introduces therecursion ecessary to permit successive l xical rule application, it also grounds therecursion in a word described by a base lexical entry.
Contrary to the MLR setup, theDLR formalization therefore requires all words feeding lexical rules to be grammaticalwith respect o the theory.Since lexical rules are expressed in the theory just like any other part of the theory,they are represented in the same way, as unary immediate dominance schemata.
8 Thisconception of lexical rules thus can be understood as underlying the computationalapproach that treats lexical rules as unary phrase structure rules as, for example,adopted in the LKB system (Copestake 1992).
Both the input and output of a lexicalrule, i.e., the mother and the daughter of a phrase structure rule, are available duringa generation or parsing process.
As a result, in addition to the information presentin the lexical entry, syntactic information can be accessed to execute the constraintson the input of a lexical rule.
The computational treatment of lexical rules that wepropose in this paper is essentially a domain-specific refinement of such an approachto lexical rules.
92.2.3 Lexical Rule Specification and Framing.
An important difference between unaryimmediate dominance schemata nd lexical rules, however, is that immediate dom-inance schemata re fully specified in the linguistic theory and can thus be directlyinterpreted as a relation on objects.
Lexical rules, on the other hand, are usually not7 This approach is, for example, taken in the ALE system.
See Section 7 for more discussion of differentcomputational  pproaches.8 Elaborating this analogy, the IN feature of derived words can be understood as the DTRS feature of aphrase.9 See Section 7 for a more detailed discussion of the relation between our approach and this perspectiveon lexical rules.546Meurers and Minnen Covariation Approach to HPSG Lexical Rulessl\] LOC\] CATLOC\[CATHEADVALHAVrFbVFOOpsP tlJsu , INDEX \[VAL (IL 'CONTLCOMpS /\[LOC\]CONTll NDEX \[~\]1 \[\]t---+VFORM pas\]SUBJ / \[LOC\] CONT \[ INDEX \[\]\]// (\[LOC ICATI HEAD prep\[ PFORMCOMPS \[\] O L CONT\]INDEX \[\]Figure 2A passivization lexical rule.written as fully specified relations between words, rather, only what is supposed tobe changed is specified.Consider, for example, the lexical rule in Figure 2, which encodes a passive lexicairule like the one presented by Pollard and Sag (1987, 215) in terms of the setup ofPollard and Sag (1994, ch.
9).
This lexical rule could be used in a grammar of Englishto relate past participle forms of verbs to their passive form2 ?The rule takes the indexof the least oblique complement of the input and assigns it to the subject of the output.The index that the subject bore in the input is assigned to an optional prepositionalcomplement in the output.Only the verb form and some indices are specified to be changed, and thus otherinput properties, like the phonology, the semantics, or the nonlocal specifications, arepreserved in the output.
This is so since the lexical rule in Figure 2 "(like all lexical rulesin HPSG) preserves all properties of the input not mentioned in the rule."
(Pollard andSag \[1994, 314\], following Flickinger \[1987\]).
This idea of preserving properties can beconsidered an instance of the well-known frame problem in AI (McCarthy and Hayes1969), and we will therefore refer to the specifications left implicit by the linguist as theframe specification, or simply frame, of a lexical rule.
Not having to represent the frameexplicitly not only enables the linguist to express only the relevant hings, but alsoallows a more compact representation f lexical rules where explicit framing wouldrequire the rules to be split up (Meurers 1994).One thus needs to distinguish the lexical rule specification provided by the linguistfrom the fully explicit lexical rule relations integrated into the theory.
The formalizationof DLRs provided by Meurers (1995) defines aformal exical rule specification languageand provides a semantics for that language in two steps: A rewrite system enriches thelexical rule specification i to a fully explicit description of the kind shown in Figure 1.This description can then be given the standard set-theoretical interpretation f King(1989, 1994).
1110 Note that the passivization lexical rule in Figure 2 is only intended to illustrate the mechanism.
We donot make the linguistic claim that passives hould be analyzed using such a lexical rule.
For spacereasons, the SYNSEM feature is abbreviated by its first letter.
The traditional (First I Rest) list notation isused, and the operator ?
stands for the append relation in the usual way.1l Manandhar (1995) proposes to unify these two steps by including an update operator in the547Computational Linguistics Volume 23, Number 4The computational treatment we discuss in the rest of the paper follows this setupin that it automatically computes, for each lexical rule specification, the frames neces-sary to preserve the properties not changed by it.
12 We will show that the detectionand specification of frames and the use of program transformation to advance theirintegration into the lexicon encoding is one of the key ingredients of the covariationapproach to HPSG lexical rules.3.
Lexical Covariation: Encoding Lexical Rules and their Interactionas Definite RelationsHaving situated the computational pproach presented in this paper as a computa-tional treatment of DLRs that emphasizes their domain-specific properties, we nowturn to the compiler that realizes this approach.
We describe four compilation stepsthat translate a set of lexical rules, as specified by the linguist, and their interactioninto definite relations to constrain lexical entries.
To give the reader a global idea ofour approach, we focus on those aspects of the compiler that are crucial to the pre-sented conception of lexical rules.
The different steps of the compiler are discussedwith emphasis on understandabil ity and not on formal details.
13Figure 3 shows the overall setup of the compiler.
The first compilation step, dis-cussed in Section 3.1, translates lexical rules into a definite clause representation a dderives, for each lexical rule, a frame predicate that ensures the transfer of propertiesthat remain unchanged.
In the second compilation step (Section 3.2), we determine thepossible interaction of the lexical rules.
This results in a finite-state automaton repre-senting global lexical rule interaction, i.e., the interaction of lexical rules irrespectiveof the lexical entries in the lexicon.
In the subsequent step of word class specialization(Section 3.3) this finite-state automaton is fine-tuned for each of the natural classesof lexical entries in the lexicon.
In the fourth compilation step (Section 3.4) these au-tomata are translated into definite relations and the lexical entries are adapted to callthe definite relation corresponding to the automaton fine-tuned for the natural classto which they belong.3.1 Lexical Rules as Definite Relations and the Automatic Specification of FramesWe start by translating each lexical rule into a definite clause predicate, called thelexical rdle predicate.
The first argument of a lexical rule predicate corresponds to thein-specification of the lexical rule and the second argument to its out-specification.Assume the signature in Figure 4 on which we base the example throughout thepaper and suppose the lexical rule specification shown in Figure 5.14 This lexical ruleapplies to base lexical entries that unify 15 wi th  the in-specification, i.e., lexical entriesspecifying B and Y as - .
The derived lexical entry licenses word objects with + as thevalue of x and Y, and b as that of A.The translation of the lexical rule into a predicate is trivial.
The result is displayeddescription language.12 In order to focus on the computational aspects of the covariation approach, in this paper we will not gointo a discussion of the full lexical rule specification language introduced in Meurers (1995).
The readerinterested in that language and its precise interpretation can find the relevant details in that paper.13 A more detailed presentation can be found in Minnen (in preparation).14 We use rather abstract lexical rules in the examples to be able to focus on the relevant aspects.15 Hinrichs and Nakazawa (1996) show that the question of whether the application criterion of lexicalrules should be a subsumption ra unification test is an important question deserving of moreattention.
We here assume unification as the application criterion, which formally corresponds totheconjunction ofdescriptions and their conversion to normal form (G6tz 1994).
Computationally, asubsumption test could equally well be used in our compiler.548Meurers and Minnen Covariation Approach to HPSG Lexical Rulesinput :output :Figure 3The compiler setup.~ x i c o ~  +translationI of lexical rulesintodefinite relations~ ~ ~ ~ ~ f  ~ ~medetermination oflexical ruleinteractionword class3 specialization oflexical ruleinteractionprunedfinite state / /translation4 of lexical rulesinteraction intodefinite relationsin Figure 6.
Though this predicate represents what was explicitly specified in the lexi-cal rule, it does not accomplish exactly what is intended.
As discussed in Section 2.2.3,features specified in a lexical entry unifying with the in-specification of the lexical rulethat are not specified differently in the out-specification of the lexical rule are intendedto receive the same value on the derived word as on the input: The compiler imple-ments this by enriching the lexical rule with type specifications and path equalitiesbetween the in- and the out-specification to arrive at an explicit representation of itsframe.The detection of which additional specifications are intended by the linguist cru-cially depends on the interpretation of the signature assumed in HPSG, discussed inSection 2.1.
This interpretation makes it possible to determine which kind of wordobjects (by ontological status fully specified) may undergo the rule.
A type can alwaysbe replaced by a disjunction of its most specific subtypes and the appropriate features549Computational Linguistics Volume 23, Number 4Tt\[w bool 1 val \] x bool|t, t2\[z list\]Figure 4An example signature.list bool valAAelist \[HD val\] + _ a bnelist TL list\]\[c,YFigure 5Lexical rule 1.lex-rule-l(\[B \ [y - - \ ] \ ] , \ [~  \[ bX ~\] \ ] )Figure 6Definite clause representation f lexical rule 1.word\[C tl\]Figure 7A sample lexical entry.of each type are known.
So, on the basis of the signature, we can determine which"appropriate" paths the linguist left unspecified in the out-specification f the lexicalrule.
For those appropriate paths not specified in the out-specification, one can thenadd path equalities between the in- and the out-specifications of the lexical rule toensure framing of those path values.Frame specification becomes lightly more difficult when one considers type spec-ifications of those paths in words serving as input to a lexical rule that occur in theout-specification f the lexical rule but are not assigned a type value.
For example, thelexical rule 1 of Figure 6 applies to word objects with tl as their c value and to thosehaving t2 as their c value.
With respect o frame specification this means that therecan be lexical entries, such as the one in Figure 7, for which we need to make surethat tl as the value of c gets transferred.
16One would think that the type information tl, which is more specific than that16 A linguistic example based on the signature given by Pollard and Sag (1994) would be a lexical rulederiving predicative signs from nonpredicative ones, i.e., changing the PRD value of substantive signsfrom - to +, much like the lexical rule for NPs given by Pollard and Sag (1994, p. 360, fn.
20).
In sucha Predicative Lexical Rule (which we only note as an example and not as a linguistic proposal) thesubtype of the head object undergoing the rule as well as the value of the features only appropriate forthe subtypes of substantive either is lost or must be specified by a separate rule for each of the subtypes.550Meurers and Minnen Covariation Approach to HPSG Lexical Rulesb lex lel, \[:, _,\]ollx framelFigure 8Lexical rule predicate representing lexical rule 1.\[B o lIB \ ] c  w r frame_l( , ).
frame_l( |W tl \[ ~1\] Ch\[W ~\] L t2LZFigure 9Definition of the frame predicate for lexical rule 1.given in the output of the lexical rule, can be specified on the out-specification of thelexical rule if the specification of c is transferred as a whole (via structure sharing ofthe value of c).
This is not possible, though, since the values of x and Y are specifiedin the out-specification of the lexical rule.
The problem seems to be that there is nonotion of sharing just the type of an object.
However,  introducing such type sharingwould not actually solve the problem, since one also needs to account for additionalappropriate features.
The subtypes of t have different appropriate features, the valuesof which have to be preserved.
In particular, in case the lexical entry has t2 as thevalue of c, we need to ensure that the value of the feature z is transferred properly.To ensure that no information is lost as a result of applying a lexical rule, itseems to be necessary to split up the lexical rule to make each instance deal witha specific case.
In the above example, this would result in two lexical rules: one forwords with tl as their c value and one for those with t2 as their c value.
In thelatter case, we can also take care of transferring the value of z.
However, as discussedby Meurers (1994), creating several instances of lexical rules can be avoided.
Instead,the disjunctive possibilities introduced by the frame specification are attached as aconstraint o a lexical rule.
This is accomplished by having each lexical rule predicatecall a so-called frame predicate, which can have multiple defining clauses.
So for thelexical rule 1, the frame specification is taken care of by extending the predicate inFigure 6 with a call to a frame predicate, as shown in Figure 8.17On the basis of the lexical rule specification and the signature, the compiler de-duces the frame predicates without requiring additional specifications by the linguist.The frame predicate for lexical rule 1 is defined by the two clauses displayed in Fig-ure 9.
The first case applies to lexical entries in which c is specified as tl.
We have toensure that the value of the feature w is transferred.
In the second case, when featurec has t2 as its value, we additionally have to ensure that z gets transferred.
Note thatneither clause of the frame predicate needs to specify the features A, X, and Y sincethese features are changed by lex_rule_l.
Furthermore, filling in features of the struc-ture below z is unnecessary as the value of z is structure shared as a whole.
Finally, ifa lexical entry specifies c as t, bothframe_l c auses apply.
TM17 We use indexing of predicate names to be able to indicate later on which lexical rule a frame predicatebelongs to.18 Since in computational systems, in contrast to the general theoretical case, we only need to ensuretransfer for the properties actually specified in the lexical entries of a given grammar, some of thedistinctions made in the signature can possibly be ignored.
One could therefore improve thecalculation of frame predicates by taking the base lexical entries into account at this stage of the551Computational Linguistics Volume 23, Number 4i V - - .V  nFigure 10Finite-state automaton representing free application.Summing up, we distinguish the lexical rule predicates encoding the specificationof the linguist from the frame predicates taking care of the frame specification.
Basedon the signature, the frame predicates are automatically derived from the lexical rulepredicates and they can have a possibly large number of defining clauses.
In Sec-tion 4 we will show that the encoding can be advanced in a way that eliminates thenondeterminism introduced by the multiply defined frame predicates.3.2 Determining Global Lexical Rule InteractionIn the second compilation step, we use the definite clause representation f a setof lexical rules, i.e., the lexical rule and the frame predicates, to compute a finite-state automaton representing how the lexical rules interact (irrespective of the lexicalentries).In general, any lexical rule can apply to the output of another lexical rule, which issometimes referred to as free application.
As shown in Figure 10, this can be representedas a finite-state automaton that consists of a single state with a cycle from/into thisstate for all lexical rules.
19 When looking at a specific set of lexical rules though, onecan be more specific as to which sequences of lexical rule applications are possible.
Onecan represent this information about he interaction of lexical rules as a more complexfinite-state automaton, which can be used to avoid trying lexical rule applications atrun-time that are bound to fail.
To derive a finite-state automaton representing globallexical rule interaction, we first determine which lexical rules can possibly follow whichother lexical rules in a grammar.
The set of follow relationships i  obtained by testingwhich in-specifications unify with which out-specifications.
2?To illustrate the steps in determining lobal lexical rule interaction, let us addthree more lexical rules to the one discussed in Section 3.1.
Figure 11 shows the fullset of four lexical rules.Figure 12 shows the definite clause representations of lexical rules 2, 3, and 4 andthe frame predicates derived for them.
The definite clauses representing lexical rule 1and its frame were already given in Figures 8 and 9.
The follow relation obtained forthe set of four lexical rules is shown in Figure 13, where follow(LR,ListOfLRs) specifiescompilation process.19 We use the following conventions with respect o finite-state automata to represent lexical ruleinteraction: The state annotated with an angle bracket represents the initial state.
All states (includingthe initial state) are final states.
The labels of the transitions from one state to another are (disjunctionsof) the lexical rule predicate indices, i.e., the lexical rule names constitute the alphabet of the finite-stateautomaton.20 For the computation of the follow relationships, the specifications of the frame predicates are taken intoaccount.
In case the frame relation called by a lexical rule has several defining clauses, thegeneralization of the frame possibilities is used.552Meurers and Minnen Covariation Approach to HPSG Lexical RulesRule 1:Rule 3:C\[Y --\] ~ C\[ X Rule 2:c r w +\]\] \[c\[Y t2 LZ \] TL ~ ~ Rule 4:Figure 11A set of four lexical rules.c\[w -\]\ [B -  \]1 c I w , ~ \[:Ex+dL t2 LZ 0lex_rule_2(\[/ll BA b-L C\[W -\]\]'E\]\[C\[W +\]\]):- frame2(\[~).
'ex~'e~,OVC \[WL t2LZIwlex_rule_4(~ C xL taL z+\]\]\[ l\] TL ~ ' [~ C [ YZ ~ ):-frame-3(\[~'m)'(~\] ,\[~\]\[~\[X+ _ ]\]):- frame_4(\[~I~).r frame-2( C Ix ~\] ' C t l Ltl "Y x ).B \['~ B ~\]frame-3( C rw ~\] ' c t 2 L  t2 uX xW ).Figure 12The definite clause encoding of lexical rules 2, 3, and 4.IA BO IA iBO fra~e~, c \[X~ 'C X~ ~L t2 Lz t2 zwo 1\]\[;i 1 \[\] frame-4( Ct2 zY ~ ' t2 Z yW [.~ ).follow(I, \[2, 3, 4\]).
follow(2, \[1, 3, 4\]).
follow(3, \[3, 4\]).
follow(4, \[\]).Figure 13The follow relation for the four lexical rules of the example.that only the lexical rules in ListOfLRs can possibly be applied to a word resultingfrom the application of lexical rule LR.Once the follow relation has been obtained, it can be used to construct an automa-ton that represents which lexical rule can be applied after which sequence of lexicalrules.
Special care has to be taken in case the same lexical rule can apply several timesin a sequence.
To obtain afinite automaton, such a repetition is encoded as a transitioncycling back to a state in the lexical rule sequence preceding it.In order to be able (in the following steps) to remove a transition representinga certain lexical rule application in one sequence without eliminating the lexical ruleapplication from other sequences, every transition, except hose introducing cycles, istaken to lead to a new state.
The finite-state automaton in Figure 14 is constructed onthe basis of the follow relation of Figure 13.553Computational Linguistics Volume 23, Number 4q19q2 1 1 3 4 q15 3 4 q20q5 4 ~ )  ql  2Figure 14Finite-state automaton representing global exical rule interaction.The finite-state automaton representing global lexical rule interaction can be usedas the backbone of a definite clause encoding of lexical rules and their interaction(see Section 3.4).
Compared to free application, the finite-state automaton i Figure 14limits the choice of lexical rules that can apply at a certain point.
However, there stillare several places where the choices can be further educed.
One possible reductionof the above automaton consists of taking into account he propagation ofspecificationsalong each possible path through the automaton.
This corresponds toactually unifyingthe out-specification f a lexical rule with the in-specification of the following lexicalrule along each path in the automaton, instead of merely testing for unifiability, whichwe did to obtain the follow relation.
21 As a result of unifying the out-specificationof a lexical rule in a path of the finite-state automaton with the in-specification ofthe following lexical rule, the out-specification f the second rule can become morespecific.
This is because of the structure sharing between the second lexical rule's in-and out-specifications, which stem from the lexical rule and its frame specification.This makes it possible to eliminate some of the transitions that seem to be possiblewhen judging on the basis of the follow relation alone.
22For example, solely on the basis of the follow relation, we are not able to discoverthe fact that upon the successive application of lexical rules 1 and 2, neither lexical rule1 nor 2 can be applied again.
Taking into account he propagation of specifications,the result of the successive application of lexical rule 1 and lexical rule 2 in any order(leading to state q7 or q9) bears the value + on features w and Y.
This excludes lexical21 The reason for first determining the automaton on the basis of the follow relation alone, instead oftaking propagation of specifications into account right from the start, is that the follow relations allowa very simple construction of a finite-state automaton representing lexical rule interaction.
Usingunification right away would significantly complicate the algorithm, in particular for automatacontaining cycles.22 Note that in the case of transitions belonging to a cycle, only those transitions can be removed that areuseless at the first visit and after any traversal of the cycle.554Meurers and Minnen Covariation Approach to HPSG Lexical Rulesj\] W -- ).
lex_entry( C X iZ ,bt2Figure 15A lexical entry.rules 1 and 2 as possible followers of that sequence since their in-specifications do notunify with those values.
As a result, the arcs 1(q7, q2) and 2(q9, q3), which are markedwith grey dots in Figure 14, can be removed.Two problems remain: First, because of the procedural interpretation of lexicalrules, duplicate lexical entries can possibly be derived.
And second, relative to a spe-cific lexical entry, many sequences of lexical rules that are bound to fail are tried any-way.
We tackle these problems by means of word class specialization, i.e., we prunethe automaton with respect o the propagation of specifications belonging to the baselexical entries.3.3 Word Class Specialization of Lexical Rule InteractionIn the third compilation step, the finite-state automaton representing lobal lexicalrule interaction is fine-tuned for each base lexical entry in the lexicon.
The result isa pruned finite-state automaton.
The pruning is done by performing the lexical ruleapplications corresponding to the transitions in the automaton representing loballexical rule interaction.
To ensure termination in case of direct or indirect cycles, weuse a subsumption check.
If the application of a particular lexical rule with respectto a lexical entry fails, we know that the corresponding transition can be pruned forthat entry.
In case of indirect or direct cycles in the automaton, however, we cannotderive all possible lexical entries, as there may be infinitely many.
Even though one canprune certain transitions even in such cyclic cases, it is possible that certain inapplicabletransitions remain in the pruned automaton.
However, this is not problematic since thelexical rule application corresponding to such a transition will simply fail at run-time.Consider the base lexical entry in Figure 15.
With respect o this base lexical en-try, we fine-tune the finite-state automaton representing global lexical rule interactionby pruning transitions.
In the automaton of Figure 14, we can prune the transitions{3(q2, q8), 4(q2, q6), 3(q3, q11), 4(q3, ql0), 3(ql, q4), 4(ql, q5)}, because the lexical rules3 and 4 can not be applied to a (derived) lexical entry that does not have both wand x of value +.
As a consequence, the states q8, q15, q11, q18, q4, and q12 are nolonger reachable and the following transitions can be eliminated as well: {3(q8,q8),4(q8, q15), 3(q11, q11), 4(q11, q18), 3(q4, q4), 4(q4, q12)}.
We can also eliminate the tran-sitions {4(q7,q13),4(q9, 17)}, because the lexical rule 4 requires the value of z to beempty list.
Note that the lexical rules 3 and 4 remain applicable in q14 and q16.Furthermore, due to the procedural interpretation of lexical rules in a computa-tional system (in contrast o the original declarative intention), there can be sequencesof lexical rule applications that produce identical entries.
23 To avoid having arcs inthe pruned automaton leading to such identical entries, we use a tabulation method23 Note that the order in which two lexical rules are applied is immaterial as long as both rules modifythe value of different features of a lexical entry.555Computational Linguistics Volume 23, Number 431 2 3 ~,.,~ 4q3Figure 16Pruned finite state automaton representing lexical rule interaction for a lexical entry.during word class specialization that keeps track of the feature structures obtained foreach node.
If we find a feature structure for a node qn that is identical to the featurestructure corresponding to another node qm, the arc leading to qn or the arc leadingto qm is discarded.
24In the example, q7 and q9 are such identical nodes.
So we candiscard either 2(q2, q7) or 1(q3, q9) and eliminate the arcs from states that then becomeunreachable.
Choosing to discard 1(q3, q9), the pruned automaton for the examplelexical entry looks as displayed in Figure 16.
25Note that word class specialization of lexical rule interaction does not influence therepresentation f the lexical rules themselves.
Pruning the finite-state automaton rep-resenting lobal lexical rule interaction only involves restricting lexical rule interactionin relation to the lexical entries in the lexicon.The fine-tuning of the automaton representing lexical rule interaction results ina finite-state automaton for each lexical entry in the lexicon.
However, identical au-tomata are obtained for certain groups of lexical entries and, as shown in the nextsection, each automaton is translated into definite relations only once.
We thereforeautomatically group the lexical entries into the natural classes for which the linguistintended a certain sequence of lexical rule applications to be possible.
26 No additionalhand-specification is required.
Moreover, the alternative computational treatment toexpand out the full lexicon at compile-time is just as costly and, furthermore, impos-sible in case of an infinite lexicon.An interesting aspect of the idea of representing lexical rule interaction for partic-ular word classes is that this allows a natural encoding of exceptions to lexical rules.More specifically, the linguist specifies exceptions as a special property of either a lex-ical rule or a lexical entry.
During word class specialization, the compiler then dealswith such specifications by pruning the corresponding transitions in the finite-stateautomaton representing global lexical rule interaction for the particular lexical entryunder consideration.
This results in an encoding of exceptions to a lexical rule in theinteraction predicate called by the irregular lexical entries.
An advantage of the setuppresented is that entries that behave according to subregularities will automatically begrouped together again and call the same interaction predicate.
The final representa-24 In general, there is not always enough information available to determine whether two sequences oflexical rule applications produce identical entries.
This is because in order to be able to treat recursivelexical rules producing infinite lexica, we perform word class specialization of the interaction predicateinstead of expanding out the lexicon.25 Note that an automaton can be made even more deterministic by unfurling instances of cycles prior topruning.
In our example, unfurling the direct cycle by replacing 3(q14, q14) with{3(q14, q14~), 3(q14 ~, q14~), 4(q14 ~, q19~)} would allow pruning of the cyclic transition 3(q14 ~, q14 ~) andthe transition 4(q14, q19).
Note, however, that unfurling of the first n instances of a cycle does notalways allow pruning of transitions, i.e., reduce nondeterminism.26 The pruned finite-state automaton constitutes valuable feedback, as it represents he interaction of theset of lexical rules possible for a word class in a succinct and perspicuous manner.556Meurers and Minnen Covariation Approach to HPSG Lexical RulesW mlex_entry(I-6~):- q_l( X ~ ,\[~\]).Z ,bt2Figure 17An extended lexical entry.tion of the lexical rules and the lexical entries remains, without a special specificationof exceptions.
273.4 Lexical Rule Interaction as Definite Relat ionsIn the fourth compilation step, the finite-state automata produced in the last step areencoded in definite clauses, called interaction predicates.
The lexical entries belongingto a particular natural class all call the interaction predicate ncoding the automatonrepresenting lexical rule interaction for that class.
Figure 17 shows the extended versionof the lexical entry of Figure 15.
The base lexical entry is fed into the first argumentof the call to the interaction predicate q_l.
For each solution to a call to q_l the valueof ~ is a derived lexical entry.Encoding a finite-state automaton as definite relations is rather straightforward.In fact, one can view the representations as notational variants of one another.
Eachtransition in the automaton is translated into a definite relation in which the corre-sponding lexical rule predicate is called, and each final state is encoded by a unitclause.
Using an accumulator passing technique (O'Keefe 1990), we ensure that uponexecution of a call to the interaction predicate q_l a new lexical entry is derived asthe result of successive application of a number of lexical rules.
Because of the wordclass specialization step discussed in Section 3.3, the execution avoids trying out manylexical rule applications that are guaranteed to fail.We illustrate the encoding with the finite-state automaton of Figure 16.
As thelexical rules themselves are already translated into a definite clause representation inthe first compilation step, the interaction predicates only need to ensure that the rightcombination of lexical rule predicates i called.
The interaction predicate ncoding thefinite-state automaton of Figure 16 is shown in Figure 18.
28We now have a first complete ncoding of the lexical rules and their interaction repre-sented as covariation i  lexical entries.
The encoding consists of three types of definiteclause predicates:1.
Lexical rule predicates representing the lexical rules;2.
Frame predicates specifying the frame for the lexical rule predicates; and3.
Interaction predicates encoding lexical rule interaction for the naturalclasses of lexical entries in the lexicon.The way these predicates interconnect is represented in Figure 19.27 Briscoe and Copestake (1996) argue that semi-productivity of lexical rules, which can be understood asa generalization of exceptions to lexical rules, can be integrated with our approach by assigningprobabilities to the automaton associated with a particular lexical entry.28 In order to distinguish the different interaction predicates for the different classes of lexical entries, thecompiler indexes the names of the interaction predicates.
Since for expository reasons we will onlydiscuss one kind of lexical entry in this paper, we will not show those indices in the examples given.557Computational Linguistics Volume 23, Number 4q_l(E\]~):- lex_rule_l(\[~,~,q_l(\[~\]):- lexxule.2(\[~\[g/~,q_2(\[~\]~\]):- lexn'ule.2(\[~\],\[~),q_7(D~\],\[-6-~):- lex_rule_3(E\],\[~),q_14 (\[~\],\[~) :-lex ~-ule _3 (E\],\[X~,q_14 (\[/T\],\[O~):-lex ~ule _4 (E\],\[X~),q~2(~\[~).q_3(\[NNN~.q_7(\[d~\[~\]).q_14(\[x~\],\[~\]).q_14(\[-X~,\[~\]).q_l 9(rA-~,\[~\]).q_l(E\]~\]), q2(E\]E), q_3(E\]~, q_7(\[~\[~\]), q_14(\[~E\]), q_19(\[~\[~\]).Figure 18The definite relations representing the pruned finite state automaton of Figure 16.extended lexical entriescall I= in teract ion  predicatescall I= lex ica l  ru le  predicatescall \[--- frame predicatesFigure 19Schematic representation f definite clause encoding of lexical rules and their interaction.4.
Partial Unfolding of Frame PredicatesThe automata resulting from word class specialization group the lexical entries intonatural classes.
In case the automata corresponding to two lexical entries are identical,the entries belong to the same natural class.
However, each lexical rule application, i.e.,each transition in an automaton, calls a frame predicate that can have a large numberof defining clauses.
Intuitively understood, each defining clause of a frame predicatecorresponds to a subclass of the class of lexical entries to which a lexical rule can beapplied.
During word class specialization, though, when the finite-state automatonrepresenting global lexical rule application is pruned with respect o a particular baselexical entry, we know which subclass we are dealing with.
For each interaction defini-tion we can therefore check which of the flame clauses are applicable and discard thenon-applicable ones.
We thereby eliminate the redundant nondeterminism resultingfrom multiply defined frame predicates.The elimination of redundant nondeterminism is based on Unfold/Fold trans-formation techniques (Tamaki and Sato 1984).
29 The unfolding transformation is alsoreferred to as partial execution, for example, by Pereira and Shieber (1987).
Intuitivelyunderstood, unfolding comprises the evaluation of a particular literal in the body ofa clause at compile-time.
As a result, the literal can be removed from the body of29 This improvement of the covariation encoding can also be viewed as an instance of the programtransformation technique r ferred to as deletion of clauses with a finitely failed body (Pettorossi and Proietti1994).558Meurers and Minnen Covariation Approach to HPSG Lexical Rulesextended lexical entriescall I.~ interaction predicatescall unfoldingc unfoldingFigure 20Schematic representation f the successive unfolding transformation.extended lexical entriescall I,, interaction predicatesca l l,, lexical rule predicates "~ unfolding/ call.~ frame predicates /Figure 21Schematic representation f the partial unfolding transformation.the clause.
Whereas unfolding can be viewed as a symbolic way of going forward incomputation, folding constitutes a symbolic step backwards in computation.Given a lexical entry as in Figure 15, we can discard all frame clauses that presup-pose tl as the value of c, as discussed in the previous section.
To eliminate the framepredicates completely, we can successively unfold the frame predicates and the lexicalrule predicates with respect o the interaction predicates.
3?
The successive unfoldingsteps are schematically represented in Figure 20.Such a transformation, however, would result in the loss of a representation f thelexical rule predicates that is independent of a particular word class, but an indepen-dent representation of lexical rules constitutes an advantage in space in case lexicalrules can be applied across word classes.
Our compiler therefore performs what canbe viewed as "partial" unfolding: it unfolds the frame predicates directly with respectto the interaction predicates, as shown in Figure 21.One can also view this transformation assuccessive unfolding of the frame predi-cates and the lexical rule predicates with respect o the interaction predicates followedby a folding transformation that isolates the original lexical rule predicates.
The defi-nite clause encoding of the interaction predicates resulting from unfolding the framepredicates for the lexical entry of Figure 15 with respect o the interaction predicate ofFigure 18 is given in Figure 22.
The lexical rule predicates called by these interactionpredicates are defined as in Figures 8 and 12, except hat the frame predicates are nolonger called.30 Note that it is only possible to eliminate the frame predicates, since they are never calledindependently of the covariation encoding.559Computational Linguistics Volume 23, Number 4\[B iCq_l(\[~\] W , \ [~)t21\] \[\] IN~) q_l/  t2 Z\[\] IN~)q_2(\[/;;\] C yXt2 Z:- lex _rule _1 (17~-I,\[-X~\]),:- lex_rule_2(E\],\[~,:- lex _rule22(\[~\[~\]),:- l ex_ ru le~3( \ [~,q_2(\[-~7~ W ,\[~).t2t2 z \[\]B \[\]q_7t2 z \[\]B \[\]q_14(\[X~\] C \[W '\[~\])"L t2 LXq_14(FX~l c w I~ .xt2q-,9  ct2 ZB \[\]q_14(\[F~\] C \[W ~\]  ,\[b-~):-lex_rule_3(\[~\],\[~\]),L t2t"L t2LZ \[\]q_l(E\],\[~\]), q_2( \ [~) ,  q~3(\[~,~\]), q_7(\[~\[~\]), q_14( \ [~) ,  q_19(\[~\]).Figure 22Unfolding the frame predicates for the example ntry with respect to the interaction predicate.5.
On-the-f ly Appl icat ion of Lexical RulesWe want our compiler to produce an encoding of lexical rules that allows us to executelexical rules on-the-fly, i.e., at some time after lexical lookup.
This is advantageousbecause postponing the execution of the interaction predicates allows more constraintson the word to be collected.
When the interaction predicate is finally called, as a resultof syntactic information being present, many of its possible solutions imply fail.
Thesearch tree that would have resulted from pursuing these possibilities at the beginningof processing does not have to be explored.
31As it stands, our encoding of lexical rules and their application as covariation inlexical entries does not yet support the application of lexical rules on-the-fly.
Withrespect o processing, the extended lexical entry of Figure 17 is problematic becausebefore execution of the call to q_l, it is not known which information of the base lexicalentry ends up in a derived lexical entry, i.e., tag ~ is completely uninstantiated.
Thismeans that there is no way of indexing the lexical entries according to what kind of31 According to Pollard and Sag (1987) on-the-fly application of lexical rules is also well-suited to playinga role in a model of language use.560Meurers and Minnen Covariation Approach to HPSG Lexical Rulesderived entry one is looking for.
As a result, it is necessary to execute the call to q_limmediately when the lexical entry is used during processing.
Otherwise, there wouldbe no information available to restrict the search-space of a generation or parsingprocess.Flickinger, Pollard, and Wasow (1985) solve this problem using additional specifi-cations: "By providing with each lexical rule a generic class frame which specifies thegeneral form and predictable properties of the rule's output, we avoid unnecessarywork when the lexical rule applies" (p. 264).
In the following, we show that the addi-tional specifications on the extended lexical entry needed to guide processing can bededuced automatically.5.1 Constraint PropagationThe intuitive idea behind this improvement of the covariation encoding is to lift intothe extended lexical entry the information that is ensured after all sequences of possiblelexical rule applications for a particular base lexical entry have occurred.
Note that thisis not an unfolding step.
Unfolding the interaction predicates with respect o the lexicalentries basically expands out the lexicon off-line.
Instead, what we do is factor out theinformation common to all definitions of the called interaction predicate by computingthe most specific generalization of these definitions.The most specific generalization does not necessarily provide additional constrain-ing information.
However, usually it is the case that lexical entries resulting from lexicalrule application differ in very few specifications compared to the number of specifica-tions in a base lexical entry.
Most of the specifications of a lexical entry are assumed tobe passed unchanged via the automatically generated frame specification.
Therefore,after lifting the common information into the extended lexical entry, the out-argumentin many cases contains enough information to permit a postponed execution of theinteraction predicate.
When C is the common information, and D1, ..., Dk are thedefinitions of the interaction predicate called, we use distributivity to factor out C in(C A D1) V -.. V (C A Dk): We compute C A (D1 V ... V Dk), where the r) are assumedto contain no further common factors.
Once we have computed c, we use it to makethe extended lexical entry more specific.
This technique closely resembles the off-lineconstraint propagation technique described by Marriott, Naish, and Lassez (1988).
Thereader is referred to Meurers and Minnen (1996) for a more detailed iscussion of ouruse of constraint propagation.
32We illustrate the result of constraint propagation with our example grammar.
Sincethe running example of this paper was kept small, for expository reasons, by onlyincluding features that do get changed by one of the lexical rules (which violatesthe empirical observation mentioned above), the full set of lexical rules would notprovide a good example.
Let us therefore assume that only the lexical rules 1 and 2of Figure 11 are given.
We then only obtain seven of the clauses of Figure 22: thosecalling lex_rule_l or lex_rule_2, as well as the unit clauses for q_l, q_2, q3, and q_7.Applying constraint propagation to the extended lexical entry of Figure 17 yields theresult shown in Figure 23.
The information common to all solutions to the interactioncall is lifted up into the lexical entry and becomes available upon lexical lookup.32 In certain cases an extension ofthe constraint language with named isjunctions orcontextedconstraints (Maxwell and Kaplan 1989; Eisele and D6rre 1990; Griffith 1996) can be used to circumventconstraint propagation.
Encoding the disjunctive possibilities for lexical rule application i this way,instead of with definite clause attachments, makes all relevant lexical information available at lexicallookup.
For analyses proposing infinite lexica, though, adefinite clause ncoding of disjunctivepossibilities i  still necessary and constraint propagation is indispensable forefficient processing.561Computational Linguistics Volume 23, Number 4- 1\] Lct2\[zB\]j c x_t2Lz \[\](a'b)JJFigure 23An entry suitable for on-the-fly application (lexical rules 1 and 2 only).5.2 Dynamic and Static CoroutiningEven though we see on-the-fly application as a prerequisite of a computational treat-ment of lexical rules, it is important o note that a postponed evaluation of lexicalrule application is not always profitable.
For example, in the case of generation, un-derspecification f the head of a construction can lead to massive nondeterminism oreven nontermination when not enough restricting information is available to generateits complements (Martinovi4 and Strzalkowski 1992; Minnen, Gerdemann, and G6tz1995).
Criteria to determine when it is most profitable to execute calls to an interactionpredicate are required.One possibility is to annotate the lexical rule encoding with such criteria by meansof delay statements, as, for example, suggested by van Noord and Bouma (1994).
Whilewe consider this kind of control facility (Naish \[1986\] and references therein) to be, ingeneral, indispensable for efficient processing, it also has disadvantages that make itdesirable to search for alternative or additional mechanisms: Delay statements presup-pose the procedural annotation of an otherwise declarative specification.
Substantialcomputational expertise is required to provide restrictions on the instantiation statusof a goal, which must be fulfilled before the goal can be executed.
Furthermore, thecomputational bookkeeping necessary for the delaying mechanism is very expensive.An interesting alternative, therefore, is to automatically determine certain control prob-lems and deal with them in an off-line fashion along the lines of Minnen, Gerdemann,and G6tz (1995) and Minnen, Gerdemann, and Hinrichs (1996).
They describe theuse of a dataflow analysis for an off-line improvement of grammars that determinesautomatically when a particular goal in a clause can best be executed.6.
Efficiency EvaluationThe computational treatment of lexical rules as covariation in lexical entries was im-plemented in Prolog by the authors in cooperation with Dieter Martini for the ConTrollsystem (Gerdemann and King 1994; G6tz and Meurers 1997a).
We tested the covaria-tion approach with a complex grammar implementing an HPSG analysis covering theso-called aux-flip phenomenon, and partial-VP topicalization i  the three clause typesof German (Hinrichs, Meurers, and Nakazawa 1994).
This test grammar includes eightlexical rules; some serve syntactic purposes, like the Partial-VP Topicalization LexicalRule, others are of morphological nature as, for example, an inflectional lexical rulethat relates nonfinite verbs to their finite form.
Our compiler distinguished seven wordclasses.
Some nouns and most verbal exical entries fed lexical rules, and a single baselexical entry resulted in up to 12 derivations.6.1 Time EfficiencyTo evaluate the time efficiency of the covariation encoding, we compared the parsetimes for our test grammar with three different computational encodings of the lexicon:562Meurers and Minnen Covariation Approach to HPSG Lexical Rulesthe expanded out lexicon, the basic covariation encoding, and the covariation encodingimproved by constraint propagation.
33As discussed in Section 5.1, the parsing times with a covariation lexicon withoutconstraint propagation suffer significantly from the lack of information directly avail-able upon lexical ookup.
For the test grammar, the resulting extended search-space ofparsing with the basic covariation encoding leads to a performance that is, on average,18 times slower than that with the expanded out lexicon.The use of constraint propagation, however, makes it possible to exploit he covari-ation encoding of lexical rule application such that it results in an increase in speed.Parsing with the test grammar using the constraint propagated covariation lexicon is,on average, 25 percent faster than the performance with the expanded out lexicon.The representation f lexical information in a constraint propagated covariation lex-icon makes the maximum information available at lexical lookup while requiring aminimum number of nondeterministic choices to obtain this information.Summing up, the relation between parsing times with the expanded out (EXP),the covariation (COV), and the constraint propagated covariation (IMP) lexicon forthe test grammar can be represented asIMP : EXP : COV = 0.75 : 1 : 18.
With respectto our test grammar, the constraint propagated covariation lexicon thus is the fastestlexical encoding.6.2 Space EfficiencyBesides the effect of requiring a minimum of nondeterministic choices and therebyreducing the number of resolution steps to increase time efficiency, the covariationencoding of lexical rules can result in an additional speedup since it reduces the spacerequirements of large grammars.A comparison of space efficiency between an expanded out and a covariation lex-icon needs to compare two different encodings.
The expanded out lexicon consistssolely of lexical entries, whereas the covariation lexicon is made up of three differ-ent data structures: the extended base lexical entries, the interaction predicates, andthe lexical rule predicates.
We focus on a qualitative valuation of space efficiency,rather than on providing results for the test grammar, since the space efficiency ofthe covariation encoding relative to the expanded out lexicon is dependent on severalproperties of the grammar: the number of lexical entries in the lexicon that can un-dergo lexical rule application, the size of the lexical entries, and the number of lexicalentries belonging to a word class.Since only base lexical entries that feed lexical rules are modified by the lexicalrule compiler, the covariation encoding naturally only results in space savings forthose lexical entries to which lexical rules apply.The space efficiency is dependent on the size of the lexical entries since in thecovariation encoding much of the lexical information that is specified in a base lexicalentry is not duplicated in the lexical entries that can be derived from it, as is the casefor an expanded lexicon.
Thus, the more information represented in a base lexicalentry, the greater the space saving achieved by the covariation encoding.
In lexicallyoriented grammar formalisms like HPSG, the lexical entries are highly informationrich.
A covariation treatment of HPSG lexica therefore can be particularly profitable.The number of lexical entries belonging to a word class is relevant since the inter-action predicates are identical for all lexical entries belonging to the same word class.33 The lexicon of the test grammar can be expanded out off-line since the recursive ComplementExtraction Lexical Rule applies only to full verbs, i.e, lexical entries with a complement list of finitelength.
As a result, the grammar does not have an infinite lexicon.563Computational Linguistics Volume 23, Number 4This means that the more lexical entries in a word class, the greater the saving inspace.
The covariation approach therefore is particularly attractive for grammars witha large lexicon.7.
Related WorkThe powerful mechanism of lexical rules (Carpenter 1991) has been used in manynatural language processing systems.
In this section we briefly discuss some of themore prominent approaches and compare them with the treatment proposed in thispaper.7.1 Off-line Expansion of Lexical RulesA common computational treatment of lexical rules adopted, for example, in the ALEsystem (Carpenter and Penn 1994) consists of computing the transitive closure of thebase lexical entries under lexical rule application at compile-time.
While this providesa front-end to include lexical rules in the grammars, it has the disadvantage that thegeneralizations captured by lexical rules are not used for computation.
We mentionedin Section 2.2 that eliminating lexical rules in a precompilation step makes it impossibleto process lexical rules or lexical entries that impose constraints that can only beproperly executed once information from syntactic processing is available.
A relatedproblem is that for analyses resulting in infinite lexica, the number of lexical ruleapplications needs to be limited.
In the ALE system, for example, a depth bound canbe specified for this purpose.
Finally, as shown in Section 6, using an expanded outlexicon can be less time and space efficient han using a lexicon encoding that makescomputational use of generalizations over lexical information, as, for example, thecovariation encoding.7.2 Lexical Rules as Unary Phrase Structure RulesAnother common approach to lexical rules is to encode them as unary phrase structurerules.
This approach is taken, for example, in LKB (Copestake 1992) where lexical rulesare introduced on a par with phrase structure rules and the parser makes no distinctionbetween lexical and nonlexical rules (Copestake 1993, 31).
A similar method is includedin PATR-II (Shieber et al 1983) and can be used to encode lexical rules as binaryrelations in the CUF system (Dbrre and Eisele 1991; D6rre and Dorna 1993b) or theTFS system (Emele and Zajac 1990; Emele 1994).
The covariation approach describedin this paper can be viewed as a domain-specific refinement of such a treatment oflexical rules.The encoding of lexical rules used in the covariation approach is related to thework of van Noord and Bouma (1994), who describe the hand-encoding of a singlelexical rule as definite relations and show how these relations can be used to constraina lexical entry.
The covariation approach builds on this proposal and extends it inthree ways: First, the approach shows how to detect and encode the interaction of aset of lexical rules.
Second, it provides a way to automatically obtain a definite clauseencoding of lexical rules and their interaction.
Finally, it automatically derives theframe specification for lexical rules such that, following standard HPSG practice, onlythe information changed in a lexical rule needs to be specified.7.3 Alternative Ways to Express Lexical GeneralizationsLexical rules have not gone unchallenged as a mechanism for expressing eneraliza-tions over lexical information.
In a number of proposals, lexical generalizations arecaptured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992;564Meurers and Minnen Covariation Approach to HPSG Lexical RulesRiehemann 1993; Oliva 1994; Frank 1994; Opalka 1995; Sanfilippo 1995).
The lexicalentries are only partially specified, and various specializations are encoded via thetype hierarchy, definite clause attachments, or a macro hierarchy.These approaches seem to propose a completely different way to capture lexicalgeneralizations.
It is therefore interesting that the covariation lexical rule compilerproduces a lexicon encoding that, basically, uses an underspecification representation:The resulting definite clause representation after constraint propagation represents thecommon information in the base lexical entry, and uses a definite clause attachmentto encode the different specializations.8.
SummaryWe presented a new computational treatment of HPSG lexical rules by describing acompiler that translates a set of lexical rules as specifed by a linguist into definiterelations, which are used to constrain lexical entries.
The frame of a lexical rule andlexical rule interaction is automatically determined and the interaction is representedas a finite-state automaton.
The automaton allows us to encode lexical rule interactionwithout actually having to apply lexical rules a possibly infinite number of times.Word classes relevant o lexical rule application are automatically detected and thecorresponding finite-state automata re refined in order to avoid lexical rule applica-tions that are guaranteed to fail.
The refined automata re encoded as definite relationsand each base lexical entry is extended to call the relation corresponding to its class.Finally, the encoding of lexical rules and their interaction is advanced using constraintpropagation to allow coroutining of its execution with other grammar constraints.
Thisreduces the number of nondeterministic choices related to lexical lookup, and, moreimportantly, allows syntactic information to be used to ensure termination of the co-variation encoding of lexical rules.
Finally, we discussed implementation results andillustrated the improvement in time and space efficiency resulting from the covariationencoding.AcknowledgmentsThe research reported here was supportedby Teilprojekt B4 "From Constraints oRules: Efficient Compilation of HPSGGrammars" of SFB 340 "SprachtheoretischeGrundlagen f~ir die Computerlinguistik" ofthe Deutsche Forschungsgemeinschaft.
Theauthors wish to thank Thilo G6tz and DaleGerdemann, Erhard Hinrichs, Paul King,Suresh Manandhar, Dieter Martini, BillRounds, and the anonymous reviewers.
Ofcourse, the authors are responsible for allremaining errors.ReferencesBriscoe, Ted and Ann Copestake.
1996.Controlling the application of lexicalrules.
In Proceedings ofthe SIGLEXWorkshop on Breadth and Depth of SemanticLexicons, Santa Cruz, CA.Briscoe, Ted, Ann Copestake, and Valeriade Paiva, editors.
1992.
Default InheritanceWithin UniX'cation-Based Approaches totheLexicon.
Cambridge University Press,Cambridge, UK.Calcagno, Mike.
1995.
Interpreting lexicalrules.
In Proceedings ofthe Conference onFormal Grammar, Barcelona.
Also in:Proceedings of the ACQUILEX IIWorkshop on Lexical Rules, 1995,Cambridge, UK.Calcagno, Mike, Detmar Meurers, and CarlPollard.
In preparation.
On the nature oflexical rules in head-driven phrasestructure grammar.
Unpublishedmanuscript, Ohio State University andUniversity of T~ibingen.Calcagno, Mike and Carl Pollard.
1995.Lexical rules in HPSG: What are they?Unpublished manuscript, Ohio StateUniversity, Columbus, OH.Carpenter, Bob.
1991.
The generative powerof categorial grammars and Head-DrivenPhrase Structure Grammars with lexicalrules.
Computational Linguistics,17(3):301-314.Carpenter, Bob and Gerald Penn.
1994.ALE--The Attribute Logic Engine, User's565Computational Linguistics Volume 23, Number 4Guide, Version 2.0.1, December 1994.Technical report, ComputationalLinguistics Program, PhilosophyDepartment, Carnegie Mellon University,Pittsburgh, PA.Copestake, Ann.
1992.
The Representation fLexical Semantic Information.
Cognitivescience research paper CSRP 280,University of Sussex, Sussex, UK.Copestake, Ann.
1993.
The Compleat LKB.Technical report 316, University ofCambridge Computer Laboratory,Cambridge, UK.D6rre, Jochen and Michael Dorna, editors.1993a.
Computational Aspects ofConstraint-Based Linguistic Description I.University of Stuttgart, Stuttgart,Germany.DOrre, Jochen and Michael Dorna.
1993b.CUF--A formalism for linguisticknowledge representation.
I  D6rre andDorna (1993a).DOrre, Jochen and Andreas Eisele.
1991.
AComprehensive Unification BasedFormalism.
DYANA Deliverable R3.1.B,University of Stuttgart, Stuttgart,Germany.Eisele, Andreas and Jochen D6rre.
1990.Disjunctive Unification.
Technical Report124, IBM Wissenschaftliches Zentrum,Institut fiir Wissensbasierte Systeme.Emele, Martin.
1994.
The typed featurestructure representation formalism.
InProceedings ofthe International Workshop onSharable Natural Language Resources, Nara,Japan.Emele, Martin and R~mi Zajac.
1990.
Typedunification grammars.
In Proceedings ofthe13th Conference on Computational Linguistics(COLING), Helsinki, Finland.Flickinger, Daniel.
1987.
Lexical Rules in theHierarchical Lexicon.
Ph.D. thesis, StanfordUniversity, Stanford, CA.Flickinger, Daniel, Carl Pollard, and ThomasWasow.
1985.
Structure-sharing i  lexicalrepresentation.
I  Proceedings ofthe 23rdAnnual Meeting, pages 262-267, Chicago,IL.
Association for ComputationalLinguistics.Frank, Annette.
1994.
Verb second byunderspecification.
In Proceedings ofKONVENS, Berlin.
Springer-Verlag.Gerdemann, Dale.
1995.
Open and closedworld types in NLP systems.
InProceedings ofthe DGfS FachtagungComputerlinguistik, Diisseldorf, Germany.Gerdemann, Dale and Paul King.
1994.
Thecorrect and efficient implementation fappropriateness specifications for typedfeature structures.
In Proceedings ofthe 15thConference on Computational Linguistics(COLING), Kyoto, Japan.Ginsberg, Matthew L., editor.
1987.
Readingsin Nonmonotonic Reasoning.
MorganKaufmann.G6tz, Thilo.
1994.
A Normal Form forTyped Feature Structures.
Arbeitspapieredes SFB 340 no.
40, University ofT~ibingen, IBM, Heidelberg, Germany.G6tz, Thilo and Detmar Meurers.
1995.Compiling HPSG type constraints intodefinite clause programs.
In Proceedings ofthe 33rd Annual Meeting, Boston, MA.Association for ComputationalLinguistics.G6tz, Thilo and Detmar Meurers.
1996.
Theimportance of being lazy--Using lazyevaluation to process queries to HPSGgrammars.
In Proceedings ofTALN 96 (JointSession with the Third InternationalConference on HPSG), Marseille, France.GOtz, Thilo and Detmar Meurers.
1997a.The ConTroll system as large grammardevelopment platform.
In Proceedings ofthe ACL/EACL Post-Conference Workshop onComputational Environments for GrammarDevelopment and Linguistic Engineering,Madrid, Spain.G6tz, Thilo and Detmar Meurers.
1997b.Interleaving universal principles andrelational constraints over typed featurelogic.
In Proceedings ofthe 35th AnnualMeeting of the ACL and the 8th Conference ofthe EACL, Madrid, Spain.Griffith, John.
1996.
Modularizing contextedconstraints.
In Proceedings ofthe 16thConference on Computational Linguistics(COLING), Copenhagen, Denmark.Hinrichs, Erhard, Detmar Meurers, andTsuneko Nakazawa, editors.
1994.Partial-VP and Split-NP Topicalization iGerman--An HPSG Analysis and itsImplementation.
Number 58.Hinrichs, Erhard and Tsuneko Nakazawa.1989.
Flipped out: Aux in German.
InPapers from the 25th Regional Meeting, pages193-202, Chicago.
Chicago LinguisticSociety.Hinrichs, Erhard and Tsuneko Nakazawa.1994.
Partial-VP and split-NPtopicalization i German: An HPSGanalysis.
In Hinrichs, Meurers, andNakazawa (1994).Hinrichs, Erhard and Tsuneko Nakazawa.1996.
Applying lexical rules undersubsumption.
In Proceedings ofthe 16thConference on Computational Linguistics(COLING), pages 543-549, Copenhagen,Denmark.Kathol, Andreas.
1994.
Passive withoutlexical rules.
In John Nerbonne, KlausNetter, and Carl Pollard, editors, HPSGfor566Meurers and Minnen Covariation Approach to HPSG Lexical RulesGerman.
CSLI Lecture Notes, StanfordUniversity, Stanford, CA.King, Paul.
1989.
A Logical Formalism forHead-driven Phrase Structure Grammar.Ph.D.
thesis, University of Manchester,Manchester, UK.King, Paul.
1994.
An Expanded LogicalFormalism for Head-driven PhraseStructure Grammar.
Arbeitspapiere desSonderforschungsbereich 340 no.
59,University of Tfibingen, Tfibingen,Germany.Krieger, Hans-Ulrich and John Nerbonne.1992.
Feature-based inheritance networksfor computational lexicons.
In Briscoe,Copestake, and de Paiva (1992).Manandhar, Suresh.
1995.
The UpdateOperation in Feature Logic.
UnpublishedManuscript, HCRC at University ofEdinburgh, UK.Marriott, Kim, Lee Naish, and Jean-LouisLassez.
1988.
Most specific logicprograms.
In Proceedings of5th InternationalConference and Symposium on LogicProgramming.MartinoviG Miroslav and TomekStrzalkowski.
1992.
Comparing twogrammar-based generation algorithms: Acase study.
In Proceedings ofthe 30thAnnual Meeting, Newark, DE.
Associationfor Computational Linguistics.Maxwell, John and Ronald Kaplan.
1989.
Anoverview of disjunctive constraintsatisfaction.
In Proceedings oftheInternational Workshop on ParsingTechnologies, pages 18-27.McCarthy, John and Patrick Hayes.
1969.Some philosophical problems from thestandpoint of artificial intelligence.
InMeltzer and Michie (1969).
Reprinted inGinsberg (1987).Meltzer, Bernard and Donald Michie,editors.
1969.
Machine Intelligence 4.Edinburgh University Press, Edinburgh,UK.Meurers, Detmar.
1994.
On implementingan HPSG theory: Aspects of the logicalarchitecture, the formalization and theimplementation f Head-driven PhraseStructure Grammars.
In Hinrichs,Meurers, and Nakazawa (1994).Meurers, Detmar.
1995.
Towards a semanticsfor lexical rules as used in HPSG.
InProceedings ofthe Conference on FormalGrammar, Barcelona.
Also in Proceedings ofthe ACQUILEX II Workshop on Lexical Rules,1995, Cambridge, UK.Meurers, Detmar and Guido Minnen.
1995.A computational treatment of HPSGlexical rules as covariation in lexicalentries.
In Proceedings ofthe FifthInternational Workshop on Natural LanguageUnderstanding and Logic Programming,Lisbon, Portugal.Meurers, Detmar and Guido Minnen.
1996.Off-line constraint propagation forefficient HPSG processing.
In Proceedingsof TALN 96 (Joint Session with the ThirdInternational Conference on HPSG),Marseille, France.Miller, Philip and Ivan Sag.
1993.
FrenchClitic Climbing Without Clitics orClimbing.
Unpublished Manuscript,University of Lille and StanfordUniversity.Minnen, Guido.
In preparation.
NaturalLanguage Processing with Constraint-LogicGrammars: Grammar Compilation forDeclarative Under-determination.
Ph D.thesis.Minnen, Guido, Dale Gerdemann, and ThiloGOtz.
1995.
Off-line optimization forearley-style HPSG processing.
InProceedings ofthe 7th Conference ofthe EACL,Dublin, Ireland.Minnen, Guido, Dale Gerdemann, andErhard Hinrichs.
1996.
Direct automatedinversion of logic grammars.
NewGeneration Computing 14(2):131-168.Naish, Lee.
1986.
Negation and Control inProlog.
Springer Verlag, New York.O'Keefe, Richard.
1990.
The Craft of Prolog.MIT Press, Cambridge, MA.Oliva, Karel.
1994.
HPSG lexicon withoutlexical rules.
In Proceedings ofthe 15thConference on Computational Linguistics(COLING), Kyoto, Japan.Opalka, Annette.
1995.
StatischeProgrammtransformationen zureffizienten Verarbeitungconstraintbasierter Grammatiken.Diplomarbeit, University of Stuttgart,Stuttgart, Germany.Pereira, Fernando and Stuart Shieber.
1987.Prolog and Natural Language Analysis.
CSLILecture Notes.
Center for the Study ofLanguage and Information, StanfordUniversity, Stanford, CA.Pettorossi, Alberto and Maurizio Proietti.1994.
Transformations of logic programs:Foundations and techniques.
Journal ofLogic Programming 19/20:261-320.Pollard, Carl and Ivan Sag.
1987.Information-based Syntax and Semantics, Vol.1.
Number 13 of CSLI Lecture Notes.Center for the Study of Language andInformation, Stanford University,Stanford, CA.Pollard, Carl and Ivan Sag.
1994.Head-Driven Phrase Structure Grammar.University of Chicago Press, Chicago, IL.567Computational Linguistics Volume 23, Number 4Riehemann, Susanne.
1993.
Word Formationin Lexical Type Hierarchies: A Case Studyof bar-Adjectives in German.
Master'sthesis, University of Ti~bingen, Tiibingen,Germany.
Also published asSfS-Report-02-93, Seminar fiirSprachwissenschaft, University ofTi~bingen.Sanfilippo, Antonio.
1995.
Lexicalpolymorphism and word disambiguation.In Proceedings ofthe American Associa tion.forArti~cial Intelligence (AAAI), StanfordUniversity, Stanford, CA.Shieber, Stuart, Hans Uszkoreit, FernandoPereira, Jane Robinson, and Mabry Tyson.1983.
The formalism and implementationof PATR II.
In Research on InteractiveAcquisition and Use of Knowledge.
SRIInternational, Menlo Park, CA, pages39-79.Tamaki, Hisao and Taisuke Sato.
1984.Unfold/Fold transformation f logicprograms.
In Proceedings ofthe 2ndInternational Conference on LogicProgramming, Uppsala, Sweden.Torisawa, Kentaro and Jun'ichi Tsuji.
1996.Off-line raising, dependency analysis andpartial unification.
In Proceedings ofTALN96 (Joint Session with the Third InternationalConference on HPSG), Marseille, France.van Noord, Gertjan and Gosse Bouma.
1994.The scope of adjuncts and the processingof lexical rules.
In Proceedings ofthe 15thConference on Computational Linguistics(COLING), Kyoto, Japan.Some of the above papers can be obtainedelectronically through the URL provided onthe first page.568
