Acquisition of Computational-Semantic Lexiconsfrom Machine Readable Lexicai ResourcesJason J. S. Chang and J. N. ChenDepartment of Computer ScienceNational Tsing Hua UniversityHsinchu 30043, Talwan, ROCTel: +886 35 731-069 Fax: 723-694(jschang,dr818314 }@cs.nthu.edu.twAbstractThis paper describes a heuristic algorithm capable of automatically assigning a label toeach of the senses in a machine readable dictionary (MRD) for the purpose of acquiring a com-putational-semantic lexicon for treatment of lexical ambiguity.
Including these labels in theMRD-based lexical database offers several positive ffects.
The labels can be used as a coarsersense division so unnecessarily fine sense distinction can be avoided in word sense disambigu-ation (WSD).The algorithm is based primarily on simple word matching between an MRD defi-nition sentence and word lists of an LLOCE topic.
We also describe an implementation f thealgorithm for labeling definition sentences in Longman Dictionary of Contemporary English(LDOCE).
For this purpose the topics and sets of related words in Longman Lexicon of Con-temporary English (LLOCE) are used in this work.
Quantitative r sults for a 12-word test setare reported.
Our discussion entails how the availability of these labels provides the means fortreating such problems as: acquisition of a lexicon capable of providing broad coverage, sys-tematic word sense shifts, lexical underspecification, and acquisition of zero-derivatives.1.
IntroductionTreatment of lexical ambiguity such as WSD has been found useful in many NLP applications, includ-ing information retrieval (McRoy 1992; Krovetz and Croft 1992) and machine translation (Brown et al1991; Dagan et al 1991; Dagan and Itai 1994).
Recently, various approaches (Dolan 1994; Luk 1995;Yarowsky 1992; Dagan et al 1991 ;Dagan and Itai 1994) to word sense division have been used in WSDresearch.
Directly using dictionary senses as the sense division has several advantages.
First, sense distinc-tion according to a dictionary is readily available from MRDs such as the LDOCE (Longman 1992).
Sec-ond, indicative words and concepts for each sense are directly available in numbered efinitions andexamples.
Lesk (1986) demonstated that dictionary entries can be used to generate signatures of senses forWSD.
However, using MRD as the knowledge source for sense division and disambiguation e counterscertain problems.
Dolan (1994) observed that sense division in MRD is frequently too free for the purposeof WSD.
A WSD system based on dictionary senses faces an unnecessary and difficult "forced-choices.
"Most researchers resorted to human intervention to identify and group closely related senses.This paper describes a heuristic algorithm capable of automatically assigning a label to each of thesenses in a machine readable dictionary (MRD) for the purpose of acquiring acomputational-semantic lex-icon for treatment of lexical ambiguity.
Including these labels in the MRD-based lexical database offersseveral positive ffects.
The labels can be used as a coarser sense division so unnecessarily fine sense dis-tinction can be avoided in word sense disambiguation (WSD).
The algorithm is based primarily on simpleword matching between an MRD definition sentence and word lists of an LLOCE (McArthur 1992) topic.We begin by giving the details of material used, including the characteristics of definition sentences inLDOCE and the organization ofwords in LLOCE.
Next, the algorithm for labeling LDOCE senses is de-scribed.
An illustrative xample demonsu~ates theeffectiveness of the algorithm.
After describing the al-30gorithm, the experimental results for a 12-word test set are presented.
Our discussion also entails thepossible implication of the labels to such problems as: acquisition of a lexicon capable of providing broadcoverage, systematic word sense shifts, lexical underspecification, a d acquisition of zero-derivatives at thesense level.
Moreover, the proposed algorithm is compared with other approaches in available literature.Finally, concluding remarks are made.2.
Identifying the topic of sensesThe labeling of dictionary definition sentences with a coarse sense distinction such as the set labels inLLOCE is a special form of the WSD problem.
No simple method can solve the general problem of WSDfor unrestricted text.
We will show that his labeling task is made simplex for several reasons.
For example,consider the definition sentences for the first 5 senses of "bank" in LDOCE:1. land along the side of a river, lake, etc.2 .
earth which is heaped up in a l~eld or garden, often making a border or division.3.a mass of snow, clouds, mud.
etc.4.a slope made at Oends in a road or race-track, so that they are safer for cars to go round.5.= SANDBANK (a high underwater bank of sand in a river, harbour, etc.
).First of aLl, only simple words are used in the definitions.
Furthermore, the text generationschemes are rather egular.
The scheme that lexicographers u ed in generating the definitions above is sim-ilar to the DEFINITION scheme described in McKeown (1985).
A DEFINITION scheme begins with agenus term (that is, conceptual parent or ancestor of the sense), followed by the so-called ifferentia thatconsists of words: semanficaUy related to the sense to provide specifics about he sense.
Those relations be-tween the sense and its defining words are reflected in semantic dusters that are termed categorical, func-tional, and situational clusters in McRoy (1992).
Moreover, those relations have been shown to be veryeffective knowledge sources for WSD (McRoy 1992) and interpretation f noun sequences (Vanderwende1994).
For instance, land, earth, mass, slope, and sand are the genus terms that are categorically relatedto bank.
On the other hand, words in the differentia such as river, lake.field, garden, l~end, road.
race-track,and harbour are Situationally related to bank through the Location relation.
Other keywords uch as rOOd,and race-tra?\[~ are related functionally to bank through the PartOfrelation.
For the most part, those rela-tions exist conveniently among words under the same topic or across cross-referendng topics in LLOCE.For instance, most of the above mentioned words are listed under the same topic Ld (Geography) of the in-tended label/Ld099, or its cross reference Me (Places).
Therefore, these definitions can be disambiguatedvery effectively on the base of similarity between the defining keywords and the words lists in LLOCE.2.1.
Organizing information in LLOCEIn this work, the labels used for tagging dictionary definitions are taken from the LLOCE (McArthur 1992).Words in LLOCE are organized mainly according to subject matter.
Nearly 2,500 sets of related words inLLOCE are organized according to 14 subjects and 129 topics (TOP).
Cross references (REF) between sets,topics, and subjects are also given to show various inter-sense r lations not captured within the same topic.The cross references in LLOCE are primarily between topics.The sets under which the word is listed in LLOCE are considered as the initial candidates for labeling.For instance, the Candidates for labeling senses of "bank" are the foUowing 4 set labels:Jel04 (banks, exchange, tc.
),Jel06 (banking and saving),Ld099 (fiver banks), andNj295 (bending and leaning)The set label Jel04 (as weU as Jel06) is listed under the topic Je (Banking, Wealth, and Investment), while31Ld099 and Nj295 are listed under Ld (Geography) and Nj (Action and Position) respectively.
For instance,there is a REF link (in Figure 1) from topic Je to topic De (Belonging and Owning, Getting and Giving).
Tofacilitate estimation of similarity between adefinition sentence and a topic, we use TOPS to denote the listof words under a LLOCE topic S, while REFS denotes the list of words under cross references of S. Forinstance, the label Jel04 (as well as Jel06) is associated with a list of words from its topic (TOPJel04) andcross reference (REFJe l 04 = TOPDe):TOPJe l04 = TOPJe = {affluent, budget, cut down, deficit, economize, fortune, giro,income, keep, luxury, maintenance, needy, pay, windfall, amenity .... }REFJeI04 = TOPDe = {bring back, contribution, doff, equip, facility, keep, yield, ... }.O SubjectPeople Material \Q TopicCS> SetsO/rganizationk\\k\?oo~Owning ~a~ateda l- , - - - _  .
.
.
.
27z  =~ /i r /  /e-  /_ - -?
-i~  / /_A  / ~ ?-p~.
.
.
.
.
II \~X 'h~ - ,cross-reference... b aak...Figure 1.
Subjects, topics, sets, and cross reference between topics in LLOCE.323.
The algorithmThe algorithm is divided into two stages.
The preprocessing steps such as part-of-speech tagging, and re-moval of stop words are necessary for the algorithm to obtain good results.
Various methods for POS tag-ging have been proposed in recent years.
For simplicity, we adapted the method proposed by Churchl(1988)to tag the definition sentence.
In the second stage, we select he label which is associated with word listsmost similar to the definition as the result.
We sum up the above descriptions and outline the procedure forlabeling a dictionary sense.Algorithm: I Sense division for a head word hStep 1: GiVen a head word h, read its definition, DEFh, from LDOCE.Step 2: For each definition D ofDEFh, tag each word in D with POS information..Step 3: Remove all stop words in D to obtain a list of keyword-POS pair, KEYD.iStep 4: Lookup LLOCE for headword h to obtain a list of sets SETh that contains h. For each S inSETh, compile a set of words TOPS that listed under the topic of S and REFS the set of wordslisted under it cross references.Step 5: Compute similarity Sim(D, S) based on Dice Coefficient for all clef'tuitions D ~ DEFh and labelsS ,SETh.S im (D, S) =whereKEYD= the set of POS-keyword pairs in definition D,~= the overall relevancy of cross references toa topic,wk= 1/the degree of ambiguity of the keyword k,In(a, B)= 1 when a ?
B,In(a, B)= 0 when a ~ B.Step 6: Assign to D the label S with the maximum value of Sire(D, S) over a threshold.Initially, the candidates are limited to the set labels indicated in LLOCE for the head word.
If thealgorithm finds all initial candidates dissimilar, a second run of the algorithm is executed with candidatesexpanded to all topics in LLOCE.3.1 An illustrative xampleWe illustrate how the algorithm functions using the 5th definition of the word "interest."
The preprocess-ing stage for definition of word "interest" includes part-of-speech (POS) tagging and stop word removal,thereby ielding the following result:h = "interest"SETinterest = {Fj228, Fb028, Jell2, KaO06 }D = "a share in a company business etc.
"POSD = { a/det, share/n, in/prep, a/det, company/n, business/n, etc./adv }KEYD = {share/n, company/n, business/n}/KEYDI = 3wshare/nwcompany/nwbusiness/n= 1/l{Del05, Hb037, Je114}1 = 1/3= 1/1{Cc042, Co292, Jh225}1 = 1/3= 1/1{Gh243, Jd138, Jh225}1 = 1/31.
In our case.
tagging errors have very little negative impact, because words in I.J.,OCE are organized primarily ac-cordln~ to topic not part-of-speech.33TOPFj228 = WFj =TOPFb028 = WFb =TOPJe l l2  = WJe =TOPKaO06 = WKa ={quite/adj, calm/adj .... interest/n, excitement/n, shrill/n .... }{likeN, fancy/v .... attraction/n, appeal/n, interest/n .... }{lend/v, loan/v .... interest/n, investment/n, share/n .... }{entertain/v, amuse/v .... game/n, hobby/n, interest/n .... }REFFj228 = WK = WKa ~,Wkb .... WKh= { entertain/v, amuse/v, ... game/n, hobby/n, interest/n, ..}REFFb028 = WCc = {friend/n, aquaintance/n .... companion/n, company/n .... }REF Je l l2  = WDe = {belong to/v, have/v .... share/n }REFKaO06 = WFj = {quite/adj, calm/adj .... interest/n, excitement/n, shrill/n .... }I TOPFj228 u REFFj2281= 1693I TOPFb028 ~ REFFb0281 = 253J TOP Je l l2  ~ REFJe1121 = 446I TOPKaO06 v REFKaO061 =224Sim(D, Fj228) 2Sire(D, Fb028)Sire(D, J e l l2 )Sire(D, KaO06)=0= 2x0.33x(lxl)/(253+3) = 0.66/256 = 0.00258= 2x0.33,,(l+lxl)/(446+3) = 0.66~2/449 = 0.00294=0The word lists associated with the label J e l l  2 is most similar to the key-words of the definition.Therefore, the algorithm produces Je112 as the label for "a share in a company business etc.
"3.2 Experiments and EvaluationAn experiment was carried out using a test set 3 containing 12 polysemous words used in recent WSD ex-periments (Yarowsky 1992; Luk 1995).
The 12-word test set used in the evaluation represents much moredifficult cases than average.
There are on the average 2.6 definitions in LDOCE for each words as opposedto the average 6.4 definitions per words in the test set.
Table 1 displays a word by word performance of thealgorithm.
The results show that on the average the algorithm can assign labels to 87% of the senses with94% precision.4.
DiscussionIn this section, we thoroughly analyze the labeling performed by the algorithm and, in particular, lookinto several uses that are made possible by the labels' availability.
In addition, those cases when the algo-rithm failed can also be analyzed.
Analyses result not only illustrate the merits of these labels, but also im-ply possible improvement of the algorithm.4.1.
Broad coverageAbout 50% of the labels are assigned uring the second run of the algorithm from the extended candidateset.
These labels represent gaps in the LLOCE.
So, the algorithm can produce much broader coverage thanthe original LLOCE.2.
For simplicity, the parameter  , is set to i.3.
Only entries relevant to ~e test set m LLOCE are manually emered to ~e computer.
We are currently trying to geta licence s.t.
the full LLOCE entries in order to ccmduct amore complete test.34Table 1.
Performance ofthe extended algorithmheadword Alternate sets in No.
of deft- Labeling with expanded candidate setLLOCE nifionsinLDOCE La-Incorrect Unknown \[ADolicabili- Precisionmolesentenceslugbassbowconedutygalleyn Ac061n Mf159nl~.~nLa!n Cm256n Gf235v Gk210nAgl l3n Hh242nGdnHbv blk335adj Kb041n Kb041hE&n.Fgtn 1-111234, n Kb046n Mf157n Nj295v Nj295vMbvK.hnlagn Na008n Ai134n Aj156n Jb044nRan Fc063n Jf160nJhn Db038n Mf157n Mf153nGd112Correctbelling11111110111121100Labelling00000000000000000010001000000000Labelling00000000001010000000000100000000Apl:ty100%100%80%86%91%100%100%100%100%100%100%100%80%100%100%100%35headwordinterestissuestartasteAlternate sets in No.
of deft- Labeling with expanded candidate setLLOCE nitionsin LDOCE La- Precisiona Fb028n Fj228n Ka006n Je112v Fb025v Fj224v Ka010n.~.
?n Aa020nGdl80n Gf243n Nf153v Gd174n.GavD?nlSan_N.~nl',~a Kd082n La002v Kd079nI:lRnL~n .N..~n Ia006n Nb035n .QA.L$1.nFI281v F1280v,nv,nn.Qb.n Fb0208101111Correctbelling1121211111100122111000IncorrectLabelling421000000000000200000000000UnknownLabelling000100000100100000011100 00 00 00 1I l I ; ' \ ]ApplicabiU-ty88%80%73%91%100%75%100%100%I /    -IllsNote: Extended labels are underscored.4.2.
Zero derivationDolan (1994) pointed out that it is helpful to identify zero-derived noun/verb pairs for such tasks asnormalization of the semantics of expressions that are only superficially different.
We have noticed that36zero derivatives are an important knowledge source for resolving PP-attachment ambiguity.
A PP with anobject involved in a noun/adjective z ro-derivation has a strong tendency to attach itself to the precedingnoun as a modifier.
For instance, consider the following example that has an ambiguous PP-attaclmaentproblem:We had a lot of interests in common.
(= We had a lot of common interests.)4.3.
Systematic inter-sense relationsSanfilippo et al (1995) contended that strong evidence would suggest that a large part of word sense ambi-guity is not arbitrary but follows regular patterns.
Moreover, gaps frequently arise in dictionaries and the-sauri n specifying this kind of virtual polysemy.
Virtual polysemy and recurring inter-sense r lations areclosely related to polymorphic senses that can support coercion in semantic typing under the theory of Gen-erative Lexicon of Putstejovsky (1991).Our experimental results indicate that he labels in LLOCE make it possible to acquire important inter-sense relations, i Many of those relations are reflected in the cross reference information i  LLOCE.
Forinstance, LLOCE lists the following cross references for the topic of Eb (Food):Ac: Animals\]MammalsAd: BirdsAf: Fish and other (water) creaturesAh: Parts of animalAi: Kinds of parts of plantsAj: Plant in generalJg: Shopkeepers and shops selling foodmost of which are systematic inter-sense r lations imilar to those described inabove-mentioned work.
Wealso observed that words involved in such inter-sense r lations are frequently underspecified.
For instance,"chicken" is listed under both topics Eb and topic Ad, while "duck" is listed under Ad but not Eb.
By char-acterizing of some 200 cross references in LLOCE, most systematic inter-sense r lations can be easily iden-tiffed among the labeled senses.
The labels attached to senses in the MRD, coupled with these inter-senserelations, can then support and realize automatic sense shifts advocated in Putstejovsky and Bouillon(1994).
For instance, the sense of "duck" label with topic Ad can be coerced into an Eb sense when neces-sary, with the availability of the lexical rule stipulating a sense shift from Ad and Eb.Krovetz (1992) observed that LDOCE indicates sense shifts via direct reference (links indicatedby a capitalized word with a sense number) and deictic reference (implicit links to the previous ense createdby this, these, that, those, its, itself, such a, such an).
Sense shifts indicated through adeictic reference arealso present in our 12-word test set.
For instance, the first 2 senses of "issue" are1.
the act of coming out.2.
an example of this.The definition of the 2nd senses indicates an A ctionNoun-CountNoun sense shifts from issue.n.1 to issue.n.2through adeictic reference of "this."
Since those types of definitions pattern are not considered, the label-ing algorithm fails in such cases.
Further work must be unde~xaken to cope with direct and deictic referenc-es, so that such def'mitions can be appropriately labeled and information on sense shifts can be acquired.4.4.
Metonymy or MetaphorMany definitions indicate metonymical ormetaphorical ssociations between word senses.
For instance,the 4th and 5th sense of "star" are4.
apiece of metal in this shape for wearing as a mark of office, rank, honour, etc.5.
a heavenly body regarded as determining one's fate.37The 4th and 5th sense are metonymically associated with two "star" senses, star.1 .n.3 (a 5- or more pointedfigure) and start.l.n.2 (a heavenly body such as a PLANET), respectively.
The algorithm often fails in suchcases for two reasons.
First, metonymies are not clearly separated and indicated in LLOCE.
Second, thegenus terms in metonymical senses are often indistinguishable from each other.
Further action must be tak-en to identify the nature of such relations before this kind of ambiguity can be successfully resolved.
Thepresence of phrases "as a ... 03 ?'
or "regarded as" and drastic hange in topic toward the second half ofthe definition may be cues for identifying metonymy and metaphor.5.
Other approachesSanfilippo and Poznanski (1992) proposed a so-caUed Dictionary Correlation Kit (DCK) in a dialog-basedenvironment for correlating word senses across pairs of MRDs, LDOCE and LLOCE.
Dolan (1994) de-scribed a heuristic approach to forming unlabeled clusters of closely related senses in a MRD.
The cluster-ing program relies on LDOCE domain code, grammar code, and 25 types of semantic relations exu'actedfrom definitions.
Yarowsky (1992) described a WSD method and an implementation based on Roget' sThesaurus and the training material of the 10-rnillion-word Grolier' s Encyclopedia.
The author suggestedthat he method can also apply to dictionary definitions.
Krovetz (1993) described a simple algorithm basedon overlap of defining words to identify related senses between morphological variants.
The author eport-ed that the success rate was over 80%.
No results were reported for closely related senses within a part-of-speech.In most of the above-mentioned works, experimental results are reported only for some senses of acouple of words.
In this study, we have evaluated our method using all senses for 12 words that have beenstudied in WSD literature.
This evaluation provides an overall picture for the expected success rate of themethod, when applied to all word senses in the MRD.
Directly comparing methods i often difficult.
Nev-ertheless, it is evident that in comparison our algorithm is simpler, requires less preprocessing, and does notrely on information idiosyncratic to LDOCE.
Thus, the algorithm described in this paper can readily applyto other MRDs besides LDOCE.
Although our algorithm akes use of defining words with various eman-tic relations with the sense, explicit computation fthose relations is not required.6.
Conclusions and Future WorkThe meth~ proposed in this work takes advantages of a number of linguistic phenomena: (1) Division ofsenses is primarily along the line of subject and topic.
(2) Rather igid schemes of text generation and pre-dictable semantic relations are used to define senses in MRDs such as LDOCE.
(3) The implicit links be-tween instances of many of these relations are available in a thesaurus such as LLOCE.This work also underscores the effectiveness oflexical rules for coarse WSD.
Hand-constructed opic-based classes of words, coupled with lexical rules as common topic and cross references of topics, prove tobe highly affecfive both in coverage and precision for WSD, admittedly for sense definitions, a somehowrestricted type of text.Merging senses via labeling has another implication as weU.
As discussed in Section 4, the sens-es sharing the same label (or cross-referencing labels) are frequently associated through various linguisticrelations.
Making those relations explicit will open the door to flexible treatment of lexicon, semantic typ-ing, and semantic under-specification, all of which have received ever-increasing interest.In a broader context, his paper promotes the progressive approach to knowledge acquisition forNLP as opposed to the "from-scratch" approach.
We believe this to be a preferable means to approachinga sound and complete knowledge base.38IAcknowledgmentThe authors would like to thank the National Science Council of the ROC for financial support of this re-search under Conu'act No.
NSC 85-2213-E-007-042.References1.
Brown, P., S.A. Pietra, V.J.D.
Pietra, and R. Mercer (1991).
"Word Sense Disambiguation using Sta-tistical Methods," In Proceedings of the 29th Annual Meeting of the Association for ComputationalLinguistics, pp 264-270.2.
Church, Ken W. (1988).
"A stochastic Parts Program and Noun Phrase Parser for Unrestricted Text.
"In Proceedings of the 2nd Conference on Applied Natural Language Processing (ANLP-88), pp 136-143, Austin, Texas, USA.3.
Dagan, Ido, Alon Itai, and Uldke Schwall (1991).
tTwo Languages are More Informative than One,$ Pro-ceedings of the 29th Annual Meeting of the Association for Computational Linguistics, pp 130-137.4.Dagan, Ido, Alon Itai (1994), "Word Sense Disambiguation Using a Second Language Monolingual Cor-pus," Computational Linguistics 20(4), pp 563-596.5.
Dolan, W.B.
(1994).
"Word Sense Disambiguation: Clustering Related Senses."
In Proceedings of theInternational Conference on Computational Linguistics, pp 712-716.6.Kilgarriff, Adam (1993).
"Dictionary Word Sense Distinctions: An Enquiry into Their Nature."
Com-puters and the Humanities, 26, pp 365-387.7.Krovetz, R. and Croft (1992).
"Lexical Ambiguity and Information Retrieval."
ACM Transaction on In-formation Systems, pp 115-141.8.Krovetz, Robert (1992).
"Sense-Linking ina Machine Readable Dictionary."
In Proceedings of the 30thAnnual meeting of the Association for Computational Linguistics, pp 330-332.9.Krovetz, Robert (1993).
"Viewing Morphology as an Inference Process."
In Proceedings of the 16th In-ternational ACM SIGIR Conference on Research and Development inInformation Retrieval, pp 191-220.J.
0.
Lesk, Michael E. (1986).
"Automatic sense disambiguation using machine readable dictionaries: howto tell a pine cone from a ice-cream cone."
In Proceedings of the ACM SIGDOC Conference, pp 24-26, Toronto, Ontario.11.
Longman (1992).
"Longman English-Chinese Dictionary of Contemporary English."
LongmanGroup (Far East) Ltd., Hong Kong.12.Luk, Alpha K (1995).
"Statistical Sense Disambiguation with Relatively Small Corpora Using Dictio-nary Definitions;" In Proceedings of the Annual Meeting of the Association for Computational Linguistics,pp 181-188.13.McArthur, Tom (1992).
"Longman Lexicon of Contemporary English."
Longman Group (Far East)Ltd., Hong Kong.14.
McKeown, Katherine R. (1985).
"Using Discourse and Focus Constraints to Generate Natural Lan-guage Text."
Combridge University Press, Cambridge, England.15.
McRoy, S. (1992).
"Using Multiple Knowledge Sources for Word Sense Discrimination."
Compu-tational Linguistics 18(1), pp 1-30.1 6.
Putstejovsky, James (1991).
"The Generative Lexicon."
Computational Linguistics (17)4, pp 409-441.17.Putstejovsky, James and Pierrette Bouillon (1994).
"On the Proper Role of Coercion in Semantic Typ-ing."
In Proceedings of the International Conference on Computational Linguistics, pp 706-711.18.
Saniilippo, A., and V. Poznanski.
(1992).
"The Acquisition of Lexical Knowledge from Combined39Machine-Readable Dictionary Sources."
In Proceedings of the 3rd Conference on Applied NaturalLanguage Processing (ANLP-92), pp 80-87, Trento, Italy.1 9.
Vanderwende (1994).
"Interpretation f Noun Sequence."
In Proceedings of the International Con-ference on Computational Linguistics, pp 454-460.20.Yarowsky, David (1992).
"Word-Sense Disambiguation Using Statistical Models of Roget' s Catego-ries Trained on Large Corpora."
In Proceedings of the International Conference on Computational Linguis-tics, pp 454.-460.Appendix Semantic Table for set labels of 12 Polysemous WordsWord Alternate sets in Semantic LabellingLLOCEmole IsentenceIsingbowconedutygalleya Ac061n Mf159n Bein Ldn Cm256a Gf235v Ck210nAgl l3n Hh242n Gdn Hbn Nk335n Hh234n Kb046n Mf157n Nj295v Nj295vMbv KbnDgn Na008n Ai134n Aj156n Jb044n Han Fc063n Jf l60n Jhn Db038n Mf157n Mf153n Gdsmall animalsharbours and yardsskin, complexion and hairgeographypunishments and deterrentsphrases and sentencespunishing and finingworms and similar creaturesshot and bulletscommunicatingobject generallystrikingbows and arrowsstring instrumentsparts of shipsbending and leaningbending and leaningputting and takingmusic and related activititiesclothes and personal belongingstypifying and embodyingifmit and seedkinds of coniferous trees;geometrical shapessubstances, materials, objects and equipmentrules of behaviourtaxesbusiness, work, and employmentthe kitchen and similar oomsparts of shipslarger kinds of sailing boatscommunication40Word Alternate sets in Semantic LabellingLLOCEinterestissuestartastenFb028n Fj228n Ka006n Je112v Fb025Iv Fj224v Ka0110nNfn Aa020n Gd180In Gf243n Nf153v Gd174n Ca!v Den Na: nNbn Nen Kd082n La002v Kd079n He:n Le!n Naattractingcommunicating, mainly by reading and writing, pnnting and pub-lishinggames and hobbiesinterest on moneyattracting and interestingnteresting and excitinginteresting and thrillingcausingyoung creaturespublications and editionssubject and topicresults and effectspublishingpeoplebelonging and owning, getting and givingbeing, becoming and happeningchancedoing thingsactorsplanets, suns, and starsplaying and rehearsing\]specific substances and materialstime generally!being, becoming and happeningn IaO06n Nb035n Gdl51n F1281v F1280v,n Ea'v,n Fan Gbn Fb020shapes and modelsfortunepunctuationtasting thingsItasting thingsfood generallyfeeling and behavior generallyknowing and learningliking and loving41
