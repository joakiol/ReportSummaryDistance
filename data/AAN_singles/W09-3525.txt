Proceedings of the 2009 Named Entities Workshop, ACL-IJCNLP 2009, pages 112?115,Suntec, Singapore, 7 August 2009. c?2009 ACL and AFNLPLanguage Independent Transliteration system using phrase basedSMT approach on substringsSara NoemanIBM Cairo Technology & DevelopmentCenterGiza, Egyptnoemans@eg.ibm.comAbstractEveryday the newswire introduce events from all overthe world, highlighting new names of persons, loca-tions and organizations with different origins.
Thesenames appear as Out of Vocabulary (OOV) words forMachine translation, cross lingual information retriev-al, and many other NLP applications.
One way to dealwith OOV words is to transliterate the unknownwords, that is, to render them in the orthography ofthe second language.We introduce a statistical approach for transliterationonly using the bilingual resources released in theshared task and without any previous knowledge ofthe target languages.
Mapping the Transliterationproblem to the Machine Translation problem, wemake use of the phrase based SMT approach and ap-ply it on substrings of names.
In the English to Russi-an task, we report ACC (Accuracy in top-1) of 0.545,Mean F-score of 0.917, and MRR (Mean ReciprocalRank) of 0.596.Due to time constraints, we made a single experimentin the English to Chinese task, reporting ACC, MeanF-score, and MRR of 0.411, 0.737, and 0.464 respect-ively.Finally, it is worth mentioning that the system islanguage independent since the author is not aware ofeither languages used in the experiments.1.
IntroductionNamed entities translation is strongly required in thefield of Information retrieval (IR) as well as its usagein Machine translation.
A significant proportion ofOOV words are named entities and typical analysesfind around 50% of OOV words to be named entities,yet these can be the most important words in the quer-ies.
Larkey et al(2003) showed that average precisionof cross language retrieval reduced more than 50%when named entities in the queries were not trans-lated.Transliteration may be considered as a phonetic trans-lation or mapping of a sequence of characters in thesource language in the alphabet of the target language,thus we can use the analogy with the Machine transla-tion problem, which translates a sequence of words inthe source language into a semantically equivalent se-quence of words in the target language.In a statistical approach to machine translation, givena foreign word F, we try to find the English word ?that maximizes P(E\F).
Using Bayes' rule, we can for-mulate the task as follows:This  is  known  as  the  noisy  channel  model,  whichsplits the problem into two sub-tasks.
The translationmodel provides an estimate for the P(F\E) for the for-eign word F being a translation for the English wordE, while the language model provides an estimate ofthe probability P(E) is an English word.In this paper we use the phrase based statistical Ma-chine Translation (PBSMT) approach introduced by(Koehn et al) to build English to Russian, and Eng-lish to Chinese transliteration systems capable oflearning the substring to substring mapping betweensource and target languages.Section 2 includes a detailed description of ourapproach, section 3 describes our experimental set upand the results.
The conclusions and future work areexplained in section 4.2.
System architectureOur approach is a formulation of the Transliterationproblem using the PBSMT technique that proved im-provement in Machine translation domain, makinguse of the analogy between the two problems.The phrase-based approach developed for statisticalmachine translation (Koehn et al, 2003) is designedto overcome the restrictions of many-to-many map-pings in word-based translation models.
We appliedthe phrase based statistical approach used in Machinetranslation on our problem, mapping the "word", andP(F\E)*P(E)?
=  argmaxE    P(F)=  argmax  P(F\E)*P(E)E112"phrase" in PBSMT terminology into "character", and"substring" in our system, where the substring in ournotation represents a sequence of adjacent characters.Figure (1) shows an overview of the whole system ar-chitecture.We used an HMM aligner similar to Giza++ (Och.
etal., 1999) over the parallel character sequences usingforward-backward alignment intersection.
Heuristicswere used to extend substring to substring mappingsbased on character-to-character alignment, with theconstraint that no characters within the substring pairare linked to characters outside the substring pair.Thus we generated a substring to substring translationmodel with relative frequencies.
We deploy heuristicsto extract character sequence mapping similar to theheuristics used in PBSMT (Koehn et al, 2003).
Fig-ure (2) shows the heuristics used for block extractionover substrings in the English to Russian task usingcharacter to character alignments.Figure (2)Unlike the Machine Translation task, in transliterationwe do not need any reordering during decoding whichmakes the decoding phase easier.
We used monotonebeam search decoder generating the best ktransliteration candidates, where the translation modeland the language model are used by the decoder to getbest Viterbi paths of character sequences as a phonetictranslation for the input English character sequence.
(Tillmann, et al, 2003).Finally, all transliteration candidates are weighted us-ing their translation and language model probabilitiesas follows:P( wr \ we) = P(we \ wr ) ?
P(wr ?
R)Here, we explain our system for the English to Russi-an task, while the English to Chinese system will fol-low the same criteria and their results are mentionedlater.a.
Data and ResourcesStandard Runs:In the English to Russian task, we used the parallelcorpus  (EnRu) released by NEWS 2009 Shared Taskon Transliteration to build the translation model.
Forthe English to Chinese standard run, we used theparallel English-Chinese (EnCh) corpus released byNEW2009 availed by (Li et al, 2004).
The targetlanguage side (Russian, Chinese) of the parallel datawas used to build the language model.
NEWS2009released 5977 of EnRu names pairs as a training set,and 943 pairs as a development set.
The EnCh corpushad 31,961 pairs as a training set, and 2896 pairs as adevelopment set.Non-Standard Runs:For the English to Russian task we used the Russiandata in UMC 0.1 Czech-English-Russian, from the In-stitute of Formal and Applied Linguistics (?FAL), tobuild a larger Russian LM, in addition to the data re-sources used in the standard run.
No Named Entitytagging has been applied on this data because we lackthe tools.
However, we are just validating the charac-ter n-gram sequences in the target language with lar-ger corpus of character sequences.We didn't use any additional resources for the Chinesetask.b.
TrainingThe training is held in two phases; first learning thelist of Russian characters aligned to multiple Englishcharacters, and thus we obtain a table of English char-acter n-grams to be added to unigram inventory of thesource language.
The second stage learns the translit-eration model over this new inventory.
(Larkey et al,2003).Table 1 shows the list of English n-gram charactersadded to unigram inventory.Table (1)s h c h shchs z c z szczs c h schz h zhc k ckp h phk h khc h chs h shs z szc z cz?
?
?
?A substring (phrase) table of Russian substringsmapped to English substrings is considered as theParallelCorpusHMMalignerBlockextract ion DecoderLanguageModelFigure (1)P    u     n       t     l    a    n  d?
?
?
?
?
?
?
?113translation model P(E\R).
A language model P(R) isbuilt using a monolingual Russian corpus.Figure (3) shows a sample of the substring featuretable generated during training using the block extrac-tion heuristics over HMM alignments.c.
DecodingThe source English word is fragmented into all itspossible substring sequences, and the decoder appliesa monotone beam search, without reordering, to gen-erate the best k phonetic translation character se-quences in the target language alphabet.Experiments 1, 2, and 3 use a substring based translit-eration system The experiments set up will be as fol-lows:i.
The effect of true casing versus lowercasingRussian characters is explained through thefirst experiment (Exp-1).ii.
The released English data contains some un-usual English characters not belonging to theEnglish alphabet, some of which are vowelslike "?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?
", andothers are consonants as "?, ?, ?, ?, ?, ?, ?, ?,?".
The effect  of normalizing these unusualEnglish characters is explained in the secondexperiment (Exp-2).iii.
In the third experiment (Exp-3) we used theunigram inventory described in Table (1).N.B.
: Chinese language has a very large number ofcharacters representing syllables rather than charac-ters (a syllables = a consonant + vowel, or a conson-ant + vowel + final), thus the unigram inventory usedin the English to Chinese task wasn't generated usingthe statistical trend used with English-Russian task.General linguistic heuristics were used to re-mergecharacter n-grams like "sh, th, gh, ph, etc?"
as wellas character repetitions like "ll, mm, nn ?
ss, tt,etc..."3.
ResultsEvaluation Metrics:The quality of the transliteration task was measuredusing the 6 metrics defined in the shared task whitepaper.
The first metric is the Word Accuracy in Top-1(ACC) which is the precision of the exact match withthe Top-1 reference.
The second one is the Fuzzinessin Top-1 (Mean F-score) which reflects an average F-score of the normalized lowest common subsequencebetween the system output and the Top-1 reference.The (MRR) represents the Mean Reciprocal Rank ofthe Top-1 reference in the k candidates generated bythe system.
The last three metrics MAPref, MAP10,MAPsys measure how the k candidates generated bythe transliteration system are mapped to the n refer-ences available for each input in the testset.English to Russian taskThe results of experiments 1, 2, and 3 on the Develop-ment set, using the 6 evaluation metrics explained be-fore, are written in Table (2).
Exp-2 reflects the effectof normalizing all the unusual English characters thatexisted in the training data.
Referring to the results ofExp-1, we conclude that this normalization decreasesthe ACC of the system around 2.5%.
In the next ex-periments we only use the set up of Exp-3, which usesthe statistical unigram inventory without true casingRussian characters or normalizing unusual Englishcharacters.Exp-1 Exp-2 Exp-3ACC 0.705 0 0Mean F-score0.945 0.939 0MRR 0.741 0.721 0MAPref 0.705 0 0MAP10 0.220 0.215 0MAPsys 0.525 0 0Table (2) explains Eng-Russian task results on the De-velopment Set for experiments 1, 2, and 3.?
Standard Run:Our Standard Run submission used the same setupused in Experiment-3, no lowercasing, no normaliza-tion, and using the list of English n-grams that wereadded to the unigram inventory after the first trainingphase.
Table (3) contains the results of our StandardSubmissions.Standard submissionACC 0.545Mean F-score0.917MRR 0.596MAPref 0.545MAP10 0.286MAPsys 0.299Table (3) explains Eng-Russian task results on theblind Test Set.
This was the Standard submission.N.B.
: We submitted the previous output in true-casedRussian characters as our standard submission, andthen we submitted the same system output after lowercasing as a Non-Standard run because we were notsure that the evaluation tool used by the Shared Task?
?
?
?
|| e a c o n 0 1?
?
|| e a f 0 1?
?
?
|| e a f ?
0 1?
?
?
?
?
?
|| e n e r i f 0 1?
?
?
?
?
?
?
|| e n e r i f e 0 1?
?
?
?
|| e n e r s 0 1?
?
?
?
?
|| e n e r s r 0 1?
?
?
?
?
?
|| e n e r s r ?
0 1Figure (3) a sample of the substring table114will be able to map true case and lower case vari-ations.The same will be done in the next run, where 2 sub-missions are submitted for the same output, one ofwhich was true-cased and the other was lower cased.?
Non-Standard Run:Using (UMC 0.1) additional LM on the blind Test set.The results are in table(5)Non-Standard submissionACC 0.524Mean F-score 0.913MRR 0.579MAPref 0.524MAP10 0.277MAPsys 0.291Table (5) explains Eng-Russian task results on theblind Test Set.
This was the Non-Standard submis-sion.English to Chinese taskFinally the previous setup with slight modificationswas applied to the Eng-Chinese transliteration task.Tables (6), and (7) represent the results on theChinese Development set and Test set respectively.Exp-3ACC 0.447Mean F-score 0.748MRR 0.489MAPref 0.447MAP10 0.147MAPsys 0.191Table (6) explains Eng-Chinese task results on theDevelopment Set.?
Standard Run:Standard submissionACC 0.411Mean F-score0.737MRR 0.464MAPref 0.411MAP10 0.141MAPsys 0.173Table (7) explains Eng-Chinese task results on theblind Test Set.
This was the Standard submission4.
Conclusion and Future WorkIn this paper we presented a substring based transliter-ation system, making use of the analogy between theMachine translation task and Transliteration.
By ap-plying the phrase based SMT approach in the translit-eration domain, and without any previous knowledgeof the target languages, we built an English to Russiansystem with ACC of 54.5% and an English to Chinesesystem with ACC of 41.2%.In the future we are planning to hold some experi-ments to filter out the generated phrase table (sub-string table) and try other decoding techniques.5.
AcknowledgementI would like to thank Dr. Hany Hassan in IBMCairo TDC for his helpful comments and tech-nical support.6.
ReferencesN.
AbdulJaleel  and  L.  S.  Larkey.
2003.
Statisticaltransliteration  for  English-Arabic  cross  languageinformation retrieval.
In CIKM, pages 139?146.Y.
Al-Onaizan and K. Knight.
2002.
Machine Trans-literation of Names in Arabic Text.
In Proceed-ingsof  the  ACL  Workshop  on  Computational  Ap-proaches to Semitic Languages.P.
F. Brown, V. J. Della Pietra, S. A. Della Pietra, andR.
L. Mercer.
1993.
The Mathematics of StatisticalMachine Translation: Parameter Estimation.
Com-putational Linguistics, 19(2):263?311.P.
Koehn, F.J. Och, and D. Marcu.
2003.
StatisticalPhrase-Based  Translation.
Proc.
Of  the  HumanLanguage  Technology  Conference,  HLT-NAACL?2003, May.H.
Li, M. Zhang, J. Su: A Joint Source-Channel Mod-el for Machine Transliteration.
ACL 2004: 159-166F.
J. Och, C. Tillmann, and H. Ney.
1999.
ImprovedAlignment Models for Statistical Machine Transla-tion.
In June 1999, EMNLP.T.
Sherif  and  G.  Kondrak.
2007.
Substring-BasedTransliteration.
In  Proceedings  of  the  ACLWorkshop  on  Computational  Approaches  toSemitic Languages.C.
Tillmann and H. Ney.
2003.Word Re-ordering andDP-based  Search  in  Statistical  MachineTranslation.
In COLING, pages  850-856.J.
Zobel and P. Dart.
1996.
Phonetic String Matching.Lessons from Information Retrieval.
SIGIR Forum,special issue:166?172.115
