Proceedings of NAACL HLT 2007, pages 292?299,Rochester, NY, April 2007. c?2007 Association for Computational LinguisticsExtracting Semantic Orientations of Phrases from DictionaryHiroya TakamuraPrecision and Intelligence LaboratoryTokyo Institute of Technologytakamura@pi.titech.ac.jpTakashi InuiIntegrated Research InstituteTokyo Institute of Technologyinui@iri.titech.ac.jpManabu OkumuraPrecision and Intelligence LaboratoryTokyo Institute of Technologyoku@pi.titech.ac.jpAbstractWe propose a method for extracting se-mantic orientations of phrases (pairs of anadjective and a noun): positive, negative,or neutral.
Given an adjective, the seman-tic orientation classification of phrases canbe reduced to the classification of words.We construct a lexical network by con-necting similar/related words.
In the net-work, each node has one of the three ori-entation values and the neighboring nodestend to have the same value.
We adoptthe Potts model for the probability modelof the lexical network.
For each adjec-tive, we estimate the states of the nodes,which indicate the semantic orientationsof the adjective-noun pairs.
Unlike ex-isting methods for phrase classification,the proposed method can classify phrasesconsisting of unseen words.
We also pro-pose to use unlabeled data for a seed set ofprobability computation.
Empirical evalu-ation shows the effectiveness of the pro-posed method.1 IntroductionTechnology for affect analysis of texts has recentlygained attention in both academic and industrial ar-eas.
It can be applied to, for example, a survey ofnew products or a questionnaire analysis.
Automaticsentiment analysis enables a fast and comprehensiveinvestigation.The most fundamental step for sentiment analy-sis is to acquire the semantic orientations of words:positive or negative (desirable or undesirable).
Forexample, the word ?beautiful?
is positive, while theword ?dirty?
is negative.
Many researchers have de-veloped several methods for this purpose and ob-tained good results.
One of the next problems to besolved is to acquire semantic orientations of phrases,or multi-term expressions, such as ?high+risk?
and?light+laptop-computer?.
Indeed the semantic ori-entations of phrases depend on context just as the se-mantic orientations of words do, but we would liketo obtain the orientations of phrases as basic unitsfor sentiment analysis.
We believe that we can usethe obtained basic orientations of phrases for affectanalysis of higher linguistic units such as sentencesand documents.A computational model for the semantic orienta-tions of phrases has been proposed by Takamura etal.
(2006).
However, their method cannot deal withthe words that did not appear in the training data.The purpose of this paper is to propose a method forextracting semantic orientations of phrases, which isapplicable also to expressions consisting of unseenwords.
In our method, we regard this task as thenoun classification problem for each adjective; thenouns that become respectively positive (negative,or neutral) when combined with a given adjectiveare distinguished from the other nouns.
We createa lexical network with words being nodes, by con-necting two words if one of the two appears in thegloss of the other.
In the network, each node has oneof the three orientation values and the neighboringnodes expectedly tend to have the same value.
For292example, the gloss of ?cost?
is ?a sacrifice, loss, orpenalty?
and these words (cost, sacrifice, loss, andpenalty) have the same orientation.
To capture thistendency of the network, we adopt the Potts modelfor the probability distribution of the lexical net-work.
For each adjective, we estimate the states ofthe nodes, which indicate the semantic orientationsof the adjective-noun pairs.
Information from seedwords is diffused to unseen nouns on the network.We also propose a method for enlarging the seedset by using the output of an existing method for theseed words of the probability computation.Empirical evaluation shows that our methodworks well both for seen and unseen nouns, and thatthe enlarged seed set significantly improves the clas-sification performance of the proposed model.2 Related WorkThe semantic orientation classification of words hasbeen pursued by several researchers.
Some ofthem used corpora (Hatzivassiloglou and McKeown,1997; Turney and Littman, 2003), while others useddictionaries (Kobayashi et al, 2001; Kamps et al,2004; Takamura et al, 2005; Esuli and Sebastiani,2005).Turney (2002) applied an internet-based tech-nique to the semantic orientation classification ofphrases, which had originally been developed forword sentiment classification.
In their method, thenumber of hits returned by a search-engine, with aquery consisting of a phrase and a seed word (e.g.,?phrase NEAR good?)
is used to determine the ori-entation.
Baron and Hirst (2004) extracted colloca-tions with Xtract (Smadja, 1993) and classified thecollocations using the orientations of the words inthe neighboring sentences.
Their method is similarto Turney?s in the sense that cooccurrence with seedwords is used.
In addition to individual seed words,Kanayama and Nasukawa (2006) used more compli-cated syntactic patterns that were manually created.The four methods above are based on context infor-mation.
In contrast, our method exploits the internalstructure of the semantic orientations of phrases.Wilson et al (2005) worked on phrase-level se-mantic orientations.
They introduced a polarityshifter.
They manually created the list of polarityshifters.
Inui (2004) also proposed a similar idea.Takamura et al (2006) proposed to use based onlatent variable models for sentiment classification ofnoun-adjective pairs.
Their model consists of vari-ables respectively representing nouns, adjectives, se-mantic orientations, and latent clusters, as well asthe edges between the nodes.
The words that aresimilar in terms of semantic orientations, such as?risk?
and ?mortality?
(i.e., the positive orientationemerges when they are ?low?
), make a cluster intheir model, which can be an automated version ofInui?s or Wilson et al?s idea above.
However, theirmethod cannot do anything for the words that did notappear in the labeled training data.
In this paper, wecall their method the latent variable method (LVM).3 Potts ModelIf a variable can have more than two values andthere is no ordering relation between the values,the network comprised of such variables is calledPotts model (Wu, 1982).
In this section, we ex-plain the simplified mathematical model of Pottsmodel, which is used for our task in Section 4.The Potts system has been used as a mathematicalmodel in several applications such as image restora-tion (Tanaka and Morita, 1996) and rumor transmis-sion (Liu et al, 2001).3.1 Introduction to the Potts ModelSuppose a network consisting of nodes and weightededges is given.
States of nodes are represented by c.The weight between i and j is represented by wij .Let H(c) denote an energy function, which indi-cates a state of the whole network:H(c) = ???ijwij?
(ci, cj)+??i?L??
(ci, ai), (1)where ?
is a constant called the inverse-temperature,L is the set of the indices for the observed variables,ai is the state of each observed variable indexed by i,and ?
is a positive constant representing a weight onlabeled data.
Function ?
returns 1 if two argumentsare equal to each other, 0 otherwise.
The state ispenalized if ci (i ?
L) is different from ai.
UsingH(c), the probability distribution of the network isrepresented as P (c) = exp{?H(c)}/Z, where Z isa normalization factor.However, it is computationally difficult to exactlyestimate the state of this network.
We resort to a293mean-field approximation method that is describedby Nishimori (2001).
In the method, P (c) is re-placed by factorized function ?
(c) =?i ?i(ci).Then we can obtain the function with the smallestvalue of the variational free energy:F (c) =?cP (c)H(c)?
?c?P (c) logP (c)= ???i?ci?i(ci)?
(ci, ai)???ij?ci,cj?i(ci)?j(cj)wij?
(ci, cj)??i?ci?
?i(ci) log ?i(ci).
(2)By minimizing F (c) under the condition that ?i,?ci ?i(ci) = 1, we obtain the following fixed pointequation for i ?
L:?i(c) =exp(??
(c, ai) + ?
?j wij?j(c))?n exp(??
(n, ai) + ?
?j wij?j(n)).
(3)The fixed point equation for i /?
L can be obtainedby removing ??
(c, ai) from above.This fixed point equation is solved by an itera-tive computation.
In the actual implementation, werepresent ?i with a linear combination of the dis-crete Tchebycheff polynomials (Tanaka and Morita,1996).
Details on the Potts model and its computa-tion can be found in the literature (Nishimori, 2001).After the computation, we obtain the function?i ?i(ci).
When the number of classes is 2, the Pottsmodel in this formulation is equivalent to the mean-field Ising model (Nishimori, 2001).3.2 Relation to Other ModelsThis Potts model with the mean-field approximationhas relation to several other models.As is often discussed (Mackay, 2003), the min-imization of the variational free energy (Equa-tion (2)) is equivalent to the obtaining the factorizedmodel that is most similar to the maximum likeli-hood model in terms of the Kullback-Leibler diver-gence.The second term of Equation (2) is the entropyof the factorized function.
Hence the optimizationproblem to be solved here is a kind of the maxi-mum entropy model with a penalty term, which cor-responds to the first term of Equation (2).We can find a similarity also to the PageRank al-gorithm (Brin and Page, 1998), which has been ap-plied also to natural language processing tasks (Mi-halcea, 2004; Mihalcea, 2005).
In the PageRank al-gorithm, the pagerank score ri is updated asri = (1?
d) + d?jwijrj , (4)where d is a constant (0 ?
d ?
1).
This updateequation consists of the first term corresponding torandom jump from an arbitrary node and the sec-ond term corresponding to the random walk from theneighboring node.Let us derive the first order Taylor expansion ofEquation (3).
We use the equation for i /?
L anddenote the denominator by Z?
, for simplicity.
Sinceexpx ?
1 + x, we obtain?i(c) =exp(?
?j wij?j(c))Z?
?1 + ?
?j wij?j(c)Z?= 1Z?+ ?Z??jwij?j(c).
(5)Equation (5) clearly has a quite similar form asEquation (4).
Thus, the PageRank algorithm can beregarded as an approximation of our model.
Let usclarify the difference between the two algorithms.The PageRank is designed for two-class classifica-tion, while the Potts model can be used for an arbi-trary number of classes.
In this sense, the PageRankis an approximated Ising model.
The PageRank isapplicable to asymmetric graphs, while the theoryused in this paper is based on symmetric graphs.4 Potts Model for Phrasal SemanticOrientationsIn this section, we explain our classification method,which is applicable also to the pairs consisting of anadjective and an unseen noun.4.1 Construction of Lexical NetworksWe construct a lexical network, which Takamura etal.
(2005) call the gloss network, by linking twowords if one word appears in the gloss of the otherword.
Each link belongs to one of two groups:294the same-orientation links SL and the different-orientation links DL.If a negation word (e.g., nai, for Japanese) followsa word in the gloss of the other word, the link is adifferent-orientation link.
Otherwise the links is asame-orientation link1.We next set weights W = (wij) to links :wij =????
?1?d(i)d(j)(lij ?
SL)?
1?d(i)d(j)(lij ?
DL)0 otherwise, (6)where lij denotes the link between word i and wordj, and d(i) denotes the degree of word i, whichmeans the number of words linked with word i. Twowords without connections are regarded as beingconnected by a link of weight 0.4.2 Classification of PhrasesTakamura et al (2005) used the Ising model to ex-tract semantic orientations of words (not phrases).We extend their idea and use the Potts model to ex-tract semantic orientations of phrasal expressions.Given an adjective, the decision remaining to bemade in classification of phrasal expressions con-cerns nouns.
We therefore estimate the state of thenodes on the lexical network for each adjective.
Thenouns paring with the given adjective in the train-ing data are regarded as seed words, which we callseen words, while the words that did not appear inthe training data are referred to as unseen words.We use the mean-field method to estimate thestate of the system.
If the probability ?i(c) of a vari-able being positive (negative, neutral) is the highestof the three classes, then the word corresponding tothe variable is classified as a positive (negative, neu-tral) word.We explain the reason why we use the Potts modelinstead of the Ising model.
While only two classes(i.e., positive and negative) can be modeled by theIsing model, three classes (i.e., positive, negativeand neutral) can be modelled by the Potts model.For the semantic orientations of words, all the wordsare sorted in the order of the average orientationvalue, equivalently the probability of the word be-ing positive.
Therefore, even if the neutral class is1For English data, a negation should precede a word, in or-der for the corresponding link to be a different-orientation link.not explicitly incorporated, we can manually deter-mine two thresholds that define respectively the pos-itive/neutral and negative/neutral boundaries.
Forthe semantic orientations of phrasal expressions,however, it is impractical to manually determinethe thresholds for each of the numerous adjectives.Therefore, we have to incorporate the neutral classusing the Potts model.For some adjectives, the semantic orientation isconstant regardless of the nouns.
We need not usethe Potts model for those unambiguous adjectives.We thus propose the following two-step classifica-tion procedure for a given noun-adjective pair <n, a >.1.
if the semantic orientation of all the instanceswith a in L is c, then classify < n, a > into c.2.
otherwise, use the Potts model.We can also construct a probability model foreach noun to deal with unseen adjectives.
However,we focus on the unseen nouns in this paper, becauseour dataset has many more nouns than adjectives.4.3 Hyper-parameter PredictionThe performance of the proposed method largely de-pends on the value of hyper-parameter ?.
In order tomake the method more practical, we propose a cri-terion for determining its value.Takamura et al (2005) proposed two kinds of cri-teria.
One of the two criteria is an approximatedleave-one-out error rate and can be used only when alarge labeled dataset is available.
The other is a no-tion from statistical physics, that is, magnetization:m =?ix?i/N.
(7)At a high temperature, variables are randomly ori-ented (paramagnetic phase, m ?
0).
At a lowtemperature, most of the variables have the samedirection (ferromagnetic phase, m 6= 0).
It isknown that at some intermediate temperature, ferro-magnetic phase suddenly changes to paramagneticphase.
This phenomenon is called phase transition.Slightly before the phase transition, variables are lo-cally polarized; strongly connected nodes have thesame polarity, but not in a global way.
Intuitively,the state of the lexical network is locally polarized.295Therefore, they calculate values of m with severaldifferent values of ?
and select the value just beforethe phase transition.Since we cannot expect a large labeled datasetto be available for each adjective, we use notthe approximated leave-one-out error rate, but themagnetization-like criterion.
However, the magne-tization above is defined for the Ising model.
Wetherefore consider that the phase transition has oc-curred, if a certain class c begins to be favored allover the system.
In practice, when the maximum ofthe spatial averages of the approximated probabil-ities maxc?i ?i(c)/N exceeds a threshold duringincreasing ?, we consider that the phase transitionhas occurred.
We select the value of ?
slightly be-fore the phase transition.4.4 Enlarging Seed Word SetWe usually have only a few seed words for a givenadjective.
Enlarging the set of seed words will in-crease the classification performance.
Therefore, weautomatically classify unlabeled pairs by means ofan existing method and use the classified instancesas seeds.As an existing classifier, we use LVM.
Theirmodel can classify instances that consist of a seennoun and a seen adjective, but are unseen as a pair.Although we could classify and use all the nounsthat appeared in the training data (with an adjectivewhich is different from the given one), we do notadopt such an alternative, because it will incorporateeven non-collocating pairs such as ?green+idea?
intoseeds, resulting in possible degradation of classifi-cation performance.
Therefore, we sample unseenpairs consisting of a seen noun and a seen adjectivefrom a corpus, classify the pairs with the latent vari-able model, and add them to the seed set.
The en-larged seed set consists of pairs used in newspaperarticles and does not include non-collocating pairs.5 Experiments5.1 DatasetWe extracted pairs of a noun (subject) and an ad-jective (predicate), from Mainichi newspaper arti-cles (1995) written in Japanese, and annotated thepairs with semantic orientation tags : positive, neu-tral or negative.
We thus obtained the labeled datasetconsisting of 12066 pair instances (7416 differentpairs).
The dataset contains 4459 negative instances,4252 neutral instances, and 3355 positive instances.The number of distinct nouns is 4770 and the num-ber of distinct adjectives is 384.
To check the inter-annotator agreement between two annotators, wecalculated ?
statistics, which was 0.6402.
This valueis allowable, but not quite high.
However, positive-negative disagreement is observed for only 0.7% ofthe data.
In other words, this statistics means thatthe task of extracting neutral examples, which hashardly been explored, is intrinsically difficult.We should note that the judgment in annotationdepends on which perspective the annotator takes;?high+salary?
is positive from employee?s perspec-tive, but negative from employer?s perspective.
Theannotators are supposed to take a perspective subjec-tively.
Our attempt is to imitate annotator?s decision.To construct a classifier that matches the decision ofthe average person, we also have to address how tocreate an average corpus.
We do not pursue this is-sue because it is out of the scope of the paper.As unlabeled data, we extracted approximately65,000 pairs for each iteration of the 10-fold cross-validation, from the same news source.The average number of seed nouns for each am-biguous adjective was respectively 104 in the la-beled seed set and 264 in the labeled+unlabeled seedset.
Please note that these figures are counted foronly ambiguous adjectives.
Usually ambiguous ad-jectives are more frequent than unambiguous adjec-tives.5.2 Experimental SettingsWe employ 10-fold cross-validation to obtain theaveraged classification accuracy.
We split the datasuch that there is no overlapping pair (i.e., any pairin the training data does not appear in the test data).Hyperparameter ?
was set to 1000, which is verylarge since we regard the labels in the seed set isreliable.
For the seed words added by the classifier,lower ?
can be better.
Determining a good value for?
is regarded as future work.Hyperparameter ?
is automatically selected from2Although Kanayama and Nasukawa (2006) that ?
for theirdataset similar to ours was 0.83, this value cannot be directlycompared with our value because their dataset includes both in-dividual words and pairs of words.296{0.1, 0.2, ?
?
?, 2.5} for each adjective and each foldof the cross-validation using the prediction methoddescribed in Section 4.3.5.3 ResultsThe results of the classification experiments aresummarized in Table 1.The proposed method succeeded in classifying,with approximately 65% in accuracy, those phrasesconsisting of an ambiguous adjective and an unseennoun, which could not be classified with existingcomputational models such as LVM.Incorporation of unlabeled data improves accu-racy by 15.5 points for pairs consisting of a seennoun and an ambiguous adjective, and by 3.5 pointsfor pairs consisting of an unseen noun and an am-biguous adjective, approximately.
The reason whythe former obtained high increase is that pairs withan ambiguous adjective3 are usually frequent andlikely to be found in the added unlabeled dataset.If we regard this classification task as binary clas-sification problems where we are to classify in-stances into one class or not, we obtain three accu-racies: 90.76% for positive, 81.75% for neutral, and86.85% for negative.
This results suggests the iden-tification of neutral instances is relatively difficult.Next we compare the proposed method withLVM.
The latent variable method is applicable onlyto instance pairs consisting of an adjective and aseen noun.
Therefore, we computed the accuracyfor 6586 instances using the latent variable methodand obtained 80.76 %.
The corresponding accuracyby our method was 80.93%.
This comparison showsthat our method is better than or at least comparableto the latent variable method.
However, we have tonote that this accuracy of the proposed method wascomputed using the unlabeled data classified by thelatent variable method.5.4 DiscussionThere are still 3320 (=12066-8746) word pairswhich could not be classified, because there are noentries for those words in the dictionary.
However,the main cause of this problem is word segmenta-3Seen nouns are observed in both the training and the testdatasets because they are frequent.
Ambiguous adjectives areoften-used adjectives such as ?large?, ?small?, ?high?, and?low?.tion, since many compound nouns and exceedingly-subdivided morphemes are not in dictionaries.
Anappropriate mapping from the words found in cor-pus to entries of a dictionary will solve this problem.We found a number of proper nouns, many of whichare not in the dictionary.
By estimating a class of aproper noun and finding the words that matches theclass in the dictionary, we can predict the semanticorientations of the proper noun based on the orienta-tions of the found words.In order to see the overall tendency of errors, wecalculated the confusion matrices both for pairs ofan ambiguous adjective and a seen noun, and forpairs of an ambiguous adjective and an unseen noun(Table 2).
The proposed method works quite well forpositive/negative classification, though it finds stillsome difficulty in correctly classifying neutral in-stances even after enhanced with the unlabeled data.In order to qualitatively evaluate the method,we list several word pairs below.
These wordpairs are classified by the Potts model with the la-beled+unlabeled seed set.
All nouns are unseen;they did not appear in the original training dataset.Please note again that the actual data is Japanese.positive instancesnoun adjectivecost lowbasic price lowloss littleintelligence higheducational background highcontagion not-happeningversion newcafe manysalary highcommission lownegative instancesnoun adjectivedamage heavychance littleterrorist manytrouble manyvariation littlecapacity smallsalary lowdisaster manydisappointment bigknowledge littleFor example, although both ?salary?
and ?com-mission?
are kinds of money, our method captures297Table 1: Classification accuracies (%) for various seed sets and test datasets.
?Labeled?
seed set correspondsto the set of manually labeled pairs.
?Labeled+unlabeled?
seed set corresponds to the union of ?labeled?
seedset and the set of pairs labeled by LVM.
?Seen nouns?
for test are the nouns that appeared in the trainingdata, while ?unseen nouns?
are the nouns that did not appear in the training dataset?.
Please note that seenpairs are excluded from the test data.
?Unambiguous?
adjectives corresponds to the pairs with an adjectivewhich has a unique orientation in the original training dataset, while ?ambiguous?
adjectives corresponds tothe pairs with an adjective which has more than one orientation in the original training dataset.seed\test seen nouns unseen nouns totallabeled 68.24 73.70 69.59(4494/6586) (1592/2160) (6086/8746)unambiguous ambiguous unambiguous ambiguous98.15 61.65 94.85 61.85(1166/1188) (3328/5398) (736/776) (856/1384)labeled+unlabeled 80.93 75.88 79.68(5330/6586) (1639/2160) (6969/8746)unambiguous ambiguous unambiguous ambiguous98.15 77.14 94.85 65.25(1166/1188) (4164/5398) (736/776) (903/1384)Table 2: Confusion matrices of classification result with labeled+unlabeled seed setPotts modelseen nouns unseen nounspositive neutral negative sum positive neutral negative sumpositive 964 254 60 1278 126 84 30 240Gold standard neutral 198 1656 286 2140 60 427 104 591negative 39 397 1544 1980 46 157 350 553sum 1201 2307 1890 5398 232 668 484 1384the difference between them; ?high salary?
is posi-tive, while ?low (cheap) commission?
is also posi-tive.6 ConclusionWe proposed a method for extracting semantic ori-entations of phrases (pairs of an adjective and anoun).
For each adjective, we constructed a Pottssystem, which is actually a lexical network extractedfrom glosses in a dictionary.
We empirically showedthat the proposed method works well in terms ofclassification accuracy.Future work includes the following:?
We assumed that each word has a semantic ori-entation.
However, word senses and subjectiv-ity have strong interaction (Wiebe and Mihal-cea, 2006).?
The value of ?
must be properly set, becauselower ?
can be better for the seed words addedby the classifier,?
To address word-segmentation problem dis-cussed in Section 5.3, we can utilize the factthat the heads of compound nouns often inheritthe property determining the semantic orienta-tion when combined with an adjective.?
The semantic orientations of pairs consisting ofa proper noun will be estimated from the namedentity classes of the proper nouns such as per-son name and organization.298ReferencesFaye Baron and Graeme Hirst.
2004.
Collocations ascues to semantic orientation.
In AAAI Spring Sympo-sium on Exploring Attitude and Affect in Text: Theo-ries and Applications.Sergey Brin and Lawrence Page.
1998.
The anatomy ofa large-scale hypertextual Web search engine.
Com-puter Networks and ISDN Systems, 30(1?7):107?117.Andrea Esuli and Fabrizio Sebastiani.
2005.
Determin-ing the semantic orientation of terms through glossanalysis.
In Proceedings of the 14th ACM Inter-national Conference on Information and KnowledgeManagement (CIKM?05), pages 617?624.Vasileios Hatzivassiloglou and Kathleen R. McKeown.1997.
Predicting the semantic orientation of adjec-tives.
In Proceedings of the 35th Annual Meeting ofthe Association for Computational Linguistics and the8th Conference of the European Chapter of the Asso-ciation for Computational Linguistics, pages 174?181.Takashi Inui.
2004.
Acquiring Causal Knowledge fromText Using Connective Markers.
Ph.D. thesis, Grad-uate School of Information Science, Nara Institute ofScience and Technology.Jaap Kamps, Maarten Marx, Robert J. Mokken, andMaarten de Rijke.
2004.
Using wordnet to measuresemantic orientation of adjectives.
In Proceedingsof the 4th International Conference on Language Re-sources and Evaluation (LREC?04), volume IV, pages1115?1118.Hiroshi Kanayama and Tetsuya Nasukawa.
2006.
Fullyautomatic lexicon expansion for domain-oriented sen-timent analysis.
In Proceedings of the Conference onEmpirical Methods in Natural Language Processing(EMNLP?06), pages 355?363.Nozomi Kobayashi, Takashi Inui, and Kentaro Inui.2001.
Dictionary-based acquisition of the lexicalknowledge for p/n analysis (in Japanese).
In Pro-ceedings of Japanese Society for Artificial Intelligence,SLUD-33, pages 45?50.Zhongzhu Liu, Jun Luo, and Chenggang Shao.
2001.Potts model for exaggeration of a simple rumor trans-mitted by recreant rumormongers.
Physical Review E,64:046134,1?046134,9.David J. C. Mackay.
2003.
Information Theory, Infer-ence and Learning Algorithms.
Cambridge UniversityPress.Mainichi.
1995.
Mainichi Shimbun CD-ROM version.Rada Mihalcea.
2004.
Graph-based ranking algorithmsfor sentence extraction, applied to text summarization.In The Companion Volume to the Proceedings of the42nd Annual Meeting of the Association for Computa-tional Linguistics, (ACL?04), pages 170?173.Rada Mihalcea.
2005.
Unsupervised large-vocabularyword sense disambiguation with graph-based algo-rithms for sequence data labeling.
In Proceedings ofthe Joint Conference on Human Language Technology/ Empirical Methods in Natural Language Processing(HLT/EMNLP), pages 411?418.Hidetoshi Nishimori.
2001.
Statistical Physics of SpinGlasses and Information Processing.
Oxford Univer-sity Press.Frank Z. Smadja.
1993.
Retrieving collocations fromtext: Xtract.
Computational Linguistics, 19(1):143?177.Hiroya Takamura, Takashi Inui, and Manabu Okumura.2005.
Extracting semantic orientations of words usingspin model.
In Proceedings of the 43rd Annual Meet-ing of the Association for Computational Linguistics(ACL?05), pages 133?140.Hiroya Takamura, Takashi Inui, and Manabu Okumura.2006.
Latent variable models for semantic orientationsof phrases.
In Proceedings of the 11th Conference ofthe European Chapter of the Association for Compu-tational Linguistics (EACL?06).Kazuyuki Tanaka and Tohru Morita.
1996.
Applicationof cluster variation method to image restoration prob-lem.
In Theory and Applications of the Cluster Vari-ation and Path Probability Methods, pages 353?373.Plenum Press, New York.Peter D. Turney and Michael L. Littman.
2003.
Measur-ing praise and criticism: Inference of semantic orien-tation from association.
ACM Transactions on Infor-mation Systems, 21(4):315?346.Peter D. Turney.
2002.
Thumbs up or thumbs down?semantic orientation applied to unsupervised classifi-cation of reviews.
In Proceedings 40th Annual Meet-ing of the Association for Computational Linguistics(ACL?02), pages 417?424.Janyce M. Wiebe and Rada Mihalcea.
2006.
Word senseand subjectivity.
In Proceedings of the 21st Interna-tional Conference on Computational Linguistics andthe 44th annual meeting of the Association for Compu-tational Linguistics (COLING-ACL?06), pages 1065?1072.Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.2005.
Recognizing contextual polarity in phrase-levelsentiment analysis.
In Proceedings of joint confer-ence on Human Language Technology / Conference onEmpirical Methods in Natural Language Processing(HLT/EMNLP?05), pages 347?354.Fa-Yueh Wu.
1982.
The potts model.
Reviews of Mod-ern Physics, 54(1):235?268.299
