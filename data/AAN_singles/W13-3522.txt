Proceedings of the Seventeenth Conference on Computational Natural Language Learning, pages 202?211,Sofia, Bulgaria, August 8-9 2013. c?2013 Association for Computational LinguisticsMultilingual WSD-like Constraints for Paraphrase ExtractionWilker AzizResearch Group in Computational LinguisticsUniversity of Wolverhampton, UKW.Aziz@wlv.ac.ukLucia SpeciaDepartment of Computer ScienceUniversity of Sheffield, UKL.Specia@sheffield.ac.ukAbstractThe use of pivot languages and word-alignment techniques over bilingual cor-pora has proved an effective approach forextracting paraphrases of words and shortphrases.
However, inherent ambiguities inthe pivot language(s) can lead to inade-quate paraphrases.
We propose a novel ap-proach that is able to extract paraphrasesby pivoting through multiple languageswhile discriminating word senses in the in-put language, i.e., the language to be para-phrased.
Text in the input language is an-notated with ?senses?
in the form of for-eign phrases obtained from bilingual par-allel data and automatic word-alignment.This approach shows 62% relative im-provement over previous work in generat-ing paraphrases that are judged both moreaccurate and more fluent.1 IntroductionParaphrases are alternative ways of expressing agiven meaning.
Generating paraphrases that gobeyond morphological variants of the original textis a challenging problem and has been shown tobe useful in many natural language applications.These include i) expanding the set of referencetranslations for Machine Translation (MT) eval-uation (Denkowski and Lavie, 2010; Liu et al2010) and parameter optimisation (Madnani et al2007), where multiple reference translations areimportant to accommodate for valid variations ofsystem translations; ii) addressing the problem ofout-of-vocabulary words or phrases in MT, eitherby replacing these by paraphrases that are knownto the MT system (Mirkin et al 2009) or by ex-panding the phrase table with new translation al-ternatives (Callison-Burch et al 2006); and iii)expanding queries for improved coverage in ques-tion answering (Riezler et al 2007).Bannard and Callison-Burch (2005) introducedan approach to paraphrasing which has shown par-ticularly promising results by pivoting through dif-ferent languages for which bilingual parallel datais available.
The approach consists in aligningphrases in the bilingual parallel corpus to findpairs of phrases (e1, e2) in the input language, i.e.,the language to be paraphrased, which typicallyalign to the same foreign phrases F = {f : e1 ?f ?
e2}.
This intermediate language is calledpivot language and the phrases f ?
F that supportthe equivalence (e1, e2) are called pivot phrases.If there exists a non-empty set of pivots connect-ing e1 to e2, e2 is said to be a paraphrase of e1.
Theparaphrase is scored in terms of the conditionalprobabilities observed in the parallel corpus1 bymarginalising out the pivot phrases that supportthe alignment (e1, e2) as shown in Equation 1.p(e2|e1) =?f?Fp(f |e1)p(e2|f) (1)Equation 1 allows paraphrases to be extractedby using multiple pivot languages such that theselanguages help discard inadequate paraphrases re-sulting from ambiguous pivot phrases.
Howeverin this formulation all senses of the input phraseare mixed together in a single distribution.
For ex-ample, for the Spanish input phrase acabar con,both paraphrases superar (overcome) and elim-inar (eliminate) may be adequate depending onthe context, however they are not generally in-terchangeable.
In (Bannard and Callison-Burch,1The distributions p(f |e) and p(e|f) are extracted fromrelative counts in word-aligned parallel corpus.2022005), the distributions learnt from different bilin-gual corpora are combined through a simple av-erage.
This makes the model naturally favourthe most frequent senses of the phrases, assigningvery low probabilities to less frequent senses.
Sec-tion 5 shows evidence of how this limitation makesparaphrases with certain senses unreachable.We propose a novel formulation of the problemof generating paraphrases that is constrained bysense information in the form of foreign phrases,which can be thought of as a quasi-sense annota-tion.
Using a bilingual parallel corpus to annotatephrases with their quasi-senses has proved help-ful in building word-sense disambiguation (WSD)models for MT (Carpuat and Wu, 2007; Chan etal., 2007): instead of monolingual senses, pos-sible translations of phrases obtained with word-alignment were used as senses.
Our approach per-forms paraphrase extraction by pivoting throughmultiple languages while penalising senses of theinput that are not supported by these pivots.Our experiments show that the proposed ap-proach can effectively eliminate inadequate para-phrases for polysemous phrases, with a significantimprovement over previous approaches.
We ob-serve absolute gains of 15-25% in precision andrecall in generating paraphrases that are judgedfluent and meaning preserving in context.This paper is structured as follows: Section 2describes additional previous work on paraphraseextraction and pivoting.
Section 3 presents theproposed model.
Section 4 introduces our experi-mental settings, while Section 5 shows the resultsof a series of experiments.2 Related workIn addition to the well-known approach by (Ban-nard and Callison-Burch, 2005), the followingprevious approaches using pivot languages forparaphrasing can be mentioned.
For a recentand comprehensive survey on a number of data-driven paraphrase generation methods, we referthe reader to (Madnani and Dorr, 2010).Cohn and Lapata (2007) make use of multi-ple parallel corpora to improve Statistical Ma-chine Translation (SMT) by triangulation for lan-guages with little or no source-target parallel dataavailable.
Translation tables are learnt by pivot-ing through languages for which source-pivot andpivot-target bilingual corpora can be found.
Multi-ple pivot languages were found useful to preservethe meaning of the source in the triangulated trans-lation, as different languages are likely to realiseambiguities differently.
Although their findingsapply to generating translation candidates, the in-put phrases are not constrained to specific senses,and as a consequence multiple translations, whichare valid in different contexts but not generallyinterchangeable, are mixed together in the samedistribution.
In SMT the target Language Model(LM) helps selecting the adequate translation can-didate in context.Callison-Burch (2008) extends (Bannard andCallison-Burch, 2005) by adding syntactic con-straints to the model.
Paraphrase extraction isdone by pivoting using word-alignment informa-tion, as before, but sentences are syntacticallyannotated and paraphrases are restricted to thosewith the same syntactic category.
This addressescategorial ambiguity by preventing that wordswith a given category (e.g.
a noun) are para-phrased by words with other categories (e.g., averb).
However, the approach does not solve themore complex issue of polysemous paraphrases:words with the same category but different mean-ings, such as the noun bank as financial institutionand land alongside a river/lake.Marton et al(2009) derive paraphrases frommonolingual data using distributional similaritymetrics.
The approach has the advantage of not re-quiring bilingual parallel data, but it suffers fromissues typical of distributional similarity metrics.In particular, it produces paraphrases that share thesame or similar contexts but are related in waysthat do not always characterise paraphrasing, suchas antonymy.3 Paraphrasing through multilingualconstraintsOur approach to paraphrasing can be applied toboth individual words or sequences of words ofany length, conditioned only on sufficient evi-dence of these segments in a parallel corpus.
Weuse segments as provided by the standard phraseextraction process from phrase-based SMT ap-proaches (see Section 4), which in most casesrange from individual words to short sequences ofwords (up to seven words in our case).
Hereafter,we refer to these segments simply as phrases.A model for paraphrasing under a constrainedset of senses should take into account both theinput phrase and the sense tag while selecting203Paired with en de nl da sv fi fr it pt eles 1.78 1.56 1.62 1.61 1.51 1.58 1.65 1.51 1.60 5.68en - 1.73 1.82 1.78 1.67 1.74 1.82 1.73 1.78 1.06Table 1: Size of the bilingual parallel corpora in millions of sentence pairsthe pivot phrases that will lead to adequate para-phrases.
In our approach a sense tag consists in aphrase in a foreign language, that is, a valid trans-lation of the input phrase in a language of interest,here referred to as target language.
Treating thetarget language vocabulary as a sense repository isa good strategy from both theoretical and practi-cal perspectives: it has been shown that monolin-gual sense distinctions can be effectively capturedby translations into second languages, especiallyas language family distance increases (Resnik andYarowsky, 1999; Specia et al 2006).
These trans-lations can be easily captured given the avail-ability of bilingual parallel data and robust au-tomatic word-alignment techniques (Carpuat andWu, 2007; Chan et al 2007).Figure 1 illustrates the proposed model to pro-duce sense tagged paraphrases.
We start the pro-cess at e1 and we need to make sure that the pivotphrases f ?
F align back to the input language,producing the paraphrase e2, and to the target lan-guage, producing the sense tag q.
To avoid com-puting the distribution p(e2, q|f) ?
which wouldrequire a trilingual parallel corpus ?
we assumethat e2 and q are conditionally independent on f :p(e2, q|f)e2?
?q|f= p(e2|f)p(q|f)In other words, we assume that pivot phrases gen-erate paraphrases and sense tags independently.Equation 2 shows how paraphrase probabilities arecomputed by marginalising out the pivot phrasesunder this assumption.GFED@ABCe1 //GFED@ABCf// GFED@ABCe2?>=<89:;qFigure 1: Pivot phrases must align back to targetphrases (sense annotation).p(e2|e1, q) =1z?f?Fp(e2|f)p(q|f)p(f |e1) (2)In order to constrain the extraction of para-phrases such that it complies with a sense repos-itory, in addition to bilingual parallel corpora be-tween the input language and the pivot languages,our model requires bilingual parallel corpora be-tween the pivot languages and the language that isused for sense annotation.Callison-Burch (2007) discusses factors affect-ing paraphrase quality, one of which is wordsenses.
Paraphrasing through pivoting essentiallyrelies on the hypothesis that different pivot phrasescan be used to identify synonymy, rather than pol-ysemy (an assumption made in the WSD liter-ature).
Callison-Burch (2007) also proposes anextraction procedure that may be conditioned onspecific contexts of the input phrase (Bannardand Callison-Burch, 2005), where the context isa given pivot phrase.2 However, that model is un-able to pivot through multiple languages.
As weshow in Section 5, this makes the model extremelysensitive to ambiguities of the one phrase used asboth sense tag and pivot.The model we propose attempts to performsense-disambiguated paraphrase extraction, thatis, paraphrases are discovered in the context oftranslation candidates of the input phrases.
In ad-dition, it allows the use of multiple pivot languagesin the process, capitalising on both the WSDand the paraphrase assumption.
While the targetphrases discriminate different senses of the inputphrases, the pivot phrases coming from multiplelanguages bring extra evidence to jointly capturethe ambiguities introduced by the target phrasesthemselves.To illustrate the impact of this contribution, con-sider the polysemous Spanish word forma, andsome of its translations into English extractedfrom our corpus (Section 4): kind, way, meansand form.
The English words distinguish threepossible senses of forma: (a) means/way of do-ing/achieving something, (b) shape, and (c) typeor group sharing common traits.
The model pre-sented in (Bannard and Callison-Burch, 2005)cannot discriminate these senses.
It mixes validsenses of forma and (correctly) proposes the para-phrases manera and modo for sense (a), and tipo2A paraphrase is scored in the context of a given pivotphrase f : p(e2|e1, f) = p(e2|f)p(f |e1).204for sense (c).
However, paraphrases for sense (b)are over penalised and account for very little of theprobability mass of the candidate paraphrases offorma.
Their extension which conditions extrac-tion on a given pivot phrase is highly sensitive tothe ambiguities of the phrase used as sense anno-tation.
Table 5 shows how this model (CB-wsd inthe Table) makes mistakes for most senses of theinput due to the ambiguities of the English contextkind, way, means and form.
Our approach (multiin the Table) on the other hand successfully sep-arates paraphrases according to the sense annota-tion provided.4 Experimental settings4.1 ResourcesThe source of bilingual data used in the experi-ments is the Europarl collection (Koehn, 2005).We paraphrase Spanish (es) phrases using theircorresponding English (en) phrases as sense tagsand nine European languages as pivots: Ger-man (de), Dutch (nl), Danish (da), Swedish (sv),Finnish (fi), French (fr), Italian (it), Portuguese(pt) and Greek (el).
The tools provided alongwith the corpus were used to extract the sentencealigned parallel data as shown in Table 1.The sentence aligned parallel data is first word-aligned using GIZA++ in both source-target andtarget-source directions, followed by the applica-tion of traditional symmetrisation heuristics (Ochand Ney, 2003).
These aligned corpora are usedfor paraphrase extraction, except for a subset ofthem used in the creation of a test set (Section 4.2).4.2 Test set creationSince we are interested in showing the abilityof our approach to find adequate paraphrases inthe presence of a foreign phrase (the sense tag),it is important that our test set contains polyse-mous phrases.
Like in (Bannard and Callison-Burch, 2005), we use the Spanish WordNet3 tobias our selection of phrases to paraphrase to con-tain ambiguous cases.
However, rather than bi-asing selection towards having more multi-wordexpressions, we chose to have more polysemouscases.
From the Spanish WordNet, we selected 50phrases (with at least one content word) to be para-phrased such that 80% of the samples (40 phrases)had at least 2 senses (with a given part-of-speech3http://nlp.lsi.upc.edu/freeling/Unambiguous Ambiguousconcreto,pol?
?tica, fon-dos, regular,haber, amorproprio, sangrefr?
?a, dar a luz,dar con, tomarel peloderecho, comercial, real, particular, le-gal, justo, comu?n, cerca, esencial, es-pecial, fuerte, puesto, oficial, figura,informe, parte, cuenta, forma, claro,clave, tiempo, seguro, respuesta, traba-jar, responder, garantizar, volver, au-mentar, incluir, tratar, ofrecer, estable-cer, pasar, dejar, realizar, punto de vista,llevar a cabo, dar vueltas, tener que,acabar conFigure 2: Words and phrases selected to be para-phrased.
Ambiguity is determined on the basis ofthe number of synsets in the Spanish WordNet.
Wenote that this information was only used to bias theselection of the phrases, i.e., WordNet is not usedin the proposed approach.La idea de conceder a la Unio?n Europea su propia compe-tencia fiscal - la palabra clave es el ?impuesto por Europa?- esta?
siendo debatida.The idea of granting the EU its own tax competence - thekeyword is the ?Europe tax?
- is being discussed.Figure 3: Example of context selected for thephrase clave.tag to avoid selecting simpler, categorial ambigui-ties).
Figure 2 lists the selected words and phrasesin their base forms.The bilingual corpus was queried for sentencescontaining at least one of the 50 phrases listed inFigure 2, or any of their morphological variants.The resulting sentences were then grouped on thebasis of whether or not they shared the same En-glish translation.
To find the English phrase (i.e.,our sense tag) which constrains the sense of theSpanish phrase, we followed the heuristics used inphrase-based SMT to extract the minimal phrasepair that includes the Spanish phrase and is con-sistent with the word-alignment4 (Koehn et al2003).
We discarded groups containing fewer thanfive sentence pairs and randomly sampled 2-6 con-texts per Spanish phrase.
The resulting test set ismade of 258 Spanish phrases in context such asthe one exemplified in Figure 3.4.3 ParaphrasingNine pivot languages were used to constrain para-phrase extraction following the approach pre-sented in Section 3.
The conditional probabil-ity distributions over phrase pairs in Equation 2are estimated using relative frequencies.
For eachSpanish phrase in the test set, we retrieve their4Note that we did not use gold-standard word-alignments.205paraphrase candidates grouped by sense (Englishtranslation) and rank them based on the evidencecollected from all bilingual corpora.
Evidencefrom different pivot languages is combined usingtheir average.
English itself was not used as a pivotlanguage.
It was used only to provide sense tags.The rationale behind this choice is that if the lan-guage used to provide sense tags is also used aspivot language, there is no obvious way of esti-mating p(q|f) in Equation 2.
Note that in this casethis probability would represent the likelihood ofthe English phrase aligning to itself.Similar to (Bannard and Callison-Burch, 2005),we weight our paraphrase probabilities using anLM to adjust it to the context of the input sentence.We use a 5-gram LM trained on the Spanish part ofEuroparl with the SRILM toolkit (Stolcke, 2002).Paraphrases are re-ranked in context by multiply-ing the paraphrase probability and the LM score ofthe sentence.5In order to assess the performance of our model,we compare it to two variants of the models pro-posed by Bannard and Callison-Burch (2005).multi: the paraphrasing model with multilingualconstraints introduced in this paper.CCB: the model in (Bannard and Callison-Burch, 2005) which does not explicitly per-form any sense disambiguation.CCB-wsd: an extended model in (Bannard andCallison-Burch, 2005) using English phrasesas sense tags for pivoting.Using each of these three models, we para-phrased the 258 samples in our test set, retrievingthe 3-best paraphrases in context for each model.CCB is used with 10 pivot languages (English isincluded as a pivot) to generate paraphrase candi-dates.
Note that CCB relies solely on the LM com-ponent to fit the paraphrase candidate to the con-text.
On the other hand, CCB-wsd and multi bothhave access to sense annotation, but while multiis able to benefit from multiple pivot languages,CCB-wsd can only pivot through the one Englishphrase provided as sense annotation.5Given the localised effect of the phrase replacementwithin a given context in terms of n-gram language mod-elling, a neighbourhood of n-1 words on each side of theselected phrase is sufficient to re-rank paraphrase candidates:p(w?4 .
.
.
w?1e2w+1 .
.
.
w+4) for our 5-gram LM.4.4 EvaluationTo assess whether the proposed model effectivelydisambiguates senses of candidate paraphrases,we perform experiments using similar settingsto those in (Bannard and Callison-Burch, 2005).Paraphrases are evaluated in context (a sentence)using binary human judgements in terms of thefollowing components:Meaning (M): whether or not the candidate con-veys the meaning of the original phrase; andGrammar (G): whether or not the candidate pre-serves the fluency of the sentence.These two components are assessed separately anda paraphrase candidate is considered to be cor-rect only when it is judged to be both meaningpreserving and grammatical.
Our evaluators werepresented with one pair of sentences at a time, theoriginal one and its paraphrased version.
For ev-ery test sample we selected the 3-best paraphrasesof each method and distributed them amongst theevaluators.
We considered two evaluation scenar-ios:Gold-standard translations: the English trans-lation as found in Europarl was taken assense tag, using automatic word-alignmentsto identify the English phrase that constrainsthe sense of the Spanish phrase.SMT translations: a phrase-based SMT systembuilt using the Moses toolkit (Koehn et al2007) and the whole Spanish-English dataset(except the sentences in the test set) wasused to translated the Spanish sentences.
In-stead of gold-standard translations as a quasi-perfect sense annotation (quasi because theword-alignment is still automatic and thusprone to errors), the phrase-based SMT sys-tem plays the role of a sense annotation mod-ule predicting the ?sense?
tags.Note that models may not be able to producea paraphrase for certain input phrases, e.g.
whenthe input phrase is not found in the bilingual cor-pora.
Therefore, we assess precision (P) and re-call (R) as the number of paraphrases in contextthat are judged correct out of the number of casesfor which a candidate paraphrase was proposed,and out of the total number of test samples, re-spectively.
To summarise the results, accuracy isexpressed in terms of F1.206Method Top M G CorrectF1 F1 P R F1CCB 1 32 28 25 25 25CCB-wsd 1 61 38 34 28 30multi 1 62 55 59 42 49CCB 2 41 37 33 33 33CCB-wsd 2 68 44 40 33 36multi 2 71 64 66 47 55CCB 3 46 42 37 37 37CCB-wsd 3 71 47 45 36 40multi 3 74 67 71 50 59Table 2: Performance in retrieving paraphrases incontext using gold-standard translations for sensetags and a 5-gram LM component.In the following section we present results onwhether the best candidate (Top-1) or at least oneof the two (Top-2) or three (Top-3) best candidatessatisfies the criterion under consideration (mean-ing/grammar).5 ResultsThe evaluation was performed by seven nativespeakers of Spanish who judged a total of 5, 110sentences containing one paraphrased input phraseeach.
We used 40 overlapping judgements acrossannotators to measure inter-annotator agreement.The average inter-annotator agreement in termsof Cohen?s Kappa (Cohen, 1960) is 0.54 ?
0.15for meaning judgements, 0.63 ?
0.16 for gram-mar judgements and 0.62 ?
0.20 for correctnessjudgements.
These figures are similar or superiorto those reported in (Bannard and Callison-Burch,2005; Callison-Burch, 2008), which we considerparticularly encouraging as in our case we haveseven instead of only two annotators.
In Tables2, 3 and 4 we report the performance of the threemodels in terms of precision, recall and F1, withp-values < 0.01 based on the t-test for statisticalsignificance.5.1 Paraphrasing from human translationsWe first assess the paraphrasing models us-ing gold-standard translations, that is, the En-glish phrases were selected via automatic word-alignments between the input text and its corre-sponding human translation from Europarl.
Ta-ble 2 shows the performance in terms of F1 forour three criteria: meaning preservation, grammat-icality, and correctness.
Our method (multi) out-performs the best performing alternative (CCB-wsd) by a large margin.
It is 19% more effectiveat selecting the 1-best candidate in terms of cor-Method M G CorrectCCB 33 23 22CCB-wsd 19 9 8multi 64 43 37Table 3: Performance (F1) in correctly retrievingthe best paraphrase in context using gold-standardtranslations without the 5-gram LM component.rectness.
A consistent gain is also observed whenmore guesses are allowed (top 2?3), showing thatour model is better at ranking the top candidatesas well.
CCB-wsd and multi are close in terms ofparaphrases that are meaning preserving, howevertheir differences become more obvious as moreguesses are allowed, again showing that multi isbetter at ranking more adequate paraphrases first.Moreover, multi consistently chooses more gram-matical paraphrases.Table 2 also shows that our model consistentlyimproves both the precision and recall of the pre-dictions.
Recall improves by 14% w.r.t.
CCB-wsdbecause multi is able to find more paraphrases,which we believe are only reachable through theadditional pivots.
For example, in our data theparaphrase forma ?
medio in the sense of way(see Table 5) is only found through the Dutchpivot middel, which is not accessible to CCB-wsd.
Recall is much lower in CCB because ofthe model?s strong bias towards the most frequentsenses: other senses receive very little of the prob-ability mass and thus rarely feature amongst thetop ranked paraphrases.
Our multilingual disam-biguation model also shows a 25% increase in pre-cision, which must be due to the stronger contri-bution of the sense discrimination over the LMcomponent in getting the senses of the paraphrasesright.To show the impact of the LM re-ranking com-ponent, in Table 3 we remove this component fromall models, such that the ranking of paraphrases isdone purely based on the paraphrase probabilities.All models are harmed by the absence of the LMcomponent, but to different extents and for differ-ent reasons.
CCB typically ranks at the top para-phrases that convey the most frequent sense andthe LM is the only component with informationabout the input context.
CCB-wsd is impacted themost: typically invalid paraphrases are producedfrom unrelated senses of the foreign phrase usedas sense tag, they do not represent any valid senseof the input but still get ranked at the top.
For207this model, the LM component is crucial to prunesuch unrelated paraphrases.
Back to Table 2, thesuperior performance of CCB-wsd over CCB inthe presence of the LM component suggest thatCCB-wsd assigns less negligible probabilities tothe paraphrases that convey a valid sense of theinput.
Finally, multi?s performance is only trulyharmed in terms of grammaticality: sense discrim-ination is the main responsible for selecting theappropriate sense, while the LM component is re-sponsible for selecting the candidate that makesthe sentence more fluent.
Further investigationshowed that in some cases the most meaning pre-serving option was down-weighted due to low flu-ency, and a less adequate option was chosen, ex-plaining the slight improvement under the mean-ing preservation criterion when no LM re-rankingis performed.Table 5 lists the 5-best paraphrases of the Span-ish phrase forma in its different senses.
The para-phrases are ranked by CCB-wsd and multi out ofcontext, that is, without LM re-ranking.
Note that,because the sense tags are themselves ambiguousin English, most of the top-ranked paraphrasesfrom CCB-wsd are inadequate, that is, they do notconvey any valid sense of forma.It is also interesting to observe the impact of thedifferent pivot languages on the performance ofour proposed approach.
Figure 4 shows CCB-wsdand multi, both using LM re-ranking.
For multiwe can see the impact of the pivot languages indi-vidually and in groups.6 Except for Finnish whenused on its own as pivot all other setups are supe-rior to CCB-wsd.
We can also see that putting to-gether languages of different families has a strongpositive impact, probably due to the fact that am-biguities are realised differently in languages thatare farther from each other, emphasising the po-tential of sense discrimination by pivoting throughmultiple languages.5.2 Paraphrasing from machine translationsFinally, we assessed the paraphrasing models us-ing machine translations instead of gold-standardtranslations from Europarl.
In order to have anidea of the quality of the SMT model beforehand,we evaluated the machine translations in terms ofBLEU scores (Papineni et al 2002) using a singlereference from Europarl.
Our phrase-based SMT6For a larger version of this figure, we refer the readerto: http://pers-www.wlv.ac.uk/?in1676/publications/2013/conll2013pivots.pdfMethod Top M G CorrectF1 F1 P R F1CCB-wsd 1 71 39 34 32 33multi 1 69 55 50 45 48CCB-wsd 2 79 46 40 38 39multi 2 82 69 63 57 60CCB-wsd 3 83 50 44 41 42multi 3 85 74 69 62 65Table 4: Performance in retrieving paraphrases incontext using machine translations for sense tagsand a 5-gram LM component.0.20.250.30.350.40.450.5en fi el da de fr nl pt sv it sv,fi el,fi sv,elit,sv it,fi it,el sv,el,fiit,sv,elit,sv,fiit,el,fiit,sv,el,fisv sv,nlsv,nl,desv,nl,de,dait it,pt it,pt,frR,sv R,sv,nlR,sv,nl,deR,D R,D,GR,D,G,FCorrectnessPivot LanguagesCCB-wsd1 pivot2 families3 families4 familiesGermanic (1-4)Romance (1-3)Romance-All (4-9)Figure 4: Impact of pivot languages on correct-ness.
Language codes follow the convention pre-sented in Section 4.1.
Additionally R stands forRomance languages, D for Germanic languages,G for Greek and F for Finnish.model achieved 48.9 BLEU, which can be con-sidered a high score for Europarl data (in-domainevaluation).
Table 4 is analogous to Table 2, butwith paraphrases extracted from machine trans-lated sentences as opposed to human translations.We observe that multi still outperforms CCB-wsd by a large margin.
On the one hand there is adrop in precision of about 9% for correctness withmulti.
On the other hand there is an improvementin recall: multi improves from 3% (top-1 guess)to 12% (top-3 guesses).
Manual inspection re-vealed that the tags predicted by the SMT modelare more frequent translation options, reducing thechance of finding rare target phrases as sense an-notation, for which significant statistics cannot becomputed.
However, with respect to correctness,the differences between this setting and that withgold-standard translations are not statistically sig-nificant.208multi: English as sense annotation and nine other pivot languagesforma ?
way forma ?
form forma ?
means forma ?
kindforma 0.34 forma 0.64 medio 0.64 tipo 0.37manera 0.24 tipo 0.10 trave?s 0.23 forma 0.23modo 0.23 forma de 0.05 instrumento 0.13 especie 0.06forma de 0.02 formas 0.03 especie de 0.03medio 0.02 modo 0.02 tipo de 0.03CCB-wsd: English as sense annotation and sole evidence for pivotingforma ?
way forma ?
form forma ?
means forma ?
kind?way 0.08 ?formulario 0.18 ?significa contar 0.07 ?amables 0.16?v?
?a por 0.08 de sus formas 0.10 medios que tiene 0.07 ?kind 0.12?camino que hay 0.07 ?formulario de 0.07 ?significa 0.06 especie 0.09?camino que hay que 0.07 modalidad 0.06 ?significa contar con 0.06 ?amable 0.08?v?
?a por la 0.07 aspecto formal 0.05 ?anterior significa 0.06 tipo 0.07Table 5: Top paraphrases of forma annotated by the English words way, form, means and kind.
Starredphrases denote inadequate candidates.5.3 Potential applicationsIn what follows we discuss two applications whichwe believe could directly benefit from the para-phrase extraction approach proposed in this paper.MT evaluation metrics such as METEOR(Denkowski and Lavie, 2010) and TESLA (Liuet al 2010) already use paraphrases of n-gramsin the machine translated sentence in an attemptto match more of the reference translation?s n-grams.
TESLA, in particular, uses paraphrasesconstrained by a single pivot language as sense tagas originally proposed in (Bannard and Callison-Burch, 2005).
Metrics like METEOR, which useparaphrases simply as a repository with extra op-tions for the n-gram matching, could be extendedto use the word-alignment between the source sen-tence and the translation to constrain the translatedphrases while paraphrasing them with multilingualconstraints.
In this case the model would attemptto paraphrase the MT, which is not necessarilyfluent, therefore potentially compromising its LMcomponent.
However, even after completely disre-garding the LM re-ranking (see context-insensitivemodel multi in Table 3), we may be able to im-prove n-gram matching by paraphrasing.Handling out-of-vocabulary words in SMT byexpanding the bilingual phrase-tables (Callison-Burch et al 2006) is a direct application of thesense constrained paraphrases.
We can add trans-lations for a given unknown phrase f1, whoseparaphrase f2 is present in the phrase-table andis aligned to the target phrase e (sense tag).
Webasically expand the phrase table to translate theout-of-vocabulary word f1 using the knowledgeassociated to its paraphrase f2 in the context of theknown translation e: (f2, e) ?
(f1, e).
The mul-tilingual constraints offer more control over ambi-guities, therefore potentially leading to more accu-rate phrase pairs added to the phrase-table.6 Conclusions and future workWe have proposed a new formulation of the prob-lem of generating ?sense?
tagged paraphrases forwords and short phrases using bilingual corporaand multiple pivot languages to jointly disam-biguate the input phrase and the sense tag.
Sensetags are phrases in a foreign language of interest,for instance the target language of a phrase-basedSMT system.The approach was evaluated against the state ofthe art method for paraphrase extraction.
Signif-icant improvements were found in particular withrespect to two aspects: i) the proposed model hashigher recall, since it has access to paraphrasesthat would receive a negligible probability massand therefore would never be selected in previ-ous formulations, and ii) the proposed model hashigher precision, since it is able to filter out or rankdown paraphrases with incorrect senses.In future work we plan to further evaluate theapproach in the two scenarios discussed in Sec-tion 5.3: i) to expand the phrase table of SMT sys-tems to address issues such as out-of-vocabularywords and phrases; and ii) to evaluate and opti-mise parameters of SMT systems using metricsthat can accommodate sense disambiguated para-phrases.
We also plan to integrate syntactic con-straints, as proposed in (Callison-Burch, 2008), toour model to investigate the complementarities be-tween these two ways of constraining paraphras-ing.209ReferencesColin Bannard and Chris Callison-Burch.
2005.
Para-phrasing with bilingual parallel corpora.
In Pro-ceedings of the 43rd Annual Meeting on Associationfor Computational Linguistics, pages 597?604, AnnArbor, Michigan.Chris Callison-Burch, Philipp Koehn, and Miles Os-borne.
2006.
Improved statistical machine transla-tion using paraphrases.
In Proceedings of the mainconference on Human Language Technology Con-ference of the North American Chapter of the Asso-ciation of Computational Linguistics, pages 17?24,New York, New York.Chris Callison-Burch.
2007.
Paraphrasing and Trans-lation.
Ph.D. thesis, University of Edinburgh, Edin-burgh, Scotland.Chris Callison-Burch.
2008.
Syntactic constraints onparaphrases extracted from parallel corpora.
In Pro-ceedings of the Conference on Empirical Methods inNatural Language Processing, EMNLP ?08, pages196?205, Honolulu, Hawaii.Marine Carpuat and Dekai Wu.
2007.
Improving sta-tistical machine translation using word sense dis-ambiguation.
In The 2007 Joint Conference onEmpirical Methods in Natural Language Process-ing and Computational Natural Language Learning,EMNLP-CoNLL ?07, pages 61?72, Prague, CzechRepublic.Yee Seng Chan, Hwee Tou Ng, and David Chiang.2007.
Word sense disambiguation improves statisti-cal machine translation.
In Proceedings of the 45thAnnual Meeting of the Association of ComputationalLinguistics, pages 33?40, Prague, Czech Republic.Jacob Cohen.
1960.
A Coefficient of Agreement forNominal Scales.
Educational and PsychologicalMeasurement, 20(1):37?46, April.Trevor Cohn and Mirella Lapata.
2007.
Machinetranslation by triangulation: Making effective use ofmulti-parallel corpora.
In Proceedings of the 45thAnnual Meeting of the Association for Computa-tional Linguistics, Prague, Czech Republic.Michael Denkowski and Alon Lavie.
2010.METEOR-NEXT and the METEOR Paraphrase Ta-bles: Improved Evaluation Support For Five TargetLanguages.
In Proceedings of the ACL 2010 JointWorkshop on Statistical Machine Translation andMetrics MATR.Philipp Koehn, Franz Josef Och, and Daniel Marcu.2003.
Statistical phrase-based translation.
InProceedings of the 2003 Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics on Human Language Technology- Volume 1, NAACL ?03, pages 48?54, Edmonton,Canada.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran,Richard Zens, Chris Dyer, Ondr?ej Bojar, AlexandraConstantin, and Evan Herbst.
2007.
Moses: opensource toolkit for statistical machine translation.
InProceedings of the 45th Annual Meeting of the As-sociation for Computational Linguistics: Demo andPoster Sessions, pages 177?180, Prague, Czech Re-public.Philipp Koehn.
2005.
Europarl: A Parallel Corpus forStatistical Machine Translation.
In The Proceedingsof the Tenth Machine Translation Summit, pages 79?86, Phuket, Thailand.
AAMT, AAMT.Chang Liu, Daniel Dahlmeier, and Hwee Tou Ng.2010.
Tesla: Translation evaluation of sentenceswith linear-programming-based analysis.
In Pro-ceedings of the Joint Fifth Workshop on StatisticalMachine Translation and MetricsMATR, pages 354?359, Uppsala, Sweden.Nitin Madnani and Bonnie J. Dorr.
2010.
Gener-ating phrasal and sentential paraphrases: A surveyof data-driven methods.
Computational Linguistics,36(3):341?387.Nitin Madnani, Necip Fazil Ayan, Philip Resnik, andBonnie J. Dorr.
2007.
Using paraphrases for param-eter tuning in statistical machine translation.
In Pro-ceedings of the Second Workshop on Statistical Ma-chine Translation, pages 120?127, Prague, CzechRepublic.Yuval Marton, Chris Callison-Burch, and PhilipResnik.
2009.
Improved statistical machine trans-lation using monolingually-derived paraphrases.
InProceedings of the 2009 Conference on EmpiricalMethods in Natural Language Processing, pages381?390, Suntec, Singapore.Shachar Mirkin, Lucia Specia, Nicola Cancedda, IdoDagan, Marc Dymetman, and Idan Szpektor.
2009.Source-language entailment modeling for translat-ing unknown terms.
In Proceedings of the JointConference of the 47th Annual Meeting of the ACLand the 4th International Joint Conference on Natu-ral Language Processing of the AFNLP, pages 791?799, Suntec, Singapore.Franz Josef Och and Hermann Ney.
2003.
Asystematic comparison of various statistical align-ment models.
Computational Linguistics, 29:19?51,March.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
Bleu: a method for automatic eval-uation of machine translation.
In Proceedings of the40th Annual Meeting on Association for Computa-tional Linguistics, pages 311?318.Philip Resnik and David Yarowsky.
1999.
Distinguish-ing systems and distinguishing senses: new evalua-tion methods for word sense disambiguation.
Nat.Lang.
Eng., 5(2):113?133.210Stefan Riezler, Er Vasserman, Ioannis Tsochantaridis,Vibhu Mittal, and Yi Liu.
2007.
Statistical machinetranslation for query expansion in answer retrieval.In Proceedings of the 45th Annual Meeting of the As-sociation for Computational Linguistics, pages 464?471, Prague, Czech Republic.Lucia Specia, Mark Stevenson, Maria das Grac?asVolpe Nunes, and Gabriela C.B.
Ribeiro.
2006.Multilingual versus monolingual WSD.
In Pro-ceedings of the EACL Workshop ?Making Sense ofSense: Bringing Psycholinguistics and Computa-tional Linguistics Together?, pages 33?40, Trento,Italy.Andreas Stolcke.
2002.
SRILM ?
an extensible lan-guage modeling toolkit.
In Proceedings of the In-ternational Conference on Spoken Language, vol-ume 2, pages 901?904, Denver, CO.211
