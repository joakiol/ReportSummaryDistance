Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 12?23,Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational LinguisticsExploiting Discourse Analysis for Article-Wide Temporal ClassificationJun-Ping Ng1, Min-Yen Kan1,2, Ziheng Lin3, Wei Feng4, Bin Chen5, Jian Su5, Chew-Lim Tan11School of Computing, National University of Singapore, Singapore2Interactive and Digital Media Institute, National University of Singapore, Singapore3Research & Innovation, SAP Asia Pte Ltd, Singapore4Department of Computer Science, University of Toronto, Canada5Institute for Infocomm Research, Singaporejunping@comp.nus.edu.sgAbstractIn this paper we classify the temporal relationsbetween pairs of events on an article-wide ba-sis.
This is in contrast to much of the exist-ing literature which focuses on just event pairswhich are found within the same or adjacentsentences.
To achieve this, we leverage on dis-course analysis as we believe that it providesmore useful semantic information than typicallexico-syntactic features.
We propose the useof several discourse analysis frameworks, in-cluding 1) Rhetorical Structure Theory (RST),2) PDTB-styled discourse relations, and 3)topical text segmentation.
We explain howfeatures derived from these frameworks can beeffectively used with support vector machines(SVM) paired with convolution kernels.
Ex-periments show that our proposal is effectivein improving on the state-of-the-art signifi-cantly by as much as 16% in terms of F1, evenif we only adopt less-than-perfect automaticdiscourse analyzers and parsers.
Making useof more accurate discourse analysis can fur-ther boost gains to 35%.1 IntroductionA good amount of research had been invested in un-derstanding temporal relationships within text.
Par-ticular areas of interest include determining the re-lationship between an event mention and a time ex-pression (timex), as well as determining the relation-ship between two event mentions.
The latter, whichwe refer to as event-event (E-E) temporal classifica-tion is the focus of this work.For a given event pair which consists of twoevents e1 and e2 found anywhere within an article,we want to be able to determine if e1 happens be-fore e2 (BEFORE), after e2 (AFTER), or within thesame time span as e2 (OVERLAP).Consider this sentence1:At least 19 people were killed and 114 people werewounded in Tuesday?s southern Philippines airport blast,officials said, but reports said the death toll could climbto 30.
(1)Three event mentions found within the sentence arebolded.
We say that there is an OVERLAP rela-tionship between the ?killed ?
wounded?
event pairas these two events happened together after the air-port blast.
Similarly there is a BEFORE relationshipbetween both the ?killed ?
said?, and ?wounded ?said?
event pairs, as the death and injuries happenedbefore reports from the officials.Being able to infer these temporal relationshipsallows us to build up a better understanding of thetext in question, and can aid several natural lan-guage understanding tasks such as information ex-traction and text summarization.
For example, wecan build up a temporal characterization of an articleby constructing a temporal graph denoting the rela-tionships between all events within an article (Ver-hagen et al 2009).
This can then be used to helpconstruct an event timeline which layouts sequen-tially event mentions in the order they take place (Doet al 2012).
The temporal graph can also be usedin text summarization, where temporal order can beused to improve sentence ordering and thereby theeventual generated summary (Barzilay et al 2002).Given the importance and value of temporal re-lations, the community has organized shared tasks1From article AFP ENG 20030304.0250 of the ACE 2005corpus (ACE, 2005).12to spur research efforts in this area, including theTempEval-1, -2 and -3 evaluation workshops (Ver-hagen et al 2009; Verhagen et al 2010; Uzzamanet al 2012).
Most related work in this area havefocused primarily on the task defintitions of theseevaluation workshops.
In the task definitions, E-E temporal classification involves determining therelationship between events found within the samesentence, or in adjacent sentences.
For brevity wewill refer to this loosely as intra-sentence E-E tem-poral classification in the rest of this paper.This definition however is limiting and insuffi-cient.
It was adopted as a trade-off between com-pleteness, and the need to simplify the evaluationprocess (Verhagen et al 2009).
In particular, onedeficiency is that it does not allow us to construct thecomplete temporal graph we seek.
As illustrated inFigure 1, being able to perform only intra-sentenceE-E temporal classification may result in a forest ofdisconnected temporal graphs.
A sentence s3 sepa-rates events C and D, as such an intra-sentence E-Eclassification system will not be able to determinethe temporal relationship between them.
While wecan determine the relationship between A and C inthe figure with the use of temporal transitivity rules(Setzer et al 2003; Verhagen, 2005), we cannot re-liably determine the relationship between say A andD.AB CD Es1s2s3s4Figure 1: A disconnected temporal graph of events withinan article.
Horizontal lines depict sentences s1 to s4, andthe circles identify events of interest.In this work, we seek to overcome this limitation,and study what can enable effective article-wide E-Etemporal classification.
That is, we want to be ableto determine the temporal relationship between twoevents located anywhere within an article.The main contribution of our work is goingbeyond the surface lexical and syntactic featurescommonly adopted by existing state-of-the-art ap-proaches.
We suggest making use of semanticallymotivated features derived from discourse analysisinstead, and show that these discourse features aresuperior.While we are just focusing on E-E temporalclassification, our work can complement other ap-proaches such as the joint inference approach pro-posed by Do et al(2012) and Yoshikawa et al(2009) which builds on top of event-timex (E-T) andE-E temporal classification systems.
We believe thatimprovements to the underlying E-T and E-E classi-fication systems will help with global inference.2 Related WorkMany researchers have worked on the E-E temporalclassification problem, especially as part of the Tem-pEval series of evaluation workshops.
Bethard andMartin (2007) presented one of the earliest super-vised machine learning systems, making use of sup-port vector machines (SVM) with a variety of lexicaland syntactic features.
Kolya et al(2010) describeda conditional random field (CRF) based learner mak-ing use of similar features.
Other researchers includ-ing Uzzaman and Allen (2010) and Ha et al(2010)made use of Markov Logic Networks (MLN).
Byleveraging on the transitivity properties of temporalrelationships (Setzer et al 2003), they found thatMLNs are useful in inferring new temporal relation-ships from known ones.Recognizing that the temporal relationships be-tween event pairs and time expressions are related,Yoshikawa et al(2009) proposed the use of a jointinference model and showed that improvements inperformance are obtained.
However this gain is at-tributed to the joint inference model they had devel-oped, making use of similar surface features.To the best of our knowledge, the only pieceof work to have gone beyond sentence boundariesand tackle the problem of article-wide E-E temporalclassification is by Do et al(2012).
Making use ofinteger linear programming (ILP), they built a jointinference model which is capable of classifying tem-poral relationships between any event pair withina given document.
They also showed that eventco-reference information can be useful in determin-ing these temporal relationships.
However they didnot make use of features directed specifically at de-termining the temporal relationships of event pairs13across different sentences.
Other than event co-reference information, they adopted the same mixof lexico-syntactic features.Underlying these disparate data-driven methodsfor similar temporal processing tasks, the reviewedworks all adopted a similar set of surface fea-tures including vocabulary features, part-of-speechtags, constituent grammar parses, governing gram-mar nodes and verb tenses, among others.
We ar-gue that these features are not sufficiently discrimi-native of temporal relationships because they do notexplain how sentences are combined together, andthus are unable to properly differentiate between thedifferent temporal classifications.
Supporting ourargument is the work of Smith (2010), where sheargued that syntax cannot fully account for the un-derlying semantics beneath surface text.
D?Souzaand Ng (2013) found out as much, and showed thatadopting richer linguistic features such as lexical re-lations from curated dictionaries (e.g.
Webster andWordNet) as well as discourse relations help tempo-ral classification.
They had shown that the Penn Dis-course TreeBank (PDTB) style (Prasad et al 2008)discourse relations are useful.
We expand on theirstudy to assess the utility of adopting additional dis-course frameworks as alternative and complemen-tary views.3 Making Use of DiscourseTo highlight the deficiencies of surface features, wequote here an example from Lascarides and Asher(1993):[A] Max opened the door.
The room was pitch dark.
[B] Max switched off the light.
The room was pitch dark.
(2)The two lines of text A and B in Example 2 havesimilar syntactic structure.
Given only syntactic fea-tures, we may be drawn to conclude that they sharesimilar temporal relationships.
However in the firstline of text, the events temporally OVERLAP, whilein the second line they do not.
Clearly, syntax aloneis not going to be useful to help us arrive at the cor-rect temporal relations.If existing surface features are insufficient, what issufficient?
Given a E-E pair which crosses sentenceboundaries, how can we determine the temporal re-lationship between them?
We take our cue from thework of Lascarides and Asher (1993).
They sug-gested instead that discourse relations hold the keyto interpreting such temporal relationships.Building on their observations, we believe thatdiscourse analysis is integral to any solution for theproblem of article-wide E-E temporal classification.We thus seek to exploit a series of different discourseanalysis studies, including 1) the Rhetorical Struc-ture Theory (RST) discourse framework, 2) PennDiscourse Treebank (PDTB)-styled discourse rela-tions based on the lexicalized Tree Adjoining Gram-mar for Discourse (D-LTAG), and 3) topical text seg-mentation, and validate their effectiveness for tem-poral classification.RST Discourse Framework.
RST (Mann andThompson, 1988) is a well-studied discourse anal-ysis framework.
In RST, a piece of text is split into asequence of non-overlapping text fragments knownas elementary discourse units (EDUs).
NeighboringEDUs are related to each other by a typed relation.Most RST relations are hypotactic, where one of thetwo EDUs participating in the relationship is demar-cated as a nucleus, and the other a satellite.
The nu-cleus holds more importance, from the point of viewof the writer, while the satellite?s purpose is to pro-vide more information to help with the understand-ing of the nucleus.
Some RST relations are howeverparatactic, where the two participating EDUs areboth marked as nuclei.
A discourse tree can be com-posed by viewing each EDU as a leaf node.
Nodesin the discourse tree are linked to one another via thediscourse relations that hold between the EDUs.RST discourse relations capture the semantic re-lation between two EDUs, and these often offer aclue to the temporal relationship between events inthe two EDUs too.
As an example, let us refer onceagain to Example 2.
Recall that in the second line oftext ?switched off?
happens BEFORE ?dark?.
TheRST discourse structure for the second line of textis shown on the left of Figure 2.
We see that thetwo sentences are related via a ?Result?
discourserelation.
This fits our intuition that when there iscausation, there should be a BEFORE/AFTER rela-tionship.
The RST discourse relation in this case isvery useful in helping us determine the relationshipbetween the two events.PDTB-styled Discourse Relations.
Another widelyadopted discourse relation annotation is the PDTBframework (Prasad et al 2008).
Unlike the RST14Max switched off the light.
The room was pitch dark.RESULTThe room was pitch dark.CONTINGENCY :: CAUSEarg1 arg2Max switched off the light.Figure 2: RST and PDTB discourse structures for the second line of text in Example 2.
The structure on the left is theRST discourse structure, while the structure on the right is for PDTB.framework, the discourse relations in PDTB build onthe work on D-LTAG by Webber (2004), a lexicon-grounded approach to discourse analysis.
Practi-cally, this means that instead of starting from a pre-identified set of discourse relations, PDTB-styledannotations are more focused on detecting possibleconnectives (can be either explicit or implicit) withinthe text, before identifying the text fragments whichthey connect and how they are related to one another.Applied again to the second line of text we have inExample 2, we get a structure as shown on the rightside of Figure 2.
From the figure we can see thatthe two sentences are related via a ?Cause?
relation-ship.
Similar to what we have explained earlier forthe case of RST, the presence of a causal effect herestrongly hints to us that events in the two sentencesshare a BEFORE/AFTER relationship.At this point we want to note the differences be-tween the use of the RST framework and PDTB-styled discourse relations in the context of our work.The theoretical underpinnings behind these two dis-course analysis are very different, and we believethat they can be complementary to each other.
First,the RST framework breaks up text within an articlelinearly into non-overlapping EDUs.
Relations canonly be defined between neighboring EDUs.
How-ever this constraint is not found in PDTB-styled re-lations, where a text fragment can participate in onediscourse relation, and a subsequence of it partic-ipate in another.
PDTB relations are also not re-stricted only to adjacent text fragments.
In this as-pect, the flexibility of the PDTB relations can com-plement the seemingly more rigid RST framework.Second, with PDTB-styled relations not everysentence needs to be in a relation with another asthe PDTB framework does not aim to build a globaldiscourse tree that covers all sentence pairs.
This isa problem when we need to do an article-wide anal-ysis.
The RST framework does not suffer from thislimitation however as we can build up a discoursetree connecting all the text within a given article.Topical Text Segmentation.
A third complemen-tary type of inter-sentential analysis is topical textsegmentation.
This form of segmentation separatesa piece of text into non-overlapping segments, eachof which can span several sentences.
Each segmentrepresents passages or topics, and provides a coarse-grained study of the linear structure of the text (Sko-rochod?Ko, 1972; Hearst, 1994).
The transition be-tween segments can represent possible topic shiftswhich can provide useful information about tempo-ral relationships.Referring to Example 32, we have delimited thedifferent lines of text into segments with parenthe-ses along with a subscript.
Segment (1) talks aboutthe casualty numbers seen at a medical centre, whileSegment (2) provides background information thatinforms us a bomb explosion had taken place.
Thesegment boundary signals to us a possible temporalshift and can help us to infer that the bombing eventtook place BEFORE the deaths and injuries had oc-curred.
(The Davao Medical Center, a regional government hos-pital, recorded 19 deaths with 50 wounded.
Medicalevacuation workers however said the injured list wasaround 114, spread out at various hospitals.
)1(A powerful bomb tore through a waiting shed at theDavao City international airport at about 5.15 pm (0915GMT) while another explosion hit a bus terminal at thecity.
)2(3)4 MethodologyHaving motivated the use of discourse analysis forour problem, we now proceed to explain how we canmake use of them for temporal classification.
Thedifferent facets of discourse analysis that we are ex-ploring in this work are structural in nature.
RST2From article AFP ENG 20030304.0250 of the ACE 2005corpus.15EDU2 EDU3r2r1EDU1ABFigure 3: A possible RST discourse tree.
The two circlesdenote two events A and B which we are interested in.t1 t2t3t4r1 r2r3BAFigure 4: A possible PDTB-styled discourse annotationwhere the circles represent events we are interested in.and PDTB discourse relations are commonly repre-sented as graphs, and we can also view the outputof text segmentation as a graph with individual textsegments forming vertices, and the transitions be-tween them forming edges.Considering this, we propose the use of supportvector machines (SVM), adopting a convolution ker-nel (Collins and Duffy, 2001) for its kernel function(Vapnik, 1999; Moschitti, 2006).
The use of convo-lution kernels allows us to do away with the exten-sive feature engineering typically required to gener-ate flat vectorized representations of features.
Thisprocess is time consuming and demands specializedknowledge to achieve representations that are dis-criminative, yet are sufficiently generalized.
Con-volution kernels had also previously been shown towork well for the related problem of E-T temporalclassification (Ng and Kan, 2012), where the fea-tures adopted are similarly structural in nature.We now describe our use of the discourse analysisframeworks to generate appropriate representationsfor input to the convolution kernel.RST Discourse Framework.
Recall that the RSTframework provides us with a discourse tree for anentire input article.
In recent years several automaticRST discourse parsers have been made available.
Inour work, we first make use of the parser by Fengand Hirst (2012) to obtain a discourse tree represen-tation of our input.
To represent the meaningful por-tion of the resultant tree, we encode path informationbetween the two sentences of interest.We illustrate this procedure using the examplediscourse tree illustrated in Figure 3.
EDUs includ-ing EDU1 to EDU3 form the vertices while dis-course relations r1 and r2 between the EDUs formthe edges.
For a E-E pair, {A,B}, we can obtain afeature structure by first locating the EDUs withinwhich A and B are found.
A is found inside EDU1and B is found within EDU3.
We trace the short-est path between EDU1 and EDU3, and use thispath as the feature structure for the E-E pair, i.e.
{r1 ?
r2}.PDTB-styled Discourse Relations.
We make use ofthe automatic PDTB discourse parser from Lin et al(2013) to obtain the discourse relations over an inputarticle.
Similar to how we work with the RST dis-course framework, for a given E-E pair, we retrievethe relevant text fragments and use the shortest pathlinking the two events as a feature structure for ourconvolution kernel classifier.An example of a possible PDTB-styled discourseannotation is shown in Figure 4.
The horizontallines represent different sentences in an article.
Theparentheses delimit text fragments, t1 to t4, whichhave been identified as arguments participating indiscourse relations, r1 to r3.
For a given E-E pair{A,B}, we use the trace of the shortest path be-tween them i.e.
{r1 ?
r2} as a feature structure.We take special care to regularize the input (as,unlike EDUs in RST, arguments to different PDTBrelations may overlap, as in r2 and r3).
We modeleach PDTB discourse annotation as a graph and em-ploy Dijkstra?s shortest path algorithm.
The graphresulting from the annotation in Figure 4 is given inFigure 5.
Each text fragment ti maps to a vertexni in the graph.
PDTB relations between text frag-ments form edges between corresponding vertices.As r2 relates t2 to both t3 and t4, two edges linkup n2 to the corresponding vertices n3 and n4 re-spectively.
By doing this, Dijkstra?s algorithm willalways allow us to find the desired shortest path.n1 n2 n3 n4r1r2 r3r2Figure 5: Graph derived from discourse annotation inFigure 4.16Topical Text Segmentation.
Taking as input a com-plete text article, we make use of the state-of-the-arttext segmentation system from Kazantseva and Sz-pakowicz (2011).
The output of the system is a se-ries of non-overlapping, linear text segments, whichwe can number sequentially.In Figure 6 the horizontal lines represent sen-tences.
Parentheses with subscripts mark out thesegment boundaries.
We can see two segments s1and s2 here.
Given a target E-E pair {A,B} (repre-sented as circles inside the figure), we identify thesegment number of the corresponding segment inwhich each of A and B is found.
We build a fea-ture structure with the identified segment numbers,i.e.
{s1 ?
s2} to capture the segmentation.ABs1s2Figure 6: A possible segmentation of three sentences intotwo segments.5 ResultsWe conduct a series of experiments to validate theutility of our proposed features.Data Set.
We make use of the same data set builtby Do et al(2012).
The data set consists of 20newswire articles which originate from the ACE2005 corpus (ACE, 2005).
Initially, the data setconsist of 324 event mentions, and a total of 375annotated E-E pairs.
We perform the same temporalsaturation step as described in Do et al(2012), andobtained a total of 7,994 E-E pairs3.A breakdown of the number of instances by eachtemporal classes is shown in Table 1.
Unlike earlierdata sets such as that for TempEval-2 where morethan half (about 55%) of test instances belong to the3Though we have obtained the data set from the original au-thors, there was a discrepancy in the number of E-E pairs.
Theoriginal paper reported a total of 376 annotated E-E pairs.
Be-sides this, we also repeated the saturation steps iteratively untilno new relationship pairs are generated.
We believe this to bean enhancement as it ensures that all inferred temporal relation-ships are generated.OVERLAP class, OVERLAP instances make up just10% of the data set.This difference is due mainly to the fact that ourdata set consists not only of intra-sentence E-E pairs,but also of article-wide E-E pairs.
Figure 7 showsthe number of instances for each temporal class bro-ken down by the number of sentences (i.e.
sentencegap) that separate the events within each E-E pair.We see that as the sentence gap increases, the pro-portion of OVERLAP instances decreases.
The in-tuitive explanation for this is that when event men-tions are very far apart in an article, it becomes moreunlikely that they happen within the same time span.Class AFTER BEFORE OVERLAP# E-E pairs 3,588 (45%) 3,589 (45%) 815 (10%)Table 1: Number of E-E pairs in data set attributable toeach temporal class.
Percentages shown in parentheses.Figure 7: Breakdown of number of E-E pairs for eachtemporal class based on sentence gap.Experiments.
The work done in Do et al(2012) ishighly related to our experiments, and so we havereported the relevant results for local E-E classifi-cation in Row 1 of Table 2 as a reference.
Whilelargely comparable, note that a direct comparison isnot possible because 1) the number of E-E instanceswe have is slightly different from what was reported,and 2) we do not have access to the exact partitionsthey have created for 5-fold cross-validation.As such, we have implemented a baseline adopt-ing similar surface lexico-syntactic features used inprevious work (Mani et al 2006; Bethard and Mar-tin, 2007; Ng and Kan, 2012; Do et al 2012), in-cluding 1) part-of-speech tags, 2) tenses, 3) depen-dency parses, 4) relative position of events in article,17System Precision Recall F1(1) DO2012 43.86 52.65 47.46(2) BASE 59.55 38.14 46.50(3) BASE + RST + PDTB + TOPICSEG 71.89 41.99 53.01(4) BASE + RST + PDTB + TOPICSEG + COREF 75.23 43.58 55.19(5) BASE + O-RST + PDTB + O-TOPICSEG + O-COREF 78.35 54.24 64.10Table 2: Macro-averaged results obtained from our experiments.
The difference in F1 scores between each successiverow is statistically significant, but a comparison is not possible between rows (1) and (2).5) the number of sentences between the target eventsand 6) VerbOcean (Chklovski and Pantel, 2004) re-lations between events.
This baseline system, andthe subsequent systems we will describe, comprisesof three separate one-vs-all classifiers for each of thetemporal classes.
The result obtained by our base-line is shown in Row 2 (i.e.
BASE) in Table 2.
Wenote that our baseline is competitive and performssimilarly to the results obtained by Do et al(2012).However as we do not have the raw judgements fromDo?s system, we cannot test for statistical signifi-cance.We also implemented our proposed features andshow the results obtained in the remaining rows ofTable 2.
In Row 3, RST denotes the RST discoursefeature, PDTB denotes the PDTB-styled discoursefeatures, and TOPICSEG denotes the text segmen-tation feature.
Compared to our own baseline, thereis a relative increase of 14% in F1, which is statis-tically significant when verified with the one-tailedStudent?s paired t-test (p < 0.01).In addition, Do et al(2012) have shown the valueof event co-reference.
Therefore we have also in-cluded this feature by making use of an automaticevent co-reference system by Chen et al(2011).The result obtained after adding this feature (de-noted by COREF) is shown in Row 4.
The relative in-crease in F1 of about 4% from Row 3 is statisticallysignificant (p < 0.01) and affirms that event co-reference is a useful feature to have, together withour proposed features.
We note that our completesystem in Row 4 gives a 16% improvement in F1,relative to the reference system DO2012 in Row 1.To get a better idea of the performance we can ob-tain if oracular versions of our features are available,we also show the results obtained if hand-annotatedRST discourse structures, text segments, as well asevent co-reference information were used.
Annota-tions for the RST discourse structures and text seg-ments were performed by the first author (RST an-notations were made following the annotation guide-lines given by Carlson and Marcu (2001)).
Oracularevent co-reference information was included in thedataset that we have used.In Row 5 the prefix O denotes oracular versionsof the features we had proposed.
From the resultswe see that there is a marked increase of over 15%in F1 relative to Row 4.
Compared to Do?s state-of-the-art system, there is also a relative gain of at least35%.
These oracular results further confirm the im-portance of non-local discourse analysis for tempo-ral processing.6 DiscussionAblation tests.
We performed ablation tests to as-sess the efficacy of the discourse features used inour earlier experiments.
Starting from the full sys-tem, we dropped each discourse feature in turn to seethe effect this has on overall system performance.Our test is performed over the same data set, againwith 5-fold cross-validation.
The results in Table 3show a statistically significant (based on the one-tailed Student?s paired t-test) drop in F1 in each case,which proves that each of our proposed features isuseful and required.From the ablation tests, we also observe that theRST discourse feature contributes the most to over-all system performance while the PDTB discoursefeature contributes the least.
However we should notconclude prematurely that the former is more use-ful than the latter; as the results are obtained usingparses from automatic systems, and are not reflec-tive of the full utility of ground truth discourse an-notations.Useful Relations.
The ablation test results showedus that discourse relations (in particular RST dis-18Figure 8: Proportion of occurence in temporal classes for every RST and PDTB relation.Ablated Feature Change in F1 Sig?RST -9.03 **?TOPICSEG -2.98 **?COREF -2.18 **?PDTB -1.42 *Table 3: Ablation test results.
?**?
and ?*?
denote statis-tically significance against the full system with p < 0.01and p < 0.05, respectively.course relations) are the most important in our sys-tem.
We have also motivated our work earlier withthe intuition that certain relations such as the RST?Result?
and the PDTB ?Cause?
relations providevery useful temporal cues.
We now offer an intro-spection into the use of these discourse relations.Figure 8 illustrates the relative proportion of tem-poral classes in which each RST and PDTB re-lation appear.
If the relations are randomly dis-tributed, we should expect their distribution to fol-low that of the temporal classes as shown in Table 1.However we see that many of the relations do notfollow this distribution.
For example, we observethat several relations such as the RST ?Condition?and PDTB ?Cause?
relations are almost exclusivelyfound within AFTER and BEFORE event pairs only,while the RST ?Manner-means?
and PDTB ?Syn-chrony?
relations occur in a disproportionately largenumber of OVERLAP event pairs.
These relationsare likely useful in disambiguating between the dif-ferent temporal classes.To verify this, we examine the convolution treefragments that lie on the support vector of our SVMclassifier.
The work of Pighin and Moschitti (2010)in linearizing kernel functions allows us to take alook at these tree fragments.
Applying the lineariza-tion process leads to a different classifier from theone we have used.
The identified tree fragments aretherefore just an approximation to those actually em-ployed by our classifier.
However, this analysis stilloffers an introspection as to what relations are mostinfluential for classification.BEFORE OVERLAPB1 (Temporal ... O1 (Manner-means ...B2 (Temporal (Elaboration ...B3 (Condition (Explanation ...B4 (Condition (Attribution ...B5 (Elaboration (Bckgrnd ...Table 4: Subset of top RST discourse fragments on sup-port vectors identified by linearizing kernel function.Table 4 shows a subset of the top RST discoursefragments identified for the BEFORE and OVER-LAP one-vs-all classifiers.
The list is in line withwhat we expect from Figure 8.
The former consistsof fragments containing relations such as ?Tempo-ral?
and ?Condition?, while the latter has a sole frag-ment containing ?Manner-Means?.To illustrate what these fragments may mean, weshow several example sentences from our data setin Example 4.
Sentence A consists of the tree frag-ment B1, i.e.
?(Temporal...?.
Its corresponding dis-course structure is illustrated in the top half of Fig-ure 9.
This fragment indicates to us (correctly) thatthe event ?wielded?
happened BEFORE Milosevicwas ?swept out?
of power.
Sentence B is madeup of tree fragment O1, i.e.
?(Manner-means...
?,19and its discourse structure is shown in the bottomhalf of Figure 9.
As with the previous example, thefragment suggests (correctly) that there should be aOVERLAP relationship for the ?requested ?
said?event pair.
[A] Milosevic and his wife wielded enormous power inYugoslavia for more than a decade before he was sweptout of power after a popular revolt in October 2000.
[B] The court order was requested by Jack Welch?s at-torney, Daniel K. Webb, who said Welch would likely beasked about his business dealings, his health and entriesin his personal diary.
(4)Milosevic ?
wielded?a decadebefore.. swept out..powerafter a?
October2000.temporaltemporalThe court?
requestedby Jack .. Webb,elaborationwho said Welch would ?diary.attributionmanner-meansFigure 9: RST discourse structures for sentences A (tophalf) and B (bottom half) in Example 4.Segment Numbers.
From the ablation test results,text segmentation is the next most important featureafter the RST discourse feature.
This is interestinggiven that the defined feature structure for topicaltext segmentation is not the most intuitive.
By us-ing actual segment numbers, the structure may notgeneralize well for articles of different lengths forexample, as each article may have vastly differentnumber of segments.
The transition across segmentsmay also not carry the same semantic significancefor different articles.Our experiments have however shown that thisfeature design is useful in improving performance.This is likely because:1.
The default settings of the text segmentationsystem we had used are such that precision isfavoured over recall (Kazantseva and Szpakow-icz, 2011, p. 292).
As such there is just an aver-age of between two to three identified segmentsper article.
This makes the feature more gener-alizable despite making use of actual segmentnumbers.2.
The style of writing in newswire articles whichwe are experimenting on generally followscommon journalistic guidelines.
The semanticsbehind the transitions across the coarse-grainedsegments that were identified are thus likely tobe of a similar nature across many different ar-ticles.We leave for future work an investigation intowhether more fine-grained topic segments can leadto further performance gains.
In particular, it will beinteresting to study if work on argumentative zoning(Teufel and Kan, 2011) can be applied to newswirearticles, and whether the subsequent learnt docu-ment structures can be used to delineate topic seg-ments more accurately.Error Analysis.
Besides examining the features wehad used, we also want to get a better idea of the er-rors made by our classifier.
Recall that we are usingseparate one-vs-all classifiers for each of the tempo-ral classes, so each of the three classifiers generatesa column in the aggregate confusion matrix shownin Table 5.
In cases where none of the SVM clas-sifiers return a positive confidence value, we do notassign a temporal class (captured as column N).
Thehigh number of event pairs which are not assigned toany temporal class explains the lower recall scoresobtained by our system, as observed in Table 2.PredictedO B A NO 119 (14.7%) 114 (14.1%) 104 (12.8%) 474 (58.5%)B 19 (0.5%) 2067 (57.9%) 554 (15.5%) 928 (26.0%)A 16 (0.5%) 559 (15.7%) 2046 (57.3%) 947 (26.5%)Table 5: Confusion matrix obtained for the full system,classifying into (O)VERLAP, (B)EFORE, (A)FTER, and(N)o result.Additionally, an interesting observation is the lowpercentage of OVERLAP instances that our classi-fier managed to predict correctly.
About 57% ofBEFORE and AFTER instances are classified cor-20rectly, however only about 15% of OVERLAP in-stances are correct.Figure 10 offers more evidence to suggest thatour classifier works better for the BEFORE and AF-TER classes than the OVERLAP class.
We see thatas sentence gap increases, we achieve a fairly con-sistent performance for both BEFORE and AFTERinstances.
OVERLAP instances are concentratedwhere the sentence gap is less than 7, with the bestaccuracy figure coming in below 30%.Although not definitive, this may be because ourdata set consists of much fewer OVERLAP in-stances than the other two classes.
This bias mayhave led to insufficient training data for accurateOVERLAP classification.
It will be useful to inves-tigate if using a more balanced data set for trainingcan help overcome this problem.Figure 10: Accuracy of the classifer for each temporalclass, plotted against the sentence gap of each E-E pair.7 ConclusionWe believe that discourse features play an importantrole in the temporal ordering of events in text.
Wehave proposed the use of different discourse anal-ysis frameworks and shown that they are effectivefor classifying the temporal relationships of article-wide E-E pairs.
Our proposed discourse-based fea-tures are robust and work well even though auto-matic discourse analysis is noisy.
Experiments fur-ther show that improvements to these underlyingdiscourse analysis systems will benefit system per-formance.In future work, we will like to explore how tobetter exploit the various discourse analysis frame-works for temporal classification.
For instance, RSTrelations are either hypotactic or paratactic.
Marcu(1997) made use of this to generate automatic sum-maries by considering EDUs which are nuclei to bemore salient.
We believe it is interesting to examinehow such information can help.
We are also inter-ested to apply discourse features in the context of aglobal inferencing system (Yoshikawa et al 2009;Do et al 2012), as we think such analyses will alsobenefit these systems as well.AcknowledgmentsWe like to express our gratitude to Quang Xuan Do,Wei Lu, and Dan Roth for generously making avail-able the data set they have used for their work inEMNLP 2012.
We would also like to thank theanonymous reviewers who reviewed this paper fortheir valuable feedback.This research is supported by the Singapore Na-tional Research Foundation under its InternationalResearch Centre @ Singapore Funding Initiativeand administered by the IDM Programme Office.ReferencesACE.
2005.
The ACE 2005 (ACE05) Evaluation Plan.October.Regina Barzilay, Noemie Elhadad, and Kathleen McKe-own.
2002.
Inferring Strategies for Sentence Order-ing in Multidocument News Summarization.
Journalof Artificial Intelligence Research (JAIR), 17:35?55.Steven Bethard and James H. Martin.
2007.
CU-TMP:Temporal Relation Classification Using Syntactic andSemantic Features.
In Proceedings of the 4th Interna-tional Workshop on Semantic Evaluations (SemEval),pages 129?132, June.Lynn Carlson and Daniel Marcu.
2001.
Discourse tag-ging manual.
Technical Report ISI-TR-545, Informa-tion Sciences Institute, University of Southern Califor-nia, July.Bin Chen, Jian Su, Sinno Jialin Pan, and Chew Lim Tan.2011.
A Unified Event Coreference Resolution by In-tegrating Multiple Resolvers.
In Proceedings of the5th International Joint Conference on Natural Lan-guage Processing (IJCNLP), pages 102?110, Novem-ber.Timothy Chklovski and Patrick Pantel.
2004.
Ver-bOcean: Mining the Web for Fine-Grained SemanticVerb Relations.
In Proceedings of the Conference onEmpirical Methods in Natural Language Processing(EMNLP), pages 33?40, July.21Michael Collins and Nigel Duffy.
2001.
ConvolutionKernels for Natural Language.
In Proceedings ofNIPS.Quang Xuan Do, Wei Lu, and Dan Roth.
2012.
JointInference for Event Timeline Construction.
In Pro-ceedings of the 2012 Joint Conference on EmpiricalMethods in Natural Language Processing and Compu-tational Natural Language Learning (EMNLP), pages677?689, July.Jennifer D?Souza and Vincent Ng.
2013.
ClassifyingTemporal Relations with Rich Linguistic Knowledge.In Proceedings of the Conference of the North Amer-ican Chapter of the Association for ComputationalLinguistics: Human Language Technologies (NAACL-HLT), pages 918?927, June.Vanessa Wei Feng and Graeme Hirst.
2012.
Text-levelDiscourse Parsing with Rich Linguistics Features.
InProceedings of the 50th Annual Meeting of the Asso-ciation for Computational Linguistics: Human Lan-guage Technologies (ACL), pages 60?68, July.Eun Young Ha, Alok Baikadi, Carlyle Licata, andJames C. Lester.
2010.
NCSU: Modeling TemporalRelations with Markov Logic and Lexical Ontology.In Proceedings of the 5th International Workshop onSemantic Evaluation (SemEval), pages 341?344, July.Marti A. Hearst.
1994.
Multi-Paragraph Segmentationof Expository Text.
In Proceedings of the 32nd AnnualMeeting of the Association for Computational Linguis-tics (ACL), pages 9?16, June.Anna Kazantseva and Stan Szpakowicz.
2011.
Lin-ear Text Segmentation Using Affinity Propagation.In Proceedings of the 2011 Conference on EmpiricalMethods in Natural Language Processing (EMNLP),pages 284?293, July.Anup Kumar Kolya, Asif Ekbal, and Sivaji Bandyopad-hyay.
2010.
JU CSE TEMP: A First Step TowardsEvaluating Events, Time Expressions and TemporalRelations.
In Proceedings of the 5th InternationalWorkshop on Semantic Evaluation (SemEval), pages345?350, July.Alex Lascarides and Nicholas Asher.
1993.
TemporalInterpretation, Discourse Relations and CommonsenseEntailment.
Linguistics and Philosophy, 16(5):437?493.Ziheng Lin, Hwee Tou Ng, and Min-Yen Kan. 2013.
APDTB-styled End-to-End Discourse Parser.
NaturalLanguage Engineering, FirstView:1?34, February.Inderjeet Mani, Marc Verhagen, Ben Wellner, Chong MinLee, and James Pustejovsky.
2006.
Machine Learningof Temporal Relations.
In Proceedings of the 21st In-ternational Conference on Computational Linguisticsand 44th Annual Meeting of the Association for Com-putational Linguistics (ACL), pages 753?760, July.William C. Mann and Sandra A. Thompson.
1988.Rhetorical Structure Theory: Toward a FunctionalTheory of Text Organization.
Text, 8(3):243?281.Daniel Marcu.
1997.
From Discourse Structures to TextSummaries.
In Proceedings of the ACL Workshop onIntelligent Scalable Text Summarization, volume 97,pages 82?88, July.Alessandro Moschitti.
2006.
Efficient Convolution Ker-nels for Dependency and Constituent Syntactic Trees.In Proceedings of the 17th European Conference onMachine Learning (ECML), September.Jun-Ping Ng and Min-Yen Kan. 2012.
Improved Tem-poral Relation Classification using Dependency Parsesand Selective Crowdsourced Annotations.
In Proceed-ings of the International Conference on ComputationalLinguistics (COLING), pages 2109?2124, December.Daniele Pighin and Alessandro Moschitti.
2010.
On Re-verse Feature Engineering of Syntactic Tree Kernels.In Proceedings of the 14th Conference on Natural Lan-guage Learning (CoNLL), August.Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Milt-sakaki, Livio Robaldo, Aravind Joshi, and BonnieWebber.
2008.
The Penn Discourse TreeBank 2.0.In Proceedings of the 6th International Conference onLanguage Resources and Evaluation (LREC), May.Andrea Setzer, Robert Gaizauskas, and Mark Hepple.2003.
Using Semantic Inferences for Temporal An-notation Comparison.
In Proceedings of the 4th In-ternational Workshop on Inference in ComputationalSemantics (ICoS), September.Eduard F. Skorochod?Ko.
1972.
Adaptive Method ofAutomatic Abstracting and Indexing.
In Proceedingsof the IFIP Congress, pages 1179?1182.Carlota S. Smith.
2010.
Temporal Structures in Dis-course.
Text, Time, and Context, 87:285?302.Simone Teufel and Min-Yen Kan. 2011.
Robust Argu-mentative Zoning for Sensemaking in Scholarly Doc-uments.
In Advanced Language Technologies for Dig-ital Libraries, pages 154?170.
Springer.Naushad Uzzaman and James F. Allen.
2010.
TRIPS andTRIOS System for TempEval-2: Extracting TemporalInformation.
In Proceedings of the 5th InternationalWorkshop on Semantic Evaluation (SemEval), pages276?283, July.Naushad Uzzaman, Hector Llorens, James F. Allen, LeonDerczynski, Marc Verhagen, and James Pustejovsky.2012.
TempEval-3: Evaluating Events, Time Expres-sions, and Temporal Relations.
Computing ResearchRepository (CoRR), abs/1206.5333.Vladimir N. Vapnik, 1999.
The Nature of StatisticalLearning Theory, chapter 5.
Springer.Marc Verhagen, Robert Gaizauskas, Frank Schilder,Mark Hepple, Jessica Moszkowicz, and James Puste-jovsky.
2009.
The TempEval Challenge: Identifying22Temporal Relations in Text.
Language Resources andEvaluation, 43(2):161?179.Marc Verhagen, Roser Sauri, Tommaso Caselli, andJames Pustejovsky.
2010.
Semeval-2010 task 13:Tempeval-2.
In Proceedings of the 5th InternationalWorkshop on Semantic Evaluation (SemEval), pages57?62, July.Marc Verhagen.
2005.
Temporal Closure in an Annota-tion Environment.
Language Resources and Evalua-tion, 39(2-3):211?241.Bonnie Webber.
2004.
D-LTAG: Extending LexicalizedTAG to Discourse.
Cognitive Science, 28(5):751?779.Katsumasa Yoshikawa, Sebastian Riedel, Masayuki Asa-hara, and Yuji Matsumoto.
2009.
Jointly IdentifyingTemporal Relations with Markov Logic.
In Proceed-ings of the 47th Annual Meeting of the Association forComputational Linguistics (ACL) and the 4th Interna-tional Joint Conference on Natural Language Process-ing of the Asian Federation of Natural Language Pro-cessing (AFNLP), pages 405?413, August.23
