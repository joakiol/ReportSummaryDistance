Machine Learning Approach To Augmenting News HeadlineGenerationRuichao WangDept.
of Computer ScienceUniversity College DublinIrelandrachel@ucd.ieJohn DunnionDept.
of Computer   ScienceUniversity College DublinIrelandJohn.Dunnion@ucd.ieJoe CarthyDept.
of Computer ScienceUniversity College DublinIrelandJoe.Carthy@ucd.ieAbstractIn this paper, we present theHybridTrim system which uses amachine learning technique to combinelinguistic, statistical and positionalinformation to identify topic labels forheadlines in a text.
We compare oursystem with the Topiary system which,in contrast, uses a statistical learningapproach to finding topic descriptorsfor headlines.
The Topiary system,developed at the University ofMaryland with BBN, was the topperforming headline generation systemat DUC 2004.
Topiary-style headlinesconsist of a number of general topiclabels followed by a compressedversion of the lead sentence of a newsstory.
The Topiary system uses astatistical learning approach to findingtopic labels.
The performance of thesesystems is evaluated using the ROUGEevaluation suite on the DUC 2004 newsstories collection.1 IntroductionIn this paper we present an approach to headlinegeneration for a single document.
This headlinegeneration task was added to the annualsumm5arisation evaluation in the DocumentUnderstanding Conference (DUC) 2003.
It wasalso included in the DUC 2004 evaluation planwhere summary quality was automaticallyjudged using a set of n-gram word overlapmetrics called ROUGE (Lin and Hovy, 2003).Eighteen research groups participated in theheadline generation task at DUC 2004, i.e.
Task1: very short summary generation.
The Topiarysystem was the top performing headline systemat DUC 2004.
It generated headlines bycombining a set of topic descriptors with acompressed version of the lead sentence, e.g.KURDISH TURKISH SYRIA: Turkey sent10,000 troops to southeastern border.
Thesetopic descriptors were automatically identifiedusing a statistical approach called UnsupervisedTopic Discovery (UTD) (Zajic et al, 2004).
Thedisadvantage of this technique is that meaningfultopic descriptors will only be identified if thistechnique is trained on the corpus containing thenews stories that are to be summarised.
Inaddition, the corpus must contain clusters ofrelated news stories to ensure that reliablecooccurrence statistics are generated.In this paper we compare the UTD methodwith an alternative topic label identifier that canbe trained on an auxiliary news corpus, andobserve the effect of these labels on summaryquality when combined with compressed leadsentences.
Our topic labeling technique worksby combining linguistic and statisticalinformation about terms using the C5.0(Quinlan, 1998) machine learning algorithm, topredict which words in the source text should beincluded in the resultant gist with thecompressed lead sentence.
In this paper, wecompare the performance of this system,HybridTrim, with the Topiary system and anumber of other baseline gisting systems on acollection of news documents from the DUC2004 corpus (DUC, 2003).1552 Topiary SystemIn this section, we describe the Topiary systemdeveloped at the University of Maryland withBBN Technologies.
As already stated, thissystem was the top performing headlinegeneration system at DUC 2004.
A Topiary-style headline consists of a set of topic labelsfollowed by a compressed version of the leadsentence.
Hence, the Topiary system viewsheadline generation as a two-step process: first,create a compressed version of the lead sentenceof the source text, and second, find a set of topicdescriptors that adequately describe the generaltopic of the news story.
We will now look ateach of these steps in more detail.Dorr et al (2003) stated that when humansubjects were asked to write titles by selectingwords in order of occurrence in the source text,86.8% of these headline words occurred in thefirst sentence of the news story.
Based on thisresult Dorr, Zajic and Schwartz, concluded thatcompressing the lead sentence was sufficientwhen generating titles for news stories.Consequently, their DUC 2003 systemHedgeTrimmer used linguistically-motivatedheuristics to remove constituents that could beeliminated from a parse tree representation of thelead sentence without affecting the factualcorrectness or grammaticality of the sentence.These linguistically-motivated trimming rules(Dorr et al, 2003; Zajic et al, 2004) iterativelyremove constituents until a desired sentencecompression rate is reached.The compression algorithm begins byremoving determiners, time expressions andother low content words.
More drasticcompression rules are then applied to removelarger constituents of the parse tree until therequired headline length is achieved.
For theDUC 2004 headline generation task systemswere required to produce headlines no longerthan 75 bytes, i.e.
about 10 words.
The followingworked example helps to illustrate the sentencecompression process.11   The part of speech tags in the example are explained asfollows: S represents a simple declarative clause; SBARrepresents a clause introduced by a (possibly empty)subordinating conjunction; NP is a noun phrase; VP is averb phrase; ADVP is an adverbial phrase.Lead Sentence: The U.S. space shuttleDiscovery returned home this morning afterastronauts successfully ended their 10-dayHubble Space telescope service mission.Parse: (S (NP (NP The U.S. space shuttle)Discovery) (VP returned (NP home) (NP thismorning)) (SBAR after (S (NP astronauts) (VP(ADVP successfully) ended (NP their 10-dayHubble Space telescope service mission)))))1.
Choose leftmost S of parse tree andremove all determiners, time expressions andlow content units such as quantifiers (e.g.each, many, some), possessive pronouns (e.g.their, ours, hers) and deictics (e.g.
this, tese,those):Before: (S (NP (NP The U.S. space shuttle)Discovery) (VP returned (NP home) (NP thismorning)) (SBAR after (S (NP astronauts) (VP(ADVP successfully) ended (NP their 10-dayHubble Space telescope service mission)))))After: (S (NP (NP U.S. space shuttle)Discovery) (VP returned (NP home))  (SBARafter (S (NP astronauts) (VP (ADVPsuccessfully) ended (NP 10-day Hubble Spacetelescope service mission)))))2.
The next step iteratively removesconstituents until the desired length isreached.
In this instance the algorithm willremove the trailing SBAR.Before: (S (NP (NP U.S. space shuttle)Discovery) (VP returned (NP home))  (SBARafter (S (NP astronauts) (VP (ADVPsuccessfully) ended (NP 10-day Hubble Spacetelescope service mission)))))After: U.S. space shuttle Discovery returnedhome.Like the ?trailing SBAR?
rule, the otheriterative rules identify and remove non-essentialrelative clauses and subordinate clauses from thelead sentence.
A more detailed description ofthese rules can be found in Dorr et al (2003) andZajic et al (2004) In this example, we can seethat after compression the lead sentence reads156more like a headline.
The readability of thesentence in this case could be further improvedby replacing the past tense verb ?returned?
withits present tense form; however, this refinementis not currently implemented by the Topiarysystem or by our implementation of thiscompression algorithm.As stated earlier, a list of relevant topicwords is also concatenated with this compressedsentence resulting in the final headline.
Thetopic labels are generated by the UTD(Unsupervised Topic Discovery) algorithm(Zajic et al, 2004).
This unsupervisedinformation extraction algorithm creates a shortlist of useful topic labels by identifyingcommonly occurring words and phrases in theDUC corpus.
So for each document in thecorpus it identifies an initial set of importanttopic names for the document using a modifiedversion of the tf.idf metric.
Topic models arethen created from these topic names using theOnTopic?
software package.
The list of topiclabels associated with the topic models closest incontent to the source document are then added tothe beginning of the compressed lead sentenceproduced in the previous step, resulting in aTopiary-style summary.One of the problems with this approach isthat it will only produce meaningful topicmodels and labels if they are generated from acorpus containing additional on-topic documentson the news story being summarised.
In the nextsection, we explore two alternative techniquesfor identifying topic labels, where usefulsummary words are identified ?locally?
byanalysing the source document rather than?globally?
using the entire DUC corpus, i.e.
theUTD method.3 C5.0C5.0 (Quinlan, 1998) is a commercial machinelearning program developed by RuleQuestResearch and is the successor of the widely usedID3 (Quinlan, 1983) and C4.5 (Quinlan, 1993)algorithms developed by Ross Quinlan.
C5.0 is atool for detecting patterns that delineatecategories.
It subsequently generates decisiontrees based on these patterns.
A decision tree is aclassifier represented as a tree structure, whereeach node is either a leaf node, a classificationthat applies to all instances that reach the leaf(Witten, 2000), or a non-leaf node, some test iscarried out on a single attribute-value, with onebranch and sub-tree for each possible outcomeof the test.
A decision tree is a powerful andpopular tool for classification and prediction andcan be used to classify an instance by starting atthe root of the tree and moving down the treebranch until reaching a leaf node.
However, adecision tree may not be very easy tounderstand.
An important feature of C5.0 is thatit can convert trees into collections of rulescalled rulesets.
C5.0 rulesets consist ofunordered collections of simple if-then rules.
Itis easy to read a set of rules directly from adecision tree.
One rule is generated for eachleaf.
The antecedent of the rule includes acondition for every node on the path from theroot to that leaf, and the consequent of the rule isthe class assigned by the leaf.
This processproduces rules that are unambiguous in that theorder in which they are executed is irrelevant(Witten, 2000).C5.0 has been used for text classification in anumber of research projects.
For example,Akhtar et al (2001) used C5.0 for automaticallymarking up XML documents, Newman et al(2005) used it for generating multi-documentsummary, while Zhang et al (2004) applied thisapproach to World Wide Web sitesummarisation.4 HybridTrim SystemThe HybridTrim system uses ourimplementation of the Hedge Trimmer algorithmand the C5.0 (Quinlan, 1998) machine learningalgorithm to create a decision tree capable ofpredicting which words in the source text shouldbe included in the resultant gist.To identify pertinent topic labels thealgorithm follows a two-step process: the firststep involves creating an intermediaterepresentation of a source text, and the secondinvolves transforming this representation into asummary text.
The intermediate representationwe have chosen is a set of features, that we feelare good indicators of possible ?summarywords?.
We focus our efforts on the contentwords of a document, i.e.
the nouns, verbs andadjectives that occur within the document.
Foreach occurrence of a term in a document, wecalculate several features: the tf, or term157frequency of the word in the document; the idf,or inverse document frequency of the term takenfrom an auxiliary corpus (TDT, 2004); and therelative position of a word with respect to thestart of the document in terms of word distance.We also include binary features indicatingwhether a word is a noun, verb or adjective andwhether it occurs in a noun or proper nounphrase.
The final feature is a lexical cohesionscore calculated with the aid of a linguistictechnique called lexical chaining.
Lexicalchaining is a method of clustering words in adocument that are semantically similar with theaid of a thesaurus, in our case WordNet.
Ourchaining method identifies the following wordrelationship (in order of strength):  repetition,synonymy, specialisation and generalisation, andpart/whole relationships.
Once all lexical chainshave been created for a text then a score isassigned to each chained word based on thestrength of the chain in which it occurs.
Morespecifically, as shown in Equation (1), the chainstrength score is the sum of each strength scoreassigned to each word pair in the chain.where repsi is the frequency of word i in thetext, and rel(i,j) is a score assigned based on thestrength of the relationship between word i and j.More information on the chaining process andcohesion score can be found in Doran et al(2004a) and Stokes (2004).Using the DUC 2003 corpus as the trainingdata for our classifier, we then assigned eachword a set of values for each of these features,which are then used with a set of gold standardhuman-generated summaries to train a decisiontree summarisation model using the C5.0machine learning algorithm.
The DUC 2003evaluation provides four human summaries foreach document, where words in the source textthat occur in these model summaries areconsidered to be positive training examples,while document words that do not occur in thesesummaries are considered to be negativeexamples.
Further use is made of these foursummaries, where the model is trained toclassify a word based on its summarisationpotential.
More specifically, the appropriatenessof a word as a summary term is determinedbased on the class assigned to it by the decisiontree.
These classes are ordered from strongest toweakest as follows: ?occurs in 4 summaries?,?occurs in 3 summaries?, ?occurs in 2summaries?, ?occurs in 1 summary?, ?occurs innone of the summaries?.
If the classifier predictsthat a word will occur in all four of the humangenerated summaries, then it is considered to bea more appropriate summary word than a wordpredicted to occur in only three of the modelsummaries.
This resulted in a total of 103267training cases, where 5762 instances occurred inone summary, 1791 in two, 1111 in three, 726 infour, and finally 93877 instances were negative.A decision tree classifier was then produced bythe C5.0 algorithm based on this training data.To gauge the accuracy of our decision treetopic label classifier, we used a training/test datasplit of 90%/10%, and found that on this test setthe classifier had a precision (true positivesdivided by true positives and false positives) of63% and recall (true positives divided by truepositives and false negatives) of 20%.5 Evaluation and ResultsIn this section we present the results of ourheadline generation experiments on the DUC2004 corpus.
2  We use the ROUGE (Recall-Oriented Understudy for Gisting Evaluation)metrics to evaluate the quality of ourautomatically generated headlines.
In DUC 2004task 1, participants were asked to generate veryshort (<=75 bytes) single-document summariesfor documents on TDT-defined events.The DUC 2004 corpus consists of 500Associated Press and New York Timesnewswire documents.
The headline-stylesummaries created by each system wereevaluated against a set of human generated (ormodel) summaries using the ROUGE metrics.The format of the evaluation was based on sixscoring metrics: ROUGE-1, ROUGE-2,ROUGE-3, ROUGE-4, ROUGE-LCS andROUGE-W.
The first four metrics are based onthe average n-gram match between a set ofmodel summaries and the system-generatedsummary for each document in the corpus.ROUGE-LCS calculated the longest common2 Details of our official DUC 2004 headline generationsystem can be found in Doran et al (2004b).
This systemreturned a list of keywords rather than ?a sentence +keywords?
as a headline.
It used a decision tree classifier toidentify appropriate summary terms in the news story basedon a number of linguistic and statistical word features.?
+= )),(*)(()( jirelrepsrepschainScore ji (1)158sub-string between the system summaries andthe models, and ROUGE-W is a weightedversion of the LCS measure.
So for all ROUGEmetrics, the higher the ROUGE value the betterthe performance of the summarisation system,since high ROUGE scores indicate greateroverlap between the system summaries and theirrespective models.
Lin and Hovy (2003) haveshown that these metrics correlated well withhuman judgments of summary quality, and thesummarisation community is now acceptingthese metrics as a credible and less time-consuming alternative to manual summaryevaluation.
In the official DUC 2004 evaluationall summary words were stemmed before theROUGE metrics were calculated; however,stopwords were not removed.
No manualevaluation of headlines was performed.5.1 ROUGE Evaluation ResultsTable 1 shows the results of our headlinegeneration experiments on the DUC 2004collection.
Seven systems in total took part inthis evaluation, three Topiary-style headlinegeneration systems and four baselines: the goalof our experiments was to evaluatelinguistically-motivated heuristic approaches totitle generation, and establish which of ouralternative techniques for padding Topiary-styleheadlines with topic labels works best.Since the DUC 2004 evaluation, Lin (2004)has concluded that certain ROUGE metricscorrelate better with human judgments thanothers, depending on the summarisation taskbeing evaluated, i.e.
single document, headline,or multi-document summarisation.
In the case ofheadline generation, Lin found that ROUGE-1,ROUGE-L and ROUGE-W scores worked bestand so only these scores are included in Table 1.Table 1.
ROUGE scores for headline generationsystemsAs the results show the best performing topiclabeling techniques are the TF and Hybridsystems.
TF system is a baseline system thatchooses high frequency content words as topicdescriptors.
Hybrid system is our decision treeclassifier described in the previous section.Both of these systems outperform theTopiary's UTD method.
The top threeperforming systems in this table combine topiclabels with a compressed version of the leadsentence.
Comparing these results to the Trimsystem (that returns the reduced lead sentenceonly), it is clear that the addition of topicdescriptors greatly improves summary quality.The performance of the baseline TFTrim systemand the HybridTrim system are very similar forall Rouge metrics; however, both systemsoutperform the Topiary headline generator.6 Conclusions and Future workThe results of our experiment have shown theTFTrim system (the simplest of the threeTopiary-style headline generators examined inthis paper) is the most appropriate headlineapproach because it yields high quality shortsummaries and, unlike the Topiary andHybridTrim systems, it requires no priortraining.
This is an interesting result as it showsthat a simple tf weighting scheme can produce asgood, if not better, topic descriptors than thestatistical UTD method employed by theUniversity of Maryland and our ownstatistical/linguistic approach to topic labelidentification.In future work, we intend to proceed byimproving the sentence compression proceduredescribed in this paper.
We are currentlyworking on the use of term frequencyinformation as a means of improving theperformance of the Hedge Trimmer algorithm bylimiting the elimination of important parse treecomponents during sentence compression.ReferencesB.
Dorr, D. Zajic, and R. Schwartz.
2003.
HedgeTrimmer: A Parse-and-Trim Approach toHeadline Generation.
In the Proceedings of theDocument Understanding Conference (DUC).C-Y Lin and E. Hovy.
2003.
Automatic Evaluation ofSummaries using n-gram Co-occurrence Statistics,Proceedings of HLT/NACCL.C-Y Lin.
2004.
ROUGE: A Package for AutomaticEvaluation of Summaries, In the Proceedings ofSystems R-1 R-L R-WTFTrim 0.279 0.213 0.126HybridTrim 0.274 0.214 0.127CombinationSystems Topiary 0.249 0.20 0.119TF 0.244 0.171 0.098Hybrid 0.219 0.176 0.102Trim 0.201 0.183 0.101BaselineSystemsUTD 0.159 0.130 0.078159the ACL workshop, Text Summarization BranchesOut, Barcelona, Spain, pp.
56-60.DUC.
2003. http://www-nlpir.nist.gov/projects/duc/,Accessed March 2005.D.
Zajic and B. Dorr and R. Schwartz.
2004.BBN/UMD at DUC-2004: Topiary, Proceedings ofthe Document Understanding Conference (DUC).I.
H. Witten and E. Frank.
2000.
Data Mining,Practical Machine Learning Tools and Techniqueswith Java Implementations.
Morgan KaufannPublishers.
ISBN 1-55860-552-5.N.
Stokes.
2004.
Applications of Lexical CohesionAnalysis in the Topic Detection and Trackingdomain.
Ph.D.  Thesis, Dept.
of ComputerScience, University College Dublin.R.
Quinlan.
1983.
Learning efficient classificationprocedures and their application to chess endgames, in Machine Learning.
An ArtificialIntelligence Approach edited by R.S.
Michalski,J.G.
Carbonell and T.M.
Mitchell, Tioga, PaloAlto, CA, 1983, pp.463-482.R.
Quinlan.
1993.
C4.5: Programs for MachineLearning.
Morgan Kaufmann Publishers, SanMateo, California ISBN 1-55860-238-0.R.
Quinlan.
1998.
C5.0: An Informal Tutorial,http://www.rulequest.com/see5-unix.html,Accessed March 2005.S.
Akhtar, J. Dunnion and R. Reilly.
2001.Automating XML mark-up, Joint InternationalConference of the Association for Computers andthe Humanities (ACH) and the Association forLiterary and Linguistic Computing (ALLC), NewYork.TDT Pilot Study Corpus.
2004.http://www.nist.gov/speech/tests/tdt.W.
Doran, N. Stokes, J. Dunnion, and J. Carthy.2004a.
Assessing the Impact of Lexical ChainScoring Methods and Sentence ExtractionSchemes on Summarization.
In the Proceedings ofCICLing, Seoul.W.
Doran, N. Stokes, E. Newman, J. Dunnion, J.Carthy, and F. Toolan.
2004b.
News Story Gistingat University College Dublin.
In the Proceedingsof the Document Understanding Conference(DUC).Y.
Zhang, N. Zincir-Heywood, E. Milios.
2004.World Wide Web Site Summaisation.
To Appear inWeb Intelligence and Agent Systems: AnInternational Journal (The Web intelligenceConsortium), 2(1), pages 39-53.160
