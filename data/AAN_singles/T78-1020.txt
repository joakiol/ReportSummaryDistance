ON THE INTERDEPENDENCE OF LANGUAGE AND PERCEPTION*David L. WaltzCoordinated Science LaboratoryUniversity of Illinois at Urbana/ChampaignABSTRACTIt is argued that without a connection to thereal world via perception, a language system can-not know what it is talking about.
Similarly, aperceptual system must have ways of expressing itsoutputs via a language (spoken, written, gesturalor other).
The relationship between perceptionand language is explored, with special attentionto the implications of results in language re-search for our models of vision systems, and vice-versa.
It is suggested that early language learn-ing is an especially fertile area for this explo-ration.
Within this area, we argue that perceptualdata is conceptualized prior to language acquisitionaccording to largely innate strategies, that thisconceptualization is in terms of an internal, non-ambiguous "language," that language productionfrom its beginnings to adulthood is a projectionof the internal language which selects and high-lights the most important portions of internalconcepts, and that schemata produced in thesensory/motor world are evolved into schemata todescribe abstract worlds.
Examples are providedwhich stress the important of "gestalt" (figure-ground) relationships and projection (3-D to2-1/2 or 2-D, conceptual to linguistic, andlinguistic to conceptual); finally mechanisms foran integrated vision-language system are proposed,and some preliminary results are described.Introductionperception i.
obs.
: CONSCIOUSNESS2a: a result of perceiving: OBSERVATIONb: a mental image: CONCEPT3a: awareness of the elements of environmentthrough physical sensation <color ~>b: physical sensation interpreted in thelight of experience4a: direct or intuitive cognition: INSIGHTb: a capacity for comprehensionsyn see DISCERNMENT(Webster's Seventh New Collegiate Dictionary)*This work was supported by the Office of NavalResearch under Contract ONR-NO0014-75-C-0612.tWhile I intend perception to refer in the humanexamples to all the senses: vision, hearing,touch, smell, taste, and motor sense, in thecase of computers, only vision has been exploredin more than a cursory manner.Language understanding in its deepest senseis not possible without direct experience of itsreal world correlates.
I believe that it is noaccident that the same word can refer both tosensory awareness and to comprehension.
Nearlyall efforts in language processing, both inartificial intelligence and linguistics, haveconcentrated on transforming strings of words intotrees or other structures of words (sometimessurface words, sometimes "primitive" words) orconversely, on producing strings of words fromthese structures.
Few researchers have evenrecognized the importance of interfacing languageand vision systems,t let alne uniting the twolines of research.
(Exceptions include \[Minsky1975\], \[Woods 1978\], \[Miller & Johnson-Laird \[1976\],\[Schank & Selfridge !977\], \[Pylyshyn 1977 a & b\],\[Clark 1973\]).
At this time in history, AIvision and natural language researchers havelittle to say to each other; most of the workwhich treats language and perception togetherwould I think be considered to lie in the realmsof philosophy or psychology.Moreover, the areas of language processingwhich could have a bearing on perception havebeen largely ignored.
Very little work has beendone on programs to understand language aboutspace, spatial relations, or object descriptions.
(Some exceptions are \[Sirmmons 1975\] and \[Novak1976\], \[Kuipers 1975\], and \[Goguen 1973\].
)By the same token, current computer visionsystems are not able to describe what they "see"in natural language; in fact very few programscan even identify objects within a scene (exceptfor programs which operate in very constraineduniverses).
Most vision systems produce scenesegmentations, labellings or 3-D interpretationsof scene portions, etc.
Very little progresshas been made toward the goal of having programswhich could describe a general scence, let alnedescribe the most salient features of a scene.
(Some exceptions are \[Preparata and Ray 1972\],\[Yakimovsky 1973\], \[Bajcsy and Joshi 1978\],\[Zucker, Rosenfeld and Davis 1975\], and \[Tenen-baum and Weyl 1975\].)
Similarly, no programs Iknow are able to locate or "point to" scene items,given a natural language description of sceneitems or their whereabouts.149The need for an internal representation separatenatural lansuaseIt is now reasonably well-established thatpeople use large structures like "scripts" \[Schankand Abelson 1977\] or "frames-systems" \[Minsky1975\] prevasively for reasoning and language andthat a large script can be invoked by referring toa single salient aspect of the script.
Thus wecan answer a question like "How did you get here?
"by saying "I borrowed my brother's car," and thisanswer can only be understood if we are able touse it to reliably retrieve a larger structurewhich answers the question more directly.
(Examplefrom George Lakoff \[1978\].)
To understand lan-guage at the level of an adult human will certainlyrequire a huge number of such scripts, with richinterconnections and powerful, flexible matchingprocedures as in Bobrow and Winograd \[1977\].
Forscripts that refer to the physical world directly,what language can be used to construct the scripts?How can we construct scripts for abstract worlds(e.g.
economics, psychology, politics)?
Whatlanguage should be used for abstract worlds?
Areall these scripts to be hand coded?Consider also sentences like "A man wasbitten by a dog".
If we were to be asked "Wherecould the man have been bitten, we would probablyin the absence of more information guess theankle, leg or arm.
However if we are also toldthat the dog was a doberman or that it was adashshund or that the man was lying down or thatthe dog was standing at the time, we would givesomewhat different answers.
It seems to me thatnatural structures for representing and answeringquestions about such language will be very differ-ent from those used in all programs today - aprototypical dog which Can be scaled, repre-sentations of a person in various canonicalpositions, sizes of mouth openings and limbs, etc.would be the most appropriate, economical repre-sentations.There is also a great deal of prima facieevidence of close ties between perception and thelanguage used by adults to describe abstractprocesses such as thinking, learning, and commu-nicating, and to describe abstract fields likeeconomics, diplomacy, and psychology.
Witnessthe wide use of basically perceptual words like:start, stop, attract, repel, divide, separate,join, connect, shatter, scratch, smash, touch,lean, flow, support, hang, sink, slide, scrape,appear, disappear, emerge, submerge, deflect, rise,fall, grow, shrink, waver, shake, spread, congeal,dissolve, precipitate, roll, bend, warp, wear,chip, break, tear, etc., etc.
While we obviouslydo not always (or even usually) experience per-ceptual imases when we use or hear such words, Isuggest that much of the machinery used duringperception is used during the processing oflanguage about space and is also used during theprocessing of abstract descriptions.
I do notfind it plausible that words like these have twoor more completely different meanings which simplyshare the same lexical entry.There are significant linguistic generali-zations to be found in language about perception.As an example, Clark \[1973\] demonstrates beauti-fully the structural regularities underlyingprepositions which express spatial relations andthe metaphorical transfer of spatial prepositionsto describe time.Finally, language plays an important role inguiding or directing attention and in providingexplanations via analogy or  via connections whichare not directly accessible to sensory perception.I contend that (i) we should strive to under-stand and to learn to represent the sensory/motorworld; (2) we should study the relationship oflanguage to the representations of the world,being aware that language does not itself repre-sent the sensory/motor world, but instead pointsto the representations of this world via a set ofword and structure conventions.The development of perception and languageWhat we learn to name and describe in ourexperience must in some sense exist prior to andseparate from the words associated with the experi-ence.
I believe that an infant develops veryearly a kind of "language of perception," i.e.
anatural, innate segmentation of experience andordering of the importance or interest of segmenteditems.
Moreover, before an infant ever learns(or can learn) the name of an object, the infantmust (i) be able to perceive that object as aunitary concept, and (2) must in fact perceivethe unitary concept of the object as the mostsalient characteristic of that object.
Thus, weassume that when we point to a telephone and say"telephone," the infant prefers to attach thename to be entire object and not to some property(e.g.
color or size) of the object.I will use the word "gestalt" to refer tosuch a unitary concept, because the words "con-cept" or "percept" may be misleading, and becauseI would not want to coin an entirely new word.By "object," I will mean not only visual objects,but also auditory "objects," having figure/groundrelationships, such as a clap of thunder or aword spoken in isolation, and of course "objects"from other sensory and motor domains as well.As I will discuss later, I believe that wecan get around having to postulate perceptualprimitives by viewing gestalts as the result ofinformation theoretic types of processes, e.g.processes which select and attach importance topoints with highly improbable surroundings (forexample, points of symmetry).How much is innate?There has recently been a good deal of dis-cussion about the "language" of thought or'~entalese" (\[Fodor 1975\]), \[Pylyshyn 1978\],\[Woods 1978\], \[Johnson-Laird 1978\]).
The centralissues discussed in these accounts are: (I) theinnate "vocabulary" of such a language (innateconcepts); (2) ways in which new concepts areadded to mentalese; and (3) the relationship ofmentalese items to words.I would like to focus on one aspect of thesediscussions: innate concepts.
To quote Pylyshyn\[1978\] at some length:150"There is no explanation, not even the begin-nings of an approach, for dealing with theaccommodation of schemata or conceptual struc-tures into ones not expressible as definitionalcomposites of existing ones.
There is, inother words, no inkling as to how a completelynew non-eliminable concept can come into being.
"and later,"The first approach \[to this dilemma\] is tosimple accept what seems an inevitable con-clusion and see what it entails.
This is theapproach taken by Fodor \[1975\] who simply acceptsthat mentalese is innate...""This approach to the innateness dilemmaplaces the puzzle of conceptual development ona different mechanism from the usual one ofconcept learning.
Now the problem becomes:given that most of the concepts are innate whydo they only emerge as effective after certainperceptual and cognitive experience and atvarious levels of maturation?
"Pylyshyn goes on to sketch another solutionin which mentalese is viewed as a sort of machinelanguage for use with the fixed hardware archi-tecture of the nervous system; new concepts couldthen arise if we allow the hardwired connectionsor architecture to change.
As he points out,this merely buries the problem in hardware, anddoes not really provide a solution, but a differ-ent locus for the problem; at least it does getbeyond the limitations inherent if the onlyformal concept development mechanism available issymbolic composition.I find the notion of an innate language tobe unsatisfying, and offer below a different sortof solution to the problem of the source of novelconcepts.A sketch of the development of perception andlanguageIn this section I sketch what I feel is aplausible account of the development of perceptionand language.
This account is heavily based onintuition and on my observation of my two children(Vanessa, now 5 and Jeremy, now 3); it thus repre-sents an extreme case of inductive generalization.However, I have attempted to also cite ties withand supportive evidence from other work of whichI am aware - I will be grateful to readers of thispaper who supply relevant supporting or conflictingreferences which I do not acknowledge.The basic positions I would like to argue onthese issues are as follows:(i) mentalese arises out of perceptual experience,and is not per se innate (i.e.
present at birth);(2) the development of mentalese depends instead oncertain innate abilities and reflexes, plus per-ceptual experience.
The innate abilities* are (atleast):a) the ability to form "figure/ground" per-ceptual relationships, where figures have distin-guishing properties like local coherence on ahomogeneous background ("objectness"), symmetry,repetition, local movement against a fixed back-ground, etc.
I will assume that the gestalts eachhave a certain salience or measure of "interest-ingness" to the infant which is a function of theinherent perceptual characteristics of eachgestalt, the order and timing of attention tovarious gestalts (in turn these are eventuallyrelated to the current goals and hypotheses of theinfant) and the current degree of pleasure or painbeing experienced by the infant - at the extremesof pleasure or pain, gestalts have high salience,and could become independent goals to be pursuedor items to be avoided.b) the ability to remember quite literallyone or more figures ("gestalts") from a figure/ground relationship for a short period of time(on the order of i0 seconds):c) the ability to form associations betweengestalts, where by association I mean that theexperience of one gestalt can lead to the experi-ence of an associated gestalt;d) infants also have reflexes and certaininnate behaviors, such as crying when hungry orin pain.
Throughout this article, I will assumethat these reflexes and behaviors - physical,mental, emotional, etc.
- are also portion of aninfant's perceptual experience.
(3) The primary goal of an infant is to maximizeits pleasure and minimize its pain, and this goaldrives the infant to attempt to understand itsperceptual experience;(4) The primary mechanism of understanding itsexperience is the organization of gestalts; thisorganization involves:a) the formation of a taxonomy of the gestaltsof experience, where the taxonomy is generated bysuccessively subdividing existing categories intotwo (usually) or more new categories, andb) the formation of associations between twoor more gestalts to form new gestalts.Reorganization occurs when previous taxonomicdecisions appear to be deficient (e.g.
are notleading to the achievement of pleasure or thecessation of pain), and the particular form chosenfor reorganization depends on which gestalts arecurrently available, and of these which are mostsalient.
The formation of gestalts by associationis only possible initially between gestalts whichboth fall within the time period during whichgestalts can be remembered.
Associations initiallyare (probably) merely links; these links are them-selves later sub-categorized into temporal sequence(elementary source of cause-effect relationshipsand "scripts"), constant copresence (elementarysource of notions of identity or inherent connect-edness), and eventually semantic relatedness (e.g.the link between the gestalt of a perceived visualobject and the auditory gestalt of a word) as wellas other connections.It is a bit strange to call these "abilities"since I do not believe that it is possible for usto experience the world at all except through theaction of these "abilities," so that they mightbetter be called "processes" or "properties ofperception".151(5) Once associations are formed, items can becomeavailable as gestalts even if they are not at thetime directly available to the external senses;this allows escape from the narrow bounds of theinitial time window associated with externallyperceived gestalts, since each gestalt can continueto reactivate others associated with it for inde-finite periods (though '~abituation" and competingexternal ge?talts will soon interfere in general).Taken together, any gestalt and the associ-ates it can evoke form something like a "frame"\[Minsky 1975\]; every non-isolated concept thus hasa frame.
Default values for slots correspond togestalts evoked in the absence of definite per-ceptual input.
Language, then, is a sort of pro-jection, where only some of the items to be com-municated need to actually be mentioned directly.Syntax can be viewed as a means of constructing aperspective toward the gestalts selected by wordsand context; specific structures and words selectspecific connections between gestalts, as in\[Fillmore 1977\].Early language is an extreme projection: achild beginning to speak can only output one wordper sentence, later two words (this is the limitfor a long time), etc.
Thus 'Ball" when utteredby a one-year old might mean "I want the ball,""That's a ball," "Where is my ball?
", "I was justhit by a ball," etc.
There is striking recentevidence from the study of deaf children deliber-ately deprived of language* \[Feldman, Goldin-Meadowand Gleitman 1977\] that these children developlanguage independently, and that the length andthe contents of their "sentences" are extremelysimilar to "sentences" of hearing children, inwhich certain types of sentences (e.g.
verb +patient case) predominate and certain case roles(e.g.
agent) are usually omitted.
I suggest thattheir language development is similar becausetheir perceptual experiences (and needs to commu-nicate) are similar, and that the items chosen toappear in sentences are the ones with the highestsalience.In order to understand projected language,one must understand the context in whichit is occurring.
(For example, at age 2 years8 months Jeremy Waltz held a new toy train upto the telephone receiver and said "look at thepresent I got, grammy.")
Later language developmentcan be viewed as learning to communicate in theabsence of a shared physical context.In the direction of language comprehension,we must then postulate a reconstruction process.Schank \[1973\] supplies evidence that by the age ofone year, children understand the concepts of theprimitive ACTs of conceptual dependancy;T Schankand Selfridge \[1977\] have demonstrated thatchildren's responses to sentences at one year canbe mimicked by a program by assuming the child hasa single word input buffer, that (s)he selectsonly one word from a given input sentence, andfinally picks and executes an ACT which plausiblycould involve the concept associated with the wordselected.
Thus, when told "Take the ball toRoger" a child might simply get the ball, or takethe ball to someone else (if ball were selected) orrun to Roger (if Roger were selected).I would finally like to emphasize the ideathat language at all ages (not just for children)involves the complementary processes of projectionfrom and reconstruction into mentalese.
(See alsoMarcus \[1978\] for more evidence on input butterrestrictions in adults.
)(6) New gestalts can probably be integrated intothe infant's taxonomy only one at a time, i.e.,new items must be associated with items which arealready part of the organized taxonomy.
Thuswords would usually be learned for items which arealready organized conceptually, although novelwords could be used to point out the need for newcategories (e.g.
by pointing out that a dog andsheep are different).
The net result is the like-lihood of many more total concepts (individualconcepts, associated individual concepts, andassociations of associations) than there are con-cepts with words attached to them (\[Woods 1978\]comes to a similar conclusion).Properties can be selectively named by (a)presenting two or more quite different objectswhich share a single property, say color, or ~)contrasting objects which differ in only a singleproperty Gig/small),  or (c) having names firmlyenough in place so that items pointed to can beunderstood as details or properties, not the nameper se.
((a) and (b) are like Winston's \[1975\]"near-misses").
I would like to point out theanalogy given above and the use of metaphor toselect and highlight relationships for which wedo not already have names.Concepts are at least potentially completelyunambiguous, with the exception of auditorygestalts corresponding to words.?
Clearly someauditory gestalts corresponding to words can beassociated with two or more different gestalts(e.g.
fair (carnival), fair (clear or beautiful),fare (travel fee), fare (menu items)); I suggestthat in order to be understood unambiguously, suchwords must occur in a context where one under-lying concept is associated much more closely withconcepts in the current context (verbal or otherperceptual).
This idea is related to work inspreading activation for semantic networks \[Collinsand Loftus 1972\], as well as to "focussing as inGrosz \[1978\].Because the Philadlphia school system believesthat lip-reading and vocal speech are best, andthat learning sign language destroys the willing-ness of children to learn to lip read and speak.#E.g MOVE (a body part), INGEST, EXPEL, PTRANS(transfer a physical object), ATRANS (transfer anabstract relationship, e.g.
possession).
MTRANS(transfer information between or within animals),PROPEL (apply force to), GRASP, SPEAK (make anoise, and ATTEND (Focus a sense organ on anobject \[Schank 1975\].
?Of course, visual or other sensory input can beambiguous at times, but if a unique mentaleseitem is selected for a sensory item, the item is~then uniquely understood.152(7) Jackendoff \[1975\] and Gruber \[1965\] have point-ed out evidence that linguistic schemata we developto describe GO, BE and STAY events in the sensory/motor ("position") world are later transferred viaa broad metaphor to describe events in abstractworlds (possession, "identification" and "circum-stantial").
Thus we learn to use parallel surfacestructures for conceptually very different sentenceslike:(la) The dishes stayed in the sink (position)(ib) The business stayed in the family (posses-sion).
(2a) His puppy went home (position).
(2b) His face went white (identification).
(3a) She got into her car and went to work(position).
(3b) She sat down at her desk and went to work(circumstantial).Along these same lines, there are strikingparallels in the structures of Schank's \[1975\]conceptual dependency diagrams for PTRANS, ATRANS,and MTRANS (see earlier footnote).
Reddy \[1977\]has described what he calls the "conduit metaphor"for linguistic communication in which we typicallyspeak of ideas and information as though they wereobjects which could be given or shipped to otherswho need only to look at the "objects" to under-stand them.
Thus we say '~ou aren't getting yourmessage across," "She gave me some good ideas,""He kept his thoughts to himself," "Let me giveyou a piece of advice," etc.
(Reddy has compileda very long list of examples.
)These examples suggest many deep and fasci-nating questions.
It seems clear that the samewords and similar syntactic structures can betransferred to describe quite different phenomena.What internal structures (if any) are also trans-ferred in such cases?
What perceptual criteriaare used to classify events to begin with?
Ulti-mately?
How does a child transfer observation toimitation?
How are memories of specific eventsgeneralized to form event types, and how are therepresentations of event types related to memoriesof specific events?To answer one portion of these questions, itseems clear from an economic point of view thatif syntax and words are conventional and not innate,we would want to include only enough distinct syn-tactic structures and words to make distinctionsthat are necessary and to unambiguously selectmentalese representations.
We would thus predictthat words and syntactic structures would be heavi-ly shared (see also \[Woods 1978\]).I suggest that internal mentalese structuresare not transferred, but that, just as single wordscan point to more than one concept, these parallelstructures for verbs can point to more than onementalese structure.
However, there are limita-tions: the structures pointed to must share someproperties, e.g.
the number of case roles must bethe same, and selection restrictions on case roleslots should be sufficient to choose the appropriateconcept unambiguously.Another interesting question involves thestatus of inferential knowledge - is it attachedto mentalese concepts or to words?
Surprisingly,there may be some evidence that inferential know-ledge is attached to words.
In the positio n worldwe know that an.object can only be in one place ata time, that two objects cannot occupy the sameplace at the the same time, etc.
Some of thesesame inferences may be carried over inappropriatelyto the possession world: for example my childrenappeared to have some difficulty fully understand-ing concepts like "joint ownership".
If we assumethat in the conceptual transfer a child createsan imaginary "possession basket" for each person,and that the interiors of two such baskets cannotintersect, then objects must be in one basket oranother, and sentences like "Real \[our dog\] belongsto all of us but he's really mine" (Vanessa,about 4-1/2) become more intelligible.
(There areof course other plausible explanations for thissentence.)
Reddy \[1977\] has also pointed out waysin which the "conduit metaphor" for communicationminimizes the constructive role of the listener,and leads to the notion that failure of communi-cation is due primarily to the speaker.
Whorf's\[1956\] ideas and data may be relevant here also.The role of aestheticsI feel that it is important to keep ourcentral attention on the functional roles of per-ception and language for the survival of theinfant, which I take to be the primary goal inevolution, and the place where we must lookultimately for explanations about innate abilitiesand early development.
I accept Pugh's \[1977\]suggestion that all our values (pleasure, pain,good, bad, happy, unhappy, etc.)
serve as "second-ary values," i.e.
as surrogate values for theprimary value of survival.
We have these second-ary values because they allow us to distinguishsituations which have significant positive ornegative survival value.
Woods \[1978\] has pointedout the survival value of language in allowingthe transmission of knowledge in the absence ofgenetically '~ired" behavior.
(See \[Dennett 1974\].
)I suggest that the values like goodness,economy, aesthetics, and interestingness are per-vasive in our perceptual systems and in themechanisms which evaluate hypothesized taxonomiesof experience.
We attend to sensory items whichinterest us, store descriptions in ways that areaesthetically satisfying (e.g.
have good symmetryproperties, divide phenomena into balanced cate-gories, help avoid dangling, unexplained phenomena,etc.
), in addition to evaluating whether our hypo-theses are helping us get what we want.Development of a taxonomy of experienceLet us assume that we start with a unitaryconcept of the world, and examine a plausibledevelopment of distinctions in the visual world.
*The first sort of distinction likely is moving/notmoving, where 'Roving" refers to a figure on aground.
The '~oving" category is soon divided intocategories for moving items over which the infanthas some control and moving items where (s)he doesnot (random motions).
Later, this category isseparated into items where the infant has directcontrol (e.g.
parts of the body), and others (e.g.It is likely that some distinctions, e.g.
kines-thetic moving/not moving, are made in utero.153parents who sometimes come when the child cries,objects nearby which can sometimes be hit ortouched by body movements, etc.
).Out of this process eventually, come basicdistinctions like self/other, mind/body, near(reachable)/far (unreachable); also, categoriesfrom various sense modalities can be merged (ob-jects from the tactile and visual worlds, motherfrom the visual, auditory and tactile worlds, etc.
).I have a wealth of observations on the developmentof these distinctions from watching my childrenwhich cannot be expounded further in the spacehere.
I would like to suggest in passing that thedevelopment of this taxonomy can have deep psycho-logical significance - to point out one example,consider the following contrasting situations:(i) parents are attentive to an infant's criesand thus are thus initially within the categoryof moving items controlled by the infant vs.(2) the parents are inattentive to cries, and thusinitially are classified in the "random motion"category.
See Wilber \[1976\] for an extensionexploration of the development of fundamentaldualities.A computer model of gestalt formationMy recent work in vision \[Waltz 1978\] hasexplored computational methods for finding pointsin scenes which have high information content,which I suggest as the primary basic of the de-finition of "interestingness," which in turnshould drive attention.Because we (George Hadden and I) have beenworking with static scenes, our programs do notsperate moving figures on grounds (which I take tobe important, as should be obvious from earlierdiscussions).
* We have concentrated instead onmethods for funding symmetry axes, points withhigh curvature, edges and edge completions, iso-lated objects on backgrounds, spatially repeatedpatterns, and characteristics texture elements.In each case we are assuming that processes thatbe bottom-up and task-independent (although Iwould be willing to include some special pre-ferences for things like vertical or horizontaldirections).This work is based on the notion that shapeis the best "property" with which to sort itemsinto categories.
Our programs attempt to locateunique points of high information (e.g.
the centerof a circle) and to store at that point suffi-cient information to "unfold" a shape envelope ofan object (the shape envelope is the same for asolid line rectangle, dotted line rectangle,rectangle with a notch removed from the side,etc.
).+ The notion here is that shape should berepresente d hierarchically, with the shape envelopetypically at the top of the hierarchy, and de-viations from the shape envelope located lower,along with other properties like ?olor, size, etc.However, in the long run visual objectsshould be described in a more flexible structurewhich draws on a list of properties; my currentfavorite list of properties comes from Pylyshyn\[1977b\] who in turn got the list from Basso \[1968\].Basso identified the items through the analysisof classificatory morphemes in diverse languages.He identifies semantic dimensions: animal/non-animal, enclosed/non-enclosed; solid/plastic/liquid; one/two/more that two; rigid/nonrigid;horizontal length > 3 times width or height/"equidimensional"; portable/nonportable.
Thesecan be combined to form categories which recurcommonly in other cultures, e.g.
"rigid andextended in one dimension" (pencil, knife, ciga-rette); "rigid and equidimensional" (pail, lightbulb, egg, box, coin, book); "flexible and ex-tended in two dimensions" (paper, blanket, shirt);"flexible and extended in one dimension" (rope,belt, chain).Of importance in all these cases is that thedescriptions be hierarchical, with meaningfulgeneralizations at the top of the hierarchy (seePreparata and Ray \[1972\] for other ideas alongthese lines that we have adopted), and the des-cription be capable of being generated bottom up.Visual imageryMy position may be acceptable to bothPylyshyn \[1973\] and Kosslyn \[1978\].
With Pylyshyn,I believe that visual descriptions are proposi-tional, and that the descriptions are organizedhierarchically.
However, as argued in the lastsection, shape seems to be the primary distin-guishing property of objects, and we have reasonto believe that shape can in general be repre-sented rather compactly with respect to somepoint (e.g.
of symmetry or a centroid).
I suggestthat shape representations may actually be capa-ble of being "run backwards" or "unfolded," andthat the result may be activation of portions ofour brains (visual cortex?)
which are also acti-vated when an item is directly perceived.In this view, visually imagery could provideuseful clues about the nature of shape representa-tion.
However visual imagery does not seem to begenerally experiences or used ~ based on informalquestioning of my classes, fewer than half ofengineering students (who might be expected tovisualize more frequently than averag~ reportother than occasional use of imagery.
(As a per-son who does use visual imagery extensively, Ifound this result surprising.)
Perhaps imageryis a latent talent which can be developed; oncedeveloped I believe it has significant value forproblem solving, organization of material, andmemorization.Moving figures are however trivial to compute bysubtraction of successive frames of a moving scene.~As discussed in Bajcsy & Joshi \[1978\], in adultspeech shape is described verbally by referring toother familiar (or canonical) objects.
However,in order to note the similarity of objects, wemust have neutral descriptions of each, e.g.
thekinds of descriptions I am discussing here.
AlsoOf interest is the observed fact that we havevery few verbal items to describe shape in a non-relational manner, except for highly regularobjects (sphere, cube, etc.
).154In a related vein, I am intrigued by (andintend to follow up further) the ides that we mayorganize memory in such a way that we can useperceptual strategies for understanding its con-tents.
Two particularly suggestive phenomena(other than visual imagery):(i) The striking similarity of some memories tosensory phenomena: in order to retrieve thepunchline of a joke or content of a story, Isometimes have to go through the whole joke orstory; I can "play back" music; etc.,(2) recent work by Fillmore \[1977\] and Grosz\[1978\] which suggests that language may guide ananalog of the attention process by suggesting aperspective from which to view memory structure(s)as they are retrieved.Can we dispense with the idea of innate ideas?In order to show that we can account formentalese without requiring innate ideas, I mustshow (I) that the mechanisms proposed are capableof generating all the primitive concepts ofmentalese, and (2) that I have not simply buriedinnate ideas somewhere in the mechanisms.
Letme say in~nediately, relative to point (2) thatthere are some innate ideas in my account; oneset of ideas are related to the values (good/bad,symmetrical/nonsyrmnetrical, etc.)
discussedearlier.
There must also be ideas relating togenerating hypotheses on which the values canoperate, and the idea of objectness (if this canbe called an idea) must be present.
Hypothesisgeneration might seem a candidate for furthersearch for embedded ideas; however, as I havedescribed it, hypothesis generation is primarilya categorizing operation, where it acts on the"raw material" of perception.
On the whole I donot believe that it is difficult to accept thesorts of innate ideas which remain in my account.It is much more difficult to make a con-vincing case for the sufficiency of thesemechanisms to explain mentalese.
(The situationis not aided by the fact that there are fewsuggestions concerning the nature of mentalese,let alne general agreement on its nature.)
Ihave dealt at least briefly here with physicalobjects (from the points of view of all senses),properties, actions (to a slight degree - I dohave what I feel is a reasonable account), cause-effect relationships, aspects of the mind-bodyproblem, as well as a number of other concepts.What is missing?
The two major areas I am awareof are (i) quantification (I suggest this couldbe handled by assuming that its origins are inoperations on finite sets); and (2) logicaloperations (probably these also need to be innate).Afterthoughts and acknowledgementsIt has been a long time since I read Koffka\[1935\] and Piaget's works (e.g.
\[1967\] and\[Piaget & !nhalder 1967\]), but clearly many of theideas in this paper can be traced to those twosources.
I had not read Jacendoff's \[1978\] paperin this volume before writing this paper, but Iwish I had been able to.I would especially like to acknowledge theideas and criticisms I have received in conver-sations with Bill Woods, Phil Johnson-Laird, HarryKlopf, Lois Boggess, and Jeff Gibbons.ReferencesBajcsy, R. and Joshi, A.
(1978), The problem ofnaming shapes: vision-language interface.
InTINLAP-2.Basso, K. H. (1968), The western apache classifi-catory verb system: a formal analysis.
South-western Journal of Anthropology 24, 252-266.Bobrow, D. G. and Winograd, T. (1977), An overviewof KRL, a knowledge representation language.Cognitive Science I, i, 1977.Clark, H. H. (1973).
Space, time, semantics, andthe child.
In T. E. Moore (ed.)
CognitiveDevelopment and the Acquisition of Language,Academic Press, N.Y., 27-63.Collins, A. and Loftus, E. (1975), A spreadingactivation theory of semantic processing.Psycholo$ical Review 82, (5).Dennett, D. (1974), Cited by Woods \[1978\] assource of many ideas; I could not locatecitation.Feldman, H., Goldin-Meadow, S. and Gleitman, L.(1977), Beyond Herodotus: The creation oflanguage by linguistically deprived deafchildred.
In A.
Lock (ed.)
Action~ Gesture andSymbol: The Emergence of Language, AcademicPress.Fillmore, C. (1977).
The case for case reopened.Draft of paper to appear in Syntax and Semanticsseries.Fodor, J.
(1975), The language of thought.
NewYork: Crowell.Goguen N. (1973), A procedural description ofspatial prepositions.
(M.S.
thesis) Universityof Pennsylvania, Dept.
of ComputerGrosz, B. J, (1978), Focussing in dialog.
InTINLAP-2,Gruber, J. S. (1965), Studies in lexical relations.Unpublished Ph.D. dissertation, MIT, Cambridge,MA.Jackendoff, R. (1975), A system of semanticprimitives.
In R. Schank and B.
Nash-Webber(eds.)
Theoretical Issues in Natural LanguageProcessin$, ACL, Arlington, VA.Jackendoff, R. (1978), An argument about thecomposftion of conceptual structure.
InTINLAP-2.Johnson-Laird (1978), Mental models of meaning.Paper presented at the Sloan Workshop onComputational Aspects of Linguistic Structureand Discourse Setting, University of Pennsyl-vania, May 1978~155Koffka, K. (1935), Principles of gestalt psychology,Harcourt Brace, New York.Kosslyn, S. M. (1978), On the ontological statusof visual mental images.
In TINLAP-2.Kuipers, B. J.
(1975), A frame for frames:representing knowledge for recognition.
InD.
Bobrow & A. Collins, Representation andUnderstanding, Academic, New York, 151-184.Lakoff, G. (1978), Comments during colloquium atDept.
of Linguistics, Univ.
of Illinois,April 1978.Marcus, M. (1978), A computational account ofsome constraints on language.
In TINLAP-2.Miller, G. A. and Johnson-Laird, P. (1976),LanEuage and Perception, Harvard UniversityPress, Cambridge, MA.Minsky, M. L. (1975), A framework for repre-senting knowledge.
In Winston (ed.)
ThePsychology of Computer Vision, McGraw-Hill,N.Y.Novak, G. S. (1976), Computer understanding ofphysics problems stated in natural language.Tech.
Report NL-30, Dept.
of Computer Science,Univ.
of Texas, Austin.Piaget, J.
(1967), Six Psychological Studies.Vintage, New York.Piaget, J. and Inhelder, B.
(1967\], The Child'sConception of Space.
Norton, New York.Preparata, F P. and Ray, S. R. (1972), Anapproach to artificial nonsymbolic cognition.Information Sciences 4, 65-86.Pugh, G. E. (1977), The Biological Origin ofHuman Values, Basic Books, New York.Pylyshyn, Z. W. (1973), What the mind's ege tellsthe mind's brain: a critique of mental imagery.Psychological Bulletin 80, i, 1-24.Pylyshyn, Z. W. (1977a).
What does it take tobookstrap a language?
In Language Learningand Thought, Academic Press, N.Y., 37-45.Pylyshyn, Z. W. (1977b), Children's internaldescriptions.
In Language, Learning, andThought, Academic Press, N.Y., 169-176.Pylyshyn, Z. W. (1978), What has language to dowith perception?
Some speculations on theLinguamentis.
In TINLAP-2.Reddy, M. (1977), Remarks delivered at the Con-ference on Metaphor and Thought, Universityof Illinois, Urbana, Sept. 1977.Schank, R. C. (1973), The development of conceptualstructures in children.
Memo AIM-203, StanfordAI Lab., Stanford, CA.Schank, R. C. (1975), The primitive ACTs ofconceptual dependency.
In R. Schank & B. Nash-Webber, Theoretical Issues in Natural LanguageProcessing, ACL, Arlington, VA, 34-7.Schank, R. C. and Abelson, R. P. (1977), Scripts,Plans~ Goals~ and Understanding, LawrenceErlbaum, N.J.Schank, R. C. and Selfridge, M. (1977), How tolearn/what to learn.
Proceedings of the 5thInt'l Joint Conf.
on Artificial Intelligence,MIT, Cambridge, MA, 8-14.Sin~nons, R. F. (1975), The Clowns Microworld.In R. Schank and B. Nash-Webber (eds.
)Theoretical Issues in Natural LanguageProcessing, ACL, Arlington, VA.Tenenbaum, M. and Wayl, S. (1975), A regionanalysis subsystem for interactive sceneanalysis.
Advance Papers of the 4th Int'l.Joint Conf.
on Artificial Intelligence, Tbilisi,USSR, 682-7.Waltz, D. L. (1978), A model for low level vision.In A. Hanson & E. Riseman (eds.)
Machine Vision,Academic Press, N.Y. (to appear).Whorl, B. L. (1956), Language, Thought andReality, MIT Press, Cambridge, MA.Wilber, K. (1977), The Spectrum of Consciousness,Quest.Winston, P. H. (1975), Learning structural des-criptions from examples.
In Winston (ed.
)The Psychology of Computer Vision, McGraw-Hill,NY.Woods, W. A.
(1978), Procedural semantics as atheory of meaning.
Draft of paper presentedat Sloan Workshop on Computational Aspects ofLinguistic Structure and Discourse Setting,Univ.
of Pennsylvania, May 1978.Yakimovsky, Y.
(1973), A semantics - based deci-sion theory region analyzer.
Advance papersof the 3rd Int'l Joint Conf.
on ArtificialIntelligence, Stanford, CA, 580-8.Zucker, S., Rosenfeld, A., and Davis, (1975),General purpose models: expectations aboutthe unexpected.
Advance Papers of the 4thInt'l Joint Conf.
on Artificial Intelligence,Tbilisi USSR, 716-21.156
