Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 320?327,Prague, Czech Republic, June 2007. c?2007 Association for Computational LinguisticsGenerating Constituent Order in German ClausesKatja Filippova and Michael StrubeEML Research gGmbHSchloss-Wolfsbrunnenweg 3369118 Heidelberg, Germanyhttp://www.eml-research.de/nlpAbstractWe investigate the factors which determineconstituent order in German clauses and pro-pose an algorithm which performs the taskin two steps: First, the best candidate forthe initial sentence position is chosen.
Then,the order for the remaining constituents isdetermined.
The first task is more difficultthan the second one because of propertiesof the German sentence-initial position.
Ex-periments show a significant improvementover competing approaches.
Our algorithmis also more efficient than these.1 IntroductionMany natural languages allow variation in the wordorder.
This is a challenge for natural language gen-eration and machine translation systems, or for textsummarizers.
E.g., in text-to-text generation (Barzi-lay & McKeown, 2005; Marsi & Krahmer, 2005;Wan et al, 2005), new sentences are fused from de-pendency structures of input sentences.
The last stepof sentence fusion is linearization of the resultingparse.
Even for English, which is a language withfixed word order, this is not a trivial task.German has a relatively free word order.
Thisconcerns the order of constituents1 within sentenceswhile the order of words within constituents is rela-tively rigid.
The grammar only partially prescribeshow constituents dependent on the verb should beordered, and for many clauses each of the n!
possi-ble permutations of n constituents is grammatical.1Henceforth, we will use this term to refer to constituentsdependent on the clausal top node, i.e.
a verb, only.In spite of the permanent interest in German wordorder in the linguistics community, most studieshave limited their scope to the order of verb argu-ments and few researchers have implemented ?
andeven less evaluated ?
a generation algorithm.
In thispaper, we present an algorithm, which orders notonly verb arguments but all kinds of constituents,and evaluate it on a corpus of biographies.
Foreach parsed sentence in the test set, our maximum-entropy-based algorithm aims at reproducing the or-der found in the original text.
We investigate theimportance of different linguistic factors and sug-gest an algorithm to constituent ordering which firstdetermines the sentence initial constituent and thenorders the remaining ones.
We provide evidencethat the task requires language-specific knowledgeto achieve better results and point to the most diffi-cult part of it.
Similar to Langkilde & Knight (1998)we utilize statistical methods.
Unlike overgenera-tion approaches (Varges & Mellish, 2001, inter alia)which select the best of all possible outputs ours ismore efficient, because we do not need to generateevery permutation.2 Theoretical Premises2.1 BackgroundIt has been suggested that several factors have an in-fluence on German constituent order.
Apart fromthe constraints posed by the grammar, informationstructure, surface form, and discourse status havealso been shown to play a role.
It has also beenobserved that there are preferences for a particularorder.
The preferences summarized below have mo-320tivated our choice of features:?
constituents in the nominative case precedethose in other cases, and dative constituentsoften precede those in the accusative case(Uszkoreit, 1987; Keller, 2000);?
the verb arguments?
order depends on theverb?s subcategorization properties (Kurz,2000);?
constituents with a definite article precedethose with an indefinite one (Weber & Mu?ller,2004);?
pronominalized constituents precede non-pronominalized ones (Kempen & Harbusch,2004);?
animate referents precede inanimate ones (Pap-pert et al, 2007);?
short constituents precede longer ones (Kim-ball, 1973);?
the preferred topic position is right after theverb (Frey, 2004);?
the initial position is usually occupied byscene-setting elements and topics (Speyer,2005).?
there is a default order based on semantic prop-erties of constituents (Sgall et al, 1986):Actor < Temporal < SpaceLocative < Means < Ad-dressee < Patient < Source < Destination < PurposeNote that most of these preferences were identifiedin corpus studies and experiments with native speak-ers and concern the order of verb arguments only.Little has been said so far about how non-argumentsshould be ordered.German is a verb second language, i.e., the po-sition of the verb in the main clause is determinedexclusively by the grammar and is insensitive toother factors.
Thus, the German main clause is di-vided into two parts by the finite verb: Vorfeld (VF),which contains exactly one constituent, and Mit-telfeld (MF), where the remaining constituents arelocated.
The subordinate clause normally has onlyMF.
The VF and MF are marked with brackets inExample 1:(1) [Au?erdem]Apart from thatentwickeltedeveloped[LummerLummereineaQuecksilberdampflampe,Mercury-vapor lampumtomonochromatischesmonochromeLichtlightherzustellen].produce.
?Apart from that, Lummer developed aMercury-vapor lamp to produce monochromelight?.2.2 Our HypothesisThe essential contribution of our study is that wetreat preverbal and postverbal parts of the sentencedifferently.
The sentence-initial position, which inGerman is the VF, has been shown to be cognitivelymore prominent than other positions (Gernsbacher& Hargreaves, 1988).
Motivated by the theoreticalwork by Chafe (1976) and Jacobs (2001), we viewthe VF as the place for elements which modify thesituation described in the sentence, i.e.
for so calledframe-setting topics (Jacobs, 2001).
For example,temporal or locational constituents, or anaphoric ad-verbs are good candidates for the VF.
We hypoth-esize that the reasons which bring a constituent tothe VF are different from those which place it, say,to the beginning of the MF, for the order in the MFhas been shown to be relatively rigid (Keller, 2000;Kempen & Harbusch, 2004).
Speakers have thefreedom of selecting the outgoing point for a sen-tence.
Once they have selected it, the remaining con-stituents are arranged in the MF, mainly according totheir grammatical properties.This last observation motivates another hypothe-sis we make: The cumulation of the properties ofa constituent determines its salience.
This saliencecan be calculated and used for ordering with a sim-ple rule stating that more salient constituents shouldprecede less salient ones.
In this case there is noneed to generate all possible orders and rank them.The best order can be obtained from a random oneby sorting.
Our experiments support this view.
Atwo-step approach, which first selects the best can-didate for the VF and then arranges the remainingconstituents in the MF with respect to their salienceperforms better than algorithms which generate theorder for a sentence as a whole.3213 Related WorkUszkoreit (1987) addresses the problem from amostly grammar-based perspective and suggestsweighted constraints, such as [+NOM] ?
[+DAT],[+PRO] ?
[?PRO], [?FOCUS] ?
[+FOCUS], etc.Kruijff et al (2001) describe an architecturewhich supports generating the appropriate word or-der for different languages.
Inspired by the findingsof the Prague School (Sgall et al, 1986) and Sys-temic Functional Linguistics (Halliday, 1985), theyfocus on the role that information structure playsin constituent ordering.
Kruijff-Korbayova?
et al(2002) address the task of word order generation inthe same vein.
Similar to ours, their algorithm rec-ognizes the special role of the sentence-initial po-sition which they reserve for the theme ?
the pointof departure of the message.
Unfortunately, they didnot implement their algorithm, and it is hard to judgehow well the system would perform on real data.Harbusch et al (2006) present a generation work-bench, which has the goal of producing not the mostappropriate order, but all grammatical ones.
Theyalso do not provide experimental results.The work of Uchimoto et al (2000) is done onthe free word order language Japanese.
They de-termine the order of phrasal units dependent on thesame modifiee.
Their approach is similar to ours inthat they aim at regenerating the original order froma dependency parse, but differs in the scope of theproblem as they regenerate the order of modifers forall and not only for the top clausal node.
Using amaximum entropy framework, they choose the mostprobable order from the set of all permutations of nwords by the following formula:P (1|h) = P ({Wi,i+j = 1|1 ?
i ?
n?
1, 1 ?
j ?
n?
i}|h)?n?1Yi=1n?iYj=1P (Wi,i+j = 1|hi,i+j)=n?1Yi=1n?iYj=1PME(1|hi,i+j)(1)For each permutation, for every pair of words , theymultiply the probability of their being in the correct2order given the history h. Random variable Wi,i+j2Only reference orders are assumed to be correct.is 1 if word wi precedes wi+j in the reference sen-tence, 0 otherwise.
The features they use are akinto those which play a role in determining Germanword order.
We use their approach as a non-trivialbaseline in our study.Ringger et al (2004) aim at regenerating the or-der of constituents as well as the order within themfor German and French technical manuals.
Utilizingsyntactic, semantic, sub-categorization and lengthfeatures, they test several statistical models to findthe order which maximizes the probability of an or-dered tree.
Using ?Markov grammars?
as the start-ing point and conditioning on the syntactic categoryonly, they expand a non-terminal node C by predict-ing its daughters from left to right:P (C|h) =nYi=1P (di|di?1, ..., di?j , c, h) (2)Here, c is the syntactic category of C, d and hare the syntactic categories of C?s daughters and thedaughter which is the head of C respectively.In their simplest system, whose performance isonly 2.5% worse than the performance of the bestone, they condition on both syntactic categories andsemantic relations (?)
according to the formula:P (C|h) =nYi=1?P (?i|di?1, ?i?1, ...di?j , ?i?j , c, h)?P (di|?i, di?1, ?i?1..., di?j , ?i?j , c, h)?
(3)Although they test their system on German data,it is hard to compare their results to ours directly.First, the metric they use does not describe the per-formance appropriately (see Section 6.1).
Second,while the word order within NPs and PPs as well asthe verb position are prescribed by the grammar to alarge extent, the constituents can theoretically be or-dered in any way.
Thus, by generating the order forevery non-terminal node, they combine two tasks ofdifferent complexity and mix the results of the moredifficult task with those of the easier one.4 DataThe data we work with is a collection of biogra-phies from the German version of Wikipedia3.
Fullyautomatic preprocessing in our system comprisesthe following steps: First, a list of people of acertain Wikipedia category is taken and an articleis extracted for every person.
Second, sentence3http://de.wikipedia.org322entwickelteum herzustellen SUBmonochromatisches Lichteine Quecksilberdampflampe OBJAau?erdem ADV (conn)Lummer SUBJ (pers)Figure 1: The representation of the sentence in Example 1boundaries are identified with a Perl CPAN mod-ule4 whose performance we improved by extend-ing the list of abbreviations.
Next, the sentencesare split into tokens.
The TnT tagger (Brants, 2000)and the TreeTagger (Schmid, 1997) are used for tag-ging and lemmatization.
Finally, the articles areparsed with the CDG dependency parser (Foth &Menzel, 2006).
Named entities are classified accord-ing to their semantic type using lists and categoryinformation from Wikipedia: person (pers), location(loc), organization (org), or undefined named entity(undef ne).
Temporal expressions (Oktober 1915,danach (after that) etc.)
are identified automaticallyby a set of patterns.
Inevitable during automatic an-notation, errors at one of the preprocessing stagescause errors at the ordering stage.Distinguishing between main and subordinateclauses, we split the total of about 19 000 sentencesinto training, development and test sets (Table 1).Clauses with one constituent are sorted out as trivial.The distribution of both types of clauses accordingto their length in constituents is given in Table 2.train dev testmain 14324 3344 1683sub 3304 777 408total 17628 4121 2091Table 1: Size of the data sets in clauses2 3 4 5 6+main 20% 35% 27% 12% 6%sub 49% 35% 11% 2% 3%Table 2: Proportion of clauses with certain lengths4http://search.cpan.org/?holsten/Lingua-DE-Sentence-0.07/Sentence.pmGiven the sentence in Example 1, we first trans-form its dependency parse into a more generalrepresentation (Figure 15) and then, based on thepredictions of our learner, arrange the four con-stituents.
For evaluation, we compare the arrangedorder against the original one.Note that we predict neither the position of theverb, nor the order within constituents as the formeris explicitly determined by the grammar, and the lat-ter is much more rigid than the order of constituents.5 Baselines and AlgorithmsWe compare the performance of two our algorithmswith four baselines.5.1 RandomWe improve a trivial random baseline (RAND) bytwo syntax-oriented rules: the first position is re-served for the subject and the second for the directobject if there is any; the order of the remaining con-stituents is generated randomly (RAND IMP).5.2 Statistical Bigram ModelSimilar to Ringger et al (2004), we find the orderwith the highest probability conditioned on syntac-tic and semantic categories.
Unlike them we use de-pendency parses and compute the probability of thetop node only, which is modified by all constituents.With these adjustments the probability of an orderO given the history h, if conditioned on syntacticfunctions of constituents (s1...sn), is simply:P (O|h) =n?i=1P (si|si?1, h) (4)Ringger et al (2004) do not make explicit, whattheir set of semantic relations consists of.
From the5OBJA stands for the accusative object.323example in the paper, it seems that these are a mix-ture of lexical and syntactic information6.
Our anno-tation does not specify semantic relations.
Instead,some of the constituents are categorized as pers, loc,temp, org or undef ne if their heads bear one of theselabels.
By joining these with possible syntactic func-tions, we obtain a larger set of syntactic-semantictags as, e.g., subj-pers, pp-loc, adv-temp.
We trans-form each clause in the training set into a sequenceof such tags, plus three tags for the verb position (v),the beginning (b) and the end (e) of the clause.
Thenwe compute the bigram probabilities7.For our third baseline (BIGRAM), we select fromall possible orders the one with the highest probabil-ity as calculated by the following formula:P (O|h) =n?i=1P (ti|ti?1, h) (5)where ti is from the set of joined tags.
For Example1, possible tag sequences (i.e.
orders) are ?b subj-pers v adv obja sub e?, ?b adv v subj-pers obja sube?, ?b obja v adv sub subj-pers e?, etc.5.3 UchimotoFor the fourth baseline (UCHIMOTO), we utilized amaximum entropy learner (OpenNLP8) and reim-plemented the algorithm of Uchimoto et al (2000).For every possible permutation, its probability is es-timated according to Formula (1).
The binary clas-sifier, whose task was to predict the probability thatthe order of a pair of constituents is correct, wastrained on the following features describing the verbor hc ?
the head of a constituent c9:vlex, vpass, vmod the lemma of the root of theclause (non-auxiliary verb), the voice of theverb and the number of constituents to order;lex the lemma of hc or, if hc is a functional word,the lemma of the word which depends on it;pos part-of-speech tag of hc;6E.g.
DefDet, Coords, Possr, werden7We use the CMU Toolkit (Clarkson & Rosenfeld, 1997).8http://opennlp.sourceforge.net9We disregarded features which use information specific toJapanese and non-applicable to German (e.g.
on postpositionalparticles).sem if defined, the semantic class of c; e.g.
im April1900 and mit Albert Einstein (with Albert Ein-stein) are classified temp and pers respectively;syn, same the syntactic function of hc and whetherit is the same for the two constituents;mod number of modifiers of hc;rep whether hc appears in the preceding sentence;pro whether c contains a (anaphoric) pronoun.5.4 Maximum EntropyThe first configuration of our system is an extendedversion of the UCHIMOTO baseline (MAXENT).
Tothe features describing c we added the followingones:det the kind of determiner modifying hc (def, indef,non-appl);rel whether hc is modified by a relative clause (yes,no, non-appl);dep the depth of c;len the length of c in words.The first two features describe the discourse statusof a constituent; the other two provide informationon its ?weight?.
Since our learner treats all valuesas nominal, we discretized the values of dep and lenwith a C4.5 classifier (Kohavi & Sahami, 1996).Another modification concerns the efficiency ofthe algorithm.
Instead of calculating probabilitiesfor all pairs, we obtain the right order from a randomone by sorting.
We compare adjacent elements byconsulting the learner as if we would sort an array ofnumbers.
Given two adjacent constituents, ci < cj ,we check the probability of their being in the rightorder, i.e.
that ci precedes cj : Ppre(ci, cj).
If it isless than 0.5, we transpose the two and compare ciwith the next one.Since the sorting method presupposes that the pre-dicted relation is transitive, we checked whether thisis really so on the development and test data sets.
Welooked for three constituents ci, cj , ck from a sen-tence S, such that Ppre(ci, cj) > 0.5, Ppre(cj , ck) >0.5, Ppre(ci, ck) < 0.5 and found none.
Therefore,unlike UCHIMOTO, where one needs to make exactlyN !
?
N(N ?
1)/2 comparisons, we have to makeN(N ?
1)/2 comparisons at most.3245.5 The Two-Step ApproachThe main difference between our first algorithm(MAXENT) and the second one (TWO-STEP) is thatwe generate the order in two steps10 (both classifiersare trained on the same features):1.
For the VF, using the OpenNLP maximum en-tropy learner for a binary classification (VF vs.MF), we select the constituent c with the high-est probability of being in the VF.2.
For the MF, the remaining constituents are putinto a random order and then sorted the way itis done for MAXENT.
The training data for thesecond task was generated only from the MF ofclauses.6 Results6.1 Evaluation MetricsWe use several metrics to evaluate our systems andthe baselines.
The first is per-sentence accuracy(acc) which is the proportion of correctly regener-ated sentences.
Kendall?s ?
, which has been used forevaluating sentence ordering tasks (Lapata, 2006),is the second metric we use.
?
is calculated as1?
4 tN(N?1) , where t is the number of interchangesof consecutive elements to arrange N elements inthe right order.
?
is sensitive to near misses andassigns abdc (almost correct order) a score of 0.66while dcba (inverse order) gets ?1.
Note that it isquestionable whether this metric is as appropriatefor word ordering tasks as for sentence ordering onesbecause a near miss might turn out to be ungrammat-ical whereas a more different order stays acceptable.Apart from acc and ?
, we also adopt the metricsused by Uchimoto et al (2000) and Ringger et al(2004).
The former use agreement rate (agr) cal-culated as 2pN(N?1) : the number of correctly orderedpairs of constituents over the total number of all pos-sible pairs, as well as complete agreement which isbasically per-sentence accuracy.
Unlike ?
, whichhas ?1 as the lowest score, agr ranges from 0 to 1.Ringger et al (2004) evaluate the performance onlyin terms of per-constituent edit distance calculatedas mN , where m is the minimum number of moves1110Since subordinate clauses do not have a VF, the first step isnot needed.11A move is a deletion combined with an insertion.needed to arrange N constituents in the right order.This measure seems less appropriate than ?
or agrbecause it does not take the distance of the move intoaccount and scores abced and eabcd equally (0.2).Since ?
and agr, unlike edit distance, give higherscores to better orders, we compute inverse distance:inv = 1 ?
edit distance instead.
Thus, all three met-rics (?
, agr, inv) give the maximum of 1 if con-stituents are ordered correctly.
However, like ?
, agrand inv can give a positive score to an ungrammat-ical order.
Hence, none of the evaluation metricsdescribes the performance perfectly.
Human eval-uation which reliably distinguishes between appro-priate, acceptable, grammatical and ingrammaticalorders was out of choice because of its high cost.6.2 ResultsThe results on the test data are presented in Table3.
The performance of TWO-STEP is significantlybetter than any other method (?2, p < 0.01).
Theperformance of MAXENT does not significantly dif-fer from UCHIMOTO.
BIGRAM performed about asgood as UCHIMOTO and MAXENT.
We also checkedhow well TWO-STEP performs on each of the twosub-tasks (Table 4) and found that the VF selectionis considerably more difficult than the sorting part.acc ?
agr invRAND 15% 0.02 0.51 0.64RAND IMP 23% 0.24 0.62 0.71BIGRAM 51% 0.60 0.80 0.83UCHIMOTO 50% 0.65 0.82 0.83MAXENT 52% 0.67 0.84 0.84TWO-STEP 61% 0.72 0.86 0.87Table 3: Per-clause mean of the resultsThe most important conclusion we draw from theresults is that the gain of 9% accuracy is due to theVF selection only, because the feature sets are iden-tical for MAXENT and TWO-STEP.
From this fol-lows that doing feature selection without splittingthe task in two is ineffective, because the importanceof a feature depends on whether the VF or the MF isconsidered.
For the MF, feature selection has shownsyn and pos to be the most relevant features.
Theyalone bring the performance in the MF up to 75%.
Incontrast, these two features explain only 56% of the325cases in the VF.
This implies that the order in the MFmainly depends on grammatical features, while forthe VF all features are important because removal ofany feature caused a loss in accuracy.acc ?
agr invTWO-STEP VF 68% - - -TWO-STEP MF 80% 0.92 0.96 0.95Table 4: Mean of the results for the VF and the MFAnother important finding is that there is no needto overgenerate to find the right order.
Insignificantfor clauses with two or three constituents, for clauseswith 10 constituents, the number of comparisons isreduced drastically from 163,296,000 to 45.According to the inv metric, our results are con-siderably worse than those reported by Ringger et al(2004).
As mentioned in Section 3, the fact that theygenerate the order for every non-terminal node se-riously inflates their numbers.
Apart from that, theydo not report accuracy, and it is unknown, how manysentences they actually reproduced correctly.6.3 Error AnalysisTo reveal the main error sources, we analyzed incor-rect predictions concerning the VF and the MF, onehundred for each.
Most errors in the VF did not leadto unacceptability or ungrammaticality.
From lexi-cal and semantic features, the classifier learned thatsome expressions are often used in the beginning ofa sentence.
These are temporal or locational PPs,anaphoric adverbials, some connectives or phrasesstarting with unlike X, together with X, as X, etc.Such elements were placed in the VF instead of thesubject and caused an error although both variantswere equally acceptable.
In other cases the classi-fier could not find a better candidate but the subjectbecause it could not conclude from the provided fea-tures that another constituent would nicely introducethe sentence into the discourse.
Mainly this con-cerns recognizing information familiar to the readernot by an already mentioned entity, but one which isinferrable from what has been read.In the MF, many orders had a PP transposed withthe direct object.
In some cases the predicted orderseemed as good as the correct one.
Often the algo-rithm failed at identifying verb-specific preferences:E.g., some verbs take PPs with the locational mean-ing as an argument and normally have them rightnext to them, whereas others do not.
Another fre-quent error was the wrong placement of superficiallyidentical constituents, e.g.
two PPs of the same size.To handle this error, the system needs more spe-cific semantic information.
Some errors were causedby the parser, which created extra constituents (e.g.false PP or adverb attachment) or confused the sub-ject with the direct verb.We retrained our system on a corpus of newspaperarticles (Telljohann et al, 2003, Tu?Ba-D/Z) which ismanually annotated but encodes no semantic knowl-edge.
The results for the MF were the same as on thedata from Wikipedia.
The results for the VF weremuch worse (45%) because of the lack of semanticinformation.7 ConclusionWe presented a novel approach to ordering con-stituents in German.
The results indicate that alinguistically-motivated two-step system, which firstselects a constituent for the initial position and thenorders the remaining ones, works significantly betterthan approaches which do not make this separation.Our results also confirm the hypothesis ?
which hasbeen attested in several corpus studies ?
that the or-der in the MF is rather rigid and dependent on gram-matical properties.We have also demonstrated that there is no needto overgenerate to find the best order.
On a prac-tical side, this finding reduces the amount of workconsiderably.
Theoretically, it lets us conclude thatthe relatively fixed order in the MF depends on thesalience which can be predicted mainly from gram-matical features.
It is much harder to predict whichelement should be placed in the VF.
We suppose thatthis difficulty comes from the double function of theinitial position which can either introduce the ad-dressation topic, or be the scene- or frame-settingposition (Jacobs, 2001).Acknowledgements: This work has been fundedby the Klaus Tschira Foundation, Heidelberg, Ger-many.
The first author has been supported by a KTFgrant (09.009.2004).
We would also like to thankElke Teich and the three anonymous reviewers fortheir useful comments.326ReferencesBarzilay, R. & K. R. McKeown (2005).
Sentence fusion formultidocument news summarization.
Computational Lin-guistics, 31(3):297?327.Brants, T. (2000).
TnT ?
A statistical Part-of-Speech tagger.
InProceedings of the 6th Conference on Applied Natural Lan-guage Processing, Seattle, Wash., 29 April ?
4 May 2000,pp.
224?231.Chafe, W. (1976).
Givenness, contrastiveness, definiteness, sub-jects, topics, and point of view.
In C. Li (Ed.
), Subject andTopic, pp.
25?55.
New York, N.Y.: Academic Press.Clarkson, P. & R. Rosenfeld (1997).
Statistical language mod-eling using the CMU-Cambridge toolkit.
In Proceedingsof the 5th European Conference on Speech Communicationand Technology, Rhodes, Greece, 22-25 September 1997, pp.2707?2710.Foth, K. & W. Menzel (2006).
Hybrid parsing: Using proba-bilistic models as predictors for a symbolic parser.
In Pro-ceedings of the 21st International Conference on Computa-tional Linguistics and 44th Annual Meeting of the Associa-tion for Computational Linguistics, Sydney, Australia, 17?21 July 2006, pp.
321?327.Frey, W. (2004).
A medial topic position for German.
Linguis-tische Berichte, 198:153?190.Gernsbacher, M. A.
& D. J. Hargreaves (1988).
Accessing sen-tence participants: The advantage of first mention.
Journalof Memory and Language, 27:699?717.Halliday, M. A. K. (1985).
Introduction to Functional Gram-mar.
London, UK: Arnold.Harbusch, K., G. Kempen, C. van Breugel & U. Koch (2006).A generation-oriented workbench for performance grammar:Capturing linear order variability in German and Dutch.
InProceedings of the International Workshop on Natural Lan-guage Generation, Sydney, Australia, 15-16 July 2006, pp.9?11.Jacobs, J.
(2001).
The dimensions of topic-comment.
Linguis-tics, 39(4):641?681.Keller, F. (2000).
Gradience in Grammar: Experimentaland Computational Aspects of Degrees of Grammaticality,(Ph.D. thesis).
University of Edinburgh.Kempen, G. & K. Harbusch (2004).
How flexible is con-stituent order in the midfield of German subordinate clauses?A corpus study revealing unexpected rigidity.
In Proceed-ings of the International Conference on Linguistic Evidence,Tu?bingen, Germany, 29?31 January 2004, pp.
81?85.Kimball, J.
(1973).
Seven principles of surface structure parsingin natural language.
Cognition, 2:15?47.Kohavi, R. & M. Sahami (1996).
Error-based and entropy-baseddiscretization of continuous features.
In Proceedings of the2nd International Conference on Data Mining and Knowl-edge Discovery, Portland, Oreg., 2?4 August, 1996, pp.
114?119.Kruijff, G.-J., I.
Kruijff-Korbayova?, J. Bateman & E. Teich(2001).
Linear order as higher-level decision: Informationstructure in strategic and tactical generation.
In Proceedingsof the 8th European Workshop on Natural Language Gener-ation, Toulouse, France, 6-7 July 2001, pp.
74?83.Kruijff-Korbayova?, I., G.-J.
Kruijff & J. Bateman (2002).
Gen-eration of appropriate word order.
In K. van Deemter &R. Kibble (Eds.
), Information Sharing: Reference and Pre-supposition in Language Generation and Interpretation, pp.193?222.
Stanford, Cal.
: CSLI.Kurz, D. (2000).
A statistical account on word order variationin German.
In A.
Abeille?, T. Brants & H. Uszkoreit (Eds.
),Proceedings of the COLING Workshop on Linguistically In-terpreted Corpora, Luxembourg, 6 August 2000.Langkilde, I.
& K. Knight (1998).
Generation that exploitscorpus-based statistical knowledge.
In Proceedings of the17th International Conference on Computational Linguisticsand 36th Annual Meeting of the Association for Computa-tional Linguistics, Montre?al, Que?bec, Canada, 10?14 August1998, pp.
704?710.Lapata, M. (2006).
Automatic evaluation of information order-ing: Kendall?s tau.
Computational Linguistics, 32(4):471?484.Marsi, E. & E. Krahmer (2005).
Explorations in sentence fu-sion.
In Proceedings of the European Workshop on Nat-ural Language Generation, Aberdeen, Scotland, 8?10 Au-gust, 2005, pp.
109?117.Pappert, S., J. Schliesser, D. P. Janssen & T. Pechmann (2007).Corpus- and psycholinguistic investigations of linguisticconstraints on German word order.
In A. Steube (Ed.
),The discourse potential of underspecified structures: Eventstructures and information structures.
Berlin, New York:Mouton de Gruyter.
In press.Ringger, E., M. Gamon, R. C. Moore, D. Rojas, M. Smets &S. Corston-Oliver (2004).
Linguistically informed statisticalmodels of constituent structure for ordering in sentence real-ization.
In Proceedings of the 20th International Conferenceon Computational Linguistics, Geneva, Switzerland, 23?27August 2004, pp.
673?679.Schmid, H. (1997).
Probabilistic Part-of-Speech tagging usingdecision trees.
In D. Jones & H. Somers (Eds.
), New Methodsin Language Processing, pp.
154?164.
London, UK: UCLPress.Sgall, P., E. Hajic?ova?
& J. Panevova?
(1986).
The Meaning of theSentence in Its Semantic and Pragmatic Aspects.
Dordrecht,The Netherlands: D. Reidel.Speyer, A.
(2005).
Competing constraints on Vorfeldbesetzungin German.
In Proceedings of the Constraints in DiscourseWorkshop, Dortmund, 3?5 July 2005, pp.
79?87.Telljohann, H., E. W. Hinrichs & S. Ku?bler (2003).
Stylebookfor the Tu?bingen treebank of written German (Tu?Ba-D/Z.Technical Report: Seminar fu?r Sprachwissenschaft, Univer-sita?t Tu?bingen, Tu?bingen, Germany.Uchimoto, K., M. Murata, Q. Ma, S. Sekine & H. Isahara(2000).
Word order acquisition from corpora.
In Proceedingsof the 18th International Conference on Computational Lin-guistics, Saarbru?cken, Germany, 31 July ?
4 August 2000,pp.
871?877.Uszkoreit, H. (1987).
Word Order and Constituent Structure inGerman.
CSLI Lecture Notes.
Stanford: CSLI.Varges, S. & C. Mellish (2001).
Instance-based natural lan-guage generation.
In Proceedings of the 2nd Conference ofthe North American Chapter of the Association for Compu-tational Linguistics, Pittsburgh, Penn., 2?7 June, 2001, pp.1?8.Wan, S., R. Dale, M. Dras & C. Paris (2005).
Searching forgrammaticality and consistency: Propagating dependenciesin the Viterbi algorithm.
In Proceedings of the 10th Euro-pean Workshop on Natural Language Generation, Aberdeen,Scotland, 8?10 August, 2005, pp.
211?216.Weber, A.
& K. Mu?ller (2004).
Word order variation in Ger-man main clauses: A corpus analysis.
In Proceedings ofthe 5th International Workshop on Linguistically InterpretedCorpora, 29 August, 2004, Geneva, Switzerland, pp.
71?77.327
