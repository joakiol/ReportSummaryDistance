Proceedings of the 3rd Workshop on Computational Approaches to Subjectivity and Sentiment Analysis, page 1,Jeju, Republic of Korea, 12 July 2012. c?2012 Association for Computational LinguisticsMultimodal Sentiment Analysis(Abstract of Invited Talk)Rada MihalceaDepartment of Computer Science and EngineeringUniversity of North TexasP.
O.
Box 311366Denton, TX 76203-6886, U.S.A.rada@cs.unt.eduAbstractWith more than 10,000 new videos postedonline every day on social websites such asYouTube and Facebook, the internet is be-coming an almost infinite source of informa-tion.
One important challenge for the com-ing decade is to be able to harvest relevantinformation from this constant flow of mul-timodal data.
In this talk, I will introducethe task of multimodal sentiment analysis, andpresent a method that integrates linguistic, au-dio, and visual features for the purpose ofidentifying sentiment in online videos.
I willfirst describe a novel dataset consisting ofvideos collected from the social media web-site YouTube, which were annotated for senti-ment polarity.
I will then show, through com-parative experiments, that the joint use of vi-sual, audio, and textual features greatly im-proves over the use of only one modality ata time.
Finally, by running evaluations ondatasets in English and Spanish, I will showthat the method is portable and works equallywell when applied to different languages.This is joint work with Veronica Perez-Rosasand Louis-Philippe Morency.1
