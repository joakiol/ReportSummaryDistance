Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 985?993,Suntec, Singapore, 2-7 August 2009. c?2009 ACL and AFNLPAn Optimal-Time Binarization Algorithmfor Linear Context-Free Rewriting Systems with Fan-Out TwoCarlos Go?mez-Rodr?
?guezDepartamento de Computacio?nUniversidade da Corun?a, Spaincgomezr@udc.esGiorgio SattaDepartment of Information EngineeringUniversity of Padua, Italysatta@dei.unipd.itAbstractLinear context-free rewriting systems(LCFRSs) are grammar formalisms withthe capability of modeling discontinu-ous constituents.
Many applications useLCFRSs where the fan-out (a measure ofthe discontinuity of phrases) is not allowedto be greater than 2.
We present an ef-ficient algorithm for transforming LCFRSwith fan-out at most 2 into a binary form,whenever this is possible.
This resultsin asymptotical run-time improvement forknown parsing algorithms for this class.1 IntroductionSince its early years, the computational linguisticsfield has devoted much effort to the developmentof formal systems for modeling the syntax of nat-ural language.
There has been a considerable in-terest in rewriting systems that enlarge the generat-ive power of context-free grammars, still remain-ing far below the power of the class of context-sensitive grammars; see (Joshi et al, 1991) for dis-cussion.
Following this line, (Vijay-Shanker et al,1987) have introduced a formalism called linearcontext-free rewriting systems (LCFRSs) that hasreceived much attention in later years by the com-munity.LCFRSs allow the derivation of tuples ofstrings,1 i.e., discontinuous phrases, that turn outto be very useful in modeling languages with rel-atively free word order.
This feature has recentlybeen used for mapping non-projective depend-ency grammars into discontinuous phrase struc-tures (Kuhlmann and Satta, 2009).
Furthermore,LCFRSs also implement so-called synchronous1In its more general definition, an LCFRS provides aframework where abstract structures can be generated, as forinstance trees and graphs.
Throughout this paper we focus onso-called string-based LCFRSs, where rewriting is definedover strings only.rewriting, up to some bounded degree, and haverecently been exploited, in some syntactic vari-ant, in syntax-based machine translation (Chiang,2005; Melamed, 2003) as well as in the modelingof syntax-semantic interface (Nesson and Shieber,2006).The maximum number f of tuple componentsthat can be generated by an LCFRS G is calledthe fan-out of G, and the maximum number r ofnonterminals in the right-hand side of a productionis called the rank of G. As an example, context-free grammars are LCFRSs with f = 1 and rgiven by the maximum length of a productionright-hand side.
Tree adjoining grammars (Joshiand Levy, 1977), or TAG for short, can be viewedas a special kind of LCFRS with f = 2, sinceeach elementary tree generates two strings, and rgiven by the maximum number of adjunction sitesin an elementary tree.Several parsing algorithms for LCFRS or equi-valent formalisms are found in the literature; seefor instance (Seki et al, 1991; Boullier, 2004; Bur-den and Ljunglo?f, 2005).
All of these algorithmswork in time O(|G| ?
|w|f ?(r+1)).
Parsing time isthen exponential in the input grammar size, since|G| depends on both f and r. In the develop-ment of efficient algorithms for parsing based onLCFRS the crucial goal is therefore to optimizethe term f ?
(r + 1).In practical natural language processing applic-ations the fan-out of the grammar is typicallybounded by some small number.
As an example,in the case of discontinuous parsing discussedabove, we have f = 2 for most practical cases.On the contrary, LCFRS productions with a rel-atively large number of nonterminals are usuallyobserved in real data.
The reduction of the rank ofa LCFRS, called binarization, is a process verysimilar to the reduction of a context-free grammarinto Chomsky normal form.
While in the specialcase of CFG and TAG this can always be achieved,985binarization of an LCFRS requires, in the gen-eral case, an increase in the fan-out of the gram-mar much larger than the achieved reduction inthe rank.
Worst cases and some lower bounds havebeen discussed in (Rambow and Satta, 1999; Satta,1998).Nonetheless, in many cases of interest binariza-tion of an LCFRS can be carried out without anyextra increase in the fan-out.
As an example, inthe case where f = 2, binarization of a LCFRSwould result in parsing time of O(|G| ?
|w|6).With the motivation of parsing efficiency, muchresearch has been recently devoted to the designof efficient algorithms for rank reduction, in casesin which this can be carried out at no extra increasein the fan-out.
(Go?mez-Rodr?
?guez et al, 2009) re-ports a general binarization algorithm for LCFRS.In the case where f = 2, this algorithm worksin time O(|p|7), where p is the input production.A more efficient algorithm is presented in (Kuhl-mann and Satta, 2009), working in time O(|p|) incase of f = 2.
However, this algorithm worksfor a restricted typology of productions, and doesnot cover all cases in which some binarization ispossible.
Other linear time algorithms for rank re-duction are found in the literature (Zhang et al,2008), but they are restricted to the case of syn-chronous context-free grammars, a strict subclassof the LCFRS with f = 2.In this paper we focus our attention on LCFRSwith a fan-out of two.
We improve upon allof the above mentioned results, by providingan algorithm that computes a binarization of anLCFRS production in all cases in which this ispossible and works in time O(|p|).
This is anoptimal result in terms of time complexity, since?
(|p|) is also the size of any output binarizationof an LCFRS production.2 Linear context-free rewriting systemsWe briefly summarize here the terminology andnotation that we adopt for LCFRS; for detaileddefinitions, see (Vijay-Shanker et al, 1987).
Wedenote the set of non-negative integers by N. Fori, j ?
N, the interval {k | i ?
k ?
j} is denotedby [i, j].
We write [i] as a shorthand for [1, i].
Foran alphabet V , we write V ?
for the set of all (fi-nite) strings over V .As already mentioned in Section 1, linearcontext-free rewriting systems generate tuples ofstrings over some finite alphabet.
This is done byassociating each production p of a grammar witha function g that rearranges the string compon-ents in the tuples generated by the nonterminalsin p?s right-hand side, possibly adding some al-phabet symbols.
Let V be some finite alphabet.For natural numbers r ?
0 and f, f1, .
.
.
, fr ?
1,consider a function g : (V ?
)f1 ?
?
?
?
?
(V ?
)fr ?
(V ?
)f defined by an equation of the formg(?x1,1, .
.
.
, x1,f1?, .
.
.
, ?xr,1, .
.
.
, xr,fr?)
= ~?,where ~?
= ?
?1, .
.
.
, ?f ?
is an f -tuple of stringsover g?s argument variables and symbols in V .
Wesay that g is linear, non-erasing if ~?
contains ex-actly one occurrence of each argument variable.We call r and f the rank and the fan-out of g, re-spectively, and write r(g) and f(g) to denote thesequantities.A linear context-free rewriting system(LCFRS) is a tuple G = (VN , VT , P, S), whereVN and VT are finite, disjoint alphabets of nonter-minal and terminal symbols, respectively.
EachA ?
VN is associated with a value f(A), called itsfan-out.
The nonterminal S is the start symbol,with f(S) = 1.
Finally, P is a set of productionsof the formp : A?
g(A1, A2, .
.
.
, Ar(g)) ,where A,A1, .
.
.
, Ar(g) ?
VN , and g : (V?T )f(A1)?
?
?
??
(V ?T )f(Ar(g)) ?
(V ?T )f(A) is a linear, non-erasing function.A production p of G can be used to transforma sequence of r(g) string tuples generated by thenonterminals A1, .
.
.
, Ar(g) into a tuple of f(A)strings generated by A.
The values r(g) and f(g)are called the rank and fan-out of p, respectively,written r(p) and f(p).
The rank and fan-out of G,written r(G) and f(G), respectively, are the max-imum rank and fan-out among all of G?s produc-tions.
Given that f(S) = 1, S generates a set ofstrings, defining the language of G.Example 1 Consider the LCFRS G defined bythe productionsp1 : S ?
g1(A), g1(?x1,1, x1,2?)
= ?x1,1x1,2?p2 : A?
g2(A), g2(?x1,1, x1,2?)
= ?ax1,1b, cx1,2d?p3 : A?
g3(), g3() = ?
?, ?
?We have f(S) = 1, f(A) = f(G) = 2, r(p3) = 0and r(p1) = r(p2) = r(G) = 1.
G generatesthe string language {anbncndn |n ?
N}.
For in-stance, the string a3b3c3d3 is generated by means986of the following bottom-up process.
First, thetuple ?
?, ??
is generated by A through p3.
Wethen iterate three times the application of p2 to?
?, ?
?, resulting in the tuple ?a3b3, c3d3?.
Finally,the tuple (string) ?a3b3c3d3?
is generated by Sthrough application of p1.
23 Position sets and binarizationsThroughout this section we assume an LCFRSproduction p : A?
g(A1, .
.
.
, Ar) with g definedthrough a tuple ~?
as in section 2.
We also assumethat the fan-out ofA and the fan-out of eachAi areall bounded by two.3.1 Production representationWe introduce here a specialized representation forp.
Let $ be a fresh symbol that does not occurin p. We define the characteristic string of p asthe string?N (p) = ??1$?
?2$ ?
?
?
$?
?f(A),where each ?
?j is obtained from ?j by removing allthe occurrences of symbols in VT .
Consider nowsome occurrence Ai of a nonterminal symbol inthe right-hand side of p. We define the position setof Ai, written XAi , as the set of all non-negativeintegers j ?
[|?N (p)|] such that the j-th symbol in?N (p) is a variable of the form xi,h for some h.Example 2 Let p : A ?
g(A1, A2, A3), whereg(?x1,1, x1,2?, ?x2,1?, ?x3,1, x3,2?)
= ~?
with~?
= ?x1,1ax2,1x1,2, x3,1bx3,2?
.We have ?N (p) = x1,1x2,1x1,2$x3,1x3,2, XA1 ={1, 3}, XA2 = {2} and XA3 = {5, 6}.
2Each position set X ?
[|?N (p)|] can be repres-ented by means of non-negative integers i1 < i2 <?
?
?
< i2k satisfyingX =k?j=1[i2j?1 + 1, i2j ].In other words, we are decomposing X into theunion of k intervals, with k as small as possible.It is easy to see that this decomposition is alwaysunique.
We call set E = {i1, i2, .
.
.
, i2k} the en-dpoint set associated with X , and we call k thefan-out of X , written f(X).
Throughout this pa-per, we will represent p as the collection of allthe position sets associated with the occurrencesof nonterminals in its right-hand side.Let X1 and X2 be two disjoint position sets(i.e., X1 ?
X2 = ?
), with f(X1) = k1 andf(X2) = k2 and with associated endpoint sets E1and E2, respectively.
We define the merge of X1and X2 as the set X1 ?
X2.
We extend the po-sition set and end-point set terminology to thesemerge sets as well.
It is easy to check that the en-dpoint set associated to position set X1 ?
X2 is(E1?E2)\ (E1?E2).
We say thatX1 andX2 are2-combinable if f(X1 ?X2) ?
2.
We also saythat X1 and X2 are adjacent, written X1 ?
X2,if f(X1 ?X2) ?
max(k1, k2).
It is not difficultto see that X1 ?
X2 if and only if X1 and X2 aredisjoint and |E1 ?
E2| ?
min(k1, k2).
Note alsothat X1 ?
X2 always implies that X1 and X2 are2-combinable (but not the other way around).Let X be a collection of mutually disjoint posi-tion sets.
A reduction of X is the process of mer-ging two position sets X1, X2 ?
X , resulting in anew collectionX ?
= (X \{X1, X2})?
{X1?X2}.The reduction is 2-feasible if X1 and X2 are 2-combinable.
A binarization of X is a sequenceof reductions resulting in a new collection withtwo or fewer position sets.
The binarization is2-feasible if all of the involved reductions are 2-feasible.
Finally, we say that X is 2-feasible ifthere exists at least one 2-feasible binarization forX .As an important remark, we observe that whena collection X represents the position sets of allthe nonterminals in the right-hand side of a pro-duction p with r(p) > 2, then a 2-feasible reduc-tion merging XAi , XAj ?
X can be interpretedas follows.
We replace p by means of a new pro-duction p?
obtained from p by substituting Ai andAj with a fresh nonterminal symbol B, so thatr(p?)
= r(p) ?
1.
Furthermore, we create a newproduction p??
with Ai and Aj in its right-handside, such that f(p??)
= f(B) ?
2 and r(p??)
= 2.Productions p?
and p??
together are equivalent to p,but we have now achieved a local reduction in rankof one unit.Example 3 Let p be defined as in example 2 andlet X = {XA1 , XA2 , XA3}.
We have that XA1and XA2 are 2-combinable, and their merge is thenew position set X = XA1 ?
XA2 = {1, 2, 3}.This merge corresponds to a 2-feasible reductionof X resulting in X ?
= {X,XA3}.
Such a re-duction corresponds to the construction of a newproduction p?
: A?
g?
(B,A3) withg?
(?x1,1?, ?x3,1, x3,2?)
= ?x1,1, x3,1bx3,2?
;987and a new production p??
: B ?
g??
(A1, A2) withg??
(?x1,1, x1,2?, ?x2,1?)
= ?x1,1ax2,1x1,2?
.
2It is easy to see that X is 2-feasible if and onlyif there exists a binarization of p that does not in-crease its fan-out.Example 4 It has been shown in (Rambowand Satta, 1999) that binarization of anLCFRS G with f(G) = 2 and r(G) = 3is always possible without increasing thefan-out, and that if r(G) ?
4 then this isno longer true.
Consider the LCFRS pro-duction p : A ?
g(A1, A2, A3, A4), withg(?x1,1, x1,2?, ?x2,1, x2,2?, ?x3,1, x3,2?, ?x4,1, x4,2?)
=~?, ~?
= ?x1,1x2,1x3,1x4,1, x2,2x4,2x1,2x3,2?.
It isnot difficult to see that replacing any set of two orthree nonterminals in p?s right-hand side forcesthe creation of a fresh nonterminal of fan-outlarger than two.
23.2 Greedy decision theoremThe binarization algorithm presented in this paperproceeds by representing each LCFRS productionp as a collection of disjoint position sets, and thenfinding a 2-feasible binarization of p. This binariz-ation is computed deterministically, by an iterativeprocess that greedily chooses merges correspond-ing to pairs of adjacent position sets.The key idea behind the algorithm is based on atheorem that guarantees that any merge of adjacentsets preserves the property of 2-feasibility:Theorem 1 LetX be a 2-feasible collection of po-sition sets.
The reduction of X by merging anytwo adjacent position sets D1, D2 ?
X results ina new collection X ?
which is 2-feasible.To prove Theorem 1 we consider that, sinceX is2-feasible, there must exist at least one 2-feasiblebinarization for X .
We can write this binariza-tion ?
as a sequence of reductions, where each re-duction is characterized by a pair of position sets(X1, X2) which are merged into X1 ?X2, in sucha way that both each of the initial sets and the res-ult of the merge have fan-out at most 2.We will show that, under these conditions, forevery pair of adjacent position sets D1 and D2,there exists a binarization that starts with the re-duction merging D1 with D2.Without loss of generality, we assume thatf(D1) ?
f(D2) (if this inequality does not holdwe can always swap the names of the two positionsets, since the merging operation is commutative),and we define a function hD1?D2 : 2N ?
2N asfollows:?
hD1?D2(X) = X; if D1 * X ?D2 * X .?
hD1?D2(X) = X; if D1 ?
X ?D2 ?
X .?
hD1?D2(X) = X ?D1; if D1 * X ?D2 ?X .?
hD1?D2(X) = X \D1; if D1 ?
X ?D2 *X .With this, we construct a binarization ??
from ?as follows:?
The first reduction in ??
merges the pair ofposition sets (D1, D2),?
We consider the reductions in ?
in or-der, and for each reduction o merging(X1, X2), if X1 6= D1 and X2 6=D1, we append a reduction o?
merging(hD1?D2(X1), hD1?D2(X2)) to ?
?.We will now prove that, if ?
is a 2-feasible bin-arization, then ??
is also a 2-feasible binarization.To prove this, it suffices to show the following:2(i) Every position set merged by a reduction in??
is either one of the original sets in X , orthe result of a previous merge in ??.
(ii) Every reduction in ??
merges a pair of posi-tion sets (X1, X2) which are 2-combinable.To prove (i) we note that by construction of ?
?,if an operand of a merging operation in ??
is notone of the original position sets in X , then it mustbe an hD1?D2(X) for some X that appears as anoperand of a merging operation in ?.
Since thebinarization ?
is itself valid, this X must be eitherone of the position sets in X , or the result of aprevious merge in the binarization ?.
So we dividethe proof into two cases:?
If X ?
X : First of all, we note that X can-not be D1, since the merging operations of ?that have D1 as an operand do not produce2It is also necessary to show that no position set is mergedin two different reductions, but this easily follows from thefact that hD1?D2(X) = hD1?D2(Y ) if and only if X ?D1 = Y ?D1.
Thus, two reductions in ?
can only produceconflicting reductions in ??
if they merge two position setsdiffering only by D1, but in this case, one of the reductionsmust merge D1 so it does not produce any reduction in ?
?.988a corresponding operation in ??.
If X equalsD2, then hD1?D2(X) is D1 ?
D2, which isthe result of the first merging operation in ?
?.Finally, if X is one of the position sets in X ,and not D1 or D2, then hD1?D2(X) = X ,so our operand is also one of the position setsin X .?
If X is the result of a previous merging oper-ation o in binarization ?
: Then, hD1?D2(X)is the result of a previous merging operationo?
in binarization ?
?, which is obtained by ap-plying the function hD1?D2 to the operandsand result of o.
3To prove (ii), we show that, under the assump-tions of the theorem, the function hD1?D2 pre-serves 2-combinability.
Since two position sets offan-out ?
2 are 2-combinable if and only if theyare disjoint and the fan-out of their union is at most2, it suffices to show that, for everyX,X1, X2 uni-ons of one or more sets of X , having fan-out ?
2,such that X1 6= D1, X2 6= D1 and X 6= D1;(a) The function hD1?D2 preserves disjointness,that is, if X1 and X2 are disjoint, thenhD1?D2(X1) and hD1?D2(X2) are disjoint.
(b) The function hD1?D2 is distributive withrespect to the union of position sets, thatis, hD1?D2(X1 ?
X2) = hD1?D2(X1) ?hD1?D2(X2).
(c) The function hD1?D2 preserves the propertyof having fan-out?
2, that is, ifX has fan-out?
2, then hD1?D2(X) has fan-out ?
2.If X1 and X2 do not contain D1 or D2, or ifone of the two unionsX1 orX2 containsD1?D2,properties (a) and (b) are trivial, since the functionhD1?D2 behaves as the identity function in thesecases.It remains to show that (a) and (b) are true in thefollowing cases:?
X1 contains D1 but not D2, and X2 does notcontain D1 or D2:3Except if one of the operands of the operation o was D1.But in this case, if we call the other operand Z, then we havethat X = D1 ?
Z.
If Z contains D2, then X = D1 ?Z = hD1?D2(X) = hD1?D2(Z), so we apply this samereasoning with hD1?D2(Z) where we cannot fall into thiscase, since there can be only one merge operation in ?
thatuses D1 as an operand.
If Z does not contain D2, then wehave that hD1?D2(X) = X \D1 = Z = hD1?D2(Z), sowe can do the same.In this case, ifX1 andX2 are disjoint, we canwriteX1 = Y1?D1, such that Y1, X2, D1 arepairwise disjoint.
By definition, we have thathD1?D2(X1) = Y1, and hD1?D2(X2) =X2, which are disjoint, so (a) holds.Property (b) also holds because, with theseexpressions for X1 and X2, we can calcu-late hD1?D2(X1 ?
X2) = Y1 ?
X2 =hD1?D2(X1) ?
hD1?D2(X2).?
X1 containsD2 but notD1,X2 does not con-tain D1 or D2:In this case, if X1 and X2 are disjoint,we can write X1 = Y1 ?
D2, such thatY1, X2, D1, D2 are pairwise disjoint.
Bydefinition, hD1?D2(X1) = Y1 ?
D2 ?
D1,and hD1?D2(X2) = X2, which are disjoint,so (a) holds.Property (b) also holds, since we can checkthat hD1?D2(X1 ?
X2) = Y1 ?
X2 ?
D2 ?D1 = hD1?D2(X1) ?
hD1?D2(X2).?
X1 contains D1 but not D2, X2 contains D2but not D1:In this case, ifX1 andX2 are disjoint, we canwriteX1 = Y1?D1 andX2 = Y2?D2, suchthat Y1, Y2, D1, D2 are pairwise disjoint.
Bydefinition, we know that hD1?D2(X1) = Y1,and hD1?D2(X2) = Y2 ?
D1 ?
D2, whichare disjoint, so (a) holds.Finally, property (b) also holds in this case,since hD1?D2(X1 ?X2) = Y1 ?X2 ?D2 ?D1 = hD1?D2(X1) ?
hD1?D2(X2).This concludes the proof of (a) and (b).To prove (c), we consider a position set X ,union of one or more sets of X , with fan-out ?
2and such that X 6= D1.
First of all, we observethat if X does not contain D1 or D2, or if it con-tains D1 ?
D2, (c) is trivial, because the functionhD1?D2 behaves as the identity function in thiscase.
So it remains to prove (c) in the cases whereX contains D1 but not D2, and where X containsD2 but not D1.
In any of these two cases, if wecall E(Y ) the endpoint set associated with an ar-bitrary position set Y , we can make the followingobservations:1.
Since X has fan-out ?
2, E(X) contains atmost 4 endpoints.2.
SinceD1 has fan-out f(D1),E(D1) containsat most 2f(D1) endpoints.9893.
SinceD2 has fan-out f(D2),E(D2) containsat most 2f(D2) endpoints.4.
Since D1 and D2 are adjacent, we knowthat E(D1) ?
E(D2) contains at leastmin(f(D1), f(D2)) = f(D1) endpoints.5.
Therefore, E(D1) \ (E(D1) ?
E(D2)) cancontain at most 2f(D1) ?
f(D1) = f(D1)endpoints.6.
On the other hand, sinceX contains only oneof D1 and D2, we know that the endpointswhere D1 is adjacent to D2 must also be en-dpoints of X , so that E(D1) ?
E(D2) ?E(X).
Therefore, E(X)\(E(D1)?E(D2))can contain at most 4?
f(D1) endpoints.Now, in the case where X contains D1 but notD2, we know that hD1?D2(X) = X\D1.
We cal-culate a bound for the fan-out ofX\D1 as follows:we observe that all the endpoints in E(X \ D1)must be either endpoints of X or endpoints ofD1, since E(X) = (E(X \ D1) ?
E(D1)) \(E(X \ D1) ?
E(D1)), so every position that isin E(X \D1) but not in E(D1) must be in E(X).But we also observe that E(X \ D1) cannot con-tain any of the endpoints where D1 is adjacent toD2 (i.e., the members of E(D1) ?
E(D2)), sinceX \D1 does not contain D1 or D2.
Thus, we cansay that any endpoint of X \D1 is either a mem-ber of E(D1) \ (E(D1) ?
E(D2)), or a memberof E(X) \ (E(D1) ?
E(D2)).Thus, the number of endpoints in E(X \ D1)cannot exceed the sum of the number of endpointsin these two sets, which, according to the reason-ings above, is at most 4 ?
f(D1) + f(D1) = 4.Since E(X \D1) cannot contain more than 4 en-dpoints, we conclude that the fan-out of X \ D1is at most 2, so the function hD1?D2 preserves theproperty of position sets having fan-out?
2 in thiscase.In the other case, where X contains D2 but notD1, we follow a similar reasoning: in this case,hD1?D2(X) = X ?
D1.
To bound the fan-outof X ?
D1, we observe that all the endpoints inE(X ?D1) must be either in E(X) or in E(D1),since E(X ?D1) = (E(X)?E(D1)) \ (E(X)?E(D1)).
But we also know that E(X ?D1) can-not contain any of the endpoints where D1 is adja-cent to D2 (i.e., the members of E(D1)?E(D2)),since X ?D1 contains both D1 and D2.
Thus, wecan say that any endpoint of X ?
D1 is either a1: Function BINARIZATION(p)2: A ?
?
; {working agenda}3: R ?
??
; {empty list of reductions}4: for all i from 1 to r(p) do5: A ?
A?
{XAi};6: while |A| > 2 and A contains two adjacentposition sets do7: choose X1, X2 ?
A such that X1 ?
X2;8: X ?
X1 ?X2;9: A ?
(A \ {X1, X2}) ?
{X};10: append (X1, X2) toR;11: if |A| = 2 then12: return R;13: else14: return fail;Figure 1: Binarization algorithm for a productionp : A ?
g(A1, .
.
.
, Ar(p)).
Result is either a listof reductions or failure.member of E(D1)\ (E(D1)?E(D2)), or a mem-ber of E(X) \ (E(D1) ?
E(D2)).
Reasoning asin the previous case, we conclude that the fan-outof X ?
D1 is at most 2, so the function hD1?D2also preserves the property of position sets havingfan-out ?
2 in this case.This concludes the proof of Theorem 1.4 Binarization algorithmLet p : A ?
g(A1, .
.
.
, Ar(p)) be a productionwith r(p) > 2 from some LCFRS with fan-outnot greater than 2.
Recall from Subsection 3.1 thateach occurrence of nonterminal Ai in the right-hand side of p is represented as a position setXAi .The specification of an algorithm for finding a 2-feasible binarization of p is reported in Figure 1.The algorithm uses an agenda A as a workingset, where all position sets that still need to be pro-cessed are stored.
A is initialized with the posi-tion sets XAi , 1 ?
i ?
r(p).
At each step in thealgorithm, the size of A represents the maximumrank among all productions that can be obtainedfrom the reductions that have been chosen so far inthe binarization process.
The algorithm also usesa list R, initialized as the empty list, where all re-ductions that are attempted in the binarization pro-cess are appended.At each iteration, the algorithm performs a re-duction by arbitrarily choosing a pair of adjacentendpoint sets from the agenda and by mergingthem.
As already discussed in Subsection 3.1, this990corresponds to some specific transformation of theinput production p that preserves its generative ca-pacity and that decreases its rank by one unit.We stop the iterations of the algorithm when wereach a state in which there are no more than twoposition sets in the agenda.
This means that thebinarization process has come to an end with thereduction of p to a set of productions equivalentto p and with rank and fan-out at most 2.
Thisset of productions can be easily constructed fromthe output list R. We also stop the iterations incase no adjacent pair of position sets can be foundin the agenda.
If the agenda has more than twoposition sets, this means that no binarization hasbeen found and the algorithm returns a failure.4.1 CorrectnessTo prove the correctness of the algorithm in Fig-ure 1, we need to show that it produces a 2-feasiblebinarization of the given production p wheneversuch a binarization exists.
This is established bythe following theorem:Theorem 2 LetX be a 2-feasible collection of po-sition sets, such that the union of all sets in X is aposition set with fan-out ?
2.
The procedure:while ( X contains any pair of adjacent setsX1, X2 ) reduce X by merging X1 with X2;always finds a 2-feasible binarization of X .In order to prove this, the loop invariant is thatX is a 2-feasible set, and that the union of all po-sition sets in X has fan-out ?
2: reductions cannever change the union of all sets in X , and The-orem 1 guarantees us that every change to the stateof X maintains 2-feasibility.
We also know thatthe algorithm eventually finishes, because everyiteration reduces the amount of position sets in Xby 1; and the looping condition will not hold whenthe number of sets gets to be 1.So it only remains to prove that the loop is onlyexited if X contains at most two position sets.
Ifwe show this, we know that the sequence of re-ductions produced by this procedure is a 2-feasiblebinarization.
Since the loop is exited when X is 2-feasible but it contains no pair of adjacent positionsets, it suffices to show the following:Proposition 1 Let X be a 2-feasible collection ofposition sets, such that the union of all the sets inX is a position set with fan-out?
2.
IfX has morethan two elements, then it contains at least a pairof adjacent position sets.
2Let X be a 2-feasible collection of more thantwo position sets.
Since X is 2-feasible, we knowthat there must be a 2-feasible binarization of X .Suppose that ?
is such a binarization, and let D1and D2 be the two position sets that are merged inthe first reduction of ?.
Since ?
is 2-feasible, D1and D2 must be 2-combinable.If D1 and D2 are adjacent, our proposition istrue.
If they are not adjacent, then, in order to be 2-combinable, the fan-out of both position sets mustbe 1: if any of them had fan-out 2, their unionwould need to have fan-out > 2 for D1 and D2not to be adjacent, and thus they would not be 2-combinable.
Since D1 and D2 have fan-out 1 andare not adjacent, their sets of endpoints are of theform {b1, b2} and {c1, c2}, and they are disjoint.If we call EX the set of endpoints correspond-ing to the union of all the position sets in X andED1D2 = {b1, b2, c1, c2}, we can show that atleast one of the endpoints in ED1D2 does not ap-pear in EX , since we know that EX can have atmost 4 elements (as the union has fan-out ?
2)and that it cannot equalED1D2 because this wouldmean that X = {D1, D2}, and by hypothesis Xhas more than two position sets.
If we call thisendpoint x, this means that there must be a posi-tion set D3 in X , different from D1 and D2, thathas x as one of its endpoints.
Since D1 and D2have fan-out 1, this implies that D3 must be ad-jacent either to D1 or to D2, so we conclude theproof.4.2 Implementation and complexityWe now turn to the computational analysis of thealgorithm in Figure 1.
We define the length of anLCFRS production p, written |p|, as the sum ofthe length of all strings ?j in ~?
in the definitionof the linear, non-erasing function associated withp.
Since we are dealing with LCFRS of fan-out atmost two, we easily derive that |p| = O(r(p)).In the implementation of the algorithm it is con-venient to represent each position set by means ofthe corresponding endpoint set.
Since at any timein the computation we are only processing posi-tion sets with fan-out not greater than two, eachendpoint set will contain at most four integers.The for-loop at lines 4 and 5 in the algorithmcan be easily implemented through a left-to-rightscan of the characteristic string ?N (p), detectingthe endpoint sets associated with each position setXAi .
This can be done in constant time for each991XAi , and thus in linear time in |p|.At each iteration of the while-loop at lines 6to 10 we have that A is reduced in size by oneunit.
This means that the number of iterations isbounded by r(p).
We will show below that eachiteration of this loop can be executed in constanttime.
We can therefore conclude that our binariz-ation algorithm runs in optimal time O(|p|).In order to run in constant time each single it-eration of the while-loop at lines 6 to 10, we needto perform some additional bookkeeping.
We usetwo arrays Ve and Va, whose elements are in-dexed by the endpoints associated with character-istic string ?N (p), that is, integers i ?
[0, |?N (p)|].For each endpoint i, Ve[i] stores all the endpointsets that share endpoint i.
Since each endpoint canbe shared by at most two endpoint sets, such a datastructure has sizeO(|p|).
If there exists some posi-tion setX inAwith leftmost endpoint i, then Va[i]stores all the position sets (represented as endpointsets) that are adjacent to X .
Since each positionset can be adjacent to at most four other positionsets, such a data structure has size O(|p|).
Finally,we assume we can go back and forth between po-sition sets in the agenda and their leftmost end-points.We maintain arrays Ve and Va through the fol-lowing simple procedures.?
Whenever a new position set X is added toA, for each endpoint i of X we add X toVe[i].
We also check whether any position setin Ve[i] other than X is adjacent to X , andadd these position sets to Va[il], where il isthe leftmost end point of X .?
Whenever some position set X is removedfrom A, for each endpoint i of X we removeX from Ve[i].
We also remove all of the posi-tion sets in Va[il], where il is the leftmost endpoint of X .It is easy to see that, for any position set X whichis added/removed from A, each of the above pro-cedures can be executed in constant time.We maintain a set I of integer numbers i ?
[0, |?N (p)|] such that i ?
I if and only if Va[i] isnot empty.
Then at each iteration of the while-loopat lines 6 to 10 we pick up some index in I and re-trieve at Va[i] some pairX,X ?
such thatX ?
X ?.Since X,X ?
are represented by means of endpointsets, we can compute the endpoint set ofX?X ?
inconstant time.
Removal of X,X ?
and addition ofX?X ?
in our data structures Ve and Va is then per-formed in constant time, as described above.
Thisproves our claim that each single iteration of thewhile loop can be executed in constant time.5 DiscussionWe have presented an algorithm for the binariza-tion of a LCFRS with fan-out 2 that does not in-crease the fan-out, and have discussed how thiscan be applied to improve parsing efficiency inseveral practical applications.
In the algorithm ofFigure 1, we can modify line 14 to return R evenin case of failure.
If we do this, when a binariza-tion with fan-out ?
2 does not exist the algorithmwill still provide us with a list of reductions thatcan be converted into a set of productions equival-ent to p with fan-out at most 2 and rank boundedby some rb, with 2 < rb ?
r(p).
In case rb <r(p), we are not guaranteed to have achieved anoptimal reduction in the rank, but we can still ob-tain an asymptotic improvement in parsing time ifwe use the new productions obtained in the trans-formation.Our algorithm has optimal time complexity,since it works in linear time with respect to theinput production length.
It still needs to be invest-igated whether the proposed technique, based ondeterminization of the choice of the reduction, canalso be used for finding binarizations for LCFRSwith fan-out larger than two, again without in-creasing the fan-out.
However, it seems unlikelythat this can still be done in linear time, since theproblem of binarization for LCFRS in general, i.e.,without any bound on the fan-out, might not besolvable in polynomial time.
This is still an openproblem; see (Go?mez-Rodr?
?guez et al, 2009) fordiscussion.AcknowledgmentsThe first author has been supported by Ministeriode Educacio?n y Ciencia and FEDER (HUM2007-66607-C04) and Xunta de Galicia (PGIDIT-07SIN005206PR, INCITE08E1R104022ES,INCITE08ENA305025ES, INCITE08PXIB-302179PR and Rede Galega de Procesamentoda Linguaxe e Recuperacio?n de Informacio?n).The second author has been partially supportedby MIUR under project PRIN No.
2007TJN-ZRE 002.992ReferencesPierre Boullier.
2004.
Range concatenation grammars.In H. Bunt, J. Carroll, and G. Satta, editors, NewDevelopments in Parsing Technology, volume 23 ofText, Speech and Language Technology, pages 269?289.
Kluwer Academic Publishers.Ha?kan Burden and Peter Ljunglo?f.
2005.
Parsing lin-ear context-free rewriting systems.
In IWPT05, 9thInternational Workshop on Parsing Technologies.David Chiang.
2005.
A hierarchical phrase-basedmodel for statistical machine translation.
In Pro-ceedings of the 43rd ACL, pages 263?270.Carlos Go?mez-Rodr?
?guez, Marco Kuhlmann, GiorgioSatta, and David Weir.
2009.
Optimal reduction ofrule length in linear context-free rewriting systems.In Proc.
of the North American Chapter of the Asso-ciation for Computational Linguistics - Human Lan-guage Technologies Conference (NAACL?09:HLT),Boulder, Colorado.
To appear.Aravind K. Joshi and Leon S. Levy.
1977.
Constraintson local descriptions: Local transformations.
SIAMJ.
Comput., 6(2):272?284.Aravind K. Joshi, K. Vijay-Shanker, and David Weir.1991.
The convergence of mildly context-sensitivegrammatical formalisms.
In P. Sells, S. Shieber, andT.
Wasow, editors, Foundational Issues in NaturalLanguage Processing.
MIT Press, Cambridge MA.Marco Kuhlmann and Giorgio Satta.
2009.
Tree-bank grammar techniques for non-projective de-pendency parsing.
In Proc.
of the 12th Conferenceof the European Chapter of the Association for Com-putational Linguistics (EACL-09), pages 478?486,Athens, Greece.I.
Dan Melamed.
2003.
Multitext grammars and syn-chronous parsers.
In Proceedings of HLT-NAACL2003.Rebecca Nesson and Stuart M. Shieber.
2006.
SimplerTAG semantics through synchronization.
In Pro-ceedings of the 11th Conference on Formal Gram-mar, Malaga, Spain, 29?30 July.Owen Rambow and Giorgio Satta.
1999.
Independentparallelism in finite copying parallel rewriting sys-tems.
Theoretical Computer Science, 223:87?120.Giorgio Satta.
1998.
Trading independent for syn-chronized parallelism in finite copying parallel re-writing systems.
Journal of Computer and SystemSciences, 56(1):27?45.Hiroyuki Seki, Takashi Matsumura, Mamoru Fujii, andTadao Kasami.
1991.
On multiple context-freegrammars.
Theoretical Computer Science, 88:191?229.K.
Vijay-Shanker, David J. Weir, and Aravind K. Joshi.1987.
Characterizing structural descriptions pro-duced by various grammatical formalisms.
In Pro-ceedings of the 25th Meeting of the Association forComputational Linguistics (ACL?87).Hao Zhang, Daniel Gildea, and David Chiang.
2008.Extracting synchronous grammar rules from word-level alignments in linear time.
In 22nd Inter-national Conference on Computational Linguistics(Coling), pages 1081?1088, Manchester, England,UK.993
