Proceedings of NAACL HLT 2007, Companion Volume, pages 125?128,Rochester, NY, April 2007. c?2007 Association for Computational LinguisticsSubtree Mining for Relation Extraction from WikipediaDat P.T.
NguyenUniversity of Tokyo7-3-1 Hongo, Bunkyo-kuTokyo 113-8656, Japannptdat@mi.ci.i.u-tokyo.ac.jpYutaka MatsuoNational Institute of AdvancedIndustrial Science and TechnologySotokanda 1-18-13Tokyo 101-0021, Japany.matsuo@aist.go.jpMitsuru IshizukaUniversity of Tokyo7-3-1 Hongo, Bunkyo-kuTokyo 113-8656, Japanishizuka@i.u-tokyo.ac.jpAbstractIn this study, we address the problem of extract-ing relations between entities from Wikipedia?sEnglish articles.
Our proposed method first an-chors the appearance of entities in Wikipedia?sarticles using neither Named Entity Recognizer(NER) nor coreference resolution tool.
It thenclassifies the relationships between entity pairsusing SVM with features extracted from theweb structure and subtrees mined from thesyntactic structure of text.
We evaluate ourmethod on manually annotated data from ac-tual Wikipedia articles.1 IntroductionWikipedia (www.wikipedia.org) has emerged as theworld?s largest online encyclopedia.
Because the ency-clopedia is managed by the Wikipedia Foundation, andbecause numerous collaborators in the world continu-ously develop and edit its articles, its contents are be-lieved to be quite reliable despite its openness.This study is intended to deal with the problem ofextracting binary relations between entity pairs fromWikipedia?s English version.
A binary relation is definedas a triple (ep, rel, es) in which ep and es are entities andrel indicates a directed relationship of ep and es.
Currentexperiment limits entities and relations to a reasonablesize in that an entity is classifiable as person, organiza-tion, location, artifact, year, month or date; and a rela-tion can be founder, chairman, CEO, COO, president,director, vice chairman, spouse, birth date, birth place,foundation, product and location.To our knowledge, only one recent work has at-tempted relation extraction on Wikipedia: (Culotta et al,2006) presents a probabilistic model to integrate extrac-tion and mining tasks performed on biographical text ofWikipedia.
Some other works (Brin, 1998; Agichtein andGravano, 2000; Ravichandran and Hovy, 2002) rely onthe abundance of web data to obtain easy patterns andlearn such patterns based mostly on lexical information.Rather than analyzing dependency path between entitypair proposed in (Bunescu and Mooney, 2006; Cui et al,2005), our method analyzes a subtree derived from thedependency structure.
Such subtree contains more evi-dence of the entities?
inter-relation than the path in somecases.
We propose a new feature obtained from the sub-tree by using a subtree-mining technique.In addition, we also make use of the characteristics ofWikipedia to allocate the mentions of entities and furtheridentify their types to help the relation extraction process.2 Wikipedia?s Article CharacteristicsDue to the encyclopedic style, each Wikipedia articlemainly provides information for a specific entity and fur-ther mentions other entities related to it.
Culotta et al(2006) defines the entities as principal entity and sec-ondary entity respectively.
We predict only relationshipsbetween the principal entity and each mentioned sec-ondary entity that contains a link to its descriptive article.We put some assumptions in this study: a relation-ship can be expressed completely in one sentence.
Fur-thermore, a relationship between an entity pair might beexpressed with the implication of the principal entity insome cases.
Thus, for an article, only sentences contain-ing at least a secondary entity are necessarily analyzed.An interesting characteristic of Wikipedia is the cate-gory hierarchy that is used to classify articles according totheir content.
Additionally, those articles for famous en-tities provide summary sections on their right side, whichare created by human editors.
Finally, the first sentenceof an article often defines the principal entity.3 Proposed MethodFigure 1 delineates our framework for relation extrac-tion.
First, Wikipedia articles are processed to removeHTML tags and to extract hyperlinks that point to otherWikipedia articles.
Raw text is submitted to a pipelineincluding a Sentence Splitter, a Tokenizer and a PhraseChunker supplied by the OpenNLP 1 tool set.
The in-stances of the principal entity and secondary entities arethen anchored in the articles.
The Secondary Entity De-tector simply labels the appropriate surface texts of thehyperlinks to other Wikipedia articles, which are proper1http://opennlp.sourceforge.net/125Figure 1: System frameworknouns as secondary entities.
The Principal Entity Detec-tor will be explained in the following subsection.After the entities are anchored, sentences that includeat least one mention of secondary entities will be selectedby a Sentence Detector.
Each mention of the secondaryentities is considered as a relation candidate between theunderlying entity and the principal entity.
Secondary en-tities are always explicit, although the principal entity issometimes implicit in sentences containing no mention.Keywords that provide clues for each relation label willbe identified by a Keyword Extractor.
Parallely, an EntityClassifier module classifies the entities into types.
TheRelation Extractor extracts subtree feature from a pair ofthe principal entity and a mention of secondary entity.
Itthen incorporates subtree feature together with entity typefeature into a feature vector and classifies relations of theentity pair using SVM-based classifiers.3.1 Principal Entity DetectorThis module detects all referring expressions of the prin-cipal entity in an article.
All occurrences of identifiedexpressions are labeled as mentions of the principal en-tity.
We adopt (Morton, 2000) to classify the expressionsinto three types: (1) personal pronoun (2) proper noun(3) common nouns.
Based on chunking information, wepropose a simple technique to identify a set of referringexpressions of the principal entity, denoted as F:(i) Start with F = {}.
(ii) Select the first two chunks for F: the proper chunk(nounphase with at least one proper noun) of the articletitle and the first proper chunk in the first sentence of thearticle, if any.
If F is still empty, stop.
(iii) For each remaining proper chunk p in the article, ifp is derived from any expressions selected in (ii), thenF ?
p. Proper chunk p1 is derived from proper chunk p2if all its proper nouns appear in p2.
(iv) In the article, select c as the most frequent subjectivepronouns, find c?
as its equivalent objective pronoun andadd them to F.(v) For each chunk p with the pattern [DT N1 .
.
.
Nk]where DT is a determiner and Nk?s are a common nouns,if p appears more frequently than all the selected pro-nouns in (iv), then F ?
p.Table 1: Sample extracted referring expressionsArticle Referring expressions Step[NP Bill/NNP Gates/NNP ] (ii)[NP William/NNP H./NNP Gates/NNP ] (ii)Bill Gates [NP Gates/NNP ] (iii)[NP The/DT Gates/NNP ] (iii)[NP he/PRP ] (iv)[NP him/PRP ] (iv)[NP Microsoft/NNP ] (ii)[NP The/DT Microsoft/NNP Corporation/NNP ] (ii)Microsoft [NP that/DT Microsoft/NNP ] (iii)[NP It/PRP ] (iv)[NP the/DT company/NN ] (v)[NP Microsoft/NNP Windows/NNP ] (ii)Microsoft [NP Microsoft/NNP ] (iii)Windows [NP Windows/NNP ] (iii)[NP the/DT Windows/NNP ] (iii)[NP it/PRP ] (iv)Table 2: List of relations and their keywordsRelation KeywordsCEO CEO, chief, executive, officerChairmans chairmanCOO coo, chief, operating, officerDirector directorFounder found, founder, founded, establish, form, foundation, openPresident presidentVicechairmanvice, chairmanBirth date born, bear, birth, birthdayBirthplaceborn, bearFoundation found, establish, form, founded, open, create, formed, estab-lished, foundation, founding, cofounder, founderLocation headquartered, based, locate, headquarter, base, location, situate,locatedProduct product, include, release, produce, service, operate, provide,market, manage, development, focus, manufacture, provider,launch, make, sell, introduce, producer, supplier, possess, re-tailer, design, involve, production, offering, serve, sale, supplySpouse marry, wife, married, husband, marriageTable 1 shows some extracted referring expressions.The third column indicates in which step the expressionsare selected.
Supported by the nature of Wikipedia, ourtechnique provides better results than those of the coref-erence tool in LingPipe library 2 and OpenNLP tool set.3.2 Entity ClassifierEntity type is very useful for relation extraction.
For in-stance, the relation label between a person and an orga-nization should be founder, chairman, etc., but cannotbe spouse, product, etc.
We first identify year, monthand date entities by directly examining their surface text.Types of other entities are identified by classifying theircorresponding articles.
We develop one SVM-based clas-sifier for each remaining type using the following fea-tures: category feature (categories collected when trac-ing from the article upto k level of its category structure),pronoun feature (the most frequent subjective pronounin the article) and singular noun feature (singular nounsof the first sentence of the article).3.3 Keyword ExtractorOur hypothesis in this research is that there exist somekeywords that provide clues for the relationship between2http://www.alias-i.com/lingpipe/index.html126Figure 2: Dependency trees in (a) & (b); core trees with respect to CEO relationship in (c) & (d); new representationof the core trees in (e) & (f); common subtree in (g).
The red phrase EP denotes the principal entity; the blue phraseES denotes the secondary entity.a pair.
For example, to express the founder relation, asentence should contain one keyword such as: found,founder, founded, co-founders, or establish, etc.
We iden-tify such keywords by using a semi-automatic method.First, we automatically extract some true relations fromsummary sections of Wikipedia articles.
Then, we mapentities in such relations to those in sentences to buildsample sentences for each relationship .
Tf-idf model isexploited to measure the relevance of words to each re-lationship for those on the dependency path between theentity pair.
Finally, we choose the keywords manuallyfrom lists of candidates ranked by relevance score withrespect to each relation.
Table 2 shows our result selectedfrom ranked lists of total 35,820 keyword candidates us-ing only one hour of human labor.3.4 Subtree Feature from Dependency PathIn this subsection, we will describe how to obtain effi-cient features for extracting relation using subtree min-ing.
We extend the idea of Bunescu et al (Bunescu andMooney, 2006) suggesting the analysis of dependencypath between the entities for extracting relation, in thatpaths between the secondary entity and the keywords of rwill be added to the dependency path between the entitiesto create a tree.
The expanded tree is defined as core treeof r because it attempts to capture the clues for r. Steps toextract the core treeC of a relationship r from a sentences are described as follows:(i)] Initialize the core tree C as blank.
(ii) Derive the dependency tree D from s.(iii) Label the group of nodes corresponding to words ofsecondary entity by an ES node in D.(iv) If the principal entity appears in s, apply (iii) to re-place principal entity with EP.
Then extract P0 as shortestpath from ES to EP in D and add P0 ?C.
(v) For each keyword w of r, extract Pw as the shortestpath from ES to node of w and add Pw ?C.Figures 2c & 2d present exemplary core trees of CEOrelationship derived from the dependency trees in Figures2a & 2b.
To analyze both words and relations of a coretree uniformly, we transform it into a uniform graph for-mat (Figures 2e & 2f) in which core tree words and rela-tions are also represented as graph nodes.We define a basic element of a relationship r as a keypattern that commonly appears in various core trees of r.As an example, the core trees in Figures 2e & 2f sharea common pattern in Figure 2g.
Intuitively, this subtreeshares the core trees of sentences that express the idea of?joined the company as CEO?
or ?joined the companyand do something as CEO?.We denote T = (V , E) as a directed tree, in whichV is a set of nodes and E is a set of directed edges.Node y is an ancestor of node x, denoted by x ?
y,if (x,y) ?
E or ?i1, ..., ik (k ?
N and k ?
1) such that(x, i1),(i1, i2), ...,(ik?1, ik),(ik,y) ?
E. We define that atree S = (VS, ES) is a subtree of T if and only if: (i)VS ?V ,and (ii) ?
(x,y) ?
ES, we have x?
y in T .We use a subtree as a feature for relation extraction.From a set of training sentences with respect to a relation-ship r, we derive the core trees.
A frequent tree-miningalgorithm (Zaki, 2002) is used to generate subtrees fromthat set of core trees to form the feature space.
Eachmined subtree corresponds to a value of the feature.4 Experiments and EvaluationsIn this experiment, 5,975 articles are selected, in which45 articles are for testing and 5,930 articles for train-ing.
We apply the framework in Figure 1 on the train-ing articles to extract keywords and select relation candi-dates.
Subsequently, 3,833 positive instances (each con-tains at least one relation) and 805 negative instances (theones containing no relation) from the candidates are an-notated to train the Relation Extractor.
Among 39,467127Table 3: Compare our proposed system and baselinesPrecision(%) Recall(%) F1(%)B0 8.70 22.26 12.51B1 9.88 25.31 14.21DepTree 29.07 53.86 37.76Table 4: Result of Entity Classifier with various levels (kvalue) of exploited category structureDepth k(%) Accuracy(%)1 64.02 69.53 81.04 81.55 79.56 77.57 77.08 78.09 75.010 74.5entities collected from all principal and secondary enti-ties, we randomly select 3,300 entities and manually an-notate their types for the Entity Classifier.
Finally, we use3,100 entities for training and 200 entities for testing.We develop two baseline systems to evaluate ourmethod, which use bag-of-words model.
The second sys-tem (B1 in Table 3) works like the Keyword Extractoron training instances in that it calculates tf-idf scores forwords on the dependency path between the entities withrespect to each relation.
During testing, it accumulatestf-idf scores of words on the path and chooses the relationlabel that gives the highest score for the entity pair.
Theonly difference between the two baseline systems is thatthe first one (B0 in Table 3) focuses on all the words be-tween the entities in sentence text, not dependency path.In our experiments, dependency graphs are obtainedby Minipar parser (Lin, 1998), classifiers are trained bySVM Light (Joachims, 1999) with 2nd- order polynomialkernel, subtrees are mined by FREQT 3 tree miner.On the basis of preliminary experiments, we report theperformance of our system compared with those of base-line systems in Table 3.
The result shows that our pro-posed method gives a substantial improvement over thebaselines.
Although the recall is quite adequate, preci-sion is low.
Data analysis reveals that although the minedsubtrees capture key features for relationships, they alsogenerate many irrelevant features which degrade the per-formance.
It is necessary to carry out feature selectionstep for subtree feature.
One more reason of the poorprecision is that our system suffers from the error accu-mulation in a long pipeline of entity detection, entity clas-sification, dependency parsing and relation classification.Table 4 shows the effectiveness of different values of kparameter in Entity Classifier.
The classifier works bestwhen we trace four levels on category system.
An inter-esting fact is that Wikipedia can be used as an external3http://chasen.org/t?aku/software/freqt/knowledge source for Named Entity Recognition.5 Conclusions and Future WorksWe have presented a method to extract relations betweenentities from Wikipedia articles by incorporating infor-mation from the Wikipedia structure and by the analysisof Wikipedia text.
The key features of our method in-clude: (1) an algorithm to build the core syntactic treethat reflects the relation between a given entity pair moreaccurately; (2) the use of a tree-mining algorithm to iden-tify the basic elements of syntactic structure of sentencesfor relationships; (3) method to make use of the nature ofWikipedia for entity allocation and entity classification.ReferencesE.
Agichtein and L. Gravano.
2000.
Snowball: Ex-tracting relations from large plain-text collections.
Inthe 5th ACM International Conference on Digital Li-braries.S.
Brin.
1998.
Extracting patterns and relations fromthe world wide web.
In Proceedings of the 1998 Inter-national Workshop on the Web and Databases, pages172?183.R.C.
Bunescu and R.J. Mooney.
2006.
Extracting rela-tions from text: From word sequences to dependencypaths.
In Anne Kao and Steve Poteet, editors, TextMining and Natural Language Processing.H.
Cui, R. Sun, K. Li, M.-Y.
Kan, and T.-S. Chua.2005.
Question answering passage retrieval using de-pendency relations.
In Proceedings of SIGIR.A.
Culotta, A. McCallum, and J. Betz.
2006.
Integratingprobabilistic extraction models and data mining to dis-cover relations and patterns in text.
In Proceedings ofthe HLT-NAACL-2006.T.
Joachims.
1999.
Making large-scale svm learningpractical.
In B. Scho?lkopf, C. Burges, and A. Smola,editors, Advances in Kernel Methods - Support VectorLearning.
MIT-Press.D.
Lin.
1998.
Dependency-based evaluation of minipar.In Proceedings of the Workshop on the Evaluation ofParsing Systems, 1st International Conference on Lan-guage Resources and Evaluation.T.
Morton.
2000.
Coreference for nlp applications.
InProceedings of the ACL-2000.D.
Ravichandran and E. Hovy.
2002.
Learning surfacetext patterns for a question answering system.
In Pro-ceedings of the ACL-2002, pages 41?47.M.J.
Zaki.
2002.
Efficiently mining frequent trees in aforest.
In Proceedings of 8th ACM SIGKDD.128
