Proceedings of the Workshop on Multiword Expressions: from Parsing and Generation to the Real World (MWE 2011), pages 25?30,Portland, Oregon, USA, 23 June 2011. c?2011 Association for Computational LinguisticsTree-Rewriting Models of Multi-Word ExpressionsWilliam SchulerDepartment of LinguisticsThe Ohio State Universityschuler@ling.osu.eduAravind K. JoshiDept.
Computer and Information ScienceUniversity of Pennsylvaniajoshi@linc.cis.upenn.eduAbstractMulti-word expressions (MWEs) account fora large portion of the language used in day-to-day interactions.
A formal system that isflexible enough to model these large and oftensyntactically-rich non-compositional chunks assingle units in naturally occurring text couldconsiderably simplify large-scale semantic an-notation projects, in which it would be un-desirable to have to develop internal compo-sitional analyses of common technical expres-sions that have specific idiosyncratic meanings.This paper will first define a notion of functor-argument decomposition on phrase structuretrees analogous to graph coloring, in which thetree is cast as a graph, and the elementarystructures of a grammar formalism are colors.The paper then presents a formal argumentthat tree-rewriting systems, a class of grammarformalism that includes Tree Adjoining Gram-mars, are able to produce a proper supersetof the functor-argument decompositions thatstring-rewriting systems can produce.1 IntroductionMulti-word expressions (MWEs), whose structureand meaning cannot be derived from their compo-nent words as they occur independently, account fora large portion of the language used in day-to-dayinteractions.
Indeed, the relatively low frequency ofcomparable single-word paraphrases for elementaryspatial relations like ?in front of?
(compare to ?be-fore?)
or ?next to?
(compare to ?beside?)
suggest afundamentality of expressions, as opposed to words,as a basic unit of meaning in language (Becker, 1975;Fillmore, 2003).
Other examples of MWEs are id-ioms such as ?kick the bucket?
or ?spill the beans?,which have figurative meanings as expressions thatsometimes even allow modification (?spill some of thebeans?)
and variation in sentence forms (?which beanswere spilled??
), but are not available when the com-ponent words of the MWE occur independently.
Aformal system that is flexible enough to model theselarge and often syntactically-rich non-compositionalchunks as single units in naturally occurring textcould considerably simplify large-scale semantic an-notation projects, in which it would be undesirableto have to develop internal compositional analysesof common technical expressions that have specificidiosyncratic meanings.Models have been proposed for MWEs based onstring-rewriting systems such as HPSG (Sag et al,2002), which model compositionality as string ad-jacency of a functor and an argument substring.This string-rewriting model of compositionality es-sentially treats each projection of a head word asa functor, each capable of combining with an argu-ment to yield a higher-level projection or functor.The set of projections from a lexical head can there-fore be thought of as a single elementary structure:an n-ary functor, subsuming the arguments of theindividual functors at each projection.
This kind ofapproach is intuitive for fully-compositional analy-ses (e.g.
in which a transitive verb like ?hold?
is afunctor and a NP complement like ?the basket?
is anargument), but is less natural when applied to sub-strings of MWEs (e.g.
treating pick as a functor andup as an argument in the verb-particle MWE pick.
.
.
up), since some of these arguments do not haveany semantic significance (in the pick .
.
.
up exam-ple , there is no coherent meaning for Up such thatJpick X upK = Pick(JXK,Up)).This paper will argue that tree-rewriting systems,a class of grammar formalisms that includes TreeAdjoining Grammars (Joshi, 1985; Joshi and Sch-abes, 1997), are a more natural candidate for mod-eling MWEs since they can model entire fragmentsof phrase structure trees as elementary (locally non-compositional) semantic building blocks, in additionto the set of head-projections used in string-rewriting25NAproverbialN?SNP?
VPVkickNPDtheNbucketFigure 1: Composition of elementary trees for idiomMWE ?kick the bucket?
and adjective ?proverbial,?
withthe same semantics as an adverb ?proverbially?
adjoiningat the VP.systems.
This allows more flexibility in defining thefunctor-argument decomposition of a given phrasestructure tree.This will be demonstrated by reducing the functor-argument decompositions (compositional accounts ofsemantics assigned to portions of phrase structuretrees) of string-rewriting systems to a special caseof functor-argument decompositions of tree-rewritingsystems.
Discussion in this paper will focus onstring-rewriting systems augmented with unification(such as HPSG) because in this framework the issueof multi-word expressions has been discussed (Saget al, 2002).
The arguments in this paper also ap-ply to other string rewriting systems such as catego-rial grammars (Ajdukiewicz, 1935; Bar-Hillel, 1953;Steedman, 2000), but in these formalisms the issuesconcerning MWEs have not been extensively devel-oped.
Essentially, this paper formalizes the intuition(Abeille?, 1993) that the extended domain of localityof tree-rewriting systems allows them to provide acompositional account of the semantics assigned tomulti-word or idiomatic portions of phrase structuretrees using elementary units that, after composition,may end up partially discontinuous in these trees.For example, a portion of a phrase structure tree for?kick the bucket?
with a single interpretation equiv-alent to ?die?
can be modified through adjunctionof the adjective ?proverbial?
at the noun constituent?bucket?
without postulating separate semantics for?kick?
(see Figure 1).2 DefinitionsString rewriting systems are sets of rules for re-placing symbols with other symbols in strings.
Arewriting of some start symbol into a set of lexicalsymbols is called a derivation.
Rewrite rules in astring rewriting system can be defined to have des-ignated functor and argument symbols.
Any deriva-tion ?
can therefore yield a functor-argument decom-position D(?
), essentially defining a set of semanticfunctor-argument dependencies among structured el-ementary categories.For simplicity, a functor-argument decompositionwill be defined as a mapping from the constituentnodes in a phrase structure tree to the nodes inthe elementary structures used to derive that tree.This can be thought of as a coloring of phrase struc-ture nodes, in which colors correspond to elementarystructures in the rewriting system.
The elementarystructures used in such a decomposition may thenbe considered n-ary functors, which may take sev-eral arguments, each of a different color.In string-rewriting systems such as HPSG, thesen-ary functors consist of a head word and its pro-jections, and the arguments of the functor are thenon-projecting child of each such projection.
Fig-ure 2 shows feature-based and categorial analysesfor the MWE ?.
.
.
to the .
.
.
power?
(as in ?raise Yto the X power?)
which is taken here to have unam-biguous meaning (in a technical context) as Y X orPow(Y,X), and is analyzed here to wrap around anordinal number argument X and then adjoin onto averb phrase ?raise Y ?
as a modifier.1 Because theirelementary structures are projected up from individ-ual head words, these systems prohibit an analysisof this MWE as a single wrapping functor.
Instead,MWEs like this must be decomposed into individualfunctor words (e.g.
power) and argument words (e.g.the, and to).Tree-rewriting systems, on the other hand, allowelementary structures to contain nodes which are nei-ther projections nor argument sites.
This permitsan analysis of ?to the .
.
.
power?
as a single functorwrapped around its argument (see Figure 3), with-out having to specify functor-argument relations be-tween power, to, and the.More generally, string-rewriting systems use ele-mentary structures (n-ary functors) that originateat the lexical item and exhibit a bottom-up branch-ing structure, branching to an argument site and ahigher level projection at each step.
In contrast, tree-rewriting systems use elementary structures thatoriginate at a phrasal or clausal node and exhibit1We are using the MWE ?.
.
.
to the .
.
.
power?
as a sim-ple example with an unambiguous meaning in the domainof mathematics to illustrate our main points in the contextof both adjunction and substitution operations.
Alternativeanalyses are possible (e.g.
with ?the?
or additional modifiersadjoining in, to allow variations like ?to every even power un-der six?
), but in any case the words ?to?
and ?power?
on eitherside of the X argument are taken to be idiosyncratic to thisexpression of Y X .
Since it is analyzed as a modifier, this ex-ample can be used to demonstrate coindexation of structurein a tree-rewriting system.26?????????????????
?label : powerleft :[label : ORD]proj :?????????????
?label : N1left :[label : the]proj :?????????
?label : NPleft :[label : to]proj :?????
?label : PPleft :[ label : VP1]proj :[ label : VP1]???????????????????????????????????????????????
?=power?OR lN1pthe lNPpto lPPpVP l1VPp1Figure 2: Elementary structures for a verb-phrase-modifying preposition in a functor-argument analysis derived froma feature structure grammar.
Here, ?
indicates the origin node and boxed numbers indicate coindexations.a top-down branching structure that mirrors that ofa phrase structure tree.
As one might expect, thereare tree-rewriting systems (namely those whose el-ementary structures contain multiple lexical items)that can produce functor-argument decompositions(?colorings?)
of a phrase structure tree which can-not be produced by a string-rewriting system.
Moresurprisingly however, this paper will show that theconverse is not true: in other words, for any string-rewriting system there always exists a tree-rewritingsystem that can produce the same functor-argumentdecomposition of a phrase structure tree.
Thus, theset of functor-argument decompositions that can beproduced by tree-rewriting systems is a proper super-set of those that can be produced by string-rewritingsystems.This is surprising because, taken as a class,there is no inherent difference in recognition com-plexity between string-rewriting systems and tree-rewriting systems (as may be the case between spe-cific members of these classes, say between CGsand TAGs), since both are worst-case exponentialif unconstrained coindexation of structure is allowed(as in unification grammars).
This is also surpris-ing because, since they branch upward, the ele-mentary structures of string-rewriting systems canspecify complex functors as arguments, which thedownward-branching elementary structures of tree-rewriting systems cannot.
However, this paper willshow that this ability to specify complex functorsas arguments does not confer any additional flexibil-ity in calculating functor-argument decompositionsof phrase structure trees, and can be factored outwith no loss in expressivity.VPVP?
PPto?
NPthe?
N1OR?
power?=VP?1VP11 PP2to1?
NP2the1?
N12OR1power2?Figure 3: Elementary structure for a verb-phrase-modifying prepositional phrase ?to the .
.
.
power?
in atree-rewriting system, derived from a tree-adjoininggrammar.
Here, ?
indicates the origin node, ?
indicates anon-argument node (or lexical ?anchor?
), and boxed num-bers indicate coindexations.3 Reduction of string-rewritingsystems to tree-rewriting systemsThe first step will be to define an n-ary functor in astring-rewriting system as a kind of elementary struc-ture ?
(a tree in fact), whose nodes ??
branch ?up-ward?
into sub-structure nodes (connected by depart-ing arcs labeled l, r, or p,) specifying a left or rightargument category (??
?l or ??
?r) and a projectedcategory (??
?p), rather than branching ?downward?into left and right child constituents as in an ordi-nary phrase structure tree.2 In order to extend thisreduction to feature-based systems, these elemen-tary structures will also be augmented with coindex-ation sets I of elementary structure nodes that mustbe identical (in terms of labels and departing arcs)in any functor-argument decomposition of a phrasestructure tree.2Here, a node ??
is defined by the path of concatenatedarcs ?
that lead to it from the origin or root ??
.27SNPCubeVPVPraises NPthe sumPPto NPthe NPORDthirdpower?
:raise?NPrVPpNP lSp?
:power?OR lN1pthe lNPpto lPPpVP l1VPp1?p?p?DFA(??
)?p?I(?p?p?p?l)Figure 4: Decomposition (?coloring?)
of a phrase structure tree ?
for the sentence ?Cube raises the sum to the thirdpower?, using elementary structures ?
and ?
shown at right.
Dotted lines from phrase structure tree nodes ??
toelementary structure nodes ??
indicate that ??
generates ??
in the functor-argument decomposition: ??
?DFA(??
).Dashed lines from elementary structure nodes ??
to other elementary structure nodes ??
indicate that ??
is amongthe nodes identified with ??
as arguments of ?
in the decomposition.
Boxed identifiers indicated coindices betweennodes ??
and ???
in ?
such that ?I??
.
??
, ???
?I.Figure 4 shows a functor-argument decomposition(or ?coloring?)
of a phrase structure tree using theseupward-branching elements.The upward-branching elementary structures usedin any such decomposition can then be convertedinto a normal form in which all argument nodes areatomic (have no departing arcs), using the followingtransformations of elementary structures to equiva-lent structures that fit together generate the samefunctor-argument decomposition.
This is done by si-multaneously excising ?matched?
material from boththe argument branch of an elementary structure andthe top of the elementary structure that is its argu-ment in the given decomposition.The use of coindexation sets complicates thistransformation somewhat.
Initial configurations ofcoindexation sets in upward-branching elementarystructures can be exhaustively partitioned into threeclasses, defined with respect to the ?trunk?
of the el-ementary structure, which is the set of nodes con-nected to the origin by paths containing only p arcs.These classes are:1. coindexations with more than one coindexednode on the trunk,2.
coindexations with fewer than one coindexednode on the trunk, and3.
coindexations with exactly one coindexed nodeon the trunk.Elementary structures in the first class, with morethan one coindexed node on the trunk, are equivalentto graphs with directed cycles, and are ordinarilyexcluded from feature-based analyses, so they willbe ignored here.Elementary structures in the second class, withfewer than one coindexed node on the trunk,can be converted to equivalent structures withno coindices (which trivially satisfies the aboveargument-atomicity requirement), using the simulta-neous excision of ?matched?
structure in functor andargument structures described above, by simply ex-tending this to cover the portion of the argumentelementary structure that extends all the way to thetop of the trunk.Elementary structures in the third class, withexactly one coindexed node on the trunk, canbe converted to equivalent structures that sat-isfy argument-atomicity using a three-step process.First, the upward-branching sub-structures abovethese coindexed nodes (if any) are unified, so the arcsdeparting from each coindexed node will be recur-sively identical (this must be possible in any feature-based grammar, or the coindexation would be ill-formed, and should therefore be excluded).
The coin-dexation is then recursively slid up along the p arcdeparting from each such node, until the coindexa-28tion set contains nothing but atomic categories (withno departing arcs).
Finally, the argument nodes aremade to be atomic using the simultaneous excision of?matched?
structure in functor and argument struc-tures described above, leaving an (atomic) coindex-ation at each (atomic) argument position in each af-fected branch.Elementary structures with multiple class 3 coin-dexation sets I and I ?
(which cannot be deletedas described above for class 2 sets) can be trans-formed into structures with a single coindexationset I by copying the portion of the trunk betweenthe (unique) on-trunk members of each initial set Iand I ?
onto every other node in the set I ?
that con-tains the lower trunk node (this copy should includethe coindex belonging to I).
The coindexation setI ?
containing the lower on-trunk node is then simplydeleted.The normal-form upward-branching structures re-sulting from this transformation can now be con-verted into downward-branching elementary trees ina tree-rewriting system (with coindexed nodes corre-sponding to ?root?
and ?foot?
nodes as defined for tree-adjoining grammars) by simply replacing each pairof argument and conclusion arcs with a pair of left-child and right-child arcs departing the conclusionnode.
Since the normal form for upward-branchingelementary structures allows only atomic arguments,this re-drawing of arcs must result in well-formeddownward-branching elementary trees in every case.3In particular, this conversion results in a subset oftree-rewriting systems in which each (binary) branchof every elementary tree must have exactly one argu-ment position and one non-argument position amongits two children.
This is a special case of a moregeneral class of tree-rewriting systems, which mayhave two argument positions or no argument po-sitions among the children at each binary branch.Such trees are not equivalent to trees with a single ar-gument position per branch, because they will resultin different functor-argument decompositions (?col-orings?)
of a target phrase structure tree.
Moreover,it is precisely these non-string-rewriting-equivalentelementary trees that are needed to model the lo-cal non-compositionality of larger multi-word expres-sions like ?threw X to the lions?
(see Figure 5), be-cause only downward branches with multiple non-3Recognition and parsing of feature-based grammars, andof tree-rewriting systems whose elementary trees contain mul-tiple foot nodes, are both exponential in the worst case.
How-ever, both types of grammars are amenable to regular-from re-strictions which prohibit recursive adjunction at internal (non-root, non-foot) tree nodes, and thereby constrain recognitionand parsing complexity to cubic time for most kinds of naturallanguage grammars (Rogers, 1994).SNP?
VPVPthrew?
NP?PPto?
NPthe?
lions?Figure 5: Elementary structure for MWE idiom ?threw.
.
.
to the lions,?
allowing modification to both VP, PPand NP sub-constituents (e.g.
?threw your friends todayright to the proverbial lions).argument children can produce the multi-level sub-trees containing the word ?threw?
and the word ?lions?in the same elementary unit.4 ConclusionThis paper has shown that tree-rewriting systemsare able to produce a superset of the functor-argument decompositions that can be produced bystring-rewriting systems such as categorial gram-mars and feature-structure grammars such as HPSG.This superset additionally allows elementary unitsto contain multiple (lexical) leaves, which a string-rewriting system cannot.
This makes tree-rewritingsystems ideally suited to the analysis of natural lan-guage texts that contain many multi-word expres-sions with idiosyncratic (non-compositional) mean-ings.
Although neither the tree-rewriting nor thestring-rewriting analyses defined above can be gen-erated in guaranteed polynomial time (since theymay require the construction of unbounded stacksof unrecognized structure during bottom-up recogni-tion), they can both be made polynomial (indeed, cu-bic) by the introduction of ?regular form?
constraints(Rogers, 1994), which limit this stack in the sameway in both cases.In contrast with representations like that of(Villavicencio et al, 2004), in which concepts are dis-tributed over several lexical entries, a tree-rewritingrepresentation such as the one described in this pa-per allows only a single lexical entry to be listed foreach concept.
For example:... throw ... to the lions:(s(np0!)(vp(v)(np1!)(pp(p)(np(d)(n)))))...
to the ...
power:(vp(vp0*)(pp(p)(np(d)(n(a1!
)(n)))))(using the notation ?!?
and ?*?
for substitution sitesand foot nodes, respectively).
It is anticipated thatthis will simplify the organization of lexical resourcesfor multi-word expressions.29ReferencesAbeille?, Anne.
1993.
The flexibility of french idioms:a representation with lexicalized tree adjoining gram-mar.
In A. Schenk and E. van der Linden, editors,Idioms.
Erlbaum.Ajdukiewicz, Kazimierz.
1935.
Die syntaktische kon-nexitat.
In S. McCall, editor, Polish Logic 1920-1939.Oxford University Press, pages 207?231.
Translatedfrom Studia Philosophica 1: 1?27.Bar-Hillel, Yehoshua.
1953.
A quasi-arithmetical nota-tion for syntactic description.
Language, 29:47?58.Becker, Joseph D. 1975.
The phrasal lexicon.
In Pro-ceedings of the Workshop on Theoretical Issues in Nat-ural Language Processing, Workshop in ComputationalLinguisitcs, Psychology, and AI, Cambridge, MA.Fillmore, Charles J.
2003.
Multiword expressions,November.
Invited talk at the Institute for Research inCognitive Science (IRCS), University of Pennsylvania.http://www.cis.upenn.edu/?ircs/colloq/2003/fall/fillmore.html.Joshi, Aravind and Yves Schabes.
1997.
Tree-adjoninggrammars.
In G. Rozenberg and A. Salomaa, edi-tors, Handbook of Formal Languages.
Springer-Verlag,Berlin, pages 69?123.Joshi, Aravind K. 1985.
How much context sensitivityis necessary for characterizing structural descriptions:Tree adjoining grammars.
In L. Karttunen D. Dowtyand A. Zwicky, editors, Natural language parsing: Psy-chological, computational and theoretical perspectives.Cambridge University Press, Cambridge, U.K., pages206?250.Rogers, James.
1994.
Capturing CFLs with tree ad-joining grammars.
In Proceedings of the 32nd AnnualMeeting of the Association for Computational Linguis-tics (ACL?94).Sag, Ivan, Timothy Baldwin, Francis Bond, Ann Copes-take, and Dan Flickinger.
2002.
Multiword expres-sions: a pain in the neck for nlp.
In Proceedingsof the Third International Conference on IntelligentText Processing and Computational Linguistics (CI-CLING?02), pages 1?15, Mexico City, Mexico.Steedman, Mark.
2000.
The syntactic process.
MITPress/Bradford Books, Cambridge, MA.Villavicencio, Aline, Ann Copestake, Benjamin Waldron,and Fabre Lambeau.
2004.
Lexical encoding ofmwes.
In Takaaki Tanaka, Aline Villavicencio, Fran-cis Bond, and Anna Korhonen, editors, Second ACLWorkshop on Multiword Expressions: Integrating Pro-cessing, pages 80?87, Barcelona, Spain, July.
Associa-tion for Computational Linguistics.30
