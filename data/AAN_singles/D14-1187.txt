Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1779?1785,October 25-29, 2014, Doha, Qatar.c?2014 Association for Computational LinguisticsCross-Lingual Part-of-Speech Tagging through Ambiguous LearningGuillaume Wisniewski Nicolas P?cheux Souhir Gahbiche-Braham Fran?ois YvonUniversit?
Paris SudLIMSI-CNRS91 403 ORSAY CEDEX, France{wisniews,pecheux,souhir,yvon}@limsi.frAbstractWhen Part-of-Speech annotated data isscarce, e.g.
for under-resourced lan-guages, one can turn to cross-lingual trans-fer and crawled dictionaries to collect par-tially supervised data.
We cast this prob-lem in the framework of ambiguous learn-ing and show how to learn an accuratehistory-based model.
Experiments on tenlanguages show significant improvementsover prior state of the art performance.1 IntroductionIn the past two decades, supervised MachineLearning techniques have established new perfor-mance standards for many NLP tasks.
Their suc-cess however crucially depends on the availabilityof annotated in-domain data, a not so common sit-uation.
This means that for many application do-mains and/or less-resourced languages, alternativeML techniques need to be designed to accommo-date unannotated or partially annotated data.Several attempts have recently been made tomitigate the lack of annotated corpora using par-allel data pairing a (source) text in a resource-richlanguage with its counterpart in a less-resourcedlanguage.
By transferring labels from the sourceto the target, it becomes possible to obtain noisy,yet useful, annotations that can be used to train amodel for the target language in a weakly super-vised manner.
This research trend was initiatedby Yarowsky et al.
(2001), who consider the trans-fer of POS and other syntactic information, andfurther developed in (Hwa et al., 2005; Ganchevet al., 2009) for syntactic dependencies, in (Pad?and Lapata, 2009; Kozhevnikov and Titov, 2013;van der Plas et al., 2014) for semantic role la-beling and in (Kim et al., 2012) for named-entityrecognition, to name a few.Assuming that labels can actually be projectedacross languages, these techniques face the issueof extending standard supervised techniques withpartial and/or uncertain labels in the presence ofalignment noise.
In comparison to the early ap-proach of Yarowsky et al.
(2001) in which POSare directly transferred, subject to heuristic fil-tering rules, recent works consider the integra-tion of softer constraints using expectation regu-larization techniques (Wang and Manning, 2014),the combination of alignment-based POS transferwith additional information sources such as dic-tionaries (Li et al., 2012; T?ckstr?m et al., 2013)(Section 2), or even the simultaneous use of bothtechniques (Ganchev and Das, 2013).In this paper, we reproduce the weakly super-vised setting of T?ckstr?m et al.
(2013).
By re-casting this setting in the framework of ambiguouslearning (Bordes et al., 2010; Cour et al., 2011)(Section 3), we propose an alternative learningmethodology and show that it improves the state ofthe art performance on a large array of languages(Section 4).
Our analysis of the remaining errorssuggests that in cross-lingual settings, improve-ments of error rates can have multiple causes andshould be looked at with great care (Section 4.2).All tools and resources used in this studyare available at http://perso.limsi.fr/wisniews/ambiguous.2 Projecting Labels across AlignedCorporaProjecting POS information across languages re-lies on a rather strong assumption that morpho-syntactic categories in the source language canbe directly related to the categories in the tar-get language, which might not always be war-ranted (Evans and Levinson, 2009; Broschart,2009).
The universal reduced POS tagset pro-posed by Petrov et al.
(2012) defines an opera-tional, albeit rather empirical, ground to performthis mapping.
It is made of the following 12 cat-egories: NOUN (nouns), VERB (verbs), ADJ (ad-1779ar cs de el es fi fr id it sv% of test covered tokens (type) 83.2 93.2 95.6 97.4 96.7 83.0 98.3 90.5 95.8 95.3% of test correctly covered token (type) 72.9 94.2 93.7 92.9 93.8 93.6 92.1 89.6 93.6 94.1avg.
number of labels per token (type) 2.1 1.3 1.3 1.3 1.3 1.4 1.3 1.2 1.3 1.3avg.
number of labels per token (type+token) 1.7 1.1 1.1 1.1 1.1 1.2 1.2 1.1 1.1 1.1% of aligned tokens 53.0 77.8 66.7 69.3 74.0 73.1 64.7 81.6 72.2 79.9% of token const.
violating type const.
2.5 16.0 15.8 21.4 16.9 14.3 16.1 19.3 17.5 13.6% informative token const.
79.7 27.5 15.7 29.8 21.3 36.0 25.5 16.2 28.2 26.4Table 1: Interplay between token and type constraints on our training parallel corpora.
?Informative?token constraints correspond to tokens for which (a) a POS is actually transfered and (b) type constraintsdo not disambiguate the label, but type+token constraints do.jectives), ADV (adverbs), PRON (pronouns), DET(determiners and articles), ADP (prepositions andpostpositions), NUM (numerals), CONJ (conjunc-tions), PRT (particles), ?.?
(punctuation marks)and X (a catch-all for other categories).
Theselabels have been chosen for their stability acrosslanguages and for their usefulness in various mul-tilingual applications.
In the rest of this work, allannotations are mapped to this universal tagset.Transfer-based methods have shown to be veryeffective, even if projected labels only deliver anoisy supervision, due to tagging (of the sourcelanguage) and other alignment errors (Yarowskyet al., 2001).
While this uncertainty can be ad-dressed in several ways, recent works have pro-posed to combine projected labels with monolin-gual information in order to filter out invalid la-bel sequences (Das and Petrov, 2011; T?ckstr?met al., 2013).
In this work we follow T?ckstr?m etal.
(2013) and use two families of constraints:Token constraints rely on word alignments toproject labels of source words to target wordsthrough alignment links.
Table 1 shows that, de-pendening on the language, only 50?80% of thetarget tokens would benefit from label transfer.Type constraints rely on a tag dictionary todefine the set of possible tags for each wordtype.
Type constraints reduce the possible la-bels for a given word and help filtering out cross-lingual transfer errors (up to 20%, as shown in Ta-ble 1).
As in (T?ckstr?m et al., 2013), we con-sider two different dictionaries.
The first one isextracted automatically from Wiktionary,1us-ing the method of (Li et al., 2012).
The secondtag dictionary is built by using for each word thetwo most frequently projected POS labels fromthe training data.2In contrast to T?ckstr?m et al.1http://www.wiktionary.org/2This heuristic is similar to the way T?ckstr?m et al.
(2013) we use the intersection3of the two typeconstraints instead of their union.
Table 1 showsthe precision and recall of the resulting constraintson the test data.These two information sources are merged ac-cording to the rules of T?ckstr?m et al.
(2013).These rules assume that type constraints are morereliable than token constraints and should takeprecedence: by default, a given word is associatedto the set of possible tags licensed type constraints;additionally, when a POS tag can be projectedthrough alignment and also satisfies the type con-straints, then it is actually projected, thereby pro-viding a full (yet noisy) supervision.As shown in Table 1, token and type con-straints complement each other effectively andgreatly reduce label ambiguity.
However, thetransfer method sketched above associates eachtarget word with a set of possible labels, of whichonly one is true.
This situation is less favorablethan standard supervised learning in which oneunique gold label is available for each occurrence.We describe in the following section how to learnfrom this ambiguous supervision information.3 Modeling Sequences under AmbiguousSupervisionWe use a history-based model (Black et al., 1992)with a LaSO-like training method (Daum?
andMarcu, 2005).
History-based models reduce struc-tured prediction to a sequence of multi-class clas-sification problems.
The prediction of a complexstructure (here, a sequence of POS tags) is thusmodeled as a sequential decision problem: at each(2013) filter the tag distribution with a threshold to build theprojected type constraints.3If the intersection is empty we use the constraintsfrom Wiktionary first, if also empty, the projected con-straints then, and by default the whole tag set.1780position in the sequence, a multiclass classifieris used to make a decision, using features thatdescribe both the input structure and the historyof past decisions (i.e.
the partially annotated se-quence).Let x = (xi)ni=1denote the observed sequenceand Y be the set of possible labels (in our casethe 12 universal POS tags).
Inference consists inpredicting labels one after the other using, for in-stance, a linear model:y?i= argmaxy?Y?w|?
(x, i, y, hi)?
(1)where ??|??
is the standard dot product operation,y?ithe predicted label for position i, w the weightvector, hi= y?1, ..., y?i?1the history of past de-cisions and ?
a joint feature map.
Inference cantherefore be seen as a greedy search in the spaceof the # {Y}npossible labelings of the input se-quence.
Trading off the global optimality of in-ference for additional flexibility in the design offeatures and long range dependencies between la-bels has proved useful for many sequence labelingtasks in NLP (Tsuruoka et al., 2011).The training procedure, sketched in Algo-rithm 1, consists in performing inference on eachinput sentence and correcting the weight vectoreach time a wrong decision is made.
Impor-tantly (Ross and Bagnell, 2010), the history usedduring training has to be made of the previous pre-dicted labels so that the training samples reflect thefact that the history will be imperfectly known attest time.This reduction of sequence labeling to multi-class classification allows us to learn a sequencemodel in an ambiguous setting by building on thetheoretical results of Bordes et al.
(2010) and Couret al.
(2011).
The decision about the correctness ofa prediction and the weight updates can be adaptedto the amount of supervision information that isavailable.Full Supervision In a fully supervised setting,the correct label is known for each word token: adecision is thus considered wrong when this goldlabel is not predicted.
In this case, a standard per-ceptron update is performed:wt+1?
wt??
(x, i, y?i, hi)+?
(x, i, y?i, hi) (2)where y?iand y?iare the predicted and the gold la-bel, respectively.
This update is a stochastic gra-dient step that increases the score of the gold labelwhile decreasing the score of the predicted label.Ambiguous Supervision During training, eachobservation i is now associated with a set of possi-ble labels, denoted by?Yi.
In this case, a decision isconsidered wrong when the predicted label is notin?Yiand the weight vector is updated as follows:wt+1?
wt??
(x, i, y?i, hi)+?y?i??Yi?
(x, i, y?i, hi)(3)Compared to (2), this rule uniformly increases thescores of all the labels in?Yi.It can be shown (Bordes et al., 2010; Cour etal., 2011), under mild assumptions (namely thattwo labels never systematically co-occur in thesupervision information), that the update rule (3)enables to learn a classifier in an ambiguous set-ting, as if the gold labels were known.
Intuitively,as long as two labels are not systematically co-occurring in?Y , updates will reinforce the correctlabels more often than the spurious ones; at theend of training, the highest scoring label shouldtherefore be the correct one.Algorithm 1 Training algorithm.
In the ambigu-ous setting,?Yicontains all possible labels; in thesupervised setting, it only contains the gold label.w0?
0for t ?
J1, T K doRandomly pick example x,?yh?
empty listfor i ?
J1, nK doy?i= argmaxy?Y?wt|?
(x, i, y, hi)?if y?i/??Yithenwt+1?
update(wt,x, i,?Yi, y?i, hi)end ifpush(y?i, h)end forend forreturn1T?Tt=1wt4 Empirical StudyDatasets Our approach is evaluated on 10 lan-guages that present very different characteristicsand cover several language families.4In all our ex-periments we use English as the source language.Parallel sentences5are aligned with the standard4Resources considered in the related works are not freelyavailable, which prevents us from presenting a more completecomparison.5All resources and features used in our experiments arethoroughly documented in the supplementary material.1781ar cs de el es fi fr id it svHBAL 27.9 10.4 8.8 8.1 8.2 13.3 10.2 11.3 9.1 10.1Partially observed CRF 33.9 11.6 12.2 10.9 10.7 12.9 11.6 16.3 10.4 11.6HBSL ?
1.5 5.0 ?
2.4 5.9 3.5 4.8 2.8 3.8HBAL + matched POS 24.1 7.6 8.0 7.3 7.4 12.2 7.4 9.8 8.3 8.8(Ganchev and Das, 2013) 49.9 19.3 9.6 9.4 12.8 ?
12.5 ?
10.1 10.8(T?ckstr?m et al., 2013) ?
18.9 9.5 10.5 10.9 ?
11.6 ?
10.2 11.1(Li et al., 2012) ?
?
14.2 20.8 13.6 ?
?
?
13.5 13.9Table 2: Error rate (in %) achieved by the method described in Sec.
3 trained in an ambiguous (HBAL)or in a supervised setting (HBSL), a partially observed CRF and different state-of-the-art results.MOSES pipeline, using the intersection heuristicthat only retains the most reliable alignment links.The English side of the bitext is tagged using astandard linear CRF trained on the Penn Treebank.Tags are then transferred to the target language us-ing the procedure described in Section 2.
For eachlanguage, we train a tagger using the method de-scribed in Section 3 with T = 100 000 iterations6using a feature set similar to the one of Li et al.
(2012) and T?ckstr?m et al.
(2013).
The baselinesystem is our reimplementation of the partiallyobserved CRF model of T?ckstr?m et al.
(2013).Evaluation is carried out on the test sets of tree-banks for which manual gold tags are known.
ForCzech and Greek, we use the CoNLL?07 SharedTask on Dependency Parsing; for Arabic, the Ara-bic Treebank; and otherwise the data of the Uni-versal Dependency Treebank Project (McDonaldet al., 2013).
Tagging performance is evaluatedwith the standard error rate.4.1 ResultsTable 2 summarizes the performance achievedby our method trained in the ambiguous setting(HBAL) and by our re-implementation of thepartially supervised CRF baseline.
As an upperbound, we also report the score of our methodwhen trained in a supervised (HBSL) settingsconsidering the training part of the various tree-banks, when it is available.7For the sake of com-parison, we also list the best scores of previousstudies.
Note, however, that a direct comparisonwith these results is not completely fair as these6Preliminary experiments showed that increasing thenumber of iterations T in Algorithm 1 has no significantimpact.7In this setting, HBSL implements an averaged percep-tron, and achieves results that are similar to those obtainedwith standard linear CRF.systems were not trained and evaluated with thesame exact resources (corpora,8type constraints,alignments, etc).
Also note that the state-of-the-art scores have been achieved by different models,which have been selected based on their scores onthe test set and not on a validation set.9Experimental results show that HBAL signif-icantly outperforms, on all considered languagesbut one, the partially observed CRF that wastrained and tested in the same setting.4.2 DiscussionThe performance of our new method still fallsshort of the performance of a fully supervised POStagger: for instance, in Spanish, full supervisionreduces the error rate by a factor of 4.
A fine-grained error analysis shows that many errors ofHBAL directly result from the fact that, contraryto the fully supervised learner HBSL, our am-biguous setting suffers from a train/test mismatch,which has two main consequences.
First, the trainand test sets do not follow exactly the same nor-malization and tokenization conventions, which isan obvious source of mistakes.
Second, and moreimportantly, many errors are caused by systematicdifferences between the test tags and the super-vised tags (i.e.
the English side of the bitext andWiktionary).
While some of these differencesare linguistically well-justified and reflect funda-mental differences in the language structure andusage, others seem to be merely due to arbitraryannotation conventions.For instance, in Greek, proper names are labeled8The test sets are only the same for Czech, Greek andSwedish.9The partially observed CRF is the best model in (T?ck-str?m et al., 2013) only for German (de), Greek (el) andSwedish (sv), and uses only type constraints extracted fromWiktionary.1782either as X (when they refer to a foreigner and arenot transliterated) or as NOUN (in all other cases),while they are always labeled as NOUN in English.In French and in Greek, contractions of a prepo-sition and a determiner such as ?????
(???
??
?,meaning ?to the?)
or ?aux?
(??
les?
also meaning?to the?)
are labeled as ADP in the Universal De-pendency Treebank but as DET in Wiktionaryand are usually aligned with a determiner in theparallel corpora.
In the Penn Treebank, quanti-fiers like ?few?
or ?little?
are generally used in con-junction with a determiner (?a few years?, ?a littleparable?, ...) and labeled as ADJ; the correspond-ing Spanish constructions lack an article (?muchotempio?, ?pocos a?os?, ...) and the quantifiers aretherefore labeled as DET.
Capturing such subtledifferences is hardly possible without prior knowl-edge and specifically tailored features.This annotation mismatch problem is all themore important in settings like ours, that relyon several, independently designed, informationsources, which follow contradictory annotationconventions and for which the mapping to the uni-versal tagset is actually error-prone (Zhang et al.,2012).
To illustrate this point, we ran three ad-ditional experiments to assess the impact of thetrain/test mismatch.We first designed a control experiment in whichthe type constraints were manually completedwith the gold labels of the most frequent errors ofHBAL.
These errors generally concern functionwords and can be assumed to result from system-atic differences in the annotations rather than pre-diction errors.
For instance, for French the typeconstraints for ?du?, ?des?, ?au?
and ?aux?
were cor-rected from DET to ADP.
The resulting model,denoted ?HBAL + matched POS?
in Table 2, sig-nificantly outperforms HBAL, stressing the diver-gence in the different annotation conventions.Additionally, in order to approximate the am-biguous setting train/test mismatch, we learn twofully supervised Spanish taggers on the same train-ing data as HBAL, using two different strategiesto obtain labeled data.
We first use HBSL (whichwas trained on the treebank) to automatically la-bel the target side of the parallel corpus.
In thissetting, the POS tagger is trained with data froma different domain, but labeled with the same an-notation scheme as a the test set.
Learning withthis fully supervised data yields an error rate of4.2% for Spanish, almost twice as much as HBSL,bringing into light the impact of domain shift.
Wethen use a generic tagger, FREELING,10to labelthe training data, this time with possible addi-tional inconsistent annotations.
The correspond-ing error rate for Spanish was 6.1%, to be com-pared with the 8.2% achieved by HBAL.
The lasttwo control experiments show that many of the re-maining labeling errors seem to be due to domainand convention mismatches rather to the trans-fer/ambiguous setting, as supervised models alsosuffer from very similar conditions.These observations show that the evaluation oftransfer-based methods suffer from several biases.Their results must therefore be interpreted withgreat care.5 ConclusionIn this paper, we have presented a novel learningmethodology to learn from ambiguous supervisioninformation, and used it to train several POS tag-gers.
Using this method, we have been able toachieve performance that surpasses the best re-ported results, sometimes by a wide margin.
Fur-ther work will attempt to better analyse these re-sults, which could be caused by several subtledifferences between HBAL and the baseline sys-tem.
Nonetheless, these experiments confirm thatcross-lingual projection of annotations have thepotential to help in building very efficient POStaggers with very little monolingual supervisiondata.
Our analysis of these results also suggeststhat, for this task, additional gains might be moreeasily obtained by fixing systematic biases intro-duced by conflicting mappings between tags orby train/test domain mismatch than by designingmore sophisticated weakly supervised learners.AcknowledgmentsWe wish to thank Thomas Lavergne and Alexan-dre Allauzen for early feedback and for providingus with the partially observed CRF implementa-tion.
We also thank the anonymous reviewers fortheir helpful comments.ReferencesEzra Black, Fred Jelinek, John Lafferty, David M.Magerman, Robert Mercer, and Salim Roukos.1992.
Towards history-based grammars: Using10http://nlp.lsi.upc.edu/freeling/1783richer models for probabilistic parsing.
In Proceed-ings of the Workshop on Speech and Natural Lan-guage, HLT ?91, pages 134?139, Stroudsburg, PA,USA.
Association for Computational Linguistics.Antoine Bordes, Nicolas Usunier, and Jason Weston.2010.
Label ranking under ambiguous supervisionfor learning semantic correspondences.
In ICML,pages 103?110.J?rgen Broschart.
2009.
Why Tongan does it differ-ently: Categorial distinctions in a language withoutnouns and verbs.
Linguistic Typology, 1:123?166,10.Timothee Cour, Ben Sapp, and Ben Taskar.
2011.Learning from partial labels.
Journal of MachineLearning Research, 12:1501?1536, July.Dipanjan Das and Slav Petrov.
2011.
Unsupervisedpart-of-speech tagging with bilingual graph-basedprojections.
In Proceedings of the 49th AnnualMeeting of the Association for Computational Lin-guistics: Human Language Technologies - Volume1, HLT ?11, pages 600?609, Stroudsburg, PA, USA.Association for Computational Linguistics.Hal Daum?, III and Daniel Marcu.
2005.
Learningas search optimization: Approximate large marginmethods for structured prediction.
In Proceedingsof the 22Nd International Conference on MachineLearning, ICML ?05, pages 169?176, New York,NY, USA.
ACM.Nicholas Evans and Stephen C. Levinson.
2009.
Themyth of language universals: Language diversityand its importance for cognitive science.
Behavioraland Brain Sciences, 32:429?448, 10.Kuzman Ganchev and Dipanjan Das.
2013.
Cross-lingual discriminative learning of sequence modelswith posterior regularization.
In Proceedings of the2013 Conference on Empirical Methods in Natu-ral Language Processing, pages 1996?2006, Seattle,Washington, USA, October.
Association for Compu-tational Linguistics.Kuzman Ganchev, Jennifer Gillenwater, and BenTaskar.
2009.
Dependency grammar inductionvia bitext projection constraints.
In Proceedings ofthe Joint Conference of the 47th Annual Meeting ofthe ACL and the 4th International Joint Conferenceon Natural Language Processing of the AFNLP:Volume 1 - Volume 1, ACL ?09, pages 369?377,Stroudsburg, PA, USA.
Association for Computa-tional Linguistics.Rebecca Hwa, Philip Resnik, Amy Weinberg, ClaraCabezas, and Okan Kolak.
2005.
Bootstrappingparsers via syntactic projection across parallel texts.Nat.
Lang.
Eng., 11(3):311?325, September.Sungchul Kim, Kristina Toutanova, and Hwanjo Yu.2012.
Multilingual named entity recognition usingparallel data and metadata from wikipedia.
In Pro-ceedings of the 50th Annual Meeting of the Associ-ation for Computational Linguistics: Long Papers- Volume 1, ACL ?12, pages 694?702, Stroudsburg,PA, USA.
Association for Computational Linguis-tics.Mikhail Kozhevnikov and Ivan Titov.
2013.
Cross-lingual transfer of semantic role labeling models.In Proceedings of the 51st Annual Meeting of theAssociation for Computational Linguistics (Volume1: Long Papers), pages 1190?1200, Sofia, Bulgaria,August.
Association for Computational Linguistics.Shen Li, Jo?o V. Gra?a, and Ben Taskar.
2012.
Wiki-lysupervised part-of-speech tagging.
In Proceedingsof the 2012 Joint Conference on Empirical Methodsin Natural Language Processing and ComputationalNatural Language Learning, EMNLP-CoNLL ?12,pages 1389?1398, Stroudsburg, PA, USA.
Associa-tion for Computational Linguistics.Ryan McDonald, Joakim Nivre, Yvonne Quirmbach-Brundage, Yoav Goldberg, Dipanjan Das, Kuz-man Ganchev, Keith Hall, Slav Petrov, HaoZhang, Oscar T?ckstr?m, Claudia Bedini, N?riaBertomeu Castell?, and Jungmee Lee.
2013.
Uni-versal dependency annotation for multilingual pars-ing.
In Proceedings of the 51st Annual Meeting ofthe Association for Computational Linguistics (Vol-ume 2: Short Papers), pages 92?97, Sofia, Bulgaria,August.
Association for Computational Linguistics.Sebastian Pad?
and Mirella Lapata.
2009.
Cross-lingual annotation projection of semantic roles.
J.Artif.
Int.
Res., 36(1):307?340, September.Slav Petrov, Dipanjan Das, and Ryan McDonald.
2012.A universal part-of-speech tagset.
In Nicoletta Cal-zolari (Conference Chair), Khalid Choukri, ThierryDeclerck, Mehmet U?gur Do?gan, Bente Maegaard,Joseph Mariani, Jan Odijk, and Stelios Piperidis, ed-itors, Proceedings of the Eight International Con-ference on Language Resources and Evaluation(LREC?12), Istanbul, Turkey, may.
European Lan-guage Resources Association (ELRA).St?phane Ross and Drew Bagnell.
2010.
Efficient re-ductions for imitation learning.
In AISTATS, pages661?668.Yoshimasa Tsuruoka, Yusuke Miyao, and Jun?ichiKazama.
2011.
Learning with lookahead: Canhistory-based models rival globally optimized mod-els?
In Proceedings of the Fifteenth Conference onComputational Natural Language Learning, pages238?246, Portland, Oregon, USA, June.
Associationfor Computational Linguistics.Oscar T?ckstr?m, Dipanjan Das, Slav Petrov, RyanMcDonald, and Joakim Nivre.
2013.
Token andtype constraints for cross-lingual part-of-speech tag-ging.
Transactions of the Association for Computa-tional Linguistics, 1:1?12.1784Lonneke van der Plas, Marianna Apidianaki, and Chen-hua Chen.
2014.
Global methods for cross-lingualsemantic role and predicate labelling.
In Proceed-ings of COLING 2014, the 25th International Con-ference on Computational Linguistics: TechnicalPapers, pages 1279?1290, Dublin, Ireland, August.Dublin City University and Association for Compu-tational Linguistics.Mengqiu Wang and Christopher D. Manning.
2014.Cross-lingual projected expectation regularizationfor weakly supervised learning.
Transactions of theACL, 2:55?66, February.David Yarowsky, Grace Ngai, and Richard Wicen-towski.
2001.
Inducing multilingual text analy-sis tools via robust projection across aligned cor-pora.
In Proceedings of the First International Con-ference on Human Language Technology Research,HLT ?01, pages 1?8, Stroudsburg, PA, USA.
Asso-ciation for Computational Linguistics.Yuan Zhang, Roi Reichart, Regina Barzilay, and AmirGloberson.
2012.
Learning to map into a univer-sal pos tagset.
In Proceedings of the 2012 JointConference on Empirical Methods in Natural Lan-guage Processing and Computational Natural Lan-guage Learning, EMNLP-CoNLL ?12, pages 1368?1378, Stroudsburg, PA, USA.
Association for Com-putational Linguistics.1785
