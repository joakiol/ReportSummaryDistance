Proceedings of the 2009 Workshop on Grammar Engineering Across Frameworks, ACL-IJCNLP 2009, pages 1?9,Suntec, Singapore, 6 August 2009. c?2009 ACL and AFNLPExploration of the LTAG-Spinal Formalism and Treebankfor Semantic Role LabelingYudong Liu and Anoop SarkarSchool of Computing ScienceSimon Fraser University{yudongl,anoop}@cs.sfu.caAbstractLTAG-spinal is a novel variant of tradi-tional Lexicalized Tree Adjoining Gram-mar (LTAG) introduced by (Shen, 2006).The LTAG-spinal Treebank (Shen et al,2008) combines elementary trees ex-tracted from the Penn Treebank with Prop-bank annotation.
In this paper, we presenta semantic role labeling (SRL) systembased on this new resource and provide anexperimental comparison with CCGBankand a state-of-the-art SRL system basedon Treebank phrase-structure trees.
Deeplinguistic information such as predicate-argument relationships that are either im-plicit or absent from the original PennTreebank are made explicit and accessiblein the LTAG-spinal Treebank, which weshow to be a useful resource for semanticrole labeling.1 IntroductionSemantic Role Labeling (SRL) aims to identifyand label all the arguments for each predicate ina sentence.
Specifically, it involves identifyingportions of the sentence that represent the pred-icate?s arguments and assigning pre-specified se-mantic roles to them.
[A0seller Ports of Call Inc.] reached agreements to[Vverb sell] [A1thing its remaining seven aircraft][A2buyer to buyers that weren?t disclosed] .is an example of SRL annotation from the Prop-Bank corpus (Palmer et al, 2005), where the sub-scripted information maps the semantic roles A0,A1 and A2 to arguments for the predicate sell asdefined in the PropBank Frame Scheme.The availability of annotated corpora like Prop-Bank and FrameNet (Fillmore et al, 2001) haveprovided rapid development of research intoSRL (Gildea and Jurafsky, 2002; Gildea andPalmer, 2002; Surdeanu et al, 2003; Chen andRambow, 2003; Gildea and Hockenmaier, 2003;Xue and Palmer, 2004; Pradhan et al, 2004; Prad-han et al, 2005).
The shared tasks in CoNLL-2004 (Carreras and Ma`rquez, 2004), CoNLL-2005 (Carreras and Ma`rquez, 2005) and CoNLL-2008 (Surdeanu et al, 2008) were all focused onSRL.SRL systems (Gildea and Jurafsky, 2002;Gildea and Palmer, 2002) have extensively usedfeatures defined over Penn Treebank phrase-structure trees.
Other syntactic representationssuch as CCG derivations (Gildea and Hocken-maier, 2003) and dependency trees (Hacioglu,2004; Surdeanu et al, 2008) have also been ex-plored.
It has been previously noted that LTAG,which has the useful property of extended domainof locality (EDL), is well-suited to address theSRL task, c.f.
(Chen and Rambow, 2003; Liu andSarkar, 2007).
However, LTAG elementary treeswere extracted from the derived parse trees byusing Magerman-Collins style head-percolationbased heuristic rules (Liu and Sarkar, 2007).
TheLTAG-spinal Treebank (Shen et al, 2008) pro-vided a corpus of derivation trees where elemen-tary trees were extracted from the Penn Tree-bank in combination with the Propbank predicate-argument annotation.
The LTAG-spinal Treebankcan be used to overcome some of the limitations ofthe previous work on SRL using LTAG: (Liu andSarkar, 2007) uses LTAG-based features extractedfrom phrase-structure trees as an additional sourceof features and combined them with features froma phrase-structure based SRL framework; (Chenand Rambow, 2003) only considers those comple-ment/adjunct semantic roles that can be localizedin LTAG elementary trees, which leads to a lossof over 17% instances of semantic roles even fromgold-standard trees.The LTAG-spinal formalism was initially pro-posed for automatic treebank extraction and sta-tistical parsing (Shen and Joshi, 2005).
However,its Propbank-guided treebank extraction processfurther strengthens the connection between theLTAG-spinal and semantic role labeling.
In thispaper, we present an SRL system that was built to1explore the utility of this new formalism, its Tree-bank and the output of its statistical parser.
Ex-periments show that our LTAG-spinal based SRLsystem achieves very high precision on both gold-standard and automatic parses, and significantlyoutperforms the one using CCGbank.
More im-portantly, it shows that LTAG-spinal is an usefulresource for semantic role labeling, with the po-tential for further improvement.2 LTAG-spinal, its Treebank and ParsersThis section gives a brief introduction of LTAG-spinal formalism, its Treebank that is extractedwith the help of Propbank annotation, and its twostatistical parsers that are trained on the Tree-bank.
Predicate-argument relations encoded in theLTAG-spinal treebank will also be discussed to il-lustrate its compatibility with Propbank and theirpotential utility for the SRL task.2.1 LTAG-spinalThe LTAG-spinal formalism (Shen et al, 2008)is a variant of Lexicalized Tree Adjoining Gram-mar (LTAG) (Abeille?
and Rambow, 2001).
Com-pared to traditional LTAG, the two types of ele-mentary trees (e-tree for short), initial and auxil-iary trees, are in spinal form with no substitutionnodes for arguments appearing in the predicate e-tree: a spinal initial tree is composed of a lexi-cal spine from the root to the anchor, and noth-ing else; a spinal auxiliary tree is composed of alexical spine and a recursive spine from the rootto the foot node.
For example, in Figure 1 (from(Shen et al, 2008)), the lexical spine for the auxil-iary tree is B1, .., Bi, .., Bn, the recursive spine isB1, .., Bi, .., B?1 .
Two operations attachment andadjunction are defined in LTAG-spinal where ad-junction is the same as adjunction in the traditionalLTAG; attachment stems from sister adjunction asdefined in Tree Insertion Grammar (TIG) (Schabesand Shieber, 1994), which corresponds to the casewhere the root of an initial tree is taken as a childof another spinal e-tree.
The two operations areapplied to LTAG-spinal e-tree pairs resulting in anLTAG derivation tree which is similar to a depen-dency tree (see Figure 2).
In Figure 2, e-tree an-chored with continue is the only auxiliary tree; allother e-trees are initial trees.
The arrow is directedfrom parent to child, with the type of operationlabeled on the arc.
The operation types are: attdenotes attachment operation; adj denotes adjunc-tion operation.
The sibling nodes may have differ-AnB1A1Bninitial: auxiliary:B1*BiFigure 1: Spinal elementary treesent landing site along the parent spine.
For ex-ample, among the child nodes of stabilize e-tree,to e-tree has VP as landing site; while even has Sas landing site.
Such information, on some level,turns out to be helpful to differentiate the semanticrole played by the different child nodes.So far, we can see that in contrast with tradi-tional LTAG where arguments refer to obligatoryconstituents only, subcategorization frames andargument-adjunct distinction are underspecifiedin LTAG-spinal.
Since argument-adjunct disam-biguation is one of the major challenges faced byLTAG treebank construction, LTAG-spinal worksaround this issue by leaving the disambiguationtask for further deep processing, such as seman-tic role labeling.LTAG-spinal is weakly equivalent to traditionalLTAG with adjunction constraints1 (Shen, 2006).The Propbank (Palmer et al, 2005) is an an-notated corpus of verb subcategorization and al-ternations which was created by adding a layerof predicate-argument annotation over the phrasestructure trees in the Penn Treebank.
The LTAG-spinal Treebank is extracted from the Penn Tree-bank by exploiting Propbank annotation.
Specif-ically, as described in (Shen et al, 2008), a PennTreebank syntax tree is taken as an LTAG-spinalderived tree; then information from the Penn Tree-bank and Propbank is merged using tree transfor-mations.
For instance, LTAG predicate coordina-tion and instances of adjunction are recognizedusing Propbank annotation.
LTAG elementarytrees are then extracted from the transformed PennTreebank trees recursively, using the Propbank an-notation and a Magerman-Collins style head per-colation table.This guided extraction process allows syntaxand semantic role information to be combined inLTAG-spinal derivation trees.
For example, the1null adjunction (NA), obligatory adjunction (OA) and se-lective adjunction (SA)2Figure 2: An example of LTAG-spinal sub-derivation tree, from LTAG-spinal Treebank Section 22Figure 3: Three examples of LTAG-spinal derivation trees where predicates and their Propbank styleargument labels are given.
These examples are from LTAG-spinal Treebank Section 22.Penn Treebank does not differentiate raising verbsand control verbs, however, based on the Propbankinformation, LTAG-spinal makes this distinctionexplicit.
Thus, the error of taking a subject ar-gument which is not semantically an argument ofthe raising verb can be avoided.
Another prop-erty of LTAG-spinal Treebank extraction lies in theflexibility and simplicity of the treatment of pred-icate coordination (see (Shen et al, 2008)).
Fig-ure 3 shows three examples of Propbank annota-tion as decorations over the LTAG-spinal deriva-tion trees.
In each derivation tree, each node isassociated with LTAG-spinal e-trees.
Each argu-ment (A0, A1, etc.)
is referred to as A and thepredicate is called P .
In most cases, the argumentis found locally in the derivation tree due to theextended domain of locality in e-trees.
Thus, mostarguments are identified by the pattern P ?
A orP ?
A.
The next section contains a discussion ofsuch patterns in more detail.Two statistical parsers have been developedby Libin Shen specifically for training on theLTAG-spinal treebank: a left-to-right incrementalparser (Shen and Joshi, 2005) and a bidirectionalincremental parser (Shen and Joshi, 2008).
If onecompares the output of these two parsers, the left-to-right parser produces full LTAG-spinal deriva-tion trees (including all the information aboutspecific elementary trees used in the derivationand the attachment information within the e-trees)while the bidirectional parser produces derivationtrees without information about elementary treesor attachment points (similar to output from a de-pendency parser).
In this paper, we use the left-to-right incremental parser for its richer outputbecause our SRL system uses feature functionsthat use information about the elementary trees inthe derivation tree and the attachment points be-tween e-trees.
The landing site of child node alongthe parent spine is useful for identifying differenttypes of arguments in SRL.
For example, assumethe parent spine is ?S-VP-VB-anchor?
(the root la-bel is S, and ?anchor?
is where the lexical item isinserted).
Along with direction information, thelanding site label ?S?
is likely to be a good indi-cator for argument A0 (subject) while the landingsite label ?VP?
could be a good indicator for ?A1?(object).
In this sense, the incremental left-to-right parser is preferable for semantic role label-ing.
However, having been developed earlier thanthe bidirectional parser, the incremental parser ob-tains 1.2% less in dependency accuracy comparedto the bidirectional parser (Shen and Joshi, 2008).2.2 Predicate-argument relations in theLTAG-spinal TreebankThe Propbank-guided extraction process forLTAG-spinal treebank naturally creates a closeconnection between these two resources.
To ex-amine the compatibility of the LTAG-spinal Tree-bank with Propbank, (Shen et al, 2008) providesthe frequency for specific types of paths fromthe predicate to the argument in the LTAG-spinalderivation trees from the LTAG-spinal Treebank.The 8 most frequent patterns account for 95.5%of the total predicate-argument pairs of the LTAG-spinal Treebank, of which 88.4% are directly con-nected pairs.
These statistics not only provide em-3Path Pattern Number Percent1 P?A 8294 81.32 P?A, V?A 720 7.13 P?Px?A 437 4.34 P?Coord?Px?A 216 2.15 P?Ax?Py?A 84 0.826 P?Coord?Px?A 40 0.397 P?Px?Py?A 13 0.13total recovered w/ patterns 9804 96.1total 10206 100.0Table 1: Distribution of the 7 most frequentpredicate-argument pair patterns in LTAG-spinalTreebank Section 22.
P : predicate, A: argument,V : modifying verb, Coord: predicate coordina-tion.pirical justification for the notion of the extendeddomain of locality (EDL) in LTAG-spinal (Shen etal., 2008), they also provide motivation to explorethis Treebank for the SRL task.We collected similar statistics from TreebankSection 22 for the SRL task, shown in Table 1,where 7 instead of 8 patterns suffice in our setting.Each pattern describes one type of P(redicate)-A(rgument) pair with respect to their dependencyrelation and distance in the LTAG-spinal deriva-tion tree.
The reason that we combine the two pat-terns P?A and V?A into one is that from SRLperspective, they are equivalent in terms of the de-pendency relation and distance between the pred-icate.
Each token present in the patterns, such asP, Px, Py, V, A, Ax and Coord, denotes a spinale-tree in the LTAG-spinal derivation tree.To explain the patterns more specifically, takethe LTAG-spinal sub-derivation tree in Figure 2as an example, Assume P(redicate) in question isstabilize then (stabilize ?
even), (stabilize ?if), (stabilize ?
Street), (stabilize ?
continue),(stabilize ?
to) all belong to pattern 1; but only(stabilize ?
Street) is actual predicate-argumentpair.
Similarly, when take continue as P, thepredicate-argument pair (continue ?
stabilize)belongs to pattern 2, where stabilize correspondsto A(rgument) in the pattern; (continue, Street) in(Street ?
stabilize ?
continue) is an example ofpattern 3, where stabilize corresponds to Px andStreet corresponds to A in the pattern 3 schema.Pattern 4 denotes the case where argument (A) isshared between coordinated predicates (P and Px);The main difference of pattern 5-7 exists wherethe sibling node of A(rgument) is categorized into:predicate (Px) in pattern 7, predicate coordinationnode (Coord) in pattern 6 and others (Ax) in pat-tern 5.
We will retain this difference instead ofmerging it since the semantic relation between Pand A varies based on these differences.
Examplesentences for other (rarer) patterns can be foundin (Shen et al, 2008).3 LTAG-spinal based SRL System De-scriptionIn this section, we describe our LTAG-spinal basedSRL system.
So far, we have studied LTAG-spinalformalism, its treebank and parsers.
In particular,the frequency distribution of the seven most seenpredicate-argument pair patterns in LTAG-spinalTreebank tells us that predicate-argument relation-ships typical to semantic role labeling are often lo-cal in LTAG-spinal derivation trees.Pruning, argument identification and argumentclassification ?
the 3-stage architecture now stan-dard in SRL systems is also used in this paper.Specifically, for the sake of efficiency, nodes withhigh probability of being NULL (non-argument)should be filtered at the beginning; usually filter-ing is done based on some heuristic rules; after thepruning stage, argument identification takes placewith the goal of classifying the pruning-survivalnodes into argument and non-argument; for thosenodes that have been classified as arguments, ar-gument classification component will further labelthem with different argument types, such as A0,A1, etc.
Argument identification and classifica-tion are highly ambiguous tasks and are usuallyaccomplished using a machine learning method.For our LTAG-spinal based SRL system, wefirst collect the argument candidates for each pred-icate from the LTAG-spinal derivation tree.
Foreach candidate, features are extracted to capturethe predicate-argument relations.
Binary classi-fiers for identification and classification are trainedusing SVMs and combined in a one-vs-all model.The results are evaluated using precision/recall/f-score.3.1 Candidate Locations for ArgumentsIn SRL systems that perform role labeling of con-stituents in a phrase-structure tree, statistics showthat after pruning, ?98% of the SRL argumentnodes are retained in the gold-standard trees inthe Penn Treebank, which provides a high upper-bound for the recall of the SRL system.
Pruningaway unnecessary nodes using a heuristic makes4learning easier as well, as many of the false posi-tives are pruned away leading to a more balancedbinary classification problem during the seman-tic role identification and classification steps.
Weneed a similar heuristic over LTAG-spinal nodesthat will have high coverage with respect to SRLarguments and provide a high upper-bound for re-call.As previously shown that the seven most fre-quent predicate-argument pair patterns that areused to describe the specific types of paths fromthe predicate to the argument account for?96% ofthe total number of predicate-argument pairs in theLTAG-spinal Treebank.
These patterns provide anatural candidate selection strategy for our SRL.Table 2 shows a similar oracle test applied to theoutput of the LTAG-spinal parser on Section 22.The total drop in oracle predicate-argument iden-tifiation drops 10.5% compared to gold-standardtrees.
9.8% is lost from patterns 1 and 2.
If ex-clude those pairs that belong to pattern i in tree-bank but belong to pattern j (i 6= j) in automaticparses (so the pattern exists but is the wrong onefor that constituent), the number drops to 81.6%from 85.6%.
This indicates that in terms of theimpact of the syntactic parser errors for SRL, theLTAG-spinal parser will suffer even more than thephase structure parser.
An alternative is to exhaus-tively search for predicate-argument pairs withoutconsidering patterns, which we found introducestoo much noise in the learner to be feasible.
Thus,the predicate-argument pairs selected through thisphase are considered as argument candidates forour SRL system.3.2 FeaturesBased on the patterns, features are defined onpredicate-argument pairs from LTAG derivationPath Pattern Number Percent1 P?A 7441 72.92 P?A, V?A 583 5.73 P?Px?A 384 3.84 P?Coord?Px?A 180 1.765 P?Ax?Py?A 75 0.736 P?Coord?Px?A 48 0.477 P?Px?Py?A 22 0.21total recovered w/ patterns 8733 85.6total 10206 100.0Table 2: Distribution of the 7 patterns in LTAG-spinal parser output for Section 22.tree, mainly including predicate e-trees, argumente-trees, intermediate e-trees and their ?topologicalrelationships?
such as operation, spine node, rel-ative position and distance.
The following are thespecific features used in our classifiers:Features from predicate e-tree and its variantspredicate lemma, POS tag of predicate, predicatevoice, spine of the predicate e-tree, 2 variants ofpredicate e-tree: replacing anchor in the spinewith predicate lemma, replacing anchor POS inthe spine with voice.
In Figure 2, if take stabi-lize as predicate, these two variants are S-VP-VB-stabilize and S-VP-VB-active respectively.Features from argument e-tree and its variantsargument lemma, POS tag of argument, NamedEntity (NE) label of the argument, spine of the ar-gument e-tree, 2 variants of argument e-tree: re-placing anchor in the spine with argument lemma,replacing anchor POS with NE label if any, labelof root node of the argument spine.
In Figure 2,if take stabilize as predicate, and Street as argu-ment, the two variants are XP-NNP-street and XP-ORGANIZATION2 respectively.PP content word of argument e-tree if the rootlabel of the argument e-tree is PP, anchor of thelast daughter node.
NE variant of this feature: re-place its POS with the NE label if any.Features from the spine node (SP1) spine node isthe landing site between predicate e-tree and argu-ment e-tree.
Features include the index along thehost spine3, label of the node, operation involved(att or adj).Relative position of predicate and argument in thesentence: before/after.Order of current child node among its siblings.In pattern 1, predicate e-tree is parent, and argu-ment e-tree is child.
This feature refers to the orderof argument e-tree among its siblings nodes (withpredicate e-tree as parent).Distance of predicate e-tree and argument tree inthe LTAG derivation tree: For example, for pattern1 and 2, the distance has value 0; for pattern 3, thedistance has value 1.Pattern ID valued 1-7.
(see Table 1 and Table 2)Combination of position and pattern ID, combi-nation of distance and pattern ID, combination of2XP-NNP is a normalized e-tree form used in (Shen etal., 2008) for efficiency and to avoid the problem of sparsedata over too many e-trees.3it can either be predicate e-tree or argument e-tree.
Forexample, for pattern P?A, the A(rgument) e-tree is the hostspine.5position and order.Features from intermediate predicate e-treesame features as predicate e-tree features.Features from spine node of intermediate pred-icate e-tree and argument e-tree (SP2) forpredicate-argument pairs of pattern 3-7.
Thesefeatures are similar to the SP1 features but insteadbetween intermediate predicate e-tree and argu-ment e-tree.Relative position between predicate e-tree and in-termediate e-tree.Combination relative positions of argument e-treeand intermediate predicate e-tree + relative posi-tion of argument e-tree and predicate e-tree.The features listed above are used to representeach candidate constituent (or node) in the LTAG-spinal derivation tree in training and test data.
Inboth cases, we identify SRLs for nodes for eachpredicate.
In training each node comes with theappropriate semantic role label, or NULL if it doesnot have any (for the predicate).
In test data,we first identify nodes as arguments using thesefeatures (ARG v.s.
NULL classification) and thenclassify a node identified as an argument with theparticular SRL using one-vs-all binary classifica-tion.4 Experiments4.1 Data SetFollowing the usual convention for parsing andSRL experiments, LTAG-spinal Treebank Section2-21 is used for training and Section 23 for test-ing.
Propbank argument set is used which includesnumbered arguments A0 to A5 and 13 adjunct-likearguments.
454 sentences in the Penn Treebankare skipped from the LTAG-spinal Treebank (Shenet al, 2008)4, which results in 115 predicate-argument pairs ignored in the test set.We applied SVM-light (Joachims, 1999) withdefault linear kernel to feature vectors.
30% ofthe training samples are used to fine tune the reg-ularization parameter c and the loss-function costparameter j for both argument identification andclassification.
With parameter validation experi-ments, we set c = 0.1 and j = 1 for {A0, AM-4Based on (Shen et al, 2008), the skipped 454 sentencesamount to less than 1% of the total sentences.
314 of these454 sentences have gapping structures.
Since PTB does notannotate the trace of deleted predicates, additional manualannotation is required to handle these sentences.
For the restof the 146 sentences, abnormal structures are generated dueto tagging errors.NEG}, c = 0.1, j = 2 for {A1, A2, A4, AM-EXT} and c = 0.1 and j = 4 for the rest.For comparison, we also built up a standard 3-stage phrase-structure based SRL system, whereexactly the same data set5 is used from 2004February release of the Propbank.
SVM-light withlinear kernel is used to train on a standard fea-ture set (Xue and Palmer, 2004).
The Charniakand Johnson parser (2006) is used to produce theautomatic parses.
Note that this phrase-structurebased SRL system is state-of-the-art and we haveincluded all the features proposed in the litera-ture that use phrase-structure trees.
This systemobtains a higher SRL accuracy which can be im-proved only by using global inference and otherways (such as using multiple parsers) to improvethe accuracy on automatic parses.4.2 ResultsWe compared our LTAG-spinal based SRL systemwith phrase-structure based one (see the descrip-tion in earlier sections), for argument identifica-tion and classification.
In order to analyze the im-pact of errors in syntactic parsers, results are pre-sented on both gold-standard trees and automaticparses.
Based on the fact that nearly 97% e-treesthat correspond to the core arguments6 belong topattern 1 and 2, which accounts for the largest por-tion of argument loss in automatic parses, the clas-sification results are also given for these core argu-ments.
We also compare with the CCG-based SRLpresented in (Gildea and Hockenmaier, 2003)7,which has a similar motivation as this paper, ex-cept they use the Combinatory Categorial Gram-mar formalism and the CCGBank syntactic Tree-bank which was converted from the Penn Tree-bank.Scoring strategy To have a fair evaluation of argu-ments between the LTAG-spinal dependency parseand the Penn Treebank phrase structure, we reportthe root/head-word based scoring strategy for per-formance comparison, where a case is counted aspositive as long as the root of the argument e-treeis correctly identified in LTAG-spinal and the headword of the argument constituent is correctly iden-tified in phrase structure.
In contrast, boundary-5The same 454 sentences are ignored.6A0, A1, A2, A3, A4, A57Their data includes the 454 sentences.
However, themissing 115 predicate-argument pairs account for less than1% of the total number of predicate-argument pairs in the testdata, so even if we award these cases to the CCGBank systemthe system performance gap still remains.6based scoring is more strict in that the string spanof the argument must be correctly identified inidentification and classification.Results from using gold standard trees Ta-ble 3 shows the results when gold standard treesare used.
We can see that with gold-standardderivations, LTAG-spinal obtains the highest pre-cision on identification and classification; it alsoachieves a competitive f-score (highest f-score foridentification) with the recall upper-bound lowerby 2-3% than phrase-structure based SRL.
How-ever, the recall gap between the two SRL systemsgets larger for classification compared to identifi-cation8, which is due to the low recall that is ob-served with our LTAG-spinal based SRL based onour current set of features.
If compare the differ-ence between the root/head-word based score andthe boundary based score in the 3 scenarios, wenotice that the difference reflects the discrepancybetween the argument boundaries.
It is not sur-prising to see that phrase-structure based one hasthe best match.
However, CCGBank appears tohave a large degree of mismatch.
In this sense,root/head word based scoring provides fair com-parison between LTAG-spinal SRL system and theCCGBank SRL system.Recent work (Boxwell and White, 2008)changes some structures in the CCGBank to cor-respond more closely with the Probbank annota-tions.
They also resolve split arguments that occurin Propbank and add these annotations into a re-vised version of the CCGBank.
As a result theyshow that the oracle f-score improves by over 2points over the (Gildea and Hockenmaier, 2003)oracle results for the numbered arguments only(A0, .
.
., A5).
It remains an open question whethera full SRL system based on a CCG parser trainedon this new version of the CCGBank will be com-petitive against the LTAG-spinal based and phrase-structure based SRL systems.Results from using automatic parses Table 4shows the results when automatic parses are used.With automatic parses, the advantage of LTAG-spinal in the precision scores still exists: givinga higher score in both identification and core argu-ment classification; only 0.5% lower for full argu-ment classification.
However, with over 6% dif-ference in upper-bound of recall (?85.6% fromLTAG-spinal; ?91.7% from Charniak?s parser),8no NULL examples are involved when training for argu-ment classification.the gap in recall becomes larger: increased to?10% in automatic parses from ?6% in gold-standard trees.The identification result is not available forCCG-based SRL.
In terms of argument classifica-tion, it is significantly outperformed by the LTAG-spinal based SRL.
In particular, it can be seen thatthe LTAG-spinal parser performs much better onargument boundaries than CCG-based one.One thing worth mentioning is that since neitherthe LTAG-spinal parser nor Charniak?s parser pro-vides trace (empty category) information in theiroutput, no trace information is used for LTAG-spinal based SRL or the phrase-structure basedSRL even though it is available in their gold-standard trees.5 Conclusion and Future WorkWith a small feature set, the LTAG-spinal basedSRL system described in this paper provides thehighest precision in almost all the scenarios, whichindicates that the shallow semantic relations, e.g.,the predicate-argument relations that are encodedin the LTAG-spinal Treebank are useful for SRL,especially when compared to the phrase structurePenn Treebank.
(Shen et al, 2008) achieves an f-score of 91.6% for non-trace SRL identification onthe entire Treebank by employing a simple rule-based system, which also suggested this conclu-sion.
In other words, there is a tighter connectionbetween the syntax and semantic role labels in theLTAG-spinal representation.However, in contrast to the high precision, therecall performance of LTAG-spinal based SRLneeds a further improvement, especially for the ar-gument classification task.
From SRL perspective,on one hand, this may be due to the pattern-basedcandidate selection, which upper-bounds the num-ber of predicate-argument pairs that can be re-covered for SRL; on the other hand, it suggeststhat the features for argument classification needto be looked at more carefully, compared to thefeature selection for argument identification, es-pecially for A2 and A3 (as indicated by our erroranalysis on the results on the development set).
Apossible solution is to customize a different fea-ture set for each argument type during classifica-tion, especially for contextual information.Experiments show that when following thepipelined architecture, the performance of LTAG-based SRL is more severely degraded by the syn-tactic parser, compared to the SRL using phrase7Identification gold-standard trees (p/r/f%)Scoring LTAG phrase CCGRoot/head-word 96.0/92.1/94.0 93.0/94.0/93.5 n/aclassification (core) gold-standard trees (p/r/f%)Scoring LTAG phrase CCGRoot/head-word 90.6/83.4/86.9 87.2/88.4/87.8 82.4/78.6/80.4classification (full) gold-standard trees (p/r/f%)Scoring LTAG phrase CCGRoot/head-word 88.2/81.7/84.8 86.1/87.1/86.6 76.3/67.8/71.8Boundary 87.4/81.0/84.1 86.0/87.0/86.5 67.5/60.0/63.5Table 3: Using gold standard trees: comparison of the three SRL systems for argument identification,core and full argument classificationIdentification automatic parses (p/r/f%)Scoring LTAG phrase CCGRoot/head-word 85.8/80.0/82.8 85.8/87.7/86.7 n/aclassification (core) automatic parses (p/r/f%)Scoring LTAG phrase CCGRoot/head-word 81.0/71.5/76.0 80.1/82.8/81.4 76.1/73.5/74.8classification (full) automatic parses (p/r/f%)Scoring LTAG phrase CCGRoot/head-word 78.0/70.0/73.7 78.5/80.3/79.4 71.0/63.1/66.8Boundary 72.3/65.0/68.5 73.8/75.5/74.7 55.7/49.5/52.4Table 4: Using automatic parses: comparison of the three SRL systems for argument identification, coreand full argument classificationstructure and CCG formalism.
Even though theleft-to-right statistical parser that was trained andevaluated on the LTAG-spinal Treebank achievesan f-score of 89.3% for dependencies on Section23 of this treebank (Shen and Joshi, 2005), theSRL that used this output is worse than expected.An oracle test shows that via the same 7 patterns,only 81.6% predicate-argument pairs can be re-covered from the automatic parses, which is a bigdrop from 96.1% when we use the LTAG-spinalTreebank trees.
Parser accuracy is high overall,but needs to be more accurate in recovering thedependencies between predicate and argument.Based on the observation that the low recalloccurs not only to the SRL when the automaticparses are used but also when the gold trees areused, we would expect that a thorough error analy-sis and feature calibrating can give us a better ideain terms of how to increase the recall in both cases.In on-going work, we also plan to improvethe dependency accuracy for predicate and argu-ment dependencies by using the SRL predictionsas feedback for the syntactic parser.
Our hypoth-esis is that this approach combined with featuresthat would improve the recall numbers would leadto a highly accurate SRL system.As a final note, we believe that our effort on us-ing LTAG-spinal for SRL is a valuable explorationof the LTAG-spinal formalism and its Treebank re-source.
We hope our work will provide useful in-formation on how to better utilize this formalismand the Treebank resource for semantic role label-ing.AcknowledgementsWe would like to thank Aravind Joshi and Lu-cas Champollion for their useful comments andfor providing us access to the LTAG-spinal Tree-bank.
We would especially like to thank LibinShen for providing us with the LTAG-spinal sta-tistical parser for our experiments and for manyhelpful comments.8ReferencesA.
Abeille?
and O. Rambow, editors.
2001.
Tree Ad-joining Grammars: Formalisms, Linguistic Analysisand Processing.
Center for the Study of Languageand Information.Stephen A. Boxwell and Michael White.
2008.
Pro-jecting propbank roles onto the ccgbank.
In LREC-2008.X.
Carreras and L. Ma`rquez.
2004.
Introduction to theCoNLL-2004 Shared Task.
In CoNLL-2004.X.
Carreras and L. Ma`rquez.
2005.
Introduction to theCoNLL-2005 Shared Task.
In CoNLL-2005.J.
Chen and O. Rambow.
2003.
Use of deep linguisticfeatures for the recognition and labeling of semanticarguments.
In EMNLP-2003.C.J.
Fillmore, C. Wooters, and C.F.
Baker.
2001.Building a large lexical databank which providesdeep semantics.
In PACLIC15-2001.D.
Gildea and J. Hockenmaier.
2003.
Identifying se-mantic roles using combinatory categorial grammar.In EMNLP-2003.D.
Gildea and D. Jurafsky.
2002.
Automatic label-ing of semantic roles.
Computational Linguistics,58(3):245?288.D.
Gildea and M. Palmer.
2002.
The necessity ofparsing for predicate argument recognition.
In ACL-2002.K.
Hacioglu.
2004.
Semantic role labeling using de-pendency trees.
In COLING-2004.T.
Joachims.
1999.
Making large-scale svm learningpractical.
Advances in Kernel Methods - SupportVector Machines.Y.
Liu and A. Sarkar.
2007.
Experimental evaluationof LTAG-based features for semantic role labeling.In EMNLP-2007.M.
Palmer, D. Gildea, and P. Kingsbury.
2005.
Theproposition bank: An annotated corpus of semanticroles.
Computational Linguistics, 31(1).S.
Pradhan, W. Ward, K. Hacioglu, , J. H. Martin, andD.
Jurafsky.
2004.
Shallow Semantic Parsing UsingSupport Vector Machines.
In HLT-NAACL-2004.S.
Pradhan, W. Ward, K. Hacioglu, , J. H. Martin, andD.
Jurafsky.
2005.
Semantic role labeling using dif-ferent syntactic views.
In ACL-2005.Yves Schabes and Stuart M. Shieber.
1994.
Analternative conception of tree-adjoining derivation.Computational Linguistics, 20(1):91?124.L.
Shen and Aravind Joshi.
2005.
Incremental ltagparsing.
In HLT-EMNLP-2005.L.
Shen and A. Joshi.
2008.
Ltag dependency pars-ing with bidirectional incremental construction.
InEMNLP-2008.L.
Shen, L. Champollion, and A. Joshi.
2008.
Ltag-spinal and the treebank: A new resource for in-cremental, dependency and semantic parsing.
Lan-guage Resources and Evaluation, 42(1):1?19.L.
Shen.
2006.
Statistical LTAG Parsing.
Ph.D. thesis,University of Pennsylvania.M.
Surdeanu, S. Harabagiu, J. Williams, andP.
Aarseth.
2003.
Using predicate-argument struc-tures for information extraction.
In ACL-2003.M.
Surdeanu, R. Johansson, A. Meyers, L. Ma`rquez,and J. Nivre.
2008.
The conll 2008 shared taskon joint parsing of syntactic and semantic dependen-cies.
In CoNLL-2008.N.
Xue and M. Palmer.
2004.
Calibrating features forsemantic role labeling.
In EMNLP-2004.9
