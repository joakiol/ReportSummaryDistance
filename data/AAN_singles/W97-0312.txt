Learning to Tag Multilingual Texts Through ObservationScott W. Bennett and Ch inatsu  Aone  and Cra ig  Love l lSRA In ternat iona l4300 Fair Lakes CourtFair fax,  VA 22033{bennett ,aonec, lovel lc} @sra.comAbstractThis paper describes RoboTag, an ad-vanced prototype for a machine learning-based multilingual information extractionsystem.
First, we describe a generalclient/server architecture used in learningfrom observation.
Then we give a detaileddescription of our novel decision-tree tag-ging approach.
RoboTag performance forthe proper noun tagging task in Englishand Japanese is compared against human-tagged keys and to the best hand-codedpattern performance (as reported in theMUC and MET evaluation results).
Re-lated work and future directions are pre-sented.1 In t roduct ionThe ability to tag proper names such as organi-zation, person, and place names in multilingualtexts has great value for tasks like information ex-traction, information retrieval, and machine trans-lation (Aone, Charocopos, and Gorlinsky, 1997).The most successful systems currently rely on hand-coded patterns to identify the desired names intexts (Adv, 1995; Def, 1996).
This approachachieves its best performance using different hand-coded rule sets for each language/domain pair.
Sev-eral of these systems have improved in ease ofuse, particularly in the speed of the write pat-tern/evaluate performance/refine pattern loop whichplays the central role in the development process.One approach in name tagging is to assist in thecreation of hand-coded rules by making it easier forthe developer to mark parts of the name and itssurrounding context o include in the pattern.
Thisboosts productivity in hand-coding rules but still re-quires a significant amount of effort by the developerto identify key parts of the pattern.
A step up fromthis is to determine how to generalize the rule sothat it is more broadly applicable or to suggest othe developer which parts of the context have high-value for inclusion in the pattern.
Nevertheless, askilled developer with a thorough knowledge of theparticular pattern language is still essential.Our goal in developing RoboTag was to make itpossible for an end-user to build a tagging systemsimply by giving examples of what should be tagged,rather than requiring the user to understand a pat-tern language.
RoboTag uses a machine learningalgorithm to discover features that the training ex-amples have in common.
This knowledge is used toconstruct a tagging procedure that can find addi-tional, previously unseen examples for extraction.It was important (for the confidence of our users)that the tagging procedure induced by the systembe easily explained in terms of how it makes its de-cisions.
This was one of the factors that led us toconsider using decision trees (Quinlan, 1993) as a keycomponent of the system.
Other potential learningor statistical approaches for a problem like this (e.g.,Neural Nets or Hidden Markov Models) did not offerthis advantage.
The RoboTag system is particularlywell instrumented for exploration of different learn-ing system parameters and inspection of the inducedtagging procedures.First, we discuss the overall architecture for thel~oboTag system.
Next, we focus on the machinelearning algorithm employed for tag learning.
Wethen present experimental results which compareRoboTag to both human-tagged keys and to the besthand-coded rule systems.
Lastly, related work andfuture directions are discussed.2 RoboTag ArchitectureRoboTag design was motivated by our goal of de-veloping an interactive l arning system.
The systemhad to process a large number of texts as well asprovide the ability to visualize learning results andallow feedback to the learning system.
To this end,RoboTag was designed as a client/server architec-ture.
The client interface is an enhancement of amanual annotation tool.
The interface works withmultiple languages and includes support for bothsingle- and double-byte coding schemes.
We focus onEnglish and Japanese in this paper.
The server por-109tion of the system performs all the document man-agement, text preprocessing, and machine learningfunctions.
Because it was important o facilitate in-teraction between the user and the learning system,it was essential to show learned results rapidly.
Byseparating the client interface from the server whichperforms the learning functionality, it was possibleto use fast machines for the CPU-intensive learningoperations rather than relying on the user's desktopmachine.2.1 Cl ient  In ter faceThe client consists of a tagging tool interface writtenin Tk/Tcl ,  a cross-platform GUI scripting language.The interface, shown in Figure 1, is designed pri-marily to function as a tagging tool.
It makes iteasy for a user to mark and edit tags within mul-tilingual texts.
The tool reads and writes texts inSGML format.
What distinguishes this tagging toolis that the manually tagged documents are passedback through the RoboTag server to build a tag-ging procedure in line with what the user is tagging.RoboTag can thus suggest what should be taggedafter having received some training through observa-tion of the user.
The interface has been augmentedwith several displays that allow for a thorough in-vestigation of the learned tagging procedure.
Theseinclude graphical displays of the induced logic fortagging (cf.
Figure 2), graphical displays of taggingaccuracy (i.e.
precision and recall), and the abilityto inspect the examples from the texts that justifythe induced tagging procedure.2.2 ServerThe RoboTag server performs the tag learning func-tions.
It manages the training and testing files,extracts features, learns tagging procedures fromtagged training texts, and applies them to un-seen test texts.
Each RoboTag client invokes itsown instance of the server to handle its learningtasks.
There can be multiple servers running onthe same machine, each independently handling asingle client's tasks.
The RoboTag server receivescommands from the client and returns learning re-sults to it.
During this dialogue, the server main-tains intermediate results such as learned taggingprocedures, texts that have been preprocessed forlearning or evaluation, and state information for thecurrent task.
This includes the parameter settingsfor the learning algorithm, feature usage statistics,and preprocessor utput.
The client connects to theRoboTag server on a network using TCP/ IP .
Thereis a well-defined interface to the server so it can actas a learning engine for other text handling applica-tions as well.Examples of server commands include:1.
Process a text for training or testing2.
Learn a classifier 1 for a tag3.
Evaluate a learned classifier on a text4.
Load a previously learned classifier or save onefor future use5.
Change a learning parameter6.
Enable or disable a lexical feature3 Learn ing  to  TagRoboTag must learn to place tags of varying typeswithin the text.
This means placing an appropriateSGML begin tag like <PERSON> prior to a per-son's name in the text and following the person'sname with an SGML end tag like </PERSON>.
Inthis paper, in order to compare with other name tag-ging system results as reported in the Message Un-derstanding Conference 6 (MUC-6) (Adv, 1995) andthe Multilingual Entity Task (MET) (Def, 1996), wewill be tagging people, places, and organizations.RoboTag provides for learning other types of tagsas well.For each tag learning task, RoboTag builds twodecision trees - one to predict begin tags and oneto predict end tags.
The results of these classifiersare then combined using a tag matching algorithmto yield complete tags of each type.
A tag post-processing step resolves overlapping tags of differ-ent types using a prioritization scheme.
Altogether,these make up the learned tagging procedure.In this section we describe RoboTag's decisiontree learning, learning representation, learning pa-rameters, the tag matching algorithm, and post-processing.3.1 Decis ion Tree  Learn ingRoboTag learns decision tree classifiers that predictwhere tags of each type should begin and end in thetext.
The decision trees are trained from texts whichhave already been tagged manually.For learning the tag begin/end classifiers, we builddecision trees using C4.5 (Quinlan, 1993).
2 C4.5 isused to learn decision tree classifiers which distin-guish items of one class from another based on at-tributes of the training examples.
These attributesare referred to as fealures.
In using a decision treefor classification, each node indicates a feature testto be performed.
The result of the test indicateswhich branch of the tree to take next.
Ultimately,a leaf node of the tree is reached which specifies theclassification result.
To produce our decision trees,an information theoretic criteria called information1RoboTag uses decision tree classifiers as part of thelearned tagging procedure.
They will be discussed in thenext section.
:C4.5 has been specially adapted to work directly onour preprocessor-produced data structures for more ef-ficient operation rather than through data files which isthe normal mode of operation.110Figure 1: RoboTag Interfacegain ratio is used to measure, at each step of treeconstruction, which feature test would best distin-guish the examples on the basis of their class.
Thesimplest classification problem involves learning todistinguish positive and negative examples of someconcept.
In our case, this means characterizing textpositions where a tag should begin or end from textpositions in which it should not.In order to extract learning features, the Robo-Tag server employs a preprocessor plug-in for eachlanguage it operates with.
This preprocessor per-forms tokenization, word segmentation, morpholog-ical analysis, and lexical lookup as necessary foreach language.
The preprocessor produces outputin a well-defined format across languages which theserver uses in carrying out the learning.
For in-stance, in processing Japanese, RoboTag may usefeatures which are uniquely Japanese but may notbe present in English, or vice versa.
Table 1 showssome of the features used by RoboTag for learning.Figure 2 shows a screen shot of a portion of adecision tree trained to produce begin tags.
Oneof the leaf nodes of the tree has been selected pro-ducing a window which shows person names in con-text as classified at the leaf.
The last test in thebranch prior to the shown window tests to see ifthe word prior to the current word is a person ti-tle (like "President," "Secretary,!'
or "Judge" whena decision is being made about whether to start aname with "Reagan," "Robert," or "Galloway" re-spectively).
The screen shot goes on to show that ifthe previous word is not a person title, the systemconsults the 2nd word prior to the candidate begintag to see if it is an organization oun prefix (suchas "bank", "board", or "court").3.2 Learn ing  Representat ionC4.5 represents training examples as fixed lengthfeature vectors with class labels.
The goal is to learnto predict the class label from the other features inthe vector.
In our case this means learning to labeltokens as begin or end tags from the token's lexicalfeatures.
When RoboTag processes a tagged train-ing text, it creates labeled feature vectors (calledtuples) from the preprocessor data.
One tuple is cre-ated for each token in the text, with the label TRUEor FALSE.
If we are learning a tree to predict be-gin tags, the label is TRUE if the token is the firsttoken inside an SGML tag we are trying to learn,and false otherwise.
Similarly for end tags, the tu-ple is labeled TRUE if the token is the last token ina training tag and false otherwise.A single token usually does not contain enoughinformation to decide whether it makes a good tagbegin or end.
Features from the surrounding tokensmust be used as well.
To create a tuple from a token,RoboTag collects the preprocessor features for thetoken as well as its immediate neighbors.
How manyneighboring tokens to use is determined by a radiusparameter, as will be discussed in Section 3.3.
Aradius of 1 means the current token and both theprevious and next tokens will be part of the tuple (1token in each direction).To fill in the tuple values, RoboTag calls on thepreprocessor as a feature extractor.
Each position inthe tuple's feature vector holds a value from a pre-processor field.
RoboTag can use whatever lexicaland token-type features that the preprocessor pro-111Table 1: Features Used in LearningFeatures ExamplesToken Type lower, upper, cap, hiragana, kanji, katakanaPOS adj, adv, aux, conj, det, n, prep, pro, vLocation continent, country, province, citySemantic Type first name, corporate designator, titleFigure 2: Part of a RoboTag Begin Tag Classifiervides.
In this way the preprocessor forms the back-ground knowledge for the target language.
Once thetraining texts have been represented as tuples, thelearning process can begin.3.3 Learn ing  ParametersThere are several parameters to ~oboTag that af-fect tagging performance.
Below are descriptions ofsome of the parameters.
The Experiments ectiondiscusses the settings that produced the best resultsfor each task.?
Radius:  This controls the number of tokensused to make each training tuple.
A higher ra-dius gives the decision tree algorithm more con-textual information in deciding whether a tokenmakes a good begin or end tag.?
Sampl ing  Rat io:  Creating one tuple fromeach token in a text leads to many more nega-tive training examples than positive, since onlythe tokens at the beginning (or end) of a taggenerate positive training tuples.
Every othertoken forms a negative xample; a place wherea tag did not begin or end.
Too many neg-ative examples can hurt learning accuracy bymaking the system too conservative.
In someextreme cases, this can lead to decision treesthat never predict a tag begin or end no mat-ter what the input.
The sampling ratio is theratio of negative to positive examples to use fortraining.
All of the positive examples are used,and negative xamples are chosen randomly inaccordance with this parameter.
What is in-teresting about the Sampling Ratio is that itallows recall to be traded off for precision di-rectly.
Increasing the sampling ratio gives thelearning system more examples of things thatshould not be tagged, reducing the number offalse positives which increases precision.
Mak-ing the decision trees more conservative in thisway can also lower recall.
Finding a balance ofprecision and recall by tuning this parameter isessential for best results.?
Cer ta in ty  Factor:  This parameter affects de-cision tree pruning, a process used to simplifylearned decision trees.
Pruning helps reduceover-fitting of training data and improves clas-sification accuracy on unseen examples.
Thisparameter takes values between 0 and 1, withlower values meaning more pruning.3.4 The  Match ing  A lgor i thmWhen tagging a text, RoboTag evaluates the learneddecision tree classifiers on the new text to producea list of potential begin and end tags for each tagtype.
These lists are produced independently, andthere may be many ways to pair begin and end tagstogether.
For each begin tag found there may be sev-eral plausible end tags that could pair with it (andvice versa).
The matching algorithm must decidethe best possible pairing of the begin and end tagsfor each tag type.Each potential begin and end tag produced by thedecision tree also has a confidence rating, a numberbetween 0 and 1 estimating the chance of correct112classification.
A scoring function is used to evalu-ate the relative merits of different sets of pairings.In addition to the confidence ratings for the tags,the scoring function makes use of statistical mea-sures like the mean and standard deviation of thetag length in the training examples.
The matehercan be biased to prefer tags longer, shorter, or clos-est to this mean length.Considering all possible begin/end tag pairingsquickly becomes intractable as the number of po-tentially interacting tags increases.
Therefore, thefirst step in the matching process eeks to divide thetext up into a set of non-interacting sections.Each time a begin/end pair is made, any begin orend tags between the pair cannot be used (or theresulting tags would overlap).
This means that eachpair could preclude other possible matches.
The textis divided into sections by observing which tags canpossibly affect other tags.
The mean distance, stan-dard deviation, and match threshold determine thedistance interval within which the matcher searchesfor tag pairs.
If two tags are far enough apart, theycan be matched independently without fear of onepairing precluding another.
These boundary pointsin the text are found first.
Then each independentsection is searched separately for tag pairings.
Thebest pairing set for a section maximizes the sum ofthe scores for each pair in the section.There are three parts to the scoring function fora pair.
The first is the confidence with which thebegin tag tree classifies the token as a good begintag.
The second component is the end tag tree con-fidence.
The last part is a distance score, which iscalculated from the tag length, mean distance, andmatch length preference.
Each of the three lengthpreferences (longest, shortest, or closest o mean dis-tance) uses an appropriate bias to the way in whichthese inputs are combined.3.5 Tag Overlap ResolutionBecause the tag matching algorithm only ensuresnon-overlapping tags within each tag type, it is pos-sible to have cases of embedded tags of differenttypes (like tagging "Boston" as a location within thetag for "Boston Edison Company").
To resolve thesecases, RoboTag uses a static tag priority scheme.
Forproper noun tagging the priority order from highestto lowest is person, entity, place.
We do not cur-rently learn the tag priorities although this is a log-ical extension to the learning technique.4 Exper imentsWe set up experiments on English and Japanesename tagging using the same texts that were usedfor the named entity task of the MUC-6 and METcompetitions.
In this way, we can most easily com-pare RoboTag performance against a variety of othername tagging systems.4.1 English ResultsFor English, the MUC-6 Wall Street Journal cor-pus was used.
RoboTag was trained with 300 train-ing texts and proceeded to automatically tag the30 blind test texts.
The scores on the test set areshown in the Table 2.
For each tag type, the tablegives the total number of tags of that type presentin the training and testing sets and the recall, pre-cision, and F-Measure 3 as measured on the test set.Overall totals are given at the bottom of the table.The best system in the MUC-6 named entitytask, using hand-coded rules, returned F-Measuresof 98.50 for person, 96.96 for place, and 92.48 forentity as shown in Table 3 (Krupka, 1995) .We found that RoboTag's best English resultswere obtained with a sampling ratio of 10, a radiusof 2, and certainty factors of 0.75 for pruning for allthe tag types.4.2 Japanese ResultsIn Japanese, the MET corpus of press-conference re-lated texts from Kyodo News Agency was used in theexperiment.
A training set of 300 texts was usedwith a blind test set of 99.
RohoTag scores on thetest set are reported in Table 4.The best system on the MET task, utilizing hand-coded rules, produced F-Measures of 95.37 for per-son, 93.43 for place, and 86.90 for entity (cf., Ta-ble 5) while the second place system posted 78.54 forperson, 84.00 for place, and 79.25 for entity.
Robo-Tag would have ranked 2nd among the MET systemson the Japanese entity task.Sampling ratios for our best Japanese results were35, 15 and 10 for person, place, and entity.
For allthree tags we used a radius of 2 and certainty factorsof 0.65 for pruning.5 Re la ted  WorkVilain and Day (Vilain and Day, 1996) report onan approach which learns and applies rule sequencesfor the name tagging task (based on Eric Brill's rulesequence work (Brill, 1993)).
It uses a greedy algo-rithm to generate and apply rules, incrementally re-fining the target concept.
They report their best pre-cision/recall results for machine-learned rules on theMUC-6 task with equivalent F-Measures 4 of 78.50ZF-measure is calculated by:F= (fl2+l.O) xPxRfl~ xP+Rwhere P is precision, R is recall, and fl is the relativeimportance given to recall over precision.
In this case, f= 1.0 as used in MUC-6 and MET.4The F-Measure formula they report seems to be inerror and they reported with a fl of 0.8.
For comparison,we used the standard F-Measure formula with a fl of 1as reported above.113Table 2: RoboTag English ResultsTag Type # Training ~ Testing Testing Recall I Testing Precision F-MeasurePerson 1978 372 93.5 95.9 94.7Place 2495 110 95.5 89.7 92.5Entity 3551 448 79.7 83.4 81.5Total 8024 930 87.1 89.2 88.1Table 3: Best MUC-6 English ResultsTag Type # Poss I Recall Precision F-MeasurePerson 373 98 99 98.5Place 110 99 95 96.96Entity 447 91 94 92.48Total 930 94.8 96.1 95.4Table 4: RoboTag Japanese ResultsTag Type # Training # Testing Testing Recall Testing Precision F-MeasurePerson 1081 346 81.0 89.9 85.2Place 1960 756 84.5 88.7 86.6Entity 1958 596 77.1 80.7 78.84999 81.2 Total 86.1 1698 83.6Table 5: Best MET Japanese ResultsTag Type \] # Poss I Recall Precision IF-MeasurePerson 346 92 99 95.37Place 756 91 96 93.43Entity 596 84 90 86.90Total 1698 88.8 94.5 91.5114for person, 74.35 for place, and 82.81 for entity.
OurEnglish score is significantly better, especially forthe person and place tasks.
Because their Japaneseresults were not reported we cannot compare ourJapanese performance.Gallippi (Gallippi, 1996) presents an approach totag classification using decision trees.
Hand-codedrules are employed to delimit proper nouns withinthe text.
Each proper noun is then classified into anappropriate type (e.g., person, entity, place) usingdecision trees (ID3), an easier task than also learningto place tags.
It is also less general to rely on handcoded rules for a significant part of the tagging task.Bikel et al (Bikel et al, 1997) report on Nymble,an HMM-based name tagging system operating inEnglish and Spanish.
Nymble performs well, turn-ing in F-measures of 90 and 93 respectively in Span-ish and English on the MUC-6 task.
These scoreswere achieved using 450,000 words of tagged text, 3times the size of the 150,000 word training set usedfor the RoboTag experimental results reported here.Bikel reports that moving from 100,000 to 450,000training texts yielded a 1-2% improvement.
A directcomparison with Nymble on particular tag types isnot possible because only the overall F-measure isreported for the MUC-6 task.
In these experimentswe only trained and tested on person, place, and en-tity tags.
If we use RoboTag with our hand-codedrules for dates and number, the overall F-measureon the MUC-6 English task is 90.1.6 Future  D i rec t ionsThere are a number of ways in which RoboTag per-formance could be improved.
Perhaps the most obvi-ous enhancement to our representation involves giv-ing the learning system the actual text of the tokenin the feature vector.
Currently, each tuple containsthe preprocessor information for a window of tokensin the text, but the actual token text is not avail-able to the learning.
The decision trees can refer toclasses of words by their lexicon features, but notindividual words themselves.
Adding this capabilitywould allow performance improvement especially incases where lexicon data is sparse.
Using words asfeatures is related to the idea of automatic word listmodification.
This would allow RoboTag to actuallyreconfigure its knowledge base of word lists and pro-pose new features.
This is one way that RoboTagcould adapt to new extraction domains.Unlike some of the name tagging systems Robo-Tag is being compared to, RoboTag has no aliasgeneration facility.
By generating an alias from arecognized name, a system can scan for that alias(e.g., a company's acronym or an individual's firstname) in order to improve the likelihood of identi-fying it.
It would be straightforward to add such analias capability to RoboTag.Another accuracy enhancement is to improve thetag matching algorithm.
RoboTag does not cur-rently use the lexical features of the tokens duringthe match process.
The scoring function takes intoaccount ag length and decision tree confidence val-ues only.
Many of the errors RoboTag makes comefrom the matching algorithm where the decisiontrees correctly predict tag begins and ends but thewrong tag pairings are chosen.
Making the match-ing algorithm sensitive to lexical features hould helpcorrect his.Although, for comparison with other systems, wehave presented traditional batch-mode learning re-sults here, one of RoboTag's trengths is in its in-teractivity.
We believe that allowing the user togive direct feedback to the learning system is key torapidly addressing new extraction tasks.
We plan todo further experiments which address how the use of ?this directed feedback can result in rapidly learnedtagging procedures utilizing fewer tagged texts.Finally, our experiments have focused on propername tagging, but RoboTag is not limited to this.We are planning to explore additional tagging tasksbesides names in multiple languages such as Chinese,Thai, Spanish as well as English and Japanese.7 SummaryRoboTag is a multilingual text extraction systemthat automatically learns to tag texts by observ-ing its users.
Decision trees are learned to predictwhere users begin and end tags.
These are combinedwith a matching algorithm to produce complete tags.RohoTag is flexible in its ability to work with mul-tiple languages.
We have shown RoboTag perfor-mance to be competitive with hand-coded pattern-based systems in very different languages like En-glish and Japanese.Re ferencesAdvanced Research Projects Agency.
1995.
Proceed-ings of Sixth Message Underslanding Conference(MUC-6).
Morgan Kaufmann Publishers.Aone, Chinatsu, Nicholas Charocopos, and JamesGorlinsky.
1997.
An Intelligent Multilingual In-formation Browsing and Retrieval System UsingInformation Extraction.
In Proceedings of theFifth Conference on Applied Natural LanguageProcessing.Bikel, Daniel M., Scott Miller, Richard Schwartz,and Ralph Weischedel.
1997.
Nymble: a High-Performance Learning Name-finder.
In Proceed-ings of the Fifth Conference on Applied NaturalLanguage Processing.Brill, Eric.
1993.
A Corpus-based Approach to Lan-guage Learning.
Ph.D. thesis, University of Penn-sylvania.115Defense Advanced Research Projects Agency.
1996.Advances in Text Processsing: TIPSTER PRO-GRAM (Phase II).
Morgan Kaufmann Publishers.Gallippi, Anthony.
1996.
Recognizing Names AcrossLanguages.
In Proceedings of the 16th Interna-tional Conference on Computational Linguistics(COLING).Krupka, George.
1995.
SRA: Description of theSRA System as Used for MUC-6.
In Proceed-ings of Sixth Message Understanding Conference(MUC-6).Quinlan, J. Ross.
1993.
C~.5: Programs for Ma-chine Learning.
Morgan Kaufmann Publishers.Vilain, Marc and David Day.
1996.
Finite-state andphrase parsing by rule sequences.
In Proceedingsof the 16th International Conference on Compu-tational Linguistics (COLING).116
