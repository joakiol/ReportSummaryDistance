IApp l i ca t ion  of  NLP  techno logy  to product ion  o f  c losed-capt ionTV  programs in Japanese  for the  hear ing  impa i redTakahiro Wakao Terumasa EharaTelecommunications NHK Science andAdvancement TechnicalOrganization (TAO) Research Labs.of Japan / TAOEiji SawamuraTAOYoshiharu AbeMitsubishiElectric CorpInformationTechnologyR&D Center / TAOKatsuhiko ShiraiWaseda UniversityDepartment ofInformation andComputer Science/ TAO1 IntroductionThe Telecommunications Advancement Organiza-tion (TAO) of Japan, with the support of the min-istry of Posts and Telecommunications, hasinitiateda project in which electronically available text ofTV news programs i summarized and synchronizedwith the speech and video automatically, then su-perimposed on the original programs for the benefitof the hearing impaired people in Japan.
This kindof service has been provided for more than 70% ofthe TV programs in the United States or in Europe,however, it is available in only 10% of the TV pro-grams in Japan.
Most of the closed captions areliteral transcriptions ofwhat is being said.
Reasonswhy the availability is low are firstly that thousandsof characters are used in the Japanese language,and secondly that the closed captions are producedmanually at present and it is a time-consuming andcostly task.The project started in 1996 and will end in 2001.Its annual budget is 200 million yen.
The main aimof the project is to establish the technology of pro-ducing closed captions for TV programs efficientlyusing natural language processing and speech recog-nition technology.We describe main research issues and the projectschedule, and show the results of preliminary re-search.2 Research IssuesMain research issues in the project are as follows:?
automatic text summarization?
automatic synchronization f text and speech?
building an efficient closed caption productionsystemWe would like to have the following system (Figure1) based on the research on the above issues.Although all types of TV programs are to be han-dled in the project, the first priority is given to TVnews programs.The outline of each research issue is describednext.2.1 Automatic Text SummarizationFor most of the TV news programs today, scripts(written text) are available before they are read outby newscasters.
The Japanese news text is read atthe speed of four hundred characters per minute andit is too fast, and there are too many characters whenall the characters of what is said are shown on thescreen (Komine et al, 1996).
Thus we need to sum-marize the news program text and then show it onTV screen.
The aim of the research on automatictext summarization is to summarize the text fullyor partially automatically to a proper size in orderto assist he closed caption production.2.2 Automatic Synchronization of Text andSpeechOnce the original news program text is summarized,it should be synchronized with the actual sound, orthe speech of the programs.
At present this is doneby hand when the closed captions are produced.
Wewould like to make use of speech recognition tech-nology to help the task of synchronizing text withspeech.
Please note that what we aim at is to syn-chronize the original te'xt rather than the summa-rized text with the speech.2.3 Efficient Closed Caption ProductionSystemWe will create a system by integrating the summa-rization and synchronization techniques with tech-niques for superimposing characters.
We also needto research on other aspects uch as what the bestway is to show the characters on the screen for thehandicapped viewers.55VTR VTR odst~ wozrm~ W \ [  __i J audio & t/me code : mgtlo & time-cede .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
!closed !
auto_=___.A____~c synchronization }automatic recognit ionsummarization J j | ~ iLori2inalABCDEFG, ~ IJKI~It4NJod~i~l ~ ~me codeABCDEFG ABC .
.
.
.
.
.
.H UKLMN HI Jim)gnun withFigure 1: System Outline3 P ro jec t  Schedu leThe project is divided into two stages; the first threeyears and the rest, two years.
We conduct researchon the above issues and create a prototype system inthe first stage.
In addition, the prototype system isto be used to produce closed captions, and the capa-bility and functions of the system will be evaluated.We will improve the prototype system in the secondstage.In 1996 and 1997, the following research as beenconducted and will be continued.?
Automatic text summarization- method for dividing a sentence into smallersections- key word extraction- method for connecting sentence sections?
Automatic synchronization f text and speech-transcription, speech model integrationsystem- maximum likelihood matching system- speech database?
E~cient closed caption production system- integrated simulation system for closedcaption production4 Pre l iminary  Research  Resu l tsWe have conducted preliminary research for auto-matic text summarization and synchronization oftext and speech, and the results are as follows.4.1 Automat ic  Text  Summar izat ionText summarization research in the past may hegrouped into three approaches.
The first is to gen-erate summarized sentences based on understandingof the text.
It is desirable, however, it is not a prac-tical method at present in order to summarize actualTV news program text.The second is to digest he text by making use oftext structures such as paragraphs.
It has been ap-plied to newspaper articles in Japanese (Yamamotoet al 1994).
In this approach important parts of thetext which are to be kept in the summarization, aredetermined by their locations, i.e.
where they ap-pear in the text.
For example, if nouns or propernouns appear in the headline, they are consideredas 'important' and may be used as measures of find-ing out how important the other parts of the textare.
As we describe later, TV news text is differ-ent from newspaper articles in that it does not haveobvious structures, i.e.
the TV news text has fewersentences and usually only one paragraph withouttitles or headlines.
Thus the second approach is notsuitable for the TV news text.The third is to detect important (or relevant)words (segments in the case of Japanese), and deter-mine which section of the text is important, and thenput them together to have 'summarization' of thetext.
This is probably most robust among the threeapproaches and we are using the third approach cur-rently (for summary of various ummarization tech-niques, please see (Paice, 1990)).To illustrate the difference between TV news pro-gram text and newspaper articles, we compared one56thousand randomly selected articles from both do-mains.
The results are shown in Fig 2 and Fig 3.0.3o0.2o".~ 0,10.0 .
.
.
.
.I0 20 30 40 50 60 70number of sentences per articlesolid line: TV, dotted line: newspaperFigure 2: Number of sentences per article0.20.1 '  " -  .
.
.
.
.
.
.
.
.
.
.
.
.
.
.oo,0 200 600characters per sentencesolid line: TV, dotted line: newspaper400Figure 3: Number of characters per sentenceFig 2 and Fig 3 show that in comparison withnewspaper text, the TV news program text has thefollowing features:?
Fewer sentences per text?
Longer sentencesIf we summarize TV news program text by se-lecting 'sentences' from the text, it will be 'rough'summarization.
On the other hand, if we can di-vide long sentences into smaller sections and thusincrease the number of 'sentences ( ections)' in thetext, then we may have better summarization (Kimand Ehara, 1994):As a method of summarization, we are using thethird approach.
To find important words in the text,high-frequency key word method and TF-IDF (TermFrequency - Inverse Document Frequency) methodhave been adopted, and the two methods are eval-uated automatically on a large-scale in our prelim-inary research.
We used ten thousand (10000) TVnews texts between 1992 and 1995 (2500 texts eachyear) for the evaluation.
One of the features of theTV news texts is that the first sentence is the mostimportant.
We conducted the evaluation by takingadvantage of the feature.Key words used in the high-frequency key wordmethod are content words which appear more thantwice in a given text (Luhn, 1957),(Edmundson,1969).
To determine the importance of a sentence,we counted the number of the key words in the sen-tence and then it is divided by the number of thewords (including function and content words).
Inthe TF-IDF method, first the weight of each wordis computed by multiplying its frequency in the text(TF) and its IDF in a given text collection.
The im-portance of the sentence is thus computed by sum-ming up all the weights of the words in the sen-tence and divided by the number of the words (SparkJones, 1972), (Salton, 1971).The evaluation details are as follows.
First, theimportance of each sentence is calculated by thehigh-frequency key word or TF-IDF method.
Thenthe sentence are ranked according to their impor-tance.
We computed the accuracy of the method bylooking at whether the first sentence is ranked thefirst, or ranked either the first or the second.The evaluation results are shown in Table 1.
Thehigh-frequency key word method produced better e-sults than TF-IDF method id.Method First First_or.Second(%) (%)High-frequency key word 68.86 88.95TF-IDF 54.02 80.67Table 1: Sentence Extraction Accuracy4.2 Automatic Synchronization of Text andSpeechAs the next step, we need to synchronize the textand the speech.
First, the written TV news textis changed into the stream of phonetic transcrip-tions, and then synchronization is done by detect-ing the time points of the text sections and theircorresponding speech sections.
At the same time,we havestarted to create news speech database.
In1996, we collected the speech data by simulatingnews programs, i.e.
the TV news texts were readand recorded in a studio rather than actual TV newsprograms on the air were recorded.
We collectedseven and half hours of recordings of twenty people57(both male and female).
We plan to record actualprograms as 'real' data in addition to the simulationrecording in 1997.
The real data will be taken fromboth radio and TV  news programs.Preliminary research on detection of synchroniza-tion points is conducted by using the data we havecreated.
A speech model is produced by using threehours (four male and four female persons) of record-ing as training data.
For each speaker, a two-loop, four-mixture-distribution phonetic HMM waslearned.
Based on the HMMs, key-word pair modelswere obtained from the phonetic transcription.
Thekey-word pair model is shown in Fig 4.
The modelconsists of two strings of words (keywordsl and key-words2) before and after the synchronization point(point B).NULL ARCBFigure 4: key-word pair modelWhen the speech is fed to the model, the non-synchronizing input data travel through the garbagearc while the synchronizing data go through the key-words.
It means that the likelihood at point B in-creases.
Thus if we observe the likelihood at pointB and it goes over a certain threshold, we decideit is the synchronization point for the input data.Twenty-one key-word pairs were taken from the datawhich was not used in the training, and selected forevaluation.
We fed one male and one female speechto the model in the evaluation.
The result is shownin Table 2.As we decrease the threshold, the detection rateincrease, however, the false alarm rate increasesrapidly.5 Conc lus ionWe have described a national project in which'speech' of TV programs is changed into captions,and superimposed to the original programs for thebenefit of the hearing impaired people in Japan.
Wealso showed results of preliminary research on TVnews text summarization, and synchronization oftext and speech.
We continue to integrate the natu-ral language processing and speech processing tech-nology for efficient closed caption production sys-tem, and put it to a practical use as soon as possible.Threshold Detection Rate False Alarm Rate(%) (FA/KW/Hour)-10-20-30-40-50-60-70-80-90-10069.0576.1985.7190.4892.8697.6297.6297.6297.6297.622.789.1739.72131.93409.97975.751774.302867.554118.565403.45Table 2: Synchronization DetectionReferencesKomine, K., Hoshino, H., Isono, H., Uchida, T., Iwa-hana, Y.
1996 Cognitive Experiments of NewsCaptioning for Hearing Impaired Persons Techni-cal Report of IEICE (The Institute of Electron-ics, Information and Communication Engineers),HCS96-23, in Japanese, pages 7-12.H.P.
Luhn 1957 A statistical approach to the mech-anized encoding and searching of literary infor-mation In IBM Journal of Research and Develop-ment, 1(4), pages 309--317H.P.
Edmundson 1969 New Methods in AutomaticExtracting.
In Journal of the ACM, 16(2), pages264-285.Chris D. Paice 1990 Constructing literature ab-stracts by computer: techniques and prospects.In Information Processing ~ Management 26(1),pages 171-186.
Pergamon Press plc.Yeun-Bae Kim, Terumasa Ehara.
1994.
An Auto-matic Sentence Breaking and Subject SupplementMethod for J /E  Machine Translation InformationProcessing Society of Japan, Ronbun-shi, Vol 35,No.
6.
In Japanese.Gerard Salton 1971 (Ed) The Smart Retrieval Sys-tem - Experiments in Automatic Document Re-trieval, Englewood Cliffs, N J: Prentice Hall Inc.Karen Spark Jones 1972 A statistical interpretationof term specificity and its application in retrievalIn Journal of Documentation, 28(1), pages 11-21.Kazuhide Yamamoto, Shigeru Masuyama, ShozoNaito 1994 GREEN: An Experimental Sys-tem Generating Summary of Japanese Editorialsby Combining Multiple Discourse CharacteristicsNL-99-3, Information Processing Society of Japan.In Japanese.58
