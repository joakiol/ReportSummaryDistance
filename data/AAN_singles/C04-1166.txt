From Controlled Document Authoringto Interactive Document NormalizationAure?lien MaxGroupe d?E?tude pour la Traduction AutomatiqueGETA-CLIPSGrenoble, Franceaurelien.max@imag.frAbstractThis paper presents an approach to nor-malize documents in constrained domains.This approach reuses resources developedfor controlled document authoring and isdecomposed into three phases.
First, can-didate content representations for an inputdocument are automatically built.
Then,the content representation that best corres-ponds to the document according to an ex-pert of the class of documents is identified.This content representation is finally used togenerate the normalized version of the docu-ment.
The current version of our prototypesystem is presented, and its limitations arediscussed.1 Document normalizationThe authoring of documents in constraineddomains and their translation into other lan-guages is a very important activity in industrialsettings.
In some cases, the distinction betweentechnical writers and technical translatorshas started to blur, so as to minimize thetime and efforts needed to obtain multilingualdocuments.
The paradigm of translation formonolinguals introduced by Kay in 1973 (Kay,1997)1 led the way to a new conception ofthe authoring task, which first materializedwith systems involving human disambiguation(e.g.
(Boitet, 1989; Somers et al, 1990)).
Arelated paradigm emerged in the 90s (Hartleyand Paris, 1997), whereby a technical authoris responsible for providing the content of adocument and a generation system producesmultilingual versions of it.
Updating docu-ments is then done by updating the documentcontent, and only some postediting may takeplace instead of full translation by a humantranslator.Systems implementing this paradigm rangefrom template-based multilingual document1This is a reedition of the original article.Figure 1: Architecture of a MDA systemcreation to systems presenting the user withthe evolving text of the document (often calledthe feedback or control text) in her language,following from the WYSIWYM (What You SeeIs What You Meant) approach (Power andScott, 1998).2 Anchors (or active zones) inthe text of the evolving document allow theuser to specify further its semantics by makingchoices presented to her in her language.
Theunderlying content representation is then usedto generate the text of the document in as manylanguages as the system supports.
The MDA(Multilingual Document Authoring) system(Dymetman et al, 2000; Brun et al, 2000)follows the WYSIWYM approach, but putsa strong emphasis on the well-formedness ofdocument semantic content.
More particularly,document content can be specified in termsof communicative goals, allowing the selectionof messages which are contrastive withinthe modelled class of documents in no moresteps than is needed to identify a predefinedcommunicative goal.
Figure 1 illustrates the ar-chitecture of a MDA system.
A MDA grammarspecifies the possible content representations ofa document in terms of trees of typed semanticobjects in a formalism inspired from DefiniteClause Grammars (Pereira and Warren, 1980).2We have done a review of these systems in (Max,2003a) in which we have identified and compared fivefamilies of approaches.Figure 2: Document normalization in a givenclass of documentsConsidering all the possibilities offered byhaving the semantic description of a docu-ment, for example the exploitation withinthe Semantic Web, it seemed very interestingto reuse resources developed for controlleddocument authoring to analyze existing docu-ments.
Also, a corpus study of drug leafletsthat we conducted (Max, 2003a) showed thatdocuments from the same class of documentscould contain a lot of variation, which canhamper the reader?s understanding.
We de-fined document normalization as the process ofthe identification of the content representationproduced by an existing document modelcorresponding best to an input document,followed by the automatic generation of thetext of the normalized document from thatcontent representation.
This is illustrated infigure 2.In the next section, we briefly describe ourparadigm for document content analysis, whichexploits the MDA formalism in a reverse way.Candidate content representations expressedin the MDA formalism are first produced andranked automatically, and a human expert thenidentifies the one that best accounts for thecommunicative content of the original docu-ment.
The core of this paper is devoted to ourimplementation of interactive negotiation fordocument normalization.
Finally, we discussour results and propose ways of improving thesystem.2 Document normalization systemA MDA grammar can enumerate the well-formed content representations for documentsof a given class and associate textual reali-zations to them (Dymetman et al, 2000).Content representations are typed abstractsemantic trees in which dependencies can beestablished through unification of variables.Generation of text is done in a compositionalmanner from the semantic representation.Figure 3 shows an excerpt of a MDA grammardescribing well-formed commands for the Unixshell.
Such a grammar describes both theabstract semantic syntax and the concretesyntax for a particular language, English in thiscase.
The first rule reads as follows: lsCommandis a semantic object of type shellCommand type,which is composed of an object of type fileSe-lection type, an object of type sortCriteria type,and an object of type displayOptions type.
Textstrings appearing in the right-hand side ofthe rules are used together with the stringsassociated with the present semantic objects tocompose the normalized text associated withthe described abstract semantic trees.Our approach to normalize documents hasbeen described in (Max, 2003b).
A heuristicsearch procedure in the space of content repre-sentations defined by a MDA grammar is firstperformed.
Its evaluation function measuresa similarity score between the document tobe normalized and the normalized documentsthat can be produced from a partial contentrepresentation.
The similarity score is inspiredfrom information retrieval, and takes intoaccount common descriptors and their relativeinformativity in the class of documents.
Theadmissibility property of the search procedureguarantees that the first complete contentrepresentation found is the one with the bestglobal similarity score.
This process uses textgeneration to measure some kind of similarity,and has been called fuzzy inverted generation.In order to better cover the space of textsconveying the same communicative content,the MDA formalism has been extended tosupport non-deterministic generation, allowingthe production of competing texts from thesame content representation, as is illustrated infigure 4.
For each considered content represen-tation, texts are produced and compared to thedocument to be normalized, thus allowing theranking of candidate content representations% semantic object of type ?shellCommand_type?
describing the ?ls?
commandlsCommand(FileSelection, SortCriteria, DisplayOptions)::shellCommand_type-e-[] -->[?List ?
],FileSelection::fileSelection_type-e-[],SortCriteria::sortCriteria_type-e-[],DisplayOptions::displayOptions_type-e-[].fileSelection(ListOfFilesAndDirectories, HiddenFilesSelection, DirectoriesContentsListing, LinksReferenceListing)::fileSelection_type-e-[] -->ListOfFilesAndDirectories::listOfFilesAndDirectories_type-e-[], [?.?
],HiddenFilesSelection::hiddenFilesSelection_type-e-[],DirectoriesContentsListing::directoriesContentsListing_type-e-[],LinksReferenceListing::linksReferencesListing_type-e-[].% ...% description for the type ?linksReferencesListing_type?type_display(e, linksReferencesListing_type, ?specifies how links are shown?
).% description for the objects ?displayLinksReferences?
and ?dontDisplayLinksReferences?functor_display(e, displayLinksReferences,?show the files and directories that are referenced by links?
).functor_display(e, dontDisplayLinksReferences,?show links as such (not the files and directories they point to)?
).displayLinksReferences::linksReferencesListing_type-e-[] -->[?
Display referenced files and directories instead of links.
?
].dontDisplayLinksReferences::linksReferencesListing_type-e-[] -->[?
Display links as such.
?
].Figure 3: MDA grammar extract for the description of the ls Unix commandFigure 4: Identification of the best contentrepresentation through fuzzy inverted genera-tionby decreasing the similarity score.Given the limitations of the similaritymeasure inspired from information retrieval,the search is continued to find the N firstdocuments with the best similarity scores.
Theidentification of the content representation thatrepresents best the communicative contentof the original document is then done byinteractive negotiation between an expert ofthe class of the document and the system basedon the candidates previously extracted.To demonstrate how the implemented systemworks, we will consider the normalization of thefollowing description in English of a commandfor the Unix shell with the grammar of figure3: List all files.
Do not show hidden files and visitsubdirectories recursively.
Sort results by date oflast modification in long format in single-columnin reverse chronological order.
Give file size inbytes.2.1 Finding candidate documentrepresentations: fuzzy invertedgenerationThe MDA grammar used is first precompiledoffline by a separate tool, in order to associateprofiles of text descriptors to semantic objectsand types in the grammar (see (Max, 2003b)for details).
In our current implementation,descriptors are WordNet synsets.
The textof the input document is then lemmatizedand the descriptors are extracted, yielding theprofile of descriptors for the input document.The grammar is then used to construct partialabstract semantic trees, which are ordered ina list of candidates according to the similarityscore computed between their profile and thatof the input document.
At each iteration, thesearch algorithm considers the most promisingcandidate content representation and performsone step of derivation on it, which correspondsto instantiating a variable in the tree with avalue for its type.
The first complete candidate(i.e.
an abstract tree not containing anyvariable) found is then kept, and the searchcontinues until a given number of candidateshas been found.
This number defines a valueof system confidence, which can be selectedby the user of our normalization system: thehigher the confidence, the fewer candidates arekept, at the risk that the best one accordingto an expert may not be present.
Given thesize of the grammar used and the complexityof the analysed document, a small number ofcandidates can be kept (20 in our example).This process restricts the search space froma large collection of virtual documents3 toa comparatively smaller number of concretetextual documents, associated with their se-mantic structure.
A factorization process thenbuilds a unique content representation thatcontains all the different alternative subtreesfound in the candidates.
Each semantic objectin the resulting factorized semantic tree isthen decorated by a list of all the candidatesto which it belongs.
Competing semanticobjects are ranked according to the score ofthe candidate with the highest score to whichthey belong.
This compact representationpermits to consider underspecifications fromthe analysis of the input document present atany depth in the candidate semantic trees.2.2 Identifying the best documentrepresentation: interactivenegotiationDocument normalization implies a normativeview on the analysis of a document.
Because thecommunicative content that will be ultimatelyretained may not be exactly that of the originaldocument, some negotiation must take place todetermine which alternative semantic content, ifany, is acceptable.
This is analoguous to whathappens in translation.
As (Kay et al, 1994)put it:Translation is not a meaning-preserving function from a sourceto a target text.
Indeed, it is probably3We call virtual documents all the documents thatcan be produced by a given grammar.Figure 5: Resolving underspecifications by in-teractive negotiationnot helpful to think of it as a functionat all, but rather as a matter ofcompromise.In our view, a human expert should beresponsible for making difficult decisions thatthe machine cannot make without significantinterpretation capabilities.
Furthermore, thesedecisions encompass cases where no explicitcontent in the input document can be used todetermine content that is expected in orderto obtain a well-formed representation in thesemantic model used.4 This will be illustratedbelow with the negotiation dialogue of figure 8.A naive way to select the candidate contentrepresentation found by the system that bestcorresponds to the input document wouldbe to show to an expert all the normalizedtexts corresponding to the candidates.
Thiswould however be a tedious and error-pronetask.
The compact representation built at theend of fuzzy inverted generation allows thediscrimination of candidates based on localunderspecifications corresponding to compe-ting semantic choices.
We have implementedthree methods for supporting interactivenegotiation that will be described below.They allow an expert to resolve underspeci-fications and therefore update the factorizedcontent representation by eliminating incorrecthypotheses.
This is iterated until the facto-rized content representation does not containany underspecification, as illustrated in figure 5.Figure 6 shows the main interface of our nor-malization system after the automatic selection4This suggests that document normalization can beused as a corrective mecanism applied on ill-formed do-cuments that can be incomplete or semantically incohe-rent relatively to a given semantic model.Figure 6: Interface of our document normalization systemof candidate content representations and theconstruction of the compact representation.Semantic view The middle panel on theright of the window contains the semantic view,which is a graphical view of the factorizedabstract semantic tree that can be interpretedby the expert.
It uses the text descriptionsfor semantic objects and types as described bythe functor display and type display predicatespresent in the original MDA formalism (seefigure 3).
The tick symbol represents asemantic object that dominates a semanticsubtree containing no underspecifications.
Inour example, this is the case for the objectdescribed as output type and detail level fordisplay.
The arrow symbol describes asemantic object that does not take part inan underspecification, but which dominates asubtree that contains at least one.
The ex-clamation mark symbol denotes a semantictype that is underspecified, and for which atleast two semantic objects are in competition.Semantic objects in competition are denotedby the interrogation mark symbol , and areordered according to the highest score of thecandidate representation to which they belong.This view can be used by the expert toFigure 7: Validation of a semantic choice withinthe semantic viewnavigate at any depth inside the compactrepresentation.
By clicking on a semanticobject in competition, the expert can decidewhether this object belongs to the solution ornot.
On the example of figure 7, the expert hasselected the first possibility (subdirectories arerecursively visited) for an underspecified type(specifies how subdirectories are visited), whichis itself dominated by another underspecifiedtype (specifies whether only directory names areshown or.
.
.
).
The menu that pops up allowsthe validation of the selected object: this willhave for effect to prune the factorized tree ofany subtree that does not belong to at leastone of the candidates of the validated object.In the present case, not only will it prune thealternative subtree dominated by subdirectoriesare not recursively visited, but also the subtreedominated by only show directory names (notFigure 8: Negotiation dialogue about how linksshould be showntheir content) present at a shallower level inthe tree.
Furthermore, subtrees that wouldbe incompatible elsewhere in the compactrepresentation because of failed parameterunification would disappear.
Conversely, theinvalidation operation prunes all the subtreeswhich have at least one candidate in commonwith the invalidated object.
The expert canalso ask for a negotiation dialogue, which willbe introduced shortly.MDA view It seemed very natural to proposea view with which a user of aMDA system wouldalready be familiar.
Such a view shows the nor-malized text corresponding to all the objectsfrom the root object that are not in competi-tion.
Underspecified semantic types appear asunderlined text spans called active zones, whichtrigger a pop up menu when clicked.
Whereasin the MDA authoring mode all the possible ob-jects for the semantic type that do not violateany semantic dependencies are shown, our sys-tem only proposes those that belong to can-didates that are still in competition.
Further-more, these semantic objects are not orderedby their order in appearance in the grammar,but by the score of their most likely candidateaccording to our system.
Selecting an objectcorresponds to validating it, implying that theinvalidation operation is not accessible from thisview.
Also, underspecified semantic types do-minated by other underspecified types cannotbe resolved using this view, as they do not ap-pear in the text.5 However, dealing with a textin natural language corresponding to the nor-malized document may be a more intuitive in-terface to some users, although it may requiremore operations.Negotiation dialogues The key element inthis task is the minimization of the number of5We thought that showing these types using cascademenus would be too confusing for the user.operations by the user.
The two previous viewsallow the expert to choose some underspecifica-tion to resolve.
The List of underspecificationspanel on the left of the window in figure 6contains an enumeration of all underspecifi-cations found in the compact representation.They are ordered by decreasing score, wherethe score can indicate the average score ofthe objects in competition, or the inverse ofthe average number of candidates per objectin competition.
Therefore, the expert canchoose to resolve first underspecifications thatcontain likely objects, or underspecificationsthat involve few candidates so that the valida-tion of an object will prune more candidatesfrom the compact representations.
Clickingon an underspecification in the list triggers anegotiation dialogue similar to that of figure 8.The semantic type on that dialogue, specifieshow links are shown, is not supported by anyevidence in the input document.
The expertcan however choose a value for it.
When theunderspecification is resolved, all the viewsare refreshed to reflect the new state of thecompact representation, and a negotiationdialogue for the underspecification then rankedfirst in the list is shown.
The expert can eitherdiscard it, or continue in the dialogue mode,with the possibility to skip the resolution of anunderspecification.3 Discussion and perspectivesWe have presented an approach to normalizedocuments in constrained domains and itsimplementation.
Our approach combines thestrictness of well-formed content representa-tions and and the flexibility of informationretrieval techniques, and makes use of humanexpertise to resolve difficult interpretationproblems in an attempt to build an opera-tional system.
Although our initial results arepromising, our approach could be improved inseveral ways.First of all, an important evaluation factor ofour approach is how much effort has to be doneby the human expert.
We have only conductedinformal experiments of evaluation by the task,which have revealed that normalization canbe performed quite fast when the user has agood command of the different views available.Nevertheless, it seems crucial to be able topresent the expert with at least some evidencefrom the text of the input document to supportcompeting semantic objects.
Morever, theevidence extracted from the input documentcould be used as the basis for learning newformulations for particular communicativegoals that would match better subsequentsimilar input.
Although our system alreadysupports non-deterministic generation, we havenot implemented a mechanism that wouldallow supervised learning of new formulationsyet.
We expect this ?normalization memory?functionality to have an important impact forthe normalization of documents from the sameorigin, as it should improve the automaticselection of content representations.In case the candidates returned by fuzzyinverted generation do not contain the contentrepresentation representing best the inputdocument, the user can choose to reanalyzethe document.
This will start search againfrom the (N+1)th content representation.
Butbecause the expert might have already resolvedsome underspecifications and thus identifiedsubparts that should belong to the solution,this information should be taken into accountwhile reanalyzing the document, which is notthe case in the current implementation.
Ifthe solution has to be present in the list ofcandidates returned, it should be as close tothe top of the list as possible, so that the firstchoices for each underspecification representthe actual best choices.
To this end, we intendto implement a second-pass analysis thatwould rerank the candidates produced by fuzzyinverted generation by computing text similari-ties over short passages such as those proposedin (Hatzivassiloglou et al, 1999).
These techni-ques were much harder to implement duringthe search in the virtual space of documentsproduced by the document model, because par-tial content representations are not actual texts.4 AcknowledgementsMany thanks to Marc Dymetman, who super-vised my work at Xerox Research Centre Eu-rope and who originally came up with the con-cept of fuzzy inverted generation.
Many thanksalso to Christian Boitet, my university PhD su-pervisor, and to Anne-Lise Bully, Ce?dric Lerayand Abdelkhalek Rherad for their programmingwork on the interface of the presented system.This work was funded by a PhD grant fromANRT and XRCE.ReferencesChristian Boitet.
1989.
Speech Synthesis andDialogue Based Machine Translation.
In Pro-ceedings of the ATR Symposium on Basic Re-search for Telephone Interpretation, Kyoto,Japan.Caroline Brun, Marc Dymetman, and VeronikaLux.
2000.
Document Structure and Multi-lingual Authoring.
In Proceedings of INLG2000, Mitzpe Ramon, Israel.Marc Dymetman, Veronika Lux, and AarneRanta.
2000.
XML and Multilingual Doc-ument Authoring: Convergent Trends.
InProceedings of COLING 2000, Saarbrucken,Germany.Anthony F. Hartley and Ce?cile L. Paris.
1997.Multilingual Document Production - FromSupport for Translating to Support for Au-thoring.
Machine Translation, 12:109?128.Vasileios Hatzivassiloglou, Judith L. Klavans,and Eleazar Eskin.
1999.
Detecting TextSimilarity over Short Passages: ExploringLinguistic Feature Combinations via MachineLearning.
In Proceedings of EMNLP/VLC-99, College Park, United States.Martin Kay, Jean Mark Gawron, and PeterNorvig.
1994.
Verbmobil ?
A TranslationSystem for Face-to-Face Dialog.
CSLI Lec-ture Notes.Martin Kay.
1997.
The Proper Place of Menand Machines in Language Translation.
Ma-chine Translation, 12:3?23.Aure?lien Max.
2003a.
De la cre?ation de docu-ments normalise?s a` la normalisation de doc-uments en domaine contraint.
PhD thesis,Universite?
Joseph Fourier, Grenoble.Aure?lien Max.
2003b.
Reversing ControlledDocument Authoring to Normalize Docu-ments.
In Proceedings of the EACL-03 Stu-dent Research Workshop, Budapest, Hungary.Fernando Pereira and David Warren.
1980.Definite Clauses for Language Analysis.
Ar-tificial Intelligence, 13.Richard Power and Donia Scott.
1998.
Multi-lingual Authoring using Feedback Texts.
InProceedings of COLING/ACL-98, Montre?al,Canada.H.
Somers, J.-I.
Tsujii, and D. Jones.
1990.Machine Translation without a Source Text.In Proceedings of COLING-90, Helsinki, Fin-land, volume 3, pages 217?276.
