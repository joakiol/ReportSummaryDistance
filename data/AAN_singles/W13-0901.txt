Proceedings of the First Workshop on Metaphor in NLP, pages 1?10,Atlanta, Georgia, 13 June 2013. c?2013 Association for Computational LinguisticsWhat metaphor identification systems can tell us aboutmetaphor-in-languageJonathan DunnPurdue UniversityWest Lafayette, Indiana USAjonathan.edwin.dunn@gmail.comAbstractThis paper evaluates four metaphor identi-fication systems on the 200,000 word VUAmsterdam Metaphor Corpus, comparing re-sults by genre and by sub-class of metaphor.The paper then compares the rate of agree-ment between the systems for each genre andsub-class.
Each of the identification systemsis based, explicitly or implicitly, on a the-ory of metaphor which hypothesizes that cer-tain properties are essential to metaphor-in-language.
The goal of this paper is to see whatthe success or failure of these systems can tellus about the essential properties of metaphor-in-language.
The success of the identificationsystems varies significantly across genres andsub-classes of metaphor.
At the same time, thedifferent systems achieve similar success rateson each even though they show low agree-ment among themselves.
This is taken tobe evidence that there are several sub-typesof metaphor-in-language and that the idealmetaphor identification system will first de-fine these sub-types and then model the lin-guistic properties which can distinguish thesesub-types from one another and from non-metaphors.1 IntroductionThe purpose of this paper is to evaluate four sys-tems for identifying metaphor-in-language on thelarge and representative VU Amsterdam MetaphorCorpus (Steen, et al 2010) and then to analyze thecorrect and incorrect identifications in order to seewhat they can tell us about the linguistic propertiesof metaphor-in-language.
The four metaphor identi-fication systems include a word-level semantic simi-larity measurement method (Sporleder and Li, 2009;Li and Sporleder, 2010), a word-level abstract-ness measurement method (Turney and Littmann,2003; Turney, et al 2011), a grammatical-relation-level source-target mapping method (Shutova, 2010;Shutova and Teufel, 2010; Shutova, Sun, and Ko-rhonen, 2010; Shutova, Teufel, and Korhonen,2013), and an utterance-level domain interactionmethod (Dunn, 2013b).2 The VU Amsterdam Metaphor CorpusThe VU Amsterdam Metaphor Corpus (Steen, etal., 2010) consists of approximately 200,000 wordstaken from the British National Corpus?s Baby Cor-pus and divided into four genres: academic, news,fiction, and conversation.
It was manually annotatedfor metaphoric uses of words by five analysts us-ing a version of the MIP method (Pragglejaz Group,2007).
For the purposes of this study, the corpuswas divided into sentences, under the assumptionthat each sentence represents an utterance.
Thereare 16,202 sentences in the corpus.
Sentences whichcontain at least one metaphoric use of a word are la-beled as metaphoric sentences.
This is done becausea metaphorically used word is not metaphoric exceptin relation to its linguistic context; thus, a larger lin-guistic unit like the sentence is necessary for reveal-ing metaphorically used words.The VU Amsterdam Corpus is annotated withseveral sub-classes of metaphor-in-language.
Thesub-classes included in this evaluation are MRW-Met (a metaphoric use of a metaphor related word);1Table 1: Number of sentences with sufficient representation in each system.System Non-Metaphor MRW-Met MRW-Lit PP Double WIDLIITotal 7,979 5,977 126 754 180 1,186Similarity 4,300 4,274 104 612 153 855Abstractness 6,851 5,497 118 723 174 1,090Source-Target 6,256 5,391 121 719 178 1,070Domain Interaction 6,770 5,588 122 729 178 1,115MRW-Lit (a literal use of a metaphor relatedword); PP (a possible personification resulting in ametaphor related word); Double (a metaphor relatedword which is involved in a double metaphor; for ex-ample, personification and a conceptual metaphor);WIDLII (possible metaphor related words whichwere considered ambiguous between metaphoricand non-metaphoric use).Table 1 shows a break-down of the number of sen-tences in each of these sub-classes in the corpus as awhole and as represented by each of the metaphoridentification systems.
Because each system usesdifferent linguistic properties to identify metaphor-in-language and uses different methods to representthose properties, the systems differ in how manyof the sentences are sufficiently represented.
Forexample, the semantic similarity measurement sys-tem looks at pairwise similarity values while the ab-stractness measurement system looks at values forindividual words.
Thus, the abstractness systemcould potentially have twice as many data points asthe similarity system.
The numbers in Table 1 in-clude only the sentences with a minimum number ofdata points.
The evaluation results below do not takeinto account sentences for which a system has insuf-ficient representation.
However, it is important tonote that the systems differ in how many sentencesthey adequately represent, which means that some(for example, the similarity system) are less able toidentify metaphor-in-language because they have aless robust representation of the linguistic utterance.For the purposes of this study, metaphor identifi-cation was conceptualized as a sentence-level task.For example, the systems evaluated here could beused within a larger computational semantic sys-tem to separate metaphoric and non-metaphoric sen-tences for purposes of reasoning.
One result of thischoice is that some of the original systems need tobe slightly reconceptualized; thus, it is better to saythat these systems are inspired by the cited systems,rather than strict reimplementations of those sys-tems.
The similarity and abstractness systems orig-inally were meant to decide which uses of a givenverb are metaphoric and which are not metaphoric.In the present study, however, metaphor is not lim-ited to verbs and the systems do not know whichwords in the sentence may be metaphoric (e.g., itcould be any noun or any verb, etc.).
Thus, thesesystems have been altered to determine whetherthere are any metaphorically used words anywherein the sentence.
Further, all of the reconceptual-ized systems compared here involve training or seedmetaphors, even those which were originally unsu-pervised systems.3 Identifying Metaphor-in-LanguageUsing Semantic SimilarityThe semantic similarity system (Sporleder and Li,2009; Li and Sporleder, 2010) uses pairwise seman-tic similarity to detect metaphoric uses of words.
Asconceptualized in this study, the system is designedto detect whether any of the words in the sentenceare used metaphorically without knowing in advancewhich words are candidates for metaphoric use.While the original system used NormalizedGoogle Distance (Cilibrasi and Vitanyi, 2007)to measure semantic similarity, the evaluation inthis study used Iosif?s SemSim system (Iosif andPotamianos, 2012).
There were two main reasonsfor not using the NGD measure: (1) SemSim offersmore control because the corpus used to determinepairwise similarity is known and can be made simi-lar to the test corpus; (2) SemSim is more transpar-ent in terms of its methodology and its results aremore stable over time.
For this evaluation we usedthe Open American National Corpus (henceforth,2OANC (Ide and Suderman, 2004)), which consistsof 14 million words taken from spoken and writ-ten contemporary American English, to determinethe pairwise similarity values.
Both the test corpusand OANC were lemmatized and had common func-tion words removed.
Pairwise similarities were de-termined for all words in the test corpus which oc-curred 10 or more times, for a total of 1,691 words.SemSim?s contextual window was set at 2.
As withall systems discussed below, Morpha (Guido, Car-roll, and Pearce, 2001) was used for lemmatizationand OpenNLP (Apache, 2011) was used for namedentity recognition.The variables used in the original system had tobe changed slightly because no particular word inthe sentence is given a special focus.
The follow-ing variables were used: (1) the number of similar-ity measurements for a given sentence; (2) the aver-age similarity; (3) the standard deviation of similar-ity, in order to see how much divergence there wasfrom the average; (4) the highest pairwise similarity;(5) the lowest pairwise similarity; (6) the differencebetween the highest and lowest pairwise similarity.One of the weaknesses of this particular implemen-tation of the system is that it only considers wordsthat are adjacent to one another (with function wordsremoved).
While the original system also used theaverage pairwise similarity between the candidateword and all other words, this was not possible heregiven that there were no words starting as candi-dates.4 Identifying Metaphor-in-LanguageUsing Word AbstractnessThe word abstractness system uses a measurementof word abstractness to identify highly abstract con-texts which are posited to be more likely to containmetaphors.
In the reconceptualization of the systemevaluated here there is also a focus on disparities inabstractness ratings within a given sentence, so thatthe mixture of abstract and concrete words can beused to detect possible metaphors.The system first rates lexical items according tohow abstract they are, on a scale from 0 to 1, with1 being the most abstract.
The approach to ratingabstraction is taken from (Turney, et al 2011); a listof rated lexical items is available from the authors.The system tags the words in the sentence with theirparts of speech and finds the abstractness rating foreach; if an abstractness rating is not available for aparticular word form, the system attempts to find amatch for its lemmatized form.
All words not foundon the list of abstractness ratings after these searcheswere removed.For each sentence a feature vector was createdthat consisted of twelve different combinations ofabstractness ratings: (1) the number of abstractnessratings available for the sentence; (2) the average ab-stractness for all words; (3) the standard deviationof the abstractness for all words; (3)-(4) the averageand standard deviation for the abstractness of nouns;(5)-(6) the average and standard deviation for the ab-stractness of verbs; (7)-(8) the average and standarddeviation for the abstractness of adjectives and ad-verbs; (9)-(10) the highest and lowest abstractness inthe sentence; (11) the difference between the highestand lowest abstractness; (12) the difference betweenthe average abstractness for nouns and for verbs.Empty slots in the feature vector (e.g., if there wereno adjectives) were filled with a value of 0.5 for ab-stractness, following the original system.5 Identifying Metaphor-in-LanguageUsing Source-Target MappingsThe source-target mapping system clusters verbsand nouns using their distributional properties andargues that abstract nouns will cluster according tothe metaphoric source domains to which they areconnected.
The system moves from the linguisticutterance to the underlying conceptual mapping byassuming that the verb directly represents the sourcedomain in the metaphoric mapping and that nouns(functioning as the subject and/or object of the verb)directly represent the target.
Thus, the system looksat grammatical relations containing a verb and anoun and generalizes from seed metaphors to othermetaphors involving words from the same clusters.The first part of evaluating the source-target map-ping approach to metaphor identification was tocluster lexical items.
The method for clusteringverbs is described in (Sun and Korhonen, 2009);(Sun, Korhonen, and Krymolowski, 2008) providea resource of the most frequent 1,510 English verbsin the Gigaword corpus divided into 170 clusters.3These clusters were used in the evaluation.
The pro-cedure used for clustering nouns in (Shutova, Teufel,and Korhonen, 2013) is to include the frequency ofgrammatical relations (subject, object, indirect ob-ject), as annotated by the RASP parser, in a featurevector.
In evaluating the source-target system, wetook a different approach to obtaining noun clus-ters.
Starting with 8,752 nouns examined by Iosif?sSemSim system (Iosif and Potamianos, 2012), weused a pairwise similarity matrix (measured usingthe Google-based Semantic Relatedness metric, ascomputed by Iosif) for the feature vector used forclustering nouns.
The nouns were divided into 200clusters using Weka?s (Witten and Frank, 2005) im-plementation of the k-means algorithm.The search for metaphors was performed on theRASP-parsed version of the evaluation corpus.
A to-tal of 1,000 randomly selected metaphoric sentenceswere used as seed metaphors; any relation betweentwo different clusters was accepted as a candidate.Many of the seed metaphoric utterances containedmultiple grammatically related clusters (e.g., verb-object) which were candidates for the metaphoricmaterial in the utterance.
In this evaluation we haveerred on the side of inclusion by searching for allpossible candidates.
A total of 903 grammatical re-lations between clusters were identified in the seedsentences; no attempt was made to trim this num-ber down.
While the original system removed verbswhich have loose selectional restrictions, such verbswere not removed from the clusters here; the origi-nal system focuses on preventing false positives, butin the evaluation here the focus is on preventing falsenegatives, which such a reduction would necessarilycreate.6 Identifying Metaphor-in-LanguageUsing Domain InteractionsThe domain interaction system (Dunn, 2013b)is a knowledge-based system unlike the previ-ous distributional-semantic systems.
It identifiesmetaphoric utterances using properties of the con-cepts pointed to by lexical items in the utterance.The system has two stages: first, determining whatconcepts are present in an utterance and what theirproperties are; second, using these properties tomodel metaphor.The system maps lexical items to their WordNetsynsets (WordNet, 2011) using the part of speechtags to maintain a four-way distinction betweennouns, verbs, adjectives, and adverbs.
The systemthen maps the WordNet synsets onto concepts in theSUMO ontology (Niles and Pease, 2001) using themappings provided (Niles and Pease, 2003).
Thisis done using the assumption that each lexical itemis used in its default sense, so that no disambigua-tion takes place.
Once the concepts present in theutterance have been identified in this manner, usingthe concepts present in the SUMO ontology, the sys-tem uses domain (ABSTRACT, PHYSICAL, SOCIAL,MENTAL) and event-status (PROCESS, STATE, OB-JECT) properties of each concept present in the ut-terance.
These are not present as such in the SUMOontology, but were developed following Ontologi-cal Semantics (Nirenburg and Raskin, 2004) as aknowledge-base specific to the system.The domain interaction system was implementedwith a feature vector created using the propertiesof the concepts referred to by lexical items in theutterance.
The feature vector uses the followingvariables: (1) number of concepts in the utterance;(2-5) number of instances of each type of domain(ABSTRACT, PHYSICAL, SOCIAL, MENTAL); (6-8) number of instances of each type of event sta-tus (PROCESS, STATE, OBJECT); (9) number of in-stances of the domain with the highest number ofinstances; (10) number of instances of event-statuswith the highest number of instances; (11) sum ofthe individual domain variables minus (9); (12) sumof individual event-status variables minus (10); (13)number of domain types present at least once in theutterance; (14) number of event-status types presentat least once in the utterance; (15) number of in-stances of the main domain divided by the numberof concepts; (16) number of other domain instancesdivided by the number of concepts; (17) number ofmain event-status instances divided by the numberof concepts; (18) number of other event-status in-stances divided by the number of concepts.7 Evaluation ResultsThe evaluation results discussed in this section con-sider only the sentences for which each system hasthe minimum representation; for example, the se-4Table 2: Results for each system across all genres and sub-classes.System True Positive False Positive True Negative False Negative F-MeasureSimilarity 5,936 4,214 86 62 0.444Abstractness 4,627 3,049 3,752 2,954 0.582Source-Target 1,063 785 5,470 5,496 0.440Domain Interaction 5,446 3,664 3,106 2,286 0.583Table 3: Results for each system across all genres and sub-classes without Named Entity Recognition.System True Pos.
False Pos.
True Neg.
False Neg.
F-Meas.
RepresentedSimilarity 5,658 3,973 63 56 0.444 9,750Abstractness 5,882 4,205 441 354 0.482 10,883Source-Target 1,725 1,342 2,171 2,677 0.487 8,547Domain Interaction 6,561 4,205 1,462 676 0.573 12,904mantic similarity system had a minimum representa-tion for many fewer sentences than does the abstract-ness system, but those unrepresented sentences arenot held against the system.
Three of the systems usefeature vectors: the semantic similarity, word ab-stractness, and domain interaction systems.
To makethe evaluation comparable all three systems are eval-uated using Weka?s (Witten and Frank, 2005) imple-mentation of the logistic regression algorithm, fol-lowing (Turney, et al 2011), using cross-validation(100 folds) and a ridge estimator value of 0.2.
Theevaluation of the source-target system searched forthe 903 seed relations in the RASP-parsed test cor-pus.
The sentences used as seeds were removedfrom the test corpus before searching.
For eachevaluation, the reported F-Measure is the weightedaverage of the F-Measures for metaphors and non-metaphors.Table 2 shows the evaluation results for the foursystems on the entire corpus.
The similarity systemhas the highest number of true positives (5,936), butalso the highest number of false positives (4,214).In fact, the similarity system identifies very few ut-terances as non-metaphors and this makes the re-sults rather unhelpful.
The abstractness and do-main interaction systems have similar F-measures(0.582 and 0.583, respectively); both make a largenumber of predictions for both metaphor and non-metaphor, so that they attempt to distinguish be-tween the two, but these predictions are not particu-larly accurate.
The source-target system stands outhere, as it does below, with a significantly smallernumber of false positives than the other systems(785).
At the same time, it also has a significantlyhigher number of false negatives (5,496).
The simi-larity and source-target systems are on opposite endsof the spectrum in terms of over-identifying andunder-identifying metaphor-in-language, and bothhave similar F-measures (0.444 and 0.440, respec-tively) which are lower than the abstractness and do-main interaction systems.In Table 3 the same results across all genres andsub-types are presented for implementations with-out Named Entity Recognition.
The only systemwhich performs significantly differently is the ab-stractness system, with an F-Measure of 0.482 with-out vs. 0.582 with NER.
This decline goes hand-in-hand with the fact that the system with NER has suf-ficient representation for a total of 14,454 sentences,while without NER it has sufficient representationfor only 10,883 sentences.Table 4 starts to break these results down furtherby genre, in order to find out if the systems performdifferently on different sorts of texts.
Every systemexcept for the similarity system (with F-measures of0.444 and then 0.463) performs more poorly on fic-tion than on the corpus as a whole.
More interest-ingly, within the fiction genre the similarity and ab-stractness systems do not predict that any utterancesare non-metaphors, which makes their F-measureslargely meaningless.
The source-target system con-tinues to make a distinction between metaphor and5Table 4: Results for each system in the Fiction genre.System True Positive False Positive True Negative False Negative F-MeasureSimilarity 1,778 1,135 0 0 0.463Abstractness 2,074 1,375 0 0 0.452Source-Target 293 244 1,151 1,567 0.379Domain Interaction 2,067 1,349 75 67 0.485Table 5: Results for each system in the News genre.System True Positive False Positive True Negative False Negative F-MeasureSimilarity 1,806 292 0 0 0.796Abstractness 1,940 321 0 0 0.792Source-Target 348 61 262 1,352 0.321Domain Interaction 1,956 324 0 0 0.792non-metaphor within this genre, although the trueand false positives (293 and 243, respectively) aremuch closer to one another than when looking at thecorpus as a whole.Table 5 looks at the systems?
performance withinthe News genre.
The similarity system, which abovemade few predictions for non-metaphor continuesto predict only metaphors; the abstractness and do-main interaction systems join it, predicting onlymetaphors.
The source-target system, on the otherhand, maintains a small number of false positives(61), although continuing to show a large number offalse negatives (1,352).
In terms of practical applica-tions, the F-measures here do not adequately reflectthe fact that three of the four systems essentially failon this genre.
One of the difficulties is the fact thatthe News genre contains 1,708 metaphoric sentencesand 325 non-metaphoric sentences according to themanual annotations in the VU Amsterdam MetaphorCorpus; that means that 84% of the sentences are an-notated as metaphoric.Table 6 looks at the results within the Academicgenre.
Here all systems make a distinction betweenmetaphor and non-metaphor; this is the first set onwhich the similarity system has predicted a mean-ingful number of non-metaphors.
The source-targetsystem misses the most metaphors (1,321) but alsomakes significantly fewer false positives (146 vs. thenext lowest 590 by the similarity system).
The F-measures do not adequately reflect the performanceof the systems for this genre.Table 7 shows the results within the Conversationgenre.
This is the reverse of the News genre: three ofthe four systems make no predictions of metaphors.This genre contains 1,958 utterances with at leastone metaphorically used word and 5,262 without.Further, this genre contains many more short and/orfragmentary sentences than the others.
Even thesource-target system, which is the only system toidentify any metaphors, has more than twice asmany false positives as true positives (334 vs. 136,respectively), which reverses its performance on thethree previous genres.The initial conclusions we can draw from thegenre break-down is that (1) the F-measure does notalways reflect meaningful performance and thus thatthe numbers of true and false positives and negativesshould be reported as well; and (2) that the perfor-mance on the corpus as a whole disguises a largeamount of variation according to genre.Table 8 shows the results for only the MRW-Metsub-class in the corpus.
This is the basic metaphorsub-class in the corpus and the most common.
Thesystems perform better on this sub-class than on anyother.
Interestingly, the source-target system makesmore false than true positives here (785 vs. 749) andis the only system to make more false than true posi-tives for this sub-class.
It also makes more false neg-atives than the other systems, although the abstract-ness, source-target, and domain interaction systemsmake a comparable number (3,971 and 3,990 and3,386, respectively).
The domain interaction system6Table 6: Results for each system in the Academic genre.System True Positive False Positive True Negative False Negative F-MeasureSimilarity 1,287 590 289 214 0.635Abstractness 1,604 667 273 204 0.649Source-Target 286 146 786 1,321 0.367Domain Interaction 1,720 720 232 154 0.646Table 7: Results for each system in the Conversation genre.System True Positive False Positive True Negative False Negative F-MeasureSimilarity 0 0 1,994 913 0.558Abstractness 0 0 4,165 1,759 0.580Source-Target 136 334 3,271 1,256 0.621Domain Interaction 0 0 4,070 1,768 0.573makes the most true positives, although all the F-measures are comparable (the lowest is only 0.062below the highest).Table 9 shows the results for the ambiguousmetaphors, under the label WIDLII, and the resultsare comparable to the results for all other sub-classesexcept for the MRW-Met sub-class (thus, the othersub-classes will not be discussed individually).
Thesimilarity, abstractness, and domain interaction sys-tems do not detect any of these sentences as con-taining metaphorically used words.
In some waysthis failure is acceptable because the original ana-lysts were not convinced that these utterances con-tained metaphors in the first place.
The source-targetsystem has a very uncharacteristic performance onthis sub-class, with 5-times as many false positivesas true positives (785 vs. 157, respectively).This is interesting because it is exactly the op-posite of the other systems, which do not predictany sentences to be metaphors at all.
This differ-ence is likely a result of the fact that the other threesystems rely on feature vectors that were trainedon the WIDLII / Non-Metaphor distinction, whilethe source-target system uses seed grammatical re-lations from other sub-classes as well (it shouldn?tmatter because the relations are hypothesized to rep-resent conceptual metaphors for which the sub-classdistinction is not relevant; more seed metaphorswere not used because this would have removedthem from the evaluation).
In other words, thesub-class comparisons try to distinguish betweenWIDLII metaphors and non-metaphors in the cor-pus.
The source-target system was trained on oneand only one set of seed metaphors; in other casesthis fact increased the system?s performance, but inthis case it had the opposite effect.
It also shows thatnon-metaphors are more likely to contain the seedclusters than are ambiguous metaphors.8 Error AnalysisThe next question to ask is whether these four sys-tems succeed and fail on the same metaphors.
Eachsystem makes different assumptions and is based ona different theory of what linguistic properties areessential to metaphor-in-language, and thus can beused to distinguish metaphor from non-metaphor.Table 10: Agreement among the four metaphor identifi-cation systems using Fleiss?
Kappa.Sub-set Full ReducedFiction 0.293 0.301News 0.279 0.277Academic 0.282 0.286Conversation 0.259 0.286MRW-Met 0.280 0.291MRW-Lit 0.285 0.298PP 0.293 0.290Double 0.346 0.369WIDLII 0.278 0.292Table 10 shows the agreement between the four7Table 8: Results for each system in the MRW-Met Sub-Class.System True Positive False Positive True Negative False Negative F-MeasureSimilarity 2,141 1,841 2,459 2,133 0.536Abstractness 1,505 1,287 5,514 3,971 0.537Source-Target 749 785 5,470 3,990 0.499Domain Interaction 2,202 1,895 4,875 3,386 0.561Table 9: Results for each system in the WIDLII Sub-Class.System True Positive False Positive True Negative False Negative F-MeasureSimilarity 0 0 4,300 855 0.759Abstractness 0 2 6,799 1,090 0.798Source-Target 157 785 5,470 768 0.785Domain Interaction 0 0 6,770 1,115 0.793systems as measured by Fleiss?
Kappa.
In the firstcolumn, under ?Full,?
the predictions used to deter-mine agreement differ slightly from the earlier pre-dictions because all sentences were included, eventhose for which a particular system lacked sufficientrepresentation.
This was done in order to makea comparison of the four systems possible (sen-tences without representation could not be identifiedas metaphors and thus defaulted to non-metaphors).The sentences used as seeds for the source-targetsystem were removed for all systems.
A possi-ble cause for low agreement between the systemsis that if one system lacks sufficient representationfor a sentence, it will cause disagreement by its lackof representation.
The second column, under ?Re-duced,?
shows the agreement between the four sys-tems for only those sentences for which all systemshad an adequate representation and which were notused for seed metaphors (a total of 8,887 sentencesrather than the full 16,202).
The results are simi-lar, showing that the low agreement is not caused bylack of sufficient representation.All of the divisions, whether by genre or by sub-class, have a similarly low level of agreement, witha range from 0.259 to 0.293.
The sub-class of Dou-ble metaphors has a higher agreement of 0.346.
Thislow agreement is the case even though the systemshave similar overall performance on these particulargenres and sub-classes.
In other words, even thoughthe systems make similar numbers of correct predic-tions, the particular utterances for which metaphor iscorrectly or incorrectly predicted are not the same.This is an important point because if all foursystems succeeded and failed on the same utter-ances then we could say that those particular ut-terances were the cause of the failure and try tomodel the properties of those utterances.
Whatseems to be happening is quite the opposite: eachsystem implements a particular model of metaphor-in-language which makes specific explicit and im-plicit assumptions about what metaphor-in-languageis and what properties are essential for distinguish-ing metaphoric language from non-metaphoric lan-guage.
These different models seem to be succeed-ing on those metaphors which fall within their scopeand failing on all others, which leads to disagree-ment in the predictions of the systems.9 Synthesizing the SystemsSeveral meta-systems were constructed using the re-sults of the four systems on the sub-set of the cor-pus for which each system had adequate representa-tion (8,887 sentences).
The first meta-system iden-tified as metaphor only those sentences which thetwo top-performing systems, the source-target map-ping and the domain interaction systems, agreedwere metaphoric; the second only those sentenceswhich all four systems agreed were metaphoric; thethird only those sentences which a majority of sys-tems agreed were metaphoric; the fourth those sen-tences for which either the domain interaction or8Table 11: Results for meta-systems across all sentences with sufficient representation for all systems.System True Positive False Positive True Negative False Negative F-MeasureOnly top two agree 520 360 3,558 4,449 0.362Only all agree 374 244 3,674 4,595 0.341Majority vote 1,513 1,655 2,263 2,921 0.445Top two inclusive 3,200 2,552 1,366 1,769 0.505Top two, settled inc 2,689 2,164 1,754 2,280 0.501Top two, settled exc 2,086 1,688 2,230 2,883 0.485the source-target system identified as metaphor; thefifth all sentences which the domain interaction andsource-target systems agreed were metaphoric, us-ing the similarity and abstractness systems to resolvedisagreement.
There are two versions of this lastmeta-system: the inclusive version identifies dis-puted sentences as metaphoric if either the similarityor abstractness system does, and the exclusive ver-sion only if the two agree.Table 11 shows the results of the evaluations ofthese meta-systems.
The system with the fewestfalse positives is the one which requires four-way agreement before an utterance is identified asmetaphor; however, this also has the fewest truepositives.
The performance of the exclusive meta-system for the top two systems has a better propor-tion of true to false positives, but also has an unfor-tunately high number of false negatives.
The major-ity vote meta-system has more false than true pos-itives and, thus, is not successful.
The last threemeta-systems differ in how they resolve disagree-ments between the top two systems; there is a con-sistent trade-off between more true positives andfewer false positives and all three have comparableF-measures.10 What This Tells Us AboutMetaphor-in-LanguageWhat can we learn about metaphor-in-languagefrom the successes and failures of these fourmetaphor identification systems?
First, there is asignificant difference between genres.
The linguisticproperties which can distinguish metaphors in onegenre may not apply to other genres.
Or, lookedat another way, different genres are more likely tocontain different types of metaphors (the types ofmetaphor referred to here involve different sourcesof metaphoric meaning and are not comparable tothe corpus?s sub-classes).Second, the predictions of the four systems, re-gardless of their accuracy, have a relatively low levelof agreement.
This low level of agreement is consis-tent across genres and sub-classes.
This means thatthe systems are succeeding and failing on differentmetaphors.
Each of the systems is based on a differ-ent theory of metaphor-in-language.
The combina-tion of these two facts suggests that different typesof metaphor have different linguistic properties.Most theories of metaphor conceive of it as asingle and coherent phenomenon, so that the pre-dictions of competing theories are mutually exclu-sive.
The lack of agreement coupled with similarsuccess rates, however, suggests that these theoriesof metaphor-in-language are not mutually exclusivebut rather apply to different types of metaphor-in-language.
If this is the case, then a more accu-rate model of metaphor-in-language will start bypositing a number of different types of metaphor-in-language, which differ in the source of theirmetaphoric meaning, and then predicting what lin-guistic properties can be used to distinguish amongthese types and between them and non-metaphors.Metaphor identification systems can be im-proved by focusing on two important properties ofmetaphor-in-language: First, metaphors are gradi-ent, with some being much more metaphoric thanothers (Dunn, 2011).
One problem with the sys-tems described in this paper is that they are forcedto draw an arbitrary line between two classes to rep-resent a gradient phenomenon.
Second, metaphoricexpressions receive their metaphoric meaning fromdifferent sources (Dunn, 2013a).
These differenttypes of metaphor-in-language have different prop-erties and should be modeled individually.9ReferencesApache.
2011.
OpenNLPBriscoe, E., Carroll, J., Watson, R. ?The Second Releaseof the RASP System.?
Curran, J.
(ed.)
Proceedingsof COLING/ACL 2006 Interactive Presentation Ses-sions 77-80 Association for Computational Linguis-tics Stroudsburg, PA 2006Cilibrasi, R. and Vitanyi, P. ?The Google similaritydistance.?
Knowledge and Data Engineering, IEEETransactions on 19(3): 370?383 2007Dunn, J.
?Gradient semantic intuitions of metaphoricexpressions?
Metaphor & Symbol 26(1): 53-67 2011Dunn, J.
?How linguistic structure influences and helpsto predict metaphoric meaning?
Cognitive Linguistics24(1): 33-66 2013Dunn, J.
?Evaluating the premises and results of fourmetaphor identification systems.?
Gelbukh, A.
(ed.
)Proceedings of CICLing 2013, LNCS 7816 471-486Springer Heidelberg 2013Guido, M., Carroll, J., Pearce, D. ?Applied morpholog-ical processing of English.?
Natural Language Engi-neering 7(3): 207-223 2001Ide, N. and Suderman, K. ?The American National Cor-pus First Release.?
Lino, M. Xavier, M., Ferreira, F.,Costa, R., and Silva, R.
(eds.)
Proceedings of LREC-2004 1681-1684 European Language Resources As-sociation Paris 2004Iosif, E. and Potamianos, A.
?SemSim: Resources forNormalized Semantic Similarity Computation UsingLexical Networks.?
Calzolari, N., Choukri, K., De-clerck, T., Doan, M., Maegaard, B., Mariani, J., Odijk,J., Piperidis, S.
(eds.)
Proceedings of LREC-20123499-3504 European Language Resources Associa-tion Paris 2012Li, L. and Sporleder, C. ?Using Gaussian Mixture Mod-els to Detect Figurative Language in Context.?
Ka-plan, R., Burstein, J., Harper, M., and Penn, G.
(eds.
)Proceedings of HLT-NAACL-2010 297?300 Associ-ation for Computational Linguistics Stroudsburg, PA2010Niles, I. and Pease, A.
?Towards a Standard Upper On-tology?
Welty, C. and Barry, C.
(eds.)
Proceedings ofFOIS-2001 2-9 Association for Computational Lin-guistics Stroudsburg, PA 2001Niles, I. and Pease, A.
?Linking Lexicons and On-tologies: Mapping WordNet to the Suggested UpperMerged Ontology.?
Arabnia, H. (ed) Proceedings ofIEEE Intl Conf on Inf.
and Knowl.
Eng.
(IKE 03) 412-416 IEEE Press New York 2003Nirenburg, S. and Raskin, V. Ontological SemanticsCambridge, MA MIT Press 2004Pragglejaz Group ?MIP: A method for identifyingmetaphorically used words in discourse.?
Metaphorand Symbol 22(1): 139 2007Princeton University WordNet 2012Shutova, E. ?Models of Metaphor in NLP.?
Hajiv, J.,Carberry, S., Clark, S. and Nivre, J.
(eds.)
Proceedingsof ACL-2010 688?697 Association for ComputationalLinguistics Stroudsburg, PA 2010Shutova, E. and Teufel, S. ?Metaphor corpus anno-tated for source ?
target domain mappings.?
Calzolari,N., Choukri, K., Maegaard, B., Mariani, J., Odijk, J.,Piperidis, S., Rosner, M. and Tapias, D.
(eds.)
Pro-ceedings of LREC 2010 3255?3261 European Lan-guage Resources Association Paris 2010Shutova, E., Sun, L,.
and Korhonen, A.
?Metaphor iden-tification using verb and noun clustering.?
Huang, C.and Jurafsky, D.
(eds.)
Proceedings of COLING 20101002?1010 Tsinghua University Press Beijing 2010Shutova, E., Teufel, S., and Korhonen, A.
?StatisticalMetaphor Processing.?
Computational Linguistics 392013Sporleder, C. and Li, L. ?Contextual idiom detectionwithout labelled data.?
Koehn, P. and Mihalcea, R.(eds.)
Proceedings of EMNLP-09 315-323 Associ-ation for Computational Linguistics Stroudsburg, PA2009Steen, G., Dorst, A., Herrmann, J., Kaal, A., and Kren-nmayr, T. ?Metaphor in usage.?
Cognitive Linguistics21(4): 765-796 2010Sun, L. and Korhonen, A.
?Improving verb clusteringwith automatically acquired selectional preferences.
?Koehn, P. and Mihalcea, R.
(eds.)
Proceedings ofEMNLP-2009 638?647 Association for Computa-tional Linguistics Stroudsburg, PA 2009Sun, L., Korhonen, A., and Krymolowski, Y.
?VerbClass Discovery from Rich Syntactic Data.?
Gelbukh,A.
(ed) Proceedings of CICLING-2008, LNCS, vol.4919 16-27 Springer Heidelberg 2008Turney, P. and Littman, M. ?Measuring praise and crit-icism: Inference of semantic orientation from asso-ciation.?
ACM Transactions on Information Systems21(4): 315?346 2003Turney, P., Neuman, Y, Assaf, D., and Cohen, Y.
?Literaland Metaphorical Sense Identification through Con-crete and Abstract Context.?
Barzilay, R. and Johnson,M.
(eds.)
Proceedings of EMNLP-2011 680?690 As-sociation for Computational Linguistics Stroudsburg,PA 2011Witten, I. and Frank, E. Data Mining: Practical Ma-chine Learning Tools and Techniques with Java Imple-mentations Morgan Kaufmann San Francisco 200510
