Proceedings of the NAACL HLT 2010 Young Investigators Workshop on Computational Approaches to Languages of the Americas,pages 15?23, Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsVariable-Length Markov Models and Ambiguous Words in Portuguese?Fabio Natanael KeplerInstitute of Mathematics and StatisticsUniversity of Sao PauloSao Paulo, SP, Brazilkepler@ime.usp.brMarcelo FingerInstitute of Mathematics and StatisticsUniversity of Sao PauloSao Paulo, SP, Brazilmfinger@ime.usp.brAbstractVariable-Length Markov Chains (VLMCs) of-fer a way of modeling contexts longer thantrigrams without suffering from data sparsityand state space complexity.
However, in His-torical Portuguese, two words show a high de-gree of ambiguity: que and a.
The numberof errors tagging these words corresponds to aquarter of the total errors made by a VLMC-based tagger.
Moreover, these words seem toshow two different types of ambiguity: onedepending on non-local context and anotheron right context.
We searched ways of ex-panding the VLMC-based tagger with a num-ber of different models and methods in orderto tackle these issues.
The methods showedvariable degrees of success, with one particu-lar method solving much of the ambiguity ofa.
We explore reasons why this happened, andhow everything we tried fails to improve theprecision of que.1 IntroductionIn the Computational Linguistics area, the task ofpart-of-speech tagging (POS tagging) consists in as-signing to words in a text the grammatical class theybelong.
Since the same word may belong to morethan one class, models for POS tagging have to lookat the context where each word occurs to try to solvethe ambiguity.Previous and current work have developed a widerange of models and methods for tagging.
The vastmajority uses supervised learning methods, which?During the course of this work Fabio received support fromBrazilian funding agencies CAPES and CNPq.need an already tagged corpus as input in order totrain the model, calculating relations, weights, prob-abilities etc.Among the various models for tagging, there areMaximum Entropy models (dos Santos et al, 2008;de Almeida Filho, 2002; Ratnaparkhi, 1996), Hid-den Markov Models (HMMs) (Brants, 2000), Trans-formation Based Learning (Brill, 1993), and othersuccesful approaches (Toutanova et al, 2003; Tsu-ruoka and Tsujii, 2005; Shen et al, 2007).Current state-of-the-art precision in tagging isachieved by supervised methods.
Although preci-sion is pretty high ?
less than 3% error rate forEnglish ?
the disavantage is exactly the need of atagged corpus, usually built manually.
This is a veryrestrictive issue for languages with lack of resourcessuch as linguistic especialists, corpora projects etc.The Portuguese language falls in between re-sourceful languages, such as English, and languageswith restricted resources.
There have been initia-tives both in Brazil and in Portugal, which includemodern Brazilian Portuguese corpora (ICMC-USP,2010), European Portuguese corpora (Flo, 2008),and historical Portuguese corpora (IEL-UNICAMPand IME-USP, 2010).
Also, some supervised POStaggers have already been developed for Portuguese(dos Santos et al, 2008; Kepler and Finger, 2006;Aires, 2000) with a good degree of success.
And fi-nally, there has also been increasing effort and in-terest in Portuguese annotation tools, such as E-Dictor1 (de Sousa et al, 2009).Despite these advances, there is still lack of mate-rial and resources for Portuguese, as well as research1See http://purl.org/edictor.15in unsupervised methods to bootstrap text annota-tion.Our work focuses on further improvement of thecurrent state-of-the-art in Portuguese tagging.
Forthis, we focus on the Tycho Brahe (IEL-UNICAMPand IME-USP, 2010) corpus for testing and bench-marking, because of its great collaboration potential:it is easily accessible2; is under continuous develop-ment; and has recently started using E-Dictor, whichalso offers a great collaboration potential.1.1 Previous WorksOne popular approach to tagging is to use HMMsof order 2.
Order 2, or trigram, means the taggerconsiders the previous two words/tags when tagginga word.
This adds context to help disambiguation.The drawback is that this context may not be suf-ficient.
Increasing the order does not help, sincethis incurs in too many model parameters and suf-fers from the data sparsity problem.In (Kepler and Finger, 2006), we developed a tag-ger for Portuguese that uses Markov chains of vari-able length, that is, orders greater than 2 can beused conditioned on certain tags and sequences oftags.
This approach is better at avoiding the spar-sity and complexity problems, while being able tomodel longer contexts.
However, one interestingconclusion from that work is that, even using longercontexts, some words stay extremely hard to disam-biguate.
Apparently, those words rely on flexiblecontexts not captured by pure VLMCs.Motivated by this problem, we improve over theprevious work, and developed a set of tagger modelsbased on Variable-Length Markov Chains (VLMCs)extended with various other approaches in order totry to tackle the problem.In the next section we describe the VLMC theory,the results it achieves, and the problems with twocommon words.
Then, in Section 3, we explain insummary the set of models and approaches we triedto mix with VLMCs, and the different types of re-sults they give.
Conclusions are drawn in Section 4.Finally, Section 5 describes how this work can be in-corporated in other projects, and Section 6 presentsideas for future work.2More information at http://www.tycho.iel.unicamp.br/~tycho/corpus/en/index.html.2 Variable-Length Markov ChainsThe idea is to allow the memory of a Markov chainto have variable length, depending on the observedpast values.
(B?hlmann and Wyner, 1999) give aformal description of VLMCs, while here we willexplain them in terms of the POS-tagging task.Consider a Markov chain with a finite, large orderk.
Let ti be a tag, and ti?k,i?1 be the k tags preced-ing ti.
Variable length memory can be seen as a cutof irrelevant states from the ti?k,i?1 history.
We callthe set of these states the context of ti.
Given a tagti, its context ti?h,i?1, h ?
k, is given by the contextfunction c(ti?k,i?1).A context tree is a tree in which each internal nodehas at most |T | children, where T is the tagset.
Eachvalue of a context function c(?)
is represented as abranch of such tree.
For example, the context givenby c(ti?k,i?1) is represented as a branch whose sub-branch at the top is determined by ti?1, the next sub-branch by ti?2, and so on, until the leaf, determinedby ti?h.The parameters of a VLMC are the underlyingfunctions c(?)
and their probabilities.
To obtain theseparameters we use a version of the context algorithmof (Rissanen, 1983).
First, it builds a big contexttree, using a training corpus.
For a tag ti, its maxi-mal history ti?k,i?1 is placed as a branch in the tree.Then, the algorithm uses a pruning function consid-ering a local decision criterion.
This pruning cutsoff the irrelevant states from the tags?
histories.
Foreach leaf u in the context tree, and branch v that goesfrom the root to the parent node of u, u is prunedfrom the tree if?vu =?t?LP (t|vu) log(P (t|vu)P (l|v))C(vu) < K,whereC(vu) is the number of occurrences of the se-quence vu in the training corpus, and K is a thresh-old value, called the cut value of the context tree,If the probability of a tag does not change muchbetween considering the entire branch together withthe leaf (all past history) and considering only thebranch (the history without the furthest tag), then theleaf does not need to be considered, and can be re-moved from the tree.We want to find the best sequence of tags t1 .
.
.
tnfor a given sequence of words w1 .
.
.
wn of size n,16that is,arg maxt1...tn[n?i=1P (ti|c(ti?k,i?1))P (wi|ti)].Probabilities are computed from a tagged trainingcorpus using maximum likelihood estimation fromthe relative frequencies of words and sequences oftags.
The context tree is built with sequences of tagsof maximum length k and then pruned, thus defin-ing the context functions.
For decoding, the ViterbiAlgorithm is used (Viterbi, 1967).2.1 Initial ResultsWe used the tagged texts available by the Ty-cho Brahe Corpus of Historical Portuguese (IEL-UNICAMP and IME-USP, 2010).
The Tycho Braheproject uses 377 POS and inflectional tags, and con-tains annotated texts written by authors born be-tween 1380 and 1845.
We have selected 19 textsfor composing our corpus, which contains 1035593tagged words and has 262 different tags.
This cor-pus was then randomly divided into 75% of the sen-tences for generating a training corpus and 25% fora testing corpus.
The training corpus has 775602tagged words, while the testing corpus has 259991tagged words.
The Tycho Brahe project is under-going rapid development, so as for today there aremore texts available which are not present in the cor-pus we used3.Because of some of the approaches explained be-low, we also created a new training corpus and a newtesting corpus by segmenting contracted words fromthe original corpus.
Contracted words are words likeda, which has the tag P+D-F and is a contraction ofthe preposition de (P) with the feminine determinera (D-F).Using the original corpus, our VLMC implemen-tation, which we will call VLMM TAGGER4 (fromVariable Length Markov Model), and which betterimplements under- and overflow control, achieves3We can provide the training and testing corpus if requestedby email.4A package containing the VLMM TAGGER will beavailable at http://www.ime.usp.br/~kepler/vlmmtagger/, but requests for the raw source code can bemade by email.
Currently, there is only an automake bundleready for download containing the VLMC TAGGER.96.29% of precision5, while the VLMC TAGGERfrom (Kepler and Finger, 2006) achieves 95.51%.Table 1 shows the numbers for both taggers, where Pand E means Precision and Error, respectively.
Thedifference in precision is mainly due to a 21.64%error reduction in known words tagging6.
That,combined with 6.82% error reduction in unknownwords, results in 17.50% total error reduction.
Withthe segmented corpus the VLMM TAGGER achieved96.54% of precision.TAGGER WORDS P (%) ERR.
/ OCURR.VLMCUnknown 69.53 2713 / 8904Known 96.39 9065 / 251087Total 95.51 11674 / 259991VLMMUnknown 71.60 2528 / 8904Known 97.17 7102 / 251087Total 96.29 9630 / 259991Table 1: Precision of VLMC-based taggers.Table 2 shows numbers for the two words thatpresent the most number of errors made by theVLMM TAGGER.
Note that they are not necessarilythe words with the highest error percentage, sincethere are known words that appear only a couple oftimes in the testing corpus and may get wrong tagshalf of this times, for example.WORDS P (%) E (%) ERR.
/ OCURR.que 84.7413 15.2586 1687 / 11056a 90.9452 9.0547 661 / 7300Table 2: Results for words with the most number of errorsusing the VLMM TAGGER with the normal corpus.These two words draw attention because togetherthey correspond to almost 25% of the errors made bythe tagger, where most confusion for each of thesewords is between two different tags:?
The word que is, most of the times, either a rel-ative pronoun ?
denoted by the tag WPRO and5Precision is given by the number of correctly assigned tagsto the words in the testing corpus over the total number of wordsin the testing corpus.6Known words are words that appear both in the training andthe testing corpus.17equivalent to the word which in English ?, or asubordinating conjunction ?
denoted by the tagC and equivalent, in English, to the words thator than;?
The word a is, usually, either a feminine deter-miner (tag D-F), or a preposition (tag P).As a baseline, assigning the most common tag to queyields a precision of 55.64%, while a gets a preci-sion of 58.09%.
Also, these words seem to show twodifferent types of ambiguity: one that needs con-text to the right, and one that needs non-local con-text.
The VLMM model does not have parametersfor these contexts, since it tags from left to right us-ing context immediately to the left.2.2 ObjectivesIt seems that a could be better disambiguated bylooking at words or tags following it: for example,if followed by a verb, a is much more likely to be apreposition.
For que, it seems that words occuringnot immediately before may add important informa-tion.
For example, if que follows mais (more than,in English), it is more likely that que has tag C. How-ever, like in the English expression, it is possible tohave various different words in between mais andque, as for example: ?mais prov?vel que?
(?morelikely than?
); ?mais caro e complexo que?
(?moreexpensive and complex than?
); and so on.
Thus, itmay yield better results if non-local context couldbe efficiently modeled.In order to develop these ideas about que and aand prove them right or wrong, we searched ways ofexpanding the VLMM tagger with a number of dif-ferent models and methods that could help solvingthese two issues.
Those models are described next.3 Auxiliary Approaches3.1 Syntactic StructureThe first idea we had was to generalize nodes in theVLMM?s context tree, that is, to model a way of ab-stracting different sequences of tags into the samenode.
This could make it possible to have branchesin the context tree like ADV * C, that could be usedfor mais * que.One way of doing this is to use sequences of tagsthat form phrases, like noun phrases (NP), preposi-tional phrases (PP), and verbal phrases (VP), and usethem in the context tree in place of the sequencesof tags they cover.
The context tree will then havebranches like, say, P VP N.In order to train this mixed model we need a tree-bank, preferably from the texts in the Tycho Brahecorpus.
However, it does not have a sufficiently largeset of parsed texts to allow efficient supervised learn-ing.
Moreover there is not much Portuguese tree-banks available, so we were motivated to implementan unsupervised parsed for Portuguese.Based on the work of (Klein, 2005), we imple-mented his CCM model, and used it over the Ty-cho Brahe corpus.
The CCM model tries to learnconstituents based on the contexts they have in com-mon.
We achieved 60% of f-measure over a set oftexts from the Tycho Brahe project that were alreadyparsed.Using the CCM constituents learned, we ex-tended the VLMM TAGGER to use this extra infor-mation.
It yielded worse results, so we restricted theuse of constituents to que (the VLMM+SPANS-QUETAGGER).
This yielded a precision of 96.56%, witha que precision increase of 3.73% and an a precisionreduction of 0.67%.
A comparison with the plainVLMM TAGGER over the segmented corpus can beseen in Table 3.
We use the segmented corpus forcomparison because the constituents only use seg-mented tags.
Even after many tries and variations inWORDS P (%) ERR.
/ OCURR.que84 .50 1715 / 1106385.18 1651 / 11063a94 .52 745 / 1359794.49 750 / 13597Total96 .5433 9559 / 27654196.5636 9503 / 276541Table 3: Comparison of precision using the VLMM TAG-GER (in italics) and the VLMM+SPANS-QUE TAGGER(upcase) with the segmented corpus.the way the VLMM TAGGER could use constituents,the result did not improve.
This led us to a new ap-proach, shown in the next section.183.2 ChunksSince induced syntactic structure did not help, a newidea was to, this time, begin with the already parsedand revised texts from the Tycho Brahe, even withthey summing only a little more than 300 thousandwords.
To ease the problem of sparsity, the treeswere flattened and merged in such a way that onlyNPs, PPs and VPs remained.
Then the bracketed no-tation was converted to the IOB notation, now form-ing a chunked corpus.Chunking, or shallow parsing, divides a sen-tence into non-overlapping phrases (Manning andSch?tze, 1999).
It is used in information extractionand in applications where full parsing is not nec-essary, offering the advantage of being simpler andfaster.We made a small experiment with the chunkedcorpus: divided the sentences randomly into 90%and 10% sets, the former for training and the laterfor testing.
Then we ran the VLMM TAGGER withthese chunked sets, and got a precision in chunkingof 79%.A model for chunks processing was mixed intothe VLMM model, similar but not equal to the mixedmodel with CCM.
The chunked corpus uses seg-mented words, because the parsed texts available inTycho Brahe only use segmented words.
Thus, weran the VLMM TAGGER with the segmented trainingcorpus and the chunked corpus, testing over the seg-mented test corpus.
The precision yielded with thisVLMM+CHUNKS TAGGER was 96.55%.Table 4 shows the results for the segmentedcorpus with the VLMM TAGGER and theVLMM+CHUNKS TAGGER.
Interestingly, results didnot change much, in spite of the VLMM+CHUNKSTAGGER achieving a higher precision.
Interestingly,the word a error rate is reduced by around 13%with the help of chunks, while the que error rateincreases almost 3%.3.3 BidirectionalAnother approach was to follow the intuition abouta: that the right context should help solving someambiguities.
The problem that makes this approachnon trivial is that a right tag context is not yet avail-able when tagging a word, due to the natural left-to-right order the tagger follows when tagging a sen-WORDS P (%) ERR.
/ OCURR.que84 .50 1715 / 1106384.05 1764 / 11063a94 .52 745 / 1359795.26 644 / 13597Total96 .5433 9559 / 27654196.5506 9539 / 276541Table 4: Comparison of precision using the VLMM TAG-GER (in italics) and the VLMM+CHUNKS TAGGER (up-case) with the segmented corpus.tence.
A right context that is available is the contextof words to the right, but this presents the problemof sparsity and will probably not yield good results.Our approach was then to model a right context oftags when the words to the right were not ambigu-ous, that is, if they could be assigned only one spe-cific tag.
During training, a new context tree is builtfor the right context, where, for each word in a sen-tence, a continuous but variable-length sequence oftags from unambiguous words to the right is addedas a branch to the right context tree.
That is, if kwords to right of a given word are not ambiguous,then the sequence of the k tags these words will haveis added to the right tree.
The right context tree isalso prunned like the left context tree and the Viterbialgorithm for tagging is adapted to consider thesenew parameters.WORDS P (%) ERR.
/ OCURR.que84 .74 1687 / 1105684.80 1680 / 11056a90 .94 661 / 730092.15 573 / 7300Total96 .29 9630 / 25999196.33 9544 / 259991Table 5: Comparison of precision using the VLMM TAG-GER (in italics) and the VLMM+A-RIGHT TAGGER (up-case) with the normal corpus.After various tests with different options for theright context tree, the result over the original VLMMtagger did not improve.
We then experimentedbuilding the right context tree only for the word a,19resulting in the VLMM+RIGHT-A TAGGER.
Table 5shows what happens with the normal corpus.The er-ror rate of a is decreased almost 5% with this bidi-rectional approach.3.4 PerceptronThe Perceptron algorithm was first applied to POS-tagging by (Collins, 2002).
It is an algorithm forsupervised learning that resembles ReinforcementLearning, but is simpler and easier to implement.
(Collins, 2002) describes the algorithm for tri-gram HMM taggers.
Here, we will describe it forthe VLMM tagger, adapting the notation and expla-nation.Instead of using maximum-likelihood estimationfor the model parameters, the perceptron algorithmworks as follows.
First, the model parameters areinitialized to zero.
Then, the algorithm iterates agiven number of times over the sentences of thetraining corpus.
For each sentence s, formed by asequence of wordsws paired with a sequence of tagsts, the Viterbi decoding is ran over ws, returning zs,the predicted sequence of tags.
Then, for each se-quence of tags o of length at most k, k the maximumorder of the VLMC, seen c1 times in ts and c2 timesin zs, we make ?c(o) = ?c(o) + c1 ?
c2.
c(o) is thecontext function defined in Section 2 applied to thetag sequence o, which returns the maximum subse-quence of o found in the context tree.
?c(o) repre-sents the parameters of the model associated to c(o),that is, the branch of the context tree that containsc(o).The above procedure effectively means that pa-rameters which contributed to errors in zs are penal-ized, while parameters that were not used to predictzs are promoted.
If ts = zs then no parameter ismodified.
See (Collins, 2002) for the proof of con-vergence.Implementing the perceptron algorithm into theVLMM tagger resulted in the VLMM+PERCEPTRONTAGGER.
Table 6 shows the results obtained.
Notethat no prunning is made to the context tree, becausedoing so led to worse results.
Training and predict-ing with a full context tree of height 10 achieved bet-ter precision.
The numbers reported were obtainedafter 25 iterations of perceptron training.
The totalprecision is lower than the VLMM TAGGER?s preci-sion, but it is interesting to note that the precision forque and a actually increased.WORDS P (%) ERR.
/ OCURR.que84 .74 1687 / 1105685.15 1641 / 11056a90 .94 661 / 730092.41 554 / 7300Total96 .29 9630 / 25999195.98 10464 / 259991Table 6: Comparison of precision using the VLMM TAG-GER (in italics) and the VLMM+PERCEPTRON TAGGER(upcase) with the normal corpus.3.5 Guided Learning(Shen et al, 2007) developed new algorithms basedon the easiest-first strategy (Tsuruoka and Tsujii,2005) and the perceptron algorithm.
The strategy isto first tag words that show less ambiguity, and thenuse the tags already available as context for the moredifficult words.
That means the order of tagging isnot necessarily from left to right.The inference algorithm works by maintaininghypotheses of tags for spans over a sequence ofwords, and two queues, one for accepted spans andone for candidate spans.
Beam search is used forkeeping only a fixed number of candidate hypothe-ses for each accepted span.
New words from thequeue of candidates are tagged based on their scores,computed by considering every possible tag for theword combined with all the available hypotheses onthe left context and on the right context.
The high-est scoring word is selected, the top hypotheses arekept, and the two queues are updated.
At each stepone word from the queue of candidates is selectedand inserted in the queue of accepted spans.The core idea of Guided Learning (GL) training isto model, besides word, tag, and context parameters,also the order of inference.
This is done by defin-ing scores for hypotheses and for actions of tagging(actions of assigning a hypothesis).
The score of atagging action if computed by a linear combinationof a weight vector and a feature vector of the action,which also dependes on the context hypotheses.
Thescore of a given span?s hypothesis is the sum of thescores of the top hypothesis of the left and right con-20texts (if available) plus the score of the action thatled to this hypothesis.The GL algorithm estimates the values of theweight vector.
The procedure is similar to the in-ference algorithm.
The top scoring span is selectedfrom the queue of candidate spans and, if its tophipothesis matches the gold standard (the tags fromthe training corpus), the queues of accepted and can-didate spans are updated as in the inference algo-rithm.
Otherwise, the weight vector is updated ina perceptron style by promoting the features of thegold standard action and demoting the features ofthe top hypothesis?
action.
Then the queue of can-didate spans is regenerated based on the acceptedspans.This model uses trigrams for the left and rightcontexts, and so it could be potentially extended bythe use of VLMCs.
It is our aim to develop a taggercombining the VLMM and the GL models.
But asfor today, we have not yet finished a succesful imple-mentation of the GL model in C++, in order to com-bine it with the VLMM TAGGER?s code (current codeis crashing during training).
Original GL?s code iswritten in Java, which we had access and were ableto run over our training and testing corpora.Table 7 shows the result over the normal corpus.The first thing to note is that the GL model does apretty good job at tagging.
The precision means a10% error reduction.
However, the most interestingthing happens with our two words, que and a. Theprecision of que is not significantly higher.
How-ever, the error rate of a is reduced by half.
Such per-formance shows that the thought about needing theright context to correctly tag a seems correct.
Ta-ble 8 shows the confusion matrix of the most com-mon tags for a.4 ConclusionsIn almost all extended versions of the VLMM TAG-GER, que and a did not suffer a great increase inprecision.
With the approaches that tried to gener-alize context ?
by using syntactic structure ?
andcapture longer dependencies for que, the results didnot change much.
We could see, however, that theright context does not help disambiguating que atall.
Training the VLMM model with a long context(order 10) helped a little with a, but showed over-WORDS P (%) ERR.
/ OCURR.que84 .74 1687 / 1105684.90 1670 / 11056a90 .94 661 / 730095.49 329 / 7300Total96 .29 9630 / 25999196.67 8650 / 259991Table 7: Comparison of precision using the VLMM TAG-GER (in italics) and the GUIDED LEARNING TAGGER (up-case) with the normal corpus.D-F P CLD-F <4144> 92 5P 189 <2528> 2CL 26 9 <294>Table 8: Confusion matrix for a with the most commontags in the normal corpus (line: reference; column: pre-dicted).all worse results.
Modeling a right context for a ina simple manner did also help a little, but not sig-nificantly.
The model that gave good results for awas the one we still have not finished extending withVLMM.
It looks promising, but a way of better dis-ambiguating que was not found.
A better approachto generalize contexts and to try to capture non-localdependencies is needed.
Some further ideas for fu-ture work or work in progress are presented in Sec-tion 6.5 Oportunities for CollaborationTycho Brahe is a corpus project undergoing contin-uous development.
Since there is already a goodamount of resource for supervised tagging, our tag-ger can be used for boosting new texts annotation.Furthermore, the project has started using E-Dictor,an integrated annotation tool.
E-Dictor offers arange of easy to use tools for corpora creators: fromtranscription, philological edition, and text normati-zation, to morphosyntactic annotation.
This last toolneeds an integrated POS-tagger to further ease thehuman task of annotation.
Besides, an increasingnumber of projects is starting and willing to start us-ing E-Dictor, so the need for an automatic tagger21is getting urgent.
We have already been contactedby the E-Dictor developers for further collaboration,and should integrate effors during this year.Another project that can benefit from a good POS-tagger is the Brasiliana Digital Library, from theUniversity of Sao Paulo7.
It started last year digi-talizing books (and other pieces of literature) aboutBrazil from the 16th to the 19th century, mak-ing them available online.
Many books have beenOCRed, and a side project is already studying waysof improving the results.
Since the library is anevolving project, the texts will soon be of reason-able size, and will be able to form another corpus ofhistorical Portuguese A POS-tagger will be of greathelp in making it a new resource for ComputationalLinguistics research.
We are already negotiating aproject for this with the Brasiliana directors.There is a tagger for Portuguese embedded inthe CoGrOO8 gramatical corrector for Open Of-fice.
They seem to implement some interesting rulesfor common use Portuguese that maybe would helpsome of our disambigation problems.
Besides in-specting the available open source code, we havecontacted the current maintainer for further conver-sation.
A possibility that has appeared is to integratethe VLMM TAGGER with CoGrOO.Using different data would be interesting in or-der to check if the exactly same problems arise, orif other languages show the same kind of problems.We will try to get in contact with other projects hav-ing annotated resources available, and seek for fur-ther collaboration.
Currently, we got in touch withpeople working on another corpus of Portuguese9.Both sides are hoping to form a partnership, with usproviding a POS tagger and them the annotated cor-pora.6 Future WorkShort term future work includes implementingGuided Learning in C++ and mixing it with VLMCs.This looks promising since the current GL imple-mentation uses a fixed trigram for contexts to theleft and to the right.
Also, there is a need for fastexecution in case our tagger is really integrated into7http://www.brasiliana.usp.br/bbd8http://cogroo.sf.net/.9History of Portuguese spoken in S?o Paulo (caipiraProject).E-Dictor, so converting GL to C++ seems more nat-ural than implementing the VLMM TAGGER in Java.To try to tackle the difficulty in tagging que thereare some ideas about using context trees of non-local tags.
It seems a potentialy good model couldbe achieved by mixing such context trees with theGuided Learning approach, making a hypothesisconsider non adjacent accepted spans.
This is stilla fresh idea, so further investigation on maybe otherapproaches should be done first.Further investigation involves analyzing errorsmade by POS taggers over modern Portuguese andother romance languages like Spanish in order toverify if que and a continue to have the same de-gree of ambiguity or, in case of Spanish, if there aresimilar words which show similar issues.
This alsoinvolves testing other taggers with our training andtesting sets, to check if they get the same errors overque and a as we did.ReferencesRachel Virg?nia Xavier Aires.
2000.
Implementa??o,adapta?
?o, combina?
?o e avalia?
?o de etiquetadorespara o portugu?s do brasil.
mathesis, Instituto de Ci?n-cias Matem?ticas e Computa?
?o, Universidade de S?oPaulo - Campus S?o Carlos, Oct.Thorsten Brants.
2000.
Tnt ?
a statistical part-of-speechtagger.
In Proceedings of the Sixth Applied NaturalLanguage Processing Conference (ANLP-2000), Seat-tle, WA.Eric Brill.
1993.
Automatic grammar induction and pars-ing free text: A transformation-based approach.
InProceedings of the 21st Annual Meeting of the Asso-ciation for Computational Linguistics.Peter B?hlmann and Abraham J. Wyner.
1999.
Variablelength markov chains.
Annals of Statistics, 27(2):480?513.Michael Collins.
2002.
Discriminative training meth-ods for hidden markov models: theory and experi-ments with perceptron algorithms.
In EMNLP ?02:Proceedings of the ACL-02 conference on Empiricalmethods in natural language processing, pages 1?8,Morristown, NJ, USA.
Association for ComputationalLinguistics.Archias Alves de Almeida Filho.
2002.
Maximiza?
?ode entropia em ling?
?stica computacional para a l?nguaportuguesa, 12.Maria Clara Paix?o de Sousa, F?bio Natanael Kepler, andPablo Picasso Feliciano de Faria.
2009.
E-Dictor: No-vas perspectivas na codifica?
?o e edi?
?o de corpora de22textos hist?ricos.
In Lingu?stica de Corpus: S?ntesese Avan?os.
Anais do VIII Encontro de Lingu?stica deCorpus, UERJ, Rio de Janeiro, RJ, Brasil, 11.
Shep-herd, T. and Berber Sardinha, T. and Veirano Pinto, M.To be published.C?cero Nogueira dos Santos, Ruy L.
Milidi?, and Ra?l P.Renter?a.
2008.
Portuguese part-of-speech tagging us-ing entropy guided transformation learning.
In PRO-POR - 8th Workshop on Computational Processing ofWritten and Spoken Portuguese, volume 5190 of Lec-ture Notes in Artificial Intelligence, pages 143?152,Vit?ria, ES, Brazil.
Springer-Verlag Berlin Heidelberg.Linguateca.pt, 2008.
The Floresta Sint?
(c)tica project.ICMC-USP, 2010.
NILC?s Corpora.
ICMC-USP.IEL-UNICAMP and IME-USP, 2010.
C?rpus Hist?ricodo Portugu?s Anotado Tycho Brahe.
IEL-UNICAMPand IME-USP.F?bio Natanael Kepler and Marcelo Finger.
2006.Comparing two markov methods for part-of-speechtagging of portuguese.
In Jaime Sim?o Sichman,Helder Coelho, and Solange Oliveira Rezende, editors,IBERAMIA-SBIA, volume 4140 of Lecture Notes inArtificial Intelligence, pages 482?491, Ribeir?o Preto,Brazil, 10.
Springer Berlin / Heidelberg.Dan Klein.
2005.
The Unsupervised Learning of NaturalLanguage Structure.
phdthesis, Stanford University.Christopher D. Manning and Hinrich Sch?tze.
1999.Foundations Of Statistical Natural Language Process-ing.
MIT Press, Cambridge, MA, USA.Adwait Ratnaparkhi.
1996.
A maximum entropy modelfor part-of-speech tagging.
In Conference on Empiri-cal Methods in Natural Language Processing, Univer-sity of Pennsylvania, 5.Jorma Rissanen.
1983.
A universal data compressionsystem.
IEEE Trans.
Inform.
Theory, IT-29:656 ?
664.Libin Shen, Giorgio Satta, and Aravind Joshi.
2007.Guided learning for bidirectional sequence classifica-tion.
In Proceedings of the 45th Annual Meeting of theAssociation of Computational Linguistics, pages 760?767, Prague, Czech Republic, 6.
Association for Com-putational Linguistics.Kristina Toutanova, Dan Klein, Christopher D. Manning,and Yoram Singer.
2003.
Feature-rich part-of-speechtagging with a cyclic dependency network.
In NAACL?03: Proceedings of the 2003 Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics on Human Language Technology,pages 173?180, Morristown, NJ, USA.
Association forComputational Linguistics.Yoshimasa Tsuruoka and Jun?ichi Tsujii.
2005.
Bidi-rectional inference with the easiest-first strategy fortagging sequence data.
In HLT ?05: Proceedings ofthe conference on Human Language Technology andEmpirical Methods in Natural Language Processing,pages 467?474, Morristown, NJ, USA.
Association forComputational Linguistics.Andrew James Viterbi.
1967.
Error bounds for convolu-tional codes and an asymptotically optimal decondingalgorithm.
IEEE Transactions on Information Theory,pages 260 ?
269, 4.23
