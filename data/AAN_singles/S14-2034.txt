Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 213?217,Dublin, Ireland, August 23-24, 2014.Copenhagen-Malm?o: Tree Approximations of Semantic Parsing ProblemsNatalie Schluter?, Jakob Elming, Sigrid Klerke, H?ector Mart?
?nez Alonso, Dirk HovyBarbara Plank, Anders Johannsen, and Anders S?gaard?Dpt.
of Computer Science Center for Language TechnologyMalm?o University University of Copenhagennatalie.schluter@mah.se {zmk867,skl,alonso}@hum.ku.dk{dirk,bplank}@cst.dk,{ajohannsen,soegaard}@hum.ku.dkAbstractIn this shared task paper for SemEval-2014 Task 8, we show that most se-mantic structures can be approximated bytrees through a series of almost bijectivegraph transformations.
We transform in-put graphs, apply off-the-shelf methodsfrom syntactic parsing on the resultingtrees, and retrieve output graphs.
Us-ing tree approximations, we obtain goodresults across three semantic formalisms,with a 15.9% error reduction over a state-of-the-art semantic role labeling system ondevelopment data.
Our system came in 3/6in the shared task closed track.1 IntroductionSemantic analyses often go beyond tree-structured representations, assigning multiple se-mantic heads to nodes, some semantic formalismseven tolerating directed cycles.1At the sametime, syntactic parsing is a mature field with effi-cient, highly optimised decoding and learning al-gorithms for tree-structured representations.
Wepresent tree approximation algorithms that in com-bination with a state-of-the-art syntactic parserachieve competitive performance in semantic di-graph parsing.We investigate two kinds of tree approximationalgorithms that we will refer to as pruning algo-rithms and packing algorithms.
Our pruning al-gorithms simply remove and reverse edges untilthe graph is a tree; edge reversals are then undoneas a postprocessing step.
Our packing algorithms,on the other hand, carry out two bijective graphThis work is licenced under a Creative Commons Attribu-tion 4.0 International License.
Page numbers and proceed-ings footer are added by the organizers.
License details:http://creativecommons.org/licenses/by/4.0/1For example, HPSG predicate-argument structures (Pol-lard and Sag, 1994).transformations to pack structural information intonew edge labels, making it possible to reconstructmost of the structural complexity as a postprocess-ing step.
Specifically, we present a packing al-gorithm that consists of two fully bijective graphtransformations, in addition to a further transfor-mation that incurs only a small information loss.We carry out experiments across three seman-tic annotations of the Wall Street Journal sectionof the Penn Treebank (Marcus et al., 1993), cor-responding to simplified versions of the semanticformalisms minimal recursion semantics (MRS)(Copestake et al., 2005), Enju-style predicate-argument structures (Miyao and Tsujii, 2003), andPrague-style tectogrammar semantics (B?ohmov?aet al., 2003).
We show that pruning and pack-ing algorithms lead to state-of-the-art performanceacross these semantic formalisms using an off-the-shelf syntactic dependency parser.2 Related workSagae and Tsujii (2008) present a pruning algo-rithm in their paper on transition-based parsing ofdirected acyclic graphs (DAGs), which discardsthe edges of longest span entering nodes.
Theyapply the dependency parser described in Sagaeand Tsujii (2007) to the tree representations.
Wenote that this algorithm is not sufficient to producetrees in our case, where the input graphs are notnecessarily acyclic.
It does correspond roughly toour LONGEST-EDGE baseline, which removes thelongest edge in cycles, in addition to flow reversal.Sagae and Tsujii (2008) also present a shift-reduce automaton approach to parsing DAGs.
Intheir paper, they report a labeled F1-score of88.7% on the PAS dataset (see Section 3), whilewe obtain 89.1%, however the results are thus notdirectly comparable due to different data splits.22We obtained code to run this as a baseline, but were un-able to, due to memory leaks, caused by subsets of our data,and on the subsets of data that actually parsed, recall was very213The shared task organizers of the Broad-coverage Semantic Dependency Parsing task atSemEval-20143also presented a pruning-basedbaseline system.
They eliminate re-entrancies inthe graph by removing dependencies to nodes withmultiple incoming edges.
Of these edges, theyagain keep the shortest.
They incorporate all sin-gleton nodes by attaching nodes to the immedi-ately following node or to a virtual root - in casethe singleton is sentence-final.
Finally, they inte-grate fragments by subordinating remaining nodeswith in-degree 0 to the root node.
They apply theparser described in Bohnet (2010), also used be-low, to the resulting trees.
This system obtaineda labeled F1-score of 54.7% on the PAS dataset.The performance of their pruning algorithm wasalso considerably lower than our algorithms on theother datasets considered below.3 Tree approximationsThis section describes two approaches to approxi-mating graphs by trees, namely pruning and pack-ing.
Pruning optimizes the number of ?good?edges in trees (Section 3.1), while packing trans-forms graphs into trees by means of a pipeline ofoperations which are 99.6% reversible (see Fig-ure 1); that is, almost no information from theoriginal graphs is lost in the trees (Section 3.2).Under both approaches, we first introduce arti-ficial root nodes to the graphs and append themto the word list.
Graphs may initially be discon-nected.
We connect all weakly connected com-ponents as follows.
We first identify a most im-portant node in each weakly connected compo-nent, which we will refer to as the root.
This rootis taken to be the first node with the ?top?
fea-ture from the data, if one exists.
If none exists,then the node with highest degree is chosen as the?root?.
(Note that the ?root?
of each non-singletonconnected component is marked as a ?top?
nodein the inverse transformation.)
The root of eachnon-singleton weakly connected component is at-tached as a dependent of the artificial root nodewith a special new label for the correspondingedge.
Also, each disconnected node is attachedas a dependent of the node to the right of it, witha distinct special new label.
It is these connectedgraphs that we take to be the input in the followinglow, suggesting that maybe the decoding algorithm was tunedto a specific planarization of the complex graphs.3http://alt.qcri.org/semeval2014/task8/two subsections describing our graph pruning andpacking algorithms.3.1 Graph pruningOur PRUNING algorithm removes a small numberof edges in the semantic graphs to be able to repre-sent them as trees.
The average edge counts fromthe training data (see Section 4.1) indicate that thepotential edge loss in pruning is relatively small(5.7% in the worst case).
In this approach, twotransformations on the connected semantic graphsare carried out: pruning and flow reversal.Pruning.
The input digraph may contain under-lying undirected cycles.
We break these cyclesby iteratively removing the longest edge from thenode with the fewest predecessors (lowest depth)in the digraph.
The resulting underlying undi-rected graph is a tree.Depth-first flow reversal.
We then carry outdepth-first traversal of the resulting underlyingundirected tree, reversing the direction of edgesfrom the leaves upwards, as needed, until reach-ing the root.
Any reversed edge?s label is given aspecial prefix, so that this reversal can be undonein a post-processing step.Following the above two transformations, we trainour parsers on the transformed semantic annota-tions and output graphs such as the one in Fig-ure 1a.3.2 Graph packingOur PACKING algorithm consists of a pipeline offour graph transformations.
The two major trans-formations are for coordination and generalisedlong-distance dependencies, being both parallelpath inducing constructions.
The transformationsare both linguistically and topologically inspiredby the f-structure annotated c-structures in Lex-ical Functional Grammar and f-structure parsingvia off-the-shelf dependency parsers (Schluter andVan Genabith, 2009).
We further ensure the defin-ing tree property that every node is connected by aunique path from the root, by carrying out flow re-versal when necessary.
Finally remaining parallelpaths are broken according to an heuristic on pathlocality.Coordination.
In some semantic representa-tions of coordination, individual conjunct nodesmay all dominate a same argument, or be domi-nated by a same head.
In both these cases, paral-lel paths are generated.
The same structures may214a)b)c)Figure 1: Example of pruned (top), packed (middle), and original (bottom) semantic graph.
(Sentence22002004 from the PAS dataset.
)be represented if the head or arguments are ?fac-tored out?.
To do this, we remove all edges fromconjuncts towards a same argument (resp.
froma shared head to each conjunct), and introduce anew edge from the root of the coordination sub-tree towards this argument (resp.
from a sharedhead to the root of the coordination subtree).
Thenew edges receive a special prefix to facilitate ap-plying the inverse transformation.Breadth-first flow reversal.
Unlike our pruningalgorithm, there is not yet any clear distinct pathfrom the root to the all nodes (as there are notleaves yet).
After carrying out the coordinationtransformation, we carry out a breadth-first searchon the graph to direct flow away from the root, andagain, reversed edges?
labels are given a specialprefix.
As we do this, we test resulting nodes tosee if there are any parallel paths leading to them.If so, these paths may be transformed immediatelyaccording to the following transformation.Generalized long-distance dependencies.Long-distance dependencies are representedin f-structure annotated c-structures by pathequations.
This gives a tree representation ofparallel paths, at least one of which is exactlyone edge long.
Given two parallel paths p1andp2in the graph, where p1= (v1, l, vn) and p2=(v1, l1, v2), (v2, l2, v3), .
.
.
, (vn?1, ln?1, vn), weremove the last edge of p2and augment p1?s labelwith the representation l1: l2: ?
?
?
: ln?1of p2.
p1becomes (v1, l and l1: l2: ?
?
?
: ln?1, vn), indi-cating that vnis also the child (with dependencylabel ln?1) of the node found by travelling (fromv1) down an l1labelled edge, followed by an l2labelled edge, and so on until the child of the ln?2labelled edge is found.Maximum average locality heuristic.
Follow-ing these transformations, there may still be paral-lel paths in the graph: those not parallel to a singleedge.
We remove ?worst?
re-entrant edges usingthe simple heuristic that the path with the lowestaverage edge span should be conserved entirely.These removed edges clearly cannot be recoveredafter transformation.Our parsers are trained on the output graphs ofthese four transformations such as the one in Fig-ure 1b.
We observe the main difference betweenPRUNING and PACKING: coordination and long-distance dependencies.
For example, PACKINGkeeps the edge between the conjunction and thefirst conjunct, which is pruned away in PRUNING.Such a difference provides a partial explanationfor the lower recall of PRUNING vis-`a-vis PACK-ING (see Section 4.5).4 Experiments4.1 DataThe three datasets are semantic annotations of theWSJ section of the Penn Treebank of English.
Theaverage sentence length, which is also the aver-age number of dependency edges in the tree ap-proximations that we use to induce our semanticparsers, is 22.93.
The three semantic formalismsare slightly richer, and the average number ofedges in the PAS-annotated treebank is 24.32.
ForDM, the average number of edges is 23.77, andfor DM it is 23.33.
While the pruning-based ap-proaches thus suffers from a modest informationloss, throwing out 5.7% of the edges in the worst215case, this is not the case for packing.
The re-versibility of the packed representations is givenby the score upper bound in the last row in Ta-ble 1.
We use the dataset splits of the SemEval2014 shared task.4.2 ModelFor both our pruning and packing models, we usethe Mate parser (Bohnet, 2010)4with default pa-rameters to learn our parsing models.
The Mateparser is trained on the output of the transforma-tion pipeline on Sections 00-19 of the three se-mantically annotated WSJ datasets.
Some modelsuse Brown clusters generated from Sections 00-19 only.
This does not solve OOV problems, butallows of slightly better generalisation across dis-tributionally similar words in the training data.4.3 BaselinesWe use the SemEval 2014 shared task baseline(SIMPLE-PRUNE; see Section 2), as well as theLONGEST-EDGE baseline, also mentioned above.The latter is our strongest baseline system.
It isvery similar to PRUNING, in doing both edge prun-ing and flow reversal, but the pruning step onlyremoves the longest edge rather than consideringnode depth.
Our third baseline is the Mate seman-tic role labeling learner (SRL-DEP) (Bj?orkelundet al., 2009), which uses predicted syntactic parsesas input; for this, we use the syntactic parses madeavailable in the SemEval 2014 shared task forreplicability.Approach Cl DM PAS PCEDT AvSystemsPRUNINGNO 86.6 88.8 72.7 82.7YES 86.9 89.1 72.5 82.8PACKINGNO 85.8 88.7 71.8 82.1YES 86.1 88.7 72.9 82.6BaselinesSIMPLE-PRUNE 54.7 50.9 67.8 57.8LONGEST-EDGE 83.8 88.9 66.1 79.6SRL-DEP 79.5 82.4 70.1 77.4Upper boundPACKING 99.9 99.5 99.5 99.6Table 1: Labelled F1-score results on developmentdata, with and without use of Brown clusters (Cl).4.4 ResultsThe results are presented in Tables 1 through 3,where the system evaluations for the SemEval taskare marked with asterisks in Table 2.
We note thatall our approaches do considerably better than our4https://code.google.com/p/mate-tools/Approach metric DM PAS PCEDT AvSystemsPACKING PREC 84.8 87.7 71.2 81.2(W/ TOP) REC 84.0 88.4 68.6 80.3F1 84.4 88.0 69.9 80.8?PREC 85.4 87.9 70.8 81.4(W/O TOP) REC 84.6 88.6 68.8 80.7F1 85.0 88.3 69.9 81.1PRUNING PREC 87.2 91.3 72.8 83.8(W/ TOP) REC 80.2 81.3 62.8 74.8F1 83.6 86.0 67.4 79.0?PREC 87.2 91.3 72.8 83.8(W/O TOP) REC 85.1 85.1 68.0 79.4F1 86.2 88.1 70.3 81.5Table 2: Labelled results on test data, with andwithout evaluation of top nodes.
The scores withasterisks correspond to the output evaluated in theSemEval task.Approach metric DM PAS PCEDT AvSystemsPACKING PREC 86.8 89.1 84.8 86.9(W/ TOP) REC 86.0 89.8 81.8 85.9F1 86.4 89.4 83.2 86.3PREC 87.5 89.4 85.4 87.4(W/O TOP) REC 86.7 90.1 83.0 86.6F1 87.1 89.7 84.2 87.0PRUNING PREC 89.2 92.6 88.2 90.0(W/ TOP) REC 82.0 82.5 76.1 80.2F1 85.4 87.3 81.7 84.8PREC 89.2 92.6 88.2 90.0(W/O TOP) REC 87.1 86.3 82.4 85.3F1 88.1 89.3 85.2 87.5Table 3: Unlabelled results on test data, with andwithout evaluation of top nodes.three baselines.
The error reduction of our bestsystem over the SRL system across all three for-malisms is 24.2%, and the error reduction overthe more competitive pruning baseline LONGEST-EDGE is 15.9%.
As mentioned in Section 2, theseresults seem to promise better performance thancurrent DAG parsing models.
Note from the re-sults in Table 2 that, as expected, PRUNING leadsto higher precision than PACKING at the expenseof recall.4.5 Error AnalysisWe observe that pruning leads to high precision,while our packing algorithm gives us much bet-ter recall.
This is not surprising, since our packedrepresentations introduce new labels, making itharder to generalize at training time.
On the otherhand, pruning approaches suffer in recall, simplybecause edges are thrown away in preprocessingthe data.2165 ConclusionsIn this paper, we experimented with using tree ap-proximation algorithms to reduce semantic struc-tures to trees and use off-the-shelf structured pre-diction techniques to train semantic parsers.
Ourapproximation algorithms include both pruningand packing algorithms, i.e., algorithms that tryto reduce graphs to trees optimally, as well as al-gorithms that pack information about graphs intotrees from which we later recover the richer struc-tures.
Using these tree approximation algorithms,we obtain 15.9% error reductions over a state-of-the-art SRL system.ReferencesAnders Bj?orkelund, Love Hafdell, and Pierre Nugues.2009.
Multilingual semantic role labeling.
In Proc.of CoNLL: Shared Task, pages 43?48, Boulder, CO,USA.Alena B?ohmov?a, Jan Haji?c, Eva Haji?cov?a, and BarboraHladk?a.
2003.
The Prague Dependency Treebank:A three-level annotation scenario.
In Anne Abeill?e,editor, Treebanks: Building and Using Syntacti-cally Annotated Corpora, pages 103?127.
Kluwer,Netherlands.Bernd Bohnet.
2010.
Top accuracy and fast depen-dency parsing is not a contradiction.
In Proc.
ofCOLING, pages 89?97, Beijing, China.Ann Copestake, Dan Flickinger, Carl Pollard, and IvanSag.
2005.
Minimal recursion semantics.
Researchon Language and Computation, 3:281?332.Mitchell Marcus, Mary Marcinkiewicz, and BeatriceSantorini.
1993.
Building a large annotated cor-pus of English: the Penn Treebank.
ComputationalLinguistics, 19(2):313?330.Yusuke Miyao and Jun?ichi Tsujii.
2003.
Probabilis-tic modeling of argument structures including non-local dependencies.
In Proc.
of RANLP, pages 79?85, Borovets, Bulgaria.Carl Pollard and Ivan Sag.
1994.
Head-driven phrasestructure grammar.
University of Chicago Press.Kenji Sagae and Jun?ichi Tsujii.
2007.
Dependencyparsing and domain adaptation with LR modelsand parser ensembles.
In Proc.
of CoNLL Sharedtask session of EMNLP-CoNLL, pages 1044?1050,Prague, Czech Republic.Kenji Sagae and Jun?ichi Tsujii.
2008.
Shift-reducedependency DAG parsing.
In Proc.
of COLING,pages 753?760, Manchester, UK.Natalie Schluter and Josef Van Genabith.
2009.
De-pendency parsing resources for French.
In Proc.
ofNODALIDA, pages 166?173, Odense, Denmark.217
