Using Parsed Corpora for Structural Disambiguat ion in theTRAINS DomainMark  CoreDepar tment  of Computer  Sc ienceUn ivers i ty  of RochesterRochester ,  New York  14627mcore@cs .
rochester .eduAbst rac tThis paper describes a prototype disam-biguation module, KANKEI, which wastested on two corpora of the TRAINSproject.
In ambiguous verb phrases of formV ... NP PP or V ... NP adverb(s), the twocorpora have very different PP and adverbattachment patterns; in the first, the cor-rect attachment is to the VP 88.7% of thetime, while in the second, the correct at-tachment is to the NP 73.5% of the time.KANKEI  uses various n-gram patterns ofthe phrase heads around these ambiguities,and assigns parse trees (with these ambigu-ities) a score based on a linear combinationof the frequencies with which these pat-terns appear with NP and VP attachmentsin the TRAINS corpora.
Unlike previ-ous statistical disambiguation systems, thistechnique thus combines evidence from bi-grams, trigrams, and the 4-gram around anambiguous attachment.
In the current ex-periments, equal weights are used for sim-plicity but results are still good on theTRAINS corpora (92.2% and 92.4% accu-racy).
Despite the large statistical differ-ences in attachment preferences in the twocorpora, training on the first corpus andtesting on the second gives an accuracy of90.9%.1 In t roduct ionThe goal of the TRAINS project is to build a com-puterized planning assistant hat can interact con-versationally with its user.
The current version ofthis planning assistant, TRAINS 95, is described in(Allen et al, 1995); it passes speech input onto aparser whose chart is used by the dialog managerand other higher-level reasoning components.
Theplanning problems handled involve moving severaltrains from given starting locations to specified des-tinations on a map display (showing a network of raillines in the eastern United States).
The 95 dialogsare a corpus of people's utterances to the TRAINS95 system; they contain 773 instances of PP or ad-verb postmodifiers that can attach to either NPs orVPs.
Many of these cases were unambiguous, asthere was no NP following the VP, or the NP didnot follow a verb.
Only 275 utterances containedambiguous constructions and in 73.5% of these, thecorrect PP/adverb attachment was to the NP.One goal of the TRAINS project is to enhancethe TRAINS 95 system sufficiently to handle themore complex TRAINS 91-93 dialogs.
This corpuswas created between 1991 and 1993 from discussionsbetween humans on transportation problems involv-ing trains.
The dialogs deal with time constraintsand the added complexity of using engines to pickup boxcars and commodities to accomplish deliv-ery goals.
This corpus contains 3201 instances ofPP or adverb postmodifiers that can attach to ei-ther NPs or VPs.
1573 of these examples containedboth an NP and a VP to which the postmodifiercould attach.
The postmodifier attached to the VPin 88.7% of these examples.
On average, a post-modifier attachment ambiguity appears in the 91-93dialogs after about 54 words, which is more frequentthan the 74 word average of the 95 dialogs.
Thissuggests that a disambiguation module is going tobecome necessary for the TRAINS system.
This isespecially true since some of the methods used byTRAINS 95 to recover from parse errors will notwork in a more complex domain.
For instance inthe 95 dialogs, a PP of form at city-name can beassumed to give the current location of an enginethat is to be moved.
However, this is not true of the91-93 dialogs where actions such as load often takeat city-name as adjuncts.2 Methodo logyKANKEI I is a first attempt at a TRAINS dis-ambiguation module.
Like the systems in (Hindleand Rooth, 1993) and (Collins and Brooks, 1995),KANKEI records attachment statistics on informa-1From the Japanese word, kankei, meaning"relation.
"345tion extracted from a corpus.
This information con-sists of phrase head patterns around the possible lo-cations of PP/adverb attachments.
Figure 1 showshow the format of these patterns allows for combi-nations including a verb, NP-head (rightmost NPbefore the postmodifier), and either the prepositionand head noun in the PP, or one or more adverbs.
2These patterns are similar to ones used by the disam-biguation system in (Collins and Brooks, 1995) and(Brill and Resnik, 1994) except hat Brill and Resnikform rules from these patterns while KANKEI andthe system of Collins and Brooks use the attachmentstatistics of multiple patterns.
While KANKEI com-bines the statistics of multiple patterns to make adisambiguation decision, Collins and Brooks' modelis a backed-off model that uses 4-gram statisticswhere possible, 3-gram statistics where possible if no4-gram statistics are available, and bigram statisticsotherwise.verb NP-head (preposition obj-head I adverbl adverb2)Figure 1: Format of an attachment patternMost items in this specification are optional.
Theonly requirement is that patterns have at least twoitems: a preposition or adverb and a verb or NP-head.
The singular forms of nouns and the baseforms of verbs are used.
These patterns (with hy-phens separating the items) form keys to two hashtables; one records attachments to NPs while theother records attachments to VPs.
Numbers arestored under these keys to record how often sucha pattern was seen in a not necessarily ambiguousVP or NP attachment.
Sentence 1 instantiates thelongest possible pattern, a 4-gram that here consistsof need, orange, in, and Elmira.I) I need the oranges in Elmira.The TRAINS corpora are much too small forKANKEI  to rely only on the full pattern of phraseheads around an ambiguous attachment.
Whilesearching for attachment statistics for sentence 1,KANKEI  will check its hash tables for the keyneed-orange-in-Elmira.
I f  it relied entirely on fullpatterns, then if the pattern had not been seen,KANKEI  would have to randomly guess the at-tachment.
Such a technique will be referred to asfull matching.
Normally KANKEI will do partialmatching, i.e., if it cannot find a pattern such asneed-orange-in-Elmira, it will look for smaller partialpatterns which here would be: need-in, orange-in,orange-in-Elmira, need-in-Elmira, and need-orange-in.
The frequency with which NP and VP attach-ment occurs for these patterns is totaled to see if oneattachment is preferred.
Currently, we count partialpatterns equally, but in future refinements we would2Examples of trailing adverb pairs are first off andright now.like to choose weights more judiciously.
For instance,we would expect shorter patterns such as need-into carry less weight than longer ones.
The need tochoose weights is a drawback of the approach.
How-ever, the intuition is that one source of evidence isinsufficient for proper disambiguation.
Future workneeds to further test this hypothesis.The statistics used by KANKEI  for partial or fullmatching can be obtained in various ways.
One is touse the same kinds of full and partial pattern match-ing in training as are used in disambiguation.
Thisis called comprehensive training.
Another method,called raw training, is to record only full patternsfor ambiguous and unambiguous attachments in thecorpus.
(Note that full patterns can be as small asbigrams, such as when an adverb follows an NP act-ing as a subject.)
Although raw training only col-lects a subset of the data collected by comprehen-sive training, it still gives KANKEI  some flexibilitywhen disambiguating phrases.
If the full pattern ofan ambiguity has not been seen, KANKEI  can testwhether a partial pattern of this ambiguous attach-ment occurred as an unambiguous attachment in thetraining corpus.Like the disambiguation system of (Brill andResnik, 1994), KANKEI  can also use word classesfor some of the words appearing in its patterns.
Therudimentary set of noun word classes used in thisproject is composed of c i ty  and commodi ty  classesand a t ra in  class including cars and engines.3 Measure  o f  SuccessOne hope of this project is to make generaliza-tions across corpora of different domains.
Thus,experiments included trials where the 91-93 dialogswere used to predict the 95 dialogs 3 and vice versa.Experiments on the effect of training and testingKANKEI on the same set of dialogs used cross val-idation; several trials were run with a different partof the corpus being held out each time.
In all thesecases, the use of partial patterns and word classeswas varied in an attempt o determine their effect.Word ClassesRaw TrainingP.
MatchingDefault Guess% by Default% AccuracyYes Yes Yes YesYes Yes No YesYes Yes No NoVP NP NP NP86.9 85.5Table 1: Results of training with the 93 dialogs andtesting on the 95 dialogsTables 1, 2, and 3 show the results for thebest parameter settings from these experiments.391-93 dialogs were used for training and the 95 di-alogs for testing.346Word ClassesRaw TrainingP.
MatchingDefault Guess% by Default% AccuracyYes Yes No Yes NoNo No No Yes Yes NoYes Yes Yes YesNP VP VP VP NP \[::4 ::0 ::0:150 ::0 ITable 2: Results of training and testing on the 95dialogsWord ClassesRaw TrainingP.
MatchingDefault Guess% by Default% AccuracyYes No Yes YesNo No Yes NoYes Yes No NoVP VP VP VP91.0 91.0Table 3: Results of training and testing on the 93dialogsThe rows labeled % by Default give the portion ofthe total success rate (last row) accounted for byKANKEI's default guess.
The results of training onthe 95 data and testing on the 93 data are not shownbecause the best results were no better than alwaysattaching to the VP.
Notice that all of these resultsinvolve either word classes or partial patterns.
Thereis a difference of at least 30 attachments (1.9% ac-curacy) between the best results in these tables andthe results that did not use word classes or partialpatterns.
Thus, it appears that at least one of thesemethods of generalization is needed for this high-dimensional space.
The 93 dialogs predicted attach-ments in the 95 test data with a success rate of 90.9%which suggests that KANKEI is capable of makinggeneralizations that are independent of the corpusfrom which they were drawn.
The overall accuracyis high: the 95 data was able to predict itself withan accuracy of 92.2%, while the 93 data predicteditself with an accuracy of 92.4%.4 D iscuss ion  and  Future  WorkThe results for the TRAINS corpora are encourag-ing.
We would also like to explore how KANKEIperforms in a more general domain such as the WallStreet Journal corpus from the Penn Treebank.
Wecould then compare results with Collins and Brooks'disambiguation system which was also tested usingthe Penn Treebank's Wall Street Journal corpus.Weighting the n-grams in a nonuniform mannershould improve accuracy on the TRAINS corporaas well as in more general domains.
(Alshawi andCarter, 1994) address a related problem, weightingscores from different disambiguation systems to ob-tain a single rating for a parse tree.
They achievedgood results using a hill climbing technique to ex-plore the space of possible weights.
Another possibletechnique for combining evidence is the maximum-entropy technique of (Wu, 1993).
We are also consid-ering using logical forms (instead of word and wordclasses) in collocation patterns.The integration of KANKEI with the TRAINSparser needs to be completed.
As a first attempt,when the TRAINS parser tries to extend the arcsassociated with the rules: VP -> VP (PP\[ADV)and NP -> NP (PP\[ADV), KANKEI will adjustthe probabilities of these arcs based on attachmentstatistics.
4 Ultimately, the TRAINS disambiguationmodule will contain functions measuring rule habit-uation and distance ffects.
Then it will become nec-essary to weight the scores of each disambiguationtechnique according to its effectiveness.
The abil-ity to adjust probabilities based on evidence seen isan advantage over rule-based approaches.
This ad-vantage is obtained at the expense of storing all thepatterns een.AcknowledgmentsThis work was supported in part by National ScienceFoundation grant IRI-95033312.
Len Schubert's u-pervision and many helpful suggestions are grate-fully acknowledged.
Thanks also to James Allen forhis helpful comments.ReferencesJames Allen, George Ferguson, Bradford Miller, andEric Ringger.
1995.
Spoken dialogue and inter-active planning.
In Proc.
of the ARPA SpokenLanguage Technology Workshop, Austin, TX.Hiyan Alshawi and David Carter.
1994.
Trainingand scaling preference functions.
ComputationalLinguistics, 20(4):635-648.Eric Brill and Philip Resnik.
1994.
A rule-based ap-proach to prepositionM phrase attachment disam-biguation.
In Proc.
of 15th International Confer-ence on Computational Linguistics, Kyoto, Japan.Michael Collins and James Brooks.
1995.
Prepo-sitional phrase attachment through a backed-offmodel.
In Proc.
of the 3rd Workshop on VeryLarge Corpora, pages 27-38, Boston, MA.Donald Hindle and Mats Rooth.
1993.
Structuralamiguity and lexical relations.
ComputationalLinguistics, 19(1):103-120.Dekai Wu.
1993.
Estimating probability distribu-tions over hypotheses with variable unification.
InProc.
of the 11th National Conference on Artifi-cial Intelligence, pages 790-795, Washington D.C.4The TRAINS parser is probabilistic although theprobabilities are parse scores not formal probabilities.347
