DETERMINISTIC PARSINGANDUNBOUNDED DEPENDENCIESTed BriscoeDept of Linguistics, Lancaster UniversityBailrigg, LancashireLA1 4YT, UKABSTRACTThis paper assesses two new approaches todeterministic parsing with respect to the analysis ofunbounded ependencies (UDs).
UDs in English are highlylocally (and often globally) ambiguous.
Several researchershave argued that the difficulty of UDs undermines theprogramme of deterministic parsing.
However, theirconclusion is based on critiques of various versions of theMarcus parser which represents only one of many possibleapproaches to deterministic parsing.
We examine thepredictions made by a LR(1) deterministic parser and theLexicat deterministic parser concerning the analysis ofUDs.
The LR(1) technique is powerful enough to resolvethe local ambiguities we examine.
However, the Lexicatmodel provides a more psychologically plausible accountof the parsing of UDs, which also offers a unified accountof the resolution of local and global ambiguities in theseconstructions.INTRODUCTIONChurch (1980:117) and Johnson-Laird (1983:313) haveargued that the high degree of ambiguity in unboundeddependencies undermines the programme of deterministicparsing.
Their conclusion is based on critiques of variousversions of the Marcus parser (Marcus, 1980; Berwick &Weinberg, 1984).
This parser epresents only one of manypossible approaches to deterministic parsing..
Therefore, theconclusion that deterministic parsing, m general, isimpractical or psychologically implausible may bepremature.In the next section, we outline the problems for thedeterministic analysis of unbounded ependencies.
In thesucceeding sections, we present two alternative parsingtechniques (and associated grammars) which makediffering predictions concerning the onset and location ofindeterminacy in the analysis of unbounded ependencies.We argue that the LR(1) parser is capable ofdeterministically resolving the local ambiguities whichoccur in these constructions, whilst the Lexicat parser isnot.
In the final section, we evaluate these predictions inthe light of the Determinism Hypothesis (Marcus, 1980)and the Interactive Determinism Hypothesis (Briscoe &Boguraev, 1984; Briscoe, in press) and argue that theLexicat parser in conjunction with the InteractiveDeterminism Hypothesis provides the most psychologicallyplausible and unified account of the parsing of unboundeddependencies.UNBOUNDED DEPENDENCY AMBIGUIT IESUnbounded dependencies are found in Englishconstituent questions, relative clauses and topicalisedconstructions.
The dependency is between the preposedconstituent and its point of attachment.
For example, in(1) Who is preposed and functioning as direct object ofthe transitive verb like.
(I) Who do you like _eMost current theories of grammar represent thegrammatical role of the prcposcd constituent byassociating it with the normal position of a constituenthaving that grammatical role.
In several theories, thisposition is occupied by a phonologically null category ortrace which is grammatically linked to the prcposedconstituent.
Wc  will use _e to mark this position becauseeach of the grammars associated with the parsers weconsider adopts a 'positional' account of the recovery ofthe grammatical role of the preposed constituent.However, we use _c to mark an unambiguous point ofattachment without any commitment to the presence ofphonologically null categories or su'ucmrc in the syntacticrepresentation of unbounded dependencies.The dependency between preposed constituent andpoint of attachment is unbounded because an unlimitedamount of lexical material can occur between these twopoints in grammatical English constructions of this type.For example, it is possible to construct more and moreembedded examples like those in (2) which exhibit thesame dependency as (I).
(2)Who do you think K im likes c_Who do you expect that K im hopes Sandy likes eA parser for English capable of producing a syntacticrepresentation adequate to guide semantic interpretationmust recover the grammatical role of thc preposedconstituent.
However, whenever these constructionscontain verbs of ambiguous valency thc correct point ofattachment for the preposcd constituent also becorncsambiguous.
For example, in (3) there are two potentialattachment points, or doubtful gaps (Fodor, 1979), writtene?.
(3) Who do you want e?
to succeed e?The correct attachment of Who is ambiguous becauseboth want and succeed can take, but do not require, NPobjects.211The ambiguity in (3) is global with respect to thesentence; however, identical ocal ambiguities exist for aparser operating incrementally from left to fight.
Forexample, in (4) the attachment of Who as object of want,although correct, remains doubtful until the end of thesentence.
(4) Who do you want e?
to succeed BillThus, at the point when the parser eaches a potential hutambiguous attachment point in the left-to-fight analysis ofthe input, it cannot be sure that this is the correctattachment point because there may be another furtherdownstream in the input, as in (3).
Moreover, the point ofattachment further downstream ay be unambiguous andobligatory, resolving the local ambiguity in the otherdirection, as in (5).
(5) Who do you want e?
to replace fiTo resolve the local ambiguities in unboundeddependencies the parser requires access to an unboundedamount of left and fight context, measured in terms oflexical material.
Firsdy, when a potential attachment pointis found, the parser must know whether or not a preposedconstituent exists to be attached.
This requires potentiallyunbounded access to the left context of the analysis sincethe preposed constituent could have occurred anunbounded istance hack from its point of attachment.Secondly, when a potential but ambiguous attachmentpoint is found, the parser must decide whether it is thecorrect point of attachment.
However, since this decisioncannot be made determinately when the potentialattachment point occurs, the parser requires access to theright context of forthcoming material downstream fromthe current position.
The examples in (6) illustrate thatthis would require unbounded lookahead.
(6)Who does Kim want e?
to think that the boss willreplace Sandy (with e_.
)Who does Kim want e?
to think that the bossexpects the directors to replace Sandy (with e_e)In (6) the ~ t  point of attachment cannot bedetermined until the end of the sentence which can bearbitrarily far away (in terms of lexical material) in thefight context.Berwick & Weinberg (1984:153f) argue that theMarcus parser can adequately represent an unbounded leftcontext with fufite resources if a successive cyclic andtrace theoretic analysis (eg.
Chomsky, 1981) ofunbounded dependencies is adopted.
However, bothChurch (1980) and Fodor (1985) demonstrate that thethree cell lookahead buffer in the Marcus parser is notpowerful enough to provide the required access to theright context in order to choose the correct point ofattachment deterministicaUy in many unboundeddependency constructions.Marcus' (1980) Determinism Hypothesis claims thatlocal ambiguities which are not resolvable in terms of thelookahead buffer are resolved by parsing strategy and thattherefore, many unbounded dependency constructionsshould be psychologically complex, 'garden paths'requiring extensive reanalysis.
There is some evidence forsyntactic preferences in the analysis of unboundeddependencies; the oddity of the examples in (7), which allrequire attachment of the preposed phrase in a doubtfulposition, suggests that the human parser prefers to ignoredoubtful points of attachment and wait for a later one.
(7)a) Who did you want to give the present o Sue.
'?b) I gave the boy who you wanted to give thebooks to three books.c) Sue wouldn't give the man who was reading thebookHowever, as Fodor (1985) points out, the great majorityof unbounded ependency constructions are not complex:Furthermore, the Marcus parser predicts a sharpdistinction between 'short' unbounded dependencieswhich fall within the buffer and the remainder.
No suchdistinction seems to be supported by the psychologicaldata.
Finally, unbounded ependencies xhibit an identicalkind of ambiguity which can be either local or global.Therefore, we would expect a unified account of theirresolution, hut the Determinism Hypothesis offers noaccount of the resolution of global ambiguities (see eg.Briscoe, in press).ALTERNATIVE  DETERMIN IST IC  PARSERSThere are a number of alternative deterministic parsingtechniques many of which are in common use incompilers for high-level computer programminglanguages.
Berwick (1985:313f) compares the Marcusparser to the most general of these techniques, LR(1)parsing (eg.
Aho & Ullman, 1972), and argues that theMarcus parser can be seen as both an extension andrestriction of the LR(1) technique.
In fact, he argues thatit is equivalent to a bounded context parser (eg.
Aho &Ullman, 1972) which only allows literal access togrammatical symbols in the c-command omain in theleft context and to two grammatical symbols in the rightcontext.To date, little attention has been given to alternativedeterministic techniques as models of natural languageparsing in their own right, though.
One exception is thework of Shieber (1983) and Pereira (1985), who haveproposed that a simple extension of the LALR(1)technique can be used to model human natural languageparsing strategies.
The LALR(1) technique is a moreefficient variant of the LR(1) technique.
Since ourimplementation of the Shieber/Pereira model uses thelatter technique, we will refer throughout to LR(1).
Withthe grammar discussed below, the behaviour of a parserusing either technique should be identical (see Aho &Ullrnan, 1972).
In addition, Briscoe & Boguraev (1984)and Briscoe (in press) propose that a bounded context,deterministic parser in conjunction with an extendedcategorial grammar will also model these strategies.Below these two alternative approaches are comparedwith respect o unbounded ependency constructions.212The Shieber/Pereira ParserThe LR(1) technique involves extensive preprocessingof the grammar used by the parser to compute all thedistinct analysis 'paths' licensed by the grammar.
Thispreprocessing results in a parse table which willdeterministically specify the operations of a shift-reduceparser provided that the input grammar is an 'LR(1)grammar'; that is, provided that it is drawn from a subsetof the unambiguous context-free grammars (see Aho &UUman, 1972; Briscoe, in press).
The parse table encodesthe set of possible left contexts for an LR(1) grammar asa deterministic finite-state machine.
In intuitive terms, theLR(1) technique is able to resolve deterministically asubset of the possible local ambiguities which can berepresented in a context-free grammar, and none of theglobal ambiguities.
If an LR(1) parsing table isconstructed from a grammar covering a realistic,ambiguous fragment of English, the resulting non-deterministic parsing table will contain 'clashes' betweenshift and reduce operations and between different reduceoperations.
Shieber and Pereira demonstrate that ifshift/reduce clashes are resolved in favour of shifting andreduce/reduce lashes in favour of reducing with the rulecontaining the most daughters, then the parser will modelseveral psychologically plausible parsing strategies, uchas right association (eg.
Frazier, 1979).Shieber (1983) and Pereira (1985) both providegrammars with a GPSG-style (Gazdar et al, 1985)SLASH feature analysis of unbounded ependencies.
(8)presents a- grammar fragment written in the same style tomimic the GPSG account of unbounded ependencies ina context-free notation.
(8)TerminalsDet N Vtr V Aux want to wh $Non-terminalsSENT S VP VPinf VP/NP VPinf/NP NPwh NP0) SENT-> S $1) S -> NP VP2) NP->DetN3) VP -> Vtr NP4) VP/NP-> Vtr5) NP->N6) NPwh -> wh7) VP/NP -> want VPinf/NP8) VP/NP -> want VPinf9) VPinf -> to VP10) VP -> V NP11) VP -> V12) VPinf/NP-> to VP/NP13) VP/NP-> V14) S -> NPwh Aux VP15) S -> NPwh Aux NP VP/NP16) VP -> want VPinf17) VP -> want NP VPinf18) VP/NP -> want NP VPInf/NPThe LR(1) technique applied to this grammar is verysuccessful at resolving local ambiguities in theseconstructions; neither of the sentences in (9) result in anyindeterminacy during parsing, despite the potential ocalambi.guity over the attachment of the preposedconstituent.
(9)a) Who do you want Bill to succeed?b) Who do you want to succeed Bill?That is, these local ambiguities fall within the subset ofpossible local ambiguities representable in a context-freegrammar which are resolvable by this technique.
On theother hand, parsing the globally ambiguous example in(3) using the same parse table derived from this grammarresults in a reduce/reduce conflict, because the LR(1)technique cannot resolve global ambiguity (by definition).The conflict arises when the parser is in the configurationshown in Figure 1.
At this point, the parser must choosebetween reducing succeed to VP or to VP/NP.
When thisindeterminacy arises the entire sentence has been shiftedonto the parse stack.StackNPwh Aux NPWho do youInput Bufferwant to V $want to succeedFigure I - Configuration of LR(1) ParserIn general, because of the LR technique of preprocessingthe grammar and despite the unbounded nature of theambiguity, the decision point will always be at the end ofthe sentence.
Therefore, local ambiguities involving thepoint of attachment of preposed constituents will notinvolve parsing indeterminacy using this technique.
Inthis instance, the suspicion arises that the power oftechnique may be too great for a model of human parsingbecause xamples uch as those in (7) above do appear tobe garden paths.
However, normally such effects are onlypredicted when a parsing conflict is resolved incorrectlyby the rules of resolution (eg.
Shieber, 1983) and noconflict will arise parsing these examples with a grammarlike that in (8).At first sight it is surprising that these localambiguities cause no problems since an LR(1) parserappears to have less access to the right context than theMarcus parser.
However, the LR(1) parser makes greateruse of the left context and also delays many syntacticdecisions until most of the input is in the parse stack; inthe configuration in Figure 1 no clause level attachmentshave been made, despite the fact that the completesentence has been shifted into the parse stack.The reduce/reduce conflict in the globally ambiguouscase occurs much later than the position of the initialdoubtful attachment point.
Moreover, the conflict cannotbe resolved using the Shieber/Pereira esolution rules asthey stand, since both possible reductions (VP -> V;VP/NP -> V) only involve one daughter.213The Lexicat ParserThe LEXlcal-CATegorial parser is a deterministic,shift-reduce parser developed for extended categoriaigrammars which include a rule of syntactic omposition,as well as the more usual rule of application.
An earlierversion of the parser is briefly described in Briscoe &Boguraev (1984).
Briscoe (in press) provides a completedescription of Lcxicat.
Ades & Stcedman (1982),Steedman (1985) and Briscoe (in press) discusscomposition in further detail from the perspectives ofsyntax, semantics and parsing.In a categofiai grammar most syntactic information islocated in the assignment of categories to lexical items.The rules of composition and application and a lexiconwhich suffices for the fragment under consideration aregiven in (I0).
(10)Function-Argument ApplicationX YIX => YFunction-Function CompositionXIY YIZ => XIZBill : NP to : VPinf/VPyou : NP  do : S/VP/NPwho : NP succeed : VPINP, VPwant : VP/VPinflNP, VP/VPinfgrammar assigns the two analyses hown in Figure 2 Thisto the ambiguous example (3).who do you want to succeedNP S/VP/NP NP VP/VPinf VPinf/VP VPINPAppS/VPCompS/VPinfS/VP-CompCompSINP.
.
.
.
-AppSwho do you want to suc.NP S/VP/NP NP VP/VPinflNP VPinffVP VP-AppS/VP- -7- -CompS/VP inf lN?.
.
.
.
.
AppS/VPinf.
.
.
.
.
.
.
.
.
.
.
.
-CompS/VP.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
AppSFigure 2 - Analysis of Unbounded DependenciesThe grammar represents the grammatical role of thepreposed constituent by relating it directly to the verbalcategory.
The material intervening between the preposedconstituent and its point of attachment is composed intoone (partial) constituent.
Steedman (1985) provideslinguistic motivation for a very similar analysis.Lcxicat employs one push down stack for analysis andstorage of partially analysed material in thc left and fightcontext.
Parsing proceeds on the basis of a three cellwindow into the stack.
The item in the first cell (at thefight hand end) of the stack represents a one wordlookahcad into the fight context.
This cell can onlycontain the lexical entry for the next word in the input.So, in common with LR(1) parsers but unlike the Marcusparser, Lexicat is restricted to lookahead of one Icxicalitem.
The second cell contains the syntactic category orcategories associated with the current (partial) constituentunder analysis.
The third cell provides the left context forthe parse and can contain the syntactic category orcategories associated with the adjacent (partial)constituent to the left of the current constituent.
Cellsfurther down the stack contain (partial) constituentsawaiting further integration into thc analysis, but do notform part of the left context for parsing decisions.Lexicat is a (1,1)-bounded context parser because itonly has access to one set of grammatical symbols to theleft and one set of grammatical symbols to the right ofthe current constituent (see Bfiscoe, in press).
As such itis demonstrably ess powerful than the LR(1) technique,which ailows access to any aspect of the left contextwhich can be represented as a regular expression, and theMarcus parser, which allows access to grammaticalsymbols in the c-command domain in the left context andtwo (not neccssafily terminal) symbols in the rightcontext (eg.
Berwick, 1985:313f).
However, it is unclear,at present, what precisely can be concluded on the basisof these differences in the parsing techniques because ofthe differing properties of the grammatical theoriesemployed in each model.The Lexicat parser does not employ a parse table oruse parsing states to maintain information about thenature of the left context.
Rules of application andcomposition (with various resa'ictions on the directionaiityof reduction and the range of categories to which eachrule applies) are used directly by the parser to performreductions.
There are two stages to each step in theparsing algorithm; a checking phase and a reductionphase.
A rule of forward application and a rule offorward composition are used to check for the possibilityof reduction between the categories in Cell1 and Cell2.
Ifreduction is possible, Lexicat shifts the next item fromthe input buffer onto the stack.
If reduction is impossible,Lexicat moves to the reduction phase and attempts areduction between Ceil2 and Cell3 using rules ofbackward and forward application and a more constrainedrule of forward composition.
If this fails, then Lexicatshifts.
This completes one step of the parsing algorithm,so Lexicat returns to the checking phase.
This processcontinues until the parse is complete or the input is214exhausted, at which point the parser halts under the usualconditions.Quite often, a shift/reduce conflict arises during thechecking phase in which case Lexicat opts, by default, toshift.
In most constructions this resolution rule results inanalyses which conform to the parsing strategies of lateclosure and right association (eg.
Frazier, 1979).However, in unbounded ependencies it results in lateattachment of the preposed constituent.
For example, ifLexicat is in the configuration shown in Figure 3, then ashift/reduce conflict will occur in the checking phase.Stack Input Buffer3 2 1NP S/VPinflNP VPinf/VP succeedS/VPinfWho (do you want) toFigure 3 - Configuration of Lexicat ParserThe ambiguity of the partial constituent do you wantresults from the ambiguous valency of want.
Dependingon which category in Cell2 is chosen, reduction byforward composition will or will not be possible.
Bydefault, Lexicat will shift in the face of this conflict; thusthe potential for reduction by backwards applicationbetween Cell2 and Cell3 will not be considered uringthis step.
In the next configuration, the preposedconstituent will be in Cell4 outside the parser's 'window'into the stack.
Therefore, the possibility of attaching thepreposed constituent does not arise again until do youwant to succeed has been composed into one (partial)constituent.
At this point, the only possible attachmentwhich remains is as object of succeed.If the parser is analysing (9a), and Bill rather than tois the item in Celll in the configuration i  Figure 3, thenessentially the same situation obtains; there will be ashift/reduce conflict, shift will be chosen by default andthe parser will go on to build the late attachmentanalysis.
If, on the other hand, the parser is analysing(9b) and Bill is in the input buffer at the end of thesentence, the parse configuration at the moment ofindeterminacy will still be as in Figure 3 and the samedefault analysis will be chosen since the parser has noaccess to the contents of the input buffer to guide itsdecisions.
However, in this case the parse will failbecause Bill will be attached as object of succeed andWho will be left dangling.Unlike the LR(1) model, Lexicat faces parsingindeterminacy at the point when the first potential pointof attachment occurs.
The resolution rule in favour ofshifting predicts that late attachment of preposedconstituents i preferred and this prediction is compatiblewith the garden path data in (7).
The Lexicat parseremploys the grammar directly without preprocessing andtherefore conforms to Berwick & Weinberg's (1984)transparency ondition.INTERACTIVE  DETERMIN ISMMarcus' (1980) Determinism Hypothesis claims thatlocal ambiguity is resolved autonomously either bylookahead or, if this fails, by parsing strategy.
Thispredicts that strategy-violating local ambiguities whichfall outside the span of the Marcus parser's lookaheadbuffer will be garden paths.
The theory tells us littleabout the resolution of global ambiguities, but impliesthat the mechanism employed must be similar to thatused to recover from garden paths, involving interactionwith other components of the language comprehensionsystem.Using the Determinism Hypothesis, it is difficult toselect between the two models outlined above (or indeedto conclusively rule out the Marcus parser) because thediffering predictions concerning the onset ofindeterminacy in the face of identical ambiguities areunimportant.
The Determinism Hypothesis concerns onlyjudgements of psychological complexity.
Thesejudgements marginally favour the Lexicat parser, but thedata relating to garden paths with unboundeddependencies is hardly overwhelming.
Moreover, theDeterminism Hypothesis eems highly suspect in the lightof the unbounded dependency examples because itpredicts that local and global ambiguities are resolvedusing completely different mechanisms.
At the very least,this approach is unparsimonious and leaves the resolutionof global ambiguity largely unexplained.
In addition, theextreme similarity between local and global ambiguitiesin unbounded ependency constructions suggests that onemechanism for the resolution of local and globalambiguity is quite feasible.Briscoe & Boguraev (1984) and Briscoe (in press)propose a different account of the relationship betweenparsing and other components of comprehension than thatentailed by the Determinism Hypothesis, dubbed theInteractive Determinism Hypothesis (IDH).
Under thisaccount of deterministic parsing, the parser proceedsautonomously until it is faced with an indeterminacy andthen requests help from other components of thecomprehension system.
By default, the parser will apply aresolution rule or parsing strategy at such a point, but thiscan be overruled by specific non-syntactic nformation atthe onset of the indeterminacy.
The IDH implies that bothlocal and global ambiguity is resolved at its onset(relative to some parsing technique) either by strategy orinteractive blocking of the strategy.
The IDH predicts, inaddition, that garden paths will arise when a strategy-violating, local ambiguity is not resolved interactively, asa result of the absence or removal of the relevant non-syntactic information.Under the IDH, the differing predictions concerningthe onset of indeterminacy in ambiguous unboundeddependency constructions become crucial in anycomparison of the two parsing models outlined above.215The Lexicat parser makes far stronger predictions becauseindeterminacy occurs much earlier in the analysis whenless of the input is available in the left context.
SinceLexicat prefers late attachment by default, it predicts thatwhen a doubtful point of attachment is reached, which isthe correct point of attachment, non-syntactic nformationin the available left context should block the preferenceto shift and force early reduction with the preposedconstituent.
By contrast, the Shieber/Pereira parser doesnot meet an indeterminacy except in globally ambiguouscases and then not until all the input is in the leftcontext.
It therefore predicts in conjunction with the IDHthat there should be no garden paths involving unboundeddependencies and that there should be some non-syntacticinformation in the entire input which resolves the globalambiguity.
The former prediction appears to be wrong inthe light of the examples in (7) and the latter is so weakas to be trivial.It turns out that there is some evidence supporting thefar stronger predictions of the Lexicat model inconjunction with the IDH.
This evidence comes from thethe distribution of prosodic boundaries in relation to theonset of strategy-violating syntactic ambiguities.
Forexample in (11)(11) Without her, contributions to the fund would beinadequate.the comma (an orthographic ounterpart to certain typesof prosodic boundary) marks the location of anintonational or major tone group boundary which wouldnormally occur in the spoken version of this sentence.The prosodic boundary prevents the potentialmisinterpretation in which her contributions is reduced asone NP.
In unbounded ependency constructions, Danly(reported in Cooper & Paecia-Cooper, 1980:159t3 hasdemonstrated that the final syllable of the verb preccedinga correct attachment point is lengthened relative to anenvironment without a potential attachment point, or witha potential but incorrect one.
Syllabic lengthening isindicative of a phrasal or minor tone group boundary.Paul Warren and the author have since tested Danly'sresult by acoustically analysing ten readers' productionsof four examples containing doubtful but correct earlypoints of attachment and four similar examples withdoubtful and incorrect early attachment points.
The resultstend to confirm the original finding since lengthening wasfound consistendy (although the measurements did notachieve statistical significance; see Briscoe, in press).
Afinal piece of evidence that lengthening occurs before acorrect point of attachment comes from the acceptabilityof contraction i  (12a), but not in (12b).
(12)a) Who do you warma succeedb) *Who do you wanna succeed BillContraction forces late attachment of Who in a), but b) isunacceptable because the only possible interpretationinvolves attachment 'into' the contracted form.
Fodor(1979:277n17) notes that it is only the occurrence ofcontraction which appears to provide determinateinformation about the correct analysis and that, sincecontraction is optional, this information cannot be reliedon.
However, metrical phonologists (eg.
Nespor & Vogel,1986) argue that such rules arc not blocked syntacticallyby the presence of the trace/gap, but by an interveningprosodic boundary and that this explains the coincidenceof other phonetic effects, such as lengthening, at pointswhere contraction is blocked (Cooper & Paccia-Cooper,1980:Ch10).
In other words, contraction is the tip of a farmore systematic prosodic iceberg which does reliably cuethe presence of a correct attachment point.When Lcxicat reaches a potential point of attachment,it is faced with a shift/reduce ambiguity.
By default,Lexicat prefers to shift, but this strategy can be blockedby a prosodic boundary intervening between the verb anditem about to be shifted into the parse stack.
Therefore,the parser opts for early attachment of the preposedconstituent.
In terms of Lexicat's operation, the prosodicboundary in the unbounded dependency constructionplays the same role as thc prosodic boundary in (II);they both block the shift operation.
By contrast, in theShieber/Pcrcira parser it is difficult to see how a prosodicboundary in unbounded dependencies could be used toselect one of two possible reductions, whilst in anexample like (11) it would need to force the parser toshift rather than reduce.
In addition, the relevant non-syntactic information occurs at the onset of theindeterminacy for the Lexicat model but well before thispoint for the Shicber/Pcreira model.
This corroborates thefar stronger prediction made by Lcxicat, and also makesthe mechanism of interaction for this model simpler (secBriscoc, in press).Finally, we should note that in the garden paths in (7)it is intuitively clear that examples b) and c) would bespoken with prosodic boundaries at the correct attachmentpoint, and probably written with commas otherwise.Example a) on the other hand, is more subtle, but theexperimental results reported above suggest that wantwould be lengthened in this context signalling the earlyattachment point.
Thus, the IDH's prediction that gardenpaths are the result of the removal or distortion of non-syntactic information which functions to prevent theparser's default analysis in the face of indeterminacy iscorroborated.CONCLUSIONThe paper has presented two approaches to thedeterministic analysis of unbounded ependencies.
TheLR(1) technique is capable of resolving the type of localambiguities which appear to occur in these constructions,suggesting that Church and Johnson-Laird were wrong toreject deterministic parsing on the basis of this data.However, we have argued that the Lexicat parserprovides a better psychological model of the parsing ofunbounded ependencies because a) it predicts the gardenpath data and b), in conjunction with the IDH, it predictsthe apparent distribution Of prosodic boundaries in theseconstructions more successfully, and c) it provides aunified account of the resolution of local and global216ambiguities, and d) it is a simpler model of deterministcparsing which does not require preprocessing thegrammar or maintaining state information concerning theleft context?REFERENCESAdes, A.
& Steedman, M. (1982).
On the order of words.Linguistics & Philosophy, 4 517-558.Aho, A.
& Ullman, J.
(1972).
The Theory of Parsing,Translating and Compiling.
Vol.
I, Englewood Cliffs, NJ:Prentice-Hall.Berwick, R. (1985).
The Acquisition of SyntacticKnowledge.
Cambridge, Mass.
: MIT Press.Berwick, R. & Weinberg, A.
(1984).
The GrammaticalBasis of Linguistic Performance.
Cambridge, Mass.
: MITPress.Briscoe, E. (In press).
Modelling Human SpeechComprehension; A Computational Approach.
Chichester,UK: Ellis Horwood,Briscoe, E. & Boguraev, B.
(1984).
Control structuresand theories of interaction in speech understandingsystems.
In Proc.
of Coling84, Stanford, Ca, pp.
259-266.Chomsky, N. (1981).
Lectures on Government andBinding?
Dordrecht, Holland: Foris.Church, K. (1980).
On Memory Limitations in NaturalLanguage Processing?
Bloomington, Ind.
: IndianaUniversity Linguistics Club.Cooper, W. & Paccia-Cooper, J.
(1980).
Syntax &Speech.
Cambridge, Mass.
: Harvard University Press.Fodor, J.D.
(1979).
Superstrategy.
In Walker, E. &Cooper, W.
(eds.)
Sentence Processing., Hillsdale, NJ:Lawrence Erlbaum.Fodor, J.D.
(1985)?
Deterministic parsing and subjacency.Language and Cognitive Processes, 1.1, 3-42.Frazier, L. (1979).
On Comprehending Sentences:Syntactic Parsing Strategies.
Bloomington, Ind.
: IndianaUniversity Linguistics Club.Gazdar, G., Klein, E., Pullum, G., & Sag, I.
(1985).Generalized Phrase Structure Grammar.
Oxford, UK:Blackwell.Johnson-Laird, P. (1983).
Mental Models.
Cambridge,UK: CUP.Marcus, M. (1980)?
A Theory of Syntactic Recognition forNatural Language.
Cambridge, Mass.
: MIT Press.Nespor, M. & Vogel, I.
(1986).
Prosodic Phonology.Dordrecht, Holland: Foris.Pereira, F. (1985).
A new characterisation of attachmentpreferences?
In Dowty, D., Karttunen, L., & Zwicky, A.(eds.)
Natural Language Parsing.
Cambridge, UK: CUP.Shieber, S. (1983)?
Sentence disambiguation by a shift-reduce parsing technique.
In Proc.
of 21st ACL,Cambridge, Mass., pp.
113-118.Steedman, M. (1985).
Dependency and coordination inthe grammar of Dutch and English.
Language 55, 523-68.217
