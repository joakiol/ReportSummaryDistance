TTP:  A FAST AND ROBUST PARSER FOR NATURAL LANGUAGETOMEK STRZALKOWSKICourant Institute of Mathematical SciencesNew York University715 Broadway, rm 704New York, NY 10003tomek@cs.nyu.eduABSTRACTIn this paper we describe TI~, a fast and robustnatural language parser which can analyze written textand generate regularized parse structures for sentencesand phrases at the speed of approximately 0.5sec/sentence, or 44 word per second.
The parser isbased on a wide coverage grammar for English,developed by the New York University's LinguisticString Project, and it uses the machine-readable ver-sion of the Oxford Advanced lw~arner's Dictionary as asource of its basic vocabulary.
The parser operates onstochastically tagged text, and contains a powerfulskip-and-fit recovery mechanism that allows it to dealwith extra-grammatical input and to operate effec-tively under a severe time pressure.
Empirical experi-ments, testing parser's peed and accuracy, were per-formed on several collections: a collection of technicalabstracts (CACM-3204), a corpus of news messages(MUC-3), a selection from ACM Computer Librarydatabase, and a collection of Wall Street Journal arti-cles, approximately 50 million words in total.1.
INTRODUCTIONRecently, there has been a growing demand forfast and reliable natural language processing tools,capable of performing reasonably accurate syntacticanalysis of large volumes of text within an acceptabletime.
A full sentential parser that produces completemmlysis of input, may be considered reasonably fast ifthe average parsing time per sentence falls anywherebetween 2 and 10 seconds.
A large volume of text,perhaps a gigabyte or more, would contain as many as7 million sentences.
At the speed of say, 6sec/sentence, this much text would require well over ayear to parse.
While 7 million sentences i a lot of text,this much may easily he contained in a fair-sized textdatabase.
Therefore, the parsing speed would have tobe increased by at least a factor of 10 to make such atask manageable.In this paper we describe a fast and robustnatural anguage parser that can analyze written textand generate regularized parse structures at a speed ofbelow 1 second per sentence.
In the experiments con-ducted on variety of natural langauge texts, includingtechnical prose, news messages, and newspaper arti-cles, the average parsing time varied between 0.4sec/sentence and 0.7 see/sentence, or between 1600and 2600 words per minute, as we tried to find anacceptable compromise between parser's speed andprecision.lIt has long been assumed that in order to gainspeed, one may have to trade in some of the purser'saccuracy.
For example, we may have to settle for par-tial parsing that would recognize only selected gram-matical structures (e.g.
noun phrases; Ruge et al,1991), or would avoid making difficult decisions (e.g.pp-attachment; Hindle, 1983).
Much of the overheadand inefficiency comes from the fact that the lexicaland structural mbiguity of natmal anguage input canonly be dealt with using limited context informationavailable to the parser.
Partial parsing techniques havebeen used with a considerable success in processinglarge volumes of text, for example AT&T's Fidditch(Hindle and Rooth, 1991) parsed 13 million words ofAssociated Press news messages, while MIT's parser(de Marcken, 1990) was used to process the 1 millionword Lancaster/Oslo/Bergen (LOB) corpus.
In bothcases, the parsers were designed to do partial process-ing only, that is, they would never attempt a completeanalysis of certain constructions, uch as the attach-ment of pp-adjuncts, ubordinate clauses, or coordina-tions.
This kind of partial analysis may be sufficient insome applications because of a relatively high preci-sion of identifying correct syntactic dependencies.
2However, the ratio at which these dependencies areidentified (that is, the recall level) isn't sufficientlyhigh due to the inherently partial character of the pars-ing process.
The low recall means that many of theimportant dependencies are lost in parsing, andt These results were obtained on a 21 MIPS SparcStafionELC.
The experiments were performed within an information re-trieval system so that he final recall and precision statistics wereused to rnealurc effectiwmess of the panmr.a Hindle and Rooth (1991) and Church and Hanks (1990) usedpartial parses generated byFidditch to study word ~urr t .nc?
pat-terns m syntactic contexts.ACRES DE COLING-92, NANTES, 23-28 AOr~ 1992 1 9 8 PROC.
OF COL1NG-92.
NANTES, AOO.
23-28, 1992therelore partial parsing may not be suitable in appli-cations such as information extraction or documentretrieval.The alternative is to create a parser that wouldattempt o produce a complete parse, and would resortto partial or approx im~ analysis only under excep-tional conditions uch as an extra-grammatical input ora severe time pressure.
Encountering a constructionthat it couldn't  handle, the parser would first try to pro-duec an approxinmte analysis of the difficult fragment,and then resume normal processing for the rest of theinput.
The outcome is a kind of "fitted" parse,reflecting a compromise between the actual input andgrammar-encoded preferences (imposed, mainly, inrule order ing))2.
SKIP-ANI) -F IT  RECOVERY IN PARSINGA robust parser must deal efficiently withdifficult input, whether it is an exUa-gmmmaticalstring, or a string whose complete analysis could be.considered too costly.
Frequently, these two situationsam not distinguishable, stmcially for long and com-plex sentences found iu free running text.
The parsermust be able to analyze such strings quickly and pro-duec at least partiM stractures, imposhlg preferenceswhen necessary, and even removing or inserting smallinput fragments, if the data-driven processing falters.For example, in the following sentence,The method is illustrated by the automatic on-struction of both recursive and iterafive programsoperating on natural numbers, lists, and tree.s, htorder to construct a program satisfying certainspecifications a theorem induced by thosespecifu:ations i proved, and the desired programis extracted from the ptooLthe italicized part is likely to cause additional compli-cations in parsing this lengthy string, and the parsermay be better off ignoring the fragment altogether.
Todo so successfully, the parser must close the consti-tuent which is being culrenfly parsed, an(l lYossibly afew of its parent constituents, removing correspumlingproductions from further consideration, until anappropriate production is rcactivatexl, The parser thenjumps over the iutervening inatedal .so as to re.startprocessing of the remainder of the sentence usiag ritenewly reactivated production.
In the example at hand,suppose that the parser has just read the wordspecifications and is looking at the following article a.Rather than continuing at the present level, the parserreduces the phrase a program satiyfying certainThe idea of parse "fitting" was partly ialspired by the UIMparser (Jen~en et al, 1983), as well as by the sumdard error mcovelytechniques used in shift-reduce parsiug.specifications to NP, and then traces further reduc-tions: SI --) to V NP; SA -~ SI; S .--) NP V NP SA, untilproduction S --* S and S is reached.
4 Subsequently, theparser skips input to find and, then resumes normalprocessing.As may be expected, this kind of  action involvesa great deal of indeterminacy which, in case of  naturallanguage strings, is compounded by the high degree oflexical ambiguity.
If the purpose of  this skip-and-fittechnique is to get the purser smoothly through eventhe most complex strings, the amount of additionalbacktracking caused by the lexical level ambiguity kscertain to defeat it.
Without lexical disambigaation ofinput, the purser's performance will deteriorate, evenif the .skipping is limited only to certain types of  adver-bial adjuncts.
The most common cases of  lexical ambi-guity are tho~ of a phwal noun (nns) vs. a singularverb (vbz), a singular noun (nn) vs. a plmal orinfinitive verb (vbp,vb), and a past tense verb (vbd) vs.a past participle (vbn), as illusWatod in the followingexarnple.The notation used (vbn or vl~l?)
explicitly asse.ci-ates (nns or vbz?)
a data structure (vb or nn)shared (vbn or vbd?)
by concun-ent processes (nn.,~or vbz?)
wiflt operatimLs defirmd (vbn or vbd?)
cutit.3.
PART OF  SPEECH TAGGEROue way of dealing with lexical ambiguity is touse a tagger to preproccss the input marking eachwurti with a tags that indicates its syntactic ategoriza.-tion: a part of speech with selected morphologicalfeatures uch as nunther, tense, mode, case and degree.The following are tagged sentcoces from the CACM-3204 collection: sThe(dr) papei'(nn) pre~nts(vbz) a(dt)proposal(on) lor(/n) stmctured(vbn)representation(nn) of(in) multipmgranuning(vbg)in(in) a(dt) high(jj) level(tin) language(nn) .
(per)The(tit) notation(nn) used(vbn) explicitly(rb)associates(vbz) ~dt) data0m.v ) structme(nn)shared(vbn) by(in) concmrent(/j) prc~esses(nns)with(in) t)peratit)ns(mJs) defined(vbn) on(in)it(pp) .
(per)The tags are underst(xxl as follows: (It - determiner, nn- singular 1~oan, nns - plural noun, in - preposition, jjadjective, vbz - verb in present tense third person"lhe decision to force ?
reducti(m rather than to back upco~ld be triggered by various means.
In clte of TTP parser, i t  iJ al-ways  induced by the thne-citt lignal.Tagged u~ing the 35-tag Penn 'ft,zebank Tagset cmmed at theUniversity of Pemtsylwmia.Acq~.s DE COLING-92, NA~'I~, 23?28 Ao(rr 1992 1 9 9 PROC.
OF COLlNG-92, NANrF.s, AUo.
23-28, 1992singular, to - particle "to", vbg - present participle, vim- past participle, vbd - past tense verb, vb - infinitiveverb, cc - coordinate conjunction.Tagging of the input text substantially reducesthe search space of a top-down parser since it resolvesmost of the lexical level ambiguities.
In the examplesahove, tagging of  presents as "vbz" in the first sen-tence cuts off  a potentially long and cosily "gardenpath" with presents as a plural noun followed by aheadless relative clause starting with (that) a proposal....
In the second sentence, tagging resolves ambiguityof used (vim vs. vbd), and associates (vbz vs. nns).Perhaps more imlxmantly, elimination of word-levellexical ambiguity allows the parser to make projectionabout the input which is yet to be parsed, using a sim-ple lookabead; in particular, phrase boundaries can bedetermined with a degree of confidence (Church,1988).
This latter property is critical for implementingskip-and-fit recovery technique outlined in the previ-ous section.Tagging of input also helps to reduce thenumber of  parse structures that can be assigned to asentence, decreases the demand for consulting of thedictionary, and simplifies dealing with unknownwords.
Since every item in the sentence is assigned atag, so are the words for which we have no entry in thelexicon.
Many of these words will be tagged as "np"(proper noun), however, the surrounding tags mayforce other selections.
In the following example,chinese, which does not appear in the dictionary, istagged as "j.j":~this(dO papca'(nn) dates(vbz) back(rb) the(d 0genesis(nn) of(in) binary(j/) conception(nn)circa(/n) 5000(cd) years(nns) ago(rb) ,(corn)as(rb) derived(vbn) by(m) the(d 0 chinese(if)ancients(nns) .
(per)We use a stochastic tagger to process the inputtext prior to parsing.
The tagger is based upon a bi-gram model; it selects most likely tag for a word givenco-occurrence probabilities computed from a smalltraining SgL 74.
PARSING wITH TTP  PARSERTTP (Tagged Text Parser) is a top down Englishparser specifically designed for fast, reliable process-ing of large amounts of text.6 We use the machine wadable version of the Oxford Ad-vanced Learner's Dictionary (OALD).7 The program, suppfiod to us by Bolt Benmck and Newman,openttes intwo almmative modes, either telocting ?
single most like-ly tag for each word (best-tag option, the one we use ?t prcaenO, orsupplying t slion tanked list of alternatives (Mercer et al, 1991).TTP is based on the Linguistic String Grammardeveloped by Sager (1981).
Written in Quintus Pro-log, the parser currently encompasses more than 400grammar productions,  T IP  produces a regularizedrepresentation f each lmrsed sentence that reflects thesentence's logical structure.
This representation maydiffer considerably from a standard Imrse tree, in thatthe constituents get moved around (e.g., de.passivization, de--dativization), and the phrases areorganized recursively around their head elements.
Animportant novel feature of T IP  parser is that it isequipped with a time-out mechanism that allows forfast closing of more difficult sub-constituents after apreset amount of time has elapsed without producing aparse.
Although a complete analysis is attempted foreach sentence, the parser may occasionally ignorefragments of input to resume "normal" processing afterskipping a few words.
These fragments are latexanalyzed separately and attached as incomplete consti-tuents to the main parse tree.As the parsing ixoceeds, each sentence receivesa new slot of time during which its parse is to bereturned.
The amount of time allotted to any particularsentence can be regulated to obtain an acceptablecompromise between parser's peed and precision.
Inour experiments we found that 0.5 see/sentence timeslot was appropriate for the CACM abstracts, while0.7 see/sentence was more appropriate for generallylonger sentences in MUC-3 articles.
9 The actual engthof the time interval allotted to any one sentence maydepend on this sentence's length in words, althoughthis dependency need not be linear.
Such adjustmentswill have only limited impact on the parser's speed,but they may affect the quality of produced parse trees.Unfortunately, there is no obvious way to evaluatequality of parsing except by using its results to attainsome measurable nds.
We used the parsed CACMcollection to generate domain-specific word correla-tions for query processing in an information retrievalsystem, and the results were satisfactory.
For otherapplications, such as information extraction and deepunderstanding, a more accurate analysis may berequired, m* See (Strzalkowski, 1990) for Prolog implementation details.Giving the parser more time per sentence doesn't a lwaysmean that ?
belmr (more accurate) parse will be obtained.
For com-plex or extra-grammatical structures we are l ike ly  to be better o(f ifwe do not allow the parser wander around for too long: the moltlikely inteq~mtation of an unexpected input is probably the one gcn-cnlted early (the grammar rule ordering en forces ome preferences).Jo A qualitative method for par~cr evaluation has he~a pro-\[me.ed in (ihrrison et al, 1990, and it may be used to mike ?
rd?-tire comtxtrison f purser's accuracy.
What is not dear is how ?oeu-ate a par~er needs to be for may particular pptic.iticct.ACTES DE COLING-92, NANTES, 23-28 AOt3T 1992 2 0 0 PROC.
OF COLING-92, NANTES, AUG. 23-28, 1992Initially, a full analysis of each sentence isattempted.
If a parse is not returned before the allottedtime elapses, the parser enters the time-out mode.From this point on, the parser is permitted to skip por-tions of input to reach a starter terminal for the nextconstituent tobe parsed, and closing the currently opeaone (or ones) with whatever partial representation hasbeen generated thus far.
The result is an approximatepartial parse, which shows the overall structure of thesentence, from which some of the constituents may bemissing.
The fragments kipped in the first pass arenot thrown out, instead they are analyzed by a simplephrasal post-processor that looks for noun phrases andrelative clauses and then attaches the recoveredmaterial to the main parse structure.The time-out mechanism is implemented using astraightforward parameter passing and is at presentlimited to only a sub~et of nonterminals used by thegrammar.
Suppose that X is such a nonterminal, andthat it appears on the right-hand side of a production S---> X Y Z.
The set of "starters" is computed for Y,which consists of the word tags that can occur as theleft-most constituent of Y.
This set is passed as aparameter while the parser attempts to recognize X inthe input.
If X is recognized successfully within apreset ime, then the parser proceeds to parse a Y, andnothing else happens.
On the other hand, if the parsercannot determine whether there is an X in the input ornot, that is, it neither succeeds nor fails in parsing Xbefore being timed out, the unfinished X constituent isclosed with a partial ~rse, and the parser is restartedat the closest element from the sta~ers et for Y thatcan be found in the remainder of the input.
If Yrewrites to an empty string, the starters for Z to theright of Y are added to the starters for Y and both setsare passed as a parameter to X.
As an example con-sider the following clauses in the T IP  parser: ~1sentence(P) : -  assert ion(\[ \ ] ,P) .assert ion (SR, P) : -c lause(SR,P l ) , s  coord(SR,  P I ,P ) .c lause  (SR, P) : -sa ( \[pdt, dr, cd, pp, ppS, J j, Jjr,j Js, nn, nns, np, nps\] ,PAl) ,subject ( \[vbd, vbz, vbp\], Tail, P 1 ),verbphrase (SR, Tail, PI, PAl, P) ,subtai l  (Tail) .thats  (SR, P) :-that, assert ion (SR, P) .In the clause production above, a (finite) clausen The clauses arc slightly simplified, and some arguments areremoved for expository reasons.rewrites into an (optional) sentence adjunct (SA), asubject, a verbphrase and subject's right adjunct(SUBTAIL, also optional).
With the exception of sub-tail, each predicate has a parameter that specifies thelist of "starter" tags for restarting the parser, should theevaluation of this predicate xceed the allotted portionof time.
Thus, in case sa is aborted before its evalua-tion is complete, the parser will jump over some ele-menUs of the unparsed portion of the input looking fora word that could begin a subject phrase (either a pre-determiner, a determiner, a count word, a pronoun, anadjective, a noun, or a proper name).
Likewise, whensubject is timed out, the parser will restart withverbphrase at either vbz, vbd or vbp (finite forms of averb).
Note that if verbphrase is timed out, then subtailwill be ignored, both verbphrase and clause will beclosed, and the parser will restart at an element of setSR passed down to clause from assertion.
Note alsothat in the top-level production for a sentence the star-ter set for assertion is initialized to be empty: if thefailure occurs at this level, no continuation is possible.When a non-terminal is timed out and the parserjumps over a non-zero length fragment of input, it isassumed that the skipped part was some sub-constituent of the closed non-terminal.
Accordingly, aplace holder is left in the parse structure under thenode dominated by this non-terminal, which will belater filled by some nominal material recovered fromthe fragment.
The examples given in the Appendixshow approximate parse structures generated by TIP.There are a few caveats in the skip-and-fit pars-ing strategy just outlined which warrant further expla-nation.
In particular, the following problems must beresolved to assure parser's effectiveness: how to selectstarter tags for non-terminals, how to select non-terminals at which to place the starter tags, and finallyhow to select non-terminals at which input skippingcall occur.Obviotlsly some tags are mote likely to occur atthe left-most position of a constituent than others.~ l y ,  a subject ~ can start with u wordtagged with any element from the following fist: Ixlt,dt, cd, ji, jjr, jjs, pp, ppS, nn, nns, np, nps, vbg, vbo, rb,in} 2 In practice, however, we may select only a subsetof these, as shown in the clause production above.Although we now risk missing the left-hand boundaryof subject p~rases in some sentences, while skippingan adjunct o their left, most cases are still covered andthe chances of making a serious misinterpretation fu Thit list it .ot comphac.
In addition to the tal~ explthledbefore: pdt - \[n~de~trniner, jjt - compamtlve *djcctiv?, j~ - mpcda-tire ~.ieO~c, pp - pronoun, ppS - s~nitiv?, rlp npl - p,x~l,er noun.
r'o- ~verb.ACTES DI~; COLING-92.
NANTES.
23-28 nor\]r 1992 2 0 l PROC.
OF COLING-92.
NANTES.
AUG. 23-28, 1992input are significantly lower.We also need to decide on how input skipping isto be done.
In a most straightforward design, when anonterminal X is timed-out, the parser would skipinput until it has reached a starter element of a nonter-minal Y adjacent to X from the right, according to thetop-down predictions, t3 On the other hand, certainadjunct phrases may be of little interest, possiblybecause of their typically low information contents,and we may choose to ignore them altogether.
There-fore, if X is timed out, and Y is a low contents adjunctphrase, we can make the parser to jump fight to thenext nonterminal Z.
In the clause production discussedbefore, subtail is skipped over if verbphrase is timedouL 14Finally, it is not an entirely trivial task to selectnon-terminals at which the input skipping can occur.
Ifwrong non-terminals are chosen the parser may gen-erate rather uninteresting structures that would be nextto useless, or it may become trapped in inadvertentlycreated dead ends, hopelessly trying to fit the parse.Consider, for example, the following sentence, takenfrom MUC-3 corpus of news messages:HONDURAN NATIONAL POLICE ON MON-DAY PRESENTED TO THE PRESS HON-DURAN JUAN BAUTISTA NUNEZ AMADORAND NICARAGUAN LUIS FERNANDO OR-DON\[~ REYES, WHO TOLD REPORTERSTHAT COMMANDER AURELIANO WAS AS-SASSINATED ON ORDERS FROM JOSE DEJESUS PENA, THE NICARAGUAN EMBASSYCHIEF OF SECURITY.After reaching the verb PRESENTED, the parser con-salts the lexicon and finds that one of the possible sub-categorizations of this verb is \[pun,to\], that is, itsobject suing can be a prepositional phrase with 'to'followed by a noun phrase.
The parser thus begins tolook for a prepositional phrase starting at "TO THEPRESS ...", but unfortunately misses the end of thephrase at PRESS (the following word is tagged as anoun), and continues until reaching the end of sen-tence.
At this point it realizes that it went too far (thereis no noun phrase left), and starts backing up.
Beforethe parser has a chance to back up to the word PRESSand correct the early mistake, however, the time-outmode is turned on, and instead of abandoning thecurrent analysis, the parser now tries hard to fix it byskipping varying portions of input.
This may take aconsiderable amount ime if the skip points are badlyi~ Note that he top-down predictions are crucial for the skip-ping parser, wheahcr the paner's processing is top-down or bouem-up.t4 :mbta//it the remainder of a discontinued subject phrase.placed.
On the other hand, we wouldn't like to allowan easy exit by accepting an empty noun phrase at theend of the sentenceI \]5One of the essential properties of  the input skip-ping mechanism is its flexibility to jump overvarying-size chunks of the input sUing.
The goal is tofit the input with a closest matching parse structurewhile leaving the minimum number of words unac-counted for.
In T IP ,  the skipping mechanism is imple-mented by adding extra productions for selected non-terminals, and these are always tried fast whenever thenonterminal is to be expanded.
We illustrate this withrn productions covering fight adjuncts to a noun.rn (SR, P) :-t imed out, !,sk ip  (SR), s to re  (P) .rn(_, \[\]) : -la  ( \[ \[pdt, dt, vbz, vbp, vbd,rod, eom, ha ,  rmr \ ]  \] ) ,\+ is  ( \[ \[C0~\] , \ [wdt ,wp,wps\ ]  \] ) .rn(SR,P) :- rnI(SR, P).In the rn predicate, SR is the list of starter tags and P isthe parse tree fragment.
The first production checks ifthe time-out mode has already been entered, in whichcase the input is skipped until a starter tag is found,while the skipped words are stored into P to beanalyzed later in the purser's econd pass.
Note that inthis case all other rn productions are cut off; however,should the first skip-and-fit attempt fail to lead to asuccessful parse, backtracking may eventually forcepredicate skip(SR) to evaluate again and make a longerleap.
In a top-down left to right parser, each inputskipping location becomes potentially a multiple buck-tracking point which needs to be controlled in order toavoid a combinatorial explosion of possibilities.
Thisis accomplished by supplementing top-down predic-tions with bottom-up, data-driven fragmentation ofinput, and a limited lookahead.
For example, in thesecond of the rn productions above, a right adjunct o anoun can be considered empty if the item followingthe noun is either a period, a semicolon, a comma, or aword tagged as pdt, dt, vbz, vbp, vbd, or md, but not acomma followed by a relative pronoun.~6,2 In the present implementation, when the skipping mode isentered, it will stay on for the balance of the first pass in parsing ofthe current sentence.
"\[~his way, o~?
skip-and-fit a tempt may lead toanc4her before any backtracking is considered.
An altemafive is todo time-out on a nonterminal bynonterminal basis, that is, to timeout processing ofselected nonterminals only and then resume r gularparsing, qhis design leads to  a far more complex implementation andsomewhat inferior performance, but it might be worth comic~ring inthe fumre.t6 md - modal veto; vbp - plural verb; wdt, wp, wps - ttladvepronouns.ACq'ES DE COLING-92, NANTES, 23-28 AOt3T 1992 2 0 2 PROC.
OF COLING-92, NANTES, AUG. 23-28, 19925.
ROBUSTNESST IP  is a robust parser and it will process nearlyevery sentence or phrase, provided the latter is reason-ably correctly tagged.
17 The lmrser robustness isfurther increased by allowing for a gradual degrada-tion of its performance rather than an outright failurein the face of an unexpected input.
Each sentence orphrase is attempted to be analyzed in up to four ways:(1) as a sentence, (2) as a noun phrase or a prepositionphrase with a right adjunct(s), (3) as a gemndiveclause, and if all these fail, (4) as a series of simplenoun phrases, with each of these attempts allotted afresh time slice) s The purpose of this extension is toaccommodate some infrequent but still important con-strnctions, uch as dries, itemizations, and lists.6.
DISCUSSIONIn this paper we described TIP,  a fast androbust parser for natural language.
In the experimentsconducted with various text collections of more that 50million words the average parsing speed recorded wasapprox.
0.5 sec/sentence.
For example, the total timespent on parsing the CACM-3204 collection was lessthan 1.5 hours.
In other words, T IP  can process100,000 words in approximately 45 minutes, and itcould parse a gigabyte of text (approx.
150 millionwords) in about 40 days, on a 21 MIPS computer.The parser is based on a wide coverage grammarfor English, and it contains a powerful skip-and-fitrecovery mechanism that allows it to deal with unex-pected input and to perform effectively under a severetime pressure.
Prior to parsing, the input text is taggedwith a stochastic tagger that assigns part-of-speechlabels to every word, thus resolving lexical evel ambi-guity.T IP  has been used as front-end of a naturallanguage processing component to a traditionaldocument-based information retrieval system (Strzal-kowski and Vauthey, 1992).
The parse structures werefurther analyzed to extract word and phrase depen-dency relations which were in turn used as input tovarious tatistical and indexing processes.
The resultsobtained were generally satisfactory: an improvementin both recall and precision of document retrieval havebeen observed.
At present, we are also conductingexperiments with large corpora of technical computer,science texts in order to extract domain-specific,7 Some sentences (1 in 5000) mmy still fail to parse if taggingerrors are.
compotmded in In unexpected way.ts Although parsing of some sentences may now approachfour drnes the allotted time limit, we noted that he average parsingtinm per sentence at0.745 sec.
is only slighdy above the time-outlimit.conceptual taxonomies for an even greater gain inretrieval effectiveness.7.
ACKNOWLEDGEMENTSWe wish to thank Ralph Weischedel and HeidiFox of BBN for assisting in the use of the part ofspeech tagger.
ACM has generously provided us withthe Computer Library text database.
This paper isbased upon work supported by the Defense AdvancedResearch Project Agency under Contract N00014-90-J-1851 from the Office of Naval Research, theNational Science Foundation under Grant IRI-89-02304, and by the Canadian Institute for Robotics andIntelligent Systems (IRIS).8.
REFERENCESChurch, Kenneth Ward.
1988.
"A  Stochastic PartsProgram and Noun Phrase Parser for UnrestrictedText."
Proceedings of the Second Conferenceon Applied Natural Language Processing, pp.136-143.Church, Kenneth Ward and Patrick Hanks.
1990.
"Word association orms, mutual information,and lexicography."
Computational Linguistics,16(1), MIT Press, pp.
22-29.De Marcken, Carl G. 1990.
"Parsing the LOBcorpus."
Proceedings of the 28th Meeting of theACL, Pittsburgh, PA. pp.
243-251.Harrison, Philip, et al 1991.
"Evaluating Syntax Per-formance of Parser/Grammars of English.
"Natural Language Processing Systems EvaluatiouWorkshop, Berkeley, CA.
pp.
71-78.Hindle, Donald.
1983.
"User manual of Fidditch, adeterministic parser."
Naval Research Labora-tory Technical Memorandum 7590-142.Hindle, Donald and Mats Rooth.
1991.
"StructuralAmbiguity and Lexical Relations."
Proceedingsof the 29th Meeting of the ACL, Berkeley, CA.pp.
229-236.Jensen, K., G.E.
Heidorn, L.A. Miller, and Y. Ravin.1983.
"Parse fitting and prose fixing: Getting ahold of ill-formedness."
Computational Linguis-tics, 9(3.-4), pp.
147-161.Meteer, Marie, Richard Schwartz, and RalphWeischedel.
1991.
"Studies in Part of SpeechLabelling."
Proceedings of the 4th DARPASpeech and Natural Language Workshop,Morgan-Kaufman, San MateD, CA.
pp.
331-336.Ruge, Gerda, Christoph Schwarz, Amy J. Warner.1991.
"Effectiveness and Efficiency in NaturalLanguage Processing for Large Amounts ofText."
Journal of the ASIS, 42(6), pp.
450-456.Sager, Nanmi.
1981.
Natural Language InformationProcessing.
Addison-Wesley.Strzalkowski, Tomek.
1990.
"Reversible logic gram-mars for natural language parsing andACRES DE COLING-92.
NANTES, 23-28 AOI3T 1992 2 0 3 PROC.
OF COLING-92, NANTES, AUG. 23-28, 1992generation.'"
Computational Intelligence, 6(3),NRC Canada, pp.
145-171.Strzalkowski, Tomek and Barbara Vauthey.
1992.
"Information Retrieval Using Robust NaturalLanguage Processing."
Proceedings of the 30thAnnual Meeting of the ACL, Newark, Delaware,June 28 - July 2.APPENDIX: Sample parsesA few examples of non-standard output gen-erated by TTP are shown in Figures 1 to 3.
In Figure 1,"ITP has failed to find the main verb and it had to jumpover much of the last phrase such as the LR(k) gram-mars, partly due to an improper tokenization of LR(k)(note skipped nodes indicating the material ignored inthe first pass).
In Figure 2, the parser has initiallyassumed that the conjunction in the sentence has thenarrow scope, then it realized that something wentwrong but, apparently, there was no time left to backup.
Note, however, that little has been lost: a completestrncture of the second half of this sentence followingthe conjuction and is easily recovered from the parsetree (var points up to the dominating rip).
Occasion-ally, sentences may come out substantially truncated,as shown in Figure 3, where although has been mis-tagged as a preposition.SENTF~CE:The problem of determining whether an arbitrarycontext-free grammar is a member of some easilyparsed subclass of grammars uch as the LR(k)grammars i considered.APPROXIMATE PARSE:\[ \[verb,\[\] \],\[subject, \[np,\[n,problem\] ,\[t_pos,the\],\[of,\[\[verb,\[determine\]\],\[subject,anyone\],\[object,\[\[verb,\[be\]\],\[subject,\[np,\[n,grammar\],\[t_pos,an\],\[adj,\[arbitrary\]\],\[adj,\[context free J\]\]\],\[object,\[np,\[n,member\],\[t_pos,a\],\[of,\[np,\[n,subclass\],\[t_pos,some\],\[a pos_v,\[\[verb,\[parse,lady,easily\]I\],\[subject,anyone\],\[object,pro\]\]\],\[of.\[np,\[n,grammar\],\[rn wb,\[\[verb,\[such\]\].\[subject,var\]\]\]\]\]\]\]\]\]\] \],\[sub_urd,Ias,\[\[verb,\[be\] \] ,\[subject,pro\],\[object,\[np,\[n,kl,\[t_pos,the\],\[adj,\["lrC\]\]\]\]\]\]\],\[skipped,\[\[np,\[n,grammar\]\]\]\]\]\]\]\],\[skipped,\[\[is\],\[wh rel,\[\[verb,\[consider\]\],\[sabject,anyone\],\[object,var\]\]\]\]\]\].Figure 1.SENTENCE:The TX-2 computer at MIT Lincoln Laboratory was usedfor the implementation f such a system and thecharacteristics of this implementation are reported.APPROXIMATE PARSE:\[\[bc\],\[\[verb,\[usc\]\],\[subject,anyone\],\[object,\[np,\[n,compster\],\[t_pos,the\],\[adj,\[tx_2\]\]\]\],\[for,\[and,\[np,\[n,implem entation\] ,\[t._pos,the\],\[of,\[np,\[n,system\] ,\[t pos,\[such,a\]\]\]\]\],\[np,\[n,characteristics\],\[t_.pos,the\],\[o f,\[np,\[n,implementation\] ,\[t pos,this\]\]\],\[skipped,\[\[are\] ,\[w h_rel,\[\[verb,\[report\]\],\[subject,anyone\],\[object,var\]\]\]\]\]\]\]\]\],\[at,\[np,\[n,laboratory\],\[adj,\[mitl\],\[n pos,\[np,\[n,lincoln\]\]\]\]\]\].Figure 2.SENTENCE:In principle, the system can deal with any ortho-graphy, although at present i is limited to 4000Chinese characters and some mathematical symbols.APPROXIMATE pARSE:\[\[can_anx\],\[\[verb.\[deal\]\].\[suhject,\[np,\[n,system\].\[t pos,the\]\]\],\[sub_oral,\[with,\[\[verb,\[limit\]\],\[subject.anyone\],\[object, \[skipped.\[ \[np.\[n,orthography\] ,\[t pos,any\]\].\[cornS.although.at\].\[np.\[n,present\]\],\[np,\[n,it\]\],\[is\]\]\]\],\[to,\[np,\[n,character\],\[counl,\[4000\]\],\[a_pos,\[chinese\]\],\[skipped,\[\[and\],\[np,\[n,symbol\],\[t~pos,some\],\[adj,\[mathematical\]\]\]\]\]\]\]\]\]\]\],\[in,\[np,\[n,principle\]\]\]\].Figure 3.AcrEs DE COLING-92, NANTES, 23-28 hotzr 1992 2 0 4 PROC.
OF COL1NG-92, NANTES, AUG. 23-28, 1992
