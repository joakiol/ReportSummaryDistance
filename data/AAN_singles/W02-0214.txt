Topic Identification In Natural Language Dialogues UsingNeural NetworksKrista Lagus and Jukka KuusistoNeural Networks Research Centre, Helsinki University of TechnologyP.O.Box 9800, FIN-02015 HUT, Finlandkrista.lagus@hut.fiAbstractIn human?computer interaction sys-tems using natural language, therecognition of the topic from user?sutterances is an important task.
Weexamine two different perspectivesto the problem of topic analysisneeded for carrying out a success-ful dialogue.
First, we apply self-organized document maps for mod-eling the broader subject of dis-course based on the occurrence ofcontent words in the dialogue con-text.
On a Finnish corpus of 57dialogues the method is shown towork well for recognizing subjects oflonger dialogue segments, whereasfor individual utterances the sub-ject recognition history should per-haps be taken into account.
Sec-ond, we attempt to identify topicallyrelevant words in the utterancesand thus locate the old information(?topic words?)
and new information(?focus words?).
For this we define aprobabilistic model and compare dif-ferent methods for model parameterestimation on a corpus of 189 dia-logues.
Moreover, the utilization ofinformation regarding the positionof the word in the utterance is foundto improve the results.1 IntroductionThe analysis of the topic of a sentence or adocument is an important task for many nat-ural language applications.
For example, ininteractive dialogue systems that attempt tocarry out and answer requests made by cus-tomers, the response strategy employed maydepend on the topic of the request (Jokinen etal., 2002).
In large vocabulary speech recog-nition knowledge of the topic can, in general,be utilized for adjusting the language modelused (see, e.g., (Iyer and Ostendorf, 1999)).We describe two approaches to analyzingthe topical information, namely the use oftopically ordered document maps for analyz-ing the overall topic of dialogue segments, andidentification of topic and focus words in anutterance for sentence-level analysis and iden-tification of topically relevant specific infor-mation in short contexts.1.1 Document map as a topicallyordered semantic spaceThe Self-Organizing Map (Kohonen, 1982;Kohonen, 1995) is an unsupervised neuralnetwork method suitable for ordering and vi-sualization of complex data sets.
It has beenshown that very large document collectionscan be meaningfully organized onto maps thatare topically ordered: documents with similarcontent are found near each other on the map(Lin, 1992; Honkela et al, 1996; Lin, 1997;Kohonen et al, 2000).The document map can be considered toform an ordered representation of possibletopics, i.e., a topical semantic space.
Eachset of map coordinates specifies a point in thesemantic space, and additionally, correspondsto a subset of the corpus, forming a kind ofassociative topical-semantic memory.Document maps have been found useful intext mining and in improving information re-Philadelphia, July 2002, pp.
95-102.
Association for Computational Linguistics.Proceedings of the Third SIGdial Workshop on Discourse and Dialogue,trieval (Lagus, 2000).
Recent experiments in-dicate that the document maps ordered usingthe SOM algorithm can be useful in focusingthe language model to the current active vo-cabulary (Kurimo and Lagus, 2002).In this article we examine the usefulnessof document maps for analyzing the topics oftranscripts of natural spoken dialogues.
Thetopic identification from both individual ut-terances and longer segments is studied.1.2 Conceptual analysis of individualutterancesWithin a single utterance or sentence thespeaker may provide several details that spec-ify the request further or provide additionalinformation that specifies something said ear-lier.
Automatic extraction of the relevantwords and the concepts they relate to may beuseful, e.g., for a system filling out the fieldsof a database query intended to answer theuser?s request.If a small set of relevant semantic conceptscan be defined, and if the sentence structuresallowed are strictly limited, the semantic con-cept identification problem can be solved, atleast to some degree, by manually designedrule-based systems (Jokinen et al, 2002).However, if the goal is the analysis of free-form dialogues, one cannot count on hearingfull sentences.
It is therefore important to tryto formulate the task as a learning probleminto which adaptive, statistical methods canbe applied.The major challenge in adaptive languagemodeling is the complexity of the learningproblem, caused by large vocabularies andlarge amount of variation in sentence struc-tures, compared to the amount of learningdata available.
For English there already existvarious tagged and analyzed corpora.
In con-trast, for many smaller languages no taggedcorpora generally exist.
Yet the methods thatare developed for English cannot as such beapplied for many other languages, such asFinnish.In the analysis of natural language di-alogues, theories of information structure(Sgall et al, 1986; Halliday, 1985) concern thesemantic concepts and their structural prop-erties within an utterance.
Such concepts in-clude the attitudes, prior knowledge, beliefsand intentions of the speaker, as well as con-cepts identifying information that is sharedbetween the speakers.
The terms ?topic?
and?focus?
may be defined as follows: ?topic?
isthe general subject of which the user is talk-ing about, and ?focus?
refers to the specificadditional information that the user now in-troduces about the topic.
An alternative wayof describing these terms is that ?topic?
con-stitutes of the old information shared by bothdialogue participants and ?focus?
contains thenew information which is communicated re-garding the topic.A traditional way of finding the old andnew information is the ?question test?
(see(Vilkuna, 1989) about using it for Finnish).For any declarative sentence, a question iscomposed so that the sentence would be a nat-ural answer to that question.
Then the itemsof the sentence that are repeated in the ques-tion belong to the topic and the new items tothe focus.A usual approach for topic?focus identi-fication is to use parsed data.
The sen-tence, or it?s semantic or syntactic-semanticrepresentation, is divided into two segments,usually at the location of the main verb,and the words or semantical concepts inthe first segment are regarded as ?topic?words/concepts and those in the second as ?fo-cus?
words/concepts.
For example in (Meteerand Iyer, 1996), the division point is placedbefore the first strong verb, or, in the absenceof such a verb, behind the last weak verb ofthe sentence.
Similar division is also the start-ing point for the algorithm for topic?focusidentification introduced in (Hajic?ova?
et al,1995).
The initial division is then modifiedaccording to the verb?s position and meaning,the subject?s definiteness or indefiniteness andthe number, type and order of the other sen-tence constituents.In language modeling for speech recogni-tion improvements in perplexity and word er-ror rate have been observed on English cor-pora when using language models trained sep-arately for the topic and the focus part of thesentence (Meteer and Iyer, 1996; Ma et al,1998).
Identification of these concepts is likelyto be important also for sentence comprehen-sion and dialogue strategy selection.In this article we examine the application ofa number of statistical approaches for identifi-cation of these concepts.
In particular, we ap-ply the notions of topic and focus in informa-tion structure (Sgall et al, 1986) to tagging aset of natural dialogues in Finnish.
We thentry several approaches for learning to identifythe occurrences of these concepts from newdata based on the statistical properties of theold instances.2 Experiments on recognizing thedialogue topic of a dialogue turnThe ordered document map can be utilizedin the analysis of dialogue topics as follows:encode a dialogue turn, i.e., an utterance u(or an utterance combined with its recent his-tory) as a document vector.
Locate the best-matching map unit, or several such units.
Uti-lize the identities of the best units as a seman-tic representation of the topic of the u.
In ef-fect, this is a latent semantic representationof the topical content of the utterance.
Eval-uation of such a latent representation directlyamounts to asking whether the dialogue man-ager can benefit from the representation, andmust therefore be carried out by the dialoguemanager.
This direct evaluation has not yetbeen done.Instead, we have utilized the following ap-proach for evaluating the ordering of the mapsand the generalization to new, unseen dia-logues: An intermediate set of named seman-tic concepts has been defined in an attemptto approximate what is considered to be inter-esting for the dialogue manager.
The latentsemantic representation of the map is then la-beled or calibrated to reflect these named con-cepts.
In effect, each dialogue segment is cat-egorized to a prior topical category.
The or-ganized map is labeled using part of the data(?training data?
), and the remaining part isused to evaluate the map (?test data?
)1.1Note that even in this case the map is ordered inFurthermore, a statistical model for docu-ment classification can be defined on top ofthe map.
The probability model used fortopic estimation isP (Ai|S) = P (XN |S)P (Ai|XN ), (1)where Ai is the topic category, S denotes thetext transcription of the spoken sentence andXN is the set of N best map vectors used forthe classification.
We approximate the proba-bility P (XN |S) to be equal for each map vec-tor inXN .
We assume thatXN conveys all in-formation about S. The terms P (Ai|XN ) arecalculated as the relative frequencies of thetopics of the document vectors in the train-ing data that were mapped to the nodes thatcorrespond to XN .2.1 Corpus: transcripts of 57 spokendialoguesThe data used in the experiments wereFinnish dialogues, recorded from the cus-tomer service phone line of Helsinki CityTransport.
The dialogues, provided by theInteract project (Jokinen et al, 2002), hadbeen transcribed into text by a person listen-ing to the tapes.The transcribed data is extremely collo-quial.
Both the customers and the customerservice personnel use a lot of expletive words,such as ?nii?
(?so?, ?yea?)
and ?tota?
(?hum?,?er?, ?like?
), often the words appear in re-duced or otherwise non-standard forms.
Theword order does not always follow grammat-ical rules and quite frequently there is con-siderable overlap between the dialogue turns.For example, the utterance of speaker A maybe interjected by a confirmation from speakerB.
This had currently been transcribed asthree separate utterances: A1 B A2.2.2 Tagging and segmentation ofdialoguesThe data set was split into training and testdata so that the first 33 dialogues were usedfor organization and calibration of the mapan unsupervised manner, although it is applied for theclassification of new instances based on old ones.Table 1: Proportions of customer utterancesin each topic category in the data sets.Training data Test dataBeginnings 0.08 0.11Endings 0.12 0.14Timetables 0.49 0.59Tickets 0.16 0.11OOD 0.15 0.06and the 24 dialogues collected later for test-ing.A small number of broad topic categorieswere selected so that they comprehensivelyencompass the subjects of discussion occur-ring in the data.
The categories were ?timeta-bles?, ?beginnings?, ?tickets?, ?endings?, and?out of domain?.The dialogues were then manually taggedand segmented, so that each continuous dia-logue segment of several utterances that be-longed to one general topic category formeda single document.
This resulted in a total of196 segments, 115 and 81 in training and testsets, respectively.
Each segment containeddata from both the customer and the assis-tant.Of particular interest is the analysis of thetopics of individual customer utterances.
Thedata was therefore split further into utter-ances, resulting in 450 and 189 customer ut-terances in the training and test set, respec-tively.
The relative frequencies of utterancesbelonging to each topic category for bothtraining and test data are shown in Table 1.Each individual utterance was labeled withthe topic category of the segment it belongedto.2.3 Creation of the document mapThe documents, whether segments or utter-ances, were encoded as vectors using themethods described in detail in (Kohonen etal., 2000).
In short, the encoding was as fol-lows.
Stopwords (function words etc.)
andwords that appeared fewer than 2 times in thetraining data were removed.
The remainingwords were weighted using their entropy overdocument classes.
The documents were en-coded using the vector space model by Salton(Salton et al, 1975) with word weights.
Fur-thermore, sparse random projection of wasapplied to reduce the dimensionality of thedocument vectors from the original 1738 to500 (for details of the method, see, e.g., (Ko-honen et al, 2000)).In organizing the map each longer dia-logue segment was considered as a document.The use of longer segments is likely to makethe organization of the map more robust.The inclusion of the utterances by the assis-tant is particularly important given the smallamount of data?all information must be uti-lized.
The document vectors were then orga-nized on a SOM of 6?
4 = 24 units.2.4 Experiments and resultsWe carried out three tests where the lengthof dialogue segments was varied.
In eachcase, different values of N were tried.
Inthe first case, longer dialogue segments in thetraining data were used to estimate the termP (Ai|XN ) whereas recognition accuracy wascalculated on customer utterances only.
Next,individual customer utterances were used alsoin estimating the model term.
The best recog-nition accuracy in both cases were obtainedusing the value N = 3, namely 60.3% forthe first case and 65.1% for the second case.In the third case we used the longer dia-logue segments both for estimating the modeland for evaluation, to examine the effect oflonger context on the recognition accuracy.The recognition accuracy was now 87.7%, i.e.,clearly better for the longer dialogue segmentsthan for the utterances.It seems that many utterances taken out ofcontext are too short or nondescript to pro-vide reliable cues regarding the topical cat-egory.
An example of such an utterance is?Onks sinne mita?a?
muuta??
(lit.
?Is to thereanything else?
?, the intended meaning prob-ably being ?Does any other bus go there??
).In this case it is the surrounding dialogue (orperhaps the Finnish morpheme correspondingto ?to?)
that would identify the correct cate-gory, namely ?timetables?.Moreover, results on comparing a docu-ment map to Independent Component Analy-sis on the same corpus are reported in (Bing-ham et al, 2002).
The slightly higher per-centages in that paper are due to evaluatinglonger segments and to reporting the resultson the whole data set instead of a separatetest set.3 Identification of old and newinformation in utterancesWe define this task as the identification of?topic words?
and ?focus words?
from utter-ances of natural Finnish dialogues.
Thereare thus no restrictions regarding the vocabu-lary or the grammar.
By observing previous,marked instances of these concepts we try torecognize the instances in new dialogues.
Itshould be noted that this task definition dif-fers somewhat from those discussed in Sec-tion 1.2 in that we do not construct any con-ceptual representation of the utterances, nordo we segment them into a ?topic?
part anda ?focus?
part.
This choice is due to utiliz-ing natural utterances in which the sentenceborders do not always coincide with the turn-taking of the speakers?a turn may consist ofseveral sentences or a partial one (when inter-rupted by a comment from the other speaker).In other words, we try to identify the centralwords that communicate the topic and focusin an utterance.
We assume that they can ap-pear in any part of the sentence and betweenthem there may be other words that are notrelevant to the topic or focus.
Whether thesecentral words form a single topic or focus orseveral such concepts is left open.3.1 Corpus and taggingThe corpus used includes the same data asin section 2 with additional 133 dialoguescollected from the same source.
Basicallyeach dialogue turn was treated as an utter-ance, with the exception that long turns weresegmented into sentence-like segments, whichwere then considered to be utterances2.
Ut-terances consisting of only one word were re-2Non-textual cues such as silences within turnscould not be considered for segmenting because theywere not marked in the data.moved from the data.
The training data con-tained 11464 words in 1704 utterances.
Of thewords 17 % were tagged as topic, and 28 % asfocus.
The test data consisted of 11750 wordsin 1415 utterances, with 14 % tagged as topicand 25 % as focus.In tagging the topic and focus words inthe corpus, the following definitions were em-ployed: In interrogative clauses focus consistsof those words that form the exact entity thatis being asked and all the other words that de-fine the subject are tagged as belonging to thetopic.
In declarative sentences that functionas answers words that form the core of theanswer are tagged as ?focus?, and other wordsthat merely provide context for the specificanswer are tagged as ?topic?.
In other declar-ative sentences ?topics?
are words that definethe subject matter and ?focus?
is applied towords that communicate what is being saidabout the topic.
Regardless, the tagging taskwas in many cases quite difficult, and the re-sulting choice of tags often debatable.As is charasteristic of spoken language, thedata contained a noticeable percentage (35 %)of elliptic utterances, which didn?t containany topic words.
Multiple topic constructs,on the other hand, were quite rare: more thanone topic concept occurred in only 1 % of theutterances.
The pronouns were quite evenlydistributed with regard to position in the ut-terances: 32 % were in medial and 36 % infinal position3.3.2 The probabilistic modelThe probability of a word belonging to theclass topic, focus or other is modeled asP (Ti|W,S) =P (Ti|W )P (Ti|S)P (Ti), (2)where W denotes the word, S its position inan utterance, and Ti ?
{topic, focus, other}stands for the class.
The model thus assumesthat being a topic or a focus word is depen-dent on the properties of that particular wordas well as its position in the utterance.
Due3We interpreted ?medial?
to mean the middle thirdof the sentence, and ?final?
to be the last third of thesentence.to computational reasons we made the sim-plifying assumption that these two effects areindependent, i.e., P (W,S) = P (W )P (S).Maximum likelihood estimates are used forthe terms P (Ti|W ) for already seen words.Moreover, for unseen words we use the aver-age of the models of words seen only rarely(once or twice) in the training data.For the term P (Ti|S) that describes the ef-fect of the position of a word we use a softmaxmodel, namelyP (Ti|Sj) =eqi(xj)?i eqi(xj), (3)where the index j identifies the word and xjis the position of the word j.
The functionsqi are defined as simple linear functionsqi(xj) = aixj + bi (4)The parameters ai and bi are estimated fromthe training data.
For the class T3 (other),these parameters are set to a constant valueof zero.3.2.1 ML estimationWhen evaluating the rest of the model pa-rameters we use two methods, first MaximumLikelihood estimation and then Bayesian vari-ational analysis.In ML estimation the cost function is thelog likelihood of the training data D giventhe model M , i.e,lnP (D|M) = ln?wP (Ti|Sw) (5)=?w?T1q1 +?w?T2q2 +?w(?
ln(1 + eq1 + eq2)).
(6)The logarithmic term is approximated by aTaylor series of first degree and the parame-ters can then be solved as usual, by setting thepartial derivatives of lnP (D|M) to zero withregard to each parameter.
The parameters bican be solved analytically and the parametersai are solved using Newton iteration.3.2.2 Bayesian estimationThe ML estimation is known to be proneto overlearning the properties of the train-ing data.
In contrast, in the Bayesian ap-proach, also the model cost is included in thecost function and can be used to avoid over-learning.
For comparison, we thus tried alsothe Bayesian approach utilizing the softwareand methodology introduced in (Valpola etal., 2001).
The method is based on variationalanalysis and uses ensemble learning for esti-mating the model parameters.
The method-ology and the software allows for the opti-mization of the model structure with roughlylinear computational complexity without therisk of over-fitting the model.
However, inthese experiments the model structure wasnot optimized.3.2.3 Disregarding positioninformationFurthermore, to study the importance ofthe position information, we calculated theprobabilities using only ML estimates forP (T |W ), i.e., disregarding the position of theword.3.2.4 Tf?idfAs a comparison, we applied the tf?idfweighting scheme, which is commonly usedin information retrieval for weighting contentwords.
This method does not benefit from thelabeling of the training data.
For this reason,it does not differentiate between ?topic?
and?focus?
words.3.3 Experiments and resultsThe following experiment was performed us-ing each described method: For each utter-ance in the test data, n words were taggedas topic, and likewise for the focus category.Further, n was varied from 1 to 8 to producethe results depicted in Figure 1.As can be seen, the Bayesian variationalanalysis and the maximum likelihood estima-tion produce nearly identical performances.This is perhaps due to the use of very smoothmodel family, namely first-order polynomials,for taking into account the effect of the posi-tion of the word.
For this reason, overlearn-0 0.5 100.10.20.30.40.50.60.7RecallPrecisionTopicsML          Bayes       No pos.
inf.Idf         Random0 0.5 100.10.20.30.40.50.60.7RecallPrecisionFocusesFigure 1: The precision?recall curves fortopic?focus estimation.
(ML = maximumlikelihood, Bayes = Bayesian variational anal-ysis, No pos.
inf.
= without position informa-tion, Idf = tf?idf weighting, Random = theaverage precision with random selection.
)ing is not problem even for the ML estima-tion.
However, since the nearly identical re-sults were obtained using two completely dif-ferent implementations of quite similar meth-ods, this can be considered as a validationexperiment on either implementation and op-timization method.
In total, it seems that thefull statistical model designed works ratherwell especially in focus identification.When compared to the full model, disre-garding position information altoghether re-sults in inferior performance.
The differenceis statistically significant (p ?
0.05) in focusidentification for all values of n and in topicidentification for small values of n. More-over, the performance of the tf?idf schemeis clearly inferior in either task.
However, itseems that the tf?idf definition of word im-portance corresponds more closely with thedefinition of ?focus?
than that of ?topic?.4 Discussion and conclusionsWe examined two different viewpoints for thetopic identification problem in natural lan-guage understanding.
In experiments utiliz-ing document maps it was found that longerdialogue segments are reliably modeled, butespecially for short segments the history ofthe utterance must be consulted.
A perhapsmore interesting idea would be to also look atmorphological features, such as cases, and in-clude them in the encoding of the utterances.We plan to study this possibility in furtherwork.In the second viewpoint, individual utter-ances were analyzed to automatically iden-tify ?topics?
(what the user is talking about)and ?focuses?
(what is being said about thetopic).
Each word in an utterance was labeledas ?topic?, ?focus?
or ?other?.A statistical model that utilized the iden-tity of the word and its position in the ut-terance was found to be rather successful, es-pecially for identification of words belongingto the ?focus?
category.
Without the positioninformation significantly lower performancewas observed, which indicates that positioninformation is indeed relevant for the iden-tification.
In this case, the Bayesian mod-eling paradigm and the maximum likelihoodestimation produced nearly identical perfor-mance.
However, this is not the case in gen-eral, when less smooth model families and op-timization of model structure are applied.
Inthe future we plan to examine other kinds ofmodel structures for this task, perhaps inte-grating new types of information sources re-garding the words, as well.
For example, itwould be interesting to see whether the ad-dition of prosodic information would provideadditional cues to improved solving of thistask.5 AcknowledgementsWe thank Harri Valpola for his valuable ad-vice concerning the estimation of the topic-focus identification model and for the possi-bility to apply the Bayesian software packagedeveloped by his group.This work is part of the collaborative ?Inter-act?
project on natural language interaction inFinnish.ReferencesElla Bingham, Jukka Kuusisto, and Krista Lagus.2002.
Ica and som in text document analy-sis.
In The 25th ACM SIGIR Conference onResearch and Development in Information Re-trieval,August 11-15, 2002, Tampere, Finland.Submitted.Eva Hajic?ova?, Petr Sgall, and Hana Skoumalova?.1995.
An automatic procedure for topic?focus identification.
Computational Linguis-tics, 21(1):81?94.M.
A. Halliday.
1985.
Introduction to FunctionalGrammar.
Oxford University Press, Oxford,UK.Timo Honkela, Samuel Kaski, Krista Lagus, andTeuvo Kohonen.
1996.
Newsgroup explorationwith WEBSOM method and browsing inter-face.
Technical Report A32, Helsinki Universityof Technology, Laboratory of Computer and In-formation Science, Espoo, Finland.R.M.
Iyer and M. Ostendorf.
1999.
Modellinglong distance dependencies in language: Topicmixtures versus dynamic cache model.
IEEETrans.
Speech and Audio Processing, 7.Kristiina Jokinen, Antti Kerminen, MauriKaipainen, Tommi Jauhiainen, Markku Tu-runen, Jaakko Hakulinen, Jukka Kuusisto, andKrista Lagus.
2002.
Adaptive dialogue systems?
interaction with interact.
In 3rd SIGdialWorkshop on Discourse and Dialogue, July 11and 12, 2002.
To appear.Teuvo Kohonen, Samuel Kaski, Krista Lagus,Jarkko Salojrvi, Vesa Paatero, and AnttiSaarela.
2000.
Organization of a massivedocument collection.
IEEE Transactions onNeural Networks, Special Issue on Neural Net-works for Data Mining and Knowledge Discov-ery, 11(3):574?585.Teuvo Kohonen.
1982.
Analysis of a simpleself-organizing process.
Biological Cybernetics,44(2):135?140.Teuvo Kohonen.
1995.
Self-Organizing Maps.3rd, extended edition, 2001.
Springer, Berlin.Mikko Kurimo and Krista Lagus.
2002.
Anefficiently focusing large vocabulary languagemodel.
In International Conference on Arti-ficial Neural Networks, ICANN?02.
To appear.Krista Lagus.
2000.
Text mining with the WEB-SOM.
Acta Polytechnica Scandinavica, Mathe-matics and Computing Series No.
110, 54 pp.December.
D.Sc(Tech) Thesis, Helsinki Univer-sity of Technology, Finland.Xia Lin.
1992.
Visualization for the documentspace.
In Proceedings of Visualization ?92,pages 274?81, Los Alamitos, CA, USA.
Cen-ter for Comput.
Legal Res., Pace Univ., WhitePlains, NY, USA, IEEE Comput.
Soc.
Press.Xia Lin.
1997.
Map displays for information re-trieval.
Journal of the American Society forInformation Science, 48:40?54.Kristine Ma, George Zavaliagkos, and MarieMeteer.
1998.
Sub-sentence discourse modelsfor conversational speech recognition.
In Pro-ceedings of the 1998 IEEE International Con-ference on Acoustics, Speech and Signal Pro-cessing, vol.
2, Seattle, Washington, USA.Marie Meteer and Rukmini Iyer.
1996.
Model-ing conversational speech for speech recogni-tion.
In Proceedings of the Conference on Em-pirical Methods in Natural Language Process-ing, Philadelphia, PA, USA.G.
Salton, A. Wong, and C. S. Yang.
1975.
A vec-tor space model for automatic indexing.
Com-munications of the ACM, 18(11):613?620.Petr Sgall, Eva Hajic?ova?, and Jarmila Panevova?.1986.
The Meaning of the Sentence in Its Se-mantic and Pragmatic Aspects.
D. Reidel Pub-lishing Company, Dordrecht, Holland.Harri Valpola, Tapani Raiko, and Juha Karhunen.2001.
Building blocks for hierarchical latentvariable models.
In In Proceedings of the 3rdInternational Conference on Independent Com-ponent Analysis and Blind Signal Separation,San Diego, California, USA.Maria Vilkuna.
1989.
Free Word Order inFinnish.
Its Syntax and discourse functions.Suomalaisen Kirjallisuuden Seura, Helsinki.
