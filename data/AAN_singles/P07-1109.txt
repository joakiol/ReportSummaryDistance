Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 864?871,Prague, Czech Republic, June 2007. c?2007 Association for Computational LinguisticsBootstrapping a Stochastic Transducerfor Arabic-English Transliteration ExtractionTarek Sherif and Grzegorz KondrakDepartment of Computing ScienceUniversity of AlbertaEdmonton, Alberta, Canada T6G 2E8{tarek,kondrak}@cs.ualberta.caAbstractWe propose a bootstrapping approach totraining a memoriless stochastic transducerfor the task of extracting transliterationsfrom an English-Arabic bitext.
The trans-ducer learns its similarity metric from thedata in the bitext, and thus can func-tion directly on strings written in differentwriting scripts without any additional lan-guage knowledge.
We show that this boot-strapped transducer performs as well or bet-ter than a model designed specifically to de-tect Arabic-English transliterations.1 IntroductionTransliterations are words that are converted fromone writing script to another on the basis of their pro-nunciation, rather than being translated on the basisof their meaning.
Transliterations include named en-tities (e.g.
??
? 	?g./Jane Austen) and lexical loans(e.g.
??KQ?
?K/television).An algorithm to detect transliterations automati-cally in a bitext can be an effective tool for manytasks.
Models of machine transliteration such asthose presented in (Al-Onaizan and Knight, 2002) or(AbdulJaleel and Larkey, 2003) require a large set ofsample transliterations to use for training.
If such atraining set is unavailable for a particular languagepair, a detection algorithm would lead to a signif-icant gain in time over attempting to build the setmanually.
Algorithms for cross-language informa-tion retrieval often encounter the problem of out-of-vocabulary words, or words not present in the algo-rithm?s lexicon.
Often, a significant proportion ofthese words are named entities and thus are candi-dates for transliteration.
A transliteration detectionalgorithm could be used to map named entities in aquery to potential transliterations in the target lan-guage text.The main challenge in transliteration detectionlies in the fact that transliteration is a lossy process.In other words, information can be lost about theoriginal word when it is transliterated.
This can oc-cur because of phonetic gaps in one language or theother.
For example, the English [p] sound does notexist in Arabic, and the Arabic [Q] sound (made bythe letter ?)
does not exist in English.
Thus, Paul istransliterated as ??K.
[bul], and???
[Qali] is translit-erated as Ali.
Another form of loss occurs when therelationship between the orthographic and phoneticrepresentations of a word are unclear.
For example,the [k] sound will always be written with the letter ?in Arabic, but in English it can be written as c, k ch,ck, cc or kk (not to mention being one of the soundsproduced by x).
Finally, letters may be deleted inone language or the other.
In Arabic, short vowelswill often be omitted (e.g.
??
?K/Yousef ), while inEnglish the Arabic Z and ?
are often deleted (e.g.?J?A??
?/Ismael).We explore the use of word similarity metrics onthe task of Arabic-English transliteration detectionand extraction.
One of our primary goals in explor-ing these metrics is to assess whether it is possiblemaintain high performance without making the al-gorithms language-specific.
Many word-similaritymetrics require that the strings being compared be864written in the same script.
Levenshtein edit distance,for example, does not produce a meaningful score inthe absence of character identities.
Thus, if thesemetrics are to be used for transliteration extraction,modifications must be made to allow them to com-pare different scripts.Freeman et al (2006) take the approach of man-ually encoding a great deal of language knowl-edge directly into their Arabic-English fuzzy match-ing algorithm.
They define equivalence classes be-tween letters in the two scripts and perform severalrule-based transformations to make word pairs morecomparable.
This approach is unattractive for tworeasons.
Firstly, predicting all possible relationshipsbetween letters in English and Arabic is difficult.For example, allowances have to be made for un-usual pronunciations in foreign words such as the chin cliche?
or the c in Milosevic.
Secondly, the algo-rithm becomes completely language-specific, whichmeans that it cannot be used for any other languagepair.We propose a method to learn letter relation-ships directly from the bitext containing the translit-erations.
Our model is based on the memorilessstochastic transducer proposed by Ristad and Yian-ilos (1998), which derives a probabilistic word-similarity function from a set of examples.
Thetransducer is able to learn edit distance costs be-tween disjoint sets of characters representing dif-ferent writing scripts without any language-specificknowledge.
The transducer approach, however, re-quires a large set of training examples, which is alimitation not present in the fuzzy matching algo-rithm.
Thus, we propose a bootstrapping approach(Yarowsky, 1995) to train the stochastic transduceriteratively as it extracts transliterations from a bi-text.
The bootstrapped stochastic transducer is com-pletely language-independent, and we show that it isable to perform at least as well as the Arabic-Englishspecific fuzzy matching algorithm.The remainder of this paper is organized as fol-lows.
Section 2 presents our bootstrapping methodto train a stochastic transducer.
Section 3 outlinesthe Arabic-English fuzzy matching algorithm.
Sec-tion 4 discusses other word-similarity models usedfor comparison.
Section 5 describes the results oftwo experiments performed to test the models.
Sec-tion 6 briefly discusses previous approaches to de-tecting transliterations.
Section 7 presents our con-clusions and possibilities for future work.2 Bootstrapping with a StochasticTransducerRistad and Yianilos (1998) propose a probabilisticframework for word similarity, in which the simi-larity of a pair of words is defined as the sum ofthe probabilities of all paths through a memorilessstochastic transducer that generate the pair of words.This is referred to as the forward score of the pair ofwords.
They outline a forward-backward algorithmto train the model and show that it outperforms Lev-enshtein edit distance on the task of pronunciationclassification.The training algorithm begins by calling the for-ward (Equation 1) and backward (Equation 2) func-tions to fill in the F and B tables for training pair sand t with respective lengths I and J .F (0, 0) = 1F (i, j) = P (si, ?
)F (i ?
1, j)+P (?, tj)F (i, j ?
1)+P (si, tj)F (i ?
1, j ?
1)(1)B(I, J) = 1B(i, j) = P (si+1, ?
)B(i + 1, j)+P (?, tj+1)B(i, j + 1)+P (si+1, tj+1)B(i + 1, j + 1)(2)The forward value at each position (i, j) in the Fmatrix signifies the sum of the probabilities of allpaths through the transducer that produce the prefixpair (si1, tj1), while B(i, j) contains the sum of theprobabilities of all paths through the transducer thatgenerate the suffix pair (sIi+1, tJj+1).
These tablescan then be used to collect partial counts to updatethe probabilities.
For example, the mapping (si, tj)would contribute a count according to Equation 3.These counts are then normalized to produce the up-dated probability distribution.C(si, tj)+ =F (i?
1, j ?
1)P (si, tj)B(i, j)F (I, J) (3)The major issue in porting the memoriless trans-ducer over to our task of transliteration extraction865is that its training is supervised.
In other words, itwould require a relatively large set of known translit-erations for training, and this is exactly what wewould like the model to acquire.
In order to over-come this problem, we look to the bootstrappingmethod outlined in (Yarowsky, 1995).
Yarowskytrains a rule-based classifier for word sense disam-biguation by starting with a small set of seed ex-amples for which the sense is known.
The trainedclassifier is then used to label examples for whichthe sense is unknown, and these newly labeled ex-amples are then used to retrain the classifier.
Theprocess is repeated until convergence.Our method uses a similar approach to train thestochastic transducer.
The algorithm proceeds asfollows:1.
Initialize the training set with the seed pairs.2.
Train the transducer using the forward-backward algorithm on the current training set.3.
Calculate the forward score for all word pairsunder consideration.4.
If the forward score for a pair of words is abovea predetermined acceptance threshold, add thepair to the training set.5.
Repeat steps 2-4 until the training set ceases togrow.Once training stops, the transducer can be usedto score pairs of words not in the training set.
Forour experiments, the acceptance threshold was op-timized on a separate development set.
Forwardscores were normalized by the average of the lengthsof the two words.3 Arabic-English Fuzzy String MatchingIn this section, we outline the fuzzy string matchingalgorithm proposed by Freeman et al (2006).
Thealgorithm is based on the standard Levenshtein dis-tance approach, but encodes a great deal of knowl-edge about the relationships between English andArabic letters.Initially, the candidate word pair is modified intwo ways.
The first transformation is a rule-basedletter normalization of both words.
Some examplesof normalization include:?
English double letter collapse: e.g.Miller?Miler.,,?,??
a,e,i,o,u H.?
b,p,vH,?,H?
t h.?
j,g??
d,z ?,Z ?
?,c,a,e,i,o,u?
?
q,g,k ?
?
k,c,s??
y,i,e,j ?
?
a,eTable 1: A sample of the letter equivalence classesfor fuzzy string matching.Algorithm VowelNorm (Estring,Astring)for each i := 0 to min(|Estring|, |Astring|)for each j := 0 to min(|Estring|, |Astring|)if Astringi = EstringjOutstring.
= Estringj; i + +; j + +;if vowel(Astringi) ?
vowel(Estringj)Outstring.
= Estringj; i + +; j + +;if ?vowel(Astringi) ?
vowel(Estringj)j + +;if j < |Estringj |Outstring.
= Estringj ; i + +; j + +;elseOutstring.
= Estringj; i + +; j + +;while j < |Estring|if ?vowel(Estringj)Outstring.
= Estringj ;j + +;return Outstring;Figure 1: Pseudocode for the vowel transformationprocedure.?
Arabic hamza collapse: e.g.
?Q???
?Q??
.?
Individual letter normalizations: e.g.
Hen-drix?Hendriks or 	?KQ???
?KQ?D?.The second transformation is an iteration throughboth words to remove any vowels in the Englishword for which there is no similarly positionedvowel in the Arabic word.
The pseudocode for ourimplementation of this vowel transformation is pre-sented in Figure 1.After letter and vowel transformations, the Leven-shtein distance is computed using the letter equiva-lences as matches instead of identities.
Some equiv-alence classes between English and Arabic lettersare shown in Table 1.
The Arabic and English letterswithin a class are treated as identities.
For example,the Arabic 	?
can match both f and v in English withno cost.
The resulting Levenshtein distance is nor-malized by the sum of the lengths of both words.866Levenshtein ALINE Fuzzy Match BootstrapLang.-specific No No Yes NoPreprocessing Romanization Phon.
Conversion None NoneData-driven No No No YesTable 2: Comparison of the word-similarity models.Several other modifications, such as light stem-ming and multiple passes to discover more diffi-cult mappings, were also proposed, but they werefound to influence performance minimally.
Thus,the equivalence classes and transformations are theonly modifications we reproduce for our experi-ments here.4 Other Models of Word SimilarityIn this section, we present two models of word simi-larity used for purposes of comparison.
Levenshteindistance and ALINE are not language-specific perse, but require that the words being compared bewritten in a common script.
Thus, they require somelanguage knowledge in order to convert one or bothof the words into the common script.
A comparisonof all the models presented is given in Table 2.4.1 Levenshtein Edit DistanceAs a baseline for our experiments, we used Leven-shtein edit distance.
The algorithm simply countsthe minimum number of insertions, deletions andsubstitutions required to convert one string into an-other.
Levenshtein distance depends on finding iden-tical letters, so both words must use the same al-phabet.
Prior to comparison, we convert the Ara-bic words into the Latin alphabet using the intuitivemappings for each letter shown in Table 3.
Thedistances are also normalized by the length of thelonger of the two words to avoid excessively penal-izing longer words.4.2 ALINEUnlike other algorithms presented here, the ALINEalgorithm (Kondrak, 2000) operates in the phonetic,rather than the orthographic, domain.
It was orig-inally designed to identify cognates in related lan-guages, but it can be used to compute similarity be-tween any pair of words, provided that they are ex-pressed in a standard phonetic notation.
Individual,,?,Z ?
a H.?
b H,??
t?
?
a H ?
th h.?
jh, ?
?
h p ?
kh X, 	?
?
dX,??
th P ?
r 	P ?
z?,?
?
s ?
?
sh ?
?
??
?
g 	?
?
f ?
?
q?
?
k ?
?
l  ?
m?
?
n ?
?
w ??
yTable 3: Arabic Romanization for Levenshtein dis-tance.phonemes input to the algorithm are decomposedinto a dozen phonetic features, such as Place, Man-ner and Voice.
A substitution score between a pairof phonemes is based on the similarity as assessedby a comparison of the individual features.
Afteran optimal alignment of the two words is computedwith a dynamic programming algorithm, the overallsimilarity score is set to the sum of the scores of alllinks in the alignment normalized by the length ofthe longer of the two words.In our experiments, the Arabic and English wordswere converted into phonetic transcriptions using adeterministic rule-based transformation.
The tran-scriptions were only approximate, especially for En-glish vowels.
Arabic emphatic consonants were de-pharyngealized.5 EvaluationThe word-similarity metrics were evaluated on twoseparate tasks.
In experiment 1 (Section 5.1) thetask was to extract transliterations from a sentencealigned bitext.
Experiment 2 (Section 5.2) providesthe algorithms with named entities from an Englishdocument and requires them to extract the transliter-ations from the document?s Arabic translation.The two bitexts used in the experiments were the867Figure 2: Precision per number of words extracted for the various algorithms from a sentence-aligned bitext.Arabic Treebank Part 1-10k word English Transla-tion corpus and the Arabic English Parallel NewsPart 1 corpus (approx.
2.5M words).
Both bi-texts contain Arabic news articles and their Englishtranslations aligned at the sentence level, and bothare available from the Linguistic Date Consortium.The Treebank data was used as a development setto optimize the acceptance threshold used by thebootstrapped transducer.
Testing for the sentence-aligned extraction task was done on the first 20ksentences (approx.
50k words) of the parallel newsdata, while the named entity extraction task was per-formed on the first 1000 documents of the paral-lel news data.
The seed set for bootstrapping thestochastic transducer was manually constructed andconsisted of 14 names and their transliterations.5.1 Experiment 1: Sentence-Aligned DataThe first task used to test the models was to compareand score the words remaining in each bitext sen-tence pair after preprocessing the bitext in the fol-lowing way:?
The English corpus is tokenized using a modi-fied1 version of Word Splitter2.?
All uncapitalized English words are removed.?
Stop words (mainly prepositions and auxiliary1The way the program handles apostrophes(?)
had to bemodified since they are sometimes used to represent glottalstops in transliterations of Arabic words, e.g.
qala?a.2Available at http://l2r.cs.uiuc.edu/?cogcomp/tools.php.verbs) are removed from both sides of the bi-text.?
Any English words of length less than 4 andArabic words of length less than 3 are removed.Each algorithm finds the top match for each En-glish word and the top match for each Arabic word.If two words mark each other as their top scorers,then the pair is marked as a transliteration pair.
Thisone-to-one constraint is meant to boost precision,though it will also lower recall.
This is because formany of the tasks in which transliteration extractionwould be useful (such as building a lexicon), preci-sion is deemed more important.
Transliteration pairsare sorted according to their scores, and the top 500hundred scoring pairs are returned.The results for the sentence-aligned extractiontask are presented in Figure 2.
Since the numberof actual transliterations in the data was unknown,there was no way to compute recall.
The measureused here is the precision for each 100 words ex-tracted up to 500.
The bootstrapping method is equalto or outperforms the other methods at all levels, in-cluding the Arabic-English specific fuzzy match al-gorithm.
Fuzzy matching does well for the first fewhundred words extracted, but eventually falls belowthe level of the baseline Levenshtein.Interestingly, the bootstrapped transducer doesnot seem to have trouble with digraphs, despite theone-to-one nature of the character operations.
Wordpairs with two-to-one mappings such as sh/ ?
or868Metric Arabic Romanized English1 Bootstrap 	?KQgB alakhyryn Algerian2 Bootstrap ????
wslm Islam3 Fuzzy M.
???
lkl Alkella4 Fuzzy M.
?A??
?mAn common5 ALINE Q??
skr sugar6 Leven.
H.A? asab Arab7 All ?PA?
mark Marks8 All 	??J?
?P rwsywn Russian9 All ?Jj.KQ? istratyjya strategic10 All ?
KQ 	?
frnk FrenchTable 4: A sample of the errors made by the word-similarity metrics.x/??
tend to score lower than their counterpartscomposed of only one-to-one mappings, but never-theless score highly.A sample of the errors made by each word-similarity metric is presented in Table 4.
Errors 1-6 are indicative of the weaknesses of each individ-ual algorithm.
The bootstrapping method encoun-ters problems when erroneous pairs become part ofthe training data, thereby reinforcing the errors.
Theonly problematic mapping in Error 1 is the p/g map-ping, and thus the pair has little trouble getting intothe training data.
Once the pair is part of trainingdata, the algorithm learns that the mapping is ac-ceptable and uses it to acquire other training pairsthat contain the same erroneous mapping.
The prob-lem with the fuzzy matching algorithm seems to bethat it creates too large a class of equivalent words.The pairs in errors 3 and 4 are given a total edit costof 0.
This is possible because of the overly gen-eral letter and vowel transformations, as well as un-usual choices made for letter equivalences (e.g.
?/cin error 4).
ALINE?s errors tend to occur when itlinks two letters, based on phonetic similarity, thatare never mapped to each other in transliteration be-cause they each have a more direct equivalent in theother language (error 5).
Although the Arabic ?
[k]is phonetically similar to the English g, they wouldnever be mapped to each other since English has sev-eral ways of representing an actual [k] sound.
Errorsmade by Levenshtein distance (error 6) are simplydue to the fact that it considers all non-identity map-pings to be equivalent.Errors 7-10 are examples of general errors madeby all the algorithms.
The most common error wasrelated to inflection (error 7).
The words are essen-tially transliterations of each other, but one or theother of the two words takes a plural or some otherinflectional ending that corrupts the phonetic match.Error 8 represents the common problem of inciden-tal letter similarity.
The English -ian ending used fornationalities is very similar to the Arabic 	?
?J[ijun]and 	?J[ijin] endings which are used for the samepurpose.
They are similar phonetically and, sincethey are functionally similar, will tend to co-occur.Since neither can be said to be derived from theother, however, they cannot be considered translit-erations.
Error 9 is a case of two words of commonorigin taking on language-specific derivational end-ings that corrupt the phonetic match.
Finally, error10 shows a mapping (?/c) that is often correct intransliteration, but is inappropriate in this particularcase.5.2 Experiment 2: Document-Aligned NamedEntity RecognitionThe second experiment provides a more challengingtask for the evaluation of the models.
It is struc-tured as a cross-language named entity recognitiontask similar to those outlined in (Lee and Chang,2003) and (Klementiev and Roth, 2006).
Essen-tially, the goal is to use a language for which namedentity recognition software is readily available as areference for tagging named entities in a languagefor which such software is not available.
For thistask, the sentence alignment of the bitext is ignored.For each named entity in an English document, themodels must select a transliteration from within thedocument?s entire Arabic translation.
This is meantto be a loose approximation of the ?comparable?corpora used in (Klementiev and Roth, 2006).
Thecomparable corpora are related documents in differ-ent languages that are not translations (e.g.
news ar-ticles describing the same event), and thus sentencealignment is not possible.The first 1000 documents in the parallel news datawere used for testing.
The English side of the bi-text was tagged with Named Entity Tagger3, whichlabels named entities as person, location, organiza-3Available at http://l2r.cs.uiuc.edu/?cogcomp/tools.php.869Method AccuracyLevenshtein 69.3ALINE 71.9Fuzzy Match 74.6Bootstrapping 74.6Table 5: Precision of the various algorithms on theNER detection task.Metric Arabic Romanized English1 Both YJ.?
?bd Abdallah2 Bootstrap YKY?
? al?dyd Alhadidi3 Fuzzy Match 	??
?
thmn OthmanTable 6: A sample of errors made on the NER detec-tion task.tion or miscellaneous.
The words labeled as per-son were extracted.
Person names are almost alwaystransliterated, while for the other categories this isfar less certain.
The list was then hand-checked toensure that all names were candidates for transliter-ation, leaving 822 names.
The restrictions on wordlength and stop words were the same as before, butin this task each of the English person names froma given document were compared to all valid wordsin the corresponding Arabic document, and the topscorer for each English name was returned.The results for the NER detection task are pre-sented in Table 5.
It seems the bootstrapped trans-ducer?s advantage is relative to the proportion ofcorrect transliteration pairs to the total number ofcandidates.
As this proportion becomes smaller thetransducer is given more opportunities to corrupt itstraining data and performance is affected accord-ingly.
Nevertheless, the transducer is able to per-form as well as the language-specific fuzzy match-ing algorithm on this task, despite the greater chal-lenge posed by selecting candidates from entire doc-uments.A sample of errors made by the bootstrappedtransducer and fuzzy matching algorithms is shownin Table 6.
Error 1 was due to the fact that names aresometimes split differently in Arabic and English.The Arabic ???
 YJ.?
(2 words) is generally writtenas Abdallah in English, leading to partial matcheswith part of the Arabic name.
Error 2 shows an issuewith the one-to-one nature of the transducer.
Thedeleted h can be learned in mappings such as sh/ ?or ph/ 	?, but it is generally inappropriate to deletean h on its own.
Error 3 again shows that the fuzzymatching algorithm?s letter transformations are toogeneral.
The vowel removals lead to a 0 cost matchin this case.6 Related WorkSeveral other methods for detecting transliterationsbetween various language pairs have been proposed.These methods differ in their complexity as well asin their applicability to language pairs other than thepair for which they were originally designed.Collier et al (1997) present a method for identi-fying transliterations in an English-Japanese bitext.Their model first transcribes the Japanese word ex-pressed in the katakana syllabic script as the con-catenation of all possible transliterations of the in-dividual symbols.
A depth-first search is then ap-plied to compute the number of matches betweenthis transcription and a candidate English transliter-ation.
The method requires a manual enumeration ofthe possible transliterations for each katakana sym-bol, which is unfeasible for many language pairs.In the method developed by Tsuji (2002),katakana strings are first split into their mora units,and then the transliterations of the units are assessedmanually from a set of training pairs.
For eachkatakana string in a bitext, all possible translitera-tions are produced based on the transliteration unitsdetermined from the training set.
The translitera-tion candidates are then compared to the Englishwords according to the Dice score.
The manual enu-meration of possible mappings makes this approachunattractive for many language pairs, and the gen-eration of all possible transliteration candidates isproblematic in terms of computational complexity.Lee and Chang (2003) detect transliterations witha generative noisy channel transliteration modelsimilar to the transducer presented in (Knight andGraehl, 1998).
The English side of the corpus istagged with a named entity tagger, and the modelis used to isolate the transliterations in the Chinesetranslation.
This model, like the transducer pro-posed by Ristad and Yianilos (1998), must be trainedon a large number of sample transliterations, mean-ing it cannot be used if such a resource is not avail-870able.Klementiev and Roth (2006) bootstrap with a per-ceptron and use temporal analysis to detect translit-erations in comparable Russian-English news cor-pora.
The English side is first tagged by a namedentity tagger, and the perceptron proposes transliter-ations for the named entities.
The candidate translit-eration pairs are then reranked according the similar-ity of their distributions across dates, as calculatedby a discrete Fourier transform.7 Conclusion and Future WorkWe presented a bootstrapping approach to traininga stochastic transducer, which learns scoring param-eters automatically from a bitext.
The approach iscompletely language-independent, and was shownto perform as well or better than an Arabic-Englishspecific similarity metric on the task of Arabic-English transliteration extraction.Although the bootstrapped transducer islanguage-independent, it learns only one-to-oneletter relationships, which is a potential drawback interms of porting it to other languages.
Our model isable to capture English digraphs and trigraphs, but,as of yet, we cannot guarantee the model?s successon languages with more complex letter relationships(e.g.
a logographic writing system such as Chinese).More research is necessary to evaluate the model?sperformance on other languages.Another area open to future research is the useof more complex transducers for word comparison.For example, Linden (2006) presents a model whichlearns probabilities for edit operations by taking intoaccount the context in which the characters appear.It remains to be seen how such a model could beadapted to a bootstrapping setting.AcknowledgmentsWe would like to thank the members of the NLP re-search group at the University of Alberta for theirhelpful comments and suggestions.
This researchwas supported by the Natural Sciences and Engi-neering Research Council of Canada.ReferencesN.
AbdulJaleel and L. S. Larkey.
2003.
Statisticaltransliteration for English-Arabic cross language in-formation retrieval.
In CIKM, pages 139?146.Y.
Al-Onaizan and K. Knight.
2002.
Machine translit-eration of names in Arabic text.
In ACL Workshop onComp.
Approaches to Semitic Languages.N.
Collier, A. Kumano, and H. Hirakawa.
1997.
Acqui-sition of English-Japanese proper nouns from noisy-parallel newswire articles using Katakana matching.In Natural Language Pacific Rim Symposium (NL-PRS?97), Phuket, Thailand, pages 309?314, Decem-ber.A.
Freeman, S. Condon, and C. Ackerman.
2006.Cross linguistic name matching in English and Ara-bic.
In Human Language Technology Conference ofthe NAACL, pages 471?478, New York City, USA,June.
Association for Computational Linguistics.A.
Klementiev and D. Roth.
2006.
Named entity translit-eration and discovery from multilingual comparablecorpora.
In Human Language Technology Conferenceof the NAACL, pages 82?88, New York City, USA,June.
Association for Computational Linguistics.K.
Knight and J. Graehl.
1998.
Machine transliteration.Computational Linguistics, 24(4):599?612.G.
Kondrak.
2000.
A new algorithm for the alignment ofphonetic sequences.
In NAACL 2000, pages 288?295.C.
Lee and J. S. Chang.
2003.
Acquisition of English-Chinese transliterated word pairs from parallel-alignedtexts using a statistical machine transliteration model.In HLT-NAACL 2003 Workshop on Building and usingparallel texts, pages 96?103, Morristown, NJ, USA.Association for Computational Linguistics.K.
Linden.
2006.
Multilingual modeling of cross-lingualspelling variants.
Information Retrieval, 9(3):295?310, June.E.
S. Ristad and P. N. Yianilos.
1998.
Learning string-edit distance.
IEEE Transactions on Pattern Analysisand Machine Intelligence, 20(5):522?532.K.
Tsuji.
2002.
Automatic extraction of translationalJapanese-katakana and English word pairs.
Interna-tional Journal of Computer Processing of OrientalLanguages, 15(3):261?279.D.
Yarowsky.
1995.
Unsupervised word sense disam-biguation rivaling supervised methods.
In Meeting ofthe Association for Computational Linguistics, pages189?196.871
