Integrating General-purpose andCorpus-based Verb ClassificationRoberto Basili*University of Roma Tor VergataMaria Teresa Pazienza*University of Roma Tor VergataPaola Velardi*University of Ancona1.
IntroductionA long-standing debate in the computational linguistic community is about the gen-erality of lexical taxonomies.
Many linguists (Nirenburg 1995; Hirst 1995) stress thattaxonomies that are not language neutral, at least at the intermediate and high level,have little hope of success.
On the other hand, lexicon builders who have experienceof designing taxonomies for real applications claim that in sublanguages there existvery domain-dependent similarity relations.
Given our experience and results, we areinclined to take the second position, but we are indeed sensitive to the theoreticalmotivations of the first.The problem is that the similarity relations uggested by the thematic structures ofwords 1 in sentences are highly domain dependent, and it is difficult, though perhapsnot impossible, to find common invariants across sublanguages when this model ofword similarity is adopted.
On the other hand, conceptual, or compositional modelsof similarity are much more difficult to understand and formalize on a systematicbasis, because of the difficulty of defining a commonly agreed upon set of semanticprimitives into which words may be decomposed.It may be possible, however, and highly interesting, to integrate the results of apurely inductive method, such as the conceptual clustering system CIAULA (Basili,Pazienza, and Velardi 1993c, 1996a), and a hand-encoded, omain-general classifica-tion, such as, for example, WordNet.
The purpose of one such experiment, whichwe describe in this paper, is to find some points of contact between psychologicallymotivated models, as WordNet, and data-driven models, as CIAULA.
22.
Detecting Verb Similarities with a SublanguageTo analyze verb similarities, we used CIAULA, a conceptual clustering algorithm forword classification, which we applied to the task of verb categorization.
We will notprovide details of the specific algorithm used (they may be found in works referredto above), we will simply summarize the main features of the system.
* Dipartimento di Informatica, Sistemi eProduzione, Via della Ricerca Scientifica, 00133 Roma, Italyt Istituto di Informatica, Via delle Brecce Bianche, Ancona, Italy1 This is referred to in the literature as a relational model of similarity.2 This research has been partially funded by the European Commission, under the ESPRIT-ECRANproject.
(~) 1996 Association for Computational LinguisticsComputational Linguistics Volume 22, Number 4CIAULA is an unsupervised learning algorithm for incremental concept formation,based on an augmented version of the well-known COBWEB (Fisher 1987).The input observations (instances) for our concept-formation algorithm are verbobservations in sentences, represented by their generalized thematic structures, ac-quired semiautomatically from corpora by ARIOSTO_LEX (Basili, Pazienza, and Ve-lardi 1993a, 1993b, 1996b).In CIAULA, the thematic roles of a verb v in a sentence are represented by afeature-vector:v/(Ri, : Catit) it @ I, jt E J t = 1,2 .
.
.
.
.
n (1)In (1), Ri, are the conceptual relations, or thematic roles (agentive, instrument, etc.
)and Carl, are the conceptual types of the words to which v is related semantically.Conceptual relations are assigned semiautomatically.
Conceptual types are assignedeither manually (in Italian, since no on-line resources are available) or automatically,using WordNet.For example, the following sentence in an English remote sensing domain (here-after RSD):... the satellite produced information with high accuracyoriginates the instance:(2) produce / (MANNER: PROPERTY,AFFECTED: ABSTRACTION,INSTRUMENT: INSTRUMENTALITY )Semantic similarity is strongly suggested by the observation of verb configurations,in which words of the same conceptual type play the same roles.Distinguishing features of CIAULA are:.2.Treatment of ambiguity and polysemy.
In contrast o classical conceptualclustering algorithms, CIAULA accounts for multiple instances of thesame concept, that is, of the same verb.Identi~cation of most representative clusters.
The method identifies thebasic-level categories (Rosch 1978) for an acquired hierarchy of verbs,i.e., those bringing the most predictive information about their members.The results of repeated experiments showed that CIAULA is able, upon an appro-priate setting of the model parameters, to detect similarity relations in the thematicstructure of verbs, and to provide a probabilistic and semantic description of the ac-quired clusters.
We observed that, by tuning the model parameters to obtain clustersof "very similar" instances, a percentage varying between 30% and 60% of verbs (de-pending upon the number of input observations) belong to singletons, that is, are not"similar enough" to any other verb.
If we relax these constraints, we obtain largerclusters and fewer singletons, but verbs in a cluster are less semantically close to eachother.In Figure 1 we show two basic-level categories obtained with different values ofthe model parameters, for the RSD.
For each cluster member, the local and globalmembership is shown.
Members of Class 1,870 are verbs that take an abstraction (ABS)as a direct object.
Class 1,603 was generated in a different run, in which we imposeda tighter similarity among the cluster members.
The verbs in this category take with560Basili, Pazienza, and Velardi Verb ClassificationClass: f870 Card:PROTOTYPE (i.e.,Verbs (and theirgeneratecustomizeprovideuseshowvary6Predicted Themat ic  Roles):(AFFECTED) --> \[ABS\]local and global degree of membership):(0.500 - 0(0.500 - 1(0.500 - 0(1.000 - 0(0.500 - 0(0.500 - 0250)ooo)167)071)333)5oo)Class: 1603 Card: 3PROTOTYPE (i.e., Predicted Thematic  Roles):-- (AGENTIVE) -- > \[ABS\]-- (MANNER) -- > \[PR,C0\]Verbs (and their  local and global degree of membership):i l lustrate (0.500 - 1.000)calculate (0.600 - 0.333)deal (I.000 - 0.333)Figure 1Two CIAULA clusters obtained with different modelparameters.highest probability an ABSTRACTION as agentive, and a manner modifier that may bea PROPERTY (PR) or a COGNITIVE_PROCESS (CO).
Some examples are: the data/ABSillustrate the problem/(ABS,CO) with accuracy/pa .
.
.
.
the algorithm/ABS efficiently/Pa calculatesThe similarity relations detected by CIAULA cannot be used tout court as a tax-onomy in a NLP system.
However, they can be used to tune a general-purpose taxon-omy to a specific domain, by reducing sense ambiguity and identifying new, domain-specific senses.
For example, the predicted thematic structure for the cluster 1,603shows that the verb to deal has a more specific use than in general language.
In theRSD, algorithms/ABS deal with parameters/pa .
.
.
.Cross-linguistic experiments (Basili, Pazienza, and Velardi 1996b) showed that sim-ilarity relations are different in different domains, which raises the issue of detectinglanguage invariants, that is, a language-neutral ontology (at least at the highest levels).Our contribution to this long-standing issue will be empirical, rather than methodolog-ical.3.
Analysing the Relations between Corpus-induced andHuman-deduced CategoriesIn this section, we propose amethod to analyze the relations between a domain-generalontology, such as WordNet, derived by linguists eeking language-neutral principles,and our example-driven clusters, derived by CIAULA.
The purpose of this analysisis not to validate CIAULA with WordNet, nor to augment WordNet with CIAULA.Rather, our purpose is to identify commonalities and discrepancies, and to investigatethe possibility of profitably integrating the two approaches.One of the motivations for using WordNet is that, in WordNet, verb meaning isrepresented in terms of semantic relations, rather than semantic primitives (Miller andFellbaum 1991).
Hence, in principle, WordNet and CIAULA adopt the same relational561Computational Linguistics Volume 22, Number 4Let C be a cluster automatically derived by CIAULA (Basili et al 1996a).
A clusteris simply a set of verbs modeled by means of a graded membership function,i.e., the local membership of verbs, #(v, C) (Basili, Pazienza, and Velardi 1993c).Let S(v) be the set of senses of the verb v.For each sense s in S(v), the set of WordNet hyperonims of s is defined.
Letsyns(v) denote this set, i.e.,= { yns 13s c S(v),s is_a syns}The is~ relation denote the transitive closure of WordNet IS_A: syns(v) is the setof possible (ambiguous) WordNet hyperonims of the verb v, through its senses(i.e., S(v)).Let syns(C) denote the set of all hyperonims of at least one verb v in C, i.e.,Let V(syns, C) be the set of verbs of a given cluster C that are hyponyms of syns.Formally,The preference score g is a real-valued function defined by:1g(syns) = Z IS(v)tvCV(syns,C)where I I denotes cardinality.The best Wordnet label syns for the cluster C is the one that maximizes g.Figure 2Labeling algorithm of CIAULA clusters.approach to describe verbs and detect similarities.
To investigate the commonalitiesbetween CIAULA and WordNet we decided to automatically select he best WordNetconcept as a label to assign to each acquired CIAULA cluster.Let vi be the members of a CIAULA basic-level cluster C, S(vi) the synsets for eachvi and h(S(vi)), or  hi, the set of supertypes (hyperonims) ofS(vi).
If gr(hi) is the numberof incoming IS_A arcs for a supertype, that is the number of synsets of vi that pointto hi, an intuitive algorithm would be to select as the best supertype for a cluster theone that maximizes gr(hi) values.Things, however, are more complex.
First, we must apply some normalization iorder to reduce the noise caused by the more ambiguous verbs.
Second, we mustbalance the effect of verbs that have more than one synset pointing to the same hi.In fact, a supertype could gain evidence only because several senses of the sameverb point to it.
Finally, the algorithm must avoid the selection of excessively generalcategories, like create, make.
Figure 2 describes the algorithm more formally.During a first experiment, we ran the tagging algorithm using unrestricted setsof verbs first clustered by CIAULA.
Because of the relatively sparse examples, theover generality of WordNet and the over specificity of CIAULA produced limitedinteractions.
In some cases, CIAULA clusters received a "pertinent" WordNet senselabel, but in some cases they did not.
A "good" example in a legal domain in Italian562Basili, Pazienza, and Velardi Verb ClassificationAGENT AB ( ) ~' .ABSTRAcr IONidentify estimate I ~"de~r ibe  | ~ D  COGNITWEPROCESS|  i'.....:.-.
?
?
.:..::.
: :  .. : :.:.:.
.
:i make de~rmineI document \ [~ '~ by ~1~ ta,\] :iac~; Iz~O~,~"~ | analyse ~,~,calctlla~ record raeastlre I ' "  1 ~solve p\[o~ de lermine \[ AFFEUrl~:ATFRIBUTE J plo!...
determine compare base inlelpretcompare plan workinclude include baserelate .... calculalereview "'"iden~'ycalculateFigure 3A portion of the acquired verb taxonomy.
(hereafter LD) is the class: evaluate, regulate, assign, determine, xamine, resolve, maintainthat received the label: judge, form an opinion of, pass judgement on.
A "bad" choice in thesame domain, is the class: indicate, establish, foresee, determine that received the overlygeneral abel: create, make.
On average, we were satisfied with one-half of the tagsassigned to clusters.This evaluation was performed by inspection, hence it is purely empirical.
Givena set of examples of verb uses, we can more or less easily tell whether a conceptualdefinition in terms of thematic structures (as provided by CIAULA) is appropriate ornot.
But it is much more difficult o say whether, for example, the CIAULA class mea-sure, propose, derive, evaluate, discover, classify, describe, calculate is appropriately describedby the WordNet label communicate, transmit houghts, transmit feelings.In WordNet, there are limited definitions of the conceptual labels used, or hyper-onims.
In general, lists of words or phrases are used in place of a single label, sothat the reader may have an idea of what is really meant.
But the higher the node, thedeeper the "meaning" behind a hyperonim, the harder is the human task of evaluatingthe appropriateness of a classification.Looking more in detail, the problem with misclassifications is twofold.
In somecases, the problem is the overambiguity and the very fine-grained concept labelsadopted in WordNet.
Especially with large CIAULA clusters, the number of synsetsbecomes too large, and the algorithm does not gain enough evidence of any sig-nificantly promising pattern in the hierarchy.
The second problem is the overspeci-ficity of CIAULA.
For example, verbs in the second cluster of the previous exam-ple (i.e., the "bad" choice), have been clustered because they occurred in patternslike: the laW~DoCUMENT indicates (establish, determine... ) the deadline/TaMeorcaa_ENT~Ty for thepresentation .. .
.
It is unlikely that the linguists who developed WordNet had in mindsuch a narrow use of these verbs when classifying them.WordNet labels for CIAULA classes are somewhat overly general.
DifferentCIAULA clusters received the same WordNet label, and this was used as a hint tofurther structure the induced classification.
An example is shown in Figure 3.
Theresulting taxonomy is built under a default node.In a second set of experiments, we ran CIAULA on a more homogeneous set ofverbs.
Rather than inducing verb categories from scratch, we augmented the seman-tic bias of CIAULA by preclassifying all the verbs in the RSD using the 15 WordNetsemantic domains for verbs, which are: bodily care, change, cognition, communication,563Computational Linguistics Volume 22, Number 4competition, consumption, contact, creation, emotion, motion, perception, possession, social in-teraction, stative, and weather.
We then fed CIAULA with groups of verbs belonging toeach of these categories.
Of course, many of these verbs are ambiguous, but we useda probabilistic method (Basili et al 1995) to select he observations of each verb thatare genuine examples of a semantic domain.This experiment produced rather appropriate classifications.
Table 1 shows thelabels assigned to some basic-level clusters generated by CIAULA for the RSD verbsbelonging to the semantic ategory cognition.
Figure 4 shows an excerpt of the CIAULAclusters of Table 1, with the prototypical description of each cluster.In Table I the fourth column (Overlap Score) is the ratio between verbs in a cluster(column 1) that belong to the WordNet synset of column 3, and the cardinality of thecluster.
In fact the best synset for a cluster does not necessarily cover all the clustermembers.
In the full experiment, 67% of the clusters have a score _> 0.5, indicating agood overlap between CIAULA and WordNet.
Worst clusters, as far as the overlapscore is concerned, are those in which there are very high-level and ambiguous verbs,like make.
These verbs usually produce noise, because of WordNet ambiguity and ofthe spurious (for the category) input examples fed to CIAULA.There are instead clusters with a low overlap score that seem very appropriate ifone looks at the usage patterns in the corpus.
For examples, the verbs of cluster 2,725in Table I are highly characterized (i.e., have high local membership values) by the factthat they take as object some physical PROPERTY (PR) of a NATURAL_OBJECT.
If weconsider the prototypical descriptions of clusters globally, we observe recurrent pat-terns of use of the clustered verbs.
Verbs of cognition in the RSD are strongly character-ized by a MENTAL OBJECT (MO), or COGNITIVE_PROCESS (CO), or ABSTRACTION(ABS), in the position of direct object (AFFECTED).
Frequently, the object of a cognitionverb is a physical PROPERTY or a NATURAL_OBJECT, and the analysis is performedwith some INSTRUMENTALITY (INS) (... cloud parameters are derived from satellite... )In order to analyze the correspondence/divergence between human-coded verbclasses and data-driven clusters we can compare the argument structure proposedfor the synsets in WordNet and the intentional description of the classes, i.e., theprototypical semantic patterns of CIAULA clusters (Figure 4).The WordNet argument structure for verbs, however, simply provides a qualitativedescription of the possible phrasal patterns in which verbs in a given synset can beused.
For example the sense record, enter, put down, make a record of of the verb to record(line 1 in Table 1), is described by(3) {Somebody, Something} records {something, somebody}Somebody records that CLAUSEAs shown, the information available is mainly syntactic, with the exception of theANIMATE/INANIMATE distinction for the arguments.The classification of CIAULA assigns the verb to record to four classes: (1) record,enter, put down, make a record of, (2) decide, make up one's mind, decide upon, determine,(3) create, make, and (4) investigate, look into, as shown in Table 1.
The different classesare characterized by the following semantic patterns, as shown in Figure 4:(i)(ii)(iii)class 4170 to record/(AFFECTED: PROPERTY)class 3637 to record/(AGENTIVE: COGNITWE_PROCESS)class 3518 to record /(LOCATION: PLACE)564Basili, Pazienza, and Velardi Verb ClassificationTable 1Excerpt of CIAULA clusters for cognition verbs in the RSD.Class # Ciaula Clusters (cognition verbs) WordNet Labels (synsets) Overlap Scores137 represent, lie symbolize, stand for, express 1.00indirectly, represent397 base, study, estimate, analyze, analyse, study, 0.33document, calculate, explore examine429 review, compare, include judge, form an opinion of, 0.66pass judgment on562 estimate, increase, soil, process, change, alter 0.42perform, observe, approach684 determine, compute decide, make up one's mind, 1.00decide upon, determine914 divide, transform, make create, make 0.661,196 include, base, deal, involve, study, think about, 0.18mind, relate, measure, review, contemplatecompare1,224 derive, describe, retrieve, get, acquire, enter upon, come 0.28document, review, compute, upon, luck intomeasure1,374 calculate, provide think, cogitate, cerebrate 1.001,587 calculate, relate, focus think, cogitate, cerebrate 1.001,941 scan, compare, propose, analyze, analyse, study, 0.30estimate, compute, analyse, examinestudy, experiment, base,evaluate2,049 assess, plan, review judge, form an opinion of, 0.66pass judgment on2,055 determine, provide, plan, create, make 0.33retrieve, view, show2,102 provide, make create, make 1.002,147 include, propose, derive include 0.332,383 account, stand, situate, create, make 0.33estimate, study, make2,491 select, locate, analyse find, regain 0.662,725 infer, derive, measure, select, reason, reason out, conclude, 0.50estimate, locate, compare, arrive at2,7973,5183,6373,7584,0804,170calculateresearch, base, recordcollect, develop, map, list,record, makedetermine, record, compare,measure, decidescan, surveyresearch, locateevaluate, plot, record, baseinvestigate, look intocreate, make0.660.50make up one's mind, decide 0.75upon, determinelook at, take a look at, 1.00examine, examine by sightinvestigate, look into 1.00record, enter, put down, make 0.50a record of(iv) class 2797 to record/(AFFECTED: ARTIFACT)Some differences between the pattern in (3) and any of the feature vectors (/-/v) are:?
Most of the syntactic relations expressed in (3) are accounted for in thesemantic patterns that CIAULA detects as prototypical for the verb to565Computational Linguistics Volume 22, Number 4CLASS: 2383 Card: 7stand (0 .500 - 1.000)situate (0 .500 - 1.000)estimate (0 .500 - 0 .037)study (0 .500 - 0 .036)account ( i .000 - 1.000)make  (0.500 - 0 .
i i i )PROT: --  (REFERENCE)  - -> \[DOC\]CLASS: 2055 Card: 7provide (0 .500 - 0 .111)plan (0 .500 - 0 .
i00)retrieve (0 .500 - 0 .167)view (0 .500 - 0 .167)determine ( i .000 - 0 .105)show (0 .500 - 0 .500)PROT: -- (AFFECTED)  - -  > lABS\]CLASS: 2725 Card: 15select (0 .800 - 0 .077)estimate (0 .800 - 0 .037)locate (0 .200 - 0 .143)measure (0 .400 - 0 .077)infer ( i .000 - 0 .556)compare (0 .200  - 0 .048)der ive  (0 .600  - 0 .103)ca lcu la te  (0 .200 - 0 .043)PROT: --  (AFFECTED)  - -> \[PR\]CLASS:  2102 Card: 3make (0.500 - 0 .111)provide (1 .000 - 0 .222)PROT: --  (MANNER) --  > \[C0\]CLASS:  914 Card: 5transform (0 .333 - 1.000)divide ( I .000 - 1.000)make  (0 .333 - 0 .
i i i )PROT: -- (LOCATION)  - -> \[LOC\]CLASS:  2797 Card :  5 CLASS:  3637 Card :  5base  (0 .333  - 0 .019)  record  (0 .500  - 0 .043)record  (0 .333  - 0 .043)  determine  (1 .000  - 0 .105)research  (1 .000  - 0 .125)  compare  (0 .500  - 0 .048)PROT: - -  (AFFECTED)  - -  > \[ART\] measure  (0.500 - 0 .038)PROT: --  (AGENT) - -> \[C0\]CLASS: 3518 Card: 7develop (0 .500 - 0 .250)  CLASS:  4170 Card: 5map (0 .500 - 0 .500)  p lo t  (0 .500 - 0 .091)l ist  (0 .500 - 1.000) record  (0 .500 - 0 .043)collect ( i .000 - 0 .667)  base  (0 .500 - 0 .019)record (0 .500 - 0 .043)  eva luate  (1.000 - 0 .286)make  (0.500 - 0 .111)  PROT: -- (AFFECTED)  --  > \[PR\]PROT: -- (LOCATION)  --  > \[LOCIFigure 4An excerpt of clusters of Table 1, with extensional and intensional descriptions.record.
Within the general properties of taking an (INANIMATE orANIMATE) entity as subject and object, however, CIAULA specifies thesemantics of the object and subject typical of the domain.
For example(see cluster 4,170) in this domain, the activity of recording, evaluating,plotting a PROPERTY (e.g., sea surface temperature, wind speed .
.
.
.  )
issignificant;In some cases the (weak) semantic expectations on the argumentstructure in WordNet are violated.
For example, in pattern (ii), aCOGNITIVE_PROCESS rather than somebody is the agentive of to record(e.g., the algorithm~co records the changes... ) and of the other members ofthe class labeled decide, make up one's mind, decide upon, determine (cluster3,637).Some relations are not predicted by WordNet, as for example pattern(iii).
Locative relations are treated in WordNet as lexical adjuncts of theverb to record.
However, they seem very relevant in the sublanguage (asfor example in sentences like: .
.
.
pollutants are recorded and analyzed insurface waters, temperature is recorded (collected) in the bay area ...  ).
It seemsthat (some) lexical adjuncts may play an important role in the definitionof domain-specific senses of verbs.566Basili, Pazienza, and Velardi Verb ClassificationIt appears that much information relevant for the lexical encoding of verbs is do-main specific and is completely missing in a general-purpose classification like Word-Net.
Therefore, semantically driven NL interpreters may profitably be augmented withthe information obtained by merging these different sources.A further interesting issue is related to identical tags assigned to different clus-ters.
Verbs in these classes hould express imilar acts or events.
An analysis of theprototypical patterns that CIAULA assigns to these classes uggests that despite theshared WordNet ags, verbs in these classes are very different.For example, the classes 2,383, 2,055, 3,518, 2,102, 914 are all labeled create, make,a very general synset in WordNet.
Their patterns are very different, and show almostno overlap.
The main motivation for this divergence between WordNet tagging andthe meanings of CIAULA clusters is twofold.
On the one hand, CIAULA clusters arevery fine grained, as they are built from single observations ofverb uses.
On the otherhand, WordNet is often missing most of these precise (technical) uses of verbs.
Asa result, the labeling algorithm of Figure 2 is forced to generalize over many levels,with a consequent loss of information.
The argument structure of the reached synsetis thus too generic.
It is worth noticing that even in these cases, we still achieveuseful information, since the WordNet argument structure can be further specified bydomain-specific semantic onstraints.
The class 2,055, for example, may be describedby an extended argument structure like(4) {Somebody, Something} makes {X},where X is an ABSTRACTION4.
ConclusionsThe results illustrated in this paper are very interesting, though not conclusive.
Verbsare vessels for human creativity in language communication, and so much is left tofurther studies.
We discovered thematic features that are apparently more "basic" thanothers, with respect o a given semantic domain (cognition) and a given sublanguage(RSD).
We could specify features that were described at a very general level in Word-Net, and detect semantic restrictions specific to the sublanguage, not accounted for inWordNet.
These results uggest that, with appropriate customization, it is still possibleto exploit he information i  general-purpose on-line thesauri that would be otherwisealmost unusable in real NLP applications.
As proposed in this paper, an appropriateprocess of lexical tuning can significantly reduce the overgenerality (excessive am-biguity) and underspecificity (weak constraints on verb argument structures) that istypical of general-purpose resources.ReferencesBasili, R., Della Rocca M., Pazienza, P.Velardi.
1995.
Contexts and categories:Tuning a general purpose verbclassification tosublanguages.
InProceedings ofthe International Conference onRecent Advances in Natural LanguageProcessing, Tzigov Chark, Bulgaria,September.Basili, R., M. T. Pazienza, and P. Velardi.1993a.
What can be acquired from rawtexts?
Journal of Machine Translation, 8.Basili, R., M. T. Pazienza, and P. Velardi.1993b.
Acquisition of selectional patternsin sublanguages.
Journal of MachineTranslation, 8:147-173.Basili, R., M. T. Pazienza, and P. Velardi.1993c.
Hierarchical c ustering of verbs.ACL-SIGLEX Workshop on LexicalAcquisition, Columbus, OH, June.Basili, R., M. T. Pazienza, and P. Velardi.1996a.
A context driven conceptualclustering method for verb classification.In B. Boguraev, and J. Pustejovsky,editors, MIT Press.567Computational Linguistics Volume 22, Number 4Basili, R., M. T. Pazienza, and P. Velardi.1996b.
An empirical symbolic approach tonatural language processing.
ArtificialIntelligence Journal.
To appear.Fisher, D. 1987.
Knowledge acquisition viaincremental conceptual c ustering.Machine Learning, 2.Hirst, G. 1995.
Working notes.
In AAAI 1995Fall Symposium on Representation a dAcquisition of Lexical Knowledge: Polisemy,Ambiguity and Generativity, Stanford, CA,March.Miller, G., and C. Fellbaum.
1991.
Semanticnetworks of English.
Cognition,41:197-229.Nirenburg, S. 1995.
Apologiae Ontologiae,Working Notes.
In AAAI 1995 FallSymposium on Representation a d Acquisitionof Lexical Knowledge: Polisemy, Ambiguityand Generativity.
Stanford, CA,March.Rosch, E. 1978.
Principle of categorization.In Cognition and Categorization, Erlbaum.568
