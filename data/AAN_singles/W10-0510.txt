Proceedings of the NAACL HLT 2010 Workshop on Computational Linguistics in a World of Social Media, pages 19?20,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsSocial Links from Latent Topics in Microblogs?Kriti Puniyani and Jacob Eisenstein and Shay Cohen and Eric P. XingSchool of Computer ScienceCarnegie Mellon University{kpuniyan,jacobeis,scohen,epxing}@cs.cmu.edu1 IntroductionLanguage use is overlaid on a network of social con-nections, which exerts an influence on both the topicsof discussion and the ways that these topics can be ex-pressed (Halliday, 1978).
In the past, efforts to under-stand this relationship were stymied by a lack of data, butsocial media offers exciting new opportunities.
By com-bining large linguistic corpora with explicit representa-tions of social network structures, social media providesa new window into the interaction between language andsociety.
Our long term goal is to develop joint sociolin-guistic models that explain the social basis of linguisticvariation.In this paper we focus on microblogs: internet jour-nals in which each entry is constrained to a few wordsin length.
While this platform receives high-profile at-tention when used in connection with major news eventssuch as natural disasters or political turmoil, less isknown about the themes that characterize microbloggingon a day-to-day basis.
We perform an exploratory anal-ysis of the content of a well-known microblogging plat-form (Twitter), using topic models to uncover latent se-mantic themes (Blei et al, 2003).
We then show that theselatent topics are predictive of the network structure; with-out any supervision, they predict which other microblogsa user is likely to follow, and to whom microbloggers willaddress messages.
Indeed, our topical link predictor out-performs a competitive supervised alternative from tra-ditional social network analysis.
Finally, we explore theapplication of supervision to our topical link predictor,using regression to learn weights that emphasize topicsof particular relevance to the social network structure.2 DataWe acquired data from Twitter?s streaming ?Gardenhose?API, which returned roughly 15% of all messages sentover a period of two weeks in January 2010.
This com-?We thank the reviews for their helpful suggestions and BrendanO?Connor for making the Twitter data available.prised 15GB of compressed data; we aimed to extract arepresentative subset by first sampling 500 people whoposted at least sixteen messages over this period, andthen ?crawled?
at most 500 randomly-selected followersof each of these original authors.
The resulting data in-cludes 21,306 users, 837,879 messages, and 10,578,934word tokens.Text Twitter contains highly non-standard orthographythat poses challenges for early-stage text processing.1 Wetook a conservative approach to tokenization, splittingonly on whitespaces and apostrophes, and eliminatingonly token-initial and token-final punctuation characters.Two markers are used to indicate special tokens: #, indi-cating a topic (e.g.
#curling); and @, indicating that themessage is addressed to another user.
Topic tokens wereincluded after stripping the leading #, but address tokenswere removed.
All terms occurring less than 50 timeswere removed, yielding a vocabulary of 11,425 terms.Out-of-vocabulary items were classified as either words,URLs, or numbers.
To ensure a fair evaluation, we re-moved ?retweets?
?
when a user reposts verbatim themessage of another user ?
if the original message authoris also part of the dataset.Links We experiment with two social graphs extractedfrom the data: a follower graph and a communicationgraph.
The follower graph places directed edges betweenusers who have chosen to follow each other?s updates;the message graph places a directed edge between userswho have addressed messages to each other (using the @symbol).
Huberman et al (2009) argue that the commu-nication graph captures direct interactions and is thus amore accurate representation of the true underlying socialstructure, while the follower graph contains more con-nections than could possibly be maintained in a realisticsocial network.1For example, some tweets use punctuation for tokenization (Youlook like a retired pornstar!lmao) while othersuse punctuation inside the token (lOv!n d!s th!ng call3dl!f3).19Figure 1: Mean rank of test links (lower is better), reported over 4-fold cross-validation.
Common-neighbors is a network-basedmethod that ignores text; the LDA (Latent Dirichlet Allocation) methods are grouped by number of latent topics.3 MethodWe constructed a topic model over twitter messages,identifying the latent themes that characterize the cor-pus.
In standard topic modeling methodology, topics de-fine distributions over vocabulary items, and each docu-ment contains a set of latent topic proportions (Blei et al,2003).
However, the average message on Twitter is onlysixteen word tokens, which is too sparse for traditionaltopic modeling; instead, we gathered together all of themessages from a given user into a single document.
Thusour model learns the latent topics that characterize au-thors, rather than messages.Authors with similar topic proportions are likely toshare interests or dialect, suggesting potential social con-nections.
Author similarity can be quantified withoutsupervision by taking the dot product of the topic pro-portions.
If labeled data is available (a partially ob-served network), then regression can be applied to learnweights for each topic.
Chang and Blei (2009) describesuch a regression-based predictor, which takes the formexp(?
?T (z?i ?
z?j) ?
(z?i ?
z?j)?
?
), denoting the pre-dicted strength of connection between authors i and j.Here z?i (z?j) refers to the expected topic proportions foruser i (j), ?
is a vector of learned regression weights, and?
is an intercept term which is only necessary if a the linkprediction function must return a probability.
We usedthe updates from Chang and Blei to learn ?
in a post hocfashion, after training the topic model.4 ResultsWe constructed topic models using an implemen-tation of variational inference2 for Latent Dirich-let Allocation (LDA).
The results of the run withthe best variational bound on 50 topics can befound at http://sailing.cs.cmu.edu/socialmedia/naacl10ws/.
While many ofthe topics focus on content (for example, electronicsand sports), others capture distinct languages and evendialect variation.
Such dialects are particularly evident in2http://www.cs.princeton.edu/?blei/lda-cstopwords (you versus u).
Structured topic models thatexplicitly handle these two orthogonal axes of linguisticvariation are an intriguing possibility for future work.We evaluate our topic-based approach for link predic-tion on both the message and follower graphs, compar-ing against an approach that only considers the networkstructure.
Liben-Nowell and Kleinberg (2003) performa quantitative comparison of such approaches, findingthat the relatively simple technique of counting the num-ber of shared neighbors between two nodes is a surpris-ingly competitive predictor of whether they are linked;we call this approach common-neighbors.
We evaluatethis method and our own supervised LDA+regression ap-proach by hiding half of the edges in the graph, and pre-dicting them from the other half.For each author in the dataset, we apply each methodto rank all possible links; the evaluation computes the av-erage rank of the true links that were held out (for ourdata, a random baseline would score 10653 ?
half thenumber of authors in the network).
As shown in Figure1, topic-based link prediction outperforms the alternativethat considers only the graph structure.
Interestingly, posthoc regression on the topic proportions did not consis-tently improve performance, though joint learning maydo better (e.g., Chang and Blei, 2009).
The text-based ap-proach is especially strong on the message graph, whilethe link-based approach is more competitive on the fol-lowers graph; a model that captures both features seemsa useful direction for future work.ReferencesD.
Blei, A. Ng, and M. Jordan.
2003.
Latent Dirichlet aloca-tion.
Journal of Machine Learning Research, 3:993?1022.J.
Chang and D. Blei.
2009.
Hierarchical relational models fordocument networks.
Annals of Applied Statistics.M.A.K.
Halliday.
1978.
Language as social semiotic: Thesocial interpretation of language and meaning.
UniversityPark Press.Bernardo Huberman, Daniel M. Romero, and Fang Wu.
2009.Social networks that matter: Twitter under the microscope.First Monday, 14(1?5), January.D.
Liben-Nowell and J. Kleinberg.
2003.
The link predictionproblem for social networks.
In Proc.
of CIKM.20
