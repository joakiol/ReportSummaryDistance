Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 165?169,Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational LinguisticsHow Much Can We Gain from Supervised Word Alignment?Jinxi Xu and Jinying ChenRaytheon BBN Technologies10 Moulton Street, Cambridge, MA 02138, USA{jxu,jchen}@bbn.comAbstractWord alignment is a central problem in sta-tistical machine translation (SMT).
In re-cent years, supervised alignment algo-rithms, which improve alignment accuracyby mimicking human alignment, have at-tracted a great deal of attention.
The objec-tive of this work is to explore the perform-ance limit of supervised alignment underthe current SMT paradigm.
Our experi-ments used a manually aligned Chinese-English corpus with 280K words recentlyreleased by the Linguistic Data Consortium(LDC).
We treated the human alignment asthe oracle of supervised alignment.
The re-sult is surprising:  the gain of humanalignment over a state of the art unsuper-vised method (GIZA++) is less than 1 pointin BLEU.
Furthermore, we showed thebenefit of improved alignment becomessmaller with more training data, implyingthe above limit also holds for large trainingconditions.1 IntroductionWord alignment is a central problem in statisticalmachine translation (SMT).
A recent trend in thisarea of research is to exploit supervised learning toimprove alignment accuracy by mimicking humanalignment.
Studies in this line of work includeHaghighi et al, 2009; DeNero and Klein, 2010;Setiawan et al, 2010, just to name a few.The objective of this work is to explore the per-formance limit of supervised word alignment.More specifically, we would like to know whatmagnitude of gain in MT performance we can ex-pect from supervised alignment over the state ofthe art unsupervised alignment if we have access toa large amount of parallel data.
Since alignmenterrors have been assumed to be a major hindranceto good MT, an answer to such a question mighthelp us find new directions in MT research.Our method is to use human alignment as theoracle of supervised learning and compare its per-formance against that of GIZA++ (Och and Ney2003), a state of the art unsupervised aligner.
Ourstudy was based on a manually aligned Chinese-English corpus (Li, 2009) with 280K word tokens.Such a study has been previously impossible due tothe lack of a hand-aligned corpus of sufficient size.To our surprise, the gain in MT performance us-ing human alignment is very small, less than 1point in BLEU.
Furthermore, our diagnostic ex-periments indicate that the result is not an artifactof small training size since alignment errors areless harmful with more data.We would like to stress that our result does notmean we should discontinue research in improvingword alignment.
Rather it shows that current trans-lation models, of which the string-to-tree model(Shen et al, 2008) used in this work is an example,cannot fully utilize super-accurate word alignment.In order to significantly improve MT quality weneed to improve both word alignment and thetranslation model.
In fact, we found that some ofthe information in the LDC hand-aligned corpusthat might be useful for resolving certain transla-tion ambiguities (e.g.
verb tense, pronoun co-references and modifier-head relations) is evenharmful to the system used in this work.1652 Experimental Setup2.1 Description of MT SystemWe used a state of the art hierarchical decoder inour experiments.
The system exploits a string totree translation model, as described by Shen et al(2008).
It uses a small set of linguistic and contex-tual features, such as word translation probabilities,rule translation probabilities, language modelscores, and target side dependency scores, to ranktranslation hypotheses.
In addition, it uses a largenumber of discriminatively tuned features, whichwere inspired by Chiang et al (2009) and imple-mented in a way described in (Devlin 2009).
Someof the features, e.g.
context dependent word trans-lation probabilities and discriminative word pairs,are motivated in part to discount bad translationrules caused by noisy word alignment.
The systemused a 3-gram language model (LM) for decodingand a 5-gram LM for rescoring.
Both LMs weretrained on about 9 billion words of English text.We tuned the system on a set of 4,171 sentencesand tested on a set of 4,060 sentences.
Both setswere drawn from the Chinese newswire develop-ment data for the DARPA GALE program.
On av-erage, each sentence has around 1.7 referencetranslations for both sets.
The tuning metric wasBLEU, but we reported results in BLEU (Papineniet al, 2002) and TER (Snover et al, 2006).2.2 Hand Aligned CorpusThe hand aligned corpus we used is LDC2010E63,which has around 280K words (English side).
Thiscorpus was annotated with alignment links be-tween Chinese characters and English words.
Sincethe MT system used in this work is word-based, weconverted the character-based alignment to word-based alignment.
We aligned Chinese word s toEnglish word t if and only if s contains a characterc that was aligned to t in the LDC annotation.A unique feature of the LDC annotation is thatit contains information beyond simple word corre-spondences.
Some links, called special links in thiswork, provide contextual information to resolveambiguities in tense, pronoun co-reference, modi-fier-head relation and so forth.
The special linksare similar to the so-called possible links describedin other studies (Och and Ney, 2003; Fraser andMarcu, 2007), but are not identical.
While suchlinks are useful for making high level inferences,they cannot be effectively exploited by the transla-tion model used in this work.
Worse, they can hurtits performance by hampering rule extraction.Since the special links were marked with specialtags to distinguish them from regular links, we canselectively remove them and check the impact onMT performance.Figure 1 shows an example sentence with hu-man alignment.
Solid lines indicate regular wordcorrespondences while dashed lines indicate spe-cial links.
Tags inside [] indicate additional infor-mation about the function of the words connectedby special links.Figure 1: An example sentence pair with humanalignment2.3 Parallel Corpora and Alignment SchemesOur experiments used two parallel training corpora,aligned by alternative schemes, from which trans-lation rules were extracted.The corpora are:?
Small: the 280K word hand-aligned cor-pus, with human alignment removed?
Large: a 31M word corpus of Chinese-English text, comprising a number ofcomponent corpora, one of which is thesmall corpus1The alignment schemes are:?
giza-weak: Subdivide the large corpus into110 chunks of equal size and run GIZA++separately on each chunk.
One of thechunks is the small corpus mentionedabove.
This produced low quality unsuper-vised alignment.1Other data items included are LDC{2002E18,2002L27,2005E83,2005T06,2005T10,2005T34,2006E24,2006E34,2006E85,2006E92,2006G05,2007E06,2007E101,2007E46,2007E87,2008E40,2009E16,2008E56}Chinese: gei[OMN]       ni    ti gong          jie shiEnglish:  provide  you   with[OMN]  an[DET]   explanation166?
giza-strong: Run GIZA++ on the largecorpus in one large chunk.
Alignment forthe small corpus was extracted for experi-ments involving the small corpus.
Thisproduced high quality unsupervised align-ment.?
gold-original: human alignment, includingspecial links?
gold-clean: human alignment, excludingspecial linksNeedless to say, gold alignment schemes do notapply to the large corpus.3 Results3.1 Results on Small CorpusThe results are shown in Table 2.
The special linksin the human alignment hurt MT (Table 2, gold-original vs. gold-clean).
In fact, with such links,human alignment is worse than unsupervisedalignment (Table 2, gold-original vs. giza-strong).After removing such links, human alignment isbetter than unsupervised alignment, but the gain issmall, 0.72 point in BLEU (Table 2, gold-clean vs.giza-strong).
As expected, having access to moretraining data increases the quality of unsupervisedalignment (Table 1) and as a result the MT per-formance (Table 2, giza-strong vs. giza-weak).Alignment Precision Recall  Fgold-clean 1.00 1.00 1.00giza-strong 0.81 0.72 0.76giza-weak 0.65 0.58 0.61Table 1: Precision, recall and F score of differentalignment schemes.
F score is the harmonic meanof precision and recall.Alignment BLEU TERgiza-weak 18.73 70.50giza-strong 21.94 66.70gold-original 20.81 67.50gold-clean 22.66 65.92Table 2: MT results (lower case) on small corpusIt is interesting to note that from giza-weak to giza-strong, alignment accuracy improves by 15% andthe BLEU score improves by 3.2 points.
In com-parison, from giza-strong to gold-clean, alignmentaccuracy improves by 24% but BLEU score onlyimproves by 0.72 point.
This anomaly can bepartly explained by the inherent ambiguity of wordalignment.
For example, Melamed (1998) reportedinter annotator agreement for human alignments inthe 80% range.
The LDC corpus used in this workhas a higher agreement, about 90% (Li et al,2010).
That means much of the disagreement be-tween giza-strong and gold alignments is probablydue to arbitrariness in the gold alignment.3.2 Results on Large CorpusAs discussed before, the gain using human align-ment over GIZA++ is small on the small corpus.One may wonder whether the small magnitude ofthe improvement is an artifact of the small size ofthe training corpus.To dispel the above concern, we ran diagnosticexperiments on the large corpus to show that withmore training data, the benefit from improvedalignment is less critical.
The results are shown inTable 3.
On the large corpus, the difference be-tween good and poor unsupervised alignments is2.37 points in BLEU (Table 3, giza-strong vs. giza-weak).
In contrast, the difference between the twoschemes is larger on the small corpus, 3.21 pointsin BLEU (Table 2, giza-strong vs. giza-weak).Since the quality of alignment of each scheme doesnot change with corpus size, the results indicatethat alignment errors are less harmful with moretraining data.
We can therefore conclude the smallmagnitude of the gain using human alignment isnot an artifact of small training.Comparing giza-strong of Table 3 with giza-strong of Table 2, we can see the difference in MTperformance is about 8 points in BLEU (20.94 vs.30.21).
This result is reasonable since the smallcorpus is two orders of magnitude smaller than thelarge corpus.Alignment BLEU TERgiza-weak 27.84 59.38giza-strong 30.21 56.62Table 3: MT results (lower case) on large corpus1673.3 DiscussionsSome studies on supervised alignment (e.g.Haghighi et al, 2009; DeNero and Klein, 2010)reported improvements greater than the limit weestablished using an oracle aligner.
This seeminglyinconsistency can be explained by a number offactors.
First, we used more data (31M) to trainGIZA++, which improved the quality of unsuper-vised alignment.
Second, some of the features inthe MT system used in this work, such as contextdependent word translation probabilities and dis-criminatively trained penalties for certain wordpairs, are designed to discount incorrect translationrules caused by alignment errors.
Third, the largelanguage model (trained with 9 billion words) inour experiments further alleviated the impact ofincorrect translation rules.
Fourth, the GALE testset has fewer reference translations than the NISTtest sets typically used by other researchers (1.7references for GALE, 4 references for NIST).
It iswell known that BLEU is very sensitive to thenumber of references used for scoring.
Had weused a test set with more references, the improve-ment in BLEU score would probably be higher.
Anarea for future work is to examine the impact ofeach factor on BLEU score.
While these factorscan affect the numerical value of our result, theydo not affect our main conclusion: Improving wordalignment alone will not produce a breakthrough inMT quality.DeNero and Klein (2010) described a techniqueto exploit possible links, which are similar to spe-cial links in the LDC hand aligned data, to improverule coverage.
They extracted rules with and with-out possible links and used the union of the ex-tracted rules in decoding.
We applied the techniqueon the LDC hand aligned data but got no gain inMT performance.Our work assumes that unsupervised alignershave access to a large amount of training data.
Forlanguage pairs with limited training, unsupervisedmethods do not work well.
In such cases, super-vised methods can make a bigger difference.4 Related WorkThe study of the relation between alignment qual-ity and MT performance can be traced as far as toOch and Ney, 2003.
A more recent study in thisarea is Fraser and Marcu, 2007.
Unlike our work,both studies did not report MT results using oraclealignment.Recent work in supervised alignment includeHaghighi et al, 2009; DeNero and Klein, 2010;Setiawan et al, 2010, just to name a few.
Fossumet al (2008) used a heuristic based method to de-lete problematic alignment links and improve MT.Li (2009) described the annotation guideline ofthe hand aligned corpus (LDC2010E63) used inthis work.
This corpus is at least an order of mag-nitude larger than similar corpora.
Without it thiswork would not be possible.5 ConclusionsOur experiments showed that even with humanalignment, further improvement in MT quality willbe small with the current SMT paradigm.
Our ex-periments also showed that certain alignment in-formation suitable for making complex inferencescan even hamper current SMT models.
A futuredirection for SMT is to develop translation modelsthat can effectively employ such information.AcknowledgmentsThis work was supported by DARPA/IPTO Con-tract No.
HR0011-06-C-0022 under the GALEprogram2 (Approved for Public Release, Distribu-tion Unlimited).
The authors are grateful to Mi-chael Kayser for suggestions to improve the pres-entation of this paper.ReferencesDavid Chiang, Kevin Knight, and Wei Wang.
2009.11,001 new features for statistical machine transla-tion.
In Proceedings of Human Language Technolo-gies: The 2009 Annual Conference of the NorthAmerican Chapter of the ACL, pages 218?226.John DeNero and Dan Klein.
2010.
DiscriminativeModeling of Extraction Sets for Machine Translation.In Proceedings of the 48th Annual Meeting of the As-sociation for Computational Linguistics, pages 1453?1463.2The views, opinions, and/or findings contained in this arti-cle/presentation are those of the author/presenter and shouldnot be interpreted as representing the official views or policies,either expressed or implied, of the Defense Advanced Re-search Projects Agency or the Department of Defense.168Jacob Devlin.
2009.
Lexical features for statistical ma-chine translation.
Master?s thesis, University ofMaryland.Victoria Fossum, Kevin Knight and Steven Abney.2008.
Using Syntax to Improve Word AlignmentPrecision for Syntax-Based Machine Translation, InProceedings of the third Workshop on Statistical MT,ACL, pages 44-52.Alexander Fraser and Daniel Marcu.
2007.
MeasuringWord Alignment Quality for Statistical MachineTranslation.
Computational Linguistics.
33(3): 293-303.Aria Haghighi, John Blitzer, John DeNero and DanKlein.
2009.
Better word alignments with supervisedITG models, In Proceedings of the Joint Conferenceof the 47th Annual Meeting of the ACL and the 4thInternational Joint Conference on Natural LanguageProcessing of the AFNLP, pages 923-931.Xuansong Li.
2009.
Guidelines for Chinese-EnglishWord Alignment, Version 4.0, April 16, 2009,http://ww.ldc.upenn.edu/Project/GALE.Xuansong Li, Niyu Ge, Stephen Grimes, Stephanie M.Strassel and  Kazuaki Maeda.
2010.
Enriching WordAlignment with Linguistic Tags.
In Proceedings ofthe Seventh International Conference on LanguageResources and Evaluation, Valletta, Malta.Dan Melamed.
1998.
Manual annotation of translationalequivalence: The blinker project.
Technical Report98-07, Institute for Research in Cognitive Science,Philadelphia.Franz Josef Och and Hermann Ney.
2003.
A systematiccomparison of various statistical alignment models.Computational Linguistics, 29(1):19-51.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
BLEU: a method for automaticevaluation of machine translation.
In Proceedings ofthe 40th Annual Meeting of the Association for Com-putational Linguistics, pages 311?318.Hendra Setiawan, Chris Dyer, and Philip Resnik.
2010.Discriminative Word Alignment with a FunctionWord Reordering Model.
In Proceedings of 2010Conference on Empirical Methods in Natural Lan-guage Processing, pages 534?544.Libin Shen, Jinxi Xu, and Ralph Weischedel.
2008.
Anew string-to-dependency machine translation algo-rithm with a target dependency language model.
InProceedings of ACL-08: HLT, pages 577?585.Matthew Snover, Bonnie Dorr, Richard Schwartz, LineaMicciulla, and John Makhoul.
2006.
A Study ofTranslation Edit Rate with Targeted Human Annota-tion.
In Proceedings of Association for MachineTranslation in the Americas, pages 223-231.169
