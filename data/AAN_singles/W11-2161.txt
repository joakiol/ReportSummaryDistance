Proceedings of the 6th Workshop on Statistical Machine Translation, pages 485?489,Edinburgh, Scotland, UK, July 30?31, 2011. c?2011 Association for Computational LinguisticsDFKI Hybrid Machine Translation System for WMT 2011- On the Integration of SMT and RBMTJia Xu and Hans Uszkoreit and Casey Kennington and David Vilar and Xiaojun ZhangDFKI GmbH, Language Technology LabStuhlsatzenhausweg 3D-66123 Saarbru?cken Germany{Jia.Xu,uszkoreit,David.Vilar}@dfki.de, {bakuzen,xiaojun.zhang.iiken}@gmail.comAbstractWe present the DFKI hybrid translation sys-tem at the WMT workshop 2011.
Three SMTand two RBMT systems are combined at thelevel of the final translation output.
The trans-lation results show that our hybrid system sig-nificantly outperformed individual systems byexploring strengths of both rule-based and sta-tistical translations.1 IntroductionMachine translation (MT), in particular the statisti-cal approach to it, has undergone incremental im-provements in recent years.
While rule-based ma-chine translation (RBMT) maintains competitive-ness in human evaluations.
Combining the advan-tages of both approaches have been investigated bymany researchers such as (Eisele et al, 2008).Nonetheless, significant improvements over statis-tical approaches still remain to be shown.
In thispaper, we present the DFKI hybrid system in theWMT workshop 2011.
Our system is different fromthe system of the last year (Federmann et al, 2010),which is based on the shallow phrase substitution.In this work, two rule-based translation systems areapplied.
In addition, three statistical machine trans-lation systems are built, including a phrase-based,a hierarchical phrase-based and a syntax-based sys-tem.
Instead of combining with rules or post-editing,we perform system combination on the final transla-tion hypotheses.
We applied the CMU open toolkit(Heafield and Lavie, 2010) among numerous com-bination methods such as (Matusov, 2009), (Sim etal., 2007) and (He et al, 2008).
The final transla-tion output outperforms each individual output sig-nificantly.2 Individual translation systems2.1 Phrase-based systemWe use the IBM model 1 and 4 (Brown et al, 1993)and Hidden-Markov model (HMM) (Vogel et al,1996) to train the word alignment using the mgizatoolkit1.
We applied the EMS in Moses (Koehn etal., 2007) to build up the phrase-based translationsystem.
Features in the log-linear model includetranslation models in two directions, a languagemodel, a distortion model and a sentence lengthpenalty.
A dynamic programming beam search al-gorithm is used to generate the translation hypoth-esis with maximum probability.
We applied a 5-gram mixture language model with each sub-modeltrained on one fifth of the monolingual corpus withKneser-Ney smoothing using SRILM toolkit (Stol-cke, 2002).
We did not perform any tuning, becauseit hurts the evaluation performance in our experi-ments.2.2 Syntax-based systemTo capture the syntactic structure, we also built atree-based system using the same configuration ofEMS in Moses (Koehn et al, 2007).
Tree-basedmodels operate on so-called grammar rules, whichinclude variables in the mapping rules.
To increasethe diversity of models in combination, the lan-guage model in each individual translation systemis trained differently.
For the tree-based system,we applied a 4-gram language model with Kneser-Ney smoothing using SRILM toolkit (Stolcke, 2002)trained on the whole monolingual corpus.
Thetest2007 news part is applied to tune the featureweights using mert, because the tuning on test20071http://geek.kyloo.net/software/doku.php/mgiza:overview485improves the translation performance more than thetuning on test2008 in a small-scale experiment forthe tree-based system.2.3 Hierarchical phrase-based systemFor the hierarchical system, we used the open sourcehierarchical phrased-based system Jane, developedat RWTH and free for non-commercial use (Vi-lar et al, 2010).
This approach is an extensionof the phrase-based approach, where the phrasesare allowed to have gaps (Chiang, 2007).
In thisway long-range dependencies and reorderings canbe modeled in a consistent statistical framework.The system uses a fairly standard setup, trainedusing the bilingual data provided by the organizers,word aligned using the mgiza.
Two 5-gram languagemodels were used during decoding: one trained onthe monolingual part of the bilingual training data,and a larger one trained on the additional news data.Decoding was carried out using the cube pruning al-gorithm.
The tuning is performed on test2008 with-out further experiments.2.4 Rule-based systemsWe applied two rule-based translation systems, theLucy system (Lucy, 2011) and the Linguatec sys-tem (Aleksic?
and Thurmair, 2011).
The Lucy sys-tem is a recent offspring of METAL.
The Linguatecsystem is a modular system consisting of grammar,lexicon and morphological analyzers based on logicprogramming using slot grammar.3 Hybrid translationA hybrid approach combining rule-based and sta-tistical machine translation is usually investigatedwith an in-box integration, such as multi-way trans-lation (Eisele et al, 2008), post-editing (Ueffing etal., 2008) or noun phrase substitution (Federmannet al, 2010).
However, significant improvementsover state-of-the-art statistical machine translationare still expected.
In the meanwhile system combi-nation methods for instance described in (Matusov,2009), (Sim et al, 2007) and (He et al, 2008) aremostly evaluated to combine statistical translationsystems, rule-based systems are not considered.
Inthis work, we integrate the rule-based and statisticalmachine translation system on the level of the finalPBT SyntaxPBT-2010 18.32Max80words 20.65 21.10Max100words 20.78+Compound 21.52 22.13+Newparallel 21.77Table 1: Translation performance BLEU[%] onphrase/syntax-based system using various settings eval-uated on test10.translation hypothesis and treat the rule-based sys-tem anonymously as an individual system.
In thisway an black-box integration is allowed using thecurrent system combination techniques.We applied the CMU open toolkit (Heafieldand Lavie, 2010) MEMT, a package by KennethHeafield to combine the translation hypotheses.
Thelanguage model is trained on the target side of theparallel training corpus using SRILM (Stolcke,2002).
We used only the Europarl part to train lan-guage models for tuning and all target side of paral-lel data to train language models for decoding.
Thebeam size is set to 80, and 300 nbest is considered.4 Translation experiments4.1 MT SetupThe parallel training corpus consists of 1.8million German-English parallel sentences fromEuroparl-v6 (Koehn, MT Summit 2005) and news-commentary with 48 million tokenized Germanwords and 54 million tokenized English words re-spectively.
The monolingual training corpus con-tains the target side of the parallel training cor-pus and the additional monolingual language modeltraining data downloaded from (SMT, 2011).
Wedid not apply the large-scale Gigaword corpus, be-cause it does not significantly reduce the perplexityof our language model but raises the computationalrequirement heavily.4.2 Single systemsFor each individual translation system, differentconfigurations are experimented to achieve a highertranslation quality.
We take phrase- and syntax-based translation system as examples.
Table 1presents official submission result on DE-EN by486PBT+Syntax 20.37PBT+Syntax+HPBT 20.78PBT+HPBT+Linguatec+Lucy 20.27PBT+Syntax+HPBT+Linguatec+Lucy 20.81Table 2: Translation performance BLEU[%] on test2011using hybrid system tuned on test10 with various settings(DE-EN).DFKI in 2010.
In 2010?s translation system onlyEuroparl parallel corpus was applied, and the trans-lation output was evaluated as 18.32% in the BLEUscore.
In 2011, we added the News Commentaryparallel corpus and trained the language model on allmonolingual data provided by (SMT, 2011) exceptfor Gigaword.
As shown in Table 1, if we increasethe maximum sentence length of the training cor-pus from 80 to 100, the BLEU score increases from20.65% to 20.78%.
In the error analysis, we foundthat many OOVs come from the compound wordsin German.
Therefore, we applied the compoundsplitting for both German and English by activatingthe corrensponding settings in the EMS in Moses.This leads to a further improvement of nearly 1%in the BLEU score.
As we add the new parallelcorpus provided on the homepage of SMT work-shop in 2011 (SMT, 2011) to the corpus in 2010,a slight improvement can be achieved.
Within oneyear, the score for the DFKI PBT system DE-EN hasimproved by nearly 3.5% absolute and 20% relativeBLEU score points, as shown in Table 1.In the phrase-based translation, the tuning was notapplied, because it improves the results on the held-out data but hurts the results on the evaluation set.In our observation, the decrease is in the range of0.01% to 1% in the BLEU score.
However tun-ing does help for the Tree-based system.
Thereforewe applied the test2007 to optimize the parameters,which enhanced the BLEU score from 17.52% to21.10%.
The compound splitting also improves thesyntax system, with about 1% in the BLEU score.We did not add the new parallel corpus into the train-ing for syntax system due to its larger computationalrequirement than that of the phrase-based system.Test10 Test08 Test11Hybrid-2010 17.43PBT 21.77 20.70 20.40Syntax 22.13 20.50 20.49HPBT 19.21 18.26 17.06Linguatec 16.59 16.07 15.97Lucy 16.57 16.66 16.68Hybrid-2011 23.88 21.13 21.25Table 3: Translation performance BLEU[%] on three testsets using different translation systems in 2011 submis-sion (DE-EN).Test10 Test11Hybrid-2010 14.42PBT 15.46 14.05Linguatec 14.92 12.92Lucy 13.77 13.0Hybrid-2011 15.55 15.83Table 4: Translation performance BLEU[%] on two testsets using different translation systems in 2011 submis-sion (EN-DE).4.3 Hybrid systemWe applied test10 as the held-out data to tunethe German-English and English-German transla-tion systems.
For experiments, we applied a small-scaled 4-gram language model trained only on thetarget side of the Europarl parallel training data.
Asshown in Table 2, different combinations are per-formed on the hypotheses generated from single sys-tems.
We first combined the PBT with syntax sys-tem, then together with the HPBT system.
Thetranslation result in the BLEU score performs bestwhen we combine all three statistical machine trans-lation systems and two rule-based systems together.4.4 Evaluation resultsFor the decoding during the WMT evaluation, weapplied a larger 4-gram language model trained onthe target side of all parallel training corpus.
Asshown in Table 3, in last year?s evaluation the DFKIhybrid translation result was evaluated as 17.34% inthe BLEU score.
In 2011, among all the transla-tion systems, the syntax system performs the beston test10 and test11, while the PBT performs the487SRC Diese Verordnung wurde vom Gesundheitsministerium in diesem Jahr einigermassen gemildert - die Ku?hlschrankpflicht fiel weg.REF It was mitigated by the Ministry of Health this year - the obligation to have a refrigerator has been removed.PBT This regulation by the Ministry of Health in this year - somewhat mitigated the fridge duty fell away.Syntax This regulation was somewhat mitigated by the Ministry of Health this year - the refrigerator duty fell away.HPBT This regulation was by the Ministry of Health in reasonably Dokvadze this year - the Ku?hlschrankpflicht fell away.Linguatec This ordinance was soothed to some extent by the brazilian ministry of health this year, the refrigerator duty was discontinued.Lucy This regulation was quite moderated by the Department of Health, Education and Welfare this year - the refrigerator duty was omitted.Hybrid This regulation was somewhat mitigated by the Ministry of Health this year - the fridge duty fell away.SRC Die Deregulierung und Bakalas ehemalige Bergarbeiterwohnungen sind ein brisantes Thema.REF Deregulation and Bakala ?s former mining flats are local hot topic.PBT The deregulation and Bakalas former miners?
homes are a sensitive issue.Syntax The deregulation and Bakalas former miners?
homes are a sensitive issue.HPBT The deregulation and Bakalas former Bergarbeiterwohnungen are a hot topic.Linguatec Former miner flats are an explosive topic the deregulation and Bakalas.HPBT The deregulation and Bakalas former miner apartments are an explosive topic.Hybrid The deregulation and Bakalas former miners?
apartments are a sensitive issue.Table 5: Examples of translation output by the different systems.best on test08.
The rule-based sytems, Linguatecand Lucy are expected to have a higher score in thehuman evaluation than in the automatic evaluation.Furthermore, as we can see from Table 3, there isstill room to improve the Jane system, with bettermodeling, configurations or even higher-order lan-guage model.
Using the hybrid system we success-fully improved the translation result to 23.88% ontest10.
The hybrid system outperforms the best sin-gle system by 0.43% and 0.76% in the BLEU scoreon the test08 and test11, respectively.For the translation from English to German, thetranslation result of last year?s submission was eval-uated as 14.42% in the BLEU score, as shown in Ta-ble 4.
In this year, the phrase-based translation resultis 15.46% in the BLEU score.
We only set up onestatistical translation system due to time limitation.With the respect of the BLEU score, phrase-basedtranslation outperforms rule-based translations.
Be-tween rule-based translation systems, Linguatec per-forms better on the test10 (14.92%) and Lucy per-forms better on the test11 (13.0%).
Combining threetranslation hypotheses leads to a smaller improve-ment (from 15.46% to 15.55%) on the test10 and agreater improvement (from 14.05% to 15.83%) onthe test11 in the BLEU score over the single besttranslation system.
Comparing to last year?s trans-lation output, the improvement is over one percentabsolutely (from 14.42% to 15.55%) in the BLEUscore on the test10.4.5 Output examplesTable 5 shows two translation examples from theMT output of the test2011.
We list the source sen-tence in German and its reference translation aswell as the translation results generated by differenttranslation systems.
As can be seen from Table 5,the translation quality of source sentences is greatlyimproved using the hybrid system over the single in-dividual systems.
Translations of words and wordorderings are more appropriate by the hybrid sys-tem.5 Conclusion and future workWe presented the DFKI hybrid translation systemsubmitted in the WMT workshop 2011.
The hy-brid translation is performed on the final translationoutput by individual systems, including a phrase-based system, a syntax-based system, a hierarchicalphrase-based system and two rule-based systems.Combining the results from statistical and rule-based systems significantly improved the translationperformance over the single-best system, which isshown by the automatic evaluation scores and theoutput examples.
Despite of the encouraging results,there is still room to improve our system, such as thetuning in the phrase-based translation and a betterlanguage model in the combination.488ReferencesVera Aleksic?
and Gregor Thurmair.
2011.
Personaltranslator at wmt2011 - a rule-based mt system withhybrid components.
In Proceedings of WMT work-shop.Peter F. Brown, Stephen A. Della Pietra, Vincent J. DellaPietra, and R. L. Mercer.
1993.
The mathematics ofstatistical machine translation: Parameter estimation.Computational Linguistics, 19(2):263?311, June.David Chiang.
2007.
Hierarchical phrase-based trans-lation.
Computational Linguistics, 33(2):201?228,June.Andreas Eisele, Christian Federmann, Hans Uszkoreit,Herve?
Saint-Amand, Martin Kay, Michael Jellinghaus,Sabine Hunsicker, Teresa Herrmann, and Yu Chen.2008.
Hybrid architectures for multi-engine machinetranslation.
In Proceedings of Translating and theComputer 30, pages ASLIB, ASLIB/IMI, London,United Kingdom, November.Christian Federmann, Andreas Eisele, Hans Uszkoreit,Yu Chen, Sabine Hunsicker, and Jia Xu.
2010.
Fur-ther experiments with shallow hybrid mt systems.
InProceedings of the Joint Fifth Workshop on StatisticalMachine Translation and MetricsMATR, pages 237?248, Uppsala, Sweden.
John Benjamins.Xiaodong He, Mei Yang, Jianfeng Gao, Patrick Nguyen,and Robert Moore.
2008.
Indirect-hmm-based hy-pothesis alignment for combining outputs from ma-chine translation systems.
In Proceedings of EMNLP,October.Kenneth Heafield and Alon Lavie.
2010.
Voting on n-grams for machine translation system combination.
InProc.
Ninth Conference of the Association for MachineTranslation in the Americas, Denver, Colorado, Octo-ber.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran, RichardZens, Chris Dyer, Ondrej Bojar, Alexandra Con-stantin, and Evan Herbst.
2007.
Moses: Open sourcetoolkit for statistical machine translation.
In Proceed-ings of ACL.Philipp Koehn.
MT Summit 2005.
Europarl: A parallelcorpus for statistical machine translation.Lucy.
2011.
Home page of software lucy and services.http://www.lucysoftware.com.Evgeny Matusov.
2009.
Combining Natural LanguageProcessing Systems to Improve Machine Translationof Speech.
Ph.D. thesis, Department of Electricaland Computer Engineering, Johns Hopkins University,Baltimore, MD.K.
C. Sim, W. J. Byrne, M. J. F. Gales, H. Sahbi, andP.
C. Woodland.
2007.
Consensus network decodingfor statistical machine translation system combination.In IN IEEE INT.
CONF.
ON ACOUSTICS, SPEECH,AND SIGNAL PROCESSING.SMT.
2011.
Sixth workshop on statistical machine trans-lation home page.
http://www.statmt.org/wmt11/.Andreas Stolcke.
2002.
SRILM - an extensible languagemodeling toolkit.
In Proceedings of the InternationalConference On Spoken Language Processing, pages901?904, Denver, Colorado, September.Nicola Ueffing, Jens Stephan, Evgeny Matusov, Lo icDugast, George F. Foster, Roland Kuhn, Jean Senel-lart, and Jin Yang.
2008.
Tighter integration of rule-based and statistical mt in serial system combination.In Proceedings of COLING 2008, pages 913?920.David Vilar, Daniel Stein, Matthias Huck, and HermannNey.
2010.
Jane: Open Source Hierarchical Trans-lation, Extended with Reordering and Lexicon Mod-els.
In Proceedings of the Joint Fifth Workshop on Sta-tistical Machine Translation and MetricsMATR, pages262?270, Uppsala, Sweden, July.Stephan Vogel, Hermann Ney, and Christoph Tillmann.1996.
HMM-based word alignment in statistical trans-lation.
In COLING ?96: The 16th Int.
Conf.
on Com-putational Linguistics, pages 836?841, Copenhagen,Denmark, August.489
