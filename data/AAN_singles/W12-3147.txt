Proceedings of the 7th Workshop on Statistical Machine Translation, pages 369?373,Montre?al, Canada, June 7-8, 2012. c?2012 Association for Computational LinguisticsLIUM?s SMT Machine Translation Systems for WMT 2012Christophe Servan, Patrik Lambert, Anthony Rousseau,Holger Schwenk and Lo?
?c BarraultLIUM, University of Le Mans72085 Le Mans cedex 9, FRANCEFirstName.LastName@lium.univ-lemans.frAbstractThis paper describes the development ofFrench?English and English?French statisti-cal machine translation systems for the 2012WMT shared task evaluation.
We developedphrase-based systems based on the Moses de-coder, trained on the provided data only.
Ad-ditionally, new features this year included im-proved language and translation model adap-tation using the cross-entropy score for thecorpus selection.1 IntroductionThis paper describes the statistical machine trans-lation systems developed by the Computer Sciencelaboratory at the University of Le Mans (LIUM) forthe 2012 WMT shared task evaluation.
We onlyconsidered the translation between French and En-glish (in both directions).
The main differences withrespect to previous year?s system (Schwenk et al,2011) are as follows: (i) use of more training data asprovided by the organizers and (ii) better selectionof the monolingual and parallel data according tothe domain, using the cross-entropy difference withrespect to in-domain and out-of-domain languagemodels (Moore and Lewis, 2010).
We kept someprevious features: the improvement of the transla-tion model adaptation by unsupervised training, aparallel corpus retrieved by Information Retrieval(IR) techniques and finally, the rescoring with a con-tinuous space target language model for the trans-lation into French.
These different points are de-scribed in the rest of the paper, together with a sum-mary of the experimental results showing the impactof each component.2 Resources UsedThe following sections describe how the resourcesprovided or allowed in the shared task were used totrain the translation and language models of the sys-tem.2.1 Bilingual dataThe latest version of the News-Commentary (NC)corpus and of the Europarl (Eparl) corpus (version7) were used.
We also took as training data a subsetof the French?English Gigaword (109) corpus.
Thisyear we changed the filters applied to select this sub-set (see Sect.
2.4).
We also included in the trainingdata the test sets from previous shared tasks, that wecalled the ntsXX corpus and which was composedof newstest2008, newstest2009, newssyscomb2009.2.2 Development dataDevelopment was initially done on newstest2010,and newstest2011 was used as internal test set (Sec-tion 3.1).
The development and internal test setswere then (Section 4) switched (tuning was doneon newstest2011 and internal evaluation on new-stest2010).
The default Moses tokenization wasused.
However, we added abbreviations for theFrench tokenizer.
All our models are case sensitiveand include punctuation.
The BLEU scores reportedin this paper were calculated with the mteval-v13tool and are case insensitive.2.3 Use of Automatic TranslationsAvailable human translated bitexts such as the Eu-roparl or 109 corpus seem to be out-of domain forthis task.
We used two types of automatically ex-tracted resources to adapt our system to the domain.369First, we generated automatic translations of theprovided monolingual News corpus in French andEnglish, for years 2009, 2010 and 2011, and selectedthe sentences with a normalised translation cost (re-turned by the decoder) inferior to a threshold.
Theresulting bitexts contain no new translations, sinceall words of the translation output come from thetranslation model, but they contain new combina-tions (phrases) of known words, and reinforce theprobability of some phrase pairs (Schwenk, 2008).Like last year, we directly used the word-to-wordalignments produced by the decoder at the outputinstead of GIZA?s alignments.
This speeds-up theprocedure and yields the same results in our experi-ments.
A detailed comparison is given in (Lambertet al, 2011).Second, as in last year?s evaluation, we auto-matically extracted and aligned parallel sentencesfrom comparable in-domain corpora.
We used theAFP (Agence France Presse) and APW (AssociatedPress Worldstream Service) news texts since thereare available in the French and English LDC Giga-word corpora.
The general architecture of our par-allel sentence extraction system is described in de-tail by Abdul-Rauf and Schwenk (2009).
We firsttranslated 91M words from French into English us-ing our first stage SMT system.
These English sen-tences were then used to search for translations inthe English AFP and APW texts of the Gigawordcorpus using information retrieval techniques.
TheLemur toolkit (Ogilvie and Callan, 2001) was usedfor this purpose.
Search was limited to a window of?5 days of the date of the French news text.
The re-trieved candidate sentences were then filtered usingthe Translation Error Rate (TER) with respect to theautomatic translations.
In this study, sentences witha TER below 75% were kept.
Sentences containinga large fraction of numbers were discarded.
By thesemeans, about 27M words of additional bitexts wereobtained.2.4 Domain-based Data selectionBefore training the target language models, a text se-lection has been made using the cross-entropy differ-ence method (Moore and Lewis, 2010).
This tech-nique works by computing the difference betweentwo cross-entropy values.We first score an out-of-domain corpus againsta language model trained on a set of in-domaindata and compute the cross-entropy for each sen-tence.
Then, we score the same out-of-domain cor-pus against a language model trained on a randomsample of itself, with a size roughly equal to the in-domain corpus.
From this point, the difference be-tween in-domain cross-entropy and out-of-domaincross-entropy is computed for each sentence, andthese sentences are sorted regarding this score.By estimating and minimizing on a developmentset the perplexity of several percentages of the sortedout-of-domain corpus, we can then estimate the the-oretical best point of data size for this specific cor-pus.
According the original paper and given our re-sults, this leads to better selection than the simpleperplexity sorting (Gao et al, 2002).
This way, wecan be assured to discard the vast majority of noisein the corpora and to select data well-related to thetask.In this task, the French and English target lan-guage models were trained on data selected from allprovided monolingual corpora.
In addition, LDC?sGigaword collection was used for both languages.Data corresponding to the development and test pe-riods were removed from the Gigaword collections.We had time to apply the domain-based data selec-tion only for French.
Thus all data were used forEnglish.We used this method to filter the French?English109 parallel corpus as well, based on the differ-ence between in-domain cross-entropy and out-of-domain cross-entropy calculated for each sentenceof the English side of the corpus.
We kept 49 mil-lion words (in the English side) to train our models,called 109f .3 Architecture of the SMT systemThe goal of statistical machine translation (SMT) isto produce a target sentence e from a source sentencef .
We have build phrase-based systems (Koehn etal., 2003; Och and Ney, 2003), using the standardlog linear framework in order to introduce severalmodels explaining the translation process:e?
= argmax p(e|f)= argmaxe{exp(?i?ihi(e, f))} (1)370The feature functions hi are the system modelsand the ?i weights are typically optimized to maxi-mize a scoring function on a development set (Och,2003).
The phrase-based system uses fourteen fea-tures functions, namely phrase and lexical transla-tion probabilities in both directions, seven featuresfor the lexicalized distortion model, a word and aphrase penalty and a target language model (LM).The system is based on the Moses SMT toolkit(Koehn et al, 2007) and is constructed as follows.First, word alignments in both directions are cal-culated.
We used a multi-threaded version of theGIZA++ tool (Gao and Vogel, 2008).1 This speedsup the process and corrects an error of GIZA++ thatcan appear with rare words.Phrases and lexical reorderings are extracted us-ing the default settings of the Moses toolkit.
Theparameters of Moses were tuned using the MERTtool.
We repeated the training process three times,each with a different seed value for the optimisationalgorithm.
In this way we have a rough idea of theerror introduced by the tuning process.4-gram back-off LMs were used.
The word listcontains all the words of the bitext used to train thetranslation model and all words that appear at leastten times in the monolingual corpora.
Words of themonolingual corpora containing special charactersor sequences of uppercase characters were not in-cluded in the word list.
Separate LMs were buildon each data source with the SRI LM toolkit (Stol-cke, 2002) and then linearly interpolated, optimizingthe coefficients with an EM procedure.
The perplex-ities of these LMs on newstest2011 were 119.1 forFrench and 174.8 for English.
In addition, we build a5-gram continuous space language model for French(Schwenk, 2007).
These models were trained onall the available texts using a resampling technique.The continuous space language model is interpo-lated with the 4-gram back-off model and used torescore n-best lists.
This reduces the perplexity byabout 13% relative.3.1 Number translationWe have also performed some experiments withnumber translation.
English and French do not use1The source is available at http://www.cs.cmu.edu/?qing/the same conventions for integer and decimal num-bers.
For example, the English decimal number 0.99is translated in French by 0,99.
In the same way,the English integer 32,000 is translated in French by32 000.
It should be possible to perform these mod-ifications by rules.In this study, we first replaced the numbers by atag @@NUM for integer and @@DEC for decimal num-bers.
Integers in the range 1 to 31 were not replacedsince they appear in dates.
Then, we created the tar-get language model using the tagged corpora.
Ta-ble 1 shows results of experiments performed withand without rule-based number translation.Corpus NT BLEU TERNC no 26.57 (0.07) 58.13 (0.06)NC yes 26.84 (0.15) 57.71 (0.34)Eparl+NC no 29.28 (0.11) 55.28 (0.13)Eparl+NC yes 29.26 (0.10) 55.44 (0.29)Table 1: Results of the study on number translation (NT)from English to FrenchWe did observe small gains in the translationquality when only the news-commentary bitexts areused, but there were no differences when more train-ing data is available.
Due to time constraints, thisprocedure was not used in the submitted system.4 Results and DiscussionThe results of our SMT systems are summarized inTable 2.
The MT metric scores for the developmentset are the average of three optimisations performedwith different seeds (see Section 3).
For the test set,they are the average of four values: the three val-ues corresponding to these different optimisations,plus a fourth value obtained by taking as weight foreach model, the average of the weights obtained inthe three optimisations (Cettolo et al, 2011).
Thenumbers in parentheses are the standard deviation ofthese three or four values.
The standard deviationgives a lower bound of the significance of the differ-ence between two systems.
If the difference betweentwo average scores is less than the sum of the stan-dard deviations, we can say that this difference is notsignificant.
The reverse is not true.The results of Table 2 show that adding severaladapted corpora (the filtered 109 corpus, the syn-371Bitext #Source newstest2011 newstest2010Words (M) BLEU TER BLEU TERTranslation : En?FrEparl+NC 57 30.91 (0.05) 53.61 (0.12) 28.45 (0.08) 56.29 (0.20)Eparl+NC+ntsXX 58 31.12 (0.08) 53.67 (0.08) 28.49 (0.04) 56.45 (0.12)Eparl+NC+ntsXX+109f 107 31.67 (0.06) 53.29 (0.03) 29.38 (0.12) 55.45 (0.15)Eparl+NC+ntsXX+109f+IR 133 32.41 (0.02) 52.20 (0.02) 29.48 (0.11) 55.33 (0.20)Eparl+NC+ntsXX+109f+news+IR 162 32.26 (0.04) 52.24 (0.12) 29.79 (0.12) 55.04 (0.20)Translation : Fr?EnEparl+NC 64 29.59 (0.12) 51.86 (0.06) 28.12 (0.05) 53.19 (0.06)Eparl+NC+ntsXX 64 29.59 (0.04) 51.89 (0.14) 28.32 (0.08) 53.22 (0.08)Eparl+NC+ntsXX+109f 120 30.69 (0.06) 50.77 (0.04) 28.95 (0.14) 52.62 (0.14)Eparl+NC+ntsXX+109f+IR 149 30.56 (0.02) 50.94 (0.15) 28.67 (0.11) 52.78 (0.06)Eparl+NC+ntsXX+109f+news+IR 179 30.85 (0.07) 50.72 (0.03) 28.94 (0.05) 52.57 (0.02)Table 2: English?French and French?English results: number of source words (in million) and scores on the develop-ment (newstest2011) and internal test (newstest2010) sets for the different systems developed.
The BLEU scores andthe number in parentheses are the average and standard deviation over 3 or 4 values when available (see Section 4.
)thetic corpus and the corpus retrieved via IR meth-ods) to the Eparl+NC+ntsXX baseline, a gain of 1.1BLEU points and 1.4 TER points was achieved forthe English?French system.On the other hand, adding the bitexts extractedfrom the comparable corpus (IR) does actually hurtthe performance of the French?English system: theBLEU score decreases from 28.95 to 28.67 on ourinternal test set.
During the evaluation period, weadded all the corpora at once and we observed thisonly in our analysis after the evaluation.In both translation directions ourbest system was the one trained onEparl+NC+ntsXX+109f+News+IR.
Finally, weapplied a continuous space language model for thesystem translating into French.AcknowledgmentsThis work has been partially funded by the Euro-pean Union under the EuroMatrixPlus project ICT-2007.2.2-FP7-231720 and the French governmentunder the ANR project COSMAT ANR-09-CORD-004.ReferencesSadaf Abdul-Rauf and Holger Schwenk.
2009.
On theuse of comparable corpora to improve SMT perfor-mance.
In Proceedings of the 12th Conference of theEuropean Chapter of the ACL (EACL 2009), pages 16?23, Athens, Greece.Mauro Cettolo, Nicola Bertoldi, and Marcello Federico.2011.
Methods for smoothing the optimizer instabilityin SMT.
In Proc.
of Machine Translation Summit XIII,Xiamen, China.Qin Gao and Stephan Vogel.
2008.
Parallel implemen-tations of word alignment tool.
In Software Engi-neering, Testing, and Quality Assurance for NaturalLanguage Processing, pages 49?57, Columbus, Ohio,June.
Association for Computational Linguistics.Jianfeng Gao, Joshua Goodman, Mingjing Li, and Kai-Fu Lee.
2002.
Toward a unified approach to statisticallanguage modeling for chinese.
In ACM Transactionson Asian Language Information Processing.Philipp Koehn, Franz Josef Och, and Daniel Marcu.2003.
Statistical phrased-based machine translation.In HLT/NACL, pages 127?133.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran, RichardZens, Chris Dyer, Ondrej Bojar, Alexandra Con-stantin, and Evan Herbst.
2007.
Moses: Open sourcetoolkit for statistical machine translation.
In ACL,demonstration session.Patrik Lambert, Holger Schwenk, Christophe Servan, andSadaf Abdul-Rauf.
2011.
Investigations on translation372model adaptation using monolingual data.
In SixthWorkshop on SMT, pages 284?293.Robert C. Moore and William Lewis.
2010.
Intelligentselection of language model training data.
In Proceed-ings of the ACL 2010 Conference Short Papers.Franz Josef Och and Hermann Ney.
2003.
A systematiccomparison of various statistical alignement models.Computational Linguistics, 29(1):19?51.Franz Josef Och.
2003.
Minimum error rate training instatistical machine translation.
In Proc.
of the AnnualMeeting of the Association for Computational Linguis-tics, pages 160?167.Paul Ogilvie and Jamie Callan.
2001.
Experiments usingthe Lemur toolkit.
In In Proceedings of the Tenth TextRetrieval Conference (TREC-10), pages 103?108.Holger Schwenk, Patrik Lambert, Lo?
?c Barrault,Christophe Servan, Sadaf Abdul-Rauf, Haithem Afli,and Kashif Shah.
2011.
Lium?s smt machine trans-lation systems for WMT 2011.
In Proceedings ofthe Sixth Workshop on Statistical Machine Translation,pages 464?469, Edinburgh, Scotland, July.
Associa-tion for Computational Linguistics.Holger Schwenk.
2007.
Continuous space languagemodels.
Computer Speech and Language, 21:492?518.Holger Schwenk.
2008.
Investigations on large-scale lightly-supervised training for statistical machinetranslation.
In IWSLT, pages 182?189.A.
Stolcke.
2002.
SRILM: an extensible language mod-eling toolkit.
In Proc.
of the Int.
Conf.
on Spoken Lan-guage Processing, pages 901?904, Denver, CO.373
