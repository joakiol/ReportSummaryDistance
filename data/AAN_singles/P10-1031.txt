Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 296?305,Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational LinguisticsUnsupervised Ontology Induction from TextHoifung Poon and Pedro DomingosDepartment of Computer Science & EngineeringUniversity of Washingtonhoifung,pedrod@cs.washington.eduAbstractExtracting knowledge from unstructuredtext is a long-standing goal of NLP.
Al-though learning approaches to many of itssubtasks have been developed (e.g., pars-ing, taxonomy induction, information ex-traction), all end-to-end solutions to daterequire heavy supervision and/or manualengineering, limiting their scope and scal-ability.
We present OntoUSP, a system thatinduces and populates a probabilistic on-tology using only dependency-parsed textas input.
OntoUSP builds on the USPunsupervised semantic parser by jointlyforming ISA and IS-PART hierarchies oflambda-form clusters.
The ISA hierar-chy allows more general knowledge tobe learned, and the use of smoothing forparameter estimation.
We evaluate On-toUSP by using it to extract a knowledgebase from biomedical abstracts and an-swer questions.
OntoUSP improves onthe recall of USP by 47% and greatlyoutperforms previous state-of-the-art ap-proaches.1 IntroductionKnowledge acquisition has been a major goal ofNLP since its early days.
We would like comput-ers to be able to read text and express the knowl-edge it contains in a formal representation, suit-able for answering questions and solving prob-lems.
However, progress has been difficult.
Theearliest approaches were manual, but the sheeramount of coding and knowledge engineeringneeded makes them very costly and limits them towell-circumscribed domains.
More recently, ma-chine learning approaches to a number of key sub-problems have been developed (e.g., Snow et al(2006)), but to date there is no sufficiently auto-matic end-to-end solution.
Most saliently, super-vised learning requires labeled data, which itself iscostly and infeasible for large-scale, open-domainknowledge acquisition.Ideally, we would like to have an end-to-end un-supervised (or lightly supervised) solution to theproblem of knowledge acquisition from text.
TheTextRunner system (Banko et al, 2007) can ex-tract a large number of ground atoms from theWeb using only a small number of seed patternsas guidance, but it is unable to extract non-atomicformulas, and the mass of facts it extracts is un-structured and very noisy.
The USP system (Poonand Domingos, 2009) can extract formulas and ap-pears to be fairly robust to noise.
However, it isstill limited to extractions for which there is sub-stantial evidence in the corpus, and in most cor-pora most pieces of knowledge are stated onlyonce or a few times, making them very difficult toextract without supervision.
Also, the knowledgeextracted is simply a large set of formulas with-out ontological structure, and the latter is essentialfor compact representation and efficient reasoning(Staab and Studer, 2004).We propose OntoUSP (Ontological USP), a sys-tem that learns an ISA hierarchy over clusters oflogical expressions, and populates it by translat-ing sentences to logical form.
OntoUSP is en-coded in a few formulas of higher-order Markovlogic (Domingos and Lowd, 2009), and can beviewed as extending USP with the capability toperform hierarchical (as opposed to flat) cluster-ing.
This clustering is then used to perform hier-archical smoothing (a.k.a.
shrinkage), greatly in-creasing the system?s capability to generalize from296sparse data.We begin by reviewing the necessary back-ground.
We then present the OntoUSP Markovlogic network and the inference and learning al-gorithms used with it.
Finally, experiments ona biomedical knowledge acquisition and questionanswering task show that OntoUSP can greatlyoutperform USP and previous systems.2 Background2.1 Ontology LearningIn general, ontology induction (constructing anontology) and ontology population (mapping tex-tual expressions to concepts and relations in theontology) remain difficult open problems (Staaband Studer, 2004).
Recently, ontology learn-ing has attracted increasing interest in both NLPand semantic Web communities (Cimiano, 2006;Maedche, 2002), and a number of machine learn-ing approaches have been developed (e.g., Snowet al (2006), Cimiano (2006), Suchanek et al(2008,2009), Wu & Weld (2008)).
However, theyare still limited in several aspects.
Most ap-proaches induce and populate a deterministic on-tology, which does not capture the inherent un-certainty among the entities and relations.
Be-sides, many of them either bootstrap from heuris-tic patterns (e.g., Hearst patterns (Hearst, 1992))or build on existing structured or semi-structuredknowledge bases (e.g., WordNet (Fellbaum, 1998)and Wikipedia1), thus are limited in coverage.Moreover, they often focus on inducing ontologyover individual words rather than arbitrarily largemeaning units (e.g., idioms, phrasal verbs, etc.
).Most importantly, existing approaches typicallyseparate ontology induction from population andknowledge extraction, and pursue each task in astandalone fashion.
While computationally effi-cient, this is suboptimal.
The resulted ontologyis disconnected from text and requires additionaleffort to map between the two (Tsujii, 2004).
Inaddition, this fails to leverage the intimate connec-tions between the three tasks for joint inferenceand mutual disambiguiation.Our approach differs from existing ones in twomain aspects: we induce a probabilistic ontologyfrom text, and we do so by jointly conducting on-tology induction, population, and knowledge ex-traction.
Probabilistic modeling handles uncer-tainty and noise.
A joint approach propagates in-1http : //www.wikipedia.orgformation among the three tasks, uncovers moreimplicit information from text, and can potentiallywork well even in domains not well covered byexisting resources like WordNet and Wikipedia.Furthermore, we leverage the ontology for hierar-chical smoothing and incorporate this smoothinginto the induction process.
This facilitates moreaccurate parameter estimation and better general-ization.Our approach can also leverage existing on-tologies and knowledge bases to conduct semi-supervised ontology induction (e.g., by incorpo-rating existing structures as hard constraints or pe-nalizing deviation from them).2.2 Markov LogicCombining uncertainty handling and joint infer-ence is the hallmark of the emerging field of statis-tical relational learning (a.k.a.
structured predic-tion), where a plethora of approaches have beendeveloped (Getoor and Taskar, 2007; Bakir et al,2007).
In this paper, we use Markov logic (Domin-gos and Lowd, 2009), which is the leading unify-ing framework, but other approaches can be usedas well.
Markov logic is a probabilistic exten-sion of first-order logic and can compactly specifyprobability distributions over complex relationaldomains.
It has been successfully applied to un-supervised learning for various NLP tasks suchas coreference resolution (Poon and Domingos,2008) and semantic parsing (Poon and Domingos,2009).
A Markov logic network (MLN) is a set ofweighted first-order clauses.
Together with a setof constants, it defines a Markov network with onenode per ground atom and one feature per groundclause.
The weight of a feature is the weight of thefirst-order clause that originated it.
The probabil-ity of a state x in such a network is given by thelog-linear model P (x) = 1Z exp (?i wini(x)),where Z is a normalization constant, wi is theweight of the ith formula, and ni is the numberof satisfied groundings.2.3 Unsupervised Semantic ParsingSemantic parsing aims to obtain a complete canon-ical meaning representation for input sentences.
Itcan be viewed as a structured prediction problem,where a semantic parse is formed by partitioningthe input sentence (or a syntactic analysis such asa dependency tree) into meaning units and assign-ing each unit to the logical form representing anentity or relation (Figure 1).
In effect, a semantic297inducesprotein CD11bnsubj dobjIL-4nninducesprotein CD11bnsubj dobjIL-4nnINDUCEINDUCER INDUCEDIL-4CD11BINDUCE(e1)INDUCER(e1,e2) INDUCED(e1,e3)IL-4(e2) CD11B(e3)IL-4 protein induces CD11bStructured prediction: Partition + AssignmentFigure 1: An example of semantic parsing.
Top:semantic parsing converts an input sentence intological form in Davidsonian semantics.
Bottom: asemantic parse consists of a partition of the depen-dency tree and an assignment of its parts.parser extracts knowledge from input text and con-verts them into logical form (the semantic parse),which can then be used in logical and probabilisticinference and support end tasks such as questionanswering.A major challenge to semantic parsing is syn-tactic and lexical variations of the same mean-ing, which abound in natural languages.
For ex-ample, the fact that IL-4 protein induces CD11bcan be expressed in a variety of ways, suchas, ?Interleukin-4 enhances the expression ofCD11b?, ?CD11b is upregulated by IL-4?, etc.Past approaches either manually construct a gram-mar or require example sentences with meaningannotation, and do not scale beyond restricted do-mains.Recently, we developed the USP system (Poonand Domingos, 2009), the first unsupervised ap-proach for semantic parsing.2 USP inputs de-pendency trees of sentences and first transformsthem into quasi-logical forms (QLFs) by convert-ing each node to a unary atom and each depen-dency edge to a binary atom (e.g., the node for?induces?
becomes induces(e1) and the subjectdependency becomes nsubj(e1, e2), where ei?sare Skolem constants indexed by the nodes.
).3For each sentence, a semantic parse comprises ofa partition of its QLF into subexpressions, eachof which has a naturally corresponding lambda2In this paper, we use a slightly different formulation ofUSP and its MLN to facilitate the exposition of OntoUSP.3We call these QLFs because they are not true logicalform (the ambiguities are not yet resolved).
This is relatedto but not identical with the definition in Alshawi (1990).Object Cluster: INDUCEinduces 0.1enhances 0.4?
?
?Property Cluster: INDUCER0.50.4?IL-4 0.2IL-8 0.1?None 0.1One 0.8?nsubjagentCore FormFigure 2: An example of object/property clusters:INDUCE contains the core-form property clusterand others, such as the agent argument INDUCER.form,4 and an assignment of each subexpressionto a lambda-form cluster.The lambda-form clusters naturally form an IS-PART hierarchy (Figure 2).
An object cluster cor-responds to semantic concepts or relations such asINDUCE, and contains a variable number of prop-erty clusters.
A special property cluster of coreforms maintains a distribution over variations inlambda forms for expressing this concept or rela-tion.
Other property clusters correspond to modi-fiers or arguments such as INDUCER (the agent ar-gument of INDUCE), each of which in turn con-tains three subclusters of property values: theargument-object subcluster maintains a distribu-tion over object clusters that may occur in thisargument (e.g., IL ?
4), the argument-form sub-cluster maintains a distribution over lambda formsthat corresponds to syntactic variations for this ar-gument (e.g., nsubj in active voice and agent inpassive voice), and the argument-number subclus-ter maintains a distribution over total numbers ofthis argument that may occur in a sentence (e.g.,zero if the argument is not mentioned).Effectively, USP simultaneously discovers thelambda-form clusters and an IS-PART hierarchyamong them.
It does so by recursively combiningsubexpressions that are composed with or by sim-ilar subexpressions.
The partition breaks a sen-tence into subexpressions that are meaning units,and the clustering abstracts away syntactic andlexical variations for the same meaning.
Thisnovel form of relational clustering is governed bya joint probability distribution P (T, L) defined inhigher-order5 Markov logic, where T are the inputdependency trees, and L the semantic parses.
The4The lambda form is derived by replacing every Skolemconstant ei that does not appear in any unary atom in thesubexpression with a lambda variable xi that is uniquely in-dexed by the corresponding node i.
For example, the lambdaform for nsubj(e1, e2) is ?x1?x2.nsubj(x1, x2).5Variables can range over arbitrary lambda forms.298main predicates are:e ?
c: expression e is assigned to cluster c;SubExpr(s, e): s is a subexpression of e;HasValue(s, v): s is of value v;IsPart(c, i, p): p is the property cluster in ob-ject cluster c uniquely indexed by i.In USP, property clusters in different object clus-ters use distinct index i?s.
As we will see later,in OntoUSP, property clusters with ISA relationshare the same index i, which corresponds to ageneric semantic frame such as agent and patient.The probability model of USP can be capturedby two formulas:x ?
+p ?
HasValue(x,+v)e ?
c ?
SubExpr(x, e) ?
x ?
p?
?1i.IsPart(c, i, p).All free variables are implicitly universallyquantified.
The ?+?
notation signifies that theMLN contains an instance of the formula, witha separate weight, for each value combination ofthe variables with a plus sign.
The first formula isthe core of the model and represents the mixtureof property values given the cluster.
The secondformula ensures that a property cluster must be apart in the corresponding object cluster; it is a hardconstraint, as signified by the period at the end.To encourage clustering, USP imposes an expo-nential prior over the number of parameters.To parse a new sentence, USP starts by parti-tioning the QLF into atomic forms, and then hill-climbs on the probability using a search operatorbased on lambda reduction until it finds the max-imum a posteriori (MAP) parse.
During learn-ing, USP starts with clusters of atomic forms,maintains the optimal semantic parses accordingto current parameters, and hill-climbs on the log-likelihood of observed QLFs using two search op-erators:MERGE(c1, c2) merges clusters c1, c2 into a largercluster c by merging the core-form clustersand argument clusters of c1, c2, respectively.E.g., c1 = {?induce?
}, c2 = {?enhance?
},and c = {?induce?, ?enhance?
}.COMPOSE(c1, c2) creates a new lambda-formcluster c formed by composing the lambdaforms in c1, c2 into larger ones.
E.g., c1 ={?amino?
}, c2 = {?acid?
}, and c ={?amino acid?
}.Each time, USP executes the highest-scored op-erator and reparses affected sentences using thenew parameters.
The output contains the optimallambda-form clusters and parameters, as well asthe MAP semantic parses of input sentences.3 Unsupervised Ontology Induction withMarkov LogicA major limitation of USP is that it either mergestwo object clusters into one, or leaves them sepa-rate.
This is suboptimal, because different objectclusters may still possess substantial commonali-ties.
Modeling these can help extract more gen-eral knowledge and answer many more questions.The best way to capture such commonalities isby forming an ISA hierarchy among the clusters.For example, INDUCE and INHIBIT are both sub-concepts of REGULATE.
Learning these ISA rela-tions helps answer questions like ?What regulatesCD11b?
?, when the text states that ?IL-4 inducesCD11b?
or ?AP-1 suppresses CD11b?.For parameter learning, this is also undesirable.Without the hierarchical structure, each cluster es-timates its parameters solely based on its own ob-servations, which can be extremely sparse.
Thebetter solution is to leverage the hierarchical struc-ture for smoothing (a.k.a.
shrinkage (McCallum etal., 1998; Gelman and Hill, 2006)).
For example,if we learn that ?super-induce?
is a verb and that ingeneral verbs have active and passive voices, theneven though ?super-induce?
only shows up oncein the corpus as in ?AP-1 is super-induced by IL-4?, by smoothing we can still infer that this proba-bly means the same as ?IL-4 super-induces AP-1?,which in turn helps answer questions like ?Whatsuper-induces AP-1?.OntoUSP overcomes the limitations of USP byreplacing the flat clustering process with a hier-archical clustering one, and learns an ISA hier-archy of lambda-form clusters in addition to theIS-PART one.
The output of OntoUSP consistsof an ontology, a semantic parser, and the MAPparses.
In effect, OntoUSP conducts ontology in-duction, population, and knowledge extraction in asingle integrated process.
Specifically, given clus-ters c1, c2, in addition to merge vs. separate, On-toUSP evaluates a third option called abstraction,in which a new object cluster c is created, and ISAlinks are added from ci to c; the argument clustersin c are formed by merging that of ci?s.In the remainder of the section, we describe the299details of OntoUSP.
We start by presenting theOntoUSP MLN.
We then describe our inferencealgorithm and how to parse a new sentence us-ing OntoUSP.
Finally, we describe the learning al-gorithm and how OntoUSP induces the ontologywhile learning the semantic parser.3.1 The OntoUSP MLNThe OntoUSP MLN can be obtained by modifyingthe USP MLN with three simple changes.
First,we introduce a new predicate IsA(c1, c2), whichis true if cluster c1 is a subconcept of c2.
For con-venience, we stipulate that IsA is reflexive (i.e.,IsA(c, c) is true for any c).
Second, we add twoformulas to the MLN:IsA(c1, c2) ?
IsA(c2, c3) ?
IsA(c1, c3).IsPart(c1, i1, p1) ?
IsPart(c2, i2, p2)?
IsA(c1, c2) ?
(i1 = i2 ?
IsA(p1, p2)).The first formula simply enforces the transitivityof ISA relation.
The second formula states that ifthe ISA relation holds for a pair of object clusters,it also holds between their corresponding propertyclusters.
Both are hard constraints.
Third, we in-troduce hierarchical smoothing into the model byreplacing the USP mixture formulax ?
+p ?
HasValue(x,+v)with a new formulaISA(p1,+p2) ?
x ?
p1 ?
HasValue(x,+v)Intuitively, for each p2, the weight corresponds tothe delta in log-probability of v comparing to theprediction according to all ancestors of p2.
Theeffect of this change is that now the value v ofa subexpression x is not solely determined by itsproperty cluster p1, but is also smoothed by statis-tics of all p2 that are super clusters of p1.Shrinkage takes place via interaction among theweights of the ISA mixture formula.
In particular,if the weights for some property cluster p are allzero, it means that values in p are completely pre-dicted by p?s ancestors.
In effect, p is backed offto its parent.3.2 InferenceGiven the dependency tree T of a sentence, theconditional probability of a semantic parse L isgiven by Pr(L|T ) ?
exp (?i wini(T,L)).The MAP semantic parse is simplyAlgorithm 1 OntoUSP-Parse(MLN, T )Initialize semantic parse L with individualatoms in the QLF of Trepeatfor all subexpressions e in L doEvaluate all semantic parses that arelambda-reducible from eend forL?
the new semantic parse with the highestgain in probabilityuntil none of these improve the probabilityreturn LargmaxL?i wini(T, L).
Directly enumer-ating all L?s is intractable.
OntoUSP uses thesame inference algorithm as USP by hill-climbingon the probability of L; in each step, OntoUSPevaluates the alternative semantic parses thatcan be formed by lambda-reducing a currentsubexpression with one of its arguments.
The onlydifference is that OntoUSP uses a different MLNand so the probabilities and resulting semanticparses may be different.
Algorithm 1 givespseudo-code for OntoUSP?s inference algorithm.3.3 LearningOntoUSP uses the same learning objective as USP,i.e., to find parameters ?
that maximizes the log-likelihood of observing the dependency trees T ,summing out the unobserved semantic parses L:L?
(T ) = logP?
(L)= log?L P?
(T, L)However, the learning problem in OntoUSP isdistinct in two important aspects.
First, OntoUSPlearns in addition an ISA hierarchy among thelambda-form clusters.
Second and more impor-tantly, OntoUSP leverages this hierarchy duringlearning to smooth the parameter estimation of in-dividual clusters, as embodied by the new ISAmixture formula in the OntoUSP MLN.OntoUSP faces several new challenges unseenin previous hierarchical-smoothing approaches.The ISA hierarchy in OntoUSP is not known inadvance, but needs to be learned as well.
Simi-larly, OntoUSP has no known examples of pop-ulated facts and rules in the ontology, but has toinfer that in the same joint learning process.
Fi-nally, OntoUSP does not start from well-formedstructured input like relational tuples, but ratherdirectly from raw text.
In sum, OntoUSP tackles a300Algorithm 2 OntoUSP-Learn(MLN, T?s)Initialize with a flat ontology, along with clus-ters and semantic parsesMerge clusters with the same core formAgenda ?
?repeatfor all candidate operations O doScore O by log-likelihood improvementif score is above a threshold thenAdd O to agendaend ifend forExecute the highest scoring operation O?
inthe agendaRegenerate MAP parses for affected trees andupdate agenda and candidate operationsuntil agenda is emptyreturn the learned ontology and MLN, and thesemantic parsesvery hard problem with exceedingly little aid fromuser supervision.To combat these challenges, OntoUSP adoptsa novel form of hierarchical smoothing by inte-grating it with the search process for identify-ing the hierarchy.
Algorithm 2 gives pseudo-code for OntoUSP?s learning algorithm.
LikeUSP, OntoUSP approximates the sum over allsemantic parses with the most probable parse,and searches for both ?
and the MAP semanticparses L that maximize P?(T,L).
In addition toMERGE and COMPOSE, OntoUSP uses a new opera-tor ABSTRACT(c1, c2), which does the following:1.
Create an abstract cluster c;2.
Create ISA links from c1, c2 to c;3.
Align property clusters of c1 and c2; for eachaligned pair p1 and p2, either merge theminto a single property cluster, or create an ab-stract property cluster p in c and create ISAlinks from pi to p, so as to maximize log-likelihood.Intuitively, c corresponds to a more abstract con-cept that summarizes similar properties in ci?s.To add a child cluster c2 to an existing ab-stract cluster c1, OntoUSP also uses an operatorADDCHILD(c1, c2) that does the following:1.
Create an ISA link from c2 to c1;2.
For each property cluster of c2, maximize thelog-likelihood by doing one of the following:merge it with a property cluster in an exist-ing child of c1; create ISA link from it toan abstract property cluster in c; leave it un-changed.For efficiency, in both operators, the best optionis chosen greedily for each property cluster in c2,in descending order of cluster size.Notice that once an abstract cluster is created,it could be merged with an existing cluster usingMERGE.
Thus with the new operators, OntoUSPis capable of inducing any ISA hierarchy amongabstract and existing clusters.
(Of course, the ISAhierarchy it actually induces depends on the data.
)Learning the shrinkage weights has been ap-proached in a variety of ways; examples includeEM and cross-validation (McCallum et al, 1998),hierarchical Bayesian methods (Gelman and Hill,2006), and maximum entropy with L1 priors(Dudik et al, 2007).
The past methods either onlylearn parameters with one or two levels (e.g., inhierarchical Bayes), or requires significant amountof computation (e.g., in EM and in L1-regularizedmaxent), while also typically assuming a givenhierarchy.
In contrast, OntoUSP has to both in-duce the hierarchy and populate it, with potentiallymany levels in the induced hierarchy, starting fromraw text with little user supervision.Therefore, OntoUSP simplifies the weightlearning problem by adopting standard m-estimation for smoothing.
Namely, the weightsfor cluster c are set by counting its observationsplus m fractional samples from its parent distribu-tion.
When c has few observations, its unreliablestatistics can be significantly augmented via thesmoothing by its parent (and in turn to a graduallysmaller degree by its ancestors).
m is a hyperpa-rameter that can be used to trade off bias towardsstatistics for parent vs oneself.OntoUSP also needs to balance between twoconflicting aspects during learning.
On one hand,it should encourage creating abstract clusters tosummarize intrinsic commonalities among thechildren.
On the other hand, this needs to be heav-ily regularized to avoid mistaking noise for the sig-nal.
OntoUSP does this by a combination of priorsand thresholding.
To encourage the induction ofhigher-level nodes and inheritance, OntoUSP im-poses an exponential prior ?
on the number of pa-rameter slots.
Each slot corresponds to a distinctproperty value.
A child cluster inherits its parent?sslots (and thus avoids the penalty on them).
On-301toUSP also stipulates that, in an ABSTRACT opera-tion, a new property cluster can be created either asa concrete cluster with full parameterization, or asan abstract cluster that merely serves for smooth-ing purposes.
To discourage overproposing clus-ters and ISA links, OntoUSP imposes a large ex-ponential prior ?
on the number of concrete clus-ters created by ABSTRACT.
For abstract cluster, itsets a cut-off tp and only allows storing a probabil-ity value no less than tp.
Like USP, it also rejectsMERGE and COMPOSE operations that improve log-likelihood by less than to.
These priors and cut-offvalues can be tuned to control the granularity ofthe induced ontology and clusters.Concretely, given semantic parses L, OntoUSPcomputes the optimal parameters and evaluatesthe regularized log-likelihood as follows.
Letwp2,v denote the weight of the ISA mixture for-mula ISA(p1,+p2)?
x ?
p1 ?
HasValue(x,+v).For convenience, for each pair of property clus-ter c and value v, OntoUSP instead computesand stores w?c,v =?ISA(c, a)wa,v, which sumsover all weights for c and its ancestors.
(Thuswc,v = w?c,v ?
w?p,v, where p is the parent ofc.)
Like USP, OntoUSP imposes local normal-ization constraints that enable closed-form esti-mation of the optimal parameters and likelihood.Specifically, using m-estimation, the optimal w?c,vis log((m ?ew?p,v +nc,v)/(m+nc)), where p is theparent of c and n is the count.
The log-likelihoodis ?c,v w?c,v ?nc,v, which is then augmented by thepriors.4 Experiments4.1 MethodologyEvaluating unsupervised ontology induction is dif-ficult, because there is no gold ontology for com-parison.
Moreover, our ultimate goal is to aidknowledge acquisition, rather than just inducingan ontology for its own sake.
Therefore, weused the same methodology and dataset as theUSP paper to evaluate OntoUSP on its capabil-ity in knowledge acquisition.
Specifically, we ap-plied OntoUSP to extract knowledge from the GE-NIA dataset (Kim et al, 2003) and answer ques-tions, and we evaluated it on the number of ex-tracted answers and accuracy.
GENIA contains1999 PubMed abstracts.6 The question set con-6http://www-tsujii.is.s.u-tokyo-.ac.jp/GENIA/home/wiki.cgi.tains 2000 questions which were created by sam-pling verbs and entities according to their frequen-cies in GENIA.
Sample questions include ?Whatregulates MIP-1alpha?
?, ?What does anti-STAT 1inhibit??.
These simple question types were usedto focus the evaluation on the knowledge extrac-tion aspect, rather than engineering for handlingspecial question types and/or reasoning.4.2 SystemsOntoUSP is the first unsupervised approach thatsynergistically conducts ontology induction, pop-ulation, and knowledge extraction.
The systemclosest in aim and capability is USP.
We thus com-pared OntoUSP with USP and all other systemsevaluated in the USP paper (Poon and Domingos,2009).
Below is a brief description of the systems.
(For more details, see Poon & Domingos (2009).
)Keyword is a baseline system based on keywordmatching.
It directly matches the question sub-string containing the verb and the available argu-ment with the input text, ignoring case and mor-phology.
Given a match, two ways to derive theanswer were considered: KW simply returns therest of sentence on the other side of the verb,whereas KW-SYN is informed by syntax and ex-tracts the answer from the subject or object of theverb, depending on the question (if the expectedargument is absent, the sentence is ignored).TextRunner (Banko et al, 2007) is the state-of-the-art system for open-domain information ex-traction.
It inputs text and outputs relational triplesin the form (R,A1, A2), where R is the relationstring, and A1, A2 the argument strings.
To an-swer questions, each triple-question pair is consid-ered in turn by first matching their relation strings,and then the available argument strings.
If bothmatch, the remaining argument string in the tripleis returned as an answer.
Results were reportedwhen exact match is used (TR-EXACT), or whenthe triple strings may contain the question ones assubstrings (TR-SUB).RESOLVER (Yates and Etzioni, 2009) inputsTextRunner triples and collectively resolves coref-erent relation and argument strings.
To answerquestions, the only difference from TextRunner isthat a question string can match any string in itscluster.
As in TextRunner, results were reportedfor both exact match (RS-EXACT) and substring(RS-SUB).DIRT (Lin and Pantel, 2001) resolves binary rela-302Table 1: Comparison of question answering re-sults on the GENIA dataset.
Results for systemsother than OntoUSP are from Poon & Domingos(2009).# Total # Correct AccuracyKW 150 67 45%KW-SYN 87 67 77%TR-EXACT 29 23 79%TR-SUB 152 81 53%RS-EXACT 53 24 45%RS-SUB 196 81 41%DIRT 159 94 59%USP 334 295 88%OntoUSP 480 435 91%tions by inputting a dependency path that signifiesthe relation and returns a set of similar paths.
Touse DIRT in question answering, it was queried toobtain similar paths for the relation of the ques-tion, which were then used to match sentences.USP (Poon and Domingos, 2009) parses the in-put text using the Stanford dependency parser(Klein and Manning, 2003; de Marneffe et al,2006), learns an MLN for semantic parsing fromthe dependency trees, and outputs this MLN andthe MAP semantic parses of the input sentences.These MAP parses formed the knowledge base(KB).
To answer questions, USP first parses thequestions (with the question slot replaced by adummy word), and then matches the questionparse to parses in the KB by testing subsumption.OntoUSP uses a similar procedure as USP for ex-tracting knowledge and answering questions, ex-cept for two changes.
First, USP?s learning andparsing algorithms are replaced with OntoUSP-Learn and OntoUSP-Parse, respectively.
Second,when OntoUSP matches a question to its KB, itnot only considers the lambda-form cluster of thequestion relation, but also all its sub-clusters.74.3 ResultsTable 1 shows the results comparing OntoUSPwith other systems.
While USP already greatlyoutperformed other systems in both precision andrecall, OntoUSP further substantially improved onthe recall of USP, without any loss in precision.In particular, OntoUSP extracted 140 more correctanswers than USP, for a gain of 47% in absolute7Additional details are available athttp : //alchemy.cs.washington.edu/papers/poon10.ISA ISAINHIBITinduce, enhance, trigger, augment, up-regulateINDUCEinhibit, block, suppress, prevent, abolish, abrogate, down-regulateactivateregulate, control, govern, modulateISAACTIVATEREGULATEFigure 3: A fragment of the induced ISA hierar-chy, showing the core forms for each cluster (thecluster labels are added by the authors for illustra-tion purpose).recall.
Compared to TextRunner (TR-SUB), On-toUSP gained on precision by 38 points and ex-tracted more than five times of correct answers.Manual inspection shows that the induced ISAhierarchy is the key for the recall gain.
LikeUSP, OntoUSP discovered the following clusters(in core forms) that represent some of the coreconcepts in biomedical research:{regulate, control, govern, modulate}{induce, enhance, trigger, augment, up-regulate}{inhibit, block, suppress, prevent, abolish, ab-rogate, down-regulate}However, USP formed these as separate clusters,whereas OntoUSP in addition induces ISA rela-tions from the INDUCE and INHIBIT clusters tothe REGULATE cluster (Figure 3).
This allowsOntoUSP to answer many more questions thatare asked about general regulation events, eventhough the text states them with specific regula-tion directions like ?induce?
or ?inhibit?.
Belowis an example question-answer pair output by On-toUSP; neither USP nor any other system wereable to extract the necessary knowledge.Q: What does IL-2 control?A: The DEX-mediated IkappaBalpha induc-tion.Sentence: Interestingly, the DEX-mediatedIkappaBalpha induction was completely inhibitedby IL-2, but not IL-4, in Th1 cells, while the re-verse profile was seen in Th2 cells.OntoUSP also discovered other interestingcommonalities among the clusters.
For exam-ple, both USP and OntoUSP formed a singletoncluster with core form ?activate?.
Although thiscluster may appear similar to the INDUCE clus-ter, the data in GENIA does not support merg-ing the two.
However, OntoUSP discovered that303the ACTIVATE cluster, while not completely resol-vent with INDUCE, shared very similar distribu-tions in their agent arguments.
In fact, they areso similar that OntoUSP merges them into a sin-gle property cluster.
It found that the patient ar-guments of INDUCE and INHIBIT are very similarand merged them.
In turn, OntoUSP formed ISAlinks from these three object clusters to REGULATE,as well as among their property clusters.
In-tuitively, this makes sense.
The positive- andnegative-regulation events, as signified by INDUCEand INHIBIT, often target similar object entitiesor processes.
However, their agents tend to differsince in one case they are inducers, and in the otherthey are inhibitors.
On the other hand, ACTIVATEand INDUCE share similar agents since they bothsignify positive regulation.
However, ?activate?tends to be used more often when the patient ar-gument is a concrete entity (e.g., cells, genes, pro-teins), whereas ?induce?
and others are also usedwith processes and events (e.g., expressions, inhi-bition, pathways).USP was able to resolve common syntactic dif-ferences such as active vs. passive voice.
How-ever, it does so on the basis of individual verbs,and there is no generalization beyond their clus-ters.
OntoUSP, on the other hand, formed a high-level cluster with two abstract property clusters,corresponding to general agent argument and pa-tient argument.
The active-passive alternation iscaptured in these clusters, and is inherited by alldescendant clusters, including many rare verbslike ?super-induce?
which only occur once in GE-NIA and for which there is no way that USPcould have learned about their active-passive al-ternations.
This illustrates the importance of dis-covering ISA relations and performing hierarchi-cal smoothing.4.4 DiscussionOntoUSP is a first step towards joint ontology in-duction and knowledge extraction.
The experi-mental results demonstrate the promise in this di-rection.
However, we also notice some limitationsin the current system.
While OntoUSP inducedmeaningful ISA relations among relation clusterslike REGULATE, INDUCE, etc., it was less success-ful in inducing ISA relations among entity clus-ters such as specific genes and proteins.
This isprobably due to the fact that our model only con-siders local features such as the parent and argu-ments.
A relation is often manifested as verbs andhas several arguments, whereas an entity typicallyappears as an argument of others and has few ar-guments of its own.
As a result, in average, thereis less information available for entities than rela-tions.
Presumably, we can address this limitationby modeling longer-ranged dependencies such asgrandparents, siblings, etc.
This is straightforwardto do in Markov logic.OntoUSP also uses a rather elaborate schemefor regularization.
We hypothesize that this canbe much simplified and improved by adopting aprincipled framework such as Dudik et al (2007).5 ConclusionThis paper introduced OntoUSP, the first unsuper-vised end-to-end system for ontology inductionand knowledge extraction from text.
OntoUSPbuilds on the USP semantic parser by adding thecapability to form hierarchical clusterings of logi-cal expressions, linked by ISA relations, and us-ing them for hierarchical smoothing.
OntoUSPgreatly outperformed USP and other state-of-the-art systems in a biomedical knowledge acquisitiontask.Directions for future work include: exploitingthe ontological structure for principled handling ofantonyms and (more generally) expressions withopposite meanings; developing and testing alter-nate methods for hierarchical modeling in On-toUSP; scaling up learning and inference to largercorpora; investigating the theoretical properties ofOntoUSP?s learning approach and generalizing itto other tasks; answering questions that require in-ference over multiple extractions; etc.6 AcknowledgementsWe give warm thanks to the anonymous reviewers fortheir comments.
This research was partly funded by AROgrant W911NF-08-1-0242, AFRL contract FA8750-09-C-0181, DARPA contracts FA8750-05-2-0283, FA8750-07-D-0185, HR0011-06-C-0025, HR0011-07-C-0060 and NBCH-D030010, NSF grants IIS-0534881 and IIS-0803481, andONR grant N00014-08-1-0670.
The views and conclusionscontained in this document are those of the authors andshould not be interpreted as necessarily representing the offi-cial policies, either expressed or implied, of ARO, DARPA,NSF, ONR, or the United States Government.ReferencesHiyan Alshawi.
1990.
Resolving quasi logical forms.
Com-putational Linguistics, 16:133?144.G.
Bakir, T. Hofmann, B.
B. Scho?lkopf, A. Smola, B. Taskar,304S.
Vishwanathan, and (eds.).
2007.
Predicting StructuredData.
MIT Press, Cambridge, MA.Michele Banko, Michael J. Cafarella, Stephen Soderland,Matt Broadhead, and Oren Etzioni.
2007.
Open informa-tion extraction from the web.
In Proceedings of the Twen-tieth International Joint Conference on Artificial Intelli-gence, pages 2670?2676, Hyderabad, India.
AAAI Press.Philipp Cimiano.
2006.
Ontology learning and populationfrom text.
Springer.Marie-Catherine de Marneffe, Bill MacCartney, and Christo-pher D. Manning.
2006.
Generating typed dependencyparses from phrase structure parses.
In Proceedings of theFifth International Conference on Language Resourcesand Evaluation, pages 449?454, Genoa, Italy.
ELRA.Pedro Domingos and Daniel Lowd.
2009.
Markov Logic:An Interface Layer for Artificial Intelligence.
Morgan &Claypool, San Rafael, CA.Miroslav Dudik, David Blei, and Robert Schapire.
2007.
Hi-erarchical maximum entropy density estimation.
In Pro-ceedings of the Twenty Fourth International Conferenceon Machine Learning.Christiane Fellbaum, editor.
1998.
WordNet: An ElectronicLexical Database.
MIT Press, Cambridge, MA.Andrew Gelman and Jennifer Hill.
2006.
Data Analysis Us-ing Regression and Multilevel/Hierarchical Models.
Cam-bridge University Press.Lise Getoor and Ben Taskar, editors.
2007.
Introduction toStatistical Relational Learning.
MIT Press, Cambridge,MA.Marti Hearst.
1992.
Automatic acquisition of hyponymsfrom large text corpora.
In Proceedings of the 14th In-ternational Conference on Computational Linguistics.Jin-Dong Kim, Tomoko Ohta, Yuka Tateisi, and Jun?ichi Tsu-jii.
2003.
GENIA corpus - a semantically annotated cor-pus for bio-textmining.
Bioinformatics, 19:180?82.Dan Klein and Christopher D. Manning.
2003.
Accurateunlexicalized parsing.
In Proceedings of the Forty FirstAnnual Meeting of the Association for Computational Lin-guistics, pages 423?430.Dekang Lin and Patrick Pantel.
2001.
DIRT - discovery ofinference rules from text.
In Proceedings of the SeventhACM SIGKDD International Conference on KnowledgeDiscovery and Data Mining, pages 323?328, San Fran-cisco, CA.
ACM Press.Alexander Maedche.
2002.
Ontology learning for the se-mantic Web.
Kluwer Academic Publishers, Boston, Mas-sachusetts.Andrew McCallum, Ronald Rosenfeld, Tom Mitchell, andAndrew Ng.
1998.
Improving text classification byshrinkage in a hierarchy of classes.
In Proceedings of theFifteenth International Conference on Machine Learning.Hoifung Poon and Pedro Domingos.
2008.
Joint unsuper-vised coreference resolution with Markov logic.
In Pro-ceedings of the 2008 Conference on Empirical Methods inNatural Language Processing, pages 649?658, Honolulu,HI.
ACL.Hoifung Poon and Pedro Domingos.
2009.
Unsupervisedsemantic parsing.
In Proceedings of the 2009 Conferenceon Empirical Methods in Natural Language Processing,pages 1?10, Singapore.
ACL.Rion Snow, Daniel Jurafsky, and Andrew Ng.
2006.
Seman-tic taxonomy induction from heterogenous evidence.
InProceedings of COLING/ACL 2006.S.
Staab and R. Studer.
2004.
Handbook on ontologies.Springer.Fabian Suchanek, Gjergji Kasneci, and Gerhard Weikum.2008.
Yago - a large ontology from Wikipedia and Word-Net.
Journal of Web Semantics.Fabian Suchanek, Mauro Sozio, and Gerhard Weikum.
2009.Sofie: A self-organizing framework for information ex-traction.
In Proceedings of the Eighteenth InternationalConference on World Wide Web.Jun-ichi Tsujii.
2004.
Thesaurus or logical ontology, whichdo we need for mining text?
In Proceedings of the Lan-guage Resources and Evaluation Conference.Fei Wu and Daniel S. Weld.
2008.
Automatically refining thewikipedia infobox ontology.
In Proceedings of the Seven-teenth International Conference on World Wide Web, Bei-jing, China.Alexander Yates and Oren Etzioni.
2009.
Unsupervisedmethods for determining object and relation synonymson the web.
Journal of Artificial Intelligence Research,34:255?296.305
