Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 713?720Manchester, August 2008Almost Flat Functional Semantics for Speech TranslationManny Rayner1, Pierrette Bouillon1, Beth Ann Hockey2, Yukie Nakao31 University of Geneva, TIM/ISSCO40 bvd du Pont-d?ArveCH-1211 Geneva 4, SwitzerlandEmmanuel.Rayner@issco.unige.chPierrette.Bouillon@issco.unige.ch2 UCSC UARC, Mail Stop 19-26NASA Ames Research CenterMoffet Field, CA 94035bahockey@ucsc.edu3 University of Nantes, LINA2, rue de la Houssinie`reBP 92208 44322 Nantes Cedex 03yukie.nakao@univ-nantes.frAbstractWe introduce a novel semantic represen-tation formalism, Almost Flat Functionalsemantics (AFF), which is designed as anintelligent compromise between linguis-tically motivated predicate/argument se-mantics and ad hoc engineering solutionsbased on flat feature/value lists; the cen-tral idea is to tag each semantic elementwith the functional marking which mostclosely surrounds it.
We argue that AFF iswell-suited for medium-vocabulary speechtranslation applications, and describe sim-ple and general algorithms for parsing,generating and performing transfer usingAFF representations.
The formalism hasbeen fully implemented within a medium-vocabulary interlingua-based Open Sourcespeech translation system which translatesbetween English, French, Japanese andArabic.1 IntroductionMany speech translation architectures requiresome way to represent the meaning of spoken ut-terances, but even a brief review of the literaturereveals a serious divergence of opinion as to howthis may best be done.
At risk of oversimplifyinga little, there are two competing heritages.
On theone hand, there is the mainstream computationalsemantics approach, which ultimately goes backto philosophers like Montague, Russell and Fregeand views predicate calculus as the paradigm rep-resentation language.
On this view of things, ac?
2008.
Licensed under the Creative CommonsAttribution-Noncommercial-Share Alike 3.0 Unported li-cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).Some rights reserved.suitable way to represent meaning is to use com-plex structures, in which components and relation-ships are based on deep grammatical functions.Typical ways to realise this strategy are unscopedlogical forms, neo-Davidsonian semantics, mini-mal recursion semantics, and similar formalisms.Thus a sentence like ?I want a pepperoni pizza?might be represented as something likewant1(E, X, Y),ref(X, pronoun(i)),quant(Y, indef), pizza1(Y),pepperoni1(Z), nn(Z, Y)Approaches based in the linguistic tradition weredominant about 10 to 15 years ago, when they wereused in major systems like Germany?s Verbmo-bil (Wahlster, 2000) and SRI?s Spoken LanguageTranslator (Rayner et al, 2000).
They are stillreasonably popular today, as exemplified by majorsystems like PARC?s XLE (Riezler et al, 2002).The competing heritage has its roots in engi-neering approaches to spoken language systems,which historically have been intimately connectedwith Machine Learning.
On this view of things,a typical semantic representation is a flat list offeature-value pairs, with the features represent-ing semantic concepts: here, ?I want a pepperonipizza?
would be represented as something like[utterance_type=request,food=pizza, type=pepperoni]It is interesting to see how little contact therehas been between these two traditions.
Writerson formal semantics usually treat ad hoc feature-value representations as not even worthy of seriousdiscussion.
Conversely, proponents of engineer-ing/machine learning approaches often assume inpractice that all semantic representations will besome version of a flat feature-value list; a good713example of this tendency is Young?s widely cited2002 survey of machine learning approaches tospoken dialogue (Young, 2002).Trying to be as neutral as possible, it is reason-able to argue that both approaches have importantthings to offer, and that it is worth trying to findsome compromise between them.
Other things be-ing equal, flat feature-value representations havedesirable formal properties: they are simple, andeasy to manipulate and reason with.
Their draw-back is that they are an impoverished represen-tation language, which can lose important infor-mation.
This means that concepts may be im-possible to represent, or, alternately viewed, thatthe representation format may conflate conceptswhich we would prefer to distinguish.
In the otherdirection, hierarchical logic-based representationsare highly expressive, but pose much more seriouschallenges in terms of formal manipulability.
Al-though they are more easily capable of represent-ing semantic distinctions, it is harder to use them toperform concrete reasoning operations.
In transla-tion systems, these abstract issues manifest them-selves in a tradeoff between complexity of trans-lation rules, and ambiguity of semantic represen-tations.
A flat semantic representation formalismmeans that translation rules are simple to write;however, it also means that the semantic represen-tations they operate on are more likely to be am-biguous.In this paper, we will explore the tradeoffs be-tween the two competing positions outlined abovein the context of a concrete Open Source sys-tem, the MedSLT medical speech translator.
Pre-vious versions of MedSLT have used a represen-tation strategy intermediate between the ?logic-based semantics?
and the ?flat semantics?
ap-proaches, though much closer to the ?flat?
end ofthe scale.
We will discuss the strengths and weak-nesses of the original MedSLT representation for-malism, and then present a revised version, ?Al-most Flat Functional Semantics?
(AFF).
As thename suggests, AFF incorporates functional mark-ings, characteristic of a logic-based semantics ap-proach, into a representation formalism which stillmainly consists of flat list structures.
We will showhow grammars using semantics written in AFF canbe compiled into parsers and generators, and de-scribe a simple formalism that can be used to spec-ify rules for translating AFF expressions into AFFexpressions.
Finally, we will show how use of AFFin MedSLT has allowed us to address in a princi-pled way most of the examples which are problem-atic for the original version of the system, whilestill retaining a simple and transparent frameworkfor writing translation rules.2 The MedSLT SystemMedSLT (Bouillon et al, 2005) is a medium-vocabulary Open Source speech translation systemfor medical domains, implemented using the OpenSource Regulus compiler (Rayner et al, 2006)and the Nuance recognition platform.
Process-ing is primarily rule-based.
Recognition uses agrammar-based language model, which producesa source-langage semantic representation.
This isfirst translated by one set of rules into an interlin-gual form, and then by a second set into a targetlanguage representation.
A target-language gram-mar, compiled into generation form, turns this intoone or more possible surface strings, after whicha set of generation preferences picks one out.
Fi-nally, the selected string is realised in spoken form.There is also some use of corpus-based statisticalmethods, both to tune the language model (Rayneret al, 2006, Section 11.5) and to drive a robust em-bedded help system (Chatzichrisafis et al, 2006).The treatment of syntactic structure is a care-fully thought-out compromise between linguisticand engineering traditions.
All grammars usedare extracted from general linguistically motivatedresource grammars, using corpus-based methodsdriven by small sets of examples (Rayner et al,2006, Chapter 9).
This results in a simpler and flat-ter grammar specific to the domain, whose struc-ture is similar to the ad hoc phrasal grammars typ-ical of engineering approaches.
The treatment ofsemantics is however less sophisticated, and ba-sically represents a minimal approach in the en-gineering tradition.
Each lexicon item contributesa set of zero or more feature-value pairs (in mostcases exactly one pair).
Most of the grammar rulessimply concatenate the sets of pairs received fromtheir daughters.
A small number of rules, primarilythose for subordinate clauses, create a nested sub-structure representing the embedded clause.
Fig-ure 1 shows an example representation.It should be obvious from the example that theflat representation is potentially very ambiguous,since nearly all information about grammaticalfunctions has been lost.
The example also illus-trates, however, why this is often unimportant in714[[utterance_type,sentence],[pronoun,vous],[path_proc,avoir],[voice,active],[tense,present],[cause,nause?e], [sc,quand],[clause,[[pronoun,vous],[symptom,mal],[path_proc,avoir],[voice,active],[tense,present]]])]Figure 1: Semantic representation produced by thecurrent MedSLT system for the French sentenceAvez-vous des nause?es quand vous avez mal?
(?Doyou have nausea when you have the pain??)practice.
From a purely syntactic point of view,the fragment[[pronoun,vous],[path_proc,avoir],[cause,nause?e]]could either represent vous avez des nause?es (?youhave nausea?)
or des nause?es vous ont (?nauseahas you?).
Except, possibly, in certain kinds ofliterary contexts, the second realisation is so im-plausible that it can be discounted.
It is thus rea-sonable to add sortal constraints to the lexical en-tries involved, which permit des nause?es to occurin well-formed utterances as the object of avoir,but not as its subject.
Thus the representation isin fact unambiguous, and will only generate onesurface realisation.With the moderate vocabularies used by Med-SLT (for example, the current French module hasa vocabulary of about 1 100 surface words), thevast majority of constructions can be rendered un-ambiguous using similar strategies.
The result isthat most translation rules are easy to write, sincethey have to do no more than map lists of feature-value pairs to lists of feature-value pairs.
To takea typical example, the Japanese question itami wakoutoubu desu ka (?pain-TOPIC back-part-head is-Q?)
receives the representation[[utterance_type,sentence],[symptom,itami],[body_part,koutoubu],[verb,desu], [tense,present]]which we wish to map to the interlingua represen-tation[[utterance_type,ynq], [verb,be],[tense,present], [voice,active],[symptom,pain], [prep,in_loc],[part,back], [body_part,head]](?is the pain in the back of the head?).
In a moreexpressive semantic framework, the structural mis-matches here would be non-trivial to resolve.
Inthe flat MedSLT notation, we only need the fol-lowing two list-to-list translation rules:transfer_rule([[body_part,koutoubu]],[[prep,in_loc], [part,back],[body_part,head]]).
(koutoubu ?
?in the back of the head?)
andtransfer_rule([[verb, desu]],[[verb, be]]).
(desu ?
?is?
).As usual, however, we pay a price for simplicity.In the terminology of Statistical Machine Transla-tion, what we are essentially doing here is weaken-ing the channel model, and relying on the strengthof the target language model.
This is a reason-able strategy partly because of the restricted natureof the domain, and partly because of the fact thatthe initial parsing stage makes it possible for usto work with bags of concepts rather than bags ofwords; clearly, bags of concepts are more expres-sive.None the less, it is normal to expect the un-derspecified channel model to cause some prob-lems, and this indeed proves to be the case.
Al-though most semantic relationships in the domainare unambiguous even as bags of concepts (?backof the head?
is possible; ?head of the back?
isn?t),there are unpleasant counterexamples.
For in-stance, {?visit?, ?doctor?, ?patient?}
can be re-alised as either ?patient visits doctor?
or ?doc-tor visits patient?.
Similarly, {?precede?, ?nau-sea?, ?headache?}
can be either ?nausea precedesheadache?
or ?headache precedes nausea?.
Caseslike these must be dealt with using ad hoc solu-tions based on domain pragmatics.
In the currentversion of the system, ?patient visits doctor?
isforced by producing both surface realisations, anddefining a generation preference.
In the case of{?precede?, ?nausea?, ?headache?
}, the problemis addressed by dividing symptoms into ?primary?
(the symptom the patient is being examined for,e.g.
?headache?)
and ?secondary?
(other possibly715utterance:[sem=concat(Verb, [[tag, obj, Np]])] -->verb:[sem=Verb], np:[sem=Np].np:[sem=concat(Adj, Noun)] -->spec:[], ?adj:[sem=Adj], noun:[sem=Noun].np:[sem=concat(Np, PP)] -->np:[sem=Np], pp:[sem=PP].pp:[sem=[[tag, Tag, Np]]] -->prep:[sem=Tag], np:[sem=Np].verb:[sem=[[action, grasp]]] --> grasp.noun:[sem=[[thing, block]]] --> block.noun:[sem=[[loc, table]]] --> table.adj:[sem=[[colour, red]]] --> red.spec:[] --> the.prep:[sem=on] --> on.Figure 2: Toy grammar with nested predicate-argument semantics.related symptoms, e.g.
?nausea?).
It is reasonablein practice to assume that the doctor will only beinterested in secondary symptoms that may causeprimary ones, and hence will precede them.Although each language in the current versionof MedSLT only contains a handful of similarcases, solutions like those outlined above are bothinelegant and brittle.
It would be desirable to findsome more principled way to deal with them; wewould, however, like to do this without sacrificingthe appealing simplicity of the translation rule for-malism.
In the next section, we will show how it ispossible to reconcile these two conflicting goals.3 Almost Flat Functional SemanticsAs we have seen, the problem with a simple bag-of-concepts representation is its ambiguity; whatwe would like to do is find some principled way toreduce that ambiguity, without greatly increasingthe formalism?s representational complexity.
Atthis point, a linguistic intuition is helpful.
Thebag-of-concepts representation can reasonably bethought of as an artificial free word-order lan-guage.
There are many natural free word-orderlanguages; the reason why they are in general nomore ambiguous than fixed word-order languagesis that they use case-marking to convey functionalinformation which constrains the space of pos-sible interpretations.
For speakers of Europeanlanguages, the best-known example will proba-bly be Classical Latin.
For instance, when St.Jerome wrote Amor ordinem nescit (?love-NOMorder-ACC not-know-PRES-3-SING?
), the case-markings make it clear that he meant ?Love doesnot know order?
rather than ?Order does not knowlove?.The comparison with free word-order languagessuggests a natural extension of the original bag-of-concepts representation, where each element isassociated with an additional functional tag whichdoes the work that a case-marking would do in anatural free word-order language.
It also suggestsa simple construction which can be used to cre-ate an unordered linear representation that includesfunctional tags.
We start by defining a standardnested predicate-argument semantics; we then flat-ten the representation of each clause S, markingeach primitive semantic element with the imme-diately surrounding functional tag in S, or with anull marking if there is no such tag.
The resultingsemantic representations still represent each clauseas an unordered list, but in contrast to the MedSLTbag-of-concepts representation now include func-tional information.
We will call this style of rep-resentation Almost Flat Functional (AFF) seman-tics; the ?almost?
comes from the fact that there isstill a minimal amount of nested structure, repre-senting the distinction between main and embed-ded clauses.Figures 2 and 3 give a concrete illustration of the716[[action, grasp], [null=[action, grasp],[tag, obj, obj=[colour, red],[[colour, red], obj=[thing, block],[thing, block], on=[loc, table]][tag, on,[[loc, table]]]]]]Figure 3: Construction of AFF representation for ?grasp the red block on the table?.
The AFF represen-tation (right) is a flattened version of the original nested predicate-argument one (left).AFF construction.
Figure 2 presents a toy Regulusgrammar, which allows a few sentences like ?graspthe red block on the table?
and assigns a nestedfunctional semantics to them.
The representationsof most constituents are unordered lists.
In the caseof utterance and np, these are formed by con-catenating the representations of their daughters.There are two examples of functional markings:the rule for utterance wraps an [tag, obj...] around its np daughter, and the rule for ppwraps a tag around its np daughter, whose label isdetermined by the semantic value of the p daugh-ter.Figure 3 introduces the AFF construction itself.The left-hand side of the figure shows the nestedpredicate-argument representation of the sentence,in which elements of the form[tag, Tag, Arg]represent tags and their associated arguments.
Theright-hand side shows the derived AFF representa-tion, where each element that is within the scope ofa [tag ...] has been marked with the tag thatwould be immediately above it in the nested ver-sion.
Thus the element [loc, table] is insidethe scope of both the obj tag and the on tag; how-ever, the AFF version assigns it the on tag, sincethis is the innermost one.In the rest of this section, we will describe howwe can parse surface strings into AFF represen-tations, generate surface strings from AFF repre-sentations, and define translation rules which mapAFF representations to AFF representations.3.1 Analysis and generationFor both analysis and generation, the starting pointis a grammar with a nested predicate-argument se-mantics like the one shown in the left half of Fig-ure 3.
Analysis is straightforward.
We first use astandard parser-generator to compile the grammarinto a parser; the nested predicate-argument repre-sentations it produces are then subjected to a post-processing phase, which flattens them in the wayillustrated in the figure.This simple approach is however not feasible forgeneration, since the flattening operation is highlynon-deterministic in the reverse direction; findingall possible ?unflattenings?
and then attemptingto generate from each one would in most casesbe hopelessly inefficient.
A better solution is totransform the original grammar into one with AFFsemantics, where the current functional markingis specified as an extra features on relevant con-stituents, and percolated through the rules.
In ef-fect, the ?unflattening?
and generation operationscan now proceed simultaneously, with each oneconstraining the other.Figure 4 presents an example, showing the re-sult of performing this transformation on the toyRegulus grammar from Figure 2.
Here, the origi-nal [tag, ...] wrappers have been removed,and replaced by the new feature tag, which hasbeen added to all constituents whose semantics isa list of items of the form Tag=Value.
The valueof the tag feature on each constituent where itis defined is the tag for the most closely enclos-ing [tag, ...] in the original grammar; thesevalues are percolated down to the lexical rules,where they unify with the tags on the semanticfragment contributed by the rule.
The transforma-tion is straightforward to define in its general form,and the transformed grammars can be readily com-piled into efficient generators by standard feature-grammar generator-compiler algorithms like Se-mantic Head-Driven Generation (Shieber et al,1990).
For the concrete experiments describedlater, we used a slightly extended version of theOpen Source Regulus generator compiler.3.2 TransferOur basic strategy for defining transfer betweenAFF expressions is to make it as close as pos-sible to transfer on the original bag-of-concepts717utterance:[sem=concat(Verb, Np)] -->verb:[sem=Verb, tag=null], np:[sem=Np, tag=obj].np:[sem=concat(Adj, Noun), tag=Tag] -->spec:[], ?adj:[sem=Adj, tag=Tag], noun:[sem=Noun, tag=Tag].np:[sem=concat(Np, PP), tag=Tag] -->np:[sem=Np, tag=Tag], pp:[sem=PP, tag=Tag].pp:[sem=Np] -->prep:[sem=Tag], np:[sem=Np, tag=Tag].verb:[sem=[Tag=[action, grasp]], tag=Tag] --> grasp.noun:[sem=[Tag=[thing, block]], tag=Tag] --> block.noun:[sem=[Tag=[loc, table]], tag=Tag] --> table.adj:[sem=[Tag=[colour, red]], tag=Tag] --> red.spec:[] --> the.prep:[sem=on] --> on.Figure 4: Version of grammar from Figure 2 after transformation to AFF semantics.representations, which is conditional mapping oflists to lists.
Since AFF is an extension of bag-of-concepts, and bag-of-concepts is usually suffi-ciently unambiguous as it stands, we only wantto add the functional markings in the cases wherethey are required.
Most of our rules will thus stillbe transfer rules like the ones shown in Sec-tion 2, except that they now map lists of function-marking-tagged items to lists of function-marking-tagged items; however, in accordance with thestated design principles, we allow tags to be omit-ted when desired, with the convention that an omit-ted tag denotes an uninstantiated tag value.One of the underlying linguistic intuitions be-hind AFF is that there are correspondences be-tween functional markings in different languages,with each given functional marking fsin thesource language typically mapping to a specificfunctional marking ftin the target language.For this reason, it would be highly unnaturalonly to specify transformations of tag values us-ing transfer rules.
We consequently intro-duce a second kind of rule, which we call atag transfer rule; as the name suggests,this defines a direct mapping from tags to tags.Given the fact that functional tags have some claimto universality, it is reasonable to hope that manytags will map onto themselves.
Thus a typical tagrule might map the English subj tag to the Arabicsubj tag, which we write astag_transfer_rule(subj, subj).Most tag transfer rules will be of the abovesimple form.
However, there are always caseswhere languages diverge structurally, and here itwill be necessary to make the tag transfer rule con-ditional on its surrounding context.
For example,English constructions with the verb ?last?
(?Doesthe headache last more than ten minutes??)
arerealised differently in Arabic, using the transitiveverb tahus bi (?feel?
), thus here hal tahus bi alsoudaa li akthar min achr daqayq?
(?Do (you)feel the headache during more than ten minutes??
).Here, ?headache?
is marked as subj in English,but the correspoding Arabic word, soudaa, is theobj of tahus bi.
We express the general fact thatwe wish to map subj to obj in the context of theverb ?last?
using the ruletag_transfer_rule(subj, obj) :-context([state, last]).We also require a normal transfer rulewhich maps ?last?
to tahus bi.
This also has tointroduce an implicit second person subject, so thefull rule istransfer_rule([[state, last]],[[state, tahus_bi],subj=[pronoun, anta]]).
(anta = ?you?).
Related sets of rules of this kindcan be written more concisely with a small exten-718sion to the formalism, as follows:transfer_rule([[state, last]],[[state, tahus_bi],subj=[pronoun, anta]],[subj:obj]).An important question we have so far postponeddiscussing is how to fill in unspecified tag valueson the RHS of a transfer rule application.At first, we believed that several possible strate-gies were feasible; rather to our surprise, examina-tion of some examples convinced us that only oneof these strategies actually made sense.
The algo-rithm is as follows.
We assume a transfer -rule R, whose LHS has successfully matched aset of tag/concept pairs, and consider the followingcases:1.
R explicitly assigns values to all of the tagson its RHS.
There is nothing more to do.2.
Not all of the tags on the RHS are assignedvalues by R. Apply tag transfer rulesto all the matched tags on the LHS whichwere not originally assigned values by R, giv-ing a set of tags {T1...Tn}.
There are now twosubcases:(a) n = 1, i.e.
only one transferred tag isproduced.
Set the values of all the unin-stantiated tags on the transferred RHS toT1.
(b) n > 1, i.e.
several different transferredtags are produced.
Leave the values ofthe ininstantiated tags on the transferredRHS uninstantiated.The least obvious part of this is (2a), whichis easier to understand when we consider somemore specific cases.
The simplest and most com-mon example is the case where R is a ?lex-ical?
transfer rule which contains exactlyone tag/concept pair on each side, each tag be-ing left unspecified.
We evidently need to applya tag transfer rule to the tag matched by thesingle pair on the LHS, to get the value of the tagattached to the transferred RHS.To take a slightly more complex case, consideran English ?
Japanese rule which maps the ex-pression ?back of the head?
to the single wordkoutoubu.
We could write this astransfer_rule([[part, back],of=[body_part,head]],[[body_part, koutoubu]])Here, it is clear that we want to translate the tagon the source-language pair that matches [part,back], and assign it to the target-language ele-ment [body part, koutoubu].
The transla-tion of the tag of is irrelevant.4 Using AFF in MedSLTWe have implemented and tested a version of AFFinside the Open Source MedSLT system, buildingAFF versions of the grammars for English, FrenchJapanese, Arabic and the Interlingua.
We also cre-ated AFF versions of the translation rules betweenthe four surface languages and the Interlingua, inboth directions.
Coverage and performance of thetwo versions of the system on development datawere essentially the same; the key differences werearchitectural in nature.
We now briefly summarisethese differences.The basic tradeoff is between analysis and gen-eration on one hand, and translation on the other.The more expressive AFF formalism implies thatrepresentations are less ambiguous, which meansfewer problems in the analysis and generationcomponents.
The downside is that the translationrules become more complex.
On the positive side,switching from bag-of-concepts to AFF allowed usto implement clean solutions to a substantial num-ber of problems which were previously handled inan ad hoc manner.
As previously noted, Englishconstructions using verbs like ?precede?, ?cause?,?accompany?, ?visit?
and ?be in contact with?
arein general ambiguous in the bag-of-words repre-sentation, and had to be solved by artificially con-straining their arguments; AFF makes it possibleto do this by simply differentiating between subjand obj tags.
Similar considerations applied toconstructions in the other two languages.
For ex-ample, using bag-of-words, the Arabic frequencyexpressions thalath marrat fi al ousbou (?threetimes a week?)
and marra kul thalathat assabii(?once every three weeks?)
were previously rep-resented in the same way, necessitating addition ofa brittle generation preference.
AFF once againallows the two expressions to be cleanly distin-guished.It was evident from the start that we wouldwin on this kind of example; what was less clear719was the price we would have to pay, in termsof increased complexity of the transfer rule set.Gratifyingly, the conservative nature of the ex-tension meant that this price turned out to bequite low.
We had originally wondered whetherit would be necessary to write many condi-tional tag transfer rules, or add functionaltags to a large proportion of the transfer -rules.
In fact, out of the total of 4444 rulesused by the eight language pairs together, only39 (0.9%) were conditional tag transfer -rules, and 524 (11.8%) were transfer rulescontaining at least one functional tag.
A fur-ther 120 rules (2.7%) were unconditional tag -transfer rules.
The remaining 3761 rules(84.6%) were transfer rules which did notexplicitly mention functional tags, and were thusessentially bag-of-concepts mapping rules.
Tosummarise, less than a sixth of the rules were af-fected by moving to the new framework.5 Summary and ConclusionsWe have described Almost Flat Functional seman-tics, a formalism which adds functional markingsto a flat atheoretical feature/value representation.The additional functional information in AFF issufficient to resolve nearly all of the representa-tional ambiguities which caused problems for theflat bag-of-concepts formalism.
In terms of repre-sentational complexity, however, the AFF formal-ism appears to be only slightly less tractable thanbag-of-concepts.
It seems reasonable to us that,like bag-of-concepts, it could also support learn-able surface-oriented parsing; this could be com-bined with statistical recognition to provide a ro-bust back-up to grammar-based speech processing(Rayner et al, 2005), a claim that we hope to inves-tigate empirically in the near future.
It is much lessclear that full logic-based representations could beused for such purposes.What we find interesting here, from a generalperspective, is that we were able to create a re-duced, but still essentially clean, form of a main-stream linguistic treatment, and incorporate it intoan ad hoc engineering framework in a way thatonly marginally affected that framework?s perfor-mance characteristics.
Without wishing to exag-gerate the importance of our results, we think ex-amples like AFF suggest that the gulf betweenthese two types of approach is not, perhaps, aswide as is sometimes suggested.ReferencesBouillon, P., M. Rayner, N. Chatzichrisafis, B.A.Hockey, M. Santaholma, M. Starlander, Y. Nakao,K.
Kanzaki, and H. Isahara.
2005.
A generic multi-lingual open source platform for limited-domainmedical speech translation.
In Proceedings of the10th Conference of the European Association forMachine Translation (EAMT), pages 50?58, Bu-dapest, Hungary.Chatzichrisafis, N., P. Bouillon, M. Rayner, M. Santa-holma, M. Starlander, and B.A.
Hockey.
2006.
Eval-uating task performance for a unidirectional con-trolled language medical speech translation system.In Proceedings of the HLT-NAACL InternationalWorkshop on Medical Speech Translation, pages 9?16, New York.Rayner, M., D. Carter, P. Bouillon, V. Digalakis, andM.
Wire?n, editors.
2000.
The Spoken LanguageTranslator.
Cambridge University Press.Rayner, M., P. Bouillon, N. Chatzichrisafis, B.A.Hockey, M. Santaholma, M. Starlander, H. Isahara,K.
Kanzaki, and Y. Nakao.
2005.
A methodol-ogy for comparing grammar-based and robust ap-proaches to speech understanding.
In Proceedingsof the 9th International Conference on Spoken Lan-guage Processing (ICSLP), pages 1103?1107, Lis-boa, Portugal.Rayner, M., B.A.
Hockey, and P. Bouillon.
2006.Putting Linguistics into Speech Recognition: TheRegulus Grammar Compiler.
CSLI Press, Chicago.Riezler, S., T.H.
King, R.M.
Kaplan, R. Crouch, J.T.Maxwell, and M. Johnson.
2002.
Parsing thewall street journal using a lexical-functional gram-mar and discriminative estimation techniques.
InProceedings of the 40th Annual Meeting of the Asso-ciation for Computational Linguistics (demo track),Philadelphia, PA.Shieber, S., G. van Noord, F.C.N.
Pereira, and R.C.Moore.
1990.
Semantic-head-driven generation.Computational Linguistics, 16(1).Wahlster, W., editor.
2000.
Verbmobil: Foundations ofSpeech-to-Speech Translation.
Springer.Young, S. 2002.
Talking to machines (statisticallyspeaking).
In Proceedings of the 7th InternationalConference on Spoken Language Processing (IC-SLP), pages 9?16, Denver, CO.720
