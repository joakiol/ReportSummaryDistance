Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 257?264Manchester, August 2008Statistical anaphora resolution in biomedical textsCaroline Gasperin Ted BriscoeComputer LaboratoryUniversity of CambridgeCambridge, UK{cvg20,ejb}@cl.cam.ac.ukAbstractThis paper presents a probabilistic modelfor resolution of non-pronominal anaphorain biomedical texts.
The model seeks tofind the antecedents of anaphoric expres-sions, both coreferent and associative ones,and also to identify discourse-new expres-sions.
We consider only the noun phrasesreferring to biomedical entities.
The modelreaches state-of-the art performance: 56-69% precision and 54-67% recall on coref-erent cases, and reasonable performanceon different classes of associative cases.1 IntroductionInspired by Ge et al (1998) probabilistic model forpronoun resolution, we have developed a model forresolution of non-pronominal anaphora in biomed-ical texts.The probabilistic model results from a simpledecomposition process applied to a conditionalprobability equation that involves several param-eters (features).
The decomposition makes useof Bayes?
theorem and independence assumptions,and aims to decrease the impact of data sparse-ness on the model, so that even small training cor-pora can be viable.
The decomposed model canbe understood as a more sophisticated version ofthe naive-Bayes algorithm, since we consider thedependence among some of the features insteadof full independence as in naive Bayes.
Proba-bilistic models can return a confidence measure(probability) for each decision they make, whilec?
2008.
Licensed under the Creative CommonsAttribution-Noncommercial-Share Alike 3.0 Unported li-cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).Some rights reserved.decision trees, for example, cannot.
Another ad-vantage of this type of model is the fact that theyconsider the prior probability of each class, whileother machine-learning techniques such as SVMsand neural networks do not.Our model seeks to classify the relation betweenan anaphoric expression and an antecedent candi-date as coreferent, associative or neither.
It com-putes the probability of each pair of anaphor andcandidate for each class.
The candidate with thehighest overall probability for each class is se-lected as the antecedent for that class, or no an-tecedent is selected if the probability of no relationovercomes the positive probabilities; in this case,the expression is considered to be new to the dis-course.Coreferent cases are the ones in which theanaphoric expression and its antecedent refer to thesame entity in the real world, as below:(1) ?The expression of reaper has beenshown ... the gene encodes ...?Associative cases are the ones in which theanaphoric expression and its antecedent refer todifferent entities, but where the antecedent playsa role in defining the meaning of the anaphoric ex-pression, as in Example 2:(2) ?Drosophila gene Bok interacts with... expression of Bok proteinpromotes apoptosis ...?Discourse new cases usually consist of the firstmention of an entity in the text, so no antecedentcan be found for it.We have focused on the biomedical domain fortwo reasons.
Firstly, there is a vast demand fromthe biomedical field for information extraction ef-forts (which require NLP processing, including257anaphora resolution), in order to process the ex-ponentially increasing number of journal publica-tions, which are the major source of novel knowl-edge to be extracted and condensed into domaindatabases for easy access.
Secondly, anaphora res-olution can benefit from the several sources of re-fined semantic knowledge that are not commonlyavailable for other domains, such as biomedicaldatabases, ontologies, and terminologies.In the next section, we describe the anaphoricrelations that we found in biomedical texts, whichwe are considering for the resolution process.
InSection 3 we describe our probabilistic model, andin Section 4 the corpus created for training it.In Section 5 we present and discuss the resultsachieved by the model, and compare it with a base-line system and a decision-tree-based system.2 Anaphora cases in biomedical textBiomedical texts differ from other genres of text(e.g.
newswire, fiction) in several points.
Differ-ent types of NPs have a particular distribution inbiomedical articles.
For example, pronouns arevery rare, accounting for a very small percentageof the noun phrases1; on the other hand, propernames occur very often, given the frequent men-tion of gene and protein names and the names ofother biomedical entities.
A system for anaphoraresolution in the biomedical domain can benefitfrom focusing on the most common types of nounphrases, that is, non-pronominal ones.In biomedical articles, the reader needs back-ground knowledge to understand the underlyingrelation between the entities mentioned in the textin order to understand the text.
For instance, in Ex-ample 2 the reader is expected to know that a geneencodes a protein (which usually carries its name),so that he/she can capture the anaphoric relationand understand the sentence.
This aspect empha-sises the need for semantic information as part ofthe anaphora resolution process.Another aspect affecting the anaphoric relationsin biomedical texts are the writing conventionsadopted in the biomedical domain to distinguishbetween the mention of a gene name and the men-tion of the protein encoded by that gene.
Themost usual convention is writing gene names withlowercase italicised letters and protein names withnon-italicised uppercase letters.
The existence of1About 3% of the noun phrases according to the corpuspresented in Section 4.such conventions allows for constructions wherethe reader keeps the conventions in mind to under-stand the text, as below.
(3) ?Drosophila has recently beenshown also to have a CED-4/Apaf-1homolog, named Dark/HAC-1/Dapaf-1.... Loss of function mutations indark/hac-1/dapaf-1 result in ...?Among the associative cases present in biomed-ical text, we were able to distinguish two maintypes of relations.
The first, which we call ?bio-type?
relations, are associative relations betweenbiomedical entities with different semantic types,which we call biotypes (e.g.
gene, gene product,part of gene).
This is the case of Example 2 and 32.If we take into account the specific biotype of theentities that are involved in a biotype relation, it ispossible to determine a WordNet-like semantic re-lation behind the anaphora relation.
For example,a biotype relation between a ?gene?
and a ?variant?of gene can be considered an hyponymy relation,the relation between a ?gene?
and a transcript (partof gene) can be seen as a meronymy relation.The second type of associative relation is morecommon to other domains as well, we call it ?set-member?
relation.
It consists of cases where theanaphor refers to a set that contains the antecedent,or vice-versa, as in Examples 4 and 5.
(4) ...ced-4 and ced-9...the genes...(5) ...the mammalian anti-apoptoticprotein Bcl-2...Bcl-2 family...3 The resolution modelOur probabilistic model aims to find the clos-est coreferent and/or associative antecedent for allnon-pronominal NPs that refer to biomedical enti-ties.
Among non-pronominal NPs we distinguishproper names, definite NPs (e.g.
?the gene?
),demonstrative NPs (e.g.
?this gene?
), indefiniteNPs (e.g.
?a gene?
), quantified NPs (e.g.
?fourgenes?, ?some genes?)
and other NPs.We consider the three classes of anaphoric rela-tions mentioned above: coreferent, associative bio-type, and associative set-member.We have chosen 11 features to describe theanaphoric relations between two noun phrases.The features are presented in Table 1.
Most fea-tures are domain-independent, while one, gp, is2Associative relations between proper names are notknown to happen in other domains, and are made possiblein the biomedical domain given the existence of naming con-ventions.258specific for the biomedical domain.
Our feature setcovers the basic aspects that influence anaphoricrelations: the form of the anaphor?s NP, stringmatching, semantic class matching, number agree-ment, and distance.Given these features, for each antecedent candi-date a of an anaphor A, we compute the probabil-ity P of an specific class of anaphoric relation Cbetween a and A. P is defined as follows:P (C = ?class?|fA, fa, hma,A, hmma,A,mma,A,numa,A, sra, bma,A, gpa,A, da,A, dma,A)For each pair of a given anaphor and an an-tecedent candidate we compute P for C=?coreferent?,C=?biotype?, and C=?set-member?.
We also computeC=?none?, that represents the probability of no rela-tion between the NPs.We decompose the probability P and assume in-dependence among some of the features in orderto handle the sparseness of the training data.
Inthe following equations, we omit the subscriptedindexes of the relational features for clarity.P (C|fA, fa, hm, hmm,mm,num, sr, bm, gp, d, dm)=P (C)P (fA, fa, hm, hmm,mm,num, sr, bm, gp, d, dm|C)P (fA, fa, hm, hmm,mm,num, sr, bm, gp, d, dm)(1)Equation 1 is obtained by applying Bayes?
theo-rem to the initial equation.
P (C) is the prior prob-ability of each class, it will encode the distributionof the classes in the training data.
As the denom-inator contains feature values that change accord-ing to the candidate being considered, we cannoteliminate it in the usual fashion, so we keep it inorder to normalise P across all candidates.
Fromthis equation, we then selectively apply the chainrule to both numerator and denominator until weget to the following equation:=P (C) P (fA|C) P (fa|C, fA) P (d, dm|C, fA, fa)P (sr|C, fA, fa, d, dm) P (bm, gp|C, fA, fa, d, dm, sr)P (num|C, fA, fa,d, dm, sr, bm, gp)P (hm, hmm,mm|C, fA,fa, d, dm, sr, bm, gp, num)P (fA) P (fa|fA) P (d, dm|fA, fa)P (sr|fA, fa, d, dm) P (bm, gp|fA, fa, d, dm, sr)P (num|fA, fa, d, dm, sr, bm, gp)P (hm, hmm,mm|fA, fa, d, dm, sr, bm, gp, num)(2)Following the decomposition, we eliminatesome of the dependencies among the features thatwe consider unnecessary3.
We consider that thelexical features hm, hmm, andmm are not depen-dent on distance d or dm, nor on sr, gp or num,so:P (hm, hmm,mm|C, fA, fa, d, dm, sr, bm, gp, num) ?P (hm, hmm,mm|C, fA, fa, bm)We model num as independent from d, dm, sr,bm, and gp, so:P (num|C, fA, fa, d, dm, sr, bm, gp) ?P (num|C, fA, fa)We also assume the semantic features bm, andgp as independent from all features but C:P (bm, gp|C, fA, fa, d, dm, sr) ?
P (bm, gp|C)We also assume sr to be independent of fAandfa:P (sr|C, fA, fa, d, dm) ?
P (sr|C, d, dm)The final equation then becomes:P (C|fA, fa, hm, hmm,mm,num, sr, bm, gp, d, dm) =P (C) P (fA|C) P (fa|C, fA) P (d, dm|C, fA, fa)P (sr|C, d, dm) P (bm, gp|C) P (num|C, fA, fa)P (hm, hmm,mm|C, fA, fa, bm)P (fA) P (fa|fA) P (d, dm|fA, fa)P (sr|d, dm) P (bm, gp) P (num|fA, fa)P (hm, hmm,mm|fA, fa, bm)(3)4 TrainingThere are very few biomedical corpora annotatedwith anaphora information, and all of them arebuilt from paper abstracts (Cohen et al, 2005), in-stead of full papers.
As anaphora is a phenomenonthat develops through a text, we believe that shortabstracts are not the best source to work with anddecided to concentrate on full papers.In order to collect the statistics to train ourmodel, we have manually annotated anaphoric re-lations between biomedical entities in 5 full-textarticles (approx.
33,300 words)4, which are part ofthe Drosophila molecular biology literature.
Thecorpus and annotation process are described in(Gasperin et al, 2007).
To the best of our knowl-edge, this corpus is the first corpus of biomedicalfull-text articles to be annotated with anaphora in-formation.3For brevity, we only show this process for the numerator,although the same is assumed for the denominator.4Corpus available via the FlySlip project websitehttp://www.wiki.cl.cam.ac.uk/rowiki/NaturalLanguage/FlySlip259Feature Possible valuesfAForm of noun phrase of the anaphor A: ?pn?, ?defnp?, ?demnp?, ?indefnp?, ?quantnp?, or ?np?.faForm of noun phrase of the antecedent candidate a: same values as for fA.hma,AHead-noun matching: ?yes?
if the anaphor?s and the candidate?s head nouns match, ?no?
otherwise.hmma,AHead-modifier matching: ?yes?
if the anaphor?s head noun matches any of the candidate?s pre-modifiers, orvice-versa, ?no?
otherwise.mma,AModifier matching: ?yes?
if anaphor and candidate have at least one head modifier in common, ?no?
otherwise.numa,ANumber agreement: ?yes?
if anaphor and candidate agree in number, ?no?
otherwise.sra,ASyntactic relation between anaphor and candidate: ?none?, ?apposition?, ?subj-obj?, ?pp?, and few others.bma,ABiotype matching: ?yes?
if anaphor?s and candidate?s biotype (semantic class) match, ?no?
otherwise.gpa,Ais biotype gene or product?
?yes?
if the anaphor biotype or candidate biotype is gene or product, ?no?
otherwise.This feature is mainly to distinguish which pairs can hold biotype relations.da,ADistance in sentences between the anaphor and the candidate.dma,ADistance in number of entities (markables) between the anaphor and the candidate.Table 1: Feature setBefore annotating anaphora, we have prepro-cessed the articles in order to (1) tag gene names,(2) identify all NPs, and (3) classify the NPs ac-cording to their domain type, which we call bio-type.
To tag all gene names in the corpus, wehave applied the gene name recogniser developedby Vlachos et al (2006).
To identify all NPs, theirsubconstituents (head, modifiers, determiner) andbroader pre- and post-modification patterns, wehave used the RASP parser (Briscoe et al, 2006).To classify the NPs according to their type inbiomedical terms, we have adopted the SequenceOntology (SO)5(Eilbeck and Lewis, 2004).
SOis a fine-grained ontology, which contains thenames of practically all entities that participate ingenomic sequences, besides the relations amongthese entities (e.g.
is-a, part-of, derived-from re-lations).
We derived from SO seven biotypes tobe used to classify the entities in the text, namely:?gene?, ?gene product?, ?part of gene?, ?part ofproduct?, ?gene variant?, ?gene subtype?, and?gene supertype?.
We also created the biotype?other-bio?
to be associated with noun phrases thatcontain a gene name (identified by the gene namerecogniser) but whose head noun does not fit anyof the other biotypes.
All NPs were tagged withtheir biotypes, and NPs for which no biotypes werefound were excluded.The gene-name tags, NP boundaries and bio-types resulting from the preprocessing phase wererevised and corrected by hand before the anaphoricrelations were annotated.For each biotyped NP we annotated its closestcoreferent antecedent (if found) and its closest as-sociative antecedent (if found), from one of the as-sociative classes.
From our annotation, we can in-5http://www.sequenceontology.org/fer coreference chains by merging the coreferentlinks between mentions of a same entity.The annotated relations, and the features de-rived from them, are used as training data for theprobabilistic model above.
We have also consid-ered negative training samples, which result fromthe absence of an anaphoric relation between aNP that precedes an anaphoric expression and wasnot marked as its antecedent (nor marked as partof the same coreference chain of its antecedent).The negative samples outnumber considerably thenumber of positive samples (annotated cases).
Ta-ble 2 presents the distribution of the cases amongthe classes of anaphora relations.We note that around 80% of the definite NPs areanaphoric in our corpus, instead of the 50% pre-sented in (Vieira and Poesio, 2000) for newspa-per texts.
Nearly all demonstrative NPs (93%) areanaphoric.
More than 70% of the proper namestake part in coreference relations, as they inher-ently refer to a specific named entity, but never-theless 5% of them take part in associative biotyperelations, due to the fact that a gene and the proteinit synthesizes usually share the same name.
44% ofquantified NPs take part in set-member relations,as they usually refer to more than one entity.
Fi-nally 51% of indefinite NPs are discourse new.To balance the ratio between positive and nega-tive training samples, we have clustered the neg-ative samples and kept only a portion of eachcluster, proportional to its size.
All negativesamples that have the same values for all fea-tures are grouped together (consequently, a clus-ter is formed by a set of identical samples) andonly110of each cluster members is kept, re-sulting in 85,314 negative samples.
This way,small clusters (with less than 10 members), which260Class/NPs pn defnp demnp indefnp quantnp other np Totalcoreferent 689 429 70 40 54 396 1678biotype 43 102 3 8 4 114 274set-member 151 126 26 14 68 158 543discourse new 63 107 0 72 38 156 436none 873,731Table 2: Training instances, according to anaphoric class and to NP formare likely to represent noisy samples (similar topositive ones), are eliminated, and bigger clus-ters are shrunk; however the shape of the dis-tribution of the negative samples is preserved.For example, our biggest cluster (feature valuesare: fA=?pn?, fa=?pn?, hm=?no?, hmm=?no?,mm=?no?, bm=?yes?, gp=?yes?, num=?yes?,sr=?none?, d=?16<?, dm=?50<?)
with 33,998 in-stances is reduced to 3,399 ?
still considerablymore numerous than any positive sample.Other works have used a different strategy to re-duce the imbalance between positive and negativesamples (Soon et al, 2001; Ng and Cardie, 2002;Strube et al, 2002), where only samples composedby a negative antecedent that is closer than theannotated one are considered.
We compare theperformance of both strategies in Section 5.1 andshow that ours is more effective.
The higher thenumber of negative samples, the higher the preci-sion of the resolution, but the lower the recall.5 ResultsGiven the small size of our corpus, we did not holdout a test set.
Instead, we have measured the av-erage performance achieved by the model in a 10-fold cross-validation setting, using the whole of theannotated corpus.We consider as antecedent candidates all nounphrases that precede the anaphor.
For a givenanaphor, we first select as antecedent according toeach anaphora class the candidate with the high-est value for P for that class.
We also computeP(C=?none?)
for all candidates.
If P(C=?coreferent?)
>P(C=?none?)
for the selected coreferent antecedent,it is kept as the resulting antecedent.
The same istested for the selected associative antecedent withthe highest probability, independent of the type ofassociative class.
For set-member cases, wherean anaphor can have multiple antecedents, if morethan one candidate has an equally high probabil-ity, all these candidates are kept.
When no coref-erent or associative antecedent is found (or whenP(C=?none?)
is higher on both cases) the anaphor isclassified as discourse new.Table 3 presents the performance scores weachieved for each anaphora class.
The first col-umn, ?perfect?, shows the result of a strict evalu-ation, where we consider as correct all pairs thatmatch exactly an antecedent-anaphor pair in theannotated data.
On the other hand, column ?re-laxed?
treats as correct also the pairs where theassigned antecedent is not the exact match in theannotated data but is coreferent with it.It is clear that the results for coreferent casesare much better than for associative cases, but thelatter are known to be more challenging.
On topof that, the ?relaxed?
column shows considerableimprovements in comparison to ?perfect?.
Thatmeans that several anaphors are being linked to thecorrect coreference chain, despite not being linkedto the closest antecedent.
This happens mainly incases where there is no string matching betweenthe closest antecedent and the anaphor, causing anearlier mention of the same entity with matchinghead and/or modifiers to get higher probability.
Webelieve we can approximate ?perfect?
to ?relaxed?results if we extend the string matching features torepresent the whole coreference chain, that is, con-sider a positive matching when the anaphor matchany of the elements in a chain, similarly to the ideapresented in (Yang et al, 2004).We believe that the lower overall performancefor associative cases is due to the difficulty of se-lecting features that capture all aspects involved inassociative relations.
Our set of features is clearlyfailing to cover some of these aspects, and a deeperfeature study should be the best way to boost thescores.
However, despite lower, these performancePerfect RelaxedClassP R F P R Fcoreferent 56.3 54.7 55.5 69.4 67.4 68.3biotype 28.5 35.0 31.4 31.2 37.9 34.2set-member 35.4 38.2 36.7 38.5 41.5 40.0discourse new 44.3 53.4 48.4 44.3 53.4 48.4Table 3: Performance of the probabilistic model261scores are higher that the ones from previous ap-proaches for newspaper texts, which used for in-stance the WordNet (Poesio et al, 1997) or theInternet (Bunescu, 2003) as source of semanticknowledge.We have analysed our features and observedthat the string matching features hm, hmm, andmm, the number agreement feature num, bio-type matching bm, and distance in markables dmare the core features and achieve reasonable per-formance.
However, fAand faplay an impor-tant role, they increase the precision of corefer-ent cases and boost considerably the performanceof the associative ones.
This is due to the differ-ent distribution of NP types across the relations asshown is Table 2.
The remaining features focusedon specific cases: gp improved biotype recall, byboosting the probability of a biotype relation whenanaphor or candidate had specific biotypes; and srimproved precision and recall of coreferent cases.Table 4 shows the ?perfect?
performance scoresaccording to each class of NP.
The resolution ofproper names achieves the highest scores amongall types of NPs for most classes.
That is due totheir limited structure, since proper names usuallydo not have elaborated pre-modification or modifi-cation at all, so our string matching features car-ried simpler patterns for these NPs.
Indefiniteand quantified NPs achieved the lowest scores forcoreferent cases, since the highest percentage oftraining instances for these NPs are not coreferent(as seen in Table 2).
Indefinite NPs, as expected,have the best scores for discourse new cases.5.1 Comparing to other approachesWe have tried training our probabilistic model us-ing a different strategy than the one described inSection 4 for selecting negative samples.
Thisstrategy consists of selecting only the negativesamples that occur between the anaphor and itscoreferent antecedent, not considering candidatesthat are further away than the antecedent.
Thisstrategy was first used for anaphora resolution bySoon et al (2001).
Column ?prob+closest?
on Ta-ble 5 shows the performance scores.
In our dataset,this strategy was able to reduce the number of neg-ative samples to about13of its size, while our strat-egy reduces it to110.
The larger number of neg-ative samples increases the precision scores andreduces the recall scores for all positive classes,while the opposite happens for the negative class,which defines the discourse new scores.
We reckonthat the considerable drop on recall numbers forthe associative cases would make the system lessviable, while the low precision for discourse newcases shows that many anaphoric cases are left un-resolved.
We view our strategy, based on the clus-tering of negative samples and consecutive clustersize reduction, to be more effective at proportion-ally eliminating negative samples that are less fre-quent and that are more likely to be noisy.We compare our model to a rule-based base-line system that we have previously developed.The baseline system (Gasperin, 2006) for eachanaphoric expression: 1) selects as coreferent an-tecedent the closest preceding NP that has the samehead noun, same biotype and agrees in numberwith the anaphor, and 2) selects as associative an-tecedent the closest preceding NP that has the samehead noun, same biotype but disagrees in num-ber with the anaphor, or that has the same headnoun or a modifier matching the anaphor head (orvice-versa) or matching modifiers, agrees in num-ber but has different biotypes.
The baseline sys-tem does not distinguish between different typesof associative cases, although it aims to cover bio-type and set-member cases.
If no antecedent thatmatches these criteria is found, the anaphor is con-sidered discourse new.
Column ?baseline?
on Ta-ble 5 shows the performance scores for the base-line system.
The scores for coreferent cases arereasonable, despite being below our probabilisticmodel, while the scores for associative cases, es-pecially recall, are considerably lower.
The base-line system relies on some sort of string matchingbetween anaphor and antecedent, and is not ableto infer a relation between expressions when thematching does not happen.
That is one of the mainaspects that the probabilistic system tries to over-come by weighting the contribution of all features.We also compared our model to a system basedon decision trees, since this approach has beentaken by several corpus-based anaphora resolutionsystems (Soon et al, 2001; Ng and Cardie, 2002;Strube et al, 2002).
We have induced a decisiontree using the C4.5 algorithm implemented in theWeka tool (Witten and Frank, 2005); we have usedthe same features used for our probabilistic model.We selected as the antecedent the candidate whichis the closest one to the anaphor for which a classother then ?none?
is assigned by the decision tree.The ?perfect?
and ?relaxed?
scores for C4.5 are pre-262coreferent biotype set-member discourse newClassP R F P R F P R F P R Fpn 77.5 71.9 74.6 26.8 25.5 26.1 53.7 65.7 59.1 35.1 59.3 44.1defnp 48.0 47.3 47.6 26.3 28.1 27.2 29.2 26.1 27.6 38.8 51.8 44.4demnp 57.8 48.5 52.8 - - - 71.4 57.6 63.8 - - -indefnp 27.0 34.2 30.2 14.2 12.5 13.3 21.0 28.5 24.2 63.4 54.7 58.8quantnp 11.2 12.9 12.0 - - - 28.5 37.6 32.5 37.1 34.2 35.6other np 41.3 41.4 41.4 30.9 48.2 37.7 19.3 19.4 19.4 49.7 56.0 52.6Table 4: Performance of the probabilistic model (?perfect?)
per NP formsented in the last two columns of Table 5.
We notethat the difference between ?perfect?
and ?relaxed?scores is not as large as for our probabilistic model;that shows that decision trees are more often get-ting even the coreference chain wrong, not just theclosest antecedent.
We assume this is due to thelack of ranking among the candidates, since weadopt the default strategy of selecting the closestcandidate that gets a positive class according to thetree.The main disadvantage of both the baseline anddecision tree systems when compared to the prob-abilistic model, besides the lower performance, isthat they do not provide a probability assigned toeach decision they make, which makes it impos-sible to know how confident the model is for dif-ferent cases and to take advantage of that infor-mation to improve the system.
This aspect alsomakes it difficult to develop a consistent strategyfor returning multiple antecedents for set-membercases, since there is no obvious way to do it.6 Related workWe are not aware of any learning-based systemwhich has dealt with coreferent as well as asso-ciative cases of anaphora.Viera and Poesio (2000) have developed aheuristic-based system for coreferent and asso-ciative anaphora resolution of definite NPs innewspaper texts, and have reached 62% recalland 83% precision for direct anaphora (coreferentcases with same head noun), but poor performancefor bridging cases (associative cases + coreferentcases with different head nouns) using WordNet assouce of semantic knowledge.Ng and Cardie (2002), extending the work ofSoon et al (2001), have developed a machine-learning system just for coreference resolution ofall types of NPs, also on newspaper texts.
Theirbest results were 64.2% recall and 78.0% preci-sion.The best-known system to resolve anaphora inthe biomedical domain is the work of Casta?no etal.
(2002), who developed a salience-based sys-tem for resolution of coreferent cases.
It seeksto resolve pronouns and nominal (which they callsortal) anaphora.
As a source of semantic knowl-edge, they have used the UMLS Semantic Net-work types6, which they report to be too coarsegrained, and assume that a finer-grained typingstrategy would help to increase the precision of theresolution system.
They achieved 74% precisionand 75% recall on a very small test set.Yang et al (2004) implemented a machine-learning approach to coreference resolution similarto Ng and Cardie?s, and evaluated it on a portion ofthe GENIA corpus, which is tagged with semanticinformation based on the GENIA Ontology7.
Theyachieved recall of 80.2% and precision of 77.4%.Both the Casta?no et al and Yang et al systemshave been developed based on abstracts of biomed-ical articles, instead of full-text articles, which in-volve only restricted use of anaphora.7 Conclusion and future workWe have presented a probabilistic model for re-solving anaphoric NPs in biomedical texts.
We arenot aware of previous works which have dealt withcoreferent and associative anaphora in the biomed-ical domain.
Our model, despite being simple andbeing trained on a very small corpus, coped wellwith its task of finding antecedents for coreferentand associative cases of anaphora, and was ableto achieve state-of-the-art performance.
It has out-performed our baseline system and a decision-tree-based system using the same set of features.Our model returns a probability for each classi-fication it makes, and this can be used as a confi-dence measure that can be exploited to improve thesystem itself or by external applications.Due to our small corpus, we had to limit the6http://www.nlm.nih.gov/research/umls/7http://www-tsujii.is.s.u-tokyo.ac.jp/GENIA/263Prob+Closest Baseline C4.5 C4.5 relaxedClassP R F P R F P R F P R Fcoreferent 66.2 50.0 56.9 47.0 57.6 51.8 49.6 58.1 53.5 52.7 61.6 56.8biotype 31.1 10.1 15.228.6 10.7 15.621.7 28.5 24.6 22.9 29.9 26.0set-member 46.3 17.5 25.4 28.5 31.3 29.8 30.4 33.3 31.8discourse new 31.3 88.1 46.2 37.3 30.2 33.4 48.5 32.5 38.9 48.5 32.5 38.9Table 5: Performance of other modelsnumber and the complexity of the features weuse, since the more features, the more sparse thedata, and the more training data needed.
However,we aim to expand the feature set with more fine-grained features.Our current work involves using the probabilis-tic model presented here as part of an active learn-ing framework.
The confidence of the model foreach decision (probability) is used to selectivelygather more samples from unlabelled data and it-eratively improve the performance of the system.The probabilistic model is intended to replacethe baseline system in a tool designed to help bi-ology researchers to curate scientific papers (Kara-manis et al, 2008).AcknowledgementsThis work is part of the BBSRC-funded FlySlipproject.
Caroline Gasperin is funded by a CAPESaward from the Brazilian government.ReferencesBriscoe, Edward J., John Carroll, and Rebecca Watson.2006.
The second release of the RASP system.
InProceedings of ACL-COLING 06, Sydney, Australia.Bunescu, Razvan.
2003.
Associative anaphora reso-lution: A web-based approach.
In Proceedings ofEACL 2003 - Workshop on The Computational Treat-ment of Anaphora, Budapest.Casta?no, Jos?e, Jason Zhang, and James Pustejovsky.2002.
Anaphora resolution in biomedical literature.In Proceedings of International Symposium on Ref-erence Resolution for NLP 2002, Alicante, Spain.Cohen, K. Bretonnel, Lynne Fox, Philip Ogren, andLawrence Hunter.
2005.
Corpus design for biomed-ical natural language processsing.
In Proceedings ofthe ACL-ISMB Workshop on Linking Biological Lit-erature, Ontologies and Databases, Detroit.Eilbeck, Karen and Suzanna E. Lewis.
2004.
Sequenceontology annotation guide.
Comparative and Func-tional Genomics, 5:642?647.Gasperin, Caroline, Nikiforos Karamanis, and RuthSeal.
2007.
Annotation of anaphoric relations inbiomedical full-text articles using a domain-relevantscheme.
In Proceedings of DAARC 2007, Lagos,Portugal.Gasperin, Caroline.
2006.
Semi-supervised anaphoraresolution in biomedical texts.
In Proceedings ofBioNLP?06, New York.Ge, Niyu, John Hale, and Eugene Charniak.
1998.
Astatistical approach to anaphora resolution.
In Pro-ceedings of the Sixth Workshop on Very Large Cor-pora - COLING-ACL?98, Montreal, Canada.Karamanis, Nikiforos, Ruth Seal, Ian Lewin, PeterMcQuilton, Andreas Vlachos, Caroline Gasperin,Rachel Drysdale, and Ted Briscoe.
2008.
Naturallanguage processing in aid of flybase curators.
BMCBioinformatics, 9(193).Ng, Vincent and Claire Cardie.
2002.
Improving ma-chine learning approaches to coreference resolution.In Proceedings of ACL 2002, Philadelphia.Poesio, Massimo, Renata Vieira, and Simone Teufel.1997.
Resolving bridging descriptions in unre-stricted texts.
In Proceedings of the Workshop onOperational Factors In Practical, Robust AnaphoraResolution for Unrestricted Texts, Madrid.Soon, Wee Meng, Hwee Tou Ng, and DanielChung Yong Lim.
2001.
A machine learning ap-proach to coreference resolution of noun phrases.Computational Linguistics, 27(4):521?544.Strube, Michael, Stefan Rapp, and Christoph M?uller.2002.
The influence of minimum edit distance onreference resolution.
In Proceedings of the EMNLP2002, Philadelphia.Vieira, Renata and Massimo Poesio.
2000.
Anempirically-based system for processing definite de-scriptions.
Computational Linguistics, 26(4):525?579.Vlachos, Andreas and Caroline Gasperin.
2006.
Boot-strapping and evaluating named entity recognition inthe biomedical domain.
In Proceedings of BioNLPat HLT-NAACL 2006, pages 138?145, New York.Witten, Ian H. and Eibe Frank.
2005.
Data Mining:Practical machine learning tools and techniques,2nd Edition.
Morgan Kaufmann, San Francisco.Yang, X., J. Su, G. Zhou, and C. L. Tan.
2004.
An NP-cluster based approach to coreference resolution.
InProceedings of COLING 2004, Geneva, Switzerland.264
