Evaluating Centering-based metrics of coherence for textstructuring using a reliably annotated corpusNikiforos Karamanis,?
Massimo Poesio,?
Chris Mellish,?
and Jon Oberlander?
?School of Informatics, University of Edinburgh, UK, {nikiforo,jon}@ed.ac.uk?Dept.
of Computer Science, University of Essex, UK, poesio at essex dot ac dot uk?Dept.
of Computing Science, University of Aberdeen, UK, cmellish@csd.abdn.ac.ukAbstractWe use a reliably annotated corpus to comparemetrics of coherence based on Centering The-ory with respect to their potential usefulness fortext structuring in natural language generation.Previous corpus-based evaluations of the coher-ence of text according to Centering did not com-pare the coherence of the chosen text structurewith that of the possible alternatives.
A corpus-based methodology is presented which distin-guishes between Centering-based metrics takingthese alternatives into account, and representstherefore a more appropriate way to evaluateCentering from a text structuring perspective.1 MotivationOur research area is descriptive text generation(O?Donnell et al, 2001; Isard et al, 2003), i.e.the generation of descriptions of objects, typi-cally museum artefacts, depicted in a picture.Text (1), from the gnome corpus (Poesio et al,2004), is an example of short human-authoredtext from this genre:(1) (a) 144 is a torc.
(b) Its present arrangement,twisted into three rings, may be a modern al-teration; (c) it should probably be a single ring,worn around the neck.
(d) The terminals arein the form of goats?
heads.According to Centering Theory (Grosz et al,1995; Walker et al, 1998a), an important fac-tor for the felicity of (1) is its entity coherence:the way centers (discourse entities), such asthe referent of the NPs ?144?
in clause (a) and?its?
in clause (b), are introduced and discussedin subsequent clauses.
It is often claimed incurrent work on in natural language generationthat the constraints on felicitous text proposedby the theory are useful to guide text struc-turing, in combination with other factors (see(Karamanis, 2003) for an overview).
However,how successful Centering?s constraints are ontheir own in generating a felicitous text struc-ture is an open question, already raised by theseminal papers of the theory (Brennan et al,1987; Grosz et al, 1995).
In this work, we ex-plored this question by developing an approachto text structuring purely based on Centering,in which the role of other factors is deliberatelyignored.In accordance with recent work in the emerg-ing field of text-to-text generation (Barzilay etal., 2002; Lapata, 2003), we assume that the in-put to text structuring is a set of clauses.
Theoutput of text structuring is merely an order-ing of these clauses, rather than the tree-likestructure of database facts often used in tradi-tional deep generation (Reiter and Dale, 2000).Our approach is further characterized by twokey insights.
The first distinguishing feature isthat we assume a search-based approach to textstructuring (Mellish et al, 1998; Kibble andPower, 2000; Karamanis and Manurung, 2002)in which many candidate orderings of clausesare evaluated according to scores assigned bya given metric, and the best-scoring orderingamong the candidate solutions is chosen.
Thesecond novel aspect is that our approach isbased on the position that the most straight-forward way of using Centering for text struc-turing is by defining a Centering-based metricof coherence Karamanis (2003).
Together, thesetwo assumptions lead to a view of text planningin which the constraints of Centering act notas filters, but as ranking factors, and the textplanner may be forced to choose a sub-optimalsolution.However, Karamanis (2003) pointed out thatmany metrics of coherence can be derived fromthe claims of Centering, all of which could beused for the type of text structuring assumed inthis paper.
Hence, a general methodology foridentifying which of these metrics represent themost promising candidates for text structuringis required, so that at least some of them canbe compared empirically.
This is the second re-search question that this paper addresses, build-ing upon previous work on corpus-based evalu-ations of Centering, and particularly the meth-ods used by Poesio et al (2004).
We use thegnome corpus (Poesio et al, 2004) as the do-main of our experiments because it is reliablyannotated with features relevant to Centeringand contains the genre that we are mainly in-terested in.To sum up, in this paper we try to iden-tify the most promising Centering-based metricfor text structuring, and to evaluate how usefulthis metric is for that purpose, using corpus-based methods instead of generally more expen-sive psycholinguistic techniques.
The paper isstructured as follows.
After discussing how thegnome corpus has been used in previous workto evaluate the coherence of a text according toCentering we discuss why such evaluations arenot sufficient for text structuring.
We continueby showing how Centering can be used to definedifferent metrics of coherence which might beuseful to drive a text planner.
We then outlinea corpus-based methodology to choose amongthese metrics, estimating how well they are ex-pected to do when used by a text planner.
Weconclude by discussing our experiments in whichthis methodology is applied using a subset of thegnome corpus.2 Evaluating the coherence of acorpus text according to CenteringIn this section we briefly introduce Centering,as well as the methodology developed in Poesioet al (2004) to evaluate the coherence of a textaccording to Centering.2.1 Computing CF lists, CPs and CBsAccording to Grosz et al (1995), each ?utter-ance?
in a discourse is assigned a list of for-ward looking centers (CF list) each of which is?realised?
by at least one NP in the utterance.The members of the CF list are ?ranked?
in or-der of prominence, the first element being thepreferred center CP.In this paper, we used what we considered tobe the most common definitions of the centralnotions of Centering (its ?parameters?).
Poe-sio et al (2004) point out that there are manydefinitions of parameters such as ?utterance?,?ranking?
or ?realisation?, and that the settingof these parameters greatly affects the predic-tions of the theory;1 however, they found viola-tions of the Centering constraints with any wayof setting the parameters (for instance, at least25% of utterances have no CB under any suchsetting), so that the questions addressed by ourwork arise for all other settings as well.Following most mainstream work on Center-ing for English, we assume that an ?utterance?corresponds to what is annotated as a finite unitin the gnome corpus.2 The spans of text withthe indexes (a) to (d) in example (1) are exam-ples.
This definition of utterance is not optimalfrom the point of view of minimizing Centeringviolations (Poesio et al, 2004), but in this waymost utterances are the realization of a singleproposition; i.e., the impact of aggregation isgreatly reduced.
Similarly, we use grammaticalfunction (gf) combined with linear order withinthe unit (what Poesio et al (2004) call gfthere-lin) for CF ranking.
In this configuration, theCP is the referent of the first NP within the unitthat is annotated as a subject for its gf.3Example (2) shows the relevant annotationfeatures of unit u210 which corresponds toutterance (a) in example (1).
According togftherelin, the CP of (a) is the referent of ne410?144?.
(2) <unit finite=?finite-yes?
id=?u210?><ne id="ne410" gf="subj">144</ne>is<ne id="ne411" gf="predicate">a torc</ne> </unit>.The ranking of the CFs other than theCP is defined according to the following pref-erence on their gf (Brennan et al, 1987):obj>iobj>other.
CFs with the same gf areranked according to the linear order of the cor-responding NPs in the utterance.
The secondcolumn of Table 1 shows how the utterances inexample (1) are automatically translated by thescripts developed by Poesio et al (2004) into a1For example, one could equate ?utterance?
with sen-tence (Strube and Hahn, 1999; Miltsakaki, 2002), useindirect realisation for the computation of the CF list(Grosz et al, 1995), rank the CFs according to theirinformation status (Strube and Hahn, 1999), etc.2Our definition includes titles which are not alwaysfinite units, but excludes finite relative clauses, the sec-ond element of coordinated VPs and clause complementswhich are often taken as not having their own CF listsin the literature.3Or as a post-copular subject in a there-clause.CF list: cheapnessU {CP, other CFs} CB Transition CBn=CPn?1(a) {de374, de375} n.a.
n.a.
n.a.
(b) {de376, de374, de377} de374 retain +(c) {de374, de379} de374 continue ?
(d) {de380, de381, de382} - nocb +Table 1: CP, CFs other than CP, CB, nocb or standard (see Table 2) transition and violations ofcheapness (denoted with an asterisk) for each utterance (U) in example (1)coherence: coherence?
:CBn=CBn?1 CBn 6=CBn?1or nocb in CFn?1salience: CBn=CPn continue smooth-shiftsalience?
: CBn 6=CPn retain rough-shiftTable 2: coherence, salience and the table of standard transitionssequence of CF lists, each decomposed into theCP and the CFs other than the CP, accordingto the chosen setting of the Centering param-eters.
Note that the CP of (a) is the centerde374 and that the same center is used as thereferent of the other NPs which are annotatedas coreferring with ne410.Given two subsequent utterances Un?1 andUn, with CF lists CFn?1 and CFn respectively,the backward looking center of Un, CBn, is de-fined as the highest ranked element of CFn?1which also appears in CFn (Centering?s Con-straint 3).
For instance, the CB of (b) is de374.The third column of Table 1 shows the CB foreach utterance in (1).42.2 Computing transitionsAs the fourth column of Table 1 shows, eachutterance, with the exception of (a), is alsomarked with a transition from the previous one.When CFn and CFn?1 do not have any cen-ters in common, we compute the nocb transi-tion (Kibble and Power, 2000) (Poesio et alsnull transition) for Un (e.g., utterance (d) inTable 1).54In accordance with Centering, no CB is computedfor (a), the first utterance in the sequence.5In this study we do not take indirect realisation intoaccount, i.e., we ignore the bridging reference (anno-tated in the corpus) between the referent of ?it?
de374in (c) and the referent of ?the terminals?
de380 in (d),by virtue of which de374 might be thought as being amember of the CF list of (d).
Poesio et al (2004) showedthat hypothesizing indirect realization eliminates manyviolations of entity continuity, the part of Constraint1 that rules out nocb transitions.
However, in this workwe are treating CF lists as an abstract representationFollowing again the terminology in Kibbleand Power (2000), we call the requirement thatCBn be the same as CBn?1 the principle of co-herence and the requirement that CBn be thesame as CPn the principle of salience.
Eachof these principles can be satisfied or violatedwhile their various combinations give rise to thestandard transitions of Centering shown in Ta-ble 2; Poesio et als scripts compute these vio-lations.6 We also make note of the preferencebetween these transitions, known as Centering?sRule 2 (Brennan et al, 1987): continue is pre-ferred to retain, which is preferred to smooth-shift, which is preferred to rough-shift.Finally, the scripts determine whether CBnis the same as CPn?1, known as the principleof cheapness (Strube and Hahn, 1999).
Thelast column of Table 1 shows the violations ofcheapness (denoted with an asterisk) in (1).72.3 Evaluating the coherence of a textand text structuringThe statistics about transitions computed asjust discussed can be used to determine the de-gree to which a text conforms with, or violates,Centering?s principles.
Poesio et al (2004)found that nocbs account for more than 50%of the atomic facts the algorithm has to structure, i.e.,we are assuming that CFs are arguments of such facts;including indirectly realized entities in CF lists wouldviolate this assumption.6If the second utterance in a sequence U2 has a CB,then it is taken to be either a continue or a retain,although U1 is not classified as a nocb.7As for the other two principles, no violation ofcheapness is computed for (a) or when Un is marked asa nocb.of the transitions in the gnome corpus in con-figurations such as the one used in this pa-per.
More generally, a significant percentage ofnocbs (at least 20%) and other ?dispreferred?transitions was found with all parameter config-urations tested by Poesio et al (2004) and in-deed by all previous corpus-based evaluations ofCentering such as Passoneau (1998), Di Eugenio(1998), Strube and Hahn (1999) among others.These results led Poesio et al (2004) to theconclusion that the entity coherence as formal-ized in Centering should be supplemented withan account of other coherence inducing factorsto explain what makes texts coherent.These studies, however, do not investigatethe question that is most important from thetext structuring perspective adopted in this pa-per: whether there would be alternative ways ofstructuring the text that would result in fewerviolations of Centering?s constraints (Kibble,2001).
Consider the nocb utterance (d) in (1).Simply observing that this transition is ?dispre-ferred?
ignores the fact that every other orderingof utterances (b) to (d) would result in morenocbs than those found in (1).
Even a text-structuring algorithm functioning solely on thebasis of the Centering constraints might there-fore still choose the particular order in (1).
Inother words, a metric of text coherence purelybased on Centering principles?trying to mini-mize the number of nocbs?may be sufficient toexplain why this order of clauses was chosen,at least in this particular genre, without needto involve more complex explanations.
In therest of the paper, we consider several such met-rics, and use the texts in the gnome corpus tochoose among them.
We return to the issue ofcoherence (i.e., whether additional coherence-inducing factors need to be stipulated in addi-tion to those assumed in Centering) in the Dis-cussion.3 Centering-based metrics ofcoherenceAs said previously, we assume a text structuringsystem taking as input a set of utterances rep-resented in terms of their CF lists.
The systemorders these utterances by applying a bias infavour of the best scoring ordering among thecandidate solutions for the preferred output.8In this section, we discuss how the Centering8Additional assumptions for choosing between the or-derings that are assigned the best score are presented inthe next section.concepts just described can be used to definemetrics of coherence which might be useful fortext structuring.The simplest way to define a metric of coher-ence using notions from Centering is to classifyeach ordering of propositions according to thenumber of nocbs it contains, and pick the or-dering with the fewest nocbs.
We call this met-ric M.NOCB, following (Karamanis and Manu-rung, 2002).
Because of its simplicity, M.NOCBserves as the baseline metric in our experiments.We consider three more metrics.
M.CHEAPis biased in favour of the ordering with thefewest violations of cheapness.
M.KP sumsup the nocbs and the violations of cheapness,coherence and salience, preferring the or-dering with the lowest total cost (Kibble andPower, 2000).
Finally, M.BFP employs thepreferences between standard transitions as ex-pressed by Rule 2.
More specifically, M.BFPselects the ordering with the highest numberof continues.
If there exist several orderingswhich have the most continues, the one whichhas the most retains is favoured.
The numberof smooth-shifts is used only to distinguishbetween the orderings that score best for con-tinues as well as for retains, etc.In the next section, we present a generalmethodology to compare these metrics, usingthe actual ordering of clauses in real texts ofa corpus to identify the metric whose behav-ior mimics more closely the way these actualorderings were chosen.
This methodology wasimplemented in a program called the System forEvaluating Entity Coherence (seec).4 Exploring the space of possibleorderingsIn section 2, we discussed how an ordering ofutterances in a text like (1) can be translatedinto a sequence of CF lists, which is the repre-sentation that the Centering-based metrics op-erate on.
We use the term Basis for Comparison(BfC) to indicate this sequence of CF lists.
Inthis section, we discuss how the BfC is used inour search-oriented evaluation methodology tocalculate a performance measure for each metricand compare them with each other.
In the nextsection, we will see how our corpus was usedto identify the most promising Centering-basedmetric for a text classifier.4.1 Computing the classification rateThe performance measure we employ is calledthe classification rate of a metric M on a cer-tain BfC B.
The classification rate estimatesthe ability of M to produce B as the output oftext structuring according to a specific genera-tion scenario.The first step of seec is to search throughthe space of possible orderings defined by thepermutations of the CF lists that B consists of,and to divide the explored search space into setsof orderings that score better, equal, or worsethan B according to M.Then, the classification rate is defined accord-ing to the following generation scenario.
Weassume that an ordering has higher chances ofbeing selected as the output of text structuringthe better it scores for M. This is turn meansthat the fewer the members of the set of betterscoring orderings, the better the chances of Bto be the chosen output.Moreover, we assume that additional factorsplay a role in the selection of one of the order-ings that score the same for M. On average, Bis expected to sit in the middle of the set ofequally scoring orderings with respect to theseadditional factors.
Hence, half of the orderingswith the same score will have better chancesthan B to be selected by M.The classification rate ?
of a metric M onB expresses the expected percentage of order-ings with a higher probability of being gener-ated than B according to the scores assignedby M and the additional biases assumed by thegeneration scenario as follows:(3) Classification rate:?
(M,B) = Better(M) + Equal(M)2Better(M) stands for the percentage of order-ings that score better than B according to M,whilst Equal(M) is the percentage of order-ings that score equal to B according to M.
If?
(Mx, B) is the classification rate of Mx on B,and ?
(My, B) is the classification rate of My onB, My is a more suitable candidate than Mxfor generating B if ?
(My, B) is smaller than?
(Mx, B).4.2 Generalising across many BfCsIn order for the experimental results to be re-liable and generalisable, Mx and My should becompared on more than one BfC from a corpusC.
In our standard analysis, the BfCs B1, ..., Bmfrom C are treated as the random factor in arepeated measures design since each BfC con-tributes a score for each metric.
Then, the clas-sification rates for Mx and My on the BfCs arecompared with each other and significance istested using the Sign Test.
After calculating thenumber of BfCs that return a lower classifica-tion rate for Mx than for My and vice versa, theSign Test reports whether the difference in thenumber of BfCs is significant, that is, whetherthere are significantly more BfCs with a lowerclassification rate for Mx than the BfCs with alower classification rate for My (or vice versa).9Finally, we summarise the performance of Mon m BfCs from C in terms of the average clas-sification rate Y :(4) Average classification rate:Y (M,C) = ?(M,B1)+...+?
(M,Bm)m5 Using the gnome corpus for asearch-based comparison ofmetricsWe will now discuss how the methodologydiscussed above was used to compare theCentering-based metrics discussed in Section3, using the original ordering of texts in thegnome corpus to compute the average classi-fication rate of each metric.The gnome corpus contains texts from differ-ent genres, not all of which are of interest to us.In order to restrict the scope of the experimentto the text-type most relevant to our study, weselected 20 ?museum labels?, i.e., short textsthat describe a concrete artefact, which servedas the input to seec together with the metricsin section 3.105.1 Permutation and search strategyIn specifying the performance of the metrics wemade use of a simple permutation heuristic ex-ploiting a piece of domain-specific communica-tion knowledge (Kittredge et al, 1991).
LikeDimitromanolaki and Androutsopoulos (2003),we noticed that utterances like (a) in exam-ple (1), should always appear at the beginningof a felicitous museum label.
Hence, we re-stricted the orderings considered by the seec9The Sign Test was chosen over its parametric al-ternatives to test significance because it does not carryspecific assumptions about population distributions andvariance.
It is also more appropriate for small sampleslike the one used in this study.10Note that example (1) is characteristic of the genre,not the length, of the texts in our subcorpus.
The num-ber of CF lists that the BfCs consist of ranges from 4 to16 (average cardinality: 8.35 CF lists).Pair M.NOCB p Winnerlower greater tiesM.NOCB vs M.CHEAP 18 2 0 0.000 M.NOCBM.NOCB vs M.KP 16 2 2 0.001 M.NOCBM.NOCB vs M.BFP 12 3 5 0.018 M.NOCBN 20Table 3: Comparing M.NOCB with M.CHEAP, M.KP and M.BFP in gnometo those in which the first CF list of B, CF1,appears in first position.11For very short texts like (1), which give rise toa small BfC, the search space of possible order-ings can be enumerated exhaustively.
However,when B consists of many more CF lists, it is im-practical to explore the search space in this way.Elsewhere we show that even in these cases itis possible to estimate ?
(M,B) reliably for thewhole population of orderings using a large ran-dom sample.
In the experiments reported here,we had to resort to random sampling only once,for a BfC with 16 CF lists.5.2 Comparing M.NOCB with othermetricsThe experimental results of the comparisons ofthe metrics from section 3, computed using themethodology in section 4, are reported in Ta-ble 3.In this table, the baseline metric M.NOCB iscompared with each of M.CHEAP, M.KP andM.BFP.
The first column of the Table identifiesthe comparison in question, e.g.
M.NOCB ver-sus M.CHEAP.
The exact number of BfCs forwhich the classification rate of M.NOCB is lowerthan its competitor for each comparison is re-ported in the next column of the Table.
For ex-ample, M.NOCB has a lower classification ratethan M.CHEAP for 18 (out of 20) BfCs fromthe gnome corpus.
M.CHEAP only achieves alower classification rate for 2 BfCs, and thereare no ties, i.e.
cases where the classificationrate of the two metrics is the same.
The p valuereturned by the Sign Test for the difference inthe number of BfCs, rounded to the third deci-mal place, is reported in the fifth column of theTable.
The last column of the Table 3 showsM.NOCB as the ?winner?
of the comparisonwith M.CHEAP since it has a lower classifica-11Thus, we assume that when the set of CF lists servesas the input to text structuring, CF1 will be identifiedas the initial CF list of the ordering to be generatedusing annotation features such as the unit type whichdistinguishes (a) from the other utterances in (1).tion rate than its competitor for significantlymore BfCs in the corpus.12Overall, the Table shows that M.NOCB doessignificantly better than the other three metricswhich employ additional Centering concepts.This result means that there exist proportion-ally fewer orderings with a higher probability ofbeing selected than the BfC when M.NOCB isused to guide the hypothetical text structuringalgorithm instead of the other metrics.Hence, M.NOCB is the most suitable amongthe investigated metrics for structuring the CFlists in gnome.
This in turn indicates that sim-ply avoiding nocb transitions is more relevantto text structuring than the combinations of theother Centering notions that the more compli-cated metrics make use of.
(However, these no-tions might still be appropriate for other tasks,such as anaphora resolution.
)6 Discussion: the performance ofM.NOCBWe already saw that Poesio et al (2004) foundthat the majority of the recorded transitions inthe configuration of Centering used in this studyare nocbs.
However, we also explained in sec-tion 2.3 that what really matters when tryingto determine whether a text might have beengenerated only paying attention to Centeringconstraints is the extent to which it would bepossible to ?improve?
upon the ordering chosenin that text, given the information that the textstructuring algorithm had to convey.
The av-erage classification rate of M.NOCB is an esti-12No winner is reported for a comparison when the pvalue returned by the Sign Test is not significant (ns),i.e.
greater than 0.05.
Note also that despite conduct-ing more than one pairwise comparison simultaneouslywe refrain from further adjusting the overall thresholdof significance (e.g.
according to the Bonferroni method,typically used for multiple planned comparisons that em-ploy parametric statistics) since it is assumed that choos-ing a conservative statistic such as the Sign Test alreadyprovides substantial protection against the possibility ofa type I error.Pair M.NOCB p Winnerlower greater tiesM.NOCB vs M.CHEAP 110 12 0 0.000 M.NOCBM.NOCB vs M.KP 103 16 3 0.000 M.NOCBM.NOCB vs M.BFP 41 31 49 0.121 nsN 122Table 4: Comparing M.NOCB with M.CHEAP, M.KP and M.BFP using the novel methodologyin MPIROmate of exactly this variable, indicating whetherM.NOCB is likely to arrive at the BfC duringtext structuring.The average classification rate Y forM.NOCB on the subcorpus of gnome studiedhere, for the parameter configuration of Cen-tering we have assumed, is 19.95%.
This meansthat on average the BfC is close to the top 20%of alternative orderings when these orderingsare ranked according to their probability ofbeing selected as the output of the algorithm.On the one hand, this result shows that al-though the ordering of CF lists in the BfCmight not completely minimise the number ofobserved nocb transitions, the BfC tends tobe in greater agreement with the preference toavoid nocbs than most of the alternative or-derings.
In this sense, it appears that the BfCoptimises with respect to the number of poten-tial nocbs to a certain extent.
On the otherhand, this result indicates that there are quitea few orderings which would appear more likelyto be selected than the BfC.We believe this finding can be interpreted intwo ways.
One possibility is that M.NOCBneeds to be supplemented by other features inorder to explain why the original text was struc-tured this way.
This is the conclusion arrived atby Poesio et al (2004) and those text structur-ing practitioners who use notions derived fromCentering in combination with other coherenceconstraints in the definitions of their metrics.There is also a second possibility, however: wemight want to reconsider the assumption thathuman text planners are trying to ensure thateach utterance in a text is locally coherent.They might do all of their planning just on thebasis of Centering constraints, at least in thisgenre ?perhaps because of resource limitations?and simply accept a certain degree of incoher-ence.
Further research on this issue will requirepsycholinguistic methods; our analysis never-theless sheds more light on two previously un-addressed questions in the corpus-based evalu-ation of Centering ?
a) which of the Centeringnotions are most relevant to the text structur-ing task, and b) to which extent Centering onits own can be useful for this purpose.7 Further resultsIn related work, we applied the methodologydiscussed here to a larger set of existing data(122 BfCs) derived from the MPIRO systemand ordered by a domain expert (Dimitro-manolaki and Androutsopoulos, 2003).
As Ta-ble 4 shows, the results from MPIRO verify theones reported here, especially with respect toM.KP and M.CHEAP which are overwhelm-ingly beaten by the baseline in the new do-main as well.
Also note that since M.BFP failsto overtake M.NOCB in MPIRO, the baselinecan be considered the most promising solutionamong the ones investigated in both domainsby applying Occam?s logical principle.We also tried to account for some additionalconstraints on coherence, namely local rhetor-ical relations, based on some of the assump-tions in Knott et al (2001), and what Kara-manis (2003) calls the ?PageFocus?
which cor-responds to the main entity described in a text,in our example de374.
These results, reportedin (Karamanis, 2003), indicate that these con-straints conflict with Centering as formulated inthis paper, by increasing - instead of reducing- the classification rate of the metrics.
Hence,it remains unclear to us how to improve uponM.NOCB.In our future work, we would like to experi-ment with more metrics.
Moreover, although weconsider the parameter configuration of Center-ing used here a plausible choice, we intend to ap-ply our methodology to study different instan-tiations of the Centering parameters, e.g.
byinvestigating whether ?indirect realisation?
re-duces the classification rate for M.NOCB com-pared to ?direct realisation?, etc.AcknowledgementsSpecial thanks to James Soutter for writing theprogram which translates the output produced bygnome?s scripts into a format appropriate for seec.The first author was able to engage in this researchthanks to a scholarship from the Greek State Schol-arships Foundation (IKY).ReferencesRegina Barzilay, Noemie Elhadad, and Kath-leen McKeown.
2002.
Inferring strategiesfor sentence ordering in multidocument newssummarization.
Journal of Artificial Intelli-gence Research, 17:35?55.Susan E. Brennan, Marilyn A. Fried-man [Walker], and Carl J. Pollard.
1987.
Acentering approach to pronouns.
In Proceed-ings of ACL 1987, pages 155?162, Stanford,California.Barbara Di Eugenio.
1998.
Centering in Italian.In Walker et al (Walker et al, 1998b), pages115?137.Aggeliki Dimitromanolaki and Ion Androut-sopoulos.
2003.
Learning to order facts fordiscourse planning in natural language gen-eration.
In Proceedings of the 9th EuropeanWorkshop on Natural Language Generation,Budapest, Hungary.Barbara J. Grosz, Aravind K. Joshi, and ScottWeinstein.
1995.
Centering: A frameworkfor modeling the local coherence of discourse.Computational Linguistics, 21(2):203?225.Amy Isard, Jon Oberlander, Ion Androutsopou-los, and Colin Matheson.
2003.
Speaking theusers?
languages.
IEEE Intelligent SystemsMagazine, 18(1):40?45.Nikiforos Karamanis and Hisar Maruli Manu-rung.
2002.
Stochastic text structuring us-ing the principle of continuity.
In Proceedingsof INLG 2002, pages 81?88, Harriman, NY,USA, July.Nikiforos Karamanis.
2003.
Entity Coherencefor Descriptive Text Structuring.
Ph.D. the-sis, Division of Informatics, University of Ed-inburgh.Rodger Kibble and Richard Power.
2000.
Anintegrated framework for text planning andpronominalisation.
In Proceedings of INLG2000, pages 77?84, Israel.Rodger Kibble.
2001.
A reformulation of Rule2 of Centering Theory.
Computational Lin-guistics, 27(4):579?587.Richard Kittredge, Tanya Korelsky, and OwenRambow.
1991.
On the need for domain com-munication knowledge.
Computational Intel-ligence, 7:305?314.Alistair Knott, Jon Oberlander, MickO?Donnell, and Chris Mellish.
2001.
Beyondelaboration: The interaction of relationsand focus in coherent text.
In T. Sanders,J.
Schilperoord, and W. Spooren, edi-tors, Text Representation: Linguistic andPsycholinguistic Aspects, chapter 7, pages181?196.
John Benjamins.Mirella Lapata.
2003.
Probabilistic text struc-turing: Experiments with sentence ordering.In Proceedings of ACL 2003, Saporo, Japan,July.Chris Mellish, Alistair Knott, Jon Oberlander,and Mick O?Donnell.
1998.
Experiments us-ing stochastic search for text planning.
InProceedings of the 9th International Work-shop on NLG, pages 98?107, Niagara-on-the-Lake, Ontario, Canada.Eleni Miltsakaki.
2002.
Towards an aposyn-thesis of topic continuity and intrasenten-tial anaphora.
Computational Linguistics,28(3):319?355.Mick O?Donnell, Chris Mellish, Jon Oberlan-der, and Alistair Knott.
2001.
ILEX: An ar-chitecture for a dynamic hypertext genera-tion system.
Natural Language Engineering,7(3):225?250.Rebecca J. Passoneau.
1998.
Interaction of dis-course structure with explicitness of discourseanaphoric phrases.
In Walker et al (Walkeret al, 1998b), pages 327?358.Massimo Poesio, Rosemary Stevenson, BarbaraDi Eugenio, and Janet Hitzeman.
2004.
Cen-tering: a parametric theory and its instantia-tions.
Computational Linguistics, 30(3).Ehud Reiter and Robert Dale.
2000.
BuildingNatural Language Generation Systems.
Cam-bridge.Michael Strube and Udo Hahn.
1999.
Func-tional centering: Grounding referential coher-ence in information structure.
ComputationalLinguistics, 25(3):309?344.Marilyn A. Walker, Aravind K. Joshi, andEllen F. Prince.
1998a.
Centering in nat-urally occuring discourse: An overview.
InWalker et al (Walker et al, 1998b), pages1?30.Marilyn A. Walker, Aravind K. Joshi, andEllen F. Prince, editors.
1998b.
CenteringTheory in Discourse.
Clarendon Press, Ox-ford.
