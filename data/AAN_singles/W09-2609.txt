Proceedings of the 2009 Workshop on Grammar Engineering Across Frameworks, ACL-IJCNLP 2009, pages 71?79,Suntec, Singapore, 6 August 2009. c?2009 ACL and AFNLPA generalized method for iterative error mining in parsing resultsDanie?l de KokUniversity of Groningend.j.a.de.kok@rug.nlJianqiang MaUniversity of Groningenj.ma@student.rug.nlGertjan van NoordUniversity of Groningeng.j.m.van.noord@rug.nlAbstractError mining is a useful technique foridentifying forms that cause incompleteparses of sentences.
We extend the iter-ative method of Sagot and de la Clerg-erie (2006) to treat n-grams of an arbi-trary length.
An inherent problem of in-corporating longer n-grams is data sparse-ness.
Our new method takes sparsenessinto account, producing n-grams that areas long as necessary to identify problem-atic forms, but not longer.Not every cause for parsing errors can becaptured effectively by looking at wordn-grams.
We report on an algorithm forbuilding more general patterns for min-ing, consisting of words and part of speechtags.It is not easy to evaluate the various er-ror mining techniques.
We propose a newevaluation metric which will enable us tocompare different error miners.1 IntroductionIn the past decade wide-coverage grammars andparsers have been developed for various lan-guages, such as the Alpino parser and grammar(Bouma et al, 2001) for Dutch and the EnglishResource Grammar (Copestake and Flickinger,2000).
Such grammars account for a large num-ber of grammatical and lexical phenomena, andachieve high accuracies.
Still, they are usuallytailored to general domain texts and fail to reachthe same accuracy for domain-specific texts, dueto missing lexicon entries, fixed expressions, andgrammatical constructs.
When parsing new textsthere are usually two types of parsing errors:?
The parser returns an incorrect parse.
Whilethe parser may have constructed the correctparse, the disambiguation model chose an in-correct parse.?
The parser can not find an analysis that spansthe full sentence.
If that sentence is allowedin the language, the grammar or lexicon is in-complete.While the first type of errors can be alleviatedby improving the disambiguation model, the sec-ond type of problems requires extension of thegrammar or lexicon.
Finding incomplete descrip-tions by hand can become a tedious task once agrammar has wide coverage.
Error mining tech-niques aim to find problematic words or n-gramsautomatically, allowing the grammar developer tofocus on frequent and highly suspicious formsfirst.2 Previous workIn the past, two major error mining techniqueshave been developed by Van Noord (2004) andSagot and de la Clergerie (2006).
In this paper wepropose a generalized error miner that combinesthe strengths of these methods.
Both methods fol-low the same basic principle: first, a large (unan-notated) corpus is parsed.
After parsing, the sen-tences can be split up in a list of parsable and a listof unparsable sentences.
Words or n-grams thatoccur in the list of unparsable sentences, but thatdo not occur in the list of parsable sentences havea high suspicion of being the cause of the parsingerror.2.1 Suspicion as a ratioVan Noord (2004) defines the suspicion of a wordas a ratio:S(w) =C(w|error)C(w)(1)where C(w) is the number of occurrences ofword w in all sentences, and C(w|error) is the71number of occurrences of w in unparsable sen-tences.
Of course, it is often useful to look at n-grams as well.
For instance, Van Noord (2004)gives an example where the word via had a lowsuspicion after parsing a corpus with the DutchAlpino parser, while the Dutch expression via via(via a complex route) was unparsable.To account for such phenomena, the notion ofsuspicion is extended to n-grams:S(wi..wj) =C(wi..wj |error)C(wi..wj)(2)Where a longer sequence wh...wi...wj ...wk isonly considered if its suspicion is higher than eachof its substrings:S(wh...wi...wj ...wk) > S(wi...wj) (3)While this method works well for forms that areunambiguously suspicious, it also gives forms thatjust happened to occur often in unparsable sen-tences by ?bad luck?
a high suspicion.
If the occur-rences in unparsable sentences were accompaniedby unambiguously suspicious forms, there is evenmore reason to believe that the form is not prob-lematic.
However, in such cases this error miningmethod will still assign a high suspicion to suchforms.2.2 Iterative error miningThe error mining method described by Sagot andde la Clergerie (2006) alleviates the problem of?accidentally suspicious?
forms.
It does so bytaking the following characteristics of suspiciousforms into account:?
If a form occurs within parsable sentences, itbecomes less likely that the form is the causeof a parsing error.?
The suspicion of a form should depend on thesuspicions of other forms in the unparsablesentences in which it occurs.?
A form observed in a shorter sentence is ini-tially more suspicious than a form observedin a longer sentence.To be able to handle the suspicion of a formwithin its context, this method introduces the no-tion of observation suspicion, which is the suspi-cion of a form within a given sentence.
The suspi-cion of a form, outside the context of a sentence,is then defined to be the average of all observationsuspicions:Sf =1|Of |?oi,j?OfSi,j (4)HereOf is the set of all observations of the formf , oi,j is the jth form of the ith sentence, and Si,jis the observation suspicion of oi,j .
The observa-tion suspicions themselves are dependent on theform suspicions, making the method an iterativeprocess.
The suspicion of an observation is thesuspicion of its form, normalized by suspicions ofother forms occurring within the same sentence:S(n+1)i,j = error(si)S(n+1)F (oi,j)?1?j?|Si| S(n+1)F (oi,j)(5)Here error(si) is the sentence error rate, whichis normally set to 0 for parsable sentences and 1for unparsable sentences.
SF (oi,j) is the suspicionof the form of observation oi,j .To accommodate the iterative process, we willhave to redefine the form suspicion to be depen-dent on the observation suspicions of the previouscycle:S(n+1)f =1|Of |?oi,j?OfS(n)i,j (6)Since there is a recursive dependence betweenthe suspicions and the observation suspicions,starting and stopping conditions need to be definedfor this cyclic process.
The observation suspicionsare initialized by uniformly distributing suspicionover observed forms within a sentence:S(0)i,j =error(si)|Si|(7)The mining is stopped when the process reachesa fixed point where suspicions have stabilized.This method solves the ?suspicion by accident?problem of ratio-based error mining.
However, theauthors of the paper have only used this method tomine on unigrams and bigrams.
They note thatthey have tried mining with longer n-grams, butencountered data sparseness problems.
Their pa-per does not describe criteria to determine when touse unigrams and when to use bigrams to representforms within a sentence.3 N-gram expansion3.1 Inclusion of n-gramsWhile the iterative miner described by Sagot andde la Clergerie (2006) only mines on unigrams and72bigrams, our prior experience with the miner de-scribed by Van Noord (2004) has shown that in-cluding longer n-grams in the mining process cancapture many additional phenomena.
To give oneexample: the words de (the), eerste (first), andbeste (best) had very low suspicions during er-ror mining, while the trigram eerste de beste hada very high suspicion.
This trigram occurred inthe expression de eerste de beste (the first you canfind).
While the individual words within this ex-pression were described by the lexicon, this multi-word expression was not.3.2 Suspicion sharingIt may seem to be attractive to include all n-gramswithin a sentence in the mining process.
However,this is problematic due to suspicion sharing.
Forinstance, consider the trigram w1, w2, w3 in whichw2 is the cause of a parsing error.
In this case,the bigrams w1, w2 and w2, w3 will become sus-picious, as well as the trigram w1, w2, w3.
Sincethere will be multiple very suspicious forms withinthe same sentence the unigramw2 will have no op-portunity to manifest itself.A more practical consideration is that the num-ber of forms within a sentence grows at such a rate(n + (n ?
1)... + 1) that error mining becomesunfeasible for large corpora, both in time and inspace.3.3 Expansion methodTo avoid suspicion sharing we have devised amethod for adding and expanding n-grams whenit is deemed useful.
This method iterates througha sentence of unigrams, and expands unigrams tolonger n-grams when there is evidence that it isuseful.
This expansion step is a preprocessor tothe iterative miner, that uses the same iterative al-gorithm as described by Sagot and De la Clergerie.Within this preprocessor, suspicion is defined inthe same manner as in Van Noord (2004), as a ra-tio of occurrences in unparsable sentences and thetotal number of occurrences.The motivation behind this method is that therecan be two expansion scenarios.
When we havethe bigram w1, w2, either one of the unigrams canbe problematic or the bigram w1, w2.
In the for-mer case, the bigram w1, w2 will also inherit thehigh suspicion of the problematic unigram.
In thelatter case, the bigram will have a higher suspicionthan both of its unigrams.
Consequently, we wantto expand the unigram w1 to the bigram w1, w2 ifthe bigram is more suspicious than both of its un-igrams.
If w1, w2 is equally suspicious as one ofits unigrams, it is not useful to expand to a bigramsince we want to isolate the cause of the parsingerror as much as possible.The same methodology is followed when weexpand to longer n-grams.
Expansion of w1, w2to the trigram w1, w2, w3 will only be permittedif w1, w2, w3 is more suspicious than its bigrams.Since the suspicion of w3 aggregates to w2, w3,we account for both w3 and w2, w3 in this com-parison.The general algorithm is that the expansion toan n-gram i..j is allowed when S(i..j) > S(i..j?1) and S(i..j) > S(i + 1..j).
This gives us a sen-tence that is represented by the n-grams n0..nx,n1..ny, ... n|si|?1..n|si|?1.3.4 Data sparsenessWhile initial experiments with the expansion al-gorithm provided promising results, the expansionalgorithm was too eager.
This eagerness is causedby data sparseness.
Since longer n-grams occurless frequently, the suspicion of an n-gram oc-curring in unparsable sentences goes up with thelength of the n-gram until it reaches its maximumvalue.
The expansion conditions do not take thiseffect into account.To counter this problem, we have introduced anexpansion factor.
This factor depends on the fre-quency of an n-gram within unparsable sentencesand asymptotically approaches one for higher fre-quencies.
As a result more burden of proofis inflicted upon the expansion: the longer n-gram either needs to be relatively frequent, or itneeds to be much more suspicious than its (n-1)-grams.
The expansion conditions are changed toS(i..j) > S(i..j ?
1) ?
extFactor and S(i..j) >S(i + 1..j) ?
extFactor, whereextFactor = 1 + e?
?|Of,unparsable| (8)In our experiments ?
= 1.0 proved to be a goodsetting.3.5 Pattern expansionPrevious work on error mining was primarily fo-cused on the extraction of interesting word n-grams.
However, it could also prove useful to al-low for patterns consisting of other informationthan words, such as part of speech tags or lemmas.We have done preliminary work on the integra-tion of part of speech tags during the n-gram ex-73pansion.
We use the same methodology as word-based n-gram expansion, however we also con-sider expansion with a part of speech tag.Since we are interested in building patterns thatare as general as possible, we expand the pat-tern with a part of speech tag if that creates amore suspicious pattern.
Expansion with a wordis attempted if expansion with a part of speechtag is unsuccessful.
E.g., if we attempt to ex-pand the word bigram w1w2, we first try the tagexpansion w1w2t3.
This expansion is allowedwhen S(w1, w2, t3) > S(w1, w2) ?
extFactorand S(w1, w2, t3) > S(w2, t3) ?
extFactor.
Ifthe expansion is not allowed, then expansion toS(w1, w2, w3) is attempted.
As a result, mixedpatterns emerge that are as general as possible.4 Implementation4.1 Compact representation of dataTo be able to mine large corpora some precau-tions need to be made.
During the n-gram expan-sion stage, we need quick access to the frequen-cies of arbitrary length n-grams.
Additionally, allunparsable sentences have to be kept in memory,since we have to traverse them for n-gram expan-sion.
Ordinary methods for storing n-gram fre-quencies (such as hash tables) and data will notsuffice for large corpora.As Van Noord (2004) we used perfect hashingto restrict memory use, since hash codes are gen-erally shorter than the average token length.
Addi-tionally, comparisons of numbers are much fasterthan comparisons of strings, which speeds up then-gram expansion step considerably.During the n-gram expansion step the minercalculates ratio-based suspicions of n-grams us-ing frequencies of an n-gram in parsable and un-parsable sentences.
The n-gram can potentiallyhave the length of a whole sentence, so it is notpractical to store n-gram ratios in a hash table.Instead, we compute a suffix array (Manber andMyers, 1990) for the parsable and unparsable sen-tences1.
A suffix array is an array that contains in-dices pointing to sequences in the data array, thatare ordered by suffix.We use suffix arrays differently than Van No-ord (2004), because our expansion algorithm re-quires the parsable and unparsable frequencies ofthe (n-1)-grams, and the second (n-1)-gram is not1We use the suffix sorting algorithm by Peter M. McIlroyand M. Douglas McIlroy.
(necessarily) adjacent to the n-gram in the suffixarray.
As such, we require random access to fre-quencies of n-grams occurring in the corpus.
Wecan compute the frequency of any n-gram by look-ing up its upper and lower bounds in the suffix ar-ray2, where the difference is the frequency.4.2 Determining ratios for pattern expansionWhile suffix arrays provide a compact and rela-tively fast data structure for looking up n-gram fre-quencies, they are not usable for pattern expansion(see section 3.5).
Since we need to look up fre-quencies of every possible combination of repre-sentations that are used, we would have to createdl suffix arrays to be (theoretically) able to lookup pattern frequencies with the same time com-plexity, where d is the number of dimensions andl is the corpus length.For this reason, we use a different method forcalculating pattern frequencies.
First, we build ahash table for each type of information that canbe used in patterns.
A hash table contains an in-stance of such information as a key (e.g.
a specificword or part of speech tag) and a set of corpus in-dices where the instance occurred in the corpus asthe value associated with that key.
Now we canlook up the frequency of a sequence i..j by calcu-lating the set intersection of the indices of j andthe indices found for the sequence i..j ?
1, afterincrementing the indices of i..j ?
1 by one.The complexity of calculating frequencies fol-lowing this method is linear, since the set of in-dices for a given instance can be retrieved witha O(1) time complexity, while both increment-ing the set indices and set intersection can be per-formed in O(n) time.
However, n can be verylarge: for instance, the start of sentence markerforms a substantial part of the corpus and is lookedup once for every sentence.
In our implementationwe limit the time spent on such patterns by cachingvery frequent bigrams in a hash table.4.3 Removing low-suspicion formsSince normally only one form within a sentencewill be responsible for a parsing error, many formswill have almost no suspicion at all.
However, dur-ing the mining process, their suspicions will berecalculated during every cycle.
Mining can besped up considerably by removing forms that havea negligible suspicion.2Since the suffix array is sorted, finding the upper andlower bounds is a binary search in O(log n) time.74If we do not drop forms, mining of the DutchWikipedia corpus described in section 5.3, withn-gram expansion and the extension factor en-abled, resulted in 4.8 million forms with 13.4 mil-lion form observations in unparsable sentences.
Ifwe mine the same material and drop forms witha suspicion below 0.001 there were 3.5 millionforms and 4.0 million form observations withinunparsable sentences left at the end of the iterativemining process.5 Evaluation5.1 MethodologyIn previous articles, error mining methods haveprimarily been evaluated manually.
Both Van No-ord (2004) and Sagot and de la Clergerie (2006)make a qualitative analysis of highly suspiciousforms.
But once one starts experimenting with var-ious extensions, such as n-gram expansion and ex-pansion factor functions, it is difficult to qualifychanges through small-scale qualitative analysis.To be able to evaluate changes to the errorminer, we have supplemented qualitative analysiswith a automatic quantitative evaluation method.Since error miners are used by grammar engineersto correct a grammar or lexicon by hand, the eval-uation metric should model this use case:?
We are interested in seeing problematic formsthat account for errors in a large number ofunparsable sentences first.?
We are only interested in forms that actuallycaused the parsing errors.
Analysis of formsthat do not, or do not accurately pinpoint ori-gin of the parsing errors costs a lot of time.These requirements map respectively to the re-call and precision metrics from information re-trieval:P =|{Sunparsable} ?
{Sretrieved}||{Sretrieved}|(9)R =|{Sunparsable} ?
{Sretrieved}||{Sunparsable}|(10)Consequently, we can also calculate the f-score(van Rijsbergen, 1979):F ?
score =(1 + ?2) ?
(P ?
R)(?2 ?
P + R)(11)The f-score is often used with ?
= 1.0 to giveas much weight to precision as recall.
In evalu-ating error mining, this can permit cheating.
Forinstance, consider an error mining that recalls thestart of sentence marker as the first problematicform.
Such a strategy would instantly give a re-call of 1.0, and if the coverage of a parser for acorpus is relatively low, a relatively good initial f-score will be obtained.
Since error mining is oftenused in situations where coverage is still low, wegive more bias to precision by using ?
= 0.5.We hope to provide more evidence in the futurethat this evaluation method indeed correlates withhuman evaluation.
But in our experience it has therequired characteristics for the evaluation of errormining.
For instance, it is resistant to recallingof different or overlapping n-grams from the samesentences, or recalling n-grams that occur often inboth parsable and unparsable sentences.5.2 Scoring methodsAfter error mining, we can extract a list of formsand suspicions, and order the forms by their sus-picion.
But normally we are not only interested informs that are the most suspicious, but forms thatare suspicious and frequent.
Sagot and de la Clerg-erie (2006) have proposed three scoring methodsthat can be used to rank forms:?
Concentrating on suspicions: Mf = Sf?
Concentrating on most frequent potential er-rors: Mf = Sf |Of |?
Balancing between these possibilities: Mf =Sf ?
ln|Of |For our experiments, we have replaced the ob-servation frequencies of the form (|Of |) by thefrequency of observations within unparsable sen-tences (|{Of,unparsable}|).
This avoids assigning ahigh score to very frequent unsuspicious forms.5.3 MaterialIn our experiments we have used two corpora thatwere parsed with the wide-coverage Alpino parserand grammar for Dutch:?
Quantitative evaluation was performed on theDutch Wikipedia of August 20083.
This cor-pus consists of 7 million sentences (109 mil-lion words).
For 8.4% of the sentences no fullanalysis could be found.3http://ilps.science.uva.nl/WikiXML/75?
A qualitative evaluation of the extensions wasperformed on the Flemish Mediargus news-paper corpus (up to May 31, 2007)4.
Thiscorpus consists of 67 million sentences (1.1billion words).
For 9.2% of the sentences nofull analysis could be found.Flemish is a variation of Dutch written and spo-ken in Belgium, with a grammar and lexicon thatdeviates slightly from standard Dutch.
Previously,the Alpino grammar and lexicon was never specif-ically modified for parsing Flemish.6 Results6.1 Iterative error miningWe have evaluated the different mining methodswith the three scoring functions discussed in sec-tion 5.2.
In the results presented in this section weonly list the results with the scoring function thatperformed best for a given error mining method(section 6.3 provides an overview of the best scor-ing functions for different mining methods).Our first interest was if, and how much itera-tive error mining outperforms error mining withsuspicion as a ratio.
To test this, we comparedthe method described by Van Noord (2004) andthe iterative error miner of Sagot and de la Clerg-erie (2006).
For the iterative error miner we eval-uated both on unigrams, and on unigrams and bi-grams where all unigrams and bigrams are used(without further selection).
Figure 6.1 shows thef-scores for these miners after N retrieved forms.00.050.10.150.20.250.30.350.40.450.50  2000  4000  6000  8000  10000F 0.5-ScoreNratioiter.unigramsiter.uni.bigramsFigure 1: F-scores after retrieving N forms forratio-based mining, iterative mining on unigramsand iterative mining on uni- and bigrams.4http://www.mediargus.be/The unigram iterative miner outperforms theratio-based miner during the retrieval of the first8000 forms.
The f-score graph of the iterativeminer on unigrams flattens after retrieving about4000 forms.
At that point unigrams are not spe-cific enough anymore to pinpoint more sophisti-cated problems.
The iterative miner on uni- and bi-grams performs better than the ratio-based miner,even beyond 8000 forms.
More importantly, thecurves of the iterative miners are steeper.
This isrelevant if we consider that a grammar engineerwill only look at a few thousands of forms.
Forinstance, the ratio-based miner achieves an f-scoreof 0.4 after retrieving 8448 forms, while the iter-ative miner on uni- and bigrams attains the samef-score after retrieving 5134 forms.6.2 N-gram expansionIn our second experiment we have compared theperformance of iterative mining on uni- and bi-grams with an iterative miner using the n-gramexpansion algorithm described in section 3.
Fig-ure 6.2 shows the result of n-gram expansion com-pared to mining just uni- and bigrams.
Both theresults for expansion with and without use of theexpansion factor are shown.00.050.10.150.20.250.30.350.40.450.50  2000  4000  6000  8000  10000F 0.5-ScoreNiter.uni.bigramiter.expansioniter.expansion.efFigure 2: F-scores after retrieving N forms for it-erative mining on uni- and bigrams, and iterativemining using n-gram expansion with and withoutusing an expansion factor.We can see that the expansion to longer n-gramsgives worse results than mining on uni- and bi-grams when data sparseness is not accounted for.The expansion stage will select forms that may beaccurate, but that are more specific than needed.As such, the recall per retrieved form is lower on76average, as can be seen in figure 6.2.
But if sparse-ness is taken into account through the use of theexpansion factor, we achieve higher f-scores thanmining on uni- and bigrams up to the retrieval ofcirca five thousand forms.
Since a user of an errormining tool will probably only look at the first fewthousands of forms, this is a welcome improve-ment.00.020.040.060.080.10.120.140.160  2000  4000  6000  8000  10000RecallNiter.uni.bigramiter.expansioniter.expansion.efFigure 3: Recall after retrieving N forms for it-erative mining on uni- and bigrams, and iterativemining using n-gram expansion with and withoutusing an expansion factor.Among the longer n-grams in the mining resultsfor the Mediargus corpus, we found many Flemishidiomatic expressions that were not described inthe Alpino lexicon.
For example:?
had er (AMOUNT) voor veil [had(AMOUNT) for sale]?
(om de muren) van op te lopen [to get terriblyannoyed by]?
Ik durf zeggen dat [I dare to say that]?
op punt stellen [to fix/correct something]?
de daver op het lijf [shocked]?
(op) de tippen (van zijn tenen) [being verycareful]?
ben fier dat [am proud of]?
Nog voor halfweg [still before halfway]?
(om duimen en vingers) van af te likken [de-licious]Since these expressions are longer than bi-grams, they cannot be captured properly withoutusing n-gram expansion.
We also found longern-grams describing valid Dutch phrases that werenot described by the grammar or lexicon.?
Het stond in de sterren geschreven dat [It waswritten in the stars that]?
zowat de helft van de [about half of the]?
er zo goed als zeker van dat [almost sure of]?
laat ons hopen dat het/dit lukt [let us hope thatit/this works]6.3 Scoring methodsThe miners that use n-gram expansion performbest with the Mf = Sf |Of | function, while theother miners perform best with the Mf = Sf ?ln|Of | function.
This is not surprising ?
the it-erative miners that do not use n-gram expansioncan not make very specific forms and give rela-tively high scores to forms that happen to occur inunparsable sentences (since some forms in a sen-tence will have to take blame, if no specific sus-picious form is found).
If such forms also hap-pen to be frequent, they may be ranked higherthan some more suspicious infrequent forms.
Inthe case of the ratio-based miner, there are manyforms that are ?suspicious by accident?
which maybecome highly ranked when they are more fre-quent than very suspicious, but infrequent forms.Since the miners with n-gram expansion can findspecific suspicious forms and shift blame to them,there is less chance of accidentally ranking a formto highly by directly including the frequency ofobservations of that form within unparsable sen-tences in the scoring function.6.4 Pattern expansionWe have done some preliminary experiments withpattern expansion, allowing for patterns consistingof words and part of speech tags.
For this exper-iment we trained a Hidden Markov Model part ofspeech tagger on 90% of the Dutch Eindhoven cor-pus using a small tag set.
We then extracted 50000unparsable and about 495000 parsable sentencesfrom the Flemish Mediargus corpus.
The patternexpansion preprocessor was then used to find in-teresting patterns.We give two patterns that were extracted to givean impression how patterns can be useful.
A fre-quent pattern was doorheen N (through followed77by a (proper) noun).
In Flemish a sentence suchas We reden met de auto doorheen Frankrijk (lit-eral: We drove with the car through France) is al-lowed, while in standard Dutch the particle heenis separated from the preposition door.
Conse-quently, the same sentence in standard Dutch is Wereden met de auto door Frankrijk heen.
Miningon word n-grams provided hints for this differencein Flemish through forms such as doorheen Krot-tegem, doorheen Engeland, doorheen Hawai, anddoorheen Middelkerke, but the pattern provides amore general description with a higher frequency.Another pattern that was found is wegens PrepAdj (because of followed by a preposition andan adjective).
This pattern captures prepositionalmodifiers where wegens is the head, and the fol-lowing words within the constituent form an ar-gument, such as in the sentence Dat idee werdsnel opgeborgen wegens te duur (literal: That ideabecame soon archived because of too expensive).This pattern provided a more general descriptionof forms such as wegens te breed (because it istoo wide), wegens te deprimerend (because it istoo depressing), wegens niet rendabel (because itis not profitable), and wegens te ondraaglijk (be-cause it is too unbearable).While instances of both patterns were found us-ing the word n-gram based miner, patterns consol-idate different instances.
For example, there were120 forms with a high suspicion containing theword wegens.
If such a form is corrected, the otherexamples may still need to be checked to see if asolution to the parsing problem is comprehensive.The pattern gives a more general description of theproblem, and as such, most of these 120 forms canbe represented by the pattern wegens Prep Adj.Since we are still optimizing the pattern ex-pander to scale to large corpora, we have not per-formed an automatic evaluation using the DutchWikipedia yet.7 ConclusionsWe combined iterative error mining with expan-sion of forms to n-grams of an arbitrary length,that are long enough to capture interesting phe-nomena, but not longer.
We dealt with the prob-lem of data sparseness by introducing an expan-sion factor that softens when the expanded form isvery frequent.In addition to the generalization of iterative er-ror mining, we introduced a method for automaticevaluation.
This allows us to test modifications tothe error miner without going through the tedioustask of ranking and judging the results manually.Using this automatic evaluation method, wehave shown that iterative error mining improvesupon ratio-based error mining.
As expected,adding bigrams improves performance.
Allowingexpansion beyond bigrams can lead to data sparse-ness problems, but if we correct for data sparse-ness the performance of the miner improves overmining on just unigrams and bigrams.We have also described preliminary work ona preprocessor that allows for more general pat-terns that incorporate additional information, suchas part of speech tags and lemmas.
We hope tooptimize and improve pattern-based mining in thefuture and evaluate it automatically on larger cor-pora.The error mining methods described in this pa-per are generic, and can be used for any grammaror parser, as long as the sentences within the cor-pus can be divided in a list of parsable and un-parsable sentences.
The error miner is freely avail-able5, and is optimized to work on large corpora.The source distribution includes a graphical userinterface for browsing mining results, showing theassociated sentences, and removing forms whenthey have been corrected in the grammar or lex-icon.ReferencesGosse Bouma, Gertjan van Noord, and Robert Malouf.2001.
Alpino: Wide-coverage Computational Anal-ysis of Dutch.
In Computational Linguistics in TheNetherlands 2000.Ann Copestake and Dan Flickinger.
2000.
Anopen source grammar development environment andbroad-coverage English grammar using HPSG.
InProceedings of LREC 2000, pages 591?600.Udi Manber and Gene Myers.
1990.
Suffix arrays: anew method for on-line string searches.
In SODA?90: Proceedings of the first annual ACM-SIAMsymposium on Discrete algorithms, pages 319?327.Society for Industrial and Applied Mathematics.Beno?
?t Sagot and E?ric de la Clergerie.
2006.
Errormining in parsing results.
In ACL-44: Proceed-ings of the 21st International Conference on Com-putational Linguistics and the 44th annual meetingof the Association for Computational Linguistics,pages 329?336, Morristown, NJ, USA.
Associationfor Computational Linguistics.5http://www.let.rug.nl/?dekok/errormining/78Gertjan Van Noord.
2004.
Error mining for wide-coverage grammar engineering.
In ACL ?04: Pro-ceedings of the 42nd Annual Meeting on Associa-tion for Computational Linguistics, page 446, Mor-ristown, NJ, USA.
Association for ComputationalLinguistics.C.
J. van Rijsbergen.
1979.
Information retrieval.
But-terworths, London, 2 edition.79
