Proceedings of the IJCNLP-08 Workshop on NER for South and South East Asian Languages, pages 51?58,Hyderabad, India, January 2008. c?2008 Asian Federation of Natural Language ProcessingBengali Named Entity Recognition using Support Vector MachineAsif EkbalDepartment of Computer Science andEngineering, Jadavpur UniversityKolkata-700032, Indiaasif.ekbal@gmail.comSivaji BandyopadhyayDepartment of Computer Science andEngineering, Jadavpur UniversityKolkata-700032, Indiasvaji_cse_ju@yahoo.comAbstractNamed Entity Recognition (NER) aims toclassify each word of a document into prede-fined target named entity classes and is nowa-days considered to be fundamental for manyNatural Language Processing (NLP) taskssuch as information retrieval, machine transla-tion, information extraction, question answer-ing systems and others.
This paper reportsabout the development of a NER system forBengali using Support Vector Machine(SVM).
Though this state of the art machinelearning method has been widely applied toNER in several well-studied languages, this isour first attempt to use this method to Indianlanguages (ILs) and particularly for Bengali.The system makes use of the different contex-tual information of the words along with thevariety of features that are helpful in predictingthe various named entity (NE) classes.
A por-tion of a partially NE tagged Bengali newscorpus, developed from the archive of a lead-ing Bengali newspaper available in the web,has been used to develop the SVM-based NERsystem.
The training set consists of approxi-mately 150K words and has been manuallyannotated with the sixteen NE tags.
Experi-mental results of the 10-fold cross validationtest show the effectiveness of the proposedSVM based NER system with the overall av-erage Recall, Precision and F-Score of 94.3%,89.4% and 91.8%, respectively.
It has beenshown that this system outperforms other ex-isting Bengali NER systems.1 IntroductionNamed Entity Recognition (NER) is an importanttool in almost all NLP application areas such asinformation retrieval, machine translation, question-answering system, automatic summarizationetc.
Proper identification and classification of NEsare very crucial and pose a very big challenge tothe NLP researchers.
The level of ambiguity inNER makes it difficult to attain human perform-anceNER has drawn more and more attention fromthe NE tasks (Chinchor 95; Chinchor 98) in Mes-sage Understanding Conferences (MUCs) [MUC6;MUC7].
The problem of correct identification ofNEs is specifically addressed and benchmarked bythe developers of Information Extraction System,such as the GATE system (Cunningham, 2001).NER also finds application in question-answeringsystems (Maldovan et al, 2002) and machinetranslation (Babych and Hartley, 2003).The current trend in NER is to use the machine-learning approach, which is more attractive in thatit is trainable and adoptable and the maintenance ofa machine-learning system is much cheaper thanthat of a rule-based one.
The representative ma-chine-learning approaches used in NER are HiddenMarkov Model (HMM) (BBN?s IdentiFinder in(Bikel, 1999)), Maximum Entropy (New YorkUniversity?s MEME in (Borthwick, 1999)), Deci-sion Tree (New York University?s system in (Se-kine, 1998) and Conditional Random Fields(CRFs) (Lafferty et al, 2001).
Support Vector Ma-chines (SVMs) based NER system was proposedby Yamada et al (2002) for Japanese.
His systemis an extension of Kudo?s chunking system (Kudoand Matsumoto, 2001) that gave the best perform-ance at CoNLL-2000 shared tasks.
The otherSVM-based NER systems can be found in (Takeu-chi and Collier, 2002) and (Asahara and Matsu-moto, 2003).Named entity identification in Indian languagesin general and particularly in Bengali is difficultand challenging.
In English, the NE always ap-pears with capitalized letter but there is no conceptof capitalization in Bengali.
There has been a very51little work in the area of NER in Indian languages.In Indian languages, particularly in Bengali, theworks in NER can be found in (Ekbal andBandyopadhyay, 2007a; Ekbal and Bandyop-adhyay, 2007b) with the pattern directed shallowparsing approach and in (Ekbal et al, 2007c) withthe HMM.
Other than Bengali, a CRF-based HindiNER system can be found in (Li and McCallum,2004).The rest of the paper is organized as follows.Support Vector Machine framework is describedbriefly in Section 2.
Section 3 deals with thenamed entity recognition in Bengali that describesthe named entity tagset and the detailed descrip-tions of the features for NER.
Experimental resultsare presented in Section 4.
Finally, Section 5 con-cludes the paper.2 Support Vector MachinesSupport Vector Machines (SVMs) are relativelynew machine learning approaches for solving two-class pattern recognition problems.
SVMs are wellknown for their good generalization performance,and have been applied to many pattern recognitionproblems.
In the field of NLP, SVMs are applied totext categorization, and are reported to haveachieved high accuracy without falling into over-fitting even though with a large number of wordstaken as the features.Suppose we have a set of training data for a two-class problem: 1 1{( , ),.....( , )}N Nx y x y , whereDix R  is a feature vector of the i-th sample in thetraining   data and { 1, 1}iy     is the class to whichix belongs.
The goal is to find a decision functionthat accurately predicts class y for an input vectorx.
A non-linear SVM classifier gives a decisionfunction f(x) sign(g(x) for an input vectorwhere,1( ) ( , )imiig x wK x z b Here, f(x) +1 means x is a member of a cer-tain class and f(x)  -1 means x is not a member.zi s are called support vectors and are representa-tives of training examples, m is the number of sup-port vectors.
Therefore, the computational com-plexity of ( )g x  is proportional to m. Support vec-tors and other constants are determined by solvinga certain quadratic programming problem.
( , )iK x z is a kernel that implicitly maps vectorsinto a higher dimensional space.
Typical kernelsuse dot products: ( , ) ( .
)iK x z k x z .
A polynomialkernel of degree d is given by( , )iK x z =(1 )dx .
We can use various kernels,and the design of an appropriate kernel for a par-ticular application is an important research issue.We have developed our system using SVM(Jochims, 1999) and (Valdimir, 1995), which per-forms classification by constructing an N-dimensional hyperplane that optimally separatesdata into two categories.
Our general NER systemincludes two main phases: training and classifica-tion.
Both the training and classification processeswere carried out by YamCha1 toolkit, an SVMbased tool for detecting classes in documents andformulating the NER task as a sequential labelingproblem.
Here, the pair wise multi-class decisionmethod and second degree polynomial kernel func-tion were used.
We have used TinySVM-0.072classifier that seems to be the best optimizedamong publicly available SVM toolkits.3 Named Entity Recognition in BengaliBengali is one of the widely used languages allover the world.
It is the seventh popular languagein the world, second in India and the national lan-guage of Bangladesh.
A partially NE tagged Ben-gali news corpus (Ekbal and Bandyopadhyay,2007d), developed from the archive of a widelyread Bengali newspaper.
The corpus containsaround 34 million word forms in ISCII (IndianScript Code for Information Interchange) andUTF-8 format.
The location, reporter, agency anddifferent date tags (date, ed, bd, day) in the par-tially NE tagged corpus help to identify some ofthe location, person, organization and miscellane-ous names, respectively that appear in some fixedplaces of the newspaper.
These tags cannot detectthe NEs within the actual news body.
The date in-formation obtained from the news corpus providesexample of miscellaneous names.
A portion of thispartially NE tagged corpus has been manually an-notated with the sixteen NE tags as described inTable 1.3.1 Named Entity TagsetA SVM based NER system has been developed inthis work to identify NEs in Bengali and classify1http://chasen-org/~taku/software/yamcha/2http://cl.aist-nara.ac.jp/~taku-ku/software/TinySVM52them into the predefined four major categories,namely, ?Person name?, ?Location name?, ?Organi-zation name?
and ?Miscellaneous name?.
In orderto properly denote the boundaries of the NEs andto apply SVM in NER task, sixteen NE and onenon-NE tags have been defined as shown in Table1.
In the output, sixteen NE tags are replaced ap-propriately with the four major NE tags by somesimple heuristics.NE tag Meaning ExamplePER Single word per-son namesachin / PERLOC Single word loca-tion namejdavpur/LOCORG Single word or-ganization nameinfosys / ORGMISC Single word mis-cellaneous name100%/ MISCB-PERI-PERE-PERBeginning, Inter-nal or the End ofa multiword per-son namesachin/B-PERramesh/I-PERtendulkar/E-PERB-LOCI-LOCE-LOCBeginning, Inter-nal or the End ofa multiword loca-tion namemahatma/B-LOCgandhi/I-LOCroad/E-LOCB-ORGI-ORGE-ORGBeginning, Inter-nal or the End ofa multiword or-ganization namebhaba/B-ORGatomic/I-ORGresearch/I-ORGcenter/E-ORGB-MISCI-MISCE-MISCBeginning, Inter-nal or the End ofa multiword mis-cellaneous name10e/B-MISCmagh/I-MISC1402/E-MISCNNE Words that arenot named enti-tiesneta/NNE,bidhansabha/NNETable 1.
Named Entity Tagset3.2 Named Entity Feature DescriptionsFeature selection plays a crucial role in the SupportVector Machine (SVM) framework.
Experimentshave been carried out in order to find out the mostsuitable features for NER in Bengali.
The mainfeatures for the NER task have been identifiedbased on the different possible combination ofavailable word and tag context.
The features alsoinclude prefix and suffix for all words.
The termprefix/suffix is a sequence of first/last few charac-ters of a word, which may not be a linguisticallymeaningful prefix/suffix.
The use of prefix/suffixinformation works well for highly inflected lan-guages like the Indian languages.
In addition, vari-ous gazetteer lists have been developed for use inthe NER task.
We have considered different com-bination from the following set for inspecting thebest feature set for NER task:F={ 1 1,..., , , ,...,i m i i i i nw w w w w    , |prefix|n, |suffix|n,previous NE tags, POS tags, First word, Digit in-formation, Gazetteer lists}Following are the details of the set of featuresthat have been applied to the NER task:Context word feature: Previous and next words ofa particular word might be used as a feature.Word suffix: Word suffix information is helpfulto identify NEs.
This feature can be used in twodifferent ways.
The first and the na?ve one is, afixed length word suffix of the current and/or thesurrounding word(s) might be treated as feature.The second and the more helpful approach is tomodify the feature as binary valued.
Variablelength suffixes of a word can be matched with pre-defined lists of useful suffixes for different classesof NEs.
The different suffixes that may be particu-larly helpful in detecting person (e.g., -babu, -da, -di etc.)
and location names (e.g., -land, -pur, -liaetc.)
are also included in the lists of variable lengthsuffixes.
Here, both types of suffixes have beenused.Word prefix: Prefix information of a word is alsohelpful.
A fixed length prefix of the current and/orthe surrounding word(s) might be treated as fea-tures.Part of Speech (POS) Information: The POS ofthe current and/or the surrounding word(s) can beused as features.
Multiple POS information of thewords can be a feature but it has not been used inthe present work.
The alternative and the betterway is to use a coarse-grained POS tagger.Here, we have used a CRF-based POS tagger,which was originally developed with the help of 26different POS tags3, defined for Indian languages.For NER, we have considered a coarse-grainedPOS tagger that has only the following POS tags:NNC (Compound common noun), NN (Com-mon noun), NNPC (Compound proper noun), NNP(Proper noun), PREP (Postpositions), QFNUM(Number quantifier) and Other (Other than theabove).3http://shiva.iiit.ac.in/SPSAL2007/iiit_tagset_guidelines.pdf53The POS tagger is further modified with twoPOS tags (Nominal and Other) for incorporatingthe nominal POS information.
Now, a binary val-ued feature ?nominalPOS?
is defined as: If the cur-rent/surrounding word is ?Nominal?
then the?nominalPOS?
feature of the corresponding word isset to ?+1?
; otherwise, it is set to ?-1?.
This binaryvalued ?nominalPOS?
feature has been used in ad-dition to the 7-tag POS feature.
Sometimes, post-positions play an important role in NER as postpo-sitions occur very frequently after a NE.
A binaryvalued feature ?nominalPREP?
is defined as: If thecurrent word is nominal and the next word is PREPthen the feature ?nomianlPREP?
of the currentword is set to ?+1?, otherwise, it is set to ?-1?.Named Entity Information: The NE tag(s) of theprevious word(s) can also be considered as the fea-ture.
This is the only dynamic feature in the ex-periment.First word: If the current token is the first word ofa sentence, then the feature ?FirstWord?
is set to?+1?
; Otherwise, it is set to ?-1?.Digit features: Several digit features have beenconsidered depending upon the presence and/or thenumber of digit(s) in a token (e.g., ContainsDigit[token contains digits], FourDigit [token consistsof four digits], TwoDigit [token consists of twodigits]), combination of digits and punctuationsymbols (e.g., ContainsDigitAndComma [tokenconsists of digits and comma], ConatainsDigi-tAndPeriod [token consists of digits and periods]),combination of digits and symbols (e.g., Con-tainsDigitAndSlash [token consists of digit andslash], ContainsDigitAndHyphen [token consistsof digits and hyphen], ContainsDigitAndPercent-age [token consists of digits and percentages]).These binary valued features are helpful in recog-nizing miscellaneous NEs such as time expres-sions, monetary expressions, date expressions, per-centages, numerical numbers etc.Gazetteer Lists: Various gazetteer lists have beendeveloped from the partially NE tagged Bengalinews corpus (Ekbal and Bandyopadhyay, 2007d).These lists have been used as the binary valuedfeatures of the SVM framework.
If the current to-ken is in a particular list, then the correspondingfeature is set to ?+1?
for the current and/or sur-rounding word(s); otherwise, it is set to ?-1?.
Thefollowing is the list of gazetteers:(i).
Organization suffix word (94 entries): This listcontains the words that are helpful in identifyingorganization names (e.g., kong, limited etc.).
Thefeature ?OrganizationSuffix?
is set to ?+1?
for thecurrent and the previous words.(ii).
Person prefix word (245 entries): This is use-ful for detecting person names (e.g., sriman, sree,srimati etc.).
The feature ?PersonPrefix?
is set to?+1?
for the current and the next two words.(iii).
Middle name (1,491 entries): These wordsgenerally appear inside the person names (e.g.,chandra, nath etc.).
The feature ?MiddleName?
isset to ?+1?
for the current, previous and the nextwords.(iv).
Surname (5,288 entries): These words usuallyappear at the end of person names as their parts.The feature ?SurName?
is set to ?+1?
for the currentword.(v).
Common location word (547 entries): This listcontains the words that are part of location namesand appear at the end (e.g., sarani, road, lane etc.
).The feature ?CommonLocation?
is set to ?+1?
forthe current word.(vi).
Action verb (221 entries): A set of actionverbs like balen, ballen, ballo, shunllo, haslo etc.often determines the presence of person names.The feature ?ActionVerb?
is set to ?+1?
for theprevious word.(vii).
Frequent word (31,000 entries): A list ofmost frequently occurring words in the Bengalinews corpus has been prepared using a part of thecorpus.
The feature ?RareWord?
is set to ?+1?
forthose words that are not in this list.(viii).
Function words (743 entries): A list of func-tion words has been prepared manually.
The fea-ture ?NonFunctionWord?
is set to ?+1?
for thosewords that are not in this list.(ix).
Designation words (947 entries): A list ofcommon designation words has been prepared.This helps to identify the position of the NEs, par-ticularly person names (e.g., neta, sangsad,kheloar etc.).
The feature ?DesignationWord?
is setto ?+1?
for the next word.(x).
Person name (72, 206 entries): This list con-tains the first name of person names.
The feature?PersonName?
is set to ?+1?
for the current word.(xi).
Location name (7,870 entries): This list con-tains the location names and the feature ?Loca-tionName?
is set to ?+1?
for the current word.(xii).
Organization name (2,225 entries): This listcontains the organization names and the feature?OrganizationName?
is set to ?+1?
for the currentword.(xiii).
Month name (24 entries): This contains thename of all the twelve different months of both54English and Bengali calendars.
The feature?MonthName?
is set to ?+1?
for the current word.(xiv).
Weekdays (14 entries): It contains the nameof seven weekdays in Bengali and English both.The feature ?WeekDay?
is set to ?+1?
for the cur-rent word.4 Experimental ResultsA partially NE tagged Bengali news corpus (Ekbaland Bandyopadhyay, 2007d) has been used to cre-ate the training set for the NER experiment.
Out of34 million wordforms, a set of 150K wordformshas been manually annotated with the 17 tags asshown in Table 1 with the help of Sanchay Editor4,a text editor for Indian languages.
Around 20K NEtagged corpus is selected as the development setand the rest 130K wordforms are used as the train-ing set of the SVM based NER system.We define the baseline model as the one wherethe NE tag probabilities depend only on the currentword:1 2 3 1 2 31...( , , ..., | , , ..., ) ( , )n n i ii nP t t t t w w w w P t wIn this model, each word in the test data is as-signed the NE tag that occurs most frequently forthat word in the training data.
The unknown wordis assigned the NE tag with the help of variousgazetteers and NE suffix lists.Seventy four different experiments have beenconducted taking the different combinations fromthe set ?F?
to identify the best-suited set of featuresfor NER in Bengali.
From our empirical analysis,we found that the following combination gives thebest result for the development set.F={ 3 2 1 1 2i i i i i iw w w w w w     , |prefix|<=3,|suffix|<=3, NE information of the window [-2, 0],POS information of the window [-1, +1], nominal-POS of the current word, nominalPREP,FirstWord, Digit features, Gazetteer lists}The meanings of the notations, used in experi-mental results, are defined below:pw, cw, nw: Previous, current and the nextword; pwi, nwi: Previous and the next ith wordfrom the current word; pt: NE tag of the previousword; pti: NE tag of the previous ith word; pre,suf: Prefix and suffix of the current word; ppre,psuf: Prefix and suffix of the previous word; npre,nsuf: Prefix and suffix of the next word; pp, cp, np:POS tag of the previous, current and the next word;4Sourceforge.net/project/nlp-sanchayppi, npi: POS tag of the previous and the next ithword; cwnl: Current word is nominal.Evaluation results of the development set arepresented in Tables 2-4.Feature (word, tag)  FS (%)pw, cw, nw, FirstWord 71.23pw2, pw, cw, nw, nw2, FirstWord 73.23pw3, pw2, pw, cw, nw, nw2,FirstWord74.87pw3, pw2, pw, cw, nw, nw2, nw3,FirstWord74.12pw4, pw3, pw2, pw, cw, nw, nw2,FirstWord74.01pw3, pw2, pw, cw, nw, nw2, FirstWord, pt75.30pw3, pw2, pw, cw, nw, nw2, FirstWord, pt, pt276.23pw3, pw2, pw, cw, nw, nw2, FirstWord, pt, pt2, pt375.48pw3, pw2, pw, cw, nw, nw2, FirstWord, pt, pt2, | |suf|<=4, pre|<=478.72pw3, pw2, pw, cw, nw, nw2, FirstWord, pt, pt2, |suf|<=3, |pre|<=381.2pw3, pw2, pw, cw, nw, nw2, FirstWord, pt, pt2, |suf|<=3, |pre|<=3|psuf|<=380.4pw3, pw2, pw, cw, nw, nw2, FirstWord, pt, pt2, |suf|<=3, |pre|<=3,|psuf|<=3, |nsuf|<=3, |ppre|<=3,|npre|<=378.14pw3, pw2, pw, cw, nw, nw2, FirstWord, pt, pt2, |suf|<=3, |pre|<=3,|nsuf|<=3, |npre|<=379.90pw3, pw2, pw, cw, nw, nw2, FirstWord, pt, pt2, |suf|<=3, |pre|<=3,|psuf|<=3, |ppre|<=3,80.10pw3, pw2, pw, cw, nw, nw2, FirstWord, pt, pt2, |suf|<=3, |pre|<=3,Digit82.8Table 2.
Results on the Development SetIt is observed from Table 2 that the word win-dow [-3, +2] gives the best result (4th row) with the?FirstWord?
feature and further increase or de-crease in the window size reduces the overall F-Score value.
Results (7th-9th rows) show that theinclusion of NE information increases the F-Scorevalue and the NE information of the previous twowords gives the best results (F-Score=81.2%).
It isindicative from the evaluation results (10th and 11th55rows) that prefixes and suffixes of length up tothree of the current word are very effective.
It isalso evident (12th-15th rows) that the surroundingword prefixes and/or suffixes do not increase theF-Score value.
The F-Score value is improved by1.6% with the inclusion of various digit features(15th and 16th rows).Feature (word, tag)  FS ( %)pw3, pw2, pw, cw, nw, nw2, FirstWord, pt, pt2, |suf|<=3, |pre|<=3,Digit, pp, cp, np87.3pw3, pw2, pw, cw, nw, nw2, FirstWord, pt, pt2, |suf|<=3, |pre|<=3,Digit, pp2, pp, cp, np, np285.1pw3, pw2, pw, cw, nw, nw2, FirstWord, pt, pt2, |suf|<=3, |pre|<=3,Digit,  pp, cp86.4pw3, pw2, pw, cw, nw, nw2, FirstWord, pt, pt2, |suf|<=3, |pre|<=3,Digit, cp, np85.8pp2, pp, cp, np, np2, pt, pt2,|pre|<=3, |suf|<=3, FirstWord, Digit41.9pp, cp, np, pt, pt2, |pre|<=3, |suf|<=3,FirstWord, Digit36.4pw3, pw2, pw, cw, nw, nw2, FirstWord, pt, pt2, |suf|<=3, |pre|<=3,Digit, cp86.1Table 3.
Results on the Development SetExperimental results (2nd-5th rows) of Table 3suggest that the POS tags of the previous, currentand the next words, i.e., POS information of thewindow [-1, +1] is more effective than the window[-2, +2], [-1, 0], [0, +1] or the current word alone.In the above experiment, the POS tagger was de-veloped with 7 POS tags.
Results (6th and 7th rows)also show that POS information with the word ishelpful but only the POS information without theword decreases the F-Score value significantly.Results (4th and 5th rows) also show that the POSinformation of the window [-1, 0] is more effectivethan the POS information of the window [0, +1].So, it can be argued that the POS information ofthe previous word is more helpful than the POSinformation of the next word.In another experiment, the POS tagger was de-veloped with 26 POS tags and the use of this tag-ger has shown the F-Score value of 85.6% with thefeature (word, tag)=[pw3, pw2, pw, cw, nw, nw2,FirstWord, pt, pt2, |suf|<=3, |pre|<=3, Digit, pp, cp,np].
So, it can be decided that the smaller POStagset is more effective than the larger POS tagsetin NER.
We have observed from two different ex-periments that the overall F-Score values can fur-ther be improved by 0.5% and 0.3%, respectively,with the ?nominalPOS?
and ?nominalPREP?
fea-tures.
It has been also observed that the ?nominal-POS?
feature of the current word is only helpfuland not of the surrounding words.
The F-Scorevalue of the NER system increases to 88.1% withthe feature: feature (word, tag)=[pw3, pw2, pw,cw, nw, nw2, FirstWord, pt, pt2, |suf|<=3, |pre|<=3,Digit pp, cp, np, cwnl, nominalPREP].Experimental results with the various gazetteerlists are presented in Table 4 for the developmentset.
Results demonstrate that the performance ofthe NER system can be improved significantlywith the inclusion of various gazetteer lists.
Theoverall F-Score value increases to 90.7%, which isan improvement of 2.6%, with the use of gazetteerlists.The best set of features is identified by trainingthe system with 130K wordforms and tested withthe help of development set of 20K wordforms.Now, the development set is included as part of thetraining set and resultant training set is thus con-sisting of 150K wordforms.
The training set has20,455 person names, 11,668 location names, 963organization names and 11,554 miscellaneousnames.
We have performed 10-fold cross valida-tion test on this resultant training set.
The Recall,Precision and F-Score values of the 10 differentexperiments for the 10-fold cross validation testare presented in Table 5.
The overall average Re-call, Precision and F-Score values are 94.3%,89.4% and 91.8%, respectively.The other existing Bengali NER systems alongwith the baseline model have been also trained andtested with the same data set.
Comparative evalua-tion results of the 10-fold cross validation tests arepresented in Table 6 for the four different models.It presents the average F-Score values for the fourmajor NE classes: ?Person name?, ?Locationname?, ?Organization name?
and ?Miscellaneousname?.
Two different NER models, A and B, aredefined in (Ekbal and Bandyopadhyay, 2007b).The model A denotes the NER system that doesnot use linguistic knowledge and B denotes thesystem that uses linguistic knowledge.
Evaluationresults of Table 6 show that the SVM based NERmodel has reasonably high F-Score value.
The av-erage F-Score value of this model is 91.8%, whichis an improvement of 7.3% over the best-reported56HMM based Bengali NER system (Ekbal et al,2007c).
The reason behind the rise in F-Scorevalue might be its better capability to capture themorphologically rich and overlapping features ofBengali language.Feature (word, tag) FS (%)pw3, pw2, pw, cw, nw, nw2, FirstWord, pt, pt2, |suf|<=3, |pre|<=3,Digit pp, cp, np, cwnl, nominal-PREP, DesignationWord, Non-FunctionWord89.2pw3, pw2, pw, cw, nw, nw2, FirstWord, pt, pt2, |suf|<=3, |pre|<=3,Digit pp, cp, np, cwnl, nominal-PREP, DesignationWord, Non-FunctionWord89.5pw3, pw2, pw, cw, nw, nw2, FirstWord, pt, pt2, |suf|<=3, |pre|<=3,Digit pp, cp, np, cwnl, nominal-PREP, DesignationWord, Non-FunctionWord OrganizationSuf-fix, PersonPrefix90.2pw3, pw2, pw, cw, nw, nw2, FirstWord, pt, pt2, |suf|<=3, |pre|<=3,Digit pp, cp, np, cwnl, nominal-PREP, DesignationWord, Non-FunctionWord OrganizationSuf-fix, PersonPrefix MiddleName,CommonLocation90.5pw3, pw2, pw, cw, nw, nw2, FirstWord, pt, pt2, |suf|<=3, |pre|<=3,Digit pp, cp, np, cwnl, nominal-PREP, DesignationWord, No-FunctionWord OrganizationSuf-fix, PersonPrefix MiddleName,CommonLocation,  Other gazet-teers90.7Table 4.
Results on the Development SetThe F-Score value of the system increases withthe increment of training data.
This fact is repre-sented in Figure 1.
Also, it is evident from Figure 1that the value of ?Miscellaneous name?
is nearlyclose to 100% followed by ?Person name?, ?Loca-tion name?
and ?Organization name?
NE classeswith the training data of 150K words.Test set no.
Recall Precision FS (%)1 92.5 87.5 89.932 92.3 87.6 89.893 94.3 88.7 91.414 95.4 87.8 91.405 92.8 87.4 90.026 92.4 88.3 90.307 94.8 91.9 93.338 93.8 90.6 92.179 96.9 91.8 94.2810 97.8 92.4 95.02Average 94.3 89.4 91.8Table 5.
Results of the 10-fold cross validationtestModel F_P F_L F_O F_M F_TBaseline61.3 58.7 58.2 52.2 56.3A 75.3 74.7 73.9 76.1 74.5B 79.3 78.6 78.6 76.1 77.9HMM 85.5 82.8 82.2 92.7 84.5SVM 91.4 89.3 87.4 99.2 91.8Table 6.
Results of the 10-fold cross validationtest (F_P: Avg.
f-score of ?Person?, F_L: Avg.
f-score of ?Location?, F_O: Avg.
f-score of ?Organi-zation?, F_M: Avg.
f-score of ?Miscellaneous?
andF_T: Overall avg.
f-score of all classes)5 ConclusionWe have developed a NER system using the SVMframework with the help of a partially NE taggedBengali news corpus, developed from the archiveof a leading Bengali newspaper available in theweb.
It has been shown that the contextual windowof size six, prefix and suffix of length up to threeof the current word, POS information of the win-dow of size three, first word, NE information ofthe previous two words, different digit features andthe various gazetteer lists are the best-suited fea-tures for NER in Bengali.
Experimental resultswith the 10-fold cross validation test have shownreasonably good Recall, Precision and F-Scorevalues.
The performance of this system has beencompared with the existing three Bengali NER sys-tems and it has been shown that the SVM-basedsystem outperforms other systems.
One possiblereason behind the high Recall, Precision and F-Score values of the SVM based system might be itseffectiveness to handle the diverse and overlappingfeatures of the highly inflective Indian languages.57The proposed SVM based system is to betrained and tested with the other Indian languages,particularly Hindi, Telugu, Oriya and Urdu.
Ana-lyzing the performance of the system using othermethods like MaxEnt and CRFs will be other in-teresting experiments.F-Score(%) vs Training file size(K)0204060801001200 100 200Number of Words (K)F-Score(%)PersonLocationOrganisationMiscellaneousFig.
1.
F-Score VS Training file sizeReferencesAnderson, T. W. and Scolve, S. 1978.
Introduction tothe Statistical Analysis of Data.
Houghton Mifflin.Asahara, Masayuki and Matsumoto, Yuji.
2003.
Japa-nese Named Entity Extraction with Redundant Mor-phological Analysis.
In Proc.
of HLT-NAACL.Babych, Bogdan, A. Hartley.
2003.
Improving MachineTranslation Quality with Automatic Named EntityRecognition.
In Proceedings of EAMT/EACL 2003Workshop on MT and other language technologytools, 1-8, Hungary.Bikel, Daniel M., R. Schwartz, Ralph M. Weischedel.1999.
An Algorithm that Learns What?s in Name.Machine Learning (Special Issue on NLP), 1-20.Bothwick, Andrew.
1999.
A Maximum Entropy Ap-proach to Named Entity Recognition.
Ph.D. Thesis,New York University.Chinchor, Nancy.
1995.
MUC-6 Named Entity TaskDefinition (Version 2.1).
MUC-6, Maryland.Chinchor, Nancy.
1998.
MUC-7 Named Entity TaskDefinition (Version 3.5).
MUC-7, Fairfax, Virginia.Cunningham, H. 2001.
GATE: A General Architecturefor Text Engineering.
Comput.
Humanit.
(36), 223-254.Ekbal, Asif, and S. Bandyopadhyay.
2007a.
PatternBased Bootstrapping Method for Named Entity Rec-ognition.
In Proceedings of ICAPR, India, 349-355.Ekbal, Asif, and S. Bandyopadhyay.
2007b.
LexicalPattern Learning from Corpus Data for Named EntityRecognition.
In Proc.
of ICON, India, 123-128.Ekbal, Asif, Naskar, Sudip and S. Bandyopadhyay.2007c.
Named Entity Recognition and Transliterationin Bengali.
Named Entities: Recognition, Classifica-tion and Use, Special Issue of Lingvisticae Investiga-tiones Journal, 30:1 (2007), 95-114.Ekbal, Asif, and S. Bandyopadhyay.
2007d.
A Web-based Bengali News Corpus for Named Entity Rec-ognition.
Language Resources and Evaluation Jour-nal (To appear December).Joachims , T. 1999.
Making Large Scale SVM LearningPractical.
In B. Scholkopf, C. Burges and A. Smolaeditions, Advances in Kernel Methods-Support Vec-tor Learning, MIT Press.Kudo, Taku and Matsumoto, Yuji.
2001.
Chunking withSupport Vector Machines.
In Proceedings of NAACL,192-199.Kudo, Taku and Matsumoto, Yuji.
2000.
Use of SupportVector Learning for Chunk Identification.
In Pro-ceedings of CoNLL-2000.Lafferty, J., McCallum, A., and Pereira, F. 2001.
Condi-tional Random Fields: Probabilistic Models for Seg-menting and Labeling Sequence Data.
In Proc.
of18th International Conference on Machine learning,282-289.Li, Wei and Andrew McCallum.
2003.
Rapid Develop-ment of Hindi Named Entity Recognition UsingConditional Random Fields and Feature Inductions.ACM TALIP, 2(3), (2003), 290-294.Moldovan, Dan I., Sanda M. Harabagiu, Roxana Girju,P.
Morarescu, V. F. Lacatusu, A. Novischi, A.Badulescu, O. Bolohan.
2002.
LCC Tools for Ques-tion Answering.
In Proceedings of the TREC, 1-10.Sekine, Satoshi.
1998.
Description of the Japanese NESystem Used for MET-2.
MUC-7, Fairfax, Virginia.Takeuchi, Koichi and Collier, Nigel.
2002.
Use of Sup-port Vector Machines in Extended Named EntityRecognition.
In Proceedings of  6th CoNLL, 119-125.Vapnik, Valdimir N. 1995.
The Nature of StatisticalLearning Theory.
Springer.Yamada, Hiroyasu, Taku Kudo and Yuji Matsumoto.2002.
Japanese Named Entity Extraction using Sup-port Vector Machine.
In Transactions of IPSJ, Vol.43, No.
1, 44-53.58
