Proceedings of the 2nd Workshop on Building and Using Comparable Corpora, ACL-IJCNLP 2009, pages 64?67,Suntec, Singapore, 6 August 2009. c?2009 ACL and AFNLPToward Categorization of Sign Language CorporaJ?r?mie SegouatLIMSI-CNRS / Orsay, FranceWebSourd / Toulouse, Francejeremie.segouat@limsi.frAnnelies BraffortLIMSI-CNRS / Orsay, Franceannelies.braffort@limsi.frAbstractThis paper addresses the notion of parallel,noisy parallel and comparable corpora in thesign language research field.
As it is quite anew field, the categorization of sign languagecorpora is not well established, and does notrely on a straightforward basis.
Nevertheless,several kinds of corpora are now availableand could raise interesting issues, providedthat adapted tools and techniques are devel-oped.1 IntroductionSign Language (SL) is a visual-gestural lan-guage, using the whole upper body articulators(chest, arms, hands, head, face, and gaze) in asimultaneous way.
Signs (in some way, equiva-lent to words in vocal languages) are articulatedin the signing space located in front of the signer.This is a natural language, with its own linguisticstructures and specificities, used by deaf peopleto communicate in everyday life.
It can be consi-dered that there is one SL for each country, as forvocal languages.
One particularity is that there isno written form of SL (Garcia, 2006): corporatake the form of videos, thus specific design andanalysis methods have to be used.
Therefore,NLP and corpus linguistics definitions may haveto be adapted to this research field.1.1 Brief History of Sign Language Corpo-raResearch in SL has begun with the creation ofnotation systems.
These systems aim to describein a written form how SL could be performed.B?bian (1825), a French teacher, wrote a bookwhere he proposed a description of the FrenchSign Language (LSF) using drawings.
This de-scription took into account facial expressions andmanual gestures.
A major study was conductedby Stokoe (1960) on American SL.
The aim wasalso to describe SL, but this time only focused onmanual gestures.
These studies were based uponlive analyses: no video corpus was created.
Theresearchers had to watch how signers were per-forming SL, and then write down or draw whatthey were observing.In the 1980s, Cuxac (1996) created one of thefirst video SL corpora for linguistic studies.From the 1990s until now, video SL corporahave been created both to be used in linguisticstudies, as listed by Brugman (2003), and forgathering lexicons to create dictionaries1.
A fewyears ago, some video SL corpora were designedto serve as the basis for NLP and ImageProcessing (Neidle, 2000).1.2 DefinitionsFung (2004) distinguishes four kinds of corpora:parallel (?a sentence-aligned corpus containingbilingual translations of the same document?
),noisy parallel (?contain non-aligned sentencesthat are nevertheless mostly bilingual translationsof the same document?
), comparable (?containnon-sentence-aligned, non-translated bilingualdocuments that are topic-aligned?
), and very-non-parallel (?contains far more disparate, very-non-parallel bilingual documents that could ei-ther be on the same topic (in-topic) or not (off-topic)?).
If these definitions are still under dis-cussion in the NLP community, there is no suchdiscussion in the community which studies SLs.Would it be possible to apply such definitions toSign Languages corpora?Many corpora are mere dictionaries2, i.e.
theyonly contain isolated signs and no utterances, justsigns, but could be considered as very basic pa-rallel SL corpora.
As far as we know, there existsvery few noisy parallel SL corpora (see section2.2), and very few comparable SL corpora (Bun-geroth 2008, ECHO project3).1http://www.spreadthesign.com/country/gb/2http://www.limsi.fr/Scientifique/iles/Theme5/corpus3http://www.let.ru.nl/sign-lang/echo/64Because not enough data can be found on theway these corpora have been built and the waythey are used, it seems difficult to discuss wheth-er Fung?s definitions apply to them.
Thus, wepresent in this paper the corpora we have built(section 2) and explain why they could be consi-dered as parallel, noisy parallel or comparable.Section 3 discusses the use of NLP processes forSL corpora analysis, and section 4 presents pros-pects on existing or possible SL corpora.2 LIMSI?s Sign Language Corpora2.1 Parallel CorporaWe are currently building a French Sign Lan-guage (LSF)-French dictionary (Segouat 2008)that will be available on the Web.
We will pro-vide not only French and LSF translations, butalso linguistic descriptions of signs, and a func-tionality to search for signs from their visual as-pects or their linguistic descriptions.
This is amere parallel corpus that will be using to analyzethe variety of LSF in France (according to wherepeople live, where they have grown, where theylearned LSF, etc.
).We have recently built a corpus related to therailway information domain (Segouat, 2009).The starting point is written French sentencesthat exactly correspond to the vocal announce-ments made in railways stations.
The goal is toprovide information in LSF as it is provided vo-cally: by coarticulating pieces of utterances.Written French sentences were translated intoLSF and filmed, in order to study coarticulationin LSF.
We use this corpus to analyze how signsare modified according to their context.We participate in the DictaSign Europeanproject (Efthimiou, 2009) that aims at gatheringparallel SL corpora from four countries (Greece,England, Germany, and France).
One of its pur-poses is to study translations between differentsign languages (SLs) of these four countries.
Thewelcome page of the website4 includes presenta-tions of the project in the four different SLs thatare each direct translations of the correspondingwritten texts.
As it is a starting project, this cor-pus has not yet been studied nor considered froma comparability point of view.2.2 Noisy Parallel CorporaWe have taken part in the creation of the LS-COLIN corpus (Cuxac, 2001).
The aim of thisproject was to design a corpus that could be used4http://www.dictasign.euby linguists and computer scientists.
The metho-dology was the following: each deaf signer (i.e.
aperson who performs SL) was explained the pro-tocol.
The person had to perform several kinds ofstories, on several given themes or elicited byusing pictures.
For the picture based story, thedeaf signer was shown six pictures that draw aline for the story, and then expressed the story inLSF.
This corpus could be considered as a noisyparallel one, because the LSF version is a trans-lation of the pictures with addition of details.
Thelinguists have created a noisy parallel version ofsome parts of LS-COLIN, by providing a tran-scription with glosses (sign to word translation,without taking into consideration the grammati-cal structure involved: thus there is a lack of in-formation).
All the annotations were made inFrench text, and were used to analyze the gram-matical structure of LSF.We have participated to the WebSi project(Martin, 2009), which aims at evaluating whethercommon representations could be designed forgestures performed by speaking and signing per-sons, allowing bilingual applications to be devel-oped.
The first step was a study dedicated to thecomparison of deictic gestures, both with multi-modal-French and LSF utterances.
The corpusconsists of answers, by a deaf and a hearing per-son, to eleven questions eliciting responses withdeictic gestures of various kinds.
A French/LSFinterpreter formulated the questions so that bothsubjects were in the closest possible interactionconditions.
The observed productions were in-deed very different.
In the deaf person?s answers,a more complex structure was observed in deic-tics, because the deictic function is incorporatedinto the lexical signs, forming what is called in-dicating signs.
However, common global aspectswere observed in both types of productions,which are all constituted by pointing using gazeand manual gestures organized with a given tem-poral structure.2.3 Comparable corporaIn the LS-COLIN corpus, each deaf signer had toperform a story on several given themes, for ex-ample September 11 tragic events.
This can beconsidered as a synchronous comparable corpusbecause each signer expressed his own version ofthe same event.
The picture-based stories mayalso be considered as comparable corpora, be-cause deaf signers were asked to perform the sto-ry twice: at the beginning and at the end of therecording.
Thus it is the same topic, and the twoversions are not translations of one another; but65we are not certain that it can be considered as?non-sentence-aligned?
because they both followpicture order.
Computer scientists have used LS-COLIN from a comparability point of view, toanalyze the visual modality in LSF: they studiedtorso (Segouat, 2006) and facial (Ch?telat-Pel?,2008) movements.
These studies were made onsame-topic stories performed by different deafsigners.
While these studies did consider thecomparability of the corpus, they were not fo-cused on that aspect.
Thanks to these studies, wemay observe differences in sign performancesamong deaf signers, from crossed linguistics andcomputer science perspectives.3 Computations on Sign LanguageCorporaThe computations in use for written data cannotbe used directly for video SL corpora.
Nowadaysthough, a way to study SL corpora is to annotatethem.
Annotations are mainly in written form,thus one might think of applying existing NLPmethods to the resulting ?texts?.
But would theconclusions be relevant enough?
A bias is thatannotations do not exactly represent SL utter-ances.
Annotations can be made with glosses orcomplete translations but these written data can-not describe in an efficient way typical SL prop-erties such as simultaneity, spatial organization,non-manual features, etc.In our opinion, it would thus be difficult toapply the computations used on written compa-rable corpora (Fung, 2004; Morin, 2006;Del?ger, 2008) or on parallel corpora to compa-rable or parallel SL corpora.Some studies currently focus on graphical an-notations, or use image processing to analyzevideo SL corpora (Bungeroth, 2008).
It is a firststep towards an analysis without any written textprocessing.
Suitable tools to deal with this kindof annotations still have to be set up.4 Promising Sign Language Corpora4.1 Existing CorporaThe Dicta-Sign project already provides a qua-drilingual corpus: the website contains four ver-sions of the same presentation in four differentsign languages.
An analysis of this corpus wouldbe interesting, because all SL videos were madefrom the English text.
The British SL, and alsothe other texts in French, Greek, and Germanwere obtained from the English written source.Then the corresponding SL videos in LSF, GreekSL, and German SL were translated from thetexts in written French, Greek, and German.
Thiscorpus is therefore parallel, although probablynoisy because of the double written-to-writtenthen written-to-SL translation process.
Compar-ing these videos would allow us to noticechanges in the translations between SLs, usingknowledge from the written-text translation fieldof research.The corpus dealing with information in Frenchrailway stations is a bilingual parallel corpus.Other corpora are going to be designed and usedin projects related to bus stations, airports, etc.Therefore we will have interesting parallel(French-LSF) and comparable (same topic) abouttransportation systems, to study.4.2 Other Possible CorporaThe WebSourd Company?s website 5  provideseveryday news translations in LSF, displayingboth the text that has been translated and the vid-eo in LSF.
Each year, all videos are archived ona DVD.
WebSourd is, as far as we know, the on-ly company that provides everyday informationin LSF.
Collecting other sources for the sametypes of information would yield an interestingsynchronous comparable corpus.In SL we distinguish ?translation?
from ?inter-pretation?.
Both could be performed either byhearing persons from vocal languages to SLs,and vice and versa, or by deaf persons from SLsto SLs.
A translation is done with significanttime taken for preparing the work.
It looks morelike a ?written?
form of language, thus suchtranslations can create parallel corpora.
Interpre-tation is done live, and often without any prepa-ration of what is going to be interpreted.
It ismore like ?oral?
expression, with discourse cor-rections, repetitions, etc., thus it is likely to pro-duce noisy corpora.
SL interpretation corpora areavailable (e.g.
every live interpretation on TV),but as far as we know they haven?t yet been ana-lyzed, although such study looks interesting.There are in France6 and in Great Britain7 twoTV programs presented in SL and made accessi-ble with oral and written translations.
These con-stitute a huge amount of parallel corpora (vocallanguage-sign language translations) that havenot yet been used in any research field.5http://www.websourd.org6http://www.france5.fr/oeil-et-la-main/index-fr.php?page=accueil7http://www.bbc.co.uk/blogs/seehear/665 ConclusionUntil now very few parallel or comparablesign language corpora of SL have been built, andthe few which exist were not studied from thesepoints of view.
Studying these parallel and com-parable SL corpora for linguistics, computerscience analysis, and for translation is therefore anew, yet to investigate area.
What we shouldconsider now is to set up a methodology to createthose corpora with the aim to study them as whatthey are: parallel orcomparable.
Moreover, wehave to develop new tools, and adapt existingones, that will fit this goal.ReferenceRoch-A.
B?bian.
1825.
Mimographie, ou essaid?
?criture mimique, propre ?
r?gulariser lelangage des sourds-muets.
Paris.
L. Colas eds.Annelies Braffort, Christian Cuxac, Annick Choisier,Christophe Collet, Patrice Dalle, Ivani Fusellier,Rachid Gherbi, Guillemette Jausions, GwenaelleJirou, Fanch Lejeune, Boris Lenseigne, NathalieMonteillard, Annie Risler, Marie-Anne Sallandre.2001.
Projet LS-COLIN.
Quel outil de notationpour quelle analyse de la LS ?
Colloque Re-cherches sur les langues des signes.
Toulouse UTMeds.
71-86.Hennie Brugman, Daan Broeder, and Gunter Senft.2003.
Documentation of Languages and Archivingof Language Data at the Max Planck Insitute forPsycholinguistics in Nijmegen.
Ringvorlesung Be-drohte Sprachen.
Bielefeld University, Germany.Jan Bungeroth, Daniel Stein, Philippe Dreuw, Her-mann Ney, Sara Morrissey, Andy Way and Lynettevan Zijl.
2008.
The ATIS Sign Language Corpus.6th International Conference on Language Re-sources and Evaluation.
Marrakech.
Morocco.
?milie Ch?telat-Pel?, Annelies Braffort.
2008.
SignLanguage Corpus Annotation: Toward a New Me-thodology.
6th International Conference on Lan-guage Resources and Evaluation.
Marrakech.
Mo-rocco.Christian Cuxac.
1996.
Fonctions et Structures del'iconicit?
dans les langues des signes; analysed'un idiolecte parisien de la Langues des SignesFran?aise.
Doctoral Thesis, Paris V University,France.Louise Del?ger and Pierre Zweigenbaum.
2008.
Pa-raphrase acquisition from comparable medicalcorpora of specialized and lay texts.
AMIA.
An-nual Fall Symposium.
Washington, DC.
146-150.Eleni Efthimiou, Stavroula-Evita Fotinea, ChristianVogler, Thomas Hanke, John Glauert, RichardBowden, Annelies Braffort, Christophe Collet, Pe-tros Maragos, and J?r?mie Segouat.
2009.
SignLanguage Recognition, Generation and Modelling:A Research Effort with Applications in Deaf Com-munication.
13th Internation Conference on Hu-man-Computer Interaction.
San Diego, CA.
USA.Pascale Fung, Percy Cheung.
2004.
Mining very-non-parallel corpora: Parallel sentence and lexicon ex-traction via bootstrapping and EM.
12th Confe-rence on Empirical Methods in Natural LanguageProcessing.
Barcelona.
Spain.
57-63.Brigitte Garcia, 2006.
The methodological, linguisticand semiological bases for the elaboration of awritten form of LSF (French Sign Language).
5thInternational Conference on Language Resourcesand Evaluation.
Genoa.
Italy.Jean-Claude Martin, Jean-Paul Sansonnet, AnneliesBraffort, and Cyril Verrecchia.
2009.
Informing theDesign of Deictic Behaviors of a Web Agent withSpoken and Sign Language Video Data.
8th Inter-national Gesture Workshop.
Bielefeld, Germany.Emmanuel Morin and B?atrice Daille.
2006.
Compa-rabilit?
de corpus et fouille terminologique multi-lingue.
Traitement Automatique des Langues.
Vol47.
113-136.Carol Neidle.
2000.
SignStream(TM): A DatabaseTool for Research on Visual-Gestural Language.American Sign Language Linguistic ResearchProject, Report No.
10.
Boston University.
USA.Marie-Anne Sallandre.
2006.
Iconicity and Space inFrench Sign Language.
Space in languages: lin-guistic systems and cognitive categories.
Collec-tion Typological Studies in Language 66.
JohnBenjamins.
239-255.J?r?mie Segouat, Annelies Braffort, and ?milie Mar-tin.
2006.
Sign Language corpus analysis: Syn-chronisation of linguistic annotation and numeri-cal data.
5th International Conference on LanguageResources and Evaluation - LREC, Genova, Italia.J?r?mie Segouat, Annelies Braffort, Laurence Bolot,Annick Choisier, Michael Filhol, and Cyril Verrec-chia.
2008.
Building 3D French Sign Languagelexicon.
6th International Conference on LanguageResources and Evaluation ?
LREC.
Marrakech,Morocco.J?r?mie Segouat.
2009.
A Study of Sign LanguageCoarticulation.
Accessibility and Computing.
SI-GACCESS Newsletter.
Issue 93.
31-38.William C Stokoe, Dorothy C Casterline, and Carl GCroneberg.
1965.
A Dictionary of American SignLanguage on Linguistic Principles.
WashingtonDC.
Gallaudet College Press.67
