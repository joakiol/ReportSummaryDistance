A Probabilistic Method for Analyzing Japanese AnaphoraIntegrating Zero Pronoun Detection and ResolutionKazuhiro Seki ?, Atsushi Fujii ?
?, ???
and Tetsuya Ishikawa ??
?National Institute of Advanced Industrial Science and Technology1-1-1, Chuuou Daini Umezono, Tsukuba 305-8568, Japan?
?University of Library and Information Science1-2, Kasuga, Tsukuba, 305-8550, Japan??
?CREST, Japan Science & Technology Corporationk.seki@aist.go.jp fujii@ulis.ac.jp ishikawa@ulis.ac.jpAbstractThis paper proposes a method to analyzeJapanese anaphora, in which zero pronouns(omitted obligatory cases) are used to refer topreceding entities (antecedents).
Unlike thecase of general coreference resolution, zero pro-nouns have to be detected prior to resolutionbecause they are not expressed in discourse.Our method integrates two probability param-eters to perform zero pronoun detection andresolution in a single framework.
The first pa-rameter quantifies the degree to which a givencase is a zero pronoun.
The second parame-ter quantifies the degree to which a given entityis the antecedent for a detected zero pronoun.To compute these parameters efficiently, we usecorpora with/without annotations of anaphoricrelations.
We show the effectiveness of ourmethod by way of experiments.1 IntroductionAnaphora resolution is crucial in natural lan-guage processing (NLP), specifically, discourseanalysis.
In the case of English, partially mo-tivated by Message Understanding Conferences(MUCs) (Grishman and Sundheim, 1996), anumber of coreference resolution methods havebeen proposed.In other languages such as Japanese andSpanish, anaphoric expressions are often omit-ted.
Ellipses related to obligatory cases are usu-ally termed zero pronouns.
Since zero pronounsare not expressed in discourse, they have to bedetected prior to identifying their antecedents.Thus, although in English pleonastic pronounshave to be determined whether or not they areanaphoric expressions prior to resolution, theprocess of analyzing Japanese zero pronouns isdifferent from general coreference resolution inEnglish.For identifying anaphoric relations, existingmethods are classified into two fundamental ap-proaches: rule-based and statistical approaches.In rule-based approaches (Grosz et al, 1995;Hobbs, 1978; Mitkov et al, 1998; Nakaiwaand Shirai, 1996; Okumura and Tamura, 1996;Palomar et al, 2001; Walker et al, 1994),anaphoric relations between anaphors and theirantecedents are identified by way of hand-crafted rules, which typically rely on syntacticstructures, gender/number agreement, and se-lectional restrictions.
However, it is difficult toproduce rules exhaustively, and rules that aredeveloped for a specific language are not neces-sarily effective for other languages.
For exam-ple, gender/number agreement in English can-not be applied to Japanese.Statistical approaches (Aone and Bennett,1995; Ge et al, 1998; Kim and Ehara,1995; Soon et al, 2001) use statistical mod-els produced based on corpora annotated withanaphoric relations.
However, only a fewattempts have been made in corpus-basedanaphora resolution for Japanese zero pro-nouns.
One of the reasons is that it is costlyto produce a sufficient volume of training cor-pora annotated with anaphoric relations.In addition, those above methods focusedmainly on identifying antecedents, and few at-tempts have been made to detect zero pronouns.Motivated by the above background, wepropose a probabilistic model for analyzingJapanese zero pronouns combined with a detec-tion method.
In brief, our model consists of twoparameters associated with zero pronoun detec-tion and antecedent identification.
We focus onzero pronouns whose antecedents exist in pre-ceding sentences to zero pronouns because theyare major referential expressions in Japanese.Section 2 explains our proposed method (sys-tem) for analyzing Japanese zero pronouns.Section 3 evaluates our method by way of ex-periments using newspaper articles.
Section 4discusses related research literature.2 A System for Analyzing JapaneseZero Pronouns2.1 OverviewFigure 1 depicts the overall design of our systemto analyze Japanese zero pronouns.
We explainthe entire process based on this figure.First, given an input Japanese text, our sys-tem performs morphological and syntactic anal-yses.
In the case of Japanese, morphologicalanalysis involves word segmentation and part-of-speech tagging because Japanese sentenceslack lexical segmentation, for which we usethe JUMAN morphological analyzer (Kurohashiand Nagao, 1998b).
Then, we use the KNPparser (Kurohashi, 1998) to identify syntacticrelations between segmented words.Second, in a zero pronoun detection phase,the system uses syntactic relations to detectomitted cases (nominative, accusative, and da-tive) as zero pronoun candidates.
To avoid zeropronouns overdetected, we use the IPAL verbdictionary (Information-technology PromotionAgency, 1987) including case frames associatedwith 911 Japanese verbs.
We discard zero pro-noun candidates unlisted in the case frames as-sociated with a verb in question.For verbs unlisted in the IPAL dictionary,only nominative cases are regarded as obliga-tory.
The system also computes a probabilitythat case c related to target verb v is a zeropronoun, Pzero(c|v), to select plausible zero pro-noun candidates.Ideally, in the case where a verb in ques-tion is polysemous, word sense disambiguationis needed to select the appropriate case frame,because different verb senses often correspondto different case frames.
However, we currentlymerge multiple case frames for a verb into a sin-gle frame so as to avoid the polysemous prob-lem.
This issue needs to be further explored.Third, in a zero pronoun resolution (i.e., an-tecedent identification) phase, for each zero pro-noun the system extracts antecedent candidatesfrom the preceding contexts, which are orderedaccording to the extent to which they can be theantecedent for the target zero pronoun.
Frominput textmorphological andsytactic analysesoutput textcase framedictionaryannotatedcorporaunannotatedcorporasemanticmodelsyntacticmodelzero pronoundetectionzero pronounresolutionFigure 1: The overall design of our system toanalyze Japanese zero pronouns.the viewpoint of probability theory, our taskhere is to compute a probability that zero pro-noun ?
refers to antecedent ai, P (ai|?
), and se-lect the candidate that maximizes the probabil-ity score.
For the purpose of computing thisscore, we model zero pronouns and antecedentsin Section 2.2.Finally, the system outputs texts containinganaphoric relations.
In addition, the numberof zero pronouns analyzed by the system canoptionally be controlled based on the certaintyscore described in Section 2.4.2.2 Modeling Zero Pronouns andAntecedentsAccording to past literature associated withzero pronoun resolution and our preliminarystudy, we use the following six features to modelzero pronouns and antecedents.?
Features for zero pronouns?
Verbs that govern zero pronouns (v), whichdenote verbs whose cases are omitted.?
Surface cases related to zero pronouns (c),for which possible values are Japanese casemarker suffixes, ga (nominative), wo (ac-cusative), and ni (dative).
Those valuesindicate which cases are omitted.?
Features for antecedents?
Post-positional particles (p), which playcrucial roles in resolving Japanese zero pro-nouns (Kameyama, 1986; Walker et al,1994).?
Distance (d), which denotes the distance(proximity) between a zero pronoun and anantecedent candidate in an input text.
Inthe case where they occur in the same sen-tence, its value takes 0.
In the case wherean antecedent occurs in n sentences previ-ous to the sentence including a zero pro-noun, its value takes n.?
Constraint related to relative clauses (r),which denotes whether an antecedent is in-cluded in a relative clause or not.
In thecase where it is included, the value of rtakes true, otherwise false.
The rationalebehind this feature is that Japanese zeropronouns tend not to refer to noun phrasesin relative clauses.?
Semantic classes (n), which represent se-mantic classes associated with antecedents.We use 544 semantic classes defined in theJapanese Bunruigoihyou thesaurus (Na-tional Language Research Institute, 1964),which contains 55,443 Japanese nouns.2.3 Our Probabilistic Model for ZeroPronoun Detection and ResolutionWe consider probabilities that unsatisfied casec related to verb v is a zero pronoun, Pzero(c|v),and that zero pronoun ?crefers to antecedentai, P (ai|?c).
Thus, a probability that case c (?c)is zero-pronominalized and refers to candidateaiis formalized as in Equation (1).P (ai|?c) ?
Pzero(c|v) (1)Here, Pzero(c|v) and P (ai|?c) are computed inthe detection and resolution phases, respec-tively (see Figure 1).Since zero pronouns are omitted obligatorycases, whether or not case c is a zero pronoundepends on the extent to which case c is oblig-atory for verb v. Case c is likely to be oblig-atory for verb v if c frequently co-occurs withv.
Thus, we compute Pzero(c|v) based on theco-occurrence frequency of ?v, c?
pairs, whichcan be extracted from unannotated corpora.Pzero(c|v) takes 1 in the case where c is ga (nom-inative) regardless of the target verb, because gais obligatory for most Japanese verbs.Given the formal representation for zero pro-nouns and antecedents in Section 2.2, the prob-ability, P (a|?
), is expressed as in Equation (2).P (ai|?)
= P (pi, di, ri, ni|v, c) (2)To improve the efficiency of probability estima-tion, we decompose the right-hand side of Equa-tion (2) as follows.Since a preliminary study showed that diandriwere relatively independent of the other fea-tures, we approximate Equation (2) as in Equa-tion (3).P (ai|?)
?
P (pi, ni|v, c) ?
P (di) ?
P (ri)= P (pi|ni, v, c) ?
P (ni|v, c)?
P (di) ?
P (ri)(3)Given that piis independent of v and ni, wecan further approximate Equation (3) to deriveEquation (4).P (ai|?c) ?
P (pi|c)?P (di)?P (ri)?P (ni|v, c) (4)Here, the first three factors, P (pi|c) ?
P (di) ?P (ri), are related to syntactic properties, andP (ni|v, c) is a semantic property associated withzero pronouns and antecedents.
We shall callthe former and latter ?syntactic?
and ?seman-tic?
models, respectively.Each parameter in Equation (4) is com-puted as in Equations (5), where F (x) denotesthe frequency of x in corpora annotated withanaphoric relations.P (pi|c) =F (pi, c)?jF (pj, c)P (di) =F (di)?jF (dj)P (ri) =F (ri)?jF (rj)P (ni|v, c) =F (ni, v, c)?jF (nj, v, c)(5)However, since estimating a semantic model,P (ni|v, c), needs large-scale annotated corpora,the data sparseness problem is crucial.
Thus,we explore the use of unannotated corpora.For P (ni|v, c), v and c are features for a zeropronoun, and niis a feature for an antecedent.However, we can regard v, c, and nias featuresfor a verb and its case noun because zero pro-nouns are omitted case nouns.
Thus, it is pos-sible to estimate the probability based on co-occurrences of verbs and their case nouns, whichcan be extracted automatically from large-scaleunannotated corpora.2.4 Computing Certainty ScoreSince zero pronoun analysis is not a stand-aloneapplication, our system is used as a module inother NLP applications, such as machine trans-lation.
In those applications, it is desirable thaterroneous anaphoric relations are not generated.Thus, we propose a notion of certainty to out-put only zero pronouns that are detected andresolved with a high certainty score.We formalize the certainty score, C(?c), foreach zero pronoun as in Equation (6), whereP1(?c) and P2(?c) denote probabilities com-puted by Equation (1) for the first and secondranked candidates, respectively.
In addition, t isa parametric constant, which is experimentallyset to 0.5.C(?c) = t?P1(?c) + (1?t)(P1(?c)?P2(?c)) (6)The certainty score becomes great in the casewhere P1(?c) is sufficiently great and signifi-cantly greater than P2(?c).3 Evaluation3.1 MethodologyTo investigate the performance of our system,we used Kyotodaigaku Text Corpus version2.0 (Kurohashi and Nagao, 1998a), in which20,000 articles in Mainichi Shimbun newspaperarticles in 1995 were analyzed by JUMAN andKNP (i.e., the morph/syntax analyzers used inour system) and revised manually.
From thiscorpus, we randomly selected 30 general articles(e.g., politics and sports) and manually anno-tated those articles with anaphoric relations forzero pronouns.
The number of zero pronounscontained in those articles was 449.We used a leave-one-out cross-validation eval-uation method: we conducted 30 trials in eachof which one article was used as a test inputand the remaining 29 articles were used for pro-ducing a syntactic model.
We used six yearsworth of Mainichi Shimbun newspaper arti-cles (Mainichi Shimbunsha, 1994?1999) to pro-duce a semantic model based on co-occurrencesof verbs and their case nouns.To extract verbs and their case noun pairsfrom newspaper articles, we performed a mor-phological analysis by JUMAN and extracteddependency relations using a relatively simplerule: we assumed that each noun modifies theverb of highest proximity.
As a result, weobtained 12 million co-occurrences associatedwith 6,194 verb types.
Then, we generalizedthe extracted nouns into semantic classes inthe Japanese Bunruigoihyou thesaurus.
In thecase where a noun was associated with multipleclasses, the noun was assigned to all possibleclasses.
In the case where a noun was not listedin the thesaurus, the noun itself was regardedas a single semantic class.3.2 Comparative ExperimentsFundamentally, our evaluation is two-fold: weevaluated only zero pronoun resolution (an-tecedent identification) and a combination ofdetection and resolution.
In the former case,we assumed that all the zero pronouns are cor-rectly detected, and investigated the effective-ness of the resolution model, P (ai|?).
In thelatter case, we investigated the effectiveness ofthe combined model, P (ai|?c) ?
Pzero(c|v).First, we compared the performance of thefollowing different models for zero pronoun res-olution, P (ai|?):?
a semantic model produced based on anno-tated corpora (Sem1),?
a semantic model produced based on unan-notated corpora, using co-occurrences ofverbs and their case nouns (Sem2),?
a syntactic model (Syn),?
a combination of Syn and Sem1 (Both1),?
a combination of Syn and Sem2 (Both2),which is our complete model for zero pro-noun resolution,?
a rule-based model (Rule).As a control (baseline) model, we took approxi-mately two man-months to develop a rule-basedmodel (Rule) through an analysis on ten articlesin Kyotodaigaku Text Corpus.
This model usesrules typically used in existing rule-based meth-ods: 1) post-positional particles that follow an-tecedent candidates, 2) proximity between zeropronouns and antecedent candidates, and 3)conjunctive particles.
We did not use seman-tic properties in the rule-based method becausethey decreased the system accuracy in a prelim-inary study.Table 1: Experimental results for zero pronoun resolution.# of Correct cases (Accuracy)k Sem1 Sem2 Syn Both1 Both2 Rule1 25 (6.2%) 119 (29.5%) 185 (45.8%) 30 (7.4%) 205 (50.7%) 162 (40.1%)2 46 (11.4%) 193 (47.8%) 227 (56.2%) 49 (12.1%) 250 (61.9%) 213 (52.7%)3 72 (17.8%) 230 (56.9%) 262 (64.9%) 75 (18.6%) 280 (69.3%) 237 (58.6%)Table 1 shows the results, where we regardedthe k-best antecedent candidates as the finaloutput and compared results for different valuesof k. In the case where the correct answer wasincluded in the k-best candidates, we judged itcorrect.
In addition, ?Accuracy?
is the ratio be-tween the number of zero pronouns whose an-tecedents were correctly identified and the num-ber of zero pronouns correctly detected by thesystem (404 for all the models).
Bold figuresdenote the highest performance for each valueof k across different models.
Here, the averagenumber of antecedent candidates per zero pro-noun was 27 regardless of the model, and thusthe accuracy was 3.7% in the case where thesystem randomly selected antecedents.Looking at the results for two different seman-tic models, Sem2 outperformed Sem1, whichindicates that the use of co-occurrences of verbsand their case nouns was effective to identifyantecedents and avoid the data sparseness prob-lem in producing a semantic model.The syntactic model, Syn, outperformed thetwo semantic models independently, and there-fore the syntactic features used in our modelwere more effective than the semantic featuresto identify antecedents.
When both syntacticand semantic models were used in Both2, theaccuracy was further improved.
While the rule-based method, Rule, achieved a relatively highaccuracy, our complete model, Both2, outper-formed Rule irrespective of the value of k. Tosum up, we conclude that both syntactic andsemantic models were effective to identify ap-propriate anaphoric relations.At the same time, since our method requiresannotated corpora, the relation between thecorpus size and accuracy is crucial.
Thus, weperformed two additional experiments associ-ated with Both2.In the first experiment, we varied the numberof annotated articles used to produce a syntacticmodel, where a semantic model was produced253035404550550 5 10 15 20 250 1 2 3 4 5 6accuracy(%)annotated corpus size for producing a syntactic model (#articles)unannotated corpus size for producing a semantic model (year)unannotatedannotatedFigure 2: The relation between the corpus sizeand accuracy for a combination of syntactic andsemantic models (Both2).based on six years worth of newspaper articles.In the second experiment, we varied the num-ber of unannotated articles used to produce asemantic model, where a syntactic model wasproduced based on 29 annotated articles.
InFigure 2, we show two independent results asspace is limited: the dashed and solid graphscorrespond to the results of the first and secondexperiments, respectively.
Given all the articlesfor modeling, the resultant accuracy for each ex-periment was 50.7%, which corresponds to thatfor Both2 with k = 1 in Table 1.In the case where the number of articles wasvaried in producing a syntactic model, the ac-curacy improved rapidly in the first five arti-cles.
This indicates that a high accuracy canbe obtained by a relatively small number of su-pervised articles.
In the case where the amountof unannotated corpora was varied in produc-ing a semantic model, the accuracy marginallyimproved as the corpus size increases.
However,note that we do not need human supervision toproduce a semantic model.Finally, we evaluated the effectiveness of the2530354045505560657010 20 30 40 50 60 70 80 90accuracy(%)coverage (%)P(ai|?c)?Pzero(c|v)P(ai|?c)Figure 3: The relation between coverage andaccuracy for zero pronoun detection (Both2).505560657075800 10 20 30 40 50 60 70 80 90 100accuracy(%)coverage (%)P(ai|?c)?Pzero(c|v)P(ai|?c)Figure 4: The relation between coverage andaccuracy for antecedent identification (Both2).combination of zero pronoun detection and res-olution in Equation (1).
To investigate the con-tribution of the detection model, Pzero(c|v), weused P (ai|?c) for comparison.
Both cases usedBoth2 to compute the probability for zero pro-noun resolution.
We varied a threshold for thecertainty score to plot coverage-accuracy graphsfor zero pronoun detection (Figure 3) and an-tecedent identification (Figure 4).In Figure 3, ?coverage?
is the ratio betweenthe number of zero pronouns correctly detectedby the system and the total number of zero pro-nouns in input texts, and ?accuracy?
is the ratiobetween the number of zero pronouns correctlydetected and the total number of zero pronounsdetected by the system.
Note that since our sys-tem failed to detect a number of zero pronouns,the coverage could not be 100%.Figure 3 shows that as the coverage decreases,the accuracy improved irrespective of the modelused.
When compared with the case of P (ai|?
),our model, P (ai|?
)?Pzero(c|v), achieved a higheraccuracy regardless of the coverage.In Figure 4, ?coverage?
is the ratio betweenthe number of zero pronouns whose antecedentswere generated and the number of zero pro-nouns correctly detected by the system.
Theaccuracy was improved by decreasing the cov-erage, and our model marginally improved theaccuracy for P (ai|?
).According to those above results, our modelwas effective to improve the accuracy for zeropronoun detection and did not have side effecton the antecedent identification process.
As aresult, the overall accuracy of zero pronoun de-tection and resolution was improved.4 Related WorkKim and Ehara (1995) proposed a probabilis-tic model to resolve subjective zero pronounsfor the purpose of Japanese/English machinetranslation.
In their model, the search scopefor possible antecedents was limited to the sen-tence containing zero pronouns.
In contrast,our method can resolve zero pronouns in bothintra/inter-sentential anaphora types.Aone and Bennett (1995) used a decision treeto determine appropriate antecedents for zeropronouns.
They focused on proper and definitenouns used in anaphoric expressions as well aszero pronouns.
However, their method resolvesonly anaphors that refer to organization names(e.g., private companies), which are generallyeasier to resolve than our case.Both above existing methods require anno-tated corpora for statistical modeling, while weused corpora with/without annotations relatedto anaphoric relations, and thus we can eas-ily obtain large-scale corpora to avoid the datasparseness problem.Nakaiwa (2000) used Japanese/English bilin-gual corpora to identify anaphoric relations ofJapanese zero pronouns by comparing J/E sen-tence pairs.
The rationale behind this methodis that obligatory cases zero-pronominalizedin Japanese are usually expressed in English.However, in the case where corresponding En-glish expressions are pronouns and anaphors,their method is not effective.
Additionally,bilingual corpora are more expensive to obtainthan monolingual corpora used in our method.Finally, our method integrates a parameterfor zero pronoun detection in computing the cer-tainty score.
Thus, we can improve the accuracyof our system by discarding extraneous outputswith a small certainty score.5 ConclusionWe proposed a probabilistic model to ana-lyze Japanese zero pronouns that refer to an-tecedents in the previous context.
Our modelconsists of two probabilistic parameters corre-sponding to detecting zero pronouns and iden-tifying their antecedents, respectively.
The lat-ter is decomposed into syntactic and semanticproperties.
To estimate those parameters ef-ficiently, we used annotated/unannotated cor-pora.
In addition, we formalized the certaintyscore to improve the accuracy.
Through exper-iments, we showed that the use of unannotatedcorpora was effective to avoid the data sparse-ness problem and that the certainty score fur-ther improved the accuracy.Future work would include word sense disam-biguation for polysemous predicate verbs to se-lect appropriate case frames in the zero pronoundetection process.ReferencesChinatsu Aone and Scott William Bennett.
1995.Evaluating automated and manual acquisition ofanaphora resolution strategies.
In Proceedings of33th Annual Meeting of the Association for Com-putational Linguistics, pages 122?129.Niyu Ge, John Hale, and Eugene Charniak.
1998.A statistical approach to anaphora resolution.
InProceedings of the Sixth Workshop on Very LargeCorpora, pages 161?170.Ralph Grishman and Beth Sundheim.
1996.
Mes-sage Understanding Conference - 6: A brief his-tory.
In Proceedings of the 16th InternationalConference on Computational Linguistics, pages466?471.Barbara J. Grosz, Aravind K. Joshi, and Scott We-instein.
1995.
Centering: A framework for mod-eling the local coherence of discourse.
Computa-tional Linguistics, 21(2):203?226.Jerry R. Hobbs.
1978.
Resolving pronoun refer-ences.
Lingua, 44:311?338.Information-technology Promotion Agency, 1987.IPA Lexicon of the Japanese language for com-puters (Basic Verbs).
(in Japanese).Megumi Kameyama.
1986.
A property-sharing con-straint in centering.
In Proceedings of the 24thAnnual Meeting of the Association for Computa-tional Linguistics, pages 200?206.Yeun-Bae Kim and Terumasa Ehara.
1995.
Zero-subject resolution method based on probabilisticinference with evaluation function.
In Proceedingsof the 3rd Natural Language Processing Pacific-Rim Symposium, pages 721?727.Sadao Kurohashi and Makoto Nagao.
1998a.
Build-ing a Japanese parsed corpus while improving theparsing system.
In Proceedings of The 1st In-ternational Conference on Language Resources &Evaluation, pages 719?724.Sadao Kurohashi and Makoto Nagao, 1998b.Japanese morphological analysis system JUMANversion 3.6 manual.
Department of Informatics,Kyoto University.
(in Japanese).Sadao Kurohashi, 1998.
Japanese Dependency/CaseStructure Analyzer KNP version 2.0b6.
De-partment of Informatics, Kyoto University.
(inJapanese).Mainichi Shimbunsha.
1994?1999.
Mainichi Shim-bun CD-ROM.Ruslan Mitkov, Lamia Belguith, and MalgorzataStys.
1998.
Multilingual robust anaphora reso-lution.
In Proceedings of the 3rd Conference onEmpirical Methods in Natural Language Process-ing, pages 7?16.Hiromi Nakaiwa and Satoshi Shirai.
1996.Anaphora resolution of Japanese zero pronounswith deictic reference.
In Proceedings of the16th International Conference on ComputationalLinguistics, pages 812?817.Hiromi Nakaiwa.
2000.
An environment for extract-ing resolution rules of zero pronouns from corpora.In COLING-2000 Workshop on Semantic Anno-tation and Intelligent Content, pages 44?52.National Language Research Institute.
1964.
Bun-ruigoihyou.
Shuei publisher.
(in Japanese).Manabu Okumura and Kouji Tamura.
1996.
Zeropronoun resolution in Japanese discourse basedon centering theory.
In Proceedings of the 16thInternational Conference on Computational Lin-guistics, pages 871?876.Manuel Palomar, Antonio Ferra?ndez, Lidia Moreno,Patricio Mart?
?nez-Barco, Jesu?s Peral, Maximil-iano Saiz-Noeda, and Rafael Mu noz.
2001.
An al-gorithm for anaphora resolution in Spanish texts.Computational Linguistics, 27(4):545?568.Wee Meng Soon, Hwee Tou Ng, and DanielChung Yong Lim.
2001.
A machine learning ap-proach to coreference resolution of noun phrases.Computational Linguistics, 27(4):521?544.Marilyn Walker, Masayo Iida, and Sharon Cote.1994.
Japanese discourse and the process of cen-tering.
Computational Linguistics, 20(2):193?233.
