2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 592?596,Montre?al, Canada, June 3-8, 2012. c?2012 Association for Computational LinguisticsStance Classification using Dialogic Properties of PersuasionMarilyn A. Walker, Pranav Anand, Robert Abbott and Ricky GrantBaskin School of Engineering & Linguistics DepartmentUniversity of California Santa CruzSanta Cruz, Ca.
95064, USAmaw,panand,abbott,rgrant@soe.ucsc.eduAbstractPublic debate functions as a forum for bothexpressing and forming opinions, an impor-tant aspect of public life.
We present resultsfor automatically classifying posts in onlinedebate as to the position, or STANCE that thespeaker takes on an issue, such as Pro or Con.We show that representing the dialogic struc-ture of the debates in terms of agreement rela-tions between speakers, greatly improves per-formance for stance classification, over mod-els that operate on post content and parent-post context alone.1 IntroductionPublic debate functions as a forum for both express-ing and forming opinions.
Three factors affect opin-ion formation, e.g.
the perlocutionary uptake of de-bate arguments (Cialdini, 2000; Petty and Cacioppo,1988; Petty et al, 1981).
First, there is the ARGU-MENT itself, i.e.
the propositions discussed alongwith the logical relations between them.
Second isthe SOURCE of the argument (Chaiken, 1980), e.g.the speaker?s expertise, or agreement relations be-tween speakers.
The third factor consists of proper-ties of the AUDIENCE such as prior beliefs, socialidentity, personality, and cognitive style (Davies,1998).
Perlocutionary uptake in debates primar-ily occurs in the audience, who may be undecided,while debaters typically express a particular positionor STANCE on an issue, e.g.
Pro or Con, as in theonline debate dialogues in Figs.
1, 2, and 3.Previous computational work on debate coversthree different debate settings: (1) congressional de-Post Stance UtteranceP1 PRO I feel badly for your ignorance because althoughthere maybe a sliver of doubt that mankind mayhave evolved from previous animals, there is nodoubt that the Earth and the cosmos have gonethrough evolution and are continuing to do soP2 CON As long as there are people who doubt evolu-tion, both lay and acedamia, then evolution is indoubt.
And please don?t feel bad for me.
I amperfectly secure in my ?ignorance?.P3 PRO By that measure, as long as organic chemistry,physics and gravity are in doubt by both lay andacedamia, then organic chemistry, physics andgravity are in doubt.
Gravity is a theory.
Whyaren?t you giving it the same treatment you doto evolution?
Or is it because you are ignorant?Angelic Falling anyone?P4 CON I?m obviously ignorant.
Look how many timesi?ve been given the title.
?Gravity is a theory.Why aren?t you giving it the same treatment youdo to evolution??
Because it doesn?t carry thesame weight.
;PFigure 1: All posts linked via rebuttal links.
The topicwas ?Evolution?, with sides ?Yes, I Believe?
vs. ?No, IDont Believe?.bates (Thomas et al, 2006; Bansal et al, 2008;Yessenalina et al, 2010; Balahur et al, 2009; Bur-foot et al, 2011); (2) company-internal discussionsites (Murakami and Raymond, 2010; Agrawal etal., 2003); and (3) online social and political publicforums (Somasundaran and Wiebe, 2009; Somasun-daran and Wiebe, 2010; Wang and Rose?, 2010; Bi-ran and Rambow, 2011).
Debates in online publicforums (e.g.
Fig.
1) differ from debates in congressand on company discussion sites in two ways.First, the language is different.
Online debatersare highly involved, often using emotional and col-orful language to make their points.
These debatesare also personal, giving a strong sense of the indi-592vidual making the argument, and whether s/he fa-vors emotive or factual modes of expression, e.g.Let me answer.... NO!
(P2 in Fig.
3).
Other com-mon features are sarcasm, e.g.
I?m obviously igno-rant.
Look how many times i?ve been given the ti-tle (P4 in Fig.
1), questioning another?s evidence orassumptions: Yes there is always room for humanerror, but is one accident that hasn?t happened yetenough cause to get rid of a capital punishment?
(P2in Fig.
3), and insults: Or is it because you are ig-norant?
(P3 in Fig.
1).
These properties may func-tion to engage the audience and persuade them toform a particular opinion, but they make computa-tional analysis of such debates challenging, with thebest performance to date averaging 64% over severaltopics (Somasundaran and Wiebe, 2010).Post Stance UtteranceP1 Superman Batman is no match for superman.
Notonly does he have SUPERnatural powers asopposed to batman?s wit and gadgetry, buthis powers have increased in number overthe years.
For example, when Superman?sprowess was first documented in the comicshe did not have x-ray vision.
It wasn?t untilhis story was told on radio that he could seethrough stuff.
So no matter what new weaponbatman could obtain, Superman would add an-other SUPERnatural weapon to foil the Capedcrusader.P2 Batman Superman GAVE Batman a krytonite ring sothat Batman could take him down should heneed to.
Superman did this because he knowsBatman is the only guy that could do it.P3 Superman But, not being privy to private conversationswith S-man, you wouldn?t know that, being thehumble chap that he is, S-man allowed batmanthe victory because he likes the bat and wantedhim to mantain some credibility.
Honest.P4 Batman Hmmm, this is confusing.
Since we all knowthat Supes doesn?t lie and yet at the time ofhim being beaten by Batman he was under thecontrol of Poison Ivy and therefore could NOThave LET Batman win on purpose.
I have tosay that I am beginning to doubt you really arefriends with Supes at all.Figure 2: All posts linked via rebuttal links.
The topicwas ?Superman vs. Batman?Second, the affordances of different online debatesites provide differential support for dialogic rela-tions between forum participants.
For example, theresearch of Somasundaran and Wiebe (2010), doesnot explicitly model dialogue or author relations.However debates in our corpus vary greatly by topicon two dialogic factors: (1) the percent of posts thatare rebuttals to prior posts, and (2) the number ofPost Stance UtteranceP1 CON 69 people have been released from death rowsince 1973 these people could have been killedif there cases and evidence did not come up rongalso these people can have lost 20 years or moreto a false coviction.
it is only a matter of time tillsome one is killed yes u could say there doinga good job now but it has been shown so manytimes with humans that they will make the hu-man error and cost an innocent person there life.P2 PRO Yes there is always room for human error, butis one accident that hasn?t happened yet enoughcause to get rid of a capital punishment?
Let meanswer...NO!
If you ban the death penalty crimewill skyrocket.
It is an effective deterannce forcrime.
The states that have strict death penaltylaws have less crime than states that don?t (Texasvs.
Michigan) Texas?s crime rate is lower thanMichigan and Texas has a higher population!!!
!Figure 3: Posts linked via rebuttal links.
The topic was?Capital Punishment?, and the argument was framed as?Yes we should keep it?
vs. ?No we should not?.posts per author.
The first 5 columns of Table 2shows the variation in these dimensions by topic.In this paper we show that information about di-alogic relations between authors (SOURCE factors)improves performance for STANCE classification,when compared to models that only have access toproperties of the ARGUMENT.
We model SOURCErelations with a graph, and add this information toclassifiers operating on the text of a post.
Sec.
2describes the corpus and our approach.
Our cor-pus is publicly available, see (Walker et al, 2012).We show in Sec.
3 that modeling source propertiesimproves performance when the debates are highlydialogic.
We leave a more detailed comparison toprevious work to Sec.
3 so that we can contrast pre-vious work with our approach.2 Experimental Method and ApproachOur corpus consists of two-sided debates from Con-vinceme.net for 14 topics that range from play-ful debates such as Superman vs. Batman (Fig.
2to more heated political topics such as the DeathPenalty (Fig.
3.
In total the corpus consists of 2902two-sided debates (36,307 posts), totaling 3,080,874words; the topic labelled debates which we use inour experiments contain 575,818 words.
On Con-vinceme, a person starts a debate by posting a topicor a question and providing sides such as for vs.against.
Debate participants can then post argu-ments for one side or the other, essentially self-593labelling their post for stance.
Convinceme pro-vides three possible sources of dialogic structure,SIDE, REBUTTAL LINKS and TEMPORAL CONTEXT.Timestamps for posts are only available by day andthere are no agreement links.
Here, we use the self-labelled SIDE as the stance to be predicted.Set/Factor DescriptionBasic Number of Characters in post, Average WordLength, Unigrams, BigramsSentiment LIWC counts and frequencies, Opinion De-pendencies, LIWC Dependencies, negationArgument Cue Words, Repeated Punctuation, Context,POS-Generalized Dependencies, QuotesTable 1: Feature SetsWe construct features from the posts, along with arepresentation of the parent post as context, and usethose features in several base classifiers.
As shownin Table 1, we distinguish between basic features,such as length of the post and the words and bi-grams in the post, and features capturing sentimentand subjectivity, including using the LIWC tool foremotion labelling (Pennebaker et al, 2001) and de-riving generalized dependency features using LIWCcategories, as well as some limited aspects of theargument structure, such as cue words signallingrhetorical relations between posts, POS generalizeddependencies, and a representation of the parent post(context).
Only rebuttal posts have a parent post, andthus values for the context features.50-10Figure 4: Sample maxcut to ConvinceMe siding.
Sym-bols (circle, cross, square, triangles) indicate authors andfill colors (white,black) indicate true side.
Rebuttal linksare marked by black edges, same-author links by red;weights are 50 and -10, respectively.
Edges in the max-cut are highlighted in yellow, and the nodes in each cutset are bounded by the green dotted line.We then construct a graph (V,E) representing thedialogue structure, using the rebuttal links and au-thor identifiers from the forums site.
Each node Vof the graph is a post, and edges E indicate dialogicrelations of agreement and disagreement betweenposts.
We assume only that authors always agreewith themselves, and that rebuttal links indicate dis-agreement.
Agreement links based on the inferencethat if A, B disagree with C they agree with eachother were not added to the graph.Maxcut attempts to partition a graph into twosides.
Fig.
4 illustrates a sample result of applyingMaxCut.
Edges connecting the partitions are saidto be cut, while those within partitions are not.
Thegoal is to maximize the sum of cut edge weights.
Bymaking edge weights high we reward the algorithmfor cutting the edge, by making edge weights nega-tive we penalize the algorithm for cutting the edge.Rebuttal links were assigned a weight +100/(num-ber of rebuttals).
Same author links were assigned aweight -60/(number of posts by author).
If author Arebutted author B at some point, then a weight of 50was assigned to all edges connecting posts by authorA and posts by author B.
If author B rebutted authorA as well, that 50 was increased to 100.
We appliedthe MaxCut partitioning algorithm to this graph, andthen we orient each of the components automati-cally using a traditional supervised classifier.
Weconsider each component separately where compo-nents are defined using the original (pre-MaxCut)graph.
For each pair of partition side p ?
{P0, P1}and classifier label l ?
{L0, L1}, we compute ascore Sp,l by summing the margins of all nodes as-signed to that partition and label.
We then computeand compare the score differences for each partition.Dp = Sp,L1 ?
Sp,L0 If DP0 < DP1 , then nodes inpartition P0 should be assigned label L0 and nodesin P1 should be assigned label L1.
Likewise, ifDP0 > DP1 , then nodes in partition P0 should be as-signed label L1 and nodes in P1 should be assignedlabel L0.
If DP0 = DP1 , then we orient the compo-nent with a coin flip.3 Results and DiscussionTable 2 summarizes our results for the base classi-fier (JRIP) compared to using MaxCut over the so-cial network defined by author and rebuttal links.We report results for experiments using all the fea-594Topic Characteristics MaxCut Algorithm JRIP AlgorithmTopic Posts Rebs P/A A> 1p MLE Acc F1 P R Acc F1 P RAbortion 607 64% 2.73 42% 53% 82% 0.82 0.78 0.88 55% 0.55 0.52 0.59Cats v. Dogs 162 40% 1.60 24% 53% 80% 0.78 0.80 0.76 61% 0.55 0.59 0.51Climate Change 207 65% 2.92 41% 50% 64% 0.66 0.63 0.69 61% 0.62 0.60 0.63Comm.
v. Capitalism 214 62% 2.97 46% 55% 70% 0.67 0.66 0.68 53% 0.49 0.48 0.49Death Penalty 331 60% 2.40 45% 56% 35% 0.31 0.29 0.34 55% 0.46 0.48 0.44Evolution 818 66% 3.74 53% 58% 82% 0.78 0.78 0.79 56% 0.49 0.48 0.50Existence Of God 852 76% 4.16 51% 56% 75% 0.73 0.70 0.76 52% 0.49 0.47 0.51Firefox v. IE 233 38% 1.27 15% 79% 76% 0.47 0.44 0.49 72% 0.33 0.34 0.33Gay Marriage 560 56% 2.01 28% 65% 84% 0.77 0.74 0.81 60% 0.43 0.43 0.44Gun Control 135 59% 2.08 45% 63% 37% 0.24 0.21 0.27 53% 0.24 0.30 0.20Healthcare 112 79% 3.11 53% 55% 73% 0.71 0.69 0.72 60% 0.49 0.56 0.44Immigration 78 58% 1.95 33% 54% 33% 0.21 0.23 0.19 53% 0.39 0.48 0.33Iphone v. Blackberry 25 44% 1.14 14% 67% 88% 0.80 0.86 0.75 71% 0.46 0.60 0.38Israel v. Palestine 64 33% 3.37 53% 58% 85% 0.82 0.79 0.85 49% 0.48 0.42 0.56Mac v. PC 126 37% 1.85 24% 52% 19% 0.18 0.17 0.18 46% 0.46 0.45 0.48Marijuana legalization 229 45% 1.52 25% 71% 73% 0.56 0.52 0.60 63% 0.34 0.35 0.34Star Wars vs. LOTR 102 44% 1.38 26% 53% 63% 0.62 0.60 0.65 63% 0.62 0.60 0.65Superman v. Batman 146 30% 1.39 20% 54% 50% 0.40 0.44 0.37 56% 0.47 0.52 0.43Table 2: Results.
KEY: Number of posts on the topic (Posts).
Percent of Posts linked by Rebuttal links (Rebs).
Postsper author (P/A).
Authors with more than one post (A > 1P).
Majority Class Baseline (MLE).tures with ?2 feature selection; we use JRIP as thebase classifier because margins are used by the auto-matic MaxCut graph orientation algorithm.
Exper-iments with different learners (NB, SVM) did notyield significant differences from JRIP.
The resultsshow that, in general, representing dialogic infor-mation in terms of a network of relations betweenposts yields very large improvements.
In the fewtopics where performance is worse (Death Penalty,Gun Control, Mac vs. PC, Superman vs. Batman),the MaxCut graph gets oriented to the stance sidesthe wrong way, so that the cut actually groups theposts correctly into sides, but then assigns them tothe wrong side.
For Maxcut, as expected, there aresignificant correlations between the % of Rebuttalsin a debate and Precision (R = .16 ) and Recall (R=.22), as well as between Posts/Author and Precision(R = .25) and Recall (R = .43).
This clearly indi-cates that the degree of dialogic behavior (the graphtopology) has a strong influence on results per topic.These results would be even stronger if all MaxCutgraphs were oriented correctly.
(Somasundaran and Wiebe, 2010) present an un-supervised approach using ICA to stance classifica-tion, showing that identifying argumentation struc-ture improves performance, with a best performanceaveraging 64% accuracy over all topics, but as highas 70% for some topics.
Other research classifiesthe speaker?s side in a corpus of congressional floordebates (Thomas et al, 2006; Bansal et al, 2008;Balahur et al, 2009; Burfoot et al, 2011).
Thomaset al(2006) achieved accuracies of 71.3% by usingspeaker agreement information in the graph-basedMinCut/Maxflow algorithm, as compared to accura-cies around 70% via an an SVM classifier operatingon content alone.
The best performance to date onthis corpus achieves accuracies around 82% for dif-ferent graph-based approaches as compared to 76%accuracy for content only classification (Burfoot etal., 2011).
Other work applies MaxCut to the replystructure of company discussion forums, showingthat rules for identifying agreement (Murakami andRaymond, 2010), defined on the textual content ofthe post yield performance improvements over usingreply structures alone (Malouf and Mullen, 2008;Agrawal et al, 2003)Our results are not strictly comparable since weuse a different corpus with different properties, butto our knowledge this is the first application of Max-Cut to stance classification that shows large perfor-mance improvements from modeling dialogic rela-tions.
In future work, we plan to explore whetherdeeper linguistic features can yield large improve-ments in both the base classifier and in MaxCut re-sults, and to explore better ways of automaticallyorienting the MaxCut graph to stance side.
We alsohope to develop much better context features and tomake even more use of dialogue structure.595ReferencesR.
Agrawal, S. Rajagopalan, R. Srikant, and Y. Xu.
2003.Mining newsgroups using networks arising from so-cial behavior.
In Proceedings of the 12th internationalconference on World Wide Web, pages 529?535.
ACM.A.
Balahur, Z. Kozareva, and A. Montoyo.
2009.
Deter-mining the polarity and source of opinions expressedin political debates.
Computational Linguistics andIntelligent Text Processing, pages 468?480.M.
Bansal, C. Cardie, and L. Lee.
2008.
The powerof negative thinking: Exploiting label disagreement inthe min-cut classification framework.
Proceedings ofCOLING: Companion volume: Posters, pages 13?16.O.
Biran and O. Rambow.
2011.
Identifying justifica-tions in written dialogs.
In 2011 Fifth IEEE Inter-national Conference on Semantic Computing (ICSC),pages 162?168.
IEEE.C.
Burfoot, S. Bird, and T. Baldwin.
2011.
Collectiveclassification of congressional floor-debate transcripts.In Proceedings of the 49th Annual Meeting of the As-sociation for Computational Linguistics: Human Lan-guage Technologies-Volume 1, pages 1506?1515.
As-sociation for Computational Linguistics.S.
Chaiken.
1980.
Heuristic versus systematic informa-tion processing and the use of source versus messagecues in persuasion.
Journal of personality and socialpsychology, 39(5):752.Robert B. Cialdini.
2000.
Influence: Science and Prac-tice (4th Edition).
Allyn & Bacon.M.F.
Davies.
1998.
Dogmatism and belief formation:Output interference in the processing of supportingand contradictory cognitions.
Journal of personalityand social psychology, 75(2):456.R.
Malouf and T. Mullen.
2008.
Taking sides: User clas-sification for informal online political discourse.
In-ternet Research, 18(2):177?190.A.
Murakami and R. Raymond.
2010.
Support orOppose?
Classifying Positions in Online Debatesfrom Reply Activities and Opinion Expressions.
InProceedings of the 23rd International Conference onComputational Linguistics: Posters, pages 869?875.Association for Computational Linguistics.J.
W. Pennebaker, L. E. Francis, and R. J. Booth, 2001.LIWC: Linguistic Inquiry and Word Count.Richard E. Petty and John T. Cacioppo.
1988.
The ef-fects of involvement on responses to argument quan-tity and quality: Central and peripheral routes to per-suasion.
Journal of Personality and Social Psychol-ogy, 46(1):69?81.R.E.
Petty, J.T.
Cacioppo, and R. Goldman.
1981.
Per-sonal involvement as a determinant of argument-basedpersuasion.
Journal of Personality and Social Psy-chology, 41(5):847.S.
Somasundaran and J. Wiebe.
2009.
Recognizingstances in online debates.
In Proceedings of the JointConference of the 47th Annual Meeting of the ACLand the 4th International Joint Conference on NaturalLanguage Processing of the AFNLP: Volume 1-Volume1, pages 226?234.
Association for Computational Lin-guistics.S.
Somasundaran and J. Wiebe.
2010.
Recognizingstances in ideological on-line debates.
In Proceedingsof the NAACL HLT 2010 Workshop on ComputationalApproaches to Analysis and Generation of Emotion inText, pages 116?124.
Association for ComputationalLinguistics.M.
Thomas, B. Pang, and L. Lee.
2006.
Get out thevote: Determining support or opposition from Con-gressional floor-debate transcripts.
In Proceedings ofthe 2006 conference on empirical methods in naturallanguage processing, pages 327?335.
Association forComputational Linguistics.M.
Walker, P. Anand, J.
Fox Tree, R. Abbott, and J. King.2012.
A corpus for research on deliberation anddebate.
In Proceedings of the Eighth InternationalConference on Language Resources and Evaluation,LREC 2012, Istanbul, Turkey, May 23-25, 2012.Y.C.
Wang and C.P.
Rose?.
2010.
Making conversationalstructure explicit: identification of initiation-responsepairs within online discussions.
In Human LanguageTechnologies: The 2010 Annual Conference of theNorth American Chapter of the Association for Com-putational Linguistics, pages 673?676.
Association forComputational Linguistics.A.
Yessenalina, Y. Yue, and C. Cardie.
2010.
Multi-level structured models for document-level sentimentclassification.
In Proceedings of the 2010 Conferenceon Empirical Methods in Natural Language Process-ing, pages 1046?1056.
Association for ComputationalLinguistics.596
