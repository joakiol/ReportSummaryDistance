Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1396?1411,Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational LinguisticsSupervised Noun Phrase Coreference Research: The First Fifteen YearsVincent NgHuman Language Technology Research InstituteUniversity of Texas at DallasRichardson, TX 75083-0688vince@hlt.utdallas.eduAbstractThe research focus of computationalcoreference resolution has exhibited ashift from heuristic approaches to machinelearning approaches in the past decade.This paper surveys the major milestones insupervised coreference research since itsinception fifteen years ago.1 IntroductionNoun phrase (NP) coreference resolution, the taskof determining which NPs in a text or dialogue re-fer to the same real-world entity, has been at thecore of natural language processing (NLP) sincethe 1960s.
NP coreference is related to the taskof anaphora resolution, whose goal is to identifyan antecedent for an anaphoric NP (i.e., an NPthat depends on another NP, specifically its an-tecedent, for its interpretation) [see van Deemterand Kibble (2000) for a detailed discussion of thedifference between the two tasks].
Despite its sim-ple task definition, coreference is generally con-sidered a difficult NLP task, typically involvingthe use of sophisticated knowledge sources andinference procedures (Charniak, 1972).
Compu-tational theories of discourse, in particular focus-ing (see Grosz (1977) and Sidner (1979)) and cen-tering (Grosz et al (1983; 1995)), have heavilyinfluenced coreference research in the 1970s and1980s, leading to the development of numerouscentering algorithms (see Walker et al (1998)).The focus of coreference research underwent agradual shift from heuristic approaches to machinelearning approaches in the 1990s.
This shift canbe attributed in part to the advent of the statisti-cal NLP era, and in part to the public availabilityof annotated coreference corpora produced as partof the MUC-6 (1995) and MUC-7 (1998) confer-ences.
Learning-based coreference research hasremained vibrant since then, with results regularlypublished not only in general NLP conferences,but also in specialized conferences (e.g., the bien-nial Discourse Anaphora and Anaphor ResolutionColloquium (DAARC)) and workshops (e.g., theseries of Bergen Workshop on Anaphora Resolu-tion (WAR)).
Being inherently a clustering task,coreference has also received a lot of attention inthe machine learning community.Fifteen years have passed since the first paperon learning-based coreference resolution was pub-lished (Connolly et al, 1994).
Our goal in thispaper is to provide NLP researchers with a sur-vey of the major milestones in supervised coref-erence research, focusing on the computationalmodels, the linguistic features, the annotated cor-pora, and the evaluation metrics that were devel-oped in the past fifteen years.
Note that severalleading coreference researchers have publishedbooks (e.g., Mitkov (2002)), written survey arti-cles (e.g., Mitkov (1999), Strube (2009)), and de-livered tutorials (e.g., Strube (2002), Ponzetto andPoesio (2009)) that provide a broad overview ofcoreference research.
This survey paper aims tocomplement, rather than supersede, these previ-ously published materials.
In particular, while ex-isting survey papers discuss learning-based coref-erence research primarily in the context of the in-fluential mention-pair model, we additionally sur-vey recently proposed learning-based coreferencemodels, which attempt to address the weaknessesof the mention-pair model.
Due to space limita-tions, however, we will restrict our discussion tothe most commonly investigated kind of corefer-ence relation: the identity relation for NPs, exclud-ing coreference among clauses and bridging refer-ences (e.g., part/whole and set/subset relations).2 Annotated CorporaThe widespread popularity of machine learningapproaches to coreference resolution can be at-tributed in part to the public availability of an-1396notated coreference corpora.
The MUC-6 andMUC-7 corpora, though relatively small (60 doc-uments each) and homogeneous w.r.t.
documenttype (newswire articles only), have been exten-sively used for training and evaluating coreferencemodels.
Equally popular are the corpora producedby the Automatic Content Extraction (ACE1) eval-uations in the past decade: while the earlier ACEcorpora (e.g., ACE-2) consist of solely Englishnewswire and broadcast news articles, the laterones (e.g., ACE 2005) have also included Chi-nese and Arabic documents taken from additionalsources such as broadcast conversations, webblog,usenet, and conversational telephone speech.Coreference annotations are also publicly avail-able in treebanks.
These include (1) the EnglishPenn Treebank (Marcus et al, 1993), which is la-beled with coreference links as part of the Onto-Notes project (Hovy et al, 2006); (2) the Tu?bingenTreebank (Telljohann et al, 2004), which is acollection of German news articles consisting of27,125 sentences; (3) the Prague DependencyTreebank (Hajic?
et al, 2006), which consists of3168 news articles taken from the Czech NationalCorpus; (4) the NAIST Text Corpus (Iida et al,2007b), which consists of 287 Japanese news arti-cles; (5) the AnCora Corpus (Recasens and Mart?
?,2009), which consists of Spanish and Catalan jour-nalist texts; and (6) the GENIA corpus (Ohta et al,2002), which contains 2000 MEDLINE abstracts.Other publicly available coreference corpora ofinterest include two annotated by Ruslan Mitkov?sresearch group: (1) a 55,000-word corpus inthe domain of security/terrorism (Hasler et al,2006); and (2) training data released as part of the2007 Anaphora Resolution Exercise (Ora?san et al,2008), a coreference resolution shared task.
Thereare also two that consist of spoken dialogues: theTRAINS93 corpus (Heeman and Allen, 1995) andthe Switchboard data set (Calhoun et al, in press).Additional coreference data will be available inthe near future.
For instance, the SemEval-2010shared task on Coreference Resolution in MultipleLanguages (Recasens et al, 2009) has promised torelease coreference data in six languages.
In addi-tion, Massimo Poesio and his colleagues are lead-ing an annotation project that aims to collect largeamounts of coreference data for English via a WebCollaboration game called Phrase Detectives2.1http://www.itl.nist.gov/iad/mig/tests/ace/2http://www.phrasedetectives.org3 Learning-Based Coreference ModelsIn this section, we examine three important classesof coreference models that were developed in thepast fifteen years, namely, the mention-pair model,the entity-mention model, and ranking models.3.1 Mention-Pair ModelThe mention-pair model is a classifier that deter-mines whether two NPs are coreferent.
It wasfirst proposed by Aone and Bennett (1995) andMcCarthy and Lehnert (1995), and is one of themost influential learning-based coreference mod-els.
Despite its popularity, this binary classifica-tion approach to coreference is somewhat undesir-able: the transitivity property inherent in the coref-erence relation cannot be enforced, as it is possiblefor the model to determine that A and B are coref-erent, B and C are coreferent, but A and C are notcoreferent.
Hence, a separate clustering mecha-nism is needed to coordinate the pairwise classifi-cation decisions made by the model and constructa coreference partition.Another issue that surrounds the acquisition ofthe mention-pair model concerns the way train-ing instances are created.
Specifically, to deter-mine whether a pair of NPs is coreferent or not,the mention-pair model needs to be trained on adata set where each instance represents two NPsand possesses a class value that indicates whetherthe two NPs are coreferent.
Hence, a natural wayto assemble a training set is to create one instancefrom each pair of NPs appearing in a training doc-ument.
However, this instance creation method israrely employed: as most NP pairs in a text are notcoreferent, this method yields a training set with askewed class distribution, where the negative in-stances significantly outnumber the positives.As a result, in practical implementations of themention-pair model, one needs to specify not onlythe learning algorithm for training the model andthe linguistic features for representing an instance,but also the training instance creation method forreducing class skewness and the clustering algo-rithm for constructing a coreference partition.3.1.1 Creating Training InstancesAs noted above, the primary purpose of train-ing instance creation is to reduce class skewness.Many heuristic instance creation methods havebeen proposed, among which Soon et al?s (1999;2001) is arguably the most popular choice.
Given1397an anaphoric noun phrase3, NPk , Soon et al?smethod creates a positive instance between NPkand its closest preceding antecedent, NPj , and anegative instance by pairing NPk with each of theintervening NPs, NPj+1, .
.
., NPk?1.With an eye towards improving the precision ofa coreference resolver, Ng and Cardie (2002c) pro-pose an instance creation method that involves asingle modification to Soon et al?s method: if NPkis non-pronominal, a positive instance should beformed between NPk and its closest preceding non-pronominal antecedent instead.
This modificationis motivated by the observation that it is not easyfor a human, let alne a machine learner, to learnfrom a positive instance where the antecedent of anon-pronominal NP is a pronoun.To further reduce class skewness, some re-searchers employ a filtering mechanism on top ofan instance creation method, thereby disallowingthe creation of training instances from NP pairsthat are unlikely to be coreferent, such as NP pairsthat violate gender and number agreement (e.g.,Strube et al (2002), Yang et al (2003)).While many instance creation methods areheuristic in nature (see Uryupina (2004) and Hosteand Daelemans (2005)), some are learning-based.For example, motivated by the fact that somecoreference relations are harder to identify thanthe others (see Harabagiu et al (2001)), Ng andCardie (2002a) present a method for mining easypositive instances, in an attempt to avoid the inclu-sion of hard training instances that may complicatethe acquisition of an accurate coreference model.3.1.2 Training a Coreference ClassifierOnce a training set is created, we can train a coref-erence model using an off-the-shelf learning algo-rithm.
Decision tree induction systems (e.g., C5(Quinlan, 1993)) are the first and one of the mostwidely used learning algorithms by coreferenceresearchers, although rule learners (e.g., RIPPER(Cohen, 1995)) and memory-based learners (e.g.,TiMBL (Daelemans and Van den Bosch, 2005))are also popular choices, especially in early appli-cations of machine learning to coreference resolu-tion.
In recent years, statistical learners such asmaximum entropy models (Berger et al, 1996),voted perceptrons (Freund and Schapire, 1999),3In this paper, we use the term anaphoric to describe anyNP that is part of a coreference chain but is not the head ofthe chain.
Hence, proper names can be anaphoric under thisoverloaded definition, but linguistically, they are not.and support vector machines (Joachims, 1999)have been increasingly used, in part due to theirability to provide a confidence value (e.g., in theform of a probability) associated with a classifica-tion, and in part due to the fact that they can beeasily adapted to train recently proposed ranking-based coreference models (see Section 3.3).3.1.3 Generating an NP PartitionAfter training, we can apply the resulting modelto a test text, using a clustering algorithm to co-ordinate the pairwise classification decisions andimpose an NP partition.
Below we describe somecommonly used coreference clustering algorithms.Despite their simplicity, closest-first cluster-ing (Soon et al, 2001) and best-first clustering(Ng and Cardie, 2002c) are arguably the mostwidely used coreference clustering algorithms.The closest-first clustering algorithm selects as theantecedent for an NP, NPk, the closest precedingnoun phrase that is classified as coreferent with it.4However, if no such preceding noun phrase exists,no antecedent is selected for NPk .
The best-firstclustering algorithm aims to improve the precisionof closest-first clustering, specifically by selectingas the antecedent of NPk the most probable preced-ing NP that is classified as coreferent with it.One criticism of the closest-first and best-firstclustering algorithms is that they are too greedy.In particular, clusters are formed based on a smallsubset of the pairwise decisions made by themodel.
Moreover, positive pairwise decisions areunjustifiably favored over their negative counter-parts.
For example, three NPs are likely to end upin the same cluster in the resulting partition even ifthere is strong evidence that A and C are not coref-erent, as long as the other two pairs (i.e., (A,B) and(B,C)) are classified as positive.Several algorithms that address one or both ofthese problems have been used for coreferenceclustering.
Correlation clustering (Bansal et al,2002), which produces a partition that respectsas many pairwise decisions as possible, is usedby McCallum and Wellner (2004), Zelenko et al(2004), and Finley and Joachims (2005).
Graphpartitioning algorithms are applied on a weighted,undirected graph where a vertex corresponds toan NP and an edge is weighted by the pairwisecoreference scores between two NPs (e.g., Mc-Callum and Wellner (2004), Nicolae and Nico-4If a probabilistic model is used, we can define a thresholdabove which a pair of NPs is considered coreferent.1398lae (2006)).
The Dempster-Shafer rule (Dempster,1968), which combines the positive and negativepairwise decisions to score a partition, is used byKehler (1997) and Bean and Riloff (2004) to iden-tify the most probable NP partition.Some clustering algorithms bear a closer resem-blance to the way a human creates coreferenceclusters.
In these algorithms, not only are the NPsin a text processed in a left-to-right manner, thelater coreference decisions are dependent on theearlier ones (Cardie and Wagstaff, 1999; Klennerand Ailloud, 2008).5 For example, to resolve anNP, NPk , Cardie and Wagstaff?s algorithm consid-ers each preceding NP, NPj , as a candidate an-tecedent in a right-to-left order.
If NPk and NPjare likely to be coreferent, the algorithm imposesan additional check that NPk does not violate anyconstraint on coreference (e.g., gender agreement)with any NP in the cluster containing NPj beforepositing that the two NPs are coreferent.Luo et al?s (2004) Bell-tree-based algorithm isanother clustering algorithm where the later coref-erence decisions are dependent on the earlier ones.A Bell tree provides an elegant way of organizingthe space of NP partitions.
Informally, a node inthe ith level of a Bell tree corresponds to an ith-order partial partition (i.e., a partition of the firsti NPs of the given document), and the ith level ofthe tree contains all possible ith-order partial parti-tions.
Hence, a leaf node contains a complete par-tition of the NPs, and the goal is to search for theleaf node that contains the most probable partition.The search starts at the root, and a partitioning ofthe NPs is incrementally constructed as we movedown the tree.
Specifically, based on the corefer-ence decisions it has made in the first i?1 levels ofthe tree, the algorithm determines at the ith levelwhether the ith NP should start a new cluster, or towhich preceding cluster it should be assigned.While many coreference clustering algorithmshave been developed, there have only been a fewattempts to compare their effectiveness.
For ex-ample, Ng and Cardie (2002c) report that best-first clustering is better than closest-first cluster-ing.
Nicolae and Nicolae (2006) show that best-first clustering performs similarly to Bell-tree-based clustering, but neither of these algorithms5When applying closest-first and best-first clustering,Soon et al (2001) and Ng and Cardie (2002c) also processthe NPs in a sequential manner, but since the later decisionsare not dependent on the earlier ones, the order in which theNPs are processed does not affect their clustering results.performs as well as their proposed minimum-cut-based graph partitioning algorithm.3.1.4 Determining NP AnaphoricityWhile coreference clustering algorithms attemptto resolve each NP encountered in a document,only a subset of the NPs are anaphoric and there-fore need to be resolved.
Hence, knowledge of theanaphoricity of an NP can potentially improve theprecision of a coreference resolver.Traditionally, the task of anaphoricity determi-nation has been tackled independently of corefer-ence resolution using a variety of techniques.
Forexample, pleonastic it has been identified usingheuristic approaches (e.g., Paice and Husk (1987),Lappin and Leass (1994), Kennedy and Bogu-raev (1996)), supervised approaches (e.g., Evans(2001), Mu?ller (2006), Versley et al (2008a)),and distributional methods (e.g., Bergsma et al(2008)); and non-anaphoric definite descriptionshave been identified using rule-based techniques(e.g., Vieira and Poesio (2000)) and unsupervisedtechniques (e.g., Bean and Riloff (1999)).Recently, anaphoricity determination has beenevaluated in the context of coreference resolution,with results showing that training an anaphoric-ity classifier to identify and filter non-anaphoricNPs prior to coreference resolution can improvea learning-based resolver (e.g., Ng and Cardie(2002b), Uryupina (2003), Poesio et al (2004b)).Compared to earlier work on anaphoricity deter-mination, recently proposed approaches are more?global?
in nature, taking into account the pair-wise decisions made by the mention-pair modelwhen making anaphoricity decisions.
Examplesof such approaches have exploited techniques in-cluding integer linear programming (ILP) (Denisand Baldridge, 2007a), label propagation (Zhouand Kong, 2009), and minimum cuts (Ng, 2009).3.1.5 Combining Classification & ClusteringFrom a learning perspective, a two-step approachto coreference ?
classification and clustering ?is undesirable.
Since the classification modelis trained independently of the clustering algo-rithm, improvements in classification accuracydo not guarantee corresponding improvements inclustering-level accuracy.
That is, overall perfor-mance on the coreference task might not improve.To address this problem, McCallum and Well-ner (2004) and Finley and Joachims (2005) elimi-nate the classification step entirely, treating coref-1399erence as a supervised clustering task where a sim-ilarity metric is learned to directly maximize clus-tering accuracy.
Klenner (2007) and Finkel andManning (2008) use ILP to ensure that the pair-wise classification decisions satisfy transitivity.63.1.6 Weaknesses of the Mention-Pair ModelWhile many of the aforementioned algorithmsfor clustering and anaphoricity determination havebeen shown to improve coreference performance,the underlying model with which they are usedin combination ?
the mention-pair model ?
re-mains fundamentally weak.
The model has twocommonly-cited weaknesses.
First, since eachcandidate antecedent for an anaphoric NP to beresolved is considered independently of the oth-ers, the model only determines how good a candi-date antecedent is relative to the anaphoric NP, butnot how good a candidate antecedent is relative toother candidates.
In other words, it fails to answerthe question of which candidate antecedent is mostprobable.
Second, it has limitations in its expres-siveness: the information extracted from the twoNPs alone may not be sufficient for making an in-formed coreference decision, especially if the can-didate antecedent is a pronoun (which is semanti-cally empty) or a mention that lacks descriptive in-formation such as gender (e.g., ?Clinton?).
Belowwe discuss how these weaknesses are addressed bythe entity-mention model and ranking models.3.2 Entity-Mention ModelThe entity-mention model addresses the expres-siveness problem with the mention-pair model.To motivate the entity-mention model, consideran example taken from McCallum and Wellner(2003), where a document consists of three NPs:?Mr.
Clinton,?
?Clinton,?
and ?she.?
The mention-pair model may determine that ?Mr.
Clinton?
and?Clinton?
are coreferent using string-matchingfeatures, and that ?Clinton?
and ?she?
are coref-erent based on proximity and lack of evidence forgender and number disagreement.
However, thesetwo pairwise decisions together with transitivityimply that ?Mr.
Clinton?
and ?she?
will end up inthe same cluster, which is incorrect due to gen-der mismatch.
This kind of error arises in partbecause the later coreference decisions are not de-pendent on the earlier ones.
In particular, had themodel taken into consideration that ?Mr.
Clinton?6Recently, however, Klenner and Ailloud (2009) have be-come less optimistic about ILP approaches to coreference.and ?Clinton?
were in the same cluster, it proba-bly would not have posited that ?she?
and ?Clin-ton?
are coreferent.
The aforementioned Cardieand Wagstaff algorithm attempts to address thisproblem in a heuristic manner.
It would be de-sirable to learn a model that can classify whetheran NP to be resolved is coreferent with a preced-ing, possibly partially-formed, cluster.
This modelis commonly known as the entity-mention model.Since the entity-mention model aims to classifywhether an NP is coreferent with a preceding clus-ter, each of its training instances (1) correspondsto an NP, NPk , and a preceding cluster, Cj , and(2) is labeled with either POSITIVE or NEGATIVE,depending on whether NPk should be assigned toCj .
Consequently, we can represent each instanceby a set of cluster-level features (i.e., features thatare defined over an arbitrary subset of the NPs inCj).
A cluster-level feature can be computed froma feature employed by the mention-pair model byapplying a logical predicate.
For example, giventhe NUMBER AGREEMENT feature, which deter-mines whether two NPs agree in number, we canapply the ALL predicate to create a cluster-levelfeature, which has the value YES if NPk agrees innumber with all of the NPs in Cj and NO other-wise.
Other commonly-used logical predicates forcreating cluster-level features include relaxed ver-sions of the ALL predicate, such as MOST, whichis true if NPk agrees in number with more than halfof the NPs in Cj , and ANY, which is true as long asNPk agrees in number with just one of the NPs inCj .
The ability of the entity-mention model to em-ploy cluster-level features makes it more expres-sive than its mention-pair counterpart.Despite its improved expressiveness, the entity-mention model has not yielded particularly en-couraging results.
For example, Luo et al (2004)apply the ANY predicate to generate cluster-levelfeatures for their entity-mention model, whichdoes not perform as well as the mention-pairmodel.
Yang et al (2004b; 2008a) also investi-gate the entity-mention model, which produces re-sults that are only marginally better than those ofthe mention-pair model.
However, it appears thatthey are not fully exploiting the expressiveness ofthe entity-mention model, as cluster-level featuresonly comprise a small fraction of their features.Variants of the entity-mention model have beeninvestigated.
For example, Culotta et al (2007)present a first-order logic model that determines1400the probability that an arbitrary set of NPs are allco-referring.
Their model resembles the entity-mention model in that it enables the use of cluster-level features.
Daume?
III and Marcu (2005) pro-pose an online learning model for constructingcoreference chains in an incremental fashion, al-lowing later coreference decisions to be made byexploiting cluster-level features that are computedover the coreference chains created thus far.3.3 Ranking ModelsWhile the entity-mention model addresses theexpressiveness problem with the mention-pairmodel, it does not address the other problem: fail-ure to identify the most probable candidate an-tecedent.
Ranking models, on the other hand, al-low us to determine which candidate antecedentis most probable given an NP to be resolved.Ranking is arguably a more natural reformula-tion of coreference resolution than classification,as a ranker allows all candidate antecedents to beconsidered simultaneously and therefore directlycaptures the competition among them.
Anotherdesirable consequence is that there exists a nat-ural resolution strategy for a ranking approach:an anaphoric NP is resolved to the candidate an-tecedent that has the highest rank.
This contrastswith classification-based approaches, where manyclustering algorithms have been employed to co-ordinate the pairwise classification decisions, andit is still not clear which of them is the best.The notion of ranking candidate antecedentscan be traced back to centering algorithms, manyof which use grammatical roles to rank forward-looking centers (see Walker et al (1998)).
Rank-ing is first applied to learning-based coreferenceresolution by Connolly et al (1994; 1997), wherea model is trained to rank two candidate an-tecedents.
Each training instance corresponds tothe NP to be resolved, NPk, as well as two candi-date antecedents, NPi and NPj , one of which is anantecedent of NPk and the other is not.
Its classvalue indicates which of the two candidates is bet-ter.
This model is referred to as the tournamentmodel by Iida et al (2003) and the twin-candidatemodel by Yang et al (2003; 2008b).
To resolve anNP during testing, one way is to apply the model toeach pair of its candidate antecedents, and the can-didate that is classified as better the largest numberof times is selected as its antecedent.Advances in machine learning have made it pos-sible to train a mention ranker that ranks all ofthe candidate antecedents simultaneously.
Whilemention rankers have consistently outperformedthe mention-pair model (Versley, 2006; Denis andBaldridge, 2007b), they are not more expressivethan the mention-pair model, as they are unableto exploit cluster-level features, unlike the entity-mention model.
To enable rankers to employcluster-level features, Rahman and Ng (2009) pro-pose the cluster-ranking model, which ranks pre-ceding clusters, rather than candidate antecedents,for an NP to be resolved.
Cluster rankers there-fore address both weaknesses of the mention-pairmodel, and have been shown to improve mentionrankers.
Cluster rankers are conceptually similarto Lappin and Leass?s (1994) heuristic pronoun re-solver, which resolves an anaphoric pronoun to themost salient preceding cluster.An important issue with ranking models thatwe have eluded so far concerns the identificationof non-anaphoric NPs.
As a ranker simply im-poses a ranking on candidate antecedents or pre-ceding clusters, it cannot determine whether an NPis anaphoric (and hence should be resolved).
Toaddress this problem, Denis and Baldridge (2008)apply an independently trained anaphoricity clas-sifier to identify non-anaphoric NPs prior to rank-ing, and Rahman and Ng (2009) propose a modelthat jointly learns coreference and anaphoricity.4 Knowledge SourcesAnother thread of supervised coreference researchconcerns the development of linguistic features.Below we give an overview of these features.String-matching features can be computed ro-bustly and typically contribute a lot to the per-formance of a coreference system.
Besides sim-ple string-matching operations such as exact stringmatch, substring match, and head noun matchfor different kinds of NPs (see Daume?
III andMarcu (2005)), slightly more sophisticated string-matching facilities have been attempted, includ-ing minimum edit distance (Strube et al, 2002)and longest common subsequence (Castan?o et al,2002).
Yang et al (2004a) treat the two NPs in-volved as two bags of words, and compute theirsimilarity using metrics commonly-used in infor-mation retrieval, such as the dot product, with eachword weighted by their TF-IDF value.Syntactic features are computed based on asyntactic parse tree.
Ge et al (1998) implement1401a Hobbs distance feature, which encodes the rankassigned to a candidate antecedent for a pronounby Hobbs?s (1978) seminal syntax-based pronounresolution algorithm.
Luo and Zitouni (2005) ex-tract features from a parse tree for implement-ing Binding Constraints (Chomsky, 1988).
Givenan automatically parsed corpus, Bergsma and Lin(2006) extract from each parse tree a dependencypath, which is represented as a sequence of nodesand dependency labels connecting a pronoun anda candidate antecedent, and collect statistical in-formation from these paths to determine the like-lihood that a pronoun and a candidate antecedentconnected by a given path are coreferent.
Ratherthan deriving features from parse trees, Iida et al(2006) and Yang et al (2006) employ these treesdirectly as structured features for pronoun resolu-tion.
Specifically, Yang et al define tree kernelsfor efficiently computing the similarity betweentwo parse trees, and Iida et al use a boosting-basedalgorithm to compute the usefulness of a subtree.Grammatical features encode the grammati-cal properties of one or both NPs involved in aninstance.
For example, Ng and Cardie?s (2002c)resolver employs 34 grammatical features.
Somefeatures determine NP type (e.g., are both NPs def-inite or pronouns?).
Some determine the grammat-ical role of one or both of the NPs.
Some encodetraditional linguistic (hard) constraints on corefer-ence.
For example, coreferent NPs have to agreein number and gender and cannot span one an-other (e.g., ?Google?
and ?Google employees?
).There are also features that encode general linguis-tic preferences either for or against coreference.For example, an indefinite NP (that is not in ap-position to an anaphoric NP) is not likely to becoreferent with any NP that precedes it.There has been an increasing amount of work oninvestigating semantic features for coreferenceresolution.
One of the earliest kinds of seman-tic knowledge employed for coreference resolu-tion is perhaps selectional preference (Dagan andItai, 1990; Kehler et al, 2004b; Yang et al, 2005;Haghighi and Klein, 2009): given a pronoun to beresolved, its governing verb, and its grammaticalrole, we prefer a candidate antecedent that can begoverned by the same verb and be in the same role.Semantic knowledge has also been extracted fromWordNet and unannotated corpora for computingthe semantic compatibility/similarity between twocommon nouns (Harabagiu et al, 2001; Versley,2007) as well as the semantic class of a noun (Ng,2007a; Huang et al, 2009).
One difficulty withderiving knowledge from WordNet is that one hasto determine which sense of a given word to use.Some researchers simply use the first sense (Soonet al, 2001) or all possible senses (Ponzetto andStrube, 2006a), while others overcome this prob-lem with word sense disambiguation (Nicolae andNicolae, 2006).
Knowledge has also been minedfrom Wikipedia for measuring the semantic relat-edness of two NPs, NPj and NPk (Ponzetto andStrube (2006a; 2007)), such as: whether NPj/k ap-pears in the first paragraph of the Wiki page thathas NPk/j as the title or in the list of categories towhich this page belongs, and the degree of overlapbetween the two pages that have the two NPs astheir titles (see Poesio et al (2007) for other usesof encyclopedic knowledge for coreference reso-lution).
Contextual roles (Bean and Riloff, 2004),semantic relations (Ji et al, 2005), semantic roles(Ponzetto and Strube, 2006b; Kong et al, 2009),and animacy (Ora?san and Evans, 2007) have alsobeen exploited to improve coreference resolution.Lexico-syntactic patterns have been used tocapture the semantic relatedness between two NPsand hence the likelihood that they are coreferent.For instance, given the pattern X is a Y (which ishighly indicative that X and Y are coreferent), wecan instantiate it with a pair of NPs and searchfor the instantiated pattern in a large corpus orthe Web (Daume?
III and Marcu, 2005; Haghighiand Klein, 2009).
The more frequently the pat-tern occurs, the more likely they are coreferent.This technique has been applied to resolve dif-ferent kinds of anaphoric references, includingother-anaphora (Modjeska et al, 2003; Markertand Nissim, 2005) and bridging references (Poesioet al, 2004a).
While these patterns are typicallyhand-crafted (e.g., Garera and Yarowsky (2006)),they can also be learned from an annotated cor-pus (Yang and Su, 2007) or bootstrapped from anunannotated corpus (Bean and Riloff, 2004).Despite the large amount of work on discourse-based anaphora resolution in the 1970s and1980s (see Hirst (1981)), learning-based resolvershave only exploited shallow discourse-based fea-tures, which primarily involve characterizing thesalience of a candidate antecedent by measuringits distance from the anaphoric NP to be resolvedor determining whether it is in a prominent gram-matical role (e.g., subject).
A notable exception1402is Iida et al (2009), who train a ranker to rankthe candidate antecedents for an anaphoric pro-noun by their salience.
It is worth noting thatTetreault (2005) has employed Grosz and Sid-ner?s (1986) discourse theory and Veins Theory(Ide and Cristea, 2000) to identify and removecandidate antecedents that are not referentially ac-cessible to an anaphoric pronoun in his heuristicpronoun resolvers.
It would be interesting to in-corporate this idea into a learning-based resolver.There are also features that do not fall into anyof the preceding categories.
For example, a mem-orization feature is a word pair composed of thehead nouns of the two NPs involved in an in-stance (Bengtson and Roth, 2008).
Memoriza-tion features have been used as binary-valued fea-tures indicating the presence or absence of theirwords (Luo et al, 2004) or as probabilistic fea-tures indicating the probability that the two headsare coreferent according to the training data (Ng,2007b).
An anaphoricity feature indicates whetheran NP to be resolved is anaphoric, and is typ-ically computed using an anaphoricity classifier(Ng, 2004), hand-crafted patterns (Daume?
III andMarcu, 2005), and automatically acquired pat-terns (Bean and Riloff, 1999).
Finally, the outputsof rule-based pronoun and coreference resolvershave also been used as features for learning-basedcoreference resolution (Ng and Cardie, 2002c).For an empirical evaluation of the contributionof a subset of these features to the mention-pairmodel, see Bengtson and Roth (2008).5 Evaluation IssuesTwo important issues surround the evaluation of acoreference resolver.
First, how do we obtain theset of NPs that a resolver will partition?
Second,how do we score the partition it produces?5.1 Extracting Candidate Noun PhrasesTo obtain the set of NPs to be partitioned by a re-solver, three methods are typically used.
In thefirst method, the NPs are extracted automaticallyfrom a syntactic parser.
The second method in-volves extracting the NPs directly from the goldstandard.
In the third method, a mention detec-tor is first trained on the gold-standard NPs in thetraining texts, and is then applied to automaticallyextract system mentions in a test text.7 Note that7An exception is Daume?
III and Marcu (2005), whosemodel jointly learns to extract NPs and perform coreference.these three extraction methods typically producedifferent numbers of NPs: the NPs extracted froma parser tend to significantly outnumber the systemmentions, which in turn outnumber the gold NPs.The reasons are two-fold.
First, in some corefer-ence corpora (e.g., MUC-6 and MUC-7), the NPsthat are not part of any coreference chain are notannotated.
Second, in corpora such as those pro-duced by the ACE evaluations, only the NPs thatbelong to one of the ACE entity types (e.g., PER-SON, ORGANIZATION, LOCATION) are annotated.Owing in large part to the difference in the num-ber of NPs extracted by these three methods, acoreference resolver can produce substantially dif-ferent results when applied to the resulting threesets of NPs, with gold NPs yielding the best resultsand NPs extracted from a parser yielding the worst(Nicolae and Nicolae, 2006).
While researcherswho evaluate their resolvers on gold NPs point outthat the results can more accurately reflect the per-formance of their coreference algorithm, Stoyanovet al (2009) argue that such evaluations are unre-alistic, as NP extraction is an integral part of anend-to-end fully-automatic resolver.Whichever NP extraction method is employed,it is clear that the use of gold NPs can considerablysimplify the coreference task, and hence resolversemploying different extraction methods should notbe compared against each other.5.2 Scoring a Coreference PartitionThe MUC scorer (Vilain et al, 1995) is the firstprogram developed for scoring coreference parti-tions.
It has two often-cited weaknesses.
As a link-based measure, it does not reward correctly iden-tified singleton clusters since there is no corefer-ence link in these clusters.
Also, it tends to under-penalize partitions with overly large clusters.To address these problems, two coreferencescoring programs have been developed: B3(Bagga and Baldwin, 1998) and CEAF (Luo,2005).
Note that both scorers have only been de-fined for the case where the key partition has thesame set of NPs as the response partition.
To applythese scorers to automatically extracted NPs, dif-ferent methods have been proposed (see Rahmanand Ng (2009) and Stoyanov et al (2009)).Since coreference is a clustering task, anygeneral-purpose method for evaluating a responsepartition against a key partition (e.g., Kappa (Car-letta, 1996)) can be used for coreference scor-1403ing (see Popescu-Belis et al (2004)).
In practice,these general-purpose methods are typically usedto provide scores that complement those obtainedvia the three coreference scorers discussed above.It is worth mentioning that there is a trend to-wards evaluating a resolver against multiple scor-ers, which can indirectly help to counteract thebias inherent in a particular scorer.
For further dis-cussion on evaluation issues, see Byron (2001).6 Concluding RemarksWhile we have focused our discussion on super-vised approaches, coreference researchers havealso attempted to reduce a resolver?s reliance onannotated data by combining a small amount oflabeled data and a large amount of unlabeleddata using general-purpose semi-supervised learn-ing algorithms such as co-training (Mu?ller et al,2002), self-training (Kehler et al, 2004a), and EM(Cherry and Bergsma, 2005; Ng, 2008).
Interest-ingly, recent results indicate that unsupervised ap-proaches to coreference resolution (e.g., Haghighiand Klein (2007; 2010), Poon and Domingos(2008)) rival their supervised counterparts, castingdoubts on whether supervised resolvers are mak-ing effective use of the available labeled data.Another issue that we have not focused on butwhich is becoming increasingly important is mul-tilinguality.
While many of the techniques dis-cussed in this paper were originally developed forEnglish, they have been applied to learn coref-erence models for other languages, such as Chi-nese (e.g., Converse (2006)), Japanese (e.g., Iida(2007)), Arabic (e.g., Luo and Zitouni (2005)),Dutch (e.g., Hoste (2005)), German (e.g., Wun-sch (2010)), Swedish (e.g., Nilsson (2010)), andCzech (e.g., Ngu.y et al (2009)).
In addition, re-searchers have developed approaches that are tar-geted at handling certain kinds of anaphora presentin non-English languages, such as zero anaphora(e.g., Iida et al (2007a), Zhao and Ng (2007)).As Mitkov (2001) puts it, coreference resolutionis a ?difficult, but not intractable problem,?
andwe have been making ?slow, but steady progress?on improving machine learning approaches to theproblem in the past fifteen years.
To ensure fur-ther progress, researchers should compare their re-sults against a baseline that is stronger than thecommonly-used Soon et al (2001) system, whichrelies on a weak model (i.e., the mention-pairmodel) and a small set of linguistic features.
As re-cent systems are becoming more sophisticated, wesuggest that researchers make their systems pub-licly available in order to facilitate performancecomparisons.
Publicly available coreference sys-tems currently include JavaRAP (Qiu et al, 2004),GuiTaR (Poesio and Kabadjov, 2004), BART (Ver-sley et al, 2008b), CoRTex (Denis and Baldridge,2008), the Illinois Coreference Package (Bengt-son and Roth, 2008), CherryPicker (Rahman andNg, 2009), Reconcile (Stoyanov et al, 2010), andCharniak and Elsner?s (2009) pronoun resolver.We conclude with a discussion of two ques-tions regarding supervised coreference research.First, what is the state of the art?
This is not aneasy question, as researchers have been evaluat-ing their resolvers on different corpora using dif-ferent evaluation metrics and preprocessing tools.In particular, preprocessing tools can have a largeimpact on the performance of a resolver (Barbuand Mitkov, 2001).
Worse still, assumptions aboutwhether gold or automatically extracted NPs areused are sometimes not explicitly stated, poten-tially causing results to be interpreted incorrectly.To our knowledge, however, the best results on theMUC-6 and MUC-7 data sets using automaticallyextracted NPs are reported by Yang et al (2003)(71.3 MUC F-score) and Ng and Cardie (2002c)(63.4 MUC F-score), respectively;8 and the bestresults on the ACE data sets using gold NPs canbe found in Luo (2007) (88.4 ACE-value).Second, what lessons can we learn from fifteenyears of learning-based coreference research?The mention-pair model is weak because it makescoreference decisions based on local informa-tion (i.e., information extracted from two NPs).Expressive models (e.g., those that can exploitcluster-level features) generally offer better perfor-mance, and so are models that are ?global?
in na-ture.
Global coreference models may refer to anykind of models that can exploit non-local infor-mation, including models that can consider mul-tiple candidate antecedents simultaneously (e.g.,ranking models), models that allow joint learningfor coreference resolution and related tasks (e.g.,anaphoricity determination), models that can di-rectly optimize clustering-level (rather than classi-fication) accuracy, and models that can coordinatewith other components of a resolver, such as train-ing instance creation and clustering.8These results by no means suggest that no progress hasbeen made since 2003: most of the recently proposed coref-erence models were evaluated on the ACE data sets.1404AcknowledgmentsWe thank the three anonymous reviewers for theirinvaluable comments on an earlier draft of the pa-per.
This work was supported in part by NSFGrant IIS-0812261.
Any opinions, findings, andconclusions or recommendations expressed arethose of the author and do not necessarily reflectthe views or official policies, either expressed orimplied, of the NSF.ReferencesChinatsu Aone and Scott William Bennett.
1995.Evaluating automated and manual acquisition ofanaphora resolution strategies.
In Proceedings of the33rd Annual Meeting of the Association for Compu-tational Linguistics, pages 122?129.Amit Bagga and Breck Baldwin.
1998.
Algorithms forscoring coreference chains.
In Proceedings of theLREC Workshop on Linguistic Coreference, pages563?566.Nikhil Bansal, Avrim Blum, and Shuchi Chawla.
2002.Correlation clustering.
In Proceedings of the 43rdAnnual IEEE Symposium on Foundations of Com-puter Science, pages 238?247.Catalina Barbu and Ruslan Mitkov.
2001.
Evaluationtool for rule-based anaphora resolution methods.
InProceedings of the 39th Annual Meeting of the Asso-ciation for Computational Linguistics, pages 34?41.David Bean and Ellen Riloff.
1999.
Corpus-basedidentification of non-anaphoric noun phrases.
InProceedings of the 37th Annual Meeting of the As-sociation for Computational Linguistics, pages 373?380.David Bean and Ellen Riloff.
2004.
Unsupervisedlearning of contextual role knowledge for corefer-ence resolution.
In Human Language Technologies2004: The Conference of the North American Chap-ter of the Association for Computational Linguistics;Proceedings of the Main Conference, pages 297?304.Eric Bengtson and Dan Roth.
2008.
Understanding thevalues of features for coreference resolution.
In Pro-ceedings of the 2008 Conference on Empirical Meth-ods in Natural Language Processing, pages 294?303.Adam L. Berger, Stephen A. Della Pietra, and Vin-cent J. Della Pietra.
1996.
A maximum entropyapproach to natural language processing.
Compu-tational Linguistics, 22(1):39?71.Shane Bergsma and Dekang Lin.
2006.
Bootstrappingpath-based pronoun resolution.
In Proceedings ofthe 21st International Conference on ComputationalLinguistics and the 44th Annual Meeting of the Asso-ciation for Computational Linguistics, pages 33?40.Shane Bergsma, Dekang Lin, and Randy Goebel.2008.
Distributional identification of non-referentialpronouns.
In Proceedings of ACL-08: HLT, pages10?18.Donna Byron.
2001.
The uncommon denominator: Aproposal for consistent reporting of pronoun resolu-tion results.
Computational Linguistics, 27(4):569?578.Sasha Calhoun, Jean Carletta, Jason Brenier, NeilMayo, Dan Jurafsky, Mark Steedman, and DavidBeaver.
(in press).
The NXT-format Switchboardcorpus: A rich resource for investigating the syn-tax, semantics, pragmatics and prosody of dialogue.Language Resources and Evaluation.Claire Cardie and Kiri Wagstaff.
1999.
Noun phrasecoreference as clustering.
In Proceedings of the1999 Joint SIGDAT Conference on Empirical Meth-ods in Natural Language Processing and Very LargeCorpora, pages 82?89.Jean Carletta.
1996.
Assessing agreement on classi-fication tasks: the kappa statistic.
ComputationalLinguistics, 22(2):249?254.Jose?
Castan?o, Jason Zhang, and James Pustejovsky.2002.
Anaphora resolution in biomedical literature.In Proceedings of the 2002 International Symposiumon Reference Resolution.Eugene Charniak and Micha Elsner.
2009.
EM worksfor pronoun anaphora resolution.
In Proceedings ofthe 12th Conference of the European Chapter of theAssociation for Computational Linguistics, pages148?156.Eugene Charniak.
1972.
Towards a Model of Chil-dren?s Story Comphrension.
AI-TR 266, ArtificialIntelligence Laboratory, Massachusetts Institute ofTechnology, USA.Colin Cherry and Shane Bergsma.
2005.
An expecta-tion maximization approach to pronoun resolution.In Proceedings of the Ninth Conference on Compu-tational Natural Language Learning, pages 88?95.Noam Chomsky.
1988.
Language and Problems ofKnowledge.
The Managua Lectures.
MIT Press,Cambridge, Massachusetts.William Cohen.
1995.
Fast effective rule induction.
InProceedings of the 12th International Conference onMachine Learning, pages 115?123.Dennis Connolly, John D. Burger, and David S. Day.1994.
A machine learning approach to anaphoricreference.
In Proceedings of International Con-ference on New Methods in Language Processing,pages 255?261.Dennis Connolly, John D. Burger, and David S. Day.1997.
A machine learning approach to anaphoricreference.
In D. Jones and H. Somers, editors, NewMethods in Language Processing, pages 133?144.UCL Press.1405Susan Converse.
2006.
Pronominal Anaphora Resolu-tion in Chinese.
Ph.D. thesis, University of Pennsyl-vania, USA.Aron Culotta, Michael Wick, and Andrew McCallum.2007.
First-order probabilistic models for corefer-ence resolution.
In Human Language Technologies2007: The Conference of the North American Chap-ter of the Association for Computational Linguistics;Proceedings of the Main Conference, pages 81?88.Walter Daelemans and Antal Van den Bosch.
2005.Memory-Based Language Processing.
CambridgeUniversity Press, Cambridge, UK.Ido Dagan and Alon Itai.
1990.
Automatic processingof large corpora for the resolution of anaphora ref-erences.
In Proceedings of the 13th InternationalConference on Computational Linguistics, pages330?332.Hal Daume?
III and Daniel Marcu.
2005.
A large-scale exploration of effective global features for ajoint entity detection and tracking model.
In Pro-ceedings of the Human Language Technology Con-ference and the Conference on Empirical Methodsin Natural Language Processing, pages 97?104.Arthur Dempster.
1968.
A generalization of Bayesianinference.
Journal of the Royal Statistical Society,30:205?247.Pascal Denis and Jason Baldridge.
2007a.
Global,joint determination of anaphoricity and coreferenceresolution using integer programming.
In HumanLanguage Technologies 2007: The Conference ofthe North American Chapter of the Association forComputational Linguistics; Proceedings of the MainConference, pages 236?243.Pascal Denis and Jason Baldridge.
2007b.
A rankingapproach to pronoun resolution.
In Proceedings ofthe Twentieth International Conference on ArtificialIntelligence, pages 1588?1593.Pascal Denis and Jason Baldridge.
2008.
Special-ized models and ranking for coreference resolution.In Proceedings of the 2008 Conference on Empiri-cal Methods in Natural Language Processing, pages660?669.Richard Evans.
2001.
Applying machine learning to-ward an automatic classification of it.
Literary andLinguistic Computing, 16(1):45?57.Jenny Rose Finkel and Christopher Manning.
2008.Enforcing transitivity in coreference resolution.
InProceedings of ACL-08: HLT, Short Papers, pages45?48.Thomas Finley and Thorsten Joachims.
2005.
Super-vised clustering with support vector machines.
InProceedings of the 22nd International Conferenceon Machine Learning, pages 217?224.Yoav Freund and Robert E. Schapire.
1999.
Largemargin classification using the perceptron algorithm.Machine Learning, 37(3):277?296.Nikesh Garera and David Yarowsky.
2006.
Resolvingand generating definite anaphora by modeling hy-pernymy using unlabeled corpora.
In Proceedingsof the Tenth Conference on Computational NaturalLanguage Learning, pages 37?44.Niyu Ge, John Hale, and Eugene Charniak.
1998.
Astatistical approach to anaphora resolution.
In Pro-ceedings of the Sixth Workshop on Very Large Cor-pora, pages 161?170.Barbara J. Grosz and Candace L. Sidner.
1986.
Atten-tion, intentions, and the structure of discourse.
Com-putational Linguistics, 12(3):175?204.Barbara J. Grosz, Aravind K. Joshi, and Scott Wein-stein.
1983.
Providing a unified account of definitenoun phrases in discourse.
In Proceedings of the21st Annual Meeting of the Association for Compu-tational Linguistics, pages 44?50.Barbara J. Grosz, Aravind K. Joshi, and Scott Wein-stein.
1995.
Centering: A framework for model-ing the local coherence of discourse.
ComputationalLinguistics, 21(2):203?226.Barbara J. Grosz.
1977.
The representation and use offocus in a system for understanding dialogs.
In Pro-ceedings of the Fifth International Joint Conferenceon Artificial Intelligence, pages 67?76.Aria Haghighi and Dan Klein.
2007.
Unsupervisedcoreference resolution in a nonparametric bayesianmodel.
In Proceedings of the 45th Annual Meet-ing of the Association of Computational Linguistics,pages 848?855.Aria Haghighi and Dan Klein.
2009.
Simple coref-erence resolution with rich syntactic and semanticfeatures.
In Proceedings of the 2009 Conference onEmpirical Methods in Natural Language Process-ing, pages 1152?1161.Aria Haghighi and Dan Klein.
2010.
Coreferenceresolution in a modular, entity-centered model.
InProceedings of Human Language Technologies: The2010 Annual Conference of the North AmericanChapter of the Association for Computational Lin-guistics.Jan Hajic?, Jarmila Panevova?, Eva Hajic?ova?, JarmilaPanevova?, Petr Sgall, Petr Pajas, Jan Ste?pa?nek, Jir??
?Havelka, and Marie Mikulova?.
2006.
The PragueDependency Treebank 2.0.
In Linguistic Data Con-sortium.Sanda Harabagiu, Ra?zvan Bunescu, and Steven Maio-rano.
2001.
Text and knowledge mining for corefer-ence resolution.
In Proceedings of the 2nd Meetingof the North American Chapter of the Associationfor Computational Linguistics, pages 55?62.1406Laura Hasler, Constantin Orasan, and Karin Naumann.2006.
NPs for events: Experiments in coreferenceannotation.
In Proceedings of the 5th InternationalConference on Language Resources and Evaluation,pages 1167?1172.Peter Heeman and James Allen.
1995.
The TRAINSspoken dialog corpus.
CD-ROM, Linguistic DataConsortium.Graeme Hirst.
1981.
Discourse-oriented anaphoraresolution in natural language understanding: A re-view.
American Journal of Computational Linguis-tics, 7(2):85?98.Jerry Hobbs.
1978.
Resolving pronoun references.Lingua, 44:311?338.Ve?ronique Hoste and Walter Daelemans.
2005.
Com-paring learning approaches to coreference resolu-tion.
There is more to it than bias.
In Proceedingsof the ICML Workshop on Meta-Learning.Ve?ronique Hoste.
2005.
Optimization Issues in Ma-chine Learning of Coreference Resolution.
Ph.D.thesis, University of Antewerp, Belgium.Eduard Hovy, Mitchell Marcus, Martha Palmer, LanceRamshaw, and Ralph Weischedel.
2006.
Ontonotes:The 90% solution.
In Proceedings of the HumanLanguage Technology Conference of the NAACL,Companion Volume: Short Papers, pages 57?60.Zhiheng Huang, Guangping Zeng, Weiqun Xu, andAsli Celikyilmaz.
2009.
Accurate semantic classclassifier for coreference resolution.
In Proceedingsof the 2009 Conference on Empirical Methods inNatural Language Processing, pages 1232?1240.Nancy Ide and Dan Cristea.
2000.
A hierarchical ac-count of referential accessibility.
In Proceedings ofthe 38th Annual Meeting of the Association for Com-putational Linguistics, pages 416?424.Ryu Iida, Kentaro Inui, Hiroya Takamura, and YujiMatsumoto.
2003.
Incorporating contextual cuesin trainable models for coreference resolution.
InProceedings of the EACL Workshop on The Compu-tational Treatment of Anaphora.Ryu Iida, Kentaro Inui, and Yuji Matsumoto.
2006.Exploting syntactic patterns as clues in zero-anaphora resolution.
In Proceedings of the 21st In-ternational Conference on Computational Linguis-tics and the 44th Annual Meeting of the Associationfor Computational Linguistics, pages 625?632.Ryu Iida, Kentaro Inui, and Yuji Matsumoto.
2007a.Zero-anaphora resolution by learning rich syntacticpattern features.
ACM Transactions on Asian Lan-guage Information Processing, 6(4).Ryu Iida, Mamoru Komachi, Kentaro Inui, and YujiMatsumoto.
2007b.
Annotating a Japanese text cor-pus with predicate-argument and coreference rela-tions.
In Proceedings of the ACL Workshop ?Lin-guistic Annotation Workshop?, pages 132?139.Ryu Iida, Kentaro Inui, and Yuji Matsumoto.
2009.Capturing salience with a trainable cache model forzero-anaphora resolution.
In Proceedings of theJoint Conference of the 47th Annual Meeting of theACL and the 4th International Joint Conference onNatural Language Processing of the AFNLP, pages647?655.Ryu Iida.
2007.
Combining Linguistic Knowledge andMachine Learning for Anaphora Resolution.
Ph.D.thesis, Nara Institute of Science and Technology,Japan.Heng Ji, David Westbrook, and Ralph Grishman.
2005.Using semantic relations to refine coreference deci-sions.
In Proceedings of the Human Language Tech-nology Conference and the Conference on Empiri-cal Methods in Natural Language Processing, pages17?24.Thorsten Joachims.
1999.
Making large-scale SVMlearning practical.
In Bernhard Scholkopf andAlexander Smola, editors, Advances in Kernel Meth-ods - Support Vector Learning, pages 44?56.
MITPress.Andrew Kehler, Douglas Appelt, Lara Taylor, andAleksandr Simma.
2004a.
Competitive self-trainedpronoun interpretation.
In Proceedings of HLT-NAACL 2004: Short Papers, pages 33?36.Andrew Kehler, Douglas Appelt, Lara Taylor, andAleksandr Simma.
2004b.
The (non)utility ofpredicate-argument frequencies for pronoun inter-pretation.
In Human Language Technologies 2004:The Conference of the North American Chapter ofthe Association for Computational Linguistics; Pro-ceedings of the Main Conference, pages 289?296.Andrew Kehler.
1997.
Probabilistic coreference in in-formation extraction.
In Proceedings of the SecondConference on Empirical Methods in Natural Lan-guage Processing, pages 163?173.Christopher Kennedy and Branimir Boguraev.
1996.Anaphor for everyone: Pronominal anaphora resolu-tion without a parser.
In Proceedings of the 16th In-ternational Conference on Computational Linguis-tics, pages 113?118.Manfred Klenner and ?Etienne Ailloud.
2008.
Enhanc-ing coreference clustering.
In Proceedings of theSecond Workshop on Anaphora Resolution, pages31?40.Manfred Klenner and ?Etienne Ailloud.
2009.
Op-timization in coreference resolution is not needed:A nearly-optimal algorithm with intensional con-straints.
In Proceedings of the 12th Conference ofthe European Chapter of the Association for Com-putational Linguistics, pages 442?450.Manfred Klenner.
2007.
Enforcing consistency oncoreference sets.
In Proceedings of Recent Ad-vances in Natural Language Processing.1407Fang Kong, GuoDong Zhou, and Qiaoming Zhu.
2009.Employing the centering theory in pronoun resolu-tion from the semantic perspective.
In Proceedingsof the 2009 Conference on Empirical Methods inNatural Language Processing, pages 987?996.Shalom Lappin and Herbert Leass.
1994.
An algo-rithm for pronominal anaphora resolution.
Compu-tational Linguistics, 20(4):535?562.Xiaoqiang Luo and Imed Zitouni.
2005.
Multi-lingualcoreference resolution with syntactic features.
InProceedings of the Human Language TechnologyConference and the Conference on Empirical Meth-ods in Natural Language Processing, pages 660?667.Xiaoqiang Luo, Abe Ittycheriah, Hongyan Jing, NandaKambhatla, and Salim Roukos.
2004.
A mention-synchronous coreference resolution algorithm basedon the Bell tree.
In Proceedings of the 42nd AnnualMeeting of the Association for Computational Lin-guistics, pages 135?142.Xiaoqiang Luo.
2005.
On coreference resolution per-formance metrics.
In Proceedings of the HumanLanguage Technology Conference and the Confer-ence on Empirical Methods in Natural LanguageProcessing, pages 25?32.Xiaoqiang Luo.
2007.
Coreference or not: A twinmodel for coreference resolution.
In Human Lan-guage Technologies 2007: The Conference of theNorth American Chapter of the Association forComputational Linguistics; Proceedings of the MainConference, pages 73?80.Mitchell P. Marcus, Beatrice Santorini, and Mary AnnMarcinkiewicz.
1993.
Building a large annotatedcorpus of English: The Penn Treebank.
Computa-tional Linguistics, 19(2):313?330.Katja Markert and Malvina Nissim.
2005.
Comparingknowledge sources for nominal anaphora resolution.Computational Linguistics, 31(3):367?402.Andrew McCallum and Ben Wellner.
2003.
Towardconditional models of identity uncertainty with ap-plication to proper noun coreference.
In Proceed-ings of the IJCAI Workshop on Information Integra-tion on the Web.Andrew McCallum and Ben Wellner.
2004.
Condi-tional models of identity uncertainty with applica-tion to noun coreference.
In Advances in Neural In-formation Proceesing Systems.Joseph McCarthy and Wendy Lehnert.
1995.
Usingdecision trees for coreference resolution.
In Pro-ceedings of the Fourteenth International Conferenceon Artificial Intelligence, pages 1050?1055.Ruslan Mitkov.
1999.
Anaphora resolution: Thestate of the art.
Technical Report (Based on theCOLING/ACL-98 tutorial on anaphora resolution),University of Wolverhampton, Wolverhampton.Ruslan Mitkov.
2001.
Outstanding issues in anaphoraresolution.
In Al.
Gelbukh, editor, ComputationalLinguistics and Intelligent Text Processing, pages110?125.
Springer.Ruslan Mitkov.
2002.
Anaphora Resolution.
Long-man.Natalia N. Modjeska, Katja Markert, and Malvina Nis-sim.
2003.
Using the web in machine learningfor other-anaphora resolution.
In Proceedings of the2003 Conference on Empirical Methods in NaturalLanguage Processing, pages 176?183.MUC-6.
1995.
Proceedings of the Sixth Message Un-derstanding Conference.MUC-7.
1998.
Proceedings of the Seventh MessageUnderstanding Conference.Christoph Mu?ller, Stefan Rapp, and Michael Strube.2002.
Applying co-training to reference resolution.In Proceedings of the 40th Annual Meeting of the As-sociation for Computational Linguistics, pages 352?359.Christoph Mu?ller.
2006.
Automatic detection of non-referential it in spoken multi-party dialog.
In Pro-ceedings of the 11th Conference of the EuropeanChapter of the Association for Computational Lin-guistics, pages 49?56.Vincent Ng and Claire Cardie.
2002a.
Combiningsample selection and error-driven pruning for ma-chine learning of coreference rules.
In Proceedingsof the 2002 Conference on Empirical Methods inNatural Language Processing, pages 55?62.Vincent Ng and Claire Cardie.
2002b.
Identifyinganaphoric and non-anaphoric noun phrases to im-prove coreference resolution.
In Proceedings ofthe 19th International Conference on ComputationalLinguistics, pages 730?736.Vincent Ng and Claire Cardie.
2002c.
Improving ma-chine learning approaches to coreference resolution.In Proceedings of the 40th Annual Meeting of the As-sociation for Computational Linguistics, pages 104?111.Vincent Ng.
2004.
Learning noun phrase anaphoricityto improve conference resolution: Issues in repre-sentation and optimization.
In Proceedings of the42nd Annual Meeting of the Association for Compu-tational Linguistics, pages 151?158.Vincent Ng.
2007a.
Semantic class induction andcoreference resolution.
In Proceedings of the 45thAnnual Meeting of the Association of ComputationalLinguistics, pages 536?543.Vincent Ng.
2007b.
Shallow semantics for coreferenceresolution.
In Proceedings of the Twentieth Inter-national Joint Conference on Artificial Intelligence,pages 1689?1694.1408Vincent Ng.
2008.
Unsupervised models for corefer-ence resolution.
In Proceedings of the 2008 Con-ference on Empirical Methods in Natural LanguageProcessing, pages 640?649.Vincent Ng.
2009.
Graph-cut-based anaphoricity de-termination for coreference resolution.
In Proceed-ings of Human Language Technologies: The 2009Annual Conference of the North American Chap-ter of the Association for Computational Linguistics,pages 575?583.Giang Linh Ngu.y, Va?clav Nova?k, and Zdene?k?Zabokrtsky?.
2009.
Comparison of classification andranking approaches to pronominal anaphora resolu-tion in Czech.
In Proceedings of the SIGDIAL 2009Conference, pages 276?285.Cristina Nicolae and Gabriel Nicolae.
2006.
Best-Cut: A graph algorithm for coreference resolution.In Proceedings of the 2006 Conference on Empiri-cal Methods in Natural Language Processing, pages275?283.Kristina Nilsson.
2010.
Hybrid Methods for Coref-erence Resolution in Swedish.
Ph.D. thesis, Stock-holm University, Sweden.Tomoko Ohta, Yuka Tateisi, and Jin-Dong Kim.
2002.The GENIA corpus: An annotated research abstractcorpus in molecular biology domain.
In Proceed-ings of the Second International Conference on Hu-man Language Technology Research, pages 82?86.Constantin Ora?san and Richard Evans.
2007.
NP ani-macy identification for anaphora resolution.
Journalof Artificial Intelligence Research, 29:79 ?
103.Constantin Ora?san, Dan Cristea, Ruslan Mitkov, andAnto?nio H. Branco.
2008.
Anaphora ResolutionExercise: An overview.
In Proceedings of the 6thLanguage Resources and Evaluation Conference,pages 2801?2805.Chris Paice and Gareth Husk.
1987.
Towards the au-tomatic recognition of anaphoric features in Englishtext: the impersonal pronoun ?it?.
Computer Speechand Language, 2:109?132.Massimo Poesio and Mijail A. Kabadjov.
2004.
Ageneral-purpose, off-the-shelf anaphora resolutionmodule: Implementation and preliminary evalua-tion.
In Proceedings of the 4th International Confer-ence on Language Resources and Evaluation, pages663?668.Massimo Poesio, Rahul Mehta, Axel Maroudas, andJanet Hitzeman.
2004a.
Learning to resolve bridg-ing references.
In Proceedings of the 42nd AnnualMeeting of the Association for Computational Lin-guistics, pages 143?150.Massimo Poesio, Olga Uryupina, Renata Vieira, MijailAlexandrov-Kabadjov, and Rodrigo Goulart.
2004b.Discourse-new detectors for definite description res-olution: A survey and a preliminary proposal.
InProeedings of the ACL Workshop on Reference Res-olution.Massimo Poesio, David Day, Ron Artstein, Jason Dun-can, Vladimir Eidelman, Claudio Giuliano, RobHall, Janet Hitzeman, Alan Jern, Mijail Kabadjov,Stanley Yong Wai Keong, Gideon Mann, Alessan-dro Moschitti, Simone Ponzetto, Jason Smith, JosefSteinberger, Michael Strube, Jian Su, Yannick Vers-ley, Xiaofeng Yang, and Michael Wick.
2007.
EL-ERFED: Final report of the research group on Ex-ploiting Lexical and Encyclopedic Resources ForEntity Disambiguation.
Technical report, SummerWorkshop on Language Engineering, Center forLanguage and Speech Processing, Johns HopkinsUniversity, Baltimore, MD.Simone Paolo Ponzetto and Massimo Poesio.
2009.State-of-the-art NLP approaches to coreference res-olution: Theory and practical recipes.
In TutorialAbstracts of ACL-IJCNLP 2009, page 6.Simone Paolo Ponzetto and Michael Strube.
2006a.Exploiting semantic role labeling, WordNet andWikipedia for coreference resolution.
In HumanLanguage Technologies 2006: The Conference ofthe North American Chapter of the Association forComputational Linguistics; Proceedings of the MainConference, pages 192?199.Simone Paolo Ponzetto and Michael Strube.
2006b.Semantic role labeling for coreference resolution.
InProceedings of the 11th Conference of the EuropeanChapter of the Association for Computational Lin-guistics, pages 143?146.Simone Paolo Ponzetto and Michael Strube.
2007.Knowledge derived from Wikipedia for computingsemantic relatedness.
Journal of Artificial Intelli-gence Research, 30:181?212.Hoifung Poon and Pedro Domingos.
2008.
Joint unsu-pervised coreference resolution with Markov Logic.In Proceedings of the 2008 Conference on Empiri-cal Methods in Natural Language Processing, pages650?659.Andrei Popescu-Belis, Lo?
?s Rigouste, SusanneSalmon-Alt, and Laurent Romary.
2004.
Onlineevaluation of coreference resolution.
In Proceedingsof the 4th International Conference on LanguageResources and Evaluation, pages 1507?1510.Long Qiu, Min-Yen Kan, and Tat-Seng Chua.
2004.A public reference implementation of the RAPanaphora resolution algorithm.
In Proceedings ofthe 4th International Conference on Language Re-sources and Evaluation, pages 291?294.John Ross Quinlan.
1993.
C4.5: Programs for Ma-chine Learning.
Morgan Kaufmann, San Mateo,CA.Altaf Rahman and Vincent Ng.
2009.
Supervised mod-els for coreference resolution.
In Proceedings of the2009 Conference on Empirical Methods in NaturalLanguage Processing, pages 968?977.1409Marta Recasens and M. Anto?nia Mart??.
2009.
AnCora-CO: Coreferentially annotated corpora for Spanishand Catalan.
Language Resources and Evaluation,43(4).Marta Recasens, Toni Mart?
?, Mariona Taule?, Llu?
?sMa`rquez, and Emili Sapena.
2009.
SemEval-2010 Task 1: Coreference resolution in multiple lan-guages.
In Proceedings of the Workshop on Seman-tic Evaluations: Recent Achievements and FutureDirections (SEW-2009), pages 70?75.Candace Sidner.
1979.
Towards a Computational The-ory of Definite Anaphora Comprehension in EnglishDiscourse.
Ph.D. thesis, Massachusetts Institute ofTechnology, USA.Wee Meng Soon, Hwee Tou Ng, and Chung Yong Lim.1999.
Corpus-based learning for noun phrase coref-erence resolution.
In Proceedings of the 1999 JointSIGDAT Conference on Empirical Methods in Nat-ural Language Processing and Very Large Corpora,pages 285?291.Wee Meng Soon, Hwee Tou Ng, and DanielChung Yong Lim.
2001.
A machine learning ap-proach to coreference resolution of noun phrases.Computational Linguistics, 27(4):521?544.Veselin Stoyanov, Nathan Gilbert, Claire Cardie, andEllen Riloff.
2009.
Conundrums in noun phrasecoreference resolution: Making sense of the state-of-the-art.
In Proceedings of the Joint Conference ofthe 47th Annual Meeting of the ACL and the 4th In-ternational Joint Conference on Natural LanguageProcessing of the AFNLP, pages 656?664.Veselin Stoyanov, Claire Cardie, Nathan Gilbert, EllenRiloff, David Buttler, and David Hysom.
2010.Coreference resolution with Reconcile.
In Proceed-ings of the ACL 2010 Conference Short Papers.Michael Strube, Stefan Rapp, and Christoph Mu?ller.2002.
The influence of minimum edit distance onreference resolution.
In Proceedings of the 2002Conference on Empirical Methods in Natural Lan-guage Processing, pages 312?319.Michael Strube.
2002.
NLP approaches to referenceresolution.
In Tutorial Abstracts of ACL 2002, page124.Michael Strube.
2009.
Anaphernresolution.
In Com-puterlinguistik und Sprachtechnologie.
Eine Ein-fuhrung.
Springer, Heidelberg, Germany, 3rd edi-tion.Heike Telljohann, Erhard Hinrichs, and Sandra Ku?bler.2004.
The tu?ba-d/z treebank: Annotating Germanwith a context-free backbone.
In Proceedings ofthe 4th International Conference on Language Re-sources and Evaluation, pages 2229?2235.Joel Tetreault.
2005.
Empirical Evaluations ofPronoun Resolution.
Ph.D. thesis, University ofRochester, USA.Olga Uryupina.
2003.
High-precision identification ofdiscourse new and unique noun phrases.
In Proceed-ings of the ACL Student Research Workshop, pages80?86.Olga Uryupina.
2004.
Linguistically motivated sampleselection for coreference resolution.
In Proceedingsof the 5th Discourse Anaphora and Anaphor Reso-lution Colloquium.Kees van Deemter and Rodger Kibble.
2000.
On core-ferring: Coreference in MUC and related annotationschemes.
Computational Linguistics, 26(4):629?637.Yannick Versley, Alessandro Moschitti, Massimo Poe-sio, and Xiaofeng Yang.
2008a.
Coreference sys-tems based on kernels methods.
In Proceedingsof the 22nd International Conference on Computa-tional Linguistics, pages 961?968.Yannick Versley, Simone Paolo Ponzetto, MassimoPoesio, Vladimir Eidelman, Alan Jern, Jason Smith,Xiaofeng Yang, and Alessandro Moschitti.
2008b.BART: A modular toolkit for coreference resolution.In Proceedings of the ACL-08: HLT Demo Session,pages 9?12.Yannick Versley.
2006.
A constraint-based approachto noun phrase coreference resolution in Germannewspaper text.
In Konferenz zur VerarbeitungNatu?rlicher Sprache.Yannick Versley.
2007.
Antecedent selection tech-niques for high-recall coreference resolution.
InProceedings of the 2007 Joint Conference on Empir-ical Methods in Natural Language Processing andComputational Natural Language Learning, pages496?505.Renata Vieira and Massimo Poesio.
2000.
Process-ing definite descriptions in corpora.
In S. Botleyand A. McEnery, editors, Corpus-based and Compu-tational Approaches to Discourse Anaphora, pages189?212.
UCL Press.Marc Vilain, John Burger, John Aberdeen, Dennis Con-nolly, and Lynette Hirschman.
1995.
A model-theoretic coreference scoring scheme.
In Proceed-ings of the Sixth Message Understanding Confer-ence, pages 45?52.Marilyn Walker, Aravind Joshi, and Ellen Prince, edi-tors.
1998.
Centering Theory in Discourse.
OxfordUniversity Press.Holger Wunsch.
2010.
Rule-based and Memory-basedPronoun Resolution for German: A Comparison andAssessment of Data Sources.
Ph.D. thesis, Univer-sity of Tu?bingen, Germany.Xiaofeng Yang and Jian Su.
2007.
Coreference reso-lution using semantic relatedness information fromautomatically discovered patterns.
In Proceedingsof the 45th Annual Meeting of the Association forComputational Linguistics, pages 528?535.1410Xiaofeng Yang, Guodong Zhou, Jian Su, andChew Lim Tan.
2003.
Coreference resolution us-ing competitive learning approach.
In Proceedingsof the 41st Annual Meeting of the Association forComputational Linguistics, pages 176?183.Xiaofeng Yang, Jian Su, and Chew Lim Tan.
2004a.Improving noun phrase coreference resolution bymatching strings.
In Proceedings of the First In-ternational Joint Conference on Natural LanguageProcessing, pages 22?31.Xiaofeng Yang, Jian Su, GuoDong Zhou, andChew Lim Tan.
2004b.
An NP-cluster based ap-proach to coreference resolution.
In Proceedings ofthe 20th International Conference on ComputationalLinguistics, pages 226?232.Xiaofeng Yang, Jian Su, and Chew Lim Tan.
2005.Improving pronoun resolution using statistics-basedsemantic compatibility information.
In Proceedingsof the 43rd Annual Meeting of the Association forComputational Linguistics, pages 165?172.Xiaofeng Yang, Jian Su, and Chew Lim Tan.
2006.Kernel based pronoun resolution with structuredsyntactic knowledge.
In Proceedings of the 21st In-ternational Conference on Computational Linguis-tics and the 44th Annual Meeting of the Associationfor Computational Linguistics, pages 41?48.Xiaofeng Yang, Jian Su, Jun Lang, Chew Lim Tan,and Sheng Li.
2008a.
An entity-mention modelfor coreference resolution with inductive logic pro-gramming.
In Proceedings of ACL-08: HLT, pages843?851.Xiaofeng Yang, Jian Su, and Chew Lim Tan.
2008b.
Atwin-candidate model for learning-based anaphoraresolution.
Computational Linguistics, 34(3):327?356.Dmitry Zelenko, Chinatsu Aone, and Jason Tibbetts.2004.
Coreference resolution for information ex-traction.
In Proceedings of the ACL Workshop onReference Resolution and its Applications, pages 9?16.Shanheng Zhao and Hwee Tou Ng.
2007.
Identifica-tion and resolution of Chinese zero pronouns: A ma-chine learning approach.
In Proceedings of the 2007Joint Conference on Empirical Methods on Natu-ral Language Processing and Computational Natu-ral Language Learning, pages 541?550.GuoDong Zhou and Fang Kong.
2009.
Global learn-ing of noun phrase anaphoricity in coreference res-olution via label propagation.
In Proceedings of the2009 Conference on Empirical Methods in NaturalLanguage Processing, pages 978?986.1411
