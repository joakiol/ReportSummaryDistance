Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 278?282,Baltimore, Maryland, USA, June 23-25 2014.c?2014 Association for Computational LinguisticsHow to Speak a Language without Knowing ItXing Shi and Kevin KnightInformation Sciences InstituteComputer Science DepartmentUniversity of Southern California{xingshi, knight}@isi.eduHeng JiComputer Science DepartmentRensselaer Polytechnic InstituteTroy, NY 12180, USAjih@rpi.eduAbstractWe develop a system that lets people over-come language barriers by letting themspeak a language they do not know.
Oursystem accepts text entered by a user,translates the text, then converts the trans-lation into a phonetic spelling in the user?sown orthography.
We trained the sys-tem on phonetic spellings in travel phrase-books.1 IntroductionCan people speak a language they don?t know?Actually, it happens frequently.
Travel phrase-books contain phrases in the speaker?s language(e.g., ?thank you?)
paired with foreign-languagetranslations (e.g., ?
????????).
Since the speakermay not be able to pronounce the foreign-languageorthography, phrasebooks additionally providephonetic spellings that approximate the sounds ofthe foreign phrase.
These spellings employ the fa-miliar writing system and sounds of the speaker?slanguage.
Here is a sample entry from a Frenchphrasebook for English speakers:English: Leave me alone.French: Laissez-moi tranquille.Franglish: Less-ay mwah trahn-KEEL.The user ignores the French and goes straightto the Franglish.
If the Franglish is well designed,an English speaker can pronounce it and be under-stood by a French listener.Figure 1 shows a sample entry from anotherbook?an English phrasebook for Chinese speak-ers.
If a Chinese speaker wants to say ??????????
?, she need only read off theChinglish ????????????
?, whichapproximates the sounds of ?Thank you for thiswonderful meal?
using Chinese characters.Phrasebooks permit a form of accurate, per-sonal, oral communication that speech-to-speechFigure 1: Snippet from phrasebooktranslation devices lack.
However, the user is lim-ited to a small set of fixed phrases.
In this paper,we lift this restriction by designing and evaluatinga software program with the following:?
Input: Text entered by the speaker, in her ownlanguage.?
Output: Phonetic rendering of a foreign-language translation of that text, which, whenpronounced by the speaker, can be under-stood by the listener.The main challenge is that different languageshave different orthographies, different phonemeinventories, and different phonotactic constraints,so mismatches are inevitable.
Despite this, thesystem?s output should be both unambiguouslypronounceable by the speaker and readily under-stood by the listener.Our goal is to build an application that coversmany language pairs and directions.
The currentpaper describes a single system that lets a Chineseperson speak English.We take a statistical modeling approach to thisproblem, as is done in two lines of research that aremost related.
The first is machine transliteration(Knight and Graehl, 1998), in which names andtechnical terms are translated across languageswith different sound systems.
The other is re-spelling generation (Hauer and Kondrak, 2013),where an English speaker is given a phonetic hintabout how to pronounce a rare or foreign wordto another English speaker.
By contrast, we aim278Chinese ????
?English It?s eight o?clock nowChinglish ?????????
(yi si ai te e ke lao ke nao)Chinese ?????????
?English this shirt is very stylish and not very expensiveChinglish ???????????????????????
?Chinese ??????????15?
?English our minimum charge for delivery is fifteen dollarsChinglish ???????????????????
?Table 1: Examples of <Chinese, English, Chinglish> tuples from a phrasebook.to help people issue full utterances that cross lan-guage barriers.2 EvaluationOur system?s input is Chinese.
The output isa string of Chinese characters that approximateEnglish sounds, which we call Chinglish.
Webuild several candidate Chinese-to-Chinglish sys-tems and evaluate them as follows:?
We compute the normalized edit distancebetween the system?s output and a human-generated Chinglish reference.?
A Chinese speaker pronounces the system?soutput out loud, and an English listener takesdictation.
We measure the normalized editdistance against an English reference.?
We automate the previous evaluation by re-place the two humans with: (1) a Chinesespeech synthesizer, and (2) a English speechrecognizer.3 DataWe seek to imitate phonetic transformations foundin phrasebooks, so phrasebooks themselves are agood source of training data.
We obtained a col-lection of 1312 <Chinese, English, Chinglish>phrasebook tuples1(see Table 1).We use 1182 utterances for training, 65 for de-velopment, and 65 for test.
We know of no othercomputational work on this type of corpus.Our Chinglish has interesting gross empiricalproperties.
First, because Chinglish and Chineseare written with the same characters, they renderthe same inventory of 416 distinct syllables.
How-ever, the distribution of Chinglish syllables differs1Dataset can be found at http://www.isi.edu/natural-language/mt/chinglish-data.txta great deal from Chinese (Table 2).
Syllables ?si?and ?te?
are very popular, because while conso-nant clusters like English ?st?
are impossible to re-produce exactly, the particular vowels in ?si?
and?te?
are fortunately very weak.Frequency Rank Chinese Chinglish1 de si2 shi te3 yi de4 ji yi5 zhi fuTable 2: Top 5 frequent syllables in Chinese(McEnery and Xiao, 2004) and ChinglishWe find that multiple occurrences of an Englishword type are generally associated with the sameChinglish sequence.
Also, Chinglish characters donot generally span multiple English words.
It isreasonable for ?can I?
to be rendered as ?kan nai?,with ?nai?
spanning both English words, but thisis rare.4 ModelWe model Chinese-to-Chinglish translation witha cascade of weighted finite-state transducers(wFST), shown in Figure 2.
We use an onlineMT system to convert Chinese to an English wordsequence (Eword), which is then passed throughFST A to generate an English sound sequence(Epron).
FST A is constructed from the CMU Pro-nouncing Dictionary (Weide, 2007).Next, wFST B translates English sounds intoChinese sounds (Pinyin-split).
Pinyin is an officialsyllable-based romanization of Mandarin Chinesecharacters, and Pinyin-split is a standard separa-tion of Pinyin syllables into initial and final parts.Our wFST allows one English sound token to map279Figure 2: Finite-state cascade for modeling the re-lation between Chinese and Chinglish.to one or two Pinyin-split tokens, and it also allowstwo English sounds to map to one Pinyin-split to-ken.Finally, FST C converts Pinyin-split into Pinyin,and FST D chooses Chinglish characters.
We alsoexperiment with an additional wFST E that trans-lates English words directly into Chinglish.5 TrainingFSTs A, C, and D are unweighted, and remain sothroughout this paper.5.1 Phoneme-based modelWe must now estimate the values of FST B pa-rameters, such as P(si|S).
To do this, we firsttake our phrasebook triples and construct samplestring pairs <Epron, Pinyin-split> by pronounc-ing the phrasebook English with FST A, and bypronouncing the phrasebook Chinglish with FSTsD and C. Then we run the EM algorithm to learnFST B parameters (Table 3) and Viterbi align-ments, such as:g r ae n dg e r uan d e5.2 Phoneme-phrase-based modelMappings between phonemes are context-sensitive.
For example, when we decode English?grandmother?, we get:labeled Epron Pinyin-split P (p|e)d d 0.46d e 0.40d i 0.06s 0.01ao r u 0.26o 0.13ao 0.06ou 0.01Table 3: Learned translation tables for thephoneme based modelg r ae n d m ah dh erg e r an d e m u e d ewhere as the reference Pinyin-split sequence is:g e r uan d e m a d eHere, ?ae n?
should be decoded as ?uan?
whenpreceded by ?r?.
Following phrase-based meth-ods in statistical machine translation (Koehn etal., 2003) and machine transliteration (Finch andSumita, 2008), we model substitution of longer se-quences.
First, we obtain Viterbi alignments usingthe phoneme-based model, e.g.
:g r ae n d m ah dh erg e r uan d e m a d eSecond, we extract phoneme phrase pairs con-sistent with these alignments.
We use no phrase-size limit, but we do not cross word boundaries.From the example above, we pull out phrase pairslike:g?
g eg r?
g e r...r?
rr ae n?
r uan...We add these phrase pairs to FST B, and callthis the phoneme-phrase-based model.5.3 Word-based modelWe now turn to WFST E, which short-cuts di-rectly from English words to Pinyin.
We create<English, Pinyin> training pairs from our phrase-book simply by pronouncing the Chinglish withFST D. We initially allow each English word typeto map to any sequence of Pinyin, up to length 7,with uniform probability.
EM learns values for pa-rameters like P (nai te|night), plus Viterbi align-ments such as:280ModelTop-1 Overall Top-1 ValidCoverageAverage Edit Distance Average Edit DistanceWord based 0.664 0.042 29/65Word-based hybrid training 0.659 0.029 29/65Phoneme based 0.611 0.583 63/65Phoneme-phrase based 0.194 0.136 63/65Hybrid training and decoding 0.175 0.115 63/65Table 4: English-to-Pinyin decoding accuracy on a test set of 65 utterances.
Numbers are average editdistances between system output and Pinyin references.
Valid average edit distance is calculated basedonly on valid outputs (e.g.
29 outputs for word based model).accept tipsa ke sha pu te ti pu siNotice that this model makes alignment errorsdue to sparser data (e.g., the word ?tips?
and ?ti pusi?
only appear once each in the training data).5.4 Hybrid trainingTo improve the accuracy of word-based EM align-ment, we use the phoneme based model to de-code each English word in the training data toPinyin.
From the 100-best list of decodings, wecollect combinations of start/end Pinyin syllablesfor the word.
We then modify the initial, uniformEnglish-to-Pinyin mapping probabilities by givinghigher initial weight to mappings that respect ob-served start/end pairs.
When we run EM, we findthat alignment errors for ?tips?
in section 5.3 arefixed:accept tipsa ke sha pu te ti pu si5.5 Hybrid decodingThe word-based model can only decode 29 of the65 test utterances, because wFST E fails if an ut-terance contains a new English word type, pre-viously unseen in training.
The phoneme-basedmodels are more robust, able to decode 63 of the65 utterances, failing only when some Englishword type falls outside the CMU pronouncing dic-tionary (FST A).Our final model combines these two, using theword-based model for known English words, andthe phoneme-based models for unknown Englishwords.6 ExperimentsOur first evaluation (Table 4) is intrinsic, measur-ing our Chinglish output against references fromthe test portion of our phrasebook, using edit dis-tance.
Here, we start with reference English andmeasure the accuracy of Pinyin syllable produc-tion, since the choice of Chinglish character doesnot affect the Chinglish pronunciation.
We see thatthe Word-based method has very high accuracy,but low coverage.
Our best system uses the Hy-brid training/decoding method.
As Table 6 shows,the ratio of unseen English word tokens is small,thus large portion of tokens are transformed us-ing word-based method.
The average edit dis-tance of phoneme-phrase model and that of hy-brid training/decoding model are close, indicatingthat long phoneme-phrase pairs can emulate word-pinyin mappings.Unseen Total RatioWord Type 62 249 0.249Token 62 436 0.142Table 6: Unseen English word type and tokens intest data.ModelValid AverageEdit DistanceReference English 0.477Phoneme based 0.696Hybrid training and decoding 0.496Table 7: Chinglish-to-English accuracy in dicta-tion task.Our second evaluation is a dictation task.
Wespeak our Chinglish character sequence outputaloud and ask an English monolingual person totranscribe it.
(Actually, we use a Chinese synthe-sizer to remove bias.)
Then we measure edit dis-tance between the human transcription and the ref-erence English from our phrasebook.
Results areshown in Table 7.281Chinese ????????
?Reference English what do you have for the Reunion dinnerReference Chinglish ?????????????
?Hybrid training/decoding Chinglish ?????????????
?Dictation English what do you have for the reunion dinnerASR English what do you high for 43 Union CenaChinese ??
?Reference English wait for meReference Chinglish ????
(wei te fo mi)Hybrid training/decoding Chinglish ????
(wei te fo mi)Dictation English wait for meASR English wait for meTable 5: Chinglish generated by hybrid training and decoding method and corresponding recognizedEnglish by dictation and automatic synthesis-recognition method.ModelValid AverageEdit DistanceWord based 0.925Word-based hybrid training 0.925Phoneme based 0.937Phoneme-phrase based 0.896Hybrid training and decoding 0.898Table 8: Chinglish-to-English accuracy in auto-matic synthesis-recognition (ASR) task.
Numbersare average edit distance between recognized En-glish and reference English.Finally, we repeat the last experiment, but re-moving the human from the loop, using bothautomatic Chinese speech synthesis and Englishspeech recognition.
Results are shown in Table 8.Speech recognition is more fragile than humantranscription, so edit distances are greater.
Table 5shows a few examples of the Chinglish generatedby the hybrid training and decoding method, aswell as the recognized English from the dictationand ASR tasks.7 ConclusionsOur work aims to help people speak foreign lan-guages they don?t know, by providing native pho-netic spellings that approximate the sounds of for-eign phrases.
We use a cascade of finite-statetransducers to accomplish the task.
We improvethe model by adding phrases, word boundary con-straints, and improved alignment.In the future, we plan to cover more languagepairs and directions.
Each target language raisesinteresting new challenges that come from its nat-ural constraints on allowed phonemes, syllables,words, and orthography.ReferencesAndrew Finch and Eiichiro Sumita.
2008.
Phrase-based machine transliteration.
In Proceedings of theWorkshop on Technologies and Corpora for Asia-Pacific Speech Translation (TCAST), pages 13?18.Bradley Hauer and Grzegorz Kondrak.
2013.
Auto-matic generation of English respellings.
In Proceed-ings of NAACL-HLT, pages 634?643.Kevin Knight and Jonathan Graehl.
1998.
Ma-chine transliteration.
Computational Linguistics,24(4):599?612.Philipp Koehn, Franz Josef Och, and Daniel Marcu.2003.
Statistical phrase-based translation.
InProceedings of the 2003 Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics on Human Language Technology-Volume 1, pages 48?54.
Association for Computa-tional Linguistics.Anthony McEnery and Zhonghua Xiao.
2004.
Thelancaster corpus of Mandarin Chinese: A corpus formonolingual and contrastive language study.
Reli-gion, 17:3?4.R Weide.
2007.
The CMU pronunciation dictionary,release 0.7a.282
