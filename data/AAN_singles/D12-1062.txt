Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational NaturalLanguage Learning, pages 677?687, Jeju Island, Korea, 12?14 July 2012. c?2012 Association for Computational LinguisticsJoint Inference for Event Timeline ConstructionQuang Xuan Do Wei Lu Dan RothDepartment of Computer ScienceUniversity of Illinois at Urbana-ChampaignUrbana, IL 61801, USA{quangdo2,luwei,danr}@illinois.eduAbstractThis paper addresses the task of construct-ing a timeline of events mentioned in a giventext.
To accomplish that, we present a novelrepresentation of the temporal structure of anews article based on time intervals.
We thenpresent an algorithmic approach that jointlyoptimizes the temporal structure by couplinglocal classifiers that predict associations andtemporal relations between pairs of tempo-ral entities with global constraints.
Moreover,we present ways to leverage knowledge pro-vided by event coreference to further improvethe system performance.
Overall, our experi-ments show that the joint inference model sig-nificantly outperformed the local classifiers by9.2% of relative improvement in F1.
The ex-periments also suggest that good event coref-erence could make remarkable contribution toa robust event timeline construction system.1 IntroductionInferring temporal relations amongst a collection ofevents in a text is a significant step towards vari-ous important tasks such as automatic informationextraction and document comprehension.
Over thepast few years, with the development of the Time-Bank corpus (Pustejovsky et al2003) , there havebeen several works on building automatic systemsfor such a task (Mani et al2006; Chambers andJurafsky, 2008; Yoshikawa et al2009; Denis andMuller, 2011).Most previous works devoted much efforts to thetask of identifying relative temporal relations (suchas before, or overlap) amongst events (Chambers???|?t1|?t2|?t3?|t4|?+?|Time?
?I1I2I3e1e2e4e3/e5e7 ?
e6Figure 1: A graphical illustration of our timeline representation.The e?s, t?s and I?s are events, time points and time intervals,respectively.and Jurafsky, 2008; Denis and Muller, 2011), with-out addressing the task of identifying correct asso-ciations between events and their absolute time ofoccurrence.
Even if this issue is addressed, certainrestrictions are often imposed for efficiency reasons(Yoshikawa et al2009; Verhagen et al2010).
Inpractice, however, being able to automatically inferthe correct time of occurrence associated with eachevent is crucial.
Such information not only leads tobetter text comprehension, but also enables fusionof event structures extracted from multiple articlesor domains.In this work, we are specifically interested in map-ping events into an universal timeline representa-tion.
Besides inferring the relative temporal rela-tions amongst the events, we would also like to au-tomatically infer a specific absolute time of occur-rence for each event mentioned in the text.
Unlikeprevious work, we associate each event with a spe-cific absolute time interval inferred from the text.
Anexample timeline representation is illustrated in Fig.6771.
Further details of our timeline representation aregiven in Sec.
2.3.We perform global inference by combining a col-lection of local pairwise classifiers through the useof an Integer Linear Programming (ILP) formula-tion that promotes global coherence among local de-cisions.
The formulation allows our model to pre-dict both event-event relations and event-time inter-val associations simultaneously.
We show that, withthe use of time intervals instead of time points, ourapproach leads to a more concise ILP formulationwith reduced number of variables and constraints.Moreover, we observed that event coreference canreveal important information for such a task.
Wepropose that different event mentions that refer tothe same event can be grouped together before clas-sification and performing global inference.
This canreduce the amount of efforts in both classificationand inference stages and can potentially eliminatemistakes that would be made otherwise without suchcoreference information.
To the best of our knowl-edge, our proposal of leveraging event coreferenceto support event timeline construction is novel.Our experiments on a collection of annotatednews articles from the standard ACE dataset demon-strate that our approach produces robust timelines ofevents.
We show that our algorithmic approach isable to combine various local evidences to producea global coherent temporal structure, with improvedoverall performance.
Furthermore, the experimentsshow that the overall performance can be further im-proved by exploiting knowledge from event corefer-ence.2 BackgroundWe focus on the task of mapping event mentions ina news article to a timeline.
We first briefly describeand define several basic concepts.2.1 EventsFollowing the annotation guidelines of the ACEproject, we define an event as an action or occur-rence that happens with associated participants orarguments.
We also distinguish between events andevent mentions, where a unique event can be core-ferred to by a set of explicit event mentions in anarticle.
Formally, an event Ei is co-referred to bya set of event mentions (ei1, ei2, .
.
.
, eik).
Each eventmention e can be written as p(a1, a2, .
.
.
, al), wherethe predicate p is the word that triggers the presenceof e in text, and a1, a2, .
.
.
al are the arguments asso-ciated with e. In this work we focus on four tempo-ral relations between two event mentions includingbefore, after, overlap and no relation.2.2 Time IntervalsSimilar to Denis and Muller (2011), we define timeintervals as pairs of time endpoints.
Each time in-terval I is denoted by [t?, t+], where t?
and t+ aretwo time endpoints representing the lower and upperbound of the interval I , respectively, with t?
?
t+.The general form of a time endpoint is written as?YYYY-MM-DD hh:mm:ss?.
An endpoint can be un-defined, in which case it is set to an infinity value:?
?, or +?.
There are two types of time intervals:Explicit intervals are time intervals that can beextracted directly from a given text.
For example,consider the following snippet of an article in ourdata set: The litigation covers buyers in auctionsoutside the United States between January 1, 1993and February 7, 2000.
In this example, we can ex-tract and normalize two time intervals which are ex-plicitly written, including January 1, 1993?
[1993-01-01 00:00:00, 1993-01-01 23:59:59] and Febru-ary 7, 2000 ?
[2000-02-07 00:00:00, 2000-02-0723:59:59].
Moreover, an explicit interval can alsobe formed by one or more separate explicit temporalexpressions.
In the example above, the connectiveterm between relates the two expressions to form asingle time interval: between January 1, 1993 andFebruary 7, 2000 ?
[1993-01-01 00:00:00, 2000-02-07 23:59:59].
To extract explicit time intervalsfrom text, we use the time interval extractor de-scribed in Zhao et al2012).Implicit intervals are time intervals that are notexplicitly mentioned in the text.
We observed thatthere are events that cannot be assigned to any pre-cise time interval but are roughly known to occurin the past or in the future relative to the Doc-ument Creation Time (DCT) of the article.
Weintroduce two implicit time intervals to representthe past and the future events as (?
?, t?DCT ] and[t+DCT ,+?
), respectively.
In addition, we also al-low an event mention to be assigned into the entiretimeline, which is denoted by (??,+?)
if we can-678not identify its time of occurrence.
We also considerDCT as an implicit interval.We say that the time interval Ii precedes the timeinterval Ij on a timeline if and only if t+i ?
t?j ,which also implies that Ii succeeds Ij if and only ift?i ?
t+j .
The two intervals overlap, otherwise.2.3 TimelineWe define a timeline as a partially ordered set of timeintervals.
Fig.
1 gives a graphical illustration of anexample timeline, where events are annotated andassociated with time intervals.
Relations amongstevents can be properly reflected in the timeline rep-resentation.
For example, in the figure, the events e1and e2 are both associated with the interval I1.
Therelation between them is no relation, since it is un-clear which occurs first.
On the other hand, e5 ande3 both happen in the interval I2 but they form anoverlap relation.
The events e6 and e7 occur withinthe same interval I3, but e7 precedes (i.e.
before) e6on the timeline.
The event e4 is associated with theinterval (??,+?
), indicating there is no knowl-edge about its time of occurrence.We believe that such a timeline representationfor temporally ordering events has several advan-tages over the temporal graph representations usedin previous works (Chambers and Jurafsky, 2008;Yoshikawa et al2009; Denis and Muller, 2011).Unlike previous works, in our model the events arepartially ordered in a single timeline, where eachevent is associated with a precise time interval.
Thisimproves human interpretability of the temporal re-lations amongst events and time.
This property ofour timeline representation, thus, facilitates merg-ing multiple timelines induced from different arti-cles.
Furthermore, as we will show later, the useof time intervals within the timeline representationsimplifies the global inference formulation and thusthe inference process.3 A Joint Timeline ModelOur task is to induce a globally coherent timelinefor a given article.
We thus adopt a global infer-ence model for performing the task.
The modelconsists of two components: (1) two local pairwiseclassifiers, one between event mentions and time in-tervals (the E?T classifier) and one between eventmentions themselves (the E?E classifier), and (2)a joint inference module that enforces global co-herency constraints on the final outputs of the twolocal classifiers.
Fig.
2 shows a simplified temporalstructure of event mentions and time intervals of anarticle in our model.Our E?T classifier is different from previouswork (Chambers and Jurafsky, 2008; Yoshikawa etal., 2009; Denis and Muller, 2011), where such clas-sifiers were trained to identify temporal relations be-tween event mentions and a temporal expression.
Inour work, in order to construct absolute timeline ofevent mentions, temporal expressions are capturedand normalized as absolute time intervals.
The E?Tclassifiers are then used to assign event mentions totheir contextually corresponding time intervals.We also lifted several restrictions imposed in pre-vious work (Bethard et al2007; Yoshikawa et al2009; Verhagen et al2010).
Specifically, we donot require that event mentions and time expressionshave to appear in the same sentence, and we do notrequire two event mentions have to appear very closeto each other (e.g., main event mentions in adjacentsentences) in order to be considered as candidatepairs for classification.
Instead, we performed clas-sifications over all pairs of event mentions and timeintervals as well as over all pairs of event mentions.We show through experiments that lifting these re-strictions is indeed important (see Sec.
5).Another important improvement over previouswork is our global inference model We would liketo highlight that our work is also distinct from mostprevious works in the global inference component.Specifically, our global inference model jointly op-timizes the E-E relations amongst event mentionsand their associations, E-T, with temporal informa-tion (intervals in our case).
Previous work (Cham-bers and Jurafsky, 2008; Denis and Muller, 2011),on the other hand, assumed that the E-T informationis given and only tried to improve E-E.3.1 The Pairwise ClassifiersWe first describe our local classifiers that associateevent mention with time interval and classify tempo-ral relations between event mentions, respectively.CE?T : is the E?T classifier that associates anevent mention with a time interval.
Given an eventmention and a time interval, the classifier predicts679e1e2e3e4en-1ene5?
?
?I1I2I3Im?
?
?Figure 2: A simplified temporal structure of an article.
Thereare m time intervals I1 ?
?
?
Im and n event mentions e1 ?
?
?
en.A solid edge indicates an association between an interval andan event mention, whereas a dash edge illustrates a temporalrelation between two event mentions.whether the former associates with the latter.CE?T (ei, Ij)?
{0, 1},?i, j, 1 ?
i ?
n, 1 ?
j ?
m, (1)where n and m are the number of event mentionsand time intervals in an article, respectively.CE?E : is the E?E classifier that identifiesthe temporal relation between two event mentions.Given a pair of event mentions, the classifier predictsone of the four temporal relations between them:b?efore, a?fter, o?verlap and n?o relation.
Specifically:CE?E(ei, ej)?
{b?, a?, o?, n?
},?i, j, 1 ?
i, j ?
n, i 6= j, (2)For training of the classifiers, we define a set offeatures following some previous work (Bethard etal., 2007; Chambers and Jurafsky, 2008; Yoshikawaet al2009), together with some additional featuresthat we believe to be helpful for the interval-basedrepresentation.
We describe the base features belowand use ?
and ?
to denote the features used for CE?Tand CE?E , respectively.
We use the term temporalentity (or entity, for short) to refer to either an eventmention or a time interval.Lexical Features: A set of lexical features relatedto the temporal entities: (i)??
the word, lemma andpart-of-speech of the input event mentions and thecontext surrounding them, where the context is de-fined as a window of 2 words before and after themention; (ii)?
the modal verbs to the left and to theright of the event mention; (iii)?
the temporal con-nectives between the event mentions1.1We define a list of temporal connectives including before,after, since, when, meanwhile, lately, etc.Syntactic Features: (i)??
which entity appearsfirst in the text; (ii)??
whether the two entities appearin the same sentence; (iii)??
the quantized number ofsentences between the two entities2; (iv)??
whetherthe input event mentions are covered by preposi-tional phrases and what are the heads of the phrases;(v)??
if the entities are in the same sentence, what istheir least common constituent on the syntactic parsetree; (vi)?
whether there is any other temporal entitythat is closer to one of the two entities.Semantic Features?
: A set of semantic features,mostly related to the input event mentions: (i)whether the input event mentions have a commonsynonym from their synsets in WordNet (Fellbaum,1998); (ii) whether the input event mentions have acommon derivational form derived from WordNet.Linguistic Features??
: The tense and the aspectof the input event mentions.
We use an in-houserule-based recognizer to extract these features.Time Interval Features?
: A set of features re-lated to the input time interval: (i) whether theinterval is implicit; (ii) if it is implicit, identifyits interval type: ?dct?
= [t?DCT , t+DCT ], ?past?
=(?
?, t?DCT ], ?feature?
= [t+DCT ,+?
), and ?en-tire?
= (??,+?
); (iii) the interval is before, afteror overlapping with the DCT.We note that unlike many previous work (Mani etal., 2006; Chambers and Jurafsky, 2008; Denis andMuller, 2011), our classifiers do not use any goldannotations of event attributes (event class, tense, as-pect, modal and polarity) provided in the TimeBankcorpus as features.In our work, we use a regularized averaged Per-ceptron (Freund and Schapire, 1999) as our classifi-cation algorithm3.
We used the one-vs.-all schemeto transform a set of binary classifiers into a multi-class classifier (for CE?E).
The raw predictionscores were converted into probability distributionusing the Softmax function (Bishop 1996).
If thereare n classes and the raw score of class i is acti, theposterior estimation for class i is:P?
(i) =eacti?1?j?n eactj2We quantize the number of sentences between two entitiesto 0, 1, 2, less than 5 and greater than or equal to 53Other algorithm (e.g.
SVM) gave comparable or worse re-sults, so we only show the results from Averaged Perceptron.6803.2 Joint Inference for Event TimelineTo exploit the interaction among the temporal enti-ties in an article, we optimize the predicted tempo-ral structure, formed by predictions from CE?T andCE?E , w.r.t.
a set of global constraints that enforcecoherency on the final structure.
We perform exactinference using Integer Linear Programming (ILP)as in (Roth and Yih, 2007; Clarke and Lapata, 2008).We use the Gurobi Optimizer4 as a solver.Let I = {I1, I2, .
.
.
, Im} denote the set of timeintervals extracted from an article, and let E ={e1, e2, .
.
.
, en} denote all event mentions in thesame article.
Let EI = {(ei, Ij) ?
E ?
I|ei ?E , Ij ?
I} denote the set of all pairs of eventmentions and time intervals.
We also denote theset of event mention pairs by EE = {(ei, ej) ?E ?
E|ei ?
E , ej ?
E , i 6= j}.
The prediction prob-ability of an association of a pair eI ?
EI, givenby classifier CE?T , is denoted by p?eI,1?5.
Now, letR = {b?, a?, o?, n?}
be the set of temporal relations be-tween two event mentions.
The prediction proba-bility of an event mention pair ee ?
EE that takestemporal relation r, given by CE?E , is denoted byp?ee,r?.
Furthermore, we define x?eI,1?
to be a binaryindicator variable that takes on the value 1 iff an as-sociation is predicted between e and I .
Similarly,we define a binary indicator variable y?ee,r?
of a pairof event mentions ee that takes on the value 1 iff eeis predicted to hold the relation r.The objective function is then defined as a linearcombination of the prediction probabilities from thetwo local classifiers as follows:arg maxx,y[??eI?EIp?eI,1?
?
x?eI,1?+ (1?
?)?ee?EE?r?Rp?ee,r?
?
y?ee,r?
](3)subject to the following constraints:x?eI,1?
?
{0, 1}, ?eI ?
EI (4)y?ee,r?
?
{0, 1}, ?ee ?
EE , r ?
R (5)?r?Ry?ee,r?
= 1, ?ee ?
EE (6)4http://gurobi.com/5This value is complementary to the non-association proba-bility, denoted by p?eI,0?
= 1?
p?eI,1?We use the single parameter ?
to balance the over-all contribution of two components E-T and E-E.?
is determined through cross validation tuning ona development set.
We use (4) and (5) to make surex?eI,1?
and y?ee,r?
are binary values.
The equalityconstraint (6) ensures that exactly one particular re-lation can be assigned to each event mention pair.In addition, we also require that each event is as-sociated with only one time interval.
These con-straints are encoded as follows:?I?Ix?eI,1?
= 1, ?e ?
E (7)Our model also enforces reflexivity and transitiv-ity constraints on the relations among event men-tions as follows:y?eiej ,r?
?
y?ejei,r??
= 0,?eiej = (ei, ej) ?
EE , i 6= j (8)y?eiej ,r1?
+ y?ejek,r2?
?
y?eiek,r3?
?
1,?eiej , ejek, eiek ?
EE , i 6= j 6= k (9)The equality constraints in (8) encode reflexiveproperty of event-event relations, where the rela-tion r?
denotes the inversion of the relation r. Theset of possible (r, r?)
pairs is defined as follows:{(b?, a?
), (a?, b?
), (o?, o?
), (n?, n?)}.
Following the workof (Bramsen et al2006; Chambers and Jurafsky,2008), we encode transitive closure of relations be-tween event mentions with inequality constraints in(9), which states that if the pair (ei, ej) has a certainrelation r1, and the pair (ej , ek) has the relation r2,then the relation r3 must be satisfied between ei andek.
Examples of such triple (r1, r2, r3) include (b?, b?,b?)
and (a?, a?, a?
).Finally, to capture the interactions between ourlocal pairwise classifiers we add the following con-straints:x?eiIk,1?
+ x?ejIl,1?
?
y?eiej ,b??
?
1,?eiIk, ejIl ?
EI, ?eiej ?
EE ,Ik precedes Il, i 6= j, k 6= l (10)Intuitively, the inequality constraints in (10) spec-ify that a temporal relation between two event men-tions can be inferred from their respective associated681time intervals.
Specifically, if two event mentions eiand ej are associated with two time intervals Ik andIl respectively, and Ik precedes Il in the timeline,then ei must happen before ej .It is important to note that our interval-based for-mulation is more concise in terms of the number ofvariables and constraints needed in the ILP relativeto time expression-based (or timepoint-based) for-mulations used in previous work (Chambers and Ju-rafsky, 2008).
Specifically, in such timepoint-basedformulations, the relation between each event men-tion and each time expression needs to be inferred,resulting in |E||T ||RT | variables, where |E|, |T |,and |RT | are the numbers of event mentions, timepoints, and temporal relations respectively.
In con-trast, only |E||I| variables are required in our for-mulation, where |I| is the number of intervals (sincewe extract intervals explicitly, |I| is roughly equalto |T |).
Furthermore, performing inference with thetimepoint-based formulation would require |E||T |equality constraints to enforce that each event men-tion can take only one relation inRT for a particulartime point, whereas our interval-based model onlyrequires |E| constraints, since each event is strictlyassociated with one interval (see Eqn.
(7)).
We jus-tify the benefits of our formulation later in Sec.
5.4.4 Incorporating Knowledge from EventCoreferenceOne of the key contributions of our work is usingevent coreference information to enhance the time-line construction performance.
This is motivated bythe following two principles:(P1) All mentions of a unique event are associ-ated with the same time interval, and overlap witheach other.
(P2) All mentions of an event have the same tem-poral relation with all mentions of another event.The example below, extracted from an article pub-lished on 03/11/2003 in the Automatic Content Ex-traction (ACE), 2005, corpus6 serves to illustrate thesignificance of event coreference to our task.6http://www.itl.nist.gov/iad/mig/tests/ace/2005/The world?s most powerful fine art auction houses,Sotheby?s and Christie?s, have agreed to [e11 =pay] 40 million dollars to settle an internationalprice-fixing scam, Sotheby?s said.
The [e12 = pay-ment], if approved by the courts, would settle aslew of [e21 = suits] by clients over auctions heldbetween 1993 and 2000 outside the US.
... Sotheby?sand Christie?s will each [e13 = pay] 20 million dol-lars,?
said Sotheby?s, which operates in 34 countries.In this example, there are 4 event mentions, whosetrigger words are highlighted in bold face.
The un-derlined text gives an explicit time interval: I1 =[1993-01-01 00:00:00, 2000-12-31 23:59:59] (weignore 2 other intervals given by 1993 and 2000to simplify the illustration).
Now if we considerthe event mention e12, it actually belongs to the im-plicit future interval I2 = [2003-03-11 23:59:59,+?).
Nevertheless, there is a reasonable chancethat CE?T associates it with I1, given that they bothappear in the same sentence, and there is no di-rect evident feature indicating the event will actu-ally happen in the future.
In such a situation, usinga local classifier to identify the correct temporal as-sociation could be challenging.Fortunately, precise knowledge from event coref-erence may help alleviate such a problem.
Theknowledge reveals that the 4 event mentions can begrouped into 2 distinct events: E1 = {e11, e12, e13},E2 = {e21}.
If CE?T can make a strong predictionin associating the event mention e11 (or e13) to I2, in-stead of I1, the system will have a high chance tore-assign e12 to I2 based on principle (P1).
Similarly,if CE?E is effective in figuring out that some men-tion of event E1 occurs after some mention of E2,then all the mentions of E1 would be predicted tooccur after all mentions in E2 according to (P2).To incorporate knowledge from event coreferenceinto our classifiers and the joint inference model, weuse the following procedure: (1) performing classi-fication with CE?T and CE?E on the data, (2) usingthe knowledge from event coreference to overwritethe prediction probabilities obtained by the two lo-cal classifiers in step (1), and (3) applying the jointinference model on the new prediction probabilitiesobtained from (2).
We note that if we stop at step (2),we get the outputs of the local classifiers enhancedby event coreference knowledge.To overwrite the classification probabilities using682event coreference knowledge, we propose two ap-proaches as follows:MaxScore: We define the probability betweenany mention e ?
Ei and an interval I as follows:p?eI,1?
= maxe??EiP?
(e?, I) (11)where P?
(e?, I) is the classifier (CE?T ) probabilityfor associating event mention e?
to the time interval.On the other hand, the probabilities for associat-ing the set of temporal relations, R, to each pair ofmentions in Ei?Ej , is given by the following pair:(ei, ej)?
= arg max(ei?
,ej?
)?Ei?Ej ,r?RP?
((ei?, ej?
), r))p?ee,r?
= P?
((ei, ej)?, r),?r ?
R (12)In other words, over all possible event mentionpairs and relations, we first pick the pair who glob-ally obtains the highest probability for some rela-tion.
Next, we simply take the probability distri-bution of that event mention pair as the distributionover the relations, for the event pair.SumScore: The probability between any mentione ?
Ei and an interval I is obtained by:p?eI,1?
=1|Ei|?e??EiP?
(e?, I) (13)To obtain the probability distribution over the setof temporal relations,R, for any pair of mentions inEi ?
Ej , we used the following procedure:r?
= arg maxr?R?ei?Ei?ej?EjP?
((ei, ej), r)(ei, ej)?
= arg max(ei?
,ej?
)?Ei?EjP?
((ei?, ej?
), r?)p?ee,r?
= P?
((ei, ej)?, r),?r ?
R (14)In other words, given two groups of event men-tions, we first compute the total score of each rela-tion, and select the relation which has the highestscore.
Next from the list of pairs of event mentionsfrom the two groups, we select the pair which has therelation r* with highest score compared to all otherpairs.
The probability distribution of this pair willbe used as the probability distribution of all eventmention pairs between the two events.In both approaches, we assign the overlap rela-tions to all pairs of event mentions in the same eventwith probability 1.0.5 Experimental StudyWe first describe the experimental data and thenpresent and discuss the experimental results.5.1 Data and SetupMost previous works in temporal reasoning usedthe TimeBank corpus as a benchmark.
The cor-pus contains a fairly diverse collection of anno-tated event mentions, without any specific focus oncertain event types.
According to the annotationguideline of the corpus, most of verbs, nominal-izations, adjectives, predicative clauses and preposi-tional phrases can be tagged as events.
However, inpractice, when performing temporal reasoning aboutevents in a given text, one is typically interested insignificant and typed events, such as Killing, Leg-islation, Election.
Furthermore, event mentions inTimeBank are annotated with neither event argu-ments nor event coreference information.We noticed that the ACE 2005 corpus contains theannotation that we are interested in.
The corpus con-sists of articles annotated with event mentions (withevent triggers and arguments) and event coreferenceinformation.
To create an experimental data set forour work, we selected from the corpus 20 newswirearticles published in March 2003.
To extract timeintervals from the articles, we used the time inter-val extractor described in (Zhao et al2012) withminimal post-processing.
Implicit intervals are alsoadded according to Sec.
2.2.
We then hired an anno-tator with expertise in the field to annotate the datawith the following information: (i) event mentionand time interval association, and (ii) the temporalrelations between event mentions, including {b?, a?,o?}.
The annotator was not required to annotate allpairs of event mentions, but as many as possible.Next, we saturated the relations based on the ini-tial annotations as follows: (i) event mentions thathad not been associated with any time intervals wereassigned to the entire timeline interval (??,+?
),and (ii) added inferred temporal relations betweenevent mentions with reflectivity and transitivity.
Ta-ble 1 shows the data statistics before and after sat-uration.
There are totally 8312 event pairs from 20documents, including no relation pairs.
We note thatin a separate experiment, we still evaluated CE?Eon the TimeBank corpus and got better performance683Data #Intervals #E-mentions #E-T #E-EInitial 232 324 305 376Saturated 232 324 324 5940Table 1: The statistics of our experimental data set.than a corresponding classifier in an existing work(see Sec.
5.4).We conducted all experiments with 5-fold crossvalidation at the instance level on our data set aftersaturation.
The global inference model was appliedon a whole document.
The results of the systems arereported in averaged precision, recall and F1 scoreon the association performance, for CE?T , and thetemporal relations (we excluded the n?
relation, forCE?E).
We also measured the overall performanceof the systems by computing the average of the per-formance of the classifiers.5.2 A BaselineWe developed a baseline system that works as fol-lows.
It associates an event mention with the closesttime interval found in the same sentence.
If suchan interval is not found, the baseline associates themention with the closest time interval to the left.If the interval is again not found, the mention willbe associated with the DCT interval.
The baselineis based on the intuition of natural reading order:events that are mentioned earlier are likely to pre-cede those mentioned later.
For the temporal rela-tion between a pair of event mentions, the baselinetreats the event mention that appears earlier in thetext as temporally happening before the other men-tion.
The baseline performance is shown in the firstgroup of results in Table 2.5.3 Our SystemsFor our systems, we first evaluated the performanceof our local pairwise classifiers and the global in-ference model.
The second group of results in Ta-ble 2 shows the systems?
performance.
Overall,the results show that our global inference modelrelatively outperformed the baseline and the localclassifiers by 57.8% and 9.2% in F1, respectively.We perform a bootstrap resampling significance test(Koehn, 2004) on the output predictions of the lo-cal classifiers with and without the inference model.The test shows that the overall improvement withthe inference model is statistically significant (p <0.01).
This indicates the effectiveness of our jointinference model with global coherence constraints.Next, we integrated event coreference knowledgeinto our systems (as described in Sec.
4) and eval-uated their performance.
Our experiments showedthat the SumScore approach works better for CE?T ,while MaxScore is more suitable for CE?E .
Our ob-servations showed that event mentions of an eventmay appear in close proximity with multiple timeintervals in the text, making CE?T produce highprediction scores for many event mention-intervalpairs.
This, consequently, confuses MaxScore onthe best association of the event and the time inter-vals, whereas SumScore overcomes the problem byaveraging out the association scores.
On the otherhand, CE?E gets more benefit from MaxScore be-causeCE?E works better on pairs of event mentionsthat appear closely in the text, which activate morevaluable learning features.
We will report the resultsusing the best approach of each classifier.To evaluate our systems with event coreferenceknowledge, we first experimented our systems withgold event coreference as given by the ACE 2005corpus.
Table 2 shows the contribution of eventcoreference to our systems in the third group of theresults.
The results show that injecting knowledgefrom event coreference remarkably improved boththe local classifiers and the joint inference model.Overall, the system that combined event corefer-ence and the global inference model achieved thebest performance, which significantly overtook allother compared systems.
Specifically, it outper-formed the baseline system, the local classifiers, andthe joint inference model without event coreferencewith 80%, 25%, and 14% of relative improvement inF1, respectively.
It also consistently outperformedthe local classifiers enhanced with event corefer-ence.
We note that the precision and recall of CE?Tin the joint inference model are the same becausethe inference model enforced each event mention tobe associated with exactly one time interval.
Thisis also true for the systems integrated with eventcoreference because our integration approaches as-sign only one time interval to an event mention.We next move to experimenting with automati-cally learned event coreference systems.
In this ex-684ModelCE?T CE?E OverallPrec.
Rec.
F1 Prec.
Rec.
F1 Prec.
Rec.
F11 Baseline 33.29 33.29 33.29 20.86 32.81 25.03 27.06 33.05 29.162No Event Coref.Local classifiers 62.70 34.50 43.29 40.46 42.42 40.96 51.58 38.46 42.13Global inference 47.88 47.88 47.88 41.42 48.04 44.14 44.65 47.96 46.013With Gold Event Coref.Local classifiers 50.88 50.88 50.88 43.86 52.65 47.46 47.37 51.77 49.17Global inference 50.88 50.88 50.88 48.04 62.45 54.05 49.46 56.67 52.474With Learned Event Coref.Local classifiers 46.37 46.37 46.37 40.83 45.28 42.60 43.60 45.83 44.49Global inference 46.37 46.37 46.37 42.09 52.50 46.47 44.23 49.44 46.42Table 2: Performance under various evaluation settings.
All figures are averaged scores from 5-fold cross-validation experiments.periment, we re-trained the event coreference sys-tem described in Chen et al2009) on all arti-cles in the ACE 2005 corpus, excluding the 20 ar-ticles used in our data set.
The performance of thesesystems are shown in the fourth group of the re-sults in Table 2.
The results show that by using alearned event coreference system, we achieved thesame improvement trends as with gold event coref-erence.
However, we did not obtain significant im-provement when comparing with global inferencewithout event coreference information.
This resultshows that the performance of an event coreferencesystem can have a significant impact on the over-all performance.
While this suggests that a betterevent coreference system could potentially help thetask more, it also opens the question whether eventcoreference can be benefited from our local classi-fiers through the use of a joint inference framework.We would like to leave this for future investigations.5.4 Previous Work-Related ExperimentsWe also performed experiments using the same set-ting as in (Yoshikawa et al2009), which followedthe guidelines of the TempEval challenges (Verha-gen et al2007; Verhagen et al2010), on our sat-urated data.
Several assumptions were made to sim-plify the task.
For example, only main events inadjacent sentences are considered when identifyingevent-event relations.
See (Yoshikawa et al2009)for more details.
We performed 5-fold cross valida-tion without event coreference.
Overall, the systemachieved 29.99 F1 for the local classifiers and 34.69when the global inference is used.
These results arebetter than the baseline but underperform our fullmodels where those simplification assumptions arenot imposed, as shown in Table 2, indicating the im-portance of relaxing their assumptions in practice.We also evaluated our CE?E on the TimeBankcorpus.
We followed the settings of Chambers andJurafsky (2008) to extract all event mention pairsthat were annotated with before (or ibefore, ?imme-diately before?)
and after (or iafter) relations in 183news articles in the corpus.
We trained and evalu-ated ourCE?E on these examples with the same fea-ture set that we evaluated in our experiments above,with gold tense and aspect features but without eventtype.
Following their work, we performed 10-foldcross validation.
Our classifier achieved a micro-averaged accuracy of 73.45%, whereas Chambersand Jurafsky (2008) reported 66.8%.
We next in-jected the knowledge of an event coreference sys-tem trained on the ACE2005 corpus into our CE?E ,and obtained a micro-averaged accuracy of 73.39%.It was not surprising that event coreference did nothelp in this dataset because: (i) different domains?
the event coreference was trained on ACE 05 butapplied on TimeBank, and (ii) different annotationguidelines on events in ACE 2005 and TimeBank.Finally, we conducted an experiment that justi-fies the advantages of our interval-based inferencemodel over a time point-based inference.
To do this,we first converted our data in Table 1 from inter-vals to time points and infer the temporal relationsbetween the annotated event mentions and the timepoints: before, after, overlap, and unknown.
Wemodified the first component in the objective func-tion in (3) to accommodate these temporal relations.We also made several changes to the constraints,including removing those in (7) since they are nolonger required, and adding constraints that ensure685the relation between a time point and an event men-tion takes exactly one value.
Proper changes werealso made to other constraints in (10) to reflect thefact that time points are considered rather than inter-vals.
We observed that experiment with such a for-mulation was unable to finish within 5 hours (we ter-minated the ILP inference after waiting for 5 hours),whereas our interval-based model finished the ex-periment with an average of 21 seconds per article.6 Related WorkResearch in temporal reasoning recently receivedmuch attention.
Allen (1983) introduced an intervalbased temporal logic which has been used widelyin the field.
Recent efforts in building an annotatedtemporal corpus (Pustejovsky et al2003) has pop-ularized the use of machine learning techniques forthe task (Mani et al2006; Bethard et al2007).This corpus was later used (with simplifications) intwo TempEval challenges (Verhagen et al2007;Verhagen et al2010).
In these challenges, severaltemporal-related tasks were defined including thetasks of identifying the temporal relation between anevent mention and a temporal expression in the samesentence, and recognizing temporal relations of pairsof event mentions in adjacent sentences.
However,with several restrictions imposed to these tasks, thedeveloped systems were not practical.Recently, there has been much work attemptingto leverage Allen?s interval algebra of temporal re-lations to enforce global constraints on local pre-dictions.
The work of Tatu and Srikanth (2008)used global relational constraints to not only expandthe training data but also identifies temporal incon-sistencies to improve local classifiers.
They usedgreedy search to select the most appropriate config-uration of temporal relations among events and tem-poral expressions.
For exact inferences, Bramsen etal.
(2006), Chambers and Jurafsky (2008), Denisand Muller (2011), and Talukdar et al2012) for-mulated the temporal reasoning problem in an ILP.However, the inference models in their work werenot a joint model involving multiple local classifiersbut only one local classifier was involved in their ob-jective functions.The work of Yoshikawa et al2009) did formu-late a joint inference model with Markov Logic Net-work (MLN).
They, however, used the same settingas the TempEval challenges, thus only pairs of tem-poral entities in the same or adjacent sentences areconsidered.
Our work, on the other hand, focuses onconstructing an event timeline with time intervals,taking multiple local pairwise predictions into a jointinference model and removing the restrictions on thepositions of the temporal entities.
Furthermore, wepropose for the first time to use event coreferenceand evaluate the importance of its role in the task ofevent timeline construction.7 Conclusions and Future WorkWe proposed an interval-based representation of thetimeline of event mentions in an article.
Our rep-resentation allowed us to formalize the joint infer-ence model that can be solved efficiently, comparedto a time point-based inference model, thus open-ing up the possibility of building more practicalevent temporal inference systems.
Our inferencemodel achieved significant improvement over the lo-cal classifiers.
We also showed that event coref-erence can naturally support timeline construction,and good event coreference led to significant im-provement in the system performance.
Specifically,when such gold event coreference knowledge wasinjected into the model, a significant improvementin the overall performance could be obtained.
Whileour experiments suggest that the temporal classi-fiers can potentially help enhance the performanceof event coreference, in future work we would liketo investigate into coupling event coreference withother components in a global inference framework.AcknowledgmentsThe authors gratefully acknowledge the supportof Defense Advanced Research Projects Agency(DARPA) Machine Reading Program under AirForce Research Laboratory (AFRL) prime contractNo.
FA8750-09-C-0181, and the Army ResearchLaboratory (ARL) under agreement W911NF-09-2-0053.
The first author also thanks the Vietnam Ed-ucation Foundation (VEF) for its sponsorship.
Anyopinions, findings, and conclusion or recommenda-tions expressed in this material are those of the au-thors and do not necessarily reflect the view of theVEF, DARPA, AFRL, ARL, or the US government.686ReferencesJames F. Allen.
1983.
Maintaining knowledge abouttemporal intervals.
Communications of the ACM.Steven Bethard, James H. Martin, and Sara Klingenstein.2007.
Timelines from text: Identification of syntactictemporal relations.
In ICSC.P.
Bramsen, P. Deshpande, Y. K. Lee, and R. Barzilay.2006.
Inducing temporal graphs.
In EMNLP.N.
Chambers and D. Jurafsky.
2008.
Jointly combin-ing implicit constraints improves temporal ordering.In EMNLP.Zheng Chen, Heng Ji, and Robert Haralick.
2009.
Apairwise event coreference model, feature impact andevaluation for event coreference resolution.
In Work-shop on Events in Emerging Text Types.J.
Clarke and M. Lapata.
2008.
Global inference forsentence compression: An integer linear programmingapproach.
Journal of Artificial Intelligence Research.Pascal Denis and Philippe Muller.
2011.
Predictingglobally-coherent temporal structures from texts viaendpoint inference and graph decomposition.
In IJ-CAI.C.
Fellbaum.
1998.
WordNet: An Electronic LexicalDatabase.
MIT Press.Yoav Freund and Robert E. Schapire.
1999.
Large mar-gin classification using the perceptron algorithm.
Ma-chine Learning.Philipp Koehn.
2004.
Statistical significance tests formachine translation evaluation.
In EMNLP.Inderjeet Mani, Marc Verhagen, Ben Wellner, Chong MinLee, and James Pustejovsky.
2006.
Machine learningof temporal relations.
In ACL.J.
Pustejovsky, P. Hanks, R. Sauri, A.
See, R. Gaizauskas,A.
Setzer, D. Radev, B. Sundheim, D. Day, L. Ferro,and M. Lazo.
2003.
The TIMEBANK corpus.
InCorpus Linguistics.D.
Roth and W. Yih.
2007.
Global inference for entityand relation identification via a linear programmingformulation.
In Introduction to Statistical RelationalLearning.Partha Pratim Talukdar, Derry Wijaya, and Tom Mitchell.2012.
Coupled temporal scoping of relational facts.
InWSDM.Marta Tatu and Munirathnam Srikanth.
2008.
Experi-ments with reasoning for temporal relations betweenevents.
In COLING.Marc Verhagen, Robert Gaizauskas, Frank Schilder,Mark Hepple, Graham Katz, and James Pustejovsky.2007.
Semeval-2007 task 15: Tempeval temporal re-lation identification.
In SemEval-2007.Marc Verhagen, Roser Sauri, Tommaso Caselli, andJames Pustejovsky.
2010.
Semeval-2010 task 13:Tempeval-2.
In SemEval-2010.Katsumasa Yoshikawa, Sebastian Riedel, Masayuki Asa-hara, and Yuji Matsumoto.
2009.
Jointly identify-ing temporal relations with markov logic.
In ACL-IJCNLP.Ran Zhao, Quang Do, and Dan Roth.
2012.
A robustshallow temporal reasoning system.
In NAACL-HLTDemo.687
