Tree-Based State Tying for High AccuracyModellingS.J.
Young, J.J. Odell, P.C.
WoodlandAcousticCambr idge  Un ivers i ty  Eng ineer ing  Depar tmentT rumpington  Street ,  Cambr idge ,  CB2 1PZ, Eng landABSTRACTThe key problem to be faced when building a HMM-basedcontinuous speech recogniser is maintaining the balance be-tween model complexity and available training data.
Forlarge vocabulary systems requiring cross-word context de-pendent modelling, this is particularly acute since many mmhcontexts will never occur in the training data.
This paper de-scribes a method of creating a tied-state continuous speechrecognition system using a phonetic decision tree.
This tree-based clustering is shown to lead to similar recognition per-formance to that obtained using an earlier data-driven ap-proach but to have the additional advantage of providing amapping for unseen triphones.
State-tying is also comparedwith traditional model-based tying and shown to be clearlysuperior.
Experimental results are presented for both theResource Management and Wall Street 3ournal tasks.1.
INTRODUCTIONHidden Markov Models (HMMs) have proved to be aneffective basis for modelling time-varying sequences ofspeech spectra.
However, in order to accurately capturethe variations in real speech spectra (both inter-speakerand intra-speaker), it is necessary to have a large numberof models and to use relatively complex output probabil-ity distributions.
For example, to achieve good perfor-mance in a continuous density HMM system, it is neces-sary to use mixture Gaussian output probability distri-butions together with context dependent phone models.In practice, this creates a data insufficiency problem dueto the resulting large number of model parameters.
Fur-thermore, the data is usually unevenly spread so thatsome method is needed to balance model complexityagainst data availability.This data insufficiency problem becomes acute when asystem incorporating cross-word context dependency isused.
Because of the large number of possible cross-word triphones, there are many models to estimate anda large number of these triphones will have few, if any,occurrences in the training data.
The total number oftriphones needed for any particular application dependson the phone set, the dictionary and the grammati-cal constraints.
For example, there are about 12,600position-independent triphones needed for the ResourceManagement task when using the standard word pairgrammar and 20,000 when no grammar is used.
For the20k Wall Street Journal task, around 55,000 triphonesare needed.
However, only 6600 triphones occur in theResource Management training data and only 18,500 inthe SI84 section of the Wall Street Journal training data.Traditional methods of dealing with these problems in-volve sharing models across differing contexts to formso-called generalised triphones and using a posteriorismoothing techniques\[5\].
However, model-based sharingis limited in that the left and right contexts cannot betreated independently and hence this inevitably leadsto sub-optimal use of the available data.
A posteriorismoothing is similarly unsatisfactory in that the modelsused for smoothing triphones are typically biphones andmonophones, and these will be rather too broad whenlarge training sets are used.
Furthermore, the need tohave cross-validation data unnecessarily complicates thetraining process.In previous work, a method of HMM estimation has beendescribed which involves parameter tying at the staterather than the model evel\[10,12\].
This method assumesthat continuous density mixture Gaussian distributionsare used and it avoids a posteriori smoothing by firsttraining robust single Gaussian models, then tying statesusing an agglomerative data clustering procedure and fi-nally, converting each tied state to a mixture Ganssian.This works well for systems which have only word inter-nal triphone models and for which it is therefore possibleto find some data for every triphone.
However, as indi-cated by the figures given above, systems which utilisecross-word triphones require data for a very large num-ber of triphones and, in practice, many of them will beunseen in the training data.In this paper, the state tying approach is developed fur-ther to accommodate he construction of systems whichhave unseen triphones.
The new system is based on theuse of phonetic decision trees I1,2,6\] which are used todetermine contextually equivalent sets of HMM states.In order to be able to handle large training sets, the treebuilding is based only on the statistics encoded within307(1)(2) J / \ ' - -- .
.
.
.
t-iy+n t-iy+ng f-iy+l s-iy+l(,,4 1 1 1.
~ .
etct-iy+n t-iy+ng f-iy+!
s-iy+l?
e tcFigure 1: The Tied-State HMM System Build Procedureeach HMM state and there is no direct reference madeto the original data.This tree-based clustering is shown to lead to similarmodelling accuracy to that obtained using the data-driven approach but to have the additional advantage ofproviding a mapping for unseen triphones\[3\].
State-tyingis also compared with traditional model-based tying andshown to be clearly superior.The arrangement of this paper is as follows.
In the nextsection, the method of HMM system building using statetying is reviewed and then in section 3, the phonetic de-cision tree based method is described.
Experimental re-sults are presented in section 4 using the HTK speechrecognition system\[8,9\] for both the Resource Manage-ment and Wall Street Journal tasks.
Finally, section 5presents our conclusions from this work.2.
T IED-STATE HMM SYSTEMThe aim in building a tied-state HMM system is to en-sure that there is sufficient raining data to robustly es-timate each set of state output distribution parameterswhilst retaining the important context-dependent acous-tic distinctions within each phone class.
The method de-scribed here uses continuous density mixture Gaussiandistributions for two reasons.
Firstly, continuous den-sity models are potentially more accurate than discrete(or semi-continuous) ystems ince they do not requirethe input feature space to be quantised (or representedby only a few basis functions).
This becomes particu-larly important when derivative features are used sincediscrete systems have to regard each derivative set asbeing statistically independent in order to achieve ade-quate coverage of the feature space.
In continuous den-sity systems, derivative features are simply appended tothe static parameters and although it is usually necessaryto make a diagonal covariance assumption, the featuresets remain coupled through a common set of mixtureweights.The second key advantage of continuous density systemsis that the modelling accuracy of any particular distri-bution can be smoothly adjusted by increasing or de-creasing the number of mixture components.
This al-lows simple single Gaussian distributions to be used foran initial untied model set where the training data is verypatchy.
Then once tying has been performed such thatevery state has an adequate amount of data, more com-plex mixture Gaussian distributions can be estimated togive increased accuracy.The process of building a tied state HMM system is il-lustrated by Fig.
1.
There are 4 main steps1.
An initial set of a 3 state left-right monophone mod-els with single Gaussian output probability densityfunctions is created and trained.2.
The state output distributions of these monophonesare then cloned to initialise a set of untied contextdependent triphone models which are then trainedusing Baum-Welch re-estimation.
The transitionmatrix is not cloned but remains tied across all thetriphones of each phone.3.
For each set of triphones derived from the samemonophone, corresponding states are clustered.
Ineach resulting cluster, a typical state is chosen asexemplar and all cluster members are tied to thisstate.4.
The number of mixture components in each stateis incremented and the models re-estimated untilperformance on a development test set peaks or thedesired number of mixture components i reached.In the above, all parameter estimation uses embeddedBaum-Welch re-estimation for which a transcription is308Initial set of untied statesR-Liquid?
~ L-Fricative?Tie states in each leaf nodeFigure 2: Example of a phonetic decision treeneeded for every training utterance.
Since the dictionarytypically has more than one pronunciation per word,transcriptions are derived from the known orthographyby using an initial bootstrap set of monophones to do a.forced recognition of each training utterance.
Since thesemodels will be rather poor, the build procedure may needto be repeated using the models generated from the firstpass to re-transcribe the training data.As noted in the introduction, previous work on state-tying used a data-driven agglomerative clustering pro-cedure in which the distance metric depended on theEuclidean distance between the state means scaled bythe state variances.
This works well but it provides noeasy way of handling unseen triphones.
The next sec-tion describes an alternative clustering procedure whichovercomes this problem.3.
TREE-BASED CLUSTERINGA phonetic decision tree is a binary tree in which a ques-tion is attached to each node.
In the system describedhere, each of these questions relates to the phonetic on-text to the immediate left or right.
For example, inFig.
2, the question "Is the phone on the left of the cur-rent phone a nasal?"
is associated with the root node ofthe tree.
One tree is constructed for each state of eachphone to cluster all of the corresponding states of all ofthe associated triphones.
For example, the tree shown inFig.
2 will partition its states into six subsets correspond-ing to the six terminal nodes.
The states in each subsetare tied to form a single state and the questions and thetree topology are chosen to maximise the likelihood ofthe training data given these tied states whilst ensur-ing that there is sufficient data associated with each tiedstate to estimate the parameters of a mixture GaussianPDF.
Once all such trees have been constructed, unseentriphones can be synthesised by finding the appropriateterminal tree nodes for that triphone's contexts and thenusing the tied-states associated with those nodes to con-struct the triphone.All of the questions used have the form "Is the left orright phone a member of the set X" where the set Xranges from broad phonetic lasses uch as Nasal, Frica-tive, Vowel, etc.
through to singleton sets such as {l},{m}, etc.Each tree is built using a top-down sequential optimi-sation procedure \[4,6\].
Initially, all of the states to beclustered are placed in the root node of the tree and thelog likelihood of the training data calculated on the as-sumption that all of the states in that node are tied.
Thisnode is then split into two by finding the question whichpartitions the states in the parent node so as to give themaximum increase in log likelihood.
This process is thenrepeated by splitting the node which yields the greatestincrease in log likelihood until this increase falls belowa threshold.
To ensure that all terminal nodes have suf-ficient training data associated with them, a minimumoccupation count is applied.Let S be a set of HMM states and let L(S) be the loglikelihood of S generating the set of training frames Funder the assumption that all states in S are tied i.e.they share a common mean/~(S) and variance ~(S) andthat transition probabilities can be ignored.
Then, as-suming that tying states does not change the frame/statealignment, a reasonable approximation for L(S) is givenbyL(S) = Z Z l?g(Pr(?l; #(S), ~(S))%(of )  (1)fEF  sESwhere %(of )  is the a postcriori probability of the ob-served frame o I being generated by state s. If the outputPDFs are Gaussian, then1 L(S) = -~(log\[(2~)"l~(s)H + n)~ ~ ~=(of) (2)sES fEFFwhere n is the dimensionality of the data.
Thus, thelog likelihood of the whole data set depends only on thepooled state variance ~(S) and the total state occupancyof the pool, ~=~s FIeF ~s(o.f).
The former can be cal-culated from the means and variances of the states inthe pool, and the state occupancy counts can be savedduring the preceding Baum-Welch re-estimation.
For agiven node with states S which is partitioned into twosubsets Su(q) and Sn(q) by question q, the node is splitusing the question q. which maximisesALq = L(Su(q)) + L(Sn(q)) - L(S) (3)309 ;Condition Question Total GainAll statesof allmodelsEntrystateof allmodelsExitstateof allconsonantsR-VowelL-VowelR-UnroundedL-UnFortisLenisR-UnFortisLenisR-rL-UnFortisLenisL-VowelL-NasalL-CentralFrontL-UnroundedL-FortisR-VowelR-UnfoundedR-HighR-eeR-RoundedR-Syllabic25.923.319.719.518.317.118.316.910.37.77.46.215.28.64.73.93.73.6Table 1: Ranking of most useful questions for the WSJtask.provided that both ALq.
and the total pooled state oc-cupation counts for both Su(q.)
and S~(q*) exceed theirassociated thresholds.As a final stage, the decrease in log likelihood is calcu-lated for merging terminal nodes with differing parents.Any pair of nodes for which this decrease is less thanthe threshold used to stop splitting are then merged.
Inpractice, this reduces the number of states by 10-20%without any degradation i performance.To gain some impression of question usage, Table 1shows, for a typical system built for the Wall Street Jour-nal task, the first six most useful questions calculated forall states of all models, the entry state of all models andthe exit state of all consonants.
The rating given is thetotal increase in log likelihood achieved by that question.As can be seen, the presence of a following vowel is themost important context-dependent effect.
There were202 questions in total to choose from and in the threecases 195, 182 and 152 questions, respectively were ac-tually used in at least one decision tree.4.
EXPERIMENTSExperiments have been performed using both the ARPAResource Management (RM) and Wall Street Journal(WSJ) databases.
Results are presented here for the1000 word RM task using the standard word pair gram-mar and for 5k closed vocabulary and 20k open vocabu-lary WSJ test sets.
All tables show the percentage worderror rate.For both databases the parameterised data consisted of12 MFCC coefficients and normalised energy plus 1st and2nd order derivatives.
In addition, for the WSJ data, thecepstral mean was calculated and removed on a sentenceby sentence basis.The RM systems used the standard SI-109 training dataand used the pronunciations and phone set (46 phonesplus silence) produced by CMU and listed in \[5\] togetherwith the standard word-pair grammar.
The RM systemswere tested on the four official evaluation test sets iden-tified by the dates when the tests took place (Feb'89,Oct'89, Feb'91 and Sep'92).The WSJ systems used training data from the SI84 orthe SI284 data sets and the pronunciations and phoneset from the Dragon Wall Street Journal PronunciationLexicon Version 2.0 together with the standard bigramand trigram language models supplied by Lincoln Labs.Some locally generated additions and corrections to thedictionary were used and the stress markings were ig-nored resulting in 44 phones plus silence.Both 5k word and 20k word WSJ systems were tested.Four 5k closed vocabulary test sets were used.
Thesewere the Nov'92 and Nov'93 5k evaluation test sets; 202sentences from the si_dt_s6 'spoke' development test setand 248 sentences fl'om the si_dt_05 'hub' developmenttest set.
At 20k, three test sets were used.
These werethe Nov'92 and Nov'93 evaluation test sets and a 252sentence subset of the si_dt_20 development test set.
Forboth the 5k and 20k cases, the Nov'93 test data was usedjust once for the actual evaluation.All phone models had three emitting states and a left-to-right topology.
Training was performed using theHTK toolkit\[Ill. All recognition etworks enforced si-lence at the start and end of sentences and allowedoptional silences between words.
All cross-word tri-phone systems used a one pass decoder that performeda beam search through a tree-structured dynamicallyconstructed network\[7\].
Word internal systems used thestandard HTK decoder, HVite.4 .1 .
Data -Dr iven  vs .
T ree-based  C lus ter -ingIn order to compare top-down tree clustering with thebottom-up agglomerative approach used in previous ys-tems, an RM system was constructed using each of thetwo methods.
Both systems used the same initial set310System I Nov192 I si-dts6 1 si-dt-05 I Nov'93Model 1 7.17 1 10.61 1 12.17 ( 11.22I State I 5.90 I 10.33 1 10.73 1 9.89 1SystemAgg D-DTreeTable 2: Comparison of Agglomerative Data-driven vs.Tree-based clustering using the RM task.
Each recog-niser used word-internal triphones, had approximately1600 tied-states and 6 mixture components per state.Oct'894.844.99Feb'894.103.87of untied triphones.
Agglomerative data-driven cluster-ing was then applied to create a word-internal triphonesystem and decision tree-based clustering was used tocreate a second word-internal triphone system.
The clus-ter thresholds in each case were adjusted to obtain sys-tems with approximately equal numbers of states, 1655and 1581, respectively.
After clustering, the constructionof the two systems was completed by applying identicalmixture-splitting and Baum-Welch re-estimation proce-dures to produce systems in which all states had 6 com-ponent mixture Gaussian PDFs and both systems had atotal of approximately 750k parameters.The results are shown in Table 2.
As can be seen, the,performance of the tree clustered models is similar tothat of the agglomeratively clustered system but thetreebased models have the advantage that, were it nec-essary, they would allow the construction of unseen tri-phones.Feb1913.783.744.2.
State- vs Model-based clusteringSep7928.057.31As noted in the introduction, the traditional approachto reducing the total number of parameters in a systemis to use model-based clustering to produce generalisedtriphones.
To compare this with the state-based a pproach, systems of similar complexity were constructedusing both methods for the RM task and the 5k closedvocabulary WSJ task.
For RM, each system had a pproximately 2400 states with 4 mixture components perstate giving about 800k parameters in total.
The WSJSystem I Feb189 I Oct'89 I Feb791 I Sep'92Model 1 3.71 1 4.58 1 4.19 1 7.031 State 1 3.12 1 3.76 ITable 3: Comparison of Model-based vs. Statebasedclustering using the RM task.
Each recogniserused cross-word triphones, had approximately 2400tied-states and 4 mixture components per state.Table 4: Comparison of Model-based vs. Statebasedclustering on the 5k WSJ task.
Each recogniser usedcross-word triphones and a bigram language model, andhad approximately 4800 tied-states and 8 mixture com-ponents per state.systems were trained on the S184 data set and had a pproximately 4800 states with 8 mixture components perstate giving about 3000k parameters in total.Tables 3 and 4 show the results.
As can be seen, thestate-clustered systems consistently out-performed themodel-clustered systems (by %20% and an average of14%).4.3.
Overall PerformanceTo determine the overall performance of the tree-clustered tiecl-state approach, a number of systems wereconstructed for both the RM and WSJ tasks in order toestablish absolute performance levels.For the RM task, a gender independent cross word tri-phone system was constructed with 1778 states each with6 mixture components per state.
The performance ofthis system on the four test sets is shown in Table 5.
Forthe WSJ task, two gender dependent cross-word triphonesystems were constructed.
The first used the SI-84 train-ing set with 3820 tied-states per gender and 8 mixturecomponents per state.
The variances across correspond-ing male and female states were tied leading to a systemwith approximately 3600k parameters.
The second system was similar but used the larger SI284 training set.
Ithad 7558 tied-states per gender, 10 mixture componentsper state and about 8900k parameters in total.
The r esults for the the 5k tests are shown in Table 6 and for the20k tests in Table 7.
These systems achieved the lowest 'error rates reported for the November 1993 WSJ eval-Table 5: Performance of the HTK recogniser on the RMtask.
It used cross-word triphones, had approximately1800 tied-states and 6 mixture components per state.Train/LM Nov'92SI84/bg 6.58SI284/bg 5.14S I2~/ tg  3.19si_dt_s6 si_dt_05 Nov'939.13 9.676.63 7.585.27 6.098.67 t6.774.90 ~Table 6: Performance of the HTK recogniser on the WSJ5k task using bigram (bg) and trigram (tg) languagemodels, t denotes ystems used for the ARPA November1993 WSJ evaluation.uations on the H2-C1 and H2-P0 5k closed vocabularytasks, and the H1-C2 20k open vocabulary task; and thesecond lowest on the HI-C1 20k open vocabulary task.A full description of these Wall Street Journal systemscan be found in \[9\].5.
CONCLUSIONSThis paper has described an efficient method of stateclustering based on the use of phonetic decision treesand its use has been demonstrated in the HTK tied-state recognition system.
It has been shown that tyingat the state rather than the model level gives improvedaccuracy and that phonetic decision trees are as effectivefor clustering as data-driven methods but have the keyadvantage of providing a mapping for unseen triphones.The overall results on both the RM and WSJ tasks in-dicate that the proposed approach leads to a recogniserwith state-of-the-art performance but which is relativelycompact and easy to construct.
The method dependscrucially on the use of continuous density HMMs sincethey provide a simple way of manipulating complexity.Initially when the data for some triphones is sparse, theuse of simple single Gaussian distributions till allowsreasonable parameter estimates to be made.
The useof single Gaussians in the initial stages also allows veryefficient ree-building since the required likelihood-basedobjective function can be computed without reference toTrain/LM Nov'92 si_dt..20 Nov'93SI284/bg 11.08 i 16.17 14.35 tSI284/tg 9.46 13.71 12.67 "~Table 7: Performance of the HTK recogniser on the WSJ20k task using bigram (bg) and trigram (tg) languagemodels, t denotes ystems used for the ARPA November1993 WSJ evaluation.the training data.
However, once the amount of data perstate has been increased by the state tying procedure,the single Gaussians can easily be converted to mixtureGaussians by splitting components and re-estimating.Model complexity can then be increased smoothly in thisway until optimal performance is achieved.6.
ACKNOWLEDGEMENTSThe WSJ pronunciation dict ionary was provided byDragon Systems Inc. J. Odell is funded by a SERC stu-dentship and part of this work was funded by SERCgrant GR/J10204.References1.
Bahl LR, de Souza PV, Copalakrishnan PS, NahamooD, Picheny MA (1991).
Context Dependent Modelingof Phones in Continuous Speech Using Decision Trees.Proc DARPA Speech and Natural Language ProcessingWorkshop, pp264-270, Pacific Grove, Calif.2.
Downey S, Russell MJ (1992).
A Decision Tree Ap-proach to Task Independent Speech Recognition.
ProcInst Acoustics Autunm Conf on Speech and Hearing,Vol 14, Part 6, pp181-188.3.
Hwang M-Y, Huang X, Alleva F (1993).
Predicting Un-seen Triphones with Senones.
Proc ICASSP'93, Vol II,pp.
311-314, Minneapolis.4.
Kannan A, Ostendorf M, Itohlicek JR (1994).
MaximumLikelihood Clustering of Gaussians for Speech Recogni-tion.
to appear, IEEE 'lh'ans on Speech and Audio Pro-cessing.5.
Lee K-F (1989).
Automatic Speech Recognition: The De-velopment of the SPHINX System.
Kluwer AcademicPublishers, Boston.6.
Odell JJ.
(1992) Ti~e Use of Decision Trees with ContextSensitive Phoneme Modelling.
MPhil Thesis, CambridgeUniversity Engineering Department.7.
Odell J J, Valtchev V, Woodland PC, Young SJ (1994) AOne-Pass Decoder Design for Large Vocabulary Recogni-tion.
ARPA Workshop on Human Language Technology,Merrill Lynch Conference Centre, March.8.
Woodland PC, Young SJ (1993).
The HTK ContinuousSpeech Recogniser.
Proc Eurospeech '93, pp2207-2219,Berlin.9.
Woodland PC, Odell J J, Valtchev V, Young SJ (1994).Large Vocabulary Continuous Speech Recognition UsingHTK.
Proc ICASSP, Adelaide.10.
Young SJ (1992).
The General Use of Ty-ing in Ptmneme-Based HMM Speech Recognisers.
ProcICASSP, Vol 1, pp569-572, San Francisco.11.
Young SJ (1993).
The HTK Hidden Markov ModelToolkit: Design and Philosophy.
Tit 152, CambridgeUniversity Engineering Dept, Speech Group.12.
Young SJ, Woodland PC (1993).
The Use of State Tyingin Continuous Speech Recognition.
Proc Eurospeech '93,pp2203-2206, Berlin.312
