HITIQA: Scenario Based Question AnsweringSharon Small, Tomek Strzalkowski, Tracy Janack, Ting Liu,Sean Ryan, Robert Salkin, Nobuyuki ShimizuThe State University of New York at Albany1400 Washington AvenueAlbany, NY 12222{small,tomek,tj5550,tl7612,seanryan,rs6021,ns3203}@albany.eduPaul Kantor, Diane Kelly, Robert Rittman, Nina WacholderRutgers UniversityNew Brunswick, New Jersey 08903{kantor, nina, diane, rritt}@scils.rutgers.eduBoris YamromLehman College of the City University of New YorkBronx, New York 10468byamrom@lehman.cuny.edyAbstractIn this paper we describe some preliminaryresults of qualitative evaluation of the answer-ing system HITIQA (High-Quality InteractiveQuestion Answering) which has been devel-oped over the last 2 years as an advanced re-search tool for information analysts.
HITIQAis an interactive open-domain question an-swering technology designed to allow analyststo pose complex exploratory questions in natu-ral language and obtain relevant informationunits to prepare their briefing reports in orderto satisfy a given scenario.
The system usesnovel data-driven semantics to conduct a clari-fication dialogue with the user that exploresthe scope and the context of the desired answerspace.
The system has undergone extensivehands-on evaluations by a group of intelli-gence analysts representing various foreign in-telligence services.
This evaluation validatedthe overall approach in HITIQA but also ex-posed limitations of the current prototype.1   IntroductionOur objective in HITIQA is to allow the user tosubmit exploratory, analytical questions, such as ?Whathas been Russia?s reaction to U.S. bombing of Kos-ovo??
The distinguishing property of such questions isthat one cannot generally anticipate what might consti-tute the answer.
While certain types of things may beexpected (e.g., diplomatic statements), the answer isheavily conditioned by what information is in fact avail-able on the topic, background knowledge of the user,context in the scenario, intended audience, etc.
From apractical viewpoint, analytical questions are often un-derspecified, thus casting a broad net on a space of pos-sible answers.
Therefore, clarification dialogue is oftenneeded to negotiate with the user the exact scope andintent of the question, and clarify whether similar topicsfound might also be of interest to the user in order tocomplete their scenario report.
This paper will presentresults from a series of evaluations conducted in a seriesof workshops with the intended end users of HITIQA(professional intelligence analysts) using the system tosolve realistic analytic problems.HITIQA project is part of the ARDA AQUAINTprogram that aims to make significant advances in thestate of the art of automated question answering.
In thispaper we focus on our approach to analytical questionanswering in order to produce a report in response to agiven scenario.
We also report on the user evaluationswe conducted and their results with respect to ourunique approach.2   Analytical QA ScenariosAnalytical scenarios are information task directivesassigned to analysts to support a larger foreign policyprocess.
Scenarios thus contain the information needspecifications at various levels of detail,  the type, for-mat and timing of the response required (an intelligencereport) as well as the primary recipient of the report(e.g., the Secretary of State).
A hypothetical, but realis-tic scenario is shown in Figure 1 below.
This scenario,along with several others like it, was used in evaluatingHITIQA performance and fitness for supporting theanalytical process.As can be readily assessed from the directives inFigure 1, scenarios are not merely tough questions; theyare far too complex to be considered as a single questionat all.
It is equally clear that no simple answer can beexpected and that preparing a report would mean find-ing answers to a series of interlocking questions or vari-ous granularities.Scenario: The al-Qaida Terrorist GroupAs an employee of the Central Intelligence Agency, your pro-fession entails knowledge of the al-Qaida terrorist group.Your division chief has ordered a detailed report on the al-Qaida Terrorist Group due in three weeks.
Provide as muchinformation as possible on this militant organization.
Eventu-ally, this report should present information regarding the mostessential concerns, including who are the key figures involvedwith al-Qaida along with other organizations, countries, andmembers that are affiliated, any trades that al-Qaida has madewith organizations or countries, what facilities they possess,where they receive their financial support, what capabilitiesthey have (CBW program, other weapons, etc.)
and how havethey acquired them, what is their possible future activity, howtheir training program operates, who their new members are.Also, include any other relevant information to your report asyou see fit.FIGURE 1: Scenario used during user evaluationsWe have organized a series of usability evaluationswith active duty intelligence analysts to find out howthey approach the problem of solving a scenario.
Theprerequisites for this were are follows:1.
A robust, broadly functional analytical QA sys-tem capable of sustaining realistic analytictasks.2.
A realistic corpus of ?raw intelligence?
in formof varying quality and verity new-like reports.3.
A set of realistic, average complexity analytictasks or scenarios to be used.HITIQA has been developed over the past two years asan open-ended highly flexible interactive QA system toallow just this type of evaluation.
The system supports avariety of information gathering functions withoutstraight jacketing the user into any particular mode orinteraction style.
The system does not produce cut anddry ?answers?
; instead it allows the analysts to build theanswers the way they want them.
While this open-endedness may seem like unfinished business, we be-lieve that further development must take into accountthe needs of analysts if they were ever to adopt thistechnology in their work.Our main hypothesis is that analysts employ a rangeof strategies to find the required information and thatthese strategies depend significantly upon the nature ofthe task and the progress the analyst is making on thetask, in addition to individual differences between ana-lysts.
Our experience with interactive systems also indi-cated that real users are unlikely to follow any singleinformation exploration strategy, but instead would usemultiple, parallel, even overlapping approaches in orderto maximize the returns and their confidence in the re-sults.
As a corollary we may expect that the scenariotasks are unlikely to be systematically decomposed intoa series of smaller tasks ahead of actual search.
In otherwords, the analytical process is a dialogue, not a se-quence of commands.
Moreover, questions actuallysubmitted to the system during the analytical processseldom seek just the exact answer, instead they are oftenconsidered as ?light beams?
through the data: focusingon the answer but also illuminating adjacent, relatedinformation which may prove just as valuable.AFRL, NIST, CNS and ARDA collaborated in thedevelopment of scenarios used in our evaluation ses-sions.3   Data Driven Semantics of QuestionsWhen the user poses a question to a system havingaccess to a huge database of unstructured data (textfiles), we need to first reduce the big pile to perhaps ahandful of documents where the answer is likely to befound.
The easiest way to do it is to convert the questioninto a search query (by removing stopwords and stem-ming and tokenizing other words) and submitting thisquery to a fast but non-exact document retrieval system,e.g.,   Smart (Buckley, 1985) or InQuery (Callan et al,1992), or if you are on the web, Google, etc.In the current prototype of HITIQA, we use a com-bination of Google and InQuery to retrieve the top 50 to200 documents from a large document database, con-sisting of several smaller collections such as newspaperstories, documents from the Center of NonproliferationStudies, as well as web mined files.
The retrieveddocuments are then broken down into passages, mostlyexploiting the naturally occurring paragraph structure ofthe original sources.The set of text passages returned from the initialsearch is the first (very crude) approximation of the An-swer Space for the user?s first question.
In order to de-termine what this answer space consists of we performautomatic analysis (a combination of hierarchical clus-tering and classification) to uncover if what we got is afairly homogenous collection (i.e., all texts have verysimilar content), or whether there are a number of di-verse topics or aspects represented in there, somehowtied together by a common thread.
In the former case,we may be reasonably confident that we have the an-swer, modulo the retrievable information.
In the lattercase, we know that the question is more complex thanthe user may have intended, and a negotiation process isneeded to clarify topics of interest for the scenario re-port.The next step is to measure how well each of the as-pects within the answer space is ?matching up?
againstthe original question.
This is accomplished through theframing process described later in this paper.
The out-come of the framing process is twofold: first, the alter-native interpretations of the question are ranked within 3broad categories: on-target, near-misses and outliers.Second, salient concepts and attributes for each topi-cal/aspectual group are extracted into topic frames.
Thisenables the system to conduct a meaningful dialoguewith the user, a dialogue which is wholly content ori-ented, and entirely data driven.4   Partial structuring of text dataIn HITIQA we use a text framing technique to de-lineate the gap between the meaning of the user?s ques-tion and the system ?understanding?
of this question.The framing is an attempt to impose a partial structureon the text that would allow the system to systemati-cally compare different text pieces against each otherand against the question, and also to communicate withthe user about this.
In particular, the framing processmay uncover topics or aspects within the answer spacewhich the user has not explicitly asked for, and thusmay be unaware of their existence.
This approach isparticularly beneficial to the needs of the scenario prob-lem, where these similar aspects frequently are neededin completely ?answering?
the scenario, with the sce-nario report.In the current version of HITIQA, frames are pre-defined structures representing various event types.
Westarted with the General frame, which can represent anyevent or relation involving any number of entities suchas people, locations, organizations, time, and so forth.In a specialized domain, or if the user interests areknown to be limited to a particular set of topics, we de-fine domain-specific frames.
Current HITIQA prototypehas three broad domain-specific frames, related to theWeapon of Mass Destruction proliferation domain(which was one of the domains of interest to our users).These frames are: WMDTransfer, WMDDevelop,WMDTreaty, and of course we keep the General frame.Obviously, these three frames do not cover the domainrepresented by our data set; they merely capture themost commonly occurring types of events.
All framescontain a small number of core attributes, such as LO-CATION, PERSON, COUNTRY, ORGANIZATION, ETC., whichare extracted using BBN?s Identifinder software, whichextracts 24 types of entities.
Domain-specific framesadd event specific attributes, which may require extract-ing additional items from text, or assigning roles to ex-isting attributes, or both.
For example, WMDTransfer?sattributes TRANSFER_TO and TRANSFER_FROM defineroles of some COUNTRY or ORGANIZATION, while theTRANSFER_TYPE attribute scans the text for keywordsthat may indicate the type of transfer, e.g., export, sale,etc.HITIQA creates a Goal frame for the user?s ques-tion, which can be subsequently compared to the dataframes obtained from retrieved data.
A Goal frame canbe a General frame or any of the domain specific framesavailable in HITIQA.
For example, the Goal framegenerated from the question, ?Where does al-Qaidahave training facilities??
is a General frame as shown inFigure 2.
This was the first question generated by oneof our analysts during the first evaluation while workingon the al-Qaida scenario shown in Figure 1.FRAME TYPE: GeneralTOPIC: training facilitiesORGANIZATION: al-QaidaFIGURE 2: HITIQA generated General-type Goal frame fromthe al-Qaida training facilities questionFRAME TYPE: GeneralCONFLICT SCORE: 1TRANSFER TYPE: providedTRANSFER TO: al-QaidaTRANSFER FROM: IraqTOPIC: providedSUB-TOPIC: importedLOCATION: IraqPEOPLE: Abu Musab al-Zarqawi, Bush, GeorgeTenet, Saddam HusseinORGANIZATION:CIA, Administration, al-QaidaDOCUMENT: web_283330PARAGRAPHS:  ["CIA chief George Tenet seems tohave gone a long way to back the Bush Administrations dec-larations that the long split between Islamic fundamentalistterrorist organizations like Al-Qaida and secular Iraqi rulerSaddam Hussein is healed.He has testified that the CIA has evidence of Iraqi provid-ing Al Qaida with training in forgery and bomb making and ofproviding two, Al Qaida associates with training in gas andpoisons.
He said also that Iraq is harboring senior membersof a terrorist network led by Abu Musab al-Zarqawi, a closeAl Qaida associate.
"]RELEVANCE:  Conflict: [Topic]FIGURE 3: A HITIQA generated data frame and the un-derlying text passage.
Words in bold were used to fill theFrame.HTIQA automatically judges a particular data frameas relevant, and subsequently the corresponding seg-ment of text as relevant, by comparison to the Goalframe.
The data frames are scored based on the numberof conflicts found between them and the Goal frame.The conflicts are mismatches on values of correspond-ing attributes.
If a data frame is found to have no con-flicts, it is given the highest relevance rank, and a con-flict score of zero.
All other data frames are scored witha decreasing value based on the number of conflicts,negative one for frames with one conflict with the Goalframe, negative two for two conflicts etc.
Frames thatconflict with all information found in the question aregiven a score of -99 indicating the lowest relevancyrank.
Currently, frames with a conflict score of -99 areexcluded from further processing as outliers.
The framein Figure 2 is scored as a near miss and will generatedialogue, where the user will decide whether or not itshould be included in the answer space.5   Clarification DialogueData frames with a conflict score of zero form theinitial kernel answer space.
Depending upon the pres-ence of other frames outside of this set, the system ei-ther proceeds to generate the answer or initiates a dia-logue with the user.
HITIQA begins asking the userquestions on these near-miss frame groups, with thelargest group first.
The groups must be at least groupsof size N, where N is a user controlled setting.
Thissetting restricts all of HITIQA?s generated dialogue.A one conflict frame has only a single attributemismatch with the Goal frame.
This could be a mis-match on any of the General attributes, for example,LOCATION, or ORGANIZATION, or TIME, etc., or in one ofthe domain specific attributes, TRANSFER_TO, or TRANS-FER_TYPE, etc.
A special case arises when the conflictoccurs on the TOPIC attribute.
Since all other attributesmatch, we may be looking at potentially different eventsor situations involving the same entities, or occurring atthe same location or time.
The purpose of the clarifica-tion dialogue in this case is to probe which of these top-ics may be of interest to the user.
Another special casearises when the Goal frame is of a different type than adata frame.
The purpose of the clarification dialogue inthis case is to expand the user?s answer space into adifferent but possibly related event.
A combination ofboth of these cases is illustrated in the exchange in Fig-ure 4 below.User: ?Where does al-Qaida have training facili-ties?
?HITIQA: ?Do you want to see material on the trans-fer of weapons and intelligence to al-Qaida?
?FIGURE 4: Dialogue generated by HITIQA for the al-Qaidatraining facilities questionIn order to understand what happened here, we needto note first that the Goal frame for this example is aGeneral Frame, from Figure 2.
One of the data framesthat caused this dialogue to be generated is shown inFigure 3 above.
While this frame is of a different frametype than the Goal frame, namely WMD Transfer, itmatches on all of the General attributes except TOPIC, soHITIQA asks the user if they would like to expand theiranswer space to this other domain, namely to includethe transfer of weapons involving this organization aswell.ANSWER REPORT:The New York Times said the Mindanao had become thetraining center for the Jemaah Islamiah network, believed bymany Western governments to be affiliated to the al-Qaidamovement of Osama bin LadenDocName: A-web_283305 ParaId: 2?IRAQ REPORTED TO HAVE PROVIDED MATERIALSTO AL QAIDA2003[CIA chief George Tenet seems to have gone a long way toback the Bush Administrations declarations that the long splitbetween Islamic fundamentalist terrorist organizations like AlQiada and secular Iraqi ruler Saddam Hussein is healed.DocName: A-web_283330 ParaId: 6He has testified that the CIA has evidence of Iraqi providingAl Qaida with training in forgery and bomb making and ofproviding two, Al Qaida associates with training in gas andpoisons.
He said also that Iraq is harboring senior members ofa terrorist network led by Abu Musab al-Zarqawi, a close AlQaida associate.
The Bush Administration and the press hascarelessly shorthanded this to mean, a senior Al Qaida mem-ber, ignoring the real ambiguities that surround the true natureof that association, and whether Zarqawi shares Al Qaidasends, or is receiving anything more than lodging inside Iraq.
]DocName: A-web_283330 ParaId: 7FIGURE 5: Partial answer generated by HITIQA to the al-Qaida training facilities questionDuring the dialogue, as new information is obtainedfrom the user, the Goal frame is updated and the scoresof all the data frames are reevaluated.
The system mayinterpret the new information as a positive or negative.Positives are added to the Goal frame.
Negatives arestored in a Negative-Goal frame and will also be used inthe re-scoring of the data frames, possibly causing con-flict scores to increase.
If the user responds the equiva-lent of ?yes?
to the system clarification question in Fig-ure 4, a corresponding WMD Transfer frame would beadded to the Goal frame and all WMD Transfer frameswill be re-scored.
If the user responds ?no?, the Nega-tive-Goal frame will be generated and all WMD Trans-fer frames will be rescored to 99 in order to removethem from further processing.
The user may end thedialogue, at any point and have an answer generatedgiven the current state of the frames.Currently, the answer is simply composed of textpassages from the zero conflict frames.
In addition,HITIQA will generate a ?headline?
for the text passagesin all the Frames in the answer space.
This is done us-ing grammar rules and the attributes of a frame.
Figure5 shows a portion of the answer generated by HITIQAfor the al-Qaida training facilities question.6   HITIQA InterfaceThere are two distinct ways for the user to interactwith HITIQA to explore their answer space.
The An-swer Panel displays the user?s current answer at anygiven time during the interaction for a single question.Through this panel the user can read the paragraphs thatare currently in their answer.
There are links on thispanel so the user is able to view the full original sourcedocument from which the passage(s) were extracted.The Visual panel offers the user an alternative toreading text by providing a tool for visually browsingthe entire answer space.
Figure 6 shows a typical viewof the visualization panel.
The spheres are representa-tive of single frames and groups of frames.
The user?sattention may be drawn to particular frames by the colorcoding or the attribute spikes.
The colors represent theframe?s score, so the user can quickly see what is intheir answer, blue, and what is not, all other colors.
Theattribute spikes may also be used as a navigation tool.The active attribute is chosen by the user through radiobuttons.
The current active attribute in Figure 6, is Lo-cation.
This displays all instances of locations men-tioned in the corresponding text.Figure 6: Frame Level DisplayThe underlying text that was used to build the framemay be displayed in the lower right hand window.
Inthis text display window there is a hyperlink that takesthe user directly to the full source document.
The user isable to interact with this panel by adding and removinginformation from their generated answer.
Moving fromthe visualization to the textual dialogue, the generatedanswer, and back is seamless in a sense that anychanges to the frame scores in one modality are imme-diately accessible to the user in another modality.
Userscan add and remove frames from the answer space andHITIQA will always seamlessly pickup a new dialogueor generate a new answer.7   HITIQA Qualitative EvaluationsIn order to assess our progress thus far, and to alsodevelop metrics to guide future evaluation, we invited agroup of analysts employed by the US government toparticipate in two three-day workshops held in Septem-ber and October 2003.The two basic objectives of the workshops were:1.
To perform a realistic assessment of the useful-ness and usability of HITIQA as an end-to-end system,from the information seeker's initial questions to com-pletion of a draft report.2.
To develop metrics to compare the answers ob-tained by different analysts and evaluate the quality ofthe support that HITIQA provides.Each of these objectives entails a particular chal-lenge.
Performing a realistic assessment of HITIQA isdifficult because many of the resources that the analystsuse, as well as the reports they produce, are classifiedand therefore inaccessible to researchers.Assessing the quality of the support that the systemprovides is not easy because analytical questions rarelyhave a single right answer.
It is not obvious how to de-fine, for example, the precision of the system.
We there-fore conducted an 'information unit' exercise, whosepurpose was to determine whether the analysts couldidentify information building blocks in their reports, sothat we could compare and contrast different reports.To obtain an adequate supply of appropriate textdata to support extensive question answering sessions(1, 2, 3 and 4 hours long), we prepared a new corpus ofapproximately 1.2 Gbytes.
This new corpus consists ofthe reports from the Center for Non-Proliferation Stud-ies (CNS) collected for the AQUAINT Program, aug-mented with a much larger collection of texts on similarsubject matter mined from the web using Google1.
Thefinal corpus proved to be sufficient to support aboutthree hours of use of HITIQA to ?solve?
each of thescenarios.The first day of the first workshop was devoted totraining, including a two-part proficiency test.
HITIQAis a fairly complex system, that includes multiple layersof data processing and user interaction, and it was criti-cal that the users are sufficiently ?fluent?
if we were tomeasure their productivity.
The analysts' primary taskon the second day was preparation of reports in re-sponse to the scenarios.1 Google has kindly agreed to temporarily extend ourusage license so we could collect the data over a shorttime.The third day was devoted to quantitative and quali-tative evaluation, discussed later.
In addition, we askedthe analysts to score each others reports, as well as toidentify key information units in them.
These informa-tion units could be later compared across different re-ports in order to determine their completeness.8   Workshop ResultsThe results of the quantitative evaluations strongly vali-date the approach that we have taken.
These conclusionsare confirmed by analysts comments gleaned both fromthe formal qualitative assessment and from informaldiscussion.
As one analyst said, ?the system as it standsnow, in my mind, gave me enough information to try toput together a 80% solution but ?I don't think you'reever gonna reach that 100% state.?
At the same time, welearned a great deal about how analysts work.It is important to determine the realism of the sce-narios used during the workshop relative to the analysts?current work tasks in order for any results to be mean-ingful.
Each analyst was asked a series of five questionssuch as, ?How realistic was the scenario?
In otherwords did it resemble tasks you could imagine perform-ing at work??
These 5 questions were all relative to therealism and difficulty of the scenario tasks.
Analystsused a scale of 1 to 5 based on their agreement with thestatements, where 5 was complete agreement.
Ourmean score was 3.84, indicating our scenarios were real-istic and of about average difficulty when compared tothe work they normally perform.We have classified the type of passages that an ana-lyst copied to their report into two categories, answerpassages and additional information passages, see Fig-ure 7 below.
The answer passages either exactly an-swered the user?s initial question or supplied supportinginformation.
The additional passages do not answer theoriginal question posed, but may have been added to theanswer through dialogue, or through the user?s explora-tion of document links offered.
This could be a piece ofinformation needed to satisfy some other aspect of thescenario that they had not asked about yet, or possibly atopic the user had not even considered but found rele-vant when it was presented to them.
As can be seenthere was a very large amount of ?additional?
informa-tion that the user copied to their report.
The amountsreported here are the averages for all of the analysts forboth workshops.
This supports our hypothesis that ana-lysts seldom seek just the exact answer, but they arealso looking at adjacent, related information, much ofwhich they retain for their report.
Note that there were asmall number of passages that contained a combinationof answer and additional information; these were addedto answer.Average Number of Passages Copied to Report2.8313.631.545.060.002.004.006.008.0010.0012.0014.0016.00answ er additionalPassage TypeNumber of Passagescopied f rom linkcopied f rom answ erFigure 7: Average Number of Passages CopiedTotal Passages Copied and Viewed: Analyst 2378 1628 272305024235215216 11 4 7 44927 26 34440501001502002503003504001 2 3 4 5ScenarioNumber of Passagespassages copied from linkspassages viewed from linkspassages copied from answerpassages viewed on answerFigure 8: Number of Passages Copied Vs. Those ViewedWe should now establish the number of passagescopied versus those viewed, relative to links and theanswer.
Figure 8 above shows the total number of pas-sages copied versus the total number of passagesviewed.
It is seen that many more passages need to beviewed through full document links before a useful pas-sage is found.
In comparison a much smaller number ofanswer passages need to be viewed from the Answerpanel in order to find useful passages.All of the analysts?
sessions were recorded usingCamtasia.
Figure 9 shows an annotation created for atypical session.
Analysts were observed to utilize arange of varying strategies as they worked differentscenarios and even while working different queries ofthe same scenario.
Figure 10 shows the statistics foreach Analyst?s use of HITIQA while working on thescenarios during the two workshops (note that Analyst-4was only able to attend the first workshop and Analyst-1did not create a report for Scenario 2).
Some of thevariations in strategies among the analysts while work-ing the same scenario are quite striking.
For example,Scenario 4 was  worked quite  differently  by  Analyst-1versus Analyst-2.
While Analyst-1 spent almost all ofhis/her  time in  the Visual Panel, Analyst-2 spent virtu-ally all of his/her time in the Answer panel.
Analyst-1produced his/her report copying 52 paragraphs whileAnalyst 2 copied only 35.
There are also large varia-tions in the number of questions asked for the same sce-nario.
Examine scenario 5, where Analyst-3 asked atotal of 11 questions and Analyst-2 only needed to ask 2questions.
Relative to this, Analyst-3, who asked amuch larger number of questions, copied only 28 pas-sages, whereas Analyst-2 copied 31.
These variations,as stated earlier in the paper, could be due to the natureof the task, the progress the analyst is making on thetask, in addition to individual differences between ana-lysts.
For example, the difference in the number ofquestions asked between Analyst-2 and Analyst-3 forscenario 5 may be due to difference in search strategiesemployed, but may also reflect the amount of back-ground knowledge of the topic.FIGURE 9: Fragment of an analytical sessionVariation of Strategies: Analyst 1805 5 518020524248041.58660.5120 16.67261101001 2 3 4 5ScenarioVariation of Strategies: Analyst 2543 325319 2035 3135 2947517612033100721101001 2 3 4 5Scenario101 115Variation of Strategies: Analyst 31234611581725 2428217197054651261101001 2 3 4 5ScenarioVariation of Strategies: Analyst 4230 0 0350 0 0370 0 0 036 400 0 0341101001 2 3 4 5Scenario# questions asked# passages copiedtime in visualtime in answerFigure 10: Varying Strategies EmployedUser: What is the status of South Africa's chemical,biological, and nuclear programs?Clarification Dialogue: 1 minute?
6 questions generated by HITIQA?
replied ?Yes?
to 5 and ?No?
to 1?
5+ passages added to answerStudying Answer Panel: 60 minutes?
Copying 24 passages to report?
10 from Answer?
14 from Links to Full Document?
Visual Panel Browsing: 5 minutes?
Nothing copiedUser: Has South Africa provided CBW material orassistance to any other countries?Clarification Dialogue: 1 minute?
5 questions generated by HITIQA?
replied ?Yes?
to 2 and ?No?
to 3?
2+ passages added to answerStudying Answer Panel: 26 minutes?
Copying 6 passages to report?
6 from Links to Full DocumentVisual Panel browsing: 1 minute?
Copying 1 passage to report?
1 from Links to Full DocumentUser: How was South Africa's CBW program fi-nanced?Clarification Dialogue: 40 seconds?
7 questions generated by HITIQA?
replied ?Yes?
to 3 and ?No?
to 4?
3+ passages added to answerStudying Answer Panel: 11 minutes?
Copying 3 passages to report?
1 from Answer2 from Links to full DocumentThere is, however, some consistency across the ana-lysts in the amount of information retained per scenario.The charts are drawn in logarithmic scale, but it shouldbe visible that scenarios 2 and 3 produced less interac-tion and required less information to fulfill than scenar-ios 4 and 5.
It is also visible that scenario 1 requiredmore questions to be asked and more exploration to bedone in visual panel than other scenarios.Finally, it is important to provide some metric re-garding the user?s overall satisfaction with their use ofHITIQA.
At the end of each workshop Analysts weregiven a series of 17 questions, such as ?HITIQA helpsme find important information?, shown in Figure 11, toassess their overall experience with the system.
Manyof these questions were designed for the user to com-pare HITIQA to the current tools they are using for thistype of task.
Analysts again used a scale of 1 to 5based on their agreement with the statements.
The re-sults were then converted, where 5 would always denotethe best, and are shown in Figure 11 below.
It is impor-tant to note that we scored highly overall, but addition-ally we scored highly in the majority of questions rela-tive to comparison of their current tools.
For example,for Question 14: ?Having HITIQA at work would helpme find information faster than I can currently find it?,our mean score was 3.83.3.7215702092Total3.003111174.1416162.86142153.83141143.16321134.14241124.00241114.007103.715293.292583.1433173.7115164.433454.2933144.141633.71141123.71611ScoreScore5Score4Score3Score2Score1QuestionMeanFrequency of Analyst's Scores of Overall Workshop I & II1                  2                 3                 4    5 scorefrequencyFIGURE 11: Final Evaluation Results, Workshop 1 & 2In summary, the results from these two evaluationsindicate that HITIQA, in its current state, is alreadycompetitive with the tools that the analysts are currentlyusing in their work, supporting our overall approach toAnalytical Question Answering.
HTIQA provides theuser with a tool to find the passages needed to completea report for a given scenario.
While working on a sce-nario HITIQA has been shown to provide informationwhich exactly answers the user?s question, and addi-tionally HITIQA?s method brings to light other relatedinformation that the analyst retains in order to completetheir report.AcknowledgementsThis paper is based on work supported by the AdvancedResearch and Development Activity (ARDA)?s AdvancedQuestion Answering for Intelligence (AQUAINT) Programunder contract number 2002-H790400-000.ReferencesAllen, J. and M. Core.
1997.
Draft of DAMSL:  Dialog Act Markup inSeveral Layers.
www.cs.rochester.edu/research/cisd/Baeza-Yates and Ribeiro-Neto.
1999.
Modern Information Retrieval.Addison Wesley.Chris Buckley.
1985.
Implementation of the Smart information re-trieval system.
Technical Report TR85-686, Department of Com-puter Science, Cornell University, Ithaca, NY.Ferguson, George and James Allen.
1998.
TRIPS: An Intelligent Inte-grated Problem-Solving Assistant, in Proceedings of the 15thAAAI Conference (AAAI-98), Madison, WI, pp.
567-573.Hardy, H., N. Shimizu, T. Strzalkowski, L. Ting, B.
Wise and X.Zhang.
2002a.
Cross-Document Summarization by Concept Clas-sification.
Proceedings of SIGIR, Tampere, Finland.Hardy, H., K. Baker, L. Devillers, L. Lamel, S. Rosset, T.Strzalkowski, C. Ursu and N. Webb.
2002b.
Multi-layer DialogueAnnotation for Automated Multilingual Customer Service.
ISLEWorkshop, Edinburgh, Scotland.Harabagiu, S., et.
al.
2002.
Answering Complex, List and Contextquestions with LCC?s Question Answering Server.
In Proceedingsof Text Retrieval Conference (TREC-10).Hovy, E., L. Gerber, U. Hermjakob, M. Junk, C-Y.
Lin.
2000.
Ques-tion Answering in Webclopedia.
Notebook.
Proceedings of TextRetrieval Conference (TREC-9).Humphreys, R. Gaizauskas, S. Azzam, C. Huyck, B. Mitchell, H.Cunningham, Y. Wilks.
1998.
Description of the LaSIE-II Systemas Used for MUC-7.
In Proceedings of the Seventh Message Un-derstanding Conference (MUC-7.
)Litman, Diane J. and Shimei Pan.
2002.
Designing and Evaluating anAdaptive Spoken Dialogue System.
User Modeling and User-Adapted Interaction.
Vol.
12, No.
2/3, pp.
111-137.Seneff, S. and J. Polifroni.
2000.
Dialogue Management in the MER-CURY Flight Reservation System.
Proc.
ANLP-NAACL 2000,Satellite Workshop, pp.
1-6, Seattle, WA.Small, Sharon, Nobuyuki Shimizu, Tomek Strzalkowski and Liu Ting(2003).
HITIQA: A Data Driven Approach to Interactive QuestionAnswering: A Preliminary Report.
AAAI Spring Symposium onNew Directions in Question Answering, Stanford University,March 24-26, 2003. pp.
94?104.Tang, Rong, K.B.
Ng, Tomek Strzalkowski and Paul Kantor (2003).Automatic Prediction of Information Quality in News Documents.Proceedings of HLT-NAACL 2003, Edmonton, May 27-June 1Walker, Marilyn A.
2002.
An Application of Reinforcement Learningto Dialogue Strategy Selection in a Spoken Dialogue System forEmail .
Journal of AI Research, vol 12., pp.
387-416.
