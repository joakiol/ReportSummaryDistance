The 7th Workshop on the Innovative Use of NLP for Building Educational Applications, pages 147?156,Montre?al, Canada, June 3-8, 2012. c?2012 Association for Computational LinguisticsGenerating Grammar ExercisesLaura Perez-BeltrachiniUniversite?
de LorraineLORIA, UMR 7503Vandoeuvre-le`s-NancyF-54500, Francelaura.perez@loria.frClaire GardentCNRS, LORIA, UMR 7503Vandoeuvre-le`s-NancyF-54500, Franceclaire.gardent@loria.frGerman KruszewskiInria, LORIA, UMR 7503Villers-le`s-NancyF-54600, Francegerman.kruszewski@inria.frAbstractGrammar exercises for language learning fallinto two distinct classes: those that are basedon ?real life sentences?
extracted from exist-ing documents or from the web; and those thatseek to facilitate language acquisition by pre-senting the learner with exercises whose syn-tax is as simple as possible and whose vo-cabulary is restricted to that contained in thetextbook being used.
In this paper, we in-troduce a framework (called GramEx) whichpermits generating the second type of gram-mar exercises.
Using generation techniques,we show that a grammar can be used tosemi-automatically generate grammar exer-cises which target a specific learning goal; aremade of short, simple sentences; and whosevocabulary is restricted to that used in a giventextbook.1 IntroductionTextbooks for language learning generally includegrammar exercises.
Tex?s French Grammar 1 for in-stance, includes at the end of each lecture, a set ofgrammar exercises which target a specific pedagog-ical goal such as learning the plural form of nouns1Tex?s French Grammar http://www.laits.utexas.edu/tex/ is an online pedagogical referencegrammar that combines explanations with surreal dialoguesand cartoon images.
Tex?s French Grammar is arranged likemany other traditional reference grammars with the parts ofspeech (nouns, verbs, etc.)
used to categorize specific grammaritems (gender of nouns, irregular verbs).
Individual grammaritems are carefully explained in English, then exemplified in adialogue, and finally tested in self-correcting, fill-in-the-blankexercises.or learning the placement of adjectives.
Figure 1shows the exercises provided by this book at the endof the lecture on the plural formation of nouns.
Asexemplified in this figure, these exercises markedlydiffer from more advanced learning activities whichseek to familiarise the learner with ?real world sen-tences?.
To support in situ learning, this latter typeof activity presents the learner with sentences drawnfrom the Web or from existing documents therebyexposing her to a potentially complex syntax and toa diverse vocabulary.
In contrast, textbook grammarexercises usually aim to facilitate the acquisition ofa specific grammar point by presenting the learnerwith exercises made up of short sentences involvinga restricted vocabulary.As shall be discussed in the next section, most ex-isting work on the generation of grammar exerciseshas concentrated on the automatic creation of thefirst type of exercises i.e., exercises whose sourcesentences are extracted from an existing corpus.
Inthis paper, we present a framework (called GramEx)which addresses the generation of the second type ofgrammar exercises used for language learning i.e.,grammar exercises whose syntax and lexicon arestrongly controlled.
Our approach uses generationtechniques to produce these exercises from an exist-ing grammar describing both the syntax and the se-mantics of natural language sentences.
Given a ped-agogical goal for which exercises must be produced,the GramEx framework permits producing Fill in theblank (FIB, the learner must fill a blank with an ap-propriate form or phrase) and Shuffle (given a set oflemmas or forms, the learner must use these to pro-duce a phrase) exercises that target that specific goal.147Give the plural form of the noun indicated in parentheses.Pay attention to both the article and the noun.1.
Bette aime _____ .
(le bijoux)2.
Fiona aime ______ .
(le cheval)3.
Joe-Bob aime ______ ame?ricaines.
(la bie`re)4.
Tex n?aime pas ______ .
(le choix)5.
Joe-Bob n?aime pas ______ difficiles.
(le cours)6.
Tammy n?aime pas ______ .
(l?ho?pital)7.
Eduard aime ______.
(le tableau)8.
Bette aime ______ de Tex.
(l?oeil)9.
Tex aime ______ franc?ais.
(le poe`te)10.
Corey aime ______ fra??ches.
(la boisson)11.
Tammy aime ______ ame?ricains.
(le campus)12.
Corey n?aime pas ______ .
(l?examen)Figure 1: Grammar exercises from the Tex?s French Grammar textbookThe exercises thus generated use a simple syntax andvocabulary similar to that used in the Tex?s FrenchGrammar textbook.We evaluate the approach on several dimensionsusing quantitative and qualitative metrics as well as asmall scale user-based evaluation.
And we show thatthe GramEx framework permits producing exercisesfor a given pedagogical goal that are linguisticallyand pedagogically varied.The paper is structured as follows.
We start bydiscussing related work (Section 2).
In Section 3,we present the framework we developed to generategrammar exercises.
Section 4 describes the exper-imental setup we used to generate exercise items.Section 5 reports on an evaluation of the exerciseitems produced and on the results obtained.
Section6 concludes.2 Related WorkA prominent strand of research in Computer AidedLanguage Learning (CALL) addresses the automa-tion of exercise specifications relying on NaturalLanguage Processing (NLP) techniques (Mitkov etal., 2006; Heilman and Eskenazi, 2007; Karama-nis et al, 2006; Chao-Lin et al, 2005; Coniam,1997; Sumita et al, 2005; Simon Smith, 2010; Linet al, 2007; Lee and Seneff, 2007).
Mostly, thiswork targets the automatic generation of so-calledobjective test items i.e., test items such as multiplechoice questions, fill in the blank and cloze exerciseitems, whose answer is strongly constrained and cantherefore be predicted and checked with high accu-racy.
These approaches use large corpora and ma-chine learning techniques to automatically generatethe stems (exercise sentences), the keys (correct an-swers) and the distractors (incorrect answers) thatare required by such test items.Among these approaches, some proposals targetgrammar exercises.
Thus, (Chen et al, 2006) de-scribes a system called FAST which supports thesemi-automatic generation of Multiple-Choice andError Detection exercises while (Aldabe et al, 2006)presents the ArikiTurri automatic question genera-tor for constructing Fill-in-the-Blank, Word Forma-tion, Multiple Choice and Error Detection exercises.These approaches are similar to the approach wepropose.
First, a bank of sentences is built which areautomatically annotated with syntactic and morpho-syntactic information.
Second, sentences are re-trieved from this bank based on their annotation andon the linguistic phenomena the exercise is meant toillustrate.
Third, the exercise question is constructedfrom the retrieved sentences.
There are importantdifferences however.First, in these approaches, the source sentencesused for building the test items are selected fromcorpora.
As a result, they can be very complexand most of the generated test items are targetedfor intermediate or advanced learners.
In addition,some of the linguistic phenomena included in thelanguage schools curricula may be absent or insuf-ficiently present in the source corpus (Aldabe et al,2006).
In contrast, our generation based approachpermits controlling both the syntax and the lexiconof the generated exercices.Second, while, in these approaches, the syntacticand morpho-syntactic annotations associated withthe bank sentences are obtained using part-of-speechtagging and chunking, in our approach, these areobtained by a grammar-based generation process.148As we shall see below, the information thus asso-ciated with sentences is richer than that obtained bychunking.
In particular, it contains detailed linguis-tic information about the syntactic constructs (e.g.,cleft subject) contained in the bank sentences.
Thispermits a larger coverage of the linguistic phenom-ena that can be handled.
For instance, we can re-trieve sentences which contain a relativised cleft ob-ject (e.g., This is the man whom Mary likes whosleeps) by simply stipulating that the retrieved sen-tences must be associated with the information CleftObject).To sum up, our approach differs from most exist-ing work in that it targets the production of syntac-tically and lexically controlled grammar exercisesrather than producing grammar exercises based onsentences extracted from an existing corpus.3 Generating ExercisesGiven a pedagogical goal (e.g., learning adjectivemorphology), GramEx produces a set of exerciseitems for practicing that goal.
The item can be ei-ther a FIB or a shuffle item; and GramEx producesboth the exercise question and the expected solution.To generate exercise items, GramEx proceeds inthree main steps as follows.
First, a generationbank is constructed using surface realisation tech-niques.
This generation bank stores sentences thathave been generated together with the detailed lin-guistic information associated by the generation al-gorithm with each of these sentences.
Next, sen-tences that permit exercising the given pedagogicalgoal are retrieved from the generation bank using aconstraint language that permits defining pedagog-ical goals in terms of the linguistic properties as-sociated by the generator with the generated sen-tences.
Finally, exercises are constructed from theretrieved sentences using each retrieved sentence todefine FIB and Shuffle exercises; and the sentenceitself as the solution to the exercise.We now discuss each of these steps in more detail.3.1 Constructing a Generation bankThe generation bank is a database associating sen-tences with a representation of their semantic con-tent and a detailed description of their syntactic andmorphosyntactic properties.
In other words, a gen-Sentence realisation:?Tammy a une voix douce?Lemma-features pairs:{?lemma?
: ?Tammy?,?lemma-features?
: {anim:+,num:sg,det: +,wh:-,cat:n,func:suj,xp: +, gen:f},?trace?
: {propername}},{?lemma?
: ?avoir?,?lemma-features?
: {aux-refl:-,inv:-,cat:v,pers:3,pron:-,num:sg,mode:ind, aspect:indet,tense:pres,stemchange:-,flexion:irreg},?trace?
: {CanonicalObject,CanonicalSubject,n0Vn1}},{?lemma?
: ?un?,?lemma-features?
: {wh:-,num:sg,mass:-,cat:d,gen:f,def:+},?trace?
: {determiner}},{?lemma?
: ?voix?,?lemma-features?
: {bar:0,wh:-,cat:n,num:sg,mass:-,gen:f,flexion:irreg,?trace?
: {noun}},{?lemma?
: ?doux?,?lemma-features?
: {num:sg,gen:f,flexion:irreg,cat:adj},?trace?
: {Epith,EpithPost}}Figure 2: Morphosyntactic information associated byGraDe with the sentence Tammy a un voix douceeration bank is a set of (Si, Li, ?i) tuples where Si isa sentence, Li is a set of linguistic properties true ofthat sentence and ?i is its semantic representation.To produce these tuples, we use the GraDe gram-mar traversal algorithm described in (Gardent andKruszewski, 2012).
Given a grammar and a setof user-defined constraints, this algorithm gener-ates sentences licensed by this grammar.
The user-defined constraints are either parameters designed toconstrain the search space and guarantee termina-tion (e.g., upper-bound on the number and type ofrecursive rules used or upper-bound on the depth ofthe tree build by GraDe); or linguistic parameterswhich permit constraining the output (e.g., by spec-ifying a core semantics the output must verbalise orby requiring the main verb to be of a certain type).Here we use GraDe both to generate from manu-ally specified semantic input; and from a grammar(in this case an existing grammar is used and nomanual input need to be specified).
As explainedin (Gardent and Kruszewski, 2012), when generat-ing from a semantic representation, the output sen-tences are constrained to verbalise that semantics butthe input semantics may be underspecified therebyallowing for morpho-syntactic, syntactic and tem-poral variants to be produced from a single se-mantics.
For instance, given the input semantics149L1:named(J bette n) A:le d(C RH SH) B:bijou n(C)G:aimer v(E J C), GraDe will output among othersthe following variants:Bette aime le bijou (Bette likes the jewel),Bette aime les bijoux (Bette likes the jewels),C?est Bette qui aime le bijou (It is Bette wholikes the jewel), C?est Bette qui aime les bijoux(It is Bette who likes the jewel), Bette aimait lebijou (Bette liked the jewel), Bette aimait lesbijoux (Bette liked the jewels), ...When generating from the grammar, the outputis even less constrained since all derivations com-patible with the user-defined constraints will be pro-duced irrespective of semantic content.
For instance,when setting GraDe with constraints restricting thegrammar traversal to only derive basic clauses con-taining an intransitive verb, the output sentences in-clude among others the following sentences:Elle chante (She sings), La tatou chante-t?elle?
(Does the armadillo sing?
), La tatou chante(The armadillo sings), Chacun chante -t?il(Does everyone sing?
), Chacun chante (Ev-eryone sings), Quand chante la tatou?
(Whendoes the armadillo sing?
), ...Figure 2 shows the linguistic properties associ-ated with the sentence Tammy a une voix douce(Tammy has a soft voice) by GraDe.
To gener-ate exercises, GramEx makes use of the morpho-syntactic information associated with each lemmai.e., the feature-value pairs occurring as values of thelemma-features fields; and of their linguistic proper-ties i.e., the items occurring as values of the tracefields.3.2 Retrieving Appropriate SentencesTo enable the retrieval of sentences that are appropri-ate for a given pedagogical goal, we define a querylanguage on the linguistic properties assigned byGraDe to sentences.
We then express each peda-gogical goal as a query in that language; and we usethese queries to retrieve from the generation bankappropriate source sentences.
For instance, to re-trieve a sentence for building a FIB exercise wherethe blank is a relative pronoun, we query the gen-eration bank with the constraint RelativePronoun.This will return all sentences in the generation bankwhose trace field contains the RelativePronounitem i.e., all sentences containing a relative pronoun.We then use this sentence to build both the exercisequestion and its solution.3.2.1 GramEx Query LanguageWe now define the query language used to retrievesentences that are appropriate to build an exercisefor a given pedagogical goal.
Let B be a genera-tion bank and let (Si, Li, ?i) be the tuples stored inB.
Then, a GramEx query q permits retrieving fromB the set of sentences Si ?
(Si, Li, ?i) such thatLi satisfies q.
In other words, GramEx queries per-mit retrieving from the generation bank all sentenceswhose linguistic properties satisfy those queries.The syntax of the GramEx query language is asfollows:BoolExpr ?
BoolTermBoolTerm ?
BoolFactor | BoolTerm ?
BoolFactorBoolFactor ?
BoolUnary | BoolFactor ?
BoolUnaryBoolUnary ?
BoolPrimary | ?
BoolPrimaryBoolPrimary ?
PrimitiveCond | ( BoolExpr ) | [ BoolExpr ]PrimitiveCond ?
traceItem | feature = valueIn words: the GramEx query language permitsdefining queries that are arbitrary boolean con-straints on the linguistic properties associated byGraDe with each generated sentence.
In addi-tion, complex constraints can be named and reused(macros); and expressions can be required to holdon a single lexical item ([ BoolExpr] indicates thatBoolExpr should be satisfied by the linguistic prop-erties of a single lexical item).The signature of the language is the set of gram-matical (traceItem) and morpho-syntactic proper-ties (feature = value) associated by GraDe witheach generated sentence where traceItem is anyitem occurring in the value of a trace field andfeature = value any feature/value pair occurringin the value of a lemma-features field (cf.
Fig-ure 2).
The Table below (Table 1) shows some of theconstraints that can be used to express pedagogicalgoals in the GramEx query language.3.2.2 Query ExamplesThe GramEx query language allows for very spe-cific constraints to be expressed thereby providingfine-grained control over the type of sentences andtherefore over the types of exercises that can be pro-duced.
The following example queries illustrate this.150Grammatical Properties (traceItem)Argument Cleft, CleftSUbj, CleftOBJ, ...,Realisation InvertedSubjQuestioned, QuSubj, ...Relativised, RelSubj ...Pronominalised, ProSubj, ...Voice Active, Passive, ReflexiveAux tse, modal, causalAdjective Predicative,Pre/Post nominalAdverb Sentential, VerbalMorpho-Syntactic Properties (feature=value)Tense present,future,pastNumber mass, count, plural, singularInflexion reg,irregTable 1: Some grammatical and morpho-syntactic prop-erties that can be used to specify pedagogical goals.
(1) a. EpithAnteTex pense que Tammy est une jolie tatou (Texthinks that Tammy is a pretty armadillo)b.
[Epith ?
flexion: irreg]Tex et Tammy ont une voix douce (Tex andTammy have a soft voice)c. POBJinf ?
CLAUSEPOBJinf ?
(DE-OBJinf ?
A-OBJinf)CLAUSE ?
Vfin?
?Mod ?
?CCoord?
?SubTammy refuse de chanter (Tammy refuses tosing)Query (1a) shows a query for retrieving sentencescontaining prenominal adjectives which uses thegrammatical (traceItem) property EpithAnte associ-ated with preposed adjectives.In contrast, Query (1b) uses both grammatical andmorpho-syntactic properties to retrieve sentencescontaining a postnominal adjective with irregular in-flexion.
The square brackets in the query force theconjunctive constraint to be satisfied by a single lex-ical unit.
That is, the query will be satisfied by sen-tences containing a lexical item that is both a post-nominal adjective and has irregular inflexion.
Thisexcludes sentences including e.g., a postnominal ad-jective and a verb with irregular inflexion.Finally, Query (1c) shows a more complex casewhere the pedagogical goal is defined in terms ofpredefined macros themselves defined as GramExquery expressions.
The pedagogical goal is de-fined as a query which retrieves basic clauses(CLAUSE) containing a prepositional infinitival ob-ject (POBJinf).
A sentence containing a preposi-tional infinitival object is in turn defined (secondline) as a prepositional object introduced either bythe de or the a` preposition.
And a basic clause (3rdline) is defined as a sentence containing a finite verband excluding modifiers, clausal or verb phrase co-ordination (CCORD) and subordinated clauses23.3 Building Exercise ItemsIn the previous section, we saw the mechanism usedfor selecting an appropriate sentence for a givenpedagogical goal.
GramEx uses such selected sen-tences as source or stem sentences to build exerciseitems.
The exercise question is automatically gen-erated from the selected sentence based on its asso-ciated linguistic properties.
Currently, GramEx in-cludes two main types of exercises namely, Fill inthe blank and Shuffle exercises.FIB questions.
FIB questions are built by remov-ing a word from the target sentence and replacing itwith either: a blank (FIBBLNK), a lemma (FIBLEM)or a set of features used to help the learner guessthe solution (FIBHINT).
For instance, in an exerciseon pronouns, GramEx will use the gender, numberand person features associated with the pronoun bythe generation process and display them to specifywhich pronominal form the learner is expected toprovide.
The syntactic representation (cf.
Figure 2)associated by GraDe with the sentence is used tosearch for the appropriate key word to be removed.For instance, if the pedagogical goal is Learn Sub-ject Pronouns and the sentence retrieved from thegeneration bank is that given in (2a), GramEx willproduce the FIBHINT question in (2b) by search-ing for a lemma with category cl (clitic) and featurefunc=subj and using its gender value to provide thelearner with a hint constraining the set of possiblesolutions.
(2) a. Elle adore les petits tatous(She loves small armadillos)b.
... adore les petits tatous (gender=fem)Shuffle questions.
Similarly to FIB questions,shuffle exercise items are produced by inspectingand using the target derivational information.
Morespecifically, lemmas are retrieved from the list of2The expressions CCoord and Sub are themselves definedrather than primitive expressions.151lemma-feature pairs.
Function words are (option-ally) deleted.
And the remaining lemmas are ?shuf-fled?
(MSHUF).
For instance, given the source sen-tence (2a), the MSHUF question (2b) can be pro-duced.
(3) a. Tammy adore la petite tatoua.
tatou / adorer / petit / TammyNote that in this case, there are several possiblesolutions depending on which tense and number isused by the learner.
For such cases, we can eitheruse hints as shown above to reduce the set of pos-sible solutions to one; or compare the learner?s an-swer to the set of output produced by GraDe for thesemantics the sentence was produced from.4 Experimental SetupWe carried out an experiment designed to assess theexercises produced by GramEx.
In what follows, wedescribe the parameters of this experiment namely,the grammar and lexicons used; the input and theuser-defined parameters constraining sentence gen-eration; and the pedagogical goals being tested.4.1 Grammar and LexiconThe grammar used is a Feature-Based LexicalisedTree Adjoining Grammar for French augmentedwith a unification-based compositional semantics.This grammar contains around 1300 elementarytrees and covers auxiliaries, copula, raising andsmall clause constructions, relative clauses, infini-tives, gerunds, passives, adjuncts, wh-clefts, PROconstructions, imperatives and 15 distinct subcate-gorisation frames.The syntactic and morpho-syntactic lexicons usedfor generating were derived from various existinglexicons, converted to fit the format expected byGraDe and tailored to cover basic vocabulary as de-fined by the lexicon used in Tex?s French Grammar.The syntactic lexicon contains 690 lemmas and themorphological lexicon 5294 forms.4.2 Pedagogical GoalsWe evaluate the approach on 16 pedagogical goalstaken from the Tex?s French Grammar book.
Foreach of these goals, we define the correspondinglinguistic characterization in the form of a GramExquery.
We then evaluate the exercises produced bythe system for each of these queries.
The pedagog-ical goals tested are the following (we indicate inbrackets the types of learning activity produced foreach teaching goal by the system):?
Adjectives: Adjective Order (MSHUF), Adjec-tive Agreement (FIBLEM), Prenominal adjec-tives (FIBLEM), Present and Past Participialused as adjectives (FIBLEM), Regular and Ir-regular Inflexion (FIBLEM), Predicative adjec-tives (MSHUF)?
Prepositions: Prepositional Infinitival Object(FIBBLNK), Modifier and Complement Prepo-sitional Phrases (FIBBLNK)?
Noun: Gender (FIBLEM), Plural form (FI-BLEM), Subject Pronoun (FIBHINT).?
Verbs: Pronominals (FIBLEM), -ir Verbs inthe present tense (FIBLEM), Simple past (FI-BLEM), Simple future (FIBLEM), SubjunctiveMode (FIBLEM).4.3 GraDe?s Input and User-DefinedParametersGraDe?s configuration As mentioned in Sec-tion 3, we run GraDe using two main configura-tions.
In the first configuration, GraDe search is con-strained by an input core semantics which guides thegrammar traversal and forces the output sentence toverbalise this core semantics.
In this configuration,GraDe will only produce the temporal variationssupported by the lexicon (the generated sentencesmay be in any simple tense i.e., present, future,simple past and imperfect) and the syntactic varia-tions supported by the grammar for the same MRSs(e.g., active/passive voice alternation and cleft argu-ments).Greater productivity (i.e., a larger output/input ra-tio) can be achieved by providing GraDe with lessconstrained input.
Thus, in the second configura-tion, we run GraDe not on core semantics but on thefull grammar.
To constrain the search, we specify aroot constraint which requires that the main verb ofall output sentences is an intransitive verb.
We alsoset the constraints on recursive rules so as to excludethe inclusion of modifiers.
In sum, we ask GraDe toproduce all clauses (i) licensed by the grammar andthe lexicon; (ii) whose verb is intransitive; and (iii)152which do not include modifiers.
Since the numberof sentences that can be produced under this con-figuration is very large, we restrict the experimentby using a lexicon containing a single intransitiveverb (chanter/To sing), a single common noun and asingle proper name.
In this way, syntactically struc-turally equivalent but lexically distinct variants areexcluded.Input Semantics We use two different sets of in-put semantics for the semantically guided configura-tion: one designed to test the pedagogical coverageof the system (Given a set of pedagogical goals, canGramEx generate exercises that appropriately targetthose goals?
); and the other to illustrate linguisticcoverage (How much syntactic variety can the sys-tem provide for a given pedagogical goal?
).The first set (D1) of semantic representations con-tains 9 items representing the meaning of exam-ple sentences taken from the Tex?s French Gram-mar textbook.
For instance, for the first itemin Figure 1, we use the semantic representationL1:named(J bette n) A:le d(C RH SH) B:bijou n(C)G:aimer v(E J C).
With this first set of input seman-tics, we test whether GramEx correctly produces theexercises proposed in the Tex?s French Grammarbook.
Each of the 9 input semantics corresponds toa distinct pedagogical goal.The second set (D2) of semantic representationscontains 22 semantics, each of them illustrating dis-tinct syntactic configurations namely, intransitive,transitive and ditransitive verbs; raising and control;prepositional complements and modifiers; sententialand prepositional subject and object complements;pronominal verbs; predicative, attributive and par-ticipial adjectives.
With this set of semantics, weintroduce linguistically distinct material thereby in-creasing the variability of the exercises i.e., makingit possible to have several distinct syntactic configu-rations for the same pedagogical goal.5 Evaluation, Results and DiscussionUsing the experimental setup described in the previ-ous section, we evaluate GramEx on the followingpoints:?
Correctness: Are the exercises produced by thegenerator grammatical, meaningful and appro-priate for the pedagogical goal they are associ-ated with??
Variability: Are the exercises produced linguis-tically varied and extensive?
That is, do the ex-ercises for a given pedagogical goal instantiatea large number of distinct syntactic patterns??
Productivity: How much does GramEx supportthe production, from a restricted number of se-mantic input, of a large number of exercises?Correctness To assess correctness, we randomlyselected 10 (pedagogical goal, exercise) pairs foreach pedagogical goal in Section 4.2 and asked twoevaluators to say for each pair whether the exer-cise text and solutions were grammatical, meaning-ful (i.e., semantically correct) and whether the ex-ercise was adequate for the pedagogical goal.
Theresults are shown in Table 3 and show that the sys-tem although not perfect is reliable.
Most sources ofgrammatical errors are cases where a missing wordin the lexicon fails to be inflected by the generator.Cases where the exercise is not judged meaningfulare generally cases where a given syntactic construc-tion seems odd for a given semantics content.
Forinstance, the sentence C?est Bette qui aime les bi-joux (It is Bette who likes jewels) is fine but C?estBette qui aime des bijoux although not ungrammati-cal sounds odd.
Finally, cases judged inappropriateare generally due to an incorrect feature being as-signed to a lemma.
For instance, avoir (To have) ismarked as an -ir verb in the lexicon which is incor-rect.Grammatical Meaningful Appropriate91% 96% 92%Table 3: Exercise Correctness tested on 10 randomly se-lected (pedagogical goal, exercise pairs)We also asked a language teacher to examine 70exercises (randomly selected in equal number acrossthe different pedagogical goals) and give her judg-ment on the following three questions:?
A.
Do you think that the source sentence se-lected for the exercise is appropriate to practicethe topic of the exercise?
Score from 0 to 3 ac-cording to the degree (0 inappropriate - 3 per-fectly appropriate)153Nb.
Ex.
1 2 4 5 6 12 17 18 20 21 23 26 31 37 138Nb.
Sem 1 4 6 1 4 3 1 1 1 1 1 1 1 1 1Table 2: Exercise Productivity: Number of exercises produced per input semantics?
B.
The grammar topic at hand together withthe complexity of the source sentence makethe item appropriate for which language level?A1,A2,B1,B2,C13?
C. Utility of the exercise item: ambiguous (notenough context information to solve it) / correctFor Question 1, the teacher graded 35 exercises as3, 20 as 2 and 14 as 1 pointing to similar problemsas was independently noted by the annotators above.For question B, she marked 29 exercises as A1/A2,24 as A2, 14 as A2/B1 and 3 as A1 suggesting thatthe exercises produced are non trivial.
Finally, shefound that 5 out of the 70 exercises lacked contextand were ambiguously phrased.Variability For any given pedagogical goal, thereusually are many syntactic patterns supporting learn-ing.
For instance, learning the gender of commonnouns can be practiced in almost any syntactic con-figuration containing a common noun.
We assess thevariability of the exercises produced for a given ped-agogical goal by computing the number of distinctmorpho-syntactic configurations produced from agiven input semantics for a given pedagogical goal.We count as distinct all exercise questions that arederived from the same semantics but differ eitherin syntax (e.g., passive/active distinction) or in mor-phosyntax (determiner, number, etc.).
Both types ofdifferences need to be learned and therefore produc-ing exercises which, for a given pedagogical goal,expose the learner to different syntactic and morpho-syntactic patterns (all involving the construct to belearned) is effective in supporting learning.
How-ever we did not take into account tense differencesas the impact of tense on the number of exercisesproduced is shown by the experiment where we gen-erate by traversing the grammar rather than from a3A1, A2, B1, B2 and C1 are reference levels establishedby the Common European Framework of Reference forLanguages: Learning, Teaching, Assessment (cf.
http://en.wikipedia.org/wiki/Common_European_Framework_of_Reference_for_Languages) forgrading an individual?s language proficiency.semantics.
Table 4 shows for each (input semantics,teaching goal) pair the number of distinct patternsobserved.
The number ranges from 1 to 21 distinctpatterns with very few pairs (3) producing a singlepattern, many (33) producing two patterns and a fairnumber producing either 14 or 21 patterns.Nb.
PG 1 2 3 4 5 6Nb.
sent 213 25 8 14 10 6Table 6: Pedagogical Productivity: Number of TeachingGoals the source sentence produced from a given seman-tics can be used forProductivity When used to generate from seman-tic representations (cf.
Section 4.3), GramEx onlypartially automates the production of grammar ex-ercises.
Semantic representations must be manuallyinput to the system for the exercises to be generated.Therefore the issue arises of how much GramExhelps automating exercise creation.
Table 5 showsthe breakdown of the exercises produced per teach-ing goal and activity type.
In total, GramEx pro-duced 429 exercises out of 28 core semantics yield-ing an output/input ratio of 15 (429/28).
Further, Ta-ble 2 and 6 show the distribution of the ratio be-tween (i) the number of exercises produced and thenumber of input semantics and (ii) the number ofteaching goals the source sentences produced frominput semantics i can be used for.
Table 6 (peda-gogical productivity) shows that, in this first exper-iment, a given input semantics can provide materialfor exercises targeting up to 6 different pedagogi-cal goals while Table 2 (exercise productivity) showsthat most of the input semantics produce between 2and 12 exercises4.When generating by grammar traversal, under theconstraints described in Section 4, from one input4If the input semantics contains a noun predicate whose gen-der is underspecified, the exercise productivity could be dou-bled.
This is the case for 4 of the input semantics in the datasetD2; i.e.
an input semantics containing the predicates tatou n(C)petit a(C) will produce variations such as: la petite tatou (thesmall armadillo (f)) and le petit tatou (the small armadillo (m)).154Nb.
SP 1 2 3 4 5 6 7 8 9 10 14 21(S,G) 3 33 16 7 2 4 6 1 4 1 2 6Table 4: Variability: Distribution of the number of distinct sentential patterns that can be produced for a given peda-gogical goal from a given input semanticsPedagogical Goal FIBLEM FIBBLNK MSHUF FIBHINTPreposition ?
28 ?
?Prepositions with infinitives ?
8 ?
?Subject pronouns?il ?
?
?
3Noun number 11 ?
?
?Noun gender ?
49 ?
?Adjective order ?
?
30 ?Adjective morphology 30 ?
?
?Adjectives that precede the noun 24 ?
?
?Attributive Adjectives ?
?
28 ?Irregular adjectives 4 ?
?
?Participles as adjectives 4 ?
?
?Simple past 78 ?
?
?Simple future 90 ?
?
?-ir verbs in present 18 ?
?
?Subjunctive mode 12 ?
?
?Pronominal verbs 12 ?
?
?Total 236 78 30 3Table 5: Number and Types of Exercises Produced from the 28 input semantics90 exercises are generated targeting 4 different ped-agogical goals (i.e.
4 distinct linguistic phenomena).6 ConclusionWe presented a framework (called GramEx) for gen-erating grammar exercises which are similar to thoseoften used in textbooks for second language learn-ing.
These exercises target a specific learning goal;and, they involve short sentences that make it eas-ier for the learner to concentrate on the grammaticalpoint to be learned.One distinguishing feature of the approach is therich linguistic information associated by the gen-erator with the source sentences used to constructgrammar exercises.
Although space restriction pre-vented us from showing it here, this informationincludes, in addition to the morphosyntactic infor-mation and the grammatical properties illustrated inFigure 2 and Table 1 respectively, a semantic rep-resentation, a derivation tree showing how the parsetree of each sentence was obtained and optionally,an underspecified semantics capturing the core pred-icate/argument and modifier/modifiee relationshipsexpressed by each sentence.
We are currently ex-ploring how this information could be used to ex-tend the approach to transformation exercises (e.g.,passive/active) where the relation between exercisequestion and exercise solution is more complex thanin FIB exercises.Another interesting question which needs furtherinvestigation is how to deal with exercise items thathave multiple solutions such as example (3) above.Here we plan to use the fact that underspecified se-mantics in GraDe permits associating many variantswith a given semantics.AcknowledgmentsWe would like to thank the language teacher, Tex?sFrench Grammar developers, and the anonymous re-viewers for their useful comments.
The researchpresented in this paper was partially supportedby the European Fund for Regional Developmentwithin the framework of the INTERREG IV A Alle-gro Project5.5http://www.allegro-project.eu/ and http://talc.loria.fr/-ALLEGRO-Nancy-.html155ReferencesItziar Aldabe, Maddalen Lopez de Lacalle, Montse Mar-itxalar, Edurne Martinez, and Larraitz Uria.
2006.Arikiturri: an automatic question generator based oncorpora and nlp techniques.
In Proceedings of the8th international conference on Intelligent TutoringSystems, ITS?06, pages 584?594, Berlin, Heidelberg.Springer-Verlag.Liu Chao-Lin, Wang Chun-Hung, Gao Zhao-Ming, andHuang Shang-Ming.
2005.
Applications of lexicalinformation for algorithmically composing multiple-choice cloze items.
In Proceedings of the secondworkshop on Building Educational Applications Us-ing NLP, EdAppsNLP 05, pages 1?8, Stroudsburg, PA,USA.
Association for Computational Linguistics.Chia-Yin Chen, Hsien-Chin Liou, and Jason S. Chang.2006.
Fast: an automatic generation system for gram-mar tests.
In Proceedings of the COLING/ACL onInteractive presentation sessions, COLING-ACL ?06,pages 1?4, Stroudsburg, PA, USA.
Association forComputational Linguistics.David Coniam.
1997.
A preliminary inquiry into usingcorpus word frequency data in the automatic genera-tion of english language cloze tests.
CALICO Journal,14:15?33.Claire Gardent and German Kruszewski.
2012.
Gener-ation for grammar engineering.
In 11th InternationalConference on Natural Language Generation (ENLG).Michael Heilman and Maxine Eskenazi.
2007.
Ap-plication of automatic thesaurus extraction for com-puter generation of vocabulary questions.
In Proceed-ings of Speech and Language Technology in Education(SLaTE2007), pages 65?68.Nikiforos Karamanis, Le An Ha, and Ruslan Mitkov.2006.
Generating multiple-choice test items frommedical text: A pilot study.
In Proceedings of theFourth International Natural Language GenerationConference, pages 111?113, Sydney, Australia.John Lee and Stephanie Seneff.
2007.
Automatic gener-ation of cloze items for prepositions.
Proceedings ofInterspeech, pages 2173?2176.Yi-Chien Lin, Li-Chun Sung, and Meng Chang Chen.2007.
An Automatic Multiple-Choice Question Gen-eration Scheme for English Adjective Understandings.In Workshop on Modeling, Management and Gener-ation of Problems/Questions in eLearning, the 15thInternational Conference on Computers in Education(ICCE 2007), pages pages 137?142.Ruslan Mitkov, Le An Ha, and Nikiforos Karamanis.2006.
A computer-aided environment for generatingmultiple-choice test items.
Natural Language Engi-neering, 12(2):177?194.Adam Kilgarriff Simon Smith, P.V.S Avinesh.
2010.Gap-fill Tests for Language Learners: Corpus-DrivenItem Generation.
In Proceedings of ICON-2010: 8thInternational Conference on Natural Language Pro-cessing.Eiichiro Sumita, Fumiaki Sugaya, and Seiichi Ya-mamoto.
2005.
Measuring non-native speakers?
pro-ficiency of english by using a test with automatically-generated fill-in-the-blank questions.
In Proceedingsof the second workshop on Building Educational Ap-plications Using NLP, EdAppsNLP 05, pages 61?68,Stroudsburg, PA, USA.
Association for ComputationalLinguistics.156
