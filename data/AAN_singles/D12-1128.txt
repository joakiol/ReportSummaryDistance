Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational NaturalLanguage Learning, pages 1399?1410, Jeju Island, Korea, 12?14 July 2012. c?2012 Association for Computational LinguisticsJoining Forces Pays Off: Multilingual Joint Word Sense DisambiguationRoberto Navigli and Simone Paolo PonzettoDipartimento di InformaticaSapienza Universita` di Roma{navigli,ponzetto}@di.uniroma1.itAbstractWe present a multilingual joint approachto Word Sense Disambiguation (WSD).
Ourmethod exploits BabelNet, a very large mul-tilingual knowledge base, to perform graph-based WSD across different languages, andbrings together empirical evidence from theselanguages using ensemble methods.
The re-sults show that, thanks to complementingwide-coverage multilingual lexical knowledgewith robust graph-based algorithms and com-bination methods, we are able to achieve thestate of the art in both monolingual and multi-lingual WSD settings.1 IntroductionNowadays the textual information needed by a useraccessing websites for content such as news re-ports, commentaries and encyclopedic knowledgeis provided in an increasingly wide range of lan-guages.
For example, even though English is stillthe majority language of the Web, the Chinese andSpanish languages are moving fast to capture their?juicy share?, and more languages are about to jointhem in the near future.
This language explosionclearly forces researchers to focus on the challeng-ing problem of being able to analyze and under-stand text written in any language.
However, it alsoopens up novel perspectives for multilingual NaturalLanguage Processing (NLP) such as, for instance,the development of approaches aimed at ?joiningforces?
and taking advantage of the lexico-semanticknowledge provided in the different languages toimprove text understanding.
These two aspects arestrongly intertwined: on the one hand, enablinglanguage-independent text understanding would al-low for the harvesting of more knowledge in arbi-trary languages, while, on the other hand, bringingtogether the lexical and semantic information avail-able in different languages would improve the qual-ity of text understanding in arbitrary languages.However, these two goals have hitherto neverbeen achieved, as is attested to by the fact that re-search in a core language understanding task such asWord Sense Disambiguation (Navigli, 2009, WSD)has always been focused mostly on English.
His-torically, English became established as the lan-guage used and understood by the scientific com-munity and, consequently, most resources were de-veloped for it, including large-scale computationallexicons like WordNet (Fellbaum, 1998) and sense-tagged corpora like SemCor (Miller et al 1993).As a result WSD in other languages was hinderedby a lack of resources, which in turn led to poor re-sults or low involvement on the part of the researchcommunity (Magnini et al 2004; Ma`rquez et al2004; Orhan et al 2007; Okumura et al 2010).Nonetheless, already in the 1990s it had been re-marked that WSD could be improved by means ofmultilingual information: a recurring idea proposedby several researchers was that plausible transla-tions of a word in context would restrict its pos-sible senses to a manageable subset of meanings(Dagan et al 1991; Gale et al 1992; Resnik andYarowsky, 1999).
While the lack of resources at thattime hampered the development of effective multi-lingual approaches to WSD, recently this idea hasbeen revamped with the organization of SemEvaltasks dealing with cross-lingual WSD (Lefever andHoste, 2010) and cross-lingual lexical substitution(Mihalcea et al 2010).
At the same time, new re-1399search on the topic has been done, including the useof statistical translations of sentences into many lan-guages as features for supervised models (Banea andMihalcea, 2011; Lefever et al 2011), and the pro-jection of monolingual knowledge onto another lan-guage (Khapra et al 2011).Yet the above two goals, i.e., disambiguating inan arbitrary language and using lexical and seman-tic knowledge from many languages in a joint wayto improve the WSD task, have not hitherto beenattained.
In this paper, we address both objectivesand propose a graph-based approach to multilingualjoint Word Sense Disambiguation.
Our proposalbrings together the lexical knowledge from differ-ent languages by exploiting empirical evidence fordisambiguation from each of them, and then com-bining this information in a synergistic way: eachlanguage provides a piece of sense evidence for themeaning of a target word in context, and subsequentintegration of these various pieces enables them to(soft) constrain each other.
The results show thatthis way we are able to improve over previous, high-performing graph-based methods in both a monolin-gual and multilingual setting, thus showing for thefirst time the beneficial effects of exploiting multi-lingual knowledge in a joint fashion.2 Related WorkParallel corpora have been used in the literaturefor the automatic creation of a sense-tagged datasetfor supervised WSD in different languages (Galeet al 1992; Chan and Ng, 2005; Zhong and Ng,2009).
Other approaches include the use of a coher-ence index for identifying the tendency to lexicalizesenses differently across languages (Ide, 2000) andthe clustering of source words which translate intothe same target word, then used to perform WSDusing a similarity measure (Diab, 2003).
A histori-cal approach (Brown et al 1991) uses bilingual cor-pora to perform unsupervised word alignment anddetermine the most appropriate translation for a tar-get word from a set of contextual features.All the above approaches to multilingual or cross-lingual WSD rely on bilingual corpora, includingthose which exploit existing multilingual WordNet-like resources (Ide et al 2002), or use automaticallyinduced multilingual co-occurrence graphs (Silbererand Ponzetto, 2010).
However, this requirement isoften very hard to satisfy, especially if we need widecoverage.
To overcome this limitation, in this workwe make use of BabelNet (Navigli and Ponzetto,2010), a very large multilingual lexical knowledgebase.
This resource ?
complementary in natureto other recent efforts presented by de Melo andWeikum (2010), Nastase et al(2010) and Meyer andGurevych (2012), inter alia ?
provides a truly multi-lingual semantic network by combining Wikipedia?smultilinguality with the output of a state-of-the-artmachine translation system to achieve high cover-age for all languages.
The key insight here is thatWord Sense Disambiguation and Machine Transla-tion (MT) are highly intertwined tasks, as previouslyshown by Carpuat and Wu (2007) and Chan et al(2007), who successfully used sense information toboost state-of-the-art statistical MT.
In this work wefocus instead on the benefits of using multilingualinformation for WSD by exploiting the structure ofa multilingual semantic network.3 Multilingual Joint WSDWe present our methodology for multilingual WSD:we first introduce BabelNet, the resource used in ourwork (Section 3.1) and then present our algorithmfor multilingual joint WSD (Section 3.2), includingits main components, namely graph-based WSD, en-semble methods and translation weighting (sections3.3, 3.4 and 3.5).3.1 BabelNetBabelNet (Navigli and Ponzetto, 2010) follows thestructure of a traditional lexical knowledge base and,accordingly, consists of a labeled directed graphwhose nodes represent concepts and named entities,and whose edges express semantic relations betweenthem.
Concepts and relations are harvested fromthe largest available semantic lexicon of English,i.e., WordNet, and a wide-coverage collaboratively-edited encyclopedia, i.e., Wikipedia1, thus makingBabelNet a multilingual ?encyclopedic dictionary?which combines lexicographic information with en-cyclopedic knowledge on the basis of an unsuper-vised mapping framework.
In addition to a core1http://www.wikipedia.org.
In the following, werefer to Wikipedia pages and senses using SMALL CAPS.1400semantic network, BabelNet provides a multilin-gual lexical dimension.
Each of its nodes, calledBabel synsets, contains a set of lexicalizations ofthe concept for different languages, e.g., { bankENn ,BankDEn , bancaITn , .
.
.
, bancoESn }2.
Multilin-gual lexicalizations for all concepts are collectedfrom Wikipedia?s inter-language links (e.g., the En-glish Wikipedia page BANK links to the ItalianBANCA), as well as by acquiring missing trans-lations by means of a statistical machine transla-tion system applied to sense-tagged data from Sem-Cor and Wikipedia itself ?
for instance, most oc-currences of bank1n in SemCor3 are translated intoGerman and Italian as Ufer and riva, respectively.As a result of combining human-edited translationsfrom Wikipedia and automatically generated onesfrom sense-labeled data, BabelNet is able to achievewide coverage for all its languages (Catalan, En-glish, French, German, Italian and Spanish): accord-ingly, we chose it to perform graph-based WSD ina multilingual setting since it is specifically focusedon lexical knowledge.
In addition, BabelNet is avail-able for any language required to perform standardSemEval cross-lingual disambiguation tasks (e.g.,Spanish, in order to perform cross-lingual lexicalsubstitution).
Since previous work in knowledge-based WSD shows the benefits of using rich lexicalresources (Navigli and Lapata, 2010; Ponzetto andNavigli, 2010), BabelNet is a suitable choice for per-forming graph-based multilingual WSD.3.2 Exploiting multilingual information in aknowledge-based WSD frameworkWe present a multilingual approach to WSDwhich exploits three main factors:i) the fact that translations of a target word pro-vide complementary information on the rangeof its candidate senses in context;ii) the wide-coverage, multilingual lexical knowl-edge stored in BabelNet;iii) the support for disambiguation from differentlanguages in a synergistic, unified way.2BabelNet senses are referred to with wlp, namely the senseof a word w in a language l with part of speech p.3We denote WordNet senses with wip, namely the i-th senseof a word w with part of speech p.Algorithm 1 Multilingual joint WSDInput: a word sequence ?
= (w1, .
.
.
, wn)a target word w ?
?BabelNet BNan ensemble method MOutput: a distribution of scores for the senses of w( indicates a comment)1: S ?
SynsetsBN (w)2: T ?
{w}3: for each s ?
S4: T ?
T ?
getTranslations(s)5: ctx?
?
?
{w}6:  LScore := {lScorei,j}i=1,...,|T |, j=1,...,|S|7: for each ti ?
T8: ??
?
{ti} ?
ctx9:  Gi := (Vi, Ei)10: Gi ?
createGraph(?
?, BN)11: for each sj ?
S ?
Vi12: lScorei,j ?
score(Gi, sj)13:  Score := (score1, .
.
.
, score|S|)14: Score?M(LScore)15: return ScoreWe call this approach multilingual joint WSD,since disambiguation is performed by exploiting dif-ferent languages together at the same time.
To thisend, we first perform graph-based WSD using thetarget word in context as input, and then combinesense evidence from its translations using an ensem-ble method.
The key idea of our joint approach isthat sense evidence from different translations pro-vides complementary views for the senses of a tar-get word in context.
Therefore, combining such ev-idence should produce more accurate sense predic-tions.
We view WSD as a sense ranking problem.Given a word sequence ?
= (w1, .
.
.
, wn), we dis-ambiguate a target word w ?
?
by scoring each ofits senses and selecting the highest-ranking one:s?
= argmaxs ?
SynsetsBN (w)score(s) , (1)where SynsetsBN (w) is the set of Babel synsets con-taining the different senses for w.4 We score these4Babel synsets unambiguously identify different sensesof the target word, e.g., { bankENn , BankDEn , bancoESn .
.
.
,bancaITn } corresponds to the ?financial institute?
sense ofbankENn (i.e., bank2n in WordNet).1401synsets using Algorithm 1, which we illustrate inthe following by means of the example sentence?bank bonuses are paid in stock?, where we focus onbankENn as the target word and { bonusENn , payENv ,stockENn } as its context.
The following steps areperformed:Initialization.
We start by gathering the data re-quired for disambiguation (lines 1?5).
First, wecollect in line 1 the set S of Babel synsets corre-sponding to the different senses of the target word w?
namely, the synsets containing the ?financial in-stitution?, ?money container?, ?building?
senses ofbankENn , among others.
Next, we obtain the multi-lingual lexicalizations of the target word: to this end,we first include in T the word w itself (line 2), andthen iterate through each synset s ?
S to collect thetranslations of each of its senses in the languages ofinterest (lines 3?4).
For instance, given the Englishword bankENn , we collect its sense-specific German,Italian and Spanish translations and obtain a set ofmultilingual terms T = { bankENn , .
.
.
, BankDEn ,Sparbu?chseDEn , Bankgeba?udeDEn , .
.
.
, bancaITn ,salvadanaioITn , .
.
.
, bancoESn , huchaESn }.
Finally,we create a disambiguation context ctx by taking theword sequence ?
and removing w from it (line 5, asa result, e.g., ctx = { bonusENn , payENv , stockENn }).Collecting sense distributions.
In the next phase(lines 6?12), we collect a scoring distribution overthe different synsets S of w for each term ti ?
T .Each distribution quantifies the empirical support forthe different senses of the target word, obtained us-ing ti and the context ctx: we store this informa-tion in a |T | ?
|S| matrix LScore, where each celllScorei,j quantifies the support for synset sj ?
S,computed using the term in ti ?
T .
We calculate thescores as follows:- We select at each step an element ti from T (line7), for instance bancoESn .- Next, we create a multilingual context ??
by com-bining ti with the words in ctx (line 8, e.g., we set??
= { bancoESn , bonusENn , payENv , stockENn }.- We use ??
to build a graph Gi = (Vi, Ei) bycomputing the paths in BabelNet which connectthe synsets of ti with those of the other wordsin ??
(line 10, see Section 3.3 for details on thecreateGraph function).
Note that by selecting ateach step a different element from T we create anew graph where different sets of Babel synsetsget activated by the context words in ctx.
In ourexample, Figures 1(a)?
(c) show the graphs ob-tained by setting at different steps ti to bankENn ,bancoESn and BankDEn , respectively (we show ex-cerpts by using only stockENn as context word forease of readability).- Finally, we compute the support from term ti foreach synset sj ?
S of the target word by applyinga graph connectivity measure to Gi and store theresult in lScorei,j (lines 11?12).
For instance, us-ing degree as graph measure, we can compute thefollowing scores from the graph in Figure 1(b):bank2n bank8n bank9nbancoESn 2 0 1By repeating the process for each term in T (lines 7?12) we compute all values in the matrixLScore.
Forinstance, given T = {bankENn , bancoESn , BankDEn },we create the set of graphs in Figures 1(a)?
(c), andcompute from each of them the following scores(again, using degree as scoring measure):LScore =bank2n bank8n bank9nbankENn?
?2 2 1?
?bancoESn 2 0 1BankDEn 2 0 0Combining sense distributions.
In the last step(line 14) we aggregate the scores associated witheach term of T using an ensemble method M (seeSection 3.4 for details).
For instance, M could sim-ply consist of summing the scores associated witheach sense over all distributions and thus return ascore of 6, 2, and 2 for bank2n, bank8n and bank9n,respectively.
As a result of the execution of Al-gorithm 1, the combined scoring distribution is re-turned (line 15).
This sense distribution in turn canbe used to select the best sense using Equation 1.The main hunch behind our approach is that usinginformation from different languages improves dis-ambiguation performance, as in the example of Fig-ure 1 where more accurate disambiguation is per-formed by combining scores computed from trans-lations in different languages, as opposed to using1402(a) Disambiguation graph using the target word bankENn .bank2nBankDEbancoESbancaITbank8nSparbu?chseDEhuchaESsalvadanaioITbank9nBankgeba?udeDEbancoES bancaITstock1nAktienDEaccionesESazioniITstock4nAktienzertifikatDEaccionesES azioniITstock17nViehDEganadoESbestiameITcommercialbankinvestmentbankingstockbroker traderpiggybank pigbuilding abattoir(b) Disambiguation graph using bancoESn as translation.bank2nBankDEbancoESbancaITbench1nBankDEbancoESpanchinaITbank8nSparbu?chseDEhuchaESsalvadanaioITbank9nBankgeba?udeDEbancoES bancaITstock1nAktienDEaccionesESazioniITstock4nAktienzertifikatDEaccionesES azioniITstock17nViehDEganadoESbestiameITcommercialbankinvestmentbankingstockbroker traderpiggybank pigbuilding abattoir(c) Disambiguation graph using BankDEn as translation.bank2nBankDEbancoESbancaITbench1n BankDEbancoES panchinaITbed4n BankDEestratoES lettoITbank8nSparbu?chseDEhuchaESsalvadanaioITbank9nBankgeba?udeDEbancoES bancaITstock1nAktienDEaccionesESazioniITstock4nAktienzertifikatDEaccionesES azioniITstock17nViehDEganadoESbestiameITcommercialbankinvestmentbankingstockbroker traderpiggybank pigbuilding abattoir(d) List of corresponding WordNet senses and their glossesbank2n financial institution that accepts deposits and channelsthe money into lending activitiesbank8n a container (usually with a slot in the top) for keepingmoney at homebank9n a building in which the business of banking transactedstock1n the capital raised by a corporation through the issueof shares entitling holders to an ownership intereststock4n a certificate documenting the shareholder?sownership in the corporationstock17n any animals kept for use or profitFigure 1: Multilingual graph construction for the input sentence ?bank bonuses are paid in stock?.
We show excerptsusing only stockENn as context word for ease of readability.monolingual sense evidence only.
Figure 1(a) showsthe graph created to disambiguate the English targetword bankENn in our example sentence.
In the graph,some of the possible senses of this word are acti-vated, including the correct one (bank2n) but also re-lated, yet incorrect ones such as bank8n and bank9n.Figure 1(b) and 1(c) show instead the graphs ob-tained from replacing the target word with its Span-ish and German translations, respectively.
In thesegraphs, different subsets of the senses of bankENnare activated, together with others pertaining to thetranslations only (e.g., the meaning of bancoESn cor-responding to the English bench1n).
However, thesense that is consistently activated across all graphsis the correct one ?
i.e., bankENn as financial insti-tution ?
which is in fact the sense selected by ourmultilingual approach by means of combining thescoring distributions from all these graphs.3.3 Graph-based WSDWe use graph-based algorithms to exploit multilin-gual knowledge from BabelNet for WSD.
These area natural choice for our approach, since BabelNet isa semantic network, and such algorithms have beenshown to achieve high performance across domains(Agirre et al 2009; Navigli et al 2011), as wellas to compete with supervised methods on a vari-ety of lexical disambiguation tasks (Ponzetto andNavigli, 2010).
To this end, we use the methodof Navigli and Lapata (2010) and construct a di-rected graphG = (V,E) for an input word sequence?
= (w1, .
.
.
, wn)5 using the lexical and semanticrelations found in BabelNet.
The result of this pro-cedure is a subgraph of BabelNet containing (1) thesenses of the words in context, (2) all edges and in-termediate senses found in BabelNet alg all pathsthat connect them.
Given G, a target word w ?
?and its set of senses in BabelNet S ?
V , we com-pute a score distribution (score1, .
.
.
, score|S|) overS, where scorej refers to the confidence score forthe j-th sense of w, e.g.
bank2n, based on some con-nectivity measure applied to G. In this paper, wespecifically focus on two such measures.5In our experiments we always take ?
to be a single sen-tence, thus disambiguating on a sentence-by-sentence basis.1403Degree Centrality (Degree): The first measureranks the senses of a given word in the graph basedon the number of their incident edges, namely:scorej = |{{sj , v} ?
E : v ?
V }| .This standard connectivity measure weights a senseas more appropriate if it has a higher degree.
Wechose context-based Degree since, albeit simple, ithad previously been shown to yield a highly com-petitive performance on various WSD tasks (Navigliand Lapata, 2010; Ponzetto and Navigli, 2010).Inverse path length sum (PLength): We then de-veloped a graph connectivity measure which scoreseach sense by summing over the inverse length of allpaths which connect it to other senses in the graph:scorej =?p?
paths(sj)1elength(p)?1,where paths(sj) is the set of simple paths con-necting sj to the senses of other context words,length(p) is the number of edges in the path p andeach path is scored with the exponential inverse de-cay of the path length.
This measure overcomes thelocality of Degree by aggregating over all paths be-tween a sense of the target word and those of thecontext words, thus being able to capture the rich-ness of the BabelNet subgraph and the semantic den-sity of the underlying knowledge base.3.4 Ensemble methods for multilingual WSDAt the core of our algorithm lies the combination ofthe scores generated using the different translationsof the target word w. For this purpose, we apply so-called ensemble methods, which have been shownto improve the performance of both supervised (Flo-rian et al 2002) and unsupervised WSD systems(Brody et al 2006).
Given |T | lexicalizations and|S| senses for w, the input to the combination com-ponent consists of a |T |?
|S|matrix LScore, whereeach cell lScorei,j quantifies the empirical supportfor sense sj from a term ti ?
T (see Section 3.2 foran example).
The ensemble method computes fromthis translation-sense matrix a combined scoring, ex-pressing the joint confidence across terms in differ-ent languages over the set of senses S. In this work,we use the ?Probability Mixture?
(PMixture) methodproposed by Brody et al(2006), which they showto be the best performing for WSD.
This methodtakes the scores associated with each term, normal-izes and combines them by summing across distri-butions.
Formally, it computes the score for the j-thsense of w as follows:scorej =|T |?i=1p(si,j), p(si,j) =lScorei,j?|S|s=1 lScorei,s.For instance, using the (normalized) sense distribu-tions from our example, the ensemble distributionwill be the following:bank2n bank8n bank9nbankENn 0.40 0.40 0.20bancoESn 0.67 0.00 0.33BankDEn 1.00 0.00 0.00PMixture 2.07 0.40 0.533.5 Weighting multilingual sense distributionComputing a sense distribution for each translationusing the same graph connectivity measure assumesthat all translations are equal.
However, a leitmotifof multilingual WSD research is that translations re-strict the set of candidate senses of the target wordin the source language.
In our example of Figure1, for instance, BankDEn provides structural supportonly for the financial sense of English bank, sincethis is the only sense it covers.
Within our frame-work this can potentially lead to skewed sense dis-tributions when only some senses of the target wordhave a translation.
In such cases, in fact, scores tendto be concentrated mostly on the senses covered bythe translations, with the result that sense evidencefor uncovered English senses is disregarded.
In or-der to cope with this issue, we weight the elementsof each sense distribution lScorei for the i-th trans-lation ti ?
T by a factor of 1+log2 cov(ti, w), wherecov(ti, w) is the number of Babel synsets where tico-occurs with the target word w ?
i.e., the numberof senses of w that it covers (we use the log func-tion to dampen the effect of high coverage values).This is to say, in order to level off the effects of un-balanced sense coverage we assume that, all thingsbeing equal, the more senses a translation covers, thestronger the disambiguation evidence it provides incontext for specific senses.
As a result, the contri-butions of each translation are weighted differently1404and we are thus able to dampen the effects of ahighly skewed distribution like, for instance, that ofBankDEn :bank2n bank8n bank9nbankENn 1.72 1.72 0.86bancoESn 1.34 0.00 0.66BankDEn 1.00 0.00 0.00Weighted PMixture 4.04 1.70 1.524 ExperimentsWe evaluate our approach in two different settings,namely a monolingual all-words WSD task in Sec-tion 4.1, as well as two different cross-lingual dis-ambiguation gold standards in Section 4.2.4.1 Monolingual WSDExperimental setting.
We first evaluate the per-formance of multilingual joint WSD on a standardmonolingual dataset, namely the SemEval-2010 do-main WSD task 17 (Agirre et al 2010), since itprovides the latest dataset for fine-grained WSD inEnglish.
We opt for an English all-words task fortwo main reasons: first, it is a well-established andwidely-participated task in the WSD community ?thus ensuring a comparison of our method with awide range of state-of-the-art approaches, includ-ing other graph-based techniques (e.g., PersonalizedPageRank), as well as weakly-supervised and super-vised approaches (see Agirre et al(2010) for de-tails on the participating systems); second, we wantto assess whether a multilingual approach benefitslexical disambiguation in all settings, namely evenin a standard monolingual one.
We use in our ex-periments the dataset?s nouns-only subset (1032 in-stances), since BabelNet currently contains multi-lingual lexicalizations for nouns only (and thus nomultilingual strategy can be applied to other partsof speech).
We perform graph-based WSD withBabelNet in two different configurations, namely amonolingual and multilingual setting.
The multi-lingual system performs WSD by means of the fulljoint multilingual approach described in Algorithm1.
The monolingual approach, instead, simply usesthe English input sentence for disambiguation ?
thatis, we skip lines 3?4 of Algorithm 1.
Knowledge-based systems typically suffer from a low recall ?i.e., they cannot provide an answer if no informationAlgorithm P R F1Monolingual Degree 50.6 45.2 47.7graph PLength 51.0 47.3 49.1Multilingual Degree?
53.9 48.6 51.1ensemble PLength?
54.3 50.2 52.2SemCor MFS 51.9 51.2 51.5Random 25.3 25.3 25.3Table 1: Performance on SemEval-2010 all-words do-main WSD (nouns only subset).
Best results for eachmeasure are bolded.
?
indicates statistically significantdifferences with respect to the monolingual setting.can be found with senses of the context words.
Toovercome this issue, in both settings we use a type-based fallback strategy which assigns to the targetword the sense which has been most frequently as-signed by the system to other instances of the wordin the dataset.Results and discussion.
We report our results interms of precision (P), recall (R) and F1 measure inTable 1, where we compare the monolingual vari-ant (rows 1?2 of the table) with our multilingualapproach (rows 3?4).
Following standard practice,(1) we benchmark our method against two baselines,namely a random sense assignment and the most fre-quent sense (MFS) from SemCor; (2) we test for sta-tistical significance by computing a 95% confidenceinterval on the recall score (i.e., the main evaluationmeasure for the WSD task) using bootstrap resam-pling (Noreen, 1989).The results show that our multilingual approachimproves over the monolingual one by a substan-tial (i.e., statistically significant) margin.
Combiningmultilingual information from different languagesyields a higher precision (+3.3 for both graph algo-rithms) and recall (+3.4 and +2.9 for Degree andPLength, respectively).
Manual inspection of theoutput reveals that these increases in precision aredue to translations in different languages constrain-ing each other ?
e.g., an implausible English sense is?ruled out?
from the sense distributions of the otherlanguages (cf.
the example in Figure 1).
The in-creases in recall, instead, indicate that using trans-lations triggers responses in those cases where nosense of the English target word can be connectedto the senses of the context words ?
i.e., some trans-1405Algorithm P R F1Monolingual Degree 52.0 51.3 51.6graph PLength 55.0 54.2 54.6Multilingual Degree?
61.6 59.5 60.5ensemble PLength?
62.5 60.4 61.4CFILT 61.4 59.4 60.4IIITH 56.4 55.3 55.8Table 2: Performance on SemEval-2010 all-words do-main WSD (nouns only subset) using the most frequentsense assigned by the system as back-off strategy whenno sense assignment is attempted.lations activate senses in the knowledge base whichare closer to the senses of the context words.
Theresult is an overall increase in F1 measure of 3.4and 3.1 points for Degree and PLength, respectively,which makes it possible for us to beat the MFSbaseline (notably a difficult competitor for WSDsystems).
Among the different graph algorithms,PLength consistently outperforms Degree: however,the differences are not statistically significant.In order to better understand the impact of our ap-proach we follow previous work (e.g., Navigli andLapata (2010)) and explore a weakly-supervised set-ting where the system attempts no sense assignmentif the highest score among those assigned to thesenses of a target word is below a certain threshold.If this is the case, in order to provide an answer forall items, we output the most frequent sense assignedby the system to other instances of the target word,and fall back to SemCor?s MFS if no assignment hasbeen attempted.
We estimate the optimal value forthe threshold by maximizing F1 on a developmentset obtained by combining the Senseval-2 (Palmer etal., 2001) and Senseval-3 (Snyder and Palmer, 2004)English all-words datasets.
The results for this set-ting are shown in Table 2, where we also comparewith the top-performing systems from the SemEvalcompetition, namely CFILT (Kulkarni et al 2010)and IIITH (Reddy et al 2010).By complementing our multilingual method withthe MFS heuristic we achieve a performance compa-rable with the state of the art on this task.
Again, themultilingual ensemble approach consistently outper-forms the monolingual one and enables us to achievethe best overall results for this dataset: without mul-tilingual information, in fact, we achieve only aver-age performance above the MFS level, whereas byeffectively combining sense evidence from multilin-gual translations we are able to boost the F1 measureby a 6-8 point margin, and thus outperform the top-ranking SemEval systems.
While differences withCFILT are not statistically significant, we still takethis to be good news, since our system is generalpurpose in nature and, accordingly, does not use anydomain information such as manually-labeled exam-ples for the most frequent domain words (CFILT) ora domain-specific sense ranking (IIITH).4.2 Cross-lingual lexical disambiguationUsing a multilingual lexical resource makes it possi-ble to perform WSD in any of its languages.
Ac-cordingly, we complement our evaluation on En-glish texts with a second set of experiments wherewe quantify the impact of our approach on a lex-ical disambiguation task in a multilingual setting.To this end, we use the SemEval-2010 cross-linguallexical substitution (Mihalcea et al 2010, CL-LS,henceforth) and WSD (Lefever et al 2011, CL-WSD) tasks and evaluate our methodology on per-forming disambiguation across different languages.Both cross-lingual WSD tasks cast disambiguationas a word translation problem: given an English pol-ysemous noun in context as input, the system dis-ambiguates it by providing a translation into anotherlanguage (translations are deemed correct if theypreserve the meaning of the source word in the targetlanguage).
Their main difference, instead, lies in therange of translations which are assumed to be valid:that is, while CL-LS assumes no predefined sense in-ventory (i.e., any translation can be potentially cor-rect), CL-WSD makes use of a sense inventory builton the basis of the Europarl corpus (Koehn, 2005).Our approach to lexical disambiguation involvestwo steps: first, given a target word in context, wedisambiguate it as usual to the highest-ranked Ba-bel synset; next, given the translations in the se-lected synset, we return the most suitable lexical-ization in the language of interest.
Since the se-lected synset can contain multiple translations in atarget language for the input English word, we ex-plore using an unsupervised strategy to select themost reliable translation from multiple candidates.To this end, we return for each test instance only the1406Algorithm P/R/F1Baseline 23.80Monolingual Degree 30.52graph PLength 30.64Multilingual Degree 32.21ensemble PLength 32.47UBA-T 32.17Table 3: Performance on SemEval-2010 lexical substitu-tion (best results are bolded).most frequent translation found in the Babel synset.Given that the two tasks make different assumptionson the sense inventory (no fixed inventory for CL-LS vs. Europarl-based for CL-WSD), the frequencyof a translation is calculated as either the numberof Babel synsets in which it occurs (CL-LS), or itsfrequency of alignment with the target word, as ob-tained by applying GIZA++ (Och and Ney, 2003) toEuroparl (CL-WSD).
To provide an answer for allinstances, we return this most frequent translationeven when no sense assignment is attempted ?
i.e.,no sense of the target word is connected to any othersense of the context words ?
or a tie occurs.Results and discussion.
We report our results forCL-LS and CL-WSD in Tables 3 and 4.
We evalu-ate using the nouns-only subset of the CL-LS datasetand the full CL-WSD dataset, consisting of 300 and1,000 instances of nouns in context, respectively.The evaluation scheme is based on the SemEval-2007 English lexical substitution task (McCarthyand Navigli, 2009), and consists of an adaptation ofthe metrics of precision and recall for the translationsetting.
For each task, we compare our monolingualand multilingual approaches against the best per-forming SemEval systems for these tasks, namelyUBA-T (Basile and Semeraro, 2010) and UVT-v(van Gompel, 2010) for CL-LS and CL-WSD, re-spectively, as well as a recent supervised proposalthat exploits automatically generated multilingualfeatures from parallel text and translated contexts(Lefever et al 2011, Parasense).
For each taskwe also report its official baseline, namely the firsttranslation from an online-dictionary6 for CL-LS,and the most frequent word alignment obtained by6www.spanishdict.comapplying GIZA++ to the Europarl data for CL-WSD.Our cross-lingual results confirm all trends of theEnglish monolingual evaluation, namely that: a) ourjoint multilingual approach substantially improvesover the simple monolingual graph-based approach;b) it enables us to achieve state-of-the-art perfor-mance for these tasks.
In the case of both CL-LS and CL-WSD, using a rich multilingual knowl-edge base like BabelNet makes it possible to achievea respectable performance already with the simplemonolingual approach, thus indicating the viabilityof a knowledge-rich approach to sense-driven wordtranslation.
The use of multilingual ensembles al-ways improves the monolingual setting for all lan-guages, and allows us to achieve the best overall re-sults for both CL-LS and CL-WSD.
Similarly to thecase of monolingual WSD, manual inspection of theoutput reveals that translations help us rule out in-correct senses and let the disambiguation algorithmfocus on the more coherent set of senses for the in-put context in a way similar to the one highlightedby the example in Figure 1.
As a result of this weare able to improve the performance of both mono-lingual Degree and PLength, and compete with thestate of the art on all disambiguation tasks.5 ConclusionsIn this paper we presented a multilingual joint ap-proach to WSD.
Key to our methodology is the ef-fective use of a wide-coverage multilingual knowl-edge base, BabelNet, which we exploit to performgraph-based WSD across languages and combinecomplementary sense evidence from translations indifferent languages using an ensemble method.
Thisis the first proposal to exploit structured multilingualinformation within a joint, knowledge-rich frame-work for WSD.
The APIs to perform multilingualWSD using BabelNet are freely available for re-search purposes (Navigli and Ponzetto, 2012b).Thanks to multilingual joint WSD we achievestate-of-the-art performance on three different goldstandards.
The good news about these results is thatnot only can further advances be achieved by usingmultilingual lexical knowledge, but, more impor-tantly, that combining multilingual sense evidencefrom different languages at the same time yieldsconsistent improvements over a monolingual ap-1407French German Italian SpanishP/R/F1 P/R/F1 P/R/F1 P/R/F1Baseline 21.25 13.16 15.18 19.74UvT-v N/A N/A N/A 23.39Parasense 24.54 16.88 18.03 22.80Monolingual Degree 22.94 17.15 18.03 22.48graph PLength 23.42 17.72 18.19 22.76Multilingual Degree 24.02 18.07 18.93 23.51ensemble PLength 24.61 18.26 19.05 23.65Table 4: Results on the SemEval-2010 cross-lingual WSD dataset (best results are bolded).proach in both monolingual and cross-lingual lexicaldisambiguation tasks ?
that is, ?joining forces paysoff?.
Effectively leveraging multilingual knowledgefor WSD helps overcome the shortcomings of theunderlying resource (noise, coverage, etc.
), thus in-dicating that further performance boosts can comein the future from even better multilingual lexicalresources.
Moreover, our methodology is general-purpose and can be adapted to tasks other thanWSD: in fact, we have already taken the first stepsin this direction by showing the beneficial effects ofa joint multilingual approach to computing semanticrelatedness (Navigli and Ponzetto, 2012a).
In ad-dition, we plan in the very near future to general-ize our multilingual joint approach and apply it tohigh-end tasks such as multilingual textual entail-ment (Mehdad et al 2011) and sentiment analysis(Lu et al 2011) ?
so as to provide a general frame-work for knowledge-rich multilingual NLP.AcknowledgmentsThe authors gratefully acknowl-edge the support of the ERC Start-ing Grant MultiJEDI No.
259234.BabelNet and its API are available for download athttp://lcl.uniroma1.it/babelnet.ReferencesEneko Agirre, Oier Lopez de Lacalle, and Aitor Soroa.2009.
Knowledge-based WSD on specific domains:performing better than generic supervised WSD.
InProceedings of the 21st International Joint Confer-ence on Artificial Intelligence (IJCAI-09), pages 1501?1506.Eneko Agirre, Oier Lo?pez de Lacalle, Christiane Fell-baum, Shu-Kai Hsieh, Maurizio Tesconi, MonicaMonachini, Piek Vossen, and Roxanne Segers.
2010.Semeval-2010 task 17: All-words Word Sense Disam-biguation on a specific domain.
In Proceedings of the5th International Workshop on Semantic Evaluations(SemEval-2010), pages 75?80.Carmen Banea and Rada Mihalcea.
2011.
Word SenseDisambiguation with multilingual features.
In Pro-ceedings of the 9th International Conference on Com-putational Semantics (IWCS 2011), pages 25?34.Pierpaolo Basile and Giovanni Semeraro.
2010.
UBA:Using automatic translation and Wikipedia for cross-lingual lexical substitution.
In Proceedings of the5th International Workshop on Semantic Evaluations(SemEval-2010), pages 242?247.Samuel Brody, Roberto Navigli, and Mirella Lapata.2006.
Ensemble methods for unsupervised WSD.In Proceedings of the 21st International Conferenceon Computational Linguistics and 44th Annual Meet-ing of the Association for Computational Linguistics(COLING-ACL-06), pages 97?104.Peter F. Brown, Stephen A. Della Pietra, Vincent J. DellaPietra, and Robert L. Mercer.
1991.
Word-sense dis-ambiguation using statistical methods.
In Proceed-ings of the 29th Annual Meeting of the Association forComputational Linguistics (ACL-91), pages 264?270.Marine Carpuat and Dekai Wu.
2007.
Improving Sta-tistical Machine Translation using Word Sense Dis-ambiguation.
In Proceedings of the 2007 Joint Con-ference on Empirical Methods in Natural LanguageProcessing and Computational Language Learning(EMNLP-CoNLL-07), pages 61?72.Yee Seng Chan and Hwee Tou Ng.
2005.
Scaling upWord Sense Disambiguation via parallel texts.
In Pro-ceedings of the 20th National Conference on ArtificialIntelligence (AAAI-05), pages 1037?1042.Yee Seng Chan, Hwee Tou Ng, and David Chiang.
2007.Word Sense Disambiguation improves Statistical Ma-1408chine Translation.
In Proceedings of the 45th AnnualMeeting of the Association for Computational Linguis-tics (ACL-07), pages 33?40.Ido Dagan, Alon Itai, and Ulrike Schwall.
1991.
Twolanguages are more informative than one.
In Proceed-ings of the 29th Annual Meeting of the Association forComputational Linguistics (ACL-91), pages 130?137.Gerard de Melo and Gerhard Weikum.
2010.
MENTA:Inducing multilingual taxonomies from Wikipedia.
InProceedings of the 19th ACM Conference on Informa-tion and Knowledge Management (CIKM-10), pages1099?1108.Mona Diab.
2003.
Word Sense Disambiguation within aMultilingual Framework.
Ph.D. thesis, University ofMaryland, College Park, Maryland.Christiane Fellbaum, editor.
1998.
WordNet: An Elec-tronic Database.
MIT Press, Cambridge, MA.Radu Florian, Silviu Cucerzan, Charles Schafer, andDavid Yarowsky.
2002.
Combining classifiers forWord Sense Disambiguation.
Natural Language En-gineering, 8(4):1?14.William A. Gale, Kenneth Church, and David Yarowsky.1992.
Using bilingual materials to develop WordSense Disambiguation methods.
In Proceedings of theFourth International Conference on Theoretical andMethodological Issues in Machine Translation, pages101?112.Nancy Ide, Tomaz Erjavec, and Dan Tufis?.
2002.
Sensediscrimination with parallel corpora.
In Proceedingsof the ACL-02 Workshop on WSD: Recent Successesand Future Directions, pages 54?60.Nancy Ide.
2000.
Cross-lingual sense determination:Can it work?
Computers and the Humanities, 34:223?234.Mitesh M. Khapra, Salil Joshi, Arindam Chatterjee, andPushpak Bhattacharyya.
2011.
Together we can:Bilingual bootstrapping for WSD.
In Proceedings ofthe 49th Annual Meeting of the Association for Com-putational Linguistics, (ACL-11), pages 561?569.Philipp Koehn.
2005.
Europarl: A parallel corpus forstatistical machine translation.
In Proceedings of Ma-chine Translation Summit X.Anup Kulkarni, Mitesh Khapra, Saurabh Sohoney, andPushpak Bhattacharyya.
2010.
CFILT: Resourceconscious approaches for all-words domain specificWSD.
In Proceedings of the 5th International Work-shop on Semantic Evaluations (SemEval-2010), pages421?426.Els Lefever and Veronique Hoste.
2010.
SemEval-2010task 3: Cross-lingual Word Sense Disambiguation.
InProceedings of the 5th International Workshop on Se-mantic Evaluations (SemEval-2010), pages 15?20.Els Lefever, Ve?ronique Hoste, and Martine De Cock.2011.
Parasense or how to use parallel corpora forWord Sense Disambiguation.
In Proceedings of the49th Annual Meeting of the Association for Computa-tional Linguistics, (ACL-11), pages 317?322.Bin Lu, Chenhao Tan, Claire Cardie, and BenjaminK.
Tsou.
2011.
Joint bilingual sentiment classificationwith unlabeled parallel corpora.
In Proceedings of the49th Annual Meeting of the Association for Computa-tional Linguistics, (ACL-11), pages 320?330.Bernardo Magnini, Danilo Giampiccolo, and Alessan-dro Vallin.
2004.
The Italian lexical sample task atSenseval-3.
In Proceedings of the 3rd InternationalWorkshop on the Evaluation of Systems for the Seman-tic Analysis of Text (SENSEVAL-3), pages 17?20.Lluis Ma`rquez, Mariona Taule?, Antonia Mart?
?, Nu?riaArtigas, Mar Garc?
?a, Francis Real, and Dani Ferre?s.2004.
Senseval-3: The Spanish lexical sample task.In Proceedings of the 3rd International Workshop onthe Evaluation of Systems for the Semantic Analysis ofText (SENSEVAL-3), pages 21?24.Diana McCarthy and Roberto Navigli.
2009.
The En-glish lexical substitution task.
Language Resourcesand Evaluation, 43(2):139?159.Yashar Mehdad, Matteo Negri, and Marcello Federico.2011.
Using bilingual parallel corpora for cross-lingual textual entailment.
In Proceedings of the 49thAnnual Meeting of the Association for ComputationalLinguistics, (ACL-11), pages 1336?1345.Christian M. Meyer and Iryna Gurevych.
2012.Ontowiktionary ?
Constructing an ontology fromthe collaborative online dictionary Wiktionary.
InMaria Teresa Pazienza and Armando Stellato, edi-tors, Semi-Automatic Ontology Development: Pro-cesses and Resources.
IGI Global, Hershey, Penn.Rada Mihalcea, Ravi Sinha, and Diana McCarthy.
2010.Semeval-2010 task 2: Cross-lingual lexical substitu-tion.
In Proceedings of the 5th International Work-shop on Semantic Evaluations (SemEval-2010), pages9?14.George A. Miller, Claudia Leacock, Randee Tengi, andRoss Bunker.
1993.
A semantic concordance.
In Pro-ceedings of the 3rd DARPA Workshop on Human Lan-guage Technology, pages 303?308.Vivi Nastase, Michael Strube, Benjamin Bo?rschinger,Caecilia Zirn, and Anas Elghafari.
2010.
WikiNet:A very large scale multi-lingual concept network.
InProceedings of the 7th International Conference onLanguage Resources and Evaluation, (LREC ?10).Roberto Navigli and Mirella Lapata.
2010.
An exper-imental study on graph connectivity for unsupervisedWord Sense Disambiguation.
IEEE Transactions onPattern Anaylsis and Machine Intelligence, 32(4):678?692.1409Roberto Navigli and Simone Paolo Ponzetto.
2010.
Ba-belNet: Building a very large multilingual semanticnetwork.
In Proceedings of the 48th Annual Meet-ing of the Association for Computational Linguistics,(ACL-10), pages 216?225.Roberto Navigli and Simone Paolo Ponzetto.
2012a.
Ba-belRelate!
A joint multilingual approach to computingsemantic relatedness.
In Proceedings of the 26th Con-ference on Artificial Intelligence (AAAI-12).Roberto Navigli and Simone Paolo Ponzetto.
2012b.Multilingual WSD with just a few lines of code: TheBabelNet API.
In Proceedings of the 50th AnnualMeeting of the Association for Computational Linguis-tics, (ACL-12).
System Demonstrations.Roberto Navigli, Stefano Faralli, Aitor Soroa, Oier Lopezde Lacalle, and Eneko Agirre.
2011.
Two birds withone stone: Learning semantic models for Text Cate-gorization and Word Sense Disambiguation.
In Pro-ceedings of the 20th ACM Conference on Informa-tion and Knowledge Management (CIKM-11), pages2317?2320.Roberto Navigli.
2009.
Word Sense Disambiguation: Asurvey.
ACM Computing Surveys, 41(2):1?69.Eric W. Noreen, editor.
1989.
Computer-intensive meth-ods for testing hypotheses: an introduction.
NewYork, N.Y.: John Wiley.Franz Josef Och and Hermann Ney.
2003.
A system-atic comparison of various statistical alignment mod-els.
Computational Linguistics, 29(1):19?51.Manabu Okumura, Kiyoaki Shirai, Kanako Komiya, andHikaru Yokono.
2010.
SemEval-2010 task: JapaneseWSD.
In Proceedings of the 5th International Work-shop on Semantic Evaluations (SemEval-2010), pages69?74.Zeynep Orhan, Emine C?elik, and Demirgu?c?
Neslihan.2007.
SemEval-2007 task 12: Turkish lexical sampletask.
In Proceedings of the 4th International Work-shop on Semantic Evaluations (SemEval-2007), pages59?63.Martha Palmer, Christiane Fellbaum, Scott Cotton, Lau-ren Delfs, and Hoa Trang Dang.
2001.
English tasks:All-words and verb lexical sample.
In Proceedings ofthe 2nd International Workshop on Evaluating WordSense Disambiguation Systems (SENSEVAL-2), pages21?24.Simone Paolo Ponzetto and Roberto Navigli.
2010.Knowledge-rich Word Sense Disambiguation rivalingsupervised system.
In Proceedings of the 48th AnnualMeeting of the Association for Computational Linguis-tics, (ACL-10), pages 1522?1531.Siva Reddy, Abhilash Inumella, Diana McCarthy, andMark Stevenson.
2010.
IIITH: Domain specificWord Sense Disambiguation.
In Proceedings of the5th International Workshop on Semantic Evaluations(SemEval-2010), pages 387?391.Philip Resnik and David Yarowsky.
1999.
Distinguish-ing systems and distinguishing senses: new evaluationmethods for Word Sense Disambiguation.
Journal ofNatural Language Engineering, 5(2):113?133.Carina Silberer and Simone Paolo Ponzetto.
2010.
UHD:Cross-lingual Word Sense Disambiguation using mul-tilingual co-occurrence graphs.
In Proceedings of the5th International Workshop on Semantic Evaluations(SemEval-2010), pages 134?137.Benjamin Snyder and Martha Palmer.
2004.
The Englishall-words task.
In Proceedings of the 3rd InternationalWorkshop on the Evaluation of Systems for the Seman-tic Analysis of Text (SENSEVAL-3), pages 41?43.Maarten van Gompel.
2010.
UvT-WSD1: A cross-lingual word sense disambiguation system.
In Pro-ceedings of the 5th International Workshop on Seman-tic Evaluations (SemEval-2010), pages 238?241.Zhi Zhong and Hwee Tou Ng.
2009.
Word Sense Dis-ambiguation for all words without hard labor.
In Pro-ceedings of the 21st International Joint Conference onArtificial Intelligence (IJCAI-09), pages 1616?1622.1410
