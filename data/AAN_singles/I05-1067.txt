Using the Structure of a Conceptual Network inComputing Semantic RelatednessIryna GurevychEML Research gGmbH, Schloss-Wolfsbrunnenweg 33, 69118, Heidelberg, Germanyhttp://www.eml-research.de/?gurevychAbstract.
We present a new method for computing semantic relatedness of con-cepts.
The method relies solely on the structure of a conceptual network andeliminates the need for performing additional corpus analysis.
The network struc-ture is employed to generate artificial conceptual glosses.
They replace textualdefinitions proper written by humans and are processed by a dictionary basedmetric of semantic relatedness [1].
We implemented the metric on the basis ofGermaNet, the German counterpart of WordNet, and evaluated the results on aGerman dataset of 57 word pairs rated by human subjects for their semantic re-latedness.
Our approach can be easily applied to compute semantic relatednessbased on alternative conceptual networks, e.g.
in the domain of life sciences.1 IntroductionSemantic relatedness of words represents important information for many applicationsdealing with processing of natural language.
A more narrowly defined phenomenonof semantic similarity has been extensively studied in psychology, cognitive science,artificial intelligence, and computational linguistics.
In the context of linguistics, it istypically defined via the lexical relation of synonymy.
While synonymy is indeed anexample of extreme similarity (suggesting that two words are interchangeable in a cer-tain context), many natural language processing applications require knowledge aboutsemantic relatedness rather than just similarity [2].
Departing from that, we define se-mantic relatedness as any kind of lexical or functional association that may exist be-tween two words.
For example, the words ?car?
and ?journey?
apparently display aclose semantic relationship, while they are not synonymous.Many natural language processing applications, e.g.
word sense disambiguation orinformation retrieval, do not need to determine the exact type of a semantic relation, butrather to judge if two words are closely semantically related or not.
For example, for anapplication in the domain of career consultancy it might be important to conclude thatthe words ?baker?
and ?bagel?
are closely related, while the exact type of a semanticrelation does not need to be assigned.Metrics of semantic relatedness are increasingly embedded into natural languageprocessing applications for English due to the availability of free software, e.g.
[3]and pre-computed information content values from English corpora.
The evaluationof all approaches to compute semantic relatedness has so far been done for the task ofsemantic similarity.
The underlying data was based on the English language [4,5].
Wepropose the following classification of the metrics of semantic relatedness:R. Dale et al (Eds.
): IJCNLP 2005, LNAI 3651, pp.
767?778, 2005.c?
Springer-Verlag Berlin Heidelberg 2005768 I. Gurevych?
intrinsic or extrinsic.
Intrinsic metrics employ no external evidence, i.e.
no know-ledge sources except for the conceptual network itself [1,6,7].
Extrinsic metrics re-quire additional knowledge, e.g.
information content values of concepts computedfrom corpora [8,9,10].?
the type of knowledge source employed, e.g.
a dictionary or a conceptual net-work.
Metrics can either employ a machine readable dictionary, i.e.
textual defi-nitions of words therein as an underlying knowledge base [1,11], or operate on thestructure of a conceptual network, whereby textual definitions themselves are notavailable [9,7].Researchers working on the processing of languages such as English, for whichmany resources exist, have a large choice of options for choosing a metric or a knowl-edge source.
This is, however, not the case for many other languages.
Extrinsic met-rics relying on a conceptual network and additional corpus data cannot always be ap-plied.
It is difficult and time-consuming to find and process a corpus, which is sub-stantially large to compute information content of concepts for a new language.
Thesame is true for domain-specific corpora, e.g.
in the domain of life sciences.
Beforeinformation content of domain concepts, e.g.
protein names can be computed, a con-siderable effort has to be invested in compiling and processing a substantially largecorpus in the respective domain.
This makes it difficult to apply corpus-based met-rics.
At the same time, many domains already have a kind of domain model in theform of thesauri or at least taxonomies, which appear to be instances ofconceptual networks.For dictionary based metrics, the difficulty is that textual definitions of word sensesin dictionaries are often inconsistent.
[12] note that dictionary definitions often do notcontain enough words to be effectively deployed in dictionary based metrics.
Fur-thermore, an important dimension is the portability of a metric to new domains, i.e.whether the metric can be applied e.g.
to medical or biological domains.
They typicallyhave well developed taxonomies, but are lacking language based descriptions (defi-nitions).
Therefore, the application of both extrinsic and dictionary based metrics isproblematic.Simultaneously, in this and in many other cases elaborated conceptual networks ortaxonomies are available.
One of the most prominent examples of that is the Open Di-rectory Project (http://www.dmoz.com).
Therefore, we propose a method for computingsemantic relatedness which overcomes the constraints related to previous metrics and iscompletely intrinsic.
It exploits solely the structure of a conceptual network, while theneed for both external statistical data and textual definitions of concepts is completelyeliminated.
Thus, our method is language independent and can be applied to differentknowledge bases represented as conceptual networks.We conducted an experiment with human subjects to determine the upper boundof performance for automatic metrics of semantic relatedness.
While this task is moredifficult than computing semantic similarity, human judgments display a high interclasscorrelation.
We evaluated our approach against this dataset, see Section 4, and com-pared it with baseline systems.
The proposed metric achieves the same performanceas a popular extrinsic (information content based) metric by [8], and is significantlybetter than the results of a conventional dictionary based measure [1] employing aUsing the Structure of a Conceptual Network 769machine-readable dictionary compiled by human writers.
To exhaustively evaluate themetric, we introduced an additional baseline based on co-occurrences of words in theWeb.
A summary of the results is given in Section 5.2 Definitions in Dictionaries and Conceptual NetworksDefinitions of words and their distinct senses are essential to our approach.
What is thedefinition of a good definition?
This question has been disputed in philosophy since thedays of Platon and Euklid, recently also in the disciplines such as cognitive science andlinguistics.
Different types of definitions were proposed, whose names are expressedin various terminologies, e.g.
lexical, theoretical, circular and the definition by genusand difference to name just a few.
Lexical definitions are what we typically find ina dictionary.
They often suffer from inaccuracies as they are confined to establishedmeanings and can prove to be confusing for example in legal matters.
According to[13], a good definition should include several indisposable components: a functionalpart describing what the concept is intended for, the characteristics of the definiendumcontrasting the general with particular, and context (time, place, cultural and mental).For example, ?window?
is a planar discontinuity in a solid artificial (context) surface(genus), which allows to look through it, or for the penetration of light or air (whennot covered or open) (differentia).
Without the differentia ?
with the genus alone ?
thedefinition can well fit the door; without the context, the definition can well fit a hole ina rock.When human writers create definitions, they take care of the structural elements andrequirements described above.
On the other hand, when creating conceptual networks,dictionaries and language based examples are often employed as knowledge sources todetermine lexical and semantic relations between words.
Therefore, information aboutfunctions, general terms, and context is integrated into a conceptual network.
The mainidea explored in the present paper is, then, the possibility to extract knowledge aboutconcepts from the conceptual network based on known properties of definitions andhow they are encoded in the network.
We call extracted pieces of knowledge pseudoglosses.
Pseudo glosses can be used in the situations when textual definitions properare not available.
The information encoded in the network as lexical semantic relationsis transformed into artificially generated glosses.
Those can be employed in NLP ap-plications.
An additional advantage of pseudo glosses as opposed to real glosses is thepossibility to include or exclude certain types of information from a gloss.
This way,glosses can be easily tailored to a specific task at hand.
In our application, this amountsto experimentally determining the types of information crucial for computing semanticrelatedness.The knowledge base employed in our experiments is GermaNet [14], the Germancounterpart of WordNet [15].
Direct re-implementation of semantic relatedness metricsdeveloped for WordNet on the basis of GermaNet is not a trivial task.
While sharingmany design principles with WordNet, GermaNet displays a number of divergent fea-tures [16].
Some of them, such as the lack of conceptual glosses, make it impossible toapply dictionary based metrics in a straightforward manner.
Therefore, pseudo glossesare generated directly from the conceptual network.770 I. GurevychWe experimented with different parameters that control which concepts are includedin a pseudo gloss:?
size determines the length of a path for the hypernyms to be included in a pseudogloss.
The values of size range over the interval [1, depthmax], where depthmax isthe maximum path length in a conceptual network.
The depth is equivalent to theheight in this context.?
limit determines the length of a path from the root node of a hierarchy (i.e.
the mostabstract concept) towards a given concept.
The concepts of the path are excludedfrom the pseudo gloss.
The values of limit range over the interval [0, depthmax].Given limit = 0 no concepts will be excluded from the pseudo gloss, and givenlimit = depthmax the resulting pseudo gloss contains solely the given word senseitself.
If size and limit are conflicting (e.g.
the concept A should be included ac-cording to size, and excluded according to limit), the latter takes precedence overthe former.?
one sense per synset (OSPS) parameter, either true or false.
A synset is often rep-resented by multiple synonymous word senses.
If the parameter is set to true, onlyone word sense from a synset will be included into a pseudo gloss (this is also thecase in paper dictionaries).
Otherwise, all word senses of a synset are included.?
lexical semantic relations control the type of relations in a conceptual networkwhich are involved in generating pseudo glosses, i.e.
hypernymy, hyponymy, syn-onymy, meronymy, association, etc.Table 1 presents examples of pseudo glosses generated according to two differentsystem configurations: a radial gloss (all lexical semantic relations of a given conceptare taken into account, except hyponyms, OSPS = true, size = 3), and a hypernymgloss (only hypernymy relation is considered, OSPS = true, size = 3, limit = 2).Table 1.
Examples of pseudo glosses for ?Bruder ?
Bursche?Radial glosses Hypernym glossesBursche1.
junger Mensch, Erwachsener, Bursche, Bub, 1.
Bursche, Junge,Junge, Knabe, Bube, Kind, Ju?ngling KindBruder1.
Bruder, Geschwister, Mitmensch, Familie, Verwandter 1.
Bruder2.
LaienpredigerIn, Fachkraft, unausgebildeter Mensch, 2. unausgebildeter Mensch,Geistlicher, Prediger, ausgebildeter Mensch, Bruder, Geistlicher, Prediger, Laie,Berufsta?tiger, Laie, Laienprediger Laienprediger3.
christlicher Sakralbau, Kloster, Geistlicher, 3.
Geistlicher,Mo?nch, Bruder, Mo?nchskloster, Ordensangeho?riger, Ordensangeho?riger, Mo?nchBerufsta?tiger, Glaubensgemeinschaft, Orden, Laie3 Dictionary Based MetricsDictionary based metrics of semantic relatedness were introduced by [1] and received alot of attention in the context of work on word sense disambiguation.
The main ideaUsing the Structure of a Conceptual Network 771of this work is to permutate all textual definitions of the senses of two words andto assign them a score based on the number of word overlaps in glosses.
Thus, thecontext which matches best the combination of the two words is assumed to be thedisambiguated sense.
This can also be viewed as a metric of how the two words aresemantically related.A dictionary gloss is typically represented by textual definitions of word senses cor-responding to a given word.
E.g.
in the Digital Dictionary of the German Language1 wefind the following definitions of ?Bruder?
(Engl.
brother), s. Example (1) and ?Bursche?(Engl.
fellow or lad), s. Example (2).
(1) Bruder, der; -s, Bru?der /Verkl.
: Bru?derchen, Bru?derlein/(11) jede ma?nnliche Person einer Geschwisterreihe in ihrer Beziehung zu jedem anderenKind derselben Geschwisterreihe(12) a) enger Freund, Gesinnungsgenosse: b) scherzh.
unter Bru?dern offen, ehrlichgesprochen: c) Rel.
kath.
Mo?nch: d) scherzh.
/bezeichnet algemein einen Mann/ e) saloppabwertend Bursche, Kerl(2) Bursche, der; -n, -n /Verkl.
: Bu?rschchen, Bu?rschlein/(21) ma?nnliche Person a) Knabe, Junge b) junger Mann c) vertraul.
alter B.
(Freund)!
d)Studentenspr.
Student einer Verbindung e) veraltend Diener, der einem anderen fu?rperso?nliche Dienstleistungen zur Verfu?gung steht(22) umg.
kra?ftiges TierIn Table 2, we present the results of the Lesk algorithm applied to this word pair.The overlaps are counted on the basis of stems because the German language is highlyinflected.
The sense combination 12 ?
21 turns out to be the best fitting one resulting inthree overlaps of stems friend, man, lad.
[17] adopts the algorithm by Lesk and applyTable 2.
The Lesk algorithm applied to ?Bruder?Bursche?Sense combin.
Stem overlaps Score11 ?
21 ma?nnlich, Person 211 ?
22 ?
012 ?
21 Freund, Mann, Bursch 312 ?
22 Bursch 1it to the task of computing semantic relatedness of WordNet concepts.
Their metricis based on the number of shared words in the glosses of concepts available throughWordNet.
They extend the metric to include the glosses of other concepts, to whichthey are related according to the WordNet hierarchy.
Those are encoded in WordNetas semantic relations, but can be found in any dictionary via synonyms, antonyms, andsee-also references.
The relatedness score relw1,w2 is formally defined in Equation 3:relc1,c2 =?score(R1(c1), R2(c2)) (3)where c1 and c2 are the compared word senses, R is a set of lexical semantic relations,score() is a function which receives the definitions of word senses and their related1 http://www.iai.uni-sb.de/iaide/de/dwds.htm772 I. Gurevychconcepts and returns a numeric score of word overlaps in them.
[17] reports a correla-tion of .67 to the Miller and Charles human study, and one of .60 to the Rubenstein andGoodenough?s experiment, which is below the performance of other semantic related-ness metrics reported in [2].
E.g.
the metric by Resnik yielded a correlation of .774 and.779 on the datasets respectively.4 Experimental WorkIn this section, we detail the process of generating artificial glosses from GermaNet.We discuss the set of parameters, their consequences for the creation of glosses andthe application of artificially generated glosses to the task of computing semantic relat-edness.
The evaluation, then, measures the performance of semantic relatedness algo-rithms based on pseudo glosses with respect to human judgments of semantic related-ness.
We apply the Lesk algorithm to pseudo glosses and compute a semantic related-ness score for each sense combination of a word pair.
The scores are related to averagehuman ratings by means of interclass correlation analysis.As no datasets for evaluating semantic relatedness are available, we translated 65word pairs from the dataset by [4] to German.
Their word pairs were selected to covera range of semantic distances.
We asked 24 subjects (native speakers of German) torate the word pairs on the scale from 0 to 4 for their semantic relatedness.
Semanticrelatedness was defined in a broader sense than just similarity.
To determine the up-per bound of performance for automatic semantic relatedness metrics, we computeda summarized correlation coefficient for a set of 24 judges.
This means that we com-puted correlations for all judges pairwise, transformed them to a Z-score, computedthe average and transformed back to a correlation coefficient yielding r = .8098,which is statistically significant at p = .01.
The evaluation results for relatednessmetrics are reported on the basis of 57 from 65 word pairs in the test dataset com-pared with average human judgments.
The remaining words were not covered inGermaNet.4.1 Experiment 1We evaluated different methods to generate pseudo glosses according to the parameters:lexical semantic relations and size.
The range of values for size was set from 2 to 6.
Thefour system configurations for generating pseudo glosses were the following:1. a radial gloss based on all types of lexical semantic relations in GermaNet;2. a hypernymy gloss based exclusively on the hypernymy relation;3. a hyponymy gloss utilizing the hyponymy relation only;4. a gloss consisting of coordinate sisters of a given concept, i.e.
the immediate hy-ponyms of the concepts?
hypernyms.Table 3 presents the results for the four system configurations (Column ?Config.?
),whereby the best result for each configuration is printed in bold.
Radial and hyper-nymy glosses yield better results as hyponymy and coordinate sisters glosses.
This hap-pens because pseudo glosses generated by these system configurations resemble theUsing the Structure of a Conceptual Network 773structural components of conventional glosses more accurately.
In Examples 1 and 2,we hardly find hyponyms in the definitions.
At the same time, e.g.
Lausbube would beincluded in the gloss as a hyponym and Boy as a coordinate of Bursche.
Summarizingthis experiment, we conclude that the information on hyponymy and coordinate wordsenses for computing semantic relatedness is not very relevant.
The remaining systemconfigurations will be further analyzed in the following.4.2 Experiment 2The aim of the experiment was to examine the performance of radial glosses underdifferent experimental conditions.
We observed that many high scores of semantic re-latedness were caused by a large number of hyponyms that some of the words, e.g.Edelstein (Engl.
gem) and Juwel (Engl.
jewel) have.
Due to this effect, e.g.
at size = 3,the number of overlaps for radial glosses increases to 199, whereas it is only 7 for hy-pernym glosses.
As there exist no well-defined guidelines or criteria as to what numberof hyponyms a synset should have, it is rather arbitrary and heavily skews the distribu-tion of semantic relatedness scores.Another parameter one sense per synset (OSPS) controls whether all of the wordsenses belonging to a synset are included in a pseudo gloss or only one.
The motiva-tion to investigate this effect is similar to the one described previously, i.e.
the numberof synonyms (word senses) for a given synset is arbitrary.
This means that countingoverlaps according to the Lesk algorithm will ?favour?
those word pairs, whose synsetshave a large number of word senses.Table 4 shows the results of the hyponyms = true/false parameter variation.
Wealso varied the size while OSPS was set to true and false.
The data makes evidentthat ignoring hyponyms in generating pseudo glosses consistently improves the perfor-mance.
It eliminates the bias in the counts of overlaps due to hyponyms, which do notskew the overall distribution of scores any more.
Table 5 further explores the effects ofthe size parameter and OSPS = true/false variation.
For radial glosses, the resultsof OSPS = true are better for size from 3 to 6.Table 3.
Evaluation results for differenttypes of pseudo glossesConfig.
Size=2 Size=3 Size=4 Size=5 Size=61 .3885 .4570 .4377 .4027 .40212 .5936 .6350 .6682 .6072 .62793 .3167 .3296 .3244 .3322 .35384 .3140 .2560 .2474 .2062 .1305Table 4.
Hyponyms true/false for radialglossesHypo true Hypo falseOSPS true, size 1 .3939 .4513OSPS true, size 2 .4235 .5494OSPS false, size 1 .3885 .4945OSPS false, size 2 .4570 .55674.3 Experiment 3We explored the application of hypernym glosses to computing semantic relatedness.Several issues were checked, such as the use of the one sense per synset true versus774 I. Gurevychfalse in glosses, the use and interaction of size and limit as well as the optimal set-tings for those.
The results of this experiment are presented in Figure 1, which showsthe correlation values for different combinations of size and limit settings.
The valueOSPS = true leads to consistently better results for the parameter combinations ofsize and limit.
Furthermore, the performance of the system rapidly drops for the limitrange [4,6].
However, the use of limit is generally justified as it improves the perfor-mance for size = 2 and size = 3.
At these points the performance is most optimal, s.Table 6 for exact results.If neither size nor limit are in use (which corresponds to the case when all hy-pernyms of a concept become part of the gloss), the correlation drops to .568.
Theseparameters, therefore, turn out to be necessary to control the choice of concepts in agloss.
As a consequence, the most abstract (close to the root) concepts of the hierarchywill not appear in the gloss.Table 5.
Evaluation results with OSPS true/false forradial glossesSize 1 Size 2 Size 3 Size 4 Size 5 Size 6OSPS false .4945 .5567 .5507 .5299 .5247 .4871OSPS true .4513 .5494 .5525 .5444 .5309 .5075Table 6.
Scope/limit in hypernympseudo glossesScope;limit (2;0) (2;1) (2;2) (2;3)r .6192 .6456 .6768 .6581Scope;limit (3;0) (3;1) (3;2) (3;3)r .6682 .6735 .6914 .6842Fig.
1.
Correlation r for one per synset = true/false.
r(scope,limit) is plotted for scope =[1; 6], limit = [0; 6].Using the Structure of a Conceptual Network 7755 Evaluation SummaryTo our knowledge, no datasets are available for validating the results of semantic re-latedness metrics.2 The results obtained for semantic similarity with WordNet are notdirectly comparable due to differences in the underlying knowledge bases, and ?
mostimportantly ?
in the task definition (changed from similarity to relatedness).
The datasetdesigned during the present study is based on the German language.
We opted for Ger-maNet as the underlying semantic network.
Testing the results of metrics for anotherlanguage, e.g.
English, would involve an experiment with native speakers to collectjudgments of semantic relatedness and employing an appropriate semantic resource forthe chosen language and the domain of interest.
However, our evaluation results canbe extrapolated to other languages and similar semantic resources, as semantic related-ness metrics themselves are not tied to a particular language or resource.
Experimentalverification of this fact remains beyond the scope of our paper.To better understand the performance of the semantic relatedness metrics, we de-signed and implemented several baselines.
The first baseline compares the performanceof our system to the original version of the Lesk algorithm operating on the glossesfrom traditional dictionaries written by human authors.
As GermaNet itself does notcontain a sufficient number of textual definitions of word senses, they were retrievedfrom the Digital Dictionary of the German Language.3 We excluded all additionalinformation from definitions, such as citations and examples of usage.
The remain-ing ?pure?
definitions were stemmed.
The resulting correlation with human judgmentsyielded r = .5307.The second baseline for the evaluation was represented by word co-occurrencecounts obtained by means of querying the Web through Google.
This baseline is basedon the assumption that the Web can be used as a corpus.
[18] provide estimates of theWeb size in words, as indexed by Altavista, for the German language: 7,035,850,000.This exceeds the size of freely available German corpora by a large margin.
We con-structed Google queries, where the query string was represented by a particular wordpair.
Semantic relatedness of words was, then, computed according to Equation 4, wherehitsw1 and hitsw2 are the frequencies of words w1 and w2.
The correlation of Googlebased results with human judgments of semantic relatedness was .5723, which is quiteimpressive if we consider that the method does not employ any sophisticated knowledgesources.
It should be noted that we tried several other established measures of lexicalassociation, e.g.
PMI and log-likelihood on Google counts, but the results were worsethan those achieved by Equation 4.simw1,w2 = hitsjoint/hitsw1 + hitsjoint/hitsw2 (4)The third baseline is a conventional approach by [8] to compute semantic related-ness via the information content of the lowest common subsumer of the two concepts.Information content of concepts was calculated on the basis of a German newspapercorpus with 172 million tokens (www.taz.de).2 English datasets were designed with semantic similarity in mind as described in Section 4.3 In fact, any other machine-readable dictionary for German could have been employed instead.776 I. GurevychIn Figure 2, we summarize the results of our experimental work.
These results arebased on the most optimal system configurations as described in Section 4: OSPS =true, hyponyms = false, size = 3 for radial glosses, OSPS = true, size = 4,limit = 2 for hypernym glosses.
The results show that radial pseudo glosses performapproximately on the same level (r = .5525) as the stemmed glosses created by humans(r = .5307).
This suggests that radial pseudo glosses mimic the behavior of ?real?glosses rather well.
Hypernym pseudo glosses outperform their radial counterparts andboth the Lesk and the Google based baselines by a large margin, yielding r = .6914.Their performance is comparable to that of a conventional method by [8] based onexternal corpus evidence (r = .7152).As the method operates exclusively on pseudo glosses generated on the basis ofthe hypernymy relation, this type of information from definitions turns out to be themost important one for computing semantic relatedness.
In other words, definitio pergenus proximum is superior to definitio per differentia specifica in this task.
It shouldbe noted that the situation can change for different types of tasks where the knowledgefrom a conceptual network is employed, e.g.
in word sense disambiguation.
As opposedto using textual definitions from traditional dictionaries, generating them automaticallyfrom a conceptual network has a great advantage: we can easily control the usage ofspecific types of information with the help of a set of parameters.
In naturally occurringtexts, this is problematic, as the required information should be first extracted from freetext, a task not trivial to achieve.Fig.
2.
A summary of evaluation resultsIf compared to results reported for the task of computing semantic similarity on thebasis of WordNet, we note that our numbers are lower due to a number of reasons:?
The upper bound for the performance of computational algorithms is lower for ourtask (r = .8089) as the one given by [8] (r = .8848).
Semantic relatedness is notas well defined as semantic similarity.
The results have to be interpreted accordingto this lower upper bound.?
The performance of the metrics is dependent on the underlying knowledge base,i.e.
WordNet versus GermaNet.
Apparently, GermaNet has a lower coverage thanWordNet.
E.g.
no lowest common subsumers are found for some word pairswhereas those exist in WordNet, and some links are missing.
Of course, the qualityof a conceptual knowledge base and the quality of resulting glosses are stronglycorrelated.Using the Structure of a Conceptual Network 7776 ConclusionsWe proposed a method to generate artificial definitions of concepts from a concep-tual network.
The method was applied to the task of computing semantic relatednessof words and tested on the basis of word senses defined in GermaNet.
This approachbridges the gap between gloss based algorithms and the cases, when textual defini-tions of concepts are not available.
This is the case for languages, which do not havewell developed machine readable dictionaries, and in many applications which do havedomain-specific taxonomies, but no additional descriptions of concepts.
The main ideais to compensate for the lack of definitions in a conceptual hierarchy by generating atextual definition of the concept automatically from a knowledge base.
NLP applica-tions can then employ the resulting glosses.We have restricted ourselves to nouns in this work, since this part of speech is veryimportant in NLP and thus represents a good starting point.
However, the metrics areapplicable to other parts of speech represented in a conceptual network.
The results of asemantic relatedness metric operating on automatically generated glosses correlate verywell with human judgments of semantic relatedness.
The metric performs significantlybetter than the Lesk algorithm itself, employing a traditional dictionary, and the baselinebased on word co-occurrences in Web pages (Google hits).
It performs on the same scaleas the information content based metric, while no additional processing of corpus datais necessary.We expect to enhance the work presented here in a number of respects.
First ofall, we are working on a considerably larger dataset including 350 word pairs withcorresponding semantic relatedness judgments.
The word pairs involve not only nouns,but verbs and adjectives as well.
The reliability of human judgments as well as theperformance of semantic relatedness metrics based on the new dataset remain to bestudied.
Also, we have to find our what kind of modifications may be necessary tomake the metrics applicable across different parts-of-speech.AcknowledgmentsThis work has been funded by the Klaus Tschira Foundation.
I would like to thankHendrik Niederlich who contributed implementations as a part of an internship andMichael Strube for his valuable comments concerning draft versions of this paper.References1.
Lesk, Michael: Automatic sense disambiguation using machine readable dictionaries: Howto tell a pine cone from an ice cream cone.
In Proceedings of the 5th Annual InternationalConference on Systems Documentation, Toronto, Ontario, Canada, June, 1986, pages 24?26.2.
Hirst, Graeme and Budanitsky, Alexander: Correcting real-word spelling errors by restoringlexical cohesion.
In Natural Language Engineering, 11(1):87?111, 2005.3.
Pedersen, Ted and Patwardhan, Siddharth and Michelizzi, Jason: WordNet::Similarity ?
Mea-suring the relatedness of concepts.
In Intelligent Systems Demonstrations of the NineteenthNational Conference on Artificial Intelligence (AAAI-04), San Jose, CA, 25?29 July 2004.778 I. Gurevych4.
Rubenstein, Herbert and Goodenough, John: Contextual Correlates of Synonymy.
In Com-munications of the ACM, 8(10), 1965, pages 627?633.5.
Miller, George A. and Charles, Walter G.: Contextual correlates of semantic similarity.
InLanguage and Cognitive Processes, 6(1), 1991, pages 1?28.6.
Leacock, Claudia and Chodorow, Martin: Combining local context and WordNet similarityfor word sense identification.
In Fellbaum, Christiane (Ed.)
WordNet: An Electronic LexicalDatabase, Cambridge: MIT Press, 1998, pages 265?283.7.
Seco, Nuno and Veale, Tony and Hayes, Jer: An Intrinsic Information Content Metric for Se-mantic Similarity in WordNet.
In Proceedings of the 16th European Conference on ArtificialIntelligence, Valencia, Spain, 22?27 August 2004, pages 1089?1090.8.
Resnik, Phil: Using information content to evaluate semantic similarity in a taxonomy.
InProceedings of the 14th International Joint Conference on Artificial Intelligence, Montre?al,Canada, 20?25 August 1995, Volume 1, pages 448?453.9.
Jiang, Jay J. and Conrath, David W.: Semantic similarity based on corpus statistics and lex-ical taxonomy.
In Proceedings of the 10th International Conference on Research in Compu-tational Linguistics (ROCLING), Tapei, Taiwan, 1997.10.
Lin, Dekang: An information-theoretic definition of similarity.
In Proceedings of the 15thInternational Conference on Machine Learning, San Francisco, Cal., pages 296?304, 1998.11.
Patwardhan, Siddharth and Banerjee, Satanjeev and Pedersen, Ted: Using measures of se-mantic relatedness for word sense disambiguation.
In Proceedings of the Fourth InternationalConference on Intelligent Text Processing and Computational Linguistics, Mexico City, Mex-ico, pages 241?257, 2003.12.
Ekedahl, Jonas and Golub, Koraljka: Word Sense Disambiguation using WordNet and theLesk algorithm, http://www.cs.lth.se/EDA171/Reports/2004/jonas koraljka.pdf, 2004.13.
Vaknin, Sam: The definition of definitions, http://samvak.tripod.com/define.html, 2005.14.
Kunze, Claudia: Lexikalisch-semantische Wortnetze.
In Carstensen, K.-U.
and Ebert, C. andEndriss, C. and Jekat, S. and Klabunde, R. and Langer, H.
(eds.)
Computerlinguistik undSprachtechnologie.
Eine Einfu?hrung.
Heidelberg, Germany: Spektrum Akademischer Ver-lag, 2004, pages 423?431.15.
Fellbaum, Christiane (Ed.
): WordNet: An Electronic Lexical Database.
MIT Press, Cam-bridge, Mass., 1998.16.
Kunze, Claudia and Lemnitzer, Lothar: GermaNet - representation, visualization, applica-tion.
In Proceedings of the International Conference on Language Resources and Evaluation(LREC), Las Palmas, Canary Islands, Spain, 29 - 31 May, 2002, pages 1485-1491.17.
Banerjee, Satanjeev and Pedersen, Ted: Extended gloss overlap as a measure of semanticrelatedness.
In Proceedings of the 13th International Joint Conference on Artificial Intelli-gence, Chambery, France, 28 August ?
3 September, 1993.18.
Kilgarriff, Adam and Grefenstette, Gregory: Introduction to the special issue on the Web asa corpus.
In Computational Linguistics, 29(3), 2003, pages 333?348.
