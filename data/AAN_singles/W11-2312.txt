Proceedings of the 2nd Workshop on Speech and Language Processing for Assistive Technologies, pages 110?119,Edinburgh, Scotland, UK, July 30, 2011. c?2011 Association for Computational LinguisticsLekbot: A talking and playing robot for children with disabilitiesPeter Ljungl?fComputer Science and EngineeringUniversity of Gothenburg, Swedenpeter.ljunglof@gu.seBritt ClaessonIngrid Mattsson M?llerDART: Centre for AAC and ATQueen Silvia Children?s HospitalGothenburg, Sweden{britt.claesson,ingrid.mattsson-muller}@vgregion.seStina EricssonCajsa Ottesj?Philosophy, Linguistics andTheory of ScienceUniversity of Gothenburg, Sweden{stina.ericsson,cajsa.ottesjo}@gu.seAlexander BermanFredrik KronlidTalkamatic ABGothenburg, Sweden{alex,fredrik}@talkamatic.seAbstractThis paper describes an ongoing projectwhere we develop and evaluate a setup in-volving a communication board and a toyrobot, which can communicate with eachother via synthesised speech.
The purposeis to provide children with communicativedisabilities with a toy that is fun and easyto use together with peers, with and with-out disabilities.
When the child selectsa symbol on the communication board,the board speaks and the robot responds.This encourages the child to use languageand learn to cooperate to reach a commongoal.
Throughout the project, three chil-dren with cerebral palsy and their peersuse the robot and provide feedback for fur-ther development.
The multimodal inter-action with the robot is video recorded andanalysed together with observational datain activity diaries.1 BackgroundThe vision of our project is to utilise currenttechnology in human computer interaction anddialogue systems to provide young people withcommunication disabilities with a fun and ex-citing toy.
Currently there are not many op-portunities for children with severe disabilitiesto play independently and to interact on equalterms with typically developing children.
Ourhope is that the toy will give children, with andwithout disabilities, the opportunity to interactFigure 1: The robot and the communication boardand play with each other.
As a side effect thiscan also help them develop their communicativeskills.We are developing a remote-controlled robotthat can be used by children with severe phys-ical and/or communicative disabilities, such ascerebral palsy or autism.
The child communi-cates by selecting a symbol on a communicationboard, which is translated into an utterance us-ing a speech synthesiser.
The robot responds us-ing synthesised utterances and physical actions,that the child in turn can respond to.
The com-munication board acts as an extension of thechild, by giving the child speech as a means ofcommunication.
The robot and its communica-tion board is shown in Figure 1.Technically the robot is controlled wirelessly,110with no speech recognition.
The spoken dialogueis there for the benefit of the child, and enablesthe child to engage in a spoken dialogue, withouthaving the physical and/or cognitive ability todo so.
Our hope is that this will facilitate thechild?s own language development while havingfun with the radio-controlled robot.1.1 The Lekbot projectThe Lekbot project is a collaboration betweenDART,1 Talkamatic AB and the University ofGothenburg.
It is funded by VINNOVA2 andruns from March 2010 to August 2011.The project is similar to the TRIK project(Ljungl?f et al, 2009), which developed a draw-ing robot that was controlled in the same man-ner as above.
The very limited user study thatwas conducted suggested that the product hadgreat potential.
The current project can be seenas a continuation of TRIK, where we perform amore full-scale user study, with video recording,transcription, interaction analyses, etc.1.2 Dialogue systems and robotsMost existing dialogue systems are meant to beused by competent language users without phys-ical, cognitive or communicative disabilities; ei-ther they are supposed to be spoken to (e.g.,phone based systems), or one has to be able totype the utterances (e.g., the interactive agentsthat can be found on the web).
Dialogue sys-tems for users with disabilities have so far beentargeted at people with physical disabilities, whoneed help in performing daily activities.Dialogue systems have also been used for sec-ond language learning; i.e., learning a new lan-guage for already language competent people.Two examples are the artificial agent ?Ville: TheVirtual Language Tutor?
(Beskow et al, 2004),and ?SCILL: Spoken Conversational Interfacefor Language Learning?, a system for practicingMandarin Chinese (Seneff et al, 2004).However, we are not aware of any exampleswhere a dialogue system is used for communicat-1Centre for AAC and AT at the Queen Silvia Chil-dren?s Hospital2The Swedish Governmental Agency for InnovationSystemsing with people with communication disorders.With the advent of tablet computers, therenow exist several spoken-language and touch-screen apps for children?s games and interactiveand linguistic training.
In these apps, the in-teraction is between the child and the tablet,whereas in Lekbot the child and the tablet acttogether as one dialogue participant, interact-ing with the robot.
The Lekbot robot is also aphysical agent, acting in the world, thus addinganother dimension to the interaction.When it comes to robots, there are a numberof past and present research projects on robotsand children.
An early inspiration is the LOGOrobot developed at Massachusetts Institute ofTechnology for teaching children to use com-puters and program simple applications (Papert,1993).
There are several robots focusing on chil-dren with disabilities (Robins et al, 2008; Sal-dien et al, 2006; Kozima et al, 2007; Lee et al,2008; Arent and Wnuk, 2007), and most com-monly autism.
Some of these communicate withchildren in different ways.
For instance, KAS-PAR is a child-sized humanoid robot for chil-dren with autism, and it trains interactional ca-pabilities through gesture imitation.3 Probo, de-veloped for hospitalised children, produces non-sense speech intended to convey different feel-ings.4 KOALA is a small round ball that in-teracts with children with autism using lightsand sounds (Arent and Wnuk, 2007).
However,none of these robots and research projects in-volves natural language communication in anyform between the child and the robot.2 Project descriptionOur basic idea is to use a dialogue systemto stimulate play and interaction for childrenwith severe communicative disabilities.
Thereare already communication boards connected tospeech synthesis in the form of communicationsoftware on computers.
The main values thatthis project adds to existing systems are that:?
the child is offered an exciting, creative andfun activity3http://kaspar.feis.herts.ac.uk/4http://probo.vub.ac.be/111?
the child can play and interact with otherpeers on equal terms?
the child can explore language in stimulat-ing cooperation with the robot and withother childrenBy being able to use a symbol-based communi-cation board the children are given an opportu-nity to play, interact, explore language, and atthe same time learn to use tools for alternativeand augmentative communication.2.1 Description of the systemThe child has a communication board that cantalk; when the child points at one of the symbolsit is translated to an utterance which the boardexpresses via speech synthesis in Swedish.
Thisis recognised by a robot that moves around in theroom, and performs the commands that the childexpresses through the board.
The robot has anincarnation as a toy animal, currently a bumble-bee.
It has a very basic personality which meansthat it can take the initiative, without the childtelling it, refuse actions, or even negotiate withthe child.The inspiration for the robot comes from robottoys such as babies, dogs and dinosaurs, butalso from electronic pets such as Tamagotchi andTalking Tom.
The main difference is that ourrobot is able to have a dialogue with the child,to find out what to do, or just to be teasinglyplayful.The Lekbot robot can move forward and back-ward, and turn right and left.
Furthermore itcan perform actions such as laughing, dancing,yawning, farting and eating.
The functionalityis constantly improving during the evaluation, tokeep the children interested in playing with therobot.2.2 Needs and potentialThe target audience is children with severephysical, cognitive or communicative disabilities.These children depend on assistive devices andpersons to be able to interact with other peopleand artifacts.
The idea is that the robot will bea fun toy that gives the child an opportunity tocontrol the artifacts itself, without the help ofother people.
Hopefully this will increase thechild?s confidence, and also promote languagedevelopment.2.2.1 The importance of playPlay may be defined by the following terms(Knutsdotter Olofsson, 1992):?
spontaneous; the child takes the initiative,not the adults?
not goal-oriented; the game does not havean explicit purpose?
fun and pleasurable?
repeating; that it can be played many timesas one wants?
voluntaryFor children with severe disabilities, playing re-quires adult help, and it is difficult for the adultnot to control the game, especially if the childhas problems communicating what it wants.
Of-ten play is used as a tool for development train-ing, and many times play is so scheduled thatit is no longer spontaneous (Brodin and Lind-strand, 2007).
A toy that is always available forthe child to play with whenever it wants, andon its own terms can help the child to play ?forreal?.Children learn from each other, and a toy thatis used on equal terms by children, with andwithout disabilities, encourages interaction thatotherwise would not have been possible betweenchildren with such diverse backgrounds.2.2.2 Educational advantagesAs discussed in section 3.3 later, the setupworks without the robot and the communicationboard actually listening to each others?
speech ?instead, they communicate wirelessly.
However,there is an important educational point in hav-ing them (apparently) communicate using spo-ken language.
It provides the child with an ex-perience of participating in a spoken dialogue,even though the child is not physically able tospeak.
For children who are more advanced intheir language development, the robot can offer112the opportunity to understand the basic proper-ties of the dialogue, such as taking turns, askingand answering questions, the importance of pro-viding sufficient information, and cooperating toachieve a shared goal.
Another educational ad-vantage is that the child learns to use tools foralternative and augmentative communication.3 ImplementationThis section describes some technical aspects ofthe implementation of the Lekbot system.3.1 ComponentsThe final Lekbot setup consists of the followingcomponents:?
a simple LEGO Mindstorms robot whichcan turn and move in all directions, canperform different specialised actions, andhas a ?costume?
which makes it look likea bumble-bee?
a touch-screen computer which functions asa communication board, and a custom sup-port frame for the computer?
the dialogue system GoDiS (Larsson, 2002),using Acapela Multimedia text-to-speechwith Swedish voices?
Bluetooth communication and wireless au-dio transmission, from the touch-screencomputer to the robot, and two sets of loud-speakers, for the computer and the robotIf the target user already has his or her ownWin-dows based communication device, with adaptedaccessibility for him or her, this special softwarefor the robot play can be installed on this device.Note that it is the communication board com-puter that controls the robot via the dialoguesystem, but the intention is that it should seemlike the robot is autonomous.
Every utteranceby the robot is executed by the speech synthe-siser, and then sent to the robot via radio.3.2 LEGO MindstormsThe robot is built using LEGO MindstormsNXT,5 a kind of technical lego which can be con-5http://mindstorms.lego.com/trolled and programmed via a computer.
Apartfrom being cheap, this technology makes it easyto build a prototype and to modify it during thecourse of the project.3.3 Perfect speech recognitionTypically, the most error-prone component of aspoken dialogue system is speech recognition;the component responsible for correctly inter-preting speech.
This of course becomes evenmore problematic when working with languagelearning or communication disorders, since inthese situations it is both more difficult and moreimportant that the computer correctly hears andunderstands the user?s utterances.
An advan-tage of the Lekbot setup is that we will, in asense, have ?perfect speech recognition?, sincewe are cheating a bit.
The robot does not ac-tually have to listen for the speech generated bythe communication board; since the informationis already electronically encoded, it can insteadbe transferred wirelessly.
This means that therobot will never hear ?go forward and then stop?when the communication board actually says ?goforward seven steps?.3.4 The GoDiS dialogue managerA dialogue system typically consists of severalcomponents: speech recogniser, natural lan-guage interpreter, dialogue manager, languagegenerator, speech synthesiser and a short-termmemory for keeping track of the dialogue state.One can make a distinction between dialoguesystems, which (ideally) are general and reusableover several domains, and dialogue system appli-cations, which are specific to a certain domain.The dialogue manager is the ?intelligence?
of thesystem, keeping track of what has been said sofar and deciding what should be said next.The GoDiS dialogue manager (Larsson, 2002)has been developed at the Department of Philos-ophy, Linguistics and Theory of Science at theUniversity of Gothenburg over several years.
Itis designed to be easily adaptable to new do-mains, but nevertheless be able to handle a va-riety of simpler or more complex dialogues.
Forexample, GoDiS can either take initiative andprompt a user for information, or take a back113seat and let the experienced user provide infor-mation in any desired order, without having towait for the right question from the system.From the viewpoint of dialogue systems re-search, there are some interesting aspects in theLekbot setting:?
Constantly changing environment : the sur-roundings of the robot can change all thetime, and the dialogue system needs toadapt?
Alternative input modalities: instead ofspeech input, we are using a touch screen in-terface, on which the symbols on the screenalso changes depending on the current dia-logue state?
Utterance generation: it is important for ev-eryone, but in particular children with com-municative disabilities, that information ispresented in a correct way ?
with correctand consequent grammar, lexicon and pro-nunciation3.5 Utterance generationClear pronunciation is important, and perhapseven more important when we are dealing withcommunicative disabilities.
We are experiment-ing with using different utterance generationstrategies and stressing important words to makethe children understand the robot better.
Inter-estingly, user feedback from children and pre-schools during the project has also indicatedwhen default intonation does not work and needsto be modified.The Lekbot system uses two different voices,one for the touch screen, acting as the child?svoice, and one for the robot.
Whereas the touch-screen voice is a vocalisation of something thechild has already seen on the screen, the utter-ances of the robot have no visualisations.
Hence,it is particularly important that the robot?s ut-terances are as clear as possible, and the TTSvoice chosen for the robot is therefore the voicethat was determined to have the best and mostflexible intonation in informal perception testsat the start of the project.3.5.1 Contextual intonationWe have incorporated models of informationstructure in GoDiS to enable the appropriateassignment of phonological emphasis (Ericsson,2005).Lekbot uses a fairly basic dialogue-move-to-string mapping for the creation of output utter-ances, which are then fed to the speech synthe-siser.
Determining the information structure ofan utterance to be generated, involves the deter-mination of what is informative in the utterance?
the focus ?
and what is a reflection of some-thing already in the context ?
the ground (Vall-duv?, 1992).
The system assigns emphasis to allalternatives, that is, all contrasting elements, inalternative questions, that are produced by therobot.
Consider the following example:User : Go forward.Robot : Do you want me to go forwarda lot or go forward a little?For the generation of the robot utterance, thesystem determines ?go forward a lot?
and ?goforward a little?
as alternatives, and assigns em-phasis to these.
Future development of the sys-tem may involve the inclusion of informationstructure also for utterances other than non-alternative questions, to determine appropriateintonation assignment more generally.Unfortunately, we have not yet been able touse this feature in the actual demonstration sys-tem, since the Swedish TTS voices do not em-phasise properly with regard to the markup.
In-stead we have tuned the utterances lexically andsyntactically to make the best possible use of thedefault TTS intonation.4 EvaluationWe are evaluating the Lekbot system duringspring and summer 2011, in parallel with con-tinued development, in the spirit of eXtremeProgramming (XP).
Some major themes in XPthat were deemed particularly interesting in thisproject are i) the need to involve the users inthe development process, ii) to work in short it-erations with frequent releases to get a nearlyconstant feedback from users, and iii) to always114prioritise the tasks that provide the greatest ben-efit to users.4.1 UsersA test group was recruited consisting of threetarget children with peers and staff, at threedifferent pre-schools, was recruited.
The targetchildren, two boys and one girl are in the ages 4?6 years, two boys and one girl.
They have cere-bral palsy with complex communication needs.They also have a poor gross motor control, butare able to use their hands for activating a touchscreen on a computer.
They serve as the testgroup and as a basis for the specifications of thefurther development of the system.
During thecourse of development the children in the testgroup use the system to verify that it works asintended and help to identify the most importantqualities to develop.
The project group workswith one month iterations with a new public re-lease every second month.
Therefore, the usershave in the end used about six releases of therobot.Along with the target children, three typicallydeveloped peers, of the same age, or slightlyyounger, were recruited at each pre-school.
Thethree peers were all girls.
Hence, there are threegroups of children playing with the robot.
Atvarious occasions other children in the pre-schoolgroup are involved in the robot play.The children were assessed regarding their re-ceptive language levels by using Test for Re-ception of Grammar (TROG) (Bishop et al,1998).
Their communication levels were es-timated by the project group in cooperationwith the pre-school staff using CommunicationFunction Classification System (CFCS) for In-dividuals with Cerebral Palsy (Hidecker et al,2009).
The pre-school staff also completedSwedish Early Communicative Development In-ventories (SECDI) forms for each child (Eriks-son and Berglund, 1999; Berglund and Eriksson,2000).
A pre-school form (F?rskoleformul?r) wasalso completed (Granlund and Olsson, 1998).
Itconsists of questions concerning the child?s en-gagement in various situations, the pre-schoolteacher?s perception of the interaction betweenher and the child as well as the interaction be-tween the child and other children.With the two youngest target children TROGtesting was not feasible, while the oldest one ap-peared to have some difficulties in understand-ing verbs, prepositions and sentences containingthese components, thus a bit lower than his age.The three peers showed results matching theirage.
From here on the target children will benamed Per, Hans and Greta.The purpose of CFCS is to classify the everyday communication performance of an individ-ual with cerebral palsy.
The levels are rangedbetween 1 and 5, where 1 is the highest and 5the lowest.?
The 6 year old Per shows a level of 3: Ef-fective sender and effective receiver with fa-miliar partners.?
The 5 year old Hans is estimated to level5: Seldom effective sender and effective re-ceiver with familiar partners, and?
The 4 year old Greta is at level 4: Incon-sistent sender and/or receiver with familiarpartners.?
All the peers, of course, reach the level of 1.The CFCS levels will be estimated over againwhen the Lekbot testing is finished.The results of SECDI and the pre-school formwill be presented at a later stage of the Lekbotproject, as they will be redistributed.4.2 Evaluation tools and methodsThe tools used to evaluate the robot play arethree:?
Talking Mats,6 which is an established com-munication tool that uses a mat with at-tached symbols as the basis for communi-cation.
It is designed to help people withcommunicative and cognitive difficulties tothink about issues discussed with them, andprovide them with a way to effectively ex-press their opinions.
Both the target chil-dren and their peers were interviewed aboutthe robot and the interaction, in order to get6http://www.talkingmats.com115feedback for evaluation and for developingthe system.They were asked questions about the be-haviour of the robot and answered byputting symbol cards either at the ?fun?
sideof the mat or at the ?boring/not nice?
side.It is also possible to put symbols between?fun?
and ?boring/not nice?.
The answerswere then checked and evaluated togetherwith the children.
An example is shown inFigure 2.?
Video recordings during the robot play weremade by the project group from Januaryto May 2011, six recordings from each peergroup, in all 18 recordings.
The durationis between 20 and 30 minutes each andshot with one camera by one of the projectmembers.
Short sequences from the videoshave been transcribed and analysed withfocus on cooperation between the childrenand joyfulness.
Transcriptions were madein CLAN7 with detailed descriptions of thenon-verbal actions, signs and gaze.
We gotpermissions to do the recordings from theparents of the children.?
Weekly Activity diaries were kept by thepre-school staff, where they could providetheir reflections about the play sessions.The diaries included headings regardingnumbers of play occasions, duration of theplay, persons participating, what happenedin the play, functionality of the robot, sug-gestions for improvement and the children?ssatisfaction with the play perceived by thestaff.Furthermore, the interaction between the com-munication board and the robot is logged by thesystem, providing valuable information.Beside these evaluation tools there have alsobeen discussions with the designated staff at thecurrent pre-schools.7http://childes.psy.cmu.edu/clan/Figure 2: Talking Mats4.3 Preliminary evaluation results fromthe activity diariesAccording to the activity diaries, Lekbot wasused 56 times during releases 2?5; just below 10times each for the early releases, and 20 timeseach for releases 4 and 5.
There is a great varia-tion in numbers of performed play sessions andin completed activity diaries, mainly due to ill-ness in children or staff, orthopedic surgery inone child and holidays.
In the beginning therewas always the same peer, and only that one,attending the play sessions.
Further on in theproject the staff chose to engage more peersfrom the pre-school.
That means that sometimesthere was a different peer than originally andsometimes there was a group of peers interact-ing in the play.
The support person attendingthe play sessions was always the same.
She alsowas the one completing the activity diaries.4.3.1 Functionality15 comments were given about the systemworking well, where release 5 got the best scores.Problems with the system were reported 16times.
Comments were given about rebootingthe system, loosing the commands, or problemswith activating them.
Dissatisfaction with theactions of the Lekbot was reported 5 times,mainly about the delay between activating acommand and the activation of the robot.
Therewere also reports of improved accessibility of thesystem, by finding a mobile piece of furniture116for the stand and by changing the angle of thedisplay.4.3.2 InteractionThe project group chose not to give strict in-structions on what to do in the play, just to leteveryone use the Lekbot at suitable level.
Thus,there was a variation in complexity of the com-ments, as the headings in the activity diariesgave a structure of open questions.
The col-lected, written comments were categorised in fivegroups; Preparations for the Lekbot play, Ex-plicit support from adult, Target child?s activityand perception of the play, Peer?s activity andperception of the play and Shared activity andperception of the play between target child andpeer(s).
The three latter are reported togetherrelease by release.Preparation for the Lekbot play occurredmainly for Per?s group, where he and his peersbuilt different tracks for the robot to follow.
Ex-plicit support by adult is mentioned only forPer?s group, where the adult chose target pointfor the robot and she used the play for educa-tional matters regarding letter teaching.
Shealso mediated between the children which im-proved their cooperation.
In the final sessionsPer initiated turn taking after being urged bythe adult.4.3.3 Activity and perceptionTarget child?s activity and perception of theplay is mentioned a lot, especially for Per andGreta.
Most frequent among the comments arethose concerning Shared activity and perceptionof the play between target child and peer(s).Release 2: Per initiates turn taking, reactsto the event followed by the activation of thecommand on the display, protests when his peerchoses ?the wrong command?.
Together they re-peatedly perform turn taking and use Per?s dig-ital communication device in the Lekbot activ-ity.
Hans and his peers make a tunnel and thechildren give commands that make the robot gothrough it.
Greta has high expectations on theplay before the session.
Repeatedly she is unwill-ing to stop the play and she gives oral commentsto the activities of the robot.Release 3: Per explores the commands andwhat happens when using them to answer thenewly implemented supplementary questions.Around Hans there is turn taking.
Several chil-dren are playing together and the children mostfrequently choose the dance command.
Gretais excited and unwilling to stop the play.
Sheprotests when the adult makes the choice for therobot.Release 4: Per shows the new commands forhis peer, and the children imitate the robot.Per and his original peer chose one new peereach.
Interaction between the children takesplace through dancing and hand clapping.
Hansplays with the robot together with adults fromoutside the preschool.
Greta likes going back-wards, turning and hitting things with the robot.She starts telling her peer how to act by us-ing the commands on the display and her papercommunication chart.
Her peer enjoys follow-ing Greta?s ?instructions?
and she likes dancing.There are repeated turn taking between themand they enjoy to cooperate getting the robot tomove from one spot to another.Release 5: Per plays with the new commands,by himself.
He finds strategies for the robot infinding food.
When there are more than twochildren in the play, Per chooses to be the onecontrolling the display.
He cooperates more ?waits for his turn and shows better understand-ing for the other?s turn.
All children repeatedlyuse communication charts and Blissymbolics toexpress themselves.
They imitate the robot andthey act instead of it when it is out of order.In Hans?s group there is dancing and lookingfor food play.
Turn taking takes place and allchildren want to participate in the Lekbot play.Greta decides whose turn it is to control therobot.
Her peer likes the play of finding food.4.3.4 SatisfactionStarting in release 3, the level of satisfactionwith the play session was noted in the activitydiary.
The staff was asked to estimate how sat-isfied the target child and the peer were on ascale from 1 to 5, where 1 is the lowest and 5the highest.
This was done every time at some117pre-schools and some times at others.
The ten-dency is that the target children seem to be moresatisfied with the play than their peers from thestart of the play session.
This is most protrud-ing regarding the oldest pair.
At release 4 wherePer and his peer interact as a group for the firsttime, the scores suddenly are reversed so the Peris perceived to 3 on the satisfactory scale and thepeer(s) at 5.
In release 5 the scores get a moreeven variation.4.4 Video recordingsMost of the interviews with Talking Mats werevideo recorded.
The full analysis will be donelater in the project.
The analysis of the videorecordings of the robot interaction is an ongoingwork were three of the project members partic-ipate.
This part of the work is time consumingand only minor sequences are transcribed andanalysed so far.
Through micro analysis the finegrained interactional movements and the coop-eration between the children and the teacher ap-pears, as well as the joy of playing.Figure 3 contains a segment from the tran-scription.
The participants are Per, his peerSelma and his teacher Isa; and the Computerand the Robot.
In the excerpt we can see howPer asks for Selma?s attention and with the helpof Isa and the communication map tells Selmato take her turn, which is to make a new com-mand for the robot to perform.
Finally theyboth dance to the music.4.5 ConclusionAll target children have enjoyed the Lekbot playfrom the beginning.
The more commands andabilities the robot has received the more appre-ciated has the play become also by the peers.Improved play and interaction skills can be ob-served in varying degrees depending on the levelof each child.
The Lekbot has been a nice andfun artefact for the children to gather round andit has given both the target children and theirpeers experiences of playing with each other.From Talking Mats interviews performed withPer and Greta it was revealed that they had noproblems handling the computer display or see-ing and hearing the display and the robot.
Mak-126 %gaze: Per looks at Selma127 %move: Selma is standing on her knees, sits downon her heels, keeps booths hands on her skirt128 %gaze: Selma looks toward the mirror on the wall129 %move: Per touches the left hand of Selma, keepshis arm stretched when Selma moves a bit131 %gaze: Isa looks at Per?s hand132 *Selma: ???????
?133 %comment : Selma is singing while Per stretches to-ward her left hand134 %gesture: Isa draws the pointing map closer135 %gaze: Per looks down at the map136 %gaze: Selma looks down at the map137 *Per : ???????
?138 %move: Selma stands up on her knee, departs on amovement forward139 *Isa: eh::: (0.3) your turn (0.3) Selma?s turn140 %gesture: Isa moves her finger back and forth overthe 6th picture on the map141 %gesture: Isa rests her finger at the picture, thenwithdraws it142 %gesture: Per points at the map143 %move: Selma moves toward the screen144 (2.1)145 %action: Selma makes a fast press at the screen146 %gaze: Per looks at the screen147 *Selma: dance: my king ???????
?148 %move: Selma moves left with arms swinging, bendsforward, landing on hands and knees149 %action: Per looks at Selma, smiles150 *Computer : dance151 *Selma: mi:ine ?
: ?
: ?
(1.8)?152 *Robot : okay I gladly dance153 (1.0)154 *Robot : plays music 11 sec155 %comment : both children are dancing, Selma on herknees and Per sitting downFigure 3: An example transcription segment, trans-lated to Englishing the same interview with Hans was not feasi-ble, though the project group experienced thathe seemed to deal pretty well with the system,although he needed a little more support thanthe two other children, who were able to controlthe toy autonomously.
More results will be pre-sented when the video sequences are analysed,later on in the project.5 AcknowledgementsWe are grateful to 5 anonymous referees fortheir valuable comments.
The Lekbot projectis financed by Vinnova, and Acapela has kindlyprovided us with speech synthesis.118ReferencesK.
Arent and M. Wnuk.
2007.
Remarks on be-haviours programming of the interactive therapeu-tic robot Koala based on fuzzy logic techniques.In First KES International Symposium on Agentand Multi-Agent Systems: Technologies and Ap-plications, Wroclaw, Poland.E.
Berglund and M. Eriksson.
2000.
Communicativedevelopment in Swedish children 16?28 monthsold: The Swedish early communicative develop-ment inventory ?
words and sentences.
Scandina-vian Journal of Psychology, 41(2):133?144.Jonas Beskow, Olov Engwall, Bj?rn Granstr?m, andPreben Wik.
2004.
Design strategies for a virtuallanguage tutor.
In INTERSPEECH 2004.Dorothy Bishop, Eva Holmberg, and Eva Lund?lv.1998.
TROG: Test for Reception of Grammar(Swedish version).
SIH L?romedel.J.
Brodin and P. Lindstrand.
2007.
Perspektiv p?IKT och l?rande f?r barn, ungdomar och vuxnamed funktionshinder.
Studentlitteratur.Stina Ericsson.
2005.
Information Enriched Con-stituents in Dialogue.
Ph.D. thesis, University ofGothenburg, Gothenburg, Sweden.M.
Eriksson and E. Berglund.
1999.
Swedish earlycommunicative development inventory ?
wordsand gestures.
First Language, 19(55):55?90.M.
Granlund and C. Olsson.
1998.
Familjen ochhabiliteringen.
Stiftelsen ALA.M.
J. C. Hidecker, N. Paneth, P. Rosenbaum, R. D.Kent, J. Lillie, and B. Johnson.
2009.
Develop-ment of the Communication Function Classifica-tion System (CFCS) for individuals with cerebralpalsy.
Developmental Medicine and Child Neurol-ogy, 51(Supplement s2):48.B.
Knutsdotter Olofsson.
1992.
I lekens v?rld.Almqvist och Wiksell.H.
Kozima, C. Nakagawa, and Y. Yasuda.
2007.Children-robot interaction: a pilot study in autismtherapy.
Progress in Brain Research, 164:385?400.Staffan Larsson.
2002.
Issue-based Dialogue Man-agement.
Ph.D. thesis, Department of Linguistics,University of Gothenburg, Sweden.C.H.
Lee, K. Kim, C. Breazeal, and R.W.
Picard.2008.
Shybot: Friend-stranger interaction for chil-dren living with autism.
In CHI2008, Florence,Italy.Peter Ljungl?f, Staffan Larsson, Katarina M?hlen-bock, and Gunilla Thunberg.
2009.
TRIK: A talk-ing and drawing robot for children with commu-nication disabilities.
In Nodalida?09: 17th NordicConference of Computational Linguistics.
Shortpaper and demonstration.Seymour Papert.
1993.
Mindstorms: Children,Computers, and Powerful Ideas.
Basic Books.B.
Robins, K. Dautenhahn, R. te Boekhorst, andC.L.
Nehaniv.
2008.
Behaviour delay and ex-pressiveness in child-robot interactions: a userstudy on interaction kinesics.
In HRI?08, 3rdACM/IEEE International Conference on HumanRobot Interaction, Amsterdam, Netherlands.J.
Saldien, K. Goris, B. Verrelst, R. Van Ham, andD.
Lefeber.
2006.
ANTY: The development ofan intelligent huggable robot for hospitalized chil-dren.
In CLAWAR, 9th International Conferenceon Climbing and Walking Robots, Brussels, Bel-gium.Stephanie Seneff, Chao Wang, and Julia Zhang.2004.
Spoken conversational interaction for lan-guage learning.
In InSTIL/ICALL 2004 Sympo-sium on Computer Assisted Learning: NLP andSpeech Technologies in Advanced Language Learn-ing Systems.E.
Vallduv?.
1992.
The Informational Component.Garland.119
