THE L INCOLN CONTINUOUS SPEECH RECOGNIT ION SYSTEM:RECENT DEVELOPMENTS AND RESULTS 1Douglas B. PaulLincoln Laboratory, MITLexington, MA 02173ABSTRACTThe Lincoln stress-resistant HMM CSR has been extended to large vocabulary continuous peech for bothspeaker-dependent (SD) and speaker-independent (SI) tasks.
Performance on the DARPA Resource Manage-ment task (991 word vocabulary, perplexity 60 word-pair grammar) \[1\] is 3.4% word error rate for SD trainingof word-context-dependent triphone models and 12.6% word error rate for SI training of (word-context-free)tied mixture triphone models.INTRODUCTIONOur earlier development efforts \[2,3,4,5,6,7,8,9\] centered on improving the SD speaker-stress robustness forboth IWR and CSR tasks.
Since our IWR database included a normal speech test section, we were able todetermine that our enhancements for robustness also improved performance for normally spoken speech (0errors/1680 test tokens, 105 word vocabulary, multi-style training).
An independent test on the TI-20 worddatabase \[10\] confirmed this normal speech performance with 3 errors out of 5120 test tokens on our firstrun on this database and no errors after a small amount of development \[3\].
Our robust CSR database wasnot useful for determining the large vocabulary normal speech performance.In order to work on a large vocabulary normal speech CSR task, we switched to the DARPA ResourceManagement database \[1\].
The SD portion of this database has 12 speakers with 600 training sentences and100 development test sentences per speaker.
This provided a total of 1,200 test sentences containing 10,242words.
For SI work we used the same development test sentences, but trained on 2,880 sentences from 72speakers from the SI training portion of the database.
(There was an overlap of 8 speakers between the SIand SD training sets making the total of 80 speakers reported in \[1\].)
When additional SI training data wasneeded, we added the designated "SI development test" data, again avoiding test speaker overlaps, to thedesignated SI training data.
This provided a total 3,990 training sentences from 109 speakers.The vocabulary of the Resource Management database is 991 words.
There is also an "official" word-pairrecognition grammar \[11\].
This grammar is just a list of allowable word pairs without probabilities for thepurpose of reducing the recognition perplexity to about 60.
(Including the probabilities slightly more thanhalves the perplexity.
)Working with a single development test set carries a risk of tuning one's system to idiosyncrasies in the testset due to the multiple tests and decisions performed uring algorithm development.
Methodologies whichfocus on correcting the individual test set errors are particularly subject o this problem and become, in effect,corrective training \[12\] on the test set.
In contrast, since different test sets have different inherent difficulties,comparisons of two systems using different est sets have a significantly reduced resolution.
Therefore, theDARPA program has had several "official evaluation tests", the most recent of which was held in June 88.This test used 25 sentences from each of the 12 speakers (2,546 total words), all of which were new data thathad not been used in the development process.
These evaluation tests provide the best comparison betweensystems developed at different sites.
The development test data, while less useful for comparing systemsdeveloped at different sites, is useful for judging progress over time at a single site, subject o the risk that a1 This work was sponsored by the Defense Advanced l:tesearch Projects Agency.
The views expressed are those of the authorand do not reflect the official policy or position of the U.S. Government.160later system may enjoy an advantage over an earlier system due to the training to the test set.
The resultsprovided below will be identified according to which test set was used: June 88 or development test.Error rates for these systems will be quoted as "% word error rate" in the text.
This number is:100 * (substitutions + insertions + deletions)correct number of wordsThe detailed results will be found in Table 1 and Table 2.
The standard eviations are calculated assuminga binomial distribution for the word error rates.Table h The June 88 System June 88 Test Set Results: % Error Rates.Training Substitution Insertion DeletionSD 3.5 .7 1.3SI 8.4 2.2 2.9SI, additional training data 6.2 1.5 2.5Word5.4613.5510.09Std Dev.45.68.60Table 2: Development Test Set Results: % Error Rates.System Substitution Insertion Deletions_~June 88 3.0 .9 1.3Word Context 2.1 .7 .6SAJune 88Word ContextTied Mix 10Tied Mix 20Tied Mix 407.910.212.38.17.86.37.92.72.93.91.92.21.71.8SI, Additional Training DataJune 88Word Context2.72.52.73.22.62.82.2Word5.193.3913.2515.5618.8713.1912.6210.8511.86Std Dev No.
Gaussians.22.18.34.36.39.33.33.31.3229161147129415881THE " JUNE 88" CSR SYSTEMThe "June 88" CSR system (which was used for the June 88 DARPA tests) uses a continuous observationHMM with triphone (left and right context-sensitive phone) models \[13\].
The observation probability densityfunctions are diagonal covariance Gaussians with either a grand (shared) variance or a fixed perceptually-motivated variance.
(Both give similar performance on normal speech; however, the perceptually motivatedvariance appears to be more robust to stress.
The grand variance is used on the systems reported here.
)The observation vector is a centisecond mel-cepstrum augmented with temporal back differences.
The phonemodels have three states with no state skip transitions.
Only one Gaussian per state is used in SD mode.The SI system is identical except hat fourth order Gaussian mixtures are used.The system is trained by an unsupervised bootstrapping procedure.
The training data is not time-marked,only its orthographic transcription and a dictionary is required.
The initial iterations of the Baum-Welch161algorithm are performed using monophone (context-free phone) models from a uniform initial state.
This,in effect, automatically marks the data.
The monophone models are then used to provide initial values forthe (single Gaussian) triphone models and a few more iterations are performed.
If mixtures are to be used,minor random perturbations ofthe single Gaussian mean vectors are used to initialize the Gaussian mixturesand a few final iterations are performed.During recognition, the system extrapolates (guesses based upon a linear combination of the available tri-phones) the triphones which were not observed uring training.
The recognition environment is modeled byadaptive background states.
In order to control the relative number of word insertions and deletions, thelikelihood is multiplied by a penalty for each word.
A Viterbi beam search using a finite state grammar withoptional interword silences produces the recognized output.RESULTS OF THE JUNE 88 TEST SYSTEMThe SD June 88 test system used word-context-free triphones (i.e., the triphone contexts included wordboundaries, but excluded the phone on the other side of the boundary).
Since the pronunciation of functionwords is often idiosyncratic, the triphones for the function words were also word-dependent \[14\].
The resultingsystem has 2,434 triphones, 2,413 of which were observed at least once in training and 21 of which wereextrapolated by the recognizer.
(The same training scripts were used for all 12 SD speakers.)
The SD worderror rates were 5.46% for the June 88 test set and 5.19% for the development test set.The SI dune 88 test system used the same set of triphones as the SD system.
Due to the more variedtraining data, 2,430 triphones were observed, many from only a few speakers.
The word error rate for thissystem is 13.55% for the June 88 test set and 13.25% for the development test set.
The large training set(2,431 observed triphones) produced 10.09% word error rate for the dune 88 test set and 10.85% for thedevelopment test set.WORD BOUNDARY MODELSThe SD system was improved significantly by the addition of word boundary triphone models.
(The word-boundary triphones are distinct from word-internal triphones.)
In this system, the training data is used twiceper Baum-Welch iteration, once to train word-context-free (WCF) models and once to train word-context-dependent models.
The same word-internal triphones are used both times.
This provides the recognizerwith a set of models for the observed word boundaries and a set of WCF models to be used for wordboundaries allowed by the grammar but not observed in the training data.
This reduces the number ofphones extrapolated in the recognizer.The number of triphones is more than doubled by the added word boundary models.
The SD trainer produces5,993 triphones: 2,413 WCF and 3,580 word context riphones.
In addition, the recognizer extrapolates 443more triphones.Inclusion of word contexts ignificantly increases the recognition etwork complexity.
Depending on thenumber of phones in the word, there are three word topologies which must be covered (Figure 1):1.
Three or more phones: each word end has a fan of initial (final) phones.2.
Two phones: each word end has a list of initial and final phones with a crossbar of interconnectionsbetween them.3.
One phone: a crossbar between beginnings and endings with a triphone on each link.Links between two adjacent words are formed according to the following priority list:1.
Both boundary triphones exist: link them.162cx?
?xa  Aabc?ya cy?CASE 1: WORD HAS _> 3 PHONES9xa?ya ~ ~ ~o ?bx' ?xa xax ax?by'?
?ya ~ ay?CASE 2: WORD HAS 2 PHONES CASE 3: WORD HAS 1 PHONEFigure 1: Word-context-dependent word model topologies.2.
Only one of the boundary triphones exist: link to a WCF triphone on the other word.3.
Neither boundary triphone exists: link WCF boundary triphones from both words.Thus, as more word boundaries are observed in the training data, the system gradually builds from theoriginal WCF system toward a system with full word context models.The SD development test results for this system showed a significant improvement over the WCF system:3.39% versus 5.19% word error rate.
An earlier system which extrapolated all missing boundary triphonesrather the defaulting to WCF triphones did not show an improvement.
Thus it is better to use observedWCF triphones rather than extrapolate boundary triphones.
The SI results were worse than the WCFsystem, both with and without the additional training data.
The word-context-dependent system appearsto be too detailed a model for the available SI training data.VARIABLE MIXTURESVariable order mixtures how a small improvement for the SI task.
The number of mixtures for the statesin a triphone was chosen by:163rain(n, sqrt \[(number o$ instances of triphone in data)J )This attempts to match the complexity of the distribution to the amount of available training data.
It hasbeen tested for n = 4 and n = 8 with both the normal and augmented training sets.
The results are inTable 3.
The variable mixtures how an improvement for n = 4 for the standard training and n = 8 for theaugmented training.
These results show that the basic idea improves performance but the function is notoptimum for choosing the mixture order.
If the function were optimum, the best results would he obtainedfor any large n.Table 3: Variable Mixture Order, Development Test Set Results: % Error Rates.System Substitution Insertion DeletionSA,fixed order 2June 88 (fixed order)n=4n=8SI, Additional Training DataJune 88 (fixed order)n=4n=810.07.97.87.96.36.16.02.62.72.53.31.71.52.0Word Std.Dev avg mixture order3.3 15.91 .362.7 13.25 .342.6 12.86 .332.3 13.47 .342.8 10.85 .312.8 10.37 .302.1 10.09 .30243.34.443.54.9T IED MIXTURESA version of tied mixtures \[15,16\] has been tested and shown to provide a small improvement for the SI task.In this system, each monophone group is given a set of Gaussians.
All triphones of each monophone groupuse mixtures chosen from the same set of Gaussians.
The mixture weights for each triphone are independentof all other triphones.
This reduces the total number of Gaussians by a significant factor.Training is again performed using a bootstrapping procedure.
After the monophones are trained, smallrandom perturbations of their mean vectors are used to initialize the mixture Gaussians for the monophonegroup.
The triphone weights, along with the parameters of the Gaussians, are then trained with a numberof iterations of the Baum-Welch algorithm.The recognizer used here is the simpler WCF system.
Three SI systems were tried using 10, 20, and 40Ganssians per monophone group.
Only the 40 system showed an improvement over the original SI system:12.62% versus 13.25% development test word error rate.
This system also reduced the number of Gaussiansby a factor of five.
Tied mixtures have not been tried on the SD task.SPEAKER GROUPINGAnother approach to improving the SI (WCF) performance was tried.
The training speakers were segregatedby sex and two separate sets of models were trained.
The recognizer kept the sets of models separate byusing two separate networks.
Thus, the system co-recognizes both the speech and the sex of the speaker.Systems which lump both sexes together in training do not discriminate against cross-group spectral matchesof individual sounds.
Mixtures were not used to save CPU time.
The results shown in Table 4 show asignificant increase in the error rate.164Table 4: Training Speakers Sex Segregated, Development Test Set Results: % Error Rates.System SubstitutionSI, no mixturesJune 88 14.0Segregated 17.8Insertion Deletion Word Std Dev4.3 I 3.7 i22.02 , .413.0 i 7.2 28.04 .44DISCUSSION AND CONCLUSIONSWord context modeling reduced the word error rate of the SD system by 35%.
This significantly increasedboth the number of triphones and the complexity of the recognizer.
Fully, 39% of the triphones occurredonly once in the training data compared to 19% for the WCF system.
However, since the system is speaker-dependent and (almost) only Gaussian means were being trained, the system was able to improve in spiteof the limited training data.Word-context modeling did not help the SI system, probably due to insufficient raining data.
Thirty-twopercent of the triphones (mostly word boundary), in contrast o 3.7% for the WCF system, occurred onlyone or two times in the training data.
This is not sufficient o train an SI system.
Since many of theword-context-dependent triphones were adapted to only one or two speakers, more damage than good wasdone.
The larger SI training data set reduced the number of single and double occurrence triphones to 22%,which helped, but was not enough to overcome the problem.Variable order mixtures (WCF) improved the SI results by matching the complexity of the distributions tothe amount of training data.
This approach required essentially no increase in the complexity of the trainer.The (WCF) tied mixture system achieved a small improvement over the June 88 SI system.
This wasprobably due to the high-order mixtures of the shared Gaussians.
This allowed more detailed modelingwhere there was sufficient raining data while allowing the system to automatically reduce its degrees offreedom where there was insufficient training data by placing very low or zero weights on unneeded mixturecomponents.
Training, however, requires o much computation that it will hamper exploration of this classof system.Grouping the speakers (WCF) yielded sufficiently poor results that mixtures were not tested.
The recognizerdid appear to correctly identify the sex of the speaker.
The reduction in performance may be due to aneffect similar to multi-style training \[5\] which may be enhanced by mixing the sexes during training.Re ferences\[1\] P. Price, W. M. Fisher, J. Bernstein, and D. S. Pallett, "The DARPA 100~Word Resource ManagementDatabase for Continuous Speech Recognition," ICASSP 88, New York, April 6-9, 1988.\[2\] D. B. Paul, R. P. Lippmann, Y. Chen, and C. J. Weinstein, "Robust HMM-Based Techniques forRecognition of Speech Produced Under Stress and in Noise," Speech Tech 86, New York, April 28-30,1986.\[3\] D. B. Paul, "A Speaker-Stress Resistant Isolated Word Recognizer", ICASSP 87, Dallas, April 6-9,1987.\[4\] E. A. Martin, R. P. Lippmann, and D. B. Paul, "Two-Stage Discriminant Analysis for Improved Isolated-Word Recognition," ICASSP 87, Dallas, April 6-9, 1987.165\[511 R. P. Lippmann, E. A. Martin, and D. B. Paul, "Multi-Style Training for Robust Isolated-Word SpeechRecognition," ICASSP 87, Dallas, April 6-9, 1987.\[611 Y. Chen, "Cepstral Domain Stress Compensation for Robust Speech Recognition," ICASSP 87, Dallas,April 6--9, 1987.\[7\] D. B. Paul, "Robust Speech Recognition for Stressful Airborne Environments," Military Speech Tech87, Washington D. C., November 1987.\[8\] D. B. Paul and E. A. Martin, "Speaker Stress-Resistant Continuous Speech Recognition," ICASSP 88,New York, April 11-14, 1988.\[9\] E. A. Martin, R. P. Lippmann, and D. B. Paul, "Dynamic Adaptation of Hidden Markov Models forRobust Isolated-Word Speech Recognition," ICASSP 88, New York, April 11-14, 1988.\[10\] G. R. Doddington and T. B. Schalk, "Speech Recognition: Turning Theory into Practice," IEEE Spec-trum, September 1981.\[11\] F. Kubala, Y. Chow, A. Derr, M. Feng, O. Kimball, J. Makhoul, P. Price, J. Rohlicek, S. Roucos, R.Schwartz, and J. Vandergrift, "Continuous Speech Recognition Results of the BYBLOS System on theDARPA 100~Word Resource Management Database," ICASSP 88, New York, April 11-14, 1988.\[12\] L. R. Bahl, P. F. Brown, P. B. de Souza, and R. L. Mercer, "A New Algorithm for the Estimation ofHidden Markov Model Parameters," ICASSP 88, New York, April 11-14, 1988.\[13\] R. M. Schwartz, Y. L. Chow, O.
A. Kimball, S. Roucos, M. Krasner, and J. Makhoul, "Context-Dependent Modeling for Acoustic-Phonetic Recognition of Continuous Speech," ICASSP 85, Tampa,April 1985.\[14\] K. F. Lee and H. W. Hon, "Large-Vocabulary Speaker-Independent Continuous Speech RecognitionUsing HMM," ICASSP 88, New York, April 11-14, 1988.\[15\] X. D. Huang and M. A. Jack, "Semi-Continuous Hidden Markov Models with Maximum LikelihoodVector Quantization," 1988 IEEE Workshop on Speech Recognition, Arden House, Harriman, NY, May31-June 3, 1988.\[16\] D. Nahamoo, personal communication, June 1988.166
