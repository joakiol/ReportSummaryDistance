c?
2003 Association for Computational LinguisticswEBMT: Developing and Validating anExample-Based Machine TranslationSystem Using the World Wide WebAndy Way?
Nano Gough?Dublin City University Dublin City UniversityWe have developed an example-based machine translation (EBMT) system that uses the WorldWide Web for two different purposes: First, we populate the system?s memory with translationsgathered from rule-based MT systems located on the Web.
The source strings input to thesesystems were extracted automatically from an extremely small subset of the rule types in the Penn-II Treebank.
In subsequent stages, the ?source, target?
translation pairs obtained are automaticallytransformed into a series of resources that render the translation process more successful.
Despitethe fact that the output from on-line MT systems is often faulty, we demonstrate in a numberof experiments that when used to seed the memories of an EBMT system, they can in fact proveuseful in generating translations of high quality in a robust fashion.
In addition, we demonstratethe relative gain of EBMT in comparison to on-line systems.
Second, despite the perception thatthe documents available on the Web are of questionable quality, we demonstrate in contrast thatsuch resources are extremely useful in automatically postediting translation candidates proposedby our system.1.
IntroductionIn quite a short space of time, translation memory (TM) systems have become a veryuseful tool in the translator?s armory.
TM systems store a set of ?source, target?
trans-lation pairs in their databases.
If a new input string cannot be found exactly in thetranslation database, a search is conducted for close (or ?fuzzy?)
matches of the inputstring, and these are retrieved together with their translations for the translator tomanipulate into the final, output translation.
From this description, it should be clearthat TM systems do not translate: Indeed, some researchers consider them to be littlemore than a search-and-replace engine, albeit a rather sophisticated one (Macklovitchand Russell 2000).We can illustrate this with respect to the TM entries in (1), taken from the CanadianHansards:(1) a.
While most were critical, some contributions were thoughtful andconstructive =?
La plupart ont formule?
des critiques, mais certains ontfait des observations re?fle?chies et constructives.b.
Others were plain meanspirited and some contained errors of fact =?D?autres discours comportaient des propos mesquins et me?me deserreurs de fait.?
School of Computing, Dublin 9, Ireland.
E-mail: away@computing.dcu.ie?
School of Computing, Dublin 9, Ireland.
E-mail: ngough@computing.dcu.ie422Computational Linguistics Volume 29, Number 3Consider the new source string in (2):(2) While most were critical, some contributions were plain meanspirited.Despite the fact that this new input in (2) is extremely close to the source stringsin the TM entries in (1), no TM system containing just these translation pairs in itsdatabase would be able to translate (2); the best they could do would be to identifyone or both of the two source sentences in the TM in (1) as fuzzy matches and displaythese, together with their French translations.
The translator would then manipulatethe target strings in the TM into the final translation (3):(3) La plupart ont formule?
des critiques, mais certains ont fait desobservations mesquines.An alternative translation that might be derived from the TM entries in (1) is that in(4):(4) La plupart ont formule?
des critiques, mais certains comportaient desobservations mesquines.At all stages in the translation process, therefore, the translators themselves are theintegral figures: They are free to accept or reject any suggested matches, they constructthe translations, and they may or may not use any translations proposed by the TMsystem to formulate the translations in the target document.
Finally, they are free toinsert the translations produced into the TM itself as they see fit: that is, either (3) or(4) could be inserted into the TM with the source string (2), or some other translation,if that were preferred.A prerequisite for TM (and example-based machine translation [EBMT]) applica-tions is a parallel corpus aligned at sentential level.
Such a corpus may be presentedto translators en bloc, or translators may help construct it themselves.
Here too thetranslator maintains a large degree of autonomy: Using a tool such as Trados WinAlign,for example, he or she may manually overwrite some of the aligner?s decisions bylinking ?source, target?
sentence pairs using the graphical interface provided.Nevertheless, TM systems are currently falling far short of their potential, giventhe limitation that the smallest accessible translation units are ?source, target?
stringsaligned only at sentential level.
Consider the fuzzy matching operation, for instance:Translators are able to set a fuzzy match threshold below which no translation pairsare proposed by the TM system.
If this threshold is set too low, then potentially usefultranslation pairs will be presented along with a lot of noise, thereby risking that thisuseful translation information will be obscured (high recall, low precision); if it is settoo low, then good matches will be presented, but potentially useful matches willnot be (low recall, high precision).
We noted above that faced with the new input in(2), a TM system might be able to present the translator with the fuzzy matches in(1).
However, if a translator were to set the level of fuzzy matching at 80% (a notunreasonable level), then neither of the translation pairs in (1) would be deemed tobe a suitably good fuzzy match, as only 7/9 (77%) of the words in (1a) match thosein (2) exactly, and only 3/9 (33%) of the words in (1b) match those in (2) exactly.Indeed, setting an appropriate fuzzy match level is such a difficult problem that sometranslators switch off this option and use the TM only to find exact matches.If subsentential alignment could be integrated into the TM databases, more usefulfragments could be put at the disposal of the translator.
If we could fragment the423Way and Gough wEBMTsententially aligned TM examples in (1) so that subsentential chunks were displayedto the user, then the chance of finding exact matches or good fuzzy matches wouldincrease considerably.
This is currently beyond the scope of TM systems.In contrast, EBMT systems have overcome this constraint by storing subsententialtranslational correspondences in addition to the sententially aligned pairs from whichthey are derived.
As a consequence, where a TM system can only propose a numberof close-scoring matches in its database for the translator to adapt into the final trans-lation, an EBMT system can produce translations itself by automatically combiningchunks from different translation examples stored in its memories.In Section 2, we describe how we automatically obtain a hierarchy of lexical re-sources that are used sequentially by our EBMT system, wEBMT, to translate newinput.
The primary resource gathered is a ?phrasal lexicon,?
constructed by extractingover 200,000 phrases from the Penn Treebank and having them translated into Frenchby three Web-based machine translation (MT) systems.Each set of translations is stored separately, and for each set the ?marker hypoth-esis?
(Green 1979) is used to segment the phrasal lexicon into a ?marker lexicon.?
Themarker hypothesis is a universal psycholinguistic constraint which states that naturallanguages are ?marked?
for complex syntactic structure at surface form by a closedset of specific lexemes and morphemes.
That is, a basic phrase-level segmentation ofan input sentence can be achieved by exploiting a closed list of known marker wordsto signal the start and end of each segment.Consider the following example, selected at random from the Wall Street Journalsection of the Penn-II Treebank:(5) The Dearborn, Mich., energy company stopped paying a dividend in thethird quarter of 1984 because of troubles at its Midland nuclear plant.Here we see that three noun phrases start with determiners and one with a possessivepronoun.
The sets of determiners and possessive pronouns are both very small.
Fur-thermore, there are four prepositional phrases, and the set of prepositions is similarlysmall.
A further assumption that could be made is that all words that end with -ed areverbs, such as stopped in (5).
The marker hypothesis is arguably universal in presum-ing that concepts and structures like these have similar morphological or structuralmarking in all languages.The marker hypothesis has been used for a number of different language-relatedtasks, including?
language learning (Green 1979; Mori and Moeser 1983; Morgan, Meier,and Newport 1989)?
monolingual grammar induction (Juola 1998)?
grammar optimization (Juola 1994)?
insights into universal grammar (Juola 1998)?
machine translation (Juola 1994, 1997; Veale and Way 1997; Gough, Way,and Hearne 2002)With respect to translation, a potential problem in using the marker hypothesis is thatsome languages do not have marker words such as articles, for instance.
Green?s (1979)work showed that artificial languages, both with and without specific marker words,may be learned more accurately and quickly if such psycholinguistic cues exist.
The424Computational Linguistics Volume 29, Number 3research of Mori and Moeser (1983) showed a similar effect due to case marking onpseudowords in such artificial languages, and Morgan, Meier, and Newport (1989)demonstrated that languages that do not permit pronouns as substitutes for phrasesalso provide evidence in favor of the marker hypothesis.
Juola?s (1994, 1998) workon grammar optimization and induction shows that context-free grammars can beconverted to ?marker-normal form.?
However, marker-normal form grammars cannotcapture the sorts of regularities demonstrated for languages that do not have a one-to-one mapping between a terminal symbol and a word.
Nevertheless, Juola (1998,page 23) observes that ?a slightly more general mapping, where two adjacent termi-nal symbols can be merged into a single lexical item (for example, a word and itscase-marking), can capture this sort of result quite handily.?
Work using the markerhypothesis for MT adapts this monolingual mapping for pairs of languages: It is rea-sonably straightforward to map an English determiner-noun sequence onto a Japanesenoun?case marker segment, once one has identified the sets of marker tags in the lan-guages to be translated.Following construction of the marker lexicon, the ?source, target?
chunks are gen-eralized further using a methodology based on Block (2000) to permit a limited formof insertion in the translation process.
As a byproduct of the chosen methodology,we also derive a standard ?word-level?
translation lexicon.
These various resourcesrender the set of original translation pairs far more useful in deriving translations ofpreviously unseen input.In Section 3, we describe in detail the segmentation process, together with theprocedure whereby target chunks are combined to produce candidate translations.
InSection 4, we report initially on two experiments in which we test different versionsof our EBMT system against test sets of NPs and sentences.
We then conduct a set offurther experiments which show that using the resources developed from more thanone on-line MT system may improve both translation coverage and quality.
Further-more, seeding the system databases with more fragments improves translation quality.In addition, we calculate the net gain of our EBMT system by comparing translationquality against that of the three on-line MT systems.
Finally, we comment on therelative strengths and weaknesses of the three on-line MT systems used.Like most EBMT systems, our approach suffers from the problem of ?boundaryfriction?
: where chunks from different translation examples are recombined, the qualityof the resulting translations may be compromised.
Assume that the aligned examplesin (6) are located in the system database:(6) a.
You can attach a phone to the connector =?
Vous pouvez re?lier unte?le?phone au connecteur.b.
Connect only the keyboard and a mouse =?
Connectez uniquementle clavier et une souris.Let us now confront the EBMT system with the new input string in (7):(7) You can attach a mouse to the connector.This could be correctly translated by the EBMT system by isolating the useful trans-lation fragments in (8):(8) a.
You can attach =?
Vous pouvez re?lier (from (6a))b. a mouse =?
une souris (from (6b))c. to the connector =?
au connecteur (from (6a))425Way and Gough wEBMTRecombining the French chunks gives us the correct translation in (9):(9) Vous pouvez re?lier une souris au connecteur.However, a number of mistranslations could also ensue, including those in (10):(10) a.
*Vous pouvez re?lier un souris au connecteur.b.
*Vous pouvez re?lier un souris au le connecteur.The mistranslation (10a) could be formed via the set of inferences in (11):(11) You can attach a =?
Vous pouvez re?lier un (from (6a))mouse =?
souris (from (6b))to the connector =?
au connecteur (from (6a))The mistranslation (10b) could be formed via the set of inferences in (12):(12) You can attach a =?
Vous pouvez re?lier un (from (6a))mouse =?
souris (from (6b))to =?
au (from (6a))the =?
le (from (6b))connector =?
connecteur (from (6a))It is clear, therefore, that unless the process by which the original ?source, target?sentence pairs are fragmented is well defined and strictly controlled, chunks maybe combined from different contexts that result in agreement errors such as those in(10).1 Depending on the input string, our wEBMT system may generate thousandsof candidate translations, including many mistranslations like those in (10).
A majoradvantage of MT systems based on probabilities is that output translations can beranked (and pruned, if required): One would hope that such systems would rankgood translations such as that in (9) more highly than poor ones such as those in (10).We demonstrate that in almost all experiments, our EBMT system consistently ranksthe ?best?
translation in the top 10 output translations, and always in the top 1% ofthe translations generated.In order to minimize errors of boundary friction, in Section 5 we develop a novel,post hoc procedure via the World Wide Web to validate and, if necessary, correcttranslations prior to their being output to the user.2 Finally we conclude and point toareas of future research.1 Note also that with respect to the translations given in (3) and (4), the translator interacting with theTM has used his or her translation knowledge to avoid a problem of boundary friction: Given the TMentries in (1), the translation of plain meanspirited would appear to be mesquins.
This is correct in thiscontext, as it co-occurs with a masculine plural noun propos.
In translating (2), however, observations is afeminine plural noun, so the adjective mesquines is inserted to maintain agreement throughout the NP.If the translation pair ?plain meanspirited, mesquines?
were not found in the system?s memories, thenonly the mistranslation observations mesquins could be produced by an EBMT system.2 One of the areas of boundary friction that we use our post hoc validation procedure to correct is that ofsubject-verb agreement.
Note that with examples such as (18), this is not usually (such) a problem formarker-based approaches to MT as we face here, as verbs are contained within (part of) the samechunk as their subject NPs.
However, given that we translate phrases rather than sentences, it is aconsiderable problem for our approach, yet one that we overcome satisfactorily.
In further work, if wewere to store the translations of the VPs with their dummy subject NPs in a sentential lexicon andderive all marker lexicons from this database, the problem of subject-verb agreement would be largelyovercome.426Computational Linguistics Volume 29, Number 32.
Deriving Translation Resources from Web-Based MT SystemsAll EBMT systems, from the initial proposal by Nagao (1984) to the recent collectionof Carl and Way (2003), are premised on the availability of subsentential alignmentsderived from the input bitext.
There is a wealth of literature on trying to establish sub-sentential translations from a bilingual corpus.3 Kay and Ro?scheisen (1993) attempt toextract a bilingual dictionary using a hybrid method of sentence and word alignmenton the assumption that the ?source, target?
words have a similar distribution.
Fungand McKeown (1997) attempt to translate technical terms using word relation matrices,although the resource from which such relations are derived is a pair of nonparallelcorpora.
Somers (1998) replicates the work of Fung and McKeown with different lan-guage pairs using the simpler metric of Levenshtein distance.
Boutsis and Piperidis(1998) use a tagged parallel corpus to extract translationally equivalent English-Greekclauses on the basis of word occurrence and co-occurrence probabilities.
The respec-tive lengths of the putative alignments in terms of characters is also an importantfactor.
Ahrenberg, Andersson, and Merkel (2002) observe that for less widely spokenlanguages, the relative lack of linguistic tools and resources has forced developers ofword alignment tools for such languages to use shallow processing and basic statis-tical approaches to word linking.
Accordingly, they generate lexical correspondencesby means of co-occurrence measures and string similarity metrics.More specifically, the notion of the phrasal lexicon (used first by Becker 1975) hasbeen used successfully in a number of areas:?
Learnability (Zernik and Dyer 1987)?
Text generation (Hovy 1988; Milosavljevic, Tulloch, and Dale 1996)?
Speech generation (Rayner and Carter 1997)?
Localization (Scha?ler 1996)More recently, Simard and Langlais (2001) have proposed the exploitation of TMs ata subsentential level, while Carl, Way, and Scha?ler (2002) and Scha?ler, Way, and Carl(2003, pages 108?109) describe how phrasal lexicons might come to occupy a centralplace in a future hybrid integrated translation environment.
This, they suggest, mayresult in a paradigm shift from TM to EBMT via the phrasal lexicon: Translators areon the whole wary of MT technology, but once subsentential alignment is enabled,translators will become aware of the benefits to be gained from ?source, target?
phrasalsegments, and from there they suggest that ?it is a reasonably short step to enablingan automated solution via the recombination element of EBMT systems such as thosedescribed in [Carl and Way 2003].
?In this section, we describe how the memory of our EBMT system is seeded witha set of translations obtained from Web-based MT systems.
From this initial resource,we subsequently derive a number of different databases that together allow manynew input sentences to be translated that it would not be possible to translate inother systems.
First, the phrasal lexicon is segmented using the marker hypothesis toproduce a marker lexicon.
This is then generalized, following a methodology based onBlock (2000), to generate the ?generalized marker lexicon.?
Finally, as a result of the3 We refer the interested reader to the excellent and comprehensive bibliography on parallel textprocessing available at http://www.up.univ-mrs.fr/?veronis/biblios/ptp.htm.427Way and Gough wEBMTmethodology chosen, we automatically derive a fourth resource, namely, a ?word-levellexicon.
?2.1 The Phrasal LexiconOur phrasal lexicon was built by selecting a set of 218,697 English noun phrases andverb phrases from the Penn Treebank.
We identified all rule types occurring 1,000or more times and eliminated those that were not relevant (e.g., rules dealing onlywith numbers).
Where rules contained just a single nonterminal on their right-handside, only those rules whose left-hand side was VP were retained in order to ensurethat we could handle intransitive verbs.
In total, 59 rule types out of a total of over29,000 (i.e., just 0.002% of the rules in Penn-II) were used in creating the various lexicalresources.
For each of these 59 rule types, the tokens corresponding to the rule right-hand sides were extracted.
These extracted English phrases were then translated usingthree on-line MT systems:?
SDL International?s Enterprise Translation Server4 (system A)?
Reverso by Softissimo5 (system B)?
Logomedia6 (system C)Translating the NPs via these MT systems was reasonably straightforward.
Wereport in Section 4 on the quality of the French NPs produced, and in Section 5 wediscuss experiments designed to discover whether our EBMT system could improveon any mistranslations obtained.
Translating the VPs involved a little more thought:In the main, on-line MT systems such as these work far better when they translatesentences.
In order to obtain finite verb forms rather than the default infinitival forms,we provided dummy subjects.
Initially these were third-person plural pronouns, whichcaused similar verb forms to be created.
This obviously biases the EBMT system morein favor of third-person plural sentences.
Nevertheless, using the WWW-based post hocevaluation methodology proposed in Section 5, we were still able to obtain reasonabletranslations for non-third-person-plural sentences too.
In a subsequent experiment,we seed the databases of wEBMT with third-person singular verb forms by providingthird-person singular pronouns as the dummy subjects, and in a final experimentwe combine all third-person fragments (both singular and plural) into the system?smemories and compare results on the same test set.The on-line MT systems were selected purely because they enable batch translationof large quantities of text.
In our experience, the most efficient way to translate largeamounts of data via on-line MT systems is to send each document as an HTML pagewith the phrases to be translated encoded as an ordered list.
We automatically taggedthe English phrases with HTML codes and input them into each translation systemusing the Unix wget function, which takes a URL as input and writes the correspondingHTML document to a file.
If the URL takes the form of a query, then the documentretrieved is the result of the query, namely, the translated Web page.
Once this isobtained, it is a simple process to retrieve the French translations and associate themwith their English source equivalents.4 http://www.freetranslation.com5 http://trans.voila.fr6 http://www.logomedia.net428Computational Linguistics Volume 29, Number 32.2 The Marker LexiconsGiven that the marker hypothesis is arguably universal, it is clear that benefits mayaccrue by using it to facilitate subsentential alignment of ?source, target?
chunks.
Juola(1994, 1997) conducts some small experiments using his METLA system to show theviability of this approach for English ??
French and English ??
Urdu.
For the English??
French language pair, Juola gives results of 61% correct translation when thesystem is tested on the training corpus, and 36% accuracy when it is evaluated withtest data.
For English ??
Urdu, Juola (1997, page 213) notes that ?the system learnedthe original training corpus .
.
.
perfectly and could reproduce it without errors?
; thatis, it scored 100% accuracy when tested against the training corpus.
On novel testsentences, he gives results of 72% correct translation.
In their Gaijin system, Veale andWay (1997) give a result of 63% accurate translations obtained for English ??
Germanon a test set of 791 sentences from CorelDRAW manuals.As in METLA and Gaijin, we exploit lists of known marker words for each languageto indicate the start and end of segments.
For English, our source language, we usethe sets of marker words in (13):(13)<DET> {the, a, an, those, these, .
.
.
}<PREP> {in, on, out, with, from, to, under, .
.
.
}<QUANT> {all, some, few, many, .
.
.
}<CONJ> {and, or, .
.
.
}<POSS> {my, your, our,.
.
.
}<PRON> {I, you, he, she, it,.
.
.
}A similar set (14) was produced for French, the target language in our wEBMT system:(14)<DET> {le, la, l?, les, ce, ces, ceux, cet, .
.
.
}<PREP> {dans, sur, avec, de, a`, sous, .
.
.
}<QUANT> {tous, tout, toutes, certain, quelques, beaucoup, .
.
.
}<CONJ> {et, ou, .
.
.
}<POSS> {mon, ma, mes, ton, ta, tes, notre, nos, .
.
.
}<PRON> {je, j?, tu, il, elle, .
.
.
}In a preprocessing stage, the aligned ?source, target?
pairs in the phrasal lexicon aretraversed word by word, and whenever any such marker word is encountered, a newchunk is begun, with the first word labeled with its marker category (<DET>, <PREP>,etc.).
The example in (15) illustrates the results of running the marker hypothesis overthe source phrase all uses of asbestos:(15)<QUANT> all uses<PREP> of asbestosIn addition, we impose a further constraint that each chunk must also contain at leastone non?marker word, so that the phrase out in the cold will be viewed as one segment(labeled with <PREP>), rather than split into still smaller chunks.For each ?English, FrenchX?
pair, where X is one of the sets of translations derivedfrom the three separate MT on-line systems (see above), we derive separate markerlexicons for each of the 218,697 source phrases and target translations.
This gives429Way and Gough wEBMTus a total of 656,091 ?source, target?
translation pairs (including many repetitions, ofcourse).
Given that English and French have essentially the same word order, thesemarker lexicons are predicated on the na?
?ve yet effective assumption that marker-headed chunks in the source S map sequentially to their target equivalents T; that is,chunkS1 ??
chunkT1, chunkS2 ??
chunkT2, .
.
.chunkSn ??
chunkTn, subject to theirmarker categories matching, where possible.
Using the previous example of all uses ofasbestos, this gives us the marker chunks in (16):(16)<QUANT> all uses : tous usages<PREP> of asbestos : d?
asbesteSometimes the number of marker chunks in the two languages differs, with respect toboth the marker categories and the number of chunks obtained.
Consider the examplein (17):(17) The man looks at the woman =?
L?homme regarde la femme.Once the marker hypothesis is applied to (17), it would be marked up as in (18):(18) <DET> The man looks <PREP> at <DET> the woman =?<DET> L?
homme regarde <DET> la femme.That is, the English verb subcategorizes for a PP complement which in this case con-tains two marker words, whereas the French verb regarder is a straightforward tran-sitive verb.
It may appear, therefore, that there are three chunks in the English stringand only two on the French side, but this is not the case: The restriction that eachsegment must contain at least one non?marker word ensures that we have just twomarker chunks for the English string in (18).
However, it remains the case that thechunks are tagged differently; we obtain the marker chunks in (19):(19) English:<DET> The man looks<PREP> at <DET> the womanFrench:<DET> L?
homme regarde<DET> la femmeOur alignment method would therefore align the first English chunk with the firstFrench chunk, as their marker categories match.
Note, of course, that this contains atranslation error: regarde translates not as looks but rather as looks at.
Errors such as thiswill adversely affect translation quality, but as we report in Section 4, good-qualitytranslations are obtainable on the whole.
The second pair in (19), however, cannotbe mapped straightforwardly onto one another, as the marker categories differ.
Nev-ertheless, our algorithm would align ?<DET> the woman?
with ?<DET> la femme,?
astheir marker categories match.
This ensures that as many potentially useful translationfragments are generated as possible.This na?
?ve alignment procedure works well between (broadly) similar languagessuch as English and French, but there are cases even between quite closely relatedlanguages in which the procedure breaks down.
In order to increase translation quality430Computational Linguistics Volume 29, Number 3still further, the mapping function needs to be improved to account for examples suchas (20):(20) The man likes the woman =?
La femme pla?
?t a` l?homme.The like =?
plaire case is an argument-switching (or relation-changing) example, inthat the subject in English becomes the indirect object in French, and the English objecttranslates as the French subject.
If we were to apply the marker hypothesis to (20), wewould derive (21):(21) <DET> The man likes <DET> the woman =?<DET> La femme pla?
?t <PREP> a` <DET> l?
homme.That is, without recourse to a lexicon or information about the relative distribution ofwords and their translations, we would derive the marker chunks in (22):(22) a.
<DET> The man likes =?
<DET> La femme pla??tb.
<DET> the woman =?
<DET> l?
hommeOf course, both alignments are wrong.
However, our alignment method correctly aligns?source, target?
segments in approximately 80% of cases.
We calculate this as an ap-proximation by testing all translations of marker chunks to see whether these Frenchchunks appear anywhere on the Web: If so, we assume that the translations obtainedby the online MT systems are correct.
For 39,895 such translations, 75.2% of thoseproduced by system A appear on the Web, with 81.7% of those generated by systemB and 81.5% of those produced by system C also appearing on the Web.
Note thatthis gives us only an approximation of the correctness of our alignments, as we aretesting whether the French translations are ?good French?
rather than whether thealignments in which they appear are actually correct.Correcting misalignments such as those in (22) is a topic for further research.Adding a bilingual lexicon (our word-level lexicon, for example) and incorporating theconstraints contained therein into the marker-based alignment process would preventchunks such as those in (22) from being generated, and we conjecture that translationquality would improve accordingly.Given marker chunks such as those in (16), we are able to extract automatically afurther bilingual dictionary, the word-level lexicon.
We take advantage of the assump-tion that where a chunk contains just one non?marker word in both source and target,these words are translations of each other.
Where a marker-headed pair contains justtwo words, as in (16), for instance, we can extract the word-level translations in (23):(23)<QUANT> all : tous<PREP> of : d?<LEX> uses : usages<LEX> asbestos : asbesteThat is, using the marker hypothesis method of segmentation, smaller aligned seg-ments can be extracted from the phrasal lexicon without recourse to any detailedparsing techniques or complex co-ocurrence measures.431Way and Gough wEBMTJuola (1994, 1997) assumes that words ending in -ed are verbs.
However, giventhat verbs are not a closed class, in our approach we do not mark chunks beginningwith a verb with any marker category.
Instead, we take advantage of the fact that theinitial phrasal chunks correspond to rule right-hand sides.
That is, for a rule in thePenn Treebank VP ??
VBG, NP, PP, we are certain (if the annotators have done theirjob correctly) that the first word in each of the strings corresponding to this right-handside is a VBG, that is, a present participle.
Given this information, in such cases we tagsuch words with the <LEX> tag.
Taking expanding the board to 14 members ??
augmentele conseil a` 14 membres as an example, we extract the chunks in (24):(24)<DET> the board : le conseil<DET> the : le<PREP> to <QUANT> 14 members : a` 14 membres<QUANT> 14 members : 14 membres<LEX> expanding : augmente<LEX> board : conseil<PREP> to : a`<LEX> members : membresWe ignore here the trivially true lexical chunk ?<QUANT> 14 : 14.?In a final processing stage, we generalize over the marker lexicon following aprocess found in Block (2000).
In Block?s approach, word alignments are assignedprobabilities by means of a statistical word alignment tool.
In a subsequent stage,chunk pairs are extracted, which are then generalized to produce a set of translationtemplates for each ?source, target?
segment.Block distinguishes chunks from ?patterns,?
as we do: His chunks are similar toour marker chunks, and his patterns are similar to our generalized marker chunks.Once chunks are derived from ?source, target?
alignments, patterns are computed fromthe derived chunks by means of the following algorithm: ?for each pair of chunk pairs?
?CS1, CT1?, ?CS2, CT2?
?, if CS1 is a substring in CS2 and CT1 is a substring in CT2, then?PS, PT?
is a pattern pair where PS equals CS2 with CS1 replaced by a variable V andPT equals CT2 with CT1 replaced by V?
(Block 2000, pages 414?415).
Block then givesan example that shows how patterns are derived.
Assume the chunk pairs in (25):(25) ?
[das], [which] ??
[ist], [is] ??
[was], [what] ??
[Sie], [you] ??
[wollten], [wanted] ??
[das ist], [which is] ??
[das ist was], [which is what] ??
[das ist was Sie], [which is what you] ??
[das ist was Sie wollten], [which is what you wanted] ?432Computational Linguistics Volume 29, Number 3Using the algorithm described above, the patterns in (26) are derived from the chunksin (25):(26) ?
[V ist], [V is] ??
[das V], [which V] ??
[das V was], [which V what] ?...?
[V ist was Sie], [V is what you] ?...?
[das ist was V wollten], [which is what V wanted] ?...Of course, many other researchers also try to extract generalized templates.
Kaji,Kida, and Morimoto (1992) identify translationally equivalent phrasal segments andreplace such equivalents with variables to generate a set of translation patterns.
Watan-abe (1993) combines lexical and dependency mappings to form his generalizations.Other similar approaches include those of Cicekli and Gu?venir (1996), McTait andTrujillo (1999), Carl (1999), and Brown (2000), inter alia.In our system, in some cases the smallest chunk obtainable via the marker-basedsegmentation process may be something like (27):(27) <DET> the good man : le bon hommeIn such cases, if our system were confronted with a good man, it would not be ableto translate such a phrase, assuming this to be missing from the marker lexicon.
Ac-cordingly, we convert examples such as (27) into their generalized equivalents, as in(28):(28) <DET> good man : bon hommeThat is, where Block (2000) substitutes variables for various words in his templates,we replace certain lexical items with their marker tag.
Given that examples such as?
?<DET> a : un?
are likely to exist in the word-level lexicon, they may be inserted atthe point indicated by the marker tag to form the correct translation un bon homme.
Wethus cluster on marker words to improve the coverage of our system (see Section 5for results that show exactly how clustering on marker words helps); others (notablyBrown [2000, 2003]) use clustering techniques to determine equivalence classes ofindividual words that can occur in the same context, and in so doing derive translationtemplates from individual translation examples.2.3 SummaryIn sum, we automatically create four knowledge sources:?
the original ?source,target?
phrasal translation pairs?
the marker lexicon (cf.
(16))?
the generalized marker lexicon (cf.
(28))?
the word-level lexicon (cf.
(24))433Way and Gough wEBMTWhen matching the input to the corpus, we search for chunks in the order givenhere, that is, from specific examples (those containing more context) to generic (thosecontaining less context).
We give in (29) an example of how a particular sentence fromour test set is translated via these different knowledge sources:(29) Input:A major concern for the parent company is what advertisers are payingper page.Chunks found in marker lexicon:for the parent company : pour la socie?te?
me`rewhat advertisers are paying per page : quels annonceurs paient per pageChunk found in generalized marker lexicon:<DET> major concern : inquie?tude majeureWords found in word-level lexicon:<DET> a : une<LEX> is : estGiven the fragments shown in (29), a translation can now be derived.
First, theword pair ?<DET> a : une?
is inserted into the generalized template ?<DET> majorconcern: inquie?tude majeure?
to begin the translation process; the next chunk, ?forthe parent company : pour la socie?te?
me`re,?
is retrieved from the marker lexicon; themissing word pair ?<LEX> is : est?
is retrieved from the word-level lexicon; and finally,the marker chunk ?what advertisers are paying per page : quels annonceurs paientper page?
is appended to produce the translation in (30):(30) Une inquie?tude majeure pour la socie?te?
me`re est quels annonceurspaient per page.Of course, this ?translation?
is not without problems: There is a poor (in this instance)translation of what as quels, and a nontranslation of per.
There is little our system cando about errors such as these made by the on-line MT systems.
Nevertheless, (29)illustrates how the various knowledge sources play a part in determining the finaltranslation in our system.Note that none of these aligned resources would be possible in a TM system.
Theproblem of segmentation is not an inconsiderable one in all EBMT systems, but we(and others) have found that using the marker hypothesis can greatly facilitate such aprocess.
We shall show in subsequent sections that because such knowledge sourcesare derived automatically from the original translations obtained via Web-based MTsystems, the translations obtained in our EBMT process are largely of high quality, areranked highly in the set of output translation candidates, and may be generated inalmost all cases?all this despite the fact that the original translations obtained via theWeb contain many errors, and that the source phrases to be translated were selectedfrom a mere fraction of the rule types in the Penn-II Treebank.3.
Retrieving Chunks and Producing TranslationsIn Section 4, we report on a number of experiments using the resources obtained inthe previous section to translate two test sets of data, one a set of NPs and the other434Computational Linguistics Volume 29, Number 3a set of sentences.
Although we are primarily interested in translating sentences, wetranslate NPs for two reasons: (1) to assure ourselves that we are in fact translatingnominal chunks correctly, and (2) to see whether our methodology can actually correctany NPs mistranslated by the three on-line MT systems.
In this section, we describethe processes involved in retrieving appropriate chunks and forming translations forNPs only (these being fewer in number than for sentences, of course).3.1 Segmentation of the InputIn many cases, a 100% match for a given NP cannot be found in the phrasal lexicon.In order to try and process the NP in a compositional manner, it is segmented intosmaller chunks, and the system then attempts to locate these chunks individually andto retrieve their relevant translation(s) from the various lexicons described above.
Weuse an n-gram-based segmentation method.
Initially, we located all possible bigrams,trigrams and so on within the input string and then searched for these within therelevant knowledge sources.However, many of these n-grams cannot be found by our system, given that newchunks are placed in the marker lexicon when a marker word is found in a sentence.Taking the NP the total at risk a year as an example, chunks such as the total at risk aor at risk a cannot be located, as new chunks would be formed at each marker word(assuming the adjacent word is a non?marker word), so the best that could be expectedhere might be to find the chunks in (31):(31) <DET> the total, <PREP> at risk, <DET> a yearThe respective translations of these chunks would then be recombined to form thetarget string.
In a recent addition to our work, we have eliminated certain n-grams(such as those that end in a marker word, for instance) from the search process, asthese would never be found given our chosen method of segmentation.3.2 Retrieving Translation ChunksWe use translations retrieved from the three different on-line MT systems specifiedabove (see Section 2.1).
These translations are further broken down using the markerhypothesis to provide us with an additional three knowledge sources A?, B?, andC?, a marker lexicon, generalized marker lexicon and word-level lexicon derived fromchunks produced by each system.
These knowledge sources can be combined in severaldifferent ways.
We have produced translations using?
information from a single source: A/A?, B/B?, or C/C?, that is, a phrasallexicon and set of marker lexicons derived from translations producedby each on-line system?
information from pairs of sources: A/A?
and B/B?, A/A?
and C/C?
orB/B?
and C/C?, that is, phrasal and marker lexicons derived fromtranslations produced by two different on-line systems?
information from all available knowledge sources: A/A?
and B/B?
andC/C?, that is, phrasal and marker lexicons derived from translationsproduced by all three on-line systemsThe objective here is to see how much translation coverage and quality are improvedby using chunks derived from multiple sources.
Assuming that the English strings are435Way and Gough wEBMTnot translated in exactly the same manner by the three on-line MT systems means thatmore knowledge sources could be combined in attempting to translate the new inputcontained in the test sets of noun phrases and sentences.
Results from experimentsconducted using multiple knowledge sources are given in Section 4.2.3.3 Calculation of WeightsEach time a source language (SL) chunk is submitted for translation, the appropriatetarget language (TL) chunks are retrieved and returned with a weight attached.
Weuse a maximum of six knowledge sources:?
Stage 1: Three sets of translations (A, B, and C) are retrieved using eachof the three on-line MT systems.?
Stage 2: Three sets of translations (A?, B?, and C?)
acquired by breakingdown the translations retrieved in Stage 1 using the marker hypothesisto form the marker lexicon, the generalized marker lexicon, and theword-level lexicon.Within each knowledge source, each translation is weighted according to the formulain (32):(32) weight = number of occurrences of the proposed translationtotal number of translations produced for SL phraseFor the SL phrase the house, assuming that la maison is found eight times and ledomicile is found twice, then P(la maison | the house) = 8/10 and P(le domicile | thehouse) = 2/10.
Note that since each SL phrase will only have one proposed translationwithin each of the knowledge sources acquired at Stage 1, these translations willalways have a weight of 1.If we wish to consider only those translations produced using a single MT system(e.g., A and A?
), we add the weights of translations found in both knowledge sourcesand divide the weights of all proposed translations by two.
For the SL phrase thehouse, assuming P(la maison | the house) = 5/10 in knowledge source A and P(lamaison | the house) = 8/10 in A?, then P(la maison | the house) = 13/20 over bothknowledge sources.
Similarly, if we wish to consider translations produced by all threeMT systems, then we add the weights of common translations and divide the weightsof all proposed translations by six.When translated phrases have been retrieved for each chunk of the input string,they must then be combined to produce an output string.
In order to calculate aranking for each TL sentence produced, we multiply the weights of each chunk usedin its construction.
Note that this ensures that greater importance is attributed to longerchunks, as is usual in most EBMT systems (cf.
Sato and Nagao 1990; Veale and Way1997; Carl 1999).7As an example, consider the translation into French of the house collapsed.
Assumethe conditional probabilities in (33):7 Note that approaches that prefer the greatest context to be taken into account are not limited to EBMT.Research in the area of data-oriented parsing (cf.
Bod, Scha, and Sima?an, 2003) also shows that unlessthe corpus is inherently biased, derivations constructed using the smallest number of subtrees have ahigher probability than those built with a larger number of smaller subtrees.436Computational Linguistics Volume 29, Number 3(33) a. P(la maison | the house) = 8/10b.
P(le domicile | the house) = 2/10c.
P(s?e?croula | collapsed) = 1/7d.
P(s?effondra | collapsed) = 6/7Given the weights in (33), the four translations in (34) can be produced, each withan associated probability:(34) a. P(la maison s?e?croula | the house collapsed) = 810 .17 =870b.
P(le domicile s?e?croula | the house collapsed) = 210 .17 =270c.
P(la maison s?effondra | the house collapsed) = 810 .67 =4870d.
P(le domicile s?effondra | the house collapsed) = 210 .67 =1270Where different derivations result in the same TL string, their weights are summedand the duplicate strings are removed.The examples in (33) and (34) are reasonably straightforward if we assume, ashere, that the chunks in (35) exist in the system databases shown:(35) Marker lexicon:<DET> the house : la maison<DET> the house : le domicileWord-level lexicon:<LEX> collapsed : s?e?croula<LEX> collapsed : s?effondraIf the input string were instead a house collapsed, and the NP a house were absent fromthe marker lexicon, then a translation could be formed via the chunks in (36):(36) Generalized marker lexicon:<DET> house : maison<DET> house : domicileWord-level lexicon:<LEX> collapsed : s?e?croula<LEX> collapsed : s?effondra<DET> a : un<DET> a : uneGiven the aligned segments in (36), the correct translations (37) would be built:(37) a. Une maison s?e?croula.b.
Une maison s?effondra.c.
Un domicile s?e?croula.d.
Un domicile s?effondra.However, in addition, the mistranslations in (38) would be constructed:(38) a.
*Un maison s?e?croula.437Way and Gough wEBMTb.
*Un maison s?effondra.c.
*Une domicile s?e?croula.d.
*Une domicile s?effondra.These mistranslations are all caused by boundary friction.Each of the translations in (37) and (38) would be output with an associated weightand ranked by the system.
We would like to incorporate into our model a procedurewhereby translation chunks extracted from the phrasal and marker lexicons are morehighly regarded than those constructed by inserting words from the word-level lexiconinto generalized marker chunks.
That is, we want to allocate a larger portion of theprobability space to the phrasal and marker lexicons than to the generalized or word-level lexicons.
We have yet to import such a constraint into our model, but we planto do so in the near future using the weighted majority algorithm (Littlestone andWarmuth 1992).4.
Experiments and System EvaluationWe report here on a number of experiments using test sets of 200 sentences and 500noun phrases.
Some typical examples from the two test sets are given in (39):(39) Noun phrases:?
the heavy use of management fees last year?
an increase through issues of new shares and convertible bonds?
a space-based defense shield for official acts by the congressmanSentences:?
The bright red one interferes with the genes that are responsible forcollecting pollen.?
A more recent novel permitted the new basket product.?
The area with the museums and the charities is under something of acloud.?
Reducing the supply of goods as commissions to middlemen permitteda chaotic sex life.The test sets were created automatically from words contained in at least one of thesystems?
knowledge bases, with the proviso that the strings corresponding to the 59rule types we extracted from the Penn Treebank reflected the frequency bias of theserule types, as far as possible.
That is, we wanted to ensure that strings correspondingto a rule type that was (approximately) twice as frequent as some other rule typeoccurred (approximately) twice as often in the test sets.
Finally, we ensured that stringscorresponding to all 59 rule types were present in the sentence test set.The experiments were designed to evaluate the coverage and translation qualityof different versions of our EBMT system.
We contrast the results obtained when thememories of our system are seeded with source strings and their translations derivedfrom?
each of the three individual on-line MT systems (A, B, and C)?
each pair of on-line MT systems (AB, AC, and BC)?
all three on-line MT systems (ABC).438Computational Linguistics Volume 29, Number 3We also compare and contrast the results obtained when the memories of our sys-tem are seeded with source strings and their translations derived using third-personsingular, third-person plural, and both third-person singular and third-person pluraldummy subjects.Both sets of experiments are designed to test whether coverage and translationquality improve when more ?source, target?
fragments are taken into account.
Withrespect to quality, the translations output (for sentences, using chunks derived withthird-person plural dummy subjects) were scored according to the following scale bytwo native speakers of French with excellent English:?
1: Contains major syntactic errors and is unintelligible?
2: Contains minor syntactic errors and is intelligible?
3: Contains no syntactic errors and is intelligibleThis scale is used to measure the impact on translation quality, both for sentencesand NPs, of using multiple knowledge sources.
Although we are primarily interestedin the translation of sentences, we use the NP test set to see whether we are in facttranslating nominal chunks correctly, and also to investigate whether our methodologycan actually correct any NPs mistranslated by the three on-line MT systems.
We discussthis further in Section 5.We also measure the ability of our system to rank the ?best?
translation (as deter-mined by our human experts) highly in the set of output translations.
Statistical MTsystems such as wEBMT may derive many different translations for a particular input,each of which is output with a confidence weighting.
We are keen to ensure that ifour system is able to produce high-quality translations, these are ranked as highlyas possible: We do not consider it feasible for a human to have to sift through manyhundreds or thousands of translations in order to determine the ?correct?
one.In a further experiment, we translate the test set of sentences via the three on-line MT systems and test to see whether our system wEBMT can improve on thesetranslations.
In so doing we calculate the ?net gain?
of performing example-based MTcompared to using on-line MT systems.Finally, we offer some thoughts on the relative merits of the three on-line MTsystems used in our research.
Although this was not the primary focus of our research,it turned out that we were able, as a direct consequence of our methodology, to evaluatethe on-line MT systems chosen.4.1 Experiments Using Single Knowledge SourcesHere we report on experiments in which the two test sets are tackled by our systemwhen its memory is seeded with translations obtained by the individual on-line MTsystems specified in Section 2.1.
A parameter that is altered in the experiment onthe sentential test set is the nature of the dummy subjects used to gather the initialtranslation fragments: third-person singular, third-person plural, and both third-personsingular and third-person plural.4.1.1 Sentences.
The test set comprised 200 sentences, with an average sentence lengthof 8.5 words (minimum 3 words, maximum 18).
The input strings were segmented byapplying the n-gram segmentation approach outlined in Section 3.439Way and Gough wEBMTExperiment 1: Third-Person Plural SubjectsAs far as coverage is concerned, our system wEBMT translated 184 (92%) of the sen-tences using chunks derived from Systems A and C, and using chunks from system B,our system managed to translate 180 sentences (90%).
The same 16 sentences were nottranslated by any of the systems owing to their failure to locate one or more words inthe sentence within the word-level lexicon.
Recall that despite the fact that all wordsin the test set were seen by the system in the training phase, only those content (i.e.,non-marker) words that occur in bigram marker chunks are inserted into the word-level lexicon (cf.
(23)).
In cases such as these, in which one or more words cannot betranslated by our system, partial translations such as those in (40) are output:(40) A little girl misplaced a full page =?
Une petite fille misplaced unepleine page.That is, although misplaced was present in the system?s database, it was not present inthe correct context.
That is, it appeared in the phrasal lexicon, as shown in (41):(41) were misplaced =?
ont e?te?
e?gare?sThe form required in (40) is a simple past-tense verb, but misplaced appears in (41) onlyas a passive participle.
The word were in (41) is not a marker word, so this fragmentcannot be broken down any further by our segmentation method.8 In such cases weoutput the partial translation with source equivalents for any untranslated words, asshown in (40).Ninety-six (48%) of the sentences were translated by combining fragments con-tained in the original phrasal lexicon or the marker lexicon, 56 (28%) of the translationswere obtained by locating single content (i.e., non-marker) words in the word-levellexicon and inserting these into the translation at the appropriate position, and 32(16%) were produced by inserting marker words into generalized templates.Table 1 shows the results obtained from our human evaluators?
ratings of thetranslations produced by our system when it was populated with fragments derivedfrom one of the individual on-line MT systems.
Evaluators rated more than one-thirdof translations as intelligible and without syntactic errors (score 3), with over 85% oftranslations deemed intelligible (scores 2 and 3) for all systems.
Unintelligble transla-tions (score 1) ranged from 14% for chunks derived from SDL to just 4.4% for trans-lations formed from knowledge sources created from Logomedia.
These initial resultsprovide some evidence in favor of the hypothesis that Logomedia might be the bestsystem.
Although such evaluation is not a primary focus of our work at the outset,our methodology provides as a spin-off an evaluation of the three MT systems.
Wediscuss this further in Section 4.5.When the system cannot produce a translation for a particular input, the mainreason is an absent word in the word-level lexicon.
Adding more lexical entries wouldimprove translation coverage and would also affect translation quality (possibly ad-versely, in some cases).
We plan to measure the impact of a larger lexicon in futurework.
Low-quality translations are almost invariably caused by inappropriate verbforms in the word-level dictionary: For the experiments carried out in which all verbs8 Of course, even if it could be, we would be able to derive only the mistranslation Une petite fille e?gare?sune pleine page, assuming there to be no other relevant fragments in the system?s databases.440Computational Linguistics Volume 29, Number 3Table 1Translation quality for sentences: Chunksderived from individual on-line MTsystems, third-person plural dummysubjects.System Score 1 Score 2 Score 3A 14.2% 51.2% 34.6%B 8.9% 54.7% 36.4%C 4.4% 59.1% 36.5%were third-person plural, any NP with a third-person singular subject in the test setwould be accompanied by a third-person plural verb in the translation.
A similar effectis seen where the databases of wEBMT were seeded with third-person singular verbs,of course.
However, we should expect an improvement in translation quality whenboth sets of verb forms are included in the memories of the system (see Experiment2).Table 2 shows where the ?best?
translation, as defined by a human expert, wasranked among the of translations output by our system.
In over 65% of cases, thesystem itself had ranked the ?best?
translation first, and the ?best?
translation wasnever located outside the top five ranked translations.
This is remarkable given thatover 2,000 translations are output for certain source sentences.Experiment 2: Seeding the Databases with More ExamplesThe results for the previous experiment were obtained when the databases were seededwith third-person plural dummy subjects.
We ran two variations on this experiment:(1) we tested the system by seeding its memories with third-person singular dummysubjects, and (2) We tested the system by seeding its memories with both third-personsingular and third-person plural dummy subjects.Figure 1 shows that translation quality improves when the system databases areseeded with more translation pairs.
We can see that the system does slightly betterwhen it uses third-person plural chunks compared to when it uses their singular coun-terparts.
When third-person singular dummy subjects are inserted in order to derivethe initial translation fragments inserted into our system?s memories, the number oftranslations rated 3 for quality deteriorates by about 5% for systems B and C and byabout 3% for system A.
Given a larger number of third-person plural NP subjects inour test set, this was to be expected.However, a considerable improvement in quality can be seen when fragments fromTable 2Ranking of ?best?
translation for sentences:Chunks derived from individual on-line MTsystems, third-person plural dummy subjects.System Ranked 1 Ranked 2?5A 71.6% 28.4%B 65.3% 34.7%C 70.3% 29.7%441Way and Gough wEBMT0102030405060708090100A B C3rd p.s:33rd p.p:33rd p.p/s:33rdp.p/s:3+2Figure 1Translation quality improves when system databases are seeded with more translation pairs:Measuring % translation quality using fragments derived from single on-line MT systems.Table 3Ranking of ?best?
translation for sentences: Chunks derived fromindividual on-line MT systems, third-person singular and third-personplural dummy subjects.System Ranked 1 Ranked 2?5 Ranked 6?10 Ranked 10?20A 65.2% 30.5% 0.0% 4.3%B 60.8% 34.9% 0.0% 4.3%C 64.1% 31.6% 0.0% 4.3%both singular and plural forms are inserted into the system?s memories.
Translationsproduced from chunks derived from system A are rated 3 in 66.1% of cases, and thisrises to 67.9% for system B and 68% for system C. Regarding intelligibility (scores 2and 3 for quality), system A scores 85.8%, system B scores 91.1%, and system C scores95.6%.
We consider these to be very reasonable results.Table 3 summarizes the relative ranking of the ?best?
translation when more trans-lation pairs are used to seed the system?s memories.
Now that both third-person sin-gular and third-person plural dummy subjects are provided, we see that the numberof ?best?
translations ranked first deteriorates, by about 6% for systems A and C andby 4.5% for system B.
In Table 2, we saw that the ?best?
translation was in no caseranked lower than fifth, but now that many more translations are output per test setsentence, we sometimes have to search as low as 20th in order to find the ?best?translation.4.1.2 Experiment 3: Noun Phrases.
The test set comprised 500 noun phrases, with anaverage NP length of 6.14 words (minimum 3 words, maximum 12).
The noun phrasesin the test set alo need to be fragmented using our n-gram segmentation method, as442Computational Linguistics Volume 29, Number 3it is highly probable that they do not exist en bloc in the phrasal lexicon and thereforeneed to be analyzed using smaller fragments in the system?s databases.We give results for coverage and translation quality in Table 4.
These results arefor NPs translated via chunks derived from the three individual on-line MT systems.As with the sentence test set, fragments derived from systems A and C achieve thebroadest coverage, producing translations for 474 out of the 500 NPs; those obtainedfrom system B enable 463 of the 500 NPs to be translated.As for quality, wEBMT clearly performs best when using translation fragmentsderived from system C: 47.3% of these translations were awarded a quality score of 3,more than 10% better than for chunks derived from system B.
For system C, a total of452 (96%) of the generated translations were deemed intelligible (scores 2 and 3), thatis, 31 (6.6%) more translations than with system B.On average, about 54% of translations are formed by combining chunks fromthe phrasal lexicon with those from the marker lexicon, about 9% are produced byinserting marker words into the generalized templates, and about 37% are generatedby inserting single non?marker words from the word-level lexicon at the appropriatelocations in phrasal chunks.
The major reason that translations fail to be produced in6% of cases is the absence of a relevant generalized template.
For example, the unseeninput her negative TV ads is generalized to (42):(42) <POSS> negative TV adsHowever, the nearest relevant generalized template found in the system?s memory is(43):(43) <DET> negative TV adsThat is, the template in (43) allows the insertion of any determiner, but no othermarker word.
Deriving translation fragments from more examples would lead to animprovement in coverage.
Alternatively, for marker words that appear in the samerelative position, such as determiners and possessive pronouns, we could ?back off?to a more general marker tag to allow mutual substitution of such words in a subse-quent operation to enable translation of examples like these.
This remains an area ofinvestigation in future work.The results in Table 4 further substantiate our findings on the sentence test set,namely, that system C may be the best of the three on-line MT systems used to populatethe memories of our EBMT system.
We comment further on this in Section 4.5.
Inaddition, these figures provide strong evidence that our system can indeed translatemost noun phrases with which it is confronted and with more than reasonable quality.Table 4Translation coverage and quality for NPs: Chunksderived from individual on-line MT systems.System Coverage QualityScore 1 Score 2 Score 3A 94.8% 13.7% 52.5% 33.8%B 92.6% 10.6% 52.3% 37.1%C 94.8% 4.0% 48.7% 47.3%443Way and Gough wEBMTTable 5Ranking of ?best?
translation for NPs: Chunks derived fromindividual on-line MT systems.System Ranked 1 Ranked 2 Ranked 3?5 Ranked 6?10A 64.6% 9.1% 23.6% 2.7%B 57.7% 15.6% 24.8% 1.9%C 60.0% 7.6% 29.3% 3.1%Table 6Number of translations produced for theNP a plan for reducing debt over 20 years.System(s) Number of TranslationsA 14B 10C 5AB 108AC 72BC 42ABC 224The results obtained regarding the ranking of the ?best?
translation appear inTable 5.
Our system ranks the ?best?
translation first over 57% of the time, and inover 96% of cases, it ranks it in the top five, and at worst in the top ten.4.2 Experiments Using Multiple Knowledge SourcesIf the three on-line MT systems translate the phrases extracted from the Penn-II Tree-bank in different ways, then combining systems to obtain results for AB, AC, BC,and ABC always involves an increase in the number of translations produced, bothfor sentences and noun phrases.
That is, if an input string receives a translation viachunks derived from the individual on-line systems, when chunks are combined fromdifferent systems, more translations will be output for that input string.As an example, the number of translations produced by each system for the NPa plan for reducing debt over 20 years is shown in Table 6.
Whereas the greatest num-ber of translations for this NP produced from chunks from any individual on-linesystem is 14, when translation fragments from all three systems are merged (ABC),224 translations are produced.
Combining systems in this way means that all possiblecombinations of chunks from the systems are produced: That is, the number of trans-lations generated via AB is much larger than those derived from either A or B, as nowchunks from A and B may be combined to produce new translations that could notbe generated from the individual knowledge sources.
As a further example, considerthe translation of the NP the total at risk a year.
When fragments from systems A andB are combined, the ?best?
translation is comprised of the chunk combination AAB,that is, the three-chunk combination in (44), with the first two chunks obtained fromsystem A, and the last from system B:(44) [Athe total], [Aat risk], [Ba year]That is, the translation of this NP improves when the performance of system AB is444Computational Linguistics Volume 29, Number 3020406080100AB BC AC ABC3rd p.s:33rd p.p:33rd p.s/p:33rdp.s/p:3+2Figure 2Translation quality improves when system databases are seeded with more translation pairsand when more knowledge sources are used: Measuring % translation quality using fragmentsderived from combinations of on-line MT systems.evaluated: Of course, if we consider (say) three-chunk combinations from either systemA or B, the only possibilities are AAA or BBB, respectively.However, the number of translations produced by the system is less significantthan their quality.
The ranking process outlined in Section 3 classifies the translationsproduced with regard to their position as the ?best?
translation.
In the sections below,we also discuss the issue of quality and show that it improves when more translationfragments are taken into account.
Furthermore, we show below that despite generatingmore translations per input string, wEBMT still ranks the ?best?
translation in the top1% of all output translation candidates.4.2.1 Experiment 4: Translating Sentences by Combining Fragments from DifferentSystems.
We saw in Experiment 1 that 16 strings in the test set were left untranslatedby systems A, B, and C individually.
When knowledge sources are combined, these 16strings remain untranslated.
However, as Figure 2 shows, the translation quality im-proves significantly.
The best individual system performance was 36.5% scoring 3.
Thisrises to a best performance of 48.9% among pairs of systems combined and improvesstill further to 50% when chunks from all three knowledge sources are combined.Table 7 provides results regarding the relative location of the ?best?
translation forsentences.
For all system combinations, the ?best?
translation is to be found amongthe top 10 ranked translations in all permutations of combinations of chunks, withat least 54% ranked first.
Despite a corresponding rise in the number of translationsproduced per input sentence when all three knowledge sources are combined (ABC),in over 97% of cases, the ?best?
translation continues to be found in the top five outputcandidates.445Way and Gough wEBMTTable 7Ranking of ?best?
translation for sentences: Chunksderived from combinations of on-line MT systems,third-person plural dummy subjects.System Ranked 1 Ranked 2?5 Ranked 6?10AB 67.6% 31.1% 1.3%AC 54.0% 46.0% 0.0%BC 63.6% 35.1% 1.3%ABC 62.2% 35.1% 2.7%4.2.2 Experiment 5: Combining Fragments from Different Systems and Seeding theDatabases with More Examples.
Figure 2 demonstrates that considerable improve-ments in translation quality are achieved when the memory of wEBMT is seeded withboth third-person singular and third-person plural fragments.
For the pairwise com-binations, 78.7% of the translations derived from AB are rated 3 for quality, comparedto 80.4% of those derived from AC and BC.
The results for ABC improve again, to81.5%.
Regarding intelligibility (scores 2 and 3 for quality), we can see from Figure 2that near perfect results are obtained: AB scores 95.6%, and all other combinationsscore 96.7%.Table 8 shows the ranking of the ?best?
translation when multiple knowledgesources are employed and both third-person singular and third-person plural dummysubjects are used to populate the system?s memories.
The number of instances in whichthe ?best?
translation is ranked first by wEBMT deteriorates: by 24% for AB, by 15% forAC, by 20% for BC, and by 27% for ABC.
For all system combinations, Table 7 showsthat the ?best?
translation was ranked no lower than 10th; for the system combinationsin Table 8, sometimes the ?correct?
translation is ranked as low as 36th.
As expected,the worst ranking results are for system combination ABC, in which all system chunksare combined for both third-person singular and third-person plural dummy subjects.However, even here the ?best?
translation is ranked in the top five in over 63% ofcases, and 72.6% of the time it is located among the top 10 ranked translations.
Forthis system configuration, the lowest we have to look to find the ?best?
translationis 36th.
For that particular sentence (i.e., the one for which the ?best?
translation isranked 36), over 4,000 possible translations are generated, so even here the ?best?translation remains in the top 1% of translation candidates.Table 8Ranking of ?best?
translation for sentences: Chunks derived from combinations ofon-line MT systems, third-person singular and third-person plural dummysubjects.System Ranked 1 Ranked 2?5 Ranked 6?10 Ranked 10?20 Ranked 20?40AB 43.4% 32.6% 2.3% 13.0% 8.7%AC 39.1% 34.8% 5.4% 12.0% 8.7%BC 43.4% 31.7% 2.7% 13.5% 8.7%ABC 35.2% 28.0% 9.4% 18.3% 9.1%446Computational Linguistics Volume 29, Number 3Table 9NPs: Coverage and quality improve whenfragments from different sources are included.Knowledge Source Coverage QualityCombination Percentage Score 3A 94.8 33.8B 92.6 37.1C 94.8 47.3AB 95.4 54.1BC 95.6 64.0AC 94.8 72.0ABC 96.0 77.84.2.3 Experiment 6: Translating Noun Phrases by Combining Fragments from Dif-ferent Systems.As we did with sentences, we seeded our EBMT system with fragments derived fromthe three different on-line MT systems and confronted it with the NP test set.
Table 9clearly shows that as more knowledge sources are added, translation quality improvesconsiderably.
The worst-performing individual system scores 3 for quality in just overa third of cases, but when all system chunks are combined, this rises to 77.8%.
Notealso that, unlike with sentences, we see an increase in coverage when more knowledgesources are used, from a low of 92.6% for system B to a high of 96% when all chunksare combined.
Many more improvements are seen when our post hoc validation andcorrection methodology, described in Section 5, is used, but the merging of fragmentsderived from different on-line systems also leads to an improvement in translationquality.
Consider the examples in (45):(45) Input: an old story in commonSystem B: une vieille histoire dans communSystem Combination BC: une vieille histoire en communThat is, the optional PP in common was mistranslated by system B as dans commun, butwhen knowledge from system C is added to that of system B, the improved translationen commun is generated.We saw in Section 4.1.2 that when translating the NP test set, the ?best?
transla-tion, as adjudged by our human evaluators, was to be found no lower than tenth ofall translations output by our system.
When knowledge sources are combined, it isTable 10Ranking of ?best?
translation for NPs: Chunks derived frommore that one on-line MT system.System Ranked 1 Ranked 2 Ranked 3?5 Ranked 6?10AB 42.2% 13.8% 41.3% 2.7%AC 62.1% 14.1% 21.3% 2.5%BC 66.4% 11.4% 19.8% 2.4%ABC 62.0% 17.5% 13.5% 7.0%447Way and Gough wEBMTimportant to measure whether the ?best?
translation is still highly ranked.
The resultsof such an assessment are summarized in Table 10.
When the ?best?
translation isranked first by the system, we see that the optimal combination of knowledge sourcesis the pair BC, with 66.4%.
This is an interesting result given that in Table 5, only 57.7%of the NPs translated by system B were ranked first, with 60% of those produced bysystem C ranked in first place.
That is, we see a 6.4% improvement (31 NPs) whenfragments from systems B and C are combined.
All other combinations cause the num-ber of ?best?
translations ranked first to deteriorate, as may be expected.
When the?best?
translation is ranked either first or second by the system, the best combinationof fragments is that from system ABC, with 79.5% (376 NPs).Importantly, for all combinations, the ?best?
translation remains among the top 10ranked translations.
This is encouraging, as any translator using our system needs onlyto examine a small subset of the translations produced to find the ?best?
one.
Indeed,given the various results shown, we are confident that we could prune the number oftranslations generated for presentation to the translator for selection of the ?best?
one:For the most part, this is the top ten translations for both NPs and sentences, but inthe worst case, we need present no more than the top 1% of the candidate translations.4.3 SummaryThe results presented in this section show that seeding the wEBMT system?s databaseswith more fragments improves both coverage and translation quality.
We do this addi-tional seeding in two ways: (1) by combining fragments derived from different on-lineMT systems, and (2) by obtaining translations using both third-person singular andthird-person plural dummy subjects.
The best combination of these parameters is touse chunks derived from Logomedia with third-person plural dummy subjects pro-vided.
Nevertheless, despite the fact that Logomedia appears to be the best on-line MTsystem, adding chunks from the other two on-line MT systems improves coverageand translation quality.
In sum, therefore, the best results are obtained when chunksfrom all three on-line systems (combination ABC) are used and the wEBMT system?sdatabases are seeded with translations from these systems for both third-person sin-gular and third-person plural versions of sentences.The disadvantage of using more knowledge sources, of course, is that many morecandidate translations are generated, which sometimes causes the ?best?
translationto appear lower in the ranked order of output translations.
Nevertheless, the ?best?translation is almost always to be found in the top 10 translations produced by wEBMTand always in the top 1% of the candidate translations.4.4 Relative Gain of EBMTIn order to try to calculate the relative gain of EBMT, we translated all 200 strings in thesentence test set via the three on-line MT systems used elsewhere in our experiments.Of course, the main advantage of using such Web-based systems is that they areextremely robust: no matter what they are confronted with, they will always producesome translation.
With respect to coverage, therefore, the on-line systems currentlywin out over wEBMT: the size of the lexicons available to the on-line systems meansthat they will generate translations with all source words translated more often thanour system will.
Nevertheless, the fact that our system outputs partial translations insituations in which it encounters a word that it cannot translate demonstrates a certainlevel of robustness in our system.Where quality is concerned, however, wEBMT can improve on the translationsproduced by the three on-line MT systems.
We provided our human evaluators withthe source sentences from the test set, together with the translation generated by our448Computational Linguistics Volume 29, Number 3wEBMT system using combinations of chunks derived from all three on-line systems(ABC), and the translation obtained directly from the on-line systems themselves.
Thepairs of translations (wEBMT and on-line MT system) were presented in a randomorder.
The evaluators were simply asked to state, for all three on-line MT systems,which of the pair of translations they preferred: that from the on-line MT system orthat from wEBMT.Translations produced by wEBMT using chunks derived from all three systemswere preferred to those from system A in 30/184 cases (16.3%) (we ignored the 16cases for which our system could produce only partial translations); for system B,our system?s translations were preferred in 8/180 cases (4.4%); and for system C,our system was judged as producing better translations in 6/184 cases (3.3%).
Someexamples in which our system offered improvements over the translations providedby the on-line MT systems are shown in (46):(46) Input: Her short term interest rates link the issues.System A: Son lien a` court terme de taux d?intere?t les questions.wEBMT ABC: Ses taux d?intere?t a` court terme lient les questions.Input: The researchers air the shows.System B: L?air de chercheurs les expositions.wEBMT ABC: Les chercheurs ae?rent les expositions.Input: A group hire lawyers to provide information about clients.System C: Un avocats de la location du groupe fournir de l?informationsau sujet de clients.wEBMT ABC: Un groupe embauche des avocats a` fournir del?informations au sujet de clients.Regarding the first two translation pairs in (46), wEBMT has provided a finite verbwhere the on-line MT systems have none.
In addition, the translation of the subjectNPs is much improved.
As for the final translation pair in (46), whereas Logomediamanaged to retrieve the correct translation of provide, this was not the main verb inthe English input string.
wEBMT, on the other hand, does translate hire correctly as averb rather than a noun.We consider three ways in which the net gain of EBMT may be calculated.
First,we assume it is equal to the number of translations produced by wEBMT that arepreferred by the human evaluator, minus those derived by the on-line MT systemsthat are preferred, divided by the total number of translations.
In fact, where bothwEBMT and the on-line systems produce a translation, those derived via wEBMT arealways preferred.
Those translations produced by the on-line systems that are preferredare those in which wEBMT was unable to generate a complete translation.
This is quitea harsh measure: As can be seen from the translations in (46), although the words inthe translations produced by the on-line systems are all French (but recall (29)?
(30),in which this was not the case), the translations themselves are poor.
In some cases,despite the fact that the translations derived via wEBMT may contain an untranslatedEnglish word, the accompanying partial translations may in fact be deemed superiorto the ?complete?
translations derived via the on-line systems.Nevertheless, assuming that the on-line systems win out in these situations, thenet gain compared to system A is 14/200 (7%), whereas for systems B and C, we seein effect a net loss: ?12/200 (?6%) for system B, and ?10/200 (?5%) for system C. Ifwe can obtain complete translations in those cases in which we currently encounter449Way and Gough wEBMTan untranslatable word, we are confident that we can convert these net losses intonet gains.
With respect to system A, we can assume that our net gain would increasefurther.However, we provide two other interpretations of the net gain of EBMT, calculatedusing the formula in (47):(47) Net Gain = Coverage Percentage + K(Translation Quality)The term Translation Quality in (47) refers to the number of translations preferred bythe human evaluator, excluding cases in which one system failed to produce a trans-lation, which is already factored into the equation under the term Coverage Percentage.Where K=1, we view coverage and translation quality as equally important.
If weconsider quality to be more important, we can increase K. We provide results for K=1and K=2 in (48):(48) Where K=1:Net GainMT = 100Net GainEBMT = 92 + 30 = 122 (compared to system A)Net GainEBMT = 92 + 8 = 100 (compared to system B)Net GainEBMT = 92 + 6 = 98 (compared to system C)Where K=2:Net GainMT = 100Net GainEBMT = 92 + 60 = 152 (compared to system A)Net GainEBMT = 92 + 16 = 108 (compared to system B)Net GainEBMT = 92 + 12 = 104 (compared to system C)That is, where K=1, wEBMT outperforms SDL by a factor of 22, whereas there is no gainwith respect to Reverso, and a slight loss compared to Logomedia.
However, wEBMToutperforms all three on-line systems when translation quality is viewed as twice asimportant as coverage.
This is a reasonable view, we feel, and our system shows a netgain against all three on-line systems in this context.
Although the coverage obtainedwith the on-line systems is better, the improved translation quality obtained withwEBMT ensures a net gain.We expect to obtain more insightful results regarding the relative gain of EBMTover on-line MT systems when automatic evaluation metrics (such as IBM?s Bleu, ordynamic programming, or sentence- and word-error rates) have been obtained.
Thisis a priority in future work.4.5 Evaluating Individual On-line MT SystemsThe previous sections detail the results obtained when translation fragments derivedfrom the three individual on-line MT systems are used, together with various combi-nations of knowledge sources.
We provided results both for coverage and translationquality.
As we noted above, we were able, as a consequence of our chosen methodol-ogy, to evaluate the on-line MT systems used.Where sentences are concerned, we saw that coverage was approximately the samefor each individual system, and that combinations of multiple knowledge sources did450Computational Linguistics Volume 29, Number 3not improve coverage.
For NPs, however, coverage improved when more fragmentswere considered: Whereas 474 NPs could be translated by both systems A (SDL) and C(Logomedia), this number rose to 480 when all three knowledge sources were combined.With respect to translation quality, whereas Logomedia and Reverso could hardlybe distinguished when it came to numbers of translations of sentences adjudged asintelligible and syntactically correct, if we consider those translations considered un-intelligible by our human evaluators, about twice as many translations produced bychunks derived from Reverso were unintelligible compared to those produced by Lo-gomedia.
This would indicate that Logomedia may be better.When fragments from combinations of systems are considered, we note that forsentences, no improvement in coverage results, but quite significant improvements inquality are seen.
System C slightly outperformed system B in the individual face-off,and we see that combinations that utilize chunks from system C outperform thosethat do not: AC and BC both score 3 for quality in 80.4% of cases, compared to AB?s78.7%, and ABC improves still further, to 81.5%.
When the databases of wEBMT areseeded with more chunks (using both singular and plural dummy subjects), system Ccontinues to outperform the other two systems.When NPs are considered, system C considerably outperforms the other two sys-tems, obtaining a score of 3 for quality in 10.2% more cases than its nearest challenger,system B.
When chunks from different systems are combined, again we see that com-binations with chunks derived from system C outperform those that omit them: BCand AC improve over AB by 10% and 18%, respectively, and ABC shows a furtherincrease.Finally, in Section 4.4, we discussed the relative gain of using wEBMT over thethree on-line MT systems.
Further evidence that Logomedia may be the best of the threesystems is provided by the fact that the relative gain compared to Logomedia was muchlower than with the other two systems.It is worth considering why some combinations seem to work better than others.For NPs, in cases where system A fails to produce the ?best?
translation, this is oftendue to incorrect word order.
For example, in the NP cellular mobile lines for the workmen,system A produces the translation cellulaire mobile lignes pour les ouvriers.9 It is also thecase that when system A fails to retrieve a translation for a particular chunk, it simplyproposes the English for that chunk as its translation.
This is useful to some extent,in that a default translation is produced (cf.
the similar approach that we have takenwith respect to (40), for instance).
However, in all of these cases this utility is lessenedconsiderably given that either system B or system C produces a better translation.System B has the added advantage that it sometimes provides an alternative translationin brackets.
If no translation is available, the English is output.
System C often producesa correct translation of a verb where the other systems are lacking.
It is probablybecause of this aspect of translation that system C?s translations are preferred overthose of the other two systems.5.
Validation and Correction of Translations via the WebA translation can be formed in our system only when the recombination of chunkscauses the input string to be matched exactly.
Therefore, if all chunks cannot be re-trieved, then no complete translation can be produced (cf.
(40) and resultant discus-9 Such a translation would be a candidate for post hoc validation via the Web (cf.
Section 5), but thecorrect translation lignes cellulaires mobiles pour les ouvriers is produced in any case by system C,rendering this unnecessary.451Way and Gough wEBMTsion).
We have shown that when a translation cannot be produced by combiningphrasal chunks, translations can be formed by the insertion of single marker wordsinto generalized templates.
This can be compared to the idea of ?hooks?
(Somers,McLean, and Jones 1994), where some context in which fragments have occurred ismaintained in the translation templates.
The hooks indicate which words and POStags can occur in the immediate left and right context of a fragment, together with aweight that reflects how often this context is found in a corpus.
The ?best?
translation,therefore, is simply that which is output by the system with the highest score.Consider the translation of the NP the personal computers.
There are three possibleways in which this may be segmented using the marker hypothesis, namely, the chunksin (49):(49) Phrasal lexicon: the personal computersMarker lexicon: <DET> the personal computersGeneralized lexicon: <DET> personal computersIn our system, the only chunk retrieved is the generalized chunk in (49).
The systemstores a list of marker words and their translations in the word-level lexicon.
A weightderived via the method in (32) is attached to each translation.
The system searchesfor marker words within the string and retrieves their translations.10 In this case, themarker word in the string is the and its translation can be one of le, la, l?, or les,depending on the context.
The system simply attaches the translation with the highestweight to the existing chunk ordinateurs personnels to produce the mistranslation in(50):(50) *la ordinateurs personnelsThe problem of boundary friction is clearly visible here: We have inserted a femininesingular determiner into a chunk that was generalized from a masculine plural NP.However, rather than output this wrong translation directly, we use a post hoc val-idation and (if required) correction process based on Grefenstette (1999).
Grefenstetteshows that the Web can be used as a filter on translation quality simply by searchingfor competing translation candidates and selecting the one that is found most often.Rather than search for competing candidates, we select the ?best?
translation and haveits morphological variants searched for on-line.
In the example above, namely, the per-sonal computers, we search for les ordinateurs personnels versus the wrong alternativesle/la/l?ordinateurs personnels.
Interestingly, using Lycos, and setting the search languageto French, the correct form les ordinateurs personnels is uniquely preferred over the otheralternatives, as it is found 2,454 times, whereas the others are not found at all.
In thiscase, this translation overrides the highest-ranked translation (50) and is output as thefinal translation.
In fact, in checking the translations obtained for NPs using systemcombination ABC, we noted that 251 NPs out of the test set of 500 could be improved.Of these 251, 207 (82.5%) were improved post hoc via the Web, with no improvementfor the remaining 43 cases.
We consider this to be quite a significant result.In addition to determiner-noun agreement, we use this methodology to check foragreement between the head noun in the subject NP with the head verb in the main10 Although this is not relevant for the example discussed here, if non?marker words remain untranslatedyet exist in the word-level marker lexicon, these too would be inserted at this stage.452Computational Linguistics Volume 29, Number 3Table 11Validating translations using AltaVistan-Gram Searched For Number of Web Occurrencesempire sont 353sont au 91,197empire est 1,809est au 217,820clause VP.
We extracted a list of all verbs in the Penn-II Treebank and obtained trans-lations for all verb forms using the three on-line MT systems by inserting appropriatethird-person dummy subjects.
We use the list of translated verbs to attempt to find themain verb and identify the head noun as the rightmost non?marker word or the right-most word before any other marker word in a nominal chunk.
Having extracted thenoun and the verb from the mistranslation in this way, we then search for this bigramon the Web and correct the verb if its morphological variant (third-person singular orthird-person plural form) is found more often than in the translation obtained by oursystem.To exemplify this procedure with a sentence from the test set, his empire is beyondthe reach of the president, system A produces the translations in (51):(51) a.
*son empire sont au dela` de la porte?e du pre?sident (ranked first, withprobability 0.614)b. son empire est au dela` de la porte?e du pre?sident (ranked fifth, withprobability 0.028)This shows that a correct translation such as (51b) may be ranked lower than an incor-rect variant (51a) with considerably less probability.
The higher ranking is accountedfor because the pair ?is beyond the reach of the president, sont au dela` de la porte?e du pre?sident?is contained in the phrasal lexicon, whereas the pair ?is beyond the reach of the president,est au dela` de la porte?e du pre?sident?
does not appear.Prior to outputting translations such as (51a), we search for the relevant n-gramsvia the Web.
For this example, using AltaVista, we obtained the results in Table 11.With the counts for all other bigrams for the two translation candidates in (51) beingexactly the same, in order to evaluate which of these proposed target strings is the?better?
translation, one can simply add the occurrences found on the Web for all fourdifferent bigrams and report their relative probabilities.
This gives us the probabilitiesin (52):(52) a.
#empire sont + #sont au = 91,550/311,179 = 0.294b.
#empire est + #est au = 219,629/311,179 = 0.706That is, the string empire est au is about 2.4 times more likely than the string empiresont au.
However, the count for the second bigram in each example in (52) can ofcourse be discounted, as the juxtaposition of sont or est with au bears no relevance tothe correctness or otherwise of the translations in (51).
The amended probabilities are,therefore, those in (53):(53) a.
#empire sont = 353/2,162 = 0.163b.
#empire est = 1,809/2,162 = 0.837453Way and Gough wEBMTTable 12Using the Web to improve noun-verb agreementImprovement No Improvement N-V Confusion Not on WebSystem A: Enterprise Translation Server58.6% 3.4% 17.3% 20.7%System B: Reverso62% 3.4% 17.3% 20.7%System C: Logomedia76% 3.4% 17.2% 3.4%These figures accurately reflect the likelihood of the translations in (51).
Given thatP(empire est) is about five times higher than P(empire sont), translation (51a) is rejectedin favor of (51b).Having given examples of how post hoc validation works within both NPs andsentences, we summarize in Table 12 the results obtained when we tested the 58 sen-tences whose translations contained subject-verb agreement errors owing to boundaryfriction.
Improvements were seen for translations derived from each of the on-line MTsystems: from a minimum of 58.6% (34 translations) for system A to a maximum of76% (44 translations) for system C. For each system, no improvement was found fortwo translations, and for 10 translations, our methodology could not tell definitivelywhether the word to be corrected was a noun or a verb, so no change was made.Finally, in a small number of cases (between 2 and 12 translations), the target stringwas not found on the Web, so again, no change was made.In order to be as accurate and relevant as possible, statistical language (and trans-lation) models should be derived from corpora that are as large as possible, represen-tative, and of high quality.
Although the Web is large, this post hoc validation processshows that despite the inherent noise contained on the Web because of the heteroge-neous nature of the documents contained therein, it remains a resource that is of greatuse in evaluating translation candidates.6.
Conclusions and Further WorkWe have presented an EBMT system based on the marker hypothesis that uses posthoc validation and correction via the Web.11 Over 218,000 NPs and VPs were extractedautomatically from the Penn-II Treebank using just 59 of its 29,000 rule types.
Thesephrases were then translated automatically by three on-line MT systems.
These trans-lations gave rise to a number of automatically constructed linguistic resources: (1) theoriginal ?source,target?
phrasal translation pairs, (2) the marker lexicon, (3) the gen-11 Thanks are due to one of the anonymous reviewers for pointing out that our wEBMT system, seededwith input from multiple translation systems, with a postvalidation process via the Web (amounting toan n-gram target language model), in effect forms a multiengine MT system as described by Frederkingand Nirenburg (1994), Frederking et al (1994), and Hogan and Frederking (1998).454Computational Linguistics Volume 29, Number 3eralized lexicon, and (4) the word-level lexicon.
When the system is confronted withnew input, these knowledge sources are searched in turn for matching chunks, andthe target language chunks are combined to create translation candidates.We presented a number of experiments that showed how the system fared whenconfronted with NPs and sentences.
For the test set of 500 NPs, we obtained trans-lations in 96% of cases, with 77.8% of the 500 NPs being translated correctly.
Forsentences, we obtained translations in 92% of cases, with a completely correct transla-tion obtained 81.5% of the time.
Translation quality improved both when chunks fromdifferent on-line systems were used and when the system?s memories were seededwith both third-person singular and third-person plural forms.
For both NPs and sen-tences, we obtained intelligible translations in over 96% of cases.
In most cases, the?best?
translation was ranked in the top 10 translations output by the system and wasalways ranked in the top 1% of translation candidates.
This facilitates the task of anytranslator interacting with our system who needs to search for the ?best?
translationamong the alternatives provided.We calculated the net gain of using wEBMT compared to the three on-line MTsystems.
In some cases, an improvement of 50% was seen when EBMT was used.As a consequence of the methodology chosen, we were able to perform a detailedevaluation of the strengths and weaknesses of the three Web-based systems used inour research, with Logomedia clearly outranking the other systems used.
Neverthe-less, adding chunks from the other two on-line MT systems improves both coverageand translation quality.
In sum, therefore, the best results are obtained when chunksfrom all three on-line systems are used, and the system?s databases are seeded withtranslations from these systems for both third-person singular and third-person pluralversions of sentences.In addition, prior to the system?s outputting the best-ranked translation candidate,morphological variants of certain components in the translation are searched for viathe Web in order to confirm it as the final output translation or to propose a correctedalternative.
Currently we validate our translations only with regard to subject headnoun?head verb agreement and determiner-noun agreement, but we plan to extendthis validation to cover more cases of boundary friction.
We demonstrated that con-siderable improvements can be made to the translations derived by the system bysubmitting them to the Web for validation and correction.A number of issues for further work present themselves.
The decision to take onlythose Penn-II rules occurring 1,000 or more times was completely arbitrary, and itmight be useful to include some strings corresponding to the less frequently occurringstructures in our database.
Similarly, it would be a good idea to extend our word-levellexicon by including more entries using rules in which the right-hand side contains asingle non-terminal.Furthermore, the quality of the output was not taken into consideration whenselecting the on-line MT systems from which all our system resources are derived, sothat any results obtained may be further improved by selecting a ?better?
MT systemthat permits batch processing.We could expect a significant improvement in the results obtained if we were to im-port the original sentences and their translations into a sentential database.
Althoughwe insert dummy subject pronouns to derive appropriate finite verb forms, we do notmaintain these translation pairs as a resource for subsequent consultation and retrieval.Although the chance of finding an exact match at sentential level is very low, it willincrease as more sentence pairs are added to the database, especially if we restrict thedomain of applicability of (a version of) our system to a particular sublanguage area.However, the major improvement that can be expected is in the segmentation process:455Way and Gough wEBMTGiven that verbs are not a closed class, any verb will be contained within (part of) achunk pertaining to its subject NP.
That is, although subject-verb agreement poses aconsiderable problem to our system given the choice of original input material, thisparticular instance of boundary friction will disappear if we segment our translationpairs at the sentential rather than at the phrasal level.In addition, we want to evaluate our system further with respect to larger data sets.Manual evaluation is costly, both in terms of time and effort required.
Accordingly,in future work we plan to use automatic evaluation methodologies such as sentenceerror rate or word error rate.
These are very harsh metrics: Consider the example in(54), extracted from the Canadian Hansards:(54) Again this was voted down by the Liberal majority =?Malheureusement, encore une fois, la majorite?
libe?rale l?a rejete?.Automatic evaluation measures presuppose the existence of an ?oracle?
(i.e., ?cor-rect?)
translation produced by a human, such as here.
Translations derived by theMT system to be evaluated are then compared against the human translation.
In theexample in (54), the human has inserted malheureusement although there is no sign ofunfortunately in the English source.
If the perfect translation Encore une fois, la majorite?libe?rale l?a rejete?
were produced by an MT system, therefore, it would be penalized, asthe human translation is always considered to be the ?correct?
translation.
We haveobtained a number of translation memories from two major computer companies, aswell as a large amount of monolingual data from the same domain, with which weplan to test our system using automatic evaluation metrics in future work.
This willalso enable us to test our EBMT methodology against other language pairs, whichmay present the segmentation method employed with new challenges to overcome.Finally, we plan to prioritize the lexical resources produced so that more weight-ing would be given to translations derived from the phrasal and marker lexicons asopposed to those derived via word insertion from the word level lexicon and thegeneralized templates.In sum, we have demonstrated that using a ?linguistics-lite?
approach based onthe marker hypothesis, with a large number of phrases extracted automatically froma very small number of the rules in the Penn Treebank, many new reusable linguisticresources can be derived automatically that can be utilized in an EBMT system capableof translating new input with quite reasonable rates of success.
We have demonstratedthat a net gain may be achieved by using EBMT over on-line MT systems.
We havealso shown that the Web can be used to validate and correct candidate translationsprior to their being output.AcknowledgmentsThe authors wish to thank Mary Hearne forhelpful input in the initial stages of thisproject.
In addition, the insightful commentsprovided by four anonymous reviewershelped improve this article considerably.
Allremaining errors are our own.ReferencesAhrenberg, Lars, Mikael Andersson, andMagnus Merkel.
2002.
A system forincremental and interactive word linking.In Proceedings of the Third InternationalConference on Language Resources andEvaluation (LREC), pages 485?490, LasPalmas, Canary Islands, Spain.Becker, Joseph.
1975.
The phrasal lexicon.
InProceedings of the International Workshop onTheoretical Issues in Natural LanguageProcessing, pages 70?73, Cambridge, MA.Block, Hans-Ulrich.
2000.
Example-basedincremental synchronous interpretation.In Wolfgang Wahlster, editor, Verbmobil:Foundations of Speech-to-Speech Translation,Springer Verlag, Berlin/Heidelberg/New456Computational Linguistics Volume 29, Number 3York, pages 411?417.Bod, Rens, Remko Scha, and Khalil Sima?an,editors.
2003.
Data-Oriented Parsing.
CSLIPublications, Stanford, CA.Boutsis, Sotiris, and Stelios Piperidis.
1998.Aligning clauses in parallel texts.
InProceedings of the Third Conference onEmpirical Methods in Natural LanguageProcessing, pages 17?26, Granada, Spain.Brown, Ralf.
2000.
Automatedgeneralization of translation examples.
InEighteenth International Conference onComputational Linguistics: COLING 2000 inEurope, pages 125?131, Saarbru?cken,Germany.Brown, Ralf.
2003.
Clustered transfer-ruleinduction for example-based translation.In Michael Carl and Andy Way, editors,Recent Advances in Example-Based MachineTranslation.
Kluwer Academic, Dordrecht,the Netherlands, pages 287?305.Carl, Michael.
1999.
Inducing translationtemplates for example-based machinetranslation.
In Machine Translation SummitVII, pages 250?258, Singapore.Carl, Michael, and Andy Way, editors.
2003.Recent Advances in Example-Based MachineTranslation.
Kluwer Academic, Dordrecht,the Netherlands.Carl, Michael, Andy Way, and ReinhardScha?ler.
2002.
Toward a hybrid integratedtranslation environment.
In StephenRichardson, editor, Machine Translation:From Research to Real Users: Fifth Conferenceof the Association for Machine Translation inthe Americas (AMTA-2002).
Lecture Notesin Artificial Intelligence 2499.
SpringerVerlag, Berlin/Heidelberg, pages 11?20.Cicekli, Ilyas, and Altay Gu?venir.
1996.Learning translation rules from abilingual corpus.
In Proceedings of theSecond International Conference on NewMethods in Language Processing, pages90?97, Ankara, Turkey.Frederking, Robert, and Sergei Nirenburg.1994.
Three heads are better than one.
InProceedings of the Fourth Conference onApplied Natural Language Processing(ANLP-94), pages 95?100, Stuttgart,Germany.Frederking, Robert, Sergei Nirenburg, DavidFarwell, Steven Helmreich, Eduard Hovy,Kevin Knight, Stephen Beale, ConstantinDomashnev, Donna Attardo, DeanGrannes, and Ralf Brown.
1994.Integrating translations from multiplesources with the Pangloss Mark IIImachine translation system.
In Proceedingsof the First Conference of the Association forMachine Translation in the Americas, pages73?80, Columbia, MD.Fung, Pascale, and Kathleen McKeown.1997.
Finding terminology translationsfrom non-parallel corpora.
In Proceedingsof the Fifth Annual Workshop on Very LargeCorpora, pages 192?202, Hong Kong.Gough, Nano, Andy Way, and MaryHearne.
2002.
Example-based machinetranslation via the Web.
In StephenRichardson, editor, Machine Translation:From Research to Real Users: Fifth Conferenceof the Association for Machine Translation inthe Americas (AMTA-2002) Lecture Notesin Artificial Intelligence 2499.
SpringerVerlag, Berlin/Heidelberg, pages 74?83.Green, Thomas.
1979.
The necessity ofsyntax markers: Two experiments withartificial languages.
Journal of VerbalLearning and Behavior, 18:481?496.Grefenstette, Gregory.
1999.
The World WideWeb as a resource for example-basedmachine translation tasks.
In Proceedings ofthe ASLIB Conference on Translating and theComputer, volume 21, London.Hogan, Christopher, and Robert E.Frederking.
1998.
An evaluation of themulti-engine MT architecture.
In MachineTranslation and the Information Soup:Proceedings of the Third Conference of theAssociation for Machine Translation in theAmericas (AMTA ?98), Lecture Notes inArtificial Intelligence 1529.
SpringerVerlag, Berlin/Heidelberg, pages 113?123.Hovy, Edward.
1988.
Generating languagewith a phrasal lexicon.
In DavidMcDonald and Leonard Bolc, editors,Natural Language Generation Systems.Springer Verlag, New York, pages353?384.Juola, Patrick.
1994.
A psycholinguisticapproach to corpus-based machinetranslation.
In CSNLP 1994: ThirdInternational Conference on the CognitiveScience of Natural Language Processing,Dublin.Juola, Patrick.
1997.
Corpus-basedacquisition of transfer functions usingpsycholinguistic principles.
In DanielJones and Harold Somers, editors, NewMethods in Language Processing.
UCL Press,London, pages 207?218.Juola, Patrick.
1998.
On psycholinguisticgrammars.
Grammars, 1(1):15?31.Kaji, Hiroyuki, Takuya Kida, and YujiMorimoto.
1992.
Learning translationtemplates from bilingual text.
InProceedings of the 15th [sic] InternationalConference on Computational Linguistics(COLING), pages 672?678, Nantes,France.Kay, Martin, and Martin Ro?scheisen.
1993.Text-translation alignment.
Computational457Way and Gough wEBMTLinguistics, 19(1):121?142.Littlestone, Nick, and Manfred Warmuth.1992.
The weighted majority algorithm.Technical Report UCSC-CRL-91-28,University of California, Santa Cruz.Macklovitch, Elliott.
2000.
Two types oftranslation memory.
In Proceedings of theASLIB Conference on Translating and theComputer, volume 22, London.Macklovitch, Elliott, and Graham Russell.2000.
What?s been forgotten in translationmemory.
In Envisioning Machine Translationin the Information Future: Proceedings ofFourth Conference of the Association forMachine Translation in the Americas(AMTA-2000), pages 137?146, Cuernavaca,Mexico.McTait, Kevin, and Arturo Trujillo.
1999.
Alanguage-neutral sparse-data algorithmfor extracting translation patterns.
InProceedings of the Eighth InternationalConference on Theoretical and MethodologicalIssues in Machine Translation, pages 98?108,Chester, England.Milosavljevic, Maria, Adrian Tulloch, andRobert Dale.
1996.
Text generation in adynamic hypertext environment.
InProceedings of the 19th AustralasianComputer Science Conference, pages417?426, Melbourne, Australia.Morgan, James, Richard Meier, and ElissaNewport.
1989.
Facilitating the acquisitionof syntax with cross-sentential cues tophrase structure.
Journal of Memory andLanguage, 28:360?374.Mori, Kazuo, and Shannon Moeser.
1983.The role of syntax markers and semanticreferents in learning an artificiallanguage.
Journal of Verbal Learning andVerbal Behavior, 22:701?718.Nagao, Makoto.
1984.
A framework of amechanical translation between Japaneseand English by analogy principle.
InAlick Elithorn and Ranan Banerji, editors,Artificial and Human Intelligence.North-Holland, Amsterdam, pages173?180.Rayner, Manny, and David Carter.
1997.Hybrid language processing in thespoken language translator.
In Proceedingsof the IEEE International Conference onAcoustics, Speech and Signal Processing,pages 107?110, Munich.Sato, Satoshi, and Makoto Nagao.
1990.Toward memory-based translation.
InCOLING-90: Papers Presented to the 13thInternational Conference on ComputationalLinguistics, pages 247?252, Helsinki.Scha?ler, Reinhard.
1996.
Machine translation,translation memories and the phrasallexicon: The localisation perspective.
InProceedings of TKE-96: EAMT Workshop onMachine Translation, pages 21?33, Vienna.Scha?ler, Reinhard, Andy Way, and MichaelCarl.
2003.
Example-based machinetranslation in a controlled environment.In Michael Carl and Andy Way, editors,Recent Advances in Example-Based MachineTranslation, Kluwer Academic, Dordrecht,the Netherlands, pages 83?114.Simard, Michel, and Philippe Langlais.
2001.Subsentential exploitation of translationmemories.
In Machine Translation SummitVIII, pages 335?339, Santiago deCompostela, Spain.Somers, Harold.
1998.
Further experimentsin bilingual text alignment.
InternationalJournal of Corpus Linguistics, 3:115?150.Somers, Harold, Ian McLean, and DanielJones.
1994.
Experiments in multilingualexample-based generation.
In CSNLP1994: Third International Conference on theCognitive Science of Natural LanguageProcessing, Dublin.Veale, Tony, and Andy Way.
1997.
Gaijin: Abootstrapping, template-driven approachto example-based machine translation.
InInternational Conference, Recent Advances inNatural Language Processing, pages239?244, Tzigov Chark, Bulgaria.Watanabe, Hideo.
1993.
A method forextracting translation patterns fromtranslation examples.
In Proceedings of theFifth International Conference on Theoreticaland Methodological Issues in MachineTranslation (TMI ?93): MT in the NextGeneration, pages 292?301, Kyoto, Japan.Zernik, Uri, and Michael Dyer.
1987.
Theself-extending phrasal lexicon.
Com-putational Linguistics, 13(3?4):308?327.
