Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 205?208,Columbus, Ohio, USA, June 2008. c?2008 Association for Computational LinguisticsFastSum:Fast and accurate query-based multi-document summarizationFrank Schilder and Ravikumar KondadadiResearch & DevelopmentThomson Corp.610 Opperman Drive, Eagan, MN 55123, USAFirstName.LastName@Thomson.comAbstractWe present a fast query-based multi-documentsummarizer called FastSum based solely onword-frequency features of clusters, docu-ments and topics.
Summary sentences areranked by a regression SVM.
The summa-rizer does not use any expensive NLP tech-niques such as parsing, tagging of names oreven part of speech information.
Still, theachieved accuracy is comparable to the bestsystems presented in recent academic com-petitions (i.e., Document Understanding Con-ference (DUC)).
Because of a detailed fea-ture analysis using Least Angle Regression(LARS), FastSum can rely on a minimal set offeatures leading to fast processing times: 1250news documents in 60 seconds.1 IntroductionIn this paper, we propose a simple method for effec-tively generating query-based multi-document sum-maries without any complex processing steps.
Itonly involves sentence splitting, filtering candidatesentences and computing the word frequencies inthe documents of a cluster, topic description and thetopic title.
We use a machine learning techniquecalled regression SVM, as proposed by (Li et al,2007).
For the feature selection we use a new modelselection technique called Least Angle Regression(LARS) (Efron et al, 2004).Even though machine learning approaches dom-inated the field of summarization systems in recentDUC competitions, not much effort has been spentin finding simple but effective features.
Exceptionsare the SumBasic system that achieves reasonableresults with only one feature (i.e., word frequencyin document clusters) (Nenkova and Vanderwende,2005).
Our approach goes beyond SumBasic byproposing an even more powerful feature that provesto be the best predictor in all three recent DUC cor-pora.
In order to prove that our feature is more pre-dictive than other features we provide a rigorous fea-ture analysis by employing LARS.Scalability is normally not considered when dif-ferent summarization systems are compared.
Pro-cessing time of more than several seconds per sum-mary should be considered unacceptable, in partic-ular, if you bear in mind that using such a systemshould help a user to process lots of data faster.
Ourfocus is on selecting the minimal set of features thatare computationally less expensive than other fea-tures (i.e., full parse).
Since FastSum can rely ona minimal set of features determined by LARS, itcan process 1250 news documents in 60 seconds.1A comparison test with the MEAD system2 showedthat FastSum is more than 4 times faster.2 System descriptionWe use a machine learning approach to rank all sen-tences in the topic cluster for summarizability.
Weuse some features from Microsoft?s PYTHY system(Toutonova et al, 2007), but added two new fea-tures, which turned out to be better predictors.First, the pre-processing module carries out tok-enization and sentence splitting.
We also createda sentence simplification component which is based14-way/2.0GHz PIII Xeon 4096Mb Memory2http://www.summarization.com/mead/205on a few regular expressions to remove unimportantcomponents of a sentence (e.g., As a matter of fact,).This processing step does not involve any syntac-tic parsing though.
For further processing, we ig-nore all sentences that do not have at least two exactword matches or at least three fuzzy matches withthe topic description.3Features are mainly based on word frequencies ofwords in the clusters, documents and topics.
A clus-ter contains 25 documents and is associated with atopic.
The topic contains a topic title and the topicdescriptions.
The topic title is list of key words orphrases describing the topic.
The topic descriptioncontains the actual query or queries (e.g., Describesteps taken and worldwide reaction prior to intro-duction of the Euro on January 1, 1999.
).The features we used can be divided into two sets;word-based and sentence-based.
Word-based fea-tures are computed based on the probability of wordsfor the different containers (i.e., cluster, document,topic title and description).
At runtime, the differentprobabilities of all words in a candidate sentence areadded up and normalized by length.
Sentence-basedfeatures include the length and position of the sen-tence in the document.
The starred features 1 and4 are introduced by us, whereas the others can befound in earlier literature.4*1 Topic title frequency (1): ratio of number ofwords ti in the sentence s that also appear inthe topic title T to the total number of wordst1..|s| in the sentence s:?|s|i=1fT (ti)|s| , wherefT ={1 : ti ?
T0 : otherwise2 Topic description frequency (2): ratio of numberof words ti in the sentence s that also appearin the topic description D to the total numberof words t1..|s| in the sentence s:?|s|i=1fD(ti)|s| ,where fD ={1 : ti ?
D0 : otherwise3 Content word frequency(3): the average contentword probability pc(ti) of all content words3Fuzzy matches are defined by the OVERLAP similarity(Bollegala et al, 2007) of at least 0.1.4The numbers are used in the feature analysis, as in figure 2.t1..|s| in a sentence s. The content word proba-bility is defined as pc(ti) = nN , where n is thenumber of times the word occurred in the clus-ter and N is the total number of words in thecluster:?|s|i=1pc(ti)|s|*4 Document frequency (4): the average documentprobability pd(ti) of all content words t1..|s| ina sentence s. The document probability is de-fined as pd(ti) = dD , where d is the number ofdocuments the word ti occurred in for a givencluster and D is the total number of documentsin the cluster:?|s|i=1pd(ti)|s|The remaining features are Headline frequency (5),Sentence length (6), Sentence position (binary) (7),and Sentence position (real) (8)Eventually, each sentence is associated with ascore which is a linear combination of the abovementioned feature values.
We ignore all sentencesthat do not have at least two exact word matches.5In order to learn the feature weights, we trained aSVM on the previous year?s data using the same fea-ture set.
We used a regression SVM.
In regression,the task is to estimate the functional dependence ofa dependent variable on a set of independent vari-ables.
In our case, the goal is to estimate the scoreof a sentence based on the given feature set.
In orderto get training data, we computed the word overlapbetween the sentences from the document clustersand the sentences in DUC model summaries.
Weassociated the word overlap score to the correspond-ing sentence to generate the regression data.
As alast step, we use the pivoted QR decomposition tohandle redundancy.
The basic idea is to avoid redun-dancy by changing the relative importance of the restof the sentences based on the currently selected sen-tence.
The final summary is created from the rankedsentence list after the redundancy removal step.3 ResultsWe compared our system with the top performingsystems in the last two DUC competitions.
With ourbest performing features, we get ROUGE-2 (Lin,2004) scores of 0.11 and 0.0925 on 2007 and 20065This threshold was derived experimentally with previousdata.206IIIT MS LIP6 IDA Peking FastSum Catalonia gen. BaselineFastSum, 6 Top Systems and generic baseline for DUC 2007ROUGE?20.000.020.040.060.080.100.120.14Figure 1: ROUGE-2 results including 95%-confidenceintervals for the top 6 systems, FastSum and the genericbaseline for DUC 2007DUC data, respectively.
These scores correspondto rank 6th for DUC 2007 and the 2nd rank forDUC 2006.
Figure 1 shows a graphical compari-son of our system with the top 6 systems in DUC2007.
According to an ANOVA test carried out bythe DUC organizers, these 6 systems are significantbetter than the remaining 26 participating systems.Note that our system is better than the PYTHYsystem for 2006, if no sentence simplification wascarried out (DUC 2006: 0.089 (without simplifica-tion); 0.096 (with simplification)).
Sentence simpli-fication is a computationally expensive process, be-cause it requires a syntactic parse.We evaluated the performance of the FastSum al-gorithm using each of the features separately.
Ta-ble 1 shows the ROUGE score (recall) of the sum-maries generated when we used each of the featuresby themselves on 2006 and 2007 DUC data, trainedon the data from the respective previous year.
Usingonly the Document frequency feature by itself leadsto the second best system for DUC 2006 and to thetenth best system for DUC 2007.This first simple analysis of features indicates thata more rigorous feature analysis would have bene-fits for building simpler models.
In addition, featureselection could be guided by the complexity of thefeatures preferring those features that are computa-tionally inexpensive.Feature name 2007 2006Title word frequency 0.096 0.0771Topic word frequency 0.0996 0.0883Content word frequency 0.1046 0.0839Document frequency 0.1061 0.0903Headline frequency 0.0938 0.0737Sentence length 0.054 0.0438Sentence position(binary) 0.0522 0.0484Sentence position (real-valued) 0.0544 0.0458Table 1: ROUGE-2 scores of individual featuresWe chose a so-called model selection algorithmto find a minimal set of features.
This problem canbe formulated as a shrinkage and selection methodfor linear regression.
The Least Angle Regres-sion (LARS) (Efron et al, 2004) algorithm can beused for computing the least absolute shrinkage andselection operator (LASSO) (Tibshirani, 1996).Ateach stage in LARS, the feature that is most corre-lated with the response is added to the model.
Thecoefficient of the feature is set in the direction of thesign of the feature?s correlation with the response.We computed LARS on the DUC data sets fromthe last three years.
The graphical results for 2007are shown in figure 2.
In a LARS graph, featuresare plotted on the x-axis and the corresponding co-efficients are shown on y-axis.
The value on the x-axis is the ratio of norm of the coefficent vector tothe maximal norm with no constraint.
The earlier afeature appears on the x-axis, the better it is.
Table2 summarizes the best four features we determinedwith LARS for the three available DUC data sets.Year Top Features2005 4 2 5 12006 4 3 2 12007 4 3 5 2Table 2: The 4 top features for the DUC 2005, 2006 and2007 dataTable 2 shows that feature 4, document frequency,is consistently the most important feature for allthree data sets.
Content word frequency (3), on theother hand, comes in as second best feature for 2006and 2007, but not for 2005.
For the 2005 data, theTopic description frequency is the second best fea-ture.
This observation is reflected by our single fea-207* * * * * * * * * ** *0.0 0.2 0.4 0.6 0.8 1.0024682007|beta|/max|beta|Standardized Coefficients* ** * * * ** ** * * * * * * ** *** ** * * * * ** ** ** * ** **** ** * * * ** ** * ** ** * ** *LASSO108234Figure 2: Graphical output of LARS analysis:Top features for 2007: 4 Document frequency, 3 Content wordfrequency, 5 Headline frequency, 2 Topic description frequencyture analysis for DUC 2006, as shown in table 1.Similarly, Vanderwende et al (2006) report that theygave the Topic description frequency a much higherweight than the Content word frequency.Consequently, we have shown that our new fea-ture Document frequency is consistently the bestfeature for all three past DUC corpora.4 ConclusionsWe proposed a fast query-based multi-documentsummarizer called FastSum that produces state-of-the-art summaries using a small set of predictors,two of those are proposed by us: document fre-quency and topic title frequency.
A feature anal-ysis using least angle regression (LARS) indicatedthat the document frequency feature is the most use-ful feature consistently for the last three DUC datasets.
Using document frequency alone can producecompetitive results for DUC 2006 and DUC 2007.The two most useful feature that takes the topic de-scription (i.e., the queries) into account is based onthe number of words in the topic description and thetopic title.
Using a limited feature set of the 5 bestfeatures generates summaries that are comparable tothe top systems of the DUC 2006 and 2007main taskand can be generated in real-time, since no compu-tationally expensive features (e.g., parsing) are used.From these findings, we draw the following con-clusions.
Since a feature set mainly based on wordfrequencies can produce state-of-the-art summaries,we need to analyze further the current set-up for thequery-based multi-document summarization task.
Inparticular, we need to ask the question whether theselection of relevant documents for the DUC top-ics is in any way biased.
For DUC, the documentclusters for a topic containing relevant documentswere always pre-selected by the assessors in prepa-ration for DUC.
Our analysis suggests that simpleword frequency computations of these clusters andthe documents alone can produce reasonable sum-maries.
However, the human selecting the relevantdocuments may have already influenced the waysummaries can automatically be generated.
Our sys-tem and systems such as SumBasic or SumFocusmay just exploit the fact that relevant articles pre-screened by humans contain a high density of goodcontent words for summarization.6ReferencesD.
Bollegala, Y. Matsuo, and M. Ishizuka.
2007.
Mea-suring Semantic Similarity between Words Using WebSearch Engines.
In Proc.
of 16th International WorldWide Web Conference (WWW 2007), pages 757?766,Banff, Canada.B.
Efron, T. Hastie, I.M.
Johnstone, and R. Tibshirani.2004.
Least angle regression.
Annals of Statistics,32(2):407?499.S.
Gupta, A. Nenkova, and D. Jurafsky.
2007.
Measur-ing Importance and Query Relevance in Topic-focusedMulti-document Summarization.
In Proc.
of the 45thAnnual Meeting of the Association for ComputationalLinguistics, pages 193?196, Prague, Czech Republic.S.
Li, Y. Ouyang, W. Wang, and B.
Sun.
2007.
Multi-document summarization using support vector regres-sion.
In Proceedings of DUC 2007, Rochester, USA.C.
Lin.
2004.
Rouge: a package for automatic evaluationof summaries.
In Proceedings of the Workshop on TextSummarization Branches Out (WAS 2004).A.
Nenkova and L. Vanderwende.
2005.
The impact offrequency on summarization.
In MSR-TR-2005-101.R.
Tibshirani.
1996.
Regression shrinkage and selectionvia the lasso.
J. Royal.
Statist.
Soc B., 58(1):267?288.K.
Toutonova, C. Brockett, J. Jagarlamudi, H. Suzuko,and L. Vanderwende.
2007.
The PYTHY Summa-rization System: Microsoft Research at DUC2007.
InProc.
of DUC 2007, Rochester, USA.L.
Vanderwende, H. Suzuki, and C. Brockett.
2006.
Mi-crosoft Research at DUC 2006: Task-focused summa-rization with sentence simplification and lexical ex-pansion.
In Proc.
of DUC 2006, New York, USA.6Cf.
Gupta et al (2007) who come to a similar conclusionby comparing between word frequency and log-likelihood ratio.208
