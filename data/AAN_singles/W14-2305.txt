Proceedings of the Second Workshop on Metaphor in NLP, pages 33?41,Baltimore, MD, USA, 26 June 2014.c?2014 Association for Computational LinguisticsAbductive Inference for Interpretation of MetaphorsEkaterina Ovchinnikova*, Ross Israel*, Suzanne Wertheim+,Vladimir Zaytsev*, Niloofar Montazeri*, Jerry Hobbs** USC ISI, 4676 Admiralty Way, CA 90292, USA{katya,israel,vzaytsev,niloofar,hobbs}@isi.edu+Worthwhile Research & Consulting, 430 1/2 N Genesee Av., Los Angeles, CA 90036, USAworthwhileresearch@gmail.comAbstractThis paper presents a metaphor interpre-tation pipeline based on abductive infer-ence.
In this framework following (Hobbs,1992) metaphor interpretation is modelledas a part of the general discourse pro-cessing problem, such that the overall dis-course coherence is supported.
We presentan experimental evaluation of the pro-posed approach using linguistic data inEnglish and Russian.1 IntroductionIn this paper, we elaborate on a semantic pro-cessing framework based on a mode of inferencecalled abduction, or inference to the best expla-nation.
In logic, abduction is a kind of inferencewhich arrives at an explanatory hypothesis givenan observation.
(Hobbs et al., 1993) describe howabduction can be applied to the discourse process-ing problem, viewing the process of interpretingsentences in discourse as the process of providingthe best explanation of why the sentence would betrue.
(Hobbs et al., 1993) show that abductive rea-soning as a discourse processing technique helpsto solve many pragmatic problems such as refer-ence resolution, the interpretation of noun com-pounds, detection of discourse relations, etc.
as aby-product.
(Hobbs, 1992) explains how abduc-tion can be applied to interpretation of metaphors.The term conceptual metaphor (CM) refersto the understanding of one concept or concep-tual domain in terms of the properties of another(Lakoff and Johnson, 1980; Lakoff, 1987).
For ex-ample, development can be understood as move-ment (e.g., the economy moves forward, the en-gine of the economy).
In other words, a concep-tual metaphor consists in mapping a target con-ceptual domain (e.g., economy) to a source do-main (e.g., vehicle) by comparing their properties(e.g., an economy develops like a vehicle moves).In text, conceptual metaphors are represented bylinguistic metaphors (LMs), i.e.
natural languagephrases expressing the implied comparison of twodomains.We present a metaphor interpretation approachbased on abduction.
We developed an end-to-end metaphor interpretation system that takes textpotentially containing linguistic metaphors as in-put, detects linguistic metaphors, maps them toconceptual metaphors, and interprets conceptualmetaphors in terms of both logical predicates andnatural language expressions.
Currently, the sys-tem can process linguistic metaphors mappingpredefined target and source domains.We perform an experimental evaluationof the proposed approach using linguisticdata in two languages: English and Rus-sian.
We select target concepts and generatepotential sources for them as described atgithub.com/MetaphorExtractionTools/mokujin.For top-ranked sources, we automatically find cor-responding linguistic metaphors.
These linguisticmetaphors are each then validated by three expertlinguists.
For the validated linguistic metaphors,we generate natural language interpretations,which are also validated by three experts.2 Related WorkAutomatic interpretation of linguistic metaphors isperformed using two principal approaches: 1) de-riving literal paraphrases for metaphorical expres-sions from corpora (Shutova, 2010; Shutova etal., 2012) and 2) reasoning with manually codedknowledge (Hobbs, 1992; Narayanan, 1999; Barn-den and Lee, 2002; Agerri et al., 2007; Veale andHao, 2008).
(Shutova, 2010; Shutova et al., 2012) presentmethods for deriving paraphrases for linguis-tic metaphors from corpora.
For example, themetaphorical expression "a carelessly leaked re-33port" is paraphrased as "a carelessly disclosed re-port".
This approach currently focuses on single-word metaphors expressed by verbs only and doesnot explain the target?source mapping.The KARMA (Narayanan, 1999) and the ATT-Meta (Barnden and Lee, 2002; Agerri et al., 2007)systems perform reasoning with manually codedworld knowledge and operate mainly in the sourcedomain.
The ATT-Meta system takes logical ex-pressions that are representations of a small dis-course fragment as input; i.e., it does not workwith natural language.
KARMA focuses on dy-namics and motion in space.
For example, themetaphorical expression the government is stum-bling in its efforts is interpreted in terms of motionin space: stumbling leads to falling, while fallingis a conventional metaphor for failing.
(Veale and Hao, 2008) suggest to derivecommon-sense knowledge from WordNet and cor-pora in order to obtain concept properties that canbe used for metaphor interpretation.
Simple in-ference operations, i.e.
insertions, deletions andsubstitution, allow the system to establish links be-tween target and source concepts.
(Hobbs, 1992) understands metaphor interpre-tation as a part of the general discourse processingproblem.
According to Hobbs, a metaphorical ex-pression should be interpreted in context.
For ex-ample, John is an elephant can be best interpretedas "John is clumsy" in the context Mary is grace-ful, but John is an elephant.
In order to obtaincontext-dependent interpretations, (Hobbs, 1992)uses abductive inference linking parts of the dis-course and ensuring discourse coherence.3 Metaphor Interpretation SystemOur abduction-based metaphor interpretation sys-tem is shown in Fig.
1.
Text fragments possiblycontaining linguistic metaphors are given as in-put to the pipeline.
The text fragments are parsedand converted into logical forms (section 3.1).The logical forms are input to the abductive rea-soner (section 3.2) that is informed by a knowl-edge base (section 4).
The processing componentlabelled "CM extractor & scorer" extracts con-ceptual metaphors from the logical abductive in-terpretations and outputs scored CMs and Target-Source mappings (section 3.3).
The Target-Sourcemappings are then translated into natural languageexpressions by the NL generator module (sec-tion 3.4).3.1 Logical Form GenerationA logical form (LF) is a conjunction of propo-sitions which have argument links showing rela-tionships among phrase constituents.
We use logi-cal representations of natural language texts as de-scribed in (Hobbs, 1985).
In order to obtain LFswe convert dependency parses into logical repre-sentations in two steps: 1) assign arguments toeach lemma, 2) apply rules to dependencies in or-der to link arguments.Consider the dependency structure for the sen-tence, John decided to leave: [PRED decide[SUBJ John] [OBJ leave]].
First, wegenerate unlinked predicates for this structure:John(e1, x1)?decide(e2, x2, x3)?leave(e3, x4).Then, based on the dependency labels, we linkargument x1with x2, x3with e3, and x1withx4to obtain the following LF: John(e1, x1) ?decide(e2, x1, e3) ?
leave(e3, x1).LFs are preferable to dependency structures inthis case because they generalize over syntax andlink arguments using long-distance dependencies.Furthermore, we need logical representations inorder to apply abductive inference.In order to produce logical forms for English,we use the Boxer semantic parser (Bos et al.,2004).
As one of the possible formats, Boxeroutputs logical forms of sentences in the style of(Hobbs, 1985).
For Russian, we use the Malt de-pendency parser (Nivre et al., 2006).
We devel-oped a converter turning Malt dependencies intological forms in the style of (Hobbs, 1985).13.2 Abductive InferenceIn order to detect conceptual metaphors and in-fer explicit mappings between target and sourcedomains, we employ a mode of inference calledweighted abduction (Hobbs et al., 1993).
Thisframework is appealing because it is a realizationof the observation that we understand new mate-rial by linking it with what we already know.Abduction is inference to the best explanation.Formally, logical abduction is defined as follows:Given: Background knowledge B, observationsO, where both B and O are sets of first-order log-ical formulas,Find: A hypothesis H such that H ?B |= O,H ?B 6|=?, where H is a set of first-order logical for-mulas.1The converter is freely available athttps://github.com/eovchinn/Metaphor-ADP.34Figure 1: Abduction-based metaphor interpretation system.Typically, there exist several hypotheses H ex-plaining O.
To rank hypotheses according to plau-sibility and select the best hypothesis, we usethe framework of weighted abduction (Hobbs etal., 1993).
Frequently, the best interpretation re-sults from identifying two entities with each other,so that their common properties only need to beproved or assumed once.
Weighted abduction fa-vors those interpretations that link parts of obser-vations together and supports discourse coherence,which is crucial for discourse interpretation.According to (Hobbs, 1985), metaphor interpre-tation can be modelled as abductive inference re-vealing conceptual overlap between the target andthe source domain.
Consider the abductive inter-pretation produced for the sentence We intend tocure poverty, Fig.
2.
In the top line of the figure,we have the LF (cf.
Sec.
3.1), where we can seethat a person (x1) is the agent for the verbs intend(e1) and cure (e2) and that poverty (x2) is the ob-ject of cure.
In the first box in the next row, wesee that cure invokes the source concepts of DIS-EASE, CURE, and DOCTOR, where DISEASE isthe object of CURE, and DOCTOR is the subject.In the same row, we see that poverty invokes thePOVERTY concept in the target domain.
Impor-tantly, POVERTY and DISEASE share the sameargument (x2), which refers to poverty.The next row contains two boxes with ellipses,representing long chains of common-sense infer-ences in the source and target domains of DIS-EASE and POVERTY, respectively.
For DIS-EASE we know that linguistic tokens such as ill-ness, sick, disease, etc.
cause the afflicted to expe-rience loss of health, loss of energy, and a generallack of productivity.
For POVERTY, we know thattokens such as poor, broke, poverty mean that theexperiencer of poverty lacks money to buy things,take care of basic needs, or have access to trans-portation.
The end result of both of these frame-works is that the affected individuals (or commu-nities) cannot function at a normal level, with re-spect to unaffected peers.
We can use this commonmeaning of causing the individual to not functionto link the target to the source.The next three rows provide the mappingfrom the meaning of the source (CURE, DOC-TOR, DISEASE) concepts to the target concept(POVERTY).
As explained above, we can con-sider DISEASE as a CAUSING-AGENT that canCAUSE NOT FUNCTION; POVERTY can be ex-plained the same way, at a certain level of abstrac-tion.
Essentially, the interpretation of poverty inthis sentence is that it causes some entity not tofunction, which is what a DISEASE does as well.For CURE, we see that cure can CAUSE NOT EX-IST, while looking for a CAUSING-AGENT (per-son) and an EXISTING DISEASE (poverty).In our system, we use the implementation ofweighted abduction based on Integer Linear Pro-gramming (ILP) (Inoue and Inui, 2012), whichmakes the inference scalable.3.3 CM Extractor and ScorerThe abductive reasoning system produces an inter-pretation that contains mappings of lexical itemsinto Target and Source domains.
Any Target-Source pair detected in a text fragment constitutesa potential CM.
For some text fragments, the sys-tem identifies multiple CMs.
We score Target-Source pairs according to the length of the depen-dency path linking them in the predicate-argumentstructure.
Consider the following text fragment:opponents argue that any state attempting to forcean out-of-state business to do its dirty work of taxcollection violates another state?s right to regulateits own corporate residents and their commerce35Figure 2: Abductive interpretation for the sentence We intend to cure poverty.Suppose our target domain is TAXATION, trig-gered by tax collection in the sentence above.
Inour corpus, we find realizations of the CM TAXA-TION is an ENEMY (fight against taxes).
The lex-eme opponent triggers the STRUGGLE/ENEMYdomain.
However, the sentence does not triggerthe CM TAXATION is an ENEMY.
Instead, it in-stantiates the CM TAXATION is DIRT (dirty workof tax collection).
The length of the dependencypath between dirty and tax is equal to 2, whereasthe path between opponent and tax is equal to9.
Therefore, our procedure ranks TAXATION isDIRT higher, which corresponds to the intuitionthat target and source words should constitute asyntactic phrase in order to trigger a CM.3.4 NL Representation of MetaphorInterpretationThe output of the abduction engine is similar tothe logical forms provided in Fig.
2.
In order tomake the output more reader friendly, we producea natural language representation of the metaphorinterpretation using templates for each CM.
Forexample, the text their rivers of money mean theycan offer far more than a single vote would invokethe WEALTH is WATER CM, and the abductionengine would output: LARGE-AMOUNT[river],THING-LARGE-AMOUNT[money].
We thentake this information and use it as input for theNL generation module to produce: "river" impliesthat there is a large amount of "money".4 Knowledge BaseIn order to process metaphors with abduction, weneed a knowledge base that encodes the informa-tion about the source domain, the target domain,and the relationships between sources and targets.We develop two distinct sets of axioms: lexical ax-ioms that encode lexical items triggering domains,and mapping axioms that encode knowledge usedto link source and target domains.
We will discussthe details of each axiom type next.4.1 Lexical AxiomsEvery content word or phrase that can be expectedto trigger a source or target domain is included as alexical axiom in the knowledge base.
For example,the STRUGGLE domain contains words like war,fight, combat, conquer, weapon, etc.
An exampleof how a lexical axiom encodes the system logic isgiven in (1).
On the left side, we have the linguistictoken, fight, along with its part-of-speech, vb, andthe argument structure for verbs where e0is theeventuality (see (Hobbs, 1985)) of the action offighting, x is the subject of the verb, and y is theobject.
On the right side, STRUGGLE is linked tothe action of fighting, the subject is marked as theAGENT, and the object is marked as the ENEMY.
(1) fight-vb(e0, x, y) ?
STRUGGLE(e0)?AGENT (x, e0) ?
ENEMY (y, e0)The lexicon is not limited to single-token en-tries; phrases can be included as single entries; Forexample, the ABYSS domain has phrases such asclimb out of as a single entry.
Encoding phrasesoften proves useful, as function words can oftenhelp to distinguish one domain from others.
Inthis case, climbing out of something usually de-notes an abyss, whereas climbing up or on usuallydoes not.
The lexical axioms also include the POS36for each word.
Thus a word like fight can be en-tered as both a noun and a verb.
In cases where asingle lexical axiom could be applied to multipledomains, one can create multiple entries for theaxiom with different domains and assign weightsso that a certain domain is preferred over others.Initial lexical axioms for each domain were de-veloped based on intuition about each domain.We then utilize ConceptNet (Havasi et al., 2007)as a source for semi-automatically extracting alarge-scale lexicon.
ConceptNet is a multilingualsemantic network that establishes links betweenwords and phrases.
We query ConceptNet forour initial lexical axioms to return a list of relatedwords and expressions.4.2 Mapping AxiomsMapping axioms provide the underlying meaningsfor metaphors and link source and target domains.All of these axioms are written by hand basedon common-sense world knowledge about eachtarget-source pair.
For each CM, we consider aset of LMs that are realizations of this CM in aneffort to capture inferences that are common forall of the LMs.
We consider the linguistic contextsof the LMs and overlapping properties of the tar-get and source domains derived from corpora asdescribed in section 5.1.We will outline the process of axiomatizing theSTRUGGLE domain here.
We know that a verblike fight includes concepts for the struggle it-self, an agent, and an enemy.
In the context ofa STRUGGLE, an enemy can be viewed as someentity a that attempts to, or actually does, inhibitthe functioning of some entity b, often through ac-tual physical means, but also psychologically, eco-nomically, etc.
The struggle, or fight, itself then,is an attempt by a to rid itself of b so that a can en-sure normal functionality.
So, given a phrase likepoverty is our enemy, the intended meaning is thatpoverty is hindering the functionality of some en-tity (an individual, a community, a country, etc.
)and is seen as a problem that must be fought,i.e.
eliminated.
In a phrase like the war againstpoverty, war refers to an effort to stop the exis-tence of poverty.
These inferences are supportedby the overlapping property propositions extractedfrom English Gigaword as described in Sec.
5.1,e.g., scourge of X, country fights X, country pullsof X, suffer from X, fight against X.To extend the example in (1), consider (2).Here, we encode a STRUGGLE action, e.g.
fight,as CAUSE NOT EXIST, the AGENT of thefight as CAUSING-AGENT, and the ENEMY asEXISTING-THING.
Then, for a verb phrase likewe fight poverty, we is the AGENT that engages incausing poverty, the ENEMY, to not exist.
(2) STRUGGLE(e0) ?
AGENT (x, e0) ?ENEMY (y, 20)?CAUSE(e0)?CAUSED(n, e0)?NOT (n, ex) ?
EXIST (ex) ?
CAUSING ?AGENT (x, e0) ?
EXISTING?
THING(y, ex)We use 75 mapping axioms to cover the validLMs discussed in Sec.
5.2.
Some interestingtrends emerge when examining the core meaningsof the LMs.
Following (Hobbs, 2005), we foundthat over 65% of the valid LMs in this study couldbe explained in terms of causality.
The next mostprevalent aspect that these metaphors touch uponis that of functionality (nearly 35%), with some ofthese overlapping with the causality aspect wherethe meaning has to do with X causing Y to functionor not function.Many of the CMs covered in this study havefairly transparent interpretations based on theseideas of causality and functionality, such asPOVERTY is DISEASE, where the main under-lying meaning is that a disease causes the suf-ferer not to function properly.
However, for someCMs, the interpretation can be more difficult topin down.
For example, the interpretation ofWEALTH is a GAME is quite opaque.
Given asentence such as, Wealth is a game and you betterstart playing the game, there are no obvious con-nections to concepts such as causality or function-ality.
Instead, game raises such ideas as competi-tion, winning, and losing.
In the literal context of agame, the competition itself, who the competitorsare, and what it means to win or lose are usuallyclearly defined, but this is not so when speakingmetaphorically about wealth.
To derive a meaningof game that can apply to wealth, we must lookat a higher level of abstraction and define game asthe instantiation of a positive or negative outcome,i.e.
to win is to achieve a positive outcome, orgain wealth.
In the same sentence play implies thatsome voluntary action must be taken to achieve apositive outcome.For some metaphors, a simple transfer of thesource properties to the target does not result ina coherent interpretation at all.
Given, for exam-ple, the CM POVERTY is a PRICE, one LM fromthis study is, poverty is the price of peace.
In thiscase, the meaning has to do with some notion of37an exchange, where a negative consequence mustbe accepted in order to achieve a desired outcome.However, the metaphorical meaning of price dif-fers from the literal meaning of the word.
In literalcontexts, price refers to an amount of money orgoods with inherent value that must be given to ac-quire something; the buyer has a supply of moneyor goods that they willingly exchange for theirdesired item.
In the metaphorical sense, though,there often is no buyer, and there is certainly notan inherent value that can be assigned to poverty,nor can one use a supply of it to acquire peace.Another issue concerns cultural differences.While writing the axioms to deal with English andRussian source-target pairs we noticed that a ma-jority of the axioms applied equally well to bothlanguages.
However, there are some subtle dif-ferences of aspect that impact the interpretationof similar CMs across the two languages.
Look-ing again at the WEALTH is a GAME metaphor,the Russian interpretation involves some nuanceof a lack of importance about the subject thatdoes not seem to be present in English when us-ing words like game and play.
Note that theremay be some notion of carelessness for English(see Sec.
5.3), but for Russian, the notion of beingcarefree, which is not the same as careless, aboutwealth has a strong prevalence.5 Experimental Validation5.1 Source GenerationFollowing from the definition of metaphor, the tar-get and the source domain share certain proper-ties.
In natural language, concepts and propertiesare represented by words and phrases.
There isa long-standing tradition for considering compu-tational models derived from word co-occurrencestatistics as being capable of producing reason-able property-based descriptions of concepts (Ba-roni and Lenci, 2008).
We use proposition storesto derive salient properties of concepts that can bepotentially compared in a metaphor.A proposition store is a collection of proposi-tions such that each proposition is assigned its fre-quency in a corpus.
Propositions are tuples ofwords that have a determined pattern of syntacticrelations among them (Clark and Harrison, 2009;Pe?as and Hovy, 2010; Tsao and Wible, 2013).For example, the following propositions can be ex-tracted from the sentence John decided to go toschool:(NV John decide)(NV John go)(NVPN John go to school)...We generated proposition stores from parsedEnglish Gigaword (Parker et al., 2011) and Rus-sian ruWac (Sharoff and Nivre, 2011).
Given theproposition stores, we generate potential sourcesfor a seed target lexeme l in three steps:1.
Find all propositions Plcontaining l.2.
Find all potential source lexemes S such thatfor each s ?
S there are propositions p, p?in the proposition store such that l occurs atposition i in p and s occurs at position i in p?.The set of propositions containing l and s atthe same positions is denoted by Pl,s.3.
Weight potential sources s ?
S using the fol-lowing equation:weightl(s) =?p?Pl,sweightl(t), (1)The source generation procedure andits validations are described in detail atgithub.com/MetaphorExtractionTools/mokujin.2In the experiment described below, we gener-ated potential sources for the target domains ofPOVERTY and WEALTH.5.2 Linguistic Metaphors Extraction andValidationFor each potential CM, we look for supportingLMs in corpora.
A a large number of LMs sup-porting a particular CM suggests that this CMmight be cognitively plausible.
We use a simplemethod for finding LMs.
If a target lexeme anda source lexeme are connected by a dependencyrelation in a sentence, then we assume that thisdependency structure contains a LM.
For exam-ple, in the phrases medicine against poverty andchronic poverty, the target word (poverty) is re-lated via dependency arc with the source words(medicine, chronic).
LMs were extracted from En-glish Gigaword (Parker et al., 2011) and RussianruWac (Sharoff and Nivre, 2011).For the generated CMs, we select seed lexemesfor target and source domains.
We expand the2The tools for generating proposition storesand the obtained resources are freely available athttps://ovchinnikova.me/proj/metaphor.html.38sets of these target and source lexemes with se-mantically related lexemes using English and Rus-sian ConceptNet (Speer and Havasi, 2013) and topranked patterns from the proposition stores.
Forexample, the expansion of the lexeme disease re-sults in the following set of lexemes: {disease,symptom, syndrome, illness, unwellness, sickness,sick, medicine, treatment, treat, cure, doctor, ... }For each language, we select 20 top-rankedsources per target.
Then we randomly select atmost 10 sentences per each target-source pair.These sentences are validated by 3 linguist expertseach.
For each sentence, the experts are asked ifit contains a metaphor comparing an indicated tar-get domain with an indicated source domain.
Theinter-annotator agreement on the validation task isdefined as the percentage of judgements on whichthe three experts agree.
Agreement is 81% for En-glish and 80% for Russian.Tables 1 and 2 show 10 potential sources pertarget with the best agreement.
Column ALL pro-vides the number of sentences per a proposed CMsuch that all experts agreed that the sentence con-tains a metaphor.
Column TWO provides the num-ber of sentences such that any two experts agreedon, and Column ONE shows the number of sen-tences such that a single expert thought it con-tained a metaphor.target source ALL TWO ONEwealthblood 10 10 10water 9 10 10drug 9 10 10food 9 9 10body 9 9 10power 8 9 10game 8 9 9security 7 9 10resource 7 7 9disease 7 8 9povertywar 10 10 10abyss 10 10 10violence 9 9 10price 8 9 9location 7 8 8disease 7 7 7crime 4 5 6crop 3 7 9terrorism 3 3 5cost 2 3 7Table 1: Validation of English linguisticmetaphors found for potential sources.5.3 Metaphor Interpretation ValidationMetaphor interpretations were generated for posi-tively validated linguistic metaphors, as described?????????(wealth)???????
(energy) 10 10 10????
(water) 10 10 10???????
(freedom) 10 10 10??????
(power) 9 10 10???
(god) 9 10 10?????
(blood) 9 10 10????
(way) 9 10 10????
(game) 8 10 10?????
(glory) 4 5 5?????
(ware) 3 8 10????????(poverty)????????
(abyss) 10 10 10????
(enemy) 9 10 10???????
(disease) 9 9 9??????
(power) 8 10 10????
(body) 6 6 6????
(pain) 5 10 10????????
(despair) 5 10 10????
(price) 4 4 4??????
(death) 3 5 6?????
(fear) 3 9 10Table 2: Validation of Russian linguisticmetaphors found for potential sources.in Sec.
3.4.
Each interpretation was validated bythree expert linguists.
We calculated strict andrelaxed agreement for the validated data.
Strictagreement is calculated over three categories: cor-rect (C), partially correct (P), and incorrect (I).
Re-laxed agreement is calculated over two categories:C/P and I.
Partially correct means that the valida-tor felt that something was missing from the inter-pretation, but that what was there was not wrong.Table 3 presents the validation results for both lan-guages.
As can be seen in the table, strict agree-ment (AgrS) is 62% and 52% and strict systemaccuracy (AccS ALL) is 62% and 50% for En-glish and Russian, respectively.
Relaxed agree-ment (AgrR) results is 93% and 83%, and relaxedaccuracy (AccR ALL) is 91% and 78%.Validators often marked things as only partiallycorrect if they felt that the interpretation was lack-ing some aspect that was critical to the meaning ofthe metaphor.
A common feeling amongst the val-idators, for example, is that the interpretation forpeople who are terrorized by poverty should in-clude some mention of "fear" as a crucial aspectof the metaphor, as the interpretation providedstates only that "terrorize" implies that "poverty"is causing "people" not to function.
However, theend result of "fear" itself is often that the experi-encer cannot function, as in paralyzed by fear.Tables 4 and 5 contain interpretation system ac-curacy results by CM.
We calculated the percent-age of LMs evoking this CM that were validatedas C vs.
I (strict) or P/C vs.
I (relaxed) by all three39AgrS AgrR AccS ALL AccS TWO AccS ONE AccR ALL AccR TWO AccR ONEEnglish 0.62 0.93 0.62 0.84 0.98 0.91 0.97 0.99Russian 0.52 0.83 0.50 0.76 0.96 0.78 0.93 0.99Table 3: Validation results for metaphor interpretation for English and Russian.
(ALL), or just two (TWO) validators.
In most ofthe cases, the system performs well on "simple"CMs related to the concepts of causation and func-tioning (e.g., WEALTH is POWER), cf.
section 4,whereas its accuracy is lower for richer metaphors(e.g., WEALTH is a GAME).target sourceALL TWOS R S Rwealthblood 0.8 1 1 1water 1 1 1 1drug 0.44 0.78 0.89 0.89food 0.89 1 1 1body 0.67 0.78 0.78 0.78power 1 1 1 1game 0.63 1 1 1security 0.14 0.88 0.71 1resource 1 1 1 1disease 0 1 1 1povertywar 0.9 0.9 1 1abyss 0 0.5 0.4 1violence 0 1 0.11 1price 0.88 0.88 0.88 1location 1 1 1 1disease 0.43 0.86 0.86 0.86crime 0.75 1 1 1crop 1 1 1 1terrorism 0 1 0.33 1cost 1 1 1 1Table 4: Accuracy of English interpretations foreach CM.The data used in the described experiments, sys-tem output, and expert validations are availableat http://ovchinnikova.me/suppl/AbductionSystem-Metaphor-Validation.7z.6 Conclusion and Future WorkThe developed abduction-based metaphorinterpretation pipeline is available athttps://github.com/eovchinn/Metaphor-ADPas a free open-source project.
This pipelineproduces favorable results, with metaphor in-terpretations that are rated as at least partiallycorrect, for over 90% of all valid metaphors it isgiven for English, and close to 80% for Russian.Granted, the current research is performed using asmall, controlled set of metaphors, so these resultscould prove difficult to reproduce on a large scalewhere any metaphor is possible.
Still, the highaccuracies achieved on both languages indicateT sourceALL TWOS R S R?????????(wealth)???????
(energy) 0.4 0.8 0.9 1????
(water) 0 0.9 0.6 0.9???????
(freedom) 1 1 1 1??????
(power) 1 1 1 1???
(god) 0.67 1 0.89 1?????
(blood) 1 1 1 1????
(way) 0.78 0.78 0.89 0.89????
(game) 0.1 0.2 0.2 0.3?????
(glory) 0 0.75 0.75 1?????
(ware) 0 0 0 1????????(poverty)????????
(abyss) 0.7 1 1 1????
(enemy) 0.56 1 1 1???????
(disease) 0.33 0.89 0.67 1??????
(power) 0.5 0.5 1 1????
(body) 0.17 0.17 0.17 0.83????
(pain) 1 1 1 1????????
(despair) 0.6 0.6 1 1????
(price) 0.75 0.75 1 1??????
(death) 0 0 0.33 1?????
(fear) 0 1 0.67 1Table 5: Accuracy of Russian interpretations foreach CM.that the approach is sound and there is potentialfor future work.The current axiomatization methodology isbased mainly on manually writing mapping ax-ioms based on the axiom author?s intuition.
Ob-viously, this approach is subject to scrutiny re-garding the appropriateness of the metaphors andfaces scalability issues.
Thus, developing new au-tomatic methods to construct the domain knowl-edge bases is a main area for future consideration.The mapping axioms present a significant chal-lenge as far producing reliable output automati-cally.
One area for consideration is the afore-mentioned prevalence of certain underlying mean-ings such as causality and functionality.
Gather-ing enough examples of these by hand could leadto generalizations in argument structure that couldthen be applied to metaphorical phrases in cor-pora to extract new metaphors with similar mean-ings.
Crowd-sourcing is another option that couldbe applied to both axiom writing tasks in order todevelop a large-scale knowledge base in consid-erably less time and at a lower cost than havingexperts build the knowledge base manually.40ReferencesR.
Agerri, J.A.
Barnden, M.G.
Lee, and A.M. Walling-ton.
2007.
Metaphor, inference and domain-independent mappings.
In Proc.
of RANLP?07,pages 17?23.J.
A. Barnden and M. G. Lee.
2002.
An artificial intel-ligence approach to metaphor understanding.
Theo-ria et Historia Scientiarum, 6(1):399?412.M.
Baroni and A. Lenci.
2008.
Concepts and proper-ties in word spaces.
Italian Journal of Linguistics,20(1):55?88.J.
Bos, S. Clark, M. Steedman, J. R. Curran, andJ.
Hockenmaier.
2004.
Wide-coverage semanticrepresentations from a ccg parser.
In Proc.
of COL-ING?04, pages 1240?1246.P.
Clark and P. Harrison.
2009.
Large-scale extrac-tion and use of knowledge from text.
In Proc.
of the5th international conference on Knowledge capture,pages 153?160.
ACM.Catherine Havasi, Robert Speer, and Jason Alonso.2007.
Conceptnet 3: a flexible, multilingual se-mantic network for common sense knowledge.
InRecent Advances in Natural Language Processing,Borovets, Bulgaria, September.J.
R. Hobbs, M. Stickel, P. Martin, and D. Edwards.1993.
Interpretation as abduction.
Artificial Intelli-gence, 63:69?142.J.
R. Hobbs.
1985.
Ontological promiscuity.
In Proc.of ACL, pages 61?69, Chicago, Illinois.J.
R. Hobbs.
1992.
Metaphor and abduction.
InA.
Ortony, J.
Slack, and O.
Stock, editors, Com-munication from an Artificial Intelligence Perspec-tive: Theoretical and Applied Issues, pages 35?58.Springer, Berlin, Heidelberg.Jerry R. Hobbs.
2005.
Toward a useful concept ofcausality for lexical semantics.
Journal of Seman-tics, 22(2):181?209.N.
Inoue and K. Inui.
2012.
Large-scale cost-basedabduction in full-fledged first-order predicate logicwith cutting plane inference.
In Proc.
of JELIA,pages 281?293.G.
Lakoff and M. Johnson.
1980.
Metaphors we Liveby.
University of Chicago Press.G.
Lakoff.
1987.
Women, fire, and dangerous things:what categories reveal about the mind.
Universityof Chicago Press.S.
Narayanan.
1999.
Moving right along: A computa-tional model of metaphoric reasoning about events.In Proc.
of AAAI/IAAI, pages 121?127.J.
Nivre, J.
Hall, and J. Nilsson.
2006.
Maltparser:A data-driven parser-generator for dependency pars-ing.
In Proc.
of LREC?06, volume 6, pages 2216?2219.R.
Parker, D. Graff, J. Kong, K. Chen, and K. Maeda.2011.
English gigaword fifth edition.
LDC.A.
Pe?as and E. H. Hovy.
2010.
Filling knowledgegaps in text for machine reading.
In Proc.
of COL-ING?10, pages 979?987.S.
Sharoff and J. Nivre.
2011.
The proper place ofmen and machines in language technology: Process-ing Russian without any linguistic knowledge.
InProc.
Dialogue 2011, Russian Conference on Com-putational Linguistics.E.
Shutova, T. Van de Cruys, and A. Korhonen.
2012.Unsupervised metaphor paraphrasing using a vectorspace model.
In COLING (Posters), pages 1121?1130.E.
Shutova.
2010.
Automatic metaphor interpretationas a paraphrasing task.
In Proc.
of NAACL?10.R.
Speer and C. Havasi.
2013.
Conceptnet 5: A largesemantic network for relational knowledge.
In ThePeople?s Web Meets NLP, pages 161?176.
Springer.N.
Tsao and D. Wible.
2013.
Word similarity us-ing constructions as contextual features.
In Proc.JSSP?13, pages 51?59.T.
Veale and Y. Hao.
2008.
A fluid knowledge repre-sentation for understanding and generating creativemetaphors.
In Proc.
of COLING?08, pages 945?952.ACL.41
