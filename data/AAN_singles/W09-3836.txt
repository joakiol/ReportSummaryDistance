Proceedings of the 11th International Conference on Parsing Technologies (IWPT), pages 226?229,Paris, October 2009. c?2009 Association for Computational LinguisticsUsing Treebanking Discriminants as Parse Disambiguation FeaturesMd.
Faisal Mahbub Chowdhury?
and Yi Zhang?
and Valia Kordoni??
Dept of Computational Linguistics, Saarland University?
Dept of Computational Linguistics, Saarland University and DFKI GmbH, Germany{chowd,yzhang,kordoni}@coli.uni-sb.deAbstractThis paper presents a novel approach of in-corporating fine-grained treebanking deci-sions made by human annotators as dis-criminative features for automatic parsedisambiguation.
To our best knowledge,this is the first work that exploits treebank-ing decisions for this task.
The advan-tage of this approach is that use of humanjudgements is made.
The paper presentscomparative analyses of the performanceof discriminative models built using tree-banking decisions and state-of-the-art fea-tures.
We also highlight how differentlythese features scale when these models aretested on out-of-domain data.
We showthat, features extracted using treebankingdecisions are more efficient, informativeand robust compared to traditional fea-tures.1 IntroductionState-of-the-art parse disambiguation models aretrained on treebanks, which are either fully hand-annotated or manually disambiguated from theparse forest produced by the parser.
While mostof the hand-annotated treebanks contain only goldtrees, treebanks constructed from parser outputsinclude both preferred and non-preferred analy-ses.
Some treebanking environments (such asthe SRI Cambridge TreeBanker (Carter, 1997) or[incr tsdb()] (Oepen, 2001)) even recordthe treebanking decisions (see section 2) that theannotators take during manual annotation.
Thesetreebanking decisions are, usually, stored in thedatabase/log files and used later for dynamic prop-agation if a newer version of the grammar on thesame corpus is available (Oepen et al, 2002).
Butuntil now, to our best knowledge, no research hasbeen reported on exploiting these decisions forbuilding a parse disambiguation model.Previous research has adopted two approachesto use treebanks for disambiguation models.
Oneapproach, known as generative, uses only the goldparse trees (Ersan and Charniak, 1995; Charniak,2000).
The other approach, known as discrimi-native, uses both preferred trees and non-preferredtrees (Johnson et al, 1999; Toutanova et al, 2005).In this latter approach, features such as local con-figurations (i.e., local sub-trees), grandparents, n-grams, etc., are extracted from all the trees andare utilized to build the model.
Neither of the ap-proaches considers cognitive aspects of treebank-ing, i.e.
the fine-grained decision-making processof the human annotators.In this paper, we present our ongoing study ofusing treebanking decisions for building a parsedisambiguation model.
We present comparativeanalyses among the features extracted using tree-banking decisions and the state-of-the-art featuretypes.
We highlight how differently these featuresscale when they are tested on out-of-domain data.Our results demonstrate that features extracted us-ing treebanking decisions are more efficient, in-formative and robust, despite the total number ofthese features being much less than that of the tra-ditional feature types.The rest of this paper is organised as follows?
section 2 presents some motivation along withdefinition of treebanking decisions.
Section 3 de-scribes the feature extraction templates that havebeen used for treebanking decisions.
Section 4 ex-plains the experimental data, results and analyses.Section 5 concludes the paper with an outline ofour future research.2 Treebanking decisionsOne of the defining characteristics of Redwoods-style treebanks1 (Oepen et al, 2002) is that thecandidate trees are constructed automatically by1More details available in http://redwoods.stanford.edu.226D1 SUBJH the dog || barksD2 HSPEC the || dog barksD3 FRAG_NP the dog barksD4 HSPEC the || dogD5 NOUN_N_CMPND dog || barks.
.
.
.
.
.D6 PLUR_NOUN_ORULE barksD7 v_-_le barksD8 n_-_mc_le barksFigure 1: Example forest and discriminantsthe grammar, and then manually disambiguated byhuman annotators.
In doing so, linguistically richannotation is built efficiently with minimum man-ual labor.
In order to further improve the manualdisambiguation efficiency, systems like [incrtsdb()] computes the difference between can-didate analyses.
Instead of looking at the hugeparse forest, the treebank annotators select or re-ject the features that distinguish between differentparses, until only one parse remains.
The numberof decisions for each sentence is normally aroundlog2(n) where n is the total number of candidatetrees.
For a sentence with 5000 candidate read-ings, only about 12 treebanking decisions are re-quired for a complete disambiguation.
A similarmethod was also proposed in (Carter, 1997).Formally, a feature that distinguishes betweendifferent parses is called a discriminant.
ForRedwoods-style treebanks, this is usually ex-tracted from the syntactic derivation tree of theHead-driven Phrase Structure Grammar (HPSG)analyses.
Figure 1 shows a set of example dis-criminants based on the two candidate trees.A choice (acceptance or rejection, either manu-ally annotated or inferred by the system) made ona discriminant is called a decision.
In the aboveexample, suppose the annotator decides to acceptthe binary structure the dog || barks as a subject-head construction and assigns a value yes to dis-criminant D1, the remaining discriminants willalso receive inferred values by deduction (no forD2, no for D3, yes for D4, etc).
These decisionsare stored and used for dynamic evolution of thetreebank along with the grammar development.Treebank decisions (especially those made byannotators) are of particular interest to our studyof parse disambiguation.
The decisions record thefine-grained human judgements in the manual dis-ambiguation process.
This is different from thetraditional use of treebanks to build parse selec-tion models, where a marked gold tree is pickedfrom the parse forest without concerning detailedselection steps.
Recent study on double annotatedtreebanks (Kordoni and Zhang, 2009) shows thatannotators tend to start with the decisions with themost certainty, and delay the ?hard?
decisions asmuch as possible.
As the decision process goes,many of the ?hard?
discriminants will receive aninferred value from the certain decisions.
Thisgreedy approach helps to guarantee high inter-annotator agreement.
Concerning the statisticalparse selection models, the discriminative natureof these treebanking decisions suggests that theyare highly effective features, and if properly used,they will contribute to an efficient disambiguationmodel.3 Treebanking Decisions asDiscriminative DisambiguationFeaturesWe use three types of feature templates for tree-banking decisions for feature extraction.
We referto the features extracted using these templates asTDF (Treebanking Decision Feature) in the rest ofthis paper.
The feature templates areT1: discriminant + lexical types of the yieldT2: discriminant + rule(left-child)2 + rule(right-child)T3: instances of T2 + rule(parent) + rule(siblings)TDFs of T1, T2 and T3 in combination are re-ferred to as TDFC or TDFs with context.
Forexample in Figure 1, instance of T1 for thediscriminant D4 is ?HSPEC3 + le_type(the)4 +le_type(dog)"; instance of T2 is ?HSPEC + rule(DET) + rule(N) "; and instance of T3 is ?HSPEC +rule(DET ) + rule(N) + rule(S) + rule(VP)".A TDF represents partial information about theright parse tree (as most usual features).
But insome way, it also indicates that it was a point ofa decision (point of ambiguity with respect to theunderlying pre-processing grammar), hence carry-ing some extra bit of information.
TDFs allow to2rule(X) represents the HPSG rule, applied on X, ex-tracted from the corresponding derivation tree.3HSPEC is the head-specifier rule in HPSG4le_type(X) denotes the abstract lexical type of word Xinside the grammar.227omit certain details inside the features by encod-ing useful purposes of relationships between lexi-cal types of the words and their distant grandpar-ents without considering nodes in the intermediatelevels (allowing some kind of underspecification).In contrast, state-of-the-art feature types containall the nodes in the corresponding branches ofthe tree.
While they encode ancestor information(through grandparenting), but they ignore siblings.TDFs include siblings along with ancestor.
Unliketraditional features, which are generated from allpossible matches (which is huge) of feature typesfollowed by some frequency cut-offs, the selectionof TDFs is directly restricted by the small num-ber of treebanking decisions themselves and ex-haustive search is not needed.
It should be notedthat, we do not use treebanking decisions made forthe parse forest of one sentence to extract featuresfrom the parse forest of another sentence.
That iswhy, the number of TDFs is much smaller thanthat of traditional features.
This also ensures thatTDFs are highly correlated to the correspondingconstructions and corresponding sentences fromwhere they are extracted.4 Experiment4.1 DataWe use a collection of 8593 English sentencesfrom the LOGON corpus (Oepen et al, 2004) forour experiment.
874 of them are kept as test itemsand the remaining 7719 items are used for train-ing.
The sentences have an average length of 14.68and average number of 203.26 readings per sen-tence.
The out-of-domain data are a set of 531English Wikipedia sentences from WeScience cor-pus (Ytrest?l et al, 2009).Previous studies (Toutanova et al, 2005; Os-borne and Baldridge, 2004) have reported rela-tively high exact match accuracy with earlier ver-sions of ERG (Flickinger, 2000) on datasets withvery short sentences.
With much higher structuralambiguities in LOGON and WeScience sentences,the overall disambiguation accuracy drops signifi-cantly.4.2 Experimental setup and evaluationmeasuresThe goal of our experiments is to compare var-ious types of features (with TDF) in terms ofefficiency, informativeness, and robustness.
Tocompare among the feature types, we build log-linear training models (Johnson et al, 1999) forparse selection (which is standard for unification-based grammars) for TDFC, local configurations,n-grams and active edges5.
For each model, wecalculate the following evaluation metrics ??
Exact (match) accuracy: it is simply the percentageof times that the top-ranked analysis for each test sen-tences is identical with the gold analysis of the samesentence.?
5-best (match) accuracy: it is the percentage of timesthat the five top-ranked analyses for each of the sen-tences contain the gold analysis.?
Feature Hit Count (FHC): it is the total number of oc-currences of the features (of a particular feature type)inside all the syntactic analyses for all the test sen-tences.
So, for example, if a feature (of a particularfeature type) is observed 100 times, then these 100 oc-currences are added to the total FHC.?
Feature Type Hit Count (FTHC): it is the total num-ber of distinct features (of the corresponding featuretype) observed inside the syntactic analyses of all thetest sentences.While exact and 5-best match measures showrelative informativeness and robustness of the fea-ture types, FHC and FTHC provide a more com-prehensive picture of relative efficiencies.4.3 Results and discussionAs we can see in Table 1, local configurationsachieve highest accuracy among the traditionalfeature types.
They also use higher number of fea-tures (almost 2.7 millions).
TDFC do better thanboth n-grams and active edges, even with a lowernumber of features.
Though, local configurationsgain more accuracy than TDFC, but they do so ata cost of 50 times higher number of features.
Thisindicates that features extracted using treebankingdecisions are more informative.For out-of-domain data (Table 1), there is a bigdrop of accuracy for local configurations.
Activeedges and TDFC also have some accuracy drop.Surprisingly, n-grams do better with our out-of-domain data than in-domain, but still that accuracyis close to that of TDFC.
Note that n-grams have8 times higher number of features than TDFC.Hence, according to these results, TDFC are morerobust, for out-of-domain data, than local config-urations and active edges, and almost as good asn-grams.5Active edges correspond to the branches (i.e.
one daugh-ter in turn) of the local sub-trees.228Feature Total 5-best accuracy 5-best accuracy Exact accuracy Exact accuracytemplate features (in-domain) (out-of-domain) (in-domain) (out-of-domain)n-gram 438,844 68.19% 62.71% 41.30% 42.37%local configuration 2,735,486 75.51% 64.22% 50.69% 44.44%active edges 89,807 68.99% 61.77% 41.88% 39.92%TDFC 53,362 70.94% 62.71% 43.59% 41.05%Table 1: Accuracies obtained on both in-domain and out-of-domain data using n-grams (n=4), localconfigurations (with grandparenting level 3), active edges and TDFC.Feature FHC FTHC Activetemplate featuresn-gram 18,245,558 32,425 7.39%local config.
62,060,610 357,150 13.06%active edges 22,902,404 27,540 30.67%TDFC 21,719,698 17,818 33.39%Table 2: FHC and FTHC calculated for in-domaindata.The most important aspect of TDFC is that theyare more efficient than their traditional counter-parts (Table 2).
They have significantly highernumber of active features ( FTHCTotalFeature# ) than n-grams and local configurations.5 Future workThe results of the experiments described in this pa-per indicate a good prospect for utilizing treebank-ing decisions, although, we think that the types offeature templates that we are using for them arenot yet fully conveying cognitive knowledge of theannotators, in which we are specifically interestedin.
For instance, we expect to model human dis-ambiguation process more accurately by focusingonly on human annotators?
decisions (instead ofonly inferred decisions).
Such a model will notonly improve the performance of the parsing sys-tem at hand, but can also be applied interactivelyin treebanking projects to achieve better annota-tion speed (e.g., by ranking the promising discrim-inants higher to help annotators make correct de-cisions).
Future experiments will also investigatewhether any pattern of discriminant selection bythe humans can be learnt from these decisions.ReferencesDavid Carter.
1997.
The treebanker: A tool for supervisedtraining of parsed corpora.
In Proceedings of the Work-shop on Computational Environments for Grammar De-velopment and Linguistic Engineering, Madrid, Spain.Eugene Charniak.
2000.
A maximum entropy-based parser.In Proceedings of the 1st Annual Meeting of the NorthAmerican Chapter of Association for Computational Lin-guistics (NAACL 2000), pages 132?139, Seattle, USA.Murat Ersan and Eugene Charniak.
1995.
A statistical syn-tactic disambiguation program and what it learns.
pages146?159.Dan Flickinger.
2000.
On building a more efficient grammarby exploiting types.
6(1):15?28.Mark Johnson, Stuart Geman, Stephen Canon, Zhiyi Chi,and Stefan Riezler.
1999.
Estimators for stochasticunifcation-based grammars.
In Proceedings of the 37thAnnual Meeting of the Association for Computational Lin-guistics (ACL 1999), pages 535?541, Maryland, USA.Valia Kordoni and Yi Zhang.
2009.
Annotating wall streetjournal texts using a hand-crafted deep linguistic gram-mar.
In Proceedings of The Third Linguistic AnnotationWorkshop (LAW III), Singapore.Stephan Oepen, Kristina Toutanova, Stuart Shieber, Christo-pher Manning, Dan Flickinger, and Thorsten Brants.2002.
The LinGO Redwoods treebank: motivation andpreliminary applications.
In Proceedings of COLING2002: The 17th International Conference on Computa-tional Linguistics: Project Notes, Taipei, Taiwan.Stephan Oepen, Helge Dyvik, Jan Tore L?nning, Erik Vell-dal, Dorothee Beermann, John Carroll, Dan Flickinger,Lars Hellan, Janne Bondi Johannessen, Paul Meurer, Tor-bj?rn Nordg?rd, and Victoria Ros?n.
2004.
Som ?
kapp-ete med trollet?
towards mrs-based norwegian-englishmachine translation.
In Proceedings of the 10th Interna-tional Conference on Theoretical and Methodological Is-sues in Machine Translation, pages 11?20, MD, USA.Stephan Oepen.
2001.
[incr tsdb()] ?
competence andperformance laboratory.
User manual.
Technical report,Computational Linguistics, Saarland University, Saar-br?cken, Germany.Miles Osborne and Jason Baldridge.
2004.
Ensemble-basedactive learning for parse selection.
In HLT-NAACL 2004:Main Proceedings, pages 89?96, Boston, USA.Kristina Toutanova, Christoper D. Manning, Dan Flickinger,and Stephan Oepen.
2005.
Stochastic HPSG parse selec-tion using the Redwoods corpus.
Journal of Research onLanguage and Computation, 3(1):83?105.Gisle Ytrest?l, Stephan Oepen, and Daniel Flickinger.
2009.Extracting and annotating wikipedia sub-domains.
In Pro-ceedings of the 7th International Workshop on Treebanksand Linguistic Theories, pages 185?197, Groningen, theNetherlands.229
