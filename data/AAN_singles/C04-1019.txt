The Queen?s Agents: Using Collaborating Object-Based Dialogue Agentsin the Queen?s CommunicatorIan O?Neill, Philip Hanna, Xingkun LiuSchool of Computer ScienceQueen?s UniversityBelfast BT7 1NN, N. Ireland{i.oneill, p.hanna,xingkun.liu}@qub.ac.ukMichael McTearSchool of Computing andMathematicsUniversity of UlsterJordanstown, BT37 0QB, N. Irelandmf.mctear@ulster.ac.ukAbstractA dialogue manager provides the decisionmaking at the heart of a spoken dialoguesystem.
In an object-oriented approach todialogue management, generic behaviour, suchas confirming new or modified information thathas been supplied by the user, is inherited bymore specialised classes.
These specialisedclasses either encapsulate behaviour typical of aparticular business domain (service agents) ormake available dialogue abilities that may berequired in many business domains (supportagents).
In this paper we consider the interplaybetween the agents?
generic and specialisedbehaviour and consider the manner in whichservice and support agents collaborate withinand across their respective groups.1 Object-orientation and cross-domain,mixed initiative dialogueObject-orientation provides an intuitiveseparation of, on the one hand, inheritable genericfunctionality and, on the other hand, domain-specific, specialized functionality that is supportedby the generic elements of the system.
Applied tothe area of natural language dialogue, this hasenabled us to create a generic, automated dialogueconfirmation strategy ?
based on confirmationstatuses and discourse pegs (see Section 3.3) ?which supports domain-specific strategies to gatherand provide information relating to particulartransactions ?
for example booking a hotel orfinding out about cinema times.
Heuristics, orexpert rules, specific to each transaction domain,prompt the user for significant missing informationor assist the user by providing choices from adatabase (e.g.
names of available hotels).Thus, while our generic confirmation strategyensures that information newly supplied by theuser is confirmed, and information changed isreconfirmed, and so on, the nature of thatinformation may differ significantly from domainto domain.
Likewise the system may respond toconfirmed information in quite different waysdepending on the domain ?
as it either completes adomain-specific transaction or attempts to elicitimportant missing information from the user.In the Queen?s Communicator dialogue system,expertise for different transaction domains isencapsulated within corresponding expert classesor ?agents?.
We have used this to our advantage byenabling the system to transfer between domainseither at the user?s or the system?s initiative ?
in amixed initiative dialogue either the user or thesystem may introduce new topics.
Agents are ableto announce their abilities to the system at large, orindeed to the user.
Thus, when key words orphrases uttered by the user indicate that the topicof conversation has turned, for example, fromaccommodation booking to payment, the system?sDomainSpotter (see Section 4) can ask the agentsif any of them deal with payments.
The mostsuitable agent is then given the task of managingthe specialised subdialogue.2 Spoken dialogue managementA spoken dialogue system typically comprises anumber of components: an automatic speechrecogniser, a semantic parser, a dialogue manager(DM), a database ?back-end?, a natural languagegenerator, and a text-to-speech engine.
The focusof our present research is the development of anobject-based DM that can support mixed initiativedialogues that involve a number of businessdomains.Our DM operates within the DARPA1Communicator architecture, which is based on theGalaxy hub ?
a software router  developed by theSpoken Language Systems group at MIT(www.sls.csail.mit.edu/sls/technologies/galaxy.shtml)and subsequently released as an open sourcepackage in collaboration with the MITRECorporation (fofoca.mitre.org).
In the ?Queen?sCommunicator?
dialogue system, our newlydeveloped DM interacts with a number of off-the-shelf components.
For semantic parsing we usePhoenix (W. Ward, 1994), available from the1 Defense Advanced Research Projects AgencyUniversity of Colorado?s ?CU Communicator?download (communicator.colorado.edu).
Forrecognition we use the Microsoft English ASRVersion 5 Engine as supplied with Windows XP.Synthesised speech is provided by Festival(www.cstr.ed.ac.uk/projects/festival/), also takenfrom the CU download.
Figure 1 shows a typicalCommunicator configuration.The DM itself embodies decision-makingsimilar to that of a human interlocutor as it queries,responds to and informs the user.
Moreover, inmixed initiative dialogues that deal with more thanone domain (e.g.
enquiries about accommodationand events, and supporting exchanges aboutpayment and addresses), the system has theadditional task of identifying the (ongoing) topic ofthe dialogue and applying appropriate dialoguemanagement expertise.3 Object-based dialogue agents3.1 A multi-agent approach to dialoguemanagementIn order to enable mixed initiative interactionsacross domains, we model the system?s behaviouras a collaboration between the cohort ofimplemented agents.
Other developers have alsoadopted an agent-based approach to dialogue,though sometimes dialogue agents each performvery simple tasks rather than engage in extensivediscourse: in (Turunen and Hakulinen, 2001) forexample, simple generic error-handling agents,based on Java and XML, ask the user to repeatmisunderstood input.
In our case an agent is aspecialist in a particular transactional area ?
e.g.booking accommodation or eliciting an address.An agent uses its own domain-specific ?expert-rules?
to elicit information (e.g.
information formaking a hotel booking) that is then stored in aspecialised dialogue frame.
Each agent thusencapsulates a skillset for a substantial dialogue orsubdialogue.Like the Communicator team at Carnegie MellonUniversity, we view the dialogue product (theknowledge to be elicited) as a tree-like structure(Rudnicky and Xu, 1999) ?
though for us the nodesare complete dialogue frames rather thanindividual data items.
In the Queen?sCommunicator the discourse structure evolvesdynamically as agents are selected by aDomainSpotter, in the light of the user?s utterancesor as a consequence of the agents?
own rules.
It isthis process, rather than an overarching dialogueplan or agenda, that drives the discourse forward,sometimes across domain boundaries.
We do,however, maintain an ExpertFocusStack, whichcontains, in sequence, the name of the agent that iscurrently handling the dialogue and the names ofagents that have last handled the dialogue and haveunfinished business: this allows the system toquickly identify the current handler and to passcontrol back, once the current handling agent isfinished.3.2 Inherited and domain-specific behaviourOur dialogue manager is implemented as a suiteof Java classes (see Figure 2).
The object-basedapproach (Booch, 1994) (O?Neill and McTear,2000) has afforded us certain advantages.
Thedomain specialists or ?Experts?
within our system?
AccommodationExpert, TheatreExpert,CinemaExpert, CreditCardExpert, etc.
?
all inheritgeneric dialogue handling skills from aDiscourseManager, whose role is to ensure thatnew information provided by the user is at leastimplicitly confirmed, and information that ischanged or negated is subjected to more detailed,explicit confirmation (O?Neill and McTear, 2002)(O?Neill et al 2003).
The domain expertsencapsulate specialised behaviour, which can bereadily extended by additional classes.
There aretwo families of domain experts:y ?service agents?
that provide front-line servicesto the user  ?
like AccommodationExpert,whose behaviour emulates that of a humanbooking clerk, andy ?support agents?
like CreditCardExpert that areable to elicit information required to completeone of the front-line service transactions.We refer to the corresponding discoursesegments as ?service?
and ?support?
dialoguesrespectively.
By assigning the agents (and thecorresponding dialogues) to one of two families wegive ourselves the option of restricting user-ledtransitions between main and ancillarytransactions.
However, the overall objective of ourimplementation is to maintain a high degree offlexibility in the manner in which the system reactsto unsolicited user utterances.3.3 Using frames of informationThe agents, whether they provide service orsupport, collect and manipulate frames ofSpeech RecogniserNatural LanguageSemantic ParserDialogue ManagerNatural LanguageGeneratorSpeech synthesiserDatabaseGalaxyhubFigure 1.
DARPA Communicator architecture.information related to their own sphere ofcompetence.
The frames consist of Attributeobjects, each of which stores:y the type and elicited value of a single piece ofinformation (datum);y the confirmation status of the datum (e.g.new_for_system);y the level to which the datum has beenconfirmed (through repetition, or by the user?saffirmative response to a system prompt ?
thelevel is represented by a simple numeric?peg?
);y and the system intention regarding the datum(e.g.
implicitly confirm new information;explicitly confirm information that has beennegated; ask the user to specify informationthat is still required) (Heisterkamp andMcGlashan, 1996).The Attribute objects thus give a multi-facettedview of each piece of information that it is beingconsidered by the system.
The evolving domain-specific (and thus generally agent-specific) framesof Attributes are maintained on a DiscourseStackwithin the DiscourseHistory object.
The agentsuse this stack to implement the inherited genericconfirmation strategy.
The frames of informationare typically populated in the course of severaldiscourse turns, as new or additional information isacquired from successive user-system interactions.Once it is handling a particular discourse segment,an agent uses its inherited confirmation strategy tocompare the latest values in its current dialogueframe with the corresponding values and systemintentions in the previous iteration of that frame.Thus the agent is able to determine which valueshave been confirmed (e.g.
the user has notchallenged an implicit confirmation request by thesystem) and which have been modified or negated.3.4 Applying expert rulesIn addition to its inherited confirmationstrategies, each of the domain Experts, whether aservice agent or a support agent, has its own expertrules, contained in one or more expert rulesequences.
Typically the expert rule sequenceswill be of one of two kinds:y ?user-focussed rules?, which determine theagent?s reaction to particular combinations ofinformation supplied by the user ?
must thesystem now ask a follow-up question, must itperform a database look-up, or can it concludea transaction ?
?
andy ?database-focussed rules?, which represent theagent?s dialogue furthering strategy whendatabase queries based on user-suppliedcombinations of information fail: because ofits access to database content, the system maybe able to modify a user-supplied constraintand so formulate a database query that willsucceed (e.g.
the system might suggest a four-star hotel if it cannot meet the user?s requestfor a five-star hotel in a particular locality.
)These rules, encapsulated within the appropriateagent (e.g.
AccommodationExpert), are applied toinformation that the agent has ?phrase-spotted?
andplaced in the appropriate dialogue frame (e.g.
anAccommodationDialogueFrame).
Sequences ofrules, encapsulated within service and supportagents and tested to see which rule can fire in thecurrent discourse state, collectively embody thekinds of domain-specific behaviour thatcharacterise a human expert.DiscourseHistory-- store generated dialogframes-- containsUtteranceStore,InfoStore, andDiscourseStack*DialogServer-- provide Galaxy hubinterfaceDialogManager-- contains a number ofEnquiryExpert subclassinstances-- contains a DiscourseHistoryinstance shared betweenthe instantiated experts.-- contains a DomainSpotterinstances to exercise high-level control over experts.DiscourseManager-- implement genericconfirmation strategyEnquiryExpert-- generic processingenquires-- enables an expert toact as a service orsupport agentDialogFrame-- provide generic dialogframe functionalityEventDialogFrame-- event-specific dialogframeAccoDialogFrame-- accommodation-specific dialog frameAttribute-- individual dialog frameattributeExpertRuleSequence-- collection of relatedexpert rulesDBRequest-- encapsulate expertinitiated DB requestAccommodationExpert-- accommodationenquiry expertiseEventExpert-- domain-specificprocessing for eventsTheatreExpert-- domain-specific theatreenquiry expertiseCinemaExpert-- domain-specific cinemaenquiry expertise1 1*Creates11 1 *InvoicePaymentExpert-- domain-specificcheque processingCinemaDialogFrame-- cinema-specific dialogframeCreditCardPaymentExpert-- domain-specific credit-card processingCreditCardDialogFrame-- credit-card specificdialog framePaymentDialogFrame-- payment specificdialog framePaymentExpert-- generic-paymentprocessingTheatreDialogFrame-- theatre-specific dialogframeExpertRule-- individual database-or user-focussed rule11 1*1* 11Service Agent Hierarchy Support Agent Hierarchy Dialog Frame HierarchyDomainSpotter-- determine andmaintain enquiryfFigure 2: Class diagram of the dialogue manager.4 Finding the right agent4.1 Apppointing an initial handling agentTo begin the dialogue, in order to identify themost appropriate ?handling agent?, theDomainSpotter supplies each service agent withthe output of the semantic parse that represents theuser?s utterance.
As it attempts to find an initialhandling agent, the DomainSpotter considers onlyservice agents (like AccommodationExpert orCinemaExpert) and not support agents (likeCreditCardExpert).
The service agents representthe primary transaction types (booking a hotelroom, enquiring about a movie, etc.)
that thesystem handles: the system is not, for example,intended to allow the user to process their creditaccount, though it may elicit credit card details insupport of a service (a hotel booking for instance).Such restrictions help the system ground itsprimary functions with the user.
Each serviceagent scores the parse of the initial user utteranceagainst the semantic categories that it can process(each agent has a range of integer values ?
degreesof relevance ?
that it will assign to differentdomain-specific parse tags) and returns the score tothe DomainSpotter.
The service agent that scoreshighest is the one that the DialogManager asks toapply its domain-specific heuristics to the moredetailed processing of the enquiry.
For example,an AccommodationExpert might score highest andso become handling agent if the user has beenasking about hotels in Belfast.
Specialised agentsgive a higher score for specialised parser tags thangeneric agents.
For example, a user request ?I?dlike to go to see Finding Nemo.?
might parse as:event_enquiry:[Event_type].[Movies].FINDINGNEMO.
Although the EventExpert could award ascore for event_enquiry, the CinemaExpert, as achild of EventExpert, would award a score notonly for event_enquiry, but for Movies as well, andso would be the winner.4.2 Finding out what the system can doIf the DomainSpotter is unable to identify awinning agent, it will ask the user to choosebetween the domains in closest contention.Indeed, if the user?s enquiry is so vague as to giveno domain-related information (?I?d like to makean enquiry.?
), the DomainSpotter will ask the userto choose from one of its highest level serviceagents: ?Please choose between event booking oraccommodation booking.?
?
the words in italics areactually provided by the service agents.
TheDomainSpotter is in effect relaying to the userinformation that the system components knowabout themselves: it is part of the system?s designphilosophy that higher level components arelargely ignorant of the precise capabilities of lowerlevel components.
Similarly, if a service agentneeds to avail of a support agent in a particulararea, it tells the DomainSpotter to find it an expertthat handles the particular specialism (payments,for instance): it does not name a specific expertobject.
So that its area of expertise can beidentified, each agent has, as one of its attributes, avector of the specialisms it deals with.
Theintention is that additional lower level expertisecan be added to the system in such a way thathigher level behaviour (i.e.
requesting theexpertise) remains unchanged.
Where more thanone expert (e.g.
CreditCardExpert andInvoiceExpert) can deal with the requestedspecialism (e.g.
payments), the DomainSpotterasks the user to choose.4.3 Transferring control between service andsupportIn order to maintain the enquiry focus we use anExpertFocusStack in the DiscouseHistory.
Oncean agent is selected to handle the current discoursesegment, it is pushed on to the top of the stack.The agent then uses its expert rules to elicit all theinformation needed to complete its discoursesegment: an AccommodationExpert, for example,will be looking for all information needed tocomplete an accommodation booking.
Dependingon the rules it encapsulates, a service agent mayrequire help from a support agent.
For example, ifan AccommodationExpert has confirmed sufficientinformation to proceed with a reservation, it willrequest help from an agent whose specialism ispayment, and the DomainSpotter will look for oneLet us pursue this example further.
ThePaymentExpert is identified as an appropriatepayment handler, and is placed aboveAccommodationExpert on the ExpertFocusStack.However, let us suppose that eliciting paymentdetails first involves eliciting address details, andso the PaymentExpert in its turn asks theDomainSpotter to find it an agent specialising inaddress processing ?
in this case theAddressExpert.
The AddressExpert now goes tothe top of the ExpertFocusStack, above thePaymentExpert.
Just like any other agent theAddressExpert has its own rules that allow it toaccept typical combinations of informationsupplied (prompted or unprompted) by the userand to ask appropriate follow-up questions forwhatever information is still missing.
Once asupport agent has all the information it needs, oneof its rules will fire to ?pass control back?, alongwith a ?finished?
message, to whatever agent wasbelow it on the ExpertFocusStack.
The ?finished?agent is removed from the stack.
ThusAddressExpert will pass control back toPaymentExpert in this example, whose rules, if theuser does not introduce a new topic, will continueto fire until all necessary payment information hasbeen elicited and the payment subdialogue can beconcluded ?
at which point control is passed backto the AccommodationExpert.4.4 Dialogue frames and user-led focus shiftsHowever, a mixed initiative dialogue managerneeds to be able to cope with user-initiated shiftsof discourse focus.
For example, a user may supplyaddress information unprompted while thesystem?s intention is first to elicit the informationshown on the user?s credit card.
At present wepermit transfer of dialogue control between serviceagents: a user may, for example, want to discuss anevent booking more or less in parallel with makingaccommodation arrangements.
In order to groundthe dialogue by eliciting information in a definitecontext, we impose some restrictions on user-initiated shifts of focus between support dialogues,and between support and service dialogues.Dialogue frames are instrumental in implementingthese policies.Dialogue frames help identify the supportdialogues associated with each service dialogue:the specification of each frame type (e.g.
anAccommodationDialogueFrame) indicates the typeof each of its Attributes, some of which maythemselves be links to other frames (e.g.
aPaymentDialogueFrame).
Dialogue frames thatare associated with service dialogues can beexpanded into a tree-like structure by recursivelytraversing the various support frames that arelinked to the service dialog frame.
For thoseframes which have already been in the discoursefocus (i.e.
frames representing dialogue tasks thathave already been the subject of user-systeminteraction), this is a straightforward task.Additionally the frames of possible future handlingagents can be predicted and included within thetree through the use of the DomainSpotter.
Forexample, at the outset of an accommodationenquiry, the related service dialogue frame will notgenerally contain an explicitly linked paymentframe.
However, the DomainSpotter is able todetermine which agents can provide paymentsupport, and so the system generates a number ofpotential discourse paths relating to payment.
Keywords in the user?s utterances determine whichpath is in fact used and which payment-relatedframes are linked to the accommodation frame.As the dialogue evolves, the DomainSpottertests which agents are best placed to handle theuser?s last utterance: the tree of dialogue framesindicates to the DomainSpotter which supportagents have been or may be involved in the currentservice enquiry, and should therefore beconsidered; the DomainSpotter will poll serviceagents as a matter of course.
If the user?s utteranceis scored most highly by a support agent (relevantto the current service) whose topic has alreadybeen in the discourse focus, the user can return tothis topic (the shift may indicate the user?sintention to add to or modify information that waspreviously supplied).
As a safeguard, the systemplaces on the ExpertFocusStack any support agentswhose rules fired on the previous path to therevisited agent, and these support agents will beallowed to test their rules again (new addressinformation, for instance, may affect a credit cardoption ?
e.g.
if the revised address is in UK, theCreditCardExpert may mention UK cardholderoffers, etc.).
The system uses the linked dialogueframes of topics that have already been in thediscourse focus to determine the order in whichsuch support experts should be placed on to theExpertFocusStackOther requests for shifts of focus from andbetween support agents are generally deferred(?Thanks, I?ll take the address details in amoment??
), until the rules of the current supportexpert allow transfer.
The system does not ignorethe contents of the utterance that led to thedeferral: the DiscourseHistory contains anUtteranceStore, a stack of the parses of the user?sutterances.
When it takes control of the dialogue,because one of the handling expert?s rules hasallowed it to, an agent first looks to theUtteranceStore to see if there is any unprocessedinformation that it can handle.
If there is, it takesthe unprocessed parsed information and begins itsprocessing as usual with its inherited confirmationstrategy and its domain-specific expert rules (?Soyou said the street address was 18 Malone Road.Can I have the city please??
).5 The Queen?s Communicator in actionThe following portion of dialogue is typical ofthe exchanges currently supported by the system.User utterances are shown as U1, U2, etc.
Systemutterances (S1a,?, S2, etc.)
are taken from ournew natural language generation (NLG) module,which we are continuing to develop.
The NLGmodule takes as its input the semantic constructsoutput from the DM.
These constructs are shownthus: MESSAGE: process?, etc.
A briefcommentary, indicating which main features of theDM are being called into play, is given at keypoints in the dialogue and is printed in italics.U1: I?d like to book a three-star hotel in Belfastfrom the fifteenth of August to the twentieth ofAugust.Key words like three-star and hotel fall withinthe accommodation domain, and are scored by theAccommodationExpert .
Accordingly the Domain-Spotter appoints the AccommodationExpert?handling agent?.
The AccommodationExpertpopulates its AccommodationDialogFrame withwhatever relevant information has been suppliedby the user.S1a:  OK, let's start a new accommodationbooking.
OK, that's a three-star hotel in Belfastfrom 2004-08-15 until 2004-08-20.
Please wait...MESSAGE: process accommodationbookingMESSAGE: GIVENAccoType [ HOTEL  ]AccoClass [ three-star  ]Location [ BELFAST  ]DateFrom [ 2004-08-15 ]DateTo [ 2004-08-20 ]MESSAGE: database enquiry initiatedThe AccommodationExpert uses the genericconfirmation strategies that it has inherited fromthe DiscourseManager to implicitly confirm newvalues, and it uses its own domain-specific rules toinitiate a database lookup that will retrieve namesof hotels that match the user?s criteria.S1b: You can choose between the following: theJurys or Lisdara.
Which would you prefer?PROMPT: SPECIFYAccoName [ jurys  ][ lisdara  ]U2:  Could you make that a four-star?Although the system in its utterance suggeststhat the user should select one of the hotel namesretrieved from the database, the user may provideinformation different to that which was requested,since this is a mixed initiative system.
In this casethe user changes the star-rating, instead ofselecting a hotel name.S2: Ok, got it.
So that's a four-star?MESSAGE: user changed valueAccoClass [ four-star  ]QUERY: confirm changesAgain, using its inherited confirmation strategy,the AccommodationExpert compares the value forthe star-rating in the previous frame with the star-rating in the current frame and performs a ?repair-confirm?
on the changed value.U3: Yes, that?s right.S3a:  Please wait...MESSAGE: database enquiry initiatedS3b:  You can choose between the following: theEuropa,  Malone Lodge,  Stormont or Holiday Inn.Which would you prefer?PROMPT: SPECIFYAccoName [  europa  ][  malone-lodge  ][  stormont  ][  holiday-inn  ]U4:  I?ll go for a double room at the Europa.S4:  So that's the four-star Europa hotel inBelfast with a double room, from 2004-08-15 until2004-08-20.
Is that correct?MESSAGE: explicit confirm valuesAccoName [ europa  ]AccoType [ HOTEL  ]AccoClass [ four-star  ]Location [ BELFAST  ]AccoRoomType [ double  ]DateFrom [ 2004-08-15 ]DateTo [ 2004-08-20 ]QUERY: CONFIRM valuesIn the current system implementation thehandling agent explicitly confirms all ?key?
valuesneeded to conclude a major segment of thediscourse ?
once these have been supplied by theuser.U5:  Make that a single room.In this case, however, the user again changeshis/her mind.
The immediate next steps in thedialogue (not shown here) would be to reconfirmthe ?key?
values, including the newly changedvalue; then ask if the user wishes to checkavailability and reserve; and if so elicit paymentdetails with the aid of the PaymentExpert andAddressExpert components...6 Related workAlthough some currently available dialoguesystems use object components in accordance withthe latest software engineering orthodoxy ?
(Allenet al, 2000) ?
little published research addressesthe question of how established techniques ofobject-oriented software engineering (Booch,1994) (Booch et al, 1998) can contribute to thedialogue management task.Some research groups confirm the suitability ofJava for the development of interactive, agent-based systems ?
for example COLLAGEN (Rich etal.
2001).
Indeed, the COLLAGEN architecture,like that of the Queen?s Communicator, managesdiscourse using a ?focus stack?, a classical idea inthe theory of discourse structure (Grosz andSidner, 1986).For dialogues that are not primarily transaction-based or frame-based, and where the system mustestablish the user?s broader objectives beforeoffering advice or presenting options, a discoursemanagement strategy based on problem-solving(PS) objects (objectives, recipes, actions andresources) is appropriate (Blaylock et al, 2003).We are currently investigating means of using PSobjects to orient a dialogue, before using expertiselike that currently encapsulated in our domainagents to complete those frame-filling tasks thatare needed to support the user?s objectives.7 ConclusionsWe have decomposed the cross-domain dialoguemanagement task intuitively into a number of sub-dialogues, each conducted by an implementeddomain specialist with its own expert rules andassociated frame of information to collect.
Byusing inheritance we easily establish a commonapproach to dialogue management, independent ofdomain: all experts inherit the same confirmationstrategy.
Through inheritance we ensure thatdomain experts have common characteristics: theyall have sequences of ?expert rules?
that they canapply to user-supplied information to determinewhat the system should do next.
Domain spottingenables us to identify appropriate dialoguehandling expertise for each of the user?s utterances.Since our DomainSpotter actively looks forrelevant expertise amongst the cohort of serviceand support agents, new expertise can readily beadded without disturbing the system?s fundamentaldialogue management strategies.
Additionally,division of the available experts into (front-line)service agents and (ancillary) support experts helpsus maintain discourse context by deferring user-ledshifts of focus that interrupt coherent dataelicitation.Future developments are likely to include:addition of new dialogue domains (e.g.
travel); andincorporation of multiple dialogue strategies (usingframes for mixed initiative transactions, PS objectsfor collaborative problem solving, and finite statetransition networks for system-led interaction).Multimodal input will also be considered,including input relating to the user?s emotionalstate, as a factor for dynamically determining anappropriate dialogue strategy for a particulardiscourse segment.8 AcknowledgementsThis research is supported by the EPSRC undergrant number GR/R91632/01.ReferencesJ.
Allen, D. Byron, M. Dzikovska, G. Ferguson, L.Galescu and A. Stent.
2000.
An Architecture fora Generic Dialogue Shell.
Natural LanguageEngineering 6 (3?4), pp.
1-16, CambridgeUniversity Press.N.
Blaylock, J. Allen and G. Ferguson.
2003.Managing communicative intentions withcollaborative problem solving.
Current and NewDirections in Discourse and Dialogue (eds.
J.van Kuppevelt and R. Smith), pp.
63 ?
84,Kluwer, Dordrecht.G.
Booch.
1994.
Object-Oriented Analysis andDesign with Applications (2nd Edition).Benjamin/Cummings, Redwood City, CA.G.
Booch, J. Rumbaugh and I. Jacobson.
1998.
TheUnified Modeling Language User Guide.Addison Wesley Longman, Reading, MA.B.
Grosz and C. Sidner.
1986.
Attention,Intentions, and the Structure of Discourse.Computational Linguistics, 12:3, pp.
175 ?
204,Cambridge, MA.P.
Heisterkamp and S. McGlashan.
1996.
Units ofDialogue Management: An Example.Proceedings of ICSLP96, pp.
200?203,Philadelphia.I.
O?Neill and M. McTear.
2000.
Object-OrientedModelling of Spoken Language DialogueSystems.
Natural Language Engineering 6 (3?4), pp.
341?362, Cambridge University Press.I.
O?Neill and M. McTear.
2002.
A PragmaticConfirmation Mechanism for an Object-BasedSpoken Dialogue Manager.
Proceedings ofICSLP-2002, Vol.
3, pp.
2045?2048.
Denver,CO.I.
O?Neill, P. Hanna, X. Liu and M. McTear.
2003.The Queen?s Communicator: an Object-OrientedDialogue Manager.
Proceedings of Eurospeech2003, pp.
593?596, Geneva.C.
Rich, C. Sidner and N. Lesh.
2001.COLLAGEN: Applying Collaborative DiscourseTheory to Human-Computer Interaction.Artificial Intelligence Magazine, Vol 22, Issue 4,pp.
15-25, Menlo Park, CA.A.
Rudnicky and W. Xu.
1999.
An agenda-baseddialog management architecture for spokenlanguage systems.
Proceedings of IEEEAutomatic Speech Recognition andUnderstanding Workshop, p. I?337.M.
Turunen and J. Hakulinen.
2001.
Agent-BasedAdaptive Interaction and Dialogue ManagementArchitecture for Speech Applications.
TextSpeech and Dialogue?Proceedings of the FourthInternational Conference TSD, pp.
357?364.W.
Ward.
1994.
Extracting information inspontaneous speech.
Proceedings of ICSLP 94,pp.
83?86, Yokohama.
