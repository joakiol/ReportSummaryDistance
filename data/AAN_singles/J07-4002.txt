SquibPrepositional Phrase Attachment without OraclesMichaela Atterer?University of StuttgartHinrich Schu?tze?
?University of StuttgartWork on prepositional phrase (PP) attachment resolution generally assumes that there is anoracle that provides the two hypothesized structures that we want to choose between.
Theinformation that there are two possible attachment sites and the information about the lexicalheads of those phrases is usually extracted from gold-standard parse trees.
We show that theperformance of reattachment methods is higher with such an oracle than without.
Because oraclesare not available in NLP applications, this indicates that the current evaluation methodology forPP attachment does not produce realistic performance numbers.
We argue that PP attachmentshould not be evaluated in isolation, but instead as an integral component of a parsing system,without using information from the gold-standard oracle.1.
IntroductionOne of the main challenges in natural language parsing is the resolution of ambiguity.One frequently studied type of ambiguity is prepositional phrase (PP) attachment.Given the quadruple (v,n1,p,n2), where v is the head of a verb phrase, n1 is the headof an NP1 dominated by v, p is the head of a prepositional phrase, and n2 the head of anNP2 embedded in the PP, the task of PP attachment is to determine whether we shouldattach the PP to the verb v or the noun n1 (Hindle and Rooth 1993).1Work on PP attachment resolution generally assumes that there is an oracle thatprovides the quadruple (v,n1,p,n2), where we define an oracle as a mechanism that pro-vides information that is not present in the data in their naturally occurring form.
In PPattachment, the oracle is usually implemented by extracting the quadruple (v,n1,p,n2)from the gold-standard parse trees.
In an application, a PP attachment module wouldbe used to change the attachment of prepositional phrases in preliminary syntacticanalyses produced by a parser?or reattach them.
The problem with oracle-based workon PP attachment is that when the parser does not find the gold-standard NP1 or PP, forinstance, the attachment ambiguity is not recognized, and the correct solution cannot?
Institute for Natural Language Processing, University of Stuttgart, Azenbergstr.
12, 70174 Stuttgart,Germany.
E-mail: atterer@ims.uni-stuttgart.de.??
Institute for Natural Language Processing, University of Stuttgart, Azenbergstr.
12, 70174 Stuttgart,Germany.
E-mail: hinrich@hotmail.com.1 PP attachment ambiguities also occur in constructions other than V NP PP (Mitchell 2004).
These casesare less frequent and in our opinion do not affect the main conclusions of this article.Submission received: 13 January 2007, accepted for publication: 7 May 2007.?
2007 Association for Computational LinguisticsComputational Linguistics Volume 33, Number 4Table 1Performance of Collins and Brooks (C&B), Olteanu and Moldovan (O&M) and Toutanova,Manning, and Ng (TM&N) on RRR when no resources other than the training set are used.Algorithm Accuracy (%)C&B 84.18O&M 84.60TM&N 85.86be found by the PP attachment method.
Likewise, it is harder for the reattachmentmethod to find the correct attachment if the heads n1 or n2 are not correctly identifiedby the parser.
The oracle approach to PP attachment differs from many other tasks inNLP like part-of-speech tagging or parsing, in which usually no data based on manualannotation are part of the input.
Thus, published evaluation results for tagging andparsing accurately reflect the performance we would expect in an application whereasPP reattachment results arguably do not.We will show in this article that the performance of reattachment methods is higherwhen an oracle is available.
This means that the current evaluation methodology forPP attachment does not produce realistic performance numbers.
In particular, it is notclear whether reattachment methods improve the parses of state-of-the-art parsers.
Thisargues for a new evaluation methodology for PP attachment, one that does not assumethat an oracle is available.To create a more realistic setup for PP reattachment, we replace the oracle withBikel?s parser (Bikel 2004).
With the removal of the oracle and the introduction of theparser, the baseline performance also changes.
It is no longer the performance of alwayschoosing the most frequent attachment.
Instead, it is the attachment performance of theparser.
In fact, we will see that it is surprisingly difficult for reattachment methods tobeat this baseline performance.The fact that standard parsers perform well on PP attachment also prompted usto investigate the performance of a standard parser on traditional oracle-based PP-attachment.
We find that standard parsers do well, further questioning the soundnessof the traditional evaluation methodology.We compare our results with three other approaches: Collins and Brooks (1995;henceforth C&B), Olteanu and Moldovan (2005; henceforth O&M), and Toutanova,Manning, and Ng (2004; henceforth TM&N).
We call these three methods PP reattach-ers.
We selected these three methods because they perform best on the widely used PPattachment evaluation set created by Ratnaparkhi, Reynar, and Roukos (1994).
We callthis data set RRR.
RRR consists of 20,801 training and 3,097 test quadruples of the form(v,n1,p,n2).
The performance of the three reattachers on RRR is shown in Table 1.2This article is structured as follows.
Section 2 compares the performance of thereattachers on oracle-based reattachment with that of a standard parser (using artificialsentences built from the RRR set) and finds no significant difference in performance.In Section 3, we look at reattachment without oracles (using the Penn Treebank) andargue that realistic performance numbers can only be produced in experiments withoutoracles.
Sections 4 and 5 discuss the experiments and related work.
Section 6 concludes.2 The table shows the performance of the algorithms when only treebank information is used andno information from other resources, such as WordNet.470Atterer and Schu?tze PP Attachment Without Oracles2.
Experiment 12.1 MethodWe use the Bikel parser (Bikel 2004) with default settings for training and parsing.In Experiment 1, we convert the RRR set into artificial sentences.
The data consist ofquadruples of the form (v,n1,p,n2): verb, noun, preposition, and embedded noun.
Tocreate sentences, we add the generic subject they.
For example, the quadruple join boardas director V becomes:( (S (NP (PRP They) ) (VP (VB join) (NP (NN board) ) (PP (IN as)(NN director) ) ) (.
.)
) )Note that these artificial sentences are not necessarily grammatically correct.
Forexample, subject and verb need not agree.When we train on these artificial sentences, attachment decisions are independentof the embedded noun n2 because the Bikel parser does not percolate non-head infor-mation up the tree.
We therefore call this experiment bilexical because we only usestandard lexical head?head relationships.
To simulate a parser that takes into accountall four elements of the quadruple, we annotate the preposition with the embeddednoun:( (S (NP (PRP They) ) (VP (VB has) (NP (NP (NN revenue) )(PP (IN ofmillion) (NN million) ) ) ) (.
.)
) )We call this mode trilexical because we effectively model three-word dependencies(e.g., have-of-million vs. revenue-of-million).
To avoid problems with sparseness, we re-strict the annotation to the N most frequent n2 nouns of the RRR train data.
We choseN = 20 based on the performance on the development set.32.2 ResultsTable 2 shows the accuracy of Bikel?s parser in bilexical and trilexical mode.
The parsersometimes does not recognize the attachment ambiguity.
For example, it may fail tocorrectly identify the PP.
We call these cases NAs (non-attachment cases) and computethree different evaluation measures:NA-error NAs are counted as errors.NA-default Noun attachment (the more frequent attachment) is chosen for NAs.NA-disc(ard) NAs are discarded from the evaluation.We assume that a reattacher like C&B could only be applied to sentences where theambiguity is recognized, namely, non-NA cases.
It would then change the attachmentdecision in these cases.
After reattaching, for this particular set of cases, the accuracywould correspond to the reattachment method?s accuracy.
We are interested in whetherthe reattacher is able to beat the performance of the parser we use.3 On the development set, performance dropped around 0.5 percentage points when using N = 10, 0.3percentage points when using N = 30, and 0.9 percentage points when using N = 50, for instance.471Computational Linguistics Volume 33, Number 4Table 2Accuracy (Acc) in percent of the Bikel parser on RRR.
For NA-discard, the size of the test setis indicated.NA Acc C&B O&M TM&NSignificantly different?bilex error 83.18 no no yes?bilex default 83.44 no no yes?bilex disc; 3,082 trees 83.58 no no yestrilex error 83.73 no no yestrilex default 83.98 no no yestrilex disc; 3,082 trees 84.13 no no noNote: The last three columns show whether differences to C&B, O&M, and TM&N are significantat the 0.05 level (?yes?)
or 0.01 level (?yes??)
(?2 test).The Bikel parser?s performance (without changing attachments) is slightly lowerthan C&B?s, O&M?s, and TM&N?s.
However, for the trilexical case, the difference isnot statistically significant for NA-discard.
We consider NA-discard to be the mostrealistic evaluation measure, because when integrated into a parser, reattachers can onlycorrect the attachment in those sentences where the attachment ambiguity was correctlyidentified.
The parser often identifies one of the possible attachments correctly, but notthe other.
The reattacher cannot operate on these sentences.The significance for the NA-discard case was calculated using the results of O&Mand TM&N on the same 3,082 sentences (which O&M and TM&N kindly provided tous) and the results of our implementation of the C&B-algorithm.3.
Experiment 2The setup in Experiment 1 is typical of work on PP attachment, but it is not a realisticmodel of PP attachment in practice.
In Experiment 2, we look at reattachment in natu-rally occurring sentences if an oracle that identifies the two alternative attachments isnot available.We first tried to convert RRR into a set of sentences by identifying for each quadru-ple the sentence in the Penn Treebank (PTB) 0.5 it was extracted from.
However, wewere not able to train the Bikel parser on this set because of inconsistencies and otherproblems (truncated incomplete sentences, etc.)
with the 0.5 treebank.
On the otherhand, it was not straightforward to create training, test, and development sets fromPTB 3, which contains the corresponding sentences.
Due to changes in the treebankversions, a considerable number of the quadruples was missing in PTB 3.For these reasons, we identified as our test data the 3,097 PTB 0.5 sentences the RRRquadruples had been extracted from because for testing we only need string inputs (andthe gold-standard attachment annotations of the quadruples).Our training data consist of those 45,156 PTB 3 sentences that remain of the totalnumber of 49,208 PTB 3 sentences after removing (i) the 3,097 test sentences and (ii)PTB 3 sentences that correspond to RRR development set quadruples.
(Note that sometest sentences had no corresponding sentence in PTB 3.
)We call this evaluation set (45,156 PTB 3 training sentences, 3,097 PTB 0.5 testsentences) RRR-sent.
The RRR-sent training set contains a mixture of sentences with472Atterer and Schu?tze PP Attachment Without Oraclesand without PP attachment ambiguities.
We believe that this is the optimal experimentalsetup because parsers are usually not trained on a subset of sentences with a particularconstruction.
RRR-sent is available at http://ifnlp.org/?schuetze/rrr-sent.3.1 MethodIn bilexical mode, we trained and tested the parser as before except that RRR-sent wasused instead of RRR-based artificial sentences.
In trilexical mode, we first trained aparser and ran it on the test data to identify the n2 heads of embedded noun phrases.We then head-annotated the prepositions in RRR-sent (both train and test data) usingthis parser (restricted to the N nouns selected previously).
Other prepositions wereleft unchanged.
Note that prepositions also remain unannotated in sentences wherethe parser does not recognize the embedding PP.
We then trained and tested a secondinstance of the Bikel parser on the head-annotated data.3.2 ResultsTable 3 shows results for Experiment 2.
There are many more things that can go wrongin a long natural sentence than in a 5-word artificial one.
Thus, the parser recognizesthe PP ambiguity less often in this experiment without an oracle than in Experiment 1,where an oracle was available.There is only a significant difference for NA-error and NA-default (for the latter notin all cases).
For NA-discard there is no significant difference.4.
DiscussionIn Experiments 1 and 2 the cases in NA-discard are the only ones where an ambiguitycould be identified by the parser and hence the only ones where the reattachmentmethods could actually be employed.
But the reattachers fail to considerably improvethe parser on these sentences.
It is only the absence of an oracle that makes the parserseem worse in the NA-error and NA-default cases.
This result shows that PP attachmentmethods need to be evaluated with respect to whether they can improve a parser.In the second experiment the results are worse for the trilexical case, that is, whenwe use information about the noun in the PP.
We believe that one reason for this is thatwe cannot identify the head noun n2 with certainty due to incorrect preliminary parses.Table 3Accuracy (Acc) in percent of the Bikel parser on RRR-sent.NA Acc C&B O&M TM&Nbilex error 80.01 yes?
yes?
yes?bilex default 82.75 no no yes?bilex disc; 2,945 trees 84.14 no no notrilex error 72.01 yes?
yes?
yes?trilex default 79.85 yes?
yes?
yes?trilex disc; 2,652 trees 84.09 no no noNote: ?yes??
marks significance at the 0.01 level.
See text for further explanations.473Computational Linguistics Volume 33, Number 4This again points to the methodological problems in previous work on PP attachment:it relies on an oracle that provides the two alternative attachments, including the fourheads involved.
Results on the traditional task have a tenuous relation at best to perfor-mance on PP attachment if no oracle is available.The results of Experiments 1 and 2 are not directly comparable.
A significant num-ber of quadruples (more than 1,000) in the RRR training set do not occur in the RRR-senttraining set due to differences between the 0.5 and 3 treebanks.
Conversely, at least asmany of the quadruples we extracted from the training set in RRR-sent do not matchquadruples in RRR.5.
Related WorkAlmost all prior work on PP attachment has adopted what we call the oracle-basedapproach (Stetina and Nagao 1997; Ratnaparkhi 1998; Pantel and Lin 2000; Olteanu2004; Bharati, Rohini, Vishnu, Bendre, and Sangal 2005), including several recent papers(Calvo, Gelbukh, and Kilgarriff 2005; Merlo and Ferrer 2006; Volk 2006; Srinivas andBhattacharyya 2007).
None of these papers attempt to improve a parser in a realisticparsing situation.However, a few studies were published recently that do evaluate PP attachmentwithout oracles (Olteanu 2004; Atterer and Schu?tze 2006; Foth and Menzel 2006).
Ourexperimental results suggest that the evaluation strategy of integrating PP reattachersinto a baseline parser should be adopted more widely.As we only use a parser and no additional resources such as WordNet, dictionaries,Web data, or named-entity recognizers and stemmers, we restrict ourselves to com-paring non-oracle reattachment to work that is evaluated using the training data only(and no other resources) as input.
Although we have not replicated experiments withadditional resources (e.g., Toutanova, Manning, and Ng 2004; Stetina and Nagao 1997),the question as to the significance of oracle-based results for realistic NLP applicationsarises independently of the use of resources.6.
ConclusionOur experiments show that oracle-based evaluation of PP attachment can be mislead-ing.
Comparing the bilexical and trilexical cases we note the following: when accuraten2 information (i.e., oracle-based information about which word heads NP2) is addedin Experiment 1, disambiguation results improve.
When noisy n2-information is addedin Experiment 2 (in the absence of an oracle), disambiguation results get worse.
Simi-larly, oracle-based disambiguation performance (84.14%) is much higher than unaidedperformance (80.01%) in Experiment 2.It is not clear from our results whether or not PP reattachers perform better thanstate-of-the-art parsers.
Although the differences between the best parsing results andthe best reattacher results are not significant in Experiments 1 and 2, the reattachers hadconsistently higher performance.
This makes it likely that PP reattachment (performedeither by a reattacher or by a reranker [Charniak and Johnson 2005; Collins and Koo2005] that processes a feature representation with PP attachment information) wouldimprove the parsing results of state-of-the-art parsers.
This is a promising direction forfuture work on PP reattachment.Our results suggest that the standard oracle-based method for evaluating PP attach-ment is problematic.
It computes numbers that are overly optimistic when compared to474Atterer and Schu?tze PP Attachment Without Oraclesthe performance that is to be expected in realistic applications without oracles.
Instead,PP reattachers should be directly compared to state-of-the-art parsers to show that theyare able to exploit statistical information that current parsing methods ignore.
Mostimportantly, PP reattachers should be tested on the type of data they are intended toprocess?output from a parser or another module that detects PP attachment ambigu-ities.
Evaluating reattachers on the output of an oracle allows no inferences as to theirreal performance.Many advances in NLP in the last decades have been driven by shared tasks, andPP attachment is one of the tasks that has stimulated much interesting research.
Thereare no realistic scenarios in which an oracle for PP attachment ambiguity would beavailable, however.
Given the differences we have found between evaluations with andwithout oracles, one should think carefully about the experimental framework for PPattachment work one adopts and whether any oracle-based findings carry over to morerealistic scenarios without oracles.Although we are only concerned with PP attachment in this article, similar consider-ations likely apply to other disambiguation tasks such as attachment of relative clausesand coordinated phrases.
In our opinion the evaluation of disambiguation algorithmson oracle-based data should always be justified by stating specifically what has beenlearned for the non-oracle case.AcknowledgmentsWe would like to thank Marian Olteanu and Kristina Toutanova for their evaluation results andHelmut Schmid and the reviewers for valuable comments.ReferencesAtterer, Michaela and Hinrich Schu?tze.
2006.The effect of corpus size in combiningsupervised and unsupervised training fordisambiguation.
In Proceedings of the JointConference of the International Committee onComputational Linguistics and the Associationfor Computational Linguistics (COLING/ACL 2006) Main Conference Poster Sessions,pages 25?32, Sydney, Australia.Bharati, Akshar, U. Rohini, P. Vishnu,Sushma Bendre, and Rajeev Sangal.2005.
A hybrid approach to single andmultiple PP attachment using WordNet.In Proceedings of International JointConference on Natural Language Processing(IJCNLP) 2005, pages 211?222, JejuIsland, Korea.Bikel, Daniel M. 2004.
Intricacies of Collinsparsing model.
Computational Linguistics,30(4):479?512.Calvo, Hiram, Alexander Gelbukh, andAdam Kilgarriff.
2005.
Distributionalthesaurus vs. WordNet: A comparisonof backoff techniques for unsupervisedPP attachment.
In Proceedings of the SixthInternational Conference on Intelligent TextProcessing and Computational Linguistics(CICLing-2005), pages 177?188, MexicoCity, Mexico.Charniak, Eugene and Mark Johnson.
2005.Coarse-to-fine n-best parsing and MaxEntdiscriminative reranking.
In Proceedings ofthe 43rd Annual Meeting of the Associationfor Computational Linguistics (ACL),pages 173?180, Ann Arbor, MI.Collins, Michael and James Brooks.
1995.Prepositional phrase attachment througha backed-off model.
In Proceedings of theThird Workshop on Very Large Corpora,pages 27?38, Somerset, NJ.Collins, Michael and Terry Koo.
2005.Discriminative reranking for naturallanguage parsing.
ComputationalLinguistics, 31(1):25?70.Foth, Kilian A. and Wolfgang Menzel.
2006.The benefit of stochastic PP attachmentto a rule-based parser.
In Proceedingsof the Joint Conference of the InternationalCommittee on Computational Linguistics andthe Association for Computational Linguistics(COLING/ACL) 2006 Main Conference PosterSessions, pages 223?230, Sydney, Australia.Hindle, Donald and Mats Rooth.
1993.Structural ambiguity and lexical relations.Computational Linguistics, 19(1):103?120.Merlo, Paola and Eva Esteve Ferrer.
2006.The notion of argument in prepositionalphrase attachment.
ComputationalLinguistics, 32(3):341?378.475Computational Linguistics Volume 33, Number 4Mitchell, Brian.
2004.
Prepositional PhraseAttachment using Machine LearningAlgorithms.
Ph.D. thesis, NaturalLanguage Processing Group,Department of Computer Science,University of Sheffield, UK.Olteanu, Marian and Dan Moldovan.2005.
PP-attachment disambiguationusing large context.
In Proceedingsof Human Language TechnologyConference/Conference on EmpiricalMethods in Natural Language Processing(HLT/EMNLP), pages 273?280,Vancouver, Canada.Olteanu, Marian G. 2004.
Prepositionalphrase attachment ambiguityresolution through a rich syntactic,lexical and semantic set of featuresapplied in support vector machineslearner.
Masters thesis, University ofTexas, Dallas.Pantel, Patrick and Dekang Lin.
2000.
Anunsupervised approach to prepositionalphrase attachment using contextuallysimilar words.
In Proceedings of the 38thAnnual Meeting of the Association forComputational Linguistics (ACL),pages 101?108, Hong Kong, China.Ratnaparkhi, Adwait.
1998.
Unsupervisedstatistical models for prepositional phraseattachment.
In Proceedings of InternationalConference on Computational Linguistics andthe Association for Computational Linguistics(COLING-ACL98), pages 1079?1085,Montreal, Canada.Ratnaparkhi, Adwait, Jeff Reynar, andSalim Roukos.
1994.
A maximum entropymodel for prepositional phraseattachment.
In Workshop on HumanLanguage Technology, pages 250?255,Plainsboro, NJ.Srinivas, Medimi and PushpakBhattacharyya.
2007.
A flexibleunsupervised PP-attachment methodusing semantic information.
In Proceedingsof Internationl Joint Conference on ArtificialIntelligence (IJCAI 2007), pages 1677?1682,Hyderabad, India.Stetina, Jiri and Makoto Nagao.
1997.Corpus based PP attachment ambiguityresolution with a semantic dictionary.In Proceedings of the Fifth Workshop onVery Large Corpora, pages 66?80, HongKong, China.Toutanova, Kristina, Christopher D.Manning, and Andrew Y. Ng.
2004.Learning random walk models forinducing word dependency distributions.In Proceedings of the Twenty-firstInternational Conference on MachineLearning (ICML ?04), pages 815?822,Banff, Alberta, Canada.Volk, Martin.
2006.
How bad is the problemof PP-attachment?
A comparison ofEnglish, German and Swedish.
InProceedings of Association for ComputationalLinguistics?Special Interest Group onComputational Semantics (ACL-SIGSEM)Workshop on Prepositions, pages 81?88,Trento, Italy.476
