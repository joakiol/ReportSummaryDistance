Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 791?799,Suntec, Singapore, 2-7 August 2009. c?2009 ACL and AFNLPSource-Language Entailment Modeling for Translating Unknown TermsShachar Mirkin?, Lucia Specia?, Nicola Cancedda?, Ido Dagan?, Marc Dymetman?, Idan Szpektor??
Computer Science Department, Bar-Ilan University?
Xerox Research Centre Europe{mirkins,dagan,szpekti}@cs.biu.ac.il{lucia.specia,nicola.cancedda,marc.dymetman}@xrce.xerox.comAbstractThis paper addresses the task of handlingunknown terms in SMT.
We propose us-ing source-language monolingual modelsand resources to paraphrase the source textprior to translation.
We further present aconceptual extension to prior work by al-lowing translations of entailed texts ratherthan paraphrases only.
A method forperforming this process efficiently is pre-sented and applied to some 2500 sentenceswith unknown terms.
Our experimentsshow that the proposed approach substan-tially increases the number of properlytranslated texts.1 IntroductionMachine Translation systems frequently encounterterms they are not able to translate due to somemissing knowledge.
For instance, a Statistical Ma-chine Translation (SMT) system translating thesentence ?Cisco filed a lawsuit against Apple forpatent violation?
may lack words like filed andlawsuit in its phrase table.
The problem is espe-cially severe for languages for which parallel cor-pora are scarce, or in the common scenario whenthe SMT system is used to translate texts of a do-main different from the one it was trained on.A previously suggested solution (Callison-Burch et al, 2006) is to learn paraphrases ofsource terms from multilingual (parallel) corpora,and expand the phrase table with these para-phrases1.
Such solutions could potentially yield aparaphrased sentence like ?Cisco sued Apple forpatent violation?, although their dependence onbilingual resources limits their utility.In this paper we propose an approach that con-sists in directly replacing unknown source terms,1As common in the literature, we use the term para-phrases to refer to texts of equivalent meaning, of any lengthfrom single words (synonyms) up to complete sentences.using source-language resources and models in or-der to achieve two goals.The first goal is coverage increase.
The avail-ability of bilingual corpora, from which para-phrases can be learnt, is in many cases limited.On the other hand, monolingual resources andmethods for extracting paraphrases from monolin-gual corpora are more readily available.
Theseinclude manually constructed resources, such asWordNet (Fellbaum, 1998), and automatic meth-ods for paraphrases acquisition, such as DIRT (Linand Pantel, 2001).
However, such resources havenot been applied yet to the problem of substitut-ing unknown terms in SMT.
We suggest that byusing such monolingual resources we could pro-vide paraphrases for a larger number of texts withunknown terms, thus increasing the overall cover-age of the SMT system, i.e.
the number of texts itproperly translates.Even with larger paraphrase resources, we mayencounter texts in which not all unknown terms aresuccessfully handled through paraphrasing, whichoften results in poor translations (see Section 2.1).To further increase coverage, we therefore pro-pose to generate and translate texts that convey asomewhat more general meaning than the originalsource text.
For example, using such approach,the following text could be generated: ?Cisco ac-cused Apple of patent violation?.
Although less in-formative than the original, a translation for suchtexts may be useful.
Such non-symmetric relation-ships (as between filed a lawsuit and accused) aredifficult to learn from parallel corpora and there-fore monolingual resources are more appropriatefor this purpose.The second goal we wish to accomplish byemploying source-language resources is to rankthe alternative generated texts.
This goal can beachieved by using context-models on the sourcelanguage prior to translation.
This has two advan-tages.
First, the ranking allows us to prune some791candidates before supplying them to the transla-tion engine, thus improving translation efficiency.Second, the ranking may be combined with targetlanguage information in order to choose the besttranslation, thus improving translation quality.We position the problem of generating alterna-tive texts for translation within the Textual Entail-ment (TE) framework (Giampiccolo et al, 2007).TE provides a generic way for handling languagevariability, identifying when the meaning of onetext is entailed by the other (i.e.
the meaning ofthe entailed text can be inferred from the mean-ing of the entailing one).
When the meanings oftwo texts are equivalent (paraphrase), entailmentis mutual.
Typically, a more general version ofa certain text is entailed by it.
Hence, through TEwe can formalize the generation of both equivalentand more general texts for the source text.
Whenpossible, a paraphrase is used.
Otherwise, an alter-native text whose meaning is entailed by the orig-inal source is generated and translated.We assess our approach by applying an SMTsystem to a text domain that is different from theone used to train the system.
We use WordNetas a source language resource for entailment rela-tionships and several common statistical context-models for selecting the best generated texts to besent to translation.
We show that the use of sourcelanguage resources, and in particular the extensionto non-symmetric textual entailment relationships,is useful for substantially increasing the amount oftexts that are properly translated.
This increase isobserved relative to both using paraphrases pro-duced by the same resource (WordNet) and us-ing paraphrases produced from multilingual paral-lel corpora.
We demonstrate that by using simplecontext-models on the source, efficiency can beimproved, while translation quality is maintained.We believe that with the use of more sophisticatedcontext-models further quality improvement canbe achieved.2 Background2.1 Unknown TermsA very common problem faced by machine trans-lation systems is the need to translate terms (wordsor multi-word expressions) that are not found inthe system?s lexicon or phrase table.
The reasonsfor such unknown terms in SMT systems includescarcity of training material and the applicationof the system to text domains that differ from theones used for training.In SMT, when unknown terms are found in thesource text, the systems usually omit or copy themliterally into the target.
Though copying the sourcewords can be of some help to the reader if theunknown word has a cognate in the target lan-guage, this will not happen in the most generalscenario where, for instance, languages use dif-ferent scripts.
In addition, the presence of a sin-gle unknown term often affects the translation ofwider portions of text, inducing errors in both lex-ical selection and ordering.
This phenomenon isdemonstrated in the following sentences, wherethe translation of the English sentence (1) is ac-ceptable only when the unknown word (in bold) isreplaced with a translatable paraphrase (3):1.
?.
.
.
, despite bearing the heavy burden of theunemployed 10% or more of the labor force.?2.
?.
.
.
, malgre?
la lourde charge de compte le10% ou plus de cho?meurs labor la force .?3.
?.
.
.
, malgre?
la lourde charge des cho?meursde 10% ou plus de la force du travail.
?Several approaches have been proposed to dealwith unknown terms in SMT systems, rather thanomitting or copying the terms.
For example, (Ecket al, 2008) replace the unknown terms in thesource text by their definition in a monolingualdictionary, which can be useful for gisting.
Totranslate across languages with different alpha-bets approaches such as (Knight and Graehl, 1997;Habash, 2008) use transliteration techniques totackle proper nouns and technical terms.
For trans-lation from highly inflected languages, certain ap-proaches rely on some form of lexical approx-imation or morphological analysis (Koehn andKnight, 2003; Yang and Kirchhoff, 2006; Langlaisand Patry, 2007; Arora et al, 2008).
Althoughthese strategies yield gain in coverage and transla-tion quality, they only account for unknown termsthat should be transliterated or are variations ofknown ones.2.2 Paraphrasing in MTA recent strategy to broadly deal with the prob-lem of unknown terms is to paraphrase the sourcetext with terms whose translation is known tothe system, using paraphrases learnt from multi-lingual corpora, typically involving at least one?pivot?
language different from the target lan-guage of immediate interest (Callison-Burch et792al., 2006; Cohn and Lapata, 2007; Zhao et al,2008; Callison-Burch, 2008; Guzma?n and Gar-rido, 2008).
The procedure to extract paraphrasesin these approaches is similar to standard phraseextraction in SMT systems, and therefore a largeamount of additional parallel corpus is required.Moreover, as discussed in Section 5, when un-known texts are not from the same domain as theSMT training corpus, it is likely that paraphrasesfound through such methods will yield misleadingtranslations.Bond et al (2008) use grammars to paraphrasethe whole source sentence, covering aspects likeword order and minor lexical variations (tensesetc.
), but not content words.
The paraphrases areadded to the source side of the corpus and the cor-responding target sentences are duplicated.
This,however, may yield distorted probability estimatesin the phrase table, since these were not computedfrom parallel data.The main use of monolingual paraphrases inMT to date has been for evaluation.
For exam-ple, (Kauchak and Barzilay, 2006) paraphrase ref-erences to make them closer to the system transla-tion in order to obtain more reliable results whenusing automatic evaluation metrics like BLEU(Papineni et al, 2002).2.3 Textual Entailment and Entailment RulesTextual Entailment (TE) has recently become aprominent paradigm for modeling semantic infer-ence, capturing the needs of a broad range oftext understanding applications (Giampiccolo etal., 2007).
Yet, its application to SMT has been sofar limited to MT evaluation (Pado et al, 2009).TE defines a directional relation between twotexts, where the meaning of the entailed text (hy-pothesis, h) can be inferred from the meaning ofthe entailing text, t. Under this paradigm, para-phrases are a special case of the entailment rela-tion, when the relation is symmetric (the texts en-tail each other).
Otherwise, we say that one textdirectionally entails the other.A common practice for proving (or generating)h from t is to apply entailment rules to t. Anentailment rule, denoted LHS ?
RHS, specifiesan entailment relation between two text fragments(the Left- and Right- Hand Sides), possibly withvariables (e.g.
build X in Y ?
X is completedin Y ).
A paraphrasing rule is denoted with ?.When a rule is applied to a text, a new text is in-ferred, where the matched LHS is replaced with theRHS.
For example, the rule skyscraper?
buildingis applied to ?The world?s tallest skyscraper wascompleted in Taiwan?
to infer ?The world?s tallestbuilding was completed in Taiwan?.
In this work,we employ lexical entailment rules, i.e.
rules with-out variables.
Various resources for lexical rulesare available, and the prominent one is WordNet(Fellbaum, 1998), which has been used in virtu-ally all TE systems (Giampiccolo et al, 2007).Typically, a rule application is valid only underspecific contexts.
For example, mouse ?
rodentshould not be applied to ?Use the mouse to markyour answers?.
Context-models can be exploitedto validate the application of a rule to a text.
Insuch models, an explicit Word Sense Disambigua-tion (WSD) is not necessarily required; rather, animplicit sense-match is sought after (Dagan et al,2006).
Within the scope of our paper, rule ap-plication is handled similarly to Lexical Substitu-tion (McCarthy and Navigli, 2007), consideringthe contextual relationship between the text andthe rule.
However, in general, entailment rule ap-plication addresses other aspects of context match-ing as well (Szpektor et al, 2008).3 Textual Entailment for StatisticalMachine TranslationPrevious solutions for handling unknown terms ina source text s augment the SMT system?s phrasetable based on multilingual corpora.
This allowsindirectly paraphrasing s, when the SMT systemchooses to use a paraphrase included in the tableand produces a translation with the correspondingtarget phrase for the unknown term.We propose using monolingual paraphrasingmethods and resources for this task to obtain amore extensive set of rules for paraphrasing thesource.
These rules are then applied to s directlyto produce alternative versions of the source textprior to the translation step.
Moreover, furthercoverage increase can be achieved by employingdirectional entailment rules, when paraphrasing isnot possible, to generate more general texts fortranslation.Our approach, based on the textual entailmentframework, considers the newly generated texts asentailed from the original one.
Monolingual se-mantic resources such as WordNet can provide en-tailment rules required for both these symmetricand asymmetric entailment relations.793Input: A text t with one or more unknown terms;a monolingual resource of entailment rules;k - maximal number of source alternatives to produceOutput: A translation of either (in order of preference):a paraphrase of t OR a text entailed by t OR t itself1.
For each unknown term - fetch entailment rules:(a) Fetch rules for paraphrasing; disregard ruleswhose RHS is not in the phrase table(b) If the set of rules is empty: fetch directional en-tailment rules; disregard rules whose RHS is notin the phrase table2.
Apply a context-model to compute a score for each ruleapplication3.
Compute total source score for each entailed text as acombination of individual rule scores4.
Generate and translate the top-k entailed texts5.
If k > 1(a) Apply target model to score the translation(b) Compute final source-target score6.
Pick highest scoring translationFigure 1: Scheme for handling unknown terms by usingmonolingual resources through textual entailmentThrough the process of applying entailmentrules to the source text, multiple alternatives ofentailed texts are generated.
To rank the candi-date texts we employ monolingual context-modelsto provide scores for rule applications over thesource sentence.
This can be used to (a) directlyselect the text with the highest score, which canthen be translated, or (b) to select a subset of topcandidates to be translated, which will then beranked using the target language information aswell.
This pruning reduces the load of the SMTsystem, and allows for potential improvements intranslation quality by considering both source- andtarget-language information.The general scheme through which we achievethese goals, which can be implemented using dif-ferent context-models and scoring techniques, isdetailed in Figure 1.
Details of our concrete im-plementation are given in Section 4.Preliminary analysis confirmed (as expected)that readers prefer translations of paraphrases,when available, over translations of directional en-tailments.
This consideration is therefore takeninto account in the proposed method.The input is a text unit to be translated, such as asentence or paragraph, with one or more unknownterms.
For each unknown term we first fetch alist of candidate rules for paraphrasing (e.g.
syn-onyms), where the unknown term is the LHS.
Forexample, if our unknown term is dodge, a possi-ble candidate might be dodge ?
circumvent.
Weinflect the RHS to keep the original morphologi-cal information of the unknown term and filter outrules where the inflected RHS does not appear inthe phrase table (step 1a in Figure 1).When no applicable rules for paraphrasing areavailable (1b), we fetch directional entailmentrules (e.g.
hypernymy rules such as dodge ?avoid), and filter them in the same way as for para-phrasing rules.
To each set of rules for a given un-known term we add the ?identity-rule?, to allowleaving the unknown term unchanged, the correctchoice in cases of proper names, for example.Next, we apply a context-model to compute anapplicability score of each rule to the source text(step 2).
An entailed text?s total score is the com-bination (e.g.
product, see Section 4) of the scoresof the rules used to produce it (3).
A set of thetop-k entailed texts is then generated and sent fortranslation (4).If more than one alternative is produced by thesource model (and k > 1), a target model is ap-plied on the selected set of translated texts (5a).The combined source-target model score is a com-bination of the scores of the source and targetmodels (5b).
The final translation is selected to bethe one that yields the highest combined source-target score (6).
Note that setting k = 1 is equiva-lent to using the source-language model alone.Our algorithm validates the application of theentailment rules at two stages ?
before and af-ter translation, through context-models applied ateach end.
As the experiments will show in Sec-tion 4, a large number of possible combinations ofentailment rules is a common scenario, and there-fore using the source context models to reduce thisnumber plays an important role.4 Experimental SettingTo assess our approach, we conducted a series ofexperiments; in each experiment we applied thescheme described in 3, changing only the mod-els being used for scoring the generated and trans-lated texts.
The setting of these experiments is de-scribed in what follows.SMT data To produce sentences for our experi-ments, we use Matrax (Simard et al, 2005), a stan-dard phrase-based SMT system, with the excep-tion that it allows gaps in phrases.
We use approxi-mately 1M sentence pairs from the English-French794Europarl corpus for training, and then translate atest set of 5,859 English sentences from the Newscorpus into French.
Both resources are takenfrom the shared translation task in WMT-2008(Callison-Burch et al, 2008).
Hence, we compareour method in a setting where the training and testdata are from different domains, a common sce-nario in the practical use of MT systems.Of the 5,859 translated sentences, 2,494 containunknown terms (considering only sequences withalphabetic symbols), summing up to 4,255 occur-rences of unknown terms.
39% of the 2,494 sen-tences contain more than a single unknown term.Entailment resource We use WordNet 3.0 asa resource for entailment rules.
Paraphrases aregenerated using synonyms.
Directionally entailedtexts are created using hypernyms, which typicallyconform with entailment.
We do not rely on senseinformation in WordNet.
Hence, any other seman-tic resource for entailment rules can be utilized.Each sentence is tagged using the OpenNLPPOS tagger2.
Entailment rules are applied for un-known terms tagged as nouns, verbs, adjectivesand adverbs.
The use of relations from WordNetresults in 1,071 sentences with applicable rules(with phrase table entries) for the unknown termswhen using synonyms, and 1,643 when using bothsynonyms and hypernyms, accounting for 43%and 66% of the test sentences, respectively.The number of alternative sentences generatedfor each source text varies from 1 to 960 whenparaphrasing rules were applied, and reaches verylarge numbers, up to 89,700 at the ?worst case?,when all TE rules are employed, an average of 456alternatives per sentence.Scoring source texts We test our proposedmethod using several context-models shown toperform reasonably well in previous work:?
FREQ: The first model we use is a context-independent baseline.
A common usefulheuristic to pick an entailment rule is to se-lect the candidate with the highest frequencyin the corpus (Mccarthy et al, 2004).
In thismodel, a rule?s score is the normalized num-ber of occurrences of its RHS in the trainingcorpus, ignoring the context of the LHS.?
LSA: Latent Semantic Analysis (Deerwesteret al, 1990) is a well-known method for rep-2http://opennlp.sourceforge.netresenting the contextual usage of words basedon corpus statistics.
We represented eachterm by a normalized vector of the top 100SVD dimensions, as described in (Gliozzo,2005).
This model measures the similaritybetween the sentence words and the RHS inthe LSA space.?
NB: We implemented the unsupervisedNa?
?ve Bayes model described in (Glickmanet al, 2006) to estimate the probability thatthe unknown term entails the RHS in thegiven context.
The estimation is based oncorpus co-occurrence statistics of the contextwords with the RHS.?
LMS: This model generates the LanguageModel probability of the RHS in the source.We use 3-grams probabilities as produced bythe SRILM toolkit (Stolcke, 2002).Finally, as a simple baseline, we generated a ran-dom score for each rule application, RAND.The score of each rule application by any ofthe above models is normalized to the range (0,1].To combine individual rule applications in a givensentence, we use the product of their scores.
Themonolingual data used for the models above is thesource side of the training parallel corpus.Target-language scores On the target side weused either a standard 3-gram language-model, de-noted LMT, or the score assigned by the com-plete SMT log-linear model, which includes thelanguage model as one of its components (SMT).A pair of a source:target models comprises acomplete model for selecting the best translatedsentence, where the overall score is the product ofthe scores of the two models.We also applied several combinations of sourcemodels, such as LSA combined with LMS, to takeadvantage of their complementary strengths.
Ad-ditionally, we assessed our method with source-only models, by setting the number of sentences tobe selected by the source model to one (k = 1).5 Results5.1 Manual EvaluationTo evaluate the translations produced using thevarious source and target models and the differentrule-sets, we rely mostly on manual assessment,since automatic MT evaluation metrics like BLEUdo not capture well the type of semantic variations795ModelPrecision (%) Coverage (%)PARAPH.
TE PARAPH.
TE1 ?
:SMT 75.8 73.1 32.5 48.12 NB:SMT 75.2 71.5 32.3 47.13 LSA:SMT 74.9 72.4 32.1 47.74 NB:?
74.7 71.1 32.1 46.85 LMS:LMT 73.8 70.2 31.7 46.36 FREQ:?
72.5 68.0 31.2 44.87 RAND 57.2 63.4 24.6 41.8Table 1: Translation acceptance when using only para-phrases and when using all entailment rules.
?:?
indicateswhich model is applied to the source (left side) and which tothe target language (right side).generated in our experiments, particularly at thesentence level.In the manual evaluation, two native speakersof the target language judged whether each trans-lation preserves the meaning of its reference sen-tence, marking it as acceptable or unacceptable.From the sentences for which rules were applica-ble, we randomly selected a sample of sentencesfor each annotator, allowing for some overlap-ping for agreement analysis.
In total, the transla-tions of 1,014 unique source sentences were man-ually annotated, of which 453 were produced us-ing only hypernyms (no paraphrases were appli-cable).
When a sentence was annotated by bothannotators, one annotation was picked randomly.Inter-annotator agreement was measured by thepercentage of sentences the annotators agreed on,as well as via the Kappa measure (Cohen, 1960).For different models, the agreement rate variedfrom 67% to 78% (72% overall), and the Kappavalue ranged from 0.34 to 0.55, which is compa-rable to figures reported for other standard SMTevaluation metrics (Callison-Burch et al, 2008).Translation with TE For each model m, wemeasured Precisionm, the percentage of accept-able translations out of all sampled translations.Precisionm was measured both when using onlyparaphrases (PARAPH.)
and when using all entail-ment rules (TE).
We also measured Coveragem,the percentage of sentences with acceptable trans-lations, Am, out of all sentences (2,494).
Asour annotators evaluated only a sample of sen-tences, Am is estimated as the model?s total num-ber of sentences with applicable rules, Sm, mul-tiplied by the model?s Precision (Sm was 1,071for paraphrases and 1,643 for entailment rules):Coveragem = Sm?Precisionm2,494 .Table 1 presents the results of several source-target combinations when using only paraphrasesand when also using directional entailment rules.When all rules are used, a substantial improve-ment in coverage is consistently obtained acrossall models, reaching a relative increase of 50%over paraphrases only, while just a slight decreasein precision is observed (see Section 5.3 for someerror analysis).
This confirms our hypothesis thatdirectional entailment rules can be very useful forreplacing unknown terms.For the combination of source-target models,the value of k is set depending on which rule-setis used.
Preliminary analysis showed that k = 5is sufficient when only paraphrases are used andk = 20 when directional entailment rules are alsoconsidered.We measured statistical significance betweendifferent models for precision of the TE re-sults according to the Wilcoxon signed ranks test(Wilcoxon, 1945).
Models 1-6 in Table 1 are sig-nificantly better than the RAND baseline (p <0.03), and models 1-3 are significantly better thanmodel 6 (p < 0.05).
The difference between?
:SMT and NB:SMT or LSA:SMT is not statisti-cally significant.The results in Table 1 therefore suggest thattaking a source model into account preserves thequality of translation.
Furthermore, the quality ismaintained even when source models?
selectionsare restricted to a rather small top-k ranks, at alower computational cost (for the models combin-ing source and target, like NB:SMT or LSA:SMT).This is particularly relevant for on-demand MTsystems, where time is an issue.
For such systems,using this source-language based pruning method-ology will yield significant performance gains ascompared to target-only models.We also evaluated the baseline strategy whereunknown terms are omitted from the translation,resulting in 25% precision.
Leaving unknownwords untranslated also yielded very poor transla-tion quality in an analysis performed on a similardataset.Comparison to related work We compared ouralgorithm with an implementation of the algo-rithm proposed by (Callison-Burch et al, 2006)(see Section 2.2), henceforth CB, using the Span-ish side of Europarl as the pivot language.Out of the tested 2,494 sentences with unknownterms, CB found paraphrases for 706 sentences(28.3%), while with any of our models, including796Model Precision (%) Coverage (%) Better (%)NB:SMT (TE) 85.3 56.2 72.7CB 85.3 24.2 12.7Table 2: Comparison between our top model and themethod by Callison-Burch et al (2006), showing the per-centage of times translations were considered acceptable, themodel?s coverage and the percentage of times each modelscored better than the other (in the 14% remaining cases, bothmodels produced unacceptable translations).NB:SMT , our algorithm found applicable entail-ment rules for 1,643 sentences (66%).The quality of the CB translations was manuallyassessed for a sample of 150 sentences.
Table 2presents the precision and coverage on this samplefor both CB and NB:SMT , as well as the numberof times each model?s translation was preferred bythe annotators.
While both models achieve equallyhigh precision scores on this sample, the NB:SMTmodel?s translations were undoubtedly preferredby the annotators, with a considerably higher cov-erage.With the CB method, given that many of thephrases added to the phrase table are noisy, theglobal quality of the sentences seem to have beenaffected, explaining why the judges preferred theNB:SMT translations.
One reason for the lowercoverage of CB is the fact that paraphrases wereacquired from a corpus whose domain is differ-ent from that of the test sentences.
The entail-ment rules in our models are not limited to para-phrases and are derived from WordNet, which hasbroader applicability.
Hence, utilizing monolin-gual resources has proven beneficial for the task.5.2 Automatic MT EvaluationAlthough automatic MT evaluation metrics areless appropriate for capturing the variations gen-erated by our method, to ensure that there was nodegradation in the system-level scores accordingto such metrics we also measured the models?
per-formance using BLEU and METEOR (Agarwaland Lavie, 2007).
The version of METEOR weused on the target language (French) considers thestems of the words, instead of surface forms only,but does not make use of WordNet synonyms.We evaluated the performance of the top mod-els of Table 1, as well as of a baseline SMT sys-tem that left unknown terms untranslated, on thesample of 1,014 manually annotated sentences.
Asshown in Table 3, all models resulted in improve-ment with respect to the original sentences (base-Model BLEU (TE) METEOR (TE)?
:SMT 15.50 0.1325NB:SMT 15.37 0.1316LSA:SMT 15.51 0.1318NB:?
15.37 0.1311CB 15.33 0.1299Baseline SMT 15.29 0.1294Table 3: Performance of the best models according to auto-matic MT evaluation metrics at the corpus level.
The baselinerefers to translation of the text without applying any entail-ment rules.line).
The difference in METEOR scores is statis-tically significant (p < 0.05) for the three top mod-els against the baseline.
The generally low scoresmay be attributed to the fact that training and testsentences are from different domains.5.3 DiscussionThe use of entailed texts produced using our ap-proach clearly improves the quality of translations,as compared to leaving unknown terms untrans-lated or omitting them altogether.
While it is clearthat textual entailment is useful for increasing cov-erage in translation, further research is required toidentify the amount of information loss incurredwhen non-symmetric entailment relations are be-ing used, and thus to identify the cases where suchrelations are detrimental to translation.Consider, for example, the sentence: ?Conven-tional military models are geared to decapitatesomething that, in this case, has no head.?.
In thissentence, the unknown term was replaced by kill,which results in missing the point originally con-veyed in the text.
Accordingly, the produced trans-lation does not preserve the meaning of the source,and was considered unacceptable: ?Les mode`lesmilitaires visent a` faire quelque chose que, dansce cas, n?est pas responsable.
?.In other cases, the selected hypernyms were toogeneric words, such as entity or attribute, whichalso fail to preserve the sentence?s meaning.
Onthe other hand, when the unknown term was avery specific word, hypernyms played an impor-tant role.
For example, ?Bulgaria is the mostsought-after east European real estate target, withits low-cost ski chalets and oceanfront homes?.Here, chalets are replaced by houses or units (de-pending on the model), providing a translation thatwould be acceptable by most readers.Other incorrect translations occurred when theunknown term was part of a phrase, for exam-ple, troughs replaced with depressions in peaks797and troughs, a problem that also strongly affectsparaphrasing.
In another case, movement was thehypernym chosen to replace labor in labor move-ment, yielding an awkward text for translation.Many of the cases which involved ambiguitywere resolved by the applied context-models, andcan be further addressed, together with the abovementioned problems, with better source-languagecontext models.We suggest that other types of entailment rulescould be useful for the task beyond the straight-forward generalization using hypernyms, whichwas demonstrated in this work.
This includesother types of lexical entailment relations, such asholonymy (e.g.
Singapore ?
Southeast Asia) aswell as lexical syntactic rules (X cure Y ?
treatY with X).
Even syntactic rules, such as clause re-moval, can be recruited for the task: ?Obama, the44th president, declared Monday .
.
.
??
?Obamadeclared Monday .
.
.
?.
When the system is un-able to translate a term found in the embeddedclause, the translation of the less informative sen-tence may still be acceptable by readers.6 Conclusions and Future WorkIn this paper we propose a new entailment-basedapproach for addressing the problem of unknownterms in machine translation.
Applying this ap-proach with lexical entailment rules from Word-Net, we show that using monolingual resourcesand textual entailment relationships allows sub-stantially increasing the quality of translationsproduced by an SMT system.
Our experimentsalso show that it is possible to perform the processefficiently by relying on source language context-models as a filter prior to translation.
This pipelinemaintains translation quality, as assessed by bothhuman annotators and standard automatic mea-sures.For future work we suggest generating entailedtexts with a more extensive set of rules, in particu-lar lexical-syntactic ones.
Combining rules frommonolingual and bilingual resources seems ap-pealing as well.
Developing better context-modelsto be applied on the source is expected to furtherimprove our method?s performance.
Specifically,we suggest taking into account the prior likelihoodthat a rule is correct as part of the model score.Finally, some researchers have advocated re-cently the use of shared structures such as parseforests (Mi and Huang, 2008) or word lattices(Dyer et al, 2008) in order to allow a compact rep-resentation of alternative inputs to an SMT system.This is an approach that we intend to explore infuture work, as a way to efficiently handle the dif-ferent source language alternatives generated byentailment rules.
However, since most current MTsystems do not accept such type of inputs, we con-sider the results on pruning by source-side contextmodels as broadly relevant.AcknowledgmentsThis work was supported in part by the ICT Pro-gramme of the European Community, under thePASCAL 2 Network of Excellence, ICT-216886and The Israel Science Foundation (grant No.1112/08).
We wish to thank Roy Bar-Haim andthe anonymous reviewers of this paper for theiruseful feedback.
This publication only reflects theauthors?
views.ReferencesAbhaya Agarwal and Alon Lavie.
2007.
METEOR:An Automatic Metric for MT Evaluation with HighLevels of Correlation with Human Judgments.
InProceedings of WMT-08.Karunesh Arora, Michael Paul, and Eiichiro Sumita.2008.
Translation of Unknown Words in Phrase-Based Statistical Machine Translation for Lan-guages of Rich Morphology.
In Proceedings ofSLTU.Francis Bond, Eric Nichols, Darren Scott Appling, andMichael Paul.
2008.
Improving Statistical MachineTranslation by Paraphrasing the Training Data.
InProceedings of IWSLT.Chris Callison-Burch, Philipp Koehn, and Miles Os-borne.
2006.
Improved Statistical Machine Trans-lation Using Paraphrases.
In Proceedings of HLT-NAACL.Chris Callison-Burch, Cameron Fordyce, PhilippKoehn, Christof Monz, and Josh Schroeder.
2008.Further Meta-Evaluation of Machine Translation.
InProceedings of WMT.Chris Callison-Burch.
2008.
Syntactic Constraintson Paraphrases Extracted from Parallel Corpora.
InProceedings of EMNLP.Jacob Cohen.
1960.
A Coefficient of Agreement forNominal Scales.
Educational and PsychologicalMeasurement, 20(1):37?46.Trevor Cohn and Mirella Lapata.
2007.
MachineTranslation by Triangulation: Making Effective Useof Multi-Parallel Corpora.
In Proceedings of ACL.798Ido Dagan, Oren Glickman, Alfio MassimilianoGliozzo, Efrat Marmorshtein, and Carlo Strappar-ava.
2006.
Direct Word Sense Matching for LexicalSubstitution.
In Proceedings of ACL.Scott Deerwester, S.T.
Dumais, G.W.
Furnas, T.K.
Lan-dauer, and R.A. Harshman.
1990.
Indexing by La-tent Semantic Analysis.
Journal of the American So-ciety for Information Science, 41.Christopher Dyer, Smaranda Muresan, and PhilipResnik.
2008.
Generalizing Word Lattice Trans-lation.
In Proceedings of ACL-HLT.Matthias Eck, Stephan Vogel, and Alex Waibel.
2008.Communicating Unknown Words in Machine Trans-lation.
In Proceedings of LREC.Christiane Fellbaum, editor.
1998.
WordNet: An Elec-tronic Lexical Database (Language, Speech, andCommunication).
The MIT Press.Danilo Giampiccolo, Bernardo Magnini, Ido Dagan,and Bill Dolan.
2007.
The Third PASCAL Recog-nising Textual Entailment Challenge.
In Proceed-ings of ACL-WTEP Workshop.Oren Glickman, Ido Dagan, Mikaela Keller, SamyBengio, and Walter Daelemans.
2006.
Investigat-ing Lexical Substitution Scoring for Subtitle Gener-ation.
In Proceedings of CoNLL.Alfio Massimiliano Gliozzo.
2005.
Semantic Domainsin Computational Linguistics.
Ph.D. thesis, Univer-sity of Trento.Francisco Guzma?n and Leonardo Garrido.
2008.Translation Paraphrases in Phrase-Based MachineTranslation.
In Proceedings of CICLing.Nizar Habash.
2008.
Four Techniques for OnlineHandling of Out-of-Vocabulary Words in Arabic-English Statistical Machine Translation.
In Pro-ceedings of ACL-HLT.David Kauchak and Regina Barzilay.
2006.
Paraphras-ing for Automatic Evaluation.
In Proceedings ofHLT-NAACL.Kevin Knight and Jonathan Graehl.
1997.
MachineTransliteration.
In Proceedings of ACL.Philipp Koehn and Kevin Knight.
2003.
EmpiricalMethods for Compound Splitting.
In Proceedingsof EACL.Philippe Langlais and Alexandre Patry.
2007.
Trans-lating Unknown Words by Analogical Learning.
InProceedings of EMNLP-CoNLL.Dekang Lin and Patrick Pantel.
2001.
DIRT ?
Discov-ery of Inference Rules from Text.
In Proceedings ofSIGKDD.Diana McCarthy and Roberto Navigli.
2007.SemEval-2007 Task 10: English Lexical Substitu-tion Task.
In Proceedings of SemEval.Diana Mccarthy, Rob Koeling, Julie Weeds, and JohnCarroll.
2004.
Finding Predominant Word Sensesin Untagged Text.
In Proceedings of ACL.Haitao Mi and Liang Huang.
2008.
Forest-basedTranslation Rule Extraction.
In Proceedings ofEMNLP.Sebastian Pado, Michel Galley, Daniel Jurafsky, andChristopher D. Manning.
2009.
Textual Entail-ment Features for Machine Translation Evaluation.In Proceedings of WMT.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
BLEU: a Method for AutomaticEvaluation of Machine Translation.
In Proceedingsof ACL.M.
Simard, N. Cancedda, B. Cavestro, M. Dymet-man, E. Gaussier, C. Goutte, and K. Yamada.
2005.Translating with Non-contiguous Phrases.
In Pro-ceedings of HLT-EMNLP.Andreas Stolcke.
2002.
SRILM ?
An Extensible Lan-guage Modeling Toolkit.
In Proceedings of ICSLP.Idan Szpektor, Ido Dagan, Roy Bar-Haim, and JacobGoldberger.
2008.
Contextual Preferences.
In Pro-ceedings of ACL-HLT.Frank Wilcoxon.
1945.
Individual Comparisons byRanking Methods.
Biometrics Bulletin, 1(6):80?83.Mei Yang and Katrin Kirchhoff.
2006.
Phrase-BasedBackoff Models for Machine Translation of HighlyInflected Languages.
In Proceedings of EACL.Shiqi Zhao, Haifeng Wang, Ting Liu, and Sheng Li.2008.
Pivot Approach for Extracting ParaphrasePatterns from Bilingual Corpora.
In Proceedings ofACL-HLT.799
