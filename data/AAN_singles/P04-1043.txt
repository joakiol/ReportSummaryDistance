A Study on Convolution Kernels for Shallow Semantic ParsingAlessandro MoschittiUniversity of Texas at DallasHuman Language Technology Research InstituteRichardson, TX 75083-0688, USAalessandro.moschitti@utdallas.eduAbstractIn this paper we have designed and experi-mented novel convolution kernels for automaticclassification of predicate arguments.
Theirmain property is the ability to process struc-tured representations.
Support Vector Ma-chines (SVMs), using a combination of such ker-nels and the flat feature kernel, classify Prop-Bank predicate arguments with accuracy higherthan the current argument classification state-of-the-art.Additionally, experiments on FrameNet datahave shown that SVMs are appealing for theclassification of semantic roles even if the pro-posed kernels do not produce any improvement.1 IntroductionSeveral linguistic theories, e.g.
(Jackendoff,1990) claim that semantic information in nat-ural language texts is connected to syntacticstructures.
Hence, to deal with natural lan-guage semantics, the learning algorithm shouldbe able to represent and process structureddata.
The classical solution adopted for suchtasks is to convert syntax structures into flatfeature representations which are suitable for agiven learning model.
The main drawback isthat structures may not be properly representedby flat features.In particular, these problems affect the pro-cessing of predicate argument structures an-notated in PropBank (Kingsbury and Palmer,2002) or FrameNet (Fillmore, 1982).
Figure1 shows an example of a predicate annotationin PropBank for the sentence: "Paul gives alecture in Rome".
A predicate may be a verbor a noun or an adjective and most of the timeArg 0 is the logical subject, Arg 1 is the logicalobject and ArgM may indicate locations, as inour example.FrameNet alo describes predicate/argumentstructures but for this purpose it uses richersemantic structures called frames.
These lat-ter are schematic representations of situationsinvolving various participants, properties androles in which a word may be typically used.Frame elements or semantic roles are argumentsof predicates called target words.
In FrameNet,the argument names are local to a particularframe.PredicateArg.
0Arg.
MSNNPD NVPV Paulingivesa lecturePPIN NRomeArg.
1Figure 1: A predicate argument structure in aparse-tree representation.Several machine learning approaches for argu-ment identification and classification have beendeveloped (Gildea and Jurasfky, 2002; Gildeaand Palmer, 2002; Surdeanu et al, 2003; Ha-cioglu et al, 2003).
Their common characteris-tic is the adoption of feature spaces that modelpredicate-argument structures in a flat repre-sentation.
On the contrary, convolution kernelsaim to capture structural information in termof sub-structures, providing a viable alternativeto flat features.In this paper, we select portions of syntactictrees, which include predicate/argument salientsub-structures, to define convolution kernels forthe task of predicate argument classification.
Inparticular, our kernels aim to (a) represent therelation between predicate and one of its argu-ments and (b) to capture the overall argumentstructure of the target predicate.
Additionally,we define novel kernels as combinations of theabove two with the polynomial kernel of stan-dard flat features.Experiments on Support Vector Machines us-ing the above kernels show an improvementof the state-of-the-art for PropBank argumentclassification.
On the contrary, FrameNet se-mantic parsing seems to not take advantage ofthe structural information provided by our ker-nels.The remainder of this paper is organized asfollows: Section 2 defines the Predicate Argu-ment Extraction problem and the standard so-lution to solve it.
In Section 3 we present ourkernels whereas in Section 4 we show compar-ative results among SVMs using standard fea-tures and the proposed kernels.
Finally, Section5 summarizes the conclusions.2 Predicate Argument Extraction: astandard approachGiven a sentence in natural language and thetarget predicates, all arguments have to be rec-ognized.
This problem can be divided into twosubtasks: (a) the detection of the argumentboundaries, i.e.
all its compounding words and(b) the classification of the argument type, e.g.Arg0 or ArgM in PropBank or Agent and Goalin FrameNet.The standard approach to learn both detec-tion and classification of predicate argumentsis summarized by the following steps:1.
Given a sentence from the training-set gene-rate a full syntactic parse-tree;2. let P and A be the set of predicates andthe set of parse-tree nodes (i.e.
the potentialarguments), respectively;3. for each pair <p, a> ?
P ?A:?
extract the feature representation set, Fp,a;?
if the subtree rooted in a covers exactly thewords of one argument of p, put Fp,a in T+(positive examples), otherwise put it in T ?
(negative examples).For example, in Figure 1, for each combina-tion of the predicate give with the nodes N, S,VP, V, NP, PP, D or IN the instances F?give?,a aregenerated.
In case the node a exactly coversPaul, a lecture or in Rome, it will be a positiveinstance otherwise it will be a negative one, e.g.F?give?,?IN?.To learn the argument classifiers the T + setcan be re-organized as positive T +argi and neg-ative T?argi examples for each argument i. Inthis way, an individual ONE-vs-ALL classifierfor each argument i can be trained.
We adoptedthis solution as it is simple and effective (Ha-cioglu et al, 2003).
In the classification phase,given a sentence of the test-set, all its Fp,aare generated and classified by each individ-ual classifier.
As a final decision, we select theargument associated with the maximum valueamong the scores provided by the SVMs, i.e.argmaxi?S Ci, where S is the target set of ar-guments.- Phrase Type: This feature indicates the syntactic typeof the phrase labeled as a predicate argument, e.g.
NPfor Arg1.- Parse Tree Path: This feature contains the path inthe parse tree between the predicate and the argumentphrase, expressed as a sequence of nonterminal labelslinked by direction (up or down) symbols, e.g.
V ?
VP?
NP for Arg1.- Position: Indicates if the constituent, i.e.
the potentialargument, appears before or after the predicate in thesentence, e.g.
after for Arg1 and before for Arg0.- Voice: This feature distinguishes between active or pas-sive voice for the predicate phrase, e.g.
active for everyargument.- Head Word : This feature contains the headword of theevaluated phrase.
Case and morphological informationare preserved, e.g.
lecture for Arg1.- Governing Category indicates if an NP is dominated bya sentence phrase or by a verb phrase, e.g.
the NP asso-ciated with Arg1 is dominated by a VP.- Predicate Word : This feature consists of two compo-nents: (1) the word itself, e.g.
gives for all arguments;and (2) the lemma which represents the verb normalizedto lower case and infinitive form, e.g.
give for all argu-ments.Table 1: Standard features extracted from theparse-tree in Figure 1.2.1 Standard feature spaceThe discovery of relevant features is, as usual, acomplex task, nevertheless, there is a commonconsensus on the basic features that should beadopted.
These standard features, firstly pro-posed in (Gildea and Jurasfky, 2002), refer toa flat information derived from parse trees, i.e.Phrase Type, Predicate Word, Head Word, Gov-erning Category, Position and Voice.
Table 1presents the standard features and exemplifieshow they are extracted from the parse tree inFigure 1.For example, the Parse Tree Path feature rep-resents the path in the parse-tree between apredicate node and one of its argument nodes.It is expressed as a sequence of nonterminal la-bels linked by direction symbols (up or down),e.g.
in Figure 1, V?VP?NP is the path betweenthe predicate to give and the argument 1, a lec-ture.
Two pairs <p1, a1> and <p2, a2> havetwo different Path features even if the paths dif-fer only for a node in the parse-tree.
This pre-SNNPD NVPV PaulindeliversatalkPPINNPjjFdeliver, Arg0formalNstyleArg.
0a) SNNPD NVPV PaulindeliversatalkPPINNPjjformalNstyleFdeliver, Arg1b) SNNPD NVPV PaulindeliversatalkPPINNPjjformalNstyleArg.
1Fdeliver, ArgMc)Arg.
MFigure 2: Structured features for Arg0, Arg1 and ArgM.vents the learning algorithm to generalize wellon unseen data.
In order to address this prob-lem, the next section describes a novel kernelspace for predicate argument classification.2.2 Support Vector Machine approachGiven a vector space in <n and a set of posi-tive and negative points, SVMs classify vectorsaccording to a separating hyperplane, H(~x) =~w ?
~x + b = 0, where ~w ?
<n and b ?
< arelearned by applying the Structural Risk Mini-mization principle (Vapnik, 1995).To apply the SVM algorithm to PredicateArgument Classification, we need a function?
: F ?
<n to map our features space F ={f1, .., f|F|} and our predicate/argument pairrepresentation, Fp,a = Fz , into <n, such that:Fz ?
?
(Fz) = (?1(Fz), .., ?n(Fz))From the kernel theory we have that:H(~x) =(?i=1..l?i~xi)?~x+ b =?i=1..l?i~xi ?~x+ b ==?i=1..l?i?
(Fi) ?
?
(Fz) + b.where, Fi ?i ?
{1, .., l} are the training in-stances and the product K(Fi, Fz) =<?
(Fi) ??
(Fz)> is the kernel function associated withthe mapping ?.
The simplest mapping that wecan apply is ?
(Fz) = ~z = (z1, ..., zn) wherezi = 1 if fi ?
Fz otherwise zi = 0, i.e.the characteristic vector of the set Fz with re-spect to F .
If we choose as a kernel functionthe scalar product we obtain the linear kernelKL(Fx, Fz) = ~x ?
~z.Another function which is the current state-of-the-art of predicate argument classification isthe polynomial kernel: Kp(Fx, Fz) = (c+~x ?~z)d,where c is a constant and d is the degree of thepolynom.3 Convolution Kernels for SemanticParsingWe propose two different convolution kernelsassociated with two different predicate argu-ment sub-structures: the first includes the tar-get predicate with one of its arguments.
We willshow that it contains almost all the standardfeature information.
The second relates to thesub-categorization frame of verbs.
In this case,the kernel function aims to cluster together ver-bal predicates which have the same syntacticrealizations.
This provides the classification al-gorithm with important clues about the possibleset of arguments suited for the target syntacticstructure.3.1 Predicate/Argument Feature(PAF)We consider the predicate argument structuresannotated in PropBank or FrameNet as our se-mantic space.
The smallest sub-structure whichincludes one predicate with only one of its ar-guments defines our structural feature.
Forexample, Figure 2 illustrates the parse-tree ofthe sentence "Paul delivers a talk in formalstyle".
The circled substructures in (a), (b)and (c) are our semantic objects associatedwith the three arguments of the verb to de-liver, i.e.
<deliver, Arg0>, <deliver, Arg1>and <deliver, ArgM>.
Note that each predi-cate/argument pair is associated with only onestructure, i.e.
Fp,a contain only one of the cir-cled sub-trees.
Other important properties arethe followings:(1) The overall semantic feature space F con-tains sub-structures composed of syntactic in-formation embodied by parse-tree dependenciesand semantic information under the form ofpredicate/argument annotation.
(2) This solution is efficient as we have to clas-sify as many nodes as the number of predicatearguments.
(3) A constituent cannot be part of two differ-ent arguments of the target predicate, i.e.
thereis no overlapping between the words of two ar-guments.
Thus, two semantic structures Fp1,a1and Fp2,a21, associated with two different ar-1Fp,a was defined as the set of features of the object<p, a>.
Since in our representations we have only oneSNP VPVP VPCCVBD NPflushed DT NNthe panand VBD NPbuckled PRP$ NNhis beltPRPHeArg0(flush and buckle)Arg1(flush) Arg1 (buckle)Predicate 1 Predicate 2FflushFbuckleFigure 3: Sub-Categorization Features for twopredicate argument structures.guments, cannot be included one in the other.This property is important because a convolu-tion kernel would not be effective to distinguishbetween an object and its sub-parts.3.2 Sub-Categorization Feature (SCF)The above object space aims to capture allthe information between a predicate and one ofits arguments.
Its main drawback is that im-portant structural information related to inter-argument dependencies is neglected.
In or-der to solve this problem we define the Sub-Categorization Feature (SCF).
This is the sub-parse tree which includes the sub-categorizationframe of the target verbal predicate.
Forexample, Figure 3 shows the parse tree ofthe sentence "He flushed the pan and buckledhis belt".
The solid line describes the SCFof the predicate flush, i.e.
Fflush whereas thedashed line tailors the SCF of the predicatebuckle, i.e.
Fbuckle.
Note that SCFs are featuresfor predicates, (i.e.
they describe predicates)whereas PAF characterizes predicate/argumentpairs.Once semantic representations are defined,we need to design a kernel function to esti-mate the similarity between our objects.
Assuggested in Section 2 we can map them intovectors in <n and evaluate implicitly the scalarproduct among them.3.3 Predicate/Argument structureKernel (PAK)Given the semantic objects defined in the previ-ous section, we design a convolution kernel in away similar to the parse-tree kernel proposedin (Collins and Duffy, 2002).
We divide ourmapping ?
in two steps: (1) from the semanticstructure space F (i.e.
PAF or SCF objects)to the set of all their possible sub-structureselement in Fp,a with an abuse of notation we use it toindicate the objects themselves.NPD NatalkNPD NNPD NaD Na   talkNPD NNPD NVPVdeliversatalkVdeliversNPD NVPVatalkNPD NVPVNPD NVPVaNPDVPVtalkNaNPD NVPVdeliverstalkNPD NVPVdeliversNPD NVPVdeliversNPVPVNPVPVdeliverstalkFigure 4: All 17 valid fragments of the semanticstructure associated with Arg 1 of Figure 2.F ?
= {f ?1, .., f?|F ?|} and (2) from F ?
to <|F?|.An example of features in F ?
is givenin Figure 4 where the whole set of frag-ments, F ?deliver,Arg1, of the argument structureFdeliver,Arg1, is shown (see also Figure 2).It is worth noting that the allowed sub-treescontain the entire (not partial) production rules.For instance, the sub-tree [NP [D a]] is excludedfrom the set of the Figure 4 since only a part ofthe production NP ?
D N is used in its gener-ation.
However, this constraint does not applyto the production VP ?
V NP PP along with thefragment [VP [V NP]] as the subtree [VP [PP [...]]]is not considered part of the semantic structure.Thus, in step 1, an argument structure Fp,a ismapped in a fragment set F ?p,a.
In step 2, thislatter is mapped into ~x = (x1, .., x|F ?|) ?
<|F?|,where xi is equal to the number of times thatf ?i occurs in F ?p,a2.In order to evaluate K(?
(Fx), ?
(Fz)) withoutevaluating the feature vector ~x and ~z we de-fine the indicator function Ii(n) = 1 if the sub-structure i is rooted at node n and 0 otherwise.It follows that ?i(Fx) =?n?Nx Ii(n), where Nxis the set of the Fx?s nodes.
Therefore, the ker-nel can be written as:K(?
(Fx), ?
(Fz)) =|F ?|?i=1(?nx?NxIi(nx))(?nz?NzIi(nz))=?nx?Nx?nz?Nz?iIi(nx)Ii(nz)where Nx and Nz are the nodes in Fx and Fz, re-spectively.
In (Collins and Duffy, 2002), it hasbeen shown that ?i Ii(nx)Ii(nz) = ?
(nx, nz)can be computed in O(|Nx| ?
|Nz|) by the fol-lowing recursive relation:(1) if the productions at nx and nz are differentthen ?
(nx, nz) = 0;2A fragment can appear several times in a parse-tree,thus each fragment occurrence is considered as a differentelement in F ?p,a.
(2) if the productions at nx and nz are thesame, and nx and nz are pre-terminals then?
(nx, nz) = 1;(3) if the productions at nx and nz are the same,and nx and nz are not pre-terminals then?
(nx, nz) =nc(nx)?j=1(1 + ?
(ch(nx, j), ch(nz , j))),where nc(nx) is the number of the children of nxand ch(n, i) is the i-th child of the node n. Notethat as the productions are the same ch(nx, i) =ch(nz, i).This kind of kernel has the drawback ofassigning more weight to larger structureswhile the argument type does not strictlydepend on the size of the argument (Moschittiand Bejan, 2004).
To overcome this prob-lem we can scale the relative importance ofthe tree fragments using a parameter ?
forthe cases (2) and (3), i.e.
?
(nx, nz) = ?
and?
(nx, nz) = ?
?nc(nx)j=1 (1 + ?
(ch(nx, j), ch(nz , j)))respectively.It is worth noting that even if the above equa-tions define a kernel function similar to the oneproposed in (Collins and Duffy, 2002), the sub-structures on which it operates are differentfrom the parse-tree kernel.
For example, Figure4 shows that structures such as [VP [V] [NP]], [VP[V delivers ] [NP]] and [VP [V] [NP [DT] [N]]] arevalid features, but these fragments (and manyothers) are not generated by a complete produc-tion, i.e.
VP ?
V NP PP.
As a consequence theywould not be included in the parse-tree kernelof the sentence.3.4 Comparison with StandardFeaturesIn this section we compare standard featureswith the kernel based representation in orderto derive useful indications for their use:First, PAK estimates a similarity betweentwo argument structures (i.e., PAF or SCF)by counting the number of sub-structures thatare in common.
As an example, the sim-ilarity between the two structures in Figure2, F?delivers?,Arg0 and F?delivers?,Arg1, is equalto 1 since they have in common only the [Vdelivers] substructure.
Such low value de-pends on the fact that different arguments tendto appear in different structures.On the contrary, if two structures differ onlyfor a few nodes (especially terminals or nearterminal nodes) the similarity remains quitehigh.
For example, if we change the tense ofthe verb to deliver (Figure 2) in delivered, the[VP [V delivers] [NP]] subtree will be trans-formed in [VP [VBD delivered] [NP]], where theNP is unchanged.
Thus, the similarity withthe previous structure will be quite high as:(1) the NP with all sub-parts will be matchedand (2) the small difference will not highly af-fect the kernel norm and consequently the fi-nal score.
The above property also holds forthe SCF structures.
For example, in Figure3, KPAK (?
(Fflush), ?
(Fbuckle)) is quite high asthe two verbs have the same syntactic realiza-tion of their arguments.
In general, flat featuresdo not possess this conservative property.
Forexample, the Parse Tree Path is very sensibleto small changes of parse-trees, e.g.
two predi-cates, expressed in different tenses, generate twodifferent Path features.Second, some information contained in thestandard features is embedded in PAF: PhraseType, Predicate Word and Head Word explicitlyappear as structure fragments.
For example, inFigure 4 are shown fragments like [NP [DT] [N]] or[NP [DT a] [N talk]] which explicitly encode thePhrase Type feature NP for the Arg 1 in Fig-ure 2.b.
The Predicate Word is represented bythe fragment [V delivers] and the Head Wordis encoded in [N talk].
The same is not true forSCF since it does not contain information abouta specific argument.
SCF, in fact, aims to char-acterize the predicate with respect to the overallargument structures rather than a specific pair<p, a>.Third, Governing Category, Position andVoice features are not explicitly contained inboth PAF and SCF.
Nevertheless, SCF mayallow the learning algorithm to detect the ac-tive/passive form of verbs.Finally, from the above observations followsthat the PAF representation may be used withPAK to classify arguments.
On the contrary,SCF lacks important information, thus, alone itmay be used only to classify verbs in syntacticcategories.
This suggests that SCF should beused in conjunction with standard features toboost their classification performance.4 The ExperimentsThe aim of our experiments are twofold: Onthe one hand, we study if the PAF represen-tation produces an accuracy higher than stan-dard features.
On the other hand, we study ifSCF can be used to classify verbs according totheir syntactic realization.
Both the above aimscan be carried out by combining PAF and SCFwith the standard features.
For this purposewe adopted two ways to combine kernels3: (1)K = K1 ?
K2 and (2) K = ?K1 + K2.
The re-sulting set of kernels used in the experiments isthe following:?
Kpd is the polynomial kernel with degree dover the standard features.?
KPAF is obtained by using PAK function overthe PAF structures.?
KPAF+P = ?
KPAF|KPAF | +Kpd|Kpd |, i.e.
the sum be-tween the normalized4 PAF-based kernel andthe normalized polynomial kernel.?
KPAF ?P =KPAF ?Kpd|KPAF |?|Kpd |, i.e.
the normalizedproduct between the PAF-based kernel and thepolynomial kernel.?
KSCF+P = ?
KSCF|KSCF | +Kpd|Kpd |, i.e.
the summa-tion between the normalized SCF-based kerneland the normalized polynomial kernel.?
KSCF ?P =KSCF ?Kpd|KSCF |?|Kpd |, i.e.
the normal-ized product between SCF-based kernel and thepolynomial kernel.4.1 Corpora set-upThe above kernels were experimented over twocorpora: PropBank (www.cis.upenn.edu/?ace)along with Penn TreeBank5 2 (Marcus et al,1993) and FrameNet.PropBank contains about 53,700 sentencesand a fixed split between training and test-ing which has been used in other researchese.g., (Gildea and Palmer, 2002; Surdeanu et al,2003; Hacioglu et al, 2003).
In this split, Sec-tions from 02 to 21 are used for training, section23 for testing and sections 1 and 22 as devel-oping set.
We considered all PropBank argu-ments6 from Arg0 to Arg9, ArgA and ArgM fora total of 122,774 and 7,359 arguments in train-ing and testing respectively.
It is worth notingthat in the experiments we used the gold stan-dard parsing from Penn TreeBank, thus our ker-nel structures are derived with high precision.For the FrameNet corpus (www.icsi.berkeley3It can be proven that the resulting kernels still sat-isfy Mercer?s conditions (Cristianini and Shawe-Taylor,2000).4To normalize a kernel K(~x, ~z) we can divide it by?K(~x, ~x) ?
K(~z, ~z).5We point out that we removed from Penn TreeBankthe function tags like SBJ and TMP as parsers usuallyare not able to provide this information.6We noted that only Arg0 to Arg4 and ArgM con-tain enough training/testing data to affect the overallperformance..edu/?framenet) we extracted all 24,558 sen-tences from the 40 frames of Senseval 3 task(www.senseval.org) for the Automatic Labelingof Semantic Roles.
We considered 18 of themost frequent roles and we mapped togetherthose having the same name.
Only verbs are se-lected to be predicates in our evaluations.
More-over, as it does not exist a fixed split betweentraining and testing, we selected randomly 30%of sentences for testing and 70% for training.Additionally, 30% of training was used as avalidation-set.
The sentences were processed us-ing Collins?
parser (Collins, 1997) to generateparse-trees automatically.4.2 Classification set-upThe classifier evaluations were carried out usingthe SVM-light software (Joachims, 1999) avail-able at svmlight.joachims.org with the defaultpolynomial kernel for standard feature evalu-ations.
To process PAF and SCF, we imple-mented our own kernels and we used them in-side SVM-light.The classification performances were evalu-ated using the f1 measure7 for single argumentsand the accuracy for the final multi-class clas-sifier.
This latter choice allows us to comparethe results with previous literature works, e.g.
(Gildea and Jurasfky, 2002; Surdeanu et al,2003; Hacioglu et al, 2003).For the evaluation of SVMs, we used the de-fault regularization parameter (e.g., C = 1 fornormalized kernels) and we tried a few cost-factor values (i.e., j ?
{0.1, 1, 2, 3, 4, 5}) to ad-just the rate between Precision and Recall.
Wechose parameters by evaluating SVM using Kp3kernel over the validation-set.
Both ?
(see Sec-tion 3.3) and ?
parameters were evaluated in asimilar way by maximizing the performance ofSVM using KPAF and ?
KSCF|KSCF | +Kpd|Kpd |respec-tively.
These parameters were adopted also forall the other kernels.4.3 Kernel evaluationsTo study the impact of our structural kernels wefirstly derived the maximal accuracy reachablewith standard features along with polynomialkernels.
The multi-class accuracies, for Prop-Bank and FrameNet using Kpd with d = 1, .., 5,are shown in Figure 5.
We note that (a) thehighest performance is reached for d = 3, (b)for PropBank our maximal accuracy (90.5%)7f1 assigns equal importance to Precision P and Re-call R, i.e.
f1 = 2P ?RP+R .is substantially equal to the SVM performance(88%) obtained in (Hacioglu et al, 2003) withdegree 2 and (c) the accuracy on FrameNet(85.2%) is higher than the best result obtainedin literature, i.e.
82.0% in (Gildea and Palmer,2002).
This different outcome is due to a differ-ent task (we classify different roles) and a differ-ent classification algorithm.
Moreover, we didnot use the Frame information which is very im-portant8.0.820.830.840.850.860.870.880.890.90.911 2 3 4 5dAccuracy FrameNetPropBankFigure 5: Multi-classifier accuracy according to dif-ferent degrees of the polynomial kernel.It is worth noting that the difference betweenlinear and polynomial kernel is about 3-4 per-cent points for both PropBank and FrameNet.This remarkable difference can be easily ex-plained by considering the meaning of standardfeatures.
For example, let us restrict the classi-fication function CArg0 to the two features Voiceand Position.
Without loss of generality we canassume: (a) Voice=1 if active and 0 if passive,and (b) Position=1 when the argument is af-ter the predicate and 0 otherwise.
To simplifythe example, we also assume that if an argu-ment precedes the target predicate it is a sub-ject, otherwise it is an object 9.
It follows thata constituent is Arg0, i.e.
CArg0 = 1, if onlyone feature at a time is 1, otherwise it is notan Arg0, i.e.
CArg0 = 0.
In other words, CArg0= Position XOR Voice, which is the classical ex-ample of a non-linear separable function thatbecomes separable in a superlinear space (Cris-tianini and Shawe-Taylor, 2000).After it was established that the best ker-nel for standard features is Kp3 , we carried outall the other experiments using it in the kernelcombinations.
Table 2 and 3 show the singleclass (f1 measure) as well as multi-class classi-fier (accuracy) performance for PropBank andFrameNet respectively.
Each column of the twotables refers to a different kernel defined in the8Preliminary experiments indicate that SVMs canreach 90% by using the frame feature.9Indeed, this is true in most part of the cases.previous section.
The overall meaning is dis-cussed in the following points:First, PAF alone has good performance, sincein PropBank evaluation it outperforms the lin-ear kernel (Kp1), 88.7% vs. 86.7% whereas inFrameNet, it shows a similar performance 79.5%vs.
82.1% (compare tables with Figure 5).
Thissuggests that PAF generates the same informa-tion as the standard features in a linear space.However, when a degree greater than 1 is usedfor standard features, PAF is outperformed10.Args P3 PAF PAF+P PAF?P SCF+P SCF?PArg0 90.8 88.3 90.6 90.5 94.6 94.7Arg1 91.1 87.4 89.9 91.2 92.9 94.1Arg2 80.0 68.5 77.5 74.7 77.4 82.0Arg3 57.9 56.5 55.6 49.7 56.2 56.4Arg4 70.5 68.7 71.2 62.7 69.6 71.1ArgM 95.4 94.1 96.2 96.2 96.1 96.3Acc.
90.5 88.7 90.2 90.4 92.4 93.2Table 2: Evaluation of Kernels on PropBank.Roles P3 PAF PAF+P PAF?P SCF+P SCF?Pagent 92.0 88.5 91.7 91.3 93.1 93.9cause 59.7 16.1 41.6 27.7 42.6 57.3degree 74.9 68.6 71.4 57.8 68.5 60.9depict.
52.6 29.7 51.0 28.6 46.8 37.6durat.
45.8 52.1 40.9 29.0 31.8 41.8goal 85.9 78.6 85.3 82.8 84.0 85.3instr.
67.9 46.8 62.8 55.8 59.6 64.1mann.
81.0 81.9 81.2 78.6 77.8 77.8Acc.
85.2 79.5 84.6 81.6 83.8 84.218 rolesTable 3: Evaluation of Kernels on FrameNet se-mantic roles.Second, SCF improves the polynomial kernel(d = 3), i.e.
the current state-of-the-art, ofabout 3 percent points on PropBank (columnSCF?P).
This suggests that (a) PAK can mea-sure the similarity between two SCF structuresand (b) the sub-categorization information pro-vides effective clues about the expected argu-ment type.
The interesting consequence is thatSCF together with PAK seems suitable to au-tomatically cluster different verbs that have thesame syntactic realization.
We note also that tofully exploit the SCF information it is necessaryto use a kernel product (K1 ?
K2) combinationrather than the sum (K1 + K2), e.g.
columnSCF+P.Finally, the FrameNet results are completelydifferent.
No kernel combinations with bothPAF and SCF produce an improvement.
On10Unfortunately the use of a polynomial kernel on topthe tree fragments to generate the XOR functions seemsnot successful.the contrary, the performance decreases, sug-gesting that the classifier is confused by thissyntactic information.
The main reason for thedifferent outcomes is that PropBank argumentsare different from semantic roles as they arean intermediate level between syntax and se-mantic, i.e.
they are nearer to grammaticalfunctions.
In fact, in PropBank arguments areannotated consistently with syntactic alterna-tions (see the Annotation guidelines for Prop-Bank at www.cis.upenn.edu/?ace).
On the con-trary FrameNet roles represent the final seman-tic product and they are assigned according tosemantic considerations rather than syntacticaspects.
For example, Cause and Agent seman-tic roles have identical syntactic realizations.This prevents SCF to distinguish between them.Another minor reason may be the use of auto-matic parse-trees to extract PAF and SCF, evenif preliminary experiments on automatic seman-tic shallow parsing of PropBank have shown noimportant differences versus semantic parsingwhich adopts Gold Standard parse-trees.5 ConclusionsIn this paper, we have experimented withSVMs using the two novel convolution kernelsPAF and SCF which are designed for the se-mantic structures derived from PropBank andFrameNet corpora.
Moreover, we have com-bined them with the polynomial kernel of stan-dard features.
The results have shown that:First, SVMs using the above kernels are ap-pealing for semantically parsing both corpora.Second, PAF and SCF can be used to improveautomatic classification of PropBank argumentsas they provide clues about the predicate argu-ment structure of the target verb.
For example,SCF improves (a) the classification state-of-the-art (i.e.
the polynomial kernel) of about 3 per-cent points and (b) the best literature result ofabout 5 percent points.Third, additional work is needed to designkernels suitable to learn the deep semantic con-tained in FrameNet as it seems not sensible toboth PAF and SCF information.Finally, an analysis of SVMs using poly-nomial kernels over standard features has ex-plained why they largely outperform linear clas-sifiers based-on standard features.In the future we plan to design other struc-tures and combine them with SCF, PAF andstandard features.
In this vision the learningwill be carried out on a set of structural featuresinstead of a set of flat features.
Other studiesmay relate to the use of SCF to generate verbclusters.AcknowledgmentsThis research has been sponsored by the ARDAAQUAINT program.
In addition, I would like tothank Professor Sanda Harabagiu for her advice,Adrian Cosmin Bejan for implementing the featureextractor and Paul Mora?rescu for processing theFrameNet data.
Many thanks to the anonymous re-viewers for their invaluable suggestions.ReferencesMichael Collins and Nigel Duffy.
2002.
New rankingalgorithms for parsing and tagging: Kernels overdiscrete structures, and the voted perceptron.
Inproceeding of ACL-02.Michael Collins.
1997.
Three generative, lexicalizedmodels for statistical parsing.
In proceedings ofthe ACL-97, pages 16?23, Somerset, New Jersey.Nello Cristianini and John Shawe-Taylor.
2000.
Anintroduction to Support Vector Machines.
Cam-bridge University Press.Charles J. Fillmore.
1982.
Frame semantics.
In Lin-guistics in the Morning Calm, pages 111?137.Daniel Gildea and Daniel Jurasfky.
2002.
Auto-matic labeling of semantic roles.
ComputationalLinguistic.Daniel Gildea and Martha Palmer.
2002.
The neces-sity of parsing for predicate argument recognition.In proceedings of ACL-02, Philadelphia, PA.R.
Jackendoff.
1990.
Semantic Structures, CurrentStudies in Linguistics series.
Cambridge, Mas-sachusetts: The MIT Press.T.
Joachims.
1999.
Making large-scale SVM learn-ing practical.
In Advances in Kernel Methods -Support Vector Learning.Paul Kingsbury and Martha Palmer.
2002.
Fromtreebank to propbank.
In proceedings of LREC-02, Las Palmas, Spain.M.
P. Marcus, B. Santorini, and M. A.Marcinkiewicz.
1993.
Building a large anno-tated corpus of english: The penn treebank.Computational Linguistics.Alessandro Moschitti and Cosmin Adrian Bejan.2004.
A semantic kernel for predicate argu-ment classification.
In proceedings of CoNLL-04,Boston, USA.Kadri Hacioglu, Sameer Pradhan, Wayne Ward,James H. Martin, and Daniel Jurafsky.
2003.Shallow Semantic Parsing Using Support VectorMachines.
TR-CSLR-2003-03, University of Col-orado.Mihai Surdeanu, Sanda M. Harabagiu, JohnWilliams, and John Aarseth.
2003.
Usingpredicate-argument structures for information ex-traction.
In proceedings of ACL-03, Sapporo,Japan.V.
Vapnik.
1995.
The Nature of Statistical LearningTheory.
Springer-Verlag New York, Inc.
