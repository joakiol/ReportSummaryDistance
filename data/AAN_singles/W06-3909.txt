A Bootstrapping Algorithm forAutomatically Harvesting Semantic RelationsMarco PennacchiottiDepartment of Computer ScienceUniversity of Rome ?Tor Vergata?Viale del Politecnico 1Rome, Italypennacchiotti@info.uniroma2.itPatrick PantelInformation Sciences InstituteUniversity of Southern California4676 Admiralty WayMarina del Rey, CA 90292pantel@isi.eduAbstractIn this paper, we present Espresso, a weakly-supervised iterative algorithm combined with aweb-based knowledge expansion technique, for extracting binary semantic relations.
Given asmall set of seed instances for a particular relation, the system learns lexical patterns, appliesthem to extract new instances, and then uses the Web to filter and expand the instances.Preliminary experiments show that Espresso extracts highly precise lists of a wide variety ofsemantic relations when compared with two state of the art systems.1.
IntroductionRecent attention to knowledge-rich problems such as question answering [18] and textualentailment [10] has encouraged Natural Language Processing (NLP) researchers to developalgorithms for automatically harvesting shallow semantic resources.
With seemingly endlessamounts of textual data at our disposal, we have a tremendous opportunity to automaticallygrow semantic term banks and ontological resources.
Methods must be accurate, adaptableand scalable to the varying sizes of domain corpora (e.g., textbooks vs. World Wide Web),and independent or weakly dependent on human supervision.In this paper we present Espresso, a novel bootstrapping algorithm for automaticallyharvesting semantic relations, aiming at effectively supporting NLP applications,emphasizing two major points that have been partially neglected by previous systems:generality and weak supervision.From the one side, Espresso is intended as a general-purpose system able to extract a widevariety of binary semantic relations, from the classical is-a and part-of relations, to morespecific and domain oriented ones like chemical reactants in a chemistry domain and positionsuccession in political texts.
The system architecture is designed with generality in mind,avoiding any relation-specific inference technique.
Indeed, for each semantic relation, thesystem builds specific lexical patterns inferred from textual corpora.From the other side, Espresso requires only weak human supervision.
In order to start theextraction process, a user provides only a small set of seed instances of a target relation (e.g.Italy-country and Canada-country for the is-a relation.)
In our experience, a handful of seedinstances, in general, is sufficient for large corpora while for smaller corpora, a slightly largerset is required.
To guarantee weakest supervision, Espresso combines its bootstrappingapproach with a web-based knowledge expansion technique and linguistic analysis,exploiting the seeds as much as possible.2.
Relevant WorkTo date, most research on lexical relation harvesting has focused on is-a and part-of relations.Approaches fall into two main categories: pattern- and clustering-based.Most common are pattern-based approaches.
Hearst [12] pioneered using patterns to extracthyponym (is-a) relations.
Manually building three lexico-syntactic patterns, Hearst sketched abootstrapping algorithm to learn more patterns from instances, which has served as the modelfor most subsequent pattern-based algorithms.Berland and Charniak [1] propose a system for part-of relation extraction, based on theHearst approach [12].
Seed instances are used to infer linguistic patterns that, in turn, are usedto extract new instances, ranked according to various statistical measures.
While this studyintroduces statistical measures to evaluate instance reliability, it remains vulnerable to datasparseness and has the limitation of taking into consideration only one-word terms.Improving upon Berland and Charniak [1], Girju et al [11] employ machine learningalgorithms and WordNet [8] to disambiguate part-of generic patterns, like [whole-NP?s part-NP].
This study is the first extensive attempt to solve the problem of generic relationalpatterns, that is, those expressive patterns that have high recall while suffering low precision,as they subsume a large set of instances.
In order to discard incorrect instances, Girju et allearn WordNet-based selectional restrictions, like [whole-NP(scene#4)?s part-NP(movie#1)].While making huge grounds on improving precision/recall, the system requires heavysupervision through manual semantic annotations.Ravichandran and Hovy [20] focus on efficiency issues for scaling relation extraction toterabytes of data.
A simple and effective algorithm is proposed to infer surface patterns froma small set of instance seeds by extracting all substrings relating seeds in corpus sentences.The frequencies of the substrings in the corpus are then used to retain the best patterns.
Theapproach gives good results on specific relations such as birthdates, however it has lowprecision on generic ones like is-a and part-of.
Pantel et al [17] proposed a similar, highlyscalable approach, based on an edit-distance technique, to learn lexico-POS patterns, showingboth good performances and efficiency.
Espresso uses a similar approach to infer patterns,but we then apply refining techniques to deal with various types of relations.Other pattern-based algorithms include Riloff and Shepherd [21], who used a semi-automaticmethod for discovering similar words using a few seed examples by using pattern-basedtechniques and human supervision, KnowItAll [7] that performs large-scale extraction offacts from the Web, Mann [15] and Fleischman et al [9] who used part of speech patterns toextract a subset of is-a relations involving proper nouns, and Downey et al [6] whoformalized the problem of relation extraction in a coherent and effective combinatorial modelthat is shown to outperform previous probabilistic frameworks.Clustering approaches to relation extraction are less common and have insofar been appliedonly to is-a extraction.
These methods employ clustering algorithms to group wordsaccording to their meanings in text, label the clusters using its members?
lexical or syntacticdependencies, and then extract an is-a relation between each cluster member and the clusterlabel.
Caraballo [3] proposed the first attempt, which used conjunction and appositionfeatures to build noun clusters.
Recently, Pantel and Ravichandran [16] extended thisapproach by making use of all syntactic dependency features for each noun.
The advantage ofclustering approaches is that they permit algorithms to identify is-a relations that do notexplicitly appear in text, however they generally fail to produce coherent clusters from fewerthan 100 million words; hence they are unreliable for small corpora.3.
The Espresso AlgorithmThe Espresso algorithm is based on a similar framework to the one adopted in [12].
For aspecific semantic binary relation (e.g., is-a), the algorithm requires as input a small set ofseed instances Is and a corpus C. An instance is a pair of terms x and y governed by therelation at hand (e.g., Pablo Picasso is-a artist).
Starting from these seeds, the algorithmbegins a four-phase loop.
In the first phase, the algorithm infers a set of patterns P thatcaptures as many of the seed instances as possible in C. In the second phase, we define areliability measure to select the best set of patterns P'?P.
In phase three, the patterns in P' areused to extract a set of instances I.
Finally, in phase four, Espresso scores each instance andthen selects the best instances I' as input seeds for the next iteration.
The algorithm terminateswhen a predefined stopping condition is met (for our preliminary experiments, the stoppingcondition is set according to the size of the corpus).
For each induced pattern p and instance i,the information theoretic scores, r?
(p) and r?
(i) respectively, aim to express their reliability.Below, Sections 3.2?3.5 describe in detail these different phases of Espresso.3.1.
Term definitionBefore one can extract relation instances from a corpus, it is necessary to define atokenization procedure for extracting terms.
Terms are commonly defined as surfacerepresentations of stable and key domain concepts [19].
Defining regular expressions overPOS-tagged corpora is the most commonly used technique to both define and extract terms.We adopt a slightly modified version of the term definition given in [13], as it is one of themost commonly used in the literature:((Adj|Noun)+|((Adj|Noun)*(NounPrep)?
)(Adj|Noun)*)NounWe operationally extend the definition of Adj to include present and past participles as mostnoun phrases composed of them are usually intended as terms (e.g., boiling point).
Thus,unlike many approaches for automatic relation extraction, we allow complex multi-wordterms as anchor points.
Hence, we can capture relations between complex terms, such as?record of a criminal conviction?
part-of ?FBI report?.3.2.
Phase 1: Pattern discoveryThe pattern discovery phase takes as input a set of instances I' and produces as output a set oflexical patterns P. For the first iteration I' = Is, the set of initial seeds.
In order to induce P, weapply a slight modification to the approach presented in [20].
For each input instance i = {x,y}, we first retrieve all sentences Sx,y containing the two terms x and y. Sentences are thengeneralized into a set of new sentences SGx,y by replacing all terminological expressions by aterminological label (TR).
For example:?Because/IN HF/NNP is/VBZ a/DT weak/JJ acid/NN and/CC x is/VBZ a/DT y?is generalized as:?Because/IN TR is/VBZ a/DT TR and/CC x is/VBZ a/DT y?All substrings linking terms x and y are then extracted from the set SGx,y, and overallfrequencies are computed.
The most frequent substrings then represent the set of new patternsP, where the frequency cutoff is experimentally set.
Term generalization is particularly usefulfor small corpora, where generalization is vital to ease the data sparseness.
However, thegeneralized patterns are naturally less precise.
Hence, when dealing with bigger corpora, thesystem allows the use of Sx,y?SGx,y in order to extract substrings.
For our experiments, weused the set SGx,y .3.3.
Phase 2: Pattern filteringIn this phase, Espresso selects among the patterns P those that are most reliable.
Intuitively, areliable pattern is one that is both highly precise and one that extracts many instances.
Therecall of a pattern p can be approximated by the fraction of input instances in I' that areextracted by p. Since it is difficult at run-time to estimate the precision of a pattern, we areweary of keeping patterns that generate many instances (i.e., patterns that generate high recallbut potentially disastrous precision).
We thus prefer patterns that are highly associated withthe input patterns I'.
Pointwise mutual information [4] is a commonly used metric formeasuring the strength of association between two events x and y:( ) ( )( ) ( )yPxPyxPyxpmi,log, =We define the reliability of a pattern p, r?
(p), as its average strength of association acrosseach input instance i in I', weighted by the reliability of each instance i:( )( )IirpipmiprIi pmi?????????
?=????
?max),(where r?
(i) is the reliability of instance i (defined in Section 3.5) and maxpmi is the maximumpointwise mutual information between all patterns and all instances.
r?
(p) ranges from [0,1].The reliability of the manually supplied seed instances are r?
(i) = 1.
The pointwise mutual in-formation between instance i = {x, y} and pattern p is estimated using the following formula:( ),**,,*,,,log,pyxypxpipmi =where |x, p, y| is the frequency of pattern p instantiated with terms x and y and where theasterisk (*) represents a wildcard.
A well-known problem is that pointwise mutualinformation is biased towards infrequent events.
To address this, we multiply pmi(i, p) withthe discounting factor suggested in [16].The set of highest n scoring patterns P', according to r?
(p), are then selected and retained forthe next phase, where n is the number of patterns of the previous iteration incremented by 1.In general, we expect that the set of patterns is formed by those of the previous iteration plusa new one.
Yet, new statistical evidence can lead the algorithm to discard a pattern that waspreviously discovered.Moreover, to further discourage too generic patterns that might have low precision, athreshold t is set for the number of instances that a pattern retrieves.
Patterns firing more thant instances are then discarded, no matter what their score is.
In this paper, we experimentallyset t to a value dependent on the size of the corpus.
In future work, this parameter can belearned using a development corpus.Our reliability measure ensures that overly generic patterns, which may potentially have verylow precision, are discarded.
However, we are currently exploring a web-expansion algorithmthat could both help detect generic patterns and also filter out their incorrect instances.
Weestimate the precision of the instance set generated by a new pattern p by looking at thenumber of these instances that are instantiated on the Web by previously accepted patterns.Generic patterns will generate instances with higher Web counts than incorrect patterns.Then, the Web counts can also be used to filter out incorrect instances from the genericpatterns?
instantiations.
More details are discussed in Section 4.3.3.4.
Phase 3: Instance discoveryIn this phase, Espresso retrieves from the corpus the set of instances I that match any of thelexical patterns in P'.In small corpora, the number of extracted instances can be too low to guarantee sufficientstatistical evidence for the pattern discovery phase of the next iteration.
In such cases, thesystem enters a web expansion phase, in which new instances for the given patterns areretrieved from the Web, using the Google search engine.
Specifically, for each instance i?
I,the system creates a set of queries, using each pattern in P' with its y term instantiated with i?sy term.
For example, given the instance ?Italy ; country?
and the pattern [Y such as X] , theresulting Google query will be ?country such as *?.
New instances are then created from theretrieved Web results (e.g.
?Canada ; country?)
and added to I.
We are currently exploringfiltering mechanisms to avoid retrieving too much noise.Moreover, to cope with data sparsity, a syntactic expansion phase is also carried out.
A set ofnew instances is created for each instance i?
I by extracting sub-terminological expressionsfrom x corresponding to the syntactic head of terms.
For example, expanding the relation?new record of a criminal conviction?
part-of ?FBI report?, the following new instances areobtained: ?new record?
part-of ?FBI report?, and ?record?
part-of ?FBI report?.3.5.
Phase 4: Instance filteringEstimating the reliability of an instance is similar to estimating the reliability of a pattern.Intuitively, a reliable instance is one that is highly associated with as many reliable patternsas possible (i.e., we have more confidence in an instance when multiple reliable patternsinstantiate it.)
Hence, analogous to our pattern reliability measure in Section 3.3, we definethe reliability of an instance i, r?
(i), as:( )( )Pprpipmiir Pp pmi??=????
?max),(where r?
(p) is the reliability of pattern p (defined in Section 3.3) and maxpmi is the maximumpointwise mutual information between all patterns and all instances, as in Section 3.3.Espresso finally selects the highest scoring m instances, I', and retains them as input for thesubsequent iteration.
In this paper, we experimentally set m = 200.4.
Experimental Results4.1.
Experimental SetupIn this section, we present a preliminary comparison of Espresso with two state of the artsystems on the task of extracting various semantic relations.4.1.1.
DatasetsWe perform our experiments using the following two datasets:?
TREC-9: This dataset consists of a sample of articles from the Aquaint (TREC-9)newswire text collection.
The sample consists of 5,951,432 words extracted from thefollowing data files: AP890101 ?
AP890131, AP890201 ?
AP890228, and AP890310?
AP890319.?
CHEM: This small dataset of 313,590 words consists of a college level textbook ofintroductory chemistry [2].We preprocess the corpora using the Alembic Workbench POS-tagger [5].4.1.2.
SystemsWe compare the results of Espresso with the following two state of the art extractionsystems:?
RH02: This algorithm by Ravichandran and Hovy [20] learns lexical extractionpatterns from a set of seed instances of a particular relation (see Section 2.)?
PR04: This is-a extraction algorithm from Pantel and Ravichandran [16] firstautomatically induces concepts (clusters) from a raw corpus, names the concepts, andthen extracts an is-a relation between each cluster member and its cluster label.
Foreach cluster member, the system may generate multiple possible is-a relations, but inthis evaluation we only keep the highest scoring one.
To apply this algorithm, bothdatasets were first analyzed using the Minipar parser [14].?
ESP: This is the algorithm described in this paper (details in Section 3).4.1.3.
Semantic RelationsEspresso is designed to extract various semantic relations exemplified by a given small set ofseed instances.
For our preliminary evaluation, we consider the standard is-a and part-ofrelations as well as three novel relations:?
succession: This relation indicates that one proper noun succeeds another in a positionor title.
For example, George Bush succeeded Bill Clinton and Pope Benedict XVIsucceeded Pope John Paul II.
We evaluate this relation on the TREC-9 corpus.?
reaction: This relation occurs between chemical elements/molecules that can becombined in a chemical reaction.
For example, hydrogen gas reacts-with oxygen gasand zinc reacts-with hydrochloric acid.
We evaluate this relation on the CHEMcorpus.?
production: This relation occurs when a process or element/object produces a result.For example, ammonia produces nitric oxide.
We evaluate this relation on the CHEMcorpus.For each semantic relation, we manually extracted a set of seed examples.
The seeds wereused for both Espresso as well as RH021.
Table 1 lists a sample of the seeds as well as sampleoutputs from Espresso.4.2.
Precision and RecallWe implemented each of the three systems outlined in Section 4.1.2 and applied them to theTREC and CHEM datasets.
For each output set, per relation, we evaluate the precision of thesystem by extracting a random sample of instances (50 for the TREC corpus and 20 for the1 PR04 does not require any seeds.CHEM corpus) and evaluating their quality manually using one human judge2.
For eachinstance, the judge may assign a score of 1 for correct, 0 for incorrect, and ?
for partiallycorrect.
Example instances that were judged partially correct include ?analyst is-a manager?and ?pilot is-a teacher?.
The precision for a given set of relation instances is the sum of thejudge?s scores divided by the number of instances.Although knowing the total number of instances of a particular relation in any non-trivialcorpus is impossible, it is possible to compute the recall of a system relative to anothersystem?s recall.
The recall of a system A, RA, is given by the following formula:CCR AA =where CA is the number of correct instances of a particular relation extracted by A and C isthe total number of correct instances in the corpus.
Following [17], we define the relativerecall of system A given system B, RA|B, as:BPAPCCRRRBABABABA ?
?===|Using the precision estimates, PA, from our precision experiments, we can estimate CA ?
PA ?|A|, where A is the total number of instances of a particular relation discovered by system A.2 In future work, we will perform this evaluation using multiple judges in order to obtain confidence bounds andagreement scores.Table 1.
Sample seeds used for each semantic relation and sample outputs from Espresso.
Thenumber in the parentheses for each relation denotes the total number of seeds.SEEDS ESPIs-a (12)wheat :: cropGeorge Wendt :: starMiami :: cityshark :: predatorPicasso :: artisttax :: chargedrug dealers :: felonsItaly :: countryPart-Of (12)leader :: panelcity :: regionplastic :: explosiveUnited States :: allianceshield :: nuclear missilebiblical quotations :: booktrees :: landmaterial :: FBI reportTREC9Succession (12)Khrushchev :: StalinCarla Hills :: YeutterGeorge Bush :: Ronald ReaganJulio Barbosa de Aquino :: MendesFord :: NixonSetrakian :: John GriesemerCamero Cardiel :: CamachoSusan Weiss :: editorIs-a (12)NaCl :: ionic compoundsdiborane :: substancenitrogen :: elementgold :: precious metalNa :: elementprotein :: biopolymerHCl :: strong acidelectromagnetic radiation :: energyPart-Of (12)ion :: matteroxygen :: waterlight particle :: gaselement :: substanceoxygen :: airpowdered zinc metal :: batteryatom :: moleculeethylene glycol :: automotive antifreezeReaction (13)magnesium :: oxygenhydrazine :: wateraluminum metal :: oxygenlithium metal :: fluorine gashydrogen :: oxygenNi :: HClcarbon dioxide :: methaneboron :: fluorineCHEMProduction (14)bright flame :: flareshydrogen :: solid metal hydridesammonia :: nitric oxidecopper :: brown gaselectron :: ionsglycerin :: nitroglycerinkidneys :: kidney stonesions :: chargeTable 8.
System performance on the productionrelation on the CHEM dataset.SYSTEM INSTANCES PRECISION* REL RECALL?RH02 197 57.5% 0.80ESP 196 72.5% 1.00* Precision estimated from 20 randomly sampled instances.?
Relative recall is given in relation to ESP.Tables 2 ?
8 reports the total number ofinstances, precision, and relative recall ofeach system on the TREC-9 and CHEMcorpora.
The relative recall is always given inrelation to the Espresso system.
For example,in Table 2, RH02 has a relative recall of 5.31with Espresso, which means that the RH02system output 5.31 times more correctrelations than Espresso (at a cost of muchlower precision).
Similarly, PR04 has a relative recall of 0.23 with Espresso, which meansthat PR04 outputs 4.35 fewer correct relations than Espresso (also with a smaller precision).4.3.
DiscussionExperimental results, for all relations and the two different corpus sizes, show that Espressogreatly outperforms the other two methods on precision.
However, Espresso fails to matchthe recall level of RH02 in all but the experiment on the production relation.
Indeed, thefiltering of unreliable patterns and instances during the bootstrapping algorithm not onlydiscards the patterns that are unrelated to the actual relation, but also patterns that are toogeneric and ambiguous ?
hence resulting in a loss of recall.As underlined in Section 3.2, the ambiguity of generic patterns often introduces much noisein the system (e.g, the pattern [X of Y] can ambiguously refer to a part-of, is-a or possessionTable 2.
System performance on the is-arelation on the TREC-9 dataset.SYSTEM INSTANCES PRECISION* REL RECALL?RH02 57,525 28.0% 5.31PR04 1,504 47.0% 0.23ESP 4,154 73.0% 1.00* Precision estimated from 50 randomly sampled instances.?
Relative recall is given in relation to ESP.Table 3.
System performance on the is-arelation on the CHEM dataset.SYSTEM INSTANCES PRECISION* REL RECALL?RH02 2556 25.0% 3.76PR04 108 40.0% 0.25ESP 200 85.0% 1.00* Precision estimated from 20 randomly sampled instances.?
Relative recall is given in relation to ESP.Table 4.
System performance on the part-ofrelation on the TREC-9 dataset.SYSTEM INSTANCES PRECISION* REL RECALL?RH02 12,828 35.0% 42.52ESP 132 80.0% 1.00* Precision estimated from 50 randomly sampled instances.?
Relative recall is given in relation to ESP.Table 5.
System performance on the part-ofrelation on the CHEM dataset.SYSTEM INSTANCES PRECISION* REL RECALL?RH02 11,582 33.8% 58.78ESP 111 60.0% 1.00* Precision estimated from 20 randomly sampled instances.?
Relative recall is given in relation to ESP.Table 6.
System performance on the successionrelation on the TREC-9 dataset.SYSTEM INSTANCES PRECISION* REL RECALL?RH02 49,798 2.0% 36.96ESP 55 49.0% 1.00* Precision estimated from 50 randomly sampled instances.?
Relative recall is given in relation to ESP.Table 7.
System performance on the reactionrelation on the CHEM dataset.SYSTEM INSTANCES PRECISION* REL RECALL?RH02 6,083 30% 53.67ESP 40 85% 1.00* Precision estimated from 20 randomly sampled instances.?
Relative recall is given in relation to ESP.relation).
However, generic patterns, while having low precision, yield a high recall, as alsoreported by [11].
We ran an experiment on the reaction relation, retaining the generic patternsproduced during Espresso?s selection process.
As expected, we obtained 1923 instancesinstead of the 40 reported in Table 7, but precision dropped from 85% to 30%.The challenge, then, is to harness the expressive power of the generic patterns whilstmaintaining the precision of Espresso.
We propose the following solution that helps both indistinguishing generic patterns from incorrect patterns and also in filtering incorrect instancesproduced by generic patterns.
Unlike Girju et al [11] that propose a highly supervisedmachine learning approach based on selectional restriction, ours is an unsupervised methodbased on statistical evidence obtained from the Web.
At a given iteration in Espresso, theintuition behind our solution is that the Web is large enough that correct instances will beinstantiated by many of the currently accepted patterns P. Hence, we can distinguish betweengeneric patterns and incorrect patterns by inspecting the relative frequency distribution oftheir instances using the patterns in P. More formally, given an instance i produced by ageneric or incorrect pattern, we count how many times i instantiates on the Web with everypattern in P, using Google.
The instance i is then considered correct if its web count surpassesa given threshold.
The pattern in question is accepted as a generic pattern if a sufficientnumber of its instances are considered correct, otherwise it is rejected as an incorrect pattern.Although our results in Section 4.2 do not include this algorithm, we performed a smallexperiment by adding an a-posteriori generic pattern recovery phase to Espresso.
We testedthe 7,634 instances extracted by the generic pattern [X of Y] on the CHEM corpus for thepart-of relation.
We randomly sample 200 of these instances and then queried Google forthese instances using the pattern [X consists of Y].
Manual evaluation of the 25 instances thatoccurred at least once on Google showed 50% precision.
Adding these instances to the resultsfrom Table 5 decreases the system precision from 60% to 51%, but dramatically increasesEspresso?s recall by a factor of 8.16.
Furthermore, it is important to note that there are severalother generic patterns, like [X?s Y], from which we expect a similar precision of 50% with acontinual increase of recall.
This is a very exciting avenue of further investigation.5.
ConclusionsWe proposed a weakly supervised bootstrapping algorithm, called Espresso, forautomatically extracting a wide variety of binary semantic relations from raw text.
Given asmall set of seed instances for a particular relation, the system learns reliable lexical patterns,applies them to extract new instances ranked by an information theoretic definition ofreliability, and then uses the Web to filter and expand the instances.There are many avenues of future work.
Preliminary results show that Espresso generateshighly precise relations, but at the expense of lower recall.
As mentioned above in Section4.3, we are working on improving system recall with a web-based method to identify genericpatterns and filter their instances.
Early results appear very promising.
We also plan toinvestigate the use of WordNet selectional constraints, as proposed by [11].
We expect herethat negative instances will play a key role in determining the selectional restriction ongeneric patterns.Espresso is the first system, to our knowledge, to emphasize both minimal supervision andgenerality, both in identification of a wide variety of relations and in extensibility to variouscorpus sizes.
It remains to be seen whether one could enrich existing ontologies with relationsharvested by Espresso, and if these relations can benefit NLP applications such as QA.AcknowledgementsThe authors wish to thank the reviewers for their helpful comments and Andrew Philpot forevaluating the outputs of the systems.References[1] Berland, M. and E. Charniak, 1999.
Finding parts in very large corpora.
In Proceedings of ACL-1999.
pp.57-64.
College Park, MD.
[2] Brown, T.L.
; LeMay, H.E.
; Bursten, B.E.
; and Burdge, J.R. 2003.
Chemistry: The Central Science, NinthEdition.
Prentice Hall.
[3] Caraballo, S. 1999.
Automatic acquisition of a hypernym-labeled noun hierarchy from text.
In Proceedingsof ACL-99.
pp 120-126, Baltimore, MD.
[4] Cover, T.M.
and Thomas, J.A.
1991.
Elements of Information Theory.
John Wiley & Sons.
[5] Day, D.; Aberdeen, J.; Hirschman, L.; Kozierok, R.; Robinson, P.; and Vilain, M. 1997.
Mixed-initiativedevelopment of language processing systems.
In Proceedings of ANLP-1997.
Washington D.C.[6] Downey, D.; Etzioni, O.; and Soderland, S. 2005.
A Probabilistic model of redundancy in informationextraction.
In Proceedings of IJCAI-2005.
pp.
1034-1041.
Edinburgh, Scotland.
[7] Etzioni, O.; Cafarella, M.J.; Downey, D.; Popescu, A.-M.; Shaked, T.; Soderland, S.; Weld, D.S.
; andYates, A.
2005.
Unsupervised named-entity extraction from the Web: An experimental study.
ArtificialIntelligence, 165(1): 91-134.
[8] Fellbaum, C. 1998.
WordNet: An Electronic Lexical Database.
MIT Press.
[9] Fleischman, M.; Hovy, E.; and Echihabi, A.
2003.
Offline strategies for online question answering:Answering questions before they are asked.
In Proceedings of ACL-03.
pp.
1-7.
Sapporo, Japan.
[10] Geffet, M. and Dagan, I.
2005.
The Distributional Inclusion Hypotheses and Lexical Entailment.
InProceedings of ACL-2005.
Ann Arbor, MI.
[11] Girju, R.; Badulescu, A.; and Moldovan, D. 2003.
Learning semantic constraints for the automaticdiscovery of part-whole relations.
In Proceedings of HLT/NAACL-03.
pp.
80-87.
Edmonton, Canada.
[12] Hearst, M. 1992.
Automatic acquisition of hyponyms from large text corpora.
In COLING-92.
pp.
539-545.Nantes, France.
[13] Justeson J.S.
and Katz S.M.
1995.
Technical Terminology: some linguistic properties and algorithms foridentification in text.
In Proceedings of ICCL-1995.
pp.539-545.
Nantes, France.
[14] Lin, D. 1994.
Principar - an efficient, broad-coverage, principle-based parser.
In Proceedings of COLING-94.
pp.
42-48.
Kyoto, Japan.
[15] Mann, G. S. 2002.
Fine-Grained Proper Noun Ontologies for Question Answering.
In Proceedings ofSemaNet?
02: Building and Using Semantic Networks, Taipei, Taiwan.
[16] Pantel, P. and Ravichandran, D. 2004.
Automatically labeling semantic classes.
In Proceedings ofHLT/NAACL-04.
pp.
321-328.
Boston, MA.
[17] Pantel, P.; Ravichandran, D.; Hovy, E.H. 2004.
Towards terascale knowledge acquisition.
In Proceedings ofCOLING-04.
pp.
771-777.
Geneva, Switzerland.
[18] Pasca, M. and Harabagiu, S. 2001.
The informative role of WordNet in Open-Domain Question Answering.In Proceedings of NAACL-01 Workshop on WordNet and Other Lexical Resources.
pp.
138-143.
Pittsburgh,PA.
[19] Pazienza M.T.
2000.
A domain-specific terminology-extraction system.
In Terminology, 5:2.
[20] Ravichandran, D. and Hovy, E.H. 2002.
Learning surface text patterns for a question answering system.
InProceedings of ACL-2002.
pp.
41-47.
Philadelphia, PA.[21] Riloff, E. and Shepherd, J.
1997.
A corpus-based approach for building semantic lexicons.
In Proceedingsof EMNLP-1997.
