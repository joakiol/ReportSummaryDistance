J apanese  OCR Error Cor rect ion  us ing Character  ShapeS imi lar i ty  and Stat ist ica l  Language Mode lMasaaki NAGATANTT Information and Communication Systems Laboratories1-1 Hikari-no-oka Yokosuka-Shi Kanagawa, 239-0847 Japannagata@nttnly, isl.
ntt.
co. jpAbstractWe present a novel OCR error correction methodfor languages without word delimiters that have alarge character set, such as Japanese and Chinese.It consists of a statistical OCR model, an approxi-mate word matching method using character shapesimilarity, and a word segmentation algorithm us-ing a statistical language model.
By using a sta-tistical OCR model and character shape similarity,the proposed error corrector outperforms the previ-ously published method.
When the baseline char-acter recognition accuracy is 90%, it achieves 97.4%character recognition accuracy.1 IntroductionAs our society is becoming more computerized, peo-ple are getting enthusiastic about entering every-thing into computers.
So the need for OCR in areassuch as office automation and information retrievalis becoming larger, contrary to our expectation.In Japanese, although the accuracy of printedcharacter OCR is about 98%, sources such as oldbooks, poor quality photocopies, and faxes are stilldifficult o process and cause many errors.
The accu-racy of handwritten OCR is still about 90% (Hilde-brandt and Liu, 1993), and it worsens dramaticallywhen the input quality is poor.
If NLP techniquescould be used to boost the accuracy of handwritingand poor quality documents, we could enjoy a verylarge market for OCR related applications.OCR error correction can be thought of a spellingcorrection problem.
Although spelling correctionhas been studied for several decades (Kukich, 1992),the traditional techniques are implicitly based onEnglish and cannot be used for Asian languages suchas Japanese and Chinese.The traditional strategy for English spelling cor-rection is called isolated word error correction: Wordboundaries are placed by white spaces.
If the tok-enized string is not in the dictionary, it is a non-word.
For a non-word, correction candidates are re-trieved from the dictionary by approximate stringmatch techniques using context-independent worddistance measures such as edit distance (Wagner andFischer, 1974) and ngram distance (Angell et al,1983).Recently, statistical language models and feature-based method have been used for context-sensitivespelling correction, where errors are corrected con-sidering the context in which the error occurs(Church and Gale, 1991; Mays et al, 1991; Goldingand Schabes, 1996).
Similar techniques are used forcorrecting the output of English OCRs (Tong andEvans, 1996) and English speech recognizers (Ring-ger and Allen, 1996).There are two problems in Japanese (and Chinese)spelling correction.
The first is the word boundaryproblem.
It is impossible to use isolated word errorcorrection techniques because there are no delimitersbetween words.
The second is the short word prob-lem.
Word distance measures are useless because theaverage word length is short (< 2), and the charac-ter set is large (> 3000).
There are a much largernumber of one edit distance neighbors for a word,compared with English.Recently, the first problem was solved by selectingthe most likely word sequence from all combinationsof exactly and approximately matched words using aViterbi-like word segmentation algorithm and a sta-tistical anguage model considering unknown wordsand non-words (Nagata, 1996).
However, the secondproblem is not solved yet, at least elegantly.
The so-lution presented in (Nagata, 1996) which sorts a listof one edit distance words considering the contextin which it will be placed is inaccurate because thecontext itself might include some errors.In this paper, we present a context-independentapproximate word match method using charactershape similarity.
This is suitable for languages withlarge character sets, such as Japanese and Chinese.We also present a method to build a statistical OCRmodel by smoothing the character confusion proba-bility using character shape similarity.It seems previous NLP researchers are reluctant922to use resources such as the character confusion ma-trix and feature vectors of the characters, and try tosolve the problem by using only linguistic devices.We found that, by using character shape similarity,the resulting OCR error corrector is robust and ac-curate enough to correct unrestricted texts with awide range of recognition accuracies.2 OCR Mode l2.1 Noisy Channel  ModelFirst, we formulate the spelling correction of OCRerrors in the noisy channel paradigm.
Let C rep-resent he input string and X represent the OCRoutput string.
Finding the most probable string C"given the OCR output X amounts to maximizingthe function P(XIC)P(C),= arg m~x P(C\[X) = arg mcax P(X\[C)P(C) (1)because Bayes' rule states that,P(C\[X)- P(X\[C)P(C)P(X) (2)P(C) is called the language model.
It is computedfrom the training corpus.
Let us call P(XIC ) theOCR model.
It can be computed from the a priorilikelihood estimates for individual characters,nP(XIC) = I I  P(xilci) (3)i=1where n is the string length.
P(xi\[ci) is called thecharacters confusion probability.2.2 Zero-Frequency ProblemThe character confusion probabilities are computedfrom the character confusion matrix, which is a set ofthe frequencies ofthe input-output character pairs ofthe OCR.
The confusion matrix, however, is highlydependent on the character recognition method andthe quality of the input image.
It is a labor intensivetask to make a confusion matrix, since Japanese hasmore than 3,000 characters.
But the more seriousproblem is that the confusion matrix is too sparseto be used for statistical modeling.For example, suppose the word "ItI~31E" (environ-ment) is incorrectly recognized as a non-word "~~" .
The following is an excerpt of a confusion ma-trix, where the pair of a character and a numberseparated by a slash represents he output characterand its frequency.input character ~:~/1289 ~/1  {~/1input character ~:~/1282 ~/5 ~/1 ~/1 ~/I  ~/1 ~/ iEven if we collect more than one thousand recog-nition examples, there are no examples in which qll'is recognized as '~'.
To compute the confusion prob-ability P(~\[!II), we need a smoothing method.This is called the zero-frequency problem.
Al-though it has been studied in many areas suchas speech recognition, statistical language modelingand text compression, o previous work has exam-ined on the smoothing of the character confusionprobabilities.
This is probably because the problemarises only when we consider OCR error correctionof languages with large character sets.We propose a novel method to smooth the char-acter confusion probabilities.
First, we estimate thesum of the probabilities of novel events.
We thendistribute the probability mass to each novel eventbased on character similarity.We use a scheme, which we refer to as the Witten-Bell method (Witten and Bell, 1991), to estimate thesum of the probabilities for all novel events becauseit is simple and robust 1.
Let C(ci,cj) be the fre-quency of events where ci and cj are the input andthe output characters, respectively.
Let ~(ci) be thesum of the probabilities of unseen output charac-ters where the input character is ci.
By using theWitten-Bell method, ~(ci) is estimated as,B(ci) = ~_, P(cijci)c a :C(ci ,c1 )=0= Ej  o(c(c.cj)) (4)C(c.c ) + o(c(c.cj))where1 i fx>OO(x) = 0 otherwise (5)In the above xample, '~ '  appears 1291(= 1289+1+1) times as input and there are three distinct char-acters in the output.
Therefore, the probability ofobserving novel characters i  3/(1291 + 3) = 3/1294.One of the possible alternatives tothe Witten-Bellmethod is the Good-Turing method (Good, 1953).But we didn't use the method since it assumes thedistribution of the frequency of frequencies tobe rel-atively smooth, which is not the case in the characterconfusion matrix.2.3 Back-off SmoothingBoth the Witten-Bell and Good-Turing methods donot in themselves tell one how to share/~(ci) among1In (Witten and Bell, 1991), the method is referred to as"method C" for estimating the escape probability in a textcompression method, Prediction by Partial Matching (PPM).It estimates the probability of observing novel events to ber/(n + r), where n is the total number of events een previ-ously, and r is the number of symbols that are distinct.
Theprobability of the event observed c times is c/(n + r).923the distinct unseen events.
The simplest strategyis to assume all unseen events are equally probable,but this is not reasonable because recognition errorsare more likely to occur among characters with simi-lar shapes.
Therefore, we distributed the probabilitymass D(c~) based on character shape similarity com-puted from feature vectors.First, we made an appropriate number of charac-ter classes in which similar characters are gathered.This is done by clustering the feature vectors of eachcharacter; details are described in the next subsec-tion.
We then made a confusion matrix between thecharacter classes from the character confusion ma-trix.
Let C(class~, classj) be the frequency that thecharacters in classl are recognized as the charactersin classj.
It is computed as the sum of the elementsin the character confusion matrix associated withthe characters in class~ and classj.C(classl,class.,) = ~_, C(ci, cj) (6)ci Ec lass  l ,cj C=class jBy using the Witten-Bell method, we can esti-mate the class confusion probabilities between arbi-trary classes.
We then distribute the probability forunseen events in proportion to the class confusionprobability,P(cj\[c~) = a(ci)P(class(cj)\[class(c~)) (7)whereZ(c~)~(c~) = E~,:c(~,,~=0 P(d~(cDId~s(~))  (8)is a normalizing constant, and class(c{) is the func-tion that returns the class of character c~.Numerical values for a's as well as the charac-ter class confusion probabilities can be precomputed.Therefore, the method is computationally efficient.2.4 Character  ClusteringIn general, character recognition consists of featureextraction and classification.
Feature extraction isapplied to concentrate the information in the im-age into a few, highly selective features.
Classifica-tion is accomplished by comparing the feature vec-tor corresponding to the input character with therepresentatives of each character, using a distancemetric.
Therefore, if we cluster feature vectors ofeach character, the members of the resulting classare characters with similar shape, and so tend tocause confusion.The feature we used in the clustering experi-ment is PDC (Peripheral Direction Contributivity)(Hagita et al, 1983), which is one of the best featuresfor Japanese character recognition 2.
We clusteredthe feature vectors for 3021 Japanese characters into128 classes by using the LBG algorithm (Linde etal., 1980), which is one of the most popular vectorquantization methods.Let's go back to the previous example of estimat-ing P(~I~)-  After character clustering, '~ '  and '~ 'are clustered into class 29 and 119, respectively.classclass29 (including ~) :119 (including ~) :Here is the excerpt of the class confusion matrix forclass 29.input class 29:29/30884 87/23 33121 59/20 15/9 119/7 94/678/6 28/5 2/4 109/4 101/4 71/4 104/3 107/321/3 58/3 70/2 113/2 56/2 0/2 34/2 38/2 26/21812 4411 7211 5011 3011 10211 1911 8911110/1 4/1 122/1 123/1Since class 29 appears 31036(30884 + 23 +-- - )times as input and there are 36 distinct classesin the output, where class 119 appeared 7 times,P(classnglclass29) = 7/(31036 + 36) = 7/31072.This class confusion probability and the normalizingconstant ~(~) are used to compute P (~I~)  usingequation (7).3 Language Mode l3.1 Word Segmentat ion ModelLet the input Japanese character sequence be C =clc2...cm, which can be segmented into word se-quence W = wlw2.
.
.w, .
We approximate P(C)in Equation (1) by the joint probability of word se-quence P(W).
P(W) is then approximated by theproduct of word bigram probabilities P(w~lwi_l).nP(C) ,~, P(W) = H P(w'lw'-l) (9)i----12PDC features are formed by assigning stroke directionsto pixels and selecting just pixels on the first, second, andthird stroke encountered by the scan line.
The marginal dis-tribution of the four direction contributivity of such three pix-els is then taken along 16 lines in eight different directions.Therefore, the dimension of the original PDC feature vector is8"3"4"16--1536.
By using 2-stage feature selection, it can bereduced to 256, while still preserving the original recognitionability.924Using the language model (9), the OCR error cor-rection task can be defined as finding a word se-quence r~d that maximizes the joint probability ofword sequence given recognized character sequenceP(WIX ).
By using Bayes' rule, this amounts tomaximizing the product of P(X IW ) and P(W).= arg mwax P(W\[X) = arg mwax P(X\[W)P(W) (10)The maximization search can be efficiently imple-mented by using the Viterbi-like dynamic program-ing procedure described in (Nagata, 1996).
Thealgorithm starts from the beginning of the inputsentence, and proceeds character by character.
Ateach point in the sentence, it looks up the combina-tion of the best partial word segmentation hypoth-esis ending there and all word hypotheses startingthere.
The word hypotheses proposed at each pointinclude both exactly matched words and approxi-mately matched words.
All prefixes of the substringstarting at the point are also proposed as unknownwords if they are not in the dictionary.3.2 Word Model for Unknown WordsWe defined a statistical word model to assign a rea-sonable word probability to an arbitrary substringin the input sentence.
The word model is formallydefined as the joint probability of the character se-quence wi = cl ... ck if it is an unknown word.
Wedecompose it into the product of word length prob-ability and word spelling probability,P(wil<tlNg>) = P(Cl... ck \[<IJNI~>) = P(k)P(cl... ck Ik) (11)where k is the length of the character sequence and<UNK> represents unknown word.We assume that word length probability P(k)obeys a Poisson distribution whose parameter is theaverage word length A in the training corpus.
Thismeans that we regard word length as the intervalbetween hidden word boundary markers, which arerandomly placed with an average interval equal tothe average word length.P(k) = (A - 1) k-1(k -  1)!
e-(X-\]) (12)We approximate the spelling probability givenword length P(cl...c~\[k) by the word-based char-acter bigram model, regardless of word length.kP(cx ... Ck) = P(Cl \[#) 1-IP(cilci-1)P(#\[ck) (13)i=2where "#" indicates the word boundary marker.4 Approx imate  Word  Match ingSince there are no delimiters between words inJapanese, we have to hypothesize all substrings inthe input sentence as words, and retrieve their ap-proximately matching words from the dictionary ascorrection candidates.
The most likely correctioncandidate isselected by the word segmentation algo-rithm using the OCR model and the language model.For simplicity, we will present he method as if itwere for an isolated word error correction.In English spelling correction, correction candi-dates are generated by the minimum edit distancetechnique (Wagner and Fischer, 1974).
Edit dis-tance is the minimum number of editing operations(insertions, deletions, and substitutions) required totransform one string into another.
Since the tar-get is OCR output, we can restrict he type of er-rors to substitutions only.
Thus, the edit distanceof two words becomes c/n, where c is the number ofmatched characters and n is the length of the mis-spelled (and the dictionary) word.
Since the cost ofcomputing the edit distance between a string and alldictionary words is expensive, we create an invertedindex into the dictionary using character bigrams asthe access keys (Angell et al, 1983).In Japanese OCR spelling correction, it is rea-sonable to generate correction candidates by editdistance for words longer than 2 characters incethe number of correction candidates would be small.However, for two character words, edit distance isuseless, because there are a large number of wordswith one edit distance.
Since the average wordlength of Japanese is about two characters, this isa serious problem.We propose an approximate word matchingmethod that uses character similarity.
Let X be anon-word caused by OCR errors, and W be a cor-rection candidate word.
X would be corrected by Wif the following relationship holds,P(X)P(X IX  ) < P (W)P(X IW ) (14)The left hand side represents the probability thatX is an unknown word and that it is correctly rec-ognized.
The right hand side represents he proba-bility that W is incorrectly recognized as X. Thelarger the product of the word unigram probabilityP(W) and the word confusion probability P(XIW),the more likely word W is the correct word for X.Therefore, for two character words, we sort the listof all one edit distance words by P(W)P(X  I W), andselect he top-k words as the correction candidates.For example, if "~"  is incorrectly recognized as"~" ,  there are at least 20 dictionary words whoseedit distance is one.925If we sort the list of one edit distance words byP(W), P(XIW), and P(W)P(X\[W), the correctioncandidates become as follows,sorted by P(W):t~  ~ \[\]~ tt~ ~ ...sorted by P(XIW):tt~ ~ ~ tt~ \[\]~ ...sorted by P(W) P(XIW):~ tt~Y ~ ~ ~ ...Thus, by using P(W)P(XIW), we can make "~~"  the most likely correction word.
The approxi-mate word matching method is so accurate that, inpractice, it is sufficient o use only the top 5 candi-dates.
This makes the program very efficient.5 Experiments5.1 Training Data  for the Language Mode lWe used the EDR Japanese Corpus Version 1.0(EDR, 1991) to train the language model.
It is acorpus of approximately 5.1 million words (208 thou-sand sentences).
It contains a variety of Japanesesentences taken from newspapers, magazines, dic-tionaries, encyclopedias, textbooks, etc.
It has avariety of annotations including word segmentation,pronunciation, and part of speech.In this experiment, we randomly selected 90% ofthe sentences in the EDR Corpus for training.
Thefirst column of Table 1 shows the number of sen-tences, words, and characters of the training set.Table 1: The amount of the training data and thetest data for handwritten OCRtrainingSentences 192802Words 4746461Characters 7521293testl10024633912There were 133281 distinct words in the trainingdata.
We discarded the words whose frequency wasone, and made a dictionary of 65152 words.
We thencounted the vocabulary dependent word bigrams.That is, the words that were not in the dictionarywere replaced with the unknown word symbol <UNK>before counting the bigrams.
There were 758172distinct word bigrams.
We discarded the bigramswhose frequency was one, and the remaining 294668bigrams were used in the word segmentation model.In the word model, we used 3167 character uni-grams and 91198 character bigrams.
All unigramsand bigrams whose frequencies were one were dis-carded.
As for the average word length, instead ofaveraging all words in the corpus (=1.58), we aver-aged the words whose frequency was one (=4.76) inorder to avoid the influence of highly frequent words.5.2 Test l :  Handwr i t ten  OCRWe designed two experiments oevaluate the perfor-mance of the OCR error corrector.
The first experi-ment used simulated outputs of a handwriting OCR,while the second used real outputs of a printed char-acter OCR.The first experiment was designed to test the OCRerror corrector over a wide range of baseline recogni-tion accuracies.
The use of the OCR simulator wasnecessary because it is very difficult to obtain a largeamount of test data with arbitrary accuracies.We selected 100 sentences from the remaining 10%of the EDR corpus for testing.
The second columnof Table 1 shows the number of sentences, words,and characters of the test set.
By using an OCRsimulator, we made four sets of character matriceswhose first-rank recognition accuracies were 70%,80%, 90%, and 95%.
They contained at most 10candidates for each character and their cumulativerecognition accuracies were 90%, 95%, 98%, and98%, respectively.For comparison, we implemented the OCR er-ror correction method, which does not use char-acter similarity information, presented in (Nagata,1996).
Instead of using character confusion matrix,he approximated it by the correct character distri-bution over the rank of the candidates 3.
We referto his method as the candidate rank method, andour method as the character similarity method.Figure 1 shows the recognition accuracies after er-ror correction for various baseline OCR accuracies.The horizontal axis represents he accuracies of thebaseline OCR, while the vertical axis represents heaccuracies after error correction.
The farther thepoint lies above the diagonal line, the more improve-ments are brought by the OCR error corrector.3In (Nagata, 1996), it was assumed that the rank orderdistribution of the correct characters i a geometric distribu-tion whose parameter is the accuracy of the first candidate.Let c/ be the i-th character in the input, xlj be the j - th  can-didate for ci in the output, and p be the probability that thefirst candidate is correct.
The confusion probability P(xij Icl)is approximated as,P(xij\]ci) ~ P(xi j  is correct) ~ p(1 -p ) j -19260.95v 0.00.80.750.70.65 i I0 .~ 0 7 0.75Error Coerec2ion Accu.1cyh - "oS=m~R=J.
.
? "
"4* "S~mly? '
' "First Rank Accuracy ,.e.--Cumulative Accuracy -4- ?Ch=mcter Similarity DCindidm Rink  xi I i I0.8 0.85 0.9 0.95C~lracter R~.ognition Accuracy (Before NiP)Figure 1: Comparison of the improvement in char-acter recognition accuracyThe character similarity method is significantlybetter than the candidate rank method for all base-line recognition accuracies examined.
For example,when the baseline accuracy is 90%, the charactersimilarity method achieved 97.4%, while the accu-racy of the candidate rank method was 93.9% 45.3 Test2:  P r in ted  Character  OCRThe second experiment was designed to test theOCR error corrector on unrestricted text and un-known OCR.
In the first experiment, although thetest sentences were open data, their statistical char-acteristics are expected to be similar to the trainingdata because both of them were taken from the samecorpus.
Moreover, since the OCR simulator and theOCR error corrector used the same character confu-sion matrix, the input character matrices were closeddata with respect o OCR.We selected 30 documents, each of which con-tained about 1000 characters.
These documents hadnothing to do with the EDR corpus.
Ten of themwere newspapers and the other 20 documents werea miscellaneous collection of novels, essays, patents,laws, scientific papers, etc.. Table 2 shows the break-down of document type and image resolution.
News-papers were scanned at 300dpi and 400dpi, two of4(Nagata, 1996) reported that, when the baseline accuracyis 90%, his method achieved 96.3%.
The difference between96.3% and 93.9% comes from the difference in the corpora.He tested the ATR corpus whose word perplexity is about 30,while we tested the EDR corpus whose perplexity is about 95.Here, perplexities are computed using word bigram model.Table 2: The document type and the image resolu-tion of the test data for the printed character OCR200dpi 300dpi 400dpinewspapers 0 8 10miscellaneous 20 20 10them, scanned at 300dpi, were discarded because oflow quality.
Other miscellaneous documents weremainly scanned at 200dpi and 300dpi.
Ten that usedsmaller fonts were also scanned at 400dpi.The printed character OCR used was a commer-cial product (RICOH Yomitori-Monogatari).
It out-puts at most 10 candidates for each character as wellas a score ranging from 0 to 100 that represents thecertainty of the first candidate.
In fact, we knownothing about the algorithm and the training dataof the OCR.
At least, the training data should bedifferent from ours since one is created for printedcharacters while the other was designed for hand-written characters.The 68 test document images contained 69102 in-put characters.
After character ecognition, therewere 69305 output characters where 67639 (97.9%)characters were correct.
There were 1422 (2.1%) re-placement errors, 244 (0.4%) insertion errors and 41(0.06%) deletion errors.10.990.980.970.960.950.940.930.920.91Error Correction Accuracyoo  oo~?o e~ oe ?
o~0 i i i i l i I i iO.
.9 0.91 0,92 0.93 0,94 0.95 0.96 0,97 0.98 0.99Character Recognition Accuracy (Before NLP)Figure 2: Error correction accuracyBy using the OCR error corrector, 575 characterswere corrected, where 294 were right and 281 werewrong.
The net improvement was only 13 charac-ters.
Figure 2 shows the recognition accuracies ofeach document image before and after error correc-927Table 3: OCR score and the number of right andwrong corrections by the error correctorOCR score <= 100right correction 294wrong correction 281net improvements 13<= 80 <= 60199 16948 22151 147tion: 24 documents were improved, 30 documentsgot worse, and 14 documents were unchanged.Figure 2 indicates that the OCR error correctorimproves the accuracy when the baseline recognitionaccuracy is less than 98%, while it worsens when theaccuracy is more than 98%.
This is mainly becauseof wrong corrections, where unknown words in theoriginal text are replaced by more frequent words inthe dictionary.
Most unknown words are numbers,acronyms, and transliterated foreign words.Wrong correction can be avoided if the certainty ofthe character recognition (OCR score) is available.Table 3 shows the number of right and wrong cor-rections when correction is allowed only if the theOCR score is less than a certain threshold.
Thescore of the printed character OCR ranges from 0to 100, where 100 means it is pretty sure about theoutput.
If we reject he corrections suggested by theerror corrector when the OCR score is more than80, the number of wrong corrections i  reduced from281 to 48, while that of right correction is reducedfrom 294 to 199.
Thus, the number of net improve-ments increases from 13 to 151, which means a 10.6%(151/1422) reduction in replacement errors.6 Discuss ionMost previous works on Japanese OCR error cor-rection considered only printed character OCRsand their target domain was limited.
(Takao andNishino, 1989) used part of speech bigram modeland heuristic templates for unknown words.
Theyachieved about 95% accuracy when the baseline ac-curacy was 91% for magazines and introductorytextbooks of science and technology.
(Ito andMaruyama, 1992) used part of speech bigram modeland beam search in order to get multiple candidatesin their interactive OCR corrector.
They achieved94.61% accuracy when the baseline accuracy was87.46% for patents in electric engineering.
We usedword bigram model, a statistical word model for un-known words, and a statistical OCR model.
Weachieved 97.4% accuracy, when the baseline accu-racy was 90% and the domain was not limited.It is very difficult to compare our results with theprevious results because the experiment conditionsare completely different.
However, considering thefact that we did not restrict he target domain, ourmethod arguably outperformed the previously pub-lished results, when the baseline accuracy is morethen 90%.
There is only one published work inves-tigating the baseline accuracy much lower than 90%(Nagata, 1996).
As we proved in the experiment, weoutperformed his results ignificantly.7 Conclus ionWe have presented a Japanese OCR error corrector.It arguably outperforms previously published tech-niques.
To improve the error correction accuracy,a more sophisticated language model for unknownwords, including numbers, acronyms, and transliter-ated foreign words, must be investigated.ReferencesRichard C. Angell, George W. Freund, and Peter Willett.1983.
Automatic spelling correction using a trigram sim-ilarity measure.
Information Processing ~ Management,19(4):255-261.Kenneth W. Church and William A. Gale.
1991.
Probabilityscoring for spelling correction.
Statistics and Computing,1:93-103.EDR.
1991.
Edr electronic dictionary version 1 technicalguide.
Technical Report TR2-003, Japan Electronic Dic-tionary Research Institute.Andrew R. Golding and Yves Schabes.
1996.
Combin-ing trigram-based and feature-based method for context-sensitive spelling correction.
In ACL-96, pages 71-78.I.
J.
Good.
1953.
The population frequencies of speciesand the estimation of population parameters.
Biometrika,40:237-264.Norihiro Hagita, Seiichiro Naito, and Isao Masuda.
1983.Handprinted chinese characters recognition by periph-eral direction contributivity feature.
IEICE Transactionson Information and Systems, J66-D(10):l185-1192.
(InJapanese).Thomas H. Hildebrandt and Wentai Liu.
1993.
Optical recog-nition of handwritten chinese characters: Advances ince1980.
Pattern recognition, 26(2):205-225.Nobuyasu Ito and Hiroshi Maruyama.
1992.
A method of de-tecting and correcting errors in the results of japanese ocr.Transaction of Information Processing Society of Japan,33(5):664-670.
(In Japanese).Karen Kukich.
1992.
Techniques for automatically correctingwords in text.
A CM Computing Surveys, 24(4):377-439.Yoseph Linde, AndrOs Buzo, and Robert M. Gray.
1980.
Analgorithm for vector quantizer design.
IEEE Transactionson Communications, COM-28(1):84-95.Eric Mays, Fred J. Damerau, and Robert L. Mercer.
1991.Context based spelling correction.
Information ProcessingManagement, 27(5).
'517-522.Masaaki Nagata.
1996.
Context-based spelling correction forjapanese ocr.
In COLING-96, pages 806-811.Eric K. Ringger and James F. Allen.
1996.
A fertility channelmodel for post-correction ofcontinuous peech recognition.In ICSLP-96, pages 897-900.Tetsuyasu Takao and Fumihito Nishino.
1989.
Implementa-tion and evaluation of post-processing for japanese docu-ment readers.
Transaction of Information Processing So-ciety of Japan, 30(11):1394-1401.
(In Japanese).Xiang Tong and David A. Evans.
1996.
A statistical approachto automatic ocr error correction in context.
In WVLC-96,pages 88-10.Robert A. Wagner and Michael J. Fischer.
1974.
Thestring-to-string correction problem.
Journal of the ACM,21(1):168-173.Ian H. Witten and Timothy C. Bell.
1991.
The zero-frequencyproblem: Estimating the probabilities of novel events inadaptive text compression.
IEEE Transaction on Infor-mation Theory, 37(4):1085-1094.928
