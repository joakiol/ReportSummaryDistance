Proceedings of the 3rd Workshop on Predicting and Improving Text Readability for Target Reader Populations (PITR) @ EACL 2014, pages 123?130,Gothenburg, Sweden, April 26-30 2014.c?2014 Association for Computational LinguisticsAn Analysis of Crowdsourced Text SimplificationsMarcelo Adriano AmancioDepartment of Computer ScienceUniversity of SheffieldSheffield, UKacp12maa@sheffield.ac.ukLucia SpeciaDepartment of Computer ScienceUniversity of SheffieldSheffield, UKl.specia@sheffield.ac.ukAbstractWe present a study on the text simplifica-tion operations undertaken collaborativelyby Simple English Wikipedia contribu-tors.
The aim is to understand whethera complex-simple parallel corpus involv-ing this version of Wikipedia is appropri-ate as data source to induce simplifica-tion rules, and whether we can automat-ically categorise the different operationsperformed by humans.
A subset of the cor-pus was first manually analysed to iden-tify its transformation operations.
We thenbuilt machine learning models to attemptto automatically classify segments basedon such transformations.
This classifica-tion could be used, e.g., to filter out po-tentially noisy transformations.
Our re-sults show that the most common transfor-mation operations performed by humansare paraphrasing (39.80%) and drop of in-formation (26.76%), which are some ofthe most difficult operations to generalisefrom data.
They are also the most diffi-cult operations to identify automatically,with the lowest overall classifier accuracyamong all operations (73% and 59%, re-spectively).1 IntroductionUnderstanding written texts in a variety of forms(newspapers, educational books, etc.)
can be achallenge for certain groups of readers (Paciello,2000).
Among these readers we can cite secondlanguage learners, language-impaired people (e.g.aphasic and dyslexic), and the elderly.
Sentenceswith multiple clauses, unusual word order and rarevocabulary are some of the linguistic phenomenathat should be avoided in texts written for these au-diences.
Although initiatives like the Plain English(Flesch, 1979) have long advocated for the use ofclear and concise language, these have only beenadopted in limited cases (UK government bodies,for example).
The vast majority of texts which areaimed at the broad population, such as news, areoften too complex to be processed by a large pro-portion of the population.Adapting texts into their simpler variants is anexpensive task.
Work on automating this processonly started in recent years.
However, already inthe 1920?s Lively and Pressey (1923) created amethod to distinguish simple from complex textsbased on readability measures.
Using such mea-sures, publishers were able to grade texts accord-ing to reading levels (Klare and Buck, 1954) sothat readers could focus on texts that were appro-priate to them.
The first attempt to automate theprocess of simplification of texts was devised byChandrasekar et al.
(1996).
This pioneer work hasshown that it was possible to simplify texts auto-matically through hand-crafted linguistic rules.
Infurther work, Chandrasekar et al.
(1997) devel-oped a method to extract these rules from data.Siddharthan (2002) defines Text Simplificationas any method or process that simplifies text whilemaintaining its information.
Instead of hand-crafted rules, recent methodologies are mostlydata-driven, i.e., based on the induction of sim-plification rules from parallel corpora of complexsegments and their corresponding simpler vari-ants.
Specia (2010) and Zhu et al.
(2010) modelthe task using the Statistical Machine Translationframework, where simplified sentences are consid-ered the ?target language?.
Yatskar et al.
(2010)construct a simplification model based on edits inthe Simple English Wikipedia.
Woodsend and La-pata (2011) adopt a quasi-synchronous grammarwith optimisation via integer linear programming.This research focuses the corpus used by most of123previous data-driven Text Simplification work: theparallel corpus of the main and simple EnglishWikipedia.Following the collaborative nature ofWikipedia, a subset of the Main EnglishWikipedia (MainEW) has been edited byvolunteers to make the texts more readable to abroader audience.
This resulted in the SimpleEnglish Wikipedia (SimpleEW)1, which we con-sider a crowdsourced text simplification corpus.Coster and Kauchak (2011) paired articles fromthese two versions and automatically extractedparallel paragraphs and sentences from them(ParallelSEW).
The first task was accomplished ina straightforward way, given that correspondingarticles have the same title as unique identifica-tion.
The paragraph alignment was performedselecting paragraphs when their normalised TF-IDF weighted cosine distance reached a minimumthreshold.
Sentence alignment was performed us-ing monolingual alignment techniques (Barzilayand Elhadad, 2003) based on a dynamic pro-gramming algorithm.
In total, 137, 000 sentenceswere found to be parallel.
The resulting parallelcorpora contains transformation operations ofvarious types, including rewording, reordering,insertion and deletion.
In our experiments weanalyse the distribution of these operations andperform some further analysis on their nature.Most studies on data-driven Text Simplificationhave focused on the learning of the operations,with no or little qualitative analysis of the TextSimplification corpora used (Yasseri et al., 2012).As in any other area, the quality of machine learn-ing models for Text Simplification will depend onthe size and quality of the training dataset.
Ourstudy takes a step back to carefully look at themost common simplification corpus and: (i) un-derstand the most common transformation oper-ations performed by humans and judge whetherthis corpus is adequate to induce simplificationrules from, and (ii) automatically categorise trans-formation operations such as to further processand ?clean?
the corpus, for example to allow themodelling of specific simplification phenomena orgroups of phenomena individually.
After review-ing some of the relevant related work (Section 2),in Section 3, we present the manual analysis of asubset of the ParallelSEW corpus.
In Section 4 we1http://simple.wikipedia.org/wiki/Main_Pagepresent a classification experiments to label thiscorpus according to different simplification oper-ations.
Finally, we present a discussion of the re-sults in section 5.2 Literature ReviewThe closest work to ours is that of Yasseri et al.(2012).
They present a statistical analysis of lin-guistic features that can indicate language com-plexity in both MainEW and SimpleEW.
Differ-ent from our work, their analysis was automatic,and therefore more superficial by nature (mostlycounts based on pattern matching and simple read-ability metrics).
They have found equivalent vo-cabulary complexity in both versions of Wikipedia,although one could expect simpler vocabulary inSimpleEW.
They have also demonstrated that Sim-pleEW is considered simpler mainly because itpresents shorter sentences, as opposed to sim-pler grammar.
Additionally, they found a highinterdependence between topicality and languagecomplexity.
Conceptual wikipages were found tobe linguistically more complex than biographicalones, for example.
For measuring language com-plexity, the Gunning readability index (Gunning,1969) was used.
As in Besten and Dalle (2008),additional complexity metrics are said to be nec-essary to better assess readability issues in Sim-pleEW.
(Petersen and Ostendorf, 2007)?s work is in thecontext of bilingual education.
A corpus of 104news parallel texts, original and simplified ver-sions of the Literacyworks corpus (Petersen andOstendorf, 2007), was used.
The goal was to iden-tify which simplification operations were morefrequent and provide a classifier (using machinelearning) as an aiding tool for teachers to deter-mine which sentences should be (manually) sim-plified.
For the classification of sentences thatshould be split, attributes such as sentence length,POS tags, average length of specific phrases (e.g.S, SBAR, NP) were used.
For the classificationof sentences that should be dropped, the featuresused included the position of the sentence in thedocument, its paragraph position, the presence ofquotation marks, rate of stop words in the sen-tence, and percentage of content words.
It wasreported that the simplified versions of texts had30% fewer words, and that sentences were 27%shorter, with the elimination of adjectives, adverbsand coordinating conjunctions, and the increase of124nouns (22%) and pronouns (33%).
In the experi-ments in this paper, we use similar features to clas-sify a broader set of text simplification operations.With similar goal and methodology, (Gasperinet al., 2009) use a parallel corpus containing origi-nal and simple news sentences in Portuguese.
Abinary classifier was built to decide which sen-tences to split, reaching precision of above 73%.The feature set used was rich, including surfacesentence cues (e.g.
number of words, number ofverbs, numbers of coordinative conjunctions), lex-icalized cue phrases and rhetoric relations (e.g.conclusions, contrast), among others.Medero and Ostendorf (2011) work was moti-vated by language-learning contexts, where teach-ers often find themselves editing texts such thatthey are adequate to readers with certain nativelanguages.
In order to develop aiding tools forthis task, a number of attributes that lead to dif-ferent operations were identified.
Attributes lead-ing to sentences splitting include sentence lengthand POS tags frequency.
Attributed that lead tosentences being dropped include position of a sen-tence in a document, paragraph number, presenceof a direct quotation, percentage of stop words,etc.
Based on these attributes, a classifier wasbuilt to make splitting and dropping decisions au-tomatically, reaching average error rates of 29%and 15%, respectively.Stajner et al.
(2013) focus on selecting can-didates for simplification in a parallel corpus oforiginal and simplified Spanish sentences.
A clas-sifier is built to decide over the following opera-tions: sentence splitting, deletion and reduction.The features are similar to those in (Petersen andOstendorf, 2007; Gasperin et al., 2009), with addi-tional complexity features, such as sentence com-plexity index, lexical density, and lexical richness.They achieve an F-measure of 92%.3 Corpus Annotation and StatisticsOur first study was exploratory.
We randomly ex-tracted 143 sentence pairs from the ParallelSWEcorpus.
We then annotated each sentence in thesimplified version for the transformation opera-tions (TOs) undertaken by Simple Wikipedia con-tributors on the Main English Wikipedia to gener-ate this version.
We refer to this corpus as Paral-lel143.
These annotations will be used as labelsfor the classification experiments in Section 4.We start our analysis by looking at the numberof transformations that have been applied to eachsentence: on average, 2.1.
More detailed statisticsare shown in Table 1 .# Sentences 143# TOs 299Avg.
TOs/sentence 2.10Table 1: Counts of transformation operations inthe Parallel143 corpusA more interesting way to look at these num-bers is the mode of the operations, as shown inTable 2.
From this table we can notice that mostsentences had only one transformation operation(about 48.2% of the corpus).
Two to three opera-tions together were found in 36.4% of the corpus.Four or more operations in only about 11.8%.N.
of TOs.
N. of sent.
% of sent.1 69 0.482 30 0.213 22 0.154 12 0.085 6 0.036 3 0.027 0 0.008 1 0.01Table 2: Mode of transformation operations in theParallel143 corpusThe 299 operations found in the corpus wereclassified into five main transformation operations,which are also common in the previous work men-tioned in Section 2: Sentence Splitting (SS); Para-phrasing (PR); Drop of Information (DI); Sen-tence Reordering (SR); Information Insertion (II);and a label for ?Not a Parallel Sentence?
(NPS).Paraphrasing is often not considered as an opera-tion on itself.
Here we use it to refer to transfor-mations that involve rewriting the sentence, be itof a single word or of the entire sentence.
In Ta-ble 3 we show the distribution these operations inthe corpus.
We can observe that the most commonoperations were paraphrasing and drop of infor-mation.
Also, it is interesting to notice that morethan 7% of the corpus contains sentences that arenot actually parallel (NPS), that is, where the sim-plified version does not correspond, in meaning, tothe original version.125TO Frequency of TO % of TOPR 119 39.80DI 80 26.76II 38 12.71NPS 23 7.69SS 21 7.02SR 18 6.02Table 3: Main transformation operations found inthe Parallel143 corpusDifferent from previous work, we further cate-gorise each of these five main transformation oper-ations into more specific operations.
These subcat-egorisation allowed us to further study the trans-formation phenomena that can occur in the Paral-lelSWE corpus.
In the following sections we de-scribe the main operations and their subcategoriesin detail and provide examples.3.1 Sentence Splitting (SS)Sentence Splitting (SS) is the rewriting of a sen-tence by breaking it into two or more sentences,mostly in order avoid to embedded sentences.
Thisis overall the most common operation modelled inautomatic Text Simplification systems, as it is rel-atively simple if a good syntactic parser is avail-able.
It has been found to be the most commonoperation in other corpora.
For example, in thestudy in (Caseli et al., 2009) it accounts for 34%of the operations.
Nevertheless, it was found to berelatively rare in the Parallel143 corpus, account-ing for only 7% of the operations.
One possiblereason for this low number is the automatic align-ment of our corpus according to similarity metrics.This matching algorithm could occasionally fail inmatching sentences that have been split.
Withinthe SS categories, we have identified three subcat-egories: (1) simple sentence splitting (59.01%),where the splitting does not alter the discoursestructure considerably; (2) complex sentence split-ting (36.36%), where sentence splitting is associ-ated with strong paraphrasing, and (3) inverse sen-tence splitting (4.63%), i.e., the joining of two ormore sentences into one.Sentences 1 and 2 show an example of com-plex sentence splitting.
In this case, the splittingseparates the information about the BirminghamSymphony Orchestra?s origin from where it is lo-cated into two different sentences.
The operationalso includes paraphrasing and adding informationto complement the original sentence.Sentence 1 ?
MainEW:?The City of Birmingham SymphonyOrchestra is a British orchestra based inBirmingham, England.
?Sentence 2 ?
SimpleEW:?The City of Birmingham SymphonyOrchestra is one of the leading Britishorchestras.
It is based in the SymphonyHall, Birmingham, England.
?3.2 Drop of Information (DI)In the Parallel143 corpus we have observed thatthe second most frequent operation is droppingparts of the segment.
We have sub-classifiedthe information removal into three classes: (1)drop of redundant words (11.25%), for caseswhen dropped words have not altered the sen-tence meaning, (2) drop of auxiliary information(12.50%), where the auxiliary information in theoriginal sentence adds extra information that canelicit and reinforce its meaning, and (3) drop ofphrases (76.25 %), when phrases with importantnuclear information are dropped, incurring in in-formation loss.Sentences 3 and 4 show an example of par-allel sentence with two occurrences of DI cases.The phrases At an elevation of 887m and in theKingdom of are dropped, with the first phrase rep-resenting a loss of information, which the secondcould be considered redundant.Sentence 3 ?
MainEW:?At an elevation of 877m, it is thehighest point in the Kingdom of theNetherlands.
?Sentence 4 ?
SimpleEW:?It is the highest point in the Nether-lands.
?3.3 Information Insertion (II)Information Insertion represents the adding of in-formation to the text.
During the corpus analy-sis we have found different sub-categories of thisoperation: (1) eliciting information (78.95%), incases when some grammatical construct or aux-iliary phrase is inserted enriching the main in-formation already in the text, or making it moreexplicit, (2) complementary external information(18.42%), for cases when external information is126inserted to complement the existing information,and (3) spurious information (2.63%), for whennew information is inserted but it does not relatewith the original text.
We assume that latter casehappens due to errors in the sentence alignmentalgorithm used to build the corpus.In sentences 5 and 6, we show an example ofexternal information insertion.
In this case, the op-eration made the information more specific.Sentence 5 ?
MainEW:?The 14 generators in the north side ofthe dam have already been installed.
?Sentence 6 ?
SimpleEW:?The 14 main generators in the northside were installed from 2003 to 2005.?3.4 Sentence Reordering (RE)Some of the transformation operations results inthe reordering of parts of the sentence.
Wehave classified reordering as (1) reorder individ-ual phrases (33.33%), when a phrase is movedwithin the sentence; and (2) invert pairs of phrases(66.67%), when two phrases have their positionswapped in the sentence.
In sentences 7 and 8we can see an example moving the phrase June20, 2003 to the end of the SimpleEW sentence.Sentence 7 ?
MainEW:?The creation of the foundation was of-ficially announced on June 20, 2003by Wikipedia co-founder Jimmy Wales, who had been operating Wikipedia un-der the aegis of his company Bomis.
?Sentence 8 ?
SimpleEW:?The foundations creation was offi-cially announced by Wikipedia co-founder Jimmy Wales, who was runningWikipedia within his company Bomis,on June 20, 2003.?3.5 Paraphrasing (PR)Paraphrase operations are the most common mod-ification found in the Parallel143 corpus.
We fur-ther classified it into 12 types:?
Specific to generic (21.01%): some specificinformation is substituted by a broader andmore generic concept;?
Generic to specific (5.88%): the opposite ofthe above operation;?
Noun to pronoun (3.36%): a noun is substi-tuted by a pronoun;?
Pronoun instantiation (2.52%): a pronoun issubstituted by its referring noun;?
Word synonym (14.29%): a word is substi-tuted by a synonym;?
Discourse marker (0.84%): a discoursemarker is altered;?
Word definition (0.84%): a word is substi-tuted by its dictionary description;?
Writing style (7.56%): the writing style of theword, e.g.
hyphenation, changes;?
Preposition (3.36%): a proposition is substi-tuted;?
Verb substitution (5.04%): a verb is replacedby another verb;?
Verb tense (2.52%): the verb tense ischanged; and?
Abstract change (32.78%): paraphrasesubstitution that contains abstract, non-systematic changes, usually depending onexternal information and human reasoning,resulting in considerable modifications in thecontent of the simplified sentence.In sentences 9 and 10 we can observe a case ofabstract change.
The MainEW sentence has de-scriptive historical details of the city of Prague.The SimpleEW version is shorter, containing lessfactual information when compared to the firstsentence.Sentence 9 ?
MainEW:?In 1993, after the split of Czechoslo-vakia, Prague became the capital city ofthe new Czech Republic.
?Sentence 10 ?
SimpleEW:?Prague is the capital and the biggestcity of the Czech Republic.
?Another common operation is shown in Sen-tences 11 and 12.
The substitution of the wordhidden by put represents a change of specific togeneric.127Sentence 11 ?
MainEW:?The bells were transported north toNorthampton-Towne, and hidden in thebasement of the Old Zion ReformedChurch, in what is now center city Al-lentown.
?Sentence 12 ?
SimpleEW:?The bells were moved north toNorthampton-Towne, and put in thebasement of the Old Zion ReformedChurch, in what is now center ofAllentown.
?The outcome of this study that is of mostrelevance to our work is the high percentageof sentences that have undergone paraphras-ing/rewriting, and in special the ones that sufferedabstract changes.
These cases are very hard togeneralise, and any learning method applied to acorpus with a high percentage of these cases islikely to fail or to induce noisy or spurious opera-tions.4 Classification ExperimentsOur ultimate goal of this experiment is to selectparts of the ParallelSWE corpus that are more ad-equate for the learning of certain simplificationrules.
While it may seem that simplification opera-tions comprise a small set which is already knownbased on previous work, we would like to focuson the learning of fine-grained, lexicalized rules.In other words, we are interested in the learning ofmore specific rules based on lexical items in ad-dition to more general information such as POStags and syntactic structures.
The learning of suchrules could benefit from a high quality corpus thatis not only noise-free, but also for which one al-ready has some information about the general op-eration(s) covered.
In an ideal scenario, one couldfor example use a subset of the corpus that con-tains only sentence splitting operations to learnvery specific and accurate rules to perform dif-ferent types of sentence splitting in unseen data.Selecting a subset of the corpus that contain onlyone transformation operation per segment is alsoappealing as it would facilitate the learning.
Theprocess of manually annotating the corpus with thecorresponding transformation operations is how-ever a laborious task.
For this reason, we havetrained classifiers on the labelled data described inthe previous section with two purposes:?
Decide over the six main transformation op-erations presented in the previous section;and?
Decide whether a sentence was simplified byone operation only, or by more than one op-eration.The features used in both experiments are de-scribed in Section 4.1 and the algorithms and re-sults are presented in Section 4.2.4.1 FeaturesWe extract simple features from the source (orig-inal, complex) and target (simplified) sentences.These were inspired by previous work, including(Medero and Ostendorf, 2011; Petersen and Os-tendorf, 2007; Gasperin et al., 2009;?Stajner et al.,2013):?
Size of the source sentence: how many wordsthere are in the source sentence;?
Size of the target sentence: how many wordsthere are in the target sentence;?
Target/source size ratio: the number of wordsin the target sentence divided by the numberof words in the source sentence;?
Number of sequences of words dropped inthe target sentence;?
Number of sequences of words inserted in thetarget sentence; and?
Occurrence of lexical substitution (true orfalse).4.2 Machine Learning ModelsOur experiments are divided in two parts.
In thefirst part, we train six binary classifiers to test thepresence of the following transformation opera-tions: Information Insertion (II); Drop of Informa-tion (DI); Paraphrasing (PR); Sentence Reordering(SR); Sentence Splitting (SS); Not a Parallel Sen-tence (NPS).The second experiment evaluated whether thesimplification operation performed in the segmentwas simple or complex (S/C).
We consider simplea transformation that has only one operation, andcomplex when it has two or more operations.A few popular classifiers from the Weka pack-age (Hall et al., 2009) with default parameters128were selected.
The experiments were devised us-ing the 10-fold cross validation.
The results ?measured in terms of accuracy ?
for each of theseclassifiers with the best machine learning algo-rithm are shown in Table 4.
These are comparedto the accuracy of the majority class baseline (i.e.,the class with the highest frequency in the train-ing set).
Table 5 shows the best machine learningalgorithm for each classification problem.TO Baseline (%) Model (%)NPS 83.3 90.2SR 89 90SS 86 87II 79 86PR 61 73DI 59 69S/C 51 81Table 4: Baselines and classifiers accuracy of thetransformation operationsAccording to Table 4, the identification of non-parallel sentences (NPS) and sentence reordering(SR) achieved the highest accuracies of 90.2% and90%, followed by syntactic simplification (SS)and Information Insertion (II) with values of 87%and 86%, respectively.
Paraphrases (PR) and dropinformation (DI) have scored last, although theyyielded a significant gain of 12% and 10% ab-solute points, respectively, when compared withbaseline.
The decision between simple and com-plex transformations was the task with best rel-ative gain in accuracy compared to the baseline(30%).TO Best algorithmNPS Bayesian LogisticSR SMOSS Simple LogisticII Simple LogisticPR LogisticDI Simple LogisticS/C Bayes NetTable 5: Best machine learning algorithm for eachoperation/taskThe difference in the performance of differentalgorithms for each operation requires further ex-amination.
For different classifiers on the samedataset, the accuracy figures varied from 2 to 10points, which is quite significant.We found the results of these experimentspromising, particularly for the classifiers NPS andS/C.
The outcome of the classifier for NPS, forexample, means that with an accuracy of over90% we can filter out sentences from the SimpleWikipedia Corpus which are not entirely parallel,and therefore would only add noisy to any rule in-duction algorithm.
The positive outcome of S/Cmeans that with 80% accuracy one could selectparallel sentences where the target contain onlyone operation to simplify the rule induction pro-cess.Overall, these results are even more promisinggiven two factors: the very small size of our la-belled corpus (143 sentences) and the very simpleset of features used.
Improvements on both frontsare likely to lead to better results.5 ConclusionThis research has focused on studying the paral-lel corpus of the Main English Wikipedia and itsSimple English Wikipedia corresponding version.Most current data-driven methods for text simpli-fication are based on this resource.
Our exper-iments include the identification and quantifica-tion of the transformation operations undertakenby contributors generating the simplified versionof the corpus, and the construction of classifiers tocategorise these automatically.Particularly interesting outcomes of our experi-ments include: (i) the high proportion of complexparaphrasing cases observed in the corpus (?40%of the operations), which is important since para-phrase generation is a difficult task to automate,particularly via machine learning algorithms; and(ii) the relatively high accuracy of our classi-fiers on the categorisation of certain phenomena,namely the identification of segment pairs whichare not parallel in meaning, and the filtering of thecorpus to select sentences that have undergone asingle transformation operation.
These classifierscan be used as filtering steps to improve the qual-ity of text simplification corpora, which we believecan in turn lead to better performance of learningalgorithms inducing rules from such corpora.AcknowledgementsThis research was supported by the CAPES PhDresearch grant n. 31983594814, process n.5475/10-4.129ReferencesRegina Barzilay and Noemie Elhadad.
2003.
Sentencealignment for monolingual comparable corpora.
InProceedings of the 2003 conference on Empiricalmethods in natural language processing, pages 25?32.
Association for Computational Linguistics.Matthijs Den Besten and Jean-Michel Dalle.
2008.Keep it simple: A companion for simple wikipedia?Industry and Innovation, 15(2):169?178.Helena M. Caseli, Tiago F. Pereira, Lucia Specia, Thi-ago A.S. Pardo, Caroline Gasperin, and Sandra M.Alu??sio.
2009.
Building a brazilian portuguese par-allel corpus of original and simplified texts.
Ad-vances in Computational Linguistics, Research inComputer Science, 41:59?70.Raman Chandrasekar and Bangalore Srinivas.
1997.Automatic induction of rules for text simplification.Knowledge-Based Systems, 10(3):183?190.Raman Chandrasekar, Christine Doran, and BangaloreSrinivas.
1996.
Motivations and methods for textsimplification.
In Proceedings of the 16th confer-ence on Computational linguistics-Volume 2, pages1041?1044.
Association for Computational Linguis-tics.William Coster and David Kauchak.
2011.
Simpleenglish wikipedia: a new text simplification task.In Proceedings of the 49th Annual Meeting of theAssociation for Computational Linguistics.
Strouds-burg, PA: Association for Computational Linguis-tics, pages 665?669.Rudolf Flesch.
1979.
How to write plainenglish.
URL: http://www.
mang.
canterbury.ac.
nz/courseinfo/AcademicWriting/Flesch.
htm [ac-cessed 2003 Oct 13][WebCite Cache].Caroline Gasperin, Lucia Specia, Tiago Pereira, andSandra Alu??sio.
2009.
Learning when to simplifysentences for natural text simplification.
Proceed-ings of ENIA, pages 809?818.Robert Gunning.
1969.
The fog index after twentyyears.
Journal of Business Communication, 6(2):3?13.Mark Hall, Eibe Frank, Geoffrey Holmes, BernhardPfahringer, Peter Reutemann, and Ian H Witten.2009.
The weka data mining software: an update.ACM SIGKDD Explorations Newsletter, 11(1):10?18.George Roger Klare and Byron Buck.
1954.
Knowyour reader: The scientific approach to readability.Hermitage House.Bertha A Lively and Sidney L Pressey.
1923.
Amethod for measuring the vocabulary burden of text-books.
Educational administration and supervision,9(389-398):73.Julie Medero and Mari Ostendorf.
2011.
Identifyingtargets for syntactic simplification.
In Proceedingsof the SLaTE 2011 workshop.Michael Paciello.
2000.
Web accessibility for peoplewith disabilities.
Taylor & Francis US.Sarah E Petersen and Mari Ostendorf.
2007.
Text sim-plification for language learners: a corpus analysis.In In Proc.
of Workshop on Speech and LanguageTechnology for Education.Advaith Siddharthan.
2002.
An architecture for atext simplification system.
In Language Engineer-ing Conference, 2002.
Proceedings, pages 64?71.IEEE.Lucia Specia.
2010.
Translating from complex to sim-plified sentences.
In Computational Processing ofthe Portuguese Language, pages 30?39.
Springer.Sanja?Stajner, Biljana Drndarevic, and Horacio Sag-gion.
2013.
Corpus-based sentence deletion andsplit decisions for spanish text simplification.Kristian Woodsend and Mirella Lapata.
2011.
Learn-ing to simplify sentences with quasi-synchronousgrammar and integer programming.
In Proceedingsof the Conference on Empirical Methods in NaturalLanguage Processing, pages 409?420.
Associationfor Computational Linguistics.Taha Yasseri, Andr?as Kornai, and J?anos Kert?esz.
2012.A practical approach to language complexity: awikipedia case study.
PloS one, 7(11):e48386.Mark Yatskar, Bo Pang, Cristian Danescu-Niculescu-Mizil, and Lillian Lee.
2010.
For the sake of sim-plicity: Unsupervised extraction of lexical simplifi-cations from wikipedia.
In Human Language Tech-nologies: The 2010 Annual Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics, pages 365?368.
Association forComputational Linguistics.Zhemin Zhu, Delphine Bernhard, and Iryna Gurevych.2010.
A monolingual tree-based translation modelfor sentence simplification.
In Proceedings of the23rd international conference on computational lin-guistics, pages 1353?1361.
Association for Compu-tational Linguistics.130
