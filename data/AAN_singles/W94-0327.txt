Bidirectional Incremental Generation and Analysis with Categorial Grammar and IndexedQuasi-Logical Form.Torbj/3m Lager William 3 BlackDepartment of Linguistics Centre for Computational LinguisticsUniversity of GOteborg UMIST, ManchesterE-mail: lager@ling.gu.se E-mail: bill@ccl.umist.ac.ukAbstractWe describe an approach to surface generation designed fora "pragmatics-based" dialogue system.
The implementationhas been extended to deal with certain well-knowndifficulties with the underlying linguistic formalism(Categorial Grammar) at the same time yielding a systemcapable of supporting incremental generation as well asinterpretation.
Aspects of the formalism used for the initialdescription that constitutes the interface with the planningcomponent are also discussed.1.
IntroductionIn a monolingual dialogue system, strong arguments areneeded for generation ot to reversibly use the samelinguistic resources as parsing.
We examine several charac-teristics of an implemented surface generation componentderiving from the needs of this application.
The generatoruses as its linguistic resource a lexicon encoded in a versionof Categorial Grammar (CG), the extension of which withrules of function composition gives rise to a problem ofspurious overgeneration.
As in analysis, these extensionspermit incremental processing, and the amelioration ofspurious overgeneration is demonstrated to follow identicallines to that in analysis.
Interpretation i  the PLUS ~ system(supporting dialogues about Yellow Pages information) wascarried out abductively (cf.
Guessoum et al1993) startingl?om an underspecified quasi-logical form.
Reversibilityrequired the same formalism to be used for surfacegeneration, the feasibility of which was demonstrated byPhillips (1993).
We improve on his earlier version, solvingnontermination with modifiers, interfacing to a structuredmorphological lexicon with efficient lookup, eliminatingspurious overgeneration arising from CG's rules of functioncomposition, and enabling incremental generation.2 Generation:from indexed QLFA working hypothesis of the PLUS project was that strictcompositionality provides too man3: meanings lbr efficientinterpretation.
The alternative is to rely on defeasiblereasoning over an underspecified (w.r.t lexical, referential,quantificational nd attachment ambiguities) representation.On the generation', side, we adopt a 3-way split betweencontent (i.e.
application dictated) planning with outputexpressed in terms of standard logical forms (LF), linguisticplanning (i.e.
"how to say it"), with output expressed inQLF, and realisation.
Here, we only discuss the last(Jokinen, 1993 describes the second).
The two planningcomponents between them need to be able to exercise fullcontrol of the linguistic hoices, and do so through the QLF,which includes linguistic features as well as predicate-argument structures derived from the LF via the lexicalchoice process.We might conclude from this reasoning that what wereally need as surface generator input is the level ofdescription found in a typical feature structure analysisassigned by a formalism like LFG/HPSG/FUG.
Manysystems in the NLG literature have adopted this kind ofinitial description language in preference to logicallanguages.
Our QLF contains the same kind of informationas this, encoded in a "flat" representation comprising a set offirst order Prolog terms.
The flat QLF notation means thatthe planner need not 'know' about the syntactic form offeature structures as defined by a particular grammar, butsimply decide which grammatical constraints hold of eachlogical element's realisation.
That QLF is a quasi logicalform can be seen from two properties:(a) It is less expressive in that it lacks scope constructs.
(b) It contains "non-semantic" information, such asgrammatical or pragmatic properties of linguisticelements corresl:xmding to logical individuals andvariables.The latter distinguishes our QLF from the bettcr known oneof Alshawi.
The non-semantic predicates comprise a closedclass and are filtered from the QLF during lexicon lookup.In the example below, past t ime ( 94 ) and nun~sing ( 96 )are examples of non-semantic annotations.\[def ( 95 ) ,name( 95 ,bill) ,book( 96 ), numsing ( 96 ),long(s (96), 96) ,very(s (96) ) ,indef (96),past time(94),write(94), sub~(94,95),ob~(94,96)\]The generator is also constrained by a syntactic descriptionof the target phrase, but only at the top level.The only properties of QLF relevant to the generationalgorithm are that it should be a conjunction of literals, withinstantiated arguments, and that each word in the lexicon hasat least one QLF term associated with it.
2 From theperspective of the inferential comlxments in the dialoguesystem, this is a proto-logical form and the relationshipbetween it and LF is beyond the scope of this paper.
Abenefit of this formalism in relation to our generationalgorithm is the simplicity of its manipulation.
Since QLFstatements are unordered sets, set theoretic operators (e.g.membership, union) suffice for information extraction.Fedder (1991) used a similar algorithm to generate fromIpI.I 'S: A Pragmatics-based Language Understanding System.
Part-funded by the(k~mmission of the European Commu,itics.
Project N ?
528.4.
See l~lack et al(ITS)3)for an overview.2 This is a defect of the notation, rexluiring that particles have a "semantics'.
This canbe remedied prapqmaticallv b either a procedural attachment tothe lexical ent~' of thesubcategorising~itcm (w\[aich sacrifices bidircctionality) or by a dummy semanticswhich can be inserted at the what to ~y  stage.2257th International Generation Workshop ?
Kennebunkport, Maine ?
June 21-24, 1994scoped logical forms, flattening them to a notation like theone used here.2.1 Lexicon lookupLexical lookup from QLF begins by filtering out thepredicates that do not correspond to lexemes.
(I) sleep(l) & past time(l) & name(2,john) &def(2) & arg0(l,2)In (1), the non-lexical elements a rgO(1 ,2)  andpast_ t ime ( 1 ) ,  are ignored in accessing the lexicon, butafter retrieval of the relevant lexical entries, play their part infiltering out inappropriate forms.
The functors of theremaining predications are used to index into the lexicon:s leep (1) 's functor s leep  corresponds to the lexeme orcitation form for the lexical entD', and the non-logicalannotation past t ime ( 1 ) will after lookup select he correctform s lept .
The indexes (1,2 in the example) are co-instantiated between the semantics and the syntax in theindividual exical and phrasal categories, o as to produce astring corresponding to the correct argument bindings.
(Thisdoes not happen correctly if the indexes are uninstantiatedvariables, as in a parse result.
)2.2 Categorial GrammarThe generation algorithm discussed in the next section is nottied to a particular linguistic formalism, but favours alexicalist formalism with as few rules as possible.
This isespecially true of CG in which most constituent structure iscaptured by the two rules of function application.
The CGrules of forward and backward function application can bestated as lbllows in the parsing grammar:%%%% Forward appl icationf : : Root/Arg:FunSem + Arg:ArgSem =>Root :MotherSem :-append ( ArgSem, FunSem, MotherSem).%%%% Backward applicationb : : Arg:ArgSem + RootkArg:FunSem =>Root :MotherSem : -append ( Ar~Sem, FunSem, MotherSem).
(Their statement in the generation grammar is slightlylonger).
In either case, the rules are matched by categoriesrecursively defined over the basic categories s,np and n andthe directional slash operators / and \.
Briefly, an expressionof category A/B combines with an expression of category Bto form a phrase of category A.
An instance is a determiner,category np/n  combining with a common oun, category n,to its right, forming a noun phrase, category rip.
All expr-essions in the lexicon belong to either basic or derivedcategories.
To take a complex example, the verb "bet"requires a subject, two object nps and a further sententialobject~ and hence has catego~' s \np /s /np /np .3 The surface generation algorithmInitial edges are asserted into a chart, for each word in thelexicon whose semantics is subsumed by the targetexpression's semantics.. As each edge is added to the chart,combinations are made with existing edges, as licensed bythe rulcs, and new spanning edges added.
?While this description may make the algorithm toappear something of a blind search, it is in fact stronglydirected by the elements present in the QLF, supported byan inversion of the indexing used in parsing.The lexicon match is not based on direct unification ofthe target phrase's semantics with that of its head, afundamental requirement of the bottom-up head-drivenalgorithm of Shieber et al(1989) and Van Noord (1990).Relaxing this requirement enables emantically equivalentQLFs (arising from commutativity of &) to be handleddirectly without any special mechanism.
The top-levelprocedure is stated as follows in Prolog:generate (--Syntax: Semantics, Text  ) : -abolish(edge, i),generate lex lookup(Semantics,Word,Syn,Sem),acceptable ( Sem, Semantics, Compl ),add_edge ( Syn: \[ Word I R \] : R: Sem: Compl, Word).generate ( Syntax :-semantics, Text ) :-ed~e(S~ntax:Text: \[ \] :_: \[ \] ).The lookup procedure retrieves a word whose semantics i asubset of that in Semant ics ,  returning the wordand tssyntactic and semantic description, acceptab le /3  ensuresthat the semantics of the word is a subset of the targetsemantics, and also returns the "unused" part of thesemantics in Compl.
Subsequent recursive calls work onCompl, ensuring that constituents are not generated moretimes (perhaps infinitely) than specified in the targetsemantics.
The second generate /2  clause requires that allelements in the target semantics are consumed.
Add edge isa recursiveprocedure that does the main work.addEdge(Categoryl ) :~\+ (edge (Categoryl) ),assert (edge ( Category i ) ),foreaoh ( (edge (Category2),addEd~e (Mother) ).addedge/ l  operates just as it would in a parser: alier addingedges to the chart, any combinations permitted with it areapplied recursively, xapp ly /3  applies the grammaticalrules, in this case the rules of categorial function application.4 Type raising and CompositionA forward composition rule and a type raising rule havebeen added to those of function application, both to theparser and to the generator.
Also, topicalization has beenadded to the parser.
In the parsing grammar (Ibr brevity)these rules are stated as follows:%%%% Functional Composit ionfc :: A/B:FunSeml + B/C:FunSem2 => A/C:MotherSem:- append(FunSeml,FunSem2,MotherSem).%%%% Type Raisingft :: np(Agr)#L:Sem =>s(Form)#S/(s(Form)#S\np(Agr)#L):Sem.%%%% Topic Type Raisingtt :: C#L:Sem => s(top)#S/(s(f in)#S/C#L):Sem :-member(C,\[np(A~r)\]) .2267th International Generation Workshop ?
Kennebunkport, Maine ?
June 21-24, 1994There have been two motivations for adding these rules to aCG.
Firstly, without hem, certain co-ordinate and gappingconstructs cannot be described neatly.
Secondly, theypermit incremental interpretation, said to be motivated onpsychological grounds.
Examples in Section 4.1 illustratethe co-ordinate and gapping constructions that can betreated.
With respect to generation, we also find incrementalprocessing well-motivated for interactive systems.
Firstly,in the context Of the PLUS project, corpus studies(particularly in French) revealed a great deal of overlapbetween the turns of the two parties in human-simulatedmachine dialogues~ and hence the generator needs to be ableto begin realisation before the content is fully planned.Secondly, this enables the generator to be incorporated into adistributed or multi-agent architecture, since partial resultsare available to external evaluation.
Thirdly, interleavinginterpretation a d planning with generation may create in theuser a more l:avourable impression of response time.However, the benefits of incrementality are not withouttheir costs.
In using rules of function composition, we?
I encounter a spurzoza" ambiguity problem.
This refers to themultiplicity of derivation paths that are semanticallyequivalent (and therefore spurious), for the same string, andwas first discussed by Wittenburg (1987).
This causesmultiple generation of identical strings with the sameanalysis, and an exponential increase in the search space.Fortunately, this problem is already known in the domain ofparsing and what we have discovered is that its solutioncarries over to generation more or less unaltered.The method of Hepple and Morrill (1989) has beenused, in both parser and generator, to cope with spuriousambiguity.
The main idea is to enforce normal form proofsby cutting the current branch in the search space when asequence of rule invocations known to lead to non-normallbrm derivations i about o be made.4.1 Coverage of'the GrammarWe begin this section with some illustrative constructs andtheir representation in the lexicon and in QLF, concludingwith an illustration of the non-constituent co-ordination andgapping constructs that specifically motivate the rules offunction composition.
Intensifier adverbs uch as very,quite, really enable sentences like (2) to be parsed orgenerated.
The QLF corresponding to adjectives is a two-place predicate where the first argument is a state-variable.The connection between a state and an object X in that stateis denoted using a skolem function s applied to X. Thus,long(X) in a classical ogic translation becomes Iong(s(X),X)in the new representation.
The full lexical entry foradjectives is given as (3), and (4) is the lexical entD' forintensifier adverbs.
(5) shows one of the definitions for"and" which enables entences like (6) and (7) to be parsedand generated.
(2) Bi l l  wrote a very long book.
(3) non_infl_lex(Word,n(Agr)#X/n(Agr)#X,\[QLF\]):- adj(Word), QLF=.. \[Word, s(X),X\].
(4) non_inf l_ lex(Word,(n(Agr)#X/n(Agr)#X)/(n(Agr)#X/n(Agr)#X),\[QLF\]) :-adverb(Word, grad), QLF =.. \[Word,s(X) \].
(5) non_infl_ lex ( and, C#Res \ C#Le ft/C#Right,\[conj (Res,Left,Right) \] ).
(6) Bi l l  and Kristi ina wrote a very shortbook and a long letter today.
(7) Bil l  saw and heard Kristiina.
(8) Bil l  heard and Nancy saw Kristiina.
(9) Bil l  walks and Nancy runs today.
(10) Bil l  saw the man who John heard.
(ii) Bi l l  saw the man who heard John.Forward composition and type raising rules cover non-constituent co-ordination as shown in (8) and (9).
They alsopermit analysis of WH-movement asshown in (10) and (11).5.
Incremental GenerationIncremental generation has been introduced (Kempen andHoenkamp 1982) on psychological grounds, and severalreports of surface generators have emphasised this property(e.g.
Reithinger, 1991, de Smedt and Kempen, 1991, van deVeen forthcoming).
In practical terms, the idea is that weshould be able to throw logical statements at the generator,one at the time, as soon as they become available (as aproduct of a reasoning process in a background application,perhaps), and that the generator should be able to startgenerating right away, without having to wait for the streamof semantic representations to end.Here we argue: 1) QLF is suitable for specifying thecontent of the target to be generated incrementally, 2) achart-based generation algorithm is suitable for incrementalgeneration, and 3) CG rules used can determine the level of'talkativeness' of an incremental generation system.QLF is a suitable formalism for this kind of job since itis designed especially with the representation of partialinformation in mind.
QLFs can, while still being well-formed in a syntactic sense, codify such things as apredicate-argument structure where one argument is not yetspecified, or a lack of knowledge concerning the propertiesof another argument, and afterwards, at another time, whenit becomes available, the missing information can be given.The main strengths of the chart-based algorithm usedare that QLF terms are not required in a particular order, orall at once.The only addition to the original CKY generationalgorithm is that when no more edges can be added to thechart, the string(s) corresponding toall the QLF given so faris printed; more QLF is requested from the backgroundprocess; It is then added as 'still to be consumed', and thegeneration process is called recursivcly from there.To see the role of the CG rules for regulating thetalkativeness of the generator, note that edges that haveconsumed all semantic input at a given point in time, andtherefore deserve to be printed, must always correspond toconstituents given the grammar.
Now, while a CG with onlyforward and backward application (FA and BA), implies astandard notion of constituency, rules like type raising (TR)and functional composition (FC) give rise to a moregenerous notion of constituency (this is what makes 'non-2277th International Generation Workshop ?
Kennebunkport, Maine ?
June 21-24, 1994constituent co-ordination' possible).
This means that anincremental generation system of the kind sketched above,employing FA, BA, TR and FC, will be 'chattier' than thevery same system employing only FA and BA.For example, assuming only FA and BA, and QLF ={indef(x), black(s(x),x)}, no string would be generated,since np/n and n/n do not form a constituent.
Assuming FA,BA, FC and TR, and the same QLF, the string a black wouldbe generated, since np/n and n/n can be composed into theconstituent p/n.
The string the black cat would be generatedunder both circumstances, if cat(x) was added to the aboveset.As another example, consider how the incrementalversion of the generator, which uses FA, BA, FC and TR,interacts with a user (where the user - input in boldface -plays the role of the QLF prcxlucing background process):?- generate.QLF term: def(x).\[ the lQLF term: man(x).\[the,man\]QLF term: write(e).OLF term: subj (e ,x ) .QLF term: obj (e,y).QLF term: pres(e).\[the,n~n,writes \]QLF term: long(s(x) ,x).\[ the, long, man, writes \]QLF term: indef(y).\[the, long,man,writes, a\]QLF term: short(s(y),y).\[ the, long, man, writes, a, short \]QLF term: letter(y).\[ the, long, man, writes, a, short, letter \]In the same circumstances, but given only FA and BA,neither \[the,man,writes\] nor \[the,long,man,writes,al, or\[the,long,man,writes,a,short\] would be generated.6.
ConehlsionA system for parsing and generation based on combinatorycategorial grammar and quasi-logical form has beenpresented.
The system seems to score high on at least thefollowing points:?
bi-directionality?
(potential) capability of handling a large repertoire ofgrammatical phenomena?
incrementalityThe system is bi-directional in the sense that given aquasi-logical form, that the parser would have produced hadit been given the same string, the generator will produce thesame string.
Of course, this is the case only if we choose tousc exactly the same rules (and lexicon) for both parsing andgeneration.The large repertoire of grammatical phenomena that can(potentially) be handled in the system is due to the fact thatit was possible, without much performance penalty (due tothe use of the Hepple-Morrill method of eliminatingspurious ambiguity), to implement, on top of forward andbackward application, rules such as type raising andfunctional composition.
This enables many forms ofdiscontinuity phenomena tobe treated.The framework used also seems to offer someinteresting possibilities for incremental generation, which isparticularly pertinent for surface generation within thecontext of dialogue systems.ReferencesBlack, William J, Nancy Underwood, Hamish Cunninghamand Kristiina Jokinen, "Dialogue Management in aPragmatics-Based Language Understanding System" InEds.
McEnery, T and Paice, C. Proc 14th InformationRetrieval Colloquium, Lancaster 1992, 79-88, Springer-Verlag, 1993.Guessoum, A, Black, W J, Gallagher, J and Wachtel, T J.
"Abduction for Pronoun Resolution", Proc ICLPWorkshop on Abduction, Budapest, 1993.Hepple, Mark and Morrill, Glyn.
"Parsing and Derix, ationalEquivalence".
Proc.
4th European ACL, 10-18, 1989.Jokinen, K. "Reasoning about Coherent and Co-operativeSystem Responses", Proc.
5th European Workshop onNatural Language Generation, Pisa, April 1993.Kempen, Gerard and Edward Hoenkamp.
"Incrementalsentence generation: implications for the structure of asyntactic processor.'"
In COLING-82, 151-156, 1982.Phillips, J. D. "Generation of text from I_.ogical Formulae"Machine Translation 8(4), 209-9_36, 1993.Reithinger, Norbert.
"POPEL: A Parallel and IncrementalNatural Language Generation System" In Eds.
Paris,Swartout and Mann Natural Language Generation iArtificial Intelligence and Computational LinguisticsKluwer, 179-200, 1991.Shieber, Stuart M, Gertjan van Noord, Robert C Moore andFernando C N Pereira, "A Semantic Head-DrivenGeneration Algorithm for Unification Grammars", Proc.ACL, 27th Annual Meeting, 7-17, 1989.de Smedt, Koenraad and Gerard Kempen, "SegmentGrammar.
A Formalism for Incremental SentenceGeneration" In Eds.
Paris, Swartout and Mann NaturalLanguage Generation i Artificial Intelligence andComputational Linguistics Kluwer, 329-350, 1991.van de Veen, Evelyn.
"Incremental generation for highlyinteractive dialogues" Proc.
Workshop on Pragmatics inDialogue Management, XIV Scandinavian Conference ofLinguistics, 16-21 August, 1993, (forthcoming).van Noord, Gertjan.
"An Overview of Head-DrivenBottom-Up Generation" In Eds.
Dale, Mellish and Zock,Current Research in Natural Language Generation.Academic Press, 141-166, 1990.Wittenburg, Kent.
"Predictive combinators: a method forefficient processing of combinatory categorial grammars.
"In ACL Proceedings.
25th Annual Meeting, 73-80, 1987.228
