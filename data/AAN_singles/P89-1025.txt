PLANNING TEXT FOR ADVISORY D IALOGUES"Johanna D. MooreUCLA Department of Computer ScienceandUSC/Information Sciences Institute4676 Admiralty WayMarina del Key, CA 90292-6695, USAC~cile L. ParisUSC/information Sciences Institute4676 Admiralty WayMarina del Key, CA 90292-6695, USAABSTRACTExplanation is an interactive process re-quiring a dialogue between advice-giver andadvice-seeker.
In this paper, we argue thatin order to participate in a dialogue with itsusers, a generation system must be capable ofreasoning about its own utterances and there-fore must maintain a rich representation fthe responses it produces.
We present a textplanner that constructs a detailed text plan,containing the intentional, attentional, and.,,e~,~nc~ ~tructures of the text it generates.INTRODUCTIONProviding explanations in an advisory situa-tion is a highly interactive process, requiringa dialogue between advice-giver and advice-seeker (Pollack eta/.
,  1982).
Participating ina dialogue requires the ability to reason aboutprevious responses, e.g., to interpret the user'sfollow-up questions in the context of the on-going conversation and to determine how toclarify a response when necessary.
To pro-vide these capabilities, an explanation facilitymust understand what it was trying to conveyand how that information was conveyed, i.e.,the intentional structure behind the explana-tion, including thegoal of the explanation as awhole, the subgoal(s)of individual parts of theexplanation, and the rhetorical means used toachieve them.Researchers in natural language under.standing have recognized the need for suchinformation.
In their work on discourse anal-ysis, Grosz and Sidner (1986) argue that it isnecessary to represent the intentional struc-ture, the attentional structure (knowledgeabout which aspects of a dialogue are in focusat each point), and the linguistic structure of"The research described in this paper was sup-ported by the Defense Advanced Research ProjectsAgency (DARPA) under a NASA Ames cooperativeagreement number NCC 2-520.
The authors wouldlike to thank William Swartout for comments on ear-lier versions of this paper.203the discourse.
In contrast, most text gener-ation systems (with the notable exception ofKAMP (Appelt, 1985)) have used only rhetor-ical and attentional information to producecoherent text (McKeown, 1985, McCoy, 1985,Paris, 1988b), omitting intentional informa-tion, or conflating intentional and rhetoricalinformation (Hovy, 1988b).
No text gener-ation system records or reasons about therhetorical, the attentional, as well as the in-tentional structures of the texts it produces.In this paper, we argue that to success-fully participate in an explanation dialogue,a generation system must maintain the kindsof information outlined by Grosz and Sidneras well as an explicit representation of therhetorical structure of the texts it generates.We present a text planner that builds a de-tailed text plan, containing the intentional,attentional, and rhetorical structures of theresponses it produces.
The main focus ofthis paper is the plan language and the planstructure built by our system.
Examples ofhow this structure is used in answering follow-up questions appear in (Moore and Swar tout ,1989).WHY A DETAILED TEXT PLAN?In order to handle follow-up questions thatmay arise if the user does not fully understanda response given by the system, a generationfacility must be able to determine what por-tion of the text failed to achieve its purpose.
Ifthe generation system only knows the top-leveldiscourse goal that was being achieved by thetext (e.g., persuade the hearer to perform anaction), and not what effect the individualparts of the text were intended to have on thehearer and how they fit together to achievethis top-level goal, its only recourse is to use adifferent strategy to achieve the top-level goal.It is not able to re-explain or clarify any partof the explanation.
There is thus a need fora text plan to contain a specification of theintended effect of individual parts of the texton the hearer and how the parts relate to oneanother.
We have developed a text plannerthat records the following information aboutthe responses it produces:?
the information that Grosz and Sidner(1986) have presented as the basics of adiscourse structure:- intent ional  structure: a represen-tation of the effect each part ofthe text is intended to have on thehearer and how the complete textachieves the overall discourse pur-pose (e.g., describe ntity, persuadehearer to perform an action).- attentional structure: information /about which objects, properties andevents are salient at each pointin the discourse.
User's follow-up questions are often ambiguous.Information about the attentionalstate of the discourse can be usedto disambiguate hem (cf.
(Mooreand Swartout, 1989)).?
in addition, for generation we require thefollowing:- rhetorical structure: an agent mustunderstand how each part of thetext relates rhetorically to the oth-ers.
This is necessary for linguis-tic reasons (e.g., to generate theappropriate clausal connectives inmulti-sentential responses) and forresponding to requests for elabora-tion/clarification.?
assumption information: ad'vice-giving systems must take knowl-edge about their users into account.However, since we cannot rely onhaving complete user models, thesesystems may have to make assump-tions about the hearer in order touse a particular explanation strat-egy.
Whenever such assumptionsare made, they must be recorded.The next sections describe this new text plan-ner and show how it records the informationneeded to engage in a dialogue.
Finally, a briefcomparison with other approaches totext gen-eration is presented.TEXT PLANNERThe text planner has been developed as partof an explanation facility for an expert sys-tern built using the Explainable Expert Sys-tems (EES) framework (Swartout and Smo-liar, 1987).
The text planner has been usedin two applications.
In this paper, we drawour examples from one of them, the ProgramEnhancement Advisor (PEA) (Neches et al,1985).
PEA is an advice-giving system in-tended to aid users in improving their Com-mon Lisp programs by recommending trans-formations that enhance the user's code.
1 Theuser supplies PEA with a program and in-dicates which characteristics of the programshould be enhanced (any combination of read-ability, maintainability, and efficiency).
PEAthen recommends transformations.
After eachrecommendation is made, the user is free toask questions about the recommendation.We have implemented a top-down hier-archical expansion planner (d la Sacerdoti(1975)) that plans utterances to achieve dis-course goals, building (and recording) the in-tentional, attentional, and rhetorical struc-ture of the generated text.
In addition, sincethe expert system explanation facility is in-tended to be used by many different users,the text planner takes knowledge about theuser into account.
In our system, the usermodel contains the user's domain goals andthe knowledge he is assumed to have aboutthe domain.THE PLAN LANGUAGEIn our plan language, intentional goals arerepresented in terms of the effects the speakerintends his utterance to have on the hearer.Following Hovy (1988a), we use the terminol-ogy for expressing beliefs developed by Cohenand Levesque (1985) in their theory of ratio-nal interaction, but have found the need toextend the terminology to represent the typesof intentional goals necessary for the kindsof responses desired in an advisory setting.Although Cohen and Levesque have subse-quently retracted some aspects of their theoryof rational interaction (Cohen and Levesque,1987), the utility of their notation for our pur-poses remains unaffected, as argued in (Hovy,1989).
2a PEA recommends transformations that improvethe 'style' of the user's code.
It does not attempt ounderstand the content of the user's program.2Space limitations prohibit an exposition of theirterminology in this paper.
We provide English para-phrases where necessary for clarity.
(BR8 S II x)should be read as 'the speaker believes the speakerand hearer mutually believe x.
'204EFFECT: (PERSUADE S H (GOAL H Eventually(DONE H ?act)))CONSTRAINTS: (AND (GOAL S ?domain-goal)(STEP ?act ?domain-goal)(BMB S H (GOAL H ?domaln-goal)))NUCLEUS: (FOR.ALL ?domain-goal(MOTIVATION ?act ?domain-goal))SATELLITES: nilFigure 1: Plan Operator for Persuading the Hearer to Do An ActEFFECT: (MOTIVAT ION ?act ?domain-goal)CONSTRAINTS: (AND (GOAL S ?domain-goal)(STEP ?act ?domain-goal)(BMB S H (GOAL H ?domain-goal))(ISA ?act REPLACE))NUCLEUS: ((SETQ ?replacee (FILLER-OF OBJECT ?act))(SETQ ?replacer (FILLER-OF GENERAL IZED-MEANS ?act))(BMB S H (D IFFERENCES ?repLacee ?repLacer ?domain-goal)) )SATELLITES: nllFigure 2: Plan Operator for Motivating a Replacement by Describing Differences between Replacerand ReplaceeRhetorical structure is represented interms of the rhetorical relations defined inRhetorical Structure Theory (RST) (Mannand Thompson, 1987), a descriptive theorycharacterizing text structure in terms of therelations that hold between parts of a text(e.g., CONTRAST, MOTIVATION).
The defini-tion of each RST  relation includes constraintson the two entities being related as well asconstraints on their combination, and a spec-ification of the effect which the speaker isattempting to achieve on the hearer's be-lids.
Although other researchers have cate-gorized typical intersentential relations (e.g.,(Grimes, 1975, Hobbs, 1978)), the set of rela-tions proposed by RST  is the most completeand the theory sufficiently detailed to be eas-ily adapted for use in generation.In our plan language, each plan operatorconsists of:an effect:  a characterization f whatgoai(s) this operator can be used toachieve.
An  effect may be an in-tentional goal, such as persuade thehearer  to do an ac~ionorarhetoricalrelation, such as provide motivationfor an action.a constraint list: a list of conditions thatmust be true before the operator can beapplied.
Constraints may refer to factsin the system's knowledge base or in theuser model.?
a nuc leus :  the main topic to be ex-pressed.
The nucleus is either a prim-itive operator (i.e., speech acts such asinform, recommend and ask) or a goalintentional or rhetorical) which must bether expanded.
All operators mustcontain a nucleus.?
sate l l i tes :  subgoal(s)that express addi-tional information which may be neededto achieve the effect of the operator.When present, satellites may be specifiedas required or optional.Examples of our plan operators are shownin Figures 1 and 2.
The operator shown inFigure 1 can be used if the speaker (S) intendsto persuade the hearer (H) to intend to dosome act.
This plan operator states that if anact is a step in achieving some domain goal(s)that the hearer shares, one way to persuadethe hearer to do the act is to motivate the actin terms of those domain goals.
Note that thisplan operator takes into account not only thesystem's knowledge of itself, but also the sys-tem's knowledge about he user's goals, as em-bodied in a user model.
If any domain goalsthat satisfy the constraints are found, this op-erator will cause the planner to post one ormore MOTIVATION subgoals.
This plan opera-tor thus indicates that one way to achieve theintentional goal of persuading the hearer toperform an action is by using the rhetoricalmeans MOTIVATION.205EFFECT: (BMB S H ?x)CONSTRAINTS: nilNUCLEUS: ( INFORM S H ?x)SATELLITES: ( ( (PERSUADE S H 7x) *optional*))Figure 3: Plan Operator for Achieving Mutual Belief of a PropositionSYSTEMUSERSYSTEM" USERSYSTEMWhat characteristics of the program would you like to enhance?Maintainability.You should replace (setq x I) with (serf x I).
Serf can be used to assign avalue to any generalized-variable.
Serq can only be used to assign a value to asimple-variable.
A generalized-variable is a storage location that can be named byany accessor function.What is a generalized variable?For example, the car and cdr of a cons are generalized-variables, named by theaccessor functions car and cdr.
Other examples are an element of an array or acomponent of a structure.Figure 4: Sample Dialogue\[11P-\]\[31\[4\]\[51Plans that achieve intentional goals andthose that achieve rhetorical relations are dis-tinguished for two reasons: (1) so that thecompleted plan structure contains both the in-tentional goals of the speaker and the rhetor-ical means used to achieve them; (2) becausethere are many different rhetorical strategiesfor achieving any given intentional goal.
Forexample, the system has several plan opera-tors for achieving the intentional goal of de-scribing a concept.
It may describe a conceptby stating its class membership and describ-ing its attributes and its parts, by drawingan analogy to a similar concept, or by givingexamples of the concept.
There may also bemany different plan operators for achievinga particular rhetorical strategy.
(The plan-ner employs selection heuristics for choosingamong applicable operators in a given situa-tion (Moore and Swartout, 1989).
)Our plan language allows both generaland specific plans to be represented.
For ex-ample, Figure 2 shows a plan operator forachieving the rhetorical relation MOTIVATION.This is a very specific operator that can beused only when the act to be motivated is areplacement (e.g., replace sezq with sezf) .In this case, one strategy for motivating theact is to compare the object being replacedand the object that replaces it with respectto the domain goal being achieved.
On theother hand, the operator shown in Figure 3is general and can be used to achieve mu-tual belief of any assertion by first inform-ing the hearer of the assertion and then, op-tionaUy, by persuading him of that fact.
Be-cause we allow very general operators as wellas very specific ones, we can include bothdomain-independent and domain-dependentstrategies.A DETAILED EXAMPLEConsider the sample dialogue with our sys-tem shown in Figure 4, in which the user in-dicates that he wishes to enhance the main-tainability of his program.
While enhanc-ing maintainability, the system recommendsthat the user perform the act rep lace- I ,namely 'replace setq with serf', and thusposts the intentional goal (BMB S H (GOALH Evenzually(DONE H replace-I))).
Thisdiscourse goal says that the speaker would liketo achieve the state where the speaker believesthat the hearer and speaker mutually believethat it is a goal of the hearer that the replace-ment eventually be done by the hearer.The planner then identifies all the opera-tors whose effect field matches the discoursegoal to be achieved.
For each operator found,the planner checks to see if all of its con-straints are satisfied.
In doing so, the textplanner attempts to find variable bindings inthe expert system's knowledge base or theuser model that satisfy all the constraints in206EFFECT: (BMB S H (GOAL H Eventually(DONE H ?act)))CONSTRAINTS:  noneNUCLEUS: (RECOMMEND S H ?act)SATELLITES: ( ( (BMB S H (COMPETENT H (DONE H ?act))) *optional*)((PERSUADE S H (GOAL H Eventually(DONE H 7act))) *optional*)Figure 5: High-level Plan Operator for Recommending an Actapply-SETQ-t o-SETF-~rans formal; ionapply-lo cal-1;ransf ormat ions-whos e-rhs-us e-is-mor e-general-1:han-lhs-us ?apply-local-1;rans f orma1~ions-thal;-enhance-mainl;ainabilityapply-1~ransforma?
ions-1~hal;-enhanc e-mainl; ainabili~yenhanc e-mainl; ainabili1: yenhance-programFigure 6: System goals leading to rep lace  setq  wil;h sel;fthe constraint list.
Those operators whoseconstraints are satisfied become candidates forachieving the goal, and the planner choosesone based on: the user model, the dialoguehistory, the specificity of the plan operator,and whether or not assumptions about theuser's beliefs must be made in order to satisfythe operator's constraints.Continuing the example, the current dis-course goal is to achieve the state whereit is mutually believed by the speaker andhearer that the hearer has the goal of even-tually executing the replacement.
This dis-course goal can be achieved by the plan op-erator in Figure 5.
This operator has noconstraints.
Assume it is chosen in thiscase.
The nucleus is expanded first, 3 causing(RECOMMEND S H replace-l) to be posted asa subgoal.
RECOMMEND is a primitive operator,and so expansion of this branch of the plan iscomplete.
4Next, the planner must expand the satel-lites.
Since both satellites are optional in thiscase, the planner must decide which, if any,are to be posted as subgoals.
In this example,the first satellite will not be expanded becausethe user model indicates that the user is ca-31n some cases, such as a satellite posting therhetorical relation background, the satellite is ex-panded first.+At this point, (RECOMMEND S H replace-l) mustbe translated into a form appropriate as input.to therealization component, the Penman system (Mann,1983, Kasper, 1989).
Based on the type of speech act,its arguments, and the context in which it occurs, theplanner builds the appropriate structure.
Batemanand Paxis (1989) have begun to investigate the prob-lem of phrasing utterances for different types of users.pable of performing replacement acts.
Thesecond satellite is expanded, s posting the in-tentional subgoal to persuade the user to per-form the replacement.
A plan operator foracldeving this goal using the rhetorical rela-tion MOTIVATION was shown in Figure i.When attempting to satisfy the con-straints of the operator in Figure 1, thesystem first checks the constraints (GOALS ?domain-goal) and (STEP replace-1?domain-goal).
These constraints state that,in order to use this operator, the system mustfind an expert system goal, ?domain-goal,that replace-I is a step in achieving.This results in several possible bindingsfor the variable ?domain-goal.
In this case,the applicable system goals, listed in orderfrom most specific to the top-level goal of thesystem, are shown in Figure 6.The last constraint of this plan opera-tor, (BMB S H (GOAL H ?domain-goal)), isa constraint on the user model stating that thespeaker and hearer should mutu~IIy believethat ?domain-goal is a goal of the hearer.Not all of the bindings found so far will sat-isfy this constraint.
Those which do not willnot be rejected immediately, however, as wedo not assume that the user model is com-plete.
Instead, they will be noted as possiblebindings, and each will be marked to indicatethat, if this binding is used, an assumptionis being made, namely that the binding ofSin other situations, the system could choose notto expand this satellite and await feedback from theuser instead (Moore and Swartout, 1989).207(BMB S H (GOAL H Eventually (DONE H replace-I)))NI(MOTIVATION replace1 enhance-maintainability)(RECOMMEND S H replace-I) (PERSUADE S H (GOAL H Eventually (DONE H replace-I)))NI(MOTIVATION replace-1 enhance-maintainability).I(BMB S H (DIFFERENCES setq serf enhance-maintainability))NIN (BMB S H (DIFFERENCE setq serf use)) S(INFORM S H (IDENTITY (VALUE-OF use serf) Sassign-value.to-generalized-variableJJ (BMR S H (KNOW H generalized-variable))(CONTRAST (IDENTITY (VALUE-OF use setq))) NN I (ELABORATION general zed-variable)(INFORM S H (IDENTITY (VALU E-OF use setq) ~ ~ Sassign-value-to-sim pie-variable)) ~ ,(INFORM S H (CLASS-ASCRIPTION (ELABORATION-OBJECT-ATTRIBUTEgeneralized-variable storage-location)) generalized-variable named-by)repla(el = replm:eSETQwithSETF N \[N ?
NucleusS = Satellite (INFORM S H (IDENTrI"Y(VALUE-OF named-by accessor-function )))Figure 7: Completed Text Plan for Recommending Replace SETQ with SETF?domain-goal is assumed to be a goal of theuser.In this example, since the user is usingthe system to enhance a program and has in-dicated that he wishes to enhance the main-tainability of the program, the system infersthe user shares the top-level goal of the system(enhance-program), as well as the more spe-cific goal enhance-mainZainabilizy.
There-fore, these are the two goals that satisfy theconstraints of the operator shown in Figure I.The text planner prefers choosing bindingenvironments that require no assumptions tobe made.
In addition, in order to avoid ex-plaining parts of the reasoning chain that theuser is familiar with, the most specific goal ischosen.
The plan operator is thus instanti-ated with enhance-mainzainability as thebinding for the variable ?domain-goal.
Theselected plan operator is recorded as such, andall other candidate operators are recorded asuntried alternatives.The nucleus of the chosen plan op-erator is now posted, resulting in thesubgoal (MOTIVATION replace-1 enhance-mainZainability).
The plan operator cho-sen for achieving this goal is the one that208was shown in Figure 2.
This operator mo-tivates the replacement by describing differ-ences between the object being replaced andthe object replacing it.
Although there aremany differences between sezq and serf,only the differences relevant o the domaingoal at hand (enhance-mainzainabilizy)should be expressed.
The relevant differ-ences are determined in the following way.From the expert system's problem-solvingknowledge, the planner determines what roleseezq and eezf play in achieving the goalenhance-maintainabilizy.
In this case, thesystem is enhancing maintainability by ap-plying transformations that replace a specificconstruct with one that has a more generalusage.
SeZq has a more specific usage thansezf, and thus the comparison between sezqand sezf should be based on the generality oftheir usage.Finally, since the term genera l i zed-var iab le  has been introduced, and theuser model indicates that the user doesnot know this term, an intentional goalto define it is posted: (BMB S H (KNOWH generalized-variable)).
This goal isachieved with a plan operator that describesconcepts by stating their class membershipand describing their attributes.
Once com-pleted, the text plan is recorded in the dia-logue history.
The completed text plan forresponse (3) of the sample dialogue is shownin Figure 7.ADVANTAGESAs illustrated in Figure 7, a text plan pro-duced by our planner provides a detailed rep-resentation of the text generated by the sys-tem, indicating which purposes different partsof the text serve, the rhetorical means usedto achieve them, and how parts of the planare related to each other.
The text plan alsocontains the assumptions that were made dur-ing planning.
This text plan thus containsboth the intentional structure and the rhetor-ical structure of the generated text.
Fromthis tree, the dominance and saris/action-precedence relationships as defined by Groszand Sidner can be inferred.
Intentional goalshigher up in the tree dominate those lowerdown and a left to right traversal of thetree provides atisfaction-precedence ordering.The attentional structure of the generatedtext can also be derived from the text plan.The text plan records the order in which top-ics appear in the explanation.
The global vari-able *local-contezt ~ always points to the plannode that is currently in focus, and previouslyfocused topics can be derived by an upwardtraversal of the plan tree.The information contained in the textplan is necessary for a generation system to beable to answer follow-up questions in context.Follow-up questions are likely to refer to thepreviously generated text, and, in addition,they often refer to part of the generated text,as opposed to the whole text.
Without an ex-plicit representation f the intentional struc-ture of the text, a system cannot recognizethat a follow-up question refers to a portion ofthe text already generated.
Even if the systemrealizes that the follow-up question refers backto the original text, it cannot plan a text toclarify a part of the text, as it no longer knowswhat were the intentions behind various piecesof the text.Consider again the dialogue in Figure 4.When the user asks 'What is a gener-alized variable?'
(utterance (4) in Fig-ure 4), the query analyzer interprets this ques-tion and posts the goal: (BMB S H (KNOW Hgenera l i zed-var iab le )  ).
At this point, theexplainer must recognize that this discoursegoal was attempted and not achieved by the209last sentence of the previous explanation.
6Failure to do so would lead to simply repeat-ing the description of a generalized variablethat the user did not understand.
By exam-ining the text plan of the previous explanationrecorded in the dialogue history, the explaineris able to determine whether the current goal(resulting from the follow-up question) is agoal that was attempted and failed, as it isin this case.
This time, when attempting toachieve the goal, the planner must select an al-ternative strategy.
Moore (1989b) has devisedrecovery heuristics for selecting an alternativestrategy when responding to such follow-upquestions.
Providing an alternative xplana-tion would not be possible without he explicitrepresentation f the intentional structure ofthe  generated text.
Note that it is importantto record the rhetorical structure as well, sothat the text planner can choose an alterna-tive rhetorical strategy for achieving the goal.In the example under consideration, the re-covery heuristics indicate that the rhetoricalstrategy of giving examples hould be chosen.RELATED WORKSchemata (McKeown, 1985) encode standardpatterns of discourse structure, but do not in-dude knowledge of how the various parts ofa schema relate to one another or what theirintended effect on the hearer is.
A schemacan be viewed as a compiled version of oneof our text plans in which all of the non-terminal nodes have been pruned out and onlythe  leaves (the speech acts) remain.
Whileschemata can produce the same initial behav-ior as one of our text plans, all of the ratio-nale for that behavior has been compiled out.Thus schemata cannot be used to participatein dialogues.
If the user indicates that he hasnot  understood the explanation, the systemcannot know which part of the schema failedto achieve its effect on the hearer or whichrhetorical strategy failed to achieve this ef-fect.
Planning a text using our approach isessentially planning a: schema from more fine-grained plan operators.
From a library of suchplan operators, many varied schemata can re-sult, improving the flexibility of the system.In an approach taken by Cohen and Ap-pelt (1979) and Appelt (1985), text is plannedby reasoning about the beliefs of the hearerand speaker and the effects of surface speechaWe are also currently implementing another in-terface which al lows users to use a mouse to point atthe noun phrases or clauses in the text that were notunderstood {Moore, 1989b).acts on these beliefs (i.e., the intentional ef-fect).
This approach does not include rhetori-cal knowledge about how clausal units may becombined into larger bodies of coherent extto achieve a speaker's goals.
It assumes thatappropriate axioms could be added to gen-erate large (more than one- or two-sentence)bodies of text and that the text produced willbe coherent as a by-product of the planningprocess.
However, this has not been demon-strated.Itecently, Hovy (1988b) built a text struc-turer which produces a coherent ext whengiven a set of inputs to express.
Hovy usesan opportunistic planning approach that or-ders the inputs according to the constraintson the rhetorical relations defined in Rhetori-cal Structure Theory.
His approach provides adescription of what can be said when, but doesnot include information about why this infor-mation can or should be included at a partic-ular point.
Hovy's approach confiates inten-tional and rhetorical structure and, therefore,a system using his approach could not laterreason about which rhetorical strategies wereused to achieve intentional goals.STATUS AND FUTURE WORKThe text planner presented is imple.mentedin Common Lisp and can produce the textplans necessary, to participate in the sample~lialogue described m this paper and severalothers (see (Moore, 1989a, Paris, 1988a)).
W ecurrently have over 60 plan operators andthe system can answer tlie following types of(follow-up) questions:- Why?- Why conclusion?- Why are you trying to achieve goal?- Why are you using method to achieve goal?Why are you doing act?How do you achieve goal?- How did you achieve goal (in this case)?- What is a concept?- What is the difference between concept1and concept2?- H u h ?The text planning system described in thispaper is being incorporated into two expertsystems currently under development.
Thesesystems will be installed and used in the field.This will give us an opportunity to evaluatethe techniques proposed here.We are currently studying how the atten-tional structure inherent in our text plans canbe used to guide the realization process, forexample in the planning of referring expres-sions and the use of cue phrases and pronouns.We are also investigating criteria for the ex-pansion and ordering of optional satellites inour plan operators.
Currently we use informa-tion from the user model to dictate whetheror not optional satellites are expanded, andtheir ordering is specified in each plan opera-tor.
We wish to extend our criteria for satel-lite expansion to include other factors such aspragmatic and stylistic goals (Hovy, 1988a)(e.g., brevity) and the conversation that hasoccurred so far.
We are also investigating theuse of attentional information to control theordering of these satellites (McKeown, 1985).We also believe that the detailed text planconstructed by our planner will allow a systemto modify its strategies based on experience(feedback from the user).
In (Paris, 1988a),we outline our preliminary ideas on this issue.We have also begun to study how our plannercan be used to handle incremental generationof texts.
In (Moore, 1988), we argue that thedetailed representation provided by our textplans is necessary for execution monitoringand to indicate points in the planning processwhere feedback from the user may be helpfulin incremental text planning.CONCLUSIONSIn this paper, we have presented a text plan-ner that builds a detailed text plan, contain-ing the intentional, attentional, and rhetor-ical structures of the responses it produces.We argued that, in order to participate in adialogue with its users, a generation systemmust be capable of reasoning about its pastutterances.
The text plans built by our textplanner provide a generator with the infor-mation needed to reason about its responses.We illustrated these points with a sample di-alogue.REFERENCESDouglas E. Appelt.
1985.
Planning Natu-ral Language Utterances.
Cambridge Univer-sity Press, Cambridge, England.John A. Bateman and C~cile L. Paris.1989.
Phrasing a text in terms the user canunderstand.
In Proceedings of the EleventhInternational Joint Conference on ArtificialIntelligence, Detroit, MI, August 20-25.Philip It.
Cohen and Hector J. Levesque.1985.
Speech Acts and RationaLity.
In Pro-ceedings of the Twenty-Third Annual Meet-ing of the Association for Computational Lin-210guistics, pages 49-60, University of Chicago,Chicago, Illinois, July 8-12.Philip I~.
Cohen and Hector J. Levesque.1987.
Intention is Choice with Commitment,November.Philip R. Cohen and C. Raymond Per-ranlt.
1979.
Elements of a Plan-based Theoryof Speech Acts.
Cognitive Science, 3:177-212.Joseph E. Grimes.
1975.
The Thread ofDiscourse.
Mouton, The Hague, Paris.Barbara J. Grosz and Candace L. Sidner.1986.
Attention, Intention, and the Struc-ture of Discourse.
Computational Linguistics,12(3):175-204.Jerry Hobbs.
1978.
Why is a DiscourseCoherent?
Technical Report 176, SRI Inter-national.Eduard H. Hovy.
1988a.
Generating Nat-ural Language Under Pragmatic Constraints.Lawrence Erlbaum, Hillsdale, New Jersey.Eduard H. Hovy.
1988b.
Planning Coher-ent Multisentential Text.
In Proceedings ofthe Twenty-Sixth Annual Meeting of the As-sociation for Computational Linguistics, StateUniversity of New York, Buffalo, New York,June 7-10.Eduard H. Hovy.
1989.
Unresolved Issuesin Paragraph Planning, April 6-8.
Presentedat the Second European Workshop on NaturalLanguage Generation.Robert Kasper.
1989.
SPL: A SentencePlan Language for Text Generation.
Technicalreport, USC/ISI.William C. Mann and Sandra A. Thomp-son.
1987.
Rhetorical Structure Theory:A Theory of Text Organization.
In LiviaPolanyi, Editor, The Structure of Discourse.Ablex Publishing Corporation, Norwood, N.J.William Mann.
1983.
An Overview of thePenman Text Generation System.
Technicalreport, USC/ISI.Kathleen F. McCoy.
1985.
CorrectingObject-Related Misconceptions.
PhD thesis,University of Pennsylvania, December.
Pub-lished by University of Pennsylvania asTech-nical Report MS-CIS-85-57.Kathleen R McKeown.
1985.
Text Gener-ation: Using Discourse Strategies and FocusConstraints to Generate Natural LanguageText.
C~mbridge University Press, Cam-bridge, England.211Johanna D. Moore and William R.Swartout.
1989.
A Reactive Approach to Ex-planation.
In Proceedings of the Eleventh In-ternational Joint Conference on Artificial fn-telligence, Detroit, MI, August 20-25.Johanna D. Moore.
1988.
Planning andReacting.
In Proceedings of the AAAI  Work-shop on Text Planning and Generation, StPaul, Minnesota, August 25.Johanna D. Moore.
1989a.
Respondingto "Huh?
": Answering Vaguely ArticulatedFollow-up Questions.
In Proceedings of theConference on Human Factors in ComputingSystems, Austin, Texas, April 30 - May 4.Johanna D. Moore.
1989b.
A Reactive Ap-proach to Explanation in Expert and Advice-Giving Systems.
PhD thesis, University ofCalifornia, Los Angeles, forthcoming.Robert Neches, William R. Swartout, andJohanna D. Moore.
1985.
Enhanced Main-tenance and" Explanation of Expert Systemsthrough Explicit Models of their Develop-meat.
IEEE Transactions on Software En-gineering, SE- 11(11), November.C~cile L. Paris.
1988a.
Generation andExplanation: Building an Explanation Fa-cility for the Explainable Expert SystemsFramework, July 17-21.
Presented at theFourth International Workshop on NaturalLanguage Generation.C~cile L. Paris.
1988b.
Tailoring ObjectDescriptions to the User's Level of Exper-tise.
Computational Linguistics Journal, 14(3), September.Martha E. Pollack, Julia Hirschberg, andBonnie Lynn Webber.
1982.
User Participa-tion in the Reasoning Processes of Expert Sys-tems.
In Proceedings of the Second NationalConference on Artificial Intelligence, Pitts-burgh, Pennsylvania, August 18-20.Earl D. Sacerdoti.
1975.
A Structure forPlans and Behavior.
Technical Report TN-109, SRI.William R. Swartout and Stephen W.Smoliar.
1987.
On Making Expert Systemsmore like Experts.
Expert Systems, 4(3), Au-gust.
