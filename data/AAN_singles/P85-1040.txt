GRAMMAR VIEWED AS A FUNCTIONING PART OF A COGNITIVE SYSTEMHelen M. GigleyDepartment of Computer ScienceUniversity of New HampshireDurham, NH 03824ABSTRACTHow can grammar be viewed as a functionalpart of a cognitive system) Given a neural basisfor the processing control paradigm of languageperformance, what roles does 'Sgrammar" play?
Isthere evidence to suggest that grammatical pro-cessing can be independent from other aspects oflanguage processing?This paper wil l  focus on these issues andsuggest answers within the context of one com-putational solution.
The example model of sen-tence comprehension, HOPE, is intended to demon-strate both representational considerations for agrammar within such a system as well as to i l lus-trate that by interpreting a grammar as a feedbackcontrol mechanism of a "neural-like" process,additional insights into language processing canbe obtained.1.
IntroductionThe role of grammar in defining cognitivemodels that are neurally plausible and psycho-logically valid wil l  be the focus of this paper.While inguistic theory greatly influences theactual representation that is included in any suchmodel, there are vast differences in how anygrammar selected is "processed" within a "naturalcomputation" paradigm.
The processing does notgrow trees expl icit ly;  i t  does not transform treesexpl icit ly;  nor does i t  move constituents.In this type of model, a grammar is an ex-p l i c i t  encoded representation that coordinates theintegrated parallel process.
I t  provides theinterfaces between parallel processes that can beinterpreted within semantic and syntactic levelsseparately.
I t  furthermore acts as a "conductor"of a time-synchronized process.
Aspects of how agrammar might be processed within a cognitive viewof sentence comprehension wil l  be demonstratedwithin an implemented model of such processing,HOPE (Gigley, 1981; 1982a; 1982b; 1983; 1984;1985).
This view of grammatical "process" sug-gests that neural processing should be included asa basis for defining what is universal in lan-guage.2.
BackgroundThere are currently several approaches todeveloping cognitive models of l inguistic function(Cottrell, 1984; Cottrell and Small, 1983; Gigley,1981; 1982a; 1982b; 1983; 1984; 1985; Small,Cottrell and Shastri, 1982; Waltz and Pollack, inpress).
These models include assumptions aboutmemory processing within a spreading activationframework (Collins and Loftus, 1975; Hinton, 1981;Quillian, 1968/1980), and a parallel, interactivecontrol paradigm for the processing.
They differin the explicit implementations of these theoriesand the degree to which they claim to be psycho-logically valid.Computational Neurolinguistics (CN), f i r s tsuggested as a problem domain by Arbib and Caplan(1979), is an Art i f ic ia l  Intelligence (AI) ap-proach to modelling neural processes which sub-serve natural language performance.
As CN hasdeveloped, such models are highly constrained bybehavioral evidence, both normal and pathological.CN provides a framework for defining cognitivemodels of natural language performance of behaviorthat includes claims of val idity at two levels,the natural computation or neural-like processinglevel, and at the system result or behaviorallevel.Using one implementation of a CN model, HOPE(Gigley, 1981; 1982a; 1982b; 1983) a model ofsingle sentence comprehension, the remainder ofthe paper wil l  i l lustrate how the role of grammarcan be integrated into the design of such a model.I t  wil l  emphasize the importance of the parallelcontrol assumptions in constraining the repre-sentation in which the grammar is encoded.
I twi l l  demonstrate how the grammar contributes tocontrol the coordination of the parallel, asyn-chronous processes included in the model.The HOPE model is chosen expl icit ly becausethe underlying assumptions in its design areintended to be psychologically valid on twolevels, while the other referenced models do notmake such claims.
The complete model is discussedin Gigley (1982a; 1982b; 1983) and wil l  be sum-marized here to i l lustrate the role of the grammarin its function.
The suggested implications andgoals for including neurophysiological evidence indesigning such models have been discussed else-324where in Lavorel and Gigley (1983) and wi l l  beincluded only as they relate to the role andfunction of the grammar.2.
I Summary of Included Knowledge and its Repre-sentationTypes of representations included in the HOPEmodel, phonetic, categorially accessed meanings,grammar, and pragmatic or local context, receivesupport as separately definable knowledge withinstudies of aphasia.
There is a vast literatureconcerning what aspects of language are indepen-dently affected in aphasia that has been used as abasis for deciding these representations.
(SeeGigley, 1982b for complete documentation.
)Information that is defined within the HOPEmodel is presented at a phonological evel asphonetic representations of words (a stub for asimilar interactive process underlying word re-cognition).
Information at the word meaning levelis represented as multiple representations, eachof which has a designated syntactic category typeand orthographic spelling associate to representthe phonetic word's meaning (also a stub).
Thegrammatical representation has two components.One is st r ic t ly  a local representation of thegrammatical structural co-occurrences in normallanguage.
The other is a functional repre-sentation, related to interpretation, that isunique for each syntactic category type.
Pleasenote that ~ ~ not used in the strictest senseof its use wlthln a t _~ semantic system.~TIF be des~ l~n detaiaT'-Ta't-e~T.
Finally, thepragmatic interpretation is assumed to reflect thesentential context of the utterance.Each piece of information is a thresholdingdevice with memory.
Associational interconnec-tions are made by using an hierarchical graphwhich includes a hypergraph fac i l i ty  that permitssimultaneous multiple interpretations for anyactive information in the process.
Using thisconcept, an active node can be ambiguous, repre-senting information that is shared among manyinterpretations.
Sentence comprehension is viewedas the resolution of the ambiguities that areactivated over the time course of the process.Within our implementation, graphs can repre-sent an aspect of the problem representation byname.
Any name can be attached to a node, or anedge, or a space (hypergraph) of the graph.
Thereare some naming constraints required due to thegraph processing system implementation, but theydo not affect the conceptual representation onwhich the encoding of the cognitive l inguisticknowledge relies.Any name can have multiple meanings asso-ciated with i t .
These meanings can be interpreteddifferently by viewing each space in which thename is referencea as a different viewpoint forthe same information.
This means that wheneverthe name is the same for any information, i t  isindeed the same information, although i t  may meanseveral things simultaneously.
An example relatedto the grammatical representation is that thesyntactic category aspect of each meaning of aphonetic word is also a part of the grammaticalrepresentation where i t  makes associations withother syntactic categories.
The associationsvisible in the grammatical representation andinterpreted as grammatical "meanings" are notviewable within the phonetic word meaning per-spective.However, any information associated with aname, for instance, an activity value, is viewablefrom any spaces in which the name exists.
Thismeans that any interpreted meaning associated witha name can only be evaluated within the context,or contexts, in which the name occurs.
Meaningfor any name is contextually evaluable.
Theexpl ic it  meaning within any space depends on therest of the state of the space, which furthermoredepends on what previous processing has occurredto affect the state of that space.2.2 Summary of the Processing ParadigmThe development of CN models emphasizesprocess.
A primary assumption of this approach isthat neural-like computations must be included inmodels which attempt to simulate any cognitivebehavior (Of Lavorel and Gigley, 1983), speci-f ica l ly  natural language processing in this case.Furthermore, CN includes the assumption that timeis a cr i t ical  factor in neural processin~mechanlsms an-~-d--that i  can be a slgnlflcant factorin language behavior in its degraded or "lesioned"state .Simulation of a process paradigm for naturallanguage comprehension in HOPE is achieved byincorporating a neurally plausible control that isinternal to the processing mechanism.
There is noexternal process that decides which path or pro-cess to execute next based on the current state ofthe solution space.
The process is time-locked;at each process t ime interval.
There are sixtypes of serial-order computations that can occur.They apply to all representation viewpoints orspaces simultaneously, and uniformly.
Thresholdf ir ing can affect multiple spaces, and has a localeffect within the space of f ir ing.Each of these serial-order computations isintended to represent an aspect of "natural compu-tation" as defined in Lavorel and Gigley, 1983.
Anatural computation, as opposed to a mechanisticone, is a "computation" that is achieved by neuralprocessing components, such as threshold devicesand energy transducers, rather than by componentssuch as are found in digital devices.
The mostimportant aspect of the control is that all of theserial order computations can occur simultaneouslyand can affect any info'~m-atTo~-'that has beendefined in the instantiated model.Processing control is achieved using activityvalues on information.
As there is no presetcontext in the current implementation, all in-formation in i t ia l l y  has a resting activity value.This activity value can be modified over timedepending on the sentential input.
Furthermore,there is an automatic activity decay scheme in-tended to represent memory processing which is325based on the state of the information, whether i thas reached threshold and fired or not.Activity is propagated in a fixed-time schemeto all "connected" aspects of the meaning of thewords by spreading activation (Collins and Loftus,1975; 1983; Hinton, 1981; Quillian, 1968/1980).Simultaneously, information interactsasynchronously due to threshold firing.
A stateof threshold f ir ing is realized as a result ofsummed inputs over time that are the result of thefixed-time spreading activation, other thresholdf ir ing or memory decay effects in combination.The time course of new information introduction,which initiates activity spread and automaticmemory decay is parameterized ue to the under-lying reason for designing such models (Gigley,1982b; 1983; 1985).The exact serial-order processes that occurat any time-slice of the process depend on the"current state" of the global information; theyare context dependent.
The serial-order processesinclude:(1) NEW-WORD-RECOGNITION: Introduction of thenext phonetically recognized word in thesentence.
(2) DECAY: Automatic memory decay exponentiallyre-e'du'ces the activity of all active informa-tion that does not receive additional input.I t  is an important part of the neural pro-cesses that occur during memory processing.
(3) REFRACTORY-STATE-ACTIVATION: ~-- _ -~ An auto-matic change of state that occurs afteractive information has reached threshold andfired.
In this state, the information cannot affect or be affected by other informa-tion in the system.
(4) POST-REFRACTORY-STATE-ACTIVATION: ~ Anautomatic hange of state which all fired in-formation enters after i t  has existed in theREFRACTORY-STATE.
The decay rate is dif-ferent than before f ir ing, although s t i l lexponential.
(5) MEANING-PROPAGATION: Fixed-time spreadingactivation to the distributed parts ofrecognized words' meanings.
(6) FIRING-INFORMATION-PROPAGATION:Asynchronous activity propagation that occurswhen information reaches threshold and fires.I t  can be INHIBITORY and EXCITATORY in itseffect.
INTERPRETATION results in activationof a pragmatic representation of a dis-ambiguated word meaning.Processes (2) through (6) are applicable toall active information in the global representa-tion, while process (1) provides the interfacewith the external input of the sentence to beunderstood.
The state of the grammar epresenta-tion affects inhibitory and excitatory firingpropagation, as well as coordinates "meaning"interpretation with on-going "input" processing.I t  is in the interaction of the results of theseasychronous processes that the process of compre-hension is simulated.3.
The Role of a Grammar in Cognitive ProcessingModelsWithin our behavioral approach to studyingnatural language processing, several considera-tions must be met.
Justification must be made forseparate representations of information and, when-ever possible, neural processing support must befound.3.1 Evidence for a Separate Representation ofGrammarNeurolinguistic and psycholinguistic evidencesupports a separately interpretable representationfor a grammar.
The neurolinguistic l i teraturedemonstrates that the grammar can be affected inisolation from other aspects of language function.
(Cf Studies of agrammatic and Broca's aphasia asdescribed in Goodenough, Zuri f ,  and Weintraub,1977; Goodglass, 1976; Goodglass and Berko, 1960;Goodglass, Gleason, Bernholtz, and Hyde, 1970;Zurif  and Blumstein, 1978).In the HOPE model, this separation isachieved by including all relevant grammaticalinformation within a space or hypergraph calledthe grammar.
The associated interpretation func-tions for each grammatical type provide the in-terface with the pragmatic representation.
Beforedescribing the nature of the local representationof the currently included grammar, a brief dis-cussion of the structure of the grammar and therole of the grammar in the global nature of thecontrol must be given.3.2 The Local Representation of the GrammarThe grammar space contains the locally de-fined grammar for the process.
The current modeldefined within the HOPE system includes a form ofa Categorial Grammar (Ajdukiewicz, 1935; Lewis,1972).
Although the original use of the grammaris not heeded, the relationship that ensues be-tween a well defined syntactic form and a "finalstate" meaning representation is borrowed.Validity of the "final state" meaning is not theissue.
Final state here means, at the end of theprocess.
As previously mentioned, typed semanticsis also not rigidly enforced in the current model.HOPE a11ows one to define a lexicon withinuser selecte~ syntactic types, and a11ows one todefine a suitable grammar of the selected types inthe prescribed form as well.
The grammar may bedefined to suit the aspects of language per-formance being modelled.There are two parts to the grammatical aspectof the HOPE model.
One is a form of the struc-tural co-occurrences that constitute context freephrase structure representations of grammar.However, these specifications only make one "con-stituent" predictions for subsequent input typeswhere each constituent may have additional sub-structure.326Predictions at this time do not spread tosubstructures because of the "time" factor betweencomputational updates that is used.
A spread tosubstructures wi l l  require a refinement in time-sequence specifications.The second aspect of the representation is aninterpretation function, for each specified syn-tactic type in the grammar definition.
Eachinterpretation function is activated when a wordmeaning fires for whatever eason.
The inter-pretation function represents a f i r ing activationlevel for the "concept" of the meaning and in-cludes its syntactic form.
For this reason, eachsyntactic form has a unique functional descriptionthat uses the instantiated meaning that is f i r ing(presently, the spelling notation) to activatestructures and relations in the pragmatic spacethat represent the "meaning understood.
"Each function activates different types ofstructures and relations, some of which depend onprior activation of other types to complete theprocess correctly.
These functions can triggersemantic feature checks and morphological matcheswhere appropriate.Syntactic types in the HOPE system are of twoforms, lexical and derived.
A lexical cateqoryte~xle is one which can be a category type of aca l  item.
A derived cate_~o type is onewhich is "composed.-a~"-~erlved category typesrepresent the occurrence of proper "meaning"interpretation in the pragmatic space.The current represented grammar in HOPEcontains the following lexical categories: OETfor determiner, ENOCONT for end of sentence in-tonation, NOUN for common noun, PAUSE for end ofclause intonation, TERM for proper nouns, VIP forintrasitive verb, VTP for transitive verb.
As isseen, the lexical "categories" relate"grammatical" structure to aspects of the inputsignal, hence in this sense ENDCONT and PAUSE arecategories.The derived categories in the current in-stantiated model include: SENTENCE, representinga composition of agent determination of a TERM foran appropriate verb phrase, TERM, representing acomposed designated DET NOUN referent, and VIP,representing the state of proper composition of aTERM object with a VTP, transitive verb sense.TERM and VIP are examples of category types inthis model that are both lexical and derived.
"Rules" in the independently representedgrammar are intended to represent what is con-sidered in HOPE as the "syntactic meaning" of therespective category.
They are expressed as localinteractions, not global ones.
Global effects ofgrammar, the concern of many rule based systems,can only be studied as the result of the timesequenced processing of an "input".
Table lcontains examples of "rules" in our current model.Other categories may be defined; other lexicalitems defined; other interpretations definedwithin the HOPE paradigm.Table l: Category specificationDET: = TERM / NOUNVIP: = SENTENCE / ENDCOUNTVTP: = VIP / TERMIn Table l ,  the "numerator" of the specifi-cation is the derived type which results fromcomposition of the "denominator" type interpre-tation with the interpretation of the categorywhose meaning is being defined.
For example,DETerminer, the defined category, combines with aNOUN category type to produce an interpretationwhich is a TERM type.
When a category occurs inmore than one place, any interpretation and re-sultant activity propagation of the correct typemay affect any "rule" in which i t  appears.
Ef-fects are in parallel and simultaneous.
Inter-pretation can be blocked for composition by un-successful matches on designated attribute fea-tures or morphological inconsistencies.Successful completion of function executionresults in a pragmatic representation that wi l leither f i re immediately i f  i t  is non-compositionalor in one time delay i f  the "meaning" is composed.Firing is of the syntactic type that representsthe correctly "understood" entity.
This "top-down" f i r ing produces feedback activity whoseeffect is "directed" by the state of the grammar,space, i.e.
what information is active and itsdegree of activity.The nature of the research in its presentstate has not addressed the generality of the l in-guistic structures i t  can process.
This is leftto future work.
The concentration at this time ison in i t ia l  validation of model produced simulationresults before any additional effort on expansionis undertaken.
With so many assumptions includedin the design of such models, in i t ia l  assessmentof the model's performance was felt  to be morecr i t ical  than its immediate xpansion along any ofthe possible dimensions previously noted as stubs.The in i t ia l  investigation is also intended tosuggest how to expand these stubs.3.3 The Grammar as a Feedback Control SystemThe role of the grammar as i t  is encoded inHOPE is to function in a systems theoretic manner.I t  provides the representation of the feedforward,or prediction, and feedback, or confirmationinterconnections among syntactic entities whichhave produced appropriate entities as pragmaticinterpretations.
I t  coordinates the serial or-dered expectations, with what actually occurs inthe input signal, with any suitable meaning in-terpretations that can affect the state of theprocess in a top-down sense.
I t  represents theinterface between the serial-order input and theparallel functioning system.Grammatical categories are activated viaspreading activation that is the result of wordmeaning activation as words are recognized.Firing of an instance of a grammatical type acti-vates that type's interpretation function which327results in the appropriate pragmatic interpreta-tion for i t ,  including the specific meaning thatwas fired.Interpretation function~ are defined forsyntactic types not specific items within eachtype.
Each type interpretation has one form withspecific lexical "parameters"L A11 nouns areinterpreted the same; a11 intransitive verbs thesame.
What di f fers in interpretation is theattributes that occur for the lexical item beinginterpreted.
These also affect the interpreta-tion.The meaning representation for a11 instancesof a certain category have the same meta-structure.
General nouns (NOUN) are presentlydepicted as nodes in the pragmatic space.
Thenode name is the "noun meaning."
For transitiveverbs, nodes named as the verb stem are producedwith a directed edge designating the appropriateTERM category as agent.
The effect of f i r ing  of agrammatical category can tr igger feature propaga-tions or morphological checks depending on whichcategory fires and the current pragmatic state ofthe on-going interpretation.Successful interpretation results in thres-hold f ir ing of the "meaning."
This "meaning" hasa syntactic component which can affect grammaticalrepresentations that have an activity value.
Thisprocess is time constrained depending on whetherthe syntactic type of the interpretation is lexi-cal or derived.3.4 Spreading Activation of the GrammarInput to HOPE is time-sequenced, as phone-t ical ly  recognized words, (a stub for futuredevelopment).
Each phonetic "word" activates allof its associated meanings.
(HOPE uses homophonesto access meanings.)
Using spreading activation,the syntactic category aspect of each meaning inturn activates the category's meaning in thegrammar space representation.Part of the grammatical meaning of any syn-tactic category is the meaning category that isexpected to follow i t  in the input.
The otherpart of the grammatical meaning for any categorytype, is the type i t  can derive by its correctinterpretation within the context of a sentence.Because each of these predictions and interpreta-tions are encoded locally, one can observe inter-actions among the global "rules" of the grammarduring the processing.
This is one of the moti-vating factors for designing the neurally moti-vated model, as i t  provides insights into howprocessing deviations can produce degraded lan-guage performance.3.5 Grammar State and Its Effect on ProcessingLexical category types have different effectsthan derived ones with respect to timing andpragmatic interpretation.
However, both lexicaland derived category types have the same effect onthe subsequent input.
This section wil l  describethe currently represented grammar and provideexample processing effects that arise due to itsinteractive activation.Through spreading activation, the state ofthe syntactic types represented in the grammaraffects subsequent category biases in the input(feedforward) and on-going interpretation ordisambiguation of previously "heard" words (feed-back).
The order of processing of the inputappears to be both right to lef t  and lef t  toright.
Furthermore, each syntactic type, onf ir ing, triggers the interpretation function thatis particular to each syntactic type.Rules, as previously discussed, are activatedduring processing via spreading activation.
Eachrecognized word activates all "meanings" inparallel.
Each "meaning" contains a syntactictype.
Spreading activation along "syntactic typeassociates" (defined in the grammar) predictivelyactivates the "expected" subsequent categories inthe input.In the HOPE model, spreading activationcurrently propagates this activity which is not atthe "threshold" level.
Propagated activity due tof ir ing is always a parameter controlled percentageof the above threshold activity and in the pre-sently "tuned" simulations always propagates avalue that is under threshold by a substantialamount.All activations occur in parallel and affectsubsequent "meaning" activities of later words inthe sentence.
In addition, when compositionsucceeds (or pragmatic interpretation isfinalized) the state of the grammar is affected toproduce or changes in category aspects of allactive meanings in the process.The remainder of this section wil l  presentinstances of the feedforward and feedback effectsof the grammar during simulation runs to i l lus-trate the role of grammar in the process.
Thelast example wil l  i l lustrate how a change in stateof the grammar representation can affect theprocess.
All examples wi l l  use snapshots of thesentence: "The boy saw the building."
This isinput phonetically as: (TH-UH B-OY S-AO TH-UHB-IH-L-D-IH-NG).3.5.1 An Example of Feedforward, Feedback, andCompositionThis example wil l  i l lustrate the feedforwardactivation of NOUN for the DETerminer grammaticalmeaning during interpretation of the in i t ia l  TERMor noun phrase of the sentence.
At1 figures arelabelled to correspond with the text.
Each in-terval is labelled at the top, t l ,  t2, etc.
Thesize of each node reflects the activity level,larger means more active.
Threshold firing isrepresented as F~ Other changes of state thataffect memory are are denoted (~ and~ andare shown for coa~leteness.
They indicateserial-order changes of state described earlier,but are not crit ical to the following discussion.328I I  l |  I$ 14 IIIr-a-,boy .
.
.
.
~'z~i ( i )/ ~/ .,' ~, ,~ ',~l 1 'P/ ~ t , v(q) --', .'
/PNO IIIT|~o I i (h)TH-UH B'<)?
S-AOFigure 1On "hearing" /TII-UH/ (a) at t l ,  the repre-sented meaning "OET-the" is activated as the onlymeaning (b).
At the next time interval, t2, themeaning of OET is activated - which spreads acti-vity to what OET predicts, a NOUN (c).
A11 NOUNmeanings are activated by spread in the next timeinterval, t3, in combination with new activity.This produces a threshold which "fires" the"meaning" selected (d).
At completion of i n ter -pretat ion (e), in t4, feedback occurs to a11instances of meaning with category types in thegrammar associated as predictors of the inter-preted category.
OET is the only active categorythat predicts NOUN so all act ive meanings of typeOET wil l  receive the feedback activity.
In FigureI, OET-the is ready to f ire (f).
The increase ordecrease in activity of a11 related types,competitive ones for the meaning ( inh ib i to ry )  (g)as well as syntact ic  ones for  composition (ex-c i ta tory )  (f) is propagated at the next intervalafter f ir ing, shown in t3 and t4.
In tS, /S-AO/enters the process (h) with its associated mean-ings.The effect of OET-the firing is also seen int5 where the compositional TERM is activated ( i ) .NOTE: DETerminers are not physically representedas entities in the pragmatic space.
Their meaningis only funct ional  and has a "semantic" combosi-t ional  effect.
Here ' tne'  requires a "one andonly one" NOUN that is unattached as a TERM tosuccessful ly denote the meaning of the boy as aproper TERM ( i) .
As th is  is a compositional"meaning", the firing wil l  affect t6.
Becausethere is no act ive TERM prediction in the grammarspace, and no competitive meanings, the top-downeffect in t6 will be null and is not shown.
Thenext exa~le will illustrate a top-down effectfollowing TERM composition.3.5.2 An Example of Feedforward, Feedback,Composition, and Subsequent FeedbackThis ex~,nple, shown in Figure 2, wil l  be verysimilar to the previous one.
Only active informa-tion discussed is shown as otherwise the figuresbecome cluttered.
The grammar is in a differentstate in Figure Z when successful TERM interpre-tation occurs at all (a).
This is due to theactivation at tg of all meanings of B-UI-L-O-IH-NG(b).The VTP meanings of /S-AO/ and then/B-UI-L-O-IH-NG/ make a TERM prediction shown asi t  remains in tlO (c).
After composition of "thebuilding" (a) shown in tel, TERM will  f i re top-down.
I t  subsequently, through feedback,- acti-vates all meanings of the category type whichpredicted the TERM, all VTP type meanings in thiscase.
This excitatory feedback, raises both VTPmeanings in t12, for saw (d), as well as, building(e).
However, the activity level of "buildingdoes" not reach threshold because of previousdisembiguation of its NOUN meaning.
When the VTPmeaning, saw, fires (d) in t\]2, additionalcomoosition occurs.
The VTP interpretationcomposes with a sui table TERM (a),  one whichmatches feature attribute specifications of saw,329/.
t l  0I I I "PRJU3~TZCbu?1dinqf/ /.,::.--'!
:i l l  (:12Figure 2.t 'O  " "  ?
?
~ " -"-~',--, I v ,_'.'"
~ ,,_., * #0=-  ~d~- - - - - - - - - - - -~/~" - -~" - -  ----."
"~ L " i -"-" "  ~" "~ " ~ ~ I " ~ " - - \  L~WJ,h --TEIm(b )S-AO ~ ~ .,8-ZH-L-O-Zn-,~ _ - -  .
.
.
.
.
.
.
( 'o  "~,- .
.
.
.%_.
f- -  ,m~ (e)um.L ? )
m,t l  9.Z t3  t4P#AOMAI~C:S-A~Figure 3.~I -U l l330to produce a VIP type at t13 this  w i l l  sub-sequently produce feedback at t14, Neither areshown.3.5.3 Effect of a Oi f ferent  Grammar State onProcessingThe f ina l  example, Figure 3, w i l l  use one ofthe " lesion" simulations using HOPE.
The grammarrepresentations remain intact.
This example wi l lpresent the understanding of the f i r s t  three wordsof the sentence under the condition that they arepresented faster  than the system is processing.E f fect ive ly ,  a slow-down of act ivat ion spread tothe grammar is assumed.
Figures such as Figure 1and Figure 3 can be compared a to suggest possiblelanguage performance problems and to gain insightsinto their possible causes.In Figure 3, when /TH-UH/ is introduced at t lCa), a l l  meanings are activated (b) as in Figure1.
The spread of act ivat ion to the grammar occursin t2 (c).
However, the second word, /8-OY/ (d)is '*heard" at the same time as the act iv i tyreaches the grammar.
The predict ive act ivat ionspread From the grammar takes ef fect  at t3, whenthe new word /S-N)/ (e) is "heard."
The immediateresult is that the NOUN meaning, saw ( f ) ,  f i resand is interpreted at t4 (g).This shows in a very simple case, now thegrammar can af fect  the processing states of aninteract ive para l le l  model.
Timing can be seen tobe c r i t i ca l .
There are many more c r i t i ca l  resultsthat occur in such " lesion" simulations thatbetter i11ustrate such grammatical af fects ,  how-ever they are very d i f f i cu l t  to present in as tat ic  form, other than within a behaviorialanalysis of the overal l  l i ngu is t i c  performance ofthe ent i re made1.
This is considered an hypo-thesized patient profile and is described inGigley (1985).
Other examDles of processing arepresented in detai l  in Gigley (lg82b; 1983).3.6 SummaryThe above figures present a very simpleexamole of the interact ive process.
I t  is hopedthat they provide an idea of the interactions andfeedback, feedfor~ard processing that is cooP-dinated by the state of the grammar.
Any pre-diction in the grammar that is not su f f i c ient lyactive affects the process.
Any decay that ac-c ident ly reduces a grammatical aspect can af fectthe process.
The timing of act ivat ion,  the cate-gorial content and the interactions between in-terpretation and prediction are imbortant Factorswhen one considers grammar as part of a func-t ioning ~ynamic system.Finally, the Categorial Grammar is one formof a Context-Free (CF) grammar which provides asuitable integration of syntactic and semanticprocessing.
In addit ion, i t  has been used in manystudies of English so that instances of gr~arssu f f i c ient ly  defined for the current implementa-t ion level of processing could be found.
Otherforms of grammar, such as Lexical-FunctionalGrammar (Kaolan and Bresnan, 1982) or GenerelizedPhrase Structure Grammar (Gazdar, 1982; 1983)could be edually suitable.The criteria to be met al that they can beencoded as predictive mechanisms, not necessarilyunamOiguous or deterministic, and also that theyspecify constraints on composit ional i ty.
Thecomposition depends on adequate definition ofinterpretation constraints to assure that it is"computed" properly or else sui tably marked fori t s  deviation.4.
ConclusionHOPE provides evidence for how one can view agrammar as an integrated part of a neuraIly-motivated processing model that is psychological lyval id .
~uitable constraints on grammatical formthat are relevant for using any grammar in the CNcontext are t~at the grammar make serial predic-tions and provide the synchronization informationto coordinate toD-down effects of interpretat ionwith the on-going process.This type of model suggests that universalsof language are inseparable from how the arecomputed.
Universals of language may only bedefinable within neural substrata and their pro-cesses.
Furthermore, i f  this view of l inguist icuniversals holds, then grammar becomes a controlrepresentation that synchronizes the kinds ofsignals that occur and when they get propagated.The states of the grammar in th is  suggested viewof grammatical function are a form of the rewriterules that are the focus of much l inguistictheory.A neural ly motivated processing paradigm fornatural language processing, demonstrates now onecan view an integrated process for language thatemploys integrated syntactic and semantic pro-cessing which relies on a suitable grammaticalform that coordinates the processes.S.
AcknowledgementsThe in i t ia l  development of the reportedresearch was supported by an Alfred P. SloanFoundation Grant for "A Training Program in Cog-nitive Science" at the Univers i ty of Massachusettsat Amherst.
Continuing development is subportedthrough a Biomedical Research Support Grant at theUnivers i ty of New Hamoshire.6.
ReferencesAjdukiewicz, O. Oie Syntaktische Konnexitat,1935.
T.anslated as "Syntactic Connection" inPolish Loqic, S. McCall, Oxford, 1967, 207-231.Arbib, H.A.
and Caplan, O. Neurol inguist icsMust Be Com!Dutational.
Behavioral and BrainSciences, 1979, 2, 449-483.Col l ins,  A.M., and Loftus, E.A.
A spreadingact ivat ion .
theory of semantic processing.Psycholo2ical Review, 1975, 82:6, 407-428.331Cottre11, G.W.
and Small, S.L.
A Connec-t ion ist  Scheme for Hodelling Word Sense Oisam-biguation.
Cognition and Brain Theory, 1983, 6:1,89-120.Cottrel l ,  G.W.
A model of Lexical Access ofAmpiguous Words.
Proceedings of AAAI -- 1984.Gazdar, G. Phrase Structure Grammar.
In P.Jacobson and G. Pullum (eds.
), The Nature ofSyntactic Representation.
Reide,T~- ~ch~,1982.Gazdar, G. Phrase Structure Grammars andNatural Languages.
Proceedings of theInternational Joint Conference on A'~tif icia|Intelligence.
Kar"~T~uhe, west German, 1983,Gigley, H.M. Neurolinguistically BasedHodeling of Natural Language Processing.
Paperpresente~ at the ACL Session of the LinguisticSociety of American Heeting, New York, Oeceed~er,1981.G|gley, H.M. A computational neurolin~uisticapproach to process~nq models of sentencehension.
"COINS Technic~o~SZ-'Z-,-~,Univers~tyo-'~-Ha-ssachusetts, Amherst, 1982.Gigley, H.M. Neurolin~uistically constrainedsimultation of sentence comprehension: \[nteqrat-~.q ar~i f ic~\]~~ence a~ ~_~ai~ theol.h.O.
Oissertation, University of Massachusetts,Amherst, 1982b.Gigley, H.M. HOPE -- AI and the OynamicProcess of Lanaguage Behavior.
Coqnition andBrain Theo~, 1983, 6, 1.Gigley, H.M. Computational Neurolinguis-tics - What is  i t  all about?
Proceedinqs of IJCAI855, Los Angeles, to appear.Gigley, H.H.
Fron HOPE en I'ESPERANCE -- Onthe Role of Computational Neuralinguistics inCross-Language Studies.
Proceedings of COLING 84.Stanfor~ University, July, 1984.Goodenough, C., Zurif, E. and Weintraub, S.Aphasic's attention to grammatical morphemes,LanquaQe end Speech, 1977, 11-19.Goodglass, H. Agrammatism.
In H. Whitakerand H.A.
Whitaker (eds.)
Studies in Neurolin~uis-t ics, :101,.
~, Academic Press,-s,i',i'~.-~37'-ZSO.Goodglass, H. and BerKo, J. Agrammatism andinflectional mOrl~hology in English.
Journal ofSpeech an~Hearin~ Research, 1960, 3, 257~.Goodglas~, H., Gleason, J .
,  Bernhoitz, N. andHyde, M. Some Linguistic ;tructures in the Soeechof a Broca's Aonasic.
Corte~, 1970, 8, 191-Z12.Hinton, G.E.
Implementing 5e~lntic Nets inParallel Hat,are.
In G.E.
Hinton and J.A.Anaerson (eds.
), Parallel Nodels of Associative ~.
.
Lawrence-~'rToaum ~ate~ Publishers,Kaplan, R.M.
and Sresnan, J. Lexical-Functional Grammar: A Fomal System for Gr~a-matical ReDresentation.
In J. Bresnan (ed.
), TheHental" Representation of Grammatical RelationS.M-'rT-P'~ess, 1982.Lavorel, P.M. and Gigley, H.H.
Elements pourune theorie generale des machines inte\]l igentes.\ [ntel lect ica,  1983, 7, 20-38.Lewis, O.
General Semantics.
In Oavidsonand Harmon (eds.
), Semantics of Natural Lanquaqe,1972, 169-218.Quil l ian, .
M.R.
Semantic Memory.
In H.Hinsky (ed.
), Semantic Information Processinq.CaLmDri~ge, Ha.
: ~ s ,  1980.Small, S., Cottre l l ,  G., and Shastri, L.Toward connectionist parsing.
Proceedings of theNational Conference on Ar t i f i c ia l  Inte\]liqence,~ g h ,  PA: 1982,~'8-20.Waltz, O. and Pollack, J. Massively ParallelParsing: A Strongly Interactive Hodel of NaturalLanguage Interpretation.
Cognitive Science.
Inpress.Zurif,  E.B.
and Blumstein, S.E.
Language andthe Brain.
In M. Halle, J.
8resnan, and G.Mtl ler,  (eds.
), Linquistic Theor~ andPsycholoqical Rea\]it~.
MIT Press, 1978.i332
