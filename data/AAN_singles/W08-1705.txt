Coling 2008: Proceedings of the workshop on Grammar Engineering Across Frameworks, pages 33?40Manchester, August 2008Speeding up LFG Parsing Using C-Structure PruningAoife Cahill?
John T. Maxwell III?
Paul Meurer?
Christian Rohrer?
Victoria Rose?n?
?IMS, University of Stuttgart, Germany, {cahillae, rohrer}@ims.uni-stuttgart.de?Palo Alto Research Center, 3333 Coyote Hill Road, Palo Alto, CA 94304, maxwell@parc.com?Unifob Aksis, Bergen, Norway, paul.meurer@aksis.uib.no?Unifob Aksis and University of Bergen, Norway, victoria@uib.noAbstractIn this paper we present a method forgreatly reducing parse times in LFG pars-ing, while at the same time maintainingparse accuracy.
We evaluate the method-ology on data from English, German andNorwegian and show that the same pat-terns hold across languages.
We achievea speedup of 67% on the English data and49% on the German data.
On a smallamount of data for Norwegian, we achievea speedup of 40%, although with moretraining data we expect this figure to in-crease.1 IntroductionEfficient parsing of large amounts of natural lan-guage is extremely important for any real-worldapplication.
The XLE Parsing System is a large-scale, hand-crafted, deep, unification-based sys-tem that processes raw text and produces bothconstituent structures (phrase structure trees) andfeature structures (dependency attribute-value ma-trices).
A typical breakdown of parsing timeof XLE components with the English grammaris Morphology (1.6%), Chart (5.8%) and Unifier(92.6%).
It is clear that the major bottleneck inprocessing is in unification.
Cahill et al (2007)carried out a preliminary experiment to test thetheory that if fewer c-structures were passed tothe unifier, overall parsing times would improve,while the accuracy of parsing would remain sta-ble.
Their experiments used state-of-the-art prob-abilistic treebank-based parsers to automaticallyc?
2008.
Licensed under the Creative CommonsAttribution-Noncommercial-Share Alike 3.0 Unported li-cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).Some rights reserved.mark certain constituents on the input sentences,limiting the number of c-structures the XLE pars-ing system would build.
They achieved an 18%speedup in parse times, while maintaining the ac-curacy of the output f-structures.
The experimentspresented in Cahill et al (2007) used the XLE sys-tem as a black box and did not make any changes toit.
However, the results were encouraging enoughfor a c-structure pruning mechanism to be fully in-tegrated into the XLE system.The paper is structured as follows: we presentthe pruning model that has been integrated into theXLE system (Section 2), and how it can be ap-plied successfully to more than one language.
Wepresent experiments for English (Section 3), Ger-man (Section 4) and Norwegian (Section 5) show-ing that for both German and English, a significantimprovement in speed is achieved, while the qual-ity of the f-structures remains stable.
For Norwe-gian a speedup is also achieved, but more trainingdata is required to sustain the accuracy of the f-structures.
In Section 7 we present an error anal-ysis on the German data.
We then relate the workpresented in this paper to similar efficient parsingstrategies (Section 8) before concluding in Section9.2 XLE and the C-Structure PruningMechanismThe XLE system is designed to deal with largeamounts of data in a robust manner.
There areseveral mechanisms which facilitate this, includingfragmenting and skimming.
Fragmenting is calledwhen the grammar is unable to provide a completeparse for the input sentence, and a fragment anal-ysis of largest possible chunks is built.
Skimmingis called when too much time or memory has beenused by XLE.
Any constituents that have not been33fully processed are ?skimmed?, which means thatthe amount of work carried out in processing theconstituent is limited.
This guarantees that XLEwill finish processing the sentence in polynomialtime.XLE uses a chart-based mechanism for build-ing parses, and has been complemented with a c-structure pruning mechanism to speed up parsingtime.
During pruning, subtrees at a particular cellin the chart are pruned if their probabilities are nothigher than a certain threshold.
The chart pruneruses a simple stochastic CFG model.
The proba-bility of a tree is the product of the probabilitiesof each of the rules used to form the tree, includ-ing the rules that lead to lexical items (such as N?
dog).
The probability of a rule is basically thenumber of times that that particular form of therule occurs in the training data divided by the num-ber of times the rule?s category occurs in the train-ing data, plus a smoothing term.
This is similarto the pruning described in Charniak and Johnson(2005) where edges in a coarse-grained parse for-est are pruned to allow full evaluation with fine-grained categories.The pruner prunes at the level of individual con-stituents in the chart.
It calculates the probabil-ities of each of the subtrees of a constituent andcompares them.
The probability of each subtreeis compared with the best subtree probability forthat constituent.
If a subtree?s probability is lowerthan the best probability by a given factor, then thesubtree is pruned.
In practice, the threshold is thenatural logarithm of the factor used.
So a value of5 means that a subtree will be pruned if its prob-ability is about a factor of 150 less than the bestprobability.If two different subtrees have different num-bers of morphemes under them, then the proba-bility model is biased towards the subtree that hasfewer morphemes (since there are fewer probabil-ities multiplied together).
XLE counteracts this bynormalizing the probabilities based on the differ-ence in length.To illustrate how this works, we give the follow-ing example.
The string Fruit flies like bananas hastwo different analyses.
Figures 1 and 2 give theiranalyses along with hypothetical probabilities foreach rule.These two analyses come together at the S con-stituent that spans the whole sentence.
The proba-bility of the first analysis is 8.4375E-14.
The prob-SNPNFruitNfliesVPVlikeNPNbananasS ?
NP VP 0.5000NP ?
N N 0.1500N ?
Fruit 0.0010N ?
flies 0.0015VP ?
V NP 0.2000V ?
like 0.0050NP ?
N 0.5000N ?
bananas 0.00158.4375E-14Figure 1: Analysis (1) for the string Fruit flies likebananas with hypothetical probabilitiesSNPNFruitVPVfliesPPPlikeNPNbananasS ?
NP VP 0.5000NP ?
N 0.5000N ?
Fruit 0.0010V ?
flies 0.0025VP ?
V PP 0.1000P ?
like 0.0500PP ?
P NP 0.9000NP ?
bananas 0.00154.21875E-12Figure 2: Analysis (2) for the string Fruit flies likebananas with hypothetical probabilitiesability of the second analysis is 4.21875E-12.
Thismeans that the probability of the second analysisis 50 times higher than the probability of the firstanalysis.
If the threshold is less than the naturallogarithm of 50 (about 3.9), then the subtree of thefirst analysis will be pruned from the S constituent.3 Experiments on EnglishWe carried out a number of parsing experiments totest the effect of c-structure pruning, both in termsof time and accuracy.
We trained the c-structurepruning algorithm on the standard sections of PennTreebank Wall Street Journal Text (Marcus et al,1994).
The training data consists of the originalWSJ strings, marked up with some of the Penn34Treebank constituent information.
We marked upNPs and SBARs as well as adjective and verbalPOS categories.
This is meant to guide the train-ing process, so that it does learn from parses thatare not compatible with the original treebank anal-ysis.
We evaluated against the PARC 700 Depen-dency Bank (King et al, 2003), splitting it into 140sentences as development data and the remainingunseen 560 for final testing (as in Kaplan et al(2004)).
We experimented with different valuesof the pruning cutoff on the development set; theresults are given in Table 1.The results show that the lower the cutoff value,the quicker the sentences can be parsed.
Usinga cutoff of 4, the development sentences can beparsed in 100 CPU seconds, while with a cutoffof 10, the same experiment takes 182 seconds.With no cutoff, the experiment takes 288 CPU sec-onds.
However, this increase in speed comes at aprice.
The number of fragment parses increases,i.e.
there are more sentences that fail to be analyzedwith a complete spanning parse.
With no pruning,the number of fragment parses is 23, while withthe most aggressive pruning factor of 4, there are39 fragment parses.
There are also many moreskimmed sentences with no c-structure pruning,which impacts negatively on the results.
The ora-cle f-score with no pruning is 83.07, but with prun-ing (at all thresholds) the oracle f-score is higher.This is due to less skimming when pruning is acti-vated, since the more subtrees that are pruned, theless likely the XLE system is to run over the timeor memory limits needed to trigger skimming.Having established that a cutoff of 5 performsbest on the development data, we carried out thefinal evaluation on the 560-sentence test set usingthis cutoff.
The results are given in Table 2.
Thereis a 67% speedup in parsing the 560 sentences, andthe most probable f-score increases significantlyfrom 79.93 to 82.83.
The oracle f-score also in-creases, while there is a decrease in the random f-score.
This shows that we are throwing away goodsolutions during pruning, but that overall the re-sults improve.
Part of this again is due to the factthat with no pruning, skimming is triggered muchmore often.
With a pruning factor of 5, there areno skimmed sentences.
There is also one sentencethat timed out with no pruning, which also lowersthe most probable and oracle f-scores.Pruning Level None 5Total Time 1204 392Most Probable F-Score 79.93 82.83Oracle F-Score 84.75 87.79Random F-Score 75.47 74.31# Fragment Parses 96 91# Time Outs 1 0# Skimmed Sents 33 0Table 2: Results of c-structure pruning experi-ments on English test data4 Experiments on GermanWe carried out a similar set of experiments onGerman data to test whether the methodology de-scribed above ported to a language other than En-glish.
In the case of German, the typical time ofXLE components is: Morphology (22.5%), Chart(3.5%) and Unifier (74%).
As training data weused the TIGER corpus (Brants et al, 2002).
Set-ting aside 2000 sentences for development andtesting, we used the remaining 48,474 sentences astraining data.
In order to create the partially brack-eted input required for training, we converted theoriginal TIGER graphs into Penn-style trees withempty nodes and retained bracketed constituents ofthe type NP, S, PN and AP.
The training data wasparsed by the German ParGram LFG (Rohrer andForst, 2006).
This resulted in 25,677 full parses,21,279 fragmented parses and 1,518 parse fail-ures.1 There are 52,959 features in the final prun-ing model.To establish the optimal pruning settings forGerman, we split the 2,000 saved sentences into371 development sentences and 1495 test sen-tences for final evaluation.
We evaluated againstthe TiGer Dependency Bank (Forst et al, 2004)(TiGerDB), a dependency-based gold standard forGerman parsers that encodes grammatical rela-tions similar to, though more fine-grained than,the ones in the TIGER Treebank as well as mor-phosyntactic features.
We experimented with thesame pruning levels as in the English experiments.The results are given in Table 3.The results on the development set show a sim-ilar trend to the English results.
A cutoff of 4 re-sults in the fastest system, however at the expense1The reason there are more fragment parses than, for ex-ample, the results reported in Rohrer and Forst (2006) is thatthe bracketed input constrains the parser to only return parsescompatible with the bracketed input.
If there is no solutioncompatible with the brackets, then a fragment parse is re-turned.35Pruning Level None 4 5 6 7 8 9 10Oracle F-Score 83.07 84.50 85.47 85.75 85.57 85.57 85.02 84.10Time (CPU seconds) 288 100 109 123 132 151 156 182# Time Outs 0 0 0 0 0 0 0# Fragments 23 39 36 31 29 27 27 24# Skimmed Sents 8 0 0 1 1 1 1 3Table 1: Results of c-structure pruning experiments on English development dataPruning Level None 4 5 6 7 8 9 10Oracle F-Score 83.69 83.45 84.02 82.86 82.82 82.95 83.03 82.81Time (CPU seconds) 1313 331 465 871 962 1151 1168 1163# Time Outs 6 0 0 5 5 5 5 6# Fragments 65 104 93 81 74 73 73 68Table 3: Results of c-structure pruning experiments on German development dataPruning Level None 5Total Time 3300 1655Most Probable F-Score 82.63 82.73Oracle F-Score 84.96 84.79Random F-Score 73.58 73.72# Fragment Parses 324 381# Time Outs 2 2Table 4: Results of c-structure pruning experi-ments on German test dataof accuracy.
A cutoff of 5 seems to provide thebest tradeoff between time and accuracy.
Again,most of the gain in oracle f-score is due to fewertimeouts, rather than improved f-structures.
In theGerman development set, a cutoff of 5 leads to aspeedup of over 64% and a small increase in or-acle f-score of 0.33 points.
Therefore, for the fi-nal evaluation on the unseen test-set, we choose acutoff of 5.
The results are given in Table 4.
Weachieve a speedup of 49% and a non-significant in-crease in most probable f-score of 0.094.
The timespent by the system on morphology is much higherfor German than for English.
If we only take theunification stage of the process into account, theGerman experiments show a speedup of 65.5%.5 Experiments on NorwegianAs there is no treebank currently available for Nor-wegian, we were unable to train the c-structurepruning mechanism for Norwegian in the sameway as was done for English and German.
Thereis, however, some LFG-parsed data that has beencompletely disambiguated using the techniquesdescribed in Rose?n et al (2006).
In total thereare 937 sentences from various text genres includ-ing Norwegian hiking guides, Sophie?s World andthe Norwegian Wikipedia.
We also use this dis-ambiguated data as a gold standard for evaluation.The typical time of XLE components with the Nor-wegian grammar is: Morphology (1.6%), Chart(11.2%) and Unifier (87.2%).From the disambiguated text, we can automati-cally extract partially bracketed sentences as inputto the c-structure pruning training method.
We canalso extract sentences for training that are partiallydisambiguated, but these cannot be used as part ofthe test data.
To do this, we extract the bracketedstring for each solution.
If all the solutions pro-duce the same bracketed string, then this is addedto the training data.
This results in an average of4556 features.
As the data set is small, we do notsplit it into development, training and test sectionsas was done for English and German.
Instead wecarry out a 10-fold cross validation over the entireset.
The results for each pruning level are given inTable 5.The results in Table 5 show that the pattern thatheld for English and German does not quite holdfor Norwegian.
While, as expected, the time takento parse the test set is greatly reduced when usingc-structure pruning, there is also a negative impacton the quality of the f-structures.
One reason forthis is that there are now sentences that could pre-viously be parsed, and that now no longer can beparsed, even with a fragment grammar.2 With c-structure pruning, the number of fragment parsesincreases for all thresholds, apart from 10.
It isalso difficult to compare the Norwegian experi-ment to the English and German, since the goldstandard is constrained to only consist of sentencesthat can be parsed by the grammar.
Theoreticallythe oracle f-score for the experiment with no prun-2With an extended fragment grammar, this would not hap-pen.36Pruning Level None 4 5 6 7 8 9 10Oracle F-Score 98.76 94.45 95.60 96.40 96.90 97.52 98.00 98.33Time (CPU seconds) 218.8 106.2 107.4 109.3 112 116.2 124 130.7# Time Outs 0 0 0 0 0 0 0 0# Parse Failures 0.2 5.7 3.9 2 3.2 4.2 4.6 4.2# Fragments 1.3 7.7 6.5 4.7 2.8 1.8 1.5 1.2Table 5: Results of c-structure pruning 10-fold cross validation experiments on Norwegian data556065707580859095None 4 5 6 7 8 9 10Figure 3: The lower-bound results for each of the10 cross validation runs across the thresholdsing should be 100.
The slight drop is due to aslightly different morphological analyzer used inthe final experiments that treats compound nounsdifferently.
A threshold of 10 gives the best results,with a speedup of 40% and a drop in f-score of 0.43points.
It is difficult to choose the ?best?
thresh-old, as the amount of training data is probably notenough to get an accurate picture of the data.
Forexample, Figure 3 shows the lower-bound resultsfor each of the 10 runs.
It is difficult to see a clearpattern for all the runs, indicating that the amountof training data is probably not enough for a reli-able experiment.6 Size of Training Data CorpusThe size of the Norwegian training corpus is con-siderably smaller than the training corpora for En-glish or German, so the question remains howmuch training data we need in order for the c-structure pruning to deliver reliable results.
In or-der to establish a rough estimate for the size oftraining corpus required, we carried out an experi-ment on the German TIGER training corpus.We randomly divided the TIGER training cor-pus into sets of 500 sentences.
We plot the learn-ing curve of the c-structure pruning mechanism inFigure 4, examining the effect of increasing thesize of the training corpus on the oracle f-score onthe development set of 371 sentences.
The curveshows that, for the German data, the highest oraclef-score of 84.98 was achieved with a training cor-pus of 32,000 sentences.
Although the curve fluc-tuates, the general trend is that the more trainingdata, the better the oracle f-score.37 Error AnalysisGiven that we are removing some subtrees duringparsing, it can sometimes happen that the desiredanalysis gets pruned.
We will take German as anexample, and look at some of these cases.7.1 Separable particles vs pronominaladverbsThe word dagegen (?against it?)
can be a separableprefix (VPART) or a pronominal adverb (PADV).The verb protestieren (?to protest?)
does not takedagegen as separable prefix.
The verb stimmen(?to agree?)
however does.
If we parse the sen-tence in (1) with the verb protestieren and activatepruning, we do not get a complete parse.
If weparse the same sentence with stimmen as in (2) wedo get a complete parse.
If we replace dagegenby dafu?r, which in the current version of the Ger-man LFG can only be a pronominal adverb, thesentence in (3) gets a parse.
We also notice thatif we parse a sentence, as in (4), where dagegenoccurs in a position where our grammar does notallow separable prefixes to occur, we get a com-plete parse for the sentence.
These examples showthat the pruning mechanism has learned to prunethe separable prefix reading of words that can beboth separable prefixes and pronominal adverbs.
(1) Sietheyprotestierenprotestdagegen.against-it?They protest against it.?
(2) Sietheystimmenvotedagegen.against-it?They vote against it.
?3Unexpectedly, the curve begins to decline after 32,000sentences.
However, the differences in f-score are not statis-tically significant (using the approximate randomization test).Running the same experiment with a different random seedresults in a similarly shaped graph, but any decline in f-scorewhen training on more data was not statistically significant atthe 99% level.3732000, 84.976988484.184.284.384.484.584.684.784.884.9855002000350050006500800095001100012500140001550017000185002000021500230002450026000275002900030500320003350035000365003800039500410004250044000455004700048500Number of Training SentencesF-ScoreFigure 4: The effect of increasing the size of the training data on the oracle f-score(3) Erheprotestiertprotestsdafu?r.for-it?He protests in favour of it.?
(4) Dagegenagainst-itprotestiertprotestser.he?Against it, he protests.
?7.2 Derived nominal vs non-derived nominalThe word Morden can be the dative plural of thenoun Mord (?murder?)
or the nominalized form ofthe verb morden (?to murder?).
With c-structurepruning activated (at level 5), the nominalizedreading, as in (6), gets pruned, whereas the dativeplural reading is not (5).
At pruning level 6, bothreadings are assigned a full parse.
We see simi-lar pruning of nominalized readings as in (7).
Ifwe look in more detail at the raw counts for re-lated subtrees gathered from the training data, wesee that the common noun reading for Morden oc-curs 156 times, while the nominalized reading onlyoccurs three times.
With more training data, the c-structure pruning mechanism could possibly learnwhen to prune correctly in such cases.
(5) ErheredetspeaksvonofMorden.murders?He speaks of murders.?
(6) DastheMordenmurderingwillwantsnichtnotenden.end?The murdering does not want to end.?
(7) DastheArbeitenworkingendet.ends?The operation ends.
?7.3 Personal pronouns which also function asdeterminersThere are a number of words in German that canfunction both as personal pronouns and determin-ers.
If we take, for example, the word ihr, whichcan mean ?her?, ?their?, ?to-her?, ?you-pl?
etc.,the reading as a determiner gets pruned as well assome occurrences as a pronoun.
In example (8),we get a complete parse for the sentence with thedative pronoun reading of ihr.
However, in ex-ample (9), the determiner reading is pruned andwe fail to get a complete parse.
In example (10),we also fail to get a complete parse, but in exam-ple (11), we do get a complete parse.
There is aparameter we can set that sets a confidence valuein certain tags.
So, for example, we set the con-fidence value of INFL-F BASE[det] (the tag givento the determiner reading of personal pronouns) tobe 0.5, which says that we are 50% confident thatthe tag INFL-F BASE[det] is correct.
This results in38examples 8, 9 and 11 receiving a complete parse,with the pruning threshold set to 5.
(8) Erhegibtgivesesitihr.her?He gives it to her.?
(9) Ihrher/theirAutocarfa?hrt.drives?Her/Their car drives.
(10) Ihryou(pl)kommt.come?You come.?
(11) Erhevertrauttrustsihr.her?He trusts her.
?7.4 Coordination of Proper NounsTraining the German c-structure pruning mecha-nism on the TIGER treebank resulted in a pecu-liar phenomenon when parsing coordinated propernouns.
If we parse four coordinated proper nounswith c-structure pruning activated as in (12), weget a complete parse.
However, as soon as we adda fifth proper noun as in (13), we get a fragmentparse.
This is only the case with proper nouns,since the sentence in (14) which coordinates com-mon nouns gets a complete parse.
Interestingly, ifwe coordinate n proper nouns plus one commonnoun, we also get a complete parse.
The reason forthis is that proper noun coordination is less com-mon than common noun coordination in our train-ing set.
(12) Hans, Fritz, Emil und Maria singen.
?Hans, Fritz, Emil and Maria sing.?
(13) Hans, Fritz, Emil, Walter und Maria sin-gen.?Hans, Fritz, Emil, Walter and Maria sing.?
(14) Hunde, Katzen, Esel, Pferde und Affenkommen.
?Dogs, cats, donkeys, horses and apescome.?
(15) Hans, Fritz, Emil, Walter, Maria undKinder singen.
?Hans, Fritz, Emil, Walter, Maria and chil-dren sing.
?We ran a further experiment to test what effectadding targeted training data had on c-structurepruning.
We automatically extracted a specializedcorpus of 31,845 sentences from the Huge Ger-man Corpus.
This corpus is a collection of 200million words of newspaper and other text.
Thesentences we extracted all contained examples ofproper noun coordination and had been automati-cally chunked.
Training on this sub-corpus as wellas the original TIGER training data did have thedesired effect of now parsing example (13) withc-structure pruning activated.8 Related WorkNinomiya et al (2005) investigate beam threshold-ing based on the local width to improve the speedof a probabilistic HPSG parser.
In each cell of aCYK chart, the method keeps only a portion of theedges which have higher figure of merits comparedto the other edges in the same cell.
In particular,each cell keeps the edges whose figure of merit isgreater than ?max- ?, where ?maxis the high-est figure of merit among the edges in the chart.The term ?beam thresholding?
is a little confusing,since a beam search is not necessary ?
instead, theCYK chart is pruned directly.
For this reason, weprefer the term ?chart pruning?
instead.Clark and Curran (2007) describe the use ofa supertagger with a CCG parser.
A supertag-ger is like a tagger but with subcategorization in-formation included.
Chart pruners and supertag-gers are conceptually complementary, since chartpruners prune edges with the same span and thesame category, whereas supertaggers prune (lexi-cal) edges with the same span and different cate-gories.
Ninomiya et al (2005) showed that com-bining a chunk parser with beam thresholding pro-duced better results than either technique alone.
Soadding a supertagger should improve the resultsdescribed in this paper.Zhang et al (2007) describe a technique toselectively unpack an HPSG parse forest to ap-ply maximum entropy features and get the n-bestparses.
XLE already does something similar whenit applies maximum entropy features to get then-best feature structures after having obtained apacked representation of all of the valid featurestructures.
The current paper shows that pruningthe c-structure chart before doing (packed) unifica-tion speeds up the process of getting a packed rep-resentation of all the valid feature structures (ex-cept the ones that may have been pruned).399 ConclusionsIn this paper we have presented a c-structure prun-ing mechanism which has been integrated into theXLE LFG parsing system.
By pruning the numberof c-structures built in the chart, the next stage ofprocessing, the unifier, has considerably less workto do.
This results in a speedup of 67% for En-glish, 49% for German and 40% for Norwegian.The amount of training data for Norwegian wasmuch less than that for English or German, there-fore further work is required to fully investigatethe effect of c-structure pruning.
However, the re-sults, even from the small training data, were en-couraging and show the same general patterns asEnglish and German.
We showed that for the Ger-man training data, 32,000 sentences was the opti-mal number in order to achieve the highest oraclef-score.
There remains some work to be done intuning the parameters for the c-structure pruning,as our error analysis shows.
Of course, with sta-tistical methods one can never be guaranteed thatthe correct parse will be produced; however we canadjust the parameters to account for known prob-lems.
We have shown that the c-structure pruningmechanism described is an efficient way of reduc-ing parse times, while maintaining the accuracy ofthe overall system.AcknowledgementsThe work presented in this paper was supportedby the COINS project as part of the linguisticCollaborative Research Centre (SFB 732) at theUniversity of Stuttgart and by the Norwegian Re-search Council through the LOGON and TREPILprojects.ReferencesBrants, Sabine, Stefanie Dipper, Silvia Hansen, Wolf-gang Lezius, and George Smith.
2002.
The TIGERTreebank.
In Proceedings of the Workshop on Tree-banks and Linguistic Theories, Sozopol, Bulgaria.Cahill, Aoife, Tracy Holloway King, and John T.Maxwell III.
2007.
Pruning the Search Space ofa Hand-Crafted Parsing System with a ProbabilisticParser.
In ACL 2007 Workshop on Deep LinguisticProcessing, pages 65?72, Prague, Czech Republic,June.
Association for Computational Linguistics.Charniak, Eugene and Mark Johnson.
2005.
Coarse-to-Fine n-Best Parsing and MaxEnt DiscriminativeReranking.
In Proceedings of the 43rd Annual Meet-ing of the Association for Computational Linguis-tics (ACL?05), pages 173?180, Ann Arbor, Michi-gan, June.
Association for Computational Linguis-tics.Clark, Stephen and James R. Curran.
2007.
Wide-Coverage Efficient Statistical Parsing with CCG andLog-Linear Models.
Computational Linguistics,33(4):493?552.Forst, Martin, Nu?ria Bertomeu, Berthold Crysmann,Frederik Fouvry, Silvia Hansen-Schirra, and ValiaKordoni.
2004.
Towards a dependency-based goldstandard for German parsers ?
The TiGer Depen-dency Bank.
In Proceedings of the COLING Work-shop on Linguistically Interpreted Corpora (LINC?04), Geneva, Switzerland.Kaplan, Ronald M., John T. Maxwell, Tracy H. King,and Richard Crouch.
2004.
Integrating Finite-stateTechnology with Deep LFG Grammars.
In Pro-ceedings of the ESSLLI 2004 Workshop on Combin-ing Shallow and Deep Processing for NLP, Nancy,France.King, Tracy Holloway, Richard Crouch, Stefan Riezler,Mary Dalrymple, and Ronald M. Kaplan.
2003.
ThePARC 700 Dependency Bank.
In Proceedings of theEACL Workshop on Linguistically Interpreted Cor-pora (LINC ?03), Budapest, Hungary.Marcus, Mitchell P., Beatrice Santorini, and Mary AnnMarcinkiewicz.
1994.
Building a Large AnnotatedCorpus of English: The Penn Treebank.
Computa-tional Linguistics, 19(2):313?330.Ninomiya, Takashi, Yoshimasa Tsuruoka, YusukeMiyao, and Jun?ichi Tsujii.
2005.
Efficacy of BeamThresholding, Unification Filtering and Hybrid Pars-ing in Probabilistic HPSG Parsing.
In Proceed-ings of the Ninth International Workshop on Pars-ing Technology, pages 103?114, Vancouver, BritishColumbia, October.
Association for ComputationalLinguistics.Rohrer, Christian and Martin Forst.
2006.
ImprovingCoverage and Parsing Quality of a Large-scale LFGfor German.
In Proceedings of the Language Re-sources and Evaluation Conference (LREC-2006),Genoa, Italy.Rose?n, Victoria, Paul Meurer, and Koenraad de Smedt.2006.
Towards a Toolkit Linking Treebanking andGrammar Development.
In Hajic, Jan and JoakimNivre, editors, Proceedings of the Fifth Workshopon Treebanks and Linguistic Theories, pages 55?66,December.Zhang, Yi, Stephan Oepen, and John Carroll.
2007.Efficiency in Unification-Based N-Best Parsing.
InProceedings of the Tenth International Conferenceon Parsing Technologies, pages 48?59, Prague,Czech Republic, June.
Association for Computa-tional Linguistics.40
