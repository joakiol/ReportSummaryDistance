Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 367?375,Beijing, August 2010RTG based surface realisation for TAGClaire GardentCNRS/LORIAclaire.gardent@loria.frLaura Perez-BeltrachiniUniversite?
Henri Poincare?/LORIAlaura.perez@loria.frAbstractSurface realisation with grammars inte-grating flat semantics is known to be NPcomplete.
In this paper, we present a newalgorithm for surface realisation based onFeature Based Tree Adjoining Grammar(FTAG) which draws on the observationthat an FTAG can be translated into a Reg-ular Tree Grammar describing its deriva-tion trees.
We carry out an extensive test-ing of several variants of this algorithmusing an automatically produced testsuiteand compare the results obtained withthose obtained using GenI, another FTAGbased surface realiser.1 IntroductionAs shown in (Brew, 1992; Koller and Striegnitz,2002), Surface Realisation is NP-complete.
Var-ious optimisation techniques have therefore beenproposed to help improve practical runtimes.
Forinstance, (Kay, 1996) proposes to reduce the num-ber of constituents built during realisation by onlyconsidering for combination constituents with nonoverlapping semantics and compatible indices.
(Kay, 1996; Carroll and Oepen, 2005; Gardentand Kow, 2007) propose various techniques to re-strict the combinatorics induced by intersectivemodifiers all applying to the same structure.
And(Koller and Striegnitz, 2002; Gardent and Kow,2007) describe two alternative techniques for re-ducing the initial search space.In this paper, we focus on the optimisationmechanisms of two TAG based surface realisersnamely, GENI (Gardent and Kow, 2007) and thealgorithm we present in this paper namely, RT-GEN (Perez-Beltrachini, 2009).
GENI?s optimisa-tion includes both a filtering process whose aim isto reduce the initial search space and a two step,?substitution before adjunction?, tree combinationphase whose effect is to delay modifier adjunc-tion thereby reducing the number of intermediatestructures being built.
In RTGEN on the otherhand, the initial FTAG is converted to a Regu-lar Tree Grammar (RTG) describing its derivationtrees and an Earley algorithm, including sharingand packing, is used to optimise tree combination.We compare GENI with several variants of theproposed RTGEN algorithm using an automati-cally produced testsuite of 2 679 input formulaeand relate the RTGEN approach to existing workon surface realisation optimisation.The paper is structured as follows.
We firstpresent the grammar used by both GENI and RT-GEN, namely SEMXTAG (Section 2).
We then de-scribe the two surface realisation algorithms (Sec-tion 3).
In Section 4, we describe the empiricalevaluation carried out and present the results.
Fi-nally, Section 5 situates RTGEN with respect torelated work on surface realisation optimisation.2 SemXTagThe grammar (SEMXTAG) used by GENI andRTGEN is a Feature-Based Lexicalised TreeAdjoining Grammar (FTAG) augmented with aunification-based semantics as described in (Gar-dent and Kallmeyer, 2003).
We briefly introduceeach of these components and describe the gram-mar coverage.
We then show how this FTAG canbe converted to an RTG describing its derivationtrees.3672.1 FTAG.A Feature-based TAG (Vijay-Shanker and Joshi,1988) consists of a set of (auxiliary or initial) el-ementary trees and of two tree-composition oper-ations: substitution and adjunction.
Initial treesare trees whose leaves are labeled with substitu-tion nodes (marked with a downarrow) or termi-nal categories.
Auxiliary trees are distinguishedby a foot node (marked with a star) whose cate-gory must be the same as that of the root node.Substitution inserts a tree onto a substitution nodeof some other tree while adjunction inserts an aux-iliary tree into a tree.
In an FTAG, the tree nodesare furthermore decorated with two feature struc-tures (called top and bottom) which are unifiedduring derivation as follows.
On substitution, thetop of the substitution node is unified with the topof the root node of the tree being substituted in.On adjunction, the top of the root of the auxiliarytree is unified with the top of the node where ad-junction takes place; and the bottom features ofthe foot node are unified with the bottom featuresof this node.
At the end of a derivation, the topand bottom of all nodes in the derived tree areunified.
Finally, each sentence derivation in anFTAG is associated with both a derived tree rep-resenting the phrase structure of the sentence anda derivation tree recording how the correspond-ing elementary trees were combined to form thederived tree.
Nodes in a derivation tree are la-belled with the name of a TAG elementary tree.Edges are labelled with a description of the opera-tion used to combine the TAG trees whose nameslabel the edge vertices.2.2 FTAG with semantics.To associate semantic representations with natu-ral language expressions, the FTAG is modified asproposed in (Gardent and Kallmeyer, 2003).NPjJohnname(j,john)ScNP?s VPcbVbarunsrun(a,s)VPxoften VP*often(x)?
name(j,john), run(a,j), often(a)Figure 1: Flat Semantics for ?John often runs?Each elementary tree is associated with a flatsemantic representation.
For instance, in Fig-ure 1,1 the trees for John, runs and often are asso-ciated with the semantics name(j,john), run(a,s)and often(x) respectively.
Importantly, the argu-ments of a semantic functor are represented byunification variables which occur both in the se-mantic representation of this functor and on somenodes of the associated syntactic tree.
For in-stance in Figure 1, the semantic index s occur-ring in the semantic representation of runs alsooccurs on the subject substitution node of the as-sociated elementary tree.
The value of semanticarguments is determined by the unifications re-sulting from adjunction and substitution.
For in-stance, the semantic index s in the tree for runs isunified during substitution with the semantic in-dex labelling the root node of the tree for John.As a result, the semantics of John often runs is{name(j,john),run(a,j),often(a)}.2.3 SemXTAG.SEMXTAG is an FTAG for English augmentedwith a unification based compositional semanticsof the type described above.
Its syntactic cover-age approaches that of XTAG, the FTAG devel-oped for English by the XTAG group (The XTAGResearch Group, 2001).
Like this grammar, itcontains around 1300 elementary trees and cov-ers auxiliaries, copula, raising and small clauseconstructions, topicalization, relative clauses, in-finitives, gerunds, passives, adjuncts, ditransitivesand datives, ergatives, it-clefts, wh-clefts, PROconstructions, noun-noun modification, extraposi-tion, sentential adjuncts, imperatives and resulta-tives.2.4 Converting SemXTAG to RTGAs shown in (Schmitz and Le Roux, 2008), anFTAG can be converted to a Regular Tree Gram-mar describing its derivation tree.
In this section,we briefly sketch this conversion process.
For amore precise description of this FTAG to RTGconversion, the reader is referred to (Schmitz andLe Roux, 2008).1Cx/Cx abbreviate a node with category C and atop/bottom feature structure including the feature-value pair{ index : x}.368In the FTAG-to-RTG conversion, each SEMX-TAG elementary tree is converted to a rule thatmodels its contribution to a TAG derivation tree.A TAG derivation involves the selection of an ini-tial tree, which has some nodes requiring substi-tution and some permitting adjunction.
Let usthink of the potential adjunction sites as requiring,rather than permitting, adjunction, but such thatthe requirement can be satisfied by ?null?
adjunc-tion.
Inserting another tree into this initial tree sat-isfies one of the substitution or adjunction require-ments, but introduces some new requirements intothe resulting tree, in the form of its own substitu-tion nodes and adjunction sites.Thus, intuitively, the RTG representation of aSEMXTAG elementary tree is a rule that rewritesthe satisfied requirement as a local tree whose rootis a unique identifier of the tree and whose leavesare the introduced requirements.
A requirementof a substitution or adjunction of a tree of rootcategory X is written as XS or XA, respectively.Here, for example, is the translation to RTG of theFTAG tree (minus semantics) for run in Figure 1,using the word anchoring the tree as its identifier(the upperscripts abbreviates features structures:b/t refers to the bottom/top feature structure andthe upper case letters to the semantic index value,[idx : X] is abbreviated to X):S[t:T ]S ?
runs(S[t:T,b:C]A NP[t:S]S V P[t:C,b:B]A V[t:B,b:A]A )The semantics of the SemXTAG tree are carriedover as-is to the corresponding RTG rule.
Fur-ther, the feature structures labelling the nodes ofthe SemXTAG tree are converted into the RTGrules so as to correctly interact with substitutionand adjunction (see (Schmitz and Le Roux, 2008)for more details on this part of the conversion pro-cess).To account for the optionality of adjunction,there are additional rules allowing any adjunctionrequirement to be rewritten as the symbol ?, a ter-minal symbol of the RTG.The terminal symbols of the RTG are thus thetree identifiers and the symbol ?, and its non-terminals are XS and XA for each terminal ornon-terminal X of SemXTAG.3 TAG-based surface realisationWe now present RTGEN and describe GENI, andcompare the optimisations they propose to dealwith the task complexity.GENI and RTGEN are similar on several points.They use the same grammar, namely SEMXTAG(cf.
Section 2).
Further, they both pipeline threemain steps.
First, lexical selection selects fromthe grammar those elementary trees whose seman-tics subsumes part of the input semantics.
Second,the tree combining phase systematically tries tocombine trees using substitution and adjunction.Third, the retrieval phase extracts the yields ofthe complete derived trees, thereby producing thegenerated sentence(s).GENI and RTGEN differ however with respectto the trees they are working with (derived treesin GENI vs derivation trees in RTGEN).
They alsodiffer in how tree combination is handled.
We nowdescribe these differences in more detail and ex-plain how each approach address the complexityissue.3.1 GenIThe tree combining phase in GENI falls into twomain steps namely, filtering and tree combining.Filtering.
The so-called polarity filtering stepaims to reduce the initial search space.
It elim-inates from the initial search space all those setsof TAG elementary trees which cover the input se-mantics but cannot possibly lead to a valid derivedtree.
In specific, this filtering removes all tree setscovering the input semantics such that either thecategory of a substitution node cannot be canceledout by that of the root node of a different tree;or a root node fails to have a matching substitu-tion site.
Importantly, this filtering relies solelyon categorial information ?
feature information isnot used.
Furthermore, auxiliary trees have no im-pact on filtering since they provide and require thesame category thereby being ?polarity neutral el-ements?.Tree combining.
The tree combining algorithmused after filtering has taken place, is a bottom-uptabular algorithm (Kay, 1996) optimised for TAGs.This step, unlike the first, uses all the features369present in the grammar.
To handle intersectivemodifiers, the delayed modifiers insertion strategyfrom (Carroll et al, 1999) is adapted to TAG asfollows.
First, all possible derived trees are ob-tained using only substitution.
Next, adjunctionis applied.
Although the number of intermediatestructures generated is still 2n for n modifiers, thisstrategy has the effect of blocking these 2n struc-tures from multiplying out with other structures inthe chart.3.2 RTGenRTGen synthesises different techniques that havebeen observed in the past to improve surface re-alisation runtimes.
We first describe these tech-niques i.e., the main features of RTGEN.
Wethen present three alternative ways of implement-ing RTGEN which will be compared in the evalu-ation.3.2.1 RTGen?s main featuresA main feature of RTGEN is that it focuses onbuilding derivation rather than derived trees.
Morespecifically, the first two steps of the surface real-isation process (lexical selection, tree combining)manipulate RTG rules describing the contributionof the SEMXTAG elementary trees to the deriva-tion tree rather than the elementary tree them-selves.
The derived trees needed to produce actualsentences are only produced in the last phase i.e.,the retrieval phase.This strategy is inspired from a similar ap-proach described in (Koller and Striegnitz, 2002)which was shown to be competitive with state ofthe art realisers on a small sample of example in-put chosen for their inherent complexity.
(Kollerand Striegnitz, 2002)?s approach combines treesusing a constraint based dependency parser ratherthan an Earley algorithm so that it is difficultto assess how much of the efficiency is due tothe parser and how much to the grammar con-version.
Intuitively however, the motivation un-derlying the construction of a derivation ratherthan a derived tree is that efficiency might be in-creased because the context free derivation trees(i) are simpler than the mildly context sensitivetrees generated by an FTAG and (ii) permit draw-ing on efficient parsing and surface realisation al-gorithms designed for such grammars.Second, RTGEN makes use of the now standardsemantic criteria proposed in (Kay, 1996; Carrollet al, 1999) to reduce the number of combinationstried out by the realiser.
On the one hand, two con-stituents are combined by the algorithm?s infer-ence rules only if they cover disjoint parts of theinput semantics.
On the other hand, the seman-tic indices present in both the input formula andthe lexically retrieved RTG trees are used to pre-vent the generation of intermediate structures thatare not compatible with the input semantics.
Forinstance, given the input formula for ?John likesMary?, semantic indices will block the generationof ?likes John?
because this constituent requiresthat the constituent for ?John?
fills the patient slotof ?likes?
whereas the input semantics requiresthat it fills the agent slot.
In addition, chart itemsin RTGEN are indexed by semantic indices to ef-ficiently select chart items for combination.Third, RTGEN implements a standard Earleyalgorithm complete with sharing and packing.Sharing allows for intermediate structures that arecommon to several derivations to be representedonly once ?
in addition to not being recomputedeach time.
Packing means that partial derivationtrees with identical semantic coverage and similarcombinatorics (same number and type of substi-tution and adjunction requirements) are groupedtogether and that only one representative of suchgroups is stored in the chart.
In this way, interme-diate structures covering the same set of intersec-tive modifiers in a different order are only repre-sented once and the negative impact of intersec-tive modifiers is lessened (cf.
(Brew, 1992)).
.
As(Carroll and Oepen, 2005) have shown, packingand sharing are important factors in improving ef-ficiency.
In particular, they show that an algorithmwith packing and sharing clearly outtperforms thesame algorithm without packing and sharing giv-ing an up to 50 times speed-up for inputs withlarge numbers of realizations.3.2.2 Three ways to implement RTGenDepending on how much linguistic information(i.e.
feature constraints from the feature struc-tures) is preserved in the RTG rules, several RT-GEN configurations can be tried out which each370reflect a different division of labour between con-straint solving and structure building.
To experi-ment with these several configurations, we exploitthe fact that the FTAG-to-RTG conversion proce-dure developed by Sylvain Schmitz permits spec-ifying which features should be preserved by theconversion.RTGen-all.
In this configuration, all the featurestructure information present in the SEMXTAG el-ementary trees is carried over to the RTG rules.As a result, tree combining and constraint solvingproceed simultaneously and the generated parseforest contains the derivation trees of all the out-put sentences.RTGen-level0.
In the RTGen-level0 configura-tion, only the syntactic category and the seman-tic features are preserved by the conversion.
Asa result, the grammar information used by the(derivation) tree building phase is comparable tothat used by GENI filtering step.
In both cases,the aim is to detect those sets of elementary treeswhich cover the input semantics and such that allsyntactic requirements are satisfied while no syn-tactic resource is left out.
A further step is addi-tionally needed to produce only those trees whichcan be built from these tree sets when applying theconstraints imposed by other features.
In GENI,this additional step is carried out by the tree com-bining phase, in RTGEN, it is realised by the ex-traction phase i.e., the phase that constructs thederived trees from the derivation trees producedby the tree combining phase.RTGen-selective.
Contrary to parsing, surfacerealisation only accesses the morphological lex-icon last i.e., after sentence trees are built.
Be-cause throughout the tree combining phase, lem-mas are handled rather than forms, much of themorpho-syntactic feature information which isnecessary to block the construction of ill-formedconstituents is simply not available.
It is thereforemeaningful to only include in the tree combiningphase those features whose value is available attree combining time.
In a third experiment, we au-tomatically identified those features from the ob-served feature structure unification failures duringruns of the realisation algorithm.
We then use onlythese features (in combination with the semanticfeatures and with categorial information) duringtree combining.4 EvaluationTo evaluate the impact of the different optimisa-tion techniques discussed in the previous section,we use two benchmarks generated automaticallyfrom SEMXTAG (Gottesman, 2009).The first benchmark (MODIFIERS) was de-signed to test the realisers on cases involving in-tersective modifiers.
It includes 1 789 input for-mulae with a varying number (from 0 to 4 modifi-cations), type (N and VP modifications) and distri-bution of intersective modifiers (n modifiers dis-tributed differently over the predicate argumentstructures).
For instance, the formula in (1) in-volves 2 N and 1 VP modification.
Further,it combines lexical ambiguity with modificationcomplexities, i.e.
for the snore modifier the gram-mar provides 10 trees.
(1) l1 : ?
(x1, hr, hs), hr ?
l2, hs ?
l3, l2 :man(x1), l2 : snoring(e1, x1), l2 : big(x1), l3 :sleep(e2, x1), l4 : soundly(e2)(A snoring big man sleeps soundly)The second benchmark (COMPLEXITY) wasdesigned to test overall performance on cases ofdiffering complexity (input formulae of increas-ing length, involving verbs with a various numberand types of arguments and with a varying num-ber of and types of modifiers).
It contains 890 dis-tinct cases.
A sample formula extracted from thisbenchmark is shown in (2), which includes onemodification and to different verb types.
(2) h1 ?
l4, l0 : want(e, h1), l1 : ?
(x1, hr, hs), hr ?l1, hs ?
l0, l1 : man(x1), l1 : snoring(e1, x1), l3 :?
(x2, hp, hw , hu), hp ?
l3, hw ?
l4, hu ?
l5, l3 :monkey(x2), l4 : eat(e2, x2, e3), l5 : sleep(e3, x2)(The snoring man wants the monkey to sleep)To evaluate GENI and the various configurationsof RTGEN (RTGEN-all, RTGEN-level0, RTGEN-selective), we ran the 4 algorithms in batch modeon the two benchmarks and collected the follow-ing data for each test case:?
Packed chart size : the number of chart itemsbuilt.
This feature is only aplicable to RTGenas GENI does not implement packing.371?
Unpacked chart size : the number of interme-diate and final structures available after un-packing (or at the end of the tree combiningprocess in the case of GENI).?
Initial Search Space (ISS) : the number of allpossible combinations of elementary trees tobe explored given the result of lexical selec-tion on the input semantics.
That is, the prod-uct of the number of FTAG elementary treesselected by each literal in the input seman-tics.?
Generation forest (GF) : the number ofderivation trees covering the input semantics.The graph in Figure 2 shows the differences be-tween the different strategies with respect to theunpacked chart size metric.A first observation is that RTGEN-all outper-forms GENI in terms of intermediate structuresbuilt .
In other words, the Earley sharing andpacking strategy is more effective in reducing thenumber of constituents built than the filtering andsubstitution-before-adjunction optimisations usedby GENI.
In fact, even when no feature informa-tion is used at all (RTGEN-level0 plot), for morecomplex test cases, packing and sharing is moreeffective in reducing the chart size than filteringand operation ordering.Another interesting observation is that RTGEN-all and RTGEN-selective have the same impact onchart size (their plots coincide).
This is unsurpris-ing since the features used by RTGEN-selectivehave been selected based on their ability to blockconstituent combination.
The features used inRTGEN-selective mode are wh, xp, assign-comp,mode, definite, inv, assign-case, rel-clause,extracted and phon, in addition to the categorialand semantic information.
In other words, usingall 42 SEMXTAG grammar features has the sameimpact on search space pruning as using only asmall subset of them.
As explained in the previ-ous section, this is probably due to the fact thatcontrary to parsing, surface realisation only ac-cesses the morphological lexicon after tree com-bining takes place.
Another possibility is that thegrammar is under constrained and that feature val-ues are missing thereby inducing overgeneration.Zooming in on cases involving three modifiers,0 1 2 3 4 5 6 7103104ppppppnumber of modifiersunpackedchartsizeRTGEN-allRTGEN-level0p RTGEN-selectiveGENIFigure 2: Performance of realisation approacheson the MODIFIERS benchmark, average unpackedchart size as a function of the number of modifiers.we show in Table 1 the average results for variousefficiency metrics 2.
This provides a more detailview of the performance of the differences amongthe three RTGEN variants.strategy GF chart unpacked-chart secondsRTGen-all 15.05 918.31 2,538.98 0.99RTGen-level0 1,118.06 2,018 6,898.28 1.41RTGen-selective 27.08 910.34 2,531.23 0.44Table 1: Average results on 610 test cases fromthe MODIFIERS benchmark.
Each test case has3 modifications, distributed in various ways be-tween adjectival and adverbial modifications.
Thesecond column, Generation Forest (GF), is thenumber of derivation trees present in the gener-ated parse forest.
The third and fourth columnsshow the chart and unpacked chart sizes, respec-tively.
The last column shows the runtime in sec-onds.This data shows that running RTGEN with nofeature information leads not only to an increasedchart size but also to runtimes that are higher inaverage than for full surface realisation i.e., reali-sation using the full grammar complete with con-2The two realisers being implemented in differentprogramming languages (RTGEN uses Prolog and GENIHaskell), runtimes comparisons are not necessarily verymeaningful.
Additionally, GENI does not provide time statis-tics.
After adding this functionality to GENI, we found thatoverall GENI is faster on simple cases but slower on morecomplex ones.
We are currently working on optimising RT-GEN prolog implementation before carrying out a full scaleruntime comparison.3720-100100-10001000-50005000-1000010000-100000100000-500000500000-1000000morethan1000000102103104105106pp pp pp p pInitial Search Space (ISS) sizeunpackedchartsizeRTGEN-allRTGEN-level0p RTGEN-selectiveGENIFigure 3: Performance of realisation approacheson the COMPLEXITY benchmark, average un-packed chart size as a function of the ISS com-plexity.straints.Interestingly, it also shows that the selectivemode (RTGEN-selective) permits improving run-times while achieving almost perfect disambigua-tion in that the average number of derivation trees(GF) produced is close to that produced whenusing all features.
The differences between thetwo generation forests stems from packing.
Usingonly a subset of features favors packing, therebyreducing the number of chart items built, but in-troduces over- generation.Graph 3 and Table 2 confirm the results ob-tained using the MODIFIERS benchmark on a test-set (COMPLEXITY) where input complexity variesnot only with respect to modification but also withrespect to the length of the input and to the de-gree of lexical ambiguity.
Typically, in a TAG, oneword or one semantic literal may be associated ei-ther with one tree or with up to several hundredtrees (e.g., ditransitive verbs and verbs with sev-eral subcategorisation types).
By varying the typeand the number of verbs selected by the seman-tic literals contained in the input semantics, theCOMPLEXITY benchmark provides a more exten-sive way to test performance on cases of varyingcomplexity.strategy GF chart unpacked-chart secondsRTGen-all 14.77 693.39 2,427.82 0.81RTGen-level0 162.02 2,114.16 6,954.84 1.09RTGen-selective 15.31 692.9 2,427.2 0.36Table 2: Average results on 335 cases with10000 < ISS ?
100000, from the COMPLEXITYbenchmark.
The columns show the same perfor-mance metrics as in Table 1.5 Related workMuch work has already been done on optimisingsurface realisation.
Because surface realisationoften draws on parsing techniques, work on pars-ing optimisation is also relevant.
In this section,we briefly relate our proposal to another gram-mar converting approach (Koller and Striegnitz,2002); to another chart based approach (Carrolland Oepen, 2005); and to approaches based onstatistical pruning (White, 2004; Bangalore andRambow, 2000).5.1 Optimising surface realisationEncoding into another grammatical formalism.As already mentioned, the RTGEN approach isclosely related to the work of (Koller and Strieg-nitz, 2002) where the XTAG grammar is con-verted to a dependency grammar capturing itsderivation trees.
This conversion enables the useof a constraint based dependency parser, a parserwhich was specifically developed for the efficientparsing of free word order languages and is shownto support an efficient handling of both lexical andmodifier attachment ambiguity.Our proposal differs from this approach in threemain ways.
First, contrary to XTAG, SEMX-TAG integrates a full-fledged, unification basedcompositional semantics thereby allowing for aprincipled coupling between semantic represen-tations and natural language expressions.
Sec-ond, the grammar conversion and the feature-based RTGs used by RTGEN accurately trans-lates the full range of unification mechanisms em-ployed in FTAG wheras the conversion describedby (Koller and Striegnitz, 2002) does not takeinto account feature structure information.
Third,the RTGEN approach was extensively tested on alarge benchmark using 3 different configurationswhilst (Koller and Striegnitz, 2002) results are re-373stricted to a few hand constructed example inputs.Chart generation algorithm optimisations.
(Carroll and Oepen, 2005) provides an extensiveand detailed study of how various techniques usedto optimise parsing and surface realisation impactthe efficiency of a surface realiser based on a largecoverage Head-Driven Phrase Structure grammar.Because they use different grammars, gram-mar formalisms and different benchmarks, it isdifficult to compare the RTGEN and the HPSGapproach.
However, one point is put forwardby (Carroll and Oepen, 2005) which it wouldbe interesting to integrate in RTGEN(Carroll andOepen, 2005) show that for packing to be effi-cient, it is important that equivalence be checkedthrough subsumption, not through equality.
RT-GEN also implements a packing mechanism withsubsumption check, i.e.
different ways of cov-ering the same subset of the input semantics aregrouped together and represented in the chart bythe most general one.
One difference however itthat RTGEN will pack analyses together as longas the new ones are more specific cases.
It willnot go backwards to recalculate the packing madeso far if a more general item is found (Stefan andJohn, 2000).
In this case the algorithm will packthem under two different groups.Statistical pruning.
Various probabilistic tech-niques have been proposed in surface realisationto improve e.g., lexical selection, the handling ofintersective modifiers or ranking.
For instance,(Bangalore and Rambow, 2000) uses a tree modelto produce a single most probable lexical selec-tion while in White?s system, the best paraphraseis determined on the basis of n-gram scores.
Fur-ther, to address the fact that there are n!
waysto combine any n modifiers with a single con-stituent, (White, 2004) proposes to use a languagemodel to prune the chart of identical edges rep-resenting different modifier permutations, e.g., tochoose between fierce black cat and black fiercecat.
Similarly, (Bangalore and Rambow, 2000) as-sumes a single derivation tree that encodes a wordlattice (a {fierce black, black fierce} cat), and usesstatistical knowledge to select the best linearisa-tion.
Our approach differs from these approachesin that lexical selection is not filtered, intersectivemodifiers are handled by the grammar (constraintson the respective order of adjectives) and the chartpacking strategy (for optimisation), and ranking isnot performed.
We are currently exploring the useof Optimality Theory for ranking.6 ConclusionWe presented RTGEN, a novel surface realiser forFTAG grammars which builds on the observationthat an FTAG can be translated to a regular treegrammar describing its derivation trees.
Usingautomatically constructed benchmarks, we com-pared the performance of this realiser with that ofGENI, another state of the art realiser for FTAG.We showed that RTGEN outperforms GENI interms of space i.e.
that the Earley sharing andpacking strategy is more effective in reducing thenumber of constituents built than the filtering andsubstitution-before-adjunction optimisations usedby GENI.
Moreover, we investigated three waysof interleaving phrase structure and feature struc-ture constraints and showed that, given a naiveconstraint solving approach, the interleaving ap-proach with selective features seems to providethe best space/runtimes compromise.Future work will concentrate on further investi-gating the interplay in surface realisation betweenphrase structure and feature structure constraints.In particular, (Maxwell and Kaplan, 1994) showsthat a more sophisticated approach to constraintsolving and to its interaction with chart process-ing renders the non interleaved approach more ef-fective than the interleaved one.
We plan to exam-ine whether this observation applies to SEMXTAGand RTGEN.
Further, we intend to integrate Op-timality Theory constraints in RTGEN so as sup-port ranking of multiple outputs.
Finally, we wantto further optimise RTGEN on intersective modi-fiers using one the methods mentioned in Section5.ReferencesBangalore, S. and O. Rambow.
2000.
Using TAGs, atree model and a language model for generation.
InProceedings of TAG+5, Paris, France.Brew, Chris.
1992.
Letting the cat out of the bag:generation for shake-and-bake mt.
In Proceedings374of the 14th conference on Computational linguistics,pages 610?616, Morristown, NJ, USA.
Associationfor Computational Linguistics.Carroll, J. and S. Oepen.
2005.
High efficiency re-alization for a wide-coverage unification grammar.2nd IJCNLP.Carroll, J., A. Copestake, D. Flickinger, andV.
Paznan?ski.
1999.
An efficient chart generatorfor (semi-)lexicalist grammars.
In Proceedings ofEWNLG ?99.Gardent, C. and L. Kallmeyer.
2003.
Semantic con-struction in FTAG.
In 10th EACL, Budapest, Hun-gary.Gardent, C. and E. Kow.
2007.
Spotting overgenera-tion suspect.
In 11th European Workshop on Natu-ral Language Generation (ENLG).Gottesman, B.
2009.
Generating examples.
Mas-ter?s thesis, Erasmus Mundus Master Language andCommunication Technology, Saarbrucken/Nancy.Kay, Martin.
1996.
Chart generation.
In Proceedingsof the 34th annual meeting on Association for Com-putational Linguistics, pages 200?204, Morristown,NJ, USA.
Association for Computational Linguis-tics.Koller, A. and K. Striegnitz.
2002.
Generation as de-pendency parsing.
In Proceedings of the 40th ACL,Philadelphia.Maxwell, J. and R. Kaplan.
1994.
The interface be-tween phrasal and functional constraints.
Computa-tional Linguistics, 19(4).Perez-Beltrachini, L. 2009.
Using regular treegrammars to reduce the search space in surfacerealisation.
Master?s thesis, Erasmus MundusMaster Language and Communication Technology,Nancy/Bolzano.Schmitz, S. and J.
Le Roux.
2008.
Feature uni-fication in TAG derivation trees.
In Gardent, C.and A. Sarkar, editors, Proceedings of the 9th In-ternational Workshop on Tree Adjoining Grammarsand Related Formalisms (TAG+?08), pages 141?148, Tu?bingen, Germany.Stefan, Oepen and Carroll John.
2000.
Parser engi-neering and performance profiling.
Journal of Nat-ural Language Engineering, 6(1):81?98.The XTAG Research Group.
2001.
A lexicalised treeadjoining grammar for english.
Technical report,Institute for Research in Cognitive Science, Univer-sity of Pennsylvannia.Vijay-Shanker, K. and AK Joshi.
1988.
Feature Struc-tures Based Tree Adjoining Grammars.
Proceed-ings of the 12th conference on Computational lin-guistics, 55:v2.White, M. 2004.
Reining in CCG chart realization.
InINLG, pages 182?191.375
