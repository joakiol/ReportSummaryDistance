Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 653?662,Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational LinguisticsPhrase-Based Translation Model for Question Retrieval in CommunityQuestion Answer ArchivesGuangyou Zhou, Li Cai, Jun Zhao?, and Kang LiuNational Laboratory of Pattern RecognitionInstitute of Automation, Chinese Academy of Sciences95 Zhongguancun East Road, Beijing 100190, China{gyzhou,lcai,jzhao,kliu}@nlpr.ia.ac.cnAbstractCommunity-based question answer (Q&A)has become an important issue due to the pop-ularity of Q&A archives on the web.
This pa-per is concerned with the problem of ques-tion retrieval.
Question retrieval in Q&Aarchives aims to find historical questions thatare semantically equivalent or relevant to thequeried questions.
In this paper, we proposea novel phrase-based translation model forquestion retrieval.
Compared to the traditionalword-based translation models, the phrase-based translation model is more effective be-cause it captures contextual information inmodeling the translation of phrases as a whole,rather than translating single words in isola-tion.
Experiments conducted on real Q&Adata demonstrate that our proposed phrase-based translation model significantly outper-forms the state-of-the-art word-based transla-tion model.1 IntroductionOver the past few years, large scale question andanswer (Q&A) archives have become an importantinformation resource on the Web.
These includethe traditional Frequently Asked Questions (FAQ)archives and the emerging community-based Q&Aservices, such as Yahoo!
Answers1, Live QnA2, andBaidu Zhidao3.
?Correspondence author: jzhao@nlpr.ia.ac.cn1http://answers.yahoo.com/2http://qna.live.com/3http://zhidao.baidu.com/Community-based Q&A services can directly re-turn answers to the queried questions instead of alist of relevant documents, thus provide an effectivealternative to the traditional adhoc information re-trieval.
To make full use of the large scale archivesof question-answer pairs, it is critical to have func-tionality helping users to retrieve historical answers(Duan et al, 2008).
Therefore, it is a meaningfultask to retrieve the questions that are semanticallyequivalent or relevant to the queried questions.
Forexample in Table 1, given questionQ1,Q2 can be re-turned and their answers will then be used to answerQ1 because the answer ofQ2 is expected to partiallysatisfy the queried question Q1.
This is what wecalled question retrieval in this paper.The major challenge for Q&A retrieval, as forQuery:Q1: How to get rid of stuffy nose?Expected:Q2: What is the best way to prevent a cold?Not Expected:Q3: How do I air out my stuffy room?Q4: How do you make a nose bleed stop quicker?Table 1: An example on question retrievalmost information retrieval models, such as vectorspace model (VSM) (Salton et al, 1975), Okapimodel (Robertson et al, 1994), language model(LM) (Ponte and Croft, 1998), is the lexical gap (orlexical chasm) between the queried questions andthe historical questions in the archives (Jeon et al,2005; Xue et al, 2008).
For example in Table 1, Q1and Q2 are two semantically similar questions, butthey have very few words in common.
This prob-653lem is more serious for Q&A retrieval, since thequestion-answer pairs are usually short and there islittle chance of finding the same content expressedusing different wording (Xue et al, 2008).
To solvethe lexical gap problem, most researchers regardedthe question retrieval task as a statistical machinetranslation problem by using IBM model 1 (Brownet al, 1993) to learn the word-to-word translationprobabilities (Berger and Lafferty, 1999; Jeon et al,2005; Xue et al, 2008; Lee et al, 2008; Bernhardand Gurevych, 2009).
Experiments consistently re-ported that the word-based translation models couldyield better performance than the traditional meth-ods (e.g., VSM.
Okapi and LM).
However, all theseexisting approaches are considered to be context in-dependent in that they do not take into account anycontextual information in modeling word translationprobabilities.
For example in Table 1, although nei-ther of the individual word pair (e.g., ?stuffy?/?cold?and ?nose?/?cold?)
might have a high translationprobability, the sequence of words ?stuffy nose?
canbe easily translated from a single word ?cold?
in Q2with a relative high translation probability.In this paper, we argue that it is beneficial to cap-ture contextual information for question retrieval.To this end, inspired by the phrase-based statisticalmachine translation (SMT) systems (Koehn et al,2003; Och and Ney, 2004), we propose a phrase-based translation model (P-Trans) for question re-trieval, and we assume that question retrieval shouldbe performed at the phrase level.
This model learnsthe probability of translating one sequence of words(e.g., phrase) into another sequence of words, e.g.,translating a phrase in a historical question into an-other phrase in a queried question.
Compared to thetraditional word-based translation models that ac-count for translating single words in isolation, thephrase-based translation model is potentially moreeffective because it captures some contextual infor-mation in modeling the translation of phrases as awhole.
More precise translation can be determinedfor phrases than for words.
It is thus reasonable toexpect that using such phrase translation probabili-ties as ranking features is likely to improve the ques-tion retrieval performance, as we will show in ourexperiments.Unlike the general natural language translation,the parallel sentences between questions and an-swers in community-based Q&A have very differentlengths, leaving many words in answers unalignedto any word in queried questions.
Following (Bergerand Lafferty, 1999), we restrict our attention to thosephrase translations consistent with a good word-level alignment.Specifically, we make the following contribu-tions:?
we formulate the question retrieval task as aphrase-based translation problem by modelingthe contextual information (in Section 3.1).?
we linearly combine the phrase-based transla-tion model for the question part and answer part(in Section 3.2).?
we propose a linear ranking model frameworkfor question retrieval in which different modelsare incorporated as features because the phrase-based translation model cannot be interpolatedwith a unigram language model (in Section3.3).?
finally, we conduct the experiments oncommunity-based Q&A data for question re-trieval.
The results show that our proposed ap-proach significantly outperforms the baselinemethods (in Section 4).The remainder of this paper is organized as fol-lows.
Section 2 introduces the existing state-of-the-art methods.
Section 3 describes our phrase-basedtranslation model for question retrieval.
Section 4presents the experimental results.
In Section 5, weconclude with ideas for future research.2 Preliminaries2.1 Language ModelThe unigram language model has been widely usedfor question retrieval on community-based Q&Adata (Jeon et al, 2005; Xue et al, 2008; Cao et al,2010).
To avoid zero probability, we use Jelinek-Mercer smoothing (Zhai and Lafferty, 2001) due toits good performance and cheap computational cost.So the ranking function for the query likelihood lan-guage model with Jelinek-Mercer smoothing can be654written as:Score(q, D) =?w?q(1 ?
?
)Pml(w|D) + ?Pml(w|C)(1)Pml(w|D) =#(w,D)|D|, Pml(w|C) =#(w,C)|C|(2)where q is the queried question, D is a document, Cis background collection, ?
is smoothing parameter.#(t,D) is the frequency of term t in D, |D| and |C|denote the length of D and C respectively.2.2 Word-Based Translation ModelPrevious work (Berger et al, 2000; Jeon et al, 2005;Xue et al, 2008) consistently reported that the word-based translation models (Trans) yielded better per-formance than the traditional methods (VSM, Okapiand LM) for question retrieval.
These models ex-ploit the word translation probabilities in a languagemodeling framework.
Following Jeon et al (2005)and Xue et al (2008), the ranking function can bewritten as:Score(q, D) =?w?q(1??
)Ptr(w|D)+?Pml(w|C) (3)Ptr(w|D) =?t?DP (w|t)Pml(t|D), Pml(t|D) =#(t,D)|D|(4)where P (w|t) denotes the translation probabilityfrom word t to word w.2.3 Word-Based Translation Language ModelXue et al (2008) proposed to linearly mix two dif-ferent estimations by combining language modeland word-based translation model into a unifiedframework, called TransLM.
The experiments showthat this model gains better performance than boththe language model and the word-based translationmodel.
Following Xue et al (2008), this model canbe written as:Score(q, D) =?w?q(1 ?
?
)Pmx(w|D) + ?Pml(w|C)(5)Pmx(w|D) = ?
?t?DP (w|t)Pml(t|D)+(1??
)Pml(w|D)(6)D:                      ?
for good cold home remedies ?
documentE:                  [for,    good,    cold,    home remedies] segmentationF:            [for1,    best2,    stuffy nose3,    home remedy4] translationM:                     (1?3?2?1?3?4?4?2) permutationq:                     best home remedy for stuffy nose queried questionFigure 1: Example describing the generative procedureof the phrase-based translation model.3 Our Approach: Phrase-BasedTranslation Model for QuestionRetrieval3.1 Phrase-Based Translation ModelPhrase-based machine translation models (Koehnet al, 2003; D. Chiang, 2005; Och and Ney,2004) have shown superior performance comparedto word-based translation models.
In this paper,the goal of phrase-based translation model is totranslate a document4 D into a queried questionq.
Rather than translating single words in isola-tion, the phrase-based model translates one sequenceof words into another sequence of words, thus in-corporating contextual information.
For example,we might learn that the phrase ?stuffy nose?
can betranslated from ?cold?
with relative high probabil-ity, even though neither of the individual word pairs(e.g., ?stuffy?/?cold?
and ?nose?/?cold?)
might havea high word translation probability.
Inspired by thework of (Sun et al, 2010; Gao et al, 2010), weassume the following generative process: first thedocument D is broken into K non-empty word se-quences t1, .
.
.
, tK , then each t is translated into anew non-empty word sequence w1, .
.
.
,wK , and fi-nally these phrases are permutated and concatenatedto form the queried questions q, where t and w de-note the phrases or consecutive sequence of words.To formulate this generative process, let Edenote the segmentation of D into K phrasest1, .
.
.
, tK , and let F denote the K translationphrases w1, .
.
.
,wK ?we refer to these (ti,wi)pairs as bi-phrases.
Finally, letM denote a permuta-tion of K elements representing the final reorderingstep.
Figure 1 describes an example of the genera-tive procedure.Next let us place a probability distribution overrewrite pairs.
Let B(D,q) denote the set of E,4In this paper, a document has the same meaning as a histor-ical question-answer pair in the Q&A archives.655F , M triples that translate D into q.
Here we as-sume a uniform probability over segmentations, sothe phrase-based translation model can be formu-lated as:P (q|D) ??
(E,F,M)?B(D,q)P (F |D,E) ?
P (M |D,E, F ) (7)As is common practice in SMT, we use the maxi-mum approximation to the sum:P (q|D) ?
max(E,F,M)?B(D,q)P (F |D,E) ?
P (M |D,E, F ) (8)Although we have defined a generative model fortranslatingD into q, our goal is to calculate the rank-ing score function over existing q andD, rather thangenerating new queried questions.
Equation (8) can-not be used directly for document ranking becauseq and D are often of very different lengths, leav-ing many words in D unaligned to any word in q.This is the key difference between the community-based question retrieval and the general natural lan-guage translation.
As pointed out by Berger and Laf-ferty (1999) and Gao et al (2010), document-querytranslation requires a distillation of the document,while translation of natural language tolerates littlebeing thrown away.Thus we attempt to extract the key documentwords that form the distillation of the document, andassume that a queried question is translated onlyfrom the key document words.
In this paper, thekey document words are identified via word align-ment.
We introduce the ?hidden alignments?
A =a1 .
.
.
aj .
.
.
aJ , which describe the mapping from aword position j in queried question to a documentword position i = aj .
The different alignment mod-els we present provide different decompositions ofP (q, A|D).
We assume that the position of the keydocument words are determined by the Viterbi align-ment, which can be obtained using IBM model 1 asfollows:A?
= argmaxAP (q, A|D)= argmaxA{P (J |I)J?j=1P (wj |taj )}=[argmaxajP (wj |taj )]Jj=1(9)Given A?, when scoring a given Q&A pair, we re-strict our attention to those E, F , M triples that areconsistent with A?, which we denote as B(D,q, A?
).Here, consistency requires that if two words arealigned in A?, then they must appear in the same bi-phrase (ti,wi).
Once the word alignment is fixed,the final permutation is uniquely determined, so wecan safely discard that factor.
Thus equation (8) canbe written as:P (q|D) ?
max(E,F,M)?B(D,q,A?
)P (F |D,E) (10)For the sole remaining factor P (F |D,E), wemake the assumption that a segmented queried ques-tion F = w1, .
.
.
,wK is generated from left toright by translating each phrase t1, .
.
.
, tK indepen-dently:P (F |D,E) =K?k=1P (wk|tk) (11)where P (wk|tk) is a phrase translation probability,the estimation will be described in Section 3.3.To find the maximum probability assignment ef-ficiently, we use a dynamic programming approach,somewhat similar to the monotone decoding algo-rithm described in (Och, 2002).
We define ?j tobe the probability of the most likely sequence ofphrases covering the first j words in a queried ques-tion, then the probability can be calculated using thefollowing recursion:(1) Initialization:?0 = 1 (12)(2) Induction:?j =?j?<j,w=wj?+1...wj{?j?P (w|tw)}(13)(3) Total:P (q|D) = ?J (14)3.2 Phrase-Based Translation Model forQuestion Part and Answer PartIn Q&A, a document D is decomposed into (q?, a?
),where q?
denotes the question part of the historicalquestion in the archives and a?
denotes the answerpart.
Although it has been shown that doing Q&Aretrieval based solely on the answer part does notperform well (Jeon et al, 2005; Xue et al, 2008),the answer part should provide additional evidenceabout relevance and, therefore, it should be com-bined with the estimation based on the question part.656In this combined model, P (q|q?)
and P (q|a?)
are cal-culated with equations (12) to (14).
So P (q|D) willbe written as:P (q|D) = ?1P (q|q?)
+ ?2P (q|a?)
(15)where ?1 + ?2 = 1.In equation (15), the relative importance of ques-tion part and answer part is adjusted through ?1 and?2.
When ?1 = 1, the retrieval model is basedon phrase-based translation model for the questionpart.
When ?2 = 1, the retrieval model is based onphrase-based translation model for the answer part.3.3 Parameter Estimation3.3.1 Parallel Corpus CollectionIn Q&A archives, question-answer pairs can be con-sidered as a type of parallel corpus, which is used forestimating the translation probabilities.
Unlike thebilingual machine translation, the questions and an-swers in a Q&A archive are written in the same lan-guage, the translation probability can be calculatedthrough setting either as the source and the other asthe target.
In this paper, P (a?|q?)
is used to denotethe translation probability with the question as thesource and the answer as the target.
P (q?|a?)
is usedto denote the opposite configuration.For a given word or phrase, the related wordsor phrases differ when it appears in the ques-tion or in the answer.
Following Xue etal.
(2008), a pooling strategy is adopted.
First,we pool the question-answer pairs used to learnP (a?|q?)
and the answer-question pairs used tolearn P (q?|a?
), and then use IBM model 1 (Brownet al, 1993) to learn the combined translationprobabilities.
Suppose we use the collection{(q?, a?
)1, .
.
.
, (q?, a?
)m} to learn P (a?|q?)
and use thecollection {(a?, q?
)1, .
.
.
, (a?, q?
)m} to learn P (q?|a?
),then {(q?, a?
)1, .
.
.
, (q?, a?
)m, (a?, q?
)1, .
.
.
, (a?, q?
)m} isused here to learn the combination translation prob-ability Ppool(wi|tj).3.3.2 Parallel Corpus PreprocessingUnlike the bilingual parallel corpus used in SMT,our parallel corpus is collected from Q&A archives,which is more noisy.
Directly using the IBM model1 can be problematic, it is possible for translationmodel to contain ?unnecessary?
translations (Lee etal., 2008).
In this paper, we adopt a variant of Tex-tRank algorithm (Mihalcea and Tarau, 2004) to iden-tify and eliminate unimportant words from parallelcorpus, assuming that a word in a question or an-swer is unimportant if it holds a relatively low sig-nificance in the parallel corpus.Following (Lee et al, 2008), the ranking algo-rithm proceeds as follows.
First, all the words ina given document are added as vertices in a graphG.
Then edges are added between words if thewords co-occur in a fixed-sized window.
The num-ber of co-occurrences becomes the weight of anedge.
When the graph is constructed, the score ofeach vertex is initialized as 1, and the PageRank-based ranking algorithm is run on the graph itera-tively until convergence.
The TextRank score of aword w in document D at kth iteration is defined asfollows:Rkw,D = (1?
d) + d ???j:(i,j)?Gei,j?
?l:(j,l)?G ej,lRk?1w,D(16)where d is a damping factor usually set to 0.85, andei,j is an edge weight between i and j.We use average TextRank score as threshold:words are removed if their scores are lower than theaverage score of all words in a document.3.3.3 Translation Probability EstimationAfter preprocessing the parallel corpus, we will cal-culate P (w|t), following the method commonlyused in SMT (Koehn et al, 2003; Och, 2002) to ex-tract bi-phrases and estimate their translation proba-bilities.First, we learn the word-to-word translation prob-ability using IBM model 1 (Brown et al, 1993).Then, we perform Viterbi word alignment accordingto equation (9).
Finally, the bi-phrases that are con-sistent with the word alignment are extracted usingthe heuristics proposed in (Och, 2002).
We set themaximum phrase length to five in our experiments.After gathering all such bi-phrases from the train-ing data, we can estimate conditional relative fre-quency estimates without smoothing:P (w|t) = N(t,w)N(t)(17)where N(t,w) is the number of times that t isaligned to w in training data.
These estimates are657source stuffy nose internet explorer1 stuffy nose internet explorer2 cold ie3 stuffy internet browser4 sore throat explorer5 sneeze browserTable 2: Phrase translation probability examples.
Eachcolumn shows the top 5 target phrases learned from theword-aligned question-answer pairs.useful for contextual lexical selection with sufficienttraining data, but can be subject to data sparsity is-sues (Sun et al, 2010; Gao et al, 2010).
An alter-nate translation probability estimate not subject todata sparsity is the so-called lexical weight estimate(Koehn et al, 2003).
Let P (w|t) be the word-to-word translation probability, and let A be the wordalignment between w and t. Here, the word align-ment contains (i, j) pairs, where i ?
1 .
.
.
|w| andj ?
0 .
.
.
|t|, with 0 indicating a null word.
Then weuse the following estimate:Pt(w|t, A) =|w|?i=11|{j|(j, i) ?
A}|??
(i,j)?AP (wi|tj)(18)We assume that for each position inw, there is ei-ther a single alignment to 0, or multiple alignmentsto non-zero positions in t. In fact, equation (18)computes a product of per-word translation scores;the per-word scores are the averages of all the trans-lations for the alignment links of that word.
Theword translation probabilities are calculated usingIBM 1, which has been widely used for question re-trieval (Jeon et al, 2005; Xue et al, 2008; Lee et al,2008; Bernhard and Gurevych, 2009).
These word-based scores of bi-phrases, though not as effectivein contextual selection, are more robust to noise andsparsity.A sample of the resulting phrase translation ex-amples is shown in Table 2, where the top 5 targetphrases are translated from the source phrases ac-cording to the phrase-based translation model.
Forexample, the term ?explorer?
used alone, most likelyrefers to a person who engages in scientific explo-ration, while the phrase ?internet explorer?
has avery different meaning.3.4 Ranking Candidate Historical QuestionsUnlike the word-based translation models, thephrase-based translation model cannot be interpo-lated with a unigram language model.
Following(Sun et al, 2010; Gao et al, 2010), we resort toa linear ranking framework for question retrieval inwhich different models are incorporated as features.We consider learning a relevance function of thefollowing general, linear form:Score(q, D) = ?T ??
(q, D) (19)where the feature vector ?
(q, D) is an arbitraryfunction that maps (q, D) to a real value, i.e.,?
(q, D) ?
R. ?
is the corresponding weight vec-tor, we optimize this parameter for our evaluationmetrics directly using the Powell Search algorithm(Paul et al, 1992) via cross-validation.The features used in this paper are as follows:?
Phrase translation features (PT):?PT (q, D,A) = logP (q|D), where P (q|D)is computed using equations (12) to (15), andthe phrase translation probability P (w|t) isestimated using equation (17).?
Inverted Phrase translation features (IPT):?IPT (D,q, A) = logP (D|q), where P (D|q)is computed using equations (12) to (15) ex-cept that we set ?2 = 0 in equation (15), andthe phrase translation probability P (w|t) is es-timated using equation (17).?
Lexical weight feature (LW):?LW (q, D,A) = logP (q|D), here P (q|D)is computed by equations (12) to (15), and thephrase translation probability is computed aslexical weight according to equation (18).?
Inverted Lexical weight feature (ILW):?ILW (D,q, A) = logP (D|q), here P (D|q)is computed by equations (12) to (15) exceptthat we set ?2 = 0 in equation (15), and thephrase translation probability is computed aslexical weight according to equation (18).?
Phrase alignment features (PA):?PA(q, D,B) =?K2 |ak ?
bk?1 ?
1|,where B is a set of K bi-phrases, ak is the startposition of the phrase in D that was translated658into the kth phrase in queried question, andbk?1 is the end position of the phrase in Dthat was translated into the (k ?
1)th phrase inqueried question.
The feature, inspired by thedistortion model in SMT (Koehn et al, 2003),models the degree to which the queried phrasesare reordered.
For all possible B, we onlycompute the feature value according to theViterbi alignment, B?
= argmaxB P (q, B|D).We find B?
using the Viterbi algorithm, which isalmost identical to the dynamic programmingrecursion of equations (12) to (14), except thatthe sum operator in equation (13) is replacedwith the max operator.?
Unaligned word penalty features (UWP):?UWP (q, D), which is defined as the ratio be-tween the number of unaligned words and thetotal number of words in queried questions.?
Language model features (LM):?LM (q, D,A) = logPLM (q|D), wherePLM (q|D) is the unigram language modelwith Jelinek-Mercer smoothing defined byequations (1) and (2).?
Word translation features (WT):?WT (q, D) = logP (q|D), where P (q|D) isthe word-based translation model defined byequations (3) and (4).4 Experiments4.1 Data Set and Evaluation MetricsWe collect the questions from Yahoo!
Answers anduse the getByCategory function provided in Yahoo!Answers API5 to obtain Q&A threads from the Ya-hoo!
site.
More specifically, we utilize the resolvedquestions under the top-level category at Yahoo!Answers, namely ?Computers & Internet?.
The re-sulting question repository that we use for questionretrieval contains 518,492 questions.
To learn thetranslation probabilities, we use about one millionquestion-answer pairs from another data set.6In order to create the test set, we randomly se-lect 300 questions for this category, denoted as5http://developer.yahoo.com/answers6The Yahoo!
Webscope dataset Yahoo answers com-prehensive questions and answers version 1.0.2, available athttp://reseach.yahoo.com/Academic Relations.
?CI TST?.
To obtain the ground-truth of ques-tion retrieval, we employ the Vector Space Model(VSM) (Salton et al, 1975) to retrieve the top 20 re-sults and obtain manual judgements.
The top 20 re-sults don?t include the queried question itself.
Givena returned result by VSM, an annotator is asked tolabel it with ?relevant?
or ?irrelevant?.
If a returnedresult is considered semantically equivalent to thequeried question, the annotator will label it as ?rel-evant?
; otherwise, the annotator will label it as ?ir-relevant?.
Two annotators are involved in the anno-tation process.
If a conflict happens, a third personwill make judgement for the final result.
In the pro-cess of manually judging questions, the annotatorsare presented only the questions.
Table 3 providesthe statistics on the final test set.#queries #returned #relevantCI TST 300 6,000 798Table 3: Statistics on the Test DataWe evaluate the performance of our approach us-ing Mean Average Precision (MAP).
We performa significant test, i.e., a t-test with a default signif-icant level of 0.05.
Following the literature, we setthe parameters ?
= 0.2 (Cao et al, 2010) in equa-tions (1), (3) and (5), and ?
= 0.8 (Xue et al, 2008)in equation (6).4.2 Question Retrieval ResultsWe randomly divide the test questions into fivesubsets and conduct 5-fold cross-validation experi-ments.
In each trial, we tune the parameters ?1 and?2 with four of the five subsets and then apply it toone remaining subset.
The experiments reported be-low are those averaged over the five trials.Table 4 presents the main retrieval performance.Row 1 to row 3 are baseline systems, all these meth-ods use word-based translation models and obtainthe state-of-the-art performance in previous work(Jeon et al, 2005; Xue et al, 2008).
Row 3 is simi-lar to row 2, the only difference is that TransLM onlyconsiders the question part, while Xue et al (2008)incorporates the question part and answer part.
Row4 and row 5 are our proposed phrase-based trans-lation model with maximum phrase length of five.Row 4 is phrase-based translation model purelybased on question part, this model is equivalent to659# Methods Trans Prob MAP1 Jeon et al (2005) Ppool 0.2892 TransLM Ppool 0.3243 Xue et al (2008) Ppool 0.3524 P-Trans (?1 = 1, l = 5) Ppool 0.3665 P-Trans (l = 5) Ppool 0.391Table 4: Comparison with different methods for questionretrieval.setting ?1 = 1 in equation (15).
Row 5 is the phrase-based combination model which linearly combinesthe question part and answer part.
As expected,different parts can play different roles: a phrase tobe translated in queried questions may be translatedfrom the question part or answer part.
All thesemethods use pooling strategy to estimate the transla-tion probabilities.
There are some clear trends in theresult of Table 4:(1) Word-based translation language model(TransLM) significantly outperforms word-basedtranslation model of Jeon et al (2005) (row 1 vs. row2).
Similar observations have been made by Xue etal.
(2008).
(2) Incorporating the answer part into the models,either word-based or phrase-based, can significantlyimprove the performance of question retrieval (row2 vs. row 3; row 4 vs. row 5).
(3) Our proposed phrase-based translation model(P-Trans) significantly outperforms the state-of-the-art word-based translation models (row 2 vs. row 4and row 3 vs. row 5, all these comparisons are sta-tistically significant at p < 0.05).4.3 Impact of Phrase LengthOur proposed phrase-based translation model, due toits capability of capturing contextual information, ismore effective than the state-of-the-art word-basedtranslation models.
It is important to investigate theimpact of the phrase length on the final retrieval per-formance.
Table 5 shows the results, it is seen thatusing the longer phrases up to the maximum lengthof five can consistently improve the retrieval per-formance.
However, using much longer phrases inthe phrase-based translation model does not seem toproduce significantly better performance (row 8 androw 9 vs. row 10 are not statistically significant).# Systems MAP6 P-Trans (l = 1) 0.3527 P-Trans (l = 2) 0.3738 P-Trans (l = 3) 0.3869 P-Trans (l = 4) 0.39010 P-Trans (l = 5) 0.391Table 5: The impact of the phrase length on retrieval per-formance.Model # Methods Average MAPP-Trans (l = 5) 11 Initial 69 0.38012 TextRank 24 0.391Table 6: Effectiveness of parallel corpus preprocessing.4.4 Effectiveness of Parallel CorpusPreprocessingQuestion-answer pairs collected from Yahoo!
an-swers are very noisy, it is possible for translationmodels to contain ?unnecessary?
translations.
In thispaper, we attempt to identify and decrease the pro-portion of unnecessary translations in a translationmodel by using TextRank algorithm.
This kind of?unnecessary?
translation between words will even-tually affect the bi-phrase translation.Table 6 shows the effectiveness of parallel corpuspreprocessing.
Row 11 reports the average numberof translations per word and the question retrievalperformance when only stopwords 7 are removed.When using the TextRank algorithm for parallel cor-pus preprocessing, the average number of transla-tions per word is reduced from 69 to 24, but theperformance of question retrieval is significantly im-proved (row 11 vs. row 12).
Similar results havebeen made by Lee et al (2008).4.5 Impact of Pooling StrategyThe correspondence of words or phrases in thequestion-answer pair is not as strong as in the bilin-gual sentence pair, thus noise will be inevitably in-troduced for both P (a?|q?)
and P (q?|a?
).To see how much the pooling strategy benefit thequestion retrieval, we introduce two baseline meth-ods for comparison.
The first method (denoted asP (a?|q?))
is used to denote the translation probabil-ity with the question as the source and the answer as7http://truereader.com/manuals/onix/stopwords1.html660Model # Trans Prob MAPP-Trans (l = 5)13 P (a?|q?)
0.38714 P (q?|a?)
0.38115 Ppool 0.391Table 7: The impact of pooling strategy for question re-trieval.the target.
The second (denoted as P (a?|q?))
is usedto denote the translation probability with the answeras the source and the question as the target.
Table 7provides the comparison.
From this Table, we seethat the pooling strategy significantly outperformsthe two baseline methods for question retrieval (row13 and row 14 vs. row 15).5 Conclusions and Future WorkIn this paper, we propose a novel phrase-based trans-lation model for question retrieval.
Compared tothe traditional word-based translation models, theproposed approach is more effective in that it cancapture contextual information instead of translatingsingle words in isolation.
Experiments conductedon real Q&A data demonstrate that the phrase-based translation model significantly outperformsthe state-of-the-art word-based translation models.There are some ways in which this research couldbe continued.
First, question structure should beconsidered, so it is necessary to combine the pro-posed approach with other question retrieval meth-ods (e.g., (Duan et al, 2008; Wang et al, 2009;Bunescu and Huang, 2010)) to further improve theperformance.
Second, we will try to investigate theuse of the proposed approach for other kinds of dataset, such as categorized questions from forum sitesand FAQ sites.AcknowledgmentsThis work was supported by the National NaturalScience Foundation of China (No.
60875041 andNo.
61070106).
We thank the anonymous reviewersfor their insightful comments.
We also thank MaoxiLi and Jiajun Zhang for suggestion to use the align-ment toolkits.ReferencesA.
Berger and R. Caruana and D. Cohn and D. Freitag andV.
Mittal.
2000.
Bridging the lexical chasm: statisticalapproach to answer-finding.
In Proceedings of SIGIR,pages 192-199.A.
Berger and J. Lafferty.
1999.
Information retrieval asstatistical translation.
In Proceedings of SIGIR, pages222-229.D.
Bernhard and I. Gurevych.
2009.
Combining lexicalsemantic resources with question & answer archivesfor translation-based answer finding.
In Proceedingsof ACL, pages 728-736.P.
F. Brown and V. J. D. Pietra and S. A. D. Pietra andR.
L. Mercer.
1993.
The mathematics of statisticalmachine translation: parameter estimation.
Computa-tional Linguistics, 19(2):263-311.R.
Bunescu and Y. Huang.
2010.
Learning the relativeusefulness of questions in community QA.
In Pro-ceedings of EMNLP, pages 97-107.X.
Cao and G. Cong and B. Cui and C. S. Jensen.
2010.A generalized framework of exploring category infor-mation for question retrieval in community questionanswer archives.
In Proceedings of WWW.D.
Chiang.
2005.
A hierarchical phrase-based model forstatistical machine translation.
In Proceedings of ACL.H.
Duan and Y. Cao and C. Y. Lin and Y. Yu.
2008.Searching questions by identifying questions topicsand question focus.
In Proceedings of ACL, pages156-164.J.
Gao and X.
He and J. Nie.
2010.
Clickthrough-basedtranslation models for web search: from word modelsto phrase models.
In Proceedings of CIKM.J.
Jeon and W. Bruce Croft and J. H. Lee.
2005.
Find-ing similar questions in large question and answerarchives.
In Proceedings of CIKM, pages 84-90.R.
Mihalcea and P. Tarau.
2004.
TextRank: Bringingorder into text.
In Proceedings of EMNLP, pages 404-411.P.
Koehn and F. Och and D. Marcu.
2003.
Statisticalphrase-based translation.
In Proceedings of NAACL,pages 48-54.J.
-T. Lee and S. -B. Kim and Y.
-I.
Song and H. -C. Rim.2008.
Bridging lexical gaps between queries and ques-tions on large online Q&A collections with compacttranslation models.
In Proceedings of EMNLP, pages410-418.F.
Och.
2002.
Statistical mahcine translation: from sin-gle word models to alignment templates.
Ph.D thesis,RWTH Aachen.F.
Och and H. Ney.
2004.
The alignment template ap-proach to statistical machine translation.
Computa-tional Linguistics, 30(4):417-449.661J.
M. Ponte and W. B. Croft.
1998.
A language modelingapproach to information retrieval.
In Proceedings ofSIGIR.W.
H. Press and S. A. Teukolsky and W. T. Vetterlingand B. P. Flannery.
1992.
Numerical Recipes In C.Cambridge Univ.
Press.S.
Robertson and S. Walker and S. Jones and M.Hancock-Beaulieu and M. Gatford.
1994.
Okapi attrec-3.
In Proceedings of TREC, pages 109-126.G.
Salton and A. Wong and C. S. Yang.
1975.
A vectorspace model for automatic indexing.
Communicationsof the ACM, 18(11):613-620.X.
Sun and J. Gao and D. Micol and C. Quirk.
2010.Learning phrase-based spelling error models fromclickthrough data.
In Proceedings of ACL.K.
Wang and Z. Ming and T-S. Chua.
2009.
A syntactictree matching approach to finding similar questions incommunity-based qa services.
In Proceedings of SI-GIR, pages 187-194.X.
Xue and J. Jeon and W. B. Croft.
2008.
Retrievalmodels for question and answer archives.
In Proceed-ings of SIGIR, pages 475-482.C.
Zhai and J. Lafferty.
2001.
A study of smooth meth-ods for language models applied to ad hoc informationretrieval.
In Proceedings of SIGIR, pages 334-342.662
