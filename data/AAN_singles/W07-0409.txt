Proceedings of SSST, NAACL-HLT 2007 / AMTA Workshop on Syntax and Structure in Statistical Translation, pages 65?71,Rochester, New York, April 2007. c?2007 Association for Computational LinguisticsCombining Morphosyntactic Enriched Representation withn-best Reranking in Statistical TranslationH.
Bonneau-Maynard, A. Allauzen, D. De?chelotte and H. SchwenkSpoken Language Processing GroupLIMSI-CNRS, BP 13391403 Orsay cedex, FRANCE{maynard,allauzen,dechelot,schwenk}@limsi.frAbstractThe purpose of this work is to explorethe integration of morphosyntactic infor-mation into the translation model itself, byenriching words with their morphosyntac-tic categories.
We investigate word dis-ambiguation using morphosyntactic cate-gories, n-best hypotheses reranking, andthe combination of both methods withword or morphosyntactic n-gram lan-guage model reranking.
Experimentsare carried out on the English-to-Spanishtranslation task.
Using the morphosyn-tactic language model alone does notresults in any improvement in perfor-mance.
However, combining morphosyn-tactic word disambiguation with a wordbased 4-gram language model results in arelative improvement in the BLEU scoreof 2.3% on the development set and 1.9%on the test set.1 IntroductionRecent works in statistical machine translation(SMT) shows how phrase-based modeling (Och andNey, 2000a; Koehn et al, 2003) significantly out-perform the historical word-based modeling (Brownet al, 1993).
Using phrases, i.e.
sequences ofwords, as translation units allows the system to pre-serve local word order constraints and to improvethe consistency of phrases during the translation pro-cess.
Phrase-based models provide some sort ofcontext information as opposed to word-based mod-els.
Training a phrase-based model typically re-quires aligning a parallel corpus, extracting phrasesand scoring them using word and phrase counts.
Thederived statistics capture the structure of natural lan-guage to some extent, including implicit syntacticand semantic relations.The output of a SMT system may be difficult tounderstand by humans, requiring re-ordering wordsto recover its syntactic structure.
Modeling languagegeneration as a word-based Markovian source (an n-gram language model) discards linguistic propertiessuch as long term word dependency and word-orderor phrase-order syntactic constraints.
Therefore, ex-plicit introduction of structure in the language mod-els becomes a major and promising focus of atten-tion.However, as of today, it seems difficult to outper-form a 4-gram word language model.
Several stud-ies have attempted to use morphosyntactic informa-tion (also known as part-of-speech or POS informa-tion) to improve translation.
(Och et al, 2004) haveexplored many different feature functions.
Rerank-ing n-best lists using POS has also been explored by(Hasan et al, 2006).
In (Kirchhoff and Yang, 2005),a factored language model using POS informationshowed similar performance to a 4-gram word lan-guage model.
Syntax-based language models havealso been investigated in (Charniak et al, 2003).
Allthese studies use word phrases as translation unitsand POS information in just a post-processing step.This paper explores the integration of morphosyn-tactic information into the translation model itselfby enriching words with their morphosyntactic cat-65egories.
The same idea has already been appliedin (Hwang et al, 2007) to the Basic Travel Ex-pression Corpus (BTEC).
To our knowledge, thisapproach has not been evaluated on a large real-word translation problem.
We report results onthe TC-STAR task (public European Parliament Ple-nary Sessions translation).
Furthermore, we pro-pose to combine this approach with classical n-bestlist reranking.
Experiments are carried out on theEnglish-to-Spanish task using a system based on thepublicly available Moses decoder.This paper is organized as follows: In Section2 we first describe the baseline statistical machinetranslation systems.
Section 3 presents the consid-ered task and the processing of the corpora.
Theexperimental evaluation is summarized in section 4.The paper concludes with a discussion of future re-search directions.2 System DescriptionThe goal of statistical machine translation is to pro-duce a target sentence e from a source sentence f .Among all possible target language sentences theone with the highest probability is chosen.
The useof a maximum entropy approach simplifies the intro-duction of several additional models explaining thetranslation process:e?
= argmaxPr(e|f)= argmaxe {exp(?i?ihi(e, f))} (1)where the feature functions hi are the systemmodels characterizing the translation process, andthe coefficients ?i act as weights.2.1 Moses decoderMoses1 is an open-source, state-of-the-art phrase-based decoder.
It implements an efficient beam-search algorithm.
Scripts are also provided to train aphrase-based model.
The popular Giza++ (Och andNey, 2000b) tool is used to align the parallel corpora.The baseline system uses 8 feature functions hi,namely phrase translation probabilities in both di-rections, lexical translation probabilities in both di-rections, a distortion feature, a word and a phrase1http://www.statmt.org/moses/penalty and a trigram target language model.
Ad-ditional features can be added, as described in thefollowing sections.
The weights ?i are typically op-timized so as to maximize a scoring function on adevelopment set (Och and Ney, 2002).The moses decoder can output n-best lists, pro-ducing either distinct target sentences or not (asdifferent segmentations may lead to the same sen-tence).
In this work, distinct sentences were alwaysused.These n-best lists can be rescored using higherorder language models (word- or syntactic-based).There are two ways to carry out the rescoring: one,by replacing the language model score or by addinga new feature function; two, by performing a log-linear interpolation of the language model used fordecoding and the new language model.
This latterapproach was used in all the experiments describedin this paper.
The set of weights is systematicallyre-optimized using the algorithm presented below.2.2 Weight optimizationA common criterion to optimize the coefficients ofthe log-linear combination of feature functions is tomaximize the BLEU score (Papineni et al, 2002)on a development set (Och and Ney, 2002).
Forthis purpose, the public numerical optimization toolCondor (Berghen and Bersini, 2005) is integrated inthe following iterative algorithm:0.
Using good general purpose weights, theMoses decoder is used to generate 1000-bestlists.1.
The 1000-best lists are reranked using the cur-rent set of weights.2.
The current hypothesis is extracted and scored.3.
This BLEU score is passed to Condor, whicheither computes a new set of weights (the al-gorithm then proceeds to step 1) or detects thata local maxima has been reached and the algo-rithm stops iterating.The solution is usually found after about 100 itera-tions.
It is stressed that the n-best lists are generatedonly once and that the whole tuning operates onlyon the n-best lists.66English: IPP declareV V P resumedV V D theDT sessionNN ofIN theDT EuropeanNP ParliamentNPSpanish: declaroV Lfin reanudadoV Ladj elART perodoNC dePREP sesionesNCdelPDEL ParlamentoNC EuropeoADJFigure 1: Example of POS-tag enriched bi-text used to train the translation models2.3 POS disambiguationIt is well-known that syntactic structures varygreatly across languages.
Spanish, for example,can be considered as a highly inflectional language,whereas inflection plays only a marginal role in En-glish.POS language models can be used to rerank thetranslation hypothesis, but this requires tagging then-best lists generated by the SMT system.
This canbe difficult since POS taggers are not well suited forill-formed or incorrect sentences.
Finding a methodin which morphosyntactic information is used di-rectly in the translation model could help overcomethis drawback but also takes account for the syntac-tic specificities of both source and target languages.It seems likely that the morphosyntactic informa-tion of each word will be useful to encode linguis-tic characteristics, resulting in a sort of word disam-biguation by considering its morphosyntactic cate-gory.
Therefore, in this work we investigate a trans-lation model which enriches every word with its syn-tactic category.
The enriched translation units are acombination of the original word and the POS tag, asshown in Figure 1.
The translation system takes a se-quence of enriched units as inputs and outputs.
Thisimplies that the test data must be POS tagged beforetranslation.
Likewise, the POS tags in the enrichedoutput are removed at the end of the process to pro-vide the final translation hypothesis which containonly a word sequence.
This approach also allowsto carry out a n-best reranking step using either aword-based or a POS-based language model.3 Task, corpus and toolsThe experimental results reported in this article wereobtained in the framework of an international evalu-ation organized by the European TC-STAR project2in February 2006.
This project is envisaged as a2http://www.tc-star.org/long-term effort to advance research in all core tech-nologies for speech-to-speech translation.The main goal of this evaluation is to trans-late public European Parliament Plenary Sessions(EPPS).
The training material consists of the sum-mary edited by the European Parliament in severallanguages, which is also known as the Final TextEditions (Gollan et al, 2005).
These texts werealigned at the sentence level and they are used totrain the statistical translation models (see Table 1for some statistics).Spanish EnglishWhole parallel corpusSentence Pairs 1.2MTotal # Words 34.1M 32.7MVocabulary size 129k 74kSentence length ?
40Sentence Pairs 0.91MTotal # Words 18.5M 18.0MWord vocabulary 104k 71kPOS vocabulary 69 59Enriched units vocab.
115k 77.6kTable 1: Statistics of the parallel texts used to trainthe statistical machine translation system.Three different conditions are considered in theTC-STAR evaluation: translation of the Final TextEdition (text), translation of the transcriptions of theacoustic development data (verbatim) and transla-tion of speech recognizer output (ASR).
Here weonly consider the verbatim condition, translatingfrom English to Spanish.
For this task, the develop-ment and test data consists of about 30k words.
Thetest data is partially collected in the Spanish parlia-ment.
This results in a small mismatch between de-velopment and test data.
Two reference translationsare provided.
The scoring is case sensitive and in-cludes punctuation symbols.673.1 Text normalizationThe training data used for normalization differs sig-nificantly from the development and test data.
TheFinal Text Edition corpus follows common ortho-graphic rules (for instance, the first letter of the wordfollowing a full stop or a column is capitalized) andrepresents most of the dates, quantities, article refer-ences and other numbers in digits.
Thus the text hadto be ?true-cased?
and all numbers were verbalizedusing in-house language-specific tools.
Numbers arenot tagged as such at this stage; this is entirely leftto the POS tagger.3.2 Translation model training corpusLong sentences (more than 40 words) greatly slowdown the training process, especially at the align-ment step with Giza++.
As shown in Figure 2, thehistogram of the length of Spanish sentences in thetraining corpus decreases steadily after a length of20 to 25 words, and English sentences exhibit a sim-ilar behavior.
Suppressing long sentences from thecorpus reduces the number of aligned sentences byroughly 25% (see Table 1) but speeds the wholetraining procedure by a factor of 3.
The impact onperformance is discussed in the next section.050001000015000200002500030000350000  10  20  30  40  50  60  70  80  90  100Histogram of Spanish sentences?
lengths (training set)Figure 2: Histogram of the sentence length (Spanishpart of the parallel corpus).3.3 Language model training corpusIn the experiments reported below, a trigram wordlanguage model is used during decoding.
Thismodel is trained on the Spanish part of the parallelcorpus using only sentences shorter than 40 words(total of 18.5M of language model training data).Second pass language models were trained on allavailable monolingual data (34.1M words).3.4 ToolsPOS tagging was performed with the TreeTagger(Schmid, 1994).
This software provides resourcesfor both of the considered languages and it is freelyavailable.
TreeTagger is a Markovian tagger thatuses decision trees to estimate trigram transitionprobabilities.
The English version is trained on thePENN treebank corpus3 and the Spanish version onthe CRATER corpus.4Language models are built using the SRI-LMtoolkit (Stolcke, 2002).
Modified Knesser-Ney dis-counting was used for all models.
In (Goodman,2001), a systematic description and comparison ofthe usual smoothing methods is reported.
ModifiedKnesser-Ney discounting appears to be the most ef-ficient method.4 Experiments and ResultsTwo baseline English-to-Spanish translation mod-els were created with Moses.
The first model wastrained on the whole parallel text ?
note that sen-tences with more than 100 words are excluded byGiza++.
The second model was trained on the cor-pus using only sentences with at most 40 words.
TheBLEU score on the development set using good gen-eral purpose weights is 48.0 for the first model and47.0 for the second.
Because training on the wholebi-text is much slower, we decided to perform ourexperiments on the bi-texts restricted to the ?short?sentences.4.1 Language model generationThe reranking experiments presented below use thefollowing language models trained on the Spanishpart of the whole training corpus:?
word language models,?
POS language model,?
POS language model, with a stop list used toremove the 100 most frequent words (POS-stop100 LM),?
language model of enriched units.3http://www.cis.upenn.edu/ treebank4http://www.comp.lancs.ac.uk/linguistics/crater/corpus.html68English : you will be aware President that over the last few sessions in Strasbourg.
..Baseline: usted sabe que el Presidente durante los u?ltimos sesiones en Estrasburgo ...Enriched units: usted sabe que el Presidente en los u?ltimos per?
?odos de sesiones en Estrasburgo ...English : ... in this house there might be some recognition ...Baseline: ... en esta asamblea no puede ser un cierto reconocimiento ...Enriched units: ... en esta asamblea existe un cierto reconocimiento ...Figure 3: Comparative translations using the baseline word system and the enriched unit system.For each of these four models, various orderswere tested (n = 3, 4, 5), but in this paper we onlyreport those orders that yielded the greatest improve-ments.
POS language models were obtained by firstextracting POS sequences from the previously POS-tagged training corpus and then by estimating stan-dard back-off language models.As shown in Table 1, the vocabulary size of theword language model is 104k for Spanish and 74kfor English.
The number of POS is small: 69 forSpanish and 59 for English.
We emphasize thatthe tagset provided by TreeTagger does include nei-ther gender nor number distinction.
The vocabularysize of the enriched-unit language model is 115k forSpanish and 77.6k for English.
The syntactical am-biguity of words is low: the mean ambiguity ratio is1.14 for Spanish and 1.12 for English.4.2 Reranking the word n-best listsThe results concerning reranking experiments of then-best lists provided by the translation model basedon words as units are summarized in Table 2.
Thebaseline result, with trigram word LM reranking,gives a BLEU score of 47.0 (1rst row).
From then-best lists provided by this translation model, wecompared reranking performances with different tar-get language models.
As observed in the literature,an improvement can be obtained by reranking witha 4-gram word language model (47.0 ?
47.5, 2drow).
By post-tagging this n-best list, a POS lan-guage model reranking can be performed.
However,reranking with a 5-gram POS language model alonedoes not give any improvement from the baseline(BLEU score of 46.9, 3rd row).
This result corre-sponds to known work in the literature (Kirchhoffand Yang, 2005; Hasan et al, 2006), when usingPOS only as a post-processing step during rerank-ing.
As suggested in section 2.3, this lack of per-formance can be due to the fact that the tagger isnot able to provide a usefull tagging of sentencesincluded in the n-best lists.
This observation isalso available when reranking of the word n-best isdone with a language model based on enriched units(BLEU score of 47.6, not reported in Table 2).4.3 POS disambiguation and rerankingThe results concerning reranking experiments of then-best lists provided by the translation model basedon enriched units are summarized in Table 3.
Us-ing a trigram language model of enriched transla-tion units leads to a BLEU score of 47.4, a 0.4 in-crease over the baseline presented in section 4.2.Figure 3 shows comparative translation examplesfrom the baseline and the enriched translation sys-tems.
In the first example, the baseline system out-puts ?durante los u?ltimos sesiones?
where the en-riched translation system produces ?en los u?ltimosper?
?odos de sesiones?, a better translation that maybe attributed to the introduction of the masculineword ?per?
?odos?, allowing the system to build asyntactically correct sentence.
In the second exam-ple, the syntactical error ?no puede ser un cierto re-conocimiento?
produced by the baseline system in-duces an incorrect meaning of the sentence, whereasthe enriched translation system hypothesis ?existe uncierto reconocimiento?
is both syntactically and se-mantically correct.Reranking the enriched n-best with POS languagemodels (either with or without a stop list) does notseem to be efficient (0.3 BLEU increasing with thePOS-stop100 language model).A better improvement is obtained when rerankingis performed with the 4-gram word language model.This results in a BLEU score of 47.9, correspond-ing to a 0.9 improvement over the word baseline.
Itis interesting to observe that reranking a n-best list69Dev.
Test3g word LM baseline 47.0 46.04g word LM reranking 47.5 46.55g POS reranking 46.9 46.1Table 2: BLEU scores using words as translationunits.obtained with a translation model based on enrichedunits with a word LM results in better performancesthan a enriched units LM reranking of a n-best listobtained with a translation model based on words.The last two rows of Table 3 give results whencombining word and POS language models to rerankthe enriched n-best lists.
In both cases, 10 featuresare used for reranking (8 Moses features + wordlanguage model probability + POS language modelprobability).
The best result is obtained by com-bining the 5-gram word language model with the 5-gram POS-stop100 language model.
In that case,the best BLEU score is observed (48.1), with a 2.3%relative increase over the trigram word baseline.4.4 Results on the test setThe results on the test set are given in the secondcolumn of Tables 2 and 3.
Although the enrichedtranslation system is only 0.1 BLEU over the base-line system (46.0 ?
46.1) when using a trigram lan-guage model, the best condition observed on the de-velopment set (word and POS-stop100 LMs rerank-ing) results in a 46.8 BLEU score, corresponding toa 0.8 increasing.It can be observed that rescoring with a 4-gramword language model leads to same score resultingin a 1.9% relative increase over the trigram wordbaseline.5 Conclusion and future workCombining word language model reranking of n-best lists based on syntactically enriched units seemsto produce more consistent hypotheses.
Using en-riched translation units results in a relative 2.3%improvement in BLEU on the development set and1.9% on the test over the trigram baseline.
Over astandard translation model with 4-gram rescoring,the enriched unit translation model leads to an abso-lute increase in BLEU score of 0.4 both on the devel-opment and the test sets.
These first results are en-Dev.
Test3g enriched units LM baseline 47.4 46.14g enriched units LM reranking 47.8 46.84g word LM reranking 47.9 46.95g POS LM reranking 47.5 46.25g POS-stop100 LM reranking 47.7 46.3word + POS LMs reranking 47.9 46.9word + POS-stop100 LMs rerank.
48.1 46.8Table 3: BLEU scores using enriched translationunits.couraging enough to further investigate the integra-tion of syntactic information in the translation modelitself, rather than to restrict it to the post-processingpass.
As follow-up experiments, it is planned to in-clude gender and number information in the tagset,as well as the word stems to the enriched units.This work should be considered as preliminaryexperiments for the investigation of factored trans-lation models, which Moses is able to handle.
POSfactorization is indeed a way to add some general-ization capability to the enriched translation models.6 AcknowledgmentsThis work has been partially funded by the EuropeanUnion under the integrated project TC-STAR (IST-2002-FP6-506738), and by the French Governmentunder the project INSTAR (ANR JCJC06 143038).We would like to thanks Marc Ferras for his helpconcerning the Spanish language.ReferencesFrank Vanden Berghen and Hugues Bersini.
2005.
CON-DOR, a new parallel, constrained extension of powell?sUOBYQA algorithm: Experimental results and com-parison with the DFO algorithm.
Journal of Computa-tional and Applied Mathematics, 181:157?175.Peter F Brown, Stephen A Della Pietra, Vincent J DellaPietra, and Robert L Mercer.
1993.
The mathematicsof statistical machine translation: Parameter estima-tion.
Computational Linguistics, 19(2):263?311.E.
Charniak, K. Knight, and K. Yamada.
2003.
Syntax-based language models for machine translation.
InProceedings of MT Summit IX.C.
Gollan, M. Bisani, S. Kanthak, R. Schlueter, and ?H.Ney.
2005.
Cross domain automatic transcription on70the TC-STAR epps corpus.
In Proceedings of ICASSP2005.Joshua T. Goodman.
2001.
A bit of progress in lan-guage modeling.
Computer Speech and Language,15(4):403?434, October.S.
Hasan, O. Bender, and H. Ney.
2006.
Reranking trans-lation hypothesis using structural properties.
In Pro-ceedings of EACL 2006.Y.S.
Hwang, A. Finch, and Y. Sasaki.
2007.
Improvingstatistical machine translation using shallow linguisticknoledge.
to be published in Computer, Speech andLanguage.Katrin Kirchhoff and Mei Yang.
2005.
Improved lan-guage modeling for statistical machine translation.
InProceedings of ACL ?05 workshop on Building and Us-ing Parallel Text, pages 125?128.Philipp Koehn, Franz Josef Och, and Daniel Marcu.2003.
Statistical phrase-based translation.
In Proceed-ings of the Human Language Technology Conference2003 (HLT-NAACL 2003), Edmonton, Canada, May.Franz Josef Och and Hermann Ney.
2000a.
Improvedstatistical alignment models.
In Proc.
of the 38th An-nual Meeting of the Association for ComputationalLinguistics, pages 440?447, Hongkong, China, Octo-ber.Franz Josef Och and Hermann Ney.
2000b.
Improvedstatistical alignment models.
In Proceedings of the38th Annual Meeting of the Association for Computa-tional Linguistics, pages 440?447, Hong Kong, China,October.Franz Josef Och and Hermann Ney.
2002.
Discrimina-tive training and maximum entropy models for statisti-cal machine translation.
In Proceedings of ACL 2002,pages 295?302.F.-J.
Och, D. Gildea, S. Khudanpur, A. Sarkar, K. Ya-mada, A. Fraser, S. Kumar, L. Shen, D. Smith, K. Eng,V.
Jain, Z. Jin, and D. Radev.
2004.
A smorgasbord offeatures for statistical machine translation.
In NAACL,pages 161?168.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
Bleu: a method for automatic evalua-tion of machine translation.
In Proceedings of the 40thAnnual Meeting of the Association for ComputationalLinguistics, pages 311?318, University of Pennsylva-nia.Helmut Schmid.
1994.
Probabilistic part-of-speech tag-ging using decision trees.
In Proceedings of Interna-tional Conference on New Methods in Language Pro-cessing, September.Andreas Stolcke.
2002.
SRILM - an extensible languagemodeling toolkit.
In Proceedings of ICSLP, pages II:901?904.71
