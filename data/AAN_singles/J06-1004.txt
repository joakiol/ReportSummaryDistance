Finite-State Registered Automatafor Non-Concatenative MorphologyYael Cohen-Sygal?University of HaifaShuly Wintner?University of HaifaWe introduce finite-state registered automata (FSRAs), a new computational device within theframework of finite-state technology, specifically tailored for implementing non-concatenativemorphological processes.
This model extends and augments existing finite-state techniques,which are presently not optimized for describing this kind of phenomena.
We first define themodel and discuss its mathematical and computational properties.
Then, we provide an extendedregular language whose expressions denote FSRAs.
Finally, we exemplify the utility of the modelby providing several examples of complex morphological and phonological phenomena, which areelegantly implemented with FSRAs.1.
IntroductionFinite-state (FS) technology has been considered adequate for describing the morpho-logical processes of the world?s languages since the pioneering works of Koskenniemi(1983) and Kaplan and Kay (1994).
Several toolboxes provide extended regular expres-sion description languages and compilers of the expressions to finite-state automata(FSAs) and transducers (FSTs) (Karttunen et al 1996; Mohri 1996; van Noord andGerdemann 2001a).
While FS approaches to most natural languages have generally beenvery successful, it is widely recognized that they are less suitable for non-concatenativephenomena; in particular, FS techniques are assumed not to be able to efficiently accountfor the non-concatenative word formation processes that Semitic languages exhibit(Lavie et al 1988).While much of the inflectional morphology of Semitic languages can be ratherstraightforwardly described using concatenation as the primary operation, the mainword formation process in such languages is inherently non-concatenative.
The stan-dard account describes words in Semitic languages as combinations of two morphemes:a root and a pattern.1 The root consists of consonants only, by default three (althoughlonger roots are known).
The pattern is a combination of vowels and, possibly, con-sonants too, with ?slots?
into which the root consonants can be inserted.
Words arecreated by interdigitating roots into patterns: The first consonant of the root is insertedinto the first consonantal slot of the pattern, the second root consonant fills the secondslot, and the third fills the last slot.
After the root combines with the pattern, some?
Department of Computer Science, University of Haifa, 31905 Haifa, Israel.
E-mail: yaelc@cs.haifa.ac.il.?
Department of Computer Science, University of Haifa, 31905 Haifa, Israel.
E-mail: shuly@cs.haifa.ac.il.1 An additional morpheme, vocalization, is used to abstract the pattern further; for the present purposes,this distinction is irrelevant.Submission received: 17 August 2004; revised submission received: 15 June 2005; accepted for publication: 26September 2005.?
2006 Association for Computational LinguisticsComputational Linguistics Volume 32, Number 1Figure 1Na?
?ve FSA with duplicated paths.morpho-phonological alternations take place, which may be non-trivial but are mostlyconcatenative.The major problem that we tackle in this work is medium-distance dependencies,whereby some elements that are related to each other in some deep-level representation(e.g., the consonants of the root) are separated on the surface.
While these phenomenado not lie outside the descriptive power of FS systems, na?
?vely implementing them inexisting finite-state calculi is either impossible or, at best, results in large networks thatare inefficient to process, as the following examples demonstrate.Example 1We begin with a simplified problem, namely accounting for circumfixes.
Consider threeHebrew patterns: haaa, hitaaut, and mia, where the empty boxes indi-cate the slots in the patterns into which the consonants of the roots are inserted.
Hebreworthography2 dictates that these patterns be written ha, htut, and m, re-spectively, i.e., the consonants are inserted into the ??
slots as one unit (i.e., the patternscan be viewed as circumfixes).
An automaton that accepts all the possible combinationsof three-consonant stems and these three circumfixes is illustrated in Figure 1.3 Given rstems and p circumfixes, the number of its states is (2r + 2)p + 2, i.e., increases linearlywith the number of stems and circumfixes.
The number of arcs in this automaton is3rp + 2p, i.e, also O(rp).
Evidently, the three basic different paths that result from thethree circumfixes have the same body, which encodes the stems.
An attempt to avoidthe duplication of paths is represented by the automaton of Figure 2, which accepts thelanguage denoted by the regular expression (ht + h + m)(root)(ut + a + ).
The numberof states here is 2r + 4, i.e., is independent of the number of circumfixes.
The numberof arcs is (3r + 2p), that is, O(r + p), and thus, the complexity of the number of arcs isalso reduced.
Obviously, however, such an automaton over-generates by accepting alsoinvalid words such as mut.
In other words, it ignores the dependencies which holdbetween prefixes and suffixes of the same circumfix.
Since finite-state devices have no2 Many of the vowels are not explicitly depicted in the Hebrew script.3 This is an over-simplified example; in practice, the process of combining roots with patterns is highlyidiosyncratic, like other derivational morphological processes.50Cohen-Sygal and Wintner Non-Concatenative MorphologyFigure 2Over-generating FSA.memory, save for the states, there is no simple and space-efficient way to account forsuch dependencies.Example 2Consider now a representation of Hebrew where all vowels are explicit, e.g., the patternhitae.
Consider also the roots r.g.z, b.$.l, and g.b.r.
The consonants of a given rootare inserted into the ??
slots to obtain bases such as hitragez, hitba$el, and hitgaber.
Thefinite state automaton of Figure 3 is the minimized automaton accepting the language;it has fifteen states.
If the number of three letter roots is r, then a general automatonaccepting the combinations of the roots with this pattern will have 4r + 3 states and 5r +1 arcs.
Notice the duplicated arcs which stem from copying the pattern in the differentpaths.Example 3Another non-concatenative process is reduplication: The process in which a morphemeor part of it is duplicated.
Full reduplication is used as a pluralization process in Malayand Indonesian; partial reduplication is found in Chamorro to indicate intensivity.
Itcan also be found in Hebrew as a diminutive formation of nouns and adjectives:keleb klablab $apan $panpan zaqan zqanqan $axor $xarxardog puppy rabbit bunny beard goatee black darkqatan qtantanlittle tinyLet ?
be a finite alphabet.
The language L = {ww | w ?
??}
is known to betrans-regular, therefore no finite-state automaton accepts it.
However, the languageLn = {ww | w ?
?
?, |w| = n} for some constant n is regular.
Recognizing Ln is a finiteapproximation of the general problem of recognizing L. The length of the words innatural languages can in most cases be bounded by some n ?
N, hence the amountof reduplication in natural languages is practically limited.
Therefore, the descriptivepower of Ln is sufficient for the amount of reduplication in natural languages (byFigure 3FSA for the pattern hitae.51Computational Linguistics Volume 32, Number 1constructing Ln for a small number of different ns).
An automaton that accepts Ln canbe constructed by listing a path for each accepted string (since ?
and n are finite, thenumber of words in Ln is finite).
The main drawback of such an automaton is thegrowth in its size as |?| and n increase: The number of strings in Ln is |?|n.
Thus, finite-state techniques can account for limited reduplication, but the resulting networks arespace-inefficient.As a final, non-linguistic, motivating example, consider the problem of n-bit incre-mentation, introduced by Kornai (1996).Example 4The goal of this example is to construct a transducer over ?
= {0, 1} whose input is a32 bit binary number and whose output is the result of adding 1 to the input.
Atransducer that performs addition by 1 on binary numbers has only 5 states and 12 arcs,4but this transducer is neither sequential nor sequentiable.
The problem is that since theinput is scanned left to right but the carry moves right to left, the output of the first bithas to be delayed, possibly even until the last input bit is scanned.
Thus, for an n-bitbinary incrementor, 2n disjunctions have to be considered, and therefore a minimizedtransducer has to assign a separate state to each combination of bits, resulting in 2nstates and a similar number of transitions.In this work we propose a novel FS model which facilitates the expression ofmedium-distance dependencies such as interdigitation and reduplication in an efficientway.
Our main motivation is theoretical, i.e., reducing the complexity of the numberof states and arcs in the networks; we show that these theoretical contributions resultin practical improvements.
In Section 3 we define the model formally, show that it isequivalent to FSAs and define many closure properties directly.5 We then (Section 4)define a regular expression language for denoting FSRAs.
In Section 5 we provide dedi-cated regular expression operators for some non-concatenative phenomena and exem-plify the usefulness of the model by efficiently accounting for the motivating examples.In Section 6 we extend FSRAs to transducers.
The model is evaluated through an actualimplementation in Section 7.
We conclude with suggestions for future research.2.
Related WorkIn spite of the common view that FS technology is in general inadequate for describingnon-concatenative processes, several works address the above-mentioned problems invarious ways.
We summarize existing approaches in this section.Several works examine the applicability of traditional two-level systems for imple-menting non-concatenative morphology.
Two-Level Morphology was used by Katajaand Koskenniemi (1988) to create a rule system for phonological and morphophonolog-ical alternations in Akkadian, accounting for word inflection and regular verbal deriva-tion.
As this solution effectively defines lexical representations of word-forms, its maindisadvantage is that the final network is the na?
?ve one, suffering from the space com-plexity problems discussed above.
Lavie et al (1988) examine the applicability of Two-4 A complete explanation of the construction can be found in http://www.xrce.xerox.com/competencies/content-analysis/fsCompiler/fsexamples.html#Add1.5 Many of the formal proofs and constructions, especially the ones that are similar to the case of standardFSAs, are suppressed; see Cohen-Sygal (2004) for the complete proofs and constructions.52Cohen-Sygal and Wintner Non-Concatenative MorphologyLevel Morphology to the description of Hebrew Morphology, and in particular to verbinflection.
Their lexicon consists of three parts: verb primary bases (the past tense, thirdperson, singular, masculine), verb prefixes, and verb suffixes.
They attempt to describeHebrew verb inflection as a concatenation of prefix+base+suffix, implementable by theTwo-Level model.
However, they conclude that ?The Two-Level rules are not the naturalway to describe .
.
.
verb inflection process.
The only alternative choice .
.
.
is to keep allbases .
.
.
it seems wasteful to save all the secondary bases of verbs of the same pattern.
?Other works deal with non-concatenative morphology by extending ordinary FSAswithout extending their expressivity.
The traditional two-level model of Koskenniemi(1983) is expanded into n-tape automata by Kiraz (2000), following the insight of Kay(1987) and Kataja and Koskenniemi (1988).
The idea is to use more than two levels ofexpression: The surface level employs one representation, but the lexical form employsmultiple representations (e.g., root, pattern) and therefore can be divided into differentlevels, one for each representation.
Elements that are separated on the surface (such asthe root?s consonants) are adjacent on a particular lexical level.
For example, to describecircumfixation using this model, a 4-tape automaton of the form ?surface, PR pattern,circumfix, stem?
is constructed, so that each word is represented by 4 levels.
The surfacelevel represents the final form of the word.
The PR pattern is the pattern in whichthe stem and the circumfix are combined (P represents the circumfix?s position andR the root letter?s position), e.g., PRRRP.
The circumfix and stem levels represent thecircumfix and the stem respectively.For example, combining the Hebrew stem pqd with the circumfix ht-ut will havethe 4-level representation shown in Figure 4.
Notice that the symbols representing thecircumfix in the PR pattern level (i.e., the occurrences of the symbol ?P?
), the circumfixsymbols in the circumfix level, and the circumfix symbols in the surface level are locatedin correlating places in the different levels.
The same holds for the stem symbols.
Inthis way, it is clear which symbols of the surface word belong to the circumfix, whichbelong to the stem, and how they combine together to create the final form of the word.The 4-tape automaton of Figure 5 accepts all the combinations created by circumfixingroots with the three circumfixes of Example 1.
Each arc is attributed with a quadruplet,consisting of four correlating symbols in the four levels.
Notice that as in FSAs, the pathsencoding the roots are duplicated for each circumfix, so that this automaton is as space-inefficient as ordinary FSAs.
Kiraz (2000) does not discuss the space complexity of thismodel, but the number of states still seems to increase with the number of roots andpatterns.
Moreover, the n-tape model requires specification of dependencies betweensymbols in different levels, which may be non-trivial.Walther (2000a) suggests a solution for describing natural language reduplicationusing finite-state methods.
The idea is to enrich finite-state automata with three newoperations: repeat, skip, and self loops.
Repeat arcs allow moving backwards within astring and thus repeat a part of it (to model reduplication).
Skip arcs allow movingforwards in a string while suppressing the spell out of some of its letters; self loop arcsmodel infixation.
In Walther (2000b), the above technique is used to describe TemiarFigure 44-tape representation for the Hebrew word htpqdut.53Computational Linguistics Volume 32, Number 1Figure 54-tape automaton for circumfixation example.reduplication, but no complexity analysis of the model is given.
Moreover, this tech-nique does not seem to be able to describe interdigitation.Beesley and Karttunen (2000) describe a technique, called compile-replace, forconstructing FSTs, which involves reapplying the regular-expression compiler to itsown output.
The compile-replace algorithm facilitates a compact definition of non-concatenative morphological processes, but since such expressions compile to the na?
?venetworks, no space is saved.
Furthermore, this is a compile-time mechanism rather thana theoretical and mathematically founded solution.Other works extend the FS model by enabling some sort of context-sensitivity.
Blank(1985, 1989) presents a model, called Register Vector Grammar, introducing context-sensitivity by representing the states and transitions of finite-state automata as ternary-valued vectors, which need not be fully specified.
No formal properties of this model arediscussed.
In a similar vein, Kornai (1996) introduces vectorized finite-state automata,where both the states and the transitions are represented by vectors of elements ofa partially ordered set.
The vectors are manipulated by operations of unification andoverwriting.
The vectors need not be fully determined, as some of the elements canbe unknown (free).
In this way information can be moved through the transitions bythe overwriting operation and traversing these transitions can be sanctioned throughthe unification operation.
As one of the examples of the advantages of this model,Kornai (1996) shows it can efficiently solve the problem of 32-bit binary incrementor(Example 4).
Using vectorized finite-state automata, a 32-bit incrementor is constructedwhere first, using overwriting, the input is scanned and stored in the vectors, andthen, using unification, the result is calculated where the carry can be computed fromright to left.
We return to this example in example 6, where we show how our ownmodel can solve it efficiently.
The formalism presented by Kornai (1996) allows asignificant reduction in the network size, but its main disadvantage lies in the factthat it significantly deviates from the standard methodology of developing finite-statedevices, and integration of vectorized automata with standard ones remains a challenge.Moreover, it is unclear how, for a given problem, the corresponding network should beconstructed: Programming with vectorized automata seems to be unnatural, and noregular expression language is provided for them.A more general approach to the design of finite-state machines is introduced byMohri, Pereira, and Riley (2000).
They introduce an object-oriented library for manipu-54Cohen-Sygal and Wintner Non-Concatenative Morphologylating finite-state devices that is based on the algebraic concepts of rational power seriesand semirings.
This approach facilitates a high degree of generality as the algorithmsare defined for the general algebraic notions, which can then be specialized accordingto the needs of the user.
They exemplify the usefulness of this library by showing how tospecialize it for the manipulation of weighted automata and transducers.
Our work canbe seen as another specialization of this general approach, tailored for ideally dealingwith our motivating examples.Several works introduce the notion of registers, whether for solving similar prob-lems or motivated by different considerations.
Krauwer and des Tombe (1981) referto transducers with a finite number of registers when comparing transducers andcontext free grammars with respect to their capabilities to describe languages.
Theysketch a proof showing that such transducers are equivalent to ordinary finite-statetransducers.
However, they never formally define the model and do not discuss itsability to efficiently implement non-concatenative natural languages phenomena.
More-over, they do not show how the closure properties can be implemented directly onthese registered transducers, and do not provide any regular language denoting suchtransducers.Motivated by different considerations, Kaminski and Francez (1994) present a com-putational model which extends finite state automata to the case of infinite alphabets.This model is limited to recognizing only regular languages over infinite alphabetswhile maintaining closure under Kleene star and boolean operations, with the excep-tion of closure under complementation.
The familiar automaton is augmented withregisters, used to store alphabet symbols, whose number is fixed for each automa-ton and can vary from one automaton to another.
The model is designed to dealwith infinite alphabets, and therefore it cannot distinguish between different symbols;it can identify different patterns but cannot distinguish between different symbolsin the pattern as is often needed in natural languages.
Our solution is reminiscentof Kaminski and Francez (1994) in the sense that it augments finite-state automatawith finite memory (registers) in a restricted way, but we avoid the above-mentionedproblem.
In addition, our model supports a register alphabet that differs from thelanguage alphabet, allowing the information stored in the registers to be more mean-ingful.
Moreover, our transition relation is a more simplified extension of the stan-dard one in FSAs, rendering our model a conservative extension of standard FSAsand allowing simple integration of existing networks with networks based on ourmodel.Finally, Beesley (1998) directly addresses medium-distance dependencies betweenseparated morphemes in words.
He proposes a method, called flag diacritics, which addsfeatures to symbols in regular expressions to enforce dependencies between separatedparts of a string.
The dependencies are forced by different kinds of unification actions.In this way, a small amount of finite memory is added, keeping the total size of thenetwork relatively small.
Unfortunately, this method is not formally defined, nor areits mathematical and computational properties proved.
Furthermore, flag diacritics aremanipulated at the level of the extended regular expressions, although it is clear thatthey are compiled into additional memory and operators in the networks themselves.The presentations of Beesley (1998) and Beesley and Karttunen (2003) do not explicatethe implementation of such operators and do not provide an analysis of their com-plexity.
Our approach is similar in spirit, but we provide a complete mathematical andcomputational analysis of such extended networks, including a proof that the modelis indeed regular and constructions of the main closure properties.
We also providededicated regular expression operations for non-concatenative processes and show55Computational Linguistics Volume 32, Number 1how they are compiled into extended networks, thereby accounting for the motivatingexamples.3.
Finite-state Registered AutomataWe define a new model, finite-state registered automata (FSRA), aimed at facilitatingthe expression of various non-concatenative morphological phenomena in an efficientway.
The model augments finite-state automata with finite memory (registers) in arestricted way that saves space but does not add expressivity.
The number of registersis finite, usually small, and eliminates the need to duplicate paths as it enables theautomaton to ?remember?
a finite number of symbols.
In addition to being associatedwith an alphabet symbol, each arc is also associated with an action on the registers.There are two kinds of actions, read and write.
The read action, denoted R, allowstraversing an arc only if a designated register contains a specific symbol.
The writeaction, denoted W, allows traversing an arc while writing a specific symbol into adesignated register.
In this section we define FSRAs and show that they are equivalentto standard FSAs (Section 3.1).
We then directly define several closure operations overFSRAs (Section 3.2) and provide some optimizations in Section 3.3.
We conclude thissection with a discussion of minimization (Section 3.4).3.1 Definitions and ExamplesDefinitionA finite-state registered automaton (FSRA) is a tuple A = ?Q, q0,?,?, n, ?, F?, where: Q is a finite set of states. q0 ?
Q is the initial state. ?
is a finite alphabet (the language alphabet). n ?
N (indicating the number of registers). ?
is a finite alphabet including the symbol ?#?
(the registers alphabet).We use meta-variables ui, vi to range over ?
and u, v to range over ?n. The initial content of the registers is #n, meaning that the initial valueof all the registers is ?empty?. ?
?
Q ?
?
?
{} ?
{R, W} ?
{0, 1, 2, .
.
.
, n ?
1} ?
??
Q is the transitionrelation.
The intuitive meaning of ?
is as follows:?
(s,?, R, i,?, t) ?
?
where i > 0 implies that if A is in state s, the inputsymbol is ?, and the content of the i-th register is ?, then A mayenter state t.?
(s,?, W, i,?, t) ?
?
where i > 0 implies that if A is in state s and theinput symbol is ?, then the content of the i-th register is changedinto ?
(overwriting whatever was there before) and A may enterstate t.?
(s,?, R, 0, #, t) implies that if A is in state s and the input symbol is ?,then A may enter state t. Notice that the content of register number 0is always #.
We use the shorthand notation (s,?, t) for such transitions. F ?
Q is the set of final states.56Cohen-Sygal and Wintner Non-Concatenative MorphologyDefinitionA configuration of A is a pair (q, u), where q ?
Q and u ?
?n (q is the current stateand u represents the registers content).
The set of all configurations of A is denoted byQ c. The pair qc0 = (q0, #n) is called the initial configuration, and configurations with thefirst component in F are called final configurations.
The set of final configurations isdenoted by Fc.DefinitionLet u = u0u1 .
.
.
un?1 and v = v0v1 .
.
.
vn?1.
Given a symbol ?
?
?
?
{} and an FSRAA, we say that a configuration (s, u) produces a configuration (t, v), denoted (s, u)?,A(t, v), iff either one of the following holds: There exists i, 0 ?
i ?
n ?
1, and there exists ?
?
?, such that (s,?, R, i,?, t) ??
and u = v and ui = vi = ?
; or There exists i, 0 ?
i ?
n ?
1, and there exists ?
?
?, such that (s,?, W, i,?, t) ??
and for all k, k ?
{0, 1, ..., n ?
1}, such that k = i, uk = vk and vi = ?.Informally, a configuration c1 produces a configuration c2 iff the automaton canmove from c1 to c2 when scanning the input ?
(or without any input, when ?
= ) in onestep.
If the register operation is R, then the contents of the registers in the two configura-tions must be equal, and in particular the contents of the designated register in the twoconfigurations should be the expected symbol (?).
If the register operation is W, then thecontents of the registers in the two configurations is equal except for the designated reg-ister, whose contents in the produced configuration should be the expected symbol (?
).DefinitionA run of A on w is a sequence of configurations c0, ..., cr such that c0 = qc0, cr ?
Fc, andfor every k, 1 ?
k ?
r, ck?1?k,A ck and w = ?1...?r.
An FSRA A accepts a word w ifthere exists a run of A on w. Notice that |w| may be less than r since some of the ?i maybe .
The language recognized by an FSRA A, denoted by L(A), is the set of words over??
accepted by A.Example 5Consider again example 1.
We construct an efficient FSRA accepting all and only thepossible combinations of stems and circumfixes.
If the number of stems is r, we definean FSRA A = ?Q, q0,?,?, 2, ?, {qf}?
where: Q = {q0, q1, .
.
.
, q2r+2, qf} ?
= {a, b, c, .
.
.
, z, ht, ut} ?
= {htut, ha, m, #} ?
= {(q0, ht, W, 1, htut, q1), (q0, h, W, 1, ha, q1)}?
{(q0, m, W, 1, m, q1), (q2r+2, ut, R, 1, htut, qf )}?
{(q2r+2, a, R, 1, ha, qf ), (q2r+2,, R, 1, m, qf )}?
{(q1,?1, qi), (qi,?2, qi+1), (qi+1,?3, q2r+2) | 2 ?
i ?
2r and?1?2?3 is the i-th stem}.57Computational Linguistics Volume 32, Number 1This automaton is shown in Figure 6.
The number of its states is 2r + 4 (like the FSAof Figure 2), that is, O(r), and in particular independent of the number of circumfixes.The number of arcs is also reduced from O(r ?
p), where p indicates the number ofcircumfixes, to O(r + p).Example 6Consider again example 2.
The FSRA of Figure 7 also accepts the same language.
Thisautomaton has seven states and will have seven states for any number of roots.
Thenumber of arcs is also reduced to 3r + 3.Next, we show that finite-state registered automata and standard finite state au-tomata recognize the same class of languages.
Trivially, every finite-state automatonhas an equivalent FSRA: Every FSA is also an FSRA since every transition (s,?, t) in anFSRA is a shorthand notation for (s,?, R, 0, #, t).
The other direction is also simple.Theorem 1Every FSRA has an equivalent finite-state automaton.We prove this by constructing an equivalent FSA to a given FSRA.
The construction isbased on the fact that in FSRAs the number of registers is finite, as are the sets ?
andQ, the register alphabet and states, respectively.
Hence the number of configurations isfinite.
The FSA?s states are the configurations of the FSRA, and the transition functionsimulates the ?produces?
relation.
Notice that this relation holds between configurationsdepending on ?
only, similarly to the transition function in an FSA.
The constructedFSA is non-deterministic, with possible -moves.
The formal proof is suppressed.The number of configurations in A is |Q| ?
|?|n, hence the growth in the number ofstates when constructing A?
from A might be in the worst case exponential in the num-ber of registers.
In other words, the move from FSAs to FSRAs can yield an exponentialreduction in the size of the network.
As we show below, the reduction in the number ofstates can be even more dramatic.The FSRA model defined above allows only one register operation on each tran-sition.
We extend it to allow up to k register operations on each transition, where kis determined for each automaton separately.
The register operations are defined as asequence (rather than a set), in order to allow more than one operation on the sameFigure 6FSRA for circumfixation.58Cohen-Sygal and Wintner Non-Concatenative MorphologyFigure 7FSRA for the pattern hitae.register over one transition.
This extension allows further reduction of the network sizefor some automata as well as other advantages that will be discussed presently.DefinitionAn order-k finite-state registered automaton (FSRA-k) is a tuple A = ?Q, q0,?,?, n,k, ?, F?, where: Q, q0,?,?, n, F and the initial content of the registers are as before. k ?
N (indicating the maximum number of register operations allowedon each arc). Let Actions?n = {R, W} ?
{0, 1, 2, .
.
.
, n ?
1} ?
?.
Then?
?
Q ?
?
?
{} ??
?k?j=1{?a1, ..., aj?
| for all i, 1 ?
i ?
j, ai ?
Actions?n}???
Qis the transition relation.
?
is extended to allow each transition to beassociated with a series of up to k operations on the registers.
Eachoperation has the same meaning as before.The register operations are executed in the order in which they are specified.
Thus,(s,?, ?a1, ..., ai?, t) ?
?
where i ?
k implies that if A is in state s, the input symbol is ?
andall the register operations a1, ..., ai are executed successfully, then A may enter state t.DefinitionGiven a ?
Actions?n we define a relation over ?n, denoted u a v for u, v ?
?n.
We defineu a v where u = u0 .
.
.
un?1 and v = v0 .
.
.
vn?1 iff the following holds: if a = (R, i,?)
for some i, 0 ?
i ?
n ?
1 and for some ?
?
?, then u = vand ui = vi = ?. if a = (W, i,?)
for some i, 0 ?
i ?
n ?
1 and for some ?
?
?, then for allk ?
{0, 1, .
.
.
, n ?
1} such that k = i, uk = vk and vi = ?.This relation is extended to series over Actions?n .
Given a series ?a1, ..., ap?
?
(Actions?n )pwhere p ?
N, we define a relation over ?n denoted u ?a1,...,ap?
v for u, v ?
?n.
Wedefine u ?a1,...,ap?
v iff the following holds: if p = 1, then u a1 v. if p > 1, then there exists w ?
?n such that u a1 w and w ?a2,...,ap?
v.59Computational Linguistics Volume 32, Number 1DefinitionLet u, v ?
?n.
Given a symbol ?
?
?
?
{} and an FSRA-k A, we say that a configuration(s, u) produces a configuration (t, v), denoted (s, u)?,A (t, v), iff there exist ?a1, .
.
.
, ap?
?
(Actions?n )p for some p ?
N such that (s,?, ?a1, .
.
.
, ap?, t) ?
?
and u ?a1,...,ap?
v.DefinitionA run of A on w is a sequence of configurations c0, ..., cr such that c0 = qc0, cr ?
Fc, and forevery l, 1 ?
l ?
r, cl?1?l,A cl and w = ?1...?r.
An FSRA-k A accepts a word w if thereexists a run of A on w. The language recognized by an FSRA-k A, denoted by L(A), isthe set of words over ??
accepted by A.Example 7Consider the Arabic nouns qamar (moon), kitaab (book), $ams (sun), and daftar (note-book).
The definite article in Arabic is the prefix al, which is realized as al when pre-ceding most consonants; however, the ?l?
of the prefix assimilates to the first consonantof the noun when the latter is ?d?, ?$?, etc.
Furthermore, Arabic distinguishes betweendefinite and indefinite case markers.
For example, nominative case is realized as thesuffix u on definite nouns, un on indefinite nouns.
Examples of the different forms ofArabic nouns are:word nominative definite nominative indefiniteqamar ?alqamaru qamarunkitaab ?alkitaabu kitaabun$ams ?a$$amsu $amsundaftar ?addaftaru daftarunThe FSRA-2 of Figure 8 accepts all the nominative definite and indefinite forms ofthe above nouns.
In order to account for the assimilation, register 2 stores informationabout the actual form of the definite article.
Furthermore, to ensure that definite nounsoccur with the correct case ending, register 1 stores information of whether or not adefinite article was seen.Figure 8FSRA-2 for Arabic nominative definite and indefinite nouns.60Cohen-Sygal and Wintner Non-Concatenative MorphologyFSRA-k and FSRAs recognize the same class of languages.
Trivially, every FSRA hasan equivalent FSRA-k: Every FSRA is an FSRA-k for k = 1.
The other direction is alsosimple.Theorem 2Every FSRA-k has an equivalent FSRA.We show how to construct an equivalent FSRA (or FSRA-1) A?
given an FSRA-k A. Eachtransition in A is replaced by a series of transitions in A?, each of which performs oneoperation on the registers.
The first transition in the series deals with the new inputsymbol and the rest are -transitions.
This construction requires additional states toenable the addition of transitions.
Each transition in A that is replaced requires theaddition of as many states as the number of register operations performed on thistransition minus one.
The formal construction is suppressed.In what follows, the term FSRA will be used to denote FSRA-k.
Simple FRSA willbe referred to as FSRA-1.
For the sake of emphasis, however, the term FSRA-k will stillbe used in some cases.FSRA is a very space-efficient finite-state device.
The next theorem shows howordinary finite-state automata can be encoded efficiently by the FSRA-2 model.
Givena finite-state automaton A, an equivalent FSRA-2 A?
is constructed.
A?
has three statesand two registers (in fact, only one register is used since register number 0 is neveraddressed).
One state functions as a representative for the final states in A, anotherone functions as a representative for the non-final states in A, and the third as aninitial state.
The register alphabet consists of the states of A and the symbol ?#?.
Eacharc in A has an equivalent arc in A?
with two register operations.
The first readsthe current state of A from the register and the second writes the new state into theregister.
If the source state of a transition in A is a final state, then the source state ofthe corresponding transition in A?
will be the final states representative; if the sourcestate of a transition in A is a non-final state, then the source state of the correspondingtransition in A?
will be the non-final states representative.
The same holds also for thetarget states.
The purpose of the initial state is to write the start state of A into theregister.
In this way A?
simulates the behavior of A.
Notice that the number of arcs in A?equals the number of arcs in A plus one, i.e., while FSRAs can dramatically reduce thenumber of states, compared to standard FSAs, a reduction in the number of arcs is notguaranteed.Theorem 3Every finite-state automaton has an equivalent FSRA-2 with three states and tworegisters.Proof 1Let A = ?Q, q0,?, ?, F?
be an FSA and let f : Q ?
{qf, qnf}be a total function definedbyf (q) ={qf q ?
Fqnf q /?
F61Computational Linguistics Volume 32, Number 1Construct an FSRA-2 A?
= ?Q?, q?0,??,?
?, 2, 2, ?
?, F?
?, where: Q?
= {q?0, qnf, qf}.
q?0 is the initial state, qf is the final states representative,and qnf is the non-final states representative ??
= ? ?
= Q ?
{#} F?
= {qf} ??
= {(f (s),?, ?
(R, 1, s), (W, 1, t)?, f (t)) | (s,?, t) ?
?}?
{(q?0,, ?
(W, 1, q0)?, f (q0))}The formal proof that L(A) = L(A?)
is suppressed.
3.2 Closure PropertiesThe equivalence shown in the previous section between the classes of languages recog-nized by finite-state automata and finite-state registered automata immediately impliesthat finite-state registered automata maintain the closure properties of regular lan-guages.
Applying the regular operations to finite-state registered automata can be easilydone by converting them first into finite-state automata.
However, as shown above,such a conversion may result in an exponential increase in the size of the automaton,invalidating the advantages of this model.
Therefore, we show how some of theseoperations can be defined directly for FSRAs.
The constructions are mostly based onthe standard constructions for FSAs with some essential modifications.
In what follows,let A1 = ?Q1, q10,?1,?1, n1, k1, ?1, F1?
and A2 = ?Q2, q20,?2,?2, n2, k2, ?2, F2?
be finite-stateregistered automata.3.2.1 Union.
Two FSRAs, A1, A2, are unioned into an FSRA A in the same way as in FSAs:by adding a new initial state and connecting it with -arcs to each of the (former) initialstates of A1, A2.
The number of registers and the maximal number of register operationsper arc in A is the maximum of the corresponding values in A1, A2.
Notice that inany specific run of A, the computation goes through just one of the original automata;therefore the same set of registers can be used for strings of L(A1) or L(A2) as needed.3.2.2 Concatenation.
We show two different constructions of an FSRA A = ?Q, q0,?,?, n, k, ?, F?
to recognize L(A1) ?
L(A2).
Concatenation in finite-state automata is achievedby leaving only the accepting states of the second automaton as accepting states andadding an -arc from every accepting state of the first automaton to the initial state ofthe second automaton.
Doing just this in FSRA is insufficient because using the sameregisters might cause undesired effects: The result might be affected by the content leftin the registers after dealing with a substring from L(A1).
Thus, this basic constructionis used with care.
The first alternative is to employ more registers in the FSRA.
In thisway when dealing with a substring from L(A1) the first n1 registers are used, and whenmoving to deal with a substring from L(A2) the next n2 registers are used.
The secondalternative is to use additional register operations that clear the content of the registersbefore handling the next substring from L(A2).
This solution may be less intuitive butwill be instrumental for Kleene closure below.62Cohen-Sygal and Wintner Non-Concatenative Morphology3.2.3 Kleene Closure.
The construction is based on the concatenation construction.Notice that it cannot be based on the first alternative (adding registers) due to the factthat the number of iterations in Kleene star is not limited, and therefore the number ofregisters needed cannot be bounded.
Thus, the second alternative is used: Register op-erations are added to delete the content of registers.
The construction is done by turningthe initial state into a final one (if it is not already final) and connecting each of the finalstates to the initial state with an -arc that is associated with a register operation thatdeletes the contents of the registers, leaving them ready to handle the next substring.3.2.4 Intersection.
For the intersection construction, assume that A1 and A2 are -free(we show an algorithm for removing -arcs in Section 3.3.1).
The following constructionsimulates the runs of A1 and A2 simultaneously.
It is based on the basic construction forintersection of finite-state automata, augmented by a simulation of the registers andtheir behavior.
Each transition is associated with two sequences of operations on theregisters, one for each automaton.
The number of the registers is the sum of the numberof registers in the two automata.
In the intersection automaton the first n1 registersare designated to simulate the behavior of the registers of A1 and the next n2 registerssimulate the behavior of A2.
In this way a word can be accepted by the intersection au-tomaton iff it can be accepted by each one of the automata separately.
Notice that registeroperations from ?1 and ?2 cannot be associated with the same register.
This guaranteesthat no information is lost during the simulation of the two intersected automata.3.2.5 Complementation.
Ordinary FSAs are trivially closed under complementation.However, given an FSA A whose language is L(A), the minimal FSA recognizing thecomplement of L(A) can be exponentially large.
More precisely, for any integer n > 2,there exists a non-deterministic finite-state automaton (NFA) with n states A, such thatany NFA that accepts the complement of L(A) needs at least 2n?2 states (Holzer andKutrib 2002).
We have no reason to believe that FSRAs will demonstrate a differentbehavior; therefore, we maintain that in the worst case, the best approach for com-plementing an FSRA would be to convert it into FSA and complement the latter.
Wetherefore do not provide a dedicated construction for this operator.3.3 Optimizations3.3.1 -removal.
An -arc in an FSRA is an arc of the form (s,, ?a?, t) where a is usedas a meta-variable over(Actions?n)+(i.e., a represents a vector of register operations).Notice that this kind of arc might occur in an FSRA by its definition.
Given an FSRAthat might contain -arcs, an equivalent FSRA without -arcs can be constructed.
Theconstruction is based on the algorithm for -removal in finite-state automata, but theregister operations that are associated with the -arc have to be dealt with, and thisrequires some care.
The resulting FSRA has one more state than the original, and someadditional arcs may be added, too.The main problem is -loops; while these can be easily removed in standard FSAs,here such loops can be associated with register operations which must be accounted for.The number of possible sequences of register operations along an -loop is unbounded,but it is easy to prove that there are only finitely many equivalence classes of suchsequences: Two sequences are in the same equivalence class if and only if they havethe same effect on the state of the machine; since each machine has a finite number ofconfigurations (see theorem 1), there are only finitely many such equivalence classes.Therefore, the basic idea behind the construction is as follows: If there exists an-path from q1 to q2 with the register operationsa over its arcs, and an arc (q2,?, ?b?, q3)63Computational Linguistics Volume 32, Number 1Figure 9 removal paradigm.where ?
= , and an -path from q3 to q4 with the register operations c over its arcs,then the equivalent -free network will include the arcs (q2,?, ?b?, q3), (q1,?, ?a,b?, q3),(q2,?, ?b,c?, q4), and (q1,?, ?a,b,c?, q3), with all the -arcs removed.
This is illustratedin Figure 9.
Notice that if q1 and q2 are the same state, then states q2 and q3 will beconnected by two parallel arcs differing in their associated register operations; the sameholds for states q2 and q4.
Similarly, when q3 and q4 are the same state.In addition to the above changes, special care is needed for the case in which theempty word is accepted by the original automaton.
The formal construction is similarin spirit to the -removal paradigm in weighted automata (Mohri 2000), where weightsalong an -path need to be gathered.
Therefore, we suppress the formal constructionand the proof of its correctness.3.3.2 Optimizing Register Operations.
In FSRAs, traversing an arc depends notonly on the input symbol but also on satisfying the series of register operations.Sometimes, a given series of register operations can never be satisfied, and thusthe arc to which it is attached cannot be traversed.
For example, the series of reg-ister operations ?
(W, 1, a), (R, 1, b)?
can never be satisfied, hence an arc of the form(q1,?, ?
(W, 1, a), (R, 1, b)?, q2) is redundant.
In addition, the constructions of Sections 3.2and 3.3.1 might result in redundant states and arcs that can never be reached or cannever lead to a final state.
Moreover, in many cases a series of register operations canbe minimized into a shorter series with the same effect.
For example, the series ofregister operations ?
(W, 1, a), (R, 1, a), (W, 1, b)?
is equal in its effect to the series ?
(W, 1, b)?.Therefore, we show an algorithm for optimizing a given FSRA by minimizing the seriesof register operations over its arcs and removing redundant arcs and states.For a given FSRA A = ?Q, q0,?,?, n, ?, F?, we construct an equivalent FSRA A?
=?Q, q0,?,?, n, ?
?, F?
= Opt(A), such that ??
is created from ?
by removing redundantarcs and by optimizing all the series of register operations.
We begin by defining(Actions?n)+|i as the subset of(Actions?n)+that consists only of operations over thei-th register.
Define a total function sati :(Actions?n)+|i ??
{true, false} by:sati(a) ={true if there exist u, v ?
?n such that u a vfalse otherwise64Cohen-Sygal and Wintner Non-Concatenative Morphologysati(a) = true iff the series of register operations a is satisfiable, i.e., there exists aconfiguration of register contents for which all the operations in the series can beexecuted successfully.
Determining whether sati(a) = true by exhaustively checkingall the vectors in ?n may be inefficient.
Therefore, we show a necessary and sufficientcondition for determining whether sati(a) = true for some a ?
(Actions?n)+|i, which canbe checked efficiently.
In addition, this condition will be useful in optimizing the seriesof register operations as will be shown later.
A series of register operations over the i-thregister is not satisfiable if either one of the following holds: A write operation is followed by a read operation expecting a differentvalue. A read operation is immediately followed by a read operation expecting adifferent value.Theorem 4For all a = ?
(op1, i,?1), (op2, i,?2), .
.
.
, (ops, i,?s)?
?
(Actions?n)+|i, sati(a) = false if andonly if either one of the following holds:1.
There exists k, 1 ?
k < s, such that opk = W and there exists m, k < m ?
s,such that opm = R, ?k = ?m and for all j, k < j < m, opj = R.2.
There exists k, 1 ?
k < s, such that opk = opk+1 = R and ?k = ?k+1.Notice that if i = 0, then by the definition of FSRAs, all the register operations inthe series are the same operation, which is (R, 0, #); and this operation can never fail.In addition, if all the operations in the series are write operations, then again, by thedefinition of FSRAs, these operations can never fail.
If none of the two conditions of thetheorem holds, then the series of register operations is satisfiable.We now show how to optimize a series of operations over a given register.
Anoptimized series is defined only over satisfiable series of register operations in thefollowing way: If all the operations are write operations, then leave only the last one (sinceit will overwrite all its predecessors). If all the operations are read operations, then by theorem 4, they are all thesame operation, and in this case just leave one of them. If there are both read and write operations, then distinguish between twocases:?
If the first operation is a write operation, leave only the last writeoperation in the series.?
If the first operation is a read operation, leave the first operation(which is read) and the last write operation in the series.
If the lastwrite operation writes into the register the same symbol that theread operation required, then the write is redundant; leave only theread operation.65Computational Linguistics Volume 32, Number 1DefinitionDefine a function mini :(Actions?n)+|i ??(Actions?n)+|i.
Let a = ?
(op1, i,?1), .
.
.
, (ops, i,?s)?.
If sati(a) = true then: If for all k, 1 ?
k ?
s, opk = W, define mini(a) = ?
(W, i,?s)?. If for all k, 1 ?
k ?
s, opk = R then define mini(a) = ?
(R, i,?s)?. If there exists m, 1 ?
m ?
s such that opm = W and if there exists t,1 ?
t ?
s, such that opt = R then:mini(a) =????????????????????
(W, i,?j)?
if op1 = W andfor all k, j < k ?
s, opk = R?
(R, i,?1), (W, i,?j)?
if op1 = R andfor all k, j < k ?
s, opk = R and ?1 = ?j?
(R, i,?1)?
if op1 = R and if there exists j, 1 ?
j ?
s,such that for all k, j < k ?
s,opk = R and ?1 = ?jThe formal proof that mini(a) is the minimal equivalent series of register operationsofa is suppressed.We now show how to optimize a series of register operations.
Define a functionmin :(Actions?n)+ ??
(Actions?n)+ ?
{null}.
For all a ?
(Actions?n)+define min(a) = bwhereb is obtained froma by: Each subseriesai ofa, consisting of all the register operations on the i-thregister, is checked for satisfaction.
If sati(ai) = false then the arc cannot betraversed and min(a) = b = null.
If sati(ai) = true thenai is replaced ina bymin(ai).
Notice that the order of the minimized subseries in the completeseries is unimportant as they operate on different registers. If there exists i = 0, such that ai is not empty, then the subseriesa0consisting only of operations of the form (R, 0, #) is deleted froma.Finally, given an FSRA A = ?Q, q0,?,?, n, ?, F?, construct an equivalent FSRA A?
=?Q, q0,?,?, n, ?
?, F?
= Opt(A) where??
={(q1,?, ?min(a)?, q2)|(q1,?, ?a?, q2)?
?
and min(a) = null}Opt(A) is optimized with respect to register operations.Like FSAs, FSRAs may have states that can never be reached or can never lead to afinal state.
These states (and their connected arcs) can be removed in the same way theyare removed in FSAs.
In sum, FSRA optimization is done in two stages:1.
Minimizing the series of register operations over the FSRA transitions.2.
Removing redundant states and arcs.Notice that stage 1 must be performed before stage 2 as it can result in further re-duction in the size of the network when performing the second stage.
For a given FSRAA, define OPT(A) as the FSRA obtained from Opt(A) by removing all the redundant66Cohen-Sygal and Wintner Non-Concatenative Morphologystates and transitions.
An FSRA A is optimized if OPT(A) = A (notice that OPT(A) isunique, i.e., if B = OPT(A) and C = OPT(A), then B = C).3.4 FSRA MinimizationFSRAs can be minimized along three different axes: states, arcs, and registers.
Reduc-tion in the number of registers can always be achieved by converting an FSRA to anFSA (Section 3.1), eliminating registers altogether.
Since FSRAs are inherently non-deterministic (see the discussion of linearization below), their minimization is relatedto the problem of non-deterministic finite-state automata (NFA) minimization, whichis known to be NP-hard.6 However, while FSRA arc minimization is NP-hard, FSRAstate minimization is different.
Recall that in theorem 3 we have shown that any FSAhas an equivalent FSRA-2 with 3 states and 2 registers.
It thus follows that any FSRAhas an equivalent FSRA-2 with 3 states (simply convert the FSRA to an FSA and thenconvert it to an FSRA-2 with 3 states).
Notice that minimizing an FSRA in terms of statesor registers can significantly increase the number of arcs.
As many implementations offinite-state devices use space that is a function of the number of arcs, the benefit that liesin such minimization is limited.
Therefore, a different minimization function, involvingall the three axes, is called for.
We do not address this problem in this work.
As forarc minimization, we cite the following theorem.
As its proof is most similar to thecorresponding proof on NFA, we suppress it.Theorem 5FSRA arc minimization is NP-hard.The main advantage of finite-state devices is their linear recognition time.
In finite-state automata, this is achieved by determinizing the network, ensuring that thetransition relation is a function.
In FSRAs, in contrast, a functional transition re-lation does not guarantee linear recognition time, since multiple possible transi-tions can exist for a given state and a given input symbol.
For example, given anFSRA A = ?Q, q0,?,?, n, k, ?, F?, and some q, q1, q2 ?
Q and ?
?
?, two arcs such as(q,?, ?
(W, 1, a)?, q1), (q,?, ?
(W, 1, b)?, q2) ?
?
do not hamper the functionality of the FSRAtransition relation.
However, they do imply that for the state q and for the same inputsymbol (?
), more than one possible arc can be traversed.
We use deterministic to denoteFSRAs in which the transition relation is a function, and a new term, linearized, is usedto denote FSRAs for which linear recognition time is guaranteed.Generally, a FSRA is linearized if it is optimized, -free, and given a current stateand a new input symbol, and at most one transition can be traversed.
Thus, if thetransition relation includes two arcs of the form (q,?, ?a?, q1), (q,?, ?b?, q2), then a andb must be a contradicting series of register operations.
Two series of register operationsare contradicting if at most one of them is satisfiable.
Since the FSRA is optimized, eachseries of register operations is a concatenation of subseries, each operating on a differ-ent register; and the subseries operating on the i-th register must be either empty or?
(W, i,?)?
or ?
(R, i,?)?
or ?
(R, i,?1), (W, i,?2)?.
?
(W, i,?)?
contradicts neither ?
(R, i,?)?
nor?
(R, i,?1), (W, i,?2)?.
?
(R, i,?)?
and ?
(R, i,?1), (W, i,?2)?
are contradicting only if ?
= ?1.6 While this theorem is a part of folklore, we were unable to find a formal proof.
We explicitly prove thistheorem in Cohen-Sygal (2004).67Computational Linguistics Volume 32, Number 1DefinitionAn FSRA A = ?Q, q0,?,?, n, k, ?, F?, is linearized if it is optimized, -free, and forall (q,?, ?a?, q1), (q,?, ?b?, q2) ?
?
such that ?a?
= ?b?, where ?a?
= ?
(op11, i11,?11), .
.
.
, (op1k ,i1k ,?1k )?
and ?b?
= ?
(op21, i21,?21), .
.
.
, (op2m, i2m,?2m)?
, there exists j1, 1 ?
j1 ?
k and thereexists j2, 1 ?
j2 ?
m, such that op1j1 = op2j2= R, i1j1 = i2j2and ?1j1 = ?2j2.A na?
?ve algorithm for converting a given FSRA into an equivalent linearized oneis to convert it to an FSA and then determinize it.
In the worst case, this results inan exponential increase in the network size.
As the following theorem shows, FSRAlinearization is NP-complete.Theorem 6FSRA linearization is NP-complete.Proof 2Evidently, given an FSRA A, it can be verified in polynomial time that A is linearized.Therefore, FSRA linearization is in NP.Let ?
be a CNF formula with m clauses and n variables.
Construct an FSRA A suchthat L(A) = {} if ?
is satisfiable, otherwise L(A) = ?.Let x1, .
.
.
, xn be the variables of ?.
Define A = ?Q, q0,?,?, n, 1, ?, F?, such that: Q = {q0, q1, .
.
.
, qn+m} F = {qn+m} ?
is irrelevant (choose any ?
). ?
= {T, F}.?
?
= {(qi?1,, (W, i, T), qi) | 1 ?
i ?
n} ?
{(qi?1,, (W, i, F), qi) | 1 ?
i ?
n}?
{(qn+i?1,, (R, j, T), qn+i) | 1 ?
i ?
m and xj occurs in the i-th clause}?
{(qn+i?1,, (R, j, F), qn+i) | 1 ?
i ?
m and xj occurs in the i-th clause}Notice that each path in A is of length m + n. The first n arcs in the pathwrite an assignment into the registers, then it is possible to traverse theremaining m arcs in the path only if the assignment stored into theregisters satisfies ?.For example, for the CNF formula (x1 ?
x2 ?
x5) ?
(x1 ?
x2) ?
(x3 ?
x4 ?
x5), the FSRA ofFigure 10 is constructed.
Observe that the number of states and arcs in this FSRA isO(mn).
Now, linearize A into an FSRA A?
and assume this can be done in polynomialtime.
By the definition of linearized FSRA, A?
does not contain -arcs.
Therefore,  ?L(A?)
iff the initial state of A?
is also a final one.
Hence, ?
is satisfiable iff the initial stateof A?
is also a final one.
4.
A Regular Expression Language for FSRAsRegular expressions are a formal way for defining regular languages.
Regular languageoperations construct regular expressions in a convenient way.
Several toolboxes (soft-ware packages) provide extended regular expression description languages and compil-68Cohen-Sygal and Wintner Non-Concatenative MorphologyFigure 10FSRA for a given CNF formula.ers of the expressions to finite-state devices, automata, and transducers (see Section 1).We provide a regular expression language for constructing FSRAs, the denotationsof whose expressions are FSRAs.
In the following discussion we assume the regularexpression syntax of XFST (Beesley and Karttunen 2003) for basic expressions.7DefinitionLet Actions?n = {R, W} ?
{0, 1, 2, .
.
.
, n ?
1} ?
?, where n is the number of registers and?
is the register alphabet.
If R is a regular expression and a ?
(Actions?n)+is a series ofregister operations, then the following are also regular expressions: a  R, a  R, a  R,anda   R.We now define the denotation of each of the above expressions.
Let R be a regularexpression whose denotation is the FSRA A, and let a ?(Actions?n)+.
The denotationof a  R is an FSRA A?
obtained from A by adding a new node, q, which becomes theinitial node of A?, and an arc from q to the initial node of A; this arc is labeled by and associated with a.
Notice that in the regular expression a  R, R and a can containoperations on joint registers.
In some cases, one would like to distinguish between theregisters used in a and in R. Usually, it is up to the user to correctly manipulate theusage of registers, but in some cases automatic distinction seems desirable.
For example,if R includes a circumfix operator (see below), its corresponding FSRA will containregister operations created automatically by the operator.
Instead of remembering thatcircumfixation always uses register 1, one can simply distinguish between the registersof a and R via the a   R operator.
This operator has the same general effect as theprevious one, but the transition relation in its FSRA uses fresh registers that are addedto the machine.In a similar way, the operators a  R and a  R are translated into networks.
Thedifference between these operators and the previous ones is that here, the registeroperations in a are executed after traversing all the arcs in the FSRA denoted by R.Using these additional operators, it is easy to show that every FSRA has a correspondingregular expression denoting it, by a trivial modification of the construction presented byKleene (1956).Example 8Consider the case of vowel harmony in Warlpiri (Sproat 1992), where the vowel ofsuffixes agrees in certain aspects with the vowel of the stem to which it is attached.7 In particular, concatenation is denoted by juxtaposition and  is denoted by 0.69Computational Linguistics Volume 32, Number 1A simplified account of the phenomenon is that suffixes come in two varieties, one with?i?
vowels and one with ?u?
vowels.
Stems whose last vowel is ?i?
take suffixes of thefirst variety, whereas stems whose last vowel is ?u?
or ?a?
take the other variety.
Thefollowing examples are from Sproat (1992) (citing Nash (1980)):1. maliki+kil.i+l.i+lki+ji+li(dog+PROP+ERG+then+me+they)2. kud.
u+kul.u+l.u+lku+ju+lu(child+PROP+ERG+then+me+they)3. minija+kul.u+l.u+lku+ju+lu(cat+PROP+ERG+then+me+they)An FSRA that accepts the above three words is denoted by the following complexregular expression:define LexI [m a l i k i]; % words ending in ?i?define LexU [k u d u]; % words ending in ?u?define LexA [m i n i j a]; % words ending in ?a?!
Join all the lexicons and write to register 1 ?u?
or ?i?!
according to the stem?s last vowel.define Stem [<(W,1,i)>  LexI] | [<(W,1,u)>  [LexU | LexA]];!
Traverse the arc only if the scanned symbol is the content of!
register 1.define V [<(R,1,i)>  i] | [<(R,1,u)>  u];define PROP [+ k V l V]; % PROP suffixdefine ERG [+ l V]; % ERG suffixdefine Then [+ l k V]; % suffix indicating ?then?define Me [+ j V]; % suffix indicating ?me?define They [+ l V]; % suffix indicating ?they?!
define the whole networkdefine WarlpiriExample Stem PROP ERG Then Me They;Register 1 stores the last vowel of the stem, eliminating the need to duplicate pathsfor each of the different cases.
The lexicon is divided into three separate lexicons(LexI, LexU, LexA), one for each word ending (?i?, ?u?, or ?a?
respectively).
The separatelexicons are joined into one (the variable Stem) and when reading the last letter ofthe base word, its type is written into register 1.
Then, when suffixing the lexiconbase words, the variable V uses the the content of register 1 to determine which ofthe symbols ?i?, ?u?
should be scanned and allows traversing the arc only if the correctsymbol is scanned.
Note that this solution is applicable independently of the size of thelexicon, and can handle other suffixes in the same way.Example 9Consider again Example 7.
The FSRA constructed for Arabic nominative definite andindefinite nouns can be denoted by the following regular expression:!
Read the definite article (if present).!
Store in register 1 whether the noun is definite or indefinite.!
Store in register 2 the actual form of the definite article.70Cohen-Sygal and Wintner Non-Concatenative Morphologydefine Prefix [<(W,1,indef)>  0] | [<(W,1,def),(W,2,l)>  ?al] |[<(W,1,def),(W,2,$)>  ?a$] | [<(W,1,def),(W,2,d)>  ?ad];!
Normal base - definite and indefinitedefine Base [ [<(R,2,l)>  0] | [<(R,1,indef)>  0] ][ [k i t a a b] | [q a m a r] ];!
Bases beginning with $ - definite and indefinitedefine $Base [ [<(R,2,$)>  0] | [<(R,1,indef)>  0] ] [$ a m s];!
Bases beginning with d - definite and indefinitedefine dBase [ [<(R,2,d)>  0] | [<(R,1,indef)>  0] ] [d a f t a r];!
Read definite and indefinite suffixes.define Suffix [<(R,1,def)>  u] | [<(R,1,indef)>  un];!
The complete network.define ArabicExample Prefix [Base | $Base | dBase] Suffix;The variable Prefix denotes the arcs connecting the first two states of the FSRA,in which the definite article (if present) is scanned and information indicating whetherthe word is definite or not is saved into register 1.
In addition, if the word is definitethen register 2 stores the actual form of the definite article.
The lexicon is dividedinto several parts: The Base variable denotes nouns that do not trigger assimilation.Other variables ($Base, dBase) denote nouns that trigger assimilation, where for eachassimilation case, a different lexicon is constructed.
Each part of the lexicon deals withboth its definite and indefinite nouns by allowing traversing the arcs only if the registercontent is appropriate.
The variable Suffix denotes the correct suffix, depending onwhether the noun is definite or indefinite.
This is possible using the information thatwas stored in register 1 by the variable Prefix.5.
Linguistic ApplicationsWe demonstrated in examples 5 and 6 that FSRAs can model some non-concatenativephenomena more efficiently than standard finite-state devices.
We now introduce newregular expression operators, accounting for our motivating linguistic phenomena, andshow how expressions using these operators are compiled into the appropriate FSRA.5.1 CircumfixesWe introduce a dedicated regular expression operator for circumfixation and show howexpressions using this operator are compiled into the appropriate FSRA.
The operatoraccepts a regular expression, denoting a set of bases, and a set of circumfixes, eachof which is a pair of regular expressions (prefix, suffix).
It yields as a result an FSRAobtained by applying each circumfix to each of the bases.
The main purpose of thisoperator is to deal with cases in which the circumfixes are pairs of strings, but it isdefined such that the circumfixes can be arbitrary regular expressions.DefinitionLet ?
be a finite set such that , {, }, ?, ?,?
/?
?.
We define the ?
operation to be ofthe formR ?
{??1?1???2?2?
.
.
.
??m?m?
}71Computational Linguistics Volume 32, Number 1where: m ?
N is the number of circumfixes; R is a regular expression over ?
denotingthe set of bases; and ?i, ?i for 1 ?
i ?
m are regular expressions over ?
denoting theprefix and suffix of the i-th circumfix, respectively.Notice that R,?i,?i may denote infinite sets.
To define the denotation of this op-erator, let A?i , A?i be the FSRAs denoted by ?i,?i, respectively.
The operator yields anFSRA constructed by concatenating three FSRAs.
The first is the FSRA constructed fromthe union of the FSRAs A?
?1 , .
.
.
, A?
?m , where each A?
?i is an FSRA obtained from A?iby adding a new node, q, which becomes the initial node of A?
?i , and an arc from qto the initial node of A?i ; this arc is labeled by  and associated with ?
(W, 1,?i?i)?
(register 1 is used to store the circumfix).
In addition, the register operations of theFSRA A?i are shifted by one register in order not to cause undesired effects by theuse of register 1.
The second FSRA is the FSRA denoted by the regular expression R(again, with one register shift) and the third is constructed in the same way as thefirst one, the only difference being that the FSRAs are those denoted by ?1, .
.
.
,?mand the associated register operation is ?
(R, 1,?i?i)?.
Notice that the concatenationoperation, defined in Section 3.2.2, adjusts the register operations in the FSRAs to beconcatenated, to avoid undesired effects caused by using joint registers.
We use thisoperation to concatenate the three FSRAs, leaving register 1 unaffected (to handle thecircumfix).Example 10Consider the participle-forming combinations in German, e.g., the circumfix ge-t. Asimplified account of the phenomenon is that German verbs in their present form takean n suffix but in participle form they take the circumfix ge-t.
The following examplesare from Sproat (1992):sa?useln ?rustle?
gesa?uselt ?rustled?bru?sten ?brag?
gebru?stet ?bragged?The FSRA of Figure 11, which accepts the four forms, is denoted by the regularexpression[s a?
u s e l | b r u?
s t e] ?
{?n?
?g et?
}This regular expression can be easily extended to accept more German verbs in otherforms.
More circumfixation phenomena in other languages such as Indonesian andArabic can be modeled in the same way using this operator.Figure 11Participle-forming combinations in German.72Cohen-Sygal and Wintner Non-Concatenative MorphologyExample 11Consider again Example 5.
The FSRA accepting all the possible combinations of stemsand the Hebrew circumfixes h-a, ht-ut, m- can be denoted by the regular expressionR ?
{?ha??htut??m?}
where R denotes an FSA accepting the roots.5.2 InterdigitationNext, we define a dedicated operator for interdigitation.
It accepts a set of regularexpressions, representing a set of roots, and a list of patterns, each of which containingexactly n slots.
It yields as a result an FSRA denoting the set containing all the stringscreated by splicing the roots into the slots in the patterns.
For example, consider the He-brew roots r.$.m, p.&.l, p.q.d and the Hebrew patterns hitae, mia, haaa.The roots are all trilateral, and the patterns have three slots each.
Given these twoinputs, the new operator yields an FSRA denoting the set {hitra$em, hitpa&el, hitpaqed,mir$am, mip&al, mipqad, har$ama, hap&ala, hapqada}.DefinitionLet ?
be a finite set such that , {, }, ?, ?,?
/?
?.
We define the splice operation to be ofthe form{?
?11,?12, ...,?1n?, ?
?21,?22, ...,?2n?, ..., ?
?m1,?m2, ...,?mn?}?{??11?12...
?1n?1 n+1?, ??21?22...
?2n?2 n+1?, ..., ??k1?k2...
?kn?k n+1?
}where: n ?
N is the number of slots (represented by ??)
in the patterns into whichthe roots letters should be inserted. m ?
N is the number of roots to be inserted. k ?
N is the number of patterns. ?ij,?ij are regular expressions (including regular expressions denotingFSRAs).The left set is a set of roots to be inserted into the slots in the right set of patterns.For the sake of brevity, ?i and ?i are used as shorthand notations for ?i1?i2...?i(n+1)and ?i1?i2...?in, respectively.Consider first the case where ?ij ?
?
?
{} for 1 ?
i ?
m and 1 ?
j ?
n and ?ij ??
?
{} for 1 ?
i ?
k and 1 ?
j ?
n + 1.
In this case the splice operation yields as a resultan FSRA-1 A = ?Q, q0,?,?, 3, ?, F?, such that L(A) = {?j1?i1?j2?i2...?jn?in?j(n+1) | 1 ?i ?
m , 1 ?
j ?
k}, where: Q = {q0, q1, ..., q2n+1} F = {q2n+1} ?
=({?ij| 1 ?
i ?
m , 1 ?
j ?
n} ?
{?ij| 1 ?
i ?
k , 1 ?
j ?
n + 1})\ {}73Computational Linguistics Volume 32, Number 1Figure 12Interdigitation FSRA ?
general. ?
= {?i| 1 ?
i ?
k} ?
{?i| 1 ?
i ?
m} ?
{#}. ?
= {(q0,?i1, W, 1,?i, q1)| 1 ?
i ?
k}?
{(q1,?i1, W, 2,?i, q2)| 1 ?
i ?
m}?
{(q2j?2,?ij, R, 1,?i, q2j?1)| 1 ?
i ?
k , 2 ?
j ?
n + 1}?
{(q2j?1,?ij, R, 2,?i, q2j)| 1 ?
i ?
m , 2 ?
j ?
n}This FSRA is shown in Figure 12.
It has 3 registers, where register 1 remembers thepattern and register 2 remembers the root.
Notice that the FSRA will have 3 registersand 2n + 2 states for any number of roots and patterns.
The number of arcs is k ?
(n +1) + m ?
n. In the (default) case of trilateral roots, for m roots and k patterns the resultingmachine has a constant number of states and O(k + m) arcs.In the general case, where ?ij and ?ij can be arbitrary regular expressions, theconstruction of the FSRA denoted by this operation is done in the same way as in thecase of circumfixes with two main adjustments.
The first is that in this case the finalFSRA is constructed by concatenating 2n + 1 intermediate FSRAs (n FSRAs for the nparts of the roots and n + 1 FSRAs for the n + 1 parts of the patterns).
The second is thathere, 2 registers are used to remember both the root and the pattern.
We suppress thedetailed description of the construction.Example 12Consider again the Hebrew roots r.$.m, p.&.l, p.q.d and the Hebrew patterns hitae,mia, and haaa.
The splice operation{?r, $, m?
?p, &, l?
?p, q, d?}
?
{?hitae??mia??haaa?
}74Cohen-Sygal and Wintner Non-Concatenative Morphologyyields the FSRA of Figure 13.
The -arc was added only for the convenience of thedrawing.It should be noted that like other processes of derivational morphology, Hebrewword formation is highly idiosyncratic: Not all roots combine with all patterns, andthere is no systematic way to determine when such combinations will be realizedin the language.
Yet, this does not render our proposed operators useless: One cannaturally characterize classes of roots and classes of patterns for which all the com-binations exist.
Furthermore, even when such a characterization is difficult to come by,the splice operator can be used, in combination with other extended regular expres-sion operators, to define complex expressions for generating the required language.This is compatible with the general approach for using finite-state techniques, imple-menting each phenomenon independently and combining them together using closureproperties.5.3 ReduplicationWe now return to the reduplication problem as was presented in example 3.
We extendthe finite-state registered model to efficiently accept Ln = {ww | w ?
?
?, |w| = n}, afinite instance of the general problem, which is arguably sufficient for describingreduplication in natural languages.
Using FSRAs as defined above does not improvespace efficiency, because a separate path for each reduplication is still needed.
Noticethat the different symbols in Ln have no significance except the pattern they create.Therefore, FSRAs are extended in order to be able to identify a pattern without actuallydistinguishing between different symbols in it.
The extended model, FSRA*, is obtainedfrom the FSRA-1 model by adding a new symbol, ?
*?, assumed not to belong to ?, andby forcing ?
to be equal to ?.
The ?*?
indicates equality between the input symbol andthe designated register content, eliminating the need to duplicate paths for differentsymbols.Figure 13Interdigitation example.75Computational Linguistics Volume 32, Number 1DefinitionLet ?
/?
?.
An FSRA* is an FSRA-1 where ?
= ?
(and thus includes ?#?)
and the tran-sition function is extended to be ?
?
Q ?
?
?
{, ?}
?
{R, W} ?
{0, 1, 2, .
.
.
, n ?
1} ??
?
{?}
?
Q.
The extended meaning of ?
is as follows: (s,?, R, i,?, t) ?
?, (s,?, W, i,?, t) ?
?
where ?,?
= ?
imply the same asbefore. (s,?, R, i, ?, t) ?
?
and (s, ?, R, i,?, t) ?
?
for ?
=  imply that if theautomaton is in state s, the input symbol is ?
and the content of the i-thregister is the same ?, then the automaton may enter state t. (s,?, W, i, ?, t) ?
?
and (s, ?, W, i,?, t) ?
?
for ?
=  imply that if theautomaton is in state s and the input symbol is ?, then the content of thei-th register is changed to ?, and the automaton may enter state t. (s, ?, R, i, ?, t) ?
?
implies that if the automaton is in state s, the inputsymbol is some ?
?
?
and the content of the i-th register is the same ?,then the automaton may enter state t. (s, ?, W, i, ?, t) ?
?
implies that if the automaton is in state s and the inputsymbol is some ?
?
?, then the content of the i-th register is changed to thesame ?, and the automaton may enter state t.With this extended model we can construct an efficient registered automaton forLn: The number of registers is n+1.
Registers 1, ..., n remember the first n symbols to beduplicated.
Figure 14 depicts an extended registered automaton that accepts Ln for n =4.
Notice that the number of states depends only on n and not on the size of ?.
Figure 15schematically depicts an extended registered automaton that accepts Ln for some n ?
N.The language {ww | |w| ?
n} for some n ?
N can be generated by a union of FSRA*,each one generating Ln for some i ?
n. Since n is usually small in natural languagereduplication, the resulting automaton is manageable, and in any case, considerablysmaller than the na?
?ve automaton.5.4 AssimilationIn example 7, FSRAs are used to model assimilation in Arabic nominative definitenouns.
Using the FSRA* model defined above, further reduction in the network sizecan be achieved.
The FSRA* of Figure 16 accepts all the nominative definite forms of theArabic nouns kitaab, qamar, and daftar (more nouns can be added in a similar way).Register 1 stores information about the actual form of the definite article, to ensure thatassimilation occurs when needed and only then.
Notice that in this FSRA, in contrast toFigure 14Reduplication for n = 4.76Cohen-Sygal and Wintner Non-Concatenative MorphologyFigure 15Reduplication ?
general case.the FSRA of Figure 8, the definite Arabic article al is not scanned as one symbol but astwo separate symbols.6.
Finite-state Registered TransducersWe extend the FSRA model to finite-state registered transducers (FSRT), denotingrelations over two finite alphabets.
The extension is done by adding to each transition anoutput symbol.
This facilitates an elegant solution to the problem of binary incrementorswhich was introduced in Example 4.Example 13Consider again the 32-bit incrementor example introduced in Example 4.
Recall thata sequential transducer for an n-bit binary incrementor would require 2n states and asimilar number of transitions.
Using the FSRT model, a more efficient n-bit transducercan be constructed.
A 4-bit FSRT incrementor is shown in Figure 17.
The first fourtransitions copy the input string into the registers, then the input is scanned (usingthe registers) from right to left (as the carry moves), calculating the result, and thelast four transitions output the result (in case the input is 1n, an extra 1 is added inthe beginning).
Notice that this transducer guarantees linear recognition time, sincefrom each state only one arc can be traversed in each step, even when there are-arcs.
In the same way, an n-bit transducer can be constructed for all n ?
N. Sucha transducer will have n registers, 3n + 1 states and 6n arcs.
The FSRT model solvesthe incrementor problem in much the same way it is solved by vectorized finite-stateFigure 16FSRA* for Arabic nominative definite nouns.77Computational Linguistics Volume 32, Number 1Figure 174-bit incrementor using FSRT.automata, but the FSRT solution is more intuitive and is based on existing finite-statetechniques.It is easy to show that FSRTs, just like FSRAs, are equivalent to their non-registeredcounterparts.
It immediately implies that FSRTs maintain the closure properties ofregular relations.
As in FSRAs, implementing the closure properties directly on FSRTsis essential for benefiting from their space efficiency.
The common operators such asunion, concatenation, etc., are implemented in the same ways as in FSRAs.
A directimplementation of FSRT composition is a na?
?ve extension of ordinary transducer com-position, based on the intersection construction of FSRAs.
We explicitly define theseoperations in Cohen-Sygal (2004).7.
Implementation and EvaluationIn order to practically compare the space and time performance of FSRAs and FSAs, wehave implemented the special operators introduced in Sections 4 and 5 for circumfix-ation and interdigitation, as well as direct construction of FSRAs.
We have comparedFSRAs with ordinary FSAs by building corresponding networks for circumfixation,interdigitation, and n-bit incrementation.
For circumfixation, we constructed networksfor the circumfixation of 1,043 Hebrew roots and 4 circumfixes.
For interdigitation weconstructed a network accepting the splicing of 1,043 roots into 20 patterns.
For n-bitincrementation we constructed networks for 10-bit, 50-bit, and 100-bit incrementors.Table 1 displays the size of each of the networks in terms of states, arcs, and actual filesize.78Cohen-Sygal and Wintner Non-Concatenative MorphologyTable 1Space comparison between FSAs and FSRAs.Operation Network type States Arcs Registers File sizeCircumfixation FSA 811 3,824 ?
47kB(4 circumfixes, 1,043 roots) FSRA 356 360 1 16kBInterdigitation FSA 12,527 31,077 ?
451kB(20 patterns, 1,043 roots) FSRA 58 3,259 2 67kB10-bit incrementor Sequential FST 268 322 ?
7kBFSRT 31 60 10 2kB50-bit incrementor Sequential FST 23,328 24,602 ?
600kBFSRT 151 300 50 8kB100-bit incrementor Sequential FST 176,653 181,702 ?
4.73MbFSRT 301 600 100 17kBTable 2Time comparison between FSAs and FSRAs.200 words 1,000 words 5,000 wordsCircumfixation FSA 0.01s 0.02s 0.08s(4 circumfixes, 1,043 roots) FSRA 0.01s 0.02s 0.09sInterdigitation FSA 0.01s 0.02s 1s(20 patterns, 1,043 roots) FSRA 0.35s 1.42s 10.11s10-bit incrementor Sequential FST 0.01s 0.05s 0.17sFSRT 0.01s 0.06s 0.23s50-bit incrementor Sequential FST 0.13s 0.2s 0.59sFSRT 0.08s 0.4s 1.6sClearly, FSRAs provide a significant reduction in the network size.
In particular, wecould not construct an n-bit incrementor FSA for any n greater than 100 as a result ofmemory problems, whereas using FSRAs we had no problem constructing networkseven for n = 50, 000.In addition, we compared the recognition times of the two models.
For that purpose,we used the circumfixation, interdigitation, 10-bit incrementation, and 50-bit incremen-tation networks to analyze 200, 1,000, and 5,000 words.
As can be seen in Table 2, timeperformance is comparable for the two models, except for interdigitation, where FSAsoutperform FSRAs by a constant factor.
The reason is that in this network the usage ofregisters is massive and thereby, there is a higher cost to the reduction of the networksize, in terms of analysis time.
This is an instance of the common tradeoff of time versusspace: FSRAs improve the network size at the cost of slower analysis time in some cases.When using finite-state devices for natural language processing, often the generatednetworks become too large to be practical.
In such cases, using FSRAs can make networksize manageable.
Using the closure constructions one can build desired networks ofreasonable size, and at the end decide whether to convert them to ordinary FSAs, iftime performance is an issue.8.
ConclusionsIn this work we introduce finite-state registered networks (automata and transducers),an extension of finite-state networks which adds a limited amount of memory, in the79Computational Linguistics Volume 32, Number 1form of registers, to each transition.
We show how FSRAs can be used to efficientlymodel several non-concatenative morphological phenomena, including circumfixation,root and pattern word formation in Semitic languages, vowel harmony, and limitedreduplication.The main advantage of finite-state registered networks is their space efficiency.
Weshow that every FSA can be simulated by an equivalent FSRA with three states andtwo registers.
For the motivating linguistic examples, we show a significant decreasein the number of states and the number of transitions.
For example, to account for allthe possible combinations of r roots and p patterns, an ordinary FSA requires O(r ?
p)arcs whereas an FSRA requires only O(r + p).
As a non-linguistic example, we showa transducer that computes n-bit increments of binary numbers.
While an ordinary(sequential) FST requires O(2n) states and arcs, an FSRT which guarantees linear recog-nition time requires only O(n) states and arcs.In spite of their efficiency, finite-state registered networks are equivalent, in termsof their expressive power, to ordinary finite state networks.
We provide an algorithm forconverting FSRAs to FSAs and prove the equivalence of the models.
Furthermore, weprovide direct constructions of the main closure properties of FSAs for FSRAs, includingconcatenation, union, intersection, and composition.In order for finite-state networks to be useful for linguistic processing, we providea regular expression language denoting FSRAs.
In particular, we provide a set ofextended regular expression operators that denote FSRAs and FSRTs.
We demonstratethe utility of the operators by accounting for a variety of complex morphological andphonological phenomena, including circumfixation (Hebrew and German), root-and-pattern (Hebrew), vowel harmony (Warlpiri), assimilation (Arabic), and limited redu-plication.
These dedicated operators can be used in conjunction with standard finitestate calculi, thereby providing a complete set of tools for the computational treatmentof non-concatenative morphology.This work opens a variety of directions for future research.
An immediate questionis the conversion of FSAs to FSRAs.
While it is always possible to convert a given FSAto an FSRA (simply add one register which is never used), we believe that it is possibleto automatically convert space inefficient FSAs to more compact FSRAs.
A pre-requisiteis a clear understanding of the parameters for minimization: These include the numberof states, arcs, and registers, and the size of the register alphabet.
For a given FSRA, thenumber of states can always be reduced to a constant (theorem 3) and registers can bedone away with entirely (by converting the FSRA to an FSA, Section 3.1).
In contrast,minimizing the number of arcs in an FSRA is NP-hard (Section 3.4).
A useful conversionof FSAs to FSRAs must minimize some combination of these parameters, and while itmay be intractable in general, it can be practical in many special cases.
In particular,the case of finite languages (acyclic FSAs) is both of practical importance and ?
weconjecture ?
can result in good compaction.More work is also needed in order to establish more properties of FSRTs.
In particu-lar, we did not address issues such as sequentiality or sequentiability for this model.Similarly, FSRA?
can benefit from further research.
All the closure constructions forFSRA?s can be done in a similar way to FSRAs, with the exception of intersection.
For in-tersection, we believe that the use of predicates (van Noord and Gerdemann 2001b) canbe beneficial.
Furthermore, the use of predicates can be beneficial for describing naturallanguage reduplication where the reduplication is not as bounded as the example wedeal with in this work.
In addition, the FSRA?
model can be extended into transducers.Finally, in Section 7 we discuss an implementation of FSRAs.
Although we haveused this system to construct networks for several phenomena, we are interested in80Cohen-Sygal and Wintner Non-Concatenative Morphologyconstructing a network for describing the complete morphology of a natural languagecontaining many non-concatenative phenomena, e.g., Hebrew.
A morphological ana-lyzer for Hebrew, based on finite-state calculi, already exists (Yona and Wintner 2005),but is very space-inefficient and, therefore, hard to maintain.
It would be beneficial tocompact such a network using FSRTs, and to inspect the time versus space tradeoff onsuch a comprehensive network.AcknowledgmentsWe are grateful to Dale Gerdemann for hishelp and inspiration.
We thank Victor Harnikand Nissim Francez for their comments onan earlier version of this paper.
We are alsothankful to the anonymous reviewers, whosecomments helped substantially to improvethis article.
This research was supported byThe Israel Science Foundation (grantno.
136/01).ReferencesBeesley, Kenneth R. 1998.
Constrainingseparated morphotactic dependencies infinite-state grammars.
In Proceedings ofFSMNLP-98, pages 118?127, Bilkent,Turkey.Beesley, Kenneth R. and Lauri Karttunen.2000.
Finite-state non-concatenativemorphotactics.
In Proceedings of theFifth Workshop of the ACL Special InterestGroup in Computational Phonology,SIGPHON-2000, pages 1?12,Luxembourg.Beesley, Kenneth R. and Lauri Karttunen.2003.
Finite-State Morphology.
CSLIPublications.Blank, Glenn D. 1985.
A new kind offinite-state automaton: Register vectorgrammar.
In Proceedings of the InternationalJoint Conference on Artificial Intelligence,pages 749?755, UCLA.Blank, Glenn D. 1989.
A finite and real-timeprocessor for natural language.Communications of the ACM,32(10):1174?1189.Cohen-Sygal, Yael.
2004.
Computationalimplementation of non-concatenativemorphology.
Master?s thesis, Departmentof Computer Science, University of Haifa,Israel.Holzer, Markus and Martin Kutrib.
2002.State complexity of basic operations onnondeterministic finite automata.
InJean-Marc Champarnaud and DenisMaurel, editors, Implementation andApplication of Automata, 7th InternationalConference, CIAA 2002, volume 2608 ofLecture Notes in Computer Science,Springer, pages 148?157.Kaminski, Michael and Nissim Francez.1994.
Finite memory automata.
TheoreticalComputer Science, 134(2):329?364.Kaplan, Ronald M. and Martin Kay.
1994.Regular models of phonological rulesystems.
Computational Linguistics,20(3):331?378.Karttunen, Lauri, Jean-Pierre Chanod,Gregory Grefenstette, and Anne Schiller.1996.
Regular expressions for languageengineering.
Natural Language Engineering,2(4):305?328.Kataja, Laura and Kimmo Koskenniemi.1988.
Finite-state description of Semiticmorphology: A case study of ancientAkkadian.
In Proceedings of COLING 88,International Conference on ComputationalLinguistics, pages 313?315, Budapest.Kay, Martin.
1987.
Nonconcatenativefinite-state morphology.
In Proceedings ofthe Third Conference of the European Chapterof the Association for ComputationalLinguistics, pages 2?10, Copenhagen,Denmark.Kiraz, George Anton.
2000.
Multitierednonlinear morphology using multitapefinite automata: A case study on Syriacand Arabic.
Computational Linguistics,26(1):77?105.Kleene, S. C. 1956.
Representation of eventsin nerve nets and finite automata.
In C. E.Shannon and J. McCarthy, editors,Automata Studies.
Princeton UniversityPress, pages 3?42.Kornai, Andra?s.
1996.
Vectorized finite-stateautomata.
In Proceedings of the Workshop onExtended Finite-State Models of Languages inthe 12th European Conference on ArtificialIntelligence, pages 36?41, Budapest.Koskenniemi, Kimmo.
1983.
Two-LevelMorphology: A General Computational Modelfor Word-Form Recognition and Production.The Department of General Linguistics,University of Helsinki.Krauwer, Steven and Louis des Tombe.
1981.Transducers and grammars as theories oflanguage.
Theoretical Linguistics, 8:173?202.Lavie, Alon, Alon Itai, Uzzi Ornan, and MoriRimon.
1988.
On the applicability oftwo-level morphology to the inflection ofHebrew verbs.
Technical Report 513,81Computational Linguistics Volume 32, Number 1Department of Computer Science,Technion, 32000 Haifa, Israel.Mohri, Mehryar.
1996.
On some applicationsof finite-state automata theory to naturallanguage processing.
Natural LanguageEngineering, 2(1):61?80.Mohri, Mehryar.
2000.
Genericepsilon-removal algorithm for weightedautomata.
In Sheng Yu and Andrei Paun,editors, 5th International Conference, CIAA2000, volume 2088, Springer-Verlag,pages 230?242.Mohri, Mehryar, Fernando Pereira, andMichael Riley.
2000.
The design principlesof a weighted finite-state transducerlibrary.
Theoretical Computer Science,231(1):17?32.Nash, David.
1980.
Topics in WarlpiriGrammar.
Ph.D. thesis, MassachusettsInstitute of Technology.Sproat, Richard W. 1992.
Morphology andComputation.
MIT Press, Cambridge, MA.van Noord, Gertjan and Dale Gerdemann.2001a.
An extendible regular expressioncompiler for finite-state approaches innatural language processing.
In O. Boldtand H. Ju?rgensen, editors, AutomataImplementation, 4th International Workshopon Implementing Automata, WIA?99,Potsdam, Germany, Revised Papers,number 2214 in Lecture Notes in ComputerScience.
Springer.van Noord, Gertjan and Dale Gerdemann.2001b.
Finite state transducers withpredicates and identity.
Grammars,4(3):263?286.Walther, Markus.
2000a.
Finite-statereduplication in one-level prosodicmorphology.
In Proceedings ofthe First Conference of the NorthAmerican Chapter of the Associationfor Computational Linguistics,pages 296?302, Seattle.Walther, Markus.
2000b.
Temiarreduplication in one-level prosodicmorphology.
In Proceedings ofSIGPHON, Workshop on Finite-StatePhonology, pages 13?21, Luxembourg.Yona, Shlomo and Shuly Wintner.2005.
A finite-state morphologicalgrammar of Hebrew.
In Proceedings ofthe ACL-2005 Workshop on ComputationalApproaches to Semitic Languages,Ann Arbor.82
