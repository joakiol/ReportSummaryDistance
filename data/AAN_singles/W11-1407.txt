Proceedings of the Sixth Workshop on Innovative Use of NLP for Building Educational Applications, pages 56?64,Portland, Oregon, 24 June 2011. c?2011 Association for Computational LinguisticsAutomatic Gap-fill Question Generation from Text BooksManish Agarwal and Prashanth MannemLanguage Technologies Research CenterInternational Institute of Information TechnologyHyderabad, AP, India - 500032{manish.agarwal,prashanth}@research.iiit.ac.inAbstractIn this paper, we present an automatic questiongeneration system that can generate gap-fillquestions for content in a document.
Gap-fillquestions are fill-in-the-blank questions withmultiple choices (one correct answer and threedistractors) provided.
The system finds the in-formative sentences from the document andgenerates gap-fill questions from them by firstblanking keys from the sentences and then de-termining the distractors for these keys.
Syn-tactic and lexical features are used in this pro-cess without relying on any external resourceapart from the information in the document.We evaluated our system on two chapters ofa standard biology textbook and presented theresults.1 IntroductionGap-fill questions are fill-in-the-blank questions,where one or more words are removed from asentence/paragraph and potential answers are listed.These questions, being multiple choice ones, areeasy to evaluate.
Preparing these questions manu-ally will take a lot of time and effort.
This is whereautomatic gap-fill question generation (GFQG)from a given text is useful.1.
A bond is the sharing of a pair of va-lence electrons by two atoms.
(a) Hydrogen (b) Covalent (c) Ionic (d) Double(correct answer: Covalent)In a gap-fill question (GFQ) such as the oneabove, we refer to the sentence with the gap as thequestion sentence (QS) and the sentence in the textthat is used to generate the QS as the gap-fill sen-tence (GFS).
The word(s) which is removed from aGFS to form the QS is referred to as the key whilethe three alternatives in the question are called asdistractors, as they are used to distract the studentsfrom the correct answer.Previous works in GFQG (Sumita et al, 2005;John Lee and Stephanie Seneff, 2007; Lin et al,2007; Pino et al, 2009; Smith et al, 2010) havemostly worked in the domain of English languagelearning.
Gap-fill questions have been generated totest student?s knowledge of English in using the cor-rect verbs (Sumita et al, 2005), prepositions (JohnLee and Stephanie Seneff, 2007) and adjectives (Linet al, 2007) in sentences.
Pino et al (2009) andSmith et al (2010) have generated GFQs to teachand evaluate student?s vocabulary.In this paper, we move away from the domainof English language learning and work on generat-ing gap-fill questions from the chapters of a biol-ogy textbook used for Advanced Placement (AP) ex-ams.
The aim is to go through the textbook, identifyinformative sentences1 and generate gap-fill ques-tions from them to aid students?
learning.
The sys-tem scans through the text in the chapter and iden-tifies the informative sentences in it using featuresinspired by summarization techniques.
Questionsfrom these sentences (GFSs) are generated by firstchoosing a key in each of these and then finding ap-propriate distractors for them from the chapter.Our GFQG system takes a document with its titleas an input and produces a list of gap-fill questions as1A sentence is deemed informative if it has the relevantcourse knowledge which can be questioned.56output.
Unlike previous works (Brown et al, 2005;Smith et al, 2010) it doesn?t use any external re-source for distractor selection, making it adaptableto text from any domain.
Its simplicity makes it use-ful not only as an aid for teachers to prepare gap-fillquestions but also for students who need an auto-matic question generator to aid their learning from atextbook.2 Data UsedA Biology text book Campbell Biology, 6th Edi-tion has been used for work in this paper.
We havereported results of our system on 2 chapters (thestructure and function of macromolecules and anintroduction to metabolism ) of unit 1.
Each chaptercontains sections and subsections with their respec-tive topic headings.
Number of subsections, sen-tences, words per sentence in each chapter are (25,416, 18.3) and (32, 423, 19.5) respectively.
Eachsubsection is taken as a document.
The chapters aredivided into documents and each document is usedfor GFQG independently.3 ApproachGiven a document, the gap-fill questions are gen-erated from it in three stages: sentence selection,key selection and distractor selection.
Sentence se-lection involves identifying informative sentences inthe document which can be used to generate a gap-fill question.
These sentences are then processed inthe key selection stage to identify the key on whichto ask the question.
In the final stage, the distrac-tors for the selected key are identified from the givenchapter by searching for words with the same con-text as that of the key.In each stage, the system identifies a set of candi-dates (i.e.
all sentences in the document in stage I,words in the previously selected sentence in stage IIand words in the chapter in stage III) and extracts aset of features relevant to the task.
Weighted sum ofextracted features (see equation 1) is used to scorethese candidates, with the weights for the featuresin each of the three steps assigned heuristically.
Asmall development data has been used to tune thefeature weights.score =n?i=0wi ?
fi (1)In equation 1, fi denotes the feature and wi denotesthe weight of the feature fi.
The overall architectureof the system is shown in Figure 1.SentenceSelectionsentence (GFS)Gap?fillselection&DistractorsselectionGAP?FILLQuestionGFSsDocumentChapterKeyFigure 1: System architectureIn earlier approaches to generating gap-fill ques-tions (for English language learning), the keys in atext were gathered first (or given as input in somecases) and all the sentences containing the key wereused to generate the question.
In domains wherelanguage learning is not the aim, a gap-fill questionneeds an informative sentence and not just any sen-tence with the desired key present in it.
For this rea-son, in our work, sentence selection is performed be-fore key selection.3.1 Sentence SelectionA good GFS should be (1) informative and (2)gap-fill question-generatable.
An informative sen-tence in a document is one which has relevantknowledge that is useful in the context of the docu-ment.
A sentence is gap-fill question-generatable ifthere is sufficient context within the sentence to pre-dict the key when it is blanked out.
An informativesentence might not have enough context to generatea question from and vice versa.The sentence selection module goes through allthe sentences in the documents and extracts a set offeatures from each of them.
These features are de-fined in such a way that the two criterion definedabove are accounted for.
Table 1 gives a summaryof the features used.First sentence: f(si) is a binary feature to checkwhether the sentence si is the first sentence of thedocument or not.
Upon analysing the documents inthe textbook, it was observed that the first sentencein the document usually provides a summary of thedocument.
Hence, f(si) has been used to make useof the summarized first sentence of the document.57Feature Symbol Description Criterionf(si) Is si the first sentence of the document?
Isim(si) No.
of tokens common in si and title / length(si) I, Gabb(si) Does si contain any abbreviation?
Isuper(si) Does si contain a word in its superlative degree?
Ipos(si) si?s position in the document (= i) Gdiscon(si) Is si beginning with a discourse connective?
Gl(si) Number of words in si Gnouns(si) No.
of nouns in si / length(si) Gpronouns(si) No.
of pronouns in si / length(si) GTable 1: Feature set for Sentence Selection (si: ith sen-tence of the document; I: to capture informative sen-tences; G: to capture the potential candidate for gener-ating a GFQs)Common tokens: sim(si) is the count of words(nouns and adjectives) that the sentence and the titleof the document have in common.
A sentence withwords from the title in it is important and is a goodcandidate to ask a question using the common wordsas the key.2.
The different states of potential energy thatelectrons have in an atom are called energylevels, or electron shells.
(Title: The EnergyLevels of Electrons)For example sentence 2, value of the feature is3/19 (common words:3, sentence length:19) andgenerating gap-fill question using energy, levels orelectrons as the key will be useful.Abbreviations and Superlatives: abb(si),super(si) features capture those sentences whichcontain abbreviations and words in superlative de-gree respectively.
The binary features determine thedegree of the importance of a sentence in terms ofthe presence of abbreviations and superlatives.3.
In living organisms, most of the strongestchemical bonds are covalent ones.For example, in sentence 3, presence of strongestmakes sentence more informative and useful forgenerating a gap-fill question.Sentence position: pos(si) is position of thesentence si, in the document (= i).
Since topic ofthe document is elaborated in the middle of thedocument, the sentences occurring in the middle ofthe document are less important for the GFSs thanthose which occur either at the start or the end of thedocument.
In order to use the above observation,the module uses this feature.Discourse connective at the beginning:discon(si)?s value is 1 if first word of si is adiscourse connective2 and 0 otherwise.
Discourseconnective at the beginning of a sentence indicatesthat the sentence might not have enough context fora QS to be understood by the students.4.
Because of this, it is both an amine and a car-boxylic acid.In example 4, after selecting amine and car-boxylic as a key, QS will be left with insufficientcontext to answer.
Thus binary feature, discon(si),is used.Length: l(si) is the number of words in thesentence.
It is important to note that a very shortsentence might generate an unanswerable questionbecause of short context and a very long sentencemight have enough context to make the questiongenerated from it trivial.Number of nouns and pronouns: Featuresnouns(si) and pronouns(si) represent the amountof context present in a sentence.
More number ofpronouns in a sentence reduces the contextual infor-mation, instead more number of nouns increases thenumber of potential keys to ask a gap-fill questionon.Four sample GFSs are shown in Table 3 with theirdocument?s titles.3.2 Key SelectionFor each sentence selected in the previous stage,the key selection stage identifies the most appropri-ate key from the sentence to ask the question on.Previous works in this area, Smith et al (2010)take keys as an input and, Karamanis et al (2006)and Mitkov et al (2006) select keys on the basis ofterm frequency and regular expressions on nouns.Then they search for sentences which contain thatparticular key in it.
Since their approaches generategap-fill questions only with one blank, they couldend up with a trivial GFQ, especially in case of con-junctions.2because, since, when, thus, however, although, for exampleand for instance connectives have been included.58(A)DT       JJS       NNS       IN    NN         NNS      VBP       JJ         NNS   CC        JJ    NNSpotential keys selection[The  strongest   kind]     of    [chemical  bonds]    are    [covalent  bond   and    ionic    bond].
[The  strongest  kind]  of   [ chemical  bonds]  are  [ covalent  bond  and   ionic  bond] .
(B)Figure 2: Generating potential key?s list, (key-list) of strongest, chemical and covalent + ionic.5.
Somewhere in the transition from molecules tocells, we will cross the blurry boundary be-tween nonlife and life.For instance in example sentence 5, selecting onlyone of non-life and life makes the question trivial.This is an other reason for performing sentence se-lection before key selection.
Our system can gen-erate GFQs with multiple blanks unlike previousworks described above.Our approach of key selection from a GFS is twostep process.
In the first step the module generatesa list of potential keys from the GFS (key-list) andin the second step it selects the best key from thiskey-list.3.2.1 Key-list formationA list of potential keys is created in this step usingthe part of speech (POS) tags of words and chunksof the sentence in the following manner:1.
Each sequence of words in all the noun chunksis pushed into key-list.
In figure 2(A), the threenoun chunks the strongest kind, chemical bondand covalent bond and ionic bond are pushedinto the key-list.2.
For each sequence in the key-list, the most im-portant word(s) is selected as the potential keyand the other words are removed.
The most im-portant word in a noun chunk in the context ofGFQG in biology domain is a cardinal, adjec-tive and noun in that order.
In case where thereare multiple nouns, the first noun is chosen asthe potential key.
If the noun chunk is a NPcoordination, both the conjuncts are selected asa single potential key making it a case of mul-tiple gaps in QS.
In Figure 2(B) potential keysstrongest, chemical and covalent + ionic are se-lected from the noun chunks by taking the orderof importance into account.An automatic POS tagger and a noun chunker hasbeen used to process the sentences selected in thefirst stage.
It was observed that if words of a keyare spread across a chunk then there might not beenough context left in QS to answer the question.The noun chunk boundaries ensure that the sequenceof words in the potential keys are not disconnected.6.
Hydrogen has 1 valence electron in the firstshell, but the shell?s capacity is 2 electrons.Any element of the key-list which occurs morethan once in the GFS is discarded as a potential keyas it more often than not generates a trivial question.For example, in sentence 6 selecting any one of thetwo electron as a key generates an easy gap-fill ques-tion.7.
In contrast , trypsin , a digestive enzyme resid-ing in the alkaline environment of the intestine, has an optimal pH of .
(a) 6 (b) 7 (c) 8 (d) 9 (correct answer: 8)If cardinals are present in a GFS, the first one is cho-sen as its key directly and a gap-fill question has beengenerated (see example 7).3.2.2 Best Key selectionIn this step three features, term(keyp),title(keyp) and height(keyp), described in Ta-ble 2, are used to select the best key from the key-list.Feature Symbol Descriptionterm(keyp)Number of occurrences of thekeyp in the document.title(keyp)Does title containkeyp ?height(keyp)height of the keyp in thesyntactic tree of the sentence.Table 2: Feature set for key selection (potential key,keyp is an element of key-list)Term frequency: term(keyp) is number of oc-currences of the keyp in the document.
term(keyp)59is considered as a feature to give preference to thepotential keys with high frequency.In title: title(keyp) is a binary feature to checkwhether keyp is present in the title of the documentor not.
A common word of GFS and the title of thedocument serves as a better key for gap-fill questionthan the ones that are not present in both.Height: height(keyp) denotes the height 3 of thekeyp in the syntactic tree of the sentence.
Heightgives an indirect indication of the importance of theword.
It also denotes the amount of text in the sen-tence that modifies the word under consideration.F(0)                G(0)D (1)                E (0)A(3)C(2)B(0)Figure 3: Height feature: node (height)An answerable question should have enough con-text left after the key blanked out.
A word withgreater height in dependency tree gets more scoresince there is enough context from its dependentwords in the syntactic tree to predict the word.
Forexample in Figure 3, node C?s height is two and thewords in the dashed box in its subtree provide thecontext to answer a question on C.The score of each potential key is normalized bythe number of words present in it and the best key ischosen based on the scores of potential keys in key-list.
Table 3 shows the selected keys (red colored)for sample GFSs.3.3 Distractor SelectionKaramanis et al (2006) defines a distractor as,an appropriate distractor is a concept semanticallyclose to the key which, however, cannot serve as theright answer itself.For distractor selection, Brown et al (2005) andSmith et al (2010) used WordNet, Kunichika et3The height of a tree is the length of the path from the deep-est node in the tree to the root.No.
Selected keys (red colored)1An electron having a certain discrete amount of energy issomething like a ball on a staircase.
(The Energy Levels of Electrons)2Lipids are the class of large biological molecules that does notinclude polymer.
(Lipids?Diverse Hydrophobic Molecules)3A DNA molecule is very long and usually consists of hundredsor thousands of genes.
(Nucleic acids store and transmit hereditary information)4The fatty acid will have a kink in its tail wherever a double bondoccurs.
(Fats store large amounts of energy)Table 3: Selected keys for each sample GFSal.
(2002) used their in-house thesauri to retrievesimilar or related words (synonyms, hypernyms, hy-ponyms, antonyms, etc.).
However, their approachescan?t be used for those domains which don?t haveontologies.
Moreover, Smith et al (2010) do not se-lect distractors based on the context of the keys.
Forexample, in the sentences 8 and 9, the key book oc-curs in two different senses but same set of distrac-tors will be generated by them.8.
Book the flight.9.
I read a book.Feature Symbol Descriptioncontext(distractorp , measure of contextual similaritykeys) of distractorp and the keysin which they are presentsim(distractorp , Dice coefficient score betweenkeys) GFS and the sentencecontaining the distractorpdiff(distractorp , difference in term frequencieskeys) of distractorp and keysin the chapterTable 4: Feature set for distractor selection (keys is theselected key for a GFS, distractorp is the potential dis-tractor for the keys)So a distractor should come from the same con-text and domain, and should be relevant.
It is alsoclear from the above discussion that only term fre-quency formula alone will not work for selectionof distractors.
Our module uses features, shown inTable 4, to select three distractors from the set ofall potential distractors.
Potential distractors are thewords in the chapter which have the same POS tagas that of the key.60Contextual similarity: context(distractorp,keys) gets the contextual similarity score of apotential distractor and the keys on the basisof context in which they occur in their respectivesentences.
Value of the feature depends on howsimilar are the key and the potential distractorcontextually.
The previous two and next two wordsalong with their POS tags are compared to calculatethe score.Sentence Similarity: sim(distractorp, keys)feature value represents similarity of the sentencesin which the keys and the distractorp occur in.Dice Coefficient (Dice, 1945) (equation 2) has beenused to assign weights to those potential distractorswhich come from sentences similar to GFS becausea distractor coming from a similar sentence will bemore relevant.dice coefficient(s1, s2) =2?
commontokensl(s1) + l(s2)(2)Difference in term frequencies: Feature,diff (distractorp, keys) is used to find distractorswith comparable importance to the key.
Term fre-quency of a word represents its importance in thetext and words with comparable importance mightbe close in their semantic meanings.
So, a smallerdifference in the term frequencies is preferable.key Distractorsenergy charge, mass, waterpolymer acid, glucose, knowDNA RNA, branch, specifickink available, start, methodTable 5: Selected distractors for selected keys, shown inTable 310.
Electrons have a negative charge, the unequalsharing of electrons in water causes the oxy-gen atom to have a partial negative charge andeach hydrogen atom a partial positive charge.A word that is present in the GFS would not beselected as a distractor.
For example in sentence 10,if system selects oxygen as a key then hydrogen willnot be considered as a distractor.
Table 5 showsselected three distractors for each selected keys.4 Evaluation and ResultsTwo chapters of the biology book are selected fortesting and top 15% candidates are selected by threemodules (sentence selection, key selection and dis-tractor selection).
The modules were manually eval-uated independently by two biology students withgood English proficiency.
Since in current systemany kind of post editing or manual work is avoided,comparison of efficiency in manual and automaticgeneration is not needed unlike Mitkov and Ha etal.
(2003).4.1 Sentence SelectionThe output of the sentence selection module isa list of sentences.
The evaluators check if eachof these sentences are good GFSs (informative andgap-fill question-generatable) or not and binaryscoring is done.
Evaluators are asked to evaluateselected sentences independently, whether they areuseful for learning and answerable, or not.The cov-erage of the selected sentences w.r.t the documenthas not been evaluated.Chapter-5 Chapter-6 TotalNo.
of 390 423 813SentencesNo.
of 55 65 120Selected SentencesNo.
of Good 51 59 110GFSs (Eval-1)No.
of Good 44 51 95GFSs (Eval-2)Table 6: Evaluation of Sentence SelectionEvaluator-1 and 2 rated 91.66% and 79.16% ofsentences as good potential candidates for gap-fillquestion respectively with 0.7 inter evaluator agree-ment (Cohen?s kappa coefficient).
Table 6 showsthe results of sentence selection for individualchapters.
Upon analysing the bad GFSs, we foundtwo different sources of errors.
The first source isthe feature first sentence and the second is lack ofused in sentence selection module.First sentence: Few documents in the data hadeither a general statement or a summary of the pre-vious section as the first sentence and the first sen-tence feature contributed to their selection as GFSeven though they aren?t good GFSs.11.
An understanding of energy is as importantfor students of biology as it is for students ofphysics, chemistry and engineering.For example, the system generated a gap-fill61question on example 11 which isn?t a good GFS atall even though it occurs as the first sentence in thedocument.Less no.
of features: Features like common to-kens, superlative and abbreviation, discourse con-nective at the beginning and number of pronounswas useful in selecting informative sentences fromthe documents.
However, in absence of these fea-tures in the document, module has selected the GFSson the basis of only two features, length and positionof the sentence.
In those cases Evaluators rated fewGFSs as bad.12.
Here is another example of how emergent prop-erties result from a specific arrangement ofbuilding components.For example, sentence 12 rated as a bad GFS bythe evaluators.
So more features are need to be toused to avoid this kind of errors.13.
A molecule has a characteristic size and shape.Apart from these we also found few cases wherethe context present in the GFS wasn?t sufficient toanswer the question although those sentences wereinformative.
In the above example 13, size andshape were selected as the key that makes gap-fillquestion unanswerable because of short context.4.2 Key SelectionOur evaluation characterizes a key into two cat-egories namely good (G) and bad (B).
Evaluator-1and 2 found that 94.16% and 84.16% of the keysare good respectively with inter evaluator agreement0.75.
Table 7 shows the results of keys selection forindividual chapters.Chap-5 Chap-6 TotalG B G B G BEval-1 50 5 63 2 113 7Eval-2 50 5 51 14 101 19Table 7: Evaluation of Key(s) Selection: Chap: Chap-ter, Eval: Evaluator, G and B are for good and bad keyrespectively14.
Carbon has a total of 6 electrons , with 2 in thefirst electron shell and 4 in the second shell.We observed that selection of first cardinal as keyis not always correct.
For example, in sentence 14selection of 6 as the key generated trivial GFQ.4.3 Distractors SelectionOur system generates four alternatives for eachgap-fill question, out of which three are distrac-tors.
To evaluate the distractors?
quality, evaluatorsare asked to substitute the distractor in the gap andcheck the readability and semantic meaning of theQS to classify the distractor as good or bad.
Eval-uators rate 0, 1, 2 or 3 depending on the number ofgood distractors in the GFQ (for example, questionsthat are rated 2 have two good distractors and onebad distractor).15.
An electron having a certain discrete amount ofis something like a ball on a staircase.
(a) charge (b) energy (c) mass (d) water(Class: 3)16.
Lipids are the class of large biologicalmolecules that does not include .
(a) acid (b)polymer (c) glucose (d) know(Class: 2)17.
A molecule is very long and usuallyconsists of hundreds or thousands of genes.
(a) DNA (b) RNA (c) specific (d) branch(Class: 1)18.
The fatty acid will have a in its tailwherever a double bond occurs .
(a) available (b) method (c) kink (d) start(Class: 0)Examples of gap-fill questions generated by oursystem are shown above (red colored alternatives aregood distractors, blue colored ones are the correctanswers for the questions and the black ones are baddistractors).Chap-5 Chap-6 TotalClass 0 1 2 3 0 1 2 3 0 1 2 3Eval-1 21 19 12 3 8 31 21 5 29 50 33 8Eval-2 20 19 13 3 9 25 28 3 29 44 41 6Table 8: Evaluation of Distractor Selection (Before anycorrections)Table 8 shows the human evaluated results forindividual chapter.
According to both evaluator-1 and evaluator-2, 75.83% of the cases the systemfinds useful gap-fill questions with 0.67 inter evalu-ator agreement.
Useful gap-fill questions are thosewhich have at least one good distractor.
60.05% and67.72% test items are answered correctly by Evalu-ator 1 and 2 respectively.62We observed that when a key has more than oneword, distractors?
quality reduces because every to-ken in a distractor must be comparably relevant.Small chapter size also effects the number of gooddistractors because distractors are selected from thechapter text.In our work, as we only considered syntactic andlexical features for distractor selection, the selecteddistractors could be semantically conflicting withthemselves or with the key.
For example, due tothe lack of semantic features in our method a hyper-nym of the key could find way into the distractorslist thereby providing a confusing list of distractorsto the students.
In the example question 1 in section1, chemical which is the hypernym of covalent andionic could prove confusing if its one of the choicesfor the answer.
Semantic similarity measures needto be used to solve this problem.5 Related workGiven the distinct domains in which our systemand other systems were deployed, a direct com-parison of evaluation scores could be misleading.Hence, in this section we compare our approach withprevious approaches in this area.Smith et al (2010) and Pino et al (2009) usedgap-fill questions for vocabulary learning.
Smith etal.
(2010) present a system, TEDDCLOG, which au-tomatically generates draft test items from a corpus.TEDDCLOG takes the key as input.
It finds dis-tractors from a distributional thesaurus.
They got53.33% (40 out of 75) accuracy after post editing(editing either in carrier sentence (GFS) or in dis-tractors) in the generated gap-fill questions.Pino et al (2009) describe a baseline technique togenerate cloze questions (gap-fill questions) whichuses sample sentences from WordNet.
They then re-fine this technique with linguistically motivated fea-tures to generate better questions.
They used theCambridge Advanced Learners Dictionary (CALD)which has several sample sentences for each senseof a word for stem selection (GFS).
The new strat-egy produced high quality cloze questions 66% ofthe time.Karamanis et al (2006) report the results of a pi-lot study on generating Multiple-Choice Test Items(MCTI) from medical text which builds on the workof Mitkov et al (2006).
Initially key set is enlargedwith NPs featuring potential key terms as their headsand satisfying certain regular expressions.
Then sen-tences having at least one key are selected and theterms with the same semantic type in UMLS are se-lected as distractors.
In their manual evaluation, thedomain experts regarded a MCTI as unusable if itcould not be used in a test or required too much revi-sion to do so.
The remaining items were consideredto be usable and could be post edited by the expertsto improve their content and readability or replaceinappropriate distractors.
They have reported 19%usable items generated from their system and afterpost editing stems accuracy jumps to 54%.However, our system takes a document and pro-duces a list of GFQs by selecting informative sen-tences from the document.
It doesn?t use any exter-nal resources for distractors selection and finds themin the chapter only that makes it adaptable for thosedomains which do not have ontologies.6 Conclusions and Future WorkOur GFQG system, selects most informative sen-tences of the chapters and generates gap-fill ques-tions on them.
Syntactic features helped in quality ofgap-fill questions.
We look forward to experiment-ing on larger data by combining the chapters.
Eval-uation of course coverage by our system and use ofsemantic features will be part of our future work.AcknowledgementsWe would like to thank Avinesh Polisetty andSudheer Kolachina from LTRC, IIIT-Hyderabad fortheir helpful discussions and pointers during thecourse of this work.
Thanks also to the anonymousreviewers for useful feedback.ReferencesEiichiro Sumita, Fumiaki Sugaya, and Seiichi Yamamoto2005.
Measuring Non-native Speakers Proficiency ofEnglish by Using a Test with Automatically-GeneratedFill-in-the-Blank Questions, 2nd Wkshop on BuildingEducational Applications using NLP, Ann Arbor.John Lee and Stephanie Seneff.
2007.
Automatic Gen-eration of Cloze Items for Prepositions, CiteSeerX- Scientific Literature Digital Library and SearchEngine [http://citeseerx.ist.psu.edu/oai2] (UnitedStates).Lin, Y. C., Sung, L. C., Chen and M. C. 2007.
An63Automatic Multiple-Choice Question GenerationScheme for English Adjective Understanding, CCE2007 Workshop Proc.
of Modeling, Management andGeneration of Problems / Questions in eLearning, pp.137-142.Juan Pino, Michael Heilman and Maxine Eskenazi.2009.
A Selection Strategy to Improve Cloze QuestionQuality, Wkshop on Intelligent Tutoring Systems forIll-Defined Domains.
9th Int.
Conf.
on ITS.Simon Smith, P.V.S Avinesh and Adam Kilgarriff.
2010.Gap-fill Tests for Language Learners: Corpus-DrivenItem Generation .Jonathan C. Brown, Gwen A. Frishkoff, Maxine Es-kenazi.
2005.
Automatic Question Generation forVocabulary Assessment, Proc.
of HLT/EMNLP ?05,pp.
819-826.Nikiforos Karamanis, Le An Ha and Ruslan Mitkov.2006 Generating Multiple-Choice Test Iterms fromMedical Text: A Pilot Study, In Proceedings of INLG2006, Sydney, Australia.Ruslan Mitkov, Le An Ha and Nikiforos Karamanis.2006 A computer-aided environment for generatingmultiple-choice test items, Natural Language Engi-neering 12(2): 177-194Hidenobu Kunichika, Minoru Urushima,Tsukasa Hi-rashima and Akira Takeuchi.
2002.
A ComputationalMethod of Complexity of Questions on Contents ofEnglish Sentences and its Evaluation, In: Proc.
ofICCE 2002, Auckland, NZ, pp.
97101 (2002).Lee Raymond Dice.
1945.
Measures of the Amount ofEcologic Association Between SpeciesRuslan Mitkov and Le An Ha.
2003 Computer-aidedgeneration of multiple-choice tests, Proceedingsof the HLT/NAACL 2003 Workshop on Buildingeducational applications using Natural LanguageProcessing.
Edmonton, Canada, 17-22.64
