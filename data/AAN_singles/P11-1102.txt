Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 1018?1026,Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational LinguisticsRecognizing Authority in Dialogue with an Integer Linear ProgrammingConstrained ModelElijah MayfieldLanguage Technologies InstituteCarnegie Mellon UniversityPittsburgh, PA 15213elijah@cmu.eduCarolyn Penstein Rose?Language Technologies InstituteCarnegie Mellon UniversityPittsburgh, PA 15213cprose@cs.cmu.eduAbstractWe present a novel computational formula-tion of speaker authority in discourse.
Thisnotion, which focuses on how speakers posi-tion themselves relative to each other in dis-course, is first developed into a reliable cod-ing scheme (0.71 agreement between humanannotators).
We also provide a computationalmodel for automatically annotating text usingthis coding scheme, using supervised learningenhanced by constraints implemented with In-teger Linear Programming.
We show that thisconstrained model?s analyses of speaker au-thority correlates very strongly with expert hu-man judgments (r2 coefficient of 0.947).1 IntroductionIn this work, we seek to formalize the ways speak-ers position themselves in discourse.
We do this ina way that maintains a notion of discourse structure,and which can be aggregated to evaluate a speaker?soverall stance in a dialogue.
We define the body ofwork in positioning to include any attempt to formal-ize the processes by which speakers attempt to influ-ence or give evidence of their relations to each other.Constructs such as Initiative and Control (Whittakerand Stenton, 1988), which attempt to operationalizethe authority over a discourse?s structure, fall underthe umbrella of positioning.
As we construe posi-tioning, it also includes work on detecting certaintyand confusion in speech (Liscombe et al, 2005),which models a speaker?s understanding of the in-formation in their statements.
Work in dialogue acttagging is also relevant, as it seeks to describe the ac-tions and moves with which speakers display thesetypes of positioning (Stolcke et al, 2000).To complement these bodies of work, we chooseto focus on the question of how speakers positionthemselves as authoritative in a discourse.
Thismeans that we must describe the way speakers intro-duce new topics or discussions into the discourse;the way they position themselves relative to thattopic; and how these functions interact with eachother.
While all of the tasks mentioned above focuson specific problems in the larger rhetorical questionof speaker positioning, none explicitly address thisframing of authority.
Each does have valuable tiesto the work that we would like to do, and in section2, we describe prior work in each of those areas, andelaborate on how each relates to our questions.We measure this as an authoritativeness ratio.
Ofthe contentful dialogue moves made by a speaker,in what fraction of those moves is the speaker po-sitioned as the primary authority on that topic?
Tomeasure this quantitatively, we introduce the Nego-tiation framework, a construct from the field of sys-temic functional linguistics (SFL), which addressesspecifically the concepts that we are interested in.We present a reproducible formulation of this so-ciolinguistics research in section 3, along with ourpreliminary findings on reliability between humancoders, where we observe inter-rater agreement of0.71.
Applying this coding scheme to data, we seestrong correlations with important motivational con-structs such as Self-Efficacy (Bandura, 1997) as wellas learning gains.Next, we address automatic coding of the Ne-gotiation framework, which we treat as a two-1018dimensional classification task.
One dimension isa set of codes describing the authoritative status ofa contribution1.
The other dimension is a segmen-tation task.
We impose constraints on both of thesemodels based on the structure observed in the workof SFL.
These constraints are formulated as booleanstatements describing what a correct label sequencelooks like, and are imposed on our model using anInteger Linear Programming formulation (Roth andYih, 2004).
In section 5, this model is evaluatedon a subset of the MapTask corpus (Anderson etal., 1991) and shows a high correlation with humanjudgements of authoritativeness (r2 = 0.947).
Aftera detailed error analysis, we will conclude the paperin section 6 with a discussion of our future work.2 BackgroundThe Negotiation framework, as formulated by theSFL community, places a special emphasis on howspeakers function in a discourse as sources or recip-ients of information or action.
We break down thisconcept into a set of codes, one code per contribu-tion.
Before we break down the coding scheme moreconcretely in section 3, it is important to understandwhy we have chosen to introduce a new framework,rather than reusing existing computational work.Much work has examined the emergence of dis-course structure from the choices speakers make atthe linguistic and intentional level (Grosz and Sid-ner, 1986).
For instance, when a speaker asks aquestion, it is expected to be followed with an an-swer.
In discourse analysis, this notion is describedthrough dialogue games (Carlson, 1983), while con-versation analysis frames the structure in terms ofadjacency pairs (Schegloff, 2007).
These expec-tations can be viewed under the umbrella of con-ditional relevance (Levinson, 2000), and the ex-changes can be labelled discourse segments.In prior work, the way that people influence dis-course structure is described through the two tightly-related concepts of initiative and control.
A speakerwho begins a discourse segment is said to have ini-tiative, while control accounts for which speaker isbeing addressed in a dialogue (Whittaker and Sten-ton, 1988).
As initiative passes back and forth be-tween discourse participants, control over the con-1We treat each line in our corpus as a single contribution.versation similarly transfers from one speaker to an-other (Walker and Whittaker, 1990).
This relation isoften considered synchronous, though evidence sug-gests that the reality is not straightforward (Jordanand Di Eugenio, 1997).Research in initiative and control has been ap-plied in the form of mixed-initiative dialogue sys-tems (Smith, 1992).
This is a large and ac-tive field, with applications in tutorial dialogues(Core, 2003), human-robot interactions (Peltasonand Wrede, 2010), and more general approaches toeffective turn-taking (Selfridge and Heeman, 2010).However, that body of work focuses on influenc-ing discourse structure through positioning.
Thequestion that we are asking instead focuses on howspeakers view their authority as a source of informa-tion about the topic of the discourse.In particular, consider questioning in discourse.In mixed-initiative analysis of discourse, asking aquestion always gives you control of a discourse.There is an expectation that your question will befollowed by an answer.
A speaker might alreadyknow the answer to a question they asked - forinstance, when a teacher is verifying a student?sknowledge.
However, in most cases asking a ques-tion represents a lack of authority, treating the otherspeakers as a source for that knowledge.
While therehave been preliminary attempts to separate out thesespecific types of positioning in initiative, such asChu-Carroll and Brown (1998), it has not been stud-ied extensively in a computational setting.Another similar thread of research is to identifya speaker?s certainty, that is, the confidence of aspeaker and how that self-evaluation affects theirlanguage (Pon-Barry and Shieber, 2010).
Substan-tial work has gone into automatically identifyinglevels of speaker certainty, for example in Liscombeet al (2005) and Litman et al (2009).
The majordifference between our work and this body of liter-ature is that work on certainty has rarely focused onhow state translates into interaction between speak-ers (with some exceptions, such as the applicationof certainty to tutoring dialogues (Forbes-Riley andLitman, 2009)).
Instead, the focus is on the person?sself-evaluation, independent of the influence on thespeaker?s positioning within a discourse.Dialogue act tagging seeks to describe the movespeople make to express themselves in a discourse.1019This task involves defining the role of each contri-bution based on its function (Stolcke et al, 2000).We know that there are interesting correlations be-tween these acts and other factors, such as learninggains (Litman and Forbes-Riley, 2006) and the rel-evance of a contribution for summarization (Wredeand Shriberg, 2003).
However, adapting dialogueact tags to the question of how speakers positionthemselves is not straightforward.
In particular,the granularity of these tagsets, which is already ahighly debated topic (Popescu-Belis, 2008), is notideal for the task we have set for ourselves.
Manydialogue acts can be used in authoritative or non-authoritative ways, based on context, and can posi-tion a speaker as either giver or receiver of informa-tion.
Thus these more general tagsets are not specificenough to the role of authority in discourse.Each of these fields of prior work is highly valu-able.
However, none were designed to specificallydescribe how people present themselves as a sourceor recipient of knowledge in a discourse.
Thus, wehave chosen to draw on a different field of soci-olinguistics.
Our formalization of that theory is de-scribed in the next section.3 The Negotiation FrameworkWe now present the Negotiation framework2, whichwe use to answer the questions left unanswered inthe previous section.
Within the field of SFL, thisframework has been continually refined over the lastthree decades (Berry, 1981; Martin, 1992; Martin,2003).
It attempts to describe how speakers use theirrole as a source of knowledge or action to positionthemselves relative to others in a discourse.Applications of the framework include distin-guishing between focus on teacher knowledge andstudent reasoning (Veel, 1999) and distribution ofauthority in juvenile trials (Martin et al, 2008).
Theframework can also be applied to problems similarto those studied through the lens of initiative, suchas the distinction between authority over discoursestructure and authority over content (Martin, 2000).A challenge of applying this work to languagetechnologies is that it has historically been highly2All examples are drawn from the MapTask corpus and in-volve an instruction giver (g) and follower (f).
Within examples,discourse segment boundaries are shown by horizontal lines.qualitative, with little emphasis placed on repro-ducibility.
We have formulated a pared-down, repro-ducible version of the framework, presented in Sec-tion 3.1.
Evidence of the usefulness of that formu-lation for identifying authority, and of correlationsthat we can study based on these codes, is presentedbriefly in Section 3.2.3.1 Our Formulation of NegotiationThe codes that we can apply to a contribution us-ing the Negotiation framework are comprised of fourmain codes, K1, K2, A1, and A2, and two additionalcodes, ch and o.
This is a reduction over the manytask-specific or highly contextual codes used in theoriginal work.
This was done to ensure that a ma-chine learning classification task would not be over-whelmed with many infrequent classes.The main codes are divided by two questions.First, is the contribution related to exchanging infor-mation, or to exchanging services and actions?
If theformer, then it is a K move (knowledge); if the latter,then an A move (action).
Second, is the contributionacting as a primary actor, or secondary?
In the caseof knowledge, this often correlates to the differencebetween assertions (K1) and queries (K2).
For in-stance, a statement of fact or opinion is a K1:g K1 well i?ve got a great viewpointhere just below the east lakeBy contrast, asking for someone else?s knowledgeor opinion is a K2:g K2 what have you got underneath theeast lakef K1 rocket launchIn the case of action, the codes usually corre-spond to narrating action (A1) and giving instruc-tions (A2), as below:g A2 go almost to the edge of the lakef A1 yeahA challenge move (ch) is one which directly con-tradicts the content or assertion of the previous line,or makes that previous contribution irrelevant.
Forinstance, consider the exchange below, where an in-struction is rejected because its presuppositions arebroken by the challenging statement.g A2 then head diagonally down to-wards the bottom of the dead treef ch i have don?t have a dead tree ihave a dutch elm1020All moves that do not fit into one of these cate-gories are classified as other (o).
This includes back-channel moves, floor-grabbing moves, false starts,and any other non-contentful contributions.This theory makes use of discourse segmenta-tion.
Research in the SFL community has focusedon intra-segment structure, and empirical evidencefrom this research has shown that exchanges be-tween speakers follow a very specific pattern:o* X2?
o* X1+ o*That is to say, each segment contains a primarymove (a K1 or an A1) and an optional precedingsecondary move, with other non-contentful movesinterspersed throughout.
A single statement of factwould be a K1 move comprising an entire segment,while a single question/answer pair would be a K2move followed by a K1.
Longer exchanges of manylines obviously also occur.We iteratively developed a coding manual whichdescribes, in a reproducible way, how to apply thecodes listed above.
The six codes we use, along withtheir frequency in our corpus, are given in Table 1.In the next section, we evaluate the reliability andutility of hand-coded data, before moving on to au-tomation in section 4.3.2 Preliminary EvaluationThis coding scheme was evaluated for reliability ontwo corpora using Cohen?s kappa (Cohen, 1960).Within the social sciences community, a kappaabove 0.7 is considered acceptable.
Two conversa-tions were each coded by hand by two trained anno-tators.
The first conversation was between three stu-dents in a collaborative learning task; inter-rater re-liability kappa for Negotiation labels was 0.78.
Thesecond conversation was from the MapTask corpus,and kappa was 0.71.
Further data was labelled byhand by one trained annotator.In our work, we label conversations using the cod-ing scheme above.
To determine how well thesecodes correlate with other interesting factors, wechoose to assign a quantitative measure of authori-tativeness to each speaker.
This measure can thenbe compared to other features of a speaker.
To dothis, we use the coded labels to assign an Authori-tativeness Ratio to each speaker.
First, we define aCode Meaning Count PercentK1 Primary Knower 984 22.5K2 Secondary Knower 613 14.0A1 Primary Actor 471 10.8A2 Secondary Actor 708 16.2ch Challenge 129 2.9o Other 1469 33.6Total 4374 100.0Table 1: The six codes in our coding scheme, along withtheir frequency in our corpus of twenty conversations.functionA(S, c, L) for a speaker, a contribution, anda set of labels L ?
{K1,K2, A1, A2, o, ch} as:A(S, c, L) ={1 c spoken by S with label l ?
L0 otherwise.We then define the Authoritativeness ratioAuth(S) for a speaker S in a dialogue consistingof contributions c1...cn as:Auth(S) =n?i=1A(S, ci, {K1, A2})n?i=1A(S, ci, {K1,K2, A1, A2})The intuition behind this ratio is that we are onlyinterested in the four main label types in our analy-sis - at least for an initial description of authority, wedo not consider the non-contentful o moves.
Withinthese four main labels, there are clearly two that ap-pear ?dominant?
- statements of fact or opinion, andcommands or instructions - and two that appear lessdominant - questions or requests for information,and narration of an action.
We sum these togetherto reach a single numeric value for each speaker?sprojection of authority in the dialogue.The full details of our external validations of thisapproach are available in Howley et al (2011).
Tosummarize, we considered two data sets involvingstudent collaborative learning.
The first data set con-sisted of pairs of students interacting over two days,and was annotated for aggressive behavior, to assesswarning factors in social interactions.
Our analysis1021showed that aggressive behavior correlated with au-thoritativeness ratio (p < .05), and that less aggres-sive students became less authoritative in the secondday (p < .05, effect size .15?).
The second dataset was analyzed for Self-Efficacy - the confidenceof each student in their own ability (Bandura, 1997)- as well as actual learning gains based on pre- andpost-test scores.
We found that the Authoritativenessratio was a significant predictor of learning gains(r2 = .41, p < .04).
Furthermore, in a multiple re-gression, we determined that the Authoritativenessratio of both students in a group predict the averageSelf-Efficacy of the pair (r2 = .12, p < .01).4 Computational ModelWe know that our coding scheme is useful for mak-ing predictions about speakers.
We now judgewhether it can be reproduced fully automatically.Our model must select, for each contribution ci in adialogue, the most likely classification label li from{K1,K2, A1, A2, o, ch}.
We also build in paral-lel a segmentation model to select si from the set{new, same}.
Our baseline approach to both prob-lems is to use a bag-of-words model of the contribu-tion, and use machine learning for classification.Certain types of interactions, explored in section4.1, are difficult or impossible to classify withoutcontext.
We build a contextual feature space, de-scribed in section 4.2, to enhance our baseline bag-of-words model.
We can also describe patterns thatappear in discourse segments, as detailed in section3.1.
In our coding manual, these instructions aregiven as rules for how segments should be coded byhumans.
Our hypothesis is that by enforcing theserules in the output of our automatic classifier, per-formance will increase.
In section 4.3 we formalizethese constraints using Integer Linear Programming.4.1 Challenging casesWe want to distinguish between phenomena such asin the following two examples.f K2 so I?m like on the bank on thebank of the east lakeg K1 yeahIn this case, a one-token contribution is indis-putably a K1 move, answering a yes/no question.However, in the dialogue below, it is equally inar-guable that the same move is an A1:g A2 go almost to the edge of the lakef A1 yeahWithout this context, these moves would be indis-tinguishable to a model.
With it, they are both easilyclassified correctly.We also observed that markers for segmentationof a segment vary between contentful initiations andnon-contentful ones.
For instance, filler noises canoften initiate segments:g o hmm...g K2 do you have a farmer?s gate?f K1 noSituations such as this are common.
This is also achallenge for segmentation, as demonstrated below:g K1 oh oh it?s on the right-hand sideof my great viewpointf o okay yeahg o right ehg A2 go almost to the edge of the lakef A1 yeahA long statement or instruction from one speakeris followed up with a terse response (in the samesegment) from the listener.
However, after that back-channel move, a short floor-grabbing move is oftenmade to start the next segment.
This is a distinc-tion that a bag-of-words model would have difficultywith.
This is markedly different from contentful seg-ment initiations:g A2 come directly down below thestone circle and we come upf ch I don?t have a stone circleg o you don?t have a stone circleAll three of these lines look like statements, whichoften initiate new segments.
However, only the firstshould be marked as starting a new segment.
Theother two are topically related, in the second line bycontradicting the instruction, and in the third by re-peating the previous person?s statement.4.2 Contextual Feature Space AdditionsTo incorporate the insights above into our model, weappend features to our bag-of-words model.
First,in our classification model we include both lexicalbigrams and part-of-speech bigrams to encode fur-ther lexical knowledge and some notion of syntac-tic structure.
To account for restatements and topicshifts, we add a feature based on cosine similarity(using term vectors weighted by TF-IDF calculated1022over training data).
We then add a feature for thepredicted label of the previous contribution - aftereach contribution is classified, the next contributionadds a feature for the automatic label.
This requiresour model to function as an on-line classifier.We build two segmentation models, one trainedon contributions of less than four tokens, and an-other trained on contributions of four or more to-kens, to distinguish between characteristics of con-tentful and non-contentful contributions.
To theshort-contribution model, we add two additional fea-tures.
The first represents the ratio between thelength of the current contribution and the length ofthe previous contribution.
The second representswhether a change in speaker has occurred betweenthe current and previous contribution.4.3 Constraints using Integer LinearProgrammingWe formulate our constraints using Integer LinearProgramming (ILP).
This formulation has an ad-vantage over other sequence labelling formulations,such as Viterbi decoding, in its ability to enforcestructure through constraints.
We then enhance thisclassifier by adding constraints, which allow expertknowledge of discourse structure to be enforced inclassification.
We can use these constraints to elim-inate label options which would violate the rules fora segment outlined in our coding manual.Each classification decision is made at the contri-bution level, jointly optimizing the Negotiation la-bel and segmentation label for a single contribution,then treating those labels as given for the next con-tribution classification.To define our objective function for optimization,for each possible label, we train a one vs. all SVM,and use the resulting regression for each label asa score, giving us six values ~li for our Negotiationlabel and two values ~si for our segmentation label.Then, subject to the constraints below, we optimize:arg maxl?~li,s?~sil + sThus, at each contribution, if the highest-scoringNegotiation label breaks a constraint, the model canoptimize whether to drop to the next-most-likely la-bel, or start a new segment.Recall from section 3.1 that our discourse seg-ments follow strict rules related to ordering and rep-etition of contributions.
Below, we list the con-straints that we used in our model to enforce thatpattern, along with a brief explanation of the intu-ition behind each.
?ci ?
s, (li = K2)?
?j < i, cj ?
t?
(lj 6= K1)(1)?ci ?
s, (li = A2)?
?j < i, cj ?
t?
(lj 6= A1)(2)The first constraints enforce the rule that a pri-mary move cannot occur before a secondary movein the same segment.
For instance, a question mustinitiate a new segment if it follows a statement.
?ci ?
s, (li ?
{A1, A2})?
?j < i, cj ?
s?
(lj /?
{K1,K2})(3)?ci ?
s, (li ?
{K1,K2})?
?j < i, cj ?
s?
(lj /?
{A1, A2})(4)These constraints specify that A moves and Kmoves cannot cooccur in a segment.
An instruc-tion for action and a question requesting informationmust be considered separate segments.
?ci ?
s, (li = A1)?
((li?1 = A1) ?
?j < i, cj ?
s?
(lj 6= A1))(5)?ci ?
s, (li = K1)?
((li?1 = K1) ?
?j < i, cj ?
s?
(lj 6= K1))(6)This pair states that two primary moves cannot oc-cur in the same segment unless they are contiguous,in rapid succession.
?ci ?
s, (li = A1)?
?j < i, cj ?
s, (lj = A2)?
(Si 6= Sj)(7)?ci ?
s, (li = K1)?
?j < i, cj ?
s, (lj = K2)?
(Si 6= Sj)(8)The last set of constraints enforce the intuitivenotion that a speaker cannot follow their own sec-ondary move with a primary move in that segment(such as answering their own question).1023Computationally, an advantage of these con-straints is that they do not extend past the currentsegment in history.
This means that they usuallyare only enforced over the past few moves, and donot enforce any global constraint over the structureof the whole dialogue.
This allows the constraintsto be flexible to various conversational styles, andtractable for fast computation independent of thelength of the dialogue.5 EvaluationWe test our models on a twenty conversation sub-set of the MapTask corpus detailed in Table 1.
Wecompare the use of four models in our results.?
Baseline: This model uses a bag-of-words fea-ture space as input to an SVM classifier.
Nosegmentation model is used and no ILP con-straints are enforced.?
Baseline+ILP: This model uses the baselinefeature space as input to both classification andsegmentation models.
ILP constraints are en-forced between these models.?
Contextual: This model uses our enhancedfeature space from section 4.2, with no segmen-tation model and no ILP constraints enforced.?
Contextual+ILP: This model uses the en-hanced feature spaces for both Negotiation la-bels and segment boundaries from section 4.2to enforce ILP constraints.For segmentation, we evaluate our models usingexact-match accuracy.
We use multiple evaluationmetrics to judge classification.
The first and mostbasic is accuracy - the percentage of accurately cho-sen Negotiation labels.
Secondly, we use Cohen?sKappa (Cohen, 1960) to judge improvement in ac-curacy over chance.
The final evaluation is the r2coefficient computed between predicted and actualAuthoritativeness ratios per speaker.
This representshow much variance in authoritativeness is accountedfor in the predicted ratios.
This final metric is themost important for measuring reproducibility of hu-man analyses of speaker authority in conversation.We use SIDE for feature extraction (Mayfieldand Rose?, 2010), SVM-Light for machine learningModel Accuracy Kappa r2Baseline 59.7% 0.465 0.354Baseline+ILP 61.6% 0.488 0.663Segmentation 72.3%Contextual 66.7% 0.565 0.908Contextual+ILP 68.4% 0.584 0.947Segmentation 74.9%Table 2: Performance evaluation for our models.
Eachline is significantly improved in both accuracy and r2 er-ror from the previous line (p < .01).
(Joachims, 1999), and Learning-Based Java for ILPinference (Rizzolo and Roth, 2010).
Performanceis evaluated by 20-fold cross-validation, where eachfold is trained on 19 conversations and tested on theremaining one.
Statistical significance was calcu-lated using a student?s paired t-test.
For accuracyand kappa, n = 20 (one data point per conversation)and for r2, n = 40 (one data point per speaker).5.1 ResultsAll classification results are given in Table 2 andcharts showing correlation between predicted andactual speaker Authoritativeness ratios are shown inFigure 1.
We observe that the baseline bag-of-wordsmodel performs well above random chance (kappaof 0.465); however, its accuracy is still very lowand its ability to predict Authoritativeness ratio ofa speaker is not particularly high (r2 of 0.354 withratios from manually labelled data).
We observe asignificant improvement when ILP constraints areapplied to this model.The contextual model described in section 4.2performs better than our baseline constrained model.However, the gains found in the contextual modelare somewhat orthogonal to the gains from usingILP constraints, as applying those constraints tothe contextual model results in further performancegains (and a high r2 coefficient of 0.947).Our segmentation model was evaluated based onexact matches in boundaries.
Switching from base-line to contextual features, we observe an improve-ment in accuracy of 2.6%.5.2 Error AnalysisAn error analysis of model predictions explains thelarge effect on correlation despite relatively smaller1024Figure 1: Plots of predicted (x axis) and actual (y axis) Authoritativeness ratios for speakers across 20 conversations,for the Baseline (left), Baseline+Constraints (center), and Contextual+Constraints (right) models.changes in accuracy.
Our Authoritativeness ratiodoes not take into account moves labelled o orch.
What we find is that the most advanced modelstill makes many mistakes at determining whether amove should be labelled as o or a core move.
This er-ror rate is, however, fairly consistent across the fourcore move codes.
When a move is determined (cor-rectly) to not be an o move, the system is highly ac-curate in distinguishing between the four core labels.The one systematic confusion that continues toappear most frequently in our results is the inabil-ity to distinguish between a segment containing anA2 move followed by an A1 move, and a segmentcontaining a K1 move followed by an o move.
Thesurface structure of these types of exchanges is verysimilar.
Consider the following two exchanges:g A2 if you come down almost to thebottom of the map that I?ve gotf A1 uh-huhf K1 but the meadow?s below my bro-ken gateg o right yesThese two exchanges on a surface level are highlysimilar.
Out of context, making this distinction isvery hard even for human coders, so it is not surpris-ing then that this pattern is the most difficult one torecognize in this corpus.
It contributes most of theremaining confusion between the four core codes.6 ConclusionsIn this work we have presented one formulation ofauthority in dialogue.
This formulation allows usto describe positioning in discourse in a way thatis complementary to prior work in mixed-initiativedialogue systems and analysis of speaker certainty.Our model includes a simple understanding of dis-course structure while also encoding informationabout the types of moves used, and the certainty of aspeaker as a source of information.
This formulationis reproducible by human coders, with an inter-raterreliability of 0.71.We have then presented a computational modelfor automatically applying these codes per contribu-tion.
In our best model, we see a good 68.4% accu-racy on a six-way individual contribution labellingtask.
More importantly, this model replicates humananalyses of authoritativeness very well, with an r2coefficient of 0.947.There is room for improvement in our model infuture work.
Further use of contextual features willmore thoroughly represent the information we wantour model to take into account.
Our segmentationaccuracy is also fairly low, and further examinationof segmentation accuracy using a more sophisticatedevaluation metric, such as WindowDiff (Pevzner andHearst, 2002), would be helpful.In general, however, we now have an automatedmodel that is reliable in reproducing human judg-ments of authoritativeness.
We are now interested inhow we can apply this to the larger questions of po-sitioning we began this paper by asking, especiallyin describing speaker positioning at various instantsthroughout a single discourse.
This will be the mainthrust of our future work.AcknowledgementsThis research was supported by NSF grants SBE-0836012 and HCC-0803482.1025ReferencesAnne Anderson, Miles Bader, Ellen Bard, ElizabethBoyle, Gwyneth Doherty, Simon Garrod, et al 1991.The HCRC Map Task Corpus.
In Language andSpeech.Albert Bandura.
1997.
Self-efficacy: The Exercise ofControlMargaret Berry.
1981.
Towards Layers of ExchangeStructure for Directive Exchanges.
In Network 2.Lauri Carlson.
1983.
Dialogue Games: An Approach toDiscourse Analysis.Jennifer Chu-Carroll and Michael Brown.
1998.
An Ev-idential Model for Tracking Initiative in CollaborativeDialogue Interactions.
In User Modeling and User-Adapted Interaction.Jacob Cohen.
1960.
A Coefficient of Agreement forNominal Scales.
In Educational and PsychologicalMeasurement.Mark Core and Johanna Moore and Claus Zinn.
2003.The Role of Initiative in Tutorial Dialogue.
In Pro-ceedings of EACL.Kate Forbes-Riley and Diane Litman.
2009.
Adapting toStudent Uncertainty Improves Tutoring Dialogues.
InProceedings of Artificial Intelligence in Education.Barbara Grosz and Candace Sidner.
1986.
Attention,Intentions, and the Structure of Discourse.
In Compu-tational Linguistics.Iris Howley and Elijah Mayfield and Carolyn PensteinRose?.
2011.
Missing Something?
Authority in Col-laborative Learning.
In Proceedings of Computer-Supported Collaborative Learning.Thorsten Joachims.
1999.
Making large-Scale SVMLearning Practical.
In Advances in Kernel Methods- Support Vector Learning.Pamela Jordan and Barbara Di Eugenio.
1997.
Controland Initiative in Collaborative Problem Solving Dia-logues.
In Proceedings of AAAI Spring Symposiumon Computational Models for Mixed Initiative Inter-actions.Stephen Levinson.
2000.
Pragmatics.Jackson Liscombe, Julia Hirschberg, and Jennifer Ven-ditti.
2005.
Detecting Certainness in Spoken TutorialDialogues.
In Proceedings of Interspeech.Diane Litman and Kate Forbes-Riley.
2006.
Correlationsbetweeen Dialogue Acts and Learning in Spoken Tu-toring Dialogue.
In Natural Language Engineering.Diane Litman, Mihai Rotaru, and Greg Nicholas.
2009.Classifying Turn-Level Uncertainty Using Word-LevelProsody.
In Proceedings of Interspeech.James Martin.
1992.
English Text: System and Structure.James Martin.
2000.
Factoring out Exchange: Types ofStructure.
In Working with Dialogue.James Martin and David Rose.
2003.
Working with Dis-course: Meaning Beyond the Clause.James Martin, Michele Zappavigna, and Paul Dwyer.2008.
Negotiating Shame: Exchange and Genre Struc-ture in Youth Justice Conferencing.
In Proceedings ofEuropean Systemic Functional Linguistics.Elijah Mayfield and Carolyn Penstein Rose?.
2010.
AnInteractive Tool for Supporting Error Analysis for TextMining.
In Proceedings of Demo Session at NAACL.Julia Peltason and Britta Wrede.
2010.
ModelingHuman-Robot Interaction Based on Generic Interac-tion Patterns.
In AAAI Report on Dialog with Robots.Lev Pevzner and Marti Hearst.
2002.
A critique andimprovement of an evaluation metric for text segmen-tation.
In Computational Linguistics.Heather Pon-Barry and Stuart Shieber.
2010.
AssessingSelf-awareness and Transparency when Classifying aSpeakers Level of Certainty.
In Speech Prosody.Andrei Popescu-Belis.
2008.
Dimensionality of Dia-logue Act Tagsets: An Empirical Analysis of LargeCorpora.
In Language Resources and Evaluation.Nick Rizzolo and Dan Roth.
2010.
Learning Based Javafor Rapid Development of NLP Systems.
In LanguageResources and Evaluation.Dan Roth and Wen-Tau Yih.
2004.
A Linear Program-ming Formulation for Global Inference in Natural Lan-guage Tasks.
In Proceedings of CoNLL.Emanuel Schegloff.
2007.
Sequence Organization in In-teraction: A Primer in Conversation Analysis.Ethan Selfridge and Peter Heeman.
2010.
Importance-Driven Turn-Bidding for Spoken Dialogue Systems.In Proceedings of ACL.Ronnie Smith.
1992.
A computational model ofexpectation-driven mixed-initiative dialog processing.Ph.D.
Dissertation.Andreas Stolcke, Klaus Ries, Noah Coccaro, ElizabethShriberg, Rebecca Bates, Daniel Jurafsky, et al 2000.Dialogue Act Modeling for Automatic Tagging andRecognition of Conversational Speech.
In Computa-tional Linguistics.Robert Veel.
1999.
Language, Knowledge, and Author-ity in School Mathematics.
In Pedagogy and the Shap-ing of Consciousness: Linguistics and Social Pro-cessesMarilyn Walker and Steve Whittaker.
1990.
Mixed Ini-tiative in Dialogue: An Investigation into DiscourseStructure.
In Proceedings of ACL.Steve Whittaker and Phil Stenton.
1988.
Cues and Con-trol in Expert-Client Dialogues.
In Proceedings ofACL.Britta Wrede and Elizabeth Shriberg.
2003.
The Re-lationship between Dialogue Acts and Hot Spots inMeetings.
In IEEE Workshop on Automatic SpeechRecognition and Understanding.1026
