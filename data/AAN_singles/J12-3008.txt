On the String Translations Produced by MultiBottom?Up Tree TransducersDaniel Gildea?University of RochesterTree transducers are defined as relations between trees, but in syntax-based machine translation,we are ultimately concerned with the relations between the strings at the yields of the input andoutput trees.
We examine the formal power of Multi Bottom-Up Tree Transducers from this pointof view.1.
IntroductionMany current approaches to syntax-based statistical machine translation fall underthe theoretical framework of synchronous tree substitution grammars (STSGs).
Treesubstitution grammars (TSGs) generalize context-free grammars (CFGs) in that eachrule expands a nonterminal to produce an arbitrarily large tree fragment, rather thana fragment of depth one as in a CFG.
Synchronous TSGs generate tree fragments inthe source and target languages in parallel, with each rule producing a tree fragmentin either language.
Systems such as that of Galley et al (2006) extract STSG rules fromparallel bilingual text that has been automatically parsed in one language, and the STSGnonterminals correspond to nonterminals in these parse trees.
Chiang?s (2007) Hierosystem produces simpler STSGs with a single nonterminal.STSGs have the advantage that they can naturally express many re-ordering andrestructuring operations necessary for machine translation (MT).
They have the dis-advantage, however, that they are not closed under composition (Maletti et al 2009).Therefore, if one wishes to construct anMT system as a pipeline of STSG operations, theresult may not be expressible as an STSG.
Recently, Maletti (2010) has argued that multibottom?up tree transducers (MBOTs) (Lilin 1981; Arnold and Dauchet 1982; Engelfriet,Lilin, and Maletti 2009) provide a useful representation for natural language processingapplications because they generalize STSGs, but have the added advantage of beingclosed under composition.
MBOTs generalize traditional bottom?up tree transducers inthat they allow transducer states to pass more than one output subtree up to subsequenttransducer operations.
The number of subtrees taken by a state is called its rank.
MBOTsare linear and non-deleting; that is, operations cannot copy or delete arbitrarily largetree fragments.Although STSGs and MBOTs both perform operations on trees, it is important tonote that, in MT, we are primarily interested in translational relations between strings.Tree operations such as those provided by STSGs are ultimately tools to translate a string?
Computer Science Department, University of Rochester, Rochester NY 14627.E-mail: gildea@cs.rochester.edu.Submission received: 3 May 2011; revised submission received: 1 October 2011; accepted for publication:28 October 2011.?
2012 Association for Computational LinguisticsComputational Linguistics Volume 38, Number 3in one natural language into a string in another.
Whereas MBOTs originate in the treetransducer literature and are defined to take a tree as input, MT systems such as thoseof Galley et al (2006) and Chiang (2007) find a parse of the source language sentenceas part of the translation process, and the decoding algorithm, introduced by Yamadaand Knight (2002), has more in common with CYK parsing than with simulating a treetransducer.In this article, we investigate the power of MBOTs, and of compositions of STSGsin particular, in terms of the set of string translations that they generate.
We relateMBOTs and compositions of STSGs to existing grammatical formalisms defined onstrings through five main results, which we outline subsequently.
The first four resultsserve to situate general MBOTs among string formalisms, and the fifth result addressesMBOTs resulting from compositions of STSGs in particular.Our first result is that the translations produced by MBOTs are a subset of thoseproduced by linear context-free rewriting systems (LCFRSs) (Vijay-Shankar, Weir, andJoshi 1987).
LCFRS provides a very general framework that subsumes CFG, tree ad-joining grammar (TAG; Joshi, Levy, and Takahashi 1975; Joshi and Schabes 1997), andmore complex systems, as well as synchronous context-free grammar (SCFG) (Aho andUllman 1972) and synchronous tree adjoining grammar (STAG) (Shieber and Schabes1990; Schabes and Shieber 1994) in the context of translation.
LCFRS allows gram-mar nonterminals to generate more than one span in the final string; the number ofspans produced by an LCFRS nonterminal corresponds to the rank of an MBOT state.Our second result states that the translations produced by MBOTs are equivalent toa specific restricted form of LCFRS, which we call 1-m-LCFRS.
From the constructionrelating MBOTs and 1-m-LCFRSs follow results about the source and target sides of thetranslations produced by MBOTs.
In particular, our third result is that the translationsproduced by MBOTs are context-free within the source language, and hence are strictlyless powerful than LCFRSs.
This implies that MBOTs are not as general as STAGs, forexample.
Similarly, MBOTs are not as general as the generalized multitext grammarsproposed for machine translation by Melamed (2003), which retain the full power ofLCFRSs in each language (Melamed, Satta, and Wellington 2004).
Our fourth resultis that the output of an MBOT, when viewed as a string language, does retain thefull power of LCFRSs.
This fact is mentioned by Engelfriet, Lilin, and Maletti (2009,page 586), although no explicit construction is given.Our final result specifically addresses the string translations that result from com-positions of STSGs, with the goal of better understanding the complexity of using suchcompositions in machine translation systems.
We show that the translations producedby compositions of STSGs are more powerful than those produced by single STSGs,or, equivalently, by SCFGs.
Although it is known that STSGs are not closed undercomposition, the proofs used previously in the literature rely on differences in treestructure, and do not generate string translations that cannot be generated by STSG.Our result implies that current approaches to machine translation decoding will needto be extended to handle arbitrary compositions of STSGs.We now turn to give definitions of MBOTs and LCFRSs in the next section, beforepresenting our results on general MBOTs in Section 3, and our result on compositionsof STSGs in Section 4.2.
PreliminariesA ranked alphabet is an alphabet where each symbol has an integer rank, denoting thenumber of children the symbol takes in a tree.
T?
denotes the set of trees constructed674Gildea On the String Translations Produced by Multi Bottom?Up Tree Transducersfrom ranked alphabet ?.
We use parentheses to write trees: for example, a(b, c, d) is anelement of T?
if a is an element of ?
with rank 3, and b, c, and d are elements of ?
withrank 0.
Similarly, given a ranked alphabet ?
and a set X, ?
(X) denotes the set of treesconsisting of a single symbol of ?
of rank k dominating a sequence of k elements fromX.
We use T?
(X) to denote the set of arbitrarily sized trees constructed from rankedalphabet ?
having items from set X at some leaf positions.
That is, T?
(X) is the smallestset such thatX ?
T?
(X) and ?
(t1, .
.
.
, tk) ?
T?
(X) if ?
is an element of?with rank k, andt1, .
.
.
, tk ?
T?(X).
Amulti bottom?up tree transducer (MBOT) (Lilin 1981; Arnold andDauchet 1982; Engelfriet, Lilin, and Maletti 2009; Maletti 2010) is a system (S,?,?,F,R)where: S,?, and?
are ranked alphabets of states, input symbols, and outputsymbols, respectively. F ?
S is a set of accepting states. R is a finite set of rules l?
r where, using a set of variables X,l ?
T?
(S(X)), and r ?
S(T?
(X)) such that:?
every x ?
X that occurs in l occurs exactly once in r and vice versa,and?
l ?
S(X) or r ?
S(X).One step in an MBOT transduction is performed by rewriting a local tree fragment asspecified by one of the rules in R. We replace the fragment l with r, copying the subtreeunder each variable in l to the location of the corresponding variable in r. Transducerrules apply bottom?up from the leaves of the input tree, as shown in Figure 1, and mustterminate in an accepting state.
We use underlined symbols for the transducer states,in order to distinguish them from the symbols of the input and output alphabets.We define a translation to be a set of string pairs, and we define the yield of anMBOT M to be the set of string pairs (s, t) such that there exist: a tree s?
?
T?
having sas its yield, a tree t?
?
T?
having t as its yield, and a transduction from s?
to t?
that isaccepted byM.
We refer to s as the source side and t as the target side of the translation.We use the notation source(T) to denote the set of source strings of a translation T,source(T) = {s | (s, t) ?
T}, and we use the notation target(T) to denote the set of targetstrings.
We use the notation yield(MBOT) to denote the set of translations producedby the set of all MBOTs.A linear context-free rewriting system (LCFRS) is defined as a system(VN,VT,P,S), where VN is a set of nonterminal symbols, VT is a set of terminal symbols,P is a set of productions, and S ?
VN is a distinguished start symbol.
Associated witheach nonterminal B is a fan-out ?
(B), which tells how many spans B covers in the finalstring.
Productions p ?
P take the form: p : A?
g(B1,B2, .
.
.
,Br), where A,B1, .
.
.
,Br ?VN, and g is a function g : (V?T )?
(B1) ?
?
?
?
?
(V?T )?
(Br ) ?
(V?T )?
(A), which specifies howto assemble the?ri=1?
(Bi) spans of the righthand side nonterminals into the ?
(A)spans of the lefthand side nonterminal.
The function gmust be linear and non-erasing,which means that if we writeg(?x1,1, .
.
.
, x1,?
(B1 )?, .
.
.
, ?xr,1, .
.
.
, xr,?
(Br )?)
= ?t1, .
.
.
, t?
(A)?the tuple of strings ?t1, .
.
.
, t?(A)?
on the right-hand side contains each variable xi,j fromthe left-hand side exactly once, and may also contain terminals from VT.
The processof generating a string from an LCFRS grammar consists of first choosing, top?down, aproduction to expand each nonterminal, and then, bottom?up, applying the functions675Computational Linguistics Volume 38, Number 3Figure 1Step-by-step example of an MBOT tree transduction.
The left column shows the transducer ruleapplied at each step; only the last rule contains variables, whereas the others contain alphabetsymbols of rank zero at their leaves.
State VPQ has rank two, and states NP and S have rank one.associated with each production to build the string.
We refer to the tree induced by top?down nonterminal expansions of an LCFRS as the derivation tree, or sometimes simplyas a derivation.As an example of how the LCFRS framework subsumes grammatical formalismssuch as CFG, consider the following CFG:S?
ABA?
aB?
bThis grammar corresponds to the following grammar in LCFRS notation:S?
gS(A,B) gS(?sA?, ?sB?)
= ?sAsB?A?
gA() gA() = ?a?B?
gB() gB() = ?b?Here, all nonterminals have fan-out one, reflected in the fact that all tuples definingthe productions?
functions contain just one string.
Just as CFG is equivalent to LCFRSwith fan-out 1, SCFG and TAG can be represented as LCFRS with fan-out 2.
Highervalues of fan-out allow strictly more powerful grammars (Rambow and Satta 1999).Polynomial-time parsing is possible for any fixed LCFRS grammar, but the degree of676Gildea On the String Translations Produced by Multi Bottom?Up Tree Transducersthe polynomial depends on the grammar.
Parsing general LCFRS grammars, where thegrammar is considered part of the input, is NP-complete (Satta 1992).Following Melamed, Satta, and Wellington (2004), we represent translation inLCFRS by using a special symbol # to separate the strings of the two languages.
OurLCFRS grammars will only generate strings of the form s#t, where s and t are stringsnot containing the symbol #, and we will identify s as the source string and t as thetarget string.
We use the notation trans(LCFRS) to denote the set of translations thatcan be produced by taking the string language of some LCFRS and splitting each stringinto a pair at the location of the # symbol.3.
Translations Produced by General MBOTsIn this section, we relate the yield of general MBOTs to string rewriting systems.To begin, we show that the translation produced by any MBOT is also producedby an LCFRS by giving a straightforward construction for converting MBOT rules toLCFRS rules.We first consider MBOT rules having only variables, as opposed to alphabetsymbols of rank zero, at their leaves.
For an MBOT rule l?
r with l ?
T?
(S(X)), letS1,S2, .
.
.
,Sk be the sequence of states appearing from left to right immediately abovethe leaves of l. Without loss of generality, we will name the variables such that xi,j is thejth child of the ith state, Si, and the sequence of variables at the leaves of l, read fromleft to right, is: x1,1, .
.
.
, x1,d(S1 ), .
.
.
, xk,1, .
.
.
, xk,d(Sk ), where d(Si) is the rank of state Si.Let S0 be the state symbol at the root of the right-hand-side (r.h.s.)
tree r ?
S(T?
(X)).Let ?
and ?
be functions such that x?(1),?
(1), x?(2),?
(2), .
.
.
, x?(n),?
(n) is the sequenceof variables at the leaves of r read from left to right.
We will call this sequence the yieldof r. Finally, let p(i) for 1 ?
i ?
d(S0) be the position in the yield of r of the rightmostleaf of S0?s ith child.
Thus, for all i, 1 ?
p(i) ?
n.Given this notation, the LCFRS rule corresponding to the MBOT rule l?
r isconstructed as S0 ?
g(S1,S2, .
.
.
,Sk).
The LCFRS nonterminal Si has fan-out equalto the corresponding MBOT state?s rank plus one: ?
(Si) = d(Si)+ 1.
This is becausethe LCFRS nonterminal has one span in the source language, and d(Si) spans inthe target language of the translation.
The combination function for the LCFRS ruleS0 ?
g(S1,S2, .
.
.
,Sk) is:g(?e1, f1,1, .
.
.
, f1,d(S1 )?, .
.
.
, ?ek, fk,1, .
.
.
, fk,d(Sk )?)
=?
e1 ?
?
?
ek, f?(1),?
(1) ?
?
?
f?(p(1)),?(p(1)),f?(p(1)+1),?
(p(1)+1) ?
?
?
f?(p(2)),?(p(2)),.
.
.
,f?
(p(d(S0 )?1)+1),?
(p(d(S0 )?1)+1) ?
?
?
f?
(p(d(S0 ))),?
(p(d(S0 )) ?Here we use ei for the variables in the LCFRS rule corresponding to spans in the inputtree of the MBOT, and fi,j for variables corresponding to the output tree.
The pattern inwhich these spans fit together is specified by the functions ?
and ?
that were read off ofthe MBOT rule.Examples of the conversion of an MBOT rule to an LCFRS rule are shown inFigure 2.
The first example shows an MBOT rule derived from an STSG rule, in thiscase converting SVO (as in English) to VSO (as in Arabic) word order.
The states ofan MBOT rule derived from an STSG rule always have rank 1.
In the resulting LCFRS677Computational Linguistics Volume 38, Number 3rule, this means that every nonterminal in the grammar has fan-out 2, correspondingto one span in the source language string and one span in the target language string ofthe translation.
This is what we would expect, given that, in terms of the translationsproduced, STSG is equivalent to SCFG (because the internal tree structure of the rules isirrelevant), and SCFG falls within the class of LCFRS grammars of fan-out 2.
Figure 2bshows a more general example, where the states of the MBOT rule have rank > 1.Now we extend this construction to handle tree symbols of rank zero, which corre-spond to terminal symbols in the LCFRS.
Let ?0 be the sequence of rank zero symbolsappearing at the leaves of l to the left of x1,1, and let ?i for 1 ?
i ?
k be the sequence ofrank zero symbols to the right of xi,d(Si ), and to the left of xi+1,1 if i < k. Let ?i,j be thesequence of symbols of rank zero at the leaves of r appearing in the subtree under theith child of S0 after the jth variable in this subtree and before the j+ 1th variable, with?i,0 being to the left of the first variable, and ?i,p(i) being to the right of the last variable.We can add these sequences of terminal symbols to the LCFRS rule as follows:g(?e1, f1,1, .
.
.
, f1,d(S1 )?, .
.
.
, ?ek, fk,1, .
.
.
, fk,d(Sk )?)
=?
?0e1?1 ?
?
?
ek?k,?1,0f?(1),?
(1)?1,1 ?
?
?
f?(p(1)),?(p(1))?1,p(1),?2,0f?(p(1)+1),?
(p(1)+1)?2,1 ?
?
?
f?(p(2)),?(p(2))?2,p(2),.
.
.
,?d(S0 ),0f?
(p(d(S0 )?1)+1),?
(p(d(S0 )?1)+1)?d(S0 ),1 ?
?
?
f?
(p(d(S0 ))),?
(p(d(S0 ))?d(S0 ),p(d(S0 )) ?An example of this conversion is shown in Figure 3.
In this example, ?1 = of, ?1,1 =?,all other ?
and ?
values are the empty string, and d(S0) = 1.
We refer to the LCFRS ruleconstructed from MBOT rule l?
r as pl?r.Figure 2Examples of the conversion of an MBOT rule to an LCFRS rule.678Gildea On the String Translations Produced by Multi Bottom?Up Tree TransducersFigure 3Conversion of an MBOT rule with symbols of rank zero to an LCFRS production with terminals.Finally, we add a start rule rule S?
g(Si), g(?e, f ?)
= ?e#f ?
for each Si ?
F to gener-ate all final states Si of the MBOT from the start symbol S of the LCFRS.We now show that the language of the LCFRS constructed from a given MBOT isidentical to the yield of the MBOT.
We represent MBOT transductions as derivationtrees, where each node is labeled with an MBOT rule, and each node?s children arethe rules used to produce the subtrees matched by any variables in the rule.
We canconstruct an LCFRS derivation tree by simply relabeling each node with the LCFRS ruleconstructed from the node?s MBOT rule.
Because, in the MBOT derivation tree, eachnode has children which produce the states required by the the MBOT rule?s left-handside (l.h.s.
), it also holds that, in the LCFRS derivation tree, each node has as its childrenrules which expand the set of nonterminals appearing in the parent?s r.h.s.
Thereforethe LCFRS tree constitutes a valid derivation.Given the mapping from MBOT derivations to LCFRS derivations, the followinglemma relates the strings produced by the derivations:Lemma 1Let TMBOT be an MBOT derivation tree with I as its input tree and O as its output tree,and construct TLCFRS by mapping each node nMBOT in TMBOT to a node nLCFRS labeledwith the LCFRS production constructed from the rule at nMBOT.
Let ?t0, t1, .
.
.
, tk?
be thestring tuple returned by the LCFRS combination function at any node nLCFRS in TLCFRS.The string t0 contains the yield of the node of I at which the MBOT rule at the node ofTMBOT corresponding to nLCFRS was applied.
Furthermore, the strings t1, .
.
.
, tk containthe k yields of the k MBOT output subtrees (subtrees of O) that are found as childrenof the root (state symbol) of the MBOT rule?s right-hand side.ProofWhen we apply the LCFRS combination functions to build the string produced by theLCFRS derivation, the sequence of function applications corresponds exactly to thebottom?up application ofMBOT rules to the input tree.
Let us refer to the tuple returnedby one LCFRS combination function g as ?t0, t1, .
.
.
, tk?.
An MBOT rule applying at thebottom of the input tree cannot contain any variables, and for MBOT rules of this type,our construction produces an LCFRS rule with a combination function of the form:g() = ?
?0,?1,0, .
.
.
,?k,0?taking no arguments and returning string constants equal to the yield of the MBOTrule?s l.h.s, and the sequence of yields of the k subtrees under the r.h.s.
?s root.
Now weconsider how further rules in the LCFRS derivation make use of the tuple ?t0, t1, .
.
.
, tk?.Our LCFRS combination functions always concatenate the first elements of the input679Computational Linguistics Volume 38, Number 3tuple in order, adding any terminals present in the portion of the input tree matchedby the MBOT?s l.h.s.
Thus the combination functions maintain the property that thefirst element in the resulting tuple, t0, contains the yield of the subtree of the inputtree where the corresponding MBOT rule applied.
The combination functions combinethe remaining elements in their input tuples in the same order given by the MBOTrule?s r.h.s., again adding any terminals added to the output tree by the MBOT rule.Thus, at each step, the strings t1, .
.
.
, tk returned by LCFRS combination functionscontain the k yields of the k MBOT output subtrees found as children of the root (statesymbol) of the MBOT rule?s r.h.s.
By induction, the lemma holds at each node in thederivation tree.
The correspondence between LCFRS string tuples and MBOT tree yields gives usour first result:Theorem 1yield(MBOT) ?
trans(LCFRS).ProofFrom a given MBOT, construct an LCFRS as described previously.
For any transductionof the MBOT, from Lemma 1, there exists an LCFRS derivation which produces a stringconsisting of the yield of the MBOT?s input and output trees joined by the # symbol.
Inthe other direction, we note that any valid derivation of the LCFRS corresponds to anMBOT transduction on some input tree; this input tree can be constructed by assemblingthe left-hand sides of the MBOT rules from which the LCFRS rules of the LCFRSderivation were originally constructed.
Because there is a one-to-one correspondencebetween LCFRS and MBOT derivations, the translation produced by the LCFRS andthe yield of the MBOT are identical.Because we can construct an LCFRS generating the same translation as the yield ofany given MBOT, we see that yield(MBOT) ?
trans(LCFRS).
The translations produced by MBOTs are equivalent to the translations producedby a certain restricted class of LCFRS grammars, which we now specify precisely.Theorem 2The class of translations yield(MBOT) is equivalent to yield(1-m-LCFRS), where 1-m-LCFRS is defined to be the class of LCFRS grammars where each rule either is a startrule of the form S?
g(Si), g(?e, f ?)
= ?e#f ?, or meets both of the following conditions: The combination function keeps the two sides of the translation separate.That is, it must be possible to writeg(?e1, f1,1, .
.
.
, f1,?1?, .
.
.
, ?er, fr,1, .
.
.
, fr,?r?
)asg1(?e1?, .
.
.
, ?er?
)+ g2(?
f1,1, .
.
.
, f1,?1?, .
.
.
, ?
fr,1, .
.
.
, fr,?r?
)where + represents tuple concatenation, for some functions g1 and g2. The function g1 returns a tuple of length 1.680Gildea On the String Translations Produced by Multi Bottom?Up Tree TransducersProofOur construction for transforming an MBOT to an LCFRS produces LCFRS grammarssatisfying the given constraints, so yield(MBOT) ?
trans(1-m-LCFRS).To show the other direction, we will construct an MBOT from a 1-m-LCFRS.
Foreach 1-m-LCFRS rule of the formS?
g(B1, .
.
.
,Br)g(?e1, f1,1, .
.
.
, f1,?1?, .
.
.
, ?er, fr,1, .
.
.
, fr,?r?)
=g1(?e1?, .
.
.
, ?er?
)+ g2(?
f1,1, .
.
.
, f1,?1?, .
.
.
, ?
fr,1, .
.
.
, fr,?r?
)g1(?e1?, .
.
.
, ?er?)
= ?
?0e1 ?
?
??r?1er?r?g2(?
f1,1, .
.
.
, f1,?1?, .
.
.
, ?
fr,1, .
.
.
, fr,?r?)
= ?t1,1 ?
?
?
t1,n1 , .
.
.
, tm,1 ?
?
?
tm,nm?where each ?i is a string of terminals, and each symbol ti,j is either a variable fi?,j?
, or asingle terminal, we construct the MBOT rule:S?0 B1f1,1 .
.
.
f1,?
(B1 )?
?
?
?r?1 Brfr,1 .
.
.
fr,?
(Br )?r?
SS1t1,1 ?
?
?
t1,n1?
?
?
Smtm,1 ?
?
?
tm,nmBy the same reasoning used for our construction of LCFRS grammars from MBOTs,there is a one-to-one correspondence between derivation trees of the 1-m-LCFRS and theconstructed MBOT, and the yield strings also correspond at each node in the derivationtrees.
Therefore, yield(1-m-LCFRS) ?
yield(MBOT).Because we have containment in both directions, yield(MBOT) = trans(1-m-LCFRS).
We now move on to consider the languages formed by the source and targetprojections of MBOT translations.Grammars of the class 1-m-LCFRS have the property that, for any nonterminal A(other than the start symbol S) having fan-out ?
(A), one span is always realized in thesource string (to the left of the # separator), and ?(A)?
1 spans are always realizedin the target language (to the right of the separator).
This property is introduced bythe start rules S?
g(Si), g(?e, f ?)
= ?e#f ?
and is maintained by all further productionsbecause of the condition on 1-m-LCFRS that the combination function must keep thetwo sides of translation separate.
For a 1-m-LCFRS rule constructed from an MBOT,we define the rule?s source language projection to be the rule obtained by discardingall the target language spans, as well as the separator symbol # in the case of the startproductions.
The definition of 1-m-LCFRS guarantees that the combination functionreturning a rule?s l.h.s.
source span needs to have only the r.h.s.
source spans availableas arguments.For an LCFRS G, we define L(G) to be the language produced by G. We definesource(G) to be the LCFRS obtained by projecting each rule in G. Because more thanone rule may have the same projection, we label the rules of source(G) with their originrule, preserving a one-to-one correspondence between rules in the two grammars.
Sim-ilarly, we obtain a rule?s target language projection by discarding the source languagespans, and define target(G) to be the resulting grammar.681Computational Linguistics Volume 38, Number 3Lemma 2For an LCFRSG constructed from anMBOTM by the given construction, L(source(G))=source(trans(M)), and L(target(G)) = target(trans(M)).ProofThere is a valid derivation tree in the source language projection for each valid deriva-tion tree in the full LCFRS, because for any expansion rewriting a nonterminal of fan-out ?
(A) in the full grammar, we can apply the projected rule to the correspondingnonterminal of fan-out 1 in the projected derivation.
In the other direction, for anyexpansion in a derivation of the source projection, a nonterminal of fan-out ?
(A) willbe available for expansion in the corresponding derivation of the full LCFRS.
Becausethere is a one-to-one correspondence between derivations in the full LCFRS and itssource projection, the language generated by the source projection is the source of thetranslation generated by the original LCFRS.
By the same reasoning, there is a one-to-one correspondence between derivations in the target projection and the full LCFRS,and the language produced by the target projection is the target side of the translationof the full LCFRS.
Lemma 2 implies that it is safe to evaluate the power of the source and targetprojections of the LCFRS independently.
This fact leads to our next result.Theorem 3yield(MBOT)  trans(LCFRS).ProofIn the LCFRS generated by our construction, all nonterminals have fan-out 1 in thesource side of the translation.
Therefore, the source side of the translation is a context-free language, and an MBOT cannot represent the following translation:{(anbncndn, anbncndn) | n ?
1}which is produced by an STAG (Shieber and Schabes 1990; Schabes and Shieber 1994).Because STAG is a type of LCFRS, yield(MBOT)  trans(LCFRS).
Although the source side of the translation produced by an MBOT must be acontext-free language, we now show that the target side can be any language producedby an LCFRS.Theorem 4target(yield(MBOT)) = LCFRSProofGiven an input LCFRS, we can construct an MBOT whose target side corresponds tothe rules in the original LCFRS, and whose source simply accepts derivation trees of theLCFRS.
To make this precise, given an LCFRS rule in the general form:S?
g(B1, .
.
.
,Br)g(?x1,1, .
.
.
, x1,?
(B1 )?, .
.
.
, ?x1,1, .
.
.
, x1,?
(Br )?)
= ?t1,1 ?
?
?
t1,n1 , .
.
.
, t?
(S),1 ?
?
?
t?(S),n?
(S)?682Gildea On the String Translations Produced by Multi Bottom?Up Tree Transducerswhere each symbol ti,j is either some variable xi?,j?
or a terminal from the alphabet ofthe LCFRS, we construct the MBOT rule:SB1x1,1 .
.
.
x1,?
(B1 )?
?
?
Brxr,1 .
.
.
xr,?
(Br )?
SS1t1,1 ?
?
?
t1,n1?
?
?
S?(S)t?
(S),1 ?
?
?
t?(S),n?
(S)where the MBOT?s input alphabet contains a symbol S for each LCFRS nonterminal S,and the MBOT?s output alphabet contains ?
(S) symbols Si for each LCFRS nontermi-nal S. This construction for converting an LCFRS to an MBOT shows that LCFRS ?target(yield(MBOT)).Given our earlier construction for generating the target projection of the LCFRSderived from an MBOT, we know that target(yield(MBOT))?
LCFRS.
Combining thesetwo facts yields the theorem.
4.
Composition of STSGsMaletti et al (2009) discuss the composition of extended top?down tree transducers,which are equivalent to STSGs, as shown by Maletti (2010).
They show that this for-malism is not closed under composition in terms of the tree transformations that arepossible.
In this article, we focus on the string yields of the formalisms under discussion,and from this point of view we now examine the question of whether the yield of thecomposition of two STSGs is itself the yield of an STSG in general.
It is important tonote that, although we focus on the yield of the composition, in our notion of STSGcomposition, the tree structure output by the first STSG still serves as input to thesecond STSG.Maletti et al (2009) give two tree transformations as counterexamples to the compo-sitionality of STSG, shown in Figure 4.
From the point of view of string yield, both of thetransformations are equivalent to an STSG rule that simply copies the three variableswith no re-ordering.
Thus, these counterexamples are not sufficient to show that theyield of the composition of two STSGs is not the yield of an STSG.We now present two STSGs, shown in MBOT notation in Figures 5 and 6, whosecomposition is not a translation produced by an STSG.
The essence of this counterex-ample, explained in more detail subsequently, is that rules from the two STSGs applyin an overlapping manner to unboundedly long sequences, as in the example of ArnoldFigure 4Examples of tree transformations not contained in STSG, from Maletti et al (2009).
Here Gndenotes a unary chain of G?s of arbitrary length.683Computational Linguistics Volume 38, Number 3Figure 5First MBOT in composition.and Dauchet (1982, section 3.4).
To this approach we add a re-ordering pattern whichresults in a translation that we will show not to be possible with STSG.The heart of each MBOT is the first rule, which reverses the order of adjacentsequences of c?s and d?s.
The MBOT of Figure 5 generates the translation:{(a[cn2i?1dn2i ]i=1a, a[dn2icn2i?1 ]i=1a) | ni ?
1,?
1}whereis the number of times the first rule of the transducer is applied, and the notation[xi]ni=1 indicates the string concatenation x1x2 ?
?
?
xn.
Here we have 2repeated sequencesof characters c and d, each occurring ni times, with each integer ni for 1 ?
i ?
2varyingfreely.The secondMBOT reverses sequences of c?s and d?s in a pattern that is offset by onefrom the pattern of the first MBOT.
It produces the translation:{(adn1 [cn2idn2i+1 ]?1i=1 cn2a, adn1 [dn2i+1cn2i ]?1i=1 cn2a) | ni ?
1,?
1}When we compose the two MBOTs, the yield of the resulting transducer is thetranslation:Tcrisscross =?
?=1Tcrisscross (1)684Gildea On the String Translations Produced by Multi Bottom?Up Tree TransducerswhereTcrisscross = {(a[cn2i?1dn2i ]i=1a, adn2 [dn2i+2cn2i?1 ]?1i=1 cn2?1a) | ni ?
1} (2)A visualization of the alignment pattern of this translation is shown in Figure 7.
Wewill show that Tcrisscross cannot be produced by any SCFG.We define an SCFG to be a system (V,?,?,P,S) where V is a set of nonterminals,?
and ?
are the terminal alphabets of the source and target language respectively,S ?
V is a distinguished start symbol, and P is a set of productions of the followinggeneral form:X0 ?
X11 ?
?
?Xnn , X?(1)?
(1) ?
?
?X?(n)?
(n)Figure 6Second MBOT in composition.Figure 7Translation resulting from MBOT composition with= 8.685Computational Linguistics Volume 38, Number 3where ?
is a permutation of length n, and the variables Xi for 0 ?
i ?
n range overnonterminal symbols (for example, X1 and X2 may both stand for nonterminal A).In SCFG productions, the l.h.s.
nonterminal rewrites into a string of terminals andnonterminals in both the source and target languages, and pairs of r.h.s.
nonterminalsthat are linked by the same superscript index must be further rewritten by the samerule.In terms of string translations, STSGs and SCFGs are equivalent, because any SCFGis also an STSG with rules of depth 1, and any STSG can be converted to an SCFG withthe same string translation by simply removing the internal tree nodes in each rule.
Wewill adopt SCFG terminology for our proof because the internal structure of STSG rulesis not relevant to our result.For a fixed value of, the translation Tcrisscross can be produced by an SCFG ofrank 2, shown in Figure 8, because one rule can produce 2nonterminals arrangedin the permutation of Figure 7.
(In the context of SCFGs, rank refers to the maxi-mum number of nonterminals on the r.h.s.
of a rule.)
We will show that strings ofthis form cannot be produced by any SCFG of rank less than 2.
Intuitively, factoringthe alignment pattern of Figure 7 into smaller SCFG rules would require identifyingsubsequences in the two languages that are consistently aligned to one another, and, ascan be seen from the figure, no such subsequences exist.
Becausecan be unboundedlylarge in our translation, the translation cannot be produced by any SCFG of fixedrank.We will assume, without loss of generality, that any SCFG is written in a normalform such that each rule?s r.h.s.
either contains only terminals in each language, orcontains only nonterminals.
An SCFG can be transformed into this normal form byapplying the following procedure to each rule:1.
Associate each sequence of terminals with the preceding nonterminal, orthe following nonterminal in the case of initial terminals.2.
Replace each group consisting of a nonterminal and its associatedterminals with a fresh nonterminal A, and add a rule rewriting A as thegroup in source and target.
(Nonterminals with no associated terminalsmay be left intact.)3.
In each rule created in the previous step, replace each sequence ofterminals with another fresh nonterminal B, and add a rule rewriting B asthe terminal sequence in source and target.Figure 9 shows an example of this grammar transformation.
Because we do not changethe rank of existing rules, and we add rules of rank no greater than 3, the transformationdoes not increase the rank of any grammar having rank at least 3.Figure 8An SCFG producing translation Tcrisscross for fixed.686Gildea On the String Translations Produced by Multi Bottom?Up Tree TransducersFigure 9Conversion of grammar (a) to normal form (b) in which each rule has only nonterminals or onlyterminals on the r.h.s.Figure 10An SCFG derivation produced by applying each rule in Figure 9b once, in the order given inFigure 9b.
Indices of linked nonterminals are renumbered after each step to be monotonicallyincreasing in the English side of the derivation.
The preterminal permutation of the derivation,(3,2,1), is the sequence of indices on the Chinese side in the last step before any terminals areproduced.In an SCFG derivation, nonterminals in either language are linked as shown in Fig-ure 10.
We restrict derivations to apply rules producing terminals after applying allother rules.
We refer to nonterminals at the last step in which the sentential formconsists exclusively of nonterminals as preterminals, and we refer to a pair of linkedpreterminals as an aligned preterminal pair.
Assuming that aligned preterminal pairsare indexed consecutively in the source side of the sentential form, we refer to thesequence of indices in the target side as the preterminal permutation of a derivation.For example, the preterminal permutation of the derivation in Figure 10 is (3,2,1).
Thepermutation of any sentential form of an SCFG of rank r can be produced by composingpermutations of length no greater than r, by induction over the length of the derivation.Thus, while the permutation (3,2,1) of our example can be produced by composingpermutations of length 2, the preterminal permutation (2,4,1,3) can never be producedby an SCFG of rank 2 (Wu 1997).
In fact, this restriction also applies to subsequences ofthe preterminal permutation.Lemma 3Let ?
be a preterminal permutation produced by an SCFG derivation containing rulesof maximum rank r, and let ??
be a permutation obtained from ?
by removing someelements and renumbering the remaining elements with a strictly increasing function.Then ??
falls within the class of compositions of permutations of length r.ProofFrom each rule in the derivation producing preterminal permutation ?, construct a newrule by removing any nonterminals whose indices were removed from ?.
The resultingsequence of rules produces preterminal permutation ??
and contains rules of rank nogreater than r. As an example of Lemma 3, removing any element from the permutation (3,2,1) resultsin the permutation (2,1), which can still (trivially) be produced by an SCFG of rank 2.687Computational Linguistics Volume 38, Number 3We will make use of another general fact about SCFGs, which we derive by ap-plying Ogden?s Lemma (Ogden 1968), a generalized pumping lemma for context-freelanguages, to the source language of an SCFG.Lemma 4 (Ogden?s Lemma)For each context-free grammar G = (V,?,P,S) there is an integer k such that for anyword ?
in L(G), if any k or more distinct positions in ?
are designated as distinguished,then there is some A in V and there are words ?, ?, ?, ?, and ?
in ??
such that: S??
?A?
??
??A??
??
?????
= ?, and hence ??m??m?
?
L(G)for all m ?
0. ?
contains at least one of the distinguished positions. Either ?
and ?
both contain distinguished positions, or ?
and ?
bothcontain distinguished positions. ???
contains at most k distinguished positions.Ogden?s lemma can be extended as follows to apply to SCFGs.Lemma 5For each SCFG G = (V,?,?,P,S) having source alphabet?
and target alhabet?, thereis an integer k such that for any string pair (?,??)
in L(G), if any k or more distinctpositions in ?
are designated as distinguished, then there is some A in V and there arewords ?, ?, ?, ?, and ?
in ??
and ?
?, ?
?, ?
?, ?
?, and ??
in??
such that: (S1,S1)??
(?A 1 ?, ?
?A 1 ??)??
(?
?A 1 ?
?, ???
?A 1 ????)??(????
?, ??????????)
= (?,??
), and hence(??m?
?m?, ??(??)m??(??)m??)
?
L(G) for all m ?
0. ?
contains at least one of the distinguished positions. Either ?
and ?
both contain distinguished positions, or ?
and ?
bothcontain distinguished positions. ???
contains at most k distinguished positions.Note that there are no guarantees on the form of ?
?, ?
?, ?
?, ?
?, and ?
?, and indeed thesemay all be the empty string.ProofThere must exist some sequence of rules in the source projection of Gwhich licenses thederivation A??
?A?.
If we write the jth rule in this sequence as Aj ?
?j, there mustexist a synchronous rule in G of the form Aj ?
?j, ?
?j that rewrites the same nontermi-nal.
Thus G licenses a synchronous derivation (A1, A1)??
(?A 1 ?, ?
?A 1 ??)
for some??
and ??.
Similarly, the source derivation S??
?A?
has a synchronous counterpart(S1, S1)??
(?A 1 ?, ?
?A 1 ??)
for some ??
and ?
?, and the source derivation A?
?
hasa synchronous counterpart (A1, A1)?
(?, ??)
for some ??.
Because the synchronous688Gildea On the String Translations Produced by Multi Bottom?Up Tree Transducersderivation (A1, A1)??
(?A 1 ?, ?
?A 1 ??)
can be repeated any number of times, thestring pairs(??m?
?m?, ??(??)m??(??)m??)
(3)are generated by the SCFG for all m ?
0.
The further conditions on ?, ?, ?, ?, and ?follow directly from Ogden?s Lemma.
We refer to a substring arising from a term cni or dni in the definition of Tcrisscross(Equation (2)) as a run.
In order to distinguish runs, we refer the run arising from cni ordni as the ith run.
We refer to the pair (cni , cni ) or (dni , dni ) consisting of the ith run inthe source and target strings as the ith aligned run.
We now use Lemma 5 to show thataligned runs must be generated from aligned preterminal pairs.Lemma 6Assume that some SCFG G?
generates the translation Tcrisscross for some fixed.
Thereexists a constant k such that, in any derivation of grammarG?
having each ni > k, for anyi, 1 ?
i ?
2, there exists at least one aligned preterminal pair among the subsequencesof source and target preterminals generating the ith aligned run.ProofWe consider a source string ?, (?, ??)
?
Tcrisscross, such that the length ni of each runis greater than the constant k of Lemma 5.
For a fixed i, 1 ?
i ?
2, we consider thedistinguished positions to be all and only the terminals in the ith run.
This implies thatthe run can be pumped to be arbitrarily long; indeed, this follows from the definition ofthe language itself.Because our distinguished positions are within the ith run, and because Lemma 5guarantees that either ?, ?, and ?
all contain distinguished positions or ?, ?, and ?all contain distinguished positions, we are guaranteed that either ?
or ?
lies entirelywithin the ith run.
Consider the case where ?
lies within the run.
We must considerthree possibilities for the location of ?
in the string:Case 1.
The string ?
also lies entirely within the ith run.Case 2.
The string ?
contains substrings of more than one run.
This cannot occur, becausepumped strings of the form ??m??m?
would contain more than 2runs, which is notallowed under the definition of Tcrisscross.Case 3.
The string ?
lies entirely within the jth run, where j = i.
The strings ??m?
?m?have the same form as ????
?, with the exception that the ith and jth runs are extendedfrom lengths ni and nj to some greater lengths n?i and n?j .
By the definition of Tcrisscross,for each source string, only one target string is permitted.
For string pairs of the form ofEquation (3) to belong to Tcrisscross, ??
and ??
must lie within the ith and jth aligned runsin the target side.
Because the permutation of Figure 7 cannot be decomposed, theremust exist some k such that the kth aligned run lies between the ith and jth alignedruns in one side of the translation, and outside the ith and jth aligned runs in the otherside of the translation.
If this were not the case, we would be able to decompose thepermutation by factoring out the subsequence between the ith and jth runs on bothsides of the translation.
Consider the case where the kth aligned run lies between the ithand jth aligned runs in the source side, and therefore is a substring of ?
in the source,689Computational Linguistics Volume 38, Number 3and a substring of either ??
or ??
in the target.
We apply Lemma 5 a second time, withall terminals of the kth run as the distinguished positions, to the derivation (A, A)??
(?, ??)
by taking A as the start symbol of the grammar.
This implies that there exist ??,?
?, ?
?, ??
?, ??
?, and ???
such that(?,??)
= (?????????
?, ?????????????????
)and all strings(??m??n???
?n?m?, ??(??)m(???)n???(???)n(??)m??
)are members of the translation Tcrisscross.
Either ??
or ??
is a substring of source side ofthe kth aligned run, so the kth aligned run can be pumped to be arbitrarily long inthe source without changing its length in the target.
This contradicts the definition ofTcrisscross.
Similarly, the case where the kth aligned run lies between ??
and ??
in thetarget leads to a contradiction.
Thus the assumption that j = imust be false.Because Cases 2 and 3 are impossible, ?
must lie entirely within the ith run.
Simi-larly, in the case where ?
contains distinguished positions, ?must lie within the ith run.Thus both ?
and ?
always lie entirely within the ith aligned run.Because the ?
and ?
lie within the ith aligned run, the strings ??m??m?
have thesame form as ????
?, with the exception that the ith run is extended from length ni tosome greater length n?i .
For the pairs of Equation (3) to be members of the translation,??
and ??
must be substrings of the ith aligned run in the target.
Because ?m?
?m and(??)m??(??
)m were derived from the same nonterminal, the two sequences of pretermi-nals generating these two strings consist of aligned preterminal pairs.
Because both?m?
?m and (??)m??(??
)m are substrings of the ith aligned run, we have at least onealigned preterminal pair among the source and target preterminal sequences generatingthe ith aligned run.
Lemma 7Assume that some SCFG G?
generates the translation Tcrisscross for some fixed.
Thereexists a constant k such that, if (?,??)
is a string pair generated by G?
having each ni > k,any derivation of (?,??)
with grammar G?
must contain a rule of rank at least 2.ProofBecause the choice of i in Lemma 6 was arbitrary, each aligned run must contain at leastone aligned preterminal pair.
If we select one such preterminal pair from each run, theassociated permutation is that of Figure 7.
This permutation cannot be decomposed, so,by Lemma 3, it cannot be generated by an SCFG derivation containing only rules ofrank less than 2.
We will use one more general fact about SCFGs to prove our main result.Lemma 8Let G be an SCFG and let T = L(G) be the translation it produces.
Let F be a finite statemachine, and let R = L(F) be the regular language it accepts.
Let T?
be the translationderived by intersecting the source strings of T with RT?
= {(s, t) | (s, t) ?
T, s ?
R}690Gildea On the String Translations Produced by Multi Bottom?Up Tree TransducersThen there exists an SCFG G?
such that T?
= L(G?
).ProofLet V be the nonterminal set of G, and let S be the state set of F. Construct the SCFG G?with nonterminal set V ?
S?
S by applying the construction of Bar-Hillel, Perles, andShamir (1961) for intersection of a CFG and finite state machine to the source side ofeach rule in G. Now we are ready for our main result.Theorem 5SCFG = yield(STSG)  yield(STSG;STSG), where the semicolon denotes composition.ProofAssume that some SCFG G generates Tcrisscross.
Note that Tcrisscross is the result of inter-secting the source of Tcrisscross with the regular language a[c+d+]a.
By Lemma 8, we canconstruct an SCFG G generating Tcrisscross.
By Lemma 7, for each, G has rank at least2.
The intersection construction does not increase the rank of the grammar, so G hasrank at least 2.
Becauseis unbounded in the definition of Tcrisscross, and because anySCFG has a finite maximum rank, Tcrisscross cannot be produced by any SCFG.
4.1 Implications for Machine TranslationThe ability of MBOTs to represent the composition of STSGs is given as a motivation forthe MBOT formalism byMaletti (2010), but this raises the issue of whether synchronousparsing and machine translation decoding can be undertaken efficiently for MBOTsresulting from the composition of STSGs.In discussing the complexity of synchronous parsing problems, we distinguishthe case where the grammar is considered part of the input, and the case where thegrammar is fixed, and only the source and target strings are considered part of the input.For SCFGs, synchronous parsing is NP-complete when the grammar is considered partof the input and can have arbitrary rank.
For any fixed grammar, however, synchronousparsing is possible in time polynomial in the lengths of the source and target strings,with the degree of the polynomial depending on the rank of the fixed SCFG (Satta andPeserico 2005).
Because MBOTs subsume SCFGs, the problem of recognizing whether astring pair belongs to the translation produced by an arbitrary MBOT, when the MBOTis considered part of the input, is also NP-complete.Given our construction for converting an MBOT to an LCFRS, we can use standardLCFRS tabular parsing techniques to determine whether a given string pair belongsto the translation defined by the yield of a fixed MBOT.
As with arbitrary-rank SCFG,LCFRS parsing is polynomial in the length of the input string pair, but the degree of thepolynomial depends on the complexity of the MBOT.
To be precise, the degree of thepolynomial for LCFRS parsing is?ri=0?
(Si) (Seki et al 1991), which yields?ri=0(1+d(Si)) when applied to MBOTs.If we restrict ourselves to MBOTs that are derived from the composition of STSGs,synchronous parsing is NP-complete if the STSGs to compose are part of the input,because a single STSG suffices.
For a composition of fixed STSGs, we obtain a fixedMBOT, and polynomial time parsing is possible.
Theorem 5 indicates that we cannotapply SCFG parsing techniques off the shelf, but rather that we must implement sometype of more general parsing system.
Either of the STSGs used in our proof of Theorem 5691Computational Linguistics Volume 38, Number 3can be binarized and synchronously parsed in time O(n6), but tabular parsing for theLCFRS resulting from composition has higher complexity.
Thus, composing STSGsgenerally increases the complexity of synchronous parsing.The problem of language-model?integrated decoding with synchronous grammarsis closely related to that of synchronous parsing; both problems can be seen as inter-secting the grammar with a fixed source-language string and a finite-state machineconstraining the target-language string.
The widely used decoding algorithms for SCFG(Yamada and Knight 2002; Zollmann and Venugopal 2006; Huang et al 2009) searchfor the highest-scoring translation when combining scores from a weighted SCFG anda weighted finite-state language model.
As with SCFG, language-model?integrateddecoding for weighted MBOTs can be performed by adding n-gram language modelstate to each candidate target language span.
This, as with synchronous parsing, givesan algorithm which is polynomial in the length of the input sentence for a fixed MBOT,but with an exponent that depends on the complexity of the MBOT.
Furthermore,Theorem 5 indicates that SCFG-based decoding techniques cannot be applied off theshelf to compositions of STSGs, and that composition of STSGs in general increasesdecoding complexity.Finally, we note that finding the highest-scoring translation without incorporatinga language model is equivalent to parsing with the source or target projection of theMBOT used to model translation.
For the source language of the MBOT, this impliestime O(n3) because the problem reduces to CFG parsing.
For the target language ofthe MBOT, this implies polynomial-time parsing, where the degree of the polynomialdepends on the MBOT, as a result of Theorem 4.5.
ConclusionMBOTs are desirable for natural language processing applications because they areclosed under composition and can be used to represent sequences of transforma-tions of the type performed by STSGs.
However, the string translations producedby MBOTs representing compositions of STSGs are strictly more powerful than thestring translations produced by STSGs, which are equivalent to the translations pro-duced by SCFGs.
From the point of view of machine translation, because parsingwith general LCFRS is NP-complete, restrictions on the power of MBOTs will benecessary in order to achieve polynomial?time algorithms for synchronous parsingand language-model?integrated decoding.
Our result on the string translations pro-duced by compositions of STSGs implies that algorithms for SCFG-based synchronousparsing or language-model-integrated decoding cannot be applied directly to theseproblems, and that composing STSGs generally increases the complexity of these prob-lems.
Developing parsing algorithms specific to compositions of STSGs, as well aspossible restrictions on the STSGs to be composed, presents an interesting area forfuture work.AcknowledgmentsWe are grateful for extensive feedbackon earlier versions of this work fromGiorgio Satta, Andreas Maletti, AdamPurtee, and three anonymous reviewers.This work was partially funded by NSFgrant IIS-0910611.ReferencesAho, Albert V. and Jeffery D. Ullman.
1972.The Theory of Parsing, Translation, andCompiling, volume 1.
Prentice-Hall,Englewood Cliffs, NJ.Arnold, Andre?
and Max Dauchet.
1982.Morphismes et bimorphismes692Gildea On the String Translations Produced by Multi Bottom?Up Tree Transducersd?arbres.
Theoretical Computer Science,20:33?93.Bar-Hillel, Y., M. Perles, and E. Shamir.1961.
On formal properties of simplephrase structure grammars.
Zeitschriftfu?r Phonetik, Sprachwissenschaft undKommunikationsforschung, 14:143?172.Reprinted in Y. Bar-Hillel.
1964.
Languageand Information: Selected Essays on theirTheory and Application, Addison-Wesley,Boston, MA, pages 116?150.Chiang, David.
2007.
Hierarchicalphrase-based translation.
ComputationalLinguistics, 33(2):201?228.Engelfriet, J., E. Lilin, and A. Maletti.2009.
Extended multi bottom?uptree transducers.
Acta Informatica,46(8):561?590.Galley, Michel, Jonathan Graehl, KevinKnight, Daniel Marcu, Steve DeNeefe,Wei Wang, and Ignacio Thayer.
2006.Scalable inference and training ofcontext-rich syntactic translation models.In Proceedings of the International Conferenceon Computational Linguistics/Association forComputational Linguistics (COLING/ACL-06), pages 961?968, Sydney.Huang, Liang, Hao Zhang, Daniel Gildea,and Kevin Knight.
2009.
Binarization ofsynchronous context-free grammars.Computational Linguistics, 35(4):559?595.Joshi, A. K., L. S. Levy, and M. Takahashi.1975.
Tree adjunct grammars.
Journal ofComputer and System Sciences, 10:136?163.Joshi, A. K. and Y. Schabes.
1997.Tree-adjoining grammars.
In G. Rozenbergand A. Salomaa, editors, Handbook ofFormal Languages, volume 3.
Springer,Berlin, pages 69?124.Lilin, Eric.
1981.
Proprie?te?s de clo?ture d?uneextension de transducteurs d?arbresde?terministes.
In CAAP, volume 112 ofLNCS.
Springer, Berlin, pages 280?289.Maletti, Andreas.
2010.
Why synchronoustree substitution grammars?
In Proceedingsof the 2010 Meeting of the North AmericanChapter of the Association for ComputationalLinguistics (NAACL-10), pages 876?884,Los Angeles, CA.Maletti, Andreas, Jonathan Graehl, MarkHopkins, and Kevin Knight.
2009.
Thepower of extended top?down treetransducers.
SIAM Journal on Computing,39:410?430.Melamed, I. Dan.
2003.
Multitext grammarsand synchronous parsers.
In Proceedingsof the 2003 Meeting of the North AmericanChapter of the Association for ComputationalLinguistics (NAACL-03), pages 158?165,Edmonton.Melamed, I. Dan, Giorgio Satta, andBen Wellington.
2004.
Generalizedmultitext grammars.
In Proceedings of the42nd Annual Conference of the Associationfor Computational Linguistics (ACL-04),pages 661?668, Barcelona.Ogden, William F. 1968.
A helpful result forproving inherent ambiguity.MathematicalSystems Theory, 2(3):191?194.Rambow, Owen and Giorgio Satta.
1999.Independent parallelism in finite copyingparallel rewriting systems.
TheoreticalComputer Science, 223(1-2):87?120.Satta, Giorgio.
1992.
Recognition of LinearContext-Free Rewriting Systems.
InProceedings of the 30th Annual Conference ofthe Association for Computational Linguistics(ACL-92), pages 89?95, Newark, DE.Satta, Giorgio and Enoch Peserico.
2005.Some computational complexity results forsynchronous context-free grammars.
InProceedings of Human Language TechnologyConference and Conference on EmpiricalMethods in Natural Language Processing(HLT/EMNLP), pages 803?810, Vancouver.Schabes, Yves and Stuart M. Shieber.
1994.An alternative conception of tree-adjoiningderivation.
Computational Linguistics,20:91?124.Seki, H., T. Matsumura, M. Fujii, andT.
Kasami.
1991.
On multiple context-freegrammars.
Theoretical Computer Science,88:191?229.Shieber, Stuart and Yves Schabes.
1990.Synchronous tree-adjoining grammars.In Proceedings of the 13th InternationalConference on Computational Linguistics(COLING-90), volume III, pages 253?258,Helsinki.Vijay-Shankar, K., D. L. Weir, and A. K.Joshi.
1987.
Characterizing structuraldescriptions produced by variousgrammatical formalisms.
In Proceedings ofthe 25th Annual Conference of the Associationfor Computational Linguistics (ACL-87),pages 104?111, Stanford, CA.Wu, Dekai.
1997.
Stochastic inversiontransduction grammars and bilingualparsing of parallel corpora.
ComputationalLinguistics, 23(3):377?403.Yamada, Kenji and Kevin Knight.
2002.
Adecoder for syntax-based statistical MT.
InProceedings of the 40th Annual Conference ofthe Association for Computational Linguistics(ACL-02), pages 303?310, Philadelphia, PA.Zollmann, Andreas and Ashish Venugopal.2006.
Syntax augmented machinetranslation via chart parsing.
In Proceedingsof the Workshop on Statistical MachineTranslation, pages 138?141, New York, NY.693
