PREDICT ING AND MANAGINGSPOKEN DISFLUENCIES  DURINGHUMAN-COMPUTER INTERACTION*Sharon OviattComputer Dialogue Laboratory & Artificial Intelligence CenterSKI International, 333 Ravenswood Avenue, Menlo Park, CA.
94025ABSTRACTThis research characterizes the spontaneous spoken disfluen-cies typical of human-computer interaction, and presents apredictive model accounting for their occurrence.
Data werecollected uring three empirical studies in which people spokeor wrote to a highly interactive simulated system.
The stud-ies involved within-subject factorial designs in which inputmodality and presentation format were varied.
Spoken dis-fluency rates during human-computer interaction were doc-umented to be substantially ower than rates typically ob-served during comparable human-human speech.
Two sep-arate factors, both associated with increased planning de-mands, were statistically related to increased speech disflu-ency rates: (1) length of utterance, and (2) lack of struc-ture in the presentation format.
Regression techniques re-vealed that a linear model based simply on utterance l ngthaccounts for over 77% of the variability in spoken disflu-encies.
Therefore, design techniques capable of channelingusers' speech into briefer sentences potentially could elim-inate most spoken disfluencies.
In addition, the degree ofstructure in the presentation format was manipulated in amanner that successfully elimluated 60 to 70% of all disflu-ent speech.
The long-term goal of this research is to provideempirical guidance for the design of robust spoken languagetechnology.1.
INTRODUCTIONRecently, researchers interested in spoken language process-ing have begun searching for reliable methods to detect andcorrect disfluent input automatically during interactions withspoken language systems \[2, 4, 9\].
In general, this researchhas focused on identifying acoustic-prosodic cues for detect-ing self-repairs, either alone or in combination with syntac-tic, semantic, and pattern matching information.
To date,however, possible avenues for simply reducing or eliminatingdisfluencies through manipulation of basic interface featureshave not been explored.Another underdeveloped but central theme in disfluency re-search is the relation between spoken disfluencies and plan-ning demands.
Although it is frequently claimed that dis-fluencies rise with increased planning demands of differentkinds \[3\], the nature of this relation remains poorly under-stood.
The major factors contributing to planning have yet*This research was supported by Grant No.
IRI-9213472from the National Science Foundation, contracts from USWest,AT&T/NCR, and ATR International to SRI International, andequipment donations from Apple Computer, Sun Microsystems,and Wacom Inc.to be identified and defined in any comprehensive manner,or linked to disfluencies and self-repairs.
From the viewpointof designing systems, information on the dynarnics of whatproduces disfluencies, and how to structure interfaces to min-imize them, could improve the robust performance of spokenlanguage systems.A related research issue is the extent o which qualitativelydifferent ypes of speech may differ in their disfluency rates.That is, does the rate of spoken disfluencies tend to be stable,or variable?
If variable, do disfluency rates differ systemat-ically between human-human and human-computer speech?And are disfluency rates sufficiently variable that techniquesfor designing spoken language interfaces might exert muchleverage in reducing them?
To compare disfluency rates di-rectly across different types of human-human and human-computer interactions, research needs to be based on com-parable rate-per-word measures, the same definition of dis-fluencies and self-repairs, and so forth, in order to obtainmeaningful comparisons.For the purpose of the present research, past studies bythe author and colleagues \[1, 6, 7\] were reanalyzed: (1)to yield data on the rate of disfluencies for four differenttypes of human-human speech, and (2) to conduct com-parative analyses of whether human-human disfluencies .dif-fer from human-computer ones.
In addition, three simula-tion studies of human-computer interaction were conducted,which generated ata on spoken and handwritten disfluen-cies.
Apart from comparing disfluencies in different com-munication modalities, two separate factors associated withplanning demands were examined.
First, presentation formatwas manipulated to investigate whether degree of structuremight be associated with disfluencies.
It was predicted thata relatively unconstrained format, which requires the speakerto self-structure and plan to a greater degree, would lead to ahigher ate of speech disfluencies.
Second, the rate of disflu-encies was examined in sentences of varying length.
Spokenutterances graduated in length were compared to determinewhether longer sentences have an elevated rate of disfluenciesper word, since they theoretically require more planning.
Fi-nally, implications are outlined for designing future interfacescapable of substantially reducing disfluent input.2.
SIMULATION EXPERIMENTS ONHUMAN-COMPUTERINTERACTIONThis section outlines three experiments on human spoken andhandwritten i put to a simulated system, with spoken dlsflu-222encies constituting the primary analytical focus.2.1.
MethodSubjects ,  Tasks, and  Procedure -  Forty-four subjectsparticipated in this research as paid volunteers.
A USer-vice 'l~ansaction System" was simulated that could assistusers with tasks that were either (1) verbal-temporal (e.g.,conference registration or cax rental exchanges, in whichproper names and scheduling information predominated), or(2) computational-numeric (e.g., personal banking or scien-tific calculations, in which digits and symbol/sign informa-tion predominated).
During the study, subjects first receiveda general orientation to the Service Transaction System, andthen were given practice using it to complete tasks.
They re-ceived instructions on how to enter information on the LCDtablet when writing, speaking, and free to use both morali-ties.
When speaking, subjects held a stylus on the tablet asthey spoke.People also were instructed on completing tasks in two dif-ferent presentation formats.
In an unconstrained format,they expressed information in an open workspace, with nospecific system prompts used to direct their speech or writ-ing.
People simply continued providing information whilethe system responded interactively with confirmations.
Forexample, in this format they spoke digits, computationalsigns, and requested totals while holding their stylus on anopen %cratch pad" area of their LCD screen.
During otherinteractions, the presentation format was explicitly struc-tured, with linguistic and graphical cues used to structurethe content and order of people's input as they worked.For example, in the verbal-temporal simulations, form-basedprompts were used to elicit input (e.g., Car  pickup lo-cation I 0, and in the computational-numeric simulation, patterned graphical layouts were usedto elicit specific digits and symbols/signs.Other than specifying the input modality and format, an ef-fort was made not to influence the manner in which peopleexpressed themselves.
People's input was received by an in-formed assistant, who performed the role of interpreting ~ndresponding as a fully functional system would.
Essentially,the assistant tracked the subject's written or spoken input,and clicked on predefined fields at a Sun SPARCstation tosend confirmations back to the subject.Semi -Automat ic  S imulat ion Technique- In developingthis simulation, an emphasis was placed on providing auto-mated support for streamlining the simul~ttion to the extentneeded to create facile, subject-paced interactions with deaxfeedback, and to have compaxable specifications for the differ-ent input modalities.
In the present simulation environment,response delays averaged 0.4 second, with less than a 1-seconddelay in all conditions.
In addition, the simulation was or-ganized to transmit analogues of human backchannel andpropositional confirmations, with propositional-level comb-inations embedded in a compact ransaction receipt.
Thesimulation also was designed to be sufficiently automated sothat the assistant could concentrate attention on monitor-ing the accuracy of incoming information, and on maintain-ing sufficient vigilance to ensure prompt responding.
Thissemi-automation contributed to the fast pace of the simula-tion, and to a low rate of technical errors.
Details of thesimulation technique and its capabilities have been detailedelsewhere \[8\].Research Design and  Data  Capture- Three studieswere completed in which the research design was a com-pletely crossed factorial with repeated measures.
In all stud-ies, the main factors of interest included: (1) communicationmodality - speech-only, pen-only, combined pen/voice, and(2) presentation format - form-based, unconstrained.
Thefirst two studies exmmined disfluencies during communica-tion of verbal-temporal content.
To test the generality ofcertain findings, a third study was conducted that compareddisfluencies in computational-numeric content.In total, data were available from 528 tasks for analysis ofspoken and written disfluencies.
All human-computer inter-actions were videotaped.
Hardcopy transcripts also were cre-ated, with the subject's handwritten input captured auto-matically, and spoken input transcribed onto the printouts.Transcr ipt  Coding-  To summarize briefly, spontaneouslyoccurring disfluencies and self-corrections were totaled foreach subject and condition.
The total number of disflu-encies per condition then was converted to a rate per 100words, and average disfluency rates were summaxized as afunction of condition and utterance length.
Disfluencieswere classified into the following types: (1) content self-corrections- task-content errors that were spontaneouslycorrected as the subject spoke or wrote, (2) false starts--alt~ations to the grammatical structure of an utterance thatoccurred spontaneously as the subject spoke or wrote, (3)verbatim repetitions-- retracings or repetitions of a letter,phoneme, syllable, word, or phrase that occurred sponta-neously as the subject spoke or wrote, (4) frilled pauses--spontaneous nonlexical sounds that frill pauses in runningspeech, which have no analogue in writing, (5) self-correctedsp~lllngs and abbreviations-- spontaneously corrected mis-spelled words or further specification of abbreviations, whichoccur in writing but have no analogue in speech.2.2.
Resu l tsFigure 1 summarizes the percentage of all spoken and writ-ten distiuencies representing different categories during com-munication of verbal-temporal content (i.e., studies 1 and2).
However, when people communicated digits (i.e., study3), disfluencies representing the diiferent categories were dis-tributed differently.
Filled pauses dropped from 46% to15.5% of all observed isfluencies.
In contrast, content cor-rections of digits increased from 25% to 34%, repetitions in-creased from 21% to 31.5%, and false staxts increased from8% to 19% of all disfluencies.
This drop in frilled pauses andincrease in other types of disfluency is niost likely relatedto the much briefer utterance lengths observed during thecomputational-numeric tasks.
CCleaxly, the relative distribu-tion of different types of disfluency fluctuates with the contentand structure of the information presented.The overall baseline rate of spontaneous disfluencies and self-corrections was 1.33 per 100 words in the verbal-ten~poralsimulations, or a total of 1.51 disfluencies per task set.
Therate per condition ranged from an average of 0.78 per 100223100%8060i Speechi Wriung40200 a - -~======i~====.~===i=~+D<=" --??
'/ -+'o+" i ,- o ~" .m" .
.~,',~..':,~Figure 1.
Psrcentage cf  all spoken anct written disfluencies indifferent care.gores.words when speaking to a form, 1.17 when writing to a form,1.61 during unconstrained writing, and a high of 1.74 dur-ing unconstrained speech.
Figure 2 illustrates this rate ofdisfluencies as ~ function of mode and format.Wilcoxon Signed Ranks tests revealed no significant modal-ity difference in the rate of disfluent input, which averaged1.26 per 100 words for speech and 1.39 for writing, T+ = 75(N = 17), z < 1.
However, the rate of disfluencies was 1.68per 100 words in the unconstrained format, in comparisonwith a reduced .98 per 100 words during form-based interac-tions.
Followup analyses revealed no significant difference inthe disfluency rate between formats when people wrote, T+= 64.5 (N = 14), p > .20.
However, significantly increaseddisfluencies were evident in the unconstrained format com-pared to the form-based one when people spoke, T+ = 88(N = 14), p < .015, one-tailed.
This significant elevation wasreplicated for unconstrained speech that occurred during thefree choice condition, 7% = 87 (N -- 14), p < .015, one-tailed,which simulated a multimodal spoken exchange rather thana unimodal one.A very similax pattern of disfluency rates per conditionemerged when people communicated digits.
In study 3, thebaseline rate of spontaneous disfluencies averaged 1.37 per100 words, with 0.87 when speaking to a form, 1.10 whenwriting to a. form, 1.42 during unconstrained writing, and ahigh of 1.87 during unconstrained speech.
Likewise, WilcoxonSigned Ranks tests revealed no significant dit~erence in thedisfluency rate between formats when people wrote, T-t- =36.5 (N = 11), p > .20, although significantly increased is-fluencies again were apparent in the unconstrained formatcompared to the form-based one when people spoke, T+ =.2OSpeech1.7t.6 WHt~ngl.:~'1.4'I.3'I.
?Tl.l'1.01o9 t0.80.7 i ,Fonm-bascd Unconswalnecl?r~scnmz/on Form=Figure 2.
Increasing raze of spoken disfluencics per 100words as a function ofsmacmre in presentation format.77 (N = 13), p < .015, one-tailed.For studies 1 and 2, disfluency rates were examined furtherfor specific utterances that were graduated in length from 1to 18 words.
I First, these analyses indicated that the aver-age rate of disfluencies per 100 words increased as a functionof utterance length for spoken disfluencies, although not forwritten ones.
When the rate of spoken disfluencies was com-pared for short (I-6 words), medium (7-12 words), and longutterances (13-18 words), it increased from 0.66, to 2.14, to3.80 disfluencies per 100 words, respectively.
Statistical com-parisons confirmed that these rates represented significant in-creases from short to medium sentences, t = 3.09 (dr = 10),p < .006, one-tailed, and also from medium to long ones, t =2.06 (dr = 8), p < .04, one-tailed.A regression analysis indicated that the strength of predictiveassociation between utterance length and disfluency rate wasP~?T = .77 (N = 16).
That is, 77% of the variance in therate of spoken disfluencies was predictable simply by knowingan utterance's specific length.
The following simple linearmodel, illustrated in the scatterplot in Figure 3, summarizesthis relation: l'~j = #Y-I- 13Y.x (X# -/.iX) -I- eij, with a Y-axisconstant coefficient of-0.32, and a.u X-axis beta coefficientrepresenting utterance length of +0.26.
These data indicatethat the demands associated with planning and generatinglonger constructions lead to substantial elevations in the rateof disfluent speech.To assess whether presentation format had an additional in-fluence on spoken disfluency rates beyond that of utterancelength, comparisons were made of disfluency rates occur-1The average utterance l ngth in study 3, in which people con-veyed digits during scientific alculations and personal bankingtasks, was too brief to permit a parallel analysis.2246" Y = -0.32 + 0 .26X.~, iw~i~3" f .
.
'I S ,?
;  " ,; " ,'5 2'oU tttcran= I~n~hFigure 3.
Linear regression model summarizing increasingrate of spoken disfluencies per 100 words as a function ofutterance length.ring in unconstrained and form-based utterances that werematched for length.
These analyses revealed that the rate ofspoken disfluencies also was significantly higher in the uncon-strained format than in form-based speech, even with utter-ance length controlled, t (paired) -- 2.42 (df = 5), p < .03,one-tailed.
That is, independent of utterance length, lack ofstructure in the presentation format also was associated withelevated isfluency rates.From a pragmatic viewpoint, it also is informative to com-pare the total number of disfluencies that would require pro-cessing during an application.
Different design alternativescan be compared with respect o effective reduction of totaldisfluencies, which then would require neither processing norrepair.
In studies 1 and 2, a comparison of the total num-ber of spoken disfiuencies revealed that people averaged 3.33per task set when using the unconstrained format, which re-duced to an average of 1.00 per task set when speaking toa form.
That is, 70% of all disfluencies were eliminated byusing a more structured form.
Likewise, in study 3, the aver-age number of disfluencies per subject per task set droppedfrom 1.75 in the unconstrained format to 0.72 in the struc-tured one.
In this simulation, a more structured presentationformat successfully eliminated 59% of people's disfluencies asthey spoke digits, in comparison with the same people com-pleting the same tasks via an unconstrained format.During post-experimental interviews, people reported theirpreference to interact with the two different presentation for-mats.
Results indicated that approximately two-thirds of thesubjects preferred using the more structured format.
This 2-to-1 preference for the structured format replicated acrossboth the verbal and numeric simulations.3.
EXPERIMENTS ONHUMAN-HUMAN SPEECHThis section reports on data that were analyzed to explore thedegree of variability in disfluency rates among different ypesof human-human and human-computer spoken interaction,and to determine whether these two classes differ systemati-cally.3.1.
MethodData originally collected by the author and colleagues duringtwo previous tudies were reanalyzed to provide comparativeinformation on human-human disfluency rates for the presentresearch \[1, 6, 7\].
One study focused on telephone speech,providing data on both: (1) two-person telephone conver-sations, and (2) three-person i terpreted telephone conver-sations, with a professional telephone interpreter interme-dinting.
Methodological details of this study are providedelsewhere \[7\].
Essentially, within-subject data were collectedfrom 12 native speakers while they participated in task-oriented dialogues about conference registration and travelarrangements.
In the second study, also outlined elsewhere\[1, 6\], speech data were collected on task-oriented dialoguesconducted in each of five different communication modalities.For the present comparison, data from two of these modal-ities were reanalyzed: (1) two-party face-to-face dialogues,and (2) single-party monologues into an audiotape machine.A between-subject design was used, in which 10 subjects de-scribed how to assemble a water pump.
All four types ofspeech were reanalyzed from tape-recordings for the samecategories of disfluency and self-correction as those codedduring the simulation studies, and a rate of spoken disflu-encies per 100 words was calculated.3.2.
Comparat ive  ResultsTable 1 summarizes the average speech disfluency rates forthe four types of human-human and two types of human-computer interaction that were studied.
Disfluency rates foreach of the two types of human-computer speech are listedin Table 1 for verbal-temporal nd computational-numericcontent, respectively, and are corrected for number of sylla-bles per word.
All samples of human-human speech reflectedsubstantially higher disfluency rates than human-computerspeech, with the average rates for these categories confirmedto be significantly different, t = 5.59 (df = 38), p < .0001,one-tailed.
Comparison of the average disfluency rate forhuman-computer speech with human monologues, the leastdiscrepant of the human-human categories, also replicatedthis difference, t = 2.65 (df = 21), p < .008, one-tailed.
Themagnitude of this disparity ranged from 2-to-ll-times higherdisfluency rates for human-human as opposed ;to human-computer speech, depending on the categories compared.Further analyses indicated that the average disfluency ratewas significantly higher during telephone speech than theother categories of human-human speech, t = 2.12 (df = 20),p < .05, two-tailed.4.
D ISCUSSIONSpoken disfluencies are strikingly sensitive to the increasedplanning demands of generating progressively longer utter-225Type  of  Spoken  In teract ion  Disf luencyRateHumau-human speech:Two-person telephone callThree-person i terpreted telephone callTwo-person face-to-face dialogueOne-person oninteractive monologueHuman-computer  speech:Unconstrained computer interactionStructured computer interaction8.836 .255 .503 .60x.r4 / L8v0.r8 / 0.8rTable 1: Spoken disfluency rates per 100 words for differ-ent types of human-human and simulated human-computerinteraction.ances.
Of all the variance in spoken disfluencies in the firsttwo studies, 77% was predictable simply by knowing an ut-terance's pecific length.
A linear model was provided,Y = -0.32 -F 0.26X, to summarize the predicted rate of spo-ken disiluencies as a function of utterance length.
Knowledgeof utterance length alone, therefore, is a powerful predictorof speech disfiuencies in human-computer interaction.Spoken disfluencies also are influenced substantially by thepresentation format used during human-computer interac-tion.
An  unconstrained format, which required the speakerto self-structure and plan to a. greater degree, led speak-ers to produce over twice the rate of disfluencies as & morestructured interaction.
Furthermore, this format effect wasreplicated across unimodal and multimodal spoken input,and across qualitatively very different spoken content.
Sincethe observed ifference between formats occurred in samplesmatched for length, it is clear that presentation format andutterance length each exert an independent influence on spo-ken disfluency levels.In these three studies, a substantial 60 to 70% of all spokendisfluencies were eliminated simply by using a more struc-tured format.
That is, selection of presentation format wasremarkably effective at channeling a speaker's language tobe less disfluent.
In part, this was accomplished by reducingsentential planning demands during use of the structured for-mats - i.e., reducing the need for people to plan the contentand order of information delivered (see Oviatt, forthcoming\[5\]).
It also was accomplished in part by the relative brevityof people's entences in the structured formats.
The percent-age of moderate to long sentences increased from 5% of allsentences during structured interactions to 20% during un-constrained speech-- a 4-fold or 300% increase.
In addition,whereas the average disfluency rate was only 0.66 for shortsentences, this rate increased to 2.81 for sentences categorizedas moderate or lengthy-- a 326% increase.
The structuredformat not only was effective at reducing disfluencies, it alsowas preferred by a factor of 2-to-1.Wide variability can be expected in the disfluency rates typi-cal of qualitatively different types of spoken language.
Basedon the six categories compared here, rates were found to varyby a magnitude of 2-to-11-fold between individual categories,with the highest rates occurring in telephone speech, andthe lowest in human-computer interaction.
This variabilitysuggests that further categories of spoken language shouldbe studied individually to evaluate how prone they may beto disfluencies, rather than assuming that the phenomenonis stable throughout spoken language.
Future work explor-ing disfluency patterns during more complex multimodal ex-changes will be of special interest.Finally, future work needs to investigate other major human-computer interface features that may serve to decrease plan-ning load on users, and to estimate how much impact theyhave on reducing disfluencies.
Such information would per-mit proactive system design aimed at supporting more robustspoken language processing.
For future applications in whichan unconstrained format is preferred, or disfluencies and self-repairs otherwise are unavoidable, methods for correctly de-tecting and processing the ones that occur also will be re-quired.
To the extent that promising work on this topic canincorporate probabilistic information on the relative likeli-hood of a disfluency for a particular utterance (e.g., of lengthN), based on either the present or future predictive models,correct detection and judicious repair of actual disfluenciesmay become feasible.5.
ACKNOWLEDGMENTSSincere thanks to the generous people who volunteered toparticipate in this research as subjects.
Thanks also toMichael Frank, Martin Fong, and John Dowding for program-ming the simulation environment, to Martin Fong and DanWilk for playing the role of the simulation assistant duringtesting, to Jeremy Gaston, Zak Zaidman, ~nd Aaron Hall-mark for careful preparation of transcripts, and to JeremyGaston, Zak Zaidman, Michelle Wang, and Erik Olsen forassistance with data analysis.
Finally, thanks to Gary Delland Phil Cohen for helpful manuscript comments.226References1.
P. R. Cohen.
The pragmatics of referring and the modal-ity of communication.
Computational Linguistics, 1984,10(2):97-146.2.
D. Hindle.
Deterministic parsing of syntactic non-fluencies.
In Proceedings of the 21st.
Annual Meetingo\] the ACL, 1983, Cambridge, Mass.
123-128.3.
W. J. M. Levelt.
Speaking: From Intention to Articula-tion.
ACL/M.I.T.
Press, Cambridge, Mass:, 1989.4.
C. Nakz~tani and J. Hirschberg.
A corpus-based studyof repair cues in spontaneous speech.
In Journal of theAcoustical Society of America, in press.5.
S. L. Oviatt.
Predicting spoken disfluencies duringhuman-computer interaction.
Journal manuscript, insubmission.6.
S. L. Oviatt and P. R. Cohen.
Discourse strtlctureand performance efficiency in interactive and noninterac-tive spoken modalities.
Computer Speech and Language,1991, 5(4):297-326.7.
S. L. Oviatt and P. R. Cohen.
Spoken language in inter-preted telephone dialogues.
Computer Speech and Lan-guage, 1992, 6:277-302.8.
S. L. Ovi~tt, P. R. Cohen, M. W. Fong, and M. P. Frank.A rapid semi-automatic simulation technique for investi-gating interactive speech and handwriting.
In Proceed-ings of the 199~ ICSLP, 1992, ed.
by J. Ohala et al,University of Alberta, vol.
2, 1351-1354.9.
E. Shriberg, J.
Bear, and g. Dowding.
Automatic de-tection and correction of repairs in human-computer di-alog.
In Proceedings of the DARPA Speech and NaturalLanguage Workshop, 1992, Morgan Kanfmann, Inc., SanMateo, CA, 23-26.227
