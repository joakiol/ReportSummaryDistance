FUTURE PROSPECTS FOR COMPUTATIONAL LINGUISTICSGary G. Hendr ixSRI InternationalPreparation of this paper was supported by theunder contract N00039-79-C-0118 with the Navalexpressed are those of the author.Defense Advance Research Projects AgencyElectronic Systems Command.
The viewsA.
IntroductionFor over two decades, researchers in artificialintelligence and computational linguistics have soughtto discover principles that would allow computersystems to process natural languages such as English.This work has been pursued both to further thescientific goals of providing a framework for acomputational theory of natural-language communicationand to further the engineering goals of creatingcomputer-based systems that can communicate with their~human users in human terms.
Although the goal offluent machine-based nautral-langusge understandingremains elusive, considerable progress has been madeand future prospects appear bright both for theadvancement of the science and for its application tothe creation of practical systems.In particular, after 20 years of nurture in theacademic nest, natural-language processing is beginningto test its wings in the commercial world \[8\].
By theend of the decade, natural-language systems are likelyto be in widespread use, bringing computer resources tolarge numbers of non-computer specialists and bringingnew credibility (and hopefully new levels of funding)to the research community.B.
Basis for OptimismMy optimism is based on an extrapolation of threemajor trends currently affecting the field:(~) The emergence of an engineering/applicationsdiscipline within the computational-linguistics community.
(2) The continuing rapid development of newcomputing hardware coupled with the beginningof a movement from time-sharing to personalcomputers.
(3) A shift from syntax and semantics as theprinciple objects of study to the developmentof theories that cast language use in termsof a broader theory of goal-motivatedbehavior and that seek primarily to explainhow a speaker's cognitive state motivates himto engage in an act of communication, how aspeaker devises utterances with which toperform the act, and how acts ofcommunication affect the cognitive states ofhearers .C.
Th___ee Impact o fEn~ineerin~The emergence of an engineering discipline maystrike many researchers in the field as being largelydetached from the mainstream of current work.
But Ibelieve that, for better or worse, this discipline willhave a major and continuing influence on our researchcommunity.
The public at large tends, often unfairly,to view a science through the products and concreteresults it produces, rather than through the mysteriesof nature it reveals.
Thus, the chemist is seen as theperson who produces fertilizer, food coloring and nylonstockings; the biologist finds cures for diseases; andthe physicist produces moon rockets, semiconductors,and nuclear power plants.
What has computationallinguistics produced that has affected the lives ofindividuals outside the limits of its own close-knitcommunity?
As long as the answer remains "virtuallynothing," our work will generally be viewed as an ivorytower enterprise.
As soon as the answer becomes a setof useful computer systems, we will be viewed as thepeople who produce such systems and who aspire toproduce better ones.My point here is that the commercial marketplacewill tend to judge both our science and our engineeringin terms of our existing or potential engineeringproducts.
This is, of course, rather unfair to thescience; but I believe that it bodes well for ourfuture.
After all, most of the current sponsors ofresearch on computational linguistics understand thescientific nature of the enterprise and are likely tocontinue their support even in the face of minorsuccesses on the engineering front.
The impact of anengineering arm can only add to our field's basis ofsupport by bringing in new suport from the commercialsector.One note of caution is appropriate, however.There is a real possibility that as commercialenterprises enter the natural-language field, they willseek to build in-house groups by attracting researchersfrom universities and nonprofit institutions.
Althoughthis would result in the creation of more jobs forcomputational linguists, it would also result inproprietary barriers being established between researchgroups.
The net effect in the short term mightactually be to retard scientific progress.D.
The State of Applied WorkI.
Accessin~ DatabasesCurrently, the most commercially viable taskfor natural-language processing is that of providingaccess to databases.
This is because databases areamong the few types of symbolic knowledgerepresentations that are computationally efficient, arein widespread use, and have a semantics that is wellunderstood.In the last few years, several systems,including LADDER \[9\], PLANES \[29\], REL \[26\], and ROBOT\[8\], have achieved relatively high levels ofproficiency in this area when applied to particulardatabases.
ROBOT has been introduced as a commercialproduct that runs on large, mainframe computers.
Apilot REL product is currently under development thatwill run on a relatively large personal machine, the HP9845.
This system, or something very much like it,seems likely to reach the marketplace within the nexttwo or three years.
Should ROBOT- and REL-like systemsprove to be commercial successes, other systems withincreasing levels of sophistication are sure to follow.2.
Immediate ProblemsA major obstacle currently limiting thecommercial viability of natural-language access todatabases is the problem of telling systems about thevocabulary, concepts and linguistic constructionsassociated with new databases.
The most proficient ofthe application systems have been hand-tailored withextensive knowledge for accessing just ONE database.Some systems (e.g., ROBOT and REL) have achieved a131degree of transportability by using the database itselfas a source of knowledge for guiding linguisticprocesses.
However, the knowledge available in thedatabase is generally rather limited.
High-performancesystems need access to information about the largerenterprise that provides the context in which thedatabase is to be used.As pointed out by Tennant \[27\], users who aregiven natural-language access to a database expect notonly to retrieve information directly stored there, butalso to compute "reasonable" derivative information.For example, if a database has the location of twoships, users will expect the system to be able toprovide the distance between them--an item ofinformation not directly recorded in the database, buteasily computed from the existing data.
In general,any system thatis to be widely accepted by users mustnot only provide access to database information, butmust also enhance that primary information by providingprocedures that calculate secondary attributes from thedata actually stored.
Data enhancement procedures arecurrently provided by LADDER and a few other hand-builtsystems.
But work is needed to devise means forallowing system users to specify their own databaseenhancement functions end to couple their functionswith the natural-language component.Efforts are now underway (e.g.
\[26\] \[13\]) tosimplify the task of acquiring and coding the knowledgeneeded to transport high-performance systems from onedatabase to another.
It appears likely that soon muchof this task can be automated or performed by adatabase administrator, rather than by a computationallinquist.
When this is achieved, natural-languageaccess to data is likely to move rapidly intowidespread use.E.
New HardwareVLSI (Very Large Scale Integration of computercircuits on single chips) is revolutionizing thecomputer industry.
Within the last year, new personalcomputer systems have been announced that, atrelatively low cost, will provide throughputs rivalingthat of the Digital Equipment KA-IO, the time-sharingresearch machine of choice as recently as seven yearsago.
Although specifications for the new machinesdiffer, a typical configuration will support a verylarge (32 bit) virtual address space, which isimportant for knowledge-intensive natural-languageprocessing, and will provide approximately 20 megabytesof local storage, enough for a reasonable-sizedatabase.Such machines will provide a great deal ofpersonal computing power at costs that are initiallynot much greater than those for a single user's accessto a time-shared system, and that are likely to fallrapidly.
Hardware costs reductions will beparticularly significant for the many small researchgroups that do not have enough demand to justify thepurchase of a large, time-shared machine.The new generation of machines will have thevirtual address space and the speed needed to overcomemany of the technical bottlenecks that have hamperedresearch in the past.
For example, researchers may beable to spend less time worrying about how to optimizeinner loops or how to split large programs intomultiple forks.
The effort saved can be devoted to theproblems of language research itself.The new machines will also make it economical tobring co 3iderable computing to people in all sectorso f the economy, including government, the military,small business, and to smaller units within largebusinesses.
Detached from the computer wizards thatstaff the batch processing center or the time-sharedfacility, users of the new personal machines will needto be more self reliant.
Yet, as the use of personalcomputers spread, these users are likely to beincreasingly less sophisticated about computation.Thus, there will be an increasing demand to makepersonal computers easier to use.
As the price ofcomputation drops (and the price of human laborcontinues to soar), the use of sophisticated means forinteracting intelligently with a broad class ofcomputer users will become more and more attractive anddemands for natural-language interfaces are likely tomushroom.F.
Future Directions for Basic Researchi.
The Research BaseWork on computational linguistics appears tobe focusing on a rather different set of issues thanthose that received attention a few years ago.
Inparticular, mechanisms for dealing with syntax and theliteral propositional content of sentences have becomefairly wall understood, so that now there is increasinginterest in the study of language as a component in abroader system of goal-motivated behavior.
Within thisframework, dialogue participation is not studied as adetached linguistic phenomenon, but as an activity ofthe total intellect, requiring close coordinationbetween language-specific and general cognitiveprocessing.Several characteristics of the communicativeuse of language pose significant problems.
Utterancesare typically spare, omitting information easilyinferred by the hearer from shared knowledge about thedomain of  d i scourse .
Speakers  depend on the i r  hearersto use such knowledge together  w i th  the context  o f  thepreced ing  d i scourse  to make par t ia l l y  spec i f ied  ideasprec ise .
In add i t ion ,  the  l i te ra l  content  o f  anu t terance  must be in terpreted  w i th in  the context  o f  thebeliefs, goals, and plans of the dialogue participants,so that a hearer can move beyond literal content to theintentions that lie behind the utterance.
Furthermore,it is not sufficient to consider an utterance ae beingaddressed to a single purpose; typically it servesmultiple purposes: it highlights certain objects andrelationships, conveys an attitude toward them, andprovides links to previous utterances in addition tocommunicating some propositional content.An examination of the current state of theart in natural-language processing systems revealsseveral deficiencies in the combination andcoordination of language-specific and general-purposereasoning capabilities.
Although there are somesystems that coordinate different kinds of language-specific capabilities \[3\] \[12\] \[20\] \[16\] \[30\] \[:7\],and some that reason about limited action scenarios\[21\] \[15\] \[19\] \[25\] to arrive at an interpretation ofwhat has been sa id ,  and o thers  that  a t tempt  to accountfor some of the ways in which context affects meaning\[7\] \[I0\] \[18\] \[14\], one or ~ore of the followingcrucial limitations is evident in every natural-language processing system constructed to date:Interpretation is literal (only propositionalcontent is determined).The user's knowledge and beliefs are assumed to beidontical with the system's.The user's plans and goals (especially as distinctfrom those of the system) ere ignored.Initial progress has been made in overcoming some ofthese limitations.
Wilensky \[28\] has investigated theuse of goals and plans in a computer system thatinterprets stories (see also \[22\] \[4\]).
Allen andPerrault \[l\] and Cohen \[63 have examined thei n te rac t ion  between beliefs and plans in task-orienteddialogues and have implemented e system that uses132information about what its "hearer" knows in order toplan and to recognize a limited set of speech acts(Searle \[23\] \[24\]).
These efforts have demonstratedthe viability of incorporating planning capabilities ina natural-language processing system, but more robustreasoning and planning capabilities are needed toapproach the smooth integration of language-specificand general reasoning capabilities required for fluentcommunication in natural language.2.
Some PredictionsBasic research provides a leading indicatorwith which to predict new directions in applied scienceand engineering; but I know of no leading indicator forbasic research itself.
About the best wc can do is toconsider the current state of the art, seek to identifycentral problems, and predict that those problems willbe the ones receiving the most attention.The view of language use as an activity ofthe total intellect makes it clear that advances incomputational linguistics will be closely tied toadvances in research on general-purpose common-sensereasoning.
Hobbs \[11\], for example, has argued that 10seemingly different and fundamental problems ofcomputational linguistics may all be reduced toproblems of common-sense deduction, and Cohen's workclearly ties language to planning.The problems of planning and reasoning are,of course, central problems for the whole of AI.
Butcomputational linguistics brings to these problems itsown special requirements, such as the need to considerthe beliefs, goals, and possible actions of multipleagents, and the need to precipitate the achievement ofmultiple goals through the performance of actions withmultiple-faceted primary effects.
There are similarneeds in other applications, but nowhere do they arisemore naturally than in human language.In addition to a growing emphasis on general-purpose reasoning capabilities, I believe that the nextfew years will see an increased interest in natural-language generation, language acquisition, information-science applications, multimedia communication, andspeech.Generation: In comparison withinterpretation, generation has received relativelylittle attention as a subject of study.
Oneexplanation is that computer systems have more controlover output than input, and therefore have been able torely on canned phrases for output.
Whatever the reasonfor past neglect, it is clear that generation deservesincreased attention.
As computer systems acquire morecomplex knowledge bases, they will require better meansof communicating their knowledge.
More importantly,for a system to carry on a reasonable dialogue with auser, it must not only interpret inputs but alsorespond appropriately in context, generating responsesthat are custom tailored to the (assumed) needs andmental state of the user.Hopefully, much of the same research that isneeded on planning and reasoning to move beyond literalcontent in interpretation will provide a basis forsophisticated generation.Acquisition: Another generally neglectedarea, at least computationally, is that of languageacquisition.
Berwick \[2\] has made an interestingstart in this area with his work on the acquisition ofgrammar rules.
Equally important is work onacquisition of new vocabulary, either through reasoningby analogy \[5\] or simply by being told new words \[13\].Because language acquisition (particularly vocabularyacquisition) is essential for moving natural-languagesystems to new domains, I believe considerableresources are likely to be devoted to this problem andthat therefore rapid progress will ensue.Information Science: One of the greatestresources of our society is the wealth of knowledgerecorded in natural-language texts; but there are majorobstacles to placing relevant texts in the hands ofthose who need them.
Even when texts are madeavailable in machine-readable form, documents relevantto the solution of particular problems are notoriouslydifficult to locate.
Although computationallinguistics has no ready solution to the problems ofinformation science, I believe that it is the only realsource of hope, and that the future is likely to bringincreased cooperation between workers in the twofields.Multimedia Communication: The use of naturallanguage is, of course, only one of several means ofcommunication available to humans.
In viewing languageuse from a broader framework of goal-directed activity,the use of other media and their possible interactionswith language, with one another, and with general-purpose problem-solving facilities becomes increasinglyimportant as a subject of study.Many of the most central problems ofcomputational linguistics come up in the use of anymedium of communication.
For example, one can easilyimagine something like speech acts being performedthrough the use of pictures and gestures rather thanthrough utterances in language.
In fact, these typesof communicative acts are what people use tocommunicate when they share no verbal language incommon.As computer systems with high-qualitygraphics displays, voice synthesizers, and other typesof output devices come into widespread use, aninteresting practical problem will be that of decidingwhat medium or mixture of media is most appropriate forpresenting information to users under a given set ofcircumstances.
I believe we can look forward to rapidprogress on the use of multimedia communication,especially in mixtures of text and graphics (e.g., asin the use of a natural-language text to help explain agraphics display).Spoken Input: In the long term, the greatestpromise for a broad range of practical applicationslles in accessing computers through (continuous) spokenlanguage, rather than through typed input.
Given itstremendous economic importance, I believe a major newattack on this problem is likely to be mounted beforethe end of the decade, but I would be uncomfortablepredicting its outcome.Although continuous speech input may be someyears away, excellent possibilities currently exist forthe creation of systems that combine discrete wordrecognition with practical natural-language processing.Such systems are well worth pursuing as an importantinterim step toward providing machines with fullynatural communications abilities.G.
Problems of Technology TransferThe expected progress in basic research over thenext few years will, of course, eventually haveconsiderable impact on the development of practicalsystems.
Even in the near term, basic research iscertain to produce many spinoffs that, in simplifiedform, will provide practical benefits for appliedsystems.
But the problems of transferring scientificprogress from the laboratory to the marketplace mustnot be underestimated.
In particular, techniques thatwork well on carefully selected laboratory problems areoften difficult to use on a large-scale basis.
(Perhaps this is because of the standard scientificpractice of selecting as a subject for experimentationthe simplest problem exhibiting the phenomena ofinterest.
)133As an example of th i s  d i f f i cu l ty ,  cons iderknowledge representat ion .
Cur rent ly ,  convent iona ldatabase management systems (DBHSs) are the onlysystems in widespread use for storing symbolicinformation.
The AI community, of course, has a numberof methods for maintaining more sophisticated knowledgebases of, say, formulas in first-order logic.
Buttheir complexity and requirements for great amounts ofcomputer resources (both memory and time) haveprevented any such systems from becoming a commerciallyviable alternative to standard DBMSs.I believe that systems that maintain moaels of theongoing dialogue and the changing physical context (asin, for example, Gross \[7\] and Robinson \[~9\]) or thatreason about the mental states of users will eventual lybecome important in practical applications.
But thecomputational requirements for such systems are so muchgreater than those of current applied systems that theywill have little commercial viability for some time.Fortunately, the linguistic coverage of severalcur rent  sys tems appears  to be adequate  fo r  manypractical purposes, so commercialization need not waitfo r  more advanced techn iques  to be t rans fer red .
On theother hand, applied systems currently are only barelyup to their tasks, and therefore there is a need for anongoing examination of basic research results to findways of repackaging advanced techniques in cost-effective forms.In general, the basic science and the applicationof computational linguistics should be pursued inparallel, with each aiding the other.
Engineering canaid the science by anchoring it to actual needs and bypointing out new problems.
Basic science can provideengineering with techniques that provide newopportunities for practical application.1341.2.3.4.6.7.8.9.10.11.12.13.14.15.REFERENCESAllen, J.
& C. Perrault.
1978.
Participating inDialogues: Understanding via plan deduction.Proceedings, Second National Conference, CanadianSociety for Computational Studies of Intelligence,Toronto, Canada.Berwick, B. C., 1980.
Computational Analogues ofConstraints on Grammars: A Model of SyntacticAcquisition.
The 18th Annual Meeting of theAssociation for Computational Linguistics,Philadelphia, Pennsylvania, June 1980.Bobrow, D. G., et al 1977.
GUS, A Frame DrivenDialog System.
Artificial Intelligence, 8, I~5-173.Carbonell, J. G. 1978.
Computer Models of Socialand Political Reasoning.
Ph.D. Thesis, YaleUniversity, New Haven, Connecticut.Carbonell, J. G. 1980.
Metaphor--A Key toExtensible Semantic Analysis.
The 18th AnnualMeeting of the Association for ComputationalLinguistics, Philadelphia, Pennsylvania, June1980.Cohen, P. 1978.
On knowing what to say: planningspeech acts.
Technical Report No.
118, Departmentof Computer Science, University of Toronto.January 1978.Grosz, B. J., 1978.
Focusing in Dialog.Proceedings of TINLAP-2, Urbana, Illinois, 24-26July, 1978.L.
R. Harris, 1977.
User Oriented Data Base Querywith the ROBOT Natural Language Query System.Proc.
Third International Conference on VeryLarge Data Bases, Tokyo (October 1977).G.
G. Hendrix, E. D. Sacerdoti, D. Sagalowicz, andJ.
Slocum, 1978.
Developing a Natural LanguageInterface to Complex Data.
ACM Transactions onDatabase Systems, Vol.
3, No.
2 (June 1978).Hobbs, J.
1979.
Coherence and coreference.Cognitive Science.
Vol.
3, No.
I, 67-90.Hobbs, J.
1980.
Selective inferencing.
ThirdNational Conference of Canadian Society forComputational Studies of Intelligence.
Victoria,British Columbia.
May 1980.Landsbergen, S. P. J., 1976.
Syntax and FormalSemantics of English in PHLIQAI.
In Coling 76,Preprints of the 6th International Conference onComputational Linguistics, Ottawa, Ontario,Canada, 28 June - 2 July 1976.
No.
21.Lewis, w. H., and Hendrix, G. G., 1979.
MachineIntelligence: Research and Applications -- FirstSemiannual Report.
SRI International, Menlo Park,California, October 8, 1979.Mann, W., J. Moore, & J. Levin 1977.
Acomprehension model for human dialogue.Proceedings, International Joint Conference onArtificial Intelligence, 77-87, Cambridge, Mass.August 1977.Novak, G. 1977.
Representations of knowledge in aprogram for solving physics problems.
Proceedings,International Joint Conference on ArtificialIntelligence, 286-291, Cambridge, Mess.
August1 977.16.17.18.19.20.21.22.23.24.25.26.27.28.29.3O.Patrick, S. R. 1978.
Automatic Syntactic andSemantic Analysis.
In Proceedings of theInterdsciplainary Conference on Automated TextProcessing (Bielefeld, German Federal Republic, 8-12 November 1976).
Edited by J. Petofi and S.Allen.
Reidel, Dordrecht, Holland.Reddy, D. R., et al 1977.
Speech UnderstandingSystems: A Summary of Results of the Five-YearResearch Effort.
Department of Computer Science.Carnegie-Mellon University, Pittsburgh,Pennsylvania, August, 1977.Rieger, C. 1975.
Conceptual Overlays: A Mechanismfor the Interpretation of Sentence Meaning inContext.
Technical Report TR-554.
Computer ScienceDepartment, University of Maryland, College Park,Maryland.
February 1975.Robinson, Ann E. The Interpretation of VerbPhrases in Dialogues.
Technical Note 206,Artificial Intelligence Center, SRI International,Menlo Park, Ca., January 1980.Sager, N. and R. Grishman.
1975.
The RestrictionLanguage for Computer Grammars.
Communications ofthe ACM, 1975, 18, 390-400.Schank, R. C., and Yale A.I.
1975.
SAM--A StoryUnderstander.
Yale University, Department ofComputer Science Research Report.Schank, R. and R. Abelson.
1977.
Scripts, plans,goals, and understanding.
Hillsdale N.J.: LaurenceErlbaum Associates.Searle, J.
1969.
Speech acts: An essay in thephilosophy of language.
Cambridge, England:Cambridge University Press.Searle, J 1975.
Indirect speech acts.
In P. Coleand J. Morgan (Eds.
), Syntax and semantics, Vol.3, 59-82.
New York: Academic Press.Sidner, C. L. 1979.
A Computational Model of Co-Reference Comprehension in English.
Ph.D. Thesis,Massachusetts Institute of Technology, Cambridge,Massachusetts.F.
B. Thompson and B. H. Thompson, 1975.
PracticalNatural Language Processing: The REL System asPrototype.
In M. Rubinoff and M. C. Yovits, eds.,Advances in Computers 13 (Academic Press, NewYork, 1975).H.
Tennant, "Experience with the Evaluation ofNatural Language Question Answerers," &Proc.
SixthInternational Joint Conference on ArtificialIntelligene&, Tokyo, Japan (August 1979).Wilensky, R. 1978.
"Understanding Goal-BasedStories."
Yale University, New Haven, Connecticut.Ph.D.
Thesis.D.
Waltz, "Natural Language Access to a Large DataBase: an ~Igineering Approach," Proc.
4thInternatioal Joint Conference on ArtificialIntelligence, Tbilisi, USSR, pp.
868-872(September 1975).Woods, W. A., et al 1976.
Speech UnderstandingSystems: Final Report.
BBN Report No.
3438, BoltBeranek and Newman, Cambridge, Massachusetts.135
