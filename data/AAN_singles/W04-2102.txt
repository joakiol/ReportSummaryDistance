Design of a Lexical Database for SanskritGe?rard HuetINRIA-RocquencourtBP 105, 78153 Le Chesnay CEDEXFranceGerard.Huet@inria.frAbstractWe present the architectural design rationaleof a Sanskrit computational linguistics plat-form, where the lexical database has a cen-tral role.
We explain the structuring require-ments issued from the interlinking of grammat-ical tools through its hypertext rendition.1 IntroductionElectronic dictionaries come into two distinctflavours: digital sources of dictionaries and en-cyclopedia, meant for human usage, and lexicaldatabases, developed for computational linguis-tics needs.
There is little interaction betweenthe two forms, mostly for sociological reasons.We shall argue, in this communication, that alexical database may be used for both purposes,to mutual advantage.
We base our thesis on aconcrete experiment on the design of linguisticsresources for the Sanskrit language.2 From book form to web site2.1 A Sanskrit-French paper dictionaryThe author started from scratch a Sanskrit toFrench dictionary in 1994, first as a personalproject in indology, then as a more structuredattempt at covering Sanskrit elementary vocab-ulary.
A systematic policy was inforced along anumber of successive invariants.
For instance,etymology, when known, was followed recur-sively through relevant entries.
Any word couldthen be broken into morphological constituents,down to verbal roots when known.
This ?et-ymological?
completeness requirement was atfirst rather tedious, since entering a new wordmay require the acquisition of many ancestors,due to complex compounding.
But it appearedthat the acquisition of new roots slowed downconsiderably after an initial ?bootstrap?
phase.When the number of entries approached 10000,with 520 roots, new roots acquisition becamequite exceptional.
This phenemenon is simi-lar to the classical ?lexical saturation?
effectwitnessed when one builds a lexicon coveringa given corpus (Polgue`re, 2003).
Progressively,a number of other consistency constraints wereidentified and systematically enforced, whichproved invaluable in the long run.At this point the source of the lexicon wasa plain ASCII file in the LaTeX format.
How-ever, a strict policy of systematic use of macros,not only for the structure of the grammaticalinformation, and for the polysemy representa-tion, but also for internal quotations, ensuredthat the document had a strict logical struc-ture, mechanically retrievable (and thus consid-erably easier to process without loss of informa-tion than an optically scanned paper dictionary(Ma et al, 2003)).Indeed, around 2000, when the author gotinterested into adapting the data as a lexicaldatabase for linguistic processing, he was ablewithout too much trouble to reverse engineerthe dictionary into a structured lexical database(Huet, 2000; Huet, 2001).
He then set to workto design a set of tools for further computerprocessing as an experiment in the use of func-tional programming for a computational linguis-tics platform.The first design decision was to avoid stan-dard databases, for several reasons.
The firstone is portability.
Many database formats areproprietary or specific to a particular product.The second reason is that the functionalities ofdata base systems, such as query languages, arenot well adapted to the management of lexi-cal information, which is highly structured in adeep manner - in a nutshell, functional ratherthan predicative.
Thirdly, it seemed best tokeep the information in the concrete format inwhich it had been developed so far, with spe-cific text editing tools, and various levels of an-notation which could remain with the statusof unanalysed comments, pending their possiblelater structuring.
After all, ASCII is the mostportable format, large text files is not an issueanymore, parsing technology is fast enough tomake compilation times negligible, and the hu-man ease of editing is the really crucial factor ?any tool which the lexicographer has to fight toorganise his data is counter-productive.A detailed description of this abstract syntaxis available as a research report (Huet, 2000),and will not be repeated here.
We shall justpoint to salient points of this abstract structurewhen needed.2.2 Grinding the abstract structureThe main tool used to extract information fromthis data-base is called the grinder (named afterthe corresponding core processor in the Word-Net effort (Miller, 1990; Fellbaum, 1998)).
Thegrinder is a parsing process, which recognizessuccessive items in the data base, representsthem as an abstract syntax value, and for eachsuch item calls a process given as argument tothe grinder.
In other words, grind is a para-metric module, or functor in ML terminology.Here is exactly the module type grind.mli inthe syntax of our pidgin ML:module Grind : functor(Process : Proc.Process_signature)-> sig end;with interface module Proc specifying the ex-pected signature of a Process:module type Process_signature = sigvalue process_header :(Sanskrit.skt * Sanskrit.skt) -> unit;value process_entry :Dictionary.entry -> unit;value prelude : unit -> unit;value postlude : unit -> unit;end;That is, there are two sorts of items inthe data base, namely headers and entries.The grinder will start by calling the processprelude, will process every header with rou-tine process_header and every entry with rou-tine process_entry, and will conclude by call-ing the process postlude.
Module interfaceDictionary describes the dictionary data struc-tures used for representing entries (i.e.
its ab-stract syntax as a set of ML datatypes), whereasmodule Sanskrit holds the private represen-tation structures of Sanskrit words (seen fromDictionary as an abstract type, insuring thatonly the Sanskrit lexical analyser may constructvalues of type skt).A typical process is the printing processPrint_dict, itself a functor.
Here is its inter-face:module Print_dict : functor(Printer:Print.Printer_signature)-> Proc.Process_signature;It takes as argument a Printer module, whichspecifies low-level printing primitives for a givenmedium, and defines the printing of entries as ageneric recursion over its abstract syntax.
Thuswe may define the typesetting primitives to gen-erate a TEX source in module Print_tex, andobtain a TEX processor by a simple instancia-tion:module Process_tex = Print_dict Print_tex;Similarly, we may define the primitives to gener-ate the HTML sources of a Web site, and obtainan HTML processor Process_html as:module Process_html = Print_dict Print_html;It is very satisfying indeed to have such shar-ing in the tools that build two ultimately verydifferent objects, a book with professional typo-graphical quality on one hand, and a Web sitefit for hypertext navigation and search, as wellas grammatical query, on the other hand1.2.3 Structure of entriesEntries are of two kinds: cross-references andproper lexemes.
Cross references are used to listalternative spellings of words and some irregularbut commonly occurring flexed forms (typicallypronoun declensions).
Lexeme entries consist ofthree components : syntax, usage, and an op-tional list of cognate etymologies in other indo-european languages.The syntax component consists itself of threesub-components: a heading, a list of variants,and an optional etymology.
The heading spellsthe main stem (in our case, the so-called weakstem), together with a hierarchical level.
Atthe top of the hierarchy, we find root verbs,non-compound nouns, suffixes, and occasionaldeclined forms which do not reduce to just across reference, but carry some usage informa-tion.
Then we have subwords, and subsub-words, which may be derived forms obtained1http://pauillac.inria.fr/~huet/SKT/by prefixing or suffixing their parent stem, orcompound nouns.Other subordinate entries are idiomatic locu-tions and citations.
Thus we have a total often sorts of entries, classified into three hierar-chical levels (to give a comparison, the muchmore exhaustive Monier-Williams Sanskrit-to-English dictionary has 4 hierarchical levels).Let us now explain the structure of the us-age component of our entries.
We have actu-ally three kinds of such usage structure, onecorresponding to nouns (substantives and adjec-tives), another one corresponding to verbs, andstill another one for idiomatic locutions.
Weshall now describe the substantives usage com-ponent, the verbs one being not very differentin spirit, and the idioms one being a mere sim-plification of it.The usage structure of a substantive entryis a list of meanings, where a meaning con-sists of a grammatical role and a sense compo-nent.
A role is itself the notation for a part-of-speech tag and an optional positional indication(such as ?enclitic?
for postfix particles, or ?iic?
[in initio composi] for prefix components).
Thepart-of-speech tag is typically a gender (mean-ing substantive or adjective of this gender), ora pronominal or numeral classifier, or an unde-clinable adverbial role, sometimes correspond-ing to a certain declension of the entry.
Thethematic role ?agent?
is also available as tag,typically for nouns which may be used in themasculine or the feminine, but not in the neuter.This results in a fairly flexible concrete syntaxat the disposal of the lexicographer, put into arigid but rigorous structure for computationaluse by the data base processors.The sense component is itself a list of elemen-tary semantic items (representing polysemy),each possibly decorated by a list of spelling vari-ants.
Elementary semantic items consist in theirturn of an explanation labeled with a classi-fier.
The classifier is either ?Sem?, in which casethe explanation is to be interpreted as a sub-stitutive definition, or else it is a field label insome encyclopedic classification, such as ?Myth?for mythological entries, ?Phil?
for philosophi-cal entries, etc., in which case the explanationis merely a gloss in natural language.
In ev-ery case the explanation component has typesentence, meaning in our case French sentence,since it applies to a Sanskrit-to-French bilingualdictionary, but here it is worth giving a few ad-ditional comments.We remark that French is solely used as a se-mantic formalism, deep at the leaves of our en-tries.
Thus there is a clear separation betweena superstructure of the lexical database, whichonly depends on a generic dictionary structureand of the specific structure of the Sanskrit lan-guage, and terminal semantic values, which inour case point to French sentences, but could aswell point to some other language within a mul-tilingual context, or a WordNet-like (Fellbaum,1998) pivot structure.The strings denoting Sanskrit references aretraeted in a special way, since they determinethe hypertext links in the HTML version ofthe dictionary.
There are two kinds of possi-ble references, proper nouns starting with anupper case letter, and common nouns or otherSanskrit words.
For both categories, we dis-tinguish binding occurrences, which constructHTML anchors, and used occurrences, whichconstruct the corresponding references.
In or-der to discuss more precisely these notions, weneed to consider the general notion of scoping.But before discussing this important notion, weneed a little digression about homonymy.2.4 HomonymsFirst of all, there is no distinction in Sanskritbetween homophons and homographs, since thewritten form reflects phonetics exactly.
Asin any language however, there are homonymswhich are words of different origin and unrelatedmeanings, but which happen to have the samerepresentation as a string of phonemes (voca-ble).
They may or may not have the same gram-matical role.
For such clearly unrelated words,we use the traditional solution of distinguish-ing the two entries by numbering them, in ourcase with a subscript index.
Thus we distin-guish entry aja1 ?he goat?, derived from root aj?to lead?, from entry aja2 ?unborn?, derived byprivative prefix a from root jan ?to be born?.Actually, primary derived words, such as sub-stantival root forms, are distinguished from theroot itself, mostly for convenience reasons (theusage structure of verbs being superficially dif-ferent from the one of substantives).
Thus theroot di?s1 ?to show?
is distinguished from the sub-stantive di?s2 ?direction?, and root jn?a?1 ?to know?is distinct from the feminine substantive jn?a?2?knowledge?.2.5 ScopingThere are two notions of scoping, one global,and the other one local.
First, every refer-ence ought to point to some binding occurrence,somewhere in the data base, so that a click onany used occurrence in the hypertext documentought to result in a successful context switch-ing to the appropriate link.
Ideally this linkought to be made to a unique binding occur-rence.
Such binding occurrences may be explicitin the document; typically, for proper nouns,this corresponds to a specific semantic item,which explains their denotation as the name ofsome human or mythological figure or geograph-ical entity.
For common nouns, the binding oc-currence is usually implicit in the structure ofthe dictionary, corresponding either to the mainstem of the entry, or to some auxiliary stem orflexed form listed as an orthographic variant.
Inthis sense a binding occurrence has as scope thefull dictionary, since it may be referred to fromanywhere.
In another sense it is itself withinthe scope of a specific entry, the one in whichit appears as a stem or flexed form or propername definition, and this entry is itself physi-cally represented within one HTML document,to be loaded and indexed when the referenceis activated.
In order to determine these, thegrinder builds a lexical tree (trie) of all bindingoccurrences in the data base, kept in permanentstorage.
A cross-reference analysis checks thateach used occurrence is bound somewhere.Actually, things are still a bit more elabo-rate, since each stem is not only bound lexico-graphically in some precise entry of the lexicon,but it is within the scope of some grammati-cal role which determines uniquely its declen-sion paradigm.
Let us explain this by way of arepresentative example.
Consider the followingtypical entry:k mAr kuma?ra m. garc?on, jeune homme; fils| prince; page; cavalier | myth.
np.
de Kuma?ra?Prince?, e?pith.
de Skanda ?
n. or pur ?
f.kuma?r??
adolescente, jeune fille, vierge.There are actually four binding occurrences inthis entry.
The stem kuma?ra is bound initiallywith masculine gender for the meaning ?boy?,and rebound with neuter gender for the mean-ing ?gold?.
The stem kuma?r??
is bound with fem-inine gender for the meaning ?girl?.
Finally theproper name Kuma?ra is bound in the mytho-logical sememe, the text of which contains anexplicit reference to proper name Skanda.3 The grammatical engineWe are now ready to understand the secondstage in our Sanskrit linguistic tools, namelythe grammatical engine.
This engine allows thecomputation of inflected forms, that is declen-sions of nouns and finite conjugated forms ofverbs.
For nouns, we observe that in Sanskrit,declension paradigms are determined by a suffixof the stem and its grammatical gender.
Sincewe just indicated that all defined occurrencesof substantive stems occurring in the dictionarywere in the scope of a gender declaration, thismeans that we can compute all inflected formsof the words in the lexicon by iterating a gram-matical engine which knows how to decline astem, given its gender.Similary, for verbs, conjugation paradigms forthe present system fall into 10 classes (and theaorist system has 7 classes).
Every root entrymentions explicitly its (possibly many) presentand aorist classes.3.1 SandhiGiven a stem and its gender, standard grammarparadigm tables give for each number and casea suffix.
Glueing the suffix to the stem is com-puted by a phonetic euphony process known assandhi (meaning ?junction?
in Sanskrit).
Actu-ally there are two sandhi processes.
One, calledexternal sandhi, is a regular homomorphism op-erating on the two strings representing two con-tiguous words in the stream of speech.
The endof the first string is modified according to thebeginning of the second one, by a local euphonyprocess.
Since Sanskrit takes phonetics seri-ously, this euphony occurs not just orally, but inwriting as well.
This external sandhi is relevantto contiguous words, and compound formation.A more complex transformation, called inter-nal sandhi, occurs for words derived by affixesand thus in particular for inflected forms in de-clension and conjugation.
The two composedstrings influence each other in a complex processwhich may influence non-local phonemes.
Thusprefixing ni (down) to root sad (to sit) makesverb nis.ad (to sit down) by retroflexion of s af-ter i, and further suffixing it with na for formingits past participle makes nis.an.
n. a (seated) by as-similation of d with n and further retroflexionof both occurrences of n.While this process remains deterministic (ex-cept for occasional cases where some pho-netic rules are optional), and thus is easilyprogrammable for the synthesis of inflectedforms, the analysis of such derivations is non-deterministic in a more complex way than thesimple external sandhi, since it involves a com-plex cascading of rewrites.3.2 DeclensionsUsing internal sandhi, systematic declension ta-bles drive the declension engine.
Here toothe task is not trivial, given the large num-ber of cases and exceptions.
At present ournominal grammatical engine, deemed sufficientfor the corpus of classical Sanskrit (that is,not attempting the treatment of complex vedicforms), operates with no less than 86 tables(each describing 24 combinations of 8 cases and3 numbers).
This engine may generate all de-clensions of substantives, adjectives, pronounsand numerals.
It is to be remarked that thisgrammatical engine, available as a stand-aloneexecutable, is to a large extent independent ofthe lexicon, and thus may be used to give thedeclension of words belonging to a larger cor-pus.
However, the only deemed correctness isthat the words actually appearing in the lexiconget their correct declension patterns, includingexceptions.This grammatical engine is accessible onlinefrom the hypertext version of the lexicon, sinceits abstract structure ensures us not only ofthe fact that every defined stem occurs withinthe range of a gender declaration, but con-versely that every gender declaration is withinthe range of some defined stem.
Thus we madethe gender declarations (of non-compound en-tries) themselves mouse sensitive as linked tothe proper instanciation of the grammaticalCGI program.
Thus one may navigate with aWeb browser not only within the dictionary asan hypertext document (thus jumping in the ex-ample above from the definition of Kuma?ra tothe entry where the name Skanda is defined, andconversely), but also from the dictionary to thegrammar, obtaining all relevant inflected forms.Similarly for roots, the present class indica-tor is mouse-sensitive, and yields on demand thecorresponding conjugation tables.
This under-lines a general requirement for the grammaticaltools: each such process ought to be callablefrom a concrete point in the text, correspond-ing unambiguously to a node in the abstractsyntax of the corresponding entry, with a scop-ing structure of the lexicon such that from thisnode all the relevant parameters may be com-puted unambiguously.In order to compute conjugated forms of non-root verbs, the list of its relevant preverbs isavailable, each preverb being a link to the ap-propriate entry (from which the etymologicallink provides the return pointer).
Other de-rived stems (causative, intensive and desider-ative forms) act also as morphology generators.3.3 Inflected forms managementOne special pass of the grinder generates thetrie of all declensions of the stems appearing inthe dictionary.
This trie may be itself pretty-printed as a document describing all such in-flected forms.
At present this represents about2000 pages of double-column fine print, for atotal of around 200 000 forms of 8200 stems(133655 noun forms and 55568 root finite verbalforms).3.4 Index managementAnother CGI auxiliary process is the index.
Itsearches for a given string (in transliterated no-tation), first in the trie of defined stems, andif not found in the trie of all declined forms.It then proposes a dictionary entry, either thefound stem (the closest stem the given string isan initial prefix of) or the stem (or stems) whosedeclension is the given string, or if both searchesfail the closest entry in the lexicon in alphabeti-cal order.
This scheme is very effective, and theanswer is given instantaneously.An auxiliary search engine searches Sanskritwords with a naive transcription, without dia-critics.
Thus a request for panini will return theproper link to pa?n.
ini.3.5 LemmatizationThe basic data structures and algorithms de-veloped in this Sanskrit processor have actuallybeen abstracted as a generic Zen toolkit, avail-able as free software (Huet, 2002; Huet, 2003b;Huet, 2003d).One important data structure is the revmap,which allows to store inflected forms as aninvertible morphological map from stems, withminimal storage.
The Sanskrit platform usesthis format to store its inflected forms in ain such a way that it may directly be usedas a lemmatizer.
Each form is tagged with alist of pairs (stem, features), where featuresgives all the morphological features used inthe derivation of the form from root stem.A lemmatization procedure, available as aCGI executable, searches this structure.
Forinstance, for form devayos it lists:{ loc.
du.
m. | gen. du.
m. |loc.
du.
n. | gen. du.
n. }[deva]where the stem deva is a hyperlink to the cor-responding entry in the lexicon.
Similarly forverbal forms.
For pibati it lists:{ pr.
a. sg.
3 }[paa_1], indicating that itis the 3rd person singular present form of rootpa?1 in the active voice.We end this section by remarking that we didnot attempt to automate derivational morphol-ogy, although some of it is fairly regular.
Actu-ally, compound formation is treated at the levelof segmentation, since classical Sanskrit doesnot impose any bound on its recursion depth.Verb formation (which sequences of preverbs areallowed to prefix which root) is explicit in thedictionary structure, but it is also treated atthe level of the segmentation algorithm, sincethis affix glueing obeys external sandhi andnot internal sandhi, a peculiarity which mayfollow from the historical development of thelanguage (preverbs derive from postpositions).At present, noun derivatives from verbal rootsare explicit in the dictionary rather than be-ing computed out, but we envision in some fu-ture edition to make systematic the derivationof participles, absolutives, infinitives, and pe-riphrastic future and perfect.4 Syntactic analysis4.1 Segmentation and taggingThe segmenter takes a Sanskrit input as astream of phonemes and returns a stream of so-lutions, where a solution is a list of (inflected)words and sandhi rules such that the input isobtainable by applying the sandhi rules to thesuccessive pairs of words.
It is presented, andits completeness is proved, in (Huet, 2004).
Fur-ther details on Sanskrit segmentation are givenin (Huet, 2003a; Huet, 2003c).Combined with the lemmatizer, we thus ob-tain a (non-deterministic) tagger which returnsall the (shallow) parses of an input sentence.Here is an easy example:# process "maarjaarodugdha.mpibati";Solution 1 :[ maarjaaras< { nom.
sg.
m. }[maarjaara] >with sandhi as|d -> od][ dugdham< { acc.
sg.
m. | acc.
sg.
n. |nom.
sg.
n. }[dugdha] >with sandhi m|p -> .mp][ pibati< { pr.
a. sg.
3 }[paa#1] >with sandhi identity]This explains that the sentencema?rja?rodugdham.
pibati (a cat drinks milk) hasone possible segmentation, where maarjaras,nominative singular masculine of maarjara (andhere the stem is a hyperlink to the entry inthe lexicon glosing it as chat i.e.
cat) combinesby external sandhi with the following word byrewriting into maarjaro, followed by dugdhamwhich is the accusative singular masculine ofdugdha (draught) or the accusative or nomi-native singular neuter of dugdha (milk - samevocable), which combines by external sandhiwith the following word by rewriting into itsnasalisation dugdham.
, followed by pibati ...(drinks).4.2 Applications to philologyWe are now at the stage which, after propertraining of the tagger to curb down its over-generation, we shall be able to use it for scan-ning simple corpus (i. e. corpus built over thestem forms encompassed in the lexicon).
Thefirst level of interpretation of a Sanskrit textis its word-to-word segmentation, and our tag-ger will be able to assist a philology specialistto achieve complete morphological mark-up sys-tematically.
This will allow the development ofconcordance analysis tools recognizing morpho-logical variants, a task which up to now has tobe performed manually.At some point in the future, one may hopeto develop for Sanskrit the same kind of in-formative repository that the Perseus web siteprovides for Latin and Classical Greek2.
Suchresources are invaluable for the preservation ofthe cultural heritage of humanity.
The consid-erable classical Sanskrit corpus, rich in philo-sophical texts but also in scientific, linguisticand medical knowledge, is an important chal-lenge for computational linguistics.Another kind of envisioned application isthe mechanical preparation of students?
read-ers analysing a text at various levels of informa-tion, in the manner of Peter Scharf?s SanskritReader3.The next stage of analysis will group togethertagged items, so as to fulfill constraints of sub-categorization (accessible from the lexicon) and2http://www.perseus.tufts.edu/3http://cgi-user.brown.edu/Departments/Classics/Faculty/Scharf/agreement.
The result ought be a set of consis-tent dependency structures.
We are currentlyworking, in collaboration with Brendan Gillon,to the design of an abstract representation forsanskrit syntax making explicit dislocations andanaphora antecedents, with the goal of buildinga consistent tree bank from his work on the anal-ysis of the exemples from Apte?s manual (Apte,1885; Gillon, 1996).An interesting piece of design is the interfacebetween lexicon citations and the corpus.
Anintermediate structure is a virtual library, act-ing as a skeleton of the corpus used for indexa-tion.
This way citations in the lexicon are merepointers in the virtual library, which acts as acitations repository, but also possibly as a cita-tion server proxy to the actual corpus materalwhen it is actually available as marked-up text.For lack of space, we omit this material here.5 ConclusionsThe computational linguistic tools should bemodular, with an open-ended structure, andtheir evolution should proceed in a breadth-firstmanner, encompassing all aspects from pho-netics to morphology to syntax to semanticsto pragmatics to corpus acquisition, with thelexical database as a core switching structure.Proper tools have to be built, so that the an-alytic structure is confronted to the linguisticfacts, and evolves through experimentally ver-ifiable improvements.
The interlinking of thelexicon, the grammatical tools and the marked-up corpus is essential to distill all linguistic in-formation, so that it is explicit in the lexicon,while encoded in the minimal way which makesit non-redundant.We have argued in this article that the de-sign of an hypertext interface is useful to refinethe structure of the lexicon in such a way asto enforce these requirements.
However, sucha linguistic platform must carefully distinguishbetween the external exchange formats (XML,Unicode) and the internal logical structure,where proper computational structures (induc-tive data types, parametric modules, powerfulfinite-state algorithms) may enforce the consis-tency invariants.ReferencesVa?man Shivara?m Apte.
1885.
The Student?sGuide to Sanskrit Composition.
A Treatise onSanskrit Syntax for Use of Schools and Col-leges.
Lokasamgraha Press, Poona, India.Christiane Fellbaum, editor.
1998.
WordNet:An Electronic Lexical Database.
MIT Press.Brendan S. Gillon.
1996.
Word order in classi-cal Sanskrit.
Indian Linguistics, 57,1:1?35.Ge?rard Huet.
2000.
Structure of a San-skrit dictionary.
Technical report, IN-RIA.
http://pauillac.inria.fr/~huet/PUBLIC/Dicostruct.psGe?rard Huet.
2001.
From an informal textuallexicon to a well-structured lexical database:An experiment in data reverse engineering.
InWorking Conference on Reverse Engineering(WCRE?2001).
IEEE.Ge?rard Huet.
2002.
The Zen computationallinguistics toolkit.
Technical report, ESSLLICourse Notes.
http://pauillac.inria.fr/~huet/ZEN/zen.pdfGe?rard Huet.
2003a.
Lexicon-directed segmen-tation and tagging of Sanskrit.
In XIIthWorld Sanskrit Conference, Helsinki.Ge?rard Huet.
2003b.
Linear contexts and thesharing functor: Techniques for symboliccomputation.
In Fairouz Kamareddine, edi-tor, Thirty Five Years of Automating Mathe-matics.
Kluwer.Ge?rard Huet.
2003c.
Towards computationalprocessing of Sanskrit.
In InternationalConference on Natural Language Processing(ICON), Mysore, Karnataka.Ge?rard Huet.
2003d.
Zen and the art of sym-bolic computing: Light and fast applicativealgorithms for computational linguistics.
InPractical Aspects of Declarative Languages(PADL) symposium.
http://pauillac.inria.fr/~huet/PUBLIC/padl.pdfGe?rard Huet.
2004.
A functional toolkitfor morphological and phonological pro-cessing, application to a Sanskrit tagger.Journal of Functional Programming, to ap-pear.
http://pauillac.inria.fr/~huet/PUBLIC/tagger.pdf.Huanfeng Ma, Burcu Karagol-Ayan, David Do-ermann, Doug Oard, and Jianqiang Wang.2003.
Parsing and tagging of bilingual dictio-naries.
Traitement Automatique des Langues,44,2:125?149.G.
A. Miller.
1990.
Wordnet: a lexical databasefor English.
International Journal of Lexicog-raphy, 3,4.Alain Polgue`re.
2003.
Lexicologie et se?mantiquelexicale.
Presses de l?Universite?
de Montre?al.
