RELAT ING COMPLEXITY  TO PRACTICALPERFORMANCE IN  PARSING WITH WIDE-COVERAGEUNIF ICAT ION GRAMMARSJ ohn  Carrol lUnivers i ty  of Cambr idge ,  Computer  LaboratoryPembroke  St reet ,  Cambr idge  CB2 3QG,  UKj ac@c l .cam.ac .ukAbstractThe paper demonstrates that exponential com-plexities with respect o grammar size and inputlength have little impact on the performance ofthree unification-based parsing algorithms, usinga wide-coverage grammar.
The results imply thatthe study and optimisation of unification-basedparsing must rely on empirical data until complex-ity theory can more accurately predict he practi-cal behaviour of such parserQ.1.
INTRODUCTIONGeneral-purpose natural language (NL) analysissystems have recently started to use declarativeunification-based sentence grammar formalisms;systems of this type include SRI's CLARE sys-tem (Alshawi et al, 1992) and the A1vey NL Tools(ANLT; Briscoe et al, 1987a).
Using a declarativeformalism helps ease the task of developing andmaintaining the grammar (Kaplan, 1987).
In ad-dition to syntactic processing, the systems incor-porate lexical, morphological, and semantic pro-cessing, and have been applied successfully to theanalysis of naturally-occurring texts (e.g.
Alshawiet al, 1992; Briscoe & Carroll, 1993).Evaluations of the grammars in these par-ticular systems have shown them to have widecoverage (Alshawi et al, 1992; Taylor, Grover &=Briscoe, 1989) 2.
However, although the practicalthroughput of parsers with such realistic gram-mars is important, for example when process-1This research was supported by SERC/DTIproject 4/1/1261 'Extensions to the Alvey Natu-ral Language Tools' and by EC ESPRIT BRA-7315'ACQUILEX-II'.
I am grateful to Ted Briscoe for com-ments on an earlier version of this paper, to DavidWeir for valuable discussions, and to Hiyan Alshawifor assistance with the CLARE system.2For example, Taylor et al demonstrate hat theANLT grammar is in principle able to analyse 96.8%of a corpus of 10,000 noun phrases taken from a varietyof corpora.ing large amounts of text or in interactive ap-plications, there is little published research thatcompares the performance of different parsingalgorithms using wide-coverage unification-basedgrammars.
Previous comparisons have either fo-cussed on context-free (CF) or augmented CFparsing (Tomita, 1987; Billot & Lang, 1989),or have used relatively small, limited-coverageunification grammars and lexicons (Shann, 1989;Bouma & van Noord, 1993; Maxwell & Kaplan,1993).
It is not clear that these results scaleup to reflect accurately the behaviour of parsersusing realistic, complex unification-based gram-mars: in particular, with grammars admitting lessambiguity parse time will tend to increase moreslowly with increasing input length, and also withsmaller grammars rule application can be con-strained tightly with relatively simple predictivetechniques.
Also, since none of these studies relateobserved performance to that of other comparableparsing systems, implementational oversights maynot be apparent and so be a confounding factor inany general conclusions made.Other research directed towards improvingthe throughput of unification-based parsing sys-tems has been concerned with the unification oper-ation itself, which can consume up to 90% of parsetime (e.g.
Tomabechi, 1991) in systems using lex-icalist grammar formalisms (e.g.
HPSG; Pollard& Sag, 1987).
However, parsing algorithms as-sume more importance for grammars having moresubstantial phrase structure components, uch asCLARE (which although employing some HPSG-like analyses till contains several tens of rules)and the ANLT (which uses a formalism derivedfrom GPSG; Gazdar et al, 1985), s incethe morespecific rule set can be used to control which uni-fications are performed.In NL analysis, the syntactic information as-sociated with lexical items makes top-down pars-ing less attractive than bottom-up (e.g.
CKY;Kasami, 1965; Younger, 1967), although the lat-ter is often augmented with top-down predic-287tion to improve performance (e.g.
Earley, 1970;Lang, 1974; Pratt,  1975).
Section 2 describesthree unification-based parsers which are relatedto polynomial-complexity bottom-up CF parsingalgorithms.
Although incorporating unificationincreases their complexity to exponential on gram-mar size and input length (section 3), this ap-pears to have little impact on practical perfor-mance (section 4).
Sections 5 and 6 discuss thesefindings and present conclusions.2.
THE PARSERSThe three parsers in this study are: a bottom-up left-corner parser, a (non-deterministic) LRparser, and an LR-like parser based on an algo-rithm devised by Schabes (1991).
All three parsersaccept grammars written in the ANLT formal-ism (Briscoe et al, 1987a), and the first two aredistributed as part of the ANLT package.
Theparsers create parse forests (Tomita, 1987) thatincorporate subtree sharing (in which identicalsub-analyses are shared between differing super-ordinate analyses) and node packing (where sub-analyses covering the same portion of input whoseroot categories are in a subsumption relationshipare merged into a single node).THE BOTTOM-UP LEFT-CORNERPARSERThe bottom-up left-corner (BU-LC) parser oper-ates left-to-right and breadth-first, storing partial(active) constituents in a chart; Carroll (1993)gives a full description.
Although pure bottom-up parsing is not usually thought of as provid-ing high performance, the actual implementationachieves very good throughput (see section 4) dueto a number of significant optimisations, amongstwhich are:?
Efficient rule invocation from cheap (static) ruleindexing, using discrimination trees keyed onthe feature values in each rule's first daughterto interleave rule access with unification andalso to share unification results across groupsof rules.?
Dynamic indexing of partial and complete con-stituents on category types to avoid attempt-ing unification or subsumption operations whichstatic analysis shows will always fail.?
Dynamic storage minimisation, deferring struc-ture copying--e.g, required by the unificationoperation or by constituent creation--until ab-solutely necessary (e.g.
unification success orparse success, respectively).The optimisations improve throughput by a factorof more than three.THE NON-DETERMINIST IC  LRPARSERBriscoe & Carroll (1993) describe a methodologyfor constructing an LR parser for a unification-based grammar, in which a CF 'backbone' gram-mar is automatically constructed from the unifi-cation grammar, a parse table is constructed fromthe backbone grammar, and a parser is driven bythe table and further controlled by unification ofthe 'residue' of features in the unification gram-mar that are not encoded in the backbone.
Inthis parser, the LALR(1) technique (Aho, SethiUllman, 1986) is used, in conjunction witha graph-structured stack (Tomita, 1987), adapt-ing for unification-based parsing Kipps' (1989)Tomita-like recogniser that achieves polynomialcomplexity on input length through caching.On each reduction the parser performs theunifications pecified by the unification grammarversion of the CF backbone rule being applied.This constitutes an on-line parsing algorithm.
Inthe general case, the off-line variant (in which allunifications are deferred until the complete CFparse forest has been constructed) is not guaran-teed to terminate; indeed, it usually does not do sowith the ANLT grammar.
However, a drawbackto the on-line algorithm is that a variant of Kipps'caching cannot be used, since the cache must nec-essarily assume that all reductions at a given ver-tex with all rules with the same number of daugh-ters build exactly the same constituent every time;in general this is not the case when the daughtersare unification categories.
A weaker kind of cacheon partial analyses (and thus unification results)was found to be necessary in the implementation,though, to avoid duplication of unifications; thissped the parser up by a factor of about three, atlittle space cost.THE COMPILED-EARLEY PARSERThe Compiled-Earley (CE) parser is based on apredictive chart-based CF parsing algorithm de-vised by Schabes (1991) which is driven by a tablecompiling out the predictive component of Ear-ley's (1970) parser.
The size of the table is relatedlinearly to the size of the grammar (unlike the LRtechnique).
Schabes demonstrates that this parseralways takes fewer steps than Earley's, althoughits time complexity is the same: O(n3).
The spacecomplexity is also cubic, since the parser uses Ear-ley's representation f parse forests.The incorporation of unification into the CEparser follows the methodology developed forunification-based LR parsing described in the pre-vious section: a table is computed from a CF'backbone', and a parser, augmented with on-lineunification and feature-based subsumption opera-288tions, is driven by the table.
To allow meaningfulcomparison with the LR parser, the CE parser usesa one-word lookahead version of the table, con-structed using a modified LALR technique (Car-roll, 1993) 3 .To achieve the cubic time bound, the parsermust be able to retrieve in unit time all items inthe chart having a given state, and start and endposition in the input string.
However, the obviousarray implenmntation, for say a ten word sentencewith the ANLT grammar, would contain almost500000 elements.
For this reason, the implementa-tion employs a sparse representation for the array,since only a small proportion of the elements areever filled.
In this parser, the same sort of dupli-cation of ratifications occurs as in the LR parser,so lists of partial analyses are cached in the sameway.3.
COMPLEXIT IES  OF  THEPARSERSThe two wu'iables that determine a parser's com-l)utational complexity are the grammar and theinput string (Barton, Berwick &: Ristad, 1987).These are considered separately in the next twosections.GRAMMAR-DEPENDENTCOMPLEXITYThe term dependent on tile grammar in the timecomplexity of the BU-LC unification-based parserdescribed above is O(IC\[2\[RI3), where ICI is thenumber of categories implicit in the grammar, and\]RI, the number of rules.
The space complexity isdominated by the size of the parse forest, O(\]C\[)(these results are proved by Carroll, 1993).
Forthe ANLT grammar, in which features are nestedto a maximum depth of two, ICI is finite but nev-ertheless extremely large (Briscoe et al, 1987b) 4.The grammar-dependent complexity of theLR parser makes it also appear intractable: John-son (1989) shows that the number of LR(0) statesfor certain (pathological) grammars is exponen-tially related to the size of the grammar, and thatthere are some inputs which force an LR parserto visit all of these states in the course of a parse.aSchabes describes a table with no lookahead; thesuccessful application of this technique supports Sch-abes' (1991:109) assertion that "several other methods(such as LR(k)-like and SLR(k)-like) can also be usedfor constructing the parsing tables \[...\]"aBarton, Berwick & Ristad (1987:221) calculatethat GPSG, also with a maximum nesting depth oftwo, licences more than 10 rr5 distinct syntactic ate-gories.
The number of categories i actually infinite ingrammars that use a fully recursive feature system.Thus the total number of operations performed,and also space consumed (by the vertices in thegraph-structured stack), is an exponential func-tion of the size of the grammar.To avoid this complexity, the CE parser em-ploys a table construction method which ensuresthat the number of states in the parse table islinearly related to the size of the grammar, re-sulting in the number of operations performed bythe parser being at worst a polynomial function ofgrammar size.INPUT-DEPENDENTCOMPLEXITYAlthough the complexity of returning all parsesfor a string is always related exponentially to itslength (since the number of parses is exponen-tial, and they must all at least be enumerated),the complexity of a parser is usually measured forthe computation of a parse forest (unless extract-ing a single analysis from the forest is worse thanlinear) 5.If one of the features of the ANLT grammarformalism, the kleene operator (allowing indefiniterepetition of rule daughters), is disallowed, thenthe complexity of the BU-LC parser with respectto the length of the input string is O(np+l), wherep is the maximum number of daughters in a rule(Carroll, 1993).
The inclusion of the operator in-creases the complexity to exponential.
To retainthe polynomial time bound, new rules can be in-troduced to produce recursive tree structures in-stead of an iterated fiat tree structure.
However,when this technique is applied to the ANLT gram-mar the increased overheads in rule invocation andstructure building actually slow the parser down.Although the time and space complexities ofCF versions of the LR and CE parsers are O(n3),the unification versions of these parsers both turnout to have time bounds that are greater than cu-bic, in the general case.
The CF versions implicitlypack identical sequences of sub-analyses, and inall reductions at a given point with rules with thesame number of daughters, the packed sequencescan be formed into higher-level constituents asthey stand without further processing.
However,in the unification versions, on each reduce actionthe daughters of the rule involved have to be uni-fied with every possible alternative sequence of thesub-analyses that are being consumed by the rule5This complexity measure does correspond to realworld usage of a parser, since practical systems canusually afford to extract only a small number of parsesfrom the frequently very large number encoded in aforest; this is often done on the basis of preference-based or probabilistic factors (e.g.
Carroll & Briscoe,1992).289(in effect expanding and flattening out the packedsequences), leading to a bound of n p+I on the totalnumber of unifications.4.
PRACTICAL  RESULTSTo assess the practical performance of the threeunification-based parsers described above, a seriesof experiments were conducted using the ANLTgrammar (Grover, Carroll & Briscoe, 1993), awide-coverage grammar of English.
The gram-mar is defined in metagrammatical formalismwhich is compiled into a unification-based 'ob-ject gran~mar'--a syntactic variant of the Defi-nite Clause Grammar formalism (Pereira & War-ren, 1980)--containing 84features and 782 phrasestructure rules.
Parsing uses fixed-arity term uni-fication.
The grammar provides full coverageof the following constructions: declarative sen-tences, imperatives and questions (yes/no, tag andwh-questions); all unbounded ependency types(topicalisation, relativisation, wh-questions); arelatively exhaustive treatment of verb and ad-jective complement types; phrasal and preposi-tional verbs of many complement types; passivi-sation; verb phrase extraposition; sentence andverb phrase modification; noun phrase comple-ments and pre- and post-modification; partitives;coordination of all major category types; and nom-inal and adjectival comparatives.Although the grammar is linked to a lexi-con containing definitions for 40000 base forms ofwords, the experiments draw on a much smallerlexicon of 600 words (consisting of closed classvocabulary and, for open-class vocabulary, defi-nitions of just a sample of words which taken to-gether exhibit the full range of possible comple-mentation patterns), since issues of lexical cover-age are of no concern here.COMPARING THE PARSERSIn the first experiment, he ANLT grammar wasloaded and a set of sentences was input to eachof the three parsers.
In order to provide an inde-pendent basis for comparison, the same sentenceswere also input to the SRI Core Language En-gine (CLE) parser (Moore & Alshawi, 1992) withthe CLARE2.5 grammar (Alshawi et al, 1992), astate-of-the-art system accessible to the author.The sentences were taken from an initial sam-ple of 175 representative s ntences extracted froma corpus of approximately 1500 that form part ofthe ANLT package.
This corpus, implicitly defin-ing the types of construction the grammar is in-tended to cover, was written by the linguist whodeveloped the ANLT grammar and is used to checkfor any adverse ffects on coverage when the gram-mar is modified during grammar development.
OfParser Grammar CPU time Storageallocated47 .0  BU-LCLRCECLEANLTANLTANLTCLARE2.575.548.998.4277.733.638.5Table 1: Parse times (in CPU seconds on a SunSparc ELC workstation) and storage allocated (inmegabytes) while parsing the 129 test sentences(1-12 words in length).the initial 175 sentences, the CLARE2.5 grammarfailed to parse 42 (in several cases because punc-tuation is strictly required but is missing from thecorpus).
The ANLT grammar also failed to parsethree of these, plus an additional four.
These sen-tences were removed from the sample, leaving 129(mean length 6.7 words) of which 47 were declar-ative sentences, 38 wh-questions and other sen-tences with gaps, 20 passives, and 24 sentencescontaining co-ordination.Table 1 shows the total parse times and stor-age allocated for the BU-LC parser, the LR parser,and the CE parser, all with ANLT grammarand lexicon.
All three parsers have been im-plemented by the author to a similar high stan-dard: similar implementation techniques are usedin all the parsers, the parsers hare the same uni-fication module, run in the same Lisp environ-ment, have been compiled with the same optimisa-tion settings, and have all been profiled with thesame tools and hand-optimised to a similar ex-tent.
(Thus any difference in performance of morethan around 15% is likely to stem from algorithmicrather than implementational reasons).
Both ofthe predictive parsers employ one symbol of looka-head, incorporated into the parsing tables by theLALR technique.
Table 1 also shows the resultsfor the CLE parser with the CLARE2.5 grammarand lexicon.
The figures include garbage collectiontime, and phrasal (where appropriate) processing,but not parse forest unpacking.
Both grammarsgive a total of around 280 analyses at a similarlevel of detail.The results show that the LR parser is ap-proximately 35% faster than the BU-LC parser,and allocates about 30% less storage.
The mag-nitude of the speed-up is less than might be ex-pected, given the enthusiastic advocation of non-deterministic CF LR parsing for NL by some re-searchers (e.g.
Tomita, 1987; Wright, Wrigley &Sharman, 1991), and in the light of improvementsobserved for predictive over pure bottom-up ars-ing (e.g.
Moore & Dowding, 1991).
However, onthe assumption that incorrect prediction of gaps is290the main avoidable source of performance degra-dation (c.f.
Moore & Dowding), further investiga-tion shows that the speed-up is near the maximumthat is possible with the ANLT grammar (around50%).The throughput of the CE parser is half thatof the LR parser, and also less than that of theBU-LC parser.
However, it is intermediate be-tween the two in terms of storage allocated.
Partof the difference in performance between it andthe LR parser is due to the fact that it performsaround 15% more unifications.
This might beexpected since the corresponding finite state au-tomaton is not determinised--to avoid theoreticalexponential time complexity on grammar s ize~thus paying a price at run time.
Additional rea-sons for the relatively poor performance of the CEparser are the overheads involved in maintaininga sparse representation f the chart, and the factthat with the ANLT grammar it generates less"densely packed" parse forests, since its parse ta-ble, with 14% more states (though fewer actions)than the LALR(1) table, encodes more contextualdistinctions (Billot & Lang, 1989:146).Given that the ANLT and CLARE2.5 gram-mars have broadly similar (wide) coverage and re-turn very similar numbers of syntactic analyses forthe same inputs, the significantly better through-lint of the three parsers described in this paperovcr the CLE parser 6 indicates that they do notcontain any significant implementational deficien-cies which would bias the results 7.SWAPPING THE GRAMMARSOVERA second experiment was carried out with theCLE parser, in which the built-in grammar andlexicon were replaced by versions of the ANLT ob-ject grammar and lexical entries translated (auto-matically) into the CLE formalism.
(The reverseof this configuration, in which the CLARE2.5grammar is translated into the ANLT formalism,is not possible since some central rules containsequences of daughters pecified by a single 'list'variable, which has no counterpart in the ANLTand cannot directly be simulated).
The through-~Although the ANLT parser is implemented inCommon Lisp and the CLE parser in Prolog, compar-ing parse times is a valid exercise since current com-piler and run-time support echnologies for both lan-guages are quite well-developed, and in fact the CLEparser takes advantage of Prolog's built-in unificationoperation which will have been very tightly coded.7The ANLT's speed advantage over CLARE is lesspronounced if the time for morphological nalysis andcreation of logical forms is taken into account, proba-bly because the systems use different processing tech-niques in these modules.put of this configuration was  only one fiftieth ofthat of the BU-LC  parser.
The  ANLT  grammarcontains more  than five t imes as many rules thandoes the sentence-level portion of the CLARE2.5grammar ,  and  A lshawi  (personal communicat ion)points out that the CLE  parser had  not previouslybeen run with a grammar  containing such a largenumber  of rules, in contrast to the ANLT  parsers.THE EFFECT OF SENTENCELENGTHAlthough the mean sentence length in the first twoexperiments i much shorter than the 20-30 wordlength (depending on genre etc.)
that is commonin real texts, the test sentences cover a wide rangeof syntactic constructions and exhibit less con-structional bias than would a set of sentences ex-tracted at random from a single corpus.
However,to investigate performance on longer sentences andthe relationship between sentence length and parsetime, a further set of 100 sentences with lengthsdistributed uniformly between 13 and 30 wordswas created by hand by the author and added tothe previous test data.
Table 2 shows  the relation-ship between sentence length and  mean parse t imewith the BU-LC  and  LR  parsers.In contrast to the results f rom the first exper-iment, the throughput  of the LR  parser is only4% better than that of the BU-LC  parser for sen-tences of 13-27 words  in length.
The  former parsesmany sentences up  to twice as fast, but a smallproportion of the others are parsed almost twiceas slowly.
As well as their wide variability withrespect to the BU-LC parser, the absolute vari-ability of the LR parse times is high (reflected inlarge standard eviations--a--see Table 2).
Mostof the sentences for which LR performance is worsecontain more than one occurrence of the passiveconstruction: due to their length this is particu-larly the case for the group of sentences of 28-30words with which the LR parser performed partic-ularly badly.
However, it is likely that if the con-straining power of the parse table were improvedin this area the difference in throughput betweenLR and BU-LC would revert to nearer the 35%figure seen in the first experiment.The standard eviations for numbers of parsesare also relatively large.
The maximum number ofparses was 2736 for one 29-word sentence, but onthe other hand some of even the longest sentenceshad fewer than ten parses.
(But note that sincethe time taken for parse forest unpacking is notincluded in parse times, the latter do not vary bysuch a large magnitude).The results of this experiment are displayedgraphically in Figure 1, together with a quadraticfunction.
Comparison with the function suggests291Sentencelength(words)1-34-67-910-1213-1516-1819-2122-2425-2728-30BU-LCParse timeMean a0.11 0.060.23 0.180.42 0.241.17 0.920.97 0.281.92 0.753.54 1.423.87 1.625.45 1.987.86 2.37LRParse timeMean a0.05 0.020.15 0.110.28 0.170.76 0.520.86 0.381.89 1.003.74 2.463.61 3.075.05 3.5912.89 5.65Number ofparsesMean a1.3 0.71.4 0.81.8 1.33.8 2.410.0 13.714.3 17.560.1 117.3143.8 200.1168.8 303.1343.5 693.7Table 2: Mean and standard eviation parse times (in CPU seconds on an HP9000/710 workstation), andnumbers of parses for the 229 test sentences (1-30 words in length) with the BU-LC and LR parsers.that, at least for the BU-LC parser, parse time isrelated roughly quadratically to input length.In previous work with the ANLT (Briscoe &Carroll, 1993), throughput with raw corpus datawas worse than that observed in these experi-ments, though probably only by a constant factor.This could be due to the fact that the vocabu-lary of the corpus concerned exhibits significantlyhigher lexical ambiguity; however, for sentencestaken from a specific corpus, constructional biasobserved in a training phase could be exploited toimprove performance ( .g.
Samuelsson &: Rayner,1991).5.
D ISCUSSIONAll three of the parsers have theoretical worst-casecomplexities that are either exponential, or poly-nomial on grammar size but with an extremelylarge multiplier.
Despite this, in the practicalexperiments reported in the previous ection theparsers achieve relatively good throughput with ageneral-purpose wide-coverage rammar of a nat-ural language.
It therefore seems likely that gram-mars of the type considered in this paper (i.e.
withrelatively detailed phrase structure components,but comparatively simple from a unification per-spective), although realistic, do not bring the pars-ing algorithms involved anywhere near the worst-case complexity.In the experiments, the CE technique resultsin a parser with worse performance than the nor-mal LR technique.
Indeed, for the ANLT gram-mar, the number of states--the term that the CEtechnique reduces from exponential to linear onthe grammar size---is actually smaller in the stan-dard LALR(1) table.
This suggests that, whenconsidering the complexity of parsers, the issue ofparse table size is of minor importance for realisticNL grammars (as long as an implementation rep-resents the table compactly), and that improve-ments to complexity results with respect o gram-mar size, although interesting from a theoreticalstandpoint, may have little practical relevance forthe processing of natural anguage.Although Schabes (1991:107) claims that theproblem of exponential grammar complexity "isparticularly acute for natural anguage processingsince in this context he input length is typicallysmall (10-20 words) and the grammar size verylarge (hundreds or thousands of rules and sym-bols)", the experiments indicate that, with a wide-coverage NL grammar, inputs of this length canbe parsed quite quickly; however, longer inputs(of more than about 30 words in length)--whichoccur relatively frequently in written text--are aproblem.
Unless grammar size takes on propor-tionately much more significance for such lougerinputs, which seems implausible, it appears thatin fact the major problems do not lie in the areaof grammar size, but in input length.All three parsers have worst-case complexitiesthat are exponential on input length.
This theo-retical bound might suggest hat parsing perfor-mance would be severely degraded on long sen-tences; however, the relationship between lengthof sentence and parse tinm with the ANLT gram-mar and the sentences tested appears to be ap-proximately only quadratic.
There are probablymany reasons why performance is lnuch betterthan the complexity results suggest, but the mostimportant may be that:?
kleene star is used only in a very limited context(for the analysis of coordination),?
more than 90% of the rules in the grammar haveno more than two daughters, and?
very few rules license both left and right re-cursion (for instance of the sort that is typi-cally used to analyse noun compounding, i.e.29214Me 12an i0C 8PU 6t 4im 2e0\[ ~BU-LC parser BLR parser ~n 2/100............... __~ ............................ ?
.
...!
| !
!
!
!
!1-3 4-6 7-9 10-12 13-15 16-18 19-21 22-24 25-27 28-30Sentence length (n)Figure h Mean parse times (in CPU seconds on an HP9000/710 workstation) for the test sentences withthe BU-LC and LR parsers.
A quadratic function is also displayed.N - ->  N N).Despite little apparent heoretical differencebetween the CLE and ANLT grammar formalisms,and the fact that no explicit or formal processof 'tuning' parsers and grammars to perform wellwith each other has been carried out in either ofthe ANLT or CLARE systems, the results of theexl)eriment comparing the performance of the re-spective parsers using the ANLT grammar sug-gests that the parallel development ofthe softwareand grammars that has occurred nevertheless ap-pears to have caused this to happen automatically.It therefore seems likely that implementational de-cisions and optimisations based on subtle proper-ties of specific grammars can, and may very of-ten be, more important than worst-case complex-ity when considering the practical performance ofparsing algorithms.6.
CONCLUSIONSThe research reported is in a similar vein tothat of, for example, Moore & Dowding (1991),Samuelsson & Rayner (1991), and Maxwell & Ka-plan (1993), in that it relies on empirical resultsfor the study and optimisation of parsing algo-rithms rather than on traditional techniques ofcomplexity analysis.
The paper demonstrates thatresearch in this area will have to rely on empiri-cal data until complexity theory is developed to apoint where it is sufficiently fine-grained and ac-curate to predict how the properties of individualunification-based grammars will interact with par-ticular parsing algorithms to determine practicalperformance.REFERENCESAho, A., R. Sethi & J. Ullman (1986) Compilers:principles, techniques and tools.
Reading, MA:Addison-Wesley.Alshawi, H., D. Carter, R. Crouch, S. Pulman, M.Rayner & A. Smith (1992) CLARE: a contex-tual reasoning and cooperative r sponse frame-work for the Core Language Engine.
SRI In-ternational, Cambridge, UK.Barton, G., R. Berwick ~z E. Ristad (1987) Com-putational complexity and natural language.Cambridge, MA: MIT Press.Billot, S. ~z B. Lang (1989) "The structure ofshared forests in ambiguous parsing."
In Pro-ceedings of the 27th Meeting of the Associationfor Computational Linguistics.
143-151.Bouma, G. & G. van Noord (1993) "Head-drivenparsing for lexicalist grammars: experimentalresults."
In Proceedings of the 6th Conferenceof the European Chapter of the Association forComputational Linguistics.
101-105.Briscoe, E., C. Grover, B. Boguraev & J. Carroll(1987a) "A formalism and environment for thedevelopment of a large grammar of English.
"In Proceedings of the lOth International JointConference on Artificial Intelligence.
703-708.293Briscoe, E., C. Grover, B. Boguraev & J. Carroll(1987b) "Feature defaults, propagation andreentrancy."
In Categories, Polymorphism andUnification, edited by E. Klein & J. van Ben-them, Centre for Cognitive Science, EdinburghUniversity, UK.
19-34.Briscoe, E. & J. Carroll (1993) "Generalisedprobabilistic LR parsing of natural anguage(corpora) with unification-based grammars.
"Computational Linguistics, 19(1): 25-59.Carroll, J.
(1993) Practical unification-based pars-ing of natural anguage.
Computer Laboratory,Cambridge University, UK, Technical Report314.Carroll, J.
& E. Briscoe (1992) "Probabilisticnormalisation and unpacking of packed parseforests for unification-based grammars."
InProceedings o/the AAAI  Fall Symposium onProbabilistic Approaches to Natural Language.33-38.Earley, J.
(1970) "An efficient context-free pars-ing algorithm."
Communications of the ACM,13.2: 94-102.Gazdar, G., E. Klein, G. Pullum & I.
Sag (1985)Generalized phrase structure grammar.
Ox-ford, UK: Blackwell.Grover, C., J. Carroll &= E. Briscoe (1993) TheAlvey natural anguage tools grammar (~th re-lease).
Computer Laboratory, Cambridge Uni-versity, UK, Technical Report 284.Johnson, M. (1989) "The computational complex-ity of Tomita's algorithm."
In Proceedings o/the 1st International Workshop on ParsingTechnologies.
203-208.Kaplan, R. (1987) "Three seductions of compu-tational psycholinguistics."
In Linguistic The-ory and Computer Applications, edited by P.Whitelock et al, New York: Academic Press.149-188.Kasami, J.
(1965) An efficient recognition andsyntax analysis algorithm for context-free lan-guages.
Air Force Cambridge Research Labo-ratory, Bedford, MA, Report AFCRL-65-758.Kipps, J.
(1989) "Analysis of Tomita's algorithmfor general context-free parsing."
In Proceed-ings o/ the 1st International Workshop onParsing Technologies.
193-202.Lang, B.
(1974) "Deterministic techniques for effi-cient non-deterministic parsers."
In Automata,Languages and Programming, Lecture Notesin Computer Science 1~, edited by J. Loeckx,Berlin, Germany: Springer-Verlag.
255-269.Maxwell, J. III ?
: R. Kaplan (1993) "The interfacebetween phrasal and functional constraints.
"Computational Linguistics, 19(4): 571-590.Moore, R. & H. Alshawi (1992) "Syntactic and se-mantic processing."
In The Core Language En-gine, edited by H. Alshawi, Cambridge, MA:MIT Press.
129-148.Moore, R. & J. Dowding (1991) "Efficient bottom-up parsing."
In Proceedings of the DARPASpeech and Natural Language Workshop.
200-203.Pereira, F. & D. Warren (1980) "Definite clausegrammars for language analysis--a survey ofthe formalism and a comparison with aug-mented transition etworks."
Artificial Intel-ligence, 13(3): 231-278.Pollard, C. & I.
Sag (1987) Information-based syn-tax and semantics: volume 1-fundamentals.Chicago, IL: University of Chicago Press.Pratt, V. (1975) "LINGOL - a progress report.
"In Proceedings o/the 5th International JointConference on Artificial Intelligence.
422-428.Samuelsson, C. ~z M. Rayner (1991) "Quantita-tive evaluation of explanation-based l arningas an optimization tool for a large-scale nat-ural language system."
In Proceedings o/the12th International Joint Conference on Artifi-cial Intelligence.
609-615.Schabes, Y.
(1991) "Polynomial time and spaceshift-reduce parsing of arbitrary context-freegrammars."
In Proceedings o/the 29th AnnualMeeting of the Association/or ComputationalLinguistics.
106-113.Taylor, L., C. Grover & E. Briscoe (1989) "Thesyntactic regularity of English noun phrases.
"In Proceedings o/the 4th European Meeting o/the Association/or Computational Linguistics.256-263.Tomabechi, H. (1991) "Quasi-destructive graphunification."
In Proceedings of the 29th AnnualMeeting of the Association for ComputationalLinguistics.
315-322.Tomita, M. (1987) "An efficient augmented-context-free parsing algoritlmL" Computa-tional Linguistics, 13(1): 31-46.Shann, P. (1989) "The selection of a parsing strat-egy for an on-line machine translation systemin a sublanguage domain.
A new practicalcomparison."
In Proceedings o/the 1st Inter-national Workshop on Parsing Technologies.264-276.Wright, J., E. Wrigley  R. Sharman (1991)"Adaptive probabilistic generalized LR pars-ing."
In Proceedings of the 2nd InternationalWorkshop on Parsing Technologies.
154-163.Younger, D. (1967) "Recognition and parsing ofcontext-free languages in time n'~. ''
IT~fo~-ma-tion and Control, 10(2): 189-208.294
