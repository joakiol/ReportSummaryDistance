DR-LINK System: Phase I SummaryElizabeth D. Liddy & Sung H. MyaengSyracuse University4-206 Center for Science & TechnologySyracuse, New York 13244-4100liddy@ mailbox.syr.edu; shmyaeng@ mailbox.syr.edu1.
Description of System1.1 ApproachThe underlying principle of the DR-LINK System isthat retrieval must be at the conceptual level, not theword level.
That is, a successful retrieval system mustretrieve on the basis of what people mean in theirquery, not just what they say in their query.
The sameis true of documents - their representation needs tocapture the content at the conceptual level ofexpression.
To accomplish this human-like goal, DR-LINK aims to represent and match documents andqueries at all of the available levels of linguisticexpression at which meaning is conveyed.
Accordingly,we have developed a modular system which processes,represents, and matches text at the lexical, syntactic,semantic, and discourse levels of language.
In concert,these levels of representation permit DR-LINK toachieve a level of intelligent retrieval beyond moretraditional pproaches.The DR-LINK system takes an innovative approach todealing with the specific characteristics of theinformation retrieval tasks required in TIPSTER,focusing on the development ofa retrieval system wheredocuments as well as queries are enriched with multiplelevels of annotation, with the final representation beinga network of concepts and relations expressed in aconceptual graph (Sowa, 1984), thereby enablingretrieval based on conceptual relations.
Relations areextracted and represented throughout the system at manylevels, ranging from relations between words, to caserelations between arguments of a verb, to discourselevel relations involving whole sections of text.The system's conceptual processing was particularlymotivated by various semantic restrictions often foundin the TIPSTER topic statements.
A retrieval systemneeds to be able to process natural language sentencesand extract key concepts and the implicit relationsamong them, which cannot be expressed as a set ofkeywords or phrases.
For example, it may be crucial todetect documents hat talk about a dispute betweenAirbus and an aircraft company (i.e.
the specificrelationship between the two concepts), not just aboutdispute, Airbus, and aircraft company in isolation.Additional relations, e.g.
the discourse level relations of'pending' or 'consequence of'are essential requirementsof topic statements that need be fulfilled in relevantdocuments.In order to achieve conceptual level representation, wehave implemented a range of methods for detectingconcepts and extracting relations from natural languagesentences in a large text database, by detectingdomain-independent li guistic patterns that revealrelations between concepts, which are contained in theset of knowledge bases.
Our efforts at knowledge baseconstruction were geared toward general-purpose u  in avariety of text processing applications and were guidedby corpus tatistics, machine-readable lexical resources,and linguistic theories.1.2 Processing FlowThe DR-LINK system employs sophisticated,linguistically-oriented text processing techniquesthroughout inorder to capture the necessary conceptualinformation in texts.
Since various modules in thesystem require different annotations of the texts, weopted for staged processing rather than a single-stagefull parsing.
The system was developed in a modularfashion and functional modularity has been achieved.
Ascurrently configured, DR-LINK performs a stagedprocessing of documents, with each module adding ameaningful annotation to the text.
For matching, atopic statement undergoes analogous processing todetermine its relevancy requirements for documents ateach stage.Among the many benefits of staged processing are:improvements and adjustments can be easil~rnadewithin any module; the contribution of the various93stages can be empirically tested by simply turning themon or off; modules can be re-ordered for betterutilization of document annotations, and; individualmodules can be incorporated inother evolving systems.The full flow is described in detail in the followingsection.1.3Description of Key ModulesAs currently configured, the DR-LINK System (Figure1) consists of two stages of processing.
The systemdescription and results will be reported according to thisdivision.
All of the documents ina corpus are processedby the modules of Stage One, which produces a rankedlist of documents according to their predicted egree ofrelevance to an individual query.
In the TIPSTERenvironment, this ranking was used in two ways: onewas for submission of test-runs for the twenty-fourmonth relevance assessment evaluation; the second wasfor provision of a selected set of documents for furtheranalysis and matching by Stage Two.
As seen in Figure1, Stage One consists of the modules beginning withthe Text Structurer which lead into the IntegratedMatcher, while the modules beginning with theRelation Concept Detector which lead into theConceptual Graph Matcher comprise Stage Two.The ~ provides a clean, standardized set ofdocuments and queries for use in both Stage One andStage Two.
The Preprocessor subdivides newspapertexts into their subtexts on the basis of orthographicclues.
This means that long newspaper articles whichconcatenate numerous reports will be accuratelyprocessed as separate stories.
Part-of-speech tags areadded to the pre-processed texts using our C version ofBBN's POST (Meteer et al, 1991).
Since severalmodules require segmentation f individual sentences,we apply our constituent boundary bracketer to thetagged texts to identify boundaries of clauses and nounphrases using a relatively simple pattern-drivenprocessing.1.3.1 Stage One ModulesThe Ig,v&,~.lrdl.qlllr, g~is based on discourse linguistictheory which suggests that texts of a particular typehave a predictable t xt-level structure which serves as anindication of how and where certain informationendemic to a text-type will be conveyed.
We haveimplemented a Text Structurer for the newspaper text-type, which produces an annotated version of a newsarticle in which each clause or sentence is tagged for thespecific slot it instantiates in the news-text model, e.g.MAIN EVENT, EXPECTATION, CONSEQUENCE.The structural annotations are used to respond moreprecisely to information eeds expressed in TopicStatements, where some aspects of relevancyrequirements such as time, source, intentionality, andstate of completion can only be met by understanding aTopic Statement's discourse requirements (e.g.
theconsequences of automation; a proposed themepark development).The Text Structurer assigns news-text component labelsto document clauses/sentences on the basis of fourtypes of linguistic evidence l arned from text.
We havereduced the matching complexity via a function thatmaps the thirty-eight news-text components which arerecognized in documents to seven meta-componentrequirements which are recognized in Topic Statements.This allows the system to impose fine-level structureon newspaper articles with excellent precision and tomap this fuller set of text components to theappropriate l vel of discourse requirement specificitytypically expressed inTopic Statements.The Subject Field Coder (SFCoder) uses anestablishet~ semantic oding scheme from the machine-readable Longmans Dictionary of ContemporaryEnglish (LDOCE) to tag each word in a text with itsdisambiguated subject code (e.g.
Agriculture, Military,Political Science) and to then produce a fixed-length,subject-based vector epresentation f each document'sand query's contents.
Using the SFCoder, each text orsub-text is represented asa vector of the normalizedfrequencies of the SFCs for that unit's constituentwords.
The normalized SFC vectors represent theimplicit semantics of text at a level of abstraction abovethe word level.The V-8 SFC Matcher combines the annotations ofthe Text Structurer and the SFCOder in a representationthat captures the distribution of SFCs across thediscourse meta-components that occur in a document.Up to eight SFC-vectors are produced for each document -one for each of the seven Text Structure meta-components, plus one for the combined categories.Experimentation with several formulas for combiningthe similarity values of the meta-component SFCvectors which are responsive to a particular queryindicated that the Dempster-Shafer algorithm issuperior.
The V-8 Matcher's unique combination ofdiscourse semantics and lexical semantics produced a13% improvement in precision over matching on justlexical semantics.The Proner Noun (PN~ Internreter uses a varietyof processing heuristics and knowledge bases to94DOCUMENTS TOPICSPreprocessorText Structurer(TS)Proper Noun (PN)InterpreterComplex Nominal (CN)PhraserTS+PN+CNInverted FileF ield i\[ CreatorCoder |V8 SFC ":~!!
::"NLP QueryConstructorRelation ConceptDetectorConceptualMarcher TS+PN+CN il Graph (CG)ilMatcher ii!
Generator illL ~  ~ In tegrated~ ~ l w l t c n e r ,  .
.
\[-:--Rec~ili------:| ............................ vreolctor j\[ ~;~ ...................... ":i:,'iiI:::~'~l4Stage 1 Stage 2Ranked List Ranked ListFigure 1.
DR-LINK SystemTopic CGProcessorIproduce: a canonical representation f each PN; aclassification of each PN into one of thirty-sevencategories (e.g.
organization, country, company), and;an expansion of group nouns into their constituent PNmembers (e.g.
European Community to all membercountries).
Inaddition, the accurate indexing of multiplereferences to a proper noun entity throughout adocument permits complete representation of themultiple relational links implicitly contained in thearticle.
The module recognizes and categorizes propernouns with 93% accuracy using 37 categories as testedon a sample of 545 PNs from newspaper text.
Therepresentations produced by the PN Interpreter a e usedin Stage One matching and also provide rich relational95information later used by the CG Matcher.The Comnlex Nominal  Phraser provides a meansfor precise matching of complex semantic onstructswhen expressed as either adjacent nouns or a non-predicating adjective +noun pair.
We have focused oncomplex nominals because they were observed toconvey much of the conceptual content of a text (e.g.debt reduction, campaign financing, electronic theft).
Inaddition, we have been experimenting with computa-tional means that permit the system to produceconceptual matches when the constructs are expressed insynonymous phrases, thereby addressing issues of bothrecall and precision.
Substitutable phrases for each CNcan be found by statistical corpus analysis whichidentifies all second order associations between each CNconstituent and terms in the corpus.
Terms that exhibitsecond order associations (terms used interchangeably incertain contexts) are compiled into equivalence classesfor use by the matching algorithms.In addition, each complex nominal and its assignedrelation in a query provides a concept-relation-concepttriple to the later Relation-Concept Detector module foruse in Stage Two matching.
Semantic relations betweenthe constituent ouns of each complex nominal in thequery are stored in a knowledge base, using an ontologyof forty-three r lations.
The existence of both case-framerelations and complex nominal relations makes itpossible for the system to detect conceptual similarityeven if expressed indifferent grammatical structures bymeans of a relation-similarity table that assigns adegreeof similarity across the two grammatically-distinguishedsets, and a degree of similarity between pairs within thesame set.
The relation-similarity able is used in StageTwo matching to allow concepts that are linked by arelation in a document that is different from the relationthat links the same two concepts in a Topic Statement,to still be awarded some degree of similarity.The Natural Laneuaee Ouerv Constructor forStage One takes as input a natural anguage TopicStatement and produces a query which reflects theappropriate logical combination of the Text Structure,Proper Noun, and Complex Nominal requirements ofaTopic Statement.
The basis of the Query Constructor(QC) is a sublanguage rammar which is based on ageneralization over the regularities exhibited in theTopic, Description, and Narrative fields of the onehundred and fifty TIPSTER Topic Statements.
The QCsublanguage grammar relies on items such ~ functionwords, meta-text phrases, and punctuation to recognizeand extract the logical combination of relevancyrequirements of Topic Statements.
The QC sublanguageinterprets a Topic Statement into pattern-action ruleswhich translate ach sentence into a first order logicassertion, reflecting the boolean-like requirements ofTopic Statements, including NOT'd assertions andresolved efinite noun phrase anaphora.The TS+PN+CN Marcher evaluates each logicalassertion produced by the Query Constructor against theentries in the inverted ocument file and assigns aweight o each document segment if it matches the PN+ CN Boolean requirements of the Topic Statement.
Ifthe document segment also matches the TopicStatement's Text Structure requirement, this weight isincreased.
Depending on which field in the TopicStatement the assertion came from, the preliminaryvalue will be weighted by a co-efficient reflectingimportance as indicated in the Topic Statement.
Thehighest similarity value for a single assertion in thedocument is selected as that document's explicitsimilarity match to the Topic Statement.The Integrated Matcher combines the 'explicitsimilarity' value as determined by the TS+PN+CNMatcher with the 'implicit similarity' value asdetermined by the SFC V-8 Matcher and an integratedsimilarity score for each document is produced.
Thissimilarity value is used in several ways: 1) to provide afull ranking of all the documents for the Stage OneRanked List, and; 2) as input to the Recall Predictor, afilter which determines for each new query how manydocuments from the ranked list should be passed toStage Two in order for this set to contain 100% of allthe relevant documents for that query.The Recall Predictor's filtering function isaccomplished by means of a multiple regressionformula that successfully predicts a ranked-list cut-offcriterion for individual queries based on the similarity ofdocuments o the query in terms of their SFC, ProperNoun, Complex Nominal, and Text Structurerequirements (Liddy et al 1993b).
The real power of theRecall Predictor is its sensitivity to the varieddistributions of similarity values for individual queries.For a few queries, agood portion of the ranked list mayneed to be passed to Stage Two.
However, for mostqueries, arelatively small portion of the database needsto be passed to Stage Two in order to guarantee thepotential of 100% recall.
For example, to achieve 100%recall for Topic Statement 42, the regression formulapredicts a cut-off criterion similarity value whichrequires that only 13% of Stage One's rankedoutput beprocessed by later modules.
The available relevancejudgments have shown that this pool of documentscontained 99% of the documents judged relevant for that96query.
Fuller performance r sults on the Recall Predictorare included in Section 5.2.1.3.2  Stage Two ModulesThe Relatinn.Coneent.Deteetor (RCD) providesbuilding blocks for the Conceptual Graph (CG)representation by generating concept-relation-concept(CRC) triples based on the domain-independentknowledge bases which have been constructed withmachine-readable resources and corpus tatistics.
In thismodule, there are several handlers that are activatedselectively depending on the input sentence.
In addition,the rich relational annotations received from the ProperNoun Interpreter and the relations between constituentssupplied by the Complex Nominal Phraser contribute tothe CRC output of the module.The Case Frame (CF) Handler generates CRC tripleswhere one of the concepts comes usually from a verb.
Itidentifies a verb in a sentence and connects it to otherconstituents surrounding the verb.
Since the relations(about 50 are used currently) included in ourrepresentation riginate from theories of linguistic aseroles, and are all semantic in nature, this moduleconsults the knowledge base containing 13,786 caseframes we have constructed, each of which prescribes apattern involving a verb and the correspondingconcept-relation-concept triples.The CF Handler selects the best case frame byattempting to instantiate each case frame and determinewhich one is satisfied most by the sentence at hand.This can be seen as a sense disambiguation processusing both syntactic and semantic information.
Thesemantic restriction information contained in the caseframes were obtained from LDOCE, and when thesentence is processed, the CF Handler also consultsLDOCE to get semantic restriction information forindividual constituents surrounding the verb in thesentence and compares it with the restrictions in thecase frames of the verb as a way to determine whichcase frame is likely to be the correct one.
For example,with the sentence fragment .... the chairman declined toelaborate on the disclosure .... the CF Handler choosesan appropriate case frame and produces\[decline\] ->(AGENT) -> \[chairman\]\[decline\] ->(ACTIVITY) -> \[elaborate\]\[elaborate\] -> (AGENT) -> \[chairman\].The Nominalized Verb (NV) Handler consults the NVcase frames to identify a NV in a sentence and createCRC triples based on the rule.
At the same time, itconverts the NV into its verb form.
In this way, we canallow for a match between a CG fragments generatedfrom a phrase containing verb and another fragmentgenerated from a noun phrase containing thecorresponding ominalized verb.
For example, the NVHandler converts the sentence fragment, ... thecompany's investigation of the incident .... into\[investigate\] -> (AGENT) -> \[company\]\[investigate\]-> (PATIENT) -> \[incident\].This process is much more than a sophisticated way ofperforming stemming in that we canonicalizeconcept-relation-concept tri les rather than just conceptnodes.The Ad-Hoc Handler looks for lexical patterns notcovered by any of the other special handlers.
Itsprocessing is also driven by its own knowledge base ofpatterns to infer relations between concepts.
Theknowledge base contains a small number of simplepatterns involving BE verbs and more than 350 patternrules for phrasal patterns across phrase boundaries (e.g."...
for the purpose of ...' reveals the relation GOAL),by which important relations are extracted.
The patternrules specify certain lexical patterns and the order ofoccurrences ofwords belonging to certain part-of-speechcategories, and the CRC triples to be generated.
Thesepatterns require a processing capability no morepowerful than a finite state automaton.The Concentual  Granh Generator mergesindividual CI~C triples generated for a document to forma set of conceptual graphs, each corresponding to aclause in most cases.
Since more than one handler cangenerate different triples for the same concept pairs (e.g.a prepositional phrase handled by the CF handler and theNP/PP handler) based on independently constructed rulesand on independent processes, a form of conflictresolution is necessary.
In the current implementation,we simply order the execution of different handlers basedon the general quality of the rules and the resultingtriples so that more reliable handlers have higherprecedence.For semi-automatic processing of topic statements forCG generation, the current system first applies the sameRCD and CG generator modules to produce topicstatement CGs.
Several topic statement-specificprocessing requirements have been identified, some ofwhich have been implemented as post-processingroutines and others are under development.
Theseinclude: elimination of concept and relation nodescorresponding to contentless meta-phrases (e.g.97"Relevant document must identify ..."); handling ofnegated parts of topic statements; automatic assignmentof weights to concept and relation odes, and; mergingcommon concept appearing in different sections of topicstatements.The ~ adds Ro~et's International Thesauruscodes to individual concept nodes as a way to make ourcurrent representation more "conceptual", so that thelabel on the nodes is not a word but a position of thehierarchy of RIT.
The lowest level position beyondindividual lexical items in the RIT hierarchy consists ofseveral terms within the delimiter of semi-colons,which represents a concept.The mapping from a word (called target) in text to aposition in RIT requires ense disambiguafion, and ourapproach is to use the words surrounding the target wordas the context within which the sense of the target wordis determined and one or more RIT codes are selected.The algorithm selects minimal number (i.e.
one ormore) of RIT codes, not just the best one, for targetwords since we feel that some of the sense distinctionsmade in RIT are unnecessarily subtle, and it is unlikelythat any attempts to make such fine distinctions wouldbe successful and hence contribute to informationretrieval.The Concentual Granh Mil|chel"s main function isto determine the relevance of each document against atopic statement CG and produce a ranked list ofdocuments as the output of Stage Two of the system.Using the techniques necessary to model plausibleinferences with CGs, this module computes the degreeto which the topic statement CG is covered by the CGsin the document.While our approach as the ability to enhance precisionby exploiting the structure of the CGs and thesemantics of relations in document and topic statementCGs, and by attempting to meet the specific semanticconstraints of topic statements, we also attempt oincrease recall by allowing flexibility in node-levelmatching.
Concept labels can be matched partially (e.g.between "Bill Clinton' and "Clinton'), and both relationand concept labels can be matched inexactly (e.g.between "aid' and "loan' or between "AGENT' and"EXPERIENCER').
For both inexact and partialmatches, we determine the degree of matching and applya multiplication factor less than 1 to the resulting score.For inexact matching cases, we have used the relationsimilarity table, described above in the ComplexNominal Phraser section, to determine the degree ofsimilarity between pairs of relations.
Although thistype of matching slows down the matching time, wefeel that until we have a more accurate way ofdetermining the conceptual relations and a way torepresent at a truly conceptual level (e.g.
our attempt touse RIT codes), it is necessary.
More importantly, thesimilarity table reflects our ontology of relations andallows for matching between relations produced bydifferent RCD handlers whose operations in turn areheavily dependent on the domain-independent knowledgebases.1.4 .Hardware/Software RequirementsThe DR-LINK System has been running in a universityenvironment on a Sun Spare workstation, runningUNIX, with a C compiler.
The only special-purposesoftware required is a part-of-speech tagger that is a Cversion of the POST tagger (Meteer et al 1991).
We arecurrently developing our own tagger based onmorphological statistics (Liddy & McHale, in press).No special-purpose hardware is required to run theDR-LINK system.1.5 Eff ic iency/Speed/Throughput StatisticsThere are two points to be made regarding the notion ofefficiency.
First, there is no question that thesophisticated text processing and document retrievalusing the rich representations described above can bedone only at the expense of processing timerequirements.
The primary goal of the project o datehas been to focus on developing and implementing newideas in a prototype without much concern forefficiency.
Whenever there was a choice betweenefficiency and a potential for improved effectivenessthrough richer representation a d more sophisticatedprocessing, we chose the latter.
In other words, ourdesign goal was to include as many features as possibleso that they can be tested not only as a whole but alsoindividually.Secondly, since we conduct our research in a universityenvironment, DR-LINK does not have a dedicated serverand must time-share computing resources with allstudents and faculty.
Therefore the throughput reportedhere is the lower bound to be expected of even thisprototype system.
Additionally, since the textprocessing and matching were done on differentmachines hared by multiple processes, it was notpossible to generate statistics on efficiency of thesystem which can be used reliably as a prediction ofthroughput of a future operational system using thealgorithms in the current experimental system.98There are a few points we can report in this regard.Stage One of the system can analyze and annotate therepresentation of an estimated 1.5 Megabyte ofdocuments an hour.
We do not have reliable times onthe matching for Stage One.
Currently, we are puttingour effort into extending and optimizing Stage One'smatching process for our ongoing tech-transfer fforts.In order to provide some indication of how much timewas spent running Stage Two of the system for the24th month evaluation, we gathered statistics using asmall sample of documents on a SUN SPARC-10workstation with 128 RAM for both concept-relation-concept generation and matching.
The RCD moduleprocessed the already POS-tagged and bracketed text atthe rate of approximately 12K bytes per second toproduce concept-relation-concept triples.The result of the sample runs of the CG matcher in thesame computing environment shows a wide range oftime requirements depending on topic statements.
Witha sample Wall Street Journal documents and three topicstatements, the average matching times per documentvaried from 1 second to 12 seconds.
It appears that thetime required for matching depends on such factors as:the number of nodes in the topic statements; thefrequency of topic statement nodes in documentconceptual graphs (i.e.
specificity of concept nodes); theextent to which similarity tables (concept termsimilarities, relation similarities, and complex nominalsimilarities) need to be looked up for inexact matching;and the connectivity and size of conceptual graphs forboth topic statement and document.1.6 Key Innovations of SystemOne unique aspect of DR-LINK is its ability torepresent content at the conceptual level rather than theword level to enable intelligent information processingwhich mimics the multiple levels of languagecomprehension used by humans in understanding textand determining whether information is relevant o aquery.
The output of Stage One combines the lexical,syntactic, semantic, and discourse levels of understan-ding into a single prediction of adocument's relevancefor a query.
The key innovations can be summarized asfollows.
Stage One of DR-LINK:?
Accepts as input, a user's lengthy, ambiguous,complex, natural anguage query, which it translatesinto a precise Boolean representation f user's relevancerequirements.?
Produces ummary-level, semantic vector epresenta-tions of queries and documents which are used toquickly provide a reliable ranking of large sets ofdocuments at the subject-domain level.
The applicationof a tested regression formula determines a cut-offcriterion for an individual query so that quick andaccurate filtering of large data sets can be done.?
Fulfills the focused proper noun requirements ofqueries with highly accurate proper noun categorizationand controlled expansion of proper names via allvariants of proper noun entities and expansion of propernoun categories to their constituent members.?
Has the capability of providing high recall andprecision simultaneously, via controlled expansion ofcomplex nominals using lexical resources for expansionof each member of the complex nominal combined withcorpus statistics on phrase contexts so that thesubstantive content of a query can be matched in itssynonymous phrasings (e. g. capital spending -> capitalexpenditures -> equipment expenditures; trade ban ->trade sanctions -> export sanctions).?
Detects the implicit significance, temporal,credibility, state of completion, and intention aspects ofinformation in documents by use of the inherentdiscourse-level structure of various text types.
Thesemore holistic information aspects regarding the contentof a document are conveyed via discourse-level f aturesand frequently cannot be detected by reliance on word orsentence l vel linguistic features.?
Combines evidence from the multiple levels oflinguistic processing done on both the query anddocuments to assign a degree of belief, based onimplicit and explicit semantics, represented asa singleweight, that a particular document is likely to berelevant.Stage Two of the system is unique and innovative in itsattempt o explicitly satisfy the semantic restrictionscontained in topic statements.
With the RCD module,we attempted to extract relations between cor/cepts othat documents containing the required concepts that arelinked with the required semantic relation would receivea higher score than those without he specified link.Unlike other ule-based retrieval systems developed for asmall domain, the rules in the knowledge bases wedeveloped for relation extractions are domain-indepen-dent and were constructed based on corpus statistics andmachine-readable lexicai resources uch as LDOCE.Since the rules are domain-independent a d based ongeneral linguistic patterns, they can be applied to any99information retrieval contexts regardless of the types ordomains of databases.
In addition, the scope andcoverage of the knowledge bases can be extended easilywith the same methodology that relies on the linguisticpatterns of the lexical resources and the corpus.To our best knowledge, our work is the first attempt torepresent document and query contents in conceptualgraphs for information retrieval and model informationretrieval as conceptual graph matching which is a formof inferencing.
With this representation, furthermore,we incorporated Dempster-Shafer's theory of evidence(Shafer, 1976) as the basis for computing the similaritybetween a document and a query so that informationretrieval can be modeled as a process of gatheringevidence under uncertainty (Myaeng & Khoo, 1993).
Asa result, our development of the DR-LINK system haslaid a firm foundation for using relations and structuralrepresentation of documents and user needs ininformation retrieval environments where a largevolume of texts needs to be handled.2.
Original Project/System GoalsAs required, we proposed to develop a system whichwould be portable, modular, extensible, and domainindependent.
With the domain and language indepen-dence requirements, one of the main emphases of theoriginal project was to develop a learning module thatwould acquire structure-revealing a d relation-revealingpatterns over time by processing texts with or withouthuman intervention.
It became apparent at an early stageof the project that it would be more fruitful tode-emphasize the goal of making the learning module asautonomous as possible and shift our attention todeveloping linguistic knowledge bases andalgorithms.We now find, at the end of Phase I, thatcertain modules are at the point where we can exploitmachine learning.
We now have an understanding of themeta-processes involved in these modules, including thenature of their underlying models, and the linguisticevidence which the system needs for learning.To an extent, we believe that the original goals ofportability, modularity and extensibility have beenachieved in certain modules of the system.
For example,the Subject Field Coder algorithms, including thesemantic disambiguation algorithm, have beensuccessfully ported to another machine-readable lexicalresource, and are producing vectors which provideretrieval results equal to the original implementationwith LDOCE.
Modularity has quite demonstrably beenachieved as evidenced by our re-ordering of the StageOne modules for the twenty-four month test runs inorder to produce the highly successful V-8 vectorswhich combine SFC and Text Structure information.
Interms of extensibility, the Subject Code vector approachto implicit semantic level representation f text contenthas been proposed for extension into a multilingualenvironment, where it will be used to provide cross-language semantic representation and access todocuments in six languages (Liddy et al 1993a).Another important aspect of the original project was toexplicitly deal with user information needs bydeveloping a method of constructing and using userprofiles for the purpose of better representing userinformation eeds.
The user profiles in this context aremuch more extensive than the notion of profiles forrouting.
With the practical difficulty of accessing realusers for modeling and testing purposes, however, theidea was dropped at an early stage.3.
Evolution of System over Two YearsWe had originally envisioned a less modular, moreintegrated processing of texts which would basicallycombine two major levels of representation: discourselevel structure and semantic relations as expressed inConceptual Graphs.
Also, we had originally planned forConceptual Graph representations to be constructed forall the documents.
When it began to appear that thiswas unreasonable due to the processing requirements ofthe CG Matcher, we introduced the Subject Field Coderas a means of limiting the number of documents whichwould need to be processed by Stage Two.
The SFCoderhas proven to be not only a reliable predictor of relevantdocument sets, it also has proven to be a unique way ofadding implicit semantics to our representations.
Inaddition, the SFC vectors provide an excellentrepresentation which to cluster the collection forbrowsing (Liddy et al 1992).We had not originally intended to have a system withtwo such distinct stages as are present in the currentsystem.
The original goal was a continued enhancementof text as it passed through the full length of thesystem.
However, the exigencies of ARPA testingrequired that the system produce ranked output forcomparative valuation for the eighteenth monthtesting.
Since the Relation Concept Detector and CGGenerator and Matcher (which were originally plannedto produce the only ranking of documents) were notcompleted, we started providing ranked results from thefirst few modules, which~eventually became known asStage One.
These results were surprisingly good eventhough many important aspects of retrieval had not yetbeen included.100Subsequently, additional levels of representation a dmatching were added to Stage One as separate modules.The modular system provided for an environment inwhich empirical testing of the contribution of variouslevels of linguistic processing could be performed, aswell as an environment in which the results of ourdetailed analysis of Topic Statement requirements andretrieval results which guided our decisions, could beacted on with the addition of new levels of linguisticanalysis.
For example, since 85% of the TopicStatements are in some way concerned with proper nounentities, we began the second year of the project with afocus on development of the Proper Noun Interpreterwhich processes the distinctive linguistic constructionswhich modify proper nouns for the extraction of vitalsemantic information.
In addition, our observation thatboth recall and precision could be positively impactedby a constrained expansion of topics via the addition ofsynonymous phrasings of complex nominals, resultedin the development ofthe Complex Nominal Phraser.One particular module, the Text Structurer, has beenthrough a very interesting evolution, including quitedrastic shifts from a holistic model, to a distributed,attribute model, back to a model which combinedaspects of both of these models.
(Liddy, In press).
Inaddition, the original Text Structurer implementationused eight sources of linguistic evidence which wereevaluated by the Dempster-Shafer Theory of EvidenceCombination (Shafer, 1976) to assign a discoursecomponent label to each segment of text.
Analysis ofthe 18th month results and the relative contribution ofeach of the evidence sources to the module'sperformance, led us to reduce the number of evidencesources to four, which also allowed for the implementa-tion of a much leaner model of discourse-levelprocessing.4.
AccomplishmentsDR-LINK, which is still in the process of development,has just begun to achieve its potential, which is theprovision of the depth of matching of informationsource to information eed that now occurs only withthe assistance of a human intermediary (e. g. librarian orinformation specialist) who can interview the user;comprehend their information eed at the conceptual,not word level; understand the complexity of ways inwhich the relevant information might be expressed invarious information sources, and; bring the user's needand relevant documents together.
This is possiblebecause the human intermediary's understanding of boththe information eed and the information content ofdocuments i not limited to surface level matching.
,Theintermediary interprets ext (both queries and documents)at the multiple levels at which meaning is conveyed inhuman language: from pure lexical pattern matching; tothe disambiguated semantic word-level representationwhere only the appropriate s nse of an ambiguous wordis considered by the intermediary; to the semanticrelation level where not only the presence of requestedconcepts occurs, but these concepts also exist in thedesired relations to each other (e.g.
company A is thebuyer, not the seller); to the discourse level where thestructuring of the information content throughout thedocument conveys implicit relations, and theconnections between concepts that are distant in text arebrought into alignment.Stage One of the system has succeeded incombining alllevels of linguistic analysis in the provision of verypromising retrieval performance.
For instance, therankings produced by Stage One combine both implicitand explicit similarity between documents and queries ina new and principled way.
In addition, the RecallPredictor makes use of these combined similarities forthe accurate prediction of precisely how manydocuments from the ranked list need to be reviewed by auser in order to achieve aparticular level of recall.
Thiscapability is not available in other systems.
Given thesize of current databases and the real need of some usersto review every potentially relevant document, hefunctionality and reliability of the Recall Predictor is asizeable accomplishment.One hard-earned achievement is he recent demonstrationof the contribution of the discourse level informationwhich is made available by the Text Structurer.
One ofthe major tenets of the original proposal was thatdiscourse structure would positively impact retrieval.During the two years of the project, our ability toprovide discourse information about both documents andqueries continually increased.
However, our ability toutilize this enrichment was slow in developing.
Therecent implementation of the V-8 representationprovides one very appropriate and successful way toincorporate Text Structure knowledge in Stage One.However, we believe that he full potential of this levelof information will only be fully realized when itsavailability and functional capability is known andexploited by future users.
Additionally, a recentrealization in the field of IR is that retrieval of verylong, full-text documents, such as those in theTIPSTER corpus, may require sub-documentprocessing.
Although it was originally believed thatparagraph level computations might prove useful,results suggest that orthographic divisions in text arenot necessarily appropriate.
Discourse theory suggests101that the text level model would predict he appropriatesubdivisions.
We believe that the Text Structure whichwe can detect in documents will provide the appropriatesub-document units of analysis which are needed forhigh performance in the retrieval of long documents.A major accomplishment i  Stage Two of the system isthat We have laid a foundation for operationalization ofan unconventional information retrieval system that canhandle a user's semantic restriction explicitly.
For theRelation-Concept Detector, it means development ofboth algorithms and knowledge bases.
In the formercategory are an efficient constituent boundary bracketerand the special handlers (e.g.
case frame handler) fordifferent types of pattern rules.
For the latter, we havedeveloped: 13,786 case frames, 15,053 nominalized verbpatterns, and 350 ad-hoc rules.Other algorithms have been developed and implementedfor the purpose of retrieving documents based onconceptual graphs representations.
The RIT coder wasdeveloped as an attempt to provide a truly conceptualrepresentation although its efficacy has not been fullytested.
The conceptual graph matching algorithm is aflexible retrieval engine capable of modeling uncertaintyhandling, evidence gathering, and retrieving texts ofvarious sizes (e.g.
sentences, paragraphs etc.
), whentexts are represented as a network of concepts andrelations.While we believe that our accomplishment of buildingand testing our system in the TIPSTER environment isa significant step toward a breakthrough in informationretrieval, the complexity of the approach as forced usto leave many "loose" ends that need to be tightened upand improvements o be made, in order to take fulladvantage of the power of the algorithms and knowledgebases.First of all, there are many errors made by individualmodules and handlers in Stage Two in generatingaccurate conceptual graphs.
Some errors are propagatedthrough the stages of text processing.
For example, thepart-of-speech tagger often is confused between VBD(past ense verb) and VBN (past participle).
The currentbracketer relies on these tags to determine the main verbof a clause or a phrase and makes errors in determiningphrase boundaries, which in turn leads the Case FrameHandler to assign incorrect case roles to noun phrases.Since conjunctions are not handled properly eitherwithin the bracketer or within the special handlers,primarily due to our design decision to make thealgorithms non-recursive for simplicity and efficiency,many errors were made in the RCD output.These errors had much more severe impact on queryconstruction for Stage Two.
We applied the same RCDmodule to the topic statements with a few additionssuch as eliminating "meta-phrases" and assigningweights automatically.
The frequent occurrences ofconjunctions and other sub-language f atures of topicstatements such as parentheticals nd examples were nothandled by the Stage Two Topic Statement processor ina special way, sometimes resulting in inadequaterepresentations.
The negative impact of these errorsmanifest i self when the retrieval results from the 24thmonth evaluations are compared to those with manuallyconstructed queries in 18th month evaluations (Myaeng& Liddy, 1993).
Although they differ in terms of topicsand databases, the 18th month results were superior tothe 24 month results.Another aspect of the RCD module that has not beenfully developed is the handling of prepositions.
Therewas no direct attempt in RCD to deal with the unsolvedproblem of prepositional phrase attachment.
We adoptedthe simple default rule that unless a case role is assignedto a prepositional phrase by the expectation i the caseframe (as specified in LDOCE), it is attached to thenearest constituent with a general relation.
While thescheme of inexact matching between relations helpedalleviating the inaccurate assignments of relations, weobserved many remaining problems.Based on our failure analysis of Stage Two, it appearsthat all the errors mentioned above and the incompletenature of some of the handlers (e.g.
ad-hoc handler)resulted in the lack of matches on relation nodes whendocument and query conceptual graphs are matched.
Inother words, there weren't as many connected graphs inthe matching results as expected, and the payoff weexpected from all the efforts we put in to extractrelations weren't as great.S.
Evaluation SummaryThe DR-LINK System was tested as a Type B system,meaning that it was run against a smaller, morehomogenous corpora than the other systems.
In manyways, therefore, our results are hard to compare to theother detection contractors' performance.
Results wereproduced for the Ad Hoc Topic Statements against heWall Street Journal collections and the Routing TopicStatements against he San Jose Mercury collection.Stage One queries were automatically constructed, whileStage Two queries were semi-automatically generated inthat automatically generated queries were adjusted tomerge a small number of common concept nodesappearing across different Topic Statement fields.1025.1  Of f i c ia l  Resu l t sStage One produced seven runs in the Routing situationand three runs in the Ad Hoe situation.
As can be seenin Tables 1 and 2, the various Stage One runs producedroughly similar results on the official precisionmeasures.
There is little observable differentiation in theresults because the conditions tested in Stage One werenot of the type to introduce much variation in the top ofthe ranked lists, but rather, were designed to improvethe Recall Predictor's ability to pass to Stage Two a setcontaining as many of the relevant documents aspossible using various methods for combiningdocuments from four possible document groupings.
Thevariation between runs occurred either further down theranking of one thousand ocuments which were used tocompute precision or, in some instance, even past theone thousand ocument point.To understand the variations we were testing, considereach document's similarity value for a given TopicStatement as being composed of two elements.
Oneelement is the implicit similarity represented by theSFC vector value and the other element is the explicitsimilarity value that represents the combined ProperNoun, Complex Nominal, and Text Structuresimilarities.
The system applies the multiple regressionformula, and computes the mean and standard deviationof the distribution of the SFC similarity values for theindividual Topic Statement.
Using these statisticalvalues, the system produces the cut-off criterion value.Since the eighteen-month results indicated that 74% ofthe relevant documents had an explicit similarity to theTopic Statement and the remaining 26% of the relevantdocuments had no such explicit similarity, thisinformation was also used in predicting what proportionof the relevant documents should come from whichsegment of the ranked ocuments inorder to achieve fullrecall.
The groupings which are used to produce thefinal ranking can be envisioned as consisting of foursegments, as shown in Figure 2.Four groups are required to reflect the two-waydistinction mentioned above.
The first distinction isbetween those groups which have an explicit similarity(Groups 1 and 2) and which should contain 74% of therelevant documents and those documents without anexplicit similarity (Groups 3 and 4), which shouldcontribute 26% of the relevant documents.
The seconddistinction is between those documents whose SFCsimilarity value is above the predicted cut-off criterion(Groups 1 and 3) and those whose SFC similarity valueis not (Groups 2 and 4).In Table 1, which presents the Adhoc results, the threeruns all use the univector (as compared to V-8) versionof the SFC representation.
DRwu~l is the "straightDocs.
having an explicit match& an SFC valueabove  the cut-offDocs.
having an explicit match& an SFC valuebelow the cut-offDocs.
having no explicit match& an SFC valueabove  the cut-offDocs.
having no explicit match& an SFC valuebe low the cut-offII Group 1I.
.
.
.
.
.
.
.
.
cut-off criterion SFC similarity valueII Group 2III Group 3I.
.
.
.
.
.
.
.
.
cut-off criterion SFC similarity valueII Group 4I.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.Figure 2: Schematic of Document Groupings103Run AveragePrecisioni iPrecisionat 100R-Precision RelativePrecisionDRwusl 0.2237 0.2672 0.2778 !
0.4004| iDRwurl 0.2243 0.2706 0.2793 0.4115DRwuml 0.2247 0.2682 0.2793 0.4052Table 1.
Stage 1, Adhoccombination" of document similarity values.
Thismeans that he ranking is produced by concatenating theranks from the groups in sequential order from 1 to 4.Therefore, all documents hat have any match on theexplicit Proper Noun or Complex Nominal re-quirements of the Topic Statement will precededocuments without any such match.
As a result,documents which have any explicit similarity, eventhough their implicit similarity might be very low, willoutrank a document with very high implicit similarity.Therefore, this run emphasizes xplicit similarity.DRwur l  uses the "regression" formula, whichincorpoates the predicted percentage of relevantdocuments with and without an explicit match, to rankthe documents.
That is, the system will produce theranking by concatenating the documents above theappropriate cut-off rom Group 1; then documents abovethe appropriate cut-off rom Group 3, then documentsfrom Group 2.
Therefore, this run emphasizes implicitsimilarity.DRwu!.._l uses a "modified regression" formula toproduce rankings.
This is an adaptation of the regressionapproach, since our test results show that there is apotential 8% error in the predicted cut-off criterion for100% recall.
Therefore, we used extrapolation toadd theappropriate proportion of the top ranked documentsfrom Group 2 to Group 1, before concatenatingdocuments from Group 3.RunDRsuslDRsurlAveragePrecision0.17150.1431Precisionat 1000 13060 1258R-Precision0.204710.1782RelativePrecision0.36210.2992DRsuml 0.1638 0 1254 0.1984 0.3231DRsdsl 0.1689 0 1302 0.1980 0.4021DRsdrl 0.1611 0 1244 0.1951 0.3458DRsasl 0.1685 0 1290 0.1989 0.4031DRsarl 0.1443 0 1160 0.1841 0.3178Table 2.
Stage 1, RoutingComparison of the results shows that reliance on theregression formula, DRwurl, without he modification,produced the highest precision on three out of the fourprecision measures.The results from the routing queries (Table 2), whichwere run against the San Jose Mercury, reflect he factthat the regression formula was developed on earlierqueries using the Wall SWeet Journal as the trainingcorpus.
Therefore, it is not surprising that in the firstthree runs, the "straight" run (DRsu~I) surpasses theruns based on the regression formula (DRsurl) and themodified regression formula (DRsuml).The remaining four runs use the V-8 vectors, which useSFC similarity values based on those segments of thedocument whose Text-Structure match the TextStructure requirement ofthe Topic Statement.
A secondvariable which was tested in these runs is how to bestcombine the V-8 similarities.
DRsEIrl and DRs_dsl are104based on use of the Dempster-Shafer videncecombining algorithm, while DRarl and DRasl combinethe evidence using a straight average.
The Dempster-Shafer algorithm outperforms the averaging approach.The comparisons were run using both the "straight"approach to combining documents from the four groupsdescribed above, as well as the "regression" approach.As expected, since the regression formula was trained onthe Wall Street Journal, it did not perform as well in therouting situation, as did the "straight" approach.One result which we would like to point out is the12.6% improvement in average precision which the V-8use of discourse structure information provides, as canbe seen by comparing DRsdrl (V-8 combined using theDempster Shafer algorithm) to DRsurl (univector).Since the use of discourse level linguistic informationis new to the field of information retrieval, this result isa very promising first effort.Tables 3 and 4 provide document level averages forStage One, as a common measure for comparison ofStage One and Stage Two output.
That is, Table 3 canbe compared with Tables 5 and 6 for Stage 2 output onthe routing queries and Table 4 can be compared withTable 7 for Stage Two output on the ad hoc queries.In conclusion, although the official results for StageOne may not be equal to the other contractors' ystemperformance, it should be remembered that theperformance goal of Stage One was to enrich the textswith the multiple levels of linguistic representationwhich would permit Stage One to pass the selected levelof recall in the ranked lists provided to Stage Two forfurther efinement and matching.
As discussed in theSection 5.2 on Unofficial Results for Stage One, thisgoal was achieved with resounding success.At 5 docsAt 10 docsAt 20 docsAt 30 docsAt 100 docsDRsusl DRsurl0,2560 0.25600.2400 0.22800.2240 0,20900.2073 0,19600.1306 0.1258DRsuml!I0.25601DRsdslI I I0.24800.2300!
0.24000.2140!
0.22900.19931i i0.1254 ~0.20930.1302DRsdrl0.24800.23200.22100.20330.1244DRsasl0.2360DRsarl0.24000.2400 0.23000.2310 0.21600.2080i0.12900.19270.1160Table 3: Stage 1 Routing, Document Level Average PrecisionDRwusl DRwurl DRwumlIAt 5 docs 0.4000 0,4080 0.4000At 10 docs 0.4080 0.4120 0.4080At 20 docs 0.3890 0.3890 0.3890At 30 docs 0.3573 0.3567 0.3560At 100 docsI I0.2672 0.2706 0.2682Table 4: Stage 1 Ad Hoc, Document Level Average PrecisionFor Stage Two of the DR-LINK system, the officialruns we submitted were different in many ways fromthose other systems produced.
The input for the finalmatching was a relatively small set of documentsselected for each topic (2838 documents on average)because Stage Two selected 81% as the recall-levelprediction point.
Another difference is that only 500documents from the output for each topic was submittedfor evaluation, as opposed to 1000 documents.
Finally,due to the time constraints, the numbers of topics forrouting and ad-hoc included in the official runs were 45and 19, respectively.Table 5 shows document level averages for the routing105case where SO, S1, $2, and $3 represent differentscoring methods in the conceptual graph matching.
SOrepresents he basic scoring scheme xplained in secdon1.3.
S1 is a scoring scheme designed to give higherscores those documents containing matched sub-graphsthat are less fragmented.
In other words, the morecoherent the matching sub-graphs are with respect to thequery graph, the higher score they get even though thenumber of matching nodes are the same.
This was doneby segmenting documents into several parts andcomputing the scores for them before they arecombined.
$2 and $3 are two different scoring schemesthat take into account the maximum score obtained by asingle sub-graph match which was averaged out in thecase S1.At 5 docsAt 10 docsAt 20 docsAt 30 docsAt 100 doesSO0.28000.24440.22220.18370.1287$10.2978$2i0.31110.2078$30.29330.2489 0.2733 0.28220.22220.1852 0.19040.1309 0.13220.22220.19330.1311Table 5: Stage 2 Routing, Document Level Average PrecisionTable 6 shows a set of corresponding values when RITcodes were used in the representation.
Although thevalues in Table 6 are lower than those in Table 5 ingeneral, it should be noted that for some topics (e.g.
53,72, and 96), the average precision values obtained withRIT codes were significantly higher than those withoutRIT codes.
This indicates that usefulness of RIT codesdepends on the characteristics oftopic statements.SO $1 $2 $3IAt 5 does  0.2605 0.2698 0.2698 0.2698At 10 does 0.2395 0.2465 0.2465 0.2419At 20 docs 0.1977 0.2151 0.2360 0.2377At 30 does 0.1860 0.1891 0.2031 0.2008At 100 docs 0.1200 0.1240 0.1226 0.1221Table 6: Stage 2 Routing, Document Level Average Precision with RITBecause of the fact that only a subset of the entiredatabases (i.e.
a subset of relevant documents) was usedfor each query and that only 500 documents weresubmitted for evaluation, we feel that the documentlevel averages are better indicators of the systemperformance than the recall level averages.
Table 7shows the results for the Stage Two ad-hoc ase withoutRIT codes.106At 5 docsAt 10 docsAt 20 docsAt 30 docs !At 100 docs iSO0.42110.35790.31320.28070.2189$10.32630.32110.30000.27720.2116S2i i0.42110.37370.33680.31400.2311S30.41050.38420.35530.31750.2316Table 7: Stage 2 Adhoc, Document Level Average PrecisionWhile there was about 8% average precision differencebetween SO and S3 in our internal experiments with asmaller test collection, the differences among the fourscoring schemes are not very apparent in the sets of topranked ocuments as shown in the table.5.2 Unofficial ResultsThere is an additional functionality exhibited by StageOne of DR-LINK which is not measured by the officialprecision and recall formulas.
That is, the RecallPredictor can successfully apply a multiple regression-based cut-off criterion formula to the ranked list ofrelevant documents produced by Stage One to provide aset of documents which very accurately reflects aselected level of recall, As seen in Table 8, the baselinerun (DRwusl) in which no cut-off prediction is made,post hoc evaluation of the documents judged relevant bythe assessors, shows that all the relevant documentswere contained in the top 29% of the ranked list, asaveraged across the 50 Topic Statements.
Bycomparison, on DRwurl, which uses the regression-based formula as the criterion to predict he cut-off or100% recall, a 40% improvement in the portion of thedatabase which is filtered out is achieved, as only 17%needs to be processed by Stage Two.
Even moreimportantly, this system-predicted set of documentscontains 97% of the relevant documents.
Using themodified regression formula, DRwuml, 99% recall isachieved and only 23% of the database needs to befurther processed, a 22% improvement over thebaseline.While these are average results across 50 queries, whatshould be remembered is the wide range amongst queriesand the Recall Predictor's ability to provide queryspecific results.
For example, for one TopicStatement, the regression formula selects only 63documents for further processing, while for anotherTopic Statement, the formula selects 16,000.
In each ofthese instances, 100% recall is achieved.BaselineDRwuslRunRecall1.0000I IActual Recall atPredicted 1.00 Recalli%DB Searched29.32Average%DB Searched%Change in %DB Searchedfrom the BaselineDRwurl 0.9670 17.50 -40.31DRwuml 0.9864 22.77 -22.33Table 8: Recall Prediction, AdhocTable 9 presents the same type of result for the routingqueries.
As noted in the Official Results section, thefact that the regression formula was trained on anothercorpus than the one it was tested on in the routingsituation, produced somewhat poorer esults.
The actualrecall achieved at the 100% predicted recall level islower than on the adhoc queries, but the savings in thepercentage (45%, 49%, 56%) of the database whichneeds to be further processed is higher.
The lower actualrecall level performance can be corrected by simply107recomputing the regression formula with training datafrom the appropriate corpus.As discussed earlier, Stage Two did not elect o use thedocument set which Stage One predicted would containBaselineDRsuslIRunIDRsurlDRsumlDRsdrlRecall1.0000Actual Recall atPredicted 1.00 Recall0.8497%DB Searchedi14.65IAverage%DB Searched%Change in %DB Searchedfrom the Baseline6.45 -55.970.9032 7.99 -45.460.8605 7.38 -49.62Table 9: Recall Prediction, Routing100% recall level, but instead chose a recall level of81% across all queries.
This recall level was based onresults from the 18th month runs which showed that theaverage number of documents per query at the 81%recall level was 2000.
Given Stage Two estimates ofhow long it would take to run the CG Matcher, anacross-the-lx~ard 81% recall evel was selected.
However,an a priori selection based on average number ofdocuments, rather than adaptive selection based on therecall predictor is not appropriate, given the fact that henumber of documents which should be processed byStage Two is known to vary a great deal by query andthis number is predicted prior to Stage Two processing.RunADHOCDRwurlActual Recall atPredicted 0.81 Recalli i I0.8655Average %DB Passedto the 2nd Stage5.86Median #Docs Passedto the 2nd Stagei3,234ROUTING 0.6459 3.82 1,485DRsurlTable 10: Recall Prediction Statistics of Stage One at the 81% Recall LevelHowever, given Stage Two's selection of 81% as thedesired recall level, Table 10 shows that for the Adhocqueries, Stage One actually passed a full 86% of therelevant documents to Stage Two.
While for theRouting Queries, 65% of the relevant documents werecontained in the set selected by Stage Two.
The lowerperformance for routing again reflects the fact that theregression formula was trained on a different corpus.5.3 Interpretation of ResultsStage One of DR-LINK provided very reasonableresults, given that its function was not intendeed tobe astand-alone retrieval system, but was intended to be afilter for Stage Two, whose task was to improveprecision by adding a finer level of matching usingConceptual Graphs.
Given that, the precision achievedby Stage One based on the use of new and specializedtypes of linguistic evidence, is very promising.Additionally, it should be remembered that Stage Onefared poorly on those Topic Statements in which singlewords mattered (e.g.
cancer), since Stage One did nothave any means for explicit matching of single words.Development efforts since the TIPSTER 24 monthevaluation have greatly improved the performance ofStage One as a stand-alone r trieval system.A detailed analysis of the Topic Statements on which108Stage One performed well, using the TIPSTER-provideddata showing query by query average precision acrosssystems, has shed some light on where Stage One isexhibiting real achievement and promise.
Twelve of thetwenty-six Topic Statements on which Stage Oneperformed well, were ones in which Text Structurerepresentations were able to place relevant documentshigher in the rankings because the information beingsought needed to possess a particular discourse-levelattribute.
This means that not only did information onan entity, person, or event need to be contained in arelevant document, but the information needed to matchon another dimension or requirement.
This might be,for example, that an event was pending, in which casethe temporal relations encoded in the Text Structurerranked more highly those documents in which the eventwas mentioned in a FUTURE component of text.
Or,the Topic Statement might require information on theimpact or outcome of an event.
The Text Structurewould, in response, rank more highly those documentsin which the CONSEQUENCE or EXPECTATIONrelation was attached to the type of event sought.An additional twelve Topic Statements on which StageOne performed well, were ones in which a 'not' wasincluded in a subtle way.
The Natural Language QueryConstructor was able to interpret these logicalrequirements correctly in its construction of the querywhich was then matched against the inverted ocumentfile.Given the errors and the incomplete nature of thevarious system modules as explained in section 4, therelatively low precision values in the tables for StageTwo are not surprising.
Nonetheless, when the numbersare interpreted, there are factors that need to be takeninto account.
First, since Stage Two selected a Recalllevel of only 81% as its input from Stage Onematching, and only top 500, as opposed to 1000,documents were submitted as official runs, smallerportion of all relevant documents were included in theoutput.
In other words, an emphasis needs to be placedin precision of highly ranked documents rather thanrecall for the Stage Two.
The average precision over allrelevant documents and the exact R-precision are notnecessarily good indicators of any systems whose majorrole is to enhance precision for the top portion ofretrieved ocuments.Second, because of the differences in the documentdatabases, the number of topics (45 and 19), and thenumber of output documents submitted, the numbers inthe tables are meaningful only for the purpose ofcomparing different strategies within the same systemand thus are not to be compared with other systems'performances.
The Table 5 and 7 show that even withthe exacdy same representation a d retrieval methods,the results obtained from different databases and topicsare radically different.6.
Future WorkThere are two types of ongoing efforts to improve StageOne of DR-LINK.
One effort is to extend the symboliclevel of natural language processing developed uringPhase I of TIPSTER by such efforts as the extension ofthe subject code vector algorithm into the multi-lingualenvironment (Liddy et al 1993a); the development ofnew corpus analysis techniques for the expansion ofcomplex nominals into their synonymous phrasings,and; the automatic construction of proper nounknowledge bases over time and multiple texts, for thepurpose of cross-document i ferencing in response tocomplex queries requiring extensive relationalinformation (Paik, In press).The second effort actually constitutes a major paradigmshift in the type of NLP which is used in Stage One.We are exploring ways to exploit the large amount oflinguistically well-motivated, tagged text that iscurrently available for the various modules in the DR-LINK System as the necessary training data for thedevelopment of more adaptive techniques for NLP-basedinformation retrieval.
The research as commenced withan investigation i to whether the functioning of each ofthe five modules in Stage One can be achieved via eitherprobabilistic or neural-net linguistic processing.
Thedistinctive aspect of our proposed use of theprobabilistic approach is that it will use probabilitiesbased on multiple levels of linguistic features.For Stage Two, we have embarked on the work ofincreasing the number of relation ode matches and thusmaximizing the value of the representation.
We notonly need to correct he errors mentioned above but alsoneed to incorporate he following strategies: 1) mergingsentential conceptual graphs with the common conceptnodes, which will benefit from anaphora resolution; 2)clean-up and refinement of knowledge bases; 3)extraction of "high-level" relations from a sub-graph toreduce the complexity of the conceptual graphs.
Webelieve that he work to date provides a strong basis foraccomplishing the tasks.In addition to the works described in section 4, we arecurrently in the process of better understanding thesemantic restrictions in the topic statements and howthey can be translated into "high-level" relations.
There109are at least two major advantages: this effort will bothincrease the value of the current representation a dmatching methods and reduce the complexity of theconceptual graph representation a d hence matching.The second advantage is particularly important in that itwill allow us to run many experiments to evaluatevarious features of the system, which were not possiblein Phase I.In conclusion, we believe that DR-LINK, Phase I hasbeen a successful foray into the use of very richrepresentations of linguistic information for the retrievalof documents which match the requirements of querieson a wide range of the dimensions on which users' needscan be expressed.
The innovative use of ConceptualGraphs shows potential for addressing many difficultissues in information retrieval research.AcknowledgmentsWe would like to thank Ken McVearry and BobDelZoppo, the software ngineers from our subcontrac-tor, Coherent Research Inc., and the following graduatestudents who worked on the research and development ofDR-LINK: Margot Clark, Saleh Elmohamed, ChrisKhoo, Tracey Lemon, Ming Li, Slawomir Mar-chinkowski, Mary McKenna, Woojin Paik, Stone Shih,Joe Woelfel, Edmund Yu, and Ahsan Zia.ReferencesLiddy, E.D.
(In press).
Development and implementa-tion of a discourse model for newspaper texts.Proceedings of the Dagstuhl on Summarizing Text forIntelligent Communication.
Saarbruken, Germany.Liddy, E.D., Paik, W. & Woelfel, J.
(1992).
Use ofsubject field codes from a machine-readable dictionaryfor automatic lassification of documents.
Proceedingsof the 3rd ASIS Classification Workshop.
pp.
83-100.Liddy, E.D., Paik, W. & Yu, E.S.
(1993a).
ConceptualInterlingua for Document Reoresentation.
Proposalsubmitted to National Science Foundation.Liddy, E.D., Paik, W. & Yu, E.S.
(1993b).
Documentfiltering using semantic information from a machinereadable dictionary.
Proceedings of the ACL WorkshoDon Vgry Large Comora.Meteer, M., Schwartz, R. & Weischedel, R. (1991).POST: Using probabilities in language processing.Proceedings of the Twelfth International Conference onArtificial Intelligence.
Sydney, Australia.Myaeng, S. H. & Khoo, C. (1993).
On UncertaintyHandling in Plausible Reasoning with ConceptualGraphs In Conceptual Structures: Theory andImplementation.
H. D. Pfeiffer & T. E. Nagle,Springer-Verlag, 1993.
An earlier version appears in theproce~;lings of the 7th ConceDtual Graohs Workshop,Las Cruces, NM.Myaeng, S. H. & Liddy, E. D. (1993) InformationRetrieval with Semantic Representation f Texts.
InProceedings of Svmoosium on Document Analvsis andInformation Retrieval.
Las Vegas.Paik, W. (In press).
Chronological informationextraction system.
Proceedings of the Dagstuhl on$gmm0rizing Text for ~ntelligent Communication.Saarbruken, Germany.Shafer, G. (1976).
A Mathematical Theorv of Evidence.Princeton, N.J. : Princeton University Press.Sowa, J.
(1984).
Conceptual Structures: InformationProcessing in Mind and Machine.
Reading, MA :Addison-Wesley.110IV.
Published PapersLiddy, E.D.
(In press).
Development and implementa-tion of a discourse model for newspaper texts.Proceedings of the Dagstuhl on Summarizing Text forIntelligent Communication.
Saarbruken, Germany.Liddy, E.D.
(1993).
An alternative representation fordocuments and queries.
Proceedings ofthe 141h Nilti0nalOnline Meeting.Liddy, E.D., McVenrry, K., Paik, W., Yu, E.S.
&McKenna, M, (1993).
Development, implementation &Testing of a Discourse Model for Newspaper Texts.Proceedings of the ARPA Work~h0p on HgmanLanguage Te~hnol0gv, Princeton, NJ, March 21-24,1993.Liddy, E.D.
& Myaeng, S.H.
(In press).
DR-LINK: Asystem update for TREC-2.
Proceedings of SecondText Retrieval Conference (TRE~-2).
National Instituteof Standards and Technology.Liddy, E.D.
& Myaeng, S. H. (1993).
DR-LINK'slinguistic-conceptual approach to document detection.Proceedings of First Text Retrieval Conference (TRE(~-~.
National Institute of Standards and Technology.Liddy, E.D.
& Myaeng, S.H.
(1992).
DR-LINK ProjectDescription.
SIGIR Forgm.Fall '92 Symposium on Probabilistic At~Droaches toBoston.Liddy, E. D. & Paik, W. (1992).
Automatic recognitionof thematic roles and semantic relations in text usingthe maximum coincidence search technique.
InProceedings of Informatics 11 Conference.
University ofYork, England.Myaeng, S. H. & Khoo, C. (1993).
On uncertaintyhandling in plausible reasoning with conceptual graphs.In Conceotual Structures: Theory and Imolementation.H.
D. Pfeiffer & T. E. Nagle, Springer-Verlag, 1993.An earlier version appears in the Proceedings ofthe 7thConcentual Graphs Workshop, Las Cruces, NM.Myaeng, S. H., Khoo, C., & Li, M. (1993).
Linguisticprocessing of text for a large-scale conceptualinformation retrieval system.
Technical Report, Schoolof Information Studies.Myaeng, S.H.
& Liddy, E.D.
(1993).
Informationretrieval with semantic representation of texts.Proceedings of the Second Annual SymPosium onDocument Analysis and Information Retrieval.Myaeng, S. H. & Li, Ming (1992).
Building termclusters by acquiring lexicai semantics from a corpus.
InProceedings of the First International Conference inInformation and Knowledge Management.
Baltimore.Liddy, E.D., Paik, W. & Yu, E.S.
(1993).
Documentfiltering using semantic information from a machinereadable dictionary.
Proceedings of the ACL Workshopon Very Lame Comora.Liddy, E.D., Paik, W., Yu, E.S.
& McVearry, K.(1993).
An overview of DR-LINK and its approach todocument filtering.
Proceedings of the ARPAWorkshoo n Human Language Technology, Princeton,NJ, March 21-24, 1993.Liddy, E.D., Paik, W. & Woelfel, J.
(1992).
Use ofsubject field codes from a machine-readable dictionaryfor automatic lassification of documents.
Proceedingsof 3rd ASIS Classification Reselarch Workshop.Liddy, E.D.
& Paik, W. (1992).
Use of multipleknowledge sources for word sense disambiguation.
IProceedings of the 2nd Pacific Rim InternationalConference on Artificial Intelligence.
Seoul, Korea.Liddy, E.D.
& Paik, W. (1992).
Statistically-guidedword sense disambiguation.
In Proceedings of AAAIMyaeng, S. H. & Lopez-Lopez, A.
(1992).
Conceptualgraph matching: A flexible algorithm and experiments.Journal of Exoerimental and Theoretical ArtificialIntelligence.
Vol.
4, 107-126.
An earlier versionappears in Proceedings of 6th Annual Workshoo onConceptual Graphs.
July 11-13, 1991.Myaeng, S. H. (1992).
Using conceptual graphs forinformation retrieval: A framework for adequaterepresentation a d flexible inferencing, proceedings ofSvmnosium on Document Analvsis and InformationRetrieval.
Las Vegas.Paik, W. (In press).
Chronological informationextraction system.
Proceedings of the Dagstuhl onSummarizing Text for Intelligent Communication.Saarbruken, Germany.Paik, W., Liddy, E.D., Yu, E.S., McKenna, M. (1993).Interpreting proper nouns for information retrieval.Proceedings of the ARPA WQrkshQp on HumanLanguage Technology, Princeton, NJ, March 21-24,1993.111Paik, W., Liddy, E.D., Yu, E.S.
& McKenna, M.(1993).
Categorizing and standardizing proper nouns forefficient information retrieval, procgedings of the ACLWorkshoo n Acauisition of Lexical Knowledge from_T_~.112
