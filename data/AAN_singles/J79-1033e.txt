American Journal of Computational LinguisticsP R O C E E D I N G S1 3 T H  A N N U A L  f l ' E E T I N GASSOCIATION FOR COMPUTATIONAL LINGUI STI csTimothy C. D i l l e r ,  E d i t o rSperry-UnivacSt.
Paul, Minnesata 55101Microfiche 33Copyright @ 1975 by the Association for Computational LinguisticsPREFACEThe papers comprising th i s  microfiche (the second off ive)  present in expanded form (as submitted by theirauthors) the s i x  talks given in Session 2: Language Gene-ration Systems.
Various aspects of generation are consi-dered, among them: relat ionsHips  between parsing andgeneration (Knaus), planning modules and data structuresbasic to story development (Meehan) , semantic networks andlinguistic generatorq (Shapiro and Slocum), message struc-tures and translation strategies (McDonald) , and l ex ica lprocesses i n  compound noun formation (Rhyne).
Thanks toMartin K a y  for chairing this session.Timothy  C .
DillerProgram C o m m i t t e e  ChairmanTABLE OF CONTENTSA Rxtsbework for Writing Generation Grammars for Inter-active Computer Programs mvid Mcmnald .
.
.
.
.
.
.
.
.
4. .
.
.
.
.
Incremental Sentence Processing Rodger m u s  18A Lexical Process Model of Nominal Compounding in.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
English James R. Rhyne 33Generation as Parsing from a Network i n t o  a LinearString Stuar t  C. shepiro .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
45Speech Generation from Semantic Nets J~Adthdn S ~ O C W  .
.
63Using Planning Structures to Generate Stories ~ a m s  R.. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
Heehan 78American Jourdal of Computational tinguktics Microfiche 33 4Artificial Intelligence Ldbora t o r yMassachusetts Ins ti tute of TechnologyCambridge, Massachusetts 02139ABSTRACTThis paper outlines t h e  stucture and operation o f  the1 ingui s t i c  component from a language generation system in aninteractive program.
The component receives messagesdescribing what i s  to b e  s a i d  f o r m u l a t e d  in t h erepresentation of the main prograr and produces fluentEnglish utterances appropriate t o  t he  current discoursesituation.
T h e  component is data-directed and uses aprocedural grammar, organized as a set of strategies.Interactive, speclalist prograas presently under developwent willheed to produce fluent, intentional English utterances in responce toparticular, complex t i t u t l o n s .
This creates a requlroaont for languagegenerating facilities that I s  not faced in transformational grarapar,rochanical translation programs, or paraphrase generating programs.
Asa component of rn interactive, specialist program, the production of t h eEnglish must be driven direct lr  by the communicative intentions of theprogram and by the discourse situation,We can imagine tha t  the overall program consist,?
o f  a number ofcooperating modules - f o r  parsing and interpreting what i s  said t o  it,ior  solving ptoblens in its domain, for managing i t s  renary, and, i nparticular, f o r  generating u t t e rances  t o  c o m ~ u n i c a t e  w l  t h  Its users*This generation component can be p r o f i t a b l y  v iewed as having threeaspects or msub-corponentsw.1) Situation/doaain specie1 i s t s  t ha t  a r e  activated when  t h e  programrecognizes what situation it i s  in+ They then decide what messagewill be produced.
They will decide what effect  on the  listener isdesired, and exactly what objects  and relations a re  t o  be nentioned.F o t  example, an appoint~ent scheduling program might be told to*scm~ule a group meeting for  F r i d a y w  and then  find t h a t  a criticalaentber o f  the group i s  uncxvailable, The situation specialists int h e  scheduling prograr a re  t h e  ones t o  decide  whether i t  is moreappropriate t o  s i m p l y  say " 1  can'tR, O F  w h e t h e r  t o  v o l u n t c pinformation - w I  can't; Mitch won't be back u W l t  Mondayn.2) Models of the audience and t h e  discourse situation to use  i nconstruct2ng utterances.
There must be a r e c o r d  of t h e  p a s tconversation to gulcfe in the selection a f  p r o n o u n s ,  A l s o ,  theprogram must have nodels of, and heuristics about  what  the audiencea l r e a d y  knows  and t h e r e f o r e  doesn't have t o  be t o l d .
T h i sInformtion l a y  be very specific and domain dependent.
Fot  exarple,In chess, one can say "the white queen could take e knightn.
Thereis no need t o  say "a black k n l p h t w ,  because t h i s  information issupplied by inferences from what one knows about c h e s s  - inferencesthat the spcarer assures the listener shares.3) Llnpu!rtic know1 edge about how to construct understandable utterancesin the English Isnpuagc.
Obviously, t h i s  lnformatlon vill Include alexicon assoclatlng objects and relations from t h e  min program withrtrate&i@~ for realizing them in English (particular words, p h r a s e s ,syntactic constructions, etc.)
.
There is also a tremendous amountof informatian which describes the characteristics of the Englishlanguage and the conditions of  i t s  use.
It specif ies  rhe allowablearrangements of strategies and what niodlfications or alternatives t othem nay be appropriate in particular circumstances.Of the three aspects just described, my work has concentrated onthe th ird .
What follows i s  drawn from sy thesis McDonald ' 75 )  and fromongoing research.The Lingufetio ComponentThe 1 inguistic knowledge required for  generat ing utterances i s  putinto one component whose job i s  t o  take a message from the  sltuatlonspecialists and cpnstruct a t r a n s l a t l w  of  tha t  message In English.
Themessages are in the representation used by the main program and thes 1  tuation specialists.
Tho translation is done by a data-directedprocess wherein the elenents and structure o f  the message i t se l f  providethe control.The design of the 1 ingui stics component was arrived a t  independentof any particular main program, f o r  the  simple reason that  no programso f  adequate complexity were available a t  the time.
However, a t  thep r e s e n t  t i m e  a grammar and f c x l c o n  is being d e v e l o p e d  t o  use with a tl e a s t  two prograRs being developed by o t h e r  people  a t  MIT.
They are  ana p p o i n t m e n t  s c h e d u l i n g  program (Goldstein ' 7 5 )  and an advisor t o  a i dusers of MACSYMA (Genesereth '75).
The s h o r t  d i a l o g  below i s  an exampleof the  degree of f l u e n c y  we arc hop ing  t o  eventually achieve.
Thed l a l o g  ts between a scheduling prograa a c t i n g  as an appolntaentsecretary (P), and a s tudent  ( 5 ) .
(5) I want t o  see Professor Winston sometime in the  next few days.
(PI H e r s  p r e t t y  busy a l l  week.
Can i t  wai t?
(S) No, it can't, All  I need i s  h i s  signature on a f o r b(PI Well, maybe he can squeeze you in tommorrow ~ o r n l n g .
Give meyour name and check back in an hour.MessagesUsing the current message fo raa t  and Ignoring t h e  d e t a i l s  of theschedulerts representation, t h e  phrase "maybe he can squeeze you int o ~ m o r r o w ~  could have c o w  from a Pessage like t h i s  one, p u t  t o g e t h e r  byone of t h e  situation specialists.Message- 1 features.
( prediction )event (event actor ( W i n s t o n )action ( f i t  p e r s o n - i n t o  du l l  schedule>t h e  (31-10-75, gar-12am)hedge <fs possible)aim-at-audience hedgeMessages have features describing the  program's communicative intentions- what sort of ut te rance  is t h i s  t o  be; what effect i s  it t o  have.Messages l i s t  the  objects t o  be desert-bed (the r i g h t  hand column) alongwith annotations f o r  each object ( l e f t  hand co1u.n) to show how theyrelate t o  t h e  rest of the message.
The phrases on the r i g h t  in anglebrackets represent actual  s t r u c t u r e s  from t h e  schedu le r  wf t h  thoseThe LexiconTranslatl~n ftor tho  in te rna l  reprcscntai  ton o f  s coaputcr programt o  natural language has the  same sort  o f  p r o b l e w  as translating b e t w ~ e nt w o  natural languages.
T k  same concepts  nay not be a v a i l a b l e  asprim1 t i v o s  in both rcpresents.tions, and the conventions o f  t h e  targetIsnguape my require additional information t h a t  was not in the source.Generally speaking translation cannot be one for  one.What English phrase is best for a particular element in a program'smessage will depend on what i s  in t h e  r e s t  of the message and of whatthe external c o n t e x t  is.
In such circunstances, translation by table-lookup is inadequate.
In this component, in order t o  allow a l l  factorst o  be considered, t h e  t r a n s l a t i o n  o f  each  element ias d o n e  byindividualized procedures called wcorposersH.For  each main program t h a t  t h e  linguistic componen t  becomesassociated with, a lexicon must be created which will list the elementsof  the rain program's representation that  cou ld  appear in a message(1.
C. w p r C d l ~ t l ~ n H ,  " e v e n t w ,  w < W i n s t o n P ,  e t c .  )
.
With each element i srecorded the  composer tha t  will be run when the  time comes t o  produce enEnglish description f o r  it (examples will be given s h o r t l y ) .
Someconposers nay be applicable f o r  a whole c l a s s  o f  elements, such as"eventsw.
They would know the structure t h a t  a l l  events have in common(e .g .
actor, actlon, tine) and would know how t o  i n t e r p r e t  t h eidiosyncratic d e t a i l s  o f  each even t  by using data  in the lexiconassociated with them.The Grammar - strategiesThe bulk o f  the g r a u a r  con&ists of  "strategiesw.
Strategies arcassociated with particular languages ra ther  than w i t h  par t icular  mainprograas as composers are.
A g i v e n  s trategy  may be used f o r  severald i f f e r e n t  purposes.
A typical case i s  the strategy u s e - s , ?
m p ~ r e s e n t -tense: a clause in the simple present  ("prices risew) my be understoodas future,  cond'itlonal, or  timeless, according t o  what other phrases arcpresent,Each composer ray know of several  strategies, or  Coabinatlons ofstrategies which it could use in dcscrlbing an ele .cnt  f r o m  the message,It w i T 1  choose between the& according t o  the c o n t e x t  - usually d e t a i l so f  the element or syntactic constraints iaposed by previously selectedstrategies.
T h e  strategies themselves do no reasoning; t h e y  areimplemented as functions which the  corposers call to  do  a l l  the actualcorsst'ruction o f  the utterance.The Tr~nslat ion ProoesaA t  t h i s  p o i n t .
the out1 ine of  t h e  data-dr Iven translation processcan be su~rnriztd.
A message is glven f o r  t rans la t ion .
The  e l e ~ e n t s  ofthe  aessage are associated i n  a lexicon with procedures  t o  describethe..
The procedures a r e  run; they cal l  grs~latica1 strategies; andt h e  strategies construct the English utterance.Of course, i f  t h i s  were a l l  t h e r e  was t o  it, the process wouldnever run, betause a l l  of the  subprocesses aust be throughly  coordinatedi f  they are n o t  to " t r i p  over t h e i r  own fee t" ,  or ,  for t h a t  ~ a t t e r ,  i fordinary human beings are t o  bo able t o  design the..
In a system wherethe  knowledge o f  what to do i s  d i s t r i b u t e d  over a l a r g e  number ofseparate procedures, contro l  structure assumes central.
iaportance.PlansBefore d t ~ c r i b i n g  the control structure, I m u s t  l a y  o u t  someadditional aspects o f  the design of  t h e  ilngulstlcs coaponent.There i s  noi n t e r l i n g u a  or intermediate level of structure c o ~ p a r a b l c  to the dkepstructures  of Transformttlonal G r a ~ s a r ,  o r  the sewnt l c  n e t s  of S l ~ a o n s(73) or Goldban ( 7 4 ) .Detorminln~ t h e  appropriate sutface s t r u c t u r e ,  however, r equ iresp l a n n f n p ,  i f  f o r  no other reason than t h a t  the Message can o n l y  beexamined one piece ax a t h e .
The en t i r e  utterance must be organizedbefore a detailed analysis and translation can get underway.
As this isdone, the w p r o t o - u t t e r a n c e w  i s  r e p r e s e n t e d  i n  t e r n s  o f  a s o r t  ofscaffolding - a representatiqp of the ult imate surface structure treeinsofar as its deta i l s  are  known w i t h  e x t e n s i v e  annotation, explicit andimplicit, t o  p o i n t  out where elements that  are n o t  y e t  described may bepositioned, and t o  implement the  graamatical restrictions on possiblefuture details as dictated by what has already been done.The scaffolding t h a t  i s  constructed in the  translation o f  eachmessage i s  called i t s  w p 4 a 0 w .
Plans are made up o f  syntactic nodes ofthe usual s o r t  - clauses ,  noun groups, e t c ,  - and nodes may havefeatures in t h e  Banner of  tysteni; grammar Winograd ' 7 2 ~  Nodes havesubplans c o n s i s t i n g  o f  a l i s t  of named slots marking the possiblepotftlons f o r  sub-constituents, given in t h e  order ~f t h o  eventualsurface structure.
Possible slots would be wsubJectw,  *.%in verbw,"noun headw, wpre-verb-adverbw, and so on.
The syntactic node t y p e swill each have a nuaber of -possible plans,  corresponding" t o  t h ed i f f erent  possible arrangements or sub-consti tuents that may occur wl t ht h o  d i f f e r e n t  combinat ions  o f  f e a t u r e s  t h a t  tho  Mdc may have,Depending on t h o  r t a g e  o f  t h e  translation process ,  a s l o t  may bc" f l 1 l o d w  with a pointer t o  an lnternal o b j e c t  fro .
the message, asyntactic node, a word or idior, a r  noth ing .The translation proaaeaTho translation i s  done i n  two phases.
The second phase does n o tbegin until the f i r s t  i s  coapletely finished.
During the f i r s t  phase, ap l a n  is se lected and t h e  eleaents of  t h e  message are transferred,l a r g e l y  untouched; t o  the  s l o t s  of the plan and features added t o  i t snodes.
During the second phase, the plan is wwalktdR topdown and froml e f t  t o  r i g h t .
Conpostrs f o r  mssage e l e ~ e h t s  in t h e  plan's s l o t s  areactivated t o  produce English descriptions f o r  the  elcments as t h e y  arereached in turn .
B o t h  processes a r e  data-directed, t h e  f i r s t  by t h eparticular conten ts  of  the message and t h e  second by the  structure o fthe p l a n  and t h e  contents o f  i t s  s lo t s .There are  sound linguistic reasons f o r  t h i s  two stage processing.Most parts of a lessage Bay be translated in terms of very modularsysltactic and lexical  units.
But o t h e r  p a r t s  a r e  translated in  terms o frelations between such units, expressed usually by ordering or clause-level  syntactic aechanislps.
The exact f o r @  o f  t h e  s ~ a l l e r  units cannotbe deternlned until their larger scale  relations have been fixed.Accordingly, t h e  objective of the  f i r s t  phase is t o  determine w h a tglobal relationships are required and t o  choose the p l a n ,  features, andpositions of message elemnts within the plan's s lots  tha t  will realfztthose relationships.
Once this has been done, Engl tsh descriptions forthe elements can be made Independent of each o the r  and will not need t obe changed af ter  they  arc i n i t i a l l y  created.One o f  the l o s t  i apor tan t  features o f  n a t u r a l  language is theability t o  omit,  prono~inal i z e ,  or otherwise abbreviate elements incertain contexts.
T h e  o n l y  known r u l e s  and hllristlcs for  using thisfeature r r o  phrased in terms of Surface structure configurations andtemporal ordering.
Because t he  second ~ h a s e  works d i r e c t l y  in thcseterms,  s t a t i n g  a n d  u s i n g  t h e  available heuristics becoaos as t ra igh t?
orwsrd, tractable problem.
"Maybe h e  can eg.ueeze you in tommoww morning"The  rest of this paper will try to put solae f lesh on your pictureof how this linguistics conponent works by following the translation oft h e  message given in the beginning t o  the sentence above.
The messagewas this.Massage- 1 features* ( prediction )event (event actor <Winston>action.
t f i t  person into full schedule)time <31-10-75,9aar-l2rm>)h-@biie <is possible,aim-at-audience hedgeThe intentional features  of a message tend t o  require the n o s t  globalrepresentation in the f Inal utterance, because that i s  where indicatorsfor questions, special emphasis, speclal formats lee n. conpari son), andthe  like w i l l  be found.
By convention then.
the composers associatedwl th  the intentions are given the job of arranging for the dispositionof a l l  o f  the  messake elements.
T h e  to ta l  aperatlon of phase oneconsists of  executing the composer associated with each feature,  oneaf  $er the other.Thls aessage has only one feature, so i t s  composer will assume a l )tho work.
Thc linguistics component is implemented in MACLISP, features(and annotations and s l o t s  and nodes) are atoms, and coar>Qsers assfunctions on t h e i r  property l i s t s .Predictioncomposer-with (lambda ... )Making a prediction is a speech act, an& wo nay expect there t o  beparticular forms in a language for expressing thee, for  example, the usea f  t h e  explicit "willw for the future tense.
Knowledge o f  these wouldDe part o f  the  composer.
Inside the  aain program, or the  situationspecial l s t ,  the concept o f  a prediction may always inc lude  certainparts: what is predicted, the time, any hedges, and so on.
These partare d i r e c t l y  re f l ec ted  in thc makeup of the elements present in themessage, and t h e i r  annotations mark what internal r o l e s  t h e 7  have.There does no t  need to be a direc t  correspondence between these and t h eparts in the l inguistic forms used, the  actual correspondence i s  pa r t  ofthe knowledge of the prediction cosposer.Typically, f o r  any feature,  one particular annotated e l e ~ e n t  willbe of greatest l ~ p o r t a n c e  in seting the cha rac t e r  of t h e  wholeutterance.
For predictions, this is t h e  "eventw.
T h e  predictioncomposer chooses a plan f o r  the utterance t o  f i t  the requireaents of theevent-element.
The realization of any other  elements will be restrictedt o  be compatible w i t h  i t .T h e  prediction composer docs not need to know t h e  element'slinguistic correlates i t s e l f ,  i t  can delegate the work to the composerfor the  element i t s e l f .
The element look l ike this,(event actor <Winston>action < f i t  person i n t o  f u l l  schedule>tine t31-10-75,9am-lZaa>)The first word points to the name of the composer, and the p a i r s  g i v eparticular details.
There i s  nothing special about the words used here(actor, action, tlme), Just a$ long as t h e  composer is designed toexpect the inforwatton in those places that the message-asseabler wantsto put  it.
The event composerfs strategy is to use a clause, and t h echoice of plan is determined by the character o f  the event's "actionw.The action is " < f i t  person into full schedulerw, and i t  will havetwo relevant properties in the  lexicon: "plan*, and ".appingW.
klan ise i ther  the nane of  a standard p l a n  t o  be used; or an actual p l a n ,partially f i l l e d  w i t h  words (1. e. i t  can be a phrase).
"Mappingw is anassociation l i s t  showing how t h e  subelements of the message are t o  betransferred t o  the plan.< f i t  person i n t o  f u l l  schedule)PLANnode-i (clause trans1 particle)slots frontings n i lsubject nilvg node-j (verb-group particle)slots modal nilpre-vb-adv n i lmvb "squeezewp r t  "inwobject1 <person being talked about)post-modifiers nilMAPP I NG((  actor subject )( time post-modifiers))The event composer proceeds t o  instanticte the nodes i n  the  phrase andmake the transfers; the prediction composer then takes the resultingplan,  and makes i t  the plan of  the whole utterance.Two message elements remain, b u t  actually there is o n l y  one,because waim-at-audiancew is supplying additional informati~n about thehedge.
T h e  annotation means t h a t  the c o n t e n t s  o f  t h e  hedge (<ispossible>) ere pore something tha t  we want to tell the audience than adetail o f  the prediction.
This will a f f e c t  how the element ispositioned in the plan.The  p r e d i c t i o n  composer l o o k s  in t h e  lexicon t o  s e e  whatgrammatical unit will be used t o  realize <is possible, ,  and sees, l e t  ussay, two possibilities involving di f f eren t  configurations of the adverbwn&ybcn and t h e  modal "can be able ton,  with the differences hingingon the placement of  the adverb.
Theoretically, a d v e r b s  can bep o s i t i o n e d  i n  a nunber o f  places  in a clause, depending on t h e i rcharacteristics.
In this instance, the choice is forced because of aheuristic written i n t o  the grammar of adverbs and accessible t o  t h ecomposer, that says tha t  when the intent of an adverb is directed t o  theaudience, i t  should be in t h e  f i r s t  position ( t h e  "frontiogsW s l o t ) .This choice implies p u t t i n g  "canw I n  t h e  modal s l o t  d i r e c t l y .
T h ealternative with w ~ y b e *  i n  the pre-vb-adv s l o t  would have necessitateda different form of the .o8al, yielding " r a y  be able t o n ,  These detailswould have been taken care of by syntactic routines associated with t heverb group node.A 1 1  the message ererents have been placed and t h e  f i r s t  phase isover.
The p l a n  is now as below.n4e - l  (clause trans1 particle)slats fmntfngs "8aybeWsubject twinston>vg node-2 (verb-group par t ic1 elslots modal "canwpre-vb-adv n i lmvb "squeezenp r t  " inwobject1 cperson being talked about )post-modifiers n i lThe second phase controller is a simple dispaching function t h a t  m v e sfrom s l o t  t o  slot.
"Fronttngs* contains a word, so t h e  word is printed.directly (there is a trap f o r  morphological adjustnents when necessary).wSttbjectw contains an in te rna l  object, so the controller should go tothe lexicon for  its composer and then come back t o  handle whatever t h ecomposer replaced the clement with,However, there is always an l h t e r v e n i n g  step t o  check for t h epossibility of pronominalizing.
This check is made with the elelpents t i l l  in i t s  internal  foro .
T h e  record  o f  t h e  discourse i s  g i v e nd i r e c t l y  in t e r m  o f  the i n t e rna l  representation and test f o r  p r i o ruccurence can be as simple as identity checks against a reference list,svoiding potentially intricate string matching operations w i t h  words.In the d i a l o g  tha t  th i s  message came from, there  is clear  reference tot w i n 9 t o n > ,  so it can be prononinallzed and "hew is printed.Any slot, or any node t y p e  may have procedures associated with i tthat are executed when the slot or node is reached during t h e  secondphase.
These procedures will handle syntac t ic  processes like agreement,rearangelaent o f  s l o t s  t o  rea l i ze  features, add function words, watchscope relationships, and in particular, position the particle in verb-part ic le  pairs.Generally,  p a r t i c l e  position ("squeeze John i n n  vs. n ~ q ~ m e  inJ o h n w )  is n o t  specifled by the grammar - except when the object i s  apronoun and the particle - must be displaced.
This, of course, will notbe known untlll a f t e r  the verb group has been passed.
To deal withthis, a subroutine in the "when-ent$redn procedure of  t h e  verb group i sactivated by the "par t i c len  procedure.
First, i t  records the particleand relaoves  it f r o m  t h e  V G  p l a n  s o  it will not be g e n e r a t e dautomatically.
A "hookw i s  available on any slot for a,procedure whichcan be run after prononinalization is checked and before the composer i scalled ( i f  i t  is t o  be c a l l e d ) .
The subroutine incorporates thepart ic le  i n t o  a standard procedure and places i t  on t h a t  hook for t h eobject1 s l o t .
The procedure will check i f  the  object has been prlntedas a pronoun, and i f  so, p r i n t s  o u t  the par t i c l e  (which i s  now I n  theproper displaced pori  tion).
If  the ob jec t  wasn' t pronominal ized,  thenit does nothing, nothing has ye t  been printed beyond the verb group, andother heuristics will be free t o  a p p l y  t o  choose the proper position.Since (person  being t a l k e d  about, is here equal to the student, t h eperson t h e  prograa is talking with, i t  i s  realized as the pronoun "youwand the  particle is dlsplaccd.Going irom <31-10-75,9a~-12arn> t o  w t o m ~ r r ~ ~  ~ o r n i n g *  my be littlemore t h a n  table lookup by a wtfme" coBposer that hat been designed toknow the formats of the time expressions inside the  scheduler .This presentation has had t o  be unfor tuna te ly  s h o r t  for the amountof new naterial involved.
A large n u ~ b e r  of interesting detail s a n dquestions about t h e  processing have had t o  be oritted.
A t  t h e  moaent<September, 19751, the data and control structures ~cntioned have beenfully iep1e~ented and t e s t s  are underway on gedanken data.
Hopefully,by the end of 1975 the component will have a reasonable g r a m a r  and willbe working with messages and lexicons form the t w o  programs mentionedbefore.
A MI7 A. I. l a b  technical r e p o r t  describing this work i n  d e p t hshould be ready in the spring o f  n e x t  year.David McDonaldCambridge, Mass.References cited in the text:Genesereth, M. (1975) A MACSYMA Advisor.
Project MAC, MIT, Cambr ldge ,Mass,Goldman, N. (1974) "Computer Generation of Natural Language fro.
a DeepConceptual Basee.
memo AIM-247, Stanford Art l f  l c i a l  I n t e l  l igenccLab., Stanford,  Calif,Goldstein, 1.
(1975) "Barganing Between Goalsw.
i h  the proceedings n fIJCAI-4, available from the MIT A I  l a b ,McDonald, D. (1975) The Design o f  a Program f o r  Generating p a t ~ .
~ ~Language.
unpubl ished Master's Thesl s, MIT D e p t .
of El ectlcslEngi neerf ng.Simmons, R. (1973) wSeaantic Networks: T h c l r  Computation and Use f o rUnderstanding E n g l i s h  Sentences" .
I n  S c h a n k  a n d  ~ o l b y  eds.Computer Models of Thought and Language.Winograd, T. (1972) Understanding Natural Language.
Academic Press, NewYork, NY.American Journal of Computational Linguistics Microfiche 33 : 2 8RODGER KNAUSSystems  of t w a r e  D i v i s i o nS o c i a l  and  E c o n o m i c  S t a t i s t i c s  AdministrationB u r e a u  of the C e n s u sW a s h i n g t o n ,  D. C .
20233A human who l e a r n s  a language  can b o t h  p a r s e  a n d  g e n e r a t es en t ences  i n  t h e  l a n g u a g e .
I n  c o n t r a s t  m o s t  a r t i f i c i a l  l a n -guage p r o c e s s o r s  o p e r a t e  i n  o n e  d i r e c t i o n  on ly  o r  requtres e p a r a t e  grammars  f o r  pa r s ing  and g e n e r a t i o n .
T h i s  paperd e s c r i b e s  a model f o r  human language p roces s ing  w h i c h  u s e sa s i n g l e  l a n g u a g e  d e s c r i p t i o n  f o r  pa r s ing  and g e n e r a t i o n .1 .
Choice o f  P a r s i n g  StrategyA number o f  c o n s t r a i n t s  l i m i t  t he  p r o c e s s o r s  s u i t a b l e  a sm o d e l s  o f  h u m a n  l a n g u a g e  p r o c e s s i n g .
Because s h o r t  termmemory i s  l i m i t e d .
t h e  l i s t e n e r  must a b s o r b  i n c o m i n g  w o r d si n t o  l a r g e r  chunks a s  t h e  s e n t e n c e  i s  heard .
A l s o  b e c a u s ehe  i s  e x p e c t e d  t o  r e p l y  w i t h i n  a c o u p l e  seconds a f t e r  t h es p e a k e r  f i n i s h e s ,  r e g a r d l e s s  o f  l eng th  o f  t h e  s p e a k e r ' su t t e r a n c e ,  t h e  l i s t e n e r  m u s t  do  much o f  t h e  s e m a n t i c  p r o c -e s s f n g  o f  a s e n t e n c e  a s  h e  h e a r s  i t .1 9Bever a n d  H a t t  p o i n t  o u t  t h a t  t h e  d i f f i c u l t y  i n  u n d e r -s t a n d i n g  a s e n t e n c e  S i s  n o t  p r e d i c t e d  by t h e  n u m b e r  o ft r a n s f o r m a t i o n s  u s e d  t o  g e n e r a t e  S .
F u r t h e r m o r e  t h e  p r o c e s so f  d e t r a n s f o r r n a t i o n  a p p e a r s  t o o  t ime-consuming  ( p e t r i c k )  f o rt h e  a p p r o x i m a t e l y  two s e c o n d s  b e f o r e  a l i s t e a e r  i s  e x p e c t e dt o  r e p l y .A d e p t h  f i r s t  t r a n s i t i o n  ne twork  p a r s e r  (Woods, ~ a p l a n ) ,i n  w h i c h  p a r s i n g  d i f f i c u l t y  i s  m e a s u r e d  by t h e  n u m b e r  o f  a r c st r a v e r s e d ,  c o r r e c t l y  p r e d i c t s  t he  r e l a t i v e  d i  f f i c u l  t y  o fa c t i v e  a n d  p a s s i v e  s e n t e n c e s  p r o g r e s s i v e  and  a d j e c t i v a l  p r e s e n tp a r t i c i p l e  s e n t e n c e s  a n d  t h e  e x t r e m e  d i f f i c u l t y  o f  m u l t i p l ecenter embeddings .
However  a s y n t a c t i c a l l y  d i r e c t e d  d e p t hf i r s t  p a r s e r  does  n o t  e x p l a i n  why s y n t a c t i c a l l y  s i m i l a rsentences s u c h  a s( 5 A )  The  h o r s e  s o l d  a t  t h e  f a i r  e s c a p e d .
( 5 % )  The horse r aced  p a s t  t h e  barn f e l l .v a r y  i n  d i f f i c u l t y ,  n o r  does  i t  e x p l a i n  e x p e r i m e n t s  o n  t h ec o m p l e t i o n  a n d  v e r i f t c a t i o n  o f  ambiguous  s e n t e n c e s  (MacKay,Olsen and MacKay) w h i c h  s u g g e s t  t h a t  a p r u n e d  b r e a d t h  f i r s ts t r a t e g y  i s  used t o  par ce s e n t e n c e s .
S e n t e n c e s  w i t h  t w oequal l y  p l a u s i b l e  a1 t e r n a t i v e s  t o o k  l o n g e r  t o  p r o c e s s  t h a ns e n t e n c e s  w i t h  o n l y  one  l i k e l y  i n t e r p r e t a t i o n .
T h i s  e x t r ap r o c e s s i n g  t i m e  may b e  a t t r i b u t e d  t o  t h e  c o n s t r u c t i o n  o f  t w oa l t e r n a t e  i n t e r p r e t a t i o n s  o v e r  a 1 o n g e ~  p o r t i o n  o f  t h e  s e n t e n c ewhen more t h a n  one i n t e r p r e t a t i o n  i s  p l a u s i b l e .I n  a d d i t i o n  s u b j e c t s  s o m e t ~ m e s  become c o n f u s e d  by t h e  t w oi n t e r p r e t a t i o n s  o f  a n  a m b i g u o u s  s e n t e n c e .
F i n a l l y  i n  e x p e r i -m e n t s  i n  which s u b j e c t s  h e a r  a n  a m b i g u o u s  s e n t e n c e  i n  o d e  e a ra n d  a d i s f r n b i g u a t i n g  s e n t e n c e  s i m u l t a n e o u s l y  i n  t h e  o t h e r  e a r( G a r r e t t )  t h e  i n t e r p r e t a t i o n  a f  t h e  a m b i g u i t y  a c t u a l l y  p e r -c e l v e d  by t h e  s u b j e c t  may be s w i t c h e d  b e t w e e n  t h e  p o s s i b i l i t i e sby c h a n g i n g  t h e  d i s a m b i g u a t i n g  s e n t e n c e s .S t e p  3 ( a ) :  ( S  N P  ( N  mail) ( N  B o x e s ) )[ V  l i k e )  (.NP) (PP*))(b): ( S  (NP ( N P  ( N  mall) ( N  B o x e s ) )( P P  ( P R E P  l i k e )  NP') (PP*))V ( N P )  f p p * ) )  ( c ) :  ( S  ( N P  ( N  m a i l ) )  ( V  Boxes)I P P  ( P R E P  l i k e )  N P )  ( P P * ) )  (d): (S V m ail) (NP ( N  B o x e s ) )( P P  ( P R E P  like) N P )  (PP*))( e ) :  ( S  ( V  m a i l )( N P  ( N P  ( N  B o x e s ) )( P P  ( P R E P  l i k e )  N P )  ( P P * ) )( p p *  1)A f t e r  completing t h e  sen tence  a f t e r  S t e p  4, t h e  parserproduces phrase markers from a, c ,  d a n d  e by a d d i n g  t h e  l a s tword a n d  de l e t ing  unfilled optional n o d e s .
T h e  phrase markerobtained f r o m  48 i s  re jec ted  because i t  c o n t a i n s  an unfilledobligatory V n o d e .The incremental parser a d d s  e a c h  successive s e n t e n c e  wordto t h e  partially completed phrase markers b u i l t  from the e a r l i e rp a r t  o f  t h e  s e n t e n c e .
The new word i s  added a t  t h e  l e f t m o s t  obligu n f i l l e d  node o f  each partial p h r a s e  marker a n d  a t  all optionalnodes t o  t h e  l e f t  o f  t h i s  node .T h r e e  d i f f e r e n t  operations a r e  used to a d d  a new word toa p a r t i a l  parse .
The word m a y  be d i r e c t l y  a d d e d  t o  an  unexpandednode ,  as i n  S t e p  3a a b o v e .
A1 ternatively, a new word may bea t t a c h e d  t o  a n  u n f i l l e d  n o d e  w i t h  a l e f t  b r a n c h i n g  a c y c l i c  treeb u i l t  from the  g r a m m a r  s u c h  a s  (PP P R E P  N P )  or ( S  ( N P  N, IN*)) V( N P )  ( P P * ) ) .
A t t a c h i n g  o c c u r s  i n  s t e p s  1 a n d  3c .Final ly  a subtrbe o f  a n  e x i s t i n g  p a r t i a l  phrase markermay be  4 e f t  embedded i n  a larger structure o f  t h e  same gram-m a t j c a l  c a t e g o r y ,  a s  i n  s teps  3b a n d  3e a b o v e .
T h e  e m b e d d i n go p e r a t i o n  u s e s  a t  most t w o  left b r a n c h i n g  trees bui1 t f r o m  thegr'ammar: a t ree  TI w i t h  a s i n g l e  cycle on t h e  l e f t  branch i sused t o  r e p l a c e  t h e  e x i s t i n g  subtree E b e i n g  embedded.
I ns tep 3e ,  f o r  e x a m p l e ,  the  s tructure  ( S  ( V  m a i l )  ( N P  N P  ( P P * ) )( P P * ) )  would be o b t a i n e d .
The E i s  u s e d  to expand  t h e  l e f t -most u n e x p a n d e d  node o f  TI: for  3 b t h i s  r e s u l t s  i n :3 e .
(S ( V  m a i l )  (NP ( N P  ( N  B o x e s )  (N*)) P P * )  ( P P * ) ) .Finally t o  t h e  r e s u l t i n g  structure t h e  new sentence word i sa d d e d  t h r o u g h  d i r e c t  node e x p a n s i o n  o r  a t t a c h i n g  wi th  anacyclic l e f t  b r a n c h i n g  tree ;  i n  t h e  example a b o v e  t h i s  p r o d u c e s3e f r o m  3el'U s i n g  d i r e c t  e x p a n s t o n  a t t a c h i n g  a n d  e m b e d d i n g ,  t h eincremental parser f i n d s  a1  1 t h e  phrase markers o f  s e n t e n c e sf n  c o n t e x t  f r e e  o r  r e g u l a r  e x p r e s s i o n  l a n g u a g e ;  a formald e f i n i t i o n  o f  t h e  parser a n d  a p r o o f  o f  i t s  correctness a p p e a rin [ l o ] .Sometlmes, a s  a t  s t e p s  3b and  3e,  t h e  same s truc ture  ( aprepos i t i obna l  phrase i n  s t e p  2) i s  used i n  more t h a n  o n e  p a r t i a lparse.
Following Earley's Algo'rithm, the  incremental parserb u i l d s  a s i n g l e  copy o f  t h e  s h a r e d  substructure Sf!!
a n d  m a i n t a i n sp o f n t e r s  l f n k i n g  Sb t o  n o d e s  i n  l a r g e r  s t ruc tures  w h i c h  $9expands .Far a l l  i t s  t r e e  b u i l d i n g  o p e r a t i o n s  the  incremental parseruses a flnlte s e t  o f  t r e e s .
e .
,  t h e  t r e e s  w i t h  o n l y  l e f t  sub -nodes  expanded and a t  most onelcycle on t h e  l e f t m o s t  b r a n c h .These trees may b e  computed djrectly from the grammar and  r e f -erenced by root and  leftmost unexpanded  node  d u r i n g  t h e  p a r s e .Using t h e s e  p r e c o n s t r u c t e d  t r e e s ,  t h e  incrementa l  parser requireso n l y  a f i x e d  number o f  o p e r a t i o n s  t o  a d d  a new word t o  a p a r t i a lpa r se :  a r e t r i e v a l  o n  a d o u b l y  indexed s e t ,  copying t h e  l e f tb ranching  t r e e ,  and a t  most four s t ruc tu re  c h a n g i n g  o p e r a t i o n s+o p a s t e  words a n d  t r e e s  t o g e t h e r .L i k e  E a r l e y ' s  Algor i thm,  IP p r o c e s s e s  each word p r o p o r t i o n -a l l y  t o  s e n t e n c e  l e n g t h .
However on s e n t e n c e s  s a t i s f y i n g  a depthd i f f e r e n c e  bound, t h e  p a r s i n g  time per word i s  c o n s t a n t .
Becausehumans c a n ' t  remember large numbers of  s e n t e n c e  w o r d s  b u t  must,process speech a t  an a p p r o x i m a t e l y  c o n s t a n t  r a t e ,  a c o n s t a n tp a r s i n g  t ime  per  ward i s  a n e c e s s a r y  p r o p e r t y  o f  a n y  a l g o r i t h mmodel i n g  human language  p r o c e s s i n g .Let t h e  depth  o f  c o n s t i t u e n t  C i n  p h r a s e  marker P bed e f i n e d  a s  t h e  l e n g t h  o f  t h e  p a t h  from t h e  r o o t  o f  C t o  t h e  r o o tof P .
I f  TI and T 2  a r e  tuo a d j a c e n t  t e r m i n a l s  w i t h  T I  precedingT 2 .
t h e  depth d i f f e r e n c e  f rom 11 t o  T2  i s  d e f i n e d  as t h e  d i f -f e r e n c e  i n  d e p t h  between 1 1  a n d  the  r o o t  ~f t h e  s m a l l e s t  t r e ec o n t a i n i n g  TI and T2.
For  e x a r n ~ l e  i n  t h e  phrase marker(9) ( S  ( N P  NP ( D E T  t h e )  ( N  t e l e p h o n e ) )[ P P  ( P R E P  I N )  (F(P ( D E T  t h e )  ( N  room)) )( V  r a n g )  ( A D V  l o u d l y ) )t h e  dep th  d i f f e r e n c e  between " t h e "  a n d  " te lephone" '  i s  1 andbe tween  "roam" and " rang"  i s  3 .The  d e p t h  d i f f e r e n c e  be tween  11 and T 2  i s  t h e  number o fnodes f r o m  T I  t o  t h e  node expanded when adding T 2  on a p o s t o r d e rt r a v e r s a l  from T I  i n  t h e  p a r t i a l  phrase  marker c o n t a i n i n g  T I  b u tn o t  T 2 .
The d e p t h  d i f f e r e n c e  between T I  and T2 a l s o  r e p r e s e n t st h e  number of  c o n s t i t u e n t s  o f  which T I  i s  t h e  r i g h t m o s t  w a r d .A proof ( requ ir ing  a forma.1 def in i  t i o n  o f  t h e  i ncrementalparse)  t h a t  p a r s i n g  time per word i s  c o n s t a n t  i n  d e p t h  d i f f e r e n c ebounded sentences  appears i n  [ l o ] .
Informally the  depth d i f -ference  b o u n d  p l a c e s  a b o u n d  b o t h  o n  t h e  n u m b e r  o f  n e x t  nodes t oexpand which may follow a g i v e n  terminal a n d  o n  t h e  a m o u n t  o ft r e e  traversal  w h i c h  t h e  parser must perform t o  f f n d  e a c h  nextu n e x p a n d e d  node.
Sfnce each m o d i f i c a t i o n  requires  only a fi'xednumber o f  operati-ons,, e a c h  o f  w h i c h  i s  b o u n d e d  on the  f i n i t e  s e to f  a t  most once c y c l i c  l e f t  branching t r e e s ,  t h e  c o m p u t a t i o na d d i n g  a new word t o  e x i s t i n g  p a r t i a l  p a r s e s  i s  bounded i n d ep e n d e n t l y  o f  s e n t e n c e  l e n g t h .N a t u r a l  l a n g u a g e  sentences tend t o  h a v e  small d e p t h  d i f -f e r e n c e s .
B o t h  r i g h t  branching sentences and l e f t  b r a n c h i n gsentences ( f o u n d  i n  Japanese  f o r  e x a m p l e )  h a v e  a n  a v e r a g e  d e p t hd i f f e r e n c e  o v e r  e a c h  three or four word s e g m e n t  o f  two or l e s s .On t h e  o the r  hand  sentences are d i f f i c u l t  t o  u n d e r s t a n d  whenthey have two  c o n s e c u t i v e  large d e p t h  d i f f e r e n c e s ,  such a s  t h emu1 t i  ple  center e m b e d d i n g( 1 0 )  The rat  the  cat t h e  d o g  b i t  chased d i e d bor t h e  complex n o u n  p h r a s e  i nThe p a d  o n  a c l a r f n e t  i n  t h e  l a s t  row whicn 1f i x e d  e a r l i e r  far E b  fe7l o u t .Furthermore i n  amhlguous sentences such as(11)  Joe figured t h a t  it was t i m e  t o  t a k e  t h e  c a t  out.Kimball o b s e r v e s  t h a t  s u b j e c t s  pr i f er  t h e  r e a d i n g  w i t h  t h esmaller depth  difference.
Flnally, Blumenthal found t h a t  s u b j e c t stended t o  understand a m u l t f p l e  c e n t e r  embedded s e n t e n c e  a s  aconjunct1 ve sen tence .
The con junc t ive  sentence ~ o n t a i n s  a r e -arrangement.
w i t h  lower depth differences o f  t h e  c o n s t i t u e n t s  o ft h e  c e n t e r  embedded sen tence .3 .
Sentence GenerationThe syntactic f o r m  g i v e n  to a sentence  depends on t h e  i n f o r -m a t i o n  being communicated i n  a sentence and on t h e  c u l t u r a l  con-t e x t  i n  w h i c h  t h e  sentence  appears .
C l a r k  a n d  Haviland show t h a ta speaker  uses va r ious  syntactic devices  sentences  t o  p lace  t h e" g i v e n "  informatian known t o  t h e  l i s t e n e r  be fore  t h e  informat ion"new" t o  t he  l i s t e n e r .
Particular s y n t a c t i c  s t r u c t u r e s  a r e  a l s oused t o  emphasize o r  suppress  p a r t i c u l a r  k i n d s  o f  informat ion;f o r  example newspaper t r a f f i c  a c c i d e n t  r e p o r t s  u s u a l l y  b e g i nw i t h  a pass ive  sentence  such a s( 1 2 )  An e l d e r l y  Lakewood man was i n ju red  when.. .
,presumably t o  e m p h a s i z e  the r e s u l t  o f  theaccident.To c a p t u r e  t h e  dependence o f  syntax on semantic con ten t  a n db o c j a l  c o n t e x t ,  t h e  sentence  gene ra to r  uses f u n c t i o n - l i k e  grammarrules o f  t h e  form( R u l  erame C a t  Variables Predicate Forms ) .Rulename i s  t h e  name o f  t h e  rule  a n d  c a t  i s  t h e  grammatiealca tegory  of t h e  c o n s t i t u e n t  generated by t h e  rul e mVariables  i s  a l i s t  o f  formal parameters .
Usually t h ev a r i a b l e  l i s t  c o n t a i n s  a v a r f a b l e  b o u n d  d u r i n g  r u l e  execut iont o  a n o d e  i n  a semantic network and ano ther  v a r i a b l e  b o u n d  t oa c o n t r o l  a s s o c i a t i o n  l i s t  con ta in ing  i n f o r m a t i o n  about t h e  con-t e x t  i n  which  t h e  generated c o n s t i t u e n t  w i l l  a p p e a r  and poss ib lyt h e  s y n t a c t i c  form t h e  c o n s t i t u e n t  s h o u l d  h a v e .P r e d i c a t e  i s  a B o o l e a n - v a l u e d  f o r m  on the parameters i nV a r i a b l e s .
A rule i s  u s e d  only when P r e d i c a t e  i s  true .Forms i s  a l i s t  o f  forms d e p e n d i n g  on Variables  w h i c hgenerate terminals or calls t o  t h e  grammar f o r  s u b c o n s t i t u e r i t so f  C A T .An example  o f  a g e n e r a t i o n  r u l e  i s(SPI SI (X  Y )  ( E q u a l  ( V o i c e  Y )  (Quote P a s s i v e ) )( N P  ( O b j e c t  X )  Y )t B e v e r b  X )  Pap ( A c t i o n  X ) )(M* X Y ) )w h i c h  generates simple p a s s i v e  s e n t e n c e s .
The v a r i a b l e  X i sbound t o  a node i n  a semant ic  n e t w o r k  and Y t o  a c o n t r o la s s o c i a t i o n  l i s t .
The rule i s  a p p l i e d  only i f  t h e  controla l i s t  contains a p a s s f v e  f l a g  and i f  t h e  s e m a n t i c  node h a s  ano b j e c t  a n d  a c t i o n ;  i n  general  a r u l e  i s  a p p l i e d  only i f  t h es e m a n t i c  subnodes called i n  t h e  r u l e  body appear in thesemantic net .
The form ( N P  ( O b j  X )  Y )  generates a f o r m  ( N PX I  fl), where X B  i s  the semantic node on the object i n d i c a t o rfrom X .
a n d  Yj3  f s  t h e  v a l u e  o f  Y .
Beverb a n d  P a p  are procedureswhich generate r e s p e c t i v e l y  a form ~f t h e  verb " t o  be" a n d  ap a s t  part i c fp le  f o r m  o f  the verb A c t i o n ( X ) .
M *  i s  a procedurewhich generates a l i s t  d e p e n d i n g  on X a n d  Y such a s  ( P P ~ V a l u eo f  T l m e ( X ) >  < V a l u e  o f  Y > )  for  generating optional p r e p o s i t i ~ n a lphrases or  r e l a t f  v c  c l a u s e s .A S  each r u l e  i s  applied,  the l i s t  o f  terminals  a n d  c a l l s  t ogrammar rules  generated by t h e  rule  i s  a d d e d  t o  a phrase m a r k e rrepresenting the s t r u c t u r e  o f  the s e n t e n c e  b e i n g  generated.Grammar c a l l s  i n  t h e  phrase marker a r e  expanded t o p  d o w n - a n dl e f t  t o  r i g h t ,  i n  a p reo rde r  t r a v e r s a l  of t h e  g r o w i n g  phrasemarker.
As t e rmina l s  a r e  generated t h e y  a r e  p r in ted  o u t .As a n  e x a m p l e ,  i l l u s t r a t i n g  t h e  e f f e c t  of semantic ands o c i a l  c o n t e s t  on sentence genera t ion ,  an i n i t i a l  sentence O Fa t r a f f i c  acc iden t  r e p o r t ,(13).
A  man was k i l l e d  when a ca r  h i t  h i m  i n  I r v i n e .was generated from the  semantic nodesAl: Agent Afl A 2 :  Agent A @ :  ClassmanO b j e c t  v0 Action h i tAction Kil l  Object VJI)Place  I r v i n e  Instrument CarCause A Za n d  t h e  con t ro l  a l i s t .Purpose: 1n t roduc t ion ;cases :  o b j e c t ,  cause,  p laceusing a grammar b u i l t  f o r  genera t ing  t r a f f i c  acc iden t  r epor tsen tences .
To summarize a t r a c e  of the  genera t ion ,  a c a l l  t ot he  sentence r u l e  w i t h  p u r p o s e  = in t roduc t ion  genera tes  a sentencec a l l  w i t h  voice  = pass ive .
The passive r u l e  app l i e s  and a  n o u nphrase on Afl i s  c a l l e d  for .
Because Purpose In t roduct ion  aN P  r u l e  a p p l i e s  which c a l l s  f o r  a NP t o  be  generated on thesemantic c l a s s  t o  which A 8  belongs.
Because CASES conta insT I M E  a n d  C A U S E ,  t h e  passive r u l e  generated c a l l s  f a r  m o d i f y i n gs t r u c t u r e s  of t he se  C A S E S .
Because t h e  cause semantic node A 2has an a c t i o n ,  t h e  modif ier  r u l e  M = >  Rela t ive  conjunct ion Sgenera tes  the  c a u s e  while t h e  time i s  descr ibed by a preposi-t l o n a l  phrase.
The pronoun "him" i s  generated by a noun p h r a s erule.
NP-1 which genera tes  a pronoun when t h e  f i rs t  semanticargument  t o  t h e  l e f t  o f  t h e  N P - 1  c a l l  i n  t h e  genera t ion  phrasemarker w h i c h  i s  d e s c r i b e d  by t h e  same pronoun a s  t h e  s e m a n t i cargument A o f  NF-1 i s  i n  f a c t  equa l  t o  A .4 .
F i n d i n g  Semantic PreimagesW h i l e  t h e  generator described in sec t ion  3 produces sentencesfrom semantic a n d  contextual  informat ion,  the  incremental pa r se rdescribed i n  sec t i on  2 recovers  merely t h e  s y n t a c t i c  s t r u c t u r eo f  a sentence.
To obta in  t h e  semantic arguments from which asentence m i g h t  have been generated a procedure t o  I n v e r t  t h egenerat ion r u l e  forms must be a d d e d  t o  t h e  incremented parser .While t h e  incremental pa r se r  begins t h e  cons t ruc t ion  o f  con-s t i t u e n t s  top  down, i t  completes them s y n t a c t i c a l l y  i n  a bottomup d i r e c t i o n .
In f a c t  IP executes pos torder  t r a v e r s a l s  o n  a l lt h e  s y n t a c t i c  parse  t r e e s  i t  b u i l d s ;  o f  course i f  a p a r t i c u l a rp a r t i a l  phrase  m a r k e r  can n o t  be f i n i s h e d ,  t h e  t r a v e r s a l  i s  n o tcompleted.
However each node n o t  a tree  terminal o f  a s y n t a c t i cphrase  marker v i s i t e d  by t h e  incrementa l  p a r s e r  i s  a  s y n t a c t i c a l l ycomplete c o n s t i t u e n t .When the parser v i s i t s  a s y n t a c t i c a l l y  complete  c o n s t i t u e n tC ,  i t  a p p l i e s  a func t ion  INVERT t o  f i n d  t h e  semantic preimageso f  C .
I n  f i n d i n g  t h e  semantic s t r u c t u r e  o f  C ,  INVERT h a s  a v a i l -a b l e  n o t  only the s y n t a c t i c  s t r u c t u r e  o f  C ,  b u t  a l s o  t h e  s e m a n t i cpreimages w h i c h  i t  found f o r  subconstituents o f  C. 'INVERT f i n d st h e  s e t  o f  generat ion rules  w h i c h  might  proruce a c o n s t i t u e n th a v i n g  the same s y n t a c t i c  f o r m  a s  C .
F o r  each such rule R.,I N V E R T  c o n s t r u c t s  a l l  t h e  p o s s i b l e  par ings  between e a c h  o u t p u t -g e n e r a t i n g  form F of R and t h e  c o n s t i t u e n t s  of C which F mightproduce .
For  e x a m p l e  i f  C i s( S  ( N P  Man) (Beverb i s )  ( P A P  I n j u r e d ) )t h e  p a i r i n g  e s t a b l i s h e d  f o r  t h e  p a s s i v e  s e n t e n c e  r u l e  would  b e( N P  ( O b j e c t  X )  Y )  ( N P  t h e  m a n )(Beverb X )  (Beverb i s )( p a p  (Act ion  X ) )  ( P a p  I n j u r e d )( M *  X Y )  N I LThe p a i r  ( (Equa l  (Voice Y )  PASSIVE) 1) i s  a l s o  c r e a t e d ,  s i n c et h e  r u l e  p r e d i c a t e  i s  t r u e  whenever a r u l e  a p p l i e s .Each i n d i c i d u a l  p a i r  P i n  s-uch a p a i r i n g  of a ru le  form andr u l e  form o u t p u t s  i s  p r o c e s s e d  by a f u n c t i o n  FIND which r e t u r n san a s s o c i a t i o n  l i s t  c o n t a i n i n g  p o s s i b l e  v a l u e s  o f  t h e  r u l epa rame te r s  ( X  and Y i n  t h e  example a b o v e )  w h i c h  w o u l d  producet h e  o u t p u t  a p p e a r i n g  i n  P .
For  t h e  example above F I N D  wouldp r o d u c e( X ( ( O b j e c t  Man) Y NIL)) ( 1  x ( ( r i m e  p a s t )  Y NIL))( (  X N I L )  ( Y  ( (  Cases N i l ) ) ) ) .
( (  X NIL)  ( Y  ( (  Voice P a s s i v e ) ) ) )Using an e x t e n s i o n  t o  a s s o c i a t i o n  l i s t s  o f  t h e  computa t ionall o g i c  U n i f i c a t i o n  Algor i thm,  t h e s e  a s s o c i a t i o n  l i s t s  a r e  u n i f i e di n t o  a s i n g l e  a s s o c i a t i o n  l i s t ,  which f o r  t h e  example i s( (  X ( ( A g e n t  man) (Time P a s t )  (Act ion  I n j u r e ) )( (  Y ( ( C a s e s  N i l )  ( V o i c e  P a s s i v e ) ) ) )Finally I N V E R T  creates a grammar r u l e  c a l l ,( S  ( (Agen t  man)(Time P a s t ) ( A c t i o n  I n j u r e ) )( ( C a s e s  N i l ) ( V o i c e  P a s s i v e ) ) ) )f r o m  t h e  a s s o c i a t i o n  l i s t  and  s t o r e s  t h e  r e s u l t  i n  t h e  i n v e r s eimage o f  C .I n  f i n d i n g  a s e m a n t i c  preimaqe, t h e  I N V E R T  f u n c t i o n  mustknow w h i c h  grammar r u l e s  m i g h t  produce a p a r t i  c u l  a r  g r a m m a t i  calc o n s t f  t u e n t .
T h i s  information i s  computed by symbol ical ly e v a l -u a t i n g  t h e  grammar r u l e s  t o  produce  t h e  strings o f  r e g u l a re x p r e s s i o n  grammar ncnterminals ( a s  opposed to g r a m m a r  calls)representing t h e  p o s s i b l e  o u t p u t  o f  e a c h  rule.
T h e  resultingr e l a t i o n  from rules t o  s t r i n g s  is i n v e r t e d  into a t a b l e  g i v i n gp o s s i b l e  rules g e n e r a t i n g  e a c h  string.The h e a r t  of t h i s  s y m b o l i c  e v a l u a t o r  i s  a  f u n c t i o n  E T E R M  ont h e  o u t p u t  g e n e r a t i n g  forms o f  a r u l e  w h i c h  r e t u r n s  a l i s t  a l llists o f  regular e x p r e s s i o n  nonterminals representing the out-p u t  o f  a f o r m .
E T E R M  t a k e s  a d v a n t a g e  o f  t h e  s i m i l a r  s y n t a x  o fmost grammar rule forms, a n d  is d e f i n e d  i n  s i m p l i f i e d  f o r m( w i t h  comments i n  a n g l e  b r a c k e t s )  a sEterm ( f o r m )  =i f  a t o m  (form) t h e n  N I L<terminates recurs i o n >else i f  car ( f o r m )  i s  a g r a m m a t i c a l  c a t e g o r ythen l i s t  (Ifst ( c a r  ( f o r m ) ) )< t h e s e  f o r m s  generate  a s i n g l e  grammar c a l l >e l s a  i f  c a r  ( f o r m )  = F U N C T I O N  ar L A M B D At h e n  E T E R M  ( c a d r  ( f o r m ) )e l s e  i f  car  ( f o r m )  = L A M B D Athen ETERM ( c a d d r  ( f o r m ) )else i f  c a r  ( f o r m )  = L l S Ti f  form i s  n o t  properly contained i n  a L I S Te x p r e s s i o nthen Mapcar((Function Concatenate)(Cartesian( (Mapcar  (Function E T E R M )c d r  ( f o r m ) )  ) )< o u t e r  L I S T S  a r e  used t o  c r e a t e  lists o f  g r a m m a r  c a l l s >e l s e  i f  farm I s  i n s i d e  e L I S T  e x p r e s s i o nE T E R M  ( c a d r  ( f o r m ) )< i n n e r  l i s t s  are u s e d  t o  c r e a t e  g r a m m a t i c a l l y >e l s e  if c a r  ( f o r m )  = M A P C O N C  t h e n  m a k e  o p t i o n a la n d  r e p e a t a b l e  a l l  t h e  n o n t e r r n i n a l s  r e t u r n e din E T E R M  ([function a r g u m e n t  of MAPCONC])e l s e  i f  car  ( f o r m )  = CONDt h e n  MAPCONC((LAMBDA(X) ETERH ( [ l a s t  f o r m  i n  X I )( c d r  f o r m )< r e t u r n s  a l t e r n a t i v e s  f r o m  each b r a n c h  o f  t h e  COND>e l s e  i f  car ( f o r m )  i s  a u s e r - d e f i n e d  f u n c t i o nt h e n  ETERM ( [ d e f i n i t i o n  o f  f u n c t i o n ] )e l s e  i f  t h e r e  i s  a s t o r e d  v a l u e  f o r  ETERM ( f o r m )t h e n  t h a t  v a l u ee l s e  a s k  t h e  t h e  u s e r  f o r  h e l pThe f u n c t i o n  FIND w h i c h  r e t u r n s  p o s s i b l e  b i n d i n g s  f o r  r u l ev a r i a b l e s  when g i v e n  a r u l e  f o r m  and  i t s  o u t p u t  i s  d e f i n e d  below.The v a r i a b l e  AL1,ST h o l d s  t h e  v a l u e  o f  t h e  a s s o c i a t i o n  l i s t  b e i n gh y p o t h e s i z e d  by FIND; t h i s  v a r i a b l e  i s  N I L  when FIND i s  c a l l e df r o m  I N V E R T .L i k e  ETERM, t h e  d e f i n i t i o n  o f  F I N D  i s  b a s e d  on  t h e  r u l e sf o r  e v a l u a t i n g  r e c u r s i v e  f u n c t i o n s .F I N D  ( A l i s t  f o r m  v a l u e ) =i f  e v a l  ( f o r m  a1  f s t ) = v a l  ue t h e n  l i s t  (A1  i s t )e l s e  i f  r e c u r s i o n  d e p t h  exceeded,  t h e n  N I Le l s e  i f  a tom ( f o r m )  t h e n  l i s t  (Merge  ( l i s t  ( c o n s( f o r m  V a l u e ) )  A l i s t )e l s e  i f  c a r  ( f o r m ) =  CONDl e t  L = c l a u s e s  w h i c h  m i g h t  b e  e n t e r e d  bye v a l u a t i n g  f o r mt h e n  Mapconc (FM 1 )  w h e r eFM ( c l a u s e )  = l i s t  (Merge  F i n d  ( A l i s t  Car  ( c 1 a u s e ) T )F i n d  ( A l i s t  l a s t  ( c l a u s e ) ) )e l s e  i f  c a r  ( f o r m )  = Q u o t e  t h e n  i f  c a d r  ( f o r m )  = v a l u et h e n  A l i s t  e l s e  N I Le l s e  i f  c a r  ( f o r m )  i s  a d e f i n e d  f u n c t i o nt h e n  FIND ( A l i s t  ( S u b s t i t u t e  c d r  ( f o r m )  f o rf o r m a l  p a r a m e t e r s  i n  d e f i n i t i o no f  c a r  ( f o r m ) )V a l u e )e l s e  i f  c a r  ( f o r m )  = MAPCONC ( f n  1 s t )t h e n  Me'rge ( F i n d  ( A l i s t  1 s t  v a l u e )F o r  each  X i n  1st.
M e r g e  ( A l i s t  for X ) )< t h i s  c l a u s e  makes t h e  a s s u m p t i o n ,  w h i c h  w o r k s  i np r a c t i c e ,  t h a t  f n  g e n e r a t e s  e i t h e r  o n e - e l e m e n to r  emp ty  l i s t s ,e l s e  N I LWith  a d e f i n i t i o n  o f  F I N D  s i m i l a r  t o  t h e  one a b o v e ,  t h eparser f o u n d  t h e  p r e i m a g e( 3  ( ( ( p l a c e  ( ( c l a s s  ( p a r k ) ) ) )  ( a g e n t  ([class ( m a n ) ) ) )( a c t i o n  ( w a l k e d ][ t h e  e x t r a  p a r e n t h e s e s  d e n 3 t e  l i s t s  o f  a l t e r n a t i v e s ]  f o r  t h es e n t e n c e( 1 3 )  T h e  man w a l k e d  i n  t h e  p a r k .g e n e r a t e d  b y  t h e  grammar[Sp S ( X )  T ( N P  (Agent  X ) )  ( V ( A c t i o n  X ) )( O p t i o n a l  ( P P  ( P l a c e  X )  ( ( C a s e  P l a c e ][ N P f l  NP ( X )  T ( D e t  X )  t N ( C l a s s  X I[ p p a  PP ( X Y )  T ( P r e p  X Y )  ( N P X ]and  t h e  p r e p o s i t i o n  f u n c t i o nP r e p  ( X Y )  = S e l e c t q  ( A s s o c  CASE Y )( P l a c e  I N )(Instrument W I T H )( S o u r c e  FROM]5.
Imp1  e m e n t a t i o nThe p r o c e s s o r s  d e s c r i b e d  i n  t h i s  p a p e r  h a v e  been programmedi n  U n i v e r s i t y  o f  C a l i f o r n i a ,  I r v i n e ,  L I S P  and r u n  i n  a b o u t  4 5 K  ona PDP-10 computer.R e f e r e n c e sB e v e r ,  Thomas G .
1970.
I n  ?
7 1  a n d  [ 5 ] .C l a r k ,  H e r b e r t  H .
and H a v i l a n d ,  Susan E .
1 9 7 5  S o c i a l  S c i e n c e sWorking P a p e r ,  67.
U.C.
I r v i n e .-C o l b y ,    en jam in W .
1973 .
A m e r i c a n  A n t h r o p o l o g i s t  7 5 ,  6 4 5 - 6 2 .F l o r r e s  d ' A r c a i o  and  L e v a l t ,  e d s .
1970  A d v a n c e s  i n  Psycholin-g u i s t i c s ,  N o r t h  H o l l a n d ,  Amsterdam.G a r r e t t ,  M e r r i l l ,  F .
1970 .
i n  [ 5 ] .Haynes,  J o h n  R .
1970 .
C o g n i t i o n  -- a n d  t h e  D e v e l o p m e n t  - o f Lanquage .John W f l e y .Kap lan ,  ~ o n a l d  M. 1972.
A .
I .
3, 77 -100Kimball, J o h n  1974.
C o g n f t i o n  2,1,15-47.Knaus, Rodge r .
1975 .
Ph.D T h e s i s .
U .
C .
I r v i n e .MacKay, D o n a l d  G. 1966.
P e r c e p t i o n  a n d  P s y c h o p h y s i c s .
4 2 6 - 3 6 .O l s o n ,  James N. and  MacKay ,  D o n a l d  G.  J V L V B  1 3 ,  45770 .P e t r i c k ,  S. R. I n  [ 1 4 ] .R u s t i n ,  R a n d a l l .
1973 .
N a t u r a l  Lanquage  process in^.W a t t ,  Wm.
1970.
I n  [ 7 ]woods,  w 1973.
I "  [iil.American Journal of Computational Linguistics Microfiche 33 : 33D e p a r t m e n t  of Computer S c i e n c eU n i v e r s i t y  of H o u s t o nHouston, T e x a s  7 7 0 0 4ABSTRACTA theoretical model for nominal compound formation in Englishis presented in which the rul-es are representations of lexicalprocesses.
It is argued that such rules can be genera l i zed  toaccount f o r  many nominal compounds with similar structure andto enable new compounds to be produced and understood.
It isshown that nominal compounding depends crucially on the existenceof a llcharacteristic'' r e l a t i o n s h i p  between a nominal and t h evexb which occurs in a relative clause paraphrase of a compoundwhich contains the nominal.
A computer implementation of themodel is presented and the problems of binding and rule selectiona r e  discussed.Linguistic Issues.Nominal compounds are sequences of two or more nominalswhich have the semantic effect of noun phrases with attachedrelative clauses.
The rightmost nominal is general ly  i he primaryreferent of t h e  compound the other nominals restrict thereference of the rightmost nominal i n  much the same fashion t h a ta relative clause does.
Tbeae are, of course, exceptions inwhich t h e  rightmost nominal i s  figurative or euphemistic(e.g.
family jewels).
Compounds occur frequently in English andGermanic languages, but infrequently in the Romance languageswhere their function is largely performed by nominal-preposition-nominal sequences (e. g. chemin de fer , agent de change) ._ _ C  -The s y n t a c t  kc s t r u c t u r e  nominal compounds is quite simple--the three variants are NAN, N-participle-N, and N-gerund-N.In the N-N form, either 0% the two nominals may in fact be yetanother nominal compound, giving a structure like (N-N)-N orN-(N-N); the f irst  of these forms seems to occur much more oftenthan the second (examples of each t y p e  are: typewriter  mechanic,liquid roach poison).I assume that the  process of nominal compounding is syntac-tically a process in which a relat ive  clause is reduced by delet-ing all elements of the  relative c l a u s e  but one and preposing t h esingle remaining element i n  front  of the  antecedent nominal.
Inaddition, the clause verb may be nominalized 4nd preposed.
Otherlinguists have proposed different derivations for nominalcompounds; Lees [ 3 ] ,  for example, derives nominal compounds fromnominal-preposition-nominal sequences.
There are two reasons whyI feel that Lees approach i s  wrong: (1) there are Englishcompounds for which no reasonable equivalent nominal-prepos it ion-nominal paraphrase can be given (e.g.
windmill), and (2) thereare subtle meaning differences between t h e  nominal compounds andtheir nominal-preposition-nominal counterparts (county clerk vs.clerk for the county).
I f  nominal compounds and nominal---preposition-nominal sequences are derived from forms l i k erelative clauses, then the differences in meaning can be accountedf o r  by deriving each form from a d i s t i n c t  r e l a t i v e  c l a u s e ;  t h erelative clauses may, of c o u r s e ,  be quite c l o s e l y  r e l a t e d  t oeach other.I have spoken r a t h e r  l o o s e l y  about  d e r i v i n g  nominal compoundsfrom r e l a t i v e  c l a u s e s ;  I am n o t  proposing a d e r i v a t i o n  systemwhich operates on s u r f a c e  forms of t h e  language,  and what Ii n t e n d  t h a t  t h e  reader should  unders tand is that an unde r ly ingform f o r  a nominal compound is de r ived  from an  unde r ly ing  formf o r  a r e l a t i v e  clause by a language p rocess  which I term al e x i c a l  rule because,  a s  we s h a l l  see, t h e  o p e r a t i o n  of suchru les  depends c r u c i a l l y  on the specific lexical items which arep r e s e n t  i n  the underlying s t r u c t u r e s .
Linguists have i d e n t i f i e da number of lexical processes in English; some examples of suchp rocesses  may be found in [I] and [ 2 ] .The unde r ly ing  forms a s s o c i a t e d  w i t h  r e l a t i ve  clauves andnominal compounds in t h e  model of nominal c om pounding beingpresented here a r e  networks (trees f o r  t h e  most p a r t )  definedin terms of a c a s e  grammar which is c l o s e l y  r e l a t e d  t o  t h a tused by S imon8 [ 51.
The cases which appear  i n  t h i s  system f a l li n t o  two general c a t e g o r i e s :  (1) cases of t h e  c l a u s e  verb,  whicha r e  the fo l lowing  -- Performer,  Object, Goal, Source,  Locat ion,Means, Cause, and Enabler  -- and (2) s t r u c t u r a l  c a s e s ,  which a r eR E E L  ( r e l a t i v e  c l a u s e )  and COMP (compound).
I w i l l  not  e x p l a i nthese c a s e s  i n  d e t a i l ,  a s  t h a t  is t h e  s u b j e c t  of a forthcomingpaper .
But the fo l lowing  o b s e r v a t i o n s  w i l l  i l l u m i n a t e  the casesystem f o r  verb  cases.
The c a s e  s y s t e m  d i s t i n g u i s h e s  t h eimmediate performer of a n  act from a remote cause or  agent ofthe act.
The reason for this distinction l i e s  in an i n t i m a t econnect ion between verbs and the assumed o r  h a b i t u a l  performerof t h e  act  which i s  t h e  reference of the verb.
The case systemalso distinguishes an a c t i v e  causative agent of an act  froma n  agen t  which mere ly  permi t s  t h k  a c t  t o  o c c u r ;  t h i s  d i s t i n c t i o ni n  the case system permi t s  two classes of ve rbs  t o  be distinguishedaccord ing  Po whether t h e  surface subject commonly causes  t h e  ac to r  permits t h e  ac t  to  occur .The case s y s t e m  used i n  the present model o f  nominalcampounding is not a deep case system; on the contrary, it Seemsthat  nominal compounding is a lexical process which occursrather near t h e  surface i n  a d e r i v a t i d n a l  grammar model.
Anexample which can be given t o  support t h i s  is t h e  compoundignition - key;  t h i s  is a key Vhich turns  a s w i t c h  which enablesa complex sequence o f  events to  take place t h a t  u l t i m a t e l y  re su l ti n  the i g n i t i o n  of a fuel/air mixture i n  an eng ine ,  ar one maydescribe it equ ivaaent ly  a s  a key which causes  i g n i t i o n .
Thef irst  a e s c r i p t i o n  corresponds to a deep c a s e  l e v e l  of d e s c r i p t i o nw h i l e  the  second corresponds to  t h e  l e v e l  a t  which the compoundi g n i t i o n  key  is formed.
I would argue tHat if one takes thedeep case approach, then one is forced  t o  inc lude  a great d e a lof structure i n  the r u l e s  for nominal compounding; i n  particular,t h e  rule for  i g n i t i o n  - key must remove all af t h e  l i n k s  i n  t h ecausal chain l e a d i n g  to  the i g n i t i o n  a c t .
The d e l e t i o n  of thisin termediate  information mast be done to o b t a i n  the d e s c r i p t i o ngiven in t h e  second case, and t o  inc lude  the d e l e t i o n  procedurei n  both a  compounding ru le  and in the rule process which leadsto  the shorter description means u n n e c e s s a r i l y  duplicating t h eprocedure.
Moreover, i f  one d e r i v e s  compounds from paradigmre lat ive  clauses of the second sort ,  e .
g .
key which causes ana c t i o n  to  occur, then it is possible to  generalize compoundforming rules so that a siqgle rule may produce severalcompounds.
I t  will not  be p o s s i b l e  to  do  this if deep cases areused a s  t h e  deep c a s e  structure o f  f i r i n g  key w i l l  be quite-d i f f e r e n t  from that  of i g n i t i o n  key.In order  t b  understand t h e  model of compounding whfch isbeing presented here, it is essent ia l  t o  cons ider  the f u n c t i o nof wmpounding in language.
I n  my v i e w ,  compounding is a p r o c e s swhich allows a speaker to  systematic8lly deLete i n fo rma t ion  froman utterance just when the speaker has reason to expect that thehearer can reconstruct that information.
I n  effect ,  I c o n s i d e rcompounding (and a great many other linguistic procesbes) ro beexamples of linguistic encoding which are used t o  speed  upcommunication, and t h e  grammar sha red  by t h e  speake r  and h e a r e rmust i n c l u d e  t h e  encodihg and decoding f u n c t i o n s .Consider  t h e  nominal compound steam d i s t i l l a t i o n ,  whichr e f e r s  t o  t h e  d i s t i l l a t i o n  of  same subs tance  w i t h  s team; t h eh e a r e r  o f  t h e  compound steam d i s t i l l a t i o n  knows t h a t  d i s t i l l a t i o nis t h e  d e r i v e d  nominal form of  d i s t i l l .
The hearep  a l s o  knowswhat t h e  common o r  c h a r a c t e r i s t i c  c a s e s  of the verb  d i s t i l l  a r e :t h e  agen t  is i n v a r i a b l y  a person o r  machine ( t h i s  would be t h eoccupant of  t h e  Cause case s l o t  i n  my s y s t e m ) ,  t h e  ins t rument(or Means) may be an a p p a r a t u s  or  a heated medium such a s  steamand t h e  Goal is a l i q u i d  which is miss ing  some of  t h e  c o n s t i t u e n t sthat it e n t e r e d  t h e  d i s t i l l a t i o n  process  w i t h .I t  happens t h a t  i n  Eng l i sh ,  whenever a, de r ived  nominal of a na c t  i s  the r i g h t  element i n  a compound, then  t h e  l e f t  element isalmbst always an  occupant of  one of  t h e  c a s e  s l o t s  o f  t h e  verb.I n  o r d e r  t o  r e c r e a t e  the under ly ing  r e l a t i v e  c l a u s e  s t r u c t u r e ,  i tis o n l y  necessa ry  for t h e  h e a r e r  t o  p r o p e r l y  choose t h e  case f o rt h e  nominal steam.
A g r e a t  d e a l  of l e x i c a l  in format ion  can bebrought t o  b e a r  on t h i s  q u e s t i o n ;  for  example, steam i s  not  al i q u i d ,  is water  vapor and t h u s  cannotsubs t ance  o r  t h e  end product  o f  a d i s t i l l a t i o n  process .
Steammight b e  t h e  Cause of t h e  a c t  o f  d i s t i l l a t i o n  except  t h a t  theredo no t  seem t o  be any compounds i n  Engl i sh  which have d i s t i l l a t i o na s  t h e  r i g h t  element and a Cause a s  t h e  l e f t  e lement .
Thus theh e a r e r  can a s s i g n  s team t o  t h e  Means c a s e  w i t h  some assurance .-I n  ano the r  example, shrimp b o a t ,  t h e  h e a r e r  can a s c e r t a i nby l e x i c a l  r e l a t i o n s  invo lv ing  t h e  word boa t ,  t h a t  boa t s  arec h a r a c t e r i s t i c a l l y  used t o  c a t c h  marine l i f e .
One choice  eor t h emain verb  i n  a synonymous r e l a t i v e  c l a u s e  is c a t c h ,  which w i l lhave boa t  a s  an  element of t h e  Means c a s e .
The Cause f o r  c a t c his commonly a person or perhaps a s o p h i s t i c a t e d  machine designedt o  o a t c h  t h i n g s  ( i .
e .
a t r a p ) .
The O b j e c t - i s  c h a r a c t e r i s t i c a l l ya n  animal .
There is a s t r o n g  c h a r a c t e r i s t i c  r e l a t i o n  betweent h e  animal  being caught and t h e  means used t o  catch i t ,  for examplemink is t r apped ,  calves are roped,  b i r d s  a r e  n e t t e d ,  and f i s h  a r ecaught w i t h  a boa t .
Th is  r e l a t i o n  e x i s t s  a s  a r u l e  i n  t h e  lbxfconof both t h e  speaker and the hearer and i t  enables t h e  speaker t oproduce the  nominal compound and the  hearer t o  understand i t .Furthermore, shrimp - boat is one member of a c l a s s  ofc lose ly  r e l a t e d  nominal compounds whioh includes l o b s t e r  - boat,whale boat tuna boat and many others .
I t  would be most- -'in teres t ing  i f  a s i n g l e  rule  could be formulated which wouldgenerate a l l  of these  cqpounds .
A l o b s t e r  boat is a boatwhich is used t o  catch l o b s t e r ,  a tuna boat is a  boat which isused t o  catch tuna, and so forth.
A l l  of these  examples a r ei d e n t i c a l  except f o r  t h e  p a r t i c u l a r  marine animal being caught.The l o g i c a l  next s t e p  is the  c r ea t i on  of a r u l e  which generalizesthe  individual marine anfmals t o  the cbmmon category of m a r i n eanimal.
Th is  r u l e  f i l l  state that a marine animal boat is a boatwhich is used t o  ca tch  marine animals,I n  making t h i s  genera l iza t ion ,  I have given t h e  rule thepower t o  help i n t e r p r e t  novel compounds and t o  generate them.With t h i s  power comes a d i f f i c u l t y ,  Which is const ra in ing therule so  t h a t  it does not generate bad compounds o r  produceincorrect i n t e rp r e t a t i ons .
The k e y  t o  t h i s  constra'int l i esi n  what I w i l l  term t h e  c h a r a c t e r i s t i c  o r  hab i tua l  aspect ofnominal compomds.
I n  the case of the boat compounds, a  boatwill only be a shrimp boat i f  it is c h a r a c t e r i s t i c a l l y ,  usua l ly ,hab i tua l ly  o r  invarfably used t o  ca tch  shrimp.
So the operat ionof a compounding rule is enabled only i f  a  c h a r a c t e r i s t i c  aspectis associa ted  with t he  verb; i n  English,  this is usua l ly  indicatedb y  a n  adverb o r  an adverbial phrase.
If the speaker is wi l l ingt o  a s s e r t  that a  boat is c h a r a c t e r i s t i c a l l y  used t o  catch t u r t l e s ,then the nominal compound t u r t l e  boat may be used.
The hearersill use the general r u l e  t o  place t u r t l e  and boat i n  the propercase slots, and because a compound was used b y  the  speaker, thehearer w i l l  i n f e r  Qhat the boat is one which  is c h a r a c t e r i s t i c a l l yused to catch t u r t l e s ,There are other  problems which arise with the genera l iza t ionof rules; for  example, compounding never produces a compound i nwhich the l e r t  element is a proper noun, unless the proper nounie t h e  name of a process (e.g.
Harkov process) or  is a Source,Performer, o r  Goal of an a c t  of g iv ing.
It a l s o  seems t o  be t r u et h a t  compounds are not genera l ly  formed when a l e x i c a l  i t e m  isseveral levels  below t h e  general term which appears i n  the r u l e(e.g.
r e p a i m i d g e t )  o r  when a c r o s s - c l a s s i f i c a t o r y  term is used(e.g.
automobile Indian  as an Indian who r e p a i r s  automobiles).With all of the preceding discussion in mind, I would now like t ot u r n  t o  the model of nominal compounding which I have p resen t lyimplemented and running.The Computer ModelThe computer model of compounding accepts  r e l a t i v e  c lauses t r u c t u r e s  as input  and produces nominal compound s t r u c t u r e s  a soutput when t h e  input  is appropr ia te .
It is w r i t t e n  i n  a languagewith many parentheses t h e  language was chosen f o r  its programdevelopment f a c i l i t i e s ,  i .
e .
b u i l t - i n  e d i t o r ,  r a the r  than for itsi n t e r p r e t i v e  c a p a b i l i t i e s .
The program which produces nominalcompounds is a p a t t e r n  matching i n t e r p r e t e r ;  it appl ies  a r u l eof compound formation by matching one side of t h e  r u l e  w i t h  t h einput s t r u c t u r e ,  and i f  c e r t a i n  c r i t e r i a  are s a t i s f i e d  by t h ematch, i t e m s  from the input  s t r u c t u r e  a r e  bound i n t o  t h e  r u l e ,t r ans fe r red  t o  t h e  o the r  side of the r u l e ,  and a copy is thenmaae a f  the o the r  s ide  of the r u l e .
The r e s u l t  is a nominalcompound s t r u c t u r e .The model has two components: a r u l e  interpreter and alexicon of r u l e s  for compounding.
There is nothing t r i c k yabout r u l e  app l i ca t ion .
Consider t h e  nominal compound flowermarket and i t s  associa ted  r e l a t i v e  c lause  paraphrase - marketwhere f lowers - are c h a r a c t e r i s t i c a l l y  sold.
These phrases havei n  my system t h e  underlying structures shown i n  Figure 1.The no ta t ion  i n  square braces means t h a t  the verb se l l  has thecharacteristic aspect  i n  this instance.market I RELCLsell [+char]m / \J-market flowers Figure 1.marketflowerThese two s t r u c t u r e s  can be made i n t o  a rule by l i n k i n g  themt o g e t h e r .
Whenever a r e l a t i v e  c l a u s e  s t r u c t u r e  i d e n t i c a l  t ot h a t  i n  F igu re  1 is r e c e i v e d ,  t h e  r u l e  a p p l i e s  and a copy isc r e a t e d  of t h e  nominal compound f lower  - market .
The matchingprocedure  is a r e l a t i v e l y  s t r a i g h t f o r w a r d ,  t o p  down, r e c u r s i v ep r o c e s s  which has  b a c k t r a c k i n g  c a p a b i l i t y  i n  t h e  even t  t h a ta s t r u c t u r e  o r  c a s e  o c c u r s  more than  once a t  any g i v e n  l e v e l  ofthe  s t r u c t u r e .
There a r e  two problems which arise; however:i f  e r u l e  is g e n e r a l i z e d  t o  account f o r  compounds o t h e r  t h a nflower market, then t h e  l e x i c a l  i tems i n  t h e  r u l e  w i l l  behave a sv a r i a b l e s  and some p r o v i s i o n s  must be made for binding of valuest o  these v a r i a b l e s ;  a l s o ,  t h e  r u l e  i n t e r p r e t e r  must  have someh e u r i s t i c s  f o r  s e l e c t i n g  a p p r o p r i a t e  r u l e s  i f  t h e  time requ i redt o  produce a compound is not  t o  i n c r e a s e  exponentially w i t h  t h esize of the l e x i c o n .The p r e s e n t  version o f  t h e  model only p a r t l y  so lves  thebinding problem.
Consider the r u l e  given i n  Figure 2 w h i c h  is  ag e n e r a l i z a t i o n  of  that given  in Figure  1.marketIs e l l  [+cha r ]LOCmarket goodsmarket I C O WgoodsFigure 2.If this rule is t o  app ly  t o  the  r e l a t i v e  clause structure glven i nFigure 1 and g e n e r a t e  the compound flower m a r k e t ,  t h e n  t h e  r u l ei n t e r p r e t e r  must recognize t h a t  t h e  r e l a t i v e  c l a u s e  i n  Figure 1is an  i n s t a n c e  of t h a t  g i v e n  i n  F igure  2.
The matching proceduredoes  this by de te rmin ing  t h a t  t h e  reference se t  of the nomina lflowers is a subset of the r e f e r e n c e  set  of the nominal goods.I n  a d d i t i o n ,  t h e  nominal flowers must  be c a r r i e d  across t othe o t h e r  side of the  rule and substituted there for goods beforet h e  other s i d e  of t h e  r u l e  is cop ied .
Thus  market and goods mustbe bound across the r u l e  s o  t h a t  whatever  l e x i c a l  i t e m  matcheseither of t h e s e  nominals becomes t h e  v a l u e  a s s o c i a t e d  w i t h  thesenominals on t h e  o t h e r  s i d e  o f  t h e  r u l e .I n  t h e  i n i t i a l  v e r s i o n  of t h e  model, t h i s  b ind ing  wase s t a b l i s h e d  e x p l i c i t l y  when t h e  r u l e  was e n t e r e d  i n t o  the l e x i c o n ,bu t  t h i s  seemed u n s a t i s f a c t o r i l y  ad hoc.
I n  a  subsequent v e r s i o n ,--t h e  i d e n t i t y  of t h e  l e x i c a l  i t e m s  on bo th  s i d e s  of t h e  r u l e  wast h e  relation used t o  e s t a b l i s h  b ind ing  r e l a t i o n s h i p s .
Consider ,however, t h e  s t r u c t u r e  shown i n  F:Lgure 3.person I RELCLs t e a l  [+char ]PERF/ \ OBJperson  v a l u a b l e sF igure  3t h i e fHere person  should be bound t o  t h i e f  but  t h e  p rev ious  techniqueis not  a b l e  t o  e s t a b l i s h  t h i s  b ind ing .
The reason t h a t  w e  knowt h a t  person  and t h i e f  should  be bound is because w e  know t h a t  at h i e f  is a  person who s t e a l s  c h a r a c t e r i s t i c a l l y .
I n  t h e  mostr e c e n t  v e r s i o n  pf t h e  model, t h i s  in format ion  is used t o  f i n d  t h eb ind ing  r e l a t i o n s h i p s  when t h e  r u l e  of i d e n t i t y  doe$ not  work.The l e x i c o n  is searched  for  a  r u l e  which can be used t o  e s t a b l i s ht h i s  b ind iag .
The r u l e  which is used i n  t h e  example shown i nF igure  3 is d i sp layed  below i n  Figure 4.person I RELCL t h i e fs t e a l  [+char  ] I PERFpersonFigure  4From the s t r u c t u r e s  g iven i n  F igure  4 ,  one c a n  see t h a t  personshduld  be bound t o  t h i e f  because t h e  r u l e  s t a t e s  t h a t  t h e  r e f e r e n c ese t  o f  t h i e f  is t h e  same as  the r e f e r e n c e  set of  person a sr e s t r i c t e d  by t h e  r e l a t i v e  c l a u s e .The technique o f  u s i n g  l e x i c a l  r u l e s  t o  e s t a b l i s h  b ind ingsworks i n  v i r t u a l l y  e v e r y  i n s t a n c e ,  but  it has t h e  d e f e c t  ofr e q u i r i n g  t h a t  t h e  informat ion t h a t  a t h i e f  is a person who s t e a l st h i n g s  be represen ted  i n  t h e  l ex icon  twice a t  l e a s t .
A new modelis under c o n s t r u c t i o n  which a t t empts  t o  reduce t h i s  redundancyby a l lowing  t h e  r u l e s  t o  have m u l t i p l e  l e f t  and r i g h t  p a r t s .The problem of s e l e c t i n g  a p p r ~ p r i a t e  r u l e s  is r a t h e r  e a s i e rt o  so lve .
I n  most compounds i n  Engl i sh ,  there is a c h a r a c t e r i s t i cassociation between t h e  r i g h t  element of the nominal compound andt h e  main verb of the as soc i a t ed  r e l a t i v e  c l a u s e  paraphrase .
Thesetwo elements which occur on  opposite sides of the compounding r u l esupply a g r e a t  d e a l  o f  in format ion  about t h e  p o s s i b i l i t i e s  f o ra p p l i c a t i o n  of t h e  ru le .
So, i n  t h e  model ,  each ru le  i n  t h el ex i con  is indexed by t h e  main verb  of  the r e l a t i v e  c l a u s e  andby the r i gh t  element of t he  nominal compaund.
T h i s  index actuallycon ta in s  some environmental informat ion as  w e l l ;  for t h e  c l a u s everb ,  t h i s  environmental informat ion is t h e  ca se  frame of t h e  ve rband the f a c t  that  it is the main verb of the r e l a t i v e  c l ause  --for t h e  compound nominal, t h e  environmental in format ion  is j u s tthe fact that the nominal is t h e  r ightmost  one i n  a nominalcompound.The basic model has been tested w i t h  a se t  of  s e v e r a lhundred nominal compounds and is very s u c c e s s f u l  i n  coping w i t ha wide v q r i e t y  of compound types .
The p r o d u c t i v i t y  of t h e  rulesvaries g r e a t l y ;  some rules  may produce hundreds of compounds w h i l eother rules may on ly  result i n  one or two compounds.
Frozen formssuch a s  k e e l  boat are handled by a rule which gene ra t e s  onlyone compound; there is a r u l e  for each f rozen  form.
The r u l es t r u c t u r e s  c o n t a i n  exc lus ion  lists a s s o c i a t e d  w i t h  each lexicali t e m  i n  the rule, and these exclusion lists prevent  t h e  r u l e  fromope ra t i ng  whenever a l e x i c a l  i t e m  matches one Of t h e  items on anexc lhs ion  list i f  t he  i t e m s  occur a t  corresponding l o c a t i o n s  i nthe s t r u c t u r e s .The model is quite quick i n  o p e r a t i o n ;  on a h igh  speeddibplay  conso le ,  i t  w i l l  generally produce compounds much faster,than a person s i t t i n g  a t  t h e  console  can conven ien t ly  read them.v i ~  is mainly due t o  t h e  r u l e  s e l e c t i o n  h e u r i s t i c ,  b u t  t h e  matchprocedure has been c a r e f u l l y  optimized as  w e l l .ConclusionsThe model program is an  e x c e l l e n t  demonstrat ion of t h eappropr ia teness  of  t h e  b a s i c  t heo ry ;  moreover, t h e  r u l e sthemselves can be genera l i zed  t o  d e a l  wi th  s y n t a c t i c  p rocesses ,s o  there is no d i s c o n t i n u i t y  i n  t h e  grammar model between t h elexical  processes  and t h e  s y n t a c t i c  processes .
I t  seems cleart h a t  t h e  r u l e s  could a l s o  be used t o  r ep re sen t  o t h e r  l e x i c a lprocesses  i n  language and t h i s  is c u r r e n t l y  being pursugd.There is no reason why t h e  r u l e s  could not  be used f o rr ecogn i t i on  as well a s  for t h e  product ion of  nominal compounds.The bindings  a r e  not  one-way, and t h e  matching procedure w i l lwork e q u a l l y  well for compound s t r u c t u r e s .
The reasons  why t h ecomputer model is a product ion model a r e :  (1) tha t  t h e  computermodel assumes t h e  semantic c o r r e c t n e s s  of t h e  inpu t  r e l a t i v ec l a u s e  s t r u c t u r e s ,  and (2) t h a t  compounds a r e  o f t e n  ambiguousand may be paraphrased by two o r  more r e l a t i v e  c l ause s ,  w h i l e  t h econverse of this is almost never t r u e .
A recogn i t ion  model wouldhave t o  genera te  under lying r e l a t i v e  c l ause  s t r u c t u r e s  f o r  eachambiguity and a semantic component would have t o ~ s c r e e n  t h er e l a t i v e  c l a u s e s  f o r  semantic e r r o r s .I hope t h a t  the reader  has not iced  t h e  avoidance of r u l eprocedures i n  t h i s  model.
When I began working on t h e  design oft h e  computer programs, I had i n  mind t h e  c r e a t i o n  of a model whichonce implemented i n  LISP could be extended merely by adding new~ u l e s  wi thout  having t o  cons t ruc t  any a d d i t i o n a l  LISP programs.I u l t i m a t e l y  wanted t o  have a model which could l l l ea rn t l  new r u l e sby systematic g e n e r a l i z a t i o n  and r e s t r i c t i o n  of existing r u l e s .I feel t h a t  t h i s  would be r e l a t i v e l y  easy  w i t h  r u l e  s t r u c t u r e s  andextremely d i f f i c u l t  w i t h  r u l e  procedures w r i t t e n  i n  a programminglanguage.
Furthermore, I subsc r ibe  t o  Karl  Popper 's  icfeas ofs c i e n t i f i c  endeavour, and r u l e  s t r u c t u r e s  appealed because i twould be more difficult t o  bury f laws or ill understood a s p e c t sof compounding and r u l e  processes  i n  s t r u c t u r e s  than  i n  procedureswhere t h e  computat ional  power of  t h e  programming language permitsand even encourages -- ad hoc s o l u t i o n s  t o  be found t o  problems.AcknowledgementsI would like to here acknowledge t h e  suggestions made byRobert F. Simmons, Carlota Smith,  Mary Boss T. Rhyne, U u r e n tS i k l o s s y ,  and Stanley Peters which have helped tsprbve myunderstanding of nominal compounding.1.
Chomsky, N. "Remarks on Naninalizatlon, '' i n  Readings - inEngXish Transformational G-r, Jacobs, R. and Rosenbaum,P.
eds.
Ginn, Waltham, Xassachusetts, 1970.2 .
Gruber, J. vvStudies in Lexical Eklat ions. "
Ph.
D .
thesis,HIT, 1965.3, Lees, R, - The Grammar - of English NosninalTzations, Mouton,The Rague, 1968.4.
Rhyne, J.
"Lexical Rules and Structures in a Computer %lode1of Nominal Compounding in English."
Ph.
D. t h e s i s ,  TheUniversity of Texas at Austin, 1975.5 ,  Simmons, R. "Semantic N e t w o r k s  : Their Camputat ion and U s efor Understanding E n g l i s h  Sentences,  '' i n  Computer Models - ofThought and Language, Schank, R. and Colby,  K. eds.
W. H.-Freeman, San Francisco, 1973.American Journal of Computational Linguistics Microfiche 33 : 45Computer Science Depar tmentI n d i a n a  U n i v e r s i t yBloon l ing ton  4 7 4 0 1ABSTRACTGeneration of English s u r f a c e  s t r i n g s  from a semant ic  networkis viewed a s  t h e  c r e a t i o n  o f  a l i n e a r  surface s t r i n g  t h a t  d e s c r i b e sa node of  t h e  semant ic  network.
The form o f  t h e  s u r f a c e  s t r i n g  i sc o n t r o l l e d  by a r e c u r s i v e  augmented t r a n s i t i o n  network grammar,which i s  capab le  of examining t h e  form and c o n t e n t  o f  t h e  semant icnetwork connected  to t h e  semant ic  node b e i n g  d e s c r i b e d .
A s i n g l enode o f  the grammar network may r e s u l t  i n  d i f f e r e n t  forms o f  sur-f a c e  strings depending on t h e  semant ic  node i t  i s  g i v e n ,  and asingle semantic node may be d e s c r i b e d  by d i f f e r e n t  s u r f a c e  s t r i n g sdepending on t h e  grammar node i t  is g iven  t o .
S i n c e  g e n e r a t i o nfrom a semantPc network r a t h e r  t h a n  from d i sconnec t ed  p h r a s e  markers , ,t h e  s u r f a c e  s t r i n g  may be g e n e r a t e d  d i r e c t l y ,  l e f t  t o  r i g h t .I n t r o d u c t i o nI n  t h i s  p a p e r ,  w e  d i s c u s s  t h e  approach b e i n g  taken i n  t h e  E n g l l s hg e n e r a t i o n  subsystem of  a n a t u r a l  language understanding systempresently under  development a t  I n d i a n a  U n i v e r s i t y .
The co re  oft h e  unde r s t ande r  i s  a semant ic  network p r o c e s s i n g  sys tem,  SNePS(Shapi ro ,  1975), which i s  a descendant  of t h e  MENTAL semant io  sub-system (Shap i ro ,  1971a, 1971b) o f  the M I N D  sys tem (Kay, 1973).The r o l e  of t h e  g e n e r a t o r  13 t o  describe, i n  E n g l i s h ,  any oP t h enodes i n  the sernantjc network, a l l  o f  which r e p r e s e n t  concepts o fthe understanding aystem.4 6and other computations are ~ e q u i r e d  in the process of pasting theset r e e s  t o g  the r  i n  a p p r o p r i a t e  places u n t i l  a ' s i n g l e  phrase markerI s  a t t a i n e d  which  w i l l  l e a d  t o  t h e  s u r f a c e  string.
S i n c e  we areg e n e r a t i n g  from a semant ic  network, aL1 the  p a s t i n g  t o g e t h e r  i sa l r e a d y  done.
Grabbing the n e t w o r k  by the node of i n t e r e s t  andl e t t i n g  the network dangl-e from it  gives a s t r u c t u r e  m i c h  may besearched apppogr i a t e ly  i n  o r d e r  t o  g e n e r a t e  t h e  s u r f a c e  s t r f n gdirectly i n  l e f t  t o  r i g h t  f a s h i o n .Our system b e a r s  a s u p e r f i c i a l  r e s e m b l a n c e  t o  that d e s c r i b e dfn Simmons and Slocum, 1972 and i n  Simmons, 1973.
T h a t  sys tem,h o w e v e r ,  s t o r e s  s u r f a c e  i n fo rma t ion  such  as t e n s e  and vo ice  i n  itssemant ic  rietwork and its ATN t a k e s  as i n p u t  a l i n e a r  list con ta in -ing the semantic node and a generation p a t t e r n  consisting o f  a" s e r i e s  of c o n s t r a i n t s  on t h e  moclalltyfl (Simmons e t  a l .
,  1973, p .
9 2The g e n e r a t o r  d.escribed i n  Schank e t  a l .
,  1973, t r a n s l a t e s  froma "conceptua l  s t r u c t u r e f 1  i n t o  a network of  t h e  form o f  Simmons 'network w h i c h  is t hen  g iven  t o  a v e r s i o n  of  Simmons g e n e r a t i o nprogram.
The two s t a g e s  use d i f f e r e n t  mechanisms.
Our systemamounts t o  a u n i f i c a t i o  of  these two s t a g e s .The g e n e r a t o r ,  as d e s c r i b e d  i n  this page r ,  as w e l l  as SNePS,a parser and an in fe rence  mechanism have been written i n  LISP 1 .
6and are runn ing  I n t e r a c t i v e l y  on a DEC system-10 on t h e  I n d i a n aUniversity Computing Network.Representation i n  t h e  Semantic_NetworkConceptual in fo rmat ion  derived from parsed sen t ences  o r  deducedfrom other in fo rmat ion  ( o r  i n p u t  d i r e c t l y  v i a  t h e  SNePS user's l an -guage) i s  stored i n  a semant ic  network.
The nodes i n  the networkrepresent concepts  which may be d i s c u s s e d  and reasoned abaat.
Theedges represent semantic b u t  non-conceptual  b i n a r x  relationsbetween nodes.
There are a l s o  a u x i l i a r y  nodes which SNePS canuse or which the user can use as SNePS v a r i a b l e s .
(For a morecomplete diecussion of SNePS and the network n e e  Z h a p i r o ,  1975.
)The semantic network representation be ing  used does no t  i n -  47olude information considered .t.6 be f e a t u r e s  of' t h e  s u r f a c e  s t r i n gsuch as t e n s e ,  vo ice  o r  main v s .
r e l a t i v e  c l a u s e .
I h s t e a d  of t e n s e ,temporal  in fo rmat ion  i s  s t o r e d  P e I a t i v e  t o  a growing t i m e  l i n ei n  a manner s i m i l a r  t o  tha t  of Bruce,  1 9 7 2 .
From t h i s  informat iona t e n s e  can be gene ra t ed  f o r  an ou tpu t  s e n t e n c e ,  bu t  i t  may be ad i f f e r e n t  t e n s e  t h a n  that of t h e  o r i g i n a l  i n p u t  sen tence  i f  t imehas progressed  i r i  %he 5nter im.
The vo ice  o f  a genera ted  sen tencei s  u s u a l l y  determined by t h e  top l e v e l  c a l l  t o  the gene ra to r  func-t i o n .
However, sometimes i t  i s  determined by t h e  g e n e r a t o r  gram-m a r .
For  example, when g e n e r a t i n g  a r e l a t i v e  c l a u s e ,  vo ice  i sdetermined by whether t h e  nodn be ing  m o d i f i e d - i s  t h e  agen t  o r  ob-ject of t h e  a c t i o n  de sc r ibed  by the r e l a t i v e  clause.
The Mainc l a w e  of a gene ra t ed  sentence  depends on which semant ic  node i sg iven  t o  t h e  g e n e r a t o r  in t h e  t o p  l e v e l  c a l l .
Other  nodes con-nec t ed  t o  it may r e s u l t  i n  r e l a t i v e  c l ause s  be ing  genera ted .
Theser o l e s  may be r e v e r s e d  i n  o t h e r  t o p  l e v e l  c a l l s  t o  t h e  g e n e r a t o r .The g e n e r a t o r  i s  d r i v e n  by  two s e t s  of data: t h e  semant ic  ne t -work and a grammar i n  t h e  form of a r e c u r s i v e  augmented t r a n s i t i o nnetwork (ATN) similar t o  tha t  of  Woods, 1973.
The edges onour  ATN a r e  somewhat d i f f e r e n t  from those  of Woods s i n c e  our  viewi s  that  t h e  g e n e r a t o r  i s  a t r a n d u c e r  from a network i n t o  a l i n e a rs t r i n g ,  whereas a p a r s e r  I s  a  t r a n s d u c e r  f r o m  a l i n e a r  string i n t oa t r e e  o r  network.
The changes t h i s  e n t a i l s  a r e  d i s cus sed  below.During any p o i n t  i n  gene ra t i on ,  t h e  gene ra to r  i s  working on somep a r t i c u l a r  semant ic  node.
Funct ions  on t h e  edges of t h e  ATN canexamine the network connecteb t o  t h i s  node and fail o r  succeedaccord ing ly .
I n  t h i s  way, nodes of  t h e  ATN can "decide" what sur-face form i s  most a p p r o p r i a t e  f o r  d e s c r i b i n g  a semantic node, whiled i f f e r e n t  ATN nodes may gene ra t e  different surface foI?ms t o  des-cribe the  same semantic node.A common assumption among l i n g u i s t s  i s  that gene ra t i on  beg in3w i t h  a set of disconnected  deep phrase markers.
T r n n u f  o ~ - m a t l o n ~LEXFizure 1: Semantic Network RepresentatLon for "Charlie believesthat a dog kissed sweet young Lucy," "Charlie i s  a person," and"Lucy i s  a person.,.Af=rmation considered t o  be features o f  surface strings are n o tstored in the semantic network, but a r e  used by the p a r s e r  in con-s t r u c t i n g  the network rrom t h e  i n p u t  sen tence  and by t h e  g e n e r a t o rf o r  generating a s u r f a c e  s t r i n g  from t h e  network.
For example,tense i s  mapped into and from temporal  r e l a t i o n s  between a noder e p r e s e n t i n g  that some a c t i o n  has, is, or will occur and a growingt i m e  l i n e .
Restrictive relative clauses are used by the  parserto Identify a node being d i scussed ,  while n o n - r e s t r i c t i v e  r e l a t i v eclauses may result i n  new i n f o r m a t i o n  b e i n g  added t o  t he  network.The example used i n  t h i s  paper  i s  designed t o  i l l u s t r a t e  t h egeneration issues being discussed.
Although i t  also i l l u s t r a t e sour general approach t o  representational issues, some details w i l l*(SNEG MOOLb)(CHARLIE IS BELIEVING THAT A DOG KISSED SWEET YOUNG L U C Y ) ,* (SNEG M0023)( A  DOG KISSED SWEET YOUNG LUCY)*(SNEG M0007)(CHARLIE WHO IS BELIEVING THAT A DOG KISSED SWEET YOUNG LUCY)"(SNEG i4OOd;j(CHARLIE IS A PERSON WXO IS BELIEVING THAT A DOG KISSED SWEET YOUNG LUCY)* (SNEG M0006) ( C H R R L I E ~ W H O  IS BELIEVING THAT A DOG KISSED SWEET YOUNG L U C Y  I S  A PERSON)(SNEG M0008)(THE BELJEVING THAT A DOG KISSED SWEET YOUNG LUCY BY CHARLIE)* (SNEG M0011)(A DOG WHICH KISSED SWEET YOUNG LUCY)*(SNEG ~ 0 O l O j(THAT WHICH KISSED SWEET YOYNG LUCY IS A DOG)* (SNEG M0012)(THE KISSING OF SWEET Y O U N G  LUCY BY k DOG)@(SNEG M0020)(SWEET YOUNG LUCY WHO WAS KISSED BY A D O G )*(SNEG M0014)(LUCY IS A SWEET YOUNG PERSON WHO NAS KISSED BY A DOG)*(SWG M0015)(SWEET YOUNG LUCY HH3 WAS KISSED BY A DOG IS A PERSON)*(SNEG M0017)(SWEET LUCY WHO WAS KLSSED BY A DOG IS YOUNG)*(SNEG M0019)(YOUNG LUCY WHO WAS KISSED BY A DOG IS SWEET)F i g u r e  2 :  R e s u l t s  of  calls t o  t h e  g e n e r a t o r  with nodes f romFigure  I* User i n p u t  i s  on l i n e s  beginning with *.c e r t a i n l y  change as work p r o g r e s s e s .
F i g u r e  1 shows t h e  semant icnetwork r e p r e s e n t a t i o n  for the i n f o r m a t i o n  i n  the sefitencesb, "Charlieb e l i e v e s  that a dog k i s s e d  sweet young Lucy,"  " C h a r l i e  is a person ,"and "Lucy i s  a p e r s o n . "
Converse edges a r e  n o t  shown, b u ti n  a l l  cases t h e  label of  a converse  edge i s  t h e  l a b e l  o f  the  fo r -ward edge with ' * '  appended exoept  f o r  BEFORE, whose converse  edgeis l a b e l l e d  AFTER.
LEX p o i n t e r s  p o i n t  t o  nodes c o n t a i n i n g  ; lexica le n t r i e s .
STIME p o i n t s  t o  the s t a r t i n g  t ime of  an  a c t i o n  and ETIMEt o  i t s  ending  time.
Nodes r e p r e s e n t i n g  i n s t a n t s  of t ime a r e  re-l a t e d  t o  each o t h e r  by t h e  BEFORE/AFTER e d g e s .
The auxiliary nodeNOW has a :VAL p o i n t e r  to t h e  c u r r e n t  i n s t a n t  of  t i m e .F i g u r e  2 shows t h e  g e n e r a t o r ' s  o u t p u t  f o r  many o f  t h e  nadcs  o fF igure  1.
Figure 3 shows t he  Lcxicon uncd i n  the example .
(BELIEVE((CTGY.V)(I~BELIEVE)(PRES.BELIEVES)(PAST.BELIEVED)(PASTP.BELIEVED)(PRESP.BELIE~JING)))(CHARLIE ( (CTGY .
NPR) (PI .
CHARLIE) 1')(DO~'((CTQY.N)(SING.DOG)(PLUR.DOGS)))(K~SS((CTGY .v) CINF.KISS)~PRES.KISSES)~PP.ST.KISSED~~PASTP.KISSED)(PRESP.KISSING~~)(LUCY-((CTGY.NPR)(PI.LUCY)))(PERSON((CTGY.N!
(sING.PERSON)(PLUR.PEOPLE)~~(SWEET(~CTGY.ADJ)(PI.SUEET) 1 )(YO~NG((CTGY.ADJ)(PI.YOUNG)))Figure 3: The l ex icon  used i n  the example of Figures 1 and 2.Generation as P a r s i n gNormal p a ~ s i n g  involves t a k i n g  i n p u t  from a linear s t r i n g  andproducing a tree o r  network structure as o u t p u t .
Viewing thisin terns of an ATN grammar as described i n  Woods, 1973, t he r e  i s  awell-defined next  input f u n c t i o n  which simply p laces  success iveword6 into t h e * *  r e g i s t e r .
The outpu t  f u n c t i o n ,  however, i s  morecomplicated, uslng BUILDQ t o  build pieces  of  t r e e s ,  o r ,  as i n  ourparser, a BUILD function t o  build p i e c e s  of  network.If we now consider g e n e r a t i n g  i n  these terms,  we see  that  t h e r ei s  no simple next  i n p u t  f u n c t i o n .
The g e n e r a t o r  will focus onsome semantic  node f o r  a whi le ,  recurs ive ly  s h i f t i n g  its a t t e n t i o nto adjacent nodes and back.
Since  there are several  ad jacen t  nodes,connected by variously l a b e l l e d  edges ,  the  grammar a u t h o r  mustspecify which edge t o  fo l low when t he  gene ra to r  i s  to move t o  ano the rsemantic node.
For t h e s e  reasons ,  t h e  same focal semantic nodeis used when traversing edges of the grammar network and a new se-mantic node is- specified by gl,ving a p a t h  from t h e  c u r r e n t  semanticnode when pushing t o  a new grammar node.
The reg i s t e r  SNODE isu s e d t o  hold the current semantic node.The output func t ion  of gene ra t ion  i s  s t r a i g h t f o r w a r d ,  s i m p l ybeing concatenation onto  a growing s t r i n g .
Since t h e  ou tpu t  s t r i n gis analogous t o  the parser's Inpu t  s t r i n g ,  w e  store i t  in the reg-garc : := (TEST test [action]* (TO gnode) )(JUMP [action]*(TO gnode)) (mM wform (wqrd*) test [action]*(TO gnode))(NOTMEM wform (word#) test [ a c t i o n ] * ( T ~  gnode))(TRANSR ([regname] regname regname) test [ac t ion]*  (TO gnode) )(GEN gnode sform [action]*regnarne [action]*(TO gnode))sform ::= w f o r mSNODEwform : := (CONCAT f ~ ~ m  form*)(GETF sarc [aform])( GETR re gname )(LEXLOOK l f  e a t  [ sf orm] )sexpform -: := w f o r msformac t  ion : := (SETR regname f o m(ADDTO regname form* )(ADDON regname f o m *  )sexptest : :  (MEMS form form)(PAT23 sform sarc* sform)formsexpgnode : := <any LISP atom which r e p r e s e n t s  a grammar node>word : := <any LISP atom>regname ::= <any non-numeric LISP atom used as a r e g i s t e r  name>sarc ::= <any LISP atom used as a semantic a r c  label>l f ea t  : := <any LISP atom used as a l e x i c a l  feature>sexp : := <any LISP s-expression>Figure 4: Syntax of  edged of gene ra to r  ATN grammarsi s t e r  *.
When a pop occurs ,  i t  i s  always t h e  cu r r en t  va lue  of *tha t  is r e t u ~ n e d .Figure 4 shows the syntax  of t h e  gene ra to r  ATN grammar.
Objectlanguage symbols  are ) , (, and elements i n  c a p i t a l  l e t t e r s .
Meta-language symbols are i n  lower case ,  Square brackets  e n c l o s e  op-t i o n a l  elements.
Elements followed by * may be repeated one o r  moret j m e s .
Angle b r a c k e t s  enc lose  informal  Eng l i sh  d e s c r ~ p t i o n s .Semantics of Eage FunctionsIn this section, the semantics of t h e  grammar arcs, forms andt e s t s  ape preaehted and compared to those of Woods1 ATNs.?
The---t A l l  comparlsona arc with Woodo, 1973.NCL ')JUMP(SETR * @(/ / / /  NO GRAMMAR NODE F O U N D ) )  M E N D  )Figure 5 :  The default en t ry  i n t o  the grammar n e t w o ~ k .essential differences are those required by the differences betweengenerating and parsfng as discussed in the previous s e c t i o n .
(TEST t e s t  [action]*(TO gnode))If the test i s  successful ( e v a l u a t e s  t o  non-NIL), t h e  a c t i o n sare performed and gene ra t i on  con t inues  at gnode.
I f  t h e  testf a i l s ,  this edge i s  not  t aken .
TEST- is the same as WoodsT TST,w h i l e  TEST(GETF s a r c )  i s  analogous t o  Woods' CAT.
(JUMP  action]*(^^ gnode))Equivalent to (TEST T [actlon]*(TO gnode)).
JUMP is simllarIn use to Woods JUMP, b u t  the d i f f e r e n c e  from TEST T disappearss ince  no edge r'consumesl' any th ing .
(MEM wform (word*) tes t  [action]* (TO gnode) )If the value of wform has a non-null  intersection w i t h  t h elist of words, the test is performed.
If t h e  test is also success-f u l  the actions are performed and gene ra t i on  continues a t  gnode.if either the Intersection is null or the t e s t  f a i l s ,  the edgeMEM(GETR VC)(PASS)T G-EN NCLNP(~ETF OBJECT)(ADDTO DONE SNODEI*( SREG PRED)OEN NCLNP(GETF AGENT)(ADDTO DONE SNODE)*Figure 6: Generation of subject of sub ject-verb-ob ject sentence.is not taken.
This is similar in form to Woods1 MEM, but mainlyused for testing r e g i s t e r s .
(NOTMEM wform (word*) test [action]*(TO gnode))This is e x a c t l y  l i k e  MEM except the intersection must be n u l l .
(TRANSR ([regnamel] regname2 regname3) t e s t  [ac t ion]*  gnode) )If regnamel i s  present, the  contents  o f  regname2 are addedon the end of regnamelo If regname is empty, t he  edge is not  3taken.
Otherwise, t h e  f i rs t  element i n  regname is removed and 3placed in regname2 arid the  t e s t  i s  performed.
If the  t e s t  f a i l s ,the edge is not  taken, b u t  if i t  succeeds, the ac t ions  are performedand generat ion continues at gnode.
TRANSR i s  used t o  iterate th roughseveral nodes all in t h e  same semantic r e l a t i o n  w i t h  the  main se-mant ic  node.
(GEN gnodel s form [action]*regname [ac t ion]*(TO gnode*))The f i r s t  s e t  of a c t i o n s  are performed and t h e  generation i sc a l l e d  recursively with the semantic node that is the value  of sformand a t  the  grammar node gnodel.
If this genera t ion  is successful( r e t u rn s  non-NIL), the result i s  placed i n  the  r e g i s t e r  regname,the  second se t  of  a c t i o n s  are performed and g e n e r a t i o n  con t inuesat gnode*.
If the generation fails, the edge i s  not t aken .
ThisI s  the same as Woods1 PUSH but requires a semantic node t o  be npeci-f i e d  and allows any register to be used t o  hold t h e  result.
In-stead o f  having a POP edge, a r e t u r n  automatically occurs when(ADDON * @WILL @HAVE)(ADDON * QWQULD)UI@(ADDON * @(/ / /CANNOT COMPUTE TENSE))TEST( MENS (GETR REF) ( *  @NOW) ) (ADDON PIS') \ aMEM(GETR VC) (PASS)T(ADDON * @BEEN) CVPFMEM(GETR VC)(PASS)T(ADDON * @BE) ( tp~ JUMP@FAST~ J U M P ( A D D 0 N  * (LExLOOK PASTP(GETF VERB)))JuMP(ADDON * (LEXLOOK INF(GETF V E R B ) ) )  CTIINF ) -Figure 7: Tense genera t ion  network.transfer is made to the node END.
At tha t  point, the con ten t s  o fthe register named * are r e tu rned .
(CONCAT form form*)The forms are evaluated and concatenated i n  the order given.Performs a r o l e  analogous to tha t  of Woodst BUILDQ.
(GETF sarc [sform])Returns a list of a l l  semantic nodes at the end of the seman-t i c  arcs label led sarc from the  aemantic node whl ch i s  t h e  valueFigure 8: The tenses of "breakn which t h e  network o f  F igure  7can generate.of  sfomn.
If sform i s  missing, SNODE is assumed.
Returns N I L  ifIt h e r e  a r e  no such semant ic  nodes.
It is similar in the semanticTensepastf u t i l ~ epresent prog~essivepas t  progressivefuture progr6ssivepast In futurefuture fq p a s tActive Passivedomain t o  Woods' GETF i n  t h e  l e x i c a l  domatn.brokewill breakis break-lngwas breakingw i l l  be break ing 'w i l l  have brokenwould break(GETR regname)Returns the contents of  register regname.
It i s  essentiallythe same as Woodst GETR.was brokenw i l l  be brokeni s  being brokenwas being brokenwill be being brokenw i l l  have been broken, wquld be broken .
(LEXLOOK l f e a t  [sform])Returns the value of  the lexical feature, l f e a t ,  of the l e x i c a len t ry  associated w i t h  the semantic node which i s  t h e  value of sform.If sform is missing, SNODE i s  assumed.
If no lexical entry i s  asso-c i a t e d  with t h e  semantic node, NIL i s  r e tu rned .
LEXLOOK i s  sirnilarto Woods1 GETR and as a l s o  i n  the l e x i c a l  domain.
(SETR regnarne form)The va lue  of form is placed in the r e g i s t e r  regname.
It isthe same as Woods1 SETR.
(ADDTO Pegname form*)Equivalent  t o  (SETR regname (CONCAT (GETR regname) form*)).Equivalent to (SETR regname (CONCAT form* (GETR regname))).
(MEW f o r m  form)Returns T If t h e  values of the t w o  forms have a non-null intersec-tion, NIL otherwise.TEST( GETF OBJECT~ P R E D O B J )UMPcpmDAm GEN KLNP (GETF AGENT) REG (ADDON * (GETR 'REG) )CpRGDOB3 GEN NCLNP (GETF OBJECT) REG (ADDON * (GETR REG ) ) IFigure 9: Generating the s u r f a c e  o b j e c t .
(PATH s f o m l  sarc* sformp)Returns T i f  a p a t h  descr3bedl By t h e  sequence o f  semantic  a r c sexists between t h e  value of  sfoml and sformp.
If %he sequencei s  sarcl s a r c 2  ... sarc,, the p a t h  desc r ibed  i s  t h e  same as t h a ti n d i c a t e d  by sarc l*  sarc2* ... sarcni.
If no such p a t h  exists,NIL i s  r e tu rned .
(Remember, * means r epea t  one o r  more t imes .
)Discussion o f  an Example Orammar Network,The top level genera tor  f u n c t i o n ,  SNEG, Ls given as argumentsa semantic node and, o p t i o n a l l y ,  a grammar node.
If t h e  grammarnode is  not g iven ,  gene ra t i on  begins a t  t h e  node G 1  which shouldbe a small d iscc i rn ina t ion  n e t  t o  choose t h e  p r e f e r r e d  d e s c r i p t i o nfor t h e  given semantic  node, Th i s  p a r t  of the  example grammar isshown i n  Figure 5.
Jn it w e  see that  t h e  preferred d e s c r i p t i o nf o r  any semantic  node i s  a sen tence .
If no sentence  can b e  formeda noun phrase w i l l  be t r i ed .
Those a r e  t h e  only p r e s e n t l y  avail-able options.Semadtic nodes wi th  an  outgoing VERB edge can be desc r ibed  bya normal SUBJECT-VERB-OBJECT sen tence .
(For  this example, wehave n o t  used a d d i t i o n a l  c a s e s . )
F i r s t  t h e  s u b j e c t  i s  genera ted ,Figure  1 0 :  Generating t h e  t h r e e  "non-regular" s e n t e n c e s .which depends on whether t h e  sen tence  i s  t o  b e  i n  a c t i v e  o r  p a s s i v evoice.
A l t e r n a t i v e l y ,  t h e  choice  could be expressed  i n  terms ofwhether t h e  agent  o r  o b j e c t  is t o  be t h e  t o p i c  as sugges ted  by Kay,1975.
Figure 6 shows Lhe network that generates t he  s u b j e c t .
Ther e g i s t e r  DONE h a l d s  semant ic  noaes f o r  which sen tences  are beingg e n e r a t e d  for l a t e r  checking too prevent i n f i n i t e  r e c u r s i o n .
WPthouti t ,  node MOO23 of  F i g u r e  I would be desc r ibed  as,  "A dog which k i s s e dyoung sweet Lucy who was k i s s e d  b y  a dog which  k i s s e d .
.
.
"The i n i t l a 1  pa r t  of t h e  PRED network i s  concerned with generat-ing t h e  tense.
This  depends on t h e  BEFORE/AFTER pa th  between t h es t a r t i n g  and/or endinb time of the  a c t i o n  and t h e  c u r r e n t  va lue  ofNOW, w h i c h , i s  given by t h e  form ( #  @ N O W ) .
Figure 7 shows t h e  t e n s eg e n e r a t i o n  network.
Figure 8 shows t h e  t e n s e s  t h i s  network i s  a b l et o  generate.A f t e r  the verb group is generated,  the surface o b j e c t  is gener-a t e d  by desc r ib ing  e i t h e r  t h e  s e m m t i c  agent  o r  object.
Figure  9skuws this part of t he  networkThe o t h e r  th ree  kinds of s e n t e n c e s  a r e  lor descr ib ing  nodesr e p r e s e n t i n g :  (1) t h a t  something has  a p a r t i c u l a r  adjective a t t r i b u -able t o  it, ( 2 )  that something has a name, ( 3 )  that something i s  amember of some c l a s s .
The networks  f o r  t h e s e  a r e  shpwn i n  F igure10 .
Again, t h e  DONE r e g i s t e r  i s  used t o  prevent  such sen tences  as"Sweet young Lucy I s  sweet," "Charlie i s  Charlie."
and "A dog is a dog.
"GEN 3 (GETF OBJECT(GETF VERB*))REG(ADDON * @THAT(GETR R E G ) )cICL>GEN SREG SNODE *(ADDTO * @THAT)Figure 11: Generating norninalized verbs and sentences.Pugure 5 showed three b a s i c  kinds of noun phrases t h a t  can begenerated: the noun clause or nominalized sentence, such as " t h a ta d o f ~  kissed sweet young Lucyt'; the nominalized verb, such as "thekisslng of sweet young Lucy by a dogn; the r egu l a r  noun phrase.The first two of these are generated by the network shown in Figure11.
Bere DONE is ased t o  prevent, f o r  example, " t h e  kissing of  sweetyoung Lucy who was kiesed by a dog by a dog.
"The regular noun phrase network begins w l t h  another descrimina-t i o n  net which has the following p r i o r i t i e s :  use a name of the o b j e c t ;use a class the obJect belongs to; use something e l se  known about*he obJect.
A lower prior i ty  description will be used if all h i g h e rpriority descriptions are a lready  in DONE.
Figure 12 shows the be-glnnlrrg of the noun phrase network.
Adject ives  are added before t h emame or before tkre  class name and a relative clause is added after.GEN ADJS SNODE *(ADDTO * @A)Cm&uMp (sETR * B A )  N E M ~(LEXLOOK SING(GETE CLASS(GETF MEMBER*))))Figure 12: The beginning of the noun phrase network.F igure  13 shows the a d j e c t i v e  s t r i n g  genera to r  and Figure  1 4  showst h e  r e l a t i v e  c lause  g e n e r a t o r .
Notice the  use o f  t h e  TRANSR edgesf o r  i t e r a t i n g .
A t  t h i s  time, we have no theory  f o r  determining t h enumber o r  which adjec t ives  and r e l a t i v e  c l auses  t o  generate ,  s oa rb i t ra r i ly  we generate a l l  a d j e c t i v e s  not  a l r e a d y  on DONE but onlyone relative c lause .
We have n o t  y e t  implemented any o rde r ing  ofadjectives.
It i s  merely f o r t u i t o u s  t h a t  "sweet young Lucyt iseenerated rather than "young sweet Lucyft.
The network i s  w r i t t e nso  t h a t  a r e l a t i v e  clause f o r  which t h e  noun i s  t h e  deep agent  ispreferred over one i n  which t h e  noun i s  the  deep o b j e c t .
Noticethat  t h i s  choice determines t h e  voice  of t h e  embedded clause.
Thefomn (STRIP(FIND MEMBER (1.
SNODE) CLASS (FIND LEX P E R S O N ) ) )  is acall t o  a SNePS f u n c t i o n  t h a t  determines  i f  t he  o b j e c t  i s  known t obe a person, i n  ~ h i c h  case  "WHO" i s  used r a t h e r  than "'WHICHft.
Thisdetermination i s  made by r e f e r r i n g  t o  t h e  semant ic  network r a t h e rthan  by i nc lud ing  a HUMAN f e a t u r e  on t h e  l e x i c a l  e n t r i e s  f o r  LUCYand CHARLIE.nDJs7JUMP(SETR ADJS(GETF W E I C H * ) )Figure 13,: The network f o r  g e n e r a t i n g  a s t r i n g  o f  a d j e c t i v e s .Notice that any in format ion  abou t  t he  object being describedby a noun phrase may be used to construct a relatfve clause eveni f  that Lnfomnation derived from some main clause.
Also,  whilethe gene ra to r  i s  examining a semantic node all t h e  in format ion  aboutthat node i s  reachable from it  and may be used d i r e c t l y .
Therei s  no need t o  examine disjoint deep phrase markers t o  d i scove r  wherethey can be attached t o  each o t h e r  s o  that a complex sentence can bederived.Future WorkAdditional work needs ts be done in developing t h e  s t y l e  ofgene ra t ion  desc r ibed  i n  this paper.
Experience with larger andricher networks will lead to the fo l lowing  i s s u e s :  d e s c r i b i n g  a nodeby a pronoun when that node has been described e a r l i e r  i n  the string;regu la t ing  verbosi ty  and complexity, p o s s i b l y  by the use  of resourcebound8 simulating the limitations of s h o r t  term memory* keeping sub-,ordinate clauses and descriptions to t h e  point of t h e  conversa t ionp o s s l b l y  by the use of a TO-DO register holding thenodes  t h a t  aret o  be included in the  string.In thla paper, only i n d e f i n i t e  descriptions were genera ted .
Weare working on a routine that  w l l l  I d e n t i f y  the proper  subnet o f  t h esemantic network t o  j u s t i f y  a d e f i n i t e  descr ip t ion .
This  must besuch that it uniquely i d e n t i f l e e  t h e  node being d e s c r i b e d .
(SETR VC @ A C T )JUMP\JUMP F JUMPTEST(STRI?
!
*I!JD :.lEMEEFl(f SI\l; DE)CLASS (YT?ID E X  PERSON) ) )Figure 14: The r e l a t i v e  clause generator .AcknowledgementsThe a u t h o r  i s  indebted t o  John  Lowrance, who lfiplemnted t h egenerator, Stan Kwasny, who implemented the p a r s e r ,  Bob Bechtel,who worked b u t  t h e  t empora l  r e p r e s e n t a t i o n ,  Nich V i t u l l i  and N i c kEastridge, who implemented versions of SNePS, and Jim McKew forgeneral software ?
u p p o r t .
Computer service was prov ided  by t h eI U P U I  Computing F a c i l i t i e s .
T y p i n g  and graphics were d ~ n s  byChristopher Charles.Bruce, B.C.
2 9 7 2 ,  A model  f o r  temporal references and its a p p l i -ca t ion  in a question answering program, A r t i f i c i a l  Intelli-gence 3 ,  1, 1-25.Ray,  M. 1973.
The MIND system.
N a t u r a l  hanguage, Probesstng, R eRustin (EB. )
, AlgorithmScs Press, Mew Ysrk,  155-188.
'Kay, M. 1975.
Syntactic processing and functional sen tence  p e r -s p e c t i v e .
Theoretical Issues in N a t u r a l  Language ProcessfngR, Sch& and B,L, maah-Webber ( E d s , ) ,  B o l t  Beranek,& Newman,fnc .
,  Ombrfdge, Massachusetts.Schan~ ,  R.C.
; @oldman, ; Rteger, C , 111; and Riesbeck,  C .
1973.NARGlE: memory, analysis ,  responae generat ion,  and inferenceon English, Proc, Third xntematf onal, J o i n t  Conference on A r t i .f i c i q l ,  ,Intelligence, Stan fo rd  University, August 20-23, 255-26T.Shapiro, S,C.
1971a.
The W I N 3  system: a data s t r u c t u r e  f o r  seman-tic Infornation processlrig.
R-837-PR.
The Rand Corp .
, S a n t aMonica, Cal%forn la .Shapirs.
S.C. l g r l b .
A n e t  structure f o r  semantic i n f o r m a t i o n- storage, deduetlon and retrieval.
2nd International J o i n t -  Con- - .-Shapiro, S. C. 1975 * bAn 2 ntroduction t o  SNePS .
Technical ReportNo.
31, CumpuLer Science Department, Ind iana  U n i v e r s i t y ,  Bloom-f ngt on,SS@@ons, R,F.
1973, Semantic networks: their cornputatSon and usefor understanding English sentences.
computer Models of ThohghtR.C* Schank and K.M.
Colby (Eds.
), W.B.
FreemanFrancisco, 63-113.Sirnone, R.B., and Slocurn, 3 .
1972.
Generating English discoursefrom rralnantic net6 + Corn,.
ACM 15, 10, 891-905.Woods, W.A+ 1973.
A n  exgerlmental parsing system for transitionne %work gramars .
, R .
Rustin ( E d . )
,Algsrf t m i o a  Press,American Journal of Computational Linguistics ~ ic ro f i che  33 : 63Artificial Intelligence CenterStanford Research InstituteMen10 Park, California 94025ABSTRACT8atur.l languag8 output  can b* generatrd fram remantic netsby ptoc*rsing ternplats8 asroeiated with concept# in the n e t r  A# q t  a t  verb teaplater i s  belng derived from a Study of t h esurfrc9 syntax o f  ran@ 3000 Englirh Verb88 fhe actlve forms ofthe  verb$ have been t Z ~ r r i f l s d  rtcorb&n$ t o  subjectr objeetCm1~and compl~aent(r1) there Syntactic Patterns, augmented with  casenams,  ara used as a grammat t o  Cantrol th4 generation O t  t e x t ,Thlr text in turn i s  pasrad through a speech syntheri8 programand output by 4 VOTRAX speech rynth4o&zax, ThLr analyrar rhouldultimately benefit systems a t t s a p t l n g  t o  understand E r l ~ l i ~ h  i n p u tby praviding surface etructurs  t o  deep  c u l  i t rue turd  maps usingthe rare trmpirter r r  emp1Qytd by the generator.T h f r  reararch w4r rupportrd by t h e  Detenra Advaneed ReuearchProleeta Agancy a f  th* Dcprrtmmnt @t D ~ f e n r e  and manit6rrd by theU, 8 .
&rmY Rs#~rrch Offica under Cantract No, DAHC04~75-C-0006.TNTRQDUCTXONIt computer6 r t r  t o  canmonicrtr e f t r e t l v c l y  with p e o p l e ,they nust spark, or a t  irart  w r i t e ,  the  urcr*r  nrtur61 Language,The b u l k  o t  the work in co~pytatlonrl Llnguilticr has beendrvot rd  t o  computer undcrstandlnq o f  n a t u t a l  language i n p u t #  b u tr e l a t i v e l y  l i t t i e  rtfo<rt  ha8 been e%pend@d in d e v e l o p i n $  naturalLanguage output .
M o r t  Enplirh output systems hrve  been along t h el i n e  of  n f i l l  In the  blanku with Perhap& soma semanticcenrtrrint6 imporad!
thera have bean few attempts a t  languagegeneration from what one could crLl wsamrntic netR structures[8g@aon8 and 8locua, 1972; Sloeuar 1973; Goldman, 19741 ,PeFh&p@ generation i s  canr ldered  a much aas i s r  problem,  Theruccrrr o f  understanding ef forts  i r  generally bclisvtd to drprndon rome warkrble theory o f  Rdlrcaurrr 6rganlzatlonc which wouldrccbunt gar affect8 of  context and would ahow how i n i p h o r i c~ ~ p r e n 8 l ~ n s  (pronoun# and noun phrases) are resolved and how#rnt*nCeS r r o  order84 t n  the  b U t P U t r  A s  t t  hrppdnot therem@chanlr@r are p r ~ L # * l Y  those t h a t  r wrr8ponre g ~ n e r r t o r ~  mustIncorporate i t  i t  1 s  t o  appear Lntrlligent.
Tha lrtudy o fqrnrtrtion r i l l  p l a y  an important r o t s  in r o l v i n g  t h e  problem ofundrrttandino i f  i t  ern draonrtrrte & mapping t ~ o m  derp ramanticrtrUctura6 t o  ru t face  r t r t n g r ,bet  ua b r i e f l y  outlina gome relevant preccrrrs in the #peachunderstanding system bring d r Y c L 0 ~ 1 d  by 8RI and SDC (Walker a ta1.t 1 9 1 5 ~  and Rite., 1915).
The urar inltlatrs rrrrton byr r t r b l i r h t n g  conmunLc~tion with the ryrtrmf a l l  subarqurnt d i a l o g( i n p u t  and o u t p u t )  is manlter@d by a Wdircaurae m a d u l a 8  (Dautacb,11975) to maintain rn accurate ca~ntrerskition41 context ,  Ane x e e u t t v c  eserdinata# v a r i a u r  Knarladge sauxcos 4 c W r t i ~ rp r o s o d i c ,  syntactic, r~mrntie, pzagmrtlc, and d i ~ e e u r r c  t oBunderotrnbw c u c c e r s i v t  utt@rane@rrThe analyzed UttaFlnge i Q  then Pas8rB l a  ZRa "resPandarw PBItllanother eamponrnt o f  the dileaurtc module.
The responder mayc a l l  the pucrtlonransrcrrr i t  t h e  lnput i r  a ques t ion !
i t  mayc a l l  4 data  bead u p d a t e  Program I t  ths i n p u t  i s  r otatcmant o ffact1 or i t  may d r c l d r  an romc other  rppropriatc r e p l y .
Thacontent ab t h e  r@DpDnD@ I s  prrora  to t h e  gsnaratar~ perhapa # i $ hSome tndicrtian of hsa i t  is t o  be tarmulat@ds TRa r e p l y  may bsa rtsrcatypsd rsrpsnss ( w y @ 8 B p  "noM, "1 @e@C)I noun p h r a r s(nodel, r o@nt+nes ( v e r b  node ) r  O r r  e ~ ~ n t u 1 1 1 y ~  a paragraph,The q e n ~ P a Q ~ r  o u t p u t s  stettotyped raspanreg Pmmed$atslyt if!the  rcrpanrr i r  nor@ complicated [ a  "nounB nab@, * v e r b R  nads, arrvcnturlly r nrtwork) ,  r mbrr detallcd proptam i r  ragulrcd.
T h i sprogram nbLl dctrrmina exactly how the responge i s  t s  bsbormulrtad m a  &g NBI 61 OH teqUIRCQ 8 f  St!
i t  may bb ~ d ~ ~ l r 6 dt o  Chooag Verb@ and noun@ with which t o  @ X g s @ @ @  t h e  d e e p  C l S c  naec tructurrr ,  r r  wall r8 a ryntaetlc from.
f o r  the genaration.
Theg~narator P ~ O ~ U C I I  tha rrrponrr in wfrxtw form1 t h i r  in turn i rp & g s a d  t o  a B ~ O I C ~  tynthrllr program t a r  trrnrtarmatlon andcutput  by r comn@rCial VOTRAX r p r a c h  rynthe~izar.
C u r r ~ n t l y  noIsntQner intenstion sr r t r ~ a s  con%sWing i~ being p @ r t ~ r m e d ,8tnea t h e  major Bntmsost a t  this papsr  i t  in " t e x t H  ganaratlanefur ther  reference t o  t h e  synfhcrlg r t r p  r i l l  be m e d e nCQNSTRAXNTS Or?
RESPONDINGThere a r e  several  censLdcr8tianr i n v o l v e d  in respondingappropriateby t o  an utterance.
First, t h e r c  are  *conver:ctlanalP o ~ t U l & t e # "  (Gordon and  Lakoff, 1 9 7 5 1  8 h a r s d  b y  t h e  u6ers a ?
eLanuurprt there  p o t t u 2 a t e r  serve  t o  canstrain t h e  c o n t e n t  andform o f  c a ~ ~ u n i c a t i o n r  from the  speaker t o  the heerare Forinstance,  t h e  rperker  should not t a l l  t h e  hearer  r e ~ s t h i n g  thehearer all@&dy knows, l c r t  he  be  bore61 y e t  t h e  speaker cannott e l l  t h e  h c a r e r  samething the  h e a r e r  knows a b ~ o l u t e l y  nathlnqabout, or t h e  hearer r l l l  n o t  comprehend.
The ggenkee c h o u l dr e l a t e  k n t  ncwa in h i s  marsaga to t h e  p r t o r  knowledgs o f  t h ehearer;  t h i s  requires t h e  r p e r k c r  t e  have ti model of!
the  h a a r c fThere heuristic6 mur t  operate in canjunctbon w ~ t h  c w ~ ~ c ~ ~ n c ~producerw t o  constrain what may be o u t p u t  by  a q ~ e n t c n c e ngeneratore We are  only beg inn ing  t o  understanG h o w  tolncorparrtt  there  partuiater in a languagc g r o c e 6 ~ b n g  k y g t c m ,Then t h e r e  Is the  matter o f  con8tructlng the b a t i c  sentenceNormal English ryntax r c q u i r r r  a t  l t a a t  ant v e r b  In t h e  s a n t c n c a fchoor ing  a mrln verb  constrains the r u r f d c t  Rt ruc tu r e ,  Forinltrncer in thr  rblcncr of campounds any v e r b s  o t h e r  than t h emain v w b  will have t o  appear  i n  another Fornr nominal,i n f i n i t i v e ,  gerundr p ~ r t L c I p L @ ~  or subordinate C f a u c e ,  How d a e ct h e  relevant fnfarmatlon centaintd In & gementic n e t  Indicate t h arpproprlate farm?
The traditlondl answer Is "by meann of t h tl a x i C 0 n r U  We w i l l  Q X p l o r Q  t h e  relationship be tween  net @ r ~ dlexicon and rdvsnce a methodology f a r  raprelcntlng a map tramdeep  case structura t a  surface s tructure ,Thlr prgrr ~ O C U L I I  an a philosophy o t  sLnglam6cnfencrfarmattinqr cmeaaing a main vatbr choosing t n a  grass  structure s tt h e  o u t p u t  scntencer and deciding how t o  generate spgropriatanoun p h r a r a s ,  Qur exarnpl~a will anB1oY limPlifia4 semantic n e trtrueturrr,  remcrhat like t h o s e  in t h e  actual  5RI ~ a a r t i t i a n a dBlarntP~ neta 8ystam lHandrlxr 19751,  MMes In t h e  net mayraprerant phylicrl objects, rcllttonshipr, evantr, s b t r ,  r u l a s ,a r  uttsrencesr a0 in the  Qxempla balaw, Directad lab@Pled aregconncct nsdaa and rsprasant c e r t a i n  w p r i m i % i r a n  tlmc-invariantr a l a t  t s n r h t p a ,In t h e  n @ t  L r r q m ~ n t  above, t h e  U.8.
an4 t h r  U , K .
r r a  elcmrntl ( a )of t h e  g a t  o f  C Q M W ~ ~ ~ @ @ ,  as  EXP@tisnt@rr t hey  b a e h  participatein OWNLng rlfurtionl lnvolvlnp as OBJlctr p a r t i c u l a r  rubmariner)reeh rubmarlnt 11 an rlcmsnt o f  same c l a s s  o t  subm&r1ntsr rndt e ~ p l a f e s  f a t  Engllah rtntcner8, Bc c h o a ~ e  a simple verb f o rdernmstrrtfin a= OWN, W a  not@ t h a t  our v e r b  h $ @ v & t & 1VynanymrRr WAVE, POSSESS, and BELONG C10L S l m c  c l f h  of thcscverb8 (including OWN1 ha8 other  Ssnsr meanings, re  D a r l t  a nodetense they have in Comment this node w i l l  be &ha m ~ r o t o t y p Z c r l EOWHI in t h s t  It w112 incarpareta the u m s r n i n ~ R  of the altuatlsnand Ln that all inaerncrs a f  owning rituatians will b4 r e r a t ~ d  P QPOSSESSt HIVEI BELONG] and trmplatrr, Wsts that  one t e m p l a t er i l l  hat  r u f f t e a  Ear a l l  dour verbs;  For inatanesr the subject 0 %t h e  subject i r  t h e  FXPeriencQsrEXP own& OBJ 1 0BJ i s  owned by EXPEXP p o r o a s s ~ a  OBJ OBJ 1s  Pabl@lldd by EXBEXP h r r  aBJ OBJ Gdronv t o  EXPtOWK (EXP V&ct OBJ) (OBJ Vprr B Y  EXD] )[PO3SES8 (EX$ Yact OBJ) (063 Ypar B Y  EXPI]fHAVE (EXP Vact OBJ)] IBEbON6 (084 Vact  TO EXP)]New# i n  Order t b  rpcilc about  a p a r t i c u l a r  Owning s l t u a t b o n r  ntt % d W r  BELONG) and an a g ~ o e 1 a t e d  template (OBJ VaeE TO EXPI, andBut we have 4 problem!
t h e r e  i s  no indication o f  how tho EXPand OBd Qrgumcntt &re t o  be generated, NP will not alwaysr o f t i c r r  note for  inrtanec t h a t  t h e  predicate argument o fin %?shn hapad to go homen must ba an Infinltlva PhP48e (ratherthan the QetUfid p h r r e e  t h a t  NP might producal, Even a cursory8tUdY o f  a few hundred verbs in t h @  language shawl that they havevery defintts Cand regular1 C o n s t t a i n t &  on the syntactic form 0 %tnrrr canststucntr, Thaas cons tra int8  appear ts bc matters % o rthe lexicon rr thar  than the grammar, we assoc ia tenet) rather than imwemsnt them v i a  QP4MmBF TUI~II and wgcxpllcltly incorporate t h s  conrtltutnt t y p e s  in t h e  tamplatcstCOWM ((NP EXP) V a ~ t  (NP OBJ)) (CNP OBJ) Ypar BY (NP EXP))I(POSSES6 ((NP EXP) Vact (NP OBJ)) ((NP OBJ) Vpe8 BY (NP EXP))][HAVE ((HP EXPI Vact (NP OBJ))][BELONG ((NP OBJ] Yaet TO (NP EXP))IA a c t  of  patterns  liLe t h t r a  i s  a s s o c i a t e d  * I t h  r v s r y" P I O ~ ~ Y P .
verbn nods in the knswZ~dg@ b r a @ *  $t would seam thatm l l  r a  need i s  an P n t n r g s e b r  t k a b  g i v ~ n  any w ~ e ~ b  instanceRnode fn the  knowb@dg@ b ~ g e r  l 0 b k o  up t h e  psttbrns P Q T  t h a t  t y p eof!
n o d h  C ~ O Q G Q ~  Q V Q t b r  1 eOrraapdnding tsmglate for  the v e r b @and then Proeaedr t s  * e v r l u a t a n  fha p a t t e r n ov e r b  [ O W N ,  S - 3 8 , D W N I  sms b Q l ~ n $tamp [(MP OBJ) Vact TQ (NP EXpll(NP Odd) 913 t h e  S ~ a w o L fY I C ~  -13 BclonqsT O  --3 t o(NP G X P )  t h e  u,s,B u t  us t t l i l  r u n  i n t o  trouble  with o u r  r i m p l c  cchema,Consldsr the  rent@ncc, *John burned the taarf b l a c k , "\ ACT \ ~ B J  colorlBy uging t h e  simple p a t t e r n  U N P  AGT) Vact (HP OBJI) we coulde a s i l y  generate the *Lncorrrctw sentence, rJahn burned t h e  b l a c ktmr;trW since (NP QBJ) might include the color o f  t h e  t e 8 l t t 8  Meneed a pattern more llke ((NP AG,T) Vact [NP O W )  (nod  R ~ S I I I  Znwhich t h e  RESult of t h e  a c t i o n  wflk bc directly r e l a t e d  t o  t h everb.
Ha*rvcrr t h l r  1% n o t  q u i t e  enough a= rt l a a r t ,  n o t  Wtthouta very c0mpfic.tad Lntcrpretcr -* because the in terpre ter  mustRnoW t h a t  (NF OBJ) cannot i n e l u d e  h a  v r a b P s  RE8 ergurnawl[ b l a c k ) .
Thus# by convention, nay indicate an e x t r a  argumentt o  bs Passed t o  r eon6tttuant q a n s r d o r  (such as the Ounetisn NP)t e  denote the item(@) not t e  appear in the resultant canrtiturnta( I N P  ACT) Vact (HP OBJ RES) (Nod RES))*he pattern (NP OBJ RES) mrrnr Vgrnaratr an NP using t h e  OBJsctof t h e  VQrbr but do n ~ t  ine lude  t h a  RESult of ths v e r b  in thep a t t a r n o  ( L e e r  a pattern  copy far  every p o r r / b l r  *mmlrrLngflconstituent), This level  o f  detail w o u l d  be unrdasonable i d  f @ wother verbs cou ld  we t h i s  template; however, there are  rnt?t@ khanrstrtlvaly few tern~lrtarr baCh s h w ~ d  by several tang BB hundred@o f  verbs ,  t h e  urt of templates proves t o  ba q u i t *  hefpfullThere?
rrr other roureqr o t  potantla1 pat tern  p r o l t f a r a t i ~ n ~an impattant one being t h e  cambindtorial arrangamants o f  CQeaarguments o f  t ime,  manner, and athar  such ~ B ~ W b i ~ l l r  &it well aaother ( p o t 8 i b l Y  non*advrrbiall ease arguments such as sourer,$041, inttrumrnt, etc .
Some a t  $ha@@ a r g u m a ~ t d  are rath@rcenstralnsd I n  t h e i r  paaitiona in t h e  rantencar but others  may"esterday t h e  s h i p  satled f rom t h e  lighthouse to t h e  d o c k , ""The # h i p  s a i l r d  from ths lighthau8a t o  t h e  dock yesterday.
"wYast@rday t h e  s h i p  r a i l e d  t o  the  dock from t h e  l l g h t h o u r ~ .
~g t  i s  a f  cauara unrsrranabl@ t a  try t o  maintain a l l  the ~ a s 8 i b X epr f t r rnr !
Lnefcad r s  leave Lnrsrtlon o f  fhrte  rdvcrb ia f  rrguncntrt o  r ring11 heuristic routine ( d c r e r i b c d  below), There arerrvcral jurtitlcations for t h j l ,  amanp them8 t i )  the particularfarm 09 the verb cannot be grneobatsd until t h e  subject bbject(a5)@ r ~ r t @ L  p o s s i b l e  P L & C I ~ ~  and ( 3 1  t h e t a  r t a  some heuristicone may question whether passive tenplatao ahou ld  be atore41c@tt@inlyr they c o u l d  be d e r i v e d r  On t h e  other  hand, neglectingt~ rtare thorn woWd farce ur t o  Ind%bat@ wAth each Verb (84n03)~whether Lt can (or,  ronrtimar, m u s t )  be p a r r i v i z c d ,  I n d i c a t i n g" t r .
n ~ l t l v @ V i r  naf enough since there are tranritlvc vrrbr( i .
a , ,  vcrbr t h a t  taka an object) t h a t  cannot bc p s s s l v i z a d .8incs we hava t o  r t o r a  t h e  information anywayp we Can r a v e  damecads and Coaput$np t i a r  by storing thr  parslvr ternplat@.There arr rtvsrrl rraronr f o r  gcnrrafinq the verb  a f t e r  t h emafor @rgumentr.
F t r ~ t  t h e  lubjre t  auat be panerrfad ro t h a t  t h everb can b r  mrdc t o  aprrr  in nuabnr.
Second,  c e r t a i n  rare t r n r r r8tr true of  vrrb-prrticlr conblnitionc rkiir n o t  cL t h e  i c o l a t r dverb,  Btncr, in addition, prrticl@c must appear r f t t r  o b j e c t 8that  F Short  (like pranownrl b u t  b s f ~ r s  a b j a e t e  t h a t  are  long(like noun phraras), t h e  particle nurt b e  positionad a f t e r  t h eo b j e c t  j S  grncrrtcd.
F f n a L 1 ~ 1  inocrtian a f  soma advarbirbrt r .
~ ,  annot" rrqulrrr an ruxllirry v e r b  I- thug  v e r b  grnaratlonaurt fotlor rdvrrbirl grncratlon,VERB PATTERNST h i s  #tudy started with t h e  25 V e r b  pattcrnr" p r c r c n t c d  byHornby (1954) .
T h e ~ e  Ln t u r n  crwr f r o m  a d l c t g o n a r y  by Hornby ctel., ( 1948 ) .
V c t M  in t h e  dict$onary &re cZ&irltird & c ~ o r d i n g  t at h e i r  gross  syntactic p r t t r r n ~  a f  lubjrctp abjrct(s1, endc o m ~ ~ r a e n t C s ) ~  most o t  t h e  ~ a f t q r n r  r r a  rub-dlvgdade Thc rutkorrcl@La t h a t  there p a t f r r n r  WXXNnt f o r  a l l  conttruetlanr involving&I& t h e  verbs I n  theLr 4ietianary dndr by N t t n e f o n ,  In t h eIangUagr, I tl&SrifiertLon i s  not Zmmcdi&telY useful t oC ~ t h p U t d h t i ~ n a l  lingulrtr r l n c a  i t  doas not a d d r a g s  underlying~ e m a a t i c s ~  H a v a t k h e l e ~ ~ ~  i t  $r c l a r r  t h a t  i t  can ssrve ae t h sbrrlr for  r &artvatIan o l  Und@rlYlng c a r r  r t r u c t u h a rprrtlculatly, &r a bar16 f o r  Vplnrrrtion tcngl&tro,*There pattern8 &re b@lng canvar tad  i n t a  t a m p l e t @ @  much llkttho#* der ived arr l fe tr  t h a  tnrlyris i s  Baing perfarmed withralD*Ct t 4  300b V6tb l  drawn f r ~ ~  the dtctionary ( S ~ O C U W ~  toappear) ,  There templatea s e r v e  ro t h o  major portion o f  a modular*gan@ratLon grammarr* with t h e  r@aarlnder in t h r  farm of  h s u t i a ; t i ctunctianr t o r  constructing syntactic constituentr,N O U N  PHRASESWhat t o  IncluBb Ln a noun phrase should be another mrttarf a r  the d i r c a u r t e  module t o  judge,  There are no w ~ 1 l ~ E a r m ~ l a C a df u l r l  eccountlng far  anaphorl In EngliShj i n d e a d ,  there arc  trwwsflee8trbliehad parameters a t h e r  than t h a t  %ha hearer must  baa b l e  t o  r ~ a a l v a  t h o  (pto)nouns t o  t h e i r  reforants, The &D@ak@a?pS h o u l d  tmploy anaphoxa In order to avo la  t@petitlonr b u t  o n l y  P th i s  B0deX of!
t h e  hearer i n d i c r t o ~  t h a t  t h e  ~ ~ Q P C P  can t d s o l v d  theambiguity, Thcrc arc same lawcpowrr ptaneminalization ru l e r  t h a tcould be directly incarp0ra t sd  in a generator rafg@x$v%zalPanrfor  s ~ 1 1 p 1 0 .
N c V ~ P ~ ~ B ~ ~ S S ~  f t  IS i m p a s t a n t  L O  P ~ B Z I Z B  that Whenr generator i r  unaware of  t h e  eanvcrtafl~nal context, it l h a u l dnot indepsndantLy decide haw to ganaratr noun phpa1481 I t  CQRonly decide when t o  d6 r o e  This r b t u a t l o n  har not beenuniv+roalLy r@caqnf iedr  b u t  I t  1s becoming hnercarlngZY c l ea rt h r t  a Q Z ~ c s u r t e  m s d u h  must be canrubtsd during t h e  ~snarrtlanphrrs .
The direourre modal.
will not know ahead of timr what NPIare %O be  p r ~ d u e @ d  u n ~ @ s g  $t p4rforrn\@ many o f  ths g e m @  ~ P o r a t i a n at h a t  t h e  paneratar would do anyr4y.
Y a t  the cantcxt-8cnritivod e c i r i o n  s t r r t ~ g ~  may h.ve  t o  resorb ts rush m a a r u t b r  a rdlaewb$quating the proporrb o u t p u t  uoLwg khs model of &he hrsrerin order t a  d ~ t e r m b n r  what rnaphdra if4 teseavabla ,  t %  I runr@rsanrble t s  ancarporrte t h l g  s t r r t ~ g y  in ths gancr a t s r ~  r i n c afor  rany rrrsonr i t  nurt be p a r t  o f  t h e  d l r c o u r r r  modulc,Therefate t h r  genrrrtor S h o u l d  p a 6 S  any R n c u n U c o n s t i t u c n tt o  t h @  dJscourre module ( p l r h s p t  r i t h  i t s  rrcommcndation a b o u thow to PIgdUce the c o n s t i t u e n t , ;  t h ~  n o d u l e  m u s t  d c t c r m i n r  i f  apronoun or b&ga noun i t  ambiguour t o  t h e  h e a r e r ,  a n d ,  i f  s o ,  whatto add to t h e  noun ln order to makt the d e s i r e d  r e f e r e n t  e l e a r ,Ln the current SRI system, noun  prt t crnr  [Slocum, t a  r p P c a r )  a r aU S I ~  t o  control noun phrase grnrrrtian, Much like verb patterns,noun prttcrnr order t h e  ~ o n ~ t l f u @ n t 8  in t h e  p h r a r r  and indicatehow each eon8tLturnf Is t o  b e  generated by naming a functicn t obe Called with the nQtwerK ~anstftuentf((DET] [Ad3 QUA&) ( A d j  SIZE) ( A d j  SHRFE) (Ad1 COLOR) (N)]Batttrhr like t h i r  era  dirtributrd a b o u t  the network h i @ r @ r e h y jin t h e  f u t u r e @  t h @  Q L ~ c ~ u r r c  aadulc r i l l  dccLde t o r  each p q t t r r nconstituent whather f t  i 8  to appear i n  t h e  p h r r c s ,MEURZSTXC RULESR ~ r n b y  d+rcrlb@r three b s r l c  porltlanr f a r  a d v c r b r  in theclrussr "rentff pa#b$tionp R ~ t d n  pssltlonr and @ a n d u  ~ e r i t l o n ~Front poritgen rdvrrbr occur b a t a r e  the s u b j r c t t  w V e r t a ~ d a y  h@want hornat from these ha took  a t a x i , *  The i n t o r r o q l t i w a  r d v a r b r(a,g, now, when?
rrr typically c o n s t r d k n ~ d  t o  front Pooitionlother8 miy r p p r r t  thrrr  t a t  p u r p o r r r  o f  rmpharla cr e a n t r a l t .M i d  p e r l e i o n  rdvarba  occur v i r h  t h e  v e r b  (atringlt Sf therear* medal s r  ru#ilLrrv v a r h r s  t h e  dbvrrls occurs a f t o r  t h e  firstone, Oth@twi8r the r d ~ ~ r b  w ~ L L  appear b t k ~ r @  t h e  Verbl  cxcaptfbr *un11tre8#aQ~ f h l t e ~  o f  bar  a n d  4 0 1  ' ~ 4  O ~ ~ Q R  $36thararl @oh@ if8 t y p i ~ l l l y  buw8] *he I t  1t11I waiting,@End position adverbs occur r t trr  t h e  verb  and a f t e r  anyd b t e e t  or indirect object pteacnt, While t a l a t i v ~ l y  fen clrursshave mare t h r h  one adVQrb in tront parttian or mara t h r n  sns In@ i d  porltianr i t  i r  common t a t  r r v c r r l  .dV@rbS to appear in and~ a r l t l o n  in t h a  rams c lausal  *thaV p l a y  t h e  P iana  PeerlYtagcthrrw,hdvarblrlr o f  time (rnrrrring t h e  4uartiont wrh@n?w) usuallydeeut  in and p o a l t i o n ,  but may appear In grsnt position f a raaphrrtr or contrast.
kdverbialr o f  frequency (anrwsrlng t k aquettbon, wRaw ~ f t a n ?
~ l  can be split i n Q  t w o  groups, The f i r s tgroup is comgo@@d ~f ringla-nerd adverbs t h a t  tyalcally seeui fn& i d  porition b u t  a I r o  may br  in i n d  patLtianj th@ sacand i reosparsd a$ m u l t i p l s = w o r d  phrrrrr that  dgp&ar Pn end p a r i t i o n  e r ~&err Lrr9UrntlYr in t r e n t  Position.
Adverbs of duration [ V l f ~ r lhew lonqtw) u d u ~ l l y  have end parltlan, wbth %song p6sBtPon fbrempha8fs or csntxartr Adverb8 o f  place and diraetlen narrnall~hivQ and porition.
Advcrbr o f  4 rgrca  and manner have mid or  and~ O S I ~ L Q R I  depbnding  on t h r  advarb ,Along W i t h  ruah  ruler c o n ~ ~ r n l n g  t h e  BarLtionr O L  Vsriouttypes  o f  advrrbr,  there  murt b r  a mcchanirm t o  0rd.f t h e  rdvcrbrt h a t  arr L a  s ~ c u r  In t h a  "maQn petitLon, Thrrr r r a  eomeh @ u a l r t i c l ~  among rdverbi.11 o f  time Car p l a ~ 1 1  t h e  smallat unit81 ururlly pL4ccb t l r l t ,  unlrrl i t  t r  44604 48  &R sftarthauphtl@ t h e  army a t taeksd  thr village in farce  an a h o t  Augut t@ftrrnoon, j u s t  a t t a r  r i e r t a H ,  Adv@rbialr of p l a c a  end diroettonusually precede t h o r e  of frequency, which in t u r n  praeode t h o o ~a t  time,There ru le8  r e  iaplrmontsd  in th@ raRr r a u t L n ~  M a tproduce@ t h e  verb1 when @ template i s  f i r a t  f n e a r p r c k e d  =- N W heo B 8equencc of  function e r l l r  t h e  R V a ~ t w  or "Vpao kaya  arclonored.
once t h e  l U b j C C t ,  ~ b j C C t ( S 1  and compltmcnt(a) l n d i c r t r dby t h e  t cnplr tr  rrr Oanrrrfrdr t h i s  *clean upm routine $ 6  c a l l e d .Et employg the h a u x i t t i e k  d ~ r c r f b e d  abava La a d d  the adverb ia lC ~ r t & t f t U @ n t &  and VhFbr then concatsnatss the canstbtutnts t aproduce r complete @IruseIDXSCUSSTONfn theory, t h e  s e t  o f  porsiblc EnpLlrh rantcncrs i ai n f  fnZtsr Tha obv laor  q u s a t l b n  man ~ t @ @ @ r  O l f  sne t r i e s  toaccount ror them with tarnp l i t rrr  won t t h e r e  bc an i n f i n i t enumber eL t a a p l a t t ~ ?
~  The simple antxcr i r r  "Nor t o r  romc of theSam@ r e l l ~ n l  that  allow a finite grammar t o  gcnrrata  an intlnitenumber of itr2ngr.R One can p r e d u c a  rantrncer o f  arbitrary Lengthby ( 1 )  ~ T ' b l t t ' a t ~  anb@ddlngr and ( 2 1  a r b i t r a r y  conjuncttan@ Caw@B o t o  not do s o  by includdng a r b i t r a r y  n u m b e r s  sf distinct car@erpuacntl.
Evrn r a  t h e  numbcr o t  basic p a t t e r n s  c o u l d  bet n l ~ a m e l Y  I a f  gc , E v i d r n c a ,  horevrrr i l  t c  the con t r a ry !
t h el V e n t U I I  nUnbqr o f  t@Bpl.t@# would appear t o  b r  r e v e r a l  time8 t h enumber OI p l t t e r n r ~  awing to thr  SUbltitUtion o f  parttcularp r a ~ a r i t l o n e  Ear n p r ~ p w  In t h e  r ~ ~ t i c t l c   attaro or, and  t h aarrlgnaent o t  dltfetent c r l e  nancr t o  a p a r t i c u l a r  canstitusntdepending on t h e  p r r t i c u l a r  vrgb u r @ d .Dcotsch, Barbara G, Establishing Context in Task-Orientedb l a l d g ~ .
Prrrcnted a t  t h e  Thirteenth Annual Meeting o t  t h eAtsooiatian f a t  Computational Llngutrflcr, Barton, M a ~ r a c h u ~ d t t ~ ,S O  October * 1 Navarnber 1975,OoLdmrnr Neil H e  Computcr G ~ n e r a t i o n  o f  Natural L@nguagatram a D I I ~  Conceptual I r r e .
A 1  Memo 2 4 7 ,  A r t i t i ~ i a lI n t e l l i g e n ~ ~  Laboratory, 8trnford Univcr8ityt Str rnf  ord,C q i f  o r n i b  1974,Gordon DIvidt and Lakaff, George.
ConvearettonalPortulater.
Syntax snd Senanticst Volume 3 1  Speech  A c t s ,  Editedby Peter Cole and Jerry L. Morganr Acadrmia  P r s a ~ ,  New Ygrkr1975 rnH@ndtixt Gary G. Expanding thr Utility of  Bemantie Nafworkrf hrough Pact i t  toning, Advance Pav@r r of  t h e  Fourth InternationclJ o h t  Contcrrncs on Artificial Zntblllgenee, Tbiiiolr C s o r ~ i a ,U6SRl 3.8 Geptambcr 1975,  I I S a I Z l rHornby, 8 t r  Gatrcby, Vetand W~lK@flb@Xdr H Q  TheAdvmced Laatnet@@ Dictionary of  C u r r a n t  Engllrh.
Oxford P r @ r r ~London@ 1948,Rita.# H, Barry, Autoastic Speech Underrfandin~ SYrtamr.Proessdlngr, Eleventh Annual IEEE Camputst S a e l e t y  Contcranea,Harhlngton, D. C e r  9 - i  1 S ~ p t r m b e r  1975,Siamanrr Robtrt & I  and S ~ O C U ~ ~  Jonathan.
Gaa@rartinqEnglish Dlrcourcr from Senrntlc N I E W O ~ K C .
CommUnicstlonr ~t theACH, 1 9 9 2 ,  1 s t  8911909nS J o c u l ,  Jonathan.
Quartion Anarrring v i a  Csnanlcrl Verb8and Bsrnrnt l c  Madcllat t C~nsra t ing  %ngllrh trow the W O ~ Q ~ ,Technical Report H t = i 3 t  Department a&  Csapartrr bcbtawcar rUniveoritp a t  T a ~ a r ~  Austin@ Ttx.8, January 1913.$locum, Jonathan, Verb Patterns and Noun Pat tarns  InE n g l i ~ h t  A Cl&r  Anrlyrir.
A r t l f i ~ L a l  Lntrlliprncs Center, SRX4Man10 Parkt Californirr (in preparatlsn),American Journal of Computational Linguistic8 Microfiche 33 : 78Y a l e  U n i v e r s i t yNew Haven, C o n n e c t i u c t  0 6 5 1 1ABSTRACTTALE-SPIN is s program which makes up stories by using planningstructures as part of its world knowledge.
Planning structuresrepresent goals and the methods of achieving those goals.Requirements for  aparticular method depend on static and dynamicfacts about the world.
TALE-SPIN changes the state of the worldby creating new characters and presenting obstacles to goals.The reader / listener makes certain p l o t  decisions during thetelling of the story.
The story is generated using the notationof Conceptual Dependency and is fed to another program whichtranslates it into English.INTRODUCTION TALE-SPIN is a computer program which makes upstories about characters who plan how to solve certain problemsThis work was supported in part by the Adudnced ResearchProjects Agency of the Department of Defense and monitored bythe Office of Naval Research under contract N00014-75-C-1111.and t h e n  carry o u t  their p l a n s .
The planning procedures i n t e r a c twith a d a t a  base of knowledge about other characters and o b j e c t sin the world,  memory, and t h e  personal  r e l a t i o n s h i p s  which e x i s tbetween characters.
The stories are  r e p r e s e n t e d  i n  ConceptualDependency and are  passed t o  a program which expresses them i nE n g l i s h .
The r e a d e r  is asked t o  make c e r t a i n  decisions about thestory d u r i n g  t h e  process of generation.
Here is an example.J O E  BEAR WAS FAMISHED, HE DECIDED HE WOULD BE FULL IF HEATE SOME HONEY, HE WANTED TO F I N D  OUT WHERE THE HONEY WAS,HE THOUGHT TRAT IRVING BIRD WOULD TELL H I M  WHERE THE HONEYWAS.J O E  BEAR WALKED TO THE TREE WHERE I R V I N G  BIRD WAS.
HEASKED IRVING BIRD I F  HE WOULD TELL HIM WHERE T H E  HONEY WAS.>> DECIDE: DOES *IRVINGBIRD* AGREE?
*NOIRVING B I R D  REFUSED TO TELL JOE BEAR WHERE T H E  HONEY WAS.J O E  BEAR DECIDED IRVING B I R D  WOULD LIKE HIM TO GIVE THE WORMTO HIM.
J O E  BEAR A S K E D  I R V I N G  B I R D  I F  HE WOULD TELL HIM WHERETHE HONEY WAS IF HE GAVE THE WORM TO H I M .>>  DECIDE: DOES *IRVINGBIRD* AGREE?
*YESHE THOUGHT THAT HE WOULD LIKE JOE BEAR TO GIVE I T  TO HIM,HE WANTED TO FIND OUT WHERE THE WORM WAS, HE THOUGHT THATI R V I N G  B I R D  WOULD TELL HIM WHERE THE WORM WAS, J O E  BEAR A S K E DI R V I N G  BIRD I F  HE WOULD TELL HIM WHERE THE WORM WAS.>.> D E C I D E :  DOES *IRVINGBIRD* AGREE?
*YESIRVING BIRD DECIDED HE WOULD TELL JOE BEAR WHERE T H E  WORMWAS- I R V I N G  B I R D  TOLD H I M  I T  WAS A T  A PATCH OF GROUND,HE WALKED TO THE PATCH OF GROUND WHERE WORM WAS, HE TOOKTHE WORM HE WALKED TO THE TREE WHERE IRVING BIRD WAS.
H EGAVE THE WORM TO I R V I N G  B I R D .> >  DECIDE: DOES * I R V I N G % I R D k  K E E P  H I S  PROMISE?
*NOHE REFUSED TO TELL JOB BEAR WHERE -THE HONEY WAS.
JOEBEAR TOLD IRVING B I R D  HE XS GOING TO STRIKE H I M  IF HE DOES NOTTELL HIM WHERE T H E  HONEY WAS.> >  D E C I D E :  DOE$ *IRVINGBIRD* IGNORE THE THREAT?
*NOIRVING BIRD DECIDED HE WOULD TELL JOE BEAR WHERE THEHONEY WAS, I R V I N G  B I R D  TOLD HIM IT WAS AT THE BEEHIVE.80JOE BEAR THOUGHT THAT HENRY BEE WOULD GIVE THE HONEY TOW I M .
JOE BEAR WALKED TO THE BEEHIVE WHERE HENRY BEE WAS.
HEASKED HENRY BEE IF HE WOULD GIVE THE HOMEY TO HIM.>> DECIDE: DOES "HENRYBEE* AGREE?
*YESHENRY BEE DECIDED HE WOULD GIVE I T  TO JOE BEAR.
HENRYBEE GAVE IT TO JOE BEAR.
BE ATE IT.
HE WAS FULL.
THE END.Here is a s t o r y  which TALE-SPIN generates which  t h etranslator  is no t  y e t  capable of producing i n  ~ n g l i s h :JOE BEAR W4S HUNGRY.
HE THOUGHT TEWJ!
I R V I N G  BIRD WUQLDTELL HIM WHERE SOME HONEY WAS, HE WALKED TO TlWE TREE WHEREIRVING BIRD WAS.
HE ASKED IRVING B I R D  TO TELL H I M  WHERE THEHONEY WAS.
IRVING BIRD TOLD HIM THE HONEY WAS I N  A [ ce r t a in ]BEEHIVEJOE BEAR WALKED TO THE BEEHIVE WHERE THE HONEY WAS.
HEASKED HENRY BEE TQ GIVE HIM THE HONEY.
HENRY BEE REFUSED.JOE BEAR TOLD HIM WHERE SOME FLOWERS WERE.
HENRY BEE FLEWFROM THE BEEHIVE TO THE FLOWERBED WHERE THE- FLOWERS WERE.
JOEBEAR ATE THE HONEY,HE WAS VERY TIRED.
HE WALKED TO HIS CAVE.
HE SLEPT.THE END.TALE-SPIN starts with a small s e t  of characters and var iousfacts about them, I t  also  has a set of problem-solvingprocedures which generate t h e  events  i n  t h e  s t o r y .
Manydecisions have to be made as the story is being t o l d .
Some aremade at random (names of characters,  fo r  example) ; o t h e r s  deperldon the re la t ionships  between characters (whom one asks fo rinformation, fox example); others  are  made by the reader(whether a character keeps a promise, f o r  example) .TALE-SPIN generates  sentences using the representationsystem of Conceptual Dependency (Schank 1975).
Some of theConceptual Dependency (CD) s t r u c t u r e s  are passed on to a programwhich expresses them in E n g l i s h .
(The o r i g i n a l  v e r s i o n  of thatprogram was writ ten  by Neil Goldman fo r  the MARGIE system.
Thepresent vers ion has been modified by Walter Stutzman and Gerald8 1D e  Jong .)
The s e n t e n c e s  which a r e  not passed t o  t h e  t r a n s l a t o ra re  t h o s e  which r e p r e s e n t  e a s i l y  i n f e r r e d  i d e a s .
N e i t h e r  programy e t  worries  about  khe s t y l e  of e x p r e s s i o n ;  t h a t  is,  we worryabout whether t o  say a newly g e n e r a t e d  piece of t h e  s t o r y ,  b u tn o t  much a b o u t  how t o  say it.A TALE-SPIN s t o r y  involves  a single main character whosolves some problem.
To make t h e  p r o c e s s  i n t e r e s t i n g ,  obstaclesa re  i n t r o d u c e d ,  some by t h e  r e a d e r  i f  he c h o o s e s ,  and some a trandom.
For i n s t a n c e ,  t h e  r e a d e r ' s  d e c i s i o n  Chat I r v i n g  B i r d  isn o t  go ing  t o  t e l l  J o e  Bear what he wants t o  know p roduces  anobstacle t o  Joe  ear's p l a n  t o  f i n d  something o u t .
Someobstacles are c ~ a a t e d  when c e r t a i n  s c e n e s  a r e  included i n  thes t o r y .
For i n s t a n c e ,  t h e  i n i t i a l  world s t a t e  has no bees i n  it,but when it comes time i n  the s t o r y  t o  conjure up  some actualhoney, w e  do so by c r e a t i n g  a whole s c e n e  which i n c l u d e s  somehoney in a b e e h i v e  i n  a tree and a bee who owns t h a t  honey.
Thebee may o r  may n o t  be a t  home.
I f  he  is, J o e  Bear is go ing  t ohave another obstacle i n  h i s  p l a n  when he g e t s  t o  the beeh ive .The story is  t h e  n a r r a t i o n  of some of t h e  e v e n t s  which occurduring the s o l u t i o n  (o r  n o n - s o l u t i o n )  of t h e  problem.
( T h a t  is,more things happen i n  t h e  s o l u t i o n  o f  a problem t h a n  astoryteller says or n e e d s  to  say.)
TALE-SPIN d i f f e r s  from otherproblem-solving systems i n  several  ways : (1) the problems itsolves a r e  t h o s e  r e q u i r i n g  i n t e r a c t i o n  w i t h  o t h e r ,  u n p r e d i c t a b l ec h a r a c t e r s  ra ther  t h a n  with a d a t a  base o f  theorems or b l o c k s  o rc i r c u i t s ;  ( 2 )  t h e  world  i n s i d e  TALE-SPIN grows: new c h a r a c t e r sare created with  u n p r e d i c t a b l e  e f fec t s  on t h e  story; ( 3 )obstacles are d e l i b e r a t e l y  introduced; ( 4 )  a n   unsuccessful"story, one i n  which t h e  problem i s  not solved,  can be just a si n t e r e s t i n g  as a U s u c c e s s f u l ~  one.PLANNING STRUCTURES Planning s t r u c t u r e s  a r e  what we use t oorganize knowledge about planf ul a c t i v i t y ,  which is  representedi n  CD by a  chain of causes and effects.
The planning s t r u c t u r e sinclude d e l t a - a c t s ,  planboxes, packages, s c r i p t s ,  s igma-states ,r h o - s t a t e s ,  and p i - s t a t e s .A d e l t a - a c t  is used t o  achieve a p a r t i c u l a r  g o a l s t a t e .Delta-prox ( w r i t t e n  here a s  dPROXl i s  t h e  procedure fo r  becomingproximate t o  some loca t ion .
A de l t a -ac t  i s  defined as a goa l ,  ase t  of planboxes, and a dec i s ion  algorithm fo r  choosing betweenplanboxes.A planbox is a p a r t i c u l a r  method for  achieving a g o a l s t a t e .A l l  t h e  planboxes under a  de l t a -ac t  achieve t h e  same g o a l s t a t e .Each planbox has a set of precondit ions (some of which may bede l t a -ac t s )  , and a set  of a c t i o n s  t o  perform.
"UnconsciousNpreconditions a r e  at tached t o  planboxes which would never occurt o  you t o  use.
If you're t ry ing  t o  become proximate t o  X ,  youdon ' t  even think about persuading X t o  come t o  you when X is aninanimate ob jec t .  "
~ n c o n t r o l l a b ~ e "  precondi t ions  cannot be madetrue i f  they ' re  not  a l ready true.
(The assumption is t h a t  theyare sometimes t rue.)
" ~ l a n t i m e '  precondi t ions  a r e  t h e  t h i n g s  youworry about when you're making up t h e  p lan .
You don' t  worryabout "runtimen preconditions u n t i l  you're executing the plan.
("Planning" is a mental a c t i v i t y .
PLAN is, i n  f a c t ,  one of thep r i m i t i v e  ACTS of CD.
"Executing a plan" i s  performing al o g i c a l l y  s t r u c t u r e d  sequence  of  a c t i o n s  t o  achieve the g o a l  o ft h e  p l a n . )
I f  1 ' m  p l a n n i n g  t o  g e t  a Coke o u t  of t h e  machineu p s t a i r s ,  I wor ry  a b o u t  having  enough money, b u t  I d o n ' t  wor rya b o u t  walking up  the s t a i r s  until 1 ' m  a t  the  s t a i r s .
That themachine a c t u a l l y  has some Coke is an  u n c o n t r o l l a b l e  r u n t i m epr econd it i o n  : I d o n ' t  worry  a b o u t  i t  u n t i l  I g e t  t h e r e ,  andt h e r e ' s  n o t h i n g  I c a n  do  i f  it is empty when I g e t  t h e r e .A package is a set of p l a n b o x e s  which lead t o  a g o a l  ac tI' a t h e r  t h a n  state.
The PERSUADE package ,  f o r  i n s t a n c e ,  c o n t a i n sp l a n b o x e s  f o r  X t o  p e r s u a d e  Y t o  d o  some a c t  2 .
The p l a n b o x e sinclude a s k i n g ,  g i v i n g  l e g i t i m a t e  r e a s o n s ,  o f f e r i n g  f a v o r s  i nr e t u r n ,  t h r e a t e n i n g ,  and so on.Goalstates come i n  v a r i o u s  f l a v o r s .
T h e r e  a r e  t h e  goalswhich are  a s s o c i a t e d  w i t h  t h e  delta-acts:  t h e  g o a l  of dPROX ist o  be somewhere, t h e  goal of dKNOW is t o  f i n d  o u t  t h e  answer t osome q u e s t i o n ,  t h e  g o a l  of dCONTROL i s  t o  p o s s e s s  something.
B u tthere are also g o a l s  of s a t i a t i o n ,  called s i g m a - s t a t e s .
Forexample, sHUNGER o r g a n i z e s  t h e  knowledge abou t  s a t i s f y i n g  hunger( i n v o k i n g  dCONTROL of some food ,  e a t i n g ) .
TALE-SPIN a l s o  u s e ssigma-state knowledge i n  t h e  b a r g a i n i n g  process; o f f e r i n gsomeone some food i n  r e t u r n  for a f a v o r  i s  l e g i t i m a t e  s i n c e  itw i l l  satisfy a p r e c o n d i t i o n  f o r  sHUNGER.
There  are a l s o  goals ofp r e s e r v a t i o n ,  c a l l e d  pi-states,  which a re  most i n t e r e s t i n g  whent h e y  are  i n  danger  o f  be ing  v io l a t ed .
The l o g i c  o f  t h e  THREATENp l anbox  i n  t h e  PERSUADE package, f o r  example,  d e r i v e s  from t h ef a c t  t h a t  p h y s i c a l  v i o l e n c e  c o n f l i c t s  w i t h  pHEALTN.A SAMPLE DELTA-ACT: dPROX-TALE-SPIN d o e s  no t  i n c l u d e  a l l  n i n edelta-acts descr ibed  by Abelson ( 1 9 7 5 ) .
I t  conta ins  t h e  threewhich closely correspond to pr im i t i v e  acts:  dPROX (PTRANS) ,dCONTROL (ATRANS) , dKNOW (MTRANS).Here is an outline of dPROXt~ P R O X ( X , Y )  -- X wishes  to be near YPlanbox 0: if x is already near Y, succeed.Planbox 1: X qoes t o  Yuncontro l lab le  precondition: can X move himself?plantime precondition: P KNOW ( locat ion  o f  Y )runtime precondition: dLINK (location of Y)action: PTRANS t o  location of Yruntime precondit ion: i s  Y really there?
(We may haveg o t t e n  false information dur ing the  KNOW.
)Planbox 2: Y comes to Xunconscidus precondit ion:  i s  Y animate?uncontrollable precondition: is Y rno~  able?action: PERSUADE Y to PTRANS himself  to X (PERSUADE package)Planbox 3: Agent A br ings  X to  Yuncontrollable precondition: i s  X movable?action: X gets AGENT to bring X to Y (AGENCY package)Planbox 4: Agent A brings Y t o  Xunconscious precondition: i s  Y animate?uncontrol lable  precondit ion: i s  Y movable?action: X gets AGENT t o  bring Y to X (AGENCY package )Planbox 5: X and Y meet a t  l o c a t i o n  Zunconscious precondition: is Y animate?uneontrollabls precondition: is Y movable?a c t i o n s :  PERSUADE Y t o  PTRANS h i m s e l f  t o  Z and dPROX(X,Z)THE DATA BASE Planning s t r u c t u r e s  a r e  e s s e n t i a l l y  p r o c e d u r a l .-- --The non-procedural  d a t a  base  used by the planning s t r u c t u r e s  i sd i v i d e d  i n t o  f i v e  classes.1.
Data about i n d i v i d u a l  PPs ( P i c t u r e  P roduce r s ,  nouns)where a p p l i c a b l e  : h e i g h t ;  weigh t ;  where t h e i r  home is; whot h e i r  a c q u a i n t a n c e s  are.2.
Data common t o  classes of PPs (e .g.
,  d a t a  common t o  a l lbirds) where a p p l i c a b l e :  what t h e y  ea t ;  what t h e i r  g o a l s(sigma-states) a r e ;  whether  t h e y  are  animate ( capab le  o fMBUILDing) , movable, self -movable ; how t h e y  move around.3 Sigma-state  knowledge i n d i c a t i n g  how t o  ach ieve  as igma-s ta te  and what t h e  p l a n t i m e  p r e c o n d i t i o n s  a r e  t h a t  someoneo t h e r  than  t h e  planner can ach ieve .
T h i s  is used i n  t h ebargaining process .
J o e  Bear o f f e r s  t o  b r i n g  I r v i n g  Bird a wormbecause dCONTROL (FOOD) i s  a p lan t ime  precond it ion for sHUNGERwhich J o e  Bear can  a c h i e v e  f o r  I r v i n g  Bird.
There are noplantime p r e c o n d i t i b n s  f o r  sREST t h a t  he can ach ieve  f o r  I r v i n gBi rd  ( excep t  maybe t o  l e a v e  him a lone )  .4.
Memory: what everybody knows ( t h i n k s ,  believes) ; w h a tJoe Bear knows; what J o e  Bear t h i n k s  I r v i n g  B i ~ d  knows; e t c .Planbox 0 of BKNOW, f o r  example, a c c e s s e s  Memory t o  test  whetherJ o e  Bear a l r e a d y  knows t h e  answer t o  t h e  q u e s t i o n  be ing  asked, o rwhether it i s  pub l i c  knowledge.
Since both t h e  q u e s t i o n  and t h efacts i n  Memory are r e p r e s e n t e d  i n  CD, t h e  p a t t e r n  match is  v e r ysimple, taking advantage of CD's c a n o n i c a l  r e p r e s e n t a t i o n  ofmeaning.5.
Personal  r e l a t i o n s h i p s .
T h e  r e l a t i o n s h i p  of onecharacter to another is d e s c i b e d  by a p o i n t  o n  each of t h r e escales:  COMPETITION, DOMINANCE, and FAMILIARITY.
S c a l e  v a l u e srange from -10 to +I@.
The relation " i s  a f r i e n d  o f "  i srepresented by a certain r a n g e  on each of t h e  three scales.
Ther e l a t i o n  "would act  a s  an agen t  f o r "  is  r e p r e s e n t e d  by adifferent range.
The s e n t e n c e  " J o e  Bear t hough t  that I r v i n g  B i r dwould t e l l  him where t h e  honey was" comes from the " A s k  a F r i e n d "planbox of dRNOW.
There is a procedure w h i c h  goes t h r o u g h  a l i s tof Joe Bear's acquaintances and produces a l i s t  of  those whoq u a l i f y  as " f r i e n d s " ,  i.e., those who fit somewhere within the" f r i e n d n  range.Relations are n o t  symmetric: Joe Bear may t h i n k  of  IrvingB i r d  a s  h i s  f r i e n d ,  so h e  might ask him where t h e  honey is, b u tIrving Bird may n o t  th ink  of Joe Bear a s  h i s  f r i e n d  a t  a l l ,  i nwhich case he might r e f u s e  to  answer Joe Bear.Relationships can change.
If Gee Bear becomes s u f f i c i e n t l yaggravated a t  h i s  " f r i e n d "  I r v i n g  B i r d  and has to t h r e a t e n  t obash him i n  the beak i n  order t o  g e t  him to t e l l  him where t h ehoney is, t h e n  the relationship between them d e t e r  i o r a t e  s .We plan t o  extend t h i s  feature t o  d e s c r i b e  a c h a r a c t e r ' s"default" r e l a t i o n s h i p :  how he relates t o  t o t a l  s t r a n g e r s .
T h i swould n o t  necessarily be t h e  p o i n t  (0,8,0) b u t  r a t h e r  some p o i n twhich would be used to give  a rough i n d i c a t i o n  of  t h e  character's"persoaal i tyn .
Big bad Joe Bear might rate a t  ( + 6  ,+9,+4)  , wheresmall meek B i l l  Worm m i g h t  r a t e  a t  (-6 ,-la , - 4 )  .Changing a r e l a t i o n s h i p  i s  a type of g o a l  we haven't y e tc o n s i d e r e d  i n  much d e t a i l ,  a 1  t h o u g h  g o a l s  of r e l a t i o n s h i p s( r h o - s t a t e s )  c l e a r l y  ex i s t .
The p r o c e d u r e  for g e t t i n g  someone t ol i k e  you ( r L I K E )  might c o n t a i n  p l anboxes  f o r  ATRANSing g i f t s ,MTRANSing sweet n o t h i n g s ,  e t c .
,  i n  a d d i t i o n  t o  changing your ownf e e l i n g s  toward that p e r s o n  so t h a t  i f  he  (she) asks you t o  dosometh ing ,  you d o n ' t  refuse.I n f o r m a t i o n  g e t s  into t h e  da ta  base i n  several ways.
Memoryda ta  gets  produced d i r e c t l y  by t h e  p l a n n i n g  s t r u c t u r e s .
Changesi n  relations are s i d e - e f f e c t s  of  t h e  present se t  of p l a n n i n gs t r u c t u r e s .
B u t  t h i n g s  have f o  s t a r t  somewhere.
There is  af u n c t i o n  CREATE ( X )  which i n v e n t s  a new item of type X ( e .
g .
,bear,  f l o w e r ,  b e r r y ) .
Associated w i t h  each type of item is asmall procedure called a picture which i n v e n t s  t h e  d e s i r e d  i t e mand o t h e r s  as r e q u i r e d .
For example,  when we c r e a t e  some honey,we also create a beehive, a t r ee ,  and a bee.
The honey is"owned" by t h e  bee  and i s  i n s i d e  t h e  b e e h i v e  which i s  i n  t h etree.
The bee may o r  n o t  be a t  home.
Randomly chosen  names,heights, w e i g h t s ,  etc., are  a t t a c h e d .
A l l  t h i s  d a t a  is  t h e nadded t o  Memory.The CREATE f u n c t i o n  is called when needed; remembet t h a tTALE-SPIN models t h e  p r o c e s s  of making - ue a s t o r y  a s  you goa long .
We will now f o l l o w ,  i n  d e t a i l ,  t h e  p r o d u c t i o n  of thesecond sample story.CREATE a bear, which i n v o k e s  a p i c t u r e  p r o c e d u r e  whichinvents a beat.
Assume the bear is named J o e ;  although since t h ename is  chosen a t  random from a list of f i r s t  names, it i s  justa s  o i t e n  I r v i n g .
A c a v e  is also i n v e n t e d ,  and has J o e  i n  i f .~ o e ' s  l o c a t i o n  becomes p u b l i c  knowledge.CREATE a b i r d ,  named I r v i n g ,  and a tree which is  h i s  home.~ r v i n g ' s  loca t ion  is a l s o  now p u b l i c  knowledge.Assert  t h a t  Joe i s  hungry.
T h i s  fact enters ~oe's Memory.We also "say" this: that is, we pass i t  to t h e  E n g l i s htranslator which t h e n  produces  t h e  sentence "JOE BEAR WASHUNGRY N .Invoke sHUNGER.Choose at random a food that bears e a t :  honey.
A s s e r t  thatJoe i s  now p lanning  t o  achieve t h e  goal (sigma-state) ofs a t i s f y i n g  his hunger.
Assert that he has d e c i d e d  that eatingt h e  food can l e a d  to  t h e  achievement of h i s  goal.sHUNGER calls dCONTROL (honey)  .
T h i s  forms a new goal,namely, t h a t  Joe have some honey.
CONTROL'S "Planbox 0" asksMemory i f  t h e  goal is a l s e a d y  true: does Joe a l r e a d y  have somehoney?
The answer comes back: n o .
A plantime p r e c o n d i t i o n  ist o  know t h e  location of some honey, so dCONTROL c a l l s  dKNOW(wherei s  honey?).
(The question is r e p r e s e n t e d  in C D ,  not English.
)dKNOW forms the  new g o a l .
KNOW'S "Planbox 0" asks Memorywhether Joe knows the  location of any honey.
Memory says no.Planbox 1 tests whether the  question can be answered byconsu l t ing  a standard reference (e .g .
,  "What time is it?")
.
T h a tf a i l s .
Planbox 2 tests whether  t h e  question r e q u i r e s  expertise:no.
Planbox 3 t e s t s  whether t h i s  i s  a "general in format ion"q u e s t i o n .
I t  i s ,  so w e  a s s e r t  t h a t  Joe i s  p lanning  to answert h i s  q u e s t i o n  u s i n g  Planbox 3 ("Ask a Friend").Planbox 3 starts.
Choose a f r i e n d :  I r v i n g .
dKNOW callsthe PERSUADE package t o  t r y  t o  g e t  I r v i n g  t o  answer ~ o e ' sq u e s t i o n .PERSUADE a s k s  Memory whether  Joe t h i n k s -  that I r v i n g  c a n n o tanswer  t h e  question.
~ n s w e r :  no.
I r v i n g  is  a " f r i e n d " ,  so w et r y  t h e  ASK p lanbox .
A s s e r t  t h a t  Joe t h i n k s  t h a t  Irviag willt e l l  him where t h e  honey is.
PERSUADE c a l l s  dPROX(,Irving),  s i n c eJ o e  needs  t o  speak t o  I r v i n g .dPROX asks Memory whether  Joe i s  a l r e a d y  n e a r  I r v i n g .Memory says no.
Planbox 1: i s  Joe se l f -movable?
Yes.
A s s e r tt h a t  Joe i s  planning t o  be nea r  I r v i n g  by go ing  there himself.dPROX c a l l s  dKNOW (where i s  I r v i n g ? )
.~KNOW'S "Planbox 0"  asks Memory whether Joe a l r e a d y  knowswhere I r v i n g  is.
The answer comes back: y e s ,  I r v i n g  is i n  ac e r t a i n  t r e e .
dKNOW r e t u r n s  t h i s  to ~ P R O X .
(We w i l l  omit  futurereferences t o  "Planbox O n .
)dPROX a s s e r t s  that Joe walks t o  t h e  t r e e  where I r v i n g  is .We a s k  Memory whether  I r v i n g  is  a c t u a l l y  there.
H e  i s ,  so dPROXh a s  achieved its desired g o a l ;  his change  i n  l o c a t i o n  is addedt o  Memory.
dPROX r e t u r n s  t o  PERSUADE.30e a s k s  Irving where some honey i s .
The reader now g e t s  t odecide whether  I r v i n g  a g r e e s  t o  do  39.
Assume t h e  r e a d e r  saysy e s .
We ask Memory whether Irving a c t u a l l y  knows where any honeyis .
I f  h e  d i d ,  w e  would have I r v i n g  tell h im,  but he doesn't, sowe CREATE some honey: a s t o r y t e l l e r  can c r e a t e  s 6 l u t i o n s  t op rob lems  as well a s  o b s t a c l e s !
Some honey is  i n v e n t e d ,  alongw i t h  a beeh ive ,  a tree, and a bee (Henry)  who is  a t  home.
I r v i n gt e l l s  Joe that t h e  honey is i n  t h e  beeh ive .
ASK s u c c e e d s ,  so90PERSUADE succeeds, so dKNOW succeeds: Joe knows where some honeyis .Back i n  dCONTROL, we ask Memory whether [Joe t h i n k s  t h a t ]anyone owns the honey.
Memory says t h a t  Henry does ,  soCONTROL'S Planbox 1 ("Free f o r  t h e  taking") fails.
Planbox 2 i st o  PERSUADE Henry t o  give t h e  honey to Joe.Given no re la t ion  between Joe and Henry ( t h e y  d o n ' t  knoweach other) , the on ly  planboxes i n  PERSUADE which can be used areASK and INFORM REASON.We try ASK f i r s t .
This calls dPROX<Henry) which succeedss i r f c e  Joe knows where Henry is;  we omit the d e t a i l s  h e r e .
Joeasks Henry to g i v e  him the honey,  and t h e  reader decides thatHenry re fuses .We try INFORM REASON next.
We c h o o s e  a goal of ~enry's andb u i l d  a causal chain backwards from t h e  goal,.
For example, oneof  Henry s goals i s  t o  "eat" f lowers .
(TALE-SP'IN t h i n k s  thatwhat beesa d o  t o  f l o w e r s  i s  e q u i v a l e n t  to e a t i n g . )
I n  order t oe a t  a f l o w e r ,  you have to  "control" a flower, which r e s u l t s  fromsomeone (possibly you yourself) ATRANSing the flower to you.
Wetest  whether what Joe i s  t r y i n g  to PERSUADE Henry to d o  matchesATRANSing a f l o w e r .
I t  doesn't, (Joe i s  trying to PERSUADEHenry to  A-TFWNS t h e  honey t o  him.)
We t h e n  consider t h a t  i no r d e r  to ATRANS a flower, you.
have to be near t h e  flowes, whichr e s u l t s  from someone PTRANSing you t o  t h e  f lower.
Does thismatch?
No .
We r e p e a t  this process  a few times, t r y i n g  toconstruct a short i n f e r e n c e  c h a i n  which -connects= what Joe i strying to  persuade Henry to do with one of Henry's g o a l s .
INFORMREASON f a i l s ,  and we r e t u r n  t o  dCONTROL.The n e x t  P l a n b o x  i s  ca l l ed  "Steal".
We ask Memory ~ h e t h e rHenry is home: i f  he  w e r e n ' t ,  J o e  would simply t a k e  t h e  honey.But Memory t e l l s  u s  t h a t  Henry  is  home, so STEAL c a l l s  PERSUADEt o  get Henry  t o  l eave  home; that is,  Joe is now going t o  t r y  t op e r s u a d e  Henry  t o  PTRANS h i m s e l f  f rom t h e  h i v e .I n  t h e  c o n t e x t  o f  STEAL,  t h e  A S K  p l a n b o x  i s  n o t  u s e d .
Joetries INFORM REASON again and succeeds i n  producing the f o l l o w i n gchain: we g e t  t o  t h e  idea of someone PTRANSing h i m s e l f  t o  af l o w e r  again a s  we d i d  before, b u t  w e  n o t i c e  t h a t  t h i s  does m a t c hwhat  we are t r y i n g  to persuade Henry  to do:  the c o n n e c t i o n  i s4 t h a t  Henry will PTRANS h i m s e l f  from the b e e h i v e  to t h e  f l o w t x .Joe now c o n s i d e r s  the p r e c o n d i t i o n  for ~ e n r y  's PTRANSing himselfto the f lower ,  namely, t h a t  Henry  h a s  t o  know where  the floweris.
Memory does n o t  i n d i c a t e  t h a t  J o e  t h i n k s  t h a t  Henry knowswhere a flower is ,  n o r  does Joe know where a f l o w e r  is ,  butr a t h e r  than invoke dKNOW(where i s  a flower?
), w e  CREATE a f l o w e r :t h i s  i s  l e g i t i m a t e  i n  a plan to s t e a l  s o m e t h i n g .
Joe now tellsHenry t h a t  there i s  a  flower i n  a c e r t a i n  f l o w e r b e d ,  and thenasks Hengy i f  he  would like t o  fly to  t h a t  f l o w e r .
Henry aqreesand flies away.
PERSUADE s u c c e e d s ,  and r e t u r n s  t o  dCONTROL.Joe now takes the honey f rom the h i v e ,  s o  dCONTROL succeedsand r e t u r n s  t o  sHUNGER.
Memory is m o d i f i e d  t o  i n d i c a t e  t h a t  Joeknows t h a t  he h a s  t h e  honey ,  b u t  t h a t  Henry d o e s  not.Joe  now oats t h e  h o n e y ,  and h a s  ach ieved  t h e  sigma-state ofn o t  b e i n g  h u n g r y .
But, when bears e a t ,  t h e y  become t i r e d ,  sosREST i s  invoked.sREST i s  v e r y  s h o r t .
I t  r e q u i r e s  a dPROX ( c a v e )  , which  i se a s i l y  a c h i e v e d ,  and t h e n  Joe goes t o  s leep .Since t h e  main goal has been a c h i e v e d ,  and the g o a l  p roducedas  a c o n s e q u e n c e  of  that g o a l  has a l s o  been a c h i e v e d ,  t h e  s t o r yends.What d i s t i n g u i s h e s  s t o r i e s  from s i m p l e  s e q u e n c e s  of  e v e n t s ?Coherency  i s  i m p o r t a n t :  t h e r e  has t o  be a l o g i c a l  flow f rom onee v e n t  t o  t h e  next.
T h i s  i s  r e p r e s e n t e d  i n  CD a s  a c h a i n  of a c t swhich r e , s u l t  i n  s t a t e s  which e n a b l e  f u r t h e r  a c t s  and s o  on.I n t e r e s t  is  i m p o r t a n t :  s o m e t h i n g  i n t e r e s t i n g  o r  u n u s u a l  h a s  t ohappen o r  else t h e  r e a d e r  w i l l  begin t o  wonder what  the p o i n t  oft h e  s t o r y  is.
TALE-SPIN c r e a t e s  impediments  t o  g o a l s ,  o n  t h ea s s u m p t i o n  t h a t  t h e  overcoming  of o b s t a c l e s  can make ani n t e r e s t i n g  s k o r y .
"One d a y  Joe Bear w a s  hungry .
T h e r e  was ajar  o f  honey r i g h t  n e x t  t o  him.
He a t e  it.
The end" i s  n o t  as t o r y .
It s h o u l d n ' t  be t h a t  e a s y .On t h e  o t h e r  hand ,  it s h o u l d n ' t  be t o o  h a r d  e i t h e r .
I nt h e o r y  a t  least, t h e r e  i s  a c o s t - e f f e c t i v e n e s s  ca l cu lus  whichpeople employ when d e c i d i n g  how much e n e r g y  t o  expend on as u b g o a l ,  based a n  how much t h e  g o a l  is w o r t h  t o  them.
T h i sp r o c e s s  p r e v e n t s  t h e  p l a n s  f rom b e i n g  t o o  complicated.A s  t h e  story i s  g e n e r a t e d ,  v a r i o u s  p l o t  d e c i s i o n s  have t o  bemade.
Some d e c i s i o n s  are made a t  random, o t h e r s  a re  made by t h er e a d e r .
When J o e  Bear t h r e a t e n s  I r v i n g  Bird because I r v i n g  B i r dwon't t e l l  him where t h e  honey  is ,  t h e  r e a d e r  g e t s  t o  decidewhether I r v i n g  B i r d  is  g o i n g  t o  i g n o r e  t h e  threat.We use  p l a n n i n g  s t r u c t u r e s  b e c a u s e  any program which r e a d so r  w r i t e s  a s t o r y ,  whether of the f o l k t a l e  v a r i e t y  or the NewYork  Times v a r i e t y ,  m u s t  have a  model of the l o g i c  of humana c t i v i t y .
I t  might be e a s i e r  t o  simulate t h e  genera t ion  of ah igh ly  s t y l i z e d  form of s t o r y ,  a s  Klein ( 1 9 7 4 )  has done using~ r o p p ' s  a n a l y s i s  of a  c l a s s  of Russian f a i r y  tales, but  the re  isl i t t l e  g e n e r a l i t y  there .
One could use any of t h e  wel.1-knownproblem-solving systems l i k e  MICRO-PLANNER, b u t  t h e  s t o r y  is t h eproof procedure, and the procedure used the re  does not  correspondt o  my conception of how people solve  problems.
hat's not ac r i t i c i s m  of MICRO-PLANNER a s  a  problem-solver, b u t  only a s  amodel human problem-solving .user i n t e r a c t i o n  was included for  two reasons.
F i r s t ,  thei n t e r a c t i v e  f e a t u r e  now serves  a s  a h e u r i s t i c  for placing boundson the  complexity of the s to ry .
Beyond, some number of obs t ac l e st o  the g o a l ,  a  s t o r y  becomes a k i n d  of joke.
Second and moreimportant ,  ex tens ions  t o  TALE-SPIN w i l l  include moresoph i s t i ca t ed  responses than t h e  present yes/no var i e ty .THE FUTURE OF TALE-SPIN.-- - There a r e  a  l o t  of th ings  t h a tTALE-SPIN doesn ' t  do ye t  t h a t  would improve it a s  a s t o r y t e l l e r .Here a r e  some of the  t h e o r e t i c a l  problems we w i l l  be working oni n  the  immediate f u t u r e .
(1) Bargaining, a s  it e x i s t s  now i nTALE-SPIN, i s  a p r e t t y  one-sided a f f a i r ,  w i t h  the main charactermaking a l l  t h e  proposals.
I rv ing Bird i s  j u s t  a s  l i k e l y  t osuggest  t h a t  Joe Bear go g e t  him a  worm as Joe is  t o  o f f e r  to  doSO Counter-proposals a r e  c e r t a i n l y  common enough.
( 2 )  Futures t o r i e s  should include planning on t h e  p a r t  of more than onecha rac te r .
The presen t  s t o r i e s  a r e  a l l  "about" the bear ,  ando n l y  i n c i d e n t a l l y  involve the b i r d  and o t h e r  c h a r a c t e r s .
Thestories a re  more concerned  w i t h  r e a c t i o n  t h a n  i n t e r a c t i o n .
( 3 )For every p l a n ,  there may be a c o u n t e r - p l a n ,  a plan t o  block t h eachievement of a goal: a p lan  for  keeping away from somethinq orsomeone; a plan not t o  f i n d  o u t  something, o r  to be c ~ n v i n c e dthat it isn't t rue ;  a plan t o  g e t  r i d  of something you own.
( 4 )How much of a plan do people consider i n  advance?
We have madesome efforts i n  t h i s  area  by making t h e  d i s t i n c t i o n s  betweenkinds of p r e c o n d i t i o n s .
C e r t a i n l y  t h e  most important  improvementhere will be t h e  c o s t - e f f e c t i v e n e s s  r e a s o n i n g .
( 5 )  The theory oft e l l i n g  s t o r i e s  (what t o  say) now implemented i n  TALE-SPIN i s  toexpress v i o l a t i o n s  o f  s i g m a - s t a t e s  ("Joe Bear was h u n g r y n )  ,p h y s i c a l  acts ,  and those mental ac t s  which provide m o t i v a t i o n  o rj u s t i f i c a t i o n  for l a t e r  events.
The r e a d e r  is assumed t o  be ablet o  infer t h e  rest.
T h i s  seems t o  work r e a s o n a b l y  we11 for t h epresent simple s t o r i e s ,  but may have  t o  be modif ied  to s u i tl o n g e r ,  more complicated storie s.REFERENCESAbe l son ,  Re P. (1975) .
Concep t s  fo r  representing mundane realityi n  p l a n s .
I n  D, Bobrow and A. Collins, eds.
Representationand understanding: Studies i n  c o g n i t i v e  science.
Academic '- 7 P r e s s ,  New York.R l e i n ,  S. e t  a1 ( 1 9 7 4 ) .
Model l ing  Propp and L e v i - S t r a u s s  i n  arneta-symbolic s i m u l a t i o n  system.
T e c h n i c a l  Report 2 2 6 ,University of.
Wisconsin a t  Madison.Schank,  Ro C. (1975) .
Concep tua l  I n f o r m a t i o n  P r o c e s s i n  .American E l s e v i e r ,  New YZ *~bis includes -___r% contri u t i o n s  byN e i l  M. Goldman, C h a r l e s  J.
~ i e g e c  111, and Chris topher  K.Riesbec k ,Schank, R. C. and Abelson, R. P. ( 1975 ) .
Scripts, plans andknowledge, In Proceedings of t h e  4 t h  I n t e r n a t i o n a l  JointConference  on Artificial I n t e l l i g e n c e .
