LOCAL AND GLOBAL STRUCTURES IN DISCOURSE UNDERSTANDINGM.
Koit, S. Litvak, H. Oim, T. Roosmaa, M. SaluveerArtificial Intelligence LaboratoryTartu State University202400 Tartu, Estonian S.S.R., U.S.S.R.(Oim's present address is Estonian Department, University of Helsinki,Fabianlnkatu 33, 00170 Helsinki 17, Finland.
)I INTRODUCTIONWe are interested in the nature of contentstructures in terms of which it would be possibleto account for reasoning processes inunderstanding natural language texts.
One of themost crucial problems here at the present time is:how and by which mechanisms these reasoningprocesses are controlled and directed.
As theemphasis in the design of discourse understandingsystems so far has been on the problems ofknowledge organization and representation, we areonly beginning to guess what the correspondingprocessing mechanisms are and how they function,although an increasing number of papers has beendevoted to these problems as well.
There arestudies of the relation of understanding to suchtypes of knowledge processing as problem solvingand planning (e.g., Black and Bower 1980, Wilensky1981).
Various types of content units andstructures needed to account for knowledgeprocessing have been proposed in the generalcontext of modeling discourse understanding (e.g.,Allen 1981; Cohen 1981; Dyer 1982; Wilensky 1980).We ourselves have discussed an approach toknowledge units and processing mechanisms inquestions, as a part of a computer system whichunderstands stories of a certain kind (Litvak etal.
1981), as well as on a more theoretical level(Oim 1980).To our mind, there are two general faultsthat characterize present day computer systemsdesigned to understand coherent natural languagetexts.
First, they make too heavy and rigoroususe of predetermined knowledge schemes relating tothe subject matter of texts and to theorganization of reasoning processes which carryout understanding.
Secondly, these predeterminedknowledge and reasoning structures operate onlevels of organization that are too far away fromthe level on which immediate text contents arepresented.
So the understanding processesmodelled by these systems are prevailinglyknowledge-driven and, secondly, reflect relativelyhigh level, global macro-operatlons upon eventsdescribed in a text.
There is little knowledge ofthe ways in which a text itself dynamicallymanipulates reasoning processes and decisionmakings of human understanders.We do not want to claim that global schemesare not needed at all in discourse understanding.But there is a theoretical and empirical lacunabetween this global level of processing, wherestory schemes or plan and goal hierarchies areacting, and the level of immediate textpresentation.II LOCAL REASONING STRUCTURESThere should exist, between two levels, a"local" level of processing and, correspondingly,"local reasoning mechanisms" that are sensitive tothe ways in which immediate text contents areorganized.
These local mechanisms should operatein terms of knowledge units and structures theyobtain from text, on the one hand, and they shouldreflect intuitive attention, interest and judgmentprocesses of the understander that occur duringreading a text, on the other.
They should beusable in interpreting very different kinds oftexts--just as words, for instance, when looked atfrom the side of their contents, constitutepreorganized "packets" of knowledge which can beused to build up different kinds of sentences andtexts.
There exist already some interestingstudies dealing with such local text processingmechanisms (e.g., Granger 1982).The crucial question here is, how do thelocal thought processes of the understanderdevelop; how does his reasoning proceed from onestate to another under the influence of theincoming text.
There should exist certain unitsby which these processes could be described andpredicted on this local level, certain "packets of(local) thought processes.
"We want to specify here one type of such aunit.
For the lack of a better term, we call them"reasoning molecules'" (RM).
By this term we wantto stress two characteristic features of theseunits.
First, they are namely processing units,units of thought processes, not static knowledgestructures (like frames).
Secondly, they are notthought to represent elementary, indivisible stepsin these processes.
They represent certaincomplexes of such steps, but complexes thatfunction as wholes, when triggered by text.
Usinga somewhat metaphorical way of speaking, we can152say that RMs embody certain agents  that work as"experts" in certain types of problems.
They makeuse of the data coming from the text and theirbuilt-in knowledge about the given problem theyare specialists of.
They may interact together,engaging one another for obtaining additionalinformation and to solve, certain subproblems oftheir particular problems.
As such, RMs form arelatively loose, decentralized society of expertswhose activiiy is chiefly directed by theimmediate text  structure.
There is also ageneral~ central "supervisor" in such a reasoningsystem (Litvak et al 1982), but its role andinfluence appear more clearly on higher levels ofreasoning and decision making.
An RM ischaracterized by the basic properties described inthe following four sections.
(I) It has a built-in goal.
As RMs functionas "experts," their task is to notice the problemsthey are experts for, and to solve them.
Thegeneral end of any RM is to make sense of thesituation to which it applies.
But let us stressthat this "making sense" does not necessarilyamount to incorporating the corresponding event orsituation into some goal-plan hierarchy.
Instead,making sense may mean for the understander, forinstance, recognizing what a particular feature ofa situation or event was representing in the worlddescribed in the text.
For instance, there existRMs for determining such structural aspects ofevents as to what end something was done ("Goal-expert"), or at what time something was done("Time-expert"), but there exist also RMs whichare experts in such questions as whac counts as arelevant motivation of a refusal (cf.
thefollowing).
Further, making sense of a partner'sresponse in a dialogue may mean to the otherpartner making a decision about how to react tothis response.
Especially on the basis of thislatter example it may be said that in fact theprimary interest of an understander is not Just tomake sense of a piece of text itself but, instead,to make sense of the situation in which he himselfis the in terpreter  of the corresponding part ofthe text.In general, it may be right that for theinvestigation of local reasoning mechanisms, textsare more suitable where global organizationalstructures are lacking, or are not so significant;interactions in face-to-face dialogue present anexample of such texts.
(2) RHs make use of semantic categories andstructures identified in text, as well as speech-act-type pragmatic structures.
In an RM thesestructures function as "influence factors," i.e.,as units that are characterized on the basis oftheir effect upon the understander.
Influencefactors are semantic and pragmatic situations intext that manlpulate the attention of anunderstander: provoke or satisfy his interest,trigger him to pose questions and to seek answersto them, to choose between alternative possibleevaluaclons, and so on.
The task of RMs is justto  notice such "interest provoking situations" intext, to register their components and to providethe understander with "packets" of reasoning stepswhich may lead him to the needed decision(ultimately, to make sense of the correspondingsituation).
For instance, assume that someone ispresented with the response:"I am not coming.
I do not want to takesuch a risk.
"which is presented as an answer to his request (ororder, or  proposal).
The "refusal reasoningmolecule" identifies the latter sentence in theresponse as motivation for the refusal.
"Not-wanting-to-take-risks'" is an influence factorwhich provides the motive of the refusal.
But atthe same time it functions as an influence factorin another RM which leads the given participant ofthe dialogue to accept or to reject the refusal,and to react accordingly.
(3) RMs are characterized by a certain innerorganization.
Typically, an RM has threefunctional components.
First it includes a"sensor mechanism" whose task is to notice in textthe situations which are relevant to the given RM.Second, there is the "task formulator" whichfunctions as the central monitor and "bookkeeper"of the corresponding RM; departing from the built-in task of the RM and the data provided by text(or by other RMs) it formulates the concreteproblem to be solved, determines the method of itssolution and keeps track of the course of itsrealization.
Third, there is the processing unitof the RH which carries out theoperations/processes determined by the caskformulator.Further, there apparently should existdefinite empirical constraints concerning the sizeof the "working space" of an RM.
It must bepossible for the understander to hold theinfluence factors relevant to an RM simultaneouslyin his working memory and to take them all intoaccount in making the resulting decision.
Again,the face-to-face dialogue is a good example: inorder to react adequately to a response in such adialogue, the participant should takesimultaneously into account all the relevantfactors contained in the response of his partner.Because of this, it is not surprising that thelength of the replies in face-to-face dialoguetends to remain in certain limits.
It would hepremature to try to determine here the exactnature of the given constraints, e.g., in terms ofthe allowed number of influence factors in areasoning molecule (although the well known number7 plus or minus 2 could be a good guess).
(4) There exist certain basic types of RMs.First of all, we can differentiate betweenthematic and textual RMs.
Thematic RMs areexperts concerning the contents of a text (theprov ided  examples,  such as "Goa l -exper t "  or"Refusal-expert" belong to this type).
TextualL53RMs are experts concerning the organizationalstructure of various texts (e.g., stories, tales,scientific arguments).
Ultimately, they should beable to answer the question: "Why is thisparticular utterance presented at this place inthe text?
"III CONCLUDING REMARKSAs empirical material we have analyzed thestructure of interactions in directive dialogues,and still more concretely, the mechanisms neededto understand interactions which present requestsand orders in such dialogues, on the one hand, andthe possible reactions, e.g., refusals to fulfillthese requests and orders, on the other.
We havebuilt a taxonomy of influence factors typical ofthese types of interactions, and constructed somebasic types of reasoning molecules used ininterpreting the replies.The work is not yet impiemented, but we haveplanned to implement it in the frames of our textunderstanding systems TARLUS (Litvak etal .
1981;Koit eta l .
1983).
TARLUS is a system whose maintask is to interpret stories of a certain kind, inparticular by recognizing so-called hypereventsimplicitly described in text, (e.g., byrecognizing that certain actions of a persondescribed in text can be qualified as robbery orstealing).Koit M., Litvak S., Roosmaa T., Saluveer M., OimH., Using frames in causal reasoning.
Paperson Artificial Intelligence, vol.
5.
TartuState University, Tartu 1983.Lehnert W., Plot units and narratives-mm~rization.
Cognitive Science, 1981, vol.5, No.
4.Litvak S., Roosmaa T., Saluveer M., Oim H.,Recognizing hyperevents by a text understandingsystem.
Papers on Artificial Intelli~ence,vol.
4.
Tartu State University, Tartu, 1981.
(in Russian)Litvak S., Roosmaa T., Saluveer M., Oim H., On theinteraction of knowledge representation andreasoning mechanism in discourse comprehension.Proceedings of the 1982 European Conference onArtificial Intelli~ence.
Orsay, France, 1982~-Oim H., Episodes in the structure of discourse.In: A. Narin'yani (ed.
), Knowledgerepresentation and modellln~ of understandin$processes.
Novosibirsk, 1980.
(in Russian)Wllensky R., Points: a theory of story content.EECS Memo No.
UCB/ERL/MBO/17.
University ofCalifornia at Berkeley, 1980.Wilensky R., Hera-planning: representing and usingknowledge about planning in problem solving andlanguage understanding.
Cognitive Science,1981, vol.
5 No.
3.IV REFERENCESAllen J .E .
,  What's necessary to hide?
: Modelingaction verbs.
Proceedings of the 19th AnnualMeetin~ of the ACL, Stanford, 1981, 77-81.Black J.B. and Bower G.H., Story understanding asproblem solving.
Poetics, v.9, 1980.Cohen R., Investigation of processing strategiesfor the structural analysis of arguments.Proceedings of the 19th Annual Meeting of theACL, Stanford, 1981, 71-75.Dyer M.G., In-depth understanding: a computermodel of integrated processing for narrativecomprehension.
Res.
Report No.
219, YaleUniversity, May 1982.Granger R.H., Judgmental inference: a theory ofinferential decision - making duringunderstanding.
Proceedings of t he4th  AnnualConference of the Cognitive Science Society,Ann Arbor, Hichigan, 1982.t54
