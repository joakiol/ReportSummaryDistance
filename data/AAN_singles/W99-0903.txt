Dual Distr ibutional Verb Sense Disambiguation with SmallCorpora and Machine Readable Dictionaries*J eong-Mi  Cho  and Jungyun SeoDept .
of  Computer  Science,Sogang Un ivers i tyS insu-dong,  Mapo-gu ,  Seoul,  121-742, Koreajmcho@nlprep .sogang.ac .k rseo jy@ccs .sogang.ac .krGi l  Chang K imDept .
of  Computer  Science,Korea  Advanced Ins t i tu te  ofSc ience and  Techno logyTae jon ,  305-701, Koreagck im@csk ing .ka is t .ac .krAbst ractThis paper presents a system for unsupervisedverb sense disambiguation using small corpus anda machine-readable dictionary (MRD) in Korean.The system learns a set of typical usages listed inthe MRD usage examples for each of the senses ofa polysemous verb in the MRD definitions usingverb-object co-occurrences acquired from the cor-pus.
This paper concentrates on the problem of datasparseness in two ways.
First, extending word sim-ilarity measures from direct co-occurrences to co-occurrences of co-occurred words, we compute theword similarities using not co-occurred words but co-occurred clusters.
Second, we acquire IS-A relationsof nouns from the MRD definitions.
It is possibleto cluster the nouns roughly by the identification ofthe IS-A relationship.
By these methods, two wordsmay be considered similar even if they do not shareany words.
Experiments show that this method canlearn from very small training corpus, achieving over86% correct disambiguation performance without arestriction of word's senses.1 In t roduct ionMuch recent research in the field of natural anguageprocessing has focused on an empirical, corpus-based approach, and the high accuracy achieved bya corpus-based approach to part-of-speech taggingand parsing has inspired similar approaches to wordsense disambiguation.
For the most successful ap-proaches to such problems, correctly annotated ma-terials are crucial for training learning-based algo-rithms.
Regardless of whether or not learning isinvolved, the prevailing evaluation methodology re-quires correct est sets in order to rigorously assessthe quality of algorithms and compare their per-formance.
This seems to require manual taggingof the training corpus with appropriate sense foreach occurrence of an ambiguous word.
However, inmarked contrast o annotated training material forpart-of-speech tagging, (a) there is no coarse-levelset of sense distinctions widely agreed upon (whereas* This work was supported in part by KISTEP for SoftScience Research project.headword : open 2sense usage examplesopen Open the window a bit, please.He opened the door for me to come in.Open the box.start Our chairman opened the conference bywelcoming new delegates/Open a public meeting.Table 1: The entry of open(vt.) in OALDpart-of-speech tag sets tend to differ in the detail);(b) sense annotation has a comparatively high er-ror rate (Miller, personal communication, reportsan upper bound for human annotators of around90~ for ambiguous cases, using a non-blind eval-uation method that may make even this estimateoverly optimistic(Resnik, 1997)); (c) in conclusion,a sense-tagged corpus large enough to achieve broadcoverage and high accuracy word sense disambigua-tion is not available at present.
This paper describesan unsupervised sense disambiguation system usinga POS-tagged corpus and a machine-readable dic-tionary (MRD).
The system we propose circumventsthe need for the sense-tagged corpus by using MRD'susage examples as the sense-tagged examples.
Be-cause these usage examples how the natural exam-ples for headword's each sense, we can acquire usefulsense disambiguation context from them.
For exam-ple, open has several senses and usage examples forits each sense listed in a dictionary as shown in Table1.
The words within usage examples window, door,box, con#fence, and meeting are useful context forsense disambiguation of open.Another problem that is common for much corpus-based work is data sparseness, and the problem es-pecially severe for work in WSD.
First, enormousamounts of text are required to ensure that all sensesof a polysemous word are represented, given the vastdisparity in frequency among senses.
In addition,the many possible co-occurrences for a given polyse-mous word are unlikely to be found in even a verylarge corpus, or they occur too infrequently to besignificant.
In this paper, we propose two methods17that attack the problem of data sparseness in W~using small corpus and dictionary.
First, extendiword similarity measures from direct co-occurren,to co-occurrences of co-occurred words, we complthe word similarities using not co-occurred woJbut co-occurred clusters.
Second, we acquire ISrelations of nouns from the MRD definitions.
Dtionary definitions of nouns are normally writtensuch a way that one can identify for each headw((the word being defined), a "genus term" (a w(more general that the headword), and these arelated via an IS-A relation(Amsler, 1979).
It is po~,ble to cluster the nouns roughly by the identificatiof the IS-A relationship.2 Dual  D is t r ibut iona l  S imi lar i tyWe attempt to have the system learn to disabiguate the appearances of a polysemous verb wits senses defined in a dictionary using the ,occurrences of syntactically related words in a P(tagged corpus.
We consider two major word classV and N, for the verbs and nouns and a single retion between them, in our experiments the relatibetween a transitive main verb and the head noof its direct object.
Thus, a noun is representeda vector of verbs that takes the noun as its object,and a verbs by a vector of nouns that appears as theverb's object.
Commonly used corpus-based modelsdepend on co-occurrence patterns of words to deter-mine similarity.
If word wl's co-occurrence patternsis similar to word w2's patterns, then wl is similarto w2 contextually.
Note that contextually similarwords do not have to be synonym, or to belong tothe same semantic ategory.
We define a word beingcomputed the similarity as a ta rget  word  and aword occurring in the co-occurrence pattern of thetarget word as a co -occur red  word.
The overlapof words between co-occurrence patterns of two tar-get words determines the similarity of them.
How-ever, in case of small training corpus, it is difficultto confide in the similarity depending on statistics ofco-occurrences.
The reason is that when two wordshave no overlap of co-occurrence patterns, we cannot discriminate whether two words are not similaror it fails to find the similarity due to sparse data Todistinguish two cases, we expand the co-occurrencesof the target word to the co-occurrences of the co-occurred words with the target word.
Accordingto the co-occurrence patterns of the co-occurredwords, it is possible to cluster the co-occurred wordsroughly.
And we can overcome the problem of datasparseness by applied not co-occurred words but co-occurred clusters to the similarity of target words.A dual distributional similarity is an extensionto word similarity measure reflecting the distribu-tions of the co-occurred words with the target wordas well as the distribution of the target word.target wordsco-occun-cd wordsco-occurredwith words onfe~renc~co-occurred wordsFigure 1: The example of dual distributional simi-larityFigure 1 demonstrates the advantage of the dualdistributional similarity, in comparison with theunitary distributional similarity.
The simple com-parison with co-occurrence patterns of conferenceand meeting fails to find the similarity between thetwo nouns because there in no overlap in the co-occurrence patterns.
However, dual distributionalsimilarity measure can be find that the two nouns aresimilar even if the co-occurrence patterns of the twonouns do not overlap.
First, since the co-occurredverbs attend, end, hold, and start with conferenceand meeting share several objects such as event, re-ply, and party, we can find that the co-occurred verbsare similar.
And since conference and meeting sharesimilar verbs, they are similar even if they do notshare any verbs.3 The  WSD System Us ing  a Corpusand  a MRDThe architecture of the WSD system using a cor-pus and a MRD is given in Figure 2.
Our systemconsists of two parts, which are the knowledge ac-quisition system and the sense disambiguation sys-tem.
The knowledge acquisition system also consistsof two parts, one of the acquisition of selectional re-striction examples from a POS-tagged corpus andanother of the acquisition of each verb's sense indi-cators and noun clustering cues from a MRD.
Thesense disambiguation system assigns an appropriatesense to an ambiguous verb by computation of sim-ilarity between its object in a sentence and its senseindicators.
The overall process for verb sense disam-biguation is as follows:?
Extract all selectional restriction examples froma POS-tagged corpus.118object verb_F 'TT----object verb zSense disambiguation systemI ORPUS Analyzerword co-occurrencesI within syntactic relationsense indicatorsc ustering cues jT I MROAnalyzer IKnowledge acquisition systemFigure 2: The WSD system using a corpus and aMRD?
Extract each polysemous verb's sense indicatorsfrom a MRD.?
For a target verb, compute similarities betweenits object and its sense indicators using the se-lectional restriction examples acquired from thecorpus and clustering cues from the MRD.?
Determine the sense of the most similar senseindicator as the verb's disambiguated sense.3.1 Context  for verb  sense d i sambiguat ionPresumably verbs differ in their selectional restric-tions because the different actions they denote arenormally performed with different objects.
Thuswe can distinguish verb senses by distinguishing se-lectional restrictions.
(Yarowsky, 1993) determinedvarious disambiguating behaviors based on syntacticcategory; for example, that verbs derive more disam-biguating information from their objects than fromtheir subjects, and adjectives derive almost all dis-ambiguating information from nouns they modify.We use verb-object relation for verb sense disam-biguation.
For example, consider the sentences Su-san opened the meeting and Susan opened the door.In deciding which open's enses in Table 1 are taggedin the two sentences, the fact that meeting and doorappear as the direct object of open respectively givessome strong evidence.3.2 Lexical  knowledge  acqu is i t ion3 .2 .1  Mach ine- readab le  d ic t ionar iesIn previous works using MRDs for word sense dis-ambiguation, the words in definition texts are usedas sense indicators.
However, the MRD definitionsalone do not contain enough information to allowreliable disambiguation.
To overcome this problem,we use the MRD usage examples as the sense-taggedexamples as well as definitions for acquiring sense in-dicators.
We acquire all objects in the MRD defini-tions and usage examples of a polysemous verb as itssense indicators.
We use objects as sense indicatorsby same reason of using verb-object selection rela-tion for verb sense disambiguation.
These sense in-dicators is very useful to verb sense disambiguationbecause the objects in usage examples are typicaland very often used with the sense of the verb.The entries of wear in OALD and ipta (wear) andssuta (write) in Korean dictionary and the sense in-dicator sets acquired from them are shown in Table2.We acquire another information from the dictio-nary definition.
Dictionary definitions of nouns arenormally written in such a way that one can iden-tify for each headword (the word being defined),a "genus term" (a word more general that theheadword), and these are related via an IS-A rela-tion(Bruce,1992; Klavans, 1990; Richardson,1997).We use the IS-A relation as noun clustering cues.For example, consider the following definitions inOALD.hat covering for the head with a brim, worn out of doors.cap 1 soft covering for the head without a brim.
bonnet.shoe 1 covering for the foot, esp.
one that does not reachabove the ankle.Here covering is common genus term of the head-words, hat, cap 1, and shoe 2.
That is, we can saythat "hat IS-A covering", "cap I IS-A covering", and"shoe 2 IS-A covering", and determine these threenouns as same cluster covering.
In cap l's definition,bonnet is a synonym of cap 1.
We also use the syn-onyms of a headword as another clustering cues.Our mechanism for finding the genus terms isbased on the observation that in Korean dictionary,the genus term is typically the tail noun of the defin-ing phrase as follows:ilki nalmata kyekkun il, sayngkakul cekunkilok(record).
(diary) (daily record of events, thoughts, etc.
)Because these clustering cues are not complete andconsistent, we use parent and sibling clusters with-out multi-step inference for acquired IS-A relations.3.2.2 CorporaWe acquire word co-occurrences within syntactic re-lations for learning word similarity from a POS-tagged corpus in Korean.
To acquire word co-occurrences within syntactic relations, we have toget the required parsing information.
Postpositionsin Korean are used to mark the syntactic relations ofthe preceding head components in a sentence.
Forexample, the postpositions ka and i usually mark19headword sense definition usage examples sense indicatorsEnglish Dictionary(OALD)wear z have one the body, carry on one'sperson or on some part of it;ace(of looks) have on the faceHe was wearing a hat/spectacles~a beard~heavy shoes/a ringon his finger/a troubled look.
{ one, hat, spectacles,beard, shoes, ring, look }Korean Dictionary(Grand Korean Dictionary)ipta 188uta  2mom-ey os-ul kelchikena tuluta(wear clothes)hanbok-ul ipta/chiraa-lul ipta {os(clothes), hanbok(Korean(wear Korean clothes)/(wear  skirt) clothes), chima(skirt)}kul-ul cista sosel-lu~: ssuta/phyenci-ul ssuta {kul(article), sosel(novel),(write an article) (write a novel/write a letter) chima(skirt)}Table 2: The entries of wear (vt.) in OALD and ipta and ssuta in Korean dictionarythe subjective relation and ul and lul the objec-tive relation.
1 Given the sentence 2 kunye-ka(she)phyenci-lul(letter) ssu-ta(write), we can know thatkunye (she) is the subject head and phyenci (letter)is the direct object head according to the postposi-tions ka and lul.
We call guessing the syntactic re-lation by postpositions as Postposition for SyntacticRelation heuristic.
When there are multiple verbs ina sentence, we should determine one verb in relationto the object component.
In such attachment ambi-guity, we apply the Left Association heuristic, corre-sponding to the Right Association in English.
Thisheuristic states that the object component prefers tobe attached to the leftmost verb in Korean.
Withthe two heuristics, we can accurately acquire wordco-occurrences within syntactic relations from thePOS-tagged corpus without parsing(Cho, 1997).3.3 Dual  d is t r ibut iona l  sensed isambiguat ionIn our system, verb sense disambiguation is the clus-tering of an ambiguous verb's objects using its senseindicators as seeds.
As noted above, a noun is rep-resented by a vector of verbs that takes the nounas its object, and a verbs by a vector of nouns thatappears as the verb's object.
We call the former anoun d is t r ibut ion  and the latter a verb distr i -but ion.
The noun distribution is probabilities ofhow often each verb had the noun as object, giventhe noun as object, that the verb is vl ,v2, .
.
.vwi .That is,d(n) =< p(vlln),p(v21n), .
.
.
,p(vwiIn ) > (1)freq(vi,n) (2) p(vi\[n)/req(vj, n)where I VI is the number of verbs used as transitiveverb in training corpus, and f req(v ,n)  is the fre-quency of verb v that takes noun n as direct object.A verb distribution is a vector of nouns that ap-pears as the verb's direct object.
We define the verb1 i is an allomorph of ka and lul is an allomorph of ul2The symbol "-" in the Korean sentence represents hemorpheme boundary.distribution as containing binary value, "1" if eachnoun occurring as its direct object and "0" other-wise.d(v) =< b(nl, v), b(n2, v), ..., b(n\]gL, v) >b(ni, v) = 1 i f  ni appeared as v' s directed object0 otherwisewhere IN\[ is the number of nouns appeared as tran-sitive verb's direct object.The process of object clustering is as follows:1.
Cluster the objects according to clustering cuesacquired from the MRD.2.
Cluster the objects excepted from Step 1 usingthe dual distribution.3.
Cluster the objects excepted from Step 2 to theMRD's first sense of the polysemous verb.3.3.1 C lus ter ing  us ing IS -A  re la t ionsimp l i c i t  in MRD def in i t ionWe define cluster cluster(w) and synonym setsynonym(w)  of a word w using IS-A relations im-plicit in the MRD definition.
The criteria of clus-tering word wl and word w2 as same cluster are asfollows:?
wl E cluster(w2)?
wl E synonym(w2)?
wi ?
cluster(w2) where wi ?
cluster(w1)?
wi ?
synonym(w2) where wi ?
cluster(w1)* wi ?
synonym(w2) where wi ?
synonym(w1)3.3.2 Measur ing  s imi la r i t ies  between nounsTo compute the similarities between nouns we usethe relative entropy or Kullback-Leibler(KL) distanceas metric to compare two noun distributions.
Therelative entropy is an information-theoretic measureof how two probability distributions differ.
Giventwo probability distributions p and q, their relativeentropy is defined asp(x)D(p H q) = - p(x)lo9--7-T (6) q(x)(3)(4)(5)20where we define Ologq ?- = 0 and otherwise plogo~ =c~.
This quantity is always non-negative, andD(pllq ) = 0 iff p = q.
Note that relative entropy isnot a metric (in the sense in which the term is usedin mathematics): it is not symmetric in p and q, andit does not satisfy a triangle equality.
Nevertheless,informally, the relative entropy is used as the "dis-tance" between two probability distribution in manyprevious works(Pereira, 1993; Resnik, 1997).
Therelative entropy can be applied straightforwardly tothe probabilistic treatment of selectional restriction.As noted above, the noun distribution d(n) is verbvi's condition probability given by noun n. Giventwo noun distributions d(n:) and d(n2), the similar-ity between them is quantified as:, ,  p(v/Inl)Dn(d(n:) I1 d(n2)) = - E p(v i ln l ) t ?g - -  (7)vieV p(viln2)3.3.3 Measur ing  similar it ies between verbsThe noun distributions p and q is easy to have zeroprobabilities by the problem of sparse data withsmall training corpus 3.
In such case, the similarity ofthe distributions i not reliable because of Ologq ?-= 0and plogo~ = co.
This can be known from the re-sults of sense disambiguation experiments using onlynoun distributions (see Section 4.2).
The verb dis-tributions play complementary roles when the noundistributions have zero probabilities.
For all verbswhere p(viln2) = 0 and p(vilnl) > 0 or the reversecase:1. execute OR operation with all distributions forthe verbs vi where p(v~ In2) = 0 and p(vilnl) > 0in the noun distribution d(n:) and make newdistribution, dVl.dv, = V d(vi), for p(vilnl ) > 0 and p(viln2 ) = 0. execute OR operation with all distributions forthe verbs vi where p(vitn2) > 0 and p(vilnl) = 0in the noun distribution d(n2) and make newdistribution, dv2.dv2 = V d(vi), for p(viln2) > 0 and p(viln: ) = 03. execute inner product with new distributions,dvl and dv2Dv (d(v:), d(v2) = dvl .
dv2We use a stop verb list to discard from Steps 1and 2 verbs taken too many nouns as objects, such3As many of the possible co-occurrences are not observedeven in a large corpus(Church, 1993), actually the noun dis-tributions have not many common verbs.as hata (do), which do not contribute to the dis-ambiguation process.
The verb distribution has thebinary values, 1 or 0 according to its object distribu-tions in the training corpus.
Thus, the inner productDverb(d(Vl), d(v2)) with dv: and dv2 means the num-ber of common objects to two distributions.
We cancompute the similarities of the co-occurred verbs inthe two noun distributions with the number of com-mon objects.
Although the two noun distributiondo not share any verbs, if they have similar verbs incommon, they are similar.Combining similarities of noun distributions andverb distributions, we compute total similarity be-tween the noun distributions.Dt = c~Dn + 3Dv (8)The a,/3 are the experimental constants(0.71 for crand 0.29 for/3).4 Exper imenta l  Eva luat ionWe used the KAIST corpus, which contains 573,193eojeols 4 and is considered a small corpus for thepresent ask.
As the dictionary, we used the GrandKorean Dictionary, which contains 144,532 entries.The system was tested on a total of 948 examplesof 10 polysemous verbs extracted from the corpus:kamta, kelta, tayta, tulta, ttaluta, ssuta, chita, thata,phwulta, and phiwuta (although we confined the testto transitive verbs, the system is applicable to in-transitive verbs or adjectives).
For this set of verbs,the average number of senses per verb is 6.7.
Weselected the test verbs considering the frequencies inthe corpus, the number of senses in the dictionary,and the usage rates of each sense.We tested the systems on two test sets fromKAIST corpus.
The first set, named C23, consistsof 229,782 eojeols and the second set, named C57,consists of 573,193 eojeols.
The experimental re-sults obtained are tabulated in Table 3.
As a base-line against which to compare results we computedthe percentage of words which are correctly disam-biguated if we chose the most frequently occurringsense in the training corpus for each verb, which re-sulted in 42.4% correct disambiguation.
Columns 3-5 illustrate the effect of adding the dual distributionand the MRD information.
When the dual distri-bution is used, we can see significant improvementsof about 22% for recall and about 12% for the pre-cision.
Specially, in smaller corpus (C23), the im-provement of recall is remarkable as 25%.
This rep-resents that the dual distribution is effective to over-come the problem of sparse data, especially for smallcorpus.
Moreover, by using both the dual distribu-tion and the MRD information, our system achieved4Eojeol is the smallest meaningful nit consisting of con-tent words (nouns, verbs, adjectives, etc.)
and functionalwords (postpositions, auxiliaries, etc.
)21measure corpus noun dis.
dual dis.
dual dis.+ MRDrecall C23 40.9% 66.0% 80.0%C57 47.8% 67.7% 86.3%precision C23 47.7% 55.8% 80.0%C57 48.3% 61.0% 86.3%Table 3: Experimental resultsthe improvements of about 16% for recall and about25% for the precision.The average performance of our system is 86.3%and this is a little behind comparing with other pre-vious work's performance in English.
Most previousworks have reported the results in "70%-92%" ac-curacies for particular words.
However, our systemis the unsupervised learning with small POS-taggedcorpus,and we do not restrict the word's sense setwithin either binary senses(Yarowsky,1995; Karov,1998) or dictionary's homograph level(Wilks, 1997).Thus, our system is appropriate for practical WSDsystem as well as bootstrapping WSD system start-ing with small corpus.5 Re la ted  WorkUsing MRDs for word sense disambiguation waspopularized by (Lesk, 1986).
Several researcherssubsequently continued and improved this line ofwork(Guthrie, 1991; Krovetz, 1989; Veronis, 1990;Wilks, 1997).
Unlike the information in a corpus,the information in the dictionary definitions is pre-sorted into senses.
However, the dictionary def-initions alone do not contain enough informationto allow reliable disambiguation.
Recently, manyworks combined a MRD and a corpus for word sensedisambiguation(Karov, 1998; Luk, 1995; Ng, 1996;Yarowsky,1995).
In (Yarowsky,1995), the definitionwords were used as initial sense indicators, automat-ically tagging the target word examples containingthem.
These tagged examples were then used as seedexamples in a bootstrapping process.
In (Luk, 1995),using the dictionary definition, co-occurrence dataof concepts, rather than words, is collected from arelatively small corpus to tackle the data sparsenessproblem.
In (Karov, 1998), all the corpus examplesof the dictionary definition words, instead of thoseword alone were used as sense indicators.
In com-parison, we suggest o combine the MRD definitionwords and usage examples as the sense indicators.Because the MRD's usage examples can be used asthe sense-tagged instances, the sense indicators ex-tracted from them are very useful for word sensedisambiguation.
And this yield much more sense-presorted training information.The problem of data sparseness, which is com-mon for much corpus-based work, is especially se-vere for work in WSD.
Traditional attempts to tacklethe problem of data sparseness include the class-based approaches and similarity-based approaches.The class-based approaches(Brown, 1992; Luk, 1995;Pereira, 1993; Resnik, 1992) attempt o obtain thebest estimates by combining observations of classesof words considered to belong to a common cate-gory.
These methods answer in part the problem ofdata sparseness and eliminate the need for pretaggeddata.
However, there is some information loss withthese methods because the hypothesis that all wordsin the same class behave in a similar fashion is toostrong.
In the similarity-based approaches(Dagan,1997; Karov, 1998), rather than a class, each wordis modeled by its own set of similar words derivedfrom statistical data extracted from corpora.
How-ever, deriving these sets of similar words requiresa substantial amount of statistical data and thusthese approaches require relatively large corpora.
(Karov, 1998) proposed an extension to similarity-based methods by means of an iterative process atthe learning stage with small corpus.
Our system issimilar to (Karov, 1998) with respect o similaritymeasure, which allows it to extract high-order con-textual relationship.
However, we attempt o con-cern a polysemous word's all senses in the trainingcorpus, rather than restricting the word's sense setwithin binary senses and this allows our system tobe more practical.6 Conc lus ionsWe have described an unsupervised sense disam-biguation system using a small corpus and a MRD.Our system combines the advantages of corpus-based approaches (large number of word patterns)with those of the MRD-based approaches (data pre-sorted by senses), by acquiring sense indicators fromthe MRD's usage examples as well as definitions andacquiring word co-occurrences from the corpus.
Be-cause the MRD's usage examples can be used as thesense-tagged instances, the sense indicators acquiredfrom them are very useful for word sense disam-biguation.
In our system, Two nouns are consideredsimilar even if they do not share any verbs if theyappear as objects to similar verbs because the simi-larities between verbs simultaneously compute withthe similarities between nouns.
Thus, we can over-come effectively the problem of sparse data due tounobserved co-occurrences of words in the trainingcorpus.
Our experiments show that the results usingthe dual distribution and the MRD information leadto better performance on very sparse data.Our immediate plans are to test our system onvarious syntactic categories involving nouns as wellas intransitive verbs and adjectives, and to suggestthat different kinds of disambiguation proceduresare needed depending on the syntactic ategory andother characteristics of the target word.
Further-22more, we plan to build a large sense-tagged corpus,where the sense distinction is at the level of a dic-tionary in Korean.
The sense-tagged corpus wouldbe reused to achieve broad coverage, high accuracyword sense disambiguation.ReferencesAmsler, R. A. and J.
White.
1979.
Development ofa computational methodology for deriving natu-ral language semantic structures via analysis ofmachine-readable dictionaries.
National ScienceFoundation, Technical Report.
MCS77-01315.Brown, Peter F., Vincent J. Dellar Peitra, Peter V.deSouza, Jenifer C. Lai, and Robert L. Mercer.1992.
Class-based n-gram models of natural lan-guage.
Computational Linguistics, vol.
14, no.
4,pp.467-479.Bruce, R. and L. Guthrie.
1992.
Genus disambigua-tion: A study in weighted preference.
In Proceed-ings of COLING92, pp.1187-1191.Cho, Jeong-Mi, Young Hwan Cho, and Gil ChangKim.
1997.
Automatic acquisition of N(oun)-C(ase)-P(redicate) information from POS-taggedcorpus.
Computer Processing of Oriental Lan-guages, vol.
11, no.
2, pp.191-204.Church, Kenneth W. and Robert L. Mercer.
1993.Introduction to the special issue on computa-tional linguistics using large corpora.
Computa-tional Linguistics, vol.
19, pp.l-24.Dagan, Ido, Lillian Lee, and Fernando Pereira.1997.
Similarity-based methods for word sense dis-ambiguation.
In Proceedings of the 35th AnnualMeeting of the ACL, pp.56-63.Guthrie, Joe A1, Louise Guthrie, Yorick Wilks, andHoma Aidinejad.
1991.
Subject-dependent cooc-currence and word sense disambiguation.
In Pro-ceedings of the 29th Annual Meeting of the ACL,pp.146-152.Karov, Yael and Shimon Edelman.
1998.
Similarity-based word sense disambiguation.
ComputationalLinguistics, vol.
24, no.
1, pp.41-60.Klavans, J., M. Chodorow, and N. Wacholder.
1990.From dictionary to knowledge base via taxonomy.In Proceedings of the 4th Annual Conference ofthe University of Waterloo Center for the NewOxford English Dictionary: Electronic Text Re-search, pp.l10-132.Krovetz, Robert and W. Bruce Croft.
1989.
Wordsense disambiguation using machine-readable dic-tionaries.
In Proceedings of A CM SIGIR'89,pp.127-136.Lesk, Michael.
1986.
Automatic sense disambigua-tion: How to tell a pine cone from an ice creamcone.
In Proceedings of the 1986 ACM SIGDOCConference, pp.24-26.Luk, Alpha K.. 1995.
Statistical sense disambigua-tion with relatively small corpora using dictio-nary definitions.
In Proceedings of the 33rd AnnualMeeting of the ACL, pp.181-188.Ng, Hwee Tou.
1996.
Integrating multiple knowledgesources to disambiguate word sense: An exemplar-based approach.
In Proceedings of the 34th AnnualMeeting of ACL, pp.40-47.Pereira, Fernando, Naftali Tishby, and Lillian Lee.1993.
Distributional Clustering Of English Words.In Proceedings of the 31st Meeting of the Associ-ation for Computational Linguistics.Resnik, Philip Stuart.
1992.
WordNet and distribu-tional analysis: a class-based approach to lexicaldiscovery.
In Proceedings of AAAI Workshop onStatistically-Based NLP Techniques.Resnik, Philip Stuart.
1997.
Selectional prefer-ence and sense disambiguation.
In Proceedings ofANLP Workshop, "Tagging Text with Lexical Se-mantics: Why, What, and How?
".Richardson, Stephen D..
Determining similarity andinferring relations in a lexical knowledge base.Ph.D.
Dissertation.
The City University of NewYork.Veronis, Jean and Nancy Ide.
1990.
Word sensedisambiguation with very large neural networksextracted from machine-readable dictionaries.
InProceedings of COLING-90, pp.389-394.Wilks, Yorick and Mark Stevenson.
1997.
Combin-ing independent knowledge sources for word sensedisambiguation.
In Proceedings of RANLP.Yarowsky, David.
1993.
One sense per collocation.
InProceedings of the ARPA Human Language Tech-nology Workshop.
pp.265-271.Yarowsky, David.
1995.
Unsupervised word sensedisambiguation rivaling supervised methods.
InProceedings of the 33rd Annual Meeting of theACL, pp.189-196.23
