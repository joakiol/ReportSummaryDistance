ROBUST CONTINUOUS SPEECH RECOGNITIONPls : John Makhoul and Richard Schwartzmakhoul@bbn.com, schwartz@bbn.comBBN Systems and Technologies70 Fawcett StreetCambridge, MA 02138PROJECT GOALS "The primary objective of this basic researchprogram is to develop robust methods andmodels for speaker-independent acousticrecognit ion of spontaneously-produced,continuous peech.
The work has focussed ondeveloping accurate and detailed models ofphonemes and their coarticulation .for the ?purpose of large-vocabulary continuous peechrecognition.
Important goals of this work are toachieve the highest possible word recognitionaccuracy in continuous peech and to developmethods for the rapid adaptation of phoneticmodels to the voice of a new speaker.RECENT RESULTSPorted the BYBLOS system to the Wall StreetJournal (WSJ) corpus.
We found that thetechniques that we had developed forrecognition of the ATIS corpus workedquite well without modification on the WSJcorpus.Performed several key experiments on theWSJ corpus.
We verified our conjecture thata speaker-independent system trained on asmall number of speakers has about thesame word error rate as a system trained on alarge number of speakers, assuming thesame total amount of training speech.
Thisis the first time that this result has beenperformed in a well-controlled way for largevocabulary speech recognition.
We alsoverified that training the system separatelyon each of the speakers and averaging theresulting models results in essentially thesame performance as training on all of thedata at once.
These results have wideranging implications for data collection andsystem design.We have shown that, for large vocabularyrecognition, a speaker-independent systemwill have about the same error rate as aspeaker-dependent system when the speaker-independent system is trained on about 15times as much speech as the correspondingspeaker-dependent system.We showed that a simple blinddeconvolution method for microphoneindependence, in which the mean cepstrumis subtracted from each eepstrurn vector, issomewhat better than the RASTA method.Developed a new algorithm for microphoneindependence which uses a codebooktransformation, based on selection amongseveral known microphones.
The algorithmreduced the word error rate for unknownmicrophones by 20% over using blinddeconvolution alone.In the Nov. 1992 speech recognition test onthe ATIS domain, our BYBLOS systemcontinued to give the best results of all sitestested, with a 30% reduction in word errorover last year.
In our first test on the WSJcorpus, our system had the second lowesterror  rates.Chaired the CSR Corpus CoordinatingCommittee.PLANS FOR THE COMING YEARFor the coming year, we plan to continue ourwork on improving speech recognitionperformance both on the Wall Street Journalcorpus and on the spontaneous ATIS speechcorpus.
We plan to explore differentpararneterizations of the speech signal and newmodels for microphone and speaker adaptation.385
