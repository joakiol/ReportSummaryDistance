Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 409?420,Edinburgh, Scotland, UK, July 27?31, 2011. c?2011 Association for Computational LinguisticsLearning to Simplify Sentences with Quasi-Synchronous Grammar andInteger ProgrammingKristian Woodsend and Mirella LapataInstitute for Language, Cognition and ComputationSchool of Informatics, University of Edinburgh10 Crichton Street, Edinburgh EH8 9ABk.woodsend@ed.ac.uk, mlap@inf.ed.ac.ukAbstractText simplification aims to rewrite text intosimpler versions, and thus make informationaccessible to a broader audience.
Most pre-vious work simplifies sentences using hand-crafted rules aimed at splitting long sentences,or substitutes difficult words using a prede-fined dictionary.
This paper presents a data-driven model based on quasi-synchronousgrammar, a formalism that can naturallycapture structural mismatches and complexrewrite operations.
We describe how such agrammar can be induced from Wikipedia andpropose an integer linear programming modelfor selecting the most appropriate simplifica-tion from the space of possible rewrites gen-erated by the grammar.
We show experimen-tally that our method creates simplificationsthat significantly reduce the reading difficultyof the input, while maintaining grammaticalityand preserving its meaning.1 IntroductionSentence simplification is perhaps one of the oldesttext rewriting problems.
Given a source sentence,the goal is to create a grammatical target that iseasier to read with simpler vocabulary and syntac-tic structure.
An example is shown in Table 1 in-volving a broad spectrum of rewrite operations suchas deletion, substitution, insertion, and reordering.The popularity of the simplification task stems fromits potential relevance to various applications.
Ex-amples include the development of reading aids forpeople with aphasia (Carroll et al, 1999), non-nativeAlso contributing to the firmness in copper, the an-alyst noted, was a report by Chicago purchasingagents, which precedes the full purchasing agents re-port that is due out today and gives an indication ofwhat the full report might hold.Also contributing to the firmness in copper, the an-alyst noted, was a report by Chicago purchasingagents.
The Chicago report precedes the full purchas-ing agents report.
The Chicago report gives an indica-tion of what the full report might hold.
The full reportis due out today.Table 1: Example of a source sentence (top) and its sim-plification (bottom).speakers (Siddharthan, 2003) and more generally in-dividuals with low literacy (Watanabe et al, 2009).A simplification component could be also used asa preprocessing step to improve the performanceof parsers (Chandrasekar et al, 1996), summarizers(Beigman Klebanov et al, 2004) and semantic rolelabelers (Vickrey and Koller, 2008).Simplification is related to, but different fromparaphrase extraction (Barzilay, 2003).
We must notonly have access to paraphrases (i.e., rewrite rules),but also be able to combine them to generate newtext, in a simpler language.
The task is also dis-tinct from sentence compression as it aims to ren-der a sentence more accessible while preserving itsmeaning.
On the contrary, compression unavoidablyleads to some information loss as it creates shortersentences without necessarily reducing complexity.In fact, one of the commonest simplification oper-ations is sentence splitting which usually produceslonger rather than shorter output!
Moreover, mod-409els developed for sentence compression have beenmostly designed with one rewrite operation in mind,namely word deletion, and are thus unable to modelconsistent syntactic effects such as reordering, sen-tence splitting, changes in non-terminal categories,and lexical substitution (but see Cohn and Lapata2008 and Zhao et al 2009 for notable exceptions).In this paper we propose a sentence simplificationmodel that is able to handle structural mismatchesand complex rewriting operations.
Our approach isbased on quasi-synchronous grammar (QG, Smithand Eisner 2006), a formalism that is well suited fortext rewriting.
Rather than postulating a strictly syn-chronous structure over the source and target sen-tences, QG identifies a ?sloppy?
alignment of parsetrees assuming that the target tree is in some way?inspired by?
the source tree.
Specifically, our modelis formulated as an integer linear program and usesQG to capture the space of all possible rewrites.Given a source tree, it finds the best target tree li-censed by the grammar subject to constraints suchas sentence length and reading ease.
Our model isconceptually simple and computationally efficient.Furthermore, it finds globally optimal simplifica-tions without resorting to heuristics or approxima-tions during the decoding process.Contrary to most previous approaches (see thediscussion in Section 2) which rely heavily onhand-crafted rules, our model learns simplifi-cation rewrites automatically from examples ofsource-target sentences.
Our work joins others in us-ing Wikipedia to extract data appropriate for modeltraining (Yamangil and Nelken, 2008; Yatskar et al,2010; Zhu et al, 2010).
Advantageously, the Sim-ple English Wikipedia (henceforth SimpleEW) pro-vides a large repository of simplified language; ituses fewer words and simpler grammar than the or-dinary English Wikipedia (henceforth MainEW) andis aimed at non-native English speakers, children,translators, people with learning disabilities or lowreading proficiency.
We exploit Wikipedia and cre-ate a (parallel) simplification corpus in two ways:by aligning MainEW sentences to their SimpleEWcounterparts, and by extracting training instancesfrom SimpleEW revision histories, thus leveragingWikipedia?s collaborative editing process.Our experimental results demonstrate that a sim-plification model can be learned from Wikipediadata alone without any manual effort.
Perhaps un-surprisingly, the quality of the QG grammar rulesgreatly improves when these are learned from re-vision histories which are less noisy than sentencealignments.
When compared against current state-of-the-art methods (Zhu et al, 2010) our modelyields significantly simpler output that is both gram-matical and meaning preserving.2 Related WorkSentence simplification has attracted a great dealof attention due to its potential impact on society.The literature is rife with attempts to simplify textusing mostly hand-crafted syntactic rules aimed atsplitting long and complicated sentences into sev-eral simpler ones (Carroll et al, 1999; Chandrasekaret al, 1996; Siddharthan, 2004; Vickrey and Koller,2008).
Other work focuses on lexical simplificationsand substitutes difficult words by more commonWordNet synonyms or paraphrases found in a pre-defined dictionary (Devlin, 1999; Inui et al, 2003;Kaji et al, 2002).More recently, Yatskar et al (2010) exploredata-driven methods to learn lexical simplificationsfrom Wikipedia revision histories.
A key idea intheir work is to utilize SimpleEW edits, while rec-ognizing that these may serve other functions, suchas vandalism removal or introduction of new con-tent.
Zhu et al (2010) also use Wikipedia to learna sentence simplification model which is able toperform four rewrite operations, namely substitu-tion, reordering, splitting, and deletion.
Inspiredby syntax-based SMT (Yamada and Knight, 2001),their model consists of three components: a lan-guage model P(s) whose role is to guarantee that thesimplification output is grammatical, a direct trans-lation model P(s|c) capturing the probability that thetarget sentence s is a simpler version of the source c,and a decoder which searches for the simplifica-tion s which maximizes P(s)P(s|c).
The translationmodel is the product of the aforementioned fourrewrite operations whose probabilities are estimatedfrom a parallel corpus of MainEW and SimpleEWsentences using an expectation maximization algo-rithm.
Their decoder translates sentences into sim-pler alternatives by greedily selecting the branch inthe source tree with the highest probability.410Our own work formulates sentence simplificationin the framework of Quasi-synchronous grammar(QG, Smith and Eisner 2006).
QG allows to describenon-isomorphic tree pairs (the grammar rules cancomprise trees of arbitrary depth, and fragments canbe mapped) and is thus suited to text-rewriting taskswhich typically involve a number of local modifi-cations to the input text.
We use quasi-synchronousgrammar to learn a wide range of rewrite opera-tions capturing both lexical and structural simplifi-cations naturally without any additional rule engi-neering.
In contrast to Yatskar et al (2010) and Zhuet al (2010), simplification operations (e.g., substi-tution or splitting) are not modeled explicitly; in-stead, we leave it up to our grammar extraction algo-rithm to learn appropriate rules that reflect the train-ing data.
Compared to Zhu et al, our model is con-ceptually simpler and more general.
The proposedILP formulation not only allows to efficiently searchthrough the space of many QG rules but also to in-corporate constraints relating to grammaticality andthe task at hand without the added computationalcost of integrating a language model.
Furthermore,our learning framework is not limited to simplifi-cation and could be easily adapted to other rewrit-ing tasks.
Indeed, the QG formalism has been pre-viously applied to parser adaptation and projection(Smith and Eisner, 2009), paraphrase identification(Das and Smith, 2009), question answering (Wanget al, 2007), and title generation (Woodsend et al,2010).Finally, our work relates to a large body of recentliterature on Wikipedia and its potential for a widerange of NLP tasks.
Beyond text rewriting, examplesinclude semantic relatedness (Ponzetto and Strube,2007), information extraction (Wu and Weld, 2010),ontology induction (Nastase and Strube, 2008), andthe automatic creation of overview articles (Sauperand Barzilay, 2009).3 Sentence Simplification ModelOur model takes a single sentence as input and cre-ates a version that is simpler to read.
This mayinvolve rendering syntactically complex structuressimpler (e.g., through sentence splitting), or sub-stituting rare words with more common words orphrases (e.g., such that a second language learnermay be familiar with), or deleting elements of theoriginal text in order to produce a relatively sim-pler and shallower syntactic structure.
In addition,the output must be grammatical and coherent.
Theseconstraints are global in their scope, and cannot beadequately satisfied by optimizing each one of themindividually.
Our approach therefore uses an ILPformulation which will provide a globally optimalsolution.
Given an input sentence, our model decon-structs it into component phrases and clauses, eachof which is simplified (lexically and structurally)through QG rewrite rules.
We generate all possiblesimplifications for a given input and use the ILP tofind the best target subject to grammaticality con-straints.
In what follows we first detail how we ex-tract QG rewrite rules as these form the backbone ofour model and then formulate the ILP proper.3.1 Quasi-synchronous GrammarPhrase alignment Our model operates on indi-vidual sentences annotated with syntactic informa-tion i.e., phrase structure trees.
In our experiments,we obtain this information from the Stanford parser(Klein and Manning, 2003) but any other broadlysimilar parser could be used instead.
Given an inputsentence S1 or its parse tree T1, the QG constructsa monolingual grammar for parsing, or generating,possible translation trees T2.
A grammar node in thetarget tree T2 is modeled on a subset of nodes in thesource tree, with a rather loose alignment betweenthe trees.We take aligned sentence pairs represented asphrase structure trees and build up a list of leaf nodealignments based on lexical identity.
We align directparent nodes where more than one child node aligns.QG rules are created from aligned nodes above theleaf node level if the all the nodes in the target treecan be explained using nodes from the source.
Thishelps to improve the quality in what is inherently anoisy process, and it is largely responsible for a rel-atively small resulting grammar (see Table 2).
Ex-amples of phrase alignments (indicated with dottedlines) are shown in Figure 1.Syntactic simplification rules Each QG rule de-scribes the transformations required from source totarget phrase sub-trees.
It allows child (and possi-bly grand-child) constituents to be deleted or re-411ST..VPVP 2NP 4NNPMaryVBD 3metADVPRBafterwardsCCandVP 1NPNNdogPRP$hisVBDwalkedNPNNPSmithNNPJohnST (main)..VP 1NPNNdogPRP$hisVBDwalkedNPNNPSmithNNPJohnST (aux)..VP 2ADVPRBlaterNP 4NNPMaryVBD 3metNPPRPHeRule involving lexical substitution:?VP, VP?
?
?
[ADVP [RB afterwards] VBD 3 NP 4 ], [VBD 3 NP 4 ADVP [RB later]]?Rule for splitting into main constituent and auxiliary sentence:?VP, VP, ST?
?
?
[VP 1 and VP 2 ], [VP 1 ], [NP [PRP He] VP 2 .
]?Figure 1: A source sentence (upper tree) is split into two sentences.
Dotted lines show word alignments, while boxedsubscripts show aligned nodes used to form QG rules.
Below, two QG rules learned from this data.ordered, and for nodes to be flattened.
In addition,we allow insertion of punctuation and some func-tion words, identified by a small set of POS tags.
Todistinguish sentences proper (which have final punc-tuation) from clauses, we modify the output of theparser, changing the root sentence parse tag from Sto ST (a ?top-level sentence?
); this allows clauses tobe extracted and rewritten as stand-alone sentences.Lexical simplification rules Lexical substitutionsare an important part of simplification.
We learnthem from aligned sub-trees, in the same way asdescribed above for syntax rules, by allowing asmall number of lexical substitutions to be presentin the rules, and provided they do not include propernouns.
The resulting QG rules could be appliedby matching the syntax of the whole sub-tree sur-rounding the substitution, but this approach is overlyrestrictive and suffers from data sparsity.
Indeed,Yatskar et al (2010) learn lexical simplificationswithout taking syntactic context into account.
Wetherefore add a post-processing stage to the learningprocess.
For rules where the syntactic structures ofthe source and target sub-trees match, and the onlydifference is a lexical substitution, we construct amore general rule by extracting the words and cor-responding POS tags involved in the substitution.Then at the generation stage, identifying suitablerules depends only on the substitution words, ratherthan the surrounding syntactic context.
An exampleof a lexical substitution rule is shown in Figure 1.Sentence splitting rules Another important sim-plification technique is to split syntactically compli-cated sentences into several shorter ones.
To learnQG rules for this operation, the source sentence isaligned with two consecutive target sentences.Rather than expecting to discover a split point inthe source sentence, we attempt to identify a nodein the source parse tree that contributes to both ofthe two target sentences.
Our intuition is that oneof the target sentences will follow the general syn-tactic structure of the source sentence.
We designatethis as the main sentence.
A node in the source sen-tence parse tree will be aligned with a (similar butsimpler) node in the main target sentence, but at thesame time it will fully explain the other target sen-tence, which we term the auxiliary sentence.
It is412possible for the auxiliary sentence to come before orafter the main sentence.
In the learning procedure,we try both possible orderings, and record the orderin any QG rules successfully produced.The resulting QG rule is a tuple of three phrasestructure elements: the source node, the node in thetarget main sentence (the top level of this node istypically the same as that of the source node), andthe phrase structure of the entire auxiliary sentence.1In addition, there is a flag to indicate if the auxiliarysentence comes before or after the main sentence.This formalism is able to capture the operations re-quired to split sentences containing coordinate orsubordinate clauses, parenthetical content, relativeclauses and apposition.
An example of a sentencesplitting rule is illustrated in Figure 1.3.2 ILP-based GenerationWe cast the problem of finding a suitable target sim-plification given a source sentence as an integer lin-ear program (ILP).
Specifically, simplified text iscreated from source sentence parse trees by identi-fying and applying QG grammar rules.
These willhave matching structure and may also require lexicalmatching (shown using italics in the example rulesin Figure 1).
The generation process starts at the rootnode of the parse tree, applying QG rules to sub-trees until leaf nodes are reached.
We do not use theBayesian probability model proposed by Smith andEisner (2006) to identify the best sequence of sim-plification rules.
Instead, where there is more thanone matching rule, and so more than one simplifi-cation is possible, the alternatives are all generatedand incorporated into the target phrase structure tree.The ILP model operates over this phrase structuretree and selects the phrase nodes from which to formthe target output.Applying the QG rules on the source sentencegenerates a number of auxiliary sentences.
Let S bethis set of sentences.
Let P be the set of nodes in thephrase structure trees of the auxiliary sentences, andPs ?
P be the set of nodes in each sentence s ?
S .Let the sets Di ?
P , ?i ?
P capture the phrase de-pendency information for each node i, where eachset Di contains the nodes that depend on the pres-1Note that the target component comprises the second andthird elements as a pair, and variables from the source compo-nent are split between them.ence of i.
In a similar fashion, the sets Ai?
S , ?i?Pcapture the indices of any auxiliary sentences thatdepend on the presence of node i.
C ?
P is the setof nodes involving a choice of alternative simplifi-cations (nodes in the tree where more than one QGrewrite rule can be applied, as mentioned above);Ci ?
P , i ?
C are the sets of nodes that are directchildren of each such node, in other words they arethe individual simplifications.
Let l(w)i be the lengthof each node i in words, and l(sy)i its length in syl-lables.
As we shall see below counts of words andsyllables are important cues in assessing readability.The model is cast as an binary integer linearprogram.
A vector of binary decision variablesx ?
{0,1}|P | indicates if each node is to be part ofthe output.
A vector of auxiliary binary variablesy ?
{0,1}|S | indicates which (auxiliary) sentenceshave been chosen.maxx ?i?P gixi +hw +hsy (1a)s.t.
x j?
xi ?i ?
P , j ?Di (1b)xi?
ys ?i ?
P ,s ?
Ai (1c)xi?
ys ?s ?
S , i ?
Ps (1d)?j?Cix j = xi ?i ?
C , j ?
Ci (1e)?s?Syi ?
1 (1f)xi ?
{0,1} ?i ?
P (1g)ys ?
{0,1} ?s ?
S .
(1h)Our objective function, given in Equation (1a),is the summation of local and global compo-nents.
Each phrase is locally given a rewritepenalty gi, where common lexical substitutions,rewrites and simplifications are penalized less (aswe trust them more), compared to rarer QG rules.The penalty is a simple log-probability measure,gi = log(nrNr), where nr is the number of times theQG rule r was seen in the training data, and Nrthe number of times all suitable rules for thisphrase node were seen.
If no suitable rules exist, weset gi = 0.The other two components of the objective,hw and hsy, are global in nature, and guide the ILP413towards simpler language.
They draw inspirationfrom existing measures of readability (the ease withwhich a document can be read and understood).The primary aim of readability formulas is to assesswhether texts or books are suitable for students atparticular grade levels or ages (see Mitchell 1985 foran overview).
Intuitively, texts ought to be simpler ifthey correspond to low reading levels.
A commonlyused reading level measure is the Flesch-KincaidGrade Level (FKGL) index which estimates read-ability as a combination of the average number ofsyllables per word and the average number of wordsper sentence.
Unfortunately, this measure is non-linear2 and cannot be incorporated directly into theobjective of the ILP.
Instead, we propose a linear ap-proximation.
We provide the ILP with targets for theaverage number of words per sentence (wps), andsyllables per word (spw).
hw(x,y) then measures thenumber of words below this target level that the ILPhas achieved:hw(x,y) = wps??i?Syi?
?i?Pl(w)i xi.When positive, this indicates that sentences areshorter than target, and contributes positively to thereadability objective whilst encouraging the appli-cation of sentence splitting and deletion-based QGrules.
Similarly, hsy(x,y) measures the number ofsyllables below that expected, from the target aver-age and the number of words the ILP has chosen:hsy(x) = spw?
?i?Pl(w)i xi?
?i?Pl(sy)i xi.This component of the objective encourages thedeletion or lexical substitution of complex words.We can use the two target parameters (wps and spw)to control how much simplification the ILP shouldapply.Constraint (1b) enforces grammatical correctnessby ensuring that the phrase dependencies are re-spected and the resulting structure is a tree.
Phrasesthat depend on phrase i are contained in the set Di.Variable xi is true, and therefore phrase i will beincluded in the target output, if any of its depen-dents x j ?Di are true.3 Constraint (1c) links main2FKGL = 0.39( total wordstotal sentences)+1.8( total syllablestotal words)?15.593Constraints (1b), (1c) and (1d) are shown as dependenciesfor clarity, but they were implemented as inequalities in the ILP.phrases to auxiliary sentences, so that the latter canonly be included in the output if the main phrasehas also been chosen.
This helps to control coher-ence within the output text.
Despite seeming similarto (1c), the role of constraint (1d) is quite different.It links phrase variables x to sentence variables y, toensure the logical integrity of the model is correct.Where the QG provides alternative simplifications,it makes sense of course to select only one.
This iscontrolled by constraint (1e), and by placing all al-ternatives in the set Di for the node i.With these constraints alone, and faced with asource sentence that is particularly difficult to sim-plify, it is possible for the ILP solver to return a ?triv-ial?
solution of no output at all, as all other avail-able solutions result in a negative objective value.It is therefore necessary to impose a global mini-mum output constraint (1f).
In combination with thedependency relations in (1c), this constraint ensuresthat at least an element of the root sentence is presentin the output.
Global maximum length constraintsare a frequently occurring aspect of ILP models usedin NLP applications.
We decided not to incorporateany such constraints into our model, as we did notwant to place limitations on the simplification oforiginal content.4 Experimental SetupIn this section we present our experimental setupfor assessing the performance of the simplificationmodel described above.
We give details on the cor-pora and grammars we used, model parameters, thesystems used for comparison with our approach, andexplain how the output was evaluated.Grammar Extraction QG rules were learnedfrom revision histories and an aligned simplifica-tion corpus, which we obtained from snapshots4 ofMainEW and SimpleEW.
Wiki-related mark-up andmeta-information was removed to extract the plaintext from the articles.SimpleEW revisions not only simplify the text ofexisting articles, they may also introduce new con-tent, vandalize or remove vandalism, or perform nu-merous automatic ?house-keeping?
modifications.4The snapshots for MainEW (enwiki) and SimpleEW (sim-plewiki dated 2010-09-16 and 2010-09-13, respectively (bothavailable from http://download.wikimedia.org/).414Corpora Syntactic Lexical SplittingRevision 316 269 184Aligned 312 96 254Table 2: Number of QG rules extracted (after removingsingletons) from revision-based and aligned corpora.We identified suitable revisions for simplification byselecting those where the author had mentioned akeyword (such as simple, clarification or grammar)in the revision comments.
Each selected revisionwas compared to the previous version.
Because theentire article is stored at each revision, we needed toidentify and align modified sentences.
We first iden-tified modified sections using the Unix diff pro-gram, and then individual sentences within the sec-tions were aligned using the program dwdiff5.
Thisresulted in 14,831 paired sentences.
With regard tothe aligned simplification corpus, we paired 15,000articles from SimpleEW and MainEW following thelanguage link within the snapshot files.
Within thepaired articles, we identified aligned sentences us-ing macro alignment (at paragraph level) then mi-cro alignment (at sentence level), using tf.idf scoresto measure similarity (Barzilay and Elhadad, 2003;Nelken and Schieber, 2006).All source-target sentences (resulting from revi-sions or alignments) were parsed with the Stanfordparser (Klein and Manning, 2003) in order to la-bel the text with syntactic information.
QG ruleswere created by aligning nodes in these sentencesas described earlier.
A breakdown of the numberand type of rules we obtained from the revisionand aligned corpora (after removing rules appear-ing only once) is given in Table 2.
Examples of themost frequently learned QG rules are shown in Ta-ble 3.
Rules (1)?
(3) involve syntactic simplificationand rules (4)?
(6) involve sentence splitting.
Exam-ples of common lexical simplifications found by ourgrammar are: ?discovered?
?
?found?, ?defeated??
?won against?, ?may refer to??
?could mean?,?original??
?first?, ?requires??
?needs?.Sentence generation We generated simplifiedversions of MainEW sentences.
For each (parsed)source sentence, we created and solved an ILP (seeEquation (1)) parametrized as follows: the number5http://os.ghalkes.nl/dwdiff.html1.
?S, ST?
?
?
[NP 1 VP 2 ], [NP 1 VP 2 .]?2.
?S, ST?
?
?
[VP 1 ], [This VP 1 .]?3.
?NP, ST?
?
?
[NP 1 , NP 2 ], [NP 1 was VP 2 .]?4.
?ST, ST, ST?
?
?
[S 1 , and S 2 ], [ST 1 ], [ST 2 ]?5.
?ST, ST, ST?
?
?
[S 1 : S 2 ], [ST 1 ], [ST 2 ]?6.
?ST, ST, ST?
?
?
[S 1 , but S 2 ], [ST 1 ], [ST 2 ]?Table 3: Examples of QG rules involving syntactic sim-plification (1)?
(3) and sentence division (4)?(6).
The lat-ter are shown as the tuple ?source, target, aux?.
The trans-form of nodes from S to ST (for example) rely on theapplication of syntactic simplification rules rules.
Boxedsubscripts show aligned nodes.of target words per sentence (wps) was set to 8, andsyllables per word (spw) to 1.5.
These two param-eters were empirically tuned on the training set.
Tosolve the ILP model we used the ZIB OptimizationSuite software (Achterberg, 2007; Koch, 2004).
Thesolution was converted into a sentence by removingnodes not chosen from the tree representation, thenconcatenating the remaining leaf nodes in order.Evaluation We evaluated our model on the samedataset used in Zhu et al (2010), an aligned cor-pus of MainEW and SimpleEW sentences.
The cor-pus contains 100/131 source/target sentences andwas created automatically.
Sentences from this cor-pus (and their revisions) were excluded from train-ing.
We evaluated two versions of our model, onewith rewrite rules acquired from revision historiesof simplified documents and another one with rulesextracted from MainEW-SimpleEW aligned sen-tences.
These models were compared against Zhuet al (2010)6 who also learn simplification rulesfrom Wikipedia, and a simple baseline that usessolely lexical simplifications7 provided by the Sim-pleEW editor ?SpencerK?
(Spencer Kelly).
An obvi-ous idea would be to treat sentence simplification asan English-to-English translation problem and usean off-the-shelf system like Moses8 for the task.However, we refrained from doing so as Zhu et al(2010) show that Moses performs poorly, it cannotmodel rewrite operations that split sentences or dropwords and in most cases generates output identical6We are grateful to Zhemin Zhu for providing us with histest set and the output of his system.7http://www.spencerwaterbed.com/soft/simple/8http://www.statmt.org/moses/415MainEW Wonder has recorded several critically acclaimed albums and hit singles, and writes and produces songsfor many of his label mates and outside artists as well.Zhu et alWonder has recorded several praised albums and writes and produces songs.
Many of his label matesand outside artists as well.AlignILP Wonder has recorded several critically acclaimed albums and hit singles.
He produces songs for manyof his label mates and outside artists as well.
He writes.RevILP Wonder has recorded many critically acclaimed albums and hit singles.
He writes.
He makes songs formany of his label mates and outside artists as well.SimpleEW He has recorded 23 albums and many hit singles, and written and produced songs for many of his labelmates and other artists as well.MainEW The London journeys In 1790, Prince Nikolaus died and was succeeded by a thoroughly unmusicalprince who dismissed the entire musical establishment and put Haydn on a pension.Zhu et alThe London journeys in 1790, prince Nikolaus died and was succeeds by a son became prince.
A sonbecame prince told the entire musical start and put he on a pension.AlignILP The London journeys In 1790, Prince Nikolaus died.
He was succeeded by a thoroughly unmusicalprince.
He dismissed the entire musical establishment.
He put Haydn on a pension.RevILP The London journeys In 1790, Prince Nikolaus died.
He was succeeded by a thoroughly unmusicalprince.
He dismissed the whole musical establishment.
He put Haydn on a pension.SimpleEW The London journeys In 1790, Prince Nikolaus died and his son became prince.
Haydn was put on apension.Table 4: Example simplifications produced by the systems in this paper (RevILP, AlignILP) and Zhu et al?s (2010)model, compared to real Wikipedia text (MainEW: input source, SimpleEW: simplified target).to the source.We evaluated model output in two ways, using au-tomatic evaluation measures and human judgments.Intuitively, readability measures ought to be suit-able for assessing the output of simplification sys-tems.
We report results with the well-known Flesch-Kincaid Grade Level index (FKGL).
Experimentswith other readability measures such as the FleschReading Ease and the Coleman-Liau index obtainedsimilar results.
In addition, we also assessed how thesystem output differed from the human SimpleEWgold standard by computing BLEU (Papineni et al,2002) and TERp (Snover et al, 2009).
Both mea-sures are commonly used to automatically evaluatethe quality of machine translation output.
BLEU9scores the target output by counting n-gram matcheswith the reference, whereas TERp is similar to worderror rate, the only difference being that it allowsshifts and thus can account for word order differ-ences.
TERp also allows for stem, synonym, andparaphrase substitutions which are common rewriteoperations in simplification.In line with previous work on text rewriting(e.g., Knight and Marcu 2002) we also evaluated9We calculated single-reference BLEU using the mteval-v13a script (with the default settings).system output by eliciting human judgments.
Weconducted three experiments.
In the first experi-ment participants were presented with a source sen-tence and its target simplification and asked to ratewhether the latter was easier to read compared to thesource.
In the second experiment, they were askedto rate the grammaticality of the simplified output.In the third experiment, they judged how well thesimplification preserved the meaning of the source.In all experiments participants used a five point rat-ing scale where a high number indicates better per-formance.
We randomly selected and automaticallysimplified 64 sentences from Zhu et al?s (2010) testcorpus using the four models described above.
Wealso included gold standard simplifications.
Our ma-terials thus consisted of 320 (64 ?
5) source-targetsentences.10 We collected ratings from 45 unpaidvolunteers, all self reported native English speakers.The studies were conducted over the Internet usinga custom built web interface.
Examples of our ex-perimental items are given in Table 4 (we omit theoutput of SpencerK as this is broadly similar to thesource sentence, modulo lexical substitutions).10A Latin square design ensured that subjects did not see twodifferent simplifications of the same sentence.416Models FKGL BLEU TERPMainEW 15.12 ?
?SimpleEW 11.25 ?
?SpencerK 14.67 0.47 0.51Zhu et al9.41 0.38 0.59RevILP 10.92 0.42 0.60AlignILP 12.36 0.34 0.85Table 5: Model performance using automatic evaluationmeasures.5 ResultsThe results of our automatic evaluation are summa-rized in Table 5.
The first column reports the FKGLreadability index of the source sentences (MainEW),of their target simplifications (SimpleEW) and theoutput of four models: a simple baseline that re-lies on lexical substitution (SpencerK), Zhu et al?s(2010) model, and two versions of our model, onetrained on revision histories (RevILP) and anotherone trained on the MainEW-SimpleEW aligned cor-pus (AlignILP).
As can be seen, the source sentenceshave the highest reading level.
Zhu et al?s systemhas the lowest reading level followed by our ownmodels and SpencerK.
All models are significantly11different in reading level from SimpleEW with theexception of RevILP (using a one-way ANOVA withpost-hoc Tukey HSD tests).
SpencerK is not signif-icantly different in readability from MainEW; Re-vILP is significantly different from Zhu et al andAlignILP.
In sum, these results indicate that RevILPis the closest to SimpleEW and that the provenanceof the QG rules has an impact on the model?s perfor-mance.Table 5 also shows BLEU and TERp scores withSimpleEW as the reference.
These scores can beused to examine how close to the gold standard ourmodels are.
SpencerK has the highest BLEU andlowest TERp scores.12 This is expected as this base-line performs only a very limited type of rewriting,namely lexical substitution.
AlignILP is most differ-ent from the reference, followed by Zhu et al (2010)and RevILP.
Taken together these results indicate11All significance differences reported throughout this paperare with a level less than 0.01.12The perfect BLEU score is one and the perfect TERp scoreis zero.Models Simplicity Grammaticality MeaningSimpleEW 3.74 4.89 4.41SpencerK 1.41 4.87 4.84Zhu et al2.92 3.43 3.44RevILP 3.64 4.55 4.19AlignILP 2.69 4.03 3.98Table 6: Average human ratings for gold standard Sim-pleEW sentences, a simple baseline (SpencerK) based onlexical substitution, Zhu et al?s 2010 model, and two ver-sions of our ILP model (RevILP and AlignILP).Zhu et alAlignILP RevILP SimpleEWSpencerK 2?4 2?4 24 24Zhu et al?4 2?4 2?4AlignILP 2?N 2?4RevILP NTable 7: 2/: is/not sig.
diff.
wrt simplicity; ?/: is/notsig.
diff.
wrt grammaticality; 4/N: is/not sig.
diff.
wrtmeaning.that the ILP models perform a fair amount of rewrit-ing without simply rehashing the source sentence.We now turn to the results of our judgment elic-itation study.
Table 6 reports the average ratingsfor Simplicity (is the target sentence simpler thanthe source?
), Grammaticality (is the target sentencegrammatical?
), and Meaning (does the target pre-serve the meaning of the source?).
With regard tosimplicity, our participants perceive the gold stan-dard (SimpleEW) to be the simplest, followed byRevILP, Zhu et al and AlignILP.
SpencerK is theleast simple model and the most grammatical oneas lexical substitutions do not change the structureof the sentence.
Interestingly, RevILP and AlignILPare also rated highly with regard to grammaticality.Zhu et al (2010) is the least grammatical model.Finally, RevILP preserves the meaning of the tar-get as well as SimpleEW, whereas Zhu et al yieldsthe most distortions.
Again SpencerK is rated highlyamongst the other models as it is does not substan-tially simplify and thus change the meaning of thesource.Table 7 reports on pairwise comparisons betweenall models and their statistical significance (again us-ing a one-way ANOVA with post-hoc Tukey HSDtests).
RevILP is not significantly different fromSimpleEW on any dimension (Simplicity, Grammat-417Original story: There was once a sweet little maid who lived with her father and mother in a pretty littlecottage at the edge of the village.
At the further end of the wood was another pretty cottage and in it livedher grandmother.
Everybody loved this little girl, her grandmother perhaps loved her most of all and gaveher a great many pretty things.
Once she gave her a red cloak with a hood which she always wore, so peoplecalled her Little Red Riding Hood.Generated simplification: There was once a sweet little maid.
She lived with her father and mother ina pretty little cottage at the edge of the village.
At the further end of the wood it lived her grandmother.Everybody loved this little girl.
Her grandmother perhaps loved her most of all.
She gave her a great manypretty things.
Once she gave her a red cloak with a hood, so persons called her Little Red Riding Hood.Table 8: Excerpt of Little Red Riding Hood simplified by the RevILP model.
Modifications to the original story arehighlighted in italics.icality, Meaning), whereas Zhu et al differs signif-icantly from RevILP and SimpleEW on all dimen-sions.
It is also significantly different from Alig-nILP in terms of grammaticality and meaning butnot simplicity.
RevILP is significantly more simpleand grammatical than AlignILP but performs com-parably with respect to preserving the meaning ofthe source.In sum, our results show that RevILP is the bestperforming model.
It creates sentences that are sim-ple, grammatical and adhere to the meaning ofthe source.
The QG rules obtained from the revi-sion histories produce better output compared to thealigned corpus.
As revision histories are created byWikipedia contributors, they tend to be a more ac-curate data source than aligned sentences which areobtained via an automatic and unavoidably noisyprocedure.
Our results also show that a more gen-eral model not restricted to specific rewrite opera-tions like Zhu et al (2010) obtains superior resultsand has better coverage.We also wanted to see whether a simplificationmodel trained on Wikipedia could be applied to an-other domain.
To this end, we used RevILP to sim-plify five children stories from the Gutenburg13 col-lection.
The model simplified one sentence at a timeand was ran with the Wikipedia settings without anymodification.
The mean FKGL on the simplified sto-ries was 3.78. compared to 7.04 for the original ones.An example of our system?s output on Little RedRiding Hood is shown in Table 8.Possible extensions and improvements to the cur-rent model are many and varied.
We have presentedan all-purpose simplification model without a target13http://www.gutenberg.orgaudience or application in mind.
An interesting re-search direction would be to simplify text accord-ing to readability levels or text genres (e.g., news-paper vs literary text).
We could do this by incorpo-rating readability-specific constraints to the ILP orby changing the objective function (e.g., by favoringmore domain-specific rules).
Finally, we would liketo extend the current model so as to simplify entiredocuments both in terms of style and content.Acknowledgments We are grateful to Lillian Leewhose invited talk at CoNLL-2010 inspired this re-search.
We would also like to thank the members ofthe Probabilistic Models of Language group at theSchool of Informatics for valuable discussions andcomments.
We acknowledge the support of EPSRCthrough project grant EP/F055765/1.ReferencesAchterberg, Tobias.
2007.
Constraint Integer Pro-gramming.
Ph.D. thesis, Technische Universita?tBerlin.Barzilay, Regina.
2003.
Information Fusion forMulti-Document Summarization: Paraphrasingand Generation.
Ph.D. thesis, Columbia Univer-sity.Barzilay, Regina and Noemie Elhadad.
2003.
Sen-tence alignment for monolingual comparable cor-pora.
In Proceedings of the Conference on Em-pirical Methods in Natural Language Processing.Sapporo, Japan, pages 25?32.Beigman Klebanov, Beata, Kevin Knight, andDaniel Marcu.
2004.
Text simplification forinformation-seeking applications.
In Proceed-ings of Ontologies, Dabases, and Applications ofSemantics (ODBASE) International Conference.418Springer, Agia Napa, Cyprus, volume 3290 ofLecture Notes in Computer Science, pages 735?747.Carroll, John, Guido Minnen, Darren Pearce,Yvonne Canning, Siobhan Devlin, and John Tait.1999.
Simplifying text for language-impairedreaders.
In Proceedings of the 9th Conference ofthe European Chapter of the ACL.
Bergen, Nor-way, pages 269?270.Chandrasekar, Raman, Christine Doran, and Ban-galore Srinivas.
1996.
Motivations and meth-ods for text simplification.
In Proceedings of the16th International Conference on ComputationalLinguistics.
Copenhagen, Denmark, pages 1041?1044.Cohn, Trevor and Mirella Lapata.
2008.
Sentencecompression beyond word deletion.
In Pro-ceedings of the 22nd International Conferenceon Computational Linguistics.
Manchester, UK,pages 137?144.Das, Dipanjan and Noah A. Smith.
2009.
Paraphraseidentification as probabilistic quasi-synchronousrecognition.
In Proceedings of the ACL-IJCNLP.Suntec, Singapore, pages 468?476.Devlin, Siobhan.
1999.
Simplifying Natural Lan-guage for Aphasic Readers.
Ph.D. thesis, Univer-sity of Sunderland.Inui, Kentaro, Atsushi Fujita, Tetsuro Takahashi,Ryu Iida, and Tomoya Iwakura.
2003.
Text sim-plification for reading assistance: A project note.In Proceedings of the Second International Work-shop on Paraphrasing.
Association for Computa-tional Linguistics, Sapporo, Japan, pages 9?16.Kaji, Nobuhiro, Daisuke Kawahara, Sadao Kuro-hashi, and Satoshi Sato.
2002.
Verb paraphrasebased on case frame alignment.
In Proceedings of40th Annual Meeting of the Association for Com-putational Linguistics.
Association for Compu-tational Linguistics, Philadelphia, Pennsylvania,USA, pages 215?222.Klein, Dan and Christopher D. Manning.
2003.
Ac-curate unlexicalized parsing.
In Proceedings ofthe 41st Annual Meeting of the Association ofComputational Linguistics.
Sapporo, Japan, pages423?430.Knight, Kevin and Daniel Marcu.
2002.
Summa-rization beyond sentence extraction: a probabilis-tic approach to sentence compression.
ArtificialIntelligence 139(1):91?107.Koch, Thorsten.
2004.
Rapid Mathematical Pro-totyping.
Ph.D. thesis, Technische Universita?tBerlin.Mitchell, James V. 1985.
The Ninth Mental Mea-surements Year-book.
University of NebraskaPress, Lincoln, Nebraska.Nastase, Vivi and Michael Strube.
2008.
DecodingWikipedia categories for knowledge acquisition.In Proceedings of the 23rd Conference on Artifi-cial Intelligence.
pages 1219?1224.Nelken, Rani and Stuart Schieber.
2006.
Towardsrobust context-sensitive sentence alignment formonolingual corpora.
In Proceedings of the 11thConference of the European Chapter of the As-sociation for Computational Linguistics.
Trento,Italy, pages 161?168.Papineni, Kishore, Salim Roukos, Todd Ward, andWei-Jing Zhu.
2002.
BLEU: a method for auto-matic evaluation of machine translation.
In Pro-ceedings of the 40th ACL.
Philadelphia, PA, pages311?318.Ponzetto, Simone Paolo and Michael Strube.
2007.Knowledge derived from Wikipedia for comput-ing semantic relatedness.
Journal of Artificial In-telligence Research 30:181?212.Sauper, Christina and Regina Barzilay.
2009.
Au-tomatically generating Wikipedia articles: Astructure-aware approach.
In Proceedings of theJoint Conference of the 47th Annual Meeting ofthe ACL and the 4th International Joint Con-ference on Natural Language Processing of theAFNLP.
Association for Computational Linguis-tics, Suntec, Singapore, pages 208?216.Siddharthan, Advaith.
2003.
Syntactic Simplifica-tion and Text Cohesion.
Ph.D. thesis, Universityof Cambridge, University of Cambridge.Siddharthan, Advaith.
2004.
Syntactic simplifica-tion and text cohesion.
in research on languageand computation.
Research on Language andComputation 4(1):77?109.Smith, David and Jason Eisner.
2006.
Quasi-synchronous grammars: Alignment by soft pro-jection of syntactic dependencies.
In Proceedingson the Workshop on Statistical Machine Transla-419tion.
Association for Computational Linguistics,New York City, pages 23?30.Smith, David A. and Jason Eisner.
2009.
Parseradaptation and projection with quasi-synchronousgrammar features.
In Proceedings of the EMNLP.Suntec, Singapore, pages 822?831.Snover, Matthew, Nitin Madnani, Bonnie Dorr, andRichard Schwartz.
2009.
Fluency, adequacy,or HTER?
Exploring different human judgmentswith a tunable MT metric.
In Proceedings of theFourth Workshop on Statistical Machine Transla-tion.
Athens, Greece, pages 259?268.Vickrey, David and Daphne Koller.
2008.
Sentencesimplification for semantic role labeling.
In Pro-ceedings of ACL-08: HLT .
Association for Com-putational Linguistics, Columbus, Ohio, pages344?352.Wang, Mengqiu, Noah A. Smith, and Teruko Mita-mura.
2007.
What is the Jeopardy model?
a quasi-synchronous grammar for QA.
In Proceedingsof the EMNLP-CoNLL.
Prague, Czech Republic,pages 22?32.Watanabe, Willian Massami, Arnaldo Candido Ju-nior, Vin?
?cius Rodriguez de Uze?da, Renata Pon-tin de Mattos Fortes, Thiago Alexandre SalgueiroPardo, and Sandra Maria Alu?sio.
2009.
Facilita:reading assistance for low-literacy readers.
InProceedings of the 27th ACM International Con-ference on Design of Communication.
Blooming-ton, IN.Woodsend, Kristian, Yansong Feng, and MirellaLapata.
2010.
Title generation with quasi-synchronous grammar.
In Proceedings of the2010 Conference on Empirical Methods in Natu-ral Language Processing.
Association for Com-putational Linguistics, Cambridge, MA, pages513?523.Wu, Fei and Daniel S. Weld.
2010.
Open infor-mation extraction using Wikipedia.
In Proceed-ings of the 48th Annual Meeting of the Associ-ation for Computational Linguistics.
Associationfor Computational Linguistics, Uppsala, Sweden,pages 118?127.Yamada, Kenji and Kevin Knight.
2001.
A syntax-based statistical translation model.
In Proceed-ings of 39th Annual Meeting of the Associationfor Computational Linguistics.
Toulouse, France,pages 523?530.Yamangil, Elif and Rani Nelken.
2008.
MiningWikipedia revision histories for improving sen-tence compression.
In Proceedings of ACL-08:HLT, Short Papers.
Association for Computa-tional Linguistics, Columbus, Ohio, pages 137?140.Yatskar, Mark, Bo Pang, Cristian Danescu-Niculescu-Mizil, and Lillian Lee.
2010.
Forthe sake of simplicity: Unsupervised extrac-tion of lexical simplifications from Wikipedia.In Proceedings of the Annual Meeting of theNorth American Chapter of the Association forComputational Linguistics.
pages 365?368.Zhao, Shiqi, Xiang Lan, Ting Liu, and Sheng Li.2009.
Application-driven statistical paraphrasegeneration.
In Proceedings of the Joint Confer-ence of the 47th Annual Meeting of the ACL andthe 4th International Joint Conference on NaturalLanguage Processing of the AFNLP.
Singapore,pages 834?842.Zhu, Zhemin, Delphine Bernhard, and IrynaGurevych.
2010.
A monolingual tree-based trans-lation model for sentence simplification.
In Pro-ceedings of the 23rd International Conference onComputational Linguistics.
Beijing, China, pages1353?1361.420
