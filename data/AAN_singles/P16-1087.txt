Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 919?929,Berlin, Germany, August 7-12, 2016.c?2016 Association for Computational LinguisticsInvestigating LSTMs for Joint Extractionof Opinion Entities and RelationsArzoo Katiyar and Claire CardieDepartment of Computer ScienceCornell UniversityIthaca, NY, 14853, USAarzoo, cardie@cs.cornell.eduAbstractWe investigate the use of deep bi-directional LSTMs for joint extraction ofopinion entities and the IS-FROM and IS-ABOUT relations that connect them ?
thefirst such attempt using a deep learningapproach.
Perhaps surprisingly, we findthat standard LSTMs are not competitivewith a state-of-the-art CRF+ILP joint in-ference approach (Yang and Cardie, 2013)to opinion entities extraction, perform-ing below even the standalone sequence-tagging CRF.
Incorporating sentence-leveland a novel relation-level optimization,however, allows the LSTM to identifyopinion relations and to perform within 1?3% of the state-of-the-art joint model foropinion entities and the IS-FROM relation;and to perform as well as the state-of-the-art for the IS-ABOUT relation ?
all with-out access to opinion lexicons, parsers andother preprocessing components requiredfor the feature-rich CRF+ILP approach.1 IntroductionThere has been much research in recent years inthe area of fine-grained opinion analysis wherethe goal is to identify subjective expressions intext along with their associated sources and tar-gets.
More specifically, fine-grained opinion anal-ysis aims to identify three types of opinion enti-ties:?
opinion expressions, O, which are directsubjective expressions (i.e., explicit mentionsof otherwise private states or speech eventsexpressing private states (Wiebe and Cardie,2005));?
opinion targets, T , which are the entities ortopics that the opinion is about; and?
opinion holders, H , which are the entitiesexpressing the opinion.In addition, the task involves identifying the IS-FROM and IS-ABOUT relations between an opinionexpression and its holder and target, respectively.In the sample sentences, numerical subscripts in-dicate an IS-FROM or IS-ABOUT relation.S1 [The sale]T1[infuriated]O1[Beijing]H1,2which [regards]O2[Taiwan]T2an integralpart of its territory awaiting reunification, byforce if necessary.S2 ?
[Our agency]T1,H2[seriously needs]O2[equipment for detecting drugs]T2,?
[he]H1[said]O1.In S1, for example, ?infuriated?
indicates thatthere is an (negative) opinion from ?Beijing?
re-garding ?the sale.
?1Traditionally, the task of extracting opinionentities and opinion relations was handled in apipelined manner, i.e., extracting the opinion ex-pressions first and then extracting opinion tar-gets and opinion holders based on their syntac-tic and semantic associations with the opinion ex-pressions (Kim and Hovy, 2006; Kobayashi et al,2007).
More recently, methods that jointly in-fer the opinion entity and relation extraction tasks(e.g., using Integer Linear Programming (ILP))have been introduced (Choi et al, 2006; Yang andCardie, 2013) and show that the existence of opin-ion relations provides clues for the identificationof opinion entities and vice-versa, and thus resultsin better performance than a pipelined approach.However, the success of these methods dependscritically on the availability of opinion lexicons,dependency parsers, named-entity taggers, etc.1This paper does not attempt to determine the sentiment,i.e., the positive or negative polarity, of an opinion.919Alternatively, neural network-based methodshave been employed.
In these approaches, therequired latent features are automatically learnedas dense vectors of the hidden layers.
Liu et al(2015), for example, compare several variationsof recurrent neural network methods and find thatlong short-term memory networks (LSTMs) per-form the best in identifying opinion expressionsand opinion targets for the specific case of prod-uct/service reviews.Motivated by the recent success of LSTMs onthis and other problems in NLP, we investigatehere the use of deep bi-directional LSTMs for jointextraction of opinion expressions, holders, targetsand the relations that connect them.
This is thefirst attempt to handle the full opinion entity andrelation extraction task using a deep learning ap-proach.In experiments on the MPQA dataset for opin-ion entities (Wiebe and Cardie, 2005; Wilson,2008), we find that standard LSTMs are not com-petitive with the state-of-the-art CRF+ILP jointinference approach of Yang and Cardie (2013),performing below even the standalone sequence-tagging CRF.
Inspired by Huang et al (2015),we show that incorporating sentence-level, andour newly proposed relation-level optimization,allows the LSTM to perform within 1?3% of theILP joint model for all three opinion entity typesand to do so without access to opinion lexicons,parsers or other preprocessing components.For the primary task of identifying opinion en-tities together with their IS-FROM and IS-ABOUTrelations, we show that the LSTM with sentence-and relation-level optimizations outperforms anLSTM baseline that does not employ joint infer-ence.
When compared to the CRF+ILP-basedjoint inference approach, the optimized LSTMperforms slightly better for the IS-ABOUT2rela-tion and within 3% for the IS-FROM relation.In the sections that follow, we describe: relatedwork (Section 2) and the multi-layer bi-directionalLSTM (Section 3); the LSTM extensions (Sec-tion 4); the experiments on the MPQA corpus(Sections 5 and 6) and error analysis (Section 7).2Target and IS-ABOUT relation identification is one im-portant aspect of opinion analysis that hasn?t been much ad-dressed in previous work and has proven to be difficult forexisting methods.2 Related WorkLSTM-RNNs (Hochreiter and Schmidhuber,1997) have recently been applied to many se-quential modeling and prediction tasks, suchas machine translation (Bahdanau et al, 2014;Sutskever et al, 2014), speech recognition(Graves et al, 2013), NER (Hammerton, 2003).The bi-directional variant of RNNs has beenfound to perform better as it incorporates infor-mation from both the past and the future (Schusterand Paliwal, 1997; Graves et al, 2013).
DeepRNNs (stacked RNNs) (Schmidhuber, 1992; Hihiand Bengio, 1996) capture more abstract andhigher-level representation in different layersand benefit sequence modeling tasks (?Irsoy andCardie, 2014).
Collobert et al (2011) foundthat adding dependencies between the tags inthe output layer improves the performance ofSemantic Role Labeling task.
Later, Huang et al(2015) also found that adding a CRF layer on topof bi-directional LSTMs to capture these depen-dencies can produce state-of-the-art performanceon part-of-speech (POS), chunking and NER.For fine-grained opinion extraction, earlierwork (Wilson et al, 2005; Breck et al, 2007; Yangand Cardie, 2012) focused on extracting subjectivephrases using a CRF-based approach from open-domain text such as news articles.
Choi et al(2005) extended the task to jointly extract opin-ion holders and these subjective expressions.
Yangand Cardie (2013) proposed a ILP-based joint-inference model to jointly extract the opinion en-tities and opinion relations, which performed bet-ter than the pipelined based approaches (Kim andHovy, 2006).In the neural network domain,?Irsoy and Cardie(2014) proposed a deep bi-directional recurrentneural network for identifying subjective expres-sions, outperforming the previous CRF-basedmodels.
Irsoy and Cardie (2013) additionally pro-posed a bi-directional recursive neural networkover a binary parse tree to jointly identify opinionentities, but performed significantly worse thanthe feature-rich CRF+ILP approach of Yang andCardie (2013).
Liu et al (2015) used several vari-ants of recurrent neural networks for joint opin-ion expression and aspect/target identification oncustomer reviews for restaurants and laptops, out-performing the feature-rich CRF based baseline.In the product reviews domain, however, the opin-ion holder is generally the reviewer and the task920does not involve identification of relations be-tween opinion entities.
Hence, standard LSTMsare applicable in this domain.
None of the aboveneural network based models can jointly modelopinion entities and opinion relations.In the relation extraction domain, several neu-ral networks have been proposed for relation clas-sification, such as RNN-based models (Socher etal., 2012) and LSTM-based models (Xu et al,2015).
These models depend on constituent ordependency tree structures for relation classifica-tion, and also do not model entities jointly.
Re-cently, Miwa and Bansal (2016) proposed a modelto jointly represent both entities and relations withshared parameters, but it is not a joint-inferenceframework.3 MethodologyFor our task, we propose the use of multi-layerbi-directional LSTMs, a type of recurrent neuralnetwork.
Recurrent neural networks have recentlybeen used for modeling sequential tasks.
Theyare capable of modeling sequences of arbitrarylength by repetitive application of a recurrent unitalong the tokens in the sequence.
However, re-current neural networks are known to have sev-eral disadvantages like the problem of vanishingand exploding gradients.
Because of these prob-lems, it has been found that recurrent neural net-works are not sufficient for modeling long term de-pendencies.
Hochreiter and Schmidhuber (1997),thus proposed long short term memory (LSTMs),a variant of recurrent neural networks.3.1 Long Short Term Memory (LSTM)Long short term memory networks are capable oflearning long-term dependencies.
The recurrentunit is replaced by a memory block.
The mem-ory block contains two cell states ?
memory cellCtand hidden state ht; and three multiplicativegates ?
input gate it, forget gate ftand output gateot.
These gates regulate the addition or removal ofinformation to the cell state thus overcoming van-ishing and exploding gradients.ft= ?
(Wfxt+ Ufht?1+ bf)it= ?
(Wixt+ Uiht?1+ bi)The forget gate ftand input gate itabove decideswhat part of the information we are going to throwaway from the cell state and what new informationwe are going to store in the cell state.
The sigmoidoutputs a number between 0 and 1 where 0 im-plies that the information is completely lost and 1means that the information is completely retained.
?Ct= tanh(Wcxt+ Ucht?1+ bc)Ct= it?
?Ct+ ft?
Ct?1Thus, the intermediate cell state?Ctand previouscell stateCt?1are used to update the new cell stateCt.ot= ?
(Woxt+ Uoht?1+ VoCt+ bo)ht= ot?
tanh(Ct)Next, we update the hidden state htbased on theoutput gate otand the cell state Ct. We pass boththe cell state Ctand the hidden state htto the nexttime step.3.2 Multi-layer Bi-directional LSTMIn sequence tagging problems, it has been foundthat only using past information for computing thehidden state htmay not be sufficient.
Hence, pre-vious works (Graves et al, 2013;?Irsoy and Cardie,2014) proposed the use of bi-directional recurrentneural networks for speech and NLP tasks, respec-tively.
The idea is to also process the sequence inthe backward direction.
Hence, we can computethe hidden state?
?htin the forward direction and?
?htin the backward direction for every token.Also, in more traditional feed-forward net-works, deep networks have been found to learnabstract and hierarchical representations of the in-put in different layers (Bengio, 2009).
The multi-layer LSTMs have been proposed (Hermans andSchrauwen, 2013) to capture long-term dependen-cies of the input sequences in different layers.For the first hidden layer, the computation pro-ceeds similar to that described in Section 3.1.However, for higher hidden layers i the input tothe memory block is the hidden state and memorycell from the previous layer i ?
1 instead of theinput vector representation.For this paper, we only use the hidden state fromthe last layer L to compute the output state yt.zt=??V??ht(L)+??V?
?ht(L)+ cyt= g(zt)4 Network TrainingFor our problem, we wish to predict a label y froma discrete set of classes Y for every word in a sen-tence.
As is the norm, we train the network by921maximizing the log-likelihood?
(x,y)?Tlog p(y|x, ?
)over the training data T, with respect to the pa-rameters ?, where x is the input sentence and y isthe corresponding tag sequence.
We propose threealternatives for the log-likelihood computation.4.1 Word-Level Log-Likelihood (WLL)We first formulate a word-level log-likelihood(WLL) (adapted from Collobert et al (2011))that considers all words in a sentence indepen-dently.
We interpret the score ztcorrespondingto the ithtag [zt]ias a conditional tag probabilitylog p(i|x, ?)
by applying a softmax operation.p(i|x, ?)
= softmax(zit)=ezit?jezjtFor the tag sequence y given the input sentence xthe log-likelihood is :log p(y|x, ?)
= zy?
logaddjzj4.2 Sentence-Level Log-Likelihood (SLL)In the word-level approach above, we discard thedependencies between the tags in a tag sequence.In our sentence-level log-likelihood (SLL) formu-lation (also adapted from Collobert et al (2011))we incorporate these dependencies: we introducea transition score [A]i,jfor jumping from tag i totag j of adjacent words in the tag sequence to theset of parameters??.
These transition scores aregoing to be trained.We use both the transition scores [A] and theoutput scores z to compute the sentence scores(x|Tt=1, y|Tt=1,??
).s(x, y,??)
=T?t=1([A]yt?1,yt+ zytt)We normalize this sentence score over all possiblepaths of tag sequences y?
to get the log conditionalprobability as below :log psent(y|x,??)
= s(x, y,??)?
logaddy?s(x, y?,??
)Even though the number of tag sequences growsexponentially with the length of the sentence, wecan compute the normalization factor in lineartime (Collobert et al, 2011).At inference time, we find the best tag sequenceargmaxy?s(x, y?,??
)for an input sentence x using Viterbi decoding.
Inthis case, we basically maximize the same likeli-hood as in a CRF except that a CRF is a linearmodel.The above sentence-level log-likelihood is use-ful for sequential tagging, but it cannot be directlyused for modeling relations between non-adjacentwords in the sentence.
In the next subsection, weextend the above idea to also model relations be-tween non-adjacent words.4.3 Relation-Level Log-Likelihood (RLL)For every word xtin the sentence x, we output thetag ytand a distance dt.
If a word at position t isrelated to a word at position k and k < t, then dt=(t ?
k).
If word t is not related to any other wordto its left, then dt= 0.
Let DLeftbe the maximumdistance we model for such left-relations3.zt=??Vr??ht(L)+??Vr?
?ht(L)+ crWe let??Vr?
R(DLeft+1)?Y?dh(where dhis thedimensionality of hidden units) such that the out-put state zt?
R(DLeft+1)?Yas compared to zt?R(1)?Yin case of sentence-level log-likelihood.In order to add dependencies between tagsand relations, we introduce a transition score[A]i,j,d?,d?for jumping from tag i and relation dis-tance d?to tag j and relation distance d?of adja-cent words in the tag sequence, to the set of pa-rameters ??.
These transition scores are also go-ing to be trained similar to the transition scores insentence-level log-likelihood.The sentence score s(x|Tt=1, y|Tt=1, d|Tt=1, ??)
is:s(x, y, d, ??)
=T?t=1([A]yt?1,yt,dt?1,dt+ zyt,dtt)We normalize this sentence score over all possi-ble paths of tag y?
and relation sequences?d to getthe log conditional probability as below :log prel,Left(y, d|x,??)
=s(x, y, d, ??)?
logaddy?,d?s(x, y?,?d, ??
)3Later in this section, we will also add a similar likeli-hood in the objective function for right-relations, i.e., for eachword the related words are in its right context.922The sale infuriated Beijing which regards Taiwan an integral part ...Entity tags B T I T B O B H O B O B T O O O ...Left Rel (dleft) 0 0 0 0 0 2 1 0 0 0 ...Right Rel (dright) 2 1 1 0 0 0 0 0 0 0 ...IS-ABOUTIS-FROMIS-FROMIS-ABOUTFigure 1: Gold standard annotation for an example sentence from MPQA dataset.
O represents the?Other?
tag in the BIO scheme.We can still compute the normalization fac-tor in linear time similar to sentence-level log-likelihood.At inference time, we jointly find the best tagand relation sequenceargmaxy?,d?s(x, y?,?d, ??
)for an input sentence x using Viterbi decoding.For our task of joint extraction of opinion en-tities and relations, we train our model to pre-dict tag y and relation distance d for every wordin the sentence by maximizing the log-likelihood(SLL+RLL) below using Adadelta (Zeiler, 2012).?
(x,y)?Tlog psent(y|x, ??
)+ log prel,Left(y, d|x, ??
)+ log prel,Right(y, d|x, ??
)5 Experiments5.1 DataWe use the MPQA 2.0 corpus (Wiebe and Cardie,2005; Wilson, 2008).
It contains news articlesand editorials from a wide variety of news sources.There are a total of 482 documents in our datasetcontaining 9471 sentences with phrase-level anno-tations.
We set aside 132 documents as a devel-opment set and use the remaining 350 documentsas the evaluation set.
We report the results us-ing 10-fold cross validation at the document levelto mimic the methodology of Yang and Cardie(2013).The dataset contains gold-standard annotationsfor opinion entities ?
expressions, targets, hold-ers.
We use only the direct subjective/opinion ex-pressions.
There are also annotations for opin-ion relations ?
IS-FROM between opinion holdersand opinion expressions; and IS-ABOUT betweenopinion targets and opinion expressions.
These re-lations can overlap but we discard all relations thatcontain sub-relations similar to Yang and Cardie(2013).
We also leave identification of overlap-ping relations for future work.Figure 1 gives an example of an annotated sen-tence from the dataset: boxes denote opinion enti-ties and opinion relations are shown by arcs.
Weinterpret these relations arcs as directed ?
froman opinion expression towards an opinion holder,and from an opinion target towards an opinion ex-pression.In order to use the RLL formulation as de-fined in Section 4.3, we pre-process these relationarcs to obtain the left-relation distances (dleft) andright-relation distances (dright) as shown in Fig-ure 1.
For each word in an entity, we find itsdistance to the nearest word in the related entity.These distances become our relation tags.
The en-tity tags are interpreted using the BIO scheme, alsoshown in the figure.
Our RLL model jointly mod-els the entity tags and relation tags.
At inferencetime, these entity tags and relation tags are used to-gether to determine IS-FROM and IS-ABOUT rela-tions.
We use a simple majority vote to determinethe final entity tag from SLL+RLL model.5.2 Evaluation MetricsWe use precision, recall and F-measure (as in Yangand Cardie (2013)) as evaluation metrics.
Sincethe identification of exact boundaries for opin-ion entities is hard even for humans (Wiebe andCardie, 2005), soft evaluation methods such asBinary Overlap and Proportional Overlap are re-ported.
Binary Overlap counts every overlappingpredicted and gold entity as correct, while Propor-tional Overlap assigns a partial score proportionalto the ratio of overlap span and the correct span(Recall) or the ratio of overlap span and the pre-dicted span (Precision).For the case of opinion relations, we report pre-cision, recall and F-measure according to the Bi-nary Overlap.
It considers a relation correct ifthere is an overlap between the predicted opin-923Opinion Expression Opinion Target Opinion HolderMethod P R F1 P R F1 P R F1CRF 84.423.2461.613.2071.172.6680.382.7246.804.4159.104.0673.374.0949.713.4659.213.49CRF+ILP 73.533.9074.892.5174.112.4977.273.4956.943.9465.403.0767.003.1767.223.5067.222.54LSTM+WLL 67.884.4966.133.2066.872.6658.714.8754.923.2356.501.5160.334.5463.342.3361.652.37LSTM+SLL 70.455.1266.653.4668.373.1463.024.6156.773.9859.653.6161.853.8263.123.5962.352.46LSTM+SLL+RLL 71.735.3570.923.9671.112.7164.525.5265.944.7464.841.4462.753.7567.174.3764.712.23CRF 80.783.2757.623.2467.192.6371.813.2242.363.7853.233.6971.563.5448.613.5157.863.43CRF+ILP 71.034.0369.722.3770.222.4471.943.2549.833.2458.722.8065.703.0765.913.6365.682.61LSTM+WLL 64.474.7959.453.5261.672.2652.725.0144.212.5447.851.4158.414.7259.722.5252.452.23LSTM+SLL 65.975.4661.763.6963.603.0554.464.4950.164.3852.013.0559.803.2961.273.7560.402.26LSTM+SLL+RLL 65.484.9265.543.6565.562.7152.756.8160.544.7855.811.9659.443.5665.514.2262.182.50Table 1: Performance on opinion entity extraction.
Top table shows Binary Overlap performance; bottomtable shows Proportional Overlap performance.
Superscripts designate one standard deviation.ion expression and the gold opinion expression aswell as an overlap between the predicted entity(holder/target) and the gold entity (holder/target).5.3 BaselinesCRF+ILP.
We use the ILP-based joint inferencemodel (Yang and Cardie, 2013) as baseline forboth the entity and relation extraction tasks.
It rep-resents the state-of-the-art for fine-grained opin-ion extraction.
Their method first identifies opin-ion entities using CRFs (an additional baseline)with a variety of features such as words, POStags, and lexicon features (the subjectivity strengthof the word in the Subjectivity Lexicon).
Theyalso train a relation classifier (logistic regression)by over-generating candidates from the CRFs (50-best paths) using local features such as word, POStags, subjectivity lexicons as well as semantic andsyntactic features such as semantic frames, depen-dency paths, WordNet hypernyms, etc.
Finally,they use ILP for joint-inference to find the opti-mal prediction for both opinion entity and opinionrelation extraction.LSTM+SLL+Softmax.
As an additional base-line for relation extraction, we train a softmaxclassifier on top of our SLL framework.
Wejointly learn the relation classifier and SLL model.For every entity pair [x]ji, [x]lk, we first sum thestart and end word output representation [zt] andthen concatenate them to learn softmax weightW?where W??
R3?2dh.yrel= softmax(W?
[[zt]i+ [zt]j[zt]k+ [zt]l])The inference is pipelined in this case.
At the timeof inference, we first predict the entity spans andthen use these spans for relation classification.5.4 Hyperparameter and Training DetailsWe use multi-layer bi-directional LSTMs for allthe experiments such that the number of hiddenlayers is 3 and the dimensionality of hidden units(dh) is 50.
We use Adadelta for training.
Weinitialize our word representation using publiclyavailable word2vec (Mikolov et al, 2013) trainedon Google News dataset and keep them fixed dur-ing training.
For RLL, we keep DLeftand DRightas 15.
All the weights in the network are initial-ized from small random uniform noise.
We trainall our models for 200 epochs.
We do not pre-train our network.
We regularize our network us-ing dropout (Srivastava et al, 2014) with the drop-out rate tuned using the development set.
We se-lect the final model based on development-set per-formance (average of Proportional Overlap for en-tities and Binary Overlap for relations).6 Results6.1 Opinion EntitiesTable 1 shows the performance of opinion entityidentification using the Binary Overlap and Pro-portional Overlap evaluation metrics.
We discussspecific results in the paragraphs below.WLL vs. SLL.
SLL performs better than WLLon all entity types, particularly with respect to Pro-portional Overlap on opinion holder and target en-tities.
A similar trend can be seen for the exam-ple sentences in Table 3.
In S1, SLL extracts ?hasbeen in doubt?
as the opinion expression whereasWLL only identifies ?has?.
Similarly in S2, WLLannotates ?Saudi Arabia?s request on a case-by-case?
as the target while SLL correctly includes?basis?
in its annotation.
Thus, we find that mod-eling the transitions between adjacent tags enables924IS-ABOUT IS-FROMMethod P R F1 P R F1CRF+ILP 61.574.5647.653.1254.392.4964.043.0858.794.4261.173.02LSTM+SLL+Softmax 36.235.1036.127.7535.403.3536.445.2640.196.1337.603.42LSTM+SLL+RLL 62.483.8749.802.8454.982.5464.193.8153.756.0058.223.01Table 2: Performance on opinion relation extraction using Binary Overlap on the opinion entities.
Su-perscripts designate one standard deviation.SLL to find entire opinion entity phrases betterthan WLL, leading to better Proportional Overlapscores.SLL vs. SLL+RLL.
From Table 1, we see thatthe joint-extraction model (SLL+RLL) performsbetter than SLL as expected.
More specifically,SLL+RLL model has better recall for all opinionentity types.
The example sentences from Table 3corroborate these results.
In S1, SLL+RLL identi-fies ?announced?
as an opinion expression, whichwas missing in both WLL and SLL.
In S3, neitherthe WLL nor the SLL model can annotate opin-ion holder (H1) or the target (T1), but SLL+RLLcorrectly identifies the opinion entities because ofmodeling the relations between the opinion ex-pression ?will decide?
and the holder/target enti-ties.CRF vs. LSTM-based Models.
From the anal-ysis of the performance in Table 1, we find thatour WLL and SLL models perform worse whileour best SLL+RLL model can only match the per-formance of the CRF baseline on opinion expres-sions.
Even though the recall of all our LSTM-based models is higher than the recall of the CRF-baseline for opinion expressions, we cannot matchthe precision of CRF baseline.
We suspect thatthe reason for such high precision on the partof the CRF is its access to carefully preparedsubjectivity-lexicons4.
Our LSTM-based modelsdo not rely on such features except via the word-vectors.
With respect to holders and targets, wefind that our SLL model performs similar to theCRF baseline.
However, the SLL+RLL modeloutperforms CRF baseline.CRF+ILP vs. SLL+RLL.
Even though we findthat our LSTM-based joint-model (SLL+RLL)outperforms our LSTM-based only-entity extrac-tion model (SLL), the performance is still belowthe ILP-based joint-model (CRF+ILP).
However,we perform comparably with respect to target en-4http://mpqa.cs.pitt.edu/lexicons/ subj lexicon/tities (Binary Overlap).
Also, our recall on tar-gets is much better than all other models whereasthe recall on holders is very similar to CRF+ILP.Our SLL+RLL model can identify targets such as?Australia?s involvement in Kyoto?
which the ILP-based model cannot, as observed for S1 in Ta-ble 3.
In S3, the ILP-based model also erroneouslydivides the target ?consider Saudi Arabia?s re-quest on a case-by-case basis?
into a holder ?SaudiArabia?s?
and opinion expression ?request?, whileSLL+RLL model can correctly identify it.
We willcompare the two models in detail in Section 7.6.2 Opinion RelationsThe extraction of opinion relations is our primarytask.
Table 25shows the performance on opinionrelation extraction task using Binary Overlap.SLL+Softmax vs. SLL+RLL.
The opinion en-tities and relations are jointly modeled in both themodels, but we see a significant improvement inperformance by adding relation level dependen-cies to the model vs. learning a classifier on topof sentence-level dependencies to learn the rela-tion between entities.
LSTM+SLL+RLL performsmuch better in terms of both precision and recallon both IS-FROM and IS-ABOUT relations.CRF+ILP vs. SLL+RLL.
We find that ourSLL+RLL model performs comparably and evenslightly better on IS-ABOUT relations.
Suchperformance is encouraging because our LSTM-based model does not rely on features such asdependency paths, semantic frames or subjectiv-ity lexicons for our model.
Our sequential LSTMmodel is able to learn these relations thus validat-ing that LSTMs can model long-term dependen-cies.
However, for IS-FROM relations, we find thatour recall is lower than the ILP-based joint model.5Yang and Cardie (2013) omitted a subset of targets andIS-ABOUT relations.
We fixed this and re-ran their modelson the updated dataset, obtaining the lower F-score 54.39 forIS-ABOUT relations.925S1 :[Australia?s involvement in Kyoto]T1[has been in doubt ]O1ever since [ the US President, George Bush]H2,[ announced]O2last year that [ ratifying the protocol ]T2would hurt the US economy.CRF+ILPAustralia?s involvement in Kyoto [has been in doubt ]O1ever since the US President, George Bush, announcedlast year that [ ratifying the protocol ]T1would hurt the US economy.WLL[Australia?s involvement in Kyoto]T[has]Obeen in doubt ever since the US [President ]H, [George Bush]H,announced last year that ratifying the protocol would hurt the US economy.SLL[Australia?s involvement in Kyoto]T[has been in doubt ]Oever since the US President, George Bush, an-nounced last year that ratifying the protocol would hurt the US economy.SLL+RLL[Australia?s involvement in Kyoto]T[has been in doubt ]Oever since the US President, [George Bush]H2,[ announced]O2last year that [ ratifying the protocol ]T2would hurt the US economy.S2 :Bush said last week [he]H1,2[was willing]O1[ to consider ]O2[Saudi Arabia?s request on a case-by-case basis ]T2but [U.S. officials ]H3[doubted]O3[ it would happen any time soon]T3.CRF+ILP[Bush]H1[ said]O1last week [he]H2[was willing to consider ]O2[Saudi Arabia?s ]H3[ request ]O3on acase-by-case basis but [U.S. officials ]H4[doubted]O4[ it ]T4would happen any time soon.WLLBush said last week [he]H[was willing]Oto [consider ]O[Saudi Arabia?s request on a case-by-case]Tbasisbut [U.S. officials ]H[doubted]O[ it ]Twould [happen any time soon]T.SLLBush said last week [he]H[was willing]Oto [consider Saudi Arabia?s request on a case-by-case basis ]Tbut[U.S. officials ]H[doubted]O[ it ]Twould happen any time soon.SLL+RLLBush said last week [he]H1[was willing to consider ]O1[Saudi Arabia?s request on a case-by-case basis ]T1but [U.S. officials ]H2[doubted]O2[ it would happen any time soon]T2.S3 :Hence, [ the Organization of Petroleum Exporting Countries (OPEC)]H1, [will decide]O1at its meeting onWednesday [whether or not to cut its worldwide crude production in an effort to shore up energy prices ]T1.CRF+ILPHence, the Organization of Petroleum Exporting Countries (OPEC), [will decide]O1at its meeting on Wednes-day whether [or not to cut its worldwide crude production in an effort to shore up energy prices ]T1.WLLHence, the Organization of Petroleum Exporting Countries (OPEC), will [decide]Oat its meeting on Wednes-day whether or not to cut its worldwide crude production in an effort to shore up energy prices.SLLHence, the Organization of Petroleum Exporting Countries (OPEC), [will decide]Oat its meeting on Wednes-day whether or not to cut its worldwide crude production in an effort to shore up energy prices.SLL+RLLHence, [ the Organization of Petroleum Exporting Countries (OPEC)]H1, [will decide]O1at its meeting onWednesday whether [or not to cut its worldwide crude production in an effort to shore up energy prices ]T1.Table 3: Output from different models.
The first row for each example is the gold standard.7 DiscussionIn this section, we discuss the various advan-tages and disadvantages of the LSTM-basedSLL+RLL model as compared to the joint-inference (CRF+ILP) model.
We provide exam-ples from the dataset in Table 4.From Table 2, we find that SLL+RLL modelperforms worse with respect to the opinion ex-pression entities and opinion holder entities.
Oncareful analysis of the output, we found casessuch as S1 in Table 4.
For such sentencesSLL+RLL model prefers to annotate the opiniontarget (T3) ?US requests for more oil exports?,whereas the ILP model annotates the embeddedopinion holder (H4) ?US?
and opinion expression(T4) ?requests?.
Both models are valid with re-spect to the gold-standard.
In order to simplifyour problem, we discard these embedded rela-tions during training similar to Yang and Cardie(2013).
However, for future work we would liketo model these overlapping relations which couldpotentially improve our performance on opinionholders and opinion expressions.We also found several cases such as S2, wherethe SLL+RLL model fails to annotate ?said?
as anopinion expression.
The gold standard opinion ex-pressions include speech events like ?said?
or ?astatement?, but not all occurrences of these speechevents are opinion expressions, some are merelyobjective events.
In S2, ?was martyred?
is an indi-cation of an opinion being expressed, so ?said?
isannotated as an opinion expression.
From our ob-servation, the ILP model is more relaxed in anno-tating most of these speech events as opinion ex-pressions and thus likely to identify corresponding926S1 :However, [Chavez]T1who [ is known for ]O1[his ]H2[ala Fidel Castro left-leaning anti-American philosophy]O2had on a number of occasions [ rebuffed]O3[ [US]H4[ requests ]O4for [more oil exports ]T4]T3.CRF+ILPHowever, [Chavez]H1who [ is known]Ofor [his ala Fidel Castro]H2[ left-leaning anti-Americanphilosophy]O2had on a number of occasions [ rebuffed]O1[US]H3[ requests ]O3for more oil exports.SLL+RLLHowever, Chavez who [ is known]Ofor his ala Fidel Castro left-leaning anti-American [philosophy]Ohad ona number of occasions [ rebuffed]O1[US requests for more oil exports ]T1.S2 :A short while ago, [our correspondent in Bethlehem]H1[ said]O1that [Ra?fat al-Bajjali ]T1was martyred ofwounds sustained in the explosion.CRF+ILPA short while ago, [our correspondent ]H1in Bethlehem [said]O1that [Ra?fat al-Bajjali ]T1was martyred ofwounds sustained in the explosion.SLL+RLLA short while ago, our correspondent in Bethlehem said that Ra?fat al-Bajjali was martyred of wounds sustainedin the explosion.S3 :This is no criticism, and is widely known and appreciated.CRF+ILPThis is no criticism, and is widely known and appreciated.SLL+RLL[This ]T1[ is no criticism]O1, and is widely [known and appreciated]O.S4 :From the fact that mothers care for their young, we can not deduce that they ought to do so, Hume argued.CRF+ILPFrom the fact that [mothers ]H1[care]O1for their young, we can not deduce that they ought to do so,[Hume]H2[argued]O2.SLL+RLLFrom the fact that mothers care for their young, [we]H1[can not deduce]O1that [ they]T1ought to do so,[Hume]H2[argued]O2.Table 4: Examples from the dataset with label annotations from CRF+ILP and SLL+RLL models forcomparison.
The first row for each example is the gold standard.opinion holders and opinion targets as comparedto SLL+RLL model.There were also instances such as S3 and S4 inTable 4 for which the gold standard does not havean annotation but the SLL+RLL output looks rea-sonable with respect to our task.
In S3, SLL+RLLidentifies ?is no criticism?
as an opinion expres-sion for the target ?This?.
However, it failsto identify the relation-link between ?known andappreciated?
and the target ?This?.
Similarly,SLL+RLL also identifies reasonable opinion enti-ties in S4, whereas the ILP model erroneously an-notates ?mothers?
as the opinion holder and ?care?as the opinion expression.We handle the task of joint-extraction of opin-ion entities and opinion relations as a sequencelabeling task in this paper and report the perfor-mance of the 1-best path at the time of Viterbi in-ference.
However, there are approaches such asdiscriminative reranking (Collins and Koo, 2005)to rerank the output of an existing system that of-fer a means for further improving the performanceof our SLL+RLL model.
In particular, the oracleperformance using the top-10 Viterbi paths fromour SLL+RLL model has an F-score of 82.11 foropinion expressions, 76.77 for targets and 78.10for holders.
Similarly, IS-ABOUT relations havean F-score of 65.99 and IS-FROM relations, an F-score of 70.80.
These scores are on average 10points better than the performance of the currentSLL+RLL model, indicating that substantial gainsmight be attained via reranking.8 ConclusionIn this paper, we explored LSTM-based modelsfor the joint extraction of opinion entities and re-lations.
Experimentally, we found that addingsentence-level and relation-level dependencies onthe output layer improves the performance onopinion entity extraction, obtaining results within1-3% of the ILP-based joint model on opinion en-tities, within 3% for IS-FROM relation and compa-rable for IS-ABOUT relation.In future work, we plan to explore the effectsof pre-training (Bengio et al, 2009) and sched-uled sampling (Bengio et al, 2015) for trainingour LSTM network.
We would also like to explorere-ranking methods for our problem.
With respectto the fine-grained opinion mining task, a poten-tial future direction to be able to model overlap-ping and embedded entities and relations and alsoto extend this model to handle cross-sentential re-lations.927ReferencesDzmitry Bahdanau, Kyunghyun Cho, and YoshuaBengio.
2014.
Neural machine translation byjointly learning to align and translate.
CoRR,abs/1409.0473.Yoshua Bengio, J?er?ome Louradour, Ronan Collobert,and Jason Weston.
2009.
Curriculum learning.
InProceedings of the 26th Annual International Con-ference on Machine Learning, ICML ?09, pages 41?48, New York, NY, USA.
ACM.Samy Bengio, Oriol Vinyals, Navdeep Jaitly, andNoam Shazeer.
2015.
Scheduled sampling for se-quence prediction with recurrent neural networks.CoRR, abs/1506.03099.Yoshua Bengio.
2009.
Learning deep architectures forai.
Found.
Trends Mach.
Learn., 2(1):1?127, Jan-uary.Eric Breck, Yejin Choi, and Claire Cardie.
2007.
Iden-tifying expressions of opinion in context.
In Pro-ceedings of the 20th International Joint Conferenceon Artifical Intelligence, IJCAI?07, pages 2683?2688, San Francisco, CA, USA.
Morgan KaufmannPublishers Inc.Yejin Choi, Claire Cardie, Ellen Riloff, and SiddharthPatwardhan.
2005.
Identifying sources of opin-ions with conditional random fields and extractionpatterns.
In Proceedings of the Conference on Hu-man Language Technology and Empirical Methodsin Natural Language Processing, HLT ?05, pages355?362, Stroudsburg, PA, USA.
Association forComputational Linguistics.Yejin Choi, Eric Breck, and Claire Cardie.
2006.
Jointextraction of entities and relations for opinion recog-nition.
In Proceedings of the 2006 Conference onEmpirical Methods in Natural Language Process-ing, EMNLP ?06, pages 431?439, Stroudsburg, PA,USA.
Association for Computational Linguistics.Michael Collins and Terry Koo.
2005.
Discrimina-tive reranking for natural language parsing.
Comput.Linguist., 31(1):25?70, March.Ronan Collobert, Jason Weston, L?eon Bottou, MichaelKarlen, Koray Kavukcuoglu, and Pavel Kuksa.2011.
Natural language processing (almost) fromscratch.
J. Mach.
Learn.
Res., 12:2493?2537,November.Alex Graves, Navdeep Jaitly, and Abdel-rahman Mo-hamed.
2013.
Hybrid speech recognition with deepbidirectional LSTM.
In 2013 IEEE Workshop onAutomatic Speech Recognition and Understanding,Olomouc, Czech Republic, December 8-12, 2013,pages 273?278.James Hammerton.
2003.
Named entity recognitionwith long short-term memory.
In Proceedings of theSeventh Conference on Natural Language Learningat HLT-NAACL 2003 - Volume 4, CONLL ?03, pages172?175, Stroudsburg, PA, USA.
Association forComputational Linguistics.Michiel Hermans and Benjamin Schrauwen.
2013.Training and analysing deep recurrent neural net-works.
In Advances in Neural Information Process-ing Systems 26: 27th Annual Conference on NeuralInformation Processing Systems 2013.
Proceedingsof a meeting held December 5-8, 2013, Lake Tahoe,Nevada, United States., pages 190?198.Salah El Hihi and Yoshua Bengio.
1996.
Hierarchicalrecurrent neural networks for long-term dependen-cies.Sepp Hochreiter and J?urgen Schmidhuber.
1997.
Longshort-term memory.
Neural Comput., 9(8):1735?1780, November.Zhiheng Huang, Wei Xu, and Kai Yu.
2015.
Bidi-rectional LSTM-CRF models for sequence tagging.CoRR, abs/1508.01991.Ozan Irsoy and Claire Cardie.
2013.
Bidirectional re-cursive neural networks for token-level labeling withstructure.
arXiv preprint arXiv:1312.0493.Ozan?Irsoy and Claire Cardie.
2014.
Opinion miningwith deep recurrent neural networks.
In Proceedingsof the Conference on Empirical Methods in NaturalLanguage Processing, pages 720?728.Soo-Min Kim and Eduard Hovy.
2006.
Extractingopinions, opinion holders, and topics expressed inonline news media text.
In Proceedings of the Work-shop on Sentiment and Subjectivity in Text, SST ?06,pages 1?8, Stroudsburg, PA, USA.
Association forComputational Linguistics.Nozomi Kobayashi, Kentaro Inui, and Yuji Matsumoto.2007.
Extracting aspect-evaluation and aspect-of re-lations in opinion mining.
In Proceedings of the2007 Joint Conference on Empirical Methods inNatural Language Processing and ComputationalNatural Language Learning (EMNLP-CoNLL.Pengfei Liu, Shafiq Joty, and Helen Meng.
2015.
Fine-grained opinion mining with recurrent neural net-works and word embeddings.
In Proceedings ofthe 2015 Conference on Empirical Methods in Natu-ral Language Processing, pages 1433?1443, Lisbon,Portugal, September.
Association for ComputationalLinguistics.Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-rado, and Jeff Dean.
2013.
Distributed representa-tions of words and phrases and their composition-ality.
In C.J.C.
Burges, L. Bottou, M. Welling,Z.
Ghahramani, and K.Q.
Weinberger, editors, Ad-vances in Neural Information Processing Systems26, pages 3111?3119.
Curran Associates, Inc.Makoto Miwa and Mohit Bansal.
2016.
End-to-endrelation extraction using lstms on sequences and treestructures.
CoRR, abs/1601.00770.928J?urgen Schmidhuber.
1992.
Learning complex, ex-tended sequences using the principle of history com-pression.
Neural Comput., 4(2):234?242, March.M.
Schuster and K.K.
Paliwal.
1997.
Bidirec-tional recurrent neural networks.
Trans.
Sig.
Proc.,45(11):2673?2681, November.Richard Socher, Brody Huval, Christopher D. Man-ning, and Andrew Y. Ng.
2012.
Semantic com-positionality through recursive matrix-vector spaces.In Proceedings of the 2012 Joint Conference onEmpirical Methods in Natural Language Process-ing and Computational Natural Language Learning,EMNLP-CoNLL ?12, pages 1201?1211, Strouds-burg, PA, USA.
Association for Computational Lin-guistics.Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky,Ilya Sutskever, and Ruslan Salakhutdinov.
2014.Dropout: A simple way to prevent neural networksfrom overfitting.
Journal of Machine Learning Re-search, 15:1929?1958.Ilya Sutskever, Oriol Vinyals, and Quoc V Le.
2014.Sequence to sequence learning with neural net-works.
In Z. Ghahramani, M. Welling, C. Cortes,N.
D. Lawrence, and K. Q. Weinberger, editors, Ad-vances in Neural Information Processing Systems27, pages 3104?3112.
Curran Associates, Inc.Janyce Wiebe and Claire Cardie.
2005.
Annotatingexpressions of opinions and emotions in language.language resources and evaluation.
In LanguageResources and Evaluation (formerly Computers andthe Humanities, page 2005.Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.2005.
Recognizing contextual polarity in phrase-level sentiment analysis.
In Proceedings of the Con-ference on Human Language Technology and Em-pirical Methods in Natural Language Processing,HLT ?05, pages 347?354, Stroudsburg, PA, USA.Association for Computational Linguistics.Theresa Ann Wilson.
2008.
Fine-grained Subjectivityand Sentiment Analysis: Recognizing the intensity,polarity, and attitudes of private states.
Ph.D. thesis,The University of Pittsburgh, June.Yan Xu, Lili Mou, Ge Li, Yunchuan Chen, Hao Peng,and Zhi Jin.
2015.
Classifying relations via longshort term memory networks along shortest depen-dency paths.
In In Proceedings of Conference onEmpirical Methods in Natural Language Process-ing.Bishan Yang and Claire Cardie.
2012.
Extractingopinion expressions with semi-markov conditionalrandom fields.
In Proceedings of the 2012 JointConference on Empirical Methods in Natural Lan-guage Processing and Computational Natural Lan-guage Learning, EMNLP-CoNLL ?12, pages 1335?1345, Stroudsburg, PA, USA.
Association for Com-putational Linguistics.Bishan Yang and Claire Cardie.
2013.
Joint infer-ence for fine-grained opinion extraction.
In Pro-ceedings of the 51st Annual Meeting of the Associa-tion for Computational Linguistics (Volume 1: LongPapers), pages 1640?1649, Sofia, Bulgaria, August.Association for Computational Linguistics.Matthew D. Zeiler.
2012.
ADADELTA: an adaptivelearning rate method.
CoRR, abs/1212.5701.929
