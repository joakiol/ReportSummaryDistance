Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 177?185,Honolulu, October 2008. c?2008 Association for Computational LinguisticsSentence Fusion via Dependency Graph CompressionKatja Filippova and Michael StrubeEML Research gGmbHSchloss-Wolfsbrunnenweg 3369118 Heidelberg, Germanyhttp://www.eml-research.de/nlpAbstractWe present a novel unsupervised sentence fu-sion method which we apply to a corpus of bi-ographies in German.
Given a group of relatedsentences, we align their dependency trees andbuild a dependency graph.
Using integer lin-ear programming we compress this graph toa new tree, which we then linearize.
We useGermaNet and Wikipedia for checking seman-tic compatibility of co-arguments.
In an eval-uation with human judges our method out-performs the fusion approach of Barzilay &McKeown (2005) with respect to readability.1 IntroductionAutomatic text summarization is a rapidly develop-ing field in computational linguistics.
Summariza-tion systems can be classified as either extractive orabstractive ones (Spa?rck Jones, 1999).
To date, mostsystems are extractive: sentences are selected fromone or several documents and then ordered.
Thismethod exhibits problems, because input sentencesvery often overlap and complement each other at thesame time.
As a result there is a trade-off betweennon-redundancy and completeness of the output.
Al-though the need for abstractive approaches has beenrecognized before (e.g.
McKeown et al (1999)), sofar almost all attempts to get closer to abstractivesummarization using scalable, statistical techniqueshave been limited to sentence compression.The main reason why there is little progress on ab-stractive summarization is that this task seems to re-quire a conceptual representation of the text which isnot yet available (see e.g.
Hovy (2003, p.589)).
Sen-tence fusion (Barzilay & McKeown, 2005), where anew sentence is generated from a group of relatedsentences and where complete semantic and con-ceptual representation is not required, can be seenas a middle-ground between extractive and abstrac-tive summarization.
Our work regards a corpus ofbiographies in German where multiple documentsabout the same person should be merged into a sin-gle one.
An example of a fused sentence (3) with thesource sentences (1,2) is given below:(1) BohrBohrstudiertestudiedanatdertheUniversita?tUniversityKopenhagenCopenhagenundanderlangtegotdortthereseinehisDoktorwu?rde.PhD?Bohr studied at the University of Copenhagenand got his PhD there?
(2) NachAfterdemtheAbiturschoolstudiertestudiederhePhysikphysicsundandMathematikmathematicsanatdertheUniversita?tUniversityKopenhagen.Copenhagen?After school he studied physics and mathemat-ics at the University of Copenhagen?
(3) NachAfterdemtheAbiturschoolstudiertestudiedBohrBohrPhysikphysicsundandMathematikmathematicsanatdertheUniversita?tUniversityKopenhagenCopenhagenundanderlangtegotdortthereseinehisDoktorwu?rde.PhD?After school Bohr studied physics and mathe-matics at the University of Copenhagen and gothis PhD there?177Having both (1) and (2) in a summary would makeit redundant.
Selecting only one of them would notgive all the information from the input.
(3), fusedfrom both (1) and (2), conveys the necessary infor-mation without being redundant and is more appro-priate for a summary.To this end, we present a novel sentence fusionmethod based on dependency structure alignmentand semantically and syntactically informed phraseaggregation and pruning.
We address the problem inan unsupervised manner and use integer linear pro-gramming (ILP) to find a globally optimal solution.We argue that our method has three important advan-tages compared to existing methods.
First, we ad-dress the grammaticality issue empirically by meansof knowledge obtained from an automatically parsedcorpus.
We do not require such resources as subcat-egorization lexicons or hand-crafted rules, but de-cide to retain a dependency based on its syntacticimportance score.
The second point concerns inte-grating semantics.
Being definitely important, ?thissource of information remains relatively unused inwork on aggregation1 within NLG?
(Reiter & Dale,2000, p.141).
To our knowledge, in the text-to-textgeneration field, we are the first to use semantic in-formation not only for alignment but also for aggre-gation in that we check coarguments?
compatibility.Apart from that, our method is not limited to sen-tence fusion and can be easily applied to sentencecompression.
In Filippova & Strube (2008) we com-press English sentences with the same approach andachieve state-of-the-art performance.The paper is organized as follows: Section 2 givesan overview of related work and Section 3 presentsour data.
Section 4 introduces our method and Sec-tion 5 describes the experiments and discusses theresults of the evaluation.
The conclusions follow inthe final section.2 Related WorkMost studies on text-to-text generation concern sen-tence compression where the input consists of ex-actly one sentence (Jing, 2001; Hori & Furui, 2004;Clarke & Lapata, 2008, inter alia).
In such set-ting, redundancy, incompleteness and compatibility1We follow Barzilay & McKeown (2005) and refer to aggre-gation within text-to-text generation as sentence fusion.issues do not arise.
Apart from that, there is noobvious way of how existing sentence compressionmethods can be adapted to sentence fusion.Barzilay & McKeown (2005) present a sentencefusion method for multi-document news summariza-tion which crucially relies on the assumption that in-formation appearing in many sources is important.Consequently, their method produces an intersec-tion of input sentences by, first, finding the centroidof the input, second, augmenting it with informa-tion from other sentences and, finally, pruning a pre-defined set of constituents (e.g.
PPs).
The resultingstructure is not necessarily a tree and allows for ex-traction of several trees, each of which can be lin-earized in many ways.Marsi & Krahmer (2005) extend the approach ofBarzilay & McKeown to do not only intersectionbut also union fusion.
Like Barzilay & McKeown(2005), they find the best linearization with a lan-guage model which, as they point out, often pro-duces inadequate rankings being unable to deal withword order, agreement and subcategorization con-straints.
In our work we aim at producing a validdependency tree structure so that most grammatical-ity issues are resolved before the linearization stage.Wan et al (2007) introduce a global revisionmethod of how a novel sentence can be generatedfrom a set of input words.
They formulate the prob-lem as a search for a maximum spanning tree whichis incrementally constructed by connecting words orphrases with dependency relations.
The grammat-icality issue is addressed by a number of hard con-straints.
As Wan et al point out, one of the problemswith their method is that the output built up fromdependencies found in a corpus might have a mean-ing different from the intended one.
Since we buildour trees from the input dependencies, this problemdoes not arise with our method.
Apart from that, inour opinion, the optimization formulation we adoptis more appropriate as it allows to integrate manyconstraints without complex rescoring rules.3 DataThe comparable corpus we work with is a collectionof about 400 biographies in German gathered from178the Internet2.
These biographies describe 140 differ-ent people, and the number of articles for one personranges from 2 to 4, being 3 on average.
Despite ob-vious similarities between articles about one person,neither identical content nor identical ordering of in-formation can be expected.Fully automatic preprocessing in our system com-prises the following steps: sentence boundaries areidentified with a Perl CPAN module3.
Then thesentences are split into tokens and the TnT tagger(Brants, 2000) and the TreeTagger (Schmid, 1997)are used for tagging and lemmatization respectively.Finally, the biographies are parsed with the CDG de-pendency parser (Foth & Menzel, 2006).
We alsoidentify references to the biographee (pronominal aswell as proper names) and temporal expressions (ab-solute and relative) with a few rules.4 Our MethodGroups of related sentences serve as input to a sen-tence fusion system and thus need to be identifiedfirst (4.1).
Then the dependency trees of the sen-tences are modified (4.2) and aligned (4.3).
Syntac-tic importance (4.4) and word informativeness (4.5)scores are used to extract a new dependency treefrom a graph of aligned trees (4.6).
Finally, the treeis linearized (4.7).4.1 Sentence AlignmentSentence alignment for comparable corpora requiresmethods different from those used in machine trans-lation for parallel corpora.
For example, given twobiographies of a person, one of them may follow thetimeline from birth to death whereas the other maygroup events thematically or tell only about the sci-entific contribution of the person.
Thus one can-not assume that the sentence order or the contentis the same in two biographies.
Shallow methodslike word or bigram overlap, (weighted) cosine orJaccard similarity are appealing as they are cheapand robust.
In particular, Nelken & Schieber (2006)2http://de.wikipedia.org, http://home.datacomm.ch/biografien, http://biographie.net/de, http://www.weltchronik.de/ws/bio/main.htm, http://www.brockhaus-suche.de/suche3http://search.cpan.org/?holsten/Lingua-DE-Sentence-0.07/Sentence.pmdemonstrate the efficacy of a sentence-based tf*idfscore when applied to comparable corpora.
Follow-ing them, we define the similarity of two sentencessim(s1, s2) asS1 ?
S2|S1| ?
|S2|=?t wS1(t) ?
wS2(t)?
?t w2S1(t)?t w2S2(t)(1)where S is the set of all lemmas but stop-words froms, and wS(t) is the weight of the term t:wS(t) = S(t)1Nt(2)where S(t) is the indicator function of S, Nt is thenumber of sentences in the biographies of one per-son which contain t. We enhance the similarity mea-sure by looking up synonymy in GermaNet (Lem-nitzer & Kunze, 2002).We discard identical or nearly identical sen-tences (sim(s1, s2) > 0.8) and greedily buildsentence clusters using a hierarchical groupwise-average technique.
As a result, one sentence maybelong to one cluster at most.
These sentence clus-ters serve as input to the fusion algorithm.4.2 Dependency Tree ModificationWe apply a set of transformations to a dependencytree to emphasize its important properties and elim-inate unimportant ones.
These transformations arenecessary for the compression stage.
An example ofa dependency tree and its modifed version are givenin Fig.
1.PREP preposition nodes (an, in) are removed andplaced as labels on the edges to the respectivenouns;CONJ a chain of conjuncts (Mathematik undPhysik) is split and each node is attached to theparent node (studierte) provided they are notverbs;APP a chain of words analyzed as appositions byCDG (Niels Bohr) is collapsed into one node;FUNC function words like determiners (der), aux-iliary verbs or negative particles are removedfrom the tree and memorized with their lexicalheads (memorizing negative particles preservesnegation in the output);179BohrMathematikundPhysikan inKopenhagenderUnistudiertesubj obja ppppkoncjpnpndet(a) Dependency treestudierterootsbioMathematikPhysik UniKopenhagenobjaobjaaninsubj(b) Modified treeFigure 1: The dependency tree of the sentence Bohr studierte Mathematik und Physik an der Uni in Kopenhagen(Bohr studied mathematics and physics at university in Copenhagen) as produced by the parser (a) and after alltransformations applied (b)ROOT every dependency tree gets an explicit rootwhich is connected to every verb node;BIO all occurrences of the biographee (Niels Bohr)are replaced with the bio tag.4.3 Node AlignmentOnce we have a group of two to four strongly relatedsentences and their transformed dependency trees,we aim at finding the best node alignment.
We usea simple, fast and transparent method and align anytwo words provided that they1.
are content words;2. have the same part-of-speech;3. have identical lemmas or are synonyms.In case of multiple possibilities, which are extremelyrare in our data, the choice is made randomly.
Bymerging all aligned nodes we get a dependencygraph which consists of all dependencies from theinput trees.
In case it contains a cycle, one of thealignments from the cycle is eliminated.We prefer this very simple method to bottom-upones (Barzilay & McKeown, 2005; Marsi & Krah-mer, 2005) for two main reasons.
Pursuing localsubtree alignments, bottom-up methods may leaveidentical words unaligned and thus prohibit fusionof complementary information.
On the other hand,they may force alignment of two unrelated words ifthe subtrees they root are largely aligned.
Althoughin some cases it helps discover paraphrases, it con-siderably increases chances of generating ungram-matical output which we want to avoid at any cost.4.4 Syntactic Importance ScoreGiven a dependency graph we want to get a new de-pendency tree from it.
Intuitively, we want to re-tain obligatory dependencies (e.g.
subject) while re-moving less important ones (e.g.
adv).
When de-ciding on pruning an argument, previous approacheseither used a set of hand-crafted rules (e.g.
Barzilay& McKeown (2005)), or utilized a subcategorizationlexicon (e.g.
Jing (2001)).
The hand-crafted rulesare often too general to ensure a grammatical argu-ment structure for different verbs (e.g.
PPs can bepruned).
Subcategorization lexicons are not readilyavailable for many languages and cover only verbs.E.g.
they do not tell that the noun son is very of-ten modified by a PP using the preposition of, as inthe son of Niels Bohr, and that the NP without a PPmodifier may appear incomplete.To overcome these problems, we decide on prun-ing an edge by estimating the conditional proba-bility of its label given its head, P (l|h)4.
For ex-ample, P (subj|studieren) ?
the probability of thelabel subject given the verb study ?
is higher thanP (in|studieren), and therefore the subject will bepreserved whereas the prepositional label and thusthe whole PP can be pruned, if needed.
Table 1presents the probabilities of several labels given thatthe head is studieren and shows that some preposi-tions are more important than other ones.
Note thatif we did not apply the PREP modification we wouldbe unable to distinguish between different prepo-sitions and could only calculate P (pp|studieren)4The probabilities are calculated from a corpus of approx.3,000 biographies from Wikipedia which we annotated auto-matically as described in Section 3.180which would not be very informative.subj obja in an nach mit zu0.88 0.74 0.44 0.42 0.09 0.02 0.01Table 1: Probabilities of subj, obja(ccusative), in, at, af-ter, with, to given the verb studieren (study)4.5 Word Informativeness ScoreWe also want to retain informative words in the out-put tree.
There are many ways in which word im-portance can be defined.
Here, we use a formulaintroduced by Clarke & Lapata (2008) which is amodification of the significance score of Hori & Fu-rui (2004):I(wi) =lN ?
fi logFAFi(3)wi is the topic word (either noun or verb), fi is thefrequency of wi in the aligned biographies, Fi is thefrequency of wi in the corpus, and FA is the sumof frequencies of all topic words in the corpus.
l isthe number of clause nodes above w and N is themaximum level of embedding of the sentence whichw belongs to.
By defining word importance differ-ently, e.g.
as relatedness of a word to the topic, wecould apply our method to topic-based summariza-tion (Krahmer et al, 2008).4.6 New Sentence GenerationWe formulate the task of getting a tree from a depen-dency graph as an optimization problem and solveit with ILP5.
In order to decide which edges of thegraph to remove, for each directed dependency edgefrom head h to word w we introduce a binary vari-able xlh,w, where l stands for the label of the edge:xlh,w ={1 if the dependency is preserved0 otherwise(4)The goal is to find a subtree of the graph whichgets the highest score of the objective function (5) towhich both the probability of dependencies (P (l|h) )and the importance of dependent words (I(w)) con-tribute:5We use lp solve in our implementation http://sourceforge.net/projects/lpsolve.f(X) =?xxlh,w ?
P (l|h) ?
I(w) (5)The objective function is subject to four types ofconstraints presented below (W stands for the set ofgraph nodes minus root, i.e.
the set of words).STRUCTURAL constraints allow to get a tree fromthe graph: (6) ensures that each word has one headat most.
(7) ensures connectivity in the tree.
(8) isoptional and restricts the size of the resulting tree to?
words (?
= min(0.6?
?
|W |, 10)).
?w ?
W,?h,lxlh,w ?
1 (6)?w ?
W,?h,lxlh,w ?1|W |?u,lxlw,u ?
0 (7)?xxlh,w ?
?
(8)SYNTACTIC constraints ensure the syntactic validityof the output tree and explicitly state which argu-ments should be preserved.
We have only one syn-tactic constraint which guarantees that a subordinat-ing conjunction (sc) is preserved (9) if and only if theclause it belongs to serves as a subordinate clause(sub) in the output.
?xscw,u,?h,lxsubh,w ?
xscw,u = 0 (9)SEMANTIC constraints restrict coordination to se-mantically compatible elements.
The idea behindthese constraints is the following (see Fig.
2).
Itcan be that one sentence says He studied math andanother one He studied physics, so the output mayunite the two words under coordination: He studiedmath and physics.
But if the input sentences are Hestudied physics and He studied sciences, then oneshould not unite both, because sciences is the gen-eralization of physics.
Neither should one unite twounrelated words: He studied with pleasure and Hestudied with Bohr cannot be fused into He studiedwith pleasure and Bohr.To formalize these intuitions we define two func-tions hm(w,u) and rel(w,u): hm(w,u) is a binary func-tion, whereas rel(w,u) returns a value from [0, 1].
We181rootsstudiedsciencesbiopleasuremathphysicssubjwithwithobjaobjaobjaBohrFigure 2: Graph obtained from sentences He studied sci-ences with pleasure and He studied math and physics withBohralso introduce additional variables ylw,u (representedby dashed lines in Fig.
2):ylw,u ={1 if ?h, l : xlh,w = 1 ?
xlh,u = 10 otherwise(10)For two edges sharing a head and having identicallabels to be retained we check in GermaNet andin the taxonomy derived from Wikipedia (Kassneret al, 2008) that their dependents are not in thehyponymy or meronymy relation (11).
We prohibitverb coordination unless it is found in one of theinput sentences.
If the dependents are nouns, wealso check that their semantic relatedness as mea-sured with WikiRelate!
(Strube & Ponzetto, 2006)is above a certain threshold (12).
We empiricallydetermined the value of ?
= 0.36 by calculating anaverage similarity of coordinated nouns in the cor-pus.
?ylw,u, hm(w, u) ?
ylw,u = 0 (11)?ylw,u, (rel(w, u) ?
?)
?
ylw,u ?
0 (12)(11) prohibits that physics (or math) and sciences ap-pear together since, according to GermaNet, physics(Physik) is a hyponym of science (Wissenschaft).
(12) blocks taking both pleasure (Freude) and Bohrbecause rel(Freude,Bohr) = 0.17. math and physicsare neither in ISA, nor part-of relation and are suffi-ciently related (rel(Mathematik, Physik) = 0.67) tobecome conjuncts.META constraints (equations (13) and (14)) guar-antee that ylw,u = xlh,w ?
xlh,u i.e.
they ensure thatthe semantic constraints are applied only if both thelabels from h to w and from h to u are preserved.
?ylw,u, xlh,w + xlh,u ?
2ylw,u (13)?ylw,u, 1 ?
xlh,w + 1 ?
xlh,u ?
1 ?
ylw,u (14)4.7 LinearizationThe ?overgenerate-and-rank?
approach to statisti-cal surface realization is very common (Langk-ilde & Knight, 1998).
Unfortunately, in its sim-plest and most popular version, it ignores syntac-tical constraints and may produce ungrammaticaloutput.
For example, an inviolable rule of Ger-man grammar states that the finite verb must be inthe second position in the main clause.
Since it ishard to enforce such rules with an ngram languagemodel, syntax-informed linearization methods havebeen developed for German (Ringger et al, 2004;Filippova & Strube, 2007).
We apply our recentmethod to order constituents and, using the CMUtoolkit (Clarkson & Rosenfeld, 1997), build a tri-gram language model from Wikipedia (approx.
1GBplain text) to find the best word order within con-stituents.
Some constraints on word order are in-ferred from the input.
Only interclause punctuationis generated.5 Experiments and EvaluationWe choose Barzilay & McKeown?s system as a non-trivial baseline since, to our knowledge, there is noother system which outperforms theirs (Sec.
5.1).
Itis important for us to evaluate the fusion part of oursystem, so the input and the linearization module ofour method and the baseline are identical.
We arealso interested in how many errors are due to the lin-earization module and thus define the readability up-per bound (Sec.
5.2).
We further present and discussthe experiments (Sec.
5.3 and 5.5).5.1 BaselineThe algorithm of Barzilay & McKeown (2005) pro-ceeds as follows: Given a group of related sentences,a dependency tree is built for each sentence.
Thesetrees are modified so that grammatical features areeliminated from the representation and memorized;noun phrases are flattened to facilitate alignment.A locally optimal pairwise alignment of modified182dependency trees is recursively found with Word-Net and a paraphrase lexicon.
From the alignmentcosts the centroid of the group is identified.
Thenthis tree is augmented with information from othertrees given that it appears in at least half of the sen-tences from this group.
A rule-based pruning mod-ule prunes optional constituents, such as PPs or rel-ative clauses.
The linearization of the resulting tree(or graph) is done with a trigram language model.To adapt this system to German, we use the Ger-maNet API (Gurevych & Niederlich, 2005) insteadof WordNet.
We do not use a paraphrase lexicon,because there is no comparable corpus of sufficientsize available for German.
We readjust the align-ment parameters of the system to prevent dissimi-lar nodes from being aligned.
The input to the al-gorithm is generated as described in Sec.
4.1.
Thelinearization is done as described in Sec.
4.7.
Incases when there is a graph to linearize, all possibletrees covering the maximum number of nodes areextracted from it and linearized.
The most probablestring is selected as the final output with a languagemodel.
For the rest of the reimplementation we fol-low the algorithm as presented.5.2 Readability Upper BoundTo find the upper bound on readability, we select onesentence from the input randomly, parse it and lin-earize the dependency tree as described in Sec.
4.7.This way we obtain a sentence which may differ inform from the input sentences but whose content isidentical to one of them.5.3 ExperimentsIt is notoriously difficult to evaluate generation andsummarization systems as there are many dimen-sions in which the quality of the output can be as-sessed.
The goal of our present evaluation is in thefirst place to check whether our method is able toproduce sensible output.We evaluated the three systems (GRAPH-COMPRESSION, BARZILAY & MCKEOWN andREADABILITY UB) with 50 native German speakerson 120 fused sentences generated from 40 randomlydrawn related sentences groups (3 ?
40).
In anonline experiment, the participants were asked toread a fused sentence preceded by the input andto rate its readability (read) and informativity inrespect to the input (inf ) on a five point scale.
Theexperiment was designed so that every participantrated 40 sentences in total.
No participant sawtwo sentences generated from the same input.
Theresults are presented in Table 2. len is an averagelength in words of the output.read inf lenREADABILITY UB 4.0 3.5 12.9BARZILAY & MCKEOWN 3.1 3.0 15.5GRAPH-COMPRESSION 3.7 3.1 13.0Table 2: Average readability and informativity on a fivepoint scale, average length in words5.4 Error AnalysisThe main disadvantage of our method, as well asother methods designed to work on syntactic struc-tures, is that it requires a very accurate parser.
Insome cases, errors in the preprocessing made ex-tracting a valid dependency tree impossible.
Thepoor rating of READABILITY UB also shows that er-rors of the parser and of the linearization module af-fect the output considerably.Although the semantic constraints ruled outmany anomalous combinations, the limited cover-age of GermaNet and the taxonomy derived fromWikipedia was the reason for some semantic oddi-ties in the sentences generated by our method.
Forexample, it generated phrases like aus England undGro?britannien (from England and Great Britain).A larger taxonomy would presumably increase therecall of the semantic constraints which proved help-ful.
Such errors were not observed in the output ofthe baseline because it does not fuse within NPs.Both the baseline and our method made subcate-gorization errors, although these are more commonfor the baseline which aligns not only synonymsbut also verbs which share some arguments.
Also,the baseline pruned some PPs necessary for a sen-tence to be complete.
For example, it pruned ander Atombombe (on the atom bomb) and generatedan incomplete sentence Er arbeitete (He worked).For the baseline, alignment of flattened NPs insteadof words caused generating very wordy and redun-dant sentences when the input parse trees were in-correct.
In other cases, our method made mistakes183in linearizing constituents because it had to rely on alanguage model whereas the baseline used unmod-ified constituents from the input.
Absense of intra-clause commas caused a drop in readability in someotherwise grammatical sentences.5.5 DiscussionA paired t-test revealed significant differences be-tween the readability ratings of the three systems(p = 0.01) but found no significant differences be-tween the informativity scores of our system and thebaseline.
Some participants reported informativityhard to estimate and to be assessable for grammat-ical sentences only.
The higher readability ratingof our method supports our claim that the methodbased on syntactic importance score and global con-straints generates more grammatical sentences thanexisting systems.
An important advantage of ourmethod is that it addresses the subcategorization is-sue directly without shifting the burden of selectingthe right arguments to the linearization module.
Thedependency structure it outputs is a tree and not agraph as it may happen with the method of Barzi-lay & McKeown (2005).
Moreover, our method candistinguish between more and less obligatory argu-ments.
For example, it knows that at is more impor-tant than to for study whereas for go it is the otherway round.
Unlike our differentiated approach, thebaseline rule states that PPs can generally be pruned.Since the baseline generates a new sentence bymodifying the tree of an input sentence, in somecases it outputs a compression of this sentence.
Un-like this, our method is not based on an input treeand generates a new sentence without being biasedto any of the input sentences.Our method can also be applied to non-trivial sen-tence compression, whereas the baseline and similarmethods, such as Marsi & Krahmer (2005), wouldthen boil down to a few very general pruning rules.We tested our method on the English compressioncorpus6 and evaluated the compressions automati-cally the same way as Clarke & Lapata (2008) did.The results (Filippova & Strube, 2008) were as goodas or significantly better than the state-of-the-art, de-pending on the choice of dependency parser.6The corpus is available from http://homepages.inf.ed.ac.uk/s0460084/data.6 ConclusionsWe presented a novel sentence fusion method whichformulates the fusion task as an optimization prob-lem.
It is unsupervised and finds a globally optimalsolution taking semantics, syntax and word informa-tiveness into account.
The method does not requirehand-crafted rules or lexicons to generate grammat-ical output but relies on the syntactic importancescore calculated from an automatically parsed cor-pus.
An experiment with native speakers demon-strated that our method generates more grammaticalsentences than existing systems.There are several directions to explore in the fu-ture.
Recently query-based sentence fusion has beenshown to be a better defined task than generic sen-tence fusion (Krahmer et al, 2008).
By modify-ing the word informativeness score, e.g.
by givinghigher scores to words semantically related to thequery, one could force our system to retain wordsrelevant to the query in the output.
To generate co-herent texts we plan to move beyond sentence gen-eration and add discourse constraints to our system.Acknowledgements: This work has been fundedby the Klaus Tschira Foundation, Heidelberg, Ger-many.
The first author has been supported by a KTFgrant (09.009.2004).
Part of the data has been usedwith a permission of Bibliographisches Institut & F.A.
Brockhaus AG, Mannheim, Germany.
We wouldlike to thank the participants in our online evalua-tion.
We are also grateful to Regina Barzilay and thethree reviewers for their helpful comments.ReferencesBarzilay, Regina & Kathleen R. McKeown (2005).
Sen-tence fusion for multidocument news summarization.Computational Linguistics, 31(3):297?327.Brants, Thorsten (2000).
TnT ?
A statistical Part-of-Speech tagger.
In Proceedings of the 6th Confer-ence on Applied Natural Language Processing, Seat-tle, Wash., 29 April ?
4 May 2000, pp.
224?231.Clarke, James & Mirella Lapata (2008).
Global inferencefor sentence compression: An integer linear program-ming approach.
Journal of Artificial Intelligence Re-search, 31:399?429.Clarkson, Philip & Ronald Rosenfeld (1997).
Statis-tical language modeling using the CMU-Cambridgetoolkit.
In Proceedings of the 5th European Con-ference on Speech Communication and Technology,184Rhodes, Greece, 22-25 September 1997, pp.
2707?2710.Filippova, Katja & Michael Strube (2007).
Generatingconstituent order in German clauses.
In Proceedings ofthe 45th Annual Meeting of the Association for Com-putational Linguistics, Prague, Czech Republic, 23?30June 2007, pp.
320?327.Filippova, Katja & Michael Strube (2008).
Dependencytree based sentence compression.
In Proceedings ofthe 5th International Conference on Natural LanguageGeneration, Salt Fork, Ohio, 12?14 June 2008, pp.
25?32.Foth, Kilian & Wolfgang Menzel (2006).
Hybrid pars-ing: Using probabilistic models as predictors for asymbolic parser.
In Proceedings of the 21st Interna-tional Conference on Computational Linguistics and44th Annual Meeting of the Association for Computa-tional Linguistics, Sydney, Australia, 17?21 July 2006,pp.
321?327.Gurevych, Iryna & Hendrik Niederlich (2005).
Access-ing GermaNet data and computing semantic related-ness.
In Companion Volume to the Proceedings of the43rd Annual Meeting of the Association for Compu-tational Linguistics, Ann Arbor, Mich., 25?30 June2005, pp.
5?8.Hori, Chiori & Sadaoki Furui (2004).
Speech summa-rization: An approach through word extraction and amethod for evaluation.
IEEE Transactions on Infor-mation and Systems, E87-D(1):15?25.Hovy, Eduard (2003).
Text summarization.
In RuslanMitkov (Ed.
), The Oxford Handbook of ComputationalLinguistics, pp.
583?598.
Oxford, U.K.: Oxford Uni-versity Press.Jing, Hongyan (2001).
Cut-and-Paste Text Summariza-tion, (Ph.D. thesis).
Computer Science Department,Columbia University, New York, N.Y.Kassner, Laura, Vivi Nastase & Michael Strube (2008).Acquiring a taxonomy from the German Wikipedia.In Proceedings of the 6th International Conference onLanguage Resources and Evaluation, Marrakech, Mo-rocco, 26 May ?
1 June 2008.Krahmer, Emiel, Erwin Marsi & Paul van Pelt (2008).Query-based sentence fusion is better defined andleads to more preferred results than generic sentencefusion.
In Companion Volume to the Proceedings ofthe 46th Annual Meeting of the Association for Com-putational Linguistics, Columbus, Ohio, 15?20 June2008, pp.
193?196.Langkilde, Irene & Kevin Knight (1998).
Generationthat exploits corpus-based statistical knowledge.
InProceedings of the 17th International Conference onComputational Linguistics and 36th Annual Meet-ing of the Association for Computational Linguistics,Montre?al, Que?bec, Canada, 10?14 August 1998, pp.704?710.Lemnitzer, Lothar & Claudia Kunze (2002).
GermaNet?
representation, visualization, application.
In Pro-ceedings of the 3rd International Conference on Lan-guage Resources and Evaluation, Las Palmas, CanaryIslands, Spain, 29?31 May 2002, pp.
1485?1491.Marsi, Erwin & Emiel Krahmer (2005).
Explorations insentence fusion.
In Proceedings of the European Work-shop on Natural Language Generation, Aberdeen,Scotland, 8?10 August, 2005, pp.
109?117.McKeown, Kathleen R., Judith L. Klavans, VassileiosHatzivassiloglou, Regina Barzilay & Eleazar Eskin(1999).
Towards multidocument summarization by re-formulation: Progress and prospects.
In Proceedingsof the 16th National Conference on Artificial Intelli-gence, Orlando, Flo., 18?22 July 1999, pp.
453?460.Nelken, Rani & Stuart Schieber (2006).
Towards robustcontext-sensitive sentence alignment for monolingualcorpora.
In Proceedings of the 11th Conference ofthe European Chapter of the Association for Compu-tational Linguistics, Trento, Italy, 3?7 April 2006, pp.161?168.Reiter, Ehud & Robert Dale (2000).
Building Natu-ral Language Generation Systems.
Cambridge, U.K.:Cambridge University Press.Ringger, Eric, Michael Gamon, Robert C. Moore, DavidRojas, Martine Smets & Simon Corston-Oliver (2004).Linguistically informed statistical models of con-stituent structure for ordering in sentence realization.In Proceedings of the 20th International Conferenceon Computational Linguistics, Geneva, Switzerland,23?27 August 2004, pp.
673?679.Schmid, Helmut (1997).
Probabilistic Part-of-Speechtagging using decision trees.
In Daniel Jones & HaroldSomers (Eds.
), New Methods in Language Processing,pp.
154?164.
London, U.K.: UCL Press.Spa?rck Jones, Karen (1999).
Automatic summarizing:Factors and directions.
In Inderjeet Mani & Mark T.Maybury (Eds.
), Advances in Automatic Text Summa-rization, pp.
1?12.
Cambridge, Mass.
: MIT Press.Strube, Michael & Simone Paolo Ponzetto (2006).WikiRelate!
Computing semantic relatedness usingWikipedia.
In Proceedings of the 21st National Con-ference on Artificial Intelligence, Boston, Mass., 16?20 July 2006, pp.
1419?1424.Wan, Stephen, Robert Dale, Mark Dras & Cecile Paris(2007).
Global revision in summarization: Generatingnovel sentences with Prim?s algorithm.
In Proceedingsof the 10th Conference of the Pacific Association forComputational Linguistics, Melbourne, Australia, 19?21 September, 2007, pp.
226?235.185
