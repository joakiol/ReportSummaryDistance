Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 104?109,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsJoint Inference for Heterogeneous Dependency ParsingGuangyou Zhou and Jun ZhaoNational Laboratory of Pattern RecognitionInstitute of Automation, Chinese Academy of Sciences95 Zhongguancun East Road, Beijing 100190, China{gyzhou,jzhao}@nlpr.ia.ac.cnAbstractThis paper is concerned with the problemof heterogeneous dependency parsing.
Inthis paper, we present a novel joint infer-ence scheme, which is able to leveragethe consensus information between het-erogeneous treebanks in the parsing phase.Different from stacked learning meth-ods (Nivre and McDonald, 2008; Martinset al, 2008), which process the depen-dency parsing in a pipelined way (e.g., asecond level uses the first level outputs), inour method, multiple dependency parsingmodels are coordinated to exchange con-sensus information.
We conduct experi-ments on Chinese Dependency Treebank(CDT) and Penn Chinese Treebank (CTB),experimental results show that joint infer-ence can bring significant improvementsto all state-of-the-art dependency parsers.1 IntroductionDependency parsing is the task of building depen-dency links between words in a sentence, whichhas recently gained a wide interest in the natu-ral language processing community and has beenused for many problems ranging from machinetranslation (Ding and Palmer, 2004) to questionanswering (Zhou et al, 2011a).
Over the past fewyears, supervised learning methods have obtainedstate-of-the-art performance for dependency pars-ing (Yamada and Matsumoto, 2003; McDonaldet al, 2005; McDonald and Pereira, 2006; Hallet al, 2006; Zhou et al, 2011b; Zhou et al,2011c).
These methods usually rely heavily onthe manually annotated treebanks for training thedependency models.
However, annotating syntac-?
(with) ??
(eyes) ??
(cast) ??
(Hongkong )   BA                      NN                 VV                         NR?
(with) ??
(eyes) ??
(cast) ??
(Hongkong )      p                       n                      v                            nsFigure 1: Different grammar formalisms of syn-tactic structures between CTB (upper) and CDT(below).
CTB is converted into dependency gram-mar based on the head rules of (Zhang and Clark,2008).tic structure, either phrase-based or dependency-based, is both time consuming and labor intensive.Making full use of the existing manually annotatedtreebanks would yield substantial savings in data-annotation costs.In this paper, we present a joint inferencescheme for heterogenous dependency parsing.This scheme is able to leverage consensus in-formation between heterogenous treebanks dur-ing the inference phase instead of using individualoutput in a pipelined way, such as stacked learningmethods (Nivre and McDonald, 2008; Martins etal., 2008).
The basic idea is very simple: althoughheterogenous treebanks have different grammarformalisms, they share some consensus informa-tion in dependency structures for the same sen-tence.
For example in Figure 1, the dependencystructures actually share some partial agreementsfor the same sentence, the two words ?eyes?
and?Hongkong?
depend on ?cast?
in both ChineseDependency Treebank (CDT) (Liu et al, 2006)and Penn Chinese Treebank (CTB) (Xue et al,2005).
Therefore, we would like to train the de-pendency parsers on individual heterogenous tree-bank and jointly parse the same sentences withconsensus information exchanged between them.The remainder of this paper is divided as fol-104Treebank1 Treebank2Parser1 Parser2consensus information exchangeJoint inference test dataFigure 2: General joint inference scheme of het-erogeneous dependency parsing.lows.
Section 2 gives a formal description ofthe joint inference for heterogeneous dependencyparsing.
In section 3, we present the experimentalresults.
Finally, we conclude with ideas for futureresearch.2 Our ApproachThe general joint inference scheme of heteroge-neous dependency parsing is shown in Figure 2.Here, heterogeneous treebanks refer to two Chi-nese treebanks: CTB and CDT, therefore we haveonly two parsers, but the framework is genericenough to integrate more parsers.
For easy expla-nation of the joint inference scheme, we regard aparser without consensus information as a base-line parser, a parser incorporates consensus infor-mation called a joint parser.
Joint inference pro-vides a framework that accommodates and coordi-nates multiple dependency parsing models.
Sim-ilar to Li et al (2009) and Zhu et al (2010),the joint inference for heterogeneous dependencyparsing consists of four components: (1) Joint In-ference Model; (2) Parser Coordination; (3) JointInference Features; (4) Parameter Estimation.2.1 Joint Inference ModelFor a given sentence x, a joint dependency parsingmodel finds the best dependency parsing tree y?among the set of possible candidate parses Y(x)based on a scoring function Fs:y?
= argmaxy?Y(x)Fs(x, y) (1)Following (Li et al, 2009), we will use dk to de-note the kth joint parser, and also use the notationHk(x) for a list of parse candidates of sentencex determined by dk.
The sth joint parser can bewritten as:Fs(x, y) = Ps(x, y) +?k,k ?=s?k(y,Hk(x)) (2)where Ps(x, y) is the score function of the sthbaseline model, and each?k(y,Hk(x)) is a partialconsensus score function with respect to dk and isdefined over y andHk(x):?k(y,Hk(x)) =?l?k,lfk,l(y,Hk(x)) (3)where each fk,l(y,Hk(x)) is a feature functionbased on a consensus measure between y andHk(x), and ?k,l is the corresponding weight pa-rameter.
Feature index l ranges over all consensus-based features in equation (3).2.2 Parser CoordinationNote that in equation (2), though the baseline scorefunction Ps(x, y) can be computed individually,the case of ?k(y,Hk(x)) is more complicated.
Itis not feasible to enumerate all parse candidatesfor dependency parsing.
In this paper, we use abootstrapping method to solve this problem.
Thebasic idea is that we can use baseline models?
n-best output as seeds, and iteratively refine jointmodels?
n-best output with joint inference.
Thejoint inference process is shown in Algorithm 1.Algorithm 1 Joint inference for multiple parsersStep1: For each joint parser dk, perform inference witha baseline model, and memorize all dependency parsingcandidates generated during inference in Hk(x);Step2: For each candidate in Hk(x), we extract subtreesand store them inH?k(x).
First, we extract bigram-subtreesthat contain two words.
If two words have a dependencyrelation, we add these two words as a subtree into H?k(x).Similarly, we can extract trigram-subtrees.
Note that thedependency direction is kept.
Besides, we also store the?ROOT?
word of each candidate in H?k(x);Step3: Use joint parsers to re-parse the sentence x withthe baseline features and joint inference features (see sub-section 2.3).
For joint parser dk, consensus-based featuresof any dependency parsing candidate are computed basedon current setting of H?s(x) for all s but k. New depen-dency parsing candidates generated by dk in re-parsing arecached in H?
?k(x);Step4: Update all Hk(x) with H?
?k(x);Step5: Iterate from Step2 to Step4 until a preset iterationlimit is reached.In Algorithm 1, dependency parsing candidatesof different parsers can be mutually improved.
Forexample, given two parsers d1 and d2 with candi-dates H1 and H2, improvements on H1 enable d2to improve H2, and H1 benefits from improvedH2, and so on.We can see that a joint parser does not en-large the search space of its baseline model, theonly change is parse scoring.
By running a com-plete inference process, joint model can be appliedto re-parsing all candidates explored by a parser.105Thus Step3 can be viewed as full-scale candidatesreranking because the reranking scope is beyondthe limited n-best output currently cached inHk.2.3 Joint Inference FeaturesIn this section we introduce the consensus-basedfeature functions fk,l(y,Hk(x)) introduced inequation (3).
The formulation can be written as:fk,l(y,Hk(x)) =?y?
?Hk(x)P (y?|dk)Il(y, y?)
(4)where y is a dependency parse of x by using parserds (s ?= k), y?
is a dependency parse in Hk(x)and P (y?|dk) is the posterior probability of depen-dency parse y?
parsed by parser dk given sentencex.
Il(y, y?)
is a consensus measure defined on yand y?
using different feature functions.Dependency parsing model P (y?|dk) can bepredicted by using the global linear models(GLMs) (e.g., McDonald et al (2005); McDonaldand Pereira (2006)).
The consensus-based scorefunctions Il(y, y?)
include the following parts:(1) head-modifier dependencies.
Each head-modifier dependency (denoted as ?edge?)
is a tu-ple t =< h,m, h ?
m >, so Iedge(y, y?)
=?t?y ?
(t, y?).
(2) sibling dependencies: Each sibling de-pendency (denoted as ?sib?)
is a tuple t =<i, h,m, h ?
i ?
m >, so Isib(y, y?)
=?t?y ?
(t, y?).
(3) grandparent dependencies: Each grand-parent dependency (denoted as ?gp?)
is a tuplet =< h, i,m, h ?
i ?
m >, so Igp(y, y?)
=?<h,i,m,h?i?m>?y ?
(t, y?).
(4) root feature: This feature (denoted as?root?)
indicates whether the multiple depen-dency parsing trees share the same ?ROOT?, soIroot(y, y?)
=?<ROOT>?y ?
(< ROOT >, y?).?
(?, ?)
is a indicator function??
(t, y?)
is 1 ift ?
y?
and 0 otherwise, feature index l ?
{edge, sib, gp, root} in equation (4).
Note that< h,m, h ?
m > and < m,h,m ?
h > aretwo different edges.In our joint model, we extend the baseline fea-tures of (McDonald et al, 2005; McDonald andPereira, 2006; Carreras, 2007) by conjoining withthe consensus-based features, so that we can learnin which kind of contexts the different parsersagree/disagree.
For the third-order features (e.g.,grand-siblings and tri-siblings) described in (Kooet al, 2010), we will discuss it in future work.2.4 Parameter EstimationThe parameters are tuned to maximize the depen-dency parsing performance on the developmentset, using an algorithm similar to the average per-ceptron algorithm due to its strong performanceand fast training (Koo et al, 2008).
Due to lim-ited space, we do not present the details.
For moreinformation, please refer to (Koo et al, 2008).3 ExperimentsIn this section, we describe the experimentsto evaluate our proposed approach by usingCTB4 (Xue et al, 2005) and CDT (Liu et al,2006).
For the former, we adopt a set of head-selection rules (Zhang and Clark, 2008) to convertthe phrase structure syntax of treebank into a de-pendency tree representation.
The standard datasplit of CTB4 from Wang et al (2007) is used.
Forthe latter, we randomly select 2,000 sentences fortest set, another 2,000 sentences for developmentset, and others for training set.We use two baseline parsers, one trained onCTB4, and another trained on CDT in the ex-periments.
We choose the n-best size of 16 andthe best iteration time of four on the developmentset since these settings empirically give the bestperformance.
CTB4 and CDT use two differentPOS tag sets and transforming from one tag setto another is difficult (Niu et al, 2009).
To over-come this problem, we use Stanford POS Tagger1to train a universal POS tagger on the People?sDaily corpus,2 a large-scale Chinese corpus (ap-proximately 300 thousand sentences and 7 mil-lion words) annotated with word segmentation andPOS tags.
Then the POS tagger produces a uni-versal layer of POS tags for both the CTB4 andCDT.
Note that the word segmentation standardsof these corpora (CTB4, CDT and People?s Daily)slightly differs; however, we do not consider thisproblem and leave it for future research.The performance of the parsers is evaluated us-ing the following metrics: UAS, DA, and CM,which are defined by (Hall et al, 2006).
All themetrics except CM are calculated as mean scoresper word, and punctuation tokens are consistentlyexcluded.We conduct experiments incrementally to eval-uate the joint features used in our first-order andsecond-order parsers.
The first-order parser1http://nlp.stanford.edu/software/tagger.shtml2http://www.icl.pku.edu.cn106?
Features CTB4 CDTUAS CM UAS CMdep1baseline 86.6 42.5 75.4 16.6+ edge 88.01 (?1.41) 44.28 (?1.78) 77.10 (?1.70) 17.82 (?1.22)+ root 87.22 (?0.62) 43.03 (?0.53) 75.83 (?0.43) 16.81 (?0.21)+ both 88.19 (?1.59) 44.54 (?2.04) 77.16 (?1.76) 17.90 (?1.30)CTB4 + CDT 87.32 43.08 75.91 16.89dep2baseline 88.38 48.81 77.52 19.70+ edge 89.17 (?0.79) 49.73 (?0.92) 78.44 (?0.92) 20.85 (?1.15)+ sib 88.94 (?0.56) 49.26 (?0.45) 78.02 (?0.50) 20.13 (?0.43)+ gp 88.90 (?0.52) 49.11 (?0.30) 77.97 (?0.45) 20.06 (?0.36)+ root 88.61 (?0.23) 48.88 (?0.07) 77.65 (?0.13) 19.88 (?0.18)+ all 89.62 (?1.24) 50.15 (?1.34) 79.01 (?1.49) 21.11 (?1.41)CTB4 + CDT 88.91 49.13 78.03 20.12Table 1: Dependency parsing results on the test set with different joint inference features.
Abbreviations:dep1/dep2 = first-order parser and second-order parser; baseline = dep1 without considering any jointinference features; +* = the baseline features conjoined with the joint inference features derived from theheterogeneous treebanks; CTB4 + CDT = we simply concatenate the two corpora and train a dependencyparser, and then test on CTB4 and CDT using this single model.
Improvements of joint models overbaseline models are shown in parentheses.Type Systems ?
40 FullDdep2 90.86 88.38MaltParser 87.1 85.8Wang et al (2007) 86.6 -CMSTMalt?
90.55 88.82Martins et al (2008)?
90.63 88.84Surdeanu et al (2010)?
89.40 86.63H Zhao et al (2009) 88.9 86.1Ours 91.48 89.62S Yu et al (2008) - 87.26Chen et al (2009) 92.34 89.91Chen et al (2012) - 91.59Table 2: Comparison of different approach onCTB4 test set using UAS metric.
MaltParser =Hall et al (2006); MSTMalt=Nivre and McDon-ald (2008).
Type D = discriminative dependencyparsers without using any external resources; C =combined parsers (stacked and ensemble parsers);H = discriminative dependency parsers using ex-ternal resources derived from heterogeneous tree-banks, S = discriminative dependency parsers us-ing external unlabeled data.
?
The results on CTB4were not directly reported in these papers, we im-plemented the experiments in this paper.
(dep1) only incorporates head-modifier depen-dency part (McDonald et al, 2005).
The second-order parser (dep2) uses the head-modifier andsibling dependency parts (McDonald and Pereira,2006), as well as the grandparent dependencypart (Carreras, 2007; Koo et al, 2008).
Table 1shows the experimental results.As shown in Table 1, we note that adding morejoint inference features incrementally, the depen-dency parsing performance is improved consis-tently, for both treebanks (CTB4 or CDT).
As afinal note, all comparisons between joint modelsand baseline models in Table 1 are statistically sig-nificant.3 Furthermore, we also present a base-line method called ?CTB4 + CDT?
for compari-son.
This method first tags both CTB4 and CDTwith the universal POS tagger trained on the Peo-ple?s Daily corpus, then simply concatenates thetwo corpora and trains a dependency parser, andfinally tests on CTB4 and CDT using this singlemodel.
The comparisons in Table 1 tell us thatvery limited information is obtained without con-sensus features by simply taking a union of thedependencies and their contexts from the two tree-banks.To put our results in perspective, we also com-pare our second-order joint parser with other best-performing systems.
??
40?
refers to the sentencewith the length up to 40 and ?Full?
refers to allthe sentences in test set.
The results are shownin Table 2, our approach significantly outperformsmany systems evaluated on this data set.
Chenet al (2009) and Chen et al (2012) reported avery high accuracy using subtree-based featuresand dependency language model based featuresderived from large-scale data.
Our systems did notuse such knowledge.
Moreover, their technique isorthogonal to ours, and we suspect that combin-ing their subtree-based features into our systemsmight get an even better performance.
We do notpresent the comparison of our proposed approach3We use the sign test at the sentence level.
All the com-parisons are significant at p < 0.05.107Type Systems UAS DADDuan et al (2007) 83.88 84.36Huang and Sagae (2010) 85.20 85.52Zhang and Nivre (2011) 86.0 -C Zhang and Clark (2008) - 86.21Bohnet and Kuhn (2012) 87.5 -H Li et al (2012) 86.44 -Ours 85.88 86.52S Chen et al (2009) - 86.70Table 3: Comparison of different approaches onCTB5 test set.
Abbreviations D, C, H and S are asin Table 2.Treebanks #Sen # Better # NoChange # WorseCTB4 355 74 255 26CDT 2,000 341 1,562 97Table 4: Statistics on joint inference output onCTB4 and CDT development set.with the state-of-the-art methods on CDT becausethere is little work conducted on this treebank.Some researchers conducted experiments onCTB5 with a different data split: files 1-815 andfiles 1,001-1,136 for training, files 886-931 and1,148-1,151 for development, files 816-885 andfiles 1,137-1,147 for testing.
The developmentand testing sets were also performed using gold-standard assigned POS tags.
We report the experi-mental results on CTB5 test set in Table 4.
Our re-sults are better than most systems on this data split,except Zhang and Nivre (2011), Li et al (2012)and Chen et al (2009).3.1 Additional ResultsTo obtain further information about how depen-dency parsers benefit from the joint inference, weconduct an initial experiment on CTB4 and CDT.From Table 4, we find that out of 355 sentences onthe development set of CTB4, 74 sentences ben-efit from the joint inference, while 26 sentencessuffer from it.
For CDT, we also find that out of2,000 sentences on the development set, 341 sen-tences benefit from the joint inference, while 97sentences suffer from it.
Although the overall de-pendency parsing results is improved, joint infer-ence worsens dependency parsing result for somesentences.
In order to obtain further informationabout the error sources, it is necessary to investi-gate why joint inference gives negative results, wewill leave it for future work.4 Conclusion and Future WorkWe proposed a novel framework of joint infer-ence, in which multiple dependency parsing mod-els were coordinated to search for better depen-dency parses by leveraging the consensus infor-mation between heterogeneous treebanks.
Exper-imental results showed that joint inference signif-icantly outperformed the state-of-the-art baselinemodels.There are some ways in which this researchcould be continued.
First, recall that the joint in-ference scheme involves an iterative algorithm byusing bootstrapping.
Intuitively, there is a lack offormal guarantee.
A natural avenue for further re-search would be the use of more powerful algo-rithms that provide certificates of optimality; e.g.,dual decomposition that aims to develop decod-ing algorithms with formal guarantees (Rush etal., 2010).
Second, we would like to combine ourheterogeneous treebank annotations into a unifiedrepresentation in order to make dependency pars-ing results comparable across different annotationguidelines (e.g., Tsarfaty et al (2011)).AcknowledgmentsThis work was supported by the National NaturalScience Foundation of China (No.
61070106, No.61272332 and No.
61202329), the National HighTechnology Development 863 Program of China(No.
2012AA011102), the National Basic Re-search Program of China (No.
2012CB316300),We thank the anonymous reviewers and the priorreviewers of ACL-2012 and AAAI-2013 for theirinsightful comments.
We also thank Dr. Li Cai forproviding and preprocessing the data set used inthis paper.ReferencesB.
Bohnet and J. Kuhn.
2012.
The best of both worlds-a graph-based completion model for transition-based parsers.
In Proceedings of EACL.X.
Carreras.
2007.
Experiments with a Higher-orderProjective Dependency Parser.
In Proceedings ofEMNLP-CoNLL, pages 957-961.W.
Chen, D. Kawahara, K. Uchimoto, and Torisawa.2009.
Improving Dependency Parsing with Subtreesfrom Auto-Parsed Data.
In Proceedings of EMNLP,pages 570-579.W.
Chen, M. Zhang, and H. Li.
2012.
Utilizing depen-dency language models for graph-based dependencyparsing models.
In Proceedings of ACL.Y.
Ding and M. Palmer.
2004.
Synchronous depen-dency insertion grammars: a grammar formalismfor syntax based statistical MT.
In Proceedings of108the Workshop on Recent Advances in DependencyGrammar, pages 90-97.X.
Duan, J. Zhao, and B. Xu.
2007.
Probabilistic Mod-els for Action-based Chinese Dependency Parsing.In Proceedings of ECML/PKDD.J.
M. Eisner.
2000.
Bilexical Grammars and TheirCubic-Time Parsing Algorithm.
Advanced in Prob-abilistic and Other Parsing Technologies, pages 29-62.J.
Hall, J. Nivre, and J. Nilsson.
2006.
DiscriminativeClassifier for Deterministic Dependency Parsing.
InProceedings of ACL, pages 316-323.L.
Huang and K. Sagae.
2010.
Dynamic Programmingfor Linear-Time Incremental Parsing.
In Proceed-ings of ACL, pages 1077-1086.T.
Koo, X. Carreras, and M. Collins.
2008.
SimpleSemi-Supervised Dependency Parsing.
In Proceed-ings of ACL.T.
Koo, A. M. Rush, M. Collins, T. Jaakkola, and D.Sontag.
2010.
Dual Decomposition for Parsing withNon-Projective Head Automata.
In Proceedings ofEMNLP.M.
Li, N. Duan, D. Zhang, C.-H. Li, and M. Zhou.2009.
Collaborative Decoding: Partial HypothesisRe-ranking Using Translation Consensus BetweenDecoders.
In Proceedings of ACL, pages 585-592.Z.
Li, T. Liu, and W. Che.
2012.
Exploiting multipletreebanks for parsing with Quasi-synchronous gram-mars.
In Proceedings of ACL.T.
Liu, J. Ma, and S. Li.
2006.
Building a DependencyTreebank for Improving Chinese Parser.
Journal ofChinese Languages and Computing, 16(4):207-224.A.
F. T. Martins, D. Das, N. A. Smith, and E. P. Xing.2008.
Stacking Dependency Parsers.
In Proceed-ings of EMNLP, pages 157-166.R.
McDonald and F. Pereira.
2006.
Online Learning ofApproximate Dependency Parsing Algorithms.
InProceedings of EACL, pages 81-88.R.
McDonald, K. Crammer, and F. Pereira.
2005.
On-line Large-margin Training of Dependency Parsers.In Proceedings of ACL, pages 91-98.Z.
Niu, H. Wang, and H. Wu.
2009.
Exploiting Het-erogeneous Treebanks for Parsing.
In Proceedingsof ACL, pages 46-54.J.
Nivre and R. McDonld.
2008.
Integrating Graph-based and Transition-based Dependency Parsing.
InProceedings of ACL, pages 950-958.A.
M. Rush, D. Sontag, M. Collins, and T. Jaakkola.2010.
On Dual Decomposition and Linear Program-ming Relation for Natural Language Processing.
InProceedings of EMNLP.M.
Surdeanu and C. D. Manning.
2010.
EnsembleModels for Dependency Parsing: Cheap and Good?In Proceedings of NAACL.R.
Tsarfaty, J. Nivre, and E. Andersson.
2011.
Eval-uating Dependency Parsing: Robust and Heuristics-Free Cross-Annotation Evaluation.
In Proceedingsof EMNLP.J.-N Wang, J-.S.
Chang, and K.-Y.
Su.
1994.
An Au-tomatic Treebank Conversion Algorithm for CorpusSharing.
In Proceedings of ACL, pages 248-254.Q.
I. Wang, D. Lin, and D. Schuurmans.
2007.
Sim-ple Training of Dependency Parsers via StructuredBoosting.
In Proceedings of IJCAI, pages 1756-1762.N.
Xue, F. Xia, F.-D. Chiou, and M. Palmer.
2005.The Penn Chinese Treebank: Phrase Structure An-notation of a Large Corpus.
Natural Language En-gineering, 10(4):1-30.Yamada and Matsumoto.
2003.
Statistical SependencyAnalysis with Support Vector Machines.
In Pro-ceedings of IWPT, pages 195-206.D.
H. Younger.
1967.
Recognition and Parsing ofContext-Free Languages in Time n3.
Informationand Control, 12(4):361-379, 1967.K.
Yu, D. Kawahara, and S. Kurohashi.
2008.
Chi-nese Dependency Parsing with Large Scale Auto-matically Constructed Case Structures.
In Proceed-ings of COLING, pages 1049-1056.Y.
Zhang and S. Clark.
2008.
A Tale of TwoParsers: Investigating and Combining Graph-basedand Transition-based Dependency Parsing UsingBeam-Search.
In Proceedings of EMNLP, pages562-571.Y.
Zhang and J. Nivre.
2011.
Transition-based De-pendency Parsing with Rich Non-local Features.
InProceedings of ACL, pages 188-193.H.
Zhao, Y.
Song, C. Kit, and G. Zhou.
2009.
CrossLanguage Dependency Parsing Using a BilingualLexicon.
In Proceedings of ACL, pages 55-63.G.
Zhou, L. Cai, J. Zhao, and K. Liu.
2011.
Phrase-Based Translation Model for Question Retrieval inCommunity Question Answer Archives.
In Pro-ceedings of ACL, pages 653-662.G.
Zhou, J. Zhao, K. Liu, and L. Cai.
2011.
Exploit-ing Web-Derived Selectional Preference to ImproveStatistical Dependency Parsing.
In Proceedings ofACL, pages 1556-1565.G.
Zhou, L. Cai, K. Liu, and J. Zhao.
2011.
ImprovingDependency Parsing with Fined-Grained Features.In Proceedings of IJCNLP, pages 228-236.M.
Zhu, J. Zhu, and T. Xiao.
2010.
HeterogeneousParsing via Collaborative Decoding.
In Proceedingsof COLING, pages 1344-1352.109
