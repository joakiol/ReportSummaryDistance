The Text REtrieval Conferences (TRECs)Donna HarmanNational Institute of Standards and TechnologyGaithersburg, MD 20899There have been four Text REtrieval Conferences(TRECs); TREC-1 in November 1992, TREC-2 in Au-gust 1993, TREC-3 in November 1994 and TREC-4 inNovember 1995.
The number of participating systemshas grown from 25 in TREC-1 to 36 in TREC-4, includ-ing most of the major text retrieval software companiesand most of the universities doing research in text re-trieval (see table for some of the participants).
The di-versity of the participating roups has ensured thatTREC represents many different approaches to text re-trieval, while the emphasis on individual experimentsevaluated in a common setting has proven to be a majorstrength of TREC.The test design and test collection used for documentdetection i  TIPSTER was also used in TREC.
The par-ticipants ran the various tasks, sent results into NIST forevaluation, presented the results at the TREC confer-ences, and submitted papers for a proceedings.
The testcollection consists of over 1 million documents from di-verse full-text sources, 250 topics, and the set of rele-vant documents or "right answers" to those topics.
ASpanish collection has been built and used duringTREC-3 and TREC-4, with a total of 50 topics.TREC-1 required significant system rebuilding bymost groups due to the huge increase in the size of thedocument collection (from a traditional test collection ofseveral megabytes in size to the 2 gigabyte TIPSTERcollection).
The results from TREC-2 showed signifi-cant improvements over the TREC-1 results, and shouldbe viewed as the appropriate baseline representing state-of-the-art retrieval techniques as scaled up to handling a2 gigabyte collection.TREC-3 therefore provided the first opportunity formore complex experimentation.
The major experimentsin TREC-3 included the development of automaticquery expansion techniques, the use of passages or sub-documents o increase the precision of retrieval results,and the use of the training information to select only thebest terms for routing queries.
Some groups exploredhybrid approaches (such as the use of the Rocchiomethodology in systems not using a vector space mod-el), and others tried approaches that were radically dif-ferent from their original approaches.TREC-4 allowed a continuation of many of thesecomplex experiments.
The topics were made muchshorter and this change triggered extensive investiga-tions in automatic query expansion.
There were alsofive new tasks, called tracks.
These were added to helpfocus research on certain known problem areas, and in-cluded such issues as investigating searching as an inter-active task by examining the process as well as the out-come, investigating techniques for merging results fromthe various TREC subcollections, examining the effectsof corrupted ata, and evaluating routing systems usinga specific effectiveness measure.
Additionally moregroups participated in a track for Spanish retrieval.The TREC conferences have proven to be very sue-cessful, allowing broad participation in the overallDARPA TIPSTER effort, and causing widespread use ofa very large test collection.
All conferences have hadvery open, honest discussions of technical issues, andthere have been large amounts of "cross-fertilization" ofideas.
This will be a continuing effort, with a TREC-5conference scheduled inNovember of 1996.A Sample of the TREC-4 ParticipantsCLARITECH/Carnegie Melon UniversityCITRI, AustraliaCity University, LondonComell UniversityDepartment ofDefenseExcalibur Technologies, Inc.GE Corporate 1/& D/New York UniversityGeorge Mason UniversityHNC, Inc.Lexis-NexisLogicon Operating SystemsNEC CorporationNew Mexico State UniversityQueens College, CUNYRutgers University (two groups)Siemens Corporate Research Inc.Swiss Federal Institute of Technology (ETH)University of California - BerkeleyUniversity of Massachusetts at AmherstUniversity of WaterlooXerox Palo Alto Research Center39
