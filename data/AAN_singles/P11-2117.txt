Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 665?669,Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational LinguisticsSimple English Wikipedia: A New Text Simplification TaskWilliam CosterComputer Science DepartmentPomona CollegeClaremont, CA 91711wpc02009@pomona.eduDavid KauchakComputer Science DepartmentPomona CollegeClaremont, CA 91711dkauchak@cs.pomona.eduAbstractIn this paper we examine the task of sentencesimplification which aims to reduce the read-ing complexity of a sentence by incorporat-ing more accessible vocabulary and sentencestructure.
We introduce a new data set thatpairs English Wikipedia with Simple EnglishWikipedia and is orders of magnitude largerthan any previously examined for sentencesimplification.
The data contains the full rangeof simplification operations including reword-ing, reordering, insertion and deletion.
Weprovide an analysis of this corpus as well aspreliminary results using a phrase-based trans-lation approach for simplification.1 IntroductionThe task of text simplification aims to reduce thecomplexity of text while maintaining the content(Chandrasekar and Srinivas, 1997; Carroll et al,1998; Feng, 2008).
In this paper, we explore thesentence simplification problem: given a sentence,the goal is to produce an equivalent sentence wherethe vocabulary and sentence structure are simpler.Text simplification has a number of important ap-plications.
Simplification techniques can be used tomake text resources available to a broader range ofreaders, including children, language learners, theelderly, the hearing impaired and people with apha-sia or cognitive disabilities (Carroll et al, 1998;Feng, 2008).
As a preprocessing step, simplificationcan improve the performance of NLP tasks, includ-ing parsing, semantic role labeling, machine transla-tion and summarization (Miwa et al, 2010; Jonnala-gadda et al, 2009; Vickrey and Koller, 2008; Chan-drasekar and Srinivas, 1997).
Finally, models fortext simplification are similar to models for sentencecompression; advances in simplification can bene-fit compression, which has applications in mobiledevices, summarization and captioning (Knight andMarcu, 2002; McDonald, 2006; Galley and McKe-own, 2007; Nomoto, 2009; Cohn and Lapata, 2009).One of the key challenges for text simplificationis data availability.
The small amount of simplifi-cation data currently available has prevented the ap-plication of data-driven techniques like those usedin other text-to-text translation areas (Och and Ney,2004; Chiang, 2010).
Most prior techniques fortext simplification have involved either hand-craftedrules (Vickrey and Koller, 2008; Feng, 2008) orlearned within a very restricted rule space (Chan-drasekar and Srinivas, 1997).We have generated a data set consisting of 137Kaligned simplified/unsimplified sentence pairs bypairing documents, then sentences from EnglishWikipedia1 with corresponding documents and sen-tences from Simple English Wikipedia2.
Simple En-glish Wikipedia contains articles aimed at childrenand English language learners and contains similarcontent to English Wikipedia but with simpler vo-cabulary and grammar.Figure 1 shows example sentence simplificationsfrom the data set.
Like machine translation and othertext-to-text domains, text simplification involves thefull range of transformation operations includingdeletion, rewording, reordering and insertion.1http://en.wikipedia.org/2http://simple.wikipedia.org665a.
Normal: As Isolde arrives at his side, Tristan dies with her name on his lips.Simple: As Isolde arrives at his side, Tristan dies while speaking her name.b.
Normal: Alfonso Perez Munoz, usually referred to as Alfonso, is aformer Spanish footballer, in the striker position.Simple: Alfonso Perez is a former Spanish football player.c.
Normal: Endemic types or species are especially likely to develop on islandsbecause of their geographical isolation.Simple: Endemic types are most likely to develop on islands becausethey are isolated.d.
Normal: The reverse process, producing electrical energy from mechanical,energy, is accomplished by a generator or dynamo.Simple: A dynamo or an electric generator does the reverse: it changesmechanical movement into electric energy.Figure 1: Example sentence simplifications extracted from Wikipedia.
Normal refers to a sentence in an EnglishWikipedia article and Simple to a corresponding sentence in Simple English Wikipedia.2 Previous DataWikipedia and Simple English Wikipedia have bothreceived some recent attention as a useful resourcefor text simplification and the related task of textcompression.
Yamangil and Nelken (2008) examinethe history logs of English Wikipedia to learn sen-tence compression rules.
Yatskar et al (2010) learna set of candidate phrase simplification rules basedon edits identified in the revision histories of bothSimple English Wikipedia and English Wikipedia.However, they only provide a list of the top phrasalsimplifications and do not utilize them in an end-to-end simplification system.
Finally, Napoles andDredze (2010) provide an analysis of the differencesbetween documents in English Wikipedia and Sim-ple English Wikipedia, though they do not view thedata set as a parallel corpus.Although the simplification problem shares somecharacteristics with the text compression problem,existing text compression data sets are small andcontain a restricted set of possible transformations(often only deletion).
Knight and Marcu (2002) in-troduced the Zipf-Davis corpus which contains 1Ksentence pairs.
Cohn and Lapata (2009) manuallygenerated two parallel corpora from news stories to-taling 3K sentence pairs.
Finally, Nomoto (2009)generated a data set based on RSS feeds containing2K sentence pairs.3 Simplification Corpus GenerationWe generated a parallel simplification corpus byaligning sentences between English Wikipedia andSimple English Wikipedia.
We obtained completecopies of English Wikipedia and Simple EnglishWikipedia in May 2010.
We first paired the articlesby title, then removed all article pairs where eitherarticle: contained only a single line, was flagged as astub, was flagged as a disambiguation page or was ameta-page about Wikipedia.
After pairing and filter-ing, 10,588 aligned, content article pairs remained(a 90% reduction from the original 110K Simple En-glish Wikipedia articles).
Throughout the rest of thispaper we will refer to unsimplified text from EnglishWikipedia as normal and to the simplified versionfrom Simple English Wikipedia as simple.To generate aligned sentence pairs from thealigned document pairs we followed an approachsimilar to those utilized in previous monolingualalignment problems (Barzilay and Elhadad, 2003;Nelken and Shieber, 2006).
Paragraphs were iden-tified based on formatting information available inthe articles.
Each simple paragraph was then alignedto every normal paragraph where the TF-IDF, co-sine similarity was over a threshold or 0.5.
We ini-tially investigated the paragraph clustering prepro-cessing step in (Barzilay and Elhadad, 2003), butdid not find a qualitative difference and opted for thesimpler similarity-based alignment approach, whichdoes not require manual annotation.666For each aligned paragraph pair (i.e.
a simpleparagraph and one or more normal paragraphs), wethen used a dynamic programming approach to findthat best global sentence alignment following Barzi-lay and Elhadad (2003).
Specifically, given n nor-mal sentences to align to m simple sentences, wefind a(n,m) using the following recurrence:a(i, j) =max????????
?a(i, j ?
1)?
skip penaltya(i?
1, j)?
skip penaltya(i?
1, j ?
1) + sim(i, j)a(i?
1, j ?
2) + sim(i, j) + sim(i, j ?
1)a(i?
2, j ?
1) + sim(i, j) + sim(i?
1, j)a(i?
2, j ?
2) + sim(i, j ?
1) + sim(i?
1, j)where each line above corresponds to a sentencealignment operation: skip the simple sentence, skipthe normal sentence, align one normal to one sim-ple, align one normal to two simple, align two nor-mal to one simple and align two normal to two sim-ple.
sim(i, j) is the similarity between the ith nor-mal sentence and the jth simple sentence and wascalculated using TF-IDF, cosine similarity.
We setskip penalty = 0.0001 manually.Barzilay and Elhadad (2003) further discouragealigning dissimilar sentences by including a ?mis-match penalty?
in the similarity measure.
Instead,we included a filtering step removing all sentencepairs with a normalized similarity below a thresholdof 0.5.
We found this approach to be more intuitiveand allowed us to compare the effects of differinglevels of similarity in the training set.
Our choice ofthreshold is high enough to ensure that most align-ments are correct, but low enough to allow for vari-ation in the paired sentences.
In the future, we hopeto explore other similarity techniques that will pairsentences with even larger variation.4 Corpus AnalysisFrom the 10K article pairs, we extracted 75Kaligned paragraphs.
From these, we extracted thefinal set of 137K aligned sentence pairs.
To evaluatethe quality of the aligned sentences, we asked twohuman evaluators to independently judge whether ornot the aligned sentences were correctly aligned ona random sample of 100 sentence pairs.
They thenwere asked to reach a consensus about correctness.91/100 were identified as correct, though many ofthe remaining 9 also had some partial content over-lap.
We also repeated the experiment using onlythose sentences with a similarity above 0.75 (ratherthan 0.50 in the original data).
This reduced thenumber of pairs from 137K to 90K, but the eval-uators identified 98/100 as correct.
The analysisthroughout the rest of the section is for thresholdof 0.5, though similar results were also seen for thethreshold of 0.75.Although the average simple article contained ap-proximately 40 sentences, we extracted an averageof 14 aligned sentence pairs per article.
Qualita-tively, it is rare to find a simple article that is a directtranslation of the normal article, that is, a simple ar-ticle that was generated by only making sentence-level changes to the normal document.
However,there is a strong relationship between the two datasets: 27% of our aligned sentences were identicalbetween simple and normal.
We left these identicalsentence pairs in our data set since not all sentencesneed to be simplified and it is important for any sim-plification algorithm to be able to handle this case.Much of the content without direct correspon-dence is removed during paragraph alignment.
65%of the simple paragraphs do not align to a normalparagraphs and are ignored.
On top of this, withinaligned paragraphs, there are a large number of sen-tences that do not align.
Table 1 shows the propor-tion of the different sentence level alignment opera-tions in our data set.
On both the simple and normalsides there are many sentences that do not align.Operation %skip simple 27%skip normal 23%one normal to one simple 37%one normal to two simple 8%two normal to one simple 5%Table 1: Frequency of sentence-level alignment opera-tions based on our learned sentence alignment.
No 2-to-2alignments were found in the data.To better understand how sentences are trans-formed from normal to simple sentences we learneda word alignment using GIZA++ (Och and Ney,2003).
Based on this word alignment, we calcu-lated the percentage of sentences that included: re-667wordings ?
a normal word is changed to a differentsimple word, deletions ?
a normal word is deleted,reorderings ?
non-monotonic alignment, splits ?
anormal words is split into multiple simple words,and merges ?
multiple normal words are condensedto a single simple word.Transformation %rewordings 65%deletions 47%reorders 34%merges 31%splits 27%Table 2: Percentage of sentence pairs that containedword-level operations based on the induced word align-ment.
Splits and merges are from the perspective ofwords in the normal sentence.
These are not mutuallyexclusive events.Table 2 shows the percentage of each of these phe-nomena occurring in the sentence pairs.
All of thedifferent operations occur frequently in the data setwith rewordings being particularly prevalent.5 Sentence-level Text SimplificationTo understand the usefulness of this data we ranpreliminary experiments to learn a sentence-levelsimplification system.
We view the problem oftext simplification as an English-to-English transla-tion problem.
Motivated by the importance of lex-ical changes, we used Moses, a phrase-based ma-chine translation system (Och and Ney, 2004).3 Wetrained Moses on 124K pairs from the data set andthe n-gram language model on the simple side of thisdata.
We trained the hyper-parameters of the log-linear model on a 500 sentence pair development set.We compared the trained system to a baseline ofnot doing any simplification (NONE).
We evaluatedthe two approaches on a test set of 1300 sentencepairs.
Since there is currently no standard for au-tomatically evaluating sentence simplification, weused three different automatic measures that havebeen used in related domains: BLEU, which hasbeen used extensively in machine translation (Pap-ineni et al, 2002), and word-level F1 and simplestring accuracy (SSA) which have been suggested3We also experimented with T3 (Cohn and Lapata, 2009)but the results were poor and are not presented here.System BLEU word-F1 SSANONE 0.5937 0.5967 0.6179Moses 0.5987 0.6076 0.6224Moses-Oracle 0.6317 0.6661 0.6550Table 3: Test scores for the baseline (NONE), Moses andMoses-Oracle.for text compression (Clarke and Lapata, 2006).
Allthree of these measures have been shown to correlatewith human judgements in their respective domains.Table 3 shows the results of our initial test.
Alldifferences are statistically significant at p = 0.01,measured using bootstrap resampling with 100 sam-ples (Koehn, 2004).
Although the baseline does well(recall that over a quarter of the sentence pairs inthe data set are identical) the phrase-based approachdoes obtain a statistically significant improvement.To understand the the limits of the phrase-basedmodel for text simplification, we generated an n-best list of the 1000 most-likely simplifications foreach test sentence.
We then greedily picked the sim-plification from this n-best list that had the highestsentence-level BLEU score based on the test exam-ples, labeled Moses-Oracle in Table 3.
The largedifference between Moses and Moses-Oracle indi-cates possible room for improvement utilizing betterparameter estimation or n-best list reranking tech-niques (Och et al, 2004; Ge and Mooney, 2006).6 ConclusionWe have described a new text simplification data setgenerated from aligning sentences in Simple EnglishWikipedia with sentences in English Wikipedia.
Thedata set is orders of magnitude larger than any cur-rently available for text simplification or for the re-lated field of text compression and is publicly avail-able.4 We provided preliminary text simplificationresults using Moses, a phrase-based translation sys-tem, and saw a statistically significant improvementof 0.005 BLEU over the baseline of no simplifica-tion and showed that further improvement of up to0.034 BLEU may be possible based on the oracleresults.
In the future, we hope to explore alignmenttechniques more tailored to simplification as well asapplications of this data to text simplification.4http://www.cs.pomona.edu/?dkauchak/simplification/668ReferencesRegina Barzilay and Noemie Elhadad.
2003.
Sentencealignment for monolingual comparable corpora.
InProceedings of EMNLP.John Carroll, Gido Minnen, Yvonne Canning, SiobhanDevlin, and John Tait.
1998.
Practical simplificationof English newspaper text to assist aphasic readers.
InProceedings of AAAI Workshop on Integrating AI andAssistive Technology.Raman Chandrasekar and Bangalore Srinivas.
1997.
Au-tomatic induction of rules for text simplification.
InKnowledge Based Systems.David Chiang.
2010.
Learning to translate with sourceand target syntax.
In Proceedings of ACL.James Clarke and Mirella Lapata.
2006.
Models forsentence compression: A comparison across domains,training requirements and evaluation measures.
InProceedings of ACL.Trevor Cohn and Mirella Lapata.
2009.
Sentence com-pression as tree transduction.
Journal of Artificial In-telligence Research.Lijun Feng.
2008.
Text simplification: A survey.
CUNYTechnical Report.Michel Galley and Kathleen McKeown.
2007.
Lexical-ized Markov grammars for sentence compression.
InProceedings of HLT/NAACL.Ruifang Ge and Raymond Mooney.
2006.
Discrimina-tive reranking for semantic parsing.
In Proceedings ofCOLING.Siddhartha Jonnalagadda, Luis Tari, Jorg Hakenberg,Chitta Baral, and Graciela Gonzalez.
2009.
To-wards effective sentence simplification for automaticprocessing of biomedical text.
In Proceedings ofHLT/NAACL.Dan Klein and Christopher Manning.
2003.
Accurateunlexicalized parsing.
In Proceedings of ACL.Kevin Knight and Daniel Marcu.
2002.
Summarizationbeyond sentence extraction: A probabilistic approachto sentence compression.
Artificial Intelligence.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran, RichardZens, Chris Dyer, Ondrej Bojar, Alexandra Con-stantin, and Evan Herbst.
2007.
Moses: Open sourcetoolkit for statistical machine translation.
In Proceed-ings of ACL.Philipp Koehn.
2004.
Statistical significance tests formachine translation evaluation.
In Proceedings ofEMNLP.Ryan McDonald.
2006.
Discriminative sentence com-pression with soft syntactic evidence.
In Proceedingsof EACL.Makoto Miwa, Rune Saetre, Yusuke Miyao, and Jun?ichiTsujii.
2010.
Entity-focused sentence simplication forrelation extraction.
In Proceedings of COLING.Courtney Napoles and Mark Dredze.
2010.
Learn-ing simple Wikipedia: A cogitation in ascertainingabecedarian language.
In Proceedings of HLT/NAACLWorkshop on Computation Linguistics and Writing.Rani Nelken and Stuart Shieber.
2006.
Towards robustcontext-sensitive sentence alignment for monolingualcorpora.
In Proceedings of AMTA.Tadashi Nomoto.
2007.
Discriminative sentence com-pression with conditional random fields.
In Informa-tion Processing and Management.Tadashi Nomoto.
2008.
A generic sentence trimmer withCRFs.
In Proceedings of HLT/NAACL.Tadashi Nomoto.
2009.
A comparison of model free ver-sus model intensive approaches to sentence compres-sion.
In Proceedings of EMNLP.Franz Josef Och and Hermann Ney.
2003.
A system-atic comparison of various statistical alignment mod-els.
Computational Linguistics, 29(1):19?51.Franz Och and Hermann Ney.
2004.
The alignment tem-plate approach to statistical machine translation.
Com-putational Linguistics.Franz Josef Och, Kenji Yamada, Stanford U, Alex Fraser,Daniel Gildea, and Viren Jain.
2004.
A smorgasbordof features for statistical machine translation.
In Pro-ceedings of HLT/NAACL.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
BLEU: a method for automatic eval-uation of machine translation.
In Proceedings of ACL.Emily Pitler.
2010.
Methods for sentence compression.Technical Report MS-CIS-10-20, University of Penn-sylvania.Jenine Turner and Eugene Charniak.
2005.
Supervisedand unsupervised learning for sentence compression.In Proceedings of ACL.David Vickrey and Daphne Koller.
2008.
Sentence sim-plification for semantic role labeling.
In Proceedingsof ACL.Elif Yamangil and Rani Nelken.
2008.
MiningWikipedia revision histories for improving sentencecompression.
In ACL.Mark Yatskar, Bo Pang, Critian Danescu-Niculescu-Mizil, and Lillian Lee.
2010.
For the sake of simplic-ity: Unsupervised extraction of lexical simplificationsfrom Wikipedia.
In HLT/NAACL Short Papers.669
