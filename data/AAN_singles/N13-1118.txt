Proceedings of NAACL-HLT 2013, pages 978?988,Atlanta, Georgia, 9?14 June 2013. c?2013 Association for Computational LinguisticsUnsupervised Metaphor Identification Using Hierarchical GraphFactorization ClusteringEkaterina ShutovaInternational Computer Science Institute andInstitute for Cognitive and Brain SciencesUniversity of California, Berkeleykatia@icsi.berkeley.eduLin SunComputer LaboratoryUniversity of Cambridgelin.sun@cl.cam.ac.ukAbstractWe present a novel approach to automaticmetaphor identification, that discovers bothmetaphorical associations and metaphoricalexpressions in unrestricted text.
Our sys-tem first performs hierarchical graph factor-ization clustering (HGFC) of nouns and thensearches the resulting graph for metaphoricalconnections between concepts.
It then makesuse of the salient features of the metaphori-cally connected clusters to identify the actualmetaphorical expressions.
In contrast to pre-vious work, our method is fully unsupervised.Despite this fact, it operates with an encour-aging precision (0.69) and recall (0.61).
Ourapproach is also the first one in NLP to exploitthe cognitive findings on the differences in or-ganisation of abstract and concrete concepts inthe human brain.1 IntroductionMetaphor has traditionally been viewed as a form oflinguistic creativity, that gives our expression morevividness, distinction and artistism.
While this istrue on the surface, the mechanisms of metaphorhave a much deeper origin in our reasoning.
To-day metaphor is widely understood as a cognitivephenomenon operating at the level of mental pro-cesses, whereby one concept or domain is system-atically viewed in terms of the properties of another(Lakoff and Johnson, 1980).
Consider the examples(1) ?He shot down all of my arguments?
and (2) ?Heattacked every weak point in my argument?.
Theydemonstrate a metaphorical mapping of the conceptof argument to that of war.
The argument, which isthe target concept, is viewed in terms of a battle (ora war), the source concept.
The existence of such alink allows us to systematically describe argumentsusing the war terminology, thus leading to a num-ber of metaphorical expressions.
Lakoff and John-son call such generalisations a source?target domainmapping, or conceptual metaphor.The ubiquity of metaphor in language has beenestablished in a number of corpus studies (Cameron,2003; Martin, 2006; Steen et al 2010; Shutovaand Teufel, 2010) and the role it plays in humanreasoning has been confirmed in psychological ex-periments (Thibodeau and Boroditsky, 2011).
Thismakes metaphor an important research area for com-putational and cognitive linguistics, and its auto-matic processing indispensable for any semantics-oriented NLP application.
The problem of metaphormodeling is gaining interest within NLP, with agrowing number of approaches exploiting statisti-cal techniques (Mason, 2004; Gedigian et al 2006;Shutova, 2010; Shutova et al 2010; Turney et al2011; Shutova et al 2012).
Compared to moretraditional approaches based on hand-coded knowl-edge (Fass, 1991; Martin, 1990; Narayanan, 1997;Narayanan, 1999; Feldman and Narayanan, 2004;Barnden and Lee, 2002; Agerri et al 2007), thesemore recent methods tend to have a wider cover-age, as well as be more efficient, accurate and ro-bust.
However, even the statistical metaphor pro-cessing approaches so far often focused on a lim-ited domain or a subset of phenomena (Gedigianet al 2006; Krishnakumaran and Zhu, 2007), andonly addressed one of the metaphor processing sub-tasks: identification of metaphorical mappings (Ma-son, 2004) or identification of metaphorical expres-sions (Shutova et al 2010; Turney et al 2011).
Inthis paper, we present the first computational method978that identifies the generalisations that govern theproduction of metaphorical expressions, i.e.
con-ceptual metaphors, and then uses these generalisa-tions to identify metaphorical expressions in unre-stricted text.
As opposed to previous works on sta-tistical metaphor processing that were supervised orsemi-supervised, and thus required training data, ourmethod is fully unsupervised.
It relies on building ahierarchical graph of concepts connected by their as-sociation strength (using hierarchical clustering) andthen searching for metaphorical links in this graph.Shutova et al(2010) introduced the hypothesisof ?clustering by association?
and claimed that inthe course of distributional noun clustering, abstractconcepts tend to cluster together if they are associ-ated with the same source domain, while concreteconcepts cluster by meaning similarity.
We sharethis intuition, but take this idea a significant stepfurther.
Our approach is theoretically grounded inthe cognitive science findings suggesting that ab-stract and concrete concepts are organised differ-ently in the human brain (Crutch and Warrington,2005; Binder et al 2005; Wiemer-Hastings andXu, 2005; Huang et al 2010; Crutch and Warring-ton, 2010; Adorni and Proverbio, 2012).
Accord-ing to Crutch and Warrington (2005), these differ-ences emerge from their general patterns of relationwith other concepts.
However, most NLP systemsto date treat abstract and concrete concepts as iden-tical.
In contrast, we incorporate this distinctioninto our model by creating a network (or a graph)of concepts, and automatically learning the differ-ent patterns of association of abstract and concreteconcepts with other concepts.
We expect that, whileconcrete concepts would tend to naturally organiseinto a tree-like structure (with more specific termsdescending from the more general terms), abstractconcepts would exhibit a more complex pattern ofassociations.
Consider the example in Figure 1.
Thefigure schematically shows a small portion of thegraph describing the concepts of mechanism (con-crete), political system and relationship (abstract)at two levels of generality.
One can see from thisgraph that if concrete concepts, such as bike or en-gine tend to be connected to only one concept at thehigher level in the hierarchy (mechanism), abstractconcepts may have multiple higher-level associates:the literal ones and the metaphorical ones.
For ex-ample, the abstract concept of democracy is liter-ally associated with a more general concept of po-litical system, as well as metaphorically associatedwith the concept of mechanism.
Such multiple as-sociations are due to the fact that political systemsare metaphorically viewed as mechanisms, they canfunction, break, they can be oiled etc.
We often dis-cuss them using mechanism terminology, and thus acorpus-based distributional learning approach wouldlearn that they share features with political systems(from their literal uses), as well as with mechanisms(from their metaphorical uses, as shown next to therespective graph edges in the figure).
Our systemdiscovers such association patterns within the graphand uses them to identify metaphorical connectionsbetween the concepts.To the best of our knowledge, our method is thefirst one to use a hierarchical clustering model forthe metaphor processing task.
The original graph ofconcepts is built using hierarchical graph factoriza-tion clustering (HGFC) (Yu et al 2006) of nouns,yielding a network of clusters with different levelsof generality.
The weights on the edges of the graphindicate association between the clusters (concepts).HGFC has not been previously employed for nounclustering in NLP, but showed successful results inthe verb clustering task (Sun and Korhonen, 2011).In summary, our system (1) builds a graph of con-cepts using HGFC, (2) traverses it to find metaphor-ical associations between clusters using weights onthe edges of the graph, (3) generates lists of salientfeatures for the metaphorically connected clustersand (4) searches the British National Corpus (BNC)(Burnard, 2007) for metaphorical expressions de-scribing the target domain concepts using the verbsfrom the set of salient features.
We evaluated theperformance of the system with the aid of humanjudges in precision- and recall-oriented settings.
Inaddition, we compared its performance to that of twobaselines, an unsupervised baseline using agglom-erative clustering (AGG) and a supervised baselinebuilt upon WordNet (Fellbaum, 1998) (WN).2 Method2.1 Dataset and Feature ExtractionOur noun dataset used for clustering contains 2000most frequent nouns in the BNC (Burnard, 2007).979Figure 1: Organisation of the hierarchical graph of conceptsFollowing previous semantic noun classification ex-periments (Pantel and Lin, 2002; Bergsma et al2008), we use the grammatical relations (GRs)as features for clustering.
We extracted the fea-tures from the Gigaword corpus (Graff et al2003), which was first parsed using the RASPparser (Briscoe et al 2006).
The verb lemmasin VERB?SUBJECT, VERB?DIRECT OBJECT andVERB?INDIRECT OBJECT relations with the nounsin the dataset were then extracted from the GR out-put of the parser.
The feature values were the relativefrequencies of the features.2.2 Hierarchical Graph FactorizationClusteringThe most widely used method for hierarchical wordclustering is AGG (Schulte im Walde and Brew,2001; Stevenson and Joanis, 2003; Ferrer, 2004;Devereux and Costello, 2005).
The method treatseach word as a singleton cluster and then succes-sively merges two closest clusters until all the clus-ters have been merged into one.
The cluster simi-larity is measured using linkage criteria (e.g.
Ward(1963) measures the decrease in variance for theclusters being merged).
As opposed to this, HGFCderives probabilistic bipartite graphs from the sim-ilarity matrix (Yu et al 2006).
Since we require agraph of concepts, our task is rather different fromstandard hierarchical word clustering that producesa tree of concepts.
In a tree, each word can onlyhave a unique parent cluster at each level.
Our con-cept graph does not have this constraint: at any levela word can be associated with an arbitrary numberof parent clusters.
Therefore, not only HGFC out-performed agglomerative clustering methods in hi-erarchical clustering tasks (Yu et al 2006; Sun andKorhonen, 2011), but its hierarchical graph outputis also a more suitable representation of the conceptgraph.
In addition, HGFC can detect the number oflevels and the number of clusters on each level ofthe hierarchical graph automatically.
This is essen-tial for our task as these settings are difficult to pre-define for a general-purpose concept graph.Given a set of nouns, V = {vn}Nn=1, the similar-ity matrix W for HGFC is constructed using Jensen-Shannon Divergence.
W can be encoded by an undi-rected graph G (Figure 2(a)), where the nouns aremapped to vertices and Wij is the edge weight be-tween vertices i and j.
The graph G and the clus-ter structure can be represented by a bipartite graphK(V,U).
V are the vertices on G. U = {up}mp=1represent the hidden m clusters.
For example, look-ing at Figure 2(b), V on G can be grouped into threeclusters u1, u2 and u3.
The matrix B denotes then?m adjacency matrix, with bip being the connec-tion weight between the vertex vi and the cluster up.Thus, B represents the connections between clus-ters at an upper and lower level of clustering.
Aflat clustering algorithm can be induced by assign-ing a lower level node to the parent node that has thelargest connection weight.
The number of clustersat any level can be determined by only counting thenumber of non-empty nodes (namely the nodes thathave at least one lower level node associated).The bipartite graph K also induces a similarity(W ?)
between vi and vj : w?ij =?mp=1bipbjp?p=(B?
?1BT )ij where ?
= diag(?1, ..., ?m).
There-fore, B can be found by minimizing the divergencedistance (?)
between the similarity matrices W andW ?
:980v1v6v2v4v3v5v7 v8v9(a)v1v7v6v9v8v2v3v4v5u1u2u3(b)u3u1u2v1v6v2v4v3v5v7 v8v9(c)u1 u2u3(d)v1v7v6v9v8v2v3v4v5u1u2u3q1q2(e)Figure 2: (a) An undirected graph G representing the similarity matrix; (b) The bipartite graph showing three clusterson G; (c) The induced clusters U ; (d) The new graph G1 over clusters U ; (e) The new bipartite graph over G1minH,??
(W,H?HT ), s.t.n?i=1hip = 1 (1)H = B?
?1; ?
(X,Y ) =?ij(xij logxijyij?
xij + yij)Yu et al(2006) showed that this cost function isnon-increasing under the update rule:h?ip ?
hip?jwij(H?HT )ij?phjp s.t.
?ih?ip = 1 (2)?
?p ?
?p?jwij(H?HT )ijhiphjp s.t.?p?
?p =?ijwij (3)The cost function can thus be optimized by updatingh and ?
alternately.The similarity between clusters p(up, uq) can beinduced from B, as follows:p(up, uq) = p(up)p(up|uq) = (BTD?1B)pq (4)D = diag(d1, ..., dn) where di =m?p=0bipWe can then construct a new graph G1 (Figure2(d)) with the clusters U as vertices, and the clus-ter similarity p as the connection weight.
The clus-tering algorithm can now be applied again (Figure2(e)).
This process can go on iteratively, leading toa hierarchical graph.The number of levels (L) and the number ofclusters (ml) are detected automatically, using themethod of Sun and Korhonen (2011).
Clusteringstarts with an initial setting of number of clusters(m0) for the first level.
In our experiment, we set thevalue of m0 to 800.
For the subsequent levels, mlis set to the number of non-empty clusters (bipartitegraph nodes) on the parent level.
The matrices Band ?
are initialized randomly.
We found that theactual initialization values have little impact on thefinal result.
The rows in B are normalized after theinitialization so the values in each row add up to one.For a word vi, the probability of assigning it to clus-ter x(l)p ?
Xl at level l is given by:p(x(l)p |vi) =?Xl?1...?x(1)?X1p(x(l)p |x(l?1))...p(x(1)|vi)= (D(?1)1 B1D?12 B2...D?1l Bl)ip (5)Due to the random walk property of the graph, mlis non-increasing for higher levels (Sun and Korho-nen, 2011).
The algorithm can thus terminate whenall nouns are assigned to one cluster.
We run 1000iterations of updates of h and ?
(equation 2 and 3)for each two adjacent levels.The resulting graph is composed of a set of bipar-tite graphs defined by Bl, Bl?1, ..., B1.
A bipartitegraph has a similar structure as in Figure 1.
For agiven noun, we can rank the clusters at any level ac-cording to the soft assignment probability (eq.
5).The clusters that have no member noun were hiddenfrom the ranking since they do not explicitly repre-sent any concept.
However, these clusters are stillpart of the organisation of conceptual space withinthe model and they contribute to the probability forthe clusters on upper levels (eq.
5).
We call the viewof the hierarchical graph where these empty clusters981are hidden an explicit graph.
The whole algorithmcan be summarized as follows:Require: N nouns V , initial number of clusters m1Compute the similarity matrix W0 from VBuild the graph G0 from W0, l?
1while ml > 1 doFactorizeGl?1 to obtain bipartite graph Kl with theadjacency matrix Bl (eq.
1, 2 and 3)Build a graph Gl with similarity matrix Wl =BTl D?1l Bl according to equation 4l?
l + 1 ; ml ?
No.
non-empty clusters (eq.
5)end whilereturn Bl, Bl?1...B12.3 Identification of Metaphorical AssociationsOnce we obtained the explicit graph of concepts, wecan now identify metaphorical associations based onthe weights connecting the clusters at different levels(eq.
5).
Taking a single noun (e.g.
fire) as input, thesystem computes the probability of its cluster mem-bership for each cluster at each level, using theseweights.
We expect the cluster membership prob-abilities to indicate the level of association of theinput noun with the clusters.
The system can thenrank the clusters at each level based on these prob-abilities.
We chose level 3 as the optimal level ofgenerality for our experiments, based on our qualita-tive analysis of the graph.
The system selects 6 top-ranked clusters from this level (we expect an averagesource concept to have no more than 5 typical tar-get associates) and excludes the literal cluster con-taining the input concept (e.g.
?fire flame blaze?
).The remaining clusters represent the target conceptsassociated with the input source concept.
Exampleoutput for the input concepts of fire and disease isshown in Figure 3.
One can see from the Figurethat each of the noun-to-cluster mappings representsa new conceptual metaphor, e.g.
EMOTION is FIRE,VIOLENCE is FIRE, CRIME is a DISEASE etc.
Thesemappings are exemplified in language by a numberof metaphorical expressions (e.g.
?His anger willburn him?, ?violence flared again?, ?it?s time theyfound a cure for corruption?
).2.4 Identification of Salient Features andMetaphorical ExpressionsAfter extracting the source?target domain mappings,we now move on to the identification of the cor-SOURCE: fireTARGET 1: sense hatred emotion passion enthusiasmsentiment hope interest feeling resentment optimismhostility excitement angerTARGET 2: coup violence fight resistance clash rebel-lion battle drive fighting riot revolt war confrontationvolcano row revolution struggleTARGET 3: alien immigrantTARGET 4: prisoner hostage inmateSOURCE: diseaseTARGET 1: fraud outbreak offense connection leakcount crime violation abuse conspiracy corruption ter-rorism suicideTARGET 2: opponent critic rivalTARGET 3: execution destruction signingTARGET 4: refusal absence fact failure lack delayFigure 3: Discovered metaphorical associationsrage-ncsubj engulf -ncsubj erupt-ncsubj burn-ncsubjlight-dobj consume-ncsubj flare-ncsubj sweep-ncsubjspark-dobj battle-dobj gut-idobj smolder-ncsubj ig-nite-dobj destroy-idobj spread-ncsubj damage-idobjlight-ncsubj ravage-ncsubj crackle-ncsubj open-dobjfuel-dobj spray-idobj roar-ncsubj perish-idobj destroy-ncsubj wound-idobj start-dobj ignite-ncsubj injure-idobj fight-dobj rock-ncsubj retaliate-idobj devastate-idobj blaze-ncsubj ravage-idobj rip-ncsubj burn-idobjspark-ncsubj warm-idobj suppress-dobj rekindle-dobjFigure 4: Salient features for fire and the violence clusterresponding metaphorical expressions.
The systemdoes this by harvesting the salient features that leadto the input noun being strongly associated with theextracted clusters.
The salient features are selectedby ranking the features according to the joint prob-ability of the feature (f ) occurring both with the in-put noun (w) and the cluster (c).
Under a simplifiedindependence assumption, p(w, c|f) = p(w|f) ?p(c|f).
p(w|f) and p(c|f) are calculated as the ra-tio of the frequency of the feature f to the totalfrequency of the input noun and the cluster respec-tively.
The features ranked higher are expected torepresent the source domain vocabulary that can beused to metaphorically describe the target concepts.We selected the top 50 features from the ranked list.Example features (verbs and their grammatical rela-tions) extracted for the source domain noun fire andthe violence cluster are shown in Figure 4.We then refined the lists of features by means ofselectional preference (SP) filtering.
We use SPs to982FEELING IS FIREhope lit (Subj), anger blazed (Subj), optimism raged(Subj), enthusiasm engulfed them (Subj), hatred flared(Subj), passion flared (Subj), interest lit (Subj), fuel re-sentment (Dobj), anger crackled (Subj), feelings roared(Subj), hostility blazed (Subj), light with hope (Iobj)CRIME IS A DISEASEcure crime (Dobj), abuse transmitted (Subj), eradicateterrorism (Dobj), suffer from corruption (Iobj), diag-nose abuse (Dobj), combat fraud (Dobj), cope withcrime (Iobj), cure abuse (Dobj), eradicate corruptionFigure 5: Identified metaphorical expressions for themappings FEELING IS FIRE and CRIME IS A DISEASEquantify how well the extracted features describe thesource domain (e.g.
fire).
We extracted nominal ar-gument distributions of the verbs in our feature listsfor VERB?SUBJECT, VERB?DIRECT OBJECT andVERB?INDIRECT OBJECT relations.
We used the al-gorithm of Sun and Korhonen (2009) to create SPclasses and the measure of Resnik (1993) to quantifyhow well a particular argument class fits the verb.Resnik measures selectional preference strengthSR(v) of a predicate as a Kullback-Leibler distancebetween two distributions: the prior probability ofthe noun class P (c) and the posterior probabilityof the noun class given the verb P (c|v).
SR(v) =D(P (c|v)||P (c)) =?c P (c|v) logP (c|v)P (c) .
In orderto quantify how well a particular argument class fitsthe verb, Resnik defines selectional association asAR(v, c) = 1SR(v)P (c|v) logP (c|v)P (c) .
We rank thenominal arguments of the verbs in our feature listsusing their selectional association with the verb, andthen only retain the features whose top 5 argumentscontain the source concept.
For example, the verbstart, that is a common feature for both fire and theviolence cluster (e.g.
?start a war?, ?start a fire?
),would be filtered out in this way, whereas the verbsflare or blaze would be retained as descriptive sourcedomain vocabulary.We then search the RASP-parsed BNC for gram-matical relations, in which the nouns from the targetdomain cluster appear with the verbs from the sourcedomain vocabulary (e.g.
?war blazed?
(subj), ?tofuel violence?
(dobj) for the mapping VIOLENCE isFIRE).
The system thus annotates metaphorical ex-pressions in text, as well as the corresponding con-ceptual metaphors, as shown in Figure 5.3 Evaluation and Discussion3.1 BaselinesAGG: the agglomerative clustering baseline isconstructed using SciPy implementation (Oliphant,2007) of Ward?s linkage method (Ward, 1963).
Theoutput tree is cut according to the number of lev-els and the number of clusters of the explicit graphdetected by HGFC.
The resulting tree is convertedinto a graph by adding connections from each clus-ter to all the clusters one level above.
The connec-tion weight (the cluster distance) is measured us-ing Jensen-Shannon Divergence between the clustercentroids.
This graph is used in place of the HGFCgraph in the metaphor identification experiments.WN: in the WN baseline, the WordNet hierarchy isused as the underlying graph of concepts, to whichthe metaphor extraction method is applied.
Givena source concept, the system extracts all its sense-1 hypernyms two levels above and subsequently allof their sister terms.
The hypernyms themselves areconsidered to represent the literal sense of the sourcenoun and are, therefore, removed.
The sister termsare kept as potential target domains.3.2 Evaluation of Metaphorical AssociationsTo create our dataset, we extracted 10 commonsource concepts that map to multiple targets fromthe Master Metaphor List (Lakoff et al 1991) andlinguistic analyses of metaphor (Lakoff and John-son, 1980; Shutova and Teufel, 2010).
Theseincluded FIRE, CHILD, SPEED, WAR, DISEASE,BREAKDOWN, CONSTRUCTION, VEHICLE, SYS-TEM, BUSINESS.
Each of the three systems identi-fied 50 source?target domain mappings for the givensource domains, resulting in a set of 150 conceptualmetaphors (each representing a number of submap-pings since all the target concepts are clusters orsynsets).
These were then evaluated against humanjudgements in two different experimental settings.Setting 1: The judges were presented with a setof conceptual metaphors identified by the three sys-tems, randomized.
They were asked to annotate themappings they considered valid.
In all our experi-ments, the judges were encouraged to rely on theirown intuition of metaphor, but they also reviewedthe metaphor annotation guidelines of Shutova andTeufel (2010).
Two independent judges, both na-983tive speakers of English, participated in this exper-iment.
Their agreement on the task was ?
= 0.60(n = 2, N = 150, k = 2) (Siegel and Castel-lan, 1988).
The main differences in the annotators?judgements stem from the fact that some metaphor-ical associations are less obvious and common thanothers, and thus need more context (or imaginativeeffort) to establish.
Such examples, where the judgesdisagreed included metaphorical mappings such asINTENSITY is SPEED, GOAL is a CHILD, COLLEC-TION is a SYSTEM, ILLNESS is a BREAKDOWN.The system performance was then evaluatedagainst these judgements in terms of precision (P ),i.e.
the proportion of the valid metaphorical map-pings among those identified.
We calculated sys-tem precision (in all experiments) as an average overboth annotations.
HGFC operates with a precision ofP = 0.69, whereas the baselines attain P = 0.36(AGG) and P = 0.29 (WN).
The precision of an-notator judgements against each other (the humanceiling) is P = 0.80, suggesting that this is a chal-lenging task.Setting 2: To measure recall, R, of the systems weasked two annotators (both native speakers with abackground in metaphor, different from Setting 1)to write down up to 5 target concepts they stronglyassociated with each of the 10 source concepts.Their annotations were then aggregated into a sin-gle metaphor association gold standard, consistingof 63 mappings in total.
The recall of the systemswas measured against this gold standard, resulting inHGFC R = 0.61, AGG R = 0.11 and WN R = 0.03.As expected, HGFC outperforms both AGG andWN baselines in both settings.
AGG has been pre-viously shown to be less accurate than HGFC in theverb clustering task (Sun and Korhonen, 2011).
Ouranalysis of the noun clusters indicated that HGFCtends to produce more pure and complete clustersthan AGG.
Another important reason AGG fails isthat it by definition organises all concepts into treeand optimises its solution locally, taking into ac-count a small number of clusters at a time.
How-ever, being able to discover connections betweenmore distant domains and optimising globally overall concepts is crucial for metaphor identification.This makes AGG less suitable for the task, as demon-strated by our results.
However, AGG identified anumber of interesting mappings missed by HGFC,e.g.
CAREER IS A CHILD, LANGUAGE IS A SYS-TEM, CORRUPTION IS A VEHICLE, EMPIRE IS ACONSTRUCTION, as well as a number of mappingsin common with HGFC, e.g.
DEBATE IS A WAR, DE-STRUCTION IS A DISEASE.
The WN system alsoidentified a few interesting metaphorical mappings(e.g.
COGNITION IS FIRE, EDUCATION IS CON-STRUCTION), but its output is largely dominated bythe concepts similar to the source noun and containssome unrelated concepts.
The comparison of HGFCto WN shows that HGFC identifies meaningful prop-erties and relations of abstract concepts that can notbe captured in a tree-like classification (even an ac-curate, manually created one).
The latter is more ap-propriate for concrete concepts, and a more flexiblerepresentation is needed to model abstract concepts.The fact that both baselines identified some validmetaphorical associations, relying on less suitableconceptual graphs, suggests that our way of travers-ing the graph is a viable approach in principle.HGFC identifies valid metaphorical associationsfor a range of source concepts.
On of them (CRIMEIS A VIRUS) happened to have been already vali-dated in psychological experiments (Thibodeau andBoroditsky, 2011).
The most frequent type of errorof HGFC is the presence of target clusters similar orclosely related to the source noun (e.g.
the parentcluster for child).
The clusters from the same do-main can, however, be filtered out if their nouns fre-quently occur in the same documents with the sourcenoun (in a large corpus), i.e.
by topical similarity.The latter is less likely for the metaphorically con-nected nouns.
We intend to implement this improve-ment in the future version of the system.3.3 Evaluation of Metaphorical ExpressionsFor each of the identified conceptual metaphors, thethree systems extracted a number of metaphoricalexpressions from the corpus (average of 430 forHGFC, 148 for AGG, and 855 for WN).
The ex-pressions were also evaluated against human judge-ments.
The judges were presented with a set of ran-domly sampled sentences containing metaphoricalexpressions as annotated by the system and by thebaselines (200 each), randomized.
They were askedto mark the tagged expressions that were metaphor-ical in their judgement as correct.
Their agreementon the task was ?
= 0.56 (n = 2, N = 600, k = 2),984HLJ 26 [..] ?effective action?
was needed to eradicateterrorism, drug-trafficking and corruption.EG0 275 In the 1930s the words ?means test?
was acurse, fuelling the resistance against it both among theunemployed and some of its administrators.CRX 1054 [..] if the rehabilitative approach weredemonstrably successful in curing crime.HL3 1206 [..] he would strive to accelerate progresstowards the economic integration of the Caribbean.HXJ 121 [..] it is likely that some industries will flour-ish in certain countries as the market widens.Figure 6: Metaphors tagged by the system (in bold)whereby the main source of disagreement was thepresence of lexicalized metaphors, e.g.
verbs suchas impose, decline etc.
The system performanceagainst these annotations is P = 0.65 (HGFC), P =0.47 (AGG) and P = 0.12 (WN).
The human ceilingfor this task was measured at P = 0.79.
Figure 6shows example sentences annotated by HGFC.
Theperformance of our unsupervised approach is closeto the previous supervised systems of Mason (2004)(accuracy of 0.73) and Shutova et al(2010) (preci-sion of 0.79), however, the results are not directlycomparable due to different experimental settings.The system errors in this task stem from multipleword senses of the salient features or the source andtarget sharing some physical properties (e.g.
one can?die from crime?
and ?die from a disease?).
Someidentified expressions invoke a chain of mappings(e.g.
ABUSE IS A DISEASE, DISEASE IS AN ENEMYfor ?combat abuse?
), however, such chains are notyet incorporated into the system.
The performanceof AGG is higher than in the mappings identificationtask, since it outputs only few expressions for theincorrect mappings.
In contrast, WN tagged a largenumber of literal expressions due to the incorrectprior identification of the underlying associations.Since there is no large metaphor-annotated corpusavailable, it was impossible for us to reliably evalu-ate the recall of metaphorical expressions.
However,we estimated it as a recall of salient features.
Wemanually compiled sets of typical features for the10 source domains, and measured their recall amongthe top 50 HGFC features at R = 0.70.
However, inpractice the coverage in this task would directly de-pend on that of the metaphorical associations.4 Related WorkOne of the first attempts to identify and interpretmetaphorical expressions in text is the met* sys-tem of Fass (1991), that utilizes hand-coded knowl-edge and detects non-literalness via selectional pref-erence violation.
In case of a violation, the re-spective phrase is first tested for being metonymicusing hand-coded patterns (e.g.
CONTAINER-FOR-CONTENT).
If this fails, the system searches theknowledge base for a relevant analogy in order todiscriminate metaphorical relations from anomalousones.
The system of Krishnakumaran and Zhu(2007) uses WordNet (the hyponymy relation) andword bigram counts to predict verbal, nominal andadjectival metaphors at the sentence level.
The au-thors discriminate between conventional metaphors(included in WordNet) and novel metaphors.
Birkeand Sarkar (2006) present a sentence clustering ap-proach that employs a set of seed sentences an-notated for literalness and computes similarity be-tween the new input sentence and all of the seed sen-tences.
The system then tags the sentence as literalor metaphorical according to the annotation in themost similar seeds, attaining an f-score of 53.8%.The first system to discover source?target domainmappings automatically is CorMet (Mason, 2004).It does this by searching for systematic variationsin domain-specific verb selectional preferences.
Forexample, pour is a characteristic verb in both LABand FINANCE domains.
In the LAB domain it hasa strong preference for liquids and in the FINANCEdomain for money.
From this the system infers thedomain mapping FINANCE ?
LAB and the conceptmapping money ?
liquid.
Gedigian et al(2006)trained a maximum entropy classifier to discrimi-nate between literal and metaphorical use.
Theyannotated the sentences from PropBank (Kingsburyand Palmer, 2002) containing the verbs of MOTIONand CURE for metaphoricity.
They used PropBankannotation (arguments and their semantic types) asfeatures for classification and report an accuracyof 95.12% (however, against a majority baseline of92.90%).
The metaphor identification system ofShutova et al(2010) starts from a small seed setof metaphorical expressions, learns the analogies in-volved in their production and extends the set ofanalogies by means of verb and noun clustering.
As985a result, the system can recognize new metaphoricalexpressions in unrestricted text (e.g.
from the seed?stir excitement?
it infers that ?swallow anger?
isalso a metaphor), achieving a precision of 79%.Turney et al(2011) classify verbs and adjectivesas literal or metaphorical based on their level of con-creteness or abstractness in relation to a noun theyappear with.
They learn concreteness rankings forwords automatically (starting from a set of exam-ples) and then search for expressions where a con-crete adjective or verb is used with an abstract noun(e.g.
?dark humour?
is tagged as a metaphor and?dark hair?
is not).
They report an accuracy of 73%.5 Conclusions and Future DirectionsPrevious research on metaphor addressed a num-ber of different aspects of the phenomenon, and hasshown that these aspects can be successfully mod-eled using statistical techniques.
However, the meth-ods often focused on a limited domain and neededmanually-labeled training data.
This made them dif-ficult to apply in a real-world setting with the goal ofimproving semantic interpretation in NLP at large.Our method takes a step towards this direction.
It isfully unsupervised, and thus more robust, and canperform accurate metaphor identification in unre-stricted text.
It identifies metaphor with a precisionof 69% and a recall of 61%, which is a very encour-aging result for an unsupervised method.
We be-lieve that this work has important implications forcomputational and cognitive modeling of metaphor,but is also applicable to a range of other seman-tic tasks within NLP.
Integrating different represen-tations of abstract and concrete concepts into NLPsystems may improve their performance, as well asmake the models more cognitively plausible.One of our key future research objectives is to in-vestigate the use and adaptation of the created con-ceptual graph to perform metaphor interpretation.
Inaddition, we plan to extend this work to cover nom-inal and adjectival metaphors, by harvesting salientnominal and adjectival features.AcknowledgmentsThis work was funded by the MetaNet project (grantnumber W911NF-12-C-0022) and the DorothyHodgkin Postgraduate Award.ReferencesRoberta Adorni and Alice Mado Proverbio.
2012.
Theneural manifestation of the word concreteness effect:An electrical neuroimaging study.
Neuropsychologia,50(5):880 ?
891.Rodrigo Agerri, John Barnden, Mark Lee, and AlanWallington.
2007.
Metaphor, inference and domain-independent mappings.
In Proceedings of RANLP-2007, pages 17?23, Borovets, Bulgaria.John Barnden and Mark Lee.
2002.
An artificial intel-ligence approach to metaphor understanding.
Theoriaet Historia Scientiarum, 6(1):399?412.Shane Bergsma, Dekang Lin, and Randy Goebel.
2008.Discriminative learning of selectional preference fromunlabeled text.
In Proceedings of the Conference onEmpirical Methods in Natural Language Processing,EMNLP ?08, pages 59?68, Honolulu, Hawaii.Jeffrey R. Binder, Chris F. Westbury, Kristen A. McKier-nan, Edward T. Possing, and David A. Medler.
2005.Distinct brain systems for processing concrete and ab-stract concepts.
Journal of Cognitive Neuroscience,17(6):905?917.Julia Birke and Anoop Sarkar.
2006.
A clustering ap-proach for the nearly unsupervised recognition of non-literal language.
In In Proceedings of EACL-06, pages329?336.Ted Briscoe, John Carroll, and Rebecca Watson.
2006.The second release of the rasp system.
In Proceed-ings of the COLING/ACL on Interactive presentationsessions.Lou Burnard.
2007.
Reference Guide for the British Na-tional Corpus (XML Edition).Lynne Cameron.
2003.
Metaphor in Educational Dis-course.
Continuum, London.Sebastian J. Crutch and Elizabeth K. Warrington.2005.
Abstract and concrete concepts have struc-turally different representational frameworks.
Brain,128(3):615?627.Sebastian J Crutch and Elizabeth K Warrington.
2010.The differential dependence of abstract and concretewords upon associative and similarity-based informa-tion: Complementary semantic interference and facil-itation effects.
Cognitive Neuropsychology, 27(1):46?71.Barry Devereux and Fintan Costello.
2005.
Propanestoves and gas lamps: How the concept hierarchy in-fluences the interpretation of noun-noun compounds.In Proceedings of the Twenty-Seventh Annual Confer-ence of the Cognitive Science Society.Dan Fass.
1991. met*: A method for discriminatingmetonymy and metaphor by computer.
ComputationalLinguistics, 17(1):49?90.986Jerome Feldman and Srini Narayanan.
2004.
Embodiedmeaning in a neural theory of language.
Brain andLanguage, 89(2):385?392.Christiane Fellbaum, editor.
1998.
WordNet: An Elec-tronic Lexical Database (ISBN: 0-262-06197-X).
MITPress, first edition.Eva E. Ferrer.
2004.
Towards a semantic classification ofspanish verbs based on subcategorisation information.In Proceedings of the ACL 2004 workshop on Studentresearch, page 13.
Association for Computational Lin-guistics.Matt Gedigian, John Bryant, Srini Narayanan, and Bran-imir Ciric.
2006.
Catching metaphors.
In In Proceed-ings of the 3rd Workshop on Scalable Natural Lan-guage Understanding, pages 41?48, New York.David Graff, Junbo Kong, Ke Chen, and Kazuaki Maeda.2003.
English gigaword.
Linguistic Data Consortium,Philadelphia.Hsu-Wen Huang, Chia-Lin Lee, and Kara D. Federmeier.2010.
Imagine that!
erps provide evidence for distincthemispheric contributions to the processing of con-crete and abstract concepts.
NeuroImage, 49(1):1116?
1123.Paul Kingsbury and Martha Palmer.
2002.
FromTreeBank to PropBank.
In Proceedings of LREC-2002, pages 1989?1993, Gran Canaria, Canary Is-lands, Spain.Saisuresh Krishnakumaran and Xiaojin Zhu.
2007.Hunting elusive metaphors using lexical resources.In Proceedings of the Workshop on ComputationalApproaches to Figurative Language, pages 13?20,Rochester, NY.George Lakoff and Mark Johnson.
1980.
Metaphors WeLive By.
University of Chicago Press, Chicago.George Lakoff, Jane Espenson, and Alan Schwartz.1991.
The master metaphor list.
Technical report,University of California at Berkeley.James Martin.
1990.
A Computational Model ofMetaphor Interpretation.
Academic Press Profes-sional, Inc., San Diego, CA, USA.James Martin.
2006.
A corpus-based analysis of con-text effects on metaphor comprehension.
In A. Ste-fanowitsch and S. T. Gries, editors, Corpus-Based Ap-proaches to Metaphor and Metonymy, Berlin.
Moutonde Gruyter.Zachary Mason.
2004.
Cormet: a computational,corpus-based conventional metaphor extraction sys-tem.
Computational Linguistics, 30(1):23?44.Srini Narayanan.
1997.
Knowledge-based Action Repre-sentations for Metaphor and Aspect (KARMA).
Tech-nical report, PhD thesis, University of California atBerkeley.Srini Narayanan.
1999.
Moving right along: A compu-tational model of metaphoric reasoning about events.In Proceedings of AAAI 99), pages 121?128, Orlando,Florida.Travis E. Oliphant.
2007.
Python for scientific comput-ing.
Computing in Science and Engineering, 9:10?20.Patrick Pantel and Dekang Lin.
2002.
Discovering wordsenses from text.
In Proceedings of the eighth ACMSIGKDD international conference on Knowledge dis-covery and data mining, pages 613?619.
ACM.Philip Resnik.
1993.
Selection and Information: AClass-based Approach to Lexical Relationships.
Ph.D.thesis, Philadelphia, PA, USA.Sabine Schulte im Walde and Chris Brew.
2001.
Induc-ing German semantic verb classes from purely syntac-tic subcategorisation information.
In ACL ?02: Pro-ceedings of the 40th Annual Meeting on Associationfor Computational Linguistics, pages 223?230, Mor-ristown, NJ, USA.
Association for Computational Lin-guistics.Ekaterina Shutova and Simone Teufel.
2010.
Metaphorcorpus annotated for source - target domain map-pings.
In Proceedings of LREC 2010, pages 3255?3261, Malta.Ekaterina Shutova, Lin Sun, and Anna Korhonen.
2010.Metaphor identification using verb and noun cluster-ing.
In Proceedings of Coling 2010, pages 1002?1010,Beijing, China.Ekaterina Shutova, Simone Teufel, and Anna Korhonen.2012.
Statistical Metaphor Processing.
Computa-tional Linguistics, 39(2).Ekaterina Shutova.
2010.
Automatic metaphor inter-pretation as a paraphrasing task.
In Proceedings ofNAACL 2010, pages 1029?1037, Los Angeles, USA.Sidney Siegel and N. John Castellan.
1988.
Nonpara-metric statistics for the behavioral sciences.
McGraw-Hill Book Company, New York, USA.Gerard J. Steen, Aletta G. Dorst, J. Berenike Herrmann,Anna A. Kaal, Tina Krennmayr, and Trijntje Pasma.2010.
A method for linguistic metaphor identifica-tion: From MIP to MIPVU.
John Benjamins, Ams-terdam/Philadelphia.Suzanne Stevenson and Eric Joanis.
2003.
Semi-supervised verb class discovery using noisy features.In Proceedings of HLT-NAACL 2003, pages 71?78.Lin Sun and Anna Korhonen.
2009.
Improvingverb clustering with automatically acquired selectionalpreferences.
In Proceedings of EMNLP 2009, pages638?647, Singapore, August.Lin Sun and Anna Korhonen.
2011.
Hierarchical verbclustering using graph factorization.
In Proceedingsof EMNLP, pages 1023?1033, Edinburgh, UK.987Paul H. Thibodeau and Lera Boroditsky.
2011.Metaphors we think with: The role of metaphor in rea-soning.
PLoS ONE, 6(2):e16782, 02.Peter D. Turney, Yair Neuman, Dan Assaf, and YohaiCohen.
2011.
Literal and metaphorical sense iden-tification through concrete and abstract context.
InProceedings of the Conference on Empirical Meth-ods in Natural Language Processing, EMNLP ?11,pages 680?690, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.Joe H. Ward.
1963.
Hierarchical grouping to optimize anobjective function.
Journal of the American statisticalassociation, 58(301):236?244.Katja Wiemer-Hastings and Xu Xu.
2005.
Content Dif-ferences for Abstract and Concrete Concepts.
Cogni-tive Science, 29(5):719?736.Kai Yu, Shipeng Yu, and Volker Tresp.
2006.
Softclustering on graphs.
Advances in Neural InformationProcessing Systems, 18.988
