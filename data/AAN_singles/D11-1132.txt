Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1426?1436,Edinburgh, Scotland, UK, July 27?31, 2011. c?2011 Association for Computational LinguisticsRelation Extraction with Relation TopicsChang Wang James Fan Aditya Kalyanpur David GondekIBM T. J. Watson Research Lab19 Skyline Drive, Hawthorne, New York 10532{wangchan, fanj, adityakal, dgondek}@us.ibm.comAbstractThis paper describes a novel approach to thesemantic relation detection problem.
Insteadof relying only on the training instances fora new relation, we leverage the knowledgelearned from previously trained relation detec-tors.
Specifically, we detect a new semanticrelation by projecting the new relation?s train-ing instances onto a lower dimension topicspace constructed from existing relation de-tectors through a three step process.
First, weconstruct a large relation repository of morethan 7,000 relations from Wikipedia.
Second,we construct a set of non-redundant relationtopics defined at multiple scales from the re-lation repository to characterize the existingrelations.
Similar to the topics defined overwords, each relation topic is an interpretablemultinomial distribution over the existing re-lations.
Third, we integrate the relation topicsin a kernel function, and use it together withSVM to construct detectors for new relations.The experimental results on Wikipedia andACE data have confirmed that background-knowledge-based topics generated from theWikipedia relation repository can significantlyimprove the performance over the state-of-the-art relation detection approaches.1 IntroductionDetecting semantic relations in text is very usefulin both information retrieval and question answer-ing because it enables knowledge bases to be lever-aged to score passages and retrieve candidate an-swers.
To extract semantic relations from text, threetypes of approaches have been applied.
Rule-basedmethods (Miller et al, 2000) employ a number oflinguistic rules to capture relation patterns.
Feature-based methods (Kambhatla, 2004; Zhao and Grish-man, 2005) transform relation instances into a largeamount of linguistic features like lexical, syntacticand semantic features, and capture the similarity be-tween these feature vectors.
Recent results mainlyrely on kernel-based approaches.
Many of them fo-cus on using tree kernels to learn parse tree struc-ture related features (Collins and Duffy, 2001; Cu-lotta and Sorensen, 2004; Bunescu and Mooney,2005).
Other researchers study how different ap-proaches can be combined to improve the extractionperformance.
For example, by combining tree ker-nels and convolution string kernels, (Zhang et al,2006) achieved the state of the art performance onACE (ACE, 2004), which is a benchmark dataset forrelation extraction.Although a large set of relations have been iden-tified, adapting the knowledge extracted from theserelations for new semantic relations is still a chal-lenging task.
Most of the work on domain adapta-tion of relation detection has focused on how to cre-ate detectors from ground up with as little trainingdata as possible through techniques such as boot-strapping (Etzioni et al, 2005).
We take a differ-ent approach, focusing on how the knowledge ex-tracted from the existing relations can be reused tohelp build detectors for new relations.
We believe byreusing knowledge one can build a more cost effec-tive relation detector, but there are several challengesassociated with reusing knowledge.The first challenge to address in this approach ishow to construct a relation repository that has suffi-1426cient coverage.
In this paper, we introduce a methodthat automatically extracts the knowledge charac-terizing more than 7,000 relations from Wikipedia.Wikipedia is comprehensive, containing a diversebody of content with significant depth and growsrapidly.
Wikipedia?s infoboxes are particularly in-teresting for relation extraction.
They are short,manually-created, and often have a relational sum-mary of an article: a set of attribute/value pairs de-scribing the article?s subject.Another challenge is how to deal with overlap ofrelations in the repository.
For example, Wikipediaauthors may make up a name when a new relationis needed without checking if a similar relation hasalready been created.
This leads to relation duplica-tion.
We refine the relation repository based on anunsupervised multiscale analysis of the correlationsbetween existing relations.
This method is parame-ter free, and able to produce a set of non-redundantrelation topics defined at multiple scales.
Similar tothe topics defined over words (Blei et al, 2003), wedefine relation topics as multinomial distributionsover the existing relations.
The relation topics ex-tracted in our approach are interpretable, orthonor-mal to each other, and can be used as basis relationsto re-represent the new relation instances.The third challenge is how to use the relation top-ics for a relation detector.
We map relation instancesin the new domains to the relation topic space, re-sulting in a set of new features characterizing therelationship between the relation instances and ex-isting relations.
By doing so, background knowl-edge from the existing relations can be introducedinto the new relations, which overcomes the limi-tations of the existing approaches when the trainingdata is not sufficient.
Our work fits in to a class of re-lation extraction research based on ?distant supervi-sion?, which studies how knowledge and resourcesexternal to the target domain can be used to im-prove relation extraction.
(Mintz et al, 2009; Jiang,2009; Chan and Roth, 2010).
One distinction be-tween our approach and other existing approaches isthat we represent the knowledge from distant super-vision using automatically constructed topics.
Whenwe test on new instances, we do not need to searchagainst the knowledge base.
In addition, our top-ics also model the indirect relationship between re-lations.
Such information cannot be directly foundfrom the knowledge base.The contributions of this paper are three-fold.Firstly, we extract a large amount of trainingdata for more than 7,000 semantic relations fromWikipedia (Wikipedia, 2011) and DBpedia (Aueret al, 2007).
A key part of this step is how wehandle noisy data with little human effort.
Sec-ondly, we present an unsupervised way to con-struct a set of relation topics at multiple scales.This step is parameter free, and results in a non-redundant, multiscale relation topic space.
Thirdly,we design a new kernel for relation detection byintegrating the relation topics into the relation de-tector construction.
The experimental results onWikipedia and ACE data (ACE, 2004) have con-firmed that background-knowledge-based featuresgenerated from the Wikipedia relation repositorycan significantly improve the performance over thestate-of-the-art relation detection approaches.2 Extracting Relations from WikipediaOur training data is from two parts: relation in-stances from DBpedia (extracted from Wikipediainfoboxes), and sentences describing the relationsfrom the corresponding Wikipedia pages.2.1 Collecting the Training DataSince our relations correspond to Wikipedia infoboxproperties, we use an approach similar to that de-scribed in (Hoffmann et al, 2010) to collect positivetraining data instances.
We assume that a Wikipediapage containing a particular infobox property islikely to express the same relation in the text ofthe page.
We further assume that the relation ismost likely expressed in the first sentence on thepage which mentions the arguments of the relation.For example, the Wikipedia page for ?Albert Ein-stein?
contains an infobox property ?alma mater?with value ?University of Zurich?, and the first sen-tence mentioning the arguments is the following:?Einstein was awarded a PhD by the University ofZurich?, which expresses the relation.
When look-ing for relation arguments on the page, we go be-yond (sub)string matching, and use link informationto match entities which may have different surfaceforms.
Using this technique, we are able to collect alarge amount of positive training instances of DBpe-1427dia relations.To get precise type information for the argu-ments of a DBpedia relation, we use the DBpediaknowledge base (Auer et al, 2007) and the asso-ciated YAGO type system (Suchanek et al, 2007).Note that for every Wikipedia page, there is a cor-responding DBpedia entry which has captured theinfobox-properties as RDF triples.
Some of thetriples include type information, where the subjectof the triple is a Wikipedia entity, and the objectis a YAGO type for the entity.
For example, theDBpedia entry for the entity ?Albert Einstein?
in-cludes YAGO types such as Scientist, Philosopher,Violinist etc.
These YAGO types are also linkedto appropriate WordNet concepts, providing for ac-curate sense disambiguation.
Thus, for any en-tity argument of a relation we are learning, we ob-tain sense-disambiguated type information (includ-ing super-types, sub-types, siblings etc.
), which be-come useful generalization features in the relationdetection model.
Given a common noun, we canalso retrieve its type information by checking againstWordNet (Fellbaum, 1998).2.2 Extracting Rules from the Training DataWe use a set of rules together with their popular-ities (occurrence count) to characterize a relation.A rule representing the relations between two ar-guments has five components (ordered): argument1type, argument2 type, noun, preposition and verb.
Arule example of ActiveYearsEndDate relation (aboutthe year that a person retired) is:person100007846|year115203791|-|in|retire.In this example, argument1 type is per-son100007846, argument2 type is year115203791,both of which are from YAGO type system.
Thekey words connecting these two arguments are in(preposition) and retire (verb).
This rule does nothave a noun, so we use a ?-?
to take the position ofnoun.
The same relation can be represented in manydifferent ways.
Another rule example characterizingthe same relation isperson100007846|year115203791|retirement|-|announce.This paper only considers three types of words:noun, verb and preposition.
It is straightforward toexpand or simplify the rules by including more orremoving some word types.
The keywords are ex-tracted from the shortest path on the dependencyFigure 1: A dependency tree example.tree between the two arguments.
A dependencytree (Figure 1) represents grammatical relations be-tween words in a sentence.
We used a slot grammarparser (McCord, 1995) to generate the parse tree ofeach sentence.
Note that there could be multiplepaths between two arguments in the tree.
We onlytake the shortest path into consideration.
The pop-ularity value corresponding to each rule representshow many times this rule applies to the given rela-tion in the given data.
Multiple rules can be con-structed from one relation instance, if multiple argu-ment types are associated with the instance, or mul-tiple nouns, prepositions or verbs are in the depen-dency path.2.3 Cleaning the Training DataTo find a sentence on the Wikipedia page that islikely to express a relation in its infobox, we con-sider the first sentence on the page that mentionsboth arguments of the relation.
This heuristic ap-proach returns reasonably good results, but brings inabout 20% noise in the form of false positives, whichis a concern when building an accurate statistical re-lation detector.
To address this issue, we have devel-oped a two-step technique to automatically removesome of the noisy data.
In the first step, we extractpopular argument types and keywords for each DB-pedia relation from the given data, and then use thecombinations of those types and words to create ini-tial rules.
Many of the argument types and keywordsintroduced by the noisy data are often not very pop-ular, so they can be filtered out in the first step.
Notall initial rules make sense.
In the second step, we1428check each rule against the training data to see if thatrule really exists in the training data or not.
If it doesnot exist, we filter it out.
If a sentence does not havea single rule passing the above procedure, that sen-tence will be removed.
Using the above techniques,we collect examples characterizing 7,628 DBpediarelations.3 Learning Multiscale Relation TopicsAn extra step extracting knowledge from the rawdata is needed for two reasons: Firstly, many DB-pedia relations are inter-related.
For example, someDBpedia relations have a subclass relationship, e.g.?AcademyAward?
and ?Award?
; others overlap intheir scope and use, e.g., ?Composer?
and ?Artist?
;while some are equivalent, e.g., ?DateOfBirth?
and?BirthDate?.
Secondly, a fairly large amount of thenoisy labels are still in the training data.To reveal the intrinsic structure of the current DB-pedia relation space and filter out noise, we car-ried out a correlation analysis of relations in thetraining data, resulting in a relation topic space.Each relation topic is a multinomial distributionover the existing relations.
We adapted diffusionwavelets (Coifman and Maggioni, 2006) for thistask.
Compared to the other well-known topic ex-traction methods like LDA (Blei et al, 2003) andLSI (Deerwester et al, 1990), diffusion wavelets canefficiently extract a hierarchy of interpretable topicswithout any user input parameter (Wang and Ma-hadevan, 2009).3.1 An Overview of Diffusion WaveletsThe diffusion wavelets algorithm constructs a com-pressed representation of the dyadic powers of asquare matrix by representing the associated matri-ces at each scale not in terms of the original (unitvector) basis, but rather using a set of custom gener-ated bases (Coifman and Maggioni, 2006).
Figure2 summarizes the procedure to generate diffusionwavelets.
Given a matrix T , the QR (a modifiedQR decomposition) subroutine decomposes T intoan orthogonal matrix Q and a triangular matrix Rsuch that T ?
QR, where |Ti,k ?
(QR)i,k| < ?for any i and k. Columns in Q are orthonormal ba-sis functions spanning the column space of T at thefinest scale.
RQ is the new representation of T with{[?j ]?0} = DWT (T, ?, J)//INPUT://T : The input matrix.//?
: Desired precision, which can be set to a smallnumber or simply machine precision.//J : Number of levels (optional).//OUTPUT://[?j ]?0 : extended diffusion scaling functions atscale j.?0 = I;For j = 0 to J ?
1 {([?j+1]?j , [T 2j ]?j+1?j )?
QR([T 2j ]?j?j , ?
);[?j+1]?0 = [?j+1]?j [?j ]?0 ;[T 2j+1 ]?j+1?j+1 = ([T2j ]?j+1?j [?j+1]?j )2;}Figure 2: Diffusion Wavelets construct multiscale repre-sentations of the input matrix at different scales.
QR is amodified QR decomposition.
J is the max step number(this is optional, since the algorithm automatically ter-minates when it reaches a matrix of size 1 ?
1).
Thenotation [T ]?b?a denotes matrix T whose column space isrepresented using basis ?b at scale b, and row space isrepresented using basis ?a at scale a.
The notation [?b]?adenotes basis ?b represented on the basis ?a.
At an arbi-trary scale j, we have pj basis functions, and length ofeach function is lj .
The number of pj is determined bythe intrinsic structure of the given dataset in QR routine.
[T ]?b?a is a pb ?
la matrix, and [?b]?a is an la ?
pb matrix.respect to the space spanned by the columns of Q(this result is based on the matrix invariant subspacetheory).
At an arbitrary level j,DWT learns the ba-sis functions from T 2j using QR.
Compared to thenumber of basis functions spanning T 2j ?s originalcolumn space, we usually get fewer basis functions,since some high frequency information (correspond-ing to the ?noise?
at that level) can be filtered out.DWT then computes T 2j+1 using the low frequencyrepresentation of T 2j and the procedure repeats.3.2 Constructing Multiscale Relation TopicsLearning Relation CorrelationsAssume we have M relations, and the ith of themis characterized by mi <rule, popularity> pairs.
Weuse s(a, b) to represent the similarity between theath and bth relations.
To compute s(a, b), we firstnormalize the popularities for each relation, and then1429look for the rules that are shared by both relation aand b.
We use the product of corresponding pop-ularity values to represent the similarity score be-tween two relations with respect to each commonrule.
s(a, b) is set to the sum of such scores overall common rules.
The relation-relation correlationmatrix S is constructed as follows:S = [s(1, 1) ?
?
?
s(1,M)?
?
?
?
?
?
?
?
?s(M, 1) ?
?
?
s(M,M)]We have more than 200, 000 argument types, tensof thousands of distinct nouns, prepositions, andverbs, so we potentially have trillions of distinctrules.
One rule may appear in multiple relations.The more rules two relations share, the more relatedtwo relations should be.
The rules shared across dif-ferent relations offer us a novel way to model thecorrelations between different relations, and furtherallow us to create relation topics.
The rules can alsobe simplified.
For example, we may treat argument1,argument2, noun, preposition and verb separately.This results in simple rules that only involve in oneargument type or word.
The correlations betweenrelations are then computed only based on one par-ticular component like argument1, noun, etc.Theoretical AnalysisMatrix S models the correlations between rela-tions in the training data.
Once S is constructed, weadapt diffusion wavelets (Coifman and Maggioni,2006) to automatically extract the basis functionsspanning the original column space of S at multi-ple scales.
The key strength of the approach is thatit is data-driven, largely parameter-free and can au-tomatically determine the number of levels of thetopical hierarchy, as well as the topics at each level.However, to apply diffusion wavelets to S, we firstneed to show that S is a positive semi-definite ma-trix.
This property guarantees that all eigenvaluesof S are ?
0.
Depending on the way we formal-ize the rules, the methods to validate this propertyare slightly different.
When we treat argument1,argument2, noun, preposition and verb separately, itis straightforward to see the property holds.
In The-orem 1, we show the property also holds when weuse more complicated rules (using the 5-tuple rulein Section 2.2 as an example in the proof).Theorem 1.
S is a Positive Semi-Denite matrix.Proof: An arbitrary rule ri is uniquely characterizedby a five tuple: argument1 type| argument2 type|noun| preposition| verb.
Since the number of dis-tinct argument types and words are constants, thenumber of all possible rules is also a constant: R.If we treat each rule as a feature, then the set ofrules characterizing an arbitrary relation ri can berepresented as a point [p1i , ?
?
?
, pRi ] in a latent R di-mensional rule space, where pji represents the popu-larity of rule j in relation ri in the given data.We can verify that the way to compute s(a, b) isthe same as s(a, b) =< [p1a ?
?
?
pRa ], [p1b ?
?
?
pRb ] >,where < ?, ?
> is the cosine similarity (kernel).
Itfollows directly from the definition of positive semi-definite matrix (PSD) that S is PSD (Scho?lkopf andSmola, 2002).In our approach, we construct multiscale re-lation topics by applying DWT to decomposeS/?max(S), where ?max(S) represents the largesteigenvalue of S. Theorem 2 shows that this decom-position will converge, resulting in a relation topichierarchy with one single topic at the top level.Theorem 2.
Let ?max(S) represent the largesteigenvalue of matrix S, then DWT (S/?max(S), ?
)produces a set of nested subspaces of the columnspace of S, and the highest level of the resulting sub-space hierarchy is spanned by one basis function.Proof: From Theorem 1, we know that S is a PSDmatrix.
This means ?max(S) ?
[0,+?)
(all eigen-values of S are non-negative).
This further impliesthat ?
(S)/?max(S) ?
[0, 1], where ?
(S) representsany eigenvalue of S.The idea underlying diffusion wavelets is basedon decomposing the spectrum of an input matrixinto various spectral bands, spanned by basis func-tions (Coifman and Maggioni, 2006).
Let T =S/?max(S).
In Figure 2, we construct spectralbands of eigenvalues, whose associated eigenvectorsspan the corresponding subspaces.
Define dyadicspatial scales tj astj =j?t=02t = 2j+1 ?
1, j ?
0 .At each spatial scale, the spectral band is defined as:?j(T ) = {?
?
?
(T ), ?tj ?
?
},1430where ?
(T ) represents any eigenvalue of T , and ?
?
(0, 1) is a pre-defined threshold in Figure 2.
We cannow associate with each of the spectral bands a vec-tor subspace spanned by the corresponding eigen-vectors:Vj = ?{??
: ?
?
?
(T ), ?tj ?
?
}?, j ?
0 .In the limit, we obtainlimj?
?Vj = ?{??
: ?
= 1}?That is, the highest level of the resulting subspacehierarchy is spanned by the eigenvector associatedwith the largest eigenvalue of T .This result shows that the multiscale analysis ofthe relation space will automatically terminate at thelevel spanned by one basis, which is the most popu-lar relation topic in the training data.3.3 High Level ExplanationWe first create a set of rules to characterize each in-put relation.
Since these rules may occur in multi-ple relations, they provide a way to model the co-occurrence relationship between different relations.Our algorithm starts with the relation co-occurrencematrix and then repeatedly applies QR decomposi-tion to learn the topics at the current level while atthe same time modifying the matrix to focus more onlow-frequency indirect co-occurrences (between re-lations) for the next level.
Running DWT is equiv-alent to running a Markov chain on the input dataforward in time, integrating the local geometry andtherefore revealing the relevant geometric structuresof the whole data set at different scales.
At scalej, the representation of T 2j+1 is compressed basedon the amount of remaining information and the de-sired precision.
This procedure is illustrated in Fig-ure 3.
In the resulting topic space, instances withrelated relations will be grouped together.
This ap-proach may significantly help us detect new rela-tions, since it potentially expands the informationbrought in by new relation instances from makinguse of the knowledge extracted from the existing re-lation repository.3.4 BenefitsAs shown in Figure 3, the topic spaces at differentlevels are spanned by a different number of basis   	   ffflfiffiffi!
#"$ %'& (*) + , - .
/'0 1*2 3 , 4.
56378, -, - 9 :;<=;...Figure 3: Learning Relation Topics at Multiple Scales.functions.
These numbers reveal the dimensions ofthe relevant geometric structures of data at differentlevels.
These numbers are completely data-driven:the diffusion wavelets approach can automaticallyfind the number of levels and simultaneously gen-erate the topics at each level.
Experiments show thatmost multiscale topics are interpretable (due to thesparsity of the scaling functions), such that we caninterpret the topics at different scales and select thebest scale for embedding.
Compared to bootstrap-ping approach, our approach is accumulative; thatis as the system learns more relations, it gets bet-ter at learning new relations.
Because our approachtakes advantage of the previously learned relations,and the topic space is enriched as we learn more andmore relations.We use diffusion wavelets (DWT) rather thanother hierarchy topic models like hLDA (Blei etal., 2004) to extract relation topics for two rea-sons.
First, DWT is parameter free while othermodels need some user-input parameters like hier-archy level.
Second, DWT is more efficient than theother models.
After the relation correlation matrixis constructed, DWT only needs a couple of min-utes to extract multiscale topics on a regular com-puter.
A direct experimental comparison betweenDWT and hLDA can be found in (Wang and Ma-hadevan, 2009).14314 Constructing Relation Detectors withMultiscale Relation Topics4.1 Project Relation Instances onto TopicsWhen we design detectors for new relations, wetreat arg1, arg2, noun, and verb separately toget stronger correlations between relations.
Wedo not directly use preposition.
Any DBpe-dia relation r ?
{1, ?
?
?
,M} is represented with4 vectors rt = [rt(1), ?
?
?
, rt(Nt)], where t ?
{arg1, arg2, noun, verb}, Nt represents the size ofthe vocabulary set of the type t component in theWikipedia training data, and rt(j) represents the oc-currence count of type t component in relation r. Forexample, Nverb is the size of the verb vocabulary setin the training data and rverb(j) represents the occur-rence count of the jth verb in relation r. When a newrelation instance x is given, we extract the depen-dency path between two arguments, and create fourvectors xt, where t ?
{arg1, arg2, noun, verb},following the same format as rt.
The projection re-sult of xt onto the DBpedia relation space Xt is asfollows:Xt = [< rt(1), xt(1) >, ?
?
?
, < rt(M), xt(M) >],where < ?, ?
> is the cosine similarity of two vec-tors.
At level k, the embedding of x is Ekx =[EkXarg1 , EkXarg2, EkXnoun , EkXverb ], where EkXt =([?k]?0)TXt, and [?k]?0 is defined in Figure 2.4.2 Design New Kernel Using Topic FeaturesWe combine Ekx with 3 existing kernels (KArgument,KPath and KBOW ) to create a new kernel for rela-tion detection.
(1) KArgument matches two arguments, it returns thenumber of common argument types that the input ar-guments share.
(2) KPath matches two dependency paths.
Thiskernel is formally defined in (Zhao and Grishman,2005).
We extended this kernel by also matchingthe common nouns, prepositions and verbs in the de-pendency paths.
We assign weight 1 to verbs, 0.5 tonouns and prepositions.
(3) KBOW models the number of common nouns,prepositions and verbs in the given sentences butnot in the dependency paths.
Since these words arenot as important as the words inside the dependencypath, we assign weight 0.25 to them.
(4) KTFk(x, y) =< Ekx , Eky >, where x, y are twoinput relation instances, and < ?, ?
> models the co-sine similarity of two vectors.
TF stands for topicfeature.
(5) The final kernel used in this paper is?1KArgument + ?2KPath + ?3KBOW + ?4KTFk ,where ?i can be tuned for each individual domain.In this paper, we set ?i = 1 for i ?
{1, 2, 3, 4}.4.3 Algorithm to Construct Relation Detectors1.
Construct a relation repository from Wikipedia.
(a) Collect training data from Wikipedia and DB-pedia (Section 2.1);(b) Clean the data representing each input relation(Section 2.2 and 2.3);(c) Create relation correlation matrix S followingthe approach described in Section 3.2, result-ing in an M ?M matrix.2.
Create multiscale relation topics.
[?k]?0 = DWT (S/?max(S), ?
), where DWT () isthe diffusion wavelets implementation described inSection 3.1.
[?k]?0 are the scaling function basesat level k represented as an M ?
pk matrix, k =1, ?
?
?
, h represents the level in the topic hierarchy.The value of pk is determined in DWT () based onthe intrinsic structure of the given dataset.
Columnsof [?k]?0 are used as relation topics at level k.3.
Construct relation detectors for new relations.Given the training data from a new relation, projectthe data onto level k of the multiscale topic hierar-chy, where k is chosen by users (Section 4.1).
Ap-ply SVM classifiers together with our kernel (Sec-tion 4.2) to create detectors for new relations.5 Experimental ResultsWe used SVMLight (Joachims, 1999) together withthe user defined kernel setting in our approach.
Thetrade-off parameter between training error and mar-gin c is 1 for all experiments.
Our approach tolearn multiscale relation topics is largely parameterfree.
The only parameter to be set is the precision?
= 10?5, which is also the default value in the dif-fusion wavelets implementation.5.1 Learning Multiscale Relation TopicsFollowing the approach discussed in Section 2.1,we collect more than 620,000 training instances for1432Table 1: Number of topics at different levels (DBpe-dia Relations) under 5 different settings: use args, noun,preposition and verb; arg1 only; arg2 only; noun only andverb only.Level args & words arg1 arg2 noun verb1 7628 7628 7628 7628 76282 269 119 155 249 2103 32 17 19 25 354 7 5 5 7 105 3 2 3 4 46 2 1 2 2 27 1 1 1 17,628 DBpedia relations.
For any given topic vec-tor v, we know it is a column vector of length M ,where M is the size of the DBpedia relation setand ?v?
= 1.
The entry v[i] represents the contri-bution of relation i to this topic.
To explain themain concept of topic v, we sort the entries onv and print out the relations corresponding to thetop entries.
These relations summarize the top-ics in the relation repository.
One topic exam-ple is as follows: [doctoraladvisor (0.683366), doc-toralstudents (0.113201), candidate (0.014662), academ-icadvisors (0.008623), notablestudents (0.003829), col-lege (0.003021), operatingsystem (0.002964), combatant(0.002826), influences (0.002285), training (0.002148),?
?
?
], where doctoraladvisor is a DBpedia relationand 0.683366 is its contribution to the topic.
Thelength of this relation vector is 7,628.
We only listthe top 10 relations here.Our approach identifies 5 different topic hierar-chies under different settings (use args, noun, prepo-sition and verb; arg1 only; arg2 only; noun only andverb only).
The number of the topics at each level isshown in Table 1.
At the first level, each input rela-tion is treated as a topic.
At the second level, num-bers of topics go down to reasonable numbers like269.
Finally at the top level, the number of topic isdown to 1 (Theorem 2 also proves this).
We showsome topic examples under the first setting.
The 3topics at level 5 are shown in Table 2.
They representthe most popular DBpedia relation topics.
Almostall 269 topics at level 5 look semantically meaning-ful.
They nicely capture the related relations.
Someexamples are in Table 3.Table 2: 3 topics at level 5 (all word types and args).Top 4 Relations and Their Contributionsstarring 86.6%, writer 3.8%, producer 3.2%, director 1.6%birthplace 75.3%, clubs 6.1%, deathplace 5.1%, location 4.1%clubs 55.3%, teams 9.3%, nationalteam 6.3% college 6.0%Table 3: Some topics at level 2 (all word types and args).Top Relationsactiveyearsenddate, careerend, finalyear, retiredcommands, partof, battles, notablecommandersoccupation, shortdescription, profession, datesinfluenced, schooltradition, notableideas, maininterestsdestinations, end, through, posttownprizes, award, academyawards, highlightsinflow, outflow, length, maxdepthafter, successor, endingterminuscollege, almamater, education5.2 Relation Detection on Wikipedia DataIn previous experiment, 20,000 relation instanceswere held and not used to construct the topic space.These instances are randomly selected from 100 re-lations (200 instances from each relation).
This setis used as a benchmark to compare different rela-tion detection approaches.
In this experiment, 100instances from each relation are used for training,and the other 100 are for testing.
In training, we trythree different settings: n = 5, 20 and 100, where nis the size of the training set for each relation.
Whenwe train a model for one relation, we use the train-ing positive instances from the other 99 relations astraining negatives.
For example, we use 5 trainingpositive instances and 5*99=495 training negativesto train a detector for each relation.We compare our approach against the regularrule-based approach (Lin and Pantel, 2001) and twoother kernel-based approaches (presented in Sec-tion 4.2) for relation detection task.
The comparisonresults are summarized in Table 4.
The approachusing relation topics (level 2) consistently outper-forms the other three approaches in all three settings.When n = 5, it achieves the largest improvementover the other three.
This indicates that using re-lation topics that integrate the knowledge extractedfrom the existing relations, can significantly benefitus when the training data is insufficient.
This is rea-sonable, since the prior knowledge becomes morevaluable in this scenario.1433The users can select the level that is the most ap-propriate for their applications.
In this example, weonly have alignment results at 7 levels.
Choosing thespace at level 2 spanned by a couple of hundreds ofbasis functions is a natural choice, since the levelsbelow and above this have too many or too few fea-tures, respectively.
A user can also select the mostappropriate level by checking if the related relationtopics are meaningful for their applications.5.3 Relation Detection on ACE DataIn this experiment, we use the news domain docu-ments of the ACE 2004 corpus (ACE, 2004) to com-pare our approaches against the state-of-the-art ap-proaches.
This dataset includes 348 documents andaround 4400 relation instances.
7 relation types,7 entity types, numerous relation sub-types, entitysub-types, and mention types are defined on thisset.
The task is to classify the relation instancesinto one of the 7 relation types or ?NONE?, whichmeans there is no relation.
For comparison, we usethe same setting as (Zhang et al, 2006), by apply-ing a 5-fold cross-validation.
The scores reportedhere are the average of all 5 folds.
This is also howthe other approaches are evaluated.
In this test, wetreat entity types, entity sub-types and mention typesequally as argument types.
Table 5 summarizesthe performance after applying the kernels presentedin Section 4.2 incrementally, showing the improve-ment from each individual kernel.
We also com-pare our approaches to the other state-of-the-art ap-proaches including Convolution Tree kernel (Collinsand Duffy, 2001), Syntactic kernel (Zhao and Grish-man, 2005), Composite kernel (linear) (Zhang et al,2006) and the best kernel in (Nguyen et al, 2009).Our approach with relation topics at level 2 has thebest performance, achieving a 73.24% F-measure.The impact of the relation topics is huge.
They im-prove the F-measure from 61.15% to 73.24%.
Wealso test our approach using the topics at level 3.The performance is slightly worse than using level2, but still better than the others.This paper studies how relation topics extractedfrom Wikipedia relation repository can help improverelation detection performance.
We do not want totune our approach to one particular relation detec-tion task, like ACE 2004.
In our experiments, noparameter tuning was taken and no domain specificheuristic rules were applied.
We are aware of somemethods that could stack on our approach to furtherimprove the performance on ACE test.
The Com-posite kernel result in Table 5 is based on a linearcombination of the Argument kernel and Convolu-tion Tree kernel.
(Zhang et al, 2006) showed thatby carefully choosing the weight of each compo-nent and using a polynomial expansion, they couldachieve the best performance on this data: 72.1% F-measure.
(Nguyen et al, 2009) further showed thatthe performance can be improved by taking syntac-tic and semantic structures into consideration.
Theyused several types of syntactic information includ-ing constituent and dependency syntactic parse treesto improve the state of the art approaches to 71.5%on F-measure.
Heuristic rules extracted from thetarget data can also help improve the performance.
(Jiang and Zhai, 2007) reported that by taking sev-eral heuristic rules they can improve the F-measureof Composite Kernel to 70.4%.
They also showedthat using maximum entropy classifier rather thanSVM achieved the best performance on this task:72.9% F-measure.
To the best of our knowledge, themost recent result was reported by (Zhou and Zhu,2011), who extended their previous work in (Zhouet al, 2007).
By using several heuristics to definean effective portion of constituent trees, and trainingthe classifiers using ACE relation sub-types (ratherthan on types), they achieved an impressive 75.8%F-measure.
However, as pointed out in (Nguyen etal., 2009), such heuristics are tuned on the target re-lation extraction task and might not be appropriate tocompare against the automatic learning approaches.Even though we have not done any domain specificparameter tuning or applied any heuristics, our ap-proach still achieve significant improvements overall approaches mentioned above except one, whichis based on heuristics extracted from the target do-main.
This also implies that by combining some ofthe above ideas with relation topics, the performanceon ACE data may be further improved.6 ConclusionsThis paper proposes a novel approach to create de-tectors for new relations integrating the knowledgeextracted from the existing relations.
The contribu-tions of this paper are three-fold.
Firstly, we pro-1434Table 4: F-measure comparison of different approachesover 100 DBpedia relations with 5, 20 and 100 posi-tive examples per relation.
AG: KArgument, DP: KPath,BOW: KBOW , TFk: KTFk .Approaches 100 20 5Rule Based 37.70% 27.45% 13.20%AG+ DP 73.64% 51.85% 22.95%AG+ DP+ BOW 78.74% 62.76% 31.98%AG+ DP+ BOW+ TF2 81.18% 68.03% 41.60%Table 5: Performance comparison of different approacheswith SVM over the ACE 2004 data.
P: Precision, R: Re-call, F: F-measure, AG: KArgument, DP: KPath, BOW:KBOW , TFk: KTFk .Approaches P(%) R(%) F(%)Convolution Tree Kernel 72.5 56.7 63.6Composite Kernel (linear) 73.50 67.00 70.10Syntactic Kernel 69.23 70.50 69.86Nguyen, et al (2009) 76.60 67.00 71.50AG 59.56 46.22 52.02AG + DP 64.44 54.93 59.28AG + DP + BOW 62.00 61.19 61.15AG + DP + BOW + TF3 69.63 76.51 72.90AG + DP + BOW + TF2 69.15 77.88 73.24vide an automatic way to collect training data formore than 7,000 relations from Wikipedia and DB-pedia.
Secondly, we present an unsupervised way toconstruct a set of relation topics at multiple scales.Different from the topics defined over words, rela-tion topics are defined over the existing relations.Thirdly, we design a new kernel for relation detec-tion by integrating the relation topics in the repre-sentation of the relation instances.
By leveragingthe knowledge extracted from the Wikipedia rela-tion repository, our approach significantly improvesthe performance over the state-of-the-art approacheson ACE data.
This paper makes use of all DBpediarelations to create relation topics.
It is possible thatusing a subset of them (more related to the targetrelations) might improve the performance.
We willexplore this in future work.AcknowledgmentsWe thank the reviewers for their helpful comments.This material is based upon work supported in partby the IBM DeepQA (Watson) project.
We alsogratefully acknowledge the support of Defense Ad-vanced Research Projects Agency (DARPA) Ma-chine Reading Program under Air Force ResearchLaboratory (AFRL) prime contract no.
FA8750-09-C-0172.
Any opinions, findings, and conclusionor recommendations expressed in this material arethose of the author(s) and do not necessarily reflectthe view of the DARPA, AFRL, or the US govern-ment.ReferencesACE.
2004.
The automatic content extraction projects,http://projects.ldc.upenn.edu/ace/.So?ren Auer, Christian Bizer, Georgi Kobilarov, JensLehmann, Richard Cyganiak, and Zachary Ives.
2007.DBpedia: A nucleus for a web of open data.
In Pro-ceedings of the 6th International Semantic Web Con-ference, Busan, Korea, pages 11?15.
Springer.D.
Blei, A. Ng, and M. Jordan.
2003.
Latent Dirich-let alocation.
Journal of Machine Learning Research,3:993?1022.D.
Blei, T. Griffiths, M. Jordan, and J. Tenenbaum.
2004.Hierarchical topic models and the nested Chineserestaurant process.
In Proceedings of the Advances inNeural Information Processing Systems (NIPS).Razvan Bunescu and Raymond Mooney.
2005.
A short-est path dependency kernel for relation extraction.
InProceedings of the Conference on Human LanguageTechnology and Empirical Methods in Natural Lan-guage Processing.Yee Seng Chan and Dan Roth.
2010.
Exploiting back-ground knowledge for relation extraction.
In Proceed-ings of the 23rd International Conference on Compu-tational Linguistics, pages 152?160.R.
Coifman and M. Maggioni.
2006.
Diffusionwavelets.
Applied and Computational HarmonicAnalysis, 21:53?94.Michael Collins and Nigel Duffy.
2001.
Convolutionkernels for natural language.
In Proceedings of theAdvances in Neural Information Processing Systems(NIPS), pages 625?632.Aron Culotta and Jeffrey Sorensen.
2004.
Dependencytree kernels for relation extraction.
In Proceedings ofthe 42nd Annual Meeting of the Association for Com-putational Linguistics (ACL), pages 423?429.S.
Deerwester, S. T. Dumais, G. W. Furnas, T. K. Lan-dauer, and R. Harshman.
1990.
Indexing by latent se-mantic analysis.
Journal of the American Society forInformation Science, 41(6):391?407.Oren Etzioni, Michael Cafarella, Doug Downey, Ana-Maria Popescu, Tal Shaked, Stephen Soderland,1435Daniel S. Weld, and Alexander Yates.
2005.
Unsuper-vised named-entity extraction from the web: An ex-perimental study.
Artificial Intelligence, 165:91?134.Christiane Fellbaum.
1998.
WordNet: An ElectronicLexical Database.
MIT Press.Raphael Hoffmann, Congle Zhang, and Daniel S. Weld.2010.
Learning 5000 relational extractors.
In Pro-ceedings of the 48th Annual Meeting of the Associationfor Computational Linguistics (ACL), pages 286?295.Jing Jiang and Chengxiang Zhai.
2007.
A systematic ex-ploration of the feature space for relation extraction.
InProceedings of the Human Language Technology Con-ference of the North American Chapter of the Associ-ation for Computational Linguistics, pages 113?120.Jing Jiang.
2009.
Multi-task transfer learning forweakly-supervised relation extraction.
In Proceedingsof the Joint Conference of the 47th Annual Meeting ofthe Association for Computational Linguistics (ACL)and the 4th International Joint Conference on NaturalLanguage Processing (IJCNLP), pages 1012?1020.T.
Joachims.
1999.
Making Large-Scale SVM LearningPractical.
MIT Press.Nanda Kambhatla.
2004.
Combining lexical, syntactic,and semantic features with maximum entropy mod-els for extracting relations.
In Proceedings of theACL 2004 on Interactive poster and demonstrationsessions.Dekang Lin and Patrick Pantel.
2001.
DIRT - discov-ery of inference rules from text.
In Proceedings of theACM SIGKDD Conference on Knowledge Discoveryand Data Mining, pages 323?328.Michael McCord.
1995.
Slot grammar: A systemfor simpler construction of practical natural languagegrammars.
Communications of the ACM, 38(11).Scott Miller, Heidi Fox, Lance Ramshaw, and RalphWeischedel.
2000.
A novel use of statistical pars-ing to extract information from text.
In Proceedingsof the 1st North American Chapter of the Associationfor Computational Linguistics Conference.Mike Mintz, Steven Bills, Rion Snow, and Dan Jurafsky.2009.
Distant supervision for relation extraction with-out labeled data.
In Proceedings of the Joint Confer-ence of the 47th Annual Meeting of the Association forComputational Linguistics (ACL) and the 4th Interna-tional Joint Conference on Natural Language Process-ing (IJCNLP), pages 1003?1011.Truc-Vien T. Nguyen, Alessandro Moschitti, andGiuseppe Riccardi.
2009.
Convolution kernels onconstituent, dependency and sequential structures forrelation extraction.
In Proceedings of the 2009 Con-ference on Empirical Methods in Natural LanguageProcessing (EMNLP).B.
Scho?lkopf and A. J. Smola.
2002.
Learning with Ker-nels: Support Vector Machines, Regularization, Opti-mization, and Beyond.
MIT Press.Fabian M. Suchanek, Gjergji Kasneci, and GerhardWeikum.
2007.
YAGO: A large ontology fromWikipedia and WordNet.
Web Semantics: Science,Services and Agents on the World Wide Web, 6(3):203?217.C.
Wang and S. Mahadevan.
2009.
Multiscale analysisof document corpora based on diffusion models.
InProceedings of the International Joint Conference onArtificial Intelligence (IJCAI), pages 1592?1597.Wikipedia.
2011. http://www.wikipedia.org/.Min Zhang, Jie Zhang, Jian Su, and Guodong Zhou.2006.
A composite kernel to extract relations betweenentities with both flat and structured features.
In Pro-ceedings of the 21st International Conference on Com-putational Linguistics and 44th Annual Meeting of theAssociation for Computational Linguistics (ACL).Shubin Zhao and Ralph Grishman.
2005.
Extracting re-lations with integrated information using kernel meth-ods.
In Proceedings of the 43rd Annual Meeting ofthe Association for Computational Linguistics (ACL),pages 419?426.G.
Zhou and Q. Zhu.
2011.
Kernel-based semantic rela-tion detection and classification via enriched parse treestructure.
Journal of Computer Science and Technol-ogy, 26:45?56.G.
Zhou, M. Zhang, D. Ji, and Q. Zhu.
2007.
Treekernel-based relation extraction with context-sensitivestructured parse tree information.
In Proceedingsof the 2007 Joint Conference on Empirical Methodsin Natural Language Processing and ComputationalNatural Language Learning (EMNLP).1436
