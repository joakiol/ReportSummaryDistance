A Corpus-based Account of Regular Polysemy: The Case ofContext-sensitive AdjectivesMaria LapataDepartment of Computational LinguisticsSaarland UniversityPO Box 15 11 5066041 Saarbru?cken, Germanymlap@coli.uni-sb.deAbstractIn this paper we investigate polysemous adjectives whosemeaning varies depending on the nouns they modify(e.g., fast).
We acquire the meanings of these adjectivesfrom a large corpus and propose a probabilistic modelwhich provides a ranking on the set of possible interpre-tations.
We identify lexical semantic information auto-matically by exploiting the consistent correspondencesbetween surface syntactic cues and lexical meaning.We evaluate our results against paraphrase judgmentselicited experimentally from humans and show that themodel?s ranking of meanings correlates reliably with hu-man intuitions: meanings that are found highly probableby the model are also rated as plausible by the subjects.1 IntroductionMuch recent work in lexical semantics has been con-cerned with accounting for regular polysemy, i.e., theregular and predictable sense alternations certain classesof words are subject to.
Adjectives, more than other cat-egories, are a striking example of regular polysemy sincethey are able to take on different meanings depending ontheir context, viz., the noun or noun class they modify(see Pustejovsky (1995) and the references therein).The adjective fast in (1) receives different interpre-tations when modifying the nouns programmer, planeand scientist.
A fast programmer is typically a program-mer who programs quickly, a fast plane is typically aplane that flies quickly, a fast scientist can be a scien-tist who publishes papers quickly, who performs exper-iments quickly, who observes something quickly, whoreasons, thinks, or runs quickly.
Interestingly, adjectiveslike fast are ambiguous across and within the nouns theymodify.
A fast plane is not only a plane that flies quickly,but also a plane that lands, takes off, turns, or travelsquickly.
Even the more restrictive fast programmer al-lows more than one interpretation.
One can easily thinkof a context where a fast programmer thinks, runs ortalks quickly.
(1) a. fast programmerb.
fast planec.
fast scientistThe work reported in this paper was carried out while the authorwas at the Division of Informatics, University of Edinburgh.
(2) a. easy problemb.
difficult languagec.
good cookd.
good soupAdjectives like fast have been extensively studied in thelexical semantics literature and their properties have beenknown at least since Vendler (1968).
The meaning ofadjective-noun combinations like those in (1) and (2) areusually paraphrased with a verb modified by the adjectivein question or its corresponding adverb.
For example, aneasy problem is ?a problem that is easy to solve?
or ?aproblem that one can solve easily?.
In order to accountfor the meaning of these combinations Vendler (1968,92) points out that ?in most cases not one verb, but a fam-ily of verbs is needed?.
Vendler further observes that thenoun figuring in an adjective-noun combination is usu-ally the subject or object of the paraphrasing verb.
Al-though fast usually triggers a verb-subject interpretation(see (1)), easy and difficult trigger verb-object interpre-tations (see (2a,b)).
An easy problem is usually a prob-lem that is easy to solve, whereas a difficult language is alanguage that is difficult to learn, speak, or write.
Adjec-tives like good allow either verb-subject or verb-objectinterpretations: a good cook is a cook who cooks wellwhereas good soup is soup that tastes good or soup thatis good to eat.Pustejovsky (1995) avoids enumerating the varioussenses for adjectives like fast by exploiting the seman-tics of the nouns they modify.
Pustejovsky treats nounsas having a qualia structure as part of their lexical en-tries, which among other things, specifies possible eventsassociated with the entity.
For example, the telic (pur-pose) role of the qualia structure for problem has a valueequivalent to solve.
When the adjective easy is combinedwith problem, it predicates over the telic role of prob-lem and consequently the adjective-noun combinationreceives the interpretation a problem that is easy to solve.Pustejovsky (1995) does not give an exhaustive listof the telic roles a given noun may have.
Furthermore,in cases where more than one interpretations are pro-vided (see Vendler (1968)), no information is given withrespect to the likelihood of these interpretations.
Out-of context, the number of interpretations for fast scien-tist is virtually unlimited, yet some interpretations aremore likely than others: fast scientist is more likely tobe a scientist who performs experiments quickly or whopublishes quickly than a scientist who draws or drinksquickly.In this paper we focus on polysemous adjective-nouncombinations (see (1) and (2)) and attempt to addressthe following questions: (a) Can the meanings of theseadjective-noun combinations be acquired automaticallyfrom corpora?
(b) Can we constrain the number of inter-pretations by providing a ranking on the set of possiblemeanings?
(c) Can we determine if an adjective has apreference for a verb-subject or verb-object interpreta-tion?
We provide a probabilistic model which combinesdistributional information about how likely it is for anyverb to be modified by the adjective in the adjective-noun combination or its corresponding adverb with in-formation about how likely it is for any verb to takethe modified noun as its object or subject.
We obtainquantitative information about verb-adjective modifica-tion and verb-argument relations from the British Na-tional Corpus (BNC), a 100 million word collection ofsamples of written and spoken language from a widerange of sources designed to represent current British En-glish (Burnard, 1995).
We evaluate our results by com-paring the model?s predictions against human judgmentsand show that the model?s ranking of meanings correlatesreliably with human intuitions.2 The Model2.1 Formalization of Adjective-Noun PolysemyIn order to come up with the meaning of ?plane that fliesquickly?
for fast plane we would like to find in the cor-pus a sentence whose subject is the noun plane or planesand whose main verb is fly, which in turn is modified bythe adverbs fast or quickly.
In the general case we wantto paraphrase the meaning of an adjective-noun combi-nation by finding the verbs that take the head noun astheir subject or object and are modified by an adverbcorresponding to the modifying adjective.
This can beexpressed as the joint probability P(a,n,v,rel) where vis the verbal predicate modified by the adverb a (derivedfrom the adjective present in the adjective-noun combi-nation) bearing the argument relation rel (i.e., subject orobject) to the head noun n. We rewrite P(a,n,v,rel) usingthe chain rule in (3).P(a,n,v,rel) =(3)P(v) P(njv) P(ajv,n) P(reljv,n,a)Although the parameters P(v) and P(njv) can be straight-forwardly estimated from the BNC, the estimation ofP(reljv,n,a) and P(ajv,n) is somewhat problematic.
Inorder to obtain P(reljv,n,a) we must estimate the fre-quency f (v,n,a,rel) (see (4)).P(reljv,n,a) = f (v,n,a,rel)f (v,n,a)(4)One way to acquire f (v,n,a,rel) would be to fully parsethe corpus so as to identify the verbs which take thehead noun n as their subject or object and are modifiedby the adverb a.
Even if we could accurately parse thecorpus, it is questionable whether we can find enoughdata for the estimation of f (v,n,a,rel).
There are onlysix sentences in the entire BNC that can be used to es-timate f (v,n,a,rel) for the adjective-noun combinationfast plane (see (5a)?(5f)).
The interpretations ?plane thatswoops in fast?, ?plane that drops down fast?
and ?planethat flies fast?
are all equally likely, since they are at-tested in the corpus only once.
This is rather counter-intuitive since fast planes are more likely to fly thanswoop in fast.
For the adjective-noun combination fastprogrammer there is only one sentence relevant for theestimation of f (v,n,a,rel) in which the modifying ad-verbial is not fast but the semantically related quickly(see (6)).
The sparse data problem carries over to the es-timation of the frequency f (v,n,a).
(5) a.
Three planes swooped in, fast and low.b.
The plane was dropping down fast towardsBangkok.c.
The unarmed plane flew very fast and veryhigh.d.
The plane went so fast it left its sound behind.e.
And the plane?s going slightly faster than theHercules or Andover.f.
He is driven by his ambition to build a planethat goes faster than the speed of sound.
(6) It means that programmers will be able to developnew applications more quickly.We avoid these estimation problems by reducing the pa-rameter space.
In particular, we make the following in-dependence assumptions:P(ajv,n)  P(ajv)(7)P(reljv,n,a)  P(reljv,n)(8)We assume that the likelihood of an adverb modifyinga verb is independent of the verb?s arguments (see (7)).Accordingly, we assume that knowing that the adverb amodifying the verb v will contribute little information tothe likelihood of the relation rel which depends more onthe verb and its argument n (see (8)).
By substituting (7)and (8) into (3), P(a,n,v,rel) can be written as:P(a,n,v,rel)  P(v) P(njv) P(ajv) P(reljv,n)(9)We estimate the probabilities P(v), P(njv), P(ajv), andP(reljv,n) as follows:P(v) =f (v)?if (vi)(10)P(njv) =f (n,v)f (v)(11)P(ajv) =f (a,v)f (v)(12)P(reljv,n) = f (rel,v,n)f (v,n)(13)By substituting equations (10)?
(13) into (9) and simpli-fying the relevant terms, (9) is rewritten as follows:P(a,n,v,rel)  f (rel,v,n)  f (a,v)f (v) ?if (vi)(14)Depending on the data (noisy or not) and the task at handwe may choose to estimate the probability P(v,n,a,rel)from reliable corpus frequencies only (e.g., f (a,v) > 1and f (rel,v,n) > 1).
If we know the interpretation pref-erence of a given adjective (i.e., subject or object), wemay vary only the term v, keeping the terms n, a and relconstant.
Alternatively, as we show in Experiment 1 (seeSection 3), we may acquire the interpretation preferencesautomatically by varying both the terms rel and v.2.2 Parameter EstimationWe estimated the parameters described in the previoussection from a part-of-speech tagged and lemmatizedversion of the BNC (100 million words).
The estimationof the terms f (v) and ?i f (vi) (see (14)) reduces to thenumber of times a given verb is attested in the corpus.In order to estimate the terms f (rel,v,n) and f (a,v) thecorpus was automatically parsed by Cass (Abney, 1996),a robust chunk parser designed for the shallow analysisof noisy text.
We used the parser?s built-in function to ex-tract tuples of verb-subjects and verb-objects (see (15)).The tuples obtained from the parser?s output are an im-perfect source of information about argument relations.Bracketing errors as well as errors in identifying chunkcategories accurately result in tuples whose lexical itemsdo not stand in a verb-argument relationship.
For exam-ple, the verb is missing from (16a) and the noun is miss-ing from (16b).
(15) a. change situation SUBJb.
come off heroin OBJc.
deal with situation OBJ(16) a. isolated people SUBJb.
smile good SUBJIn order to compile a comprehensive count of verb-argument relations we discarded tuples containing verbsor nouns attested in a verb-argument relationship onlyonce.
Non-auxiliary instances of the verb be (e.g., OBJ beembassy) were also eliminated since they contribute nosemantic information with respect to the events or statesthat are possibly associated with the noun with which theadjective is combined.
Particle verbs (see (15b)) wereretained only if the particle was adjacent to the verb.Verbs followed by the preposition by and a head nounwere considered instances of verb-subject relations.
Theverb-object tuples also included prepositional objects(see (15c)).
It was assumed that PPs adjacent to the verbheaded by either of the prepositions in, to, for, with,on, at, from, of, into, through, upon were prepositionalobjects.
This resulted in 737,390 distinct types of verb-subject pairs and 1,077,103 distinct types of verb-objectpairs.Generally speaking, the frequency f (a,v) representsnot only a verb modified by an adverb derived from theadjective in question (see (17a)) but also constructionslike the ones in (17b,c) where the adjective takes an in-finitival VP complement whose logical subject can be re-alized as a for-PP (see (17c)).
It is relatively straight-forward to develop an automatic process which mapsan adjective to its corresponding adverb, modulo excep-tions and idiosyncrasies.
However in the experiments de-scribed in the following sections this mapping was man-ually specified.
(17) a. comfortable chair !
a chair on which one sitscomfortablyb.
comfortable chair !
a chair that is comfort-able to sit onc.
comfortable chair !
a chair that is comfort-able for me to sit onWe estimated the frequency f (a,v) by collapsing thecounts from cases where the adjective was followed byan infinitival complement (see (17b,c)) and cases wherethe verb was modified by the adverb corresponding tothe related adjective (see (17a)).
We focused only on in-stances where the verb and the adverbial phrase modify-ing it (AdvP) were adjacent and extracted the verb andthe head of the AdvP immediately following or preced-ing it.
From constructions with adjectives immediatelyfollowed by infinitival complements with an optionallyintervening for-PP (see (17c)) we extracted the adjectiveand the main verb of the infinitival complement.2.3 Comparison against the LiteratureIn what follows we explain the properties of the model byapplying it to a small number of adjective-noun combina-tions taken from the lexical semantics literature.
Table 1gives the interpretations of eight adjective-noun com-binations discussed in Pustejovsky (1995) and Vendler(1968).
Table 2 shows the five most likely interpretationsfor these combinations as derived by the model discussedin the previous sections (v1 is the most likely interpreta-tion, v2 is the second most likely interpretation, etc.
).First notice that our model predicts variation in mean-ing when the same adjective modifies different nouns byproviding different interpretations for easy problem andeasy planet (see Table 2).
Our model agrees with Vendler(1968) in the interpretation of easy problem (see Tables 1and 2).
Furthermore, it provides the additional meanings?a problem that is easy to deal with, identify, tackle, andhandle?.
Although the model does not derive Vendler?sinterpretation of easy planet, it produces complementarymeanings such as ?a planet that is easy to predict, iden-tify, plunder, work with?.
Similarly, although the modeldoes not discover the suggested interpretation for goodumbrella it comes up with the plausible meaning ?an um-brella that covers well?.
In fact the latter can be consid-ered as a subtype of the meaning suggested by Puste-jovsky (1995): an umbrella functions well if it openswell, closes well, covers well, etc.
Although Pustejovskysuggests only a subject-related interpretation for goodumbrella, the model also derives plausible object-relatedinterpretations: ?an umbrella that is good to keep, goodfor waving, good to hold, good to run for, good to leave?.Adjective Interpretationeasy problem a problem that is easy to solve (Vendler, 1968, 97)easy planet a planet that is easy to observe (Vendler, 1968, 99)good umbrella an umbrella that functions well (Pustejovsky, 1995, 43)good shoe a shoe that is good for wearing, for walking (Vendler, 1968, 99)fast horse a horse that runs fast (Vendler, 1968, 92)difficult language a language that is difficult to speak, learn, write, understand (Vendler, 1968, 99)careful scientist a scientist who observes, performs, runs experiments carefully (Vendler, 1968, 92)comfortable chair a chair on which one sits comfortably (Vendler, 1968, 98)Table 1: Paraphrases for adjective-noun combinations taken from the literatureP(v,n,a,rel) v1 v2 v3 v4 v5P(v,problem,easy,OBJ) solve deal with identify tackle handleP(v,planet,easy,OBJ) predict identify plunder see on work withP(v,umbrella,good,SUBJ) coverP(v,umbrella,good,OBJ) keep wave hold run for leaveP(v,shoe,good,OBJ) wear keep buy get stickP(v,horse, fast,OBJ) run learn go come riseP(v, language,difficult,OBJ) understand interpret learn use speakP(v,careful,scientist,SUBJ) calculate proceed investigate study analyseP(v,comfortable,chair,OBJ) sink into sit on lounge in relax in nestle inTable 2: Model-derived paraphrases for adjective-noun combinations, ranked in order of likelihoodThe model and Vendler (1968) agree in their inter-pretation of the pairs good shoe and fast horse.
Themodel additionally acquires the fairly plausible mean-ings ?a shoe that is good to keep, to buy, and get?
forgood shoe and ?a horse that learns, goes, comes and risesfast?
for fast horse.
The model?s interpretations for dif-ficult language are a superset of the meanings suggestedby Vendler (see Table 1).
The model?s interpretations forcareful scientist seem intuitively plausible (even thoughthey don?t overlap with those suggested by Vendler).
Fi-nally, note that the meanings derived for comfortablechair are also plausible (the second most likely meaningis the one suggested by Vendler, see Table 1).The examples in Table 1 may not be entirely represen-tative of the types of polysemous adjective-noun combi-nations occurring in unrestricted text since they are takenfrom linguistic texts where emphasis is given on explain-ing polysemy with examples that straightforwardly illus-trate it.
In other words, the adjective-noun combinationsin Table 1 may be too easy for the model to handle.
InExperiment 1 (see Section 3) we test our model on poly-semous adjective-noun combinations randomly sampledfrom the BNC, and formally evaluate our results againsthuman judgments.3 Experiment 1: Comparison againstHuman Judgments3.1 MethodThe ideal test of the proposed model of adjective-noun polysemy will be with randomly chosen materi-als.
We evaluate the acquired meanings by comparingthe model?s rankings against judgments of meaning para-phrases elicited experimentally from human subjects.
Bycomparing the model-derived meanings against humanintuitions we are able to explore: (a) whether plausi-ble meanings are ranked higher than implausible ones;(b) whether the model can be used to derive the argu-ment preferences for a given adjective, i.e., whether theadjective is biased towards a subject or object interpre-tation or whether it is equi-biased; (c) whether there is alinear relationship between the model-derived likelihoodof a given meaning and its perceived plausibility, usingcorrelation analysis.3.1.1 Materials and DesignWe chose nine adjectives according to a set of minimalcriteria and paired each adjective with 10 nouns ran-domly selected from the BNC.
We chose the adjectivesas follows: we first compiled a list of all the polysemousadjectives mentioned in the lexical semantics literature(Vendler, 1968; Pustejovsky, 1995).
From these we ran-domly sampled nine adjectives (difficult, easy, fast, good,hard, right, safe, slow, wrong).
These adjectives had tobe unambiguous with respect to their part-of-speech:each adjective was unambiguously tagged as ?adjective?98.6% of the time, measured as the number of differentpart-of-speech tags assigned to the word in the BNC.We identified adjective-noun pairs using Gsearch(Corley et al, 2000), a chart parser which detects syn-tactic patterns in a tagged corpus by exploiting a user-specified context free grammar and a syntactic query.Gsearch was run on a lemmatized version of the BNC soas to compile a comprehensive corpus count of all nounsoccurring in a modifier-head relationship with each of thenine adjectives.
From the syntactic analysis provided byProbability BandAdjective-noun High Medium Lowdifficult customer satisfy ?20.27 help ?22.20 drive ?22.64easy food cook ?18.94 introduce ?21.95 finish ?23.15fast pig catch ?23.98 stop ?24.30 use ?25.66good postcard send ?20.17 draw ?22.71 look at ?23.34hard number remember ?20.30 use ?21.15 create ?22.69right school apply to ?19.92 complain to ?21.48 reach ?22.90safe drug release ?22.24 try ?23.38 start ?25.56slow child adopt ?19.90 find ?22.50 forget ?22.79wrong colour use ?21.78 look for ?22.78 look at ?24.89Table 3: Randomly selected example stimuli with log-transformed probabilities derived by the modelthe parser we extracted a table containing the adjectiveand the head of the noun phrase following it.
In the caseof compound nouns, we only included sequences of twonouns, and considered the rightmost occurring noun asthe head.We used the model outlined in Section 2 to derivemeanings for the 90 adjective-noun combinations.
Weemployed no threshold on the frequencies f (a,v) andf (rel,v,n).
In order to obtain the frequency f (a,v) theadjective was mapped to its corresponding adverb.
In par-ticular, good was mapped to good and well, fast to fast,easy to easily, hard to hard, right to rightly and right,safe to safely and safe, slow to slowly and slow andwrong to wrongly and wrong.
The adverbial function ofthe adjective difficult is expressed only periphrastically(i.e., in a difficult manner, with difficulty).
As a result,the frequency f (difficult,v) was estimated only on thebasis of infinitival constructions (see (17)).
We estimatedthe probability P(a,n,v,rel) for each adjective-noun pairby varying both the terms v and rel.In order to generate stimuli covering a wide rangeof model-derived paraphrases corresponding to differ-ent degrees of likelihood, for each adjective-noun com-bination we divided the set of the derived meanings intothree probability ?bands?
(High, Medium, and Low) ofequal size and randomly chose one interpretation fromeach band.
The division ensured that the experimen-tal stimuli represented the model?s behavior for likelyand unlikely paraphrases and enabled us to test the hy-pothesis that likely paraphrases correspond to high rat-ings and unlikely paraphrases correspond to low rat-ings.
We performed separate divisions for object-relatedand subject-related paraphrases resulting in a total of sixinterpretations for each adjective-noun combination, aswe wanted to determine whether there are differencesin the model?s predictions with respect to the argumentfunction (i.e., object or subject) and also because wewanted to compare experimentally-derived adjective bi-ases against model-derived biases.
Example stimuli (withobject-related interpretations only) are shown in Table 3for each of the nine adjectives.Our experimental design consisted of the factorsadjective-noun pair (Pair), grammatical function (Func)and probability band (Band).
The factor Pair included 90adjective-noun combinations.
The factor Func had twolevels, subject and object, whereas the factor Band hadthree levels, High, Medium and Low.
This yielded a to-tal of Pair  Func  Band = 90 2 3 = 540 stim-uli.
The number of the stimuli was too large for sub-jects to judge in one experimental session.
We limitedthe size of the design by selecting a total of 270 stimulias follows: our initial design created two sets of stimuli,270 subject-related stimuli and 270 object-related stim-uli.
For each stimuli set we randomly selected five nounsfor each of the nine adjectives together with their cor-responding interpretations in the three probability bands(High, Medium, Low).
This yielded a total of Pair Func  Band = 4523 = 270 stimuli.
This way, stim-uli were created for each adjective in both subject-relatedand object-related interpretations.We administered the 270 stimuli to two separate sub-ject groups.
Each group saw 135 stimuli consistingof interpretations for all adjectives with both subject-related and object-related interpretations.
Each exper-imental item consisted of an adjective-noun pair anda sentence paraphrasing its meaning.
Paraphrases werecreated by the experimenter by converting the model?soutput to a simple phrase, usually a noun modified by arelative clause.
A native speaker of English was askedto confirm that the paraphrases were syntactically well-formed.3.1.2 ProcedureThe experimental paradigm was Magnitude Estima-tion (ME), a technique standardly used in psychophysicsto measure judgments of sensory stimuli Stevens (1975),which Bard et al (1996) and Cowart (1997) have appliedto the elicitation of linguistic judgments.
ME has beenshown to provide fine-grained measurements of linguis-tic acceptability which are robust enough to yield statis-tically significant results, while being highly replicableboth within and across speakers.ME requires subjects to assign numbers to a series oflinguistic stimuli in a proportional fashion.
Subjects arefirst exposed to a modulus item, to which they assignan arbitrary number.
All other stimuli are rated propor-tional to the modulus.
In this way, each subject can es-tablish their own rating scale, thus yielding maximallyfine-grained data and avoiding the known problems withthe conventional ordinal scales for linguistic data (Bardet al, 1996; Schu?tze, 1996).In the present experiment, the subjects were instructedto judge how well a sentence paraphrases an adjective-noun combination proportional to a modulus item.
Theexperiment was conducted remotely over the Inter-net.
Subjects accessed the experiment using their webbrowser, which established an Internet connection to theexperimental server running WebExp 2.1 (Keller et al,1998), an interactive software package for administer-ing web-based psychological experiments.
Subjects firstsaw a set of instructions that explained the ME tech-nique and included some examples, and had to fill in ashort questionnaire including basic demographic infor-mation.
Each subject group saw 135 experimental stim-uli (i.e., adjective-noun pairs and their paraphrases).
Sub-jects were assigned to subject groups at random, and arandom stimulus order was generated for each subject.3.1.3 SubjectsThe experiment was completed by 60 unpaid volunteers,all native speakers of English.
Subjects were recruitedvia postings to local Usenet newsgroups.3.2 ResultsAs is standard in magnitude estimation studies (Bard etal., 1996), statistical tests were done using geometricmeans to normalize the data (the geometric mean is themean of the logarithms of the ratings).We first performed an analysis of variance (ANOVA) todetermine whether there is a relation between the para-phrases derived by the model and their perceived likeli-hood.
In particular, we tested the hypothesis that mean-ings assigned high probabilities by the model are per-ceived as better paraphrases by the subjects and cor-respondingly that meanings with low probabilities areperceived as worse paraphrases.
The descriptive statis-tics for log-transformed model-derived probabilities areshown in Table 4.
The ANOVA revealed that the Prob-ability Band effect was significant, in both by-subjectsand by-items analyses: F1(2,118) = 101.46, p < .01;F2(2,88) = 29.07, p < .01.
The geometric mean ofthe ratings in the High band was ?.0005, compared toMedium items at ?.1754 and Low items at ?.2298 (seeTable 5).
Post-hoc Tukey tests indicated that the differ-ences between all pairs of conditions were significant at?
= .01 in the by-subjects analysis.
The difference be-tween High and Medium items as well as High and Lowitems was significant at ?
= .01 in the by-items analysis,whereas the difference between Medium and Low itemsdid not reach significance.
These results show that mean-ing paraphrases derived by the model correspond to hu-man intuitions: paraphrases assigned high probabilitiesby the model are perceived as better than paraphrases thatare assigned low probabilities.We further explored the linear relationship betweenthe subjects?
rankings and the corpus-based model, usingcorrelation analysis.
The elicited judgments were com-Rank ?
SD SE Min MaxHigh ?20.5 1.71 .18 ?24.0 ?15.9Medium ?22.6 .99 .10 ?25.2 ?20.2Low ?23.9 .86 .18 ?25.9 ?22.5Table 4: Descriptive statistics for model-derived proba-bilitiesRank ?
SD SE Min MaxHigh ?.0005 .2974 .0384 ?.68 .49Medium ?.1754 .3284 .0424 ?.70 .31Low ?.2298 .3279 .0423 ?.68 .37Table 5: Descriptive statistics for Experiment 1, by sub-jectspared with the interpretation probabilities which wereobtained from the model described in Section 2 to exam-ine the extent to which the proposed interpretations cor-relate with human intuitions.
A comparison between ourmodel and the human judgments yielded a Pearson corre-lation coefficient of .40 (p < .01, N = 270).
This verifiesthe Probability Band effect discovered by the ANOVA, inan analysis which compares the individual interpretationlikelihood for each item with elicited interpretation pref-erences, instead of collapsing all the items in three equiv-alence classes (i.e., High, Medium, Low).
In order toevaluate whether the grammatical function has any effecton the relationship between the model-derived meaningsand the human judgments, we split the items into thosethat received a subject interpretation versus those that re-ceived an object interpretation.
A comparison betweenour model and the human judgments yielded a corre-lation of r = .53 (p < .01, N = 135) for object-relateditems and a correlation of r = .21 (p < .05, N = 135)for subject-related items.
Note that a weaker correlationis obtained for subject-related interpretations.
One expla-nation for that could be the parser?s performance, i.e., theparser is better at extracting verb-object tuples than verb-subject tuples.
Another hypothesis (which we test be-low) is that most adjectives included in the experimentalstimuli have an object-bias, and therefore subject-relatedinterpretations are generally less preferred than object-related ones.An important question is how well humans agree intheir paraphrase judgments for adjective-noun combina-tions.
Inter-subject agreement gives an upper bound forthe task and allows us to interpret how well the model isdoing in relation to humans.
For each subject group weperformed correlations on the elicited judgments usingleave-one-out resampling (Weiss and Kulikowski, 1991).For the first group, the average inter-subject agreementwas .67 (Min = .03, Max = .82, SD = .14), and for thesecond group .65 (Min = .05, Max = .82, SD = .14).This means that our model performs satisfactorily giventhat humans do not perfectly agree in their judgments.The elicited judgments can be further used to deriveAdj Model ?
SD SE Subjects ?
SD SEdiffi-pOBJ ?21.6 1.36 .04pOBJ .07 .36 .07cult SUBJ ?21.8 1.34 .05 SUBJ ?.29 .28 .05easypOBJ ?21.6 1.51 .05pOBJ .10 .34 .06SUBJ ?22.1 1.36 .06 SUBJ ?.14 .23 .04fast OBJ ?24.2 1.27 .13 OBJ ?.35 .29 .05pSUBJ ?23.8 1.40 .14pSUBJ ?.15 .45 .08good OBJ ?22.1 1.28 .06 OBJ ?.01 .39 .07SUBJ ?22.3 1.10 .07 SUBJ ?.16 .30 .05hardpOBJ ?21.7 1.53 .06pOBJ .01 .34 .06SUBJ ?22.1 1.35 .06 SUBJ ?.25 .24 .04rightpOBJ ?21.7 1.36 .04pOBJ ?.01 .25 .05SUBJ ?21.8 1.24 .04 SUBJ ?.24 .44 .08safe OBJ ?22.7 1.48 .10pOBJ .01 .25 .05pSUBJ ?22.4 1.59 .12 SUBJ ?.34 .43 .08slow OBJ ?22.5 1.53 .08 OBJ ?.30 .48 .08SUBJ ?22.3 1.50 .07pSUBJ ?.09 .24 .04wrong OBJ ?23.2 1.33 .08pOBJ ?.04 .25 .05SUBJ ?23.3 1.30 .08 SUBJ ?.24 .37 .08Table 6: Log-transformed model-derived and subject-based argument preferences for polysemous adjectivesthe grammatical function preferences (i.e., subject or ob-ject) for a given adjective.
In particular, we can determinewhich is the preferred interpretation for individual adjec-tives and compare these preferences against the ones pro-duced by our model.
Argument preferences can be easilyderived from the model?s output by comparing subject-related and object-related paraphrases.
For each adjectivewe gathered the subject and object-related interpretationsderived by the model and performed an ANOVA in orderto determine the significance of the Grammatical Func-tion effect.We interpret a significant effect as bias towards a par-ticular grammatical function.
We classify an adjective asobject-biased if the mean of the judgments for the objectinterpretation of this particular adjective is larger than themean for the subject interpretation; subject-biased adjec-tives are classified accordingly, whereas adjectives forwhich no effect of Grammatical Function is found areclassified as equi-biased.
Table 6 shows the biases for thenine adjectives as derived by our model.
The presenceof the symbolpindicates significance of the Grammat-ical Function effect as well as the direction of the bias.Argument preferences were elicited from human sub-jects in a similar fashion.
For each adjective we gatheredthe elicited responses pertaining to subject- and object-related interpretations and performed an ANOVA.
The bi-ases and the significance of the Grammatical Functioneffect (p) are shown in Table 6.Comparison of the biases derived from the model withones derived from the elicited judgments shows that themodel and the humans are in agreement for all adjec-tives but slow, wrong and safe.
On the basis of humanjudgments slow has a subject bias, whereas wrong hasan object bias.
Although the model could not reproducethis result there is a tendency in the right direction (seeTable 6).Note that in our correlation analysis reported above theelicited judgments were compared against model-derivedparaphrases without taking argument preferences into ac-count.
We would expect a correct model to produce intu-itive meanings at least for the interpretation a given ad-jective favors.
We further examined the model?s behav-ior by performing separate correlation analyses for pre-ferred and dispreferred biases as determined previouslyby the ANOVAs conducted for each adjective.
Since theadjective good was equi-biased we included both biases(i.e., object-related and subject-related) in both correla-tion analyses.
The comparison between our model andthe human judgments yielded a Pearson correlation co-efficient of .52 (p < .01, N = 150) for the preferred in-terpretations and a correlation of .23 (p < .01, N = 150)for the dispreferred interpretations.
The result indicatesthat our model is particularly good at deriving meaningscorresponding to the argument-bias for a given adjective.However, the dispreferred interpretations also correlatesignificantly with human judgments, which suggests thatthe model derives plausible interpretations even in caseswhere the default argument bias is overridden.4 Experiment 2: Comparison againstNaive BaselineThe probabilistic model described in Section 2 explic-itly takes adjective/adverb and verb co-occurrences intoaccount.
However, one could derive meanings for poly-semous adjective-noun combinations by solely concen-trating on verb-noun relations, ignoring thus the adjec-tive/adverb and verb dependencies.
For example, in or-der to interpret the combination easy problem we couldsimply take into account the types of activities whichare related with problems (i.e., solving them, settingthem, etc.).
This simplification is consistent with Puste-jovsky?s (1995) claim that polysemous adjectives likeeasy are predicates, modifying the events associated withthe noun.
A ?naive?
or ?baseline?
model would be onewhich simply takes into account the number of times thenoun in the adjective-noun pair acts as the subject or ob-ject of a given verb, ignoring the adjective completely.4.1 Naive ModelGiven an adjective-noun combination we are interestedin finding the verbs whose object or subject is the nounappearing in the adjective-noun combination.
This can besimply expressed as P(vjrel,n), the conditional probabil-ity of a verb v given an argument-noun relation rel,n:P(vjrel,n) = f (v,rel,n)f (rel,n)(18)The model in (18) assumes that the meaning of anadjective-noun combination is independent of the ad-jective in question.
The model in (18) would come upwith the same probabilities for fast plane and wrongplane since it does not take the identity of the modi-fying adjective into account.
We estimated the frequen-cies f (v,rel,n) and f (rel,n) from verb-object and verb-subject tuples extracted from the BNC using Cass (Ab-ney, 1996).4.2 MethodUsing the naive model we calculated the meaning prob-ability for each of the 270 stimuli included in Experi-ment 1.
Through correlation analysis we explored thelinear relationship between the elicited judgments andthe naive baseline model.
We further directly comparedthe two models, our initial, linguistically more informedmodel, and the naive baseline.4.3 ResultsUsing correlation analysis we explored which modelperforms better at deriving meanings for adjective-nouncombinations.
A comparison between the naive model?sprobabilities and the human judgments yielded a Pearsoncorrelation coefficient of .25 (p < .01, N = 270).
Recallthat we obtained a correlation of .40 (p < .01, N = 270)when comparing our original model to the human judg-ments.
Not surprisingly the two models are intercorre-lated (r = .38, p < .01, N = 270).
An important questionis whether the difference between the two correlation co-efficients (r = .40 and r = .25) is due to chance.
Compar-ison of the two correlation coefficients revealed that theirdifference was significant (t(267) = 2.42, p < .01).
Thismeans that our original model performs reliably betterthan a naive baseline at deriving interpretations for poly-semous adjective-noun combinations.We further compared the naive baseline model andthe human judgments separately for subject-related andobject-related items.
The comparison yielded a correla-tion of r = .29 (p < .01, N = 135) for object interpreta-tions.
Recall that our original model yielded a correlationcoefficient of .53.
The two correlation coefficients weresignificantly different (t(132) = 3.03, p < .01).
No cor-relation was found for the naive model when comparedagainst elicited subject interpretations (r = .09, p = .28,N = 135).5 ConclusionsIn this paper we showed how adjectival meanings can beacquired from a large corpus and provided a probabilis-tic model which derives a preference ordering on the setof possible interpretations.
Our model does not only ac-quire clusters of meanings (following Vendler?s (1968)insight) but furthermore can be used to obtain argumentpreferences for a given adjective.We rigorously evaluated the results of our model byeliciting paraphrase judgments from subjects naive to lin-guistic theory.
Comparison between our model and hu-man judgments yielded a reliable correlation of .40 whenthe upper bound for the task (i.e., inter-subject agree-ment) is approximately .65.
Furthermore, our model per-formed reliably better than a naive baseline model, whichonly achieved a correlation of .25.
Although adjective-noun polysemy is a well researched phenomenon inthe theoretical linguistics literature, the experimental ap-proach advocated here is new to our knowledge.Furthermore, the proposed model can be viewed ascomplementary to linguistic theory: it automatically de-rives a ranking of meanings, thus distinguishing likelyfrom unlikely interpretations.
Even if linguistic theorywas able to enumerate all possible interpretations for agiven adjective (note that in the case of polysemous ad-jectives we would have to take into account all nounsor noun classes the adjective could possibly modify)it has no means to indicate which ones are likely andwhich ones are not.
Our model fares well on both tasks.It recasts the problem of adjective-noun polysemy in aprobabilistic framework deriving a large number of in-terpretations not readily available from linguistic intro-spection.
The information acquired from the corpus canbe also used to quantify the argument preferences of agiven adjective.
These are only implicit in the lexicalsemantics literature where certain adjectives are exclu-sively given a verb-subject or verb-object interpretation.We have demonstrated that we can empirically derive ar-gument biases for a given adjective that correspond tohuman intuitions.ReferencesSteve Abney.
1996.
Partial parsing via finite-state cascades.
InJohn Carroll, editor, Workshop on Robust Parsing, pages 8?15, Prague.
European Summer School in Logic, Languageand Information.Ellen Gurman Bard, Dan Robertson, and Antonella Sorace.1996.
Magnitude estimation of linguistic acceptability.Language, 72(1):32?68.Lou Burnard, 1995.
Users Guide for the British National Cor-pus.
British National Corpus Consortium, Oxford Univer-sity Computing Service.Steffan Corley, Martin Corley, Frank Keller, Matthew W.Crocker, and Shari Trewin.
2000.
Finding syntactic struc-ture in unparsed corpora: The Gsearch corpus query system.Computers and the Humanities.
To appear.Wayne Cowart.
1997.
Experimental Syntax: Applying Ob-jective Methods to Sentence Judgments.
Sage Publications,Thousand Oaks, CA.Frank Keller, Martin Corley, Steffan Corley, Lars Konieczny,and Amalia Todirascu.
1998.
WebExp: A Java toolboxfor web-based psychological experiments.
Technical Re-port HCRC/TR-99, Human Communication Research Cen-tre, University of Edinburgh.James Pustejovsky.
1995.
The Generative Lexicon.
The MITPress, Cambridge, MA.Carson T. Schu?tze.
1996.
The Empirical Base of Linguis-tics: Grammaticality Judgments and Linguistic Methodol-ogy.
University of Chicago Press, Chicago.S.
Smith Stevens.
1975.
Psychophysics: Introduction to itsPerceptual, Neural, and Social Prospects.
John Wiley, NewYork.Zeno Vendler.
1968.
Adjectives and Nominalizations.
Mou-ton, The Hague.Sholom M. Weiss and Casimir A. Kulikowski.
1991.
Com-puter Systems that Learn: Classification and PredictionMethods from Statistics, Neural Nets, Machine Learning,and Expert Systems.
Morgan Kaufmann, San Mateo, CA.
