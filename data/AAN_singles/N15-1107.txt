Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 1024?1029,Denver, Colorado, May 31 ?
June 5, 2015.c?2015 Association for Computational LinguisticsParadigm classification in supervised learning of morphologyMalin AhlbergSpr?akbankenUniversity of Gothenburgmalin.ahlberg@gu.seMarkus ForsbergSpr?akbankenUniversity of Gothenburgmarkus.forsberg@gu.seMans HuldenDepartment of LinguisticsUniversity of Colorado Bouldermans.hulden@colorado.eduAbstractSupervised morphological paradigm learningby identifying and aligning the longest com-mon subsequence found in inflection tableshas recently been proposed as a simple yetcompetitive way to induce morphological pat-terns.
We combine this non-probabilistic strat-egy of inflection table generalization with adiscriminative classifier to permit the recon-struction of complete inflection tables of un-seen words.
Our system learns morphologicalparadigms from labeled examples of inflectionpatterns (inflection tables) and then producesinflection tables from unseen lemmas or baseforms.
We evaluate the approach on datasetscovering 11 different languages and show thatthis approach results in consistently higher ac-curacies vis-`a-vis other methods on the sametask, thus indicating that the general methodis a viable approach to quickly creating high-accuracy morphological resources.1 IntroductionUse of detailed and sophisticated morphological fea-tures has been found to be crucial for many down-stream NLP tasks, including part-of-speech tag-ging and parsing (Tseng et al, 2005; Spoustov?a etal., 2007).
However, creating an accurate wide-coverage morphological analyzer for a new lan-guage that can be used in tandem with other higher-level analyses is an arduous task.Learning word inflection patterns by organizingrelated word-forms into morphological paradigmsbased on the longest common subsequence (LCS)found in an inflection table has recently beenproposed as a method for supervised and semi-supervised induction of morphological processingtools from labeled data (Ahlberg et al, 2014).
Also,the argument that the LCS shared by different in-flected forms of a word?even if discontinuouswithin a word?corresponds strongly to a cross-linguistic notion of a ?stem?
has later been advancedindependently on grounds of descriptive economyand minimum description length (Lee and Gold-smith, 2014).We used this idea in (Ahlberg et al, 2014) tocreate a relatively simple-to-implement system thatlearns paradigms from example inflection tables andis then able to reconstruct inflection tables for un-seen words by comparing suffixes of new base formsto base forms seen during training.
The systemperforms well on available datasets and results inhuman-readable and editable output.
The longestcommon subsequence strategy itself shows little biastoward any specific morphological process such asprefixation, suffixation, or infixation.
Using themodel, we argued, a selection of ready-inflected ta-bles could be quickly provided by a linguist, allow-ing rapid development of morphological resourcesfor languages for which few such resources exist.Potentially, however, the model?s commitment toa simple suffix-based learner is a weakness.
Toassess this, we evaluate a similar LCS-based gen-eralization system with a more refined discrimina-tive classifier that takes advantage of substrings inthe example data and performs careful feature se-lection.
We show that much higher accuracies canbe achieved by combining the LCS paradigm gen-eralization strategy with such a feature-based classi-1024fier that assigns unknown words to the LCS-learnedparadigm based on substring features taken fromword edges.
This holds in particular for languageswhere paradigmatic behavior is triggered by mate-rial in the beginning of a word (e.g.
German verbs).We present experiments on 18 datasets in 11 lan-guages varying in morphological complexity.
In allthe experiments, the task is to reconstruct a com-plete inflection table from a base form, which usu-ally corresponds to the lemma or dictionary form ofa noun, verb, or adjective.
The experiments are di-vided into two sets.
In the first, we use an earlierdataset (Durrett and DeNero, 2013) of Finnish, Ger-man, and Spanish to compare against other methodsof paradigm learning.
In the second, we use a morecomprehensive and complex dataset we have devel-oped for 8 additional languages.
This new datasetis less regular and intended to be more realistic inthat it also features defective or incomplete inflec-tion tables and inflection tables containing variousalternate forms, naturally making the classificationtask substantially more difficult.1Overall, supervised and semi-supervised learningof morphology by generalizing patterns from inflec-tion tables is an active research field.
Recent worksharing our goals includes Toutanova and Cherry(2009), Dreyer and Eisner (2011), which works witha fully Bayesian model, Dinu et al (2012), Eskan-der et al (2013), which attempts to learn lexiconsfrom morphologically annotated corpora, and Dur-rett and DeNero (2013), who train a discriminativemodel that learns transformation rules between wordforms.
We directly compare our results against thelast using the same dataset.The paper is organized as follows: section 2 con-tains the experimental setup, section 3 the datasets,and section 4 the results and discussion.2 MethodAs a first step, our system converts inflection tablesinto paradigms using a procedure given in Hulden(2014).
The system generalizes concrete inflectiontables by associating the common symbol subse-quences shared by the words (the LCS) with vari-1The data and the code is available at our websitehttps://svn.spraakbanken.gu.se/clt/naacl/2015/extractgj?fgj?fgj?fgjafargjafirgjafirgj?fumgjafah?fnh?fnh?fnhafnarhafnirhafnirh?fnumhafnax1 ?
x2x1 ?
x2x1 ?
x2x1 a x2 ar x1 a x2 ir x1 a x2 ir x1 ?
x2 um x1 a x2 agj?f?generalize classify &reconstructin?ection tables paradigms in?ection tableFigure 1: General overview of the system, exempli-fied using Icelandic nouns.
First, a large number of in-flection tables are generalized into a smaller number ofparadigms; the generalization of the table for h?ofn ?har-bor?
into a paradigm is illustrated here.
At classifica-tion time, an unknown base form is classified into oneof the learned paradigms and its inflection table is recon-structed, illustrated here by gj?of ?present?.ables.
These variables represent abstractions that attable reconstruction time can correspond to any se-quence of one or more symbols.
As many inflec-tion tables of different words are identical after as-signing the common parts to ?variables,?
this pro-cedure results in a comparatively small number ofparadigms after being input a large number of in-flection tables.
The process is illustrated in Figure 1.During generalization, the forms that gave rise toa particular paradigm are stored and later used fortraining a classifier to assign unknown base formsto paradigms.
Having a number of paradigms at ourdisposal by this generalization method, the task ofreconstructing an inflection table for an unseen baseform in effect means picking the correct paradigmfrom among the ones generalized, a standard classi-fication task of choosing the right/best paradigm.After seeing a number of inflection tables gener-alized into abstract paradigms as described above,the task we evaluate is how well complete inflectiontables can be reconstructed from only seeing an un-known base form.
To this end, we train a ?one-vs-the-rest?
linear multi-class support vector machine(SVM).2For each example base form wbithat is amember of paradigm pj, we extract all substringsfrom wbifrom the left and right edges, and use thoseas binary features corresponding to the paradigm pj.2Using LIBLINEAR (Fan et al, 2008) with L2-regularization.1025For example, during training, the German verb lesenwould have the following binary features activated:{#l, #le, #les, #lese, #lesen, #lesen#, lesen#, esen#,sen#, en#, n#}.Before applying the classifier to an unseen baseform and reconstructing the corresponding inflectiontable, many competing paradigms can be ruled outas being ill-matched simply by inspecting the baseform.
For example, the infinitive for the paradigmcontaining the English verb sing is generalized asx1+i+x2.
At classification time of a verb like run,this paradigm can be ruled out due to incompatibil-ity, as there is no i in run, and so the infinitive cannotbe generated.
Likewise, the Icelandic paradigm seenin Figure 1 can be ruled out for the base form hest?horse?, as the base form does not contain?o.
TheSVM-classifier may indeed suggest such paradigmassignments, but such classifications are ignored andthe highest scoring compatible paradigm is selectedinstead.
These additional constraints on possiblebase form-paradigm pairings are a general feature ofthe LCS-strategy and are not at all tied to the classi-fication method here.2.1 Feature selectionIn order to eliminate noise features, we performedfeature selection using the development set.
We si-multaneously tuned the SVM soft-margin penaltyparameter C, as well as the length and type (pre-fix/suffix) of substrings to include as features.
Moreconcretely, we explored the values using a gridsearch over C = 0.01 .
.
.
5.0, with a growing se-quence gap (Hsu et al, 2003), as well as tuning themaximum length of anchored substring features touse (3 .
.
.
9), and whether to include prefix-anchoredsubstrings at all (0/1).
In the second experiment,where cross-validation was used, we performed thesame tuning procedure on each fold?s developmentset.3 DataFor the first experiment, we use the datasets pro-vided by Durrett and DeNero (2013).
This datasetcontains complete inflection tables for Germannouns and verbs (DE-NOUNS, DE-VERBS), Finnishverbs and nouns combined with adjectives (FI-VERBS, FI-NOUNADJ), and Spanish verbs (ES-VERBS).
The number of inflection tables in thisset ranges from 2,027 (DE-VERBS) to 7,249 (FI-VERBS).
From these tables, 200 were held out fordevelopment and 200 for testing, following the splitsthat previous authors have used (Durrett and DeN-ero, 2013; Ahlberg et al, 2014) to ensure a fair base-line.3For the second experiment, we collected addi-tional inflection tables from Catalan (CA), English(EN), French (FR), Galician (GL), Italian (IT), Por-tuguese (PT), Russian (RU) (all from the FreeLingproject (Padr?o and Stanilovsky, 2012)) and Maltese(MT) (Camilleri, 2013).4These inflection tables areoften incomplete or defective and some contain veryrarely occurring grammatical forms.
Many alternateforms are also given.
To avoid having to account forrare or historical forms, we filtered out grammaticalforms (slots) that occur in less than ?1% of all in-flection tables.
We also performed an independentcross-check with Wiktionary and removed some in-flection table slots that did not appear in that re-source.
We further limited the number of inflectiontables to 5,000.
In the second experiment, we alsosplit each dataset into 5 folds for cross-validation(maximally 4,000 tables for training, 500 for devel-opment and 500 for testing for each fold).4 Results and discussionIn the main results tables 1, 2, and 3 we reportthe per table accuracy and per form accuracy in re-constructing complete inflection tables from unseenbase forms.
The per table accuracy is the percentageof inflection tables that are perfectly reconstructedfrom the base form.
The per form accuracy is thepercentage of correct forms in the reconstructed ta-ble.
The associated oracle scores, which indepen-dently provide a measure of generalization power ofthe LCS-method, represent the maximal percentageachievable by an oracle classifier that always picks3The development and test data for the first experiment hadbeen filtered to not contain any of the 200 most frequentlyoccurring forms in the language (Durrett and DeNero, 2013);this may result in an easier classification task because themaneuver in effect ensures that words belonging to irregularparadigms?i.e.
those which would otherwise be difficult toclassify correctly?are never evaluated against.4The FreeLing data also included Russian verbs.
However,this data set was deemed too incomplete to be useful and wasleft out.1026Data Per table accuracy Per form accuracy Oracle acc.per form (table)SVM AFH14 D&DN13 SVM AFH14 D&DN13DE-VERBS 91.5 68.0 85.0 98.11 97.04 96.19 99.70 (198/200)DE-NOUNS 80.5 76.5 79.5 89.88 87.81 88.94 100.00 (200/200)ES-VERBS 99.0 96.0 95.0 99.92 99.52 99.67 100.00 (200/200)FI-VERBS 94.0 92.5 87.5 97.14 96.36 96.43 99.00 (195/200)FI-NOUNS-ADJS 85.5 85.0 83.5 93.68 91.91 93.41 100.00 (200/200)Table 1: Results on experiment 1.
Here AFH14 stands for Ahlberg et al (2014) and D&DN for Durrett and DeNero(2013).
The SVM-columns show the results of the current method.the best learned paradigm for an unseen base form.In experiment 2, where the correct forms may con-sist of several alternatives, we only count a form ascorrect if all alternatives are given and all are correct.For example, the verb dream in English lists twoalternative past participles, dreamed and dreamt,which both must be reconstructed for the past par-ticiple form to count as being correct.Experiment 1The accuracies obtained on the first three-languagecomparison experiment are shown in Table 1.
Here,we see a consistent improvement upon the max-suff -strategy (AFH14) that simply picks the longestmatching suffix among the base forms seen and as-signs the unseen word to the same paradigm (break-ing ties by paradigm frequency), as well as improve-ment over other learning strategies (D&DN13).
Par-ticularly marked is the improved accuracy on Ger-man verbs.
We assume that this is because Germanverb prefixes, which are ignored in a suffix-basedclassifier, contain information that is useful in clas-sifying verb behavior.
German verbs that contain so-called inseparable prefixes like miss-, ver-, wider-do not prefix a ge- in the past participle form.
For ex-ample: kaufen?
gekauft, brauchen?
gebraucht,legen ?
gelegt, but verkaufen ?
verkauft, wider-legen ?
widerlegt, missbrauchen ?
missbraucht,reflecting the replacement of the standard ge- by theinseparable prefix.
There are many such inseparableprefixes that immediately trigger this behavior (al-though some prefixes only occasionally show insep-arable behavior), yet this information is lost whenonly looking at suffixes at classification time.
Thisanalysis is supported by the fact that, during featureselection, German verbs was the only dataset in thisfirst experiment where word prefixes were not re-moved by the feature selection process.Experiment 2The results of the second experiment are given intables 2 (per table accuracy) and 3 (per form ac-curacy).
The tables contain information about howmany inflection tables were input on average over5 folds to the learner (#tbl), how many paradigmsthis reduced to (#par), and how many forms (slots)each paradigm has (#forms).
The mfreq column isa baseline where the classifier always picks the mostpopulated paradigm, i.e.
the paradigm that resultedfrom combining the largest number of different in-flection tables by the LCS process.
The AFH14shows the performance of a maximal suffix match-ing classifier, identical to that used in Ahlberg et al(2014).DiscussionOverall, the results support earlier claims that theLCS-generalization appears to capture paradigmaticbehavior well, especially if combined with care-ful classification into paradigms.
There is a clearand consistent improvement over baselines that usethe same data sets.
In addition, the SVM-classifieryields results comparable, and in many cases bet-ter, to using a maximum suffix classifier and addi-tionally having access to raw corpus data in the lan-guage, a semi-supervised experiment reported sepa-rately in Ahlberg et al (2014).
In this work we havenot attempted to extend the current method to sucha semi-supervised scenario, although such an exten-sion seems both interesting and possible.1027Data #tbl #par mfreq AFH14 SVM OracleDE-N 2,210 66 18.99 76.09 77.68 98.99DE-V 1,621 125 52.77 65.02 83.59 95.45ES-V 3,243 90 70.42 92.25 93.48 96.59FI-N&A 4,000 233 26.52 83.20 82.84 98.12FI-V 4,000 204 43.04 91.88 91.64 94.76MT-V 826 200 10.68 18.83 38.64 85.63CA-N 4,000 49 44.12 94.00 94.92 99.44CA-V 4,000 164 60.44 90.76 93.40 98.48EN-V 4,000 161 77.12 89.40 90.00 97.40FR-N 4,000 57 92.16 91.60 93.96 98.72FR-V 4,000 95 81.52 93.72 96.48 98.80GL-N 4,000 24 88.36 90.48 95.08 99.80GL-V 3,212 101 45.21 58.92 60.87 98.95IT-N 4,000 39 83.84 92.32 93.76 99.40IT-V 4,000 115 63.96 89.68 91.56 98.68PT-N 4,000 68 74.52 88.12 90.88 99.04PT-V 4,000 92 62.00 76.96 80.20 99.20RU-N 4,000 260 15.76 64.12 66.36 96.80Table 2: Per table accuracy results on the second exper-iment.
5-fold cross-validation is used throughout.
The#tbl-column shows the number of inflection tables inputto the LCS-learner and the #par column shows the num-ber of resulting unique paradigms.
The mfreq-column il-lustrates a baseline of simply picking the most frequentparadigm, while AFH14 is the strategy of finding thelongest suffix match to the base forms in the training data(Ahlberg et al, 2014).
The SVM-column shows the re-sults discussed in this paper.Data #forms mfreq AFH14 SVM OracleDE-N 8 57.36 89.72 90.25 99.69DE-V 27 87.35 96.12 95.28 99.20ES-V 57 93.80 98.72 98.83 99.47FI-N&A 233 52.15 91.03 91.06 98.95FI-V 54 70.38 95.27 95.22 96.76MT-V 16 39.75 54.66 61.15 95.49CA-N 2 71.30 96.89 97.33 97.93CA-V 53 86.89 98.18 98.89 99.77EN-V 6 91.43 95.93 96.16 99.28FR-N 2 93.24 92.48 94.68 99.08FR-V 51 91.47 97.09 98.33 99.02GL-N 2 91.92 92.82 95.38 99.78GL-V 70 94.89 98.48 98.32 99.67IT-N 3 89.36 93.38 94.59 97.44IT-V 51 89.51 97.76 98.21 99.64PT-N 4 83.35 89.78 91.97 98.60PT-V 65 92.62 96.81 97.20 99.68RU-N 12 25.16 88.19 89.35 99.15Table 3: Per form accuracy results on the second exper-iment.
5-fold cross-validation is used throughout.
The#forms-column shows the number of different slots in theparadigms.
Other columns are as in table 2.In some cases, we see a significant drop betweenthe per-form and the per-table accuracy.
For exam-ple, in the case of Russian nouns, per table accu-racy is at 66.36%, while the per-form accuracy is89.35%.
This effect is explained?not only in theRussian case but in many others?by the existenceof similar paradigms that differ only in very fewforms.
If the classifier picks an incorrect, but closelyrelated paradigm, most forms may be produced cor-rectly although the entire reconstructed table countsas wrong if even a single form is incorrect.A few outliers remain.
The Maltese verbs, whichexhibit Semitic interdigitation in some paradigms,seem to generalize fairly well, and have a per formoracle score of 95.49 (shown in table 3).
However,this is not reflected in the relatively low per formaccuracy (61.15), which warrants further analysis.
Itmay be an indication of that the correct paradigm issimply difficult to ascertain based only on the lemmaform, or that additional features could be developed,perhaps ones that are discontinuous in the word.An obvious extension to the current method is toinspect a suggested reconstructed table holistically,i.e., not relying only on base form features.
That is,one could avoid making a commitment to a particu-lar paradigm based solely on the features of the baseform, and instead also include features from all theforms that a paradigm would generate.
Such fea-tures are of course available in the training data inthe various forms in an inflection table.
Featuresfrom the seen forms could be used to rate compat-ibility since an incorrect reconstruction of an inflec-tion table may likely be identified by its tendency toproduce phonotactic patterns rarely or never seen inthe training data.With relatively few paradigms learned from col-lections of word forms, one can achieve fairly highcoverage on unseen data.
In principle, for example,the 13 most frequently used paradigms of Spanishverbs suffice to cover 90% of all verbs (per token).A useful application of this is rapid language re-source development?one can elicit from a speakera small number of well-chosen inflection tables, e.g.all forms of specific nouns, verbs, adjectives; gener-alize these inflection tables into paradigms; and usethis information to deduce the possible morphologi-cal classes for a majority of unseen word forms.1028ReferencesMalin Ahlberg, Markus Forsberg, and Mans Hulden.2014.
Semi-supervised learning of morphologicalparadigms and lexicons.
In Proceedings of the 14thConference of the European Chapter of the Associ-ation for Computational Linguistics, pages 569?578,Gothenburg, Sweden.
Association for ComputationalLinguistics.John J. Camilleri.
2013.
A computational grammar andlexicon for Maltese.
Master?s thesis, Chalmers Uni-versity of Technology.
Gothenburg, Sweden.Liviu P Dinu, Vlad Niculae, and Octavia-Maria S?ulea.2012.
Learning how to conjugate the Romanian verb:rules for regular and partially irregular verbs.
InProceedings of the 13th Conference of the EuropeanChapter of the Association for Computational Linguis-tics, pages 524?528.
Association for ComputationalLinguistics.Markus Dreyer and Jason Eisner.
2011.
Discover-ing morphological paradigms from plain text usinga Dirichlet process mixture model.
In Proceedingsof the Conference on Empirical Methods in NaturalLanguage Processing, pages 616?627.
Association forComputational Linguistics.Greg Durrett and John DeNero.
2013.
Supervised learn-ing of complete morphological paradigms.
In Pro-ceedings of NAACL-HLT, pages 1185?1195.Ramy Eskander, Nizar Habash, and Owen Rambow.2013.
Automatic extraction of morphological lexiconsfrom morphologically annotated corpora.
In Proceed-ings of the 2013 Conference on Empirical Methods inNatural Language Processing, pages 1032?1043.
As-sociation for Computational Linguistics.Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-RuiWang, and Chih-Jen Lin.
2008.
LIBLINEAR: A li-brary for large linear classification.
Journal of Ma-chine Learning Research, 9:1871?1874.Chih-Wei Hsu, Chih-Chung Chang, Chih-Jen Lin, et al2003.
A practical guide to support vector classifica-tion.Mans Hulden.
2014.
Generalizing inflection tables intoparadigms with finite state operations.
In Proceed-ings of the 2014 Joint Meeting of SIGMORPHON andSIGFSM, pages 29?36.
Association for ComputationalLinguistics.Jackson L Lee and John A Goldsmith.
2014.
Complexityacross morphological paradigms: a minimum descrip-tion length approach to identifying inflectional stems.In Poster at the MorphologyFest: Symposium on Mor-phological Complexity, Indiana University, Blooming-ton.Llu?
?s Padr?o and Evgeny Stanilovsky.
2012.
Freeling3.0: Towards wider multilinguality.
In Proceedings ofthe Language Resources and Evaluation Conference(LREC 2012), Istanbul, Turkey, May.
ELRA.Drahom?
?ra Spoustov?a, Jan Haji?c, Jan Votrubec, Pavel Kr-bec, and Pavel Kv?eto?n.
2007.
The best of two worlds:Cooperation of statistical and rule-based taggers forCzech.
In Proceedings of the Workshop on Balto-Slavonic Natural Language Processing, pages 67?74.Kristina Toutanova and Colin Cherry.
2009.
A globalmodel for joint lemmatization and part-of-speech pre-diction.
In Proceedings of the Joint Conference of the47th Annual Meeting of the ACL and the 4th Interna-tional Joint Conference on Natural Language Process-ing of the AFNLP: Volume 1-Volume 1, pages 486?494.
Association for Computational Linguistics.Huihsin Tseng, Daniel Jurafsky, and Christopher Man-ning.
2005.
Morphological features help POS taggingof unknown words across language varieties.
In Pro-ceedings of the fourth SIGHAN workshop on Chineselanguage processing, pages 32?39.1029
