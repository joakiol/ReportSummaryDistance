Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 720?728,October 25-29, 2014, Doha, Qatar.c?2014 Association for Computational LinguisticsOpinion Mining withDeep Recurrent Neural NetworksOzan?Irsoy and Claire CardieDepartment of Computer ScienceCornell UniversityIthaca, NY, 14853, USAoirsoy, cardie@cs.cornell.eduAbstractRecurrent neural networks (RNNs) are con-nectionist models of sequential data that arenaturally applicable to the analysis of naturallanguage.
Recently, ?depth in space?
?
asan orthogonal notion to ?depth in time?
?
inRNNs has been investigated by stacking mul-tiple layers of RNNs and shown empiricallyto bring a temporal hierarchy to the architec-ture.
In this work we apply these deep RNNsto the task of opinion expression extractionformulated as a token-level sequence-labelingtask.
Experimental results show that deep,narrow RNNs outperform traditional shallow,wide RNNs with the same number of parame-ters.
Furthermore, our approach outperformsprevious CRF-based baselines, including thestate-of-the-art semi-Markov CRF model, anddoes so without access to the powerful opinionlexicons and syntactic features relied upon bythe semi-CRF, as well as without the standardlayer-by-layer pre-training typically requiredof RNN architectures.1 IntroductionFine-grained opinion analysis aims to detect the sub-jective expressions in a text (e.g.
?hate?)
and to char-acterize their intensity (e.g.
strong) and sentiment (e.g.negative) as well as to identify the opinion holder (theentity expressing the opinion) and the target, or topic,of the opinion (i.e.
what the opinion is about) (Wiebe etal., 2005).
Fine-grained opinion analysis is importantfor a variety of NLP tasks including opinion-orientedquestion answering and opinion summarization.
As aresult, it has been studied extensively in recent years.In this work, we focus on the detection of opinion ex-pressions ?
both direct subjective expressions (DSEs)and expressive subjective expressions (ESEs) as de-fined in Wiebe et al.
(2005).
DSEs consist of explicitmentions of private states or speech events expressingprivate states; and ESEs consist of expressions that in-dicate sentiment, emotion, etc., without explicitly con-veying them.
An example sentence shown in Table 1 inwhich the DSE ?has refused to make any statements?explicitly expresses an opinion holder?s attitude and theThe committee , as usual , hasO O O B ESE I ESE O B DSErefused to make any statements .I DSE I DSE I DSE I DSE I DSE OTable 1: An example sentence with labelsESE ?as usual?
indirectly expresses the attitude of thewriter.Opinion extraction has often been tackled as a se-quence labeling problem in previous work (e.g.
Choiet al.
(2005)).
This approach views a sentence asa sequence of tokens labeled using the conventionalBIO tagging scheme: B indicates the beginning of anopinion-related expression, I is used for tokens insidethe opinion-related expression, and O indicates tokensoutside any opinion-related class.
The example sen-tence in Table 1 shows the appropriate tags in the BIOscheme.
For instance, the ESE ?as usual?
results in thetags B ESE for ?as?
and I ESE for ?usual?.Variants of conditional random field (CRF) ap-proaches have been successfully applied to opinion ex-pression extraction using this token-based view (Choiet al., 2005; Breck et al., 2007): the state-of-the-artapproach is the semiCRF, which relaxes the Marko-vian assumption inherent to CRFs and operates at thephrase level rather than the token level, allowing the in-corporation of phrase-level features (Yang and Cardie,2012).
The success of the CRF- and semiCRF-basedapproaches, however, hinges critically on access to anappropriate feature set, typically based on constituentand dependency parse trees, manually crafted opinionlexicons, named entity taggers and other preprocessingcomponents (see Yang and Cardie (2012) for an up-to-date list).Distributed representation learners provide a differ-ent approach to learning in which latent features aremodeled as distributed dense vectors of hidden lay-ers.
A recurrent neural network (RNN) is one suchlearner that can operate on sequential data of variablelength, which means it can also be applied as a se-quence labeler.
Moreover, bidirectional RNNs incor-porate information from preceding as well as follow-ing tokens (Schuster and Paliwal, 1997) while recentadvances in word embedding induction (Collobert andWeston, 2008; Mnih and Hinton, 2007; Mikolov et720al., 2013; Turian et al., 2010) have enabled more ef-fective training of RNNs by allowing a lower dimen-sional dense input representation and hence, more com-pact networks (Mikolov et al., 2010; Mesnil et al.,2013).
Finally, deep recurrent networks, a type ofRNN with multiple stacked hidden layers, are shownto naturally employ a temporal hierarchy with multi-ple layers operating at different time scales (Hermansand Schrauwen, 2013): lower levels capture short terminteractions among words; higher layers reflect inter-pretations aggregated over longer spans of text.
Whenapplied to natural language sentences, such hierarchiesmight better model the multi-scale language effects thatare emblematic of natural languages, as suggested byprevious results (Hermans and Schrauwen, 2013).Motivated by the recent success of deep architecturesin general and deep recurrent networks in particular, weexplore an application of deep bidirectional RNNs ?henceforth deep RNNs ?
to the task of opinion ex-pression extraction.
For both DSE and ESE detection,we show that such models outperform conventional,shallow (uni- and bidirectional) RNNs as well as previ-ous CRF-based state-of-the-art baselines, including thesemiCRF model.In the rest of the paper we discuss related work(Section 2) and describe the architecture and trainingmethods for recurrent neural networks (RNNs), bidi-rectional RNNs, and deep (bidirectional) RNNs (Sec-tion 3).
We present experiments using a standard cor-pus for fine-grained opinion extraction in Section 4.2 Related WorkOpinion extraction.
Early work on fine-grainedopinion extraction focused on recognizing subjectivephrases (Wilson et al., 2005; Munson et al., 2005).Breck et al.
(2007), for example, formulated the prob-lem as a token-level sequence-labeling problem and ap-ply a CRF-based approach, which significantly outper-formed previous baselines.
Choi et al.
(2005) extendedthe sequential prediction approach to jointly identifyopinion holders; Choi and Cardie (2010) jointly de-tected polarity and intensity along with the opinion ex-pression.
Reranking approaches have also been ex-plored to improve the performance of a single sequencelabeler (Johansson and Moschitti, 2010; Johansson andMoschitti, 2011).
More recent work relaxes the Marko-vian assumption of CRFs to capture phrase-level inter-actions, significantly improving upon the token-levellabeling approach (Yang and Cardie, 2012).
In par-ticular, Yang and Cardie (2013) propose a joint infer-ence model to jointly detect opinion expressions, opin-ion holders and targets, as well as the relations amongthem, outperforming previous pipelined approaches.Deep learning.
Recurrent neural networks (Elman,1990) constitute one important class of naturally deeparchitecture that has been applied to many sequentialprediction tasks.
In the context of NLP, recurrent neu-ral networks view a sentence as a sequence of tokensand have been successfully applied to tasks such as lan-guage modeling (Mikolov et al., 2011) and spoken lan-guage understanding (Mesnil et al., 2013).
Since clas-sical recurrent neural networks only incorporate infor-mation from the past (i.e.
preceding tokens), bidirec-tional variants have been proposed to incorporate in-formation from both the past and the future (i.e.
sub-sequent tokens) (Schuster and Paliwal, 1997).
Bidirec-tionality is especially useful for NLP tasks, since infor-mation provided by the following tokens is generallyhelpful (and sometimes essential) when making a deci-sion on the current token.Stacked recurrent neural networks have been pro-posed as a way of constructing deep RNNs (Schmidhu-ber, 1992; El Hihi and Bengio, 1995).
Careful empir-ical investigation of this architecture showed that mul-tiple layers in the stack can operate at different timescales (Hermans and Schrauwen, 2013).
Pascanu et al.
(2013) explore other ways of constructing deep RNNsthat are orthogonal to the concept of stacking layers ontop of each other.
In this work, we focus on the stackingnotion of depth.3 MethodologyThis section describes the architecture and trainingmethods for the deep bidirectional recurrent networksthat we propose for the task of opinion expression min-ing.
Recurrent neural networks are presented in 3.1,bidirectionality is introduced in 3.2, and deep bidirec-tional RNNs, in 3.3.3.1 Recurrent Neural NetworksA recurrent neural network (Elman, 1990) is a class ofneural network that has recurrent connections, whichallow a form of memory.
This makes them applica-ble for sequential prediction tasks with arbitrary spatio-temporal dimensions.
Thus, their structure fits manyNLP tasks, when the interpretation of a single sentenceis viewed as analyzing a sequence of tokens.
In thiswork, we focus our attention on only Elman-type net-works (Elman, 1990).In an Elman-type network, the hidden layer htattime step t is computed from a nonlinear transforma-tion of the current input layer xtand the previous hid-den layer ht?1.
Then, the final output ytis computedusing the hidden layer ht.
One can interpret htas an in-termediate representation summarizing the past, whichis used to make a final decision on the current input.More formally, given a sequence of vectors{xt}t=1..T, an Elman-type RNN operates by comput-ing the following memory and output sequences:ht= f(Wxt+ V ht?1+ b) (1)yt= g(Uht+ c) (2)where f is a nonlinear function, such as the sigmoidfunction and g is the output nonlinearity, such as the721Figure 1: Recurrent neural networks.
Each black, orange and red node denotes an input, hidden or output layer,respectively.
Solid and dotted lines denote the connections of forward and backward layers, respectively.
Top:Shallow unidirectional (left) and bidirectional (right) RNN.
Bottom: 3-layer deep unidirectional (left) and bidirec-tional (right) RNN.softmax function.
W and V are weight matrices be-tween the input and hidden layer, and among the hiddenunits themselves (connecting the previous intermediaterepresentation to the current one), respectively, whileU is the output weight matrix.
b and c are bias vec-tors connected to hidden and output units, respectively.As a base case for the recursion in Equation 1, h0isassumed to be 0.Training an RNN can be done by optimizing a dis-criminative objective (e.g.
the cross entropy for classifi-cation tasks) with a gradient-based method.
Backprop-agation through time can be used to efficiently com-pute the gradients (Werbos, 1990).
This method is es-sentially equivalent to unfolding the network in timeand using backpropagation as in feedforward neuralnetworks, while sharing the connection weights acrossdifferent time steps.
The Elman-style RNN is shown inFigure 1, top left.3.2 BidirectionalityObserve that with the above definition of RNNs, wehave information only about the past, when making adecision on xt.
This is limiting for most NLP tasks.As a simple example, consider the two sentences: ?Idid not accept his suggestion?
and ?I did not go tothe rodeo?.
The first has a DSE phrase (?did not ac-cept?)
and the second does not.
However, any suchRNN will assign the same labels for the words ?did?and ?not?
in both sentences, since the preceding se-quences (past) are the same: the Elman-style unidirec-tional RNNs lack the representational power to modelthis task.
A simple way to work around this problemis to include a fixed-size future context around a singleinput vector (token).
However, this approach requirestuning the context size, and ignores future informationfrom outside of the context window.
Another way toincorporate information about the future is to add bidi-rectionality to the architecture, referred as the bidirec-tional RNN (Schuster and Paliwal, 1997):?
?ht= f(??Wxt+??V??ht?1+?
?b ) (3)?
?ht= f(??Wxt+??V??ht+1+?
?b ) (4)yt= g(U??
?ht+ U??
?ht+ c) (5)where?
?W ,?
?V and?
?b are the forward weight matri-ces and bias vector as before;?
?W ,?
?V and?
?b are theirbackward counterparts; U?, U?are the output ma-trices; and c is the output bias.1Again, we assume??h0=?
?hT+1= 0.
In this setting??htand?
?htcanbe interpreted as a summary of the past, and the future,respectively, around the time step t. When we makea decision on an input vector, we employ the two in-termediate representations??htand?
?htof the past and1As a convention, we adopt the following notationthroughout the paper: Superscript arrows for vectors disam-biguate between forward and backward representations.
Su-perscript arrows for matrices denote the resulting vector rep-resentations (connection outputs), and subscript arrows formatrices denote incoming vector representations (connectioninputs).
We omit subscripts when there is no ambiguity.722the future.
(See Figure 1, top right.)
Therefore in thebidirectional case, we have perfect information aboutthe sequence (ignoring the practical difficulties aboutcapturing long term dependencies, caused by vanishinggradients), whereas the classical Elman-type networkuses only partial information as described above.Note that the forward and backward parts of the net-work are independent of each other until the outputlayer when they are combined.
This means that duringtraining, after backpropagating the error terms from theoutput layer to the forward and backward hidden lay-ers, the two parts can be thought of as separate, andeach trained with the classical backpropagation throughtime (Werbos, 1990).3.3 Depth in SpaceRecurrent neural networks are often characterized ashaving depth in time: when unfolded, they are equiv-alent to feedforward neural networks with as manyhidden layers as the number tokens in the input se-quence (with shared connections across multiple layersof time).
However, this notion of depth likely does notinvolve hierarchical processing of the data: across dif-ferent time steps, we repeatedly apply the same trans-formation to compute the memory contribution of theinput (W ), to compute the response value from the cur-rent memory (U ) and to compute the next memory vec-tor from the previous one (V ).
Therefore, assuming theinput vectors {xt} together lie in the same representa-tion space, as do the output vectors {yt}, hidden rep-resentations {ht} lie in the same space as well.
As aresult, they do not necessarily become more and moreabstract, hierarchical representations of one another aswe traverse in time.
However in the more conventional,stacked deep learners (e.g.
deep feedforward nets), animportant benefit of depth is the hierarchy among hid-den representations: every hidden layer conceptuallylies in a different representation space, and constitutesa more abstract and higher-level representation of theinput (Bengio, 2009).In order to address these concerns, we investi-gate deep RNNs, which are constructed by stackingElman-type RNNs on top of each other (Hermans andSchrauwen, 2013).
Intuitively, every layer of the deepRNN treats the memory sequence of the previous layeras the input sequence, and computes its own memoryrepresentation.More formally, we have:?
?h(i)t= f(??W(i)???h(i?1)t+??W(i)???h(i?1)t+??V(i)??h(i)t?1+?
?b(i)) (6)?
?h(i)t= f(??W(i)???h(i?1)t+??W(i)???h(i?1)t+??V(i)??h(i)t+1+?
?b(i)) (7)when i > 1 and?
?h(1)t= f(??W(1)xt+??V(1)??h(1)t?1+?
?b(1)) (8)?
?h(1)t= f(??W(1)xt+??V(1)??h(1)t+1+?
?b(1)) (9)Importantly, note that both forward and backward rep-resentations are employed when computing the forwardand backward memory of the next layer.Two alternatives for the output layer computationsare to employ all memory layers or only the last.
Inthis work we adopt the second approach:yt= g(U??
?h(L)t+ U??
?h(L)t+ c) (10)whereL is the number of layers.
Intuitively, connectingthe output layer to only the last hidden layer forces thearchitecture to capture enough high-level informationat the final layer for producing the appropriate output-layer decision.Training a deep RNN can be conceptualized as in-terleaved applications of the conventional backprop-agation across multiple layers, and backpropagationthrough time within a single layer.The unidirectional and bidirectional deep RNNs aredepicted in the bottom half of Figure 1.Hypotheses.
In general, we expected that the deepRNNs would show the most improvement over shal-low RNNS for ESEs ?
phrases that implicitly conveysubjectivity.
Existing research has shown that theseare harder to identify than direct expressions of sub-jectivity (DSEs): they are variable in length and in-volve terms that, in many (or most) contexts, are neu-tral with respect to sentiment and subjectivity.
As a re-sult, models that do a better job interpreting the contextshould be better at disambiguating subjective vs. non-subjective uses of phrases involving common words(e.g.
?as usual?, ?in fact?).
Whether or not deep RNNswould be powerful enough to outperform the state-of-the-art semiCRF was unclear, especially if the semi-CRF is given access to the distributed word represen-tations (embeddings) employed by the deep RNNs.
Inaddition, the semiCRF has access to parse tree informa-tion and opinion lexicons, neither of which is availableto the deep RNNs.4 ExperimentsActivation Units.
We employ the standard softmaxactivation for the output layer: g(x) = exi/?jexj.For the hidden layers we use the rectifier linear ac-tivation: f(x) = max{0, x}.
Experimentally, recti-fier activation gives better performance, faster conver-gence, and sparse representations.
Previous work alsoreported good results when training deep neural net-works using rectifiers, without a pretraining step (Glo-rot et al., 2011).Data.
We use the MPQA 1.2 corpus (Wiebe et al.,2005) (535 news articles, 11,111 sentences) that ismanually annotated with both DSEs and ESEs at thephrase level.
As in previous work, we separate 135documents as a development set and employ 10-foldCV over the remaining 400 documents.
The develop-ment set is used during cross validation to do modelselection.723Layers |h| Precision Recall F1Prop.
Bin.
Prop.
Bin.
Prop Bin.Shallow 36 62.24 65.90 65.63* 73.89* 63.83 69.62Deep 2 29 63.85* 67.23* 65.70* 74.23* 64.70* 70.52*Deep 3 25 63.53* 67.67* 65.95* 73.87* 64.57* 70.55*Deep 4 22 64.19* 68.05* 66.01* 73.76* 64.96* 70.69*Deep 5 21 60.65 61.67 56.83 69.01 58.60 65.06Shallow 200 62.78 66.28 65.66* 74.00* 64.09 69.85Deep 2 125 62.92* 66.71* 66.45* 74.70* 64.47 70.36Deep 3 100 65.56* 69.12* 66.73* 74.69* 66.01* 71.72*Deep 4 86 61.76 65.64 63.52 72.88* 62.56 69.01Deep 5 77 61.64 64.90 62.37 72.10 61.93 68.25Table 2: Experimental evaluation of RNNs for DSE extractionLayers |h| Precision Recall F1Prop.
Bin.
Prop.
Bin.
Prop Bin.Shallow 36 51.34 59.54 57.60 72.89* 54.22 65.44Deep 2 29 51.13 59.94 61.20* 75.37* 55.63* 66.64*Deep 3 25 53.14* 61.46* 58.01 72.50 55.40* 66.36*Deep 4 22 51.48 60.59* 59.25* 73.22 54.94 66.15*Deep 5 21 49.67 58.42 48.98 65.36 49.25 61.61Shallow 200 52.20* 60.42* 58.11 72.64 54.75 65.75Deep 2 125 51.75* 60.75* 60.69* 74.39* 55.77* 66.79*Deep 3 100 52.04* 60.50* 61.71* 76.02* 56.26* 67.18*Deep 4 86 50.62* 58.41* 53.55 69.99 51.98 63.60Deep 5 77 49.90* 57.82 52.37 69.13 51.01 62.89Table 3: Experimental evaluation of RNNs for ESE extractionEvaluation Metrics.
We use precision, recall and F-measure for performance evaluation.
Since the bound-aries of expressions are hard to define even for humanannotators (Wiebe et al., 2005), we use two soft notionsof the measures: Binary Overlap counts every over-lapping match between a predicted and true expres-sion as correct (Breck et al., 2007; Yang and Cardie,2012), and Proportional Overlap imparts a partial cor-rectness, proportional to the overlapping amount, toeach match (Johansson and Moschitti, 2010; Yang andCardie, 2012).
All statistical comparisons are done us-ing a two-sided paired t-test with a confidence level of?
= .05.Baselines (CRF and SEMICRF).
As baselines, weuse the CRF-based method of Breck et al.
(2007)and the SEMICRF-based method of Yang and Cardie(2012), which is the state-of-the-art in opinion expres-sion extraction.
Features that the baselines use arewords, part-of-speech tags and membership in a manu-ally constructed opinion lexicon (within a [-1, +1] con-text window).
Since SEMICRF relaxes the Markovianassumption and operates at the segment-level insteadof the token-level, it also has access to parse trees ofsentences to generate candidate segments (Yang andCardie, 2012).Word Vectors (+VEC).
We also include versions ofthe baselines that have access to pre-trained word vec-tors.
In particular, CRF+VEC employs word vectorsas continuous features per every token.
Since SEMI-CRF has phrase-level rather than word-level features,we simply take the mean of every word vector for aphrase-level vector representation for SEMICRF+VECas suggested in Mikolov et al.
(2013).In all of our experiments, we keep the word vec-tors fixed (i.e.
do not finetune) to reduce the degreeof freedom of our models.
We use the publicly avail-able 300-dimensional word vectors of Mikolov et al.
(2013), trained on part of the Google News dataset(?100B words).
Preliminary experiments with otherword vector representations such as Collobert-Weston(2008) embeddings or HLBL (Mnih and Hinton, 2007)provided poorer results (?
?3% difference in propor-tional and binary F1).Regularizer.
We do not employ any regularizationfor smaller networks (?24,000 parameters) because wehave not observed strong overfitting (i.e.
the differ-ence between training and test performance is small).Larger networks are regularized with the recently pro-posed dropout technique (Hinton et al., 2012): we ran-domly set entries of hidden representations to 0 witha probability called the dropout rate, which is tunedover the development set.
Dropout prevents learned724Model Precision Recall F1Prop.
Bin.
Prop.
Bin.
Prop Bin.DSE CRF 74.96* 82.28* 46.98 52.99 57.74 64.45semiCRF 61.67 69.41 67.22* 73.08* 64.27 71.15*CRF +vec 74.97* 82.43* 49.47 55.67 59.59 66.44semiCRF +vec 66.00 71.98 60.96 68.13 63.30 69.91Deep RNN 3 100 65.56 69.12 66.73* 74.69* 66.01* 71.72*ESE CRF 56.08 68.36 42.26 51.84 48.10 58.85semiCRF 45.64 69.06 58.05 64.15 50.95 66.37*CRF +vec 57.15* 69.84* 44.67 54.38 50.01 61.01semiCRF +vec 53.76 70.82* 52.72 61.59 53.10 65.73Deep RNN 3 100 52.04 60.50 61.71* 76.02* 56.26* 67.18*Table 4: Comparison of Deep RNNs to state-of-the-art (semi)CRF baselines for DSE and ESE detectionfeatures from co-adapting, and it has been reportedto yield good results when training deep neural net-works (Krizhevsky et al., 2012; Dahl et al., 2013).Network Training.
We use the standard multiclasscross-entropy as the objective function when trainingthe neural networks.
We use stochastic gradient de-scent with momentum with a fixed learning rate (.005)and a fixed momentum rate (.7).
We update weightsafter minibatches of 80 sentences.
We run 200 epochsfor training.
Weights are initialized from small randomuniform noise.
We experiment with networks of vari-ous sizes, however we have the same number of hiddenunits across multiple forward and backward hidden lay-ers of a single RNN.
We do not employ a pre-trainingstep; deep architectures are trained with the supervisederror signal, even though the output layer is connectedto only the final hidden layer.
With these configura-tions, every architecture successfully converges with-out any oscillatory behavior.
Additionally, we employearly stopping for the neural networks: out of all itera-tions, the model with the best development set perfor-mance (Proportional F1) is selected as the final modelto be evaluated.4.1 Results and DiscussionBidirectional vs. Unidirectional.
Although our fo-cus is on bidirectional RNNs, we first confirm that theSHALLOW bidirectional RNN outperforms a (shallow)unidirectional RNN for both DSE and ESE recogni-tion.
To make the comparison fair, each network hasthe same number of total parameters: we use 65 hid-den units for the unidirectional, and 36 for the bidirec-tional network, respectively.
Results are as expected:the bidirectional RNN obtains higher F1 scores than theunidirectional RNN ?
63.83 vs. 60.35 (proportionaloverlap) and 69.62 vs. 68.31 (binary overlap) for DSEs;54.22 vs. 51.51 (proportional) and 65.44 vs. 63.65 (bi-nary) for ESEs.
All differences are statistically signif-icant at the 0.05 level.
Thus, we will not include com-parisons to the unidirectional RNNs in the remainingexperiments.Adding Depth.
Next, we quantitatively investigatethe effects of adding depth to RNNs.
Tables 2and 3 show the evaluation of RNNs of various depthsand sizes.
In both tables, the first group networkshave approximately 24,000 parameters and the secondgroup networks have approximately 200,000 parame-ters.
Since all RNNs within a group have approxi-mately the same number of parameters, they grow nar-rower as they get deeper.
Within each group, boldshows the best result with an asterisk denoting statis-tically indistinguishable performance with respect tothe best.
As noted above, all statistical comparisonsuse a two-sided paired t-test with a confidence level of?
= .05.In both DSE and ESE detection and for larger net-works (bottom set of results), 3-layer RNNs provide thebest results.
For smaller networks (top set of results),2, 3 and 4-layer RNNs show equally good performancefor certain sizes and metrics and, in general, adding ad-ditional layers degrades performance.
This could be re-lated to how we train the architectures as well as to thedecrease in width of the networks.
In general, we ob-serve a trend of increasing performance as we increasethe number of layers, until a certain depth.deepRNNs vs. (semi)CRF.
Table 4 shows compari-son of the best deep RNNs to the previous best resultsin the literature.
In terms of F-measure, DEEP RNNperforms best for both DSE and ESE detection, achiev-ing a new state-of-the-art performance for the morestrict proportional overlap measure, which is harder toimprove upon than the binary evaluation metric.
SEMI-CRF, with its very high recall, performs comparably tothe DEEP RNN on the binary metric.
Note that RNNsdo not have access to any features other than word vec-tors.In general, CRFs exhibit high precision but low re-call (CRFs have the best precision on both DSE andESE detection) while SEMICRFs exhibit a high re-call, low precision performance.
Compared to SEMI-CRF, the DEEP RNNs produce an even higher recallbut sometimes lower precision for ESE detection.
Thissuggests that the methods are complementary, and can725(1)The situation obviously remains fluid from hour to hour but it [seems to be] [going in the right direction]DEEPRNN The situation [obviously] remains fluid from hour to hour but it [seems to be going in the right] directionSHALLOW The situation [obviously] remains fluid from hour to hour but it [seems to be going in] the right directionSEMICRF The situation [obviously remains fluid from hour to hour but it seems to be going in the right direction](2)have always said this is a multi-faceted campaign [but equally] we have also said any future military action[would have to be based on evidence] , ...DEEPRNN have always said this is a multi-faceted campaign but [equally we] have also said any future military action[would have to be based on evidence] , ...SHALLOW have always said this is a multi-faceted [campaign but equally we] have also said any future military actionwould have to be based on evidence , ...SEMICRF have always said this is a multi-faceted campaign but equally we have also said any future military actionwould have to be based on evidence , ...(3)Ruud Lubbers , the United Nations Commissioner for Refugees , said Afghanistan was [not yet] securefor aid agencies to operate in and ?
[not enough] ?
food had been taken into the country .DEEPRNN Ruud Lubbers , the United Nations Commissioner for Refugees , said Afghanistan was [not yet] securefor aid agencies to operate in and ?
[not enough] ?
food had been taken into the country .SHALLOW Ruud Lubbers , the United Nations Commissioner for Refugees , said Afghanistan was [not yet] securefor aid agencies to operate in and ?
[not enough] ?
food had been taken into the country .SEMICRF Ruud Lubbers , the United Nations Commissioner for Refugees , said Afghanistan was not yet securefor aid agencies to operate in and ?
not enough ?
food had been taken into the country .Figure 2: Examples of output.
In each set, the gold-standard annotations are shown in the first line.potentially be even more powerful when combined inan ensemble method.Word vectors.
Word vectors help CRFs on both pre-cision and recall on both tasks.
However, SEMICRFsbecome more conservative with word vectors, produc-ing higher precision and lower recall on both tasks.This sometimes hurts overall F-measure.Among the (SEMI)CRF-based methods, SEMICRFobtains the highest F1 score for DSEs and for ESEsusing the softer metric; SEMICRF+VEC performs bestfor ESEs according to the stricter proportional overlapmeasure.Network size.
Finally, we observe that even smallnetworks (such as 4-layer deep RNN for DSE and2-layer deep RNN for ESE) outperform conventionalCRFs.
This suggests that with the help of good wordvectors, we can train compact but powerful sequentialneural models.When examining the output, we see some system-atic differences between the previously top-performingSEMICRF and the RNN-based models.
(See Figure 2.
)First, SEMICRF often identifies excessively long sub-jective phrases as in Example 1.
Here, none of the mod-els exactly matches the gold standard, but the RNNsare much closer.
And all three models appear to haveidentified an ESE that was mistakenly omitted by thehuman annotator ?
?obviously?.
At the same time,the SEMICRF sometimes entirely misses subjective ex-pressions that the RNNs identify ?
this seems to occurwhen there are no clear indications of sentiment in thesubjective expression.
The latter can be seen in Exam-ples 2 and 3, in which the SEMICRF does not identify?but equally?, ?would have to be based on evidence?,?not yet?, and ?not enough?.We also observe evidence of the power of the DEEP-RNN over the SHALLOWRNN in Examples 4 and 5.
(See Figure 3.)
In contrast to Figure 2, Figure 3 dis-tinguishes subjective expressions that are (correctly)assigned an initial Begin label from those that con-sist only of Inside labels2?
the latter are shown inALL CAPS and indicate some degree of confusion inthe model that produced them.
In Example 4, SHAL-LOWRNN exhibits some evidence for each ESE ?
itlabels one or more tokens as Inside an ESE (?any?
and?time?).
But it does not explicitly tag the beginningof the ESE.
DEEPRNN does better, identifying the firstESE in its entirety (?in any case?)
and identifying morewords as being Inside the second ESE (?it is high time).A similar situation occurs in Example 5.5 ConclusionIn this paper we have explored an application of deeprecurrent neural networks to the task of sentence-levelopinion expression extraction.
We empirically evalu-ated deep RNNs against conventional, shallow RNNsthat have only a single hidden layer.
We also com-pared our models with previous (semi)CRF-based ap-proaches.Experiments showed that deep RNNs outperformedshallow RNNs on both DSE and ESE extrac-2Sequences of I?s are decoded as the associated DSE orESE even though they lack the initial B.726(4)[In any case] , [it is high time] that a social debate be organized ...DEEPRNN [In any case] , it is HIGH TIME that a social debate be organized ...SHALLOW In ANY case , it is high TIME that a social debate be organized ...(5)Mr. Stoiber [has come a long way] from his refusal to [sacrifice himself] for the CDU in an election that[once looked impossible to win] , through his statement that he would [under no circumstances]run against the wishes...DEEPRNN Mr. Stoiber [has come a long way from] his [refusal to sacrifice himself] for the CDU in an election that[once looked impossible to win] , through his statement that he would [under no circumstancesrun against] the wishes...SHALLOW Mr. Stoiber has come A LONG WAY FROM his refusal to sacrifice himself for the CDU in an election that[once looked impossible] to win , through his statement that he would under NO CIRCUMSTANCESrun against the wishes...Figure 3: DEEPRNN Output vs. SHALLOWRNN Output.
In each set of examples, the gold-standard annotationsare shown in the first line.
Tokens assigned a label of Inside with no preceding Begin tag are shown in ALL CAPS.tion.
Furthermore, deep RNNs outperformed previous(semi)CRF baselines, achieving new state-of-the-art re-sults for fine-grained on opinion expression extraction.We have trained our deep networks without any pre-training and with only the last hidden layer connectedto the output layer.
One potential future direction isto explore the effects of pre-training on the architec-ture.
Pre-training might help to exploit the additionalrepresentational power available in deeper networks.Another direction is to investigate the impact of fine-tuning the word vectors during supervised training.Additionally, alternative notions of depth that are or-thogonal to stacking, as in Pascanu et al.
(2013) can beinvestigated for this task.AcknowledgmentsThis work was supported in part by NSF grant IIS-1314778 and DARPA DEFT Grant FA8750-13-2-0015.The views and conclusions contained herein are thoseof the authors and should not be interpreted as necessar-ily representing the official policies or endorsements,either expressed or implied, of NSF, DARPA or theU.S.
Government.ReferencesYoshua Bengio.
2009.
Learning deep architectures forai.
Foundations and trendsR?
in Machine Learning,2(1):1?127.Eric Breck, Yejin Choi, and Claire Cardie.
2007.
Iden-tifying expressions of opinion in context.
In IJCAI,pages 2683?2688.Yejin Choi and Claire Cardie.
2010.
Hierarchical se-quential learning for extracting opinions and their at-tributes.
In Proceedings of the ACL 2010 ConferenceShort Papers, pages 269?274.
Association for Com-putational Linguistics.Yejin Choi, Claire Cardie, Ellen Riloff, and SiddharthPatwardhan.
2005.
Identifying sources of opinionswith conditional random fields and extraction pat-terns.
In Proceedings of HLT/EMNLP, pages 355?362.
Association for Computational Linguistics.Ronan Collobert and Jason Weston.
2008.
A unifiedarchitecture for natural language processing: Deepneural networks with multitask learning.
In Pro-ceedings of the 25th international conference on Ma-chine learning, pages 160?167.
ACM.George E Dahl, Tara N Sainath, and Geoffrey E Hin-ton.
2013.
Improving deep neural networks for lvcsrusing rectified linear units and dropout.
In Acous-tics, Speech and Signal Processing (ICASSP), 2013IEEE International Conference on, pages 8609?8613.
IEEE.Salah El Hihi and Yoshua Bengio.
1995.
Hierarchicalrecurrent neural networks for long-term dependen-cies.
In Advances in Neural Information ProcessingSystems, pages 493?499.Jeffrey L Elman.
1990.
Finding structure in time.Cognitive science, 14(2):179?211.Xavier Glorot, Antoine Bordes, and Yoshua Bengio.2011.
Deep sparse rectifier networks.
In Proceed-ings of the 14th International Conference on Arti-ficial Intelligence and Statistics.
JMLR W&CP Vol-ume, volume 15, pages 315?323.Michiel Hermans and Benjamin Schrauwen.
2013.Training and analysing deep recurrent neural net-works.
In Advances in Neural Information Process-ing Systems, pages 190?198.Geoffrey E Hinton, Nitish Srivastava, Alex Krizhevsky,Ilya Sutskever, and Ruslan R Salakhutdinov.
2012.Improving neural networks by preventing co-adaptation of feature detectors.
arXiv preprintarXiv:1207.0580.Richard Johansson and Alessandro Moschitti.
2010.Syntactic and semantic structure for opinion ex-pression detection.
In Proceedings of the Four-teenth Conference on Computational Natural Lan-727guage Learning, pages 67?76.
Association for Com-putational Linguistics.Richard Johansson and Alessandro Moschitti.
2011.Extracting opinion expressions and their polarities:exploration of pipelines and joint models.
In Pro-ceedings of the 49th Annual Meeting of the Associ-ation for Computational Linguistics: Human Lan-guage Technologies: short papers-Volume 2, pages101?106.
Association for Computational Linguis-tics.Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hin-ton.
2012.
Imagenet classification with deep convo-lutional neural networks.
In NIPS, volume 1, page 4.Gr?egoire Mesnil, Xiaodong He, Li Deng, and YoshuaBengio.
2013.
Investigation of recurrent-neural-network architectures and learning methods for spo-ken language understanding.
Interspeech.Tomas Mikolov, Martin Karafi?at, Lukas Burget, JanCernock`y, and Sanjeev Khudanpur.
2010.
Recur-rent neural network based language model.
In IN-TERSPEECH, pages 1045?1048.Tomas Mikolov, Stefan Kombrink, Lukas Burget,JH Cernocky, and Sanjeev Khudanpur.
2011.Extensions of recurrent neural network languagemodel.
In Acoustics, Speech and Signal Processing(ICASSP), 2011 IEEE International Conference on,pages 5528?5531.
IEEE.Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-rado, and Jeff Dean.
2013.
Distributed representa-tions of words and phrases and their compositional-ity.
In Advances in Neural Information ProcessingSystems, pages 3111?3119.Andriy Mnih and Geoffrey Hinton.
2007.
Three newgraphical models for statistical language modelling.In Proceedings of the 24th international conferenceon Machine learning, pages 641?648.
ACM.M Arthur Munson, Claire Cardie, and Rich Caruana.2005.
Optimizing to arbitrary nlp metrics using en-semble selection.
In Proceedings of HLT/EMNLP,pages 539?546.
Association for Computational Lin-guistics.Razvan Pascanu, C?a?glar G?ulc?ehre, Kyunghyun Cho,and Yoshua Bengio.
2013.
How to constructdeep recurrent neural networks.
arXiv preprintarXiv:1312.6026.J?urgen Schmidhuber.
1992.
Learning complex, ex-tended sequences using the principle of history com-pression.
Neural Computation, 4(2):234?242.Mike Schuster and Kuldip K Paliwal.
1997.
Bidirec-tional recurrent neural networks.
Signal Processing,IEEE Transactions on, 45(11):2673?2681.Joseph Turian, Lev Ratinov, and Yoshua Bengio.
2010.Word representations: a simple and general methodfor semi-supervised learning.
In Proceedings of the48th Annual Meeting of the Association for Compu-tational Linguistics, pages 384?394.
Association forComputational Linguistics.Paul J Werbos.
1990.
Backpropagation through time:what it does and how to do it.
Proceedings of theIEEE, 78(10):1550?1560.Janyce Wiebe, Theresa Wilson, and Claire Cardie.2005.
Annotating expressions of opinions and emo-tions in language.
Language resources and evalua-tion, 39(2-3):165?210.Theresa Wilson, Janyce Wiebe, and Paul Hoff-mann.
2005.
Recognizing contextual polarity inphrase-level sentiment analysis.
In Proceedings ofHLT/EMNLP, pages 347?354.
Association for Com-putational Linguistics.Bishan Yang and Claire Cardie.
2012.
Extractingopinion expressions with semi-markov conditionalrandom fields.
In Proceedings of the 2012 JointConference on Empirical Methods in Natural Lan-guage Processing and Computational Natural Lan-guage Learning, pages 1335?1345.
Association forComputational Linguistics.Bishan Yang and Claire Cardie.
2013.
Joint inferencefor fine-grained opinion extraction.
In Proceedingsof ACL.728
