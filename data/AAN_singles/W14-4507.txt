Proceedings of the AHA!
Workshop on Information Discovery in Text, pages 37?42,Dublin, Ireland, August 23 2014.This work is licensed under a Creative Commons Attribution 4.0 International License.
Page numbers and proceedings footerare added by the organizers.
License details: http://creativecommons.org/licenses/by/4.0/A Comparative Study of Conversion Aided Methods for WordNetSentence Textual SimilarityMuhidin MohamedEECE University of Birmingham,Edgbaston, Birmingham, UKMam256@bham.ac.ukM.
OussalahEECE University of Birmingham,Edgbaston, Birmingham, UKM.Oussalah@bham.ac.ukAbstractIn this paper, we present a comparison of three methods for taxonomic-based sentence semantic relatedness, aid-ed with word parts of speech (PoS) conversion.
We use WordNet ontology for determining word level semanticsimilarity while augmenting WordNet with two other lexicographical databases; namely Categorial VariationDatabase (CatVar) and Morphosemantic Database in assisting the word category conversion.
Using a humanannotated benchmark data set, all the three approaches achieved a high positive correlation reaching up to (r =0.881647) with comparison to human ratings and two other baselines evaluated on the same benchmark data set.1 IntroductionSentence textual similarity is a crucial and a prerequisite subtask for many text processing and NLPtasks including text summarization, document classification, text clustering, topic detection, automaticquestion answering, automatic text scoring, plagiarism detection, machine translation, conversationalagents among others (Ali, Ghosh, & Al-Mamun, 2009; Gomaa & Fahmy, 2013; Haque, Naskar, Way,Costa-Juss?, & Banchs, 2010; K. O?Shea, 2012; Osman, Salim, Binwahlan, Alteeb, & Abuobieda,2012).
There are two predominant approaches for sentence similarity: corpus-based and knowledge-based.
The former utilises information exclusively derived from large corpora including word fre-quency of occurrence, and latent semantic analysis, to infer semantic similarity.
On the other hand,Knowledge-based measures employ the intrinsic structure of a semantic network including its hierar-chy to derive the semantic similarity.
One of the commonly used knowledge networks for semanticsimilarity is WordNet.
It is a hierarchical lexical database for English developed at Princeton Universi-ty (Miller, 1995).
The state of the art WordNet sentence similarity is harvested from pairing the con-stituent words of the two compared sentences.
This is based on the intuition that similar sentences inmeaning will indeed comprise semantically related words.
However, these pairings only handle nounsand verbs as other part-of-speech (PoS) attributes are not accounted for in WordNet taxonomy.
Taxo-nomic similarity is a conceptual relatedness derived from hyponymy/hypernymy relations of lexicalontologies.
In this study, we use a group of WordNet semantic relations, e.g.
synonymy, hyponymy,for similarity determination and for the approximation of noun equivalents of other PoS words.In implementing the conversion aided methods, we adapted a publicly available package (Pedersen,Patwardhan, & Michelizzi, 2004) to measure word level similarity.
We computed word similaritiesfrom word senses using Wu and Palmer?s measure (Wu & Palmer, 1994) as given in expression 1.
(     )(  )          (  )((   (     ))(  )       (  ))                                                 ( )Where    (     ) (lowest common subsumer) stands for the synset subsuming concepts    andwhile depth (  ) indicates the number of nodes from concept    to the root node of the hierarchy.Next, the above word-to-word semantic similarity is extended to sentence-to-sentence semantic simi-larity, say    and    using (Malik, Subramaniam, & Kaushik, 2007) like approach, where pairs of thesame PoS tokens from the two sentences are evaluated.
(     )[?
(    )|  |?
(    )|  |]     (  )     (  )    ( )In (2),    (     ) stands for word level similarity measure in (1).37Nevertheless, for common natural language texts, it remains biased if only verbs and nouns are usedto measure semantic relatedness ignoring other word categories such as adjectives, adverbs and namedentities.
To elaborate that, consider the following pair of semantically identical sentences with differ-ent word surface forms and classes.S1:  He stated that the construction of the house is complete.S2:  He said in a statement that the house is completely constructed.Initial preprocessing tasks including tokenization, normalization, and stop-words removal reducesentences to their semantic words with S1 yielding (state, construction, house, complete) and (state-ment, house, completely, construct) for S2.
To optimize the semantic similarity of the two sentences,their scores from the word pairings need to be maximized regardless their associated part of speech.For S1 and S2, this is only achievable when words are paired as (statement, state), (house, house),(construction, construct) and (complete, completely).
However, using quantification (2) yields aSim(S1,S2) score of 0.543.
This is justifiable as computing the similarity of the above first, third andfourth pairs, is out of reach using conventional WordNet measures due to each word pair falling indifferent PoS.
To handle the above limitation, the idea advocated in this paper is to turn all non-nounPoS terms into corresponding noun expressions in order to enhance the pairing tasks.The rationale behind the migration to noun category instead of other PoS categories relies on the in-herent well elaborated properties of noun category in the taxonomical hierarchy, e.g., number of nounsis much more important than other attributes in most lexical databases, which increases the chance offinding noun-counterpart; WordNet 3 has a depth of 20 for nouns and 14 for verbs, which allows formuch more elaborated hyponym/hypernym relations for instance.
It is also the case that words in thelower layers of the deeper hierarchical taxonomy have more specific concepts which consequentlyyield a high semantic similarity (Li, McLean, Bandar, O'shea, & Crockett, 2006).
This is again sup-ported by the argument presented in (Bawakid & Oussalah, 2010).The reasons stated above and WordNet limitation of parts of speech boundary motived the currentstudy of word PoS conversion in an attempt to improve the measurement of taxonomic-based shorttext semantic similarity.
In this respect, transforming all other primary word categories1 of the previ-ous example to nouns using CatVar (Habash & Dorr, 2003) aided conversion has raised the similarityfrom 0.543 to 0.86.
Since the two sentences of the previous example are intuitively highly semantical-ly related, the noun-conversion brings the sentence similarity closer to human judgement.
This againhighlights the importance of word PoS conversion to move freely beyond the barrier of PoS re-striction.
This paper aims to investigate three distinct word conversion schemes.
Although, all thethree approaches use WordNet for measuring the term level similarity, each stands on a distinct exter-nal lexical resource in converting word?s category; namely, WordNet 3.0, the Categorial VariationDatabase (CatVar), and the Morphosemantic Database (Fellbaum, Osherson, & Clark, 2009).CatVar is a lexical database containing word categorial variations for English lexemes sharing acommon stem, e.g.
researchV, researcherN, researchableAJ,.
Likewise, Morphosematic Database is aWordNet-related linguistic resource that links morphologically related nouns and verbs in WordNet.Both aforementioned databases are solely utilized to aid the PoS conversion of three primary wordclasses to nouns.
Contributions of this paper are two folded.
First, we improved traditional WordNetsentence similarity by converting poorly or non-hierarchized word categories (e.g.
verbs, adverbs andadjectives) to a class with well-structured and deep taxonomy (nouns) using WordNet relations, Cat-Var and Morphosemantic databases.
Second, we have performed a comparison among the three PoSconversion techniques to discover the most appropriate supplementary database to WordNet.2 Word Parts of Speech Conversion MethodsThe two conversion methods aided with CatVar and Morphosemantics were performed by looking upthe word to be converted from the corresponding database and replacing it with target category word.For example to convert the verb arouse, a simple look-up database matching yields arousal as anequivalent noun to arouse in both databases (arouse ?
arousal).
However, WordNet aided conversioncannot be accomplished with a simple look up and replacement strategy due to the nature of its lexicalorganization that emphasises word semantics rather than their morphology.
For this purpose, to con-1 Verbs, adjectives, adverbs38vert verb category into noun category, we designed a systematic four level conversion procedure start-ing with a verb surface form where the verb itself is checked for having noun form.
If the latter fails,the second level investigates the synonyms of the verb senses, where each synset is checked whether anoun-form exists.
If a noun member is found a replacement is issued, otherwise, another subsequentreasoning is applied.
The third level differs from the previous two in that it goes down one level to thechild node in the WordNet taxonomy following the hyponymy relation in which case the verb is con-verted by replacing it by the first encountered node containing the target category.
Last but not least,the fourth level is based on moving one parent node up the taxonomy through the hypernymy relationwhere the first obtained noun is used as an approximate noun counterpart.
Fig.
1 illustrates the Word-Net aided conversion levels indicating an example of word conversion achieved at each level (see un-derneath the figure).
On the other hand, derivation rules in WorldNet allow us to convert ad-vert/adjective categories into their noun counterparts if available.Fig.
1: The 4-level WordNet Aided Parts of Speech (PoS) Conversion3 Implementation and ExperimentsFigure 2 (a) depicts our layered implementation of the multiple conversion aided sentence semanticsimilarity.
For every two sentences, we determine how closely the two are semantically related usingscores between 1 and 0 with 1 indicating identical texts.
Fig 1 (b) highlights a functional algorithmthat summarizes the word category conversion process.
The convert(w) function in the same algorithmperforms the parts of speech conversion from the selected database depending on the active approach(A in Fig.2 (a)).
All text pre-processing tasks including tokenization, parts of speech tagging, and stopwords removal are implemented in layer 1.
The second layer houses the three main word categoryconversion approaches in discussion.
In each experimental run, only one approach is used dependingon the choice of internally hardcoded system logic.
The generated output from layer 2 is sentence textvectors having the same part of speech.
These vectors are then fed into the Text Semantic SimilarityModule to measure the similarity score using Wu and Palmer measure (Wu & Palmer, 1994) for wordlevel similarity and WordNet taxonomy as an information source according to equations (1-2).3.1 Data setWe conducted system experiments on a pilot benchmark data set created for measuring short-text se-mantic similarity (O'Shea, Bandar, Crockett, & McLean, 2008).
It contains 65 sentence pairs with hu-39man similarity judgements assigned to each pair.
During this data set creation, 32 graduate nativespeakers were assigned to score the degree of similarity using scores from 0 to 4 and following  aguideline of semantic anchor (Charles, 2000)  included in  Table 2.
To make the semantic anchorscomply with our system generated scores (0 to 1), the scale points have been linearly transformed asindicated in the second column of the same table.Fig.
2:  (a) Word POS conversion aided semantic similarity system; (b) Word parts of speech conversion AlgorithmTable 1: Semantic AnchorsScalePointsTransformedScale Points*Semantic Anchor0.0 0.0 The sentences are unrelated in meaning1.0 0.25 The sentences are vaguely similar in meaning2.0 0.5 The sentences are very much a like in meaning3.0 0.75 The sentences are strongly related in meaning4.0 1.0 The sentences are identical in meaning3.2 Results and EvaluationOur evaluation for all three conversion assisted systems is centered around the human judgements.Human ratings reflect the extent to which every two sentences are semantically related from the hu-man perception.
A comparison of our conversion aided methods (TW, CwW, CwM, CwC) and the find-ings of two baseline methods (STASIS, LSA) is presented in Table 2.
The notations TW, CwW, CwM,CwC stand for, traditional WordNet, conversion with WordNet, conversion with Morphosemanticsand conversion with CatVar respectively.
We selected the baselines because of their fitness for pur-pose and their evaluation on the same benchmark data.
STASIS, thoroughly described in (Li, et al.,2006), is a textual similarity measure combining taxonomy and word order information to compute thesemantic relatedness for two sentences.
While LSA (latent sematic analysis) (Deerwester et.
al, 1990)is a corpus-based measure developed for indexing and retrieval of text documents but later adapted fortasks including sentence similarity.
In LSA, texts are represented as a matrix, of high dimensional se-mantic vectors, which is then transformed using Singular Value Decomposition (SVD); namely,where A is a term-document matrix, S is the diagonal matrix of the Singular Value De-composition, while T and D are left and right singular vectors with orthogonal columns.
As pointedout, the results obtained in (J. O?Shea, Bandar, Crockett, & McLean, 2008) have been compared to ourexperimental results.
Due to the space limitation, results of only 10 randomly selected sentence pairsfrom the benchmark data set are listed in Table 2 with the second column being the human ratings.Algorithm1: Word Parts Of Speech ConversionInput:      sentence with  different word classes;Output:   sentence with  same word class(CWS);S   ?
Sentence;CWS?
{ };C ?
{ }W ?
tokenize(S)for each  wi ?
W  doIf  wi  = inflected   thenwi  ?
baseform(wi)endifIf (wi  not in targetcategory)cw?
convert (wi)endifCWS ?
CWS {cw}end forreturn CWS(a) (b)40Table 2.
Human, STASIS, LSA, TW, CwW, CwM and CwC similarity scores for 10 sentence pairsSentence Pair Human STASIS LSA TW CwW CwM CwC1.cord:smile 0.01 0.329 0.51 0.362 0.49 0.57 0.6679.asylum:fruit 0.005 0.209 0.505 0.430 0.43 0.506 0.52217.coast:forest 0.063 0.356 0.575 0.616 0.738 0.80 0.79129.bird:woodland 0.013 0.335 0.505 0.465 0.583 0.665 0.66533.hill:woodland 0.145 0.59 0.81 0.826 0.826 0.826 0.82657.forest:woodland 0.628 0.7 0.75 0.709 0.804 0.867 0.86758.implement:tool 0.59 0.753 0.83 0.781 0.744 0.905 0.88559.cock:rooster 0.863 1 0.985 1 1 1 161.cushion:pillow 0.523 0.662 0.63 0.636 0.637 0.723 0.84265.gem: jewel 0.653 0.831 0.86 0.717 0.745 0.793 0.778To measure the strength of the linear association measured in terms of the correlation coefficients r,between the score of each conversion aided method and the human judgements, are computed and pre-sented in Table 3 using equation 3 where n is the number of sentence pairs while mi and hi representmachine and human scores, respectively, for the ith pair.?
?
??
( ?(?    )
) ?
( ?(?    )
)( )The performances of all the three methods gradually excel with an increasing shared semanticstrength between the sentence pairs.
However, for the less related sentence pairs, it is evident that thehuman perception of similarity is more strict than the loose definition of similarity based on lexicalconcepts and hierarchical taxonomy.
Table 2 shows that all the three conversion aided methods con-siderably improve semantic scores over the traditional WordNet (TW).
Out of the three schemes, Cat-Var-aided conversion establishes the highest semantic correlation between the sentence pairs corrobo-rating the hypothesis that CatVar can be used as a supplementary resource to WordNet.
Overall, scoresof correlation coefficients of the developed approaches with the baseline methods; STASIS and LSAand human judgements indicate that CatVar-based conversion provides best performance.
On the otherhand, the correlation coefficients (expression 3) between our conversions aided schemes and the twocompared benchmark methods along with the human judgements, summarized in Table 3, shows thatstatistically speaking, latent semantic analysis (LSA) provides the best consistency with WordNet-based similarity measures.Table 3: Correlations Coefficients (r) between machine and human scoresCwW CwM CwC STASIS LSAHuman 0.729826 0.830984 0.881647 0.816 0.838STASIS 0.771874 0.851675 0.872939 -- 0.76LSA 0.804518 0.875024 0.822453 0.76 --In order to visualize the effect of correlation coefficient across sentence pairs, Fig.
3 illustrates theassociation between the human ratings and each of the achieved results.
It is evident that all the threerelationships follow a positive linear trend with slightly varying but strong correlation with the humanjudgements and without outliers.
For those sentence pairs which are either strongly related or identicalin meaning, there is a high agreement between the human evaluation and machine assessment for se-mantic similarity.
The results also confirm that CatVar aided conversion yields a strong positive corre-lation with the human rating.41Fig.
3:  Relationships between the obtained results and human judgements for the benchmark data set4 ConclusionTo improve the accuracy of capturing semantic textual relatedness, we carried out word parts ofspeech conversion by augmenting two lexical databases; CatVar and Morphosemantics to traditionalWordNet similarity.
Our comparative analysis with human judgements and two baseline systemsfound that WordNet taxonomy can be supplemented with other linguistic resources, such as CatVar, toenhance the measurement of sentence semantic similarity.
The findings revealed that the word parts ofspeech conversion captures the sematic correlation between two pieces of text in a way that bringscloser to human perception.
As a future work, we plan to improve the suggested conversion aided sim-ilarity measures and apply them on various large scale data set.ReferencesAli, M., Ghosh, M. K., & Al-Mamun, A.
(2009).
Multi-document Text Summarization: SimWithFirst BasedFeatures and Sentence Co-selection Based Evaluation.
Paper presented at the Future Computer andCommunication, 2009.
ICFCC 2009. International Conference on.Bawakid, A., & Oussalah, M. (2010).
A semantic-based text classification system.
Paper presented at theCybernetic Intelligent Systems (CIS), 2010 IEEE 9th International Conference on.Charles, W. G. (2000).
Contextual correlates of meaning.
Applied Psycholinguistics, 21(04), 505-524.Deerwester et.
al, S. C. (1990).
Indexing by latent semantic analysis.
JASIS, 41(6), 391-407.Fellbaum, C., Osherson, A., & Clark, P. E. (2009).
Putting semantics into WordNet?s" morphosemantic" linksHuman Language Technology.
Challenges of the Information Society (pp.
350-358): Springer.Gomaa, W. H., & Fahmy, A.
A.
(2013).
A Survey of text similarity approaches.
International Journal ofComputer Applications, 68(13), 13-18.Habash, N., & Dorr, B.
(2003).
A categorial variation database for English.
Paper presented at the Proceedingsof the 2003 Conference of the North American Chapter of the Association for ComputationalLinguistics on Human Language Technology-Volume 1.Haque, R., Naskar, S. K., Way, A., Costa-Juss?, M. R., & Banchs, R. E. (2010).
Sentence similarity-basedsource context modelling in pbsmt.
Paper presented at the Asian Language Processing (IALP), 2010International Conference on.Li, Y., McLean, D., Bandar, Z.
A., O'shea, J. D., & Crockett, K. (2006).
Sentence similarity based on semanticnets and corpus statistics.
Knowledge and Data Engineering, IEEE Transactions on, 18(8), 1138-1150.Malik, R., Subramaniam, L. V., & Kaushik, S. (2007).
Automatically Selecting Answer Templates to Respond toCustomer Emails.
Paper presented at the IJCAI.Miller, G. A.
(1995).
WordNet: a lexical database for English.
Communications of the ACM, 38(11), 39-41.O'Shea, J., Bandar, Z., Crockett, K., & McLean, D. (2008).
Pilot short text semantic similarity benchmark dataset: Full listing and description.
Computing.O?Shea, J., Bandar, Z., Crockett, K., & McLean, D. (2008).
A comparative study of two short text semanticsimilarity measures Agent and Multi-Agent Systems: Technologies and Applications (pp.
172-181):Springer.O?Shea, K. (2012).
An approach to conversational agent design using semantic sentence similarity.
AppliedIntelligence, 37(4), 558-568.Osman, A. H., Salim, N., Binwahlan, M. S., Alteeb, R., & Abuobieda, A.
(2012).
An improved plagiarismdetection scheme based on semantic role labeling.
Applied Soft Computing, 12(5), 1493-1502.Pedersen, T., Patwardhan, S., & Michelizzi, J.
(2004).
WordNet:: Similarity: measuring the relatedness ofconcepts.
Paper presented at the Demonstration Papers at HLT-NAACL 2004.Wu, Z., & Palmer, M. (1994).
Verbs semantics and lexical selection.
Paper presented at the Proceedings of the32nd annual meeting on Association for Computational Linguistics.42
