Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 73?84,Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational LinguisticsParaphrasing 4 Microblog NormalizationWang Ling Chris Dyer Alan W Black Isabel TrancosoL2F Spoken Systems Lab, INESC-ID, Lisbon, PortugalLanguage Technologies Institute, Carnegie Mellon University, Pittsburgh, PA, USAInstituto Superior Te?cnico, Lisbon, Portugal{lingwang,cdyer,awb}@cs.cmu.eduisabel.trancoso@inesc-id.ptAbstractCompared to the edited genres that haveplayed a central role in NLP research, mi-croblog texts use a more informal register withnonstandard lexical items, abbreviations, andfree orthographic variation.
When confrontedwith such input, conventional text analysistools often perform poorly.
Normalization?
replacing orthographically or lexically id-iosyncratic forms with more standard variants?
can improve performance.
We propose amethod for learning normalization rules frommachine translations of a parallel corpus ofmicroblog messages.
To validate the utility ofour approach, we evaluate extrinsically, show-ing that normalizing English tweets and thentranslating improves translation quality (com-pared to translating unnormalized text) usingthree standard web translation services as wellas a phrase-based translation system trainedon parallel microblog data.1 IntroductionMicroblogs such as Twitter, Sina Weibo (a popularChinese microblog service) and Facebook have re-ceived increasing attention in diverse research com-munities (Han and Baldwin, 2011; Hawn, 2009, in-ter alia).
In contrast to traditional text domains thatuse carefully controlled, standardized language, mi-croblog content is often informal, with less adher-ence to conventions regarding punctuation, spelling,and style, and with a higher proportion of dialector pronouciation-derived orthography.
While thisdiversity itself is an important resource for study-ing, e.g., sociolinguistic variation (Eisenstein et al2011; Eisenstein, 2013), it poses challenges to NLPapplications developed for more formal domains.
Ifretaining variation due to sociolinguistic or phono-logical factors is not crucial, text normalization canimprove performance on downstream tasks (?2).This paper introduces a data-driven approach tolearning normalization rules by conceiving of nor-malization as a kind of paraphrasing and takinginspiration from the bilingual pivot approach toparaphrase detection (Bannard and Callison-Burch,2005) and the observation that translation is aninherently ?simplifying?
process (Laviosa, 1998;Volansky et al 2013).
Starting from a parallel cor-pus of microblog messages consisting of Englishpaired with several other languages (Ling et al2013), we use standard web machine translation sys-tems to re-translate the non-English segment, pro-ducing ?English original,English MT?
pairs (?3).These are our normalization examples, with MT out-put playing the role of normalized English.
Sev-eral techniques for identifying high-precision nor-malization rules are proposed, and we introduce acharacter-based normalization model to account forpredictable character-level processes, like repetitionand substitution (?4).
We then describe our decod-ing procedure (?5) and show that our normaliza-tion model improve translation quality for English?Chinese microblog translation (?6).12 Why Normalize?Consider the English tweet shown in the first row ofTable 1 which contains several elements that NLP1The datasets used in this paper are available from http://www.cs.cmu.edu/?lingwang/microtopia.73Table 1: Translations of an English microblog messageinto Mandarin, using three web translation services.orig.
To DanielVeuleman yea iknw imma work on thatMT1 ?iknw DanielVeuleman????
?MT2 DanielVeuleman?iknw??????
?MT3 ?DanielVeuleman?
?iknw imma?????
?systems trained on edited domains may not handlewell.
First, it contains several nonstandard abbre-viations, such as, yea, iknw and imma (abbrevia-tions of yes, I know and I am going to).
Second,there is no punctuation in the text although stan-dard convention would dictate that it should be used.To illustrate the effect this can have, consider nowthe translations produced by Google Translate,2 Mi-crosoft Bing,3 and Youdao,4 shown in rows 2?4.Even with no knowledge of Chinese, it is not hardto see that all engines have produced poor transla-tions: the abbreviation iknw is left translated by allengines, and imma is variously deleted, left untrans-lated, or transliterated into the meaningless sequence??
(pronounced y??
ma?
).While normalization to a form like To DanielVeuleman: Yes, I know.
I am going to work on that.does indeed lose some information (information im-portant for an analysis of sociolinguistic or phono-logical variation clearly goes missing), it expressesthe propositional content of the original in a formthat is more amenable to processing by traditionaltools.
Translating the normalized form with GoogleTranslate produces ????Veuleman???????????????
?, which is a substantialimprovement over all translations in Table 1.3 Obtaining Normalization ExamplesWe want to treat normalization as a supervised learn-ing problem akin to machine translation, and to doso, we need to obtain pairs of microblog posts andtheir normalized forms.
While it would be possibleto ask annotators to create such a corpus, it wouldbe quite expensive to obtain large numbers of ex-amples.
In this section, we propose a method forcreating normalization examples without any human2http://translate.google.com/3http://www.bing.com/translator4http://fanyi.youdao.com/Table 2: Translations of Chinese original post to Englishusing web-based service.orig.
To DanielVeuleman yea iknw imma work on thatorig.
?DanielVeuleman?????????????????
?MT1 Right DanielVeuleman say, yes, I know, I?mXiangna effortsMT2 DanielVeuleman said, Yes, I know, I?m that hardMT3 Said to DanielVeuleman, yes, I know, I?m tothat effortannotation, by leveraging existing tools and data re-sources.The English example sentence in Table 1 was se-lected from the ?topia parallel corpus (Ling etal., 2013), which consists of self-translated mes-sages from Twitter and Sina Weibo (i.e., each mes-sage contains a translation of itself).
Row 2 ofTable 2 shows the Mandarin self-translation fromthe corpus.
The key observation is what happenswhen we automatically translate the Mandarin ver-sion back into English.
Rows 3?5 shows automatictranslations from three standard web MT engines.While not perfect, the translations contain severalcorrectly normalized subphrases.
We will use suchre-translations as a source of (noisy) normalizationexamples.
Since such self-translations are relativelynumerous on microblogs, this technique can providea large amount of data.Of course, to motivate this paper, we argued thatNLP tools ?
like the very translation systems wepropose to use ?
often fail on unnormalized input.Is this a problem?
We argue that it is not for thefollowing two reasons.Normalization in translation.
Work in transla-tion studies has observed that translation tends tobe a generalizing process that ?smooths out?
author-and work-specific idiosyncrasies (Laviosa, 1998;Volansky et al 2013).
Assuming this observa-tion is robust, we expect that dialectal variant formsfound in microblogs to be normalized in translation.Therefore, if the parallel segments in our microblogparallel corpus did indeed originate through a trans-lation process (rather than, e.g., being generated astwo independent utterances from a bilingual), wemay then state the following assumption about thedistribution of variant forms in a parallel segment74?e, f?
: if e contains nonstandard lexical variants,then f is likely to be a normalized translation usingwith fewer nonstandard lexical variants (and vice-versa).Uncorrelated orthographic variants.
Any writ-ten language has the potential to make creative useof orthography: alphabetic scripts can render ap-proximations of pronunciation variants; logographicscripts can use homophonic substitutions.
However,the kinds of innovations used in particular languageswill be language specific (depending on details ofthe phonology, lexicon, and orthography of the lan-guage).
However, for language pairs that differ sub-stantially in these dimensions, it may not alwaysbe possible (or at least easy) to preserve particularkinds of nonstandard orthographic forms in trans-lation.
Consider the (relatively common) pronoun-verb compounds like iknw and imma from our mo-tivating example: since Chinese uses a logographicscript without spaces, there is no obvious equivalent.3.1 Variant?Normalized Parallel CorpusFor the two reasons outlined above, we argue thatwe will be able to translate back into English us-ing MT, even when the underlying English part ofthe parallel corpus has a great deal of nonstandardcontent.
We leverage this fact to build the normal-ization corpus, where the original English tweet istreated as the variant form, and the automatic trans-lation obtained from another language is considereda potential normalization.5Our process is as follows.
The microblog cor-pus of Ling et al(2013) contains sentence pairs ex-tracted from Twitter and Sina Weibo, for multiplelanguage pairs.
We use all corpora that include En-glish as one of the languages in the pair.
The respec-tive non-English side is translated into English usingdifferent translation engines.
The different sets weused and the engines we used to translate are shownin Table 3.
Thus, for each original English post o,we obtain n paraphrases {pi}ni=1, from n differenttranslation engines.5We additionally assume that the translation engines aretrained to output more standardized data, so there will be addi-tional normalizing effect from the machine translation system.Table 3: Corpora Used for Paraphrasing.Lang.
Pair Source Segs.
MT EnginesZH-EN Weibo 800K Google, Bing, YoudaoZH-EN Twitter 113K Google, Bing, YoudaoAR-EN Twitter 114K Google, BingRU-EN Twitter 119K Google, BingKO-EN Twitter 78K Google, BingJA-EN Twitter 75K Google, Bing3.2 Alignment and FilteringOur parallel microblog corpus was crawled automat-ically and contains many misaligned sentences.
Toimprove precision, we attempt to find the similar-ity between the (unnormalized) original and eachof the normalizations using an alignment based onthe one used in METEOR (Denkowski and Lavie,2011), which computes the best alignment betweenthe original tweet and each of the normalizationsbut modified to permit domain-specific approximatematches.
To address lexical variants, we allow fuzzyword matching, that is, we allow lexically similar,such as yea and yes to be aligned (similarity is de-termined by the Levenshtein distance).
We also per-form phrasal matchings, such as ikwn to i know.
Todo so, we extend the alignment algorithm from wordto phrasal alignments.
More precisely, given theoriginal post o and a candidate normalization n, wewish to find the optimal segmentation producing agood alignment.
A segmentation s = ?s1, .
.
.
, s|s|?is a sequence of segments that aligns as a block to asource word.
For instance, for the sentence yea iknwimma work on that, one possible segmentation couldbe s1 =yea ikwn, s2 =imma and s3 =work on that.Model.
We define the score of an alignment a andsegmentation s in using a model that makes semi-Markov independence assumptions, similar to thework in (Bansal et al 2011), u(a, s | o,n) =|s|?i=1[ue(si, ai | n)?
ut(ai | ai?1)?
u`(|si|)]In this model, the maximal scoring segmentationand alignment can be found using a polynomial timedynamic programming algorithm.
Each segmentcan be aligned to any word or segment in o. Thealigned segment for sk is defined as ak.
For the75score of a segment correspondence ue(s, a | n), weassume that this can be estimated using the lexicalsimilarity between segments, which we define to be1?
L(sk,ak)max{|sk|,|ak|} , where L(x, y) denotes the Leven-shtein distance between strings x and y, normalizedby the highest possible distance between those seg-ments.For the alignment score ut, we assume that therelative order of the two sequences will be mostlymonotonous.
Thus, we approximate ut with the fol-lowing density poss(ak) ?
pose(ak?1) ?
N (1, 1),where the poss is the index of the first word in thesegment and pose the one of the last word.After finding the Viterbi alignments, we computethe similarity measure ?
= |A||A|+|U | , used in (Resnikand Smith, 2003), where |A| and |U | are the numberof words that were aligned and unaligned, respec-tively.
In this work, we extract the pair if ?
> 0.2.4 Normalization ModelFrom the normalization corpus, we learn a nor-malization model that generalizes the normalizationprocess.
That is, from the data we observe that ToDanielVeuleman yea iknw imma work on that is nor-malized to To Daniel Veuleman: yes, I know.
Iam going to work on that.
However, this is notuseful, since the chances of the exact sentence ToDanielVeuleman yea iknw imma work on that occur-ring in the data is low.
We wish to learn a process toconvert the original tweet into the normalized form.There are two mechanisms that we use in ourmodel.
The first (?4.1) learns word?word andphrase?phrase mappings.
That is, we wish to findthat DanielVeuleman is normalized to Daniel Veule-man, that iknw is normalized to I know and thatimma is normalized to I am going.
These mappingsare more useful, since whenever iknw occurs in thedata, we have the option to normalize it to I know.The second (?4.2) learns character sequence map-pings.
If we look at the normalization DanielVeule-man to Daniel Veuleman, we can see that it is onlyapplicable when the exact word DanielVeuleman oc-curs.
However, we wish to learn that it is uncom-mon for the letters l and v to occur in the same wordsequentially, so that be can add missing spaces inwords that contain the lv character sequence, such asnormalizing phenomenalvoter to phenomenal voter.I wanna go 4 pizza 2dayI want go for pizza todaytoFigure 1: Variant?normalized alignment with the variantform above and the normalized form below; solid linesshow potential normalizations, while dashed lines repre-sent identical translations.However, there are also cases where this is not true,for instance, in the word velvet, we do not wish toseparate the letters l and v. Thus, we shall describethe process we use to decide when to apply thesetransformations.4.1 From Sentences To PhrasesThe process to find phrases from sentences has beenthroughly studied in Machine Translation.
This isgenerally done in two steps, Word Alignments andPhrase Extraction.Alignment.
The first step is to find the word-levelalignments between the original post and its nor-malization.
This is a well studied problem in MT,referred as Word Alignment (Brown et al 1993).Many alignment models have been proposed, suchas, the HMM-based word alignment models (Vo-gel et al 1996) and the IBM models (Och andNey, 2003).
Generally, a symmetrization step is per-formed, where the bidirectional alignments are com-bined heuristically.
In our work, we use the fastaligner proposed in (Dyer et al 2013) to obtain theword alignments.
Figure 1 shows an example of anword aligned pair of a tweet and its normalization.Phrase Extraction.
The phrasal extractionstep (Ling et al 2010), uses the word alignedsentences and extracts phrasal mappings betweenthe original tweet and its normalization, namedphrase pairs.
For instance, in Figure 1, we wouldlike to extract the phrasal mapping from go 4 to gofor, so that we learn that the word 4 in the context ofgo is normalized to the proposition for.
To do this,the most common approach is to use the templateproposed in (Och and Ney, 2004), which allowsphrase pairs to be extracted, if there is at least oneword alignment within the pair, and there are no76Table 4: Fragment of the phrase normalization modelbuilt, for each original phrase o, we present the top-3 nor-malized forms ranked by f(n | o).Original (o) Normalization (n) f(n | o)wanna want to 0.4679wanna will 0.0274wanna going to 0.01144 4 0.56414 for 0.01795go 4 go for 1.0000words inside the pair that are aligned to words notin the pair.
For instance, in the example above, thephrase pair that normalizes wanna to want to wouldbe extracted, but the phrase pair normalizing wannato want to go would not, because the word go in thenormalization is aligned to a word not in the pair.Phrasal Features.
After extracting the phrasepairs, a model is produced with features derivedfrom phrase pair occurrences during extraction.
Thismodel is equivalent to phrasal translation model inMT, but we shall refer to it as the normalizationmodel.
For a phrase pair ?o,n?, where o is the origi-nal phrase, and n is the normalized phrase, we com-pute the normalization relative frequency f(n | o) =C(n,o)C(o) , where C(n, o) denotes the number of timeso was normalized to n and C(o) denotes the numberof times o was seen in the extracted phrase pairs.
Ta-ble 4 gives a fragment of the normalization model.The columns represent the original phrase, its nor-malization and the probability, respectively.In Table 4, we observe that the abbreviationwanna is normalized to want to with a relativelyhigh probability, but it can also be normalized toother equivalent expressions, such as will and go-ing to.
The word 4 by itself has a low probabilityto be normalized to the preposition for.
This is ex-pected, since this decision cannot be made withoutcontext.
However, we see that the phrase go 4 isnormalized to go for with a high probability, whichspecifies that within the context of go, 4 is generallyused as a preposition.4.2 From Phrases to CharactersWhile we can learn lexical variants that are in thecorpora using the phrase model, we can only addressword forms that have been observed in the corpora.Table 5: Fragment of the character normalization modelwhere examples representative of the lexical variant gen-eration process are encoded in the model.Original (o) Normalization (n) f(n | o)o o o o o 0.0223o o o o 0.0439s c 0.0331z s 0.0741s h c h 0.0192 t o 0.0144 f o r 0.00130 o 0.0657i n g f o r i n g <space> f o r 0.4545g f g <space> f 0.01028This is quite limited, since we cannot expect all theword forms to be present, such as all the possibleorthographic errors for the word cat, such as catt,kat and caaaat.
Thus, we will build a character-based model that learns the process lexical variantsare generated at the subword level.Our character-based model is similar to thephrase-based model, except that, rather than learn-ing word-based mappings from the original tweetand the normalization sentences, we learn character-based mappings from the original phrases to the nor-malizations of those phrases.
Thus, we extract thephrase pairs in the phrasal normalization model, anduse them as a training corpora.
To do this, for eachphrase pair, we add a start token, <start>, and aend token, <end>, at the beginning and ending ofthe phrase pair.
Afterwards, we separate all charac-ters by space and add a space token <space> wherespaces were originally.
For instance, the phrasepair normalizing DanielVeuleman to Daniel Veule-man would be converted to <start> d a n i e l v e ul e m a n <end> and <start> d a n i e l <space> ve u l e m a n <end>.Character-based Normalization Model - Tobuild the character-based model, we proceed usingthe same approach as in the phrasal normalizationmodel.
We first align characters using Word Align-ment Models, and then we perform phrase extrac-tion to retrieve the phrasal character segments, andbuild the character-based model by collecting statis-tics.
Once again, we provide examples of entries inthe model in Table 5.77We observe that many of the normalizations dealtwith in the previous model by memorizing phrasesare captured with string transformations.
For in-stance, from phrase pairs such as tooo to too andsooo to so, we learn that sequences of o?s can bereduced to 2 or 1 o.
Other examples include or-thographic substitutions, such as 2 for to and 4for for (as found in 2gether, 2morrow, 4ever and4get).
Moreover, orthographic errors can be gener-ated from mistaking characters with similar phoneticproperties, such as, s to c, z to s and sh to ch, gener-ating lexical variants such as reprecenting.
Finally,we learn that the number 0 that resembles the lettero, can be used as a replacement, as in g00d.
Finally,we can see that the rule ingfor to ing for attempts tofind segmentation errors, such as goingfor, where aspace between going and for was omitted.65 Normalization DecoderIn section 4, we built two models to learn the processof normalization, the phrase-based model and thecharacter-based model.
In this section, we describethe decoder we used to normalize the sentences.The advantage of the phrase-based model is that itcan make decisions for normalization based on con-text.
That is, it contains phrasal units, such as, go4, that determine, when the word 4 should be nor-malized to the preposition for and when to leave itas a number.
However, it cannot address words thatare unseen in the corpora.
For instance, if the wordform 4ever is not seen in the training corpora, it isnot be able to normalize it, even if it has seen theword 4get normalized to forget.
On the other hand,the character-based model learns subword normal-izations, for instance, if we see the word nnnnnonormalized to no, we can learn that repetitions ofthe letter n are generally shorted to n, which al-lows it to generate new word forms.
This modelhas strong generalization potential, but the weak-ness of the character-based model is that it fails to6Note that this captures the context in which such transfor-mations are likely to occur: there are not many words that con-tain the sequence ingfor, so the probability that these should benormalized by inserting a space is high.
On the other hand, wecannot assume that if we observe the sequence gf, we can safelyseparate these with a space.
This is because, there are manywords that contain this sequence, such as the abbreviation ofgf (girlfriend), dogfight, and bigfoot.consider the context of the normalization that thephrase-based model uses to make normalization de-cisions.
Thus, our goal in this section is describe adecoder that uses both models to improve the qualityof the normalizations.5.1 Phrasal DecoderWe use Moses, an off-the-shelf phrase-based MTsystem (Koehn et al 2007), to ?translate?
the orig-inal tweet its normalized form using the phrasalmodel (?4.1).
Aside form the normalization prob-ability, we also use the common features used inMT.
These are the reverse normalization probabil-ity, the lexical and reverse lexical probabilities andthe phrase penalty.
We also use the MSD reorder-ing model proposed in (Koehn et al 2005), whichadds reordering features.7 The final score of eachphrase pair is given as a sum of weighted log fea-tures.
The weights for these features are optimizedusing MERT (Och, 2003).
In our work, we sampled150 tweets randomly from Twitter and normalizedthem manually, and used these samples as devel-opment data for MERT.
As for the character-basedmodel features, we simply rank the training phrasepairs by their relative frequency the f(n | o), and usethe top-1000 phrase pairs as development set.
Fi-nally, a language model is required during decodingas a prior, since it defines the type of language thatis produced by the output.
We wish to normalizedto formal language, which is generally better pro-cessed by NLP tools.
Thus, for the phrase model,we use the English NIST dataset composed of 8Msentences in English from the news domain to builda 5-gram Kneser-Ney smoothed language model.5.2 Character and Phrasal DecoderWe now turn to how to apply the character-based(?4.2), together with the phrasal model.
For thismodel, we again use Moses, treating each charac-ter as a ?word?.
The simplest way to combine bothmethods is first to decode the input o sentence withthe character-based decoder, normalizing each wordindependently and then normalizing the resultingoutput using the phrase-based decoder, which en-ables the phrase model to score the outputs of thecharacter model in context.7Reordering helps find lexical variants that are generated bytransposing characters, such as, mabye to maybe.780 1 2 3 4 5 6Iwannawant to meeeeetmeetmetDanielVeulemanDaniel VeulemanFigure 2: Example output lattice of the character-based decoder, for the sentence I wanna meeeeet DanielVeuleman.Our process is as follows.
Given the input sen-tence o, with the words o1, .
.
.
, om, where m isthe number of words in the input, we generate foreach word oi a list of n-best normalization candi-dates z1oi , .
.
.
, znoi .
We further filter the candidatesusing two criteria.
We start by filtering each can-didate zjoi that occurs less frequently than the orig-inal word oi.
This is motivated by our observationthat lexical variants occur far less than the respec-tive standard form.
Second, we build a corpus ofEnglish language Twitter consisting of 70M tweets,extract the unigram counts, and perform Brown clus-tering (Brown et al 1992) with k = 3000 clusters.Next, we calculate the cluster similarity between oiand each surviving candidate, zjoi .
We filter the can-didate if the similarity is less than 0.8.
The similar-ity between two clusters represented as bit strings,S[c(oi), c(zjoi)], calculated as:S(x, y) =2 ?
|lpm{x, y)}||x|+ |y|,where lpm computes the longest common prefix ofthe contexts and |x| is the length of the bit string.8If a candidate contains more than one word (becausea space was inserted), we set its count as the mini-mum count among its words.
To find the cluster formultiple word units, we concatenate the words to-gether, and find the cluster with the resulting word ifit exists.
This is motivated by the fact that it is com-mon for missing spaces to exist in microblog cor-pora, generating new word forms, such as wantto,goingfor, and given a large enough corpora as theone we used, these errors occur frequently enough tobe placed in the correct cluster.
In fact, the variantssuch as wanna and tmi, occur in the same clusters asthe words wantto and toomuchinformation.Remaining candidates are combined into a wordlattice, enabling us to perform lattice-based decod-8Brown clusters are organized such that more words withmore similar distributions share common prefixes.ing with the phrasal model (Dyer et al 2008).
Fig-ure 2, provides an example of such a lattice for thevariant sentence I wanna meeeet DanielVeuleman.5.3 Learning Variants from Monolingual DataUntil now, we learned normalizations from pairs oforiginal tweets and their normalizations.
We shallnow describe a process to leverage monolingual doc-uments to learn new normalizations, since the mono-lingual data is far easier to obtain than parallel data.This process is similar to the work in (Han et al2012), where confusion sets of contextually simi-lar words are built initially as potential normaliza-tion candidates.
We again use the k = 3000 Brownclusters,9 and this time consider the contents of eachcluster as a set of possible normalization variants.For instance, we find that the cluster that includes theword never, also includes the variant forms neverrrr,neva and nevahhh.
However, the cluster also con-tains non-variant forms, such as gladly and glady.Thus, we want to find that neverrrr maps to never,while glady maps to gladly in the same cluster.
Ourwork differs from previous work in that, rather thandefining features manually, we use our character-based decoder to find the mappings between lexicalvariants and their normalizations.For every word type wi in cluster c(wi) ={w1, .
.
.
, wn}, we generate a set of possible candi-dates for each word w1i , .
.
.
, wmi .
Then, we builda directed acyclic graph (DAG), where every word.We add an edge between wi and wj , if wi can bedecoded into wj using the character model from theprevious section, and also if wi occurs less than wj ;the second condition guarantees that the graph willbe acyclic.
Sample graphs are shown in Figure 3.Afterwards, we find the number of paths betweenall nodes in the graph (this can be computed effi-ciently in O(|V | + |E|) time).
Then, for each word9The Brown clustering algorithm groups words togetherbased on contextual similarity.79neverrneva nevenevarnevergladygladlycladlyFigure 3: Example DAGs, built from the cluster contain-ing the words never and gladly.wi, we find the wj to which it has the highest num-ber of paths to and extract the normalization of wito wj .
In case of a tie, we choose the word wj thatoccurs more often in the monolingual corpora.
Thisis motivated by the fact that normalizations are tran-sitive.
Thus, even if neva cannot be decoded directlyto never, we can use nevar as an intermediate step tofind the correct normalization.
This is performed forall the clusters, and the resulting dictionary of lexi-cal variants mapped to their standard forms is addedto the training data of the character-based model.6 ExperimentsWe evaluate our normalization model intrinsicallyby testing whether our normalizations more closelyresemble standardized data, and then extrinsicallyby testing whether we can improve the translationquality of in-house as well as online Machine Trans-lation systems by normalizing the input.6.1 SetupWe use the gold standard by Ling et al(2013), com-posed by 2581 English-Mandarin microblog sen-tence pairs.
From this set, we randomly select 1290pairs for development and 1291 pairs for testing.The normalizer model is trained on the corporaextracted and filtered in section 3, in total, therewere 1.3M normalization pairs used during training.The test sentences are normalized using four differ-ent setups.
The first setup leaves the input sentenceunchanged, which we call No Norm.
The seconduses the phrase-based model to normalize the inputsentence, which we will denote Norm+phrase.
Thethird uses the character-based model to output lat-tices, and then decodes with the phrase based model,which we will denote Norm+phrase+char.
Finally,we test the same model after adding the training dataextracted using monolingual documents, which wewill refer as Norm+phrase+char+mono.To test the normalizations themselves, we usedGoogle Translate to translate the Mandarin side ofthe 1291 test sentence pairs back to English and usethe original English tweet.
While, this is by itselfdoes not guarantee that the normalizations are cor-rect, since the normalizations could be syntacticallyand semantically incorrect, it will allow us to checkwhether the normalizations are closer to those pro-duced by systems trained on news data.
This exper-iment will be called Norm.As an application and extrinsic evaluation for ournormalizer, we test if we can obtain gains on theMT task on microblog data by using our normalizerprior to translation.
We build two MT systems us-ing Moses.
Firstly, we build a out-of-domain modelusing the full 2012 NIST Chinese-English dataset(approximately 8M sentence pairs), which is datasetfrom the news domain, and we will denote this sys-tem as Inhouse+News.
Secondly, we build a in-domain model using the 800K sentence pairs from?topia corpora (Ling et al 2013).
We also addthe NIST dataset to improve coverage.
We call thissystem Inhouse+News+Weibo.
To train these sys-tems, we use the Moses phrase-based MT systemwith standard features (Koehn et al 2003).
For re-ordering, we use the MSD reordering model (Axel-rod et al 2005).
As the language model, we traina 5-gram model with Kneser-ney smoothing using a10M tweets from twitter.
Finally, the weights weretuned using MERT (Och, 2003).
As for online sys-tems, we consider the systems used to generate theparaphrase corpora in section 3, which we will de-note as Online A, Online B and Online C10The normalization and MT results are evaluatedwith BLEU-4 (Papineni et al 2002) comparing theproduced translations or normalizations with the ap-propriate reference.6.2 ResultsResults are shown in Table 6.
In terms of the normal-izations, we observe a much better match between10The names of the systems are hidden to not violate the pri-vacy issues in the terms and conditions of these online systems.80Table 6: Normalization and MT Results.
Rows denote different normalizations, and columns different translationsystems, except the first column (Norm), which denotes the normalization experiment.
Cells display the BLEU scoreof that experiment.Moses MosesCondition Norm (News) (News+Weibo) Online A Online B Online Cbaseline 19.90 15.10 24.37 20.09 17.89 18.79norm+phrase 21.96 15.69 24.29 20.50 18.13 18.93norm+phrase+char 22.39 15.87 24.40 20.61 18.22 19.08norm+phrase+char+mono 22.91 15.94 24.46 20.78 18.37 19.21the normalized text with the reference, than the orig-inal tweets.
In most cases, adding character-basedmodels improves the quality of the normalizations.We observe that better normalizations tend to leadto better translations.
The relative improvementsare most significant, when moving from No Normto norm+phrase normalization.
This is because,we are normalizing words that are not seen in gen-eral MT system?s training data, but occur frequentlyin microblog data, such as wanna to want to, u toyou and im to i?m.
The only exception is in the In-house+News+Weibo system, where the normaliza-tion deteriorates the results.
This is to be expected,since this system is trained on the same microblogdata used to learn the normalizations.
However, wecan observe on norm+phrase+char that if we addthe character-based model, we can observe improve-ments for this system as well as for all other ones.This is because the model is actually learning nor-malizations that are unseen in the data.
Some ex-amples of these normalization include, normalizinglookin to looking, nutz to nuts and maimi to miamibut also separating peaceof to peace of.
The factthat these improvements are obtained for all sys-tems is strong evidence that we are actually produc-ing good normalizations, and not overfitting to oneof the systems that we used to generate our data.The gains are much smaller from norm+phraseto norm+phrase+char, since the improvements weobtain come from normalizing less frequent words.Finally, we can obtain another small improvementby adding monolingual data to the character-basedmodel in norm+phrase+char+mono.7 Related WorkMost of the work in microblog normalization is fo-cused on finding the standard forms of lexical vari-ants (Yang and Eisenstein, 2013; Han et al 2013;Han et al 2012; Kaufmann, 2010; Han and Bald-win, 2011; Gouws et al 2011; Aw et al 2006).
Alexical variant is a variation of a standard word ina different lexical form.
This ranges from minor ormajor spelling errors, such as jst, juxt and jus thatare lexical variants of just, to abbreviations, such astmi and wanna, which stand for too much informa-tion and want to, respectively.
Jargon can also betreated as variants, for instance cday is a slang wordfor birthday, in some groups.There are many rules that govern the process lex-ical variants are generated.
Some variants are gener-ated from orthographic errors, caused by some mis-take from the user when writing.
For instance, thevariants representin, representting, or reprecentingcan be generated by a spurious letter swap, insertionor substitution by the user.
One way to normalizethese types of errors is to attempt to insert, removeand swap words in a lexical variant until a word ina dictionary of standard words is found (Kaufmann,2010).
Contextual features are another way to findlexical variants, since variants generally occur in thesame context as their standard form.
This includesorthographic errors, abbreviations and slang.
How-ever, this is generally not enough to detect lexicalvariants, as many words share similar contexts, suchas already, recently and normally.
Consequently,contextual features are generally used to generate aconfusion set of possible normalizations of a lexicalvariant, and then more features are used to find thecorrect normalization (Han et al 2012).
One simpleapproach is to compute the Levenshtein distance tofind lexical similarities between words, which wouldeffectively capture the mappings between represent-ting, reprecenting and representin to representing.However, a pronunciation model (Tang et al 2012)81would be needed to find the mapping between g8,2day and 4ever to great, today and forever, respec-tively.
Moreover, visual character similarity featureswould be required to find the mapping between g00dand?
to good and i.Clearly, learning this process is a challengingtask, and addressing each different case individuallywould require vast amounts of resources.
Further-more, once we change the language to normalizeto another language, the types of rules that generatelexical variants would radically change and a new setof features would have to be engineered.
We believethat to be successful in normalizing microblogs,the process to learn new lexical variants should belearned from data, making as few assumptions aspossible.
We learn our models without using anytype of predefined features, such as phonetic fea-tures or lexical features.
In fact, we will not assumethat most words and characters map to themselves,as it is assumed in methods using the Levenshteindistance (Kaufmann, 2010; Han et al 2012; Wangand Ng, 2013).
All these mappings are learned fromour data.
Furthermore, in the work above, the dictio-naries built using these methods assume that lexicalvariants are mapped to standard forms in a word-to-word mapping.
Thus, variants such as wanna, gonnaand imma are not normalizable, since they are nor-malized to multiple words want to, going to and Iam gonna.
Moreover, there are segmentation errorsthat occur from missing spaces, such as sortof andgoingfor, which also map to more than one word tosort of and going for.
These cases shall also be ad-dressed in our work.Wang and Ng (2013) argue that microblog nor-malization is not simply to map lexical variants intostandard forms, but that other tasks, such as punctua-tion correction and missing word recovery should beperformed.
Consider the example tweet you free?,while there are no lexical variants in this message,the authors consider that it is the normalizer shouldrecover the missing article are and normalize thistweet to are you free?.
To do this, the authors train aseries of models to detect and correct specific errors.While effective for narrow domains, training modelsto address each specific type of normalization is notscalable over all types of normalizations that need tobe performed within the language, and the fact that aset of new models must be implemented for anotherlanguage limits the applicability of this work.Another strong point of the work above is thata decoder is presented, while the work on build-ing dictionaries only normalize out of vocabu-lary (OOV) words.
The work on (Han et al 2012)trains a classifier to decide whether to normalize aword or not, but is still preconditioned on the factthat the word in question is OOV.
Thus, lexical vari-ants, such as, 4 and u, with the standard forms forand you, are left untreated, since they occur in othercontexts, such as u in u s a.
Inspired by the workabove, we also propose a decoder based on the exist-ing off-the-self decoder Moses (Koehn et al 2007).Finally, the work in (Xu et al 2013) obtains para-phrases from Twitter, by finding tweets that containcommon entities, such as Obama, that occur duringthe same period by matching temporal expressions.The resulting paraphrase corpora can also be used totrain a normalizer.8 ConclusionWe introduced a data-driven approach to microblognormalization based on paraphrasing.
We build acorpora of tweets and their normalizations using par-allel corpora from microblogs using MT techniques.Then, we build two models that learn generalizationsof the normalization process, one the phrase leveland on the character level.
Then, we build a de-coder that combines both models during decoding.Improvements on multiple MT systems support thevalidity of our method.In future work, we shall attempt to build normal-izations for other languages.
We shall also attemptto learn an unsupervised normalization model withonly monolingual data, similar to the work for MTin (Ravi and Knight, 2011).AcknowledgementsThe PhD thesis of Wang Ling is supported by FCT ?Fundac?a?o para a Cie?ncia e a Tecnologia, under projectSFRH/BD/51157/2010.
This work was supported by na-tional funds through FCT ?
Fundac?a?o para a Cie?ncia e aTecnologia, under project PEst-OE/EEI/LA0021/2013.The authors also wish to express their gratitude to theanonymous reviewers for their comments and insight.82References[Aw et al006] AiTi Aw, Min Zhang, Juan Xiao, andJian Su.
2006.
A phrase-based statistical model forSMS text normalization.
In Proceedings of the ACL,COLING-ACL ?06, pages 33?40, Stroudsburg, PA,USA.
Association for Computational Linguistics.
[Axelrod et al005] Amittai Axelrod, Ra Birch Mayne,Chris Callison-burch, Miles Osborne, and David Tal-bot.
2005.
Edinburgh system description for the 2005iwslt speech translation evaluation.
In In Proc.
Inter-national Workshop on Spoken Language Translation(IWSLT.
[Bannard and Callison-Burch2005] Colin Bannard andChris Callison-Burch.
2005.
Paraphrasing with bilin-gual parallel corpora.
In Proceedings of the 43rd An-nual Meeting of the Association for ComputationalLinguistics (ACL?05), pages 597?604, Ann Arbor,Michigan, June.
Association for Computational Lin-guistics.
[Bansal et al011] Mohit Bansal, Chris Quirk, andRobert C. Moore.
2011.
Gappy phrasal alignment byagreement.
In Proceedings of the 49th Annual Meet-ing of the Association for Computational Linguistics:Human Language Technologies - Volume 1, HLT ?11,pages 1308?1317, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.
[Brown et al992] Peter F Brown, Peter V Desouza,Robert L Mercer, Vincent J Della Pietra, and Jenifer CLai.
1992.
Class-based n-gram models of natural lan-guage.
Computational linguistics, 18(4):467?479.
[Brown et al993] Peter F. Brown, Vincent J. DellaPietra, Stephen A. Della Pietra, and Robert L. Mer-cer.
1993.
The mathematics of statistical machinetranslation: parameter estimation.
Comput.
Linguist.,19:263?311, June.
[Denkowski and Lavie2011] Michael Denkowski andAlon Lavie.
2011.
Meteor 1.3: Automatic metricfor reliable optimization and evaluation of machinetranslation systems.
In Proceedings of the SixthWorkshop on Statistical Machine Translation, pages85?91, Edinburgh, Scotland, July.
Association forComputational Linguistics.
[Dyer et al008] Chris Dyer, Smaranda Muresan, andPhilip Resnik.
2008.
Generalizing word lattice trans-lation.
In Proceedings of HLT-ACL.
[Dyer et al013] Chris Dyer, Victor Chahuneau, andNoah A Smith.
2013.
A simple, fast, and effectivereparameterization of ibm model 2.
In Proceedings ofNAACL-HLT, pages 644?648.
[Eisenstein et al011] Jacob Eisenstein, Noah A. Smith,and Eric P. Xing.
2011.
Discovering sociolinguis-tic associations with structured sparsity.
In Proceed-ings of the 49th Annual Meeting of the Association forComputational Linguistics: Human Language Tech-nologies - Volume 1, HLT ?11, pages 1365?1374,Stroudsburg, PA, USA.
Association for ComputationalLinguistics.
[Eisenstein2013] Jacob Eisenstein.
2013.
What to doabout bad language on the internet.
In Proceedingsof NAACL-HLT, pages 359?369.
[Gouws et al011] Stephan Gouws, Dirk Hovy, and Don-ald Metzler.
2011.
Unsupervised mining of lexicalvariants from noisy text.
In Proceedings of the FirstWorkshop on Unsupervised Learning in NLP, EMNLP?11, pages 82?90, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.
[Han and Baldwin2011] Bo Han and Timothy Baldwin.2011.
Lexical normalisation of short text messages:makn sens a #twitter.
In Proceedings of the 49th An-nual Meeting of the Association for ComputationalLinguistics: Human Language Technologies - Volume1, HLT ?11, pages 368?378, Stroudsburg, PA, USA.Association for Computational Linguistics.
[Han et al012] Bo Han, Paul Cook, and Timothy Bald-win.
2012.
Automatically constructing a normalisa-tion dictionary for microblogs.
In Proceedings of the2012 Joint Conference on Empirical Methods in Natu-ral Language Processing and Computational NaturalLanguage Learning, EMNLP-CoNLL ?12, pages 421?432, Stroudsburg, PA, USA.
Association for Compu-tational Linguistics.
[Han et al013] Bo Han, Paul Cook, and Timothy Bald-win.
2013.
Lexical normalization for social mediatext.
ACM Transactions on Intelligent Systems andTechnology (TIST), 4(1):5.
[Hawn2009] Carleen Hawn.
2009.
Take two aspirin andtweet me in the morning: how twitter, facebook, andother social media are reshaping health care.
Healthaffairs, 28(2):361?368.
[Kaufmann2010] M. Kaufmann.
2010.
Syntactic Nor-malization of Twitter Messages.
studies, 2.
[Koehn et al003] Philipp Koehn, Franz Josef Och, andDaniel Marcu.
2003.
Statistical phrase-based trans-lation.
In Proceedings of the 2003 Conference of theNorth American Chapter of the Association for Com-putational Linguistics on Human Language Technol-ogy - Volume 1, NAACL ?03, pages 48?54, Morris-town, NJ, USA.
Association for Computational Lin-guistics.
[Koehn et al005] Philipp Koehn, Amittai Axelrod,Alexandra Birch Mayne, Chris Callison-Burch, MilesOsborne, David Talbot, and Michael White.
2005.Edinburgh system description for the 2005 nist mtevaluation.
In Proceedings of Machine TranslationEvaluation Workshop 2005.
[Koehn et al007] Philipp Koehn, Hieu Hoang, Alexan-dra Birch, Chris Callison-burch, Richard Zens, Rwth83Aachen, Alexandra Constantin, Marcello Federico,Nicola Bertoldi, Chris Dyer, Brooke Cowan, WadeShen, Christine Moran, and Ondrej Bojar.
2007.Moses: Open source toolkit for statistical machinetranslation.
In Proceedings of the 45th Annual Meet-ing of the Association for Computational LinguisticsCompanion Volume Proceedings of the Demo andPoster Sessions, pages 177?180, Prague, Czech Re-public, June.
Association for Computational Linguis-tics.
[Laviosa1998] Sara Laviosa.
1998.
Core patterns oflexical use in a comparable corpus of English lexicalprose.
Meta, 43(4):557?570.
[Ling et al010] Wang Ling, Tiago Lu?
?s, Joa?o Grac?a,Lu?
?sa Coheur, and Isabel Trancoso.
2010.
Towards ageneral and extensible phrase-extraction algorithm.
InIWSLT ?10: International Workshop on Spoken Lan-guage Translation, pages 313?320, Paris, France.
[Ling et al013] Wang Ling, Guang Xiang, Chris Dyer,Alan Black, and Isabel Trancoso.
2013.
Microblogsas parallel corpora.
In Proceedings of the 51st An-nual Meeting on Association for Computational Lin-guistics, ACL ?13.
Association for Computational Lin-guistics.
[Och and Ney2003] Franz Josef Och and Hermann Ney.2003.
A systematic comparison of various statis-tical alignment models.
Computational linguistics,29(1):19?51.
[Och and Ney2004] Franz Josef Och and Hermann Ney.2004.
The alignment template approach to statisticalmachine translation.
Comput.
Linguist., 30(4):417?449, December.
[Och2003] Franz Josef Och.
2003.
Minimum error ratetraining in statistical machine translation.
In Pro-ceedings of the 41st Annual Meeting on Associationfor Computational Linguistics - Volume 1, ACL ?03,pages 160?167, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.
[Papineni et al002] Kishore Papineni, Salim Roukos,Todd Ward, and Wei-Jing Zhu.
2002.
Bleu: amethod for automatic evaluation of machine transla-tion.
In Proceedings of the 40th Annual Meeting onAssociation for Computational Linguistics, ACL ?02,pages 311?318, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.
[Ravi and Knight2011] Sujith Ravi and Kevin Knight.2011.
Deciphering foreign language.
In ACL, pages12?21.
[Resnik and Smith2003] Philip Resnik and Noah ASmith.
2003.
The web as a parallel corpus.
Com-putational Linguistics, 29(3):349?380.
[Tang et al012] Hao Tang, Joseph Keshet, and KarenLivescu.
2012.
Discriminative pronunciation mod-eling: A large-margin, feature-rich approach.
In Pro-ceedings of the 50th Annual Meeting of the Associationfor Computational Linguistics: Long Papers-Volume1, pages 194?203.
Association for Computational Lin-guistics.
[Vogel et al996] S. Vogel, H. Ney, and C. Tillmann.1996.
Hmm-based word alignment in statistical trans-lation.
In Proceedings of the 16th conference on Com-putational linguistics-Volume 2, pages 836?841.
Asso-ciation for Computational Linguistics.
[Volansky et al013] Vered Volansky, Noam Ordan, andShuly Wintner.
2013.
On the features of transla-tionese.
Literary and Linguistic Computing.
[Wang and Ng2013] Pidong Wang and Hwee Ng.
2013.A beam-search decoder for normalization of socialmedia text with application to machine translation.
InProceedings of NAACL-HLT 2013, NAACL ?13.
As-sociation for Computational Linguistics.
[Xu et al013] Wei Xu, Alan Ritter, and Ralph Grish-man.
2013.
Gathering and generating paraphrasesfrom twitter with application to normalization.
In Pro-ceedings of the Sixth Workshop on Building and Us-ing Comparable Corpora, pages 121?128, Sofia, Bul-garia, August.
Association for Computational Linguis-tics.
[Yang and Eisenstein2013] Yi Yang and Jacob Eisenstein.2013.
A log-linear model for unsupervised text nor-malization.
In Proc.
of EMNLP.84
