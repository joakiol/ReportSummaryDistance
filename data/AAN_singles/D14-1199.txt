Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1852?1857,October 25-29, 2014, Doha, Qatar.c?2014 Association for Computational LinguisticsEvent Role Extraction using Domain-Relevant Word RepresentationsEmanuela Boros??
?Romaric Besanc?on?Olivier Ferret?Brigitte Grau??
?CEA, LIST, Vision and Content Engineering Laboratory, F-91191, Gif-sur-Yvette, France?LIMSI, rue John von Neumann, Campus Universitaire d?Orsay, F-91405 Orsay cedex?ENSIIE, 1 square de la r?esistance F-91025?Evry cedexfirstname.lastname@cea.fr firstname.lastname@limsi.frAbstractThe efficiency of Information Extractionsystems is known to be heavily influencedby domain-specific knowledge but the costof developing such systems is consider-ably high.
In this article, we consider theproblem of event extraction and show thatlearning word representations from unla-beled domain-specific data and using themfor representing event roles enable to out-perform previous state-of-the-art event ex-traction models on the MUC-4 data set.1 IntroductionIn the Information Extraction (IE) field, event ex-traction constitutes a challenging task.
An eventis described by a set of participants (i.e.
at-tributes or roles) whose values are text excerpts.The event extraction task is related to several sub-tasks: event mention detection, candidate role-filler extraction, relation extraction and event tem-plate filling.
The problem we address here is thedetection of role-filler candidates and their associ-ation with specific roles in event templates.
Forthis task, IE systems adopt various ways of ex-tracting patterns or generating rules based on thesurrounding context, local context and global con-text (Patwardhan and Riloff, 2009).
Current ap-proaches for learning such patterns include boot-strapping techniques (Huang and Riloff, 2012a;Yangarber et al., 2000), weakly supervised learn-ing algorithms (Huang and Riloff, 2011; Sudo etal., 2003; Surdeanu et al., 2006), fully supervisedlearning approaches (Chieu et al., 2003; Freitag,1998; Bunescu and Mooney, 2004; Patwardhanand Riloff, 2009) and other variations.
All thesemethods rely on substantial amounts of manuallyannotated corpora and use a large body of lin-guistic knowledge.
The performance of these ap-proaches is related to the amount of knowledgeengineering deployed and a good choice of fea-tures and classifiers.
Furthermore, the efficiencyof the system relies on the a priori knowledge ofthe applicative domain (the nature of the events)and it is generally difficult to apply a system ona different domain with less annotated data with-out reconsidering the design of the features used.An important step forwards is TIERlight(Huangand Riloff, 2012a) that targeted the minimizationof human supervision with a bootstrapping tech-nique for event roles detection.
Also, PIPER (Pat-wardhan and Riloff, 2007; Patwardhan, 2010) dis-tinguishes between relevant and irrelevant regionsand learns domain-relevant extraction patterns us-ing a semantic affinity measure.
Another possi-ble approach for dealing with this problem is tocombine the use a restricted set of manually anno-tated data with a much larger set of data extractedin an unsupervised way from a corpus.
This ap-proach was experimented for relations in the con-text of Open Information Extraction (Soderland etal., 2010) but not for extracting events and theirparticipants to our knowledge.In this paper, we propose to approach the taskof labeling text spans with event roles by auto-matically learning relevant features that requireslimited prior knowledge, using a neural model toinduce semantic word representations (commonlyreferred as word embeddings) in an unsupervisedfashion, as in (Bengio et al., 2006; Collobert andWeston, 2008).
We exploit these word embed-dings as features for a supervised event role (mul-ticlass) classifier.
This type of approach has beenproved efficient for numerous tasks in natural lan-guage processing, including named entity recog-nition (Turian et al., 2010), semantic role label-ing (Collobert et al., 2011), machine translation(Schwenk and Koehn, 2008; Lambert et al., 2012),word sense disambiguation (Bordes et al., 2012) orsentiment analysis (Glorot et al., 2011; Socher etal., 2011) but has never been used, to our knowl-1852edge, for an event extraction task.
Our goal is two-fold: (1) to prove that using as only features wordvector representations makes the approach com-petitive in the event extraction task; (2) to showthat these word representations are scalable androbust when varying the size of the training data.Focusing on the data provided in MUC-4 (Lehnertet al., 1992), we prove the relevance of our ap-proach by outperforming state-of-the-art methods,in the same evaluation environment as in previousworks.2 ApproachIn this work, we approach the event extraction taskby learning word representations from a domain-specific data set and by using these representa-tions to identify the event roles.
This idea relieson the assumption that the different words usedfor a given event role in the text share some se-mantic properties, related to their context of useand that these similarities can be captured by spe-cific representations that can be automatically in-duced from the text, in an unsupervised way.
Wethen propose to rely only on these word repre-sentations to detect the event roles whereas, inmost works (Riloff, 1996; Patwardhan and Riloff,2007; Huang and Riloff, 2012a; Huang and Riloff,2012b), the role fillers are represented by a setof different features (raw words, their parts-of-speech, syntactic or semantic roles in the sen-tence).Furthermore, we propose two additional contri-butions to the construction of the word representa-tions.
The first one is to exploit limited knowledgeabout the event types (seed words) to improve thelearning procedure by better selecting the dictio-nary.
The second one is to use a max operation1onthe word vector representations in order to buildnoun phrase representations (since slot fillers aregenerally noun phrases), which represents a betterway of aggregating the semantic information bornby the word representations.2.1 Inducing Domain-Relevant WordRepresentationsIn order to induce the domain-specific word rep-resentations, we project the words into a 50-dimensional word space.
We chose a single1This max operation consists in taking, for each compo-nent of the vector, the max value of this component for eachword vector representation.layer neural network (NN) architecture that avoidsstrongly engineered features, assumes little priorknowledge about the task, but is powerful enoughto capture relevant domain information.
Follow-ing (Collobert et al., 2011), we use an NN whichlearns to predict whether a given text sequence(short word window) exists naturally in the consid-ered domain.
We represent an input sequence of nwords as ?wi?
= ?wi?(n/2).
.
.
, wi, .
.
.
wi+(n/2)?.The main idea is that each sequence of words inthe training set should receive a higher score thana sequence in which one word is replaced witha random one.
We call the sequence with a ran-dom word corrupted (??wi?)
and denote as correct(?wi?)
all the sequences of words from the dataset.
The goal of the training step is then to min-imize the following loss function for a word wiin the dictionary D: Cwi=?wi?Dmax(0, 1 ?g(?wi?)+g(??wi?
)), where g(?)
is the scoring func-tion given by the neural network.
Further detailsand evaluations of these embeddings can be foundin (Bengio et al., 2003; Bengio et al., 2006; Col-lobert and Weston, 2008; Turian et al., 2010).
Forefficiency, words are fed to our architecture as in-dices taken from a finite dictionary.
Obviously,a simple index does not carry much useful infor-mation about the word.
So, the first layer of ournetwork maps each of these word indices into afeature vector, by a lookup table operation.
Ourfirst contribution intervenes in the process of thechoosing the proper dictionary.
(Bengio, 2009)has shown that the order of the words in the dic-tionary of the neural network is not indifferent tothe quality of the achieved representations: he pro-posed to order the dictionary by frequency and se-lect the words for the corrupted sequence accord-ing to this order.
In our case, the most frequentwords are not always the most relevant for the taskof event role detection.
Since we want to have atraining more focused to the domain specific task,we chose to order the dictionary by word relevanceto the domain.
We accomplish this by consideringa limited number of seed words for each event typethat needs to be discovered in text (e.g.
attack,bombing, kidnapping, arson).
We then rate withhigher values the words that are more similar to theevent types words, according to a given semanticsimilarity, and we rank them accordingly.
We usethe ?Leacock Chodorow?
similarity from Word-net 3.0 (Leacock and Chodorow, 1998).
Initial ex-perimental results proved that using this domain-1853oriented order leads to better performance for thetask than the order by frequency.2.2 Using Word Representations to IdentifyEvent RolesAfter having generated for each word their vec-tor representation, we use them as features for theannotated data to classify event roles.
However,event role fillers are not generally single words butnoun phrases that can be, in some cases, identi-fied as named entities.
For identifying the eventroles, we therefore apply a two-step strategy.
First,we extract the noun chunks using SENNA2parser(Collobert et al., 2011; Collobert, 2011) and webuild a representation for these chunks defined asthe maximum, per column, of the vector represen-tations of the words it contains.
Second, we usea statistical classifier to recognize the slot fillers,using this representation as features.
We chosethe extra-trees ensemble classifier (Geurts et al.,2006), which is a meta estimator that fits a num-ber of randomized decision trees (extra-trees) onvarious sub-samples of the data set and use averag-ing to improve the predictive accuracy and controlover-fitting.3 Experiments and Results3.1 Task DescriptionWe conducted the experiments on the officialMUC-4 training corpus that consists of 1,700 doc-uments and instantiated templates for each doc-ument.
The task consists in extracting informa-tion about terrorist events in Latin America fromnews articles.
We classically considered the fol-lowing 4 types of events: attack, bombing, kid-napping and arson.
These are represented by tem-plates containing various slots for each piece ofinformation that should be extracted from the doc-ument (perpetrators, human targets, physical tar-gets, etc).
Following previous works (Huang andRiloff, 2011; Huang and Riloff, 2012a), we onlyconsider the ?String Slots?
in this work (other slotsneed different treatments) and we group certainslots to finally consider the five slot types PerpInd(individual perpetrator), PerpOrg (organizationalperpetrator), Target (physical target), Victim (hu-man target name or description) and Weapon (in-strument id or type).
We used 1,300 documents(DEV) for training, 200 documents (TST1+TST2)2Code and resources can be found at http://ml.nec-labs.com/senna/for tuning, and 200 documents (TST3+TST4) asthe blind test set.
To compare with similar works,we do not evaluate the template construction andonly focus on the identification of the slot fillers:for each answer key in a reference template, wecheck if we find it correctly with our extractionmethod, using head noun matching (e.g., the vic-tim her mother Martha Lopez Orozco de Lopez isconsidered to match Matha Lopez), and mergingduplicate extractions (so that different extractedslot fillers sharing the same head noun are countedonly once).
We also took into account the answerkeys with multiple values in the reference, deal-ing with conjunctions (when several victims arenamed, we need to find all of them) and disjunc-tions (when several names for the same organiza-tion are possible, we need to find any of them).Our results are reported as Precision/Recall/F1-score for each event role separately and averagedon all roles.3.2 ExperimentsIn all the experiments involving our model, we es-tablished the following stable choices of parame-ters: 50-dimensional vectors obtained by trainingon sequences of 5 words, which is consistent withprevious studies (Turian et al., 2010; Collobertand Weston, 2008).
All the hyper-parameters ofour model (e.g.
learning rate, size of the hiddenlayer, size of the word vectors) have been chosenby finetuning our event extraction system on theTST1+TST2 data set.
For DRVR-50 and W2V-50,the embeddings were built from the whole trainingcorpus (1,300 documents) and the dictionary wasmade of all the words of this corpus under theirinflected form.We used the extra-trees ensemble classifier im-plemented in (Pedregosa et al., 2011), with hyper-parameters optimized on the validation data: for-est of 500 trees and the maximum number offeatures to consider when looking for the bestsplit is?number features.
We present a 3-fold evaluation: first, we compare our system withstate-of-the-art systems on the same task, then wecompare our domain-relevant vector representa-tions (DRVR-50) to more generic word embed-dings (C&W50, HLBL-50)3and finally to another3C&W-50 are described in (Collobert and Weston,2008), HLBL-50 are the Hierarchical log-bilinear embed-dings (Mnih and Hinton, 2007), provided by (Turian etal., 2010), available at http://metaoptimize.com/projects/wordreprs induced from the Reuters-RCV11854State-of-the-art systemsPerpInd PerpOrg Target Victim Weapon Average(Riloff, 1996) 33/49/40 53/33/41 54/59/56 49/54/51 38/44/41 45/48/46(Patwardhan and Riloff, 2007) 39/48/43 55/31/40 37/60/46 44/46/45 47/47/47 44/36/40(Patwardhan and Riloff, 2009) 51/58/54 34/45/38 43/72/53 55/58/56 57/53/55 48/57/52(Huang and Riloff, 2011) 48/57/52 46/53/50 51/73/60 56/60/58 53/64/58 51/62/56(Huang and Riloff, 2012a) 47/51/47 60/39/47 37/65/47 39/53/45 53/55/54 47/53/50(Huang and Riloff, 2012b) 54/57/56 55/49/51 55/68/61 63/59/61 62/64/63 58/60/59Models based on word embeddingsC&W-50 80/55/65 64/65/64 76/72/74 53/63/57 85/64/73 68/63/65HLBL-50 81/53/64 63/67/65 78/72/75 53/63/58 93/64/75 69/62/66W2V-50 79/57/66 88/71/79 74/72/73 69/75/71 97/65/78 77/68/72DRVR-50 79/57/66 91/74/81 79/57/66 77/75/76 92/58/81 80/67/73Table 1: Accuracy of ?String Slots?
on the TST3 + TST4 test set P/R/F1 (Precision/Recall/F1-Score)word representation construction on the domain-specific data (W2V-50)4.Figure 1: F1-score results for event role labelingon MUC-4 data, for different size of training data,of ?String Slots?
on the TST3+TST4 with differ-ent parameters, compared to the learning curve ofTIER (Huang and Riloff, 2012a).
The grey pointsrepresent the performances of other IE systems.Figure 1 presents the average F1-score results,computed over the slots PerpInd, PerpOrg, Tar-get, Victim and Weapon.
We observe that mod-els relying on word embeddings globally outper-form the state-of-the-art results, which demon-strates that the word embeddings capture enoughsemantic information to perform the task of eventnewswire corpus4W2V-50 are the embeddings induced from the MUC4data set using the negative sampling training algorithm(Mikolov et al., 2013a; Mikolov et al., 2013b; Mikolov etal., 2013c), available at https://code.google.com/p/word2vec/role labeling on ?String Slots?
without using anyadditional hand-engineered features.
Moreover,our representations (DRVR-50) clearly surpass themodels based on generic embeddings (C&W-50and HLBL-50) and obtain better results than W2V-50, based the competitive model of (Mikolov etal., 2013a), even if the difference is small.
Wecan also note that the performance of our modelis good even with a small amount of training data,which makes it a good candidate to easily developan event extraction system on a new domain.Table 1 provides a more detailed analysis of thecomparative results.
We can see in this table thatour results surpass those of previous systems (0.73vs.
0.59) with, particularly, a consistently higherprecision on all roles, whereas recall is smaller forcertain roles (Target and Weapon).
To further ex-plore the impact of these representations, we com-pared our word embeddings with other word em-beddings (C&W-50, HLBL-50) and report the re-sults in Figure 1 and Table 1.
The results showthat our model also outperforms the models usingothers word embeddings (F1-score of 0.73 against0.65, 0.66).
This proves that a model learnedon a domain-specific data set does indeed pro-vide better results, even if its size is much smaller(whereas it is usually considered that neural mod-els require often important training data).
Finally,we also achieve slightly better results than W2V-50with other word representations built on the samecorpus, which shows that the choices made for theword representation construction, such as the useof domain information for word ordering, tend tohave a positive impact.18554 Conclusions and PerspectivesWe presented in this paper a new approach forevent extraction by reducing the features to onlyuse unsupervised word representations and a smallset of seed words.
The word embeddings inducedfrom a domain-specific corpus bring improvementover state-of-art models on the standard MUC-4 corpus and demonstrate a good scalability ondifferent sizes of training data sets.
Therefore,our proposal offers a promising path towards eas-ier and faster domain adaptation.
We also provethat using a domain-specific corpus leads to bet-ter word vector representations for this task thanusing other publicly-available word embeddings(even if they are induced from a larger corpus).As future work, we will reconsider the archi-tecture of the neural network and we will refo-cus on creating a deep learning model while tak-ing advantage of a larger set of types of infor-mation such as syntactic information, following(Levy and Goldberg, 2014), or semantic informa-tion, following (Yu and Dredze, 2014).ReferencesYoshua Bengio, Rejean Ducharme, and Pascal Vincent.2003.
A neural probabilistic language model.
Jour-nal of Machine Learning Research, 3:1137?1155.Yoshua Bengio, Holger Schwenk, Jean-S?ebastianSen?ecal, Fr?ederic Morin, and Jean-Luc Gauvain.2006.
Neural probabilistic language models.
InDawnE.
Holmes and LakhmiC.
Jain, editors, Inno-vations in Machine Learning, volume 194 of Studiesin Fuzziness and Soft Computing, pages 138?186.Springer Berlin Heidelberg.Yoshua Bengio.
2009.
Learning deep architectures forAI.
Foundations and trends in Machine Learning,2(1).Antoine Bordes, Xavier Glorot, Jason Weston, andYoshua Bengio.
2012.
Joint learning of wordsand meaning representations for open-text seman-tic parsing.
In Fifteenth International Conferenceon Artificial Intelligence and Statistics (AISTATS2012), pages 127?135.Razvan Bunescu and Raymond J Mooney.
2004.Collective information extraction with relationalmarkov networks.
In 42nd Annual Meeting on As-sociation for Computational Linguistics (ACL-04),pages 438?445.Hai Leong Chieu, Hwee Tou Ng, and Yoong Keok Lee.2003.
Closing the gap: Learning-based informationextraction rivaling knowledge-engineering methods.In 41st international Annual Meeting on Associationfor Computational Linguistics (ACL-2003), pages216?223.Ronan Collobert and Jason Weston.
2008.
A unifiedarchitecture for natural language processing: Deepneural networks with multitask learning.
In 25th In-ternational Conference of Machine learning (ICML-08), pages 160?167.
ACM.Ronan Collobert, Jason Weston, L?eon Battou, MichaelKarlen, Koray Kavukcuoglu, and Pavel Kuksa.2011.
Natural language processing (almost) fromscratch.
Journal of Machine Learning Research,12:2493?2537.Ronan Collobert.
2011.
Deep learning for efficientdiscriminative parsing.
In 14th International Con-ference on Artificial Intelligence and Statistics (AIS-TATS 2011).Dayne Freitag.
1998.
Information extraction fromHTML: Application of a general machine learningapproach.
In AAAI?98, pages 517?523.Pierre Geurts, Damien Ernst, and Louis Wehenkel.2006.
Extremely randomized trees.
Machine Learn-ing, 63(1):3?42.Xavier Glorot, Antoine Bordes, and Yoshua Bengio.2011.
Domain adaptation for large-scale senti-ment classification: A deep learning approach.
In28th International Conference on Machine Learning(ICML-11), pages 513?520.Ruihong Huang and Ellen Riloff.
2011.
Peeling backthe layers: Detecting event role fillers in secondarycontexts.
In ACL 2011, pages 1137?1147.Ruihong Huang and Ellen Riloff.
2012a.
Bootstrappedtraining of event extraction classifiers.
In 13th Con-ference of the European Chapter of the Associationfor Computational Linguistics (EACL 2012), pages286?295.Ruihong Huang and Ellen Riloff.
2012b.
Modelingtextual cohesion for event extraction.
In 26th Con-ference on Artificial Intelligence (AAAI 2012).Patrik Lambert, Holger Schwenk, and Fr?ed?eric Blain.2012.
Automatic translation of scientific documentsin the hal archive.
In LREC 2012, pages 3933?3936.Claudia Leacock and Martin Chodorow.
1998.
Com-bining local context and Wordnet similarity for wordsense identification.
In Christiane Fellbaum, edi-tor, WordNet: An electronic lexical database., pages265?283.
MIT Press.Wendy Lehnert, Claire Cardie, David Fisher, John Mc-Carthy, Ellen Riloff, and Stephen Soderland.
1992.University of Massachusetts: MUC-4 test resultsand analysis.
In 4th Conference on Message under-standing, pages 151?158.1856Omer Levy and Yoav Goldberg.
2014.
Dependency-based word embeddings.
In 52nd Annual Meet-ing of the Association for Computational Linguis-tics (ACL 2014), Short Papers, pages 302?308, Bal-timore, Maryland, June.Tomas Mikolov, Kai Chen, Greg Corrado, and JeffreyDean.
2013a.
Efficient estimation of word represen-tations in vector space.
In International Conferenceon Learning Representations (ICLR 20013), work-shop track.Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-rado, and Jeff Dean.
2013b.
Distributed representa-tions of words and phrases and their compositional-ity.
In Advances in Neural Information ProcessingSystems 26 (NIPS 2013), pages 3111?3119.Tomas Mikolov, Wen-tau Yih, and Geoffrey Zweig.2013c.
Linguistic regularities in continuous spaceword representations.
In NAACL-HLT 2013, pages746?751.Andriy Mnih and Geoffrey Hinton.
2007.
Threenew graphical models for statistical modelling.
In24th International Conference of Machine learning(ICML 2007), pages 641?648.
ACM.Siddharth Patwardhan and Ellen Riloff.
2007.
Ef-fective information extraction with semantic affinitypatterns and relevant regions.
In 2007 Joint Con-ference on Empirical Methods in Natural LanguageProcessing and Computational Natural LanguageLearning (EMNLP-CoNLL 2007), pages 717?727.Siddharth Patwardhan and Ellen Riloff.
2009.
A uni-fied model of phrasal and sentential evidence for in-formation extraction.
In 2009 Conference on Em-pirical Methods in Natural Language Processing(EMNLP 2009), pages 151?160.Siddharth Patwardhan.
2010.
Widening the field ofview of information extraction through sententialevent recognition.
Ph.D. thesis, University of Utah.F.
Pedregosa, G. Varoquaux, A. Gramfort, V. Michel,B.
Thirion, O. Grisel, M. Blondel, P. Pretten-hofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Pas-sos, D. Cournapeau, M. Brucher, M. Perrot, andE.
Duchesnay.
2011.
Scikit-learn: Machine learn-ing in Python.
Journal of Machine Learning Re-search, 12:2825?2830.Ellen Riloff.
1996.
Automatically generating extrac-tion patterns from untagged text.
In AAAI?96, pages1044?1049.Holger Schwenk and Philipp Koehn.
2008.
Largeand diverse language models for statistical machinetranslation.
In IJCNLP 2008, pages 661?666.Richard Socher, Cliff C Lin, Chris Manning, and An-drew Y Ng.
2011.
Parsing natural scenes and nat-ural language with recursive neural networks.
In28th International Conference on Machine Learning(ICML-11), pages 129?136.Stephen Soderland, Brendan Roof, Bo Qin, Shi Xu,Mausam, and Oren Etzioni.
2010.
Adapting openinformation extraction to domain-specific relations.AI Magazine, 31(3):93?102.Kiyoshi Sudo, Satoshi Sekine, and Ralph Grishman.2003.
An improved extraction pattern representa-tion model for automatic ie pattern acquisition.
In41st Annual Meeting on Association for Computa-tional Linguistics (ACL-03), pages 224?231.Mihai Surdeanu, Jordi Turmo, and Alicia Ageno.2006.
A hybrid approach for the acquisition ofinformation extraction patterns.
In EACL-2006Workshop on Adaptive Text Extraction and Mining(ATEM 2006), pages 48?55.Joseph Turian, Lev Ratinov, and Yoshua Bengio.
2010.Word representations: a simple and general methodfor semi-supervised learning.
In 48th internationalAnnual Meeting on Association for ComputationalLinguistics (ACL 2010), pages 384?394.Roman Yangarber, Ralph Grishman, Pasi Tapanainen,and Silja Huttunen.
2000.
Automatic acquisitionof domain knowledge for information extraction.
In18th Internation Conference on Computational Lin-guistics (COLING 2000), pages 940?946.Mo Yu and Mark Dredze.
2014.
Improving lexical em-beddings with semantic knowledge.
In 52nd AnnualMeeting of the Association for Computational Lin-guistics (ACL 2014), Short Papers, pages 545?550,Baltimore, Maryland, June.1857
