Coling 2010: Demonstration Volume, pages 21?24,Beijing, August 2010COMUNICA - A Question Answering System for BrazilianPortugueseRodrigo Wilkens?, Aline Villavicencio?, Daniel Muller?, Leandro Wives?,Fabio da Silva?, Stanley Loh?
?Institute of Informatics, Federal University of Rio Grande do Sul (Brazil),?Conexum (Brazil), ?DFL (Brazil), ?IntextMining (Brazil){rwilkens,avillavicencio,wives}@inf.ufrgs.br, conexum@conexum.com.br, fabio@dfl.psi.br, sloh@terra.com.brAbstractCOMUNICA is a voice QA system forBrazilian Portuguese with search ca-pabilities for consulting both struc-tured and unstructured datasets.One of the goals of this work is to helpaddress digital inclusion by providingan alternative way to accessing writ-ten information, which users can em-ploy regardless of available computa-tional resources or computational lit-eracy.1 IntroductionA crucial social problem in many countriesis functional illiteracy, and in Latin Amer-ica, according to UNESCO, the process ofliteracy is only effectively achieved for peoplewho completed at least four years of school-ing.
Among those who have not completedthis cycle of education, there has been highrates of return to illiteracy.
According to thisdefinition, in 2002 Brazil had a total of 32.1million functionally illiterate citizens, repre-senting 26% of the population aged 15 orolder1.
This may have a significant effecton digital inclusion, preventing a consider-able part of the population from accessingmassive amounts of information such as thatavailable on the Web, or benefitting fromadvances in technology.
Although these fig-ures do not include digital iliteracy, or lackof computational resources, they can give anidea of the magnitude of the problem.In this context, voice question answeringsystems (QA) have the potential to makewritten information more easily accessible to1IBGE: http://www.ibge.gov.br/ibgeteen/pesquisas/educacao.htmlwider audiences as they allow users to askquestions in their own native language andespecially if this includes spoken language,sometimes without the need even for a com-puter (e.g.
using the phone).
This paper de-scribes COMUNICA, a voice QA system forBrazilian Portuguese with search capabilitiesfor consulting both structured and unstruc-tured datasets.
The domain chosen to eval-uate the system is that of municipal infor-mation from the FAMURS database.2 Oneof the goals of this work is to help addressdigital inclusion by providing a way to over-come (a) difficulties in accessing written in-formation (for visually challenged users), (b)lack of computational resources (for users inremote or computerless areas) and (c) com-putational illiteracy.2 QA systemsIn recent years, QA has received consider-able attention, as can be seen by the initia-tives devoted to the task, such as the TREC3and CLEF4.
The task of a QA system isto automatically answer a question in nat-ural language, searching for information in agiven data source (e.g.
a database, or cor-pora from a given domain).
This is a chal-lenging task as question types can range fromlists to facts and definitions, while answersmay come from small data sets such as doc-ument collections, to the World Wide Web.Moreover, the difficulty of the task is alsoinfluenced by whether the questions are re-stricted to a particular domain (e.g.
sports,genes) or not, which additional sources of in-2http://www.famurs.com.br3http://trec.nist.gov4http://www.clef-campaign.org21formation are available for a given language(e.g.
ontologies of domain-specific knowl-edge, general ontologies), their coverage, andwhich tools can be used to help the task (e.g.named entity recognisers, parsers, word sensedisambiguation tools).
Furthermore, there isno concensus as to the amount of resourcesand tools that are needed in order to build aworking QA system with reasonable perfor-mance.For a resource rich language like English,there is a consistent body of work exempli-fied by systems such as JAVELIN (Nyberg etal., 2002) and QuALiM (Kaisser, 2005).
Forother languages, like Portuguese, and partic-ularly the Brazilian variety, QA systems arenot as numerous.
Over the years, there wasan increase in the number of participatingsystems and data sources in the CLEF evalu-ation.
For instance, in 2004 there were 2 par-ticipating systems, and in 2006 it had 4 sys-tems and the best performance was obtainedby Priberam (Amaral et al, 2005) with 67%accuracy (Magnini et al, 2006).
Figure 1summarizes the performance of the QA sys-tems for Portuguese for QA@CLEF over theyears.3 COMUNICA ArchitectureThe Comunica system is composed of fivemodules: a manager module and four pro-cessing modules, as shown in figure 2.
Themanager is responsible for the integrationand communication with the speech recog-nition, text processing, database access, andspeech synthesis modules.Figure 2: Architecture of the system.3.1 Speech RecognitionFor continuous speech recognition of theusers?
requests we use an automated phoneservice.
This module uses two researchfronts signal analysis (Fourier transform andWavelets).
The coefficients obtained aresequenced on three fronts for continuousspeech recognition: HMMs (Becerikli andOysal, 2007) TDDNN and NESTOR (Nasutoet al, 2009).
To train the models, a corpusof FAMURS callcentre telephone interactionshas been recorded.
The recognition focuseson the vocabulary employed in the domain,in this case municipal information related totaxes from FAMURS.
In order to do that,it uses 2 ontologies to validate the candidatewords in the input: (a) a general purposeand (b) a domain ontology.
The recognisedtranscribed input is passed to the managerfor further processing.3.2 Text ProcessingThe manager sends the transcribed inputto be processed by the natural languageprocessing module.
The natural languagequeries are processed using shallow and deeptools and accessing both a general and a do-main specific ontologies (illustrated in Figure3).
This module needs to determine whichtype of query the user performed and whatis the likely type of answer, based on mostlylexical and syntactic information.
This pro-cess is divided into 3 mains steps: parsing,concept identification and pattern selection.In the first step, the input is parsed usingthe PALAVRAS parser (Bick, 2002), andthe output provides information about theparticular pronoun (wh-word), subject andother verbal complements in the sentence.For concept identification, the system usesthe domain ontology, which contains the rel-evant concepts to be used in next steps.
Theontologies also provide additional informa-tion about nouns (such as hyperonymy andsynonymy) for determining which instancesof the concepts were present in the input.For example, ?Gramado?
is an instance of22Figure 1: Performance of QA systems for Portuguese QA-CLEF.the concept ?city?.
Both absolute and rela-tive dates and periods (e.g.
last quarter, firstweek) need to be treated.Finally, based on this information thismodule selects from a set of pre-defined ques-tion patterns linking concepts of the domainontology with SQL commands, the one whichcontains the largest number of concepts incommon with the input, and sends it to themanager in an XML format.
If there is nocomplete frame, this module identifies whichconcepts are missing and returns this in theXML output.Figure 3: The domain ontology3.3 Database AccessThe search module is divided in two sub-modules: one for searching information in astructured database and the other for search-ing in an unstructured knowledge base.
Itreceives as entry an XML file, containingthe original input in natural language andthe concepts identified in the question.
Thestructured search module receives the inputtagged with concepts of the ontology and anidentified search pattern, and selects a struc-tured SQL query.
These queries are prede-fined according to the search patterns andthe structure of the database.
For example,in the case of the FAMURS domain, thereare concepts related to time period, citiesand taxes.
When these 3 concepts are foundin the input, a special pattern is selectedwhich defines the kind of information thatmust be retrieved from the database.
AnSQL command is then executed in the struc-tured database.
All possible patterns aremapped to a specific SQL command.
Thesecommands have slots that are filled with in-stances of the concepts identified in the sen-tence.
For example, names of cities are in-stances of the concept ?city?.
The retrievedvalues are used for producing the answer innatural language, using some predefined an-swer patterns.Otherwise, the system uses the ADSDigital Company Virtual Assistant (VA)(Duizith et al, 2004) to search the unstruc-tured data (e.g.
Frequently Asked Ques-23tions), using the lexical information to lo-cate the answer associated to the most simi-lar question.
This answer is written in natu-ral language and will be returned to the mainmodule of the system.
If no similar questionis found according to a predefined degree ofsimilarity, the VA returns a standard answer.3.4 Speech SynthesisThe text output to the user is synthesized,resulting in an audio file that is transmittedthrough the server.3.5 ManagerThe manager is responsible for the integra-tion and communication of the modules.
Itprocesses requests, interpreting the actionsto be taken and dispatching the requests tospecific modules.
To start the interaction themanager activates the speech recogniser, andif no problem is detected with the input, itis passed to to the text processing module.In the case of missing information, the man-ager informs the user that more informationis needed.
Othwerise, the query is passed tothe database module.
The database modulethen returns the result of the query to themanager, which sends this information to theinterface component.All the components are SOA compliantand designed as Web services.
This allowsus to use a common and simple way of com-munication among components, allowing acertain degree of independence.
Then com-ponents can be implemented using differenttechnologies and may be distributed amongdifferent servers, if needed.4 System DemonstrationThis is an ongoing project, and a workingversion of the system will be demonstratedthrough some text example interactions fromthe FAMURS domain as the speech recog-nizer and synthesizer are currently under de-velopment.
However, users will be able tointeract with the other modules, and experi-ence the benefits of natural language inter-action for accessing database information.AcknowledgmentsThis research was partly supported by CNPq(Projects 479824/2009-6 and 309569/2009-5), FINEP and SEBRAE (COMUNICAproject FI- NEP/SEBRAE 1194/07).ReferencesAmaral, Carlos, Helena Figueira, Andre?
F. T. Mar-tins, Afonso Mendes, Pedro Mendes, and Cla?udiaPinto.
2005.
Priberam?s question answering sys-tem for portuguese.
In Peters, Carol, Fredric C.Gey, Julio Gonzalo, Henning Mu?ller, Gareth J. F.Jones, Michael Kluck, Bernardo Magnini, andMaarten de Rijke, editors, CLEF, pages 410?419.Springer.Becerikli, Yasar and Yusuf Oysal.
2007.
Modelingand prediction with a class of time delay dynamicneural networks.
Applied Soft Computing, 7:1164?1169.Bick, Eckhard.
2002.
The Parsing System Palavras -Automatic Grammatical Analysis of Portuguese ina Constraint Grammar Famework.
Ph.D. thesis,Aarhus University.Duizith, Jose?
Luiz, Lizandro Kirst da Silva, DanielBrahm, Gustavo Tagliassuchi, and Stanley Loh.2004.
A virtual assistant for websites.
RevistaEletronica de Sistemas de Informac?a?o, 3.Kaisser, Michael.
2005.
Qualim at trec 2005: Web-question answering with framenet.
In Proceedingsof the 2005 Edition of the Text REtrieval Confer-ence, TREC 2005.Magnini, Bernardo, Danilo Giampiccolo, PamelaForner, Christelle Ayache, Valentin Jijkoun, PetyaOsenova, Anselmo Pen?as, Paulo Rocha, BogdanSacaleanu, and Richard F. E. Sutcliffe.
2006.Overview of the clef 2006 multilingual questionanswering track.
In Peters, Carol, Paul Clough,Fredric C. Gey, Jussi Karlgren, Bernardo Magnini,Douglas W. Oard, Maarten de Rijke, and Maxi-milian Stempfhuber, editors, CLEF, volume 4730of Lecture Notes in Computer Science, pages 223?256.
Springer.Nasuto, S.J., J.M.
Bishop, and K. DeMeyerc.
2009.Communicating neurons: A connectionist spik-ing neuron implementation of stochastic diffusionsearch.
Neurocomputing, (72):704?712.Nyberg, Eric, Teruko Mitamura, Jaime G. Carbonell,James P. Callan, Kevyn Collins-Thompson,Krzysztof Czuba, Michael Duggan, Laurie Hiyaku-moto, N. Hu, Yifen Huang, Jeongwoo Ko, Lu-cian Vlad Lita, S. Murtagh, Vasco Pedro, andDavid Svoboda.
2002.
The javelin question-answering system at trec 2002.
In TREC.24
