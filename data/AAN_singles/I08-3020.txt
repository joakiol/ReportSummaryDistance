Proceedings of the IJCNLP-08 Workshop on NLP for Less Privileged Languages, pages 123?130,Hyderabad, India, January 2008. c?2008 Asian Federation of Natural Language ProcessingSpeech to speech machine translation:Biblical chatter from Finnish to EnglishDavid EllisBrown UniversityProvidence, RI 02912Mathias Creutz Timo HonkelaHelsinki University of TechnologyFIN-02015 TKK, FinlandMikko KurimoAbstractSpeech-to-speech machine translation is insome ways the peak of natural language pro-cessing, in that it deals directly with ouroriginal, oral mode of communication (asopposed to derived written language).
Assuch, it presents challenges that are not to betaken lightly.
Although existing technologycovers each of the steps in the process, fromspeech recognition to synthesis, deriving amodel of translation that is effective in thedomain of spoken language is an interestingand challenging task.
If we could teach ouralgorithms to learn as children acquire lan-guage, the result would be useful both forlanguage technology and cognitive science.We propose several potential approaches, animplementation of a multi-path model thattranslates recognized morphemes alongsidewords, and a web-interface to test our speechtranslation tool as trained for Finnish to En-glish.
We also discuss current approaches tomachine translation and the problems theyface in adapting simultaneously to morpho-logically rich languages and to the spokenmodality.1 IntroductionEffective and fluent machine translation poses manychallenges, and often requires a variety of resources.Some are language-specific, some domain-specific,and others manage to be relatively independent (onemight even say context-free), and thus generally ap-plicable in a wide variety of circumstances.
Thereare still untapped resources, however, that mightbenefit machine translation systems.
Most statisticalapproaches do not take into account any similaritiesin word forms, so words that share a common root,(like ?blanche?
and ?bianca?, meaning ?white?
inFrench and Italian respectively) are no more likely tobe aligned than others (like ?vache?
and ?guardare?,meaning ?cow?
and ?to watch?
respectively).
Sucha root is sometimes subject to vowel shift and conso-nant gradation, and may not be reflected in orthog-raphy, since it is often purely phonetic.This means we are not taking advantage of every-thing that normally benefits human speakers, hear-ers and translators.
It may be that a more naturalapproach to translation would first involve under-standing of the input, stored in some mental rep-resentation (an interlingua), and then generation ofan equivalent phrase in the target language, directlyfrom the knowledge sources.In order to allow for more dramatic differencesin grammar like agglutinativity, it seems that thestatistical machine translation (SMT) system mustbe more aware of sub-word units (morphemes) andfeatures (phonetic similarity).
This general sort ofmorphological approach could potentially benefitany language pair, but might be crucial for a sys-tem that handles Finnish, Turkish, Hungarian, Es-tonian or any other highly inflectional language.
Inthe following section we discuss the confounds pre-sented by agglutinative languages, and how aware-ness of morphemes might improve the situation.This is followed by a brief foray into semanticsand natural language generation as a component of123SMT.
Capturing phonetic features is most applicableto speech-to-speech translation, which will be dis-cussed in the penultimate section.
A description ofthe Bible conversation experiment and some of itsresults can be found in the final section.2 Agglutinative ConfoundsTraditional n-gram language models and phrase-based translation models do not work terribly wellfor Finnish because each lexical item can appear indozens of inflected or declined forms.
If an SMTsystem is presented with ?taloosi?
(to your house), itwill not know if that is another form of a word it sawin training (like ?taloissaan?, in their houses).
Align-ment data are thus unnaturally sparse and test sen-tences often contain several unknown items, whichshare their stems with trained words.
It has beenassumed that morphological analysis would be es-sential for handling agglutinative languages.
How-ever, although several effective segmenters and an-alyzers for specific languages exist, and even unsu-pervised language-neutral versions such as Morfes-sor (Creutz and Lagus, 2007), only recently havesimilar approaches been successfully used in thecontext of machine translation to improve the BLEUscore (Oflazer and El-Kahlout, 2007), and none yetin Finnish.In our experience, building a translation modelthrough stemmed (truncated) word-alignment out-performs full-form alignment, or any morph-segmented alignment.
But once one has generatedsuch a translation model, including phrase tableswhere stemmed forms (keys in source language)are associated with full forms (values in target lan-guage), is there anything to be gained from inductionof morphology?
Our research in this area has yet toreveal any positive results, but we are still workingon it.
It is also worth considering the effectiveness ofthe evaluation metrics.
Does BLEU accurately cap-ture the accuracy of a translation, particularly in anagglutinative language?
Unfortunately not.We think the word segmentation in the BLEUmetric is biased against progress in morpheme-leveltranslation.
Some other metrics have been set forth,but none is widely accepted, in part due to inertia,but also because translation cannot be objectivelyevaluated, unless both the communicative intent andits effectiveness can be quantified.
The same prob-lem occurs for teachers grading essays ?
what wasthe student intending to convey, was the phrasingcorrect, the argument sound, and where does all thisdiverge from the underlying power of words, writtenor well said, to transmit information?
Translation isan art, and maybe in addition to human evaluationby linguists and native speakers of the language, weshould consider the equivalent of an art or literarycritic.
On the other hand, that might only be worth-while for poetry, wherein automated translation isperhaps not the best approach.One might think that the stemmed model de-scribed above would lose track of closed-class func-tion items (like prepositions), particularly when theyare represented as inflectional morphemes in onelanguage but as separate words in the other.
How-ever, it seems that the language model for the targettakes care of that quite well in most cases.
Thereare some languages (like Japanese) with underspec-ified noun phrases, in which efforts to preserve def-initeness (i.e., the book, kirjan; a book, kirjaa) seemfutile, but given the abundance of monolingual datato train LM?s on, these are contextually inferred andcorrected at the tail end of the production line.
Ag-glutinative confounds are thus very closely related toother issues found throughout machine translation,and perhaps an integrated solution (including a newevaluation metric) is necessary.3 Knowledge-Based ApproachesIncorporating statistical natural language generationinto a machine translation system involves somemodifications to the above.
First, the source lan-guage is translated or parsed into ontological rep-resentations.
This is similar to sentence parsingtechniques that can be used to induce a context-freegrammar for a language (Charniak, 1997), and couldin fact be considered one of their more useful appli-cations.
The parsing generally depends on a proba-bilistic model trained on sentences aligned with theirsyntactic and semantic representations, often in atree that could be generated by a context-free gram-mar.
The resulting semantic representation can thenbe used as the source of a target-language generationprocess.The algorithm that generates such a representa-124tion from raw input could be trained on a tree-bank, and an annotated form of the same corpus(where the derivations in the generation space areassociated with counts for each decision made) canbe used to train the output component to generatelanguage.
(Belz, 2005) To incorporate the statisti-cal component, which allows for robust generaliza-tion, per (Knight and Hatzivassiloglou, 1995), theNLG on the target side is filtered through a languagemodel (described above).
This helps address manyof the knowledge gap problems introduced by lin-guistic differences or in a component of the system- the analyzer or generator.This approach does have significant advantages,particularly in that it is more focused on semantics(as opposed to statistical cooccurrence), so it maybe less likely to distort meaning.
On the other hand,it could misinterpret or miscommunicate (or both),just like a human translator.
Perhaps the crucial dif-ference is that, while machine learning often has lit-tle to do with our understanding of cognitive pro-cesses, this sort of machine translation has greaterpotential for illuminating mysterious areas of the hu-man process.
It is not an ersatz brain, nor neuralnetwork, but in many ways it has more in commonwith those technologies (particularly in that theymodel cognition) than many natural language pro-cessing algorithms.
That is because, if we can geta semantically-aware machine translation system towork, it may more closely mirror human cognition.Humans certainly do not ignore meaning when theytranslate, but today?s statistical machine translationhas no awareness of it at all.Potential disadvantages of the system include itsdependence on more resources.
However, this isless of a problem with WordNet(Miller, 1995) andother such semantic webs.
It is also worth men-tioning again that humans always have an incred-ible amount of information at their disposal whentranslating.
Not only all of their past experience andword-knowledge, but their interlocutor?s demeanor,manner, intonation, facial expressions, gestures, andso on.
There are often things that would be obvi-ous in the context of a conversation, but are missingfrom the transcribed text.
For instance, the referentof many pronouns is ambiguous, but usually there isa unique individual or item picked out by the speak-ers?
shared information.
This is true for simple sen-tences like ?He hit him,?
which are normally dis-ambiguated by conversational context, but a purelystatistical, pseudo-syntactic interpretation would getlittle of the meaning a human would glean from thatutterance.4 Spoken FeaturesSpeech-to-speech machine translation is in someways the peak of natural language processing, in thatit deals directly with our (humans?)
original, oralmode of communication (as opposed to derived writ-ten language).
As such, it presents challenges thatare not to be taken lightly.
Much of the pipeline in-volved is at least relatively straightforward: acousticmodeling and language modeling on the input sidecan take advantage of the latest advances withoutextensive adaptation; similarly, speech synthesis onthe output can be directly connected with the system(i.e., not work with text output, but a richer repre-sentation).Although such a system might seem quite com-plicated, it could better take advantage of all theavailable data.
Natural language understanding andgeneration could even be incorporated to an extent,perhaps to add further confidence measures basedon semantic equivalence.
Designing it in this wayalso allows for a variety of methods to be tried withease, in a modular fashion.
It may be that yet an-other source of information can be found to improvethe translation by adding features to the translationmodel ?
perhaps leveraging multilingual corpora inother languages, segmenting into morphemes earlierin the process, or even incorporating intonation insome fashion.
Weights for all such features couldbe learned during training, such that no language-specific tuning would be necessary.
This frameworkwould certainly not make speech-to-speech transla-tion simple, but its flexibility might make researchand improvement in this area more tractable.Efficiency is crucial in online translation of con-versation, so a word alignment model with collapsedGibbs sampling, rather than EM, at its core is worthexperimenting with.
We have written up a bare-bones IBM Model 1 in both C++ and Python, us-ing the standard EM approach and a Gibbs samplingone.
The latter allows for optimizations using lin-ear algebra, and although it does not quite match the125perplexity or log-likelihood achieved by EM, it issignificantly faster, particularly on longer sentences.Since morpheme segmentation is at least somewhathelpful in speech recognition (Creutz, 2006; Creutzet al, 2007), it should still be considered a potentialcomponent in speech-to-speech translation.
In termsof incorporating the knowledge-based approach intosuch a system, we think it may yet be too early,but if existing understanding-and-generation frame-works for machine translation could be adapted tothis use, it could be very fruitful, in particular sincespoken language generation might be more effectivefrom a knowledge base, since it would know whatit was trying to say, instead of relying on statisticsalone, hoping the phonemes end up in a meaningfulorder.The critical step of SST is, of course, transla-tion.
In an integrated system, as described above,the translation model could be trained on a parallelspoken corpus (perhaps tokenized into phonemes, orsegmented into morphemes), since there might beadvantages to limiting the intermediate steps in theprocess.
The Bible is a massively multilingual publi-cation, and as it happens, its text is available alignedbetween Finnish and English, and it is possible tofind corresponding recordings in both languages.So, this corpus would enable a direct approachto speech-to-speech translation.
Alternatively, onecould treat the speech recognition and synthesis asdistinct from the translation, in which case text cor-pora corresponding to the style and genre of speechwould be necessary.
This would be particularly fea-sible when, for instance, translating UN parliamen-tary proceedings from a recording, for which trans-lated transcripts are readily available.
For a moregeneral and robust solution, we might advocate acombined approach, in the hope that some potentialweaknesses of one might be avoided or compensatedfor by using whatever limited resources are availableto add features from the other.
Thus, a direct trans-lation from speech to speech could be informed, in asense, by a derived translation from the recognizedtext.5 Biblical ChatterHere, we present a system for translating Finnish toEnglish speech, in a restricted and ancient domain:the Bible.5.1 IntroductionSpeech to speech translation attacks a variety ofproblems at once, from speech recognition to syn-thesis, and can similarly be used for several pur-poses.
If a system is efficient enough to be usedwithout introducing significant delay, it can trans-late conversational speech online, acting as an in-terpreter in place of (or in cooperation with) a hu-man professional.
On the other hand, a slow speechtranslation system is still useful because it can makenews broadcasts (radio or television) accessible towider audiences through offline multilingual dub-bing, allowing international viewers to enjoy a de-layed broadcast.5.2 System DescriptionThe domain selected for our experiments was heav-ily influenced by the available data.
We needed abilingual (Finnish and English) and bimodal (textand speech) corpus, and unfortunately none is read-ily available, but we put one together using theBible.
Both Old and New Testaments were used,with one book from each left out for testing pur-poses.
We used multiple editions of the Bible totrain the translation model: the American StandardVersion (first published in 1901, updated 1997),and Finnish translations (from 1992 and 1933,38).The spoken recordings used were the World EnglishBible (1997) and Finnish Bible (Raamattu) readings(recorded at TKK 2004).Our approach was to use existing components,and try weaving them together in an optimal way.First, there is the open vocabulary automatic speechrecognition (ASR) task, where the goal is to de-tect phonemes in an acoustic signal and map themto words.
Here, we use an ?unlimited vocabu-lary?
continuous speech recognizer (Hirsima?ki et al,2006), trained on a multi-speaker Finnish acousticmodel with a varigram (Siivola et al, 2007) lan-guage model that includes Bible n-grams.
Then,for translation, Moses (Koehn et al, 2007) is trainedon words and morphemes (derived from MorfessorBaseline (Creutz and Lagus, 2005)).
For speech syn-thesis, we used Festival (Taylor, 1999), including thebuilt-in English voice and a Finnish voice developedat Helsinki University.1265.3 ResultsThe following is an example fragment, taken fromthe test corpus.Niin Daavid meni David slept with hislepoon isiensa?
luo, fathers, and wasja ha?nethaudattiin buried in theDaavidin kaupunkiin.
city of David.
The daysNelja?kymmenta?
vuotta that David reignedha?n oli ollut over Israel wereIsraelin kuninkaana.
forty years; sevenHebronissa ha?n years reigned hehallitsi seitsema?n in Hebron, andvuotta, Jerusalemissa thirty-three yearskolmenkymmenenkolmen reigned hevuoden ajan.
in Jerusalem.Salomo nousi Solomon sat onisa?nsa?
Daavidin the throne of Davidvaltaistuimelle,ja his father; andha?nen kuninkuutensa his kingdom wasvahvistui lujaksi.
established greatly.A translation of the reference text skips recogni-tion, and runs the system from translation to synthe-sis.
The following shows how the sample text wastranslated by our system (BLEU = 0.735):Niin Daavid meni so david slept with hislepoon isiensa?
luo, fathers and wasja ha?net haudattiin buried in theDaavidin kaupunkiin.
city of davidNelja?kymmenta?
vuotta forty years heha?n oli ollut was king overIsraelin kuninkaana.
israel and inHebronissa ha?n hebron he reignedhallitsi seitsema?n seven yearsvuotta, Jerusalemissa in jerusalemkolmenkymmenenkolmen thirty and threevuoden ajan.
years solomonSalomo nousi went up toisa?nsa?
Daavidin the throne ofvaltaistuimelle, ja david his fatherha?nen kuninkuutensa and his kingdomvahvistui lujaksi.
was strong for lujaThe following recognized translation (BLEU =0.541) represents a complete run of the system.
Therecognition (on the left) had a LER of 12.9% and aWER of 56.8%.niintaa meni niintaa wentlepoon isiensa?lla isiensa?lla rest and wasja ha?net haudattiin buried in thedaavidin kaupunkiin city of david the kingnelja?kymmenta?
of israel wasvuotta ha?n oli ollut forty years he wasisraelin kuninkaan in hebron hehebronissa ha?n reigned seven yearshallitsi seitsema?n in jerusalemvuotta jerusalemissa kymmenenkolmenkolmen kymmenenkolmen three yearsvuoden ajan after the newsalomon uusi on the throne of davidisa?nsa?
daavidin and solomonvaltaistuimelle ja his fatherha?nenkuninkuutensa ha?nenkuninkuutensavalmistulujaksi valmistulujaksiHere we have an alternative path through the sys-tem, which uses Morfessor on the recognized text,and then translates using a model trained on themorpheme-segmented corpus.
This results in a re-duced score (BLEU = 0.456), but fewer unknownwords.n iin taa# meni# iin behind went tolepo on# isi ensa?
lla# the sabbath thatja# ha?n et# hauda ttiin# is with ensa?
and hedaavid in# kaupunki in# shall not at the grave of abnernelja?kymmenta?# vuotta# was forty years of theha?n# oli# ollut# city of david andisraeli n kuninkaan# he was israeli tohebron issa# ha?n# the king of hebronhallitsi# seitsema?n# and he reignedvuotta# jerusalem seven years inissa# kolmen# jerusalem three tenthkymmenen kolmen# three years ofvuoden# ajan# the new solomon hissalomo n# uusi# isa?
istuim to davidnsa?# daavid in# my father of thevalta istuim elle# kingdoms ofja# ha?n en kun ink ink and heuutensa# valmistu luja ksi# uutensa valmistu to lujaThe morphemes might have been more effectivein translation if they had been derived through rule-based morphological analysis.
Or, they could still bestatistical, but optimized for the translation phase byminimizing perplexity during word alignment.A significant barrier to thorough and concreteevaluation of our system involves segmentation ofthe speech stream into sentences (or verses) to matchthe text.
In the above examples, we manuallyclipped the audio files.
Evaluating performance onthe entire test set reduced the BLEU score if thedata were streamed through each component unseg-mented.
When the recognizer was set to insert a pe-riod for detected pauses of a certain length, or at sen-tence boundaries identified by its language model,127input to the translation phase became considerablymore problematic.
In particular, the lattice inputought to be split into sentences, but there would usu-ally be a period in every time slice (but with lowprobability).5.4 DiscussionThere were significant difficulties in the process,particularly in the English to Finnish direction.Whereas Finnish speech recognition is relativelystraightforward, since its orthography is consistent,English speech recognition is more dependent ona pronunciation dictionary.
Although many suchdictionaries are available, and the pronunciation ofnovel words can be estimated, neither of these re-sources is terribly effective within the Bible domain,where there are many archaic words and names.
Inthe second step, translation into Finnish is demon-strably difficult from any source language, and re-sults in consistently lower BLEU scores (Virpiojaet al, 2007).
And although using morphemes canreduce the frequency of unknown words, it also re-duces the BLEU score.It might improve translation quality if we use therecognizer lattice as translator input, since acous-tically improbable segments may lead to the mostfluent translation.
Having access to many possibili-ties might help the translation model, but then again,second-guessing the recognizer might not be help-ful.
There were some difficulties with the Moses in-tegration, in part because the word-sausage formatvaries from SRILM?s.
Also, the recognizer outputindicates word boundaries as <w>, not string-finalhash-marks (#).
This is problematic since the for-mer are separate symbols, occupying a node in thelattice, whereas the latter are appended to anothersymbol (e.g., ?<w> morph eme </w>?, 4 nodes,versus ?morph eme#?, 2 nodes).
Using the lattice,final output from Moses tends to be more fluent,but less on-topic, and often truncated.
Although wehave no improvements thus far, it is likely that withfurther parameter tuning, we could achieve better re-sults.
On the other hand, we seek a general, robust,domain-independent solution, so focusing on Bibletranslation may not be worthwhile.Our speech-to-speech translation system isaccessible through a web interface.http://www.cis.hut.fi/projects/speech/translate/It accepts a sound file, with recorded Finnishbible-style chatter, an optional reference text andtranslation, and within a half hour (usually muchless) sends a detailed report, including a sound filewith the synthesized English.Ideas for future research include online speech-to-speech translation, which must be efficient, light-weight and robust.
A potential barrier to this andother applications is the lack of spoken languagetraining texts.
It might be possible to adaptively trainto new speakers and contexts, perhaps taking advan-tage of an efficient alternative to EM in word align-ment (see discussion of Gibbs sampling).
As men-tioned elsewhere, it might be worth using prosodicfeatures captured during recognition as factors intranslation.
Adapting existing resources to new lan-guage pairs is particularly essential in an area whereso much is necessary, and so little available.6 ConclusionWe cannot yet say for sure whether linguistic orstatistically optimized morphemes derived from textcorpora could be useful somehow in machine trans-lation, but it has been demonstrated helpful inspeech recognition.
Awareness of sub-word unitscould benefit a speech-to-speech translation system,and it may in fact help to maintain informationfrom the speech recognizer about morpheme seg-mentation throughout the translation process, evenin speech generation.
Incorporating natural lan-guage understanding may also be fruitful, but forcompact, efficient systems (like a handheld transla-tor) might not have access to the necessary resourcesor computational power to support that.
On the otherhand, it is our duty as researchers to stay ahead of thetechnology and push its limits.We are by no means the first to imagine this, butperhaps we will soon be speaking into wrist watchesthat understand our query, seemingly instantly shiftthrough more information than Google has currentlyindexed, and reply in fluent English, Finnish, or Pun-jabi with as much detail as could be hoped for afterhours of painstaking research with current technol-ogy.
In this case (and computational linguists mustalways be optimistic), knowledge-based natural lan-guage processing certainly has a crucial place.128Morphemes and agglutinative languages do poseunique problems for computational linguists, butmany of the general techniques developed for lan-guages like Arabic and Chinese, which are equallyfar from English in grammar (and even orthogra-phy), might surmount those problems without anymanual adaptation.
Discriminative training of fea-tures used in the translation model allows for suchsolutions to be molded automatically to whateverlanguage pair (and set of corpora) they are beingused for.
There is, as always, much more to be donein this area, and we hope our research into efficient,online Bible-conversational translation ?
a modernBabelfish in an ancient genre?
is fruitful, and helpsto shed light on lemmatization.AcknowledgmentsMany thanks to Teemu Hirsima?ki, Antti Puurula,Sami-Virpioja and Jaakko J. Va?yrynen for theirhelp with components of the system and for theirthoughts and comments at various stages of theproject.ReferencesAnja Belz.
2005.
Statistical generation: Three methodscompared and evaluated.
In Proceedings of the 10thEuropean Workshop on Natural Language Generation(ENLG05), pages 15?23.Eugene Charniak.
1997.
Statistical parsing witha context-free grammar and word statistics.
InAAAI/IAAI, pages 598?603.Mathias Creutz and Krista Lagus.
2005.
Unsupervisedmorpheme segmentation and morphology inductionfrom text corpora using Morfessor 1.0.
Technical Re-port A81, Publications in Computer and InformationScience, Helsinki University of Technology.Mathias Creutz and Krista Lagus.
2007.
Unsupervisedmodels for morpheme segmentation and morphologylearning.
ACM Transactions on Speech and LanguageProcessing, 4(1), January.Mathias Creutz, Teemu Hirsim?ki, Mikko Kurimo, AnttiPuurula, Janne Pylkknen, Vesa Siivola, Matti Var-jokallio, Ebru Arisoy, Murat Saraclar, and AndreasStolcke.
2007.
Analysis of morph-based speechrecognition and the modeling of out-of-vocabularywords across languages.
In Proceedings of Hu-man Language Technologies / The Annual Conferenceof the North American Chapter of the Associationfor Computational Linguistics (HLT-NAACL 2007),Rochester, NY, USA.Mathias Creutz.
2006.
Morfessor in the morpho chal-lenge.
In Mikko Kurimo, Mathias Creutz, and KristaLagus, editors, Proceedings of the PASCAL ChallengeWorkshop on Unsupervised Segmentation of Wordsinto Morphemes, Venice, Italy.T.
Hirsima?ki, M. Creutz, V. Siivola, M. Kurimo, S. Vir-pioja, and J. Pylkko?nen.
2006.
Unlimited vocabu-lary speech recognition with morph language modelsapplied to Finnish.
Computer Speech and Language,20(4):515?541.Kevin Knight and Vasileios Hatzivassiloglou.
1995.Two-level, many-paths generation.
In Proceedings ofthe 33rd annual meeting on Association for Compu-tational Linguistics, pages 252?260, Morristown, NJ,USA.
Association for Computational Linguistics.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran, RichardZens, Ondrej Bojar, Alexandra Constantin, and EvanHerb.
2007.
Moses: Open source toolkit for statisticalmachine translation.
In Proceedings of the ACL 2007Demo and Poster Sessions, pages 177?180.George A. Miller.
1995.
Wordnet: a lexical database forEnglish.
Commun.
ACM, 38(11):39?41.Kemal Oflazer and Ilknur Durgar El-Kahlout.
2007.
Ex-ploring different representational units in English-to-Turkish statistical machine translation.
In Proceedingsof the ACL 2007 Demo and Poster Sessions, pages 25?32.Vesa Siivola, Teemu Hirsima?ki, and Sami Virpioja.
2007.On growing and pruning Kneser-Ney smoothed n-gram models.
IEEE Transactions on Audio, Speechand Language Processing, 15(5):1617?1624.Paul Taylor.
1999.
The Festival Speech Architecture.Web page.Sami Virpioja, Jaakko J. Va?yrynen, Mathias Creutz, andMarkus Sadeniemi.
2007.
Morphology?aware statis-tical machine translation based on morphs induced inan unsupervised manner.
In Proceedings of the Ma-chine Translation Summit XI, Copenhagen, Denmark.To appear.129130
