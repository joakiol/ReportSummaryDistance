Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 57?60,Columbus, Ohio, USA, June 2008. c?2008 Association for Computational LinguisticsFour Techniques for Online Handling of Out-of-Vocabulary Wordsin Arabic-English Statistical Machine TranslationNizar HabashCenter for Computational Learning SystemsColumbia Universityhabash@ccls.columbia.eduAbstractWe present four techniques for online han-dling of Out-of-Vocabulary words in Phrase-based Statistical Machine Translation.
Thetechniques use spelling expansion, morpho-logical expansion, dictionary term expansionand proper name transliteration to reuse orextend a phrase table.
We compare the per-formance of these techniques and combinethem.
Our results show a consistent improve-ment over a state-of-the-art baseline in termsof BLEU and a manual error analysis.1 IntroductionWe present four techniques for online handling ofOut-of-Vocabulary (OOV) words in phrase-basedStatistical Machine Translation (SMT).1 The tech-niques use morphological expansion (MORPHEX),spelling expansion (SPELLEX), dictionary word ex-pansion (DICTEX) and proper name transliteration(TRANSEX) to reuse or extend phrase tables online.We compare the performance of these techniquesand combine them.
We work with a standard Arabic-English SMT system that has been already opti-mized for minimizing data sparsity through the useof morphological preprocessing and orthographicnormalization.
Thus our baseline token OOV rate israther low (average 2.89%).
None of our techniquesare specific to Arabic and all can be retargetedto other languages given availability of technique-specific resources.
Our results show that we improveover a state-of-the-art baseline by over 2.7% (rel-ative BLEU score) and handle all OOV instances.An error analysis shows that, in 60% of the time,our OOV handling successfully produces acceptableoutput.
Additionally, we still improve in BLEUscore even as we increase our system?s training databy 10-fold.1This work was funded under the DARPA GALE program,contract HR0011-06-C-0023.2 Related WorkMuch work in MT has shown that orthographic andmorpho-syntactic preprocessing of the training andtest data reduces data sparsity and OOV rates.
Thisis especially true for languages with rich morphol-ogy such as Spanish, Catalan, and Serbian (Popovic?and Ney, 2004) and Arabic (Sadat and Habash,2006).
We are interested in the specific task ofonline OOV handling.
We will not consider solu-tions that game precision-based evaluation metricsby deleting OOVs.
Some previous approaches an-ticipate OOV words that are potentially morpholog-ically related to in-vocabulary (INV) words (Yangand Kirchhoff, 2006).
Vilar et al (2007) addressspelling-variant OOVs in MT through online re-tokenization into letters and combination with aword-based system.
There is much work on nametransliteration and its integration in larger MT sys-tems (Hassan and Sorensen, 2005).
Okuma et al(2007) describe a dictionary-based technique fortranslating OOV words in SMT.
We differ from pre-vious work on OOV handling in that we addressspelling and name-transliteration OOVs in additionto morphological OOVs.
We compare these differ-ent techniques and study their combination.
Ourmorphology expansion technique is novel in that weautomatically learn which source language morpho-logical features are irrelevant to the target language.3 Out-of-Vocabulary Words inArabic-English Machine TranslationArabic Linguistic Issues Orthographically, wedistinguish three major challenges for Arabic pro-cessing.
First, Arabic script uses optional vocalicdiacritics.
Second, certain letters in Arabic scriptare often spelled inconsistently, e.g., variants ofHamzated Alif, ?2 or ?A, are often written without2Arabic transliteration is provided in the Habash-Soudi-Buckwalter transliteration scheme (Habash et al, 2007).57Hamza:  A.
Finally, Arabic?s alphabet uses obliga-tory dots to distinguish different letters (e.g., H.b, Ht and H ?).
Each letter base is ambiguous two wayson average.
Added or missing dots are often seenin spelling errors.
Morphologically, Arabic is a richlanguage with a large set of morphological featuressuch as gender, number, person and voice.
Addition-ally, Arabic has a set of very common clitics that arewritten attached to the word, e.g., the conjunction+?
w+ ?and?.
We address some of these challengesin our baseline system by removing all diacritics,normalizing Alif and Ya forms, and tokenizing Ara-bic text in the highly competitive Arabic Treebankscheme (Sadat and Habash, 2006).
This reduces ourOOV rates by 59% relative to raw text.
So our base-line is a real system with 2.89% token OOV rate.The rest of the challenges such as spelling errors andmorphological variations are addressed by our OOVhandling techniques.Profile of OOV words in Arabic-English MT Ina preliminary study, we manually analyzed a ran-dom sample of 400 sentences containing at least oneOOV token extracted from the NIST MTEval datasets.
There were 686 OOV tokens altogether.
40%of OOV cases involved proper nouns.
60% involvedother parts-of-speech such as nouns (26.4%), verbs(19.3%) and adjectives (14.3%).
The proper nounsseen come from different origins including Arabic,Hebrew, English, French, and Chinese.
In manycases, the OOV words were less common morpho-logical variants of INV words, such as the nominaldual form.
The different techniques we discuss inthe next section address these different issues in dif-ferent ways.
Proper name transliteration is primar-ily handled by TRANSEX.
However, an OOV with adifferent spelling of an INV name can be handled bySPELLEX.
Morphological variants are handled pri-marily by MORPHEX and DICTEX, but since somemorphological variations involve small changes inlettering, SPELLEX may contribute too.4 OOV-Handling TechniquesOur approach to handling OOVs is to extend thephrase table with possible translations of theseOOVs.
In MORPHEX and SPELLEX techniques, wematch the OOV word with an INV word that is apossible variant of the OOV word.
Phrases asso-ciated with the INV token in the phrase table are?recycled?
to create new phrases in which the INVword is replaced with the OOV word.
The transla-tion weights of the INV phrase are used as is in thenew phrase.
We limit the added phrases to source-language unigrams and bigrams (determined empir-ically).
In DICTEX and TRANSEX techniques, weadd completely new entries to the phrase table.
Allthe techniques could be used with other approaches,such as input-text lattice extension with INV vari-ants of OOVs or their target translations.
We brieflydescribe the techniques next.
More details are avail-able in a technical report (Habash, 2008).MORPHEX We match the OOV word with an INVword that is a possible morphological variant of theOOV word.
For this to work, we need to be able tomorphologically analyze the OOV word (into lex-eme and features).
OOV words that fail morpho-logical analysis cannot be helped by this technique.The morphological matching assumes the words tobe matched agree in their lexeme but have differentinflectional features.
We collect information on pos-sible inflectional variations from the original phrasetable itself: in an off-line process, we cluster all theanalyses of single-word Arabic entries in our phrasetable that (a) translate into the same English phraseand (b) have the same lexeme analysis.
From theseclusters we learn which morphological inflectionalfeatures in Arabic are irrelevant to English.
We cre-ate a rule set of morphological inflection maps thatwe then use to relate analyses of OOV words to anal-yses of INV words (which we create off-line forspeedy use).
The most common inflectional varia-tion is the addition or deletion of the Arabic definitearticle +?
 Al+, which is part of the word in our tok-enization.SPELLEX We match the OOV token with an INVtoken that is a possible correct spelling of the OOVtoken.
In our current implementation, we considerfour types of spelling correction involving one let-ter only: letter deletion, letter insertion, letter inver-sion (of any two adjacent letters) and letter substitu-tion.
The following four misspellings of the word??J????
flsTyny ?Palestinian?
correspond to thesefour types, respectively: ??????
flsTny, ??JJ???
?flsTynny, ??J????
flTsyny and ??J????
qlsTyny.
Weonly allow letter substitution from a limited list ofaround 90 possible substitutions (as opposed to all1260 possible substitutions).
The substitutions weconsidered include cases we deemed harder than58usual to notice as spelling errors: common lettershape alternations (e.g., P r and 	P z), phonologicalalternations (e.g., ?
S and ?
s) and dialectal vari-ations (e.g., ?
q and Z ? '
y?).
We do not handle mis-spellings involving two words attached to each otheror multiple types of single letter errors in the sameword.DICTEX We extend the phrase table with entriesfrom a manually created dictionary ?
the Englishglosses of the Buckwalter Arabic morphological an-alyzer (Buckwalter, 2004).
For each analysis of anOOV word, we expand the English lemma gloss toall its possible surface forms.
The newly generatedpairs are equally assigned very low translation prob-abilities that do not interfere with the rest of thephrase table.TRANSEX We produce English transliteration hy-potheses that assume the OOV is a proper name.
Ourtransliteration system is rather simple: it uses thetransliteration similarity measure described by Free-man et al (2006) to select a best match from a largelist of possible names in English.3 The list was col-lected from a large collection of English corpora pri-marily using capitalization statistics.
For each OOVword, we produce a list of possible transliterationsthat are used to add translation pair entries in thephrase table.
The newly generated pairs are assignedvery low translation probabilities that do not inter-fere with the rest of the phrase table.
Weights ofentries were modulated by the degree of similarityindicated by the metric we used.
Given the largenumber of possible matches, we only pass the top20 matches to the phrase table.
The following aresome possible transliterations produced for the nameP ?J ?
AK.bAstwr together with their similarity scores:pasteur and pastor (1.00), pastory and pasturk (0.86)bistrot and bostrom (0.71).5 EvaluationExperimental Setup All of our training datais available from the Linguistic Data Consortium(LDC).4 For our basic system, we use an Arabic-English parallel corpus5 consisting of 131K sen-tence pairs, with approximately 4.1M Arabic tokens3Freeman et al (2006) report 80% F-score at 0.85 threshold.4http://www.ldc.upenn.edu5The parallel text includes Arabic News (LDC2004T17),eTIRR (LDC2004E72), Arabic Treebank with English transla-tion (LDC2005E46), and Ummah (LDC2004T18).and 4.4M English tokens.
Word alignment is donewith GIZA++ (Och and Ney, 2003).
All evalu-ated systems use the same surface trigram languagemodel, trained on approximately 340 million wordsfrom the English Gigaword corpus (LDC2003T05)using the SRILM toolkit (Stolcke, 2002).
We usethe standard NIST MTEval data sets for the years2003, 2004 and 2005 (henceforth MT03, MT04 andMT05, respectively).6We report results in terms of case-insensitive 4-gram BLEU (Papineni et al, 2002) scores.
Thefirst 200 sentences in the 2002 MTEval test set wereused for Minimum Error Training (MERT) (Och,2003).
We decode using Pharaoh (Koehn, 2004).We tokenize using the MADA morphological dis-ambiguation system (Habash and Rambow, 2005),and TOKAN, a general Arabic tokenizer (Sadat andHabash, 2006).
English preprocessing simply in-cluded down-casing, separating punctuation fromwords and splitting off ?
?s?.OOV Handling Techniques and their Combina-tion We compare our baseline system (BASELINE)to each of our basic techniques and their full combi-nation (ALL).
Combination was done by using theunion of all additions.
In each setting, the extensionphrases are added to the baseline phrase table.
Ourbaseline phrase table has 3.5M entries.
In our ex-periments, on average, MORPHEX handled 60% ofOOVs and added 230 phrases per OOV; SPELLEXhandled 100% of OOVs and added 343 phrases perOOV; DICTEX handled 73% of OOVs and added 11phrases per OOV; and TRANSEX handled 93% ofOOVs and added 16 phrases per OOV.Table 1 shows the results of all these settings.
Thefirst three rows show the OOV rates for each testset.
OOVsentence indicates the ratio of sentenceswith at least one OOV.
The last two rows show thebest absolute and best relative increase in BLEUscores above BASELINE.
All conditions improveover BASELINE.
Furthermore, the combination im-proved over BASELINE and its components.
Thereis no clear pattern of technique rank across all testsets.
The average increase in the best performingconditions is around 1.2% BLEU (absolute) or 2.7%(relative).
These consistent improvements are notstatistically significant.
However, this is still a nice6The following are the statistics of these data sets in termsof (sentences/tokens/types): MT03 (663/18,755/4,358), MT04(1,353/42,774/8,418) and MT05(1,056/32,862/6,313).
The datasets are available at http://www.nist.gov/speech/tests/mt/.59Table 1: OOV Rates (%) and BLEU Results of UsingDifferent OOV Handling TechniquesMT03 MT04 MT05OOVsentence 40.12 54.47 48.30OOVtype 8.36 13.32 11.38OOVtoken 2.46 3.21 2.99BASELINE 44.20 40.60 42.86MORPHEX 44.79 41.18 43.37SPELLEX 45.09 41.11 43.47DICTEX 44.88 41.24 43.46TRANSEX 44.83 40.90 43.25ALL 45.60 41.56 43.95Best Absolute 1.40 0.96 1.09Best Relative 3.17 2.36 2.54result given that we only focused on OOV words.Scalability Evaluation To see how well our ap-proach scales up, we added over 40M words (1.6Msentences) to our training data using primarily theUN corpus (LDC2004E13).
As expected, the tokenOOV rates dropped from an average of 2.89% in ourbaseline to 0.98% in the scaled-up system.
Our av-erage baseline BLEU score went up from 42.60 to45.00.
However, using the ALL combination, westill increase the scaled-up system?s score to an av-erage BLEU of 45.28 (0.61% relative).
The increasewas seen on all data sets.Error Analysis We conducted an informal erroranalysis of 201 random sentences in MT03 fromBASELINE and ALL.
There were 95 different sen-tences containing 141 OOV words.
We judgedwords as acceptable or wrong.
We only consideredas acceptable cases that produce a correct translationor transliteration in context.
Our OOV handling suc-cessfully produces acceptable translations in 60% ofthe cases.
Non-proper-noun OOVs are well handledin 76% of the time as opposed to proper nouns whichare only correctly handled in 40% of the time.6 Conclusion and Future PlansWe have presented four techniques for handlingOOV words in SMT.
Our results show that we con-sistently improve over a state-of-the-art baseline interms of BLEU, yet there is still potential roomfor improvement.
The described system is publiclyavailable.
In the future, we plan to improve eachof the described techniques; explore better ways ofweighing added phrases; and study how these tech-niques function under different tokenization condi-tions in Arabic and with other languages.ReferencesT.
Buckwalter.
2004.
Buckwalter Arabic Morphologi-cal Analyzer Version 2.0.
Linguistic Data Consortium(LDC2004L02).A.
Freeman, S. Condon, and C. Ackerman.
2006.
CrossLinguistic Name Matching in English and Arabic.
InProc.
of HLT-NAACL.N.
Habash.
2008.
Online Handling of Out-of-VocabularyWords for Statistical Machine Translation.
CCLSTechnical Report.N.
Habash, A. Soudi and T. Buckwalter.
2007.
OnArabic Transliteration.
In A. van den Bosch andA.
Soudi, editors.
Arabic Computational Morphology:Knowledge-based and Empirical Methods, Springer.N.
Habash and O. Rambow.
2005.
Arabic Tokeniza-tion, Part-of-Speech Tagging and Morphological Dis-ambiguation in One Fell Swoop.
In Proc.
of ACL?05.H.
Hassan and J. Sorensen.
2005.
An integrated ap-proach for Arabic-English named entity translation.In Proc.
of the ACL Workshop on Computational Ap-proaches to Semitic Languages.P.
Koehn.
2004.
Pharaoh: a Beam Search Decoder forPhrase-based Statistical Machine Translation Models.In Proc.
of AMTA.F.
Och and H. Ney.
2003.
A Systematic Comparison ofVarious Statistical Alignment Models.
ComputationalLinguistics, 29(1):19?52.F.
Och.
2003.
Minimum Error Rate Training for Statisti-cal Machine Translation.
In Proc.
of ACL.H.
Okuma, H. Yamamoto, and E. Sumita.
2007.
Intro-ducing translation dictionary into phrase-based SMT..In Proc.
of MT Summit.K.
Papineni, S. Roukos, T. Ward, and W. Zhu.
2002.BLEU: a Method for Automatic Evaluation of Ma-chine Translation.
In Proc.
of ACL.M.
Popovic?
and H. Ney.
2004.
Towards the Use of WordStems and Suffixes for Statistical Machine Translation.In Proc.
of LREC.F.
Sadat and N. Habash.
2006.
Combination of ArabicPreprocessing Schemes for Statistical Machine Trans-lation.
In Proc.
of ACL.A.
Stolcke.
2002.
SRILM - an Extensible LanguageModeling Toolkit.
In Proc.
of ICSLP.D.
Vilar, J. Peter, and H. Ney 2007.
Can we translateletters?.
In Proc.
of ACL workshop on SMT.M.
Yang and K. Kirchhoff.
2006.
Phrase-based back-off models for machine translation of highly inflectedlanguages.
In Proc.
of EACL.60
