Proceedings of the 11th International Conference on Parsing Technologies (IWPT), pages 142?145,Paris, October 2009. c?2009 Association for Computational LinguisticsApplication of feature propagation to dependency parsingKepa Bengoetxea Koldo GojenolaIXA NLP Group, Technical School of Engineering, BilbaoUniversity of the Basque Country, Plaza La Casilla 3, 48012, Bilbaokepa.bengoetxea@ehu.es, koldo.gojenola@ehu.esAbstractThis paper presents a set of experiments per-formed on parsing the Basque DependencyTreebank.
We have applied feature propaga-tion to dependency parsing, experimenting thepropagation of several morphosyntactic fea-ture values.
In the experiments we have usedthe output of a parser to enrich the input of asecond parser.
Both parsers have been gener-ated by Maltparser, a freely data-driven de-pendency parser generator.
The transforma-tions, combined with the pseudoprojectivegraph transformation, obtain a LAS of 77.12%improving the best reported results for Basque.1 IntroductionThis work presents several experiments per-formed on dependency parsing of the BasqueDependency Treebank (BDT, Aduriz et al2003).
We have experimented the idea of featurepropagation through dependency arcs, in order tohelp the parser.
Feature propagation has beenused in classical unification-based grammars as ameans of propagating linguistic informationthrough syntax trees.
We apply this idea in thecontext of inductive dependency parsing, com-bining a reduced set of linguistic principles thatexpress feature propagation among linguisticelements with Maltparser (Nivre et al 2007a), anautomatic dependency parser generator.We have concentrated on propagating severalmorphosyntactic feature values from: a) auxiliaryverbs to the main verb, b) the last constituent tothe head noun, in noun phrases c)  the last con-junct to the conjunction, in coordination.This work was developed in the context of de-pendency parsing exemplified by the CoNLLshared task on dependency parsing in years 2006and 2007 (Nivre et al 2007b), where several sys-tems had to compete analyzing data from a typo-logically varied range of 11 languages.
The tree-banks for all languages were standardized usinga previously agreed CoNLL-X format (see Fig-ure 1).
BDT was one of the evaluated treebanks,which will allow a direct comparison of results.Many works on treebank parsing have dedi-cated an effort to the task of pre-processing train-ing trees (Nilsson et al 2007).
When these ap-proaches have been applied to dependency pars-ing several works (Nilsson et al 2007; Ben-goetxea and Gojenola 2009) have concentratedon modifying the structure of the dependencytree, changing the shape of the graph.
In contrast,rather than modifying the tree structure, we willexperiment changing the information containedin the nodes of the tree.
This approach requireshaving an initial dependency tree in order to ap-ply the feature propagation process, which willbe obtained by means of a standard trainedmodel.
This way, the features will be propagatedthrough some incorrect dependency arcs, and theprocess will be dependent on the reliability of theinitial arcs.
After enriching the tree, a secondparsing model will try to use this new informa-tion to improve the standard model.
This processcan also be seen as an example of stacked learn-ing (Martins et al 2008, Nivre and McDonald2008) where a second parser is used to improvethe performance of a first one.The rest of the paper is organized as follows.Section 2 presents the main resources used in thiswork.
Section 3 presents three different propos-als for the propagation of the most importantmorphological features.
Next, section 4 willevaluate the results of each transformation, andthe last section outlines the main conclusions.2 ResourcesThis section will describe the main elements thathave been used in the experiments.
First, subsec-tion 2.1 will present the Basque DependencyTreebank data, while subsection 2.2 will describethe main characteristics of Maltparser, a state ofthe art and data-driven dependency parser.2.1 The Basque Dependency TreebankThe BDT can be considered a pure dependencytreebank, as its initial design considered that allthe dependency arcs would connect sentence to-kens.
Although this decision had consequenceson the annotation process, its simplicity is alsoan advantage when applying several of the most142efficient parsing algorithms.
The treebank con-sists of 55,469 tokens forming 3,700 sentences,334 of which were used as test data.
(1) Etorri (come) dela (that-has) eta(and) joan  (go) dela (that-has) esan(tell) zien (did) mutil (boy)txikiak(the-little)He told the little boy that he has comeand he has goneFigure 1 contains an example of a sentence(1), annotated in the CoNLL-X format.
The textis organized in eight tab-separated columns:word-number, form, lemma, category , subcate-gory, morphological features, and the depend-ency relation (headword + dependency).
Basqueis an agglutinative language and it presents ahigh power to generate inflected word-forms.The information in Figure 1 has been simplifieddue to space reasons, as typically the Featurescolumn will contain many morphological fea-tures, which are relevant for parsing.2.2 MaltparserMaltparser (Nivre et al 2007a) is a state of theart dependency parser that has been successfullyapplied to typologically different languages andtreebanks.
While several variants of the baseparser have been implemented, we will use oneof its standard versions (Maltparser version 0.4).The parser obtains deterministically a depend-ency tree in linear-time in a single pass over theinput.
To determine which is the best action ateach parsing step, the parser uses history-basedfeature models and discriminative machine learn-ing.
In all the following experiments, we madeuse of a SVM classifier.
The specification of thefeatures used for learning can in principle be anykind of data in Figure 1 (such as word-form,lemma, category or morphological features).3 ExperimentsWe applied the following steps:a) Application of feature propagation to thetraining data, using the gold standard arcs, ob-taining a ?enriched training data?.b) Training Maltparser on the ?enriched train-ing data?
to generate a ?enriched parser?.c) Training Maltparser with the training data,without any transformation, to generate a?standard parser?.d) Parse the test data with the ?standardparser?, obtaining the ?standard output?.e) Apply feature propagation to the ?standardoutput?, using the dependency arcs given bythe parser (with some incorrect arcs), obtain-ing the ?standard parser?s enriched output?.f) Finally, parsing the ?standard parser?s en-riched output?
with the ?enriched parser?,Index Word Lemma Category Subcategory Features  Head Dependency1 etorri etorri V  V  _   3 lot2 dela izan AUXV  AUXV  SC:CMP|SUBJ:3S 1 auxmod3 eta eta CONJ  CONJ  _   6 ccomp_obj4 joan joan V  V  _   3 lot5 dela izan AUXV  AUXV  SC:CMP|SUBJ:3S 4 auxmod6 esan esan V  V  _   0 ROOT7 zien *edun AUXV  AUXV  SUBJ:3S|OBJ:3P 6 auxmod8 mutil mutil NOUN  NOUN  _   6 ncsubj9 txikiak txiki ADJ  ADJ  CASE:ERG|NUM:S 8 ncmod10 .
.
PUNT  PUNT_PUNT _   9 PUNCFigure 1: Example of a BDT sentence in the CONLL-X format(V = main verb, AUXV = auxiliary verb, SC = subordinated clause, CMP = completive, ccomp_obj = clausalcomplement object,  SUBJ:3S: subject in 3rd person sing., OBJ:3P: object in 3rd person pl.
).auxmodcoordauxmod auxmodcoordccomp_objEtorri da+la  eta joan da+la  esan zien  mutil txiki+akcome has+he+that and go has+he+that tell did+he+them  boy little+theV AUXV+3S+CMP CONJ V AUXV+3S+CMP V    AUXV+SUBJ3S+OBJ3P  NOUN ADJ+ERGFigure 2: Dependency tree for the sentence in Figure 1.
(V = main verb; AUXV: auxiliary verb; CMP: completive subordinated mark; CONJ: conjunction; ERG: ergative case).ncmodncsubj143evaluating the output with the gold test data.We have applied three types of feature propa-gation of the most important morphological fea-ture values: a) from auxiliary verbs to the mainverb (verb phrases) b) from post-modifiers to thehead noun (noun phrases) c) from the last con-junct to the conjunction (coordination).
This wasdone because Basque is a head final language,where many relevant features are located at theend of constituents.
Figure 3 shows (dotted lines)the arcs that will propagate features from child toparent.
The three transformations will be de-scribed in the following subsections.3.1 Verb compoundsIn BDT the verbal elements are organized aroundthe main verb, but much syntactically relevantverbal information, like subordination type, as-pect, tense and agreement usually appear at-tached to the auxiliary verb, which is the de-pendent.
Its main consequence for parsing is thatthe elements bearing the relevant information forparsing are situated far in the tree with respect totheir head.
In Figure 2, we can see that the mor-pheme ?la, indicating a subordinated completivesentence, appears down in the tree, and this couldaffect the correct attachment of the two coordi-nated verbs to the conjunction (eta), as conjunc-tions should link elements showing similargrammatical features (-la in this example).
Simi-larly, it could affect the decision about the de-pendency type of eta (and) with respect to themain verb esan (to say), as the dependency rela-tion ccomp_obj is defined by means of the ?la(completive) morpheme, far down in the tree.Figure 3 shows the effect of propagating thecompletive feature value (CMP) from the auxil-iary verb to the main verb through the auxmod(auxiliary modifier) relation.3.2 Noun PhrasesIn noun phrases and postpositional phrases, themost important morphological feature values(case and number) are situated in the last post-modifier after the noun.
Figure 3 shows the ef-fect of propagating the ergative (ERG) case fea-ture value from the adjective (the last constituentof the noun phrase) to the noun through the rela-tion ncmod (non-clausal modifier).3.3 CoordinationCoordination in BDT was annotated in the socalled Prague Style, where the conjunction istaken as the head, and the conjuncts depend on it.Basque is head final, so usually the last conjunctcontains syntactically relevant features.
We ex-perimented the promotion of the category, caseand subordination information from the last con-junct to the conjunction.
In the example in Figure3, the conjunction (eta) receives a new feature(HV for Head:Verb) from its dependent.
This canbe seen as an alternative to (Nilsson et al 2007)who transform dependency arcs.4 EvaluationEvaluation was performed dividing the treebankin three sets: training set (45,000 tokens), devel-opment and test sets (5,000 tokens each).
Train-ing and testing of the system have been per-formed on the same datasets presented at theCoNLL 2007 shared task, which will allow for adirect comparison.
Table 1 presents the LabeledAttachment Score (LAS) of the different tests ondevelopment and test data.
The first row presentsthe best system score (76.94% LAS) in CoNLL2007.
This system combined six variants of abase parser (Maltparser).
The second row showsthe single Maltparser approach which obtainedthe fifth position.
Row 3 presents Bengoetxeaand Gojenola?s results (76.80% LAS) when ap-plying graph transformations (pseudo-projective,coordination and verb groups) to Basque, in thespirit of Nilsson et al (2007).
Row 4 shows ourresults after applying several feature optimiza-tions, which we will use as our baseline.auxmodcoordauxmod auxmodcoordccomp_objEtorri  da+la  eta  joan  da+la  esan zien    mutil  txiki+akcome  has+he+that and   go  has+he+that tell did+he+them   boy    little+theV+CMP   AUXV+3S+CMP CONJ+HV    V+CMP AUXV+3S+CMP      V    AUXV+SUBJ3S+OBJ3P NOUN+ERG ADJ+ERGFigure 3: Dependency tree after propagating the morphological features.ncmodncsubj144Feature propagation in verb groups (PVG) im-proves LAS in almost 0.5% (row 6 in Table 1).While coordination and case propagation do notimprove significantly the accuracy by themselves(rows 7 and 8), their combination with PVG (verbgroups) significantly increases LAS (+0.86%,see row 10).
Looking at the accuracy of the de-pendency arcs used for feature propagation, aux-liary verbs are the most reliable elements, astheir arcs (linking it to its head, the main verb)have 97% precision and 98% recall.
This is inaccord with PVG giving the biggest increase,while arcs related to coordination (63% precisionand 65% recall) give a more modest contribution.BDT contains 2.9% of nonprojective arcs, sowe experimented the effect of combining thepseudoprojective transformation (Nilsson et al2007) with feature propagation, obtaining a LASof 77.12%, the best reported results for the BDT.5 ConclusionsWe have performed a set of experiments usingthe output of a parser to enrich the input of asecond parser, propagating the relevant morpho-logical feature values through dependency arcs.The best system, after applying three types offeature propagation, obtains a 77.12% LAS(2.05% improvement over the baseline) on thetest set, which is the best reported result forBasque dependency parsing, improving the betterpublished result for a combined parser (76.94%).AcknowledgementsThis research was supported by the Basque Gov-ernment (EPEC-RS, S-PE08UN48) and the Uni-versity of the Basque Country (EHU-EJIE,EJIE07/05).ReferencesI.
Aduriz, M. J. Aranzabe, J. M. Arriola, A. Atutxa, A.Diaz de Ilarraza, A. Garmendia and M. Oronoz.2003.
Construction of a Basque dependencytreebank.
Treebanks and Linguistic Theories.Kepa Bengoetxea and Koldo Gojenola.
2009.
Explor-ing Treebank Transformations in DependencyParsing.
Proceedings of RANLP?2009.Johan Hall, Jens Nilsson, Joakim Nivre J., Eryigit G.,Megyesi B., Nilsson M. and Saers M. 2007.
SingleMalt or Blended?
A Study in MultilingualParser Optimization.
Proceedings of the CoNLLShared Task EMNLP-CoNLL.Andr?
F. T. Martins, Dipanjan Das, Noah A. Smith,Eric P. Xing.
2008.
Stacking Dependency Pars-ing.
EMNLP-2008.Jens Nilsson, Joakim Nivre and Johan Hall.
2007.Tree Transformations for Inductive Depend-ency Parsing.
Proceedings of the 45th ACL.Joakim Nivre, Johan Hall, Jens Nilsson, Chanev A.,G?lsen Eryi?it, Sandra K?bler, Marinov S., andEdwin Marsi.
2007a.
MaltParser: A language-independent system for data-driven depend-ency parsing.
Natural Language Engineering.Joakim Nivre, Johan Hall, Sandra K?bler, RyanMcDonald, Jens Nilsson,  Sebastian Riedel andDeniz Yuret.
2007b.
The CoNLL 2007 SharedTask on Dependency Parsing.
EMNLP-CoNLL.Joakim Nivre and Ryan McDonald.
2008.
Integrat-ing graphbased and transition-based depend-ency parsers.
ACL-2008.LASSystem Development Test1 Nivre et al 2007b (CoNLL 2007) -  76.94%2 Hall et al 2007 (CoNLL 2007)   74.99%3 Bengoetxea and Gojenola 2009   76.80%4 Feature optimization (baseline) 77.46%  75.07%5 Proj 78.16%  (+0.70) *75.99%  (+0.92)6 PVG 78.14%  (+0.68) 75.54%  (+0.47)7 PCOOR 77.36%  (-0.10) 75.22%  (+0.15)8 PCAS 77.32%  (-0.14) 74.86%  (-0.21)9 PVG + PCAS  78.53%  (+1.09) 75.42%  (+0.35)10 PCOOR + PVG + PCAS  78.31%  (+0.85) *75.93%  (+0.86)11 PCOOR + PVG 78.25%  (+0.79) *75.93%  (+0.86)12 Proj + PVG  78.91%  (+1.45) *76.12%  (+1.05)13 Proj + PVG + PCOOR  + PCAS 78.31%  (+0.85) *77.12%  (+2.05)Table 1.
Evaluation results(Proj: Pseudo-projective, PVG, PCAS, PCOOR: Propagation on verb compounds, case (NPs)  and coordination; *: statisticallysignificant in McNemar's test with respect to labeled attachment score with p < 0.01)145
