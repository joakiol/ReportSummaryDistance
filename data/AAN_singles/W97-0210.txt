mmInvestigating Complementary Methods for Verb Sense PruningHongyan Jing and Vasileios Hatzivassiloglouand Rebecca Passonneau and Kathleen McKeownmumDepar tment  of Computer  Science450 Computer  Science BuildingColumbia UniversityNew York, N.Y. 10027{hj ing, vh, becky, kathy}@?s, columbia, eduAbst ractWe present an approach for tagging verbsense that combines a domain-independentmethod based on subcategorization and al-ternations with a domain-dependent meth-od utilizing statistically extracted verbclusters.
Initial results indicate that verbsenses can be pruned for highly polysemousverbs by up to 74% by the first method andby up to 85% by the second method.1 In t roduct ionMuch work in natural anguage processing is predi-cated on the notion that linguistic usage varies suf-ficiently across different situations of language usethat systems can be tailored to a particular sub-language variety (Kittredge and Lehrberger, 1982).Biber (1993) presents evidence that a corpus re-stricted to one or two language registers would ex-clude "much of the English language" by narrow-ing the lexicon, verb tense and aspect, and syntacticcomplexity.
Such observations inform the increas-ing trend towards analysis of homogeneous corporato identify linguistic constraints for use in systemsintended to understand or generate coherent dis-course.
Recent work in this vein includes identi-fication of lexical constraints from textual tutorialdialogue (Moser and Moore, 1995), constraints onillocutionary act type from spoken task-oriented di-alogue (Allen et al, 1995), prosodic onstraints fromspoken information-seeking monologues (Hirschbergand Nakatani, 1996), and constraints on referring ex-pressions from spoken arrative monologue (Passon-neau, 1996).
Related work suggests that constraintsof different ypes are interdependent (Biber, 1993;Passonneau and Litman, forthcoming), hence shouldbe investigated together.
Our ultimate goal is to de-velop methods to tag lexical semantic features in dis-course corpora in order to enhance xtraction of con-straints of the sort just listed.
Two types of inves-tigations that would undoubtedly be enhanced areexplorations of the interrelation of lexical cohesionand global discourse structure (Morris and Hirst,1991; Hearst, 1994), and identification oflexicaliza-:tion patterns for domain-specific concepts (Robin,1994).In this paper, we propose a two-pronged approachto an initial step in lexical semantic tagging, prun-ing the search space for polysemous verbs.
Ratherthan attempting to identify unique word senses, weaim for the more realistic goal of pruning sense in-formation.
We will then incrementally evaluate theutility of tagging corpora with pruned sense sets fordifferent types of discourse.
We begin with verbs onthe hypothesis that verb sense distinctions correlatewith syntactic properties of verbs (Levin, 1993).
Ourinitial results indicate that domain-independent sy -tactic information reduces potential verb senses formultiply polysemous verbs (five or more WordNetsenses) by more than 50%.
In Section 2, we outlineour first method, based on domain-independent l x-ical knowledge, presenting results from an analysisof thousands of verbs.
In the section following that,we present our complementary method, a techniqueutilizing verb clusters automatically computed fromcorpus data.
In the conclusion, we discuss how thecombination of the two methods increases the per-formance of our system and enhances the robustnessof the final results.2 Exp lo i t ing  domain - independentsyntact i c  c luesA given word may have n distinct senses and appearwithin m different syntactic ontexts, but typically,not all n x m combinations are valid.
The syntacticcontext can partly disambiguate he semantic on-tent.
For example, when the verb question has athat-clause complement, i  cannot have the sense of"ask", but rather must have the sense of "challenge".To identify such interacting syntactic and seman-tic constraints at the lexical level, we utilize threeknowledge bases for verbs:* The COMLEX database (Grishman et al, 1994;Macleod and Grishman, 1995), which includes de-tailed subcategorization nformation for each verb,and some adjectives and nouns.\[\]mmm\[\]mmmmm58?
Levin's classification of verbs in terms of their al-lowed alternations (Levin, 1993).
Alternationsinclude syntactic transformations such as there-insertion (e.g., A ship appeared on the horizon---, There appeared a ship on the horizon) andlocative-inversion (e.g., --* On the horizon thereappeared aship).
Much in the same way as subcat-egorization frames, alternations are constrainedby the sense of the word; for example, the verb ap-pear allows there-insertion and locative-inversionin its senses of "come into being" or "become vis-ible", but not in its senses of "come out" or "par-ticipate in a play".?
WordNet's (Miller et al, 1990) hierarchical se-mantic classification.
WordNet supplies links be-tween semantically related senses as encoded insynonym sets (synsets).
Though many words arepolysemous, Miller et al (1990) argue that a setof synonymous or nearly synonymous words canserve to identify the single lexical concept theyhave in common.
It also supplies limited subcate-gorization information, in the form of allowed sen-tential frames ("verb frames") for each sense.WordNet contains the needed information on per-missible combinations of syntactic ontext and se-mantic content, but its subcategorization informa-tion is limited.
Thirty-five different subcategoriza-tion frames are used for all verbs in WordNet, andthe frames supplied are partial.
COMLEX pro-vides more detailed specifications of the syntacticframes for each verb (92 distinct subcategorizationtypes).
The allowed alternations (which we encodedin machine-readable form from the detailed rulessupplied in (Levin, 1993)) provide additional con-straints.
Mapping the more precise syntactic infor-mation in COMLEX to the verb frames of WordNetallows the construction of a more detailed syntac-tic entry for each word sense, and enables the as-sociation of alternation constraints with the sensesin WordNet.
In the future, it will also allow us touse corpora tagged with COMLEX subcategoriza-tion frames, e.g., (Macleod et al, 1996).We have manually constructed a table that mapsWordNet syntactic onstraints to the ones used inCOMLEX (and vice versa) and another that mapsallowed alternations from (Levin, 1993) to COM-LEX or WordNet syntactic frames.
A program con-suits the three databases and the mapping tablesand, for each word occurrence constructs a list ofthe senses that are compatible with the syntacticconstraints.
During this process, a detailed entry forthe word is formed, containing both syntactic and se-mantic information.
The resulting entries comprisea rich lexical resource that we plan to use for textgeneration and other applications (Jing et al, 1997).For a specific example, consider the verb appear.The pertinent information i  the three databases forthis word is listed in parts (a)-(c) of Figure 1.
For59(VERB :ORTH "appear":SUBC ((PP-TO-INF-RS :PVAL ("to"))(PP-PRED-RS:PVAL ("to" "of""under" "against"" in  favor Of""before .... at" )  )(EXTI~P-TO-NP-S)(INTRAmS)(SEEK-S)(SEEN-T0-NP-S)(TO-INF-RS)(NP-PRF.D-RS)(ADJP-PRKI)-RS)(ADVP-PRm-RS)(AS-NP)))(a) COMLEX entry for appearINTR&WS THEB~-V-SUBJ:ALT there - inser t ionLOCPP LOCPP-V-SUBJ:ALT locat ive- invers ion(b) Allowed alternations for appearappear Sense 1 (give an impression)?
> Something s Adjective/Moun?
> Somebody _~ Adjective?
> Somebody _. to INFINITIVESense 2 (become vis ib le)?
> Something s?
> Somebody s?
> Something is ing PP?
> Somebody s PP.
.
.Sense 8 (have an outeaxdexpression)?
> Something s Adjective/Noun?
> Somebody.
s Adjective(c) WordNet sense-syntax constraints for appearFigure 1: Database information for the verb appear.example, one of the subcategorization frames of ap-pear in part (a), aDJP-PRKD-R$, indicates a pred-icate adjective with subject raising, as in He ap-peared confused.
Part (b) of Figure 1 lists no al-ternations that are applicable to this subcategoriza-tion frame, while part (c) shows only two Word-Net synsets where appear takes an adjectival com-plement, senses $1 and $8.
The complex entry ofFigure 2 is produced automatically from these threetypes of lexical information.
The resulting syntax-semantics restriction matrix for appear is shown inTable 1.
When appear is encountered in a partic-ular syntactic structure, the program consults the( appear((I ((PP-T0-Ir~-RS :PVAL ("to"):SO ((sb, --)))(T0,IIIF-RS :SO ((sb, --)))(NP-PRED-RS :SO ((sb,  --) (sth,  --)))(ADJP-PRED-RS :SO ((sb, --)(sth,  --)))))(ADVP-PRED-RS :SO ((sb,  --)(sth,  --)))))(2 ((PP-T0-INF-RS :PVAL ("to"):SO ((sb, --)(sth, --)))(PP-PRED-RS :PVAL ("to" "of""under" "agaSnst""in favor of""before" "at"):SO ( ( sb , - - )  (sth,  --)))(INTRANS :SO ((sb, --) (sth, -)))(AS-~P :so ((sb, -) (sth, -)))(LOCPP :SO ((sb, --) (sth,  --)))(INTRANS THERE-V-SUBJ:ALT there-insertion:SO ((sb, --) (sth, -)))(LOCPP LOCPP-V-SUBJ:ALT locat ive- invers ion:SO ((sb, --) (sth,  - - ) ))))CS ((IP-PRm)-RS :so CCsth, -)))(ADJP-PRED-RS :SO ((sb,  --)(sth, --)))(ADVP-PRF.,D-RS :SO ((sb,  --)(st,t, - ) ) ) ) ) ) )Figure 2: Automatically synthesized lexicon entryfor the verb appear.restriction matrix to eliminate senses that can beexcluded.
In the case of appear, only 47 cells ofthe 8 x 23 matrix represent possible combinationsof syntactic patterns with senses, corresponding toa 74.5% reduction in ambiguity.Due to incompatibilities between the COMLEXand WordNet representations of syntactic informa-tion, and the differences in coverage, the process oflinking the information sources can in some cases?
result in relatively underspecified rows of a restric-tion matrix, or to spurious cells.
For example, theframe ADVP-PRED-RS in Table I occurs in COMLEXbut does not correspond to any of the more generalframes mentioned in WordNet.
Rather than havingno appropriate senses for this syntactic pattern, wemap it to WordNet's verb frames "Something sAdjective/Noun" and "Somebody s Adjective"by analyzing experiment results regrsssively.On the other hand, the entry for $2 in thePP-TO-IIIF-RS frame for appear epresents a spuri-ous entry: appear does not occur in the $2 meaningof "become visible" with a to-prepositional phraseand a subject-controlled infinitive.
In a sentencewith this syntactic structure, such as '~fhe river ap-peared to the residents to be rising too rapidly",appear can take only senses $1 and $6 for animatesubjects and senses $3 and $7 for inanimate sub-jects.
Yet the cell for $2 x PP-T0-IIIF-RS is gen-erated in our matrix because of the overly gen-eral specification of verb frames in WordNet.
Wehave chosen to risk overgeneration in these cases atpresent, rather than accidentally eliminating a validsense.
Eliminating spurious cells by hand would betime-consuming and error-prone, but the automaticclassification method we report in the next sectionmay help prune them.
Also, as reported elsewhere(Jing et al, 1997), we are extending our lexical re-source with annotations of frequency informationfor each sense-subcategorization pair, derived fromsense-tagged corpus data.
As data is accumulated,zero frequency could be taken to represent less validusages.We have performed preliminary evaluation testsof our method for tagging verb occurrences withpruned word sense tags using the Brown corpus.
Thefirst step of the method is to identify the subcatego-rization pattern for a specific verb token.
Here werely on heuristics to identify the major constituentsto the left and right of a verb token, as describedin (Jing et al, 1997).
After hypothesizing the sub-categorization pattern for a specific verb token, weuse our sense restriction matrices (as in Table 1)to tag the verb token with a pruned set of senses.We evaluate the resulting sense tag against the ver-sion of the Brown corpus that has been hand-taggedwith WordNet senses (Miller et al, 1993).
For ap-pear, which we use as an example throughout thispaper, we find 100 tokens in the Brown corpus.
Ofthese, 46 are intransitive or have a locative preposi-tional phrase complement.
Our method tags each ofthese tokens with two or three possible senses, andin all but one case, the sense tag includes the validsense.
Another 31 tokens are followed by to anda subject-controlled infinitive.
In all these cases,our method makes a single, correct prediction outof the eight possible senses.
For all 100 uses of ap-pear in the corpus, the average number of possiblesenses predicted by our method is 1.99.
We find a75-76% reduction of possible senses (depending onwhether we use the additional something~somebodyselectional constraints), with only 2-3% of the tagsbeing incorrect.For the 5,676 verbs present in all three databases,the average reduction in ambiguity was 36.82% forwords with two to four senses, 59.36% for words withfive to ten senses, and 73.86% for words with morethan ten senses; the overall average for all polyse-mous words was 47.91%.
Figure 3 is a bar chartshowing, for each number of senses from 1 to 41,how many verbs with that number of senses occur60Subcategorization/AlternationPP-TO-I~F-RS (sb, -) (sZh, -)PP-PRED-RS (sb, -) (sth, -)EXTRAP-TO-NP-SINTRANS (sb, --) Cash, -)SEFJI-SSEFJI-TO-NP-STO-INF-RS (sb, --) (sth, -)BP-PRED-RS (sb, -)(sth,  --)ADJP-PRF.J)-RS (sb, -) (sth, -)ADVP-PRED-RS (sb, --) (sth, --)AS-~P (sb, -)(sth, -)LOCPP (sb, --)(sth, -)THERE-INSERTIONLOCATIVE-IIVERSIONSense$1 $2 $3 $4 $5 $6 $7 $8+++ ++ + +?
++ % +%+ ++ + ++++++%++++ ++ %+ % ++ + %% % %+++++++Table 1: Valid combinations of syntactic subcategorization frames/alternations and senses (marked with +)for the verb appear.\ [ \ ]z~ool= l -\ [ \ ]  .
,ooo.u ,~ SO0.m lhlm----.1'0 ~) 30 41Number of sensesFigure 3: Distribution of verbs according to numberof senses.
Low frequencies are not drawn to scale;rather, the presence of a bar for a category corre-sponding to more than 10 senses indicates that atleast one verb falls in that category.in our databases.
The most polysemous verb in ourdatabases, run, is identified as having 41 senses.About half the verbs have more than one sense,and 20% have more than two.
Our method performsbetter on the more polysemous words, which axe themost difficult to prune.
This increased difficulty ap-plies even to statistical methods because of the largenumber of alternatives and the likely closeness inmeaning among them.
Selecting a subset of almostsynonymous verb senses is significantly harder than,for example, disambiguating bank between the "edgeof river" and '~financial institution" senses.3 Us ing  domain -dependent  semant icc lass i f i ca t ions  to  ident i fy  p redom-inant  sensesThe process outlined above has two significant ad-vantages: first, it can be automatically applied, as-suming a robust method for parsing the relevantverb phrase context (the experiments presented in(Pustejovsky et al, 1993) depend on the same typeof information).
Second, it reduces the ambiguityof a given word without sacrificing accuracy, inso-far as the three input knowledge sources are accu-rate.
To further estrict he size of the set of validsenses produced, we are currently exploring domain-dependent, automatically constructed semantic clas-sifications.Semantic lassification programs (Brown et al,1992; Hatzivassiloglou and McKeown, 1993; Pereiraet al, 1993) use statistical information based on co-occurrence with appropriate marker words to parti-tion a set of words into semantic groups or classes.61For example, using head nouns that occur with pre-modifying adjectives as one type of marker word,the adjective set {blue, cold, green, hot, red} can bepartitioned into the subsets (l~r, ical fields (Lehrer,1974)) {blue, green, red} and .
{cold, hot}.
Auto-matic classification programs can achieve high per-formance, near that of humans on the same task,when supplied with enough da~a and with appro-priate syntactic constraints (see (Hatzivassiloglou,1996) for a detailed evaluation).
However, giventhat each word must be assigned to one class in-dependently of context, 1 the problem of ambiguityis "solved" by placing each word in the class whereit fits best; that is, in the class dictated by the pre-dominant sense of the word in the training text.While this might be a limitation of partitioningmethods for lexicographical purposes, it offers anadvantage for our task.
By an indirect route, it al-lows the automatic identification ofthe predominantsense of a word in a given text or subject opic.
It isindirect because the actual result is groups of wordforms, but we presume ach group to represent a rel-atively homogeneous semantic lass.
Thus we pre-sume that the relevant sense of a given word formin a group is in the same lexical field as the sensesof the other word forms in the same group.
Theprocess is highly domain-dependent, i.e., the sameset of words will be partitioned in different wayswhen the domain changes.
For example, when ourword grouping system (Hatzivassiloglou and McKe-own, 1993) classified about 280 frequent adjectivesin stock market reports, it formed, among others,the cluster {common, preferred}.
This cluster wouldlook odd were not the domain considered.
~This information on predominant senses for eachword form in a given corpus can be computed au-tomatically, but remains implicit.
To map the re-sults onto word sense associations, and thus explic-itly identify the predominant senses, we utilize thelinks between senses provided by WordNet.
We notethat while words like question and ask are ultimatelyconnected in WordNet, the actual connections areonly between some of the senses of the two words.Similarly, the words question and dispute are alsoconnected, but through a different subset of senses.Thus, if the automatically induced semantic lassifi-cation indicates that the predominant sense of ques-tion is associated with dispute rather than with ask(by placing question and dispute but not ask in thesame group), we can infer which of the WordNetsenses of question is the predominant one in this do-main.
The algorithm involves the following steps:aSome systems produce "soft s clusters, where wordscan belong into more than one group.
These can beconverted to non-overlapping groups for the purposes ofthis discussion by assigning each word to the group forwhich it has the highest membership coefficient.2In this domain, the two adjectives are complemen-taxies, describing the two types of issued stock shares.?
Construct the domain-dependent word classifica-tion.?
For each word z, let Y - {YI,Y2,...} be the setof other words placed in the same semantic groupwith z.
* For each I~ 6 Y, traverse the WordNet hierarchyand locate the (set of) senses of z, Si, that are con-nected with some sense of ~.
The distance andthe types of links that can be traversed while stillconsidering two senses "related" can be heuristi-cally determined; alternatively, we can use a mea-sure of semantic distance such as those proposedin (Resnik, 1995) or (Passonneau et al, 1996).?
Finally, the union of the sets S~ contains the pre-dominant sense of x.
While in the general caseit is possible to have multiple links between wordforms (corresponding to different sense pairings),typically each Si will contain only one sense, andtheir union will contain a few elements.
This set ~can be further reduced, e.g., by giving more weightto senses supported by more than one of the ~'sor by unambiguous Y~'s.For a concrete example, consider the verb ques-tion, which can have, among others, the senses ofdispute (sense 1 in WordNet) or inquire (sense 3 inWordNet).
If we consider a sense as linked withone of the senses of question if it is in the maxi-mal subtree which includes that sense but no othersenses of question, we find the following links be-tween question and the verbs ask, inquire, chal.lenge, and dispute: (question1, asks), (questiou~,asks), (questions, asks), (questions, inquire~), and(question1, challenge~).
Thus, if question is placedin the same semantic group with ask and inquire, thethree senses {1, 2, 3} survive out of the five sensesof question, with a preference for sense 3.
If, on theother hand, question is classified with challenge anddispute, only sense 1 survives.We performed an experiment analyzing a specificverb group produced by one semantic lustering pro-gram (McMahon and Smith, 1996).
This groupcontains 19 verbs, all but one of them ambiguous,including ask, call, charge, regard, say, and wish.We measured for each sense of the 19 words howmany of the other words have at least one senselinked with that sense in WordNet (in the same top-level verb sense tree).
The results, part of whichis shown in Table 2, indicate that some senses aremuch more strongly connected with the other wordsin the group, and so probably predominate in thecorpus that was used to induce the group.
For ex-ample, one of the senses of ask, "require" (as in Thisjob asks (for) long hours) is not linked to any of theother 18 words in the cluster, and should thereforebe removed.
If, for each word w we analyze, we re-quire that each of its probable senses be linked toat least a fixed percentage (e.g., one-third) of thetotal number of words linked to to, we can eliminate62WordaskcallchargedescribeknowregardNumberof senses S1513Number of other words in group linked with given sense$2 83 54 55 86 $7 58 59 S10 Sll S12 S139 9 9 0 90 0 9 1 9 9 1 9 2 0 9 9 33 2 0 0 2 3 0 2 31 9 3 00 0 0 0 '9 5 1 15 0 00 I say 9 2 0 9 0 9 1 9wish 7 2 2 1 2 2 9 9Table 2: Number of words in a semantic group linked with each sense of each word in it, and associatedreduction in ambiguity.
Eight of the 19 words are shown.Verbshowdescribepresentpro f}eintroduceNumber ofsenses inWordNet1312910IW,_i,L~ ~, ,  , - -~ ,  o\]1~,Surviving sensesafter cluster-basedmethod is applied9644sReductionin ambi~ uity(typ~l)30.7T go50.00%50.00%55.56%60.00%4.q 27?7,Occurrencesin the corpus(tokens)109328i0633WronglytasgedtokensErrorrate3.67%3.12%-12.50%50.00%50.00%Table 3: Reduction in ambiguity and sense tagging error rate for the cluster-based method, as measured forfive verbs on the J part of the Brown corpus.many of the senses as improbable.
The achieved re-duction in ambiguity (for the 18 ambiguous words)ranges from 20% to 84.62% (including cases of fulldisambiguation), and its average for all 18 words is55.89%.In another experiment, we looked at a specific or-pus, taking into account he frequency distributionof the verbs in it.
We selected the J part of theBrown corpus, which focuses on learned knowledge(the Natural Sciences, Mathematics, Medicine, theHumanities, etc.)
(Ku~era nd Francis, 1967).
Thispart of the corpus is more homogeneous and con-tains a larger number of articles (80).
The increasedhomogeneity makes it suitable for investigating ourhypothesis of predominant verb senses.We selected five verbs from this sub-corpus ( how,describe, present, prove, and introduce), and appliedour algorithm assuming that the predominant sensesof these verbs axe linked together and consequently,that the five verbs would be placed in the same groupby the clustering program.Under this assumption, we measured the reduc-tion in ambiguity (number of possible senses) foreach verb (types) as well as over all occurrences ofthe five verbs in the sub-corpus (tokens) when thecluster-based algorithm is applied.
We also countedhow many of the verbs receive a wrong tag, i.e., aset of senses that does not include the hand-assiguedone.
The results of these experiments are shown inTable 3.
We observe that the cluster-based methodachieves a 49.27% reduction in the number of senses-when measured on types.
When the distribution ofthe words is factored in, the corresponding measureon tokens (which better describes the applicabilityof the method in practice) is 38.00%.
The averageerror rate is 8.48%; this average is driven up by theinclusion of present, prove, and introduce in our testset.
The relatively high error rate for these verbsmay be due to their low frequency in our corpus, ormay indicate that their predominant senses axe notassociated with the predominant senses of show anddescribe as we hypothesized.4 Combin ing  the  two  methodsWhile the syntactic constraints method almost al-ways produces a semantic tag that includes the cor-rect sense for a verb, 3 it has no capability to furtherdistinguish the surviving senses in the tag.
The se-mantic link-based method, on the other hand, caneliminate some senses from this tag.
By applying thetwo methods in tandem and intersecting the sensesets produced by them, we can reduce the size of thefinal tag.
Using the verb "show" of the experimentdescribed in the previous section as an illustration,we note that whenever the verb takes only a directobject, the syntactic method eliminates three of thethirteen possible senses while always retaining theZAssuming no gaps in the subcategorization informa-tion for this verb in COMLEX and WordNet.63correct sense in the produced tag (error rate 0%).For the same verb and subcal~.egorization pattern,the cluster-based method rejects four of the thirteensenses with error rate 5% (i.e, 3 out of 58 occurrencesin the Y part of the Brown Corpus will be assignedwrong tags).
The intersection of the two methodsincreases the number of rejected senses to five.
Itreduces the ambiguity by 38% but has the combinederror rate of both methods, in this case 5%.As we see from this experiment, he integration ofthe two methods can improve the reduction rate ofambiguity, but may slightly increase the error rate.We are investigating ways to stratify the applicationof the cluster-based method on appropriate groupsof tokens identified by the syntactic method, by sep-arately clustering tokens of the same verb that ap-pear in different syntactic frames.
We expect hatthis will partly alleviate the increase in the errorrate.5 DiscussionOur method for using detailed knowledge about verbsubcategorizations and alternations to prune verbsenses is domain independent.
It also prunes senseswithout loss of correctness.
By intersecting the re-sulting sense sets with the output of our cluster-based method, verb senses can be pruned further.In using the clustering method's output, we maketwo further assumptions.
Previous work has shownthat within a given discourse (Gale et al, 1992), orwith respect to a given collocation (Yarowsky, 1993),a word appears in only one sense.
By extrapolation,we will assume that words appear in only one sensewithin a homogeneous corpus, 4 except for certainhigh frequency verbs or for semantically empty sup-port verbs.
We will assign this predominant sense toall non-disambignated occurrences of a verb.
Whilethis provides a reasonable default, the resulting se-mantic tag has to be considered provisional, and vali-dated independently.
Also, we currently assume thatwords placed in the same group will share relativelyfew links (connecting pairs of competing senses) inWordNet.
This is supported by our initial experi-ments, but is an issue we will continue to investigate.Above we gave some preliminary evaluation re-sults; we plan to carry out a more complete valu-ation of our system by continuing to use the hand-tagged (with WordNet senses) Brown corpus (Milleret al, 1993) as the initial evaluation standard.
Eachstage will be separately measured, as well as theircombined effectiveness in pruning senses.
We antici-pate that the use of multiple methods to investigatesense pruning will lead to more robust results.
In ad-dition, we believe that the two methods can be inter-leaved in the following manner: Both methods relytOt a few predominant senses, that can perhaps bedisambigu&ted using syntactic onstraints as we discussbelow.on recognizing features of the local syntactic contextof a verb occurrence; the look-up method uses thelocal syntactic context to identify the likely subcate-gorization pattern while the automatic classificationmethod uses the local syntactic context to extractmarker words.
The look-up method can tag distincttokens of the same verb with distinct senses if thesubcategorization patterns are distinct and correlatewith distinct senses.
The automatic classificationmethod could be extended to classify sense sets, us-ing as its input corpus the output of the syntacticconstraints look-up method, where verb tokens havebeen tagged with a subset of the full collection ofsenses.
In principle, this would make it possible touse the automatic classification method on a moreheterogeneous corpus, i.e., where the same verb oc-curs frequently with two distinct senses.ReferencesJames F. Allen, Lenhart K. Schubert, George Fergn-son, Peter Heeman, Chung Hee Hwang, TsuneakiKato, Marc Light, Nathaniel G. Martin, Brad-ford W. Miller, Massimo Poesio, and David R.Tranm.
1995.
The TRAINS project: A case studyin defining a conversational planning agent.
Jour-nal o/Ezperimental nd Theoretical AI, 7:7-48.Douglas Biber.
1993.
Using register-diversified cor-pora for general language studies.
ComputationalLinguistics, 19(2):219-242, June.
Special Issue onUsing Large Corpora: II.Peter F. Brown, Vincent J. della Pietra, Peter V.de Souza, Jennifer C. Lai, and Robert L. Mercer.1992.
Class-based n-gram models of natural an-guage.
Computational Linguistics, 18(4):467-479.William A. Gale, Kenneth W. Church, and DavidYarowsky.
1992.
One sense per discourse.
InProceedings ofthe ~th DARPA Speech and NaturalLanguage Workshop, February.Ralph Grishman, Catherine Macleod, and AdamMeyers.
1994.
COMLEX syntax: Building a com-putational lexicon.
In Proceedings o/COLING-9~,Kyoto, Japan, August.Vasileios Hatzivassiloglou and Kathleen McKeown.1993.
Towards the automatic identification of ad-jectival scales: Clustering adjectives according tomeaning.
In Proceedings ofthe 31st Annual Meet-ing o/the Association for Computational Linguis-tics, pages 172-182, Columbus, Ohio, June.Vasileios Hatzivassiloglou.
1996.
Do we need lin-guistics when we have statistics?
A comparativeanalysis of the contributions of linguistic cues toa statistical word grouping system.
In Judith L.Klavans and Philip S. Resnik, editors, The Bal-ancing Act: Combining Symbolic and StatisticalApproaches to Language, pages 67-94.
The MITPress, Cambridge, Massachusetts.64Mufti A. Hearst.
1994.
Multi-paragraph segmenta-tion of expository text.
In Proceedings ofthe 3$ndAnnual Meeting of the Association for Computa-tional Linguistics, pages 9-16, Las Cruces, NewMexico.Julia Hirschberg and Christine H. Nakatani.
1996.A prosodic analysis of discourse segments indirection-giving monologues.
In Proceedings ofthe 34th Annual Meeting of the Association forComputational Linguistics, pages 286-293, SantaCruz, California, June.Hongyan Jing, Kathleen MeKeown, and RebeccaPassonneau.
1997.
Building a rich large-scale x-teal base for generation.
Submitted to the 35thAnnual Meeting of the Association for Computa-tional Linguistics.R.
Kittredge and J. Lehrberger, editors.
1982.
Sub-language: Studies of Language in Restricted Se-mantic Domains.
De Gruyter, Berlin.Henry Ku~era nd W. Nelson Francis.
1967.
Com-putational Analysis of Present-Day American En-glish.
Brown University Press, Providence, RhodeIsland.Adrienne Lehrer.
1974.
Semantic Fields and LezicalStructure.
North Holland, Amsterdam and NewYork.Beth Levin.
1993.
English Verb Classes and Alter-nations: A Preliminary Investigation.
Universityof Chicago Press, Chicago, Illinois.Catherine Macleod and Ralph Grishman, 1995.COMLEX Syntaz Reference Manual.
ProteusProject,.
New York University.Catherine Macleod, Adam Meyers, and Ralph Gr-ishman.
1996.
The influence of tagging on theclassification of lexical complements.
In Proceed-ings of COLING-96, Copenhagen, Denmark.John G. McMahon and Francis J. Smith.
1996.
Im-proving statistical language model performancewith automatically generated word hierarchies.Computational Linguistics, 22(2):217-247, June.George A. Miller, Richard Beckwith, Christiane Fell-baum, Derek Gross, and Katherine J. Miller.1990.
Introduction to WordNet: An on-line lexi-cal database.
International Journal of Lexicogra-phy (special issue), 3(4):235-312.George A. Miller, Claudia Leacock, Randee Tengi,and Ross T. Bunker.
1993.
A semantic oncor-dance.
Cognitive Science Laboratory, PrincetonUniversity.Jane Morris and Graeme Hirst.
1991.
Lexical co-hesion computed by thesaural relations as an in-dicator of the structure of text.
ComputationalLinguistics, 17(1):21-48.Megan Moser and Johanna D. Moore.
1995.
Investi-gating cue selection and placement in tutorial dis-course.
In Proceedings ofthe 33rd Annual Meetingof the Association for Computational Linguistics,pages 130-135, Cambridge, Massachusetts, June.Rebecca J. Passonneau and Diane J. Litman.
Forth-coming.
Combining multiple knowledge sourcesfor discourse segmentation.
Computational Lin-guistics.
Special Issue on Empirical Studies inDiscourse Interpretation a d Generation.Rebecca J. Passonneau, Karen K. Kukich, JacquesRobin, Vasileios Hatzivassiloglou, Larry Lefko-witz, and Hongyan Jing.
1996.
Generatingsummaries of work flow diagrams.
In Proceed-ings of the International Conference on Natu-ral Language Processing and Industrial Applica-tions, New Brunswick, Canada, June.
Universityof Moncton.Rebecca J. Passonneau.
1996.
Using centeringto relax informational constraints on discourseanaphorie noun phrases.
Language and Speech,39(2-3):229-264, April-September.
Special Dou-ble Issue on Discourse and Syntax.Fernando Pereira, Naftali Tishby, and Lillian Lee.1993.
Distributional clustering of English words.In Proceedings ofthe 31st Annual Meeting of theAssociation for Computational Linguistics, pages183-190, Columbus, Ohio, June.James Pustejovsky, Sabine Bergler, and Peter An-ick.
1993.
Lexical semantic techniques for corpusanalysis.
Computational Linguistics, 19(2):331-359, June.
Special Issue on Using Large Corpora:II.Philip Resnik.
1995.
Using information content oevaluate semantic similarity in a taxonomy.
InProceedings of the Fourteenth International JointConference on Artificial Intelligence (IJCAI-gs),volume 1, pages 448-453, Montreal, Quebec,Canada, August.
Morgan Kaufmann, San Mateo,California.Jacques Robin.
1994.
Revision-Based Generation ofNatural Language Summaries Providing HistoricalBackground: Corpus-Based Analysis, Design, Im-plementation, and Evaluation.
Ph.D. thesis, De-partment of Computer Science, Columbia Univer-sity, New York.
Also Technical Report CU-CS-034-94.David Yarowsky.
1993.
One sense per collocation.In Proceedings ofthe ARPA Workshop on HumanLanguage Technology, pages 266-271, Plainsboro,New Jersey, March.
ARPA Software and Intelli-gent Systems Technology Office, Morgan Kauf-mann, San Francisco, California.65
