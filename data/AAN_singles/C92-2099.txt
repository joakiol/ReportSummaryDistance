ACQUIS IT ION OF SELECTIONAL PATTERNSRALPH GRISHMAN and JOHN STERLINGComputer  Science DepartmentNew York UniversityNew York, NY 10003, U.S.A.1 The  Prob lemFor most natural anguage analysis ystems, oneof the major hurdles in porting the system to anew domain is the development of an appropri-ate set of semantic patterns.
Such patterns aretypically needed to guide syntactic analysis (asselectional constraints) and to control the trans-lation into a predicate-argument representation.As systems are ported to more complex domains,the set of patterns grows and the task of accumu-lating them manually becomes more formidable.There has therefore been increasing interestin acquiring such patterns automatically froin asample of text in the domain, through an analysisof word co-occurrence patterns either in raw text(word sequences) or in parsed text.
We brieflyreview some of this work later in the article.
Wehave been specificaily concerned about the prac-ticality of using such techniques in place of man-ual encoding to develop the selectional patternsfor new domains.
In the experiments reportedhere, we have therefore been particularly con-cerned with the evaluation of our automaticallygenerated patterns, in terms of their complete-hess and accuracy and in terms of their efficacyin performing selection during parsing.2 Pat terns  and Word  C lassesIn principle, the semantic patterns could bestated in terms of individual words - this verbcan meaningfully occur with this subject, etc.
Inpractice, however, this would produce an unman-ageable number of patterns for even a small do-main.
We therefore need to define semantic wordclasses for the domain and state our patterns interms of these classes.Ideally, then, a discovery proeednre for seman-tic patterns would acquire both the word classesand the patterns from an analysis of the wordco-occurrence patterns.
In order to simplify thetask, however, while we are exploring differentstrategies, we have divided it into separate tasks,that of acquiring word classes and that of ac-quiring semantic patterns (given a set of wordclasses).
We have previously described \[1\] someexperiments in which the principal word classesfor a sublanguge were obtained through the clus-tering of words based on the contexts in whichthey occurred, and we expect to renew such ex-periments using the larger corpora now available.However, the experiments we report below arelimited to the acquisition of semantic patternsgiven a set of manually prepared word classes.3 Pattern AcquisitionThe basic mechanism of pattern acquisition isstraightforward.
A sample of text in a new do-main is parsed using a broad-coverage rammar(but without any semantic onstraints).
The re-sulting parse trees are then transformed into aregularized syntactic structm'e (similar to the f-structure of Lexical-Fnnctional Grammar).
Thisregularization i particular educes all differentclausM forms (active, passive, questions, extra-posed forms, relative clauses, reduced relatives,etc.)
into a uniform structure with the 'logical'subject and object explicitly marked.
For exam-ple, the sentenceFred ate fresh cheese from France.would produce the regularized syntactic struc-ture(s eat (subject (np Fred))(object (np cheese (a-pos fresh)(from (np France)))))We then extract from this regularized structurea series of triples of the formAcrEs DE COLING-92.
NAMES.
23-28 hot;r 1992 6 5 8 PROC.
OF COLING-92, NANTES, AUG. 23-28, 1992head syntactic-function valuewhere - if the value is another NP or S - onlythe head is recorded.
For example, for the abovesentence we would get tile tripleseat subject Fredeat object cheesecheese a-pos freshcheese from bYanceFinally, we generalize these triples by replacingwords by word classes.
We had previously pre-pared,  by a purely manual  analysis of the corpus,a hierarchy of word classes and a set of semanticpatterns for the corpus we were using.
From thishierarchy we identified the classes which weremost frequently referred to in the nlanual ly pre-pared patterns.
The general ization process re-places a word by the most specific class to whichit belongs (since we have a hierarchy with uestedclasses, a word will typical ly belong to severalclasses).
As we cxplain in our experiment sec-tion below, we made some runs generalizing justthe value and others general izing both tlle headand the value.As we process the corl)us , we kee t) a count ofthe frequency of each head-function wdue triple.In addit ion,  we keep separate counts of the num-ber of t imes each word appears as a head, andthe number of t imes eacll head-fitnction pair al)-pears ( independent of value).4 Coping with Multiple ParsesThe procedure described above is sufficient ifwe are able to obtain ttlc correct parse for eacllsentence, l lowever, if we are port ing to a newdomain and have no semantic constraints, welnust rely entirely upon syntact ic onstraints andso will be confronted with a large number ofincorrect parses for each sentence, along with(hopefully) the correct one.
We have exl)eri-mented with several approaches to dealing withthis problem:1.
If a sentence has N parses, we can generatetr iples front all the parses and tllen includeeach triple with a weight of 1/N.2.
We can generate a stochastic grammarthrough unsupervised training on a portionof the corpus \[2\].
We can then parse the cor-pus with this stochastic grammar  at , l  takeonly the most probable parse for each sen-tence.
\]:or sentences which stil l  generatedN > 1 equal ly-probable parses, we woulduse a 1/N weight ;us before.3.
In place of a 1/N weighting, we can re-tine the weights for a l ternat ive parse treesnsing an i terat ive procedure analogous tothe inside-outside algorithm \[3\].
We he-gin by generat ing all parses, as in approach1.
Then, based on the counts obtained ini-t ial ly (using 1/N weighting), we can com-pute the probabi l i ty for the various triplesattd from these tim probabil it ies of the al-ternative parse trees.
We can then repeatthe process, recomputing the counts withweightings based on these probabil it ies.All of these approaches rely on the expectat ionthat correct patterns arising from correct parseswill occur repeatedly, while the distr ibution ofincorrect patterns from incorrect parses will bemore scattered, and so over a sufficiently largecorpus-  we cat, dist inguish correct from incor-rect patterns on the basis of frequency.5 Evaluation Methods~\['o gather patterns,  we analyzed a series of arti-cles on terrorism which were obtained from timForeign l l roadcast lnh)rmation Service and usedas the development era'pus for the Third MessageUnderstanding Confiwence (held in San Diego,CA, May 1991) \[4\].
l'br pattern collection, weused 1000 such articles with a total of :14,196sentences and 330,769 wor(ls.
Not all sentencesparsed, both because of l imitat ions in our gram-mar and becanse we inlpose a l imit on the searchwhich the parser can perform for each sentence.Within these l imits,  we were able to parse a totalof 7,455 sentencesJThe most clearly definable function of tbetriples we collect is to act as a selectional con-straint: to differentiate between meaningfld andmeaningless triples in new text, and thus identifythe correct attalysls.We used two methods to evaluate the effec-tiveness of tile triples we generated.
The firstIF or these runs we disabled several heuristics in oursystelll which increase tile nulnbef of sentences which canbe parsed at some cost m the average quality of parses;hence the relatively low percentage of sentences which ob-tained parses.ACRES DE COLING-92, NANrES, 23-28 Ao(rr 1992 6 5 9 PROC, OF COLING-92.
NANrrEs, AUO.
23-28, 1992method involved a comparison with manually-classified triples.
We took 10 articles (not in thetraining corpus), generated all parses, and pro-duced the triples from each parse.
These tripleswere stated in terms of words, and were notgeneralized to word classes.
We classified eachtriple as semantically valid or invalid (a triplewas counted as valid if we believed that this pairof words could meaningfully occur in this rela-tionship, even if this was not the intended rela-tionship in this particular text).
This produced atest set containing a total of 1169 distinct riples,of which 716 were valid and 453 were invalid.We then established a threshold T for theweighted triples counts in our training set, anddefinedv+ number of triples in test set which were clas-sified as valid and which appeared in train-ing set with count > Tv_ number of triples in test set which were clas-sified ms valid and which appeared in train-ing set with count < Ti+ number of triples in test set which were classi-fied ms invalid and which appeared in train-ing set with count > Ti_ number of triples in test set which were classi-fied as invalid and which appeared in train-ing set with count < Tand then definedrecall - v+v++v_precision - v+v+ + i+i+error rate - i++i_By varying tim threshold, we can plot graphsof recall vs. precision or recall vs. error-rate.These plots can then be compared among differ-ent strategies for collecting triples and for gen-eralizing triples.
The precision figures are some-what misleading because of the relatively smallnumber of invalid triples in the test set: sinceonly 39% of the triples are invalid, a filter whichaccepted all the triples in the test set would stillbe accounted as having 61% precision, We havetherefore used the error rate in the figures below(plotting recall against l~rror-rate).The second evaluation method involves theuse of the triples in selection and a comparisonof the parses produced against a set of knowncorrect parses.
In this case the known correctparses were prepared manually by the Univer-sity of Pennsylvania as part of their "'Free Bank"project.
For this evaluation, we used a set of 317sentences, again distinct from the training set,In comparing the parser output against he stan-dard trees, we measured the degree to which thetree structures coincide, stated as recall, preci-sion, and number of crossings.
These measureshave been defined in earlier papers \[5,6,7\].6 Resu l tsOur first set of experiments were conducted tocompare three methods of coping with multipleparses.
These methods, as described in section 4,are (1) generating all N parses of a sentence, andweighting each by l/N; (2)selecting the N mostlikely parses as determined by a stochastic gram-mar, and weighting those each by 1/N; (3) gen-erating all parses, but assigning weights to alter-native parses using a form of the inside-outsideprocedure.
These experiments were conductedusing a smaller training set, a set of 727 sen-tences drawn from 90 articles.
We generated aset of triples using each of the three methods andthen evaluated them against our hand-classifiedtriples, as described in section 5.
We show inFigure 1 the threshold vs. recM1 curves for thethree methods; in Figure 2 the recall vs. 1-errorrate curves.These experiments showed only very small dif-ferences between the three methods (the inside-outside method showed slightly better accuracyat some levels of recall).
Based on this, wedecided to use method 2 (statistical grammar)for subsequent experiments.
Other ttfings beingequal, method 2 hms the virtue of generating farfewer parses (an average of 1.5 per sentence, vs.37 per sentence when all parses are produced),and hence a far smaller file of regularized parses(about 10 MB for our entire training corpus of1000 articles, vs. somewhat over 200 MB whichwould have been required if all parses were gener-ated).
Using method 2, therefore, we generatedthe triples for our 1000-article training corpus.Our second series of experiments comparedthree different ways of accumulating data fromthe triples:ACTES DE COLING-92, NANTES.
23-28 hot~r 1992 6 6 0 PRoc.
OF COLING-92, NANTES, AUG. 23-28, 19920.40 -, 00o0.30 - * *~ '~recall 0.20 - '~OO0.10 - '~ l~0.00-  --, ....... , , ~ ..... *, , -'~,,,I0.1 1 10 100thresholdFigure 1: Comparison of methods for dealingwith mult iple parses in pattern collection, us-ing training corpus of 90 articles.
Threshoklvs.
recall for o = all parses; o = all parses +inside-outside; ?
= most t)robable parses fromstochastic grammar.1.00 -****ooo0.95 - meoO\] ?error 0 .90-rate0.85 -o o5 mooo%0.80" ' ' ,  , i - -70.00 0.10 0.20 0.30 0.40recallFigure 2: Comparison of methods for dealingwith mult iple parses in pattern collection, usingtraining corpus of 90 articles.
RecM1 vs. l -e rrot rate for o = all parses; o = all parses +inside-outside; ?
= most probable parses fromstochast ic grammar.1.00?
~mmo0.80 .mo.
o \recall %0.40 o~O 0(I.200.00 ....... ~ ...... .0.1 l 10 100thresholdFigure 3: Comparison of pattern generalizationtechniques, using training corpus of 1000 arti-cles.
Threshold vs. recall for o = triples withoutgeneralized heads; o = triples with generalizedheads; ?
= 1)airs.1.
general izing the value in a head-flmction-value triple to a word class, but not gen-eral izing tile head2.
general izing hoth the value and the head3.
ignoring the value field entirely in ahead-function-value triple, ,~n(l accumulat-ing counts of head-fimction pairs (with nogeneral izat ion applied to the head); a matchwith the hand-marked triples is thereforerecorded if the head and flmction fieldsmatchAgain, we evaluated the patterns produced byeach method against tile hand-marked triples.Figure 3 shows the threshohl vs. recall curvesfor each method; Figure 4 the recM1 vs. 1-errorrate curves.
Figure 3 indicates that  using pairsyields the highest recall for a given threshold,triples with generalized \]leads an intermediatevalue, and triples without generalized heads thelowest recall.
The error rate vs. recall curvesof ligure 4 do not show a great difference be-tween mcdLods, but they do indicate ttlat, overtile range of recalls for which they overlap, usingtriples without generalized heads l)roduces thelowest error ra te .Finally, we conducted a series of experimentsto compare the effectiveness of the triples in se-lecting the correct parse, in effect, the selectionprocedure works as follows, l'br each sentence inthe test corpus, the system generates all possibleAcrEs DE COLING-92, NANTES, 23-28 Ao~r 1992 6 6 1 PROC.
OF COLING-92.
Nx~,~r~s.
AUG. 23-28.
19921 -e r ro rrate1.00  -0 .80  -0 .600.400.200 o|||I I ' I I I I ' I "  "1 I" '1L00 0.20 0.40 0.60 0.80 \].00recallFigure 4: Comparison of pattern general izationtechniques, using training corpus of 1000 articles.Recall vs. 1-error rate for o = triples withoutgeneralized beads; o = triples with generalizedheads; ?
= pairs.parses and then generates a set of triples fromeach parse.
Each triple is assigned a score; thescore for the parse is the product of the scoresof the triples obtained from the parse (the useof products is consistent with the idea that  thescore for a triple to some degree reflects the prob-abi l i ty that  this triple is semantical ly valid).
Theparse or parses with the highest total  score arethen selected for evaluation.We tested three approaches to assigning ascore to a triple:1.
We used the frequency of head-function-value triples relative to the frequency of thehead as an est imate of the probabi l i ty thatthis head would appear with this function-value combination.
We used the "expectedl ikelihood est imate" \[8\] in order to assurethat  tr iples which do not appear in the train-ing corpus are still assigned non-zero proba-bil ity; this simple est imator  adds 1/2 to eachobserved frequency:freq.
of triple + 0.5score =freq.
of head + 0.52.
We applied a threshold to our set of col-lected triples: if a triple appeared with afrequency above the threshold it was as-signed one score; if at or below the thresh-old, a lower score.
We selected a thresholdof 0.9, so that any tr iple which appearedunambiguously in at least one sentence ofthe training corpus was included.
For ourscores, we used the results of our previ-ous set of experiments.
These experimentsshowed that at a threshold of 0.9, 82% ofthe triples above the threshold were seman-tically valid, while 47% of the triples belowthe threshold were val id3 Thus we usedscore = 0.82 if freq.
of triple > 0.90.47 if freq.
of triple < 0.9We expanded on method 2 by using bothtriples and pairs information.
To assigna score to a head-function-value triple, wefirst ascertain whether this tr iple appearswith frequency > T in the collected pat-terns; if so, we assign a high score to thetriple.
If not, we determine whether thehead-function pair appears with frequency> T in the collected patterns.
If so, weassign an intermediate score to the triple;if not, we assign a low score to the triple.Again, we chose a threshold of 0.9 for bothtriples and pairs.
Our earlier experimentsindicated that ,  of those head-function-valuetriples for which the triple was below thethreshold for triples frequency but the head-function pair was above the threshold forpair frequency, 52% were semanticai ly valid.Of those for which the head-function pairwas below the threshold for pair frequency,40% were semantical ly valid.
Thus we usedscore = 0.82 if freq.
of triple > 0.9, else0.52 if freq.
of pair > 0.9, else0.40 if freq.
of pair < 0.9Using these three scoring flmctions for selec-tion, we parsed our test set of sentences and thenscored the resulting parses against our "standardparses".
As a further comparison, we also parsedthe same set using selectional constraints whichhad been previously manuMly prepared for thisdomain.
The parses were scored against he stan-dard in terms of average recall, precision, andnumber of crossings; the results are shown in Ta-ble 1.
3 A better match to the correct parses2"Fhe actual value of the scores only matters in caseswhere one parse generates more triples than another.3These averages are calculated only over the subset oftest sentences which yielded a parse with our  granunarwithin the edge limit alloted.ACTI':S DE COLING-92, NANTES, 23-28 AOUT 1992 6 6 2 PROC.
OF COL1NG-92, NAMES, AUG. 23-28, 1992selection strategy crossings rec',di precision1.
frequency-based 2.00 75.70 71.862. triples-threshold 2.17 73.57 70.223. triples-and-pairs ?
2-09 74:33 70.94-3. hand-generated 2.04 "t4.34 iTable 1: A comparison of the effect of differentselection strategies on the quality of parses gen-erated.is reflected in higher recall and precision andlower number of crossings.
These results indi-cate that the frequency-based scores performedbetter than either the threshold-ha.qed scores orthe manually-prepared selection.7 Re la ted  WorkAt NYU we have long been interested in the pos-sibilities of automatically acquiring sublanguage(semantic) word classes and patterns from textcorpora.
In 1975 we reported on experiments- -  using a few hundred manuMly prepared reg-ularized parses --- for clustering words based ontheir co-occurrence patterns and thus generat-ing the principal sublanguage word classes for adomain \[1\].
In the early 1980's we performedexperiments, again with relatively small corporaand machine-generated (but manually selected)parses, for collecting snblanguage patterns, simi-lar to the work reported here \[9\].
By studying thegrowth curves of size of text sample vs. number ofpatterns, we attempted to estimate at that timethe completeness of the subtanguage patterns weobtained.More recently there has been a surge of in-terest in such corpus-based studies of lexicai cooccurrence patterns (e.g., \[1{},11,12,13\]).
The re-cent volume edited by Zernik \[14\] reviews manyof these efforts.
We mention only two of thesehere, one seeking a similar range of patterns, theother using several ewduation methods.Velardi et al \[11\] are using co-occurence datato build a "semantic lexicon" with informationabout the conceptual classes of the argumentsand modifiers of lexical items.
This informa-tlon is closely related to our selectional patterns,although the function'a\] relations are semanticor conceptual whereas ours are syntactic.
Theyuse manually-encoded coarse-grained selectionalconstraints to limit the patterns which are gen-erated.
No evaluation results are yet reported.IIindle aml Rooth \[10\] h~ve used co-occurrencedata to determine whether prepositional phrasesshould be attached to a preceding noun or verb.Unambiguous cases in the corpus are identifiedfirst; co-occurrence statistics based on these arethen used iteratively to resolve ambiguous cases.A detailed evaluation of the predictive power ofthe resulting p~tterns i provided, comparing thepatterns against human judgements over a set of1909 sentences, aud analyzing the error rate interms of the type of verh and noun association.8 Conc lus ionWe have described two different approachesto evahtating automatically collected selectionalpatterns: by comparison to a set of manually-classified patterns and in terms of their effective-hess in selecting correct parses.
We have shownthat, without any manual selection of the parsesor patterns ilt our trMning set, we are able toobtain selectioual p~tterns of quite satisfactoryrecall and precision, and which perform betterthan a set of manual selectional patterns in se~lecting correct parses.
We are not aware of anycomparable etlorts to evaluate a hdl range of au-tomatically acquired selectional patterns.Further studies are clearly needed, particularlyof the best way in which the collected triples canbe used for selection.
The expected likelihoodestimator is quite crude and more robust estima-tors should be tried, particularly given the sparsenature of tim data.
We should experiment withbetter ways of combining of triples and pairs datato give estimates of semantic validity.
Finally, weneed to explore ways of combining these auto-tactically collected patterns with manually gen-erated selectional patterns, which will probablyhave narrower coverage but may be more preciseand complete for the w~rbs covered.9 .AcknowledgementsThi~ report is based upon work supported bythe Defense Advanced Research Projects Agencyunder Grant N00014-9O-J-1851 from the Officeof Naval Research and by the National Sciencel:oun(lation under Grant 11H-89-02304.AcrEs DE COLING-92.
NANTES, 23-28 ^oLrr 1992 6 6 3 |)ROC.
or COLING-92.
NAN'rE.S.
Atro.
2.3-28, 1992References\[1\] Lynette ttirschman, Ralph Grishman, andNaomi Sager.
Grammatically-based auto-matic word class formation.
InformationProcessing and Management, 11(1/2):39-57, 1975.\[2\] Mahesh Chitrao and Ralph Grishman.
Sta-tistical parsing of messages.
In Proceedingsof the Speech and Natural Language Work-shop, pages 263--266, Hidden Valley, PA,June 1990.
Morgan Kaufmann.\[3\] J. K. Baker.
Trainable grammars for speechrecognition.
In D. H. Klatt and J. J. Wolf,editors, Speech Communication Papers forthe 97th Meeting of the Acoustic Society ofAmerica, 1979.\[4\] Beth Sundheim.
Third message under-standing evaluation and conference (MUC-3): t'hase 1 statns report.
In Proceedings ofthe Speech and Natural Language Workshop,pages 301-305, Pacific Grove, CA, 1,'ebruary1991.
Morgan Kaufmann.\[5\] Ezra Black, Steven Abney, Dan Flickenger,Claudia Gdaniec, Ralph Grishman, Philiptlarrison, Donald Hindle, Robert Ingria,Fred Jelinek, Judith Klavans, Mark Liber-man, Mitch Marcus, Salim Roukos, BeatriceSantorini, and Tomek Strzalkowski.
A pro-cedure for quantitatively comparing the syn-tactic coverage of English.
In Proceedings ofthe Speech and Natural Language Workshop,pages 306-311, Pacitic Grove, CA, February1991.
Morgan Kaufinann.\[6\] Philip tlarrison, Steven Abney, Ezr,~ Black,Dan Flickinger, Claudia Gdaniec, RalphGrishman, Donald ltindle, Robert lngria,Mitch Marcus, Beatrice Santorini, andToiuek Strzalkowski.
Evaluating syntaxperformance of parser/grammars.
In Pra-ceedings of the Natural Language Process-ing Systems Evaluation Workshop, Berke-ley, CA, June 1991.
To be published as aRome Laboratory Technical Report.\[7\] Ralph Grishman, Catherine Macleod, andJohn Sterling.
Evaluating parsing strate-gies using standardized parse files.
In Proe.Third Conf.
on Applied Natural LanguageProcessing, Treuto, Italy, April 1992.\[8\] William Gale and Kenneth Church.
Poorestimates of context are worse than none.In Proceedings of the Speech and NaturalLanguage Workshop, pages 283 287, tliddenValley, PA, June 1990.
Morgan Kaufmann.\[9\] R. Grishman, L. Hirschman, and N.T.Nhan.
Discovery procedures for sub-language selectional patterns: Initial ex-periments.
Computational Linguistics,12(3):205-16, 1986.\[10\] Donald IIindle and Mats Rooth.
Structuralambiguity and lexical relations.
In P~aceed~ings of the 29th Annual Meeting of the Assn.for Computational Linguistics, pages 229236, Berkeley, CA, June 1991.\[11\] Paota Velardi, Maria Teresa Pazienza, andMichela Fasolo.
How to encode semanticknowledge: A method for meaning repre-sentation and computer-aided acquisition.Computational Linguistics, 17(2):153-170,1991.\[12\] Frank Smadja.
From n-grams to colloca-tions: An evaluation of xtract.
In Proceed-ings of the 29th Annual Meeting of the Assn.for Computational Linguistics, pages 279--284, Berkeley, CA, June 1991.\[13\] Nicolette Calzolari and Remo Bindi.
Acqui-sition of lexical information from a large tex-tual italian corpus.
In Proc.
13th Int'l Conf.Computational Linguistics (COLING-90),pages 54-59, Iletsinki, Finland, August1990.\[ld\] Uri Zernik, editor.
Lexical Acquisition: Ex-ploiting On-Line Resou~ves to Build a Lex-icon.
Lawrence Erlbaum Assoc., tlillsdale,N J, 1991.AC'Tt~ DE COLING-92.
NANTES, 23-28 AOl~r 1992 6 6 4 PROC.
OF COLING-92, NANTES, AUG. 23-28, 1992
