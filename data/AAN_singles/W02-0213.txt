Dialogue Act Recognition with Bayesian Networks for Dutch DialoguesSimon Keizer, Rieks op den Akker and Anton NijholtDepartment of Computer ScienceUniversity of TwenteP.O.
Box 217, 7500 AE Enschede, The Netherlands{skeizer,infrieks,anijholt}@cs.utwente.nlAbstractThis paper presents work on usingBayesian networks for the dialogue actrecognition module of a dialogue sys-tem for Dutch dialogues.
The Bayesiannetworks can be constructed from thedata in an annotated dialogue corpus.For two series of experiments - usingdifferent corpora but the same anno-tation scheme - recognition results arepresented and evaluated.1 IntroductionIn several papers (Nijholt, 2000; Luin et al, 2001;Nijholt et al, 2001) we reported on our virtualmusic centre - the VMC - a virtual environmentinhabited by (embodied) agents and on multi-modal interaction between human users and theseagents.
Of these agents Karin is an embodiedagent users can ask for information about theatreperformances (see Figure 1).A second agent is the navigation agent.
Nav-igation is a) way finding - the user knows wherehe wants to go but doesn?t know how to go there;or b) exploring the environment - the user walksthrough the environment to obtain an overview ofthe building and the objects, locations, rooms thatare in it.
Related to these navigation tasks the nav-igation assistant has the task to assist the visitorin a) explaining how to go from his current loca-tion to a location he is looking for and b) to givethe agent information about objects, and locationsin the environment.
The navigation agent is notpresent as an avatar in the environment.
The usersees the environment from a first person perspec-tive and interacts with the agents by means of aDutch dialogue.
The user has two views of theenvironment: a) a first person view of the visiblepart of the 3D virtual theatre and b) an abstract2D map of the floor of the building the user isvisiting.
This map is shown in a separate win-dow.
In a multi-modal interaction the user canpoint at locations or objects on the 2D map andeither ask information about that object or loca-tion or he can ask the assistant to bring him to thelocation pointed at.Figure 1: Karin in the VMC.An important part of our dialogue systems fornatural language interaction with agents is themodule for recognition of the dialogue acts per-formed by the human user (visitor).
This pa-per discusses the construction of and experimentswith Bayesian networks as implementation of thismodule.Various other work has been presented on us-ing statistical techniques for dialogue act classi-fication (Andernach, 1996; Stolcke et al, 2000),and even some first efforts on using Bayesian net-works for this task (Pulman, 1996; Keizer, 2001).Other work on using Bayesian networks in dia-logue systems aims more at interaction and usermodelling (Paek and Horvitz, 2000) and does notspecifically involve linguistic aspects.The paper is organised as follows.
Section 2Philadelphia, July 2002, pp.
88-94.
Association for Computational Linguistics.Proceedings of the Third SIGdial Workshop on Discourse and Dialogue,provides some necessary and general backgroundabout the use of Bayesian networks for speech actrecognition.
In Section 3 we discuss experimentswith a Bayesian network for dialogue act classi-fication based on a dialogue corpus for the Karinagent.
In Section 4 we discuss our current ex-periments with a network for the navigation dia-logue system that was automatically created froma small corpus.
Section 5 reflects on our findingsand presents plans for the near future.2 Bayesian Networks and Speech ActRecognitionSince Austin and Searle deliberately producing alinguistic utterance (?locutionary act?)
is perform-ing a speech act (?illocutionary act?).
Many re-searchers have contributed in distinguishing andcategorising types of speech acts we can perform.See (Traum, 2000) for a valuable discussion ondialogue act taxonomies and an extensive bibli-ography.A dialogue system needs a user model.
Thebetter the user model the better the system is ableto understand the user?s intentions from the locu-tionary act.
We consider the human participantin a dialogue as a source of communicative ac-tions.
Actions can be some verbal dialogue actor some non-verbal pointing act (the act of point-ing at some object).
We assume the user is ra-tional: there is a dependency between the actionperformed and the intentional state of the user.
Ifwe restrict to communicative acts that are realizedby uttering (speaking or typing) a sentence wecan model the user by a probability distributionP (U = u|DA = da): the probability that the userproduces an utterance u (the stochastic variable Uhas value u) given that he performs a dialogue actda ( DA has the value da).
Or - maybe better: theconfidence we can have in believing that the useruses utterance u if we know that the dialogue acthe performs is da.
Since there are many distinctwordings u for performing a given dialogue actda and on the other hand there are distinct dia-logue acts that can be performed by the same ut-terance, we need more than superficial linguisticinformation to decide upon the intended dialogueact given an utterance.
The task of the dialogueact recognition (DAR) module of a dialogue sys-tem is to answer the question: what is the mostlikely dialogue act da intended by the user giventhe system has observed the utterance u in a dia-logue context c. (Notice that we have equated theutterance produced by the user with the utterancerecognised by the system: there is no informationloss between the module that records the utter-ance and the input of the dialogue act recognitionmodule.
)To make this problem tractable we further re-strict the model by assuming that a) the user en-gaged in a dialogue can only have the intentionto perform one of a finite number of possible di-alogue acts; b) each of the possible natural lan-guage utterances u produced by the user and ob-served by the system can be represented by a fi-nite number of feature value pairs (fi = vi); andc) the dialogue context can be represented by afinite number of feature value pairs (gi = ci).Given these restrictions the DAR problem be-comes to find that value da of DA that maximisesP ( DA = da | f1 = v1, .
.
.
, fn = vn,g1 = c1, .
.
.
, gm = cm ).For the probabilistic model from which this canbe computed we use a Bayesian network (Pearl,1988).
A Bayesian network is a directed acyclicgraph in which the nodes represent the stochasticvariables considered, while the structure (givenby the arcs between the nodes) constitutes a setof conditional independencies among these vari-ables: a variable is conditionally independent ofits non-descendants in the network, given its par-ents in the network.
Consider the network in Fig-ure 2: it contains one node representing the di-alogue act (DA), 3 nodes representing utterancefeatures (NumWrds, CanYou and IWant) anda node representing a context feature (PrevDA).From the network structure follows that for ex-ample variable DA is conditionally independentof variable NumWrds, given variable CanYou.The conditional independencies make themodel computationally more feasible: finding aspecification of the joint probability distribution(jpd) for the model reduces to finding the condi-tional probability distributions of each of the vari-ables given their network parents.
In our examplenetwork, the following jpd specification holds:P (DA, NumWrds,CanYou, IWant,PrevDA) =P (IWant) ?
P (PrevDA|DA) ?
P (CanYou) ?DAPrevDAIWantCanYouNumWrdsFigure 2: A Bayesian Network for Dialogue ActRecognition.?
P (DA|CanYou, IWant) ??
P (NumWrds|CanYou,PrevDA)The construction of a Bayesian network henceamounts to choosing a network structure (the con-ditional independencies) and choosing the condi-tional probability distributions.
In practice, theprobabilities will have to be assessed from em-pirical data by using statistical techniques.
Thestructure can generated from data too, but anotheroption is to choose it manually: the arcs in thenetwork can be chosen, based on the intuition thatthey represent a causal or temporal relationshipbetween two variables.
Strictly spoken however,a Bayesian network only represents informationalrelationships between variables.Notice that the machine learning techniqueknown as Naive Bayes Classifier (see for instance(Mitchell, 1997)) assumes that all variables areconditionally independent of each other giventhe variable that has to be classified.
A NaiveBayes classifier can be seen as a special case ofa Bayesian network classifier, where the networkstructure consists of arcs from the class variableto all variables representing the features: see Fig-ure 3.DAIWant CanYou NumWrdsPrevDAFigure 3: Naive Bayes classifier as Bayesian Net-work.Naive Bayes classifiers will perform as goodas the Bayesian network technique only if indeedall feature variables are conditionally indepen-dent, given the class variable.
The problem isof course how do we know that they are condi-tionally independent?
If we don?t have completeanalytical knowledge about the (in)dependencies,only analysing the data can give an answer to thisquestion.
The advantage of using Bayesian net-works is that methods exist to construct the net-work structure as well as the conditional proba-bilities.
Moreover Bayesian networks are moreflexible in their use: unlike Bayesian classifierswe can retrieve the posterior probabilities of allthe network variables without re-computation ofthe model.
The same advantage do Bayesian net-works have over Decision Tree learning methodslike C4.5 that output a decision tree for classi-fying instances with respect to a given selectedclass variable.
Experiments have shown thatNaive Bayesian classifiers give results that are asgood as or even better than those obtained bydecision tree classification techniques.
Hence,there are theoretical as well as practical reasonsto use Bayesian networks.
However, since thereis hardly any experience in using Bayesian net-works for dialogue act classification we have todo experiments to see whether this technique alsoperforms better than the alternatives mentionedabove for this particular application.The next two sections describe experimentswith 1) the SCHISMA corpus - elaborating on pre-vious work described in (Keizer, 2001) - and 2) apreliminary small corpus of navigation dialogues.We motivate our choice of dialogue acts and fea-tures and present some first results in training aBayesian network and testing its performance.3 Experiments with the Schisma corpus3.1 Dialogue acts and featuresThe current dialogue system for interacting withKarin is based on analyses of the SCHISMA cor-pus.
This is a corpus of 64 dialogues, obtainedthrough Wizard of Oz experiments.
The interac-tion between the wizard - a human simulating thesystem to be developed - and the human user wasestablished through keyboard-entered utterances,so the dialogues are textual.
The task at handis information exchange and transaction: usersare enabled to make inquiries about theatre per-formances scheduled and if desired, make ticketreservations.We have manually annotated 20 dialoguesfrom the SCHISMA corpus, using two layersof the DAMSL multi-layer annotation scheme(Allen and Core, 1997), a standard for annotat-ing task-oriented dialogues in general.
The layerof Forward-looking Functions contains acts thatcharacterise the effect an utterance has on thesubsequent dialogue, while acts on the layer ofBackward-looking Functions indicate how an ut-terance relates to the previous dialogue.
BecauseDAMSL does not provide a refined set of dia-logue acts concerning information-exchange, wehave added some new dialogue acts.
For example,ref-question, if-question and alts-question were added as acts that further spec-ify the existing info-request.For the experiments, we selected a subset offorward- and backward-looking functions fromthe hierarchy that we judged as the most impor-tant ones to recognise: those are listed in Table1.
In Figure 4, a fragment of an example dia-logue between S (the server) and C (the client) isgiven, in which we have indicated what forward-and backward-looking functions were performedin each utterance.Forward-lookingFunctionsassertopen-optionrequestref-questionif-questionalts-questionaction-directiveoffercommitconventionalexpressiveotherffBackward-lookingFunctionsacceptapproverejectdisapproveholdacknowledgenot-understoodpositive answernegative answerfeedbackotherbfTable 1: Dialogue Acts for SCHISMA.The user utterances have also been tagged man-ually with linguistic features.
We have distin-guished the features in Table 2, assuming they canbe provided for by a linguistic parser.The dialogue context features selected includethe backward-looking function of the last systemutterance and the forward-looking function of theprevious user utterance.
In the experiment withS: Hello, how can I help you?conventionalC: When can I see Herman Finkers?ref-question; otherbfS: On Saturday the 12th at 20h.assert; pos-answerC: I would like 2 tickets please.action-directive; otherbfS: Do you have a discount card?if-question; hold.
.
.Figure 4: Dialogue fragment with forward- andbackward-looking functions.Sentence Typedeclarativeyn-questionwh-questionimperativenoun phraseadverbialadjectivenumberinterjectivecontinuationSubject Typefirst personsecond personthird personPunctuationperiodquestion markexclam.
markcommanoneTable 2: Utterance features for SCHISMA.the SCHISMA dialogues we have constructed anetwork structure (see Figure 5) by hand and thenused the data of the annotated dialogues to trainthe required conditional probabilities.PBFSFFCSeTpSuTpPunctPFFCFigure 5: Bayesian network for DAR to be trainedwith the SCHISMA dialogues.The choice of structure is based on the in-tuition that the model reflects how a client de-cides which communicative action to take; al-though the arcs themselves have no explicitmeaning - they only contribute to the set ofconditional independencies - they can be seenhere as a kind of temporal or causal relation-ships between the variables (as mentioned ear-lier in Section 2): given the dialogue context -defined by the previous forward-looking functionof the client (PFFC) and the previous backward-looking function of the server (PBFS), the clientdecides which forward-looking function to per-form (FFC); from this decision he/she formulatesa natural language utterance with certain featuresincluding the sentence type (SeTp) the subjecttype (SuTp) and punctuation (Punct).Recalling the notion of conditional indepen-dence in Bayesian networks described in Section2, it follows that by choosing the network struc-ture of Figure 5, we have made the (admittedly,disputable) assumption that, given the forward-looking function of the client, the three utterancefeatures are conditionally independent of eachother.3.2 Results and evaluationFor assessing the conditional probability distribu-tions, we have used the Maximum A Posteriori(MAP) learning technique - see e.g.
(Heckerman,1999).
For training we have used 330 data sam-ples which is 75% of the available data; the re-maining samples have been used for testing.
Wehave measured the performance of the networkin terms of the accuracy of estimating the cor-rect forward-looking function for different casesof available evidence, varying from having no ev-idence at all to having evidence on all features.This resulted in an average accuracy of 43.5%.Adding complete evidence to the network for ev-ery test sample resulted in 38.7% accuracy.As the amount of data from the SCHISMA cor-pus currently available is rather small, the resultscannot expected to be very good and more datahave to be collected for further experiments.
Still,the testing results show that the accuracy is signif-icantly better than an expected accuracy of 8.3%in the case of guessing the dialogue act randomly.A tighter baseline commonly used is the relativefrequency of the most frequent dialogue act.
Forthe data used here, this gives a baseline of 32.5%,which is still less than our network?s accuracy.4 Experiments with the navigationcorpus4.1 Dialogue acts and featuresA small corpus of dialogues was derived from thefirst implementation of a dialogue system for in-teraction with the navigation agent.
For the ex-periments with the navigation corpus we also usethe DAMSL layers of Forward- and Backward-looking functions.
On each of these two lay-ers we only distinguish dialogue acts on the firstlevel of the hierarchies (see Table 3 for the di-alogue acts used); a more refined subcategorisa-tion should be performed by a second step in theDAR module.
The dialogue acts in Table 1 canbe found at the deeper levels of the DAMSL hi-erarchy, e.g.
a request is a special case of ainfl addr fut act and an acknowledgeis a special case of an understanding.
Thedialogue act recogniser may also use more ap-plication specific knowledge in further identifi-cation of the user intention.
Information thatmay be used is dialogue information concerningtopic/focus.Forward-lookingFunctionsstatementinfl addr fut actinfo requestcomm sp fut actconventionalexpl performativeexclamationBackward-lookingFunctionsagreementunderstandinganswerTable 3: Dialogue Acts for Navigation.For the navigation dialogues, we have chosena set of surface features of what will eventuallybe spoken utterances, in contrast to the typed di-alogues in the SCHISMA corpus.
Therefore, wedon?t use a textual feature like punctuation.
Foreach utterance, the feature values are found au-tomatically using a tagger (the features in theSCHISMA dialogues were tagged manually).
InTable 4 we have listed the features with their pos-sible values we initially consider relevant.The dialogue context features include thebackward- and forward-looking function of theprevious dialogue act.
This is always a dialogueact performed by the system.
The possible dia-logue acts performed by the system are the sameas those performed by the user.The network is generated from data that wereobtained by manually annotating the user ut-terances in the navigation corpus following theDAMSL instructions as close as possible.
Aswith every categorisation there are problematicFeatures Valueslenq one, few, manyiswh true, falsenot in prev true, falsestartsWithCanYou true, falsestartsWithCanI true, falsestartsWithIWant true, falsecontainsPositive true, falsecontainsNegative true, falsecontainsOkay true, falsecontainsLocativePrep true, falsecontainsLocativeAdverb true, falsecontainsTell true, falsecontainsDo true, falseTable 4: Surface features of user utterances andtheir possible values.border cases, e.g.
when to annotate with in-direct speech acts.
We used the criterion thatsuch an act should be recognised without task-specific considerations.
Therefore the utterance?I want to make a phone-call?
is annotated as astatement although eventually it should be in-terpreted as an info request (?where can Ifind a phone??)
in the context of a navigation di-alogue.After the dialogue act has been recognised thenavigation agent will make a plan for further ac-tions and perform the planned actions.
We willnot discuss that here.4.2 Results and evaluationIn this experiment the data are used for learningboth structure and conditional probabilities of aBayesian network.
We have used an implementa-tion of the K2 algorithm (Cooper and Herskovits,1992) to generate the network structure and then- like in the SCHISMA experiment - used MAP toassess the conditional probability distributions.Starting from the small corpus of navigationdialogues, a procedure has been planned to iter-atively enlarge the corpus: given the annotatedcorpus, derive a network, use the network in adialogue system, test the network and add thesedialogues - with the corrected backward- andforward-looking functions - to the corpus.
Thisresults in a more extended set of annotated dia-logues.
And we start again.
After each of thecycles we compare the results (in terms of accu-racies) with the results of the previous cycle.
Thisshould give more insight in the usefulness of thefeatures and values chosen for the Bayesian net-work.
After deciding to adapt the set of featureswe automatically annotate the corpus; we derivea new network and we test again.The current corpus is too small to expect goodresults from a generated network, especially if thedata are used for learning both the structure andthe probability distributions.
From the initial cor-pus of 81 utterances 75% was used for generatinga Bayesian network.
Testing on the remaining25% resulted in accuracy of 57.1% for classify-ing the forward-looking function and 81.0% forclassifying the backward-looking function.
Af-ter this first cycle, new data have been generatedinteractively, following the procedure describedabove.
The Bayesian network trained from thisnew data set resulted in the improved accuraciesof 76.5% and 88.2% for classifying the forward-and backward-looking function respectively.
Fol-lowing this training and testing procedure, wehope to develop Bayesian networks with increas-ing performance.5 Discussion and conclusionsIn this paper we have discussed the use ofBayesian networks for dialogue act recognition ina natural language dialogue system.
We have de-scribed the construction of such networks fromdata in two cases: 1) using annotated dialoguesfrom the SCHISMA corpus - information ex-change and transaction - and 2) using a small cor-pus of annotated navigation dialogues.As the amount of data currently available israther small (especially the navigation corpus),the network performances measured are not tooimpressive.
In order to get more data, we have de-veloped a testing environment which at the sametime enables us to enlarge the corpus.
With theincreasing amount of data we hope to constructBayesian networks with increasing performance.As for the SCHISMA corpus, there are 44 dia-logues that remain to be annotated, also resultingin more data.One of the first and most important questionsto be answered concerns the selection of a set offeatures (and their values) that set up the model.We started with a set of features selected on in-tuition.
Then the dialogue corpus was annotated.As a result of experiments we may conclude thatsome of the features have no selective value, sowe can leave them out of the model.In the future we would like to compare theapproach of using Bayesian networks with otherclassifiers that can also be constructed from data,e.g.
decision trees or Bayesian classifiers.
Figure5 shows the accuracies of three different classi-fiers that were generated from the current set ofnavigation data.Class Bayesian Decision Naivevariable network tree Bayesforw funct 76.5% 50.0% 55.9%backw funct 88.2% 64.7% 61.8%Table 5: Accuracies of three different classi-fiers for classifying the forward-looking func-tion (forw funct) and backward-looking function(backw funct), where all classifiers have beenbuilt from the same set of navigation data.In our future experiments we will take into ac-count more refined performance measures likeprecision and recall and confusion matrices inwhich classification results for individual dia-logue act types are shown.
Such results can helpus make decisions w.r.t.
the selected dialogue acttypes and features.Furthermore, non-verbal communicative ac-tions like pointing at objects in the virtual envi-ronment could be relevant in recognising dialogacts and should therefore be made available aspossible features in our Bayesian network clas-sifiers.AcknowledgementWe would like to thank the referees for their com-ments on our paper; these have been very usefulto us in preparing this final version.ReferencesJ.
Allen and M. Core.
1997.
Draft ofDAMSL: Dialog Act Markup in Several Lay-ers.
URL: http://www.cs.rochester.edu/research/trains/annotation.T.
Andernach.
1996.
A machine learning approach tothe classification and prediction of dialogue utter-ances.
In Proceedings of the Second InternationalConference on New Methods in Language Process-ing (NeMLaP-2), pages 98?109, Ankara, Turkey.G.
F. Cooper and E. Herskovits.
1992.
A Bayesianmethod for the induction of probabilistic networksfrom data.
Machine Learning, 9:309?347.D.
Heckerman.
1999.
A tutorial on learning withBayesian networks.
In M. Jordan, editor, Learningin Graphical Models.
MIT Press, Cambridge MA.S.
Keizer.
2001.
A Bayesian approach to dialogueact classification.
In P. Ku?hnlein, H. Rieser, andH.
Zeevat, editors, BI-DIALOG 2001: Proc.
of the5th Workshop on Formal Semantics and Pragmaticsof Dialogue, pages 210?218.J.
van Luin, R. op den Akker, and A. Nijholt.
2001.A dialogue agent for navigation support in virtualreality.
In J. Jacko and A. Sears, editors, ACMSIGCHI Conf.
CHI 2001: Anyone.
Anywhere, pages117?118, Seattle.
Association for Computing Ma-chinery.T.M.
Mitchell.
1997.
Machine Learning.
ComputerScience Series.
McGraw-Hill.A.
Nijholt, J. Zwiers, and B. van Dijk.
2001.
Maps,agents and dialogue for exploring a virtual world.In N. Callaos, S. Long, and M. Loutfi, editors, 5thWorld Multiconference on Systemics, Cyberneticsand Informatics (SCI 2001), volume VII of HumanInformation and Education Systems, pages 94?99,Orlando, July.A.
Nijholt.
2000.
Multimodal interactions withagents in virtual worlds.
In N. Kasabov, editor,Future Directions for Intelligent Systems and Infor-mation Science, Physica-Verlag: Studies in Fuzzi-ness and Soft Computing, chapter 8, pages 148?173.
Springer.T.
Paek and E. Horvitz.
2000.
Conversation as actionunder uncertainty.
In 16th Conference on Uncer-tainty in Artificial Intelligence (UAI-2000), pages455?464, San Francisco, CA, June.
Morgan Kauf-mann Publishers.J.
Pearl.
1988.
Probabilistic Reasoning in IntelligentSystems: Networks of Plausible Inference.
MorganKaufmann.S.G.
Pulman.
1996.
Conversational games, belief re-vision and Bayesian networks.
In J. Landsbergen,J.
Odijk, K. van Deemter, and G. Veldhuijzen vanZanten, editors, Computational Linguistics in theNetherlands.A.
Stolcke et al 2000.
Dialogue act modelling for au-tomatic tagging and recognition of conversationalspeech.
Computational Linguistics, 26(3):339?374.D.R.
Traum.
2000.
20 questions on dialogue act tax-onomies.
Journal of Semantics, 17(1):7?30.
