Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 605?615,Edinburgh, Scotland, UK, July 27?31, 2011. c?2011 Association for Computational LinguisticsNon-parametric Bayesian Segmentation of Japanese Noun PhrasesYugo Murawaki and Sadao KurohashiGraduate School of InformaticsKyoto University{murawaki, kuro}@i.kyoto-u.ac.jpAbstractA key factor of high quality word segmenta-tion for Japanese is a high-coverage dictio-nary, but it is costly to manually build sucha lexical resource.
Although external lexicalresources for human readers are potentiallygood knowledge sources, they have not beenutilized due to differences in segmentation cri-teria.
To supplement a morphological dictio-nary with these resources, we propose a newtask of Japanese noun phrase segmentation.We apply non-parametric Bayesian languagemodels to segment each noun phrase in theseresources according to the statistical behaviorof its supposed constituents in text.
For in-ference, we propose a novel block samplingprocedure named hybrid type-based sampling,which has the ability to directly escape a lo-cal optimum that is not too distant from theglobal optimum.
Experiments show that theproposed method efficiently corrects the initialsegmentation given by a morphological ana-lyzer.1 IntroductionWord segmentation is the first step of natural lan-guage processing for Japanese, Chinese and Thaibecause they do not delimit words by white-space.Segmentation for Japanese is a successful field of re-search, achieving the F-score of nearly 99% (Kudoet al, 2004).
This success rests on a high-coveragedictionary.
Unknown words, or words not coveredby the dictionary, are often misidentified.Historically, researchers have devoted exten-sive human resources to build and maintain high-coverage dictionaries (Yokoi, 1995).
Since the or-thography of Japanese does not specify a standardfor segmentation, researchers define their own crite-ria before constructing lexical resources.
For thisreason, it is difficult to exploit existing externalresources, such as dictionaries and encyclopediasfor human readers, where entry words are not seg-mented according to the criteria.
Among them,encyclopedias are especially important in that theycontain a lot of terms that a morphological dictio-nary fails to cover.
Most of these terms are nounphrases and consist of more than one word (mor-pheme).
For example, an encyclopedia has an en-try ?????
(tsuneyama-jou, ?Tsuneyama Castle?
).According to our segmentation criteria, it consistsof two words ????
(tsuneyama) and ???
(jou).However, the morphological analyzer wrongly seg-ments it into ???
(tsune) and ????
(yamashiro)because ????
(tsuneyama) is an unknown word.In this paper, we present the first attempt to uti-lize encyclopedias for word segmentation.
We seg-ment each entry noun phrase into words.
To do this,we examine the main text of the entry, on the as-sumption that if the noun phrase in question con-sists of more than one word, its constituents appearin the main text either freely or as part of othernoun phrases.
For ?????
(tsuneyama-jou), itsconstituent ????
(tsune) appears by itself and asconstituents of other nouns phrases such as ??????
(peak of Tsuneyama) and ?????
(TsuneyamaStation) while ????
(yamashiro) does not.To segment each noun phrase, we use non-parametric Bayesian language models (Goldwater etal., 2009; Mochihashi et al, 2009).
Our approach605is based on two key factors: the bigram model andtype-based block sampling.
The bigram model al-leviates a problem of the unigram model, that is, atendency to misidentify a sequence of words in com-mon collocations as a single word.
Type-based sam-pling (Liang et al, 2010) has the ability to directlyescape a local optimum, making inference very ef-ficient.
However, type-based sampling is not easilyapplicable to the bigrammodel owing to sparsity andits dependence on latent assignments.We propose a hybrid type-based sampling proce-dure, which combines the Metropolis-Hastings al-gorithm with Gibbs sampling.
We circumvent thesparsity problem by joint sampling of unigram-leveltype.
Also, instead of calculating the probability ofevery possible state of the jointly sampled randomvariables, we only compare the current state witha proposed state.
This greatly eases the samplingprocedure while retaining the efficiency of type-based sampling.
Experiments show that the pro-posed method quickly corrects the initial segmen-tation given by a morphological analyzer.2 Related WorkJapanese Morphological Analysis and LexicalAcquisition Word segmentation for Japanese isusually solved as the joint task of segmentation andpart-of-speech tagging, which is called morpholog-ical analysis (Kurohashi et al, 1994; Asahara andMatsumoto, 2000; Kudo et al, 2004).
The stan-dard approach in Japanese morphological analysisis lattice-based path selection instead of character-based IOB tagging.
Given a sentence, an analyzerfirst builds a lattice of words with dictionary look-upand then selects an optimal path using pre-definedparameters.
This approach enables fast decodingand achieves accuracy high enough for practical use.This success, however, depends on a high-coverage dictionary, and unknown words are oftenmisidentified.
Although a line of research attemptsto identify unknown words on the fly (Uchimoto etal., 2001; Asahara and Matsumoto, 2004), it by nomeans provides a definitive solution because it suf-fers from locality of contextual information avail-able for identification (Nakagawa and Matsumoto,2006).
Therefore we like to perform separate lexicalacquisition processes in which wider context can beexamined.Our approach in this paper has a complementaryrelationship with unknown word acquisition fromtext, which we previously proposed (Murawaki andKurohashi, 2008).
Since, unlike Chinese and Thai,Japanese is rich in morphology, morphological reg-ularity can be used to determine if an unknownword candidate in text is indeed the word to be ac-quired.
In general, this method works pretty well,but one exception is noun phrases.
Noun phrasescan hardly be distinguished from single nouns be-cause in Japanese, no morphological marker is at-tached to join nouns to form a noun phrase.
Wepreviously resort to a heuristic measure to segmentnoun phrases.
The new statistical method provides astraightforward solution to this problem.Meanwhile, our language models have their ownproblem.
The assumption that language is a se-quence of invariant words fails to capture rich mor-phology, as our segmentation criteria specify thateach verb or adjective consists of an invariant stemand an ending that changes its form according toits grammatical roles.
For this reason, we limit ourscope to noun phrases in this paper.Use of Noun Phrases Named entity recogni-tion (NER) is a field where encyclopedic knowl-edge plays an important role.
Kazama and Tori-sawa (2008) encode information extracted from agazetteer (e.g.
Wikipedia) as features of a CRF-based Japanese NE tagger.
They formalize the NERtask as the character-based labeling of IOB tags.Noun phrases extracted from a gazetteer are alsostraightforwardly represented as IOB tags.
How-ever, this does not fully solve the knowledge bot-tleneck problem.
They also used the output of amorphological analyzer, which does not utilize en-cyclopedic knowledge.
NER performance may beaffected by segmentation errors in morphologicalanalysis involving unknown words.Chinese word segmentation is often formalized asa character tagging problem (Xue, 2003).
In thissetting, it is easy to incorporate external resourcesinto the model.
Low et al (2005) introduce an exter-nal dictionary as features of a discriminative model.However, they only use words up to 4 characters inlength.
We conjecture that words in their dictionaryare not noun phrases.
External resources used by606Peng et al (2004) are also lists of short words andcharacters.Non-parametric Language Models Non-parametric Bayesian statistics offers an elegantsolution to the task of unsupervised word segmen-tation, in which the vocabulary size is not known inadvance (Goldwater et al, 2009; Mochihashi et al,2009).
It does not compete with supervised segmen-tation, however.
Unsupervised word segmentationis used elsewhere, for example, with theoreticalinterest in children?s language acquisition (Johnson,2008; Johnson and Demuth, 2010) and with theapplication to statistical machine translation, inwhich segmented text is merely an intermediate rep-resentation (Xu et al, 2008; Nguyen et al, 2010).In this paper we demonstrate that non-parametricmodels can complement supervised segmentation.3 Japanese Noun Phrase SegmentationOur goal is to overcome the unknown word prob-lem in morphological analysis by utilizing existingresources such as dictionaries and encyclopedias forhuman readers.
In our settings, we are given a list ofentries from external resources.
Almost all of themare noun phrases and each entry consists of one ormore words.A na?
?ve implementation would be to use nounphrases as they are.
In fact, ipadic1 regards as singlewords a large number of long proper nouns like ?????????????
(literally, Kansai Interna-tional Airport Company Connecting Bridge).
How-ever, this approach has various drawbacks.
For ex-ample, in information retrieval, the query ?KansaiInternational Airport?
does not match the ?single?word for the bridge.
So we apply segmentation.Each entry is associated with text, which is usu-ally the main text of the entry.2 We assume the textas the key to segmenting the noun phrase.
If thenoun phrase in question consists of more than oneword, its constituents would appear in the text eitherfreely or as part of other noun phrases.We obtain the segmentation of an entry nounphrase by considering the segmentation of the whole1http://sourceforge.jp/projects/ipadic/2We may augment the text with related documents if themain text is not large enough.text.
One may instead consider a pipeline ap-proach in which we first extract noun phrases intext and then identify boundaries within these nounphrases.
However, noun phrases in text are not triv-ially identifiable in the case that they contain un-known words as their constituents.
For example,the analyzer erroneously segments the word ???????
(chiNsukou) into ????
(chiN) and ?????
(sukou), and since the latter is misidentified asa verb, the incorrect noun phrase ????
(chiN) isextracted.We have a morphological analyzer with a dictio-nary that covers frequent words.
Although it oftenmisidentifies unknown words, the overall accuracyis reasonably high.
For this reason, we like to usethe segmentation given by the analyzer as the ini-tial state and to make small changes to them to geta desired output.
We also use an annotated corpus,which was used to build the analyzer.
As the an-notated corpus encodes our segmentation criteria, itcan be used to force the models to stick with oursegmentation criteria.We concentrate on segmentation in this paper, butwe also need to assign a POS tag to each constituentword and to incorporate segmented noun phrasesinto the dictionary of the morphological analyzer.We leave them for future work.34 Non-parametric Bayesian LanguageModelsTo correct the initial segmentation given by the an-alyzer, we use non-parametric Bayesian languagemodels that have been applied to unsupervised wordsegmentation (Goldwater et al, 2009).
Specifically,we adopt unigram and bigram models.
We proposea small modification to these models in order to ex-ploit an annotated corpus when it is much larger thanraw text.4.1 Unigram ModelIn the unigram model, a word in the corpus wi isgenerated as follows:G|?0, P0 ?
DP(?0, P0)wi|G ?
G3Fortunately, the morphological analyzer JUMAN is capa-ble of handling phrases, each of which consists of more thanone word.
All we need to do is POS tagging.607where G is a distribution over a countably infiniteset of words, and DP(?0, P0) is a Dirichlet pro-cess (Ferguson, 1973) with the concentration param-eter ?0 and the base distribution P0, for which weuse a zerogram model described in Section 4.3.Marginalizing out G, we can interpret the modelas a Chinese restaurant process.
Suppose that wehave observed i ?
1 words w?i = w1, ?
?
?
, wi?1,the probability of wi is given byP1(wi = w|w?i) =nw?iw + ?0P0i?
1 + ?0, (1)where nw?iw is the number of word label w observedin w?i.The unigram model is known for its tendency tomisidentify a sequence of words in common collo-cations as a single word (Goldwater et al, 2009).
Inpreliminary experiments, we found that the unigrammodel often interpreted a noun phrase as a singleword, even in the case that its constituents frequentlyappeared in text.4.2 Bigram ModelThe problem of the unigram model can be alleviatedby the bigram model based on a hierarchical Dirich-let process (Goldwater et al, 2009).
In the bigrammodel, word wi is generated as follows:G|?0, P0 ?
DP(?0, P0)Hl|?1, G ?
DP(?1, G)wi|wi?1 = l,Hl ?
HlMarginalizing out G and Hl, we can again explainthe model with the Chinese restaurant process.
Un-like the unigram model, however, the bigram modeldepends on the latent table assignments z?i.P2(wi|h?i) =nh?i(wi?1,wi) + ?1P1(wi|h?i)nh?i(wi?1,?)
+ ?1(2)P1(wi|h?i) =th?iwi + ?0P0(wi)th?i?
+ ?0(3)where h?i = (w?i, z?i), th?iwi is the number of ta-bles labeled with wi and th?i?
is the total number oftables.
Thanks to exchangeability, we do not need totrack the exact seating assignments.
Still, we need tomaintain a histogram for each w that consists of fre-quencies of table customers (Blunsom et al, 2009).4.3 Zerogram ModelFollowing Nagata (1996) and Mochihashi et al(2009), we model the zerogram distribution P0 withthe word length k and the character sequence w =c1, ?
?
?
, ck.
Specifically, we define P0 as the combi-nation of a Poisson distribution with mean ?
and abigram distribution over characters.P0(w) = P (k;?
)P (c1, ?
?
?
, ck, k|?
)P (k|?
)P (k;?)
= e??
?kk!P (c1, ?
?
?
, ck, k|?)
=k+1?i=1P (ci|ci?1)?
is the zerogrammodel, and c0 and ck+1 are a wordboundary marker.
P (k|?)
can be estimated by ran-domly generating words from the model.
We usedifferent ?
for different scripts.
The Japanese writ-ing system uses several scripts, and each word canbe classified by script such as hiragana, katakana,kanji, the mixture of hiragana and kanji, etc.
The op-timal value for ?
depends on scripts.
For example,katakana, which predominantly denotes loan words,is longer on average than hiragana, which is oftenused for short function words.We obtain the parameters and counts from an an-notated corpus and fix them during noun phrase seg-mentation.
This greatly simplifies inference but maymake the model fragile with unknown words.
Forthis reason, we set a hierarchical Pitman-Yor processprior (Teh, 2006; Goldwater et al, 2006) for the bi-gram probability P (ci|ci?1) with the base distribu-tion of character unigrams.
Note that even characterbigrams are sparse because thousands of charactersare used in Japanese.4.4 Mixing an Annotated CorpusAn annotated corpus can be used to force the mod-els to stick with our segmentation criteria.
Astraightforward way to do this is to mix it withraw text while fixing the segmentation during infer-ence (Mochihashi et al, 2009).
A word found inthe annotated corpus is generally preferred becauseit has fixed counts obtained from the annotated cor-pus.
We call this method direct mixing.Direct mixing is problematic when raw text ismuch smaller than the annotated corpus.
With this608situation, the role of raw text associated with thenoun phrase in question is marginalized by the an-notated corpus.As a solution to this problem, we propose anothermixing method called back-off mixing.
In back-offmixing, the annotated corpus is used as part of thebase distribution.
In the unigram model, P0 in (1) isreplaced byPBM0 = ?IPP0 + (1?
?IP)PREF1 ,where ?IP is a parameter for linear interpolation andPREF1 is the unigram probability obtained from theannotated text.
The loose coupling makes the mod-els robust to an imbalanced pair of texts.
Similarly,the back-off mixing bigram model replaces P1 in (2)withPBM1 = ?IPP1 + (1?
?IP)PREF2 .5 InferenceCollapsed Gibbs sampling is widely used to findan optimal segmentation (Goldwater et al, 2009).In this section, we first show that simple collapsedsampling can hardly escape the initial segmentation.To address this problem, we apply a block sam-pling algorithm named type-based sampling (Lianget al, 2010) to the unigram model.
Since type-basedsampling is not applicable to the bigram model, wepropose a novel sampling procedure for the bigrammodel, which we call hybrid type-based sampling.5.1 Collapsed SamplingIn collapsed Gibbs sampling, the sampler repeatedlysamples every possible boundary position, condi-tioned on the current state of the rest of the corpus.It stochastically decides whether the correspondinglocal area consists of a single word w1 or two wordsw2w3 (w1 = w2.w3).
The conditional probabilitiescan be derived from (1).Collapsed sampling is known for slow conver-gence.
This property is especially problematic inour settings where the initial segmentation is givenby a morphological analyzer.
Since the analyzer de-terministically segments text using pre-defined pa-rameters, the resultant segmentation is fairly consis-tent.
Segmentation errors involving unknown wordsalso occur in a regular way.
Intuitively, we start witha local optimum although it is not too distant fromthe global optimum.
The collapsed Gibbs sampler iseasily entrapped by this local optimum.
For this rea-son, the initial segmentation is usually chosen at ran-dom (Goldwater et al, 2009).
Sentence-based blocksampling is also susceptible to consistent initializa-tion (Liang et al, 2010).5.2 Type-based SamplingTo achieve fast convergence, we adopt a block sam-pling algorithm named type-based sampling (Lianget al, 2010).
For the unigram model, a type-basedsampler jointly samples multiple positions that sharethe same type.
Two positions have the same typeif the corresponding areas are both of the form w1or w2w3.
Type-based sampling takes advantage ofthe exchangeability of multiple positions with thesame type.
Given n positions with the same type,the sampler first samples the number of new bound-aries m?
(0 ?
m?
?
n), and then uniformly arrangesm?
boundaries out of n positions.Type-based sampling has the ability to jump froma local optimum (e.g.
consistently segmented) to an-other stable state (consistently unsegmented).
WhileLiang et al (2010) used random initialization, wetake particular note of the possibility of efficientlycorrecting the consistent segmentation by the ana-lyzer.Type-based sampling is, however, not applicableto the bigram model for two reasons.
The first prob-lem is sparsity.
For the bigram model, we need toconsider adjacent words, wl on the left and wr onthe right.
This means that each type consists ofthree or four words, wlw1wr or wlw2w3wr.
Con-sequently, few positions share the same type andwe fail to change closely-related areas wl?w1wr?
andwl?w2w3wr?
, making inference inefficient.The second and more fundamental problem arisesfrom the hierarchical settings.
Since the bigrammodel depends on latent table assignments, the jointdistribution of multiple positions is no longer aclosed-form function of counts.Strictly speaking, we need to update the modelcounts even when sampling one position becausethe observation of the bigram ?wlw1?, for exam-ple, may affect the probability P2(w2|h?, ?wlw1?
).Goldwater et al (2009) approximate the probabilityby not updating the model counts in collapsed Gibbs609sampling (i.e.
P2(w2|h?, ?wlw1?)
?
P2(w2|h?
)).They rely on the assumption that repeated bigramsare rare.
Obviously this does not hold true for type-based sampling.
Hence for type-based sampling, wehave to update the model counts whenever we ob-serve a new word.One way to obtain the joint probability is to ex-plicitly simulate the updates of histograms and othermodel counts.
This is very cumbersome as we needto simulate n+ 1 ways of model updates.5.3 Hybrid Type-based SamplingTo address these problems, we propose a hybridsampler which incorporates the Metropolis-Hastingsalgorithm into blocked Gibbs sampling.
Metropolis-Hastings is another technique for sampling from aMarkov chain.
It first draws a proposed next stateh?
based on the current state h according to someproposal distribution Q(h?;h).
Then it accepts theproposal with the probability ofmin{P (h?)Q(h;h?
)P (h)Q(h?
;h) , 1}.
(4)If the proposal is not accepted, the current state isused as the next state.
Metropolis-Hastings is usefulwhen it is difficult to directly sample from P .We use the Metropolis-Hastings algorithm withinGibbs sampling.
Instead of calculating the n + 1probabilities of the number of boundaries, we onlycompare the current state with a proposed bound-ary arrangement.
Also, the set of positions sampledjointly is chosen at unigram-level type instead ofbigram-level type.
The positions are no longer ex-changeable.
Therefore we calculate the conditionalprobability of one specific boundary arrangement.When n = 1, the only choice is to flip the cur-rent state (i.e.
(m,m?)
?
{(0, 1), (1, 0)}).
This re-duces to simple collapsed sampling.
Otherwise wedraw a proposed state in two steps.
Given the npositions and the number of current boundaries m,we first draw the number of proposed boundaries m?from a probability distribution fn(m?;m).
We thenrandomly arrange m?
boundaries.
The probabilitymass is uniformly divided by nCm?
arrangements.One exception is the case when m /?
{0, n} andm?
= m. In this case we perform permutation toobtain h?
?= h. To sum up, the proposal distribution00.10.20.30.40  2  4  6  8  10 00.10.20.30.4probabilitym?Figure 1: Probability of # of boundaries f10(m?
; 3).is defined as follows:Q(h?
;h) = fn(m?;m)nCm?
?
In(m,m?
), (5)where In(m,m?)
is 1 if m /?
{0, n} and m?
= m;otherwise 0.We construct fn(m?
;m) by discretizing a betadistribution (?
= ?
< 1) and a normal distributionwith mean m, as shown in Figure 1.
The former fa-vors extreme values while the latter prefers smallermoves.The sampling of each type is done in the follow-ing steps.1.
Collect n positions that share a unigram-leveltype.2.
Propose a new boundary arrangement.
In whatfollows, we only focus on flipped boundariesbecause the rest does not change the likelihoodratio of the current and proposed states.3.
Calculate the current conditional probability.This can be done by repeatedly applying (2)while removing words one-by-one and updat-ing the model counts accordingly.4.
Calculate the proposed conditional probabilitywhile adding words one-by-one.5.
Decide whether to accept the proposal accord-ing to (4).
If the proposal is accepted, we final-ize the arrangement; otherwise we revert to thecurrent state.We implement skip approximation (Liang et al,2010) and sample each type once per iteration.
Thisis motivated by the observation that although the610joint sampling of a large number of positions is com-putationally expensive, the proposal is accepted veryinfrequently.5.4 Additional ConstraintsPartial annotations (Tsuboi et al, 2008; Neubig andMori, 2010) can be used for inference.
If we know inadvance that a certain position is a boundary or non-boundary, we simply keep it unaltered.
As partially-annotated text, we can use markup.
Suppose that theoriginal text is written with wiki markup as follows:*JR[[???]][[???
]][gloss] JR Ube Line Tsuneyama StationIt is clear that the position between ???
(line) and???
(tsune) is a boundary.Similarly, we can impose our trivial rules of seg-mentation on the model.
For example, we can keeppunctuation markers (Li and Sun, 2009) separatefrom others.6 Experiments6.1 SettingsData Set We evaluated our approach on JapaneseWikipedia.
For each entry of Wikipedia, we re-garded the title as a noun phrase and used both thetitle and main text for segmentation.
We separatelyapplied our segmentation procedure to each entry.We constructed the data set as follows.
We ex-tracted each entry from an XML dump of JapaneseWikipedia.4 We normalized the title by droppingtrailing parentheses that disambiguate entries withsimilar names (e.g.
???
(??)?
for Akagi (aircraftcarrier)).
We extracted the main text from wikitextand used wiki markup as boundary markers.
We ap-plied both the title and main text to the morphologi-cal analyzer JUMAN5 to get an initial segmentation.If the resultant segmentation conflicted with markupinformation, we overrode the former.
The initial seg-mentation was also used as the baseline.We only used entries that satisfied all of the fol-lowing conditions.1.
The (normalized) title is longer than one char-acter and contains hiragana, katakana and/orkanji.4http://download.wikimedia.org/jawiki/5http://nlp.ist.i.kyoto-u.ac.jp/EN/index.php?JUMAN2.
The main text is longer than 1,000 characters.3.
The title appears at least 5 times in the maintext.The first condition ensures that there are segmenta-tion ambiguities.
The second and third conditionsexclude entries unsuitable for statistical methods.14% of the entries satisfied these conditions.We randomly selected 500 entries and manuallysegmented their titles for evaluation.
The 2-personinter-annotator Kappa score was 0.95.As an annotated corpus, we used Kyoto Text Cor-pus.6 It contained 1,675,188 characters.Models We compared the unigram and bigrammodels.
As for inference procedures, we used col-lapsed Gibbs sampling (CL) for both models, type-based sampling (TB) for the unigram model andhybrid type-based sampling (HTB) for the bigrammodel.We tested two mixing methods of the annotatedcorpus, direct mixing (DM) and back-off mixing(BM).To investigate the effect of initialization, we alsotried randomly segmented text as the initial state(RAND).
For random initialization, we placed aboundary with probability 0.5 on each position un-less it was a fixed boundary.The unigram model has one Dirichlet processconcentration hyperparameter ?0 and the bigrammodel has ?0 and ?1.
For each model, we experi-mented with the following values.
?0: 0.1, 0.5, 1 5 10, 50, 100, 500, 1,000 and 5,000?1: 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100 and 500For comparison, we also performed hyperparame-ter sampling.
Following Escobar and West (1995),we set a gamma prior and introduced auxiliary vari-ables to infer concentration parameters from data.For back-off mixing, we used the linear interpola-tion parameter ?IP = 0.5.
The zerogram model wastrained on the annotated corpus.In each run, we performed 10 burn-in iterations.We then performed another 10 iterations to collectsamples.6http://nlp.ist.i.kyoto-u.ac.jp/EN/index.php?Kyoto%20University%20Text%20Corpus611Table 1: Results of segmentation of entry titles (F-score (precision/recall)).model best median inferredunigram + CL 81.35 (77.78/85.27)** 80.09 (75.80/84.89) 80.86 (76.81/85.36)unigram + TB 55.87 (66.71/48.06) 51.04 (62.64/43.06) 42.63 (54.91/34.84)bigram + CL 80.65 (76.73/84.99) 79.96 (75.50/84.99) 80.54 (76.84/84.61)bigram + HTB 83.23 (85.25/81.30)** 74.52 (71.33/78.00) 34.52 (46.69/27.38)unigram + CL + DM 85.29 (83.14/87.54)** 81.62 (77.93/85.70)** 80.91 (82.87/79.04)unigram + TB + DM 35.26 (47.74/29.95) 33.81 (46.20/26.66) 31.90 (44.30/24.93)bigram + CL + DM 80.37 (76.01/85.27) 79.88 (75.42/84.89) 73.77 (78.49/69.59)bigram + HTB + DM 69.66 (67.68/71.77) 67.39 (64.35/70.73) 31.54 (43.79/24.64)unigram + CL + BM 81.28 (77.48/85.46) 80.23 (76.06/84.89) 81.42 (77.75/85.46)unigram + TB + BM 57.22 (68.01/49.39) 52.98 (64.50/44.95) 42.43 (54.69/34.66)bigram + CL + BM 81.33 (77.34/85.74) 80.07 (75.69/84.99) 81.46 (77.82/85.46)**bigram + HTB + BM 86.32 (85.67/86.97)** 76.35 (71.89/81.40) 40.81 (53.35/33.05)unigram + TB + RAND 56.01 (66.93/48.16) 50.89 (62.21/43.06) 42.68 (54.81/34.94)bigram + HTB + RAND 79.68 (80.13/79.23) 68.16 (63.64/73.37) 34.99 (47.05/27.86)unigram + TB + BM + RAND 57.44 (67.91/49.76) 50.86 (61.92/43.15) 42.31 (54.55/34.56)bigram + HTB + BM + RAND 84.03 (83.10/84.99) 70.46 (65.25/76.58) 40.16 (52.60/32.48)baseline (JUMAN) 80.09 (75.80/84.89)** Statistically significant improvement with p < 0.01.Evaluation Metrics We evaluated the segmenta-tion accuracy of 500 entry titles.
Specifically weevaluated the performance of a model with preci-sion, recall and the F-score, all of which were basedon tokens.
We report the score of the most frequentsegmentation among 10 samples.Following Lee et al (2010), we report the best andmedian settings of hyperparameters based on the F-score, in addition to inferred values.In order to evaluate the degree of differencebetween a pair of segmentations, we employedcharacter-based evaluation.
Following Kudo etal.
(2004), we converted a word sequence intocharacter-based BI labels and examined labeling dis-agreements.
McNemar?s test of significance wasbased on this metric.6.2 ResultsTable 1 shows segmentation accuracy of variousmodels.
One would notice that the baseline scoreis much lower than the score previously reported re-garding newspaper articles (Kudo et al, 2004).
Itis because unlike newspaper articles, the titles ofWikipedia entries contain an unusually high pro-portion of unknown words.
As suggested by rel-atively low precision, unknown words tend to beover-segmented by the morphological analyzer.In the best hyperparameter settings, the back-offmixing bigram model with hybrid type-based sam-pling (bigram + HTB + BM) significantly outper-formed the baseline and achieved the best F-score.It did not performed well in the median setting asit was sensitive to the value of ?1.
Hyperparameterestimation led to catastrophic decreases in bigrammodels as it made the hyperparameters much largerthan those in the best settings.Collapsed sampling (+CL) returned scores com-parable to that of the baseline.
It is simply becauseit did not change the initial segmentation a lot.
Incontrast, type-based sampling (+TB) brought largemoves to the unigram model and significantly hurtaccuracy.
As suggested by relatively low recall, theunigram model prefers under-segmentation.When combined with (hybrid) type-based sam-pling (+TB/+HTB), back-off mixing (+BM) in-creased accuracy from the corresponding non-mixing models.
By contrast, direct mixing (+DM)drastically decreased accuracy from the non-mixingmodels.
We can confirm that when the main textis orders of magnitude smaller than the annotatedtext, the role of constituent words in the main textis underestimated.
To our surprise, collapsed sam-pling with mixing models (+CL, +DM/+BM) out-performed the baseline.
However, the scores of type-based sampling (+TB) suggest that with much moreiterations, the models would converge to undesiredstates.612The unigram model with random initializationwas indifferent from that with default initialization.By contrast, the performance of the bigram modelslightly degenerated with random initialization.6.3 ConvergenceFigure 2 shows how segmentations differed fromthe initial state in the course of inference.7 A diffis defined as the number of character-based dis-agreements between the baseline segmentation and amodel output.
Hyperparameters used were those ofthe best model with (hybrid) type-based sampling.We can see that collapsed sampling was almostunable to escape the initial state.
With type-basedsampling (+TB), the unigram model went furtherthan the bigram model, but to an undesired direc-tion.
The bigram model with hybrid type-basedsampling (bigram + HTB) converged in few itera-tions.
Although the model with random initializa-tion (+RAND) converged to a nearby point, the ini-tial segmentation by the morphological analyzer re-alized a bit faster convergence and better accuracy.Figure 2 shows how acceptance rates changedduring inference.
For comparison, a sample by atype-based Gibbs sampler was treated as ?accepted?if the number of new boundaries was different fromthat of the current boundaries (i.e.
m?
?= m).
Theacceptance rates were low and samplers seeminglystayed around modes.6.4 ApproximationUp to this point, we consider every possible bound-ary position.
However, this seems wasteful, giventhat a large portion of text has only marginal influ-ence on the segmentation of the noun phrase in ques-tion.
For this reason, we implemented approxima-tion named matching skip.
We sampled a boundaryonly if the corresponding local area contained a sub-string of the noun phrase in question.Table 2 shows the result of approximation.
Hy-perparameters used were those of the best modelswith full sampling.
Matching skip steadily worsenedperformance although not to a large extent.
Mean-7For a fair comparison, we might need to report changesover time instead of iterations.
However, the difference of con-vergence speed is obvious in the iteration-based comparison al-though (hybrid) type-based sampling takes several times longerthan collapsed sampling in the current na?
?ve implementation.01002003004005006007008009000  5  10  15  20diffiterationunigram + CLunigram + TBbigram + CLbigram + HTBunigram + TB + RANDbigram + HTB + RANDFigure 2: Diffs in the course of iteration.
All models werewith back-off mixing (+BM).00.020.040.060.080.10.120.140  5  10  15  20acceptancerateiterationunigram + TBbigram + HTBunigram + TB + RANDbigram + HTB + RANDFigure 3: Acceptance rates for a noun phrase in thecourse of iteration.
All models were with back-off mix-ing (+BM).while it drastically reduced the number of sampledpositions.
The median skip rate was 90.87%, with astandard deviation of 8.5.6.5 DiscussionFigure 4 shows some segmentations corrected bythe back-off mixing bigram model with hybrid type-based sampling.
?????
(ichihino) is a rare placename but can be identified by the model becauseit is frequently used in the article.
???????
(konamiruku in hiragana) seems a pun on ??????
(kona miruku, ?powdered milk?)
and ?????
(konami in katakana, a company).
We consider itas a single word because we cannot reconstruct theetymology solely based on the main text.
Note thedifferent scripts.
In Japanese, people often changethe script to derive a proper noun from a commonnoun, which a na?
?ve analyzer fails to recognize.
It is613Table 2: Effect of matching skip (F-score (precision/recall)).model full matching skipbigram + HTB 83.23 (85.25/81.30)** 82.86 (84.27/81.49)bigram + HTB + BM 86.32 (85.67/86.97)** 83.87 (82.60/85.17)**bigram + HTB + RAND 79.68 (80.13/79.23) 78.81 (78.64/75.07)bigram + HTB + BM + RAND 84.03 (83.10/84.99) 81.08 (80.22/81.96)baseline (JUMAN) 80.09 (75.80/84.89)** Statistically significant improvement with p < 0.01.?
+?
+?
+?
+?
+????hiwaki+?chou+??
?ichihino(Ichihino, Hiwaki Town, an address)?
+??
+???????risona+??
?kaRdo(Risona Card, a company)??
+??
+????????
?chiritotechiN (name of a play)??
+??
+??????
?konamiruku(a shop affiliated with Konami Corporation)??
+??????
?haiziI (stage name of a comedian)??
+????????
?chiNsukou (a traditional sweet)??????????????????koNtora+???aruto+?????
?kurarineQto (Contra-alto clarinet)Figure 4: Examples of improved segmentations.very important to identify hiragana words correctly.As hiragana is mainly used to write function wordsand other basic words, segmentation errors concern-ing hiragana often bring disastrous effects on ap-plications of morphological analysis.
For example,the analyzer over-segments ????????
(chiri-totechiN) into three shorter words among which thesecond word ????
(tote) is a particle, and this se-quence of words is transformed into a terrible parsetree.Most improvements come from correction ofover-segmentation because the initial segmenta-tion by the analyzer shows a tendency of over-segmentation.
An example of corrected under-segmentation is ?contra-alto clarinet.?
The pres-ence of ?clarinet,?
?alto?
and ?contrabass?
and oth-ers in the main text allowed the model to iden-tify the constituents.
On the other hand, the seg-mentation failed when our assumption about con-stituents does not hold.
For example, the personname ??????
(kikuchi shuNkichi) is two wordsbut was erroneously combined into a single word bythe model because unfortunately he was always re-ferred to by the full name.7 ConclusionsIn this paper, we proposed a new task of Japanesenoun phrase segmentation.
We adopted non-parametric Bayesian language models and proposedhybrid type-based sampling that can efficiently cor-rect segmentation given by the morphological an-alyzer.
Although supervised segmentation is verycompetitive, we showed that it can be supplementedwith our unsupervised approach.We applied the proposed method to encyclopedictext to segment noun phrases in it.
The proposedmethod can be applied to other tasks.
For example,in unknown word acquisition (Murawaki and Kuro-hashi, 2008), noun phrases are often acquired fromtext as single words.
We can now segment them intowords in a more sophisticated way.In the future we will assign a POS tag to eachword in order to use segmented noun phrases in mor-phological analysis.
We assume that the meaningof constituents in a noun phrase rarely depends onouter context.
So it would be helpful to augmentthem with rich semantic information in advance in-stead of disambiguating their meaning every time weanalyze given text.AcknowledgmentsThis work was partly supported by JST CREST.ReferencesMasayuki Asahara and Yuji Matsumoto.
2000.
Extendedmodels and tools for high-performance part-of-speech614tagger.
In Proc.
of COLING 2000, pages 21?27.Masayuki Asahara and Yuji Matsumoto.
2004.Japanese unknown word identification by character-based chunking.
In Proc.
COLING 2004, pages 459?465.Phil Blunsom, Trevor Cohn, Sharon Goldwater, andMarkJohnson.
2009.
A note on the implementation of hier-archical Dirichlet processes.
In Proc.
of ACL-IJCNLP2009: Short Papers, pages 337?340.Michael D. Escobar and Mike West.
1995.
Bayesiandensity estimation and inference using mixtures.Journal of the American Statistical Association,90(430):577?588.Thomas S. Ferguson.
1973.
A Bayesian analysis ofsome nonparametric problems.
Annals of Statistics,1(2):209?230.Sharon Goldwater, Thomas L. Griffiths, and Mark John-son.
2006.
Interpolating between types and tokens byestimating power-law generators.
In NIPS 18, pages459?466.Sharon Goldwater, Thomas L. Griffiths, and Mark John-son.
2009.
A Bayesian framework for word segmen-tation: Exploring the effects of context.
Cognition,112(1):21?54.Mark Johnson and Katherine Demuth.
2010.
Unsu-pervised phonemic Chinese word segmentation usingadaptor grammars.
In Proc.
of COLING 2010, pages528?536.Mark Johnson.
2008.
Using adaptor grammars to iden-tify synergies in the unsupervised acquisition of lin-guistic structure.
In Proc.
of ACL 2008, pages 398?406.Jun?ichi Kazama and Kentaro Torisawa.
2008.
Inducinggazetteers for named entity recognition by large-scaleclustering of dependency relations.
In Proc.
of ACL2008, pages 407?415, June.Taku Kudo, Kaoru Yamamoto, and Yuji Matsumoto.2004.
Applying conditional random fields to Japanesemorphological analysis.
In Proc.
of EMNLP 2004,pages 230?237.Sadao Kurohashi, Toshihisa Nakamura, Yuji Matsumoto,and Makoto Nagao.
1994.
Improvements of Japanesemorphological analyzer JUMAN.
In Proc.
of The In-ternational Workshop on Sharable Natural LanguageResources, pages 22?38.Yoong Keok Lee, Aria Haghighi, and Regina Barzilay.2010.
Simple type-level unsupervised POS tagging.In Proc.
of EMNLP 2010, pages 853?861.Zhongguo Li and Maosong Sun.
2009.
Punctuation asimplicit annotations for Chinese word segmentation.Computational Linguistics, 35(4):505?512.Percy Liang, Michael I. Jordan, and Dan Klein.
2010.Type-based MCMC.
In Proc.
of NAACL 2010, pages573?581.Jin Kiat Low, Hwee Tou Ng, and Wenyuan Guo.
2005.
Amaximum entropy approach to Chinese word segmen-tation.
In Proc.
of the 4th SIGHAN Workshop, pages161?164.Daichi Mochihashi, Takeshi Yamada, and Naonori Ueda.2009.
Bayesian unsupervised word segmentation withnested Pitman-Yor language modeling.
In Proc.
ofACL-IJCNLP 2009, pages 100?108.Yugo Murawaki and Sadao Kurohashi.
2008.
Onlineacquisition of Japanese unknown morphemes usingmorphological constraints.
In Proc.
of EMNLP 2008,pages 429?437.Masaaki Nagata.
1996.
Automatic extraction of newwords from Japanese texts using generalized forward-backward search.
In Proc.
of EMNLP 1996, pages 48?59.Tetsuji Nakagawa and Yuji Matsumoto.
2006.
Guessingparts-of-speech of unknown words using global infor-mation.
In Proc.
of COLING-ACL 2006, pages 705?712.Graham Neubig and Shinsuke Mori.
2010.
Word-basedpartial annotation for efficient corpus construction.
InProc.
of LREC 2010.ThuyLinh Nguyen, Stephan Vogel, and Noah A. Smith.2010.
Nonparametric word segmentation for machinetranslation.
In Proc.
of COLING 2010, pages 815?823.Fuchun Peng, Fangfang Feng, and Andrew McCallum.2004.
Chinese segmentation and new word detectionusing conditional random fields.
In Proc.
of COLING?04, pages 562?568.Yee Whye Teh.
2006.
A Bayesian interpretation of in-terpolated Kneser-Ney.
Technical Report TRA2/06,School of Computing, National University of Singa-pore.Yuta Tsuboi, Hisashi Kashima, Shinsuke Mori, HirokiOda, and Yuji Matsumoto.
2008.
Training conditionalrandom fields using incomplete annotations.
In Proc.of COLING 2008, pages 897?904.Kiyotaka Uchimoto, Satoshi Sekine, and Hitoshi Isahara.2001.
The unknown word problem: a morphologicalanalysis of Japanese using maximum entropy aided bya dictionary.
In Proc.
of EMNLP 2001, pages 91?99.Jia Xu, Jianfeng Gao, Kristina Toutanova, and HermannNey.
2008.
Bayesian semi-supervised Chinese wordsegmentation for statistical machine translation.
InProc.
of COLING 2008, pages 1017?1024.Nianwen Xue.
2003.
Chinese word segmentation ascharacter tagging.
Computational Linguistics andChinese Language Processing, 8(1):29?48.Toshio Yokoi.
1995.
The EDR electronic dictionary.Communications of the ACM, 38(11):42?44.615
