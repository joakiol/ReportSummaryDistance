Learning dialog act processingSte fan  Wermter  and  Mat th ias  LSche lComputer  Sc ience Depar tmentUn ivers i ty  of I tamburg22765 HamburgGermanywermter@in format ik .un i -hamburg .de15chel @in format ik .un i -h  amburg .deAbst ractIn this paper we describe a new approachfor learning dialog act processing.
Inthis approach we integrate a symbolic se-mantic segmentation parse,: with a learn-ing dialog act network.
In order to sup-port the unforeseeable errors and varia-tions of spoken language we have con-centrated on robust data-driven learn-ing.
This approach already compares fa-vorably with the statistical average plan-sibility method, produces a segmenta-tion and dialog act assignment for allutteranccs in a robust manner, and re-daces knowledge ngineering since it canbe bootstrapped from rather small cor-pora.
Therefore, we consider this newapproach as very promising for learningdialog act processing.1 In t roduct ionFor several decades, the pragmatic interpretationat a dialog act level belongs to the most diffi-cult and challenging tasks tbr natural languageprocessing and computational linguistics (Austin,1962; Searle, 1969; Wilks, 1985).
Recently, wecan see an important development in natural an-guage processing and computational linguisticstowards the use of empirical learning methods(for instance, (Charniak, 1993; Marcus et al,1993; Wermter, 11995; Jones, 1995; Werml;er et al,1996)).Primarily, new learning approaches have beensuccessful for leo~'ically or syntactically tagged textcorpora.
In this paper we want to examine thepotential of learning techniques at highcr prag-matic dialog levels of spoken language.
Learn-ing at least part of the dialog knowledge is de-sirable since it could reduce the knowledge ngi-neering effort.
Furthermore, inductive learning al-gorithms work in a data-driven mode and have theability to extract gradual regularities in a robustmanner.
This robustness is particularly impor-tant for processing spoken language since spokenlanguage can contain constructions including in-terjections, pauses, corrections, repetitions, falsestarts, semantically or syntactically incorrect con-structions, etc.Tile use of learning is a new approach at thelevel of dialog acts and only recently, there havebeen some learning approaches for dialog knowl-edge (Mast et al, 1996; Alexanderson et al, 1995;Reithinger and Maier, 1995; Wang and Waibel,1995).
Different from these approaches, in this pa-per we examine the combination of learning tech-niques in simple recurrent networks with symbolicsegmentation parsing at a dialog act level.Input to our dialog component are utterancesh'om a corpus of business meeting arrangementslike: "Tuesday at 10 is for me now again badbecause I there still train I think we should \[de-lay\] the whole then really to the next week is thisfor you possible" 1.
For a fiat level of dialog actprocessing, the incrementM output is (1) utter-ance boundaries within a dialog turn and (2) thespecific dialog act within an utterance.
The pa-per is structured as follows: First we will out-line the domain and task and we will illustratethe dialog act categories.
Then, we will describethe overall architecture of the dialog componentin the SCREEN system (Symbolic ConnectionistRobust Enterprise for Natural language), consist-ing of the segmentation parser and the dialog actnetwork.
We will describe the learning and gen-eralization results for this dialog component andwe will point out contributions and further work.l'Phis is ahnost a literal translation of the Ger-mau utterance: "l)ienstags um zehn ist bei mir nunwiederum schlecht weft ich da noch trainieren bin ichdenke wir sollten das Ganze dann doch auf die niichsteWoche verschieben geht es bei ihnen da."
We havechosen the literal word-by-word trauslation since ourprocessing is incremental nd knowledge about the or-der of the German words matter for processing.7402 The Task'Fb.e main task is the examinatiotl of learning h)r(liMog act processing and the donlain is (,\]tc ar-rangement of business dates.
For this domain wehave developed a classification of dialog acts whichis shown in table 1 together with examples.
Ourguideline for the choice of these dialog acts wasbased on (l) the particular domMn and corpusand (2) our goal to learn rather few dialog <:at<;:gories but in a robusl; n\]anucr 2.Dialog act (Abbreviation)acceptance (ace)query (query)rejection (rej)request comment (re-c)request suggestion (re-s)statement (state)date/loc, suggestion (sag)miscellaneous (mist)ExampleThat would be \[ine1)o you know ttamburgThis is /,oo late for mcIs that possibleWhen wouM it be okRight, it's a Tuesday\[ propose April 13thSo long, byeTable I: Dialog acts and examplesFor example, in our example turu below therearc several utterances and each of them has a par-ticular dialog act as shown below.
The turn startswith a reiection, followed by all explaining state-ment.
rl'hen a suggestion is made and a requestfor commenting on this suggestion:* l)ienstags nm zehn ist bei mir mm wiederums(:hlecht (Tuesday at I0 is for me now againbad) -+ rejection- well ich da noch trainieret, bin (because Ithere still train) --~ statement?
ich denke (I think) -+ miscellaneous?
wit sollten das Ganze dann doch auf dienaechstc Woche verschieben (we should tilewhole then really to the next week delay; weshould delay the whole then really to the nextweek) -+ suggestion?
geht es bei ihnen da (is that for you possible)-+ request commentIt is important o note that segmentation pars-ing and dialog act processing work increinentMand in parallel on the incoming stream of wordhypotheses.
Alter each incoming word the seg-mentation parsing and dialog act processing an-alyze the current input.
For instance, dialog acthypotheses are available with the first input word,although good hypotheses may only be possible2This is also motivated by our additional goal of re-ceiving noisy input directly from a speech recognizer.after most of an utterance has been seen.
Ourgenera\] goal here is to produce hypotheses aboutsegmentation and diMog acts as early as possiblein an incremental manner.3 The Overall ApproachThe research presented here is embedded in alarger effort for examining hybrid eonnectionistlearning capabilities for the analysis of spokenlanguage at various acoustic, syntactic, semanticand pragmatic levels.
To investigate hybrid con-nectionist architectures for speech/language anal-ysis we devek)l)ed the SCREEN system (Sym-bolic Connectionist ll.obust Enterprise for Natu-ral language) (Wermter and Weber, 1996).
For thetask of analyzing spontancous language we pursuea shallow screening analysis which uses prima,>ily flat representations (like category sequences)wherever possible.also Friday the nineteenth is not possiblerejectbut Thursday afternoon isok for mcacceptsegmetqfr;ntledialog acttype (is)verb-\[onnquestmnauxiliaryagentotjectrecipientJmc-at~ dialog act nrocessint~ - -l - -  knowledge base --  I \] \[+_+ aM semantic \[ knowledge \]1 ldial?g kn?wledge \] /l,'igure 1: Architecture of dialog act componentFigure 1 gives an overview of our dialog compo-nent in SCI{EEN.
The interpretation ofutterancesis based on syntactic, semantic and dialog knowl-edge for each word.
The syntactic and semanticknowledge is provided by other SCREEN conlpo-heats and has been described elsewhere (Wermteratt(l Weber, 1995).
Each word of an utteranceis processed incrementally and passed to tile seg-741mentat ion parser and to the dialog act network.The dialog act network provides the currently rec-ognized dialog act for the current fiat fl'ame rep-resentation of the utterance part.
The segmen-tation parser provides knowledge about utteranceboundaries.
This is important control knowledgefor the dialog act network since without know-ing about utterance boundaries the dialog networkmay assign incorrect dialog acts.4 The  Segmentat ion  ParserThe segmentation parser receives one word at atime and builds up a flat frame structure in anincremental manner (see tables 2 and 3).
Togetherwith each word the segmentation parser receivessyntactic and semantic knowledge about this wordbased on other syntactic and semantic modulesin SCREEN.
Each word is associated with 1. itsmost plausible basic syntactic ategory (e.g.
noun,verb, adjective), 2. its most plausible abstractsyntactic category (e.g.
noun group, verb group,prepositional group), 3. basic semantic category(e.g., animate, abstract), and 4:.
abstract semanticcategory (e.g., agent, object, recipient).Slots 3.
Phrase Final l'hrasedialog acttypeverb-formquestionauxiliaryagentobjectrecipienttime-atcat?is((is))nilnilnilnil((Tuesday)(at :tO))rejectis((is))nilnilnilnil((for n,e))((Tn~sday)(at 1o))time-from niltimeoto nillocation-at nillocation-from nillocation-to nilconfirm nilnegation nilmiscellaneous nilinput %msday at 10isnilnilnilnilnilnil((bad))((now a~ai~))Tuesday at 10is for menow again badTable 2: Incremental slot filling in frame 1 : literalincremental translation: Dienstags mn zehn ist betmir nun wiederum schlecht (Tuesday at 10 is forme now again bad)This syntactic and semantic category knowl-edge is used by the segmentation parser for twomain purposes.
First, this category knowledgeis needed for our segmentation heuristics.
Forour domain we have developed segmentation ruleswhich allow the system to split turns into utter-ances.
For instance, if we know that the basic syn-tactic category of a word "because" is col\junctionand it is part of a conjunction group, then this isan indication to close the current frame and trig-ger a new fl:ame for the next; utterance.
Second,the category knowledge, primarily the abstract se-mantic knowledge, is used for :filling the flames,so that we get a symbolically accessible structurerather than a tagged word sequence.Slots 1.-3.
Phrase Final Phrasedialog acttypeverb-formquestionauxiliaryagentobjectrecipienttime-attime-fromtime-tolocation-atlocation-fl'omlocation-toc o nt~r 11(1negationmiscellaneousinputcat?Inovenilnilnil((I))nilnilnilnillfilnilnilnilnilnil((because)(there still))because Ithere stillstatementmove((t,-ain))nilaIn((t))nilnilnilnilnilnilnilnilnilnil((because)(there still))because Ithere stilltrain amTable 3: Incremental slot filling ill frame 2;...wellich (la noch trainieren bin (because I there stilltrain \[am\])The segmentation parser is able to segment 84%of the 184 turns with 314 utterances correctly.The remaining 16% are mostly difficult ambigu-ous cases some of which could be resolved if moreknowledge could be used.
For instance, whilemany conjunctions like "because" are good indi-cators for utterance borders, some conjunctionslike "and" and "or" may not start new coordi-nated subsentences but coordinate noun groups.Fundamental  structural disambiguation could beused to deal with these cases.
Since they occurrelatively rarely in our spoken utterances we havechosen not to incorporate structural disambigua-lion.
Furthermore, another class of errors is char-acterized by time and location specifiers which canoccur at the end or start of an utterance.
For in-stance, consider the example: "On Tuesday thesixth of April \[ still have a slot in the afternoon- is that possible" versus "On Tuesday the sixthof April I still have a slot --- in the afternoon isthat possible".
Such decisions are difficult and ad-742ditional knowledge' like prosody might help here.Currently, there is a pref>rence for @ling the ear-lier Dame.5 The  D ia log  Act  NetworkIn t, able I we have described the dialog acts w('use in our domain.
Before we start to describe,any experiments on learning dialog acts we showthe distributioll of dialog acts across our tr;dningand test, sets.
Table ,1 shows the distribution forore: set of 1184 turns with 3:14 utterances.
Therewere 100 utterances in the training set att(l 21d inthe test set.
As we can see, st,ggestions and ex-l>lanatory st~d;ements often occur but in general alldialog acts occur reasonably of'ten.
This disl, ribu--Lion analysis is iml)orl,;mt \[br judging tit(: leat'ltiugand generalization behavior.Categorysug 371%state 20%rej 12%mist I 1%re-s 10%aec 9%query 5%re-e 2%'Fal)le d: l)istribution of the dialog actsand test sot,Training Test26%21%1 0%18%8%12%3%:/%in trainingAfter this initial distribution aualysis we nowdescribe ore: nel, work architectur(, for learning di-alog acts.
I)iaJog acts depend a lot on signiti-cant words and word order.
Certain key wordsare much more significant R)r n certain dialog actthan others.
For instance "prol)ose" is highly sig-nificanl; for the dialog act, su.qgcsl, while "in" isnol,.
'Fherefore we COlnputed a, smoothed dialogact plausibility vector for each word w which re-\[lects the i)lausilility of the cat,egol:ies \[br a par-ticular word.
The sm-n of all values is 1 and eachwdue is at leasl, 0.01.
The plausibility value of aword w in a. dialog category chti with the frequencyf is computed as describ('d in tJtc formula below.J~,+, (,,t,) - (A ,  (',,,) * A ,  := 0(,%) * o.ol)Total frcq.uc, ucy f (w)  in cortms'1%1)1(; 5 shows ex~unples of plausibility w'.cl,orsrot some words.
As we can see, "bad" has thehighest plausibility Rw 1,he reject dialog act, aml"l)ropose" for the 8tty!leSl, dialog act.
On I;he otherhaud the word "is" is not i)articul,u'ly significantfor certain dialog acts and therefore has a plau-sibility vector with relatively evenly distributedV~|lteS.bad propose ist.cc 0.28 0.01 0.22nisc 0.0l 0.38 0.02lucry 0.01 0.01 0.07cj 0.66 0.01 0.34e-c 0.0J 0.0J 0.01e-s 0.0:1 0.01 0.02tate 0.01 0.01 0.27ug 0.01 0.56 0.05'l'aloh" 5: Three examples for plausibility vectorsWe have experimented with dilferent variationsof simple recurrent networks (Elman, 1990) forlearning dialog ~mt assignment.
We had chosensimple recurrent networks since these networkscan represent he previous context in an utter-ante in their recurrent context layer.
The bestperforming network is shown in figure 2.output layer hidden l ;a~' t~in mJ3~ayer+% % %5.
% %+ % %Figm:e 2: I)ia\]og act network with dialog plausi-1)ilil;y vectors a.s inputInput to t, his network is tile current word repre-sented by its dialog plausibility vector.
The out-put is the dialog act of the whole uttera.m:(,.
Be-tween input and output layer there are the hiddenlayer and the context layer.
All the DedR)rwardconnections in the network are flflly connected.Only the recurrent connections fi:om the hiddenlayer to the context layer are 1:1 copy connec-tR)tlS, which represent the internal earned contextof the.
utl;erance before the current word.
'lYa\[n-ing in these uetworks is per\[brined by using gra-dient descent; (l{mnelhart et M., 1986) using upto 3000 cycles through the training set.. By us-ing Che iuternM learned context it is possiMe to~na.ke dialog act assignments for a whole utter-743ance.
While processing a whole utterance, eachword is presented with its plausibility vector andat the output layer we can check the incrementallyassigned ialog acts for each incoming word of theutterance.We have experimented with different inputknowledge (only dialog act plausibility vectors,additional abstract semantic plausibility vectors,etc.
), different architectures (different numbers ofcontext layers, and different number of units inhidden layer, ere).
l)ue to space restrictions itis not possible to describe all these comparisons.Therefbre we just focus on the description of thenetwork with the best generalization performance.Dialog actsaCCstatemiscqueryr~jsugre-cre-sTotal'Ih:aining Test88.9 72.090.0 90.954.5 73.740.0 0.09\]..7 85.790.3 92.90.0 0.090.0 82.482.0 79.4Table 6: Performance of simple recurrent networkwith dialog plausibility vectors in percentTable 6 shows the results for our training andtest utterances.
The overall performance on thetraining set was 82.0% on the training set and79.4% on the test set.
An utterance was countedas classified in the correct dialog act class if themajority of the outputs of the dialog act networkcorresponded with the desired dialog act.
Thisgood performance is partly due to the distributedrepresentation i  the dialog plausibility vector atthe input layer.
Other second best networks withadditional local representations tbr abstract se-mantic category knowledge could perform betteron the training set but failed to generalize on thetest set and only reached 71%.The remaining errors are partly due to seldomlyoccurring dialog acts.
Por instance, there are only2% of the training utterances and 2.8% of the testutterances which belong to the request-commentdialog act.
The network was not able to learn cor-rect assignments due to the little training data.The drop in the performance for the query dia-log act from training to test set can be explainedby the higher variability of the queries comparedto all other categories.
Since queries differ muchmore from each other than all other dialog actsthey could not be generalized.
However they donot occur very often.
All other often occurringdialog act categories performed very well as theindividual percentages and the overall percentageshow.6 D iscuss ion  and Conc lus ionsWhat do we learn from this?
When we started thiswork it was not clear to what extent a symbolicsegmentation parser and a connectionist learningdialog act network could be integrated to performan analysis at the semantics and dialog level.
Wehave shown that a symbolic segmentation parserand a learning dialog network can be integratedto perform dialog act assignments for spoken ut-terances.
While other related work has focusedon statistical learning we have explored the use oflearning in simple recurrent networks.
Our corpusof 2228 words is still medium size.
Nevertheless,we consider the results as promising, given thatit is - to the best of our knowledge - the first at-tempt go integrate symbolic segmentation parsingwith dialog act learning in simple recurrent net-works.How well do we perform compared to relatedwork?
In spite of many projects in the ATIS andVERBMOBIL domains there is not a lot of workon learning for the dialog level.
However, recentlythere have been some investigations of statisticaltechniques (Reithinger and Maier, 1995) (Alexan-derson et al, 1995) (Mast et al, 1996).
For in-stance Mast and colleagues report 58% for learn-ing dialog act assignment with semantic lassifica-tion trees and 69% for learning with pentagramsbut they also used more categories than in ourapproach so that the approaches are not directlycomparable.For a further evaluation of our trMned networkarchitecture we compared our results with a sta-tistical approach based on the same data.
Pl?u-sibility vectors for dialog acts represent he dis-tribution of dialog acts for each word for the cur-rent corpus, t\]owever, for assigning a dialog actto a whole utterance all the words of this utter-ance have to be considered.
A simple but efficientapproach would be to compute the average plau-sibility vector: for each utterance which has beentbund.
Then the dialog act with the highest aver-aged plausibility vector for a complete utterancewould be taken as the computed ialog act.
Thisstatistical approach reached a performance of 62%correctness on the training and test set comparedto the 82% and 79% of our dialog network.
Sosimple recurrent networks performed better thanthe statistical average plausibility method.
Incomparison to statistical techniques which have744also been used successflllly on large corpora, it isour understanding that simple recurrent networksmay be particularly suitable tbr domains whereonly smaller corpora are awdlable or where clas-s|liter|on data is hard to got (as it is the case {'orpragmatic dialog acts.
)What will be further work?
So far we llave con-centratcd on single utterances and we do not ac-count for the relationship between utl;erances in adialog.
While we could demonstrate that such alocal strategy could assign correct dialog acts inmany eases, it might be interesting to explore towhat extent knowledge about previous dialog actsin previous utterances could oven improve our re-salts.
Furthermore, we have developed tim seg-mentation parser and dialog act network as veryrobust components, lit fact, both are very ro-bust in the sense that they will always producethe best possible segmentation and dialog act cat-egorization, hi the future we plan to explore howthe output from a speech recognizer can be pro-cessed by our dialog conlponent.
~qenteiice andword hypotheses from a speech recognizer are stillfar fl'om optimal for continuously spoken spon-taneous speech.
Therefore we have to accountfor highly ungrammaticM constructions.
The seg-mentation parser and the dialog network alreadycontain the robustness which is a precondition fordealing with real-world speech input.AcknowledgementsThis research was funded by the German FederalMinistry for fteseareh and '\['echnology (BMBF)under Grant @01IV101A0 and by the German l{e-search Association (DI,'G) under contract I)I"G IIa1026/6-2.
We would like to thank S. Ilaack, M.Meurer, U. Sauerland, M. Schrattenholzer, and V.Weber for their work on SCREEN.ReferencesJ.
Alexanderson, E. Meier, and N. lh;ithinger.1995.
A robust and efficient three-layered di-alogue component tbr a speech-to-speech trans-lation system.
In Proceedings of the Euro-pean Association for Computational Linguis-tics, l)ublin.J.
Austin.
1962. tlow to do things wilh words.Clarendon Press, Oxford.E.
Charniak.
1993.
Statistical Language Learning.MIT Press, Cambridge, MA.J.
1,. l,Jhnan.
1990.
Finding structure in time.Cognitive ?
'cience., 14:179 221.1).
Jones, editor.
1995.
New Methods in LanguageProcessing.
University College London.M.
Marcus, B. Santorini, and M. Marcinkiewicz.1993.
Building a large annotated corpus of En-glish: the Penn treebank.
Computational Lin-guistics, 19(1).M.
Mast, E. Noeth, 11.
Niemann, andE.
G. Schukat 'l'alanmzzini.
1996.
Automaticclassification of dialog acts with semantic las-sification trees and polygrarns.
In S. Wermter,E.
Rilotf, and G. Scheler, editors, Connection|st,Slatistical and Symbolic Approaches to Learningfor Nalural Language P'wcessing, pages 217-229.
Springer, tleidelberg.N.
l{eithinger and E. Maim:.
1995.
Utilizing sta-tistical dialogue act processing in verbmobil.
InComputational Linguistics A~hive.I).
E. lt.uinelhart, G. E. Hinton, and IL.
J.Williams.
1986.
Learning internal representa-tions by error propagation.
In D. E. Rumel-hart and J. L. MeClelland, editors, Parallel Dis-tribaled Processing, volume 1, pages 318-362.MIT Press, Cambridge, MA.J.
R. Searle.
1969.
?
'pecch Acts.
Cambridge Uni-versity Press, Cambridge.Y.
Wang and A. Waibel.
1995.
Connection|sttraust'cr in machine translation.
In Proceedingso\]" the International Conference on Recent Ad-vances in Natural Language Processing, pages37 44, Tzigov Cliark.S.
Wcrmter and V. Weber.
1995.
Artificial neurMnetworks for automatic knowledge acquisitionin multiple real-world language domains.
InProceedings of the International Conference onNeural Networks and their Applications, Mar-seille.S.
Wermter and V. Weber.
1996.
Interactive spo-ken language processing in the hybrid connec-tion|st system SCREEN: learning robustness inthe real world.
IEEE Computer, 1996. in press.S.
Wermter, E. l{iloff, and G. Scheler.
1996.
Con-nectionist, Statistical and Symbolic Approachesto Learning for Natural Language Pwccssing.Springer, Berlin.S.
Wermter.
1995.
Hybrid Connection|st Natu-ral Language Processing.
Chapman and tIall,London, UK.Y.
Wilks.
1985.
I{elevance, points of viewand speech acts: An artificial intelligence view.Technical Report MCCS-85-25, New MexicoState University.745
