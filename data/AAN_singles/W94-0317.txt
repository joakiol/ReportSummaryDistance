Planning Reference Choices for Argumentative TextsXiaorong HuangFachbereich Informatik, Universit?t des SaarlandesPostfach 15 11 50, D-66041 Saarbr/icken, GermanyEmail: huangQcs.uni-sb.deAbstractThis paper deals with the reference choices involved in thegeneration of argumentative t xt.
A piece of argument-ative text such as the proof of a mathematical theoremconveys a sequence of derivations.
For each step of de-rivation, the premises (previously conveyed intermediateresults) and the inference method (such as the applica-tion of a particular theorem or definition) must be madeclear.
The appropriateness of these references cruciallyaffects the quality of the text produced.Although hot restricted to nominal phrases, our refer-ence decisions are similar to those concerning nominalsubsequent referring expressions: they depend on theavailability of the object referred to within a context andare sensitive to its attentional hierarchy.
In this paper,we show how the current context can be appropriatelysegmented into an attentional hierarchy by viewing textgeneration as a combination of planned and unplannedbehavior, and how the discourse theory of Reichmann canbe  adapted to handle our special reference problem.1 Introduct ionThis paper describes how reference decisions are madein PROVERB, a system that verbalizes machine-foundnatural deduction (ND) proofs.
A piece of argumentativetext such as the proof of a mathematical theorem can beviewed as a sequence of derivations.
Each such derivationis called a proof communicative act (PCA), following theviewpoint hat speeches are actions.
By reference choiceswe mean the explicitness of the verbalization of certainentities in the PCAs.
Concretely, such decisions must bemade for intermediate conclusions used as premises, aswell as for the inference method.
As an example, let uslook at the PCA with the name Derive below:(Derive Der ived-Formula:  u * Iu = uReasons : (unit( lu, U, *), u 6U)Method : Def -Semigroup*uni t )Here, Derived-Formula is filled by a new intermediateconclusion the current PCA aims to convey, which is de-rivable by applying the filler of Method, with the filler ofReasons as premises.
While the new conclusion will usu-ally be handed over unchanged for verbalization, thereare alternatives for referring to both the Reasons and theMethod.
Depending on the discourse history, the follow-ing are two of the possible verbalizations:1.
(inference method omitted): "Since lu is the unit ele-ment of U, and u is an element of U, u* 1v = u."2.
(reasons omitted): "According to the definition of unitelement, u * 1v= u.
"Note that, an explicit reference to a premise or an in-ference method is not restricted to a nominal phrase, asopposed to the traditional subsequent references.
Despitethis difference, the choices to be made here have much incommon with the choices of subsequent references dis-cussed in more general frameworks \[Rei85, GS86, Da192\]:they depend on the availability of the object to be re-ferred to in the context and are sensitive to the segment-ation of the current context into an attentional hierarchy.Although this observation is widely agreed upon for sub-sequent references, no consensus about where the segmentboundaries lie has been reached.
In PROVERB, we at-tack this problem by viewing text generation as a com-bination of hierarchical planning \[Hov88, Moo89, Reigl,Dal92\] and local organization \[Sib90\].
Following \[GS86\],moreover, we assume that every posting of a new task bythe hierarchical planning mechnism creates a new atten-tional unit.
As a consequence, the attentional hierarchy isequivalent to the plan hierarchy.
Based on this segment-ation of context, PRO VERB makes reference choices ac-cording to a discourse theory adapted from that of Reich-man \[Rei85, Hua90\].2 The System PROVERBPROVERB is a text planner that verbalizes natural de-duction (ND) style proofs \[Gen35\].
Several similar at-tempts can be found in previous work.
The system EX-POUND \[Che76\] is an example of direct translation: Al-though a sophisticated linearization is applied on the in-put ND proofs, the steps are then translated locally ina template driven way.
ND proofs were tested as inputsto an early version of MUMBLE \[McD83\], the main aimhowever, was to show the feasibility of the architecture.
Amore recent attempt can be found in THINKER \[EP93\],which implements several interesting but isolated proofpresentation strategies.
PRO VERB therefore can be seen1457th International Generation Workshop ?
Kennebunkport, Maine ?
June 21-24, 1994as the first serious attempt o devise a comprehensivecomputational model that produces adequate argument-ative texts from ND style proofs.Most current NL text planners assume that languagegeneration is planned behavior and therefore adopt ahierarchical planning approach \[Hov88, Moo89, Da192,Rei91\].
Nevertheless there is psychological evidence thatlanguage has an unplanned, spontaneous aspect as well\[Och79\].
Based on this observation, Sibun \[Sib90\] imple-mented a system for generating descriptions of objectswith a strong domain structure, such as houses, chipsand families.
Once a discourse is started, local struc-tures suggest the next objects available.
From a compu-tational point of view, a hierarchical planner elaboratesrecursively on the initial communicative goal until thefinal subgoals can be achieved by applying primitive op-erators.
Local organization, on the other hand, chooses apart of the remaining task and carries it out.2.1 The  P lann ing  F rameworkPROVERB combines both of these approaches in a uni-form planning framework \[Hua94c\].
The hierarchicalplanning is realized by so-called top-down presentationoperators that split the task of presenting a particularproof into subtasks of presenting subproofs.
While the?
overall planning mechanism follows the RST-based plan-ning approach \[Hov88, Moo89, Rei91\], the planning oper-ators resemble more the schemata in schema-based plan-ning \[McK85, Par88\].
Bottom-up resentation operatorsare devised to simulate the unplanned aspect, where thenext intermediate conclusion to be presented is chosen un-der the guidance of the local focus mechanism.
It is calledbottom-up since one new intermediate conclusion or sub-proof is chosen and presented, using previously presentedintermediate conclusions as premises.The two kinds of presentation operators are treated if-ferently.
Since top-down operators embody explicit com-municative norms, they are given a higher priority.
Onlywhen no top-down presentation operator is applicable,will a bottom-up resentation operator be chosen.
Theoverall planning framework is realized by a function calledPresent.
Taking as input a subproof, Present repeatedlyexecutes a basic planning cycle until the input subproofis conveyed.
Each cycle carries out one presentation op-erator, where Present always tries first to choose andapply a top-down operator.
If impossible, a bottom-upoperator will be chosen.
The function Present is firstcalled with the entire proof as the presentation task.
Theexecution of a top-down presentation operator may gen-erate subtasks by calling it recursively.2.2 The  D iscourse  Mode l  and  the  At ten-t iona l  H ie rarchyThe discourse carried out so far is recorded in a discoursemodel.
Rather than recording the semantic objects andtheir properties, the intermediate conclusions of a ongoingargument or mathematical proof are stored.
Therefore,our discourse model consists basically of the part of theinput proof tree which has already been conveyed.
Thesegmentation f the discourse is described in section 3.The following are some notions useful for the formulationof the presentation operators:?
Task is the subproof in the input proof whose present-ation is the current ask.?
Local focus is the intermediate conclusion last presen-ted, the semantic objects involved in the local focus arecalled the focal centers.2.3 P roo f  Communicat ive  ActsPCAs are the primitive actions planned to achieve com-municative goals.
When enriched with reference de-cisions, they are called preverbal messages (PM).
Likespeech acts, PCAs can be defined in terms of the com-municative goals they fulfill as well as their possible verb-alizations.
Based on analysis on proofs in mathematicaltextbooks, thirteen PCAs are identified and employed inPROVERB, see \[Hua94b\] for details.
The simplist oneconveying the derivation of a new intermediate conclu-sion is illustrated in the introduction.
There are alsoPCAs that update the global attentional structure.
ThesePCAs also convey a partial plan for the further present-ation.
For instance, the PCA(Beg in -Cases  Goa l :  FormulaAssumptions: (A B))creates two attentional units with A and B as the as-sumptions, and Formula as the goal by producing theverbalization:"To prove Formula, let us consider the two cases byassuming A and B.
"2.4 Top-Down P lann ingTop-down presentation operators express communicativenorms concerning how a proof to be presented can be splitinto subproofs, as well as how the hierarchically struc-tured subproofs can be mapped onto some linear orderfor presentation.
Because it is not the main concernof this paper, we will look at only one such operator,which handles proof segments containing cases.
The cor-responding schema of such a proof tree is shown in Fig-ure 1, where the subproof rooted at ?L4 leads to F V G,while subproofs rooted at ?L2 and ?La are the two casesproving Q by assuming F or G, respectively.
Under twocircumstances a writer may recognize that he is confron-ted with a proof segment containing cases.
First, whenthe subproof that has the structure as given above is thecurrent presentation task, tested by (task ?L1) 1.
Second,1 Labels tand for the corresponding odes1467th International Generation Workshop * Kennebunkport, Maine ?
June 21-24, 1994F G: : :7;4: FVa  CASE?L1 :A   OFigure 1: Proof Schema Casewhen the disjunction FVG has just been presented in thebottom-up mode, tested by (local-focus ?L4).
In both cir-cumstances, a communication norm motivates the writerto first present he part leading to F V G (in the secondcase this subgoal has already been achieved), and then toproceed with the two cases.
This norm also requires thatcertain PCAs be used to mediate between parts of proofs.This procedure is ,captured by the presentation operatorbelow.Case-Implicit?
Proof: as given in Figure 1?
Applicability Condition: ((task ?L1) V(local-focus ?L4)) A (not-conveyed (?L2 ?L3))?
Acts:1. if ?L4 has not been conveyed, then present ?L4 (sub-goal 1)2. a PCA with the verbalization: "First, let us considerthe first case by assuming F."3. present ?L2 (subgoal 2)4. a PCA with the verbalization: "Next, we considerthe second case by assuming G."5. present ?L3 (subgoal 3)6. mark ?L1 as conveyed?
features: (top-down compulsory implicit)2.5 Bot tom-up  Presentat ionThe bottom-up resentation process simulates the un-planned part of proof presentation.
Instead of splittingpresentation goals into subgoals, it follows the local deriv-ation relation to find a proof node to be presented next.2.5.1 The Local FocusThe node to be presented next is suggested by the mech-anism of local focus.
Although logically any proof nodehaving the local focus as a child could be chosen for thenext step, usually the one with the greatest semantic over-lap with the focal centers is preferred.
As mentionedabove, focal centers are semantic objects mentioned inthe proof node which is the local focus.
This is based onthe observation that if one has proved a property aboutsome semantic objects, one will tend to continue to talkabout these particular objects, before turning to new ob-jects.
Let us examine the situation when the proof belowis awaiting presentation.\[1\]: P(a,b) \[1\]: P(a,b), \[3\]: S(c)\[2\]: Q(a,b)' \[4\]: R(b,c)\[5\]: Q(a, b) A R(b, c)Assume that node \[1\] is the local focus, {a, b} is the setof focal centers, \[3\] is a previously presented node andnode \[5\] is the current task.
\[2\] is chosen as the nextnode to be presented, since it does not (re)introduce anynew semantic element and its overlapping with the focalcenters ({a, b}) is larger than the overlap of \[4\] with thefocal centers ({b}).2.5.2 The Bottom-Up Presentat ion  OperatorsUnder different circumstances the derivation of the next-node is also presented in different ways.
The corres-ponding presentation k owledge is encoded as bottom-uppresentation operators.
In this paper, we only examinethe most frequently used bottom-up operator below:Der ive-Bottom-Up* Proof: ?Node1,.. "7 ?Noden ?M?Noden+l* Applicability Condition: ?Noden+l is suggested by thefocus mechanism as the next node, and ?Node1, ...,?Noden are conveyed.?
Acts: a PCA that conveys the fact that the conclu-sion ?Noden+l is derived from the premises ?Node1,..., ?Noden by applying the method ?M.?
Features: (bottom-up general explicit detailed)If the conclusion, the premises and the method are in-stantiated to a E $1, (a E $2, $1 E $2), and def-subsetrespectively, the following verbalization can be produced:"Since a is an element of $1, and S1 is a subset of $2, ais an element of $2 according to the definition of subset.
"Currently seven bottom-up operators are integrated inPROVERB.3 The Attent ional  HierarchyThe distinction between planned and unplanned present-ation leads to a very natural segmentation f the discourseinto an attentional hierarchy, since following the theoryof Grosz and Sidner \[GS86\], there is a one-to-one cor-respondence between the intentional hierarchy and theattentional hierarchy.
In this section, we illustrate theattentional hierarchy with the help of an example, whichwill be used to discuss reference choices.The input proof in Figure 2 2 is an ND style proof at theassertion level, abstracted from a machine-generated NDproof \[Hua94a\], for a theorem taken from a mathematicaltextbook.2The first 6 lines axe definitions and theorems use, which areomitted1477th International Generation Workshop ?
Kennebunkport, Maine * June 21-24, 1994NNo S;D Formula7 .
7; ?
group(F,*)Asubgroup(U,F,*)Aunit(F,l,*)Aunit(U, 1v,*)8.
7; ?
UCF9.
7; ?
1v E U10.
7; ?
3~x E U11.
;11 ?
u E U12.
7;11 ?
u* 1u = u13.
7;11 ?
u E F14.
7;11 ?
Iu E F15.
7;11 ?
semigroup(F, *)16.
7;11 ?
solution(u, u, 1u, F, *)17.
7;11 ?
u * 1 = u18.
7;11 ?
1 E F19.
7;11 ?
solution(u, u, 1, F, *)20.
7;11 ?
1 = IU21.
7; ?
1 = 1U22.
; ?
group(F, *) A subgroup(U, F, *) A unit(F, 1, *) Aunit(U, 1u,*) ~ 1 = IyF~eason(Hyp)(Def-subgroup 7)(Def-unit 7)(3 9)(Hyp)(Def-unlt 7 11)(Def-subset 8 11)(Defosubset 8 9)(Def-group 7)(Def-solutionl2 13 14 15)(Def-tm.it 7 13)(Def-unlt 7)(Def-solutionl3 17 18 15)(Th-solution 17 16 19)(Choice 10 20)(Ded 7 21)Figure 2: Abstracted Proof about Unit Element of SubgroupsTheorem:Let F be a group and U a subgroup of F. If 1 and luare unit elements of F and U respectively, then 1 = 1v.The definitions of semigroup,  group, and unit  are ob-vious, solution(a, b, c, F, *) should be read as "c is a solu-tion of the equation a * z = b in F."The proof-to be presented is represented in a linearizedversion of ND proofs.
In this formalism, every proof is asequence of proof lines, each of them is of the form:Label ~ ~- Conclusion (Justif ication reason-pointers)where Justification is either an ND inference rule, a defin-ition or theorem, which justifies the derivation of theConclusion using formulas in lines pointed to by reason-pointers as the premises.
~ can be ignored for our pur-pose.The corresponding discourse model after the comple-tion of the presentation is a proof tree shown in Figure3.
Children of nodes are given in the order as they havebeen presented.
The circles denote nodes which are firstderived at this place, and nodes in the form of small boxesare copies of some previously derived nodes, which areused as premises again.
The big boxes represent atten-tional units called proof units, created during the present-ation process.
The naturalness of this segmentation islargely due to the naturalness of the top-down presenta-tion operators.
For example, unit U2 has two subordinateunits U3 and U4.
This reflects a natural shift of atten-tion between a subproof that derives a formula of thepattern 3~P(x)  (node 10, 3~x E U), and the subproofthat proceeds after assuming a new constant u satisfyingP(u)  (node 11, ul E U).
There are also elementary unitscomposed of multiple PCAs, such as U5 and U6.
Theyproduce two important premises required by a theoremabout the concept solution, which are applied at node20.
It is interesting to node that elementary attentionalunits that contain multiple PCAs would be impossible, ifwe did not distinguish between hierarchical planning andlocal organization.Adapting the theory of Reichman for our purpose\[Rei85\], we assume that each proof unit may have oneof the following status:?
a unit is said to be.
open, if its root is still awaiting tobe conveyed.- The active proof unit is the innermost proof unit con-taining the local focus.
There is exactly one activeproof unit at any moment.- The controlling proof unit is the innermost proof unitcontaining the active unit.- precontrol proof units are proof units containing thecontrolling proof unit.?
Closed units are proof units containing only conveyedproof nodes.4 A Classi f icat ion of ReferenceFormsThis section presents a classification of the possible formswith which mathematicians refer to intermediate conclu-sions previously proved (called reasons) or to methods ofinference.
The classification is based on our analysis ofproofs presented in mathematical  textbooks.4.1 Reference  Forms for ReasonsThree reference forms have been identified for reasons innaturally occurring proofs:1.
The omit form: where a reason is not mentioned at all.2.
The explicit form: where a reason is literally stated.For instance, if the omit form and the explicit formare adopted for the first respectively second reason inthe PCA in Section 1, the sentence may be produced:"Since u is an element in U, u * 1u = u."3.
The implicit form: By an implicit form we mean thatalthough a reason is not verbalized irectly, an implicit1487th International Generation Workshop ?
Kennebunkport, Maine ?
June 21-24, 1994usU4?'
C3 io, iIIU2UXFigure 3: Proof Tree for Satz 1.9hint is nevertheless given in other components of thePCA.
That  is, either in the verbalization of the infer-ence method, or in that of the conclusion.
For example,in the verbalization below"Since u is an element in U, u*  1v = u by thedefinition of unit.
"the first reason of the PCA in Section 1, "since 1v isthe unit element of U" is hinted at by the inferencemethod which reads "by the definition of unit".Note that although omit and implicit forms lead to anidentical surface structure, the existence of an implicithint in the other part of the verbalization affects a reader'sunderstanding.4 .2  Reference  Forms fo r  MethodsPROVERB must select referring expressions for methodsof inference in PCAs as well.
Below are the three referenceforms identified, which are analogous to the correspond-ing cases for reasons:1. the explicit form: this is the case where a writer maydecide to indicate explicitly which inference rule he isusing.
For instance, explicit translations of domain-specific rules could look like: "by the definition of unitelement", or "by the uniqueness of solution."
ND ruleshave usually standard verbalizations.2.
the omit form: in this case a word such as "thus" or"therefore" will be used.3.
The implicit form: Similar to the implicit form forreasons, an implicit hint to a domain-specific inferencemethod can be given either in the verbalization of thereasons, or in that of the conclusion.5 Making Reference Choices forReasonsBecause reasons are intermediate conclusions proved pre-viously in context, their reference choices have much incommon with the problem of choosing anaphoric referringexpressions in natural anguage generation in general.
Anumber of theories have been put forward to account forthe pronominalization, which is usually ascribed to the fo-cus mechanism.
For this purpose, concepts like activated-ness, foregroundness and consciousness have been intro-duced.
More recently, the shift of focus has been furtherinvestigated in the light of a more structured flow of dis-course \[Rei85, GS86, Dal92\].
The issue of salience is alsostudied in a broader framework in \[PC93\].
Apart fromsalience, it is also shown that referring expressions arestrongly influenced by other aspects of human preference.For example, easily perceivable attributes and basic-levelattributes values are preferred \[DH91, Da192, RD92\].Common to all discourse based theories, the update ofthe focus status is tightly coupled to the factoring of theflux of text into segments.
As illustrated in section 3, webasically follow the approach of Grosz and Sidner \[GS86\]in that a direct correspondence b tween the plan hier-archy and the attentional spaces is assumed.With the segmentation problem settled, the referencechoices in our theory largely follow the approach of Reich-man.
Reichman handles the reference problem in a moregeneral framework of her discourse grammar \[Rei85\].Based on empirical data, Reichman argues that the choiceof referring expressions i constrained both by the statusof the discourse space and by the object's level of focuswithin this space.
In her theory, there are seven status as-signments a discourse space may have at any given time.Within a discourse space, four levels of focus can be as-1497th International Generation Workshop ?
Kennebunkport, Maine ?
June 21-24, 1994signed to individual objects: high, medium, low, or zero,since there are four major ways of referring to an objectusing English, namely, by using a pronoun, by name, by adescription, or implicitly.
Thirteen rules are formulatedto assign level of focus to objects when they are activ-ated, either with the initialization of a discourse unit orwhen they are added to the active unit.
Four rules furtherreassign the level of focus on reentrance to a suspendeddiscourse space.
Based on the status assignment of dis-course spaces, as well as the level of focus of individualobjects, four rules are formulated constraining adequatereferring expressions.In short, Reichman takes into account both the fore-ground and background status of discourse spaces as wellas the level of focus of individual objects.
As a simplifica-tion for argumentative discourse, the notions of structuralcloseness and textual closeness are introduced.The structural closeness of a reason reflects the fore-ground and background character of the innermost proofunit containing it.
Intuitively, reasons that may still re-main in the focus of attention at the current point fromthe structural perspective are considered as structurallyclose.
Otherwise they are considered as structurally dis-tant.
If a re ,on ,  for instance, is last mentioned or provedin the active proof unit (the unit a writer is currentlyworking on), it is more likely that this reason should stillremain in his focus of attention.
On the other hand, ifthe reason is in a closed unit, and is not the root, it isvery likely that the reason has already been moved outof the writer's focus of attention.
Although the notion offore- and backgroundness might actually be a continuum,our theory only distinguishes between reasons residing inproof units which are structurally close or structurally dis-rant.
Rules assigning this structural status are given asfollowing.1.
Reasons in the active unit are structurally close.2.
Reasons in the controlling unit are structurally close.3.
Reasons in closed units:(a) reasons that are the root of a closed proof unit imme-diate subordinate to the active unit are structurallyclose.
(b) Other reasons in a closed unit are structurally dis-tant.4.
Reasons in precontrol proof units are structurally dis-tant.Note that, the rules are specified with respect to theinnermost proof unit containing a proof node.
Rule 3means that only the conclusions of closed subordinatedsubproofs still remain in the focus of attention.
As aspecial treatment, premises of the entire theorem will bedefined as both structurally distant and far in distance,if they are not repeated at the beginning of the proof.The textual closeness i used as an approximation to thelevel of focus of an individual reason.
In general, the levelof focus of an object is established when it is activated,and decreases with the flow of discourse.
In Reichman'stheory, although four levels of focus can be establishedupon activation, only one is used in the formulation of thefour reference rules.
In other words, it suffices to track thestatus high alone.
Based on the discussion above, we useonly two values to denote the level of focus of individualintermediate conclusions, depending solely on the textualdistance between the last mentioning of a reason and thecurrent sentence where the reason is referred to.In summary, we assume that each intermediate conclu-sion is put into high focus when it is presented as a newlyderived result or cited as a reason supporting the deriv-ation of a further intermediate r sult.
This level of focusdecreases, either when a proof unit is moved out of theforeground of discussion, or with the increase of textualdistance.
On account of the above, the four referencerules used in our computational model are given below.Choices for  Re fer r ing  Express ions  for  Reasons1.
If a reason is both structurally and textually close, itwill be omitted.2.
If a reason is structurally close but textually far, firsttry to find an implicit form, if impossible, use an expli-cit form.3.
If a reason is structurally distant but textually close,first try to find an implicit form, if impossible, omit it.4.
An explicit form will be used for reasons that are bothstructurally and textually far.Notice that the result of applying rule 2 and rule 3depends on the fact that an implicit form is available,which often interacts with the verbalization of the restof the PCA.
In particular, it interacts with the referencechoices for inference methods.
In PROVERB as it cur-rently stands, the interaction is realized by associating akeyword with the verbalization of every predicate, func-tion, and assertion.
For instance, suppose the verbaliza-tion of unit(F, 1, *) as a reason is "since 1 is an unit ele-ment of F", and the verbalization of the definition of unitelement as an inference method is "by the definition ofthe unit element".
Both the predicate unit and the defin-ition are associated with the same keyword "unit".
Basedon this information, PROVERB assumes that the verb-alization of the reason unit(F, 1, *) and the verbalizationof the definition of unit element hint at each other.
Dis-tance is currently calculated in an ad hoc way by countingthe PCAs uttered after the corresponding reason was lastexplicitly mentioned.1507th International Generation Workshop ?
Kennebunkport, Maine ?
June 21-24, 19946 Making Reference Choices forInference MethodsLike the reference to a reason, the explicitness or im-plicitness of referring to an inference method at a par-ticular point depends on whether the particular methodcan be easily called into the foreground of the focus ofattention.
In contrast o references to reasons, this isevidently irrelevant to the particular discourse structureconcerned.
Actually it is less concerned with the proofcontext han with the user's familiarity with the partic-ular inference method.
This referring behavior emains?
the same throughout a whole discourse, similar to thereferring behavior relating to the so-called canonical sali-ence \[PC93\].
In the case of applications of definitions ortheorems, it depends on the reader's familiarity with thecorresponding definition or theorem.
This is found to besensitive to the global hierarchy of the mathematical the-ories.
As it currently stands, PROVERB distinguishesonly between assertions in the underlying theories andassertions belonging to the current theory.
The referencechoice rules for inference methods currently incorporatedare listed as follows.
?Choices for Referring Expressions for Methods1.
Reference Choices for ND Inference Rules(a) All non-structural ND rules (such as eliminationsof quantifiers) will be omitted (In the case of PCADERIVE, a word like "thus", "hence", etc.
will beused), because the readers are supposed to be famil-iar with the elementary logic.
(b) All structural ND rules (such as the one dividingproofs into eases) will be explicitly given.
Althoughthey are also familiar to the readers, they providelandmarks for the overall proof structure.2.
Reference Choices for Applications of AssertionsReaders are assumed to be familiar with definitions andtheorems of the "underlying theories" upon which thecurrent theory is based.
For example, when we arereasoning about properties of group theory we assumethat the users are familiar with basic set theory:(a) Applications of definitions and theorems of underly-ing theories will be omitted.
(b) For applications ofdefinitions or theorems of the cur-rent theory, try first to find an implicit form.
If im-possible, an explicit indication will be given.7 An Integrated Algor i thm forReference ChoicesAs illustrated above, reference choices for reasons and formethods interact with each other.
This section describesan algorithm that combines the reference choice rules forreason and the reference choice rules for methods, to pro-duce preverbal messages (PMs) from PCAs.
As such, themain task is to utilize the interaction between the twosets of reference rules to eliminate the indeterminacy inboth of the rule sets.
The indeterminacy lies in referencerule 1 and 2 in Section 5 and in reference rule 2(b) in Sec-tion 6, which need information on decisions made by theother set of rules.
In other words, decisions in one ruleset may help to narrow the alternatives in the other set.PROVERB first makes the reference choice for the infer-ence method.
While doing so, it looks ahead and takesthe possible reference choices for reasons into account.
Ifstill no unique choice can be made, the decision is madeaccording to a predetermined order.
Concretely the ex-plicit form will be chosen for rule 2(b) in Section 6.
Afterthe reference form of the method has been determined, aunique reference form can always be determined for thereasons.
The concrete algorithm is omitted ue to spacerestrictions.Now we continue with the subgroup example introducedin section 2.
The PCA below aims to convey the deriv-ation of proof node 9 (1v E U) from a part of node 7(unit(Iv, U, *)), justified by the application of the defin-ition of the unit element in semigroups.
(Derive Der ived-Formula:  iu EUReasons : unit(iU, U, *)Method: Def -Semigroup*Uni t )The current unit is U3.
U2 and U1 are the controllingand precontrol unit, respectively, see Figure 3.
Since node7 is in the controlling unit and is mentioned last only twosteps earlier, it is therefore judged as both structurallyclose and near in distance.
Rule 1 in Section 5 is applic-able and the omit form is chosen.
Since the definition ofthe unit element resides in the current heory, Rule 2(b)in Section 6 suggests that its application be referred toeither implicitly or explicitly.
Because the implicit optionis ruled out by the omit form for reasons, the explicit formis chosen.
The PM below is therefore generated:(Derive Derived-Formula: iu qUMethod: Def -Semigroup*Uni t )Next let us jump over some steps and consider the PCAbelow.
(Derive Der ived-Formula:  u * IU = uReasons :  (unit(1u, U,*), u qU)Method: Def-unit)This PCA is generated to convey that node 12 (u *1u) can be derived from part of node 7 (unit(1u, U,*))and node 11 (u E U) by applying the definition of theunit element.
U5 is now the current unit, with U4 andU2 as controlling and precontrol unit.
U3 is the uniqueclosed unit.
Reason node 7 is now structurally distantbut still near in distance, and node 11 is in the currentunit, and is the node last conveyed, therefore, both 7 and1517th International Generation Workshop ?
Kennebunkport, Maine ?
June 21-24, 199411 are omitted.
The reference form for the definition ofunit element is decided upon as above.
The PM below isgenerated:(Derive Der ived-Formula :  u ?
iu  ---- uMethod : Def -Semigroup*Un i t )Fifteen preverbal messages are generated by PRO VERBfor our example.
One sentence in English is gener-ated from each PM by the surface generator TAG-GEN\[Kilger94\].
The text as generated follows.Let F be a group, U be a subgroup of F, 1 be a unitelement o fF  and 1u be a unit element of U. Accordingto the definition of unit element, 1u E U. Thereforethere is an X ,  X E U.
Now suppose that ul is such anX .
According to the definition of unit element, ut * lu  =ul.
Since U is a subgroup of F,  U C F. Therefore1u E F. Similarly ul E F, since ul E U.
Since F is agroup, F is a semigroup.
Because ul * 1u = ul, 1u is asolution of the equation ul * X = u~.
Since 1 is a unitelement o fF ,  ul * 1 = ul.
Since 1 is a unit elemento fF ,  1 E F.  Because ul E F,  1 is a solution of theequation ul * X = ul.
Since F is a group, 1u = 1 by theuniqueness_of solution.
This conclusion is independentof the choice of the element ul .8 Conc lus ionThis paper describes the way in which PROVERB refersto previously conveyed intermediate r sults and inferencemethods while verbalizing natural deduction style proofs.By distinguishing between the planned and unplannedpart of NL generation, PRO VERB achieves a natural seg-mentation of context into an attentional hierarchy.
Basedon this segmentation, PROVERB makes reference de-cisions basically according to a discourse theory adaptedfrom Reichmann for this special application.
The firstexperience shows that output texts are of good quality.Currently, it proves difficult to compare text generatedby PROVERB with naturally occurring texts, since thelatter are usually at a still higher level of abstraction thenthe assertion level proofs we can reconstruct \[Hua94a\].Nonetheless it might still be useful to build up a smallcorpus of texts.
On the other hand, the naturMness ofreferences could also be improved by further experiment-ing with different settings of the ad hoc thresholds inthe system.
We are also exploring more flexible lexiconchoices as well as refinement of text planning process.Acknowledgment  This work was supported bythe Deutsche Forschungsgemeinschaft, SFB 314 (D2).Thanks are due to Dan Nesmith, who carefully read thisfinal version.
I am also grateful to the two anonymousreviewers for their critical and constructive remarks.References\[Che76\] D. Chester.
The translation of formal proofs intoEnglish.
AL 7, 1976.\[Dal92\] R. Dale.
Generating Referring Ezpressions.
MITPress, 1992.\[DH91\] R. Dale and N. Haddock.
Content determinationin the generation of referring expressions.
Compu-tational Intelligence, 7(4), 1991.\[EP93\] A. Edgar and F. J. Pelletier.
Natural language x-planation of natural deduction proofs.
In Proc.
o\]the lth Conj.
o\] the Pacific Assoc.
for Comp.
Lin-guistics.
Simon Fraser University, 1993.\[Gen35\] G. Gentzen.
Untersuchungen fiber das logischeSchliet3en I.
Math.
Zeitschrift, 39, 1935.\[GS86\] B. J .
Grosz and C. L. Sidner.
Attention, intentions,and the structure of discourse.
Computational Lin-guistics, 12(3), 1986.\[Hov88\] E. H. Hovy.
Generating Natural Language underPragmatic Constraints.
Lawrence Erlbaum, 1988.\[Huag0\] X Huang.
Reference choices in mathematical proofs.In Proc.
of ECAI.90, Pitman, 1990.\[Hua94a\] X. Huang.
Reconstructing proofs at the assertionlevel.
In Proc.
o\] l~th CADE.
1994, forthcoming.\[Hua94b\] X. Huang.
Human Oriented Proof Presentation: AReconstructive Approach.
PhD thesis, University ofSaarbrficken, 1994, forthcoming.\[Hua94c\] X. Huang.
Planning argumentative t xt.
In Proc.
of15th COLING.
1994, forthcoming.\[Kilger94\] A. Kflger.
Using UTAGs for Incremental and Par-allel Generation.
Computational Intelligence, 1994,forthcoming.\[Lev89\] W. J. M. Levelt.
Speaking: From Intention to Artic-ulation.
MIT Press, 1989.\[McD83\] David D. McDonald.
Natural anguage generation asa computational problem.
In Brady/Berwick: Com-putational Models o\] Discourse.
MIT Press, 1983.\[McK85\] K. R. McKeown.
Text Generation.
Cambridge Uni-versity Press, 1985.\[Moo89\] J. D. Moore.
A Reactive Approach to Explanationin Expert and Advice-Giving Systems.
PhD thesis,Univ.
of California, 1989.\[Och79\] E. Ochs.
Planned and unplanned iscourse.
Syntaxand Semantics, 12, 1979.\[Par88\] C. Paris.
Tailoring object descriptions to a user'slevel of expertise.
Computational Linguistics, 14,1988.\[PC93\] T. Pattabhiraman d N Cercone.
Decision-theoreticsalience interactions in language generation.
Proc.
ofI\]CAI-93, Morgan Kanfmann, 1993.\[RD92\] E. Reiter and R. Dale.
A fast algorithm for the gener-ation of referring expressions.
In Proc.
o\] COLING-92, 1992.\[Rei85\] R. Reichman.
Getting Computer to Talk Like Youand Me.
MIT Press, 1985.\[Rei91\] N. Reithinger.
Eine parallele Architektur zur inkre-menteller Dialogbeitr~ige.
PhD thesis, University ofSaarbrficken, 1991.\[Sib90\] P. Sibun.
The local organization of text.
In Proc.
ofthe 5th International Natural Language GenerationWorkshop, 1990.152
