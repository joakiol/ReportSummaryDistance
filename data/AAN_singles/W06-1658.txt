Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP 2006), pages 492?500,Sydney, July 2006. c?2006 Association for Computational LinguisticsEntity Annotation based on Inverse Index OperationsGanesh Ramakrishnan, Sreeram Balakrishnan, Sachindra JoshiIBM India Research LabsIIT Delhi, Hauz Khas,New Delhi, India{ganramkr, sreevb, jsachind}@in.ibm.comAbstractEntity annotation involves attaching a la-bel such as ?name?
or ?organization?
to asequence of tokens in a document.
All thecurrent rule-based and machine learning-based approaches for this task operate atthe document level.
We present a newand generic approach to entity annotationwhich uses the inverse index typically cre-ated for rapid key-word based searchingof a document collection.
We define a setof operations on the inverse index that al-lows us to create annotations defined bycascading regular expressions.
The entityannotations for an entire document cor-pus can be created purely of the indexwith no need to access the original docu-ments.
Experiments on two publicly avail-able data sets show very significant perfor-mance improvements over the document-based annotators.1 IntroductionEntity Annotation associates a well-defined labelsuch as ?person name?, ?organization?, ?place?,etc., with a sequence of tokens in unstructuredtext.
The dominant paradigm for annotating adocument collection is to annotate each documentseparately.
The computational complexity of an-notating the collection in this paradigm, dependslinearly on the number of documents and the costof annotating each document.
More precisely, itdepends on the total number of tokens in the doc-ument collection.
It is not uncommon to have mil-lions of documents in a collection.
Using this par-adigm, it can take hours or days to annotate suchbig collections even with highly parallel serverfarms.
Another drawback of this paradigm is thatthe entire document collection needs to be re-processed whenever new annotations are required.In this paper, we propose an alternative para-digm for entity annotation.
We build an index forthe tokens in the document collection first.
Us-ing a set of operators on the index, we can gener-ate new index entries for sequences of tokens thatmatch any given regular expression.
Since a largeclass of annotators (e.g., GATE (Cunningham etal., 2002)) can be built using cascading regular ex-pressions, this approach allows us to support anno-tation of the document collection purely from theindex.We show both theoretically and experimentallythat this approach can lead to substantial reduc-tions in computational complexity, since the orderof computation is dependent on the size of the in-dexes and not the number of tokens in the doc-ument collection.
In most cases, the index sizesused for computing the annotations will be a smallfraction of the total number of tokens.In (Cho and Rajagopalan, 2002) the authors de-velop a method for speeding up the evaluation ofa regular expression ?R?
on a large text corpus byuse of an optimally constructed multi-gram indexto filter documents that will match ?R?.
Unfortu-nately, their method requires access to the docu-ment collection for the final match of ?R?
to thefiltered document set, which can be very time con-suming.
The other bodies of related prior workconcern indexing annotated data (Cooper et al,2001; Li and Moon, 2001) and methods for doc-ument level annotation (Agichtein and Gravano,2000; McCallum et al, 2000).
The work on index-ing annotated data is not directly relevant, sinceour method creates the index to the annotations di-rectly as part of the algorithm for computing theannotation.
(Eikvil, 1999) has a good survey ofexisting document level IE methods.
The rele-vance to our work is that only a certain class ofannotators can be implemented using our method:namely anything that can be implemented usingcascading weighted regular expressions.
Fortu-492nately, this is still powerful enough to enable alarge class of highly effective entity annotators.The rest of the paper is organized as follows.
InSection 2, we present an overview of the proposedapproach for entity annotation.
In Section 3, weconstruct an algorithm for implementing a deter-ministic finite automaton (DFA) using an inverseindex of a document collection.
We also comparethe complexity of this approach against the directapproach of running the DFA over the documentcollection, and show that under typical conditions,the index-based approach will be an order of mag-nitude faster.
In Section 4, we develop an alter-native algorithm which is based on translating theoriginal regular expression directly into an orderedAND/OR graph with an associated set of indexlevel operators.
This has the advantage of oper-ating directly on the much more compact regularexpressions instead of the equivalent DFA (whichcan become very large as a result of the NFA toDFA conversion and epsilon removal steps).
Weprovide details of our experiments on two publiclyavailable data sets in Section 5.
Finally we presentour conclusions in Section 6.2 OverviewFigure 1 shows the process for entity annotationpresented in the paper.
A given document collec-tion D is tokenized and segmented into sentences.The tokens are stored in an inverse index I .
Theinverse index I has an ordered list U of the uniquetokens u1, u2, ..uW that occur in the collection,where W is the number of tokens in I .
Addition-ally, for each unique token ui, I has a postingslist L(ui) =< l1, l2, .
.
.
lcnt(ui) > of locations inD at which ui occurs.
cnt(ui) is the length ofL(ui).
Each entry lk, in the postings list L(ui),has three fields: (1) a sentence identifier, lk.sid,(2) the begin position of the particular occurrenceof ui, lk.first and (3) the end position of the sameoccurrence of ui, lk.last.We require the input grammar to be the sameas that used for named entity annotations in GATE(Cunningham et al, 2002).
The GATE architec-ture for text engineering uses the Java Annota-tions Pattern Engine (JAPE) (Cunningham, 1999)for its information extraction task.
JAPE is a pat-tern matching language.
We support two classesof properties for tokens that are required by gram-mars such as JAPE: (1) orthographic propertiessuch as an uppercase character followed by lowercase characters, and (2) gazetteer (dictionary) con-tainment properties of tokens and token sequencessuch as ?location?
and ?person name?.
The set oftokens along with entity types specified by eitherof these two properties are referred to as BasicEntities.
The instances of basic entities specifiedby orthographic properties must be single tokens.However, instances of basic entities specified us-ing gazetteer containment properties can be tokensequences.The module (1) of our system shown in Fig-ure 1, identifies postings lists for each basic en-tity type.
These postings lists are entered as indexentries in I for the corresponding types.
For ex-ample, if the input rules require tokens/token se-quences that satisfy Capsword or Location Dic-tionary properties, a postings list is created foreach of these basic types.
Constructing the post-ings list for a basic entity type with some ortho-graphic property is a fairly straightforward task;the postings lists of tokens satisfying the ortho-graphic properties are merged (while retaining thesorted order of each postings list).
The mecha-nism for generating the postings list of basic en-tities with gazetteer properties will be developedin the following sections.
A rule for NE an-notation may require a token to satisfy multipleproperties such as Location Dictionary as well asCapsword.
The posting list for tokens that satisfymultiple properties are determined by perform-ing an operation parallelint(L,L?)
over the post-ing lists of the corresponding basic entities.
Theparallelint(L,L?)
operation returns a posting listsuch that each entry in the returned list occurs inboth L as well as L?.
The module (2) of our sys-tem shown in Figure 1 identifies instances of eachannotation type, by performing index-based oper-ations on the postings lists of basic entity types andother tokens.3 Annotation using Cascading RegularExpressionsRegular expressions over basic entities have beenextensively used for NE annotations.
The Com-mon Pattern Specification Language (CSPL)1specifies a standard for describing Annotators thatcan be implemented by a series of cascading regu-lar expression matches.Consider a regular expression R over an al-phabet ?
of basic entities, and a token sequence1http://www.ai.sri.com/?appelt/TextPro493Figure 1: Overview of the entity annotation process described in this paperT = {t1, .
.
.
, tW }.
The annotation problem aimsat determining all matches of regular expressionR in the token sequence T .
Additionally, NE an-notations do not span multiple sentences.
We willtherefore assume that the length of any annotatedtoken sequence is bounded by ?, where ?
canbe the maximum sentence length in the documentcollection of interest.
In practice, ?
can be evensmaller.3.1 Computing Annotations using a DFAGiven a regular expression R, we can convert itinto a deterministic finite automate (DFA) DR. ADFA is a finite state machine, where for each pairof state and input symbol, there is one and onlyone transition to a next state.
DR starts process-ing of an input sequence from a start state sR, andfor each input symbol, it makes a transition to astate given by a transition function ?R.
WheneverDR lands in an accept state, the symbol sequencetill that point is accepted by DR. For simplicity ofthe document and index algorithms, we will ignoredocument and sentence boundaries in the follow-ing analysis.Let @ti,i+?, 1 ?
i ?
W ??
be a subsequenceof T of length ?.
On a given input @ti,i+?, DRwill determine all token sequences originating at tithat are accepted by the regular expression gram-mar specified through DR.
Figure 2 outlines thealgorithm findAnnotations that locates all tokensequences in T that are accepted by DR.Let DR have {S1, .
.
.
, SN} states.
We assumethat the states have been topologically ordered sothat S1 is the start state.
Let ?
be the time takento consume a single token and advance the DFAto the next state (this is typically implemented asa table or hash look-up).
The time taken by the al-findAnnotations(T,DR)Let T = {t1, .
.
.
, tW }for i = 1 to W ??
dolet @ti,i+?
be a subsequence of length ?
startingfrom ti in Tuse DR to annotate @ti,i+?end forFigure 2: The algorithm for finding all the occur-rences of R in a token sequence T .gorithm findAnnotations can be obtained by sum-ming up the number of times each state is vis-ited as the input tokens are consumed.
Clearly,the state S1 is visited W times, W being the totalnumber of symbols in the token sequence T .
Letcnt(Si) give the total number of times the state Sihas been visited.
The complexity of this methodis:CD = ?i=N?i=1cnt(Si) = ?
[W +i=N?i=2cnt(Si)](1)3.2 Computing Regular Expression Matchesusing IndexIn this section, we present a new approach for find-ing all matches of a regular expression R in a to-ken sequence T , based on the inverse index I of T .The structure of the inverse index was presented inSection 2.
We define two operations on postingslists which find use in our annotation algorithm.1.
merge(L,L?
): Returns a postings list suchthat each entry in the returned list occurs either inL or L?
or both.
This operation takes O(|L|+ |L?|)time.2.
consint(L,L?
): Returns a postings list suchthat each entry in the returned list points to a to-ken sequence which consists of two consecutive494subsequences @sa and @sb within the same sen-tence, such that, L has an entry for @sa and L?has an entry for @sb.
There are several meth-ods for computing this depending on the relativesize of L and L?.
If they are roughly equal insize, a simple linear pass through L and L?, anal-ogous to a merge, can be performed.
If there isa significant difference in sizes, a more efficientmodified binary search algorithm can be imple-mented.
The details are shown in Figure 3.
Theconsint(L,L?
)Let M elements of L be l1 ?
?
?
lMLet N elements of L?
be l?1 ?
?
?
lNif M < N thenset j = 1for i = 1 to M doset k = 1, keep doubling k untill?j .first ?
li.last < l?j+k.firstbinary search the L?
in the interval j ?
?
?
kto determine the value of p such thatl?p.first ?
li.last < l?p+1.firstif l?p.first = li.last a match exists, copy to outputset j = p+ 1end forelseSame as above except l and l?
are reversedend ifFigure 3: The modified binary search algorithmfor consintcomplexity of this algorithm is determined by thesize qi of the interval required to satisfy l?j .first ?li.last < l?j+qi .first (assuming |L| < |L?|).
Itwill take an average of log2(qi) operations to de-termine the size of interval and log2(qi) opera-tions to perform the binary search, giving a to-tal of 2 log2(qi).
Let q1 ?
?
?
qM be the sequenceof intervals.
Since the intervals will be at mosttwo times larger than the actual interval betweenthe nearest matches in L?
to L, we can see that|L?| ?
?Mi=1 qi ?
2 ?
|L?|.
Hence the worst casewill be reached when qi = 2|L?|/|L| with a timecomplexity given by 2|L| (log2(|L?|/|L|) + 1), as-suming |L| < |L?|.To support annotation of a token sequence thatmatches a regular expression only in the con-text of some regular expression match on its leftand/or right, we implement simple extensions tothe consint(L1, L2) operator.
Details of the ex-tensions are left out from this paper owing to spaceconstraints.3.3 Implementing a DFA using the InverseIndexIn this section, we present a method that takes aDFA DR and an inverse index I of a token se-quence T , to compute a postings list of subse-quences of length at most ?, that match the regu-lar expression R.Let the set S = {S1, .
.
.
, SN} denote the setof states in DR, and let the states be topologi-cally ordered with S1 as the start state.
We as-sociate an object lists,k with each state s ?
S and?1 ?
k ?
?.
The object lists,k is a posting listof all token sequences of length exactly k that endin state s. The lists,k is initialized to be emptyfor all states and lengths.
We iteratively computelists,k for all the states using the algorithm givenin Figure 4.
The function dest(Si) returns a setof states, such that for each s ?
dest(Si), thereis an arc from state Si to state s. The functionlabel(Si, Sj) returns the token associated with theedge (Si, Sj).for k = 1 to ?
dofor i = 1 to N dofor s ?
dest(Si) doif i == 1 thent = L(label(Si, s))elset = consint(listSi,k?1, L(label(Si, s)))end iflists,k = merge(lists,k, t)end forend forend forFigure 4: The algorithm for building the index toall token sequences in T that match R.At the end of the algorithm, all token sequencescorresponding to postings lists lists,i, s ?
S, 1 ?i ?
?
are sequences that are matched by the reg-ular expression R.3.4 Complexity Analysis for the Index-basedApproachThe complexity analysis of the algorithm givenin Figure 4 is based on the observation that,?k=?k=1 |listSi,k| = cnt(Si).
This holds, sincelistSi,k contains an entry for all sequences thatvisit the state Si and are of length exactly k. Sum-ming the length of these lists for a particular stateSi across all the values of k will yield the totalnumber of sequences of length at most ?
that visitthe state Si.For the algorithm in Figure 3, the time taken by495one consint operation is given by 2?
(|listSi,k| ?
(log(?ijk) + 1)) where ?
is a constant that varieswith the lower level implementation.
?ijk =|L(label(Si,Sj))||listSi,k|is the ratio of the postings list sizeof the label associated with the arc from Si toSj to the list size of Si at step k. Note that?ijk ?
1.
Let prev(Si) be the list of pre-decessor states to Si.
The time taken by allthe merge operations for a state Si at step kis given by ?
(log(|prev(Si)|)|listSi,k|) Assum-ing all the merges are performed simultaneously,?
(log(|prev(Si)|) is the time taken to create eachentry in the final merged list, where ?
is a con-stant that varies with the lower level implementa-tion.
Note this scales as the log of the number oflists that are being merged.The total time taken by the algorithm given inFigure 4 can be computed using the time spent onmerge and consint operations for all states andall lengths.
Setting ?
?is = maxk ?isk, the total timeCI can be given as:CI =i=N?i=2???
log(|prev(Si)|) + 2??s?dest(Si)log(??is)??
cnt(Si)(2)Note that in deriving Equation 2, we have ig-nored the cost of merging list(Sa, k) for k =1 ?
?
??
for the accept states.3.5 Comparison of ComplexitiesTo simplify further analysis, we can replacecnt(Si) with fcnt(Si) where fcnt(Si) =cnt(Si)/W .
If we assume that the token distribu-tion statistics of the document collection remainconstant as the number of documents increases,we can also assume that fcnt(Si) is invariant toW .
Since ?ijk is given by a ratio of list sizes, wecan also consider it to be invariant to W .
We nowassume ?
?
?
?
?
since these are implementa-tion specific times for similar low level computeoperations.
With this assumptions from Equations1 and 2, the ratio CD/CI can be approximated by:1 +?Ni=2 fcnt(Si)?Ni=2[?s?dest(Si)2 log(?
?is) + log(|prev(Si)|)]fcnt(Si)(3)The overall ratio of CD to CI is invariant to Wand depends on two key factors fcnt(Si) and?s?dest(Si) log(??is).
If fcnt(Si)  1, the ratiowill be large and the index-based approach will bemuch faster.
However, if either fcnt(Si) starts ap-proaching 1 or?s?dest(Si) log(?
?is) starts gettingvery large (caused by a large fan out from Si), thedirect match using the DFA may be more efficient.Intuitively, this makes sense since the main ben-efit of the index is to eliminate unnecessary hashlookups for tokens do not match the arcs of theDFA.
As fcnt(Si) approaches 1, this assumptionbreaks down and hence the inherent efficiency ofthe direct DFA approach, where only a single hashlookup is required per state regardless of the num-ber of destination states, becomes the dominantfactor.3.6 Comparison of Complexities for SimpleDictionary DFATo illustrate the potential gains from the index-based annotation, consider a simple DFA DR withtwo states S1 and S2.
Let the set of unique to-kens A be {a, b, c ?
?
?
z}.
Let E be the dictionary{a, e, i, o, u}.
Let DR have five arcs from S1 to S2one for each element in E. The DFA DR is a sim-ple acceptor for the dictionary E, and if run overa token sequence T drawn from A, it will matchany single token that is in E. For this simple casefcnt(S2) is just the fraction of tokens that occurin E and hence by definition fcnt(S2) ?
1.
Sub-stituting into 3 we getCDCI=1 + fcnt(S2)2 log(5)fcnt(S2)(4)As long as fcnt(S2) < 0.27, this ratio will alwaysbe greater than 1.4 Inverse Index-based Annotation usingRegular ExpressionsA DFA corresponding to a given regular expres-sion can be used for annotation, using the inverseindex approach as described in Section 3.3.
How-ever, the NFA to DFA conversion step may resultin a DFA with a very large number of states.
Wedevelop an alternative algorithm that translates theoriginal regular expression directly into an orderedAND/OR graph.
Associated with each node in thegraph is a regular expression and a postings listthat points to all the matches for the node?s regu-lar expression in the document collection.
Thereare two node types: AND nodes where the outputlist is computed from the consint of the postingslists of two children nodes and OR nodes wherethe output list is formed by merging the posting496lists of all the children nodes.
Additionally, eachnode has two binary properties: isOpt and self-Loop.
The first property is set if the regular ex-pression being matched is of the form ?R?
?, where???
denotes that the regular expression R is op-tional.
The second property is set if the regularexpression is of the form ?R+?, where ?+?
is theKleen operator denoting one or more occurrences.For the case of ?R*?, both properties are set.The AND/OR graph is recursively built by scan-ning the regular expression from left to right andidentifying every sub-regular expression for whicha sub-graph can be built.
We use capital lettersR,X to denote regular expressions and small let-ters a, b, c, etc., to denote terminal symbols inthe symbol set ?.
Figure 5 details the algorithmused to build the AND/OR graph.
Effectively, theAND/OR graph decomposes the computation ofthe postings list for R into a ordered set of mergeand consint operations, such that the output L(v)for node v become the input to its parents.
Thegraph specifies the ordering, and by evaluating allthe nodes in dependency order, the root node willend up with a postings list that corresponds to thedesired regular expression.if R is empty thenReturn NULLelse if R is a symbol a ?
?
thenReturn createNode(name = a)elseDecompose R such that R ?
R?
<regexp>if <regexp> is empty thenif R?
== (X) or X+ or X?
or X?
thennode = createGraph(X)if R?
== X+ or X?
thennode.selfLoop = 1end ifif R?
== X?
or X?
thennode.isOpt = 1end ifelse if R?
== (X1|X2|..|Xk) thennode = createNode(name = R)node.nodetype = ORfor i = 1 to k donode.children[i] = createGraph(Xi)end forend ifelsenode = createNode(name = R)node.nodetype = ANDnode.children[1] = createGraph(R?
)node.children[2] = createGraph(<regexp>)end ifReturn nodeend ifFigure 5: createGraph(R)Figure 6: An example regular expression and cor-responding AND/OR graph4.1 Handling ???
and Kleen OperatorsThe isOpt and selfLoop properties of a node areset if the corresponding regular expression is ofthe form R?, R+ or R?.
To handle the R?
casewe associate a new property isOpt with the outputlist L(v) from node v, such that L(v).isOpt = 1if the v.isOpt = 1.
We also define two operationsconsint in Figure 7 and merge which accountfor the isOpt property of their argument lists.
Forconsint, the generated list has its isOpt set to1 if and only if both the argument lists have theirisOpt property set to 1.
The merge operation re-mains the same as merge, except that the resultantlist has isOpt set to 1 if any of its argument listshas isOpt set to 1.
The worst case time taken byconsint is bounded by 1 consint and 2 mergeoperations.To handle the R+ case, we define a new oper-ator consint(L,+) which returns a postings listL?, such that each entry in the returned list pointsto a token sequence consisting of all k ?
[1,?
]consecutive subsequences @s1,@s2 .
.
.
@sk, each@si, 1 ?
i ?
k being an entry in L. A sim-ple linear pass through L is sufficient to obtainconsint(L,+).
The time complexity of this op-eration is linear in the size of L?.
The isOpt prop-erty of the result list L?
is set to the same value asits argument list L.Figure 6 shows an example regular expres-sion and its corresponding AND/OR graph; ANDnodes are shown as circles whereas OR nodes areshown as square boxes.
Nodes having isOpt andselfLoop properties are labeled with +, ?
or ?.Any AND/OR graph thus constructed is acyclic.The edges in the graph represent dependency be-tween computing nodes.
The main regular expres-sion is at the root node of the graph.
The leafnodes correspond to symbols in ?.
Figure 8 out-lines the algorithm for computing the postings listof a regular expression by operating bottom-up onthe AND/OR graph.497consint(L,L?
)if ((L.isOpt == 0) and (L?.isOpt == 0)) thenReturn consint(L,L?
)end ifif ((L.isOpt == 0) and (L?.isOpt == 1)) thenReturn merge(L, consint(L,L?
))end ifif ((L.isOpt == 1) and (L?.isOpt == 0)) thenReturn merge(consint(L,L?
), L?
)end ifif ((L.isOpt == 1) and (L?.isOpt == 1)) thent = merge(consint(L,L?
), L?
)Return merge(t, L)end ifFigure 7: consintfor Each node v in the reverse topological sorting of GRdoif v.nodetype == AND thenLet v1 and v2 be the children of vL(v) = consint(L(v1), L(v2))else if v.type == OR thenL(v) = merge(L(v.child1), ?
?
?
, L(v.childn))end ifif v.selfLoop == 1 thenL(v) = consint(L(v),+)end ifif v.isOpt == 1 thenL(v).isOpt = 1end ifend forFigure 8: The algorithm for computing postingslist of a regular expression R using the inverse in-dex I and the corresponding AND/OR graph GR5 Experiments and ResultsIn this section, we present empirical compari-son of performance of the index-based annotationtechnique (Section 4) against annotation based onthe ?document paradigm?
using GATE.
The exper-iments were performed on two data sets, viz., (i)the enron email data set2 and (ii) a combination ofReuters-21578 data set3 and the 20 Newsgroupsdata set4.
After cleaning, the former data set was2.3 GB while the latter was 93 MB in size.
Ourcode is entirely in Java.
The experiments wereperformed on a dual 3.2GHz Xeon server with 4GB RAM.
The code for creation of the index wascustom-built in Java.
Prior to indexing, the sen-tence segmentation and tokenization of each dataset was performed using in-house Java versions of2http://www.cs.cmu.edu/?enron/3http://www.daviddlewis.com/resources/testcollections/reuters21578/4http://people.csail.mit.edu/jrennie/20Newsgroups/standard tools5.5.1 Rule Specification using JAPEJAPE is a version of CPSL6 (Common PatternSpecification Language).
JAPE provides finitestate transduction over annotations based on reg-ular expressions.
The JAPE grammar requires in-formation from two main resources: (i) a tokenizerand (ii) a gazetteer.
(1) Tokenizer: The tokenizer splits the text intovery simple tokens such as numbers, punctuationand words of different types.
For example, onemight distinguish between words in uppercase andlowercase, and between certain types of punctua-tion.
Although the tokenizer is ca pable of muchdeeper analysis than this, the aim is to limit itswork to maximise efficiency, and enable greaterflexibility by placing the burden on the grammarrules, which are more adaptable.
A rule has aleft hand side (LHS) and a right hand side (RHS).The LHS is a regular expression which has to bematched on the input; the RHS describes the an-notations to be added to the Annotation Set.
TheLHS is separated from the RHS by ?>?.
The fol-lowing four operators can be used on the LHS: ?|?,??
?, ???
and ?+?.
The RHS uses ?;?
as a separa-tor between statements that set the values of thedifferent attributes.
The following tokenizer ruleidentifies each character sequence that begins witha letter in upper case and is followed by 0 or moreletters in lower case:"UPPERCASELETTER" "LOWERCASELETTER"*>>> Token; orth=upperInitial; kind=word;Each such character sequence will be annotated astype ?Token?.
The attribute ?orth?
(orthography)has the value ?upperInitial?
; the attribute ?kind?has the value ?word?.
(2) Gazetteer: The gazetteer lists used are plaintext files, with one entry per line.
Each list rep-resents a set of names, such as names of cities,organizations, days of the week, etc.
An index fileis used to access these lists; for each list, a ma-jor type is specified and, optionally, a minor type.These lists are compiled into finite state machines.Any text tokens that are matched by these ma-chines will be annotated with features specifyingthe major and minor types.
JAPE grammar rules5http://l2r.cs.uiuc.edu/?cogcomp/tools.php6A good description of the original version of this lan-guage is in Doug Appelt?s TextPro manual: http://www.ai.sri.com/?appelt/TextPro.498then specify the types to be identified in particularcircumstances.The JAPE Rule: Each JAPE rule has two parts,separated by ??>?.
The LHS consists of an an-notation pattern to be matched; the RHS describesthe annotation to be assigned.
A basic rule is givenas:Rule::=<rule> <ident> ( <priority> <integer> )?LeftHandSide ">>>" RightHandSide(1) Left hand side: On the LHS, the pattern isdescribed in terms of the annotations already as-signed by the tokenizer and gazetteer.
The annota-tion pattern may contain regular expression opera-tors (e.g.
?, ?, +).
There are 3 main ways in whichthe pattern can be specified:1. value: specify a string of text, e.g.
{Token.string == ?of?}2.
attribute: specify the attributes (and values)of a token (or any other annotation), e.g.
{Token.kind == number}3. annotation: specify an annotation type fromthe gazetteer, e.g.
{Lookup.minorType ==month}(2) Right hand side: The RHS consists of de-tails of the annotations and optional features to becreated.
Annotations matched on the LHS of a rulemay be referred to on the RHS by means of labelsthat are attached to pattern elements.
Finally, at-tributes and their corresponding values are addedto the annotation.
An example of a complete ruleis:Rule: NumbersAndUnit(({Token.kind=="number"})+:numbers{Token.kind=="unit"})>>>:numbers.Name={rule="NumbersAndUnit"}This says ?match sequences of numbers followedby a unit; create a Name annotation across the spanof the numbers, and attribute rule with value Num-bersAndUnit?.Use of context: Context can be dealt with in thegrammar rules in the following way.
The pattern tobe annotated is always enclosed by a set of roundbrackets.
If preceding context is to be included inthe rule, this is placed before this set of brackets.This context is described in exactly the same wayas the pattern to be matched.
If context follow-ing the pattern needs to be included, it is placedFigure 9: An example JAPE rule used in the ex-perimentsafter the label given to the annotation.
Context isused where a pattern should only be recognised ifit occurs in a certain situation, but the context itselfdoes not form part of the pattern to be annotated.For example, the following rule for ?email-id?s(assuming an appropriate regular expression for?EMAIL-ADD?)
would mean that an email ad-dress would only be recognized if it occurred in-side angled brackets (which would not themselvesform part of the entity):Rule: Emailaddress1({Token.string=="<"})({Token.kind==EMAIL-ADD}):email({Token.string==">"})>>>:email.Address={kind="email",rule="Emailaddress1"}5.2 ResultsIn our first experiment, we performed annotationof the two corpora for 4 annotation types using 2JAPE rules for each type.
The 4 annotation typeswere ?Person name?, ?Organization?, ?Location?and ?Date?.
A sample JAPE rule for identifyingperson names is shown in Figure 9.
This rule iden-tifies a sequence of words as a person name wheneach word in the sequence starts with an alpha-bet in upper-case and when the sequence is imme-diately preceded by a word from a dictionary of?INITIAL?s.
Example words in the ?INITIAL?
dic-tionary are: ?Mr.
?, ?Dr.
?, ?Lt.
?, etc.499Table 1 compares the time taken by the index-based annotator against that taken by GATE for the8 JAPE rules.
The index-based annotator performs8-13 times faster than GATE.
Table 2 splits thetime mentioned for the index-based annotator inTable 1 into the time taken for the task of comput-ing postings lists for basic entities and derived en-tities (c.f.
Section 2) for each of the data sets.
Wecan also observe that a greater speedup is achievedfor the larger corpus.Data set GATE Index-basedEnron 4974343 374926Reuters 752287 92238Table 1: Time (in milliseconds) for computing an-notations using the two techniquesData set Orthographic Gazetteer Derivedentity types entity types entity typesEnron 38285 105870 230771Reuters 28493 21531 42214Table 2: Time (in milliseconds) for computingpostings lists of entity typesAn important advantage of performing annota-tions over the inverse index is that index entriesfor basic entity types can be preserved and reusedfor annotation types as additional rules for anno-tation are specified by users.
For instance, the in-dex entry for ?Capsword?
might find reuse in sev-eral annotation rules.
As against this, a document-based annotator has to process each documentfrom scratch for every newly introduced annota-tion rule.
To verify this, we introduced 1 addi-tional rule for each of the 4 named entity types.In Table 3, we compare the time required bythe index-based annotator against that required byGATE for annotating the two corpora using the 4additional rules.
We achieve a greater speedup fac-tor of 23-37 for incremental annotation.Data set GATE Index-basedEnron 1479954 62227Reuters 661157 17929Table 3: Time (in milliseconds) for computing an-notations using the two techniques for the addi-tional 4 rules6 ConclusionsIn this paper we demonstrated that a suitably con-structed inverse index contains all the necessaryinformation to implement entity annotators thatuse cascading regular expressions.
The approachhas the key advantage of not requiring access tothe original unstructured data to compute the an-notations.
The method uses a basic set of opera-tors on the inverse index to construct indexes to allmatches for a regular expression in the tokenizeddata set.
We showed theoretically, that for a DFAimplementation, the index approach can be muchfaster if the index sizes corresponding to the labelson the DFA are a small fraction of the total num-ber of tokens in the data set.
We also provideda more efficient index-based implementation thatis directly computed from the regular expressionswithout the need of a DFA conversion and experi-mentally demonstrated the gains.ReferencesEugene Agichtein and Luis Gravano.
2000.
Snow-ball: Extracting relations from large plain-text col-lections.
In Proceedings of the Fifth ACM Interna-tional Conference on Digital Libraries.Junghoo Cho and Sridhar Rajagopalan.
2002.
A fastregular expression indexing engine.
In Proceedingsof the 18th International Conference on Data Engi-neering.Brian Cooper, Neal Sample, Michael J.
Franklin,G?
?sli R. Hjaltason, and Moshe Shadmon.
2001.
Afast index for semistructured data.
In The VLDBConference, pages 341?350.H.
Cunningham, D. Maynard, K. Bontcheva, andV.
Tablan.
2002.
GATE: A framework and graph-ical development environment for robust NLP toolsand applications.H.
Cunningham.
1999.
Jape ?
a java annotation pat-terns engine.Line Eikvil.
1999.
Information extraction from worldwide web - a survey.
Technical Report 945, Nor-weigan Computing Center.Quanzhong Li and Bongki Moon.
2001.
Indexing andquerying XML data for regular path expressions.
InThe VLDB Journal, pages 361?370.Andrew McCallum, Dayne Freitag, and FernandoPereira.
2000.
Maximum entropy Markov mod-els for information extraction and segmentation.
InProc.
17th International Conf.
on Machine Learn-ing, pages 591?598.
Morgan Kaufmann, San Fran-cisco, CA.500
