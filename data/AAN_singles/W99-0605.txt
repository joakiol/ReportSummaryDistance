Cross-Language Information Retrieval for Technical DocumentsAtsushi  Fuj i i  and Tetsuya  I sh ikawaUniversity of Library and Information Science1-2 Kasuga Tsukuba 305-8550, JAPAN{fuj  i i ,  i sh ikawa}@ul is ,  ac.
jpAbstractThis paper proposes a Japanese/English cross-language information retrieval (CLIR) systemtargeting technical documents.
Our systemfirst translates a given query containing tech-nical terms into the target language, and thenretrieves documents relevant o the translatedquery.
The translation of technical terms is stillproblematic in that technical terms are oftencompound words, and thus new terms can beprogressively created simply by combining ex-isting base words.
In addition, Japanese of-ten represents loanwords based on its phono-gram.
Consequently, existing dictionaries findit difficult to achieve sufficient coverage.
Tocounter the first problem, we use a compoundword translation method, which uses a bilin-gual dictionary for base words and collocationalstatistics to resolve translation ambiguity.
Forthe second problem, we propose a translitera-tion method, which identifies phonetic equiva-lents in the target language.
We also show theeffectiveness of our system using a test collec-tion for CLIR.1 Int roduct ionCross-language information retrieval (CLIR),where the user presents queries in one languageto retrieve documents in another language, hasrecently been one of the major topics within theinformation retrieval community.
One strongmotivation for CLIR is the growing number ofdocuments in various languages accessible viathe Internet.
Since queries and documents arein different languages, CLIR requires a trans-lation phase along with the usual monolingualretrieval phase.
For this purpose, existing CLIRsystems adopt various techniques explored innatural language processing (NLP) research.
Inbrief, bilingual dictionaries, corpora, thesauriand machine translation (MT) systems are usedto translate queries or/and documents.In this paper, we propose a Japanese/EnglishCLIR system for technical documents, focus-ing on translation of technical terms.
Ourpurpose also includes integration of differentcomponents within one framework.
Our re-search is partly motivated by the "NACSIS"test collection for IR systems (Kando et al,1998) 1 , which consists of Japanese queriesand Japanese/English abstracts extracted fromtechnical papers (we will elaborate on the NAC-SIS collection in Section 4).
Using this col-lection, we investigate the effectiveness of eachcomponent as well as the overall performance ofthe system.As with MT systems, existing CLIR systemsstill find it difficult to translate technical termsand proper nouns, which are often unlisted ingeneral dictionaries.
Since most CLIR systemstarget newspaper articles, which are comprisedmainly of general words, the problem related tounlisted words has been less explored than otherCLIR subtopics (such as resolution of transla-tion ambiguity).
However, Pirkola (1998), forexample, used a subset of the TREC collectionrelated to health topics, and showed that com-bination of general and domain specific (i.e.,medical) dictionaries improves the CLIR perfor-mance obtained with only a general dictionary.This result shows the potential contribution oftechnical term translation to CLIR.
At the sametime, note that even domain specific dictionarieslhttp ://www.
rd.
nacs is.
ac.
j p/-nt cadm/index-en, html29do not exhaustively ist possible technical terms.We classify problems associated with technicalterm translation as given below:(1) technical terms are often compound word~which can be progressively created simplyby combining multiple existing morphemes("base words"), and therefore it is not en-tirely satisfactory to exhaustively enumer-ate newly emerging terms in dictionaries,(2) Asian languages often represent loanwordsbased on their special phonograms (primar-ily for technical terms and proper nouns),which creates new base words progressively(in the case of Japanese, the phonogram iscalled katakana).To counter problem (1), we use the compoundword translation method we proposed (Fujiiand Ishikawa, 1999), which selects appropri-ate translations based on the probability of oc-currence of each combination of base words inthe target language.
For problem (2), we use"transliteration" (Chen et al, 1998; Knightand Graehl, 1998; Wan and Verspoor, 1998).Chen et al (1998) and Wan and Verspoor (1998)proposed English-Chinese transliteration meth-ods relying on the property of the Chinesephonetic system, which cannot be directly ap-plied to transliteration between English andJapanese.
Knight and Graehl (1998) proposed aJapanese-English transliteration method basedon the mapping probability between Englishand Japanese katakana sounds.
However, sincetheir method needs large-scale phoneme inven-tories, we propose a simpler approach usingsurface mapping between English and katakanacharacters, rather than sounds.Section 2 overviews our CLIR system, andSection 3 elaborates on the translation mod-ule focusing on compound word translation andtransliteration.
Section 4 then evaluates theeffectiveness of our CLIR system by way ofthe standardized IR evaluation method used inTREC programs.2 Sys tem Overv iewBefore explaining our CLIR system, we clas-sify existing CLIR into three approaches interms of the implementation f the translationphase.
The first approach translates queriesinto the document language (Ballesteros andCroft, 1998; Carbonell et al, 1997; Davis andOgden, 1997; Fujii and Ishikawa, 1999; Hull andGrefenstette, 1996; Kando and Aizawa, 1998;Okumura et al, 1998), while the second ap-proach translates documents into the query lan-guage (Gachot et al, 1996; Oard and Hack-ett, 1997).
The third approach transfers bothqueries and documents into an interlingual rep-resentation: bilingual thesaurus classes (Mon-gar, 1969; Salton, 1970; Sheridan and Ballerini,1996) and language-independent vector spacemodels (Carbonell et al, 1997; Dumais et al,1996).
We prefer the first approach, the "querytranslation", to other approaches because (a)translating all the documents in a given col-lection is expensive, (b) the use of thesauri re-quires manual construction or bilingual compa-table corpora, (c) interlingual vector space mod-els also need comparable corpora, and (d) querytranslation can easily be combined with existingIR engines and thus the implementation cost islow.
At the same time, we concede that otherCLIR approaches are worth further exploration.Figure 1 depicts the overall design of ourCLIR system, where most components are thesame as those for monolingual IR, excluding"translator".First, "tokenizer" processes "documents" ina given collection to produce an inverted file("surrogates").
Since our system is bidirec-tional, tokenization differs depending on thetarget language.
In the case where documentsare in English, tokenization involves eliminat-ing stopwords and identifying root forms forinflected words, for which we used "Word-Net" (Miller et al, 1993).
On the other hand,we segment Japanese documents into lexicalunits using the "ChaSen" morphological ana-lyzer (Matsumoto et al, 1997) and discard stop-words.
In the current implementation, we useword-based uni-gram indexing for both Englishand Japanese documents.
In other words, com-pound words are decomposed into base wordsin the surrogates.
Note that indexing and re-trieval methods are theoretically independent of30!the translation method.Thereafter, the "translator" processes a queryin the source language ("S-query") to outputthe translation ("T-query").
T-query can con-sist of more than one translation, because mul-tiple translations are often appropriate for a sin-gle technical term.Finally, the "IR engine" computes the sim-ilarity between T-query and each documentin the surrogates based on the vector spacemodel (Salton and McGill, 1983), and sorts doc-ument according to the similarity, in descendingorder.
We compute term weight based on thenotion of TF.IDF.
Note that T-query is decom-posed into base words, as performed in the doc-ument preprocessing.In Section 3, we will explain the "translator"in Figure 1, which involves compound wordtranslation and transliteration modules.
( S-query ) (documents)1 1\]translator \] \] tokenizer \]( T-query ~ IR engine I: ~surrogates)( result )Figure 1: The overall design of our CLIR system3 Trans la t ion  Modu le3.1 OverviewGiven a query in the source language, tokeniza-tion is first performed as for target documents(see Figure 1).
To put it more precisely, we useWordNet and ChaSen for English and Japanesequeries, respectively.
We then discard stop-words and extract only content words.
Here,"content words" refer to both single and com-pound words.
Let us take the following queryas an example:improvement of data mining methods.For this query, we discard "of", to extract "im-provement" and "data mining methods".Thereafter, we translate ach extracted con-tent word individually.
Note that we currentlydo not consider elation (e.g.
syntactic relationand collocational information) between contentwords.
If a single word, such as "improvement"in the example above, is listed in our bilingualdictionary (we will explain the way to producethe dictionary in Section 3.2), we use all pos-sible translation candidates as query terms forthe subsequent retrieval phase.Otherwise, compound word translation isperformed.
In the case of Japanese-Englishtranslation, we consider all possible segmenta-tions of the input word, by consulting the dic-tionary.
Then, we select such segmentationsthat consist of the minimal number of basewords.
During the segmentation process, thedictionary derives all possible translations forbase words.
At the same time, transliterationis performed whenever katakana  sequences un-listed in the dictionary are found.
On the otherhand, in the case of English-Japanese transla-tion, transliteration is applied to any unlistedbase word (including the case where the inputEnglish word consists of a single base word).
Fi-nally, we compute the probability of occurrenceof each combination of base words in the targetlanguage, and select those with greater proba-bilities, for both Japanese-English and English-Japanese translations.3.2 Compound Word Translat ionThis section briefly explains the compoundword translation method we previously pro-posed (Fujii and Ishikawa, 1999).
This methodtranslates input compound words on a word-by-word basis, maintaining the word order in thesource language 2.
The formula for the sourcecompound word and one translation candidateare represented asbelow.S = 81 ,82 , .
.
.
,8nT = t l ,  t2 ,  ?
?
?
, tn2A preliminary study showed that approximately 95%of compound technical terms defined in a bilingual dic-tionary maintain the same word order in both source andtarget languages.31Here, si and ti denote i-th base words in sourceand target languages, respectively.
Our task,i.e., to select T which maximizes P(TIS), istransformed into Equation (1) through use ofthe Bayesian theorem.arg n~x P(TIS ) = arg n~x P(SIT ) ?
P(T) (1)P(SIT ) and P(T) are approximated asin Equa-tion (2), which has commonly been used inthe recent statistical NLP research (Church andMercer, 1993).nP(SIT) ~ I~P(silti)i----1n-1P(T) "~ 1Y~ p(ti+llti)i= l(2)We produced our own dictionary, becauseconventional dictionaries are comprised primar-ily of general words and verbose definitionsaimed at human readers.
We extracted 59,533English/Japanese translations consisting of twobase words from the EDR technical terminol-ogy dictionary, which contains about 120,000translations related to the information process-ing field (Japan Electronic Dictionary ResearchInstitute, 1995), and segment Japanese ntriesinto two parts 3.
For this purpose, simple heuris-tic rules based mainly on Japanese charactertypes (i.e., kanji, katakana, hiragana, alpha-bets and other characters like numerals) wereused.
Given the set of compound words whereJapanese ntries are segmented, we correspondEnglish-Japanese base words on a word-by-wordbasis, maintaining the word order between En-glish and Japanese, to produce a Japanese-English/English-Japanese base word dictionary.As a result, we extracted 24,439 Japanese basewords and 7,910 English base words from theEDR dictionary.
During the dictionary produc-tion, we also count the collocational frequencyfor each combination of si and ti, in order toestimate P(silti).
Note that in the case where3The number of base words can easily be identifiedbased on English words, while Japanese compound wordslack lexical segmentation.si is transliterated into ti, we use an arbitrar-ily predefined value for P(s,ilti).
For the esti-mation of P(ti+llti), we use the word-based bi-gram statistics obtained from target languagecorpora, i.e., "documents" in the collection (seeFigure 1).3.3 Trans l i terat ionFigure 2 shows example correspondences be-tween English and (romanized) katakana words,where we insert hyphens between each katakanacharacter for enhanced readability.
The basisof our transliteration method is analogous tothat for compound word translation describedin Section 3.2.
The formula for the sourceword and one transliteration candidate are rep-resented as below.S -~ s1 ,82 , .
.
.
,8  nT z t l , t2 , .
.
.
, t  nHowever, unlike the case of compound wordtranslation, si and ti denote i-th "symbols"(which consist of one or more letters), respec-tively.
Note that we consider only such T'sthat are indexed in the inverted file, becauseour transliteration method often outputs anum-ber of incorrect words with great probabilities.Then, we compute P(TIS ) for each T usingEquations (1) and (2) (see Section 3.2), andselect k-best candidates with greater probabili-ties.
The crucial content here is the way to pro-duce a bilingual dictionary for symbols.
For thispurpose, we used approximately 3,000 katakanaentries and their English translations listed inour base word dictionary.
To illustrate our dic-tionary production method, we consider Fig-ure 2 again.
Looking at this figure, one maynotice that the first letter in each katakanacharacter tends to be contained in its corre-sponding English word.
However, there are afew exceptions.
A typical case is that sinceJapanese has no distinction between "L" and"R" sounds, the two English sounds collapseinto the same Japanese sound.
In addition,a single English letter corresponds to multiplekatakana characters, uch as "x" to "ki-su" in"<text, te-ki-su-to>".
To sum up, English and32romanized katakana words are not exactly iden-tical, but similar to each other.English katakanasystemminingdatanetworktextcollocationshi-su-te-muma-i-ni-n-gudee-tane-tto-waa-kute-ki-su-toko-ro-ke-i-sho-nFigure 2: Examples of English-katakana corre-spondenceWe first mangally define the similarity be-tween the EngliSh letter e and the first roman-ized letter for each katakana character j ,  asshown in Table 1.
In this table, "phoneticallysimilar" letters refer to a certain pair of letters,such as "L" and "R ''4.
We then consider thesimilarity for afiy possible combination of let-ters in English and romanized katakana words,which can be represented as a matrix, as shownin Figure 3.
This figure shows the similaritybetween letters in "<text, te-ki-su-to>".
Weput a dummy letter "$", which has a positivesimilarity only t.o itself, at the end of both En-glish and katakana words.
One may notice thatmatching plausible symbols can be seen as find-ing the path which maximizes the total similar-ity from the first to last letters.
The best pathcan easily be found by, for example, Dijkstra'salgorithm (Dijkstra, 1959).
From Figure 3,we can derive the following correspondences:"<re, te>", "<X, ki-su>" and "<t, to>".
Theresultant correspondences contain 944 Japaneseand 790 English symbol types, from which wealso estimated P(si\[ti) and P(ti+l\]ti).As can be predicted, a preliminary experi-ment showed that our transliteration methodis not accurate when compared with a word-based translation.
For example: the Japaneseword "re-ji-su-ta (register)" is transliterated to"resister", "resistor" and "register", with theprobability score in descending order.
How-4~re identified approximately twenty pairs of phonet-ically similar letters.ever, combined with the compound word trans-lation, irrelevant ransliteration outputs are ex-pected to be discarded.
For example, a com-pound word like "re-ji-su-ta tensou 9engo (reg-ister transfer language)" is successfully trans-lated, given a set of base words "ten.sou (trans-fer)" and "gengo (language)" as a context.Table 1: The similarity between English andJapanese letterscondition similaritye and j are identical 3e and j are phonetically similarboth e and j axe vowels or consonants 1otherwise 0Etext$te kiJSU toi 1 2 3 0o o o.).
..... o0 0 o 0Figure 3: An example matrix for English-Japanese symbol matching (arrows denote thebest path)4 Eva luat ionThis section investigates the performance of ourCLIR system based on the TREC-type evalu-ation methodology: the system outputs 1,000top documents, and TREC evaluation softwareis used to calculate the recall-precision trade-offand l l -point average precision.For the purpose of our evaluation, we usedthe NACSIS test collection (Kando et al, 1998).This collection consists of 21 Japanese queri~'sand approximately 330,000 documents (in el-33ther a confl)ination of English and Japanese oreither of the languages individually), collectedfi'om technical papers published by 65 Japaneseassociations tbr various fields.
Each documentconsists of the document ID, title, name(s) ofauthor(s), name/date of conference, hosting or-ganization, abstract and keywords, from whichtitles, abstracts and keywords were used for ourevaluation.
We used as target documents ap-proximately 187,000 entries where abstracts arein both English and Japanese.
Each query con-sists of the title of the topic, description, narra-tive and list of synonyms, from which we usedonly the description.
Roughly speaking, mosttopics are related to electronic, information andcontrol engineering.
Figure 4 shows example de-scriptions (translated into English by one of theauthors).
Relevance assessment was performedbased on one of the three ranks of relevance,i.e., "relevant", "partially relevant" and "irrel-evant".
In our evaluation, relevant documentsrefer to both "relevant" and "partially relevant"documents 5.ID0005000600190024descriptiondimension reduction for clusteringintelligent information retrievalsyntactic analysis methods for Japanesemachine translation systemsFigure 4: Example descriptions in the NACSISquery4.1 Evaluat ion of compound wordtrans lat ionWe compared the following query translationmethods:(1 i a control, in which all possible translationsderived from the (original) EDR technicalterminology dictionary are used as queryterms ("EDR"),(2) all possible base word translations derivedfrom our  dictionary are used ("all"),5The result did not significantly change depending onwhether we regarded "partially relevant" as relevant ornot.
(3) randomly selected k translations derivedfrom our bilingual dictionary are used("random"),(4) k-best translations through compoundword translation are used ("C\?T").For system "EDR", compound words unlisted inthe EDR dictionary were manuMly segmentedso that substrings (shorter compound words orbase words) can be translated.
For both sys-tems "random" and "CWT", we arbitrarily setk = 3.
Figure 5 and Table 2 show the recall-precision curve and l 1-point average precisionfor each method, respectively.
In these, "J-J"refers to the result obtained by the Japanese-Japanese IR system, which uses as documentsJapanese titles/abstracts/keywords comparableto English fields in the NACSIS collection.
Thiscan be seen as the upper bound for CLIR perfor-mance 6.
Looking at these results, we can con-clude that the dictionary production and prob-abilistic translation methods we proposed areeffective for CLIR.0.8?
0.6.90.40.2i i , ,j _ j  oCWT ..... all -~,..\ EDR --~ ..... ~,, ,~, random -A -.--~.:::..,.?.,.
( ,2 , ,0 0.2 0 .4  0.6 0.8recallFigure 5: RecM1-Precision curves for evaluationof compound word translation6Regrettably, since the NACSIS collection does notcontain English queries, we cannot estimate the upperbound performance by English-English IR.34Table 2: Comparison of average precision forevaluation of compound word translationII avg.
precision \[ratio to J-3J-J 0.204 - -CWT 0.193 0.946all 0.171 0.838EDR 0.130 0.637random 0.116 0.5694.2 Eva luat ion  of  t rans l i te ra t ionIn the NACSIS collection, three queries con-tain katakana (base) words unlisted in our bilin-gual dictionary: Those words are "ma-i-ni-n-gu (mining)" and "ko-ro-ke-i-sho-n (colloca-tion)".
However, to emphasize the effectivenessof transliteration, we compared the following ex-treme cases:(1) a control, in which every katakana word isdiscarded from queries ("control"),(2) a case where transliteration is applied toevery katakana word and top 10 candidatesare used ("translit").Both cases use system "CWT" in Section 4.1.In the case of "translit", we do not use katakanaentries listed in the base word dictionary.
Fig-ure 6 and Table 3 show the recall-precision curveand l l -point average precision for each case, re-spectively.
In these, results for "CWT" corre-spond to those in Figure 5 and Table 2, respec-tively.
We can conclude that our transliterationmethod significantly improves the baseline per-fomlance (i.e., "control"), and comparable toword-based translation ill terms of CLIR per-formance.An interesting observation is that the use oftransliteration is robust against typos in docu-ments, because a number of similar strings areused as query terms.
For example, our translit-eration method produced the following stringsfor "ri-da-ku-sho-n (reduction)":riduction, redction, redaction, reduc-tion.All of these words are effective for retrieval, be-cause they are contained in the target docu-ments.1 i i , iJ - J  .~CWT -+ --t rans l i t  .~-.-0.8  " cont ro l  1.-~ .......0.6.~20.4t "'x.. ""s.-...x ..... ""~:....... x .
.
-\ [ - -  l I I ~ ?
"~-0 0.2 0.4 0.6 0.8recall0.2Figure 6: Recall-Precision curves for evaluationof transliterationTable 3: Comparison of average precision forevaluation of transliterationII avg.
precision ratio to J-JJ-J 0.204 - -CWT 0.193 0.946translit 0.193 0.946control 0.115 0.5644.3 Eva luat ion  of  the  overallper formanceWe compared our system ("CWT+transl i t")with the Japanese-Japanese IR system, where(unlike the evaluation in Section 4.2) transliter-ation was applied only to "ma-i-ni-n-gu (min-ing)" and "ko-ro-ke-i-sho-n (collocation)".
Fig-ure 7 and Table 4 show the recall-precision curveand l 1-point average precision for each sys-tem, respectively, from which one can see thatour CLIR system is quite comparable with themonolingual IR system in performance.
In ad-dition, from Figure 5 to 7, one can see that themonolingual system generally performs better35at lower re(:all while the CLIR system pertbrmsb( , I t ( , r  at higher recall.For further investigation, let us discuss sim-ilar (~xperim(mtal results reported by Kandoand Aizawa (1998), where a bilingual dictionaryproduced ti'om Japanese/English keyword pairsin the NACSIS documents is used for querytranslation.
Their evaluation method is al-most the same as pertbrmed in our experinmnts.One difference is that they use the "OpenText"search engine 7, and thus the performance tbrJal)anese-Japanese IR is higher than obtainedin out" evaluation.
However, the performanceof their Japanese-English CLIR systems, whichis roughly 50-60% of that for their Japanese-Japanese IR system, is comparable with ourCLIR system performance.
It is expected thatusing a more sophisticated search engine, ourCLIR system will achieve a higher performancethan that obtained by Kando and Aizawa.0.80.6 .olaD.
O.40.2J - J  oCWT + translit -+- - -"',,?
- .?
."
' - k .0 0.2 0.4 0.6 0.8recallFigure 7: Recall-Precision curves for evaluationof overall performance5 Conc lus ionIn this paper, we proposed a Japanese/Englishcross-language information retrieval system,targeting technical documents.
We combineda query translation module, which performs7Devcloped by OpenText Corp.Table 4: Comparison of average precision tbrevaluation of overall l)erfbrmanceII avg.
I)recision ratio to J-.l?
I-J 0.204 --CWT + translit 0.212 1.04compound wor(1 translation and translitera-tion, with an existing monolingual retrievalmethod.
Our experimental results showed thatcompound word translation and transliterationmethods individually improve on the baselineperformance, and when used together the im-provement is even greater.
Future work will in-elude the application of automatic word align-ment methods (Fung, 1995; Smadja et al, 1996)to enhance the dictionary.AcknowledgmentsThe authors would like to thank Noriko Kando(National Center for Science Information Sys-tems, Japan) for her support with the NACSIScollection.ReferencesLisa Ballesteros and W. Bruce Croft.
1998.
Resolv-ing ambiguity for cross-language retrieval.
In Pro-ceedings of the 21th Annual International ACMSIGIR Conference on Research and Developmentin Information Retrieval, pages 64-71.Jaime G. Carbonell, Yiming Yang, Robert E. Fred-erking, Ralf D. Brown, Yibing Geng, and DannyLee.
1997.
Translingual information retrieval:A comparative valuation.
In Proceedings of the15th International Joint Conference on ArtficialIntelligence, pages 708-714.Hsin-Hsi Chen, Sheng-Jie Huang, Yung-Wei Ding,and Shih-Chung Tsai.
1998.
Proper name trans-lation in cross-language information retrieval.
InProceedings of the 36th Annual Meeting of the As-sociation for Computational Linguistics and the17th InteT'national Conference on ComputationalLinguistics, pages 232-236.Kenneth W. Church and Robert L. Mercer.
1993.Introduction to the special issue on computa-tional linguistics using large corpora.
Computa-tional Linguistics, 19(1):1-24.Mark W. Davis and William C. Ogden.
1997.QUILT: hnI)lementing a large-scale cross-language36text retrieval system.
In Proceedings of the 20thAnnual International ACM SIGIR Conference onResearch and Development in Information Re-trieval, pages 92-98.Edsgar W. Dijkstra.
1959.
A note on two problemsin connexion with graphs.
Numerische Mathe-matik, 1:269-271.Susan T. Dumais, Thomas K. Landauer, andMichael L. Littman.
1996.
Automatic cross-linguistic information retrieval using latent se-mantic indexing.
In ACM SIGIR Workshop onCross-Linguistic Information Retrieval.Atsushi Fujii and Tetsuya Ishikawa.
1999.
Cross-language information retrieval using compoundword translation.
In Proceedings of the 18th In-ternational Conference on Computer Processingof Oriental Languages, pages 105-110.Pascale Fung.
1995.
A pattern matching method forfinding noun and proper noun translations fromnoisy parallel corpora.
In Proceedings of the 33rdAnnual Meeting of the Association for Computa-tional Linguistics, pages 236-243.Denis A. Gachot, Elke Lange, and Jin Yang.
1996.The SYSTRAN NLP browser: An application ofmachine translation technology inmultilingual in-formation retrieval.
In A CM SIGIR Workshop onCross-Linguistic Information Retrieval.David A.
Hull and Gregory Grefenstette.
1996.Querying across languages: A dictionary-basedapproach to multilingual information retrieval.In Proceedings of the 19th Annual InternationalACM SIGIR Conference on Research and Devel-opment in Information Retrieval, pages 49-57.Japan Electronic Dictionary Research Institute.1995.
Technical terminology dictionary (informa-tion processing).
(In Japanese).Noriko Kando and Akiko Aizawa.
1998.
Cross-lingual information retrieval using automaticallygenerated multilingual keyword clusrters.
In Pro-ceedings of the 3rd International Workshop on In-formation Retrieval with Asian Languages, pages86--94.Noriko Kando, Teruo Koyama, Keizo Oyama, KyoKageura, Masaharu Yoshioka, Toshihiko Nozue,Atsushi Matsumura, and Kazuko Kuriyama.1998.
NTCIR: NACSIS test collection project.
InThe 20th Annual BCS-IRSG Colloquium on In-formation Retrieval Research.Kevin Knight and Jonathan Graehl.
1998.
Ma-chine transliteration.
Computational Linguistics,24(4) :599-612.Yuji Matsumoto, Akira Kitauchi, Tatsuo Yamashita,Osamu Imaichi, and Tomoaki Imamura.
1997.Japanese morphological mlalysis system ChaSenmanual.
Technical Report NAIST-IS-TR97007,NAIST.
(In Japanese).George A. Miller, Richard Beckwith, Christiane Fell-baum, Derek Gross, Katherine Miller, and RandeeTengi.
1993.
Five papers on WordNet.
Techni-cal Report CLS-Rep-43, Cognitive Science Labo-ratory, Princeton University.P.
E. Mongar.
1969. International co-operation iabstracting services for road engineering.
The In-formation Scientist, 3:51-62.Douglas W. Oard and Paul Hackett.
1997.
Docu-ment translation for cross-language text retrievalat the University of Maryland.
In The 6th TextRetrieval Conference.Akitoshi Okumura, Kai Ishikawa, and Kenji Satoh.1998.
Translingual information retrieval by abilingual dictionary and comparable corpus.
InThe 1st International Conference on LanguageResources and Evaluation, workshop on translin-gual information management: current levels andfuture abilities.Ari Pirkola.
1998.
The effects of query structureand dictionary setups in dictionary-based cross-language information retrieval.
In Proceedings ofthe 21th Annual International ACM SIGIR Con-ference on Research and Development in Informa-tion Retrieval, pages 55-63.Gerard Salton and Michael J. McGill.
1983.Introduction to Modern Information Retrieval.McGraw-Hill.Gerard Salton.
1970.
Automatic processing of for-eign language documents.
Journal of the Amer-ican Society for Information Science, 21(3):187-194.PgLraic Sheridan and Jean Paul Ballerini.
1996.
Ex-periments inmultilingual information retrieval us-ing the SPIDER system.
In PTvceedings of the19th Annual International ACM SIGIR Confer-ence on Research and Development in Informa-tion Retrieval, pages 58-65.Frank Smadja, Kathleen R. McKeown, and VasileiosHatzivassiloglou.
1996.
Translating collocationsfor bilingual lexicons: A statistical approach.Computational Linguistics, 22(1):1-38.Stephen Wan and Cornelia Maria Verspoor.
1998.Automatic English-Chinese name transliterationfor development of multilingual resources.
In Pro-ceedings of the 36th Annual Meeting of the Associ-ation for Computational Linguistics and the 17thInternational Conference on Computational Lin-guistics, pages 1352-1356.37
