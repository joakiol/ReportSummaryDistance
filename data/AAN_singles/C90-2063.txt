Parsing for Grammar and Style CheckingGregor ThurmairDI AP 323Siemens AGInternet: metal@ztivax.siemens.comuucp: mcsun!
unido!ztivax!metal1.
AbstractThe following paper describes ome basicproblems which have to be tackled if a mor-phosyntactic parser is to be configured in agrammm" and style checking environment.Whereas grammar checking has to deal withill-formed input which by definition is out-side the scope of a grammar, style checkinghas problems in grammar coverage and in-tentionality of style.To overcome these problems, a method ispresented based on the METAL grammarformalism which allows for fallback rules,levelling and scoring mechanisms, and otherfeatures which can be used.
It will be de~scribed what kinds of information and pro-cessing are needed to implement suchcheckers.Finally, some examples are given which il-lustrate the mode of operation of the methoddescribed.2.
Tile problem domainThere is a fundamental difference betweengrammar and style checking: Grammarchecking tries to find ill-formedness whichby definition is considered to be a mistakeand MUST be corrected; style checking hasto do with well-formed but somehow markedtext.
As a result, style checking has to bemuch more "liberal" as it has to do with "de-viations" which might have been intended bythe author, but CAN be corrected.
This resultsin two different sets of requirements for a pars~el'.Concerning a grammar checker, its task is out-side the scope of a grammar by definition: Agrammar tries to describe (only and exactly)the grammatical structures of a language.
Ewery ungrammatical sentence should cause aparse failure.Moreover, to detect a grammar error, the pars-er has to successfully pm'se a given sentence.In order to parse it, however, information mustbe used which could have been violated.
E.g.in (1) (example from German), agreement isthe only way to decide which NP is subject(namely the second) and which is object; (2) isambiguous as both NPs are plural:1.
Die Tiger t6tet der Mann(the tigers kills the man)2.
Die Tiger t6ten die M~inner(the tigers kill the men)If agreement is violated it is hard to find outwhat the subject should be; and therefore it ishard to detect hat agreement is violated.~Iqae "circulus vitiosus" is that the parsershould detect errors the correct interpretationof which is needed to obtain an overall parseon the basis of which the error can be detected.There is an additional problem with grammarchecking: If the grammar becomes more corn-365plex, several competing parses for a givensentence might be found.
Diagnosis then de-pends on what parse has been chosen.
Theapplication (checking of larger texts) doesnot allow for asking the user which interpre-tation to pick; the parser has to find the "bestpath" and interpret i .
This might lead to theresult that sentences are flagged which arecorrect (from the user's point of view) butdid not result in the "best path" parse.
E.g.
ifa PP can be argument of a noun as well as averb, different flags might be set dependingon which reading "wins".Style checking has a different set of prob-lems to solve.
First it has to be found out,what "style" is, i.e.
what has to be checked.The present paper will not contribute to thisdebate; we take as input guidelines which areused in the process of technical writing andin the production of technical documents (of.Schmitt 89).These guidelines have to be "translated" intoa operational form; e.g.
what should bechecked if the user is asked not to write "toocomplex" sentences?
In 4. below, some ex-amples of phenomena are given whichshould be marked.As style is a kind of producing non-standardstructures (i.e.
structures which are not cov-ered by standard grammars), we need a pow-erful parser and a grammar with largecoverage to interpret style phenomena; i.e.the linguistic structures which have to be in-terpreted for style phenomena can and willbe w;ry complex.
Also, the risk of parse fail-ure will increase, and we need a kind of"post mortem" diagnosis for cases whichcould not be handled.
We need a parserwhich allows for that.As far as diagnosis is concerned, the checkershould be cautious and formulate questionsrather than correct hings, as a stylistic vari-ant could be intended by the text author.
Italso should not mark too many things; e.g.
ifthe rule is "avoid passives" it should certain-ly not flag every passive sentence.
I.e.
the di-agnostics require practical tuning to be reallyuseful.3.
Properties of a parser forstyle and grammar checkingpurposes3.1 Grammar  checkingA parser for grammar checking should havethe following features:It should be able to allow for the analysis ofparse failures.
Compared to an ATN (cf.
Weis-chedel 1982), where a failure ends with thestarting state, a chart keeps all the intermediateresults and is well suited for diagnostics?However, diagnostics follow specific informa-tion: The diagnosis must know "what to lookfor" (e.g.
wrong agreement, wrong punctua-tion etc.).
It therefore will cover only a part ofthe potential grammar errors.Such a "two step approach" has been imple-mented in the CRITIQUE system (of.
Ravin1988), where a parse failure is more closelylooked at.
However, one could think of special"fallback rules" which implement these diag-nostics already in the grammar.
This means toenlarge the coverage of the grammar for ex-plicitly ungrammatical structures which duringparsing could be marked as ungramrrmtical.This would be just a different kind of repre-senting the diagnosis knowledge but it wouldbe computationally more effective as it: couldbe integrated into the parse itself, leading to a"one step approach".In this approach, we do not want the fallbackrules to fire except if all other rules failed; i.e.we have to avoid that rules which build gram-matical structures are not selected, but ruleswhich are meant as fallback rules fire in "regu-lar" parses.
Therefore we must be able to buildSETs of rules which can be controlled by thegrammar writer.
We then can fire the setswhich build grammatical structures first, andthe fallback rules later on.
Then we only needto mark the nodes built by the fallback rules366with a flag indicating that there was a fall-back rule (and of what kind it was).Moreover, as only the "best first" strategycan be applied in this application area, wemust be able to tune the parser in such a waythat the most plausible reading comes outfirst.
This can be done by a proper scoringmechanism which should be accessible tothe grammar writer.
This cannot alwaysavoid that the "intended" parse differs fromthe "best" one, but it at least makes the par-sing process more stable and independent ofsystem-internal determinants (like rule order,parsing strategy etc.
)Finally, we must be able to change the errordetected by local operations.
These opera-t:ions consist in changing, adding or deletingfeature-value pairs or nodes etc.
The alterna-t:ives here are: Overwrite the respective pieceof information by the correct one and re-gen-erate the whole morphosyntactic surfacestructure; or exchange just a partial structure.This will depend on the kind of error detect-ed.3?2 Sty le  check ingInstead of discussing what style might be,we concentrate on "bad style" phenomenamentioned in texts on technical writing (cf.Schmitt 89).
Examples of bad style are:?
too long sentences, too complex sentences?
too many prenominal modifiers?
inconsistent terminology?
unclear prepositional phrase relationsetc.
(these are, of course, languagespecific)These criteria have to be reformulated in for-real terms of linguistic descriptions, e.g.complexity of sentences could be:?
number of rules fired to parse it?
number of nodes in a tree?
number of nodes of a certain property(e.g.
subclauses) etc.These formal specifications then have to beused in the diagnosis part.Here again we have the choice between a "twostep" approach which first parses and thendoes diagnostics, or a "one step" approachwhich does everything during parsing.
Wecould do diagnosis on partial structures andmark the nodes which have been built.
If thesenodes are used by the parser to build highernon-terminal nodes, the flags are valid; if thenodes are rejected by the parser they are justignored.As using bad style does not lead to ungram-matical sentences, we should not need addi-tional grammar ules for style checking.
Butwhat we need is a set of flags which are at-tached to the nodes in question as soon assome diagnosis ucceeds.
This could be an ad-ditional feature set which is set on top of thefeatures used in the regular grammar.
It is usedto INTERPRET the rules which have fired ac-cording to stylistic criteria.These features have to be kept local to allowfor error localization: If the user is told "toocomplex word" then the system should be ableto localize this word in the tree.
On the otherhand, we need some global information as wellwhich is related either to a sentence as a wholeor even the whole text.
(If we want we caneven compute overall stylistic scores out ofthem as soon as we know what that means).They also should be able to be easily added orremoved from the grammar, i.e.
should be keptas an independent module which simply is notadded if the grammar is used for other purpos-es.
Therefore, we need flexible feature mainte-nance possibilities.3.3 The  METAL  grammar  as bas ictoolAlthough originally developed for machinetranslation, the METAL system can fulfill allthe requirements mentioned above:367?
it is language independent, i.e.
it has acommon software kernel which inter-prets the different language knowledgesources.
It also takes care of problemslike separation of text and layout infor-mation in a given text, treatment of edi-tor specific information, etc.oil uses an active chart as controlstructure and does some parse failurediagnosis already (for MT purposes),and it stores those tests which did notsucceed and prevented a rule from fi-ring to enable later diagnosis?
it has large grammars and lexica for se-veral languages; therefore considerablecoverage is available.
Also, some fall-back rules already exist.
Moreover, therule structure is such that the analysisparts can easily be separated from thetranslation parts and enriched by otherpurpose components (like grammar~md style checking) (cf.
Thurmair1990)?
it has a special evelling and preferenc-ing mechanism which allows to grouprules into levels and use these levels to-gether with explicit scores for good orbad partial parses to control the overallbehavior of the parser according to lin-guistic needs?
it treats nodes as complex bundles ofteatures and values; and it allows foreasy feature manipulation (e.g.
percol-ating, unifying, adding etc.)
using a setof grammar operators?
it does not only allow for simple tests(e.g.
presence of a feature) but also forcomplex tests, e.g.
on structural de-scriptions of tree structures?
it has to be modified, however, by ad-Cling a component which at the end of aparse collects the grammatical nd sty-listic flags and evaluates them if neces-sary4.
Some examplesThe following section gives some examplesand shows how they could be treated.
They aretaken from German because the need for fullparsing is more obvious here than for English.They try to implement some of the technicalwriters' requirements.4.1 Conditional clauses withoutsubordinative conjunctionThey can be recognized by searching for asubclause which has the finite verb in the firstposition:3.
Kommt er, (so) gehen wir(Comes he, (so) go we)4.
Lesen Sic die Daten ein, schreibt dasProgramm eine Fehlermeldungen(Read you the data in, writes the pro-gram an error message)Conditional clauses like (3) and (4) share theproperty of having the verb in first positionwith infinitives, however.
Sometimes it is hardto distinguish between both cases: (5) is condi-tional, (6) is imperative:5.
Geben Sie "Ja" ein, beenden Sic; dasProgramm(Enter you "Yes" in, finish you theprogram)6.
Geben Sie "Ja" ein, beenden Sic dasProgramm und schalten Sie das Ger/itaus(Enter you "Yes" in, finish you theprogram and switch you the deviceoff)As the conditionals just mentioned are abso-lutely grammatical in German, the grammarmust have a rule that covers this case (i.e.
thata subclause can consist of a clause withoutsubordinate conjunction if the verb is first).The only thing to do for a style checking de-vice is to mark the subclause node for havingbeen built by a rule which is bad from a stylis-tic point of view.
This could be done by put-ting an appropriate feature onto this node.
If368this node contributes to the overall parse (asin (5)) this feature is evaluated; else (as in(6)) it is not.4.2 Cllains of prepositional phrasesThese problems are well known in linguis-tics.
Cases like (7) have unclear eferences,and not just for the machine!
Therefore,chains of PPs should be avoided:7.
The data were input for processingin machine internal format in binaryformHere the parser will find a solution (e.g.
at-taching the first two PPs to the NP, the thirdto clause level), but it will have trouble to doso.
"Trouble" might be indicated by manyPP-attaching rules being fired; and even ifnot all of them are successful, some will be,and attachment on different levels is stillpossible.In this case, the system cannot simply checkthe input linear precedence order (as PPs arenonterminal nodes), but we also cannot relyon all PPs being attached as sisters of eachother like in (8); cases like (9) are muchmore likely; and then there is no direct pre-cedence between the PPs any more as prece-dence holds between X 1 and PP, X2 and PPand X3 and PP respectively...... PP PP PP .....<b,... X1 PP ...X2 PP.
/NX3 PPWe need some intermediate level here onwhich a notion like PP is already known, andprecedence relations can be determined inde-pendent of the actual attachment of these PPs.This requires complex structural matchingprocesses on the trees.Ambiguity of conjunction falls into the sameclass of problems: Here again, the parser willfinally decide somehow, i.e.
try to resolve theambiguity e.g.
of (10).10.
The data were input and output com-patibleAgain, the question is, how difficult this willbe; and this can be expressed in terms of howmany rules a conjunctional terminal node canfeed (whether successfully or not).
In order toknow this, we have to examine the chart (asmost of the rules tried will not have led to asuccessful parse) and mark the conjunction ac-cordingly.4.3 Subject-Object inversionThis last example shows possible complex in-teractions in the area of style checking.
In Ger-man, the direct object of a verb can be putbefore the subject, e.g.
in (11), (12), (i3):11.
Den Mann hat er gesehen(the man has he seen)12.
Die Daten beschreibt das Programm(the data describes the program)13.
Daten beschreiben die Program- Dieme(the data describe the programs)All these sentences are grammatical nd haveto be covered by the verb valency routines.Sometimes, however, the subject-object-con-version leads to unclear eferences (as in (13)where both NPs can be both subject and ob-ject).
This is considered to complicate the pro-cess of text understanding.
A style checkercould flag these occurrences; but there is thefollowing interference:If the grammar can recognize subject-object-inversion easily (as in (11)), then the reader369can do so as well, and a style checker shouldnot flag anything.
The cases which might beambiguous for the reader, however, are am-biguous for the grammar as well; and as theparser uses certain heuristics to decide onsubject and object in unclear cases, it mightpick the wrong distribution and not flag any-thing, although it should do so in exactly thiscase.
The result is that the checker's flaggingis useless in the cases where the recognitionis good, and that there is no flagging in thereal important cases.This example shows that much fine tuning isnecessary, tomake a checking device a reallyuseful tool and improve its value to users.- Weischedel, R.M., Sondheimer, N.K., 1993:Meta-rules as a basis for processing ill-formedinput, in: ACL 9- Weischedel, R.M., Ramshaw, L.A., 1987:Reflections on the knowledge needed to pro-cess ill-formed language.
In: Nirenburg, S.,ed.
: Machine Translation, Theoretical andmethodological issues.
Cambridge Univ.Press, 155-1675.
References- Chandler, B., 1989: Grammar problems?in: Electric Word 15- Fink, R, Biermann, A.W., 1986: The Cor-rection of Ill-Formed Input using History-Based Expectation with Applications toSpeech Understanding.
in: ComputationalLinguistics 12,1- Gebruers, R., 1988: Valency and MT, re-cent developments in the METAL system.in: Proc.
2nd applied ACL, Austin, Tx- Jensen, K., Binot, J.-L., 1987: Disambigu-ating Prepositional Phrase Attachments byUsing On-Line Dictionary Definitions.
in:Computational Linguistics, 13,3/4- MacDonald, H.H., Frase, L.T., Gingrich,P., Keenan, S.A., 1982: The WRITER'SWORKBENCH: Computer Aids for TextAnalysis.
in: IEEE Transactions on Commu-nication 30- Ravin, Y., 1988: Grammar Errors and StyleWeaknesses in a text- Critiquing System.
in:IEEE Transactions on Communication 31,3- Schmitt, H., 1989: Writing UnderstandableTechnical Texts.
Esprit 2315 Report.- Thurmair, G., 1990: Recent developmentsin Machine Translation.
(to appear in: Com-puters and Humanities)370
