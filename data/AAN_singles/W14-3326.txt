Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 221?228,Baltimore, Maryland USA, June 26?27, 2014.c?2014 Association for Computational LinguisticsMachine Translation of Medical Texts in the Khresmoi ProjectOnd?rej Du?sek, Jan Haji?c, Jaroslava Hlav?a?cov?a, Michal Nov?ak,Pavel Pecina, Rudolf Rosa, Ale?s Tamchyna, Zde?nka Ure?sov?a, Daniel ZemanCharles University in Prague, Faculty of Mathematics and PhysicsInstitute of Formal and Applied LinguisticsMalostransk?e n?am?est??
25, 11800 Prague, Czech Republic{odusek,hajic,hlavacova,mnovak,pecina,rosa,tamchyna,uresova,zeman}@ufal.mff.cuni.czAbstractThis paper presents the participation ofthe Charles University team in the WMT2014 Medical Translation Task.
Our sys-tems are developed within the Khresmoiproject, a large integrated project aim-ing to deliver a multi-lingual multi-modalsearch and access system for biomedicalinformation and documents.
Being in-volved in the organization of the Medi-cal Translation Task, our primary goal isto set up a baseline for both its subtasks(summary translation and query transla-tion) and for all translation directions.Our systems are based on the phrase-based Moses system and standard meth-ods for domain adaptation.
The con-strained/unconstrained systems differ inthe training data only.1 IntroductionThe WMT 2014 Medical Translation Task posesan interesting challenge for Machine Translation(MT).
In the ?standard?
translation task, the endapplication is the translation itself.
In the Medi-cal Translation Task, the MT system is considereda part of a larger system for Cross-Lingual Infor-mation Retrieval (CLIR) and is used to solve twodifferent problems: (i) translation of user searchqueries, and (ii) translation of summaries of re-trieved documents.In query translation, the end user does not evennecessarily see the MT output as their queries aretranslated and search is performed on documentsin the target language.
In summary translation, thesentences to be translated come from documentsummaries (snippets) displayed to provide infor-mation on each of the documents retrieved by thesearch.
Therefore, translation quality may not bethe most important measure in this task ?
the per-formance of the CLIR system as a whole is thefinal criterion.
Another fundamental differencefrom the standard task is the nature of the trans-lated texts.
While we can consider document sum-maries to be ordinary texts (despite their higher in-formation density in terms of terminology from anarrow domain), search queries in the medical do-main are an extremely specific type of data, andtraditional techniques for system development anddomain adaptation are truly put to a test here.This work is a part of the of the large integratedEU-funded Khresmoi project.1Among othergoals, such as joint text and image retrieval of ra-diodiagnostic records, Khresmoi aims to developtechnology for transparent cross-lingual search ofmedical sources for both professionals and laypeo-ple, with the emphasis primarily on publicly avail-able web sources.In this paper, we describe the Khresmoi sys-tems submitted to the WMT 2014 Medical Trans-lation Task.
We participate in both subtasks (sum-mary translation and query translation) for alllanguage pairs (Czech?English, German?English,and French?English) in both directions (to Englishand from English).
Our systems are based on theMoses phrase-based translation toolkit and stan-dard methods for domain adaptation.
We submitone constrained and one unconstrained system foreach subtask and translation direction.
The con-strained and unconstrained systems differ in train-ing data only: The former use all allowed trainingdata, the latter take advantage of additional web-crawled data.We first summarize previous works in MT do-main adaptation in Section 2, then describe thedata we used for our systems in Section 3.
Sec-1http://www.khresmoi.eu/221tion 4 contains an account of the submitted sys-tems and their performance in translation of searchqueries and document summaries.
Section 5 con-cludes the paper.2 Related workTo put our work in the context of other approaches,we first describe previous work on domain adap-tation in Statistical Machine Translation (SMT),then focus specifically on SMT in the medical do-main.2.1 Domain adaptation of Statistical machinetranslationMany works on domain adaptation examine theusage of available in-domain data to directly im-prove in-domain performance of SMT.
Some au-thors attempt to combine the predictions of twoseparate (in-domain and general-domain) transla-tion models (Langlais, 2002; Sanchis-Trilles andCasacuberta, 2010; Bisazza et al., 2011; Nakov,2008) or language models (Koehn and Schroeder,2007).
Wu and Wang (2004) use in-domain datato improve word alignment in the training phase.Carpuat et al.
(2012) explore the possibility of us-ing word sense disambiguation to discriminate be-tween domains.Other approaches concentrate on the acquisitionof larger in-domain corpora.
Some of them ex-ploit existing general-domain corpora by select-ing data that resemble the properties of in-domaindata (e.g., using cross-entropy), thus building alarger pseudo-in-domain training corpus.
Thistechnique is used to adapt language models (Ecket al., 2004b; Moore and Lewis, 2010) as well astranslation models (Hildebrand et al., 2005; Axel-rod et al., 2011) or their combination (Mansour etal., 2011).
Similar approaches to domain adapta-tion are also applied in other tasks, e.g., automaticspeech recognition (Byrne et al., 2004).2.2 Statistical machine translation in themedical domainEck et al.
(2004a) employ an SMT system for thetranslation of dialogues between doctors and pa-tients and show that according to automatic met-rics, a dictionary extracted from the Unified Medi-cal Language System (UMLS) Metathesaurus andits semantic type classification (U.S. National Li-brary of Medicine, 2009) significantly improvestranslation quality from Spanish to English whenapplied to generalize the training data.Wu et al.
(2011) analyze the quality of MT onPubMed2titles and whether it is sufficient for pa-tients.
The conclusions are very positive espe-cially for languages with large training resources(English, Spanish, German) ?
the average fluencyand content scores (based on human evaluation)are above four on a five-point scale.
In automaticevaluation, their systems substantially outperformGoogle Translate.
However, the SMT systems arespecifically trained, tuned, and tested on the do-main of PubMed titles, and it is not evident howthey would perform on other medical texts.Costa-juss`a et al.
(2012) are less optimistic re-garding SMT quality in the medical domain.
Theyanalyze and evaluate the quality of public web-based MT systems (such as Google Translate) andconclude that in both automatic and manual eval-uation (on 7 language pairs), the performance ofthese systems is still not good enough to be usedin daily routines of medical doctors in hospitals.Jimeno Yepes et al.
(2013) propose a methodfor obtaining in-domain parallel corpora from ti-tles and abstracts of publications in the MED-LINE3database.
The acquired corpora containfrom 30,000 to 130,000 sentence pairs (dependingon the language pair) and are reported to improvetranslation quality when used for SMT training,compared to a baseline trained on out-of-domaindata.
However, the authors use only one sourceof in-domain parallel data to adapt the translationmodel, and do not use any in-domain monolingualdata to adapt the language model.In this work, we investigate methods combiningthe different kinds of data ?
general-domain, in-domain, and pseudo-in-domain ?
to find the opti-mal approach to this problem.3 Data descriptionThis section includes an overview of the paralleland monolingual data sources used to train oursystems.
Following the task specification, theyare split into constrained and unconstrained sec-tions.
The constrained section includes medical-domain data provided for this task (extracted bythe provided scripts), and general-domain textsprovided as constrained data for the standard task(?general domain?
here is used to denote data2http://www.ncbi.nlm.nih.gov/pubmed/3http://www.nlm.nih.gov/pubs/factsheets/medline.html222Czech?English German?English French?Englishdom set pairs source target pairs source target pairs source targetmed con 2,498 18,126 19,964 4,998 123,686 130,598 6,139 202,245 171,928gen con 15,788 226,711 260,505 4,520 112,818 119,404 40,842 1,470,016 1,211,516gen unc ?
?
?
9,320 525,782 574,373 13,809 961,991 808,222Table 1: Number of sentence pairs and tokens (source/target) in parallel training data (in thousands).dom set English Czech German Frenchmed con 172,991 1,848 63,499 63,022gen con 6,132,107 627,493 1,728,065 1,837,457med unc 3,275,272 36,348 361,881 908,911gen unc 618,084 ?
339,595 204,025Table 2: Number of tokens in monolingual training data (in thousands).which comes from a mixture of various differentdomains, mostly news, parliament proceedings,web-crawls, etc.).
The unconstrained section con-tains automatically crawled data from medical andhealth websites and non-medical data from patentcollections.3.1 Parallel dataThe parallel data summary is presented in Table 1.The main sources of the medical-domain datafor all the language pairs include the EMEA cor-pus (Tiedemann, 2009), the UMLS metathesaurusof health and biomedical vocabularies and stan-dards (U.S. National Library of Medicine, 2009),and bilingual titles of Wikipedia articles belongingto the categories identified to be medical domain.Additional medical-domain data comes from theMAREC patent collection: PatTR (W?aschle andRiezler, 2012) available for DE?EN and FR?EN,and COPPA (Pouliquen and Mazenc, 2011) forFR?EN (only patents from the medical categoriesA61, C12N, and C12P are allowed in the con-strained systems).The constrained general-domain data includethree parallel corpora for all the language pairs:CommonCrawl (Smith et al., 2013), Europarl ver-sion 6 (Koehn, 2005), the News Commentary cor-pus (Callison-Burch et al., 2012).
Further, the con-strained data include CzEng (Bojar et al., 2012)for CS?EN and the UN corpus for FR?EN.For our unconstrained experiments, we also em-ploy parallel data from the non-medical patentsfrom the PatTR and COPPA collections (other cat-egories than A61, C12N, and C12P).3.2 Monolingual dataThe monolingual data is summarized in Table 2.The main sources of the medical-domain mono-lingual data for all languages involve Wikipediapages, UMLS concept descriptions, and non-parallel texts extracted from the medical patentsof the PatTR collections.
For English, the mainsource is the AACT collection of texts from Clin-icalTrials.gov.
Smaller resources include: Drug-Bank (Knox et al., 2011), GENIA (Kim et al.,2003), FMA (Rosse and Mejino Jr., 2008), GREC(Thompson et al., 2009), and PIL (Bouayad-Aghaet al., 2000).In the unconstrained systems, we use additionalmonolingual data from web pages crawled withinthe Khresmoi project: a collection of about onemillion HON-certified4webpages in English re-leased as the test collection for the CLEF 2013eHealth Task 3 evaluation campaign,5additionalweb-crawled HON-certified pages (not publiclyavailable), and other webcrawled medical-domainrelated webpages.The constrained general-domain resources in-clude: the News corpus for CS, DE, EN, and FRcollected for the purpose of the WMT 2014 Stan-dard Task, monolingual parts of the Europarl andNews-Commentary corpora, and the Gigaword forEN and FR.For the FR?EN and DE?EN unconstrained sys-tems, the additional general domain monolingualdata is taken from monolingual texts of non-medical patents in the PatTR collection.4https://www.hon.ch/5https://sites.google.com/site/shareclefehealth/223medical generalconstrained?15?10?5051015?15?10?5051015unconstrained?15?10?5051015Figure 1: Distribution of the domain-specificityscores in the English?French parallel data sets.3.3 Data preprocessingThe data consisting of crawled web pages, namelyCLEF, HON, and non-HON, needed to be cleanedand transformed into a set of sentences.
TheBoilerpipe (Kohlsch?utter et al., 2010) and Justext(Pomik?alek, 2011) tools were used to remove boil-erplate texts and extract just the main content fromthe web pages.
The YALI language detection tool(Majli?s, 2012) trained on both in-domain and gen-eral domain data then filtered out those cleanedpages which were not identified as written in oneof the concerned languages.The rest of the preprocessing procedure was ap-plied to all the datasets mentioned above, bothparallel and monolingual.
The data were tok-enized and normalized by converting or omit-ting some (mostly punctuation) characters.
Aset of language-dependent heuristics was appliedin an attempt to restore and normalize the open-ing/closing quotation marks, i.e.
convert "quoted"to ?quoted?
(Zeman, 2012).
The motivation hereis twofold: First, we hope that paired quota-tion marks could occasionally work as bracketsand better denote parallel phrases for Moses; sec-ond, if Moses learns to output directed quotationmarks, the subsequent detokenization will be eas-ier.
For all systems which translate from German,decompounding is employed to reduce source-sidedata sparsity.
We used BananaSplit for this task(M?uller and Gurevych, 2006).We perform all training and internal evaluationon lowercased data; we trained recasers to post-process the final submissions.medical generalconstrained?15?10?5051015?15?10?5051015unconstrained?15?10?5051015?15?10?5051015Figure 2: Distribution of the domain-specificityscores in the French monolingual data sets.4 Submitted systemsWe first describe our technique of psedo-in-domain data selection in Section 4.1, then com-pare two methods of combining the selected datain Section 4.2.
This, along with using constrainedand unconstrained data sets to train the systems(see Section 3), amounts to a total of four systemvariants submitted for each task.
A description ofthe system settings used is given in Section 4.3.4.1 Data selectionWe follow an approach originally proposed forselection of monolingual sentences for languagemodeling (Moore and Lewis, 2010) and its modi-fication applied to selection of parallel sentences(Axelrod et al., 2011).
This technique assumestwo language models for sentence scoring, onetrained on (true) in-domain text and one trainedon (any) general-domain text in the same lan-guage (e.g., English).
For both data domains(general and medical), we score each sentenceby the difference of its cross-perplexity given thein-domain language model and cross-perplexitygiven the general-domain language model (in thisorder).
We only keep sentences with a negativescore in our data, assuming that these are themost ?medical-like?.
Visualisation of the domain-specificity scores (cross-perplexity difference) inthe FR?EN parallel data and FR monolingual datais illustrated in Figures 1 and 2, respectively.6Thescores (Y axis) are presented for each sentence inincreasing order from left to right (X axis).6For the medical domain, constrained and unconstrainedparallel data are identical.224cs?en de?en en?cs en?de en?fr fr?encon concat 33.64?1.14 32.84?1.24 18.10?0.94 18.29?0.92 33.39?1.11 36.71?1.17con interpol 32.94?1.11 32.31?1.20 18.96?0.93 18.41?0.93 34.06?1.11 37.42?1.21unc concat 34.10?1.11 34.52?1.20 21.12?1.03 19.76?0.92 36.23?1.03 38.15?1.16unc interpol 34.48?1.16 34.92?1.17 22.15?1.06 20.81?0.95 36.26?1.13 37.91?1.13Table 3: BLEU scores of summary translations.cs?en de?en en?cs en?de en?fr fr?encon concat 30.87?4.70 33.21?5.03 23.25?4.85 17.72?4.75 28.64?3.77 35.56?4.94con interpol 32.46?5.05 33.74?4.97 21.56?4.80 16.90?4.39 29.34?3.73 35.28?5.26unc concat 34.88?5.04 31.24?5.59 22.61?4.91 19.13?5.66 33.08?3.80 36.73?4.88unc interpol 33.82?5.16 34.19?5.27 23.93?5.16 15.87?11.31 31.19?3.73 40.25?5.14Table 4: BLEU scores of query translations.The two language models for sentence scoringare trained with a restricted vocabulary extractedfrom the in-domain training data as words occur-ring at least twice (singletons and other words aretreated as out-of-vocabulary).
In our experiments,we apply this technique to select both monolin-gual data for language models and parallel datafor translation models.
Selection of parallel datais based on the English side only.
The in-domainmodels are trained on the monolingual data in thetarget language (constrained or unconstrained, de-pending on the setting).
The general-domain mod-els are trained on the WMT News data.Compared to the approach of Moore and Lewis(2010) and Axelrod et al.
(2011), we prune themodel vocabulary more aggressively ?
we discardnot only the singletons, but also all words withnon-Latin characters, which helps clean the mod-els from noise introduced by the automatic processof data acquisition by web crawling.4.2 Data combinationFor both parallel and monolingual data, we obtaintwo data sets after applying the data selection:?
?medical-like?
data from the medical domain?
?medical-like?
data from the general domain.For each language pair and for each systemtype (constrained/unconstrained), we submittedtwo system variants which differ in how the se-lected data are combined.
The first variant usesa simple concatenation of the two datasets bothfor parallel data and for language model data.
Inthe second variant, we train separate models foreach section and use linear interpolation to com-bine them into a single model.
For language mod-els, we use the SRILM linear interpolation feature(Stolcke, 2002).
We interpolate phrase tables us-ing Tmcombine (Sennrich, 2012).
In both cases,the held-out set for minimizing the perplexity isthe system development set.4.3 System detailsWe compute word alignment on lowercase 4-cha-racter stems using fast align (Dyer et al., 2013).We create phrase tables using the Moses toolkit(Koehn et al., 2007) with standard settings.
Wetrain 5-gram language models on the target-sidelowercase forms using SRILM.
We use MERT(Och, 2003) to tune model weights in our systemson the development data provided for the task.The only difference between the system variantsfor query and summary translation is the tuningset.
In both cases, we use the respective sets pro-vided offcially for the shared task.4.4 ResultsTables 3 and 4 show case-insensitive BLEU scoresof our systems.7As expected, the unconstrainedsystems outperform the constrained ones.
Linearinterpolation outperforms data concatenation quitereliably across language pairs for summary trans-lation.
While the picture for query translation issimilar, there is more variance in the results, sowe cannot state that interpolation definitely works7As we use the same recasers for both summary and querytranslation, our systems are heavily penalized for wrong let-ter case in query translation.
However, letter case is not takeninto account in most CLIR systems.
All BLEU scores re-ported in this paper will be case-insensitive for this reason.225better in this case.
This is due to the sizes of thedevelopment and test sets and most importantlydue to sentence lengths ?
queries are very short,making BLEU unreliable, MERT unstable, andbootstrap resampling intervals wide.If we compare our score to the other competi-tors, we are clearly worse than the best systems forsummary translation.
From this perspective, ourdata filtering seems overly eager (i.e., discardingall sentence pairs with a positive perplexity differ-ence).
An experiment which we leave for futurework is doing one more round of interpolation tocombine a model trained on the data with negativeperplexity with models trained on the remainder.5 ConclusionsWe described the Charles University MT systemused in the Shared Medical Translation Task ofWMT 2014.
Our primary goal was to set up abaseline for both the subtasks and all translationdirections.
The systems are based on the Mosestoolkit, pseudo-in-domain data selection based onperplexity difference and two different methods ofin-domain and out-of-domain data combination:simple data concatenation and linear model inter-polation.We report results of constrained and uncon-strained systems which differ in the training dataonly.
In most experiments, using additional dataimproved the results compared to the constrainedsystems and using linear model interpolation out-performed data concatenation.
While our systemsare on par with best results for case-insensitiveBLEU score in query translation, our overly ea-ger data selection techniques caused lower scoresin summary translation.
In future work, we planto include a special out-of-domain model in oursetup to compensate for this problem.AcknowledgmentsThis work was supported by the EU FP7 projectKhresmoi (contract no.
257528), the Czech Sci-ence Foundation (grant no.
P103/12/G084), andSVV project number 260 104.
This work hasbeen using language resources developed, stored,and distributed by the LINDAT/CLARIN projectof the Ministry of Education, Youth and Sports ofthe Czech Republic (project LM2010013).ReferencesA.
Axelrod, X.
He, and J. Gao.
2011.
Domain adap-tation via pseudo in-domain data selection.
In Pro-ceedings of the 2011 Conference on Empirical Meth-ods in Natural Language Processing, pages 355?362, Edinburgh, United Kingdom.
ACL.A.
Bisazza, N. Ruiz, and M. Federico.
2011.
Fill-up versus interpolation methods for phrase-basedSMT adaptation.
In Proceedings of the Interna-tional Workshop on Spoken Language Translation,pages 136?143, San Francisco, CA, USA.
Interna-tional Speech Communication Association.O.
Bojar, Z.?Zabokrtsk?y, O.
Du?sek, P. Galu?s?c?akov?a,M.
Majli?s, D. Mare?cek, J.
Mar?s?
?k, M. Nov?ak,M.
Popel, and A. Tamchyna.
2012.
The joy ofparallelism with CzEng 1.0.
In Proceedings of theEighth International Conference on Language Re-sources and Evaluation, pages 3921?3928, Istanbul,Turkey.
European Language Resources Association.N.
Bouayad-Agha, D. R. Scott, and R. Power.
2000.Integrating content and style in documents: A casestudy of patient information leaflets.
InformationDesign Journal, 9(2?3):161?176.W.
Byrne, D. S. Doermann, M. Franz, S. Gustman,J.
Haji?c, D. W. Oard, et al.
2004.
Automatic recog-nition of spontaneous speech for access to multilin-gual oral history archives.
Speech and Audio Pro-cessing, IEEE Transactions on, 12(4):420?435.C.
Callison-Burch, P. Koehn, C. Monz, M. Post,R.
Soricut, and L. Specia.
2012.
Findings of the2012 Workshop on Statistical Machine Translation.In Proceedings of the Seventh Workshop on Statis-tical Machine Translation, pages 10?51, Montr?eal,Canada.
ACL.M.
Carpuat, H. Daum?e III, A. Fraser, C. Quirk,F.
Braune, A. Clifton, et al.
2012.
Domain adap-tation in machine translation: Final report.
In2012 Johns Hopkins Summer Workshop Final Re-port, pages 61?72.
Johns Hopkins University.M.
R. Costa-juss`a, M. Farr?us, and J. Serrano Pons.2012.
Machine translation in medicine.
A qual-ity analysis of statistical machine translation in themedical domain.
In Proceedings of the 1st VirtualInternational Conference on Advanced Research inScientific Areas, pages 1995?1998,?Zilina, Slovakia.
?Zilinsk?a univerzita.C.
Dyer, V. Chahuneau, and N. A. Smith.
2013.
A sim-ple, fast, and effective reparameterization of IBMmodel 2.
In Proceedings of NAACL-HLT, pages644?648.M.
Eck, S. Vogel, and A. Waibel.
2004a.
Improv-ing statistical machine translation in the medical do-main using the Unified Medical Language System.In COLING 2004: Proceedings of the 20th Inter-national Conference on Computational Linguistics,pages 792?798, Geneva, Switzerland.
ACL.226M.
Eck, S. Vogel, and A. Waibel.
2004b.
Languagemodel adaptation for statistical machine translationbased on information retrieval.
In Maria TeresaLino, Maria Francisca Xavier, F?atima Ferreira, RuteCosta, and Raquel Silva, editors, Proceedings of theInternational Conference on Language Resourcesand Evaluation, pages 327?330, Lisbon, Portugal.European Language Resources Association.A.
S. Hildebrand, M. Eck, S. Vogel, and A. Waibel.2005.
Adaptation of the translation model for statis-tical machine translation based on information re-trieval.
In Proceedings of the 10th Annual Con-ference of the European Association for MachineTranslation, pages 133?142, Budapest, Hungary.European Association for Machine Translation.A.
Jimeno Yepes,?E.
Prieur-Gaston, and A. N?ev?eol.2013.
Combining MEDLINE and publisher data tocreate parallel corpora for the automatic translationof biomedical text.
BMC Bioinformatics, 14(1):1?10.J.-D Kim, T. Ohta, Y. Tateisi, and J. Tsujii.
2003.
GE-NIA corpus ?
a semantically annotated corpus forbio-textmining.
Bioinformatics, 19(suppl 1):i180?i182.C.
Knox, V. Law, T. Jewison, P. Liu, Son Ly, A. Frolkis,A.
Pon, K. Banco, C. Mak, V. Neveu, Y. Djoum-bou, R. Eisner, A. C. Guo, and D. S. Wishart.2011.
DrugBank 3.0: a comprehensive resource for?Omics?
research on drugs.
Nucleic acids research,39(suppl 1):D1035?D1041.P.
Koehn and J. Schroeder.
2007.
Experiments in do-main adaptation for statistical machine translation.In Proceedings of the Second Workshop on Statis-tical Machine Translation, pages 224?227, Prague,Czech Republic.
ACL.P.
Koehn, H. Hoang, A. Birch, C. Callison-Burch,M.
Federico, N. Bertoldi, B. Cowan, W. Shen,C.
Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin,and E. Herbst.
2007.
Moses: Open Source Toolkitfor Statistical Machine Translation.
In Proceedingsof the 45th Annual Meeting of the Association forComputational Linguistics Companion Volume Pro-ceedings of the Demo and Poster Sessions, pages177?180, Praha, Czechia, June.
ACL.P.
Koehn.
2005.
Europarl: a parallel corpus for sta-tistical machine translation.
In Conference Proceed-ings: the tenth Machine Translation Summit, pages79?86, Phuket, Thailand.
Asia-Pacific Associationfor Machine Translation.C.
Kohlsch?utter, P. Fankhauser, and W. Nejdl.
2010.Boilerplate detection using shallow text features.
InProceedings of the Third ACM International Confer-ence on Web Search and Data Mining, WSDM ?10,pages 441?450, New York, NY, USA.
ACM.P.
Langlais.
2002.
Improving a general-purpose statis-tical translation engine by terminological lexicons.In COLING-02 on COMPUTERM 2002: secondinternational workshop on computational terminol-ogy, volume 14, pages 1?7, Taipei, Taiwan.
ACL.M.
Majli?s.
2012.
Yet another language identifier.
InProceedings of the Student Research Workshop atthe 13th Conference of the European Chapter of theAssociation for Computational Linguistics, pages46?54, Avignon, France.
ACL.S.
Mansour, J. Wuebker, and H. Ney.
2011.
Com-bining translation and language model scoring fordomain-specific data filtering.
In InternationalWorkshop on Spoken Language Translation, pages222?229, San Francisco, CA, USA.
ISCA.R.
C. Moore and W. Lewis.
2010.
Intelligent selectionof language model training data.
In Proceedings ofthe ACL 2010 Conference Short Papers, pages 220?224, Uppsala, Sweden.
ACL.C.
M?uller and I. Gurevych.
2006.
Exploring the po-tential of semantic relatedness in information re-trieval.
In LWA 2006 Lernen ?
Wissensentdeck-ung ?
Adaptivit?at, 9.-11.10.2006, Hildesheimer In-formatikberichte, pages 126?131, Hildesheim, Ger-many.
Universit?at Hildesheim.P.
Nakov.
2008.
Improving English?Spanish statisticalmachine translation: Experiments in domain adapta-tion, sentence paraphrasing, tokenization, and recas-ing.
In Proceedings of the Third Workshop on Statis-tical Machine Translation, pages 147?150, Colum-bus, OH, USA.
ACL.F.
J. Och.
2003.
Minimum error rate training in statis-tical machine translation.
In ACL ?03: Proceedingsof the 41st Annual Meeting on Association for Com-putational Linguistics, pages 160?167, Morristown,NJ, USA.
ACL.J.
Pomik?alek.
2011.
Removing Boilerplate and Du-plicate Content from Web Corpora.
PhD thesis,Masaryk University, Faculty of Informatics, Brno.B.
Pouliquen and C. Mazenc.
2011.
COPPA, CLIRand TAPTA: three tools to assist in overcoming thepatent barrier at WIPO.
In Proceedings of the Thir-teenth Machine Translation Summit, pages 24?30,Xiamen, China.
Asia-Pacific Association for Ma-chine Translation.C.
Rosse and Jos?e L. V. Mejino Jr. 2008.
The foun-dational model of anatomy ontology.
In A. Burger,D.
Davidson, and R. Baldock, editors, Anatomy On-tologies for Bioinformatics, volume 6 of Computa-tional Biology, pages 59?117.
Springer London.G.
Sanchis-Trilles and F. Casacuberta.
2010.
Log-linear weight optimisation via Bayesian adaptationin statistical machine translation.
In Proceedingsof the 23rd International Conference on Computa-tional Linguistics: Posters, pages 1077?1085, Bei-jing, China.
ACL.227R.
Sennrich.
2012.
Perplexity minimization for trans-lation model domain adaptation in statistical ma-chine translation.
In Proceedings of the 13th Confer-ence of the European Chapter of the Association forComputational Linguistics, pages 539?549.
ACL.J.
R. Smith, H. Saint-Amand, M. Plamada, P. Koehn,C.
Callison-Burch, and A. Lopez.
2013.
Dirt cheapweb-scale parallel text from the common crawl.
InProceedings of the 51st Annual Meeting of the As-sociation for Computational Linguistics (Volume 1:Long Papers), pages 1374?1383, Sofia, Bulgaria.ACL.A.
Stolcke.
2002.
SRILM ?
an extensible languagemodeling toolkit.
In Proceedings of InternationalConference on Spoken Language Processing, Den-ver, Colorado, USA.P.
Thompson, S. Iqbal, J. McNaught, and Sophia Ana-niadou.
2009.
Construction of an annotated corpusto support biomedical information extraction.
BMCbioinformatics, 10(1):349.J.
Tiedemann.
2009.
News from OPUS ?
a collectionof multilingual parallel corpora with tools and in-terfaces.
In Recent Advances in Natural LanguageProcessing, volume 5, pages 237?248, Borovets,Bulgaria.
John Benjamins.U.S.
National Library of Medicine.
2009.
UMLSreference manual.
Metathesaurus.
Bethesda, MD,USA.K.
W?aschle and S. Riezler.
2012.
Analyzing paral-lelism and domain similarities in the MAREC patentcorpus.
In M. Salampasis and B. Larsen, edi-tors, Multidisciplinary Information Retrieval, vol-ume 7356 of Lecture Notes in Computer Science,pages 12?27.
Springer Berlin Heidelberg.H.
Wu and H. Wang.
2004.
Improving domain-specificword alignment with a general bilingual corpus.
InRobert E. Frederking and Kathryn B. Taylor, editors,Machine Translation: From Real Users to Research,volume 3265 of Lecture Notes in Computer Science,pages 262?271.
Springer Berlin Heidelberg.C.
Wu, F. Xia, L. Deleger, and I. Solti.
2011.
Statisticalmachine translation for biomedical text: are we thereyet?
AMIA Annual Symposium proceedings, pages1290?1299.D.
Zeman.
2012.
Data issues of the multilingual trans-lation matrix.
In Proceedings of the Seventh Work-shop on Statistical Machine Translation, pages 395?400, Montr?eal, Canada.
ACL.228
