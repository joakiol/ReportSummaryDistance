Proceedings of the 43rd Annual Meeting of the ACL, pages 387?394,Ann Arbor, June 2005. c?2005 Association for Computational LinguisticsWord Sense Disambiguation vs. Statistical Machine TranslationMarine CARPUAT Dekai WU1marine@cs.ust.hk dekai@cs.ust.hkHuman Language Technology CenterHKUSTDepartment of Computer ScienceUniversity of Science and TechnologyClear Water Bay, Hong KongAbstractWe directly investigate a subject of muchrecent debate: do word sense disambiga-tion models help statistical machine trans-lation quality?
We present empirical re-sults casting doubt on this common, butunproved, assumption.
Using a state-of-the-art Chinese word sense disambigua-tion model to choose translation candi-dates for a typical IBM statistical MTsystem, we find that word sense disam-biguation does not yield significantly bet-ter translation quality than the statisticalmachine translation system alone.
Erroranalysis suggests several key factors be-hind this surprising finding, including in-herent limitations of current statistical MTarchitectures.1 IntroductionWord sense disambiguation or WSD, the task of de-termining the correct sense of a word in context, isa much studied problem area with a long and hon-orable history.
Recent years have seen steady ac-curacy gains in WSD models, driven in particularby controlled evaluations such as the Senseval seriesof workshops.
Word sense disambiguation is oftenassumed to be an intermediate task, which shouldthen help higher level applications such as machine1The authors would like to thank the Hong Kong Re-search Grants Council (RGC) for supporting this researchin part through grants RGC6083/99E, RGC6256/00E, andDAG03/04.EG09, and several anonymous reviewers for in-sights and suggestions.translation or information retrieval.
However, WSDis usually performed and evaluated as a standalonetask, and to date there have been very few efforts tointegrate the learned WSD models into full statisti-cal MT systems.An energetically debated question at conferencesover the past year is whether even the new state-of-the-art word sense disambiguation models actu-ally have anything to offer to full statistical machinetranslation systems.
Among WSD circles, this cansometimes elicit responses that border on implyingthat even asking the question is heretical.
In effortssuch as Senseval we tend to regard the constructionof WSD models as an obviously correct, if necessar-ily simplified, approach that will eventually lead toessential disambiguation components within largerapplications like machine translation.There is no question that the word sense disam-biguation perspective has led to numerous insights inmachine translation, even of the statistical variety.
Itis often simply an unstated assumption that any fulltranslation system, to achieve full performance, willsooner or later have to incorporate individual WSDcomponents.However, in some translation architectures andparticularly in statistical machine translation (SMT),the translation engine already implicitly factors inmany contextual features into lexical choice.
Fromthis standpoint, SMT models can be seen as WSDmodels in their own right, albeit with several majorcaveats.But typical statistical machine translation modelsonly rely on a local context to choose among lexicaltranslation candidates, as discussed in greater detaillater.
It is therefore often assumed that dedicatedWSD-based lexical choice models, which can incor-387porate a wider variety of context features, can makebetter predictions than the ?weaker?
models implicitin statistical MT, and that these predictions will helpthe translation quality.Nevertheless, this assumption has not been em-pirically verified, and we should not simply assumethat WSD models can contribute more than what theSMT models perform.
It may behoove us to takenote of the sobering fact that, perhaps analogously,WSD has yet to be conclusively shown to help in-formation retrieval systems after many years of at-tempts.In this work, we propose to directly investigatewhether word sense disambiguation?at least as it istypically currently formulated?is useful for statis-tical machine translation.
We tackle a real Chineseto English translation task using a state-of-the-art su-pervised WSD system and a typical SMT model.
Weshow that the unsupervised SMT model, trained onparallel data without any manual sense annotation,yields higher BLEU scores than the case where theSMT model makes use of the lexical choice predic-tions from the supervised WSD model, which aremore expensive to create.
The reasons for the sur-prising difficulty of improving over the translationquality of the SMT model are then discussed andanalyzed.2 Word sense disambiguation vs.statistical machine translationWe begin by examining the respective strengths andweaknesses of dedicated WSD models versus fullSMT models, that could be expected to be relevantto improving lexical choice.2.1 Features Unique to WSDDedicated WSD is typically cast as a classificationtask with a predefined sense inventory.
Sense dis-tinctions and granularity are often manually prede-fined, which means that they can be adapted to thetask at hand, but also that the translation candidatesare limited to an existing set.To improve accuracy, dedicated WSD models typ-ically employ features that are not limited to the lo-cal context, and that include more linguistic infor-mation than the surface form of words.
This of-ten requires several stages of preprocessing, suchas part-of-speech tagging and/or parsing.
(Prepro-cessor domain can be an issue, since WSD accu-racy may suffer from domain mismatches betweenthe data the preprocessors were trained on, and thedata they are applied to.)
For example, a typi-cal dedicated WSD model might employ featuresas described by Yarowsky and Florian (2002) intheir ?feature-enhanced naive Bayes model?, withposition-sensitive, syntactic, and local collocationalfeatures.
The feature set made available to the WSDmodel to predict lexical choices is therefore muchricher than that used by a statistical MT model.Also, dedicated WSD models can be supervised,which yields significantly higher accuracies than un-supervised.
For the experiments described in thisstudy we employed supervised training, exploit-ing the annotated corpus that was produced for theSenseval-3 evaluation.2.2 Features Unique to SMTUnlike lexical sample WSD models, SMT modelssimultaneously translate complete sentences ratherthan isolated target words.
The lexical choices aremade in a way that heavily prefers phrasal cohesionin the output target sentence, as scored by the lan-guage model.
That is, the predictions benefit fromthe sentential context of the target language.
Thishas the general effect of improving translation flu-ency.The WSD accuracy of the SMT model dependscritically on the phrasal cohesion of the target lan-guage.
As we shall see, this phrasal cohesion prop-erty has strong implications for the utility of WSD.In other work (forthcoming), we investigatedthe inverse question of evaluating the Chinese-to-English SMT model on word sense disambigua-tion performance, using standard WSD evaluationmethodology and datasets from the Senseval-3 Chi-nese lexical sample task.
We showed the accuracy ofthe SMT model to be significantly lower than that ofall the dedicated WSD models considered, even af-ter adding the lexical sample data to the training setfor SMT to allow for a fair comparison.
These re-sults highlight the relative strength, and the potentialhoped-for advantage of dedicated supervised WSDmodels.3883 The WSD systemThe WSD system used for the experiments is basedon the model that achieved the best performance, bya large margin, on the Senseval-3 Chinese lexicalsample task (Carpuat et al, 2004).3.1 Classification modelThe model consists of an ensemble of four votingmodels combined by majority vote.The first voting model is a naive Bayes model,since Yarowsky and Florian (2002) found this modelto be the most accurate classifier in a comparativestudy on a subset of Senseval-2 English lexical sam-ple data.The second voting model is a maximum entropymodel (Jaynes, 1978), since Klein and Manning(2002) found that this model yielded higher accu-racy than naive Bayes in a subsequent comparisonof WSD performance.
(Note, however, that a differ-ent subset of either Senseval-1 or Senseval-2 Englishlexical sample data was used for their comparison.
)The third voting model is a boosting model (Fre-und and Schapire, 1997), since has consistentlyturned in very competitive scores on related taskssuch as named entity classification (Carreras et al,2002) .
Specifically, an AdaBoost.MH model wasused (Schapire and Singer, 2000), which is a multi-class generalization of the original boosting algo-rithm, with boosting on top of decision stump clas-sifiers (i.e., decision trees of depth one).The fourth voting model is a Kernel PCA-basedmodel (Wu et al, 2004).
Kernel Principal Compo-nent Analysis (KPCA) is a nonlinear kernel methodfor extracting nonlinear principal components fromvector sets where, conceptually, the n-dimensionalinput vectors are nonlinearly mapped from theiroriginal space Rn to a high-dimensional featurespace F where linear PCA is performed, yielding atransform by which the input vectors can be mappednonlinearly to a new set of vectors (Scho?lkopf et al,1998).
WSD can be performed by a Nearest Neigh-bor Classifier in the high-dimensional KPCA featurespace.
(Carpuat et al, 2004) showed that KPCA-based WSD models achieve close accuracies to thebest individual WSD models, while having a signif-icantly different bias.All these classifiers have the ability to handlelarge numbers of sparse features, many of whichmay be irrelevant.
Moreover, the maximum entropyand boosting models are known to be well suited tohandling features that are highly interdependent.The feature set used consists of position-sensitive,syntactic, and local collocational features, as de-scribed by Yarowsky and Florian (2002).3.2 Lexical choice mapping modelIdeally, we would like the WSD model to predict En-glish translations given Chinese target words in con-text.
Such a model requires Chinese training dataannotated with English senses, but such data is notavailable.
Instead, the WSD system was trained us-ing the Senseval-3 Chinese lexical sample task data.
(This is suboptimal, but reflects the difficulties thatarise when considering a real translation task; wecannot assume that sense-annotated data will alwaysbe available for all language pairs.
)The Chinese lexical sample task includes 20 tar-get words.
For each word, several senses are definedusing the HowNet knowledge base.
There are an av-erage of 3.95 senses per target word type, rangingfrom 2 to 8.
Only about 37 training instances pertarget word are available.For the purpose of Chinese to English translation,the WSD model should predict English translationsinstead of HowNet senses.
Fortunately, HowNetprovides English glosses.
This allows us to mapeach HowNet sense candidate to a set of Englishtranslations, converting the monolingual ChineseWSD system into a translation lexical choice model.We further extended the mapping to include any sig-nificant translation choice considered by the SMTsystem but not in HowNet.4 The SMT systemTo build a representative baseline statistical machinetranslation system, we restricted ourselves to mak-ing use of freely available tools, since the potentialcontribution of WSD should be easier to see againstthis baseline.
Note that our focus here is not on theSMT model itself; our aim is to evaluate the impactof WSD on a real Chinese to English statistical ma-chine translation task.389Table 1: Example of the translation candidates before and after mapping for the target word ?4?
(lu)HowNet Sense ID HowNet glosses HowNet glosses + improved transla-tions56520 distance distance56521 sort sort56524 Lu Lu56525, 56526, 56527, 56528 path, road, route, way path, road, route, way, circuit, roads56530, 56531, 56532 line, means, sequence line, means, sequence, lines56533, 56534 district, region district, region4.1 Alignment modelThe alignment model was trained with GIZA++(Och and Ney, 2003), which implements the mosttypical IBM and HMM alignment models.
Transla-tion quality could be improved using more advancedhybrid phrasal or tree models, but this would inter-fere with the questions being investigated here.
Thealignment model used is IBM-4, as required by ourdecoder.
The training scheme consists of IBM-1,HMM, IBM-3 and IBM-4, following (Och and Ney,2003).The training corpus consists of about 1 millionsentences from the United Nations Chinese-Englishparallel corpus from LDC.
This corpus was automat-ically sentence-aligned, so the training data does notrequire as much manual annotation as for the WSDmodel.4.2 Language modelThe English language model is a trigram modeltrained on the Gigaword newswire data and on theEnglish side of the UN and Xinhua parallel corpora.The language model is also trained using a publiclyavailable software, the CMU-Cambridge StatisticalLanguage Modeling Toolkit (Clarkson and Rosen-feld, 1997).4.3 DecodingThe ISI ReWrite decoder (Germann, 2003), whichimplements an efficient greedy decoding algorithm,is used to translate the Chinese sentences, using thealignment model and language model previously de-scribed.Notice that very little contextual information isavailable to the SMT models.
Lexical choice dur-ing decoding essentially depends on the translationprobabilities learned for the target word, and on theEnglish language model scores.5 Experimental method5.1 Test set selectionWe extracted the Chinese sentences from the NISTMTEval-04 test set that contain any of the 20 targetwords from the Senseval-3 Chinese lexical sampletarget set.
For a couple of targets, no instances wereavailable from the test set.
The resulting test set con-tains a total of 175 sentences, which is smaller thantypical MT evaluation test sets, but slightly largerthan the one used for the Senseval Chinese lexicalsample task.5.2 Integrating the WSD system predictionswith the SMT modelThere are numerous possible ways to integrate theWSD system predictions with the SMT model.
Wechoose two different straightforward approaches,which will help analyze the effect of the differentcomponents of the SMT system, as we will see inSection 6.5.5.2.1 Using WSD predictions for decodingIn the first approach, we use the WSD sense pre-dictions to constrain the set of English sense candi-dates considered by the decoder for each of the tar-get words.
Instead of allowing all the word transla-tion candidates from the translation model, when weuse the WSD predictions we override the translationmodel and force the decoder to choose the best trans-lation from the predefined set of glosses that maps tothe HowNet sense predicted by the WSD model.390Table 2: Translation quality with and without the WSD modelTranslation System BLEU scoreSMT 0.1310SMT + WSD for postprocessing 0.1253SMT + WSD for decoding 0.1239SMT + WSD for decoding with improved translation candidates 0.12325.2.2 Using WSD predictions forpostprocessingIn the second approach, we use the WSD predic-tions to postprocess the output of the SMT system:in each output sentence, the translation of the targetword chosen by the SMT model is directly replacedby the WSD prediction.
When the WSD system pre-dicts more than one candidate, a unique translationis randomly chosen among them.
As discussed later,this approach can be used to analyze the effect of thelanguage model on the output.It would also be interesting to use the gold stan-dard or correct sense of the target words instead ofthe WSD model predictions in these experiments.This would give an upper-bound on performanceand would quantify the effect of WSD errors.
How-ever, we do not have a corpus which contains bothsense annotation and multiple reference translations:the MT evaluation corpus is not annotated with thecorrect senses of Senseval target words, and the Sen-seval corpus does not include English translations ofthe sentences.6 Results6.1 Even state-of-the-art WSD does not helpBLEU scoreTable 2 summarizes the translation quality scoresobtained with and without the WSD model.
Usingour WSD model to constrain the translation candi-dates given to the decoder hurts translation quality,as measured by the automated BLEU metric (Pap-ineni et al, 2002).Note that we are evaluating on only difficult sen-tences containing the problematic target words fromthe lexical sample task, so BLEU scores can be ex-pected to be on the low side.6.2 WSD still does not help BLEU score withimproved translation candidatesOne could argue that the translation candidates cho-sen by the WSD models do not help because theyare only glosses obtained from the HowNet dictio-nary.
They consist of the root form of words only,while the SMT model can learn many more transla-tions for each target word, including inflected formsand synonyms.In order to avoid artificially penalizing the WSDsystem by limiting its translation candidates to theHowNet glosses, we expand the translation set us-ing the bilexicon learned during translation modeltraining.
For each target word, we consider the En-glish words that are given a high translation prob-ability, and manually map each of these Englishwords to the sense categories defined for the Sen-seval model.
At decoding time, the set of transla-tion candidates considered by the language model istherefore larger, and closer to that considered by thepure SMT system.The results in Table 2 show that the improvedtranslation candidates do not help BLEU score.
Thetranslation quality obtained with SMT alone is stillbetter than when the improved WSD Model is used.The simpler approach of using WSD predictions inpostprocessing yields better BLEU score than thedecoding approach, but still does not outperform theSMT model.6.3 WSD helps translation quality for very fewtarget wordsIf we break down the test set and evaluate the effectof the WSD per target word, we find that for all buttwo of the target words WSD either hurts the BLEUscore or does not help it, which shows that the de-crease in BLEU is not only due to a few isolated tar-get words for which the Senseval sense distinctions391are not helpful.6.4 The ?language model effect?Error analysis revealed some surprising effects.
Oneparticularly dismaying effect is that even in caseswhere the WSD model is able to predict a better tar-get word translation than the SMT model, to use thebetter target word translation surprisingly often stillleads to a lower BLEU score.The phrasal coherence property can help explainthis surprising effect we observed.
The translationchosen by the SMT model will tend to be more likelythan the WSD prediction according to the languagemodel; otherwise, it would also have been predictedby SMT.
The translation with the higher languagemodel probability influences the translation of itsneighbors, thus potentially improving BLEU score,while the WSD prediction may not have been seenoccurring within phrases often enough, thereby low-ering BLEU score.For example, we observe that the WSD modelsometimes correctly predicts ?impact?
as a bettertranslation for ????
(chongji), where the SMTmodel selects ?shock?.
In these cases, some ofthe reference translations also use ?impact?.
How-ever, even when the WSD model constrains the de-coder to select ?impact?
rather than ?shock?, theresulting sentence translation yields a lower BLEUscore.
This happens because the SMT model doesnot know how to use ?impact?
correctly (if it did, itwould likely have chosen ?impact?
itself).
Forcingthe lexical choice ?impact?
simply causes the SMTmodel to generate phrases such as ?against Japan forpeace constitution impact?
instead of ?against Japanfor peace constitution shocks?.
This actually lowersBLEU score, because of the n-gram effects.6.5 Using WSD predictions in postprocessingdoes not help BLEU score eitherIn the postprocessing approach, decoding is donebefore knowing the WSD predictions, which elim-inates the ?language model effect?.
Even in theseconditions, the SMT model alone is still the best per-forming system.The postprocessing approach also outperformsthe integrated decoding approach, which shows thatthe language model is not able to make use of theWSD predictions.
One could expect that letting theTable 3: BLEU scores per target word: WSD helpsfor very few target wordsTarget word SMT SMT +WSD??
bawo 0.1482 0.1484?
bao 0.1891 0.1891a?
cailiao 0.0863 0.0863??
chongji 0.1396 0.1491?0 difang 0.1233 0.1083I fengzi 0.1404 0.1402??
huodong 0.1365 0.1465?
lao 0.1153 0.11364 lu 0.1322 0.1208?u qilai 0.1104 0.1082 qian 0.1948 0.1814B?
tuchu 0.0975 0.0989??
yanjiu 0.1089 0.1089??
zhengdong 0.1267 0.1251 zhou 0.0825 0.0808decoder choose among the WSD translations alsoyields a better translation of the context.
This isindeed the case, but for very few examples only:for instance the target word ??0?
(difang) is bet-ter used in the integrated decoding ouput ?the placeof local employment?
, than in the postprocessingoutput ?the place employment situation?.
Instead,the majority of cases follow the pattern illustratedby the following example where the target word is???
(lao): the SMT system produces the best output(?the newly elected President will still face old prob-lems?
), the postprocessed output uses the fluent sen-tence with a different translation (?the newly electedPresident will still face outdated problems?
), whilethe translation is not used correctly with the decod-ing approach (?the newly elected President will faceproblems still to be outdated?
).6.6 BLEU score biasThe ?language model effect?
highlights one of thepotential weaknesses of the BLEU score.
BLEU pe-nalizes for phrasal incoherence, which in the presentstudy means that it can sometimes sacrifice ade-quacy for fluency.However, the characteristics of BLEU are by392no means solely responsible for the problems withWSD that we observed.
To doublecheck that n-grameffects were not unduly impacting our study, we alsoevaluated using BLEU-1, which gave largely simi-lar results as the standard BLEU-4 scores reportedabove.7 Related workMost translation disambiguation tasks are definedsimilarly to the Senseval Multilingual lexical sam-ple tasks.
In Senseval-3, the English to Hindi trans-lation disambigation task was defined identically tothe English lexical sample task, except that the WSDmodels are expected to predict Hindi translations in-stead of WordNet senses.
This differs from our ap-proach which consists of producing the translationof complete sentences, and not only of a predefinedset of target words.Brown et al (1991) proposed a WSD algorithm todisambiguate English translations of French targetwords based on the single most informative contextfeature.
In a pilot study, they found that using thisWSD method in their French-English SMT systemhelped translation quality, manually evaluated usingthe number of acceptable translations.
However, thisstudy is limited to the unrealistic case of words thathave exactly two senses in the other language.Most previous work has focused on the distinctproblem of exploiting various bilingual resources(e.g., parallel or comparable corpora, or even MTsystems) to help WSD.
The goal is to achieve accu-rate WSD with minimum amounts of annotated data.Again, this differs from our objective which consistsof using WSD to improve performance on a full ma-chine translation task, and is measured in terms oftranslation quality.For instance, Ng et al (2003) showed that it ispossible to use word aligned parallel corpora to trainaccurate supervised WSD models.
The objective isdifferent; it is not possible for us to use this methodto train our WSD model without undermining thequestion we aim to investigate: we would need touse the SMT model to word-align the parallel sen-tences, which could too strongly bias the predic-tions of the WSD model towards those of the SMTmodel, instead of combining predictive informationfrom independent sources as we aim to study here.Other work includes Li and Li (2002) who pro-pose a bilingual bootstrapping method to learn atranslation disambiguation WSD model, and Diab(2004) who exploited large amounts of automati-cally generated noisy parallel data to learn WSDmodels in an unsupervised bootstrapping scheme.8 ConclusionThe empirical study presented here argues that wecan expect that it will be quite difficult, at the least,to use standard WSD models to obtain significantimprovements to statistical MT systems, even whensupervised WSD models are used.
This casts signif-icant doubt on a commonly-held, but unproven, as-sumption to the contrary.
We have presented empiri-cally based analysis of the reasons for this surprisingfinding.We have seen that one major factor is that thestatistical MT model is sufficiently accurate so thatwithin the training domain, even the state-of-the-artdedicated WSD model is only able to improve on itslexical choice predictions in a relatively small pro-portion of cases.A second major factor is that even when the ded-icated WSD model makes better predictions, cur-rent statistical MT models are unable to exploit this.Under this interpretation of our results, the depen-dence on the language model in current SMT ar-chitectures is excessive.
One could of course ar-gue that drastically increasing the amount of train-ing data for the language model might overcome theproblems from the language model effect.
Givencombinatorial problems, however, there is no way atpresent of telling whether the amount of data neededto achieve this is realistic, particularly for translationacross many different domains.
On the other hand, ifthe SMT architecture cannot make use of WSD pre-dictions, even when they are in fact better than theSMT?s lexical choices, then perhaps some alterna-tive model striking a different balance of adequacyand fluency is called for.
Ultimately, after all, WSDis a method of compensating for sparse data.
Thusit may be that the present inability of WSD modelsto help improve accuracy of SMT systems stems notfrom an inherent weakness of dedicated WSD mod-els, but rather from limitations of present-day SMTarchitectures.393To further test this, our experiments could betried on other statistical MT models.
For exam-ple, the WSD model?s predictions could be em-ployed in a Bracketing ITG translation model suchas Wu (1996) or Zens et al (2004), or alternativelythey could be incorporated as features for rerank-ing in a maximum-entropy SMT model (Och andNey, 2002), instead of using them to constrain thesentence translation hypotheses as done here.
How-ever, the preceding discussion argues that it is doubt-ful that this would produce significantly different re-sults, since the inherent problem from the ?languagemodel effect?
would largely remain, causing sen-tence translations that include the WSD?s preferredlexical choices to be discounted.
For similar rea-sons, we suspect our findings may also hold even formore sophisticated statistical MT models that relyheavily on n-gram language models.
A more gram-matically structured statistical MT model that less n-gram oriented, such as the ITG based ?grammaticalchannel?
translation model (Wu and Wong, 1998),might make more effective use of the WSD model?spredictions.ReferencesPeter Brown, Stephen Della Pietra, Vincent Della Pietra, andRobert Mercer.
Word-sense disambiguation using statisticalmethods.
In Proceedings of 29th meeting of the Associa-tion for Computational Linguistics, pages 264?270, Berke-ley, California, 1991.Marine Carpuat, Weifeng Su, and Dekai Wu.
Augmenting en-semble classification for word sense disambiguation with aKernel PCA model.
In Proceedings of Senseval-3, ThirdInternational Workshop on Evaluating Word Sense Disam-biguation Systems, Barcelona, July 2004.
SIGLEX, Associ-ation for Computational Linguistics.Xavier Carreras, Llu?
?s Ma`rques, and Llu?
?s Padro?.
Named en-tity extraction using AdaBoost.
In Dan Roth and Antal vanden Bosch, editors, Proceedings of CoNLL-2002, pages 167?170, Taipei, Taiwan, 2002.Philip Clarkson and Ronald Rosenfeld.
Statistical languagemodeling using the CMU-Cambridge toolkit.
In Proceed-ings of Eurospeech ?97, pages 2707?2710, Rhodes, Greece,1997.Mona Diab.
Relieving the data acquisition bottleneck in wordsense disambiguation.
In Proceedings of the 42nd AnnualMeeting of the Association for Computational Linguistics,2004.Yoram Freund and Robert E. Schapire.
A decision-theoreticgeneralization of on-line learning and an application toboosting.
In Journal of Computer and System Sciences,55(1), pages 119?139, 1997.Ulrich Germann.
Greeedy decoding for statistical machinetranslation in almost linear time.
In Proceedings of HLT-NAACL-2003.
Edmonton, AB, Canada, 2003.E.T.
Jaynes.
Where do we Stand on Maximum Entropy?
MITPress, Cambridge MA, 1978.Dan Klein and Christopher D. Manning.
Conditional structureversus conditional estimation in NLP models.
In Proceed-ings of EMNLP-2002, Conference on Empirical Methodsin Natural Language Processing, pages 9?16, Philadelphia,July 2002.
SIGDAT, Association for Computational Linguis-tics.Cong Li and Hang Li.
Word translation disambiguation usingbilingual bootstrapping.
In Proceedings of the 40th AnnualMeeting of the Association for Computational Linguistics,pages 343?351, 2002.Hwee Tou Ng, Bin Wang, and Yee Seng Chan.
Exploiting paral-lel texts for word sense disambiguation: An empirical study.In Proceedings of ACL-03, Sapporo, Japan, pages 455?462,2003.Franz Och and Hermann Ney.
Discriminative training and max-imum entropy models for statistical machine translation.
InProceedings of ACL-02, Philadelphia, 2002.Franz Josef Och and Hermann Ney.
A systematic comparisonof various statistical alignment models.
Computational Lin-guistics, 29(1):19?52, 2003.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-JingZhu.
BLEU: a method for automatic evaluation of machinetranslation.
In Proceedings of the 40th Annual Meeting ofthe Association for Computational Linguistics, 2002.Robert E. Schapire and Yoram Singer.
BoosTexter: A boosting-based system for text categorization.
Machine Learning,39(2):135?168, 2000.Bernhard Scho?lkopf, Alexander Smola, and Klaus-RoberMu?ller.
Nonlinear component analysis as a kernel eigenvalueproblem.
Neural Computation, 10(5), 1998.Dekai Wu and Hongsing Wong.
Machine translation with astochastic grammatical channel.
In Proceedings of COLING-ACL?98, Montreal,Canada, August 1998.Dekai Wu, Weifeng Su, and Marine Carpuat.
A Kernel PCAmethod for superior word sense disambiguation.
In Proceed-ings of the 42nd Annual Meeting of the Association for Com-putational Linguistics, Barcelona, July 2004.Dekai Wu.
A polynomial-time algorithm for statistical machinetranslation.
In Proceedings of 34th Annual Meeting of theAssociation for Computational Linguistics, Santa Cruz, Cal-ifornia, June 1996.David Yarowsky and Radu Florian.
Evaluating sense disam-biguation across diverse parameter spaces.
Natural Lan-guage Engineering, 8(4):293?310, 2002.Richard Zens, Hermann Ney, Taro Watanabe, and EiichiroSumita.
Reordering constraints for phrase-based statisti-cal machine translation.
In Proceedings of COLING-2004,Geneva,Switzerland, August 2004.394
