Proceedings of the BioNLP Shared Task 2013 Workshop, pages 86?93,Sofia, Bulgaria, August 9 2013. c?2013 Association for Computational LinguisticsPerformance and limitations of the linguistically motivated Cocoa/Pea-berry system in a broad biomedical domain.S.
V. RamananRelAgent Private Ltd.56, Venkatratnam NagarAdyar, Chennai 600020ramanan@npjoint.comP.
Senthil NathanRelAgent Private Ltd.56, Venkatratnam NagarAdyar, Chennai 600020senthil@npjoint.comAbstractWe tested a linguistically motivated rule-based system in the Cancer Genetics taskof the BioNLP13 shared task challenge.The performance of the system was verymoderate, ranging from 52% against thedevelopment set to 45% against the testset.
Interestingly, the performance of thesystem did not change appreciably whenusing only  entities tagged by the inbuilttagger as compared to performance usingthe gold-tagged entities.
The lack of anevent anaphoric module, as well as prob-lems in reducing events generated by alarge trigger class to the task-specificevent subset, were likely major contribut-ory factors to the rather moderate per-formance.1 IntroductionThe Cancer Genetics (CG) task of the BioN-LP-13 shared task (Pyysalo et al 2013) hasevent types defined from a strict subset of GObiological processes.
However, the events in theCG task have arguments that span a range of en-tities from molecules to system-wide processes,the latter focused primarily on cancer.
Thus theCG task is an interesting case-study for text min-ing from a biological point of view, in that thetask spans the literature from molecular events tobehaviors linked to phenotypes, and thus con-siders a broader context than earlier BioNLPshared tasks (Kim et al 2009, 2011).An early article by Swanson (1988) exploredthe value of literature-based discovery (LBD) indiscovering relations that span scientific sub-spe-cializations.
The LBD program of Swanson in-volves 3 nominally independent subtasks: (i) ac-curate representations of events within a docu-ment (b) normalization of entities to a standardrepresentation to facilitate inter-document span-ning and (c) a strategy to span event graphsacross multiple documents.
We explored the CGtask primarily in the context of subtask (a) of thisLBD program.2 MethodsOur system currently consists of the followingmajor components (a) Cocoa, a NER module thatdetects over 20 biomedical entity classes,  in-cluding macromolecules, chemicals,protein/DNA parts, complexes, organisms, pro-cesses, anatomical parts, locations, physiologicalterms, parameters, values, experimental tech-niques, surgical procedures, and foods and (b)Peaberry, a 'stitcher' that combines local predic-ate-argument  structures  to produce a  depend-ency-parse like output.
The system also resolvessortal/pronominal anaphora and coreferences.2.1 Entity detectionAs entity detection is not part of the CG task,we provide only a brief overview of this module.However, as we did not use the entities providedby the event organizers on the test set, this de-scription may be of interest given that our resultswith and without gold entities on the develop-ment and test sets are comparable (please see theResults section below).The Cocoa entity detection system consists ofthe following modules run as a pipeline: (a) sen-tence boundary detection (b) acronym detection(c) a POS tagger based on Brill's tagger, post-modified for the biological domain (d) a fnTBL-based chunker, also heavily postmodified for thebiomedical domain (e) an entity tagging module,86driven by dictionaries based both on words aswell as morphological features, primarily pre-fixes and suffixes for biomedical entities, butalso using infixes for chemical entities (f) entitytag based correction of chunks, primarily mis-tagged VP chunks (g) a narrow context/triggerbased tagging of entities that are orthographicallydefined (presence of caps or numbers) such asassigning a protein tag for Cx43 from the phrase'phosphorylation of Cx43' (h) a multi-word entityaggregator (i) a shallow coordination module forNPs (j) a limited set of hypernymic and apposi-tional relations, followed by reuse of tags for or-thographically defined unlabeled entities (k) achemical formula detector.
The entity tagger per-forms reasonably against proteins, anatomicalparts and diseases as evaluated against existingtagged datasets (RelAgent, 2012).2.2 Event DetectionThe main steps here are: (a) detecting voice/fi-niteness of verbs (b) predicate-argument  struc-ture  extraction  for trigger words (c) argumentmerging and discourse connective parser (d) ana-phora detection (e) discourse-connective basedfilling of empty themes and (f) sense disambigu-ation (WSD) of trigger words based on argumentstructure.
A block-level pipeline of the system isgiven in Figure 1.Figure  1.
Block  level  pipeline  of  the  system.Blocks with a light gray background are part ofthe  event  detection  system (Peaberry),  and  arediscussed here.
The other blocks are part of theCocoa entity tagger.
WSD = Word sense disam-biguation.We will use a single sentence throughout to il-lustrate processing by the various modules:"Concomitantly, immunostaining for apoptosisinducing factor (AIF) showed a time-dependenttranslocation from the mitochondria to the nucle-us.
"2.2.1 Voice detectionThe voice detection module uses about 150rules to detect the voice of a verb.
It also classi-fies the verb as finite/nonfinite while marking itspresence in a reduced or finite relative clause.The module determines these various aspects ofa verb primarily with the local context, but usesthe aspects of a previous verb in cases of co-ordinated verbs.
Voice detection is facilitated byspecific handling of (a)  middle verbs, which ap-pear to be in the active voice, but whose theme isthe subject ('The protein translocated to the nuc-leus')  (b) ergative verbs,  which act  like middleverbs when they do not have a direct object, butbehave regularly when they are used transitively('Protein levels increased' vs 'Application of thechemical increased protein levels') (c) intransit-ives, which are verbs that do not take a direct ob-ject, but whose subject is the agent ('The patientfell'), (d)  verbs in the active voice, but with anobject separated from the verb  by a  preposition('leads to', 'resulted in', 'binds to').
Voice markupis therefore determined primarily by the roles ofthe  subject/object,  and  is  thus  a  little  differentfrom  the  voice  markings  as  conventionallydefined.In the sample sentence, there is only one verb,and the output reads:"[ Concomitantly AV] , [ immunostaining NP]for [ apoptosis inducing factor (AIF) NP] [showed VP_Af] [ a time -dependent transloca-tion NP] from [ the mitochondria NP] to [ thenucleus NP] .
"where the verb phrase 'showed' is in the activevoice ('A') and is finite ('f').
Another sentencesbetter illustrates a wider range in voice markings:[ Adult naive T cells NP] , which [ areVP_Pfcr] at [ rest NP] in [ normal conditionsNP] , [ proliferate strongly VP_Pf] when [ trans-ferred VP_Pnd] to [ lymphopenic hosts NP] .Here 'VP_Pfcr' stands for passive voice ('P'), fi-nite ('f'), copula ('c'), and relative clause ('r'),while 'VP_Pnd' stands for Passive ('P'), non-fin-ite ('n') and reduced ('d').872.2.2 Argument extractionLocal arguments are extracted for all verbs ina sentence, as well as all nominals marked as po-tential  triggers  by  the  entity  tagger.
Currently,there  are  approximately  60  classes  of  predic-ate-argument structures based both on the partic-ular prepositions heading noun phrases as well asentity tags; these classes cover about 500 specifictrigger words.
Additionally, there are generic ar-gument  structures  for  verbs  and  nominals  notcovered in the specific classes above.
We accom-modate  3  additional  arguments  apart  from  theagent/theme, such as FromLoc, ToLoc and AtLocfor movement-type trigger words.
In addition, wealso mark the subject/object nature of the argu-ments.The argument  structures  for  the  sample sen-tence are shown in a pipe separated format (verb|cause|theme):immunostaining  |  -  |  apoptosis  inducing  factor(AIF)showed  |  immunostaining  |  a  time  -dependenttranslocation-dependent | time | translocationtranslocation | - | - | FromLoc:the nucleus| ToLoc:the mitochondria2.2.3 Argument stitching and connectivesWe link argument  structures  for  individualtriggers  by looking for missing syntactical con-stituents for verbs (subject/object) or semanticconstituents for nominals (agent/theme).
Forverbs, we use the voice/finite aspects of the cur-rent verb to locate previous verbs with which thecurrent verb is associated with, either throughembedding or by coordination.
For example, inthe sentence fragment: '...  had no effect on theability  of  beta-adrenergic  agonists  to  stimulateinternalization  of  beta2ARs  ,  but  blocked  theability of ...?,  'blocked' coordinates with the fi-nite  verb  'had'  but  not  with  the  non-finite  'tostimulate'.
An example of an embedding is: 'Withmajor  interfering  currents  inhibited,  NaCaECwas measured as the current that is sensitive tothe  nickel  (Ni)  during  a  descending  voltageramp.'.
Here the VP  'was measured' is finite, andthis allows its object 'the current' to be identifiedas the subject of 'is sensitive'.Other examples of rules for resolving the argu-ments  of  relative  clauses  (RCs)  are:  (a)  Dis-course  connectives  ('whereas,  'whereby,'because')  form  clausal  boundaries  and  shouldnot be crossed (b) Certain coordination markers('besides',  'via')  also  should  not  be  crossed  forRC's (c) If an RC is recognized as coordinatedwith a prior RC, the arguments are transferred.A general point in inferring missing argumentsis that the nature of the current trigger word canalso determine the nature  of  the  induced argu-ment.
Certain trigger words ('induce', 'cause', en-hance',  'prevent')  can take an event as an argu-ment ,  although most  trigger  words  do not(theme argument for 'methylation').
Triggers inthe former class are primarily regulatory actionsand/or belief statements, which can take a clauseor  a  nominal as an  argument.
The  distinctionbetween these two types of trigger words is re-lated  to  that  between  'embedding  propositions'and 'atomic propositions' noted in Kilicoglu andBergler  (2012).
An  example  is:  'Promotermethylation may interfere with AP1 binding tothe  promoter  to  cause  aberrant  Cx43 gene  ex-pression.
', where it is the interference that causesaberrant expression.The stitcher/parser  does not examine  the in-ternal structure of chunks to locate missing argu-ments  for  predicates.
This  rule  is  violated  fortrigger  words  that  can  accept  events  as  argu-ments, where the presence of an event trigger (asmarked  by  the  NER  tagger)  inside  a  NP  ischecked  for.
While  this  makes  the  process  insome sense 'domain-neutral',  it  may also  intro-duce errors unless the  predicate-argument rulesare  complete  and comprehensive for individualtriggers.The parser also locates discourse connectives('whereas', 'because' , 'via', 'when') and assemblesargument frames for these connectives, based onfiniteness of verbs when possible.
Connectives('by') that can take nominals as arguments ('Loc-alization ... by fusing') are also handled by theparser.
Hypernymic and appositional relationsare also detected at this stage.
A final check loc-ates all unattached prepositional phrases in thesentence and attaches them as verbal phrases tothe nearest verb in a greedy step.
At any point,the parser looks back no more than 2 verbs backfor resolution, with parse time thus ~ O(2x),where 'x' is the number of trigger words in a sen-tence.We  recognize  that  the  description  of  the'stitching' process above is somewhat brief, butfeel that a full description may not be appropriatehere due to the large number of rules and interde-pendencies in the system.
We note that:  (a) thefinal output of the process is similar to a depend-ency parse, except that semantic roles are identi-fied (b) the stitching is done in a shallow manner,88with two verbs look-back at most, and is hencereasonably fast and (c) the implementation is ourown, and does not borrow from existing parsers.We plan to describe this system in greater detailin a separate publication elsewhere.As an example, in the paraphrase 'X activatesY to increase Z', the arguments are:activates | X | Yincrease  | - | Zand the stitcher recognizes the infinitival 'to' con-struct, and transfers the previous event as theagent for 'increase':activates | X         | Yincrease  | activates | Z2.3 AnaphoraWe implemented the algorithm of Lappin andLeass (1994) for pronominal anaphora, as imple-mented by Kennedy and Boguraev (1996), withadditional weights for matching entity tags forheadwords.
The weights were refined againsthandpicked abstracts, but are  yet to be com-pletely validated.
In addition, we also resolvedsortal anaphora  ('this protein', 'these genes') andprenominal anaphora ('its binding partner', 'theirproperties')  by the same rules  as  used for  pro-nominal anaphors ('it', 'they'), but with differentweights.
We also implemented event anaphora,i.e.
reference of one trigger word to another trig-ger word with the same root (lemma) or anotherevent in the same class (for regulation triggers).Due to lack of time, we could not completely testthe performance of event anaphora, and theywere dropped in the test set.
Coreference resolu-tion with the determiner 'the' ('the gene') was notimplemented.2.4 Transferring arguments across eventsCertain arguments can be resolved by compar-ing argument structures for events linked by dis-course connectives (DCs), such as :'found to overexpress eph mRNAs withoutgene amplification' (DC: 'without')'Upon retroviral transduction of the mouse c-myc gene, Rat 6 cells showed mildly alteredmorphology' (DC: 'Upon')'SCAI acts on the RhoA-Dia1 signal transduc-tion pathway and localizes in the nucleus, whereit binds and inhibits the myocardin-related tran-scription factor MAL by forming a ternary com-plex with serum response factor (SRF).'
(ana-phoric resolution for 'it' followed by a discourseconnective:'by')When events are linked by a discourse con-nective, arguments can be transferred if theevents are in the same event class.
Even if theevents are of different classes, the theme can betransferred if it satisfies the entity type con-straints of the recipient event.
Further, certain be-lief/demonstration trigger words ('display','show', 'exhibit', 'demonstrate') that take an eventas the theme have a similar structure: 'Cloning ofa  human  phosphoinositide  3-kinase  with  a  C2domain  that  displays  reduced sensitivity  to  theinhibitor wortmannin.'
or 'X exhibits cytotoxicityagainst  cell  lines'.
Agent arguments for suchverbs are transferred to the appropriate argumentslot of the theme event.
In certain contexts, verbssuch as  'act'   which can take  an infinitival  'to'complement behave similarly:   'p15 may act asan effector of TGF-beta-mediated cell cycle ar-rest.
'.For the sample sentence, the trigger/beliefword 'showed' causes a transfer of the theme slotof its cause process ('immunostaining', aPlanned_process in the CG task) to the same slotin the theme event ('translocation'):immunostaining | - | apoptosis inducing factor(AIF)showed | immunostaining | a time -dependenttranslocation-dependent | time | translocationtranslocation | - | apoptosis inducing factor (AIF)| FromLoc:the nucleus| ToLoc: the mitochondria2.5 RuntimesThe run-time of the system is about 100ms/sentence on a 2007 vintage dual-core system.This time was estimated by processing whole ab-stracts varying from 10-15 sentences.
This figureincludes the time for all components, includingentity recognition, parsing, intra-document ana-phora resolution (both sortal/pronominal andevent), event extraction and final A1/A2 output.The extrapolated time of processing for the entireMedline corpus (1.2 x 10^8 sentences in 2013) isabout 180 CPU-days.3 ResultsWe first tested the system against the develop-ment  set  by  using  the  internal  entity  detector(Cocoa) to tag entities, and using these tags alonetill  the  end of  the  event  extraction  phase,  andonly then remapping the Cocoa-tagged entities to89entities in the gold annotations ('a1' entities) giv-en by the task organizers.
This gave a score (f-measure) of 52.2% with the evaluation options '-s  -p'  which  stand  respectively  for  soft  spanmatching  and  partial  recursive  matching.
Wethen reran the event extraction module after re-moving  all  internally  generated  entity  tags  forchemicals, proteins and anatomical parts and tag-ging only such entities as were specified in thegold 'a1' files.
To our surprise, the f-measure was2% lower on the development set when using thegold  entities.
This  probably  indicates  an  un-wanted dependence of the event extraction mod-ule on some peculiarities in the way the internalCocoa tagger tags entities.
We are currently ana-lyzing the results for such dependencies (see Dis-cussion  for  some  examples).
Nevertheless,  theresults  are  encouraging in  that  the  system per-formance is similar with or without reference en-tities and thus may be indicative of performanceon a new document collection where entities arenot specified manually beforehand.As the task allows only one submission,  wesubmitted the results of the system with entitiestagged by the internal tagger and mapped only atthe  end  to  the  gold  tagged  entities.
This  wasbased on the better performance of this approachagainst the development set.
However, the resultsof the system were considerably lower on the testset (f = 45.3%; best score by TEES 2.1 system =55.4%; Pyysalo et  al.,  2013).
Using  the evalu-ation portal for the test dataset, the results withgold-tagged  entities  improved  the  performanceonly by 0.3%, confirming that, at least at the per-formance levels of this system, the inbuilt Cocoaentity tags can substitute for pre-annotated entit-ies.The  performance  on  the  test  set  was  lowprimarily  against  the  events  in  the  regulationclass (f=35.6%),  which form about 40% of theevents in both the test and development sets.
Thisis  similar  to  the  result  in  the  development  set,where  the  performance  in  the  regulation  classwas also quite low at f=37%.
Part of the reasonfor this is that the system's rules for regulatorytriggers generally give preference to other eventsover entities as causes/agents.
Thus for examplein  the  sentence  fragment  (PMID:21963494)'AglRhz  induced  activation  of  caspase-3  andpoly(ADP-ribose) polymerase (PARP), and DNAfragmentation in HT-29 cells, leads to inductionof apoptosis as well as suppression of tumorigen-icity of HT-29 cells.
', the gold annotations statethat  'AglRhz'  is  the  cause for  the  trigger  word'leads',  while  the  Peaberry  system  prefers  thetrigger  word  'induced'  for  the  causative  agent.However, we have not done a detailed study toexamine  if  such  differences  account  for  morethan a small minority of the errors that contributeto low performance in the regulatory class.
Over-all, and surprisingly for a rule-based system, theprecision  was  quite  low  on  both  the  test  set(49%) and the development set (54%).
The lowoverall  precision was dominated by the corres-ponding number for regulatory events (37% and44% on test and development sets respectively),but  the  precision of  non-regulatory events  wasquite dismal as well (please see Discussion sec-tion below).The  low recall  for  regulatory  events  can  becaused by low recall for those primary (i.e.
non-regulatory) events that are regulated.
In the de-velopment set, the recall for these non-regulatoryclasses varied between 55% and 75%, but in thetest set the recall for some primary event classes(Pathology and General event classes) dropped to~30-40% (see Table 1 below).
Another reason forlow recall is the absence of themes for primaryevents  when these  themes  are  lifted/transferredfrom mentions of the same trigger word in previ-ous  sentences.
Our  lack  of  a  event  anaphoramodule would thus certainly have contributed tothe low recall  for such primary events.
We areanalyzing the gold annotations to determine othercauses for the low precision and recall in the de-velopment dataset.Event Class Recall Precision FscoreAnatomy 63.34 80.29 70.82Pathology 43.30 54.20 48.14Molecule 57.46 64.38 60.72General 34.67 49.82 40.89Regulation 34.22 37.05 35.58Modifier 26.24 37.50 30.88Total 41.73 49.58 45.32Table 1.
Summary of results for the Test set.
Re-call,  precision and F-score are shown for eventclasses  for anatomical  changes,  pathology,  mo-lecular processing events,  general events (bind-ing and movement), regulatory events, modifiers(negation and speculation) and the total score.4 DiscussionWe have developed a rule-based linguisticallymotivated system for tagging entities and extract-ing events from biomedical documents.
A major90problem with our linguistically-based system isthe large open-ended number of trigger wordsthat generate events.
This explosive event gener-ation occurs as the system generates predicate ar-gument structures for all verbs in a document aswell as for generically defined nominal processes(which are marked as event triggers by morpho-logical considerations, such as words  ending in"ation").
Moreover, the entity tagger also marks avariety of other words as event triggers whenthey are known to stand for biological or diseaseprocesses, in the Gene Ontology for example.Projecting the system output into a limited sets oftrigger words for a particular task was somewhatproblematic for us, although a good training ex-ercise on transferring arguments (e.g.
the theme)from 'other' trigger words into the subset of trig-ger words sufficient for the task.
It is possiblethat defects  in  this argument transfer processcould account for some of the low performancein the test set.Developing a rule-based system involves alarge amount of manual work in tuning the vari-ous aspects of the system to the task at hand.This is true even if the framework for the systemis already in place.
For example, with the CGtask, the predicate-argument structures  for eachindividual trigger have to be exhaustivelyworked out to handle all possible locations of ar-gument structures.
For certain triggers, the themein the CG task is somewhat indirect, as in thesentence: 'Almost all patients respond to G-CSFwith increased neutrophils, reduced infections,and improved survival.
', where the theme of 're-sponse' are not the patients but the 'increasedneutrophils'.
This is perhaps clearer in the para-phrase: "Organism responded to Drug withSymptoms", and cellular symptoms are the ap-propriate theme for the trigger 'responded' in theCG task.
Distinguishing such a sentence from asyntactically similar but semantically distinctsentence ' Organism responded well to Drug' is achallenging, and perhaps arduous, task for a rule-based linguistically motivated system.
We notethat the CG task annotations are quite consistentin this aspect, as the theme is again Symptoms inthe paraphrase 'Drug protects Organism fromSymptoms'.Further, in certain sentences, it is somewhathard to express the meaning in the A2 notation.This is particularly true for adjectives whichrefer to the state of an entity rather than an event.Consider (PMID 17367752): "These results sug-gest that SWAP-70 may be required for oncogen-ic transformation and contributes to cell growthin MEFs transformed by v-Src."
where one of thegold annotations transcribes functionally as'contributes ( Agent: SWAP-70, Theme: trans-formed ( Theme: MEFs ) )'which suggests that SWAP-70 contributes to thetransformation of MEF's, whereas 'transformed'is only an attribute of the MEF's for this annota-tion.
These aspects of the CG task annotationsare particularly hard to capture in a rule-basedsystem.
A similar problematic sentence is 'recom-binant  EBVs  that  lack  the  BHRF1  miRNAcluster display a reduced ability to transform Blymphocytes in vitro' where the gold annotationsread:reduced  (Agent:  recombinant_EBVs  Theme:transform (B_lymphocytes))The sentence however suggests that it is the 'lack'of a 'miRNA cluster'  in the EBV's that reducesthe transformation.
Again, this reading is some-what hard to express in A2 notation.As an additional example of the task com-plexity, we noted that distinguishing between therole of the trigger word 'transform' as 'Cell_trans-formation' and its role as a 'Planned_process'seems to require some level of discourse analysisat least in the CG training data.Some defects in the system output arise fromdifferences  in  interpretation.
In  the  sentence'Merlin protein might contribute to the initiationof metastasis of NSCLC.
', (PMID:2174350), thegold annotations read:'contribute(Agent:Merlin,  Theme:  initiation(Theme: NSCLC))''contribute  (Agent:  Merlin  Theme:  metastasis(Theme: NSCLC))where NSCLC is a cancer.
Peaberry gives instead'contribute  (Agent:  Merlin,  Theme:initiation(Theme: metastasis(Theme: NSCLC)))As  'initiation'  generally  requires  an  event/pro-cess/disease as a theme, its theme could be either'metastasis' or 'NSCLC', and the system makes agreedy choice in this case.
As changes in this lo-gic would have a system-wide impact,  this ex-ample perhaps shows the inflexibility of the sys-tem.A straightforward example shows the costs ofmissed  anaphora:  'Gene  silencing  and over-ex-91pression  techniques  were  used  to  modulateRASSF1C  expression  in  human  breast  cancercells.'
The system misses both events 'expression(Theme:RASSF1C)'  and  'over-expression(Theme:  RASSF1C)',  both  themes  resolving  tothe anaphoric entity 'Gene', which needs resolu-tion.
Similar  considerations  apply  for  the  sen-tence:  'knockdown  of  HDGF,  an  up-regulatedprotein and a target of NF-kappaB, induced cellapoptosis',  where  'protein'  and  not  'HDGF'  isseen as the theme of the trigger 'up-regulated'.Rule based systems have been used in previ-ous  BioNLP shared  tasks.
Such  a  system,  de-scribed  by  Kilicoglu  and  Bergler  (2012),  wasemployed for the BioNLP shared task 2011.
Thissystem used  output  from the  Stanford  depend-ency parser together with the notion of embed-ding to construct a semantic graph, from whichpropositions were extracted.
These propositionswere converted into events,  and semantic roleswere derived depending on the nature of the pre-dicate trigger word.
In comparing the perform-ance  of  this  system  on  the  2011  GENIA taskagainst our system on the CG task in commoncategories, the striking difference is that our pre-cision is far lower in most categories (see Table2), even while recall is comparable.
In particular,the difference in precision in non-regulation cat-egories is quite noticeable.
We are yet to under-stand the reasons for these low precision scoresin the Peaberry system.Event Class GENIA CGLocalization 90.36 59.43Binding 49.66 34.69Gene expression 86.84 71.46Transcription 58.95 100.00Phosphorylation 94.56 70.83Regulation 45.85 37.05Modifier 40.89 37.50Total 59.58 49.58Table 2.
Comparison of  precision  between tworule-based systems for similar event classes: (a)system of  Kilicoglu  and Bergler  (2012)  in  theGENIA task of BioNLP 11 (b) current system inthe CG task of BioNLP 13.We noted in the Results section that perform-ance of the system with and without gold-taggedentities (tagged in the latter case by the internalCocoa tagger) was similar, 0.7% better with thegold entities in the test run, and 2% better withinternal entities on the development set.
A pre-liminary  analysis  shows  that  the  reduction  insome cases with gold entities was due to peculi-arities in the way the system handles acronyms.The internal  tagger lumps together an acronymwith its  expansion as a  single token, while thegold annotations tokenizes the acronym and thedefinition  separately.
This  affects  downstreamprocessing,  especially  in  the  stitching  module.The gold annotations also do not markup sortalanaphors  ('gene'  in  'this  gene'),  and the systemdepends on entities being marked up in such ana-phors to find a referent.
Altogether, while the res-ults  may initially  seem surprising,  they  do  notsupport  any notion that  automatically predictedentities are somehow better than gold annotatedentities for event extraction systems.
At most, thesimilarities in results with and without gold an-notated  entities  are  indicative  of  a  comparableperformance, a very moderate f =~ 0.45, of thecomplete system on a new document collectionwithout gold annotations.We note that it seems possible that the rulesdeveloped for the CG task can be extendedwithout major modifications to the PC and theGE tasks, whose set of event triggers are a subsetof the CG task, without degrading the perform-ance of the CG task.
This may be one of the fewadvantages of a labor-intensive rule-based sys-tem; however, we are yet to validate such a sup-position.Cancer is founded at themolecular/genetic/cellular level and is localizedto an individual organ/tissue before metastasis.
Itwould thus seem that the text processing logicused for the CG task should be generalizable (atleast) to diseases of individual organs.
However,cancer is not a true multi-organ systemic prob-lem of the type that characterizes life-style dis-eases such as diabetes and cardiovascular dis-ease, which are both linked to multiple genomicloci as well as to multiple organs, and it would beinteresting to explore coverage of event extrac-tion schemes for these diseases with the text min-ing techniques developed in the CG task.
In thiscontext, we note that automatic annotation of allevents in a document needs to be followed byhighlighting of the novel events/properties in thedocument, which may require some discourseanalysis.ReferenceC.
Kennedy and B. Boguraev (1996) Anaphora forEveryone: Pronominal Anaphora Resolutionwithout a Parser.
COLING '96 Proceedings of the9216th conference on Computational linguistics.1:113-118H.
Kilicoglu and S. Bergler  2012.
Biological  EventComposition.
BMC Bioinformatics 13:Supplement11.
Edited by J-D. Kim, S. Pyysalo, C. Nedellec, S.Ananiadou and J. Tsujii.J.
D. Kim, T. Ohta, S. Pyysalo, Y. Kano, and J. Tsujii.2009.
Overview of BioNLP'09 shared task on eventextraction.
In Proceedings of the Workshop onBioNLP: Shared Task.
2009:1-9.J.
D. Kim , S. Pyysalo, T. Ohta, R. Bossy, and J.Tsujii.
2011.
Overview of BioNLP Shared Task2011.
In Proceedings of the BioNLP 2011 Work-shop Companion Volume for Shared Task.
2011:1-6.S.
Lappin and H. J. Leass.
1994.
An Algorithm forPronominal Anaphora  Resolution.
J. Comp.
Ling.20:(4):535-561S.
Pyysalo, T. Ohta, M. Miwa, H.C. Cho, J. Tsujii J,and S. Ananiadou.
2012.
Event extraction acrossmultiple levels of biological organization.
Bioin-formatics.
28(18):i575-i581S.
Pyysalo,  T. Ohta and S. Ananiadou.
Overview ofthe Cancer Genetics (CG) task of BioNLP SharedTask 2013.
In Proceedings of BioNLP Shared Task2013 Workshop.
To appear.S.
Pyysalo, T. Ohta and S. Ananiadou.
2013.
CancerGenetics task.
Final evaluation results - RelAgent.http://weaver.nlplab.org/~bionlp-st/BioNLP-ST-2013/CG/final-results/RelAgent.htmlRelAgent.
2012.
Evaluation of Cocoa against somecorpora.
http://npjoint.com/CocoaEval.htmlD.
Swanson.
1988.
Migraine and Magnesium: ElevenNeglected Connections.
Persp.
Bio.
Med.31(4):526?557.93
