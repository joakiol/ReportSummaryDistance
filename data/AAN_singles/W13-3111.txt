Proceedings of the MultiLing 2013 Workshop on Multilingual Multi-document Summarization, pages 77?81,Sofia, Bulgaria, August 9 2013. c?2013 Association for Computational LinguisticsMultilingual Single-Document Summarization with MUSEMarina LitvakDepartment of Software EngineeringShamoon College of EngineeringBeer Sheva, Israelmarinal@sce.ac.ilMark LastDepartment of Information SystemsEngineering, Ben Gurion UniversityBeer Sheva, Israelmlast@bgu.ac.ilAbstractMUltilingual Sentence Extractor (MUSE)is aimed at multilingual single-documentsummarization.
MUSE implements asupervised language-independent summa-rization approach based on optimization ofmultiple sentence ranking methods using aGenetic Algorithm.
The main advantageof MUSE is its language-independency?
it is using statistical sentence features,which can be calculated for sentences inany language.In our previous work, the performance ofMUSE was found to be significantly bet-ter than the best known state-of-the-artextractive summarization approaches andtools in three different languages: English,Hebrew, and Arabic.
Moreover, our ex-perimental results in the cross-lingual do-main suggest that MUSE does not need tobe retrained on a summarization corpus ineach new language, and the same weight-ing model can be used across several lan-guages (Last and Litvak, 2012).MUSE participated in the MultiLing 2013single document summarization task onthree languages: English, Hebrew andArabic.
Due to a very limited time thatwas given to the participants to run theirsystems on the MultiLing 2013 data, theresults submitted to evaluation were ob-tained by summarizing the documents us-ing models pre-trained on different cor-pora.
As such, no training has been per-formed on the MultiLing 2013 corpus.1 MUltilingual Sentence Extractor(MUSE): Overview1.1 MethodologyMUSE implements a supervised learning ap-proach to language-independent extractive sum-marization where the best set of weights for a lin-ear combination of sentence scoring methods isfound by a genetic algorithm trained on a col-lection of documents and their summaries.
Theweighting vector thus obtained is used for sen-tence scoring in future summarizations.
Sincemost sentence scoring methods have a linear com-putational complexity, only the training phase ofour approach is time-consuming.Using MUSE, the user can choose the subset oftotally 31 sentence metrics that will be includedin the linear combination.
The available metricsare based on various text representation modelsand are language-independent since they do notrely on any language-specific knowledge.
Fig-ure 1 demonstrates the taxonomy of all 31 met-rics.
We divided them into three main categories?structure-, vector-, and graph-based?accordingto their text representation model, where each sub-category contains group of metrics using the samescoring method.A detailed description of sentence metrics usedby MUSE can be found in (Last and Litvak, 2012).The best linear combination of the metrics de-picted in Figure 1 can be found using a GeneticAlgorithm (GA).
GAs are categorized as globalsearch heuristics.
Figure 2 shows a simplified GAflowchart.A typical genetic algorithm requires (1) a ge-netic representation of the solution domain, (2) afitness function to evaluate the solution domain,and (3) some basic parameter settings like selec-tion and reproduction rules.We represent each solution as a vector ofweights for a linear combination of sentence scor-77Multilingual sentencescoringmetricsStructure-basedVector-basedGraph-basedPosition Length Frequency Similarity Degree SimilarityPagerankTitle DocumentPOS_FPOS_LPOS_BLEN_WLEN_CHLUHN?KEY ?COV ?TFTFIISFSVDTITLE_OTITLE_JTITLE_CD_COV_OD_COV_JD_COV_CLUHN_DEG ?KEY_DEG ?COV_DEG ?DEGGRASELUHN_PR ?KEY_PR ?COV_PR ?PRML_TRTitle DocumentTITLE_E_OTITLE_E_JD_COV_E_OD_COV_E_JFigure 1: Taxonomy of language-independent sentence scoring metrics (Litvak et al 2010b)SelectionMatingCrossoverMutationTerminate?BestgeneyesnoInitializationReproductionFigure 2: Simplified flowchart of GAing metrics?real-valued numbers in the unlimitedrange normalized in such a way that they sum upto 1.
The vector size is fixed and it equals to thenumber of metrics used in the combination.Defined over the genetic representation, the fit-ness function measures the quality of the rep-resented solution.
We can use ROUGE-1 andROUGE-2, Recall (Lin and Hovy, 2003) as afitness functions for measuring summarizationquality?similarity with gold standard summaries,which should be maximized during the train-ing (optimization procedure).
We use an anno-tated corpus of summarized documents, whereeach document is accompanied by several human-generated summaries?abstracts or extracts, as atraining set.The reader is referred to (Litvak et al 2010b)for a detailed description of the optimization pro-Algorithm 1 Step 1: TrainingRequire: Gold Standard - a corpus of summarized docu-ments D, N chosen metricsEnsure: A weighted model W - vector of weights for eachof N metricsStep 1.1: Compute M - sentence-score matrixfor all d ?
D doLet R1, R2, and R3 are d representationsfor all sentences s ?
d doCalculate N metrics using R1, R2, and R3Add metrics row for s into Mend forend forStep 1.2: Compute a vector W of metrics weightsRun a Genetic Algorithm on M , given D:Initialize a population Prepeatfor all solution g ?
P doGenerate a summary aEvaluate a by ROUGE on summaries of Dend forSelect the best solutions GP - a new population generated by Guntil convergence - no better solutions are foundreturn a vector W of weights - output of a GAcedure implemented by MUSE.Algorithms 1 and 2 contain the pseudo-code fortwo independent phases of MUSE: training andsummarization, respectively.
Assuming efficientimplementation, all metrics have a linear compu-tational complexity relative to the total number ofwords in a document - O(n).
As a result, thesummary extraction time, given a trained model,is also linear (in the number of metrics in a com-bination).
The training time is proportional to thenumber of GA iterations multiplied by the num-ber of individuals in a population times the fitnessevaluation (ROUGE) time.
On average, in our ex-periments the GA performed 5 ?
6 iterations?78Algorithm 2 Step 2: Summarizing a new docu-mentRequire: A document d, maximal summary length L, atrained weighted model WEnsure: A set of n sentences, which were top-ranked by thealgorithm as the most important.Step 2.1: Compute a score of each sentenceLet R1, R2, and R3 are d representationsfor all sentense s ?
d doCalculate N metrics using R1, R2, and R3Calculate a score as a linear combination according toWend forStep 2.2: Compile the document summaryLet S = ?
be a summary of drepeatget the top ranked sentence siS = S?siuntil S exceeds max length Lreturn Sselection and reproduction?before reaching con-vergence.1.2 ArchitectureThe current version of MUSE tool can be ap-plied only to text documents or textual content ofHTML pages.
It consists of two main modules:the training module activated in offline, and thereal-time summarization module.
Both modulesutilize two different representations of documentsdescribed in (Litvak et al 2010b): vector- andgraph-based.
The preprocessing module is respon-sible for constructing each representation, and it isembedded in both modules.The training module receives as input a corpusof documents, each accompanied by one or severalgold-standard summaries?abstracts or extracts?compiled by human assessors.
The set of docu-ments may be either monolingual or multilingualand their summaries have to be in the same lan-guage as the original text.
The training moduleapplies a genetic algorithm to a document-featurematrix of precomputed sentence scores with thepurpose of finding the best linear combination offeatures using any ROUGE metric as a fitnessfunction.
ROUGE-1 Recall is used as a defaultunless specified otherwise by the end-user.
Theoutput/model of the training module is a vectorof weights for user-specified sentence ranking fea-tures.
In the current version of the tool, the usercan choose from 31 vector-based and graph-basedfeatures.
The recommendation for the best 10 fea-tures can be found in (Litvak et al 2010a).The summarization module performs summa-rization of input text/texts in real time.
Each sen-tence of an input text obtains a relevance score ac-cording to the trained model, and the top rankedsentences are extracted to the summary in theiroriginal order.
The length of resulting summariesis limited by a user-specified value (maximumnumber of words, maximum number of sentencesor a compression ratio).
Being activated in real-time, the summarization module is expected to usethe model trained on the same language as in-put texts.
However, if such model is not avail-able (no annotated corpus in the text language),the user can choose one of the following options:(1) a model trained on some other language/corpus(in (Litvak et al 2010b) we show that the samemodel can be efficiently used across different lan-guages), or (2) user-specified weights for eachsentence feature (from 31 provided in the system)in the linear combination.The preprocessing module performs the follow-ing tasks: (1) sentence segmentation, (2) wordsegmentation, (3) vector space model constructionusing tf and/or tf-idf weights, (4) a word-basedgraph representation construction, (5) a sentence-based graph representation construction, and (6)document metadata construction, including suchinformation like frequency (tf and tf-idf) for eachunique term, its location inside the document, etc.The outputs of this submodule are: sentence seg-mented text (SST), vector space model (VSM), thedocument graphs, and the metadata stored in thexml files.
Steps (1) and (2) are performed by thetext processor submodule, which consists of threeelements: filter, reader and sentence segmenter.The filter works on the Unicode character leveland performs such operations like identification ofcharacters, digits, punctuations and normalization(optional for some languages).
The reader invokesthe filter, constructs word chunks from the inputstream and identifies the following states: words,special characters, white spaces, numbers, URLlinks and punctuation marks.
The sentence seg-menter invokes reader and divides the input spaceinto sentences.
By implementing different filters,the reader can work either with a specific language(taking into account its intricacies) or with docu-ments written in arbitrary language (in this case,a general filtering according to UTF-8 encoding isperformed).Figure 3 shows the general architecture of theMUSE system.79ScoringandRankingScoringGAUser-specifiedparametersand settingsSummariesTextdocumentsPreprocessingSummarizeddocumentsTRAININGSUMMARIZATIONROUGEPreprocessingDocumentRepresentationModelsDocument-FeatureScores MatrixDocumentRepresentationModelsWeightingModelFigure 3: MUSE architecture2 Training of MUSESince a very limited time was given to partici-pants to run their summarizers on the MultiLing2013 dataset, we did not perform training on a newdata.
The models obtained from training MUSEon monolingual corpora of English, Hebrew, andArabic texts in 2011 (Last and Litvak, 2012), havebeen used for summarization in three languages.Both ROUGE-1 and ROUGE-2 have beed usedfor building the models.
In the current settings,ROUGE-1-based models were utilized.The English text material used in the ex-periments comprised the corpus of summa-rized documents available for the summarizationtask at the Document Understanding Conference2002 (DUC, 2002).
This benchmark dataset con-tains 533 news articles, each accompanied by twoto three human-generated abstracts of approxi-mately 100 words each.For the Arabic language, we used a corpus com-piled from 90 news articles.
Each article was sum-marized by three native Arabic speakers select-ing the most important sentences into an extractivesummary of approximately 100 words each.For the Hebrew language, we used a corpuswhere 120 news articles of 250 to 830 words aresummarized by five human assessors each.The documents from all corpora have a title asthe first sentence.ROUGE-1 and ROUGE-2 metrics (Lin, 2004)have been used as a fitness function during thetraining of MUSE.
The same metrics have beenused for evaluation of generated summaries inthree languages.
In order to use the ROUGEtoolkit on Hebrew and Arabic, it was adapted tothese languages by specifying the regular expres-sions for a single ?word?
using Hebrew and Arabic-1.000 -0.500 0.000 0.500 1.000COVCOV_DEGCOV_PRDEGD_COV_CD_COV_E_JD_COV_E_OD_COV_JD_COV_OGRASEKEYKEY_DEGKEY_PRLEN_CHLEN_WLUHNLUHN_DEGLUHN_PRPOS_BPOS_FPOS_LPRSVDTFTFISFTITLE_CTITLE_E_JTITLE_E_OTITLE_JTITLE_OML_TRENG HEB ARAB-1.000 -0.500 0.000 0.500 1.000COVCOV_DEGCOV_PRDEGD_COV_CD_COV_E_JD_COV_E_OD_COV_JD_COV_OGRASEKEYKEY_DEGKEY_PRLEN_CHLEN_WLUHNLUHN_DEGLUHN_PRPOS_BPOS_FPOS_LPRSVDTFTFISFTITLE_CTITLE_E_JTITLE_E_OTITLE_JTITLE_OML_TRENG HEB ARABFigure 4: Models trained on monolingual corpora:ROUGE-1 (left) and ROUGE-2 (right)characters.Figure 4 present models learned by MUSE ondifferent monolingual corpora using ROUGE-1and ROUGE-2, respectively.
The actual results inthe trained models include some negative values.The evaluation results of MUSE on threemonolingual corpora using 10-fold cross valida-tion showed its significant superiority over Tex-tRank (Mihalcea, 2005), the best known language-independent unsupervised approach.3 Experimental ResultsAccording to the results of automated evaluationin MultiLing 2013 (N-gram graph methods: Au-toSummENG, MeMoG, NPowER), MUSE tookfourth place in English corpus (out of 7 systems),third place in Hebrew (out of 5 summarizers), andthe first place in Arabic (out of 6 participants).We believe, that training MUSE on the originaldata and using correct titles1 (by parsing xml doc-uments) may significantly improve its results.1Due to the time constraints of the single-document sum-marization task, we used a simple txt format of summarizeddocuments in the published dataset, where the title is not sep-arated from the first sentence by punctuation marks.80ReferencesDUC.
2002.
Document Understanding Conference.http://duc.nist.gov.M.
Last and M. Litvak.
2012.
Cross-lingual trainingof summarization systems using annotated corporain a foreign language.
Information Retrieval, pages1?28, September.Chin-Yew Lin and Eduard Hovy.
2003.
Auto-matic evaluation of summaries using N-gram co-occurrence statistics.
In NAACL ?03: Proceedings ofthe 2003 Conference of the North American Chapterof the Association for Computational Linguistics onHuman Language Technology, pages 71?78.Chin-Yew Lin.
2004.
ROUGE: A Package for Auto-matic Evaluation of summaries.
In Proceedings ofthe Workshop on Text Summarization Branches Out(WAS 2004), pages 25?26.M.
Litvak, S. Kisilevich, D. Keim, H. Lipman, A. Ben-Gur, and M. Last.
2010a.
Towards language-independent summarization: A comparative analysisof sentence extraction methods on english and he-brew corpora.
In Proceedings of the CLIA/COLING2010.Marina Litvak, Mark Last, and Menahem Friedman.2010b.
A new approach to improving multilingualsummarization using a Genetic Algorithm.
In ACL?10: Proceedings of the 48th Annual Meeting of theAssociation for Computational Linguistics, pages927?936.Rada Mihalcea.
2005.
Language independent extrac-tive summarization.
In AAAI?05: Proceedings of the20th National Conference on Artificial Intelligence,pages 1688?1689.81
