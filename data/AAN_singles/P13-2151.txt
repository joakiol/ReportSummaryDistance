Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 873?877,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsDoes Korean defeat phonotactic word segmentation?Robert DalandDepartment of LinguisticsUniversity of California, Los Angeles3125 Campbell Hall, Box 951543Los Angeles, CA 90095-1543, USAr.daland@gmail.comKie ZurawDepartment of LinguisticsUniversity of California, Los Angeles3125 Campbell Hall, Box 951543Los Angeles, CA 90095-1543, USAkie@ucla.eduAbstractComputational models of infant wordsegmentation have not been tested on awide range of languages.
This paper ap-plies a phonotactic segmentation modelto Korean.
In contrast to the underseg-mentation pattern previously found inEnglish and Russian, the model exhibitedmore oversegmentation errors and moreerrors overall.
Despite the high error rate,analysis suggested that lexical acquisitionmight not be problematic, provided thatinfants attend only to frequently seg-mented items.1 IntroductionThe process by which infants learn to parse theacoustic signal into word-sized units?wordsegmentation?is an active area of research indevelopmental psychology (Polka and Sundara2012; Saffran et al1996) and cognitive model-ing (Daland and Pierrehumbert 2011 [DP11],Goldwater et al2009 [GGJ09]).
Word segmen-tation is a classic bootstrapping problem: to learnwords, infants must segment the input, becausearound 90% of the novel word types they hearare never uttered in isolation (Aslin et al1996;van de Weijer 1998).
However, in order to seg-ment infants must know some words, or gener-alizations about the properties of words.
Howcan infants form generalizations about wordsbefore learning words themselves?1.1 DiBSTwo approaches in the literature might be termedlexical and phonotactic.
Under the lexical ap-proach, exemplified by GGJ09, infants are as-sumed to exploit the Zipfian distribution of lan-guage, identifying frequently recurring and mu-tually predictive sequences as words.
In the pho-notactic approach, infants are assumed to lever-age universal and/or language-specific knowl-edge about the phonological content of se-quences to infer the optimal segmentation.
Thepresent study focuses on the phonotactic ap-proach outlined in DP11, termed DiBS.
For otherexamples of approaches that use phonotactics,see Fleck 2008, Blanchard et al2010.A (Di)phone-(B)ased (S)egmentation modelconsists of an inventory of segment-segment se-quences, with an estimated probability that aword boundary falls between the two segments.For example, when [pd] occurs in English, theprobability of an intervening word boundary isvery high: Pr(# | [pd]) ?
1.
These probabilitiesare the parameters of the model to be learned.
Inthe supervised setting (baseline model), theseparameters may be estimated directly from datain which the word boundaries are labeled: Pr(# |pd) = Fr(# ^ pd) / (Fr(# ^ pd) + Fr(?# ^ pd))where Fr(# ^ pd) is the number of [pd] sequencesseparated by a word boundary, and Fr(?# ^ pd)the number of [pd]?s not separated by a wordboundary.
For assessment purposes, these prob-abilities are converted to hard decisions.DP11 describe an unsupervised learning algo-rithm for DiBS that exploits a positional inde-pendence assumption, treating phrase edges as aproxy for word edges (phrasal model).
Thislearning model?s performance on English is onpar with state-of-the-art lexical models (GGJ09),reflecting the high positional informativeness ofdiphones in English.
We apply the baseline andphrasal models to Korean.1.2 Linguistic properties of KoreanKorean is unrelated to languages previouslymodeled (English, Dutch, French, Spanish, Ara-873bic, Greek, Russian), and it is an interesting testcase for both phonotactic and lexical approaches.Korean syntax and morphology (Sohn 1999)present a particular challenge for unsupervisedlearning.
Most noun phrases are marked with alimited set of case suffixes, and clauses generallyend in a verb, inflected with suffixes ending in alimited set of sounds ([a,?,i,jo]).
Thus, thephrase-final distribution may not reflect theoverall word-final distribution?problematic forsome phonotactic approaches.
Similarly, the highfrequency and positional predictability of affixescould lead a lexical model to treat them as words.A range of phonological processes apply in Ko-rean, even across word boundaries (Sohn 1999),yielding extensive allomorphy.
Phonotacticmodels may be robust to this kind of variation,but it is challenging for current lexical models(see DP11).Korean consonantal phonology gives diphonesseveral informative properties, including:?
Various consonant clusters (obstruent-lenis, lenis-nasal, et al are possible onlyif they span a word boundary?
Various consonants cannot precede aword boundary?
[?]
cannot follow a word boundaryConversely, unlike in previously studied lan-guages, vowel-vowel sequences are commonword-internally.
This is likely to be problematicfor phonotactic models, but not for lexical ones.2 MethodsWe obtained a phonetic corpus representing Ko-rean speech by applying a grapheme-to-phoneticconverter to a text corpus.
First, we conducted ananalysis of this phonetic corpus, with results inTable 1.
Next, for comparability with previousstudies, two 750,000-word samples (representingapproximately one month of child input each)were randomly drawn from the phonetic cor-pus?the training and test corpora.
The phrasaland baseline DiBS models described above weretrained and tested on these corpora; results arereported in Table 2.
Finally, we inspected one?day?
worth of segmentations, and offer a quali-tative assessment of errors.2.1 Corpus and phonetic conversionThe Korean Advanced Institute of Science andTechnology Raw Corpus, available from the Se-mantic Web Research Center, semantic-web.kaist.ac.kr/home/index.php/KAIST_Corpuscontains approximately 70,000,000 words fromspeeches, novels, newspapers, and more.
Thecorpus was preprocessed to supply phrase breaksat punctuation marks and strip XML.The grapheme-to-phonetic conversion systemof Kim et al(2002) was generously shared by itscreators.
It includes morphosyntactic processing,phrase-break detection, and a dictionary of pho-netic exceptions.
It applies regular and lexically-conditioned phonological rules, but not optionalrules.
Kim et alreported per-grapheme accuracyof 99.7% in one corpus and 99.98% in another.An example of original text and the phoneticconversion is given below, with phonologicalchanges in bold:orthographic: ???
1 ????
2 ??
3.???
4 ???????
5 ????
6.phonetic: ??????
?1 ??????
2??????
3 # ???????
4?????????????????
5?????????
6IPA: k j?
?
k i t o1  j?
t?
u e s ?2   t??
u l s* ?
?3   #   t?
u ?
a ?
t ?4   m u n e t??
a ?
t?
a k?
a kk* wa l ?
l5   t?
o l ?
p?
?
t t* a6(the * diacritic indicates tense consonants)gloss: Born3 in Yeoju2, Gyeonggi-do1.Graduated6 from Jungang University4Department of Creative Writing5.We relied on spaces in the corpus to indicateword boundaries, although, as in all languages,there can be inconsistencies in written Korean.2.2 Error analysisAn under-researched issue is the nature of theerrors that segmentation algorithms make.
For agiven input word in the test corpus, we definedthe output projection as the minimal sequence ofsegmented words containing the entire inputword.
For example, if the#kitty were segmentedas thekitty, then thekitty would be the output pro-jection for both the and kitty.
Similarly, for aposited word in the segmentation/output of thetest corpus, we defined the input projection.
Forexample, if the#kitty were segmented astheki#tty, then the the#kitty would be the inputprojection of both theki and tty.
For each word,we examined the input-output relationship.
Sev-eral questions were of interest.
Are highly fre-quent items segmented frequently enough thatthe child is likely to be able to learn them?
Is it874the case that all or most items which are seg-mented frequently are themselves words?
Arethere predicted errors which seem especially se-rious or difficult to overcome?3 Results and discussionThe 1350 distinct diphones found in the phoneticcorpus were grouped into phonological classes.Table 1 indicates the probabilities (percentage)that a word boundary falls inside the diphone;when the class contains 3 or more diphones, themedian and range are shown.
Because of variousphonological processes, some sequences cannotexist (blank cells), some can occur only word-internally (marked int), and some can occur onlyacross word boundaries (marked span).
For ex-ample, the velar nasal [?]
cannot begin a word,so diphones of the form X?
must be word-internal.
Conversely, a lenis-/h/ sequence indi-cates a word boundary, because within a word alenis stop merges with following /h/ to becomean aspirated stop.
If all diphones in a cell have aspanning rate above 90%, the cell says span*,and if below 10%, int*.
This means that all thediphones in that class are highly informative;other classes contain a mix of more and less in-formative diphones.The performance of the DiBS models isshown in Table 2.
An undersegmentation error isa true word boundary which the segmentationalgorithm fails to find (miss), while an overseg-mentation error is a falsely posited boundary(false alarm).
The under- and over-segmentationerror rates are defined as the number of such er-rors per word (percent).
We also report the preci-sion, recall, and F scores for boundary detection,word token segmentation, and type segmentation(for details see DP11, GGJ09).model baseline phrasalunder (errs per wd) 43.4 72.5over (errs per wd) 17.7 22.0prec (bdry/tok/type) 68/36/34 28/11/12recall (bdry/tok/type) 46/27/29 11/6/8F (bdry/tok/type) 55/31/31 15/8/9Table 2: Results of DiBS modelsOn the basis of the fact that the oversegmenta-tion error rate in English and Russian was con-sistently below 10% (<1 error/10 wds), DP11conjectured that phonotactic segmenters will,cross-linguistically, avoid significant overseg-mentation.
The results in Table 2 provide a coun-terexample: oversegmentation is distinctly higherthan in English and Russian.
Indeed, Korean is amore challenging language for purely phonotac-tic segmentation.3.1 Phonotactic cues to word segmentationBecause phonological processes are more likelyto apply word-internally, word-internal se-quences are more predictable (Aslin et al1996;DP11; GGJ09; Saffran et al1996; van de Weijer1998).
The phonology of Korean is a potentiallyseg.
2seg.
1lenisstoplenisnon-stoptense asp.
h n m ?
liquid vowel diphth.lenis stop span 1004-100int* 275-53span 10098-100span  10010-100int* 70-100lenisnon-stopint inttense          int intaspirated          int inth          int intn 6529-6646, 57 3818-824532-6735 32 61  span* 121-375320-99m 1914-2118, 18 144-571412-2614 int* 21  span int* 121-92?
1211-1310, 12 96-551110-15int* int* 10  span 60-64184-86liquid 5543-6384, 88 716-905317-6842 90 53  int* 30-14397-95vowel 166-873212-82364-97183-88389-8451-31132-70int int* 441-90513-100diphthong 100-79120-55210-100110-87160-8830-15190-74int int* 260-100310-100Table 1: Diphone behavior875rich source of information for word segmenta-tion: obstruent-initial diphones are generally in-formative as to the presence/absence of wordboundaries.
However, as we suspected, vowel-vowel sequences are problematic, since they oc-cur freely both within words and across wordboundaries.
Korean differs from English in thatmost English diphones occur nearly exclusivelywithin words, or nearly exclusively across wordboundaries (DP11), while in Korean most sono-rant-obstruent sequences occur both within andacross words.3.2 Errors and word-learningIt seems reasonable to assume that word-learningis best facilitated by seeing multiple occurrencesof a word.
A segmentation that is produced onlyonce might be ignored; thus we defined an inputor output projection as frequent if it occurredmore than once in the test sample.A word learner relying on a phonotactic modelcould expect to successfully identify many fre-quent words.
For 73 of the 100 most frequentinput words, the only frequent output projectionin the baseline model was the input word itself,meaning that the word was segmented correctlyin most contexts.
For 20 there was no frequentoutput projection, meaning that the word was notsegmented consistently across contexts, whichwe assume is noise to the learner.
In the phrasalmodel, for 16 items the most frequent output pro-jection was the input word itself and for 64 therewas no frequent output projection.Conversely, of the 100 most frequent potentialwords identified by the baseline model, in 26cases the most frequent input projection was theoutput word itself: a real word was correctlyidentified.
In 26 cases there was no frequent in-put projection, and in 48 another input projectionwas at least as frequent as the output word.
Onesuch example is [mj?n] ?cotton?, frequently seg-mented out when it was a bound morpheme (?if?or ?how many?).
The most frequently segmenteditem was [ke], which can be a freestanding word(?there/thing?
), but was often segmented out fromwords suffixed with [-ke] ?-ly/to?
and [-eke] ?to?.What do these results mean for a child using aphonotactic strategy?
First, many of the typessegmented in a day would be experienced onlyonce (and presumably ignored).
Second, infantswould not go far astray if they learned fre-quently-segmented items as words.3.3 Phrase edges and independenceWe suspected the reason that the phrasal DiBSmodel performed so much worse than baselinewas its assumption that phrase-edge distributionsapproximate word-edge distributions.
Phrase be-ginnings were a good proxy for word beginnings,but there were mismatches phrase-finally.
Forexample, [a] is much more frequent phrase-finally than word-finally (because of commonverb suffixes ending in [a]), while [n] is muchmore frequent word-finally (because of non-sentence-final suffixes ending in [n]).
The posi-tional independence assumption is too strong.4 ConclusionThis paper extends previous studies by applyinga computational learning model of phonotacticword segmentation to Korean.
Various propertiesof Korean led us to believe it would challengeboth unsupervised phonotactic and lexical ap-proaches.Phonological and morphological analysis oferrors yielded novel insights.
For example, thegenerally greater error rate in Korean is partlycaused by a high tolerance for vowel-vowel se-quences within words.
Interactions betweenmorphology and word order result in violationsof a key positional independence assumption.Phonotactic segmentation was distinctly worsethan in previous languages (English, Russian),particularly for oversegmentation errors.
Thisimplies the segmentation of simplistic diphonemodels is not cross-linguistically stable, a find-ing that aligns with other cross-linguistic com-parisons of segmentation algorithms.
In general,distinctly worse performance is found for lan-guages other than English (Sesotho: Blanchard etal.
2010; Arabic and Spanish: Fleck 2008).
Thesefacts suggest that the successful segmentationmodel must incorporate richer phonotactics, orintegrate some lexical processing.
On the brightside, we found that frequently segmented itemswere mostly words, so a high segmentation errorrate does not necessarily translate to a high errorrate for word-learning.ReferencesAslin, R. N., Woodward, J.
Z., LaMendola, N. P., &Bever, T. G. (1996).
Models of word segmentationin fluent maternal speech to infants.
In J. L. Mor-gan & K. Demuth (Eds.).
Signal to syntax.
Mah-wah, NJ: LEA, pp.
117?134.Blanchard, D., Heinz, J., & Golinkoff, R. (2010).Modeling the contribution of phonotactic cues to876the problem of word segmentation.
Journal ofChild Language 37(3), 487-511.Daland, R. & Pierrehumbert, J.B. (2011).
Learnabilityof diphone-based segmentation.
Cognitive Science35(1), 119-155.Fleck, M. (2008).
Lexicalized phonotactic word seg-mentation.
Proceedings of ACL-08: HLT, 130-138.Goldwater, S., Griffiths, T. L., & Johnson, M. (2009).A Bayesian framework for word segmentation:Exploring the effects of context.
Cognition 112(1),21-54.Kim, B., Lee, G., & Lee, J.-H. (2002).
Morpheme-based grapheme to phoneme conversion usingphonetic patterns and morphophonemic connec-tivity information.
ACM Trans.
Asian Lang.
Inf.Process.
1(1), 65-82.Polka, L. & Sundara, M. (2012).
Word segmentationin monolingual infants acquiring Canadian-Englishand Canadian-French: Native language, cross-language and cross-dialect comparisons.
Infancy17(2), 198-232.Saffran, J. R., Aslin, R. N., & Newport, E. L. (1996).Statistical learning by 8-month-old infants.
Science275(5294), 1926-1928.Sohn, H.-M. (1999).
The Korean Language.
Cam-bridge: Cambridge University Press.van de Weijer, J.
(1998).
Language input for worddiscovery.
MPI series in psycholinguistics (No.
9).877
