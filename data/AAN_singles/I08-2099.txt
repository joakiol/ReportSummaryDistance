Dependency Annotation Scheme for Indian LanguagesRafiya Begum, Samar Husain, Arun Dhwaj, Dipti MisraSharma, Lakshmi Bai and Rajeev SangalLanguage Technologies Research Center,IIIT, Hyderabad, India.
{rafiya,samar}@research.iiit.ac.in,{dipti,lakshmi,sangal}@iiit.ac.inAbstractThe paper introduces a dependency annota-tion effort which aims to fully annotate amillion word Hindi corpus.
It is the first at-tempt of its kind to develop a large scaletree-bank for an Indian language.
In thispaper we provide the motivation for fol-lowing the Paninian framework as the an-notation scheme and argue that the Pan-inian framework is better suited to modelthe various linguistic phenomena manifestin Indian languages.
We present the basicannotation scheme.
We also show how thescheme handles some phenomenon such ascomplex verbs, ellipses, etc.
Empirical re-sults of some experiments done on the cur-rently annotated sentences are also re-ported.1 IntroductionA major effort is currently underway to develop alarge scale tree bank for Indian Languages (IL).The lack of such a resource has been a major limit-ing factor in the development of good natural lan-guage tools and applications for ILs.
Apart fromthat, a rich and large-scale tree bank can be an in-dispensable resource for linguistic investigations.Some notable efforts in this direction for other lan-guages have been the Penn Tree Bank (Marcus etal., 1993) for English and the Prague DependencyBank (Hajicova, 1998) for Czech.It is well known that context free grammar(CFG) is not well-suited for free-word orderlanguages (Shieber, 1985); instead dependencyframework appears to be better suited (Hudson,1984; Mel'Cuk, 1988, Bharati et al, 1995).
Also,the dependency framework is arguably closer tosemantics than the phrase structure grammar (PSG)if the dependency relations are judiciously chosen.In recent times many research groups have beenshifting to the dependency paradigm due to thisreason.
Modern dependency grammar is attributedto Tesni?re (1959).
In a dependency analysis, thereis no hierarchical arrangement of phrases (orsubstrings) like in phrase structure grammar.Rather, we just have words connected viadependency relations between them.Prague Dependency Bank (PDT) for Czech(which has relatively free word order) is one suchlarge-scale effort which implements a three-tierannotation scheme and annotates morphologicalinformation, analytical and tectogrammatical levelannotations at these three levels.
Out of the threelevels, the analytical and tectogrammatical levelare dependency based.
The tectogrammatical leveltries to capture the deep-semantics of the sentence;the annotation at this level is very rich and islinked to the other two lower levels.
Other majorefforts in the dependency framework are Alpino(van der Beek et.
al, 2002) for Dutch, (Rambow et.al, 2002) for English, TUT (Bosco and Lombardo,2004) for Italian, TIGER (Brants et.
al, 2002)(combines dependency with PSG) for German.
Inthis paper we describe an approach to annotate ILsusing the Paninian1 model.
The paper is arrangedas follows, Section 2 gives a brief overview of the1Paninian theory was formulated by Panini abouttwo thousand five hundred years ago for Sanskrit.
Itevolved with the contributions of grammarians that fol-lowed.721grammatical model and the motivation forfollowing the framework.
Section 3 talks about thechosen corpus and the annotation procedure.
InSection 4 we discuss some dependency relations.Section 5 describes the evaluation procedure.
Wereport the empirical results of experiments done onthe annotated data in Section 6.
Section 7,concludes the paper.2 Grammatical ModelILs are morphologically rich and have a relativelyflexible word order.
For such languages syntacticsubject-object positions are not always able to ele-gantly explain the varied linguistic phenomena.
Infact, there is a debate in the literature whether thenotions ?subject?
and ?object?
can at all be definedfor ILs (Mohanan, 1982).
Behavioral properties arethe only criteria based on which one can confi-dently identify grammatical functions in Hindi(Mohanan, 1994); it can be difficult to exploit suchproperties computationally.
Marking semanticproperties such as thematic role as dependencyrelation is also problematic.
Thematic roles areabstract notions and will require higher semanticfeatures which are difficult to formulate and to ex-tract as well.
So, thematic roles are not marked atthis juncture.
On the other hand, the notion of ka-raka relations (explained shortly) provides us alevel which while being syntactically groundedalso helps in capturing some semantics.
What isimportant to note here is that such a level can beexploited computationally with ease.
This providesus with just the right level of syntactico-semanticinterface.
The experiments conducted on the pre-sent annotated text provide empirical evidence forthis claim (section 6).
Paninian grammar is basi-cally a dependency grammar (Kiparsky and Staal,1969; Shastri, 1973).
In this section we briefly dis-cuss the Paninian model for ILs and lay downsome basic concepts inherent to this framework.The main problem that the Paninian approachaddresses is to identify syntactico-semantic rela-tions in a sentence.
The Paninian approach treats asentence as a series of modifier-modified relations.A sentence is supposed to have a primary modified(the root of the dependency tree) which is gener-ally the main verb of the sentence.
The elementsmodifying the verb participate in the action speci-fied by the verb.
The participant relations with theverb are called karaka.
The appropriate mapping ofthe syntactic cues helps in identifying the appro-priate karakas (?participants in an action?).
Theframework is inspired by an inflectionally rich lan-guage like Sanskrit; it emphasizes the role of caseendings or markers such as post-positions and ver-bal inflections.There are six basic karakas, namely; adhikarana?location?,  apaadaan ?source?, sampradaan?recipient?,  karana ?instrument?, karma ?theme?,karta ?agent?.
We must note here that although onecan roughly map the first four karaka to their the-matic role counterpart, karma and karta are verydifferent from ?theme?
and ?agent?
respectively(see section 4.1.1).In our annotation scheme, we use chunks as adevice for modularity.
A chunk represents a set ofadjacent words which are in dependency relationswith each other, and are connected to the rest ofthe words by a single incoming dependency arc.The relations among the words in a chunk are notmarked for now and hence allow us to ignore localdetails while building the sentence level depend-ency tree.
Thus, in our dependency tree each nodeis a chunk and the edge represents the relationsbetween the connected nodes labeled with the ka-raka or other relations.
All the modifier-modifiedrelations between the heads of the chunks (inter-chunk relations) are marked in this manner.
Intra-chunk relations can be marked by a set of rules at alater point.
Experiments have been conducted withhigh performance in automatically marking intra-chunk dependencies.Using information such as karakas based onsome vibhaktis (post-positions) and other informa-tion like TAM (tense, aspect and modality) of themain verb seems very well suited for handling freeword order languages.
Other works based on thisscheme like (Bharati et al, 1993; Bharati et al,2002; Pedersen et al, 2004) have shown promisingresults.
We, therefore, propose the use of depend-ency annotation based on the Paninian model in theIndian context.3 Annotation Procedure and Corpus De-scriptionThe annotation task is planned on a million wordHindi corpora obtained from CIIL (Central Insti-tute for Indian Languages), Mysore, India.
It is arepresentative corpus which contains texts fromvarious domains like newspaper, literature, gov-722ernment reports, etc.
The present subset on whichthe dependency annotation is being performed hasalready been manually tagged and chunked.
Cur-rently the annotation is being carried out by 2 an-notators, who are graduate students with linguisticknowledge.
The tool being used for the annotationis part of Sanchay (Singh, 2006) which is a collec-tion of tools and APIs for South Asian languages.4 SchemeThere are a total of 28 relations (see,http://ltrc.deptagset.googlepages.com/home) whichwe encode during the annotation.
The total numberof relations in the framework is few which has adirect bearing on the parser based on this frame-work (both, rule based and statistical).
We brieflydiscuss some of these relations in this section.4.1 Dependency relationsAs mentioned earlier, the proposed scheme usesthe dependency relations from Paninian grammar.Section 4.1.1 below shows some karaka relations,section 4.1.2 shows some other relations;4.1.1 karaka relations(1) raama phala   khaataa hai?Ram?
?fruit?
?eat?
?is?
?Ram eats fruit?Figure1.
(2) raama   chaaku   se     saiv     kaattaa hai?Ram?
?knife?
-inst  ?apple?
?cut?
?is?
?Ram cuts the apple with a knife?Figure2.Examples (1), and (2) above show some simplecases which have karaka relations such as k3(karana; ?instrument?
), k1 (karta), k2 (karma) (theterm karta and karma can be roughly translated as?agent?
and ?theme?).
One must note here that thenotion of karta, karma, etc, is not equivalent to thatof the ?agent?, ?theme?
thematic roles (althoughthey might map to them sometimes).
The reasonfor this divergence in the two notions (karaka andthematic role) is due to the difference in what theyconvey.
Thematic role is purely semantic in naturewhereas the karaka is syntactico-semantic.
Exam-ples (3), illustrates this point,(3) chaabhi  ne      darvaazaa   kholaa?key?
?-erg?
?door?
?opened?
?The key opened the door?In the above examples chaabhi is k1 (karta),whereas it takes instrument thematic role.
Whilethe karaka relations are primarily motivated viaverbal semantics, syntactic cues like postpositionsand verbal morphology play an important role too.For example in (3) above, the ergative case ?ne?provides a strong cue to identify karta.
Panini de-fines ?karta?
as ?svatantra karta?
which can betranslated as ?the participant which is the most in-dependent in a given action?.
In (3) ?key?
has sucha property.
When the speaker uses ?key?
in (3),he/she intends to elevate the role of ?key?
in theaction of opening and does not communicate theactual agent of the action.
The speaker uses ?key?as the independent participant in the act of open-ing.
Hence, ?key?
is the karta (see Bharati et al,1995, pp.
65-73, for a more detailed discussion).4.2 Special Cases(a) POF (Part of relation)Conjunct verbs form a very challenging case foranalysis in Indian languages.
They have been ex-tensively analyzed in the past.
Some notable at-tempts have been (Greaves, 1983; Kellogg, 1972;Mohanan, 1994; Butt, 2004).
The example belowshows a N+V conjunct verb usage;(4)  raama   ne    mujhase     prashna    kiyaa?Ram?
-erg  ?me-inst?
?question?
?do?
?Ram asked me a question.
?723In example (4), prashna kiyaa is a conjunct verband behaves as a single semantic unit.
These verbscan also be discontiguous as in (5),(5) raama  ne    mujhase   prashna   pichle saal kiyaa?Ram?
-erg  ?me-inst?
?question?
?last?
?year?
?did?
?Ram asked me a question last year.
?In the above example above a normal conjunctverb sequence prashna kiyaa is disjoint, making itrather difficult to annotate.
In fact, practicallyanything can come between the disjointedelements.
Ideally, the noun/adjective + verbsequence of the conjunct verb is placed in onechunk.
Keeping this in mind, example (6) below iseven more problematic,(6)  maine     usase       ek       prashna  kiyaa?I-erg?
?him-inst?
?one?
?question?
?did?
?I asked him a question?The noun prashna ?question?
within the con-junct verb sequence prashna kiyaa is being modi-fied by the adjective ek ?one?
and not the entirenoun-verb sequence; the annotation scheme shouldbe able to account for this relation in the depend-ency tree.
If prashna kiyaa is grouped as a singleverb chunk, it will not be possible to mark the ap-propriate relation between ek and prashna.
Toovercome this problem it is proposed to break ekprashna kiyaa into two separate chunks, [ekprashna]/NP2 [kiyaa]/VG3.
The dependency rela-tion of prashna with kiyaa will be POF (?Part OF?relation), i.e.
the noun or an adjective in the con-junct verb sequence will have a POF relation withthe verb.
This way, the relation between ek andprashna becomes an intra-chunk relation as theywill now become part of a single NP chunk.
Whatmakes such a sequence unique is the fact that thecomponents which make up a conjunct verb arechunked separately, but semantically they consti-tute a single unit.The proposed scheme has the following advan-tages:(i) It captures the fact that the noun-verb sequeence is a conjunct verb by linking them with anappropriate tag, this information is extremely cruc-2 Noun Phrase3 Verb Groupial syntactically.
(ii) It allows us to deal with the modifier-modified relation between an adjective and itsmodified noun, as in example (6), which is a fre-quent phenomenon.The tree below shows the proposed solution,where the adjective ek modifies the noun prashnainstead of the entire prashna kiyaa, which wouldhave been the case had we not separated prashnakiyaa into two separate chunks.Figure3.
(b) ccof (?conjunct of?
relation) and ellipsesIn the case of coordinating conjunction like aur?and?
, the conjunct becomes the root and takes thetwo conjoined elements as children, the relationmarked on the edges is ccof (conjunct of).
Thisanalysis captures the fact that neither of the con-joined elements is the head.
(The head of the two(or more) conjoined elements lies in the conjunct,and may be so computed when needed.)
The ele-ments participating in the coordination can belongto various categories, such as, noun, adjective, ad-verbs etc; they can also be entire clauses, partici-ples, etc.
Other conjunct and punctuations whichact like conjuncts are annotated similarly.When one or more element from a sentence isdropped, it is called ellipses.
A null elementmarked with a special tag ?NULL?
is introduced incases of ellipses, where without inserting it the treecannot be drawn.
Null_NP, Null_VG, Null_CCPetc mark different kinds of ellipses.In this section, we have briefly discussed someof the relations and showed their actual usage us-ing some sentences.
The number of tags in the pro-posed scheme is not very large.
A limited set oftags helps immensely in developing high-performance parsers (both rule based and statisti-cal) and other related applications.
We should notehere that our tag-set, although small, is not a de-724limiting factor and is not a compromise on the se-mantics, as these 28 relations are enough to fullyparse the sentences in the language.5 EvaluationTo make sure that the quality of the annotated cor-pus is good, the annotators cross-validate eachother?s work.
A senior team member finally checksthe annotated corpus (of both the annotators) toensure that the errors are minimized.
Note thatsuch a setup is only temporary, we need such athorough validation because we are still in theprocess of revising the guidelines.
Once the guide-lines become stable, the annotators won?t need tocross-validate.
Of course, the task of final valida-tion will still continue.6 ExperimentsSome preliminary experiments were conducted ona corpus of 1403 Hindi sentences that have beenfully annotated.
The aim was to access;1.
Whether the syntactic cues can be ex-ploited for better machine learnability.2.
Whether certain generalization can bemade for a constraint parser.3.
How far would the automatic annotationhelp the annotators?We found a strong co-relation between mostvibhakti-karaka occurrences (shaded cells in Table1).
k7 (?place?)
for example, overwhelmingly takesmem post-position, k3 (karana) takes se in all thecases.
Of course, there are some competing rela-tions which show preference for the same post-position.
In such cases only the post-position in-formation will not be sufficient and we need totake into account other syntactic cues as well.These syntactic cues can be TAM (tense, aspectand modality) of the verb, verb class information,etc.
For example, in case of karata karaka (k1), thefollowing heuristics help resolve the ambiguitiesseen in Table 1.
These heuristics are applied se-quentially, i.e.
if the first fails then the next follows.Note that the heuristics mentioned below are meantonly for illustrative purpose.
The cues mentionedin the heuristics will finally be used as features byan efficient ML technique to automate the task ofannotation.H1: k1 agrees in gender, number and personwith the verb if it takes a nominative case,H2: k1 takes a ko case-marker if the TAM of theverb has nA,H3: It takes a kaa/ke/ki if the verb is infinitive,H4: It takes a se or dvaara if the TAM of theverb is passiveH5: It takes a ne case-marker if the verb is tran-sitive and the TAM is perfectiveTable-2 shows the results when the heuristicswere tested on the annotated corpus to test theireffectiveness.Table 1. karaka-vibhakti correlationTable 2.
Heuristics for k1 disambiguationThe field ?Total?
in Table-2 gives us the numberof instances where a particular heuristic was ap-plied.
For example, there were 1801 instanceswhere k1 appeared in a nominative case and H1correctly identified 1461 instances.
H1 failed dueto the errors caused by the morphological analyzer,presence of conjuncts, etc.
Of particular interestare H2 and H3 which didn?t work out for largenumber of cases.
It turns out that H2 failed forwhat is understood in the literature as dative sub-jects.
Dative subjects occur with some specificverbs, one possible solution could be to use suchverbs for disambiguation.
Automatic identificationof conjunct verbs is a difficult problem; in fact,there isn?t any robust linguistic test which can be4 karaka relations (see,http://ltrc.deptagset.googlepages.com/home)5 vibhakti (post-position)725used to identify such verbs.
Similar heuristics canbe proposed for disambiguating other karaka basedon some syntactic cues.
Based on the above resultsone can safely conclude that arriving at some ro-bust generalization (like, karaka-vibhakti correla-tion) based on the syntactic cues is in fact possible.This can help us immensely in building an efficientparser for Hindi (and other ILs).
It goes withoutsaying that there exists a lot of scope for automat-ing the annotation task.7 ConclusionIn this paper we have introduced an ongoing effortto annotate Indian languages with dependency rela-tion.
We stated the motivation behind followingthe Paninian framework in the Indian Languagescenario.
We discussed the basic scheme alongwith some new relations such as ccof, POF, etc.We also showed the results of some experimentsconducted on the annotated data which showedthat there is a strong co-relation between vibhakti-karaka relations.AcknowledgementThanks are due to Prof. Ramakrishnamacharyuluwho has been guiding us throughout the develop-ment of the proposed scheme.ReferencesAkshar Bharati and Rajeev Sangal.
1993.
Parsing FreeWord Order Languages in the Paninian Framework,ACL93: Proc.
of Annual Meeting of Association forComputational Linguistics.Akshar Bharati, Vineet Chaitanya and Rajeev Sangal.1995.
Natural Language Processing: A PaninianPerspective, Prentice-Hall of India, New Delhi, pp.65-106.Akshar Bharati, Rajeev Sangal, T Papi Reddy.
2002.
AConstraint Based Parser Using Integer Programming,In Proc.
of ICON-2002: International Conference onNatural Language Processing, 2002.Cristina Bosco and V. Lombardo.
2004.
Dependencyand relational structure in treebank annotation.
InProceedings of Workshop on Recent Advances inDependency Grammar at COLING'04.S.
Brants, S. Dipper, S. Hansen, W. Lezius and G.Smith.
2002.
The TIGER Treebank.
In Proceedingsof the Workshop on Treebanks and Linguistic Theo-ries.M.
Butt.
2004.
The Light Verb Jungle.
In G. Aygen, C.Bowern & C. Quinn eds.
Papers from theGSAS/Dudley House Workshop on Light Verbs.Cambridge, Harvard Working Papers in Linguistics,p.
1-50.Edwin Greaves.
1983.
Hindi Grammar.
Asian Educa-tional Services, New Delhi, pp.
335-340E.
Hajicova.
1998.
Prague Dependency Treebank: FromAnalytic to Tectogrammatical Annotation.
In Proc.TSD?98.R.
Hudson.
1984.
Word Grammar, Basil Blackwell, 108Cowley Rd, Oxford, OX4 1JF, England.S.
H. Kellogg.
1972.
A Grammar of the Hindi Language.Munshiram Manoharlal, New Delhi, pp.
271-279.P.
Kiparsky and J. F. Staal.
1969.
?Syntactic and Rela-tions in Panini?, Foundations of Language 5, 84-117.M.
Marcus, B. Santorini, and M.A.
Marcinkiewicz.1993.
Building a large annotated corpus of English:The Penn Treebank, Computational Linguistics 1993.I.
A. Mel'cuk.
1988.
Dependency Syntax: Theory andPractice, State University, Press of New York.K.
P. Mohanan.
1982.
Grammatical relations in Malaya-lam, In Joan Bresnan (ed.
), The Mental Representa-tion of Grammatical Relations, MIT Press, Cam-bridge.Tara Mohanan, 1994.
Arguments in Hindi.
CSLI Publi-cations.M.
Pedersen, D. Eades, S. K. Amin, and L. Prakash.2004.
Relative Clauses in Hindi and Arabic: A Pan-inian Dependency Grammar Analysis.
In COLING2004 Recent Advances in Dependency Grammar,pages 9?16.
Geneva, Switzerland.O.
Rambow, C. Creswell, R. Szekely, H. Taber, and M.Walker.
2002.
A dependency treebank for English.
InProceedings of the 3rd International Conference onLanguage Resources and Evaluation.Anil Kumar Singh.
2006.http://sourceforge.net/projects/nlp-sanchayCharudev Shastri.
1973.
Vyakarana Chandrodya (Vol.
1to 5).
Delhi: Motilal Banarsidass.
(In Hindi)S. M. Shieber.
1985.
Evidence against the context-freeness of natural language.
In Linguistics and Phi-losophy, p. 8, 334?343.L.
Tesni?re.
1959.
El?ments de Syntaxe Structurale.Klincksiek, Paris.L.
van der Beek, G. Bouma, R. Malouf, and G. vanNoord.
2002.
The Alpino dependency treebank.Computational Linguistics in the Netherlands.726
