An Endogeneous Corpus-Based Method for Structural Noun PhraseDisambiguationDidier BourigaultCentre d'Analyse t de Math6matiques Sociales(EHESS - Paris Sorbonne - CNRS)andElectricit6 de France - Direction des Etudes et RecherchesService Informatique etMath6matiques Appliqu6es1, avenue du G6n6ral de Gaulle92141 Clamart CedexFRANCEAbstractIn this paper, we describe amethod for structuralnoun phrase disambiguation which mainly relieson the examination of the text corpus underanalysis and doesn't need to integrate anydomain-dependent l xico- or syntactico-semanticinformation.
This method is implemented in theTerminology Extraction Sotware LEXTER.
Wefirst explain why the integration of LEXTER inthe LEXTER-K project, which aims at buildinga tool for knowledge extraction from largetechnical text corpora, requires improving thequality of the terminolgy extracted by LEXTER.Then we briefly describe the way LEXTERworks and show what kind of disambiguation ithas to perform when parsing "maximal-length"noun phrases.
We introduce a method ofdisambiguation which relies on a very simpleidea : whenever LEXTER has to choose amongseveral competing noun sub-groups in order todisambiguate a maximal-length noun phrase, itchecks each of these sub-groups if it occursanywhere lse in the corpus in a non-ambiguoussituation, and then it makes a choice.
Thehalf-a-million words corpus analysis resulted inan efficient strategy of disambiguation.
Theaverage rates are :27 % no disambiguation70 % correct disambiguation3 % wrong disambiguationThe LEXTER-K project :knowledge extraction from largetechnical text corporaLEXTER is a Terminology Extraction Software(Bourigault, 1992a, 1992b).
A corpus ofFrench-language texts on any (technical) subject is fedin.
LEXTER performs a grammatical nalysis of thiscorpus and yields a list of noun phrases which arelikely to be terminological units, representing theconcepts of the subject field.
This list together with thecorpus it has been extracted from is then passed on toan expert for validation by the means of aterminological hypertext web.
LEXTER has beendevelopped inan industrial context, in the Research andDevelopment Division of Electricit6 de France.
It waspreviously designed to deal with the problem ofcreating or updating thesauri used by an AutomaticIndexing System.We are integrating LEXTER in a text analysistool to aid knowledge acquisition in the framework ofKnowledge-Based System construction.
This tool(LEXTER-K) will propose a structured list of candidateterms, rather than a flat list, which could be consideredas a first coarse-grained modelisation of the informationconveyed by the texts under analysis.Structuring of the terminology will beperformed in two ways : on the one hand, by astructural analysis of the terminological noun phrasesextracted by LEXTER; on the other hand, by ananalysis of the sentences in which the candidate termsoccur.
This analysis will focus on the most relevantterms, determined by a statistical processing based onthe assumption that the most frequent erms areprobably the most relevant.We plan a two-stage architecture forLEXTER-K, that is, (1) the extraction of theterminology of the subject field, by a robustgrammatical nalysis (LEXTER), (2) the syntacticanalysis of the sentences by a parser using thisterminology.
The syntactic structures of the sentencesin a text, and the syntactic structures of theterminological units have to be placed on two differentorganisational levels.
As the terminological unit is asemantic unit, it should be treated as such on thesyntactic level, as well.
Dissociating these two81analysis, though one taking advantages of the resultsgiven by the other, will guarantee a better efficiency forthe parser, in particular by limiting the combinatoryexplosion of structural ambiguities.It is well known that Natural Languagesystems usually require considerable knowledgeacquisition, especially in building a specificallyoriented field vocabulary in the case of systems whichhave to analyse technical texts.
We think that thistwo-stage analysis (extracting the terminology of thedomain with a robust superficial analysis, andanalysing the texts with a more in-depth parser usingthis terminology), may lighten the expensive burden ofhand-coding a specialized language and may lead tomore generic and domain-independant Na ural Languagesystems.As long as the terminology extracted uringthe first step has not been validated by an expert, as isnow the case, and it directly feeds the syntacticanalyser, this two-stage architecture quires a betterquality of the terminology extracted by LEXTER.
Thisis the reason why we tried to improve the precision ratein the detection of the terminological noun phrases byimplementing an efficient strategy for structural nounphrase disambiguation.
This strategy isdescribed in thefollowing sections.2 The issue of parsing theambiguous "Maximal-Length"Noun PhrasesIn this section, we briefly describe the type ofgrammatical nalysis performed by LEXTER to extractlikely terminological units and show what kind ofdisambiguation LEXTER has to perform.As we already pointed out, LEXTER has beenachieved in an industrial context; from the beginning ofthe project, we had decided to focus upon a stronglyrestrictive criterium : applying and testing the systemover a wide range of texts.
The texts to be analysed areunrestricted texts gathered in large corpora.
We had thento choose a fast and well-proved method.
Moreover, weargued that, given the restricted grammatical structuresof complex terminological units, it was not necessaryto go into a complete syntactic analysis of thesentences to extract he terminology from a corpus(Bourigault, 1992b).First, a morphological nalyser tags the texts,using a large lexical database and rules of lexicaldisambiguation.
LEXTER treats texts in which eachword is tagged with a grammatical category (noun,verb, adjective, etc.).
LEXTER works in two mainphases : (1) splitting and (2) parsing.
(1) At the splitting stage, LEXTER takesadvantage of "negative" knowledge about he form ofterminological units, by identifying those string levelpatterns which never go to make up these units andwhich can thus be considered as potentialterminological limits.
Such patterns are made up by,say, conjugated verbs, pronouns, conjonctions, certainstrings of preposition + determiner.
The splittingmodule is thus set up with a base of about 60 rules foridentifying frontier markers, which it uses to split thetexts.
The splitting phase produces a series of textsequences, most often noun phrases.
These nounphrases may well be likely terminological unitsthemselves, but more often than not, they containsub-groups which are also likely units.
That is why itis preferable at the splitting stage to refer to the nounphrases identified as "maximal-length noun phrases".Here is an example of a real maximal-length nounphrase : MESURE DU DEBIT DU VENTILATEURD'EXTRACTION AVEC TRAPPE EN POSITIONFERMEE (noun prep det noun prep det noun prepnoun prep noun prep noun adj).
(2) At the parsing stage, LEXTER parses themaximal-length noun phrases (henceforth MLNP) inorder to generate sub-groups, in addition to the MLNP,which are likely terminological units by virtue of theirgrammatical structure and their position in the MLNP.The LEXTER parsing module is made up of parsingrules which indicate which sub-groups to extract from aMLNP on the basis of grammatical structure.Some of the MLNP structures arenon-ambiguous : given such a structure it can be statedwith a very high rate of certainty (Bourigault 1992a)that only one parsing is valid.
The correspondingparsing rules are called non-ambiguous rules.
Forexample, structure (1) is non-ambiguous, and parsingrule \[a\] is a non-ambiguous rule.
(1) noun1 adj prep noun2parsing rule \[a\]noun1 adj prep noun2noun1 adjexample of parseFUSIBLE THERMIQUE DE FERMETUREFUSIBLE THERMIQUESome of the MLNP structures are ambiguous,that is, given such a structure it cannot be stated with asufficient rate of certainty that only one parsing isvalid.
Several sub-structures compete.
Thecorresponding ambiguous parsing rules generate severalcompeting sub-groups.
For example, when informationabout gender or number agreement are not available orof no help, structure (2) is ambiguous, that is, either82the adjective attaches the head noun1 of the nounsub-group noun1 prep noun2, or it attaches noun2,constituting the noun sub-group (noun2 adj); thecompeting noun sub-groups (noun1 prep noun2) and(noun2 adj) will be generated by the ambiguous parsingrule \[b\].
Structure (3) and parsing rule \[c\] are otherexamples of ambiguous structure and rule.
(2) noun1 prep noun2 adjparsing rule \[blnoun1 prep noun2 adj# nounl prep noun2# noun2 adjexample of parseREGISTRE D' EQUILIBRAGE MANUEL# REGISTRE D'EQUILIBRAGE# EQU1LIBRAGE MANUEL(3) noun1 prep noun2 prep noun3parsing rule \[c\]noun1 prep noun2 prep noun3# noun1 prep noun2# noun2 prep noun3example of parseALARME DE SYNTHESE DE DEFAUT# ALARME DE SYNTHESE# SYNTHESE DE DEFAUTThe issue is how to disambiguate in cases ofMLNP with ambiguous structures, that means,whenever an ambiguous rule applies, how to chooseamong the competing generated sub-groups.
Thestrategy of disambiguation is described in the nextsection.3 Strategy of disambiguation :looking at non ambiguoussituations anywhere else in thecorpusThe strategy of disambiguation relies on a very simpleidea, that of looking for non-ambiguous situationselsewhere in the corpus.
Whenever an ambiguous ruleapplying to a MLNP with an ambiguous tructuregenerates competing sub-groups, LEXTER (1) checkseach of them to ascertain if it has been detected in anon-ambiguous ituation (i.e.
generated by anon-ambiguous rule) somewhere else in the corpus, and(2) chooses among the competing sub-groups using aset of disambiguation rules.There is one specific set of disambiguationrules for each ambiguous structure, which covers allthe possibles itutations, that is, all, some, only one,none of the competing sub-group non-ambiguouslydetected.3.1 Situations where none of the competingsub-groups has been non-ambiguouslydetectedGiven an ambiguous Maximal-Length Noun Phrase, ifnone of the competing sub-groups has been detected ina non-ambiguous situation, LEXTER proposes onlythis MLNP, without any sub-group.
Nodisambiguation is performed.
On our half-a-millionwords test corpus, the total number of non-ambiguousMLNPs is 13,591, the total number of ambiguousMLNPs is 3,230, among which 880 are notdisambiguated.
The average rate of no-disambiguationis 27%.
Rates of no-disambiguation for the ten mostfrequent ambiguous structures are shown in Table 1.
(1)noun prep noun adjnoun prep noun prep det nounnoun adj nounnoun prep noun nounnoun prep noun prep nounnoun noun adjnoun noun nounnoun noun prep nounnoun prep noun prep noun adjnoun prep noun adj adj(2)573331294260241193160824233(3)1109174535573472772(4)19 %27 %25 %20 %23 %38 %29 %33 %17 %6%Table 1 Rates of no-disambiguation for the ten most frequent ambiguous structures(1) ambiguous Maximal-Length Noun Phrase (MLNP) structure(2) total number of MLNP with this structure on the half-a-million words test corpus(3) number of cases where none of the competing subgroups has been detected ina non-ambiguous situation(4) rate of no-disambiguation83We are investigating rules that could perform acorrect disambiguation in some of these cases.Choosing the right sub-group can be done by checkingfor each competing sub-group if it has been generatedfrom the analysis of other ambiguous MLNP.
Forexample, RE JET D'AIR FROID and CIRCUIT D'AIRFROID are two ambiguous MLNP extracted from thetest corpus and parsed by parsing rule \[lo\] above :REJET D'AIR FROID# REJET D'AIR# AIR FROIDCIRCUIT D'AIR FROID# CIRCUIT D'AIR# AIR FROIDSince none of the sub-groups RE JET D'AIRand AIR FROID on the one hand, and CIRCUIT D'AIRand AIR FROID on the other hand, have been detectedin non-ambiguous situations, the MLNPs RE JETD'AIR FROID and CIRCUIT D'AIR FROID have notbeen disambiguated by LEXTER.
But comparing theparsings of these ambiguous MLNPs (AfR FROIDgenerated in both cases) can lead to the hypothesis thatextracting AIR FROID is the correct way ofdisambiguating them.
This hypothesis reinforced bythe fact that the pattern AIR + adj.
is very productive inthe corpus (AIR EXTERIEUR, AIR FRAIS, AIRNEUF, AIR AMBIANT, AIR RECYCLE, etc.
).Our experiments show that such situations(sub-groups never non-ambiguously detected butgenerated from different ambiguous MLNPs) are veryrare and this explains why we have no specifictreatment for them yet.nounl  prep noun2detectednounl  prep noun2not detectednumber of occurrences : 141 number of occurrences : 132noun2 adj noun2 adj noun2 adjdetected number of wrong disamb.
: 16 number of wrong disamb.
: 1number of occurrences : 190 number of occurrences : 110noun2 adj noun1 prep noun2not detected number of wrong disamb.
: 15Table 2 Set of disambiguation rules for the ambiguous parsing rule \[b\] :noun1 prep noun2 adj-># nounl prep noun2# noun,?
adjnounl  prep noun2detectednounl  prep noun2not detectednumber of occurrences : 52 number of occurrences : 81noun2 prep noun3 noun2 prep noun3 noun2 prep noun3detected number of wrong disamb.
: 2 number of wrong disamb.
: 0number of occurrences : 53 number of occurrences : 55noun2 prep noun3not detectedTable 3 Set of disambiguation rules for the ambiguous parsing rule \[c\] :nounl prep noun2 prep noun3-># nounl prep noun2# noun2 prep noun3843.2 Situations where at least one competingsub-group has been non-ambiguouslydetectedGiven an ambiguous MLNP, systematically keeping(all) the competing sub-group(s) detected elsewhere inthe corpus in a non-ambiguous situation is not asatisfying principle of disambiguation.
We need moreprecise rules of disambiguation.For example, for each of the parsing rules \[b\]and \[c\], in more than 20 % of the cases on our testcorpus (see top left cells of Table 2 and Table 3), bothcompeting sub-groups have been non-ambiguouslydetected.
That means that both sub-groups are attestedvalid noun phrases as such.
However, only one of themcorresponds toa correct parsing of the MLNP they havebeen extracted from.
In these cases keeping bothsub-groups would alter the precision rate since one ofthem is not grammatically valid.
On the contrary,generating none of them would alter the recall rate.
Wechose to build a set of disambiguation rules for each ofthe ambiguous parsing rules.To work out the disambiguation rules, weadopted an empirical approach based on large-scalecorpus experimentation.
For each of the ambiguousstructures, we examined all the different situations ofdisambiguation (only one, more than one, all thecompeting sub-groups non-ambiguously detected) andfor each of them, we parsed by hand a significativenumber of ambiguous noun phrases extracted from areference test corpus.
Applied to the ambiguous parsingrules \[b\] and \[c\], this approach led us to the followingset of disambiguation rules (see Table 2 and Table 3) :where both competing sub-groups have beennon-ambiguously detected, we checked that mostoften (125 cases/141 for rule \[b\], 50 cases/52 for rule\[c\]) the correct parsing isolates the secondsub-group,noun2 adj for rule \[b\], noun2 prep noun3for rule \[c\] (see the top left cells of Table 2 andTable 3).where only the second sub-group has beennon-ambiguously detected, it always corresponds tothe correct parsing and so it is systematically kept(see the top right cells of Table 2 and Table 3).parsing rules \[b\] and \[c\] differs for the situationswhere only the first sub-group (nounl prep noun2for both rules) has been non-ambiguously detected.For rule \[b\], this sub-group is kept since it mostoften corresponds to a correct parsing of the MLNP(175 cases/190, see the bottom left cell of Table 2).On the contrary, for rule \[c\], no systematic rule canbe stated since the correct parsing sometimes i olatesthis non-ambiguously detected sub-group, but oftenisolates the second one (noun2 prep noun3), altoughit appears nowhere else in the corpus in anon-ambiguous situation (see the bottom left cell ofTable 3).
This mainly happens in cases of "ellipticaldenominations", that is, a concept is first designatedin a text by a "complete" term (for example,CIRCUIT D'ASPERSION D'ENCEINTE), and thenis systematically refered to with an "elliptical" term(for example, CIRCUIT D'ASPERSION).The results we obtained with such sets ofdesambiguation rules (see Table 4) are satisfactory andshow that the strategy described in this paper isefficient.
This is partly due to the fact thatterminological noun phrases are fixed neverdisconnected sequences of words with constrainedgrammatical structures.
Our strategy was not designedto deal with adjective and prepositional phraseattachment i  unrestricted noun phrases.rule \[b\]noun1 prep noun2 adj--># noun1 prep noun2# noun2 ad, irate of no-disambiguationrate of correct disambiguationrate of wrong-disambi~uationrule \[c\]noun1 prep noun2 prep noun3--># noun1 prep noun2# noun2 prep noun3rate of no-disambiguationrate of correct disambi$uationrate of wrong-disambiguation19 %75 %6%45 %54 %1%Table 4 Rates of disambiguation for parsing rules \[b\]and\[c\]4 Re la ted  worksSome of the methodological ideas of LEXTER aresimilar to those expressed in (Andreewsky et al, 1977)for the extraction and disambiguation of lexicalsequences in a method of building lexical semanticrelations dictionaries.
More recently a great deal ofwork in computational linguistics has been devoted toambiguity resolution.
Many rule-based approaches havebeen proposed which require a huge amount ofhand-coded knowledge.
(Jensen and Binot, 1987)proposes a method to disambiguate prepositional phraseattachment in English sentences which is similar toours in that it aims at eliminating the hand coding ofsemantic nformation by exploiting an already availablesource of information.
This method iffers from ours inthat the source of information is a machine-readabledictionary, and it uses complex heuristics, which aredifferent according to the preposition under analysis and85it makes use of some semantic relationships signaledby prepositions.With regards to the specific problem ofstructural noun phrase disambiguation, (Wermter,1989) describes some experiments on article titles forscientific and technical domains.
These noun phraseshave very similar grammatical structures to those ofour "maximal-length noun phrases".
The proposedapproach, based upon the integration of semantic andsyntactic onstraints, is quite different from ours sinceit requires hand-coding of head nouns with semanticfeatures.
(Zernik, 1992a, 1992b) describes a method todistinguish thematic relations (e.g., expressedconcerns), which take on syntactic variations in thecorpus, and sentential relations (e.g., preferred stocks)that do not.
It consists of testing how many times agiven ambiguous relation occurs anywhere else in thecorpus in different syntactic onfigurations.
Thismethod ("Asking the right questions of the corpus") issimilar to the strategy described in this paper, and weagree with Zernik's general line of thinking : "In orderfor a program to interpret natural anguage text, it musttrain on and exploit word connections in the text underinterpretation (Zernik, 1992a).
"Proceedings of the 2nd symposium of TernuVet,Avignon, May 1992\[Bourigault, 1992b\] Didier Bourigault.
SurfaceGrammatical Analysis for the Extraction ofTerminological Noun Phrases.
In Proceedings ofCOLING-92, Nantes, August 1992\[Jensen and Binot, 1987\] Karen Jensen and Jean-LouisBinot.
Disambiguating Prepositional PhraseAttachments by Using On-Line DictionaryDefinition.
Computational Linguistics 13 (3-4),1987\[Wermter, 1989\] Stefan Wermter.
Integration ofSemantic and Syntactic Constraints for StructuralNoun Phrases Disambiguation.
InProceedings of thel l th IJCAI, 1989, Detroit\[Zernik, 1992a\] Lid Zernik.
Shipping Departments v .Shipping Pacemakers : Using Thematic Analysis toImprove Tagging Accuracy.
In Proceedings ofAAAI-92, July 1992, San Jose\[Zernik, 1992b\] Uri Zernik.
Closed Yesterday andClosed Minds: Asking the Right Questions of theCorpus To Distinguish Thematic from SententialRelations.
In Proceedings of COLING-92, August1992, Nantes5 ConclusionWe described a method for the structuraldisambiguation of complex terminological nounphrases, which relies on a simple idea : looking fornon-ambiguous situations anywhere else in the corpus.We call this method Endogeneous since it does not needto integrate any domain-dependent, lexico- orsyntactico-semantic information.
We called itCorpus-Based since it exploits the experience thesystem has acquired after a first reading of the corpusunder analysis.
In that sense, our method can be viewedas a particular implementation f a model of languagePerformance (Bod, 1992), and may belong to the familyof Data-Oriented methods in ComputationalLinguistics.References\[Andreewsky etal., 1977\] Alexandre Andreewsky,Christian Fluhr and Fathi Debilli.
ComputationalLearning of Semantic Lexical Relations for theGeneration and Automatical Analysis of Content.Information Processing 77, 1977\[Bod, 1992\] Rens Bod.
A Computational Model ofLanguage Performance : Data Oriented Parsing.
InProceedings of COLING-92, Nantes, August 1992\[Bourigault, 1992a\] Didier Bourigault.
LEXTER, unLogiciel d'EXtraction de TERminologie.
In86
