Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL 2007, pp.
962?966,Prague, June 2007. c?2007 Association for Computational LinguisticsLog-linear Models of Non-projective Trees, k-best MST Parsing andTree-rankingKeith Hall1 and Jir???
Havelka2 and David A. Smith11Center for Language and Speech ProcessingJohns Hopkins UniversityBaltimore, MD USAkeith hall@jhu.edudasmith@cs.jhu.edu2Institute of Formal and Applied LinguisticsCharles UniversityPrague, Czech Republichavelka@ufal.mff.cuni.czAbstractWe present our system used in the CoNLL2007 shared task on multilingual parsing.The system is composed of three compo-nents: a k-best maximum spanning tree(MST) parser, a tree labeler, and a rerankerthat orders the k-best labeled trees.
Wepresent two techniques for training theMST parser: tree-normalized and graph-normalized conditional training.
The tree-based reranking model allows us to explic-itly model global syntactic phenomena.
Wedescribe the reranker features which includenon-projective edge attributes.
We providean analysis of the errors made by our systemand suggest changes to the models and fea-tures that might rectify the current system.1 IntroductionReranking the output of a k-best parser has beenshown to improve upon the best results of a state-of-the-art constituency parser (Charniak and John-son, 2005).
This is primarily due to the ability toincorporate complex structural features that cannotbe modeled under a CFG.
Recent work shows thatk-best maximum spanning tree (MST) parsing andreranking is also viable (Hall, 2007).
In the currentwork, we explore the k-best MST parsing paradigmalong with a tree-based reranker.
A system usingthe parsing techniques presented in this paper wasentered in the CoNLL 2007 shared task competi-tion (Nivre et al, 2007).
This task evaluated pars-ing performance on 10 languages: Arabic, Basque,Catalan, Chinese, Czech, English, Greek, Hungar-ian, Italian, and Turkish using data originating froma wide variety of dependency treebanks, and trans-formations of constituency-based treebanks (Hajic?et al, 2004; Aduriz et al, 2003; Mart??
et al, 2007;Chen et al, 2003; Bo?hmova?
et al, 2003; Marcus etal., 1993; Johansson and Nugues, 2007; Prokopidiset al, 2005; Csendes et al, 2005; Montemagni et al,2003; Oflazer et al, 2003).We show that oracle parse accuracy1 of the out-put of our k-best parser is generally higher than thebest reported results.
We also present the resultsof a reranker based on a rich set of structural fea-tures, including features explicitly targeted at mod-eling non-projective configurations.
Labeling of thedependency edges is accomplished by an edge la-beler based on the same feature set as used in train-ing the k-best MST parser.2 Parser DescriptionOur parser is composed of three components: a k-best MST parser, a tree-labeler, and a tree-reranker.Log-linear models are used for each of the com-ponents independently.
In this section we give anoverview of the models, the training techniques, andthe decoders.2.1 MST Parsing, Reranking, and LabelingThe connection between the maximum spanningtree problem and dependency parsing stems fromthe observation that a dependency parse is simply anoriented spanning tree on the graph of all possible1The oracle accuracy for a set of hypotheses is the maximalaccuracy for any of the hypotheses.962dependency links (the fully connected dependencygraph).
Unfortunately, by mapping the problem toa graph, we assume that the scores associated withedges are independent, and thus, are limited to edge-factored models.Edge-factored models are severely limited in theircapacity to predict structure.
In fact, they can onlydirectly model parent-child links.
In order to allevi-ate this, we use a k-best MST parser to generate aset of candidate hypotheses.
Then, we rerank thesetrees using a model based on rich structural featuresthat model features such as valency, subcategoriza-tion, ancestry relationships, and sibling interactions,as well as features capturing the global structure ofdependency trees, aimed primarily at modeling lan-guage specific non-projective configurations.We assign dependency labels to entire trees, ratherthan predicting the labels during tree construction.Given that we have a reranking process, we can la-bel the k-best tree hypotheses output from our MSTparser, and rerank the labeled trees.
We have ex-plored both labeled and unlabeled reranking.
In thelatter case, we simply label the maximal unlabeledtree.2.1.1 MST TrainingMcDonald et al (2005) present a technique fortraining discriminative models for dependency pars-ing.
The edge-factored models we use for MSTparsing are closely related to those described in theprevious work, but allow for the efficient compu-tation of normalization factors which are requiredfor first and second-order (gradient-based) trainingtechniques.We consider two estimation procedures forparent-prediction models.
A parent-predictionmodel assigns a conditional score s(g|d) for ev-ery parent-child pair (we denote the parent/governorg, and the child/dependent d), where s(g|d) =s(g, d)/?g?
s(g?, d).
In our work, we computeprobabilities p(g|d) based on conditional log-linearmodels.
This is an approximation to a generativemodel that predicts each node once (i.e.,?d p(d|g)).In the graph-normalized model, we assume thatthe conditional distributions are independent of oneanother.
In particular, we find the model parametersthat maximize the likelihood of p(g?|d), where g?is the correct parent in the training data.
We per-form the optimization over the entire training set,tying the feature parameters.
In particular, we per-form maximum entropy (MaxEnt) estimation overthe conditional distribution using second-order gra-dient descent optimization techniques.2 An advan-tage of the parent-prediction model is that we canframe the estimation problem as that of minimum-error training with a zero-one loss term:p(e, g|d) =exp(?i ?ifi(e, g, d))Zd(1)where e ?
{0, 1} is the error term (e is 1 forthe correct parent and 0 for all other nodes) andZd =?j exp(?i ?ifi(ej , gj , d)) is the normaliza-tion constant for node d. Note that the normaliza-tion factor considers all graphs with in-degree zerofor the root node and in-degree one for other nodes.At parsing time, of course, our parent predictionsare constrained to produce a (non-projective) treestructure.
We can sum over all non-projective span-ning trees by taking the determinant of the Kirchhoffmatrix of the graph defined above, minus the rowand column corresponding to the root node (Smithand Smith, 2007).
Training graph-normalized andtree-normalized models under identical conditions,we find tree normalization wins by 0.5% to 1% ab-solute dependency accuracy.
Although tree normal-ization also shows a (smaller) advantage in k-bestoracle accuracy, we do not believe it would have alarge effect on our reranking results.2.1.2 Reranker TrainingThe reranker is based on a conditional log-linearmodel subject to the MaxEnt constraints using thesame second-order optimization procedures as thegraph-normalized MST models.
The primary dif-ference here is that there is no single correct tree inthe set of k candidate parse trees.
Instead, we havek trees that are generated by our k-best parser, eachwith a score assigned by the parser.
If we are per-forming labeled reranking, we label each of thesehypotheses with l possible labelings, each with ascore assigned by the labeler.As with the parent-prediction, graph-normalizedmodel, we perform minimum-error training.
The2For the graph-normalized models, we use L-BFGS opti-mization provided through the TAO/PETSC optimization li-brary (Benson et al, 2005; Balay et al, 2004).963optimization is achieved by assuming the oracle-bestparse(s) are correct and the remaining hypothesesare incorrect.
Furthermore, the feature values arescaled according to the relative difference betweenthe oracle-best score and the score assigned to thenon-oracle-best hypothesis.Note that any reranker could be used in place ofour current model.
We have chosen to keep thereranker model closely related to the MST parsingmodel so that we can share feature representationsand training procedures.2.1.3 Labeler TrainingWe used the same edge features to train a sep-arate log-linear labeling model.
Each edge featurewas conjoined with a potential label, and we thenmaximized the likelihood of the labeling in the train-ing data.
Since this model is also edge-factored, wecan store the labeler scores for each of the n2 po-tential edges in the dependency tree.
In the submit-ted system, we simply extracted the Viterbi predic-tions of the labeler for the unlabeled trees selectedby the reranker.
We also (see below) ran experimentswhere each entry in the k-best lists input as trainingdata to the reranker was augmented by its l-best la-belings.
We hoped thereby to inject more diversityinto the resulting structures.2.1.4 Model FeaturesOur MST models are based on the features de-scribed in (Hall, 2007); specifically, we use featuresbased on a dependency nodes?
form, lemma, coarseand fine part-of-speech tag, and morphological-string attributes.
Additionally, we use surface-stringdistance between the parent and child, buckets offeatures indicating if a particular form/lemma/tagoccurred between or next to the parent and child, anda branching feature indicating whether the child isto the left or right of the parent.
Composite features,combining the above features are also included (e.g.,a single feature combining branching, parent & childform, parent & child tag).The tree-based reranker includes the features de-scribed in (Hall, 2007) as well as features based onnon-projective edge attributes explored in (Havelka,2007a; Havelka, 2007b).
One set of features mod-els relationships of nodes with their siblings, in-cluding valency and subcategorization.
A secondset of features models global tree structure and in-cludes features based on a node?s ancestors and thedepth and size of its subtree.
A third set of fea-tures models the interaction of word order and treestructure as manifested on individual edges, i.e., thefeatures model language specific projective and non-projective configurations.
They include edge-basedfeatures corresponding to the global constraints ofprojectivity, planarity and well-nestedness, and fornon-projective edges, they furthermore include leveltype, level signature and ancestor-in-gap features.All features allow for an arbitrary degree of lexical-ization; in the reported results, the first two sets offeatures use coarse and fine part-of-speech lexical-izations, while the features in the third set are usedin their unlexicalized form due to time limitations.3 Results and AnalysisHall (2007) shows that the oracle parsing accuracyof a k-best edge-factored MST parser is consid-erably higher than the one-best score of the sameparser, even when k is small.
We have verified thatthis is true for the CoNLL shared-task data by evalu-ating the oracle rates on a randomly sampled devel-opment set for each language.In order to select optimal model parameters forthe MST parser, the labeler, and reranker, we sam-pled approximately 200 sentences from each train-ing set to use as a development test set.
Training thereranker requires a jackknife n-fold training proce-dure where n?1 partitions are used to train a modelthat parses the remaining partition.
This is done ntimes to generate k-best parses for the entire trainingset without using models trained on the data they arerun on.For lack of space, we report only results on theCoNLL evaluation data set here, but note that thetrends observed on the evaluation data are identicalto those observed on our development sets.In Table 1 we present results for labeled (and un-labeled) dependency accuracy on the CoNLL 2007evaluation data set.
We report the oracle accu-racy for different sized k-best hypothesis sets.
Thecolumns are labeled by the number of trees outputfrom the MST parser, k;3 and by the number of al-3All results are reported for the graph-normalized trainingtechnique.964Language Oracle Accuracy New CoNLL07 CoNLL07k = 1, l = 1 k = 10, l = 5 k = 50, l = 1 k = 50, l = 2 Reranked Reported BestArabic (83.10) (85.56) (86.96) (83.67) 73.40 (83.45) 76.52 (86.09)Basque 67.92 (76.88) 76.25 (82.19) 69.93 (84.99) 76.81 (77.76) 69.80 (78.52) 76.92 (82.80)Catalan 82.28 (87.82) 85.11 (90.87) 86.82 (92.68) 86.82 (89.43) 82.38 (87.80) 88.70 (93.40)Chinese 73.86 (85.58) 91.32 (93.39) 82.39 (95.80) 92.21 (87.87) 82.77 (87.91) 84.69 (88.94)Czech 74.05 (80.21) 78.58 (85.08) 80.97 (87.60) 80.97 (82.20) 72.27 (78.47) 80.19 (86.28)English 82.21 (83.63) 85.95 (87.59) 87.99 (89.75) 87.99 (85.31) 81.93 (83.21) 89.61 (90.63)Greek 72.21 (81.16) 78.58 (84.89) 74.13 (86.95) 79.48 (81.81) 74.21 (82.04) 76.31 (84.08)Hungarian 71.68 (78.57) 79.70 (83.03) 74.32 (85.12) 80.75 (80.05) 74.20 (79.34) 80.27 (83.55)Italian 77.92 (83.16) 85.05 (87.54) 80.30 (89.66) 86.42 (84.71) 80.69 (84.81) 84.40 (87.91)Turkish 75.34 (83.63) 83.96 (89.65) 77.78 (92.40) 84.98 (84.13) 77.42 (85.18) 79.81 (86.22)Table 1: Labeled (unlabeled) attachment accuracy for k-best MST oracle results and reranked data on the evaluation set.
The1-best results (k = 1, l = 1) represent the performance of the MST parser without reranking.
The New Reranked field shows recentunlabeled reranking results of 50-best trees using a modified feature set.
For arabic, we only report unlabeled accuracy for differentk and l.ternative labelings for each tree, l. When k = 1,the score is the best achievable by the edge-factoredMST parser using our models.
As k increases, theoracle parsing accuracy increases.
The most ex-treme difference between the one-best accuracy andthe 50-best oracle accuracy can be seen for Turkishwhere there is a difference of 9.64 points of accu-racy (8.77 for the unlabeled trees).
This means thatthe reranker need only select the correct tree froma set of 50 to increase the score by 9.64%.
As ourreranking results show, this is not as simple as it mayappear.We report the results for our CoNLL submissionas well as recent results based on alternative param-eters optimization on the development set.
We re-port the latest results only for unlabeled accuracy ofreranking 50-best MST output.4 ConclusionOur submission to the CoNLL 2007 shared taskon multilingual parsing supports the hypothesis thatedge-factored MST parsing is viable given an effec-tive reranker.
The reranker used in our submissionwas unable to achieve the oracle rates.
We believethis is primarily related to a relatively impoverishedfeature set.
Due to time constraints, we have notbeen able to train lexicalized reranking models.
Theintroduction of lexicalized features in the rerankershould influence the selection of better trees, whichwe know exist in the k-best hypothesis sets.ReferencesA.
Abeille?, editor.
2003.
Treebanks: Building and UsingParsed Corpora.
Kluwer.I.
Aduriz, M. J. Aranzabe, J. M. Arriola, A. Atutxa, A. Diazde Ilarraza, A. Garmendia, and M. Oronoz.
2003.
Con-struction of a Basque dependency treebank.
In Proc.
of the2nd Workshop on Treebanks and Linguistic Theories (TLT),pages 201?204.Satish Balay, Kris Buschelman, Victor Eijkhout, William D.Gropp, Dinesh Kaushik, Matthew G. Knepley, Lois Curf-man McInnes, Barry F. Smith, and Hong Zhang.
2004.PETSc users manual.
Technical Report ANL-95/11 - Re-vision 2.1.5, Argonne National Laboratory.Steven J. Benson, Lois Curfman McInnes, Jorge More?, andJason Sarich.
2005.
TAO user manual (revision 1.8).Technical Report ANL/MCS-TM-242, Mathematics andComputer Science Division, Argonne National Laboratory.http://www.mcs.anl.gov/tao.A.
Bo?hmova?, J.
Hajic?, E.
Hajic?ova?, and B. Hladka?.
2003.
ThePDT: a 3-level annotation scenario.
In Abeille?
(Abeille?,2003), chapter 7, pages 103?127.Eugene Charniak and Mark Johnson.
2005.
Coarse-to-fine n-best parsing and MaxEnt discriminative reranking.
In Pro-ceedings of the 43rd Annual Meeting of the Association forComputational Linguistics.K.
Chen, C. Luo, M. Chang, F. Chen, C. Chen, C. Huang, andZ.
Gao.
2003.
Sinica treebank: Design criteria, representa-tional issues and implementation.
In Abeille?
(Abeille?, 2003),chapter 13, pages 231?248.D.
Csendes, J. Csirik, T. Gyimo?thy, and A. Kocsor.
2005.
TheSzeged Treebank.
Springer.J.
Hajic?, O.
Smrz?, P. Zema?nek, J.
S?naidauf, and E. Bes?ka.
2004.Prague Arabic dependency treebank: Development in dataand tools.
In Proc.
of the NEMLAR Intern.
Conf.
on ArabicLanguage Resources and Tools, pages 110?117.Keith Hall.
2007. k-best spanning tree parsing.
In (To Appear)Proceedings of the 45th Annual Meeting of the Associationfor Computational Linguistics.965Jir???
Havelka.
2007a.
Beyond projectivity: Multilingual eval-uation of constraints and measures on non-projective struc-tures.
In (To Appear) Proceedings of the 45th Annual Meet-ing of the Association for Computational Linguistics.Jir???
Havelka.
2007b.
Relationship between non-projectiveedges, their level types, and well-nestedness.
In HumanLanguage Technologies 2007: The Conference of the NorthAmerican Chapter of the Association for Computational Lin-guistics; Companion Volume, Short Papers, pages 61?64.R.
Johansson and P. Nugues.
2007.
Extended constituent-to-dependency conversion for English.
In Proc.
of the 16thNordic Conference on Computational Linguistics (NODAL-IDA).M.
Marcus, B. Santorini, and M. Marcinkiewicz.
1993.
Build-ing a large annotated corpus of English: the Penn Treebank.Computational Linguistics, 19(2):313?330.M.
A.
Mart?
?, M.
Taule?, L. Ma`rquez, and M. Bertran.2007.
CESS-ECE: A multilingual and multilevelannotated corpus.
Available for download from:http://www.lsi.upc.edu/?mbertran/cess-ece/.Ryan McDonald, Koby Crammer, and Fernando Pereira.
2005.Online large-margin training of dependency parsers.
In Pro-ceedings of the 43nd Annual Meeting of the Association forComputational Linguistics.S.
Montemagni, F. Barsotti, M. Battista, N. Calzolari, O. Coraz-zari, A. Lenci, A. Zampolli, F. Fanciulli, M. Massetani,R.
Raffaelli, R. Basili, M. T. Pazienza, D. Saracino, F. Zan-zotto, N. Nana, F. Pianesi, and R. Delmonte.
2003.
Build-ing the Italian Syntactic-Semantic Treebank.
In Abeille?
(Abeille?, 2003), chapter 11, pages 189?210.J.
Nivre, J.
Hall, S. Ku?bler, R. McDonald, J. Nilsson, S. Riedel,and D. Yuret.
2007.
The CoNLL 2007 shared task on de-pendency parsing.
In Proc.
of the Joint Conf.
on Empiri-cal Methods in Natural Language Processing and Computa-tional Natural Language Learning (EMNLP-CoNLL).K.
Oflazer, B.
Say, D. Zeynep Hakkani-Tu?r, and G. Tu?r.
2003.Building a Turkish treebank.
In Abeille?
(Abeille?, 2003),chapter 15, pages 261?277.P.
Prokopidis, E. Desypri, M. Koutsombogera, H. Papageor-giou, and S. Piperidis.
2005.
Theoretical and practical is-sues in the construction of a Greek dependency treebank.
InProc.
of the 4th Workshop on Treebanks and Linguistic The-ories (TLT), pages 149?160.David A. Smith and Noah A. Smith.
2007.
Probabilistic mod-els of nonprojective dependency trees.
In (To Appear) Pro-ceedings of the 2007 Conference on Empirical Methods inNatural Language Processing.966
