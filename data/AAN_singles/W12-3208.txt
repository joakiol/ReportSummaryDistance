Proceedings of the ACL-2012 Special Workshop on Rediscovering 50 Years of Discoveries, pages 76?82,Jeju, Republic of Korea, 10 July 2012. c?2012 Association for Computational LinguisticsText Reuse with ACL: (Upward) TrendsParth Gupta and Paolo RossoNatural Language Engineering Lab - ELiRFDepartment of Information Systems and ComputationUniversidad Polite?cnica de Valencia, Spainhttp://www.dsic.upv.es/grupos/nle{pgupta,prosso}@dsic.upv.esAbstractWith rapidly increasing community, a plethoraof conferences related to Natural LanguageProcessing and easy access to their proceed-ings make it essential to check the integrityand novelty of the new submissions.
Thisstudy aims to investigate the trends of textreuse in the ACL submissions, if any.
We car-ried a set of analyses on two spans of five yearspapers (the past and the present) of ACL usinga publicly available text reuse detection appli-cation to notice the behaviour.
In our study,we found some strong reuse cases which canbe an indicator to establish a clear policy tohandle text reuse for the upcoming editions ofACL.
The results are anonymised.1 IntroductionText reuse refers to using the original text again ina different work.
The text reuse in its most generalform can be of two types: verbatim (quotations, defi-nitions) and modified (paraphrasing, boilerplate text,translation).
Although, the text reuse can be legal orillegal from a publishing authority perspective aboutthe accreditation to the original author, more impor-tantly it involves the ethical issues, especially in thescientific work.There is a fuzzy line between the text reuseand the plagiarism and often this line is legislative.There are no straight-forward measures to declare awork as plagiarism and hence the publishing housesusually deploy their own rules and definitions to dealwith plagiarism.
For example, IEEE1 and ACM2both consider the reuse as plagiarism in case of:1. unaccredited reuse of text;2. accredited large portion of text without properdelineation or quotes to the complete reusedportion.IEEE does not allow reusing large portion of ownprevious work, generally referred as self reuse orself plagiarism, without delineation, while ACM al-lows it provided the original source being explicitlycited.With the advent of a large number of conferencesand their publicly available proceedings, it is ex-tremely easy to access the information on the desiredtopic to refer to and to reuse.
Therefore, it becomesessential to check the authenticity and the novelty ofthe submitted text before the acceptance.
It becomesnearly impossible for a human judge (reviewer) todiscover the source of the submitted work, if any,unless the source is already known.
Automatic pla-giarism detection applications identify such poten-tial sources for the submitted work and based on it ahuman judge can easily take the decision.Unaccredited text reuse is often referred to asplagiarism and there has been abundant researchabout the same (Bouville, 2008; Loui, 2002; Mad-dox, 1995).
Self plagiarism is another related is-sue, which is less known but not less unethical.1http://www.ieee.org/publications_standards/publications/rights/ID_Plagiarism.html2http://www.acm.org/publications/policies/plagiarism_policy76There has been limited research on the nature of self-plagiarism and its limit to the acceptability (Bretagand Mahmud, 2009; Collberg and Kobourov, 2005).In theory, the technologies to identify either of themdo not differ at the core and there have been manyapproaches to it (Bendersky and Croft, 2009; Hoadand Zobel, 2003; Seo and Croft, 2008).
The textreuse can also be present in the cross-language en-vironment (Barro?n-Ceden?o et al, 2010; Potthast etal., 2011a).
Since few years, PAN organises com-petitions at CLEF3 (PAN@CLEF) on plagiarism de-tection (Potthast et al, 2010; Potthast et al, 2011b)and at FIRE4 (PAN@FIRE) on cross-language textreuse (Barro?n-Ceden?o et al, 2011).In the past, there has been an attempt to identifythe plagiarism among the papers of ACL anthologyin (HaCohen-Kerner et al, 2010), but it mainly aimsto propose a new strategy to identify the plagiarismand uses the anthology as the corpus.
In this study,we are concerned about the verbatim reuse and thattoo in large amount, only.
We identify such strongtext reuse cases in two spans of five years papers ofACL (conference and workshops) and analyse themto notice the trends in the past and the present basedon their year of publication, paper type and the au-thorship.
The detection method along with the sub-section of the ACL anthology used are described inSection 2.
Section 3 contains the details of the car-ried experiments and the analyses.
Finally, in Sec-tion 4 we summarise the work with remarks.2 Detection MethodThe aim of this study is to investigate the trend oftext reuse, and not proposing a new method.
Look-ing at the importance of the replicability of the ex-periments, we use one of the publicly available toolsto detect the text reuse.
First we describe the bestplagiarism detection system tested in (Potthast etal., 2010) and then explain how the tool we usedworks similarly.
The partition of the ACL anthol-ogy used for the experiments is described in Section2.1.
The details of the system along with the detec-tion method are presented in the Section 2.2.3http://pan.webis.de/4http://www.dsic.upv.es/grupos/nle/fire-workshop-clitr.htmlYear Long Short Workshop Total1993 47 0 68 1151994 52 0 56 1081995 56 0 15 711996 58 0 73 1311997 73 0 232 3052007 131 57 340 5282008 119 68 363 5502009 121 93 740 9542010 160 70 772 10022011 164 128 783 1075Table 1: The year-wise list of the number of acceptedpapers in ACL.2.1 Data PartitionWe crawled the long and short papers of the ACLconference and all the workshop papers from theACL anthology of the years 1990-1997 and 2004-2011.
We converted all the papers from the PDFformat to plain text for processing using ?pdftotext?utility available with ?xpdf?
package in linux5.
Thebibtex files available in the anthology are used forthe author analysis.
We investigate the trends overtwo span of five years (1993-97 and 2007-11) to de-pict the past and the present trends.
The numberof papers accepted for the mentioned categories inthese years are listed in Table 1.2.2 Reuse IdentificationFirst, we describe how the best plagiarism detectionsystem at PAN@CLEF 2010 works.
Then we showthat WCopyFind6, the tool we used, works in a sim-ilar way.2.2.1 State-of-the-artThe best system in PAN@CLEF 2010 editionwas (Kasprzak and Brandejs, 2010).
The overviewof the system is as follows.1.
Preprocessing: The documents are processed tonormalise the terms and word 5-gram chunksare made using MD5 hashing scheme.5http://linux.die.net/man/1/pdftotext6WCopyFind is freely available under GNU publiclicense at http://plagiarism.bloomfieldmedia.com/z-wordpress/software/wcopyfind/.
Version4.1.1 is used.772.
Similarity: Inverted index of these chunks iscreated.
Then for the given suspicious docu-ment, the source documents which contain atleast 20 such chunks in common, are retrieved.3.
Annotation: The boundary of the exact frag-ments (cases) are annotated based on the posi-tion information of the common chunks.
Falsepositives are removed by neglecting the caseswhere the chunks are sparse (lay far from oneanother).2.2.2 WCopyFindFor the identification of text reuse, we used anopen source application WCopyFind.
This systemParameter ValueShortest Phrase to Match 6Fewest Matches to Report 500Ignore Punctuation YesIgnore Outer Punctuation YesIgnore Numbers YesIgnore Letter Case YesSkip Non-Words YesSkip Long Words NoMost Imperfections to Allow 0Table 2: Parameters used of WCopyFind to identify thetext reuse.works very similarly to the approach explained inSec.
2.2.1.7 It handles the preprocessing by user de-fined variables as shown in Table 2 to tokenise theterms.
Then it creates the word n-grams where n= Shortest Phrase to Match parameter and convertsthe chunks into 32-bit hash codes for similarity esti-mation.
It outputs the reuse text portions among thedocuments in question explicitly as shown in Fig.
1.The system extends a wide variety of parameterswith word and phrase-based similarity.
We used theparameter values as depicted in Table 2.
Most ofthe parameters are self-explanatory.
We used word6-grams for the identification because the value ofn=6 is suggested by the developers of WCopyFind.Parameter ?Fewest Matches to Report?
interprets thenumber of words in the matching n-grams hence itis set to 500, which practically stands for ?85 word7http://plagiarism.bloomfieldmedia.com/How_WCopyfind_and_Copyfind_Work.pdfFigure 1: Screen-shot of the output of WCopyFind.
Thesize is deliberately kept small to anonymise the case.
Bestviewed in color.6-grams.
There was a high overlap of the text amongthe papers in the ?reference?
section which can notbe considered as reuse.
To avoid this influence, weestimated the maximum words overlap of the refer-ence section between two papers empirically, whichturned out to be 200 words.
Therefore, setting thethreshold value to 500 words safely avoided highbibliographical similarity based false positives.
Inorder to confirm the reliability of the threshold, wemanually assessed 50 reported cases at random, inwhich 48 were actually cases of text reuse and only2 were false positives.3 ExperimentsWe carried out a number of experiments to under-stand the nature and the trends of text reuse amongthe papers of ACL.
These experiments were carriedfor papers over two spans of five years to notice thetrends.3.1 At presentIn this category, we carry out the experiments on pa-pers within the most recent five years.I.
Text reuse in the papers among the same yearsubmissions This experiment aimed to identifythe text reuse among the papers accepted in the sameyear.
Each year, ACL welcomes the work in manydifferent formats like long, short, demo, student ses-sion and workshop papers.
This analysis reveals thesame or highly similar text submitted in multiple for-mats.Fig.
2 shows the number of reuse cases identi-fied among the papers accepted in the same year.7801020304050602007 2008 2009 2010 2011 2012  0102030405060Year# of cases1020 2746?Figure 2: The text reuse cases identified among the pa-pers of the same year submissions (span 2007-11).010203040506070SS LS LL LW SW WW  010203040506070Paper Type# of cases1 520 2759Figure 3: The text reuse cases based on the type of thepapers involved.
The ?L?, ?S?
and ?W?
denote the long,short and workshop papers respectively.
?XY?
refers tothe cases of reuse involving one paper of type X and theother of type Y (span 2007-11).We also analysed the types of the papers involvedin these reuse cases.
In the same year papers, it isdifficult to decide the source and the target paper,because both are not published at the time of theirreview.
Therefore, the number of cases based on theunordered pairs of the paper types involved in thereuse are shown in Fig.
3.
It is noticeable from Fig.
2and Table 1 that, although there is no big differencebetween the number of accepted papers in the lastthree years, the number of reuse cases are increasingrapidly.
Moreover, Fig.
3 reveals that the chance of aworkshop paper being involved in a reuse case witha long, short or another workshop paper is higher.II.
Text reuse in the papers from the previousyear submissions This experiment aimed to de-pict the phenomenon of text reuse from an alreadypublished work, in this case, the ACL papers of theprevious years.
In this experimental setting, we con-sidered the papers of a year ?X?
as the target papersand the papers of the past three years from ?X?
asthe source papers.
Fig.
4 depicts the reuse trend of0 1020 3040 5060 7080 902007 2008 2009 2010 2011 2012  010 2030 4050 6070 8090Year# of cases12294358?Figure 4: The text reuse cases in the papers of a year con-sidering the papers of the past three years as the source(span 2007-11).01020304050602007 2008 2009 2010 2011 2012  0102030405060Year# of cases6243746?Figure 5: The text reuse cases in the papers of a yearconsidering the papers of the immediate past year as thesource (span 2007-11).this nature over a span of five years.We also carried a similar analysis consideringonly the immediate past year papers as the source.Fig.
5 presents the trend of such cases.
It is notice-able from the Fig.
4 and 5 that the trend is upwards.Moreover, it is interesting to notice that the majorityof the reuse cases involved the immediate past yearpapers as the source compared to the previous threeyear papers as the source.We also analysed the trend of reuse based on thesource and the target paper types and the findings aredepicted in Fig.
6.
Though the reuse cases involvingthe workshop papers are very high, there are notice-able amount of text reuse cases involving the paperswhere both of them (source and target) are of typelong.3.2 In retrospectIn this section we investigate the trends of text reusein early 5 years papers i.e.
papers from the span ofyears 1993-1997.
Though the ACL Anthology con-tains papers from 1979, we chose this span because,for the consistency we wanted to include workshop79020406080100120SS SL WS SW LS LW WL LL WW  020406080100120Paper Type# of cases1 4 5 5 9 1018108Figure 6: The text reuse trend based on the source and thetarget paper type.
The ?L?, ?S?
and ?W?
denote the long,short and workshop papers respectively.
?LS?
refers tosource is long paper and target is short paper, ?SL?
refersto opposite and so on (span 2007-11).024681012141993 1994 1995 1996 1997  02468101214Year# of cases1 0 08Figure 7: The text reuse cases identified among the pa-pers of the same year submissions (span 1993-97).02468101214LL LW WW  02468101214Paper Type# of cases5 4Figure 8: The text reuse cases based on the type of thepapers involved.
The ?L?
and ?W?
denote the long andworkshop papers respectively.
?XY?
refers to the cases ofreuse involving one paper of type X and the other of typeY (span 1993-97).papers in the experiments, which only started in1990.
So our first test year became 1993 consid-ering previous three years papers to it serving as thesource.Figs.
7, 8, 9, 10 and 11 show the behaviour in thepast years for the experiments described in Section3.1.
These results are relatively low compared to thebehaviour in the present.
To better understand this,024681012141993 1994 1995 1996 1997  02468101214Year# of cases1 0 07Figure 9: The text reuse cases in the papers of a year con-sidering the papers of the past three years as the source(span 1993-97).024681012141993 1994 1995 1996 1997  02468101214Year# of cases1 0 06Figure 10: The text reuse cases in the papers of a yearconsidering the papers of the immediate past year as thesource (span 1993-97).02468101214LW WL LL WW  02468101214Paper Type# of cases404Figure 11: The text reuse trend based on the source andthe target paper type.
The ?L?
and ?W?
denote the longand workshop papers respectively.
?LW?
refers to sourceis long paper and target is a workshop paper, ?WL?
refersto opposite and so on (span 1993-97).we present the number of text reuse cases in boththe test spans as a relative frequency based on thetotal number of accepted papers in Table 3.
It can benoticed from Table 3 that the reuse cases were quitea few in the past except the year 1997.
Moreover,in the last five years the amount of text reuse caseshave grown from 5.11% to 9.67%.
In should alsobe noticed that in spite of these cases of text reuse,80a large partition of the accepted papers (more than90%) still remains free from text reuse.Year Tot.
Cases Tot.
Accepted % Cases1993 1 115 0.871994 2 108 1.851995 0 71 01996 0 131 01997 15 305 4.922007 27 528 5.112008 22 550 4.002009 49 954 5.142010 70 1002 6.992011 104 1075 9.67Table 3: The relative frequency of text reuse cases overthe years.3.3 Author analysis of the reuse casesFinally we analysed the authorship of these textreuse cases and categorised them as self and crossreuse.
If the two papers involved in text reuse shareat least one common author then it is considered as acase of self reuse otherwise is reffered as cross reuse.The number of the self and cross reuse cases in thelast five year papers are reported in Table 4.
Theself reuse cases are much higher than the cross reusecases.We also analysed the frequency of a particular au-thor being involved in the text reuse cases.
Thisanalysis is presented in Fig.
12.
This phenomenonfollows the Zipf?s power law i.e.
a small set of au-thors (635 out of 8855 = less than 10%) refer to thereported cases of reuse in the last five years.
Moreinterestingly, only 80 authors (roughly 1% of the to-tal authors) are involved in more than 5 cases of textreuse.Reuse Type No.
of CasesSelf 232Cross 17Total 249Table 4: Authorship of the text reuse cases.
?Self?
de-notes that at least one author is common in the papersinvolved and ?Cross?
denotes otherwise.051015202530354045505520 40 60 80 100 200 250 300 600 800 8855# of casesoftext reuseAuthorsauthors involved in the number of casesFigure 12: Involvement of an author in the number of textreuse cases.4 RemarksThese cases are reported based on the verbatim copyof the text in the ACL proceedings only.
We didnot aim to detect any text reuse that is paraphrased,which in reality can not be neglected.
The para-phrased cases of text reuse are even harder to de-tect, as remarked in (Stein et al, 2011): the state-of-the-art plagiarism detectors succeeded in detect-ing less than 30% of such plagiarised text fragments.Moreover, including the other major conferencesand journals of the field, the number of reportedcases may increase.
The manual analysis revealedthat, in some cases, the related work section is com-pletely copied from another paper.
There were manycases when two papers share a large portion of thetext and differ mostly in the experiments and resultssection.
This study revealed that self reuse is moreprominent in the ACL papers compared to the crossreuse.
The cross reuse could be a plagiarism case ifthe original authors are not acknowledged properlyand explicitly.
The ethicality and the acceptabilityof the self text reuse is arguable.
Once more, theaim of this paper is not to judge the acceptability ofthe text reuse cases but to advocate the need of suchsystems to help in the review process.
Text reuse inthe same year submissions is also an eye opener be-cause in such cases the text is novel but is used topublish in multiple formats and can stay unnoticedfrom the reviewers.
In order to uphold the qualityand the novelty of the work accepted in ACL, it isessential to implement a clear policy for text reuseand the technology to handle such reuse cases.
Wehope this work will help the ACL research commu-81nity to consider handling the text reuse for the up-coming editions.AcknowledgmentThis work has been done in the framework of theVLC/CAMPUS Microcluster on Multimodal Inter-action in Intelligent Systems and it has been partiallyfunded by the European Commission as part of theWIQ-EI IRSES project (grant no.
269180) withinthe FP 7 Marie Curie People Framework, and bythe Text-Enterprise 2.0 research project (TIN2009-13391-C04-03).
We thank Rafael Banchs for hissuggestions and ideas.ReferencesAlberto Barro?n-Ceden?o, Paolo Rosso, Eneko Agirre, andGorka Labaka.
2010.
Plagiarism detection across dis-tant language pairs.
In Proceedings of the 23rd In-ternational Conference on Computational Linguistics,COLING ?10, Beijing, China, August 23-27.Alberto Barro?n-Ceden?o, Paolo Rosso, Shobha DeviLalitha, Paul Clough, and Mark Stevenson.
2011.Pan@fire: Overview of the cross-language !ndian textre-use detection competition.
In In Notebook Papersof FIRE 2011, Mumbai, India, December 2-4.Michael Bendersky and W. Bruce Croft.
2009.
Findingtext reuse on the web.
In Proceedings of the SecondACM International Conference on Web Search andData Mining, WSDM ?09, pages 262?271, New York,NY, USA.
ACM.Mathieu Bouville.
2008.
Plagiarism: Words and ideas.Science and Engineering Ethics, 14(3).Tracey Bretag and Saadia Mahmud.
2009.
Self-plagiarism or appropriate textual re-use?
Journal ofAcademic Ethics, 7(3):193?205.Christian Collberg and Stephen Kobourov.
2005.
Self-plagiarism in computer science.
Commun.
ACM,48(4):88?94, April.Yaakov HaCohen-Kerner, Aharon Tayeb, and Natan Ben-Dror.
2010.
Detection of simple plagiarism in com-puter science papers.
In Proceedings of the 23rd In-ternational Conference on Computational Linguistics,COLING ?10, pages 421?429, Beijing, China.Timothy C. Hoad and Justin Zobel.
2003.
Methods foridentifying versioned and plagiarized documents.
J.Am.
Soc.
Inf.
Sci.
Technol., 54(3):203?215, February.Jan Kasprzak and Michal Brandejs.
2010.
Improving thereliability of the plagiarism detection system - lab re-port for pan at clef 2010.
In Martin Braschler, DonnaHarman, and Emanuele Pianta, editors, CLEF (Note-book Papers/LABs/Workshops).Michael C. Loui.
2002.
Seven ways to plagiarize: han-dling real allegations of research misconduct.
Scienceand Engineering Ethics, 8(4):529?539.JohnMaddox.
1995.
Plagiarism is worse than mere theft.Nature, 376(6543):721.Martin Potthast, Alberto Barro?n-Ceden?o, Andreas Eiselt,Benno Stein, and Paolo Rosso.
2010.
Overview of the2nd international competition on plagiarism detection.In Notebook Papers of CLEF 2010 LABs and Work-shops, CLEF ?10, Padua, Italy, September 22-23.Martin Potthast, Alberto Barro?n-Ceden?o, Benno Stein,and Paolo Rosso.
2011a.
Cross-language plagia-rism detection.
Language Resources and Evaluation,45(1):45?62.Martin Potthast, Andreas Eiselt, Alberto Barro?n-Ceden?o,Benno Stein, and Paolo Rosso.
2011b.
Overview ofthe 3rd international competition on plagiarism detec-tion.
In Notebook Papers of CLEF 2011 LABs andWorkshops, CLEF ?11, Amsterdam, The Netherlands,September 19-22.Jangwon Seo and W. Bruce Croft.
2008.
Local text reusedetection.
In Proceedings of the 31st annual inter-national ACM SIGIR conference on Research and de-velopment in information retrieval, SIGIR ?08, pages571?578, New York, NY, USA.
ACM.Benno Stein, Martin Potthast, Paolo Rosso, AlbertoBarro?n-Ceden?o, Efstathios Stamatatos, and MosheKoppel.
2011.
Fourth international workshop on un-covering plagiarism, authorship, and social softwaremisuse.
SIGIR Forum, 45(1):45?48, May.82
