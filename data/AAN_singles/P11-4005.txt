Proceedings of the ACL-HLT 2011 System Demonstrations, pages 26?31,Portland, Oregon, USA, 21 June 2011. c?2011 Association for Computational LinguisticsEdIt: A Broad-Coverage Grammar Checker Using Pattern GrammarChung-Chi Huang Mei-Hua Chen Shih-Ting Huang Jason S. ChangInstitute of Information Systems and Department of Computer Science,Applications, National Tsing Hua University, National Tsing Hua University,HsinChu, Taiwan, R.O.C.
300 HsinChu, Taiwan, R.O.C.
300{u901571,chen.meihua,koromiko1104,Jason.jschang}@gmail.comAbstractWe introduce a new method for learning todetect grammatical errors in learner?s writ-ing and provide suggestions.
The methodinvolves parsing a reference corpus andinferring grammar patterns in the form of asequence of content  words, function words,and parts-of-speech (e.g., ?play ~ role inVing?
and ?look forward to  Ving?).
At run-time, the given passage submitted by thelearner is matched using an extendedLevenshtein algorithm against  the set  ofpattern rules in order to detect  errors andprovide suggestions.
We present a proto-type implementation of the proposedmethod, EdIt, that  can handle a broad rangeof errors.
Promising results are illustratedwith three common types of errors in non-native writing.1 IntroductionRecently, an increasing number of research hastargeted language learners?
need in editorial assis-tance including detecting and correcting grammarand usage errors in texts written in a second lan-guage.
For example, Microsoft  Research has de-veloped the ESL Assistant, which provides such aservice to ESL and EFL learners.Much of the research in this area depends onhand-crafted rules and focuses on certain errortypes.
Very little research provides a generalframework for detecting and correcting all types oferrors.
However, in the sentences of ESL writing,there may be more than one errors and one errormay affect the performance of handling other er-rors.
Erroneous sentences could be more efficientlyidentified and corrected if a grammar checker han-dles all errors at  once, using a set of pattern rulesthat reflect the predominant usage of the Englishlanguage.Consider the sentences, ?He play an importantroles to close this deals.?
and ?He looks forward tohear you.?
The first  sentence contains inaccurateword forms (i.e., play, roles, and deals), and rareusage (i.e., ?role to close?
), while the second sen-tence use the incorrect verb form of ?hear?.
Goodresponses to these writing errors might  be (a) Use?played?
instead of ?play.?
(b) Use ?role?
insteadof ?roles?,  (c) Use ?in closing?
instead of ?toclose?
(d) Use ?to hearing?
instead of ?to hear?,and (e) insert  ?from?
between ?hear?
and ?you.
?These suggestions can be offered by learning thepatterns rules related to ?play ~ role?
and ?lookforward?
based on analysis of ngrams and collo-cations in a very large-scale reference corpus.
Withcorpus statistics, we could learn the needed phra-seological tendency in the form of pattern rulessuch as ?play ~ role in  V-ing) and ?look forwardto V-ing.?
The use of such pattern rules is in linewith the recent  theory of Pattern Grammar putforward by Hunston and Francis (2000).We present  a system, EdIt, that automaticallylearns to provide suggestions for rare/wrong usagesin non-native writing.
Example EdIt  responses to a26text are shown in Figure 1.
EdIt has retrieved therelated pattern grammar of some ngram and collo-cation sequences given the input  (e.g., ?play ~ rolein V-ing1?, and ?look forward to V-ing?).
EdItlearns these patterns during pattern extractionprocess by syntactically analyzing a collection ofwell-formed, published texts.At run-time, EdIt first processes the input  pas-sages in the article (e.g., ?He play an importantroles to close ?)
submitted by the L2 learner.
AndEdIt  tag the passage with part  of speech informa-tion, and compares the tagged sentence against  thepattern rules anchored at  certain collocations (e.g.,?play ~ role?
and ?look forward?).
Finally, EdItfinds the minimum-edit-cost  patterns matching thepassages using an extended Levenshtein?s algo-rithm (Levenshtein, 1966).
The system then high-lights the edits and displays the pattern rules assuggestions for correction.
In our prototype, EdItreturns the preferred word form and prepositionusages to the user directly (see Figure 1); alterna-tively, the actual surface words (e.g., ?closing?
and?deal?)
could be provided.Input:Related pattern rulesplay ~ role in Nounplay ~ role in V-inghe plays DEThe played DETlook forward to V-inghear from PRON ...Suggestion:He played an important role in closing this deal.
He looksforward to hearing from you.He play an important roles to close thisdeals.
He looks forward to hear you.Figure 1.
Example responses to the non-native writing.2 Related WorkGrammar checking has been an area of active re-search.
Many methods, rule-oriented or data-driven, have been proposed to tackle the problemof detecting and correcting incorrect grammaticaland usage errors in learner texts.
It is at  times noeasy to distinguish these errors.
But Fraser andHodson (1978) shows the distinction between thesetwo kinds of errors.For some specific error types (e.g., article andpreposition error), a number of interesting rule-based systems have been proposed.
For example,Uria et al (2009) and Lee et  al.
(2009) leverageheuristic rules for detecting Basque determiner andKorean particle errors, respectively.
Gamon et  al.
(2009) bases some of the modules in ESL Assistanton rules derived from manually inspecting learnerdata.
Our pattern rules, however, are automaticallyderived from readily available well-formed data,but nevertheless very helpful for correcting errorsin non-native writing.More recently, statistical approaches to develop-ing grammar checkers have prevailed.
Among un-supervised checkers, Chodorow and Leacock(2000) exploits negative evidence from edited tex-tual corpora achieving high precision but low re-call, while Tsao and Wible (2009) uses generalcorpus only.
Additionally, Hermet et al (2008) andGamon and Leacock (2010) both use Web as acorpus to detect  errors in non-native writing.
Onthe other hand, supervised models, typically treat-ing error detection/correction as a classificationproblem, may train on well-formed texts as in themethods by De Felice and Pulman (2008) and Te-treault et  al.
(2010), or with additional learner textsas in the method proposed by Brockett et al(2006).
Sun et  al.
(2007) describes a method forconstructing a supervised detection system trainedon raw well-formed and learner texts without errorannotation.Recent work has been done on incorporatingword class information into grammar checkers.
Forexample, Chodorow and Leacock (2000) exploitbigrams and trigrams of function words and part-of-speech (PoS) tags, while Sun et al (2007) uselabeled sequential patterns of function, time ex-pression, and part-of-speech tags.
In an approachsimilar to our work, Tsao and Wible (2009) use acombined ngrams of words forms, lemmas, andpart-of-speech tags for research into constructionalphenomena.
The main differences are that  we an-chored each pattern rule in lexical collocation soas to avoid deriving rules that  is may have two1In the pattern rules, we translate the part-of-speech tag to labels that are commonly used in learner dictionaries.
Forinstance, we use V-ing for the tag VBG denoting the progressive verb form, and Pron and Pron$ denotes a pronounand a possessive pronoun respectively.27consecutive part-of-speech tags (e.g, ?V Pron$socks off?).
The pattern rules we have derived aremore specific and can be effectively used in detect-ing and correcting errors.In contrast  to the previous research, we intro-duce a broad-coverage grammar checker that ac-commodates edits such as substitution, insertionand deletion, as well as replacing word forms orprepositions using pattern rules automatically de-rived from very large-scale corpora of well-formedtexts.3 The EdIt SystemUsing supervised training on a learner corpus is notvery feasible due to the limited availability oflarge-scale annotated non-native writing.
Existingsystems trained on learner data tend to offer highprecision but low recall.
Broad coverage grammarcheckers may be developed using readily availablelarge-scale corpora.
To detect  and correct errors innon-native writing, a promising approach is toautomatically extract  lexico-syntactical patternrules that  are expected to distinguish correct and incorrect sentences.3.1 Problem StatementWe focus on correcting grammatical and usageerrors by exploiting pattern rules of specific collo-cation (elastic or rigid such as ?play ~ rule?
or?look forward?).
For simplification, we assumethat there is no spelling errors.
EdIt provides sug-gestions to common writing errors2of the follow-ing correlated with essay scores3.
(1)  wrong word form(A) singular determiner preceding plural noun(B) wrong verb form: concerning modal verbs (e.g.,?would said?
), subject-verb agreement, auxiliary(e.g., ?should have tell the truth?
), gerund and in-finitive usage (e.g., ?look forward to see you?
and?in an attempt to helping you?
)(2) wrong preposition (or infinitive-to)(A) wrong preposition (e.g., ?to depends of it?
)(B) wrong preposition and verb form (e.g., ?to playan important role to close this deal?
)(3) transitivity errors(A) transitive verb (e.g., ?to discuss about the mat-ter?
and ?to affect to his decision?
)(B) intransitive verb (e.g., ?to listens the music?
)The system is designed to find pattern rules relatedto the errors and return suggestionst.
We now for-mally state the problem that we are addressing.Problem  Statement: We are given a referencecorpus C and a non-native passage T. Our goal isto detect  grammatical and usage errors in T andprovide suggestions for correction.
For this, weextract a set of pattern rules, u1,?, umfrom Csuch that the rules reflect the predominant usageand are likely to distinguish most errors in non-native writing.In the rest  of this section, we describe our solu-tion to this problem.
First, we define a strategy foridentifying predominant  phraseology of frequentngrams and collocations in Section 3.2.
Afer that,we show how EdIt proposes grammar correc-tionsedits to non-native writing at  run-time in Sec-tion 3.3.3.2 Deriving Pattern RulesWe attempt  to derive patterns (e.g., ?play ~ role inV-ing?)
from C expected to represent the immedi-ate context  of collocations (e.g., ?play ~ role?
or?look forward?).
Our derivation process consists ofthe following four-stage:Stage 1.
Lemmatizing, POS Tagging and Phrasechunking.
In the first  stage, we lemmatize and tagsentences in C. Lemmatization and POS taggingboth help to produce more general pattern rulesfrom ngrams or collocations.
The based phrases areused to extract collocations.Stage 2.
Ngrams and Collocations.
In the secondstage of the training process, we calculate ngramsand collocations in C, and pass the frequentngrams and collocations to Stage 4.We employ a number of steps to acquire statisti-cally significant collocations--determining the pairof head words in adjacent base phrases, calculatingtheir pair-wise mutual information values, and fil-tering out candidates with low MI values.Stage 3. onstructing Inverted Files.
In the thirdstage in the training procedure, we build up in-verted files for the lemmas in C for quick access inStage 4.
For each word lemma we store surfacewords, POS tags, pointers to sentences with basephrases marked.2See (Nicholls, 1999) for common errors.3See (Leacock and Chodorow, 2003) and (Burstein et al, 2004) for correlation.28procedure GrammarChecking(T,PatternGrammarBank)(1) Suggestions=?
?//candidate suggestions(2) sentences=sentenceSplitting(T)for each sentence in sentences(3)   userProposedUsages=extractUsage(sentence)for each userUsage in userProposedUsages(4)     patGram=findPatternGrammar(userUsage.lexemes,PatternGrammarBank)(5)     minEditedCost=SystemMax; minEditedSug=?
?for each pattern in patGram(6)        cost=extendedLevenshtein(userUsage,pattern)if cost<minEditedCost(7)            minEditedCost=cost; minEditedSug=patternif minEditedCost>0(8)       append (userUsage,minEditedSug) to Suggestions(9) Return SuggestionsFigure 2.
Grammar suggestion/correction at run-timeStage 4.
Deriving pattern rules.
In the fourth andfinal stage, we use the method described in a pre-vious work (Chen et al, 2011) and use the invertedfiles to find all sentences containing a give wordand collocation.
Words surrounding a collocationare identified and generalized based on their corre-sponding POS tags.
These sentences are then trans-formed into a set  of n-gram of words and POStags, which are subsequently counted and ranked toproduce  pattern rules with high frequencies.3.3 Run-Time Error CorrectionOnce the patterns rules are derived from a corpusof well-formed texts, EdIt utilizes them to checkgrammaticality and provide suggestions for a giventext via the procedure in Figure 2.In Step (1) of the procedure, we initiate a setSuggestions to collect grammar suggestions to theuser text T according to the bank of pattern gram-mar PatternGrammarBank.
Since EdIt  system fo-cuses on grammar checking at  sentence level, T isheuristically split (Step (2)).For each sentence, we extract ngram and POStag sequences userUsage in T. For the example of?He play an important  roles.
He looks forword tohear you?,  we extract ngram such as he V DET,play an JJ NNS, play ~ roles to V, this NNS, lookforward to VB, and hear Pron.For each userUsage, we first access the patternrules related to the word and collocation within(e.g., play-role  patterns for ?play ~ role to close?
)Step (4).
And then we compare userUsage againstthese rules (from Step (5) to (7)).
We use the ex-tended Levenshtein?s algorithm shown in Figure 3to compare userUsage and pattern rules.Figure 3.
Algorithm for identifying errorsIf only partial matches are found for userUsage,that could mean we have found a potential errors.We use minEditedCost and minEditedSug to con-train the patterns rules found for error suggestions(Step (5)).
In the following, we describe how tofind minimal-distance edits.In Step (1) of the algorithm in Figure 3 we allo-cate and initialize costArray to gather the dynamicprogramming based cost  to transform userUsageinto a specific contextual rule pattern.
Afterwards,the algorithm defines the cost of performing substi-tution (Step (2)), deletion (Step (3)) and insertion(Step (4)) at  i-indexed userUsage and j-indexedpattern.
If the entries userUsage[i] and pattern[j]are equal literally (e.g., ?VB?
and ?VB?)
or gram-matically (e.g., ?DT?
and ?Pron$?
), no edit  isneeded, hence, no cost  (Step (2a)).
On the otherhand, since learners tend to select wrong wordform and preposition, we set a lower cost  for  sub-stitution among different word forms of the samelemma or lemmas with the same POS tag (e.g.,replacing V with V-ing or replacing to with in?.
Inaddition to the conventional deletion and insertion(Step (3b) and (4b) respectively), we look ahead tothe elements userUsage[i+1] and pattern[j+1] con-sidering the fact that  ?with or without preposition?and ?transitive or intransitive verb?
often puzzlesEFL learners (Step (3a) and (4a)).
Only a smalledit cost is counted if the next  elements in use-rUsage and Pattern are ?equal?.
In Step (6) theextended Levenshtein?s algorithm returns theminimum edit  cost of revising userUsage usingpattern.Once we obtain the costs to transform the use-rUsage into a similar, frequent pattern rules, wepropose the minimum-cost rules as suggestions  forprocedure extendedLevenshtein(userUsage,pattern)(1) allocate and initialize costArrayfor i in range(len(userUsage))for j in range(len(pattern))if equal(userUsage[i],pattern[j]) //substitution(2a)       substiCost=costArray[i-1,j-1]+0elseif sameWordGroup(userUsage[i],pattern[j])(2b)       substiCost=costArray[i-1,j-1]+0.5(2c)     else substiCost=costArray[i-1,j-1]+1if equal(userUsage[i+1],pattern[j+1]) //deletion(3a)       delCost=costArray[i-1,j]+smallCost(3b)     else delCost=costArray[i-1,j]+1if equal(userUsage[i+1],pattern[j+1]) //insertion(4a)        insCost=costArray[i,j-1]+smallCost(4b)      else insCost=costArray[i,j-1]+1(5)        costArray[i,j]=min(substiCost,delCost,insCost)(6) Return costArray[len(userUsage),len(pattern)]29correction (e.g., ?play ~ role in V-ing?
for revising?play ~ role to V?)
(Step (8) in Figure 2), if itsminimum edit  cost  is greater than zero.
Otherwise,the usage is considered valid.
Finally, the Sugges-tions accumulated for T are returned to users (Step(9)).
Example input  and editorial suggestions re-turned to the user are shown in Figure 1.
Note thatpattern rules involved flexible collocations are de-signed to take care of long distance dependenciesthat might be always possible to cover with limitedngram (for n less than 6).
In addition, the long pat-ter rules can be useful even when it  is not  clearwhether there is an error when looking at a verynarrow context.
For example, ?hear?
can be eitherbe transitive or intransitive depending on context.In the context of ?look forward to?
and personnoun object, it is should be intransitive and  requirethe preposition ?from?
as suggested in the resultsprovided by EdIt (see Figure 1).In existing grammar checkers, there are typicallymany modules examining different types of errorsand different module may have different  priorityand conflict  with one another.
Let  us note that thisgeneral framework for error detection and correc-tion is an original contribution of our work.
In ad-dition, we incorporate probabilities conditioned onword positions in order to weigh edit  costs.
Forexample, the conditional probability of V to imme-diately follow ?look forward to?
is virtually  0,while the probability of V-ing  to do so is approxi-mates 0.3.
Those probabilistic values are used toweigh different edits.4 Experimental ResultsIn this section, we first present the experimentalsetting in EdIt (Section 4.1).
Since our goal is toprovide to learners a means to efficient  broad-coverage grammar checking, EdIt  is web-basedand the acquisition of the pattern grammar in use isoffline.
Then, we illustrate three common types oferrors, scores correlated, EdIt4capable of handling.4.1 Experimental SettingWe used British National Corpus (BNC) as ourunderlying general corpus C. It is a 100 millionBritish English word collection from a wide rangeof sources.
We exploited GENIA tagger to obtainthe lemmas, PoS tags and shallow parsing resultsof C?s sentences, which were all used in construct-ing inverted files and used as examples for GRASPto infer lexicalized pattern grammar.Inspired by (Chen et al, 2011) indicating EFLlearners tend to choose incorrect  prepositions andfollowing word forms following a VN collocation,and (Gamon and Leacock, 2010) showing fixed-length and fixed-window lexical items are the bestevidence for correction, we equipped EdIt withpattern grammar rules consisting of fixed-length(from one- to five-gram) lexical sequences or VNcollocations and their fixed-window usages (e.g.,?IN(in) VBG?
after ?play ~ role?, for window 2).4.2 ResultsWe examined three types of errors and the mixtureof them for our correction system (see Table 1).
Inthis table, results of ESL Assistant  are shown forcomparison, and grammatical suggestions are un-derscored.
As suggested, lexical and PoS informa-tion in learner texts is useful for a grammarchecker, pattern grammar EdIt  uses is easily acces-sible and effective in both grammaticality and us-age check, and a weighted extension to Leven-shtein?s algorithm in EdIt  accommodates substitu-tion, deletion and insertion edits to learners?
fre-quent mistakes in writing.5 Future Work and SummaryMany avenues exist  for future research and im-provement.
For example, we could augment  pat-tern grammar with lexemes?
PoS information inthat the contexts of a word of different PoS tagsvary.
Take discuss for instance.
The present tenseverb discuss is often followed by determiners andnouns while the passive is by the preposition in  asin ??
is discussed in Chapter one.?
Additionally,an interesting direction to explore is enriching pat-tern grammar with semantic role labels (Chen etal., 2011) for simple semantic check.In summary, we have introduced a method forcorrecting errors in learner text based on its lexicaland PoS evidence.
We have implemented themethod and shown that the pattern grammar andextended Levenshtein algorithm in this method arepromising in grammar checking.
Concerning EdIt?sbroad coverage over different  error types, simplic-ity in design, and short  response time, we plan toevaluate it more fully: with or without  conditionalprobability using majority voting or not.4At http://140.114.214.80/theSite/EdIt_demo2/30Erroneous sentence EdIt suggestion ESL Assistant suggestionIncorrect word form?
a sunny days ?
a sunny N a sunny dayevery days, I ?
every N every dayI would said to ?
would V would sayhe play a ?
he V-ed none?
should have tell the truth should have V-en should have to tell?
look forward to see you look forward to V-ing none?
in an attempt to seeing you an attempt to V none?
be able to solved this problem able to V noneIncorrect prepositionhe plays an important role to close ?
play ~ role in nonehe has a vital effect at her.
have ~ effect on effect on herit has an effect on reducing ?
have ~ effect of V-ing none?
depend of the scholarship depend on depend onConfusion between intransitive and transitive verbhe listens the music.
missing ?to?
after ?listens?
missing ?to?
after ?listens?it affects to his decision.
unnecessary ?to?
unnecessary ?to?I understand about the situation.
unnecessary ?about?
unnecessary ?about?we would like to discuss about this matter.
unnecessary ?about?
unnecessary ?about?Mixedshe play an important roles to close this deals.
she V-ed; an Adj N;play ~ role in V-ing; this Nplay an important role;close this dealI look forward to hear you.
look forward to V-ing;missing ?from?
after ?hear?noneTable 1.
Three common score-related error types and their examples with suggestions from EdIt and ESL Assistant.ReferencesC.
Brockett, W. Dolan, and M. Gamon.
2006.
Correcting ESLerrors using phrasal SMT techniques.
In Proceedings of theACL.J.
Burstein, M. Chodorow, and C. Leacock.
2004.
Automatedessay evaluation: the criterion online writing  service.
AIMagazine, 25(3):27-36.M.
H. Chen, C. C. Huang, S. T. Huang, H. C. Liou, and J. S.Chang.
2011.
A cross-lingual pattern retrieval framework.In Proceedings of the CICLing.M.
Chodorow and C. Leacock.
2000.
An unsupervised methodfor detecting grammatical  errors.
In Proceedings of theNAACL, pages 140-147.R.
De Felice and S. Pulman.
2008.
A classifer-based approachto  preposition and determiner error correction in  L2 Eng-lish.
In COLING.I.
S. Fraser and L. M. Hodson.
1978.
Twenty-one kicks at thegrammar horse.
English Journal.M.
Gamon, C. Leacock, C. Brockett, W. B. Bolan, J. F. Gao,D.
Belenko, and A. Klementiev.
Using statistical tech-niques and web search to correct ESL errors.
CALICO,26(3): 491-511.M.
Gamon and C. Leacock.
2010.
Search right and thou shaltfind ?
using web queries for learner error detection.
InProceedings of the NAACL.M.
Hermet, A. Desilets, S. Szpakowicz.
2008.
Using the webas a linguistic resource to automatically correct lexico-syntatic errors.
In LREC, pages 874-878.S.
Hunston and G. Francis.
2000.
Pattern grammar: a corpus-driven approach to the lexical grammar of English.C.
M. Lee, S. J. Eom, and M. Dickinson.
2009.
Toward ana-lyzing Korean learner particles.
In CALICO.V.
I. Levenshtein.
1966.
Binary codes capable of correctingdeletions, insertions and reversals.
Soviet Physics Doklady,10:707-710.C.
Leacock and M. Chodorow.
2003.
Automated grammaticalerror detection.D.
Nicholls.
1999.
The Cambridge Learner Corpus ?
errorcoding and analysis for writing dictionaries and otherbooks for English Learners.G.
H. Sun, X. H. Liu, G. Cong, M. Zhou, Z. Y. Xiong, J. Lee,and C. Y. Lin.
2007.
Detecting erroneous sentences usingautomatically mined sequential patterns.
In ACL.J.
Tetreault, J.
Foster, and M. Chodorow.
2010.
Using parsefeatures for prepositions selection and error detection.
InProceedings of the ACL, pages 353-358.N.
L. Tsao and D. Wible.
2009.
A method for unsupervisedbroad-coverage lexical error detection and correction.
InNAACL Workshop, pages 51-54.31
