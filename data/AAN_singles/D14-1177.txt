Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1701?1712,October 25-29, 2014, Doha, Qatar.c?2014 Association for Computational LinguisticsCombining String and Context Similarityfor Bilingual Term Alignment from Comparable CorporaGeorgios Kontonatsios1,2Ioannis Korkontzelos1,2Jun?ichi Tsujii3Sophia Ananiadou1,2National Centre for Text Mining, University of Manchester, Manchester, UK1School of Computer Science, University of Manchester, Manchester, UK2Microsoft Research Asia, Beijing, China3{gkontonatsios,ikorkontzelos,sananiadou}@cs.man.ac.ukjtsujii@microsoft.comAbstractAutomatically compiling bilingual dictio-naries of technical terms from comparablecorpora is a challenging problem, yet withmany potential applications.
In this paper,we exploit two independent observationsabout term translations: (a) terms are of-ten formed by corresponding sub-lexicalunits across languages and (b) a term andits translation tend to appear in similar lex-ical context.
Based on the first observa-tion, we develop a new character n-gramcompositional method, a logistic regres-sion classifier, for learning a string similar-ity measure of term translations.
Accord-ing to the second observation, we use anexisting context-based approach.
For eval-uation, we investigate the performance ofcompositional and context-based methodson: (a) similar and unrelated languages,(b) corpora of different degree of compa-rability and (c) the translation of frequentand rare terms.
Finally, we combine thetwo translation clues, namely string andcontextual similarity, in a linear model andwe show substantial improvements overthe two translation signals.1 IntroductionBilingual dictionaries of technical terms are re-sources useful for various tasks, such as computer-aided human translation (Dagan and Church,1994; Fung and McKeown, 1997), Statistical Ma-chine Translation (Och and Ney, 2003) and Cross-Language Information Retrieval (Ballesteros andCroft, 1997).
In the last two decades, researchershave focused on automatically compiling bilingualterm dictionaries either from parallel (Smadja etal., 1996; Van der Eijk, 1993) or comparable cor-pora (Rapp, 1999; Fung and Yee, 1998).
Whileparallel corpora contain the same sentences in twolanguages, comparable corpora consist of bilin-gual pieces of text that share some features, only,such as topic, domain, or time period.
Comparablecorpora can be constructed more easily than paral-lel corpora.
Freely available, up-to-date, on-lineresources (e.g., Wikipedia) can be employed.In this paper, we exploit two different sourcesof information to extract bilingual terminologyfrom comparable corpora: the compositional andthe contextual clue.
The compositional clue isthe hypothesis that the representations of a termin any pair of languages tend to consist of cor-responding lexical or sub-lexical units, e.g., pre-fixes, suffices and morphemes.
In order to cap-ture associations of textual units across languages,we investigate three different character n-gram ap-proaches, namely a Random Forest (RF) classifier(Kontonatsios et al., 2014), Support Vector Ma-chines with an RBF kernel (SVM-RBF) and a Lo-gistic Regression (LogReg) classifier.
Whilst theprevious approaches take as an input monolingualfeatures and then try to find cross-lingual map-pings, our proposed method (LogReg classifier)considers multilingual features, i.e., tuples of co-occurring n-grams.The contextual clue is the hypothesis that mu-tual translations of a term tend to occur in similarlexical context.
Context-based approaches are un-supervised methods that compare the context dis-tributions of a source and a target term.
A bilin-gual seed dictionary is used to map context vec-tor dimensions of two languages.
Li and Gaussier(2010) suggested that the seed dictionary can beused to estimate the degree of comparability of abilingual corpus.
Given a seed dictionary, the cor-pus comparability is the expectation of finding foreach word of the source corpus, its translation inthe target part of the corpus.
The performance ofcontext-based methods has been shown to dependon the frequency of terms to be translated and the1701corpus comparability.
In this work, we use an ex-isting distributional semantics approach to locateterm translations.Furthermore, we hypothesise that the compo-sitional and contextual clue are orthogonal, sincethe former considers the internal structure of termswhile the latter exploits the surrounding lexicalcontext.
Based on the above hypothesis, we com-bine the two translation clues in a linear model.For experimentation, we construct compara-ble corpora for four language pairs (English-Spanish, English-French, English-Greek andEnglish-Japanese) of the biomedical domain.We choose this domain because a large propor-tion of the medical terms tends to composition-ally translate across languages (Lovis et al., 1997;Namer and Baud, 2007).
Additionally, given thevast amount of newly introduced terms (neolo-gisms) in the medical domain (Pustejovsky et al.,2001), term alignment methods are needed in or-der to automatically update existing resources.We investigate the following aspects of termalignment: (a) the performance of compositionalmethods on closely related and on distant lan-guages, (b) the performance of context vectors andcompositional methods when translating frequentor rare terms, (c) the degree to which the corpuscomparability affects the performance of context-based and compositional methods (d) the improve-ments that we can achieve when we combine thecompositional and context clue.Our experiments show that the performance ofcompositional methods largely depends on the dis-tance between the two languages.
The perfor-mance of the context-based approach is greatlyaffected by corpus-specific parameters (the fre-quency of occurrence of the terms to be translatedand the degree of corpora comparability).
It is alsoshown that the combination of compositional andcontextual methods performs better than each ofthe clues, separately.
Combined systems can bedeployed in application environments with differ-ent language pairs, comparable corpora and seedsdictionaries.The LogReg, dictionary extraction method de-scribed in this paper is freely available1.1http://personalpages.manchester.ac.uk/postgrad/georgios.kontonatsios/Software/LogReg-TermAlign.tar.gz2 Related WorkContext-based methods (Fung and Yee, 1998;Rapp, 1999) adapt the Distributional Hypothesis(Harris, 1954), i.e., words that occur in similarlexical context tend to have the same meaning, ina multilingual environment.
They represent thecontext of each term t as a context vector, usu-ally following the bag-of-words model.
Each di-mension of the vector corresponds to a contextword occurring within a predefined window, whilethe corresponding value is computed by a corre-lation metric, e.g., Log-Likelihood Ratio (Morinet al., 2007; Chiao and Zweigenbaum, 2002) orPoint-wise Mutual Information (Andrade et al.,2010).
A general bilingual dictionary is then usedto translate/project the target context vectors intothe source language.
As a result, the source andtarget context vectors become directly compara-ble.
In a final step, candidate translations are beingranked according to a distance metric, e.g., cosinesimilarity (Tamura et al., 2012) or Jaccard index(Zanzotto et al., 2010; Apidianaki et al., 2012).Whilst context-based methods have become acommon practise for bilingual dictionary extrac-tion from comparable corpora, nonetheless, theirperformance is subject to various factors, one ofwhich is the quality of the comparable corpus.
Liand Gaussier (2010) introduced the corpus com-parability metric and showed that it is related tothe performance of context vectors.
The higherthe corpus comparability is, the higher the perfor-mance of context vectors is.
Furthermore, contextvector approaches are sensitive to the frequency ofterms.
For frequent terms, distributional seman-tics methods exhibit robust performance since thecorresponding context is more informative.
Chiaoand Zweigenbaum (2002) reported an accuracy of91% for the top 20 candidates when translatingterms that occur 100 times or more.
However,the performance of context vectors drastically de-creases for lower frequency terms (Kontonatsios etal., 2014; Morin and Daille, 2010).Our work is more closely related to a secondclass of term alignment methods that exploits theinternal structure of terms between a source anda target language.
Compositional translation al-gorithms are based on the principal of composi-tionality (Keenan and Faltz, 1985), which claimsthat the translation of the whole is a function ofthe translation of its parts.
Lexical (Morin andDaille, 2010; Daille, 2012; Robitaille et al., 2006;1702Tanaka, 2002) and sub-lexical (Delpech et al.,2012) compositional algorithms are knowledge-rich approaches that proceed in two steps, namelygeneration and selection.
In the generation step,an input source term is segmented into basic trans-lation units: words (lexical compositional meth-ods) or morphemes (sub-lexical methods).
Thena pre-compiled, seed dictionary of words or mor-phemes is used to translate the components of thesource term.
Finally, a permutation function gen-erates candidate translations using the list of thetranslated segments.
In the selection step, candi-date translations are ranked according to their fre-quency (Morin and Daille, 2010; Robitaille et al.,2006) or their context similarity with the sourceterm (Tanaka, 2002).
The performance of thecompositional translation algorithms is bound tothe coverage of the seed dictionary (Daille, 2012).Delpech et al.
(2012) noted that 30% of untrans-lated terms were due to the low coverage of theseed dictionary.Kontonatsios et al.
(2014) introduced a RandomForest (RF) classifier that learns correspondencesof character n-grams between a source and targetlanguage.
Unlike lexical and sub-lexical compo-sitional methods, a RF classifier does not requirea bilingual dictionary of translation units.
Themodel is able to automatically build correlationpaths between source and target sub-lexical seg-ments that best discriminate translation from non-translation pairs.
However, being a supervisedmethod, it still requires a seed bilingual dictio-nary of technical terms for training.
The RF classi-fier was previously applied on an English-Spanishcomparable corpus and it was shown to signifi-cantly outperform context-based approaches.3 MethodsIn this section we describe the character n-grammodels, the context vector method and the hybridsystem.
The lexicon induction task is formalisedas a two-class classification problem.
Given a pairof terms in a source and a target language, the out-put is a prediction of whether the terms are mutualtranslations are not.
Furthermore, each term align-ment method implements a ranking function thatcalculates a similarity score between a source anda target term.
The methods rank target terms ac-cording to the similarity score and select the top Nranked terms as candidate translations.
The rank-ing functions will be discussed in the followingsubsections.3.1 Character n-gram modelsLet s be a source term containing p character n-grams (s={s1, s2, ..., sp} si?
S, ?i ?
[1, p])and t a target term of q n-grams (t={t1, t2, ..., tq}ti?
T , ?i ?
[1, q]).
We extract charac-ter n-grams by considering any contiguous, non-linguistically motivated sequence of charactersthat occurs within a window size of [2 ?
5]2) forEnglish, French and Greek.
For Japanese, uni-grams are included (window size of [1 ?
5] be-cause Japanese terms often contain Kanji (Chi-nese) characters.Given the two lists of source and target n-grams,our objective is to find an underlying relationshipbetween S and T that best discriminates trans-lation from non-translation pairs.
The RF clas-sifier was previously shown to exhibit such be-haviour (Kontonatsios et al., 2014).
An RF clas-sifier (Breiman, 2001) is a collection of decisiontrees voting for the most popular class.
For a pairof source and target terms ?s, t?, the RF methodcreates feature vectors of a fixed size 2r, i.e., firstorder feature space.
The first r features are ex-tracted from the source term, while the last r fea-tures from the target term.
Each feature has aboolean value (0 or 1) that designates the pres-ence/absence of the corresponding n-gram in theinput instance.The ability of the RF to detect latent associa-tions between S and T relies on the decision trees.The internal nodes of a decision tree represent then-gram features that are linked together in the tree-hierarchy.
Each leaf node of the trees is labelled astranslation or non-translation indicating whetherthe parent path of n-gram features is positively ornegatively associated.
The classification marginthat we use to rank the candidate translations isgiven by a margin function (Breiman, 2001):mg(X,Y ) = av(I(x) = 1)?av(I(x)) = 0) (1)where x is an instance ?s, t?, y ?
Y = {0, 1} theclass label, I(?)
: (s, t) ??
{0, 1} is the indicatorfunction of a decision tree and av(I(?))
the aver-age number of trees voting for the same class la-bel.
In our experiments, we used the same settingsas the ones reported in Kontonatsios et al.
(2014).2we have experiments with larger and narrower windowsizes but this setting resulted in better translation accuracy1703We used 140 decision trees and log2|2q| + 1 ran-dom features.
For training an RF model, we usedthe WEKA platform (Hall et al., 2009).The second class of machine learning algo-rithms that we investigate is Support Vector Ma-chines (SVMs).
The simplest version of SVMsis a linear classifier (linear-SVM) that tries toplace a hyperplane, a decision boundary, that sepa-rates translation from non-translation instances.
Alinear-SVM is a feature agnostic method since themodel only exploits the position of the vectors inthe hyperspace to achieve class separation (Hastieet al., 2009).The first order feature representation used withthe RF classifier does not model associations be-tween S and T .
Hence, intuitively, a first or-der feature space is not linearly separable, i.e.,there exists no decision boundary that divides thedata points into translations and non-translations.3.
To solve non-linear classification problems,SVMs employ non-linear kernels.
A kernel func-tion projects input instances into a higher dimen-sional space to discover non-linear associationsbetween the initial features.
In this new, projectedfeature space, the SVM attempts to define a sep-arating plane.
For training an non-linear SVM onthe first order feature space, we used the LIBSVMpackage (Chang and Lin, 2011) with a radial ba-sis function (RBF) kernel.
For ranking candidatetranslations, we used the decision value given byLIBSVM which represents the distance betweenan instance and the hyperplane.
To translate asource term, the method ranks candidate transla-tions by decision value and suggests as best trans-lation the candidate with the maximum distance(maximum margin).While the first order models try to find cross-lingual mappings between monolingual features,our proposed method follows a different approach.It models cross-lingual links between the sourceand target character n-grams and uses them assecond order features to train a linear classifier.A second order feature is a tuple of n-grams inS and T , respectively, that co-occur in a train-ing, translation instance.
Second order feature3We applied a linear-SVM with the first order featurerepresentation on the four comparable corpora for English-French, English-Spanish, English-Greek and English-Japanese.
In all cases, the best accuracies achieved were closeto zero.
Additionally, the ranked list of candidate translationswas the same for all source terms.
Hence, we can empiri-cally suggest that the linear-SVM cannot exploit a first orderfeature space.values are boolean.
Given a translation instance?s, t?
of p source and q target n-grams, there arep?q second order features.
For dimensionality re-duction, we consider as second order features themost frequent out of all possible first order featurecombinations, only.
Experiments indicate that alarge number of features needs to be consideredto achieve robust performance.
To cope with thehigh dimensional second order space, we use LI-BLINEAR (Fan et al., 2008), which is designedto solve large-scale, linear classifications prob-lems.
LIBLINEAR implements two linear clas-sification algorithms: LogReg and linear-SVM.Both models solve the same optimisation problem,i.e., determine the optimal separating plane, butthey adopt different loss functions.
Since LIBLIN-EAR does not support decision value estimationsfor the linear-SVM, we only experimented withLogReg.
Similarly to SVM-RBF, LogReg rankscandidate translations by classification margin.3.2 Context vectorsWe follow a standard approach to calculate contextsimilarity of source and target terms (Rapp, 1999;Morin and Daille, 2010; Morin and Prochasson,2011a; Delpech et al., 2012).
Context vectorsof candidate terms in the source and target lan-guage are populated after normalising each bilin-gual corpus, separately.
Normalisation consistsof stop-word filtering, tokenisation, lemmatisa-tion and Part-of-Speech (PoS) tagging.
For En-glish, Spanish and French we used the TreeTagger(Schmid, 1994) while for Greek we used the ILSPtoolkit (Papageorgiou et al., 2000).
The Japanesecorpus was segmented and PoS-tagged using Ju-man (Kurohashi and Kawahara, 2005).In succession, monolingual context vectors arecompiled by considering all lexical units that oc-cur within a window of 3 words before or af-ter a term (a seven-word window).
Only lexicalunits (seeds) that occur in a bilingual dictionaryare retained The values in context vectors are Log-Likelihood Ratio associations (Dunning, 1993) ofthe term and a seed lexical unit occurring in it.
Ina second step, we use the translations in the seeddictionary to map target context vectors into thesource vector space.
If there are several transla-tions for a term, they are all considered with equalweights.
Finally, candidate translations are rankedin descending order of the cosine of the angle be-tween the mapped target vectors and the source1704TrainingcorpusTestcorpuscharacter n-grammodel context vectorshybrid modelAnnotate AnnotateTrain Projectseed termdictionary seed worddictionaryFigure 1: Architecture of the hybrid term align-ment system.vector.3.3 Hybrid term alignment systemFigure 1 illustrates a block diagram of our termalignment system.
We use two bilingual seed dic-tionaries: (a) a dictionary of term translation pairsto train the n-gram models and (b) a dictionary ofword-to-word correspondences to translate targetcontext vectors.
The n-gram and context vectormethods are used separately to score term pairs.The n-gram model computes the value of the com-positional clue while the context vector estimatesthe score of the contextual clue.
The hybrid modelcombines both methods by using the correspond-ing scores as features to train a linear classifier.For this, we used a linear-SVM of the LIBSVMpackage with default values for all parameters.4 DataFollowing previous research (Prochasson andFung, 2011; Irvine and Callison-Burch, 2013;Klementiev et al., 2012), we construct compara-ble biomedical corpora using Wikipedia as a freelyavailable resource.Starting with a list of 4K biomedical Englishterms (query-terms), we collected 4K EnglishWikipedia articles, by matching query-terms to thetopic signatures of articles.
Then, we followedthe Wikipedia interlingual links to retrieve the-matically related articles in each target language.Since not all English articles contain links for allfour target languages (Spanish, French, Greek andJapanese), we used a different list of query-termsfor each language pair.
Corpora were randomlydivided into training and testing parts.
For train-ing we used 3K documents and for testing the re-maining 1K.
Table 1 shows the size of corpora interms of numbers of source (SW) and target words(TW).4.1 Seed dictionariesAs shown in Figure 1, the term alignment methodsrequire two seed bilingual dictionaries: a term anda word dictionary.
The character n-gram modelsrely on a bilingual term dictionary to learn asso-ciations of n-grams that appear often in technicalterms.
The dictionary may contain both single-word and multi-word terms.
For English-Spanishand English-French we used UMLS (Bodenreider,2004) while for English-Japanese we used an elec-tronic dictionary of medical terms (Denshika andKenkyukai, 1991).An English-Greek biomedical dictionary wasnot available at the time of conducting these ex-periments, thus we automatically compiled a dic-tionary from a parallel corpus.
For this, we traineda standard Statistical Machine Translation system(Koehn et al., 2007) on EMEA (Tiedemann, 2009),a biomedical parallel corpus containing sentence-aligned documents from the European MedicinesAgency.
Then, we extracted all English-Greekpairs for which: (a) the English sequence waslisted in UMLS and (b) the translation probabilitywas equal or higher to 0.7.The sizes of the seed term dictionaries vary sig-nificantly, e.g., 500K entries for English-Frenchbut only 20K entries for English-Greek.
How-ever, the character n-gram models require a rela-tively small portion of the corresponding dictio-nary to converge.
In the reported experiments,we used 10K translation pairs as positive, train-ing instances.
In addition, we generated an equalnumber of pseudo-negative instances by randomlymatching non-translation terms.Morin and Prochasson (2011b) showed that thetranslation accuracy of context vectors is higherwhen using bilingual dictionaries that contain bothgeneral language entries and technical terms ratherthan general or domain-specific dictionaries, sep-1705Training corpus Test Corpus# SW # TW # SW # TWen-fr 4.8M 2.2M 1.9M 1.1Men-es 4.9M 2.5M 1.8M 0.9Men-el 10.2M 2.4M 3.3M 1.3Men-jpn 5.3M 2.4M 2.3M 1.2MTable 1: Statistics of the English-French (en-fr), Engish-Spanish (en-es), English-Greek (en-el) and English-Japanese (en-jpn) Wikipedia com-parable corpora.
SW: source words, TW: targetwordsCorpus Seed wordsComparability in dictionaryen-fr 0.71 66Ken-es 0.75 40Ken-el 0.68 22Ken-jpn 0.49 57KTable 2: Corpus comparability and number of fea-tures of the seed word dictionariesarately.
In a mixed dictionary, lexical units areeither single-word technical terms, such as ?dis-ease?
and ?patient?, or general language words,such as ?occur?
and ?high?.
Note that we havealready compiled a seed term dictionary for eachpair of languages.
Following the suggestion ofMorin and Prochasson (2011b), we attempt to en-rich the seed term dictionaries with general lan-guage entries.
For this, we extracted bilingualword dictionaries for English-Spanish, English-French and English-Greek by applying GIZA++(Och and Ney, 2003) on the EMEA corpus.
Wethen concatenated the word with the term dictio-naries to obtain enhanced seeds for the three lan-guage pairs.
For English-Japanese, we only usedthe term dictionary to translate the target contextvectors.Once the word dictionaries have been compiled,we compute the corpus comparability measure.
Liand Gaussier (2010) define corpus comparabilityas the percentage of words that can be translatedbi-directionally, given a seed dictionary.Table 2 shows corpus comparability scores ofthe four corpora accompanied with the numberof English, single words in the seed dictionar-ies.
It can be observed that seed dictionary sizesare not necessarily proportional to the correspond-ing corpus comparability scores.
As expected, forEnglish-Japanese, corpus comparability is low be-cause the dictionary contains single-word terms,only.
The English-Spanish dictionary is smallerthan the English-French but achieved higher cor-pus comparability, i.e., a higher percentage ofwords can be bi-directionally translated using thecorresponding seed dictionary.
A possible ex-planation is that the comparable corpora wereconstructed using different lists of query-terms.Hence, the query-terms used for English-Spanishretrieved a more coherent corpus.
The resultingvalues of corpus comparability indicate that thecontext vectors will perform the best for English-Spanish while for English-Japanese the perfor-mance is expected to be substantially lower.4.2 Training and evaluation datasetsFor evaluation, we construct a test dataset ofsingle-word terms, in particular nouns or adjec-tives.
The dataset contains 1K terms that occurmore frequently than 20 but not more than 200times and are listed in the English part of theUMLS.
In order to extract candidate translations,we considered all nouns or adjectives that occurat least 5 times in the target part of the corpus.Furthermore, we do not constraint the evaluationdatasets only to those terms whose correspondingtranslation occurs in the corpus.The hybrid model that combines the composi-tional and context clue, is based on a two-featuremodel.
Therefore, the model converges using onlya few hundred instances.
For training a hybridmodel, we used 1K translation instances that oc-curred in the training comparable corpora.
Sim-ilarly, to the character n-gram models, pseudo-negative instances were generated by randomlycoupling non-translation terms.
The ratio of posi-tive to negative instances is 1 : 1.5 ExperimentsIn this section, we present three experiments con-ducted to evaluate the character n-gram, con-text vector and hybrid methods.
Firstly, weexamine the performance of the n-gram mod-els on closely related language pairs (English-French, English-Spanish), on a distant languagepair (English-Greek) and on an unrelated languagepair (English-Japanese).
English and Greek arenot unrelated because they are members of thesame language family, but also not closely re-lated because they use different scripts.
Secondly,1706we compare the character n-gram methods againstcontext vectors when translating frequent or rareterms and on comparable corpora of similar lan-guage pairs (English-French, English-Spanish) butof different corpus comparability scores.
Thirdly,we evaluate the hybrid method on all four com-parable corpora and investigate the improvementmargin of combining the contextual with the com-positional clue.As evaluation metrics, we adopt the top-Ntranslation accuracy, following most previous ap-proaches (Rapp, 1999; Chiao and Zweigenbaum,2002; Morin et al., 2007; Tamura et al., 2012).
Thetop-N translation accuracy is defined as the per-centage of source terms for which a given methodhas output the correct translation among the top Ncandidate translations.5.1 Character n-gram modelsIn the first experiment, we investigate the perfor-mance of the character n-gram models consider-ing an increasing number of features.
The featureswere sorted in order of decreasing frequency of oc-currence.
Starting from the top of the list, morefeatures were incrementally added and translationaccuracy was recorded.Figure 2 shows the top-20 translation accu-racy of single-word terms on an increasing num-ber of first and second order features.
With re-gards to the first order models (Subfigure 2a),the Random Forest (RF) classifier outperformsour baseline method (SVM-RBF) for all four lan-guage pairs.
The largest margin between RF andSVM-RBF can be observed for the English-Greekdataset while for closely related language pairs,i.e., English-French and English-Spanish, the mar-gin is smaller.
Furthermore, it can be noted thatusing only a small number of first order features,1K features (500 for the source and 500 for thetarget language, both n-gram models reach a sta-ble performance.In contrast to the first order models, the Lo-gReg classifier requires a large number of sec-ond order features to achieve a robust performance(Subfigure 2b).
Starting from 100K features, thetranslation accuracy continuously increases.
Thebest performance is observed for a total numberof 4M second order features when consideringthe English-French, English-Spanish and English-Greek datasets.
For English-Japanese, the bestperformance is achieved for 2M features.
Beyondthis point, translation accuracy decreases slightly.After feature selection is performed, we directlycompare all the character n-gram models.
Table 3summarises performance achieved by the LogReg,RF and SVM-RBF models.
It can be noted thatLogReg and RF performed similarly for closelyrelated languages (no statistically significant dif-ferences were observed) while both methods out-performed the SVM-RBF.
However, for English-Greek and English-Japanese, LogReg achieveda statistically significant improvement over thetranslation accuracy of RF and SVM-RBF.
Lo-gReg outperformed RF by 7% for English-Greek,while for English-Japanese the improvement was10% and 17% percent for top-1 and top-20 accu-racy, respectively.
Finally, it can be observed thatthe more distant the language pair is, the lower theperformance.5.2 N-gram methods and context vectorsIn this experiment, we compare the n-gram meth-ods against context vectors with regards to two pa-rameters: (a) the frequency of source terms to betranslated and (b) corpus comparability.
English-French and English-Spanish are similar languagepairs but the corresponding corpora are of dif-ferent corpus comparability scores.
To investi-gate how performance is affected by term occur-rence frequency, we compiled an additional testdataset of 1K rare English terms in the frequencyrange [10, 20].
Our intuition is, that character n-gram methods will perform similarly for all set-tings since character n-grams are corpus indepen-dent features.We compare (a) the character n-gram models(LogReg, RF and SVM-RBF) with (b) the con-text vector method (context) and (c) an upperbound.
The latter represents the percentage ofsource terms for which a reference translation ac-tually occurs in the target corpus.
Hence, the up-per bound is the maximum performance achiev-able according to the reference evaluation.Figure 3a shows the top-20 translation accu-racy for high and medium frequency terms, withinthe frequency range [20, 200].
Context vectorsachieved a robust performance of 52% and 45%for English-Spanish and English-French, respec-tively.
The difference in corpus comparabilitycan explain this 7% margin between these perfor-mances.
As shown in Table 2, the corpus com-parability scores for English-Spanish and English-170700.10.20.30.40.50.6100 200 400 600 800 1000translationaccuracy@ 20# first order featuresRF (en-jpn)SVM-RBF (en-jpn)RF (en-el)SVM-RBF (en-el)RF (en-fr)SVM-RBF (en-fr)RF (en-es)SVM-RBF (en-es)(a) First order n-gram models0.30.350.40.450.50.550.60.65100 200 300 400 500 1000 2000 3000 4000translationaccuracy@ 20# second order features (x10^3)en-jpn en-el en-fr en-es(b) Second order n-gram modelFigure 2: Top-20 translation accuracy of models trained on (a) first and (b) second order featuresEnglish-French English-Spanish English-Greek English-Japaneseacc@1 acc@20 acc@1 acc@20 acc@1 acc@20 acc@1 acc@20LogReg 0.45 0.61 0.42 0.62 0.3 0.48 0.25 0.41RF 0.47 0.58 0.43 0.59 0.23 0.41 0.15 0.24SVM-RBF 0.38 0.51 0.33 0.53 0.1 0.25 0.06 0.16Table 3: Top-1 (acc@1) and top-20 (acc@20) translation accuracy of LogReg, RF and SVM-RBF0.10.20.30.40.50.60.70.80.9en-fr en-es%top-20translation accuracyLogRegRFSVM-RBFContextupper bound(a) Test terms with frequency [20, 200]0.10.20.30.40.50.60.70.80.9en-fr en-es%top-20translation accuracyLogRegRFSVM-RBFContextupper bound(b) Test terms with frequency [10, 20]Figure 3: Top-20 translation accuracy of terms in the frequency range of [10, 200] and [10, 20]French are 0.75 and 0.71, respectively.
In contrastto context vectors, the character n-gram methodsperformed comparably.A second factor that affects the performance ofcontext vectors, is the frequency of the terms tobe translated.
The translation of rare terms hasbeen shown to be a challenging case for contextvectors.
For example, Morin and Daille (2010)reported low accuracy (21% for the top-20 can-didates) of context vectors for terms occurring 20times or less.
In our experiments, Figure 3b illus-trates accuracies achieved for less frequent terms([10, 20]).
The performance of context vectors issignificantly lower, 26% for English-Spanish and21% for English-French.
Furthermore, the trans-lation accuracy of the n-gram methods decreasesslightly (?
5% to 8%).
This can be explainedby the decrease of the upper bound for lower fre-quency terms (?
3% to 6%).5.3 Combining internal and contextualsimilarityWe have hypothesised that the compositional andcontextual clue are orthogonal, i.e., they convey17080.1 0.20.3 0.40.5 0.60.7 0.80.9en-fr en-es en-el en-jpn%top-1 translation accuracyLogRegLogReg+ContextRFRF+ContextSVM-RBFSVM-RBF+ContextContextupper bound(a) Top-20 accuracy (acc@20)0.1 0.20.3 0.40.5 0.60.7 0.80.9en-fr en-es en-el en-jpn%top-1 translation accuracyLogRegLogReg+ContextRFRF+ContextSVM-RBFSVM-RBF+ContextContextupper bound(b) Top-1 accuracy (acc@1)Figure 4: Overall performance.
Top-20 and top-1 translation accuracydifferent and possibly complimentary information.To investigate this intuition, we evaluate the hybridmodel on all four comparable corpora, for term oc-currence frequencies in [20, 200].Figure 4a illustrates top-20 translation accu-racy scores for (a) the character n-gram models,(b) the context vector method and (c) the hy-brid models, i.e., LogReg+Context, RF+Context,SVM-RBF+Context.
We observe that the com-bination of the compositional and contextual clueimproved the performance of all methods.
The hy-brid model largely improved the performance ofthe SVM-RBF (?
14% to 20%).
With regardsto the combined signals the translation accuracyof LogReg and RF increased by ?
4% for theEnglish-Japanese corpus and ?
8% for all othercorpora.For the top 1 candidate translation, we observein Figure 4 smaller improvements achieved by thehybrid model in comparison to the top-20 accu-racy.
Interestingly, the RF classifier performedslightly better on its own for English-French,English-Spanish and English-Japanese.
This in-dicates that the hybrid method ranks more correcttranslations in the top 20 candidates but it does notalways assign the best score to the correct answer.6 Discusion and Future workIn this paper, we investigated a compositionaland a context-based approach useful for compil-ing bilingual dictionaries of terms automaticallyfrom comparable corpora.
Compositional transla-tion methods exploit the internal structure of termsacross languages while context-based approachesinvestigate the surrounding lexical context.We proposed a character n-gram composi-tional method, i.e., a Logistic Regression clas-sifier, which uses a multilingual representation,i.e., source and target terms.
Experimental evi-dence showed that the LogReg classifier signifi-cantly outperformed the baseline methods on dis-tant languages.
For closely related languages, Lo-gReg performed comparably to an existing n-grammethod based on a Random Forest classifier.Furthermore, we compared the n-gram modelsagainst a context-based approach under differentcorpus-specific parameters: (a) corpus compara-bility, which is relevant to the seed dictionary, and(b) the occurrence frequency of the terms to betranslated.
It was shown that the performance ofn-gram methods was not affected by different pa-rameter settings.
Only small fluctuations were ob-served, since the n-gram methods are based oncorpus-independent features, only.
In contrast,the context-based method was affected by corpuscomparability scores.
The corresponding transla-tion accuracy declined significantly for rare terms.Finally, we hypothesised that the n-gram andcontext-based methods provide complimentary in-formation.
To test this hypothesis, we developed ahybrid method that combines compositional andcontextual similarity scores as features in a lin-ear classifier.
The hybrid model achieved signif-icantly better top-20 translation accuracy than thetwo methods separately but minor improvementswere observed in terms of top-1 accuracy.As future work, we plan to improve the qual-ity of the extracted dictionary further by exploitingadditional translation signals.
For example, previ-ous works (Schafer and Yarowsky, 2002; Klemen-tiev et al., 2012) have reported that the temporaland topic similarity are clues that indicate transla-tion equivalence.
It would be interesting to investi-gate the contribution of different clues for various1709experimental parameters, e.g., domain, distance oflanguages, types of comparable corpora.AcknowledgementsThe authors would like to thank Dr. DanushkaBollegala for providing feedback on this paperand the three anonymous reviewers for their usefulcomments and suggestions.
This work was fundedby the European Community?s Seventh Frame-work Program (FP7/2007-2013) [grant number318736 (OSSMETER)].ReferencesDaniel Andrade, Tetsuya Nasukawa, and Jun?ichi Tsu-jii.
2010.
Robust measurement and comparison ofcontext similarity for finding translation pairs.
InProceedings of the 23rd International Conferenceon Computational Linguistics, pages 19?27.
Asso-ciation for Computational Linguistics.Marianna Apidianaki, Nikola Ljube?sic, and DarjaFi?ser.
2012.
Disambiguating vectors for bilin-gual lexicon extraction from comparable corpora.In Eighth Language Technologies Conference, pages10?15.Lisa Ballesteros and W.Bruce Croft.
1997.
Phrasaltranslation and query expansion techniques forcross-language information retrieval.
In ACM SIGIRForum, volume 31, pages 84?91.
ACM.Olivier Bodenreider.
2004.
The unified medical lan-guage system (umls): integrating biomedical termi-nology.
Nucleic acids research, 32(suppl 1):D267?D270.Leo Breiman.
2001.
Random Forests.
Machine Learn-ing, 45:5?32.Chih-Chung Chang and Chih-Jen Lin.
2011.
Lib-svm: a library for support vector machines.
ACMTransactions on Intelligent Systems and Technology(TIST), 2(3):27.Yun-Chuang Chiao and Pierre Zweigenbaum.
2002.Looking for Candidate Translational Equivalents inSpecialized, Comparable Corpora.
In InternationalConference on Computational Linguistics.Ido Dagan and Ken Church.
1994.
Termight: Identi-fying and translating technical terminology.
In Pro-ceedings of the fourth conference on Applied naturallanguage processing, pages 34?40.
Association forComputational Linguistics.Emmanuel Morin B?
?eatrice Daille.
2012.
Revising thecompositional method for terminology acquisitionfrom comparable corpora.
COLING 2012, 1810.Estelle Delpech, B?eatrice Daille, Emmanuel Morin,and Claire Lemaire.
2012.
Extraction of domain-specific bilingual lexicon from comparable corpora:Compositional translation and ranking.
In COLING,pages 745?762.Igakuyo Denshika and Jisho Kenkyukai.
1991.250,000 medical term dictionary (in japanese).Nichigai Associates, Inc.Ted Dunning.
1993.
Accurate methods for the statis-tics of surprise and coincidence.
Computational lin-guistics, 19(1):61?74.Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-Rui Wang, and Chih-Jen Lin.
2008.
Liblinear: Alibrary for large linear classification.
The Journal ofMachine Learning Research, 9:1871?1874.Pascale Fung and Kathleen McKeown.
1997.
Atechnical word-and term-translation aid using noisyparallel corpora across language groups.
MachineTranslation, 12(1-2):53?87.Pascale Fung and Lo Yuen Yee.
1998.
An ir approachfor translating new words from nonparallel, compa-rable texts.
In Proceedings of the 17th internationalconference on Computational linguistics-Volume 1,pages 414?420.
Association for Computational Lin-guistics.M.
Hall, E. Frank, G. Holmes, B. Pfahringer, P. Reute-mann, and I.H.
Witten.
2009.
The weka data miningsoftware: an update.
ACM SIGKDD ExplorationsNewsletter, 11(1):10?18.Z.S.
Harris.
1954.
Distributional structure.
Word.Trevor Hastie, Robert Tibshirani, Jerome Friedman,T Hastie, J Friedman, and R Tibshirani.
2009.
Theelements of statistical learning, volume 2.
Springer.Ann Irvine and Chris Callison-Burch.
2013.
Su-pervised bilingual lexicon induction with multiplemonolingual signals.
In Proceedings of NAACL-HLT, pages 518?523.Edward L Keenan and Leonard M Faltz.
1985.Boolean semantics for natural language, volume 23.Springer.Alexandre Klementiev, Ann Irvine, Chris Callison-Burch, and David Yarowsky.
2012.
Toward statisti-cal machine translation without parallel corpora.
InProceedings of the 13th Conference of the EuropeanChapter of the Association for Computational Lin-guistics, pages 130?140.
Association for Computa-tional Linguistics.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran,Richard Zens, et al.
2007.
Moses: Open sourcetoolkit for statistical machine translation.
In Pro-ceedings of the 45th Annual Meeting of the ACLon Interactive Poster and Demonstration Sessions,1710pages 177?180.
Association for Computational Lin-guistics.G.
Kontonatsios, I. Korkontzelos, J. Tsujii, and S. Ana-niadou.
2014.
Using a random forest classifierto compile bilingual dictionaries of technical termsfrom comparable corpora.
In Proceedings of the14th Conference of the European Chapter of the As-sociation for Computational Linguistics, volume 2:Short Papers, pages 111?116.
Association for Com-putational Linguistics.Sadao Kurohashi and Daisuke Kawahara.
2005.Japanese morphological analysis system juman ver-sion 5.1 manual.Bo Li and Eric Gaussier.
2010.
Improving corpuscomparability for bilingual lexicon extraction fromcomparable corpora.
In Proceedings of the 23rd In-ternational Conference on Computational Linguis-tics, pages 644?652.
Association for ComputationalLinguistics.Christian Lovis, R Baud, PA Michel, JR Scherrer, andAM Rassinoux.
1997.
Building medical dictionar-ies for patient encoding systems: A methodology.
InArtificial Intelligence in Medicine, pages 373?380.Springer.Emmanuel Morin and B?eatrice Daille.
2010.
Com-positionality and lexical alignment of multi-wordterms.
Language Resources and Evaluation, 44(1-2):79?95.Emmanuel Morin and Emmanuel Prochasson.
2011a.Bilingual lexicon extraction from comparable cor-pora enhanced with parallel corpora.
In Proceedingsof the 4th Workshop on Building and Using Compa-rable Corpora: Comparable Corpora and the Web,pages 27?34.
Association for Computational Lin-guistics.Emmanuel Morin and Emmanuel Prochasson.
2011b.Bilingual lexicon extraction from comparable cor-pora enhanced with parallel corpora.
In Proceedingsof the 4th Workshop on Building and Using Compa-rable Corpora: Comparable Corpora and the Web,pages 27?34, Portland, Oregon, June.
Associationfor Computational Linguistics.Emmanuel Morin, B?eatrice Daille, Koichi Takeuchi,and Kyo Kageura.
2007.
Bilingual terminologymining - using brain, not brawn comparable corpora.In Proceedings of the 45th Annual Meeting of the As-sociation of Computational Linguistics, pages 664?671, Prague, Czech Republic, June.
Association forComputational Linguistics.Fiammetta Namer and Robert Baud.
2007.
Defin-ing and relating biomedical terms: towards a cross-language morphosemantics-based system.
Interna-tional Journal of Medical Informatics, 76(2):226?233.Franz Josef Och and Hermann Ney.
2003.
A sys-tematic comparison of various statistical alignmentmodels.
Computational linguistics, 29(1):19?51.Harris Papageorgiou, Prokopis Prokopidis, VoulaGiouli, and Stelios Piperidis.
2000.
A unified postagging architecture and its application to greek.
InProceedings of the 2nd Language Resources andEvaluation Conference, pages 1455?1462, Athens,June.
European Language Resources Association.Emmanuel Prochasson and Pascale Fung.
2011.
Rareword translation extraction from aligned compara-ble documents.
In Proceedings of the 49th An-nual Meeting of the Association for ComputationalLinguistics: Human Language Technologies-Volume1, pages 1327?1335.
Association for ComputationalLinguistics.James Pustejovsky, Jose Castano, Brent Cochran, Ma-ciej Kotecki, and Michael Morrell.
2001.
Au-tomatic extraction of acronym-meaning pairs frommedline databases.
Studies in health technology andinformatics, (1):371?375.Reinhard Rapp.
1999.
Automatic identification ofword translations from unrelated english and germancorpora.
In Proceedings of the 37th annual meetingof the Association for Computational Linguistics onComputational Linguistics, pages 519?526.
Associ-ation for Computational Linguistics.Xavier Robitaille, Yasuhiro Sasaki, MasatsuguTonoike, Satoshi Sato, and Takehito Utsuro.
2006.Compiling french-japanese terminologies from theweb.
In EACL.Charles Schafer and David Yarowsky.
2002.
Inducingtranslation lexicons via diverse similarity measuresand bridge languages.
In proceedings of the 6th con-ference on Natural language learning-Volume 20,pages 1?7.
Association for Computational Linguis-tics.Helmut Schmid.
1994.
Probabilistic part-of-speechtagging using decision trees.
In Proceedings of theInternational Conference on New Methods in Lan-guage Processing, volume 12, pages 44?49.
Manch-ester, UK.Frank Smadja, Kathleen R McKeown, and VasileiosHatzivassiloglou.
1996.
Translating collocations forbilingual lexicons: A statistical approach.
Compu-tational linguistics, 22(1):1?38.Akihiro Tamura, Taro Watanabe, and Eiichiro Sumita.2012.
Bilingual lexicon extraction from compara-ble corpora using label propagation.
In Proceedingsof the 2012 Joint Conference on Empirical Methodsin Natural Language Processing and ComputationalNatural Language Learning, pages 24?36.
Associa-tion for Computational Linguistics.Takaaki Tanaka.
2002.
Measuring the similarity be-tween compound nouns in different languages us-ing non-parallel corpora.
In Proceedings of the19th international conference on Computationallinguistics-Volume 1, pages 1?7.
Association forComputational Linguistics.1711J?org Tiedemann.
2009.
News from opus-a collectionof multilingual parallel corpora with tools and in-terfaces.
In Recent Advances in Natural LanguageProcessing, volume 5, pages 237?248.Pim Van der Eijk.
1993.
Automating the acquisition ofbilingual terminology.
In Proceedings of the sixthconference on European chapter of the Associationfor Computational Linguistics, pages 113?119.
As-sociation for Computational Linguistics.Fabio Massimo Zanzotto, Ioannis Korkontzelos,Francesca Fallucchi, and Suresh Manandhar.
2010.Estimating linear models for compositional distribu-tional semantics.
In Proceedings of the 23rd Inter-national Conference on Computational Linguistics,COLING ?10, pages 1263?1271, Stroudsburg, PA,USA.
Association for Computational Linguistics.1712
