Proceedings of the 53rd Annual Meeting of the Association for Computational Linguisticsand the 7th International Joint Conference on Natural Language Processing, pages 1427?1437,Beijing, China, July 26-31, 2015.c?2015 Association for Computational LinguisticsTransferring Coreference Resolvers with Posterior RegularizationAndr?e F. T.
Martins??
?Priberam Labs, Alameda D. Afonso Henriques, 41, 2o, 1000-123 Lisboa, Portugal?Instituto de Telecomunicac?
?oes, Instituto Superior T?ecnico, 1049-001 Lisboa, Portugalatm@priberam.ptAbstractWe propose a cross-lingual frameworkfor learning coreference resolvers forresource-poor target languages, given a re-solver in a source language.
Our methoduses word-aligned bitext to project infor-mation from the source to the target.
Tohandle task-specific costs, we propose asoftmax-margin variant of posterior regu-larization, and we use it to achieve robust-ness to projection errors.
We show empir-ically that this strategy outperforms com-petitive cross-lingual methods, such asdelexicalized transfer with bilingual wordembeddings, bitext direct projection, andvanilla posterior regularization.1 IntroductionThe goal of coreference resolution is to find thementions in text that refer to the same discourseentity.
While early work focused primarily on En-glish (Soon et al, 2001; Ng and Cardie, 2002),efforts have been made toward multilingual sys-tems, this being addressed in recent shared tasks(Recasens et al, 2010; Pradhan et al, 2012).
How-ever, the lack of annotated data hinders rapid sys-tem deployment for new languages.
Unsupervisedmethods (Haghighi and Klein, 2007; Ng, 2008)and rule-based approaches (Raghunathan et al,2010) avoid this data annotation bottleneck, butthey often require complex generative models orexpert linguistic knowledge.We propose cross-lingual coreference resolu-tion as a way of transferring information froma rich-resource language to build coreference re-solvers for languages with scarcer resources; as atestbed, we transfer from English to Spanish andto Brazilian Portuguese.
We build upon the recentsuccesses of cross-lingual learning in NLP, whichproved quite effective in several structured predic-tion tasks, such as POS tagging (T?ackstr?om et al,2013), named entity recognition (Wang and Man-ning, 2014), dependency parsing (McDonald etal., 2011), semantic role labeling (Titov and Kle-mentiev, 2012), and fine-grained opinion mining(Almeida et al, 2015).
The potential of these tech-niques, however, has never been fully exploitedin coreference resolution (despite some existingwork, reviewed in ?6, but none resulting in an end-to-end coreference resolver).We bridge this gap by proposing a simplelearning-based method with weak supervision,based on posterior regularization (Ganchev etal., 2010).
We adapt this framework to handlesoftmax-margin objective functions (Gimpel andSmith, 2010), leading to softmax-margin poste-rior regularization (?4).
This step, while fairlysimple, opens the door for incorporating task-specific cost functions, which are important tomanage the precision/recall trade-offs in corefer-ence resolution systems.
We show that the result-ing problem involves optimizing the difference oftwo cost-augmented log-partition functions, mak-ing a bridge with supervised systems based on la-tent coreference trees (Fernandes et al, 2012;Durrett and Klein, 2013), reviewed in ?3.
In-spired by this idea, we consider a simple penal-ized variant of posterior regularization that tunesthe Lagrange multipliers directly, bypassing thesaddle-point problem of existing EM and alternat-ing stochastic gradient algorithms (Ganchev et al,2010; Liang et al, 2009).
Experiments (?5) showthat the proposed method outperforms commonlyused cross-lingual approaches, such as delexical-ized transfer with bilingual embeddings, directprojection, and ?vanilla?
posterior regularization.2 Architecture and Experimental SetupOur methodology, outlined as Algorithm 1, is in-spired by the recent work of Ganchev and Das(2013) on cross-lingual learning of sequence mod-els.
For simplicity, we call the source and tar-1427Figure 1: Excerpt of a bitext document with automatic coreference annotations (from FAPESP).
The English side had itscoreferences resolved by a state-of-the-art system (Durrett and Klein, 2013).
The predicted coreference chains {The pulmonaryalveoli, the alveoli, their} and {The pulmonary surfactant} are then projected to the Portuguese side, via word alignments.Algorithm 1 Cross-Lingual Coreference Resolution viaSoftmax-Margin Posterior RegularizationInput: Source coreference system Se, parallel data DeandDf, posterior constraintsQ.Output: Target coreference system Sf.1: De?f?
RUNWORDALIGNER(De,Df)2: D?e?
RUNCOREF(Se,De)3: D?f?
PROJECTANDFILTERENTITIES(De?f, D?e)4: Sf?
LEARNCOREFWITHSOFTMARGPR(D?f,Q)get languages English (e) and ?foreign?
(f ), re-spectively, and we assume the existence of paralleldocuments on the two languages (bitext).The first two steps (lines 1?2) run a word alignerand label the source side of the parallel data witha pre-trained English coreference system.
After-wards, the predicted English entities are projectedto the target side of the parallel data (line 3), in-ducing an automatic (and noisy) training datasetfor the foreign language.
Finally, a coreferencesystem is trained in this dataset with the aid ofsoftmax-margin posterior regularization (line 4).We next detail all the datasets and tools involvedin our experimental setup.
Table 1 provides a sum-mary, along with some statistics.Parallel Data.
As parallel data, we use asentence-aligned trilingual (English-Portuguese-Spanish) parallel corpus based on the scien-tific news Brazilian magazine Revista PesquisaFAPESP, collected by Aziz and Specia (2011).1We preprocessed this dataset as follows.
We la-beled the English side with the Berkeley Corefer-ence Resolution system v1.0, using the providedEnglish model (Durrett and Klein, 2013).
Then,we computed word alignments using the Berke-ley aligner (Liang et al, 2006), intersected themand filtered out all the alignments whose confi-1We found that other commonly used parallel data (suchas Europarl or the UN corpus) have a predominance of directspeech that is not suitable for our newswire test domain, sowe decided not to use these data.Dataset # Doc.
# Sent.
# Tok.EN OntoNotes (train) 2,374 48,762 1,007,359EN OntoNotes (dev) 303 6,894 136,257EN OntoNotes (test) 322 8,262 152,728ES FAPESP (aligned) 2,704 142,633 3,840,936ES AnCora (train) 875 8,999 295,276ES AnCora (dev) 140 1,417 46,167ES AnCora (test) 168 1,704 53,042PT FAPESP (aligned) 2,823 166,719 4,538,147PT Summ-It (train) 30 469 11,771PT Summ-It (dev) 7 111 2,983PT Summ-It (test) 13 257 6,491Table 1: Corpus statistics.
EN, ES, and PT denote English,Spanish, and Portuguese, respectively.dence is below 0.95.
After this, we projected En-glish mentions to the target side using the maxi-mal span heuristic of Yarowsky et al (2001).
Wefiltered out documents where more than 15% ofthe mentions were not aligned.
At this point, weobtained an automatically annotated corpus?Dfin the target language.
Figure 1 shows a smallexcerpt where all mentions were correctly pro-jected.
In practice, not all documents are so wellbehaved: in the English-Portuguese parallel data,only 200,175 out of the original 271,122 mentions(about 73.8%) were conserved after the projectionstep.
In Spanish, this number drops to 69.9%.Monolingual Data.
We also use monolingualdata for validation and comparison with super-vised systems.
The Berkeley Coreference Reso-lution system is trained in the English OntoNotesdataset used in the CoNLL 2011 shared task; thisdataset is also used to train delexicalized models.For Spanish, we use the AnCora dataset (Re-casens and Mart?
?, 2010) provided in the SemEval2010 coreference task, which we preprocessed asfollows.
We split all MWEs into individual tokens(for consistency with the other corpora).
We alsoremoved the extra gap tokens associated with zero-anaphoric relations, and the anaphoric annotationsassociated with relative pronouns (e.g., in ?
[unacentral de ciclo combinado [que]1debe empezar1428a funcionar en mayo del 2002]1?
we removed thenested mention [que]1), since these are not anno-tated in the English dataset.For Portuguese, we used the Summ-It 3.0 cor-pus (Collovini et al, 2007), which contains 50documents annotated with coreferences, from thescience section of the Folha de S?ao Paulo newspa-per.
This dataset is much smaller than OntoNotesand AnCora, as shown in Table 1.
We split thedata into train, development, and test partitions.For both Spanish and Portuguese, we obtainedautomatic POS tags and dependency parses by us-ing TurboParser (Martins et al, 2013).3 Coreference Resolution3.1 Problem Definition and Prior WorkIn coreference resolution, we are given a set ofmentions M := {m1, .
.
.
,mM}, and the goalis to cluster them into discourse entities, E :={e1, .
.
.
, eE}, where each ej?
M and ej6= ?.The set E must form a partition ofM, i.e., we musthave?Ej=1ej=M, and ei?
ej= ?
for i 6= j.A variety of approaches have been proposedto this problem, including entity-centric models(Haghighi and Klein, 2010; Rahman and Ng,2011; Durrett et al, 2013), pairwise models(Bengtson and Roth, 2008; Versley et al, 2008),greedy rule-based methods (Raghunathan et al,2010), and mention-ranking decoders (Denis andBaldridge, 2008; Durrett and Klein, 2013).
Wechose to base our coreference resolvers on this lastclass of methods, which permit efficient decodingby shifting from entity clusters to latent corefer-ence trees.
In particular, the inclusion of lexical-ized features by Durrett and Klein (2013) yieldsnearly state-of-the-art performance with surfaceinformation only.
Given that our goal is to pro-totype resolvers for resource-poor languages, thismodel is a good fit?we next describe it in detail.3.2 Latent Coreference Tree ModelsLet x be a document containing M mentions,sorted from left to right.
We associate to the mthmention a random variable ym?
{0, 1, .
.
.
,m?1}to denote its antecedent, where the value ym= 0means that m is a singleton or starts a new coref-erence chain.
We denote by Y(x) the set of coref-erence trees that can be formed by linking men-tions to their antecedents; we represent each treeas a vector y := ?y1, .
.
.
, yM?.
Note that eachtree y induces a unique clustering E , but that thismap is many-to-one, i.e., different trees may corre-spond to the same set of entity clusters.
We denoteby Y(E) the set of trees that are consistent with agiven clustering E .We model the probability distribution p(y|x) asan arc-factored log-linear model:pw(y|x) ?
exp(?Mm=1w>f(x,m, ym)), (1)where w is a weight vector, and each f(x,m, ym)is a local feature vector that depends on thedocument x, the mention m, and its candi-date antecedent ym.
This model permits acheap computation of the most likely tree y?
:=argmaxy?Y(x)pw(y|x): simply compute the bestantecedent independently for each mention, andcollect them to form a tree.
An analogous pro-cedure can be employed to compute the posteriormarginals pw(ym|x) for every mention m.Gold coreference tree annotations are rarelyavailable; datasets usually consist of documentsannotated with entity clusters, {?x(n), E(n)?
}Nn=1.Durrett and Klein (2013) proposed to learn theprobabilistic model in Eq.
1 by maximizing condi-tional log-likelihood, treating the coreference treesas latent variables.
They also found advantageousto incorporate a cost function `(y,Y(E)), measur-ing the extent to which a prediction y differs fromthe ones that are consistent with the gold entity setE .2Putting these pieces together, we arrive at thefollowing loss function to be minimized:L(w) = ?
?Nn=1log(?y?Y(E(n))p?w(y|x(n))),(2)where p?w is the cost-augmented distribution:p?w(y|x) ?
pw(y|x)e`(y,Y(E)).
(3)The loss function in Eq.
2 can be seen as a prob-abilistic analogous of the hinge loss of supportvector machines, and a model trained this wayis called a softmax-margin CRF (Gimpel andSmith, 2010).
Note that L(w) is non-convex, cor-responding to the difference of two log-partitionfunctions (both convex on w),L(w) =?Nn=1(logZ?
(w, x(n))?
log?Z(w, x(n)));(4)above we denotedZ?
(w, x) =?y?Y(x)ew>f(x,y)+`(y,Y(E))(5)?Z(w, x) =?y?Y(E)ew>f(x,y), (6)2A precise definition of this cost is provided in ?4.3.1429where f(x, y) :=?Mm=1f(x,m, ym).3Evaluat-ing the gradient of the loss in Eq.
4 requires com-puting marginals for the candidate antecedents ofeach mention, which can be done in a mention-synchronous fashion.
This enables a simplestochastic gradient descent algorithm, which wasthe procedure taken by Durrett and Klein (2013).Another way of regarding this framework, ex-pressed through the marginalization in Eq.
2, is to?pretend?
that the outputs we care about are theactual coreference trees, but that the datasets areonly ?weakly labeled?
with the entity clusters.
Webuild on this point of view in ?4.1.4 Cross-Lingual Coreference ResolutionWe now adapt the framework above to learn coref-erence resolvers in a cross-lingual manner.4.1 Softmax-Margin Posterior RegularizationIn the weakly supervised case, the training datamay only be partially labeled or contain annota-tion errors.
For taking advantage of these data, weneed a procedure that handles uncertainty aboutthe missing data, and is robust to mislabelings.
Wedescribe next an approach based on posterior reg-ularization (PR) that fulfills these requirements.For ease of explanation, we introduce corpus-level counterparts for the variables in ?3.2.
Weuse bold capital letters X := {x(1), .
.
.
, x(N)} andY := {y(1), .
.
.
, y(N)} to denote the documentsand candidate coreference trees in our corpus.
Wedenote by pw(Y|X) :=?Nn=1pw(y|x(n)) theconditional distribution of trees over the corpus,induced by a model w, and similarly for the cost-augmented distribution p?w(Y|X).In PR, we define a vector g(X,Y) of corpus-level constraint features, and a vector b of upperbounds for those features.
We consider the familyof distributions over Y (call itQ) that satisfy theseconstraints in a posteriori expectation,Q := {q | Eq[g(X,Y)] ?
b}.
(7)To make the analysis simpler, we assume that 0 ?b ?
1, and that for every j, minYgj(X,Y) = 0and maxYgj(X,Y) = 1, where the min/maxabove are over all possible coreference trees Ythat can be build from the documents X in the cor-3Note that the scope of the sum is different in Eqs.
5 and 6:Z?
(w, x) sums over all coreference trees, while Z?
(w, x)sums only over those consistent with the gold clusters.pus.4Under this assumption, the two extreme val-ues of the upper bounds have a precise meaning: ifbj= 0, the jth feature becomes a hard constraint,(i.e., any feasible distribution inQwill vanish out-side {Y | gj(X,Y) = 0}), while bj= 1 turns itinto a vacuous feature.We also make the usual assumption that theconstraint features decompose over documents,g(X,Y) :=?Nn=1g(x(n), y(n)); if this were notthe case, decoding would be much harder, as thedocuments would be coupled.In vanilla PR (Ganchev et al, 2010), one seeksthe model w minimizing the Kullback-Leibler di-vergence between the set Q and the distributionpw.
Here, we go one step farther to consider thecost-augmented distribution in Eq.
3.
That is, weminimize KL(Q||p?w) := minq?QKL(q?p?w).The next proposition shows that this expressionalso corresponds to a difference of two log-partition functions, as in Eq.
4.Proposition 1.
The (regularized) minimization ofthe cost-augmented KL divergence is equivalent tothe following saddle-point problem:minwKL(Q?p?w) +?2?w?2= (8)minw maxu?0 F (w,u)?
b>u+?2?w?2,where F (w,u) :=?Nn=1(logZ?
(w, x(n))?
logZ?u(w, x(n))),(9)with Z?
(w, x) as in Eq.
5, andZ?u(w, x) :=?y?Y(x)ew>f(x,y)+`(y,Y(E))?u>g(x,y).(10)Proof.
See Appendix A.In sum, what Proposition 1 shows is that wecan easily extend the vanilla PR framework ofGanchev et al (2010) to incorporate a task-specificcost: by Lagrange duality, the resulting optimiza-tion problem still amounts to finding a saddlepoint of an objective function (Eq.
8), which in-volves the difference of two log-partition func-tions (Eq.
9).
The difference is that these par-tition functions now incorporate the cost term`(y,Y(E)).
If this cost term has a factorizationcompatible with the features and the constraints,this comes at no additional computational burden.4We can always reduce the problem to this case by scalingand adding a constant to the constraint feature vectors.14304.2 Penalized VariantIn their discriminative PR formulation for learningsequence models, Ganchev and Das (2013) opti-mize an objective similar to Eq.
8 by alternatingstochastic gradient updates with respect to w andu.
In their procedure, b was chosen a priori vialinear regression (see their Figure 2).Here, we propose a different strategy, based onProposition 1 and a simple observation: while theconstraint values b have a more intuitive meaningthan the Lagrange multipliers u (since they maycorrespond, e.g., to proportions of events observedin the data), choosing these upper bounds is oftenno easier than tuning u.
In this case, a preferablestrategy is to specify u directly?this leaves thisvariable fixed in Eq.
8, and allows us to get rid ofb.
The resulting problem becomesminw F (w,u) +?2?w?2, (11)which is a penalized variant of PR and no longer asaddle point problem.
This variant requires tuningthe Lagrange multipliers ujin the range [0,+?
],for every constraint.
The two extreme cases ofbj= 0 and bj= 1 correspond respectively touj= +?
and uj= 0.5Note that this grid searchis only appealing for a small number of posteriorconstraints at corpus-level (since document-levelconstraints would require tuning separate coeffi-cients for each document).The practical advantages of the penalized vari-ant over the saddle-point formulation are illus-trated in Figure 2, which compares the perfor-mance of stochastic gradient algorithms for thetwo formulations (there, ?2= 1?
b2).An interesting aspect of this penalized formula-tion is its resemblance to latent variable models.Indeed, the objective of Eq.
11 is also a differ-ence of log-partition functions, as the latent-treesupervised case (cf.
Eq.
4).
The noticeable differ-ence is that now both partition functions includeextra cost terms, either task-specific (`(y,Y(E))in Z?)
or with soft constraints (u>g(x, y) in Z?u).In particular, if we set a single constrained featureg1(x, y) := I(`(y,Y(E)) 6= 0) with weight u1?+?, all non-zero-cost summands in Z?u(w, x)5This follows from Lagrange duality.
If bj= 1, theconstraint is vacuous and by complementary slackness wemust have uj= 0.
If bj= 0, this becomes a hard con-straint, so for the nth document, any coreference tree y forwhich gj(x(n), y) 6= 0 must have probability zero?this cor-responds to setting uj?
+?
in Eq.
10.Figure 2: Comparison of saddle-point and penalized PR forSpanish, using the setup in ?5.5.
Left: variation of the mul-tiplier u2over gradient iterations, with strong oscillations ininitial epochs and somewhat slow convergence.
Right: im-pact in the averaged F1scores (on the dev-set).
Contrast withthe more ?stable?
scores achieved by the penalized method.vanish and we get Z?u(w, x) =?Z(w, x), recov-ering the supervised case (see Eq.
6).Intuitively, this formulation pushes probabilitymass toward structures that respect the constraintsin Eq.
7, while moving away from those that have alarge task-specific cost.
A similar idea, but appliedto the generative case, underlies the framework ofconstrastive estimation (Smith and Eisner, 2005).4.3 Cost FunctionDenote by Emthe entire coreference chain of themth mention (so E =?m?M{Em}), and byMsing:= {m ?M | Em= {m}} the set of men-tions that are projected as singleton in the data (wecall this gold-singleton mentions).We design a task-specific cost `(y?,Y(E)) asin Durrett and Klein (2013) to balance threekinds of mistakes: (i) false anaphora (y?m6=0 while m ?
Msing); (ii) false new (y?m=0 while m /?
Msing); and (iii) wrong link(y?m6= 0 but Em6= Ey?m).
Letting IFA(y?m, E),IFN(y?m, E), and IWL(y?m, E) be indicators forthese events, we define a weighted Hamming costfunction: `(y?,Y(E)) :=?Mm=1(?FAIFA(y?m, E)+?FNIFN(y?m, E) + ?WLIWL(y?m, E)).
We set?FA= 0.0, ?FN= 3.0, and ?WL= 1.0.6Sincethis cost decomposes as a sum over mentions, thecomputation of cost-augmented marginals (neces-sary to evaluate the gradient of Eq.
11) can still bedone with mention-ranking decoders.4.4 Constraint FeaturesFinally, we describe the constraint features (Eq.
7)used in our softmax-margin PR formulation.Constraint #1: Clusters should not split.
Let|M| ?
|E| be the number of anaphoric mentions6The only difference with respect to Durrett and Klein(2013) is that they set ?FA= 0.1.
We set this coefficientto zero so that all configurations licensed by the constraintfeatures (to be made precise in ?4.4) will have zero cost.1431in the projected data.
We push these mentions topreserve their anaphoricity (ym6= 0) and to havetheir antecedent in the projected coreference chain(Em= Eym).
To do so, we force the fraction ofmentions satisfying these properties to be at least?1.
This can be enforced via a constraint featureg1(X,Y) := (12)?
?Nn=1?M(n)m=1I(y(n)m6= 0 ?
E(n)m= E(n)ym),and an upper bound b1:= ?
?1?Nn=1(|M(n)| ?|E(n)|).
(These quantities are summed by a con-stant and rescaled to meet the assumption in ?4.1.
)In our experiments, we set ?1= 1.0, turning thisinto a hard constraint.
This is equivalent to settingu1= +?
in the penalized formulation.Constraint #2: Most projected singletonsshould become non-anaphoric.
We define asoft constraint so that a large fraction of the gold-singleton mentions m ?
Msingsatisfy ym= 0.This can be done via a constraint featureg2(X,Y) := (13)?
?Nn=1?M(n)m=1I(y(n)m= 0 ?
E(n)m= {m}),and an upper bound b2:= ??2?Nn=1|M(n)sing|.
Inour experiments, we varied ?2in the range [0, 1],either directly or via the dual variable u2, as de-scribed in ?4.1.
The extreme case ?2= 0 corre-sponds to a vacuous constraint, while for ?2= 1this becomes a hard constraint which, combinedwith the previous constraint, recovers bitext directprojection (see ?5.3).
The intermediate case makesthis a soft constraint which allows some single-tons to be attached to existing entities (thereforeintroducing some robustness to non-aligned men-tions), but penalizes the number of reattachments.5 ExperimentsWe now present experiments using the setup in?2.
We compare our coreference resolvers trainedwith softmax-margin PR (?5.5) with three otherweakly-supervised baselines: delexicalized trans-fer with cross-lingual embeddings (?5.2), bitextprojection (?5.3), and vanilla PR (?5.4).
We alsorun fully supervised systems (?5.1), to obtain up-per bounds for the level of performance we expectto achieve with the weakly-supervised systems.An important step in coreference resolution sys-tems is mention prediction.
For English, mentionspans were predicted from the noun phrases givenby the Berkeley parser (Petrov and Klein, 2007),the same procedure as Durrett and Klein (2013).For Spanish and Portuguese, this prediction reliedon the output of the dependency parser, using asimple heuristic: besides pronouns, each maximalspan formed by contiguous descendants of a nounbecomes a candidate mention.
This heuristic isquite effective, as shown by Attardi et al (2010).5.1 Supervised SystemsTable 2 shows the performance of supervised sys-tems for English, Spanish and Portuguese.
All op-timize Eq.
4 appended with an extra regularizationterm?2?w?2, by running 20 epochs of stochasticgradient descent (SGD; we set ?
= 1.0 and se-lected the best epoch using the dev-set).
All lexi-calized systems use the same features as the SUR-FACE model of Durrett and Klein (2013), plus fea-tures for gender and number.7We collected a listof pronouns for all languages along with their gen-der, number, and person information.
For English,we trained on the WSJ portion of the OntoNotesdataset, and for Spanish and Portuguese we trainedon the monolingual datasets described in ?2.We observe that the Spanish system obtains av-eraged F1scores around 44%, a few points belowthe English figures.8In Portuguese, these scoresare significantly lower (in the 37?39% range),which is explained by the fact that the trainingdataset is much smaller (cf.
Table 1).For English, we also report the performance ofdelexicalized systems, i.e., systems where all thelexical features were removed.
The second rowof Table 2 shows a drop of 2?2.5 points with re-spect to the lexicalized system.
For the third andfourth rows, the lexical features were replacedby bilingual word embeddings (either English-Spanish or English-Portuguese; a detailed descrip-tion of these embeddings will be provided in ?5.2).Here the drop is small, and for English-Spanish itlooks on par with the lexicalized system.7For English, the gender and number of nominal andproper mentions were obtained from the statistics collectedby Bergsma and Lin (2006).
For Spanish and Portuguese weused a simple heuristic for nominal mentions, based on thedeterminer preceding the noun (when there is one).8We point out that the supervised Spanish system wepresent here is strong enough to outperform all participatingsystems in the SemEval 2010?s closed regular track.
Whentrained on the original Spanish SemEval data (with zero- andrelative pronoun anaphoras) and evaluated in the providedscorer, it achieves 53.0% averaged F1in the test partition; forcomparison, TALN-1 (Attardi et al, 2010), the best system atthe shared task, achieved 49.6% averaged F1.1432Dev TestMUC B3CEAFeAvg.
MUC B3CEAFeAvg.EN lexicalized 58.35 50.75 52.08 53.73 59.07 49.25 48.78 52.37EN delexicalized, no embed.
56.59 48.81 49.95 51.78 55.96 46.94 46.19 49.70EN delexicalized, emb.
EN-ES 57.55 49.83 51.21 52.86 59.00 49.25 49.00 52.42EN delexicalized, emb.
EN-PT 57.91 49.67 51.01 52.86 58.03 48.16 48.33 51.51ES lexicalized 48.24 40.97 43.59 44.27 47.03 40.68 44.09 43.93PT lexicalized 35.60 34.47 42.56 37.54 41.61 36.91 40.96 39.83Table 2: Results for the supervised systems.
We show also the performance of delexicalized English systems, with and withoutcross-lingual embeddings.
Shown are MUC (Vilain et al, 1995), B3(Bagga and Baldwin, 1998), and CEAFe(Luo, 2005), aswell their averaged F1scores, all computed using the reference implementation of the CoNLL scorer (Pradhan et al, 2014).Dev TestMUC B3CEAFeAvg.
MUC B3CEAFeAvg.ES simple baseline 25.73 24.73 27.89 26.12 26.06 26.12 29.87 27.35ES baseline #1 (delex.
transfer) 33.04 27.47 32.71 31.07 34.35 28.69 34.42 32.49ES baseline #2 (bitext dir.
proj.)
39.42 30.04 38.25 35.90 37.21 29.72 35.97 34.30ES baseline #3 (vanilla PR) 41.29 33.68 38.56 37.84 39.34 32.95 38.23 36.84ES softmax-margin PR 42.34 35.53 39.95 39.27 41.22 35.30 39.94 38.82PT simple baseline 26.04 26.67 33.19 28.63 22.72 23.91 27.35 24.66PT baseline #1 (delex.
transfer) 22.51 23.27 33.27 26.35 31.11 27.36 32.78 30.42PT baseline #2 (bitext dir.
proj.)
30.43 27.37 36.47 31.42 31.93 27.97 35.40 31.77PT baseline #3 (vanilla PR) 30.97 27.82 35.14 31.31 38.39 33.34 38.73 36.82PT softmax-margin PR 33.43 31.00 38.82 34.42 38.18 34.05 39.47 37.23Table 3: Results for all the cross-lingual systems.
Bold indicates the overall highest scores.
As a lower bound, we show a simpledeterministic baseline that, for pronominal mentions, selects the closest non-pronominal antecedent, and, for non-pronominalmentions, selects the closest non-pronominal mention that is a superstring of the current mention.5.2 Baseline #1: Delexicalized Transfer WithCross-Lingual EmbeddingsWe now turn to the cross-lingual systems.
Delex-icalized transfer is a popular strategy in NLP (Ze-man and Resnik, 2008; McDonald et al, 2011),recently strengthened with cross-lingual word rep-resentations (T?ackstr?om et al, 2012).
The proce-dure works as follows: a delexicalized model forthe source language is trained by eliminating allthe language-specific features (such as lexical fea-tures); then, this model is used directly in the tar-get language.
We report here the performance ofthis baseline on coreference resolution for Span-ish and Portuguese, using the delexicalized modelstrained on the English data as mentioned in ?5.1.To achieve a unified feature representation, wemapped all language-specific POS tags to univer-sal tags (Petrov et al, 2012).
All lexical featureswere replaced either by cross-lingual word em-beddings (for words that are not pronouns); or bya universal representation containing the gender,number, and person information of the pronoun.To obtain the cross-lingual word embeddings, weran the method described by Hermann and Blun-som (2014) for the English-Spanish and English-Portuguese pairs, using the parallel sentences in?2.
When used as features, these 128-dimensionalcontinuous representations were scaled by a factorof 0.5 (selected on the dev-set), using the proce-dure of Turian et al (2010).The second and seventh rows in Table 3 showthe performance of this baseline, which is ratherdisappointing.
For Spanish, we observe a largedrop in performance when going from supervisedtraining to delexicalized transfer (about 11?13%in averaged F1).
For Portuguese, where the super-vised system is not so accurate, the difference isless sharp (about 9?11%).
These drops are mainlydue to the fact that this method does not take intoaccount the intricacies of each language?e.g.,possessive forms have different agreement rules inEnglish and in Romance languages;9those, on theother hand, have clitic pronouns that are absent inEnglish.
Feature weights that promote certain En-glish agreement relations may then harm perfor-mance more than they help.5.3 Baseline #2: Bitext Direct ProjectionAnother popular strategy for cross-lingual learn-ing is bitext direct projection, which consists inprojecting annotations through parallel data inthe source and target languages (Yarowsky et al,2001; Hwa et al, 2005).
This is essentially thesame as Algorithm 1, except that line 4 is replacedby simple supervised learning, via a minimization9For example, in Figure 1, their agrees in number withthe possessor (the alveoli), but the corresponding sua agreesin number and gender with the thing possessed (func?
?ao).1433of the loss function in Eq.
4 with `2-regularization.This procedure has the disadvantage of being verysensitive to annotation errors, as we shall see.
ForPortuguese, this baseline is a near-reproduction ofSouza and Or?asan (2011)?s work, discussed in ?6.The third and eighth rows in Table 3 showthat this baseline is stronger than the delexicalizedbaseline, but still 6?8 points away from the super-vised systems.
This gap is due to a mix of twofactors: prediction errors in the English side ofthe bitext, and missing alignments.
Indeed, whenautomatic alignments are used, false negatives forcoreferent pairs of mentions are common, due towords that have not been aligned with sufficientlyhigh confidence.
The direct projection method isnot robust to these annotation errors.5.4 Baseline #3: Vanilla PROur last baseline is a vanilla PR approach; thisis an adaptation of the procedure carried out byGanchev and Das (2013) to our coreference reso-lution problem.
The motivation is to increase therobustness of bitext projection to annotation er-rors, which we do by applying the soft constraintsin ?4.4.
We seek a saddle-point of the PR objec-tive by running 20 epochs of SGD, alternating w-updates and u-updates.
The best results in the dev-set were obtained with ?1= 1.0 and ?2= 0.9.By looking at the fourth and ninth rows of Ta-ble 3, we observe that vanilla PR manages to re-duce the gap to supervised systems, obtaining con-sistent gains over the bitext projection baseline(with the exception of the Portuguese dev-set).This confirms the ability of PR methods to handleannotation mistakes in a robust manner.5.5 Our Proposal: Softmax-Margin PRFinally, the fifth and last rows in Table 3 show theperformance of our systems trained with softmax-margin PR, as described in ?4.1.
We optimized theloss function in Eq.
11 with ?
= 1.0 by running 20epochs of SGD, setting u1= +?
and u2= 1.0(cf.
?4.4)?the last value was tuned in the dev-set.As shown in Figure 2, this penalized variant wasmore effective than the saddle point formulation.From Table 3, we observe that softmax-marginPR consistently beats all the baselines, narrow-ing the gap with respect to supervised systems toabout 5 points for Spanish, and 2?3 points for Por-tuguese.
Gains over the vanilla PR procedure (thestrongest baseline) lie in the range 0.5?3%.
Thesegains come from the ability of softmax-margin PRto handle task-specific cost functions, enabling abetter management of precision/recall tradeoffs.5.6 Error AnalysisWe carried out some error analysis, focused onthe Spanish development dataset, to better under-stand where the improvements of softmax-marginPR come from.
The main conclusions carry out tothe Portuguese case, with a few exceptions, mostlydue to different human annotation criteria.Table 4 shows the precision and recall scoresfor mention prediction and the different corefer-ence evaluation metrics.
Note that all systems pre-dict the same candidate mentions; however a finalpost-processing discards all mentions that endedup in singleton entities, for compliance with theofficial scorer.
Therefore, the mention predictionscore reflects how well a system does in predictingif a mention is anaphoric or not.
The first thing tonote is that the PR methods, due to their abilityto create new links during training (via constraint#2) tend to predict fewer singletons than the directprojection method.
Indeed, we observe that softmax-margin PR achieves 47.1% mention predic-tion recall, which is more than 5% above the di-rect projection method, and 10% above the delex-icalized transfer method.
Note also that, whilethe vanilla PR method achieves higher recall thanthe two other baselines, it is still almost 5% be-low the system trained with soft-max margin PR.This is because vanilla PR does not benefit fromthe cost function in ?4.3?such cost is able to pe-nalize false non-anaphoric mentions and encour-age larger clusters, allowing softmax-margin PRto achieve a better precision-recall trade-off.
FromTable 4, we can see that this improvement in men-tion recall consistently translates into higher recallfor the MUC, B3and CEAFecoreference metrics.Further analysis revealed that a major source oferror for the delexicalized baseline is its inabil-ity to handle pronominal mentions robustly acrosslanguages?as hinted in footnote 9.
In practice,we found the delexicalized systems to be quiteconservative with possessive pronouns: for theSpanish dataset, where the vast majority of pos-sessive pronouns are anaphoric, the delexicalizedmodel incorrectly predicts 53.3% of these pro-nouns as non-anaphoric.
The direct projectionmodel is slightly less conservative, missing 30.1%of the possessives (arguably due to its inability torecover missing links in the projected data, dur-1434Mention MUC B3CEAFedelex.
37.1 / 62.2 25.6 / 46.5 19.6 / 45.7 27.9 / 39.5dir.
proj.
41.7 / 77.5 29.3 / 60.4 19.2 / 69.5 31.8 / 47.9vanilla PR 42.2 / 78.0 30.9 / 62.3 23.2 / 61.7 31.9 / 48.8our PR 47.1 / 74.1 33.7 / 57.1 26.0 / 56.1 34.9 / 46.7Table 4: Recall/precision scores for mention prediction,MUC, B3and CEAFe, all computed in the Spanish dev set.ing training).
By comparison, the vanilla and soft-max margin PR models only miss 4.9% and 3.4%of the possessives, respectively.
In Portuguese,where many possessives are not annotated in thegold data, we observe a similar but much less pro-nounced trend.6 Related WorkWhile multilingual coreference resolution hasbeen the subject of recent SemEval and CoNLLshared tasks, no submitted system attemptedcross-lingual training.
As shown by Recasens andHovy (2010), language-specific issues pose a chal-lenge, due to phenomena as pronoun dropping andgrammatical gender that are absent in English butexist in other languages.
We have discussed someof these issues in the scope of the present work.Harabagiu and Maiorano (2000) and Postolacheet al (2006) projected English corpora to Roma-nian to bootstrap human annotation, either manu-ally or via automatic alignments.
Rahman and Ng(2012) applied translation-based projection at testtime (but require an external translation service).Hardmeier et al (2013) addressed the related taskof cross-lingual pronoun prediction.
While allthese approaches help alleviate the corpus annota-tion bottleneck, none resulted in a full coreferenceresolver, which our work accomplished.The work most related with ours is Souza andOr?asan (2011), who also used parallel data totransfer an English coreference resolver to Por-tuguese, but could not beat a simple baseline thatclusters together mentions with the same head.Their approach is similar to our bitext direct pro-jection baseline, except that they used Reconcile(Stoyanov et al, 2010) instead of the BerkeleyCoreference System, and a smaller version of theFAPESP corpus.
We have shown that our softmax-margin PR procedure is superior to this approach.Discriminative PR has been proposed byGanchev et al (2010).
The same idea underliesthe generalized expectation criterion (Mann andMcCallum, 2010; Wang and Manning, 2014).
AnSGD algorithm for solving the resulting saddlepoint problem has been proposed by Liang et al(2009), and used by Ganchev and Das (2013) forcross-lingual learning of sequence models.
We ex-tended this framework in two aspects: by incorpo-rating a task-specific cost in the objective function,and by formulating a penalized variant of PR.7 ConclusionsWe presented a framework for cross-lingual trans-fer of coreference resolvers.
Our method usesword-aligned bitext to project information fromthe source to the target language.
Robust-ness to projection errors was achieved via aPR framework, which we generalized to handletask-specific costs, yielding softmax-margin PR.We also proposed a penalized formulation thatis effective for a small number of corpus-basedconstraints.
Empirical gains were shown overthree popular cross-lingual methods: delexicalizedtransfer, bitext direct projection, and vanilla PR.AcknowledgmentsI would like to thank the reviewers for theirhelpful comments, Jos?e Guilherme Camargo deSouza for pointing to existing datasets, and Mar-iana Almeida for valuable feedback.
This workwas partially supported by the EU/FEDER pro-gramme, QREN/POR Lisboa (Portugal), underthe Intelligo project (contract 2012/24803), andby the FCT grants UID/EEA/50008/2013 andPTDC/EEI-SII/2312/2012.A Proof of Proposition 1Let us fix w and see how to evaluate KL(Q||p?w) =minq?QKL(q?p?w).
We have:KL(q?p?w) = ?H(q)?
?Yq(Y) log p?w(Y|X)= ?H(q) +?nlogZ?
(w, x(n))?
?Yq(Y)(w>f(X,Y) + `(Y)),where `(Y) :=?Nn=1`(y,Y(E(n))) and f(X,Y) :=?Nn=1f(x(n), y(n)).
Introducing Lagrange multipliers u forthe posterior constraints, we get the Lagrangian function:L(q,u) = ?H(q) +?nlogZ?
(w, x(n))?
b>u?
?Yq(Y)(w>f(X,Y)+`(Y)?u>g(X,Y)).By standard variational arguments (namely, Fenchel dualitybetween the the log-partition function and the negative en-tropy; see e.g.
Martins et al (2010)), we have that the optimalq?that minimizes the Lagrangian isq?
(Y) =ew>f(X,Y)+` (Y)?u>g(X,Y)?Nn=1Z?u(w, x(n)).Plugging this in the Lagrangian yields Eq.
8.1435ReferencesMariana S. C. Almeida, Cl?audia Pinto, Helena Figueira, Pe-dro Mendes, and Andr?e F. T. Martins.
2015.
Aligningopinions: Cross-lingual opinion mining with dependen-cies.
In Proc.
of the Annual Meeting of the Associationfor Computational Linguistics.Giuseppe Attardi, Stefano Dei Rossi, and Maria Simi.
2010.TANL-1: coreference resolution by parse analysis andsimilarity clustering.
In Proc.
of the International Work-shop on Semantic Evaluation.Wilker Aziz and Lucia Specia.
2011.
Fully automatic com-pilation of a Portuguese-English parallel corpus for statis-tical machine translation.
In STIL 2011.Amit Bagga and Breck Baldwin.
1998.
Algorithms for scor-ing coreference chains.
In Proc.
of International Confer-ence on Language Resources and Evaluation: Workshopon Linguistics Coreference.Eric Bengtson and Dan Roth.
2008.
Understanding the valueof features for coreference resolution.
In Proc.
of Empiri-cal Methods in Natural Language Processing.Shane Bergsma and Dekang Lin.
2006.
Bootstrapping path-based pronoun resolution.
In Proc.
of the Annual Meetingof the Association for Computational Linguistics.Sandra Collovini, Thiago Carbonel, Juliana Thiesen Fuchs,Jorge C?esar Coelho, L?ucia Rino, and Renata Vieira.
2007.Summ-it: Um corpus anotado com informac?
?oes discursi-vas visando a sumarizac?
?ao autom?atica.
In Workshop emTecnologia da Informac?
?ao e da Linguagem Humana.Pascal Denis and Jason Baldridge.
2008.
Specialized modelsand ranking for coreference resolution.
In Proc.
of Empir-ical Methods in Natural Language Processing.Greg Durrett and Dan Klein.
2013.
Easy victories and uphillbattles in coreference resolution.
In Proc.
of EmpiricalMethods in Natural Language Processing.Greg Durrett, David Hall, and Dan Klein.
2013.
Decentral-ized entity-level modeling for coreference resolution.
InProc.
of Annual Meeting of the Association for Computa-tional Linguistics.Eraldo Rezende Fernandes, C?
?cero Nogueira dos Santos, andRuy Luiz Milidi?u.
2012.
Latent structure perceptron withfeature induction for unrestricted coreference resolution.In Joint Conference on EMNLP and CoNLL-Shared Task,pages 41?48.Kuzman Ganchev and Dipanjan Das.
2013.
Cross-lingualdiscriminative learning of sequence models with posteriorregularization.
In Proc.
of Empirical Methods in NaturalLanguage Processing.Kuzman Ganchev, Jo?ao Grac?a, Jennifer Gillenwater, and BenTaskar.
2010.
Posterior regularization for structured latentvariable models.
Journal of Machine Learning Research,11:2001?2049.Kevin Gimpel and Noah A. Smith.
2010.
Softmax-MarginCRFs: Training Log-Linear Models with Loss Functions.In NAACL.Aria Haghighi and Dan Klein.
2007.
Unsupervised coref-erence resolution in a nonparametric bayesian model.
InProc.
of Annual Meeting of the Association for Computa-tional Linguistics.Aria Haghighi and Dan Klein.
2010.
Coreference resolutionin a modular, entity-centered model.
In Proc.
of AnnualConference of the North American Chapter of the Associ-ation for Computational Linguistics.Sanda M Harabagiu and Steven J Maiorano.
2000.
Multilin-gual coreference resolution.
In Proc.
of the Conference onApplied Natural Language Processing.Christian Hardmeier, J?org Tiedemann, and Joakim Nivre.2013.
Latent anaphora resolution for cross-lingual pro-noun prediction.
In Proc.
of Empirical Methods in NaturalLanguage Processing.Karl Moritz Hermann and Phil Blunsom.
2014.
MultilingualModels for Compositional Distributional Semantics.
InProc.
of the Annual Meeting of the Association for Com-putational Linguistics.Rebecca Hwa, Philip Resnik, Amy Weinberg, Clara Cabezas,and Okan Kolak.
2005.
Bootstrapping parsers via syn-tactic projection across parallel texts.
Natural languageengineering, 11(3):311?325.Percy Liang, Ben Taskar, and Dan Klein.
2006.
Alignmentby agreement.
In Proc.
of North American Chapter of theAssociation of Computational Linguistics.Percy Liang, Michael I Jordan, and Dan Klein.
2009.
Learn-ing from measurements in exponential families.
In Proc.of International Conference on Machine Learning, pages641?648.Xiaoqiang Luo.
2005.
On coreference resolution perfor-mance metrics.
In Proc.
of Empirical Methods in Natu-ral Language Processing.
Association for ComputationalLinguistics.Gideon Mann and Andrew McCallum.
2010.
General-ized expectation criteria for semi-supervised learning withweakly labeled data.
Journal of Machine Learning Re-search, 11:955?984.Andr?e F. T Martins, Noah A. Smith, Eric P. Xing, PedroM.
Q. Aguiar, and M?ario A. T. Figueiredo.
2010.
TurboParsers: Dependency Parsing by Approximate VariationalInference.
In Proc.
of Empirical Methods for Natural Lan-guage Processing.Andr?e F. T Martins, Miguel B. Almeida, and Noah A.Smith.
2013.
Turning on the turbo: Fast third-order non-projective turbo parsers.
In Proc.
of the Annual Meetingof the Association for Computational Linguistics.Ryan McDonald, Slav Petrov, and Keith Hall.
2011.
Multi-source transfer of delexicalized dependency parsers.
InProc.
of Empirical Methods in Natural Language Process-ing.Vincent Ng and Claire Cardie.
2002.
Improving machinelearning approaches to coreference resolution.
In Proc.of the Annual Meeting on Association for ComputationalLinguistics.Vincent Ng.
2008.
Unsupervised models for coreference res-olution.
In Proc.
of Empirical Methods in Natural Lan-guage Processing.Slav Petrov and Dan Klein.
2007.
Improved inference forunlexicalized parsing.
In Proc.
of Annual Meeting of theNorth American Chapter of the Association for Computa-tional Linguistics, pages 404?411.1436Slav Petrov, Dipanjan Das, and Ryan McDonald.
2012.
Auniversal part-of-speech tagset.
In Proc.
of LREC.Oana Postolache, Dan Cristea, and Constantin Orasan.
2006.Transferring coreference chains through word alignment.In Proc.
of the International Conference on Language Re-sources and Evaluation.Sameer Pradhan, Alessandro Moschitti, Nianwen Xue, OlgaUryupina, and Yuchen Zhang.
2012.
CoNLL-2012Shared Task: Modeling multilingual unrestricted corefer-ence in OntoNotes.
In Proc.
of the Conference on Compu-tational Natural Language Learning: Shared Task.Sameer Pradhan, Xiaoqiang Luo, Marta Recasens, EduardHovy, Vincent Ng, and Michael Strube.
2014.
Scoringcoreference partitions of predicted mentions: A referenceimplementation.
In Proc.
of the Annual Meeting of theAssociation for Computational Linguistics.Karthik Raghunathan, Heeyoung Lee, Sudarshan Rangara-jan, Nathanael Chambers, Mihai Surdeanu, Dan Jurafsky,and Christopher Manning.
2010.
A multi-pass sieve forcoreference resolution.
In Proc.
of Empirical Methods inNatural Language Processing.Altaf Rahman and Vincent Ng.
2011.
Narrowing themodeling gap: A cluster-ranking approach to coreferenceresolution.
Journal of Artificial Intelligence Research,40(1):469?521.Altaf Rahman and Vincent Ng.
2012.
Translation-based pro-jection for multilingual coreference resolution.
In Proc.of the Conference of the North American Chapter of theAssociation for Computational Linguistics.Marta Recasens and Eduard Hovy.
2010.
Coreference res-olution across corpora: Languages, coding schemes, andpreprocessing information.
In Proc.
of the Annual Meet-ing of the Association for Computational Linguistics.Marta Recasens and M Ant`onia Mart??.
2010.
Ancora-co:Coreferentially annotated corpora for spanish and catalan.Language resources and evaluation, 44(4):315?345.Marta Recasens, Llu?
?s M`arquez, Emili Sapena, M Ant`oniaMart?
?, Mariona Taul?e, V?eronique Hoste, Massimo Poesio,and Yannick Versley.
2010.
Semeval-2010 task 1: Coref-erence resolution in multiple languages.
In Proc.
of theInternational Workshop on Semantic Evaluation.Noah A Smith and Jason Eisner.
2005.
Contrastive es-timation: Training log-linear models on unlabeled data.In Proc.
of Annual Meeting on Association for Computa-tional Linguistics.Wee Meng Soon, Hwee Tou Ng, and Daniel Chung YongLim.
2001.
A machine learning approach to corefer-ence resolution of noun phrases.
Computational linguis-tics, 27(4):521?544.Jos?e Guilherme Camargo de Souza and Constantin Or?asan.2011.
Can projected chains in parallel corpora help coref-erence resolution?
In Anaphora Processing and Applica-tions, pages 59?69.
Springer.Veselin Stoyanov, Claire Cardie, Nathan Gilbert, Ellen Riloff,David Buttler, and David Hysom.
2010.
Coreference res-olution with reconcile.
In Proc.
of the Annual Meeting ofthe Association for Computational Linguistics.Oscar T?ackstr?om, Ryan McDonald, and Jakob Uszkoreit.2012.
Cross-lingual word clusters for direct transfer oflinguistic structure.
In Proc.
of the North American Chap-ter of the Association for Computational Linguistics.Oscar T?ackstr?om, Dipanjan Das, Slav Petrov, Ryan McDon-ald, and Joakim Nivre.
2013.
Token and type constraintsfor cross-lingual part-of-speech tagging.
Transactions ofthe Association for Computational Linguistics, 1:1?12.Ivan Titov and Alexandre Klementiev.
2012.
Cross-lingualinduction of semantic roles.
In Proc.
of the Annual Meet-ing of the Association for Computational Linguistics.Joseph Turian, Lev Ratinov, and Yoshua Bengio.
2010.
Wordrepresentations: a simple and general method for semi-supervised learning.
In Proc.
of the Annual Meeting of theAssociation for Computational Linguistics.Yannick Versley, Simone Paolo Ponzetto, Massimo Poesio,Vladimir Eidelman, Alan Jern, Jason Smith, XiaofengYang, and Alessandro Moschitti.
2008.
Bart: A modulartoolkit for coreference resolution.
In Proc.
of the AnnualMeeting of the Association for Computational Linguistics:Demo Session.Marc Vilain, John Burger, John Aberdeen, Dennis Connolly,and Lynette Hirschman.
1995.
A model-theoretic corefer-ence scoring scheme.
In Proc.
of the Conference on Mes-sage Understanding, pages 45?52.
Association for Com-putational Linguistics.Mengqiu Wang and Chris Manning.
2014.
Cross-lingualprojected expectation regularization for weakly super-vised learning.
Transactions of the Association for Com-putational Linguistics, 2:55?66.David Yarowsky, Grace Ngai, and Richard Wicentowski.2001.
Inducing multilingual text analysis tools via robustprojection across aligned corpora.
In Proc.
of the First In-ternational Conference on Human Language TechnologyResearch.Daniel Zeman and Philip Resnik.
2008.
Cross-languageparser adaptation between related languages.
In IJCNLP,pages 35?42.1437
