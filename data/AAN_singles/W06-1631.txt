Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP 2006), pages 258?266,Sydney, July 2006. c?2006 Association for Computational LinguisticsCapturing Out-of-Vocabulary Words in Arabic TextAbdusalam F.A.
Nwesri S.M.M.
Tahaghoghi Falk ScholerSchool of Computer Science and Information TechnologyRMIT University, GPO Box 2476V, Melbourne 3001, Australia{nwesri,saied,fscholer}@cs.rmit.edu.auAbstractThe increasing flow of information be-tween languages has led to a rise in the fre-quency of non-native or loan words, whereterms of one language appear transliter-ated in another.
Dealing with such outof vocabulary words is essential for suc-cessful cross-lingual information retrieval.For example, techniques such as stemmingshould not be applied indiscriminately toall words in a collection, and so before anystemming, foreign words need to be iden-tified.
In this paper, we investigate threeapproaches for the identification of foreignwords in Arabic text: lexicons, languagepatterns, and n-grams and present that re-sults show that lexicon-based approachesoutperform the other techniques.1 IntroductionArabic words are derived from roots having three,four, or, in rare instances, five characters.
Thederivation process consistently follows patternsthat are based on the three letter verb???
(/fa?ala/to do)1.
Each root word matches a base pattern.Characters are added at the beginning, the mid-dle, or end of the root, but the base characters thatmatch the pattern remain unchanged.The pronunciation of Arabic characters is as-sociated with short vowels; these are representedby diacritics, and attached to other characters toshow how the characters should be pronounced.An Arabic character can be pronounced in severaldifferent ways.
For example, the letter H.with the1We represent phonetics using the International Pho-netic Alphabet (http://www.arts.gla.ac.uk/IPA/ipachart.html)diacritic Fatha H.is pronounced /ba/, with the dia-critic Kasra H.is pronounced /bI/, and with havingthe diacritic Damma H.is pronounced /bU/.
Di-acritics are not shown in general written Arabic,and the reader must rely on the context to deter-mine the implicit diacritics and therefore the pro-nunciation of each word.
For example, the wordI.
?X can represent I.?X (/Dahaba/ = went), I.
?X(/Dahab/ = gold).Pure Arabic words follow restricted rules intheir construction to keep them short and easyto pronounce.
Their sounds usually follow theCVCV pattern, where C stands for a consonantand V stands for a Vowel.
An Arabic word neverhas two consecutive consonants nor four consecu-tive vowels (Al-Shanti, 1996).Foreign words are words that are borrowed fromother languages.
Some are remodelled to con-form with Arabic word paradigms, and becomepart of the Arabic lexicon; others are transliteratedinto Arabic as they are pronounced by differentArabic speakers, with some segmental and vowelchanges.
The latter are called Out-Of-Vocabulary(OOV) words as they are not found in a standardArabic lexicon.
Such OOV words are increas-ingly common due to the inflow of informationfrom foreign sources, and include terms that areeither new and have yet to be translated into nativeequivalents, or proper nouns that have had theirphonemes replaced by Arabic ones.
Examples in-clude words such as HQ 	?PA?
/margrIt/ (Margaret)or ??
JJ?
/linIks/ (Linux).
This process often re-sults in different Arabic spellings for the sameword.Current Arabic Information Retrieval (AIR)systems do not handle the problem of retriev-ing the different versions of the same foreign258word (Abdelali et al, 2004), and instead typicallyretrieve only the documents containing the samespelling of the word as used in the query.One solution to this problem has been used incross-lingual information retrieval, where OOVwords in the query are transliterated into their pos-sible equivalents.
Transliterating terms in Englishqueries into multiple Arabic equivalents using anEnglish-Arabic dictionary has been shown to havea positive impact on retrieval results (Abduljaleeland Larkey, 2003).
However, we are aware of nowork on handling OOV terms in Arabic queries.For this, proper identification of foreign wordsis essential.
Otherwise, query expansion for suchwords is not likely to be effective: many Ara-bic words could be wrongly expanded, resultingin long queries with many false transliterations ofArabic words.
Furthermore, proper identificationof foreign words would be helpful because suchwords could then be treated differently using tech-niques such as approximate string matching (Zo-bel and Dart, 1995).In this paper, we examine possible techniquesto identify foreign words in Arabic text.
In thefollowing sections we categorise and define for-eign words in Arabic, and follow in section 2 witha discussion of possible different approaches thatcan identify them in Arabic text.
In section 3 wepresent an initial evaluation of these approaches,and describe improvements in section 4 that wethen explore in a second experiment in section 5.We discuss results in section 6 and finally con-clude our work in section 7.1.1 Foreign words in ArabicArabic has many foreign words, with varying lev-els of assimilation into the language.
Words bor-rowed from other languages usually have differentstyle in writing and construction, and Arabic lin-guists have drawn up rules to identify them.
Forexample, any root Arabic word that has four ormore characters should have one or more of the?Dalaga?
letters ( 	?, P, , 	?, ?, H.).
Those thathave no such letters are considered foreign (Al-Shanti, 1996).
However, while such rules couldbe useful for linguistic purposes, they have limitedapplication in Information Retrieval (IR); based onrules, many foreign words that have long been ab-sorbed into the language and are spelled consis-tently would be considered to be OOV.
From theIR perspective, foreign words can be split into two?J????J??JJ?J???J??J????J??J?J??J???J?J??J??J?J???J??J????J??J?J??J??J?J????J????J??J??J???J??J???J??J?J??J?J?
?J?J???J???J??J??J????J??
?J?????J??J?KP??J??J???J??
?J?J???J??J?P??J??J?????J??J?J???J??J?J???J??JJ????J??J????J???J???J??J???
?J?Table 1: Different spelling versions for the nameMilosevicgeneral categories: translated and transliterated.Translated: These are foreign words that aremodified or remodelled to conform with Ara-bic word paradigms; they are well assimi-lated into Arabic, and are sometimes referredto as Arabicised words (Aljlayl and Frieder,2002).
This process includes changes in thestructure of the borrowed word, includingsegmental and vowel changes, and the addi-tion, deletion, and modification of stress pat-terns (Al-Qinal, 2002).
This category of for-eign words usually has a single spelling ver-sion that is used consistently.
Examples in-clude words such as 	?AJ?.
(/bUst?n/ = gar-den), h.QK.
(/bUrZ/ = tower), ?KXP (/r?duU/ =radio), and ??J.J?
(/qUnbula = bomb).Transliterated: Words in this category aretransliterated into Arabic by replacingphonemes with their nearest Arabic equiv-alents.
Although Arabic has a broad soundsystem that contains most phonemes used inother languages, not all phonemes have Ara-bic equivalents.
In practice, such phonemesmay be represented in different ways by dif-ferent persons, resulting in several spellingversions for the same foreign word.
Forexample, we observed 28 transliteratedversions for the name of the former Serbianleader (Milosevic) in the TREC 2002 Arabiccollection; these are shown in Table 1.Transliteration has become more common thantranslation due to the need for instant access tonew foreign terms.
It can take considerable timefor a new foreign term to be included in reference259dictionaries.
However, users often need to imme-diately use a particular term, and cannot wait un-til a standard form of the word is created; newsagencies form an important category of such users.This transliteration process often results in multi-ple spellings in common usage.1.2 Related workIn the context of information retrieval, most workon foreign words in Arabic has been based ontransliteration, and carried out under machinetranslation and cross-lingual information retrieval(CLIR) tasks, where English queries are used tosearch for Arabic documents, or vice versa.
Thisoften involves the use of a bilingual dictionary totranslate queries and transliterate OOV words intotheir equivalents in Arabic.Expanding a foreign word to its possible vari-ants in a query has been shown to increase the pre-cision of search results (Abduljaleel and Larkey,2003).
However, OOV words in the query areeasily recognised based on English rules and anEnglish-Arabic dictionary: capitalised words aremarked as nouns, and the remaining words aretranslated using the dictionary.
Words not found inthe dictionary are marked as OOV and are translit-erated into probable Arabic forms.
In contrast, weaim to identify foreign words as a within Arabictext which is made difficult by the absence of sucheasily perceptible difference.Stalls and Knight (1998) describe research todetermine the original foreign word from its Ara-bic version; this is known as back transliteration.However, rather than using automatic methods toidentify foreign words, they used a list of 2 800names to test the accuracy of the back translit-eration algorithm.
Of these, only 900 nameswere successfully transliterated to their sourcenames.
While this approach can be used to iden-tify transliterated foreign words, its effectivenessis not known on normal Arabic words as onlynames were used to test the algorithm.Jeong et al (1999) used statistical differ-ences in syllable unigram and bigram patternsbetween pure Korean words and foreign wordsto identify foreign words in Korean documents.This approach was later enhanced by Kang andChoi (2002) to incorporate word segmentation.A related area is language identification, wherestatistics derived from a language model are usedto automatically identify languages (Dunning,1994).
Using N-gram counting produces good ac-curacy for long strings with 50 or more charac-ters, and moderately well with 10-character-longstrings.
It is unclear how well this approach wouldwork on individual words with five characters onaverage.2 Identifying foreign wordsWe categorise three general approaches for recog-nising foreign words in Arabic text:Arabic lexiconOOV words can be easily captured by checkingwhether they exist in an Arabic lexicon.
However,the lexicon is unlikely to include all Arabic words,while at the same time it could contain some for-eign words.
Moreover, this approach will identifymisspelled Arabic words as foreign.Arabic patterns systemArabic uses a pattern system to derive wordsfrom their roots.
Roots are three, four or some-times five letters long.
The reference pattern???
(/fa?ala/ = to do) is often used to represent three-letter root words.
For example, the wordIjK.(/b?
Ta/ = searched) can be represented by this pat-tern through mapping K.to ?, j to  ?, andIto?.Many stems can be generated from this root us-ing standard patterns.
For instance,??A?
(/f?
?Il/ =doer) , and?
??K(/yf?lU/ = is doing) are two dif-ferent patterns that respectively represent the ac-tive participle, and present tense verb from the pat-tern???.
By placing the appropriate core lettersand adding additional letters in each pattern, wecan generate words such asIkAK.(/b?
?IT/ = re-searcher), I j.K(/yb?TU/ = does search) respec-tively.
New words can further accept prefixes andsuffixes.We can recognise whether a word is an Ara-bic or foreign word by reversing the process andtesting the different patterns.
If, after all pos-sible affixes have been removed, the remainingstem matches an Arabic pattern, the word is likelyto be an Arabic word.
For example, to checkwhether the wordIkAJ.?
?
(/walb?
?IT/ = and theresearcher) is a foreign word, we first remove theprefixes ?
and ?
 to get the stemIkAK.
; we findthat this word matches the pattern??A?
?
it hasthe same length, and the letter A is in the same po-260sition ?
and conclude that it is therefore an Arabicword.
Note that we must perform this determina-tion without relying on diacritics.This approach is not perfect, as general Arabictext does not include explicit diacritics; if parts ofa foreign word match a pattern, it will be markedas being Arabic.
Similarly, misspelled words maybe classified as foreign words if no matching pat-tern is found.N-gram approachTransliterated foreign words exhibit construc-tion patterns that are often different from Arabicpatterns.
By counting the N-grams of a sample offoreign words, a profile can be constructed to iden-tify similar words.
This approach has been usedin language identification, although it is reportedto have only moderate effectiveness in identifyingshort strings (Cavnar and Trenkle, 1994; Dunning,1994).2.1 ResourcesFor the lexicon approach, we used three lexicons:the Khoja root lexicon (Khoja and Garside, 1999),the Buckwalter Lexicon (Buckwalter, 2002), andthe Microsoft office 2003 lexicon (Microsoft Cor-poration, 2002).The Khoja stemmer has an associated com-pressed language dictionary that contains well-known roots.
The stemmer strips prefixes and suf-fixes and matches the remaining stem with a list ofArabic patterns.
If a match is found, the root is ex-tracted and checked against the dictionary of rootwords.
If no entry is found, the word is consideredto be a non-Arabic word.
We call this the KhojaLexicon Approach (KLA).The Buckwalter morphological analyser is alexicon that uses three tables and an algorithm tocheck possible affixes.
The algorithm checks aword and analyses its possible prefixes and suf-fixes to determine possible segmentation for anArabic word.
If the algorithm fails to find anypossible segmentation, the word is considered notfound in the lexicon.
We name this approach theBuckwalter Lexicon Approach (BLA).The Microsoft office lexicon is the one used inthe Microsoft Office 2003 spell-checker.
We testwhether an Arabic word is found in this lexicon,and classify those that are not in the lexicon to beforeign words.
We call this approach the OfficeLexicon Approach (OLA).????
 ZC??
 ?C??
????
 ?????
?????
 ?J??
 ??
?J??J?A?K ?A??K???
?K ????K???A?
???A?
BA????A??
??A??
?J?
A???????<???CJ????J??
?J???
??AJ?
?J?AJ????A????
A???
C????????
???????
?K ??????
A???????
????J??J???
CJ??
?Table 2: Patterns added to the Khoja modifiedstemmer to implement the KPA approachTo use Arabic patterns, we modified the Khojastemmer to check whether there is a match be-tween a word and a list of patterns after stemmingwithout further checking against the root dictio-nary.
If there is no match, the word is considereda foreign word.
This approach is similar to the ap-proach used by Taghva et al (2005).
We adoptedthe patterns of the Khoja stemmer and added 37patterns compiled from Arabic grammar books,these are shown in Table 2.
We call these ap-proaches the Khoja Pattern Approach (KPA), andModified Khoja Pattern Approach (MKP) respec-tively.
A word is also considered to be an Arabicword if the remaining stem has three or fewer let-ters.We evaluate the effectiveness of the n-grammethod in two ways.
First, we extend the n-gramtext categorisation method presented by Cavnarand Trenkle (1994).
The method uses languageprofiles where, for each language, all n-grams thatoccur in a training corpus are sorted in order ofdecreasing frequency of occurrence, for n rangingfrom 1 to 5.
To classify a text t, we build its n-gram frequency profile, and compute the distancebetween each n-gram in the text and in each lan-guage profile lj .
The total distance is computed bysumming up all differences between the positionof the n-gram in the text profile and the position ofthe same n-gram in the language profile:Dj =Ni?i=1| rank(ti, text)Ni?
rank(ti, lj)Nj|where Dj is the total distance between a text t withNi n-grams, and a language profile lj with Nj n-grams; and rank is the position of the n-gram inthe frequency-sorted list of all n-grams for eitherthe text or language profile.In our work, we build two language profiles, one261for native Arabic words and another for foreignwords.
We compare the n-grams in each word inour list against these two profiles.
If the total dis-tance between the word and the foreign words pro-file is smaller than the total distance between theword and the Arabic words profile, then it is clas-sified as a foreign word.
As the two language pro-files are not in same size, we compute the relativeposition of each n-gram by dividing its position inthe list by the number of the n-grams in the lan-guage profile.
We call this approach the n-gramapproach (NGR).We also tried a simpler approach based on theconstruction of two trigram models: one fromArabic words, and another from foreign words.The probability that a string is a foreign word isdetermined by comparing the frequency of its tri-grams with each language model.
A word is con-sidered foreign if the sum of the relative frequencyof its trigrams in the foreign words profile is higherthan the sum of the relative frequency of its tri-grams in the Arabic words profile.
We call thisapproach trigram (TRG).3 Training ExperimentsIn this section, we describe how we formed adevelopment data set using Arabic text from theWeb, and how we evaluated and improved tech-niques for identification of foreign words.3.1 DataTo form our development data set, we crawled theArabic web sites of the Al-Jazeera news channel1,the Al-Anwar2 and El-Akhbar3 newspapers.
A listof 285 482 Arabic words was extracted.
After re-moving Arabic stop words such as pronouns andprepositions, the list had 246 281 Arabic wordswith 25 492 unique words.In the absence of diacritics, we decided to re-move words with three or fewer characters, asthese words could be interpreted as being eitherArabic or foreign in different situations.
For ex-ample, the word ?G.
(/bi/) could be interpreted asthe Arabic word meaning ?in me?, or the Englishletter B.
After this step, 24 218 unique words re-mained.We examined these words and categorised eachof them either as Arabic word (AW), or a translit-1http://www.aljazeera.net2http://www.alanwar.com3http://www.elkhabar.comerated foreign word (FW).
We also had to clas-sify some terms as misspelled Arabic word (MW).We used the Microsoft Office spell-checker as afirst-pass filter to identify misspelled words, andthen manually inspected each word to identify anythat were actually correct; the spell-checker failsto recognise some Arabic words, especially thosewith some complex affixes.
The list also had somelocal Arabic dialect spellings that we chose toclassify as misspelled.The final list had three categories: 22 295 cor-rect Arabic words, 1 218 foreign words and 705misspelled words.To build language models for the trigramapproaches (NRG and TRG), we used theTREC 2001 Arabic collection (Gey and Oard,2001).
We manually selected 3 046 foreign wordsout of the OOV words extracted from the col-lection using the Microsoft office spell-checker.These foreign words are transliterated foreignwords.
We built the Arabic language model us-ing 100 000 words extracted from the TREC col-lection using the same spell-checker.
However, weexcluded any word that could be a proper noun, toavoid involving foreign words.
We used an algo-rithm to exclude any word that does not accept thesuffix haa ( ?), as transliterated proper nouns cannot accept Arabic affixes.3.2 EvaluationWe measure the accuracy of each approach by ex-amining the number of foreign words correctlyidentified, and the number of incorrect classifica-tions.
The precision of each approach is calculatedas the ratio of correctly identified foreign wordsto the total number of words identified as foreignThe latter could be correct or misspelled Arabicwords identified as foreign plus the actual foreignwords identified.
The recall is calculated as theratio of correctly identified foreign words to thenumber of words marked manually as foreign.
Al-though there is generally a compromise betweenprecision and recall, we consider precision to bemore important, since incorrectly classifying Ara-bic words as foreign would be more likely to harmgeneral retrieval performance.
The left-hand sideof Table 3 shows the results of our experiments.We have included the MW results to illustrate theeffects of misspelled words on each approachThe results show that the n-gram approach(NGR) has the highest precision, while the262AW MW FWAppr.
# # # R POLA 614 698 1 017 0.834 0.437BLA 384 404 628 0.515 0.443KLA 1 732 215 745 0.612 0.277KPA 1 034 135 590 0.480 0.340MKP 940 126 573 0.470 0.350NGR 718 95 726 0.596 0.471TRG 1 591 118 737 0.605 0.301AW MW FWAppr.
# # # R POLA 145 248 866 0.711 0.687BLA 88 149 534 0.438 0.693KLA 420 83 642 0.527 0.508KPA 302 52 520 0.430 0.590MKP 269 51 507 0.416 0.613NGR 411 69 669 0.549 0.582TRG 928 85 642 0.527 0.387Table 3: Identification of foreign words: initial results (left) and results after improvements (right)lexicon-based OLA approach gives the highest re-call.
The pattern approaches (KPA) and (MKP)perform well compared to the combination of pat-terns and the root lexicon (KLA), although thelatter produces higher recall.
There is a slightimprovement in precision when adding more pat-terns, but recall is sightly reduced.
The KLA ap-proach produces the poorest precision, but has bet-ter recall rate than the NGR approach.The results show that many Arabic native wordsare mistakenly caught in the foreign words net.Our intention is to handle foreign words differ-ently from Arabic native words.
Our approachis based on normalising the different forms of thesame foreign word to one form at the index levelrather than expanding the foreign word to its possi-ble variants at the query level.
Retrieval precisionwill be negatively affected by incorrect classifica-tion of native and foreign words.
Consequently,we consider that keeping the proportion of falsepositives ?
correct Arabic words identified as for-eign (precision) ?
low to be more important thancorrectly identifying a higher number of foreignwords (recall).Some of the Arabic words categorised as for-eign are in fact misspelled; we believe that thesehave limited effect on retrieval precision, and thereis limited value in identifying such words in aquery unless the retrieval system incorporates acorrection process.4 Enhanced rulesTo reduce the false identification rate of foreignwords, we analysed the lists of foreign words, cor-rect Arabic words identified as foreign, and Arabicmisspelled words identified as foreign.
We noticedthat some Arabic characters rarely exist in translit-erated foreign words, and used these to separateArabic words ?
correctly or incorrectly spelledLetter count letter count letter count?3 839  632 h 2 3 599 X 559 ?
2?
2 453 ?
514 ?
1?
1 660 h.458 Z 0?
1 587 	P 334?
0H 1 544 ?
171 0P 1 244 p 84 0?
1 070 H 23? 0H.900 ?
20 	?
0?
863 ?
12 	?
0?
769?
7 ?
0?
728 	X 3 ?
0Table 4: Frequency of Arabic letters in a sampleof 3 046 foreign words?
from true foreign words.
Table 4 shows thecount of each character in the sample of 3 046 for-eign words; foreign words tend to have vowels in-serted between consonants to maintain the CVCVparadigm.
We also noticed that most of translit-erated foreign words do not start with the definitearticle ?
, or end with the Taa Marbuta ?.
Foreignwords also rarely end with two Arabic suffixes.We also noticed that lexicon based approachesfail to recognise some correct Arabic words for thefollowing reasons:?
Words with the letter  (Alef) with or with-out the diacritics Hamza (, ), or the diacriticMadda (?) are not recognised as correct inmany cases.
Many words are also categorisedincorrectly if the Hamza is wrongly placedabove or below the initial Alef or the Maddais absent.
In modern Arabic text, the Alef of-ten appears without the Hamza diacritic and263the Madda is sometimes dropped.?
Correct Arabic words are not recognised withparticular suffixes.
For example, words thathave the object suffix, such as the suffix A?in A??
K???
?K(/yU?alImunakaha/ = they teachit to you).?
Some Arabic words are compound words,written attached to each other most of thetime.
For example, compound nouns such asPXA??
YJ.?
(/?bdulqadIr/), although composedof two words that are individually identi-fied as being correct, are flagged as incorrectwhen combined.?
Some common typographical shortcuts resultin words being written without white spacebetween them.
Where a character that alwaysterminates a word (for example ? )
is foundin the apparent middle of a word, it is clearthat this problem has occurred.From these observations, we constructed thefollowing rules.
Whenever one of the followingconditions is met, a word is not classified as for-eign:1. the word contains any of the Arabic charac-ters:?, Z,X, h, ?,?,, ,?,?,?, ?,?;2.
the word starts with the definite article ( ?
);3. the word has more than one Arabic suffix(pronouns attached at the end of the word);4. the word has no vowels between the secondand penultimate character (inclusive); or5.
the word contains one of the strings: ?, ?,Z,  , ?AK, ?P, ?P, ?X, ?X, ??, ?, and whensplit into two parts at the first character of anysequence, the first part is three characters orlonger, and the second part is four charactersor longer.The right-hand side of Table 3 shows the im-provements achieved using these rules.
It canbe seen that they have a large positive impact.Overall, OLA performs the best, with precisionat 69% and recall at 71%.
Figure 1 showsthe precision obtained before and after applyingthese rules.
Improvement is consistent acrossall approaches, with an increase in precision be-tween 10% and 25%.OLA BLA KLA KPA MKP NRG TRGApproach0.00.20.40.60.81.0PrecisionBeforeAfterFigure 1: Precision of different approaches beforeand after Improvements5 Verification ExperimentsTo verify our results, we used another data setof similar size to the first to verify our approach.We collected a list of 23 466 unique words fromthe Dar-al-Hayat newspaper4.
Words, and classi-fied and marked words in the same way as for thefirst data set (described in Section 3.1).
We de-termined this new set to comprise 22 800 Arabicwords (AW), 536 Foreign words (FW), and 130Misspelled words (MW).
Table 5 shows the initialresults and improvements using the enhanced rulesobtained by each approach using this data set.The results on this unseen data are relativelyconsistent with the previous experiment, but pre-cision in this sample is expectedly lower.6 DiscussionWe have seen that foreign words are not easilyrecognised in Arabic text, and a large number ofArabic words are affected when we try to excludeforeign words.We found the lexicon approach to be the bestin identifying foreign words.
However, currentlexicons are relatively small, and the variety ofArabic inflection makes it very difficult to includeall correct word forms.
Furthermore, current lex-icons include many foreign words; for examplewhen using OLA approach, 1 017 foreign wordsout of 1 218 are OOV, indicating that about 200foreign words are present in that lexicon.
Thepattern approach is more efficient but the lackof diacritics in general written Arabic makes itvery difficult to precisely match a pattern with a4http://www.daralhayat.com264AW MW FWAppr.
# # # R POLA 1 189 112 417 0.777 0.242BLA 780 96 267 0.498 0.234KLA 1 684 55 312 0.582 0.152KPA 992 29 238 0.440 0.189MKP 901 26 231 0.431 0.199NGR 740 22 286 0.533 0.272TRG 1 655 19 308 0.575 0.155AW MW FWAppr.
# # # R POLA 302 38 307 0.572 0.474BLA 149 33 184 0.343 0.502KLA 350 16 216 0.403 0.371KPA 238 9 166 0.310 0.402MKP 202 8 162 0.302 0.435NGR 401 8 245 0.457 0.374TRG 972 11 235 0.438 0.193Table 5: Identification of foreign words on the test set: initial results (left) and results after improvements(right)word, resulting in many foreign words being in-correctly identified as Arabic.
Passing the list ofall 3 046 manually judged foreign words to thepattern approach, some 2 017 words of this listwere correctly judged as foreign, and about onethird (1 029) were incorrectly judged to be Ara-bic.
The n-gram method produced reasonable pre-cision compared to the lexicon-based methods.
Incontrast, TRG had the worst results.
This couldbe due to the limited size of the training corpus.However, we expect that improvements to this ap-proach will remain limited due to the fact thatmany Arabic and foreign words share the sametrigrams.
It is clear that all the approaches are im-proved dramatically when applying the enhance-ment rules.
The improvements of the NGR wasn?tas equal as other approaches.
This is because someof the rules are implicitly applied within the n-gram approach.
The lack of diacritics also makesit very difficult to distinguish between certain for-eign and Arabic words.
For example, without dia-critics, the word 	?JJ??
could be 	?JJJ??
(/klIn-tUn/ = Clinton), or 	?JJJ??
(/kalinatin/ = as twodate trees).
The pronunciation is different in thetwo cases, but only context or diacritics can makeit clear which word is being used.7 ConclusionIdentifying foreign words in Arabic text is an im-portant problem for cross-lingual information re-trieval, since commonly-used techniques such asstemming should not be applied indiscriminatelyto all words in a collection.We have presented three approaches for identi-fying foreign words in Arabic text: lexicons, pat-terns, and n-grams.
We have presented resultsthat show that the lexicon approach outperformsthe other approaches, and have described improve-ments to minimise the false identification of for-eign words.
These rules result in improved preci-sion, but have a small negative impact on recall.Overall, the results are relatively low for practicalapplications, and more work is needed to deal withthis problem.
As foreign words are characterisedby having different versions, an algorithm that col-lapse those versions to one form could be usefulin identifying foreign words.
We are presently ex-ploring algorithms to normalise foreign words inArabic text.
This will allow us to identify nor-malised forms for foreign words and use a singleconsistent version for indexing and retrieval.8 AcknowledgementsWe thank Microsoft Corporation for providingus with a copy of Microsoft Office ProofingTools 2003.ReferencesAhmed Abdelali, Jim Cowie, and Hamdy S. Soliman.
2004.Arabic information retrieval perspectives.
In Proceedingsof the 11th Conference on Natural Language Processing,Journes d?Etude sur la Parole - Traitement Automatiquedes Langues Naturelles (JEP-TALN), Fez, Morocco.Nasreen Abduljaleel and Leah S. Larkey.
2003.
Statisticaltransliteration for English-Arabic cross-language informa-tion retrieval.
In Proceedings of the International Confer-ence on Information and Knowledge Management, pages139?146.
ACM Press.Jamal B. S. Al-Qinal.
2002.
Morphophonemics of loan-words in translation.
Journal of King Saud University,13:1?132.Mohamed Saleh Al-Shanti.
1996.
Al Maharat Allughawia.Al Andalus for publishing and distribution.
4th edition.Mohammed Aljlayl and Ophir Frieder.
2002.
On Arabicsearch: improving the retrieval effectiveness via a lightstemming approach.
In Proceedings of the InternationalConference on Information and Knowledge Management,pages 340?347.
ACM Press.265Tim Buckwalter.
2002.
Buckwalter Arabic morphologicalanalyzer version 1.0.
LDC Catalog No.
LDC2002L49.William B. Cavnar and John M. Trenkle.
1994.
N-gram-based text categorization.
In Proceedings of 3rd AnnualSymposium on Document Analysis and Information Re-trieval, SDAIR-94,, pages 161?175, Las Vegas, US.Ted Dunning.
1994.
Statistical identification of language.Technical Report MCCS-94-273, Computing ResearchLab (CRL), New Mexico State University.Fredric C. Gey and Douglas W. Oard.
2001.
The TREC-2001 cross-language information retrieval track: Search-ing Arabic using English, French or Arabic queries.
InTREC-2001, volume NIST Special Publication:SP 500-250.
National Institute of Standards and Technology.Kil S. Jeong, Sung Hyon Myaeng, Jae S. Lee, and Key-Sun Choi.
1999.
Automatic identification and back-transliteration of foreign words for information retrieval.Information Processing and Management, 35(4):523?540.Byung-Ju Kang and Key-Sun Choi.
2002.
Effective foreignword extraction for Korean information retrieval.
Infor-mation Processing and Management, 38(1):91?109.Shereen Khoja and Roger Garside.
1999.
Stemming Arabictext.
Technical report, Computing Department, LancasterUniversity, Lancaster.Microsoft Corporation.
2002.
Arabic proofing tools inOffice 2003.URL: http://www.microsoft.com/middleeast/arabicdev/office/office2003/Proofing.asp.Bonnie Glover Stalls and Kevin Knight.
1998.
Trans-lating names and technical terms in Arabic text.
InCOLING/ACL Workshop on Computational Approachesto Semitic Languages, pages 34?41.Kazem Taghva, Rania Elkhoury, and Jeffrey Coombs.
2005.Arabic stemming without a root dictionary.
In Proceed-ings of ITCC 2005 Intlernational Conference on Informa-tion Technology: Coding and Computing.Justin Zobel and Philip Dart.
1995.
Finding approximatematches in large lexicons.
Software - Practice and Expe-rience, 25(3):331?345.266
