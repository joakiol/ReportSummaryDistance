Proceedings of the 7th Workshop on Statistical Machine Translation, pages 480?489,Montre?al, Canada, June 7-8, 2012. c?2012 Association for Computational LinguisticsOptimization Strategies for Online Large-Margin Learning in MachineTranslationVladimir EidelmanUMIACS Laboratory for Computational Linguistics and Information ProcessingDepartment of Computer ScienceUniversity of Maryland, College Park, MDvlad@umiacs.umd.eduAbstractThe introduction of large-margin based dis-criminative methods for optimizing statisticalmachine translation systems in recent yearshas allowed exploration into many new typesof features for the translation process.
Byremoving the limitation on the number ofparameters which can be optimized, thesemethods have allowed integrating millions ofsparse features.
However, these methods havenot yet met with wide-spread adoption.
Thismay be partly due to the perceived complex-ity of implementation, and partly due to thelack of standard methodology for applyingthese methods to MT.
This papers aims to shedlight on large-margin learning for MT, explic-itly presenting the simple passive-aggressivealgorithm which underlies many previous ap-proaches, with direct application to MT, andempirically comparing several widespread op-timization strategies.1 IntroductionStatistical machine translation (SMT) systems rep-resent knowledge sources in the form of features,and rely on parameters, or weights, on each feature,to score alternative translations.
As in all statisticalmodels, these parameters need to be learned fromthe data.
In recent years, there has been a growingtrend of moving away from discriminative trainingusing batch log-linear optimization, with Minimum-Error Rate Training (MERT) (Och, 2003) being theprinciple method, to online linear optimization (Chi-ang et al, 2008; Watanabe et al, 2007; Arun andKoehn, 2007).
The major motivation for this hasbeen that while MERT is able to efficiently optimizea small number of parameters directly toward an ex-ternal evaluation metric, such as BLEU (Papineni etal., 2002), it has been shown that its performancecan be erratic, and it is unable to scale to a largeset of features (Foster and Kuhn, 2009; Hopkins andMay, 2011).
Furthermore, it is designed for batchlearning, which may be prohibitive or undesirablein certain scenarios, for instance if we have a largetuning set.
One or both of these limitations haveled to recent introduction of alternative optimizationstrategies, such as minimum-risk (Smith and Eis-ner, 2006), PRO (Hopkins and May, 2011), Struc-tured SVM (Cherry and Foster, 2012), and RAM-PION (Gimpel and Smith, 2012), which are batchlearners, and online large-margin structured learn-ing (Chiang et al, 2009; Watanabe et al, 2007;Watanabe, 2012).A popular method of large-margin optimiza-tion is the margin-infused relaxed algorithm(MIRA) (Crammer et al, 2006), which has beenshown to perform well for machine translation, aswell as other structured prediction tasks, such asparsing.
(McDonald et al, 2005).
This is an at-tractive method because we have a simple analyticalsolution for the optimization problem at each step,which reduces to dual coordinate descent when us-ing 1-best MIRA.
It is also quite easy to implement,as will be shown below.Despite the proven success of MIRA-based large-margin optimization for both small and large num-bers of features, these methods have not yieldedwide adoption in the community.
Part of the rea-son for this is a perception that these methods arecomplicated to implement, which has been cited asmotivation for other work (Hopkins and May, 2011;Gimpel and Smith, 2012).
Furthermore, there is a di-480vergence between the standard application of thesemethods in machine learning, and our applicationin machine translation (Gimpel and Smith, 2012),where in machine learning there are usually clearcorrect outputs and no latent structures.
As a con-sequence of the above, there is a lack of standardpractices for large-margin learning for MT, whichhas resulted in numerous different implementationsof MIRA-based optimizers, which further add to theconfusion.This paper aims to shed light on practical con-cerns with online large margin training.
Specif-ically, our contribution is first, to present theMIRA passive-aggressive update, which underliesall MIRA-based training, with an eye to applica-tion in MT.
Then, we empirically compare severalwidespread as well as novel optimization strategiesfor large-margin training on Czech-to-English (cs-en) and French-to-English (fr-en) translation.
Ana-lyzing the findings, we recommend an optimizationstrategy which should ensure convergence and sta-bility.2 Large-Margin Learning2.1 DescriptionMIRA is an online large-margin learner, and be-longs to a class of passive-aggressive (PA) algo-rithms (Crammer et al, 2006).
Although the exactprocedure it employs is different from other subgra-dient optimizers, in essence it is performing a sub-gradient descent step, where the step size is adjustedbased on each example.
The underlying objectiveof MIRA is the same as that of the margin rescaledStructural SVM (Tsochantaridis et al, 2004; Mar-tins et al, 2010), where we want to predict the cor-rect output over the incorrect one by a margin at leastas large as the cost incurred by predicting the in-correct output.
However, the norm constraint fromSVM is replaced with a proximity constraint, indi-cating we want to update our parameters, but keepthem as close as possible to the previous parame-ter estimates.
In the original formulation for sepa-rable classification (Crammer and Singer, 2003), ifno constraints are violated, no update occurs.
How-ever, when there is a loss, the algorithm updates theparameters to satisfy the constraints.
To allow fornoise in the data, i.e.
nonseparable instances, a slackvariable ?i is introduced for each example, and weoptimize a soft-margin.
The usual presentation ofMIRA is then given as:wt+1 = argminw12||w ?wt||2 + C?is.t.
w>f(xi, yi)?w>f(xi, y?)
?
cost(yi, y?)?
?i(1)where f(xi, yi) is a vector of feature functions1, wis a vector of corresponding parameters, y?
?
Y(xi),where Y(xi) is the space of possible translations weare able to produce from x,2 and cost(yi, ?)
is com-puted using an external measure of quality, such asBLEU.The underlying structured hinge loss objectivefunction can be rewritten as:`h = ?w>f(xi, yi)+maxy?
?Y(xi)(w>f(xi, y?)
+ cost(yi, y?))
(2)2.2 Hypothesis SelectionOur training corpus T = (xi, yi)Ti=1 for selecting theparameters w that optimize this objective consists ofinput sentences xi in the source language paired withreference translations yi in the target language.
No-tice that `h depends on computing the margin be-tween y?
?
Y(xi) and the correct output, yi.
How-ever, there is no guarantee that yi ?
Y(xi) sinceour decoder is often incapable of producing the ref-erence translation yi.
Since we need to have somenotion of the correct output in order to compute itsfeature vector for the margin, in practice we revert tousing surrogate references in place of yi.
These areoften referred to as oracles, y+, which are selectedfrom the hypothesis space Y(xi) of the decoder.We are also faced with the problem of how bestto select the most appropriate y?
to shy away from,which we will refer to as y?.
Since optimization willproceed by setting parameters to increase the scoreof y+, and decrease the score of y?, the selectionof these two hypotheses is crucial to success.
Therange of possibilities is presented in Eq.
3 below.1More appropriately, since we only observe translationsyi, which may have many possible derivations dj , we modelthe derivations as a latent variable, and our feature functionsare actually computed over derivation and translation pairsf(xi, yi, dj).
We omit dj for clarity.2The entire hypergraph in hierarchical translation or latticein phrase based translation.481`r = ?
maxy+?Y(xi)(?+w>f(xi, y+)?
?+cost(yi, y+))+ maxy??Y(xi)(?
?w>f(xi, y?)
+ ?
?cost(yi, y?
))(3)Although this formulation has commonly beenreferred to as the hinge loss in previous litera-ture, Gimpel and Smith (2012) have recently pointedout that we are in fact optimizing losses that arecloser to different variants of the structured ramploss.
The difference in definition between the two issubtle, in that for the ramp loss, yi is replaced withy+.
Each setting of ??
and ??
corresponds to opti-mizing a different loss function.
Several definitionsof `r have been explored in the literature, and wediscuss them below with corresponding settings of??
and ?
?.In selecting y+, we vary the settings of ?+ and?+.
Assuming our cost function is based on BLEU,in setting ?+ ?
1 and ?+ ?
0, if Y(xi) is takento be the entire space of possible translations, weare selecting the hypothesis with the highest BLEUoverall.
This is referred to in past work as max-BLEU (Tillmann and Zhang, 2006) (MB).
If we ap-proximate the search space by restricting Y(xi) toa k-best list, we have the local-update (Liang etal., 2006), where we select the highest BLEU can-didate from those hypotheses that the model consid-ers good (LU).
With increasing k-best size, the max-BLEU and local-update strategies begin to converge.Setting both ?+ ?
1 and ?+ ?
1, we ob-tain the cost-diminished hypothesis, which consid-ers both the model and the cost, and corresponds tothe ?hope?
hypothesis in Chiang et al (2008) (M-C).
This can be computed over the entire space ofhypotheses or a k-best list.
In a sense, this is theintuition that local-updating is after, but expressedmore directly.The alternatives for selecting y?
are quite sim-ilar.
Setting ??
?
1 and ??
?
0, we selectthe hypothesis with the highest cost (MC).
Setting??
?
0 and ??
?
1, we have the highest scor-ing hypothesis according to the model, which cor-responds to prediction-based selection (Crammer etal., 2006) (PB).
Setting both to 1, we have the cost-augmented hypothesis, which is referred to as the?fear?
(Chiang et al, 2008), and max-loss (Cram-mer et al, 2006) (M+C).
This hypothesis is consid-ered the most dangerous because it has a high modelscore along with a high cost.Considering the settings for both parts of Eq.
3,?+, ?+ and ?
?, ?
?, assigning all ??
and ??
to 1corresponds to the most commonly used loss func-tion in MT (Gimpel and Smith, 2012; Chiang etal., 2009).
This is the ?hope?/?fear?
pairing, wherewe use the cost-diminished hypothesis y+ and cost-augmented hypothesis y?.
Other loss functions havealso been explored, such as ??
?
1, ?+ ?
1,??
?
0 (Liang et al, 2006), and something ap-proximating ??
?
1, ?+ ?
0, ??
?
1 (Cherryand Foster, 2012), which is closer to the usual lossused for max-margin in machine learing.
To our bestknowledge, other loss functions explored below arenovel to this work.Since our external metric, BLEU, is a gain, we canthink of the first term in Eq.
3 as the model score plusthe BLEU score, and the second term as the modelminus the BLEU score.
That is, with all ??
and ?
?set to 1, we want y+ to be the hypothesis with ahigh model score, as well as being close to the refer-ence translation, as indicated by a high BLEU score.While for y?, we want a high model score, but itshould be far away from the reference, as indicatedby a low BLEU score.
The motivation for choosingy?
in this fashion is grounded in the fact that sincewe are penalized by this term in the ramp loss ob-jective, we should try to optimize on it directly.
Inpractice, we can compute the cost for both terms as(1-BLEU(y,yi)), or use that as the cost of the firstterm, and after selecting y+, compute the cost of y?by taking the difference between BLEU(y+,yi) andBLEU(y,yi).The ramp loss objectives are non-convex, and byseparately computing the max for both y+ and y?,we are theoretically prohibited from online learningsince we are no longer guaranteed to be optimizingthe desired loss.
This is one motivation for the batchlearner, RAMPION (Gimpel and Smith, 2012).
How-ever, as with many non-convex optimization prob-lems in NLP, such as those involving latent vari-ables, in practice online learning in this setting be-haves quite well.4822.3 Parameter UpdateThe major practical concern with these methods forSMT is that oftentimes the implementation aspectis unclear, a problem which is further exacerbatedby the apparent difficulty of implementation.
Thisis further compounded with a lack of standard prac-tices; both theoretical, such as the objective to op-timize, and practical, such as efficient paralleliza-tion.
The former is a result of the disconnect be-tween the standard machine learning setting, whichposits reachable references and lack of latent vari-ables, and our own application.
The latter is anactive engineering problem.
Both of these aspectshave been receiving recent attention (McAllester etal., 2010; Mcallester and Keshet, 2011; Gimpel andSmith, 2012; McDonald et al, 2010), and althoughcertain questions remain as to the exact loss beingoptimized, we now have a better understanding ofthe theoretical underpinnings of this method of opti-mization.The first adaptations of MIRA-based learning forstructured prediction in NLP utilized a set of k con-straints, either for y+, y?, or both.
This complicatedthe optimization by creating a QP problem with a setof linear constraints which needed to be solved witheither Hildreth?s algorithm or SMO style optimiza-tion, thereby precluding the possibility of a sim-ple analytical solution.
Later, Chiang (2012) intro-duced a cutting-plane algorithm, like that of Struc-tural SVM?s (Tsochantaridis et al, 2004), which op-timizes on a small set of active constraints.While these methods of dealing with structuredprediction may perform better empirically, theycome with a higher computational cost.
Crammeret al (2006) shows that satisfying the single mostviolated margin constraint, commonly referred toas 1-best MIRA, is amenable to a simple analyt-ical solution for the optimization problem at eachstep.
Furthermore, the 1-best MIRA update is con-ceptually and practically much simpler, while retain-ing most of the optimization power of the more ad-vanced methods.
Thus, this is the method we presentbelow.Since the MIRA optimization problem is an in-stance of a general structured problem with an `2norm, the update at each step reduces to dual co-ordinate descent (Smith, 2011).
In our soft-marginAlgorithm 1 MIRA TrainingRequire: : Training set T = (xi, yi)Ti=1, w, C1: for j ?
1 to N do2: for i?
1 to T do3: Y(xi)?Decode(xi,w)4: y+ ?
FindOracle(Y(xi))5: y?
?
FindPrediction(Y(xi))6: margin?
w>f(xi, y?
)?w>f(xi, y+)7: cost?
BLEU(yi, y+)?
BLEU(yi, y?
)8: loss = margin + cost9: if loss > 0 then10: ?
?
min(C, loss?f(xi,y+)?f(xi,y?
)?2)11: w?
w+ ?
(f(xi, y+)?
f(xi, y?
))12: end if13: end for14: end for15: return wAlgorithm 2 FindOracleRequire: : Y(xi)1: if ?+=0 and ?+=1 then2: y+ ?
argmaxy?Y(xi)?cost(yi, y)3: else if ?+ = ?+ = 1 then4: y+ ?
argmaxy?Y(xi)w>f(xi, y) ?cost(yi, y)5: end if6: return y+setting, this is analogous to the PA-I update of Cram-mer et al (2006).
In fact, this update remains largelyintact as the inner core within k-best constraint orcutting plane optimization.
Algorithm 1 presents theentire training regime necessary for 1-best MIRAtraining of a machine translation system.
As can beseen, the parameter update at step 11 depends on thedifference between the features of y+ and y?, where?
is the step size, which is controlled by the regular-ization parameter C; indicating how far we are will-ing to move at each step.
Y(xi) may be a k-best listor the entire space of hypotheses.33For a more in depth examination and derivation of large-margin learning in MT, see (Chiang, 2012).483Algorithm 3 FindPredictionRequire: : Y(xi)1: if ?
?=0 and ?
?=1 then2: y?
?
argmaxy?Y(xi) cost(yi, y)3: else if ?
?=1 and ?
?=0 then4: y?
?
argmaxy?Y(xi)w>f(xi, y)5: else if ??
= ??
= 1 then6: y?
?
argmaxy?Y(xi)w>f(xi, y) +cost(yi, y)7: end if8: return y?3 Experiments3.1 SetupTo empirically analyze which loss, and therebywhich strategy, for selecting y+ and y?
is mostappropriate for machine translation, we conducteda series of experiments on Czech-to-English andFrench-to-English translation.
The parallel corporaare taken from the WMT2012 shared translationtask, and consist of Europarl data along with theNews Commentary corpus.
All data were tokenizedand lowercased, then filtered for length and alignedusing the GIZA++ implementation of IBM Model4 (Och and Ney, 2003) to obtain bidirectional align-ments, which were symmetrized using the grow-diag-final-and method (Koehn et al, 2003).
Gram-mars were extracted from the resulting parallel textand used in our hierarchical phrase-based system us-ing cdec (Dyer et al, 2010) as the decoder.
We con-structed a 5-gram language model from the providedEnglish News monolingual training data as well asthe English side of the parallel corpus using the SRIlanguage modeling toolkit with modified Kneser-Ney smoothing (Chen and Goodman, 1996).
Thiswas used to create a KenLM (Heafield, 2011).As the tuning set for both language pairs, we usedthe 2051 sentences in news-test2008 (NT08), and re-port results on the 2525 sentences of news-test2009(NT09) and 2489 of news-test2010 (NT10).Corpus Sentences Tokensen *cs-en 764K 20.5M 17.5Mfr-en 2M 57M 63MTable 1: Corpus statisticspair 1 500 50k 100kcs-en 17.9 24.9 29.4 29.7fr-en 20.25 29.9 33.8 34.1Table 2: Oracle score for model 1-best (baseline) and fork-best of size 500, 50k, and 100k on NT08We approximate cost-augmented decoding by ob-taining a k-best list with k=500 unique best from ourdecoder at each iteration, and selecting the respec-tive hypotheses for optimization from it.
To approx-imate max-BLEU decoding using a k-best list, we setk=50k unique best hypotheses.4 As can be seen inTable 2, we found this size was sufficient for our pur-poses as increasing size led to small improvementsin oracle BLEU score.
C is set to 0.01.For comparison with MERT, we create a base-line model which uses a small standard set of fea-tures found in translation systems: language modelprobability, phrase translation probabilities, lexi-cal weighting probabilities, and source word, pass-through, and word penalties.While BLEU is usually calculated at the corpuslevel, we need to approximate the metric at the sen-tence level.
In this, we mostly follow previous ap-proaches, where in the first iteration through the cor-pus we use a smoothed sentence level BLEU approx-imation, similar to Lin and Och (2004), and in sub-sequently iterations, the BLEU score is calculated inthe context of the previous set of 1-best translationsof the entire tuning set.To make parameter estimation more efficient,some form of parallelization is preferred.
While ear-lier versions of MIRA training had complex paral-lelization procedures which necessitated passing in-formation between learners, performing iterative pa-rameter mixing (McDonald et al, 2010) has beenshown to be just as effective (Chiang, 2012).
Weuse a simple implementation of this regime, wherewe divide the tuning set into n shards and distributethem amongst n learners, along with the parametervectorw.
Each learner decodes and updates parame-4We are able to theoretically extract more constraints froma large list, in the spirit of k-constraints or a cutting plane,but Chiang (2012) showed that cutting plane performance isapproximately 0.2-0.4 BLEU better than a single constraint, soalthough there is a trade off between the simplicity of a singleconstraint and performance, it is not substantial.484cs-en NT09 NT10LU M-C LU M-CPB 16.4 18.3 17 19.3MC 18.5 16 19.1 17.5M+C 17.8 18.7 18.4 19.6Table 3: Results with different strategies on cs-en transla-tion.
MERT baseline is 18.4 for NT09 and 19.7 for NT10ters on its shard of the tuning set, and once all learn-ers are finished, these n parameter vectors are aver-aged to form the initial parameter vector for the nextiteration.
In our experiments, n=20.3.2 ResultsThe results of using different optimization strategiesfor cs-en and fr-en are presented in Tables 3 and 4below.
For all experiments, all settings are kept ex-actly the same, with the only variation being the se-lection of the oracle y+ and prediction y?.
The firstcolumn in each table indicates the method for se-lecting the prediction, y?.
PB indicates prediction-based, MC is the hypothesis with the highest cost,and M+C is cost-augmented selection.
Analogously,the headings across the table indicate oracle selec-tion strategies, with LU indicating local updating,and M-C being cost-diminished selection.From the cs-en results in Table 3, we can see thattwo settings fair the best: LU oracle selection pairedwith MC prediction selection (LU/MC), and M-Coracle selection paired with M+C prediction selec-tion (M?C).
On both sets, (M?C) performs better,but the results are comparable.
Pairing M-C withPB is also a viable strategy, while no other pairing issuccessful for LU.When comparing with MERT, note that we usea hypergraph based MERT (Kumar et al, 2009),while the MIRA updates are computed from a k-bestlist.
For max-BLEU oracle selection paired with MC,the performance decreases substantially, to 15.4 and16.6 BLEU on NT09 and NT10, respectively.
Usingthe augmented k-best list did not significantly affectperformance for M-C oracle selection.For fr-en, we see much the same behavior as incs-en.
However, here LU/MC slightly outperformsM?C.
From both tasks, we can see that LU is moresensitive to prediction selection, and can only op-fr-en NT09 NT10LU M-C LU M-CPB 20.5 23.1 22.2 25MC 23.9 23 25.8 24.8M+C 22.2 23.6 24 25.4Table 4: Results with different strategies on fr-en transla-tion.
MERT baseline is 24.2 for NT09 and 26 for NT10timize effectively when paired with MC.
M-C onthe other hand, is more forgiving, and can makeprogress with PB and MC, albeit not as effectivelyas with M+C.3.3 Large Feature SetSince one of the primary motivations for large-margin learning is the ability to effectively handlelarge quantities of features, we further evaluate theability of the strategies by introducing a large num-ber of sparse features into our model.
We introducesparse binary indicator features of the form com-monly found in MT research (Chiang et al, 2009;Watanabe et al, 2007).
Specifically, we introducetwo types of features based on word alignment fromhierarchical phrase pairs and a target bigram fea-ture.
The first type, a word pair feature, fires forevery word pair (ei, fj) observed in the phrase pair.The second, insertion features, account for spuriouswords on the target side of a phrase pair by firing forunaligned target words, associating them with ev-ery source word, i.e.
(ei, fj), (ei, fj+1), etc.. Thetarget bigram feature fires for every pair of consec-utive words on the target side (ei, ei+1).
In all, weintroduce 650k features for cs-en, and 1.1M for fr-en.
Taking the two best performing strategies fromthe baseline model, LU/MC and M?C, we comparetheir performance with the larger feature set in Ta-ble 5.Although integrating these features does not sig-nificantly alter the performance on either task, ourpurpose was to establish once again that the large-margin learning framework is capable of effectivelyoptimizing parameters for a large number of sparsefeatures in the MT setting.4850.070.120.170.220.270.321 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20BLEUIterationFigure 1: Comparison of performance on development setfor cs-en when using LU/MC and M?C selection.0.070.120.170.220.270.320.370.421 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20BLEUIterationFigure 2: Comparison of performance on development setfor fr-en when using LU/MC and M?C selection.fr-en cs-enNT09 NT10 NT09 NT10LU/MC 23.9 25.7 18.5 19.6M?C 23.8 25.4 18.6 19.6Table 5: Results on cs-en and fr-en with extended featureset.4 DiscussionAlthough the performance of the two strategies iscompetitive on the evaluation sets, this does not re-lay the entire story.
For a more complete view ofthe differences between optimization strategies, weturn to Figures 1-6.
Figure 1 and 2 present thecomparison of performance on the NT08 develop-ment set for cs-en and fr-en, respectively, when us-ing LU/MC to select the oracle and prediction ver-sus M?C selection.
M?C is indicated with a solidblack line, while LU/MC is a dotted red line.
Thecorpus-level oracle and prediction BLEU scores ateach iteration are indicated with error bars aroundeach point, using solid lines for M?C and dottedlines for LU/MC.
As can be seen in Figure 1, whileoptimizing with M?C is stable and smooth, wherewe converge on our optimum after several iterations,optimizing with LU/MC is highly unstable.
This isat least in part due to the wide range in BLEU scoresfor the oracle and prediction, which are in the rangeof 10 BLEU points higher or lower than the currentmodel best.
On the contrary, the range of BLEUscores for the M?C optimizer is on the order of 2BLEU points, leading to more gradual changes.We see a similar, albeit slightly less pronouncedbehavior on fr-en in Figure 2.
M?C optimizationis once again smooth, and converges quickly, witha small range for the oracle and prediction scoresaround the model best.
LU/MC remains unstable,oscillating up to 2 BLEU points between iterations.Figures 3-6 compare the different optimizationstrategies further.
In Figures 3 and 5, we use M-Cas the oracle, and show performance on the develop-ment set while using the three prediction selectionstrategies, M+C with a solid blue line, PB with adotted green line, and MC with a dashed red line.Error bars indicate the oracle and prediction BLEUscores for each pairing as before.
In all three cases,the oracle BLEU score is in about the same range,as expected, since all are using the same oracle se-lection strategy.
We can immediately observe thatPB has no error bars going down, indicating that thePB method for selecting the prediction keeps pacewith the model best at each iteration.
On the otherhand, MC selection also stands out, since it is theonly one with a large drop in prediction BLEU score.Crucially, all learners are stable, and move towardconvergence smoothly, which serves to validate ourearlier observation that M-C oracle selection can bepaired with any prediction selection strategy and op-timize effectively.
In both cs-en and fr-en, we canobserve that M?C performs the best.In Figures 4 and 6, we use LU as the oracle, andshow performance using the three prediction selec-tion strategies, with each line representing the samestrategy as described above.
The major difference,which is immediately evident, is that the optimizersare highly unstable.
The only pairing which showssome stability is LU/MC, with both the other predic-4860.050.070.090.110.130.150.170.190.210.230.251 2 3 4 5 6 7 8 9 10BLEUIterationFigure 3: Comparison of performance on development setfor cs-en of the three prediction selection strategies whenusing M-C selection as oracle.0.050.10.150.20.250.30.351 2 3 4 5 6 7 8 9 10BLEUIterationFigure 4: Comparison of performance on development setfor cs-en of the three prediction selection strategies whenusing LU selection as oracle.0.050.10.150.20.250.31 2 3 4 5 6 7 8 9 10BLEUIterationFigure 5: Comparison of performance on development setfor fr-en of the three prediction selection strategies whenusing M-C selection as oracle.0.050.10.150.20.250.30.350.41 2 3 4 5 6 7 8 9 10BLEUIterationFigure 6: Comparison of performance on development setfor fr-en of the three prediction selection strategies whenusing LU selection as oracle.tion selection methods, PB and M+C significantlyunderperforming it.Given that the translation performance of optimiz-ing the loss functions represented by LU/MC andM?C selection is comparable on the evaluation setsfor fr-en and cs-en, it may be premature to makea general recommendation for one over the other.However, taking the unstable nature of LU/MC intoaccount, the extent of which may depend on the tun-ing set, as well as other factors which need to befurther examined, the current more prudent alterna-tive is selecting the oracle and prediction pair basedon M?C.5 ConclusionIn this paper, we strove to elucidate aspects of large-margin structured learning with concrete applicationto the MT setting.
Towards this goal, we presentedthe MIRA passive-aggressive algorithm, which canbe used directly to effectively tune a statistical MTsystem with millions of parameters, in the hope thatsome confusion surrounding MIRA-based methodsmay be cleared, and more MT researchers can adoptit for their own use.
We then used the presented al-gorithm to empirically compare several widespreadloss functions and strategies for selecting hypothe-ses for optimization.
We showed that although thereare two competing strategies with comparable per-formance, one is an unstable learner, and before weunderstand more regarding the nature of the insta-bility, the preferred alternative is to use M?C as thehypothesis pair in optimization.AcknowledgmentsWe would like to thank the anonymous reviewersfor their comments.
The author is supported bythe Department of Defense through the NationalDefense Science and Engineering Graduate Fellow-487ship.
Any opinions, findings, conclusions, or rec-ommendations expressed are the author?s and do notnecessarily reflect those of the sponsors.ReferencesAbishek Arun and Philipp Koehn.
2007.
Online learningmethods for discriminative training of phrase basedstatistical machine translation.
In MT Summit XI.Stanley F. Chen and Joshua Goodman.
1996.
An empir-ical study of smoothing techniques for language mod-eling.
In Proceedings of the 34th Annual Meeting ofthe Association for Computational Linguistics, pages310?318.Colin Cherry and George Foster.
2012.
Batch tuningstrategies for statistical machine translation.
In Pro-ceedings of NAACL.David Chiang, Yuval Marton, and Philip Resnik.
2008.Online large-margin training of syntactic and struc-tural translation features.
In Proceedings of the 2008Conference on Empirical Methods in Natural Lan-guage Processing, Honolulu, Hawaii, October.David Chiang, Kevin Knight, and Wei Wang.
2009.11,001 new features for statistical machine transla-tion.
In Proceedings of Human Language Technolo-gies: The 2009 Annual Conference of the North Ameri-can Chapter of the Association for Computational Lin-guistics, NAACL ?09, pages 218?226.David Chiang.
2012.
Hope and fear for discriminativetraining of statistical translation models.
To appear inJ.
Machine Learning Research.Koby Crammer and Yoram Singer.
2003.
Ultraconser-vative online algorithms for multiclass problems.
J.Mach.
Learn.
Res., 3:951?991, March.Koby Crammer, Ofer Dekel, Joseph Keshet, Shai Shalev-Shwartz, and Yoram Singer.
2006.
Online passive-aggressive algorithms.
J. Mach.
Learn.
Res., 7:551?585.Chris Dyer, Adam Lopez, Juri Ganitkevitch, JonathanWeese, Ferhan Ture, Phil Blunsom, Hendra Setiawan,Vladimir Eidelman, and Philip Resnik.
2010. cdec: Adecoder, alignment, and learning framework for finite-state and context-free translation models.
In Proceed-ings of ACL System Demonstrations.George Foster and Roland Kuhn.
2009.
Stabilizingminimum error rate training.
In Proceedings of theFourth Workshop on Statistical Machine Translation,pages 242?249, Athens, Greece, March.
Associationfor Computational Linguistics.Kevin Gimpel and Noah A. Smith.
2012.
Structuredramp loss minimization for machine translation.
InProceedings of NAACL.Kenneth Heafield.
2011.
Kenlm: faster and smallerlanguage model queries.
In Proceedings of the SixthWorkshop on Statistical Machine Translation, WMT?11, pages 187?197.Mark Hopkins and Jonathan May.
2011.
Tuning as rank-ing.
In Proceedings of the 2011 Conference on Empir-ical Methods in Natural Language Processing, pages1352?1362, Edinburgh, Scotland, UK., July.
Associa-tion for Computational Linguistics.Philipp Koehn, Franz Josef Och, and Daniel Marcu.2003.
Statistical phrase-based translation.
In Pro-ceedings of the 2003 Conference of the North Ameri-can Chapter of the Association for Computational Lin-guistics on Human Language Technology - Volume 1,NAACL ?03, Stroudsburg, PA, USA.Shankar Kumar, Wolfgang Macherey, Chris Dyer, andFranz Och.
2009.
Efficient minimum error rate train-ing and minimum bayes-risk decoding for translationhypergraphs and lattices.
In Proceedings of the JointConference of the 47th Annual Meeting of the ACL andthe 4th International Joint Conference on Natural Lan-guage Processing of the AFNLP, pages 163?171.Percy Liang, Alexandre Bouchard-Co?te?, Dan Klein, andBen Taskar.
2006.
An end-to-end discriminative ap-proach to machine translation.
In Proceedings of the21st International Conference on Computational Lin-guistics and the 44th annual meeting of the Associ-ation for Computational Linguistics, ACL-44, pages761?768.Chin-Yew Lin and Franz Josef Och.
2004.
Orange: amethod for evaluating automatic evaluation metrics formachine translation.
In Proceedings of the 20th inter-national conference on Computational Linguistics.A.
F. T. Martins, K. Gimpel, N. A. Smith, E. P.Xing, P. M. Q. Aguiar, and M. A. T. Figueiredo.2010.
Learning structured classifiers with dual coor-dinate descent.
Technical Report CMU-ML-10-109,Carnegie Mellon University.David Mcallester and Joseph Keshet.
2011.
Generaliza-tion bounds and consistency for latent structural pro-bit and ramp loss.
In J. Shawe-Taylor, R.S.
Zemel,P.
Bartlett, F.C.N.
Pereira, and K.Q.
Weinberger, edi-tors, Advances in Neural Information Processing Sys-tems 24, pages 2205?2212.David McAllester, Tamir Hazan, and Joseph Keshet.2010.
Direct loss minimization for structured predic-tion.
In J. Lafferty, C. K. I. Williams, J. Shawe-Taylor,R.S.
Zemel, and A. Culotta, editors, Advances in Neu-ral Information Processing Systems 23, pages 1594?1602.Ryan McDonald, Koby Crammer, and Fernando Pereira.2005.
Online large-margin training of dependencyparsers.
In Proceedings of the 43rd Annual Meeting on488Association for Computational Linguistics, ACL ?05.Association for Computational Linguistics.Ryan McDonald, Keith Hall, and Gideon Mann.
2010.Distributed training strategies for the structured per-ceptron.
In Human Language Technologies: The 2010Annual Conference of the North American Chapter ofthe Association for Computational Linguistics, pages456?464, Los Angeles, California.Franz Och and Hermann Ney.
2003.
A systematic com-parison of various statistical alignment models.
InComputational Linguistics, volume 29(21), pages 19?51.Franz Josef Och.
2003.
Minimum error rate training instatistical machine translation.
In Proceedings of the41st Annual Meeting of the Association for Computa-tional Linguistics, pages 160?167.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
BLEU: a method for automatic eval-uation of machine translation.
In Proceedings of 40thAnnual Meeting of the Association for ComputationalLinguistics, pages 311?318.David A. Smith and Jason Eisner.
2006.
Minimumrisk annealing for training log-linear models.
In Pro-ceedings of the COLING/ACL 2006 Main ConferencePoster Sessions, Sydney, Australia, July.
Associationfor Computational Linguistics.Noah A. Smith.
2011.
Linguistic Structure Predic-tion.
Synthesis Lectures on Human Language Tech-nologies.
Morgan and Claypool, May.Christoph Tillmann and Tong Zhang.
2006.
A discrim-inative global training algorithm for statistical mt.
InProceedings of the 21st International Conference onComputational Linguistics and the 44th annual meet-ing of the Association for Computational Linguistics,ACL-44, pages 721?728.Ioannis Tsochantaridis, Thomas Hofmann, ThorstenJoachims, and Yasemin Altun.
2004.
Support vec-tor machine learning for interdependent and structuredoutput spaces.
In Proceedings of the twenty-first inter-national conference on Machine learning, ICML ?04.Taro Watanabe, Jun Suzuki, Hajime Tsukada, and HidekiIsozaki.
2007.
Online large-margin training for sta-tistical machine translation.
In Proceedings of the2007 Joint Conference on Empirical Methods in Natu-ral Language Processing and Computational NaturalLanguage Learning (EMNLP-CoNLL), Prague, CzechRepublic, June.
Association for Computational Lin-guistics.Taro Watanabe.
2012.
Optimized online rank learningfor machine translation.
In Proceedings of NAACL.489
