Automatic Adaptation of WordNet to Sublanguages and toComputational TasksRoberto Basil i(+) Alessandro Cucchiarelli (*) Carlo Consoli (+)Maria Teresa Pazienza (+) Paola Velardi (~)(+) Univer,fita' di Roma Tor Vergata (ITALY)(*) Universita' di Ancona (ITALY)(#) Universita' di Roma, La Sapienza (ITALY)Abst rac tSemantically tagging a corpus is useful for manyintermediate NLP tasks such as: acquisition ofword argument structures in sublanguages, ac-quisition of syntactic disambiguation cues, ter-minology learning, etc.
Semantic ategories al-low the generalization of observed word pat-terns, and facilitate the discovery of irecurrentsublanguage phenomena and selectional rules ofvarious types.
Yet, as opposed to POS tags inmorphology, there is no consensus in literatureabout the type and granularity of the categoryinventory.
In addition, most available on-linetaxonomies, as WordNet, are over ambiguousand, at the same time, may not include manydomain-dependent senses of words.
In this pa-per we describe a method to adapt a generalpurpose taxonomy to an application sub\[an-guage: flint, we prune branches of the Wordnethierarchy that are too " fine grained" for the do-main: then.
a statistical model of classes is builtfrom corpus contexts to sort the different classi-fications or assign a classification to known andunknown words, respectively.1 In t roduct ionLexical learning methods based on the use ofsemantic ategories are faced with the problemof overambiguity and entangled structures ofThesaura and dictionaries.
WordNet and Ro-get's Thesaura were not initially conceived, de-spite their success among researchers in lexi-cal statistics, as tools for automatic languageprocessing.
The purpose was rather to pro-vide the linguists with a very refined, generalpurpose, linguistically motivated source of tax-onomic knowledge.
As a consequence, in moston-fine Thesaura words are extremely ambigu-ous.
with very subtle distinctions among senses.High ambiguity, entangled nodes, and asymme-try have already been emphasized in (Hearstand Shutze, 1993) as being an obstacle to theeffective use of on-line Thesaura in corpus lin-guistics.
In most cases, the noise introducedby overambiguity almost overrides the positiveeffect of semantic lustering.
For example, in(BriIl and Resnik, 1994) clustering PP heads ac-cording to WordNet synsets produced only a \[%improvement in a PP disambiguation task.
withrespect o the non-clustered method.
A subse-quent paper (Resnik.
1997) reports of a 40%precision in a sense disambiguation task.
al-ways based on generalization through WordNetsynsets.
Context-based sense clisambiguationbecomes a prohibitive task on a wide-scale basis,because when words in the context of unambigu-ous word are replaced by their s.vnsets, thereis a multiplication of possible contexts, ratherthan a generalization.
\[n (Agirre and Rigau.1996) a method called Conceptual Distance isproposed to reduce this problem, but the re-ported performance in disambiguation still doesnot reach 50%.
On the other hand, (Dolan.1994) and (Krovetz and Croft.
1992) claim thatfine-grained semantic distinctions are unlikelyto be of practical value for many applications.Our experience supports this claim: often, whatmatters is to be able to distinguish among con-trastive (Pustejowsky.
1995) ambiguities of thebank_river bank_organisation flavor.
The prob-lem however is that the notion of"coutrastive"is domain-dependent.
Depending upon the sub-language (e.g.
medicine, finance, computers.etc.)
and upon the specific NLP application(e.g.
Information Extraction, Dialogue etc.)
agiven semantic label may be too general or toospecific for the task at hand.
For example, theword line has 27 senses in WordNet.
many ofwhich draw subtle distinctions e.g.
line of ~cork(sense 26) and line of products (sense \[9).
In aa80IIIIIIIIIiIIIIIIIIapplication aimed at extracting information onnew products in an economic domain, we wouldbe interested in identi~-ing occurrences of suchsenses, but perhaps all the other senses couldbe clustered in one or two categories, lbr exam-ple Artifact, grouping senses uch as: telephone-line, railway and cable, and Abstraction, group-ing senses uch as series, conformity and indica-tion.
Vice versa, if the sublanguage is technicalhandbooks in computer science, we would liketo distinguish the cable and the string of wordssenses (7 and 5, respectively), while any otherdistinction may not have any practical interest.The research described in this paper is aimedat providing some principled, and algorithmic,methods to tune a general purpose taxonomy tospecific sublanguages and domains.In this paper, we propose a method by whichwe select a set of core semantic nodes in theWordNet taxonomy that  "optimally" describethe semantics of a sublanguage, according toa scoring function defined as a linear combi-nation of general and corpus-dependent perfor-mance factors.
The selected categories are usedto prune WordNet branches that appear, ac-cording to our scoring function, less pertinent tothe given sublanguage, thus reducing the initialambiguity.
Then, we learn from the applicationcorpus a statistical model of the core categoriesand use this model to further tune the initialtaxonomy.
Tuning implies two actions:The first is to attempt a reclassificationof relevant word:; in the corpus that arenot covered bv the selected categories,i.e.. words belonging exclusively to prunedbranches.
Often.
:hese words have domain-dependent .,;enses that are not captured inthe initial WordNet classification (,e.g.
thesoftware sense of release in a software hand-books sublanguage).
The decision to as-sign an unclassified word to one of the se-lected categories is based on a strong de-tected similarity between the contexts inwhich the word o.:curs, and the statisticalmodel of the core categories.The second iis to further educe the ambigu-itv of words that :;till have a high ambigu-ity, with respect o the other word.s in thecorpus.
For example, the word stock in a fi-nancial domain still preserved the gunstock81sense, because instrumentality was one ofthe selected core categories for the domain.The expectation of this sense ,nay be low-ered, as before, by comparing the typicalcontexts of stock with the acquired modelof instrumentality.In the next sections, we first describe the al-gorithm for selecting core categories.
Then, wedescribe the method for redistributing relevantwords among the nodes of the pruned hierarchy.Finally, we discuss an evaluation experiment.2 Se lec t ion  o f  core  categor ies  f romWordNetThe first step of our method is to select fromWordNet an inventory of core categories thatappear particularly appropriate for the domain.and prune all the hierarchy branches that doesnot belong to such core categories.
This choiceis performed as follows:Creat ion  of  a l te rnat ive  sets o f  ba lancedcategor iesFirst, an iterative method is used to create alter-native sets of balanced categories, using infor-mation on words and word frequencies in the ap-plication corpus.
Sets of categories have an in-creasing level of generality.
The set-generationalgorithm is an iterative application of the algo-rithm proposed in (Hearst and Sht, tze.
1993) forcreating WordNet categories of a fixed ~tveragesize.
\[n short .
the algorithm works as follows:Let C be a set of WordNet svnsets .
iV the setof different words (nouns) in the corpus.
P(C)the number of words ill W that are instancesof C. weighted by their frequency in the cor-pus, UB and LB the upper and lower boundfor P(C).
At each iteration step i. a new synsets is added to the current category set C~.
iffthe weight of s lies within the current bound-aries, that is.
P(s) <_ UBi and P(s) >_ LBi.If P(s) >_ UBi s is replaced in Ci by its de-scendants, for which the same constraints areverified.
If P(s) < LBi .
s is added to a list of"small;' categories SCT(C'i).
\[n fact.
when re-placing an overpopulated category by its sons.it may well be the case that some of its sons areunder populated.I The procedure new_cat\[S) is almost the same as in(Hearst and Shutze, 1993).
For sake of brevity, the algo-rithm is not explained in much details here.IIIIIIIScor ing A l te rnat ive  Sets o f  Categor iesSecond, a scoring function is applied to alter-native sets to identify the core set.
The coreset is modeled as the linear function of fourperformance factors: generality, coverage of thedomain, average ambiguity, and discriminationpower.
For a formal definition of these four mea-sures, see (Cucchiarelli and Velardi, 1997).
Weprovide here an intuitive description of thesefactors:Genera l i ty  (G): In principle, we would like torepresent the semantics of the domain using thehighest possible level of generalization.
A smallnumber of categories allows a compact repre-sentation of the semantic knowledge base, andrenders word sense disambiguation more sim-ple.
On the other side, over general categoriesfail to capture important distinctions.
The Gen-erality is a gaussian measure that mediates be-tween over generality and overambiguity.Coverage  (CO) This is a measure of the cov-erage that a given category set C'i has over thewords in the corpus.
The algorithm for balancedcategory selection does not allow a full coverageof the words in the domain: given a selectedpair < UB, LB >.
it may well be the case thatseveral words are not assigned to any category,because when branching from an overpopulatedcategory to its descendants, some of the descen-dants may be under populated.
Each iterativestep that creates a C, also creates a set of un-der populated categories SCT(Ci).
Clearly, a"good" selection of Ci is one that minimizes thisproblem (and has therefore a "high" coverage).D iscr iminat ion Power  (DP) :  A certain se-lection of categories may not allow a full dis-crimination of the lowest-level senses for a word(leaves-synsets hereafter).
For example, if psy-chological_feature is one of the core categories,and if we choose to tag a corpus only with corecategories, it would be impossible to discrimi-nate between the business-target and business-concern senses.
Though nothing can be saidabout the practical importance of discriminat-ing between such two synsets, in general a goodchoice of Ci is one that allows as much as possi-ble the discrimination between low level sensesof ambiguous words.Average  Ambigu i ty  (A) : Each choice of Ciin general reduces the initial ambiguity of thecorpus.
In part.
because there are leaves-synsetsthat converge into a single category of the set.in part because there are leaves-synsets of aword that do not reach any of these categories.Though in general we don't know if.
by cuttingout a node.
we are removing aset of senses inter-esting (or not) for the domain, still in principle82a good choice of categories i one that reduces asmuch as possible the initial ambiguity.
The cu-mulative scoring function for a set of categoriesCi is defined as the linear combination of theperformance parameters described above:Sco~( C'i ) = aG(C~) + 3C.
'0(C~) +1+,(DP(C~) +6A(G)  (t)Est imat ion o f  model  parameters  and re-f inementsAn interpolation method is adopted to estimatethe parameters of the model against a reference.correctly tagged, corpus (SemCor, tile WordNetsemantic oncordance).
The performance of al-ternative inventories of core categories i evalu-ated in terms of effective reduction of overam-biguity.
This measure is a combination of thesystem precision at pruning out spurious (forthe domain) senses, and the global reduction ofambiguity.
Notice that we are not measuringthe precision of sense disambiguation in con-texts, but simply the precision at reducing a-priori the set of possible senses for a word.
in agiven domain.The method above is weakly supervised: theparameters estimated have been used withoutre-estimation tocapture core categories in otherdomains such as Natural Science and a UNIXmanual.
Details on portability of this choice arein (Cucchiarelli and Velardi.
forthcoming 1998).In the different experiments, the best per-forming choice of core categories is the onewith an upper population of 62.000 words(frequency weighted).
This corresponds to thefollowing list of 14 categories:num.x:a.t=14 t=61 UB=62000 LB=24800 N=2000 k----IO00 h=O.40person, individuM, ~omeone.
mortal,  human,  soulin~trument.~lity, ins t rumentat ion~ttr |butewr|t  ten.~omm u nicatlon, wrltten-l~ngu~gemessage, content.
~ubject-m~tter.
3ubst.xncemeasuL'e, quantity,  amount,  quantum~ction:Lctivitygroup..~ctionorganiz~.ttonp~ychologlealMe~t urepoJLeJsioa.It ~,te|OC&ttOnThis selection of core categories i measuredto have the following performance:Precision: 77.6~.Reduction of Ambiguity: 37~IIIIII.IIIIIIIIIIIIICoverage: - ~?
'In (Cucchiarelli and Velardi, forthcoming1998) a method is proposed to automaticallyincrease the coverage of the core set with anadditional set of categories, selected from theset of under populated categories SCT(Ci) (seestep 1 of the algorithm).
With the extension:subt~nce, m&~tereventgathering, assemblagephenomenonsgructure,const ructionna~urxl.objectcreationthe following performance is obtained:Precision: 78,9%Reduction of Ambiguity: 26%Coverage: 93%With some manual refinement of the ex-tended set , the precision rises to over 80%.Obtaining a higher precision is difficult because,neither SemCor nor WordNet can be considereda golden standard.
In a recent workshop on se-mantic texts tagging (TAGWS 1997), the diffi-culty of providing comprehensible guidelines forsemantic annotators in order to avoid disagree-ment and inconsistencies was highlighted.
Onthe other side.
there are many redundancies andsome inconsistencies in WordNet that makes thetask of (manual) classification very complex.
Tomake an example, one of the detected classi-ficatiou errors in our Wall Street Journal ex-periment was the selection of two possible coresenses for the word market: : organization andact\[city.
Vice versa, in the economic fragmentof SemCor.
market is consistently classifies associo-economic-class, which happens not to bea descendent of any of these two categories.Our intuition when observing the specific exam-ples was more in agreement with the automaticclassification than with SemCor.
Our feelingwas that the selected core categories could, inmany cases, represent a good model of clas-.~ification for words that remained unclassifiedwith respect o the "not pruned" WordNet.
orappeared misclassified in our evaluation experi-i l l eu t .in the next section we describe an method toverify" this hypothesis and.
at the same time, tofurther tune WordNet to a domain.833 Red is t r ibut ion  of  words  amongcore  categor iesThe purpose of the method described hereafteris twofold:?
The first is to attempt a reclassification ofwords that are not classified, or appeared asmisclassified, with respect o the "'original"WordNet.?
The second is to further reduce the ambi-guity of words that are still very ambigu-ous with respect to the "pruned" Word-Net.
The general idea is that ambiguityof words is reduced in a specific domain,and enumeration of all their senses is un-necessary.
Second, some words function assense primers for others.
Third, raw con-texts of words provide a significant bundleof information to guide disambiguation.To verify this hypothesis ystematically weneed to acquire from the corpus a contextualmodel of the core categories, and then verifyto what extent certain "interesting" words (forexample, unclassified words) adhere to the con-textual model of one of such categories.Our method, inspired by (Yarowsky, t992),works as follows (see (Basil\[ et al 1997} for de-tails}:?
Step 1.
Select the most typical words ineach core category:Step 2.
Acquire the collective contexts ofthese words and use them ms a (distribu-tional) description of each category:Step 3.
Use tile distributional descrip-tions to evaluate the (corpus-dependent)membership of each word to the differentcategories.Step l is carried out detecting tile more sig-nificant (and less ambiguous) words in any ofthe core classes : these sets are called the kernelof the corresponding class.
Rather than train-ing the classifier on all the nouns in tile learningcorpus ,as in (Yarowsky.
\[992).
we select only asubset of protot!lpical words for each category.We call these words w the salient words of aIIIIIIIIIIIIIIIIIIIcategory C'.
We define the typicality T~(C') ofw in C, as:Nw,c _ - -  (2)I'V wwhere:,V,, is the total number of synsets of a word w, i.e.all the WordNet synonymy sets including w..V,o.c is the number of synsets of w that belong tothe semantic ategory C, i.e.
synsets indexed withC in WordNet.The typicality depends only on WordNet.
Atypical noun for a category C is one that is ei-ther non ambiguously assigned to C in Word-Net, or that has most of its senses (synsets) inC.The synonymy S~, of w in C, i.e.
the degreeof synonymy showed by words other than w inthe synsets of the class C in which w appears.is modeled by the following ratio:s , , , ( c ) _  o ,c (3)O~where:O,.
is the number of words in the corpus that appearin at least one of the synsets of w.O, : .c  is the number of words in the corpus appearingill at least one of the synsets of w, that belong to C."\['lie synonymy depends both on WordNetand on the corpus.
A noun with a high de-gree of synonymy in C is one with a high num-ber of synonyms in the corpus, with referenceto a specific sense (synset) belonging to C.Salient nouns for C are frequent, typical, andwith a high synonymy in C. The salient wordsw.
for a semantic ategory C, are thus identifiedmaximizing the following function, that we callSPo l'{~ := 0 .% ?
?
S,.
(C') (4)where O.4~, are the absolute occurrences of win the corpus.
The value of Score depends bothon the corpus and on '~,brdNet.
O.4~, dependsobviously on the corpus.The kernel of a category kernel(C), is the setof salient words w with a "high" 5core~(C).
In,\[,able I some kernel words for the class gather-ing.as.~emblage r  reported.Step 2 uses the kernel words to build (asin (Yarowsky.
i992)) a probabilistic model of a84Table 1: Some kernel elements for classgathering, assemblageScore Word  Score Word17:0.68835 executive 0.11108 business0.55539 senate 0.11108 household0.33828 public 0.10014 council0.28485 court 0.08920 school0.23815 family 0.08864 session0.20869 commune 0.08780 form0.14839 press 0.08667 town0.11907 vote 0.07868 staffclass: this model is based on the distributionof class relevance of the surrounding terms intypical contexts.In Step 3 a word is assigned to one.
or more,classes according to the contexts in which itappears.
Many contexts may enforce the se-lection of a given class, or multiple classifica-tions are possible when different contexts ug-gest independent classes.
For a given wordw, and for each category C, we evaluate thefollowing function, that we call Domain Sense(DSense(w, C)):where1 DSense(w.C) = -~= ~ Y(k.C') (5)kY(k'.C) = ~ Pr(..'.
(') ?
Pr(C),L,'6~:(6)where k's are tile contexts of w. and a" is ageneric word in k.In (6), P r (C) i s  the (not uniform) probability ofa class C, given by the ratio between the num-ber of collective contexts for (7' 2 and the totalnumber of collective contexts.4 D iscuss ion  o f  the  exper imentIn this section we describe some preliminary re-suits of an experiment conducted on tile WallStreet Journal.
We used 21 categories including\[4 core categories plus 7 additional categoriesobtained with automatic extension of tile bestcore set (see section 2).
\[n experiment I. weselected the 6 most frequent unclassified wordsin the corpus, and attempted a reclassification"those collected around the kernel words of Caccording to the contextual description of the21 categories.
In experiment 2, we selected the6 most frequent and still very ambiguous (ac-cording to the pruned WordNet) words, andattempted a reduction of ambiguity.
For eachword w and each category C, we compute theDSense(w, C) and then select only those sensesthat exhibit a membership value higher than theaverage membership of kernel words of C. Theassignment ofa word to a category is performedregardless of the current classification of w inthe pruned WordNet.The following Table 2 summarizes the resultsof experiment 1:Table 2: Selected categories for some unclassi-fied wordsWord/ f req  Selected cate~;oriesw~.11/447 g~.t her in  g, w r i f t  e n .x:o m m u nic~.tio n,o  r &a.nizatio npert tagon/183  gat  h e r in g,\[oc ~,tio n.o  rga.niza.t io npeop le /g73  g~ther ingx i rpor t /$9  co nst ruc t ion , loc~t ioncongress /456 ~;a.therin~,personTable 3 reports on experiment 2.
\[n column3.
selected categories are reported in decreasingorder of class membership evidence.Ia Table 2, notice the apparently "strange"classification of wall.
The problem is that, inthe current version of our system, proper nounsare not correctly detected (this problem willTable 3: Selected and Initial WN categories forsome very ambiguous wordsW ~,rd,  I r cq,hare/347?~pr ice /2132b~nk/ t3 t3b , t :one J$ / l  "~63bo.nd/ l .366I In l l l a l  W 31 categor tcswr| t te  n-co rn rn un i t  ~t lonpoJsesslonr roup-} ,c t lonact iv i tymst rumert ta .
l i tyw r l t ten -com rnu n lc&t lonposres.~ionper.~onn&tur l l~b jectIn~t r u menta.lit~?rne~saKe,contentpo.
.se~ion.~tt r lbuteorga, n l z3t ionpoJJe~Jioni ns t rumenta l i tyr ta tura l .Ob lectgroq p.-~ctlonorg~,nlz~tiong~,theringp~ych, featureact iv i typo~Je$$ion~tt r ibutephenomenonmi t rurnent l l i tvSe lec ted  cat  cgor ie r ,w r i t  t e n ..co m m urt tc.~.t,o rtposse J~ iongrou  p .
.xct ionw r l t t  en .xomrn  un|c~t lor tpossess ionpersortines~a$te,con terttpossesJion~tt r lbuteor&~niz~t ionpossessiongroup_~ct lo r tor gan iz~.
t long~therm&cre~tlortpo$$e$~|orl,1.t r ib  u te85be fixed shortly) since in the Wall Street Jour-nal there is no special syntactic tag for propernames.
Erroneously, several proper names, suchas Wall Street, Wall Street Journal, Bush, Delta.Apple, etc.
were initially classified as commonnouns, therefore causing some noise in the datathat we need now to eliminate 3.The word wall is in fact part of the com-plex nominals Wall Street and Wall StreetJournal, and it is very interesting that.based on the context, the system classifiesit correctly in the three categories: gather-ing, written_communication, rganization Noticethat the category: "gathering, assemblage" hassomehow an unintuitive label, but in the WSJdomain this class includes rather uniform words,most of which refer to political organizations, asshown in Table 1.In Table 3. it is shown that often some reduc-tion of ambiguity is possible.
However.
somespurious senses survive, for example, the pro-genitor (person) sense of stock.
\[t is very im-portant that.
in all tile analyzed cases, the se-lected classes are a subset of the initial Word-Net classes: remember that the assignment ofa word to a category is performed only on thebasis of its computed membership to that cat-egory.
There is one example of additional de-tected sense (not included in the pruned Word-Net), i.e.
the sense creation for the word hood.Typical (for the domain) words in this class are:plan.
yeld.
software, magazine, jottroal, is.~,e.etc.
therefore, the creation sense seems appro-priate.Clearly.
we need to perform a better (inthe large} experimentation, but the first resultsseem encouraging.
A large scale experiment re-quires, besides a better tuning of the statisticalparameters and fixing some obvious bug (e.g.the identification of proper nouns}, the prepara-tion of a test set in which the correct classifica-tion of a large nurnber of words is verified man-ually in the actual corpus contexts.
Finally, ex-periments should be extended to domains otherthan WordNet.
We already experimented thealgorithm for core category selection on a UNIXcorpus and on a small Natural Science corpus.but again, extending the complete experimentFor example, the addit ional category n,Oftrrtl.x, bjectwas created because of rhe high frequency of spuriousnouns as apple, delta, b lsh.
etc.IIIIIIIIIIIIIIIIIIto other corpora is not trivial for the requiredintensive linguistic and statistical corpus pro-cessiug.5 References(Agirre and Rigau, 1996) E. Agirre and G. Rigau,Word'Sense Disambiguation using ConceptualDensity, proc.
of COLING 1996Basili, Della Rocca, Pazienza, 1997) R. Basili,M.Della Rocca, M.T.
Pazienza, Towards aBootstrapping Fr'amework for Corpus SemanticTagging, in (TAGWS 1997)Basili et al 1995b.)
Basili R., M. Della Rocca,M.T.
Pazienza, P. Velardi.
"Contexts and cat-egories: tuning a general purpose verb clas-sification to sublanguages".
Proceeding ofRANLP95, Tzigov Chark, Bulgaria, 1995.Brill and Resnik, /994) E. Brill and P. Resnik, Atransformation-based approach to prepositionalphrase attachment disambiguation, proc.
ofCOLING 1994(Chen and Chen, 1996) K. Chen and C. Chen,A rule-based and MT-oriented Approach toPrepositional Phrase Attachment, proc.
ofCOLING 1996(Cucchiarelli and Velardi.
forthcoming 1998) Cuc-chiarelli A., Velardi P. "Finding a Domain-Appropriate Sense Inventory for SemanticallyTagging aCorpus" Int.
Journal of Natural Lan-guage Engineering, in press.
1998(Cucchiarelli and Velardi, 1997) Cucchiarelli A., Ve-lardi P. "Automatic Selection of Class Labelsfrom a Thesaurus for an Effective Semantic Tag-ging of Corpora", 6th Conf.
on Applied Nat-ural Language Processing, ANLP97.
Washing-toll.
April t-3 1997(Dolau.
1994) W. Dolan.
Word Sense Ambiguation:Clustering Related Senses.
Proc.
of Coling 1994(Felibaum.
\[997) C. Fellbaum.
"'Analysis of a hand-tagging task" in (TAGWS 1997).
(Hearst and Schuetze.
1993) M. Hearst and H.Schuetze.
Customizing a Lexicon to BetterSuite a Computational Task, ACL SIGLEX.Workshop on Lexical Acquisition from Text,Columbus.
Ohio, USA, 1993.(Yarowsky.
D. 1992), "Word-Sense disambiguationusing statistical models of Roget's categoriestrained on large corpora".
Nantes: Proceedingsof COLING 92.
(Krovetz and Croft, I992) R. Krovetz and B. Croft,Lexical Ambiguity and Information Retrieval,in AC'M trans, on Information Systems, tO:2,1992(Gale et al 1992) Gale.
W. K. Church and D.Yarowsky.
One sense per discourse, in proc.
ofthe DARPA speech and and Natural Languageworkshop, Harriman, NY, February 1992(Pustejovsky, 1995) J. Pustejovsky, The generativeLexicon, MIT Press, 1995(Resnik, 1995) P. Resnik.
Disambiguating NounGroupings with respect to Wordnet Senses,proc.
of 3rd Workshop on Very Large Corpora,1995(Resnik, 1997) P. Resnik, Selectional reference andSense disambiguation, i  TAGWS97(TAGWS 1997) Proceedings of the workshop "Tag-ging Text with Lexical Semantics: Why, What,and How?
", published by ACL, 4-5 April 1997,Whashington, USA86
