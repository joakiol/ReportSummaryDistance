Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 685?688,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsSummarizing Microblogs AutomaticallyBeaux Sharifi, Mark-Anthony Hutton, and Jugal KalitaUniversity of Colorado at Colorado Springs1420 Austin Bluffs ParkwayColorado Springs, CO 80918, USA{bsharifi, mhutton, jkalita}@uccs.eduAbstractIn this paper, we focus on a recent Web trendcalled microblogging, and in particular a sitecalled Twitter.
The content of such a site is anextraordinarily large number of small textualmessages, posted by millions of users, at ran-dom or in response to perceived events or sit-uations.
We have developed an algorithm thattakes a trending phrase or any phrase specifiedby a user, collects a large number of postscontaining the phrase, and provides an auto-matically created summary of the posts relatedto the term.
We present examples of summa-ries we produce along with initial evaluation.1 IntroductionSince Twitter?s inception in 2006, it has grown atan unprecedented rate.
In just four years, the ser-vice has grown to approximately 20 million uniquevisitors each month with users sending short 140-character messages (known as ?tweets?)
approx-imately 40 million times a day.
While the majorityof these tweets are pointless babble or conversa-tional, approximately 3.6% of these posts are top-ics of mainstream news (Pear Analytics, 2009).For example, Twitter has been cited as breakingmany important events before traditional media,such as the attacks in Mumbai and the crash of theUS Airways flight into the Hudson River.In order to help users sort through the vast num-ber of tweets that occur each day, Twitter.com hasadded a number of tools.
For instance, Twitter?shomepage displays important topics for three dif-ferent ranges of time in order to see what topics arepopular.
For most topics, users are forced to readthrough related posts in order to try and understandwhy a topic is trending.
In order to help users fur-ther, Twitter has partnered with the third-partywebsite WhatTheTrend1 in order to provide defini-tions of trending topics.
WhatTheTrend allowsusers to manually enter descriptions of why a topicis trending.
Unfortunately, WhatTheTrend sufferswith spam and rants as well as lag time before anew trending topic is defined by a user.While WhatTheTrend is a step in the right direc-tion, a better approach is to automatically summar-ize important events as they occur in real time.
Wehave developed such a method.
Our method canautomatically summarize a collection of micro-blogging posts that are all related to a topic into ashort, one-line summary.
Our results show that ourautomated summarizer produces summaries thatare close to human-generated summaries for thesame set of posts.
For example, Table 1 belowcontains a sample of automatically produced sum-maries for some recently trending topics on Twit-ter.2 Related WorkSome early work focused on summarizing resultsof database queries for presentation during naturallanguage interactions (e.g., Kalita et al, 1986).Most summaries are generated for the purposes ofproviding a ?gist?
of a document or a set of docu-ments to human readers (e.g., Luhn, 1958; Bran-dow et al, 1995).
Summaries are sometimes alsoused as inputs to machine learning approaches, sayfor categorization.
Kolcz et al (2001) summarizetextual documents in order to classify them, usingthe summaries as a feature to be input to a classifi-er.
Most early studies used a news corpus like theReuters dataset.
As the Web started growing insize, the focus moved to Web pages.1http://www.whatthetrend.com685Table 1.
Example Summaries Produced by the Phrase Reinforcement Algorithm.For example, Mahesh (1997) examines the effec-tiveness of Web document summarization by sen-tence extraction.
Recently, there has been work onsummarizing blogs (e.g.
Zhou and Hovy, 2006; Huet al, 2007).
Most techniques focus on extraction:the selecting of salient pieces of documents in or-der to generate a summary.
Applying extractionon microblogs at first appears irrelevant since amicroblog post is already shorter than most sum-maries.
However, extraction is possible when oneconsiders extracting from multiple microblogsposts that are all related to a central theme.3 Approach3.1 Twitter APIThrough an entirely HTTP-based API provided byTwitter, users can programmatically perform al-most any task that can be performed via Twitter?sweb interface.
For non-whitelisted users, Twitterrestricts a user to 150 requests/hour.
Furthermore,searches are limited to returning 1500 posts for agiven request.
Our summarizer has been shown toproduce comparable automated summaries to hu-man summaries with as few as 100 posts.3.2 Phrase Reinforcement AlgorithmGiven a trending topic, one can query Twitter.comfor posts that contain the topic phrase.
Presently,users would have to read these posts in order tocomprehend and manually summarize their con-tent.
Instead, we automate this process using ourPhrase Reinforcement Algorithm.The central idea of the Phrase Reinforcement(PR) algorithm is to find the most commonly usedphrase that encompasses the topic phrase.
Thisphrase is then used as a summary.
The algorithmwas inspired from two simple observations: (1)users will often use the same word or sets of wordsadjacent to the topic phrase when describing a keyidea and (2) users will often ?re-tweet?
(a Twitterform of quoting) the most relevant content for atrending topic.
These two patterns create highlyoverlapping sequences of words when consideringa large number of posts for a single topic.
The PRalgorithm capitalizes on these behaviors in order togenerate a summary.The Phrase Reinforcement algorithm beginswith a starting phrase.
This is typically a trendingtopic, but can be non-trending as well.
Given thestarting phrase, the PR algorithm submits a queryto Twitter.com for a list of posts that each containsthe phrase.
Once the posts are retrieved, the algo-rithm filters the posts to remove any spam or othersources of irrelevant data (e.g.
hyperlinks).
Filter-ing is an important step in order to focus the algo-rithm on the most relevant content.
We filter anyspam by using a Na?ve Bayes classifier which wetrained using previously gathered spam contentfrom Twitter.com.
Next, non-English posts as wellas duplicate posts are removed since we are con-cerned with English summaries only and want toprevent a single user from dominating a topic.
Fi-nally, given a set of relevant posts, we isolate thelongest sentence from each post that contains thetopic phrase.
These sentences form the input intothe PR algorithm.Once we have the set of input sentences, the PRalgorithm formally begins.
The algorithm starts bybuilding a graph representing the common se-quences of words (i.e.
phrases) that occur both be-Topic Automated Summary DateIce Dancing Canadians Tessa Virtue and Scott Moir clinch the gold in Olympic icedancing; U.S. pair Davis and White win silver2/22/2010Dodgers Phillies defeat Dodgers to take the National League Championship series.
10/21/2009Limbaugh Limbaugh dropped from group bidding for St. Louis Rams 10/14/2009Dow Jones The Dow Jones Industrial Average passes 10,000 for the first time sinceOctober 7th, 2008.10/14/2009Captain Lou Wrestler, personality Captain Lou Albano dies at 76 10/14/2009Bloomberg Bloomberg Acquires Businessweek for Less Than $5 million 10/13/2009G20 Trouble breaks out at G20 summit: Protesters and riot police have clashedahead of the G20 summit in Pittsburgh09/24/2009AT&T AT&T plans for iPhone MMS to arrive Friday 09/23/2009686fore and after the topic phrase.
The graph is gen-erated such that it centers about a common rootnode representing the topic phrase.
Adjacent to theroot node are chains of common sequences ofwords found within the input sentences.
In par-ticular, each word is represented by a node and anassociated count that indicates how many times thenode?s phrase occurs within the set of input sen-tences.
The phrase of a node is simply the se-quence of words generated by following the pathfrom the node to the root node.
To illustrate, con-sider the following set of input sentences for thetopic ?Ted Kennedy?.1.
A tragedy: Ted Kennedy died today ofcancer2.
Ted Kennedy died today3.
Ted Kennedy was a leader4.
Ted Kennedy died at age 77Using these sentences, the PR algorithm wouldgenerate a graph similar to the one shown below inFigure 1.Figure 1.
Example Phrase Reinforcement Graph.In Figure 1, we see the node ?today?
has a countof two.
This indicates that the phrase ?Ted Kenne-dy died today?
occurs exactly two times within theset of input sentences (in sentences 1 and 2).Likewise, the node ?tradegy?
has a count of oneindicating the phrase ?tragedy Ted Kennedy?
onlyoccurs one time (in sentence 1).
In actuality, thePR algorithm would only add nodes to the graphwith a count of at least two since it is looking forthe most common phrase.
These are shown as theblack nodes in Figure 1.
However, Figure 1 alsoincludes unique nodes (shown in white) for helpingillustrate the graph?s structure.After the graph is constructed, the PR algorithmassigns a weight to every node in order to preventlonger phrases from dominating the output.
In par-ticular, stop words are given a weight of zero whileremaining words are given weights that are bothproportional to their count and penalized the farth-er they are from the root node: 		?
logIn the above equation, the RootDistance of a nodeis simply the number of hops to get from the nodeto the root node and the logarithm base, b, is a pa-rameter to the algorithm.
Smaller values of b (e.g.2) can be used for preferring shorter summariesover longer summaries.Finally, once the graph is constructed andweighted, the PR algorithm is ready to generate apartial summary.
To do so, the PR algorithmsearches for the path with the most total weight bysearching all paths that begin with the root nodeand end with a non-root node.
This path is denotedas the best partial path since it only represents onehalf of the summary (i.e.
the most common phraseoccurring either before or after the topic phrase).In order to generate the remaining half of thesummary, the PR algorithm is essentially repeatedby initializing the root node with the partial sum-mary and rebuilding the graph.
The most heavilyweighted path from this new graph is the finalsummary produced by the PR algorithm.Using our example above and assuming thatnode weights are equal to their counts, the pathwith the most total weight is the path ?Ted Kenne-dy died today of cancer?
with a total weight of 11.This phrase would then be used as the root node ofa new graph and the PR algorithm would be re-peated.
For this new graph, the only input sen-tence that contains this root phrase would besentence 1.
Therefore, the final summary for ourexample (assuming we allow unique phrases)would be sentence 1: ?A tragedy: Ted Kennedydied today of cancer?.
However, if we only allownon-unique phrases in our graph (the black nodes),then our final summary would be ?Ted Kennedydied today?.4 ResultsIn order to evaluate the PR algorithm, we gathereda set of testing data by collecting the top ten cur-rently trending topics from Twitter?s home pageevery day for five consecutive days.
For each ofthe 50 trending topics, we retrieved the maximum687number of posts from Twitter using its own APIand then filtered the number of posts to 100 postsper topic.
These posts were then given to two vo-lunteers.
The volunteers were instructed to simplygenerate the best summary possible using only theinformation contained within the posts and in 140characters or less.
Furthermore, automated sum-maries for each topic were also produced using thesame 100 posts per topic.
These summaries werethen compared.For comparing the manual and automated sum-maries, we adopted two of the metrics used by theDocument Understanding Conference (DUC) of2002 and 2004 (Lin and Hovy, 2003).
First, weused their Content metric which asks a humanjudge to measure how completely an automatedsummary expresses the meaning of the manualsummaries on a five point scale where 1 representsno meaning overlap and 5 represents completemeaning overlap.
Next, we also used the auto-mated evaluation metric ROUGE-1 developed byLin (2004) which measures co-occurring unigramoverlap between a set of manual and automatedsummaries.
We restricted our automated evalua-tion to ROUGE-1 as opposed to the other ROUGEmetrics since Lin indicates that this metric corre-lates highly with human judgments for very shortsummary tasks similar to the one we are perform-ing (Lin, 2004).For the 50 trending topics we used as our evalu-ation corpus, the PR algorithm produced an aver-age Content score of 3.72 using   100 for ourweighting measure.
This result indicates our au-tomated summaries express slightly less than mostof the meaning of the manual summary content.To compare, we also used this same metric on ourtwo sets of manual summaries which produced anaverage content score of 4.25.
For the ROUGE-1metric, the PR algorithm produced an average pre-cision score of 0.31 and an average recall score of0.30.
Combining these scores using F1-Measure,the PR algorithm produced a combined F1 score of0.30.
Comparing the manual summaries againstone another using ROUGE-1, they produced thesame average precision, recall, and F1 score of0.34.5 Future WorkPresently, we are working on extending our PRalgorithm to providing real-time summaries withinspecific topics.
We are experimenting with using afront-end classifier for producing trending topicswithin distinct categories and then summarizingaround these topics in order to generate an auto-mated real-time newspaper.AcknowledgmentsThe work reported in this paper is partially sup-ported by the NSF Grant ARRA: :  CNS 0851783.ReferencesBrandow, R., Mitze K., and Rau, L.F. Automatic Con-densation of Electronic Publications by Sentence Se-lection, Information Processing and Management,Vol 31, No 5, pp.
675-685, 1995.Hu, M. and Sun, A. and Lim, E.P.
Comments-orientedblog summarization by sentence extraction, ACMCIKM, pp.
901-904, 2007.Kalita, J.K., Jones, M.L., and McCalla, G.I., Summariz-ing Natural Language Database Responses, Compu-tational Linguistics, Volume 12, No.
2, pp.
107-124,1986.Kolcz, A., Prabhakarmurthi, V, and Kalita, J. Summa-rizing as Feature Selection for Text Categorization,CIKM ?01, pp.
365-370, 2001.Lin, C.Y.
ROUGE: a Package for Automatic Evaluationof Summaries, Proceedings of Workshop on TextSummarization, 2004.Lin, C.Y.
and Hovy, E. Automatic evaluation of sum-maries using n-gram co-occurrence statistics,NAACL, pp.
71-78, 2003.Luhn, P. The Automatic Creation of Literature Ab-stracts, in IRE National Convention, pp.
60-68, 1958.Mahesh, K. Hypertext Summary Extraction for FastDocument Browsing, Working Notes of the AAAISpring Symposium for the WWW, pp.
95-103, 1997.Pear Analytics.
Twitter Study, Retrieved 03 31, 2010,from http://www.scribd.com/doc/18548460/Pear-Analytics-Twitter-Study-August-2009, 2009.Zhou, L. and Hovy, E. On the summarization of dynam-ically introduced information: Online discussions andblogs, AAAI-2006 Spring Symposium on Computa-tional Approaches to Analyzing Weblogs, 2006.688
