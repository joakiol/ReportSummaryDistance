Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational NaturalLanguage Learning, pages 286?296, Jeju Island, Korea, 12?14 July 2012. c?2012 Association for Computational LinguisticsSource Language Adaptation for Resource-Poor Machine TranslationPidong WangDepartment of Computer ScienceNational University of Singapore13 Computing DriveSingapore 117417wangpd@comp.nus.edu.sgPreslav NakovQCRIQatar FoundationTornado Tower, P.O.
5825Doha, Qatarpnakov@qf.org.qaHwee Tou NgDepartment of Computer ScienceNational University of Singapore13 Computing DriveSingapore 117417nght@comp.nus.edu.sgAbstractWe propose a novel, language-independentapproach for improving machine translationfrom a resource-poor language to X by adapt-ing a large bi-text for a related resource-richlanguage and X (the same target language).We assume a small bi-text for the resource-poor language to X pair, which we use tolearn word-level and phrase-level paraphrasesand cross-lingual morphological variants be-tween the resource-rich and the resource-poorlanguage; we then adapt the former to getcloser to the latter.
Our experiments forIndonesian/Malay?English translation showthat using the large adapted resource-rich bi-text yields 6.7 BLEU points of improvementover the unadapted one and 2.6 BLEU pointsover the original small bi-text.
Moreover,combining the small bi-text with the adaptedbi-text outperforms the corresponding com-binations with the unadapted bi-text by 1.5?3 BLEU points.
We also demonstrate applica-bility to other languages and domains.1 IntroductionStatistical machine translation (SMT) systems learnhow to translate from large sentence-aligned bilin-gual corpora of human-generated translations, calledbi-texts.
Unfortunately, collecting sufficiently large,high-quality bi-texts is hard, and thus most of the6,500+ world languages remain resource-poor.
For-tunately, many of these resource-poor languagesare related to some resource-rich language, withwhom they overlap in vocabulary and share cog-nates, which offers opportunities for bi-text reuse.Example pairs of such resource rich?poor lan-guages include Spanish?Catalan, Finnish?Estonian,Swedish?Norwegian, Russian?Ukrainian, Irish?Gaelic Scottish, Standard German?Swiss Ger-man, Modern Standard Arabic?Dialectical Arabic(e.g., Gulf, Egyptian), Turkish?Azerbaijani, etc.Previous work has already demonstrated the ben-efits of using a bi-text for a related resource-richlanguage to X (e.g., X=English) to improve ma-chine translation from a resource-poor language toX (Nakov and Ng, 2009; Nakov and Ng, 2012).Here we take a different, orthogonal approach: weadapt the resource-rich language to get closer to theresource-poor one.We assume a small bi-text for the resource-poorlanguage, which we use to learn word-level andphrase-level paraphrases and cross-lingual morpho-logical variants between the two languages.
Assum-ing translation into the same target language X , weadapt (the source side of) a large training bi-text fora related resource-rich language and X .Training on the adapted large bi-text yields verysignificant improvements in translation quality com-pared to both (a) training on the unadapted version,and (b) training on the small bi-text for the resource-poor language.
We further achieve very sizable im-provements when combining the small bi-text withthe large adapted bi-text, compared to combining theformer with the unadapted bi-text.While we focus on adapting Malay to look likeIndonesian in our experiments, we also demonstratethe applicability of our approach to another languagepair, Bulgarian?Macedonian, which is also from adifferent domain.2862 Related WorkOne relevant line of research is on machine trans-lation between closely related languages, which isarguably simpler than general SMT, and thus canbe handled using word-for-word translation, man-ual language-specific rules that take care of the nec-essary morphological and syntactic transformations,or character-level translation/transliteration.
Thishas been tried for a number of language pairs in-cluding Czech?Slovak (Hajic?
et al2000), Turkish?Crimean Tatar (Altintas and Cicekli, 2002), Irish?Scottish Gaelic (Scannell, 2006), and Bulgarian?Macedonian (Nakov and Tiedemann, 2012).
In con-trast, we have a different objective ?
we do not carryout full translation but rather adaptation since ourultimate goal is to translate into a third language X .A special case of this same line of research is thetranslation between dialects of the same language,e.g., between Cantonese and Mandarin (Zhang,1998), or between a dialect of a language and a stan-dard version of that language, e.g., between someArabic dialect (e.g., Egyptian) and Modern StandardArabic (Bakr et al2008; Sawaf, 2010; Salloum andHabash, 2011).
Here again, manual rules and/orlanguage-specific tools are typically used.
In thecase of Arabic dialects, a further complication arisesby the informal status of the dialects, which are notstandardized and not used in formal contexts butrather only in informal online communities1 such associal networks, chats, Twitter and SMS messages.This causes further mismatch in domain and genre.Thus, translating from Arabic dialects to ModernStandard Arabic requires, among other things, nor-malizing informal text to a formal form.
In fact,this is a more general problem, which arises withinformal sources like SMS messages and Tweets forjust any language (Aw et al2006; Han and Bald-win, 2011).
Here the main focus is on coping withspelling errors, abbreviations, and slang, which aretypically addressed using string edit distance, whilealso taking pronunciation into account.
This is dif-ferent from our task, where we try to adapt good,formal text from one language into another.A second relevant line of research is on languageadaptation and normalization, when done specifi-cally for improving SMT into another language.1The Egyptian Wikipedia is one notable exception.For example, Marujo et al2011) described arule-based system for adapting Brazilian Portuguese(BP) to European Portuguese (EP), which they usedto adapt BP?English bi-texts to EP?English.
Theyreport small improvements in BLEU for EP?Englishtranslation when training on the adapted ?EP?
?Enbi-text compared to using the unadapted BP?En(38.55 vs. 38.29), or when an EP?English bi-text isused in addition to the adapted/unadapted one (41.07vs.
40.91 BLEU).
Unlike this work, which heav-ily relied on language-specific rules, our approach isstatistical, and largely language-independent; more-over, our improvements are much more sizable.A third relevant line of research is on reusing bi-texts between related languages without or with verylittle adaptation, which works well for very closelyrelated languages.
For example, our previous work(Nakov and Ng, 2009; Nakov and Ng, 2012) ex-perimented with various techniques for combininga small bi-text for a resource-poor language (In-donesian or Spanish, pretending that Spanish isresource-poor) with a much larger bi-text for a re-lated resource-rich language (Malay or Portuguese);the target language of all bi-texts was English.
How-ever, our previous work did not attempt languageadaptation, except for very simple transliteration forPortuguese?Spanish that ignored context entirely;since it could not substitute one word for a com-pletely different word, it did not help much forMalay?Indonesian, which use unified spelling.
Still,once we have language-adapted the large bi-text, itmakes sense to try to combine it further with thesmall bi-text; thus, below we will directly compareand combine these two approaches.Another alternative, which we do not explore inthis work, is to use cascaded translation using apivot language (Utiyama and Isahara, 2007; Cohnand Lapata, 2007; Wu and Wang, 2009).
Unfortu-nately, using the resource-rich language as a pivot(poor?rich?X) would require an additional paral-lel poor?rich bi-text, which we do not have.
Pivotingover the target X (rich?X?poor) for the purposeof language adaptation, on the other hand, wouldmiss the opportunity to exploit the relationship be-tween the resource-poor and the resource-rich lan-guage; this would also be circular since the first stepwould ask an SMT system to translate its own train-ing data (we only have one rich?X bi-text).2873 Malay and IndonesianMalay and Indonesian are closely related, mutuallyintelligible Austronesian languages with 180 millionspeakers combined.
They have a unified spelling,with occasional differences, e.g., kerana vs.
karena(?because?
), Inggeris vs. Inggris (?English?
), andwang vs. uang (?money?
).They differ more substantially in vocabulary,mostly because of loan words, where Malay typi-cally follows the English pronunciation, while In-donesian tends to follow Dutch, e.g., televisyen vs.televisi, Julai vs. Juli, and Jordan vs. Yordania.While there are many cognates between the twolanguages, there are also a lot of false friends, e.g.,polisi means policy in Malay but police in Indone-sian.
There are also many partial cognates, e.g.,nanti means both will (future tense marker) and laterin Malay but only later in Indonesian.Thus, fluent Malay and fluent Indonesian can dif-fer substantially.
Consider, for example, Article 1 ofthe Universal Declaration of Human Rights:2?
Semua manusia dilahirkan bebas dan samarata dari segi kemu-liaan dan hak-hak.
Mereka mempunyai pemikiran dan perasaanhati dan hendaklah bertindak di antara satu sama lain dengansemangat persaudaraan.
(Malay)?
Semua orang dilahirkan merdeka dan mempunyai marta-bat dan hak-hak yang sama.
Mereka dikaruniai akal danhati nurani dan hendaknya bergaul satu sama lain dalamsemangat persaudaraan.
(Indonesian)There is only 50% overlap at the word level, butthe actual vocabulary overlap is much higher, e.g.,there is only one word in the Malay text that doesnot exist in Indonesian: samarata (?equal?).
Otherdifferences are due to the use of different morpho-logical forms, e.g., hendaklah vs. hendaknya (?con-science?
), derivational variants of hendak (?want?
).Of course, word choice in translation is often amatter of taste.
Thus, we asked a native speaker ofIndonesian to adapt the Malay version to Indonesianwhile preserving as many words as possible:?
Semua manusia dilahirkan bebas dan mempunyai martabatdan hak-hak yang sama.
Mereka mempunyai pemikiran danperasaan dan hendaklah bergaul satu sama lain dalamsemangat persaudaraan.
(Indonesian)2English: All human beings are born free and equal in dig-nity and rights.
They are endowed with reason and conscienceand should act towards one another in a spirit of brotherhood.Obtaining this latter version from the originalMalay text requires three word-level operations:(1) deletion of dari, segi, (2) insertion of yang, sama,and (3) substitution of samarata with mempunyai.Unfortunately, we do not have parallel Malay-Indonesian text, which complicates the process oflearning when to apply these operations.
Thus, be-low we restrict our attention to the simplest and mostcommon operation of word substitution only, leav-ing the other two3 operations for future work.Note that word substitution is enough in manycases, e.g., it is all that is needed for the followingMalay-Indonesian sentence pair:4?
KDNK Malaysia dijangka cecah 8 peratus pada tahun 2010.?
PDB Malaysia akan mencapai 8 persen pada tahun 2010.4 MethodWe improve machine translation from a resource-poor language (Indonesian) to English by adapting abi-text for a related resource-rich language (Malay)and English, using word-level and phrase-level para-phrases and cross-lingual morphological variants.4.1 Word-Level ParaphrasingGiven a Malay sentence, we generate a confusionnetwork containing multiple Indonesian word-levelparaphrase options for each Malay word.
Each suchIndonesian option is associated with a correspond-ing weight in the network, which is defined as theprobability of this option being a translation of theoriginal Malay word (see Eq.
1 below).
We decodethis confusion network using a large Indonesian lan-guage model, thus generating a ranked list of n cor-responding adapted ?Indonesian?
sentences.Then, we pair each such adapted ?Indonesian?sentence with the English counter-part for theMalay sentence it was derived from, thus obtain-ing a synthetic ?Indonesian?
?English bi-text.
Fi-nally, we combine this synthetic bi-text with theoriginal Indonesian?English one to train the finalIndonesian?English SMT system.Below we first describe how we generate word-level Indonesian options and corresponding weightsfor the Malay words.
Then, we explain how webuild, decode, and improve the confusion network.3There are other potentially useful operations, e.g., a correcttranslation for the Malay samarata can be obtained by splittingit into the Indonesian sequence sama rata.4Malaysia?s GDP is expected to reach 8 percent in 2010.2884.1.1 Inducing Word-Level ParaphrasesWe use pivoting over English to induce potentialIndonesian translations for a given Malay word.First, we generate separate word-level alignmentsfor the Indonesian?English and the Malay?Englishbi-texts.
Then, we induce Indonesian-Malay wordtranslation pairs assuming that if an Indonesian wordi and a Malay word m are aligned to the sameEnglish word e, they could be mutual translations.Each translation pair is associated with a conditionalprobability, estimated by pivoting over English:Pr(i|m) =?ePr(i|e)Pr(e|m) (1)Pr(i|e) and Pr(e|m) are estimated using maxi-mum likelihood from the word alignments.
Follow-ing (Callison-Burch et al2006), we further assumethat i is conditionally independent of m given e.4.1.2 Confusion Network ConstructionGiven a Malay sentence, we construct an Indone-sian confusion network, where each Malay word isaugmented with a set of network transitions: pos-sible Indonesian word translations.
The weightof such a transition is the conditional Indonesian-Malay translation probability as calculated by Eq.
1;the original Malay word is assigned a weight of 1.Note that we paraphrase each word in the in-put Malay sentence as opposed to only those Malaywords that we believe not to exist in Indonesian, e.g.,because they do not appear in our Indonesian mono-lingual text.
This is necessary because of the largenumber of false friends and partial cognates betweenMalay and Indonesian (see Section 3).Finally, we decode the confusion network for aMalay sentence using a large Indonesian languagemodel, and we extract an n-best list.5 Table 1shows the 10-best adapted ?Indonesian?
sentences6we generated for the confusion network in Figure 1.4.1.3 Further RefinementsMany of our paraphrases are bad: some have verylow probabilities, while others involve rare wordsfor which the probability estimates are unreliable.5For balance, in case of less than n adaptations for a Malaysentence, we randomly repeat some of the available ones.6According to a native Indonesian speaker, options 1 and 3in Table 1 are perfect adaptations, options 2 and 5 have a wrongword order, and the rest are grammatical though not perfect.Moreover, the options we propose for a Malayword are inherently restricted to the small Indone-sian vocabulary of the Indonesian?English bi-text.Below we describe how we address these issues.Score-based filtering.
We filter out translationpairs whose probabilities (Eq.
1) are lower thansome threshold (tuned on the dev dataset), e.g., 0.01.Improved estimations for Pr(i|e).
We concate-nate k copies of the Indonesian?English bi-text andone copy of the Malay?English bi-text, where thevalue of k is selected so that we have roughly thesame number of Indonesian and Malay sentences.Then, we generate word-level alignments for theresulting bi-text.
Finally, we truncate these align-ments keeping them for one copy of the originalIndonesian?English bi-text only.
Thus, we end upwith improved word alignments for the Indonesian?English bi-text, and with better estimations for Eq.
1.Since Malay and Indonesian share many cognates,this improves word alignments for Indonesian wordsthat occur rarely in the small Indonesian?English bi-text but are relatively frequent in the larger Malay?English one; it also helps for some frequent words.Cross-lingual morphological variants.
We in-crease the Indonesian options for a Malay word us-ing morphology.
Since the set of Indonesian op-tions for a Malay word in pivoting is restricted tothe Indonesian vocabulary of the small Indonesian?English bi-text, this is a severe limitation of pivot-ing.
Thus, assuming a large monolingual Indone-sian text, we first build a lexicon of the words in thetext.
Then, we lemmatize these words using two dif-ferent lemmatizers: the Malay lemmatizer of Bald-win and Awab (2006), and a similar Indonesian lem-matizer.
Since these two analyzers have differentstrengths and weaknesses, we combine their outputsto increase recall.
Next, we group all Indonesianwords that share the same lemma, e.g., for minum,we obtain {diminum, diminumkan, diminumnya, makan-minum,makananminuman, meminum, meminumkan, meminumnya, meminum-minuman, minum, minum-minum, minum-minuman, minuman, minu-manku, minumannya, peminum, peminumnya, perminum, terminum}.Since Malay and Indonesian are subject to the samemorphological processes and share many lemmata,we use such groups to propose Indonesian transla-tion options for a Malay word.
We first lemmatizethe target Malay word, and then we find all groupsof Indonesian words the Malay lemmata belong to.2890 1pdb|0.576172sebesar|0.052080maka|0.026044perkiraan|0.026035panggar|0.026035rkp|0.026035gdp|0.0260342malaysia|1.0 3akan|0.079793untuk|0.050155diharapkan|0.044511diperkirakan|0.039131ke|0.018960dapat|0.018436adalah|0.017422menjadi|0.011655ini|0.0111584remaja|0.047619mencapai|0.042930hit|0.030612sr|0.030482guncang|0.023810di|0.022778untuk|0.018425hits|0.013605diguncang|0.01007458|1.0 6persen|0.473588per|0.148886 7pada|1.0 8tahun|1.0 92010|1.0 10.|1.0Figure 1: Indonesian confusion network for the Malay sentence ?KDNK Malaysia dijangka cecah 8 peratus pada tahun 2010.?Arcs with scores below 0.01 are omitted, and words that exist in Indonesian are not paraphrased (for better readability).Rank ?Indonesian?
Sentence1 pdb malaysia akan mencapai 8 persen pada tahun 2010 .2 pdb malaysia untuk mencapai 8 persen pada tahun 2010 .3 pdb malaysia diperkirakan mencapai 8 persen pada tahun 2010 .4 maka malaysia akan mencapai 8 persen pada tahun 2010 .5 maka malaysia untuk mencapai 8 persen pada tahun 2010 .6 pdb malaysia dapat mencapai 8 persen pada tahun 2010 .7 maka malaysia diperkirakan mencapai 8 persen pada tahun 2010 .8 sebesar malaysia akan mencapai 8 persen pada tahun 2010 .9 pdb malaysia diharapkan mencapai 8 persen pada tahun 2010 .10 pdb malaysia ini mencapai 8 persen pada tahun 2010 .Table 1: The 10-best ?Indonesian?
sentences extracted from the confusion network in Figure 1.The union of these groups is the set of morpholog-ical variants that we will add to the confusion net-work as additional options for the Malay word.7 Forexample, given seperminuman (?drinking?)
in theMalay input, we first find its stem minum, and thenwe get the above example set of Indonesian words,which contains some reasonable substitutes such asminuman (?drink?).
In the confusion network, theweight of the original Malay word is set to 1, whilethe weight of a morphological option is one minusthe minimum edit distance ratio (Ristad and Yian-ilos, 1998) between it and the Malay word, multi-plied by the highest probability for all pivoting vari-ants for the Malay word.4.2 Phrase-Level ParaphrasingWord-level paraphrasing ignores context when gen-erating Indonesian variants, relying on the Indone-sian language model to make the right contextualchoice.
We also try to model context more directlyby generating adaptation options at the phrase level.7While the different morphological forms typically have dif-ferent meanings, e.g., minum (?drink?)
vs. peminum (?drinker?
),in some cases the forms could have the same translation in En-glish, e.g., minum (?drink?, verb) vs. minuman (?drink?, noun).This is our motivation for trying morphological variants, eventhough they are almost exclusively derivational, and thus quiterisky as translational variants; see also (Nakov and Ng, 2011).Phrase-level paraphrase induction.
We usestandard phrase-based SMT techniques to build sep-arate phrase tables for the Indonesian?English andthe Malay?English bi-texts, where we have fourconditional probabilities: forward/reverse phrasetranslation probability, and forward/reverse lexical-ized phrase translation probability.
We pivot overEnglish to generate Indonesian-Malay phrase pairs,whose probabilities are derived from the corre-sponding ones in the two phrase tables using Eq.
1.Cross-lingual morphological variants.
Whilephrase-level paraphrasing models context better, itremains limited in the size of its Indonesian vocab-ulary by the small Indonesian?English bi-text, justlike word-level paraphrasing was.
We address thisby transforming the sentences in the developmentand the test Indonesian?English bi-texts into confu-sion networks, where we add Malay morphologicalvariants for the Indonesian words, weighting them asbefore.
Note that we do not alter the training bi-text.4.3 Combining Bi-textsWe combine the Indonesian?English and the syn-thetic ?Indonesian?
?English bi-texts as follows:Simple concatenation.
Assuming the two bi-texts are of comparable quality, we simply train anSMT system on their concatenation.290Balanced concatenation with repetitions.
How-ever, the two bi-texts are not directly comparable andare clearly not equally good as a source of trainingdata for an Indonesian-English SMT system.
Forone thing, the ?Indonesian?
?English bi-text is ob-tained from n-best lists, i.e., it has exactly n verysimilar variants for each Malay sentence.
Moreover,the original Malay?English bi-text is much largerin size than the Indonesian?English one, and nowit has been further expanded n times in order to be-come an ?Indonesian?
?English bi-text, which meansthat it will dominate the concatenation due to itssize.
In order to counter-balance this, we repeat thesmaller Indonesian?English bi-text enough times sothat we can make the number of sentences it containsroughly the same as for the ?Indonesian?
?Englishbi-text; then we concatenate the two bi-texts and wetrain an SMT system on the resulting bi-text.Sophisticated phrase table combination.
Fi-nally, we experiment with a method for combiningphrase tables proposed in (Nakov and Ng, 2009;Nakov and Ng, 2012).
The first phrase table isextracted from word alignments for the balancedconcatenation with repetitions, which are then trun-cated so that they are kept for only one copy of theIndonesian?English bi-text.
The second table is builtfrom the simple concatenation.
The two tables arethen merged as follows: all phrase pairs from thefirst one are retained, and to them are added thosephrase pairs from the second one that are not presentin the first one.
Each phrase pair retains its orig-inal scores, which are further augmented with 1?3additional feature scores indicating its origin: thefirst/second/third feature is 1 if the pair came fromthe first/second/both table(s), and 0 otherwise.
Weexperiment using all three, the first two, or the firstfeature only; we also try setting the features to 0.5instead of 0.
This makes the following six combina-tions (0, 00, 000, .5, .5.5, .5.5.5); on testing, we usethe one that achieves the highest BLEU score on thedevelopment set.Other possibilities for combining the phrase ta-bles include using alternative decoding paths (Birchet al2007), simple linear interpolation, and directphrase table merging with extra features (Callison-Burch et al2006); they were previously found in-ferior to the last two approaches above (Nakov andNg, 2009; Nakov and Ng, 2012).5 ExperimentsWe run two kinds of experiments: (a) isolated,where we train on the synthetic ?Indonesian?
?English bi-text only, and (b) combined, where wecombine it with the Indonesian?English bi-text.5.1 DatasetsIn our experiments, we use the following datasets,normally required for Indonesian?English SMT:?
Indonesian?English train bi-text (IN2EN):28,383 sentence pairs; 915,192 English tokens;796,787 Indonesian tokens;?
Indon.
?English dev bi-text (IN2EN-dev):2,000 sentence pairs; 36,584 English tokens;35,708 Indonesian tokens;?
Indon.
?English test bi-text (IN2EN-test):2,018 sentence pairs; 37,101 English tokens;35,509 Indonesian tokens;?
Monolingual English text (EN-LM): 174,443sentences; 5,071,988 English tokens.We also use a Malay?English set (to be turnedinto ?Indonesian?
?English), and monolingual In-donesian text (for decoding the confusion network):?
Malay?English train bi-text (ML2EN):290,000 sentence pairs; 8,638,780 Englishtokens; 8,061,729 Malay tokens;?
Monolingual Indonesian text (IN-LM):1,132,082 sentences; 20,452,064 Indonesiantokens.5.2 Baseline SystemsWe build five baseline systems ?
two using a sin-gle bi-text, ML2EN or IN2EN, and three combin-ing ML2EN and IN2EN, using simple concatenation,balanced concatenation, and sophisticated phrase ta-ble combination.
The last combination is a verystrong baseline and the most relevant one we needto improve upon.5.3 Isolated ExperimentsThe isolated experiments only use the adapted?Indonesian?
?English bi-text, which allows for a di-rect comparison to using ML2EN / IN2EN only.5.3.1 Word-Level ParaphrasingIn our word-level paraphrasing experiments, weadapt Malay to Indonesian using three kinds of con-fusion networks (see Section 4.1.3 for details):291?
CN:pivot ?
using word-level pivoting only;?
CN:pivot?
?
using word-level pivoting, withprobabilities from word alignments for IN2ENthat were improved using ML2EN;?
CN:pivot?+morph ?
CN:pivot?
augmented withcross-lingual morphological variants.There are two parameter values to be tunedon IN2EN-dev for the above confusion networks:(1) the minimum pivoting probability threshold forthe Malay-Indonesian word-level paraphrases, and(2) the number of n-best Indonesian-adapted sen-tences that are to be generated for each input Malaysentence.
We try {0.001, 0.005, 0.01, 0.05} for thethreshold and {1, 5, 10} for n.5.3.2 Phrase-Level ParaphrasingIn our phrase-level paraphrasing experiments, weuse pivoted phrase tables (PPT) with the followingfeatures for each phrase table entry (in addition tothe phrase penalty; see Section 4.2 for more details):?
PPT:1 ?
only uses the forward conditionaltranslation probability;?
PPT:4 ?
uses all four conditional probabilities;?
PPT:4::CN:morph ?
PPT:4 but used with across-lingual morphological confusion networkfor the dev/test Indonesian sentences.Here we tune one parameter only: the number ofn-best Indonesian-adapted sentences to be generatedfor each input Malay sentence; we try {1, 5, 10}.5.4 Combined ExperimentsThese experiments assess the impact of our adap-tation approach when combined with the originalIndonesian?English bi-text IN2EN as opposed tocombining ML2EN with IN2EN (as was in the lastthree baselines).
We experiment with the same threecombinations: simple concatenation, balanced con-catenation, and sophisticated phrase table combina-tion.
We tune the parameters as before; for the lastcombination, we further tune the six extra featurecombinations (see Section 4.3 for details).6 Results and DiscussionFor all tables, statistically significant improvements(p < 0.01), according to Collins et al2005)?s signtest, over the baseline are in bold; in case of twobaselines, underline is used for the second baseline.System BLEUML2EN 14.50IN2EN 18.67Simple concatenation 18.49Balanced concatenation 19.79Sophisticated phrase table combination 20.10(.5.5)Table 2: The five baselines.
The subscript indicates theparameters found on IN2EN-dev and used for IN2EN-test.The scores that are statistically significantly better thanML2EN and IN2EN (p < 0.01, Collins?
sign test) areshown in bold and are underlined, respectively.6.1 Baseline ExperimentsThe results for the baseline systems are shown in Ta-ble 2.
We can see that training on ML2EN instead ofIN2EN yields over 4 points absolute drop in BLEU(Papineni et al2002) score, even though ML2EN isabout 10 times larger than IN2EN and both bi-textsare from the same domain.
This confirms the exis-tence of important differences between Malay andIndonesian.
While simple concatenation does nothelp, balanced concatenation with repetitions im-proves by 1.12 BLEU points over IN2EN, whichshows the importance of giving IN2EN a properweight in the combined bi-text.
This is further re-confirmed by the sophisticated phrase table combi-nation, which yields an additional absolute gain of0.31 BLEU points.6.2 Isolated ExperimentsTable 3 shows the results for the isolated experi-ments.
We can see that word-level paraphrasingimproves by up to 5.56 and 1.39 BLEU pointsover the two baselines (both statistically signifi-cant).
Compared to ML2EN, CN:pivot yields an ab-solute improvement of 4.41 BLEU points, CN:pivot?adds another 0.59, and CN:pivot?+morph adds 0.56more.
The scores for TER (v. 0.7.25) and METEOR(v. 1.3) are on par with those for BLEU (NIST v. 13).Table 3 further shows that the optimal parametersfor the word-level SMT systems (CN:*) involve avery low probability cutoff, and a high number ofn-best sentences.
This shows that they are robust tonoise, probably because bad source-side phrases areunlikely to match the test-time input.
Note also theeffect of repetitions: good word choices are sharedby many n-best sentences, and thus they would havehigher probabilities compared to bad word choices.292n-gram precisionSystem 1-gr.
2-gr.
3-gr.
4-gr.
BLEU TER METEORML2EN (baseline) 48.34 19.22 9.54 4.98 14.50 67.14 43.28IN2EN (baseline) 55.04 23.90 12.87 7.18 18.67 61.99 54.34CN:pivot 54.50 24.41 13.09 7.35 18.91(+4.41,+0.24)(0.005,10best) 61.94 51.07CN:pivot?
55.05 25.09 13.60 7.69 19.50(+5.00,+0.83)(0.001,10best) 61.25 51.97(i) CN:pivot?+morph 55.97 25.73 14.06 7.99 20.06(+5.56,+1.39)(0.005,10best) 60.31 55.65PPT:1 55.11 25.04 13.66 7.80 19.58(+5.08,+0.91)(10best) 60.92 51.93PPT:4 56.64 26.20 14.53 8.40 20.63(+6.13,+1.96)(10best) 59.33 54.23(ii) PPT:4::CN:morph 56.91 26.53 14.76 8.55 20.89(+6.39,+2.22)(10best) 59.30 57.19System combination: (i) + (ii) 57.73 27.00 15.03 8.71 21.24(+6.74,+2.57) 58.19 54.63Table 3: Isolated experiments.
The subscript shows the best tuning parameters, and the superscript shows the absolutetest improvement over the ML2EN and the IN2EN baselines.
The last line shows system combination results.Combining IN2EN with an adapted version of ML2ENCombination with Simple Concatenation Balanced Concatenation Sophisticated Combination(i) + ML2EN (unadapted; baseline) 18.49 19.79 20.10(.5.5)+ CN:pivot 19.99(+1.50)(0.001,1best) 20.16(+0.37)(0.001,10best) 20.32(+0.22)(0.01,10best,.5.5)+ CN:pivot?
20.03(+1.54)(0.05,1best) 20.80(+1.01)(0.05,10best) 20.55(+0.45)(0.05,10best,.5.5)(ii) + CN:pivot?+morph 20.60(+2.11)(0.01,10best) 21.15(+1.36)(0.01,10best) 21.05(+0.95)(0.01,5best,00)+ PPT:1 20.61(+2.12)(1best) 20.71(+0.92)(10best) 20.32(+0.22)(1best,000)+ PPT:4 20.75(+2.26)(1best) 21.08(+1.29)(5best) 20.76(+0.66)(10best,.5.5.5)(iii) + PPT:4::CN:morph 21.01(+2.52)(1best) 21.31(+1.52)(5best) 20.98(+0.88)(10best,.5)System combination: (i) + (ii) + (iii) 21.55(+3.06) 21.64(+1.85) 21.62(+1.52)Table 4: Combined experiments: BLEU.
The best tuning parameter values are in subscript, and the absolute testimprovement over the corresponding baseline (on top of each column) is in superscript.The gap between ML2EN and IN2EN for unigramprecision could be explained by vocabulary differ-ences between Malay and Indonesian.
Comparedto IN2EN, all CN:* models have higher 2/3/4-gramprecision.
However, CN:pivot has lower unigramprecision, which could be due to bad word align-ments, as the results for CN:pivot?
show.When morphological variants are further added,the unigram precision improves by almost 1% ab-solute over CN:pivot?.
This shows the importanceof morphology for overcoming the limitations of thesmall Indonesian vocabulary of the IN2EN bi-text.The lower part of Table 3 shows that phrase-levelparaphrasing performs a bit better.
This confirms theimportance of modeling context for closely-relatedlanguages like Malay and Indonesian, which are richin false friends and partial cognates.
We furthersee that using more scores in the phrase table isbetter.
Extending the Indonesian vocabulary withcross-lingual morphological variants is still helpful,though not as much as at the word-level.Finally, the combination of the output ofthe best PPT and the best CN systems usingMEMT (Heafield and Lavie, 2010) yields even fur-ther improvements, which shows that the two kindsof paraphrases are complementary.
The best overallBLEU score for our isolated experiments is 21.24,which is better than the results for all five baselinesin Table 2, including the three bi-text combinationbaselines, which only achieve up to 20.10 BLEU.6.3 Combined ExperimentsTable 4 shows the performance of the three bi-text combination strategies (see Section 4.3 for ad-ditional details) when applied to combine IN2EN(1) with the original ML2EN and (2) with variousadapted versions of it.We can see that for the word-level paraphras-ing experiments (CN:*), all combinations exceptfor CN:pivot perform significantly better than theircorresponding baselines, but the improvements aremost sizeable for the simple concatenation.293Note that while there is a difference of 0.31 BLEUpoints between the balanced concatenation and thesophisticated combination for the original ML2EN,they differ little for the adapted versions.
This isprobably due to the sophisticated combination as-suming that the second bi-text is worse than the firstone, which is not really the case for the adapted ver-sions: as Table 3 shows, they all outperform IN2EN.Overall, phrase-level paraphrasing performs a bitbetter than word-level paraphrasing, and systemcombination with MEMT improves even further.This is consistent with the isolated experiments.7 Further AnalysisParaphrasing non-Indonesian words only.
InCN:* above, we paraphrased each word in the Malayinput, because of false friends like polisi and partialcognates like nanti.
This risks proposing worse al-ternatives, e.g., changing beliau (?he?, respectful) toia (?he?, casual), which confusion network weightsand LM would not always handle.
Thus, we triedparaphrasing non-Indonesian words only, i.e., thosenot in IN-LM.
Since IN-LM occasionally containssome Malay-specific words, we also tried paraphras-ing words that occur at most t times in IN-LM.
Ta-ble 5 shows that this hurts by up to 1 BLEU pointfor t = 0; 10, and a bit less for t = 20; 40.System BLEUCN:pivot, t = 0 17.88(0.01,5best)CN:pivot, t = 10 17.88(0.05,10best)CN:pivot, t = 20 18.14(0.01,5best)CN:pivot, t = 40 18.34(0.01,5best)CN:pivot (i.e., paraphrase all) 18.91(0.005,10best)Table 5: Paraphrasing non-Indonesian words only:those appearing at most t times in IN-LM.Manual evaluation.
We asked a native Indone-sian speaker who does not speak Malay to judgewhether our ?Indonesian?
adaptations are more un-derstandable to him than the original Malay in-put for 100 random sentences.
We presented himwith two extreme systems: (a) the conservativeCN:pivot,t=0 vs. (b) CN:pivot?+morph.
Since thelatter is noisy, the top 3 choices were judged forit.
Table 6 shows that CN:pivot,t=0 is better/equalto the original 53%/31% of the time.
In contrast,CN:pivot?+morph is typically worse than the orig-inal; even compared to the best in top 3, the bet-ter:worse ratio is 45%:43%.Still, this latter model works better, which meansthat phrase-based SMT systems are robust to noiseand prefer more variety.
Note also that the judg-ments were at the sentence level, while phrases aresub-sentential, i.e., there can be many good phrasesin a ?bad?
sentence.System Better Equal WorseCN:pivot, t = 0(Rank1) 53% 31% 16%CN:pivot?+morph(Rank1) 38% 8% 54%CN:pivot?+morph(Rank2) 41% 9% 50%CN:pivot?+morph(Rank3) 32% 11% 57%CN:pivot?+morph(Ranks:1?3) 45% 12% 43%Table 6: Human judgments: Malay vs. ?Indonesian?.The parameter values are those from Tables 3 and 5.Reversed Adaptation.
In all experiments above,we were adapting the Malay sentences to look likeIndonesian.
Here we try to reverse the direction ofadaptation, i.e., to adapt Indonesian to Malay: wethus build a ?Malay?
confusion network for eachdev/test Indonesian sentence to be used as an in-put to a Malay?English SMT system trained on theML2EN dataset.
We tried two variations of this idea:?
lattice: Use Indonesian-to-Malay confusionnetworks directly as input to the ML2EN SMTsystem, i.e., tune a log-linear model using con-fusion networks for the source side of theIN2EN-dev dataset, and then evaluate the tunedsystem using confusion networks for the sourceside of the IN2EN-test dataset.?
1-best: Use the 1-best output from theIndonesian-to-Malay confusion network foreach sentence of IN2EN-dev and IN2EN-test.Then pair each 1-best output with the corre-sponding English sentence.
Finally, get anadapted ?Malay?
?English development set andan adapted ?Malay?
?English test set, and usethem to tune and evaluate the ML2EN SMTsystem.Table 7 shows that both variations perform worsethan CN:pivot.
We believe this is because lattice en-codes many options, but does not use a Malay LM,while 1-best uses a Malay LM, but has to committo 1-best.
In contrast, CN:pivot uses both n-bestoutputs and an Indonesian LM; designing a similarsetup for reversed adaptation is a research directionwe would like to pursue in future work.294System BLEUCN:pivot (Malay?Indonesian) 18.91(0.005,10best)CN:pivot (Indonesian?Malay) ?
lattice 17.22(0.05)CN:pivot (Indonesian?Malay) ?
1-best 17.77(0.001)Table 7: Reversed adaptation: Indonesian to Malay.Adapting Macedonian to Bulgarian.
We ex-perimented with another pair of closely-related lan-guages,8 Macedonian (MK) and Bulgarian (BG), us-ing data from a different, non-newswire domain: theOPUS corpus of movie subtitles (Tiedemann, 2009).We used datasets of sizes that are comparable tothose in the previous experiments: 160K MK2ENand 1.5M BG2EN sentence pairs (1.2M and 11.5MEN words).
Since the sentences were short, we used10K MK2EN sentence pairs for tuning and testing(77K and 72K English words).
For the LM, we used9.2M Macedonian and 433M English words.Table 8 shows that both CN:* and PPT:* yieldstatistically significant improvements over balancedconcatenation with unadapted BG2EN; system com-bination with MEMT improves even further.
Thisindicates that our approach can work for other pairsof related languages and even for other domains.We should note though that the improvementshere are less sizeable than for Indonesian/Malay.This may be due to our monolingual MK dataset be-ing smaller (10M MK vs. 20M IN words), and toonoisy, containing many OCR errors, typos, concate-nated words, and even some Bulgarian text.
More-over, Macedonian and Bulgarian are arguably some-what more dissimilar than Malay and Indonesian.System BLEU TER METEORBG2EN (baseline) 24.57 57.64 41.60MK2EN (baseline) 26.46 54.55 46.15Balanced concatenation of MK2EN with an adapted BG2EN+ BG2EN (unadapted) 27.33 54.61 48.16+ CN:pivot?+morph 27.97(+0.64,+1.51) 54.08 49.65+ PPT:4::CN:morph 28.38(+1.05,+1.92) 53.35 48.21Combining last three 29.05(+1.72,+2.59) 52.31 50.96Table 8: Improving Macedonian?English SMT byadapting Bulgarian to Macedonian.8There is a heated political and linguistic debate aboutwhether Macedonian represents a separate language or is a re-gional literary form of Bulgarian.
Since there are no clear cri-teria for distinguishing a dialect from a language, linguists aredivided on this issue.
Politically, the Macedonian remains un-recognized as a language by Bulgaria and Greece.8 Conclusion and Future WorkWe have presented a novel approach for improvingmachine translation for a resource-poor language byadapting a bi-text for a related resource-rich lan-guage, using confusion networks, word/phrase-levelparaphrasing, and morphological analysis.We have achieved very significant improvementsover several baselines (6.7 BLEU points over an un-adapted version of ML2EN, 2.6 BLEU points overIN2EN, and 1.5?3 BLEU points over three bi-textcombinations of ML2EN and IN2EN), thus provingthe potential of the idea.
We have further demon-strated the applicability of the general approach toother languages and domains.In future work, we would like to add word dele-tion, insertion, splitting, and concatenation as al-lowed editing operations.
We further want to ex-plore tighter integration of word-based and phrase-based paraphrasing.
Finally, we plan experimentswith other language pairs and application to otherlinguistic problems.AcknowledgmentsWe would like to give special thanks to Harta Wijayaand Aldrian Obaja Muis, native speakers of Indone-sian, for their help in the linguistic analysis of theinput and output of our system.
We would also liketo thank the anonymous reviewers for their construc-tive comments and suggestions, which have helpedus improve the quality of this paper.This research is supported by the Singapore Na-tional Research Foundation under its InternationalResearch Centre @ Singapore Funding Initiativeand administered by the IDM Programme Office.ReferencesKemal Altintas and Ilyas Cicekli.
2002.
A machinetranslation system between a pair of closely relatedlanguages.
In Proceedings of the 17th InternationalSymposium on Computer and Information Sciences,ISCIS ?02, pages 192?196.AiTi Aw, Min Zhang, Juan Xiao, and Jian Su.
2006.
Aphrase-based statistical model for SMS text normal-ization.
In Proceedings of the 21st International Con-ference on Computational Linguistics and 44th AnnualMeeting of the Association for Computational Linguis-tics, ACL-COLING ?06.295Hitham Abo Bakr, Khaled Shaalan, and Ibrahim Ziedan.2008.
A hybrid approach for converting written Egyp-tian colloquial dialect into diacritized Arabic.
In Pro-ceedings of the 6th International Conference on Infor-matics and Systems, INFOS ?08.Timothy Baldwin and Su?ad Awab.
2006.
Open sourcecorpus analysis tools for Malay.
In Proceedings of the5th International Conference on Language Resourcesand Evaluation, LREC ?06, pages 2212?2215.Alexandra Birch, Miles Osborne, and Philipp Koehn.2007.
CCG supertags in factored statistical machinetranslation.
In Proceedings of the Second Workshopon Statistical Machine Translation, WMT ?07, pages9?16.Chris Callison-Burch, Philipp Koehn, and Miles Os-borne.
2006.
Improved statistical machine transla-tion using paraphrases.
In Proceedings of the HumanLanguage Technology Conference of NAACL, HLT-NAACL ?06, pages 17?24.Trevor Cohn and Mirella Lapata.
2007.
Machine trans-lation by triangulation: Making effective use of multi-parallel corpora.
In Proceedings of the 45th AnnualMeeting of the Association for Computational Linguis-tics, ACL ?07, pages 728?735.Michael Collins, Philipp Koehn, and Ivona Kuc?erova?.2005.
Clause restructuring for statistical machinetranslation.
In Proceedings of the 43rd Annual Meet-ing of the Association for Computational Linguistics,ACL ?05, pages 531?540.Jan Hajic?, Jan Hric, and Vladislav Kubon?.
2000.
Ma-chine translation of very close languages.
In Proceed-ings of the Sixth Conference on Applied Natural Lan-guage Processing, ANLP ?00, pages 7?12.Bo Han and Timothy Baldwin.
2011.
Lexical normal-isation of short text messages: Makn sens a #twitter.In Proceedings of the 49th Annual Meeting of the As-sociation for Computational Linguistics: Human Lan-guage Technologies, ACL-HLT ?11, pages 368?378.Kenneth Heafield and Alon Lavie.
2010.
Combin-ing machine translation output with open source:The Carnegie Mellon multi-engine machine transla-tion scheme.
The Prague Bulletin of MathematicalLinguistics, 93(1):27?36.Lu?
?s Marujo, Nuno Grazina, Tiago Lu?
?s, Wang Ling,Lu?
?sa Coheur, and Isabel Trancoso.
2011.
BP2EP -adaptation of Brazilian Portuguese texts to EuropeanPortuguese.
In Proceedings of the 15th Conferenceof the European Association for Machine Translation,EAMT ?11, pages 129?136.Preslav Nakov and Hwee Tou Ng.
2009.
Improved statis-tical machine translation for resource-poor languagesusing related resource-rich languages.
In Proceedingsof the Conference on Empirical Methods in NaturalLanguage Processing, EMNLP ?09, pages 1358?1367.Preslav Nakov and Hwee Tou Ng.
2011.
Trans-lating from morphologically complex languages: Aparaphrase-based approach.
In Proceedings of the49th Annual Meeting of the Association for Compu-tational Linguistics: Human Language Technologies,ACL-HLT ?11, pages 1298?1307.Preslav Nakov and Hwee Tou Ng.
2012.
Improvingstatistical machine translation for a resource-poor lan-guage using related resource-rich languages.
Journalof Artificial Intelligence Research, 44:179?222.Preslav Nakov and Jo?rg Tiedemann.
2012.
Combin-ing word-level and character-level models for machinetranslation between closely-related languages.
In Pro-ceedings of the 50th Annual Meeting of the Associationfor Computational Linguistics, ACL-Short ?12.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
BLEU: a method for automatic eval-uation of machine translation.
In Proceedings of the40th Annual Meeting of the Association for Computa-tional Linguistics, ACL ?02, pages 311?318.Eric Ristad and Peter Yianilos.
1998.
Learning string-edit distance.
IEEE Transactions on Pattern Analysisand Machine Intelligence, 20(5):522?532.Wael Salloum and Nizar Habash.
2011.
Dialectalto Standard Arabic paraphrasing to improve Arabic-English statistical machine translation.
In Proc.
of theWorkshop on Algorithms and Resources for Modellingof Dialects and Language Varieties, pages 10?21.Hassan Sawaf.
2010.
Arabic dialect handling in hybridmachine translation.
In Proceedings of the 9th Confer-ence of the Association for Machine Translation in theAmericas, AMTA ?09.Kevin P. Scannell.
2006.
Machine translation for closelyrelated language pairs.
In Proceedings of the LREC2006 Workshop on Strategies for Developing MachineTranslation for Minority Languages.Jo?rg Tiedemann.
2009.
News from OPUS - a collectionof multilingual parallel corpora with tools and inter-faces.
In Recent Advances in Natural Language Pro-cessing, volume V, pages 237?248.Masao Utiyama and Hitoshi Isahara.
2007.
A com-parison of pivot methods for phrase-based statisticalmachine translation.
In Proceedings of the HumanLanguage Technology Conference of NAACL, HLT-NAACL ?07, pages 484?491.Hua Wu and Haifeng Wang.
2009.
Revisiting pivot lan-guage approach for machine translation.
In Proceed-ings of the Joint Conference of the 47th Annual Meet-ing of the ACL, ACL ?09, pages 154?162.Xiaoheng Zhang.
1998.
Dialect MT: a case study be-tween Cantonese and Mandarin.
In Proceedings of the17th International Conference on Computational Lin-guistics, COLING ?98, pages 1460?1464.296
