A LARGE-VOCABULARY CONTINUOUS SPEECH RECOGNITIONALGORITHM AND ITS APPLICATION TO A MULTI-MODAL TELEPHONEDIRECTORY ASSISTANCE SYSTEMYasuhiro Minami, Kiyohiro Shikano, Osamu Yoshioka, Satoshi Takahashi,Tomokazu Yamada and Sadaoki FuruiNTT Human Interface Laboratories3-9-11 Midori-cho, Musashino-shi, Tokyo, 180 JapanABSTRACTThis paper describes an accurate and efficient algorithm forvery-large-vocabulary continuous peech recognition basedon an HMM-LR algorithm.
The HMM-LR algorithm usesa generalized LR parser as a language model and hiddenMarkov models (HMMs) as phoneme models.
To reduce thesearch space without pruning the correct candidate, we useforward and backward trellis likelihoods, an adjusting win-dow for choosing only the probable part of the trellis foreach predicted phoneme, and an algorithm for merging candi-dates that have the same allophonic phoneme sequences andthe same context-free grammar states.
Candidates are alsomerged at the meaning level.
This algorithm is applied to atelephone directory assistance system that recognizes pon-taneous peech containing the names and addresses of morethan 70,000 subscribers (vocabulary size is about 80,000).The experimental results show that the system performs wellin spite of the large perplexity.
This algorithm was also ap-plied to a multi-modal telephone directory assistance system,and the system was evaluated from the human-interface pointof view.
To cope with the problem of background noise,an HMM composition technique which combines a noise-source HMM and a clean phoneme HMM into a noise-addedphoneme HMM was investigated and incorporated into thesystem.1.
INTRODUCTIONOne of the main problems with very-large-vocabulary con-tinuous speech recognition is how to accurately and effi-ciently reduce the search space without pruning the cor-rect candidate.
Our speech recognition system is based onthe HMM-LR algorithm \[1\] which utilizes a generalized LRparser \[2\] as a language model and hidden Markov mod-els (HMMs) as phoneme models.
Applying this algorithmto large-vocabulary continuous peech requires: (1) accuratescoring for phoneme sequences, (2) reduction of trellis calcu-lation, and (3) efficient pruning of phoneme sequence candi-dates.For the first requirement, several speech recognition algo-rithms that calculate the backward trelhs likelihood from theend of the utterance, as well as the forward trellis likehhood,have been proposed \[3\]\[41 .
We also use forward and back-ward trellis likelihoods for accurate scoring.
For the secondrequirement, we use an adjusting window, which chooses onlythe probable part of the trellis according to the predictedphoneme.
For the third requirement, we use an algorithm formerging candidates which have the same allophonle phonemesequences and the same context-free grammar states \[5\].
Inaddition, candidates are also merged at the meaning level \[6\].Speech HMMs are sensitive to incoming noise and this of-ten results in a large decrease in the recognition.
One solu-tion is to train HMMs on noisy speech to obtain the corre-sponding optimum HMMs.
For large-vocabulary continuousspeech recognition, however, the computation load of this so-lution becomes too high, because all the HMMs need to be re-trained each time the characteristics of the background noise(such as its level) change.
Taking inspiration from I-IMMdecomposition \[7\], we proposed an HMM-composition tech-nique to easily adapt the speech recognition system based onclean-speech HMMs to background noise \[8\].
This techniqueis similar to the technique of Nolasco Flores et al \[9\] whichwas investigated independently.Providing access to directory information via spoken namesand addresses is an interesting and useful application oflarge-vocabulary continuous peech recognition technology intelecommunication networks.
Although many systems basedon recognizing spoken spelled names are being investigated, itis unreasonable to expect users to correctly spell the names ofthe persons whose telephone number they want.
In addition,there are several sets of letters having similar pronunciations,such as the English E-rhyming letters, and pronunciation ofthe spelling of another person's names is often unstable, sincethis is not a familiar action for people.
Therefore, it is noteasy to correctly recognize alphabetically spelled names, anda more successful approach might be to recognize naturallyspoken names, even if the machine has to recognize hundredsof thousand names.
We applied our speech recognition tech-nology to a directory assistance system recognizing namesand addresses continuously spoken in Japanese.
This sys-tem was evaluated from the human-machine-interface pointof view.2.
SPEECH RECOGNIT IONALGORITHM2.1.
Two-Stage LR ParserFigure 1 shows the structure of our continuous peech recog-nition system for telephone directory assistance.
We havedeveloped a two-stage LR parser that uses two classes of LRtables: "a main grammar table and several sub-grammar ta-bles.
These grammar tables are separately compiled from acontext-free grammar.
The sub-grammar tables deal with se-mantically classified items, such as city names, town names,block numbers, and subscriber names.
The main grammartable controls the relationships between these semantic items.387Dividing the grammar into two classes has two advantages:since each grammar can be compiled separately, the timeneeded for compiling the LR table is reduced, and the sys-tem cart easily be adapted to many types of utterances bychanging the main grammar ules.Speech |LR table \] Context-free~m~n ~m)  \[ gr~mm~LR table (Tokyo) \]LR table (city names) " I-" '1 LR table (town names) \[----t LR table (block numbers) \]I LR table (subscriber names)Two-stage LR parserResultFigure 1: Structure of the continuous speech recognition sys-tem.2.2.
Accurate  Scor ingFigure 2 shows the search algorithm.
Our algorithm usesa backward trellis as well as a forward trellis so as to ac-curately calculate the score of a phoneme sequence candi-date.
The backward trellis likelihood is calculated withoutany grammatical constraints on the phoneme sequences; it isused as a likelihood estimate of potential succeeding phonemesequences.2.3.
Adjus t ing  WindowWe proposed an algorithm for determining an adjusting win-dow that restricts calculation to a probable part of the trellisfor each predicted phoneme.
The adjusting window (shadedrectangle in Fig.
2) has a length of 50 frames (400 ms).
Thescore within the adjusting window is calculated by taking theconvolution of the forward and backward trdlises.
In thisprocedure, the likelihood in the backward trellis is multipliedby (1-~), where ~ is a small positive value.2.4.
Merg ing  Cand idatesThe LR tables need multiple pronunciation rules to coverallophonic phonemes, such as devoicing a~ad long vowels inJapanese pronunciation.
These multiple rules cause an explo-sion of the search space.
To make the search space smaller, wemerge phoneme sequence candidates as well as grammaticalstates when they are phonetically and semantically the same.We further merge the candidate word sequences having thesame meaning, ignoring the differences in non-keywords.3.
RECOGNIT ION EXPERIMENTS3.1.
Exper imenta l  Sys temWe developed a telephone directory assistance system thatcovers two cities and contains more than 70,000 subscribernames.
The vocabulary size is roughly 80,000.
The gram-mar used in this system has various rules for interjections,verb phrases, post-positional particles, etc.
It was made byanalyzing 300 sentences in simulated telephone directory as-sistance dialogs.
Figure 3 gives an example of an inquirythat can be accepted by the system.
The word perplexitywas about 70,000.
In this task, no constraints were placedon t ic  combination of addresses and subscriber names by thedirectory database, since users may sometimes input wrongaddresses.I Adjusting / /Input speech framest PredictedphonemeFigure 2: Search algorithm for the continuous peech recog-nition system.?
"Sumimasen etto, Tokyo no Mitaka-shi, ettoAmari-san no denwabangou wo oshietekudasai"("Excuse me, uh could you give me the phonenumber of Mr. Amari in Mitaka Tokyo?
"(in English))Figure 3: Example of inquiry that can be accepted by thesystem.We prepared two speaker-independent HMM types to evalu-ate our algorithm: 56 context-independent phoneme HMMs,and 358 context-dependent phoneme HMMs.
Each HMM has3 states, each with 4 Gaussian distributions.
We evaluatedour proposed algorithm by using 51 sentences that included388184 keywords.
These utterances were prepared as text withvarious interjections and verb phrases.
They were "sponta-neously" uttered by eight different speakers.3.2.
Experimental ResultsThe average sentence understanding and key-word recogni-tion rates are shown in Fig.
4.
These results confirm theeffectiveness of merging at the meaning level and of context-dependent HMMs.
These techniques achieved an averagesentence understanding rate of 65% and an average keywordrecognition rate of 89%.8590SO~o o"'6o ' ,0"'~50, a , ,  ~3OUnderstanding ratefor top six candidates| pho~me HMM ~'i ~.
\ ]  (35s mod~,~...."--ndetstanding rate forContext-independentphoneme HMM(56 mo~Js)100959oS5757O ~65Without merging With merging Without merging With m~gingin meaning in meaning in meaning in meaninglevel level level levelFigure 4: Sentence and keyword recognition rates.eflicients.
An example of the HMM composition process tocreate a NOVO HMM as the product of two source HMMs isshown in Fig.
5.
Initial probabilities and transitional proba-bilities of the NOVO HMM can be deduced irectly from thesource HMMs as the product of the corresponding parame-ters of the source HMMs.Spe~:h lcfl-to-rigM HMMInitial state" Final staleEvgodic noise HMMI Initial a?d ffnal ~-,,'5HMM Composition \[InitialStales ".
StalesJNOVO HMMFigure 5: Example of the HMM composition process to createa NOVO HMM as the product of two source HMMs.4.
HMM COMPOSIT ION4.1.
PrincipleThe HMM composition assumes that the NOVO HMM(NOVO means voice mixed with noise) obtained by com-bining two or more "source HMMs" will adequately modela complex signal (i.e.
noisy speech) resulting from the in-teraction of these sources.
The source HMMs may modelclean speech recorded in noise-free conditions or various noisesources, such as stationary or non-stationary noises, back-ground voices, etc.
In HMM decomposition \[7\], recognitionis carried out by decomposing a noisy observation i  a multi-dimensional state-space (at least 3 dimensions), whereas inHMM composition the noisy observation is modeled beforethe recognition so the computation load is much smaller thanfor HMM decomposition.Let R,S, and N represent the noisy-speech, clean-speech, andnoise signals.
Xcp, Xig, and X i ,  are the variables correspond-ing to signal X in the cepstrum, the logarithm and the linearspectrum; # and ~ are the mean vector and the covariancematrix of the Gaussian variable, respectively; F is the cosinetransform matrix; and c is the vector of LPC cepstrum co-The output probabilities of the NOVO HMM are inferred asshown in Fig.
6.
Since source HMMs axe defined in the cep-strum domain, and clean speech and noise are additive in thelinear spectrum domain, the normal distributions defined inthe cepstrum domain are transformed into lognormal distri-butions in the linear spectrum domain and summed.
In thefigure, k(SNR) is a weighting fa~ctor that depends on the esti-mated SNR of the noisy speech.
The distributions obtainedin the linear spectrum domain are finally converted back intothe cepstrum domain.
The process hown in the figure hasto be repeated for all states and for all mixture componentsof the noise and clean-speech HMMs.4.2.
Experimental ResultsThe effectiveness of the HMM composition technique wasevaluated by the telephone directory assistance system, us-ing the 56 context-independent phoneme HMMs.
The clean-speech and the noisy-speech HMMs had 3 states, each with4 Gaussiau distributions.
The noise model had one state andone Gaussian distribution.
Thus the NOVO HMMs had 3states, each with 4 Gaussian distributions; there was no in-crease in the decoding time.
Two kinds of noise were usedfor this experiment: computer-room noise (stationary) and389Cl~plll~l,lln l.,,oS.llthm\]\] ,V~= r,V,,, I '~ '~R,p=/"'R.
L **~" \[C~uml~r  sFecmml~k = ~s/dl Combimtion~k = tN/II R~ =S~ + Nk \[k (SNR)\] [R~ = log Rb 1- ~z~.m-6  --%$Multi-modaldialogsystemTelephonedirectorydatabaseFigure 6: NOVO transform to infer the output probabilitiesof the NOVO HMM.Figure 7: Basic structure of the multi-modal dialog systemfor telephone directory assistance.crowd noise (nonstationary).
The same sentences as in Chap-ter 3 were used for testing.The experimental results showed that the NOVO HMMscould be obtained very rapidly and gave similar recognitionrates to those of HMMs trained by using a large noise-addedspeech database.
The efficiency and flexibility of the algo-rithm and its adaptabil ity to new noises and various SNRsmake it suitable as a basis for a real-time speech recognizerresistant to noise.5.
MULTI-MODAL TELEPHONEDIRECTORY ASSISTANCESYSTEM5.1.
System StructureWe designed a multi-modal speech dialog system for tele-phone directory assistance with three input devices (mi-crophone, keyboard and mouse) and two output devices(speaker and display), based on the above-mentioned contin-uous speech recognition and NOVO HMM techniques.
Figure7 shows the basic structure of the dialog system \[10\].
Sincethe interaction time, that is, the recognition speed is cru-cially important in testing dialog systems, we reduced thenumber of subscribers to 2,300 in this experimental system.The vocabulary size was roughly 4,000 as shown in Table 1.The corresponding beam width was also reduced to 200.
Thisrecognition system uses context-independent HMMs and doesnot use merging at the meaning level.
Implemented on anHP-9000-735, the recognition currently takes about 20 sec-onds per sentence.Figure 8 shows an output window example in our system.The numbers on the left side of the window show the orderof candidates.
This window displays five potential subscribercandidates.
For each candidate, the system displays five slots:city, town, block number, subscriber name, and telephonenumber.
A simple example of how this dialog system is usedis as follows:1.
After clicking the speech button, a user states an addressand subscriber name.2.
The system recognizes the input speech and displays fivecandidates.3.
If one of the candidates i correct, the user obtains thetelephone number by clicking the telephone number slotof the correct candidate.5.2.
Dialog ControllerThe main functions of the dialog controller are as follows.D isp lay  Cand idates  After speech recognition, four po-tential candidates are displayed in order of their likelihoodscores.
The telephone directory assistance database con-straint is not usually used in selecting these candidates.
How-ever, the fifth candidate is the candidate that satisfies theconstraint in the telephone directory assistance database, be-cause there is a high possibility that the candidate that sat-isfies the constraint is correct, even if it has a low likelihoodscore.Table 1: Vocabulary size of the multi-modal telephone direc-tory assistance system.Se.mandc City Town Block Subscriberitem names names numbers names~ze 2 27 620 (Full ram-" 2287),' (L~tntme: 1217}390i\]i\]\]i\]iiii\]E, ,  ...._bFigure 8: Exaznple of a window in the multi-modal dialogsystem for telephone directory assistance.E r ror  Cor rect ion  If there is no correct candidate amongthe five candidates, the user corrects the input error by choos-ing the candidate closest to the correct subscriber addressand name, clicking the wrong keyword slot, and uttering asentence with the specified semantic item.
In the error cor-rection mode, the system switches the main grammar to thegrammar in which the clicked item must be uttered.
For ex-ample, if a user clicks the subscriber name slot, the systemswitches the main grammar to the grammar for utterancesthat need to include a subscriber name.
The user can in-clude some new information in the sentence, in addition tothe specified item.
The beam width is also increased to raisethe recognition accuracy.5.3.
Evaluat ionThis system was evaluated from the human-machine-interfacepoint of view.
We asked 20 researchers in our laboratory totry to use this system.
Dialog experiments were performedto evaluate the following issues:1.
System performance (task completion rate, sentence un-derstanding rate, task completion time, etc),2.
User evaluation of the system,3.
Content and manner of user utterances, and4.
Problems encountered with the system.T ra in ing  The users were first requested to practice operat-ing this system by themselves using a tutorial system, whichwas an interactive system implemented on a workstation.The tutorial system was designed to control and unify theguidance as well as knowledge given to each user.
One se-quence of the practice, including examples of correct recog-nition and incorrect recognition, takes roughly 10 minutes,in which users operate the system following instructions dis-played on the screen.
A typical way of speaking is also dis-played and practiced in this stage.
Pauses and speaking ratesare not controlled.Test ing  20 sheets of paper indicating the tasks using sketchmaps were given to each user.
Each task was indicated bythe name and location of the person whose telephone numberhad to be requested on the map.
Figure 9 shows an exampleof a sheet.
The amount of information indicated on the sheetvaried; for exumple, the first name or the town name of theperson was sometimes not given.
The users were requested tomake inquiries based on the information given in each sheet.We used maps for indicating the tasks to avoid controllingthe structure of the spoken sentences.
When the user couldobtain the desired telephone number, he/she wrote down thenumber on the answer sheet, and proceeded to the next task.Even if the user could not get the telephone number alter allefforts, he/she was requested to proceed to the next task.. .
.
.
: I" , !  "'"
IFigure 9: Example of the sheet indicating a directory inquirytask.Quest ionna i res  After testing, each user was requested toanswer several questions, and the information obtained wascompared with various logs recorded uring the test.Resu l ts  The results of the experiments gave the task com-pletion rate as 99%, which means that, in most of the tri-Ms, the users could get the correct telephone numbers.
Theaverage number of utterances for each task was 1.4, and theaverage sentence understanding rate was 57.87o.
The averagerate for the correct recognition result being indicated in thetop five candidates was 77.5%.
We found that the higher thetop five recognition rate was, the lower the average numberof utterances became.The average time needed to complete each task was 57.2seconds, and it decreased as the users became mote experi-enced.
About 75% of the users said that they prefered usingthe computer-based dialog system to a telephone directory.About 55% of the users said that the system was easy to use.The main reason for negative answers to this question washighly related to the feeling that the response time of thesystem was too slow.We have collected a speech database through these experi-ments for future analysis and experiments.3916.
CONCLUSIONSWe proposed a very-large-vocabulary speaker-independentcontinuous speech recognition algorithm and applied it to atelephone directory assistance system including 70,000 sub-scriber names.
The algorithm is accurate and efficient, usinga two-stage LB.
parser with phoneme HMMs.
The sentenceunderstanding and keyword recognition rates with context-dependent phoneme HMMs and merging at the meaning levelaxe 65% and 89%, respectively, demonstrating that our al-gorithm works well for large-vocabulary continuous peechrecognition.
A multi-modal dialog system that uses thisrecognition algorithm was implemented, and evaluated fromthe human-machine-interface point of view.
Although experi-mental results how that the smaller-scale system containing2,300 subscribers works very well, we still need to improvethe performance of the system; in particular, to speed up theprocessing time.References1.
K. Kita, K. Kawabata, and H. Saito, "HMM ContinuousSpeech Recognition Using Predictive LR Parsing, ~ Proc.ICASSP 89, pp.703-706 (May 1989).2.
M. Tomita, "Efficient Parsing for Natural Language:A Fast Algorithm for Practical Systems," Kluwer Aca-demic Publishers (1988).3.
S. Austin, R. Schwartz, and P. Placeway, "The Forward-Backward Search Algorithm," Proc.
ICASSP 91, pp.697-700 (May 1991).4.
R. Schwartz and S. Austin, "A Tree-Trellis Based FastSearch for Finding N Best Sentence Hypotheses in Con-tinuous Speech Recognition," Proc.
ICASSP 91, pp.705-708 (May 1991).5.
Y. Minami, T. Matsuoka, and K. Shikano, "Very LargeVocabulary Speech Recognition Algorithm for Tele-phone Directory Assistance", Proc.
1st IEEE Workshopon Interactive Voice Technology for TelecommunicationsApplications (Octorber 1992).6.
Y. Minami, K. Shikano, S. Takahashi, T. Yamada and O.Yoshioka, "Laxge-Vocabulaxy Continuous Speech Recog-nition System for Telephone Directory Assistance",Proc.
ICASSP 94, 75.5 (April 1994) (to be published)7.
A. P. Vaxga and R. K. Moore, "Midden Markov ModelDecomposition ofSpeech and Noise", Proc.
ICASSP 90,pp.
845-848 (April 1990)8.
F. Martin, K. Shikano and Y. Minami, "Recognition ofNoisy Speech by Composition of Hidden Markov Mod-els", Proc.
Eurospeech '93, pp.
1031-1034 (September1993)9.
J.
A. Nolazco Flores and S. J.
Young, "Adapting aHMM-Based Recogniser for Noisy Speech Enhanced bySpectral Subtraction", Proc.
Eurospeech '93, pp.
829-832 (September 1993)10.
O. Yoshioka, Y. Minami and K. Shikano, "Developmentand Evaluation of a Multi-Modal Dialogue System forTelephone Directory Assistance", Technical Report ofIEICE, SP93-128 (January 1994) (in Japanese)392
