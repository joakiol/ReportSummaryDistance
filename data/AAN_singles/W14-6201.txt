Proceedings of Third Workshop on Semantic Web and Information Extraction, pages 1?8,Dublin, Ireland, 24 August, 2014.Corpus-based Translation of Ontologies for Improved MultilingualSemantic AnnotationClaudia Bretschneider1,2, Heiner Oberkampf1,3, Sonja Zillner1, Bernhard Bauer3, Matthias Hammon41Siemens AG, Corporate Technology, Munich, Germany2Center for Information and Language Processing, University Munich, Germany3Software Methodologies for Distributed Systems, University Augsburg, Germany4Department of Radiology, University Hospital Erlangen, Germany{claudia.bretschneider.ext,heiner.oberkampf.ext,sonja.zillner}@siemens.com,bernhard.bauer@informatik.uni-augsburg.de, matthias.hammon@uk-erlangen.deAbstractOntologies have proven to be useful to enhance NLP-based applications such as information ex-traction.
In the biomedical domain rich ontologies are available and used for semantic annotationof texts.
However, most of them have either no or only few non-English concept labels and can-not be used to annotate non-English texts.
Since translations need expert review, a full translationof large ontologies is often not feasible.
For semantic annotation purpose, we propose to use thecorpus to be annotated to identify high occurrence terms and their translations to extend respec-tive ontology concepts.
Using our approach, the translation of a subset of ontology concepts issufficient to significantly enhance annotation coverage.
For evaluation, we automatically trans-lated RadLex ontology concepts from English into German.
We show that by translating a rathersmall set of concepts (in our case 433), which were identified by corpus analysis, we are able toenhance the amount of annotated words from 27.36 % to 42.65 %.1 IntroductionOntologies offer a powerful way to represent a shared understanding of a conceptualization of a domain(Gruber, 1993a).
They define concepts and relations between them.
Further linguistic information, suchas labels, synonyms, abbreviations or definitions, can be attached.
This is how ontologies provide a con-trolled vocabulary for the respective domain.
In Information Extraction (IE), the controlled vocabularyof ontologies is used to recognize ontology concepts in text (also referred to as semantic annotation) andcombine the textual information and the ontological knowledge to allow a deeper understanding of thetext?s semantics.The problem, however, is that most of the available ontologies are not multilingual, i.e., they have ei-ther no or only few non-English concept labels.
To make ontologies applicable for IE-based applicationsdealing with non-English texts, one has to translate at least some of the concept labels.
Since high qualitytranslations need expert review, a full translation of big ontologies is often not feasible.
In the biomedicaldomain, ontologies have a long tradition and many well designed, large and semantically rich ontologiesexist.
At the time of writing, the BioPortal (Noy et al., 2008), an ontology repository for the biomedicaldomain, contains 370 ontologies, where 49 have more than 10,000 concepts.
Their complete translationwould be very costly.In many application scenarios, only a subset of ontology concepts is of relevance.
This is especiallytrue for IE: If we consider, e.g., the semantic annotation of medical records in the context of a specificdisease, the translation of a subset of ontology concept labels can be sufficient to increase the numberof ontology concepts found.
Thus, the translation of a small set of labels, which is relevant for theapplication scenario, is sufficient to increase the ontology?s applicability for IE from non-English texts.That is why we propose a translation approach that identifies the most relevant concepts for the ap-plication scenario and adds their translations to the ontology.
The application scenario is representedby the corpus, a ?large set of domain-specific text?.
In the context of IE, the main goal is to achieve aThis work is licensed under a Creative Commons Attribution 4.0 International Licence.
Page numbers and proceedings footerare added by the organisers.
Licence details: http://creativecommons.org/licenses/by/4.0/1high annotation coverage, i.e., a high amount of words are semantically annotated with the correlatingontology concepts.
Therefore, we define the terms with high frequency in the corpus as most relevant fortranslation, as the translation of high frequency terms increases the annotation coverage significantly.
Todemonstrate the feasibility of our approach, we use the RadLex ontology (Langlotz, 2006) and a corpusof German radiology reports of lymphoma patients.2 Related WorkOntology-based IE is a commonly used technique in the biomedical domain.
(Meystre et al., 2008) givea detailed overview of recent research activities.
However, most projects focus on English texts.
Theontology translation problem was first described by (Gruber, 1993b) and further formalized by (Espinozaet al., 2009b).
The subproblem we are dealing with is ontology localization, which (Su?arez-figueroa andG?omez-P?erez, 2008) refers to as ?the adaptation of an ontology to a particular language and culture?.
Thechallenges of ontology localization are analyzed in (Espinoza et al., 2009b) and a general methodologyfor guiding the localization process is presented.
By (Cimiano et al., 2010), ontology localization canaffect two different layers: the lexical layer (labels, definitions and accompanying documentation innatural language) and the conceptualization itself.
Thus, the translation of concept labels we conductcan be seen as a subtask of ontology localization targeting only the lexical layer.
The focus of ourwork does not lie in the machine translation task itself but in the intelligent use of existing resources formultilingual extension of ontologies with the aim to enhance the annotation coverage for a certain corpus.
(Espinoza et al., 2009a) focus on sense disambiguation as major problem in ontology localization, whilewe investigate how to increase the efficiency by incorporating a corpus.3 Overview of the approachAs explained, our main goal is to enhance the annotation coverage of a given non-English corpus by on-tology translation.
Using the corpus to be annotated within the translation process has three advantages:?
The translation is conducted more efficiently, since we reduce the number of translations that requirea review.
This is because only concepts that actually occur in the corpus are proposed as translations.?
The process results in high quality translations, because the corpus can be used to disambiguate thecorrect (target) translation candidate for a concept automatically.?
By facilitating a corpus, we make sure that the terms extracted as (target) translation candidatesresult in semantic text annotations in the end.Figure 1 illustrates the approach: Based on the corpus information, ?L?asion?
is added as German trans-lation to the ontology concept with RID38780.
Now, the corpus term can be annotated, which was notpossible before.RID58 Preferred name ?liver?.
RID38780 Preferred nameRID58 Synonym ?Leber?.
?lesion?.RID38780 rdfs:label ?L?asion?
@de.1 Corpus Analysis2 Concept Filtering3 Mapping Corpus Termsto Ontology ConceptExtendedRadLexRadLex... Leber ohne fokale L?asion ...... Leber ohne fokale L?asion ...+Figure 1: The text Leber ohne fokale L?asion ?Liver without focal lesion?
from a large medical corpus isprocessed and a new translation is added to the ontology to increase the number of semantic annotations.2The system designed makes use of this rationale and implements an approach that operates in threesteps (as illustrated in Figure 2) for translating the ontology vocabulary:Input resourcesABCA Ontology to be extendedB Domain-specific corpusC Translation dictionariesLinguistic AnalysisSemantic AnnotationN-Gram CalculationStatisticsN-gram FilteringDictionary lookupConcept MappingDOutput resourceD Extended ontology1 Corpus Analysis2 Concept Filtering3 Mapping Corpus Termsto Ontology ConceptFigure 2: Processing steps in text analysis system@prefix rdfs:<http://www.w3.org/2000/01/rdf-schema#> .
@prefix radlex:<http://www.owl-ontologies.com/Ontology1375951364.owl#> .radlex:RID58rdfs:subClassOf radlex:RID13419 ;radlex:Preferred_name "liver"?
?xsd:string ;radlex:Synonym "Leber"?
?xsd:string ;radlex:RID38780rdfs:subClassOf radlex:RID34300 ;radlex:Preferred_name "lesion"?
?xsd:string ;rdfs:label "L?asion"@de.Figure 3: (Incomplete) RDF representation ofthe RadLex concept radlex:RID58 with Germantranslation ?Leber?
as currently maintained asradlex:Synonym and concept radlex:RID38780with translation ?L?asion?
and proposed repre-sentation using rdfs:label and language tags1 Corpus Analysis The initial processing step is designed to make use of the corpus to find the high fre-quency terms.
Using this resource allows us to customize our approach for the required applicationscenario.
Its content is used to digest the most relevant concepts for translation and determine thecorrect translation option.
The processing incorporates linguistic and statistical NLP techniques toextract terms in target language with high frequency from the corpus.2 Concept Filtering As the list of extracted terms still includes terms without semantic importance,we introduce this step in order to reduce the list.
This includes the removal of terms with certaintechnical characters but also those with special linguistic structures, which makes the approach moreefficient.3 Mapping Corpus Terms to Ontology Concepts Our approach is targeted to translate only existingontology concepts.
Thus, we need a mechanism to map the terms of the corpus to the ontologyconcepts.
We do this by employing state-of-the-art dictionary lookups: The English dictionaryequivalences of the German corpus terms are used to find ontology concepts with the same Englishlabels.
Then, the (corpus) term is added as translation to the matching ontology concept as non-English label.
The resulting translated ontology can be used in subsequent NLP-based applicationsand is able to serve the need for non-English texts.In the end, the ontology will be extended with translations.
In our case, the RadLex ontology currentlymaintains translations as synonyms, but we propose the usage of rdfs:label and language tags as shownin Figure 3.
The introduced steps are described in detail in the following sections.4 Corpus-Based Analysis and Concept Filtering4.1 Corpus DescriptionOne of the core resources for the approach is a domain-specific corpus.
Combined with the ontology tobe translated it serves several purposes: On the one hand, based on IE techniques we find and extract3translations from the corpus in order to extend the ontology?s vocabulary.
Further, we use the corpus assemantic annotation target, which is annotated with ontology terms.
The language-specific translationsused for semantic annotation were found before with the help of the corpus itself.
For the study, we usea corpus of 2,713 radiology reports (from 27 different readers1) of lymphoma patients containing thefindings and evaluation sections.4.2 Linguistic AnalysisThis initial analysis includes several steps that enable a statistical analysis of the textual context.
Each ofthe processing steps is implemented as a single UIMA annotator and integrated into an overall pipeline.First, semantic information units such as dates and measurements are recognized using regular ex-pressions.
Medical language is rich in abbreviations.
Particularly radiologists make use of them, becausethey allow an efficient reporting.
Therefore, as second step, we build an abbreviation recognition andextension algorithm on a simple dictionary.
The third linguistic task is the determination of the basicprocessing units: (1) tokens and (2) sentences.
Tokens are split employing the spaces and ?-?
in thetext, hence no compound splitting is conducted.
While token splitting is a rather simple task, sentencesplitting requires disambiguation facilities.
Indicators like ???,?!?,?;?,?.?
are used to determine sentenceends.
However, the full stop determines sentence ends only if they are not part of a measurement, date orabbreviation.
As a fourth step, stopwords are removed from the documents to reduce the content to onlyrelevant tokens.
Available language-dependent stopword lists are employed.
Finally, each of the tokensin the text is stemmed with the German version of the Porter stemmer.
(Porter, 1997)4.3 Semantic AnnotationSince most ontologies are already partially translated, we make use of this fact and semantically annotateconcepts and exclude them in the subsequent filter process (Section 4.6).
The annotator implementationis based on the UIMA ConceptMapper (Tanenblatt et al., 2010).
The annotation dictionary is builtfrom the preferred names and synonyms in the RadLex ontology (as shown in Figure 3).
Our conceptmapper combines the stems of the dictionary terminology and the stems of the text tokens and annotatesthe matches with the ontology information.
If a dictionary term consists of more than one token, anannotation is created if all of its stems are contained in a single sentence of the corpus.
That is also howsingle tokens can be assigned more than one annotation.4.4 N-Gram CalculationAfter the linguistic processing of the preceding steps, the actual term extraction can be performed.
Inthis initial work, we limit the length of n-grams to three because of performance reasons.
Furthermore,we define that the individual tokens of an n-gram have to co-occur within the same sentence.
The outputof this step is a list of terms in target language that are candidates for ontology translation.4.5 StatisticsThe n-grams relevant for translation are determined by their frequency in the corpus.
Based on thestems, the frequency of each n-gram is calculated according to their (co-)occurrence.
The individual(co-)occurrence count of the terms is used for ordering of the terms, whereas the most frequent occurringterm is ranked top.4.6 N-Gram FilteringThe list of high frequency terms still contains several terms with tokens representing special charactersand sentence ends (like ?.
?, ??
?, ?<?, ?>?, ?/?)
or semantic classes meaningless for ontology extension (likedates, measurements, negation, and image references).
Since the overall aim is to identify concepts thatshould be added as translations to the ontology, we remove occurrences of these information units thatare very specific and without ontology importance.
Also, if the term contains numbers, this precise and1In the radiology domain, readers are physicians, who read and interpret radiology images and produce the reports analyzedin this work.4rather technical information is removed from the n-gram list.
The resulting list contains terms we wouldlike to add as labels to respective ontology concepts if available.5 Mapping Corpus Terms to Ontology ConceptsBased on the list of terms ranked by their frequency, we identify ontology concepts, whose translationshave a high impact on annotation coverage for the respective corpus.
We assume that each ontologyconcept has at least one label in the source language, in our case in English.
In the following, wedescribe our language resources employed in the approach and the mapping procedure.5.1 Translation dictionariesFor this work, we used German-English translations from Dict.cc2and multilingual information fromDBpedia to create two dictionaries.1.
Medical Dictionary: 60,082 different English entriesDict.cc contains specialized dictionaries for 130 different subjects.
For our medical dictio-nary, we collected all entries from the specialized dictionaries with subjects ?anatomy?, ?biol-ogy?, ?chemistry?, ?medicine?, ?pharmacy?, and ?medical engineering and imaging?.
Additionally,we retrieved all medically relevant concepts from DBpedia that have an English and a Germanor Latin label (about 9,500 concepts).
More precisely, we used the DBpedia ontology (Bizeret al., 2009) to retrieve all concepts of type dbp:AnatomicalStructure3, dbp:Disease, dbp:Drug,dbp:ChemicalSubstance and subclasses (see SPARQL query in Figure 4).2.
General Dictionary: 623,294 different English entriesThe general dictionary is the complete English-German Dict.cc dictionary without restriction to aspecific subject.PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>PREFIX dbp: <http://dbpedia.org/ontology/>PREFIX dbpedia2: <http://dbpedia.org/property/>SELECT ?s ?labelEn ?labelDe ?labelLatWHERE {?s a ?type ;rdfs:label ?labelEn .FILTER ( ?type = dbp:AnatomicalStructure|| ?type = dbp:Disease|| ?type = dbp:Drug|| ?type = dbp:ChemicalSubstance )FILTER ( lang(?labelEn) = "en" )OPTIONAL { ?s dbpedia2:latin ?labelLat }OPTIONAL { ?s rdfs:label ?labelDe .FILTER ( lang(?labelDe) = "de" ) }FILTER( bound(?labelDe) || bound(?labelLat) )}Figure 4: SPARQL query to retrieve English-German and English-Latin translations from DBpedia usingthe SPARQL endpoint at http://dbpedia.org/sparql.5.2 Ontology concept translationThe mapping of given corpus terms to corresponding ontology concepts as translations involves two substeps.1.
Dictionary Lookup For all occurrences of a term, we try to find English options in our dictionaries.If no complete lookup option is found for a n-gram, we try to find a lookup option in the dictionaryfor each single token to combine them into a complete English n-gram.
E.g.
the corpus term?L?asion?
is translated to ?lesion?
using the medical dictionary.2http://www.dict.cc/3We use the prefix notation dbp for http://dbpedia.org/ontology/AnatomicalStructure52.
Concept Mapping The list of English lookup options from the first step is used to find ontologyconcepts, whose (English) labels match the dictionary lookup.
We find that the ontology conceptwith RID38780 is assigned the given preferred name ?lesion?.
If a match is found, the German n-gram that resulted in the match (?L?asion?)
is regarded as probable translation.
In order to increasethe quality of the translation, an expert review is conducted at this time.
This is the only manualstep in the whole translation process.
After the review, the n-gram is inserted as new RDF triplefor the respective ontology concept.
In RadLex translations are currently maintained as synonyms.However, as this modeling of translations as synonyms does not represent the correct semantics andmisses the important language information, we propose to use rdfs:label for translations added by acorresponding language tag.
Thus, for the example we insert ?L?asion?
as additional German labelto the ontology concept (see Figure 3).6 Evaluation6.1 ResourcesThe evaluation of our system is based on the RadLex ontology and a corpus of 2,713 radiology reports oflymphoma patients.
We use the OWL DL version of RadLex3.9.1 from NCBO BioPortal.
This versioncontains 42,321 concepts, which all have an assigned (English) preferred name and few additionally syn-onyms.
The German translations are represented as synonyms.
Most of the German labels were added in2009, when a first German version was created.
Even though the number of concepts is growing signif-icantly (RadLex3.9 contained 34,899), the number of concepts with non-English labels is not evolvingthe same way.
Thus, in RadLex3.9.1 less than 25% of the 42,321 concepts have German labels.Proposed translations for ontology concepts - as output of the described automatic approach - areevaluated by a clinical expert.
We restricted the corpus terms translated to those occurring at leasttwo times.
The whole process results in a list of 742 German labels proposed for ontology extension.The expert classified these translations as correct or incorrect.
In order to assist the expert in betterunderstanding of the ontology concept to be extended, we provide information on the preferred name,synonyms as well as preferred names of the next two super classes.This list of evaluated translations is analyzed in detail using three dimensions: First, we analyze howthe choice of the dictionary influences the translation outcome.
Second, we figure out how the term lengthand the processing of multi-word terms influences the translation results.
Third, the correct translationsare added to an extended RadLex ontology.
We compare the annotation results using the initial andextended RadLex version.
We apply accuracy as evaluation measure, which is the proportion of correcttranslations in the system-proposed set.6.2 Evaluation of the Translation ServicesAs described in Section 5.1, we use two different dictionaries.
As expected, the accuracy of the medicaldictionary is significantly higher than the accuracy of the general dictionary (see Table 1(a)).
This isbecause in many cases only the domain-specific dictionary contains the correct lookup entry for theterms.
Nevertheless, the general dictionary is necessary, because RadLex contains also general languageterms like ?increased?
or ?normal?.
Combining the two dictionaries accuracy reaches 75.2%.6.3 Evaluation of the N-Gram LengthIf we take a closer look at n-gram distribution of terms, we see that we translate mainly single words (1-grams), while 2-grams and 3-grams are translated less often.
However, the accuracy of 3-grams reachesexcellent values (see Table 1(b)).
Nevertheless, the translation of n-grams is of high importance, asmost of the ontology concepts in the biomedical domain have multiword labels.
In particular, labels ofanatomical entities are multiword terms; in RadLex they can grow to 10-grams.
Consider for example?Organ component of lymphatic tree organ?
or ?Tendon of second palmar interosseous of left hand?.Thus, a more sophisticated multiword translation is needed to enhance the number of translations forn-grams.
For us, the improved handling of stopwords is the main focus in future work: While we removestopwords in the n-grams, ontology concepts that contain stopwords prevent a match.6Table 1: Evaluation of translation outcomes by choice of dictionary and term length.
Proposed de-notes the number of German labels translated and added to the ontology.
Correct denotes the subset oftranslations evaluated by the expert as correct.
(a) Evaluation by translation dictionaryTranslationsProposed Correct Accuracymedical dict 258 240 0.9302general dict 484 318 0.6570both dicts 742 558 0.7520(b) Evaluation by n-gram lengthTranslationsProposed Correct Accuracy1-grams 609 451 0.74062-grams 118 92 0.77973-grams 15 15 1.0000Table 2: Comparison of the annotation coverage using RadLex3.9.1 and the extended version.
Totalnumber of tokens of the corpus: 346,963.extendedRadLex3.9.1 RadLex3.9.1Tokens with annotation 94,914 147,982 +0.5591Annotation Coverage 27.36 % 42.65 % +0.5591Tokens without annotation 252,049 198,981 - 0.2105Number of annotations 133,156 204,491 +0.53576.4 Extension of RadLex and Evaluation of Annotation CoverageFrom Table 1(a), one can see that we correctly translated 558 RadLex concept labels using both dictio-naries.
After the expert review, we added the (German) terms of these correct matches as labels to 433distinct RadLex concepts.
I.e., some concepts were assigned more than one additional German label.We refer to the new ontology as the extended RadLex.
For the analysis of how the added translationsinfluence the number of annotations, we conducted two annotation processes.
Both the original and theextended RadLex versions were used to semantically annotate the corpus using the annotator describedin Section 4.3.
The measure to indicate the annotation success is annotation coverage, which denotesthe relative amount of tokens for which at least one annotation exists.
Table 2 shows that we are able toenhance the annotation coverage by about 56% by adding only 558 translations.
This shows the effec-tiveness of the approach.
A comparison indicator of these numbers deliver English texts: In (Woods andEng, 2013) an annotation rate of 62 % was observed for English chest radiography reports.
Despite therestrictiveness of the comparison, we see that an annotation coverage of 42.65 % is high considering thatonly about 25 % of the extended RadLex?s concepts have a German label.6.5 LimitationsDue to the characteristics of our approach, the outcome of the increased annotation coverage is specificfor the corpus used: Even though the reports come from 27 different readers, the vocabulary of theevaluated corpus is specific to one disease and thus limited to a certain degree.
Because the vocabularydifferentiates in other corpora, the application of the translation added for texts describing other diseasesor reports may not result in increases of the annotation coverage as shown.
For other corpora, one hasto run our approach a second time using the new corpus and add further concepts to obtain a similarannotation coverage.
However, we expect the additional effort needed to get smaller over time.7 ConclusionWe propose a method to make ontologies usable for multilingual semantic annotation of texts by auto-matically extending them with translations, without the need to invest much effort in a full translation.We believe that our approach is able to unlock the high potential of existing ontologies also for low re-7sourced languages.
We address the key problem of identifying those concepts that are worth translatingby defining the increase of annotation coverage for a given corpus as the main target.
Although it mightseem intuitive to apply an English corpus to identify the most frequent terms and their (source) ontologyconcepts to translate, we do not pursue this approach.
Especially when dealing with a domain-specificlanguage, translations are often ambiguous.
As the English corpus does not help picking the correct(target) translation candidate, we decided to start the other way around and facilitate a corpus in targetlanguage.
We show the high quality and efficiency of the approach by translating medical terms fromEnglish to German.
According to the evaluation results, a better treatment of n-grams shows the biggestpotential for enhancement of the approach.
Sophisticated linguistic algorithms for the translation, whichincorporate the ontology context, can increase the matching of the multi-word terms.
In future work, weplan to evaluate our approach using other ontologies from the BioPortal.AcknowledgementsThis research has been supported in part by the KDI project, which is funded by the German FederalMinistry of Economics and Technology under grant number 01MT14001.
We thank Dict.cc for providingus with the dictionaries.ReferencesChristian Bizer, Jens Lehmann, Georgi Kobilarov, Sren Auer, Christian Becker, Richard Cyganiak, and SebastianHellmann.
2009.
{DBpedia} - a crystallization point for the web of data.
Web Semantics: Science, Servicesand Agents on the World Wide Web, 7(3):154 ?
165.Philipp Cimiano, Elena Montiel-Ponsoda, Paul Buitelaar, Mauricio Espinoza, and Asunci?on G?omez-P?erez.
2010.A note on ontology localization.
Applied Ontology, 5(2):127?137.M Espinoza, A G?omez-P?erez, and E Montiel-Ponsoda.
2009a.
Multilingual and Localization Support for Ontolo-gies.
The Semantic Web Research and Applications, 5554:821?825.Mauricio Espinoza, Elena Montiel-Ponsoda, and Asunci?on G?omez-P?erez.
2009b.
Ontology localization.
InProceedings of the Fifth International Conference on Knowledge Capture, pages 33?40, New York.
ACM.Thomas R Gruber.
1993a.
Toward Principles for the Design of Ontologies Used for Knowledge Sharing.
Interna-tional Journal Human-Computer Studies 43, pages 907?928.Thomas R. Gruber.
1993b.
A translation approach to portable ontology specifications.
Knowl.
Acquis., 5(2):199?220, June.Curtis P. Langlotz.
2006.
Radlex: A new method for indexing online educational materials.
RadioGraphics,26(6):1595?1597.
PMID: 17102038.S.M.
Meystre, G.K. Savova, K.C.
Kipper-Schuler, and J.F.
Hurdle.
2008.
Extracting information from textualdocuments in the electronic health record: A review of recent research.
Yearbook of Medical Informatics, pages128?144.Natalya F. Noy, Nigam H. Shah, Benjamin Dai, Michael Dorf, Nicholas Griffith, Clement Jonquet, Michael J.Montegut, Daniel L. Rubin, Cherie Youn, and Mark A. Musen.
2008.
Bioportal: A web repository for biomed-ical ontologies and data resources [demonstration].M.
F. Porter.
1997.
Readings in information retrieval.
chapter An Algorithm for Suffix Stripping, pages 313?316.Morgan Kaufmann Publishers Inc., San Francisco, CA, USA.Mari Carmen Su?arez-figueroa and Asunci?on G?omez-P?erez.
2008.
First Attempt towards a Standard Glossary ofOntology Engineering Terminology.
In Proceedings of the 8th International Conference on Terminology andKnowledge Engineering (TKE2008).Michael Tanenblatt, Anni Coden, and Igor Sominsky.
2010.
The conceptmapper approach to named entityrecognition.
In Proceedings of the Seventh conference on International Language Resources and Evaluation(LREC?10), Valletta, Malta.
European Language Resources Association (ELRA).Ryan W. Woods and John Eng.
2013.
Evaluating the Completeness of RadLex in the Chest Radiography Domain.Academic Radiology, 20(11):1329?1333.8
