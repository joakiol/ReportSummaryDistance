Turn-taking in Mandarin Dialogue:Interactions of Tone and IntonationGina-Anne LevowComputer Science DepartmentUniversity of ChicagoChicago, IL 60637 USAlevow@cs.uchicago.eduAbstractFluent dialogue requires that speak-ers successfully negotiate and signalturn-taking.
While many cues to turnchange have been proposed, especiallyin multi-modal frameworks, here we fo-cus on the use of prosodic cues to thesefunctions.
In particular, we considerthe use of prosodic cues in a tone lan-guage, Mandarin Chinese, where varia-tions in pitch height and slope addition-ally serve to determine word meaning.Within a corpus of spontaneous Chi-nese dialogues, we find that turn-unit fi-nal syllables are significantly lower inaverage pitch and intensity than turn-unit initial syllables in both smoothturn changes and segments ended byspeaker overlap.
Interruptions are char-acterized by significant prosodic dif-ferences from smooth turn initiations.Furthermore, we demonstrate that thesecontrasts correspond to an overall low-ering across all tones in final posi-tion, which largely preserves the rela-tive heights of the lexical tones.
In clas-sification tasks, we contrast the use oftext and prosodic features.
Finally, wedemonstrate that, on balanced trainingand test sets, we can distinguish turn-unit final words from other words at?
93% accuracy and interruptions fromsmooth turn unit initiations at 62% ac-curacy.1 IntroductionFluent dialogues require effective turn transitionsbetween speakers.
Research in turn-taking, typ-ified by (Duncan, 1974), posits several key sig-nals for turn-taking, including a turn-change sig-nal which offers to cede the floor, speaker-statesignal which indicates taking the floor, within-turn signal, and continuation signals.
This pro-cess fundamentally requires cooperation betweenparticipants both to produce the contextually ap-propriate signals and to interpret those of their in-terlocutor.
These analyses have proposed a widerange of cues to turn status, ranging from gaze andgesture in a multi-modal context to prosodic cuesincluding pitch, intensity, and duration as well aslexical and syntactic cues.Much of this fundamental research as wellas computational implementations have focusedon English, a language with well-studied intona-tional sentence and discourse structure.
A sub-stantial body of work has identified sentence-likeunits as well as fragments and repairs in con-versational speech, including (Ostendorf, forth-coming; Liu et al, 2004; Shriberg et al, 2001)These approaches have employed lexical andprosodic cues in diverse frameworks, includingHidden Markov Models employing decision treesand hidden state language models, neural net-works, and maximum entropy models.
(Shriberget al, 2001) identified jump-in points and jump-in words in multi-party meeting speech usingprosodic and language model features at accura-cies of 65 and 77% under equal priors.
Further-more, (Ward and Tsukahara, 2000) demonstratedthat backchannels occurred at predictable points72with specific prosodic characteristics in both En-glish and Japanese.In the current paper, we consider the interac-tion of potential prosodic intonational cues re-lated to turn-taking with the realization of lexicaltone in a tone language, Putonghua or MandarinChinese.
Mandarin employs four canonical lexi-cal tones distinguished by pitch height and pitchcontour: high level, mid-rising, low falling-rising,and high falling.
We explore whether prosodicfeatures are also employed in turn-taking behav-ior in this language and whether the forms arecomparable to those employed in languages withlexical tone.
We demonstrate that intonationalcues quite similar to those in English are alsoemployed in Chinese with lower pitch and in-tensity at ends of turn units than at the begin-nings of those turn units.
Interruptions likewiseare distinguished from smooth turn transitions byprosodic means, including greater pitch elevation.We demonstrate how these changes interact withlexical tone by substantial lowering of averagepitch height across all tones in final positions andcontrast pitch contours in final and non-final po-sitions.
Finally, these cues in conjunction withsilence and durational features can be employedto distinguish turn-unit final words from non-finalwords in the dialogue and words that initiate in-terruptions from those which start smoother turntransitions.In the remainder of the paper we will briefly de-scribe the data set employed in these experimentsand the basic extraction of prosodic features (Sec-tion 2).
We then present acoustic analyses con-trasting turn unit final and turn unit initial sylla-bles under different turn transition types (Section3).
We will describe the impact of these intona-tional cues on the realization of lexical tone (Sec-tion 4).
Finally we will apply these prosodic con-trasts to enable classification of words for finalityand interruption status (Section 5).2 Experimental DataThe data in this study was drawn from the Tai-wanese Putonghua Speech Corpus1.
The mate-rials chosen include 5 spontaneous dialogues byTaiwanese speakers of Mandarin, seven females1Available from http://www.ldc.upenn.eduand three males.
The dialogues, averaging 20minutes in duration, were recorded on two chan-nels, one per speaker, in a quiet room and digi-tized at 16KHz sampling.
The recordings werelater manually transcribed and segmented intowords; turn-beginnings and overlaps were time-stamped.
The manual word segmentation wasbased on both syntax and phonology according toa methodology described in detail in (Duanmu,1996).2.1 Prosodic FeaturesFor the subsequent analysis, the conversa-tions were divided into chunks based on theturn and overlap time-stamps.
Using a Chi-nese character-to-pinyin dictionary and a hand-constructed mapping of pinyin sequences toARPABET phonemes, the transcribed text wasthen force-aligned to the corresponding audiosegments using the language porting mechanismin the University of Colorado Sonic speech rec-ognizer (Pellom et al, 2001).
The resulting align-ment provided phone, syllable, and word dura-tions as well as silence positions and durations.Pitch and intensity values for voiced regionswere computed using the functions ?To Pitch?
and?To Intensity?
in the freely available Praat acous-tic analysis software package(Boersma, 2001).We then computed normalized pitch and inten-sity values based on log-scaled z-score normal-ization of each conversation side.
Based on theabove alignment, we then computed maximumand mean pitch and intensity values for each syl-lable and word for all voiced regions.
Given thepresence of lexical tone, we extracted five pointsevenly distributed across the ?final?
region of thesyllable, excluding the initial consonant, if any.We then estimated the linear syllable slope basedon the latter half of this region in which the effectsof tonal coarticulation are likely to be minimizedunder the pitch target approximation model(Xu,1997).3 Acoustic Analysis of Turn-takingEach of the turn units extracted above was taggedbased on its starting and ending conditions as oneof four types: smooth, rough, intersmooth, andinterrough.
?Smooth?
indicates a segment-endingtransition from one speaker to another, not caused73Position Start Start?Overlap or +Overlap?Spkr Change +Spkr ChangeEnd Smooth Intersmooth?Overlap 1413 289End Rough Interrough+Overlap 407 68Table 1: Types of turn unitsby the start of overlap with another speaker.
Bycontrast, a rough transition indicates the end of achunk at the start of overlap with another speaker.The prefix ?inter?
indicates the turn began withan interruption, identified by overlap with the pre-vious speaker and change of speaker holding thefloor.
In this class, the new speaker continues tohold the floor after the period of overlap.We contrast turn unit initial and turn unit finalsyllables for each type of transition and across allturns.
We compare mean pitch and mean intensityin each case.
We find in all cases highly signifi-cant differences between mean pitch of turn unitinitial syllables and mean pitch of final syllables(p < 0.0001) as illustrated in Figure 1.
Syllablesin initial position have much higher log-scaledmean pitch in all conditions.
For intensity, wefind highly significant differences across all con-ditions (p < 0.005), with initial syllables havinghigher amplitude than final syllables.
These con-trasts appear in Figure 2.
Furthermore, compar-ing final intensity of transitions not marked by thestart of overlap with the intensity of the final pre-overlap syllable in a transition caused by overlap,we find significantly higher normalized mean in-tensity in all rough transitions relative to others.In contrast, comparable differences in pitch do notreach significance.Finally we compare smooth turn unit initia-tions (?smooth?)
to successful interruptions (?in-terrough?,?intersmooth?
), contrasting initial syl-lables in each class.
Here we find that both nor-malized mean pitch (Figure 3) and normalizedmean intensity (Figure 4) in turn unit initial sylla-bles are significantly higher in interruptions thanin ?smooth?
turn transitions.2 Speakers use these2If one compares both ?smooth?
and ?rough?
transitionsto ?intersmooth?
and ?interrough?
transitions, initial syl-lables are significantly higher in pitch for the interruptionFigure 1: Pitch contrasts between syllables in ini-tial and final position across turn types.
Values forinitial position are in grey, final position in black.Figure 2: Intensity contrasts between syllables ininitial and final position across turn types.
Val-ues for initial position are in grey, final positionin black.74Figure 3: Pitch contrasts between initial syllablesin smooth turn transitions and interruptions.
Val-ues for smooth transitions are in black, interrup-tions in grey.Figure 4: Intensity contrasts between initial sylla-bles in smooth turn transitions and interruptions.Values for smooth transitions are in black, inter-ruptions in grey.prosodic cues to take the floor by interruption.These descriptive analyses demonstrate that in-tonational cues to turn-taking do play a role in atone language.
Not only does intensity play a sig-nificant role, but pitch also is employed to dis-tinguish initiation and finality, in spite of its con-current use in determining lexical identity.
In thefollowing section, we describe the effects on toneheight and tone shape caused by these broader in-tonational phenomena.4 Tone and IntonationWe have determined that syllables in turn unit fi-nal position have dramatically reduced averagepitch relative to those in turn unit initial posi-tion, and these contrasts can serve to signal turn-change and speaker change as suggested by (Dun-classes, but differences for intensity do not reach signifi-cance (p = 0.053)Figure 5: Contrasts in average pitch for the fourcanonical tones in turn non-final and final posi-tions.
Values for non-final positions are in grey,final positions in black.can, 1974).
How do these changes interact withlexical identity and lexical tone?
Since tone oper-ates on a syllable in Chinese, we consider the av-erage pitch and tone contours of syllables in finaland non-final position.
We find that average pitchfor all tones is reduced, and relative tone heightis largely preserved.3 Thus a final high tone isreadily distinguishable from a final low tone, ifthe listener can interpret the syllable as turn-final.The contrasts appear in Figure 5.Turning to tone contour, we find likewise lit-tle change between non-final and final contours,with the contours running parallel, but at a muchlower pitch.4 For illustration, mid-rising and highfalling tones are shown in Figure 6.
Compara-ble behavior has been observed at other discourseboundaries such as story boundaries in newswirespeech.
(Levow, 2004).5 Recognizing Turn Unit Boundariesand InterruptionsBased on the salient contrasts in pitch and in-tensity observed above, we employ prosodic fea-tures both to identify turn boundaries and to dis-tinguish between the start of interruptions andsmooth transitions.
We further contrast the useof prosodic features with text n-gram features.3This analysis excludes exclamatory and interjective par-ticles.4It is also true that contours do not always match theircanonical forms even in non-final position.
This variationmay be attributed to a combination of tonal coarticulatoryeffects and the presence of other turn-internal boundaries.75Figure 6: Contrasts in pitch contour for mid-rising and high falling tones in turn non-final andfinal positions.
Values for non-final positions arein heavy lines, final positions in thin lines.
Mid-rising tone is in black, dashed lines, high fallingin solid lines.5.1 Classifier Features: ProsodicThe features used in the classifier trained to rec-ognize turn boundaries and turn types fall into twoclasses: local and contextual.
The local featuresdescribe the words or syllables themselves, whilethe contextual features capture contrasts betweenadjacent words or syllables.
The first set of fea-tures thus includes the mean pitch and mean in-tensity for the current word and syllable, the wordduration, and the maximum pitch and intensityfor the syllable.
The second set of features in-clude the length of any following silence and thedifferences in mean pitch and mean intensity be-tween the current word or syllable and the follow-ing word or syllable.5.2 Classifier Features: TextFor contrastive purposes, we also consider the useof textual features for turn boundary and bound-ary type classification.5 Here we exploit syllableand word features, as well as syllable n-gram fea-tures.
We use the toneless pinyin representationof the current word and the final syllable in eachword.
Such features aim to capture, for example,question particles that signal the end of a turn.In addition, we extracted the five preceding andfive following syllables in the sequence aroundthe current syllable.
We then experimented withdifferent window widths for n-gram construction,5All text features are drawn from the ground truth manualtext transcripts.ranging from one to five, as supported by the clas-sifier described below.5.3 ClassifiersWe performed experiments with several classi-fiers: Boostexter (Schapire and Singer, 2000),a well-known implementation of boosted weaklearners, multi-class Support Vector Machineswith linear kernels (C-C.Cheng and Lin, 2001),an implementation of a margin-based discrimina-tive classifier, and decision trees, implemented byC4.5(Quinlan, 1992).
All classifiers yielded com-parable results on this classification task.
Herewe present the results using Boostexter to ex-ploit its support for text features and automatic n-gram feature selection as well as its relative inter-pretability.
We used downsampled balanced train-ing and test sets to enable assessment of the utilityof these features for classification and employed10-fold cross-validation, presenting the averageover the runs.5.3.1 Recognizing Turn Unit EndsUsing the features above we created a set of1610 turn unit final words and 1610 non-finalwords.
Based on 10-fold cross-validation, usingcombined text and prosodic features, we obtain anaccuracy of 93.1% on this task.
The key prosodicfeatures in this classification are silence duration,which is the first feature selected, and maximumintensity.
The highest lexical features are preced-ing ?ta?, preceding ?ao?, and following ?dui?.
Ifsilence features are excluded, classification accu-racy drops substantially to 69%, still better thanthe 50% chance baseline for this set.
In this case,syllable mean intensity features become the firstselected for classification.We also consider the relative effectiveness ofclassifiers based on text, with silence, or prosodicfeatures alone.
We find that, when silenceduration features are available, both text- andprosodic-based classifiers perform comparably at93.5% and 93.7% accuracy respectively, near theeffectiveness of the combined text and prosodicclassifier.
However, when silence features areexcluded, a greater difference is found betweenclassification based on text features and classifi-cation based on prosodic features.
Specifically,without silence information, classification based76on text features alone reaches only 59.5%.
How-ever, classification based on prosodic features re-mains somewhat more robust, though still with asubstantial drop in accuracy, at 66.5% for prosodyonly.
This finding suggests that although the pres-ence of a longer silence interval is the best cue tofinality, additional prosodic features, such as dif-ferences in pitch and intensity, concurrently sig-nal the opportunity for another speaker to start aturn.
Text features, especially in highly disflu-ent conversational speech, provide less clear ev-idence.
Results appear in Table 5.3.1.5.3.2 Recognizing InterruptionsIn order to create a comparable context for ini-tial words in interruption and smoothly initiatedturns, we reversed the direction of the contex-tual comparisons, comparing the preceding wordfeatures to those of the current word and mea-suring pre-word silences rather than followingsilences.
Using this configuration, we createda set of 218 interruption initial words and 218smooth transition initial words, following smoothtransitions without overlap.
Based on 10-foldcross-validation for this downsampled balancedcase, we obtain an accuracy of 62%, relative to a50% baseline.
The best classifiers employed onlyprosodic features with silence duration and nor-malized mean word pitch.
Addition of text fea-tures degrades test set performance as the classi-fier rapidly overfits to the training materials.
If weexclude silence related features, accuracy drops toalmost chance.6 Discussion and ConclusionWe have demonstrated that even in a languagethat employs lexical tone, cues to turn and speakerstatus are still carried by prosodic means, includ-ing pitch.
Specifically, turn unit initial syllableshave significantly higher mean pitch and inten-sity than do final syllables in different turn transi-tion types.
The elevation of initial pitch is furtherenhanced in interruptions, when a new speakerseizes the floor beginning with an overlap of thecurrent speaker.
These contrasts are similar tothose observed for English, and consistent withsignals described in the literature.
These changesresult in an overall reduction in pitch for sylla-bles in final position across all tones, but relativepitch height employed by lexical tone is preservedin most cases.
Finally, we employed these cues totrain classifiers to distinguish turn unit final wordsfrom other words in the dialogue and to distin-guish interruption initial words from initial wordsin smooth transitions with no overlap.We further contrasted the utility of text andprosodic features for the identification of turnboundary position and type.
We find that silenceis the most reliable cue both to identify final turnboundaries and to distinguish types of turn tran-sitions.
In conjunction with silence features, text,prosodic, and joint text-prosodic features can farecomparably.
However, for turn unit boundaries,the availability of a variety of prosodic featuresproves to be essential for relatively better classifi-cation in the absence of silence information.In future work, we plan to enhance tone recog-nition by better contextual modeling that willcompensate for the effects of a variety of dis-course boundaries, including turn and topic, ontone realization.
We also plan to embed turn-based classification in a sequential discriminativemodel to further facilitate integration of prosodicand lexical features as well as sequence con-straints on turn structure.AcknowledgmentsWe would like to thank the developers of the Tai-wanese Putonghua corpus and the Linguistic DataConsortium for the provision of these resources.This work was supported by NSF Grant 0414919.ReferencesP.
Boersma.
2001.
Praat, a system for doing phoneticsby computer.
Glot International, 5(9?10):341?345.C-C.Cheng and C-J.
Lin.
2001.
LIBSVM:a libraryfor support vector machines.
Software available at:http://www.csie.ntu.edu.tw/ cjlin/libsvm.San Duanmu.
1996.
Notes on word boundaries.
Tai-wanese Putonghua Corpus Documentation.S.
Duncan, 1974.
Some signals and rules for takingspeaking turns in conversations, pages 298?311.Gina-Anne Levow.
2004.
Prosody-based topic seg-mentation for mandarin broadcast news.
In Pro-ceedings of HLT-NAACL 2004, Companion Volume,pages 137?140.77Prosody Only Text Prosody + TextWith silence 93.7% 93.5% 93.1%Without silence 66.5% 59.5% 69%Table 2: Recognition of turn unit final vs. non-final wordsY.
Liu, A. Stolcke, E. Shriberg, and M. Harper.
2004.Comparing and combining generative and poste-rior probability models: Some advances in sentenceboundary detection in speech.
In Proceedings ofConf.
on Empirical Methods in Natural LanguageProcessing.M.
Ostendorf.
forthcoming.
Prosodic boundary de-tection.
In M. Horne, editor, Prosody: Theoryand Experiment.
Studies Presented to Gosta Bruce.Kluwer.B.
Pellom, W. Ward, J. Hansen, K. Hacioglu, J. Zhang,X.
Yu, and S. Pradhan.
2001.
University of Col-orado dialog systems for travel and navigation.J.R.
Quinlan.
1992.
C4.5: Programs for MachineLearning.
Morgan Kaufmann.Robert E. Schapire and Yoram Singer.
2000.
Boost-exter: A boosting-based system for text categoriza-tion.
Machine Learning, 39(2?3):135?168.E.
Shriberg, A. Stolcke, and D. Baron.
2001.
Canprosody aid the automatic processing of multi-partymeetings?
evidence from predicting punctuation,disfluencies, and overlapping speech.
In Proc.
ofISCA Tutorial and Research Workshop on Prosodyin Speech Recognition and Understanding.N.
Ward and W. Tsukahara.
2000.
Prosodic featureswhich cue back-channel responses in English andJapanese.
Journal of Pragmatics, 23:1177?1207.Yi Xu.
1997.
Contextual tonal variations in Mandarin.Journal of Phonetics, 25:62?83.78
