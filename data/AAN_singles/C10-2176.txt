Coling 2010: Poster Volume, pages 1541?1549,Beijing, August 2010Automatic Treebank Conversion via Informed DecodingMuhua ZhuNatural Language Processing Lab.Northeastern Universityzhumuhua@gmail.comJingbo ZhuNatural Language Processing Lab.Northeastern Universityzhujingbo@mail.neu.edu.cnAbstractIn this paper, we focus on the challengeof automatically converting a constituencytreebank (source treebank) to fit the stan-dard of another constituency treebank (tar-get treebank).
We formalize the conver-sion problem as an informed decodingprocedure: information from original an-notations in a source treebank is incorpo-rated into the decoding phase of a parsertrained on a target treebank during theparser assigning parse trees to sentences inthe source treebank.
Experiments on twoChinese treebanks show significant im-provements in conversion accuracy overbaseline systems, especially when trainingdata used for building the parser is smallin size.1 IntroductionRecent years have seen extensive applications ofmachine learning methods to natural languageprocessing problems.
Typically, increase in thescale of training data boosts the performance ofmachine learning methods, which in turn en-hances the quality of learning-based NLP systems(Banko and Brill, 2001).
However, annotatingdata by human is time consuming and labor inten-sive.
For this reason, human-annotated corporaare considered as the most valuable resource forNLP.In practice, there often exist more than one cor-pus for the same NLP tasks.
For example, forconstituent syntactic parsing (Collins, 1999; Char-niak, 2000; Petrov et al, 2006) for Chinese, in ad-dition to the most popular treebank Chinese Tree-bank (CTB) (Xue et al, 2002), there are alsoother treebanks such as Tsinghua Chinese Tree-bank (TCT) (Zhou, 1996).
For the purpose offull use of readily available human annotationsfor the same tasks, it is significant if such cor-pora can be used jointly.
Such attempt is es-pecially significant for some languages that havelimited size of labeled data.
At first sight, a di-rect combination of multiple corpora is a way tothis end.
However, corpora created for the sameNLP tasks are generally built by different orga-nizations.
Thus such corpora often follow dif-ferent annotation standards and/or even differentlinguistic theories.
We take CTB and TCT asa case study.
Although both CTB and TCT areChomskian-style treebanks, they have annotationdivergences in at least two dimensions: a) CTBand TCT have dramatically different tag sets, in-cluding parts-of-speech and grammar labels, andthe tags cannot be mapped one to one; b) CTB andTCT have distinct hierarchical structures.
For ex-ample, the Chinese words ???
(Chinese) ??
(traditional) ??
(culture)?
are grouped as a flatnoun phrase according to the CTB standard (rightside in Fig.
1), but in TCT, the last two words areinstead grouped together beforehand (left side inFig.
1).
The differences cause such treebanks ofdifferent annotation standard to be generally usedindependently.In this paper, we focus on unifying multipleconstituency treebanks of distinct annotation stan-dards through treebank conversion.
The task oftreebank conversion is defined to be conversion ofannotations in one treebank (source treebank) to1541npnS??npa??n??NPNR??NN??NN????????
(Chinese) (traditional) (culture)Figure 1: Example tree fragments with TCT (left)and CTB (right) annotationsfit the standard of another treebank (target tree-bank).
To this end, we propose a language in-dependent approach called informed decoding 1,in which a parser trained on a target treebank au-tomatically assigns new parse trees to sentencesin a source treebank with the aid of informa-tion derived from annotations in the source tree-bank.
We conduct experiments on two open Chi-nese treebanks 2: CTB and TCT.
Experimental re-sults show that our approach achieves significantimprovements over baseline systems, especiallywhen training data used for building the parser issmall in size.The rest of the paper is structured as follows.
InSection 2 we describe previous work on treebankconversion.
In Section 3, we describe in detail theinformed decoding approach.
Section 4 presentsexperimental results which demonstrate the effec-tiveness of our approach.
Finally, Section 5 con-cludes our work.2 Related WorkPrevious work on treebank conversion can begrouped into two categories according to whethergrammar formalisms of treebanks are identical.One type focuses on converting treebanks of dif-ferent grammar formalisms.
Collins et al (1999)1The terminology decoding is referred to the parsingphase of a parser.2Note that although we use Chinese treebanks, our ap-proach is language independent.addressed constituent syntactic parsing on Czechusing a treebank converted from a Prague depen-dency treebank, where conversion rules derivedfrom head-dependent pairs and heuristic rules areapplied.
Xia and Palmer (2001) compared threealgorithms for conversion from dependency struc-tures to phrase structures.
The algorithms ex-panded each node in input dependency structuresinto a projection chain, and labeled the newly in-serted node with syntactic categories.
The threealgorithms differ only in heuristics adopted tobuild projection chains.
Xia et al (2008) auto-matically extracted conversion rules from a tar-get treebank and proposed strategies to handle thecase when more than one conversion rule are ap-plicable.
Instead of using conversion rules, Niuet al (2009) proposed to convert a dependencytreebank to a constituency one by using a parsertrained on a constituency treebank to generate k-best lists for sentences in the dependency tree-bank.
Optimal conversion results are selectedfrom the k-best lists.
There also exists work in thereverse direction: from a constituency treebank toa dependency treebank (Nivre, 2006; Johanssonand Nugues, 2007).Relatively few efforts have been put on conver-sion between treebanks that have the same gram-mar formalisms but follow different annotationstandards.
Wang et al (1994) applied a similarframework as in (Niu et al, 2009) to convert froma simple constituency treebank to a more infor-mative one.
The basic idea is to apply a parserbuilt on a target treebank to generate k-best listsfor sentences in the source treebank.
Then, amatching metric is defined on the number of iden-tical bracketing spans between two trees.
Such afunction computes a score for each parse tree ina k-best list and its corresponding parse tree inthe source treebank.
Finally, the parse tree withthe highest score in a k-best list is selected to bethe conversion result.
The difference between ourwork and (Wang et al, 1994) is that, instead of us-ing trees from the source treebank to select parsetrees from k-best lists, we propose to use suchtrees to guide the decoding phase of the parserbuilt on the target treebank.
Making use of thesource treebank in such a novel way is believed tobe the major contribution of our work.15423 Treebank Conversion via InformedDecodingThe task of treebank conversion is defined to con-vert parse trees in a source treebank to fit the stan-dard of a target treebank.
In the informed de-coding approach, treebank conversion proceeds intwo steps: 1) build a parser on a target treebank;2) apply the parser to decode sentences in a sourcetreebank with the aid of information derived fromthe source treebank.
For convenience, parse treesin a source treebank are referred to as source treesand corresponding, trees from a target treebankare referred to as target trees.
Moreover, a parserbuilt on a target treebank is referred to as targetparser.
In the following sections, we first describemotivation of our work and then present details ofthe informed decoding approach.3.1 MotivationWe use the example in Fig.
2 to illustrate whyoriginal annotations in a source treebank can helpin treebank conversion.
The figure depicts threetree fragments for the Chinese words ?
(pay) ?
(already) ?
(one) ?
(day) ?
(of) ??
(salary),among which Fig.
2(a) and Fig.
2(b) are tree frag-ments of the CTB standard and Fig.
2(c) is a treefragment of the TCT standard.
From the fig-ure, we can see that these Chinese words actu-ally have (at least) two plausible interpretationsof the meaning.
In Fig.
2(a), the words meanpay salary for one-day work while in Fig.
2(b),the words mean spend one day on paying salary.If Fig.
2(c) is a source tree to be converted intothe CTB standard, then Fig.
2(b) will be rejectedsince it conflicts with Fig.
2(c) with respect to treestructures.
Note that structures reflect underlyingsentence meaning.
On the other hand, althoughFig.
2(a) also has (minor) differences in tree struc-tures from Fig.
2(c), it is preferred as the conver-sion result3.
From the example we can get in-spired by the observation that original annotationsin a source treebank are informative and necessaryto converting parse trees in the source treebank.In general, conversion like that from Fig.
2(c)3Note that we don?t deny existence of annotation distinc-tions between the treebanks, but we aim to make use of whatthey both agree on.
We assume that consensus is the major-ity.to Fig.
2(a) requires sentence-specific conversionrules which are difficult to obtain in practice.
Inorder to make use of information provided byoriginal annotations in a source treebank, Wanget al (1994) proposed a selecting-from-k-best ap-proach where source trees are used to select one?optimal?
parse tree from each k-best list gener-ated by a target parser.
In this paper, we instead in-corporate information of original annotations intothe parsing phase.
The underlying motivation istwo-fold:?
The decoding phase of a parser is essentiallya search process.
Due to the extreme mag-nitude of searching space, pruning of searchpaths is practically necessary.
If reliable in-formation is provided to guide the pruning ofsearch paths, more efficient parsing and bet-ter results are expected.?
Selecting-from-k-best works on the basis ofk-best lists.
Unfortunately, we often see veryfew variations in k-best lists.
For exam-ple, 50-best trees present only 5 to 6 varia-tions (Huang, 2008).
The lack of diversi-ties in k-best lists makes information fromthe source treebank less effective in selectingparse trees.
By contrast, incorporating suchinformation into decoding makes the infor-mation affect the whole parse forest.3.2 Formalization of Information fromSource TreebankIn this paper, information from a source treebanktranslates into two strategies which help a targetparser to prune illegal partial parse trees and torank legal partial parse trees higher.
Following arethe two strategies:?
Pruning strategy: despite distinctions exist-ing between annotation standards of a sourcetreebank and a target treebank, a source tree-bank indeed provides treebank conversionwith indicative information on bracketingstructures and grammar labels.
So when apartial parse tree is generated, it should beexamined against the corresponding sourcetree.
Unless the partial parse tree does notconflict with any constituent in the sourcetree, it should be pruned out.1543VPVV?AS?NPDNPQPCD?CLPM?DEC?NN??VPDVPVPVV?AS?QPCD?CLPM?DEC?NPNN??vpv?uA?npmpm?qN?uJDE?n??
(a) (b) (c)???????
(pay) (already) (one) (day) (of) (salary)Figure 2: tree fragments of words???????
: (a) and (b) show two plausible tree fragments ofthe words using the CTB standard; (c) shows a tree fragment of the TCT standard which has the sameinterpretation as (a).64152 3[1,3],[2,3],[1,1][1,1][2,3],[2,2],[3,3][1,1][2,2][3,3]Figure 3: Constituent set of a synthetic parse tree?
Rescoring strategy: in practice, decoding isoften a local optimal search process.
In somecases even if a correct parse tree exits in theparse forest, parsers may fail to rank it to thetop position.
Rescoring strategy is used toincrease scores for partial parse trees whichare confidently thought to be valid.3.2.1 Pruning StrategyThe pruning strategy used in this paper is basedon the concept of conflict which is defined in twodimensions: structures and grammar labels.
Sincea tree structure can be equivalently representedas its span (interval of word indices) set, we cancheck whether two trees conflict by checking theirspans.
See Fig.
3 for an illustration of spans of atree.
Following are criteria determining whethertwo trees conflict in their structures.?
If one node in tree A is raised to be a childof the node?s grandfather in tree B, and thegrandfather has more than two children, thentree A and tree B conflict in structures.?
If tree A has a span [a, b] and tree B has aspan [m,k] and these two spans satisfy thecondition of either a < m ?
b < k or m <a ?
k < b, then tree A and B conflict instructures.Fig.
4 illustrates criteria mentioned above, whereFig.
4(a) is compatible (not conflict) with Fig.
4(b)although they have different structures.
ButFig.
4(a) conflicts with Fig.
4(c) (according to cri-terion 1; node 3 is raised) and (d) (according tocriterion 2).1544651 2 347651 234651 23 4751 263 4(a) (b) (c) (d)Figure 4: Illustrating example of the concept of conflict: (a) and (b) are compatible (not conflict); (a)conflicts with (c) (condition 1) and (d) (condition 2)For the dimension of grammar labels, we manu-ally construct a mapping between label sets (POStags excluded) of source and target treebanks.Such a mapping is frequently a many-to-manymapping.
Two labels are said to be conflicting ifthey are from different label sets and they cannotbe mapped.By combining these two strategies, two parsetrees (of different standards) which yield the samesentence are said to be conflicting if they conflictin both structures and labels.
Note that we de-scribe pruning strategy for the case of two parsetrees.
In informed decoding process, this strategyis actually applied to every partial parse tree gen-erated during decoding.3.2.2 Rescoring StrategyAs mentioned above, despite that the pruningstrategy helps in improving conversion accuracy,we are faced with the problem of how to rankvalid parse trees higher in a parse forest.
To solvethe problem, we adjust the scores of those partialparse trees that are considered to be confidently?good?.
The criteria which is used to judge ?good-ness?
of a partial parse are listed as follows:?
The partial parse tree can find in the sourcetree a constituent that has the same structureas it.?
When the first criterion is satisfied, gram-mar categories of this partial parse should notconflict with the grammar categories of itscounterpart.In practice, we use a parameter ?
to adjust thescore.Pnew(e) = ?
?
P (e) (1)Here e represents any partial tree that is rescored,and P (e) and Pnew(e) refer to original and newscores, respectively.3.3 Parsing ModelTheoretically all parsing models are applicable ininformed decoding, but we prefer to adopt a CKY-style parser for two reasons: CKY style parsersare dynamically bottom-up and always have edges(or parsing items) belonging to the same spanstacked together in the same chart4 cell.
Theproperty of CKY-style parsers being dynamicallybottom-up can make the pruning strategy efficientby avoiding rechecking subtrees that have alreadybeen checked.
The property of stacking edges inthe same chart cell makes CKY-style parsers eas-ily portable to the situaiton of informed decod-ing.
In this paper, Collins parser (Collins, 1999)is used.
Algorithm 1 presents the extended ver-sion of the decoding algorithm used in Collinsparser.
What the algorithm needs to do is togenerate edges for each span.
And before edgesare allowed to enter the chart, pruning conditions4Data structure used to store paring items that are notpruned1545Algorithm 1 CKY-style decodingArgument: a parsing decodera sentence to be parsed and correspondingsource treeBeginSteps:1. initialization steps2.
for span from 2 to sentence length dofor start from 1 to (sentence length-span+1) doend := (start + span - 1)for each edge e for span [start, end] dogenerate(e, start, end)prune(e, start, end)rescore(e, start, end)add edge(e, start, end)EndSubroutine:generate: generates an edge which belongs to thespan [start, end].prune: apply pruning strategy to check whether theedge should be pruned.rescore: apply rescoring strategy to weight the edge.add edge: add the edge into chart.should be checked in prune subroutine and rescor-ing should be conducted in rescore subroutinewith respect to the corresponding source tree.4 Experiments4.1 Experimental SetupIn this paper, we conduct two groups of experi-ments in order to evaluate 1) treebank conversionaccuracy and 2) how much newly generated datacan boost syntactic parsing accuracy.
For the ex-periments of treebank conversion, Penn ChineseTreebank (CTB) 5.1 is used as the target treebank.That is, the CTB standard is the one we are inter-ested in.
Following the conventional data split-ting of CTB5.1, articles 001-270 and 400-1151(18,100 sentences, 493,869 words) are used fortraining, articles 271-300 (348 sentences, 8,008words) are used as test data, and articles 301-325(352 sentences, 6,821 words) are used as devel-opment data 5.
Moreover, in order to directlyevaluate conversion accuracy, we randomly sam-pled 150 sentences from the CTB test set and havethree annotators manually label sentences of theseparse trees according to the standard of TsinghuaChinese Treebank (TCT).
Thus each of the 150sentences has two parse trees, following the CTB5Development set is not used in this paper.and TCT standard, respectively.
For convenienceof reference, the set of 150 parse trees of theCTB standard is referred to as Sample-CTB andits counterpart which follows the TCT standard isreferred to as Sample-TCT.
In such setting, the ex-periments of treebank conversion is designed touse the informed decoding approach to convertSample-TCT to the standard of CTB and conver-sion results are evaluated with respect to Sample-CTB.
The CTB training data (or portion of it) isused as target training data on which parsers aretrained for conversion.For the experiments of syntactic parsing, theTCT corpus is used as the source treebank.The TCT corpus contains 27,268 sentences and587,298 words, which are collected from the lit-erature and newswire domains.
In this group ofexperiments, the CTB training data is again usedas target training data and the whole TCT cor-pus is converted using the informed decoding ap-proach.
The newly-gained parse trees are used asadditional training data for syntactic parsing onthe CTB test data.
One thing worth noting in theexperiments is that, using Collins parser to con-vert the TCT corpus requires Part-of-Speech tagsof the CTB standard be assigned to sentences inTCT ahead of conversion being conducted.
To thisend, instead of using POS taggers, we use the la-bel correspondence learning method described in(Zhu and Zhu, 2009) in order to get high POS tag-ging accuracy.For all the experiments in this paper, bracketingF1 is used as the performance metric, provided bythe EVALB program 6. ?
in Eq.1 is set to 3.0 sinceit provides best conversion results in our experi-ments.4.2 Experiments on ConversionThe setup of conversion experiments is describedabove.
In the experiments, we use two representa-tive baseline systems.
One, named directly pars-ing (DP) converts Sample-TCT by directly pars-ing using Collins parser which is trained on tar-get training data, and the other is the method pro-posed in (Wang et al, 1994) (hereafter referredto as Wang94).
For the latter baseline, we useBerkeley parser (Petrov et al, 2006) instead of6http://nlp.cs.nyu.edu/evalb1546Ratio 20% 40% 60% 80% 100%DP 73.19 75.21 79.43 80.64 81.40Wang94 75.00 76.82 78.08 81.50 82.47This paper 82.71 83.00 83.37 84.80 84.34Table 1: Conversion accuracy with varying size oftarget training dataCollins parser.
The reason is that we want to builda strong baseline since Berkeley parser is ableto generate better k-best lists than Collins parserdoes (Zhang et al, 2009).
In detail, Wang94 pro-ceeds in two steps: 1) use Berkeley parser to gen-erate k-best lists for sentences in Sample-TCT; 2)select a parse tree from each k-best list with re-spect to original annotations in Sample-TCT.
Herewe set k to 50.
Table 1 reports F1 scores of thebaseline systems and our informed decoding ap-proach with varying size of target training data.The first row of the table represents fractions ofthe CTB training data which are used as targettraining data.
For example, 40% means 7,240parse trees (of 18,100) in the CTB training dataare used.
To relieve the effect of ordering, werandomly shuffled parse trees in the CTB trainingdata.From the table, we can see that our ap-proach performs significantly better than DP andWang94.
In detail, when 100% CTB training datais used as target training data, 2.95% absolute im-provement is achieved.
When the size of targettraining data decreases, absolute improvements ofour approach over baseline systems are further en-larged.
More interestingly, decreasing in targettraining data only results in marginal decrementin conversion accuracy of our approach.
This is ofsignificant importance in the situation where tar-get treebank is small in size.In order to evaluate the accuracy of conversionmethods on different span lengths, we comparethe results of Wang94 and informed decoding pro-duced by using 100% CTB training data.
Table 2shows the statistics.From the results we can see that our ap-proach performs significantly better on long spansand achieves marginally lower accuracy on smallones.
But notice that the informed decoding ap-proach is implemented on the base of CollinsSpan Length 2 4 6 8 10Wang94 82.45 83.97 80.72 77.83 71.72This paper 83.72 82.95 79.84 77.27 70.67Span Length 12 14 16 18 20Wang94 75.29 68.00 77.27 70.83 76.66This paper 71.79 75.00 86.27 80.00 80.00Table 2: Conversion accuracy on different spanlengthsCategory ADJP VCD CP DNP ADVPWang94 79.62 57.14 65.43 84.76 91.73This paper 88.00 66.67 71.60 88.31 93.44Table 3: Conversion results with respect to differ-ent grammar categoriesparser and that Wang94 works on the basis ofBerkeley parser.
Taking the performance gap ofCollins parser and Berkeley parser, we actuallycan conclude that on small spans, our approach isable to achieve results comparable with or evenbetter than Wang94.
We can also infer fromthe observation that our approach can outperformWang94 when converting parse trees which yieldlong sentences.Another line of analysis is to compare theresults of Wang94 and our approach, with re-spect to different grammar categories.
Table 3lists five grammar categories in which our ap-proach achieves most improvements.
For cat-egories NP and VP, absolute improvements are1.1% and 1.4% respectively.
Take into accountlarge amounts of instances of NP and VP, the im-provements are also quite significant.4.3 Experiments on ParsingBefore doing the experiments of parsing, we firstconverted the whole TCT corpus using 100%CTB training data as target training data.
Us-ing the newly-gained data only as training datafor Collins parser, we can get F1 score 75.4%on the CTB test data.
We can see that the scoreis much lower than the accuracy achieved by us-ing the CTB training data (75.4% vs. 82.04%).Possible reasons that result in lower accuracy in-cludes: 1) divergences in word segmentation stan-dards between TCT and CTB; 2) divergences ofdomains of TCT and CTB; 3) conversions errorsin newly-gained data.
Although the newly-gained1547data cannot replace the CTB training data thor-oughly, we would like to use it as additional train-ing data besides the CTB training data.
Followingexperiments aim to examine effectiveness of thenewly-gained data when used as additional train-ing data.In the first parsing experiment, the TCT cor-pus is converted using portions of the CTB train-ing data.
As in the conversion experiments, parsetrees in the CTB training data are randomly or-dered before splitting of the training set.
For eachportion, newly-gained data together with the por-tion of the CTB training data are used to train anew parser.
Evaluation results on the CTB testdata are presented in Table 4.Ratio 20% 40% 60% 80% 100%Collins 75.74 77.65 79.43 81.22 82.04Collins+ 78.86 79.52 80.06 81.77 82.38Table 4: Parsing accuracy with new data added inHere in Table 4, the first row represents ratiosof parse trees from the CTB training data.
Forexample, 40% means the first 40% parse trees inthe CTB training data are used.
The Collins rowrepresents the results of only using portions of theCTB training data, and the Collins+ row containsthe results achieved with enlarged training data.From the results, we find that new data indeedprovides complementary information to the CTBtraining data, especially when the training data issmall in size.
But benefits of Collins parser gainedfrom additional training data level out with the in-crement of the training data size.
Actually if tech-niques like corpus weighting (Niu et al, 2009) areapplied to weight differently training data and theadditional data, higher parsing accuracy is reason-ably expected.Another obversion from Table 4 is that theparser trained on 40% CTB training data plusadditional training data achieves higher accuracythan using 60% CTB training data.
We incre-mentally add labeled training data and automatictraining data respectively to 40% CTB trainingdata.
The purpose of this experiment is to see themagnitude of automatic training data which canachieve the same effect as labeled training datadoes.
The results are depicted in Table 5.# of Added Data 2k 4k 6k 8kLabeled Data 78.51 79.52 80.01 81.37Auto Data 78.23 79.11 79.85 79.67Table 5: Parsing accuracy with new data added inFrom the results we see that accuracy gaps be-tween using labeled data and using automatic dataget large with the increment of added data.
Onepossible reason is that more noise is taken whenmore data is added.
This observation further veri-fies that refining techniques like corpus weightingare necessary for using automatically-gained data.5 ConclusionsIn this paper we proposed an approach called in-formed decoding for the task of conversion be-tween treebanks which have different annotationstandards.
Experiments which evaluate conver-sion accuracy directly showed that our approachsignificantly outperform baseline systems.
Moreinterestingly we found that the size of target train-ing data have limited effect on the conversion ac-curacy of our approach.
This is extremely impor-tant for languages which lack enough treebanks inwhose standards we are interested.We also added newly-gained data to targettraining data to check whether new data can boostparsing results.
Experiments showed additionaltraining data provided by treebank conversioncould boost parsing accuracy.ReferencesBanko, Michele and Eric Brill.
2001.
Scaling tovery very large corpora for natural language dis-ambiguation.
In Proc.
of ACL 2001, pages 26-33.Charniak, Eugene.
2000.
A Maximum-Entropy-Inspired Parser.
In Proc.
of NAACL 2000, pages132-139.Collins, Michael.
1999.
Head-driven statistical mod-els for natural language parsing.
Ph.D. thesis, Uni-versity of Pennsylvania.Collins, Michael, Lance Ramshaw, Jan Hajic, andChristoph Tillmann.
1999.
A Statistical Parser forCzech.
In Proc.
of ACL 1999, pages 505-512.Charniak, Eugene.
2000.
A maximum-entropy-inspired parser.
In Proc.
of NAACL 2000, pages132-139.1548Huang, Liang.
2008.
Forest reranking: Discrimina-tive parsing with non-local features.
In Proc.
ofACL 2008, pages 586-594.Johansson, Richard and Pierre Nugues.
2007.
Ex-tended constituent-to-dependency conversion forEnglish.
In Proc.
of NODALIDA 2007, pages 105-112.Nivre, Joakim.
2006.
Inductive Dependency Parsing.In Springer, Volume 34.Niu, Zheng-Yu, Haifeng Wang, Hua Wu.
2009.
Ex-ploiting heterogeneous treebanks for parsing.
InProc.
of ACL 2009, pages 46-54.Petrov, Slav, Leon Barrett, Romain Thibaux, and DanKlein.
2006.
Learning accurate, compact, and in-terpretable tree annotation.
In Proc.
of COLING-ACL 2006, pages 433-440.Xue, Nianwen, Fu dong Chiou, and Martha Palmer.2002.
Building a large-scale Annotated Chinesecorpus.
In Proc.
of COLING 2002, pages 1-8.Wang, Jong-Nae, Jing-Shin Chang, and Keh-Yih Su.1994.
An automatic treebank conversion algorithmfor corpus sharing.
In Proc.
of ACL 1994, pages248-254.Xia, Fei, Rajesh Bhatt, Owen Rambow, MarthaPalmer, and Dipti M. Sharma.
2008.
Towards aMulti-Representational Treebank.
In Proc.
of the7th International Workshop on Treebanks and Lin-guistic THeories, pages 159-170.Zhang, Hui, Min Zhang, Chew Lim Tan, and HaizhouLi.
2009.
K-best combination of syntactic parsers.In Proc.
of EMNLP 2009, pages 1552-1560.Zhou, Qiang.
1996.
Phrase bracketing and annotatingon Chinese language corpus.
(in Chinese) Ph.D.thesis, Beijing University.Zhu, Muhua and Jingbo Zhu.
2009.
Label Corre-spondence Learning for Part-of-Speech AnnotationTransformation.
In Proc.
of CIKM 2009, pages1461-1464.1549
