Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 994?1003,Berlin, Germany, August 7-12, 2016.c?2016 Association for Computational LinguisticsA Persona-Based Neural Conversation ModelJiwei Li1*Michel Galley2Chris Brockett2Georgios P. Spithourakis3*Jianfeng Gao2Bill Dolan21Stanford University, Dept.
of Computer Sciencejiweil@stanford.edu2Microsoft Research, Redmond{mgalley,chrisbkt,jfgao,billdol}@microsoft.com3University College London, Dept.
of Computer Scienceg.spithourakis@cs.ucl.ac.ukAbstractWe present persona-based models for han-dling the issue of speaker consistency inneural response generation.
A speakermodel encodes personas in distributed em-beddings that capture individual charac-teristics such as background informationand speaking style.
A dyadic speaker-addressee model captures properties of in-teractions between two interlocutors.
Ourmodels yield qualitative performance im-provements in both perplexity and BLEUscores over baseline sequence-to-sequencemodels, with similar gains in speaker con-sistency as measured by human judges.1 IntroductionAs conversational agents gain traction as user in-terfaces, there has been growing research inter-est in training naturalistic conversation systemsfrom large volumes of human-to-human interac-tions (Ritter et al, 2011; Sordoni et al, 2015;Vinyals and Le, 2015; Li et al, 2016).
One major is-sue for these data-driven systems is their propensityto select the response with greatest likelihood?ineffect a consensus response of the humans repre-sented in the training data.
Outputs are frequentlyvague or non-committal (Li et al, 2016), and whennot, they can be wildly inconsistent, as illustratedin Table 1.In this paper, we address the challenge of consis-tency and how to endow data-driven systems withthe coherent ?persona?
needed to model human-like behavior, whether as personal assistants, per-* The entirety of this work was conducted at Microsoft.message Where do you live now?response I live in Los Angeles.message In which city do you live now?response I live in Madrid.message In which country do you live now?response England, you?message Where were you born?response I was born in Canada.message Where are you from?response England, you?message Where did you grow up?response I grew up in Texas.message How old are you?response 16 and you?message What?s your age?response 18.message What is your major?response I?m majoring in psychologymessage What did you study in college?response English lit.Table 1: Inconsistent responses generated by a 4-layerSEQ2SEQ model trained on 25 million Twitter conversationsnippets.sonalized avatar-like agents, or game characters.1For present purposes, we will define PERSONAas the character that an artificial agent, as actor,plays or performs during conversational interac-tions.
A persona can be viewed as a compositeof elements of identity (background facts or userprofile), language behavior, and interaction style.A persona is also adaptive, since an agent mayneed to present different facets to different humaninterlocutors depending on the interaction.Fortunately, neural models of conversation gen-eration (Sordoni et al, 2015; Shang et al, 2015;Vinyals and Le, 2015; Li et al, 2016) provide astraightforward mechanism for incorporating per-sonas as embeddings.
We therefore explore two per-1(Vinyals and Le, 2015) suggest that the lack of a coherentpersonality makes it impossible for current systems to passthe Turing test.994sona models, a single-speaker SPEAKER MODELand a dyadic SPEAKER-ADDRESSEE MODEL,within a sequence-to-sequence (SEQ2SEQ) frame-work (Sutskever et al, 2014).
The Speaker Modelintegrates a speaker-level vector representation intothe target part of the SEQ2SEQ model.
Analo-gously, the Speaker-Addressee model encodes theinteraction patterns of two interlocutors by con-structing an interaction representation from theirindividual embeddings and incorporating it intothe SEQ2SEQ model.
These persona vectors aretrained on human-human conversation data andused at test time to generate personalized responses.Our experiments on an open-domain corpus ofTwitter conversations and dialog datasets compris-ing TV series scripts show that leveraging personavectors can improve relative performance up to20% in BLEU score and 12% in perplexity, witha commensurate gain in consistency as judged byhuman annotators.2 Related WorkThis work follows the line of investigation initiatedby Ritter et al (2011) who treat generation of con-versational dialog as a statistical machine transla-tion (SMT) problem.
Ritter et al (2011) representsa break with previous and contemporaneous dialogwork that relies extensively on hand-coded rules,typically either building statistical models on topof heuristic rules or templates (Levin et al, 2000;Young et al, 2010; Walker et al, 2003; Pieracciniet al, 2009; Wang et al, 2011) or learning genera-tion rules from a minimal set of authored rules orlabels (Oh and Rudnicky, 2000; Ratnaparkhi, 2002;Banchs and Li, 2012; Ameixa et al, 2014; Nio etal., 2014; Chen et al, 2013).
More recently (Wenet al, 2015) have used a Long Short-Term Memory(LSTM) (Hochreiter and Schmidhuber, 1997) tolearn from unaligned data in order to reduce theheuristic space of sentence planning and surfacerealization.The SMT model proposed by Ritter et al, onthe other hand, is end-to-end, purely data-driven,and contains no explicit model of dialog structure;the model learns to converse from human-to-humanconversational corpora.
Progress in SMT stemmingfrom the use of neural language models (Sutskeveret al, 2014; Gao et al, 2014; Bahdanau et al, 2015;Luong et al, 2015) has inspired efforts to extendthese neural techniques to SMT-based conversa-tional response generation.
Sordoni et al (2015)augments Ritter et al (2011) by rescoring out-puts using a SEQ2SEQ model conditioned on con-versation history.
Other researchers have recentlyused SEQ2SEQ to directly generate responses in anend-to-end fashion without relying on SMT phrasetables (Serban et al, 2015; Shang et al, 2015;Vinyals and Le, 2015).
Serban et al (2015) proposea hierarchical neural model aimed at capturing de-pendencies over an extended conversation history.Recent work by Li et al (2016) measures mutualinformation between message and response in or-der to reduce the proportion of generic responsestypical of SEQ2SEQ systems.
Yao et al (2015) em-ploy an intention network to maintain the relevanceof responses.Modeling of users and speakers has been exten-sively studied within the standard dialog model-ing framework (e.g., (Wahlster and Kobsa, 1989;Kobsa, 1990; Schatztnann et al, 2005; Lin andWalker, 2011)).
Since generating meaningful re-sponses in an open-domain scenario is intrinsi-cally difficult in conventional dialog systems, ex-isting models often focus on generalizing characterstyle on the basis of qualitative statistical analysis(Walker et al, 2012; Walker et al, 2011).
Thepresent work, by contrast, is in the vein of theSEQ2SEQ models of Vinyals and Le (2015) and Liet al (2016), enriching these models by trainingpersona vectors directly from conversational dataand relevant side-information, and incorporatingthese directly into the decoder.3 Sequence-to-Sequence ModelsGiven a sequence of inputs X = {x1, x2, ..., xnX},an LSTM associates each time step with an inputgate, a memory gate and an output gate, respec-tively denoted as it, ftand ot.
We distinguish eand h where etdenotes the vector for an individualtext unit (for example, a word or sentence) at timestep t while htdenotes the vector computed by theLSTM model at time t by combining etand ht?1.ctis the cell state vector at time t, and ?
denotes thesigmoid function.
Then, the vector representationhtfor each time step t is given by:????itftotlt????=???????tanh???
?W ?
[ht?1est](1)ct= ft?
ct?1+ it?
lt(2)hst= ot?
tanh(ct) (3)995where Wi, Wf, Wo, Wl?
RK?2K.
InSEQ2SEQ generation tasks, each input X is pairedwith a sequence of outputs to predict: Y ={y1, y2, ..., ynY}.
The LSTM defines a distribu-tion over outputs and sequentially predicts tokensusing a softmax function:p(Y |X) =ny?t=1p(yt|x1, x2, ..., xt, y1, y2, ..., yt?1)=ny?t=1exp(f(ht?1, eyt))?y?exp(f(ht?1, ey?
))where f(ht?1, eyt) denotes the activation functionbetween ht?1and eyt.
Each sentence terminateswith a special end-of-sentence symbol EOS.
Inkeeping with common practices, inputs and out-puts use different LSTMs with separate parametersto capture different compositional patterns.During decoding, the algorithm terminates whenan EOS token is predicted.
At each time step, eithera greedy approach or beam search can be adoptedfor word prediction.4 Personalized Response GenerationOur work introduces two persona-based models:the Speaker Model, which models the personal-ity of the respondent, and the Speaker-AddresseeModel which models the way the respondent adaptstheir speech to a given addressee ?
a linguistic phe-nomenon known as lexical entrainment (Deutschand Pechmann, 1982).4.1 NotationFor the response generation task, let M de-note the input word sequence (message) M ={m1,m2, ...,mI}.
R denotes the word sequence inresponse to M , where R = {r1, r2, ..., rJ, EOS}and J is the length of the response (terminatedby an EOS token).
rtdenotes a word token thatis associated with a K dimensional distinct wordembedding et.
V is the vocabulary size.4.2 Speaker ModelOur first model is the Speaker Model, which mod-els the respondent alone.
This model representseach individual speaker as a vector or embedding,which encodes speaker-specific information (e.g.,dialect, register, age, gender, personal informa-tion) that influences the content and style of herresponses.
Note that these attributes are not ex-plicitly annotated, which would be tremendouslyexpensive for our datasets.
Instead, our model man-ages to cluster users along some of these traits (e.g.,age, country of residence) based on the responsesalone.Figure 1 gives a brief illustration of the SpeakerModel.
Each speaker i ?
[1, N ] is associated witha user-level representation vi?
RK?1.
As in stan-dard SEQ2SEQ models, we first encode messageS into a vector representation hSusing the sourceLSTM.
Then for each step in the target side, hiddenunits are obtained by combining the representationproduced by the target LSTM at the previous timestep, the word representations at the current timestep, and the speaker embedding vi:????itftotlt????=???????tanh???
?W ???ht?1estvi??
(4)ct= ft?
ct?1+ it?
lt(5)hst= ot?
tanh(ct) (6)whereW ?
R4K?3K.
In this way, speaker informa-tion is encoded and injected into the hidden layer ateach time step and thus helps predict personalizedresponses throughout the generation process.
TheSpeaker embedding {vi} is shared across all con-versations that involve speaker i.
{vi} are learnedby back propagating word prediction errors to eachneural component during training.Another useful property of this model is that ithelps infer answers to questions even if the evi-dence is not readily present in the training set.
Thisis important as the training data does not contain ex-plicit information about every attribute of each user(e.g., gender, age, country of residence).
The modellearns speaker representations based on conversa-tional content produced by different speakers, andspeakers producing similar responses tend to havesimilar embeddings, occupying nearby positionsin the vector space.
This way, the training data ofspeakers nearby in vector space help increase thegeneralization capability of the speaker model.
Forexample, consider two speakers i and j who sounddistinctly British, and who are therefore close inspeaker embedding space.
Now, suppose that, inthe training data, speaker i was asked Where doyou live?
and responded in the UK.
Even if speakerj was never asked the same question, this answercan help influence a good response from speakerj, and this without explicitly labeled geo-locationinformation.996EOS RobWordembeddings(50k)englandlondonu.s.greatgoodstaylive okaymondaytuesdaySpeakerembeddings(70k)Rob_712where do you liveinin Rob england Robengland.
Rob.
EOSSource Targetskinnyoflynny2TomcoatezKush_322D_Gomes25Dreamswallskierongillen5TheCharlieZThe_Football_BarThis_Is_ArtfulDigitalDan285Jinnmeow3Bob_Kelly2Figure 1: Illustrative example of the Speaker Model introduced in this work.
Speaker IDs close in embedding space tend torespond in the same manner.
These speaker embeddings are learned jointly with word embeddings and all other parameters ofthe neural model via backpropagation.
In this example, say Rob is a speaker clustered with people who often mention Englandin the training data, then the generation of the token ?england?
at time t = 2 would be much more likely than that of ?u.s.?.
Anon-persona model would prefer generating in the u.s. if ?u.s.?
is more represented in the training data across all speakers.4.3 Speaker-Addressee ModelA natural extension of the Speaker Model is amodel that is sensitive to speaker-addressee inter-action patterns within the conversation.
Indeed,speaking style, register, and content does not varyonly with the identity of the speaker, but also withthat of the addressee.
For example, in scripts forthe TV series Friends used in some of our exper-iments, the character Ross often talks differentlyto his sister Monica than to Rachel, with whomhe is engaged in an on-again off-again relationshipthroughout the series.The proposed Speaker-Addressee Model oper-ates as follows: We wish to predict how speaker iwould respond to a message produced by speaker j.Similarly to the Speaker model, we associate eachspeaker with a K dimensional speaker-level repre-sentation, namely vifor user i and vjfor user j. Weobtain an interactive representation Vi,j?
RK?1by linearly combining user vectors viand vjinan attempt to model the interactive style of user itowards user j,Vi,j= tanh(W1?
vi+W2?
v2) (7)where W1,W2?
RK?K.
Vi,jis then linearly in-corporated into LSTM models at each step in thetarget:????itftotlt????=???????tanh???
?W ???ht?1estVi,j??
(8)ct= ft?
ct?1+ it?
lt(9)hst= ot?
tanh(ct) (10)Vi,jdepends on both speaker and addressee andthe same speaker will thus respond differently toa message from different interlocutors.
One po-tential issue with Speaker-Addressee modelling isthe difficulty involved in collecting a large-scaletraining dataset in which each speaker is involvedin conversation with a wide variety of people.Like the Speaker Model, however, the Speaker-Addressee Model derives generalization capabil-ities from speaker embeddings.
Even if the twospeakers at test time (i and j) were never involvedin the same conversation in the training data, twospeakers i?and j?who are respectively close inembeddings may have been, and this can help mod-elling how i should respond to j.4.4 Decoding and RerankingFor decoding, the N-best lists are generated us-ing the decoder with beam size B = 200.
We set amaximum length of 20 for the generated candidates.Decoding operates as follows: At each time step,we first examine allB ?B possible next-word can-didates, and add all hypothesis ending with an EOStoken to the N-best list.
We then preserve the top-Bunfinished hypotheses and move to the next wordposition.To deal with the issue that SEQ2SEQ modelstend to generate generic and commonplace re-sponses such as I don?t know, we follow Li et al(2016) by reranking the generated N-best list using997a scoring function that linearly combines a lengthpenalty and the log likelihood of the source giventhe target:log p(R|M,v) + ?
log p(M |R) + ?|R| (11)where p(R|M, v) denotes the probability of thegenerated response given the message M and therespondent?s speaker ID.
|R| denotes the lengthof the target and ?
denotes the associated penaltyweight.
We optimize ?
and ?
on N-best lists ofresponse candidates generated from the develop-ment set using MERT (Och, 2003) by optimizingBLEU.
To compute p(M |R), we train an inverseSEQ2SEQ model by swapping messages and re-sponses.
We trained standard SEQ2SEQ models forp(M |R) with no speaker information considered.5 Datasets5.1 Twitter Persona DatasetData Collection Training data for the SpeakerModel was extracted from the Twitter FireHose forthe six-month period beginning January 1, 2012.We limited the sequences to those where the respon-ders had engaged in at least 60 (and at most 300)3-turn conversational interactions during the period,in other words, users who reasonably frequently en-gaged in conversation.
This yielded a set of 74,003users who took part in a minimum of 60 and a max-imum of 164 conversational turns (average: 92.24,median: 90).
The dataset extracted using responsesby these ?conversationalists?
contained 24,725,7113-turn sliding-window (context-message-response)conversational sequences.In addition, we sampled 12000 3-turn conversa-tions from the same user set from the Twitter Fire-Hose for the three-month period beginning July 1,2012, and set these aside as development, valida-tion, and test sets (4000 conversational sequenceseach).
Note that development, validation, and testsets for this data are single-reference, which is bydesign.
Multiple reference responses would typ-ically require acquiring responses from differentpeople, which would confound different personas.Training Protocols We trained four-layerSEQ2SEQ models on the Twitter corpus followingthe approach of (Sutskever et al, 2014).
Detailsare as follows:?
4 layer LSTM models with 1,000 hidden cellsfor each layer.?
Batch size is set to 128.?
Learning rate is set to 1.0.?
Parameters are initialized by sampling fromthe uniform distribution [?0.1, 0.1].?
Gradients are clipped to avoid gradient explo-sion with a threshold of 5.?
Vocabulary size is limited to 50,000.?
Dropout rate is set to 0.2.Source and target LSTMs use different sets of pa-rameters.
We ran 14 epochs, and training tookroughly a month to finish on a Tesla K40 GPUmachine.As only speaker IDs of responses were specifiedwhen compiling the Twitter dataset, experimentson this dataset were limited to the Speaker Model.5.2 Twitter Sordoni DatasetThe Twitter Persona Dataset was collected for thispaper for experiments with speaker ID informa-tion.
To obtain a point of comparison with priorstate-of-the-art work (Sordoni et al, 2015; Li etal., 2016), we measure our baseline (non-persona)LSTM model against prior work on the datasetof (Sordoni et al, 2015), which we call the Twit-ter Sordoni Dataset.
We only use its test-set por-tion, which contains responses for 2114 contextand messages.
It is important to note that the Sor-doni dataset offers up to 10 references per message,while the Twitter Persona dataset has only 1 refer-ence per message.
Thus BLEU scores cannot becompared across the two Twitter datasets (BLEUscores on 10 references are generally much higherthan with 1 reference).
Details of this dataset arein (Sordoni et al, 2015).5.3 Television Series TranscriptsData Collection For the dyadic Speaker-Addressee Model we used scripts from theAmerican television comedies Friends2and TheBig Bang Theory,3available from Internet MovieScript Database (IMSDb).4We collected 13main characters from the two series in a corpusof 69,565 turns.
We split the corpus into train-ing/development/testing sets, with developmentand testing sets each of about 2,000 turns.Training Since the relatively small size of thedataset does not allow for training an open domaindialog model, we adopted a domain adaption strat-egy where we first trained a standard SEQ2SEQ2https://en.wikipedia.org/wiki/Friends3https://en.wikipedia.org/wiki/The_Big_Bang_Theory4http://www.imsdb.com998System BLEUMT baseline (Ritter et al, 2011) 3.60%Standard LSTM MMI (Li et al, 2016) 5.26%Standard LSTM MMI (our system) 5.82%Human 6.08%Table 2: BLEU on the Twitter Sordoni dataset (10 references).We contrast our baseline against an SMT baseline (Ritter et al,2011), and the best result (Li et al, 2016) on the establisheddataset of (Sordoni et al, 2015).
The last result is for a humanoracle, but it is not directly comparable as the oracle BLEU iscomputed in a leave-one-out fashion, having one less referenceavailable.
We nevertheless provide this result to give a sensethat these BLEU scores of 5-6% are not unreasonable.models using a much larger OpenSubtitles (OSDb)dataset (Tiedemann, 2009), and then adapting thepre-trained model to the TV series dataset.The OSDb dataset is a large, noisy, open-domaindataset containing roughly 60M-70M scripted linesspoken by movie characters.
This dataset does notspecify which character speaks each subtitle line,which prevents us from inferring speaker turns.
Fol-lowing Vinyals et al (2015), we make the simplify-ing assumption that each line of subtitle constitutesa full speaker turn.5We trained standard SEQ2SEQmodels on OSDb dataset, following the protocolsalready described in Section 5.1.
We run 10 itera-tions over the training set.We initialize word embeddings and LSTM pa-rameters in the Speaker Model and the Speaker-Addressee model using parameters learned fromOpenSubtitles datasets.
User embeddings are ran-domly initialized from [?0.1, 0.1].
We then ran 5additional epochs until the perplexity on the devel-opment set stabilized.6 Experiments6.1 EvaluationFollowing (Sordoni et al, 2015; Li et al, 2016)we used BLEU (Papineni et al, 2002) for parame-ter tuning and evaluation.
BLEU has been shownto correlate well with human judgment on the re-sponse generation task, as demonstrated in (Galleyet al, 2015).
Besides BLEU scores, we also reportperplexity as an indicator of model capability.6.2 BaselineSince our main experiments are with a new dataset(the Twitter Persona Dataset), we first show thatour LSTM baseline is competitive with the state-of-5This introduces a degree of noise as consecutive lines arenot necessarily from the same scene or two different speakers.Model Standard LSTM Speaker ModelPerplexity 47.2 42.2 (?10.6%)Table 3: Perplexity for standard SEQ2SEQ and the Speakermodel on the Twitter Persona development set.Model Objective BLEUStandard LSTM MLE 0.92%Speaker Model MLE 1.12% (+21.7%)Standard LSTM MMI 1.41%Speaker Model MMI 1.66% (+11.7%)Table 4: BLEU on the Twitter Persona dataset (1 reference),for the standard SEQ2SEQ model and the Speaker model usingas objective either maximum likelihood (MLE) or maximummutual information (MMI).the-art (Li et al, 2016) on an established dataset,the Twitter Sordoni Dataset (Sordoni et al, 2015).Our baseline is simply our implementation of theLSTM-MMI of (Li et al, 2016), so results shouldbe relatively close to their reported results.
Table 2summarizes our results against prior work.
We seethat our system actually does better than (Li et al,2016), and we attribute the improvement to a largertraining corpus, the use of dropout during training,and possibly to the ?conversationalist?
nature ofour corpus.6.3 ResultsWe first report performance on the Twitter Personadataset.
Perplexity is reported in Table 3.
We ob-serve about a 10% decrease in perplexity for theSpeaker model over the standard SEQ2SEQ model.In terms of BLEU scores (Table 4), a significant per-formance boost is observed for the Speaker modelover the standard SEQ2SEQ model, yielding an in-crease of 21% in the maximum likelihood (MLE)setting and 11.7% for mutual information setting(MMI).
In line with findings in (Li et al, 2016), weobserve a consistent performance boost introducedby the MMI objective function over a standardSEQ2SEQ model based on the MLE objective func-tion.
It is worth noting that our persona modelsare more beneficial to the MLE models than to theMMI models.
This result is intuitive as the personamodels help make Standard LSTM MLE outputsmore informative and less bland, and thus make theuse of MMI less critical.For the TV Series dataset, perplexity and BLEUscores are respectively reported in Table 5 and Ta-ble 6.
As can be seen, the Speaker and Speaker-Addressee models respectively achieve perplexityvalues of 25.4 and 25.0 on the TV-series dataset,999Model Standard LSTM Speaker Model Speaker-Addressee ModelPerplexity 27.3 25.4 (?7.0%) 25.0 (?8.4%)Table 5: Perplexity for standard SEQ2SEQ and persona models on the TV series dataset.Model Standard LSTM Speaker Model Speaker-Addressee ModelMLE 1.60% 1.82% (+13.7%) 1.83% (+14.3%)MMI 1.70% 1.90% (+10.6%) 1.88% (+10.9%)Table 6: BLEU on the TV series dataset (1 reference), for the standard SEQ2SEQ and persona models.7.0% and 8.4% percent lower than the correspon-dent standard SEQ2SEQ models.
In terms of BLEUscore, we observe a similar performance boostas on the Twitter dataset, in which the Speakermodel and the Speaker-Addressee model outper-form the standard SEQ2SEQ model by 13.7% and10.6%.
By comparing the Speaker-Addresseemodel against the Speaker model on the TV Se-ries dataset, we do not observe a significant dif-ference.
We suspect that this is primarily due tothe relatively small size of the dataset where theinteractive patterns might not be fully captured.Smaller values of perplexity are observed for theTelevision Series dataset than the Twitter dataset,the perplexity of which is over 40, presumably dueto the noisier nature of Twitter dialogues.6.4 Qualitative AnalysisDiverse Responses by Different Speakers Ta-ble 7 represents responses generated by personamodels in response to three different input ques-tions.
We randomly selected 10 speakers (withoutcherry-picking) from the original Twitter dataset.We collected their user level representations froma speaker look-up table and integrated them intothe decoding models.
The model tends to generatespecific responses for different people in responseto the factual questions.6Table 8 shows responses generated from theSpeaker-Addressee Model using the TV-seriesdataset.
Interestingly, we regularly observe thatthis model is sensitive to the identity of the ad-dressee, generating words specifically targeted atthat addressee (e.g., her name).
For example, themodel produces Of course, I love you, Emily inresponse to an input from Emily.
Also, the modelgenerates Of course I love you.
( kisses him), wherethe pronoun ?him?
accurately identifies the genderof the addressee.6There appears to be a population bias in the training setthat favors British users.message Where is your hometown?baseline I was born in Canada.user1 I?m from England.user2 I?m from Manchester.user3 I?m from Liverpool.user4 England.
You?user5 My hometown.user6 I?m from Texas.user7 I?m from LA.user8 England.user9 I was born here.user10 I was born in the us.message What company do you work for?baseline I work for a company.user1 I don?t have a job.user2 I?m a manager.user3 I?m working.
#user4 I work for a company.user5 I?m working.
#user6 Customer service.user7 I work in retail.user8 I work in a cafe.user9 I work at a gas station.user10 I don?t know #message What did you have for dinner?baseline I had fish and chips.user1 I had spag bol.user2 Chicken and chips.user3 Chicken and rice.user4 Fish and chips.user5 I had spag bol.user6 I had Mexican food.user7 Salad...user8 I had chicken and chips.user9 I had spag bol.user10 Pizza.Table 7: Responses generated by the baseline (LSTM-MMI)and the Speaker Model for ten randomly selected users, with-out cherry picking.
# indicates poor-quality responses pro-duced by the system.Human Evaluation We conducted a human eval-uation of outputs from the Speaker Model, usinga crowdsourcing service.
Since we cannot expectcrowdsourced human judges to know or attempt tolearn the ground truth of Twitter users who are notwell-known public figures, we designed our experi-ment to evaluate the consistency of outputs associ-ated with the speaker IDs.
To this end, we collected24 pairs of questions for which we would expect1000message Do you love me?baseline Of course, I love you.addressee: Emily, speaker: Sheldonresponse Of course, I love you, Emily.addressee: Emily, speaker: Pennyresponse Of course, I love you, Emily.addressee: Leonard, speaker: Pennyresponse Of course, I love you, Leonard.addressee: Monica, speaker: Chandlerresponse Of course I love you.
I want to marry you.addressee: Rachel, speaker: Chandlerresponse Of course I love you.addressee: Ross, speaker: Chandlerresponse Of course I love you.addressee: Ross, speaker: Rachelresponse Of course I love you.
(kisses him)addressee: Emily, speaker: Rachelresponse Of course I love you.Table 8: Responses to Do you love me?
from the Speaker-Addressee model on the TV-series dataset using different ad-dressees and speakers.responses to be consistent if the persona model iscoherent.
For example, responses to the questionsWhat country do you live in?
and What city do youlive in?
would be considered consistent if the an-swers were England and London respectively, butnot if they were UK and Chicago.
Similarly, theresponses to Are you vegan or vegetarian?
and Doyou eat beef?
are consistent if the answers gener-ated are vegan and absolutely not, but not if theyare vegan and I love beef.
We collected 20 pairs ofoutputs for randomly-selected personas providedby the Speaker Model for each question pair (480response pairs total).
We also obtained the corre-sponding outputs from the baseline MMI-enhancedSEQ2SEQ system.Since our purpose is to measure the gain in con-sistency over the baseline system, we presented thepairs of answers system-pairwise, i.e., 4 responses,2 from each system, displayed on the screen, andasked judges to decide which of the two systemswas more consistent.
The position in which thesystem pairs were presented on the screen was ran-domized.
The two systems were judged on 5-pointzero-sum scale, assigning a score of 2 (-2) if onesystem was judged more (less) consistent than theother, and 1 (-1) if one was rated ?somewhat?
more(less) consistent.
Ties were assigned a score of zero.Five judges rated each pair and their scores wereaveraged and remapped into 5 equal-width bins.After discarding ties, we found the persona modelwas judged either ?more consistent?
or ?somewhatmore consistent?
in 56.7% of cases.
If we ignorethe ?somewhat more consistent?
judgments, thepersona model wins in 6.1% of cases, comparedUser1message Where is your hometown?response I?m from England.message Where are you from?response I?m from England.message In which city do you live now?response I live in London.message In which country do you live now?response I live in England.message What is your major?response Business.
You?message What did you study in college?response I did business studies.message How old are you?response I?m 18.message What is your age?response I?m 18.User2message Where is your hometown?response I live in Indonesia.message Where are you from?response England, you?message In which city do you live now?response I live in Jakarta.message In which country do you live now?response I live in Indonesia.message What is your major?response Business, you?message What did you study in college?response Psychology, you?message How old are you?response I?m 18.message What is your age?response I?m 16.Table 9: Examples of speaker consistency and inconsistencygenerated by the Speaker Modelwith only 1.6% for the baseline model.
It shouldbe emphasized that the baseline model is a strongbaseline, since it represents the consensus of all70K Twitter users in the dataset7.Table 9 illustrates how consistency is an emer-gent property of two arbitrarily selected users.
Themodel is capable of discovering the relations be-tween different categories of location such as Lon-don and the UK, Jakarta and Indonesia.
However,the model also makes inconsistent response de-cisions, generating different answers in the sec-ond example in response to questions asking aboutage or major.
Our proposed persona models inte-grate user embeddings into the LSTM, and thuscan be viewed as encapsulating a trade-off betweena persona-specific generation model and a generalconversational model.7I?m not pregnant is an excellent consensus answer to thequestion Are you pregnant?, while I?m pregnant is consistentas a response only in the case of someone who also answersthe question Are you a guy or a girl?
with something in thevein of I?m a girl.10017 ConclusionsWe have presented two persona-based responsegeneration models for open-domain conversationgeneration.
There are many other dimensions ofspeaker behavior, such as mood and emotion, thatare beyond the scope of the current paper and mustbe left to future work.Although the gains presented by our new mod-els are not spectacular, the systems outperform ourbaseline SEQ2SEQ systems in terms of BLEU, per-plexity, and human judgments of speaker consis-tency.
We have demonstrated that by encodingpersonas in distributed representations, we are ableto capture personal characteristics such as speakingstyle and background information.
In the Speaker-Addressee model, moreover, the evidence suggeststhat there is benefit in capturing dyadic interactions.Our ultimate goal is to be able to take the pro-file of an arbitrary individual whose identity isnot known in advance, and generate conversationsthat accurately emulate that individual?s personain terms of linguistic response behavior and othersalient characteristics.
Such a capability will dra-matically change the ways in which we interactwith dialog agents of all kinds, opening up richnew possibilities for user interfaces.
Given a suffi-ciently large training corpus in which a sufficientlyrich variety of speakers is represented, this objec-tive does not seem too far-fetched.AcknowledgmentsWe with to thank Stephanie Lukin, Pushmeet Kohli,Chris Quirk, Alan Ritter, and Dan Jurafsky forhelpful discussions.ReferencesDavid Ameixa, Luisa Coheur, Pedro Fialho, and PauloQuaresma.
2014.
Luke, I am your father: dealingwith out-of-domain requests by using movies sub-titles.
In Intelligent Virtual Agents, pages 13?21.Springer.Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben-gio.
2015.
Neural machine translation by jointlylearning to align and translate.
In Proc.
of the Inter-national Conference on Learning Representations(ICLR).Rafael E Banchs and Haizhou Li.
2012.
IRIS: a chat-oriented dialogue system based on the vector spacemodel.
In Proc.
of the ACL 2012 System Demonstra-tions, pages 37?42.Yun-Nung Chen, Wei Yu Wang, and Alexander Rud-nicky.
2013.
An empirical investigation of sparselog-linear models for improved dialogue act classifi-cation.
In Acoustics, Speech and Signal Processing(ICASSP), 2013 IEEE International Conference on,pages 8317?8321.
IEEE.Werner Deutsch and Thomas Pechmann.
1982.
Socialinteraction and the development of definite descrip-tions.
Cognition, 11:159?184.Michel Galley, Chris Brockett, Alessandro Sordoni,Yangfeng Ji, Michael Auli, Chris Quirk, MargaretMitchell, Jianfeng Gao, and Bill Dolan.
2015.?BLEU: A discriminative metric for generationtasks with intrinsically diverse targets.
In Proc.
ofACL-IJCNLP, pages 445?450, Beijing, China, July.Jianfeng Gao, Xiaodong He, Wen-tau Yih, and Li Deng.2014.
Learning continuous phrase representationsfor translation modeling.
In Proc.
of ACL, pages699?709, Baltimore, Maryland.Sepp Hochreiter and J?urgen Schmidhuber.
1997.Long short-term memory.
Neural computation,9(8):1735?1780.Alfred Kobsa.
1990.
User modeling in dialog systems:Potentials and hazards.
AI & society, 4(3):214?231.Esther Levin, Roberto Pieraccini, and Wieland Eckert.2000.
A stochastic model of human-machine inter-action for learning dialog strategies.
IEEE Transac-tions on Speech and Audio Processing, 8(1):11?23.Jiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao,and Bill Dolan.
2016.
A diversity-promoting ob-jective function for neural conversation models.
InProc.
of NAACL-HLT.Grace I Lin and Marilyn A Walker.
2011.
All theworld?s a stage: Learning character models fromfilm.
In Proceedings of the Seventh AAAI Confer-ence on Artificial Intelligence and Interactive Digi-tal Entertainment (AIIDE).Thang Luong, Ilya Sutskever, Quoc Le, Oriol Vinyals,and Wojciech Zaremba.
2015.
Addressing the rareword problem in neural machine translation.
In Proc.of ACL, pages 11?19, Beijing, China, July.Lasguido Nio, Sakriani Sakti, Graham Neubig, TomokiToda, Mirna Adriani, and Satoshi Nakamura.
2014.Developing non-goal dialog system based on exam-ples of drama television.
In Natural Interaction withRobots, Knowbots and Smartphones, pages 355?361.Springer.Franz Josef Och.
2003.
Minimum error rate training instatistical machine translation.
In Proceedings of the41st Annual Meeting of the Association for Compu-tational Linguistics, pages 160?167, Sapporo, Japan,July.
Association for Computational Linguistics.1002Alice H Oh and Alexander I Rudnicky.
2000.
Stochas-tic language generation for spoken dialogue systems.In Proceedings of the 2000 ANLP/NAACL Workshopon Conversational systems-Volume 3, pages 27?32.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
BLEU: a method for automaticevaluation of machine translation.
In Proc.
of ACL,pages 311?318.Roberto Pieraccini, David Suendermann, KrishnaDayanidhi, and Jackson Liscombe.
2009.
Are wethere yet?
research in commercial spoken dialogsystems.
In Text, Speech and Dialogue, pages 3?13.Springer.Adwait Ratnaparkhi.
2002.
Trainable approaches tosurface natural language generation and their appli-cation to conversational dialog systems.
ComputerSpeech & Language, 16(3):435?455.Alan Ritter, Colin Cherry, and William B Dolan.
2011.Data-driven response generation in social media.
InProceedings of the Conference on Empirical Meth-ods in Natural Language Processing, pages 583?593.Jost Schatztnann, Matthew N Stuttle, Karl Weilham-mer, and Steve Young.
2005.
Effects of theuser model on simulation-based learning of dialoguestrategies.
In Automatic Speech Recognition and Un-derstanding, 2005 IEEE Workshop on, pages 220?225.Iulian V Serban, Alessandro Sordoni, Yoshua Bengio,Aaron Courville, and Joelle Pineau.
2015.
Buildingend-to-end dialogue systems using generative hierar-chical neural network models.
In Proc.
of AAAI.Lifeng Shang, Zhengdong Lu, and Hang Li.
2015.Neural responding machine for short-text conversa-tion.
In ACL-IJCNLP, pages 1577?1586.Alessandro Sordoni, Michel Galley, Michael Auli,Chris Brockett, Yangfeng Ji, Meg Mitchell, Jian-YunNie, Jianfeng Gao, and Bill Dolan.
2015.
A neuralnetwork approach to context-sensitive generation ofconversational responses.
In Proc.
of NAACL-HLT.Ilya Sutskever, Oriol Vinyals, and Quoc V Le.
2014.Sequence to sequence learning with neural networks.In Advances in neural information processing sys-tems (NIPS), pages 3104?3112.J?org Tiedemann.
2009.
News from OPUS ?
a collec-tion of multilingual parallel corpora with tools andinterfaces.
In Recent advances in natural languageprocessing, volume 5, pages 237?248.Oriol Vinyals and Quoc Le.
2015.
A neural conver-sational model.
In Proc.
of ICML Deep LearningWorkshop.Wolfgang Wahlster and Alfred Kobsa.
1989.
Usermodels in dialog systems.
Springer.Marilyn A Walker, Rashmi Prasad, and Amanda Stent.2003.
A trainable generator for recommendations inmultimodal dialog.
In INTERSPEECH.Marilyn A Walker, Ricky Grant, Jennifer Sawyer,Grace I Lin, Noah Wardrip-Fruin, and MichaelBuell.
2011.
Perceived or not perceived: Film char-acter models for expressive nlg.
In Interactive Story-telling, pages 109?121.
Springer.Marilyn A Walker, Grace I Lin, and Jennifer Sawyer.2012.
An annotated corpus of film dialogue forlearning and characterizing character style.
InLREC, pages 1373?1378.William Yang Wang, Ron Artstein, Anton Leuski, andDavid Traum.
2011.
Improving spoken dialogueunderstanding using phonetic mixture models.
InFLAIRS Conference.Tsung-Hsien Wen, Milica Gasic, Nikola Mrk?si?c, Pei-Hao Su, David Vandyke, and Steve Young.
2015.Semantically conditioned LSTM-based natural lan-guage generation for spoken dialogue systems.
InProc.
of EMNLP, pages 1711?1721, Lisbon, Portu-gal, September.
Association for Computational Lin-guistics.Kaisheng Yao, Geoffrey Zweig, and Baolin Peng.2015.
Attention with intention for a neural networkconversation model.
CoRR, abs/1510.08565.Steve Young, Milica Ga?si?c, Simon Keizer, Franc?oisMairesse, Jost Schatzmann, Blaise Thomson, andKai Yu.
2010.
The hidden information state model:A practical framework for pomdp-based spoken dia-logue management.
Computer Speech & Language,24(2):150?174.1003
