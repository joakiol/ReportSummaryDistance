Constraint-based RMRS Construction from Shallow GrammarsAnette FrankLanguage Technology LabGerman Research Center for Artificial Intelligence, DFKI GmbHStuhlsatzenhausweg 3, 66123 Saarbru?cken, GermanyAnette.Frank@dfki.deAbstractWe present a constraint-based syntax-semanticsinterface for the construction of RMRS (RobustMinimal Recursion Semantics) representationsfrom shallow grammars.
The architecture is de-signed to allow modular interfaces to existingshallow grammars of various depth ?
rangingfrom chunk grammars to context-free stochasticgrammars.
We define modular semantics con-struction principles in a typed feature structureformalism that allow flexible adaptation to al-ternative grammars and different languages.11 IntroductionSemantic formalisms such as MRS (Copestake etal., 2003) provide elegant solutions for the treatmentof semantic ambiguities in terms of underspecifi-cation ?
most prominently scope.
In recent workCopestake (2003) has investigated a novel aspectof underspecification in the design of semantic for-malisms, which is concerned with the representationof partial semantic information, as it might be ob-tained from shallow, i.e.
incomplete syntactic anal-ysis.
The main rationale for this type of underspeci-fication is to ensure monotonicity, and thus upwardscompatibility of the output of shallow parsing withsemantic representations obtained from full syntac-tic parsing.
Thus, Copestake?s design of RMRS ?Robust Minimal Recursion Semantics ?
provides animportant contribution to a novel line of research to-wards integration of shallow and deep NLP.
Whileprevious accounts (Daum et al, 2003; Frank et al,2003) focus on shallow-deep integration at the syn-tactic level, Copestake aims at integration of shal-low and deep NLP at the level of semantics.In this paper we review the RMRS formalism de-signed by Copestake (2003) and present an archi-tecture for a principle-based syntax-semantics in-terface for RMRS construction from shallow gram-mars.
We argue for a unification-based approach,1The research reported here was conducted in the projectQUETAL, funded by the German Ministry for Education andResearch, BMBF, under grant no.
01 IW C02.to account for (underspecified) argument bindingin languages with case-marking as opposed tostructural argument identification.
The architec-ture we propose is especially designed to supportflexible adaptation to different types of shallowto intermediate-level syntactic grammars that mayserve as a basis for RMRS construction.
A chal-lenge for principle-based semantics constructionfrom shallow grammars is the flat and sometimesnon-compositional nature of the structures they typ-ically produce.
We present RMRS semantics con-struction principles that can be applied to flat syn-tactic structures with various degrees of partiality.2 RMRS ?
For Partial SemanticRepresentationCopestake (2003) presents a formalism for partialsemantic representation that is derived from MRSsemantics (Copestake et al, 2003).
Robust Min-imal Recursion Semantics is designed to supportnovel forms of integrated shallow and deep NLP,by accommodating semantic representations pro-duced by NLP components of various degrees ofpartiality and depth of analysis ?
ranging fromPoS taggers and NE recognisers over chunk and(non-)lexicalised context-free grammars to deepgrammars like HPSG with MRS output structures.The potential of a variable-depth semantic anal-ysis is most evident for applications with conflict-ing requirements of robustness and accuracy.
Givena range of NLP components of different depths ofanalysis that deliver compatible semantic represen-tations, we can apply flexible integration methods:apply voting techniques, or combine partial resultsfrom shallow and deep systems (Copestake, 2003).To allow intersection and monotonic enrichmentof the output representations from shallow systemson one extreme of the scale with complete repre-sentations of deep analysis on the other, the missingspecifications of the weakest system must be fac-tored out from the most comprehensive deep repre-sentations.
In the RMRS formalism, this concernsthe following main aspects of semantic information:Argument encoding.
A ?Parsons style?
notationaccommodates for partiality of shallow systemswrt.
argument identification.
Instead of predicateswith fixed arity, e.g.
l4:on(e?
,e,y), predicates and ar-guments are represented as independent elementarypredications: on(l4,e?
), ARG1(l4,e), ARG2(l4,y).This accounts for uncertainty of argument identi-fication in shallow grammars.
Underspecificationwrt.
the type of argument is modeled in terms of ahierarchy over disjunctive argument types: ARG1 <ARG12, ARG2 < ARG12, ARG12 < .
.
.
< ARGn.Variable naming and equalities.
Constraints forequality of variables in elementary predications areto be added incrementally, to accommodate forknowledge-poor systems like PoS taggers, wherethe identity of referential variables of, e.g., adjec-tives and nouns in potential NPs cannot be estab-lished, or else chunkers, where the binding of argu-ments to predicates is only partially established.An example of corresponding MRS (1.a) andRMRS (1.b) representations illustrate these differ-ences, cf.
Copestake (2003).
(1) Every fat cat sat on a mata.
l0:every(x,h1,h2), l1:fat(x), l2:cat1(x),l3:CONJ, l4:sit1(espast ,x), l14:on2(e?
,e,y),l9:CONJ, l5:some(y,h6,h7), l6:table1(y),qeq(h1,l3), qeq(h6,l6), in-g(l3,l1), in-g(l3,l2),in-g(l9,l4), in-g(l9,l14)b. l0:every(x0), RSTR(l0,h1), BODY(l0,h2),l1:fat(x1), l2:cat1(x2), l3:CONJ,l4:sit1(e3spast), ARG1(l4,x2), l14:on2(e4),ARG1(l14,e3), ARG2(l14,x5), l9:CONJ,l5:some(x5), RSTR(l5,h6), BODY(l5,h7),l6:table1(x6), qeq(h1,l1), qeq(h6,l6), in-g(l3,l1), in-g(l3,l2), in-g(l9,l4), in-g(l9,l14),x0 = x1, x1 = x2, x5 = x63 RMRS from Shallow GrammarsWe aim at a modular interface for RMRS construc-tion that can be adapted to a wide range of exist-ing shallow grammars such as off-the-shelf chunkparsers or probabilistic (non-)lexicalised PCFGs.Moreover, we aim at the construction of under-specified, but maximally constrained (i.e., resolved)RMRS representations from shallow grammars.A unification-based account.
Chunk-parsers andPCFG parsers for sentential structure do in generalnot provide functional information that can be usedfor argument identification.
While in languageslike English argument identification is to a large ex-tent structurally determined, in other languages ar-guments are (partially) identified by case marking.In case-marking languages, morphological agree-ment constraints can yield a high degree of com-pletely disambiguated constituents.
Morphologicaldisambiguation can thus achieve maximally con-strained argument identification for shallow analy-ses.
We therefore propose a unification-based ap-proach for RMRS construction, where agreementconstraints can perform morphological disambigua-tion for partial (i.e.
underspecified) argument identi-fication.
Moreover, by interfacing shallow analysiswith morphological processing we can infer impor-tant semantic features for referential and event vari-ables, such as PNG and TENSE information.
Thus,morphological processing is also beneficial for lan-guages with structural argument identification.A reparsing architecture.
In order to realise amodular interface to existing parsing systems, wefollow a reparsing approach: RMRS constructiontakes as input the output structure of a shallowparser.
We index the nodes of the parse tree andextract a set of rules and lexicon entries with cor-responding node indices.
Reparsing of the originalinput string according to this set of rules determin-istically replays the original parse.
In the reparsingprocess we apply RMRS construction principles.Constraint-based RMRS construction.
We defineconstraint-based principles for RMRS constructionin a typed feature structure formalism.
These con-straints are applied to the input syntactic structures.In the reparsing step the constraints are resolved, toyield maximally specified RMRS representations.The RMRS construction principles are definedand processed in the SProUT processing platform(Drozdzynski et al, 2004).
The SProUT systemcombines finite-state technology with unification-based processing.
It allows the definition of finitestate transduction rules that apply to (sequences of)typed feature structures (TFS), as opposed to atomicsymbols.
The left-hand side of a transduction rulespecifies a regular expression over TFS as a recog-nition pattern; the right-hand side specifies the out-put in terms of a typed feature structure.
The sys-tem has been extended to cascaded processing, suchthat the output of a set of rule applications can pro-vide the input for another set of rewrite rules.
Thesystem allows several distinct rules to apply to thesame input substring, as long as the same (maxi-mal) sequence of structures is matched by these dif-ferent rules.
The output structures defined by theseindividual rules can be unified, by way of flexibleinterpreter settings.
These advanced configurationsallows us to state RMRS construction principles ina modular way.S1NP11 VVFIN12 PP13ART111 ADJA112 NN113 sa?
APPR131 ART132 NN141ein dicker Kater auf der MatteFigure 1: Input syntactic tree: Ein dicker Kater sa?auf der Matte ?
A fat cat sat on the matphrase & [ID ?11?, CAT ?NP?, M-ID ?1?, M-CAT ?S?
]lex & [ID ?12?, CAT ?VVFIN?, M-ID ?1?, M-CAT ?S?
]phrase & [ID ?13?, CAT ?PP?, M-ID ?1?, M-CAT ?S?
]lex & [ID ?111?, CAT ?ART?, M-ID ?11?, M-CAT ?NP?
]lex & [ID ?112?, CAT ?ADJA?, M-ID ?11?, M-CAT ?NP?
]lex & [ID ?113?, CAT ?NN?, M-ID ?11?, M-CAT ?NP?
]lex & [ID ?131?, CAT ?APPR?, M-ID ?13?, M-CAT ?PP?
]lex & [ID ?132?, CAT ?ART?, M-ID ?13?, M-CAT ?PP?
]lex & [ID ?133?, CAT ?NN?, M-ID ?13?, M-CAT ?PP?
]Figure 2: TFS representations for lexical andphrasal nodes (here for tree of Figure 1)phrase :> synsem & [M-ID #1, M-CAT #mcat]+?> phrase & [ID #1, CAT #mcat].Figure 3: Reparsing ruleCascaded Reparsing.
We extract informationabout phrase composition from the indexed inputparse trees.
For each local subtree, we extractthe sequence of daughter nodes as TFS, recordingfor each node its node identifier (ID) together withthe identifier (M-ID) and category (M-CAT) of itsmother node (cf.
Figure 2).
This implicitly en-codes instructions for phrase composition that areemployed in the cascaded system to guide phrasecomposition and concurrent semantics construction.A general reparsing rule (cf.
Figure 3) is appliedto an input sequence of TFS for lexical or phrasalnodes and produces as output a TFS for the implic-itly defined mother node.
The rule specifies thatfor all nodes in the matched input sequence, theirmother node identifier and category features (M-ID,M-CAT) must be identical, and defines the output(mother) node?s local identifier and category feature(ID, CAT) by use of variable co-references (#var).Since the system obeys a longest-match strategy,the regular expression is constrained to apply to thesame constituents as in the original parse tree.Cascaded reparsing first applies to the sequenceof leaf nodes.
The output node sequence is enrichedwith the phrase-building information from the origi-nal parse tree, and is again input to the phrase build-ing and semantics construction rules.
Thus, we de-fine a cyclic cascade, where the output of a cascadeis fed in as input to the same rules.
The cycle termi-nates when no phrase building rule could be appliedto the input, i.e.
the root category has been derived.agr :> lex & [M-ID #1]*( lex & [M-ID #1, CAT ?NN?, MSYN [AGR #agr]]+| lex & [M-ID #1, CAT ?ADJA?, MSYN [AGR #agr]]+| lex & [M-ID #1, CAT ?ART?, MSYN [AGR #agr]]+ )lex & [M-ID #1]*?> phrase & [ID #1, MSYN [AGR #agr]].Figure 4: Modular agreement projection rulesMorpho-syntactic disambiguation.
Before ruleapplication, the SProUT system performs morpho-logical lookup on the input words (Krieger and Xu,2003).
Morphological information is modeled in aTFS hierarchy with disjunctive types to underspec-ify ambiguities of inflectional features, e.g.
case.We define very general principles for morpho-syntactic agreement, defining agreement betweendaughter and mother constituents individually forcategories like determiner, adjective or noun (Figure4).
Since in our reparsing approach the constituentsare pre-defined, the agreement projection principlescan be stated independently for possible mother-daughter relations, instead of specifying complexprecedence patterns for NPs.
Defining morphologi-cal agreement independently for possibly occurringdaughter constituents yields few and very general(disjunctive) projection principles that can apply to?unseen?
constituent sequences.The rule in Figure 4 again exploits the longest-match strategy to constrain application to the pre-defined constituents, by specifying coreferent M-IDfeatures for all nodes in the rule?s input sequence.In reparsing, the (possibly disjunctive) morpho-logical types in the output structure of the individ-ual rule applications are unified, yielding partiallyresolved inflectional features for the mother node.For NP11, e.g., we obtain CASE nom by unifica-tion of nom (from ART and ADJA) and nom-acc-dat (from NN).
The resolved case value of the NPcan be used for (underspecified) argument bindingin RMRS construction.4 Semantics Projection Principles forShallow GrammarsLexical RMRS conditions.
Lexical entries forRMRS construction are constrained by types forPoS classes, with class-specific elementary predi-cations (EP) in RMRS.RELS, cf.
Figure 5.
RELSand CONS are defined as set-valued features insteadof lists.
This allows for modular content projec-tion principles (see below).
We distinguish differ-ent types of EPs: ep-rel, defining relation and la-bel, ep-rstr and ep-body for quantifiers, with LB andRSTR/BODY features.
Arguments are encoded as atype ep-arg, which expands to disjunctive subtypesep-arg-1, ep-arg-12, ep-arg-23, .
.
.
, ep-arg-n.rmrs-nn & [CAT ?NN?, MSYN [AGR #agr],STEM <#stem>,RMRS [KEY #1, BIND-ARG [AGR #agr ],RELS {ep-rel &[LB #lb, REL #stem] ,ep-arg0 & #1 & [LB #lb, ARG0 var]},CONS { }]].Figure 5: Lexical types with RMRS EPscont proj :> [M-ID #1]*[M-ID #1, RMRS [RELS #rels, CONS #cons]][M-ID #1]*?> [ID #1, RMRS [RELS #rels, CONS #cons]].Figure 6: Content projectionContent projection.
The content projection rule(Figure 6) assembles the RMRS conditions in RELSand CONS features of the daughter constituents.
InSProUT, the unification of output structures withset-valued features is defined as set union.
Whilethe classical list representation would require multi-ple content rules for different numbers of daughters,the set representation allows us to state a single con-tent principle: it applies to each individual daughter,and yields the union of the projected set elements asthe semantic value for the mother constituent.Argument and variable binding.
Managementfeatures (KEY, BIND-ARG) propagate values of labelsand variables for argument binding.
The maximallyspecific type ep-arg-x of the arguments to be boundis determined by special bind-arg principles that de-fine morpho-syntactic constraints (case, passive).For languages with structural argument identifica-tion we can employ precedence constraints in theregular expression part of argument binding rules.Content projection from flat structures.
A chal-lenge for principle-based RMRS construction fromshallow grammars are their flat syntactic struc-tures.
They do not, in general, employ strictly bi-nary structures as assumed in HPSG (Flickinger etal., 2003).
Constituents may also contain multipleheads (cf.
the PP in Fig.
1).
Finally, chunk parsersdo not resolve phrasal attachment, thus providingdiscontinuous constituents to be accounted for.With flat, non-binary structures, we need to as-semble EP (ep-arg-x) conditions for argument bind-ing for each potential argument constituent of aphrase.
In the SRroUT system, this can again bedone without explicit list operations, by applicationof individual argument binding rules that projectbinding EP conditions for each potential argumentto the RELS feature of the mother.
Thus, simi-lar to Figure 6, we can state general and modularmother-daughter principles for argument binding.For multiple-headed constituents, such as flat PPs,we use secondary KEY and BIND-ARG features.
Forargument binding with chunk parsers, where PP at-tachment is not resolved, we will generate in-groupconditions that account for possible attachments.5 Comparison to Related WorkCompared to the RMRS construction methodCopestake (2003) applies to the English PCFGparser of Carroll and Briscoe (2002), the mainfeatures of our account are argument identifica-tion via morphological disambiguation and defini-tion of modular semantics construction principlesin a typed unification formalism.
The architecturewe propose can be applied to sentence- or chunk-parsing.
The rule-based SProUT system allows thedefinition of modular projection rules that can betailored to specific properties of an underlying shal-low grammar (e.g.
identification of active/passivevoice, of syntactic NP/PP heads).
In future work wewill compare our semantics construction principlesto the general model of Copestake et al (2001).Acknowledgements I am greatly indebted to mycolleagues at DFKI, especially the SProUT teammembers Witold Droz?dz?yn?ski, Hans-Ulrich Krieger,Jakub Piskorski and Ulrich Scha?fer, for their techni-cal support and advice.
Special thanks go to KathrinSpreyer for support in grammar development.ReferencesA.
Copestake, A. Lascarides, and D. Flickinger.
2001.An Algebra for Semantic Construction in Constraint-based Grammars.
In Proceedings of the ACL 2001,Toulouse, France.A.
Copestake, D. Flickinger, I.
Sag, and C. Pollard.2003.
Minimal Recursion Semantics.
Ms.A.
Copestake.
2003.
Report on the Design of RMRS.Technical Report D1.1a, University of Cambridge,University of Cambridge, UK., October.
23 pages.M.
Daum, K.A.
Foth, and W. Menzel.
2003.
Constraint-based Integration of Deep and Shallow Parsing Tech-niques.
In Proceedings of EACL 2003, Budapest,Hungary.W.
Drozdzynski, H.-U.
Krieger, J. Piskorski, U. Scha?fer,and F. Xu.
2004.
Shallow processing with unificationand typed feature structures ?
foundations and appli-cations.
Ku?nstliche Intelligenz, 1:17?23.D.
Flickinger, E. M. Bender, and S. Oepen.
2003.
MRSin the LinGO Grammar Matrix: A Practical User?sGuide.
Technical report, Deep Thought Project De-liverable 3.5.A.
Frank, M. Becker, B. Crysmann, B. Kiefer, andU.
Scha?fer.
2003.
Integrated Shallow and Deep Pars-ing: ToPP meets HPSG.
In Proceedings of the ACL2003, pages 104?111, Sapporo, Japan.H.-U.
Krieger and F. Xu.
2003.
A type-driven methodfor compacting mmorph resources.
In Proceedings ofRANLP 2003, pages 220?224.
