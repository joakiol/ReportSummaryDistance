Word Complet ion :  A First  S tep  TowardTarget -Text  Med ia ted  IMTGeorge Foster, Pierre Isabelle, and Pierre PlamondonCentre for hfformation Technology Innovation (CITI)1575 Chomedey Blvd.Laval, Quebec, Canada, H7V 2X2{foster, isabelle, plamondon}@citi, doc .
caAbstractWe argue that the conventional pproachto Interactive Machine ~Ih-anslation is notthe best way to provide assistance toskilled translators, and propose an alter-native whose central feature is the useof the target text as a medium of inter-action.
We describe an automatic word-completion system intended to serve as avehicle for exploring the feasibility of thisnew approach, and give results in termsof keystrokes aved in a test corpus.1 IntroductionMachine translation is usually significantly infe-rior to human translation, and for most appli-cations where high-quality results are needed itmust be used in conjunction with a human trans-lator.
There are essentially three ways of organiz-ing the process by which a person and a machinecooperate to produce a translation: prccdition, inwhich the person's contribution takes the form ofa source-text analysis and occurs before the MTsystem is brought to bear; postedition, in whichthe translator simply edits the system's output;and interactive MT (IMT), which involves a di-alog between person and machine.
Of the three,IMT is the most ambitious and theoretically themost powerflfl.
It has a potential advantage overpostedition in that information imparted to thesystem may help it to avoid cascading errors thatwould later require much greater effort to correct;and it has a potential advantage over preeditionin that knowledge of the machine's current statemay be useful in reducing the number of analysesthe human is required to provide.Existing approaches to IMT (Blanchon, 1994;Boitet, 1990; Brown and Nirenburg, 1990; Kay,1973; Maruyama nd Watanabe, 1990; Whitelocket al, 1986; Zajac, 1988) place the MT systemin control of the translation process and for themost part limit the human's role to performingvarious source language disambiguations on de-man& Although this arrangement is appropriatefor some applications, notably those in which theuser's knowledge of tile target language may belimited, or where there are multiple target, lan-guages, it is not well suited to tile needs of pro-fessional oi' other highly skilled translators.
Thelack of direct human control over the tinal targettext (modulo postedition) is a serious drawbackin this case, and it is not clear that, for a com-petent translator, disambiguat, ing a source text, ismuch easier than translating it.
This conclusionis supported by the fact that true IMT is not,to our knowledge, used in most modern transla-tor's support environments, eg (Eurolang, 1995;I,'rederking et al, 1993; IBM, 1995; Kugler et al,1991; Nirenburg, 1992; ~li'ados, 1995).
Such envi-ronments, when they incorporate MT at all, tendto do so wholesale, giving the user control overwhether and when an MT component is invoked,as well as extensive postediting facilities for mod-ifying its outtmt, but not the ability to intervenewhile it is operating.In our view, this state of affairs should not betaken as evidence that IMT for skilled translatorsis an inherently bad idea.
We feel that there isan alternate approach which has the potential toavoid most of the problems with conventional IMTin this context,: use the target ext as a medium ofcommunication, and have the translator and MTsystem interact by making changes and extensionsto it, with the translator's contributions serving asprogressively informative constraints for the sys-te,n.
This arrangement has the advantage of leav-ing the translator in full control of the translationprocess, of diverting his or her attention very lit-tle from the object of its natural focus, and of ne-cessitating a minimum of interface paraphernaliabeyond those of a word processor.
It can in prin-ciple accomodate a wide range of MT proficien-394cies, frolil very high, in which the system inightbe called ut)on to propose entire translations andInoditly them in response to changes Inade by thetranslator; to very low, in which its chief contri-l)ution will be the reduction of typing labour.The aim of this paper ix to explore the feasi-bility of this target-tezt mediated style of IMT inone parti(:ularly simph; form: a word-(:onq)h',tionsystem which ai;temltts to fill in the sutlixes oftarget-text words from manually typed prefixes.tWe describe a prototype completion system forEnglish to l~?ench translation which is based onsimple statistical MT techniques, att(t give mea-StlFenlents el: its performance ill terms of (;}larac-ters saved in a test cortms.
The system has notyet been integrated with a word processor, st) we(;annot qltantify the anlollnt of a(:tual time and(;fl'ort it woul(t save a translator, t)nt it seems rea-sonable to expect this to lie faMy well correlatedwith total character savings.2 Word Complet ionOur scenm'io for wor(1 completion SUl)t)oses thata translator works on some designated segment ofthe source text (of attproxinmtely sentence size),and elaborates its (;ranslation from left to right.As each target-text character is tylted , a t)rot)osed(:omttletion for tit(; currenl; word is (tisttlayed; ifthis is (',orreet, the translator ntay a(',cept it att(ll)cgin typing the next word.
Although inore elab-orate comi)lel;ion schemes are imaginable, in(:lud-ing ones that involve the use, of alternate hyI)othe-sos or 1)revisions for morl)hologieal repair, we haveot)ted against these for the time t)eing becausethey necessitate st)eeial commands whose benetitin terms of characters saved would t)e diilicult toestimate.The heart of ore" system is a comltletion enginefor English to t~'ench translation which finds thebest completion for a \[,?eneh word prefix given thecurrent English source text segment utnler trans-lation, attd the words which precede the prefixin the corresponding l~?eneh target text segment.It comprises two main components: an cvalua-tot which assigns cores to completion hypotheses,and a generator which produces a list of hyp(tthe-sos that match the current prefix and picks theone with the highest score.1This idea is similm to existing work on tyl)ingae(:elerators for the disabled (Demasco and McCoy,1992), but our methods differ signitieantly in manyaspects, chief among which is the use of bilingualcontext.3 Hypothes is  Eva luat ionEach score produced by the evaluator is an es-tilnate of p(tl{, st, the probability of a target.-language word t given a preceding target text t,anti a source text s. For etticiency, this distribu-tion is modeled as a silnple linear combination ofSOl)re'ate tn'edietions fl'om tit(; target text and thesottree text:p(tlE, s) = Ap(tl{ ) + (1-  A)p(tls ).The vahte of /~ was chosen so as to maximizee, otnpletion lterforInanee over a test text; (see s(!c-tion 5).3.1 Target -Text  Based  Pred ic t ionThe target-text based prediction p(t l t )  comest?om an interpolated trigranl language model forl%:ench, of the type commonly used in speechrecognition (Jelinek, 11!190).
It; was trained on 47Mwords fiom the Canadian Hansard Corpus, with750/o used to make relative-fl'equency I)arameterestintates and 25% used to reestimate interpola-tion coefticients.3.2 Source-Text  Based  Pred ic t ionThe source text prediction p(t\[s) comes fl'om astatistical model of English-to-l,?ench translationwhich is based on the IBM translation models 1and 2 (Brown el; al., 1993).
Model 1 is a Hid.-den Markov Model (HMM) of the target languagewhose states correspond to source text tokens (seefigure l), with the addition of one special nullstate to account for target ext words that have nostrong direct correlation to any word in the sourcetext.
The output distribution of any state tie theset of probabilities with which it generates targetwords) deitends only on the correspondit~g sourcetext word, and all next-state transition distribu-tions are uniform.
Model 2 is similar to model 1except that states are attgmented with a target-token t)osition cotnponent, attd transition proba-bilities depend on both source and target tokenpositions, '2with the topographical constraint thata state's target-token t)ositioll component mustalways match the current actual position.
Be-cause of the restricted form of the state transitionUAlong with source and target text lengths inl/town et als fornmlation, lint these are  constant forarty particular HMM.
The results 1)resented in this pa-lter are optimistic in that the target text lengl;h wasassumed to be known in advance, which of course isunrealistic.
IIowever, (Dagan et al, 1993) have shownthat knowledge of target-text length is not crucial tothe model's i)ertbrmanee.395J' ai d' autres cxcmplcs d' autres pays3 c ~ 1 :4 5 counlrics 8 8Figure 1: A plausible state sequence by which the HMM corresponding to the English sentence I have othercxamples from many other countries might generate the French sentence shown.
The state-transition probabilities(horizontal arrows) are all 1/9 for model 1, and depend on the next state for model 2, eg p((froms, 6} I') = a(516).The output probabilities (vertical arrows) depend on the words involved, eg p(d' I {from~, 6}) = p(d' I from ).matrices for these models, they have the prop-erty that- unlike HMM's in general they gen-erate target-language words independently.
Theprobability of generating hypothesis t at positioni is just:Islp(tls, i ) = EP( t l s i )a ( j  li)j=0where sj is the j th  source text token (so is anull token), p(t ls j)  is a word-for-word transla-tion probability, and a( j l i  ) is a position align-ment probability (equal to 1/( M + 1) for inodel1).We introduced a simple enhancement to theIBM models designed to extend their coverage, andmake them more compact.
It is based on the ob-servation that there are (at least) three classesof English forms which most often translate intoFk'ench either verbatim or via a predictable trans-formation: proper nouns, numbers, and specialatphanuineric codes such as C-~5.
We found thatwe could reliably detect such "invariant" forms inan English source text using a statistical taggerto identify proper nouns, and regular expressionsto match immbers and codes, along with a filterfor frequent names like United States that do nottranslate verbatim into French and Immbers like10 that tend to get translated into a fairly widevariety of forms.When the translation models were trained, in-variant okens in each source text segment were re-placed by special tags specific to each class (differ-ent invariants occuring in the same segment wereassigned serial numbers to distinguish them); anyinstances of these tokens found in the correspond-ing target text segment were also replace(\] by theappropriate tag.
This strategy reduced the nmn-ber of parameters in the inodels by about 15%.When ewfluating hypotheses, a siufilar replace-ment operation is carried out and the transla-tion probabilities of paired invariants are obtainedfrom those of the tags to which they map.Parameters for the translation models werereestimated fl'om the Hansard corpus, automat-ically aligned to the sentence level using themethod described in (Simard et al, 1992), withnon one-to-one aliglmmnts arid sentences longerthan 50 words filtered out; the ret~fine(l materialconsisted of 36M English words and 37M Fren(:hwords.4 Hypothes is  Generat ionThe main challenge in generating hypotheses i 1;obalance the opposing requirements of completionaccuracy and speed the former tends to increase,and tile latter to decrease with tile nmnber of hy-potheses considered.
We took a number of stepsin art effort to achieve a good compromise.4.1 Act ive  and  Pass ive  Vocabu lar iesA well-established corollary to Zipf's law holdsthat a minority of words account for a majorityof tokens in text.
To capitalize on this, our sys-tem's French  vocabulary is divided i n to  two  parts:a small active component whose contents are al-ways used for generation, and a much larger pas-sive part which comes into play only when theactive vocabulary contains no extensions to the(:urrent )refix.Space requirements for the passive vocabularywere minimized by storing it as a special triein which con ln lon  Srl\[~cix patterns are representedonly once, and variable-length coding techniquesare used for structural information.
This allowsus to maintain a large dictionary containing over380,000 forms entirely in memory, using about475k bytes.The active vocabulary is also represented as atrie.
For efficiency, explicit lists of hypotheses at'(;not generated; instead, evaluation is performedduring a reeursive search over the portion of thetrie below the current coinpletion prefix.
Repeatsearches when the prefix is extended by one char-acter are ol)viated in inost situations by memo\]z-ing the results of tile original search with a best-child pointer in each trie node (see figure 2).4.2 Dynamic  Vocabu laryTo set the contents of the active vocabulary, weborrowed the idea of a dynamic vocabulary from(Brousseau et al, 1995).
This involves using396f"F igure  2: Menioized port;ion of t;\]l(; a(:i, ive vocal)u-lary trie for i;he l~i'en(;h preiix parhJv hea,vy liues show1)esl;-child links and sha, ded nodes rcpr(',scnt vidid wordends.
The, currelii: best; (:andidalm is pa'dc'co'~Z; if ana is ap1)cnded l)y i,h(; t:ranslal;or~ |;he new 1)esl; can-didal;(; po, rlc'rait (:~ui 1)e r(',t;ri(;ved froln i, he t)esl;-(;liildl inks wii;houi; having 1;o i'e-evahlai;c all 6 1)ossil)le hy-l)oi;heses.l ; rmislai; ion rood(;1 1 Ix) (;olnl)ul;(; ;~ \]isl, of  t im 'n, nlosl:prob~fl)le I;arg(,t: l;(;xl; words (in('hl(l ing t, rmisla.lJoninvm'ianl;s),  g iven th(; curr(;nl; sour(',(; l;(;xt; s(;gliCieilt.As figur(; 3 illusl;r;.rlx;s, (:ompar('(l to ;l~lt ~c\[l:(;ril~d,(~reel:hod of sl;;tl;i(:;dly ('.hoosing t, he n m()st; frequenl:tornis  in l;he t i ; I Jn ing (:orlms , use of a, ( lyna,mic vo--(',abul~ry (h'amal;i(:a,lly r(;(lu(:(;s l;h(; a v(!rage, a(:l,iv('~vo(',~l)ulm'y size r(',(tuir(;(1 t;o iu',hi(w(!
a, given levc, l ofi;a, rgel: ix~xi: covcra,g(;.
Mol:ivalxxl by t:he Im:i, th;~tr(;(;(!nl; words l;en(l 1;o recur in l:cxt;, wc ~dso a,d(ledall t )reviously (;ncounl;ered l;m'g(;l;-t;(;xl; t,ol(ens 1;oi;ho dynami(' ,  vo(:ttl)ul<%y.4.3 Case  Hand l ingThe l;re.~l;nlcnl: of \](;l;lx;r ca.s(; L'-; ;~ 1Mcky l)r()/)i(!nifor hyi)oi;l/(;sis general; ion mid one tlta.l; cil~llll()l; })(;ig;llor(;(\] \ 11 kill inl;(~ra.
('.l;iv(; al)l)li(:id;ion.
IVlt)st; wordscan al)pc, ar in ;L l l l l l l l i ) ( !
l '  ()\[' ( l i f fer(;nl ;  ('.
;/os(!-v;rli;l,I i l ,\['orllt,~ gbll(l \[;h(~l'(!
~%1'c, llO sit\[It)l(', ;)dl(1 ;d)solul,(~ l/l\[(',,ql;lii~t spec, i\[i7 wh ich  iS al)t)rot)ria,l;c i / l  a t);u'l;ic, ula, r(:onlx'.xl;.
To (x)pe wii,h I;his ,sil:ll;d;i()n~ w(; axh)l)ix;da.
\]i(;urisl;i(: sl,ra,1;(%y I)as(;(t on an idealiz(;( l  nl()(l(;Iof Fr(;n(:ti case  c()iiv(~,ll{;iOllS in which w(irds m'e di-rt( led into l;wo (:lass(;s: (:lass ;I words m'(; thosewhich are normal ly  wrii:l:en in low(we;me; (:lass 2words  are t, hose H/t(',h ;;~S \])rOl)(',r ltoittls whi( ;h l ior-nml ly  1;~dce a, Sl)e(:i;fl case lml;Ix;rn (',onl;a,inin/r ~d;\](\]~-IoS/; () I IC llt)\])(~I'CktS(~ c, tmra,c,l;er.
Class 1 words  gO, I f .
('r;m; ('.ai)italiz('d hyt)ol;}i.
(;s(!,~ ;i J: Lhe \[)el,;innillg o\['gt S(',Ill~(',it(;(', O1' wh( ' , l l  l;h(; (;Ollll)\](',I;iOll l)r('fix is (;;~l)-ita,liz(,d; llI)I)(;rt:;tso hyi)othos(;,q when the (:oml)le-1 oo089694929088a613482t~o  - - g - -  1 _ J200O 4OO0 6000average aciive voc;ahulafy sizeo y-,' ........... i ;  ;?i:l .,?dyna ln ic  *dynamic wilh histoly14 slatic with hisloly ,~..s ta t i cxLBoo0 100o0\[?i~ur(', 3: Targel; I:e?t coverag(; versus acl;ive vocal),olary size, lot st;at,it and (tynmni(: met;hods.
The wiU~,hi,~4,o'qq (:urv(,.s reilex:i~ (;he addiiiion of previously cn--(:omd;(u(~d (:aq4(',I, t (~xl, tokens l;() the act;ive voc~l)ulary,l;ion l)r(~tix is upt)(;r(:ics(; mid  al: \[(;asl; i,wo (:}l;rra, cix~rslon G and \]()w('.F(;;t,q(; hyl)ot;hesc,~ ol;h(!rwis(,.
(7lass2 w()rds ~(',II(!I'}IJ,C upl)('.r(;as(; hyl)ol,hes(;,~ ml(h;r 1;h(',~mn(; con(li l Jol is ~ts (',lass I words,  ol;h('mwise ver-lml; ini  hyt)ol;hcses.5 l .
\ [esu l t s\?e lx~stx~d i l l(;  (Ximl)letfion (;ligiii(,, (m \[;wo differ(;ni\ ] \ [mism'd lx;xlis nol: in ()ill' l ;raJnlng (',ortms.
Texl,A, (:Olll;~inint\[ 786 (\[~lll;onlld;it;ilJly) ic|iEll(;(l pa.il's~19/157 Engl ish ;aid 21 ,\] 30 Frent:h ix)kens, w~m used1,o del;e, rufil~c o l ) l Jnuun lia,rmnt;lx',r sel, i;ings; t;exl:\] 1, (:onl;~lJning l id0  (mtlxmiatica.l ly) a l igned tmirs,29,886 Engl ish and 32,\] 38 Frcnci i  1;okens, was usedI,o tx)rrol)or;iAx~ the.
l'(;Sltll;s. Tests wcr(.'
COlithl('l;(,.tiwiiJl ~ 3000-word dynmnic  acl;ivt, vocabu lm'y  mlg-I l i(;tit(;d wi l J i  al l  en(:ount;er(xt l;m'get;-l, cxl; t7)rlns.Four  lil(~SUl'C,s o\[" (',oint)lelJon t)p,r\['orlna,lic,(!
w(;l()used.
A l l  ll,SSlllllO l;tl~l, i;iic 1;ra, lisl~tl;or w i l l  a,c,c, epl; a('.orr(;('.l; ?
'.Oml)letion prot)osa.1 a.s SOOli ?i.s it is mad(;(it,, wil;houl: l ;yping \[ l lr l;hc, l ) .
Th(~ lll()~ql; direcl: iu-(lex is l;iu', l ) ropor l Jon of (Jl0d~%(;t(!rs in (:orl(!t'.t;ly-coiui) lc ix;d ,quflix(;s. \[/,cla, t;ed 1:o th is  is i;lm pro-por t ion  of (:orrc,(:l;ly-mll;icip~tt,d chltl'~K;l;(;i'S: l;}i()S(~itt COI'I'(W.I; sutI ixes phls rely /;h;d; ln;~t;cli /.it('.
lICK|,ch~racl;er the l,rmisl;~l;or will tiave l;o tyl)c. The fi-lilt.| l;WO lll(~;tsur(!s ;IAo in lxmdcd Ix) ~t)prt)xiimd,t~ i,hcIIIIlHI)CF o\[" \]?eysl;rokes s;tved w i th in  words.
Thefirsl; ooSSIllliCS l\]ud; l, he, l irlmslal;()r TlS(',S ~ SlmcialCOllil\[igblid> ('.OSl,iug OIIC k(;ysi;rok(', lx) ~r(:c(;i)t; ;L p rot)()S;-I\[, r|~h(\] s(',COlI(t 0~S,SlllllCS |;h0ol; ~t(;(;(',t)l;};~ll(:(~ COll-sisl;s merely  ill l ;yping l;h(', chm'~mlx;r whit:h fol-lows i,he word  e i ther  a st)~me or a punci;ua, I;ion\[ll}~l'k.
3 Complel ; ions m'e free in this i~ccoIlltl;hlt,~>:;S()lne IDri!nch lirt!l ixes si1ch &,q .jusqu' \vhich el ide3 9 V7570656055504540; o, /  Sa'"" anticipated characters ~,--completed characters -*--.keystrokes saved 2 ,.
:: ..... ~e.t,o~ .
.
.
.
.
edld :~"...... ~ .................. x .
?
.
.
.
.
.
.
.
.
.
~ .
.
.
.
.
.
.
.
.
.
~ .
.
.
.
.
.
.
.
.
x .
.
.
.
.
.
.
.
.
.
~ .
.
.
.
.
.
.
.
.
.
.
.
.
.
x ?
_ .....?.
.l0.2 0.4 0.6 0.8trlgram weightFigure 4: Combined trigram/translation model per-formance versus trigram weight 1.but all punctuation must be manually typed, andany spaces or punctuation characters in hand-typed prefixes are assessed a one-keystroke escapepenalty.Figure 4 shows the performance of the systemfor various values of the trigram coefficient A. Anoteworthy feature of this graph is that interpola-tion improves performance over the pure trigramby only about 3%.
This is due in large part to thefact that the translation model has already made acontribution in non-linear fashion through the dy-namic vocabulary, which excludes many hypothe-ses that might otherwise have misled the languagemodel.Another interesting characteristic of the data isthe discrepancy between the number of correctlyanticipated characters and those in completed suf-fixes.
Investigation revealed the bulk of this tobe attributable to morphological error.
In orderto give the system a better chance of getting in-flections right, we modified the behaviour of thehypothesis generator so that it would never pro-duce the same best candidate more than once fora single token; in other words, when the trans-lator duplicates the first character of a proposal,the system infers that the proposal is wrong andchanges it.
As shown in table 1, completion per-formance improves ubstantially as a result.
Fig-ure 5 contains a detailed record of a completionsession that points up one further deficiency in thesystem: it proposes punctuation hypotheses toooften.
We found that simply suppressing punctu-ation in the generator led to another small incre-ment in keystroke savings, as indicated in table 1.letters are not normally followed by either spaces orpunctuation.
We assume the system can detect heseand automatically suppress the character used to ef-fect the completion.nleasure(% chars)anticipatedcompletedkeystrokeslkeystrokes2methodtext A text Bstd PBHR P+NP P+NP77.2 80.0 79.2 78.967.1 73.6 72.6 72.265.1 71.8 72.3 71.949.8 54.6 55.1 55.1Table 1: Final performance figures.
PBHR standsfor previous-best-hypothesis rejection, and P+NP forPHBR without punctuation hypotheses.6 Conc lus ionThe work described in this paper constitutes arudimentary but concrete first step toward a newapproach to IMT in which the medium of inter-action is simply the target text itself.
In con-trast with previous interactive approaches, thetranslator is never expected to perform tasks thatare outside the realm of translation proper (suchas advising a machine about common sense is-sues).
In line with the spirit of truly interac-tive approaches, the translator is called upon earlyenough to guide the system away from a "raw ma-chine translation" he or she would rather not haveto revise.
And in fact the machine is now the onerequired to revise its own copy, making use of ev-ery keystroke ntered by the translator to steeritself in a useful direction.This strikes us as the "proper place" of menand machines in IMT, and we intend to contiimeexploring this promising avenue in our future re-search.Re ferencesHervd Blanchon.
1994.
Perspectives of DBMTfor monolingual authors on the basis of MDIA-1, an implemented mock-up.
In COLING-9/~,pages 115-119, Kyoto, August.Christian Boitet.
1990.
Towards personal MT.
InCOLING-90, pages 30 35, Helsinki, August.J.
Brousseau, C. Drouin, G.Foster, P. Isabelle,R.
Kuhn, Y. Normandin, and P. Plamondon.1995.
French speech recognition in an au-tomatic dictation system for translators: theTransTalk project.
In Eurospeech 95, pages193- 196, Madrid, Spain, September.Ralf D. Brown and Sergei Nirenburg.
1990.Human-computer interaction for semantic dis-ambiguation.
In COLING-90, pages 42-47,Helsinki, August.Peter F. Brown, Stephen A. Della Pietra, VincentDella J. Pietra, and Robert L. Mercer.
1993.398gous + /Nousrfialisons r~al+ /avons r/endre rfi/aliser r4a/lise r4al/isonstous t+ /des t/ousque q+ /les q/uele + /leCanada C+ /gouvernement C/anadaco~e ~+ / ,  c lo thebien bi+ /un b/eaucoup bi/end '  + /d 'autres + /autrespays p+ /, p/ays+ /,riches r+ /, r/iehesOU + /OUpauvres + /pauvresa a+ /lesbeaucoup b+ /6t~ b/eaucouptrop t+ /de t/ropde + /deses se+ /temps s/ervices se/scitoyens c+ /trop c/itoyensqui q+ /.
q/uiFigure 5: A sample completion run Ibr the English source sentence We all realize that like many other countries,rich or poor, Canada has too many citizens who cannot afford deeent housing.
The first column contains theFrench target sentence; the second the prefix typed by the translator, followed by a plus sign; and the third therecord of successive proposals for each token, with a slash separating prefix from proposed completion.The mathematics of machine translation: Pa-rameter estimation.
Computational Linguistics,19(2) :263- 312, June.hto Dagan, Kenneth W. Church, and William A.Gale.
1993.
Robust bilingual word alignmentfor machine aided translation.
Ill Proceedingsof the Workshop on Very Large Corpora (A CL93), Columbus, Ohio.Patrick W. Demasco and Kathleen F. McCoy.1992.
Generating text froin coinpressed input:An intelligent interface for people with severemotor impairments.
CACM, 35(5), May.Eurolang.
1995.
Eurolang Optimizer, product de-scription.Robert Frederking, Dean Grannes, Peter Cous-seau, and Sergei Nirenburg.
1993.
An MAT9 tool and its etfectiveness.
In \[ roceedings of th, eDARPA HLT Workshop, Princeton, NJ.IBM.
1995.
IBM 35"anslation Manager, productdescription.F.
Jelinek.
1990.
Self-organized language mod-eling for speech recognition.
\[n A. Waibel andK.
Lee, editors, Readings in Speech Recognition,pages 450 5{)6.
Morgan Kaufmaim, San Mateo,California.Martin Kay.
1973.
Tile MIND system.
InR.
Rustin, editor, Natural Language Processing,pages 155-188.
Algorithmics Press, New York.M.
Kugler, G. Heyer, R. Kese, B. yon Kleist-Retzow, and G. Winkelmann.
1991.
The Trans-lator's Workbench: An environment for multi-lingual text processing and translation.
In Pro-eeedings of Mr1 'Summit IH, pages 81 83, Wash-ington, July.Hiroshi Maruyama and Hideo Wataimbe.
11990.An interactive Japanese parser for machinetranslation.
In COLING-90, pages 257-262,Helsinld, August.S(xge, Nirenburg.
1992.
Tools for machine-aided translation: The CMU TWS.
META,37(4):709 720.Michel Simard, George F. Foster, and Pierre Is-abelle.
1992.
Using cognates to align sen-tences in bilingual corpora.
In TMI-4, Mon-treal, Canada.Trados.
1995.
3\]'ados ~lk'anslators Workbench,product description.P.
,l. Whitelock, M. McGee Wood, B. J. Chandler,N.
Itolden, and H. J. Horsfall.
1986.
Strategiesfor interaetiw ~.
machine translation: the experi-ence and implications of the UMIST Japaneseproject.
In COLING-86, pages 329 334, \]~Oliil.l{dlni Zajae.
1988.
Interactive translation: A newapproach.
In COLING-88, pages 785 790, Bu-dapest.399
