Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 697?701,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsIncremental Topic-Based Translation Model Adaptation forConversational Spoken Language TranslationSanjika Hewavitharana, Dennis N. Mehay, Sankaranarayanan Ananthakrishnanand Prem NatarajanSpeech, Language and Multimedia Business UnitRaytheon BBN TechnologiesCambridge, MA 02138, USA{shewavit,dmehay,sanantha,pnataraj}@bbn.comAbstractWe describe a translation model adapta-tion approach for conversational spokenlanguage translation (CSLT), which en-courages the use of contextually appropri-ate translation options from relevant train-ing conversations.
Our approach employsa monolingual LDA topic model to de-rive a similarity measure between the testconversation and the set of training con-versations, which is used to bias trans-lation choices towards the current con-text.
A significant novelty of our adap-tation technique is its incremental nature;we continuously update the topic distribu-tion on the evolving test conversation asnew utterances become available.
Thus,our approach is well-suited to the causalconstraint of spoken conversations.
Onan English-to-Iraqi CSLT task, the pro-posed approach gives significant improve-ments over a baseline system as measuredby BLEU, TER, and NIST.
Interestingly,the incremental approach outperforms anon-incremental oracle that has up-frontknowledge of the whole conversation.1 IntroductionConversational spoken language translation(CSLT) systems facilitate communication be-tween subjects who do not speak the samelanguage.
Current systems are typically used toachieve a specific task (e.g.
vehicle checkpointsearch, medical diagnosis, etc.).
These task-drivenDisclaimer: This paper is based upon work supported by theDARPA BOLT program.
The views expressed here are thoseof the authors and do not reflect the official policy or positionof the Department of Defense or the U.S. Government.Distribution Statement A (Approved for Public Release,Distribution Unlimited)conversations typically revolve around a set ofcentral topics, which may not be evident at thebeginning of the interaction.
As the conversationprogresses, however, the gradual accumulation ofcontextual information can be used to infer thetopic(s) of discussion, and to deploy contextuallyappropriate translation phrase pairs.
For example,the word ?drugs?
will predominantly translateinto Spanish as ?medicamentos?
(medicines) in amedical scenario, whereas the translation ?drogas?
(illegal drugs) will predominate in a law enforce-ment scenario.
Most CSLT systems do not takehigh-level global context into account, and insteadtranslate each utterance in isolation.
This oftenresults in contextually inappropriate translations,and is particularly problematic in conversationalspeech, which usually exhibits short, spontaneous,and often ambiguous utterances.In this paper, we describe a novel topic-basedadaptation technique for phrase-based statisticalmachine translation (SMT) of spoken conversa-tions.
We begin by building a monolingual la-tent Dirichlet alocation (LDA) topic model on thetraining conversations (each conversation corre-sponds to a ?document?
in the LDA paradigm).At run-time, this model is used to infer a topicdistribution over the evolving test conversation upto and including the current utterance.
Transla-tion phrase pairs that originate in training conver-sations whose topic distribution is similar to thatof the current conversation are given preferencethrough a single similarity feature, which aug-ments the standard phrase-based SMT log-linearmodel.
The topic distribution for the test conver-sation is updated incrementally for each new utter-ance as the available history grows.
With this ap-proach, we demonstrate significant improvementsover a baseline phrase-based SMT system as mea-sured by BLEU, TER and NIST scores on anEnglish-to-Iraqi CSLT task.6972 Relation to Prior WorkDomain adaptation to improve SMT performancehas attracted considerable attention in recent years(Foster and Kuhn, 2007; Finch and Sumita, 2008;Matsoukas et al, 2009).
The general theme is todivide the training data into partitions representingdifferent domains, and to prefer translation optionsfor a test sentence from training domains that mostresemble the current document context.
Weak-nesses of this approach include (a) assuming theexistence of discrete, non-overlapping domains;and (b) the unreliability of models generated bysegments with little training data.To avoid the need for hard decisions about do-main membership, some have used topic modelingto improve SMT performance, e.g., using latentsemantic analysis (Tam et al, 2007) or ?biTAM?
(Zhao and Xing, 2006).
In contrast to our sourcelanguage approach, these authors use both sourceand target information.Perhaps most relevant are the approaches ofGong et al (2010) and Eidelman et al (2012),who both describe adaptation techniques wheremonolingual LDA topic models are used to ob-tain a topic distribution over the training data, fol-lowed by dynamic adaptation of the phrase tablebased on the inferred topic of the test document.While our proposed approach also employs mono-lingual LDA topic models, it deviates from theabove methods in the following important ways.First, the existing approaches are geared towardsbatch-mode text translation, and assume that thefull document context of a test sentence is alwaysavailable.
This assumption is incompatible withtranslation of spoken conversations, which are in-herently causal.
Our proposed approach inferstopic distributions incrementally as the conversa-tion progresses.
Thus, it is not only consistentwith the causal requirement, but is also capableof tracking topical changes during the course of aconversation.Second, we do not directly augment the trans-lation table with the inferred topic distribution.Rather, we compute a similarity between the cur-rent conversation history and each of the trainingconversations, and use this measure to dynami-cally score the relevance of candidate translationphrase pairs during decoding.3 Corpus Data and Baseline SMTWe use the DARPA TransTac English-Iraqi par-allel two-way spoken dialogue collection to trainboth translation and LDA topic models.
This dataset contains a variety of scenarios, including med-ical diagnosis; force protection (e.g.
checkpoint,reconnaissance, patrol); aid, maintenance and in-frastructure, etc.
; each transcribed from spokenbilingual conversations and manually translated.The SMT parallel training corpus contains ap-proximately 773K sentence pairs (7.3M Englishwords).
We used this corpus to extract transla-tion phrase pairs from bidirectional IBM Model4 word alignment (Och and Ney, 2003) based onthe heuristic approach of (Koehn et al, 2003).
A4-gram target LM was trained on all Iraqi Ara-bic transcriptions.
Our phrase-based decoder issimilar to Moses (Koehn et al, 2007) and usesthe phrase pairs and target LM to perform beamsearch stack decoding based on a standard log-linear model, the parameters of which were tunedwith MERT (Och, 2003) on a held-out develop-ment set (3,534 sentence pairs, 45K words) usingBLEU as the tuning metric.
Finally, we evaluatedtranslation performance on a separate, unseen testset (3,138 sentence pairs, 38K words).Of the 773K training sentence pairs, about100K (corresponding to 1,600 conversations) aremarked with conversation boundaries.
We use theEnglish side of these conversations for trainingLDA topic models.
All other sentence pairs areassigned to a ?background conversation?, whichsignals the absence of the topic similarity featurefor phrase pairs derived from these instances.
Allof the development and test set data were markedwith conversation boundaries.
The training, devel-opment and test sets were partitioned at the con-versation level, so that we could model a topicdistribution for entire conversations, both duringtraining and during tuning and testing.4 Incremental Topic-Based AdaptationOur approach is based on the premise that biasingthe translation model to favor phrase pairs origi-nating in training conversations that are contextu-ally similar to the current conversation will leadto better translation quality.
The topic distributionis incrementally updated as the conversation his-tory grows, and we recompute the topic similaritybetween the current conversation and the trainingconversations for each new source utterance.6984.1 Topic modeling with LDAWe use latent Dirichlet alocation, or LDA, (Blei etal., 2003) to obtain a topic distribution over con-versations.
For each conversation di in the train-ing collection (1,600 conversations), LDA infers atopic distribution ?di = p(zk|di) for all latent top-ics zk = {1, ...,K}, where K is the number oftopics.
In this work, we experiment with valuesof K ?
{20, 30, 40}.
The full conversation his-tory is available for training the topic models andestimating topic distributions in the training set.At run-time, however, we construct the con-versation history for the tuning and test sets in-crementally, one utterance at a time, mirroring areal-world scenario where our knowledge is lim-ited to the utterances that have been spoken up tothat point in time.
Thus, each development/test ut-terance is associated with a different conversationhistory d?, for which we infer a topic distribution?d?
= p(zk|d?)
using the trained LDA model.
Weuse Mallet (McCallum, 2002) for training topicmodels and inferring topic distributions.4.2 Topic Similarity ComputationFor each test utterance, we are able to infer thetopic distribution ?d?
based on the accumulatedhistory of the current conversation.
We use thisto compute a measure of similarity between theevolving test conversation and each of the train-ing conversations, for which we already have topicdistributions ?di .
Because ?di and ?d?
are proba-bility distributions, we use the Jensen-Shannon di-vergence (JSD) to evaluate their similarity (Man-ning and Schu?tze, 1999).
The JSD is a smoothedand symmetric version of Kullback-Leibler diver-gence, which is typically used to compare twoprobability distributions.
We define the similar-ity score as sim(?di , ?d?)
= 1?
JSD(?di ||?d?
).1Thus, we obtain a vector of similarity scores in-dexed by the training conversations.4.3 Integration with the DecoderWe provide the SMT decoder with the similar-ity vector for each test utterance.
Additionally,the SMT phrase table tracks, for each phrase pair,the set of parent training conversations (includingthe ?background conversation?)
from which thatphrase pair originated.
Using this information, thedecoder evaluates, for each candidate phrase pair1JSD(?di ||?d?)
?
[0, 1] when defined using log2.REFERENCE TRANSCRIPTIONSSYSTEM BLEU?
TER?
NIST?Baseline 19.32 58.66 6.22incr20 19.39 58.44 6.26*incr30 19.36 58.32* 6.26incr40 19.68* 58.19* 6.28*conv20 19.60* 58.36* 6.27*conv30 19.48 58.38* 6.27*conv40 19.50 58.33* 6.28*ASR TRANSCRIPTIONSSYSTEM BLEU?
TER?
NIST?Baseline 16.92 62.57 5.75incr20 16.99 62.28* 5.77incr30 16.96 62.33* 5.78incr40 17.31* 61.97* 5.83*conv20 17.29* 62.28* 5.81*conv30 17.12 62.19* 5.80*conv40 17.00 62.14* 5.79*Table 1: Stemmed results on 3,138-utterance testset.
Asterisked results are significantly better thanthe baseline (p ?
0.05) using 1,000 iterationsof paired bootstrap re-sampling (Koehn, 2004).
(Key: incrN = incremental LDA with N topics;convN = non-incremental, whole-conversationLDA with N topics.
)X ?
Y added to the search graph, its topic simi-larity score as follows:FX?Y = maxi?Par(X?Y )sim(?di , ?d?)
(1)where Par(X ?
Y ) is the set of training con-versations from which the candidate phrase pairoriginated.
Phrase pairs from the ?backgroundconversation?
only are assigned a similarity scoreFX?Y = 0.00.
In this way we distill the in-ferred topic distributions down to a single featurefor each candidate phrase pair.
We add this fea-ture to the log-linear translation model with itsown weight, which is tuned with MERT.
The in-tuition behind this feature is that the lower boundof suitability of a candidate phrase pair should bedirectly proportional to the similarity between itsmost relevant conversational provenance and thecurrent context.
Phrase pairs which only occur inthe background conversation are not directly pe-nalized, but contribute nothing to the topic simi-larity score.699Figure 1: Rank trajectories of 4 LDA inferred topics, with incremental topic inference.
The x-axisindicates the utterance number.
The y-axis indicates a topic?s rank at each utterance.5 Experimental Setup and ResultsThe baseline English-to-Iraqi phrase-based SMTsystem was built as described in Section 3.
Thissystem translated each utterance independently,ignoring higher-level conversational context.For the topic-adapted system, we comparedtranslation performance with a varying number ofLDA topics.
In intuitive agreement with the ap-proximate number of scenario types known to becovered by our data set, a range of 20-40 topicsyielded the best results.
We compared the pro-posed incremental topic tracking approach to anon-causal oracle approach that had up-front ac-cess to the entire source conversations at run-time.In all cases, we compared translation perfor-mance on both clean-text and automatic speechrecognition (ASR) transcriptions of the source ut-terances.
ASR transcriptions were generated usinga high-performance two-pass HMM-based sys-tem, which delivered a word error rate (WER) of10.6% on the test set utterances.Table 1 summarizes test set performance inBLEU (Papineni et al, 2001), NIST (Doddington,2002) and TER (Snover et al, 2006).
Given themorphological complexity of Iraqi Arabic, com-puting string-based metrics on raw output canbe misleadingly low and does not always reflectwhether the core message was conveyed.
Sincethe primary goal of CSLT is information transfer,we present automatic results that are computed af-ter stemming with an Iraqi Arabic stemmer.We note that in all settings (incrementaland non-causal oracle) our adaptation approachmatches or significantly outperforms the baselineacross multiple evaluation metrics.
In particular,the incremental LDA system with 40 topics is thetop-scoring system in both clean-text and ASR set-tings.
In the ASR setting, which simulates a real-world deployment scenario, this system achievesimprovements of 0.39 (BLEU), -0.6 (TER) and0.08 (NIST).6 Discussion and Future DirectionsWe have presented a novel, incremental topic-based translation model adaptation approach thatobeys the causality constraint imposed by spokenconversations.
This approach yields statisticallysignificant gains in standard MT metric scores.We have also demonstrated that incrementaladaptation on an evolving conversation performsbetter than oracle adaptation based on the com-plete conversation history.
Although this mayseem counter-intuitive, Figure 1 gives clues as towhy this happens.
This figure illustrates the ranktrajectory of four LDA topics as the incremen-tal conversation grows.
The accompanying textshows excerpts from the conversation.
We indi-cate (in superscript) the topic identity of most rele-vant words in an utterance that are associated withthat topic.
At the first utterance, the top-rankedtopic is ?5?, due to the occurrence of ?captain?in the greeting.
As the conversation evolves, wenote that this topic become less prominent.
Theconversation shifts to a discussion on ?windows?,raising the prominence of topic ?4?.
Finally, topic?3?
becomes prominent due to the presence of the700words ?project?
and ?contract?.
Thus, the incre-mental approach is able to track the topic trajecto-ries in the conversation, and is able to select morerelevant phrase pairs than oracle LDA, which esti-mates one topic distribution for the entire conver-sation.In this work we have used only the source lan-guage utterance in inferring the topic distribution.In a two-way CLST system, we also have accessto SMT-generated back-translations in the Iraqi-English direction.
As a next step, we plan to useSMT-generated English translation of Iraqi utter-ances to improve topic estimation.ReferencesDavid M. Blei, Andrew Y. Ng, and Michael I. Jordan.2003.
Latent Dirichlet alocation.
Journal of Ma-chine Learning Research, 3:993?1022, March.George Doddington.
2002.
Automatic evaluationof machine translation quality using n-gram co-occurrence statistics.
In Proceedings of the sec-ond international conference on Human LanguageTechnology Research, HLT ?02, pages 138?145, SanFrancisco, CA, USA.
Morgan Kaufmann PublishersInc.Vladimir Eidelman, Jordan Boyd-Graber, and PhilipResnik.
2012.
Topic models for dynamic transla-tion model adaptation.
In Proceedings of the 50thAnnual Meeting of the Association for Computa-tional Linguistics: Short Papers - Volume 2, ACL?12, pages 115?119, Stroudsburg, PA, USA.
Associ-ation for Computational Linguistics.Andrew Finch and Eiichiro Sumita.
2008.
Dynamicmodel interpolation for statistical machine transla-tion.
In Proceedings of the Third Workshop onStatistical Machine Translation, StatMT ?08, pages208?215, Stroudsburg, PA, USA.
Association forComputational Linguistics.George Foster and Roland Kuhn.
2007.
Mixture-model adaptation for SMT.
In Proceedings of theSecond Workshop on Statistical Machine Transla-tion, StatMT ?07, pages 128?135, Stroudsburg, PA,USA.
Association for Computational Linguistics.Zhengxian Gong, Yu Zhang, and Guodong Zhou.2010.
Statistical machine translation based on LDA.In Universal Communication Symposium (IUCS),2010 4th International, pages 286?290.Philipp Koehn, Franz Josef Och, and Daniel Marcu.2003.
Statistical phrase-based translation.
InNAACL ?03: Proceedings of the 2003 Conferenceof the North American Chapter of the Associationfor Computational Linguistics on Human LanguageTechnology, pages 48?54, Morristown, NJ, USA.Association for Computational Linguistics.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran,Richard Zens, Chris Dyer, Ondr?ej Bojar, AlexandraConstantin, and Evan Herbst.
2007.
Moses: Opensource toolkit for statistical machine translation.
InProceedings of the 45th Annual Meeting of the ACLon Interactive Poster and Demonstration Sessions,ACL ?07, pages 177?180, Stroudsburg, PA, USA.Association for Computational Linguistics.Philipp Koehn.
2004.
Statistical significance tests formachine translation evaluation.
In EMNLP, pages388?395, Barcelona, Spain, July.Christopher D. Manning and Hinrich Schu?tze.
1999.Foundations of statistical natural language process-ing.
MIT Press, Cambridge, MA, USA.Spyros Matsoukas, Antti-Veikko I. Rosti, and BingZhang.
2009.
Discriminative corpus weight es-timation for machine translation.
In Proceedingsof the 2009 Conference on Empirical Methods inNatural Language Processing: Volume 2 - Volume2, EMNLP ?09, pages 708?717, Stroudsburg, PA,USA.
Association for Computational Linguistics.Andrew Kachites McCallum.
2002.
Mal-let: A machine learning for language toolkit.http://mallet.cs.umass.edu.Franz Josef Och and Hermann Ney.
2003.
A sys-tematic comparison of various statistical alignmentmodels.
Computational Linguistics, 29(1):19?51,March.Franz Josef Och.
2003.
Minimum error rate train-ing in statistical machine translation.
In ACL ?03:Proceedings of the 41st Annual Meeting on Asso-ciation for Computational Linguistics, pages 160?167, Morristown, NJ, USA.
Association for Compu-tational Linguistics.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2001.
BLEU: A method for automaticevaluation of machine translation.
In ACL ?02: Pro-ceedings of the 40th Annual Meeting on Associa-tion for Computational Linguistics, pages 311?318,Morristown, NJ, USA.
Association for Computa-tional Linguistics.Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-nea Micciulla, and John Makhoul.
2006.
A study oftranslation edit rate with targeted human annotation.In Proceedings AMTA, pages 223?231, August.Yik-Cheung Tam, Ian Lane, and Tanja Schultz.
2007.Bilingual LSA-based adaptation for statistical ma-chine translation.
Machine Translation, 21(4):187?207, December.Bing Zhao and Eric P. Xing.
2006.
BiTAM: Bilingualtopic admixture models for word alignment.
In InProceedings of the 44th Annual Meeting of the As-sociation for Computational Linguistics (ACL ?06).701
