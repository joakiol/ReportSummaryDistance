Proceedings of the 53rd Annual Meeting of the Association for Computational Linguisticsand the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 674?680,Beijing, China, July 26-31, 2015.c?2015 Association for Computational LinguisticsA Language-Independent Feature Schema for Inflectional MorphologyJohn Sylak-Glassman*, Christo Kirov*, David Yarowsky**, Roger Que***Center for Language and Speech Processing**Department of Computer ScienceJohns Hopkins UniversityBaltimore, MD 21218jcsg@jhu.edu, ckirov@gmail.com, yarowsky@jhu.edu, query@jhu.eduAbstractThis paper presents a universal morphological fea-ture schema that represents the finest distinctions inmeaning that are expressed by overt, affixal inflec-tional morphology across languages.
This schemais used to universalize data extracted from Wik-tionary via a robust multidimensional table parsingalgorithm and feature mapping algorithms, yielding883,965 instantiated paradigms in 352 languages.These data are shown to be effective for trainingmorphological analyzers, yielding significant accu-racy gains when applied to Durrett and DeNero?s(2013) paradigm learning framework.1 IntroductionSemantically detailed and typologically-informedmorphological analysis that is broadly cross-linguistically applicable and interoperable has thepotential to improve many NLP applications, in-cluding machine translation (particularly of mor-phologically rich languages), parsing (Choi et al.,2015; Zeman, 2008; Mikulov?a et al., 2006), n-gram language models, information extraction,and co-reference resolution.To do large-scale cross-linguistic analysis andtranslation, it is necessary to be able to comparethe meanings of morphemes using a single, well-defined framework.
Haspelmath (2010) notes thatwhile morphological categories will never mapwith perfect precision across languages and canonly be exhaustively defined within a single lan-guage, practitioners of linguistic typology havetypically recognized that there is sufficient simi-larity in these categories across languages to domeaningful comparison.
For this purpose, Haspel-math (2010) proposes that typologists preciselydefine dedicated language-independent compara-tive concepts and identify the presence of theseconcepts in specific languages.
In this spirit, wepresent a universal morphological feature schema,in which features that have a status akin to thoseof comparative concepts are used to represent thefinest distinctions in meaning that are expressedby inflectional morphology across languages.
Thisschema can in turn be used to universalize mor-phological data from the world?s languages, whichallows for direct comparison and translation ofmorphological material across languages.
Thisgreatly increases the amount of data available tomorphological analysis tools, since data from anylanguage can be specified in a common formatwith the same features.Wiktionary constitutes one of the largestavailable sources of complete morphologicalparadigms across diverse languages, with sub-stantial ongoing growth in language and lemmacoverage, and hence forms a natural source ofdata for broadly multilingual supervised learn-ing.
Wiktionary paradigm table formats, how-ever, are often complex, nested, 2-3 dimensionalstructures intended for human readability ratherthan machine parsing, and are broadly inconsistentacross languages and Wiktionary editions.
Thispaper presents an original, robust multidimen-sional table parsing system that generalizes effec-tively across these languages, collectively yield-ing significant gains in supervised morphologicalparadigm learning in Durrett and DeNero?s (2013)framework.2 Universal Morphological FeatureSchemaThe purpose of the universal morphological fea-ture schema is to allow any given overt, affixal(non-root) inflectional morpheme in any languageto be given a precise, language-independent def-inition.
The schema is composed of a set offeatures that represent semantic ?atoms?
that arenever decomposed into more finely differentiatedmeanings in any natural language.
This ensuresthat the meanings of all inflectional morphemesare able to be represented either through singlefeatures or through multiple features in combina-674tion.
These features capture only the semanticcontent of morphemes, but can be integrated intoexisting frameworks that precisely indicate mor-pheme form (Sagot and Walther, 2013) or auto-matically discover it (Dreyer and Eisner, 2011;Hammarstr?om, 2006; Goldsmith, 2001).
The factthat the schema is meant to capture only the mean-ings of overt, non-root affixal morphemes restrictsthe semantic-conceptual space that must be cap-tured by its features and renders an interlingualapproach to representing inflectional morphologyfeasible.The universal morphological feature schemais most similar to tagset systematization effortsacross multiple languages, such as the Univer-sal Dependencies Project (Choi et al., 2015) andInterset (Zeman, 2008).
While these efforts en-code similar morphological features to the cur-rent schema, their goal is different, namely to sys-tematize pre-existing tagsets, which include lex-ical and syntactic information, for 30 specificlanguages.
The goal of the schema presentedhere is to capture the most basic meanings en-coded by inflectional morphology across all theworld?s languages and to define those meaningsin a language-independent manner.
Because of itswide-scope, our universal morphological featureschema will likely need to include other featuresand even other dimensions of meaning, for whichthe authors invite suggestions.2.1 Construction MethodologyThe first step in constructing the universal mor-phological feature schema was to identify the di-mensions of meaning (e.g.
case, number, tense,mood, etc.)
that are expressed by inflectional mor-phology in the world?s languages.
These wereidentified by surveying the linguistic typology lit-erature on parts of speech and then identifying thekinds of inflectional morphology that are typicallyassociated with each part of speech.For each dimension, we identified the finest dis-tinctions in meaning made within that dimensionby a natural language.
Some higher-level ?coverfeatures?
representing common cross-linguisticgroupings were also included.
For example, fea-tures such as indicative (IND) and subjunctive(SBJV) represent groupings of basic modality fea-tures which occur in multiple languages and showsimilar usage patterns (Palmer, 2001).Each dimension has an underlying semantic ba-sis used to define its features.
To determine theunderlying semantic basis for each dimension, theliterature in linguistic typology and in description-oriented linguistic theory was surveyed for expla-nations of each dimension that offered ways toprecisely define the observed features.2.2 Contents of the SchemaThe universal morphological feature schema rep-resents 23 dimensions of meaning with 212 fea-tures.
Because space limitations preclude a de-tailed discussion of the semantic basis of each di-mension and the definitions of each feature, Ta-ble 1 presents each dimension of meaning, thelabels of its features, and citations for the mainsources for the semantic bases of each dimension.To the extent possible, feature labels conform tothe Leipzig Glossing Rules (Comrie et al., 2008)and to the labels in the sources used to define thesemantic basis for each dimension of meaning.
Asubstantially expanded exploration and analysis ofthese dimensions and schema framework may befound in Sylak-Glassman et al.
(To appear).Note that because gender categories are not nec-essarily defined by semantic criteria and rarelymap neatly across languages, this schema treatsgender features as open-class.13 Wiktionary Data Extraction andMappingWiktionary contains a wealth of training data formorphological analysis, most notably inflectionalparadigm tables.
Since its pages are primar-ily written by human authors for human readers,and there are no overarching standards for howparadigms should be presented, these tables con-tain many inconsistencies and are at best semi-structured.
Layouts differ depending on the edi-tion language in which a word is being definedand within an edition depending on the word?s lan-guage and part of speech.
The textual descriptorsused for morphological features are also not sys-tematically defined.
These idiosyncrasies causenumerous difficulties for automatic paradigm ex-traction, but the redundancy of having data pre-sented in multiple ways across different editionsgives us an opportunity to arrive at a consensusdescription of an inflected form, and to fill in gapswhen the coverage of one edition diverges from1To limit feature proliferation, the schema encodes gendercategories as features that may be shared across languageswithin a phylogenetic stock or family, in order to captureidentical gender category definitions and assignments that re-sult from common ancestry, as may be possible for the 25historical noun classes in the Bantu stock (Demuth, 2000).675Dimension Features Semantic BasisAktionsart ACCMP, ACH, ACTY, ATEL, DUR, DYN, PCT, SEMEL, STAT, TEL Cable (2008), Vendler (1957), Comrie (1976a)Animacy ANIM, HUM, INAN, NHUM Yamamoto (1999), Comrie (1989)Aspect HAB, IPFV, ITER, PFV, PRF, PROG, PROSP Klein (1994)Case ABL, ABS, ACC, ALL, ANTE, APPRX, APUD, AT, AVR, BEN, CIRC, COM, COMPV, DAT, EQU,ERG, ESS, FRML, GEN, INS, IN, INTER, NOM, NOMS, ON, ONHR, ONVR, POST, PRIV, PROL,PROPR, PROX, PRP, PRT, REM, SUB, TERM, VERS, VOCBlake (2001), Radkevich (2010)Comparison AB, CMPR, EQT, RL, SPRL Cuzzolin and Lehmann (2004)Definiteness DEF, INDEF, NSPEC, SPEC Lyons (1999)Deixis ABV, BEL, DIST, EVEN, MED, NVIS, PROX, REF1, REF2, REM, VIS Bhat (2004), Bliss and Ritter (2001)Evidentiality ASSUM, AUD, DRCT, FH, HRSY, INFER, NFH , NVSEN, QUOT, RPRT, SEN Aikhenvald (2004)Finiteness FIN, NFIN Binary finite vs. nonfiniteGender+ BANTU1-23, FEM, MASC, NAKH1-8, NEUT Corbett (1991)Info.
Structure FOC, TOP Lambrecht (1994)Interrogativity DECL, INT Binary declarative vs. interrogativeMood ADM, AUNPRP, AUPRP, COND, DEB, IMP, IND, INTEN, IRR, LKLY, OBLIG, OPT,PERM, POT, PURP, REAL, SBJV, SIMPalmer (2001)Number DU, GPAUC, GRPL, INVN, PAUC, PL, SG, TRI Corbett (2000)Parts of Speech ADJ, ADP, ADV, ART, AUX, CLF, COMP, CONJ, DET, INTJ, N, NUM, PART, PRO,V, V.CVB, V.MSDR, V.PTCPCroft (2000), Haspelmath (1995)Person 0, 1, 2, 3, 4, EXCL, INCL, OBV, PRX Conventional person, obviation and clusivityPolarity NEG, POS Binary positive vs. negativePoliteness AVOID, COL, FOREG, FORM, FORM.ELEV, FORM.HUMB, HIGH, HIGH.ELEV,HIGH.SUPR, INFM, LIT, LOW, POLBrown and Levinson (1987), Comrie (1976b)Possession ALN, NALN, PSSD, PSSPNO+ Type of possession, characteristics of possessorSwitch-Reference CN-R-MN+, DS, DSADV, LOG, OR, SEQMA, SIMMA, SS, SSADV Stirling (1993)Tense 1DAY, FUT, HOD, IMMED, PRS, PST, RCT, RMT Klein (1994), ?
)Valency DITR, IMPRS, INTR, TR Number of verbal arguments from zero to threeVoice ACFOC, ACT, AGFOC, ANTIP, APPL, BFOC, CAUS, CFOC, DIR, IFOC, INV, LFOC,MID, PASS, PFOC, RECP, REFLKlaiman (1991)Table 1: Dimensions of meaning and their features, both sorted alphabeticallythat of another.To make these data available for morphologi-cal analysis, we developed a novel multidimen-sional table parser for Wiktionary to extract in-flected forms with their associated descriptors.
Al-though we describe its function in Wiktionary-specific terms, this strategy can be generalized toextract data tuples from any HTML table with cor-rectly marked-up header and content cells.
We ex-tracted additional descriptors from HTML head-ings and table captions, then mapped all descrip-tors to features in the universal schema.3.1 Extraction from HTML TablesIn its base form, the table parser takes advantageof HTML?s distinction between header and contentcells to identify descriptors and potential inflectedforms, respectively, in an arbitrary inflection ta-ble.
Each content cell is matched with the head-ers immediately up the column, to the left of therow, and in the ?corners?
located at the row andcolumn intersection of the previous two types ofheaders.
Matching headers are stored in a list or-dered by their distance from the content cell.
Fig-ure 1 shows an example where prenais is assignedthe following descriptors:?
Directly up the column: tu, second, singu-lar, simple.?
Directly to the left of the row: imperfect,simple tenses.?
In corners located at the row and column in-tersection of any headers identified by the previoustwo methods: indicative, person.?
Important structured fields found outside thetable, including French and Verb.Lang: French, POS: VerbFigure 1: A portion of the English-edition Wik-tionary conjugation table for the French verb pren-dre ?take.?
The inflected form prenais and its row,column, and corner headers are highlighted.Further, when additional content cells intervenebetween headers, as they do between simple andsingular, the more distant header is marked as?distal.?
This labeling is important for proper han-dling of the column header simple in this exam-676ple: It only applies to the top half of the table, andshould be left out of any labeling of the inflectedforms in the lower half.
This distance information,and a hierarchy of positional precedence, is usedin Section 3.4 to discount these and other poten-tially irrelevant descriptors in the case of conflictsduring the subsequent mapping of descriptors tofeatures in the universal schema.
In general, thepositionally highest ranking header value for eachschema dimension are utilized and lower-rankingconflicting values are discarded.3.2 Extraction from Parenthetical ListsFor some languages, inflected forms are presentedinline next to the headword, instead of in a sep-arate table, as shown for the German noun Haus?house?
:Haus n (genitive Hauses, plural H?auser, diminu-tive H?auschen n or H?auslein n)Here, the italic n indicates a neuter noun.
The in-flection data inside the parentheses are extractedas simple tuples containing the lemma, inflectedform, and inflectional relationship (e.g.
Haus,H?auser, plural).3.3 Improving Extraction AccuracyThe approach described above is sufficient to parsemost Wiktionary data, but a large percentage ofWiktionary inflection tables do not use the cor-rect tags to distinguish between header and contentcells, an important component of the parsing pro-cedure.
In particular, table authors frequently useonly the content cell tag to mark up all of a table?scells, and create ?soft?
headers with a distinct vi-sual appearance by changing their styling (as withCzech verbs, such as spadat ?to be included, falloff?).
This is indistinguishable to human viewers,but a na?
?ve parse mistakes the soft headers for in-flected forms with no descriptors.
Hence we in-vestigated several methods for robustly identifyingimproperly marked-up table headers and overrid-ing the HTML cell-type tags in a preprocessingstep.Visual identification.
Since most of the softheaders on Wiktionary have a distinct backgroundcolor from the rest of their containing tables, weinitially added a rule that treated content cells thatdefined a background color in HTML or inlineCSS as header cells.
However, the mere pres-ence of this attribute was not a reliable indicatorsince some tables, such as those for Latin nouns(e.g.
aqua ?water?
), gave every cell a backgroundcolor.
This caused them to be erroneously con-sidered to consist entirely of headers, resulting inmissing data.
Other tables used background colorfor highlighting, as with Faroese nouns (e.g.
vatn?water?)
and the past historic row in Figure 1,whose inflected forms were considered to be head-ers.
For these reasons, visual cues were assessedas an unreliable method of identification.Frequency-based methods.
Another, more suc-cessful strategy for header discrimination headerdiscrimination utilized the frequency characteris-tics of cell text, regardless of the cell?s type.
Al-though Wiktionary?s inflection tables have manydifferent layouts, words with the same languageand part of speech pair often share a single tem-plate with consistent descriptors.
In addition,many simple descriptors, such as singular, oc-cur frequently throughout a single edition.
Eachinflected form, however, can be expected to ap-pear on only a few pages (and in most cases justone).
We exploited this tendency by counting thenumber of pages where each distinct cell text ina Wiktionary edition appeared, and, for each lan-guage, manually determined a cutoff point abovewhich any cell with matching text was consid-ered a header.
Cells containing only punctuationwere excluded from consideration, to avoid prob-lems with dashes that occurred in many tables asa content cell indicating that no such form existed.This strategy surmounted all the problems identi-fied thus far, including both the improper taggingof headers as content cells and the overspecifica-tion of background colors.3.4 Mapping Inflected Forms to UniversalFeaturesUsing the results of the frequency-based prepro-cessing step to the table parsing algorithm, the firsttwo authors manually inspected the list of parsedcells and their frequencies within each language,and then determined both a threshold for inclusionas a header feature (descriptor) and a universalrepresentation for each header feature.
When pos-sible header features were above the threshold, butjudged not to be contentful, they were not given auniversal schema representation.All inflected forms found by our scrape of Wik-tionary were assigned complete universal repre-sentation vectors by looking up each of their Wik-tionary descriptors using the mapping described inthe above paragraph and then concatenating the re-sults.
Any conflicts within a dimension were re-solved using a positional heuristic that favored de-677scriptors nearer to the inflected form in its origi-nal HTML table, with column headings assignedhigher precedence than row headings, which hadhigher precedence to corner headings, based onan empirical assessment of positional accuracy incase of conflict.Ultimately, the process of extraction and map-ping yielded instantiated paradigms for 883,965unique lemmas across 352 languages (of which130 had more than 100 lemmas), with each in-flected form of the lemma described by a vectorof features from the universal morphological fea-ture schema.4 Seeding Morphological AnalyzersTo test the accuracy, consistency, and utility ofour Wiktionary extraction and feature mappings,the fully mapped data from the English editionof Wiktionary were used as input to Durrett andDeNero?s (2013) morphological paradigm learner.While the results were comparable to those ob-tained by the hand-tooled and language-specifictable parsers of Durrett and DeNero (2013) givenan equivalent quantity of training data, the num-ber of language and part of speech combinationswhich could be subjected to analysis using datafrom our general-purpose Wiktionary parser andmapping to features in the universal schema wasfar greater: 123 language-POS pairs (88 distinctlanguages) versus Durrett and DeNero?s 5 pairs (3languages).2In addition, when the available train-ing data were increased from 500 lemmas to thefull amount (a number that varied per language butwas always > 2000), ?2tests demonstrated thatthe gain in wordform generation accuracy was sta-tistically significant (p < 0.05) for 44% (14/32) ofthe tested language-POS pairs.
In the language-POS pairs without significant gains, wordformswere predictable using smaller amounts of data.For example, nearly half (8/18) of the language-POS pairs in this category were nouns in Romancelanguages, whose pluralization patterns typicallyinvolve simply adding /-s/ or some similar variant.Some of the language-POS pairs with significantgains contained multiple inflection classes and/ormorpheme altering processes such as vowel har-mony, umlaut, or vowel shortening.
These lin-guistic characteristics introduce complexity thatreduces the number of exemplars of any given2Language-POS pairs were considered to be suitable foranalysis if they possessed 200 or more lemmas that exhibitedthe maximal paradigm possible.10 50 100 500 3124Lemmas in training set0255075100PercentcorrectLatin verbsTemplates correctIndividual forms correct10 50 100 500 7892Lemmas in training set0255075100PercentcorrectHungarian nounsTemplates correctIndividual forms correct10 50 100 500 7236Lemmas in training set0255075100PercentcorrectFinnish verbsTemplates correctIndividual forms correct10 50 100 500 2289Lemmas in training set0255075100PercentcorrectIcelandic nounsTemplates correctIndividual forms correctFigure 2: Examples of significant improvementsin per-lemma paradigm and wordform generationaccuracy with varying amounts of training datamorpheme form, which increases the value of ad-ditional data.
Figure 2 shows the influence ofadditional training data on paradigm and word-form generation accuracy for the four languages inwhich the addition of the full amount of trainingdata provided the most significant improvement(all p < 0.001).5 ConclusionThe proposed universal morphological featureschema incorporates findings from research in lin-guistic typology to provide a cross-linguisticallyapplicable method of labeling inflectional mor-phemes according to their meaning.
The schemaoffers many potential benefits for NLP and ma-chine translation by facilitating direct meaning-to-meaning comparison and translation across lan-guage pairs.
We have also developed original, ro-bust and general multidimensional table parsingand feature mapping algorithms.
We then appliedthese algorithms and universal schema to Wik-tionary to generate a significant sharable resource,namely standardized universal feature representa-tions for inflected wordforms from 883,965 instan-tiated paradigms across 352 languages.
We haveshown that these data can be used to successfullytrain morphological analysis tools, and that the in-creased amount of data available can significantlyimprove their accuracy.678ReferencesAlexandra Y. Aikhenvald.
2004.
Evidentiality.
OxfordUniversity Press, Oxford.D.
N. Shankara Bhat.
2004.
Pronouns.
Oxford Uni-versity Press, Oxford.Balthasar Bickel and Johanna Nichols.
2005.Inclusive-exclusive as person vs. number categoriesworldwide.
In Elena Filimonova, editor, Clusivity,pages 49?72.
John Benjamins, Philadelphia.Barry J. Blake.
2001.
Case.
Cambridge UniversityPress, Cambridge, UK, 2nd edition.Heather Bliss and Elizabeth Ritter.
2001.
Developinga database of personal and demonstrative pronounparadigms: Conceptual and technical challenges.
InSteven Bird, Peter Buneman, and Mark Lieberman,editors, Proceedings of the ICRS Workshop on Lin-guistic Databases.
Institute for Research in Cogni-tive Science, Philadelphia.Penelope Brown and Stephen C. Levinson.
1987.Politeness: Some Universals in Language Usage.Studies in Interactional Sociolinguistics.
CambridgeUniversity Press, Cambridge, UK.Seth Cable.
2008.
Tense, aspect and Aktion-sart.
Unpublished handout from ?Proseminaron Semantic Theory?
for Theoretical Perspectiveson Languages of the Pacific Northwest.
Availableat: http://people.umass.edu/scable/PNWSeminar/handouts/Tense/Tense-Background.pdf, Fall.Shobhana L. Chelliah and Willem J. de Reuse.2011.
Handbook of Descriptive Linguistic Field-work.
Springer, Dordrecht, Netherlands.Jinho Choi, Marie-Catherine de Marneffe, TimDozat, Filip Ginter, Yoav Goldberg, Jan Haji?c,Christopher Manning, Ryan McDonald, JoakimNivre, Slav Petrov, Sampo Pyysalo, NataliaSilveira, Reut Tsarfaty, and Dan Zeman.2015.
Universal Dependencies.
Accessibleat: http://universaldependencies.github.io/docs/,January.Bernard Comrie, Martin Haspelmath, andBalthasar Bickel.
2008.
The LeipzigGlossing Rules: Conventions for inter-linear morpheme-by-morpheme glosses.http://www.eva.mpg.de/lingua/resources/glossing-rules.php, February.Bernard Comrie.
1976a.
Aspect: An Introduction tothe Study of Verbal Aspect and Related Problems.Cambridge University Press, Cambridge, UK.Bernard Comrie.
1976b.
Linguistic politenessaxes: Speaker-addressee, speaker-referent, speaker-bystander.
Pragmatics Microfiche, 1.7(A3).
Depart-ment of Linguistics, University of Cambridge.Bernard Comrie.
1989.
Language Universals and Lin-guistic Typology.
Basil Blackwell, Oxford, 2nd edi-tion.Greville G. Corbett.
1991.
Gender.
Cambridge Uni-versity Press, Cambridge, UK.Greville G. Corbett.
2000.
Number.
Cambridge Uni-versity Press, Cambridge, UK.William Croft.
2000.
Parts of speech as languageuniversals and as language-particular categories.
InPetra M. Vogel and Bernard Comrie, editors, Ap-proaches to the Typology of Word Classes, pages 65?102.
Mouton de Gruyter, New York.Pierluigi Cuzzolin and Christian Lehmann.
2004.Comparison and gradation.
In Geert Booij, Chris-tian Lehmann, Joachim Mugdan, and StavrosSkopeteas, editors, Morphologie.
Ein interna-tionales Handbuch zur Flexion und Wortbildung /An International Handbook on Inflection and Word-Formation, volume 2, pages 1212?1220.
Mouton deGruyter, Berlin.Katherine Demuth.
2000.
Bantu noun classes: Loan-word and acquisition evidence of semantic produc-tivity.
In G. Senft, editor, Classification Systems,pages 270?292.
Cambridge University Press, Cam-bridge, UK.Markus Dreyer and Jason Eisner.
2011.
Discover-ing morphological paradigms from plain text usinga Dirichlet process mixture model.
In Proceedingsof EMNLP 2011, pages 616?627, Edinburgh.
Asso-ciation for Computational Linguistics.Greg Durrett and John DeNero.
2013.
Supervisedlearning of complete morphological paradigms.
InProceedings of the 2013 Conference of the NorthAmerican Chapter of the Association for Compu-tational Linguistics: Human Language Technolo-gies, pages 1185?1195.
Association for Computa-tional Linguistics, Atlanta.John Goldsmith.
2001.
Unsupervised learning of themorphology of natural language.
ComputationalLinguistics, 27(2):153?198.Harald Hammarstr?om.
2006.
A naive theory of mor-phology and an algorithm for extraction.
In RichardWicentowski and Grzegorz Kondrak, editors, SIG-PHON 2006: Proceedings of the 8th Meeting ofthe ACL Special Interest Group on ComputationalPhonology, pages 79?88, New York.
Association forComputational Linguistics.Martin Haspelmath.
1995.
The converb as a cross-linguistically valid category.
In Martin Haspel-math and Ekkehard K?onig, editors, Converbs inCross-Linguistic Perspective: Structure and Mean-ing of Adverbial Verb Forms ?
Adverbial Participles,Gerunds, Empirical Approaches to Language Typol-ogy, pages 1?56.
Mouton de Gruyter, Berlin.679Martin Haspelmath.
2010.
Comparative conceptsand descriptive categories in crosslinguistic studies.Language, 86(3):663?687, September.M.
H. Klaiman.
1991.
Grammatical Voice.
Cam-bridge University Press, Cambridge, UK.Wolfgang Klein.
1994.
Time in Language.
Routledge,New York.Knud Lambrecht.
1994.
Information Structure andSentence Form: Topic, Focus and the Mental Repre-sentations of Discourse Referents.
Cambridge Uni-versity Press, Cambridge, UK.Christopher Lyons.
1999.
Definiteness.
CambridgeUniversity Press, Cambridge.Marie Mikulov?a, Alevtina B?emov?a, Jan Haji?c, EvaHaji?cov?a, Ji?r??
Havelka, Veronika Kol?a?rov?a, LucieKu?cov?a, Mark?eta Lopatkov?a, Petr Pajas, JarmilaPanevov?a, Magda Raz?
?mov?a, Petr Sgall, Jan?Step?anek, Zde?nka Ure?sov?a, Kate?rina Vesel?a, andZden?ek?Zabokrtsk?y.
2006.
Annotation on thetectogrammatical level in the Prague DependencyTreebank: Annotation manual.
Technical report,?UFAL/CKL, Prague.
Technical Report TR-2006-30.Frank R. Palmer.
2001.
Mood and Modality.
Cam-bridge University Press, Cambridge, UK, 2nd edi-tion.Nina V. Radkevich.
2010.
On Location: The Structureof Case and Adpositions.
Ph.D. thesis, University ofConnecticut, Storrs, CT.Beno?
?t Sagot and G?eraldine Walther.
2013.
Imple-menting a formal model of inflectional morphology.In Cerstin Mahlow and Michael Piotrowski, editors,Systems and Frameworks for Computational Mor-phology, pages 115?134.
Springer, Berlin.Lesley Stirling.
1993.
Switch-Reference and Dis-course Representation.
Cambridge Studies in Lin-guistics.
Cambridge University Press, Cambridge,UK.John Sylak-Glassman, Christo Kirov, Matt Post, RogerQue, and David Yarowsky.
To appear.
A uni-versal feature schema for rich morphological anno-tation and fine-grained cross-lingual part-of-speechtagging.
In Proceedings of the Fourth InternationalWorkshop on Systems and Frameworks for Compu-tational Morphology, Communications in Computerand Information Science.
Springer-Verlag, Berlin.Zeno Vendler.
1957.
Verbs and times.
The Philosoph-ical Review, 66(2):143?160, April.Mutsumi Yamamoto.
1999.
Animacy and Reference.John Benjamins, Amsterdam.Daniel Zeman.
2008.
Reusable tagset conversion us-ing tagset drivers.
In Proceedings of LREC 2008,pages 213?218.680
