Proceedings of the ACL 2010 Conference Short Papers, pages 253?257,Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational LinguisticsVocabulary Choice as an Indicator of PerspectiveBeata Beigman Klebanov, Eyal Beigman, Daniel DiermeierNorthwestern University and Washington University in St. Louisbeata,d-diermeier@northwestern.edu, beigman@wustl.eduAbstractWe establish the following characteris-tics of the task of perspective classifi-cation: (a) using term frequencies in adocument does not improve classificationachieved with absence/presence features;(b) for datasets allowing the relevant com-parisons, a small number of top features isfound to be as effective as the full featureset and indispensable for the best achievedperformance, testifying to the existenceof perspective-specific keywords.
We re-late our findings to research on word fre-quency distributions and to discourse ana-lytic studies of perspective.1 IntroductionWe address the task of perspective classification.Apart from the spatial sense not considered here,perspective can refer to an agent?s role (doctor vspatient in a dialogue), or understood as ?a par-ticular way of thinking about something, espe-cially one that is influenced by one?s beliefs orexperiences,?
stressing the manifestation of one?sbroader perspective in some specific issue, or ?thestate of one?s ideas, the facts known to one, etc.,in having a meaningful interrelationship,?
stress-ing the meaningful connectedness of one?s stancesand pronouncements on possibly different issues.1Accordingly, one can talk about, say, opinionon a particular proposed legislation on abortionwithin pro-choice or pro-life perspectives; in thiscase, perspective essentially boils down to opi-nion in a particular debate.
Holding the issue con-stant but relaxing the requirement of a debate on aspecific document, we can consider writings frompro- and con- perspective, in, for example, thedeath penalty controversy over a course of a periodof time.
Relaxing the issue specificity somewhat,1Google English Dictionary, Dictionary.comone can talk about perspectives of people on twosides of a conflict; this is not opposition or sup-port for any particular proposal, but ideas abouta highly related cluster of issues, such as Israeliand Palestinian perspectives on the conflict in allits manifestations.
Zooming out even further, onecan talk about perspectives due to certain life con-tingencies, such as being born and raised in a par-ticular culture, region, religion, or political tradi-tion, such perspectives manifesting themselves incertain patterns of discourse on a wide variety ofissues, for example, views on political issues in theMiddle East from Arab vs Western observers.In this article, we consider perspective at allthe four levels of abstraction.
We apply the sametypes of models to all, in order to discover anycommon properties of perspective classification.We contrast it with text categorization and withopinion classification by employing models rou-tinely used for such tasks.
Specifically, we con-sider models that use term frequencies as features(usually found to be superior for text categoriza-tion) and models that use term absence/presence(usually found to be superior for opinion classi-fication).
We motivate our hypothesis that pre-sence/absence features would be as good as orbetter than frequencies, and test it experimentally.Secondly, we investigate the question of featureredundancy often observed in text categorization.2 Vocabulary SelectionA line of inquiry going back at least to Zipf strivesto characterize word frequency distributions intexts and corpora; see Baayen (2001) for a sur-vey.
One of the findings in this literature is thata multinomial (called ?urn model?
by Baayen)is not a good model for word frequency distri-butions.
Among the many proposed remedies(Baayen, 2001; Jansche, 2003; Baroni and Evert,2007; Bhat and Sproat, 2009), we would like todraw attention to the following insight articulated253most clearly in Jansche (2003).
Estimation is im-proved if texts are construed as being generated bytwo processes, one choosing which words wouldappear at all in the text, and then, for words thathave been chosen to appear, how many times theywould in fact appear.
Jansche (2003) describes atwo-stage generation process: (1) Toss a z-biasedcoin; if it comes up heads, generate 0; if it comesup tails, (2) generate according to F (?
), whereF (?)
is a negative binomial distribution and z is aparameter controlling the extent of zero-inflation.The postulation of two separate processes iseffective for predicting word frequencies, but isthere any meaning to the two processes?
The firstprocess of deciding on the vocabulary, or wordtypes, for the text ?
what is its function?
Jansche(2003) suggests that the zero-inflation componenttakes care of the multitude of vocabulary wordsthat are not ?on topic?
for the given text, includingtaboo words, technical jargon, proper names.
Thisimplies that words that are chosen to appear areall ?on topic?.
Indeed, text segmentation studiesshow that tracing recurrence of words in a textpermits topical segmentation (Hearst, 1997; Hoey,1991).
Yet, if a person compares abortion to infan-ticide ?
are we content with describing this wordas being merely ?on topic,?
that is, having a certainprobability of occurrence once the topic of abor-tion comes up?
In fact, it is only likely to occurif the speaker holds a pro-life perspective, while apro-choicer would avoid this term.We therefore hypothesize that the choice of vo-cabulary is not only a matter of topic but alsoof perspective, while word recurrence has mainlyto do with the topical composition of the text.Therefore, tracing word frequencies is not going tobe effective for perspective classification beyondnoting the mere presence/absence of words, dif-ferently from the findings in text categorization,where frequency-based features usually do betterthan boolean features for sufficiently large voca-bulary sizes (McCallum and Nigam, 1998).3 DataPartial Birth Abortion (PBA) debates: We usetranscripts of the debates on Partial Birth Abor-tion Ban Act on the floors of the US House andSenate in 104-108 Congresses (1995-2003).
Simi-lar legislation was proposed multiple times, passedthe legislatures, and, after having initially been ve-toed by President Clinton, was signed into lawby President Bush in 2003.
We use data from278 legislators, with 669 speeches in all.
Wetake only one speech per speaker per year; sincemany serve multiple years, each speaker is repre-sented with 1 to 5 speeches.
We perform 10-foldcross-validation splitting by speakers, so that allspeeches by the same speaker are assigned to thesame fold and testing is always inter-speaker.When deriving the label for perspective, it is im-portant to differentiate between a particular leg-islation and a pro-choice / pro-life perspective.A pro-choice person might still support the bill:?I am pro-choice, but believe late-term abortionsare wrong.
Abortion is a very personal decisionand a woman?s right to choose whether to ter-minate a pregnancy subject to the restrictions ofRoe v. Wade must be protected.
In my judgment,however, the use of this particular procedure can-not be justified.?
(Rep. Shays, R-CT, 2003).
Toavoid inconsistency between vote and perspective,we use data from pro-choice and pro-life non-governmental organizations, NARAL and NRLC,that track legislators?
votes on abortion-relatedbills, showing the percentage of times a legislatorsupported the side the organization deems consis-tent with its perspective.
We removed 22 legisla-tors with a mixed record, that is, those who gave20-60% support to one of the positions.2Death Penalty (DP) blogs: We use Universityof Maryland Death Penalty Corpus (Greene andResnik, 2009) of 1085 texts from a number of pro-and anti-death penalty websites.
We report 4-foldcross-validation (DP-4) using the folds in Greeneand Resnik (2009), where training and testing datacome from different websites for each of the sides,as well as 10-fold cross-validation performance onthe entire corpus, irrespective of the site.3Bitter Lemons (BL): We use the GUEST partof the BitterLemons corpus (Lin et al, 2006), con-taining 296 articles published in 2001-2005 onhttp://www.bitterlemons.org by more than 200 dif-ferent Israeli and Palestinian writers on issues re-lated to the conflict.Bitter Lemons International (BL-I): We col-lected 150 documents each by a different per-2Ratings are from: http://www.OnTheIssues.org/.
We fur-ther excluded data from Rep. James Moran, D-VA, as hechanged his vote over the years.
For legislators rated by nei-ther NRLC nor NARAL, we assumed the vote aligns with theperspective.3The 10-fold setting yields almost perfect performancelikely due to site-specific features beyond perspective per se,hence we do not use this setting in subsequent experiments.254son from either Arab or Western perspectiveson Middle Eastern affairs in 2003-2009 fromhttp://www.bitterlemons-international.org/.
Thewriters and interviewees on this site are usuallyformer diplomats or government officials, aca-demics, journalists, media and political analysts.4The specific issues cover a broad spectrum, includ-ing public life, politics, wars and conflicts, educa-tion, trade relations in and between countries likeLebanon, Jordan, Iraq, Egypt, Yemen, Morocco,Saudi Arabia, as well as their relations with theUS and members of the European Union.3.1 Pre-processingWe are interested in perspective manifestationsusing common English vocabulary.
To avoid thepossibility that artifacts such as names of senatorsor states drive the classification, we use as featureswords that contain only lowercase letters, possiblyhyphenated.
No stemming is performed, and nostopwords are excluded.5Table 1: Summary of corporaData #Docs #Features # CV foldsPBA 669 9.8 K 10BL 296 10 K 10BL-I 150 9 K 10DP 1085 25 K 44 ModelsFor generative models, we use two versionsof Naive Bayes models termed multi-variateBernoulli (here, NB-BOOL) and multinomial (here,NB-COUNT), respectively, in McCallum andNigam (1998) study of event models for text cate-gorization.
The first records presence/absence of aword in a text, while the second records the num-ber of occurrences.
McCallum and Nigam (1998)found NB-COUNT to do better than NB-BOOL forsufficiently large vocabulary sizes for text catego-rization by topic.
For discriminative models, weuse linear SVM, with presence-absence, norma-lized frequency, and tfidf feature weighting.
Bothtypes of models are commonly used for text clas-sification tasks.
For example, Lin et al (2006) use4We excluded Israeli, Turkish, Iranian, Pakistani writersas not clearly representing either perspective.5We additionally removed words containing support, op-pos, sustain, overrid from the PBA data, in order not to in-flate the performance on perspective classification due to theexplicit reference to the upcoming vote.NB-COUNT and SVM-NORMF for perspective clas-sification; Pang et al (2002) consider most andYu et al (2008) all of the above for related tasksof movie review and political party classification.We use SVMlight (Joachims, 1999) for SVM andWEKA toolkit (Witten and Frank, 2005; Hall etal., 2009) for both version of Naive Bayes.
Param-eter optimization for all SVMmodels is performedusing grid search on the training data separatelyfor each partition into train and test data.65 ResultsTable 2 summarizes the cross-validation results forthe four datasets discussed above.
Notably, theSVM-BOOL model is either the best or not signif-icantly different from the best performing model,although the competitors use more detailed textualinformation, namely, the count of each word?s ap-pearance in the text, either raw (NB-COUNT), nor-malized (SVM-NORMF), or combined with docu-ment frequency (SVM-TFIDF).Table 2: Classification accuracy.
Scores sig-nificantly different from the best performance(p2t<0.05 on paired t-test) are given an asterisk.Data NB SVMBOOL COUNT BOOL NORMF TFIDFPBA *0.93 0.96 0.96 0.96 0.97DP-4 0.82 0.82 0.83 0.82 0.727DP-10 *0.88 *0.93 0.98 *0.97 *0.97BL 0.89 0.88 0.89 0.86 0.84BL-I 0.68 0.66 0.73 0.65 0.65We conclude that there is no evidence for therelevance of the frequency composition of thetext for perspective classification, for all levels ofvenue- and topic-control, from the tightest (PBAdebates) to the loosest (Western vs Arab authorson Middle Eastern affairs).
This result is a clearindication that perspective classification is quitedifferent from text categorization by topic, wherecount-based features usually perform better thanboolean features.
On the other hand, we have not6Parameter c controlling the trade-off between errorson training data and margin is optimized for all datasets,with the grid c = {10?6, 10?5, .
.
.
, 105}.
On the DPdata parameter j controlling penalties for misclassificationof positive and negative cases is optimized as well (j ={10?2, 10?1, .
.
.
, 102}), since datasets are unbalanced (forexample, there is a fold with 27%-73% split).7Here SVM-TFIDF is doing somewhat better than SVM-BOOL on one of the folds and much worse on two other folds;paired t-test with just 4 pairs of observations does not detecta significant difference.255observed that boolean features are reliably betterthan count-based features, as reported for the sen-timent classification task in the movie review do-main (Pang et al, 2002).We note the low performance on BL-I, whichcould testify to a low degree of lexical consolida-tion in the Arab vs Western perspectives (more onthis below).
It is also possible that the small size ofBL-I leads to overfitting and low accuracies.
How-ever, PBA subset with only 151 items (only 2002and 2003 speeches) is still 96% classifiable, so sizealone does not explain low BL-I performance.6 Consolidation of perspectiveWe explore feature redundancy in perspectiveclassification.We first investigate retention of onlyN best features, then elimination thereof.
As aproxy of feature quality, we use the weight as-signed to the feature by the SVM-BOOL modelbased on the training data.
Thus, to get the per-formance with N best features, we take the N2highest and lowest weight features, for the posi-tive and negative classes, respectively, and retrainSVM-BOOL with these features only.8Table 3: Consolidation of perspective.
Nbestshows the smallest N and its proportion out ofall features for which the performance of SVM-BOOL with only the best N features is not sig-nificantly inferior (p1t>0.1) to that of the fullfeature set.
No-Nbest shows the largest num-ber N for which a model without N best fea-tures is not significantly inferior to the full model.N={50, 100, 150, .
.
.
, 1000}; for DP and BL-I, ad-ditionally N={1050, 1100, ..., 1500}; for PBA, ad-ditionally N={10, 20, 30, 40}.Data Nbest No-NbestN % N %PBA 250 2.6% 10 <1%BL 500 4.9% 100 <1%DP 100 <1% 1250 5.2%BL-I 200 2.2% 950 11%We observe that it is generally sufficient to usea small percentage of the available words to ob-tain the same classification accuracy as with thefull feature set, even in high-accuracy cases suchas PBA and BL.
The effectiveness of a smallsubset of features is consistent with the observa-tion in the discourse analysis studies that rivals8We experimented with the mutual information based fea-ture selection as well, with generally worse results.in long-lasting controversies tend to consolidatetheir vocabulary and signal their perspective withcertain stigma words and banner words, that is,specific keywords used by a discourse commu-nity to implicate adversaries and to create sym-pathy with own perspective, respectively (Teubert,2001).
Thus, in abortion debates, using infanti-cide as a synonym for abortion is a pro-life stigma.Note that this does not mean the rest of the fea-tures are not informative for classification, onlythat they are redundant with respect to a small per-centage of top weight features.When N best features are eliminated, perfor-mance goes down significantly with even smallerN for PBA and BL datasets.
Thus, top featuresare not only effective, they are also crucial for ac-curate classification, as their discrimination capa-city is not replicated by any of the other vocabu-lary words.
This finding is consistent with Linand Hauptmann (2006) study of perspective vstopic classification: While topical differences be-tween two corpora are manifested in difference indistributions of great many words, they observedlittle perspective-based variation in distributionsof most words, apart from certain words that arepreferentially used by adherents of one or the otherperspective on the given topic.For DP and BL-I datasets, the results seemto suggest perspectives with more diffused key-word distribution (No-NBest figures are higher).We note, however, that feature redundancy exper-iments are confounded in these cases by either alow power of the paired t-test with only 4 pairs(DP) or by a high variance in performance amongthe 10 folds (BL-I), both of which lead to nume-rically large discrepancy in performance that is notdeemed significant, making it easy to ?match?
thefull set performance with small-N best features aswell as without large-N best features.
Better com-parisons are needed in order to verify the hypo-thesis of low consolidation.In future work, we plan to experiment with ad-ditional features.
For example, Greene and Resnik(2009) reported higher classification accuraciesfor the DP-4 data using syntactic frames in whicha selected group of words appeared, rather thanmere presence/absence of the words.
Another di-rection is exploring words as members of seman-tic fields ?
while word use might be insufficientlyconsistent within a perspective, selection of a se-mantic domain might show better consistency.256ReferencesHerald Baayen.
2001.
Word frequency distributions.Dordrecht: Kluwer.Marco Baroni and Stefan Evert.
2007.
Wordsand Echoes: Assessing and Mitigating the Non-Randomness Problem in Word Frequency Distribu-tion Modeling.
In Proceedings of the ACL, pages904?911, Prague, Czech Republic.Suma Bhat and Richard Sproat.
2009.
Knowing theUnseen: Estimating Vocabulary Size over UnseenSamples.
In Proceedings of the ACL, pages 109?117, Suntec, Singapore, August.Stephan Greene and Philip Resnik.
2009.
Morethan Words: Syntactic Packaging and Implicit Sen-timent.
In Proceedings of HLT-NAACL, pages 503?511, Boulder, CO, June.Mark Hall, Eibe Frank, Geoffrey Holmes, BernhardPfahringe, Peter Reutemann, and Ian H. Witten.2009.
The WEKA data mining software: An up-date.
SIGKDD Explorations, 11(1).Marti Hearst.
1997.
TextTiling: Segmenting Text intoMulti-Paragraph Subtopic Passages.
ComputationalLinguistics, 23(1):33?64.Michael Hoey.
1991.
Patterns of Lexis in Text.
OxfordUniversity Press.Martin Jansche.
2003.
Parametric Models of Linguis-tic Count Data.
In Proceedings of the ACL, pages288?295, Sapporo, Japan, July.Thorsten Joachims.
1999.
Making large-scale SVMlearning practical.
In B. Schlkopf, C. Burges, andA.
Smola, editors, Advances in Kernel Methods -Support Vector Learning.
MIT Press.Wei-Hao Lin and Alexander Hauptmann.
2006.
Arethese documents written from different perspec-tives?
A test of different perspectives based on sta-tistical distribution divergence.
In Proceedings ofthe ACL, pages 1057?1064, Morristown, NJ, USA.Wei-Hao Lin, Theresa Wilson, Janyce Wiebe, andAlexander Hauptmann.
2006.
Which side are youon?
Identifying perspectives at the document andsentence levels.
In Proceedings of CoNLL, pages109?116, Morristown, NJ, USA.Andrew McCallum and Kamal Nigam.
1998.
A com-parison of event models for Naive Bayes text clas-sification.
In Proceedings of AAAI-98 Workshopon Learning for Text Categorization, pages 41?48,Madison, WI, July.Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.2002.
Thumbs up?
Sentiment Classification usingMachine Learning Techniques.
In Proceedings ofEMNLP, Philadelphia, PA, July.Wolfgang Teubert.
2001.
A Province of a FederalSuperstate, Ruled by an Unelected Bureaucracy ?Keywords of the Euro-Sceptic Discourse in Britain.In Andreas Musolff, Colin Good, Petra Points, andRuth Wittlinger, editors, Attitudes towards Europe:Language in the unification process, pages 45?86.Ashgate Publishing Ltd, Hants, England.Ian H. Witten and Eibe Frank.
2005.
Data Mining:Practical Machine Learning Tools and Techniques.Morgan Kaufmann, 2 edition.Bei Yu, Stefan Kaufmann, and Daniel Diermeier.2008.
Classifying party affiliation from politicalspeech.
Journal of Information Technology and Pol-itics, 5(1):33?48.257
