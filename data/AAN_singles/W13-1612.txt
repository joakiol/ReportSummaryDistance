Proceedings of the 4th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 87?93,Atlanta, Georgia, 14 June 2013. c?2013 Association for Computational LinguisticsBilingual Experiments on an Opinion Comparable CorpusE.
Mart?
?nez-Ca?maraSINAI research groupUniversity of Jae?nE-23071, Jae?n (Spain)emcamara@ujaen.esM.
T.
Mart?
?n-ValdiviaSINAI research groupUniversity of Jae?nE-23071, Jae?n (Spain)maite@ujaen.esM.
D. Molina-Gonza?lezSINAI research groupUniversity of Jae?nE-23071, Jae?n (Spain)mdmolina@ujaen.esL.
A. Uren?a-Lo?pezSINAI research groupUniversity of Jae?nE-23071, Jae?n (Spain)laurena@ujaen.esAbstractUp until now most of the methods publishedfor polarity classification are applied to En-glish texts.
However, other languages on theInternet are becoming increasingly important.This paper presents a set of experiments onEnglish and Spanish product reviews.
Us-ing a comparable corpus, a supervised methodand two unsupervised methods have been as-sessed.
Furthermore, a list of Spanish opinionwords is presented as a valuable resource.1 IntroductionOpinion Mining (OM) is defined as the computa-tional treatment of opinion, sentiment, and subjec-tivity in text.
The OM discipline combines NaturalLanguage Processing (NLP) with data mining tech-niques and includes a large number of tasks (Pangand Lee, 2008).
One of the most studied tasksis polarity classification of reviews.
This task fo-cuses on determining which is the overall sentiment-orientation (positive or negative) of the opinionscontained within a given document.Two main appraoches are followed by researchesto tackle the OM task.
On the one hand, the Ma-chine Learning (ML) approach (also known as thesupervised approach) is based on using a collectionof data to train the classifiers (Pang et al 2002).
Onthe other hand, (Turney, 2002) proposed an unsuper-vised method based on the semantic orientation ofthe words and phrases in the reviews.
Both method-ologies have their advantages and drawbacks.
Forexample, the ML approach depends on the avail-ability of labelled data sets (training data), whichin many cases are impossible or difficult to achieve,partially due to the novelty of the task.
On thecontrary, the unsupervised method requires a largeamount of linguistic resources which generally de-pend on the language, and often this approach ob-tains lower recall because it depends on the presenceof the words comprising the lexicon in the documentin order to determine the polarity of opinion.Although opinions and comments on the Inter-net are expressed in any language, most of researchin OM is focused on English texts.
However, lan-guages such as Chinese, Spanish or Arabic, are evermore present on the web.
Thus, it is important todevelop resources for these languages.
The workpresented herein is mainly motivated by the needto develop polarity classification systems and re-sources in languages other than English.
We presentan experimental study over the SFU Review Corpus(Taboada, 2008), a comparable corpus that includesopinions of several topics in English and in Span-ish.
We have followed this line of work: Firstly,we have taken as baseline a supervised experimentusing Support Vector Machine (SVM).
Then wehave tried different unsupervised strategies.
The firstone uses the method presented in (Montejo-Ra?ez etal., 2012).
This approach combines SentiWordNetscores with a random walk analysis of the conceptsfound in the text over the WordNet graph in order todetermine the polarity of a tweet.
This method ob-tained very good results in short texts (tweets) andso, we want to try it using larger document.
Al-though we have carried out several experiments us-ing different parameters and modifications, the re-sults are not as good as we hoped.
For this, we have87tried a very simple experiment using a list of opin-ionated words in order to classify the polarity of thereviews.
For English we have used the Bin Liu En-glish lexicon (BLEL) (Hu and Liu, 2004) and forSpanish we have automatically translated the BLELlexicon into Spanish.
In addition, we have alsochecked manually and improved the Spanish list.The paper is organized as follows: Section 2briefly describes papers that study non-English sen-timent polarity classification and, specifically workrelated to Spanish OM.
In Section 3 we explainthe resources used in the unsupervised methods as-sessed.
Section 4 presents the experiments carriedout and discusses the main results obtained.
Finally,we outline conclusions and further work.2 Related WorkThere are some interesting papers that have stud-ied the problem using non-English collections.
De-necke (2008) worked on German comments col-lected from Amazon.
These reviews were translatedinto English using standard machine translation soft-ware.
Then the translated reviews were classified aspositive or negative, using three different classifiers:LingPipe7, SentiWordNet (Baccianella et al 2010)with classification rule, and SentiWordNet with ma-chine learning.
Ghorbel and Jacot (2011) used a cor-pus with movie reviews in French.
They applied asupervised classification combined with SentiWord-Net in order to determine the polarity of the reviews.In (Rushdi-Saleh et al 2011a) a corpus of moviesreviews in Arabic annotated with polarity was pre-sented and several supervised experiments were per-formed.
Subsequently, they generated the parallelEVOCA corpus (English version of OCA) by trans-lating the OCA corpus automatically into English.The results showed that they are comparable to otherEnglish experiments, since the loss of precision dueto the translation process is very slight, as can beseen in (Rushdi-Saleh et al 2011b).Regarding Spanish, there are also some interest-ing studies.
Banea et al(2008) showed that au-tomatic translation is a viable alternative for theconstruction of resources and tools for subjectivityanalysis in a new target language.
In (Brooke etal., 2009) several experiments are presented deal-ing with Spanish and English resources.
They con-clude that although the ML techniques can providea good baseline performance, it is necessary to inte-grate language-specific knowledge and resources inorder to achieve an improvement.
Cruz et al(2008)manually recollected the MuchoCine (MC) corpusto develop a sentiment polarity classifier based onthe semantic orientation of the phrases and words.The corpus contains annotated Spanish movie re-views from the MuchoCine website.
The MC cor-pus was also used in (Mart?
?nez-Ca?mara et al 2011)to carry out several experiments with a supervisedapproach applying different ML algorithms.
Finally,(Mart?
?n-Valdivia et al 2012) also dealt with the MCcorpus to present an experimental study of super-vised and unsupervised approaches over a Spanish-English parallel corpus.3 Resources for the unsupervised methodsIn order to tackle the unsupervised experiments wehave chosen several well-known resources in theOM research community.
In addition, we have alsogenerated a new Spanish linguistic resource.Comparable corpora are those consisted of textsin two or more languages about the same topic, butthey are not the translated version of the texts in thesource language.
For the experiments, we chose thecomparable corpus SFU Review Corpus.
The SFUReview Corpus is composed of reviews of prod-ucts in English and Spanish.
The English version(Taboada and Grieve, 2004) has 400 reviews (200positive and 200 negative) of commercial productsdownloaded in 2004 from the Epinions web whichare divided into eight categories: books, cars, com-puters, cookware, hotels, movies, music and phones.Each category includes 25 positive reviews and 25negative reviews.
Recently, the authors of SFU Re-view Corpus have made available the Spanish ver-sion of the corpus1.
The Spanish reviews are dividedinto the same eight categories, and also each cate-gory has 25 positive and 25 negative reviews.In the unsupervised experiments we have anal-ysed the performance of two approaches, the firstone is based on lexicon and the other one in a graph-based method.
We have selected the BLEL lexicon(Hu and Liu, 2004) to carry out the experiment based1http://www.sfu.ca/?mtaboada/download/downloadCorpusSpa.html88on lexicon on the English version of the corpus.
Thelexicon is composed by 6,787 opinion words thatindicate positive or negative opinions, which 2,005are positive and 4,782 are negative.
With the aim offollowing the same approach over the Spanish ver-sion, firstly we have translated the BLEL lexiconwith the Reverso machine translator, and them wehave checked manually the resultant list.
The Span-ish Opinion Lexicon2 (SOL) is composed by 2,509positive and 5,627 negative words, thus in total SOLhas 8,136 opinion words.
If a review has more orthe same positive words than negative the polarity ispositive, otherwise negative.The graph-based method is a modular systemwhich is made up of different components andtechnologies.
The method was first presented in(Montejo-Ra?ez et al 2012) with a good perfor-mance over a corpus of English tweets.
The mainidea of the algorithm is to represent each review as avector of polarity scores of the senses in the text andsenses related to the context of the first ones.
Be-sides, the polarity score is weighted with a measureof importance.
Taking a review as input, the work-flow of the algorithm is the following:1.
Disambiguation: To get the correspondingsense of the words that are in the text is requiredto disambiguate them.
Thus, the output of thisfirst step is one unique synset from WordNet3(Miller, 1995) for each term.
The input of thealgorithm is the set of words with a POS-Tagallowed in WordNet.
The graph nature of theWordNet structure is the basis for the UKB dis-ambiguation method proposed by (Agirre andSoroa, 2009).
The UKB disambiguation algo-rithm apply PageRank (Page et al 1999) onthe WordNet graph starting from term nodes,where each term node points to all its possiblesenses or synsets.
The output of the process is aranked list of synsets for each input word, andthe highest rank synset is chosen as candidatesense.For the Spanish disambiguation process wehave chosen the Spanish WordNet versionoffered by the project Multilingual Central2http://sinai.ujaen.es/wiki/index.php/SOL3We have used the 3.0 release of WordNet.Repository (MCR) (Gonzalez-Agirre et al2012).
The Spanish WordNet of MCR has38,702 synsets while WordNet has 117,659, i.e.the MCR covers the 32.89% of WordNet.2.
PPV: Once the synsets for the reviews are com-puted, the following step performs a second runof PageRank described in (Agirre and Soroa,2009).
Using the Personalized PageRank, aset of Personalized PageRank Vectors (PPVs)is obtained.
This vector is a list of synsets withtheir ranked values.
The key of this approachis to take from this vector additional synsetsnot related directly to the set of synsets disam-biguated in the first step.
The result is a longerlist of pair <synset, weight> where the weightis the rank value obtained by the propagation ofthe weights of original synsets across theWord-Net graph.3.
Polarity: The following step is to calculate thepolarity score.
For this purpose it is necessary asemantic resource to take the polarity score foreach retrieved synset in the two previous steps.The semantic resource selected is SentiWord-Net (Baccianella et al 2010).
According tothese values, the three following equations havebeen applied to obtain the final polarity value:p(r) = 1|r|?s?r1|s|?i?s(p+i ?
p?i )wi (1)p(r) = 1|r|?s?r1|s|?i?sf(pi)f(pi) ={p+i if p+i > p?ip?i if p+i <= p?i(2)p(r) = 1|r|?s?r1|s|?i?sf(pi)f(pi) =??????
?1 if i ?
[positive words]?1 if i ?
[negative words]p+i if p+i > p?ip?i if p+i <= p?i(3)where p(r) is the polarity of the review; |r| isthe number of sentences in the review r; s is asentence in r, being itself a set of synsets; i is asynset in s; p+i is the positive polarity of synseti; p?i is the negative polarity of synset i and wiis the weight of synset i.894 Experiments and ResultsSystems based on supervised approach are the mostsuccessfully in the OM literature.
Therefore, we be-gan the set of experiments applying a machine learn-ing algorithm to the SFU corpus.
Also, we have car-ried out a set of unsupervised experiments followinga lexicon-based approach and a graph-based algo-rithm.
For all the experiments the evaluation mea-sures have been: precision, recall, F1 and Accuracy(Acc.).
The validation approach followed for thesupervised approach has been the well-known 10-cross-validation.The algorithm chose for the supervised experi-ments is SVM (Cortes and Vapnik, 1995) becauseis one of the most successfully used in OM.
Lib-SVM4 (Chang and Lin, 2011) was the implementa-tion selected to carry out several experiments usingSVM.
We have evaluated unigrams and bigrams asminimum unit of information.
Also, the influence ofstemmer have been assessed.
The weight scheme forrepresenting each unit of information is TF-IDF.
Thesame configuration has been applied to English andSpanish version of SFU corpus.
Table 1 and Table2 show the results for English version and Spanishversion respectively.Precision Recall F1 Acc.Unigrams 79.07% 78.50% 78.78% 78.50%Unigrams& stemmer 79.82% 79.50% 79.66% 79.50%Bigrams 78.77% 78.25% 78.51% 78.25%Bigrams& stemmer 80.64% 80.25% 80.44% 80.25%Table 1: SVM results for English SFU corpusPrecision Recall F1 Acc.Unigrams 73.65% 73.25% 73.45% 73.25%Unigrams& stemmer 74.10% 73.75% 73.92% 73.75%Bigrams 74.02% 73.50% 73.76% 73.50%Bigrams& stemmer 73.90% 73.50% 73.70% 73.50%Table 2: SVM results for Spanish SFU corpusThe results show one of the differences betweenthe works published in SA, the use of unigrams or4http://www.csie.ntu.edu.tw/?cjlin/libsvm/bigrams.
In (Pang et al 2002) is asserted that thereviews should be represented with unigrams, butin (Dave et al 2003) bigrams and trigrams outper-formed the unigrams features.
In our case, regardingthe results reached without using a stemmer, the useof unigrams as minium unit of information achievesbetter result than the use of bigrams when the lan-guage is English, but bigrams outperform unigramswhen the texts are in Spanish.
On the other hand, thebest result both in English and Spanish is reachedwhen a stemmer algorithm is applied.
So, one con-clusion of the supervised experiments is that the useof stemmer enhances the polarity classification in re-views.
The following conclusion is that in Englishthe presence of pair of words separate better the pos-itive and negative classes, while in Spanish the useof unigrams is enough to classify the polarity whena stemmer algorithm is used.The set of unsupervised experiments begins witha lexicon-based method.
The method consists of findthe presence in the reviews of opinion words whichare included in a lexicon of opinion words.
BLELhas been used for the English reviews, and SOL forthe Spanish reviews.
The results are presented inTable 3.Precision Recall F1 Acc.BLEL lexicon 69.56% 64.42% 66.89% 64.75%SOL 66.91% 61.94% 64.33% 62.25%Table 3: Lexicon-based approch resultsThe differences in the results between the En-glish and Spanish version of SFU Review Corpusare lower when a lexicon is used instead of a ma-chine learning algorithm is applied.
In a lexicon-based method is very important the recall value, be-cause it indicates whether the set of words coversthe vocabulary of the corpus.
The recall value isupper 60% regarding English and Spanish, althoughis not an excellent value, is good for the two smalland independent-domain lexicons.
In the case ofSpanish the supervised method is only 15.59% bet-ter regarding Accuracy.
The results show that maybe considered the use of a lexicon-based method forSpanish due to the few computer resources needed.Moreover, it must be highlighted the performance ofSOL, so it is the first time that this resource is usedto resolve a polarity classification problem.90The graph-based method has been described as amodular and flexible algorithm.
Due to its modularnature we have carried out several experiments:1. wnet ant+ eq1 [en|es]: As baseline, we haverun the algorithm with the same configurationas is described in (Montejo-Ra?ez et al 2012),i.e.
using the equation 1.2. wnet ant- eq1 [en|es]: We have assessed thealgorithm with a version of WordNet withoutthe antonym relation.3.
wnet ant+ eq2 [en|es]: The equation to calcu-late the polarity is 24. wnet ant- eq2 [en|es]: The same aswnet ant+ eq2 [en|es] but the antonymrelation is not considered.5.
wnet ant+ eq3 [en|es]: The same aswnet ant+ eq2 [en|es] but the equation 3is used to calculate the polarity.6.
wnet ant- eq3 [en|es]: The same aswnet ant+ eq3 [en|es] but the antonymrelation is not considered.Furthermore, one of the key elements of the al-gorithm is the possibility of setting the number ofrelated synsets to get from WordNet.
In all of the ex-periments we have evaluated from an expansion of 0sysnsets to 100 synsets.
In Table 4 are the best re-sults obtained with the English and the Spanish ver-sion of SFU corpus.Regarding the results, only for English is evidentthat the selection of the right equation to calculatethe polarity score is important.
On the other hand,the initial assumption that the relation of antonymcould complicate the calculation of the final polarity,and the use of a graph of WordNet without antonymcould enhance the results cannot be demonstratedbecause these experiments have reached the sameresults as the obtained ones using the graph withthe relation of antonym.
The equation 3, which in-cludes additional information (in this case the BLELlexicon) to calculate the final polarity score, out-performs the original way to get the polarity score(equation 1).
The equation 3 for the English versionof the corpus reaches 5.84% and 8.4% better resultsthan equation 1 regarding F1 and Accuracy respec-tively.The results obtained with the Spanish reviews area bit different.
In this case, the results are alwaysimproved when the antonym relation is not takinginto account.
So the first conclusion is the relationof antonym is not convenient for the calculation ofthe polarity value on Spanish texts.
The process ofexpansion with related senses has not been relevantfor the final results on the English reviews, but whenthe language of the reviews is Spanish the expan-sion is more decisive.
For the wnet ant- eq3 es ex-periment the best result has been reached consider-ing 71 related senses, so we can conclude that forSpanish the context should be considered.
Althoughthe best results is obtained with the configurationwnet ant+ eq3 es, it must be highlighted the pre-cision value of 68.03% reached by the configura-tion wnet ant+ eq2 es.
In some OM experiments ismore important the precision of the system than therecall or other evaluation measures, so for Spanishreviews should be taken account this configurationtoo.Regarding English and Spanish results, Table 4shows similar performance, i.e.
the graph-based al-gorithm obtained better results when the antonym isnot considered and the use of a lexicon of opinionwords enhances considerably the results.The supervised approach clearly outperforms thetwo unsupervised approaches.
The results obtainedby the two unsupervised approaches are closer.
Thelexicon based method has a better performance onEnglish reviews regarding the four different eval-uation measures considered.
Thus, the lexiconmethod not only has better results but also it is sim-pler, faster and more efficient than the graph-basedmethod.
Nevertheless, the graph-based method onSpanish reviews outperforms in precision regard-ing the configuration wnet ant+ eq2 es and in theother three measures take into account the configu-ration wnet ant+ eq3 es.
However, the graph-basedmethod is only 1.64% better regarding the precisionvalue, and 0.54% better regarding F1.
Therefore, wealso considered the lexicon-based approach as themore suitable approach than the graph-based one.91Expansion Precision Recall F1 Accuracywnet ant+ eq1 en 2 66.86% 57.25% 61.68% 57.25%wnet ant- eq1 en 2 66.86% 57.25% 61.68% 57.25%wnet ant+ eq2 en 0 65.27% 55.5% 59.99% 55.50%wnet ant- eq2 en 0 65.27% 55.5% 59.99% 55.50%wnet ant+ eq3 en 3 68.83% 62.50% 65.51% 62.50%wnet ant- eq3 en 3 68.83% 62.50% 65.51% 62.50%wnet ant+ eq1 es 0 65.42% 54.5% 59.46% 54.5%wnet ant- eq1 es 19 64.39% 57.75% 60.89% 57.75%wnet ant+ eq2 es 0 68.03% 52.75% 59.42% 52.75%wnet ant- eq2 es 70 64.62% 58.00% 61.13% 58.00%wnet ant+ eq3 es 71 65.91% 63.50% 64.68% 63.05%wnet ant- eq3 es 71 65.91% 63.50% 64.68% 63.05%Table 4: Results of the graph-based algorithm5 Conclusion and future workIn this work, we have presented a set of experimentswith a comparable corpora in English and Spanish.As it is usual, the supervised experiment has outper-forms the unsupervised ones.
The unsupervised ex-periments have included the evaluation of two differ-ent approaches: lexicon-based and graph-based.
Inthe lexicon-based approach we have presented a newresource for the Spanish OM research community,being an important contribution of this paper.
Theresults reached with SOL are very closed to the onesobtained with graph-based methods.
Although, forshort texts the graph-based method performed well,for the kind of reviews used in these experiments isnot as good.
Due to the fact that for English theBLEL lexicon has reached better results, for Span-ish the results of SOL are nearly the same ones ob-tained by the graph method, and the use of a lexiconis more efficient, we conclude that the lexicon-basedmethod is most suitable.Currently we are improving the SOL lexicon, andalso we are adding domain information to the wordsin SOL.
Furthermore, one of our main objectives isthe treatment of the negation because we consideredthat is essential for OM.AcknowledgmentsThis work has been partially supported by a grantfrom the Fondo Europeo de Desarrollo Regional(FEDER), TEXT-COOL 2.0 project (TIN2009-13391-C04-02) and ATTOS project (TIN2012-38536-C03-0) from the Spanish Government.
Also,this paper is partially funded by the EuropeanCommission under the Seventh (FP7 - 2007-2013)Framework Programme for Research and Techno-logical Development through the FIRST project(FP7-287607).
This publication reflects the viewsonly of the authors, and the Commission cannot beheld responsible for any use which may be made ofthe information contained therein.ReferencesEneko Agirre and Aitor Soroa.
2009.
Personalizingpagerank for word sense disambiguation.
In Proceed-ings of the 12th Conference of the European Chap-ter of the Association for Computational Linguistics,EACL ?09, pages 33?41, Stroudsburg, PA, USA.
As-sociation for Computational Linguistics.Stefano Baccianella, Andrea Esuli, and Fabrizio Se-bastiani.
2010.
Sentiwordnet 3.0: An enhancedlexical resource for sentiment analysis and opinionmining.
In Nicoletta Calzolari (Conference Chair),Khalid Choukri, Bente Maegaard, Joseph Mariani,Jan Odijk, Stelios Piperidis, Mike Rosner, and DanielTapias, editors, Proceedings of the Seventh Interna-tional Conference on Language Resources and Evalu-ation (LREC?10), Valletta, Malta, may.
European Lan-guage Resources Association (ELRA).Carmen Banea, Rada Mihalcea, Janyce Wiebe, andSamer Hassan.
2008.
Multilingual subjectivityanalysis using machine translation.
In Proceedingsof the Conference on Empirical Methods in NaturalLanguage Processing, EMNLP ?08, pages 127?135,Stroudsburg, PA, USA.
Association for ComputationalLinguistics.Julian Brooke, Milan Tofiloski, and Maite Taboada.2009.
Cross-linguistic sentiment analysis: From en-glish to spanish.
In Proceedings of the InternationalConference RANLP-2009, pages 50?54, Borovets,92Bulgaria, September.
Association for ComputationalLinguistics.Chih-Chung Chang and Chih-Jen Lin.
2011.
Libsvm:A library for support vector machines.
ACM Trans.Intell.
Syst.
Technol., 2(3):27:1?27:27, May.Corinna Cortes and Vladimir Vapnik.
1995.
Support-vector networks.
Machine Learning, 20:273?297.Ferm?
?n L. Cruz, Jose A. Troyano, Fernando Enriquez,and Javier Ortega.
2008.
Clasificacio?n de documen-tos basada en la opinio?n: experimentos con un cor-pus de cr?
?ticas de cine en espan?ol.
Procesamiento delLenguaje Natural, 41:73?80.Kushal Dave, Steve Lawrence, and David M. Pennock.2003.
Mining the peanut gallery: opinion extractionand semantic classification of product reviews.
In Pro-ceedings of the 12th international conference on WorldWide Web, WWW ?03, pages 519?528, New York, NY,USA.
ACM.Kerstin Denecke.
2008.
Using sentiwordnet for multilin-gual sentiment analysis.
In Data Engineering Work-shop, 2008.
ICDEW 2008.
IEEE 24th InternationalConference on, pages 507?512.
IEEE.Hatem Ghorbel and David Jacot.
2011.
Sentiment anal-ysis of french movie reviews.
Advances in DistributedAgent-Based Retrieval Tools, pages 97?108.Aitor Gonzalez-Agirre, Egoitz Laparra, and GermanRigau.
2012.
Multilingual central repository version3.0.
In Nicoletta Calzolari (Conference Chair), KhalidChoukri, Thierry Declerck, Mehmet Ug?ur Dog?an,Bente Maegaard, Joseph Mariani, Jan Odijk, and Ste-lios Piperidis, editors, Proceedings of the Eight In-ternational Conference on Language Resources andEvaluation (LREC?12), Istanbul, Turkey, may.
Euro-pean Language Resources Association (ELRA).Minqing Hu and Bing Liu.
2004.
Mining and summa-rizing customer reviews.
In Proceedings of the tenthACM SIGKDD international conference on Knowl-edge discovery and data mining, KDD ?04, pages 168?177, New York, NY, USA.
ACM.Eugenio Mart?
?nez-Ca?mara, M. Teresa Mart?
?n-Valdivia,and L. Alfonso Uren?a Lo?pez.
2011.
Opinion clas-sification techniques applied to a spanish corpus.
InProceedings of the 16th international conference onNatural language processing and information sys-tems, NLDB?11, pages 169?176, Berlin, Heidelberg.Springer-Verlag.M.
Teresa Mart?
?n-Valdivia, Eugenio Mart?
?nez-Ca?mara,Jose M. Perea-Ortega, and L. Alfonso Uren?a Lo?pez.2012.
Sentiment polarity detection in spanish reviewscombining supervised and unsupervised approaches.Expert Systems with Applications.
In press.George A. Miller.
1995.
Wordnet: a lexical database forenglish.
Communications of the ACM, 38(11):39?41.Arturo Montejo-Ra?ez, Eugenio Mart??nez-Ca?mara,M.
Teresa Mart?
?n-Valdivia, and L. Alfonso Uren?aLo?pez.
2012.
Random walk weighting over senti-wordnet for sentiment polarity detection on twitter.
InProceedings of the 3rd Workshop in ComputationalApproaches to Subjectivity and Sentiment Analy-sis, pages 3?10, Jeju, Korea, July.
Association forComputational Linguistics.Lawrence Page, Sergey Brin, Rajeev Motwani, and TerryWinograd.
1999.
The pagerank citation ranking:Bringing order to the web.
Technical Report 1999-66, Stanford InfoLab, November.
Previous number =SIDL-WP-1999-0120.Bo Pang and Lillian Lee.
2008.
Opinion mining andsentiment analysis.
Found.
Trends Inf.
Retr., 2(1-2):1?135, January.Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.2002.
Thumbs up?
: Sentiment classification usingmachine learning techniques.
In Proceedings of theACL-02 conference on Empirical methods in naturallanguage processing - Volume 10, EMNLP ?02, pages79?86, Stroudsburg, PA, USA.
Association for Com-putational Linguistics.Mohammed Rushdi-Saleh, M. Teresa Mart??n-Valdivia,L.
Alfonso Uren?a Lo?pez, and Jose?
M. Perea-Ortega.2011a.
OCA: Opinion corpus for Arabic.
Journalof the American Society for Information Science andTechnology, 62(10):2045?2054, October.Mohammed Rushdi-Saleh, Maria Teresa Martn-Valdivia,Luis Alfonso Urea-Lpez, and Jos M. Perea-Ortega.2011b.
Bilingual Experiments with an Arabic-EnglishCorpus for Opinion Mining.
In Galia Angelova,Kalina Bontcheva, Ruslan Mitkov, and Nicolas Ni-colov, editors, RANLP, pages 740?745.
RANLP 2011Organising Committee.Maite Taboada and Jack Grieve.
2004.
Analyzing ap-praisal automatically.
In Proceedings of AAAI SpringSymposium on Exploring Attitude and Affect in Text(AAAI Technical Re# port SS# 04# 07), Stanford Uni-versity, CA, pp.
158q161.
AAAI Press.Maite Taboada.
2008.
Sfu review corpus.
http://www.sfu.ca/?mtaboada/research/SFU_Review_Corpus.html.Peter D. Turney.
2002.
Thumbs up or thumbs down?
:semantic orientation applied to unsupervised classifi-cation of reviews.
In Proceedings of the 40th AnnualMeeting on Association for Computational Linguis-tics, ACL ?02, pages 417?424, Stroudsburg, PA, USA.Association for Computational Linguistics.93
