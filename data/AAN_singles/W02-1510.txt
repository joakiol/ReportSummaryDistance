A Development Environment for Large-scale Multi-lingual Parsing SystemsHisami SuzukiMicrosoft ResearchOne Microsoft WayRedmond WA 98052 USAhisamis@microsoft.comAbstractWe describe the development environmentavailable to linguistic developers in our labin writing large-scale grammars formultiple languages.
The environmentconsists of the tools that assist writinglinguistic rules and running regressiontesting against large corpora, both of whichare indispensable for realistic developmentof large-scale parsing systems.
We alsoemphasize the importance of parserefficiency as an integral part of efficientparser development.
The tools and methodsdescribed in this paper are actively used inthe daily development of broad-coveragenatural language understanding systems inseven languages (Chinese, English, French,German, Japanese, Korean and Spanish).1 IntroductionThe goal of the grammar development at MicrosoftResearch is to build robust, broad-coverageanalysis and generation systems for multiplelanguages.
The runtime system is referred to asNLPWin, which provides the grammardevelopment environment described in this paper.The graphical user interface of NLPWin is shownin Figure A in the Appendix.
The system is modularin that the linguistic code is separate fromnon-linguistic code.
All languages share the sameparsing engine, which is a bottom-up chart parserand is fully Unicode-enabled.
Linguistic code itselfis also modular, in that it can be specific to aparticular language (e.g., syntax rules) or can belargely shared across languages (e.g., semanticmapping rules).
Linguistic rules are written in aproprietary language called G; a sample syntax rulewritten in G is given in Figure B in the Appendix.G-rules are translated into C, yet they are moreconvenient for a linguist to use than C, as it givesspecial notational support to attribute-value datastructures used within the system.
The rule and datastructure formalisms are shared by all languages;for details, see Jensen et al (1993) and Heidorn(2000).In this paper, we describe the tools andmethods for the cross-linguistic development ofanalysis components of our system, which consistsof three major modules: (i) the tokenizationcomponent, which performs word segmentation (inthe case of Chinese and Japanese) andmorphological analysis; (ii) the parsing component,which performs phrase-structure analysis andcreates parse tree(s)1; (iii) the Logical Form (LF)component, which computes the basicpredicate-argument structure from parse tree(s)2.
Inthis paper, we focus on the tools and the methodsfor the development of parsing and LF components,which are essentially the same3.For an efficient development of a computationalgrammar of these modules, we find it necessary tohave a development environment that can provideimmediate feedback to the grammar-writer of thechanges he or she has made.
We have three types oftools in our system to meet these requirements:y Tools for linguistic rule writing: these includethe tools that let linguists navigate through thefinal and intermediate parse trees, and tracerule application (Section 2).y Tools for grammar testing: these tools allowlinguists to compare results of two versions of1This component is further divided into the Sketchcomponent, which produces trees with defaultattachment of constituents, and the Portrait component,which finds the best attachment sites (Heidorn, 2000).2LF is computed from a surface syntax tree via a level ofrepresentation called Language-Neutral Syntax (LNS),which serves as an interface to various semanticrepresentations including predicate-argument structure.For a more detailed description of LNS, see Campbelland Suzuki (2002).3Similar tools and methods are also available for thedevelopment of sentence realization component.grammar, and update the database of desiredoutput structures (called regression suites,Section 3).y A very fast processing environment (Section4).These tools are described in the following threesections of this paper.
Section 5 gives a summaryand suggests directions for future research.2 Tools for linguistic rule writingIn this section we present the tools available for thedevelopment of the parsing component.
The outputstructure of parsing is graphically represented as aphrase-structure tree, as in Figure 1 above.
Variousfunctionalities are available to navigate through thistree as well as intermediate (or failed)representations, by simple operations such asdouble-clicking the node in the user interface, or bytyping in commands in the Command window,which can be invoked by the Command menu in theuser interface (see Figure A).
Below is a selectedset of examples of tree navigation functionalitieswhich are essential to the fast development oflinguistic rules:Figure 1: A parse treeFigure 2: Lexical record for VERB1 ?discusses?
Figure 3: A derivational treeAccessible recordsAt any point, a linguist can access the recordsunderlying the parse tree by double-clicking thenode.
The record for a node is comprised of lexicaland morphological information, syntactic andfunctional features and attributes, as well aspointers to the sub-constituents and parent of thenode.
For example, double-clicking on the VERB1node in Figure 1 will display the record structure inFigure 2.Derivational treeWe can also display the history of rule applicationin graphical form, as in Figure 3.
Any node in thehistory tree (called the derivational tree) can alsobe double-clicked in order to access the recordunderlying it.Apply Rule and Rule ExplainRule Explain shows the application of the ruleunderlying the formation of a node in the tree.
Therule application is displayed using a color-codeddisplay to highlight successful conditions (green),failed conditions (red) and the actions performed onthe resulting record (purple) on the rules such as theone displayed in Figure B.
The display is availablefor both successful and failed rule applications: wecan access the Rule Explain display bydouble-clicking the resulting node, or we canmanually apply any rule to any constituent to bringup Rule Explain.CompareParsed trees can be quite large and it may bedifficult to determine exactly where two trees differfrom each other.
In such a case, trees and nodes canbe easily compared to detect subtle differences incomposition or rule history by the Comparefunction.Display treesThis command is particularly useful in checking theedges of possible, intermediate constituents.
Itdisplays all the partial trees with a certain label thatincludes a particular node or spans over specifiednodes.
The following are some examples ofpossible variations in the query:(a)  display trees VP 1 5(b)  display trees NP NOUN4(c)  display trees AJP(a) displays all VPs that span from position 1 to 5;(b) displays all NPs that include the node NOUN4;and (c) displays all possible subtrees whosenodetype (label) is AJP.Tree filtersThis functionality does not directly assist thegrammarian in writing rules, yet is extremely usefulin collecting and examining particular linguisticconstructions of interest that are output by theparser.
The linguistic developer can writecustom-made tree filters in G, which traverses theparse trees or LF structures and exports only theinformation needed for a particular purpose, or onlythose sentences with particular linguisticconfigurations.
Tree filters are also convenient increating a linguistic annotation for externalapplications.The tools described in this section enable linguiststo inspect the effect of grammar changes in detail,with the information of how exactly a particularrule applied or failed.
These tools are used in thecontext of daily grammar development, which wedescribe in the next section.3 Process of grammar development3.1 Incremental grammar testing andcreation of regression suitesThe standard practice of parser development withinour group is schematically shown in Figure 4.
Thegrammarian for each language processes a text filewith input sentences and adds only the sentenceswith desired parses to what we call a master file,which contains the sentences and their targetstructure.
A collection of master files is called aregression suite.
A regression suite thus containsthe target structures given a particular version ofthe grammar.
When new grammar changes aremade in order to accommodate a new sentence orconstruction, the linguist runs the new grammaragainst the regression suite (called regressiontesting) to examine the consequences of thechanges to the grammar.
When differences arefound, they are kept in *.dff files and are displayedin two colors, highlighting the differences.
Figure Cin the Appendix is an example display of adifference (unfortunately in black and white): thehighlights in green (here the first three lines)correspond to the analysis in the master file, whilethose in red (the next three lines) indicate the newanalysis introduced by the new grammar rules.
Thelines that did not change are grayed out.
If thechange is an improvement, the developer canchoose to update the master file by double-clickingon the sentence number (in purple), adding thesentence or construction that is newlyaccommodated by the parser to the regression suite.If the change is evaluated as negative, the linguisticdeveloper reworks the rules that caused theregression.3.2 Testing against relative standardsAs is described above, we run regression testsagainst the machine-created master files rather thanagainst an independent set of hand-annotated targetcorpora.
The test is therefore incremental andrelative, in that new sentences and their targetstructures are constantly added as the grammardevelops, and what it measures is not the coverageagainst an absolute standard, but the coverageimprovements relative to the output of an oldversion of the grammar.The incremental and relative testing method hasproven to facilitate the development of abroad-coverage parsing system in some importantrespects.
First, it ensures that the desired structuresin the master files are always current.
Because themaster files are constantly incremented and updatedusing the most recent version of the grammar, theywill never become obsolete should the targetstructures change.
The ease of maintenance of theregression suite is one of the key featurescontributing to the usefulness of the regressionsuite in our daily development work.Secondly, because the master files are createdautomatically rather than by hand, the resultantannotation is guaranteed to be consistent.
Creatinga test corpus for parser evaluation by hand is knownto be an extremely laborious, inconsistency-pronetask, especially when the tagging is performed onreal-life data 4 .
In addition, a broad-coveragegrammar must also work with input strings that arenot necessarily well-formed, including sentencefragments, ungrammatical sentences and extremecolloquialisms.
Hand-annotating these structuresmay either be impossible or extremely error-prone.In contrast, by annotating them automaticallyusing the output of the parser, these structures canbe added to our regression suite easily andconsistently.
Effects of later grammar changes caneasily be detected by running the regression testingas part of the regular development process.Finally, incremental and relative testing makesthe parser development data-driven rather thanbeing dictated by a theory.
This is an importantfeature for a large-scale system.
Though it iseventually up to the grammarian to accept or rejecta particular analysis, the system always provides acandidate analysis for any input string, whichfacilitates the rapid creation of the master files.
Italso allows linguistic developers to experiment onthe grammar code in the following sense: assumethat there is a sentence or a construction that allowsmultiple linguistically valid analyses, and that thereis no obvious reason to prefer one to the other, asituation that arises often in the development of abroad-coverage grammar.
In this case, thegrammarian can temporarily choose one of thestructures as a target, and add it to the regressionsuite.
If the target structure the grammarian hasselected is inconsistent with the rest of the grammar,it will constantly come back as a regression(difference) when further changes to the other partsof the grammar are made, because the assumptionimplicit in the tentative target structure is notconsistent with the rest of the grammar.
Once thechange is made to the target structure that isconsistent with the remainder of the grammar, ittypically stops appearing as a difference inregression tests.
The data-driven nature ofdevelopment therefore helps the grammarians toproceed with grammar development even whenthere is indeterminacy in the target structure.Regular regression testing over large corpora4One piece of evidence for this statement is that thebracketing guidelines for Penn Treebank project (Bies etal.
1995) consist of over 300 pages of documentation forannotating relatively homogeneous text.Figure 4.
Flow diagram of daily grammardevelopmentensures that any outlandish analyses have only ashort life span in our regression suites.Possible disadvantages of testing against arelative standard include: (i) it is difficult get a feelfor how mature the grammar is in general; (ii) itmakes the comparison across different systemsdifficult.
The first problem is addressed partially byrunning evaluation testing against blind benchmarkcorpora, which consists of sentences never used inthe grammar development.
The parser coverage isautomatically measured in terms of the number ofsentences that received at least one spanning parse,versus those that failed to receive any spanninganalysis.Testing and comparing parser performanceacross different systems is an extremely difficulttask, given different aims and grammaticalfoundations.
One possibility, which is currentlypursued in our group, is to develop a metric thatenables comparison with manually created goldenstandards, as they have become more widelyavailable for various languages, such as the PennTreebank for Chinese and English, NEGRA corpusfor German, and Kyoto Corpus for Japanese.Ultimately, the parser output must be comparedand evaluated at the level of an application that usesthe result of linguistic analysis.
Campbell et al(2002) is an attempt to use machine translation as atest bed for a multi-lingual parsing system.4 Parser efficiency as part of efficientparser developmentFor a development of a truly broad-coverage parser,it is critical that grammar changes are constantlyverified against a very large set of sentences, andthat the time for feedback is minimal.
Theefficiency of the parsing engine is thus inseparablefrom efficient grammar development.Our parsing engine is already quite fast: forexample, our English system currently parsesSection 21 of Penn Wall Street Journal (WSJ)Treebank (1,671 sentences) in 110 seconds (orabout 15 sentences/sec) on a standard machine(993MHz Pentium III with 512MB RAM); thisperformance is comparable across languages.Speed improvements are usually performed bynon-linguistic developers following standardoptimization techniques.
We use internal profilingtools to identify performance bottlenecks, andmake a special effort to ensure that the G-to-Ctranslator generates efficient C-code.
Because thelinguistic code is independent of the non-linguisticcode of the system, the parsers for any language canimmediately benefit from performanceimprovements made at the system level.For regression testing, we also have a means todistribute the processing onto multiple CPUs: theprocessing cluster currently consists of 19machines with 2 CPUs each (500MHz,128~512MB RAM), which parses the entire WSJsection of Penn Treebank (49,208 sentences) in 3minutes and 10 seconds (or 259 sentences/sec), anda one million-sentence Nikkei newspaper corpus ofJapanese in about 30 minutes (550+ sentences/sec).In daily grammar development, each grammariantypically works with a regression suite consisting of10,000 to 30,000 sentences at various levels ofanalyses; the time required for processing aregression suite is 2 to 6 minutes.
In addition,automatic regression testing is run nightly againstrelevant regression suites using the most recentbuilds of the system, ensuring that no negativeimpact is made by any changes introduced duringthe day5.In this section, we have discussed the issue ofparser efficiency from the perspective of grammardevelopment.
Our processing environment enablesimmediate feedback to grammar changes over verylarge corpora, and is thus an essential part of thedevelopment environment for a broad-coverageparser.5 ConclusionIn this paper we have described the tools andmethods for a development of large-scale parsingsystems.
We have argued that constant testing ofthe grammar against a large regression suite is thecentral part of the daily grammar development, andthat the tools and methods described in this paperare indispensable for maximizing the productivityof linguistic developers.
Though the tools arespecific to NLPWin, we believe that the generalpractice of grammar development presented in thispaper is of interest to anyone engaged in grammardevelopment under any grammar formalism.As a cross-linguistic development environmentfor analysis and generation components, some of5We use standard version control software to manageboth linguistic and non-linguistic source code.the properties of NLPWin discussed in this paperare shared with such projects as ParGram (Butt etal., 1999).
One of the main differences betweenParGram and NLPWin is that the latter has so farbeen developed and used at one site.
As there aremore parsers available in many languages, it wouldbe interesting to see if externally developedcomponents can be plugged into NLPWin at thelevel of LNS.
Such research is left for the future asa possible extension to the modularity andcross-linguistic aspect of NLPWin.AcknowledgementsThis paper presents the work that has been designedand implemented by many people in the NLPGroup at Microsoft Research, particularly GeorgeHeidorn and Karen Jensen.ReferencesBies, Ann, Mark Ferguson, Karen Katz, and RobertMacIntyre, 1995.
Bracketing Guidelines forTreebank II Style.
Penn Treebank Project,University of Pennsylvania.Butt, Miriam, Tracy Holloway King,Maria-Eugenia Ni?o and Fr?d?rique Segond.1999.
A Grammar Writer's Cookbook.
CSLIPublications, Stanford.Campbell, Richard, and Hisami Suzuki.
2002.Language-Neutral Representation of SyntacticStructure.
In Proceedings of SCANALU 2002.Campbell, Richard, Carmen Lozano, JessiePinkham and Martine Smets.
2002.
MachineTranslation as a Test Bed for MultilingualAnalysis.
In Proceedings of the Workshop onGrammar Engineering and Evaluation, COLING2002, Taipei.Heidorn, George.
2000.
Intelligent WritingAssistance.
In Robert Dale, Hermann Moisl andHarold Somers (eds.
), A Handbook of NaturalLanguage Processing: Techniques andApplications for the Processing of Language asText.
Marcel Dekker, New York.
Chapter 8.Jensen, Karen, George E. Heidorn and Stephen D.Richardson (eds.).
1993.
Natural LanguageProcessing: The PLNLP Approach.
KluwerAcademic Publishers, Dordorecht.AppendixFigure A: Graphical user interface of NLPWinFigure B: Example of a phrase-structure rule6AVPwAVPl:AVP#1 (^Comma & ^Conjt & ^NoAdv & ^Top & Nodetype(Head)^="IJ" &(Nodetype ^in?
set{AVPNP AVPVP} | Compr | Intens | Tme | Ntimes) &(Advrz -> (^Adv(Lex) & Intens)) &(ModalAdvs -> Intens) &(Nconj -> (^Conj(Lex) & Lemma^in?
set{})) )AVP#2 (^AVPcoord & ^Conjt & ^Kakari & ^Nconj & ^NoAdv & ^Wh &Nodetype^in?
set{AVPNP AVPVP} & Nodetype(Head)^="IJ" &^tokntest("ADV", Ft(AVP#1), Lt, []) &^tokntest(-1, Ft(AVP#1), Lt(first(Factrecs)), []) &(Compr(AVP#1) -> (Advrz | Quant)) &(Demo(AVP#1) -> ^J_state_zyoo) &(Intens -> Intens(AVP#1)) &(Tme -> (Quant | P_every_mai)) &(Tme(AVP#1) -> (Intens(AVP#1) | Compr(AVP#1))) &Lem^="hoka" &Lemma^in?
set{} )--> AVP { %%AVP#2; Temp=segrec{%%AVP#1; -Quant;if (Quant) Nodetype="QUANP";if (Comp & ^Wa5(AVP#2)) -Mim; };Prmods=Temp++Prmods; Degree=Degree(AVP); -Temp;if (Compr(AVP#1) | (Lem(AVP)=="mou" & Quant)) +Comp;}Figure C: Example of the difference display with master file6This rule, taken from the NLPWin Japanese grammar, is read as "AVP with AVP to the left", which takes twoadjacent nodes, whose categories are both AVP (adverbial phrase), and creates a new node that spans both of the inputnodes, also labeled as AVP, whose head is the second AVP of the left-hand side of the rule (indicated by %%AVP#2in the right-hand side of the rule).
A rule can be as small as this one, or can be very large (up to hundreds of lines ofcode).
Each language in NLPWin has about 100 to 150 phrase-structure rules, in 10 to 20 files that arelanguage-specific.
LF rules are also written in G and have a similar format, but the files are shared by all languages, asare most rules, to ensure the output of the LF component is consistent across languages.
