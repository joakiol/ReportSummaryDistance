Acquisit ion of a Lexicon from Semantic Representations ofSentences*Cynthia A. ThompsonDepar tment  of Computer  SciencesUnivers i ty  of Texas2.124 Taylor  HallAust in,  TX  78712c thomp@cs.utexas .eduAbst ractA system, WOLFIE, that acquires a map-ping of words to their semantic representa-tion is presented and a preliminary evalua-tion is performed.
Tree least general gener-alizations (TLGGs) of the representationsof input sentences are performed to assistin determining the representations of indi-vidual words in the sentences.
The bestguess for a meaning of a word is the TLGGwhich overlaps with the highest percentageof sentence representations in which thatword appears.
Some promising experimen-tal results on a non-artificial data set arepresented.1 In t roduct ionComputer language learning is an area of much po-tential and recent research.
One goal is to learn tomap surface sentences to a deeper semantic mean-ing.
In the long term, we would like to communi-cate with computers as easily as we do with peo-ple.
Learning word meanings is an important stepin this direction.
Some other approaches to the lexi-cal acquisition problem depend on knowledge of syn-tax to assist in lexical earning (Berwick and Pilato,1987).
Also, most of these have not demonstratedthe ability to tie in to the rest of a language learningsystem (Hastings and Lytinen, 1994; Kazman, 1990;Siskind, 1994).
Finally, unnatural data is sometimesneeded (Siskind, 1994).We present a lexicM acquisition system that learnsa mapping of words to their semantic representa-tion, and which overcomes the above problems.
Oursystem, WOLFIE (WOrd Learning From InterpretedExamples), learns this mapping from training ex-amples consisting of sentences paired with their se-mantic representation.
The representation used hereis based on Conceptual Dependency (CD) (Schank,1975).
The results of our system can be used to*This research was supported by the National ScienceFoundation under grant IRI-9310819assist a larger language acquisition system; in par-ticular, we use the results as part of the input toCHILL (Zelle and Mooney, 1993).
CHILL learns toparse sentences into case-role representations by an-Myzing a sample of sentence/case-role pairings.
Byextending the representation f each word to a CDrepresentation, the problem faced by CHILL is mademore difficult.
Our hypothesis is that the outputfrom WOLFIE can ease the difficulty.In the long run, a system such as WOLFIE couldbe used to help learn to process natural anguagequeries and translate them into a database querylanguage.
Also, WOLFIE could possibly assist intranslation from one natural anguage to another.2 P rob lem Def in i t ion  and  A lgor i thm2.1 The Lexical Learning Prob lemGiven: A set of sentences, S paired with represen-tations, R.Find: A pairing of a subset of the words, W in Swith representations of those words.Some sentences can have multiple representationsbecause of ambiguity, both at the word and sentencelevel.
The representations for a word are formedfrom subsets of the representations of input sen-tences in which that word occurred.
This assumesthat a representation for some or all of the wordsin a sentence is contained in the representation forthat sentence.
This may not be true with all formsof sentence representation, but is a reasonable as-sumption.Tree least general generalizations (TLGGs) plusstatistics are used together to solve the problem.We make no assumption that each word has a singlemeaning (i.e., homonymy is allowed), or that eachmeaning is associated with one word only (i.e., syn-onymy is allowed).
Also, some words in S may nothave a meaning associated with them.2.2 Background:  Tree Least Genera lGeneral izat ionsThe input to a TLGG is two trees, and the outputsreturned are common subtrees of the two input trees.335Our trees have labels on their arcs; thus a tree withroot p, one child c, and an arc label to that child1 is denoted \ [p , l : c \ ] .
TLGGs are related to theLGGs of (Plotkin, 1970).
Summarizing that work,the LGG of two clauses is the least general clausethat subsumes both clauses.
For example, given thetrees\[ate, agt : \[person, sex: male, age : adult\],pat : \[food, type : cheese\] \]and \[hit, inst : \[inst ,type :ball\],pat : \[person, sex : male, age : child\] \]the TLGGs are \[person,sex:male\] and \[male\].Notice that the result is not unique, since the al-gorithm searches all subtrees to find commonalities.2.3 A lgor i thm Descr ip t ionOur approach to the lexical learning problem usesTLGGs to assist in finding the most likely mean-ing representation for a word.
First, a table, Tis built from the training input.
Each word, Win S is entered into T, along with the representa-tions, R of the sentences W appeared in.
We callthis the representation set, WR.
If a word occurstwice in the same sentence, the representation ofthat sentence is entered twice into Wn.
Next, foreach word, several TLGGs of pairs from WR are per-formed and entered into T. These TLGGs are thepossible meaning representations for a word.
Forexample, \[person, sex :male, age : adul t \ ]  is a pos-sible meaning representation for man.
More than oneof these TLGGs could be the correct meaning, if theword has multiple meanings in R. Also, the wordmay have no associated meaning representation iR.
"The" plays such a role in our data set.Next, the main loop is entered, and greedy hillclimbing on the best TLGG for a word is performed.A TLGG is a good candidate for a word meaning if itis part of the representation f a large percentage ofsentences in which the word appears.
The best word-TLGG pair in T, denoted (w, t) is the one with thehighest percentage of this overlap.
At each iteration,the first step is to find and add to the output thisbest (w,t) pair.
Note that t can also be part ofthe representation f a large percentage of sentencesin which another word appears, since we can havesynonyms in our input.Second, one copy of each sentence representationthat has t somewhere in it is removed from w's entryin T. The reason for this is that the meaning of w forthose sentences has been learned, and we can gain nomore information from those sentences.
If t occursn times in one of these sentence representations, thesentence representation is removed n times, since weadd one copy of the representation to wR for eachoccurrence of w in a sentence.Finally, for each word E T, if word and w appearin one or more sentences together, the sentence rep-resentations in word's entry that correspond to suchsentences are modified by eliminating the portionof the sentence representation that matches t, thusshortening that sentence representation for the nextiteration.
This prevents us from mistakenly choos-ing the same meaning for two different words in thesame sentence.
This elimination might not alwayssucceed since w can have multiple meanings, and itmight be used in a different way than that indicatedby t in the sentence with both w and word in it.
Butif it does succeed the TLGG list for wordis modifiedor recomputed as needed, so as to still accurately re-flect the (now modified) sentence representations forword.
Loop iteration continues until all W E T haveno associated representations.2.4 ExampleLet us illustrate the workings of WOLFIE with anexample.
Consider the following input:1.
The boy hit the window.\[prop el, agt: \[person, sex :m ale, age :child\],pat: \[obj ,type: window\]\]2.
The hammer hit the window.\[propel,inst: \[obj ,type :hammer\],pat:\[obj,type:window\]\]3.
The hammer moved.\[ptrans,pat: \[obj ,type :hammer\]\]4.
The boy ate the pasta with the cheese.\[ingest, agt: \[p erson,sex:m ale, age :child\],pat: \[food, type: past a, accomp: \[food ,type :cheese\]\]\]5.
The boy ate the pasta with the fork.\[ingest,agt:\[person,sex:male,age:child\],pat: \[food ,type :pasta\] ,inst: \[inst , ype :fork\]\]A portion of the initial T follows.
The TLGGsfor boy are \[ingest, agt:\[person, sex:male, age:child\],pat:\[food, type:pasta\]l, \[person, sex:male, age:child\],\[male\], [child\], \[food, type:pasta\], \[food\], and \[pasta\].The TLGGs for pasta  are the same as for boy.The TLGGs for hammer are \[obj, type:hammer\] and\[hammer\].In the first iteration, all the above wordshave a TLGG which covers 100% of the sen-tence representations.
For clarity, let us choose\ [person ,  sex  : ma le ,  age : ch i ld \ ]  as the meaning forboy.
Since each sentence representation for boy hasthis TLGG in it, we remove all of them, and boy's en-try will be empty.
Next, since boy and pasta  appearin some sentences together, we modify the sentencerepresentations for pasta.
They are now as follows:\[ingest,pat:\[food,type:pasta,accomp:\[food,type:cheese\]\]\] and \[ingest,pat:\[food,type:pasta\],inst:\[inst,type:fork\]\].
We also have to modify the TLGGs,resulting in the list: \[ingest,pat:\[food,type:pasta\]\],\[food,type:pasta\], \[food\], and \[pasta\].
Since all ofthese have 100% coverage in this example set, any ofthem could be chosen as the meaning representationfor pasta.
Again, for clarity, we choose the correctone, and the final meaning representations for theseexamples would be: (boy, \ [person ,  sex  : ma le ,336age:ch i ld \ ]  ) , (pasta ,  \ [ food , type  :pasta\]  ) ,(hammer, \ [ob j , type  :hammer\] ) ,  (a te ,  \ [ ingest \ ]  ) ,( fo rk ,  \ [ ins t , type : fo rk \ ] ) ,  (cheese,  \ [ food,type : cheese\]  ), and (window, \ [obj ,  type :window\]).
As noted above, in this example, thereare some alternatives for the meanings for pasta,and also for window and cheese.
In a larger exam-ple, some of these ambiguities would be eliminated,but those remaining are an area for future research.3 Exper imenta l  Eva luat ionOur hypothesis is that useful meaning representa-tions can be learned by WOLFIE.
One way to testthis is by examining the results by hand.
Anotherway to test this is to use the results to assist a largerlearning system.The corpus used is based on that of (McClellandand Kawamoto, 1986).
That corpus is a set of 1475sentence/case-structure pairs, produced from a set of19 sentence templates.
We modified only the case-structure portion of these pairs.
There is still thebasic case-structure presentation, but instead of asingle word for each filler, there is a semantic repre-sentation, as in the previous ection.The system is implemented in prolog.
We chosea random set of training examples, starting with50 examples, and incrementing by 100 for each ofthree trials.
To measure the success of the sys-tem, the percentage of correct word meanings ob-tained was measured.
This climbed to 94% correctafter 450 examples, then went down to around 83%thereafter, with training going up to 650 examples.In one case, in going from 350 to 450 training ex-amples, the number of word-meaning pairs learnedwent down by ten while the accuracy went up by31%.
This happened, in part, because the incor-rect pair (broke,  \ [ ins t \ ] )  was hypothesized earlyin the loop with 350 examples, causing many of theinstruments to have an incomplete representation,such as (hatchet ,  \ [hatchet \ ]  ), instead of the cor-rect (hatchet ,  \ [ ins t , type :hatchet \ ]  ).
This er-ror was not made in cases where a higher percentof the correct word meanings were learned.
It is anarea for future research to discover why this error isbeing made in some cases but not in others.We have only preliminary results on the task ofusing WOLFIE to assist CHILL.
Those results in-dicate that CHILL, without WOLFIE's help cannotlearn to parse sentences into the deeper semanticrepresentation, but that with 450 examples, assistedby WOLFIE, it can learn parse up to 55% correct ona testing set.4 Future  WorkThis research is still in its early stages.
Many ex-tensions and further tests would be useful.
More ex-tensive testing with CHILL is needed, including usinglarger training sets to improve the results.
We wouldalso like to get results on a larger, real world dataset.
Currently, there is no interaction between lex-ical and syntactic/parsing acquisition, which couldbe an area for exploration.
For example, just learn-ing (a te ,  \ [ ingest \ ]  ) does not tell us about the caseroles of ate  (i.e., agent and optional patient), butthis information would help CHILL with its learningprocess.
Many acquisition processes are more incre-mental than our system.
This is also an area of cur-rent research.
In the longer term, there are problemssuch as adding the ability to: acquire one definitionfor multiple morphological forms of a word; workwith an already existing lexicon, to revise mistakesand add new entries; map a multi-word phrase toone meaning; and many more.
Finally, we have nottested the system on noisy input.5 Conc lus ionIn conclusion, we have described a new system forlexical acquisition.
We use a novel approach to learnsemantic representations for words.
Though in itsearly stages, this approach shows promise for manyfuture applications, including assisting another sys-tem in learning to understand entire sentences.Re ferencesBerwick, Robert C., and Pilato, S. (1987).
Learningsyntax by automata induction.
Machine Learning,2(1):9-38.Hastings, Peter, and Lytinen, Steven (1994).
The upsand downs of lexical acquisition.
In Proceedings of theTwelfth National Conference on Artificial Intelligence,754-759.Kazman, Rick (1990).
Babel: A psychologically plausi-ble cross-linguistic model of lexical and syntactic ac-quisition.
In Proceedings of the Eighth InternationalWorkshop on Machine Learning, 75-79.
Evanston, IL.McClelland, James L., and Kawamoto, A. H. (1986).Mechanisms of sentence processing: Assigning rolesto constituents of sentences.
In Rumelhart, D. E.,and McClelland, J. L., editors, Parallel DistributedProcessing, Vol.
II, 318-362.
Cambridge, MA: MITPress.Plotkin, Gordon D. (1970).
A note on inductive gener-alization.
In Meltzer, B., and Michie, D., editors, Ma-chine Intelligence (Vol.
5).
New York: Elsevier North-Holland.Schank, Roger C. (1975).
Conceptual Information Pro-cessing.
Oxford: North-Holland.Siskind, Jeffrey M. (1994).
Lexical acquisition in thepresence of noise and homonymy.
In Proceedings of theTwelfth National Conference on Artificial Intelligence,760-766.Zelle, John M., and Mooney, Raymond J.
(1993).
Learn-ing semantic grammars with constructive inductivelogic programming.
In Proceedings of the Eleventh Na-tional Conference on Artificial Intelligence, 817-822.Washington, D.C.337
