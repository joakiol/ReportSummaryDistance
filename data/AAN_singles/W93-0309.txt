Extraction of V-N-Col locations from Text Corpora:A Feasibility Study for GermanElisabeth Breidt"Seminar fiir SprachwissenschaftUniversity of TiibingenKleine Wilhelmstr.
113, D-72074 Tiibingenbreidt~arbuckle.sns.neuphilologie.uni-tuebingen.deAbst rac tThe usefulness of a statistical approach suggested by Church and Hanks(1989) is evaluated for the extraction of verb-noun (V-N) collocations from Ger-man text corpora.
Some motivations for the extraction of V-N collocations fromcorpora are given and a couple of differences concerning the German languageare mentioned that have implications on the applicability of extraction methodsdeveloped for English.
We present precision and recall results for V-N collo-cations with support verbs and discuss the consequences for further work onthe extraction of collocations from German corpora.
Depending on the goal tobe achieved, emphasis can be put on a high recall for lexicographic purposesor on high precision for automatic lexical acquisition, in each case leading toa decrease of the corresponding other variable.
Low recall can still be accept-able if very large corpora (i.e.
50 - 100 miUion words) are available or if corporaare used for special domains in addition to the data found in machine readable(collocation) dictionaries.1 IntroductionCollocations present an area that is important both for lexicography to improve theircoverage in modern dictionaries as well as for lexical acquisition in computationallinguistics, where the goal is to build either large reusable lexical databases (LDBs) orspecific lexica for specialized NLP-applications.
We have tested the statistical approachMutual Information (MI), brought up by Church and Hanks (1989) for linguistics, fora (semi- )automatic extraction of verb-noun (V-N) collocations from untagged Germantext corpora.
We try to answer the question how much can be done with an untaggedcorpus and what might be gained by lemmatizing, POS-tagging or even superficialparsing.Choueka (1988) describes how to automatical ly extract word combinations fromEnglish corpora as a preselection of collocation candidates to ease a lexicographer'ssearch for collocations.
He only uses quantitative selection criteria, no statistical ones,his main extraction criterion being frequency with a lower threshold of at least oneoccurrence of the collocation in one million words.
He mentions plans to define a"My thanks go to the ldS that made the two corpora available for research purposes, to AngelikaStorrer for her steady encouragement and many fruitful discussions, and to Mats Ftooth and MatthiasHeyn who introduced me to the corpora tools.
1 am also greatful to the anonymous reviewers for theirhelpful comments and constructive criticism.74"binding degree' on how strong tile words of a collocation attract each other, whichwould be similar in spirit to what is calculated with MI.
The work described in Smadjaand McKeown (1990) and Smadja (1991a.b) is along the same lines as ours, though heuses a different statistical calculation, a z-score, and tagged, lemmatized corpora.
Someproperties pecific to German, however, lead to a type of problem that needs differenttreatment (section a.a).
Calzolari, Bindi {1990) use MI to extract compounds, fixedexpressions and collocations fl'om an Italian corpus, but to our knowledge have notevaluated their results so far.2 Domain of Investigation2.1 What  Do We Mean by 'Co l locat ion '?Collocations in the sense of 'frequently cooccurring words' can quite easily be extractedfrom corpora by statistic means.
From a linguistic point of view, however, a more re-stricted use of the term is preferable which takes into account he difference betweenwhat Sinclair (1966) called casual vs. signiticant collocations.
Casual word combina-tions show a normal, free syntagmatic behaviour.
In this paper, collocations hall referonly to word combinations that have a certain affinity to each other in that they followcombinatory restrictions not explainable with syntactic and semantic principles (e.g.hammer a nail into sth.
rather than "beat a nail into sth.
).For collocations that are based on a verb and a noun (preferably an object argument,sometimes however the subject of an intransitive verb), three types of V-N combina-tions are distinguished for German in the literature: verbal phrasemes (idioms) (e.g.Brundage et al 1992), support verb constructions (SVCs) (v.Polenz 1989 or Danlos1992) and collocations in the narrower sense (Hausmann 1989).
As Brundage et al(1992:7) and Barkema (1989:24) point out, the differences between these three typesare gradual and "it is hard to find criteria of good selectivity to distinguish collocationsfrom phrasemes".
Although our main interest lies in SVCs we will in the following notdistinguish between i) SVCs (e.g.
to take into consideration), ii) lexicalized combina-tions with support verbs where the noun has lost its original meaning and which belongto phrasemes (e.g.
to take a \[ancy), and iii) collocational combinations of support verbswith concrete or non-predicative nouns (e.g.
to ta/,'e a seat); we will refer to all thesecases as V-N collocations.2.2 Why V-N Col locat ions?Collocations are well suited for statistical corpora studies.
The semantics of a colloca-tion in the narrower sense according to Fleischer (1982:63f) is "given by the individualsemantics of its components, its meaning differs however in an unpredictable way fromthe pure sum of its parts.
A substantial cause for this unpredictable difference is thefrequency of occurrence and the probability with which the occurrence of one compo-nent determines the occurrence of the other" (our translation).
The unpredictabilityof a collocation is thus partly caused by the high cooccurrence frequency of its com-ponents compared to the relative frequency of the single words.
This holds even more75for SVCs and phrasemes due to  their (parlly) non-compositional semantics.In German, common nouns, proper names and abbreviations of names starl withan uppercase letter (sentence beginnings are changed to lowercase in the corpus).
Sothe verb-noun pattern was chosen for our sludv instead of possible others, because theuppercase makes it possible to extract V-N collocations even from untagged corporaif the verb is used as the key-word.
The results of extracting V-N collocations givegood indications how promising the retrieval of collocations would be with POS-taggedcorpora.
Besides, N-N combinations in German are mainly restricted to proper names,and Adj-N collocations are not as extensive in our corpus due to the small number offrequent and interesting adjectives.3 Resources and Methods Used in the StudyTwo untagged corpora were used for our study', kindly supplied by the 'Institut f/Jrdeutsche Sprache' (IdS), Mannheim: the 2.7 million words 'Mannheimer Korpus I'(MK1) which contains approx.
73% fiction and scientific/philosophical literature andabout 27% newspaper texts, and the 'Bonner Zeitungskorpus' (BZK), a 3.7 millionwords newspaper corpus.
Except for the test how results could differ for larger corporadescribed in section 4.5, where the MK1 was combined with the BZK, the investigationwas based on the MK1 on its own, for technical reasons and also because verbs occurmore often on average in the MK1 than in the BZK (cf.
Breidt 1993).3.1 Stat is t ica l  Method  and ToolsMI is a function well suited for the statistical characterization f collocations becauseit compares the joint probability p(wl,w2) that two words occur together within apredefined istance with the independent probabilities p(wI) and p(u,~) that the twowords occur at all in the corpus (for a more detailed description see Church et al(1991:120) or Breidt (1993:18)): p(2-..v)MI(x, y) = log 2 p(x)p(y)Several methods are possible for the calculation of probabilities (cf.
Gale and Church1990); for our purposes we use the simplest one.
where the frequency of occurrencein the corpus is divided by the size N of the corpus, p(z) = f(x)/N.
Distance will bedefined as a window-size in which bigrams are calculated.MI does not give realistic figures for very low frequencies.
If a relatively unfrequentword occurs only once in a certain combination, the resulting very high MI valuesuggests a strong link between the words where it might well be simply by chance.So a lower bound of at least 3 occurrences of a word pair is necessary to calculateMI.
The t-test used to check whether the difference between the probability for acollocational occurrence and the probability for an independent occurrence of the twowords is significant, is a standard significance test in statistics (e.g.
Hatch and Farhady1982).
The statistical calculations were done as described in Church et al (1991), and76were performed together with N\VIC queries and the creat.ioxl of bigrams using toolsavailable at the "Institut f/.ir Maschinelle Sprachverarbeitung', University of Stuttgart ).3.2 The  'S tandard '  MethodVerbs that can occur in SVCs are in the centre of our study because the5' provideexamples for all three types of V-N collocations; besides, the chosen 'potential '  sup-port verbs belong to the most frequent verbs in the corpus anyway.
V-N collocationswere extracted for the following 16 verbs (no translations are given because they dif-fer depending on the N argument): bleiben, bringen, erfahren, finden, geben, gehen,gelangen, geraten, halten, km72men, ehmen, setzen, stehen, stellen, treten, ziehen.Bigram tables of all words that occur within a certain distance of these verbs, to-gether with their cooccurrence fi'equencies, form the basis for the calculation of MI.Bigram calculations were restricted to words occurring within a 6-word window to theleft (cf.
next.
section), inclusive of the verb, a span which captures 95% of significantcollocations in English (Martin et al 1983).
We will refer to these with BI6.
Forcombinations that occur at.
least 3 times, MI was calculated together with a t-score.From these, candidates for V-N collocations were automatically extracted, sorted byMI.
All of these were checked by means of NWIC-listings and classified w.r.t, their col-locational status by the author.
The classification was in most cases very obvious.
If acombination potentially formed a collocation but was not used as such in the corpus itwas not counted; a couple of times, where some of the usages were indeed collocationsand others not, the decision was made in favour of the predominant case.3.3 App l i ca t ion  for German Corpora :  Some Prob lemsSome properties of the German language make the task of extracting V-N collocationsfrom German text corpora more difficult than for English corpora.
A minor differenceconcerns the strong inflection of German verbs.
Whereas in English a verb lexemeappears in 3 or 4 different forms plus one for the present participle, German verbs have7 to I0 verb forms (without subjunctive forms) for one lexeme and additional 4 forthe present participle.
This has to be considered for the evaluation of queries based onsingle inflection forms, because in English more usages are covered with one verb formthan in German.Another point concerns the variable word order in German (see Uszkoreit 1987)which makes it, more difficult to locate lhe parts of a V-N collocation.
In a main clause(verb-second order), a noun preceding a finite verb usually is the subject, but it canalso be a topicalized complement; in sentences where the main verb occurs at the end(nonfinite verb or subordinate clause) the preceding noun is mostly a direct object orother complement, or an adjunct.. A noun to the right of a finite verb can be any ofsubject, object or other argument due to topicalization or scrambling.
We restrict oursearch to V-N combinations where the noun precedes the verb either directly or withintwo to five words, because this at least definitely captures complements of main verbsIWe greatfully acknowledge thai.
the work reported here would not have been possible without hesupplied tools and corpora.77in verb-final position.
To find the correct argument to the right of the verb is difficultin an unparsed corpus because of the variable number of intervening constituents.As illustrated in the la.,~t paragraph the assumption that a "semantic agent \[...\]is principally used before the verb" and a "'semantic object \[...\] is used after it" asdescribed in Smadja (1991a:180) does not hold for German.
Therefore, complicatedparsing is necessary to distinguish subject-verb from object-verb combinations.
Theresults of V-N extractions reflect this problem.
In many if not in most of the uninter-esting combinations extracted, the noun to the left of the verb is the subject ratherthan a complement of the verb (cf.
section 4.6).4 Eva luat ion  of the Resul tsBelow, the top bigrams with kommen (come) are shown, and some of the nonsignificantones (t < 1.65), to illustrate MI and t-scores.
Bigrams with the infinitive form give bestresults compared to other inflection forms, possibly because this form covers lst/3rdpers.
pl.
present tense, the infinitive and the nonfinite main verb of complex tenses(modals, conditional, future) at the same time.
Also, the latter two always occur inverb-final position.N + kommen Translation(zur) Geltung k.(in) Betracht k.(in) Beriihrung k.(zur) Anwen<hmg k.(zu) Trgnen k.(zur) Ruhe k.(auf den) Gedanken k.(in den) Himrnel k.(zu) Hilfe k.(zu) Wort k.Vernunft(in) Frage k.~z.ur) Welt k.:fieshow to advantageto be consideredcome into contactto be usedcome to tearsget some peaceget the ideago to heavencome to aidget a chance to speakreasonto be possibleto be bornYouf(x,y) f(y) MI t-score V-N-Coll.27 96 9.86 5.19 +9 42 9.47 2.99 +4 41 8.33 1.99 +4 126 6.71 1.97 +3 107 6.53 1.70 +4 216 5.93 1.95 +7 403 5.84 2.58 +3 270 5.20 1.66 +4 477 4.79 1.89 ?3 647 3.94 1.57 +3 736 3.75 1.55 -4 1054 3.65 1.77 +4 1900 2.80 1.60 +3 2414 2.04 1.17 -4.1 Prec is ion  and Reca l lThe question how much is extractable fully automatically can be answered by an eval-uation of precision and "recall' of the described method as it is done for memory tests.Following Smadja (1991a) we define precision as the number of correctly found collo-cations divided by the number of V-N combinations found at all.
Recall reflects theratio of the number of correctly found collocations and the maximal number of colloca-tions that could possibly have been found.
The latter is slightly difficult to determine,because in principle this means to know the total number of collocations occurring inthe whole corpus.
Another possibility, to take all collocations that are mentioned in adictionary as the maximal number of valid collocations, had to be discarded: a com-parison with Agricola (1970) or Drosdowski (1970) is not really possible because the78collocations found in the corpus are not a subset of those mentioned in the dictionaries.Only 22 of the .-1:3 collocations found with the lemma bring- in the MKI (BI6) belongto the 135 combinations mentioned in the lexical entry for bringen in Agricola (1970).Of the remaining 21 in the MKI, 9 can be found in the corresponding noun entries,and 12 do not appear at all though they are 'significant' collocations, e.g.
Klarheitbringen (clarify).
zur Entfaltung hr.
(develop), zur Wirkung hr.
(bring the effect), inSchwierigkeiten br.
(create difh'culties), ins Gespr~:ch br.
(bring into discussion).
Thus,we decided to use instead the number of collocations with the infinitive as determinedby the standard method (BI6) as the basis for recall comparisons, i.e.
100% recall isset to this number.4.2 Resul ts  of the  S tandard  MethodFrequencies for the infinitives of the 16 verbs range from 832 (kommen) to 117 (gelan-gen).
The number of V-N combinations varies from 46 (bringen) to 6 (erfahren, gelan-gen, geraten, treten), precision fiom 100% (geraten, ziehen) to 33% (eHa hren).
Averagefigures are presented in table 1 below, labeled BI6 Inf.
If non-significant combinationsare omitted with a t-test (BI6/t  Inf),  the average of collocations among the extractedV-N combinations i only 95.8% of those found without a significance boundar.v, butprecision rises slightly.
With a threshold of MI > 6, precision would go up to 82.1%with a still acceptable loss in recall of approximately 10%.4.3 Exper iment  1: Var iat ion of Window-S izeTo see whether the collocational nouns could be better located directly to the left of theverb rather than within a couple of words, we reduced window-size to 3 words includingthe verb (this allows one word in between, e.g.
'zu' (to) in infinitival constructions).As shown in table 1 for BI3 In:f, precision rises about 10%, but with a recall of 72.1%,because those collocations where other arguments or post modifiers occur between Nand V are no longer captured.
Taking again only significant combinations (BI3/'tIn:f) precision rises again slightly.
This leads to the conclusion that for German, unlesssyntactic relations can be determined, a smaller window is preferable to improve acorrect detection of preceding object arguments and to exclude unrelated nouns.Table 1: Average figures for varying window-size and lemmatizingBigramsBI6 InfBl6/t InfBI3 InfBl3/t InfBI3 LemmaO V-N O Collocations Precision % Recall %21.5 13.5 66.3 100 (def.
)18.25 12.9 71.6 95.812.4 9.5 81.2 72.111.5 9.1 83.1 70.029.9 16.1 59.8 114.74.4 Exper iment  2: S imulat ing  Lemmat iz ingBecause no lemmatizing program was available we used an additional program on topof the bigram calculations for the inflected forms.
In order to keep the amount of V-Ncombinations within a magnitude that could still be checked manually for correctness,79we restricted search to a 3-word window to the left.
V-N combinations that occurredless than two times with a single inflection forth of the verb were sorted out.
Theinflection forms for the infinitive (also lst /3rd pers.
pl.
), 3rd pers.
sg.
present and pasttense, lst /3rd pets.
pl.
past and past participle were added up; 1st pers.
sg.
and 2ndpers.
sg./pl, were so rare thai they could be ignored.
The average results are againpresented in table 1 (BI3 3.emma); the number of extracted collocations i maximal, butprecision is the lowest of all.
Precision ranges from 33.3% (gehen) to 88.2% (setzen),recall from 50% (erfahren) to 166.7% (setzen).
Recall figures are above 100% becausethe absolute number of collocations found is higher than for BI6 In:f, the basis forthe recall calculations.
Regarding lemmatization our study shows that one gets morecollocations, but at the expense of more uninteresting combinations as well.
Oneexplanation for this is that 3rd pers.
sg.
present/past and lst/3rd pers.
pl.
past onlyoccur to the right of their noun argument in subordinate clauses, whereas lst/3rd pers.pl.
present are identical with the nonfinite form which additionally occurs in verb-finalposition in main clauses with a finite auxiliary or modal verb and in infinitive clauses.4.5 Exper iment  3: Vary ing Corpus  SizeFor infinitive bringen and lexeme bring-, V-N combinations were also calculated withBI6 for a larger corpus consisting of the MK1 and BZK together.
For MK1 alone, 31 of46 combinations are collocations, a precision of 67.4% (recall is set to 100%).
With thelarger corpus the number of found V-N collocations i more than twice as big, with onlya slightly lower precision 2.
Thus, larger corpora would improve results considerably.Results for the \]exeme with the highest number of collocations at all (73) are alongthe same lines; however almost, every second V-N combination is no V-N collocationin the sense defined in section 2, i.e.
results are much better overall for the infinitiveseparately.
The complete data for bringen are listed below.Table 2: Variations forBigrams f(V) V-NBI6 Inf 550 46BI6/t Inf 550 44BI6 MKI+BZK Inf.
1065 97BI3 Inf 550 33BI3/t Inf 550 31BI6 Lemma 1508 74BI6 MKI+BZK Lemma 3145 142BI3 Lemma 1508 464.6 Exper iment  4: S imula t ing  Syntaet leIn order to see how much the precision couldthe verb bringenColl.
Precision % Recall %31 67.4 100 (def.
)31 70.5 10063 65.0 20328 84.9 90.327 87.1 87.143 58.0 138.773 51.4 235.537 80.4 119.4Taggingpossibly be improved by determiningsyntactic relations as done by Smadja (1991a,b) for English, we conducted another testwith bringen, where we manually excluded those uninteresting extracted combinationsin which the nouns were in fact used in subject position of the verb.
The results for~The latest runs with the combined corpus showed that for the infinitives precision even risesslightly on average (82.1%) while recall is almost doubled (134,9%); compared to BI3 Inf in table 1.80the two window-sizes, infinitive and lexeme, are shown in table 3.
Precision would riseup to 100t?~, with still a good recall of S7.1t~.
if one could consider syntactic/'elations forthe extraction of V-N collocations.
Tile best recall of 43 collocations within 5 wordsto the left of the lexeme would then still correspond to 78.2c70 precision as comparedto 587~, if subjects can/rot be detected.
These results point in the same direction asSmadja's who reports an improvement fi'om 40 to 80% precision if syntactic relationsare considered, with a 94% recall of all collocations that had been found regardlessof syntactic/'elations.
However, this cannot as easily be achieved in a large scale forGerman due to the complicated parsing techniques necessary for the varying wordorder.Table 3: Results for bringen if subject nouns are excluded manually.Bigrams V-N Coll.
Precision % Recall %Bl3/t Inf (no sub j) 27 27 i00 87.1BI6/t Inf ('no sub j) 39 31 79.5 100 (def.
)BI3 Lemma (no subj) 40 37 92.5 119.4BI6 Lemma (no subj) 55 43 78.2 138.75 Conc lus ions  and Out lookPrec./Recall % Coll.
counts240200-150"10(50RecallRecallP r e c .
~I I I I I ,l I 1 I3tl 31 6tl 6I 6I+ 3L 3L(oS) 6L 6L+200150I0050Figure 1: Results for bringenThe graphics in figure 1 visualize the results of the experiments for the verb br/ngen;the left y-axis shows recall and precision in per cent, the one to the right the numberof counted V-N collocations.
The left, graph compares the results for the infinitive,the right one those for the lexeme.
From left to right are shown: 3-word window81with t-threshold (3tl), 3-word window without t (3I), 6-word window with t (6tl)and without (6I), 6-word window for the enlarged corpus (6I+).
3L stands for '3-word window, lexeme', 3L(oS) means the exclusion of subject nouns; 6L and 6L+ areanalogous to the infinitive version.The result for '61+' implies that larger corpora will improve recall without a seriousdecline of precision compared to the same method used with the smaller corpus (6I; seealso footnote 2).
Whether the recall number should at the cost of a bad precision bepushed even higher by calculating MI for lexemes (6L vs. 6L+) can be decided in viewof the application the data are extracted for.
Once the number of V-N collocationsis generally big enough, higher significance and MI thresholds can be used in orderto improve precision again.
MI sorts the extracted combinations in such a way thatthe collocations are the better the higher the MI-score is (with a few exceptions whichoften reflect highly significant, but linguistically uninteresting word combinations fromone of the texts; this could hopefully be avoided with a more balanced corpus).In general, a trade-off has to be found between the number of extracted collocations(recall) and the number of uninteresting items in between (precision), depending onthe application.
The described approach seems to be a good method for corpora withtexts from restricted omains, where a special terminology is used which will thus showup strongly against 'normal' combinations.Very high precision rates, which are an indispensible r quirement for lexical acqui-sition, can only realistically be envisaged for German with parsed corpora (3L(oS) hasthe best recall-precision ratio in figure 1); otherwise the main advantage lies in a betterlexicographical support, which should not be underestimated both for manually builtNLP lexica and for printed dictionaries.
Lemmatizing does not seem to be alwaysuseful, as a comparison of 61+ and 3L shows.
Possibly the data are blurred because asmentioned on p. 6 the various inflection forms are distributed ifferently in verb-finaland verb-second clauses, at least in the investigated corpus.
Restricted lemmatizingwith infinitive (lst/3rd pers.
pl.)
and past participle for a search to the left, and with3rd pers.
sg.
pres./past and lst/3rd pers.
pl.
past for a search to the right (which isproblematic, though) promises to give more precise results, as long as search strategiescannot take into account, the syntactic structure of a sentence.Work is currently in progress to calculate trigrams to check for prepositions in SVCsor for specific (or no) determiners for phrasemes.
This will give indications to distin-guish SVCs and lexicalized, phraseological SVCs from other collocations.
In addition,we plan to consider the variation in span position of the noun within the searchedwindow in order to distinguish fixed phrasemes from flexible ones.ReferencesAgricola, E., H. Garner, R. Kiifner (eds.)
(1962/1970).
W~rter uad Wendungen.
W~rterbuchzum deutschen Sprachgebrauch.
Leipzig: Verlag Enzyklop~die; Mfinchen.Barkema, H. (1989).
Morphosyntactic ttexibility: the other side of the idiomaticity coin.
In:Everaert, M., E. van der Linden (eds.).
Proc.
of the 1st Tilburg Workshop on Idioms.
23-40.82Breidt, E. (199:1).
Extraklio, van ~k'rb-Nomen-Verbindungell aus tlem Mannheimer KorpusI.
SfS-Report 03-93.
University of Tiibingen.Brundage, J., M. Kresse, U. Schwall, A. Storrer (1992).
Multi~'ord /exemes: a monolin-gual and contrastive typology for A'LP and MT.
IWBS-Report 232, September 1992.
IBMGermany, Scientific Centre Heidelberg.Calzolari, N., R. Bindi (1990).
Acquisition of iexical information from a large textual italiancorpus.
13th COLING 1990, Helsinki.
54-59.Choueka, Y.
(1988).
Looking for needles in a haystack, or: locating interesting collocationalexpressions in large textual databa.~es.
Proceedings of the RIAO.
609-623.Church, K. W., P. ltanks (1989).
Word Association Norms, Mutual Information and Lexi-cography.
27th ACL, Vancouver.
76-83.Church, K. W., W. A. Gale, P. Ranks, D. M. Hindle (1991).
Using statistics in lexicalanalysis.
In: Zernik, U.
(ed.).
Lexical acquisition: exploring on-line resources to build alexicon.
Hillsdale, NJ.Danlos, L. (1992).
Suppor!
verb constructions.
Linguistic properties, representation, trans-lation.
Journal of French Linguistic Stud); Vol.
2, No.
I. CUP.Drosdowski, G. et al (eds.)
(1970).
sl Duden Stilw6rterbuch der deutschen Sprache: DieVerwendung der W6rter im Satz.
6th completely revised and extended edition.
Mannheim.Fieischer, W. (1982).
Phraseologie der deutsche11 Gegenwartssprache.
L ipzig.Gale, W., K. W. Church (1990).
Whets wrong with adding one?
IEEE Transactions onAcoustics, Speech and Signal Processing.Hatch, E., H. Farhady (1982).
Research design and statistics for applied linguistics.
Rowley.Hausmann, F. J.
(1989).
Le dictionnaire de collocations.
In: Hausmann, F. J. et a.l.
(eds.
).Dictionaries: an international handbook for lexicography.
Part I. HSK 5.1.
1010-1019.Ma.rtin, W., B. Al, P. van Sterkenburg (1983).
On the processing of a text corpus.
In:Ha.rtmann, B.. R. K.
(ed.).
Lexicography: principles and practice.
London.
77-87.v.Polenz, P. (1989).
Funktionsverbgefiige m allgemeinen einsprachigen W6rterbuch.
In:Hausmann, F. J. et el.
(eds.).
Dictionaries: an international handbook for lexicograph):Part I. HSK 55.1.
882-887.Sinclair, J. M. (1966).
Beginning the study of lexis.
In: Ba~,el.l, C. E. et el.
(eds.)
(1966).
Inmemory of J. R. Firth.
London.
410-430.Smadja., F. A., K. R. McKeown (1990).
Automatically extracting and representing colloca-tions for language generation.
28th ACL 1990.
252-259.Smadja, F. A.
(1991a).
Macrocoding the lexicon with co-occurrence knowledge.
In: Zernik,13.
(ed.).
Lexical acquisition: exploring on-line resources to build a lexicon.
Hillsdaie, NJ.Smadja., F. A.
(1991b).
From n-grams to collocations: an evaluation of Xtra.ct.
29th ACL,Berkeley, CA.
279-284.Uszkoreit, H. (1987).
Word order and constituent structure.
CSLI Lecture Notes 8.83
