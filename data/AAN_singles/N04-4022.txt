Context-based Speech Recognition Error Detection and CorrectionArup Sarma and David D. PalmerVirage Advanced Technology Group300 Unicorn ParkWoburn, MA 01801dpalmer@virage.comAbstractIn this paper we present preliminary resultsof a novel unsupervised approach for high-precision detection and correction of errors inthe output of automatic speech recognition sys-tems.
We model the likely contexts of all wordsin an ASR system vocabulary by performinga lexical co-occurrence analysis using a largecorpus of output from the speech system.
Wethen identify regions in the data that containlikely contexts for a given query word.
Finally,we detect words or sequences of words in thecontextual regions that are unlikely to appearin the context and that are phonetically similarto the query word.
Initial experiments indicatethat this technique can produce high-precisiontargeted detection and correction of misrecog-nized query words.1 IntroductionSpoken language sources, such as news broadcasts, meet-ings, and telephone conversations, are becoming a verycommon data source for user-centered tasks such as infor-mation retrieval, question answering, and summarization.Automatic speech recognition (ASR) systems, which canrapidly produce a transcript of spoken audio, are con-sequently becoming an essential part of the informationflow.
However, ASR systems often generate transcriptswith many word errors, which can adversely affect theperformance of systems designed to assist users in man-aging large quantities of natural language data.
Retriev-ing documents or passages relevant to a user query is sig-nificantly easier when the words in the query are con-tained in the document; when a query word is misrec-ognized by the ASR system, retrieval accuracy declines.For example, if a user is searching for spoken documentsrelated to ?Iraq,?
and the spoken word ?Iraq?
is consis-tently misrecognized, the user will not be able to locatemany of the desired documents.In this work we introduce a novel unsupervised ap-proach to detecting and correcting misrecognized querywords in a document collection.
Our approach takes ad-vantage of two important patterns in the appearance ofASR errors.
First, specific words in a large corpus tendto co-occur frequently with certain other context words,and misrecognitions of those specific words will also tendto co-occur with the same context words.
Second, manyASR errors are phonetically similar to the actual spokenwords.
Our approach takes advantage of these patterns ofASR errors and seeks to find output words that are bothphonetically similar to a query word and that occur in acontext that is more likely to indicate the query word.
Forexample, ?Iraq?
and ?a rock?
are phonetically very simi-lar but generally occur in different contexts.Our ASR error detection and correction is carried outin three steps that are separate from the speech recogni-tion itself.
We first analyze a large corpus of output froma given ASR system to compile co-occurrence statisticsfor each word in the system?s vocabulary.
This analy-sis results in a set of context words likely to occur witheach vocabulary word.
Next, given a target word, suchas a query word entered into an information retrieval sys-tem, we identify regions in the search corpus containing alarge number of the expected context words for the queryword.
Finally, we detect words in the regions that are un-likely to occur with the context words and that are pho-netically similar to the query.2 Our ApproachThere are several key components to our approach to de-tecting and correcting in-vocabulary speech recognitionerrors.
First, we calculate co-occurrence statistics for allwords in a large corpus of ASR output data; this is an of-fline processing step that we describe in Section 2.1.
Thisco-occurrence information is used in an online error de-tection process based on word context analysis.
The errordetection process first requires the input of a query wordthat is to be sought in the test corpus of ASR output fromthe same engine; the goal of this step is to detect placesin the corpus where the query word was spoken but mis-recognized.
We describe the contextual analysis in Sec-tion 2.2.
From the set of candidate error regions, ASRerrors are detected using phonetic comparison betweenthe query word and words in the window; this phoneticanalysis is described in Section 2.3.Our approach to ASR error detection and correctionbuilds on recent work in statistical lexical and contextualmodeling using co-occurrence analysis, such as (Roarkand Charniak, 1998).
We apply the contextual modelingto a speech retrieval task, as in (Kupiec et al, 1994).
Inthe earlier work, general mathematical models were de-veloped to measure lexical similarity between words incontext.
We seek to develop a simple contextual modelbased on word co-occurrences in order to facilitate theretrieval of spoken documents containing critical word er-rors.Our approach has a similar goal to that of Logan(2002); however, their work focuses primarily on out-of-vocabulary words while we focus on in-vocabularywords.
Our work also builds on recent directions inlanguage modeling for speech recognition, in which abroader context beyond n-grams is considered.
For exam-ple, the dimensionality reduction modeling of Bellegarda(1998) seeks to model long-range contextual similarityamong words in a training corpus.
Rosenfeld (2000) hasdeveloped another language modeling approach that canmodel word occurrences beyond the common trigram ap-proaches.
While language modeling techniques seek toimprove the ASR engine itself, we present an ASR post-processing correction model, in which we process andimprove the output of an ASR system.The data used for our experiments consisted of a largecorpus of English broadcast news transcripts produced bythe broadcast news speech system described in (Makhoulet al, 2000).
This real-time ASR system has a vocabu-lary size of about 64k words and a reported performancethat normally ranges from WER=20% to 30% for En-glish news broadcasts.
Our training corpus consisted of360 half-hour broadcast transcripts containing roughly1.6 million words.
The broadcasts were from three differ-ent English sources (CNN Headline News, BBC Amer-ica, and News World International) from July 2003.
Wedivided the data into a training set, from which all modelparameters were trained, and a separate test set consist-ing of files that were randomly selected from the corpus.The evaluation corpus consisted of 39 half-hour broad-cast transcripts containing about 180,000 words.2.1 Word Co-occurrence AnalysisThe goal of the first step in our approach, co-occurrenceanalysis, is to determine, for any given word in the ASRvocabulary, the other words that are very likely to occurnear the given word and are not likely to occur elsewhere.We compile co-occurrence frequencies for a target wordby counting all other words that co-occur in a documentwith the target word within a certain window size w (w/2words to the left and w/2 words to the right).
In ourcase, we investigated windows sizes ranging from w=2 tow=40; as with all our system parameters, optimal valuefor a given source empirically through training.We calculate several maximum likelihood prior proba-bilities for use in the co-occurrence analysis.
For a targetword x and each context word y, we calculate p(x) =c(x)/n and p(y) = c(y)/n, where c(x) and c(y) are thetotal corpus counts for x and y and where n is the totalnumber of words in the training corpus (1,638,224).
Wealso calculate the joint probability p(x, y) = c(x, y)/n,the probability of co-occurrence for x and y in the train-ing data.
In addition, we calculate the pointwise mutualinformation I(x, y) for two words x and y, I(x, y) =logp(x,y)p(x)p(y).
The value I(x, y) is highest for target wordsx and context words y that occur frequently togetherwithin a window w but rarely outside the window.
Thecontext words are ranked by mutual information, and thisranked list of co-occurring context words for each targetword is used in the context analysis step described in Sec-tion 2.2.The resulting ranked context lists demonstrate the dif-ferent contexts in which words like ?Iraq?
and ?rock?appear in the data.
The top 5 context words for a win-dow size of 20 for ?Iraq?
are inge, chirac?s, refusal, re-construction, and waging.
The top 5 context words for?rock?
are uplifting, kt, folk, lejeune, and assertion.
Mostof the top words in the first list are, for the most part, rel-evant to the word ?Iraq,?
and the words in the second listare clearly not relevant to ?Iraq.?
The corresponding top5 list for ?Abbas?
is mahmoud, ariel, prime, minister, andcommitted; the list for ?bus?
is michelle, blew, moscow,jerusalem, and responsible.These lists also demonstrate the value of modeling thepatterns in the ASR output directly, rather than compilingco-occurrence frequencies from a clean data source with-out word errors: the output word inge occurs exclusivelyin the data as an ASR error for in going in the context ?ingoing to war with Iraq.?
Similarly, kt occurs frequentlyin the data as part of the call letters for a television sta-tion in Little Rock, Arkansas.
Systematic and recurringerrors such as this provide a great deal of information inthe co-occurrence statistics.
However, the use of ASRoutput without ?clean?
transcripts in training also intro-duces the possibility of modeling false positives in theoutput, such as ?Iraq?
being output as an error when ?arock?
was spoken; this type of error can adversely affectthe co-occurrence statistics we calculate.2.2 Context AnalysisThe context analysis component seeks to identify contex-tual regions in the test data that are likely to contain agiven query word, and thus also likely to contain a mis-recognition of the query word.
This analysis uses theprobabilities and mutual information output from the co-occurrence analysis described in Section 2.1.We slide a window of w words across a document inthe test data, where w is the same window size used totrain the word co-occurrence statistics.
We also define aminimum number of context words c that must be con-tained with the window in order to mark the center wordof the window as a possible ASR error.
As an exam-ple of this context matching, consider the word sequence?...
the reconstruction of a rock proceeds despite Chirac?srefusal...?
The word ?rock?
is at the center of an 8-wordcontext window (4 on either side) containing 3 of the top-ranked context words for ?Iraq?
from the previous sec-tion.
This instance of the word ?rock?
would thus be acandidate misrecognition of ?Iraq?
for w ?
8 and c ?
3.Table 1 shows the number of candidate words detectedfor ?Iraq?
in the evaluation data for different windowsizes w and minimum context words c. As might be ex-pected, the number of candidate words increases as thewindow size increases and decreases as the minimumnumber of context words increases.Window Size wc 2 6 10 14 201 10412 27643 42142 54507 702122 346 3941 8820 14409 231333 x 597 2152 4314 84184 x 84 505 1411 34375 x 9 123 438 1387Table 1: Candidate errors for ?Iraq?
detected within arange of window sizes w for minimum numbers of con-text words c.Most combinations result in a large number of candi-dates, so we also apply candidate pruning based on prob-abilistic metrics.
Given a candidate error and c contextwords contained in a window, we then compare the prob-ability of observing both the query word and the actualword in the data.
This comparison is carried out us-ing the Kullback-Leibler divergence for observation dis-tributions containing the c context words, D(p ?
q) =?x?X p(x) logp(x)q(x), where p(x) is the conditional prob-ability of the co-occurrence of the query word with a con-text word x in the set of c context words X and q(x) is theprobability of the candidate error with the context word.A larger Kullback-Leibler divergence value indicates ahigher probability that the candidate word is actually amisrecognition of the query word.2.3 Phonetic ComparisonGiven the set of candidate errors for a query word, asdetected using the context matching technique describedin Section 2.2, we next apply a phonetic distance cri-terion to determine the similarity between each candi-date error and the query word being sought, based onthe pronunciations in the ASR system lexicon.
We usedthe common minimum-distance weighted phonetic align-ment technique described in detail in (Kondrak, 2003);in our experiments we used phonetic weights availablethrough the alignment package altdistsm originally de-scribed in (Fisher and Fiscus, 1993).The final decision whether to correct the ASR error ismade based on the phonetic distance between the candi-date word and the query word.
Since the candidate wordis already known to have occurred in a lexical context thatis likely to contain the query, a strong phonetic similaritybetween the words provides very strong evidence that thecandidate word is, in fact, a misrecognition of the queryword.3 Results and DiscussionWe carried out an initial evaluation of our system usingthree specific query words that were featured in a largenumber of news stories in the training corpus: ?Iraq,??Abbas,?
and ?Lynch?
(from Jessica Lynch, an Ameri-can soldier during the war in Iraq).
The 39 files in thetest corpus were annotated to indicate all the locationsof recognition errors involving these three spoken words.In addition, the location of errors that are morphologicalvariants of the query word, such as ?Iraqi?
and ?Iraq?s?were annotated and were not included in the evaluationresults; in the context of information retrieval these mor-phological variants can easily be addressed using com-mon techniques such as stemming.The query word ?Lynch?
turned out to be an uninter-esting case for our approach: it was misrecognized only4 times in the test corpus, each time as the morphologi-cal variant ?lynched.?
Nevertheless, the context matchingtest worked well, as three of the top-ranked context wordswere the very relevant ?Jessica,?
?private,?
and ?rescue.
?The detection and correction results for the word ?Abbas?were also very encouraging, although the small samplesize makes it difficult to draw significant conclusions.
Inour test corpus, there were n=10 examples in which ?Ab-bas?
was misrecognized.
Our method detected 8 candi-dates, 7 of which were actually misrecognitions of ?Ab-bas,?
for a recall of 70% and a precision of 88% (windowsize w=10, minimum context c=2).
Corrections included?a bus,?
?a bass,?
and ?a boss,?
and the false positive wasthe word ?about,?
which is phonetically very similar.The query term ?Iraq?
proved to be the most fruitfulquery term, due to its prevalence throughout the corpus.There was a total of 142 cases in which ?Iraq?
was mis-recognized.
Examples of common errors were ?rock,?
?a rock,?
?your rocks,?
?warren rock?
(war in Iraq), ?herrock,?
?any rocket?
(in Iraq), and ?a rack.?
Table 2 showsthe final results for the query term ?Iraq?
for the 39 ASRoutput test files, for a range of minimum required contextwords c and the most-successful window size (14 ).c Detect Correct False Pos R P1 138 120 18 85 872 92 87 5 61 953 51 51 0 36 1004 27 27 0 19 1005 9 9 0 6 100Table 2: Results for query word ?Iraq?
for window sizew=14 and a range of minimum context words c: hypothe-sized errors detected and corrected, false positives, recall,and precision (n=142).Although we can not draw conclusions about the gen-eral applicability of this approach until we carry out fur-ther experiments with more test cases, the preliminary de-tection and correction results indicate that it is possible toachieve very high precision with a reasonable recall forcertain window sizes and numbers of context words.
Ta-ble 3 shows recall and precision values for some of themost effective combinations of window sizes w and min-imum context words c which return few false positivesand many accurate corrections.w c R P8 1 69 888 2 38 10010 1 77 8710 2 44 9814 2 61 9514 3 36 100Table 3: Recall and precision values for selected windowand minimum context values.The work we describe in this paper is complementaryto ASR algorithmic improvements, in that we treat er-ror detection and correction as a post-processing step thatcan be applied to the output of any ASR system and canbe adapted to incremental improvements in the systems.This form of post-processing also allows us to take advan-tage of long-range contextual features that are not avail-able during the ASR decoding itself.
Post-processing alsoenables large-scale data analysis that models the types ofsystematic errors that ASR systems make.
All the steps inour approach, co-occurrence analysis, context matching,and phonetic distance pruning, are unsupervised methodsthat can be automatically run for large quantities of data.The results in this paper are promising but are obvi-ously very preliminary.
We are in the process of evalu-ating the work on a much larger set of query words.
Weshould emphasize that the goal of this work is not to pro-duce a significant improvement in the overall word errorrate of a particular corpus of ASR output, although we be-lieve that such an improvement is possible using similarcontextual analysis.
Instead, the focus of the work is toimprove the specific aspects of the ASR output that mayadversely affect a user-centered task like information re-trieval.
While we have not formally evaluated the impactof our error detection and correction on retrieval perfor-mance, there is an obvious benefit to correcting misrecog-nitions of the specific query term that a user is seeking.ReferencesJerome R. Bellegarda, ?A multi-span language modelingframework for large vocabulary speech recognition,?IEEE Transactions on Speech and Audio Processing,6:456?467, 1998.W.
M. Fisher and J.G.
Fiscus, ?Better Alignment Proce-dures for Speech Recognition Evaluation,?
Proc.
Inter-national Conference on Acoustic, Speech and SignalProcessing, pp.
II-59 - II-62, 1993.G.
Kondrak, ?Phonetic Alignment and Similarity,?
Com-puters and the Humanities 37(3), August 2003, pp.273?291.J.
Kupiec, D. Kimber, and V. Balasubramanian, ?Speech-Based Retrieval Using Semantic Co-Occurrence Filter-ing,?
In Proc.
Human Language Technologies, pp.
373-377, 1994.B.
Logan and J.M.
Van Thong, ?Confusion-based QueryExpansion for OOV Words in Spoken Document Re-trieval,?
In Proc.
ICSLP 2002,, Denver, Colorado, pp.1997-2000, 2002.J.
Makhoul, F. Kubala, T. Leek, D. Liu, L. Nguyen, R.Schwartz, and A. Srivastava, ?Speech and LanguageTechnologies for Audio Indexing and retrieval,?
InProceedings of the IEEE, vol.
88, no.
8, pp.
1338-1353,2000.B.
Roark and E. Charniak, ?Noun-Phrase Co-OccurrenceStatistics for Semi-Automatic Semantic Lexicon Con-struction,?
In Proceedings of the 36th Annual Meetingof the Association for Computational Linguistics, pp.1110-1116, 1998.R.
Rosenfeld, ?Two decades of Statistical LanguageModeling: Where Do We Go From Here??
Proceed-ings of the IEEE, 88(8), 2000.
