Determin is t i c  Pars ing of Syntact ic  Non- f luenc iesDona ld  H ind leBell LaboratoriesMurray Hill, New Jersey 07974It is often remarked that natural language, usednaturally, is unnaturally ungrammatical.
* Spontaneousspeech contains all manner of false starts, hesitations, andself-corrections that disrupt the well-formedness of strings.It is a mystery then, that despite this apparent widedeviation from grammatical norms, people have littledifficx:lty understanding the non-fluent speech that is theessential medium of everyday life.
And it is a still greatermystery that children can succeed in acquiring the grammarof a language on the basis of evidence provided by a mixedset of apparently grammatical nd ungrammatical strings.I.
Sell-correction: a Rule-governed SystemIn this paper I present a system of rules for resolving thenon-fluencies of speech, implemented as part of acomputational model of syntactic processing.
The essentialidea is that non-fluencies occur when a speaker correctssomething that he or she has already said out loud.
Sincewords once said cannot be unsaid, a speaker can onlyaccomplish a self-correction by saying something additional-- namely the intended words.
The intended words aresupposed to substitute for the wrongly produced words.For example, in sentence (1), the speaker initially said I butmeant we.
(1) I was-- we were hungry.The problem for the hearer, as for any natural languageunderstanding system, is to determine what words are to beexpunged from the actual words said to find the intendedsentence.Labov (1966) provided the key to solving this problemwhen he noted that a phonetic signal (specifically, amarkedly abrupt cut-off of the speech signal) always marksthe site where self-correction takes place.
Of course,finding the site of a self-correction is only half the problem;it remains to specify what should be removed.
A first guesssuggests that this must be a non-deterministic problem,requiring complex reasoning about what the speaker meantto say.
Labov claimed that a simple set of rules operatingon the surface string would specify exactly what should bechanged, transforming nearly all non-fluent strings intofully grammatical sentences.
The specific set oftransformational rules Labor proposed were not formallyadequate, in part because they were surface transformationswhich ignored syntactic constituenthood.
But his workforms the basis of this current analysis.This research was done for the most part at the University ofPennsylvama.
supported by the National Institute of Education undergrants GTg-0169 and G80-0163.Labor's  claim was not of course that ungrammaticalsentences are never produced in speech, for that clearlywould be false.
Rather, it seems that truly ungrammaticalproductions represent only a tiny fraction of the spokenoutput, and in the preponderance of cases, an apparentungrammaticality can be resolved by simple editing rules.
Inorder to make sense of non-fluent speech, it is essential thatthe various types of grammatical deviation be distinguished.This point has sometimes been missed, andfundamentally different kinds of deviation from standardgrammaticality have been treated together because they allpresent the same sort of problem for a natural languageunderstanding system.
For example, Hayes and Mouradian(1981) mix together speaker-initiated self-corrections withfragmentary sentences of all sorts:people often leave out or repeat words or phrases, breakoff what they are saying and rephrase or replace it,speak in fragments, or otherwise use incorrect grammar(1981:231).Ultimately, it will befluent productions onare fully grammaticalother.
Although wecharacterization ofessential to distinguish between non-the one hand, and constructions thatthough not yet understood, on themay not know in detail the correctsuch processes as ellipsis andconjunction, they are without doubt fully productivegrammatical processes.
Without an understanding of thedifferences in the kinds of non-fluencies that occur, we areleft with a kind of grab bag of grammatical deviation thatcan never be analyzed except by some sort of generalpurpose mechanisms.In this paper, I want to characterize the subset of spokennon-fluencies that can be treated as self-corrections, and todescribe how they are handled in the context of adeterministic parser.
I assume that a system for dealingwith self-corrections similar to the one I describe must be apart of the competence of any natural anguage user.
I willbegin by discussing the range of non-fluencies that occur inspeech.
Then, after reviewing the notion of deterministicparsing, I will describe the model of parsing self-correctionsin detail, and report results from a sample of 1500sentences.
Finally, I discuss some implications of thistheory of self-correction, particularly for the problem oflanguage acquisition.2.
Errors in Spontaneous SpeechLinguists have been of less help in describing the natureof spoken non-fluencies than might have been hoped;relatively little attention has been devoted to the actualperformance of speakers, and studies that claim to be based123on performance data seem to ignore the problem of non-fluencies.
(Notable exceptions include Fromkin (1980), andThompson (1980)).
For the discussion of self-correction, Iwant to distinguish three types of non-fluencies thattypically occur in speech.1.
Unusual Constructions.
It is perhaps worthemphasizing that the mere fact that a parser does not handlea construction, or that linguists have not discussed it, doesnot mean that it is ungrammatical.
In speech, there is arange of more or less unusual constructions which occurproductively (some occur in writing as well), and whichcannot be considered syntactically ill-formed.
For example,(2a) I imagine there's a lot of them must have had somegood reasons not to go there.
(2b) That's the only thing he does is fight.Sentence (2a) is an example of non-standard subject relativeclauses that are common in speech.
Sentence (2b), whichseems to have two tensed "be" verbs in one clause is aproductive sentence type that occurs regularly, thoughrarely, in all sorts of spoken discourse (see Kroch andHindle 1981).
I assume that a correct and completegrammar for a parser will have to deal with all grammaticalprocesses, marginal as well as central.
I have nothingfurther to say about unusual constructions here.2.
True Ungrammatical/ties.
A small percentage ofspoken utterances are truly ungrammatical.
That is, they donot result from any regular grammatical process (howeverrare), nor are they instances of successful self-correction.Unexceptionable xamples are hard to find, but thefollowing give the flavor.
(3a) I've seen it happen is two girls fight.
(3b) Today if you beat a guy wants to blow your headoff for something.
(3c) And aa a lot of the kids that are from ourneighborhood-- there's one section that the kids aren'ttoo-- think they would usually-- the-- the ones that werethe-- the drop outs and the stoneheads.Labov (1966) reported that less that 2% of the sentences ina sample of a variety of types of conversational Englishwere ungrammatical in this sense, a result that is confirmedby current work (Kroch and Hindle 1981).3.
Self-corrected strings.
This type of non-fluency is thefocus of this paper.
Self-corrected strings all have thecharacteristic that some extraneous material was apparentlyinserted, and that expunging some substring results in awell-formed syntactic structure, which is apparentlyconsistent with the meaning that is intended.In the degenerate case, self-correction i serts non-lexicalmaterial, which the syntactic processor ignores, as in (4).
(aa) He was uh still asleep.
(4b) I didn't ko-- go right into college.The minimal non-lexical material that self-correction mightinsert is the editing signal itself.
Other cases (examples 6-10 below) are only interpretable given the assumption thatcertain words, which are potentially part of the syntacticstructure, are to be removed from the syntactic analysis.The status of the material that is corrected by self-correction and is expunged by the editing rules is somewhatodd.
I use the term expunction to mean that it is removedfrom any further syntactic analysis.
This does not meanhowever that a self-corrected string is unavailable forsemantic processing.
Although the self-corrected string isedited from the syntacti c analysis, it is neverthelessavailable for semantic interpretation.
Jefferson (1974)discusses the example(5) ... \[thuh\] -- \[thiy\] officer ...where the initial, self-corrected string (with the pre-consonantal form of the rather than the pre-vocalic form)makes it clear that the speaker originally inteTided to referto the police by some word other than officer.I should also note that the problems addressed by theself-correction component hat I am concerned with areonly part of the kind of deviance that occurs in naturallanguage use.
Many types of naturally occurring errors arenot part of this system, for example, phonological andsemantic errors.
It is reasonable to hope that much of thisdreck will be handled by similar subsystems.
Of course,there will always remain errors that are outside of anysystem.
But we expect that the apparent chaos is muchmore regular than it at first appears and that it can bemodeled by the interaction of components that arethemselves simple.In the following discussion, I use the terms self-correction and editing more or less interchangeably, thoughthe two terms emphasize the generation and interpretationaspects of the same process.3.
The ParserThe editing system that I will describe is implemented ontop of a deterministic parser, called Fidditch.
based on theprocessing principles proposed by Marcus (1980).
It takesas input a sentence of standard words and returns a labeledbracketing that represents the syntactic structure as anannotated tree structure.
Fidditch was'designed to processtranscripts of spontaneous peech, and to produce ananalysis, partial if necessary, for a large corpus of interviewtranscripts.
Because Jris a deterministic parser, it producesonly one analysis for each sentence.
When Fidditch isunable to build larger constituents out of subphrases, itmoves on to the next constituent of the sentence.In brief, the parsing process proceeds as follows.
Thewords in a transcribed sentence (where sentence means onetensed clause together with all subordinate clauses) areassigned a lexical category (or set of lexical categories) onthe basis of a 2000 word lexicon and a morphologicalanalyzer.
The lexicon contains, for each word, a list ofpossible lexical categories, subcategorization i formation,and in a few cases, information on compound words.
Forexample, the entry for round states that it is a noun, verb,adjective or preposition, that as a verb it is subcategorizedfor the movable particles out and up and for NP, and that itmay be part of the compound adjective/preposition roundabout.Once the lexical analysis is complete, The phrasestructure tree is constructed on the basis of pattern-actionrules using two internal data structures: 1) a push-downstack of incomplete nodes, and 2) a buffer of completeconstituents, into which the grammar ules can look through124a window of three constituents.
The parser matches rulepatterns to the configuration of the window and stack.
Itsbasic actions include- -  starting to build a new node by pushing a category ontothe stack- -  attaching the first element of the window to the stack- -  dropping subtrees from the stack into the first position inthe window when they are complete.The parser proceeds deterministically in the sense that noaspect of the tree structure, once built may be altered byany rule.
(See Marcus 1980 for a comprehensive discussionof this theory of parsing.)4.
The  ser f -cor rec t ion  ru lesThe self-correction rules specify how much, if anything,to expunge when an editing signal is detected.
The rulesdepend crucially on being able to recognize an editingsignal, for that marks the right edge of an expunction site.For the present discussion, I will assume little about thephonetic nature of the signal except that it is phoneticallyrecognizable, and that, whatever their phonetic nature, allediting signals are, for the self-correction system,equivalent.
Specifying the nature of the editing signal is,obviously, an area where further research is needed.The only action that the editing rules can perform isexpunct ion ,  by which I mean removing an element from theview of the parser.
The rules never replace one elementwith another or insert an element in the parser datastructures.
However, both replacements and insertions canbe accomplished within the self-correction system byexpunction of partially identical strings.
For example, in(6) I am-- I was really annoyed.The self-correction rules will expunge the I am whichprecedes the editing signal, thereby in effect replacing amwith was and inserting real ly.Self-corrected strings can be viewed formally as havingextra material inserted, but not involving either deletion orreplacement of material.
The linguistic system does seem tomake use of both deletions and replacements in othersubsystems of grammar however, namely in ellipsis andrank sh i f t .
.As  with the editing system, these are not errorsbut formal systems that interact with the central features ofthe syntax.
True errors do of course occur involving allthree logical possibilities (insertion, deletion, andreplacement) but these are relatively rare.The self-correction rules have access to the internal datastructures of the parser, and like the parser itself, theyoverate deterministicallv.
The parser views the editingsignal as occurring at the end of a constituent, because itmarks the r ight edge of an expunged element.
There aretwo types of editing rules in the system: expunction ofcopies, for which there are three rules, and lexicallytriggered restarts, for which there is one rule.4.1 Copy  Ed i t ingThe copying rules say that if you have two elementswhich are the same and they are separated by an editingsignal, the first should be expunged from the structure.Obviously the trick here is to determine what counts ascopies.
There are three specific places where copy editingapplies.SURFACE COPY EDITOR.
This is essentially a non-syntactic rule that matches the surface string on either sideof the editing signal, and expunges the first copy.
Itapplies to the surface string (i.e., for transcripts, theorthographic string) before any syntactic proct... i ,~.
Forexample, in (7), the underlined strings are expunged beforeparsing begins.
(7a) Well i f  they 'd - -  if they'd had a knife 1 wou--  Iwouldn't be here today.
(Tb) l f they - -  if they could do it.Typically, the Surface Copy Editor expunges a string ofwords that would later be analyzed as a constituent (orpartial constituent), and would be expunged by theCategory or the Stack Editors (as in 7a).
However.
thestring that is expunged by the Surface Copy Editor need notbe dominated by a single node; it can be a sequence ofunrelated constituents.
For example, in (7b) the parser willnot analyze the first i / they  as an SBAR node since there isno AUX node to trigger the start of a sentence, andtherefore, the words will not be expunged by either theCategory or the Stack editor.
Such cases where ',he SurfaceCopy Editor must apply are rare, and it may therefore bethat there exists an optimal parser grammar that wouldmake the Surface Copy Editor redundant; all strings wouldbe edited by the syntactically based Category and StackCopy rules.
However, it seems that the Surface CopyEditor must exist at some stage in the process of syntacticacquisition.
The overlap between it and the other rules maybe essential in iearning.CATEGORY COPY EDITOR.
This copy editormatches syntactic constituents in the first two positions inthe parser's buffer of complete constituents.
When the firstwindow position ends with an editing signal and the firstand second constituents in the window are of the same type,the first is expunged.
For example, in sentence (8) the firstof two determiners eparated by an editing signal isexpunged and the first of two verbs is similarly expunged.
(8) I was just that -- the kind of guy that didn't have--like to have people worrying.STACK COPY EDITOR.
If the first constituent in thewindow is preceded by an editing signal, the Stack CopyEditor looks into the stack for a constituent of the sametype, and expunges any copy it finds there along with alldescendants.
(In the current implementation, the StackCopy Editor is allowed to look at successive nodes in thestack, back to the first COMP node or attention shiftingboundary.
If it finds a copy, it expunges that copy alongwith any nodes that are at a shallower level in the stack.
IfFidditch were allowed to attach of incomplete constituents,the Stack Copy Editor could be implemented to delete thecopy only, without searching through the stack.
Thespecifics of the implementation seems not to matter for thisdiscussion of the editing rules.)
In sentence (9), the initialembedded sentence is expunged by the Stack Copy Editor.
(9) I think that you get-- it's more strict in Catholicschools.1254.2  An  ExampleIt will be useful to look a little more closely at theoperation of the parser to see the editing rules at work.Sentence (10)(10) I-- the-- the guys that I'm-- was telling you aboutwere .includes three editing signals which trigger the copy editors.
(note also that the complement of were  is ellipted.)
I willshow a trace of the parser at each of these correction stages.The first editor that comes into play is the Surface CopyEditor, which searches for identical strings on either side ofan editing signal, and expunges the first copy.
This is doneonce for each sentence, before any lexical categoryassignments are made.
Thus in effect, the Surface CopyEditor corresponds to a phonetic/phonological matchingoperation, although it is in fact an orthographic procedurebecause we are dealing with transcriptions.
Obviously, afull understanding of the self-correction system calls fordetailed phonetic/phonological investigations.After the Surface Copy Editor has applied, the stringthat the lexical analyzer sees is (11)(11) I-- the guys that I'm-- was telling you about were.rather than (10).
Lexical assignments are made, and theparser proceeds to build the tree structures.
After someprocessing, the configuration of the data structures is thatshown in Figure 1.5432eUi'l'elltNODE STACKNP<I ->NP < the guys >?
?
ATTENSHIFT< <NP<I>AUX < am-- ?Before determining what next rule to apply, the two editingrules come into play, the Category Editor and the StackEditor.
At this pulse, the Stack Editor will apply becausethe first constituent in the window is the same (an AUXnode) as the current active node, and the current node endswith an edit signal.
As a result, the first window element ispopped into another dimension, leaving the the parser datastructures in the state shown in Figure 2.Parsing of the sentence proceeds, and eventually reachesthe state shown in Figure 3. where the Stack Editorconditions are again met.
The current active node and thefirst e lement in the window are both NPs, and the activenode cads with an edit signal.
This causes the current nodeto be expunged, leaving only a single NP node, the one inthe window.
The final analysis of the sentence, after somemore processing is the tree shown in Figure 4.I should reemphasize that the status of the editedelements is special.
The copy editing rules remove aconstituent, no matter how large, from the view of theparser.
The parser continues as if those words had not beensaid.
Although the expunged constituents may be availablefor semantic interpretation, they do not form part of themain predication.NODE STACKcurrent ENP< I - '>  \]COMPLETE NODES IN WINDOWINP< theguys> \] SBAR < that.-.> I AUX< were> IFigure 3.
The parser state before the secondaFplication of the Stack Copy Editor.COMPLETE NODES IN WINDOW\[ \] I - -  \] AUX < was> V < te l l ing> PRON < you >Figure 1.
The parser state before theStack Copy Editor applies.432currentNODE STACK.NP < the guys >COMPLETE NODES IN WINDOWI AUX< was> IV< telling> \[ PRON< Y?U> 1.Figure 2.
The parser state afterStack Copy Editing the AUX node.NP NPDETER DART theNOM Np\[N guySBARCOMPCMP thatNP  tSNP PRON IAUXTNS PAST sbe+ in$VPV tellNP PRON youPREP aboutNP tAUX THS PAST plVP V beFigure 4, The final analysis of sentence (10).2264.3 RestartsA somewhat different sort of self-correction, lesssensitive to syntactic structure and flagged not only bY theediting signal but also by a lexical item, is the restart.
Arestart triggers the expunction of all words from the editsignal back to the beginning of the sentence.
It is signaledby a standard edit signal followed by a specific lexical itemdrawn from a set including well, ok. see, you know, like Isaid, etc.
For example,(12a) That's the way if-- well everybody was so stoned,anyway.
(12b) But when l was young I went in-- oh I was n'ineteenyears old.It seems likely that, in addition to the lexical signals,specific intonational signals may also be involved inrestarts.5.
A sampleThe editing system I have described has been applied toa corpus of over twenty hours of transcribed speech, in theprocess of using the parser to search for various syntacticconstructions.
Tht~ transcripts are of sociolinguisticinterviews of the sort developed by Labor and designed toelicit unreflecting speech that approximates naturalconversation."
They are conversational interviews coveringa range of topics, and they typically include considerablenon-fluency.
(Over half the sentences in one 90 minuteinterview contained at least one non-fluency).The transcriptions are in standard orthography, withsentence boundaries indicated.
The alternation of speakers'turns is indicated, but overlap is not.
Editing signals, whennoted by the transcriber, are indicated in the transcriptswith a double dash.
It is clear that this approach totranscription only imperfectly reflects the phonetics ofediting signals; we can't be sure to what extent the editingsignals in our transcripts represent facts about productionand to what extent they represent facts about perception.Nevertheless, except for a general tendency towardunderrepresentation, there seems to be no systematic bias inour transcriptions of the editing signals, and therefore ourfindings are not likely to be undone by a betterunderstanding of the phonetics of self-correction.One major problem in analyzing the syntax of English isthe multiple category membership of words.
In general,most decisions about category membership can be made onthe basis of local context.
However, by its nature, self-correction disrupts the local context, and therefore thedisambiguation of lexical categories becomes a moredifficult problem.
It is not clear whether the rules forcategory disambiguation extend across an editing signal ornot.
The results I present depend on a successfuldisambiguation of the syntactic categories, though thealgorithm to accomplish this is not completely specified.Thus, to test the self-correction routines I have, wherenecessary, imposed the proper category assignment.Table 1 shows the result of this editing system in theparsing of the interview transcripts from one speaker.
Allin all this shows the editing system to be quite successful inresolving non-fluencies.The interviews for this study were conducted by Tony Kroch and byAnne Bower.TABLE 1.
SELF-CORRECTION RULE APPLICATIONtotal sentencestotal sentences with no edit signal15121108 (73%)Editing Rule Applicationsexpunction ofedit signal only 128 24%surface copy 161 29%category copy 47 9%stack copy 148 27%restart 32 6%failures 17 3%remaining unclearand ungrammatical 11 2%6.
DiscussionAlthough the editing rules for Fidditch are written asdeterministic pattern-action rules of the same sort as therules in the parsing grammar, their operation is in a senseisolable.
The patterns of the self-correction rules arechecked first, before any of the grammar ule patterns arechecked, at each step in the parse.
Despite thisindependence in terms of rule ordering, the operation ofthe self-correction component is closely tied to the grammarof the parser; for it is the parsing grammar that specifieswhat sort of constituents count as the same for copying.For example, if the grammar did not treat there as a nounphrase when it is subject of a sentence, the self-correctionrules could not properly resolve a sentence like(13) People-- there's a lot of people from Kennsingtonbecause the editing rules would never recognize that peopleand there are the same sort of element.
(Note that (13)cannot be treated as a Restart because the lexical trigger isnot present.)
Thus, the observed pattern of self-correctionintroduces empirical constraints on the set of features thatare available for syntactic rules.The self-correction rules impose constraints not only onwhat linguistic elements must count as the same, but also onwhat must count as different.
For example, in sentence(14), could and be must be recognized as different sorts ofelements in the grammar for the AUX node to be correctlyresolved.
If the grammar assigned the two words exactlythe same part of speech, then the Category Cc'gy Editorwould necessarily apply, incorrectly expunging could.
(14) Kid could-- be a brain in school.It appears therefore that the pattern of self-corrections thatoccur represents a potentially rich source of evidence aboutthe nature of syntactic ategories.Learnability.
If the patterns of self-correction count asevidence about the nature of syntactic categories for thelinguist, then this data must be equally available to thelanguage learner.
This would suggest hat, far from beingan impediment to language learning, non-fluencies may infact facilitate language acquisition bv highlightingequivalent classes.L27This raises the general question of how children canacquire a language in the face of unrestrained non-fluency.How can a language learner sort out the grammatical fromthe ungrammatical  strings?
(The non-fluencies of speechare of course but one aspect of the degeneracy of input thatmakes language acquisition a puzzle.)
The self-correctionsystem I have described suggests that many non-f luentstrings can be resolved with little detailed linguisticknowledge.As Table 1 shows, about a quarter of the editing signalsresult in expunction of only non-linguistic material.
Thisrequires only an ability to distinguish linguistic from non-linguistic stuff, and it introduces the idea that edit signalssignal an expunction site.
Almost a third are resolved bythe Surface Copying rule, which can be viewed simply as aninstance of the general non-linguistic rule that multipleinstances of the same thing count as a single instance.
Thecategory copying rules are generalizations of simplecopying, applied to a knowledge of linguistic categories,Making the transition from surface copies to category copiesis aided by the fact that there is considerable overlap incoverage, defining a path of expanding generalization.Thus at the earliest stages of learning, only the simplest,non-linguistic self-correction rules would come into play,and gradually the more syntactically integrated would beacquired.Contrast this self-correction system to an approach thathandles non-fluencies by some general problem solvingroutines, for example Granger (1982), who proposesreasoning from what a speaker might be expected to say.Besides the obvious inefficiencies of general problemsolving approaches, it is worth giving special emphasis tothe problem with learnabil ity.
A general problem solvingapproach depends crucially on evaluating the l ikelihood ofpossible deviations from the norms.
But a language learnerhas by definition only partial and possibly incorrectknowledge of the syntax, and is therefore unable toconsistently identify deviations from the grammaticalsystem.
With the editing system I describe, the learner neednot have the ability to recognize deviations fromgrammatical norms, but merely the non-linguistic ability torecognize copies of the same thing.Generation.
Thus far, I have considered the self-correction component from the standpoint of parsing.However,  it is clear that the origins are in the process ofgeneration.
The mechanism for editing self-corrections thatI have proposed has as its essential operation expunging oneof two identical elements.
It is unable to expunge asequence of two elements.
(The Surface Copy Editor mightbe viewed as a counterexample to this claim, but seebelow.)
Consider expunction now from the standpoint ofthe generator.
Suppose self-correction bears a one-to-onerelationship to a possible action of the generator (initiatedby some monitoring component)  which could be calledABANDON CONSTRUCT X.
And suppose that thisaction can be initiated at any time up until CONSTRUCT Xis completed, when a signal is returned that the constructionis complete.
Further suppose that ABANDONCONSTRUCT X causes an editing signal.
When thespeaker decides in the middle of some linguistic element oabandon it and start again, an editing signal is produced.If this is an appropriate model, then the elements whichare self-corrected should be exactly those elements thatexist at some stage in the generation process.
Thus, weshould be able to find evidence for the units involved ingeneration by looking at the data of self-correction.
Andindeed, such evidence should be available to the languagelearner as well.SummaryI have described the nature of self-corrected speech(which is a major source of spoken non.f luencies) and howit can be resolved by simple editing rules within the contextof a deterministic parser.
Two features are essential to theself-correction system: I) every self-correction site (whetherit results in the expunction of words or not) is marked by aphonetically identif iable signal placed at the right edge ofthe potential expunction site; and 2) the expunged part isthe left-hand member  of a pair of copies, one on each sideof the editing signal.
The copies may be of three types: 1)identical surface strings, which are edited by a matchingrule that applies before syntactic analysis begins; 2)complete constituents, when two constituents of the sametype appear in the parser's buffer; or 3) incompleteconstituents, when the parser finds itself trying to completea constituent of the same type as a constituent it has justcompleted.
Whenever  two such copies appear in such aconfiguration, and the first one ends with an editing signal,the first is expunged from further analysis.
This editingsystem has been implemented as part of a deterministicparser, and tested on a wide range of sentences fromtranscribed speech.
Further study of the self-correctionsystem promises to provide insights into the units ofproduction and the nature of linguistic categories.AcknowledgementsMy thanks to Tony Kroch, Mitch Marcus, and KenChurch for helpful comments on this work.ReferencesFromkin, Victoria A. ed.
1980.
Errors in LinguisticPerformance: Slips of the Tongue.
Ear.
Pen and Hand.Academic Press: New York.Granger,  Richard H. 1982.
Scruffy Text Understanding:Design and Implementat ion of 'Tolerant '  Understanders.Proceedings of the 20th Annual Meeting of the ACL.Hayes, Philip I. and George V. Mouradian.
1981.Flexible Parsing.
American Journal of ComputationalLinguistics 7.4, 232-242.J'efferson, Gall.
1974.
Error correction as aninteractional resource.
Language in Society 2:181-199.Kroch, Anthony and Donald Hindle.
1981.
Aquantitative study of the syntax of speech and writing.
Finalreport to the National Institute of Education, grant 78-0169.Labor ,  Will iam.
1966.
On the grammatical ity ofeveryday speech.
Paper presented at the Linguistic Societyof America annual meeting.Marcus, Mitchell P. 1980.
A Theory of SyntacticRecognition for Natural Language.
MIT Press: Cambridge,MA.Thompson,  Bozena H. 1980.
A linguistic analysis ofnatural language communicat ion with computers.Proceedings of the eighth international conference oncomputational linguistics.128
