Evaluation of an Algorithm for the Recognit ion andClassification of Proper NamesTakahiro  Wakao Rober t  Ga izauskas  Yor ick Wi lksDepar tment  of Computer  Science,Un ivers i ty  of Sheffield{T. Wakao, R. Gaizauskas, Y. Wilks}@dcs.
shef.
ac.
ukAbst rac tWe describe an information extraction sys-tem in which four classes of naming expres-sions organisation, person, location andtinm names are recognised and classifiedwith nearly 92% combined precision and re-call.
The system applies a mixture of tech-niques to perform this task and these aredescribed in detail.
We have quantitativelyevaluated the system against a blind testset of Wall Street Journal business articlesand report results not only for the system asa whole, but for each component techniqueand for each class of name.
These resultsshow that in order to have high recall, thesystem needs to make use not only of in-formation internal to the naming expressionbut also information from outside the nmne.They also show that the contribution of eachsystem component w~ries fl'om one (:lass ofname expression to another.1 In t roduct ionThe appropriate treatment of proper names is es-sential in a natural language understanding sys-tem which processes unedited newswire text, sinceup to 10 % of this type of text may consist ofproper names (Coates-Stephens, 1992).
Nor is itonly the sheer volume of names that makes themimportant; for some applications, such as inform-ation extraction (IE), robust handling of propernames is a prerequisite for successflflly performingother tasks such as template filling where correctlyidentifying the entities which play semantic rolesin relational frames is crucial.
Recent research inthe fifth and sixth Message Understanding Con-ferences (MUC5, 1993) (MUC6, 1995) has shownthat the recognition and classification of propernames in business newswire text can now be doneon a large scale and with high accuracy: the suc-cess rates of the best systems now approach 96%.We have developed an IE system - LaS I f(Large Scale Information Extraction) (Gaizauslmsct al, 1995) which extracts important facts fromtmsiness newswire texts.
As a key part of theextraction task, the system recognises and clas-sifies certain types of naming expressions, namelythose specified in the MUC-6 named entity (NE)task definition (MUC6, 1995).
These include or-ganisation, person, and location names, time ex-pressions, percentage xpressions, and monetaryamount expressions.
As defined for MUC-6, thefirst three of these are proper names, the fourthcontains some expressions that would be classi-fied as proper names by linguists and some that;would not, while the last two would generally notbe thought of as proper names.
In this paper weconcentrate only the behaviour of the LaSIE sys-tem with regards to recognising and classifying ex-pressions in the first four classes, i.e.
those whichconsist entirely or in part of proper names (thoughnothing hangs on omitting the others).
The ver-sion of the system reported here achieves ahnost92% combilmd precision and recall scores on thistask against blind test data.Of course the four name classes mentioned arenot the only classes of proper names.
Brandnarnes, book and movie names, and ship namesare .just a few further classes one might chose toidentify.
One might also want to introduce sub-classes within the selected classes.
We have notdone so here for two reasons.
First, and foremost,in order to generate quantitative valuation res-ults we have used tile MUC-6 data and scoring re-sources and these restrict us to the above propername classes.
Secondly, these four name classesaccount for the bulk of proper name occurrencesin business newswire text.
Our approach couldstraightforwardly be extended to account for ad-ditional classes of proper nalnes, and the pointswe wish to make about tile approach can be ad-equately presented using only this restricted set.Our approach to proper name recognition isheterogeneous.
We take advantage of grapholo-gical, syntactic, semantic, world knowledge, anddiscourse level information to perform the task.
Inthe paper we present details of the approach, de-scribing those data and processing componm~ts ofthe overall IE system which contribute to propername recognition and classification.
Since name418recognition and classification is achieved throughthe activity of four successive components in thesystem, we quantitatively ewfluate tile successivecontribution of each comt)onent in our overall ap-proach.
We perform this analysis not only forall classes of names, but for each class separately.The, resulting analysis1.
supports McDonald's obse, rvation (McDoi>aid, 1993) that external evidence as well as in-ternal evidence is essential for achieving highprecision and recall ill the recognition andclassification task; i.e.
not just the namestring itself must be examined, but other in-formation in the text must be used as well;2. shows that all eoInponents in our heterogen-eous apt)roach contribute significantly;3. shows that not all classes of prot)er nainesbenefit equally h'om the contritmtions of thedifferent colnponents in our system: in par-ticular, organisation ames t)enefit most fromthe use of external evidence.In tile second section an overview of the I,aSIEsystem is presented.
The third section explainsin detail how proper names are reeognised andclassified in the system.
The results of evaluatingthe system on a blind test set; of 30 articles arepresented and discussed in section 4.
Section 5concludes the paper.2 LaSIE system overviewNel l l i l l l t~  --.
.
.
.
.
.
.
.
.
.
.
.
i l i a /  -- _N ~ _ .
_ -  N I "~q .......... N { TeC'e'l');;;"~ \[ \[ "e , ,,7\[ .~  P.e!ul~/"~ - ~ _ ~ t~vAelnents~JFigure 1: LaSIE Systeln ArchitectureLaSIE has been designed as a general tmrpose IEresearch system, initially geared towards, but notsolely restricted to, carrying out the tasks spe-cified by the sixth Message Understanding Confe, r-ence: named entity recognition, coreference resol-ution, template lement illing, and scenario tem-plate filling tasks (see (MUC6, 1995) for fllrtherdetails of the task descriptions).
In addition, thesystem can generate a brief natural anguage sum-mary of the scenario it.
has detected in the text.All of these tasks are carried out by building asingle rich inodel of the text the discourse modelfrom which the various results are read oil.Tile high level structure of LaSIE is illustratedin F igure  1.
The system is a pipelined archi-tecture which processes a text sentence-at-a-timeand consists of three principal processing stages:lexical preproeessing, parsing plus semant;ic inter--pretation, and discourse interpretation.
The over-all contributions of these stages may be brieflydescribed as follows:?
lexlcal  p reproeess ing  reads and tokenisestile raw inlmt text, tags the toke, ns withparts-of-speech, t)e, rforms morI)hological ana-lysis, Imrtbrms phrasal matching against listsof proper names, and builds lexical andphrasal chart edges in a h'.ature-based form-alism for hand-over to the parser;?
pars ing  does two pass parsing, pass one witha special proper name grairlmal'~ pass twowith a general grammar and, after selecting a'best parse', passes on a semantic represent-ation of the current senteliC(~ which includesnanle clans infi)rmation;?
d iscourse in terpretat ion  adds the inform-ation ill its input semantic representation to ahierarchically structured selnantic ne, t whichencodes the system's world model, adds ad-ditional ilffOl',natioi1 presupposed by the in-put to the world model, perforlns coreferenceresolution be, tween new instances added andothers already ill the world model, and addsinformation consequent upon the addition ofthe input to the worhl Inodel.For fltrther det~fils of the systeln see (Gaizauskasct al, 1.995).3 How proper  names  arerecognised and classifiedAs indicated in section 1, our approach is a het-erogeneous one ill which the system makes useof graI)hological, syntactic, selnantic, world know-ledge,, and discourse level intb,'mation for the re-cognition and classification of proper names.
Thesystem utilises both the information which comesfl'oln the name itse.lf (internal evidence ill McDon-ald's sense (McDonaht, 1993)) as well as tile in-formation which colnes from outside, the name,froln its context in the text: (external evidence).In what tbllows we describe how proper namesare recognised and classified in LaS IE  by consid-ering the contribution of each system component.3.1 Lexieal  p reproeess ingThe input text is first tokenise.d and then eachtoken is tagged with a part-of-stmech tag fromthe, Penn qtYeebank tagset (Marcus ct al, 1993) us-ing a slightly custolnised ~ version of Brill's tag-1The tagger has been:customised by adding someentries to its lexicon and by adding several special tags419ger (Brill, :1.994).
The tagset contains two tagsfin' proper nouns NNP for singular proper nounsand I~NPS for plurals.
The tagger tags a word as aproper noun as follows: if the word is timnd in thetagger's lexicon and listed as a proper noun thentag it, as such; otherwise, if the word is not foundin the lexicon and is uppercase initial then tagit as a proper noun.
Thus, capitalised unknowntokens are tagged as proper nouns by default.Before parsing an attempt is made to identi\[yproper naine phrases sequences of proper namesand to classify them.
This is done by matchingtile input against pre-stored lists of proper nalnes.The.se lists are compiled via a flex program into afinite state recogniser.
Each sentence is fed to therecogniser and all single and multi-word matchesare tagged with special tags which indicate thename (:lass.Lists of names used include:?
organisation : about 2600 company andgovernmental institution nmnes based onan organisation ame list which was semi-automatical ly collected from the MUC-5 an-swer keys and training corl)us (Wall StreetJournal articles);?
location : about 2200 major country,province~state, and city names derived fl'oma gazetteer list of about 150,000 place naines;?
person : about 500 given names taken Doma list; of given names in the Oxford AdvancedLe.arner's Dictionary (Hornby, 1980);?
eompmly designator : 94 designators (e.g.'Co. '
, 'PLC' ) ,  based on the company desig-nator list provided in the MUC6 reference re-sources.?
human titles : about 160 titles, (e.g.
'Presid-ent' , 'Mr. ')
,  manually collected;As well as name phrase matching, another tech-nique is applied at this point, inside multi-wordproper names, certain words m~y flmction as triq-get words.
A trigger word indicates that thetokens surrounding it are' probably a proper nameand may reliably pernfit the class or even sub-class 2 of tile proper nmne to be determined.
Forexample, 'Wing and l ' rwer  Airlines' is ahnost cer-tainly a company, given tile presence of the word'Airlines'.
~Digger words are detected by matchingagainst, lists of such words and are then speciallytagged.
Subsequently these tags are used by theproper nmne parser to build complex proper nameconstituents.The lists of trigger words are:?
AMine company: 3 trigger words for findingairline company names, e.g.
'Airlines';?
Governmental institutions: 7 trigger wordsfor governmental institutions, e.g 'Ministry';for word classes uch as days of the week and months.2company and governmental institution are sub-classes of the class organisation, airline is a sub-class of company.?
Location: 8 trigger words for location nanle, s,e.g.
'Gulf';?
Organisation: 135 trigger words for organisa-tion names, e.g 'Association'.These lists of trigger words were produced byhand, though the organisation trigger word listswere generated semi-automatical ly b  looking atorganisation ames in tile MUC-6 training textsand applying certain heuristics.
So, for example,words were (:ollected which come inmmdiately be-fore 'of'  in those organisation ames which eOll-tain 'of', e.g.
'Association' in ~Assoeiation of AirFlight Attendants' ;  l he last; words of organisationnames which do not contain 'of'  were examined tofind trigge.r words like ' International' .3.2  Grammar  ru les  lbr  proper  namesThe LaSIE parser is a simple bottom-up chartparser i inplemented in Prolog.
The grammars itprocesses are unification-style feature-based con-text, fl'ee grammars.
During parsing, semantic rep-resentations of constituents are constructed usingProlog terin unification.
When parsing {:eases, i.e.when the parser can generate no further edges, a'best parse selection' algorithm is rml on the finalchart to chose ~ single analysis.
The semanticsare then extracted fl'om this analysis trod passedon to the discourse interpreter.Parsing takes place in two passes, each usinga separate grammar.
In the first pass a spe-cial grammar is used to identify proper nanms.These constituents are then treated as unanalys-able units during the second pass which employsa more general 'sentence' grammar.Proper  Name Grammar  The grammar ulesfor proper names constitute a subset of the sys-tem's noun t)hrase.
(NP) rules.
All the rules wereprodu(:ed 1)y hand.
There are 177 such rules illtotal of which 94 are for organisation, 54 for per-son, 11 for location, and 18 for time exl)ressions.Here are some examt)les of the i)roper nmnegrammar ules:NP - ->  0KGAN NP0RGAN NP --> LIST_LOC NP NAMES_NP CDG NP0RGAN_NP --> LIST_0RGAN_NP NAMES NP CDG_NPORGAN_NP --> NAMES NP '&' NAMES_NPNAMES_NP --> NNP NAMES_NPNAMES_NP --> NNP PUNC(_) NNPNAMES NP --> NNPThe non-terminals LIST_LOCJNP~ LIST_0RGAN_NPand CDG~IP are tags assigned to one or lnor(~ in-put tokens in the name phrase tagging stage oflexical preproeessing.
The non-terminal NNP is thetag for proper name assigned to a single token bythe Brill tagger.The rule 0RGAN_hIP--> NAMES_NP '&' NAMES_NPmeans that if an as yet unclassified or ambigu-ous proper name (NANES~P) is followed by '&' andanother mnbiguous proper nmne, then it is an or-ganisation ame.
So, for example, 'Marks & Spell-420(:(n" and 'Amer ican Telct)hone & %le.gratth' willtie (:lassilicd as (/rganisat, i(m names by this rule.Nearly half of the t/rol)('x name rules ard for (n'-ganisat ion names be(:ausc they may contain fm-ther prOller name, s (e.g.
l/erson or location name, s)as well as normal  nomls, att(l their coml/inations.There arc Mso a good nmnb(~r of rules tilt' 1)(wsonnames sin(:c care must be taken with given names,family nmnes, t it les (e.g.
'Mr . '
, 'P res ident ' ) ,  andspecial lcxical i tems su(:h as 'de'  (as in 'J.
lgnacioLot)cz (1(,' Arr ior tua ' )  and ' J r . '
, ' I I ' ,  ct;(:.Thor(; are thwcr rules lin' location ttmnes, as th(!yare i(h;ntiti(*.d mainly in tim 1)r(!vious l)r(!l)rO(:(~ssingstage by lool<-ul / in tim miifi-gaz('.tt;e('a'.Sentence  (~rannnar  Ru les  The grammarused for l/arsing at the scnten(:e l(,.vel contains at/-t)roximately 1 l0 rules and was derived automat ic-at\[y from the Penn 3 i 'ceBank- l l  (PTB- I I )  (Marcusct al, 1993), (Mar('.us ct al, 1995).
When l larsingfor a senten(:e is (:omplet('.
the resultant chart ixanalysed to i(hmtitly the 'best parsC.
From tit(',best pars(', the.
associated selnal lt; i( :s ate ('.xtra(:t(;dto lie 1)ass(xl on to I;\]le dis('.om'sc int(~rl)r(%(;r.Rules for COml/()siti(ntally ('onstrut:ting s(mmnti(:representat ions were assigned t/y han(l t;() {,tmgrammar  rules.
F()r simple verbs and llotnls I;h(;mort)hologi('.al root is llSe(l as a in(~(ti(:at(~ natncill tim s('.nt;tllti(:s, and t(;llS(?
a l ld  lIlltll})Of fcatllt'(~,sare translat(,.d (tir(w.tly inl;o tll(', s(muult, i(: l'ellrCs-(rotation where, ai)l)ropriat(;.
F(/r \[latnc(l ci,\[;i\[;-ies a t(/kcn (if the most siiccific tyi)c 1)ossiblc(e.g.
company or perhaps only ob jec t )  is ere-aged and a name attr it)ute ix associated with theentity, the a ttritlute?s vahm being the, SllrBtc(~string form of th(.'
name.
St), \['or examtlh b its-stoning 'Ford Mol;or Co.' has ah'eady I)('.cn (:las-si\[ie(l as a c(nnl)any nam(~, its scmanti(: rei)r(~s-(,ntation will be something like company(e23)  &name(e23, 'Ford  Motor  Co . '
) .a.a  D iscourse  in ter l ) re ta t ionThe discourse inl;('.rt)r(,t;(w too(hilt performs twoa(:l;ivities l;ha\[; (:(nttribute to t)roper name (:lassi-f ication (no fllrth(;r rc(:ogniti(m of pr(/1)(!r ll&nlcsgoes on at this point, only a rctlning of theirclassification).
The first a(:tivity is (',orcf(~rcnc(,'resolution an unclassified name may bc core-fcrr(;d wil;h t~ previously classified one tly virtue ofwhich the (:lass of the unclassifi('.d name.
b(,.(:om(;sknown.
The second activity, whi(:h is arguablynot l/rolterly '(lis(:ourse intcrilr(.
't;ation' but never-t, heh'~ss takes tllac(', in this module, is t(/tier form in-f(;ren(:(;s al/(/ut, the s(;manti(: I;yl)eS of al'glllnCtll;S iIl(:crtain reladons; for example,  in comtl(nmd n(/m-inals such as 'Er ikson stocks' our s('.mantic inter-1)retcr will tell us that the, re is a qnalitier relat ionl/ctwcen 'Er ikson'  and 'stocks'  and sin(:e the sys-tem stores the fact thai; named entit ies qualifyingthings of type s tock  are, of type company it canclassil~y the i)roper name 'l@ikson ~ as a (:Oral)any.Note that  both of these tcctmiques Inake use ofexternal  evidence, i.e.
rely on information sup-plied by the.
(:ontext beyond the words in th('.
in-stance of the proper name being classilic(l."1.3.1 Proper  name core ference(~orcfcr(mcc rcsolul;ion for i)ropcr names is car-ried out in or(let to rtx:ognis() alternativ(', forms,(;specially of otganisat ion ames.
For cx~mq)le.,,Ford Motor Co.' might lm used in a text whimth(,' ( :ompa l ly  iS first mentioned, but~ subscquc.nl~ref('xenccs are likely to b(; to 'For(t'.
Similarly,' (beat ivc  Art ists Agency'  might lm al)bre, v iated to%',At\' lat(n ()it in th(; same Lexl;.
~qltch s\]lorttumd\['(Wills lllllS\[; 1)O l 't;solvett aS llall iOs of  t;h('..qmn(' o fganisi~t;ion.In or(let t(l (h%('.rmin(,.
wlmther giv(m two prolmrIDl.l\[l(~S ttntl;t:h, vatiOllS hem'istics are used.
For c,x-aant)lc , given two itg:l.ln(~,s, Rain(<\[  aI lt l  Nmnc2:?
if Name2 is consists (if an init ial SllbSt!
(lllClt(:(,,of th(; words in Namel  then Name2 matctmsNamel  t'..g. 'Amer ican Airl ines Co.' aud'Anw.rican AMines' ;?
if Nalne \ ]  is a 1)Cl'S()ii ltall/(~ ant i  Name2 is(qth(w the first, tim family, or 1)()l;h nanms (ifNam(<l, then Name2 niat(:hes Nanml  e.g.
',lohn .I.
Major  .h. '
lind ', lohn Major'.There are 31 such heurist ic ruh~s for match-lug organisat ion ames, I \] tmuristi(:s for 1)(ns(/nnames, ;m(t 3 rules lbr h/(:al;ion names.Wh(',n an un(:lassified t/rolmr noun is matchedwith a previously classil ied proper  llatn( ~, ill thetext, it is marke(l as a tn'(/p(',r name of the (:lassof  th(  ~, kllOWt\] l ) rop(;r  ltai\[lO.
Thl lS ,  whe l l  w(~ know'Ford Motor  Co.' is an organisati(m name bil lhave n(/t (:lassificd 'F(/rd' in the same text,  (:or(>f(w('.n(:(', resolution (let(~rmin('.s 'Ford '  to lie an or-ganisi~tion ame.3.3 .2  Semant ic  Type  ln l i~xence\ [n t,h(; f '(/ l lowing (;onl;(~xl,q, se.nmnd(; l yI)e inf()l'tIt-al;ion al)olll; th(; tyI/eS of il, t'gllln(~ll\[;S ill ('.
(!rl;ain re-lad(ms is used to (lriv(; illfCl(?llt;Cs permit t ing thedassit icat ion of prt)lmr nanlcs.
The sysl;cltt llSeSthes(~ t;et:hnittucs in a fairly l infited and ext)eri-mental  way ill; l/resent, and there ix much roomf(n their (',xtcnsi(m.?
nOllll-itOlllt qllalificati(m: when an un(:\]assi-.tled t)rot)(!r nanle qualifies ttlt organisat ion-related thing then the name is c, lassifie(l itsan orga.nisation; e.g.
in 't,h'i(:kson sl;o(:ks'sin(:c 'sl;(/(:k' ix scmanti(:al ly tyt/ed as anorganisation-r(~qa(;(!
(t dfing, 'Er ickson'  get;s(:lassiticd as an organisat ion ame.?
t/ossessivcs: when an un(:\[assitic(l prol lerll;I.Ill(~ stands in a possessive r(;lation to a.n (/r-ganisat ion post, then th(, ~ name is classiti(xl asall organisation; e.g.
'vice l/resident of ABC' ,'ABC 's  v ice  1)resi(h',nt'.?
at ) I ios i t ion : when an unclassil ied propername ix apt/(/s('.d with a known locati(m nanm,421the former name is also classified as a loca-tion; e.g.
given 'Fort Lauderdale, Fla.' if weknow 'Fla.'
is a location name, 'Fort Lauder-dale' is also classified as a location name.
* verbal arguments: when an unclassifiedproper name names an entity playing a rolein a verbal fi'ame where the semantic typeof the argument position is known, then thename is classified accordingly; e.g.
in 'Smithretired from his position as .
.
. '
we (:an inferthat 'Smith' is a person name since the se-mantic type of the logical subject of 'retire'(in this sense) is person.4 Resu l ts  and Evaluat ionAfter these processing stages, the results gener-ator produces a version of the original text inwhich all the proper names which have been detec-ted are marked up with pre-defined SGML tags,specifying their classes.
These marked up textsare then automatically scored against manuallymarked up texts.A series of evaluations has been done on tilesystem using a blind test set consisting of 30 WallStreet Journal texts.
In these texts there are 449organisation ames, 373 person names, and 110location names and 111 time expressions in total.The overall precision and recall scores for the fourclasses of proper naines are shown in Table 1.Proper Naine Class Recall PrecisionOrganisation 91% 91%l'erson 90 % 95 %Location 88 % 89 %Time 94 % 97 %Overall 91% 93 %Table 1: Overall Precision and Recall Scores4.1 System modu le  cont r ibut ionWe have analysed tile results in terms of howmuch each module of the system contributes tothe proper nmne task.Table 2 illustrates the contribution of each sys-tem module to the task for all classes of propernames.
In addition to recall and t)recision scores,we have added Van Rijsbergen's F-measure whichcombines these scores into a single measure (Rijs-bergen, 1979).
The F-measure (also called P&R)allows the differential weighting of precision andrecall.
With precision and recall weighted equallyit is computed by the formula:2 x Precis ion x RecallF=Precis ion + RecallThere are tour different settings of the system.?
se t t ing  1 : Only the lexical preprocessingteehifiques are used tmrt-of-speeeh taggingand name phrase matching.?
se t t ing  2 : Two-stage parsing is added to 1.?
set t ing 3 : Coreference resolution for propernames is added to 2.?
se t t ing  4 : Full discourse interpretation isadded to 3.
This is the full-fledged systemSetting1 ~\ [ -Reca l l  I P rec i s i ?n49  N 89~ 7-?
-N  94~ ~ A  94Table 2: Module Contribution ScoresTable 2 shows thai; we can attain reasonableresults using tagging, exact, phrase matching, trig-ger word detection, and parsing (setting 2).
Notethat this amounts to making use of only internalevidence.
However, to achieve higher recall, weneed coreference r solution for proper names (set-ting 3) and other context information (setting 4).4.2 Dif ferent classes of  p roper  namesWe have also examined how the contribution ofeach component varies from one class of propernanm to another.For organisation names, using the same settingsas above, scores are shown in Table 3.Setting Recall Precision P&R1 46 87 59.912 65 92 76.153 87 93 89.844 91 91 91.13Table 3: Module Contributions for Org NamesFor person names, location names and time ex-pressions the results are shown in Tables 4-6.Precision1 47 88 61.642 89 95 92.343 90 95 92.144 90 95 92.14Table 4: Module Contrilmtions for Person NamesF igure  2 shows graphically how the systemcomponents contribute for each of the four dif-ferent classes of proper names as well as for allclasses combined.5 Conc lus ionWe have described an IE system in which fourclasses of naming expressions (organisation, per-son, and location names and time expressions) arerecognised and classified.
The system was testedOil 30 unseen Wall Street Journal texts and theresults were analysed in terms of inajor systemcomponents and ditti~rent (:lasses of referring ex-pression.422h ... .
.
- J - -SF -d - -%4- - - I  86_s4 \]a- -  8,?
- 8L sa\]a - - -  ~ 88-  \] -89  _ r88 .58- JTable 5: Module Contributions for Location Names\[ I .
.
.
.
.
d__ 32 d 100 \] 4S.97~\[2 .
.
.
.
~:-_T- 9 -4_ \ [  97- / , all\ [3  .
.
.
.
~_  94 A 97 \ ] ~k~ .
.
.
.
.
q -~, Jw~ ~ / 95.41 ITable 6: Module Contritmtions for Time ExpressionsTab les  3-6  an<t F igure  2 enabh; us to make.the following observations:\].
Techniques relying on internal cwich;n(:c, only?
e, xac:t word and phrase mat, thing, gral)holo-gic:al conventions, and t)arsing m'e not mlf-ficient, t;o re ( :ogn ise  and (:lassi(y organisal;ionnames.
It is clear l;hal; in order to have highrecall for organisation ames, we need 1;o l)e;rifle to make good use, of exWxnal evidenceas well, i.e.
proper IlalSlO (;or(i'(;r(,,n(:(~ to,so lul, ion and information fl'c>m t;he sm'rounding(:onl;0,xI;.2.
On tim ol;her han(l, for person an(t lo(:ationnames and time (;xprc',ssions, 1;echni(lueS rely-ing soMy on inl;ernal evi<h',nc(!
<1o t)e, rmil; us1;o atl;ain high recall whilst maint, aining highprecision.
Thus, the <:ontribution of difl'ercntsystem coillt)OIlenl;s vm'ies fl'om one (:lass oft)rot)(;r name l;o anol;hcr.3.
I\[owever, giw',n that in a reasonable sampleof business newswire text, 43 % of @c t)s'ot)ernames are oigalfisal;ion names, it is (wi<l(m(;that for a sysLcm I;o achieve high overall pre-cision and re.
(:all in the!
name rec:ognil;ion and(:lassific:al;iol~ (;ask on this (;ext 1;yi)(~,, il; must;utilise not only inl, ernal evidence bul ;  also ex-ternal (;viden(:c.More generally, I;wo (;Oll(:hlsiOSlS can Is(,, ds&Wll.First, the results l)r(;s(mt(',d al)ove suggesl; t;hal;when a sysl;em fc)r t)rot)er IlalSl(!
l'(;(;OgSlii;iosl an<l/orc;lassificat;ion is evaluatc'd, mu('.h I)en(;fil: (:an t)egained by analysing il; not only in t;erms of ovea'-all recall and pre,<:ision tigures, 1)ut; also in terms ofsys l ; ( ;S l l  COS l l l )OS le l l l ;S  & l id  class<',s of I l a l I ICS .
S( : ( ;OS I ( I~a heterogeneous approach l;o l;he r(',cognit;ion an(lclassifi(:ation of t)l.'Ot)c'r names in n(,,wswir(; |;o, xl;such as describ(xt here is at)t)r<)priat;(,' sin<:e il;provides me, chanisms thai; can utilis(; the variety ofinternal and external evidence which is availableand which needs t,o b(; taken inl;o a(:(;ounl;.6 AcknowledgementsThis resear(-h has 1)ceil made, l)ossil)le l)y I;hegt'ant, s from t;h(; U.K. \])cl)artln('Jl|; ()f rl'ra<l('~ andF measures (I'&R)Ovmalle95.00 , ~: ...................... ~t ........................ x/,+  47 " Organfisalion,)o.+ ............... i .................... ~'?
^ t ~ ,~5, (}{)  ?
.
.
.
.
.
.
I: .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
!
: : 2 PeI SOili ) , "  is0,+ { ............... ) ..... ......... <......... !
.
.
.
.
.
.
.
.
.
?t - "  !
\[ ,OCltliOll75.00 : ~ , m '  i V  ^70.
(x) ,' ,'" Time6 /65JX) / .
.
.
.
.
.
.
~ ................... ....t , , '+  60.
{10 ................... ~ .............................. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.i5s.m) / .
.
.
.
.+ !50.00 +;v' .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.I 2 3 4 Se l l ingl,isI IookLLp IAst I (ilallllllalt Nallle COlCl~MellCel,ist I {;l\[Itll\[ll\[\[I I;Ul\] sysIclIIFigure 2: C<ml,rilml,ion of Syst,em (~OlStl)on(~,nl;s\]n(hlstry ((;ranl; Ref.
YA\],;/8/5/1002) aml the En-ginc<;ring an(t l)hysical Sci('.nce.
l{escarch Council((;,.am; # (mlKZ~2(;7).ReferencesBrill, E. (1994).
"S<)me Advances in ~hansfc>Imat;i(>nBased Parl; of Spee<:h Tagging."
In l'roc.
AAAL(?oates-Sl;e4)he.ns, S. (19/)2).
The Analysi,~ and Acq'u, is-ition of I'Tvp('.r Names for l~obust Text Understand..ing.
Phi) thesis, Department of Comlmtea: S<:i(mce,City Univcrsii;y, lxm(hm.Gaizauskas, 1L; Wakao, T.; Humphreys, K.; Cmming-ham, It.
and Wilks, Y.
(1995).
"Universii;y ofSheffield: Dcsc,iption of LaSIE system as used fl)rMUC-6."
In Proceedings of the Sixth Mcssag<'~ Un-derstandin 9 Confc/rc'ucc (MUG-6), Morgan I (aufl\[l~t?II.H<>rn|,y A.S.
led.).
(1980).
Oafo'rd Advo, ncedLearner's Dictio'n.ary of (Iv, trent E'r~.qIish.
l,on<hm:()xford University lhess.Marcus, M.; Santorini, 13. and Marcinkiewicz, M.A.(1993).
"I}uihling a l,a.rge Annotated (?<)rims ofl'htglish: The l'(mn '.lh:e(;bmtk."
Computational l,i'n,.~.quistics, 19 (2): 313 aao.Marcus, M.; K im,  (4; Mar<:inkiewicz, M.A.
;Ma(:InWre, ll,.
; Bies, A.; Ferguson, M.; Katz, K.an(l S<:hasl)erger, B.
(1995).
"The Prom Trcel)mtk:Annotating Predicate Argument Stru(:t, ure."
Dis-trilmt(;<l on The: INmn q?
('.ebank lh;lcase 2 CI)-R()Mby the Linguistic Data Consortium.McDonald, 1).1).
(1993).
"Internal mt<t Exl;ermflFvidence in l ie hhml,ification and S(unant;ic Cat:egorisati<m of Proper Names."
In l)t'occ, dingsof ,qlG'Ll(X 'wo'ckshop o'u "Acqui.sition of lm:cicalKnowh'&tc fl'om T<d,", pp.
32 43.M-U(J-5.
(1993).
l",'occcdings of the Fifth, Message Un-dc.rstandinfl Conference (MUC-5).
Morgan Kauf-I l l& I I .MUC:6.
(1995).
l'roceedin\[ls of the Sixth M(:s,sage U'n,-dcrsta'udi'n,g Co'ufe'rcnce (MUG-6).
Morgan Kaut~l l l } I J l ,Van \]{ijsl)ergen, (J.J. (1979).
Information lh,,trie,val.l,ondon: Butlaerworl;hs.423
