Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 233?238,Baltimore, Maryland USA, June 26?27, 2014. c?2014 Association for Computational LinguisticsDomain Adaptation for Medical Text Translation Using Web Re-sourcesYi Lu, Longyue Wang, Derek F. Wong, Lidia S. Chao, Yiming Wang, Francisco OliveiraNatural Language Processing & Portuguese-Chinese Machine Translation Laboratory,Department of Computer and Information Science,University of Macau, Macau, Chinatakamachi660@gmail.com, vincentwang0229@hotmail.com,derekfw@umac.mo, lidiasc@umac.mo, wang2008499@gmail.com,olifran@umac.moAbstractThis paper describes adapting statisticalmachine translation (SMT) systems tomedical domain using in-domain andgeneral-domain data as well as web-crawled in-domain resources.
In order tocomplement the limited in-domain corpo-ra, we apply domain focused web-crawling approaches to acquire in-domain monolingual data and bilinguallexicon from the Internet.
The collecteddata is used for adapting the languagemodel and translation model to boost theoverall translation quality.
Besides, wepropose an alternative filtering approachto clean the crawled data and to furtheroptimize the domain-specific SMT sys-tem.
We attend the medical summarysentence unconstrained translation task ofthe Ninth Workshop on Statistical Ma-chine Translation (WMT2014).
Our sys-tems achieve the second best BLEUscores for Czech-English, fourth forFrench-English, English-French languagepairs and the third best results for re-minding pairs.1 IntroductionIn this paper, we report the experiments carriedout by the NLP2CT Laboratory at University ofMacau for WMT2014 medical sentence transla-tion task on six language pairs: Czech-English(cs-en), French-English (fr-en), German-English(de-en) and the reverse direction pairs (i.e., en-cs,en-fr and en-de).As data in specific domain are usually rela-tively scarce, the use of web resources to com-plement the training resources provides an effec-tive way to enhance the SMT systems (Resnikand smith, 2003; Espl?-Gomis and Forcada, 2010;Pecina et al., 2011; Pecina et al., 2012; Pecina etal., 2014).
In our experiments, we not only useall available training data provided by theWMT2014 standard translation task 1 (general-domain data) and medical translation task2 (in-domain data), but also acquire addition in-domain bilingual translations (i.e.
dictionary) andmonolingual data from online sources.First of all, we collect the medical terminolo-gies from the web.
This tiny but significant par-allel data are helpful to reduce the out-of-vocabulary words (OOVs) in translation models.In addition, the use of larger language modelsduring decoding is aided by more efficient stor-age and inference (Heafield, 2011).
Thus, wecrawl more in-domain monolingual data from theInternet based on domain focused web-crawlingapproach.
In order to detect and remove out-domain data from the crawled data, we not onlyexplore text-to-topic classifier, but also proposean alternative filtering approach combined theexisting one (text-to-topic classifier) with per-plexity.
After carefully pre-processing all theavailable training data, we apply language modeladaptation and translation model adaptation us-ing various kinds of training corpora.
Experi-mental results show that the presented approach-es are helpful to further boost the baseline system.The reminder of this paper is organized as fol-lows.
In Section 2, we detail the workflow ofweb resources acquisition.
Section 3 describesthe pre-processing steps for the corpora.
Section5 presents the baseline system.
Section 6 reportsthe experimental results and discussions.
Finally,1 http://www.statmt.org/wmt14/translation-task.html.2 http://www.statmt.org/wmt14/medical-task/.233the submitted systems and the official results arereported in Section 7.2 Domain Focused Web-CrawlingIn this section, we introduce our domain focusedweb-crawling approaches on acquisition of in-domain translation terminologies and monolin-gual sentences.2.1 Bilingual DictionaryTerminology is a system of words used to namethings in a particular discipline.
The in-domainvocabulary size directly affects the performanceof domain-specific SMT systems.
Small size ofin-domain vocabulary may result in seriousOOVs problem in a translation system.
Therefore,we crawl medical terminologies from someonline sources such as dict.cc3, where the vocab-ularies are divided into different subjects.
Weobtain the related bilingual entries in medicinesubject by using Scala build-in XML parser andXPath.
After cleaning, we collected 28,600,37,407, and 37,600 entries in total for cs-en, de-en, and fr-en respectively.2.2 Monolingual DataThe workflow for acquiring in-domain resourcesconsists of a number of steps such as domainidentification, text normalization, language iden-tification, noise filtering, and post-processing aswell as parallel sentence identification.Firstly we use an open-source crawler, Com-bine4, to crawl webpages from the Internet.
Inorder to classify these webpages as relevant tothe medical domain, we use a list of triplets<term, relevance weight, topic class> as thebasic entries to define the topic.
Term is a wordor phrase.
We select terms for each languagefrom the following sources:?
The Wikipedia title corpus, a WMT2014 of-ficial data set consisting of titles of medicalarticles.?
The dict.cc dictionary, as is described in Sec-tion 2.1.?
The DrugBank corpus, which is a WMT2014official data set on bioinformatics andcheminformatics.For the parallel data, i.e.
Wikipedia and dict.ccdictionary, we separate the source and target textinto individual text and use either side of themfor constructing the term list for different lan-3 http://www.dict.cc/.4 http://combine.it.lth.se/.guages.
Regarding the DrugBank corpus, we di-rectly extract the terms from the ?name?
field.The vocabulary size of collected text for eachlanguage is shown in Table 1.EN CS DE FRWikipedia Titles 12,684 3,404 10,396 8,436dict.cc 29,294 16,564 29,963 22,513DrugBank 2,788Total 44,766 19,968 40,359 30,949Table 1: Size of terms used for topic definition.Relevance weight is the score for each occur-rence of the term, which is assigned by its length,i.e., number of tokens.
The topic class indicatesthe topics.
In this study, we are interested inmedical domain, the topic class is always markedwith ?MED?
in our topic definition.The topic relevance of each document is cal-culated5 as follows:?
?
(1)where is the amount of terms in the topic defi-nition;is the weight of term  ;is theweight of term at location  .
is the number ofoccurrences of term  at  position.
In implemen-tation, we use the default values for setting andparameters.
Another input required by the crawl-er is a list of seed URLs, which are web sites thatrelated to medical topic.
We limit the crawlerfrom getting the pages within the http domainguided by the seed links.
We acquired the listfrom the Open Directory Project6, which is a re-pository maintained by volunteer editors.
Totally,we collected 12,849 URLs from the medicinecategory.Text normalization is to convert the text ofeach HTML page into UTF-8 encoding accord-ing to the content_charset of the header.
In addi-tion, HTML pages often consist of a number ofirrelevant contents such as the navigation links,advertisements disclaimers, etc., which may neg-atively affect the performance of SMT system.Therefore, we use the Boilerpipe tool(Kohlsch?tter et al., 2010) to filter these noisydata and preserve the useful content that ismarked by the tag, <canonicalDocument>.
Theresulting text is saved in an XML file, which willbe further processed by the subsequent tasks.
Forlanguage identification, we use the language-detection7 toolkit to determine the possible lan-5http://combine.it.lth.se/documentation/DocMain/node6.html.6 http://www.dmoz.org/Health/Medicine/.7 https://code.google.com/p/language-detection/.234guage of the text, and discard the articles whichare in the right language we are interested.2.3 Data FilteringThe web-crawled documents (described in Sec-tion 2.2) may consist a number of out-domaindata, which would harm the domain-specific lan-guage and translation models.
We explore andpropose two filtering approaches for this task.The first one is to filter the documents based ontheir relative score, Eq.
(1).
We rank all the doc-uments according to their relative scores and se-lect top K percentage of entire collection for fur-ther processing.Second, we use a combination method, whichtakes both the perplexity and relative score intoaccount for the selection.
Perplexity-based dataselection has shown to be a powerful mean onSMT domain adaptation (Wang et al., 2013;Wang et al., 2014; Toral, 2013; Rubino et al.,2013; Duh et al., 2013).
The combination methodis carried out as follows: we first retrieve thedocuments based on their relative scores.
Thedocuments are then split into sentences, andranked according to their perplexity using Eq.
(2)(Stolcke et al., 2002).
The used language modelis trained on the official in-domain data.
Finally,top N percentage of ranked sentences are consid-ered as additional relevant in-domain data.
( )( )(2)where  is a input sentence or document,  ( ) isthe probability of  -gram segments estimatedfrom the training set.
is the number oftokens of an input string.3 Pre-processingBoth official training data and web-crawled re-sources are processed using the Moses scripts8,this includes the text tokenization, truecasing andlength cleaning.
For trusecasing, we use both thetarget side of parallel corpora and monolingualdata to train the trucase models.
We consider thetarget system is intended for summary translation,the sentences tend to be short in length.
We re-move sentence pairs which are more than 80words at length in either sides of the parallel text.In addition to these general data filtering steps,we introduce some extra steps to pre-process thetraining data.
The first step is to remove the du-plicate sentences.
In data-driven methods, themore frequent a term occurs, the higher probabil-8 http://www.statmt.org/moses/?n=Moses.Baseline.ity it biases.
Duplicate data may lead to unpre-dicted behavior during the decoding.
Therefore,we keep only the distinct sentences in monolin-gual corpus.
By taking into account multipletranslations in parallel corpus, we remove theduplicate sentence pairs.
We also use a biomedi-cal sentence splitter9 (Rune et al., 2007) to splitsentences in monolingual corpora.
The statisticsof the data are provided in Table 2.4 Baseline SystemWe built our baseline system on an optimizedlevel.
It is trained on all official in-domain train-ing corpora and a portion of general-domain data.We apply the Moore-Lewis method (Moore andLewis, 2010) and modified Moore-Lewis method(Axelrod et al., 2011) for selecting in-domaindata from the general-domain monolingual andparallel corpora, respectively.
The top M per-centages of ranked sentences are selected as apseudo in-domain data to train an additional LMand TM.
For LM, we linearly interpolate the ad-ditional LM with in-domain LM.
For TM, theadditional model is log-linearly interpolated withthe in-domain model using the multi-decodingmethod described in (Koehn and Schroeder,2007).
Finally, LM adaptation and TM adapta-tion are combined to further improve the transla-tion quality of baseline system.5 Experiments and ResultsThe official medical summary development sets(dev) are used for tuning and evaluating thecomparative systems.
The official medical sum-mary test sets (test) are only used in our finalsubmitted systems.The experiments were carried out with theMoses 1.010 (Koehn et al., 2007).
The translationand the re-ordering model utilizes the ?grow-diag-final?
symmetrized word-to-word align-ments created with MGIZA++11 (Och and Ney,2003; Gao and Vogel, 2008) and the trainingscripts from Moses.
A 5-gram LM was trainedusing the SRILM toolkit12 (Stolcke et al., 2002),exploiting improved modified Kneser-Neysmoothing, and quantizing both probabilities andback-off weights.
For the log-linear model train-ing, we take the minimum-error-rate training(MERT) method as described in (Och, 2003).9 http://www.nactem.ac.uk/y-matsu/geniass/.10 http://www.statmt.org/moses/.11 http://www.kyloo.net/software/doku.php/mgiza:overview.12 http://www.speech.sri.com/projects/srilm/.235In the following sub-sections, we describe theresults of baseline systems, which are trained onthe official corpora.
We also present the en-hanced systems that make use of the web-crawled bilingual dictionary and monolingualdata as the additional training resources.
Twovariants of enhanced system are constructedbased on different filtering criteria.5.1 Baseline SystemThe baseline systems is constructed based on thecombination of TM adaptation and LM adapta-tion, where the corresponding selection thresh-olds ( ) are manually tuned.
Table 3 shows theBLEU scores of baseline systems as well as thethreshold values of for general-domain mono-lingual corpora and parallel corpora selection,respectively.By looking into the results, we find that en-cssystem performs poorly, because of the limitedin-domain parallel and monolingual corpora(shown in Table 2).
While the fr-en and en-frsystems achieve the best scores, due the availa-bility of the high volume training data.
We ex-periment with different values of ={0, 25, 50,75, 100} that indicates the percentages of sen-tences out of the general corpus used for con-structing the LM adaptation and TM adaptation.After tuning the parameter  , we find thatBLEU scores of different systems peak at differ-ent values of .
LM adaptation can achieve thebest translation results for cs-en, en-fr and de-enpairs when  =25, en-cs and en-de pairs when=50, and fr-en pair when  =75.
While TMadaptation yields the best scores for en-fr and en-de pairs at  =25 and cs-en and fr-en pairs at=50, de-en pair when =75 and en-cs pair at=100.Lang.
Pair BLEUMono.
(M%)Parallel(M%)en-cs 17.57 50% 100%cs-en 31.29 25% 50%en-fr 38.36 25% 25%fr-en 44.36 75% 50%en-de 18.01 50% 25%de-en 32.50 25% 75%Table 3: BLEU scores of baseline systems fordifferent language pairs.5.2 Based on Relevance Score FilteringAs described in Section 2.3, we use the relevancescore to filter out the non-in-domain documents.Once again, we evaluate different values ofData Set Lang.
Sent.
Words Vocab.
Ave. Len.
Sites DocsIn-domainParallel Datacs/en 1,770,4219,373,482/10,605,222134,998/156,4025.29/5.99de/en 3,894,09952,211,730/58,544,6081,146,262/487,85013.41/15.03fr/en 4,579,53377,866,237/68,429,649495,856/556,58717.00/14.94General-domainParallel Datacs/en 12,426,374180,349,215/183,841,8051,614,023/1,661,83014.51/14.79de/en 4,421,961106,001,775/112,294,4141,912,953/919,04623.97/25.39fr/en 36,342,5301,131,027,766/953,644,9803,149,336/3,324,48131.12/26.24In-domainMono.
Datacs 106,548 1,779,677 150,672 16.70fr 1,424,539 53,839,928 644,484 37.79de 2,222,502 53,840,304 1,415,202 24.23en 7,802,610 199430649 1,709,594 25.56General-domainMono.
Datacs 33,408,340 567,174,266 3,431,946 16.98fr 30,850,165 780,965,861 2,142,470 25.31de 84,633,641 1,548,187,668 10,726,992 18.29en 85,254,788 2,033,096,800 4,488,816 23.85Web-crawledIn-domainMono.
Dataen 8,448,566 280,211,580 3,047,758 33.16 26 1,601cs 44,198 1,280,326 137,179 28.96 4 388de 473,171 14,087,687 728,652 29.77 17 968fr 852,036 35,339,445 718,141 41.47 10 683Table 2: Statistics summary of corpora after pre-processing.236={0, 25, 50, 75, 100} that represents the per-centages of crawled documents we used fortraining the LMs.
In Table 4, we show the abso-lute BLEU scores of the evaluated systems, listedwith the optimized thresholds, and the relativeimprovements (?%) in compared to the baselinesystem.
The size of additional training data (forLM) is displayed at the last column.Lang.PairDocs( %)BLEU?
(%)Sent.en-cs 50 17.59 0.11 31,065en-de 75 18.52 2.83 435,547en-fr 50 39.08 1.88 743,735cs-en 75 32.22 2.97 7,943,931de-en 25 33.50 3.08 4,951,189fr-en 100 45.45 2.46 8,448,566Table 4: Evaluation results for systems thattrained on relevance-score-filtered documents.The relevance score filtering approach yieldsan improvement of 3.08% of BLEU score for de-en pair that is the best result among the languagepairs.
On the other hand, en-cs pair obtains amarginal gain.
The reason is very obvious thatthe training data is very insufficient.
Empiricalresults of all language pairs expect fr-en indicatethat data filtering is the necessity to improve thesystem performance.5.3 Based on Moore-Lewis FilteringIn this approach, we need to determine the valuesof two parameters, top  documents and topsentences, where  ={100, 75, 50} and  ={75,50, 25},    .
When  =100, it is a conven-tional perplexity-based data selection method, i.e.no document will be filtered.
Table 5 shows thecombination of different  and  that gives thebest translation score for each language pair.
Weprovide the absolute BLEU for each system, to-gether with relative improvements (?%) thatcompared to the baseline system.Lang.PairDocs( %)TargetSize ( %)BLEU ?
(%)en-cs 50 25 17.69 0.68en-de 100 50 18.03 0.11en-fr 100 50 38.73 0.96cs-en 100 25 32.20 2.91de-en 100 25 33.10 1.85fr-en 100 25 45.22 1.94Table 5: Evaluation results for systems thattrained on combination filtering approach.In this shared task, we have a quality andquantity in-domain monolingual training data forEnglish.
All the systems that take English as thetarget translation always outperform the otherreverse pairs.
Besides, we found the systemsbased on the perplexity data selection methodtend to achieve a better scores in BLEU.6 Official Results and ConclusionsWe described our study on developing uncon-strained systems in the medical translation taskof 2014 Workshop on Statistical Machine Trans-lation.
In this work, we adopt the web crawlingstrategy for acquiring the in-domain monolingualdata.
In detection the domain data, we exploitedMoore-Lewis data selection method to filter thecollected data in addition to the build-in scoringmodel provided by the crawler toolkit.
However,after investigation, we found that the two meth-ods are very competitive to each other.The systems we submitted to the shared taskwere built using the language models and trans-lation models that yield the best results in theindividual testing.
The official test set is convert-ed into the recased and detokenized SGML for-mat.
Table 9 presents the official results of oursubmissions for every language pair.Lang.PairBLEU of CombinedsystemsOfficialBLEUen-cs 23.16 (+5.59) 22.10cs-en 36.8 (+5.51) 37.40en-fr 40.34 (+1.98) 40.80fr-en 45.79 (+1.43) 43.80en-de 19.36 (+1.35) 18.80de-en 34.17 (+1.67) 32.70Table 6: BLEU scores of the submitted systemsfor the medical translation task in six languagepairs.AcknowledgmentsThe authors are grateful to the Science andTechnology Development Fund of Macau andthe Research Committee of the University ofMacau for the funding support for their research,under the Reference nos.
MYRG076 (Y1-L2)-FST13-WF and MYRG070 (Y1-L2)-FST12-CS.ReferencesAmittai Axelrod, Xiaodong He, and Jianfeng Gao.2011.
Domain adaptation via pseudo in-domain da-ta selection.
In Proceedings of EMNLP, pages 355-362.237K.
Duh, G. Neubig, K. Sudoh, H. Tsukada.
2013.
Ad-aptation data selection using neural language mod-els: Experiments in machine translation.
In Pro-ceedings of the Annual Meeting of the Associationfor Computational Linguistics, pages, 678?683.M.
Espl?-Gomis and M. L. Forcada.
2010.
CombiningContent-Based and URL-Based Heuristics toHar-vest Aligned Bitexts from Multilingual Sites withBitextor.
The Prague Bulletin of MathemathicalLingustics, 93:77?86.Qin Gao and Stephan Vogel.
2008.
Parallel Imple-mentations of Word Alignment Tool.
Software En-gineering, Testing, and Quality Assurance for Nat-ural Language Processing, pp.
49-57.Kenneth Heafield.
2011.
KenLM: Faster and smallerlanguage model queries.
In Proceedings of theSixth Workshop on Statistical Machine Translation,pages 187-197.Papineni, Kishore, Salim Roukos, ToddWard, and-Wei-Jing Zhu.
2002.
BLEU: a method for automat-ic evaluation of machine translation.
In 40th Annu-al Meeting on Association for Computational Lin-guistics, ACL ?02, pages 311?318, Philadelphia,USA.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran et al.2007.
Moses: Open source toolkit for statisticalmachine translation.
In Proceedings of ACL, pages177-180.Philipp Koehn and Josh Schroeder.
2007.
Experi-ments in domain adaptation for statistical machinetranslation.
In Proceedings of the 2nd ACL Work-shop on Statistical Machine Translation, pages224-227.Christian Kohlsch?tter, Peter Fankhauser, and Wolf-gang Nejdl.
2010.
Boilerplate detection using shal-low text features.
In Proceedings of the 3rd ACMInternational Conference on Web Search and DataMining, pages 441-450.Robert C. Moore and William Lewis.
2010.
Intelli-gent selection of language model training data.
InProceedings of ACL: Short Papers, pages 220-224.Franz Josef Och.
2003.
Minimum error rate trainingin statistical machine translation.
Proceedings ofACL, pp.
160-167.Franz Josef Och and Hermann Ney.
2003.
A system-atic comparison of various statistical alignmentmodels.
Computational Linguistics, 29:19-51.P.
Pecina, A. Toral, A.
Way, V. Papavassiliou, P.Prokopidis, and M. Giagkou.
2011.
Towards UsingWebCrawled Data for Domain Adaptation in Sta-tistical Machine Translation.
In Proceedings of the15th Annual Conference of the European Associta-tion for Machine Translation, pages 297-304.P.
Pecina, A. Toral, V. Papavassiliou, P. Prokopidis, J.van Genabith,  and R. I. C. Athena.
2012.
Domainadaptation of statistical machine translation usingweb-crawled resources: a case study.
In Proceed-ings of the 16th Annual Conference of the Europe-an Association for Machine Translation, pp.
145-152.P.
Pecina, O.
Du?ek, L. Goeuriot, J.
Haji?, J.
Hla-v?
?ov?, G. J. Jones, and Z. Ure?ov?.
2014.
Adapta-tion of machine translation for multilingual infor-mation retrieval in the medical domain.
Artificialintelligence in medicine, pages 1-25.Philip Resnik and Noah A. Smith.
2003.
The Web asa parallel corpus.
Computational Linguistics,29:349?380Raphael Rubino, Antonio Toral, Santiago Cort?sVa?llo, Jun Xie, Xiaofeng Wu, Stephen Doherty,and Qun Liu.
2013.
The CNGL-DCU-Prompsittranslation systems for WMT13.
In Proceedings ofthe Eighth Workshop on Statistical Machine Trans-lation, pages 213-218.S?tre Rune, Kazuhiro Yoshida, Akane Yakushiji,Yusuke Miyao, Yuichiro Matsubayashi and Tomo-ko Ohta.
2007.
AKANE System: Protein-ProteinInteraction Pairs in BioCreAtIvE2 Challenge, PPI-IPS subtask.
In Proceedings of the Second BioCre-ative Challenge Evaluation Workshop, pp.
209-212.Andreas Stolcke.
2002.
SRILM-an extensible lan-guage modeling toolkit.
Proceedings of the Inter-national Conference on Spoken Language Pro-cessing, pp.
901-904.Antonio Toral.
2013.
Hybrid selection of languagemodel training data using linguistic informationand perplexity.
In ACL Workshop on Hybrid Ma-chine Approaches to Translation.Longyue Wang, Derek F. Wong, Lidia S. Chao, Yi Lu,and Junwen Xing.
2014.
A Systematic Com-parison of Data Selection Criteria for SMT DomainAdaptation.
The Scientific World Journal, vol.2014, Article ID 745485, 10 pages.Longyue Wang, Derek F. Wong, Lidia S. Chao, Yi Lu,Junwen Xing.
2013. iCPE: A Hybrid Data Selec-tion Model for SMT Domain Adaptation.
ChineseComputational Linguistics and Natural LanguageProcessing Based on Naturally Annotated Big Da-ta.
Springer Berlin Heidelberg.
pages, 280-290238
