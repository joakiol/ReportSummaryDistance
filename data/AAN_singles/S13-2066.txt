Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on SemanticEvaluation (SemEval 2013), pages 402?407, Atlanta, Georgia, June 14-15, 2013. c?2013 Association for Computational LinguisticsSINAI: Machine Learning and Emotion of the Crowd for SentimentAnalysis in MicroblogsE.
Mart?
?nez-Ca?maraSINAI research groupUniversity of Jae?nE-23071, Jae?n (Spain)emcamara@ujaen.esA.
Montejo-Ra?ezSINAI research groupUniversity of Jae?nE-23071, Jae?n (Spain)amontejo@ujaen.esM.
T.
Mart?
?n-ValdiviaSINAI research groupUniversity of Jae?nE-23071, Jae?n (Spain)maite@ujaen.esL.
A. Uren?a-Lo?pezSINAI research groupUniversity of Jae?nE-23071, Jae?n (Spain)laurena@ujaen.esAbstractThis paper describes the participation ofthe SINAI research group in the 2013 edi-tion of the International Workshop Se-mEval.
The SINAI research group hassubmitted two systems, which cover thetwo main approaches in the field of sen-timent analysis: supervised and unsuper-vised.1 IntroductionIn the last years, the sentiment analysis (SA) re-search community wants to go one step further,which consists in studying different texts thatusually can be found in commerce websites oropinions websites.
Currently, the users publishtheir opinions through other platforms, being oneof the most important the microblogging plat-form Twitter1.
Thus, the SA research commu-nity is focused on the study of opinions that userspublish through Twitter.
This interest is shown inseveral workshops focused on the study of SA inTwitter:1.
RepLab 2012 at CLEF2 (Amigo?
et al2012): Competition carried out within theCLEF conference, where the participantshad to develop a system for measuring thereputation of commercial brands.1http://twitter.com2http://limosine-project.eu/events/replab20122.
TASS 2012 at SEPLN3(Villena-Roma?n etal., 2013): Satellite event of the SEPLN2012 Conference to foster the research inthe field of SA in social media, specificallyfocused on the Spanish language.In this paper is described the participation ofthe SINAI4 research group in the second task ofthe 2013 edition of the International WorkshopSemEval (Wilson et al 2013).
We have submit-ted two systems (constrained and unconstrained).The constrained system follows a supervised ap-proach, while the unconstrained system is basedon an unsupervised approach which used two lin-guistic resources: the Sentiment Analysis Lexi-con5 (Hu and Liu, 2004) andWeFeelFine6 (Kam-var and Harris, 2011).The paper is organized as follows: first wepresent a description of the preparing data pro-cess.
Then the constrained system is outlined.The participation overview finishes with the de-scription of the unconstrained system.2 Preparing dataThe organizers provided two sets of data, one fortraining and another for the development.
Thedata was concerned by a set of identificationnumber of tweets with their corresponding po-larity label.
We used the script provided by theorganizers to download the two sets of tweets.3http://www.daedalus.es/TASS/4http://sinai.ujaen.es5http://www.cs.uic.edu/?liub/FBS/opinion-lexicon-English.rar6http://wefeelfine.org402The python script was no able to download all thetweets.
The training set was composed by 8,633tweets and the development set by 1,053 tweets.The data preparation is a step in the workflowof most data mining tasks.
Also, in Natural Lan-guage Processing is usual the preparation of thedocuments or the texts for their further process-ing.
Internet is usually the source of texts for SAtasks, so the application of a specific processingto those texts with the aim of extracting their po-larity is recommended.
The texts published inTwitter have several issues that must be resolvedbefore processing them:1.
The linguistic style of tweets is usually in-formal, with a intensive usage of abbrevia-tions, idioms, and jargon.2.
The users do not care about the correct useof grammar, which increases the difficultyof carrying out a linguistic analysis.3.
Because the maximum length of a tweet is140 characters, the users normally refer tothe same concept with a large variety ofshort and irregular forms.
This problems isknown as data sparsity, and it is a challengefor the sentiment-topic task.4.
The lack of context, which makes difficultto extract the semantics of these sort piecesof text.Before applying a cleaning process to the cor-pus with the aim of overcoming the issues de-scribed above, we have studied the differentkinds of marks, like emoticons, question and ex-clamation marks or hashtags in the tweets.Regarding the issues listed above and themarks in the tweets, we have carried out a clean-ing and a normalization process which imply thefollowing operations:1.
The uppercase characters have been ex-changed by lowercase characters.2.
Links have been replaced by the token?
ULR ?.3.
Question and exclamation marks have beenswitched to the tokens ?
QUESTION ?
and?
EXCLAMATION ?
respectively.4.
Mentions7 have been exchanged by the to-ken ?
MENTION ?.5.
All the HTML tags have been removed.6.
The hashtags8 have been normalized withthe token ?
HASHTAG ?.7.
Tokens that express laughing (hahaha,hehehe...) have been normalized with thetoken ?
LAUGH ?.8.
Users usually write expressions or abbrevi-ations for surprise phrases like omg.
Allthese kind of expressions are replaced by thetoken ?
SURPRISE ?.9.
Positive emoticons like :), ;) or :, have beennormalized with the token ?
HAPPY ?.10.
Negative emoticons like :(, :?
( or :-( havebeen normalized with the token ?
SAD ?.11.
Twitter users usually repeat letters to em-phasize the idea that they want to express.Therefore, all the words with a letter re-peated more than two times have been re-duced to only two instances.
For exam-ple, the word ?aaaamaaaaaziiiing?
in tweet111733236627025920 is transformed into?aamaaziing?.After applying a normalization process to thetraining and development sets, we have used forthe constrained system and the unsconstrainedsystem a dataset of 9,686 tweets.3 Constrained SystemThe guidelines of the task define a constrainedsystem as a system that only can use the traindata provided by the organizers.
Due to this re-striction we decided to follow a supervised ap-proach.
It is required to define a set of parame-ters when the supervised method is the elected.The first step is to choose the minimum unit ofinformation, i.e.
what segments of text are con-sidered as features.
Pang et al(2002) assert that7A twitter mention is a reference to another user whichhas the pattern ?
@user name?8A hashtag is the way to refer a topic in Twitter, whichhas the pattern ?#topic name?403Class Precision Recall F1-scorePositive 0.6983 0.6295 0.6621Neutral 0.6591 0.8155 0.7290Negative 0.5592 0.2710 0.3651Average 0.6652Table 1: Assessment with TF-IDF weighting schemeopinions or reviews should be represented withunigrams, but other work shows bigrams and tri-grams outperformed the unigrams features (Daveet al 2003).
Therefore, there is not agreementin the SA research community about what is thebest choice, unigrams or n-grams.
Before severalvalidations on the training set of the task we de-cided to use unigrams as feature for the polarityclassification process.
Thus, for the supervisedalgorithm, we have represented each tweet as avector of unigrams.The next decision was about the applicationof a stemmer process and getting rid off the En-glish stop words.
We only have applied stemmerprocess to the data because in previous works(Mart?
?nez-Ca?mara et al 2013a) we did not reachgood results removing the stop words in textsfrom Twitter.
Another topic of discussion in theSA research community is the weighting scheme.Pang et al(2002) weighted each unigram fol-lowing a binary scheme.
Also, in the most citedsurvey about SA (Pang and Lee, 2008) the au-thors indicated that the overall sentiment may notusually be highlighted through repeated use ofthe same terms.
On the other hand, Mart?
?nez-Ca?mara et al(2011) achieved the best resultsusing TF-IDF as weighting scheme.
Due to thelack of agreement in the SA research communityabout the use of a specific weight scheme, wehave carried out several assessments with aim ofdeciding the most suitable one for the task.
Themachine learning algorithm selected for the eval-uation was SVM.
The results are shown in Tables1 and 2.The results achieved with the two weightingschemes are very similar.
Regarding the posi-tive class, the binary weighting scheme obtainsbetter results than the TF-IDF one, so the pres-ence of positive keywords is more useful thanClass Precision Recall F1-scorepositive 0.7037 0.6335 0.6668neutral 0.6506 0.8313 0.7299negative 0.5890 0.2105 0.3112Average 0.6654Table 2: Assessment with a binary weighting schemethe frequent occurrence of those keywords.
Forthe neutral class, regarding precision and F1-score, the TF-IDF scheme outperformed the bi-nary scheme, but the recall had a higher valuewhen the terms are weighted binary.
The pre-cision of the classification for the neutral classis only 1.2% better than the case where TF-IDFis used, while recall and the F1-score is betterwhen the weighting of the features is binary.
Al-though the negative class has a similar perfor-mance to that of the positive one with the twoweighting schemes, we highlighted the high dif-ference between the other two classes and thenegative.
The difference is more evident in therecall value, while the neutral class has a valueof 0.8313 (binary), the negative one has a valueof 0.2105 (binary).
Therefore, due to the fact thatthe binary weighting scheme achieved better re-sults in average, we decided to use it in the finalsystem.The last step in the configuration of a su-pervised approach based on machine learning isthe selection of the algorithm.
The algorithmselected was Support Vector Machine (SVM)(Cortes and Vapnik, 1995).
Our decision is basedon the widely used SVM by the research com-munity of SA.
The first application of SVM forSA was in (Pang et al 2002) with good re-sults.
Since the publication of the previous work,other researchers have used SVM, and some ofthem are: (Zhang et al 2009), (Pang and Lee,2004) and (Jindal and Liu, 2006).
Also, the al-gorithm SVM has been used to classify the po-larity over tweets (Go et al 2009) (Zhang et al2011) (Jiang et al 2011).
A broader review ofthe research about SA in Twitter can be found in(Mart?
?nez-Ca?mara et al 2013b).
Furthermore,our decision is supported by previous in-houseexperimentation.404For the experimentation we have used theframework for data mining RapidMiner9.
InRapidMiner there are several implementationsof SVM, among which we have selected Lib-SVM10(Chang and Lin, 2011) with built-in de-fault parametrization.To sum up, the configuration of the SINAIconstrained system is:1.
Machine learning approach: Supervised2.
Features: Unigrams.3.
Weighted scheme: Binary.
If the term ispresence the value is 1, 0 in other case.4.
Stemmer: Yes5.
Stopper: No6.
Algorithm: SVM.The results reached during the developmentperiod are shown in Table 24 Unconstrained SystemOur unconstrained system follows a two levelcategorization approach, determining whetherthe tweet is subjective or not at a first stage, and,for the subjective classified ones, whether thetweet is positive or negative.
Both classificationphases are fully based on knowledge resources.A predefined list of affective words is used forsubjectivity detection, and a search process overthe collection of emotions generated from a webresource is applied for final polarity classifica-tion.
Figure 1 shows a general diagram of thesystem.4.1 Step 1: determining subjectivityThe system based in WeFeelFine only catego-rizes between positive and negative texts, so apreliminary classification into subjective and ob-jective (i.e.
neutral) must be performed.
To thisend, a lexical approach is followed: those tweetscontaining at least one affective term from a listof predefined ones are considered subjective.
If9http://rapid-i.com/10http://www.csie.ntu.edu.tw/?cjlin/libsvm/Figure 1: Unconstrained system general diagramaffective terms are not found, then the tweet isdirectly labeled as neutral.
This list is called Sen-timent Analysis Lexicon (SAL), which is definedin the work of Bing Liu (Hu and Liu, 2004).
Thelist has two differentiated groups: a list of posi-tive terms (agile, enjoy, improving) and anotherwith negative ones (anger, refusing, unable...).At this phase, the polarity is not considered, soboth lists are merged into a list of around 6,800subjectivity terms.4.2 Step 2: determining polarityThe WeFeelFine project (Kamvar and Harris,2011) has been used as knowledge base for po-larity classification following the approach pro-posed by (Montejo-Ra?ez, 2013).
WeFeelFine11gathers affective texts from several blogs, cre-ating a huge database of mood-related expres-sions.
Almost two millions ?feelings?
are col-lected and indexed by the system.
It is possibleto retrieve related sentences and expressions byusing its API.
In this way, we have obtained the11http://wefeelfine.org405top 200 most frequent feelings.
For each feeling,about 1,500 sentences are include in a documentthat represents such a feeling.
Then, using theLucene12 search engine, these documents havebeen indexed.
In this way, we can use an incom-ing tweet as query and retrieve a ranked list offeelings, as shown in Figure 2.Figure 2: Polarity classificationThe ranked list with the top 100 feelings (i.e.those feelings more related to the tweet) is takenfor computing the final polarity by a summationof the manually assigned polarity of the feelingweighted with the score value returned by the en-gine, as shown in Equation 1.p(t) = 1|R|?r?RRSVr ?
lr (1)wherep(t) is the polarity of tweet tR is the list of retrieved feelingslr is the polarity label of feeling rRSVr is the Ranking Status Value of the feel-ing determined by Lucene.As we did with the constrained system, wealso assess the unconstrained system before ap-plying the test data.
The results reached duringthe evaluation phase are shown in Table 3.
It isremarkable the fact that the precision value of theunconstrained system is a bit higher than the one12http://lucene.apache.org/Class Precision Recall F1-scorepositive 0.5004 0.6341 0.5593neutral 0.6772 0.5416 0.6018negative 0.3580 0.3456 0.3516Average 0.5094Table 3: Assessment of the unconstrained systemreached by the constrained configuration.
Thus,SAL is a good resource for subjective classifi-cation tasks.
The unconstrained system reachedworse results with positive and negative classes,but it is an expected result because supervisedapproaches usually obtain better results than theunsupervised and knowledge based approaches.However, the polarity classification has reachedacceptable results, so it encourage us to followimproving the method based of the use of We-FeelFine.AcknowledgmentsThis work has been partially supported by a grantfrom the Fondo Europeo de Desarrollo Regional(FEDER), TEXT-COOL 2.0 project (TIN2009-13391-C04-02) and ATTOS project (TIN2012-38536-C03-0) from the Spanish Government.Also, this paper is partially funded by the Eu-ropean Commission under the Seventh (FP7- 2007-2013) Framework Programme for Re-search and Technological Development throughthe FIRST project (FP7-287607).
This publica-tion reflects the views only of the authors, andthe Commission cannot be held responsible forany use which may be made of the informationcontained therein.ReferencesEnrique Amigo?, Adolfo Corujo, Julio Gonzalo, EdgarMeij, and Md Rijke.
2012.
Overview of replab2012: Evaluating online reputation managementsystems.
In CLEF 2012 Labs and Workshop Note-book Papers.Chih-Chung Chang and Chih-Jen Lin.
2011.
Libsvm:A library for support vector machines.
ACM Trans.Intell.
Syst.
Technol., 2(3):27:1?27:27, May.Corinna Cortes and Vladimir Vapnik.
1995.
Support-vector networks.
Machine Learning, 20:273?297.406Kushal Dave, Steve Lawrence, and David M. Pen-nock.
2003.
Mining the peanut gallery: opinionextraction and semantic classification of productreviews.
In Proceedings of the 12th internationalconference on World Wide Web, WWW ?03, pages519?528, New York, NY, USA.
ACM.Alec Go, Richa Bhayani, and Lei Huang.
2009.
Twit-ter sentiment classification using distant supervi-sion.
CS224N Project Report, Stanford, pages 1?12.Minqing Hu and Bing Liu.
2004.
Mining and sum-marizing customer reviews.
In Proceedings of thetenth ACM SIGKDD international conference onKnowledge discovery and data mining, KDD ?04,pages 168?177, New York, NY, USA.
ACM.Long Jiang, Mo Yu, Ming Zhou, Xiaohua Liu, andTiejun Zhao.
2011.
Target-dependent twitter sen-timent classification.
In Proceedings of the 49thAnnual Meeting of the Association for Computa-tional Linguistics: Human Language Technologies- Volume 1, HLT ?11, pages 151?160, Stroudsburg,PA, USA.
Association for Computational Linguis-tics.Nitin Jindal and Bing Liu.
2006.
Identifying com-parative sentences in text documents.
In Proceed-ings of the 29th annual international ACM SIGIRconference on Research and development in infor-mation retrieval, SIGIR ?06, pages 244?251, NewYork, NY, USA.
ACM.Sepandar D. Kamvar and Jonathan Harris.
2011.
Wefeel fine and searching the emotional web.
In Pro-ceedings of the fourth ACM international confer-ence on Web search and data mining, WSDM ?11,pages 117?126, New York, NY, USA.
ACM.Eugenio Mart?
?nez-Ca?mara, M. Teresa Mart?
?n-Valdivia, Jose?
M. Perea-Ortega, and L. Al-fonso Ure na Lo?pez.
2011.
Opinion classificationtechniques applied to a spanish corpus.
Proce-samiento de Lenguaje Natural, 47.Eugenio Mart?
?nez-Ca?mara, M. Teresa Mart?
?n-Valdivia, L. Alfonso Ure na Lo?pez, and RuslanMitkov.
2013a.
Detecting sentiment polarity inspanish tweets.
Information Systems Management,In Press.Eugenio Mart?
?nez-Ca?mara, M. Teresa Mart?
?n-Valdivia, L. Alfonso Ure na Lo?pez, and ArturoMontejo-Ra?ez.
2013b.
Sentiment analysisin twitter.
Natural Language Engineering,FirstView:1?28, 2.Arturo Montejo-Ra?ez.
2013.
Wefeelfine as resourcefor unsupervised polarity classification.
Proce-samiento del Lenguaje Natural, 50:29?35.Bo Pang and Lillian Lee.
2004.
A sentimental educa-tion: sentiment analysis using subjectivity summa-rization based on minimum cuts.
In Proceedings ofthe 42nd Annual Meeting on Association for Com-putational Linguistics, ACL ?04, Stroudsburg, PA,USA.
Association for Computational Linguistics.Bo Pang and Lillian Lee.
2008.
Opinion mining andsentiment analysis.
Found.
Trends Inf.
Retr., 2(1-2):1?135, January.Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.2002.
Thumbs up?
: Sentiment classification us-ing machine learning techniques.
In Proceedingsof the ACL-02 conference on Empirical methods innatural language processing - Volume 10, EMNLP?02, pages 79?86, Stroudsburg, PA, USA.
Associ-ation for Computational Linguistics.Julio Villena-Roma?n, Sara Lana-Serrano, Euge-nio Mart?
?nez-Ca?mara, and Jose?
Carlos Gonza?lez-Cristo?bal.
2013.
Tass - workshop on sentimentanalysis at sepln.
Procesamiento del LenguajeNatural, 50(0).Theresa Wilson, Zornitsa Kozareva, Preslav Nakov,Sara Rosenthal, Veselin Stoyanov, and Alan Ritter.2013.
SemEval-2013 task 2: Sentiment analysis intwitter.
In Proceedings of the International Work-shop on Semantic Evaluation, SemEval ?13, June.Changli Zhang, Daniel Zeng, Jiexun Li, Fei-YueWang, and Wanli Zuo.
2009.
Sentiment analy-sis of chinese documents: From sentence to docu-ment level.
Journal of the American Society for In-formation Science and Technology, 60(12):2474?2487.Ley Zhang, Riddhiman Ghosh, Mohamed Dekhil,Meichun Hsu, and Bing Liu.
2011.
Combininglexiconbased and learning-based methods for twit-ter sentiment analysis.
HP Laboratories, TechnicalReport HPL-2011-89.407
