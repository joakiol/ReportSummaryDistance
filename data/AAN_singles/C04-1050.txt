Improving Japanese Zero Pronoun Resolutionby Global Word Sense DisambiguationDaisuke Kawahara and Sadao KurohashiGraduate School of Information Science and Technology, University of Tokyo{kawahara,kuro}@kc.t.u-tokyo.ac.jpAbstractThis paper proposes unsupervised wordsense disambiguation based on automati-cally constructed case frames and its in-corporation into our zero pronoun resolu-tion system.
The word sense disambigua-tion is applied to verbs and nouns.
Weconsider that case frames define verb sensesand semantic features in a thesaurus definenoun senses, respectively, and perform sensedisambiguation by selecting them based oncase analysis.
In addition, according to theone sense per discourse heuristic, the wordsense disambiguation results are cached andapplied globally to the subsequent words.We integrated this global word sense disam-biguation into our zero pronoun resolutionsystem, and conducted experiments of zeropronoun resolution on two different domaincorpora.
Both of the experimental resultsindicated the effectiveness of our approach.1 IntroductionFor a long time, parsing has been a central is-sue for the area of natural language analyses.In recent years, its accuracy has improved toover 90%, and it became the fundamental tech-nology that is applied to a lot of NLP applica-tions, such as question answering, text summa-rization, and machine translation.
Accordingly,anaphora resolution, which is positioned as thenext step of parsing, has been studied actively(Ng and Cardie, 2002; Yang et al, 2003; Iidaet al, 2003; Isozaki and Hirao, 2003; Kawa-hara and Kurohashi, 2004).
Its performance,however, is not satisfactory enough to benefitthe NLP applications.
We investigated errorsof our Japanese zero pronoun resolution system(Kawahara and Kurohashi, 2004), and foundthat word sense ambiguity causes a major partof errors.Our zero pronoun resolution system uti-lizes the general-purpose thesaurusNihongo GoiTaikei (Ikehara et al, 1997) (hereafter, NTTthesaurus) to do matching of example words.In this thesaurus, one or more semantic featuresare given to each word, and similarity betweenwords can be calculated by comparing closenessof their semantic features in the thesaurus tree(Appendix A).
Multiple semantic features fora word, i.e.
word sense ambiguity, cause in-correct matching, and furthermore deteriorateaccuracy of the zero pronoun resolution sys-tem.
For instance, in the thesaurus, ?gobou?
(burdock/priest/temple) has four semantic fea-tures: <crop>, <vegetable>, <priest> and<temple>?.
If <priest> is used for ?gobou?
ina cooking domain text, though ?gobou?
means?burdock?
(a genus of coarse biennial herbs) inits context, ?gobou?
is identified as an agent.That is, ?gobou?
is incorrectly analyzed as an-tecedents of the following nominative zero pro-nouns.If such word sense ambiguity can be resolved,incorrect matching decreases, and the anaphoraresolution system will improve.
Word sense dis-ambiguation is a basic issue of NLP.
Recently,the evaluation exercises for word sense disam-biguation such as SENSEVAL-1 (Kilgarriff andPalmer, 2000) and SENSEVAL-2 (Yarowsky,2001) have been held, but word sense disam-biguation has rarely been incorporated intodeep analyses like anaphora resolution.This paper proposes unsupervised word sensedisambiguation based on automatically con-structed case frames and its incorporation intothe zero pronoun resolution system.
The wordsense disambiguation is applied to verbs?
andnouns.
We consider that case frames defineverb senses and semantic features in the the-saurus define noun senses, respectively.
A verbis disambiguated by selecting a correspondingcase frame to its context, and a noun is disam-biguated by selecting an appropriate semantic?In this paper, <> means a semantic feature.
?In this paper, we use ?verb?
instead of ?verb, adjectiveand noun+copula?
for simplicity.NOUNCONCRETE ABSTRACTAGENT PLACE CONCRETEHUMAN ORGANIZATIONABSTRACT EVENT ABSTRACT RELATIONTIME POSITION QUANTITY .
.
.
.Figure 1: The upper levels of the NTT thesaurus.feature from the ones defined for the noun inthe thesaurus.
In addition, according to the onesense per discourse heuristic, the disambigua-tion results are cached and applied globally tothe following words in the same text.The remainder of this paper is organized asfollows.
Section 2 briefly describes the NTT the-saurus and the automatic construction methodof case frames.
Section 3 outlines our zero pro-noun resolution system.
Section 4 describes themethod of word sense disambiguation and itsintegration into the zero pronoun resolution sys-tem.
Section 5 presents the experiments of theintegrated system.
Section 6 summarizes theconclusions.2 ResourcesWe consider that verb and noun senses corre-spond to case frames and semantic features de-fined in the NTT thesaurus, respectively.
Thissection describes the NTT thesaurus and thecase frames briefly.2.1 NTT thesaurusNTT Communication Science Laboratories con-structed a semantic feature tree, whose 3,000nodes are semantic features, and a nominal dic-tionary containing about 300,000 nouns, each ofwhich is given one or more appropriate seman-tic features.
Figure 1 shows the upper levels ofthe semantic feature tree.The similarity between two words is definedby formula (1) in Appendix A.2.2 Automatically constructed caseframesWe employ the automatically constructed caseframes (Kawahara and Kurohashi, 2002) asthe basic resource for zero pronoun resolutionand word sense disambiguation.
This sectionoutlines the method of constructing the caseframes.The biggest problem in automatic case frameconstruction is verb sense ambiguity.
Verbswhich have different meanings should have dif-ferent case frames, but it is hard to dis-ambiguate verb senses precisely.
To dealwith this problem, predicate-argument exam-ples which are collected from a large cor-pus are distinguished by coupling a verb andits closest case component.
That is, ex-amples are not distinguished by verbs (e.g.?tsumu?
(load/accumulate)), but by couples(e.g.
?nimotsu-wo tsumu?
(load baggage) and?keiken-wo tsumu?
(accumulate experience)).This process makes separate case frameswhich have almost the same meaning or usage.For example, ?nimotsu-wo tsumu?
(load bag-gage) and ?busshi-wo tsumu?
(load supply) aresimilar, but have separate case frames.
To copewith this problem, the case frames are clustered.Example words are collected for each casemarker, such as ?ga?, ?wo?, ?ni?
and?kara?.
They are case-marking postpositionsin Japanese, and usually mean nominative, ac-cusative, dative and ablative, respectively.
Wecall such a case marker ?case slot?
and examplewords in a case slot ?case examples?.Case examples in a case slot are similar, buthave some incorrect semantic features becauseof word sense ambiguity.
For instance, ?ni-motsu?
(baggage), ?busshi?
(supply) and ?nise-mono?
(imitation) are gathered in a case slot,and all of them are below the semantic feature<goods>.
On the other hand, ?nisemono?
be-longs to <lie>.
<lie> is incorrect for this caseslot, and possibly causes errors in case analysis.We delete a semantic feature that is not similarto the other semantic features of its case slot.To sum up, the procedure for the automaticcase frame construction is as follows.1.
A large raw corpus is parsed by theJapanese parser, KNP (Kurohashi andNagao, 1994b), and reliable predicate-argument examples are extracted from theparse results.2.
The extracted examples are bundled ac-cording to the verb and its closest case com-ponent, making initial case frames.3.
The initial case frames are clustered using asimilarity measure function.
This similar-ity is calculated by formula (5) in AppendixB.4.
For each case slot of clustered case frames,an inappropriate semantic feature that isnot similar to the other semantic featuresis discarded.We constructed two sets of case frames: fornewspaper and cooking domain.The newspaper case frames are constructedfrom about 21,000,000 sentences of newspaperarticles in 20 years (9 years of Mainichi news-paper and 11 years of Nihonkeizai newspaper).They consist of 23,000 verbs, and the averagenumber of case frames for a verb is 14.5.The cooking case frames are constructed fromabout 5,000,000 sentences of cooking domainthat are collected from WWW.
They consistof 5,600 verbs, and the average number of caseframes for a verb is 6.8.In Figure 1, some examples of the resultingcase frames are shown.
In this table, ?CS?
meansa case slot.
<agent> in the table is a general-ized case example, which is given to the caseslot where half of the case examples belong to<agent>.
<agent> is also given to ?ga?
caseslot that has no case examples, because ?ga?case components are often omitted, but ?ga?case slots usually mean nominative.3 The Outline of the Zero PronounResolution SystemWe have proposed a Japanese zero pronounresolution system using the case frames, an-tecedent preference orders, and a machine learn-ing technique (Kawahara and Kurohashi, 2004).Its procedure is as follows.1.
Parse an input sentence using the Japaneseparser, KNP.2.
Process each verb in the sentence from leftto right by the following steps.Table 1: Case frame examples.CS case examples?ga <agent>, group, party, ?
?
?youritsu (1) wo <agent>, candidate, applicant(support) ni <agent>, district, election, ?
?
?ga <agent>youritsu (2) wo <agent>, member, minister, ?
?
?
(support) ni <agent>, candidate, successor... ... ...orosu (1) ga <agent>(grate) wo radishga <agent>orosu (2) wo money(withdraw) kara bank, post... ... ...itadaku (1) ga <agent>(have) wo soupga <agent>itadaku (2) wo advice, instruction, address(be given) kara <agent>, president, circle, ?
?
?...
... ...?case examples are expressed only in English forspace limitation.2.1.
Narrow case frames down to corre-sponding ones to the verb and its clos-est case component.2.2.
Perform the following processes foreach case frame of the target verb.i.
Match each input case componentwith an appropriate case slot ofthe case frame.
Regard case slotsthat have no correspondence aszero pronouns.ii.
Estimate an antecedent of eachzero pronoun.2.3.
Select a case frame which has the high-est total score, and output the analysisresult for the case frame.The rest of this section describes the abovesteps (2.1), (2.2.i) and (2.2.ii) in detail.3.1 Narrowing down case framesThe closest case component plays an importantrole to determine the usage of a verb.
In par-ticular, when the closest case is ?wo?
or ?ni?,this trend is clear-cut.
In addition, an expres-sion whose nominative belongs to <agent> (e.g.
?<agent> has accomplished?
), does not haveenough clue to decide its usage, namely a caseframe.
By considering these aspects, we imposethe following conditions on narrowing down caseframes.?
The closest case component exists, andmust immediately precede its verb.?
The closest case component and the closestcase meet one of the following conditions:?
The closest case is ?wo?
or ?ni?.?
The closest case component doesnot belong to the semantic marker<agent>.?
A case frame with the closest case exists,and the similarity between the closest casecomponent and examples in the closest caseexceeds a threshold.We choose the case frames whose similarityis the highest.
If the above conditions are notsatisfied, case frames are not narrowed down,and the subsequent processes are performed foreach case frame of the target verb.
The simi-larity used here is defined as the best similaritybetween the closest case component and exam-ples in the case slot.
The similarity between twoexamples is defined as formula (1) in AppendixA.Let us consider ?youritsu?
(support) in thesecond sentence of Figure 2.
?youritsu?
has thecase frames shown in Table 1.
The input expres-sion ?kouho-wo youritsu?
(support a candidate)satisfies the above two conditions, and the caseframe ?youritsu (1)?
meets the last condition.Accordingly, this case frame is selected.3.2 Matching input case componentswith case slots in the case frameWe match case components of the target verbwith case slots in the case frame (Kurohashi andNagao, 1994a).
When a case component has acase marker, it must be assigned to the caseslot with the same case marker.
When a casecomponent is a topic marked phrase or a clausalmodifiee, which does not have a case marker, itcan be assigned to one of the case slots in thefollowing table.topic marked phrases : ga, wo, ga2clausal modifiees : ga, wo, non-gappingThe conditions above may produce multiplematching patterns.
In this case, one which hasthe best score is selected.
The score of a match-ing pattern is defined as the sum of similaritiesof case assignments.
This similarity is calcu-lated as the same way described in Section 3.1. 	 ff	fi	flffifi"!fi#fi$ffifl"!#%"!&	fi'()fl%"!#%%+*,-%./,0%01,*%-1,	2%2ff,3 4	fi#	"!#%()fl5  %6 457879#:79<;79>=79<?Figure 2: Analysis example.The result of case analysis tells if the zeropronouns exist.
That is, vacant case slots inthe case frame, which have no correspondencewith the input case components, mean zero pro-nouns.
In this paper, we concentrate on threecase slots: ?ga?, ?wo?, and ?ni?.In the case of ?youritsu?
(support) in Figure2 and the selected case frame ?youritsu (1)?,?wo?
case slot has a corresponding case compo-nent, but ?ga?
and ?ni?
case slots are vacant.Accordingly, two zero pronouns are identified in?ga?
and ?ni?
case of ?youritsu?.3.3 Antecedent estimationThe antecedents of the detected zero pronounsare estimated.
Possible antecedents are exam-ined according to the antecedent preference or-der (Kawahara and Kurohashi, 2004).
If a pos-sible antecedent is classified as positive by a bi-nary classifier and its similarity to examples inits case slot exceeds a threshold, it is determinedas the antecedent.For example, ?youritsu?
(support) in Fig-ure 2 has zero pronouns in ?ga?
and ?ni?cases.
The ordered possible antecedents for?ga?
are L7:?Minsyutou?, L14:?Jimintou?
(?ga), L14:?Ishihara chiji?(?
wo), ?
?
?.
The firstcandidate ?Minsyutou (similarity:0.73)?, whichis labeled as positive by the classifier, and whosesimilarity to the case frame examples exceedsa threshold (0.60), is determined as the an-tecedent.4 Global Word SenseDisambiguationWe integrate a global method of word sense dis-ambiguation into the zero pronoun resolutionsystem described in the previous section.
Theword sense disambiguation is applied to verbsand nouns based on the case frames.
Further-more, the word sense disambiguation results arecached and applied globally by the subsequentanalyses based on the one sense per discourseheuristic.
In the rest of this section, we de-scribe verb and noun sense disambiguation re-spectively using examples of cooking domain.4.1 Verb sense disambiguationThe case frames are specific enough to the diver-sity of verb senses, because their meanings aredistinguished by the couple of the verb and itsclosest case component (Kawahara and Kuro-hashi, 2002).
We regard the process of verbsense disambiguation as the case frame selection(Step (2.3) described in Section 3).
In addition,the verb sense disambiguation results are cachedand applied globally in the same text.
In otherwords, the selected case frames are cached foreach verb, and only the case frames that aresimilar to the cache are used for the same verbfollowing in the same text.
The similarity mea-sure for two case frames is stated in AppendixB, and the threshold is set to 0.60 empirically.Here is an example article that consists of threesentences.oroshi-gane-degraterkabura-woturniporoshite-ikimasu.grate(Let?s grate a turnip.
)kore-wathisookiibigkaburaturnipdesu.be(This is a big turnip.
)konoyounilike thisoroshi-masu.grate(Grate like this.
)For ?oroshite?
(grate) in the first sentence,the case frame ?orosu (1)?
(in Table 1), whichmeans ?grate radish?, is selected, because theclosest case component ?kabura?
(turnip) ex-ists, and is very similar to the ?wo?
case exam-ple ?daikon?
(radish).
This selected case frameis cached for the verb ?orosu?.
For ?oroshi?
(grate) in the third sentence, case frames arenot narrowed down for lack of the closest com-ponent.
The previous system performs theantecedent estimation process for all the caseframes of ?orosu?, and incorrectly estimates theantecedent of ?wo?
zero pronoun as ?oroshi-gane?
(grater)?.
On the other hand, our pro-posed method deals with only the similar caseframes to the cached ?orosu (1)?.
That is, thecase frame ?orosu (2)?, which means ?with-draw money from bank or post?, is not similarto ?orosu (1)?, and is not used.
Accordingly,the system certainly estimates the antecedentof ?wo?
zero pronoun as ?kabura?
(turnip).4.2 Noun sense disambiguationWe define the process of noun sense disambigua-tion as selecting an appropriate semantic fea-ture from the ones given to a noun in the NTTthesaurus.
This process is performed based onthe matching of the input case components andthe case frame decided by the step (2.3) de-scribed in Section 3.
For each input case compo-nent, its semantic features are matched againstthose of case examples of its corresponding caseslot, and the best matched one is selected.
Inaddition, this disambiguation result is appliedglobally like the verb sense disambiguation.
Thedetermined semantic feature is cached for eachnoun, and is given to the same noun following inthe same text, instead of reconsidering all of itssemantic features.
Here is an example article.mazuwafirstosumashi -woclear soupitadaki -masu.have(First, let?s have clear soup.
)honkakutekinarealdashi -wostocktori -mashita.prepare(We prepared real stock.)?itadaki?
(have) in the first sentence hasthe closest case component ?osumashi?
(clearsoup), and the case frame ?itadaku (1)?
(in Ta-ble 1) is selected, because its ?wo?
case example?soup?
is very similar to ?osumashi?.In the NTT thesaurus, ?osumashi?
(clearsoup) has three semantic features: <soup>,<look> and <eccentric>.
<eccentric> is lo-cated below <agent> in the thesaurus, andthe previous system incorrectly estimates an-tecedents of ?ga?
zero pronouns of the follow-ing verbs as ?osumashi?
(because almost all the?In Japanese, ?gane?
of ?oroshi-gane?
(grater) ex-actly matches with ?kane?
(money), the ?wo?
case ex-ample of ?orosu (2)?.Table 2: Accuracy (newspaper).precision recall Fbaseline 515/924 (0.557) 515/1087 (0.474) 0.512our method 526/911 (0.577) 526/1087 (0.484) 0.527Table 3: Accuracy (cooking).precision recall Fbaseline 696/1092 (0.637) 696/1482 (0.470) 0.541our method 713/1081 (0.660) 713/1482 (0.481) 0.556case frames have <agent> in their ?ga?
caseslots).
In our approach, each of the semanticfeatures are matched against the case example?soup?, and only the best matched semanticfeature <soup> is given to ?osumashi?.5 Experimental Results andDiscussionWe conducted experiments of zero pronoun res-olution on two different domain corpora.
Oneis newspaper articles of ?Relevance-tagged cor-pus?
(Kawahara et al, 2002), and the otheris utterances of cooking TV programs.
Thesecooking utterances were handled by (Shibata etal., 2003).
They annotated various relations toclosed captions of the cooking utterances basedon the specification of the ?Relevance-taggedcorpus?
(Kawahara et al, 2002).For newspaper domain, the antecedent pref-erence and the classifier were trained with 1,841sentences in the newspaper corpus, and thenewspaper case frames were used.
The exper-iment was performed on 633 sentences.
Forcooking domain, we used 813 sentences (5 TVprograms), and conducted 5-fold cross valida-tion using the cooking case frames.We evaluated ?ga?, ?wo?
and ?ni?
cases thatare the large majority of zero pronouns.
Theexperimental results are shown in Table 2 andTable 3.
The accuracies in these tables are cal-culated by evaluating both detection and an-tecedent estimation of zero pronouns together.The baseline corresponds to our previous sys-tem without word sense disambiguation.From Table 2 and Table 3, we can see thatthe system accuracy is improved by the globalword sense disambiguation.
The improvementis not big, but there are no analysis result thatchanged for the worse.
The improvement ishardly contributed by the verb sense disam-biguation, but mainly by the noun sense dis-ambiguation.
This is because appropriate caseframes are used in many cases without the verbsense disambiguation, and this process did notlead to the improvement.
The number of caseframes of the verbs to which the verb sense dis-ambiguation is applied decreased to 16%, andthis indicates that the analysis efficiency im-proved significantly.
In addition, we evaluatedrandomly selected 100 nouns to which the nounsense disambiguation is applied.
91 nouns weredisambiguated correctly, and quite high disam-biguation accuracy was achieved.6 ConclusionThis paper has incorporated a frameworkof global word sense disambiguation into aJapanese zero pronoun resolution system.
Theword sense disambiguation is applied to verbsand nouns.
A verb is disambiguated by select-ing a corresponding case frame to its context,and a noun is disambiguated by selecting anappropriate semantic feature.
Furthermore, thedisambiguation results are cached and appliedglobally.
That is to say, it is utilized in the fol-lowing analyses in the same text.
In the future,we will investigate the word sense disambigua-tion errors further, and expect to improve thesystem accuracy.ReferencesRyu Iida, Kentaro Inui, Hiroya Takamura, and YujiMatsumoto.
2003.
Incorporating contextual cuesin trainable models for coreference resolution.
InProceedings of the 10th EACL Workshop on TheComputational Treatment of Anaphora, pages 23?30.Satoru Ikehara, Masahiro Miyazaki, Satoshi Shirai,Akio Yokoo, Hiromi Nakaiwa, Kentarou Ogura,and Yoshifumi Oyama Yoshihiko Hayashi, editors.1997.
Japanese Lexicon.
Iwanami Publishing.Hideki Isozaki and Tsutomu Hirao.
2003.
Japanesezero pronoun resolution based on ranking rulesand machine learning.
In Proceedings of the 2003Conference on Empirical Methods in Natural Lan-guage Processing, pages 184?191.Daisuke Kawahara and Sadao Kurohashi.
2002.Fertilization of case frame dictionary for robustJapanese case analysis.
In Proceedings of the 19thInternational Conference on Computational Lin-guistics, pages 425?431.Daisuke Kawahara and Sadao Kurohashi.
2004.Zero pronoun resolution based on automaticallyconstructed case frames and structural preferenceof antecedents.
In Proceedings of the 1st Inter-national Joint Conference on Natural LanguageProcessing, pages 334?341.Daisuke Kawahara, Sadao Kurohashi, and Ko?itiHasida.
2002.
Construction of a Japaneserelevance-tagged corpus.
In Proceedings of the 3rdInternational Conference on Language Resourcesand Evaluation, pages 2008?2013.Adam Kilgarriff and Martha Palmer.
2000.
Intro-duction to the special issue on SENSEVAL.
Com-puters and the Humanities, 34(1):1?13.Sadao Kurohashi and Makoto Nagao.
1994a.
Amethod of case structure analysis for Japanesesentences based on examples in case frame dic-tionary.
In IEICE Transactions on Informationand Systems, volume E77-D No.2.Sadao Kurohashi and Makoto Nagao.
1994b.
A syn-tactic analysis method of long Japanese sentencesbased on the detection of conjunctive structures.Computational Linguistics, 20(4):507?534.Vincent Ng and Claire Cardie.
2002.
Improving ma-chine learning approaches to coreference resolu-tion.
In Proceedings of the 40th Annual Meetingof the Association for Computational Linguistics,pages 104?111.Tomohide Shibata, Daisuke Kawahara, MasashiOkamoto, Sadao Kurohashi, and Toyoaki Nishida.2003.
Structural analysis of instruction utter-ances.
In Proceedings of Seventh InternationalConference on Knowledge-Based Intelligent In-formation and Engineering Systems (KES2003),pages 1054?1061.Xiaofeng Yang, Guodong Zhou, Jian Su, andChew Lim Tan.
2003.
Coreference resolution us-ing competition learning approach.
In Proceedingsof the 41st Annual Meeting of the Association forComputational Linguistics, pages 176?183.David Yarowsky, editor.
2001.
SENSEVAL-2: Sec-ond International Workshop on Evaluating WordSense Disambiguating Systems.
The Associationfor Computational Linguistics.AppendixA Similarity between examplesThe similarity between two examples e1, e2 iscalculated using the NTT thesaurus as follows:sim(e1, e2) = maxx?s1,y?s2 sim(x, y) (1)sim(x, y) = 2Llx + lywhere x, y are semantic features, and s1, s2 aresets of semantic markers of e1, e2 respectively.lx, ly are the depths of x, y in the thesaurus, andthe depth of their lowest (most specific) com-mon node is L. If x and y are in the same nodeof the thesaurus, the similarity is 1.0, the max-imum score based on this criterion.B Similarity between case framesTwo case frames, F1 and F2, are first aligned ac-cording to the agreement of case markers (caseslots).
Suppose the result of the case slot align-ment of F1 and F2 is as follows:F1 : C11, C12, ?
?
?
C1l ?
?
?
C1ml l lF2 : C21, C22, ?
?
?
C2l ?
?
?
C2nwhere Cxx denotes a case slot which containsseveral case examples.
This result means thatl case slots are aligned between F1 and F2 and(m ?
l) and (n ?
l) case slots remained in F1and F2 respectively.The similarity between two case slots, C1i andC2i, is the sum of the similarities of case exam-ples as follows:sim(C1i, C2i) =?e1?C1i?e2?C2i?|e1||e2|?sim(e1,e2)?e1?C1i?e2?C2i?|e1||e2|(2)where |e1| and |e2| represent the frequencies ofe1 and e2 respectively.The similarities of case slots are summed upwith the weight of frequencies of case examplesas follows:WSofCS =?li=1?|C1i||C2i|?sim(C1i,C2i)?li=1?|C1i||C2i|(3)where|C1i| =?e1?C1i|e1|, |C2i| =?e2?C2i|e2|On the other hand, the ratio of aligned caseslots is calculated as follows:RofACS =?
?li=1 |C1i|?mi=1 |C1i|?
?li=1 |C2i|?ni=1 |C2i|(4)Finally, the similarity between case frames iscalculated as follows:sim(F1, F2) = WSofCS?
RofACS (5)
