Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1447?1455,Edinburgh, Scotland, UK, July 27?31, 2011. c?2011 Association for Computational LinguisticsDiscovering Relations between Noun CategoriesThahir P Mohamed * Estevam R Hruschka Jr. Tom M MitchellUniversity Of Pittsburgh Federal University of Sao Carlos Carnegie Mellon Universitypmthahir@gmail.com estevam@cs.cmu.edu tom.mitchell@cs.cmu.eduAbstractTraditional approaches to Relation Extractionfrom text require manually defining the rela-tions to be extracted.
We propose here an ap-proach to automatically discovering relevantrelations, given a large text corpus plus an ini-tial ontology defining hundreds of noun cate-gories (e.g., Athlete, Musician, Instrument).Our approach discovers frequently stated rela-tions between pairs of these categories, using atwo step process.
For each pair of categories(e.g., Musician and Instrument) it first co-clusters the text contexts that connect knowninstances of the two categories, generating acandidate relation for each resulting cluster.
Itthen applies a trained classifier to determinewhich of these candidate relations is semanti-cally valid.
Our experiments apply this to a textcorpus containing approximately 200 millionweb pages and an ontology containing 122 cat-egories from the NELL system [Carlson et al,2010b], producing a set of 781 proposed can-didate relations, approximately half of whichare semantically valid.
We conclude this is auseful approach to semi-automatic extension ofthe ontology for large-scale information extrac-tion systems such as NELL.1 IntroductionThe Never-Ending Language Learner (NELL)(Carlson et al, 2010b)) is a computer system thatlearns continuously to extract facts from the web.NELL is given as input an initial ontology thatspecifies the semantic categories (e.g.
city, compa-ny, sportsTeam) and semantic relations (e.g.
hasOf-ficesIn(company,city), teamPlay-sInCity(sportsTeam,city)) it must extract from theweb.
In addition, it is provided 10-20 seed positivetraining examples for each of these categories andrelations, along with hundreds of millions of unla-beled web page.
Given this input, NELL applies alarge-scale multitask, semisupervised learningmethod to learn to extract new instances of thesecategories (e.g., city(?London?))
and relations(e.g., teamPlaysInCity(?Steelers?,?Pittsburgh?
))from the web.
During the past 17 months NELLhas been running nearly continuously, learning toextract over 600 categories and relations, and pop-ulating a knowledge base containing over 700,000instances of these categories and relations with aprecision of approximately 0.851.This paper considers the problem of automati-cally discovering new relations to extend the on-tology of systems such as NELL, enabling them toincrease over time their learning and extractioncapabilities.
More precisely, we consider the fol-lowing problem:Input:?
An ontology specifying a set of categories?
A knowledge base containing instances of thesecategories (perhaps including errors)?
A large text corpusOutput:?
A set of two-argument relations that are fre-quently mentioned in the text corpus, andwhose argument types correspond to categoriesin the input ontology (e.g., RiverFlows-ThroughCity(<River>,<City>).?
For each proposed relation, a set of instances(i.e.
RiverFlowsThroughCity(?Nile?,?Cairo?)).?
For each proposed relation, a set of text extrac-tion patterns that can be used to extract addi-tional instances of the relation (e.g., the text ?Xin the heart of Y?, where X is a known river,and Y a known City, suggests extractingRiverFlowsThroughCity(X,Y)).Note the above inputs are easily available fromNELL in the form of its existing ontology and ex-tracted knowledge base.
Note also that the outputs*  Thahir P. Mohamed is currently at Amazon Inc.1  NELL?s extracted knowledge can be viewed anddownloaded at http://rtw.ml.cmu.edu.1447of our system are sufficient to initiate NELL?slearning of additional extraction methods to furtherpopulate each proposed relation.
One goal of thisresearch is to create a system that can provideNELL with an ongoing set of new learning andextraction tasks.
The system is called OntExt (On-tology Extension System)Table 1 shows a sample of successful relationsand corresponding relation contexts and sampleseed instances generated by OntExt.Table 1.
Examples of valid relations (generatedby OntExt), their text extraction patterns andextracted instances.name(category1-main context-category2)Extraction pat-ternsSeedInstancesRiver-in heart of-City?in heart of?
?in the centerof?
?which flowsthrough?
?Seine, Paris?
?Nile, Cairo?
?Tiber river, Rome?
?River arno, Florence?Food-to produce-Chemical?to produce?
?to make?
?to form?
?Salt, Chlorine?
?Sugar, Carbon diox-ide?
?Protein, Serotonin?StadiumOrVenue-in downtown-City?in downtown?
?Ford field, Detroit?
?Superdome, New Or-leans?
?Turner field, Atlanta?Disease-caused by-Bacteria?caused by?
?is the causa-tive agent of?
?is the causeof?
?pneumonia, legionel-la?
?mastitis, staphylococ-cus aureus?
?gonorrhea, neisseriagonorrhoeae?Disease-destroys-CellType?destroys??attacks?
"alzheimer, brain cells"?vitiligo", melano-cytes""aids, lymphocytes"County-county-StateOrProvince?county?
?county of?
?county in?
"sufolk, massachusetts""marin, california""sussex, delaware""osceola, michigan"2 BackgroundTraditional Relation ExtractionWe define Traditional RE systems as those thatrequire the user to specify information about therelations to be learned.
For instance, SnowBall(Agichtein and Gravano 2000) & CPL (Carlson etal.
2009) are bootstrapped learning systems thatrequire manual input of relation predicates.
In the-se systems, for each relation predicate, the relationname (e.g.
City ?Capital of?
Country), the seed in-stances and the category type (e.g.
City, Country,Celebrity etc) are provided (for domain and range).In CPL (Carlson et al 2009), learning of rela-tion/category instances is coupled by using con-straints such as mutual exclusion relationshipsamong the predicates.
The authors show that thiscoupling reduces semantic drift, which commonlyoccurs with bootstrapping systems, thus leading toimproved precision.
CPL achieved 89% precisionfor the relation instances extracted (Carlson, Bet-teridge et al 2009).
KNOWITALL (Etzioni, Ca-farella et al 2005) is a web-scale relation extrac-tion system, which requires as input the relationnames.
Hence, in these ?traditional relation extrac-tion?
methods, the need to manually define the re-lations to be extracted makes it difficult to work inapplications having thousands of possible relationpredicates.2.1 Open Relation ExtractionOpen RE methods do not require a user to manual-ly specify the information about the relations to belearned, such as their names, seed examples, etc.TextRunner (Banko, Cararella et al 2007) is suchan Open Information Extraction system that re-trieves from the web millions of relational tuplesbetween noun phrase entities.
TextRunner uses adeep linguistic parser to perform self-supervisedlearning and extracts a positive set (i.e.
valid rela-tion between entities) and a negative set (i.e.
inva-lid relationships) of relational tuples based on cer-tain heuristics.
Then, a Naive Bayes classifier isbuilt having features such as part-of-speech tags ofthe words in the relation tuples, number of tokens,stopwords etc., and uses the labeled instances asthe training set.
This classifier runs on sentencesfrom a web corpus to extract millions of relationaltuples.
However, of the 11 million high confidentrelational tuples extracted by this system only 1million were concrete facts (Banko, Cararella et al2007).
Of these concrete facts 88% were estimatedto be correct.
For instance, (Mountain View, head-quarters of, Google) is a tuple representing a validconcrete fact.
The remaining 90% of the tuples areabstract or do not have well-formed arguments orwell-formed relations.
For instance, (Einstein, de-rived, theory) is an abstract tuple as it does not1448have enough information to indicate a concrete fact(Banko, Cararella et al 2007) because the specifictheory which Einstein derived is missing in thattuple.
In the tuple (45, ?went to?, ?Boston?
), one ofthe arguments (i.e.
45) is not well formed.In (Banko and Etzioni, 2008) a ConditionalRandom Field (CRF) classifier is used to performOpen Relation Extraction which improves by morethan 60% the F-score achieved by the Naive Bayesmodel in the TextRunner system.
However theCRF approach does not solve the problem associ-ated with extraction of abstract/non-well formedtuples.
Further, in the same work, it is shown thatOpen RE has a much lower recall in comparison toTraditional RE systems.
On four common relations(Acquisition, Birthplace, InvetorOf, WonAward),Open RE attained a recall of 18.4% in comparisonto 58.4% achieved by Traditional RE (Banko andEtzioni 2008).
Both Open RE systems discussed(Banko, Cararella et al 2007; Banko and Etzioni2008) do not perform learning of the category typeof the entities involved in the relations.
They aresingle-pass and do not perform continuous learningto improve/extend on what has been learnt.2.2 Unsupervised Methods to Extract Rela-tions between Named EntitiesIn general, traditional RE methods extract concretefacts and have much higher recall for a given rela-tion, than Open RE methods.
This is due to theknowledge fed into Traditional RE methods suchas the category type of the entities in the relationand seed instances for the relation.
Traditional REmethods require the relations to be manually de-fined and extract instances only for them.
Open REmethods, on the other hand, do not require anysuch domain specific knowledge to be manuallyinput.
They extract instances for a wide spectrumof relations that are not manually pre-defined.To overcome the drawbacks of using Traditionaland Open RE methods, some researchers have usedunsupervised learning methods to automaticallygenerate new relations (with seeds and contexts)between specific categories.
These automaticallygenerated relations can then be used as input toTraditional RE systems.Hasegawa et.al (Hasegawa, Sekine et al 2004),propose an unsupervised clustering based ap-proach.
One feature vector for each co-occurringNE pair is formed based on the context words inwhich the NE pair co-occurs.
Then, a cosine-similarity metric is applied to each pair of featurevectors to generate a ?NE-pair x NE-pair?
matrix.Clustering is done on this matrix and each clusterof NE-pairs corresponds to a relation predicate.The work by Zhang et.al (Zhang, Su et al 2005)generates a shallow parse tree for each sentencecontaining a NE pair to generate relation instances.A tree similarity metric is used to cluster the rela-tion instances.
This method gives improved F-score over Hasegawa et.al (Hasegawa, Sekine et al2004).
Further they use a specialized NE taggerbuilt to recognize entities that belong to specificpredefined categories.
The aforementioned meth-ods (Hasegawa, Sekine et al 2004) (Zhang, Su etal.
2005) were tested on a news corpus to identifyrelations between only a couple of pairs of entitytypes (Person-GeoPoliticalEntity and Company-Company).Both of these methods cluster NE-pairs primari-ly based on lexical similarity of the context wordsconnecting the entities.
Hence NE-pairs connectedby lexically different but semantically similar con-text patterns (e.g.
river ?in heart of?
city and river?flows through?
city) would probably not get clus-tered together.
The web data is, however, muchnoisier and has a larger number of entity types (i.e.category predicates), thus, another issue is that forweb scale data NE pairs X NE pairs similarity ma-trix would not be scalable for many thousands ofNE-pairs.3 Ontology Extension System - OntExtThe OntExt system for ontology extension, pro-posed in this paper, combines characteristics fromboth ?Traditional RE?
and ?Open RE,?
to discovernew relations among categories that are alreadypresent in the ontology, and for which many in-stances have already been extracted.Our proposed method for automatic relation ex-traction offers the following advantages over themethods discussed above.?
The key idea in our approach is to make useof redundancy of information in web data - thesame relational fact is often stated multipletimes in large text corpora, using different con-text patterns.
We use this redundancy to clus-ter together context patterns which are seman-tically similar although they may be lexicallydissimilar.1449?
Instead of clustering on the ?NE-pairs XNE-pairs?
matrix, clustering is done on a ?Con-text-pattern X Context-pattern?
matrix.
This ismuch more scalable as the context patterns arefewer in number and since our method appliesseveral criteria to prune out irrelevant patterns.?
To accommodate errors in the input catego-ry instances and ambiguity in web data, webuild a classifier which learns to distinguishvalid relations from semantically invalid rela-tions.OntExt has 3 components.
1) It starts exploringa large web corpus and 2) category instances ex-tracted by CPL to generate new relations.
After therelations are generated, 3) a classifier is developedto classify semantically valid relations.3.1 Pre-processingFollowing along the same strategy used in [Carlsonet al, 2010], OntExt uses as input a corpus of 2billion sentences, which was generated by usingthe OpenNLP2 package to extract, tokenize, andPOS-tag sentences from the 500 million web pageEnglish portion of the ClueWeb09 data [Callan andHoy, 2009].
Before performing relation extraction,this corpus is preprocessed.
First, sentences whichcontain a pair of known category instances are re-trieved (e.g.
the sentence ?Ottawa is the capital ofCanada.
?, where ?Ottawa?
is a known instance ofthe ?City?
category and ?Canada?
is a known in-stance of ?Country?).
For every category pair (e.g.<City, Country>) the sentences containing knowninstances of both categories are grouped into a setS.
The text between the two instances is called the?context pattern?
(e.g.
?is the capital of?
is a contextpattern).
Three types of pruning are done on thisset S.1.
If the context pattern is a rare one (i.e.
if thecontext pattern occurs in less than a thresholdnumber of sentences), all sentences with thatcontext pattern are removed.
Thus we retainonly frequently occurring contexts.
We use athreshold requiring at least 5 sentences in theexperiments presented in Section 4.2.
Context patterns which co-occur with veryfew instances of either category type are re-moved.
For example, the category pair <Vehi-cle,SportsTeam> has several sentences such as2  http://opennlp.sourceforge.net.
?Car was engulfed in flames?,  ?Truck was en-gulfed in flames?
etc.
Note that Flames (Calga-ry Flames) is a SportsTeam.
But here flamesclearly does not refer to a Sportsteam.
Thiscontext ?was engulfed in?
connects several in-stance of a ?Vehicle?
category to a single in-stance of SportsTeam instance.
Hence all sen-tences with this context are removed.
Note thiscontext would not have been removed in step 1as that is just a threshold on the number of sen-tences in which any pair occurs.
We use athreshold requiring at least 3 distinct instancesof both the domain and the range, for eachcontext.3.
Banko et.al, 2008 show that most binary re-lational contexts fall under certain types of lex-ico-synctatic patterns.
They include contextpatterns like ?C1 Verb C2?, ?C1 NP Prep C2?,?C1 Verb Prep C2?
and ?C1 to Verb C2?
(C1and C2 are category instances).
Hence contextpatterns which do not fall under the abovetypes are removed from the set S as they arenot likely to produce relation instances.3.2 Relation GenerationFrom the previous pre-processing step OntExt re-trieves for each category pair a pruned set S?
ofsentences.
Each sentence has a pair of categoryinstances and the context connecting them.Algorithm 1: Relation GeneratorInput: One pair of Categories (C1, C2) and set ofsentences, each containing a pair of instancesknown to belong to C1 and C2.
The phrase con-necting the instances in the sentence is the context.Output: Relations and their seed instancesSteps:1.
From the input sentences, build a Context byContext co-occurrence matrix (Shown in figure1).
The matrix is then normalized.2.
Apply K-means clustering on the matrix tocluster the related contexts together.
Each clus-ter corresponds to a possible new relation be-tween the two input categories.
(Weka Ma-chine Learning package [Hall et al, 2009] wasused to perform K-means clustering.
The valueof K was set to 5 based on trial and error ex-periments.)14503.
Rank the known instance pairs (belonging toC1,C2) for each cluster and take the top 50 asseed instances for the relationThe key data structure used by OntExt is a co-occurrence matrix of the contexts for each categorypair, as shown in Figure 1.
In this matrix, each cellcorresponds to the number of pairs of category in-stances that both contexts co-occur with (e.g.
thesentences ?Vioxx can cure Arthritis?
and ?Vioxx isa treatment for Arthritis?
provide a case where the2 contexts ?can cure?
and ?is a treatment for?
co-occur with an instance pair [Vioxx, Arthritis]).
Ini-tially, the value of Matrix(I,j) is the number of cat-egory instance pairs that occur with both context iand context j.
We then normalize each cell in thematrix, dividing it by by the total count for its row.???
NjjiMatrixjiMatrixjiMatrix0),(),(),(We also give higher weight to contexts which co-occur with only a few contexts over ones which aregeneric and co-occur with most contexts.|}0),(:)({|*),(),( ??
jiMatrixjContextNjiMatrixjiMatrixWhere N is the total number of contexts, and|{Context(j) : Matrix(i,j) > 0}| refers to the numberof cells in the row Matrix(i) which are greater thanzero.For example, for the <drug, disease> categorypair after 122 contexts were obtained after prepro-cessing.
Contexts such as ?to treat?, ?for treatmentof?, ?medication?
which all indicate the same rela-tion (drug-to treat-disease) have high co-occurrence values (see Figure 1).
Similarly con-texts such as ?can cause?, ?may cause?, ?can lead to?
(indicating the relation drug-can cause-disease)have high co-occurrence values (see Figure 1).When OntExt performs clustering on this co-occurrence matrix the contexts with large co-occurrences get clustered together.
Each cluster isthen used to propose a possible new relation.
Thecentroid of each cluster is used to build the relationname.
If the centroid of a cluster is the context ?fortreatment of?, then the relation name is ?drug-for-treatment-of-disease?.OntExt next generates seed instances for theproposed relation.
The seed instances which co-occur with contexts corresponding to the clustercentroid or close to centroid will be best repre-sentative of the relation.
So the strength of the seedinstance is inversely proportional to the standarddeviation of the context from the centroid of therelation contexts cluster.
Also the strength of theseed instance is directly proportional to the numberof times it co-occurs with the context.Figure 1: This figure shows the Context by Contextsub-matrix (with 6 contexts) for the category pair(Drug, Disease) and the seed instances for eachrelation.
As described in the text, each entry givesthe normalized count of the number of known<drug, disease> pairs that occur with both the rowcontext and the column context.To summarize, each seed instance s (pair of cat-egory instances) is weighted as followsWhere,Pattern_cluster is the cluster of pattern contexts forthis given relationOcc(c,s) is the number of times instance ?s?
co-occurs with the pattern context ?c?sd(c) is the standard deviation of the context fromthe centroid of the pattern cluster.Using this metric the instances are ranked and thetop 50 are output as initial seed instances for theproposed relation.14513.3 Classifying semantically valid relationsMore than half of the relations generated in theprevious step are invalid due to the following rea-sons1.
Error in category instances: The categoryinstances input to OntExt come from NELL.
Inthe version of the knowledge base used in the-se experiments, the accuracy of these instanceswas 78%.
Due to the erroneous category in-stances some invalid relations are generated byOntExt.
For instance the generated relation,?condiment-wearing-clothing?
with seeds(pig,dress), (rabbit,pants) etc.
Here ?pig?
and?rabbit?
were incorrectly identified by NELL asinstances of ?condiment?.2.
Semantic Ambiguity: Consider the generatedrelation ?bakedgood-baking-magazine?
with in-stances (cookies,time), (cupcakes, people), etc.Here the instances ?time?
and ?people?
do notrefer to magazines, although they can in gen-eral.
Due to the semantic ambiguity of theseinstances this invalid relation got generated3.
Semantically Incomplete relations: Some ofthe generated relations require a third entity orsome more contextual information, in order tobe considered semantically valid.
For instance,?personUs-said-company?
or ?newspaper-is-reporting-that-company?.
These don?t stand bythemselves as two-argument relational factsand need more information to be complete4.
Illogical relations: Some generated relationssimply have no real semantic meaning.
Theserelations are generated due to the category in-stances appearing together in some unrelatedcontexts.
E.g.
the generated relation ?date-starting-date?
with seeds such as (Wednesday,June), (friday, July) and the relation ?country-minister-of- economicsector?
with seeds (ja-pan,agriculture), (india, industry).The introduction of these invalid relations canadversely affect the performance of NELL.
How-ever, it is a challenging problem to develop auto-mated ways to distinguish between valid and inva-lid relations without any domain specificknowledge.
To approach this problem, we identi-fied a set of features which can help characterizingvalid and invalid relations, and which can be gen-erated automatically.
Below is a description of thefeatures and the intuition behind their use for thisclassification task.Each generated relation has a pair of categorytypes (C1, C2), a corresponding set of seed in-stances (which are pairs of instances belonging toC1 and C2) and pattern contexts connecting C1and C2.
Let N be the number of seed instancepairs and N1 and N2 be number of unique instanc-es (out of these N instance pairs) belonging to cat-egories C1 and C2 respectively.1.
Normalized frequency count: The frequencycount of each category instance is obtainedfrom the corpus and normalized by the catego-ry instance with maximum count.
For a givenrelation, a feature is generated by averagingthe normalized frequency counts of the in-stances belonging to C1.
Another similar fea-ture is generated for C2 following the samestrategy.
For example the relation <Profession?believe that?
Movie> was generated due tocommon words like ?predator?, ?earthquake?being identified as movie names out of con-text.
These features can help identify such in-valid relations.2.
Distribution of extraction patterns: NELLlearns instances as well as extraction patternsfor each category (e.g.
the category Actor hasextraction patterns such as ?_ got an Oscaraward?, ?_ is the movie?s lead actor?).
If a cat-egory instance co-occurs in the web corpuswith several extraction patterns belonging toother categories, then that instance has largeambiguity.
We measure ambiguity of an in-stance (i) belonging to category ?C?
with re-spect to another category ?M?
(where M is nota sub type or super type of ?C?)
asAmbiguity(i,M) =withoccurs-co i''  that C''in  patterns extraction of #ithoccurs-co i'' that M''in  patterns extraction of #We measure the average ambiguity for the setof instances (of size N) belonging to categoryC in the generated seeds as follows,?
?CiM NMiAmbiguityMax /),(()Two features are generated for categories C1and C2 in the relation.3.
Relationship characteristics: We identified afew characteristics of the relation which helpin identifying valid relations.
If in the generat-ed relation, most instances of C1 co-occur only1452with very few instances of C2 (or vice versa)then the relation could be weak.
For example,<Organization ?Provides?
EconomicSector> -the instance ?Information?
(of category Eco-nomicSector) connects to a large percentage ofitems in the category ?Organization?
but doesnot express a meaningful relation.
So we con-sider the instance (in this example ?Infor-mation?, let us call it ?maxconnect_instance?
)co-occurring with maximum number of in-stances of the other category.
The percentageof instances it co-occurs with from among thetotal number of instances of the other categorywhich are part of the seed instances is taken asa feature.
Also if that instance is a very com-mon word (like ?information?
which in severalcontexts does not refer to ?EconomicSector?
)then this could indicate the presence of an in-valid relation.
So the normalized frequencycount of this instance (maxconnect_instance) istaken as another feature.4.
Pattern Contexts: The number of pattern con-texts attained through pattern clustering for therelation is taken as another feature.
The pres-ence of several pattern contexts connecting theinstances between the two categories could in-dicate that the relation is a valid one.
Thepresence of Hearst patterns (Hearst M, 1992)referring to a hyponym (?is-a?)
relation in pat-tern contexts indicates the possibility of a validrelation, and is taken as another featureAnother feature is regarding how specific isthe context pattern to this relation.
If the samecontext connects say C1 instances to instancesof several other categories apart from C2, thenthis context is not unique to this relation andmight not indicate a meaningful valid relation-ship.
So the ratio of the number of instances inC2 connected to C1 versus the number of in-stances from all categories connected to C1 bythe most significant pattern context (i.e.
cen-troid in pattern cluster) is taken as a feature.
Asimilar feature is generated for C2 as well.4 Experimental Setup and Results4.1 CPL SystemCPL (Carlson et al, 2010) is a semi-supervisedlearning system which takes in an input ontology(containing category and relation predicates andcorresponding seed instances) and constraints(such as Mutual exclusion rules between predi-cates).
The system iteratively extracts patterns andinstances for the category/relation predicates froma web corpus of around 500 million web pages.CPL is one learning component in NELL (the Nev-er Ending Language Learner) (Carlson et al,2010b).4.2 Relation Generation:We use approximately 22,000 category instancesbelonging to 122 categories extracted by CPL atthe end of its 20th iteration and the web corpus asinput to perform the co-clustering described inSection 3.2 and generate the new relations.
Theprocess generated 781 relations.
For each relation,the relation name, types of the categories involvedin the relation and the seed instances and patternsfor each relation were generated.
Table 1 in section1 shows a sample of valid relations generated bythis method.Tables 2, 3, 4 and 5 show invalid relations foreach type of invalidity, ?Error in the Category In-stances?, ?Semantic Ambiguity?, ?SemanticallyIncomplete Relations?
and ?Illogical Relations?respectively.
More specifically, Table 2 shows asample of relations generated due to an entity be-ing labeled incorrectly as to belong to a category.The incorrect category instances are in italics.Table 3 presents a sample of relations whichwere generated because of semantic ambiguity.Instances with ambiguity are in italics.Table 4 shows some of the generated relationswhich are semantically incomplete.Table 5 presents samples of illogical relationswhich do not establish any concrete fact.Table 2.
Examples of Incorrect category in-stances.name(category1-main context-category2)RelationContextsSeedInstancesSportsGame-Beating-Country?beating?
"tournament,Sri Lanka""champions, France""match, canada"Animal-will eat-Condiment?will eat??eating?
"wolf, sheep""fox, rabbit""lion, lamb"1453Table 3.
Examples of Semantically Ambiguousrelations.Name RelationContextsSeedInstancesBird-play-City?play?
"Cardinals, Atlanta""Ravens, Miami""Eagles, Chicago"BakedGood-baking-Magazine?baking?
"time, cakes""people, cookies"Table 4.
Examples of semantically incompleterelations.Name RelationContextsSeedInstancesPersonusacknowledgedDate?acknowledged??warned??met?
"mr obama, tues-day""george w .
bush,tuesday""al gore, thursday"NewsPaper-is reportingthat-Company?is reportingthat?
?writes that?
?reported that?
"financial times,apple""wall street jour-nal, gm""wall street jour-nal, yahoo"Table 5.
Examples of relations representingfacts that are not concrete.Name RelationContextsSeedInstancesEmotion-of living in-StateOrProvince?of living in?
"joy, california""excitement, colora-do""fear, iowa"BodyPart-to keep-BodyPart?to keep??guard?
?hand, eye?
?nose, throat?
?eye, brain?
?elbow, hand?4.3 Relation Classification:To determine the feasibility of automatically classi-fying OntExt?s proposed relations as valid or inva-lid, we trained and tested a classifier using the fea-tures described above, using manually assignedclass label for some of the generated relations (252relations) as valid or invalid (the criteria for whichwas explained before).
115 of these 252 relationswere found to be valid by manual evaluation.
Thisshows the need for a machine learning classifier toidentify valid/invalid relations.
The various fea-tures described earlier (such as normalized fre-quency count, relationship characteristics, patterncontext features, distribution of extraction patterns)were generated for each relation.
Ten-fold crossvalidation experiments were carried out with vari-ous classifiers.
A Random Forest classifier per-formed the best.
Precision, recall and ROC-area isshown in the table below (ROC area is the areaunder the ROC curve which plots the classifierperformance by having the True Positive Rate onthe Y-axis and False Positive Rate on the X-axis).Table 6.
Classifier performance.RelationType Precision Recall ROC AreaValid 71.6 72.2 0.804Invalid 76.5 75.9 0.804WeightedAvg.74.2 74.2 0.804These results indicate that the system is able tolearn to identify semantically valid relations with-out using any manually input information.
The val-id relations generated can be input to NELL, al-lowing it to iteratively learn additional instancesfor each proposed relation.5 Conclusion and Future work:Open Relation Extraction and Traditional RelationExtraction have their respective strengths andweaknesses.
The OntExt system proposed in thiswork combines the strengths of both of thosemethods.
The relation predicates automaticallygenerated by our approach are typed, have a mean-ingful name identifying the relation, and are ac-companied by suggested context patterns and seedinstances.
These relations can be input to NELL tolearn more instances for the relation.
We proposein the future to integrate this relation generationsystem into NELL, to iteratively extend NELL?sinitial ontology, providing an ongoing stream ofnew learning tasks.
After every fixed set ofNELL?s iterations, its growing knowledge basewould be input to the relation generation systemwhich will in turn feed NELL with new relationpredicates.
One additional area for future researchis to extend OntExt to discover new categories inaddition to new relations.1454AcknowledgementsWe gratefully acknowledge support for this re-search from Darpa, Google, Yahoo!
and the Brazil-ian research agency CNPq.
We also gratefullyacknowledge Dr. Madhavi Ganapathiraju (at Uni-versity of Pittsburgh) for her support and encour-agement.ReferencesAgichtein, E. and L. Gravano (2000).
"Snowball: Ex-tracting relations from large plain-text collections."Procs.
of the Fifth ACM International Conference onDigital Libraries.Banko, M., M. Cararella, et al (2007).
"Open infor-mation extraction from the web."
In Procs.
of IJCAI.Banko, M. and O. Etzioni (2008).
"The Tradeoffs Be-tween Open and Traditional Relation Extraction."
InProceedings of ACL-08.Callan, J., and Hoy, M. (2009).
Clueweb09 data set.http://boston.lti.cs.cmu.edu/Data/clueweb09/.Carlson, A., J. Betteridge, et al (2009).
"CouplingSemi-Supervised Learning of Categories and Rela-tions."
Proceedings of the NAACL HLT 2009 Work-shop on Semi-supervised Learning for Natural Lan-guage Processing.A.
Carlson, J. Betteridge, et al (2010).
?Coupled Semi-Supervised Learning for Information Extraction,?Proceedings of the ACM International Conference onWeb Search and Data Mining (WSDM), 2010.A.
Carlson, J. Betteridge, et al, (2010b).
?Toward anArchitecture for Never-Ending Language Learning,?Proceedings of the Conference on Artificial Intelli-gence (AAAI), 2010.Etzioni, O., M. Cafarella, et al (2005).
"Unsupervisednamed-entity extraction from the web: An experi-mental study."
Artificial Intelligence.Hasegawa, T., S. Sekine, et al (2004).
"Discoveringrelations among named entities from large corpora.
"Proceedings of the 42nd Annual Meeting on Associa-tion for Computational LinguisticsZhang, M., J. Su, et al (2005).
"Discovering Relationsbetween Named Entities from a Large Raw CorpusUsing Tree Similarity-based Clustering."
IJCNLP 05.Hasegawa, T., S. Sekine, et al (2004).
"Discoveringrelations among named entities from large corpora.
"Proceedings of the 42nd Annual Meeting on Associa-tion for Computational LinguisticsZhang, M., J. Su, et al (2005).
"Discovering Relationsbetween Named Entities from a Large Raw CorpusUsing Tree Similarity-based Clustering."
IJCNLHearst, M. (1992) Automatic Acquisition of Hyponymsfrom Large Text Corpora.
Proc.
of the Fourteenth In-ternational Conference on Computational Linguistics,Nantes, FMark Hall, Eibe Frank, Geoffrey Holmes, BernhardPfahringer, Peter Reutemann, Ian H. Witten (2009);The WEKA Data Mining Software: An Update;SIGKDD Explorations, Volume 11, Issue 1.1455
