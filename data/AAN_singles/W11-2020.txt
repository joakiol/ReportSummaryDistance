Proceedings of the SIGDIAL 2011: the 12th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 173?184,Portland, Oregon, June 17-18, 2011. c?2011 Association for Computational LinguisticsModeling and Predicting Quality in Spoken Human-Computer InteractionAlexander Schmitt, Benjamin Schatz and Wolfgang MinkerDialogue Systems Research GroupInstitute for Information TechnologyUlm University, Germany{alexander.schmitt, benjamin.schatz, wolfgang.minker}@uni-ulm.deAbstractIn this work we describe the modeling andprediction of Interaction Quality (IQ) in Spo-ken Dialogue Systems (SDS) using SupportVector Machines.
The model can be employedto estimate the quality of the ongoing inter-action at arbitrary points in a spoken human-computer interaction.
We show that the useof 52 completely automatic features character-izing the system-user exchange significantlyoutperforms state-of-the-art approaches.
Themodel is evaluated on publically available datafrom the CMU Let?s Go Bus Information sys-tem.
It reaches a performance of 61.6% un-weighted average recall when discriminatingbetween 5 classes (good to very poor).
It canbe further shown that incorporating knowl-edge about the user?s emotional state doeshardly improve the performance.1 IntroductionFor years, the research community has been tryingto model quality of Spoken Dialogue Systems (SDS)with statistical approaches.
Most vividly discussedhas been the PARADISE approach which tries tomap objective performance metrics of an SDS tosubjective user ratings (Walker et al, 2000).
Theparadigm assumes that task success and dialoguecosts contribute to user satisfaction which is the tar-get variable in the model.
By that, an automatic eval-uation of an SDS should be enabled.
While the in-tention of PARADISE is to evaluate and compareSDS or different system versions among each other,it is not suited to evaluate a spoken dialogue at ar-bitrary points during an interaction.
Such a modelcan be helpful for a number of reasons: Firstly,it allows for a prediction of critical dialogue sit-uations.
These predictions could be employed toadapt the dialogue strategy or - in telephone appli-cations with human assistance - escalate to humanoperators.
Secondly, it could help to uncover poten-tially weak dialogue design and point out problem-atic turns that need a re-design.
Thirdly, user sat-isfaction models help understand the satisfaction ofthe users.
In this study we present such a statisti-cal model that is trained with a large set of domain-independent features taken from system logs and useadditional manually created features, such as emo-tional state and dialogue acts, to create an upperbaseline.This paper is organized as follows: In Section 2we present related work and discuss afterwards inSection 3 further issues that need to be addressed inthis field.
There, we also disambiguate the term usersatisfaction from Interaction Quality.
After that, wedescribe the annotation scheme as well as the ratingprocess for modeling IQ and present, how we derivea generic label from the different raters?
opinions inSection 4.
The input feature groups along with theirfeatures are presented in Section 5.
We anticipatethat the problem is best modeled with Support Vec-tor Machines (SVM), which is addressed in Section6.
Ensuing, the performance of the model is evalu-ated.
In the first place, we analyze the impact of dif-ferent feature groups on the SVM classifier in Sec-tion 7 and secondly, we optimize the model and de-termine the most relevant features for predicting theIQ score in Section 8.
A linear modeling approachof IQ by use of multivariate linear regression will be173presented and discussed in Section 9 to obtain com-parability with PARADISE.
This study closes witha conclusion and a discussion in Section 10.2 Related WorkModels predicting user satisfaction at any point inan SDS have only been deficiently explored to date.
(Engelbrecht et al, 2009) modeled user satisfac-tion as process evolving over time with HiddenMarkov Models (HMM).
In the experiment, userswere asked to interact with a Wizard-of-Oz restau-rant information system.
Each participant followeddialogues which have previously been defined fol-lowing predefined scripts, i.e.
specific scenarios.This resulted in equally long dialogue transcriptsfor each scenario.
The users were constrained torate their satisfaction on a 5-point scale with ?bad?,?poor?, ?fair?, ?good?
and ?excellent?
after each di-alogue step.
The interaction was halted while theuser voted.In a similar spirit, (Higashinaka et al, 2010a)developed a model for predicting turn-wise rat-ings, which was evaluated on human-machine andhuman-human dialogues.
The data employed wasnot spoken dialogue but text dialogues from a chatsystem and a transcribed conversation between hu-mans.
The labels in the model originated fromtwo expert raters that listened to the recorded in-teractions and provided turn-wise scores from 1-7on smoothness (?Smoothness of the conversation?
),closeness (?Closeness perceived by the user towardsthe system?)
and willingness (?Willingness to con-tinue the conversation?).
Rater-independent perfor-mance scores of the model reached about 0.2-0.24unweighted average recall, which is about 0.1 pointsabove the baseline of app.
0.14.
(Hara et al, 2010) created n-gram models fromdialogue acts (DA) to predict user satisfaction basedon dialogues from real users interacting with a musicretrieval system.
The model is based on overall rat-ings from the users measuring their satisfaction on afive point scale after the interaction.
The best resultcould be achieved with a 3-gram model that reached34% accuracy in distinguishing between six classesat any point in the dialogue.
It seems that the predic-tion of turn-level user satisfaction scores given onlyone overall dialogue-level score seems hardly possi-ble and is close to random: The prediction of the fiveuser satisfaction classes reach an average F-score aslow as 0.252, which is only 0.052 score points abovethe baseline of 0.20.
A similar result as (Hara et al,2010) was obtained by (Higashinaka et al, 2010b).Using HMMs they derived turn-level ratings fromdialogue-wide ratings.
The model?s performancewhen trained on dialogue-level ratings was closer torandom than when trained on turn-level ratings.
Theopen issues that arise from the cited work are ad-dressed in the following.3 IssuesOur aim is to create a general model that may beused to predict the quality of the interaction - orideally the actual satisfaction of the user - at arbi-trary system-user exchanges in an SDS.
It has be-come obvious from the cited work that current mod-els are not suited for deployment due to low predic-tion accuracy.
Crucial for a successful recognitionof user satisfaction is the choice and appropriatenessof the input variables.
(Higashinaka et al, 2010a),(Higashinaka et al, 2010b) and (Hara et al, 2010)employ a - mostly hand annotated - ?dialogue act?feature to predict the target variable.
Dialogue actsare frequently highly system-dependent and do notmodel the full bandwidth of the interaction.
(Engel-brecht et al, 2009) additionally employed contex-tual appropriateness, confirmation strategy and tasksuccess, of which many require hand annotation.
Yetit is mandatory for an automatic prediction of usersatisfaction to design and derive completely auto-matic features that do not require manual interven-tion.
It is further easy to comprehend that the mod-eling of user satisfaction in ongoing dialogues startswith a dilemma: tracking user satisfaction from realusers in real environments performing real tasks isvirtually impracticable.
Consequently data for de-riving models can either be obtained under labora-tory conditions with real users performing fake tasksin an artificial environment, cf.
(Engelbrecht et al,2009), or by manual annotation of real-life data fromexperts that pretend to be the users.It is thus vital for modeling ?user satisfaction?
tounderstand the term itself.
In the literature there ex-ists no rigorous definition, however, it seems obvi-ous that it is the user himself who determines the174satisfaction - and not expert annotators.
Accord-ing to (Doll and Torkzadeh, 1991) ?user satisfac-tion?
is the opinion of users about a specific com-puter application, which they use.
Other terms for?user satisfaction?
are common, such as ?user infor-mation satisfaction?, which is defined as ?the extentto which users believe the information system avail-able to them meets their information requirements?
(Ives et al, 1983).
User satisfaction and usability areclosely interwoven.
(ISO, 1998) subsumes under thedefinition ?usability?
a compound of efficiency, ef-fectiveness and satisfaction.
Yet satisfaction is oftenseen as a by-product of great usability in HCI lit-erature (Lindgaard and Dudek, 2003).
They couldalso show that user satisfaction ratings are subject tolarge fluctuations among different users and it can befurther assumed that those fluctuations do also occurwithin a single dialogue of a user.
As a result, gen-eral prediction models that mirror a universal, un-biased understanding of satisfaction can presumablyhardly be derived from user?s impressions.
Largeinfluence of subjectivity - and also randomness inassigning the scores - would prevent such a generalmodel.
Consequently, it seems unavoidable to em-ploy expert annotations.
In the proper meaning ofthe word, the scores then do not exactly mirror thesubjective impression of users but the more objec-tive impression of expert raters.Thus we decide against the use of the term usersatisfaction in the course of this work in contrast to(Higashinaka et al, 2010a) and instead opt for theexpression Interaction Quality.
It can be assumedthat basic attitudes towards dialogue systems in gen-eral, opinions about the TTS voice, environmentalfactors etc.
that would typically influence user satis-faction scores, and which are not of interest for ourprediction, are not dominant in expert satisfactionscores in a series of annotated dialogues.
Expertsare expected to fade out such system-dependent andenvironment-dependent influences and instead focuson the dialogue behavior (i.e.
the Interaction Qual-ity) only.As a result, two key issues are addressed in thiswork: First of all, the input feature set has to be de-signed as a generic, domain-independent set that canbe derived from any spoken dialogue system log andthat takes into account a maximum of available in-formation about the interaction.
Secondly, the tar-get variable, i.e.
the IQ score, needs to be deter-mined in a guided rating process in order to be re-producible in future work and has to be empiricallyderived from several expert annotators that providescores for each single system-user turn of an inter-action.4 Corpus AnnotationFor our study we employ data from the Let?s GoBus information system (Raux et al, 2006).
Threeraters, advanced students of computer science andengineering, annotated respectively 200 dialoguescomprising 4885 system-user exchanges from the2006 corpus.
The raters were asked to annotate thequality of the interaction at each system-user ex-change with the scores 5 (very good), 4 (good), 3(fair), 2 (poor) and 1 (very poor).
Every dialogueis initially rated with a score of 5 since every inter-action at the beginning can be considered as gooduntil the opposite eventuates.
Our model assumesthat users are initially interacting with an SDS with-out bias, i.e.
the basic attitude towards a dialoguesystem is positive.
Other assumptions would not bestatistically predictable.
An example dialogue is de-picted in Table 5 along with the ratings (cf.
Figure 2in the Appendix).
(Higashinaka et al, 2010b) and(Higashinaka et al, 2010a) report low correlationamong the ratings (Spearman?s ?
0.04-0.32), whichmotivated us to develop a set of basic guidelines thatshould be used by the raters (cf.
Table 6 in the Ap-pendix).
The guidelines have been designed in sucha way that the raters still have sufficient level of free-dom when choosing the labels but preventing themfrom too strong variations among the neighboringsystem-user exchanges.The distribution of the labels provided by the sin-gle raters is depicted in Figure 3.
As expected, thedistribution is skew towards label ?5?
since every di-alogue initially is assumed to have a good IQ.The inter-rater agreement shows that InteractionQuality is still a subjective metric, although guide-lines seem to synchronize the labels to a certain ex-tent.
The overall mean agreement can be reportedwith Cohen?s ?
= 0.31 and the correlation amongthe raters can be reported with Spearman?s ?
= 0.72which depicts a by 0.4 points higher correlation asreported by (Higashinaka et al, 2010a).
Since we175aim to model a general opinion on Interaction Qual-ity, i.e.
the model should mirror the IQ score otherraters - and in the last instance users - agree with,we determine the final label empirically.
A major-ity voting for the distinction of the final label can-not be used since in 21% of the exchanges all threeraters opted for different scores.
Thus we considerthe mean of all rater opinions as possible candidatesfor the final class label:ratingmean = b(1RR?r=1IQr)+ 0.5cwhere IQ is the Interaction Quality score pro-vided by rater r. byc denotes the biggest integervalue smaller than y.
Every value IQr contributesequally to the result that is finally rounded half up toan integer value.
Furthermore we consider the me-dian, which we define asratingmedian = select(sort(IQR),R+ 12)for an odd number of raters R, where sort is a func-tion that orders the ratings of all raters ascending andselect(X = [x1, ..., xn], i) chooses the item with in-dex i from X .The compliance of the single user ratings with thefinal label (calculated on mean and median) is de-picted in Table 1.
As can be seen, the agreement ofthe three raters with the median label is significantlyhigher than with the mean label.
Consequently themedian label represents the most objective measure-ment of Interaction Quality and commends itself forcreating the model.5 Input FeaturesThe system-user interaction is modeled on exchangelevel.
Each system-user exchange consists of a setof fully automatic features that can be derived fromsystem logs.
We used parameters similar to the onesdescribed in (Schmitt et al, 2008; Schmitt et al,2010b).
In the first place, we modeled each system-user exchange with a number of Speech Recognition(ASR), Spoken Language Understanding (SLU) andDialog Manager (DM)-related features:Mean Label Median LabelCohen?s ?Rater1 0.557 0.688Rater2 0.554 0.679Rater3 0.402 0.478Mean 0.504 0.608*Spearman?s ?Rater1 0.901 0.900Rater2 0.911 0.907Rater3 0.841 0.814Mean 0.884 0.874AccuracyRater1 0.651 0.755Rater2 0.647 0.749Rater3 0.539 0.598Mean 0.612 0.701*Table 1: Agreement of single rater opinions to the mergedlabel when determined by mean and median, measured in?, ?
and accuracy.
(*)=significantly higher (?
< 0.05)ASR ASRRECOGNITIONSTATUS: one of ?suc-cess?, ?reject?, ?timeout?
; ASRCONFIDENCE:confidence of the ASR; BARGED-IN?
: did theuser barge-in?, MODALITY: one of ?speech?,?DTMF?
; EXMO: the modality expected fromthe system (?speech?, ?DTMF?, ?both?
); UN-EXMO?
: did the user employ another modal-ity than expected?
; GRAMMARNAMES: namesof the active grammars; TRIGGEREDGRAM-MAR: name of grammar that matched; UTTER-ANCE: raw ASR transcription; WPUT: num-ber of words per user turn; UTD: utterance turnduration;SLU SEMANTICPARSE: semantic interpretationof caller utterance; HELPREQUEST?
: is thecurrent turn a help request?
; OPERATORRE-QUEST?
: is the current turn an operator re-quest?
;Dialog Manager ACTIVITY: identifier ofthe current system action; ACTIVITY-TYPE: one of ?question?, ?announcement?,?wait for user feedback?
; PROMPT: systemprompt; WPST: number of words per systemturn; REPROMPT?
: is the current system turna reprompt?
; CONFIRMATION?
: whether the176current system prompt is a confirmation toelicit common ground between user and systemdue to low ASR confidence; TURNNUMBER:current turn; DD: dialog duration up to thispoint in seconds.To account for the overall history of importantsystem events we added running tallies, percentagesand mean values for certain features symbolizedwith the suffixes ?#?, ?%?
and ?MEAN?.
Theyare: MEANASRCONFIDENCE, the average ofASR confidence scores from all user utterancesso far in the dialog, and #ASRSUCCESS, thenumber of succesfully parsed user utterances so far.Further we calculate #ASRREJECTIONS, #TIME-OUTPROMPTS, #BARGEINS, #UNEXMO and therespective normalized equivalents with the prefix?%?
instead of ?#?.
We consider the immediatecontext within the previous 3 turns of the currentturn as particularly relevant for the Interaction Qual-ity.
Hence, derived from the basic parameters wecreated further parameters that emphasize specificuser behavior prior to the classification point.
Theyare symbolized with the prefix {#} for a number and{Mean} for the mean value.
A number of successivebarge-ins or recognition problems might indicate alow IQ.
Thus we add {MEAN}ASRCONFIDENCE,the mean confidence of the ASR within the win-dow, {#}ASRSUCCESS, {#}ASRREJECTIONSand {#}TIME-OUTPROMPTS, i.e.
the numberof successfully and unsuccessfully parsed ut-terances within the window and the numberof time-outs.
The other counters are calcu-lated likewise: {#}BARGEINS; {#}UNEXMO,{#}HELPREQUESTS, {#}OPERATORREQUESTS,{#}REPROMPT, {#}CONFIRMATIONS,{#}SYSTEMQUESTIONS.To provide comparability to previous work (Hi-gashinaka et al, 2010a), we further introduce adialogue act feature group that we create semi-automatically:DAct SYSTEMDIALOGUEACT: one of 28 dis-tinct dialogue acts, such as greeting,offer help,ask bus, confirm departure, deliver result, etc.USERDIALOGUEACT: one of 22 distinct DAs,such as confirm departure, place information,polite, reject time, request help, etc.To create an upper baseline of our model we fur-ther introduce the negative emotional state of theuser that is manually annotated by a human raterwho chooses one of the labels garbage, non-angry,slightly angry, very angry for each single user turn:Emo EMOTIONALSTATE: emotional state of thecaller in the current exchange.
One of garbage,non-angry, slightly angry, very angry.The same annotation scheme as in our previouswork on anger detection has been applied, see e.g.
(Schmitt et al, 2009).
From all 4,832 user turns,68.5% were non-angry, 14.3% slightly angry, 5.0%very angry and 12.2% contained garbage, i.e.
non-speech events.
In total, the number of interactionparameters servings as input variables for the modelamounts to 52.6 Non-Linear Modeling with SupportVector MachinesThe IQ scores are classified with Support VectorMachines (Bennett and Campbell, 2000).
In short,an SVM uses a set of training examples(x1, y1) .
.
.
(xn, yn)|xi ?
X , yi ?
{?1, 1}to create a hyperplane that separates two classes{?1, 1} in such a manner that the smallest marginbetween all training samples is maximized.
The hy-perplane is described by a normal vector w and aso-called bias b.
To classify an unknown sample thefollowing decision rule is applied:Y = sgn[wTx+ b > 0] ={+1, wTx+ b > 0?1, wTx+ b ?
0Depending on the position of the training sample inrelation to the hyperplane, the class 1 or ?1 is as-signed to the unknown sample.
Multi-class prob-lems are solved by reducing the problem to severalbinary classification problems where usually a one-versus-all decision is applied.The model is constructed with an SVM with lin-ear kernel that uses the fast Sequential Minimal Op-timization (SMO) algorithm (Platt, 1999).
Inputvariables are features from the described groups, i.e.x ?
{DAct,ASR, SLU,DM,Emo}.
The targetvariable is the IQ score.1777 Feature Group EvaluationThe skew distribution of the five classes requires theemployment of an evaluation metric that weights theprediction of all classes equally.
Hence, a perfor-mance metric, such as accuracy, would not be a re-liable measurement.
We select the unweighted aver-age recall (UAR) to assess the model performance.Although it does not consider the severity of the er-ror, i.e.
predicting ?1?
for an IQ of ?5?
is consideredas fatal as predicting ?4?, it has been proven to be su-perior to other evaluation metrics, see (Higashinakaet al, 2010a), where the UAR is called Match Rateper Rating (MR/R).
It is defined as follows:MR/R(R,H) =1KK?r=1?i?
{i|Ri=r}match(Ri, Hi)?i?
{i|Ri=r}1,where K is the number of classes, here ?5?, and?match?
is either ?1?
or ?0?
depending on whetherthe classifier?s hypothesis Hi for the class r matchesthe reference label Ri.
In the course of this workwe will stick to the expression MR/R by reason ofclearness.
We further list Cohen?s ?
and Spearman?s?
to make our work comparable to other studies butwill use MR/R as central evaluation criterion and forfeature selection.We have split all available data into two disjointsubsets consisting of 60% of the dialogues for train-ing and testing via 10-fold cross-validation and theremaining 40% of the dialogues for optimization.The dialogues have been selected randomly.In order to assess the performance contribution ofthe single feature groups, we trained the SVM re-spectively with all features from the DAct, ASR, SLUand DM groups.
Further, we subsumed the groupsASR, SLU and DM as AUTO features since they canautomatically be derived from logs without manualintervention.
In addition, the AUTOEMO group con-tains all AUTO features plus the emotion label.
Fi-nally, the ALL group contains the AUTOEMO fea-tures plus the DAct features.
For all groups, the sup-port vector classifier has been trained and evaluatedin 10-fold cross validation with the 3110 exchangesfrom the 118 training/testing dialogues.
The firstturn of each dialogue has been excluded from theevaluation since each dialogue starts with a score of?5?.
Results are depicted in the first half of Table 2.Input Feature Selection MR/R ?
?Majority Baseline 0.200 0.0 NADAct no 0.269 0.136 0.363ASR no 0.605 0.551 0.753SLU no 0.250 0.083 0.293DM no 0.429 0.334 0.653AUTO no 0.584 0.526 0.776AUTOEMO no 0.606 0.549 0.785ALL no 0.619 0.559 0.800DAct ?
- - -ASR 13/25 0.598 0.545 0.730SLU 4/5 0.250 0.083 0.293DM 10/17 0.436 0.338 0.649AUTO 20/47 0.616 0.563 0.786AUTOEMO 31/48 0.604 0.545 0.785ALL 23/52 0.625 0.575 0.795Table 2: Model performance after 10-fold cross valida-tion on training/test set.
The first half comprises resultswhen all features of a group are employed.
The secondhalf contains results after feature selection on the opti-mization set ((x/y)=where x is the number of featuresused from all y available features.
)As can be seen, the model reaches a similarperformance as (Higashinaka et al, 2010a) withMR/R=0.26, when trained with dialogue act featuresalone.
The slightly higher performance of our modelcan potentially be explained by the lower numberof classes (5 vs. 7), a different definition of thedialogue act set, the employment of Support Vec-tor Machines instead of Hidden Markov Models orthe difference in the target variable (IQ vs. close-ness/smoothness/willingness).
It can be noted thatthe utilization of other features considerably outper-forms dialogue act features.
Particularly the groupof the ASR features alone reaches a performanceof 60.5%.
The employment of all AUTO featuresdelivers 58.4% which is 2.1% below the ASR fea-tures.
Consequently, other variables seem to beless meaningful for predicting the Interaction Qual-ity and seem to harm the performance of the SVM.The knowledge of the emotional state of the usercontributes with merely another 0.1% in compari-son to the ASR features.
It can be assumed that theemotion feature increases the recognition rate of thelower IQ scores ?1?
and ?2?.
However, this couldnot be confirmed: even when considering class-wise178performance values a significant contribution of theemotion feature cannot be observed.
We also haveto bear in mind that we employed hand-annotatedemotions.
Emotion recognition itself is error-proneand a distinction of the emotional state of the callerwith the employed annotation scheme can be ex-pected with approximately 70%-80% UAR, see e.g.
(Schmitt et al, 2010a).
The influence of emotionrecognition on the IQ distinction can be consideredas limited and is insofar not surprising as the occur-rence of strong anger in the data is not dominant(5.0%).
The contribution of the single features tothe classification result (across the groups they areassigned to) is analyzed in the following.8 Optimizing the Model by FeatureSelectionSince too many (potentially irrelevant) featuresmight harm the classifier?s performance we performfeature selection with the optimization set.
First,the features are ordered according to an Informa-tion Gain Ratio (IGR) ranking.
The 10 most rele-vant features according to IGR for predicting IQ aredepicted in Table 3.Feature IGR1 #ASRREJECTIONS 12 #TIMEOUT ASRREJ 0.9672883 #ASRSUCCESS 0.8342384 #REPROMPTS 0.8047525 %REPROMPTS 0.8004626 #TIMEOUTPROMPTS 0.7575967 #SYSTEMQUESTIONS 0.7575968 ROLEINDEX 0.6992469 DD 0.56683610 #BARGE-INS 0.566836Table 3: Top 10 features on optimization set according toIGR.As can be seen the Interaction Quality is obvi-ously heavily influenced by the performance of theASR.
In other words, it can be assumed that theraters themselves are influenced by the ASR?s per-formance when assigning the IQ scores.
All featuresbelong to the group AUTO, i.e.
they can be deter-mined automatically during runtime.
Furthermore,nearly all features are related to the overall interac-tion, i.e.
features related to the current exchange,such as UTTERANCE, ASRSUCCESS?
etc.
do noteven occur.
It can also be noted that the emotionalstate and the dialogue acts are not listed as most rel-evant features.
To determine the global maximum ofthe classifier, i.e.
the best performing feature set, weincrementally select the k topmost features from thelist and perform 10-fold cross validation on the opti-mization set.
A plot of the iterative feature selectionis depicted in Figure 1.8.2 Prediction Results 53Rapidminer GUIMissingfigureFigure 8.2: The Graphical User Interface of RapidMiner 4.6Table 8.1: Baseline perfomances.Configurations PerformanceCorpus Input Target MR/R ?
?LetsGo DAct IQ-Med - - -AUTO IQ-Med - - -ALL IQ-Med - - -LetsGoUser DAct IQ - - -AUTO IQ - - -ALL-U IQ - - -DAct US - - -AUTO US - - -ALL-U US - - -5 10 15 20 25 30 35 40 450.450.50.550.60.65 max#ParametersMR/RIGR Parameter SelectionFigure 8.3: Parameter selection performance on the LetsGo Corpus for the optimizationset using set AUTO for prediction of IQ-Med.Figure 1: Performance of the SVM when iteratively in-creasing the size of the feature vector with the k topmostfeatures according to IGR.Several observations can be made: the best per-forming feature set consists of 20 features with anabsolute performance of 65 % MR/R on the op-timization set.
However, a similar performancecan already be gained with the 7 top-most fea-tures.
All other features obviously neither signif-icantly decrease nor increase the performance andcan be considered irrelevant for predicting the IQscore.
The impact of feature selection on the modelwhen evaluated on the single feature groups fromthe test/training set using only the most relevant fea-tures from the optimization set can be seen in thelower part of Table 2.
Again, 10-fold cross vali-dation has been applied.
The AUTO group benefitsfrom the selection and delivers the highest perfor-mance with 20 features with an MR/R of 61.6%,which is an increase of 3.2%.
The upper baselinewith hand annotated features (ALL group) amountsto 62.5%.
The fact that the AUTOEMO set underper-forms with 60.4% - in comparison to the AUTO set- can be explained due to the potentially too smallsize of the optimization set.The confusion matrix for the AUTO feature set isdepicted in Table 4, along with the class-wise pre-cision and recall values.
The model yields the best179performance in predicting the scores at the edge, i.e.?5?
and ?1?.
In between, the confusion is slightlyhigher and the model performance lower.Table 4: Confusion matrix including class-wise preci-sion and recall values after 10-fold cross validation (train-ing/test set) using the AUTO set.
A (weighted average)accuracy of 67.5% can be derived.true 5 true 4 true 3 true 2 true 1 prec.pred.
5 721 154 42 9 5 0.774pred.
4 89 464 104 44 19 0.644pred.
3 17 63 231 49 38 0.580pred.
2 2 15 39 89 33 0.500pred.
1 4 23 29 27 169 0.670rec.
0.865 0.645 0.519 0.408 0.6409 Linear Regression ModelingModels from the initially mentioned PARADISE ap-proach presume a linear relationship between inputvariables - quantifying the dialogue - and the targetvariable US, the user satisfaction.
Assuming lin-earity, such linear models allow inferences such as?The longer the dialogue duration, the lower the sat-isfaction?.
While linear modeling is descriptive andeasy to read it delivers poor performance when ap-plied on non-linear problems.
Such non-linear prob-lems reach a better predictability using Support Vec-tor Machines (SVM).
Although we anticipate that arelationship between IQ and the interaction param-eters is not given, we list a multivariate linear re-gression model for comparison reasons with PAR-ADISE.The linear regression model of Interaction Qualityis calculated as follows:IQ =n?i=1wi ?
N (pi)where wi is the weight for the interaction parame-ters pi, and N the z-score normalization function.N normalizes the input variables to a mean of zeroand a standard deviation of one.
This eliminates thevariying scales of the input variables.From the CMU Let?s Go dataset we obtained thefollowing IQ function using the ALL feature set:IQ = 0.7797 ?
N (TURNNUMBER)+ 0.7797 ?
N (#SYSTEMTURNS)?
0.7386 ?
N (#ASRSuccess)?
0.7175 ?
N (#USERTURNS)?
0.3019 ?
N (%RePrompts)?
0.2371 ?
N (EMOTIONALSTATE)?
0.2224 ?
N (#ASRRejections)?
0.1961 ?
N (#TIMEOUTS ASRREJ)+ 0.1912 ?
N (ASRRECOGNITIONSTATUS)+ 0.1648 ?
N (ASRCONFIDENCE)?
0.1592 ?
N (#ASRSUCCESS)?
0.1466 ?
N (ACTIVITY)+ 0.1388 ?
N (ACTIVITYTYPE)+ 0.1231 ?
N (MEANASRCONFIDENCE)?
0.0981 ?
N (#SYSTEMQUESTIONS)+ 0.0948 ?
N (%ASRREJECTIONS)?
0.0918 ?
N (#TIMEOUTS ASRREJ)+ 0.0835 ?
N (#Reprompts)+ 0.0812 ?
N (%BARGE-INS)?
0.0567 ?
N (%TIME-OUTPROMPTS)?
0.0555 ?
N (#TIMEOUTS?ASRREJ)?
0.0467 ?
N (#Time-OutPrompts)+ 0.0461 ?
N (WPST)+ 0.0432 ?
N (HANDTRANSCRIPTION)?
0.0425 ?
N (LOOPNAME)+ 0.0375 ?
N (#SystemQuestions)+ 0.0374 ?
N (SEMANTICPARSE)?
0.0345 ?
N (BARGED-IN?
)+ 0.0338 ?
N (RoleIndex)?
0.0335 ?
N (#REPROMPTS)?
0.0316 ?
N (#ASRREJECTIONS)+ 0.0302 ?
N (REPROMPT?
)+ 0.0249 ?
N (WPUT)+ 0.0225 ?
N (ROLENAME)Parameters occurring in the top 10 feature list ac-cording to IGR (see Table 3) are printed in bold-face.
It is interesting to note that parameters relatedto the progress of the dialogue (TURNNUMBER,#SYSTEMTURNS, #USERTURNS) seem to play themost important role, which can easily be explained:the later in the dialogue, the higher the probabil-ity that the score is low, due to the nature of IQ.Remember that all dialogues have been annotatedwith high IQ scores (?5?)
in the beginning (see also180Table 5).
However, many inconsistencies remainunexplained, e.g.
the negative sign in ?
?0.7175 ?N (#USERTURNS)?
contradicting the positive signin ?+0.7797 ?
N (#SYSTEMTURNS)?.
The nega-tive sign in ?
?0.7386 ?
N (#ASRSUCCESS)?
wouldfurther imply that the more successful the ASR, thelower the IQ score.
This corroborates our suspicionthat IQ is not a linear problem.To assess the performance of linear regression forpredicting IQ we employed 10-fold cross validation,again with all 200 annotated dialogues.
We obtaineda root mean squared error of 0.594 and R2 = 0.646.Mapping the continuous values to discrete scoreclasses from 1-5, we obtain MR/R = 45.5%(62.5% using SVM), ?
= 0.352 (0.575) and ?
=0.46 (0.795).
All values finally suggest that IQ isbetter modeled with non-linear classifiers such asSVMs or Multilayer Perceptrons (MLP).10 Conclusion and DiscussionIn this work we have developed a statistical modelthat predicts Interaction Quality, an objective mea-sure of user satisfaction, at arbitrary points in anSDS.
The model targets on predicting critical situ-ations on exchange level in ongoing dialogues.
Theclassifier, an SVM, reaches a performance of 61.6%MR/R (?
= 0.563, ?
= 0.786) by use of an opti-mized feature set that can be automatically derivedduring the interaction.
It could be further shownthat linear modeling with multivariate linear regres-sion is not appropriate for predicting IQ and reachesmerely 45.5.% MR/R.
Among all five feature groupscomprising altogether 52 features, the ASR and DMgroups contribute the most, while the EMOTIONAL-STATE underperforms.
We could further show thatfeatures requiring manual annotation, such as dia-logue acts, do not significantly improve the model?sperformance.
The model has been evaluated with200 dialogues from the CMU Let?s Go corpus com-prising 4885 system-user exchanges where three an-notators labeled the Interaction Quality on a scorefrom 1-5.
We could show that the median of all threeopinions depicts the most generic view on the IQ andis thus chosen as final score for the model.Some issues have to be addressed in future work:In the current study we assume that InteractionQuality is an objective metric for determining thesatisfaction of users during the interaction.
Howfar this assumption is justified has to be empiricallyproven in a laboratory study with real users.
A cor-responding study is in preparation and the resultswill be published in a follow-up work.
Althoughthe model?s performance can be considered as sat-isfying, the direct deployment in dialogue systemscannot be recommended at this stage.
For enablinga dialogue system to react on poor interaction qual-ity, a correct prediction of the low IQ scores 1,2 and3 is urgent, i.e.
the classifier has to be optimizedto deliver a very high precision on such low scoresrather than towards a high general MR/R value.
Weassume that the performance can be further drivenup by extending the feature space to the last n ex-changes, which would take into account a largerdialogue history for the decision (cf.
(Schmitt etal., 2010b)).
The presented model can principallybe trained on data from any dialogue system; how-ever, we did not yet deliver the proof that the presentmodel trained on Let?s Go data is general enoughfor cross-domain and cross-system application with-out significant performance loss.
Due to the generalcharacter of the ten most relevant features (cf.
Table3), portability can at least be assumed - without theneed for domain-dependent and system-dependentre-training.11 AcknowledgementsWe would like to thank Maxine Eskenazi, AlanBlack, Lori Levin, Rita Singh, Antoine Raux andBrian Langner from the Let?s Go Lab at CarnegieMellon University, Pittsburgh, for providing theLet?s Go Sample Corpus.
Further we would like tothank the reviewers for their constructive advices.The research leading to these results has re-ceived funding from the Transregional Collabora-tive Research Centre SFB/TRR 62 ?Companion-Technology for Cognitive Technical Systems?funded by the German Research Foundation (DFG).181ReferencesK.
P. Bennett and C. Campbell.
2000.
Support vectormachines: Hype or hallelujah?
Journal of SIGKDDExplorations, 2(2):1?13.W.
J. Doll and G. Torkzadeh.
1991.
The measure-ment of end-user computing satisfaction: theoreticaland methodological issues.
MIS Q., 15:5?10, March.K.-P. Engelbrecht, F. Go?dde, F. Hartard, H. Ketabdar, andS.
Mo?ller.
2009.
Modeling user satisfaction with hid-den markov model.
In Proc.
of SIGDIAL 2009 Con-ference, pages 170?177.
ACL.S.
Hara, N. Kitaoka, and K. Takeda.
2010.
Estimationmethod of user satisfaction using n-gram-based dialoghistory model for spoken dialog system.
In Proc.
ofthe Seventh conference on International Language Re-sources and Evaluation (LREC?10), Valletta, Malta.R.
Higashinaka, Y. Minami, K. Dohsaka, and T. Meguro.2010a.
Issues in predicting user satisfaction transi-tions in dialogues: Individual differences, evaluationcriteria, and prediction models.
In Spoken DialogueSystems for Ambient Environments, Lecture Notes inComputer Science, pages 48?60.
Springer Berlin /Heidelberg.R.
Higashinaka, Y. Minami, K. Dohsaka, and T. Meguro.2010b.
Modeling user satisfaction transitions in dia-logues from overall ratings.
In Proceedings of the SIG-DIAL 2010 Conference, pages 18?27, Tokyo, Japan,September.
ACL.ISO.
1998.
Ergonomic requirements for office work withvisual display terminals (VDTs), Part 11: Guidance onusability.
International Standardization Organization(ISO).B.
Ives, M. H. Olson, and J. J. Baroudi.
1983.
The mea-surement of user information satisfaction.
Commun.ACM, 26:785?793.D.
Larcker and V. P. Lessig.
1980.
Perceived usefulnessof information: A psychometric examination.
Deci-sion Sciences, pages 121?134, November.G.
Lindgaard and C. Dudek.
2003.
What is this evasivebeast we call user satisfaction?
Interacting with Com-puters, 15(3):429?452.J.
C. Platt, 1999.
Fast training of support vector ma-chines using sequential minimal optimization, pages185?208.
MIT Press, Cambridge, MA, USA.A.
Raux, D. Bohus, B. Langner, A. W. Black, and M. Es-kenazi.
2006.
Doing research on a deployed spokendialogue system: One year of lets go!
experience.
InProc.
of the International Conference on Speech andLanguage Processing (ICSLP).A.
Schmitt, C. Hank, and J. Liscombe.
2008.
Detectingproblematic calls with automated agents.
In 4th IEEETutorial and Research Workshop Perception and Inter-active Technologies for Speech-Based Systems, Irsee(Germany), June.Alexander Schmitt, Tobias Heinroth, and Jackson Lis-combe.
2009.
On nomatchs, noinputs and bargeins:Do non-acoustic features support anger detection?
InProceedings of the 10th Annual SIGDIAL Meeting onDiscourse and Dialogue, SigDial Conference 2009,London (UK), September.
Association for Computa-tional Linguistics.Alexander Schmitt, Tim Polzehl, and Wolfgang Minker.2010a.
Facing reality: Simulating deployment ofanger recognition in ivr systems.
In Second In-ternational Workshop on Spoken Dialogue Systems(IWSDS), September.Alexander Schmitt, Michael Scholz, Wolfgang Minker,Jackson Liscombe, and David Su?ndermann.
2010b.Is it possible to predict task completion in automatedtroubleshooters?
In Proc.
of the International Confer-ence on Speech and Language Processing (ICSLP).Marilyn Walker, Candace Kamm, and Diane Litman.2000.
Towards developing general models of usabil-ity with paradise.
Nat.
Lang.
Eng., 6(3-4):363?377.182Appendix1 Welcome to the CMU Let?s Go bus information system.2 To get help at any time, just say Help or press zero.3 What can I do for you?<DTMF-Zero>4 I am an automated spoken dialogue system that can give youschedule information for bus routes in Pittsburgh?s East End.You can ask me about the following buses: 28X, 54C, 56U,59U, 61A, 61B, 61C, 61D, 61F, 64A, 69A, and 501.5 What bus schedule information are you looking for?6 For example, you can say, when is the next 28X from DOWN-TOWN to THE AIRPORT?
or I?d like to go from MCK-EESPORT to HOMESTEAD tomorrow at 10 a.m..28X7 The 56C .
Is this correct?No, 28X8 What can I do for you?I want to know whether /uh/ tomorrow the bus is available ornot.9 Leaving at 11 p.m. .
Did I get that right?No, I just want to know is there any bus service for 28X tomor-row.10 Please use shorter answers because I have trouble understand-ing long sentences.11 Leaving at 11 p.m. .
Is this correct?On twenty third november.12 Leaving at 11 p.m. .
Is this correct?No, I want to know the schedule on twenty third november13 Leaving at 2 a.m. .
Did I get that right?<noise>14 If you want to leave at 2 a.m. say yes or press one, otherwisesay no or press three.no <noise>15 Going to NORTH AND CEDAR.
Did I get that right?28x going to airport at seven a.m.16 Please use shorter answers because I have trouble understand-ing long sentences.17 Going to NORTH AND CEDAR.
Is this correct?No.18 Leaving from DYNAMO.
Is this correct?No.19 Leaving from DYNAMO.
Is this correct?Leaving to airport.20 Leaving from AIRPORT .
Did I get that right?yes21 Right22 Where are you going?To airport.23 Going to AIRPORT.
Did I get that right?yeah, yep24 Okay25 When would you like to travel?yes26 When would you like to travel?Twenty third November.27 When would you like to travel?Tomorrow.28 At what time do you wanna travel?Seven a.m.29 Leaving at 7 a.m. .
Is this correct?yep30 Alright31 Just a minute.
I?ll look that up.32 AIRPORT and AIRPORT are both the same stop.
Please pro-vide a different start or end point.33 To ask about a different trip, you can say, start a new query.
Ifyou are finished, you can say goodbye.Yes.34 You can say start a new query, or goodbye.No.35 To ask about a different trip, you can say, start a new query.
Ifyou are finished, you can say goodbye.<noise>36 You can say start a new query, or goodbye.<noise>You can say start a new query, or goodbye.<hangup>Table 5: Example dialogue (ID: 2061122025) from the CMU Let?s Go System (2006 corpus) with low InteractionQuality.
The user utterances are printed in italic.516111621263136ualityExchangesmedianrater11234Interaction?Qrater2rater31 345tion?Qualitymedianmodel?hypothesis12InteracFigure 2: Upper chart: Turn-wise Interaction Quality (IQ) annotation from 3 raters.
The final label is the median ofall three opinions.
Lower chart: median reference vs. hypothesis of the model trained with AUTO feature set.1831 2 3 4 505001,0001,500 12941220792595983RatingFrequencyRater11 2 3 4 505001,0001,500 141710437975551072RatingFrequencyRater21 2 3 4 505001,0001,50016561416927442443RatingFrequencyRater3Figure 3: Rating distribution for Interaction Quality within the Let?s Go Corpus for each rater.Table 6: Rater guidelines for annotating Interaction Quality.Rule Description1.
The rater should try to mirror the users point of view on the interaction as objectively as possible.2.
An exchange consists of the system prompt and the user response.
Due to system design, the latter is not always present.3.
The IQ score is defined on a 5-point scale with ?1=bad?, ?2=poor?, ?3=fair?, ?4=good?
and ?5=excellent?.4.
The Interaction Quality is to be rated for each exchange in the dialogue.
The history of the dialogue should be kept inmind when assigning the score.
For example, a dialogue that has proceeded fairly poor for a long time, should requiresome time to recover.5.
A dialogue always starts with an Interaction Quality score of ?5?.6.
The first user input should also be rated with 5, since until this moment, no rateable interaction has taken place.7.
A request for help does not invariably cause a lower Interaction Quality, but can result in it.8.
In general, the score from one exchange to the following exchange is increased or decreased by one point at the most.9.
Exceptions, where the score can be decreased by two points are e.g.
hot anger or sudden frustration.
The rater?sperception is decisive here.10.
Also, if the dialogue obviously collapses due to system or user behavior, the score can be set to ?1?
immediately.
Anexample herefore is a reasonable frustrated sudden hang-up.11.
Anger does not need to influence the score, but can.
The rater should try to figure out whether anger was caused by thedialogue behavior or not.12.
In the case a user realizes that he should adapt his dialogue strategy to obtain the desired result or information andsucceeded that way, the Interaction Quality score can be raised up to two points per turn.
In other words, the userrealizes that he caused the poor Interaction Quality by himself.13.
If the system does not reply with a bus schedule to a specific user query and prompts that the request is out of scope,this can nevertheless be considered as ?task completed?.
Therefore this does not need to affect the Interaction Quality.14.
If a dialogue consists of several independent queries, each query?s quality is to be rated independently.
The formerdialogue history should not be considered when a new query begins.
However, the score provided for the first exchangeshould be equal to the last label of the previous query.15.
If a dialogue proceeds fairly poor for a long time, the rater should consider to increase the score more slowly if thedialogue starts to recover.
Also, in general, he should observe the remaining dialogue more critical.16.
If a constantly low-quality dialogue finishes with a reasonable result, the Interaction Quality can be increased.184
