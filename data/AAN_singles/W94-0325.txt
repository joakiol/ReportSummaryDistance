!Situation Viewpoints for Generat ionHenry Hamburger s and Dan Tufts 2ABSTRACT: Representation systems are presented for the input and output of the first or deep phase of a languagegeneration system.
Actions and viewpoints are the key factors in determining what sentence isproduced; viewpoints providea wide range of ways tO discuss actions, their states and the plans they compose.
The language generator plays a key role in atwo-medium conversational system for a naturalistic foreign language l arning environment.KEYWORDS: viewpoint, action-based natural language generation, two-medium, conversationOverviewAfter an inlroduction to the nature and role of viewpoints,we motivate this work in terms of our two-mediumsystem for conversational l nguage l arning.
Since ourversion of generation is action-based, we then sketchactions.
Finally, we ,return to a finer-grained look atviewpoints.1 ViewpointsIn the natural use of natural language, a single event canbe talked about in a variety of ways, taking a variety ofviewpoints.
Such variety is necessary across languagesbecause of differences in how cultures prefer to expressthings (Delin et al, 1993) and because of differences inhow languages make it possible to express things(Felshin, 1993).
A sel~tion of viewpoints is also neededwithin languages, both for coherence (Meteer,forthcoming) and for effective rhetoric (Hovy, 1988).For us, varied viewpoints are a way to expose learners of aforeign language to a v~u'iety of linguistic onstructions inthe naturalistic, situation-based, two-medium (graphical swell as linguistic) conversations that take place in ourforeign language learning environment called Fluent-2.To achieve this objective, we have been developing andimplementing our notion of an abstract situationviewpoint, hereafter called simply a view.1.
You picked up the pot.\[description f an action\]2.
The pot is in your hand.\[description f a state\]3.
Now fill the pot.\[command tocontinue plan\]4.
The water is not on.\[unmet precondition\]5.
What is (still) on the counter?\[question  related object\]6.
I asked you to pick up the cup,not the pot.
\[unheeded command\]These examples show differences not only in views butalso in the type of conversational interaction: #5 is aquestion, while #3 and #6 show different aspects of acommand-act interaction.
Views differ in what actionsthey refer to, with #1 as the most straightforward case,describing asingle action that just occurred.
In contrast,#6 refers to two actions, one of which was created earlierin formulating a command that was never performed.Among state views, the most straightforward is tocomment on the new value of an object's attribute, as in#2, but it is usually also quite possible to comment onthe cessation of the corresponding previous value.
Yetanother state View is applicable if the new value is thesame as the corresponding one for another object; one canthen say, for example, that here are two cups on the tableor that both cabinet doors are open.A view specifies a way to operate on an action or apossible action in a Situation to produce a language-independent conceptual structure that corresponds to astatement, command or question about an action or itsresults, purpose, participants, etc.
This paper sketches aninternal structure for views and indicates their range ofexpression.
The choice of which view to use at aparticular point can be made by the tutorial strategist,taking into account the Student's limited knowledge of thelanguage (Hamburger, in press).
View processing is thedeepest of three levels forming the NLG capability of thelearning environment.
The general idea of views can beseen from a few examples in three categories: action, stateand plan views.1.
Computer Science, George Mason Univ., Fairfax, VA2.
Institute for Informatics, Bucharest, RumaniaUnderlying sentence #3, above, is a plan view, in thiscase the notion of transition to the next action in thecurrent plan.
Plans can also refer to such things as thecompletion of a plan or subplan and the transition fromone subplan to the next.
Plans exist in the microworldsso that the successive actions will make sense, not onlythose chosen by the tutor to carry out itself, but alsothose the tutor tells the student o do, as in #3.
Theresulting situational continuity supports a languagebeginner by keeping it clear what is being talked about.For a more advanced student, plan views provide their ownform of variety, including two-clause sentences like,"Now that the pot is full, put it on the stove," in whichthe first clause involves a state view, the second an actionview and the whole sentence comes from a plan view, thetransition from a just completed subplan to the nextaction whose goal is not already satisfied.2177th International Generation Workshop ?
Kennebunkport, Maine ?
June 21-24, 1994\]Tutorselected Ise c ed  View'I, A ProcessorSituationReasoner eflnstantiatedAction & Microworld Plan StateSem uc  enemfionView I S~ucture ISentenceFigure 1.
View Processing in context.
Organization of modules relevant to language generation.2 Two-Medium Language LearningFluent-2 is a two-medium tutorial system whose principalgoal is to provide an essential form of foreign languagelearning experience: realistic onversation i the targetlanguage.
Figure 1 shows key parts of the system.Language interaction i Fluent-2 is tightly integrated witha visual second medium consisting of partially animatedgraphics under shared control of the student and theelectronic tutor.
Both the graphics and the language arethe outward manifestations of an underlying microworld ofobjects, in a hierarchy of classes, taking part in actionsthat are structured into plans.
The graphics and animationprovide a realistic auxiliary source of information aboutwhat is being said.
This independent channel helps thestudent pick up new vocabulary and languageconstructions in a clear situational context.
This two-medium interaction capability, including the deepgeneration component sketched in this paper, should alsobe applicable to tutoring systems in other subject matter.Surface generation is done by a large natural languageprocessing system, developed by Susan Felshin of theMIT Athena Language Learning Project (ALLP) andadapted for us.
It is this system that takes semanticstructures to syntactic structures and ultimately tosentences of English, Spanish and, to a lesser extent,other languages.
The natural language processing,graphics, microworlds and tutorial reasoning are all inMCL2 Common Lisp with CLOS on a Mac-Ilfx with20MB of main memory.The availability of the two media, along with situationalcontinuity, can provide to adults the kind of redundancythat seems essential to children in their race to fluent useof their native tongue.
This is not to say that adults learnin the same way as children.
Nevertheless, Fluent-2, hasbeen designed with careful attention to successful secondlanguage pedagogy and appropriate second languageresearch.
Language generation is especially important atthe outset, since the learner must comprehend languagebefore meaningfully producing it.Second language research provides support for usingsimplified language in meaningful contexts.
Threesources of such experience are foreigner talk (by nativespeakers, to foreigners), motherese (by parents andcaregivers, to children) and teacher talk (by teachers, tostudents).
We seek to replicate the benefits of these stylesin a computational system, by identifying and adaptingspecific aspects that underlie their success.
Suchproperties include: restricted vocabulary size; exaggeratedintonation and stress; short grammatical sentences; use ofconcrete references; repetitions, expansions and rephrases;few pro-forms; few contractions; yes-no, choice and tagquestions rather than Wh-questions; and so on.
(SeeHamburger, 1993 for a fuller account).3 Representing Situations and ActionsThe actions in a microworld are of special interest becausethey constitute an input to view processing, our centralconcern here.
Both actions and plans are implemented asparametrized rules with constrained variables, as in theaction rule example in Figure 2.
Binding the parametersof an action (or plan) to microworld objects yields aninstantiated action (or plan), which can then be carried out,with graphical and internal consequences, and/or forwardedto the generation process.
Objects are of various types orclasses, with individual properties, ome inherited, andrelationships to each other.
Actions and objects, thebridge between the two media, are chosen partly on thebasis of having consequences that are clearly realizable ingraphics.
Actions are organized into flexible, hierarchicalplans that support coherent everyday activityHEADER: (pick-up ($h hand) ($obj physical-object)($from physical-object)(Stow microworld))GOALS: ((oav $h grasp $obj))PRECONDS: ((oav Sh grasp nothing)... )K-RESULTS: ((modify-oav Sh grasp $obj)(delete-among Sfrom things-on-top $obj)... )Figure 2.
Non-graphics parts of action rule, Pick-Up2187th International Generation Workshop ?
Kennebunkport, Maine ?
June 21-24, 1994Action rules are bi-directional: either the student or thetutor can activate them, depending on the type ofinteraction.
The student does this in a graphically realisticmanner, for example by dragging ahand to the faucet andclicking the mouse.
The.parameters have scope over thewhole rule; binding originates in any slot.
Informationthus can flow among student, tutor and microworld,supporting the two-way, two-medium conversation.An action rule's Header slot is a key to view processing.It contains the rule name or predicate as well as argument-constraint pairs, and is used in the straightforward view inFigure 3 for a simplel description of the action.
Alsouseful in view processing is the K-Results slot,containing object-attribute-value triples for updating theinternal situation as a :result of the action.
State viewscan select among these results to report various changes.The Goal slot makes it possible, when executing a plan,to skip over any actions and subplans whose goals arealready achieved.
Besides permitting variety in studentaction sequences, the satisfied goal can form, via a view,the basis of a useful remark.
Views for failed Precondscan also yield comments worth making.
Two other actionrule slots are for information passed to and from thegraphics module; they are not used for views and areomitted from Figure 3..To see the key role of views, suppose that the student hasjust made something happen and the system's role is nowto make a relevant comment.
A simple choice is to saywhat the student just did, using a representation f thestudent's preceding microworld action, consisting of anoperator with its operands.
Just such a representation isin the Header slot of the action rule just triggered by thestudent (via the graphics input slot).
It can be transformedto a semantic structure that is an appropriate input for thesurface generation module, which can output he resultingsentence.
We do exactly that, but not deterministically.Into this action-to-semantics connection, we use views toinsert he possibility of a wide-ranging choice of differentapproaches toconstructing something tosay.4 Views, Levels and InstantiationsA view is an abstraction of what to say and how to say it,expressed as a structure.
It guides the view processor inselecting parts of an instantiated action, to instantiate heview.
The instantiatedi view is a language-independentintermediate r presentation which ultimately ields anoutput sentence.The partial example of a view in Figure 3 shows thecontext level, event level and object level.
(Object-levelinformation is not shown.)
The event level is central inthat it corresponds roughly to the proposition expressed inthe main (or only) clause of a sentence.
The view typehere is 'action', yielding a view that expresses the actionitself, without reference:to he plan or the resulting state.
'What-action' can be one that has actually occurred, hasbeen talked about or has been constructed for generation.In Figure 3, this choice depends on the interaction type,which also controls the distinction between commands anddeclarative s ntences and the choice of tense.NAME: current-actionCONTEXT: (case interaction-type((movecaster tourguide) '(recent-pas0)(antetourguide '(near-future))(commander '(imperative)) )EVENT: view-type: actionwhat-action: (case interaction-type(movecaster 'student-did)(tourguide 'tutor-did)((antetourguide commander)'tutor-thought))OBJECT: ...Figure 3.
Part of the view, Current-Action.These observations point to the key role of interactiontypes within views.
Interaction types complement viewsby organizing the basic conversational move structure.An interaction is a short sequence of specified kinds oflinguistic and spatial turns by the tutor and student.Choosing an interaction type determines whether it is thetutor or the student that momentarily takes the initiative.A pedagogically useful interaction type for languagelearning has at least one linguistic move (is not purelygraphical).
Either the tutor or the student can start withone of four move types: action, command, question orstatement.
Following each with its anticipated responseyields the eight simplest interaction types.In the Movecaster type, the student can make any possiblemove, and the tutor then comments; the tutor asks aquestion in Quizmaster; it gives a command that thestudent may act on in Commander; and these roles arereversed in Servant.
Tourguide is an interaction type withthree moves: an action by the tutor, a description of thataction, and acknowledgement by he student.
Tourguidecan provide initial exposure to a new microworld.Variations of it allow the'description to precede or followthe action, or both, giving a basis for variations in tense.The second move in an interaction should be responsive tothe first.
Thus some kinds of questions call for a sentencein answer, others a phrase or "yes" or "no".
Similarly,actions are expected to be responsive to commands.
Thetutor may comment about responsiveness to a commandor lack of it, using a view-constrained interaction type.It is now easier to see why, in Figure 3, Movecaster isassociated with Student-Did, the student's action, whereasCommander calls for an action - Tutor-Thought - not yetcarried out by anyone.
What-Action takes four possiblevalues: Student-Did or Tutor-Did for the most recentaction executed by the student or tutor; and Tutor-Did or2197th International Generation Workshop * Kennebunkport, Maine ?
June 21-24, 1994Tutor-Thought for an action constructed by the tutor asthe basis of something already said or about o be said.State views need two slots at the event-level that are notin event views; see Figure 4.
Since an action may resultin more than one change inthe values of object attributes,state views have an Aspect o specify how to select one ofthe changes.
The selection method in Figure 4 simplytakes the first one in the list of updates - reasonable ifresults are in order of importance.
The Pre-Post slot tellswhether to use the updated value or the prior one.VIEW-TYPE: stateWHAT-ACTION: last-actionASPECT: (position 1)PRE-POST: preFigure 4.
State view, event level: "The cup was inyour hand"Whereas a view tells where to get information, theinstantiated view (IV) holds the information itself, whichthe view processor has for the most part extracted from theinstantiated action.
For an action view, this is pnncipallythe arguments, taken from the action header and placed inIV slots called Agent, Objectl, Object2 and Modifier.Under the guidance of the object level of the view, theview processor associates each argument with the correctslot and puts in the contents.
Designed for this purpose isthe IV-O, or object level of an IV.
Each IV slot can befilled by (i) an IV-O, (ii) a microworld object, (iii) a class,which is a language-independent meaning corresponding toa common oun, (iv) a list of items of the three foregoingkinds, or (v) another IV.
The latter yields a subordinateclause, whereas each of the others underlies a noun phrase.Object-level views determine how to express a particularmicroworld object to convey its relationship to otheraspects of a conversation.
With a black and a grey cup,for example, after moving the black one, the grey one canbe referred to as "the other one," "the grey cup," "thesecond cup" or even "the cup that is still on the table."
Ineach noun phrase the head noun corresponds by default othe class of the object, unless "one" is included in thespecification for that object (giving, in English, the likesof "the red one").
The decision whether to includemodifiers (adjectives, relative clauses, and prepositionalphrases) may in some cases be expressed by code thatincludes a method that selects whatever properties areneeded to distinguish an entity from others of its class.The object level may also have information that affectsdecisions about determiners and possibly quantifiers orpronouns.
The choice of determiner can not be specifiedin isolation by the view, since it must take into accountthe recent mentions of, and actions on, an entity, forexample, "Pick up a (indefinite) box" and then, "Good!You picked it (definite pronoun) up.
"Subslot Possible ValuesPRECISIONREFERENCEPROMINENCETop,Parent, Direct, DistinctOther, Pronoun, NilTopic, Wh, NilFigure 5.
Possible values at Object levelObject-level subslots and their permitted values appear inFigure 5.
First comes the degree of Precision with whichthe object is to be described.
It can indicate whether theclass for describing the object should be its direct class(e.g., girl, teaspoon), its parent class (e.g., child, spoon)or the highest class permitted by the type constraint forthe particular argument of the action rule (e.g., person,thing).
Another option is the highest level distinguishingthe item from everything else in the current situation.
Ifthe item is not alone in the class named, the output needsa modifier or else an indefinite determiner.I f  the Reference subslot in a view has the value Other, theitem is to be described in terms of other items in its class,e.g., "'the other X" or "the rest of the Xs", as opposed tothe default case, a description of an object by its ownproperties.
The Prominence subslot specifies whether itsobject should be made prominent or not, and if so,whether by topicalization - Topic - or by being questionedwith a Wh word.Acknowledgement.
This work is supported undergrant IRI-9020711 from the National Science Foundation.ReferencesDelin, J., Scott, D. and Hartley, T. (1993) Knowledge,intention, rhetoric.
In O. Rambow (Ed.)
Intentionalityand Structure in Discourse Relations.
Morristown, NJ:Association for Computational Linguistics.Felshin, S. (1993) The Lingo Manual.
Carnbndge, MA:Lab.
for Advanced Technology in the Humanities, MIT.Hamburger, H. (in press) Tutorial tools for languagelearning by two-medium dialog.
In M. Holland, J.Kaplan and M. Sams (Eds.)
Hillsdale, NJ: LawrenceErlbaum Associates.Hamburger, H. (1993) SCIALogie and Fluent: Pedagogyand microworlds for language immersion and tutoring.
InT.
Chanier, D. Renie and C. Fouquere (Eds.)
Actes duColloque SCIAL.
Clermont-Ferrand, France.Hovy, E. (1988) Generating Natural Language underPragmatic Constraints.
Hillsdale, NJ: Lawrence ErlbaumAssociates.Meteer, M. (forthcoming) Text planning and textstructuring.
Computational Linguistics.220
