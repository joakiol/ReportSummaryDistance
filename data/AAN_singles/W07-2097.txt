Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 434?437,Prague, June 2007. c?2007 Association for Computational LinguisticsUPV-WSD : Combining different WSD Methodsby means of Fuzzy Borda VotingDavide Buscaldi and Paolo RossoDSIC, Dpto.
Sistemas Informa?ticos y Computacio?nUniversidad Polite?cnica de ValenciaValencia, Spain{dbuscaldi,prosso}@dsic.upv.esAbstractThis paper describes the WSD system devel-oped for our participation to the SemEval-1.It combines various methods by means of afuzzy Borda voting.
The fuzzy Borda vote-counting scheme is one of the best knownmethods in the field of collective decisionmaking.
In our system the different disam-biguation methods are considered as expertsthat give a preference ranking for the sensesa word can be assigned.
Then the prefer-ences are evaluated using the fuzzy Bordascheme in order to select the best sense.
Themethods we considered are the sense fre-quency probability calculated over SemCor,the Conceptual Density calculated over bothhyperonyms and meronyms hyerarchies inWordNet, the extended Lesk by Banerjeeand Pedersen, and finally a method based onWordNet domains.1 IntroductionOne of the lessons learned from our previous experi-ence at Senseval-31 (Buscaldi et al, 2004; Vazquezet al, 2004) is that the integration of different sys-tems usually works better than a standalone system.In our opinion this reflects the reality where humansdo not apply always the same rule in order to disam-biguate the same ambigue word; for instance, if weconsider the sentences ?He hit a home run?
and ?Thethermometer hit 100 degrees?, in the first case thesport domain helps in determining the right sense for1http://www.senseval.orghit, whereas in the latter the disambiguation is car-ried out mostly depending on the fact that the subjectof the sentence is an object.The combination of distinct methods representsitself a major problem.
If the methods return dif-ferent answers, how can we select the best one?
Inthis sense the available choices are the following:?
Rule-based selection: a set of rules that can beboth hand-made or automatically learned fromexamples;?
Probability-based: the output of the methods isnormalized in the range [0, 1] and is consideredas a probability.
Then the values are multipliedin order to obtain the sense with a maximumprobability.?
Vote-based: the output of the methods is con-sidered as a weighted vote.
Then a votingscheme is used in order to obtain the most votedsense.In our previous participation with the R2D2 project(Vazquez et al, 2004) the selection was rule-based,with hand-made rules that attempted to take into ac-count the reliability of the various method.
We sub-sequently attempted to learn automatically the rules,but the results of these experiments did not allow todetermine clearly which method was to be used ineach context.Working with probabilities can be problematicdue to the null probabilities that make necessary theadoption of smoothing techniques.
Therefore, weopted for a voting scheme, in this case the fuzzyBorda (Nurmi, 2001; Garc?
?a Lapresta and Mart?
?nez434Panero, 2002), one of the best known methods inthe field of collective decision making.
With thisscheme the disambiguation methods are consideredas experts providing a preference ranking over thesense of the word.The methods we choose as experts are the senseprobability calculated over SemCor, the ConceptualDensity algorithm by (Rosso et al, 2003), the ex-tended Lesk by (Banerjee and Pedersen, 2002), andan algorithm that takes into account the domains ofthe word to be disambiguated and the context words.In the following sections we describe in detail thefuzzy Borda scheme and each WSD expert.2 The Fuzzy Borda voting schemeThe original Borda vote-counting scheme was in-troduced in 1770 by Jean Charles de Borda, andadopted by the French Academy of Sciences withthe purpose of selecting its members.
In the classicalBorda count each expert gives a mark to each alter-native, according to the number of alternatives worsethan it.
The fuzzy variant (Nurmi, 2001; Garc?
?aLapresta and Mart?
?nez Panero, 2002) is a natural ex-tension that allows the experts to show numericallyhow much some alternatives are preferred to the oth-ers, evaluating their preference intensities from 0 to1.Let R1, R2, .
.
.
, Rm be the fuzzy prefer-ence relations of m experts over n alternativesx1, x2, .
.
.
, xn.
For each expert k we obtain amatrix of preference intensities:????
?rk11 rk12 .
.
.
rk1nrk21 rk22 .
.
.
rk2n.
.
.
.
.
.
.
.
.
.
.
.rkn1 rkn2 .
.
.
rknn????
?where each rkij = ?Rk(xi, xj), with ?Rk : X?X ?
[0, 1] being the membership function of Rk.
Thenumber rkij ?
[0, 1] is considered as the degree ofconfidence with which the expert k prefers xi to xj .The final value assigned by the expert k to each al-ternative xi is:rk(xi) =n?j=1,rkij>0.5rkij (1)which coincides with the sum of the entries greaterthan 0.5 in the i-th row in the preference matrix.
Thethreshold 0.5 ensure the relation Rkto be an ordinarypreference relation (Garc?
?a Lapresta and Mart?
?nezPanero, 2002).Therefore, the definitive fuzzy Borda count for analternative xi is obtained as the sum of the valuesassigned by each expert:r(xi) =m?k=1rk(xi) (2)In order to fill the preference matrix with thecorrect confidence values, the output weightsw1, w2, .
.
.
, wn of each expert k are transformed tofuzzy confidence values by means of the followingtransformation:rkij =wiwi + wj(3)An example of how fuzzy Borda is used to combinethe votes in order to obtain the right sense of thetarget word is shown in Section 4.3 WSD ExpertsWe considered five experts in order to carry outthe disambiguation process.
Sense probability andthe extended lesk were available for every word,while the Conceptual Density was calculated onlyfor nouns.
Therefore, all the experts were availableonly for the nouns.
For each expert different con-texts were taken into account, depending on the spe-cific characteristics of each expert.3.1 Sense ProbabilityThis expert is the simplest one: its votes are calcu-lated using only the frequency count in SemCor ofthe WordNet senses of the word.
The transformationof the frequency counts to the preference ranking isdone according to Formula (3).
Zero frequency arenormalized to 1.3.2 Conceptual DensityConceptual Density (CD) was originally introducedby (Agirre and Rigau, 1996).
It is computed onWordNet subhierarchies, determined by the hyper-nymy (or is-a) relationship.
Our formulation (Rossoet al, 2003) of the Conceptual Density of a WordNetsubhierarchy s is:CD(m, f, n) = m?
(mn)(4)435Where m are the relevant synsets in the subhierar-chy, n is the total number of synsets in the subhierar-chy.The relevant synsets are both the synsets of theword to be disambiguated and those of the contextwords.The WSD system based on this formula par-ticipated at the Senseval-3 competition as theCIAOSENSO system (Buscaldi et al, 2004), ob-taining 75.3% in precision over nouns in the all-words task (baseline: 70.1%).
These results wereobtained with a context window of two nouns, theone preceding and the one following the word.
InSenseval-3 the WSD system took also into accountthe frequency of senses depending on their rank.
InSemEval-1 we do not, because of the presence of theSense Probability expert.The CD-based expert uses a context of two nounsfor the disambiguation process too.
The weightsfrom Formula (4) are used for computing the fuzzyconfidence values that are used to fill the preferencematrix after they are transformed according to For-mula (3).A second CD-based expert exploits the holonymy,or part-of relationship instead of hyperonymy.
Thisexpert uses as context all the nouns in the sentenceof the word to be disambiguated.3.3 Extended LeskThis expert is based on the algorithm by (Banerjeeand Pedersen, 2002), a WordNet-enhanced versionof the well-known dictionary-based algorithm pro-posed by (Lesk, 1986).
The original Lesk was basedon the comparison of the gloss of the word to be dis-ambiguated with the context words and their glosses.This enhancement consists in taking into accountalso the glosses of concepts related to the word tobe disambiguated by means of various WordNet re-lationships.
Then similarity between a sense of theword and the context is calculated by means of over-laps.
The word is assigned the sense obtaining thebest overlap match with the glosses of the contextwords and their related synsets.The weights used as input for Formula (3) are thesimilarity values between the senses of the worldand the context words.
The context for this ex-pert consists of 4 WordNet words (disregarding theirPart-Of-Speech) located in the same sentence of theword to be disambiguated, i.e., words with POSnoun, verb, adjective or adverb that can be found inWordNet.3.4 WordNet DomainsThis expert uses WordNet Domains (Magnini andCavaglia`, 2000) in order to provide the system withdomain-awareness.
All WordNet words in the samesentence of the target word are used as context.
Theweight for each sense is obtained by counting thenumber of times the same domain of the sense ap-pears in the context (all senses of context words areconsidered).
We decided to not take into account the?factotum?
domain.4 ExampleIn this example we will consider only the senseprobability and extended Lesk experts for simplic-ity.Let us consider the following phrase: ?And he haskept mum on how his decision might affect a bidfor United Airlines , which includes a big stake byBritish Airways PLC.?
with affect as target word.We can observe that in WordNet the verb affect has5 senses.
The sense count values are 43 for the firstsense, 11 for the second, 4 for both the third and thefourth one, and 0 for the last one.
We decided to nor-malize the cases with 0 occurrences to 1.
After ap-plying the transformation (3) to the sense counts, weobtain the following preference matrix for the senseprobability expert:??????
?0.5 0.80 0.91 0.91 0.980.20 0.5 0.73 0.73 0.920.09 0.27 0.5 0.5 0.80.09 0.27 0.5 0.5 0.80.02 0.08 0.2 0.2 0.5??????
?Therefore, the final fuzzy Borda counts by thesense probability expert are 3.60 for affect(1),2.38 for affect(2), 0.8 for affect(3) andaffect(4), and 0 for affect(5), obtainedfrom the sum of the rows where the value is greaterthan 0.5.The extended Lesk expert calculates the followingsimilarity scores for thesenses of affect, with contextwords decision, might, bid and include: respectively107, 70, 35, 63 and 71 for senses 1 to 5.
After apply-ing the transformation (3) to the weights, we obtain436the preference matrix for this expert:??????
?0.5 0.60 0.75 0.63 0.600.40 0.5 0.67 0.53 0.490.25 0.33 0.5 0.36 0.330.37 0.47 0.64 0.5 0.470.40 0.51 0.67 0.53 0.5??????
?In this case the final fuzzy Borda counts are 2.58 forthe first sense, 1.2 for sense 2, 0 for sense 3, 0.64and 1.71 for senses 4 and 5 respectively.Finally, the sum of Borda counts of every expertfor each sense (see Table 4) are used to disambiguatethe word.sense no: 1 2 3 4 5expert 1 3.60 2.38 0.80 0.80 0expert 2 2.58 1.20 0 0.64 1.71total: 6.18 3.58 0.80 1.44 1.71Table 1: Borda Count for the verb affect in the ex-ample phrase.5 ResultsThe system was not tested before SemEval.
Our par-ticipation was limited to the All-Word and Coarse-Grained tasks (without the sense inventory providedby the organizers).
The results are compared to thebest system and the MFS (Most Frequent Sense)baseline.
We calculated also the partial results overnouns in the all word task, obtaining that the MFSbaseline in this case is about 0.633, whereas our sys-tem obtains 0.520.task upv-wsd MFS best systemcoarse-grained 0.786 0.789 0.832awt 0.420 0.471 0.537Table 2: Recall obtained by our system (upv-wsd)in each task we participated in, compared with themost frequent sense baseline and the best system inthe task.6 ConclusionsThe combination of different systems allowed us toattain higher recall than with our previous systemused in Senseval-3.
However, overall results werenot as good as expected.
Partial results over thenouns show that the CD expert did not perform asin the Senseval-3 and that the CD formula needs toinclude sense frequency ranking in order to achievea good performance.
As a further work we plan toadd a weight reflecting the reliability of each expert.AcknowledgementsWe would like to thank the TIN2006-15265-C06-04 researchproject for partially supporting this work.
We would also like tothank Prof. Eugene Levner of the Holon Institute of Technologyfor inspiring us to use the fuzzy Borda voting scheme.ReferencesEneko Agirre and German Rigau.
1996.
Word sense dis-ambiguation using conceptual density.
In COLING,pages 16?22.Satanjeev Banerjee and Ted Pedersen.
2002.
An adaptedlesk algorithm for word sense disambiguation usingwordnet.
In Proceedings of CICLing 2002, pages 136?145, London, UK.
Springer-Verlag.Davide Buscaldi, Paolo Rosso, and Francesco Masulli.2004.
The upv-unige-CIAOSENSO WSD System.In Proc.
of Senseval-3 Workshop, Barcelona (Spain),July.
ACL.Jose?
Luis Garc?
?a Lapresta and Miguel Mart?
?nez Panero.2002.
Borda Count Versus Approval Voting: A FuzzyApproach.
Public Choice, 112(1-2):167?184.Michael Lesk.
1986.
Automatic sense disambiguationusing machine readable dictionaries: how to tell a pinecone from an ice cream cone.
In Proc.
of SIGDOC?86, pages 24?26.Bernardo Magnini and Gabriela Cavaglia`.
2000.
Inte-grating Subject Field Codes into WordNet.
In Proc.
ofthe 2nd LREC Conference, pages 1413?1418, Athens,Greece.Hannu Nurmi.
2001.
Resolving Group Choice Para-doxes Using Probabilistic and Fuzzy Concepts.
GroupDecision and Negotiation, 10(2):177?199.Paolo Rosso, Francesco Masulli, Davide Buscaldi, Fer-ran Pla, and Antonio Molina.
2003.
Automatic nounsense disambiguation.
In Proc.
of CICLing 2003,pages 273?276.Sonia Vazquez, Rafael Romero, Armando Suarez, An-dres Montoyo, Manuel Garc?
?a, M. Teresa Martin,M.
Angel Garc?
?a, Alfonso Uren?a, Davide Buscaldi,Paolo Rosso, Antonio Molina, Ferran Pla, and EncarnaSegarra.
2004.
The R2D2 Team at SENSEVAL-3.
InProc.
of Senseval-3 Workshop.437
