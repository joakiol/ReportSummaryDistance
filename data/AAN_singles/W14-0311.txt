Workshop on Humans and Computer-assisted Translation, pages 72?77,Gothenburg, Sweden, 26 April 2014.c?2014 Association for Computational LinguisticsReal Time Adaptive Machine Translation for Post-Editing withcdec and TransCenterMichael Denkowski Alon Lavie Isabel Lacruz?Chris DyerLanguage Technologies Institute, Carnegie Mellon University, Pittsburgh, PA 15213 USA?Institute for Applied Linguistics, Kent State University, Kent, OH 44242 USA{mdenkows,alavie,cdyer}@cs.cmu.edu ilacruz@kent.eduAbstractUsing machine translation output as astarting point for human translation hasrecently gained traction in the transla-tion community.
This paper describescdec Realtime, a framework for build-ing adaptive MT systems that learn frompost-editor feedback, and TransCenter, aweb-based translation interface that con-nects users to Realtime systems and logspost-editing activity.
This combinationallows the straightforward deployment ofMT systems specifically for post-editingand analysis of human translator produc-tivity when working with these systems.All tools, as well as actual post-editingdata collected as part of a validation exper-iment, are freely available under an opensource license.1 IntroductionThis paper describes the end-to-end machinetranslation post-editing setup provided by cdecRealtime and TransCenter.
As the quality of MTsystems continues to improve, the idea of usingautomatic translation as a primary technology inassisting human translators has become increas-ingly attractive.
Recent work has explored thepossibilities of integrating MT into human transla-tion workflows by providing MT-generated trans-lations as a starting point for translators to cor-rect, as opposed to translating source sentencesfrom scratch.
The motivation for this process isto dramatically reduce human translation effortwhile improving translator productivity and con-sistency.
This computer-aided approach is directlyapplicable to the wealth of scenarios that still re-quire precise human-quality translation that MTis currently unable to deliver, including an ever-increasing number of government, commercial,and community-driven projects.The software described in the following sec-tions enables users to translate documents withthe assistance of an adaptive MT system usinga web-based interface.
The system learns fromuser feedback, improving translation quality asusers work.
All user interaction is logged, al-lowing post-editing sessions to be replayed andanalyzed.
All software is freely available underan open source license, allowing anyone to eas-ily build, deploy, and evaluate MT systems specif-ically for post-editing.
We first describe the under-lying adaptive MT paradigm (?2) and the Realtimeimplementation (?3).
We then describe Trans-Center (?4) and the results of an end-to-end post-editing experiment with human translators (?5).All data collected as part of this validation experi-ment is also publicly available.2 Adaptive Machine TranslationTraditional machine translation systems operate inbatch mode: statistical translation models are es-timated from large volumes of sentence-parallelbilingual text and then used to translate new text.Incorporating new data requires a full system re-build, an expensive operation taking up to days oftime.
As such, MT systems in production scenar-ios typically remain static for large periods of time(months or even indefinitely).
Recently, an adap-tive MT paradigm has been introduced specifi-cally for post-editing (Denkowski et al., 2014).Three major MT system components are extendedto support online updates, allowing human post-editor feedback to be immediately incorporated:?
An online translation model is updated to in-clude new translations extracted from post-editing data.?
A dynamic language model is updated to in-clude post-edited target language text.?
An online update is made to the system?sfeature weights after each sentence is post-edited.72These extensions allow the MT system to gener-ate improved translations that require significantlyless effort to correct for later sentences in the doc-ument.
This paradigm is now implemented inthe freely available cdec (Dyer et al., 2010) ma-chine translation toolkit as Realtime, part of thepycdec (Chahuneau et al., 2012) Python API.Standard MT systems use aggregate statisticsfrom all training text to learn a single largetranslation grammar (in the case of cdec?s hi-erarchical phrase-based model (Chiang, 2007), asynchronous context-free grammar) consisting ofrules annotated with feature scores.
As an alter-native, the bitext can be indexed using a suffix ar-ray (Lopez, 2008), a data structure allowing fastsource-side lookups.
When a new sentence is to betranslated, training sentences that share spans oftext with the input sentence are sampled from thesuffix array.
Statistics from the sample are used tolearn a small, sentence-specific grammar on-the-fly.
The adaptive paradigm extends this approachto support online updates by also indexing thenew bilingual sentences generated as a post-editorworks.
When a new sentence is translated, match-ing sentences are sampled from the post-editingdata as well as the suffix array.
All feature scoresthat can be computed on a suffix array sample canbe identically computed on the combined sample,allowing uniform handling of all data.
An addi-tional ?post-edit support?
feature is included thatindicates whether a grammar rule was extractedfrom the post-editing data.
This allows an opti-mizer to learn to prefer translations that originatefrom human feedback.
This adaptation approachalso serves as a platform for exploring expandedpost-editing-aware feature sets; any feature thatcan be computed from standard text can be addedto the model and will automatically include post-editing data.
Implementationally, feature scoringis broken out into a single Python source file con-taining a single function for each feature score.New feature functions can be added easily.The adaptive paradigm uses two language mod-els.
A standard (static) n-gram language model es-timated on large monolingual text allows the sys-tem to prefer translations more similar to human-generated text in the target language.
A (dy-namic) Bayesian n-gram language model (Teh,2006) can be updated with observations of thepost-edited output in a straightforward way.
Thissmaller model exactly covers the training bitextand all post-editing data, letting the system up-weight translations with newly learned vocabu-lary and phrasing absent in the large monolingualtext.
Finally, the margin-infused relaxed algorithm(MIRA) (Crammer et al., 2006; Eidelman, 2012)is used to make an online parameter update aftereach sentence is post-edited, minimizing model er-ror.
This allows the system to continuously rescaleweights for translation and language model fea-tures that adapt over time.Since true post-editing data is infeasible to col-lect during system development and internal test-ing, as standard MT pipelines require tens of thou-sands of sentences to be translated with low la-tency, a simulated post-editing paradigm (Hardtand Elming, 2010) can be used, wherein pre-generated reference translations act as a stand-infor actual post-editing.
This approximation is ef-fective for tuning and internal evaluation whenreal post-editing data is unavailable.
In simulatedpost-editing tasks, decoding (for both the test cor-pus and each pass over the development corpusduring optimization) begins with baseline mod-els trained on standard bilingual and monolingualtext.
After each sentence is translated, the fol-lowing take place in order: First, MIRA uses thenew source?reference pair to update weights forthe current models.
Second, the source is alignedto the reference using word-alignment modelslearned from the initial data and used to update thetranslation grammar.
Third, the reference is addedto the Bayesian language model.
As sentences aretranslated, the models gain valuable context infor-mation, allowing them to adapt to the specific tar-get document and translator.
Context is reset at thestart of each development or test corpus.
Systemsoptimized with simulated post-editing can then bedeployed to serve real human translators withoutfurther modification.3 cdec RealtimeNow included as part of the free, open sourcecdec machine translation toolkit (Dyer et al.,2010), Realtime1provides an efficient implemen-tation of the adaptive MT paradigm that can servean arbitrary number of unique post-editors concur-rently.
A full Realtime tutorial, including step-by-step instructions for installing required soft-ware and building full adaptive systems, is avail-1https://github.com/redpony/cdec/tree/master/realtime73import rt# Start new Realtime translator using a Spanish--English# system and automatic, language-independent text normalization# (pre-tokenization and post-detokenization)translator = rt.RealtimeTranslator(?es-en.d?, tmpdir=?/tmp?, cache_size=5,norm=True)# Translate a sentence for user1translation = translator.translate(?Muchas gracias Chris.
?, ctx_name=?user1?
)# Learn from user1?s post-edited transaltiontranslator.learn(?Muchas gracias Chris.
?, ?Thank you so much, Chris.?,ctx_name=?user1?
)# Save, free, and reload state for user1translator.save_state(file_or_stringio=?user1.state?, ctx_name=?user1?)translator.drop_ctx(ctx_name=?user1?
)translator.load_state(file_or_stringio=?user1.state?, ctx_name=?user1?
)Figure 1: Sample code using the Realtime Python API to translate and learn from post-editing.able online.2Building an adaptive system beginswith the usual MT pipeline steps: word alignment,bitext indexing (for suffix array grammar extrac-tion), and standard n-gram language model esti-mation.
Additionally, the cpyp3package, alsofreely available, is used to estimate a Bayesiann-gram language model on the target side of thebitext.
The cdec grammar extractor and dy-namic language model implementations both in-clude support for efficient inclusion of incrementaldata, allowing optimization with simulated post-editing to be parallelized.
The resulting system,optimized for post-editing, is then ready for de-ployment with Realtime.At runtime, a Realtime system operates as fol-lows.
A single instance of the indexed bitext isloaded into memory for grammar extraction.
Sin-gle instances of the directional word alignmentmodels are loaded into memory for force-aligningpost-edited data.
When a new user requests atranslation, a new context is started.
The follow-ing are loaded into memory: a table of all post-edited data from the user, a user-specific dynamiclanguage model, and a user-specific decoder (inthis case an instance of MIRA that has a user-specific decoder and set of weights).
Each useralso requires an instance of the large static lan-guage model, though all users effectively share asingle instance through the memory mapped im-plementation of KenLM (Heafield, 2011).
When a2http://www.cs.cmu.edu/?mdenkows/cdec-realtime.html3https://github.com/redpony/cpypnew sentence is to be translated, the grammar ex-tractor samples from the shared background dataplus the user-specific post-editing data to generatea sentence-specific grammar incorporating datafrom all prior sentences translated by the sameuser.
The sentence is then decoded using the userand time-specific grammar, current weights, andcurrent dynamic language model.
When a post-edited sentence is available as feedback, the fol-lowing happen in order: (1) the source-referencepair is used to update feature weights with MIRA,(2) the source-reference pair is force-aligned andadded to the indexed post-editing data, and (3) thedynamic language model is updated with the ref-erence.
User state (current weights and indexedpost-edited data for grammars and the languagemodel) can be saved and loaded, allowing mod-els to be loaded and freed from memory as trans-lators start and stop their work.
Figure 1 showsa minimal example of the above using the Real-time package.
While this paper describes integra-tion with TransCenter, a tool primarily targetingdata collection and analysis, the Realtime PythonAPI allows straightforward integration with othercomputer-assisted translation tools such as full-featured translation workbench environments.4 TransCenter: Web-Based TranslationResearch SuiteThe TransCenter software (Denkowski and Lavie,2012) dramatically lowers barriers in post-editingdata collection and increases the accuracy and de-scriptiveness of the collected data.
TransCenter74Figure 2: Example of editing and rating machine translations with the TransCenter web interface.Figure 3: Example TransCenter summary report for a single user on a document.provides a web-based translation editing interfacethat remotely monitors and records user activity.The ?live?
version4now uses cdec Realtime toprovide on-demand MT that automatically learnsfrom post-editor feedback.
Translators use a webbrowser to access a familiar two-column editingenvironment (shown in Figure 2) from any com-puter with an Internet connection.
The left columndisplays the source sentences, while the right col-umn, initially empty, is incrementally populatedwith translations from the Realtime system as theuser works.
For each sentence, the translator ed-its the MT output to be grammatically correct andconvey the same information as the source sen-tence.
During editing, all user actions (key pressesand mouse clicks) are logged so that the full edit-ing process can be replayed and analyzed.
Afterediting, the final translation is reported to the Re-altime system for learning and the next transla-tion is generated.
The user is additionally askedto rate the amount of work required to post-editeach sentence immediately after completing it,yielding maximally accurate feedback.
The ratingscale ranges from 5 (no post-editing required) to1 (requires total re-translation).
TransCenter alsorecords the number of seconds each sentence isfocused, allowing for exact timing measurements.A pause button is available if the translator needsto take breaks.
TransCenter can generate reports4https://github.com/mjdenkowski/transcenter-liveof translator effort as measured by (1) keystroke,(2) exact timing, and (3) actual translator post-assessment.
Final translations are also availablefor calculating edit distance.
Millisecond-leveltiming of all user actions further facilitates timesequence analysis of user actions and pauses.
Fig-ure 3 shows an example summary report gener-ated by TransCenter showing a user?s activity oneach sentence in a document.
This informationis also output in a simple comma-separated valueformat for maximum interoperability with otherstandards-compliant tools.TransCenter automatically handles resourcemanagement with Realtime.
When a TransCenterserver is started, it loads a Realtime system withzero contexts into memory.
As users log in to workon documents, new contexts are created to deliveron-demand translations.
As users finish work-ing or take extended breaks, contexts automati-cally time out and resources are freed.
Translatorand document-specific state is automatically savedwhen contexts time out and reloaded when transla-tors resume work with built-in safeguards againstmissing or duplicating any post-editing data dueto timeouts or Internet connectivity issues.
Thisallows any number of translators to work on trans-lation tasks at their convenience.5 ExperimentsIn a preliminary experiment to evaluate the impactof adaptive MT in real-world post-editing scenar-75HTER RatingBaseline 19.26 4.19Adaptive 17.01 4.31Table 1: Aggregate HTER scores and averagetranslator self-ratings (5 point scale) of post-editing effort for translations of TED talks fromSpanish into English.ios, we compare a static Spanish?English MT sys-tem to a comparable adaptive system on a blindout-of-domain test.
Competitive with the currentstate-of-the-art, both systems are trained on the2012 NAACL WMT (Callison-Burch et al., 2012)constrained resources (2 million bilingual sen-tences) using the cdec toolkit (Dyer et al., 2010).Blind post-editing evaluation sets are drawn fromthe Web Inventory of Transcribed and TranslatedTalks (WIT3) corpus (Cettolo et al., 2012) thatmakes transcriptions of TED talks5available inseveral languages, including English and Spanish.We select 4 excerpts from Spanish talk transcripts(totaling 100 sentences) to be translated into En-glish.
Five students training to be professionaltranslators post-edit machine translations of theseexcerpts using TransCenter.
Translations are pro-vided by either the static or fully adaptive system.Tasks are divided such that each user translates2 excerpts with the static system and 2 with theadaptive system and each excerpt is post-edited ei-ther 2 or 3 times with each system.
Users do notknow which system is providing the translations.Using the data collected by TransCenter, weevaluate post-editing effort with the establishedhuman-targeted translation edit rate (HTER) met-ric (Snover et al., 2006).
HTER computes anedit distance score between initial MT outputs andthe ?targeted?
references created by human post-editing, with lower scores being better.
Resultsfor the two systems are aggregated over all usersand documents.
Shown in Table 1, introducingan adaptive MT system results in a significant re-duction in editing effort.
We additionally aver-age the user post-ratings for each translation bysystem to evaluate user perception of the adap-tive system compared to the static baseline.
Alsoshown in Table 1, we see a slight preference forthe adaptive system.
This data, as well as precisekeystroke, mouse click, and timing information is5http://www.ted.com/talksmade freely available for further analysis.6Trans-Center records all data necessary for more sophis-ticated editing time analysis (Koehn, 2012) as wellas analysis of translator behavior, including pauses(used as an indicator of cognitive effort) (Lacruz etal., 2012).6 Related WorkThere has been a recent push for new computer-aided translation (CAT) tools that leverage adap-tive machine translation.
The CASMACAT7project (Alabau et al., 2013) focuses on buildingstate-of-the-art tools for computer-aided transla-tion.
This includes translation predictions backedby machine translation systems that incrementallyupdate model parameters as users edit translations(Mart?
?nez-G?omez et al., 2012; L?opez-Salcedo etal., 2012).
The MateCat8project (Cattelan, 2013)specifically aims to integrate machine translation(including online model adaptation and translationquality estimation) into a web-based CAT tool.Bertoldi et al.
(2013) show improvements in trans-lator productivity when using the MateCat toolwith an adaptive MT system that uses cache-basedtranslation and language models.7 ConclusionThis paper describes the free, open source MTpost-editing setup provided by cdec Realtimeand TransCenter.
All software and the data col-lected for a preliminary post-editing experimentare all freely available online.
A live demon-stration of adaptive MT post-editing powered byRealtime and TransCenter is scheduled for the2014 EACL Workshop on Humans and Computer-assisted Translation (HaCaT 2014).AcknowledgementsThis work is supported in part by the National Sci-ence Foundation under grant IIS-0915327, by theQatar National Research Fund (a member of theQatar Foundation) under grant NPRP 09-1140-1-177, and by the NSF-sponsored XSEDE programunder grant TG-CCR110017.6www.cs.cmu.edu/?mdenkows/transcenter-round1.tar.gz7http://casmacat.eu/8http://www.matecat.com/76ReferencesVicent Alabau, Ragnar Bonk, Christian Buck, MichaelCarl, Francisco Casacuberta, Mercedes Garc??a-Mart?
?nez, Jes?us Gonz?alez-Rubio, Philipp Koehn,Luis A. Leiva, Bartolom?e Mesa-Lao, Daniel Ortiz-Mart?
?nez, Herv?e Saint-Amand, Germ?an Sanchis-Trilles, and Chara Tsoukala.
2013.
Casmacat:An open source workbench for advanced computeraided translation.
In The Prague Bulletin of Mathe-matical Linguistics, pages 101?112.Nicola Bertoldi, Mauro Cettolo, and Marcello Fed-erico.
2013.
Cache-based online adaptation for ma-chine translation enhanced computer assisted trans-lation.
In Proceedings of the XIV Machine Transla-tion Summit, pages 35?42.Chris Callison-Burch, Philipp Koehn, Christof Monz,Matt Post, Radu Soricut, and Lucia Specia.
2012.Findings of the 2012 workshop on statistical ma-chine translation.
In Proceedings of the SeventhWorkshop on Statistical Machine Translation, pages10?51, Montr?eal, Canada, June.
Association forComputational Linguistics.Alessandro Cattelan.
2013.
Second version of Mate-Cat tool.
Deliverable 4.2.Mauro Cettolo, Christian Girardi, and Marcello Fed-erico.
2012.
Wit3: Web inventory of transcribedand translated talks.
In Proceedings of the SixteenthAnnual Conference of the European Association forMachine Translation.Victor Chahuneau, Noah A. Smith, and Chris Dyer.2012.
pycdec: A python interface to cdec.
ThePrague Bulletin of Mathematical Linguistics, 98:51?61.David Chiang.
2007.
Hierarchical phrase-based trans-lation.
Computational Linguistics, 33.Koby Crammer, Ofer Dekel, Joseph Keshet, ShaiShalev-Shwartz, and Yoram Singer.
2006.
Onlinepassive-aggressive algorithms.
Journal of MachineLearning Research, pages 551?558, March.Michael Denkowski and Alon Lavie.
2012.
Trans-Center: Web-based translation research suite.
InAMTA 2012 Workshop on Post-Editing Technologyand Practice Demo Session.Michael Denkowski, Chris Dyer, and Alon Lavie.2014.
Learning from post-editing: Online modeladaptation for statistical machine translation.
InProceedings of the 14th Conference of the EuropeanChapter of the Association for Computational Lin-guistics.Chris Dyer, Adam Lopez, Juri Ganitkevitch, JonathanWeese, Ferhan Ture, Phil Blunsom, Hendra Seti-awan, Vladimir Eidelman, and Philip Resnik.
2010.cdec: A decoder, alignment, and learning frameworkfor finite-state and context-free translation models.In Proceedings of the ACL 2010 System Demonstra-tions, pages 7?12, Uppsala, Sweden, July.
Associa-tion for Computational Linguistics.Vladimir Eidelman.
2012.
Optimization strategies foronline large-margin learning in machine translation.In Proceedings of the Seventh Workshop on Statisti-cal Machine Translation, pages 480?489, Montr?eal,Canada, June.
Association for Computational Lin-guistics.Daniel Hardt and Jakob Elming.
2010.
Incrementalre-training for post-editing smt.
In Proceedings ofthe Ninth Conference of the Association for MachineTranslation in the Americas.Kenneth Heafield.
2011.
KenLM: faster and smallerlanguage model queries.
In Proceedings of the SixthWorkshop on Statistical Machine Translation, pages187?197, Edinburgh, Scotland, United Kingdom,July.Philipp Koehn.
2012.
Computer-aided translation.Machine Translation Marathon.Isabel Lacruz, Gregory M. Shreve, and Erik Angelone.2012.
Average Pause Ratio as an Indicator of Cogni-tive Effort in Post-Editing: A Case Study.
In AMTA2012 Workshop on Post-Editing Technology andPractice (WPTP 2012), pages 21?30, San Diego,USA, October.
Association for Machine Translationin the Americas (AMTA).Adam Lopez.
2008.
Machine translation by patternmatching.
In Dissertation, University of Maryland,March.Francisco-Javier L?opez-Salcedo, Germ?an Sanchis-Trilles, and Francisco Casacuberta.
2012.
On-line learning of log-linear weights in interactive ma-chine translation.
Advances in Speech and Lan-guage Technologies for Iberian Languages, pages277?286.Pascual Mart?
?nez-G?omez, Germ?an Sanchis-Trilles, andFrancisco Casacuberta.
2012.
Online adaptationstrategies for statistical machine translation in post-editing scenarios.
Pattern Recognition, 45:3193?3203.Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-nea Micciulla, and John Makhoul.
2006.
A studyof translation edit rate with targeted human annota-tion.
In Proceedings of the 7th Conference of the.Association for Machine Translation of the Ameri-cas, pages 223?231.Yee Whye Teh.
2006.
A hierarchical Bayesian lan-guage model based on Pitman-Yor processes.
InProc.
of ACL.77
