Proceedings of the ACL 2010 Conference Short Papers, pages 98?102,Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational LinguisticsA Structured Model for Joint Learning ofArgument Roles and Predicate SensesYotaro WatanabeGraduate School of Information SciencesTohoku University6-6-05, Aramaki Aza Aoba, Aoba-ku,Sendai 980-8579, Japanyotaro-w@ecei.tohoku.ac.jpMasayuki Asahara Yuji MatsumotoGraduate School of Information ScienceNara Institute of Science and Technology8916-5 Takayama, Ikoma,Nara, 630-0192, Japan{masayu-a, matsu}@is.naist.jpAbstractIn predicate-argument structure analysis,it is important to capture non-local de-pendencies among arguments and inter-dependencies between the sense of a pred-icate and the semantic roles of its argu-ments.
However, no existing approach ex-plicitly handles both non-local dependen-cies and semantic dependencies betweenpredicates and arguments.
In this pa-per we propose a structured model thatovercomes the limitation of existing ap-proaches; the model captures both types ofdependencies simultaneously by introduc-ing four types of factors including a globalfactor type capturing non-local dependen-cies among arguments and a pairwise fac-tor type capturing local dependencies be-tween a predicate and an argument.
Inexperiments the proposed model achievedcompetitive results compared to the state-of-the-art systems without applying anyfeature selection procedure.1 IntroductionPredicate-argument structure analysis is a processof assigning who does what to whom, where,when, etc.
for each predicate.
Arguments of apredicate are assigned particular semantic roles,such as Agent, Theme, Patient, etc.
Lately,predicate-argument structure analysis has been re-garded as a task of assigning semantic roles ofarguments as well as word senses of a predicate(Surdeanu et al, 2008; Hajic?
et al, 2009).Several researchers have paid much attention topredicate-argument structure analysis, and the fol-lowing two important factors have been shown.Toutanova et al (2008), Johansson and Nugues(2008), and Bjo?rkelund et al (2009) presentedimportance of capturing non-local dependenciesof core arguments in predicate-argument structureanalysis.
They used argument sequences tied witha predicate sense (e.g.
AGENT-buy.01/Active-PATIENT) as a feature for the re-ranker of thesystem where predicate sense and argument rolecandidates are generated by their pipelined archi-tecture.
They reported that incorporating this typeof features provides substantial gain of the systemperformance.The other factor is inter-dependencies betweena predicate sense and argument roles, which re-late to selectional preference, and motivated usto jointly identify a predicate sense and its argu-ment roles.
This type of dependencies has beenexplored by Riedel and Meza-Ruiz (2008; 2009b;2009a), all of which use Markov Logic Networks(MLN).
The work uses the global formulae thathave atoms in terms of both a predicate sense andeach of its argument roles, and the system identi-fies predicate senses and argument roles simulta-neously.Ideally, we want to capture both types of depen-dencies simultaneously.
The former approachescan not explicitly include features that captureinter-dependencies between a predicate sense andits argument roles.
Though these are implicitly in-corporated by re-ranking where the most plausi-ble assignment is selected from a small subset ofpredicate and argument candidates, which are gen-erated independently.
On the other hand, it is dif-ficult to deal with core argument features in MLN.Because the number of core arguments varies withthe role assignments, this type of features cannotbe expressed by a single formula.Thompson et al (2010) proposed a gener-ative model that captures both predicate sensesand its argument roles.
However, the first-ordermarkov assumption of the model eliminates abil-ity to capture non-local dependencies among ar-guments.
Also, generative models are in generalinferior to discriminatively trained linear or log-98!!!"#!"$%!"%!"$!&'!&(!
&)!&*!&+!,!Figure 1: Undirected graphical model representa-tion of the structured modellinear models.In this paper we propose a structured modelthat overcomes limitations of the previous ap-proaches.
For the model, we introduce severaltypes of features including those that capture bothnon-local dependencies of core arguments, andinter-dependencies between a predicate sense andits argument roles.
By doing this, both tasks aremutually influenced, and the model determinesthe most plausible set of assignments of a predi-cate sense and its argument roles simultaneously.We present an exact inference algorithm for themodel, and a large-margin learning algorithm thatcan handle both local and global features.2 ModelFigure 1 shows the graphical representation of ourproposed model.
The node p corresponds to apredicate, and the nodes a1, ..., aN to argumentsof the predicate.
Each node is assigned a particu-lar predicate sense or an argument role label.
Theblack squares are factors which provide scores oflabel assignments.
In the model, the nodes for ar-guments depend on the predicate sense, and by in-fluencing labels of a predicate sense and its argu-ment roles, the most plausible label assignment ofthe nodes is determined considering all factors.In this work, we use linear models.
Let x bewords in a sentence, p be a sense of a predicate inx, and A = {an}N1 be a set of possible role labelassignments for x.
A predicate-argument structureis represented by a pair of p and A.
We definethe score function for predicate-argument struc-tures as s(p,A) =?Fk?F Fk(x, p,A).
F is aset of all the factors, Fk(x, p,A) corresponds to aparticular factor in Figure 1, and gives a score to apredicate or argument label assignments.
Since weuse linear models, Fk(x, p,A) = w ?
?k(x, p,A).2.1 Factors of the ModelWe define four types of factors for the model.Predicate Factor FP scores a sense of p, anddoes not depend on any arguments.
The scorefunction is defined byFP (x, p,A) = w?
?P (x, p).Argument Factor FA scores a label assignmentof a particular argument a ?
A.
The score is deter-mined independently from a predicate sense, andis given by FA(x, p, a) = w ?
?A(x, a).Predicate-Argument Pairwise FactorFPA captures inter-dependencies betweena predicate sense and one of its argumentroles.
The score function is defined asFPA(x, p, a) = w ?
?PA(x, p, a).
The dif-ference from FA is that FPA influences boththe predicate sense and the argument role.
Byintroducing this factor, the role label can beinfluenced by the predicate sense, and vise versa.Global Factor FG is introduced to capture plau-sibility of the whole predicate-argument structure.Like the other factors, the score function is de-fined as FG(x, p,A) = w ?
?G(x, p,A).
A pos-sible feature that can be considered by this fac-tor is the mutual dependencies among core argu-ments.
For instance, if a predicate-argument struc-ture has an agent (A0) followed by the predicateand a patient (A1), we encode the structure as astring A0-PRED-A1 and use it as a feature.
Thistype of features provide plausibility of predicate-argument structures.
Even if the highest scoringpredicate-argument structure with the other factorsmisses some core arguments, the global featuredemands the model to fill the missing arguments.The numbers of factors for each factor type are:FP and FG are 1, FA and FPA are |A|.
By inte-grating the all factors, the score function becomess(p,A) = w ?
?P (x, p) +w ?
?G(x, p,A) +w ?
?a?A{?A(x, a) + ?PA(x, p, a)}.2.2 InferenceThe crucial point of the model is how to dealwith the global factor FG, because enumeratingpossible assignments is too costly.
A number ofmethods have been proposed for the use of globalfeatures for linear models such as (Daume?
IIIand Marcu, 2005; Kazama and Torisawa, 2007).In this work, we use the approach proposed in(Kazama and Torisawa, 2007).
Although the ap-proach is proposed for sequence labeling tasks, it99can be easily extended to our structured model.That is, for each possible predicate sense p of thepredicate, we provide N-best argument role as-signments using three local factors FP , FA andFPA, and then add scores of the global factor FG,finally select the argmax from them.
In this case,the argmax is selected from |Pl|N candidates.2.3 Learning the ModelFor learning of the model, we borrow a funda-mental idea of Kazama and Torisawa?s perceptronlearning algorithm.
However, we use a more so-phisticated online-learning algorithm based on thePassive-Aggressive Algorithm (PA) (Crammer etal., 2006).For the sake of simplicity, we introduce somenotations.
We denote a predicate-argument struc-ture y = ?p,A?, a local feature vector as?L(x,y) = ?P (x, p) +?a?A{?A(x, a) +?PA(x, p, a)}?a feature vector coupling bothlocal and global features as ?L+G(x,y) =?L(x,y) + ?G(x, p,A), the argmax using ?L+Gas y?L+G, the argmax using ?L as y?L.
Also, weuse a loss function ?(y,y?
), which is a cost func-tion associated with y and y?.The margin perceptron learning proposed byKazama and Torisawa can be seen as an optimiza-tion with the following two constrains.
(A) w??L+G(x,y)?w?
?L+G(x, y?L+G) ?
?
(y, y?L+G)(B) w ?
?L(x,y) ?w ?
?L(x, y?L) ?
?
(y, y?L)(A) is the constraint that ensures a sufficientmargin ?
(y, y?L+G) between y and y?L+G.
(B)is the constraint that ensures a sufficient margin?
(y, y?L) between y and y?L.
The necessity ofthis constraint is that if we apply only (A), the al-gorithm does not guarantee a sufficient margin interms of local features, and it leads to poor qualityin the N-best assignments.
The Kazama and Tori-sawa?s perceptron algorithm uses constant valuesfor the cost function ?
(y, y?L+G) and ?
(y, y?L).The proposed model is trained using the follow-ing optimization problem.wnew = arg minw?
?<n12 ||w?
?w||2 + C?(s.t.
lL+G ?
?, ?
?
0 if y?L+G 6= ys.t.
lL ?
?, ?
?
0 if y?L+G = y 6= y?L(1)lL+G = w ?
?L+G(x, y?L+G)?w ?
?L+G(x,y) + ?
(y, y?L+G) (2)lL = w ?
?L(x, y?L) ?w ?
?L(x,y) + ?
(y, y?L) (3)lL+G is the loss function for the case of usingboth local and global features, corresponding tothe constraint (A), and lL is the loss function forthe case of using only local features, correspond-ing to the constraints (B) provided that (A) is sat-isfied.2.4 The Role-less Argument Bias ProblemThe fact that an argument candidate is not as-signed any role (namely it is assigned the la-bel ?NONE?)
is unlikely to contribute pred-icate sense disambiguation.
However, it re-mains possible that ?NONE?
arguments is bi-ased toward a particular predicate sense by FPA(i.e.
w ?
?PA(x, sensei, ak= ?NONE??)
> w ?
?PA(x, sensej , ak= ?NONE??
).In order to avoid this bias, we define a spe-cial sense label, senseany, that is used to cal-culate the score for a predicate and a roll-lessargument, regardless of the predicate?s sense.We use the feature vector ?PA(x, senseany, ak)if ak= ?NONE??
and ?PA(x, sensei, ak) other-wise.3 Experiment3.1 Experimental SettingsWe use the CoNLL-2009 Shared Task dataset(Hajic?
et al, 2009) for experiments.
It is adataset for multi-lingual syntactic and semanticdependency parsing 1.
In the SRL-only challengeof the task, participants are required to identifypredicate-argument structures of only the specifiedpredicates.
Therefore the problems to be solvedare predicate sense disambiguation and argumentrole labeling.
We use Semantic Labeled F1 forevaluation.For generating N-bests, we used the beam-search algorithm, and the number of N-bests wasset to N = 64.
For learning of the joint model, theloss function ?(yt,y?)
of the Passive-AggressiveAlgorithm was set to the number of incorrect as-signments of a predicate sense and its argumentroles.
Also, the number of iterations of the modelused for testing was selected based on the perfor-mance on the development data.Table 1 shows the features used for the struc-tured model.
The global features used for FG arebased on those used in (Toutanova et al, 2008;Johansson and Nugues, 2008), and the features1The dataset consists of seven languages: Catalan, Chi-nese, Czech, English, German, Japanese and Spanish.100FP Plemma of the predicate and predicate?s head, and ppos of the predicateDependency label between the predicate and predicate?s headThe concatenation of the dependency labels of the predicate?s dependentsFA Plemma and ppos of the predicate, the predicate?s head, the argument candidate, and the argument?s headPlemma and ppos of the leftmost/rightmost dependent and leftmost/rightmost siblingThe dependency label of predicate, argument candidate and argument candidate?s dependentThe position of the argument candidate with respect to the predicate position in the dep.
tree (e.g.
CHILD)The position of the head of the dependency relation with respect to the predicate position in the sentenceThe left-to-right chain of the deplabels of the predicate?s dependentsPlemma, ppos and dependency label paths between the predicate and the argument candidatesThe number of dependency edges between the predicate and the argument candidateFPA Plemma and plemma&ppos of the argument candidateDependency label path between the predicate and the argument candidatesFG The sequence of the predicate and the argument labels in the predicate-argument structure (e.g.
A0-PRED-A1?Whether the semantic roles defined in frames exist in the structure, (e.g.
CONTAINS:A1)The conjunction of the predicate sense and the frame information (e.g.
wear.01&CONTAINS:A1)Table 1: Features for the Structured ModelAvg.
Ca Ch Cz En Ge Jp SpFP+FA 79.17 78.00 76.02 85.24 83.09 76.76 77.27 77.83FP+FA+FPA 79.58 78.38 76.23 85.14 83.36 78.31 77.72 77.92FP+FA+FG 80.42 79.50 76.96 85.88 84.49 78.64 78.32 79.21ALL 80.75 79.55 77.20 85.94 84.97 79.62 78.69 79.29Bjo?rkelund 80.80 80.01 78.60 85.41 85.63 79.71 76.30 79.91Zhao 80.47 80.32 77.72 85.19 85.44 75.99 78.15 80.46Meza-Ruiz 77.46 78.00 77.73 75.75 83.34 73.52 76.00 77.91Table 2: Results on the CoNLL-2009 Shared Task dataset (Semantic Labeled F1).SENSE ARGFP+FA 89.65 72.20FP+FA+FPA 89.78 72.74FP+FA+FG 89.83 74.11ALL 90.15 74.46Table 3: Predicate sense disambiguation and argu-ment role labeling results (average).used for FPA are inspired by formulae used inthe MLN-based SRL systems, such as (Meza-Ruizand Riedel, 2009b).
We used the same featuretemplates for all languages.3.2 ResultsTable 2 shows the results of the experiments, andalso shows the results of the top 3 systems in theCoNLL-2009 Shared Task participants of the SRL-only system.By incorporating FPA, we achieved perfor-mance improvement for all languages.
This resultssuggest that it is effective to capture local inter-dependencies between a predicate sense and oneof its argument roles.
Comparing the results withFP+FA and FP+FA+FG, incorporating FG alsocontributed performance improvements for all lan-guages, especially the substantial F1 improvementof +1.88 is obtained in German.Next, we compare our system with top 3 sys-tems in the CoNLL-2009 Shared Task.
By in-corporating both FPA and FG, our joint modelachieved competitive results compared to the top 2systems (Bjo?rkelund and Zhao), and achieved thebetter results than the Meza-Ruiz?s system 2.
Thesystems by Bjo?rkelund and Zhao applied featureselection algorithms in order to select the best setof feature templates for each language, requiringabout 1 to 2 months to obtain the best feature set.On the other hand, our system achieved the com-petitive results with the top two systems, despitethe fact that we used the same feature templatesfor all languages without applying any feature en-gineering procedure.Table 3 shows the performances of predicatesense disambiguation and argument role labelingseparately.
In terms of sense disambiguation re-sults, incorporating FPA and FG worked well.
Al-though incorporating either of FPA and FG pro-vided improvements of +0.13 and +0.18 on av-erage, adding both factors provided improvementsof +0.50.
We compared the predicate sense dis-2The result of Meza-Ruiz for Czech is substantially worsethan the other systems because of inappropriate preprocess-ing for predicate sense disambiguation.
Excepting Czech, theaverage F1 value of the Meza-Ruiz is 77.75, where as oursystem is 79.89.101ambiguation results of FP +FA and ALL with theMcNemar test, and the difference was statisticallysignificant (p < 0.01).
This result suggests thatcombination of these factors is effective for sensedisambiguation.As for argument role labeling results, incorpo-rating FPA and FG contributed positively for alllanguages.
Especially, we obtained a substan-tial gain (+4.18) in German.
By incorporatingFPA, the system achieved the F1 improvementsof +0.54 on average.
This result shows that cap-turing inter-dependencies between a predicate andits arguments contributes to argument role label-ing.
By incorporating FG, the system achieved thesubstantial improvement of F1 (+1.91).Since both tasks improved by using all factors,we can say that the proposed joint model suc-ceeded in joint learning of predicate senses andits argument roles.4 ConclusionIn this paper, we proposed a structured model thatcaptures both non-local dependencies between ar-guments, and inter-dependencies between a pred-icate sense and its argument roles.
We designeda linear model-based structured model, and de-fined four types of factors: predicate factor, ar-gument factor, predicate-argument pairwise fac-tor and global factor for the model.
In the ex-periments, the proposed model achieved compet-itive results compared to the state-of-the-art sys-tems without any feature engineering.A further research direction we are investi-gating is exploitation of unlabeled texts.
Semi-supervised semantic role labeling methods havebeen explored by (Collobert and Weston, 2008;Deschacht and Moens, 2009; Fu?rstenau and La-pata, 2009), and they have achieved successfuloutcomes.
However, we believe that there is stillroom for further improvement.ReferencesAnders Bjo?rkelund, Love Hafdell, and Pierre Nugues.2009.
Multilingual semantic role labeling.
InCoNLL-2009.Ronan Collobert and Jason Weston.
2008.
A unifiedarchitecture for natural language processing: Deepneural networks with multitask learning.
In ICML2008.Koby Crammer, Ofer Dekel, Joseph Keshet, ShaiShalev-Shwartz, and Yoram Singer.
2006.
Onlinepassive-aggressive algorithms.
JMLR, 7:551?585.Hal Daume?
III and Daniel Marcu.
2005.
Learningas search optimization: Approximate large marginmethods for structured prediction.
In ICML-2005.Koen Deschacht and Marie-Francine Moens.
2009.Semi-supervised semantic role labeling using the la-tent words language model.
In EMNLP-2009.Hagen Fu?rstenau and Mirella Lapata.
2009.
Graphalignment for semi-supervised semantic role label-ing.
In EMNLP-2009.Jan Hajic?, Massimiliano Ciaramita, Richard Johans-son, Daisuke Kawahara, Maria Anto`nia Mart?
?, Llu?
?sMa`rquez, Adam Meyers, Joakim Nivre, SebastianPado?, Jan S?te?pa?nek, Pavel Stran?a?k, Mihai Surdeanu,Nianwen Xue, and Yi Zhang.
2009.
The CoNLL-2009 shared task: Syntactic and semantic dependen-cies in multiple languages.
In CoNLL-2009, Boul-der, Colorado, USA.Richard Johansson and Pierre Nugues.
2008.Dependency-based syntactic-semantic analysiswith propbank and nombank.
In CoNLL-2008.Jun?Ichi Kazama and Kentaro Torisawa.
2007.
A newperceptron algorithm for sequence labeling withnon-local features.
In EMNLP-CoNLL 2007.Ivan Meza-Ruiz and Sebastian Riedel.
2009a.
Jointlyidentifying predicates, arguments and senses usingmarkov logic.
In HLT/NAACL-2009.Ivan Meza-Ruiz and Sebastian Riedel.
2009b.
Multi-lingual semantic role labelling with markov logic.In CoNLL-2009.Sebastian Riedel and Ivan Meza-Ruiz.
2008.
Collec-tive semantic role labelling with markov logic.
InCoNLL-2008.Mihai Surdeanu, Richard Johansson, Adam Mey-ers, Llu?
?s Ma`rquez, and Joakim Nivre.
2008.
TheCoNLL-2008 shared task on joint parsing of syntac-tic and semantic dependencies.
In CoNLL-2008.Synthia A. Thompson, Roger Levy, and Christopher D.Manning.
2010.
A generative model for semanticrole labeling.
In Proceedings of the 48th AnnualMeeting of the Association of Computational Lin-guistics (to appear).Kristina Toutanova, Aria Haghighi, and Christopher D.Manning.
2008.
A global joint model for semanticrole labeling.
Computational Linguistics, 34(2).102
