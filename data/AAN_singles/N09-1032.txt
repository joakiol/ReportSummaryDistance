Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the ACL, pages 281?289,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsDomain Adaptation with Latent Semantic Associationfor Named Entity RecognitionHonglei Guo Huijia Zhu Zhili Guo Xiaoxun Zhang Xian Wu and Zhong SuIBM China Research LaboratoryBeijing, P. R. China{guohl, zhuhuiji, guozhili, zhangxx, wuxian, suzhong}@cn.ibm.comAbstractDomain adaptation is an important problem innamed entity recognition (NER).
NER classi-fiers usually lose accuracy in the domain trans-fer due to the different data distribution be-tween the source and the target domains.
Themajor reason for performance degrading isthat each entity type often has lots of domain-specific term representations in the differentdomains.
The existing approaches usuallyneed an amount of labeled target domain datafor tuning the original model.
However, itis a labor-intensive and time-consuming taskto build annotated training data set for everytarget domain.
We present a domain adapta-tion method with latent semantic association(LaSA).
This method effectively overcomesthe data distribution difference without lever-aging any labeled target domain data.
LaSAmodel is constructed to capture latent seman-tic association among words from the unla-beled corpus.
It groups words into a set ofconcepts according to the related context snip-pets.
In the domain transfer, the original termspaces of both domains are projected to a con-cept space using LaSA model at first, then theoriginal NER model is tuned based on the se-mantic association features.
Experimental re-sults on English and Chinese corpus show thatLaSA-based domain adaptation significantlyenhances the performance of NER.1 IntroductionNamed entities (NE) are phrases that contain namesof persons, organizations, locations, etc.
NER is animportant task in information extraction and natu-ral language processing (NLP) applications.
Super-vised learning methods can effectively solve NERproblem by learning a model from manually labeleddata (Borthwick, 1999; Sang and Meulder, 2003;Gao et al, 2005; Florian et al, 2003).
However, em-pirical study shows that NE types have different dis-tribution across domains (Guo et al, 2006).
TrainedNER classifiers in the source domain usually loseaccuracy in a new target domain when the data dis-tribution is different between both domains.Domain adaptation is a challenge for NER andother NLP applications.
In the domain transfer,the reason for accuracy loss is that each NE typeoften has various specific term representations andcontext clues in the different domains.
For ex-ample, {?economist?, ?singer?, ?dancer?, ?athlete?,?player?, ?philosopher?, ...} are used as contextclues for NER.
However, the distribution of theserepresentations are varied with domains.
We expectto do better domain adaptation for NER by exploit-ing latent semantic association among words fromdifferent domains.
Some approaches have been pro-posed to group words into ?topics?
to capture im-portant relationships between words, such as LatentSemantic Indexing (LSI) (Deerwester et al, 1990),probabilistic Latent Semantic Indexing (pLSI) (Hof-mann, 1999), Latent Dirichlet Allocation (LDA)(Blei et al, 2003).
These models have been success-fully employed in topic modeling, dimensionalityreduction for text categorization (Blei et al, 2003),ad hoc IR (Wei and Croft., 2006), and so on.In this paper, we present a domain adaptationmethod with latent semantic association.
We focus281on capturing the hidden semantic association amongwords in the domain adaptation.
We introduce theLaSA model to overcome the distribution differencebetween the source domain and the target domain.LaSA model is constructed from the unlabeled cor-pus at first.
It learns latent semantic associationamong words from their related context snippets.In the domain transfer, words in the corpus are as-sociated with a low-dimension concept space usingLaSA model, then the original NER model is tunedusing these generated semantic association features.The intuition behind our method is that words in oneconcept set will have similar semantic features orlatent semantic association, and share syntactic andsemantic context in the corpus.
They can be consid-ered as behaving in the same way for discriminativelearning in the source and target domains.
The pro-posed method associates words from different do-mains on a semantic level rather than by lexical oc-currence.
It can better bridge the domain distribu-tion gap without any labeled target domain samples.Experimental results on English and Chinese corpusshow that LaSA-based adaptation significantly en-hances NER performance across domains.The rest of this paper is organized as follows.
Sec-tion 2 briefly describes the related works.
Section 3presents a domain adaptation method based on latentsemantic association.
Section 4 illustrates how tolearn LaSA model from the unlabeled corpus.
Sec-tion 5 shows experimental results on large-scale En-glish and Chinese corpus across domains, respec-tively.
The conclusion is given in Section 6.2 Related WorksSome domain adaptation techniques have been em-ployed in NLP in recent years.
Some of themfocus on quantifying the generalizability of cer-tain features across domains.
Roark and Bacchiani(2003) use maximum a posteriori (MAP) estimationto combine training data from the source and targetdomains.
Chelba and Acero (2004) use the param-eters of the source domain maximum entropy clas-sifier as the means of a Gaussian prior when train-ing a new model on the target data.
Daume III andMarcu (2006) use an empirical Bayes model to esti-mate a latent variable model grouping instances intodomain-specific or common across both domains.Daume III (2007) further augments the feature spaceon the instances of both domains.
Jiang and Zhai(2006) exploit the domain structure contained in thetraining examples to avoid over-fitting the trainingdomains.
Arnold et al (2008) exploit feature hier-archy for transfer learning in NER.
Instance weight-ing (Jiang and Zhai, 2007) and active learning (Chanand Ng, 2007) are also employed in domain adap-tation.
Most of these approaches need the labeledtarget domain samples for the model estimation inthe domain transfer.
Obviously, they require muchefforts for labeling the target domain samples.Some approaches exploit the common structure ofrelated problems.
Ando et al (2005) learn pred-icative structures from multiple tasks and unlabeleddata.
Blitzer et al (2006, 2007) employ structuralcorresponding learning (SCL) to infer a good fea-ture representation from unlabeled source and targetdata sets in the domain transfer.
We present LaSAmodel to overcome the data gap across domains bycapturing latent semantic association among wordsfrom unlabeled source and target data.In addition, Miller et al (2004) and Freitag(2004) employ distributional and hierarchical clus-tering methods to improve the performance of NERwithin a single domain.
Li and McCallum (2005)present a semi-supervised sequence modeling withsyntactic topic models.
In this paper, we focus oncapturing hidden semantic association among wordsin the domain adaptation.3 Domain Adaptation Based on LatentSemantic AssociationThe challenge in domain adaptation is how to cap-ture latent semantic association from the source andtarget domain data.
We present a LaSA-based do-main adaptation method in this section.NER can be considered as a classification prob-lem.
Let X be a feature space to represent the ob-served word instances, and let Y be the set of classlabels.
Let ps(x, y) and pt(x, y) be the true under-lying distributions for the source and the target do-mains, respectively.
In order to minimize the effortsrequired in the domain transfer, we often expect touse ps(x, y) to approximate pt(x, y).However, data distribution are often varied withthe domains.
For example, in the economics-to-282entertainment domain transfer, although many NEtriggers (e.g.
?company?
and ?Mr.?)
are used inboth domains, some are totally new, like ?dancer?,?singer?.
Moreover, many useful words (e.g.?economist?)
in the economics NER are useless inthe entertainment domain.
The above examplesshow that features could change behavior across do-mains.
Some useful predictive features from one do-main are not predictive or do not appear in anotherdomain.
Although some triggers (e.g.
?singer?,?economist?)
are completely distinct for each do-main, they often appear in the similar syntactic andsemantic context.
For example, triggers of per-son entity often appear as the subject of ?visited?,?said?, etc, or are modified by ?excellent?, ?popu-lar?, ?famous?
etc.
Such latent semantic associationamong words provides useful hints for overcomingthe data distribution gap of both domains.Hence, we present a LaSA model ?s,t to cap-ture latent semantic association among words in thedomain adaptation.
?s,t is learned from the unla-beled source and target domain data.
Each instanceis characterized by its co-occurred context distribu-tion in the learning.
Semantic association featurein ?s,t is a hidden random variable that is inferredfrom data.
In the domain adaptation, we transfer theproblem of semantic association mapping to a pos-terior inference task using LaSA model.
Latent se-mantic concept association set of a word instance x(denoted by SA(x)) is generated by ?s,t.
Instancesin the same concept set are considered as behavingin the same way for discriminative learning in bothdomains.
Even though word instances do not ap-pear in a training corpus (or appear rarely) but are insimilar context, they still might have relatively highprobability in the same semantic concept set.
Obvi-ously, SA(x) can better bridge the gap between thetwo distributions ps(y|x) and pt(y|x).
Hence, LaSAmodel can enhance the estimate of the source do-main distribution ps(y|x; ?s,t) to better approximatethe target domain distribution pt(y|x; ?s,t).4 Learning LaSA Model from VirtualContext DocumentsIn the domain adaptation, LaSA model is employedto find the latent semantic association structures of?words?
in a text corpus.
We will illustrate howto build LaSA model from words and their contextsnippets in this section.
LaSA model actually canbe considered as a general probabilistic topic model.It can be learned on the unlabeled corpus using thepopular hidden topic models such as LDA or pLSI.4.1 Virtual Context DocumentThe distribution of content words (e.g.
nouns, adjec-tives) is usually varied with domains.
Hence, in thedomain adaptation, we focus on capturing the latentsemantic association among content words.
In or-der to learn latent relationships among words fromthe unlabeled corpus, each content word is charac-terized by a virtual context document as follows.Given a content word xi, the virtual context docu-ment of xi (denoted by vdxi) consists of all the con-text units around xi in the corpus.
Let n be the totalnumber of the sentences which contain xi in the cor-pus.
vdxi is constructed as follows.vdxi = {F (xs1i ), ..., F (xski ), ..., F (xsni )}where, F (xski ) denotes the context feature set ofxi in the sentence sk, 1 ?
k ?
n.Given the context window size {-t, t} (i.e.
pre-vious t words and next t words around xi in sk).F (xski ) usually consists of the following features.1.
Anchor unit AxiC : the current focused word unit xi.2.
Left adjacent unit AxiL : The nearest left adjacentunit xi?1 around xi, denoted by AL(xi?1).3.
Right adjacent unit AxiR : The nearest right adjacentunit xi+1 around xi, denoted by AR(xi+1).4.
Left context set CxiL : the other left adjacent units{xi?t, ..., xi?j , ..., xi?2} (2 ?
j ?
t) around xi, de-noted by {CL(xi?t), ..., CL(xi?j), ..., CL(xi?2)}.5.
Right context set CxiR : the other right adjacent units{xi+2, ..., xi+j , ..., xi+t} (2 ?
j ?
t ) around xi, de-noted by {CR(xi+2), ..., CR(xi+j), ..., CR(xi+t)}.For example, given xi=?singer?, sk=?This popu-lar new singer attended the new year party?.
Letthe context window size be {-3,3}.
F (singer)= {singer, AL(new), AR(attend(ed)), CL(this),CL(popular), CR(the), CR(new) }.vdxi actually describes the semantic and syntac-tic feature distribution of xi in the domains.
Weconstruct the feature vector of xi with all the ob-served context features in vdxi .
Given vdxi =283{f1, ..., fj , ..., fm}, fj denotes jth context featurearound xi, 1 ?
j ?
m, m denotes the total num-ber of features in vdxi .
The value of fj is calculatedby Mutual Information (Church and Hanks, 1990)between xi and fj .Weight(fj , xi) = log2 P (fj , xi)P (fj)P (xi) (1)where, P (fj , xi) is the joint probability of xi andfj co-occurred in the corpus, P (fj) is the probabil-ity of fj occurred in the corpus.
P (xi) is the proba-bility of xi occurred in the corpus.4.2 Learning LaSA ModelTopic models are statistical models of text that posita hidden space of topics in which the corpus is em-bedded (Blei et al, 2003).
LDA (Blei et al, 2003) isa probabilistic model that can be used to model anddiscover underlying topic structures of documents.LDA assumes that there are K ?topics?, multinomialdistributions over words, which describes a collec-tion.
Each document exhibits multiple topics, andeach word in each document is associated with oneof them.
LDA imposes a Dirichlet distribution onthe topic mixture weights corresponding to the doc-uments in the corpus.
The topics derived by LDAseem to possess semantic coherence.
Those wordswith similar semantics are likely to occur in the sametopic.
Since the number of LDA model parametersdepends only on the number of topic mixtures andvocabulary size, LDA is less prone to over-fittingand is capable of estimating the probability of un-observed test documents.
LDA is already success-fully applied to enhance document representationsin text classification (Blei et al, 2003), informationretrieval (Wei and Croft., 2006).In the following, we illustrate how to constructLDA-style LaSA model ?s,t on the virtual con-text documents.
Algorithm 1 describes LaSAmodel training method in detail, where, FunctionAddTo(data, Set) denotes that data is added toSet.
Given a large-scale unlabeled data set Duwhich consists of the source and target domain data,virtual context document for each candidate contentword is extracted from Du at first, then the value ofeach feature in a virtual context document is calcu-lated using its Mutual Information ( see Equation 1in Section 4.1) instead of the counts when runningAlgorithm 1: LaSA Model TrainingInputs:1?
Unlabeled data set: Du ;2Outputs:3?LaSA model: ?s,t;4Initialization:5?
Virtual context document set: V Ds,t = ?;6?
Candidate content word set: Xs,t = ?
;7Steps:8begin9foreach content word xi ?Du do10if Frequency(xi)?
the predefined threshold then11AddTo(xi, Xs,t);12foreach xk ?Xs,t do13foreach sentence Si ?Du do14if xk ?
Si then15F (xSik ) ?
?16{xk, AxkL , AxkR , CxkL , CxkR };AddTo(F (xSik ), vdxk );AddTo(vdxk , V Ds,t);17?
Generate LaSA model ?s,t with Dirichlet distribution on V Ds,t .18end19LDA.
LaSA model ?s,t with Dirichlet distribution isgenerated on the virtual context document set V Ds,tusing the algorithm presented by Blei et al(2003).1 2 3 4 5customer theater company Beijing musicpresident showplace government Hongkong filmsinger courtyard university China artsmanager center community Japan concerteconomist city team Singapore partypoliceman gymnasium enterprise New York Balletreporter airport bank Vienna dancedirector square market America songconsumer park organization Korea banddancer building agency international operaTable 1: Top 10 nouns from 5 randomly selected topicscomputed on the economics and entertainment domainsLaSA model learns the posterior distribution todecompose words and their corresponding virtualcontext documents into topics.
Table 1 lists top 10nouns from a random selection of 5 topics computedon the unlabeled economics and entertainment do-main data.
As shown, words in the same topic arerepresentative nouns.
They actually are grouped intobroad concept sets.
For example, set 1, 3 and 4correspond to nominal person, nominal organizationand location, respectively.
With a large-scale unla-beled corpus, we will have enough words assignedto each topic concept to better approximate the un-derlying semantic association distribution.In LDA-style LaSA model, the topic mixtureis drawn from a conjugate Dirichlet prior that re-mains the same for all the virtual context docu-284ments.
Hence, given a word xi in the corpus, wemay perform posterior inference to determine theconditional distribution of the hidden topic featurevariables associated with xi.
Latent semantic asso-ciation set of xi (denoted by SA(xi)) is generatedusing Algorithm 2.
Here, Multinomial(?s,t(vdxi))refers to sample from the posterior distribution overtopics given a virtual document vdxi .
In the domainadaptation, we do semantic association inference onthe source domain training data using LaSA modelat first, then the original source domain NER modelis tuned on the source domain training data set byincorporating these generated semantic associationfeatures.Algorithm 2: Generate Latent Semantic As-sociation Set of Word xi Using K-topicLaSA ModelInputs:1?
?s,t: LaSA model with multinomial distribution;2?Dirichlet(?
): Dirichlet distribution with parameter ?;3?
xi: Content word;4Outputs:5?
SA(xi): Latent semantic association set of xi ;6Steps:7begin8?
Extract vdxi from the corpus.9?
Draw topic weights ?s,t(vdxi ) from Dirichlet(?);10?
foreach fj in vdxi do11draw a topic zj?
{ 1,...,K} from Multinomial(?s,t(vdxi ));12AddTo(zj , Topics(vdxi ));13?
Rank all the topics in Topics(vdxi );14?
SA(xi)??
top n topics in Topics(vdxi );15end16LaSA model better models latent semantic asso-ciation distribution in the source and the target do-mains.
By grouping words into concepts, we effec-tively overcome the data distribution difference ofboth domains.
Thus, we may reduce the numberof parameters required to model the target domaindata, and improve the quality of the estimated pa-rameters in the domain transfer.
LaSA model ex-tends the traditional bag-of-words topic models tocontext-dependence concept association model.
Ithas potential use for concept grouping.5 ExperimentsWe evaluate LaSA-based domain adaptation methodon both English and Chinese corpus in this section.In the experiments, we focus on recognizing person(PER), location (LOC) and organization (ORG) inthe given four domains, including economics (Eco),entertainment (Ent), politics (Pol) and sports (Spo).5.1 Experimental settingIn the NER domain adaptation, nouns and adjectivesmake a significant impact on the performance.
Thus,we focus on capturing latent semantic associationfor high-frequency nouns and adjectives (i.e.
occur-rence count ?
50 ) in the unlabeled corpus.
LaSAmodels for nouns and adjectives are learned fromthe unlabeled corpus using Algorithm 1 (see section4.2), respectively.
Our empirical study shows thatbetter adaptation is obtained with a 50-topic LaSAmodel.
Therefore, we set the number of topics N as50, and define the context view window size as {-3,3} (i.e.
previous 3 words and next 3 words) in theLaSA model learning.
LaSA features for other irre-spective words (e.g.
token unit ?the?)
are assignedwith a default topic value N+1.All the basic NER models are trained on thedomain-specific training data using RRM classifier(Guo et al, 2005).
RRM is a generalization Winnowlearning algorithm (Zhang et al, 2002).
We set thecontext view window size as {-2,2} in NER.
Given aword instance x, we employ local linguistic features(e.g.
word unit, part of speech) of x and its contextunits ( i.e.
previous 2 words and next 2 words ) inNER.
All Chinese texts in the experiments are auto-matically segmented into words using HMM.In LaSA-based domain adaptation, the semanticassociation features of each unit in the observationwindow {-2,2} are generated by LaSA model at first,then the basic source domain NER model is tuned onthe original source domain training data set by incor-porating the semantic association features.
For ex-ample, given the sentence ?This popular new singerattended the new year party?, Figure 1 illustratesvarious features and views at the current word wi=?singer?
in LaSA-based adaptation.?
Tagging ?Position wi?2 wi?1 wi wi+1 wi+2Word popular new singer attend thePOS adj adj noun verb articleSA SA(popular) SA(new) SA(singer) SA(attend) SA(the).....Tag ti?2 ti?1 tiFigure 1: Feature window in LaSA-based adaptationIn the viewing window at the word ?singer?
(seeFigure 1), each word unit around ?singer?
is codi-fied with a set of primitive features (e.g.
POS, SA,Tag), together with its relative position to ?singer?.285Here, ?SA?
denotes semantic association feature setwhich is generated by LaSA model.
?Tag?
denotesNE tags labeled in the data set.Given the input vector constructed with the abovefeatures, RRM method is then applied to train linearweight vectors, one for each possible class-label.
Inthe decoding stage, the class with the maximum con-fidence is then selected for each token unit.In our evaluation, only NEs with correct bound-aries and correct class labels are considered as thecorrect recognition.
We use the standard Precision(P), Recall (R), and F-measure (F = 2PRP+R ) to mea-sure the performance of NER models.5.2 DataWe built large-scale English and Chinese anno-tated corpus.
English corpus are generated fromwikipedia while Chinese corpus are selected fromChinese newspapers.
Moreover, test data do notoverlap with training data and unlabeled data.5.2.1 Generate English Annotated Corpusfrom WikipediaWikipedia provides a variety of data resources forNER and other NLP research (Richman and Schone,2008).
We generate all the annotated English corpusfrom wikipedia.
With the limitation of efforts, onlyPER NEs in the corpus are automatically tagged us-ing an English person gazetteer.
We automaticallyextract an English Person gazetteer from wikipediaat first.
Then we select the articles from wikipediaand tag them using this gazetteer.In order to build the English Person gazetteerfrom wikipdedia, we manually selected several keyphrases, including ?births?, ?deaths?, ?surname?,?given names?
and ?human names?
at first.
Foreach article title of interest, we extracted the cate-gories to which that entry was assigned.
The en-try is considered as a person name if its relatedexplicit category links contain any one of the keyphrases, such as ?Category: human names?.
We to-tally extracted 25,219 person name candidates from204,882 wikipedia articles.
And we expanded thisgazetteer by adding the other available commonperson names.
Finally, we obtained a large-scalegazetteer of 51,253 person names.All the articles selected from wikipedia are furthertagged using the above large-scale gazetteer.
Sincehuman annotated set were not available, we held outmore than 100,000 words of text from the automat-ically tagged corpus to as a test set in each domain.Table 2 shows the data distribution of the trainingand test data sets.Domains Training Data Set Test Data SetSize PERs Size PERsPol 0.45M 9,383 0.23M 6,067Eco 1.06M 21,023 0.34M 6,951Spo 0.47M 17,727 0.20M 6,075Ent 0.36M 12,821 0.15M 5,395Table 2: English training and test data setsWe also randomly select 17M unlabeled Englishdata (see Table 3) from Wikipedia.
These unlabeleddata are used to build the English LaSA model.All DomainPol Eco Spo EntData Size(M) 17.06 7.36 2.59 3.65 3.46Table 3: Domain distribution in the unlabeled Englishdata set5.2.2 Chinese DataWe built a large-scale high-quality Chinese NEannotated corpus.
All the data are news articles fromseveral Chinese newspapers in 2001 and 2002.
Allthe NEs (i.e.
PER, LOC and ORG ) in the corpus aremanually tagged.
Cross-validation checking is em-ployed to ensure the quality of the annotated corpus.Domain Size NEs in the training data set(M) PER ORG LOC TotalPol 0.90 11,388 6,618 14,350 32,356Eco 1.40 6,821 18,827 14,332 39,980Spo 0.60 11,647 8,105 7,468 27,220Ent 0.60 12,954 2,823 4,665 20,442Domain Size NEs in the test data set(M) PER ORG LOC TotalPol 0.20 2,470 1,528 2,540 6,538Eco 0.26 1,098 2,971 2,362 6,431Spo 0.10 1,802 1,323 1,246 4,371Ent 0.10 2,458 526 738 3,722Table 4: Chinese training and test data setsAll the domain-specific training and test data areselected from this annotated corpus according to thedomain categories (see Table 4).
8.46M unlabeledChinese data (see Table 5) are randomly selectedfrom this corpus to build the Chinese LaSA model.5.3 Experimental ResultsAll the experiments are conducted on the abovelarge-scale English and Chinese corpus.
The overallperformance enhancement of NER by LaSA-based286All DomainPol Eco Spo EntData Size(M) 8.46 2.34 1.99 2.08 2.05Table 5: Domain distribution in the unlabeled Chinesedata setdomain adaptation is evaluated at first.
Since thedistribution of each NE type is different across do-mains, we also analyze the performance enhance-ment on each entity type by LaSA-based adaptation.5.3.1 Performance Enhancement of NER byLaSA-based Domain AdaptationTable 6 and 7 show the experimental results forall pairs of domain adaptation on both English andChinese corpus, respectively.
In the experiment,the basic source domain NER model Ms is learnedfrom the specific domain training data set Ddom(see Table 2 and 4 in Section 5.2).
Here, dom ?
{Eco,Ent, Pol, Spo}.
F indom denotes the top-lineF-measure of Ms in the source trained domain dom.When Ms is directly applied in a new target do-main, its F-measure in this basic transfer is consid-ered as baseline (denoted by FBase).
FLaSA de-notes F-measure of Ms achieved in the target do-main with LaSA-based domain adaptation.
?
(F ) =FLaSA?FBaseFBase , which denotes the relative F-measureenhancement by LaSA-based domain adaptation.Source ?
Performance in the domain transferTargetFBase FLaSA ?
(F ) ?
(loss) FTopEco?Ent 57.61% 59.22% +2.79% 17.87% F inEnt=66.62%Pol?Ent 57.5 % 59.83% +4.05% 25.55% F inEnt=66.62%Spo?Ent 58.66% 62.46% +6.48% 47.74% F inEnt=66.62%Ent?Eco 70.56 % 72.46% +2.69% 19.33% F inEco=80.39%Pol?Eco 63.62% 68.1% +7.04% 26.71% F inEco=80.39%Spo?Eco 70.35% 72.85% +3.55% 24.90% F inEco=80.39%Eco?Pol 50.59% 52.7% +4.17% 15.81% F inPol=63.94%Ent?Pol 56.12% 59.82% +6.59% 47.31% F inPol=63.94%Spo?Pol 60.22% 62.6% +3.95% 63.98% F inPol=63.94%Eco?Spo 60.28% 61.21% +1.54% 9.93% F inSpo=69.65%Ent?Spo 60.28% 62.68% +3.98% 25.61% F inSpo=69.65%Pol?Spo 56.94% 60.48% +6.22% 27.85% F inSpo=69.65%Table 6: Experimental results on English corpusExperimental results on English and Chinese cor-pus indicate that the performance of Ms signifi-cantly degrades in each basic domain transfer with-out using LaSA model (see Table 6 and 7).
For ex-ample, in the ?Eco?Ent?
transfer on Chinese cor-pus (see Table 7), F ineco of Ms is 82.28% while FBaseof Ms is 60.45% in the entertainment domain.
F-measure of Ms significantly degrades by 21.83 per-Source ?
Performance in the domain transferTargetFBase FLaSA ?
(F ) ?
(loss) FTopEco?Ent 60.45% 66.42% +9.88% 26.29% F inEnt=83.16%Pol?Ent 69.89% 73.07% +4.55% 23.96% F inEnt =83.16%Spo?Ent 68.66% 70.89% +3.25% 15.38% F inEnt =83.16%Ent?Eco 58.50% 61.35% + 4.87% 11.98% F inEco=82.28%Pol?Eco 62.89% 64.93% +3.24% 10.52% F inEco=82.28%Spo?Eco 60.44% 63.20% + 4.57 % 12.64% F inEco=82.28%Eco?Pol 67.03% 70.90 % +5.77% 27.78% F inPol=80.96%Ent?Pol 66.64 % 68.94 % +3.45% 16.06% F inPol=80.96%Spo?Pol 65.40% 67.20% +2.75% 11.57% F inPol=80.96%Eco?Spo 67.20% 70.77% +5.31% 15.47% F inSpo=90.24%Ent?Spo 70.05% 72.20% +3.07% 10.64% F inSpo=90.24%Pol?Spo 70.99% 73.86% +4.04% 14.91% F inSpo=90.24%Table 7: Experimental results on Chinese corpuscent points in this basic transfer.
Significant perfor-mance degrading of Ms is observed in all the basictransfer.
It shows that the data distribution of bothdomains is very different in each possible transfer.Experimental results on English corpus show thatLaSA-based adaptation effectively enhances the per-formance in each domain transfer (see Table 6).For example, in the ?Pol?Eco?
transfer, FBase is63.62% while FLaSA achieves 68.10%.
Comparedwith FBase, LaSA-based method significantly en-hances F-measure by 7.04%.
We perform t-tests onF-measure of all the comparison experiments on En-glish corpus.
The p-value is 2.44E-06, which showsthat the improvement is statistically significant.Table 6 also gives the accuracy loss due to transferin each domain adaptation on English corpus.
Theaccuracy loss is defined as loss = 1 ?
FF indom .
Andthe relative reduction in error is defined as ?
(loss)=|1 ?
lossLaSAlossBase |.
Experimental results indicate thatthe relative reduction in error is above 9.93% withLaSA-based transfer in each test on English cor-pus.
LaSA model significantly decreases the ac-curacy loss by 29.38% in average.
Especially for?Spo?Pol?
transfer, ?
(loss) achieves 63.98% withLaSA-based adaptation.
All the above results showthat LaSA-based adaptation significantly reduces theaccuracy loss in the domain transfer for EnglishNER without any labeled target domain samples.Experimental results on Chinese corpus also showthat LaSA-based adaptation effectively increases theaccuracy in all the tests (see Table 7).
For example,in the ?Eco?Ent?
transfer, compared with FBase,LaSA-based adaptation significantly increases F-measure by 9.88%.
We also perform t-tests on F-287measure of 12 comparison experiments on Chinesecorpus.
The p-value is 1.99E-06, which shows thatthe enhancement is statistically significant.
More-over, the relative reduction in error is above 10%with LaSA-based method in each test.
LaSA modeldecreases the accuracy loss by 16.43% in average.Especially for the ?Eco?Ent?
transfer (see Table 7),?
(loss) achieves 26.29% with LaSA-based method.All the above experimental results on English andChinese corpus show that LaSA-based domain adap-tation significantly decreases the accuracy loss in thetransfer without any labeled target domain data.
Al-though automatically tagging introduced some er-rors in English source training data, the relative re-duction in errors in English NER adaptation seemscomparable to that one in Chinese NER adaptation.5.3.2 Accuracy Enhancement for Each NEType RecognitionOur statistic data (Guo et al, 2006) show that thedistribution of NE types varies with domains.
EachNE type has different domain features.
Thus, theperformance stability of each NE type recognition isvery important in the domain transfer.Figure 2 gives F-measure of each NE type recog-nition achieved by LaSA-based adaptation on En-glish and Chinese corpus.
Experimental resultsshow that LaSA-based adaptation effectively in-creases the accuracy of each NE type recognition inthe most of the domain transfer tests.
We performt-tests on F-measure of the comparison experimentson each NE type, respectively.
All the p-value isless than 0.01, which shows that the improvementon each NE type recognition is statistically signifi-cant.
Especially, the p-value of English and ChinesePER is 2.44E-06 and 9.43E-05, respectively, whichshows that the improvement on PER recognition isvery significant.
For example, in the ?Eco?Pol?transfer on Chinese corpus, compared with FBase,LaSA-based adaptation enhances F-measure of PERrecognition by 9.53 percent points.
Performance en-hancement for ORG recognition is less than that onefor PER and LOC recognition using LaSA modelsince ORG NEs usually contain much more domain-specific information than PER and LOC.The major reason for error reduction is that exter-nal context and internal units are better semanticallyassociated using LaSA model.
For example, LaSAFigure 2: PER, LOC and ORG recognition in the transfermodel better groups various titles from different do-mains (see Table 1 in Section 4.2).
Various industryterms in ORG NEs are also grouped into the seman-tic sets.
These semantic associations provide usefulhints for detecting the boundary of NEs in the newtarget domain.
All the above results show that LaSAmodel better compensates for the feature distributiondifference of each NE type across domains.6 ConclusionWe present a domain adaptation method with LaSAmodel in this paper.
LaSA model captures latent se-mantic association among words from the unlabeledcorpus.
It better groups words into a set of conceptsaccording to the related context snippets.
LaSA-based domain adaptation method projects words toa low-dimension concept feature space in the trans-fer.
It effectively overcomes the data distribution gapacross domains without using any labeled target do-main data.
Experimental results on English and Chi-nese corpus show that LaSA-based domain adapta-tion significantly enhances the performance of NERacross domains.
Especially, LaSA model effectivelyincreases the accuracy of each NE type recogni-tion in the domain transfer.
Moreover, LaSA-baseddomain adaptation method works well across lan-guages.
To further reduce the accuracy loss, we willexplore informative sampling to capture fine-graineddata difference in the domain transfer.ReferencesRie Ando and Tong Zhang.
2005.
A Framework forLearning Predictive Structures from Multiple Tasks288and Unlabeled Data.
In Journal of Machine LearningResearch 6 (2005), pages 1817?1853.Andrew Arnold, Ramesh Nallapati, and William W. Co-hen.
2008.
Exploiting Feature Hierarchy for Trans-fer Learning in Named Entity Recognition.
In Pro-ceedings of 46th Annual Meeting of the Association ofComputational Linguistics (ACL?08), pages 245-253.David Blei, Andrew Ng, and Michael Jordan.
2003.
La-tent Dirichlet Allocation.
Journal of Machine Learn-ing Research, 3:993?1022.John Blitzer, Ryan McDonald, and Fernando Pereira.2006.
Domain Adaptation with Structural Correspon-dence Learning.
In Proceedings of the 2006 Confer-ence on Empirical Methods in Natural Language Pro-cessing (EMNLP 2006), pages 120-128.John Blitzer, Mark Dredze, and Fernando Pereira.
2007.Biographies, Bollywood, Boom-boxes and Blenders:Domain Adaptation for Sentiment Classification.
InProceedings of the 45th Annual Meeting of the Asso-ciation of Computational Linguistics (ACL?07), pages440-447.Andrew Borthwick.
1999.
A Maximum Entropy Ap-proach to Named Entity Recognition.
Ph.D. thesis,New York University.Yee Seng Chan and Hwee Tou Ng.
2007.
Domain Adap-tation with Active Learning for Word Sense Disam-biguation.
In Proceedings of the 45th Annual Meet-ing of the Association of Computational Linguistics(ACL?07).Ciprian Chelba and Alex Acero.
2004.
Adaptation ofmaximum entropy capitalizer: Little data can help alot.
In Proceedings of the 2004 Conference on Empir-ical Methods in Natural Language Processing.Kenneth Ward Church and Patrick Hanks.
1990.
Wordassociation norms, mutual information and lexicogra-phy.
Computational Linguistics, 16(1):22?29.Hal Daume III.
2007.
Frustratingly Easy Domain Adap-tation.
In Proceedings of the 45th Annual Meeting ofthe Association of Computational Linguistics.Hal Daume III and Daniel Marcu.
2006.
Domain adap-tation for statistical classifiers.
Journal of ArtificialIntelligence Research, 26:101?126.Scott Deerwester, Susan T. Dumais, and Richard Harsh-man.
1990.
Indexing by latent semantic analysis.Journal of the American Society for Information Sci-ence, 41(6):391?407.Radu Florian, Abe Ittycheriah, Hongyan Jing, and TongZhang.
2003.
Named entity recogintion through clas-sifier combination.
In Proceedings of the 2003 Confer-ence on Computational Natural Language Learning.Freitag.
2004.
Trained Named Entity Recognition UsingDistributional Clusters.
In Proceedings of the 2004Conference on Empirical Methods in Natural Lan-guage Processing (EMNLP 2004).Scott Miller, Jethran Guinness, and Alex Zamanian.2004.
Name Tagging with Word Clusters and Discrim-inative Training.
In Proceedings of HLT-NAACL 04.Jianfeng Gao, Mu Li, Anndy Wu, and Changning Huang.2005.
Chinese Word Segmentation and Named EntityRecognition: A Pragmatic Approach.
ComputationalLinguisitc, 31(4):531?574.Honglei Guo, Jianmin Jiang, Gang Hu, and Tong Zhang.2005.
Chinese Named Entity Recognition Based onMultilevel Linguistic Features.
In Lecture Notes in Ar-tificial Intelligence, 3248:90?99.Honglei Guo, Li Zhang, and Zhong Su.
2006.
EmpiricalStudy on the Performance Stability of Named EntityRecognition Model across Domains.
In Proceedingsof the 2006 Conference on Empirical Methods in Nat-ural Language Processing (EMNLP 2006), pages 509-516.Thomas Hofmann.
1999.
Probabilistic latent semanticindexing.
In Proceedings of the 22th Annual Inter-national SIGIR Conference on Research and Develop-ment in Information Retrieval (SIGIR?99).Jing Jiang and ChengXiang Zhai.
2006.
Exploiting Do-main Structure for Named Entity Recognition.
In Pro-ceedings of HLT-NAACL 2006, pages 74?81.Jing Jiang and ChengXiang Zhai.
2007.
InstanceWeighting for Domain Adaptation in NLP.
In Pro-ceedings of the 45th Annual Meeting of the Associ-ation of Computational Linguistics (ACL?07), pages264?271.Wei Li and Andrew McCallum.
2005.
Semi-supervisedsequence modeling with syntactic topic models.
InProceedings of Twenty AAAI Conference on ArtificialIntelligence (AAAI-05).Alexander E. Richman and Patrick Schone.
2008.
Min-ing Wiki Resources for Multilingual Named EntityRecognition.
In Proceedings of the 46th Annual Meet-ing of the Association of Computational Linguistics.Brian Roark and Michiel Bacchiani.
2003.
Supervisedand unsupervised PCFG adaptation to novel domains.In Proceedings of the 2003 Human Language Technol-ogy Conference of the North American Chapter of theAssociation for Computational Linguistics.Erik F. Tjong Kim Sang and Fien De Meulder.
2003.Introduction to the conll-2003 shared task: Languageindependent named entity recognition.
In Proceed-ings of the 2003 Conference on Computational NaturalLanguage Learning (CoNLL-2003), pages 142?147.Xing Wei and Bruce Croft.
2006.
LDA-based documentmodels for ad-hoc retrieval.
In Proceedings of the 29thAnnual International SIGIR Conference on Researchand Development in Information Retrieval.Tong Zhang, Fred Damerau, and David Johnson.
2002Text chunking based on a generalization of Winnow.Journal of Machine Learning Research, 2:615?637.289
