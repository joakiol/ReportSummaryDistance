Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 1262?1267,Denver, Colorado, May 31 ?
June 5, 2015.c?2015 Association for Computational LinguisticsClustering Sentences with Density Peaks for Multi-documentSummarizationYang ZhangShenzhen Graduate SchoolPeking University, Chinaecezhangy@sz.pku.edu.cnYunqing XiaDept.
of Comp.
Sci.
and Tech.Tsinghua University, Chinayqxia@tsinghua.edu.cnYi LiuIMSL, PKU-HKUST ShenzhenHong Kong Institution, Chinayi.liu@imsl.org.cnWenmin WangShenzhen Graduate SchoolPeking University, Chinawangwm@ece.pku.edu.cnAbstractMulti-document Summarization (MDS) is ofgreat value to many real world applications.Many scoring models are proposed to selectappropriate sentences from documents to formthe summary, in which the clustering-basedmethods are popular.
In this work, we proposea unified sentence scoring model which mea-sures representativeness and diversity at thesame time.
Experimental results on DUC04demonstrate that our MDS method outper-forms the DUC04 best method and the ex-isting clustering-based methods, and it yieldsclose results compared to the state-of-the-artgeneric MDS methods.
Advantages of theproposed MDS method are two-fold: (1) Thedensity peaks clustering algorithm is firstlyadopted, which is effective and fast.
(2)No external resources such as Wordnet andWikipedia or complex language parsing al-gorithms is used, making reproduction anddeployment very easy in real environment.1 IntroductionDocument summarization is the process of gener-ating a generic or topic-focused summary by re-ducing documents in size while retaining the maincharacteristics of original documents(Wang et al,2011).
The summary may be formed in a varietyof different ways, which are generally categorizedas abstractive and extractive(Shen et al, 2007).
Inthis paper, we address the problem of generic multi-document summarization (MDS).
An effective sum-marization method should properly consider the fol-lowing three important issues: representativeness,diversity, conciseness.Many scoring models are proposed to select ap-propriate sentences from documents to form thesummary, in which the clustering-based methodsare popular.
Some researchers address the sentencescoring task in an isolation manner(Radev et al,2004; Wang et al, 2008; Wan and Yang, 2008)(i.e., clustering and ranking are two independentsteps).
Others handle the sentence ranking task ina mutuality manner(Cai and Li, 2013; Cai et al,2010; Wang et al, 2011) (i.e., clustering improvesranking and vice versa).
Two drawbacks of theexisting clustering-based methods are worth noting.First, extra algorithms are required to determine thenumber of clusters beforehand.
Second, models arerequired to rank or score sentences within and acrossthe clusters after clustering.Our proposed MDS method is inspired by therecent work on density peaks clustering (DPC) al-gorithm published on Science (Rodriguez and Laio,2014).
The underlying assumption is that clus-ter centers are characterized by a higher densitythan their neighbors and by a relatively large dis-tance from points with higher densities.
In thispaper, we adapt the density peaks clustering algo-rithm(Rodriguez and Laio, 2014) to simultaneouslycluster sentences and rank them in the mutualitymanner.
Thanks to the density peaks clusteringalgorithm, we do not need to set the number ofclusters and do not need a post-processing moduleto reduce redundancy.
From the view of summa-rization task, DPC is superior to other clusteringmethods because it can not only find the best clustercenters, but also do rank all data points, including1262cluster centers, within and across clusters at thesame time.
Experimental results on the DUC2004demonstrate that our method outperforms the bestmethod in DUC04 and yields close results comparedto the state-of-the-art unsupervised MDS methods.The major contributions of this work are two-fold: Firstly, a unified sentence scoring model isproposed to consider representativeness, diversityand conciseness at the same time.
Secondly, thedensity peaks clustering algorithm is first appliedin the MDS task.
We further revise the clusteringalgorithm to address the summary length constraint.2 Related WorkA vast number of methods are reported in litera-tures on MDS.
The MDS methods can be generallycategorized into abstractive and extractive.
Theextractive MDS can be also categorised into super-vised and unsupervised.
Several supervised learningmethods have been developed for training accuratemodel for extract-based summarization.
The unsu-pervised methods, on the other hand, also contributea lot to MDS.
In this work, we put our contributionsin context of the sentence ranking-based extractiveMDS under the unsupervised framework.Several clustering-based MDS methods have alsobeen proposed.
For example, ClusterHITS is pro-posed to incorporate the cluster-level informationinto the process of sentence ranking(Wan and Yang,2008).
RankClus is proposed to update sentenceranking and clustering interactively and iterativelywith frequency relationships between two sentences,or sentences and terms (Cai et al, 2010).
Somekinds of matrix factorization methods are also ex-plored in MDS methods(Gong and Liu, 2001; Leeet al, 2009; Wang et al, 2008; Wang et al, 2011;Shen et al, 2011).
For example, matrix factorizationmethods is adopted to generate sentence clusters,in which non-negative factorization is performed onthe term-document matrix using the term-sentencematrix as the base so that the document-topic andsentence-topic matrices could be constructed(Wanget al, 2008).We follow the idea of clustering-based sentenceranking.
Different from the previous work, weattempt to design a unified sentence scoring modelto rank sentences and reduce redundancy at the sametime.3 MethodIn this work, the density peaks sentence clustering(DPSC) method is designed for multi-documentsummarization.3.1 Density Peaks Sentence ClusteringThe density peaks clustering (DPC) algorithm isachieved upon the object similarity matrix.
Ob-jects are finally assigned density values and mini-distance values.
In this work, we consider sentencesas objects and follow the framework to calculaterepresentativeness score and diversity score of eachsentence in a unified model.To construct the sentence similarity matrix forthe DPC algorithm, we first segment documentsinto sentences and remove the non-stop words inthe sentences.
We then represent the sentencesusing bag-of-words vector space model, thus thecosine equation is applicable to calculate sentencesimilarity.
The terms can be weighted with differentschemes such as boolean (occurring or not), tf (ter-m frequency) and tf ?
isf (term frequency inversesentence frequency).
We finally choose the booleanscheme in our experiments because it performs bestin our empirical study.3.2 Representativeness ScoringFor document summarization, we need a represen-tative score to quantify the degree how much asentence is important in the documents.
Enlightenedby the DPC algorithm, we assume that when asentence has more similar sentences (i.e., higherdensity), it will be considered more important ormore representative.
Thus we define the followingfunction to calculate the representativeness scoresREP(i) for each sentence si:sREP(i) =1KK?j=1,j 6=i?(simij?
?
), (1)?
(x) ={1 if x > 00 otherwise(2)where simijdenotes the similarity value betweenthe i-th and j-th sentence, and K denotes the num-ber of sentences in the datasets.
?
denotes a prede-1263fined density threshold.
Note that we set the densitythreshold following (Rodriguez and Laio, 2014),which attempts to exclude the sentences holdinglower similarity with the current sentence.3.3 Diversity ScoringMost of the previous work handles diversity viareduce redundancy in a post processing module afterthe sentences are ranked.
In this work, we measurediversity in the ranking model.Diversity score of a sentence is measured by com-puting the minimum distance between the sentencesiand any other sentences with higher density score.In order to reflect the above observation, we de-fine the following function to calculate the diversityscore sDIV(i):sDIV(i) = 1?
maxj:sREP(j)>sREP(i)simij.
(3)For the sentence with the highest density, weconventionally takesDIV(i) = 1?minj 6=isimij.
(4)The proposed diversity score looks similar tothe famous Maximum Marginal Relevance (MMR)(Carbonell and Goldstein, 1998), which is widelyused in removing redundancy by using a greedyalgorithm to remove sentences that are too similarto the already selected ones.
The difference lies thatMMR selects a sentence by comparing it to thoseselected sentences while we compare it to all theother sentences in the dataset, thus it can enhancethe diversity globally.3.4 Length ScoringIt is widely accepted that summarization task hasan important constraint, i.e., summary length.
Inorder to satisfy this constraint, the length of selectedsentences should be as short as possible.
Based onthis analysis, we propose the length score, whichhas relationship with the effective length and reallength.
The real length is defined as the number ofword occurrences that a sentence contains.
We thendefine the effective length as how many unique non-stop terms a sentence contains.
We finally definethe following function to calculate the length scoresLEN(i).The motivation to propose the length score is,shorter sentences with better representativeness s-core and diversity score are more favorable for the fi-nal summaries.
Furthermore, as we use the Booleanscheme to measure sentence similarity, we onlycount unique words as effective sentence length.sLEN(i) =el(si)maxKj=1el(sj)?
log(maxKj=1rl(sj))rl(si),(5)where el(si) returns the effective length of sentencesi, and rl(si) the real length of sentence si.3.5 Unified Sentence ScoringNow we integrate representativeness score, diversityscore and length score in the following unifiedsentence scoring function:sDPSC(i) = sREP(i)?
sDIV(i)?
sLEN(i).
(6)The assumption is obviously that we need thosesentences which are as representative, diversifiedas possible and contain unique terms as many aspossible within a limited length.In calculation, we simply apply logarithm since:sDPSC(i) ?
log sREP(i) + log sDIV(i) + log sLEN(i)(7)3.6 Summary GenerationAs three scores above including the representative-ness, diversity and length constraint are measuredin a unified sentence scoring model, generating asummary with out method is basically achieved byselecting the higher ranking sentences.
In otherwords, our summary contains more representativeand diversified information in the limited length.Complexity Analysis: Suppose K is the totalnumber of sentences in the document collection.The complexity in calculating the sentence sim-ilarity matrix is O(K2).
As the complexity inthe function of representativeness scoring, diversityscoring and length scoring are all O(K), the totaltime complexity of our DPSC method is O(K2) +O(K) +O(K) ?
O(K2).12644 EvaluationTwo experiments are reported in this paper:comparing the MDS methods and tuning thedensity threshold.
For both experiments, we usethe DUC2004(task 2)1dataset, which is annotatedmanually for generic MDS.
We adopted ROUGE(Lin, 2004) version 1.5.52and take F-measure ofROUGE-1, ROUGE-2 and ROUGE-SU as ourevaluation metrics.
In pre-processing, we use thePorter Stemmer3in sentence segmenting, stop-wordremoving and word stemming.
Note that our MDSmethod is purely unsupervised, and uses no trainingor development data.4.1 The MDS MethodsWe selected three categories of baselines4:(1) DUC04 MDS methods: DUC04Best (Conroyet al, 2004).
(2) Clustering-based MDS methods: Centroid(Radev et al, 2004), ClusterHITS (Wan and Yang,2008), SNMF (Wang et al, 2008), RTC (Cai andLi, 2013), FGB (Wang et al, 2011), and AASum(Canhasi and Kononenko, 2013).
(3) Other state-of-the-art MDS methods: LexRank(graph-based method) (Erkan and Radev, 2004),CSFO (optimization-oriented method) (Lin andBilmes, 2011) and WCS (aggregation-orientedmethod) (Wang and Li, 2012).For our DPSC method, we adopt the followingsettings: (1) Density threshold is set 0.22 as it isempirically found as optimal in Section 4.2 in theDUC04 dataset.
(2) Term weighting scheme is setBoolean.
In our experiments, Boolean is foundoutperforming tf and tfisf in sentence representa-tion, this is because term repetition happens lessfrequently in short text units like sentences than thatin documents.
Experimental results of the MDSmethods are presented in Table 1.
Note the ROUGEvalues of some MDS methods are not reported in theliteratures and marked with??
?in Table 1.According to Table 1, DPSC outperformsDUC04Best, which ignores the cross-sentenceinformation to solve the diversity problem.
DPSC1http://duc.nist.gov/duc2004/tasks.html2Options used: -a -c 95 -b 665 -m -n 4 -w 1.23http://tartarus.org/martin/PorterStemmer/4Interested readers can refer to details in the references.Table 1: Experimental results of the MDS methods onDUC04.System ROUGE-1 ROUGE-2 ROUGE-SUDUC04Best 0.38224 0.09216 0.13233Centroid 0.36728 0.07379 0.12511ClusterHITS 0.36463 0.07632 ?SNMF ?
0.08400 0.12660RTC 0.37475 0.08973 ?FGB 0.38724 0.08115 0.12957AASum 0.41150 0.09340 0.13760LexRank 0.37842 0.08572 0.13097CSFO 0.38900 ?
?WCS 0.39872 0.09611 0.13532DPSC 0.39075 0.09376 0.14000outperforms most clustering-based methods exceptfor AASum, which performs slightly better thanDPSC on ROUGE-1.
AASum is a very complexMDS method which fully exploits the advantages ofclustering and the flexibility of matrix factorization.A weakness of the approach is that the numberof archetypes must be predefined, and a post-processing module is required to reduce redundancy(Canhasi and Kononenko, 2013).DPSC also outperforms LexRank and CSFO, andyields close results compared with WCS.
Accordingto Table 1, DPSC performs slightly worse than WCS.The marginal performance gain of WCS comes fromthe aggregation strategy, namely, multiple MDSsystems are required.
As a comparison, DPSC isa pure and simple MDS method, exhibiting muchlower complexity.DPSC method is also advantageous on usability,because it does not involve any external resourcessuch as Wordnet and Wikipedia or very complexnatural language processing algorithms such as sen-tence parsing.
Moreover, DPSC is a very fast MDSmethod.
Thus it can be easily reproduced anddeployed in real environment.4.2 Density ThresholdFollowing (Rodriguez and Laio, 2014), we designan experiment on DUC04 dataset to investigate howthe density threshold influences quality of the sum-maries.
We tune the density threshold by varying itfrom 0.10 to 0.40(see the X-axis in Figure 1).Figure 1 shows that on the specific dataset (i.e.,DUC04), DPSC reaches the best ROUGE score12650.10 0.15 0.20 0.25 0.30 0.35 0.40Density threshold0.3550.3600.3650.3700.3750.3800.3850.3900.395ROUGE-10.10 0.15 0.20 0.25 0.30 0.35 0.40Density threshold0.0750.0800.0850.0900.0950.100ROUGE-20.10 0.15 0.20 0.25 0.30 0.35 0.40Density threshold0.1150.1200.1250.1300.1350.140ROUGE-SUFigure 1: ROUGE curves of DPSC method varying the density threshold.when the density threshold is set around 0.22 whilestarts to drop significantly after 0.30.
This indicatesthat 0.22 is a good setting for the density thresholdon DUC04.5 Conclusion and Future WorkIn this paper we report the density peaks sentenceclustering (DPSC) method for multi-document sum-marization.
Different from the prior work whichdeals with representativeness and redundancy in-dependently, a unified sentence scoring model isdesigned in DPSC to combine the representative-ness score, the diversity score and the length s-core of each sentence.
Experimental results onDUC04 dataset show that DPSC outperforms theDUC04 best method and the existing clustering-based methods.
Meanwhile, it yields close resultswhen compared with the state-of-the-art genericMDS methods.
It is thus verified that densitypeaks clustering algorithm is able to handle MDSeffectively.However, this work is still preliminary.
Wewill study semantic text similarity to improve thesentence similarity matrix.
We will then apply theproposed method in query-based multi-documentsummarization.AcknowledgementThis work is partially supported by NaturalScience Foundation of China (61272233,61373056, 61433018) and Shenzhen PeacockScheme(183003656).
We thank the reviewers forthe insightful comments.ReferencesXiaoyan Cai and Wenjie Li.
2013.
Ranking throughclustering: An integrated approach to multi-documentsummarization.
Audio, Speech, and LanguageProcessing, IEEE Transactions on, 21(7):1424?1433.Xiaoyan Cai, Wenjie Li, You Ouyang, and HongYan.
2010.
Simultaneous ranking and clusteringof sentences: a reinforcement approach to multi-document summarization.
In Proceedings of the 23rdInternational Conference on Computational Linguis-tics, pages 134?142.
Association for ComputationalLinguistics.Ercan Canhasi and Igor Kononenko.
2013.
Multi-document summarization via archetypal analysis ofthe content-graph joint model.
Knowledge andInformation Systems, pages 1?22.Jaime Carbonell and Jade Goldstein.
1998.
The use ofmmr, diversity-based reranking for reordering docu-ments and producing summaries.
In Proceedings ofthe 21st annual international ACM SIGIR conferenceon Research and development in information retrieval,pages 335?336.
ACM.John M Conroy, Judith D Schlesinger, Jade Goldstein,and Dianne P Oleary.
2004.
Left-brain/right-brainmulti-document summarization.
In Proceedings of theDocument Understanding Conference (DUC 2004).G?unes Erkan and Dragomir R Radev.
2004.
Lexrank:Graph-based lexical centrality as salience in textsummarization.
J. Artif.
Intell.
Res.
(JAIR), 22(1):457?479.Yihong Gong and Xin Liu.
2001.
Generic textsummarization using relevance measure and latentsemantic analysis.
In Proceedings of the 24th annualinternational ACM SIGIR conference on Research anddevelopment in information retrieval, pages 19?25.ACM.Ju-Hong Lee, Sun Park, Chan-Min Ahn, and Daeho Kim.2009.
Automatic generic document summarization1266based on non-negative matrix factorization.
Informa-tion Processing & Management, 45(1):20?34.Hui Lin and Jeff Bilmes.
2011.
A class ofsubmodular functions for document summarization.In Proceedings of the 49th Annual Meeting of theAssociation for Computational Linguistics: HumanLanguage Technologies-Volume 1, pages 510?520.Association for Computational Linguistics.Chin-Yew Lin.
2004.
Rouge: A package for automaticevaluation of summaries.
In Text SummarizationBranches Out: Proceedings of the ACL-04 Workshop,pages 74?81.Dragomir R Radev, Hongyan Jing, Ma?gorzata Sty?s, andDaniel Tam.
2004.
Centroid-based summarizationof multiple documents.
Information Processing &Management, 40(6):919?938.Alex Rodriguez and Alessandro Laio.
2014.
Clusteringby fast search and find of density peaks.
Science,344(6191):1492?1496.Dou Shen, Jian-Tao Sun, Hua Li, Qiang Yang, andZheng Chen.
2007.
Document summarization usingconditional random fields.
In IJCAI, volume 7, pages2862?2867.Chao Shen, Tao Li, and Chris HQ Ding.
2011.
Integrat-ing clustering and multi-document summarization bybi-mixture probabilistic latent semantic analysis (plsa)with sentence bases.
In AAAI.Xiaojun Wan and Jianwu Yang.
2008.
Multi-documentsummarization using cluster-based link analysis.
InProceedings of the 31st annual international ACMSIGIR conference on Research and development ininformation retrieval, pages 299?306.
ACM.Dingding Wang and Tao Li.
2012.
Weighted consensusmulti-document summarization.
Information Process-ing & Management, 48(3):513?523.Dingding Wang, Tao Li, Shenghuo Zhu, and ChrisDing.
2008.
Multi-document summarizationvia sentence-level semantic analysis and symmetricmatrix factorization.
In Proceedings of the 31st annualinternational ACM SIGIR conference on Research anddevelopment in information retrieval, pages 307?314.ACM.Dingding Wang, Shenghuo Zhu, Tao Li, Yun Chi,and Yihong Gong.
2011.
Integrating documentclustering and multidocument summarization.
ACMTransactions on Knowledge Discovery from Data(TKDD), 5(3):14.1267
