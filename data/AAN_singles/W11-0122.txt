The People?s Web meets Linguistic Knowledge:Automatic Sense Alignment of Wikipedia and WordNetElisabeth Niemann and Iryna GurevychUbiquitous Knowledge Processing LabTechnische Universita?t DarmstadtHochschulstra?e 10D-64289 Darmstadt, Germanyhttp://www.ukp.tu-darmstadt.deAbstractWe propose a method to automatically alignWordNet synsets andWikipedia articles to obtain a senseinventory of higher coverage and quality.
For eachWordNet synset, we first extract a set of Wikipediaarticles as alignment candidates; in a second step, we determine which article (if any) is a validalignment, i.e.
is about the same sense or concept.
In this paper, we go significantly beyond state-of-the-art word overlap approaches, and apply a threshold-based Personalized PageRank method forthe disambiguation step.
We show that WordNet synsets can be aligned to Wikipedia articles with aperformance of up to 0.78 F1-Measure based on a comprehensive, well-balanced reference datasetconsisting of 1,815 manually annotated sense alignment candidates.
The fully-aligned resource aswell as the reference dataset is publicly available.11 IntroductionLexical semantic resources often used as sense inventories are a prerequisite in automatic processing ofhuman language.
In the last few years, there has been a rise in research aligning different resources toovercome the knowledge acquisition bottleneck and coverage problems pertinent to any single resource.In this paper, we address the task of aligning WordNet noun synsets and Wikipedia articles to obtain asense inventory of higher coverage and quality.
WordNet, a lexical database for English, is extensivelyused in the NLP community and is a de-facto standard resource in many NLP tasks, especially in currentWSD research (Fellbaum, 1998).
WordNet?s manually defined comprehensive taxonomymotivates manyresearchers to utilize it.
However, as WordNet is maintained by only a small group of experts, it is hard tocope with neologisms, named entities, or rare usages on a large scale (Agirre and Edmonds, 2006; Meyerand Gurevych, 2010).
In order to compensate for WordNet?s lack of coverage, Wikipedia has turnedout to be a valuable resource in the NLP community.
Wikipedia has the advantage of being constantlyupdated by thousands of voluntary contributors.
It is multilingual and freely available containing atremendous amount of encyclopedic knowledge enriched with hyperlink information.In the past, researchers have explored the alignment of Wikipedia categories and WordNet synsets (e.g.,Toral et al (2008); Ponzetto and Navigli (2009)).
However, using the categories instead of the articlescauses three limitations: First, the number of Wikipedia categories (about 0.5 million in the Englishedition) is much smaller compared to the number of articles (about 3.35 million).
Secondly, the categorysystem inWikipedia is not structured consistently (Ponzetto and Navigli, 2009).
And finally, disregardingthe article level neglects the huge amount of textual content provided by the articles.Therefore, attempts to align WordNet synsets and Wikipedia articles (instead of categories) have beenrecently made.
This has three major benefits.
First of all, as WordNet and Wikipedia were found tobe partly complementary on the word sense level, an aligned resource would increase the coverage of1http://www.ukp.tu-darmstadt.de/data/sense-alignment205senses (Wolf and Gurevych, 2010).
Second, word senses contained in both resources can then be rep-resented by relational information from WordNet and encyclopedic information from Wikipedia in amultilingual manner yielding an enriched knowledge representation.
And finally, the third major benefitof the alignment is the ability to automatically acquire sense-tagged corpora in a mono- and multilin-gual fashion.
For each WordNet synset, the text of the aligned Wikipedia article (or all sentences orparagraphs in Wikipedia that contain a link to the article) can be automatically extracted similar to theapproach proposed by Mihalcea (2007).
Automatically generated sense-tagged corpora can be used to,e.g., counter the bottleneck of supervised WSD methods that rely on such sense-tagged text collections,which are rare.
Further, due to the cross-lingual links in Wikipedia, also corpora in different languagescan be constructed easily.Our contribution to this paper is two-fold.
First, we propose a novel two-step approach to align WordNetsynsets and Wikipedia articles.
We model the task as a word sense disambiguation problem applyingthe Personalized PageRank algorithm proposed by Agirre and Soroa (2009) as it is state-of-the-art inWSD and combine it with a word overlap measure, which increases the overall performance.
Second,we generate and introduce a well-balanced reference dataset for evaluation consisting of 1,815 manuallyannotated sense alignment candidates.
WordNet synsets and their corresponding Wikipedia article can-didates are sampled along their distinctive properties such as synset size, domain, or the location in theWordNet taxonomy.
An evaluation on this dataset let us generalize the performance to a full alignmentbetween WordNet and Wikipedia, which is publicly available for further research activities.2 Related workThe alignment of WordNet and Wikipedia has been an active area of research for several years with thegoal of creating an enriched ontology.
One of the first attempts proposed a new resource YAGO inte-grating WordNet and Wikipedia consisting of more than 1 million entities and 5 million facts (Suchaneket al, 2007).
The set of entities contains all WordNet synsets and Wikipedia articles with titles that arenot represented as terms in WordNet.
Thus, they ignore ambiguous entities, e.g., the British rock bandQueen is not covered as the term queen is already contained in WordNet.Other approaches automatically align WordNet with the categories of Wikipedia instead of the articles.Toral et al (2008) enrich WordNet with named entities mined from Wikipedia.
Therefore, the nounis-a hierarchy of WordNet is mapped to the Wikipedia categories determining the overlap of articlesbelonging to the category and the instances for each of the senses of a polysemous word in WordNet.Ponzetto and Navigli (2009) applied a knowledge-rich method which maximizes the structural over-lap between the WordNet taxonomy and the category graph extracted from Wikipedia.
Based on themapping information, the taxonomy automatically generated from the Wikipedia category graph is re-structured to enhance the quality.
Toral et al (2009) disambiguate WordNet noun synsets and Wikipediacategories using multiple text similarity measures similar to our approach.
A Wikipedia category isthereby represented by its main article or an article, which has the same title string as the category.
Wuand Weld (2008) integrate the Wikipedia?s infobox information with WordNet to build a rich ontologyusing statistical-relational learning.Ruiz-Casado et al (2005) proposed a method to align WordNet synsets and Wikipedia articles (insteadof categories).
They align articles of the Simple English Wikipedia to their most similar WordNet synsetsdepending on the vector-based similarity of the synset?s gloss and the article text.
Recently, Ponzetto andNavigli (2010) presented a method based on a conditional probability p(s|w) of selecting the WordNetsense s given the Wikipedia article w, whereas the conditional probability relies on a normalized wordoverlap measure of the textual sense representation.
Both approaches, however, have the followingtwo major drawbacks: first, the algorithms are modeled such that they always assume a counterpart inWordNet for a given Wikipedia article, which does not hold for the English Wikipedia (see Section 4).Second, the algorithms always assign the most likely WordNet synset to a Wikipedia article, not allowingmultiple alignments.
However, due to the different sense granularities in WordNet and Wikipedia, someWikipedia articles might be assigned to more than one WordNet synset.
Based on these observations,206there is a need for a better approach yielding none, one, or more than one alignment for a given synset orarticle.
We will describe a novel idea to tackle this in the next section.3 MethodologyAutomatic sense alignment aims to match senses of different resources that have the same meaning.2 Ingeneral, one sense is given and the task is to find a correspondent within another resource, in case one ex-ists.
Thereby, automatic sense alignment meets two subgoals.
At first, all potential alignment candidatesenses for a given sense have to be extracted.
Secondly, these extracted candidates have to be scored toselect the sense(s) that match in meaning.
For example, given theWordNet synsetwn =<schooner: sail-ing vessel used in former times> and the two Wikipedia alignment candidate articles wp1 =<Schooner:A schooner is a type of sailing vessel ...> and wp2 =<Schooner (glass): A schooner is a type of glassused for ...>; the article wp1 should be aligned with the synset wn, while the second should not bealigned.
The recall of the extraction step can highly influence the performance of the whole alignmentprocess.
If a sense is not extracted in the first step, it cannot be selected in the alignment step either.In Section 3.1, we state how we extract Wikipedia alignment candidate articles for a given synset.
In thesubsequent Section 3.2, we describe how we determine the article that is aligned to the synset (if any atall).
As almost all Wikipedia articles refer to nouns, we focus on this part-of-speech.3.1 Candidate extractionIn order to extract Wikipedia articles for a given WordNet synset, we follow the procedure introduced byWolf and Gurevych (2010).
We shortly summarize this method here: Let wn be a WordNet synset witha set of synonyms {s1, ?
?
?
, sn} of size n. For each synonym s ?
wn, we extract all Wikipedia articleswp ?
WPwn that match one of the following constraints:a) the article title matches s, e.g., the article Window is retrieved for the synonym term Window,b) the article title is of the form s (description tag), e.g., Window (computing),c) the article has a redirect that matches s or is of the form s (description tag), e.g., Chaff (counter-measure) has a redirect Window (codename) and, thus, is retrieved for the synonym term Window,d) the article is linked in a hyperlink, in which the link anchor text matches s, e.g., the articleBandwagon effect is retrieved for the term bandwagon, as there exist a hyperlink of the form[[Bandwagon effect|bandwagon]].
Only hyperlinks that occur in at least 3 different articles aretaken into account in order to reduce noise.3.2 Candidate alignmentGiven the set ofWikipedia candidatesWPwn extracted for synsetwn, we have to classify eachWikipediaarticle wp ?
WPwn as being a valid alignment or not with respect to wn.
Therefore, we first calculatesimilarities between synset?article pairs of a given training set.
In a second step, we learn a thresholdcorresponding to the minimum similarity a sense pair should have to be aligned.
This threshold is thenused to fully align WordNet and Wikipedia.Sense similarity.
The basis of our new approach for sense alignment is the PageRank algorithm (Brinand Page, 1998) relying on a lexical-semantic knowledge base, which is modeled as a graph G =(V,E).
As knowledge base we use WordNet 3.0 extended with manually disambiguated glosses fromthe ?Princeton Annotated Gloss Corpus?3.
The vertices v ?
V represent the synsets; the edges (undi-rected and unweighted) represent semantic relations between synsets, such as hyponym and hypernymrelations.2We do not differentiate between the terms sense and concept in this paper as they both refer to the same ?artifact?
andonly differ in representation.
Concepts in WordNet are described by the entire synset, e.g.
the synset <design, plan>.
Senses,however, are words tagged with a sense number, e.g.
design N #2, which means the word check as a noun in its second sense.3http://wordnet.princeton.edu/glosstag.shtml207pprWNbag-of-words????
???
??WPbag-of-words?????
?pprWNsynsetWPbag-of-words?????
?db2b1Figure 1: Schematic illustration of the basic ppr (left) and direct pprd (right) approach.The PageRank algorithm ranks the vertices in a graph according to their importance within the set.
LetM be a (n ?
n) transition probability matrix, where Mji = 1outdegreei , if there exist a link from vertex ito vertex j.
Then, the PageRank vector pr over the graph G is equivalent to resolve:pr = cMpr+ (1?
c)v , (1)whereas c is a damping factor between 0 and 1, and v is an n-dimensional vector whose elements are 1n .An element of the PageRank vector denotes the probability for the corresponding vertex that a jumper,randomly following the edges in the graph, ends at that vertex, i.e.
the importance of that vertex.Now, vector v can be personalized by assigning stronger initial probabilities to certain vertices in thegraph.
This personalized version of the PageRank algorithm (Agirre and Soroa, 2009) is used in ourapproach in two different ways (see Figure 1):In the basic version ppr , we represent both, Wikipedia articles and WordNet synsets as bag-of-words(abbreviated as b in the following).
The textual representation is tokenized and lemmatized using theTreeTagger (Schmid, 1994); standard stopword removal is applied.
For a given synset?article pair, wecalculate two Personalized PageRank vectors.
For each Personalized PageRank vector, we initializevector v depending on the terms occurring in b:vi ={1m if a synonymous word of synseti in WordNet occurs in b0 else ,(2)wherem is the number of synsets with a synonymous word occurring in b.
For example, given the Word-Net synset <payment, defrayal, defrayment: the act of paying money> with its bag-of-words (payment,defrayal, defrayment, act, paying, money), we assign each synset, i.e.
vertex in the graph, a weight, forwhich at least one of its synonymous words occurs in the bag-of-words.
Then, the PageRank vector is asemantic representation over all WordNet synsets for the given bag-of-words.In the direct version ppr d, the WordNet synset is directly represented in v by assigning a weight of 1to the corresponding vector element.
It induces that the WordNet synset is already disambiguated andthus, motivates the use of the Personalized PageRank algorithm on the WordNet graph.
Only for theWikipedia article, the vector v is built up according to Eq.
2.Given two Personalized PageRank vectors pprwn and pprwp for the WordNet synset wn and theWikipedia article wp, we calculate their similarity using the ?2 measure.4simppr(wn,wp) = 1?
?2(pprwn, pprwp) = 1?
?i(pprwni ?
pprwpi)2pprwni + pprwpi(3)4This vector distance measure has shown the best overall performance compared to the cosine and euclidean distance in ourexperiments.208Learning classifier.
Based on the similarity, the sense pair has to be classified as alignment (class 1)or non-alignment (class 0) formally defined as:c(wn,wp) ={1 if sim(wn,wp) > t0 else ,(4)where sim(wn,wp) is the similarity of a WordNet synset and a Wikipedia article, and t is a real valuedthreshold.
We apply 10-fold cross-validation to determine the threshold.
We measure the performance ofclassification by means of F1-Measure (see Section 5) and iteratively search (from 0 to 1 in 0.001 steps)for a threshold that maximizes the performance on the training fold.
A threshold-based classificationscheme induces that a WordNet synset can be aligned to none, one, or more than one Wikipedia article,which is the main potential of our approach compared to existing methods.
However, in the scope of thispaper, we assign at most one Wikipedia article (if any) to a WordNet synset (the one with the highestsimilarity above the threshold) as this yields the best performance (see Section 5).Word overlap measure.
For comparison, we also applied the standard cosine word overlap similaritymeasure cos used in existing sense alignment approaches (e.g., Ruiz-Casado et al (2005)).
We deter-mine the similarity of the bag-of-words vectors of the WordNet synset and Wikipedia article calculatingthe cosine between them.
According to Eq.
4 we also learn a classifier based on the cosine similarity.Combination of the classifiers?
output.
Finally, we experiment with a heuristic, classifying only thosesynset?article pairs as alignment, for which the Personalized PageRank-based classifier and the cosine-based classifier, i.e.
cppr and ccos, or cpprd and ccos, return an alignment to further increase the precision.Baselines.
We implemented two different baselines.
The baseline rand randomly selects a Wikipediaarticle from the extracted candidate set for each synset.
The baseline mfs (most frequent sense) assignsalways the most frequently linked Wikipedia article of the candidate set defined as the article with thehighest number of incoming links.
For example, for the synset wn =<tree: a tall perennial woody planthaving a main trunk [...]> suppose we extract the two Wikipedia articles, namely wp1 =<Tree: A treeis a perennial woody plant.> and wp2 =<Tree (data structure)>.
In this case, the sense wp1 is alignedto the synset wn as it has 4,339 inlinks, about 4,000 more than the article wp2.
Both, the rand and mfsbaseline always return a one-to-one alignment.4 Well-balanced reference datasetPublicly available evaluation datasets as provided by Fernando and Stevenson (2010) and Wolf andGurevych (2010), are either quite small or follow a different annotation scheme.
Others consist of ran-domly sampled synsets, which do not properly represent the distribution of synsets in WordNet followingspecific properties.
For example, the dataset used in (Ponzetto and Navigli, 2010) consists of only 2 sensepairs, whose lemmas are monosemous in WordNet and Wikipedia (e.g.
the lemma specifier correspondsto one synset in WordNet and one article in Wikipedia).
As this property holds for one-third of all Word-Net noun synsets, it is crucial for the choice of the alignment method and thus, should be represented inthe evaluation dataset adequately.
Therefore, our goal in this paper is to compile a well-balanced datasetto cover different domains and properties.Synsets can be characterized with respect to their so-called assigned Unique Beginner, their synset size,and their location within the WordNet taxonomy.
The Unique Beginners group synsets in semanticallyrelated fields (Fellbaum, 1998) such as entity (subsuming animals, persons, plants, artifacts, body andfood related synsets), abstraction, psychological features, shapes, states, and locations.
The synset sizerefers to the number of synonymous word senses in the synset.
A synset can further be characterizedby its location within the WordNet taxonomy defined as the shortest path between the given synset andthe synset entity, which is the root element of all noun synsets.
In addition, we distinguish between209Property # synsets in WordNet # sampled synsets # manually aligned synsetsSynset size=1 42,054 160 110> 1 40,061 160 111Path length to root0-5 8,586 60 336-10 67,082 200 14311-16 6,447 60 45Unique BeginnerEntity 47,330 160 118Non-Entity 34,785 160 103# extracted WP candidates=1 23,991 160 108> 1 46,569 160 113Total # 82,115 320 221Table 1: Sampling by properties and # manual alignmentsAnnotator A B C majority# non-alignments 1,586 1,571 1,605 1,588# alignments 229 244 210 227Table 2: Annotations per classA?B A?C B?CAO .9697 .9741 .9724?
.8663 .8782 .8742Table 3: Inter-annotator agreementsynsets for which more than one Wikipedia candidate article is returned.
In summary, for example, thesynset <article, clause: a separate section of a legal document> has a synset size of 2, is assigned to theUnique Beginner communication, has a shortest path to the root element of length 6, and has 5 extractedWikipedia candidate articles.Based on these distinctive properties, we sampled 320 noun synsets yielding 1,815 sense pairs to beannotated, i.e.
5.7 Wikipedia articles per synset on average.
The exact proportion of synsets with respectto their properties is detailed in Table 1 in the first four columns.The manual sense alignment is performed by three human annotators.
The annotators were providedsense alignment candidate pairs, each consisting of a WordNet synset and a Wikipedia article.
The anno-tation task was to label each sense pair either as alignment or not.
Table 2 outlines the class distributionfor three annotators and the majority decision.The most sense alignment candidates were annotated as non-alignments; only between 210 and 244sense pairs were considered as alignments (extracted for 320 WordNet synsets).
To assess the reliabilityof the annotators?
decision, we computed the pairwise observed inter-annotator agreement AO and thechance-corrected agreement ?
(Artstein and Poesio, 2008)5.
The agreement values are shown in Table 3.The average observed agreement AO is 0.9721, while the multi-?
is 0.8727 indicating high reliability.The final dataset was compiled by means of a majority decision.
Given 1,815 sense alignment candidatepairs, 1,588 were annotated as non-alignments, while 227 were annotated as alignments.
215 synsetswere aligned with one article, while 6 synsets were aligned with two articles.
Interesting to note is that thealigned samples are uniformly distributed among the different sampling dimensions as shown in Table 1(right column).
It demonstrates that WordNet synsets of different properties are contained in Wikipedia.On the other side, 99 synsets, i.e.
approx.
1/3 of the sampled synsets, could not be aligned.
Most ofthem are not contained in Wikipedia at all, e.g.
the synset <dream (someone or something wonderful)>or <outside, exterior (the region that is outside of something)>.
Others are not explicitly encoded onthe article level such as the synset <quatercentennial, quatercentenary (the 400th anniversary (or thecelebration of it))>, which is part of the more general Wikipedia article <Anniversary>.5 ExperimentsIn our experiments, we represent a WordNet synset either by itself (in the direct version pprd ) or byits set of synonymous word senses and its gloss and examples (in the basic version ppr ).
Optionally,we include hyponym and hypernym synsets to extend the sense representation of a synset: (SYN): the5Note: ?As the class distribution is highly skewed, the test for reliability in such cases is the ability to agree on the rarecategories [.
.
.
]?
(Artstein and Poesio, 2008).
This, in fact, is the category/class, in which we are most interested in.210WordNet Wikipediacos pprd pprd + cos ppr ppr + cosF1 Acc F1 Acc F1 Acc F1 Acc F1 AccSYN P+T .691 .907 .719 .921 .726 .923 .707 .914 .727 .927+HYPO P+T .694 .908 .701 .916 .716 .931 .700 .912 .718 .926+HYPER P+T .726 .921 .708 .918 .737 .935 .756 .928 .774 .940+HYP2 P+T .725 .927 .713 .920 .720 .937 .741 .923 .756 .940SYN P+T+R .684 .907 .721 .921 .738 .936 .707 .913 .725 .926+HYPO P+T+R .689 .910 .711 .918 .729 .936 .698 .910 .721 .927+HYPER P+T+R .719 .917 .724 .928 .748 .937 .762 .938 .755 .940+HYP2 P+T+R .727 .920 .729 .929 .739 .937 .747 .932 .761 .940SYN P+T+C .698 .909 .754 .930 .756 .937 .726 .918 .743 .931+HYPO P+T+C .702 .910 .739 .927 .747 .938 .722 .917 .740 .930+HYPER P+T+C .738 .925 .752 .931 .765 .943 .765 .935 .781 .945+HYP2 P+T+C .732 .923 .739 .928 .757 .942 .746 .930 .769 .942SYN P+T+R+C .699 .912 .736 .926 .752 .939 .719 .916 .734 .929+HYPO P+T+R+C .695 .911 .736 .926 .735 .936 .711 .914 .727 .928+HYPER P+T+R+C .718 .917 .744 .930 .758 .940 .776 .940 .772 .943+HYP2 P+T+R+C .724 .918 .751 .932 .756 .939 .762 .936 .769 .942rand ?
.527 .857mfs ?
.534 .860Table 4: Results for the automatic alignmentgiven synset; (HYPER): all hypernym synsets of the given synset; (HYPO): all hyponym synsets of thegiven synset; (HYP2): all hypernym and hyponym synsets of the given synset.A Wikipedia article is represented by either its first paragraph6 as it usually contains a compact descrip-tion of the article or its whole article text.
The article title and additional assigned information such ascategories or redirects can also be taken into account: (P): first paragraph of Wikipedia article (with aminimum length of 200 characters7); (TXT): the whole article text; (T): article title; (C): all categoriesassigned to the article; (R): all redirects assigned to the article.Table 4 lists the performance of our approach for different experimental settings.8 We evaluate ourapproach in terms of F1-Measure (F1 = 2?P?RP+R ), where P is the precision andR the recall.
The precisionP determines the ratio of correct alignments to all alignments assigned by the algorithm.
The recall Ridentifies the number of correct alignments to the total number of correct alignments in the gold standard.Further, we provide an accuracy measure Acc, which denotes the percentage of the correctly identifiedalignments and non-alignments.Similarity measure.
Overall, the Personalized PageRank approach outperforms the cosine similar-ity.
cos achieves an F1-Measure of 0.738, while pprd reaches 0.754 and ppr even 0.776, which is aperformance gain of 2.1% and 5.1%, respectively.
This, in fact, strengthens our motivation to employ se-mantic relatedness based approaches instead of a simple word overlap approach.
For example, the synset<Johannesburg> and its corresponding Wikipedia article is not aligned based on the cosine approach asonly three terms overlap.
However, the ppr and pprd approach classify the synset?article pair as align-ment as there exists semantic relatedness between ?large economy?
and ?commercial center?
occurringin the textual sense representations.The performance differences between pprd and ppr correlate with the synset representation.
On the onehand, utilizing the SYN representation, pprd outperforms the ppr approach.
This shows the effect ofdisambiguating the WordNet synset beforehand.
On the other hand, when presenting the synset togetherwith its hypernym or both, hypernyms and hyponyms, ppr yields the best performance.
This mightbe due to the fact that a Wikipedia article often contains more general terms, i.e.
hypernym concepts,especially within the first paragraph of a Wikipedia article.All combinations yield higher performance compared to the stand-alone classifiers.
For example, forthe setting SYN+HYPER and P+T+C, cos yields 0.738, ppr 0.765, and the combination of both 0.7816Extracted with JWPL (Zesch et al, 2008) and some additional post-processing steps.7We have not optimized this value for this task.8As all experimental settings, in which the Wikipedia article was represented with its first paragraph instead of the wholearticle text, yield higher performance, we report only these numbers here.211Measure A B Ccos .688 .692 .676pprd .711 .711 .690pprd + cos .724 .
714 .716ppr .737 .718 .716ppr + cos .740 .730 .728Table 5: Agreement (?)
between automatic and human annotatorsautomaticalignment non-alignmentmanualalignment 178 49non-alignment 51 1,537Table 6: Confusion matrix (Setting: ppr + cos , SYN+HYPER, P+T+C)performance, which is an improvement of 5.8% and 2.1% compared to the cos and ppr approach,respectively.
The performance gain originates from higher precision.Sense representation.
All similarity measures yield better performance representing the WordNetsynset together with their hypernym synsets regardless of the representation of the Wikipedia article.As stated before, this might be due to the fact that Wikipedia articles often contain hypernym conceptsin their textual representation.
Further, each synset has exactly one direct hypernym concept, while thenumber of hyponym concepts is not limited.
This can cause a very noisy description of a synset, notfocusing on the textual representation of the actual sense.
When representing the Wikipedia sense, thecategories always boost the performance, while redirects are not helpful and can yield even a performancedrop.
The reason might be that redirects contain much noisy information, e.g.
spelling variations.Baselines.
The rand and the mfs baselines achieve an F1-Measure of 0.527 and 0.534, respectively.They always assign a sense even only 221 of 320 synsets can be aligned to Wikipedia.
If we onlyconsider the 221 synsets for which an alignment exist, the mfs baseline achieves an F1-Measure of 0.76,i.e.
for 146 out of 221 synsets the aligned Wikipedia article is the most frequent sense as we defined it inSection 3.2.Upper bound.
The human annotators show a pairwise agreement ?
between 0.866 and 0.878, whichserves as an upper bound for this task.
For each measure and its best performing experimental setting aslisted in Table 4, we calculate the agreement with the annotators?
alignments (see Table 5).
The combinedapproach ppr + cos achieves the highest agreement values ?, between 0.728 and 0.740.
These valuesshow that the automatic annotation is fairly reliable.5.1 Error analysisWe manually analyzed the alignments generated by the best performing experimental setup (ppr + cos,SYN+HYPER, P+T+C).
For synsets corresponding to more than one extracted Wikipedia candidate, theaverage number of Wikipedia candidates is around 10, which, indeed, makes the alignment step verychallenging for some synsets.
For example, for the synset <mission, military mission (an operationthat is assigned by a higher headquarters)> 30 Wikipedia candidates were extracted in total, whereasonly the article with the title <Military operation> was aligned manually.
10 out of the 30 are articlesabout space flight missions and Christian missionary.
Most of the remaining 19 refer to city names, songtitles, and other named entities.
Our approach returns the highest similarity for the article <Militaryoperation>, which demonstrates that the alignment works well in this example.As listed in Table 6, the best performing experimental setup correctly aligned 178 of the 227 manualalignments.
The remaining 49 manual alignments were not assigned.
Instead, 51 additional sense can-212didate pairs were incorrectly considered as alignment.
It is noticeable that the errors are almost equallydistributed among the distinctive properties a synset can have as defined in Section 4.
We could notobserve that a specific synset property causes the majority of errors.Most of the 51 false positives are due to highly related sense alignment candidates, e.g.
(cottonseed, cot-tonseed oil), (electroretinogram, electroretrinography), or (insulin shock, insulin shock therapy).
Thesesense alignment candidates have either the same stem but different suffixes or one part is a holonym ormeronym of the other part.
This knowledge can be used to apply additional post-processing steps toboost the performance.
Further, even if they are non-aligned manually as they do not describe the samesense, the concepts are highly related, and thus, the alignment might be useful in specific tasks.Most of the 49 manual alignments that could not be aligned automatically are due to the differences howsenses are defined in WordNet and Wikipedia.
For example, the WordNet synset <payment, defrayal,defrayment: the act of paying money> and the manually alignedWikipedia article<Payment: A paymentis the transfer of wealth from one party (such as person or company) to another ...> could not be alignedautomatically.
In this example, the textual similarity or relatedness is not sufficient to classify them as avalid alignment.
This fact shows that other types of knowledge should be additionally integrated in thealignment approach, such as structural or taxonomic knowledge.6 ConclusionsWe have presented a novel two-step approach to automatically align English Wikipedia articles andWordNet synsets.
We have shown that a threshold-based method models the task properly yieldingnone, one, or more than one alignment of a Wikipedia article for a given WordNet synset.
This is dif-ferent to previous sense alignment approaches.
Further, we have shown that it is important to employsemantic relatedness measuring the similarity of textual sense representations.
Our approach to the auto-matic alignment shows an encouraging performance of 0.78 F1-Measure and 94.5% accuracy based on acomprehensive, well-balanced reference dataset consisting of 1,815 manually annotated sense alignmentcandidates.We have created a fully-aligned resource with our best performing setting (ppr + cos , SYN+HYPER,P+T+C, threshold: 0.439 for ppr , 0.048 for cos ), in which two-thirds of all WordNet noun synsets arealigned with one article from the English Wikipedia.
On the one hand, this fact supports our assumptionand overall motivation that both resources are partly complementary at the sense level (one-third of allnoun synsets are not in Wikipedia).
On the other hand, for the two-thirds of WordNet noun synsets, thealignment yields relational information from WordNet and encyclopedic information from Wikipedia.We believe that this new resource and the enhanced knowledge therein can boost the performance ofvarious NLP systems that previously had to rely on a single resource only.
We already started researchon integrating the aligned resource in WSD and semantic relatedness tasks.
The fully-aligned resourceas well as the reference dataset are publicly available at http://www.ukp.tu-darmstadt.de/data/sense-alignment for further research activities.AcknowledgmentsThis work has been supported by the Emmy Noether Program of the German Research Foundation (DFG) underthe grant No.
GU 798/3-1, and by the Volkswagen Foundation as part of the Lichtenberg-Professorship Programunder the grant No.
I/82806.
We thank our colleague Christian M. Meyer for many fruitful discussions during thework on this paper and our students Yevgen Chebotar and Christian Kirschner for their help on the experiments.Further, we thank the IXA group at the University of the Basque Country for making their code on the PersonalizedPageRank method based on WordNet available online.99http://ixa2.si.ehu.es/ukb213ReferencesAgirre, E. and P. G. Edmonds (2006).
Word Sense Disambiguation: Algorithms and Applications.
Springer.Agirre, E. and A. Soroa (2009).
Personalizing PageRank for Word Sense Disambiguation.
In Proceedings of the12th Conference of the European Chapter of the Association for Computational Linguistics, Athens, Greece,pp.
33?41.Artstein, R. and M. Poesio (2008).
Inter-Coder Agreement for Computational Linguistics.
Computational Lin-guistics 34(4), 555?596.Brin, S. and L. Page (1998).
The Anatomy of a Large-Scale Hypertextual Web Search Engine.
Computer Net-works 30(1-7), 107?117.Fellbaum, C. (1998).
WordNet: An Electronic Lexical Database (Language, Speech, and Communication).
Cam-bridge, MA: MIT Press.Fernando, S. and M. Stevenson (2010).
Aligning WordNet Synsets and Wikipedia Articles.
In Proceedings of theAAAI Workshop on Collaboratively-built Knowledge Sources and Artificial Intelligence, Atlanta, GA, USA.Meyer, C. M. and I. Gurevych (2010).
How Web Communities Analyze Human Language: Word Senses inWiktionary.
In Proceedings of the Second Web Science Conference, Raleigh, NC, USA.Mihalcea, R. (2007).
Using Wikipedia for Automatic Word Sense Disambiguation.
In Proceedings of the NorthAmerican Chapter of the Association for Computational Linguistics, Rochester, NY, USA, pp.
196?203.Ponzetto, S. P. and R. Navigli (2009).
Large-Scale Taxonomy Mapping for Restructuring and IntegratingWikipedia.
In Proceedings of the 21th International Joint Conference on Artificial Intelligence, Pasadena,CA, USA, pp.
2083?2088.Ponzetto, S. P. and R. Navigli (2010).
Knowledge-rich Word Sense Disambiguation rivaling supervised system.In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, Uppsala, Sweden,pp.
1522?1531.Ruiz-Casado, M., E. Alfonseca, and P. Castells (2005).
Automatic Assignment of Wikipedia Encyclopedic Entriesto WordNet Synsets.
In Advances in Web Intelligence, Volume 3528 of LNCS, pp.
380?386.
Springer Verlag.Schmid, H. (1994).
Probabilistic Part-of-Speech Tagging Using Decision Trees.
In Proceedings of the InternationalConference on New Methods in Language Processing, Manchester, United Kingdom, pp.
44?49.Suchanek, F. M., G. Kasneci, and G. Weikum (2007).
Yago: A Core of Semantic Knowledge.
In Proceedings ofthe 16th International World Wide Web Conference, Banff, Canada, pp.
697?706.Toral, A., O. Ferrandez, E. Agirre, and R. Munoz (2009).
A study on Linking Wikipedia categories to Wordnetusing text similarity.
In Proceedings of Recent Advances in Natural Language Processing, Borovets, Bulgaria,pp.
449?454.Toral, A., R. Munoz, and M. Monachini (2008).
Named Entity WordNet.
In Proceedings of the 6th InternationalConference on Language Resources and Evaluation, Marrakech, Marocco, pp.
741?747.Wolf, E. and I. Gurevych (2010).
Aligning Sense Inventories in Wikipedia and WordNet.
In Proceedings of the1st Workshop on Automated Knowledge Base Construction, Grenoble, France, pp.
24?28.Wu, F. and D. S. Weld (2008).
Automatically Refining the Wikipedia Infobox Ontology.
In Proceedings of the17th International Conference on World Wide Web, Beijing, China, pp.
635?644.Zesch, T., C. Mu?ller, and I. Gurevych (2008).
Extracting Lexical Semantic Knowledge from Wikipedia and Wik-tionary.
In Proceedings of the 6th International Conference on Language Resources and Evaluation, Marrakech,Marocco, pp.
1646?1652.214
