Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 870?878,Suntec, Singapore, 2-7 August 2009. c?2009 ACL and AFNLPMining Bilingual Data from the Web with Adaptively Learnt PatternsLong Jiang1, Shiquan Yang2, Ming Zhou1, Xiaohua Liu1, Qingsheng Zhu21Microsoft Research AsiaBeijing, 100190, P.R.China2Chongqing University,Chongqing, 400044, P.R.China{longj,mingzhou,xiaoliu}@microsoft.com shiquany@gmail.com,qszhu@cqu.edu.cnAbstractMining bilingual data (including bilingual sen-tences and terms1) from the Web can benefitmany NLP applications, such as machinetranslation and cross language information re-trieval.
In this paper, based on the observationthat bilingual data in many web pages appearcollectively following similar patterns, anadaptive pattern-based bilingual data miningmethod is proposed.
Specifically, given a webpage, the method contains four steps: 1) pre-processing: parse the web page into a DOMtree and segment the inner text of each nodeinto snippets; 2) seed mining: identify poten-tial translation pairs (seeds) using a wordbased alignment model which takes both trans-lation and transliteration into consideration; 3)pattern learning: learn generalized patternswith the identified seeds; 4) pattern based min-ing: extract all bilingual data in the page usingthe learned patterns.
Our experiments on Chi-nese web pages produced more than 7.5 mil-lion pairs of bilingual sentences and more than5 million pairs of bilingual terms, both withover 80% accuracy.1 IntroductionBilingual data (including bilingual sentences andbilingual terms) are critical resources for build-ing many applications, such as machine transla-tion (Brown, 1993) and cross language informa-tion retrieval (Nie et al, 1999).
However, mostexisting bilingual data sets are (i) not adequatefor their intended uses, (ii) not up-to-date, (iii)apply only to limited domains.
Because it?s veryhard and expensive to create a large scale bilin-1 In this paper terms refer to proper nouns, technical terms,movie names, and so on.
And bilingual terms/sentencesmean terms/sentences and their translations.gual dataset with human effort, recently manyresearchers have turned to automatically miningthem from the Web.If the content of a web page is written in twolanguages, we call the page a Bilingual WebPage.
Many such pages exist in non-English websites.
Most of them have a primary language(usually a non-English language) and a second-ary language (usually English).
The content inthe secondary language is often the translation ofsome primary language text in the page.Since bilingual web pages are very common innon-English web sites, mining bilingual datafrom them should be an important task.
However,as far as we know, there is no publication availa-ble on mining bilingual sentences directly frombilingual web pages.
Most existing methods formining bilingual sentences from the Web, suchas (Nie et al, 1999; Resnik and Smith, 2003; Shiet al, 2006), try to mine parallel web documentswithin bilingual web sites first and then extractbilingual sentences from mined parallel docu-ments using sentence alignment methods.As to mining term translations from bilingualweb pages, Cao et al (2007) and Lin et al (2008)proposed two different methods to extract termtranslations based on the observation that authorsof many bilingual web pages, especially thosewhose primary language is Chinese, Japanese orKorean, sometimes annotate terms with theirEnglish translations inside a pair of parentheses,like ?c1c2...cn(e1 e2 ... em)?
(c1c2...cn is a primarylanguage term and e1 e2 ... em is its English trans-lation).Actually, in addition to the parenthesis pattern,there is another interesting phenomenon that inmany bilingual web pages bilingual data appearcollectively and follow similar surface patterns.Figure 1 shows an excerpt of a page which intro-duces different kinds of dogs2.
The page provides2 http://www.chinapet.net870a list of dog names in both English and Chinese.Note that those bilingual names do not follow theparenthesis pattern.
However, most of them areidentically formatted as: ?{Number}?
{Englishname}{Chinese name}{EndOfLine}?.
One ex-ceptional pair (?1.Alaskan Malamute ???????
?)
differs only slightly.
Furthermore,there are also many pages containing consistentlyformatted bilingual sentences (see Figure 2).
Thepage3 lists the (claimed) 200 most common oralsentences in English and their Chinese transla-tions to facilitate English learning.Figure 1.
Consistently formatted term translationpairsFigure 2.
Consistently formatted sentence trans-lation pairsPeople create such web pages for various rea-sons.
Some online stores list their products intwo languages to make them understandable toforeigners.
Some pages aim to help readers withforeign language learning.
And in some pageswhere foreign names or technical terms are men-tioned, the authors provide the translations fordisambiguation.
For easy reference, from now onwe will call pages which contain many consis-tently formatted translation pairs Collective Bi-lingual Pages.According to our estimation, at least tens ofmillions of collective bilingual pages exist inChinese web sites.
Most importantly, each suchpage usually contains a large amount of bilingual3 http://cul.beelink.com/20060205/2021119.shtmldata.
This shows the great potential of bilingualdata mining.
However, the mining task is notstraightforward, for the following reasons:1) The patterns vary in different pages, soit?s impossible to mine the translationpairs using predefined templates;2) Some pages contain consistently format-ted texts in two languages but they are nottranslation pairs;3) Not all translations in a collective bilin-gual page necessarily follow an exactlyconsistent format.
As shown in Figure 1,the ten translation pairs are supposed tofollow the same pattern, however, due totypos, the pattern of the first pair isslightly different.Because of these difficulties, simply using aclassifier to extract translation pairs from adja-cent bilingual texts in a collective bilingual pagemay not achieve satisfactory results.
Therefore inthis paper, we propose a pattern-based approach:learning patterns adaptively from collective bi-lingual pages instead of using the parenthesispattern, then using the learned patterns to extracttranslation pairs from corresponding web pages.Specifically, our approach contains four steps:1) Preprocessing: parse the web page into aDOM tree and segment the inner text ofeach node into snippets;2) Seed mining: identify potential translationpairs (seeds) using an alignment modelwhich takes both translation and translite-ration into consideration;3) Pattern learning: learn generalized pat-terns with the identified seeds;4) Pattern based mining: extract all bilingualdata in the page using the learnt patterns.Let us take mining bilingual data from the textshown in Figure 1 as an example.
Our methodidentifies ?Boxer???
and ?Eskimo Dog??????
as two potential translation pairs basedon a dictionary and a transliteration model (Step2 above).
Then we learn a generalized patternthat both pairs follow as ?
{BulletNumb-er}{Punctuation}{English term}{Chineseterm}{EndOfLine}?, (Step 3 above).
Finally, weapply it to match in the entire text and get altranslation pairs following the pattern (Step 4above).The remainder of this paper is organized asfollows.
In Section 2, we list some related work.The overview of our mining approach is pre-sented in Section 3.
In Section 4, we give de-871tailed introduction to each of the four modules inour mining approach.
The experimental resultsare reported in Section 5 followed by our conclu-sion and some future work in Section 6.Please note that in this paper we describe ourmethod using example bilingual web pages inEnglish and Chinese, however, the method canbe applied to extract bilingual data from webpages written in any other pair of languages,such as Japanese and English, Korean and Eng-lish etc.2 Related WorkMining Bilingual Data from the WebAs far as we know, there is no publication avail-able on mining parallel sentences directly frombilingual web pages.
Most existing methods ofmining bilingual sentences from the Web, suchas (Nie et al, 1999; Resnik and Smith, 2003; Shiet al, 2006), mine parallel web documents withinbilingual web sites first and then extract bilingualsentences from mined parallel documents usingsentence alignment methods.
However, since thenumber of bilingual web sites is quite small,these methods can not yield a large number ofbilingual sentences.
(Shi et al, 2006), mined atotal of 1,069,423 pairs of English-Chinese paral-lel sentences.
In addition to mining from paralleldocuments, (Munteanu and Marcu, 2005) pro-posed a method for discovering bilingual sen-tences in comparable corpora.As to the term translation extraction from bi-lingual web pages, (Cao et al, 2007) and (Lin etal., 2008) proposed two different methods utiliz-ing the parenthesis pattern.
The primary insightis that authors of many bilingual web pages, es-pecially those whose primary language is Chi-nese, Japanese or Korean sometimes annotateterms with their English translations inside a pairof parentheses.
Their methods are tested on alarge set of web pages and achieve promisingresults.
However, since not all translations inbilingual web pages follow the parenthesis pat-tern, these methods may miss a lot of translationsappearing on the Web.Apart from mining term translations directlyfrom bilingual web pages, more approaches havebeen proposed to mine term translations fromtext snippets returned by a web search engine(Jiang et al, 2007; Zhang and Vines, 2004;Cheng et al, 2004; Huang et al, 2005).
In theirmethods the source language term is usually giv-en and the goal is to find the target languagetranslations from the Web.
To obtain web pagescontaining the target translations, they submit thesource term to the web search engine and collectreturned snippets.
Various techniques have beenproposed to extract the target translations fromthe snippets.
Though these methods achieve highaccuracy, they are not suitable for compiling alarge-scale bilingual dictionary for the followingreasons: 1) they need a list of predefined sourceterms which is not easy to obtain; 2) the relev-ance ranking in web search engines is almostentirely orthogonal to the intent of finding thebilingual web pages containing the target transla-tion, so many desired bilingual web pages maynever be returned; 3) most such methods relyheavily on the frequency of the target translationin the collected snippets which makes mininglow-frequency translations difficult.Moreover, based on the assumption that anc-hor texts in different languages referring to thesame web page are possibly translations of eachother, (Lu et al, 2004) propose a novel approachto construct a multilingual lexicon by making useof web anchor texts and their linking structure.However, since only famous web pages mayhave inner links from other pages in multiplelanguages, the number of translations that can beobtained with this method is limited.Pattern-based Relation ExtractionPattern-based relation extraction has also beenstudied for years.
For instance, (Hearst, 1992;Finkelstein-Landau and Morin, 1999) proposedan iterative pattern learning method for extract-ing semantic relationships between terms.
(Brin,1998) proposed a method called DIPRE (DualIterative Pattern Relation Expansion) to extract arelation of books (author, title) pairs from theWeb.
Since translation can be regarded as a kindof relation, those ideas can be leveraged for ex-tracting translation pairs.3 Overview of the Proposed ApproachWebpagesSeed miningPattern-basedminingPatternlearningPreprocessingBilingualdictionaryinputoutputdependTranslationpairsTransliterationmodel dependFigure 3.
The framework of our approach872As illustrated in Figure 3, our mining systemconsists of four main steps: preprocessing, seedmining, pattern learning and pattern based min-ing.
The input is a set of web documents and theoutput is mined bilingual data.In the preprocessing step, the input web doc-uments are parsed into DOM trees and the innertext of each tree node is segment into snippets.Then we select those tree nodes whose innertexts are likely to contain translation pairs collec-tively with a simple rule.The seed mining module receives the innertext of each selected tree node and uses a word-based alignment model to identify potentialtranslation pairs.
The alignment model can han-dle both translation and transliteration in a uni-fied framework.The pattern learning module receives identi-fied potential translation pairs from the seed min-ing as input, and then extracts generalized patterncandidates with the PAT tree algorithm.
Then aSVM classifier is trained to select good patternsfrom all extracted pattern candidates.In the pattern-based mining step, the selectedpatterns were used to match within the wholeinner text to extract all translation pairs follow-ing the patterns.4 Adaptive Pattern-based Bilingual Da-ta MiningIn this section, we will present the details aboutthe four steps in the proposed approach.4.1 PreprocessingHTML Page ParsingThe Document Object Model (DOM) is an appli-cation programming interface used for parsingHTML documents.
With DOM, an HTML doc-ument is parsed into a tree structure, where eachnode belongs to some predefined types (e.g.
DIV,TABLE, TEXT, COMMENT, etc.).
We removednodes with types of ?B?, ?FONT?, ?I?
and so on,because they are mainly used for controlling vis-ual effect.
After removal, their child nodes willbe directly connected to their parents.Text SegmentationAfter an HTML document is parsed, the innertext of each node in the DOM tree will be seg-mented into a list of text snippets according totheir languages.
That means each snippet will belabeled as either an English snippet (E) or a Chi-nese snippet (C).The text segmentation was performed basedon the Unicode values of characters 4  first andthen guided by the following rules to decide theboundary of a snippet under some special situa-tions:1) Open punctuations (such as ?(?)
are pad-ded into next snippet, and close punctua-tions (such as ?)?)
are padded into pre-vious snippet; other punctuations (such as?;?)
are padded into previous snippet;2) English snippets which contains only 1 or2 ASCII letters are merged with previousand next Chinese snippets (if exist).
Sincesometimes Chinese sentences or terms al-so contain some abbreviations in English.Table 1 gives some examples of how the innertexts are segmented.Inner textChina Development Bank (??)
?????
?SegmentationChina Development Bank |(??
)?????
?Inner text Windows XP ??????
XP?Segmentation Windows XP |??????
XP?Table 1.
Example segmentations (?|?
indicates theseparator between adjacent snippets)Since a node?s inner text includes all innertexts of its children, the segmentation to all textsof a DOM tree has to be performed from the leafnodes up to the root in order to avoid repetitivework.
When segmenting a node?s inner text, wefirst segment the texts immediately dominated bythis node and then combine those results with itschildren?s segmented inner texts in sequence.As a result of the segmentation, the inner textof every node will look like ?
?ECECC 5EC?
?.Two adjacent snippets in different languages (in-dicated as ?EC?
or ?CE?)
are considered a Bilin-gual Snippet Pair (BSP).Collective Nodes SelectionSince our goal is to mine bilingual knowledgefrom collective bilingual pages, we have to de-cide if a page is really a collective bilingual page.In this paper, the criterion is that a collectivepage must contain at least one Collective Nodewhich is defined as a node whose inner text con-tains no fewer than 10 non-overlapping bilingualsnippet pairs and which contains less than 104 For languages with the same character zone, other tech-niques are needed to segment the text.5 Adjacent snippets in the same language only appear in theinner texts of some non-leaf nodes.873percent of other snippets which do not belong toany bilingual snippet pairs.4.2 Seed MiningThe input of this module is a collective nodewhose inner text has been segmented into conti-nuous text snippets, suchas ?EkChEk+1Ch+1Ch+2?.
In this step, every ad-jacent snippet pair in different languages will bechecked by an alignment model to see if it is apotential translation pair.
The alignment modelcombines a translation and a transliteration mod-el to compute the likelihood of a bilingual snip-pet pair being a translation pair.
If it is, we callthe snippet pair as a Translation Snippet Pair(TSP).
If both of two adjacent pairs, e.g.
EkChand ChEk+1, are considered as TSPs, the one withlower translation score will be regarded as aNON-TSP.Before computing the likelihood of a bilingualsnippet pair being a TSP, we preprocess it via thefollowing steps:a) Isolating the English and Chinese con-tents from their contexts in the bilingualsnippet pair.
Here, we use a very simplerule: in the English snippet, we regard allcharacters within (and including) the firstand the last English letter in the snippet asthe English content; similarly, in the Chi-nese snippet we regard all characterswithin (and including) the first and thelast Chinese character in the snippet asthe Chinese content;b) Word segmentation of the Chinese con-tent.
Here, the Forward Maximum Match-ing algorithm (Chen and Liu, 1992) basedon a dictionary is adopted;c) Stop words filtering.
We compiled asmall list of stop words manually (for ex-ample, ?of?, ?to?, ??
?, etc.)
and removethem from the English and Chinese con-tent;d) Stemming of the English content.
We usean in-house stemming tool to get the un-inflected form of all English words.After preprocessing, all English words form acollection E={e1,e2,?,em } and all Chinesewords constitute a collection C={c1,c2,?,cn},where ei is an English word, and ci is a Chineseword.
We then use a linking algorithm whichtakes both translation and transliteration intoconsideration to link words across the two col-lections.In our linking algorithm, there are three situa-tions in which two words will be linked.
The firstis that the two words are considered translationsof each other by the translation dictionary.
Thesecond is that the pronunciation similarity of thetwo words is above a certain threshold so thatone can be considered the transliteration of theother.
The third is that the two words are identic-al (this rule is especially designed for linkingnumbers or English abbreviations in Chinesesnippets).
The dictionary is an in-house dictio-nary and the transliteration model is adaptedfrom (Jiang et al, 2007).After the linking, a translation score over theEnglish and Chinese content is computed by cal-culating the percentage of words which can belinked in the two collections.
For some pairs,there are many conflicting links, for example,some words have multiple senses in the dictio-nary.
Then we select the one with highest trans-lation score.For example, given the bilingual snippet pairof ?Little Smoky River?
and ??????
?, itsEnglish part is separated as ?Little/Smoky/River?,and its Chinese part is separated as ??/?/?/?/??.
According to the dictionary, ?Little?
can belinked with ??
?, and ?River?
can be linked with???.
However, ?Smoky?
is translated as ?????
in the dictionary which does not match anyChinese characters in the Chinese snippet.
How-ever the transliteration score (pronunciation simi-larity) between ?Smoky?
(IPA: s.m.o.k.i) and??/?/??
(Pinyin: si mo ji) is higher than thethreshold, so the English word ?Smoky?
can belinked to three Chinese characters ??
?, ???
and???.
The result is a translation score of 1.0 forthe pair ?Little Smoky River?
and ??????
?.4.3 Pattern LearningThe pattern learning module is critical for miningbilingual data from collective pages, becausemany translation pairs whose translation scoresare not high enough may still be extracted bypattern based mining methods.In previous modules, the inner texts of allnodes are segmented into continuous text snip-pets, and translation snippet pairs (TSP) are iden-tified in all bilingual snippet pairs.
Next, in thepattern learning module, those translation snippetpairs are used to find candidate patterns and thena SVM classifier is built to select the most usefulpatterns shared by most translation pairs in thewhole text.874Candidate Pattern ExtractionFirst, as in the seed mining module, we isolatethe English and Chinese contents from their con-texts in a TSP and then replace the contents withtwo placeholders ?[E]?
and ?[C]?
respectively.Second, we merge the two snippets of a TSPinto a string and add a starting tag ?[#]?
and anending tag ?[#]?
to its start and end.
Following(Chang and Lui, 2001), all processed strings areused to build a PAT tree, and we then extract allsubstrings containing ?E?
and ?C?
as patterncandidates from the PAT tree.
However, patterncandidates which start or end with ?[E]?
(or?[C]?)
will be removed, since they cannot speci-fy unambiguous boundaries when being matchedin a string.Web page authors commonly commit format-ting errors when authoring the content into anhtml page, as shown in Figure 1.
There, the tenbilingual terms should have been written in thesame pattern, however, because of the mistakenuse of ?.?
instead of ??
?, the first translationpair follows a slightly different pattern.
Someother typical errors may include varying lengthor types of white space, adjacent punctuationmarks instead of one punctuation mark, and soon.
To make the patterns robust enough to handlesuch variation, we generalized all pattern candi-dates through the following two steps:1) Replace characters in a pattern with theirclasses.
We define three classes of cha-racters: Punctuation (P), Number (N), andWhite Space (S).
Table 2 lists the threeclasses and the corresponding regular ex-pressions in Microsoft .Net Framework6.2) Merge identical adjacent classes.Class Corresponding regular expressionP [\p{P}]N [\d]S [\s]Table 2.
Character classesFor example, from the translation snippet pairof ?7.
Don?t worry.?
and ?????
?, we willlearn the following pattern candidates:?
?#[N][P][S][E][P][S][C][P]#?;?
?[N][P][S][E][P][S][C][P]#?;?
?[N][P][S][E][P][S][C][P]?;?
??
?[S][E][P][S][C][P]?
;6 In System.Text.RegularExpressions namespacePattern SelectionAfter all pattern candidates are extracted, a SVMclassifier is used to select the good ones:???
xwxfw ????
,)(where, x?
is the feature vector of a patterncandidate pi, and w?
is the vector of weights.???
?,  stands for an inner product.
f is the decisionfunction to decide which candidates are good.In this SVM model, each pattern candidate pihas the following four features:1) Generality: the percentage of those bi-lingual snippet pairs which can match piin all bilingual snippet pairs.
This featuremeasures if the pattern is a common pat-tern shared by many bilingual snippetpairs;2) Average translation score: the averagetranslation score of all bilingual snippetpairs which can match pi.
This featurehelps decide if those pairs sharing thesame pattern are really translations;3) Length: the length of pi.
In general, long-er patterns are more specific and can pro-duce more accurate translations, however,they are likely to produce fewer matches;4) Irregularity: the standard deviation ofthe numbers of noisy snippets.
Here noisysnippets mean those snippets between anytwo adjacent translation pairs which canmatch pi.
If the irregularity of a pattern islow, we can be confident that pairs shar-ing this pattern have a reliably similar in-ner relationship with each other.To estimate the weight vector, we extracted allpattern candidates from 300 bilingual web pagesand asked 2 human annotators to label each ofthe candidates as positive or negative.
The anno-tation took each of them about 20 hours.
Thenwith the labeled training examples, we use SVMlight7 to estimate the weights.4.4 Pattern-based MiningAfter good patterns are selected, every two adja-cent snippets in different languages in the innertext will be merged as a target string.
As wementioned previously, we add a starting tag ?
[#]?and an ending tag ?[#]?
to the start and end ofevery target string.
Then we attempt to matcheach of the selected patterns in each of the targetstrings and extract translation pairs.
If the target7 http://svmlight.joachims.org/875string was matched with more than one pattern,the matched string with highest translation scorewill be kept.The matching process is actually quite simple,since we transform the learnt patterns into stan-dard regular expressions and then make use ofexisting regular expression matching tools (e.g.,Microsoft .Net Framework) to extract translationpairs.However, to make our patterns more robust,when transforming the selected patterns intostandard regular expressions, we allow each cha-racter class to match more than once.
That means?
[N]?, ?[P]?
and ?[S]?
will be transformed into?
[\d]+?, ?[\p{P}]+?
and ?[\s]+?
respectively.
And?[E]?
and ?[C]?
will be transformed into?[^\u4e00-\u9fa5]+?
(any character except Chi-nese character) and ?.+?, respectively.5 Experimental ResultsIn the following subsections, first, we will reportthe results of our bilingual data mining on a largeset of Chinese web pages and compare them withprevious work.
Second, we will report some ex-perimental results on a manually constructed testdata set to analyze the impact of each part of ourmethod.5.1 Evaluation on a Large Set of PagesWith the proposed method, we performed bilin-gual data extraction on about 3.5 billion webpages crawled from Chinese web sites.
Out ofthem, about 20 million were determined to con-tain bilingual collective nodes.
From the innertexts of those nodes, we extracted 12,610,626unique translation pairs.
If we consider thosepairs whose English parts contain more than 5words as sentence translations and all others asterm translations, we get 7,522,803 sentencetranslations and 5,087,823 term translations.
Weevaluated the quality of these mined translationsby sampling 200 sentence translations and 200term translations and presenting those to humanjudges, with a resulting precision of 83.5% forsentence translations and 80.5% for term transla-tions.As we mentioned in Section 2, (Shi et al,2006) reported that in total they mined 1,069,423pairs of English-Chinese parallel sentences frombilingual web sites.
However, our method yieldsabout 7.5 million pairs, about seven times asmany.We also re-implemented the extraction methodusing the parenthesis pattern proposed by (Lin etal., 2008) and were able to mine 6,538,164 bilin-gual terms from the same web pages.
A sampleof 200 terms was submitted for human judgment,resulting in a precision of 78.5% which is a littlelower than that of our original result.
Furtheranalysis showed that fewer than 20% of the bi-lingual terms mined with our method overlapwith the data mined using the re-implementedmethod proposed by (Lin et al, 2008).
This indi-cates that our method can find many translationswhich are not covered by the parenthesis patternand therefore can be used together with the pa-renthesis pattern based method to build a bilin-gual lexicon.Out of the term translations we mined, wefound many which co-occur with their sourceterms only once in the Web.
We check this bysearching in Google with a Boolean query madeof the term and its translation and then get thenumber of pages containing the query.
If oneattempts to extract this kind of low-frequencytranslation using a search engine-based method,the desired bilingual page which contains thetarget translation is not likely to be returned inthe top n results when searching with the sourceterm as the query.
Even if the desired page isreturned, the translation itself may be difficult toextract due to its low frequency.5.2 Evaluation on a Human Made Test Da-ta SetBesides the evaluation of our method on a hugeset of web pages, we also carried out some expe-riments on a human-constructed test data set.
Werandomly selected 500 collective nodes from thehuge set of Chinese web pages and asked twoannotators to label all bilingual data in their innertexts.
Half of the labeled data are then used asthe development data set and the rest as the testdata set to evaluate our systems with differentsettings.
Table 3 shows the evaluation results.Setting Type Recall Precision F-ScoreWithoutpatternExact 52.2 75.4 61.7Fuzzy 56.3 79.3 65.8WithoutPGExact 69.2 78.6 73.6Fuzzy 74.3 82.9 78.4With PGExact 79.3 80.5 79.9Fuzzy 86.7 87.9 87.3Table 3.
Performance of different settingsIn Table 3, ?Without pattern?
means that wesimply treat those seed pairs found by the align-ment model as final bilingual data.
?Without PG?and ?With PG?
mean not generalizing and gene-ralizing the learnt patterns to class based form,876respectively.
Evaluation type ?Exact?
means themined bilingual data are considered correct onlyif they are exactly same as the data labeled byhuman, while ?Fuzzy?
means the mined bilin-gual data are considered correct if they containthe data labeled by the human.As shown in Table 3, the system without pat-tern-based extraction yields only 52.2% recall.However, after adding pattern-based extraction,recall is improved sharply, to 69.2% for ?With-out PG?
and to 79.3% for ?With PG?.
Most ofthe improvement comes from those translationswhich have very low translation scores andtherefore are discarded by the seed mining mod-ule, however, most of them are found with thehelp of the learnt patterns.From Table 3, we can also see that the system?With PG?
outperforms ?Without PG?
in termsof both precision and recall.
The reason may bethat web writers often make mistakes when writ-ing on web pages, such as punctuation misuse,punctuation loss, and extra spaces etc., so ex-tracting with a strict surface pattern will oftenmiss those translations which follow slightly dif-ferent patterns.To find out the reasons why some non-translation pairs are extracted, we checked 20pairs which are not translations but extracted bythe system.
Out of them, 5 are caused by wrongsegmentations.
For example, ?????????????
Double Concerto for Violin andCello D???????
Symphony No.2 in DMajor?
is segmented into ?????????????
?, ?Double Concerto for Violin and CelloD?, ????????
?, and ?Symphony No.2 inD Major?.
However, the ending letter ?D?
of thesecond segment should have been padded intothe third segment.
For 9 pairs, the Chinese partsare explanative texts of corresponding Englishtexts, but not translations.
Because they containthe translations of the key words in the Englishtext, our seed mining module failed to identifythem as non-translation pairs.
For 3 pairs, theyfollow the same pattern with some genuine trans-lation pairs and therefore were extracted by thepattern based mining module.
However, they arenot translation pairs.
For the other 3 pairs, theerrors came from the pattern generalization.To evaluate the contribution of each featureused in the pattern selection module, we elimi-nated one feature at a time in turn from the fea-ture set to see how the performance changed inthe absence of any single feature.
The results arereported below.Eliminated feature F-Score (Exact)Null 79.9Generality 72.3Avg.
translation score 74.3Length 77.5Irregularity 76.6Table 4.
Contribution of every featureFrom the table above, we can see that everyfeature contributes to the final performance andthat Generality is the most useful feature amongall four features.6 ConclusionsBilingual web pages have shown great potentialas a source of up-to-date bilingualterms/sentences which cover many domains andapplication types.
Based on the observation thatmany web pages contain bilingual data collec-tions which follow a mostly consistent but possi-bly somewhat variable pattern, we propose a uni-fied approach for mining bilingual sentences andterms from such pages.
Our approach can adap-tively learn translation patterns according to dif-ferent formatting styles in various web pages andthen use the learnt patterns to extract more bilin-gual data.
The patterns are generalized to minim-ize the impact of format variation and typos.
Ac-cording to experimental results on a large set ofweb pages as well as on a manually made testdata set, our method is quite promising.In the future, we would like to integrate thetext segmentation module with the seed miningand pattern learning module to improve the accu-racy of text segmentation.
We also want to eva-luate the usefulness of our mined data for ma-chine translation or other applications.ReferencesP.
F. Brown, S. A. Della Pietra, V. J. Della Pietra andR.
L. Mercer.
1993.
The mathematics of statisticalmachine translation: parameter estimation.
Compu-tational Linguistics, 19:2, 263-311.Sergey Brin.
1998.
Extracting patterns and relationsfrom the World Wide Web.
In Proc.
of the 1998 In-ternational Workshop on the Web and Databases.Pp: 172-183.G.H.
Cao, J.F.
Gao and J.Y.
Nie.
2007.
A system tomine large-scale bilingual dictionaries from mono-lingual web pages.
MT summit.
Pp: 57-64.877Chia-Hui Chang and Shao-Chen Lui.
2001.
IEPAD:Inform extract based on pattern discovery.
In Proc.of the 10th ACM WWW conference.Keh-Jiann Chen, Shing-Huan Liu.
1992.
Word Identi-fication for Mandarin Chinese Sentences.
In theProceedings of COLING 1992.
Pp:101-107.Cheng, P., Teng, J., Chen, R., Wang, J., Lu, W., andCheng, L. 2004.
Translating Unknown Querieswith Web Corpora for Cross-Language InformationRetrieval.
In the Proceedings of SIGIR 2004, pp162-169.Michal Finkelstein-Landau, Emmanuel Morin.
1999.Extracting Semantic Relationships between Terms:Supervised vs. Unsupervised Methods.
In Proceed-ings of International Workshop on Ontological En-gineering on the Global Information Infrastructure.Pp:71-80.Marti A. Hearst.
1992.
Automatic Acquisition of Hy-ponyms from Large Text Corpora.
In the Proceed-ings of COLING-92.
Pp: 539-545.Huang, F., Zhang, Y., and Vogel, S. 2005.
MiningKey phrase Translations from Web Corpora.
In theProceedings of HLT-EMNLP.L.
Jiang, M. Zhou, L.-F. Chien, C. Niu.
2007.
NamedEntity Translation with Web Mining and Translite-ration, Proceedings of the 20th IJCAI.
Pp: 1629-1634.D.
Lin, S. Zhao, B. Durme and M. Pasca.
2008.
Min-ing Parenthetical Translations from the Web byWord Alignment.
In ACL-08.
pp 994-1002.Lu, W. and Lee, H. 2004.
Anchor text mining fortranslation of Web queries: A transitive translationapproach.
ACM transactions on Information Sys-tems, Vol.22, April 2004, pages 242-269.D.
S. Munteanu, D. Marcu.
Improving MachineTranslation Performance by Exploiting Non-Parallel Corpora.
2005.
Computational Linguistics.31(4).
Pp: 477-504.J-Y Nie, M. Simard, P. Isabelle, and R. Durand.
1999.Cross-Language Information Retrieval Based onParallel Texts and Automatic Mining of parallelText from the Web.
In SIGIR 1999.
Pp: 74-81.Philip Resnik, Noah A. Smith.
2003.
The Web as aParallel Corpus.
Computational Linguistics.
29(3).Pp: 349-380.Li Shao and Hwee Tou Ng.
2004.
Mining new wordtranslations from comparable corpora.
In Proc.
ofCOLING 2004.
Pp: 618?624.Lei Shi, Cheng Niu, Ming Zhou, Jianfeng Gao.
2006.A DOM Tree Alignment Model for Mining Paral-lel Data from the Web.
In ACL 2006.Jung H. Shin, Young S. Han and Key-Sun Choi.
1996.Bilingual knowledge acquisition from Korean-English parallel corpus using alignment method:Korean-English alignment at word and phrase level.In Proceedings of the 16th conference on Computa-tional linguistics, Copenhagen, Denmark.J.C.
Wu, T. Lin and J.S.
Chang.
2005.
LearningSource-Target Surface Patterns for Web-basedTerminology Translation.
ACL Interactive Posterand Demonstration Sessions,.
Pp 37-40, Ann Arbor.Zhang, Y. and Vines, P.. 2004.
Using the Web forAutomated Translation Extraction in Cross-Language Information Retrieval.
In the Proceed-ings of SIGIR 2004.
Pp: 162-169.878
