Proceedings of the Workshop on Information Extraction Beyond The Document, pages 36?47,Sydney, July 2006. c?2006 Association for Computational LinguisticsAutomatic Knowledge Representation using a Graph-based Algorithm forLanguage-Independent Lexical ChainingGae?l DiasHULTIGUniversity of Beira InteriorCovilha?, Portugalddg@di.ubi.ptCla?udia SantosHULTIGUniversity of Beira InteriorCovilha?, Portugalclaudia@dmnet.ubi.ptGuillaume CleuziouLIFOUniversity of Orle?ansOrle?ans, Francecleuziou@univ-orleans.frAbstractLexical Chains are powerful representa-tions of documents.
In particular, theyhave successfully been used in the fieldof Automatic Text Summarization.
How-ever, until now, Lexical Chaining algo-rithms have only been proposed for Eng-lish.
In this paper, we propose a greedyLanguage-Independent algorithm that au-tomatically extracts Lexical Chains fromtexts.
For that purpose, we build a hier-archical lexico-semantic knowledge basefrom a collection of texts by using thePole-Based Overlapping Clustering Algo-rithm.
As a consequence, our method-ology can be applied to any languageand proposes a solution to language-dependent Lexical Chainers.1 IntroductionLexical Chains are powerful representations of doc-uments compared to broadly used bag-of-words rep-resentations.
In particular, they have successfullybeen used in the field of Automatic Text Summa-rization (Barzilay and Elhadad, 1997).
However, un-til now, Lexical Chaining algorithms have only beenproposed for English as they rely on linguistic re-sources such as Thesauri (Morris and Hirst, 1991) orOntologies (Barzilay and Elhadad, 1997; Hirst andSt-Onge, 1997; Silber and McCoy, 2002; Galley andMcKeown, 2003).Morris and Hirst (1991) were the first to proposethe concept of Lexical Chains to explore the dis-course structure of a text.
However, at the time ofwriting their paper, no machine-readable thesauruswas available so they manually generated LexicalChains using Roget?s Thesaurus (Roget, 1852).A first computational model of Lexical Chainsis introduced by Hirst and St-Onge (1997).
Theirbiggest contribution to the study of Lexical Chainsis the mapping of WordNet (Miller, 1995) relationsand paths (transitive relationships) to (Morris andHirst, 1991) word relationship types.
However, theirgreedy algorithm does not use a part-of-speech tag-ger.
Instead, the algorithm only selects those wordsthat contain noun entries in WordNet to computeLexical Chains.
But, as Barzilay and Elhadad (1997)point at, the use of a part-of-speech tagger couldeliminate wrong inclusions of words such as read,which has both noun and verb entries in WordNet.So, Barzilay and Elhadad (1997) propose the firstdynamic method to compute Lexical Chains.
Theyargue that the most appropriate sense of a word canonly be chosen after examining all possible Lexi-cal Chain combinations that can be generated froma text.
Because all possible senses of the word arenot taken into account, except at the time of inser-tion, potentially pertinent context information thatis likely to appear after the word is lost.
However,this method of retaining all possible interpretationsuntil the end of the process, causes the exponentialgrowth of the time and space complexity.As a consequence, Silber and McCoy (2002) pro-pose a linear time version of (Barzilay and Elhadad,1997) lexical chaining algorithm.
In particular, (Sil-ber and McCoy, 2002)?s implementation creates astructure, called meta-chains, that implicitly stores36all chain interpretations without actually creatingthem, thus keeping both the space and time usageof the program linear.Finally, Galley and McKeown (2003) propose achaining method that disambiguates nouns prior tothe processing of Lexical Chains.
Their evaluationshows that their algorithm is more accurate than(Barzilay and Elhadad, 1997) and (Silber and Mc-Coy, 2002) ones.One common point of all these works is that Lex-ical Chains are built using WordNet as the standardlinguistic resource.
Unfortunately, systems based onstatic linguistic knowledge bases are limited.
First,such resources are difficult to find.
Second, theyare largely obsolete by the time they are available.Third, linguistic resources capture a particular formof lexical knowledge which is often very differentfrom the sort needed to specifically relate words orsentences.
In particular, WordNet is missing a lotof explicit links between intuitively related words.Fellbaum (1998) refers to such obvious omissionsin WordNet as the ?tennis problem?
where nounssuch as nets, rackets and umpires are all present,but WordNet provides no links between these relatedtennis concepts.In order to solve these problems, we propose toautomatically construct from a collection of docu-ments a lexico-semantic knowledge base with thepurpose to identify cohesive lexical relationships be-tween words based on corpus evidence.
This hi-erarchical lexico-semantic knowledge base is builtby using the Pole-Based Overlapping Clustering Al-gorithm (Cleuziou et al, 2004) that clusters wordswith similar meanings and allows words with mul-tiple meanings to belong to different clusters.
Thesecond step of the process aims at automaticallyextracting Lexical Chains from texts based on ourknowledge base.
For that purpose, we propose anew greedy algorithm which can be seen as an ex-tension of (Hirst and St-Onge, 1997) and (Barzilayand Elhadad, 1997) algorithms which allows polyse-mous words to belong to different chains thus break-ing the ?one-word/one-concept per document?
par-adigm (Gale et al, 1992)1.
In particular, it imple-1This characteristic can be interesting for multi-topic docu-ments like web news stories.
Indeed, in this case, there may bedifferent topics in the same document as different news storiesmay appear.
In some way, it follows the idea of (Krovetz, 1998).ments (Lin, 1998) information-theoretic definitionof similarity as the relatedness criterion for the at-tribution of words to Lexical Chains2.2 Building a Similarity MatrixIn order to build the lexico-semantic knowledgebase, the Pole-Based Overlapping Clustering Algo-rithm needs as input a similarity matrix that gathersthe similarities between all the words in the corpus.For that purpose, we propose a contextual analysisof each nominal unit (nouns and compound nouns)in the corpus.
In particular, each nominal unit is as-sociated to a word context vector and the similar-ity between nominal units is calculated by the in-formative similarity measure proposed by (Dias andAlves, 2005).2.1 Data PreparationThe context corpus is first pre-processed in orderto extract nominal units from it.
The TnT tagger(Brants, 2000) is first applied to our context cor-pus to morpho-syntactically mark all the words init.
Once all words have been morpho-syntacticallytagged, we apply the statistically-based multiwordunit extractor SENTA (Dias et al, 1999) that ex-tracts multiword units based on any input text3.
Forexample, multiword units are compound nouns (freekick), compound determinants (an amount of), ver-bal locutions (to put forward), adjectival locutions(dark blue) or institutionalized phrases (con carne).Finally, we use a set of well-known heuristics(Daille, 1995) to retrieve compound nouns using theidea that groups of words that correspond to a pri-ori defined syntactical patterns such as Adj+Noun,Noun+Noun, Noun+Prep+Noun can be identifiedas compound nouns.
Indeed, nouns usually con-vey most of the information in a written text.
Theyare the main contributors to the ?aboutness?
of atext.
For example, free kick, city hall, operating sys-tem are compound nouns which sense is not com-positional i.e.
the sense of the multiword unit can2Of course, other similarity measures (Resnik, 1995; Jiangand Conrath, 1997; Leacock and Chodorow, 1998) could beimplemented and should be evaluated in further work.
How-ever, we used (Lin, 1998) similarity measure as it has shownimproved results for Lexical Chains construction.3By choosing both the TnT tagger and the multiword unitextractor SENTA, we guarantee that our architecture remains aslanguage-independent as possible.37not be expressed by the sum of its constituentssenses.
So, identifying lexico-semantic connectionsbetween nouns is an adequate means of determiningcohesive ties between textual units4.2.2 Word Context VectorsThe similarity matrix is a matrix where each cell cor-responds to a similarity value between two nominalunits5.
In this paper, we propose a contextual analy-sis of nominal units based on similarity betweenword context vectors.Word context vectors are an automated methodfor representing information based on the local con-text of words in texts.
So, for each nominal unit inthe corpus, we associate an N-dimension vector con-sisting of its N most related words6.In order to find the most relevant co-occurrentnominal units, we implement the Symmetric Con-ditional Probability (Silva et al, 1999) which isdefined in Equation 1 where p(w1, w2), p(w1)and p(w2) are respectively the probability of co-occurrence of the nominal units w1 and w2 and themarginal probabilities of w1 and w2.SCP (w1, w2) =p(w1, w2)2p(w1)?
p(w2)(1)In particular, the window context for the calcula-tion of co-occurrence probabilities is settled to F=20words.
In fact, we count, in all the texts of thecorpus, the number of occurrences of w1 and w2appearing together in a window context of F ?
2words.
So, p(w1, w2) represents the density func-tion computed as follows: the number of times w1and w2 co-occur divided by the number of words inthe corpus7.
In the present work, the values of theSCP (., .)
are not used as a factor of importance be-tween words in the word context vector i.e.
no dif-ferentiation is made in terms of relevance betweenthe words within the word context vector.
This issuewill be tackled in future work8.4However, we acknowledge that verbs and adjectives shouldalso be tackled in future work.5Many works have been proposed on word similarity (Lin,1998).6In our experiments, N=10.7We note that multiword units are counted as single wordsas when they are identified (e.g.
President of the United States),they are re-written in the corpus by linking all single words withan underscore (e.g.
President of the United States)8We may point at the fact that satisfying results were2.3 Similarity between Context VectorsThe closeness of vectors in the space is equivalent tothe closeness of the subject content.
Thus, nominalunits that are used in a similar local context will havevectors that are relatively close to each other.
How-ever, in order to define similarities between vectors,we must transform each word context vector intoa high dimensional vector consisting of real-valuedcomponents.
As a consequence, each co-occurringword of the word context vector is associated to aweight which evaluates its importance in the corpus.2.3.1 Weighting scoreThe weighting score of any word in a documentcan be directly derived from an adaptation of thescore proposed in (Dias and Alves, 2005).
In par-ticular, we consider the combination of two mainheuristics: the well-known tf.idf measure proposedby (Salton et al, 1975) and a new density measure(Dias and Alves, 2005).tf.idf: Given a word w and a document d, thetf.idf(w, d) is defined in Equation 2 where tf(w, d)is the number of occurrences of w in d, |d| corre-sponds to the number of words in d, N is the num-ber of documents in the corpus and df(w) stands forthe number of documents in the corpus in which theword w occurs.tf.idf(w, d) =tf(w, d)|d|?
log2Ndf(w)(2)density: The basic idea of the word density mea-sure is to evaluate the dispersion of a word withina document.
So, very disperse words will not beas relevant as dense words.
This density measuredens(., .)
is defined in Equation 3.dens(w, d) =tf(w,d)?1Xk=11ln(dist(o(w,k), o(w,k+1)) + e)(3)For any given word w, its density dens(w, d)is calculated from all the distances between allits occurrences in document d, tf(w, d).
So,dist(o(w,k), o(w,k+1)) calculates the distance thatseparates two consecutive occurrences of w in termsof words within the document.
In particular, e is theobtained by the Symmetric Conditional Probability measurecompared to the Pointwise Mutual Information for instance(Cleuziou et al, 2003)38base of the natural logarithm so that ln(e) = 1.
Thisargument is included into Equation 3 as it will givea density value of 1 for any word that only occursonce in the document.
In fact, we give this word ahigh density value.final weight: The weighting score weight(w) ofany word w in the corpus can be directly derivedfrom the previous two heuristics.
This score is de-fined in Equation 4 where tf and dens are respec-tively the average of tf(., .)
and dens(., .)
over allthe documents in which the word w occurs i.e.
Nw.weight(w) = tf .idf(w)?
dens(w) (4)where tf =Pd tf(w,d)Nwand dens(w) =Pd dens(w,d)Nw2.3.2 Informative Similarity MeasureThe next step aims at determining the similaritybetween all nominal units.
Theoretically, a similar-ity measure can be defined as follows.
Suppose thatXi = (Xi1, Xi2, Xi3, , Xip) is a row vector of ob-servations on p variables associated with a label i.The similarity between two words i and j is definedas Sij = f(Xi, Xj) where f is some function of theobserved values.
In the context of our work, Xi andXj are 10-dimension word context vectors.In order to avoid the lexical repetition problem ofsimilarity measures, (Dias and Alves, 2005) haveproposed an informative similarity measure calledinfoSimBA, which basic idea is to integrate intothe Cosine measure, the word co-occurrence fac-tor inferred from a collection of documents withthe Symmetric Conditional Probability (Silva et al,1999).
See Equation 5.InfoSimBA(Xi, Xj) =AijBi ?Bj + Aij(5)whereAij =pXk=1pXl=1Xik ?Xjl ?
SCP (wik, wjl)?i, Bi =vuutpXk=1pXl=1Xik ?Xil ?
SCP (wik, wil)and any Xzv corresponds to the word weighting fac-tor weight(wzv), SCP (wik, wjl) is the SymmetricConditional Probability value betweenwik, the wordthat indexes the word context vector i at position kand wjl, the word that indexes the word context vec-tor j at position l.In particular, this similarity measure has proved tolead to better results compared to the classical simi-larity measure (Cosine) and shares the same idea asthe Latent Semantic Analysis (LSA) but in a differ-ent manner.
Let?s consider the following two sen-tences.
(1) Ronaldo defeated the goalkeeper once more.
(2) Real_Madrid_striker scored again.It is clear that both sentences (1) and (2) are simi-lar although they do not share any word in common.Such a situation would result in a null Cosine valueso evidencing no relationship between (1) and (2).To solve this problem, the InfoSimBA(., .)
func-tion would calculate for each word in sentence (2),the product of its weight with each weight of all thewords in sentence (1), and would then multiply thisproduct by the degree of cohesiveness existing be-tween those two words calculated by the Symmet-ric Conditional Probability measure.
For example,Real Madrid striker would give rise to the sum of6 products i.e.
Real Madrid striker with Ronaldo,Real Madrid striker with defeated and so on andso forth.
As a consequence, sentence (1) and (2)would show a high similarity as Real Madrid strikeris highly related to Ronaldo.Once the similarity matrix is built based on theinfoSimBA between all word context vectors ofall nominal units in the corpus, we give it as in-put to the Pole-Based Overlapping Clustering Algo-rithm (Cleuziou et al, 2004) to build a hierarchy ofconcepts i.e.
our lexico-semantic knowledge base.3 Hierarchy of ConceptsClustering is the task that structures units in sucha way it reflects the semantic relations existing be-tween them.
In our framework nominal units are firstgrouped into overlapping clusters (or soft-clusters)such that final clusters correspond to conceptualclasses (called ?concepts?
in the following).
Then,concepts are hierarchically structured in order tocapture semantic links between them.Many clustering methods have been proposed inthe data analysis research fields.
Few of thempropose overlapping clusters as output, in spite ofthe interest it represents for domains of application39such as Natural Language Processing or Bioinfor-matics.
PoBOC (Pole-Based Overlapping Cluster-ing) (Cleuziou et al, 2004) and CBC (Clustering ByCommittees) (Pantel and Lin, 2002) are two clus-tering algorithms suitable for the word clusteringtask.
They both proceed by first constructing tightclusters9 and then assigning residual objects to theirmost similar tight clusters.A recent comparative study (Cicurel et al, 2006)shows that CBC and PoBOC both lead to relevantresults for the task of word clustering.
Neverthe-less CBC requires parameters hard to tune whereasPoBOC is free of any parametrization.
The last ar-gument encouraged us to use the PoBOC algorithm.Unlike most of commonly used clustering algo-rithms, the Pole-Based Overlapping Clustering Al-gorithm shows the following advantages among oth-ers : (1) it requires no parameters i.e.
input is re-stricted to a single similarity matrix, (2) the num-ber of final clusters is automatically found and (3) itprovides overlapping clusters allowing to take intoaccount the different possible meanings of lexicalunits.3.1 A Graph-based ApproachThe Pole-Based Overlapping Clustering Algorithmis based on a graph-theoretical framework.
Graphformalism is often used in the context of cluster-ing (graph-clustering).
It first consists in defininga graph structure which illustrates the data (vertices)with links (edges) between them and then in propos-ing a graph-partitioning process.Numerous graph structures have been proposed(Estivill-Castro et al, 2001).
They all consider thedata set as set of vertices but differ on the way to de-cide that two vertices are connected.
Some method-ologies are listed below where V is the set of ver-tices, E the set of edges, G(V,E) a graph and d adistance measure:?
Nearest Neighbor Graph (NNG) : each vertexis connected to its nearest neighbor,?
Minimum Spanning Tree (MST) : ?
(xi, xj) ?V ?V a path exists between xi and xj in G withP(xi,xj)?Ed(xi, xj) minimized,9The tight clusters are called ?committees?
in CBC and?poles?
in PoBOC.?
Relative Neighborhood Graph (RNG) : xi andxj are connected iff ?xk ?
V \ {xi, xj},d(xi, xj) ?
max{d(xi, xk), d(xj , xk)}?
Gabriel Graph (GG) : xi and xj are connectediff the circle with diameter xixj is empty,?
Delaunay Triangulation (DT) : xi and xj areconnected iff the associated Voronoi cells areadjacent.In particular, an inclusion order exists on thesegraphs.
One can show that NNG ?
MST ?
RNG ?GG ?
DT .The choice of the suitable graph structure dependson the expressiveness we want an edge to captureand the partitioning process we plan to perform.
ThePole-Based Overlapping Clustering Algorithm aimsat retrieving dense subsets in a graph where twosimilar data are connected and two dissimilar onesare disconnected.
Noticing that previous structuresdo not match with this definition of a proximity-graph10, a new variant is proposed with the Pole-Based Overlapping Clustering Algorithm in defini-tion 3.1.Definition 3.1 Given a similarity measure s on adata set X , the graph (denoted Gs(V,E)) is definedby the set of vertices V = X and the set of edges Esuch that (xi, xj) ?
E ?
xi ?
N (xj) ?
xj ?
N (xi).In particular,N (xi) corresponds to the local neigh-borhood of xi built as in equation 6.N (xi) = {xj ?
X|s(xi, xj) > s(xi, X)} (6)where the notation s(xi, I) denotes the average sim-ilarity of xi with the set of objects I i.e.Xxk?Is(xi, xk)|I|(7)This definition of neighborhood is a way to avoidrequiring to a parameter that would be too dependentof the similarity used.
Furthermore, the use of lo-cal neighborhoods avoids the use of arbitrary thresh-olds which mask the variations of densities.
Indeed,clusters are extracted from a similarity graph whichdiffers from traditional proximity graphs (Jarom-czyk and Toussaint, 1992) in the definition of local10Indeed, for instance, all of these graphs connect an outlierwith at least one other vertex.
This is not the case with PoBOC.40neighborhoods which condition edges in the graph.Neighborhood is different for each object and iscomputed on the basis of similarities with all otherobjects.
Finally, an edge connects two vertices ifthey are both contained in the neighborhood of theother one.
Figure 1 illustrates the neighborhood con-straint above.
In this case, as xi and xj are not bothin the intersection, they would not be connected.Figure 1: To be connected, both xi and xj must bein the intersection.3.2 Discovery of PolesThe graph representation helps to discover a setof fully-connected subgraphs (cliques) highly sep-arated, denoted as Poles.
Because Gs(V,E) is builtsuch that two vertices xi and xj are connected if andonly if they are similar11, a clique has the requiredproperties to be a good cluster.
Indeed, such a clus-ter guarantees that all its constituents are similar.The search of maximal cliques in a graph is anNP-complete problem.
As a consequence, heuristicsare used in order to (1) build a great clique around astarting vertex (Bomze et al, 1999) and (2) choosethe starting vertices in such a way cliques are as dis-tant as possible.Given a starting vertex x, the first heuristic con-sists in adding iteratively the vertex xi which satis-fies the following conditions:?
xi is connected to each vertex in P (with P theclique/Pole in construction),?
among the connected vertices, xi is the nearestone in average (s(xi, P )).11In the sense that xi (resp.
xj) is more similar to xj (resp.xi) than to other data on average.As a consequence, initialized with P = {x}, theclique then grows until no vertex can be added.The second heuristic guides the selection of thestarting vertices in a simple manner.
Given a setof Poles P1, .
.
.
, Pm already extracted, we select thevertex x as in Equation 8.s(x, P1 ?
?
?
?
?
Pm) = minxis(xi, P1 ?
?
?
?
?
Pm) (8)A new Pole is then built from x if and only if xsatisfies the following conditions:?
?k ?
{1, .
.
.
,m} , x /?
Pk ,?
s(x, P1 ?
?
?
?
?
Pm) < s(X,X) =1|X|2XxiXxjs(xi, xj)Poles are thus extracted while P1 ?
?
?
?
?
Pm 6=X and the next starting vertex x is far enough fromthe previous Poles.
In particular, as Poles representthe seeds of the further final clusters, this heuristicgives no restriction on the number of clusters.
Thefirst Pole is obtained from the starting point x?
thatchecks Equation 9.x?
= argminxk?Xs(xk, X) (9)3.3 Multi-AssignmentOnce the Poles are built, the Pole-Based Overlap-ping Clustering algorithm uses them as clusters rep-resentatives.
Membership functions m(., .)
are de-fined in order to assign each object to its nearestPoles as shown in Equation 10.?xi ?
X, Pj ?
{P1, .
.
.
, Pm} : m(xi, Pj) = s(xi, Pj) (10)For each object xi to assign, the set of poles isordered (P1(xi), .
.
.
, Pm(xi)) such that P1(xi) de-notes the nearest pole12 for xi, P2(xi) the secondnearest pole for xi and so on.
We first assign xi to itsclosest Pole (P1(xi)).
Then, for each pole Pk(xi)(inthe order previously defined) we decide to assign xito Pk(xi) if it satisfies to the following two condi-tions :?
?k?
< k, xi is assigned to Pk?
(xi),?
if k < m,s(xi, Pk(xi)) ?s(xi, Pk?1(xi)) + s(xi, Pk+1(xi))2This methodology results into a coverage of thestarting data set with overlapping clusters (extendedPoles).12P1(xi) = argmaxPj s(xi, Pj)413.4 Hierarchical OrganizationA final step consists in organizing the obtained clus-ters into a hierarchical tree.
This structure is use-ful to catch the topology of a set of a priori discon-nected groups.
The Pole-Based Overlapping Clus-tering algorithm integrates this stage and proceedsby successive merging of the two nearest clusterslike for usual agglomerative approaches (Sneath andSokal, 1973).
In this process, the similarity be-tween two clusters is obtained by the average-link(or complete-link) method:s(Ip, Iq) =1|Ip|.|Iq|Xxi?IpXxj?Iqs(xi, xj) (11)To deal with overlapping clusters we considere inEquation 11 the similarity between an object and it-self to be equal to 1 : s(xi, xi) = 1.4 Lexical Chaining AlgorithmOnce the lexico-semantic knowledge base has beenbuilt, it is possible to use it for Lexical Chaining.In this section, we propose a new greedy algorithmwhich can be seen as an extension of (Hirst and St-Onge, 1997) and (Barzilay and Elhadad, 1997) al-gorithms as it allows polysemous words to belongto different chains thus breaking the ?one-word/one-concept per document?
paradigm (Gale et al, 1992).Indeed, multi-topic documents like web news sto-ries may introduce different topics in the same doc-ument/url and do not respect the ?one sense per dis-course?
paradigm.
As we want to deal with real-world applications, this characteristic may show in-teresting results for the specific task of Text Summa-rization for Web documents.
Indeed, comparativelyto the experiments made by (Gale et al, 1992) thatdeal with ?well written discourse?, web documentsshow unusual discourse structures.
In some way,our algorithm follows the idea of (Krovetz, 1998).Finally, it implements (Lin, 1998)?s information-theoretic definition of similarity as the relatednesscriterion for the attribution of words to LexicalChains.4.1 AlgorithmOur chaining algorithm is based on both approachesof (Barzilay and Elhadad, 1997) and (Hirst and St-Onge, 1997).
So, our chaining model is developedaccording to all possible alternatives of word senses.In fact, all senses of a word are defined by the clus-ters the word appears in13.
We present our algorithmbelow.Begin with no chain.For all distinct nominal units in text order doFor all its senses doa) - among present chains find the sensewhich satisfies the relatednesscriterion and link the new word tothis chain.- Remove unappropriate senses of thenew word and the chain members.b)if no sense is close enough, start a new chain.End ForEnd ForEnd4.2 Assignment of a word to a Lexical ChainIn order to assign a word to a given Lexical Chain,we need to evaluate the degree of relatedness of thegiven word to the words in the chain.
This is doneby evaluating the relatedness between all the clusterspresent in the Lexical Chain and all the clusters inwhich the word appears.4.2.1 Scoring FunctionIn order to determine if two clusters are semanti-cally related, we use our lexico-semantic knowledgebase and apply (Lin, 1998)?s measure of semanticsimilarity defined in Equation 12.simLin(C1, C2) =2?
logP (C0)logP (C1) + logP (C2)(12)The computation of Equation 12 is illustrated be-low using the fragment of WordNet in Figure 2.Figure 2: Fragment of WordNet (Lin, 1998).13From now on, for presentation purposes, we will take assynonymous the words clusters and senses42In this case, it would be easy to compute the sim-ilarity between the concepts of hill and coast wherethe number attached to each node C is P (C).
It isshown in Equation 13.simLin(hill, coast) =2 logP (geological ?
formation)logP (hill) + logP (coast)= 0.59 (13)However, in our taxonomy, as in any knowl-edge base computed by hierarchical clustering algo-rithms, only leaves contain words.
So, upper clusters(i.e.
nodes) in the taxonomy gather all distinct wordsthat appear in the clusters they subsume.
We presentthis situation in Figure 3.Figure 3: Fragment of our taxonomy.In particular, clusters C305 and C306 of ourhierarchical tree, for the domain of Economy,are represented by the following sets of wordsC305 ={life, effort, stability, steps, negotiations}and C306 ={steps, restructure, corporations, abuse,interests, ministers} and the number attached to eachnode C is P (C) calculated as in Equation 1414.P (Ci) =# of words in the cluster# of distinct words in all clusters(14)4.2.2 Relatedness criterionThe relatedness criterion is the threshold thatneeds to be respected in order to assign a word toa Lexical Chain.
In fact, it works like a threshold.In this case, it is based on the average semantic sim-ilarity between all the clusters present in the taxon-omy.
So, if all semantic similarities between a candi-date word cluster Ck and all the clusters in the chain?l, Cl respect the relatedness criterion, the word is14The value 2843 in Figure 3 is the total number of distinctwords in our concept hierarchy.assigned to the Lexical Chain.
This situation is de-fined in Equation 15 where c is a constant to be tunedand n is the number of words in the taxonomy.
So,if Equation 15 is satisfied, the word w with clusterCk is agglomerated to the Lexical Chain.
?l, simLin(Ck, Cl) > c?nXi=0nXj=i+1simLin(Ci, Cj)n22?
n(15)In the following section, we present an exampleof our algorithm.4.2.3 Example of the Lexical Chain algorithmThe example below illustrates our Lexical Chainalgorithm.
Let?s consider that a node is createdfor the first nominal unit encountered in the texti.e.
crisis with its sense (C31).
The next ap-pearing candidate word is recession which has twosenses (C29 and C34).
Considering a relatedness cri-terion equal to 0.81 and the following similarities,simLin(C31, C29) = 0.87, simLin(C31, C34) = 0.82 , thechoice of the sense for recession splits the LexicalChain into two different interpretations as shownin Figure 4, as both similarities overtake the giventhreshold 0.81.Figure 4: Interpretations 1 and 2.The next candidate word trouble has also twosenses (C29 and C32).
As all the words in a Lexi-cal Chain influence each other in the selection of therespective senses of the new word considered, wehave the following situation in Figure 5.So, three cases can happen: (1) all similaritiesovertake the threshold and we must consider bothrepresentations, (2) only the similarities related toone representation overtake the threshold and we43Figure 5: Selection of senses.only consider this representation or (3) none of thesimilarities overtake the threshold and we create anew Lexical Chain.
So, we proceed with our algo-rithm for both interpretations.Interpretation 1 shows the following similari-ties simLin(C31, C29) = 0.87, simLin(C31, C32) =0.75, simLin(C29, C29) = 1.0, simLin(C29, C32) =0.78 and interpretation 2 the following ones,simLin(C31, C29) = 0.87, simLin(C31, C32) = 0.75,simLin(C34, C29) = 0.54, simLin(C34, C32) = 0.55 .By computing the average similarities for in-terpretations 1 and 2, we reach the following re-sults: average(Interpretation1) = 0.85 > 0.81 andaverage(Interpretation2) = 0.68 ?
0.81 .As a consequence, the word trouble is inserted inthe Lexical Chain with the appropriate sense (C29)as it maximizes the overall similarity of the chainand the chain members senses are updated.
In thisexample, the interpretation with (C32) is discardedas is the cluster (C34) for recession.
This processingis described in Figure 6.Figure 6: Selection of appropriate senses.4.2.4 Score of a chainOnce all chains have been computed, only thehigh-scoring ones must be picked up as represent-ing the important concepts of the original docu-ment.
Therefore, one must first identify the strongestchains.
Like in (Barzilay and Elhadad, 1997), wedefine a chain score which is defined in Equation 16where |chain| is the number of words in the chain.score(chain) =|chain|?1Xi=0|chain|Xj=i+1simLin(Ci, Cj)(|chain| ?
1)|chain|2(16)As all chains will be scored, the ones with higherscores will be extracted.
Of course, a threshold willhave to be defined by the user.
In the next section,we will show some qualitative and quantitative re-sults of our architecture.5 EvaluationThe evaluation of Lexical Chains is generally diffi-cult.
Even if they can be effectively used in manypractical applications, Lexical Chains are seldomdesirable outputs in a real-world application, andit is unclear how to assess their quality indepen-dently of the underlying application in which theyare used (Budanitsky and Hirst, 2006).
For example,in Summarization, it is hard to determine whether agood or bad performance comes from the efficiencyof the lexical chaining algorithm or from the appro-priateness of using Lexical Chains in that kind ofapplication.
It is also true that some work has beendone in this direction (Budanitsky and Hirst, 2006)by collecting Human Lexical Chains to compareagainst automatically built Lexical Chains.
How-ever, this type of evaluation is logistically impos-sible to perform as we aim at developing a systemthat does not depend on any language or topic.
So,in this section, we will only present some resultsgenerated by our architecture (like (Barzilay and El-hadad, 1997; Teich and Fankhauser, 2004) do), al-though we acknowledge that other comparative eval-uations (with WordNet, with Human Lexical Chainsor within independent applications like Text Sum-marization) must be done in order to draw definitiveconclusions.We have generated four taxonomies from four dif-ferent domains (Sport, Economy, Politics and War)from a set of documents of the DUC 200415.
More-over, we have extracted Lexical Chains for all four15http://duc.nist.gov/duc2004/44domains to show the ability of our system to switchfrom domain to domain without any problem.5.1 Quantitative FunctionFour texts from each domain of the DUC 2004 cor-pus have been used to extract Lexical Chains basedon the four knowledge bases built from all texts ofDUC 2004 for each one of the four following do-mains: Sport, Economy, Politics and War.
However,in this section, we will only present the results fromthe Sport Domain as results show similar behaviorsfor the other domains.
In particular, we present inTable 1 the characteristics of each document.# Words #Distinct Words #Distinct NounsDoc 1 8133 1956 672Doc 2 3823 1630 708Doc 3 4594 953 324Doc 4 4530 1265 431Table 1: Characteristics of Documents for SportThe first interesting conclusion shown in Table 2is that the number of Lexical Chains does not de-pend on the document size but rather on the nominalunits distribution.
Indeed, for example, the numberof words in Document 1 is twice as big as in Doc-ument 2.
Although, we have more Lexical Chainsin Document 2 than in Document 1, as Document 2has more distinct nominal units.c=5 c=6 c=7 c=8Doc 1 27 43 73 73Doc 2 31 52 81 83Doc 3 28 40 51 51Doc 4 29 53 83 87Table 2: # Lexical Chains per DocumentThe second interesting conclusion is that our algo-rithm does not gather words that belong to only onecluster and take advantage of the automatically builtlexico-semantic knowledge base.
This is illustratedin Table 3.
However, it is obvious that by increasingthe constant c the words in a chain tend to belong toonly one cluster as it is the case for most of the bestLexical Chains with c = 8.5.2 Qualitative EvaluationIn this section, as it is done in (Barzilay and Elhadad,1997; Teich and Fankhauser, 2004), we present thec=5 c=6 c=7 c=8Doc 1 19 13 7 7Doc 2 13 6 3 3Doc 3 3 4 4 4Doc 4 6 4 3 3Table 3: # Clusters per Lexical Chainfive highest-scoring chains for the best threshold thatwe experimentally evaluated to be c = 7 for eachdomain (See Tables 4, 5, 6, 7).
It is clear that theobtained Lexical Chains show a desirable degree ofrepresentativeness of the text in analysis.Domain=Sport, Document=3, c=7- #0, 1 cluster and score=1.0: {United States, couple, competition}- #6, 3 clusters and score=1.0: {boats, Sunday night, sailor, Sword, Orion,veteran, cutter, Winston Churchill, Solo Globe, Challenger, navy, Race, sup-position, instructions, responsibility, skipper, east, Melbourne, deck, kilo-meter, masts, bodies, races, GMT, Admiral?s, Cups, Britain, Star, Class,Atlanta, Seattle, arms, fatality, sea, waves, dark, yacht?s, Dad, Guy?s, son,Mark, beer, talk, life, Richard, Winning, affair, canopy, death}- #9, 1 cluster and score=1.0: {record, days, hours, minutes, rescue}- #16, 3 clusters and score=1.0: {Snow, shape, north, easters, thunder,storm, change, knots, west, level, maxi?s, search, Authority, seas, helicopter,night vision, equipment, feet, rescues, Campbell, suffering, hypothermia,safety, foot, sailors, colleagues, Hospital, deaths, bodies, fatality}- #19, 2 clusters and score=1.0: {challenge, crew, Monday, VC, Offshore,Stand, Newcastle, mid morning, Eden, Rescuers, aircraft, unsure, where-abouts, killing, contact}Table 4: 5 best Lexical Chains for SportDomain=Economy, Document=5, c=7- #88, 4 clusters and score=1.0: {sign, chance, Rio, Janeiro, Grande, Sul,uphill, promise, hospitals, powerhouse, success, inhabitants, victory, pad,presidency, contingent, exit, legislature}- #50, 1 cluster and score=1.0: {transactions, taxes, Stabilization, spate,fuel, income, fortunes, means}- #77, 1 cluster and score=1.0: {proposal, factory, owners, Fund, Rubin?s}- #126, 1 cluster and score=1.0: {disaster, control, investment, review}- #12, 2 clusters and score=0.99: {issue, order, University, population, ques-tion, timing, currencies}Table 5: 5 best Lexical Chains for EconomyFor instance, the Lexical Chain #16 in the domainof Sport clearly exemplifies the tragedy of climbersthat were killed in a sudden change of weather inthe mountains and who could not be rescued by theauthorities.However, some Lexical Chains are less expres-sive.
For instance, it is not clear what the LexicalChain #40 expresses in the domain of Politics.
In-deed, none of the words present in the chain seem45Domain=Politics, Document=3, c=7- #5, 1 cluster and score=1.0: {report, leaders, lives, information}- #33, 1 cluster and score=1.0: {past, attention, defenders, investigations}- #28, 2 clusters and score=0.95: {investigators, hospital, ward, wounds,neck, description, fashion, suspects, raids, assault, rifles, door, further de-tails, surgery, service, detective, Igor, Kozhevnikov, Ministry}- #40, 2 clusters and score=0.92: {security, times, weeks, fire}- #24, 3 clusters and score=0.85: {enemies, Choice, stairwell, assailants,woman, attackers, entrance, car, guns, Friends, relatives, Mrs. Staravoitova,founder, movement, well thought, Sergei, Kozyrev, Association, Societies,supporter, Stalin?s, council, criminals, Yegor, Gaidar, minister, ally, sugges-tions, measures, smile, commitment}Table 6: 5 best Lexical Chains for PoliticsDomain=War, Document=1, c=7- #25, 2 clusters and score=1.0: {lightning, advance, Africa?s, nation,outskirts, capital Kinshasa, troops, Angola, Zimbabwe, Namibia, chunk,routes, Katanga, Eastern, Kasai, provinces, copper}- #53, 1 cluster and score=1.0: {Back, years, Ngeyo, farm, farmers, organi-zation, breadbasket, quarter, century, businessman, hotels, tourist, memory,rivalry, rebellions}- #56, 1 cluster and score=1.0: {political, freedoms, Hutus, Mai-Mai, war-riors, Hunde, Nande, militiamen, Rwanda, ideology, weapons, persecu-tion, landowners, ranchers, anarchy, Safari, Ngezayo, farmer, hotel, owner,camps}- #24, 2 clusters and score=0.87: {fighting, people, leaders, diplomats,cause, president, Washington, U.S, units, weeks}- #51, 2 clusters and score=0.82: {West, buildings, sight, point, tourists,mountain, gorillas, shops, guest, disputes}Table 7: 5 best Lexical Chains for Warto express any idea about Politics.
Moreover, dueto the small number of inter-related nominal unitswithin the Lexical Chain, this one can not be under-stood as it is without context.
In fact, it was relatedto problems of car firing that have been occurring inthe past few weeks and provoked security problemsin the town.Although some Lexical Chains are understand-able as they are, most of them must be replaced intheir context to fully understand their representative-ness of the topics or subtopics of the text being an-alyzed.
As a consequence, we deeply believe thatLexical Chains must be evaluated in the context ofNatural Language Processing applications (such asText Summarization (Doran et al, 2004)), as com-paring Lexical Chains as they are is a very difficulttask to tackle which may even lead to inconclusiveresults.6 Conclusions and Future WorkIn this paper, we implemented a greedy Language-Independent algorithm for building Lexical Chains.For that purpose, we first constructed a lexico-semantic knowledge base by applying the Pole-Based Overlapping Clustering algorithm (Cleuziouet al, 2004) to word-context vectors obtained by theapplication of the SCP (., .)
measure (Silva et al,1999) and the InfoSimBA(., .)
(Dias and Alves,2005) similarity measure.
In a second step, we im-plemented (Lin, 1998)?s similarity measure and usedit to define the relatedness criterion in order to as-sign a given word to a given chain in the lexicalchaining process.
Finally, our experimental eval-uation shows that relevant Lexical Chains can beconstructed with our lexical chaining algorithm, al-though we acknowledge that more comparative eval-uations must be done in order to draw definitive con-clusions.
In particular, in future work, we want tocompare our methodology using WordNet as the ba-sic knowledge base, implement different similaritymeasures (Resnik, 1995; Jiang and Conrath, 1997;Leacock and Chodorow, 1998), experiment differ-ent Lexical Chains algorithms (Hirst and St-Onge,1997; Barzilay and Elhadad, 1997; Galley andMcK-eown, 2003), scale our greedy algorithm for real-world applications following (Silber and McCoy,2002) ideas and finally evaluate our system in inde-pendent Natural Language Processing applicationssuch as Text Summarization (Doran et al, 2004).ReferencesR.
Barzilay andM.
Elhadad.
1997.
Using Lexical Chainsfor Text Summarization.
Proceedings of the Intelli-gent Scalable Text Summarization Workshop (ISTS-97), ACL, Madrid, Spain, pages 10-18.I.
Bomze, M. Budinich, P. Pardalos, andM.
Pelillo.
1999.The Maximum Clique Problem.
Handbook of Com-binatorial Optimization, volume 4.
Kluwer Academicpublishers, Boston, MA.T.
Brants.
2000.
TnT - a Statistical Part-of-Speech Tag-ger.
In Proceedings of the 6th Applied NLP Confer-ence, ANLP-2000.
Seattle, WA.A.
Budanitsky and G. Hirst.
2006.
Evaluating WordNet-based Measures of Lexical Semantic Relatedness.
InComputational Linguistics, 32(1).
pages: 13-47.L.
Cicurel, S. Bloehdorn and P. Cimiano.
2006.
Cluster-ing of Polysemic Words.
In Advances in Data Analysis- 30th Annual Conference of the German Classifica-tion Society (GfKl).
Berlin, Germany, March 8-10.46G.
Cleuziou, L. Martin, and C. Vrain.
2004.
PoBOC:an Overlapping Clustering Algorithm.
Application toRule-Based Classication and Textual Data.
In Pro-ceedings of the 16th European Conference on Artifi-cial Intelligence, pages 440-444, Spain, August 22-27.G.
Cleuziou, V. Clavier, L. Martin.
2003.
Une Me?thodede Regroupement de Mots Fonde?e sur la Recherche deCliques dans un Graphe de Cooccurrences.
In Pro-ceedings of Rencontres Terminologie et IntelligenceArtificielle, France.
pages 179-182.B.
Daille.
1995.
Study and Implementation of CombinedTechniques for Automatic Extraction of Terminology.In The balancing act combining symbolic and statisti-cal approaches to language.
MIT Press.G.
Dias and E. Alves.
2005.
Unsupervised Topic Seg-mentation Based on Word Co-occurrence and Multi-Word Units for Text Summarization.
In Proceedingsof the ELECTRA Workshop associated to 28th ACMSIGIR Conference, Salvador, Brazil, pages 41-48.G.
Dias, S. Guillore?
and J.G.P.
Lopes.
1999.
LanguageIndependent Automatic Acquisition of Rigid Multi-word Units from Unrestricted Text Corpora.
In Pro-ceedings of 6th Annual Conference on Natural Lan-guage Processing, Carge`se, France, pages 333-339.W.
Doran, N. Stokes, J. Carthy and J. Dunnion.
2004.Assessing the Impact of Lexical Chain Scoring Meth-ods and Sentence Extraction Schemes on Summariza-tion.
In Proc.
of the 5th Conference on Intelligent TextProcessing and Computational Linguistics.V.
Estivill-Castro, I. Lee, and A. T. Murray.
2001.
Crite-ria on Proximity Graphs for Boundary Extraction andSpatial Clustering.
In Proceedings of the 5th Pacific-Asia Conference on Knowledge Discovery and DataMining, Springer-Verlag.
pages 348-357.C.D.
Fellbaum.
1998.
WordNet: An Electronic LexicalDatabase.
MIT Press, New York.W.
Gale, K. Church, and D. Yarowsky.
1992.
One Senseper Discourse.
In Proceedings of the DARPA Speechand Natural Language Workshop.M.
Galley and K. McKeown.
2003.
Improving WordSense Disambiguation in Lexical Chaining.
In Pro-ceedings of 18th International Joint Conference on Ar-tificial Intelligence (IJCAI?03), Acapulco, Mexico.G.
Hirst and D. St-Onge.
1997.
Lexical Chains as Repre-sentation of Context for the Detection and Correctionof Malapropisms.
In WordNet: An electronic lexicaldatabase and some of its applications.
MIT Press.J.W.
Jaromczyk and G.T.
Toussaint.
1992.
RelativeNeighborhood Graphs and Their Relatives.
P-IEEE,80, pages 1502-1517.J.J.
Jiang and D.W. Conrath.
1997.
Semantic SimilarityBased on Corpus Statistics and Lexical Taxonomy.
InProceedings of International Conference on Researchin Computational Linguistics, Taiwan.R.
Krovetz.
1998.
More than One Sense per Discourse.NEC Princeton NJ Labs., Research Memorandum.C.
Leacock and M. Chodorow.
1998.
Combining LocalContext and WordNet Similarity for Word Sense Iden-tification.
In C. Fellbaum, editor, WordNet: An elec-tronic lexical database.
MIT Press.
pages 265-283.D.
Lin.
1998.
An Information-theoretic Definition ofSimilarity.
In 15th International Conference on Ma-chine Learning.
Morgan Kaufmann, San Francisco.G.
Miller.
1995.
WordNet: An Lexical Database for Eng-lish.
Communications of the Association for Comput-ing Machinery (CACM), 38(11), pages 39-41.J.
Morris and G. Hirst.
1991.
Lexical Cohesion Com-puted by Thesaural Relations as an Indicator of theStructure of Text.
Computational Linguistics, 17(1).P.
Pantel and D. Lin.
2002.
Discovering WordSenses from Text.
In Proceedings of the EighthACM SIGKDD International Conference on Knowl-edge Discovery and Data Mining.
pages 613-619.P.
Resnik.
1995.
Using Information Content to EvaluateSemantic Similarity.
In Proceedings of the 14th In-ternational Joint Conference on Artificial Intelligence,Montreal.
pages 448-453.P.M.
Roget.
1852.
Roget?s Thesaurus of English Wordsand Phrases.
Harlow, Essex, England: Longman.G.
Salton, C.S.
Yang and C.T.
Yu.
1975.
A Theoryof Term Importance in Automatic Text Analysis.
InAmerican Society of Information Science, 26(1).G.
Silber and K. McCoy.
2002.
Efficiently ComputedLexical Chains as an Intermediate Representation forAutomatic Text Summarization.
Computational Lin-guistics, 28(4), pages 487-496.J.
Silva, G. Dias, S. Guillore?
and J.G.P.
Lopes.
1999.
Us-ing LocalMaxs Algorithm for the Extraction of Con-tiguous and Non-contiguous Multiword Lexical Units.In Proceedings of 9th Portuguese Conference in Arti-ficial Intelligence.
Springer-Verlag.P.
H. A. Sneath and R. R. Sokal.
1973.
Numerical Taxon-omy - The Principles and Practice of Numerical Clas-sification.
San Francisco, Freeman and Co.E.
Teich and P. Fankhauser.
2004.
Exploring Lexical Pat-terns in Text: Lexical Cohesion Analysis with Word-Net.
In Proceedings of the 2nd International WordnetConference, Brno, Czech Republic.
pages 326-331.47
