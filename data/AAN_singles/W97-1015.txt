A Comparative Study of the Application of DifferentLearning Techniques to Natural Language InterfacesWerner Winiwarter and Yahiko KambayashiDept.
of Information ScienceKyoto UniversitySakyo, Kyoto 606-01, Japan{ww I yahiko}?kuis, kyoto-u, ac.
jpAbstractIn this paper we present first results froma comparative study.
Its aim is to testthe feasibility of different inductive learn-ing techniques to perform the automaticacquisition of linguistic knowledge within anatural anguage database interface.
In ourinterface architecture the machine learn-ing module replaces an elaborate semanticanalysis component.
The learning modulelearns the correct mapping of a user's inputto the corresponding database commandbased on a collection of past input data.We use an existing interface to a produc-tion planning and control system as evalu-ation and compare the results achieved bydifferent instance-based and model-basedlearning algorithms.1 IntroductionOne of the main obstacles to the efficient use of nat-ural language interfaces is the often required highamount of manual knowledge ngineering (see (An-droutsopoulos etal., 1995) for a recent survey).
Thistime-consuming and tedious process is often referredto as "knowledge acquisition bottleneck".
It may re-quire extensive fforts by experts highly experiencedin linguistics as well as in the domain and the task(Riloff and Lehnert, 1994).
Therefore, natural an-guage interfaces represent a domain that is very wellsuited for the application of machine learning algo-rithms to automate the acquisition process of lin-guistic knowledge.So far, inductive learning has already been ap-plied successfully to a large variety of natural Jan-guage tasks.
This includes basic linguistic problemssuch as morphological nalysis (van den Bosch etal., 1996), parsing (Zelle and Mooney, 1996), wordsense disambiguation (Mooney, 1996), and anaphoraresolution (Aone and Bennett, 1996).
Besides this,there also exists some research on applications, e.g.machine translation (Yamazaki et al, 1996), textcategorization (Moulinier and Ganaseia, 1996), orinformation extraction (Soderland et al, 1996).The learning task in natural anguage interfaces ito select he correct command class based on seman-tic features extracted from the user input.
There-fore, it can be modeled as classification problem, i.e.the machine learning algorithms construct a theoryfrom the training data that is used for classifyingunseen test data (Quinlan, 1996).
So far, we con-sider only supervised learning so that each trainingcase has to be labeled with the correct class.We apply different existing instance-based andmodel-based algorithms to this problem and com-pare the achieved results.
In addition, we havealso developed several new algorithms, which wepresent briefly in this paper.
We have implementedall algorithms by means of the deductive object-oriented database system ROCK ~ ROLL (Barjaet al, 1994).It solves the problem of updates in deductivedatabases in that it separates the declarative logicquery language ROLL from the imperative data ma-nipulation language ROCK within the context of acommon object-oriented data model.
Besides this,ROCK ~ ROLL makes a clean distinction betweentype declarations, which describe the structural char-acteristics of a set of instance objects and the meth-ods that can be applied to them, and class defini-tions, which specify the implementation f the meth-ods associated with a type.The use of the available powerful logic and object-oriented programming language nables an efficientimplementation of the different approaches to ma-chine learning.
It also gives us a convenient in-tegrated tool that assists in applying the machinelearning algorithms to the data collection stored inthe same database.Winiwarter ~ Kambayashi 125 Learning and NL InterfacesWerner Winiwarter and Yahiko Kambayashi (1997) A Comparative Study of the Appl icat ion of DifferentLearning Techniques to Natural Language Interfaces.
In T.M.
Ellison (ed.)
CoNLL97: ComputationalNatural Language Learning, ACL pp 125-135.
(~) 1997 Association for Computational LingtfisticsUser inputand lexical analysis and lexical analysis ~ I.o.
d l exical analysi__, _ sUVL analysis .
!ML classifierI Database commandgenerationDatabase commandFigure 1: System architecture ofnatural language interfaceAs comparative valuation of the implementedalgorithms, we applied them to an extensive casestudy: a natural language interface for a productionplanning and control system.
The system is usedin a multilingual environment, which includes thelanguages English, German, and Japanese.
There-fore, an important issue of the evaluation was tocheck whether the learned knowledge is language-independent, i.e.
if it really operates based on se-mantic deep forms so that it abstracts from linguisticsurface phenomena.The rest of the paper is organized as follows.First, we briefly introduce the learning task beforewe present he applied machine learning algorithmsin more detail.
Finally, we explain the set-up ofthe case study and discuss the achieved results fromevaluation.2 Learn ing  TaskOur interface architecture is displayed in Fig.
1.
Itrepresents a multilingual database interface for thelanguages English, German, and Japanese.
First,the language of the user input is detected and theinput is transferred to the corresponding language-specific morphological nd lexical analyzer.Morphological and lexical analysis performs thetokenization of the input, i.e.
the segmentation intoindividual words or tokens.
This task is not alwaystrivial as in the case of Japanese, which uses nospaces for separating words.
As next step the inputis transformed into a deep form list (DFL), whichindicates for each token its surface form, category,and semantic deep form.For database interfaces, unknown values con-tained in the input possess particular importancefor the meaning of a command.
Therefore, we treatthose unknown values separately in the unknownvalue list (UVL) analyzer.
This module checks thedata type of unknown values and looks them up inthe database to find out whether they represent iden-tifiers of existing entities.
In such a case, the entitytype is indicated in the resulting UVL, otherwise weuse the data type instead.DFL and UVL represent the input to the machinelearning (ML) classifier.
It assigns a ranked listof command classes to the input sentence accord-ing to the learned classification rules.
As last stepthe classifications are used for generating appropri-Winiwarter ~ Kambayashi 126 Learning and NL InterfacesInputDFLUVLNew purchase price St 37 H kostet nun St37Hg) l l~.Xd'~rof St 37 H is 1,7.
1.7 Schining 1, 7 \ [ : .~ _ ?.e ~ k ~,newpurchasepriceofbe1 material1 realcostnowschilling1 material1 realpurchasepricechange1 material1 realFigure 2: Example of feature encodingate database commands.For the encoding :of the training data we only makeuse of the semantic deep forms contained in the DFL.We use English concepts as deep forms and mapthem to binary features, i.e.
a certain feature qualsI if the deep form is a member of the DFL, otherwiseit equals 0.
For the elements of the UVL we applya more detailed encoding, which maps the numberand the type to binary features.
Figure 2 shows anexample of the features derived from English, Ger-man, and Japanese input sentences for the updateof the purchase price for a material.Thus, the learning task replaces an elaborate se-mantic analysis of the user input.
The developmentof the corresponding underlying rule base might re-quire several man-months.
The learning task rep-resents a realistic real-life application, which differsfrom many other problems tudied in machine learn-ing research in that it consists of a large numberof features and classes.
Furthermore, the commandclasses are often very similar and even for humanexperts very difficult to distinguish.3 Learn ing  A lgor i thmsIns tance-based  Learn ingInstance-based approaches represent the learnedknowledge simply as collection of training cases orinstances.
For that purpose they use the same lan-guage as for the description of the training data(Quinlan, 1993a).
A new case is then classified byfinding the instance with the highest similarity andusing its class as prediction.
Therefore, instance-based algorithms are characterized by a very lowtraining effort.
On the other hand, this leads to ahigh storage requirement because the algorithm hasto keep all training cases in memory.
Besides this,one has to compare new cases with all existing in-stances, which results in a high computation cost forclassification.Different instance-based algorithms Vary in howthey assess the similarity (or distance) between twoinstances.
Two very commonly used methods areIB1 (Aha et al, 1991) and IBI- IG (Daelemans andvan den Bosch, 1992).
Whereas IB1 applies the sim-ple approach of treating all features as equally im-portant, IBI-IG uses the information gain (Quinlan,1986) of the features as weighting function.We have developed an algorithm called BIN-CATfor binary features with class-dependent weightingand asymmetric treatment of the feature values.
Thesimilarity between a new case X and a trainingcase Y is calculated according to the following for-mula:SIMx,y =nEp (D,, Cy) .
w, .
o" (x,, Yi) -i----1nEp (D,, Cy) " w, .
5y (x,, y,) -i=1ni= l(1)In this formula, n indicates the number of fea-tures, Di the number of instances that have value 1for feature i, and Cy the class of the training case Y.The term p(Di, Cy) then denotes the proportion ofinstances in Di that belong to class Cy.
o'(xl,yi),~Y(a~i, yi), and 5x(zi ,  yi) are determined as follows:1 i fx i=  1Ay i  = 1o" (xi, Yi) = 0 otherwise1 i fx i=OAy i= lY (xi,Yi) = 0 otherwiseWiniwarter ~ Kambayashi 127 Learning and NL Interfaces1 i f z~=lAy i=O5x(~i,yi) = 0 otherwise (2)so that the second sum in (1) is rated higher fora larger number of occurrences of the ith featurefor class Cy whereas the third sum is rated lower.This means that if the training case Y contains acertain feature and the new case X does not, thenwe rate this difference the stronger the more oftenthe feature occurs for class Cy.
On the other hand,for features appearing in the new case X but notin Y, the opposite is true.Finally, wi represents the weight of feature i.
It iscalculated by making use of the following formula:c1 E1  4.p(Di j) \[1 p(Di,j)\] (3) W i ~ - -  .
_ , ?Cj= lThe term under the summation symbol representsthe selectivity of feature i for class j.
It equals 1if either all or none of the cases have value 1 forthis feature.
In other words, all instances for class jthen either possess or do not possess this feature,which makes it a very discriminative characteristic.The Other extreme is that p(Di,j) equals 50%.
Inthat case, this feature allows for no prediction ofthe class and the term under the summation symbolbecomes 0.We have implemented all above-mentioned algo-rithms for binary features in ROCK & ROLL inthat we store the instances as objects and assignto them the features as ordered lists sorted by thefeature numbers.
The calculation of the similaritybetween two cases is then realized as method invo-cation on the feature list.
For example, Fig.
3 showsthe ROCK method to compute the distance betweentwo feature lists according to IS1.Besides pure instance-based learning we have alsodeveloped an algorithm BIN-PRO, which creates aprototype for each class.
Those prototypes are thenused for the comparison with new cases.
This hasthe big advantage that one does not have to storeall the training instances and that the number ofrequired comparisons for classification is reduced tothe number of existing classes.
As similarity func-tion between a new case X and a certain class C weuse the following formula:SIMx,c IDcl.p (D:, C) .w!
-rexEp(Dy ,C I 'w!
?rexWiniwarter 8J KambayashiIn this formula, we give more emphasis to fea-tures f that are present in X in that we multiplythem by lOci, the number of instances for class C.However, the second sum takes also important fea-tures for class C into account that are missing inthe new case X.
As weighting function wl we useagain (3).
The implementation in ROCK ~ ROLL isperformed by creating an object for each prototypeand by invoking the associated method for comput-ing the similarity to a new test case.Mode l -based  Learn ingIn contrast o instance-based learning, model-basedapproaches represent the learned knowledge in a the-ory language that is richer than the language usedfor the description of the training data (Quinlan,1986).
Such learning methods construct explicit gen-eralizations of training cases resulting in a large re-duction of the size of the stored knowledge base andthe cost of testing new test cases.In our research we consider the subtypes of deci-sion trees and rule-based learning as well as hybridapproaches between them.
The main difference be-tween the various methods for constructing decisiontrees is the selection of the feature for splitting anode.
The following two main categories are distin-guished:?
static splitting: selects the best feature for split-ting always on the basis of the complete collec-tion of instances,?
dynamic splitting: re-evaluates the best featurefor splitting for each node based on the currentlocal set of instances.
(4)Static splitting requires less computational effortbecause it performs the feature ranking only oncefor the construction process.
However, it entailsoverhead to keep track of already used features andto eliminate features that provide no proper split-ting of the set of instances.
Besides that, dynamicsplitting methods produce much more compact reeswith fewer nodes, leaves, and levels.
This results ina sharp reduction of the storage requirement as wellas the number of comparisons during classification.We have implemented ecision trees for static(BS-tree) and dynamic splitting (SO-tree) by us-ing the weighting function (3) as ranking schemefor the splitting criterion.
In addition, we havealso implemented the IGTree algorithm (Daelemanset al, 1997), which uses the information gain asstatic splitting criterion, and C~.5 (Quinlan, 1993b),which applies the information gain to dynamicsplitting.
The decision trees are implemented in128 Learning and NL Interfacestype E,featurelist:public \[feature\];ROCK:distance(x: featurelist): int;end-typeclass E.featurelistpublic:distance(x: featurelist): intbeginvar ix: int;var  iy: int;var fx: int;var  fy: int;var dist: int;ix := 1;iy := 1;while (ix <= upper@x) dobeginfx := get_fnr@(l\[ix\]);fy := get_fnr@(get_member at(iy) @self);if (fx = fy) thenbeginix := ix+ 1;i y := iy+ 1;endelsebegindist := dist + 1;if (fx < fy) thenix := ix + 1;elseiy := iy+ 1;endif (ix > upper@x) thenwhile (iy <= upper@self) dobeginiy := iy + 1;dist := dist + 1;endif (iy > upper@self) thenwhile (ix <= upper@x) dobeginix := ix+ 1;dist := dist + 1;endenddistendend-classtype declaration for feature listslist of featuresROCK methodsmethod for calculation of distance tofeature list of new instance Xpersistent class definitionvisibilitymethod for distance calculationindex for instance Xindex for instance Yfeature for instance Xfeature for instance Ycomputed distanceinitialization of index ixinitialization of index iywhile index/xS that of last feature for X doget feature number for instance X at index ixget feature number for instance Y at index iyif same feature, thenincrement indiceselseincrement distanceif feature number for X smaller thanthat for Y, then increment index/xelseincrement index iyif index ix> that of last feature for X, thenwhile index iy~ that of last feature for Y doincrement index iyincrement distanceif index iy> that of last feature for Y, thenwhile index/x~ that of last feature for X doincrement index ixincrement distancereturn distanceFigure 3: ROCK & ROLL code segment for IB1 distance calculationROCK & ROLL by creating an object for each nodeand by linking the nodes according to the tree struc-ture.
The classification of a new case is then simplyperformed as top-down traversal of the tree startingfrom the root.
Besides this exact search we have alsoimplemented an approximate search method, whichallows one incorrect edge along the traversal to finda larger number of similar cases.Rule-based learning represents a second large cat-egory of model-based techniques.
It aims at derivinga set of rules from the instances of the training set.A rule is here defined as a conjunction of literals,which, if satisfied, assigns a class to a new case.
Forthe case of binary features, the literals correspondto feature tests with positive or negative sign.
Thismeans that they check whether a new case possessesa certain feature (for positive tests) or not (for neg-ative tests).The methods for deriving the rules originate fromthe field of inductive logic programming (Muggleton,1992).
One of the most prominent algorithms forrule-based learning is FOIL (Quinlan and Cameron-Jones, 1995), which learns for each class a set ofrules by applying a separate-and-conquer strategy.The algorithm takes the instances of a certain classas target relation.
It iteratively learns a rule and re-moves those instances from the target relation thatare covered by the rule.
This is repeated until no in-Winiwarter 8?
Kambayashi 129 Learning and NL Interfacestype E.literal:properties:public:lift: feature,sign: bool;ROLL:differ(featurelist);end-typeclass E.literalpublic:differ(featurelist)begindiffer(Flist) :-S == geLsign@self,S == true,F == get_lift@self,-is_in(F) @ Flist;differ(Flist) :-S == get_sign @ self,S == false,F == geLlift@self,is_in(F) @ Flist;endend-classtype E.rule:properties:public:rulenr: int,ruleclass: int;public \[literal\];ROLL:differ(featurelist);end-typeclass E.rulepublic:differ(featurelist)begindiffer(Flist) :-is in(L)@self,differ(Flist) @ L;endend-classtype declaration for literalsattributesvisibilityfeaturesign of feature testROLL methodsmethod for performing feature testpersistent class definitionvisibilitymethod for performing feature testretums true if test is not satisfied, otherwise falsetest for positive signget sign of feature testtest if sign is positiveget featuretest if feature is not member of feature listtest for negative signget sign of feature testtest if sign is negativeget featuretest if feature is member of feature listtype declaration for ruleattributesvisibilityrule numberclass of rulelist of literalsROLL methodsmethod for performing test of rulepersistent class definitionvisibilitymethod for performing test of rulereturns true if test is not satisfied, otherwise falseget individual iteralsinvoke method for all literalsFigure 4: ROCK & ROLL code segment for test of rulesstances are left in the target relation.
A rule is grownby repeated specialization, adding literals until therule does not cover any instances of other classes.In other words, the algorithm tries to find rules thatpossess ome positive bindings, i.e.
instances that be-long to the target relation, but no negative bindingsfor instances of other classes.
Therefore, the reasonfor adding a literal is to increase the relative propor-tion of positive bindings.As weighting function for selecting the next literal,FOIL uses the information gain.
We have imple-mented FOIL, and besides this, we also use the algo-rithm BIN-rules with the following weighting func-tion:w1, , , c  = b \ ] .
(b-  - bT) .
?
(5)In this formula, s indicates the sign of the featuretest.
The number of positive (negative) bindingsafter adding the literal for the test of feature f iswritten as b~" (57).
Finally, b- indicates the numberof negative bindings before adding the literal so thatb- - b~ calculates the reduction of negative bindingsachieved by adding the literal.
The weights w1,~,care calculated as class-dependent weights for class Cby making use of the feature weights w!
from (3):wy .
p(D/ ,  C) if s positivew/,,,c = w I ?
\[1 - p(D1, C)\] otherwise .
(6)We have implemented the test of rules as deduc-tive ROLL method as shown in Fig.
4.
The invoca-tion of the method is a query with the parameter f lfor the feature list of the new case.
The test returnsWiniwarter ~ Kambayashi 130 Learning and NL Interfacesfalse for those rules that are satisfied by the newcase.
The result of the query can then be assigned tothe set of satisfied rules rs by using the command:rs := \[{l:t}l,-~diffor(!f l)~l~\] ;.
As in the case ofdecision trees, we have developed an approximatetest, which tolerates one divergent literal.As last group of:model-based algorithms we lookat hybrid approaches between decision trees and rule-based learning.
There exist two ways in principleto combine the advantages of the two paradigms.The first one is to extract rules from a decision treewhereas the second one follows the opposite direc-tion by constructing a decision tree from a rule base.As example of the first type of approach we haveimplemented C~.
5-R ULES (Quinlan, 1993b), whichextracts rules from the decision tree built by C4.5.Rules are computed as paths along the traversalfrom the root to all'leaves.
In a second run, rules arepruned by removing redundant literals and rules.Regarding the second type of approach, we startfrom the rule base:produced by BIN-rules and useit for building an SE-tree (Rymon, 1993).
SE-treesare a generalization of decision trees in that theyallow not only one but several feature tests at onenode.
Therefore, a much flatter and more compacttree structure is achieved.
For the construction ofthe tree we sort the feature tests of the rules first.Starting from a root node, we then construct pathsaccording to the literals of the individual rules.
Forthis process we make use of existing paths as far aspossible before creating new branches.4 Eva luat ionAs case study for investigating the feasibility of theimplemented machine learning algorithms, we use amultilinguM natura !
language interface to a produc-tion planning and control system (PPC).
The PPCperforms the mean-term scheduling of products andresources involved in the manufacturing processes,i.e.
material, machines, and labor.
The resultingmaster production schedule forms the basis of thecoordination of related business ervices uch as en-gineering, manufacturing, and finance.
The modeledenterprise makes precision tools by using job orderproduction and serial manufacture as basic strate-gies.
The efficient realization of the high demandsof the application exceeds the power of relationaldatabase technology.
Therefore, it represents anexcellent choice for deriving full advantage of theextended functionality of deductive object-orienteddatabase systems, iFurthermore, the sophisticatedfunctionality justifies the effective use of a naturallanguage interface.During previous research (Winiwarter, 1994) wedeveloped a German natural language interfacebased on 1000 input sentences that had been col-lected from users by means of questionnaires.
Theinput sentences were then mapped to 100 commandclasses (10 for each class).
The mapping was per-formed by elaborate semantic analysis; for the devel-opment of the underlying rule base we spent severalman-months.Therefore, we were eager to see if we could replacethis extensive ffort by a machine learning compo-nent that learns the same linguistic knowledge auto-matically.
For this purpose we divided the 1000 sen-tences into 900 training cases and 100 test cases.
Inaddition, we collected 100 Japanese and 100 Englishtest sentences to check whether the learned knowl-edge really operates at a semantic level independentfrom language-specific phenomena.As result of the encoding of the training set (seeSect.
2), we obtained the large number of 316 fea-tures, 289 for the DFL and 27 for the UVL.
Forthe evaluation of the different machine learning algo-rithms we used as performance measures the successrate, i.e.
the proportion of correctly classified testcases, and the top-3 rate.
The latter indicates theproportion of cases where the correct classificationis among the first three predicted classes.
For thecase of model-based approaches we had to produceadditional candidates for classes.
This was achievedby applying approximate methods that allow one in-correct edge along the traversal of decision trees orone divergent literal for the test of rules (see Sect.
3).Our first experiment was the comparison of thefour instance-based algorithms IB1, IBi-IG, BIN-CAT, and BIN-PRO.
As can be seen from the resultsin Table 1, BIN-CAT clearly outperforms IB1 andIBi-IG.
Concerning the method BIN-PRO, whichuses prototypes of classes, we achieved results at thesame quality level as for BIN-CAT.
This is remark-able if one considers the much more condensed rep-resentation of the learned knowledge.The comparison between the results for the indi-vidual languages hows that there is no advantagefor the German test sentences.
On the contrary,the test results for German are inferior to that forEnglish or Japanese.
This may be partly due toa greater deviation of the German expressions andphrases used in the test set from the ones used inthe training set.
Besides this, the restriction of ex-tracted features during encoding the test set to thoselearned from the training set certainly performs animportant filtering function.
It removes language-specific syntactic particles that do not contribute tothe meaning Of the input.
This is especially truefor the case of Japanese sentences, which possess aWiniwarter ~ I(ambayashi 131 Learning and NL InterfacesIB1IBI-IGBIN-CATBIN-PROIGTreeBS-treeC4.5BD-treeSE-treeGERMANSuccess rate I 'lbp-3 rate82% I 94%84 % 98 %94 % 100 %95 % 100 %ENGLISHSuccess rate 'lbp-3 rate98 % 99 %97 % 100 %99 % 100 %97 % 100 %J A PAN ES ESuccess rate 'lbp-3 rate94 % 98 %90 % 99 %99 % 100 %97 % 100 %Table 1: Test results for instance-based learningGERMANSuccess rate Top-3 rate80% 94%86 % 97 %94 % 100 %93 % 99 %94 % 97 %ENGLISHSuccess rate rlbp-3 rate92 % I00 %95 % 100 %94 % 100 %94 % 99 %96 % 97 %JAPANESESuccess rate Top-3 rate86 % 97 %90 % 96 %89 % 100 %91% 99 %91% 95 %Table 2: Test results for decision treescompletely different syntactic structure in compari-son with English or German including many parti-cles with no equivalent words in the other two lan-guages.The second part of the evaluation was the com-parison of the four algorithms for building decisiontrees: IGTree, BS-tree, C4.5, and BD-tree.
Besidesthis, we also included the SE-tree constructed by ahybrid approach (see Sect.
3).
The test results in Ta-ble 2 indicate that the trees with dynamic splittingare superior to those with static splitting and thatC4.5, BD-tree, and SE-tree produce results of simi-lar quality.
Table 3 compares the number of nodes,leaves, and levels for the individual trees.
The twotrees with dynamic splitting are much more compactthan those with static splitting, with C4.5 clearlyoutperforming BD-tree.
Finally, the hybrid SE-treeis much flatter than C4.5 but possesses a larger num-ber of nodes and leaves.Nodes Leaves LevelsIGTree 865 433 33BS-tree 719 360 86C4.5 339 170 26BD-tree 451 226 52SE-tree 559 209 8Table 3: Characteristics for decision treesAs last part of our comparative study we testedthe rule-based techniques FOIL, BIN-rules, and thehybrid approach C4.5-RULES.
As Table 4 shows,FOIL produces the most compact representation flearned knowledge, followed by C4.5-RULES andBIN-rules.
However, according to Table 5 both BIN-rules and C4.5-RULES outperform FOIL with al-most identical results.Rules Literals Max.
lengthFOIL 215 534 5BIN-rules 209 726 7C4.5-1~U LES 167 677 24Table 4: Characteristics for rule-based learningAn advantage of rule-based learning in compari-son with other methods is that the learned knowl-edge can be easily presented to the user in a clearand understandable form.
The derived rules allow atransparent knowledge representation that one canuse for explaining decisions of the system to the user.Figure 5 gives some examples of rule sets learned byBIN-rules for several command classes.If we take a final look at Table 1, Table 2, andTable 5, we can see that independent from the ap-plied machine learning paradigm the achieved resultsreached satisfactory quality for all three groups.
Byconsidering the three best representatives BIN-CAT,C4.5, and BIN-rules, we obtain an average successrate for all three languages of 94.3 % and a top-3 rateof 98.8 %.
This result is surprisingly high if one con-siders the complexity of the task at hand.
Unfortu-nately, we had no possibility of a direct comparisonwith the results of the hand-engineered interface be-cause the previous interface had been developed onlyfor German based on the complete collection of 1000sentences by using a different software.
In any case,we could show that machine learning represents asound alternative to manual knowledge acquisitionfor the application in natural anguage interfaces.Winiwarter ~4 Kambayashi 132 Learning and NL InterfacesFOILBIN-rulesC4.5-RULESGERMANSuccess rate 'lbp-3 rate85 % 97 %94% 97%94 % 98 %ENGLISHSuccess rate i 'lbp-3 rate92 % 97 %95 % 97 %94 % 96 %J A PAN ES ESuccess rate 'lbp-3 rate88 % 96 %91% 95 %91% 96 %Table 5: Test results for rule-based learningClass descriptionupdate of purchase pricefor materialliquidation of stock for productUpdate of salary for operatorlist of product orders groupedby statusquery of master data foroperatorRule set1 material AND 1 reali product AND liquidate1 product AND stockI operator AND 1 realI operator AND salary1 operator AND earnstatus AND product order1 operator AND aboutI operator AND data AND NOT stoppageFigure 5: Examples of learned rules5 ConclusionIn this paper we have presented first results froma comparative study of applying different inductivelearning techniques to natural anguage interfaces.We have implemented a representative s lection ofinstance-based and model-based algorithms by mak-ing use of deductive object-oriented database func-tionality.
The extensive case study for an inter-face to a production planning and control systemshows the feasibility of the approach in that linguis-tic knowledge is learned the acquisition of which nor-mally takes a large effort of human experts.Future work will concentrate on the importantpoint of increasing: the reliability of test results inthat we apply cross-validation trials and statisticaltests for the significance of performance differencesbetween two algorithms.
Furthermore, we also wantto generate l arning functions that plot success ratesas function of the size of the training collection.
Be-sides this, we plan to test our learning algorithms onstandard benchmark machine learning datasets andother typical natural anguage learning datasets.Finally, we intend to extend the implemented al-gorithms to include also unsupervised methods aswell as connectionist and evolutionary techniques.In addition, we will implement incremental learningtechniques, which continue the learning process dur-ing the test phase, and adaptive boosting methods,which apply several classifiers instead of just one.We believe that our study is a first promising steptowards the challenging task of carrying out compar-ative evaluations ofthe performance ofdifferent ma-chine learning algorithms for specific linguistic prob-lems.ReferencesDavid W. Aha, Dennis Kibler, and Marc Albert.1991.
Instance-based learning algorithms.
Ma-chine Learning, 7:37-66.Ioannis Androutsopoulos, Graeme D. Ritchie, andPeter Thanisch.
1995.
Natural anguage inter-faces to databases - - an introduction.
Journalof Natural Language Engineering, 1(1) :29-81.Chinatsu Aone and Scott W. Bennett.
1996.
Apply-ing machine learning to anaphora resolution.In S. Wermter, E. Riloff, and G. Scheler, ed-itors, Connectionist, Statistical, and SymbolicWiniwarter ~ Kambayashi 133 Learning and NL InterfacesApproaches to Learning for Natural LanguageProcessing, pages 302-314.
Springer-Verlag,Berlin, Germany.Maria L. Barja, Norman W. Paton, Alvaro A.A.Fernandes, M. Howard Williams, and AndrewDinn.
1994.
An effective deductive object-oriented database through language integra-tion.
In Proceedings of the 20th InternationalConference on Very Large Data Bases, pages463-474, Athens, Greece.
Morgan Kaufmann,San Mateo, California.Walter Daelemans and Antal van den Bosch.
1992.Generalisation performance of backpropaga-tion learning on a syllabification task.
InM.
Drossaers and A. Nijholt, editors, TWLT3:Connectionism and Natural Language Process-ing, pages 27-37.
Twente University Press, En-schede, Netherlands.Walter Daelemans, Antal van den Bosch, and TonWeijters.
1997.
IGTree: Using trees for com-pression and classification in lazy learning al-gorithms.
Artificial Intelligence Review.
Toappear.Raymond J. Mooney.
1996.
Comparative xperi-ments on disambiguating word senses: An il-lustration of the role of bias in machine learn-ing.
In Proceedings of the Conference on Em-pirical Methods in Natural Language Process-ing, pages 82-91, Philadelphia, Pennsylvania,May.Isabelle Moulinier and Jean-Gabriel Ganascia.
1996.Applying an existing machine learning algo-rithm to text categorization.
In S. Wermter,E.
Riloff, and G. Scheler, editors, Connec-tionist, Statistical, and Symbolic Approachesto Learning for Natural Language Processing,pages 343-354.
Springer-Verlag, Berlin, Ger-many.Stephen Muggleton, editor.
1992.
Inductive LogicProgramming.
Academic Press, London, Eng-land.J.
Ross Quinlan.
1986.
Induction of decision trees.Machine Learning, 1:81-206.J.
Ross Quinlan.
1993a.
Combining instance-based and model-based learning.
In Proceed-ings of the lOth International Conference onMachine Learning, pages 236-243, Amherst,Massachusetts.
Morgan Kaufmann, San Ma-teo, California.J.
Ross Quinlan.
1993b.
C4.5: Programs for Ma-chine Learning.
Morgan Kaufmann, San Ma-teo, California.J.
Ross Quinlan and R. Michael Cameron-Jones.1995.
Induction of logic programs: FOIL andrelated systems.
New Generation Computing,13:287-312.J.
Ross Quinlan.
1996.
Learning first-order defini-tions of functions.
Journal of Artificial Intel-ligence Research, 5:139-161.Ellen Riloff and Wendy Lehnert.
1994.
Informationextraction as a basis for high-precision textclassification.
ACM Transactions on Informa-tion Systems, 12(3):296-333.Ron Rymon.
1993.
An SE-tree-based characteri-zation of the induction problem.
In Proceed-ings of the lOth International Conference onMachine Learning, pages 268-275, Amherst,Massachusetts.
Morgan Kaufmann, San Ma-teo, California.Stephen Soderland, David Fisher, Jonathan Asel-tine, and Wendy Lehnert.
1996.
Issues ininductive learning of domain-specific text ex-traction rules.
In S. Wermter, E. Riloff, andG.
Scheler, editors, Connectionist, Statisti-cal, and Symbolic Approaches to Learning forNatural Language Processing, pages 290-301.Springer-Verlag, Berlin, Germany.Antal van den Bosch, Walter Daelemans, and TonWeijters.
1996.
Morphological analysis as clas-sification: An inductive-learning approach.
InProceedings of the Second International Con-ference on New Methods in Language Process-ing, Ankara, Turkey, September.Werner Winiwarter.
1994.
The Integrated DeductiveApproach to Natural Language Interfaces.
PhDthesis, University of Vienna, Austria.Takefumi Yamazaki, Michael J. Pazzani, andChristopher Merz.
1996.
Acquiring and updat-ing hierarchical knowledge for machine trans-lation based on a clustering technique.
InS.
Wermter, E. Riloff, and G. Scheler, edi-tors, Connectionist, Statistical, and SymbolicApproaches to Learning for Natural LanguageProcessing, pages 329-342.
Springer-Verlag,Berlin, Germany.Winiwarter 8J Kambayashi 134 Learning and NL InterfacesJohn M. Zelle and Raymond J. Mooney.
1996.
Com-parative results on using inductive logic pro-gramming for corpus-based parser construc-tion.
In S. Wermter, E. Riloff, and G. Scheler,editors, Connectionist, Statistical, and Sym-bolic Approaches to Learning for Natural Lan-guage Processing, pages 355-369.
Springer-Verlag, Berlin, Germany.Winiwarter ~ Kambayashi 135 Learning and NL Interfaces
