Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,pages 444?454, Dublin, Ireland, August 23-29 2014.Fourteen Light Tasks for Comparing Analogical and Phrase-basedMachine TranslationRafik RhoumaRALI / DIROUniversit?e de Montr?ealrafikrhouma@live.frPhilippe LanglaisRALI / DIROUniversit?e de Montr?ealfelipe@iro.umontreal.caAbstractIn this study we compare two machine translation devices on twelve machine translation medical-domain specific tasks, and two transliteration tasks, altogether involving twelve language pairs,including English-Chinese and English-Russian, which do not share the same scripts.
We imple-mented an analogical device and compared its performance to the state-of-the-art phrase-basedmachine translation engine Moses.
On most translation tasks, the analogical device outperformsthe phrase-based one, and several combinations of both systems significantly outperform eachsystem individually.
For the sake of reproducibility, we share the datasets used in this study.1 IntroductionA proportional analogy is a relation between 4 objets, x , y , z and t , noted [x : y :: z : t], which readsx is to y as z is to t .
A formal proportional analogy, hereafter analogy, is a proportional analogy whichinvolves a relationship at the graphemic level, such as [atomkraftwerken : atomkriegen :: kraftwerks :kriegs] in German.
Analogical learning is a holistic learning paradigm (sketched in Section 2) whichrelies on proportional analogies for generalizing a training set.Lepage and Denoual (2005b) pioneered the application of analogical learning to Machine Transla-tion (MT).
Different variants of their system have been tested within the IWSLT evaluation campaigns(Lepage and Denoual, 2005a; Lepage and Lardilleux, 2008; Lepage et al., 2008; Lepage et al., 2009).Since then, a number of studies have been investigating analogical learning for performing more specificmachine translation tasks.
Langlais et al.
(2009) applied it to translating medical terms, and Langlaisand Patry (2007) investigated the more specific task of translating unknown words, a problem simultane-ously investigated in (Denoual, 2007).
Recently, Langlais (2013) applied formal analogies to transliterateEnglish proper names into Chinese.Those works suggest, at least on the tasks investigated, that analogical translation typically shows bet-ter precision than phrase-based Statistical MT (SMT), but at a much lower recall.
Still, the analogicaldevices tested in these works vary from task to task, making it difficult to draw a clear picture of thestrengths and weaknesses of analogy-based translation.
In this study, we perform a systematic compari-son of an analogical and a phrase-based MT engine for the translation of fourteen different testbeds.
Wealso improve the state-of-the-art of analogical learning by revisiting the aggregation step of the process.In particular, we observe that ranking analogical candidates according to random forests improves theperformance of the analogical device, over training a classifier, as proposed for instance in (Langlais,2013).
On each task we tackle, we report improvements to the state-of-the-art in analogical learning.In the remainder of this paper, we describe the principle of analogical learning and sketch our analogi-cal device in Section 2.
We describe our experimental protocol in Section 3.
We analyze the performanceof several variants of our analogical device in Section 4 and compare it to a state-of-the-art phrase-baseSMT engine.
We conclude this work and discuss future avenues in Section 5.This work is licenced under a Creative Commons Attribution 4.0 International License.
Page numbers and proceedings footerare added by the organizers.
License details: http://creativecommons.org/licenses/by/4.0/4442 ANALOGICAL LEARNING2.1 PrincipleWe note [x : y :: z : ? ]
an analogical equation.
It can have 0 or several solutions, depending on thedefinition of analogy being considered.
We are given a training set (or memory) of pairs of input andoutput forms that are in (translation) relation: L = {?x1, y1?, .
.
.
, ?xl, yl?
}, and we note ?
(x) the set ofoutput forms to which the input form x corresponds in the training set: ?
(x) = {y : ?x, y?
?
L}.Given an input form u unseen at training time, analogical learning generates its associated output form(in our case its translation), by accomplishing 3 steps.
First, analogies in the input space [x : y :: z : u]are searched for.
Second, output equations [x?
: y?
:: z?
: ? ]
are solved for all x?
, y?
, and z?
in?
(x), ?
(y), and ?
(z) respectively.
By applying those two steps (that we call the generator), a numberof candidate solutions are typically produced.
They need to be aggregated.
This is the purpose of thethird step, or selector.
Note that for the mapping to happen between input and output strings, there is noattempt to align subsequences of forms in both spaces, as it is typically done in statistical MT.
There isactually no alignment whatsoever: analogies are treated in each space separately, and the mapping is theresult of the inductive bias which promotes that an analogy in the input space corresponds to an analogyin the output space.Figure 1 depicts the overall process for the translation of the English term proton pump inhibitors intoSpanish, given a memory of pairs such as ?blood coagulation factors, factores de coagulaci?on sangu?
?nea?and ?proton pumps, bombas de protones?.
6 input analogies are being identified (2 are reported), there-fore 6 (output) equations are being solved, yielding a total of 5268 different forms that are sorted indecreasing order of frequency with which they have been generated.
This is the output of the generator.The reference translation (in bold) ranks 11thaccording to frequency.
The aggregator finally selects twocandidates from this list.
The best ranked one according to the aggregator is the correct translation.u ?
proton pump inhibitors?
[blood coagulation factors : proton pumps :: blood coagulation factor inhibitors : u]??
[factores de coagulaci?on sangu?
?nea : bombas de protones ::inhibidores de factor de coagulaci?on sangu?
?nea : ?
]15 solutions: inhibidores de dbomba protones (32) inhibidores de d bombaprotones (20) .
.
.
[protein c : proton pumps :: protein c inhibitor : u]??[prote?
?na c : bombas de protones :: inhibidor de prote?
?na c : ?
]2541 solutions: proton pumps inhibitor (382) proton pum inhibitorps (59) .
.
....inhibidor de bombas de protones (119) inhibidores de bombas de protone (70)inhibidores de la bombas de protone (70) inhbidores de ibombas de protone (65)nhibidores de ibombas de protone (65) inhibdores de ibombas de protone (65) .
.
.
?inhibidores de la bomba de protones (16026) inhibidor de bombas de protones (9702)Figure 1: Excerpt of the translation session of the English term proton pump inhibitors into Spanish.
Thereference translation is in bold.
Spaces are underlined for readability.2.2 ImplementationImplementing such a learning procedure requires the definition of a formal analogy, the implementationof an analogical solver, as well as a way to handle computational issues: the identification of inputanalogies is an operation a priori cubic in the size of the input space.
We describe each component ofour implementation below.
In practice, and for the tasks we consider in this work, our implementationallows the translation of an input form within a few seconds on average.445We would like to point out that analogical learning often suffers from a silence issue, that is, there are(input) forms for which no solution is provided.
This may happen because no input analogy is identified,or because none yields an output equation with solutions.
In contrast, there are many forms for whichseveral candidate translations will be provided, thus the need for a good aggregator (see next section).This happens because an equation typically allows many solutions, and because many input analogiesmight be identified for solving a given input form.Formal Analogy We used the definition of formal analogy proposed by Yvon et al.
(2004), wherean analogy is defined in terms of d-factorizations.
A d-factorization of a string x over an alphabet?, noted fx, is a sequence of d factors fx?
(f1x, .
.
.
, fdx), where fix?
?
?for all i, and such thatf1xf2xfdx?
x; where  denotes the concatenation operator.Definition 1. ?
x, y, z and t ?
?
?, [x : y :: z : t] iff there exists a 4-uple of d-factorizations(fx, fy, fz, ft) of x, y, z and t respectively, such that ?i ?
[1, d], (fiy, fiz) ?
{(fix, fit), (fit, fix)}.
Thesmallest d for which this holds is called the degree of the analogy.For instance, [protein c : proton pumps :: protein c inhibitor : proton pump inhibitors] becauseof the 4-uple of 3-factorizations shown in Fig.
2, whose factors are aligned column-wise for clarity,and where spaces (underlined) are treated as regular characters.
There is no 4-uple of d-factorizations,with d smaller than 3.
Therefore, the degree of this analogy is 3.
Note that there are many 4-uple ofd-factorizations for d greater than 3.Figure 2: A 4-uple of 3-factorizations demonstrating that [protein c : proton pumps ::protein c inhibitor : proton pump inhibitors].fx?
( protein c   )fy?
( proton pump  s )fz?
( protein c inhibitor  )ft?
( proton pump inhibitor s )Analogical Solver With the aforementioned definition, it has been showed by Yvon et al.
(2004) thatthe set of solutions to an analogical equation is a rational language, therefore we can build a finite-statemachine for encoding those solutions.
In practice however, the automaton is non-deterministic, and inthe worst case, enumerating the solutions can be exponential in the length of the forms involved in theequation.
We adopted the solution proposed in (Langlais et al., 2009) which consists in sampling thisautomaton without building it.
The more we sample this automaton, the more solutions we produce.
Itis sufficient to note that typically, a solver produces several solutions to an equation, many being simplyspurious, which means that, while they obey the definition of formal analogy, they are not valid forms.Figure 3: Three most frequent solutions to the equation [protein c : proton pumps ::protein c inhibitor : ? ]
along with their frequency, as a function of the number of samples considered10n.
nb stands for the total number of solutions produced.n nb solutions1 43 p inhibitorroton pumps (2) proton p inhiubitomrps (2) prot ion pnhibitumorps (2)2 320 proton pumps inhibitor (8) proton pum inhibitposr (4) prot inhibion pumtorps (4)3 2 597 proton pumps inhibitor (121) roton pumpps inhibitor (19) proton pump inhsibitor (19)4 16 006 proton pumps inhibitor (764) proton pump inhibsitor (103) proton pump isnhibitor (95)5 72 610 proton pumps inhibitor (3706) proton pump sinhibitor (501) proton pump inhibitosr (481)To illustrate this, Figure 3 reports the solutions produced to the equation [protein c : proton pumps ::protein c inhibitor : ? ]
by our implementation of the solver, as a function of the number of samplingsdone in the automaton.
Clearly, many solutions are not valid forms in English, although they define446proper solutions according to the aforementioned definition.
Note that with enough sampling, the solu-tion proton pumps inhibitor (involving a degree-2 analogy) is the most frequently generated one, whilethe solution proton pump inhibitors involved in the analogy illustrated in Figure 2 is generated less often(typically at the 10thposition).Searching input analogies Identifying input analogies for an input term u is an operation a prioricubic in the size of the input space.
Langlais and Yvon (2008) developed an algorithm for speedingup the search procedure that we adopted in this work.
The main idea is to exploit a property of formalanalogies (Lepage and Shin-ichi, 1996):[x : y :: z : u]?
|x|c+ |u|c= |y|c+ |z|c?c ?
A (1)where A is the (input) alphabet, and |x|cstands for the number of occurrences of symbol c in x .The strategy consists in first selecting a form x in the input space.
This enforces a set of necessaryconstraints on the counts of symbols that any two forms y and z must satisfy for [x : y :: z : u] to hold.By considering all forms x in turn, we collect a set of candidate triplets for u .
We then have to find outwhich of these triplets form an analogy with u.
Formally, we search for:{?x, y, z?
: x ?
I,?x, y?
: y ?
I and |x|c+ |u|c= |y|c+ |z|c?c ?
A,[x : y :: z : u]}(2)where I ?
{x1, .
.
.
, xl}.
This strategy relies on the fact that one can efficiently identify the pairs ?y, z?that satisfy a set of constraints on symbol counts.
See (Langlais et al., 2009) for the tree-count solutionwe implemented in this work.3 Experimental Protocol3.1 TasksWe use two families of tasks in this study.
The first one concerns the translation of medical terms, thesecond one is about transliterating proper names.
The main characteristics of the datasets we consider arereported in Table 1.
If both tasks are of importance in practice, we admit that they are rather specific.
Thereason for this is that analogical learning is quite computationally intensive.
Therefore, tackling broadertasks, such as those typically considered in MT evaluation campaigns is currently too challenging.Medical term translation We use the datasets described in (Langlais et al., 2009).
Part of the datacomes from the Medical Subject Headings (MESH) thesaurus.
This thesaurus is used by the US NationalLibrary of Medicine to index the biomedical scientific literature in the MEDLINE database.
The MESHmaterial concerns five language pairs with three relatively close European languages (English-French,English-Spanish and English-Swedish), a more distant one (English-Finnish) and one pair involvingdifferent scripts (English-Russian).
The material was split in three randomly selected parts (TRAIN, DEVand TEST), so that the development and test material contain exactly 1000 terms each.
Roughly a thirdof the examples are pairs of single-word terms.For the Spanish-English language pair, a set of medical terms from the Medical Drug RegulatoryActivities thesaurus (MEDDRA) is also available.
This dataset contains roughly three times more termsthan the Spanish-English material from the MESH dataset.
Forms in the dataset are typically longer andthe percentage of examples that are pairs of single-word terms is only 5.6%.
This set is used for studyinghow the silence rate of analogical learning evolves with the size of the training set.We are pleased to share those datasets.
They can be downloaded at http://rali.iro.umontreal.ca/rali/?q=en/12-medical-translation-tasks.Proper name transliteration This task is part of the NEWS evaluation campaign conducted in 2009(Li et al., 2009).
The organizers of this evaluation campaign kindly provided us with the Chinese-Englishdataset.
This task has been investigated recently by Langlais (2013).
This allows a direct comparison ofour analogical system.
We also consider the reverse transliteration direction, i.e., the transliteration of447Chinese proper names into English.
This was done by simply switching the source and target languagesin the NEWS dataset.TRAIN TEST DEVnb avg.
nb oov% oov%MESH examples:FI 19 787 19.3 1 000 65.0 63.8 orthodontic retainersFR 17 230 21.5 1 000 35.8 36.8 ??
FI:tandregleringshj?alpmedel, f?orankradeRU 21 407 38.5 1 000 42.3 45.1ES 19 021 21.5 1 000 37.4 34.9 aid to families with dependent childrenSW 17 090 17.3 1 000 69.3 70.0 ??
SW:bidrag till barnfamiljerMEDDRA poor urinary streamES 65 276 34.6 1 000 7.1 7.1 ??
ES: chorro de orina d?ebilNEWS Abberley ?
CN:??
?CN 31 961 9.5 2 896 ?
?
Schemansky ?
CN:???
?Table 1: Main characteristics of our datasets.
nb indicates the number of pairs of terms in a bitext,avg.
indicates the average length (in symbols) of the foreign forms; oov% indicates the percentage ofout-of-vocabulary types (space-separated types of TEST or DEV unseen in TRAIN).3.2 Evaluation MetricsAll the tasks we consider are characterized by a rather high out-of-vocabulary rate (see Table 1).
Thus,word-based translation is not an adequate solution.
Therefore, we devised engines which translate se-quences of symbols (characters), without taking into account the notion of word.1In particular, spacesin forms were considered as any ordinary symbol.
Measuring how close a candidate translation is to areference is of little interest here, since typically, a medical term only has one reference translation thatwe seek to discover.
Therefore, rewarding partially correct translations (like a metric such as BLEU (Pa-pineni et al., 2002) does) is not especially useful.
Therefore we report the accuracy of the first candidateproposed by a translation device for each source term.
Accuracy is measured as the percentage of testforms for which the first candidate is the sanctioned one.
So in the example of Figure 1, the aggregatorillustrated in the bottom frame would get one point since the first translation produced is the sanctionedone, while an aggregator that would pick the most frequently generated candidate would receive no point.Accuracy is the main metric of the NEWS evaluation campaign, and we used the NEWS 2009 officialevaluation script2in order to compute it.
Also of interest for the analogical devices, is the silence rate,computed as the percentage of input forms for which no output is generated.
As we will see, on sometasks, this ratio can be rather high, a clear limitation of the analogical approach we discuss in Section 5.3.3 Systems3.3.1 Reference SystemWe compare a number of analogical devices to the state-of-the-art statistical translation engine Moses(Koehn et al., 2007).
In a nutshell, SMT seeks to find the optimal translation e?
of a sentence f usingto a log-linear combination of models (hi), including a language model p(e) which scores how likely ahypothesis is in the target language, and a translation model p(f |e) which predicts the likelihood thattwo sentences are translations:e?
= argmaxep(f |e)p(e) ?
argmaxeexp(?i?ihi(e, f))(3)1We tried it, but the results are very low.2http://translit.i2r.a-star.edu.sg/news2009/448We trained such a system at the character level,3very similarly to the approach described in (Finchand Sumita, 2010).
Such a system has been massively used as a key component by the participantsof the NEWS 2009 evaluation campaign.
We used the default configuration of Moses for training andtesting the SMT engine.
We trained a 5-gram character-based language model on the target part of theTRAIN material.4We used the DEV corpus for tuning the coefficients (?i) given to each model.
Theresulting system have high BLEU scores (e.g., 55.7 for the CN?EN NEWS task).
A random extract of thephrase-table learnt by Moses for the English-Swedish system is shown in Figure 4.Figure 4: Phrases stored in the SW?EN phrase-table, along with 4 estimations of their likelihoodeckos ||| echos ||| 0.303 0.006 0.303 0.002, kvinn ||| , fema ||| 0.101 8.3e-09 0.303 2.5e-11eckrina ||| eccrine ||| 0.151 0.009 0.303 0.001edel ||| ator ||| 0.002 4.6e-06 0.002 1.9e-063.3.2 Analogical SystemsWe ran our analogical generator for translating the DEV set, using the TRAIN set as a memory.
Thecandidate translations generated were used for training our aggregators in a supervised way.
Then, wegenerated the translation of the TEST terms with our analogical device, making use of the TRAIN and theDEV set as a memory.
Adding the DEV corpus to the memory used by the generator is acceptable since itdoes not involve training.
We only consider the (at most) 100 most frequently generated forms for eachinput term.
This certainly decreases the recall of the analogical device, but simplifies the overall process.These candidates are passed on to the aggregator, and one candidate is finally selected.Aggregators A number of aggregators have been proposed in the literature.
Lepage and Denoual(2005b; Stroppa and Yvon (2005) keep the candidate that has been generated the most frequently.
Wecall this aggregator FREQ henceforth.
Langlais et al.
(2009) trained a binary classifier to recognize goodexamples from bad ones.
A training instance in their case was constituted by an input analogy, and thecorresponding output equation along with one solution produced.
Therefore, for the translation of theinput form u , any pair ([x : y :: z : u], [x?
: y?
:: z?
: c]), with x?
, y?
, and z?
in ?(x?
), ?(y?
), and?(z?)
respectively, and c a candidate translation would be considered for classification.
The authors hadto face a particularly unbalanced classification task.
Indeed, when translating a test form, a large numberof input analogies can be considered (hundreds) and therefore a large number of output equations, eachgenerating potentially numerous solutions (recall the translation session in Figure 1).
They reportedfor instance that on the English-to-Finnish translation direction, they had over 2.7 million instances toclassify among which slightly less than 4200 were positive ones.
Not only is this task very unbalanced,it is also challenging to train a classifier on that many instances.In this work, we reframe the classification task as one of identifying the correct candidate among the100 most frequently generated ones.
An instance in this setting is simply a candidate form, and not apair of analogies as in (Langlais et al., 2009).
This is still an unbalanced task, since typically at most onecandidate will be correct, but the ratio 1:100 is more manageable, and the classification task is easier todeploy.
A total of 81 features are computed for each candidate form:ANA is a set of 59 features (mostly analogical ones, therefore the name).
Some features are characteriz-ing the candidate solution thanks to a character-based language model (the same 5-gram languagemodel used by Moses).
Others are characterizing the process with which a given candidate is gener-ated, such as the number of input analogies involved, the number of target equations that generatedthe candidate, the average degree of the analogies involved, etc.
The remaining features are cohort-based ones, such as the rank of the candidate according to frequency, to the language model, etc.3This was done by separating each character in the training material by a space; true spaces being previously substituted bya special character not belonging to the alphabet.4A Markov model of order 4.
We tried higher order models, without gains.449IBM is a set of 18 features that are capitalizing on statistical word alignment.
The alignment modelsbeing used are word-based generative models that are exploited by Moses in order to build thephrase table, namely IBM models, therefore the name of the feature set.
Different likelihood-basedfeatures were computed, as well as rank features (the rank of the likelihood of the candidate in thecohort of candidates, the ratio of its likelihood over the highest likelihood in the cohort, etc.).
Toour knowledge, this is the first attempt to capitalize on such features in the analogical sphere.MOS is a set of 4 features that are exploiting the n-best solutions we asked Moses to produce.
The ideabeing that if Moses ranks a given analogical candidate well (in rank or in score), this is a goodindicator of the salience of this candidate.
The two main features are the rank of the candidate inthe n-best list and its score as given by Moses (or 0 if Moses does not produce the candidate).We point out that an analogical device with an aggregator that uses the features ANA and IBM isbasically making use of the same models (language and IBM) as those used by Moses.
It is thereforeinteresting to compare this configuration to Moses.
Also, the aggregators that are making use of the MOSfeatures are performing a kind of combination that has not been explored so far.
Note also that we didnot engineer task-specific features.
For instance, for the medical term translation task, terms and theirtranslation often share the same latin root, which could be exploited to boost performance.We investigated two families of classifiers: voted-perceptrons (Freund and Schapire, 1999) and supportvector machines (Cortes and Vapnik, 1995).
We investigated all the metaparameters that LibSVM (Changand Lin, 2011) offers (penalization, kernels, etc.
), but did not manage to outperform the performance ofthe former classifier (an in-house implementation) that we trained with 500 epochs.
Therefore we onlyreport the results of the voted-perceptron classifier (VP).
Classifying each candidate solution separatelyis not optimal.
This is why we also investigated reranking algorithms in this study.
To our knowledge,this is the first time reranking is applied in analogical learning.
We tested the algorithms implemented inRankLib5and SVMRank6toolkits, and found random forests (Breiman, 2001) to be the most beneficial.We note it RF in the sequel.
We only considered bipartite ranking in this work (Argarwal, 2005).4 Results4.1 MESHThe accuracy of the translation devices we trained are summarized in Table 2 for the 10 translationdirections we tested.
This table calls for several comments.
First, it is noticeable that our implementationof analogical learning with the FREQ aggregator (line LYZ) outperforms the equivalent configuration in(Langlais et al., 2009) by roughly 10 absolute points in accuracy.
We also observe a slight reduction ofthe silence rate, which still remains high, since on average 54.6% of the test forms do not receive anycandidate solution.
Second, we observe that Moses slightly outperforms the FREQ variant at a silencerate of 0 (a decision is always returned by Moses).
This suggests that FREQ is actually more precise thanMoses and calls for a simple combination where the analogical device is trusted whenever it produces acandidate solution, and Moses otherwise.
This is illustrated in line CASC(FREQ,MOSES).
We observe aclear improvement over each system: almost 10 absolute accuracy points on average are gained by thiscombination (38.6%).
Third, we observe that the aggregators that are relying on a classifier or a rerankeroffer better performance than picking the most frequently generated form (as done by FREQ).
The gainsare not especially high, but are consistent over all translation directions.
Overall, it seems that the randomforest reranker we investigated (the best reranker we tried) offers the best performance on average.
Thisrepresents 92% of the reachable accuracy according to line ORACLE which involves a perfect classifier.This validates the usefulness of the features we designed.
As far as features are concerned, it seems thatusing all of them leads to better performance overall, and that the configurations that are making useof the ANA and IBM feature sets are comparable or higher than Moses.
Cascading the best analogicaldevice with Moses (last line) finally gives a slight boost in accuracy.
In the end, the best system we testedcorrectly translated 41.9% of the test terms in the first position on average across translation directions.5http://people.cs.umass.edu/?vdang/ranklib.html6http://www.cs.cornell.edu/people/tj/svm_light/svm_rank.html450?
EN EN?FR RU FI ES SW FR RU FI ES SW avg.LYZ 18.1 20.8 16.4 20.3 18.2 14.6 18.7 14.9 19.5 15.4 17.7(61.5) (57.9) (55.2) (57.4) (55.4) (58.8) (53.8) (52.9) (53.0) (57.2) (56.3)FREQ 27.3 29.1 28.5 30.5 28.3 21.8 29.0 24.7 29.8 26.3 27.5(59.3) (56.7) (53.7) (55.6) (54.3) (56.0) (52.5) (50.9) (51.6) (55.2) (54.6)MOSES 22.3 33.4 27.0 29.0 38.8 20.0 30.5 26.4 28.6 37.0 29.3VP(ANA) 28.4 29.8 29.8 31.9 29.7 23.2 31.0 27.2 32.3 27.9 29.1VP(ANA+IBM) 28.8 31.8 31.6 32.4 31.2 24.5 32.3 28.4 34.2 29.2 30.4VP(ANA+IBM+MOS) ?
29.2 32.3 31.6 32.8 31.9 25.0 32.6 28.8 34.0 30.1 30.8RF(ANA) 28.3 29.8 30.7 32.0 29.5 23.0 31.2 27.4 31.6 28.3 29.2RF(ANA+IBM) 29.1 31.6 31.8 32.8 31.0 24.4 32.4 28.7 33.5 30.1 30.5RF(ANA+IBM+MOS) 29.4 31.8 32.2 32.9 32.4 24.9 32.5 29.9 34.0 31.1 31.1ORACLE 31.3 34.0 34.9 35.2 34.9 28.2 35.7 33.2 37.3 33.3 33.8(68.7) (66.0) (65.1) (64.8) (65.1) (71.8) (64.3) (66.8) (62.7) (66.7) (66.2)casc(FREQ,MOSES) 36.9 42.4 37.7 41.6 43.8 29.6 38.9 34.3 40.7 39.9 38.6casc(?,MOSES) 38.8 45.6 40.8 43.9 47.4 32.8 42.5 38.4 44.9 43.7 41.9Table 2: Accuracy on the MESH tasks.
Figures in parenthesis are silence rates.
LYZ stands for the systemdescribed in (Langlais et al., 2009), reproduced according to Table 4, p. 492. avg.
indicates the averageover the 10 translation directions.4.2 MEDDRAThe results presented so far show that the analogical device is more accurate than the statistical one,but that it suffers from a high silence rate.
We tested whether increasing the size of the training setwould lower the silence rate.
We used the datasets of MEDDRA for this.
The results are reported in theleft column of Table 3.
We observe that the silence rate decreases drastically, since less than a fourthof the test forms do not receive a candidate translation.
We also observe that the analogical devices,even the simplest FREQ, are far more accurate than Moses (over 30 absolute points on average).
Thepoor performance of the SMT engine might be explained by the fact that the forms in the MEDDRAdatasets are longer in terms of characters, therefore reducing the chance of getting the full translationright.
Again, combining both approaches does improve accuracy, but the improvement is small sinceMoses is much less accurate on this task.
Also, we observe that using a classifier is preferable to pickingthe most frequently generated form, and again, the random forest reranker delivers the best performanceon average.
It is noticeable however, that the performance is far less than the oracle?s, therefore, there isstill room for improvement.4.3 NEWSThe right column of Table 3 summarizes the performance of the transliteration devices we trained on theNEWS tasks.
The silence rate is rather low (less than 4%).
Here again, we observe that aggregating byclassifying or reranking is preferable to picking the most frequent solution.
There is no clear differencebetween random forest and voted perceptron here.
On the English-to-Chinese transliteration tasks, Mosesoutperforms the analogical devices, but the opposite is observed for the reverse transliteration direction.Our best configuration slightly outperforms the best analogical device reported in (Langlais, 2013), butthe gain is likely not significant.451MEDDRA NEWSES?EN EN?ES CN?EN EN?CNFREQ 52.2 (25.1) 45.5 (16.7) 17.2 (2.5) 43.3 (3.7)MOSES 10.2 11.0 15.4 66.6VP(ANA) 55.1 46.8 20.0 57.3VP(ANA+IBM) 56.2 46.9 20.9 59.5VP(ANA+IBM+MOS) ?
21.4 64.2RF(ANA) 54.1 49.3 20.9 57.8RF(ANA+IBM) 55.7 49.5 21.6 59.2RF(ANA+IBM+MOS) 22.3 64.1ORACLE 64.3 (34.4) 61.8 (38.2) 64.9 (32.9) 81.5 (18.5)casc(FREQ,MOSES) 53.2 46.7 17.5 44.9casc(?,MOSES) ?
?
68.9(Langlais, 2013) 68.5Table 3: Accuracy on the MEDDRA and NEWS tasks.
The performance of (Langlais, 2013) is takenfrom Table 1 p. 687.4.4 Examples of translationsWe conducted a random inspection of the outputs produced by Moses and by the analogical device whichuses a voted perceptron classifier trained on the ANA and the IBM features.7We report in Figure 5 a fewexamples that we found representative of the problems each translation device faces.
The FI?EN exampleshows a case where Moses fails to produce a valid sequence of words.
The EN?ES example illustratesthe weakness of Moses at reordering words.
The CN?EN example shows the incorrect transliterationsmade by both systems, and the EN?CN one illustrates a failure of the analogical engine were ph and usare transliterated separately.MESH(FI?EN) hammasytimen sairaudet NEWS(CN?EN) ????
?Analog dental marrow diseases Analog BennidicktMOSES dental ne diseases MOSES BenniDickertReference dental pulp diseases Reference BenedictMEDDRA(EN?ES) intrinsic asthma with status asthmaticus NEWS(EN?CN) AdolphusAnalog asma intr?
?nseca con estatus asm?atico Analog ????
?MOSES intr?
?nseco asm?atico con estatus asm?atico MOSES ???
?Reference asma intr?
?nseca con estatus asm?atico Reference ???
?Figure 5: Examples of analogical and phrase-based outputs5 DiscussionWe have applied analogical learning on a number of key tasks involving various language pairs.
Over-all, we confirm the findings of Langlais et al.
(2009) and Langlais (2013) that analogical devices aretypically more accurate than statistical phrase-based SMT, but that they are too often silent.
We alsoverified that cascading the analogical device with Moses increases accuracy.
We compared a num-ber of classification algorithms and rerankers, and observed that overall, reranking by random forest7This variant fares well compared to Moses in terms of information used (same language and IBM models).452delivers the best performance.
Our implementation outperforms previously reported ones.
Our gen-erator is more efficient than the one described in (Langlais et al., 2009).
Reranking candidate solu-tions is preferable to their classification, as proposed in (Langlais, 2013).
In order to foster repro-ducibility, the datasets related to the medical-translation tasks we investigated can be downloaded athttp://rali.iro.umontreal.ca/rali/?q=en/12-medical-translation-tasks.We believe this systematic comparison shows the high potential of analogical learning as a translationengine.
Still, this work raises a number of issues that we must address.
First, we need to find waysto remedy analogical learning?s high silence rate.
Lepage and Denoual (2005b) describe a recursiveprocess where the input form is split into two parts whenever no solution is returned in the first place.This process is at the very least costly and deserves further investigations.
Lepage and Lardilleux (2008)augments the training set with sub-sentential alignment (bootstrapping).
Second, the solver we use isproducing many solutions that are currently ranked according to frequency.
We are addressing the issueof producing less, but more accurate solutions, by integrating structured learning in the solver.
Last, weinvestigated here the translation of sequences of characters on modestly sized tasks.
We want to tacklebroader translation tasks, e.g., translating plain sentences, as done in (Lepage and Denoual, 2005b), tosee whether our analogical device is still beneficial.AcknowledgementsWe thank the reviewers for their valuable comments and apologize for having failed to taking all of theminto account in this version.
This work has been partially funded by the Natural Science and EngineeringResearch Council of Canada.
We are grateful to Fabrizio Gotti for his advice.ReferencesShivani Argarwal.
2005.
A study of the bipartite ranking problem in Machine Learning.
Technical report, Univer-sity of Illinois.Leo Breiman.
2001.
Random Forests.
Machine Learning, 45(1):5?32.Chih-Chung Chang and Chih-Jen Lin.
2011.
LIBSVM: A Library for Support Vector Machines.
ACM Trans.Intell.
Syst.
Technol., 2(3):1?27, May.Corinna Cortes and Vladimir Vapnik.
1995.
Support-vector networks.
Machine Learning, 20(3):273?297.
?Etienne Denoual.
2007.
Analogical translation of unknown words in a statistical machine translation framework.In MT Summit XI, pages 135?141, Copenhagen, Denmark.Andrew Finch and Eiichiro Sumita.
2010.
Transliteration Using a Phrase-based Statistical Machine TranslationSystem to Re-score the Output of a Joint Multigram Model.
In 2nd Named Entities Workshop (NEWS?10), pages48?52, Uppsala, Sweden.Yoav Freund and Robert Schapire.
1999.
Large Margin Classification Using the Perceptron Algorithm.
Mach.Learn., 37(3):277?296.Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, BrookeCowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ond?rej Bojar, Alexandra Constantin, and EvanHerbst.
2007.
Moses: Open Source Toolkit for Statistical Machine Translation.
In 45th ACL, pages 177?180.Interactive Poster and Demonstration Sessions.Philippe Langlais and Alexandre Patry.
2007.
Translating Unknown Words by Analogical Learning.
In EMNLP,pages 877?886, Prague, Czech Republic.Philippe Langlais and Franc?ois Yvon.
2008.
Scaling up Analogical Learning.
In 22nd International Conferenceon Computational Linguistics (COLING 2008), Poster session, pages 51?54, Manchester, United Kingdom,Aug.Philippe Langlais, Franc?ois Yvon, and Pierre Zweigenbaum.
2009.
Improvements in Analogical Learning: Appli-cation to Translating multi-Terms of the Medical Domain.
In 12th EACL, pages 487?495, Athens.453Philippe Langlais.
2013.
Mapping Source to Target Strings without Alignment by Analogical Learning: A CaseStudy with Transliteration.
In Proceedings of the 51st Annual Meeting of the Association for ComputationalLinguistics (Volume 2: Short Papers), pages 684?689, Sofia, Bulgaria.Yves Lepage and?Etienne Denoual.
2005a.
Aleph: an EBMT system based on the preservation of proportionalanalogies.
In 2nd IWSLT, pages 47?54, Pittsburgh, USA.Yves Lepage and?Etienne Denoual.
2005b.
Purest ever example-based machine translation: Detailed presentationand assesment.
Mach.
Translat, 19:25?252.Yves Lepage and Adrien Lardilleux.
2008.
The GREYC Translation Memory for the IWSLT 2007 EvaluationCampaign.
In 4th IWSLT, pages 49?54, Trento, Italy.Yves Lepage and Ando Shin-ichi.
1996.
Saussurian Analogy: A Theoretical Account and Its Application.
In 7thCOLING, pages 717?722.Yves Lepage, Adrien Lardilleux, Julien Gosme, and Jean-Luc Manguin.
2008.
The GREYC Translation Memoryfor the IWSLT 2008 Evaluation Campaign.
In 5th IWSLT, pages 39?45, Hawai, USA.Yves Lepage, Adrien Lardilleux, and Julien Gosme.
2009.
The GREYC Translation Memory for the IWSLT 2009Evaluation Campaign: one step beyond translation memory.
In 6th IWSLT, pages 45?49, Tokyo, Japan.Haizhou Li, A. Kumaran, Vladimir Pervouchine, and Min Zhang.
2009.
Report of NEWS 2009 machine translit-eration shared task.
In Proceedings of the 2009 Named Entities Workshop: Shared Task on Transliteration,NEWS ?09, pages 1?18.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
BLEU: a Method for Automatic Evaluationof Machine Translation.
In Proc.
of the 40th ACL, pages 311?318, Philadelphia, Pennsylvania, USA.Nicolas Stroppa and Franc?ois Yvon.
2005.
An Analogical Learner for Morphological Analysis.
In 9th Conf.
onComputational Natural Language Learning (CoNLL), pages 120?127, Ann Arbor, USA.Franc?ois Yvon, Nicolas Stroppa, Arnaud Delhay, and Laurent Miclet.
2004.
Solving Analogies on Words.
Tech-nical Report D005,?Ecole Nationale Sup?erieure des T?el?ecommuncations, Paris, France.454
