Determining Recurrent Sound Correspondencesby Inducing Translation ModelsGrzegorz KondrakDepartment of Computer ScienceUniversity of TorontoToronto, Ontario, Canada M5S 3G4AbstractI present a novel approach to the determinationof recurrent sound correspondences in bilingualwordlists.
The idea is to relate correspondences be-tween sounds in wordlists to translational equiva-lences between words in bitexts (bilingual corpora).My method induces models of sound correspon-dence that are similar to models developed for sta-tistical machine translation.
The experiments showthat the method is able to determine recurrent soundcorrespondences in bilingual wordlists in which lessthan 30% of the pairs are cognates.
By employ-ing the discovered correspondences, the method canidentify cognates with higher accuracy than the pre-viously reported algorithms.1 IntroductionGenetically related languages often exhibit recur-rent sound correspondences (henceforth referred tosimply as correspondences) in words with similarmeaning.
For example, t:d, T:t, n:n, and otherknown correspondences between English and Latinare demonstrated by the word pairs in Table 1.
Wordpairs that contain such correspondences are calledcognates, because they originate from the sameprotoform in the ancestor language.
Correspon-dences in cognates are preserved over time thanks tothe regularity of sound changes, which normally ap-ply to sounds in a given phonological context acrossall words in the language.The determination of correspondences is the prin-cipal step of the comparative method of languagereconstruction.
Not only does it provide evidencefor the relatedness of languages, but it also makesit possible to distinguish cognates from loan wordsand chance resemblances.
However, because man-ual determination of correspondences is an ex-tremely time-consuming process, it has yet to be ac-complished for many proposed language families.A system able to perform this task automaticallyEnglish Latint E n d e k e ?ten?t u?
d u o ?two???
t e d ?eat?t u?
T d e n t ?tooth?n E s t n i d ?nest?n ??
g e n ?knee?n E f j u?
n e p o t ?nephew?f u t p e d ?foot?f o?
m s p u m ?foam?w u l f l u p ?wolf?Table 1: Examples of English?Latin cognatesexhibiting correspondences.
The correspondingphonemes shown in boldface originate from a sin-gle proto-phoneme.from unprocessed bilingual wordlists could be ofgreat assistance to historical linguists.
The Recon-struction Engine (Lowe and Mazaudon, 1994), a setof programs designed to be an aid in language re-construction, requires a set of correspondences tobe provided beforehand.The determination of correspondences is closelyrelated to another task that has been much stud-ied in computational linguistics, the identificationof cognates.
Cognates have been employed forsentence and word alignment in bitexts (Simardet al, 1992; Melamed, 1999), improving statisti-cal machine translation models (Al-Onaizan et al,1999), and inducing translation lexicons (Koehnand Knight, 2001).
Some of the proposed cognateidentification algorithms implicitly determine andemploy correspondences (Tiedemann, 1999; Mannand Yarowsky, 2001).Although it may not be immediately apparent,there is a strong similarity between the task ofmatching phonetic segments in a pair of cognatewords, and the task of matching words in two sen-tences that are mutual translations (Figure 1).
Thel fl u pw uNix iacet in terraonlies the groundSnowFigure 1: The similarity of word alignment in bi-texts and phoneme alignment between cognates.consistency with which a word in one language istranslated into a word in another language is mir-rored by the consistency of sound correspondences.The former is due to the semantic relation of syn-onymy, while the latter follows from the principleof the regularity of sound change.
Thus, as alreadyasserted by Guy (1994), it should be possible to usesimilar techniques for both tasks.The primary objective of the method proposed inthis paper is the automatic determination of corre-spondences in bilingual wordlists, such as the onein Table 1.
The method exploits the idea of relat-ing correspondences in bilingual wordlists to trans-lational equivalence associations in bitexts throughthe employment of models developed in the con-text of statistical machine translation, The secondtask addressed in this paper is the identification ofcognates on the basis of the discovered correspon-dences.
The experiments to be described in Sec-tion 6 show that the method is capable of determin-ing correspondences in bilingual wordlists in whichless than 30% of the pairs are cognates, and out-performs comparable algorithms on cognate identi-fication.
Although the experiments focus on bilin-gual wordlists, the approach presented in this papercould potentially be applied to other bitext-relatedtasks.2 Related workIn a schematic description of the comparativemethod, the two steps that precede the determi-nation of correspondences are the identification ofcognate pairs (Kondrak, 2001), and their phoneticalignment (Kondrak, 2000).
Indeed, if a compre-hensive set of correctly aligned cognate pairs isavailable, the correspondences could be extractedby simply following the alignment links.
Unfortu-nately, in order to make reliable judgments of cog-nation, it is necessary to know in advance what thecorrespondences are.
Historical linguists solve thisapparent circularity by guessing a small number oflikely cognates and refining the set of correspon-dences and cognates in an iterative fashion.Guy (1994) outlines an algorithm for identifyingcognates in bilingual wordlists which is based oncorrespondences.
The algorithm estimates the prob-ability of phoneme correspondences by employinga variant of the ?2 statistic on a contingency ta-ble, which indicates how often two phonemes co-occur in words of the same meaning.
The prob-abilities are then converted into the estimates ofcognation by means of some experimentation-basedheuristics.
The paper does not contain any eval-uation on authentic language data, but Guy?s pro-gram COGNATE, which implements the algorithm,is publicly available.
An experimental evaluation ofCOGNATE is described in Section 6.Oakes (2000) describes a set of programs thattogether perform several steps of the comparativemethod, from the determination of correspondencesin wordlists to the actual reconstruction of the proto-forms.
Word pairs are considered cognate if theiredit distance is below a certain threshold.
The editoperations cover a number of sound-change cate-gories.
Sound correspondences are deemed to beregular if they are found to occur more than once inthe data.
The paper describes experimental resultsof running the programs on a set of wordlists rep-resenting four Indonesian languages, and comparesthose to the reconstructions found in the linguisticliterature.
Section 6 contains an evaluation of oneof the programs in the set, JAKARTA, on the cog-nate identification task.3 Models of translational equivalenceIn statistical machine translation, a translationmodel approximates the probability that two sen-tences are mutual translations by computing theproduct of the probabilities that each word in thetarget sentence is a translation of some source lan-guage word.
A model of translation equivalence thatdetermines the word translation probabilities can beinduced from bitexts.
The difficulty lies in the factthat the mapping, or alignment, of words betweentwo parts of a bitext is not known in advance.Algorithms for word alignment in bitexts aim atdiscovering word pairs that are mutual translations.A straightforward approach is to estimate the likeli-hood that words are mutual translations by comput-ing a similarity function based on a co-occurrencestatistic, such as mutual information, Dice coeffi-cient, or the ?2 test.
The underlying assumption isthat the association scores for different word pairsare independent of each other.Melamed (2000) shows that the assumption of in-dependence leads to invalid word associations, andproposes an algorithm for inducing models of trans-lational equivalence that outperform the models thatare based solely on co-occurrence counts.
His mod-els employ the one-to-one assumption, which for-malizes the observation that most words in bitextsare translated to a single word in the correspond-ing sentence.
The algorithm, which is related tothe expectation-maximization (EM) algorithm, iter-atively re-estimates the likelihood scores which rep-resent the probability that two word types are mu-tual translations.
In the first step, the scores areinitialized according to the G2 statistic (Dunning,1993).
Next, the likelihood scores are used to in-duce a set of one-to-one links between word tokensin the bitext.
The links are determined by a greedycompetitive linking algorithm, which proceeds tolink pairs that have the highest likelihood scores.After the linking is completed, the link counts areused to re-estimate the likelihood scores, which inturn are applied to find a new set of links.
Theprocess is repeated until the translation model con-verges to the desired degree.Melamed presents three translation-model esti-mation methods.
Method A re-estimates the like-lihood scores as the logarithm of the probability ofjointly generating the pair of words u and v:scoreA(u;v) = loglinks(u;v)?u0;v0 links(u0;v0)where links(u;v) denotes the number of links in-duced between u and v. Note that the co-occurrencecounts of u and v are not used for the re-estimation,In Method B, an explicit noise model with auxil-iary parameters ?+ and ?  is constructed in order toimprove the estimation of likelihood scores.
?+ isa probability that a link is induced between two co-occurring words that are mutual translations, while?  is a probability that a link is induced betweentwo co-occurring words that are not mutual trans-lations.
Ideally, ?+ should be close to one and ? should be close to zero.
The actual values of the twoparameters are calculated by the maximum likeli-hood estimation.
Let cooc(u;v) be the number ofco-occurrences of u and v. The score function isdefined as:scoreB(u;v) = logB(links(u;v) jcooc(u;v);?+)B(links(u;v) jcooc(u;v);? )where B(k jn; p) denotes the probability of k beinggenerated from a binomial distribution with param-eters n and p.In Method C, bitext tokens are divided intoclasses, such as content words, function words,punctuation, etc., with the aim of producing moreaccurate translation models.
The auxiliary parame-ters are estimated separately for each class.scoreC(u;v jZ = class(u;v)) =log B(links(u;v) jcooc(u;v);?+Z )B(links(u;v) jcooc(u;v);? Z )4 Models of sound correspondenceThanks to its generality and symmetry, Melamed?sparameter estimation process can be adapted to theproblem of determining correspondences.
The mainidea is to induce a model of sound correspondencein a bilingual wordlist, in the same way as one in-duces a model of translational equivalence amongwords in a parallel corpus.
After the model has con-verged, phoneme pairs with the highest likelihoodscores represent the most likely correspondences.While there are strong similarities between thetask of estimating translational equivalence ofwords and the task of determining recurrent corre-spondences of sounds, a number of important modi-fications to Melamed?s original algorithm are neces-sary in order to make it applicable to the latter task.The modifications include the method of finding agood alignment, the handling of null links, and themethod of computing the alignment score.For the task at hand, I employ a different methodof aligning the segments in two corresponding se-quences.
In sentence translation, the alignmentlinks frequently cross and it is not unusual for twowords in different parts of sentences to correspond.In contrast, the processes that lead to link inter-section in diachronic phonology, such as metathe-sis, are quite sporadic.
The introduction of theno-crossing-links constraint on alignments not onlyleads to a dramatic reduction of the search space, butalso makes it possible to replace the approximatecompetitive-linking algorithm of Melamed with avariant of the well-known dynamic programmingalgorithm (Wagner and Fischer, 1974; Kondrak,2000), which computes the optimal alignment be-tween two strings in polynomial time.Null links in statistical machine translation areinduced for words on one side of the bitext thathave no clear counterparts on the other side of thebitext.
Melamed?s algorithm explicitly calculatesthe likelihood scores of null links for every wordtype occurring in a bitext.
In diachronic phonol-ogy, phonological processes that lead to insertionor deletion of segments usually operate on individ-ual words rather than on particular sounds across thelanguage.
Therefore, I model insertion and deletionby employing a constant indel penalty for unlinkedsegments.The alignment score between two words is com-puted by summing the number of induced links, andapplying an indel penalty for each unlinked seg-ment, with the exception of the segments beyond therightmost link.
The exception reflects the relativeinstability of word endings in the course of linguis-tic evolution.
In order to avoid inducing links thatare unlikely to represent recurrent sound correspon-dences, only pairs whose likelihood scores exceed aset threshold are linked.
All correspondences abovethe threshold are considered to be equally valid.
Inthe cases where more than one best alignment isfound, each link is assigned a weight that is its av-erage over the entire set of best alignments (for ex-ample, a link present in only one of two competingalignments receives the weight of 0:5).5 ImplementationThe method described above has been implementedas a C++ program, named CORDI, which will soonbe made publicly available.
The program takes asinput a bilingual wordlist and produces an orderedlist of correspondences.
A model for a 200-pair listusually converges after 3?5 iterations, which takesonly a few seconds on a Sparc workstation.
Theuser can choose between methods A, B, and C, de-scribed in Section 3, and an additional Method D. InMethod C, phonemes are divided into two classes:non-syllabic (consonants and glides), and syllabic(vowels); links between phonemes belonging to dif-ferent classes are not induced.
Method D differsfrom Method C in that the syllabic phonemes do notparticipate in any links.Adjustable parameters include the indel penaltyratio d and the minimum-strength correspondencethreshold t. The parameter d fixes the ratio be-tween the negative indel weight and the positiveweight assigned to every induced link.
(A lowerratio causes the program to be more adventurousin positing sparse links.)
The parameter t controlsthe tradeoff between reliability and the number oflinks.
In Method A, the value of t is the minimumnumber of phoneme links that have to be inducedfor the correspondence to be valid.
In methods B,C, and D, the value of t implies a likelihood scorethreshold of t  log ?+?  , which is a score achieved bya pair of phonemes that have t links out of t co-occurrences.
In the experiments reported in Sec-tion 6, d was set to 0:15, and t was set to 1 (suf-ficient to reject all non-recurring correspondences).In Method D, where the lack of vowel links causesthe linking constraints to be weaker, a higher valueof t = 3 was used.
These parameter values were op-timized on the development set described below.6 Evaluation6.1 The data for experimentsThe experiments in this section were performed us-ing a well-known list of 200 basic meanings that areconsidered universal and relatively resistant to lex-ical replacement (Swadesh, 1952).
The Swadesh200-word lists are widely used in linguistics andhave been compiled for a large number of lan-guages.The development set consisted of three 200-wordlist pairs adapted from the Comparative Indoeuro-pean Data Corpus (Dyen et al, 1992).
The cor-pus contains the 200-word lists for a number ofIndoeuropean languages together with cognationjudgments made by a renowned historical linguistIsidore Dyen.
Unfortunately, the words are rep-resented in the Roman alphabet without any dia-critical marks, which makes them unsuitable forautomatic phonetic analysis.
The Polish?Russian,Spanish?Romanian, and Italian?Serbocroatian wereselected because they represent three different levelsof relatedness (73.5%, 58.5%, and 25.3% of cognatepairs, respectively), and also because they have rel-atively transparent grapheme-to-phoneme conver-sion rules.
They were transcribed into a phoneticnotation by means of Perl scripts and then stemmedand corrected manually.The test set consisted of five 200-word lists repre-senting English, German, French, Latin, and Alba-nian, compiled by Kessler (2001) As the lists con-tain rich phonetic and morphological information,the stemmed forms were automatically convertedfrom the XML format with virtually no extra pro-cessing.
The word pairs classified by Kessler asdoubtful cognates were assumed to be unrelated.6.2 Determination of correspondences in wordpairsExperiments show that CORDI has little difficultyin determining correspondences given a set of cog-nate pairs (Kondrak, 2002) However, the assump-tion that a set of identified cognates is already avail-able as the input for the program is not very plausi-ble.
The very existence of a reliable set of cognatepairs implies that the languages in question have al-ready been thoroughly analyzed and that the soundcorrespondences are known.
A more realistic in-put requirement is a list of word pairs from twolanguages such that the corresponding words havethe same, well-defined meaning.
Determining cor-respondences in a list of synonyms is clearly a morechallenging task than extracting them from a list ofreliable cognates because the non-cognate pairs in-troduce noise into the data.
Note that Melamed?soriginal algorithm is designed to operate on alignedsentences that are guaranteed to be mutual transla-tions.cooc links score validr:r 26 24 158.7 yesn:n 24 23 154.2 yest:d 18 18 122.4 yesk:k 12 11 72.5 yess:s 11 10 65.7 yesf:p 9 9 61.2 yesm:m 10 9 58.9 yesd:t 10 8 49.8 nol:l 14 9 49.7 yesh:k 7 7 47.6 yesTable 2: English?Latin correspondences discoveredby CORDI in noisy synonym data.In order to test CORDI?s ability to determine cor-respondences in noisy data, Method D was appliedto the 200-word lists for English and Latin.
Only29% of word pairs are actually cognate; the remain-ing 71% of the pairs are unrelated lexemes.
Thetop ten correspondences discovered by the programare shown in Table 2.
Remarkably, all but one arevalid.
In contrast, only four of the top ten phonemematchings picked up by the ?2 statistic are valid cor-respondences (the validity judgements are my own).6.3 Identification of cognates in word pairsThe quality of correspondences produced byCORDI is difficult to validate, quantify, and com-pare with the results of alternative approaches.However, it is possible to evaluate the correspon-dences indirectly by using them to identify cog-nates.
The likelihood of cognation of a pair of wordsincreases with the number of correspondences thatthey contain.
Since CORDI explicitly posits corre-spondence links between words, the likelihood ofcognation can be estimated by simply dividing thenumber of induced links by the length of the wordsthat are being compared.
A minimum-length pa-rameter can be set in order to avoid computing cog-nation estimates for very short words, which tend tobe unreliable.ri word pair cognate?
i pi1 /hArt/:/kord/ yes 1 1.002 /hAt/:/kalid/ no3 /sno?/:/niw/ yes 2 0.66Table 3: An example ranking of cognate pairs.The evaluation method for cognate identificationalgorithms adopted in this section is to apply themto a bilingual wordlist and order the pairs accord-ing to their scores (refer to Table 3).
The rankingis then evaluated against a gold standard by com-puting the n-point average precision, a generaliza-tion of the 11-point average precision, where n isthe total number of cognate pairs in the list.
Then-point average precision is obtained by taking theaverage of n precision values that are calculated foreach point in the list where we find a cognate pair:pi = iri ; i = 1; : : : ;n, where i is the number of thecognate pair counting from the top of the list pro-duced by the algorithm, and ri is the rank of thiscognate pair among all word pairs.
The n-point pre-cision of the ranking in Table 3 is (1:0+0:66)=2 =0:83.
The expected n-point precision of a programthat randomly orders word pairs is close to the pro-portion of cognate pairs in the list.Languages MethodA B C DPolish Russian .989 .994 .994 .986Romanian Spanish .898 .948 .948 .875Italian Serbocr.
.499 .455 .527 .615Table 4: Average cognate identification precision onthe development set for various methods.Languages Proportion COGNATE JAKARTA Methodof cognates A B C DEnglish German .590 .878 .888 .936 .957 .952 .950French Latin .560 .867 .787 .843 .914 .838 .866English Latin .290 .590 .447 .584 .641 .749 .853German Latin .290 .532 .518 .617 .723 .736 .857English French .275 .324 .411 .482 .528 .545 .559French German .245 .390 .406 .347 .502 .487 .528Albanian Latin .195 .449 .455 .403 .432 .568 .606Albanian French .165 .306 .432 .249 .292 .319 .437Albanian German .125 .277 .248 .156 .177 .154 .312Albanian English .100 .225 .227 .302 .373 .319 .196Average .283 .484 .482 .492 .554 .567 .616Table 5: Average cognate identification precision on the test set for various methods.Table 4 compares the average precision achievedby methods A, B, C, and D on the development set.The cognation judgments from the Comparative In-doeuropean Data Corpus served as the gold stan-dard.All four methods proposed in this paper as wellas other cognate identification programs were uni-formly applied to the test set representing five In-doeuropean languages.
Apart from the English?German and the French?Latin pairs, all remaininglanguage pairs are quite challenging for a cognateidentification program.
In many cases, the gold-standard cognate judgments distill the findings ofdecades of linguistic research.
In fact, for some ofthose pairs, Kessler finds it difficult to show by sta-tistical techniques that the surface regularities areunlikely to be due to chance.
Nevertheless, in or-der to avoid making subjective choices, CORDI wasevaluated on all possible language pairs in Kessler?sset.Two programs mentioned in Section 2, COG-NATE and JAKARTA, were also applied to the testset.
The source code of JAKARTA was obtained di-rectly from the author and slightly modified accord-ing to his instructions in order to make it recognizeadditional phonemes.
Word pairs were ordered ac-cording to the confidence scores in the case of COG-NATE, and according to the edit distances in thecase of JAKARTA.
Since the other two programsdo not impose any length constraints on words, theminimum-length parameter was not used in the ex-periments described here.The results on the test set are shown in Table 5.The best result for each language pair is underlined.The performance of COGNATE and JAKARTA isquite similar, even though they represent two rad-ically different approaches to cognate identifica-tion.
On average, methods B, C, and D outper-form both comparison programs.
On closely re-lated languages, Method B, with its relatively un-constrained linking, achieves the highest precision.Method D, which considers only consonants, isthe best on fairly remote languages, where vowelcorrespondences tend to be weak.
The only ex-ception is the extremely difficult Albanian?Englishpair, where the relative ordering of methods seemsto be accidental.
As expected, Method A is out-performed by methods that employ an explicit noisemodel.
However, in spite of its extra complexity,Method C is not consistently better than Method B,perhaps because of its inability to detect importantvowel-consonant correspondences, such as the onesbetween French nasal vowels and Latin /n/.7 Conclusions and future workI have presented a novel approach to the determi-nation of correspondences in bilingual wordlists.The results of experiments indicate that the ap-proach is robust enough to handle a substantialamount of noise that is introduced by unrelatedword pairs.
CORDI does well even when thenumber of non-cognate pairs is more than doublethe number of cognate pairs.
When tested on thecognate-identification task, CORDI achieves sub-stantially higher precision than comparable pro-grams.
The correspondences are explicitly posited,which means that, unlike in some statistical ap-proaches, they can be verified by examining indi-vidual cognate pairs.
In contrast with approachesthat assume a rigid alignment based on the syl-labic structure, the models presented here can linkphonemes in any word position.Currently, I am working on the incorporation ofcomplex correspondences into the cognate identifi-cation algorithm by employing Melamed?s (1997)algorithm for discovering non-compositional com-pounds in parallel data.
Such an extension wouldovercome the limitation of the one-to-one model,in which links are induced only between individualphonemes.
Other possible extensions include takinginto account the phonological context of correspon-dences, combining the correspondence-based ap-proach with phonetic-based approaches, and iden-tifying correspondences and cognates directly indictionary-type data.The results presented here prove that the tech-niques developed in the context of statistical ma-chine translation can be successfully applied to aproblem in diachronic phonology.
The transfer ofmethods and insights should also be possible in theother direction.AcknowledgmentsThanks to Graeme Hirst, Radford Neal, andSuzanne Stevenson for helpful comments, toMichael Oakes for assistance with JAKARTA, andto Gemma Enriquez for helping with the experimen-tal evaluation of COGNATE.
This research was sup-ported by the Natural Sciences and Engineering Re-search Council of Canada.ReferencesY.
Al-Onaizan, J. Curin, M. Jahr, K. Knight, J. Laf-ferty, D. Melamed, F. Och, D. Purdy, N. Smith, andD.
Yarowsky.
1999.
Statistical machine translation.Technical report, Johns Hopkins University.Ted Dunning.
1993.
Accurate methods for the statisticsof surprise and coincidence.
Computational Linguis-tics, 19(1):61?74.Isidore Dyen, Joseph B. Kruskal, and Paul Black.1992.
An Indoeuropean classification: A lexicosta-tistical experiment.
Transactions of the AmericanPhilosophical Society, 82(5).
Word lists available athttp://www.ldc.upenn.edu/ldc/service/comp-ie.Jacques B. M. Guy.
1994.
An algorithm for identify-ing cognates in bilingual wordlists and its applicabilityto machine translation.
Journal of Quantitative Lin-guistics, 1(1):35?42.
MS-DOS executable available athttp://garbo.uwasa.fi.Brett Kessler.
2001.
The Significance of Word Lists.Stanford: CSLI Publications.
Word lists available athttp://spell.psychology.wayne.edu/bkessler.Philipp Koehn and Kevin Knight.
2001.
Knowledgesources for word-level translation models.
In Pro-ceedings of the 2001 Conference on Empirical Meth-ods in Natural Language Processing, pages 27?35.Grzegorz Kondrak.
2000.
A new algorithm for thealignment of phonetic sequences.
In Proceedings ofNAACL 2000: 1st Meeting of the North AmericanChapter of the Association for Computational Lin-guistics, pages 288?295.Grzegorz Kondrak.
2001.
Identifying cognates by pho-netic and semantic similarity.
In Proceedings ofNAACL 2001: 2nd Meeting of the North AmericanChapter of the Association for Computational Lin-guistics, pages 103?110.Grzegorz Kondrak.
2002.
Algorithms for Language Re-construction.
Ph.D. thesis, University of Toronto.Available at http://www.cs.toronto.edu/kondrak.John B. Lowe and Martine Mazaudon.
1994.
The re-construction engine: a computer implementation ofthe comparative method.
Computational Linguistics,20:381?417.Gideon S. Mann and David Yarowsky.
2001.
Multipathtranslation lexicon induction via bridge languages.
InProceedings of NAACL 2001: 2nd Meeting of theNorth American Chapter of the Association for Com-putational Linguistics, pages 151?158.I.
Dan Melamed.
1997.
Automatic discovery of non-compositional compounds in parallel data.
In Pro-ceedings of the Second Conference on EmpiricalMethods in Natural Language Processing, pages 97?108.I.
Dan Melamed.
1999.
Bitext maps and alignmentvia pattern recognition.
Computational Linguistics,25(1):107?130.I.
Dan Melamed.
2000.
Models of translational equiv-alence among words.
Computational Linguistics,26(2):221?249.Michael P. Oakes.
2000.
Computer estimation of vocab-ulary in protolanguage from word lists in four daugh-ter languages.
Journal of Quantitative Linguistics,7(3):233?243.Michel Simard, George F. Foster, and Pierre Isabelle.1992.
Using cognates to align sentences in bilingualcorpora.
In Proceedings of the Fourth InternationalConference on Theoretical and Methodological Is-sues in Machine Translation, pages 67?81, Montreal,Canada.Morris Swadesh.
1952.
Lexico-statistical dating of pre-historic ethnic contacts.
Proceedings of the AmericanPhilosophical Society, 96:452?463.Jo?rg Tiedemann.
1999.
Automatic construction ofweighted string similarity measures.
In Proceedingsof the Joint SIGDAT Conference on Empirical Meth-ods in Natural Language Processing and Very LargeCorpora, College Park, Maryland.Robert A. Wagner and Michael J. Fischer.
1974.
Thestring-to-string correction problem.
Journal of the As-sociation for Computing Machinery, 21(1):168?173.
