Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 25?28,New York, June 2006. c?2006 Association for Computational LinguisticsSemi-supervised Relation Extraction with Label PropagationJinxiu Chen1 Donghong Ji1 Chew Lim Tan2 Zhengyu Niu11Institute for Infocomm Research 2Department of Computer Science21 Heng Mui Keng Terrace National University of Singapore119613 Singapore 117543 Singapore{jinxiu,dhji,zniu}@i2r.a-star.edu.sg tancl@comp.nus.edu.sgAbstractTo overcome the problem of not hav-ing enough manually labeled relation in-stances for supervised relation extractionmethods, in this paper we propose a labelpropagation (LP) based semi-supervisedlearning algorithm for relation extractiontask to learn from both labeled and unla-beled data.
Evaluation on the ACE corpusshowed when only a few labeled examplesare available, our LP based relation extrac-tion can achieve better performance thanSVM and another bootstrapping method.1 IntroductionRelation extraction is the task of finding relation-ships between two entities from text.
For the task,many machine learning methods have been pro-posed, including supervised methods (Miller et al,2000; Zelenko et al, 2002; Culotta and Soresen,2004; Kambhatla, 2004; Zhou et al, 2005), semi-supervised methods (Brin, 1998; Agichtein and Gra-vano, 2000; Zhang, 2004), and unsupervised method(Hasegawa et al, 2004).Supervised relation extraction achieves good per-formance, but it requires a large amount of manu-ally labeled relation instances.
Unsupervised meth-ods do not need the definition of relation types andmanually labeled data, but it is difficult to evaluatethe clustering result since there is no relation typelabel for each instance in clusters.
Therefore, semi-supervised learning has received attention, whichcan minimize corpus annotation requirement.Current works on semi-supervised resolution forrelation extraction task mostly use the bootstrap-ping algorithm, which is based on a local consis-tency assumption: examples close to labeled ex-amples within the same class will have the samelabels.
Such methods ignore considering the simi-larity between unlabeled examples and do not per-form classification from a global consistency view-point, which may fail to exploit appropriate mani-fold structure in data when training data is limited.The objective of this paper is to present a labelpropagation based semi-supervised learning algo-rithm (LP algorithm) (Zhu and Ghahramani, 2002)for Relation Extraction task.
This algorithm worksby representing labeled and unlabeled examples asvertices in a connected graph, then propagating thelabel information from any vertex to nearby verticesthrough weighted edges iteratively, finally inferringthe labels of unlabeled examples after the propaga-tion process converges.
Through the label propaga-tion process, our method can make the best of theinformation of labeled and unlabeled examples to re-alize a global consistency assumption: similar ex-amples should have similar labels.
In other words,the labels of unlabeled examples are determined byconsidering not only the similarity between labeledand unlabeled examples, but also the similarity be-tween unlabeled examples.2 The Proposed Method2.1 Problem DefinitionLet X = {xi}ni=1 be a set of contexts of occurrencesof all entity pairs, where xi represents the contextsof the i-th occurrence, and n is the total number ofoccurrences of all entity pairs.
The first l examplesare labeled as yg ( yg ?
{rj}Rj=1, rj denotes relationtype and R is the total number of relation types).And the remaining u(u = n?
l) examples are unla-beled.Intuitively, if two occurrences of entity pairs have25the similar contexts, they tend to hold the same re-lation type.
Based on this assumption, we create agraph where the vertices are all the occurrences ofentity pairs, both labeled and unlabeled.
The edgebetween vertices represents their similarity.
Thenthe task of relation extraction can be formulated asa form of propagation on a graph, where a vertex?slabel propagates to neighboring vertices accordingto their proximity.
Here, the graph is connected withthe weights: Wij = exp(?
s2ij?2 ), where sij is the sim-ilarity between xi and xj calculated by some simi-larity measures.
In this paper,two similarity mea-sures are investigated, i.e.
Cosine similarity measureand Jensen-Shannon (JS) divergence (Lin, 1991).And we set ?
as the average similarity between la-beled examples from different classes.2.2 Label Propagation AlgorithmGiven such a graph with labeled and unlabeled ver-tices, we investigate the label propagation algorithm(Zhu and Ghahramani, 2002) to help us propagatethe label information of any vertex in the graphto nearby vertices through weighted edges until aglobal stable stage is achieved.Define a n ?
n probabilistic transition matrix TTij = P (j ?
i) = wij?nk=1 wkj, where Tij is the prob-ability to jump from vertex xj to vertex xi.
Also de-fine a n?R label matrix Y , where Yij representingthe probabilities of vertex yi to have the label rj .Then the label propagation algorithm consists thefollowing main steps:Step1: Initialization Firstly, set the iteration in-dex t = 0.
Then let Y 0 be the initial soft labels at-tached to each vertex and Y 0L be the top l rows of Y 0,which is consistent with the labeling in labeled data(Y 0ij = 1 if yi is label rj and 0 otherwise ).
Let Y 0Ube the remaining u rows corresponding to unlabeleddata points and its initialization can be arbitrary.Step 2: Propagate the label by Y t+1 = TY t,where T is the row-normalized matrix of T , i.e.Tij = Tij/?k Tik, which can maintain the classprobability interpretation.Step 3: Clamp the labeled data, i.e., replace thetop l row of Y t+1 with Y 0L .
In this step, the labeleddata is clamped to replenish the label sources fromthese labeled data.
Thus the labeled data act likesources to push out labels through unlabeled data.Table 1: Frequency of Relation SubTypes in the ACE trainingand devtest corpus.Type SubType Training DevtestROLE General-Staff 550 149Management 677 122Citizen-Of 127 24Founder 11 5Owner 146 15Affiliate-Partner 111 15Member 460 145Client 67 13Other 15 7PART Part-Of 490 103Subsidiary 85 19Other 2 1AT Located 975 192Based-In 187 64Residence 154 54SOC Other-Professional 195 25Other-Personal 60 10Parent 68 24Spouse 21 4Associate 49 7Other-Relative 23 10Sibling 7 4GrandParent 6 1NEAR Relative-Location 88 32Step 4: Repeat from step 2 until Y converges.Step 5: Assign xh(l + 1 ?
h ?
n) with a label:yh = argmaxjYhj .3 Experiments and Results3.1 DataOur proposed graph-based method is evaluated onthe ACE corpus 1, which contains 519 files fromsources including broadcast, newswire, and news-paper.
A break-down of the tagged data by differentrelation subtypes is given in Table 1.3.2 FeaturesWe extract the following lexical and syntactic fea-tures from two entity mentions, and the contexts be-fore, between and after the entity pairs.
Especially,we set the mid-context window as everything be-tween the two entities and the pre- and post- contextas up to two words before and after the correspond-ing entity.
Most of these features are computed fromthe parse trees derived from Charniak Parser (Char-niak, 1999) and the Chunklink script 2 written bySabine Buchholz from Tilburg University.1 http://www.ldc.upenn.edu/Projects/ACE/2Software available at http://ilk.uvt.nl/?sabine/chunklink/26Table 2: Performance of Relation Detection: SVM and LP algorithm with different size of labeled data.
The LP algorithm isperformed with two similarity measures: Cosine similarity and JS divergence.SVM LPCosine LPJSPercentage P R F P R F P R F1% 35.9 32.6 34.4 58.3 56.1 57.1 58.5 58.7 58.510% 51.3 41.5 45.9 64.5 57.5 60.7 64.6 62.0 63.225% 67.1 52.9 59.1 68.7 59.0 63.4 68.9 63.7 66.150% 74.0 57.8 64.9 69.9 61.8 65.6 70.1 64.1 66.975% 77.6 59.4 67.2 71.8 63.4 67.3 72.4 64.8 68.3100% 79.8 62.9 70.3 73.9 66.9 70.2 74.2 68.2 71.1Table 3: Performance of Relation Classification on Relation Subtype: SVM and LP algorithm with different size of labeled data.The LP algorithm is performed with two similarity measures: Cosine similarity and JS divergence.SVM LPCosine LPJSPercentage P R F P R F P R F1% 31.6 26.1 28.6 39.6 37.5 38.5 40.1 38.0 39.010% 39.1 32.7 35.6 45.9 39.6 42.5 46.2 41.6 43.725% 49.8 35.0 41.1 51.0 44.5 47.3 52.3 46.0 48.950% 52.5 41.3 46.2 54.1 48.6 51.2 54.9 50.8 52.775% 58.7 46.7 52.0 56.0 52.0 53.9 56.1 52.6 54.3100% 60.8 48.9 54.2 56.2 52.3 54.1 56.3 52.9 54.6Words: Surface tokens of the two entities andthree context windows.Entity Type: the entity type of both entity men-tions, which can be PERSON, ORGANIZATION,FACILITY, LOCATION and GPE.POS: Part-Of-Speech tags corresponding to alltokens in the two entities and three context windows.Chunking features: Chunk tag information andGrammatical function of the two entities and threecontext windows.
IOB-chains of the heads of thetwo entities are also considered.
IOB-chain notesthe syntactic categories of all the constituents on thepath from the root node to this leaf node of tree.We combine the above features with their positioninformation in the context to form the context vec-tor.
Before that, we filter out low frequency featureswhich appeared only once in the entire set.3.3 Experimental Evaluation3.3.1 Relation DetectionWe collect all entity mention pairs which co-occurin the same sentence from the training and devtestcorpus into two set C1 and C2 respectively.
The setC1 includes annotated training data AC1 and un-related data UC1.
We randomly sample l examplesfrom AC1 as labeled data and add a ?NONE?
classinto labeled data for the case where the two entitymentions are not related.
The data of the ?NONE?Table 4: Comparison of performance on individual relationtype of Zhang (2004)?s method and our method.
For Zhang(2004)?s method, feature sampling probability is set to 0.3 andagreement threshold is set to 9 out of 10.Bootstrapping LPJSRel-Type P R F P R FROLE 78.5 69.7 73.8 81.0 74.7 77.7PART 65.6 34.1 44.9 70.1 41.6 52.2AT 61.0 84.8 70.9 74.2 79.1 76.6SOC 47.0 57.4 51.7 45.0 59.1 51.0NEAR undef 0 undef 13.7 12.5 13.0class is resulted by sampling l examples from UC1.Moreover, we combine the rest examples of C1 andthe whole set C2 as unlabeled data.Given labeled and unlabeled data,we can performLP algorithm to detect possible relations, whichare those entity pairs that are not classified to the?NONE?
class but to the other 24 subtype classes.In addition,we conduct experiments with differentsampling set size l, including 1% ?
Ntrain,10% ?Ntrain,25%?Ntrain,50%?Ntrain,75%?Ntrain,100% ?
Ntrain (Ntrain = |AC1|).
If any majorsubtype was absent from the sampled labeled set,weredo the sampling.
For each size,we perform 20 tri-als and calculate an average of 20 random trials.3.3.2 SVM vs. LPTable 2 reports the performance of relation detec-tion by using SVM and LP with different sizes of27labled data.
For SVM, we use LIBSVM tool withlinear kernel function 3.
And the same sampled la-beled data used in LP is used to train SVM mod-els.
From Table 2, we see that both LPCosine andLPJS achieve higher Recall than SVM.
Especially,with small labeled dataset (percentage of labeleddata ?
25%), this merit is more distinct.
Whenthe percentage of labeled data increases from 50%to 100%, LPCosine is still comparable to SVM in F-measure while LPJS achieves better F-measure thanSVM.
On the other hand, LPJS consistently outper-forms LPCosine.Table 3 reports the performance of relation classi-fication, where the performance describes the aver-age values over major relation subtypes.
From Table3, we see that LPCosine and LPJS outperform SVMby F-measure in almost all settings of labeled data,which is due to the increase of Recall.
With smallerlabeled dataset, the gap between LP and SVM islarger.
On the other hand, LPJS divergence consis-tently outperforms LPCosine.3.3.3 LP vs. BootstrappingIn (Zhang, 2004), they perform relation classifi-cation on ACE corpus with bootstrapping on top ofSVM.
To compare with their proposed BootstrappedSVM algorithm, we use the same feature stream set-ting and randomly selected 100 instances from thetraining data as the size of initial labeled data.Table 4 lists the performance on individual rela-tion type.
We can find that LP algorithm achieves6.8% performance improvement compared with the(Zhang, 2004)?s bootstrapped SVM algorithm aver-age on all five relation types.
Notice that perfor-mance reported on relation type ?NEAR?
is low, be-cause it occurs rarely in both training and test data.4 Conclusion and Future workThis paper approaches the task of semi-supervisedrelation extraction on Label Propagation algorithm.Our results demonstrate that, when only very fewlabeled examples are available, this manifold learn-ing based algorithm can achieve better performancethan supervised learning method (SVM) and boot-strapping based method, which can contribute to3LIBSVM : a library for support vector machines.
Soft-ware available at http://www.csie.ntu.edu.tw/?cjlin/libsvm.minimize corpus annotation requirement.
In the fu-ture we would like to investigate how to select moreuseful feature stream and whether feature selectionmethod can improve the performance of our graph-based semi-supervised relation extraction.ReferencesAgichtein E. and Gravano L. 2000.
Snowball: Extracting Rela-tions from large Plain-Text Collections, In Proceeding of the5th ACM International Conference on Digital Libraries.Brin Sergey.
1998.
Extracting patterns and relations fromworld wide web.
In Proceeding of WebDB Workshop at 6thInternational Conference on Extending Database Technol-ogy.
pages 172-183.Charniak E. 1999.
A Maximum-entropy-inspired parser.
Tech-nical Report CS-99-12.
Computer Science Department,Brown University.Culotta A. and Soresen J.
2004.
Dependency tree kernels forrelation extraction, In Proceedings of 42th ACL conference.Hasegawa T., Sekine S. and Grishman R. 2004.
Discover-ing Relations among Named Entities from Large Corpora,In Proceeding of Conference ACL2004.
Barcelona, Spain.Kambhatla N. 2004.
Combining lexical, syntactic and semanticfeatures with Maximum Entropy Models for extracting rela-tions, In Proceedings of 42th ACL conference.
Spain.Lin,J.
1991.
Divergence Measures Based on the Shannon En-tropy.
IEEE Transactions on Information Theory.
37:1,145-150.Miller S.,Fox H.,Ramshaw L. and Weischedel R. 2000.
A noveluse of statistical parsing to extract information from text.In Proceedings of 6th Applied Natural Language ProcessingConference 29 April-4 may 2000, Seattle USA.Yarowsky D. 1995.
Unsupervised Word Sense DisambiguationRivaling Supervised Methods.
In Proceedings of the 33rd An-nual Meeting of the Association for Computational Linguis-tics.
pp.189-196.Zelenko D., Aone C. and Richardella A.
2002.
Kernel Meth-ods for Relation Extraction, In Proceedings of the EMNLPConference.
Philadelphia.Zhang Zhu.
2004.
Weakly-supervised relation classification forInformation Extraction, In proceedings of ACM 13th con-ference on Information and Knowledge Management.
8-13Nov 2004.
Washington D.C.,USA.Zhou GuoDong, Su Jian, Zhang Jie and Zhang min.
2005.Combining lexical, syntactic and semantic features withMaximum Entropy Models for extracting relations, In pro-ceedings of 43th ACL conference.
USA.Zhu Xiaojin and Ghahramani Zoubin.
2002.
Learning fromLabeled and Unlabeled Data with Label Propagation.
CMUCALD tech report CMU-CALD-02-107.28
