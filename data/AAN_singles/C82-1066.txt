COLING 82, ,IT.
Horeck2) (ed.
)North.Holland Publishing Company?
Academi~ 1982Taking the Initiative in Natural LanguageData Base Interactions: Justifying WhyBonnie Webber and Aravind JoshlDepartment of Computer and Information ScienceUniversity of PennsylvaniaPhiladelphia PA 19104I.
IntroductionIn answering a factual database query, one often has the option of providingmore than just the answer explicitly requested.
As part of our research onNatural Language interactions with databases~ we have been looking at three waysin which the system could so "take the initiative" in constructing a response:(i) pointing out incorrect presuppositions reflected in the user's query \[4,5\];(2) offering to "monitor" for the requested information or additional relevantinformation as the system learns of it \[6,7\]; and (3) providing grounds for thesystem's response i.e., "justifying why".
The following responses illustrate"presupposition correctlon"~ "monitor offers" and "justification", respectively.This paper describes our research on producing justifications.
("U" refers to theuser, "S" to the system.
)U: Is John taking four courses?SI: No.
John can't take any courses: he's not a student.$2: NoD three.
Shall I let you know if he registers for a fourth?$3: No, three - CIS531, CIS679 and Linguistics 650.Database systems are growing more complex in both their domain models andreasoning capabilities.
For many reasons, it is important that such systems beable to point the user to what responses follow from.
In this regard,Justification differs from argument, whose role is to convince the listener.
Therole of justification is rather to give the listener an informed basis for eitheraccepting the system's response or quest\[onlng its premises or reasoning.There are at least three issues involved in producing Justifications:(I) what Justification does a query call for?
(2) what justification can the system give?
(3) What constitutes a clear and understandab\]e justification?The first depends prlmarily on whether or not the user's perceivedexpectations have been fulfilled by the system's answer.
For example, the use of"still" in a query indicates that the user expects that the potentially changingsituation described in hls/her query has not in fact changed.U: Does anyone still have an Incomplete in CSE1107$I: Yes, John does.$2: No.
The last remaining Incomplete was made up on 1 December.If the user's expectation is correct (i.e., not all Ineompletes have been nkadeup), then facts corroborating that expectation may constitute appropriatejustification as in the "yes" answer above.
If it isn't correct (as ~n the "no"case), then specifying the event that enabled the change may constitue a moreappropr ia te  jus t i f i ca t ion .413414 B. WEBBER and A. JOSHIMore often than not, the user's expectations will not be as clearlyidentif lable as in the "still" case above.
The system will have to formulate andkeep a growing model of the user, as its basis for determining what situation theuser believes to hold and hence what s/he expects to learn from his or herqueries.
This is a slgnlficant area of research, which we are pursulng inparallel wlth the work report'ed on in this paper.The second ~ssue in Justifying a dlrect answer is what justif ication thesystem can give.
In the simple case, the system may know no more than thepartlcular facts in its data base.
In that case, the only justif ication thesystem can provide is those facts themselves (or some description of them).
Forexample, suppose the system knows for each student-course palr only whether thestudent h~d passed (P) or failed (F) the course.
Then only the followingjustflcatlon is possible:U: Did anyone fail CIS531?S: Yes, John and Martha.On the other hand, some reasoning may have been involved in deriving the answer,as in the case where the system knows (e.g.
has an axiom to the effect) that"fall ing" a graduate course follows from a receiving a grade of C or worse.
Inthis case, speclfyi~g the particular grade each fall ing student recelved could beused to justify the system's assertion that they had failed - i.e.,U: Did anyone fall CIS531?S: Yes, John recelved a C and Martha, a D.Or the system could give some indlcatlon of its reasoning as well, as inU: Did anyone fail CIS531?S: Yes.
With a graduate course, everyone fails who gets a C or below.
InCIS531, John received a C and Martha, a D.We shall clalm that posslble Justificatlons are related but not equivalent tohow the system comes to know an answer.
The reason for this reservation has to dowith the third issue mentioned earlier in justifying a direct answer and the onewe wil l  address further In this paper: that is, what constitutes a clear andunderstandable justlficatlon.II?
Towards Clear and Informative Justlf icationsThe issue of clear and understandable justifications is important everywherethat reasoning is involved in deriving an answer, be it database systems, expertsystems or elsewhere.
While our theme is extended database questlon-answerlng, webelieve our points are of general applicabll lty.
Where reasoning is involved inderiving an answer, clarity and ease of understanding translate into two goals:(i) succinct justlflcatlons that do not say more than Is necessary (lest they losethe user)  and (2) conceptually well-structured justifications that the user canunderstand and evaluate.
To meet the first goal, we are drawing upon an oft-madeobservation \[2,|0, II\], first made in Arlstotle's Rhe___ toric, that in exposltlon,"abbreviated proofs" ~ what Sadoek has called "modus breves" - are both sufflelentand desirable.
Our approach to the second goal draws on the strong similarity wesee between reasoning and hierarchical planning.
Again, while our examples willbe drawn prlmarlly from the database domain, our approach, discussed in moredeta~l below, should be of general interest.JUSTIFYING WIlY 415A.
Succinct Justif ications - "Modus Brevis"As a simple i l lustration of "modus brevis" and its use in forming succinctjustifications, consider a modus ponens deduction, possibly used in deriving anassertion and now to be used in justifying it.
It has been observed that inpresenting such reasoning one need not make explicit all three parts of the proof- the major premise (A -> B), the mlnor premise (A), and the conclusion (B).Rather it is sufficient to state the conclusion, with either the major premise orminor premise (but not both) as support.
So suppose in response to the query "DidJohn fall physics?
", the system makes the following modus ponens deductionAnyone who gets below a C fails physics.
(e major premise *)John got below a C. (* minor premise *)John failed physics.
(* conclusion *)The system can then justify its "yes" answer in either of the following ways,relying on the user's abil ity to recognize the underlying deduction.S: Yes.
Everyone failed physlcs who got below a C.S: Yes.
He got below a C."Modus brevls" forms can be used in justifying other types of reasoning aswell) both deductive and non-monotonlc.
However, the speaker must be able toassume that the listener can, on the bas~s of what is essentially a clue to anargument, reconstruct that argument.
On the other hand, whether the listener isconvinced by the argument s/he deduces - i.e., whether s/he accepts the inferredpremise - is a separate issue: the listener can always initiate a subsequentinteraction to confirm that s/he has inferred what the speaker has intended or to~uest ion it.
For example,U: Did John fail physics?S: Yes.
He got a B.U: Is the fail ing grade really B or below?Since the successful use of' "modus brevis" in justifications dependsessential ly on the listener's ability to reconstruct an argument from a singleclue, it is only used in place of very short reasoning chains.
On the other hand,the reasoning we may want to Justify may grow quite large and complex.
Thus weexpect to "modus brevis" forms to reduce the bulk of substructures, rather thanfor Justifying entire arguments.
Currently we are cataloguing "modus brevls"forms of various argument types and notlng context-dependencies in their use.These schemas wlll then be used as tools for generating succinct justlfications.B.
Clear Justif ications - Hierarchical ReasoningThe other goal of our research into producing justifications involvescreating text structures which convey appropriate justifications in anunderstandable way.
We have two claims to make here.
The first is that just asactions have a hierarchlcal conceptual organlzatlon, so does reasonln~ - which isessentlal ly the act of supporting or denying a propesltion.
The formerorganization can be used in formln~ plans, revising plans, or describing them toanother person \[3,9\].
Siml\]ar\]y, the hierarchical organization of reasoning canbe used both in constructln 8 a proof and in ~ a  result.
Our second claimIs that the computatlonally efflclent reasoning strategies used to r ~  aproposlt ien (~.e., respond to a query) are not necessarily the best ones to use inJustifying a result.
What one wants rather is the ability to use the system'sreasoning to suggest and instantiate conceptually more accessible strategles fnrorganlz~ng and presenting justi f ications.
Both claims will be discussed in thissection.
"416 B. WEBBER ~nd A. JOSH1Many researchers have already observed that explanations have a tree-llkestructure.
This observation reflects a view of each supported assertion as anon-terminal node in a tree, with the sub-tree under it corresponding to thereasons given in its support \[2,11\].
Since a statement acting as a "reason" mayin turn be supported by other statements/reasons, explanations have a recursivestructure.While the above is true, it masks what we see as a more significant recursiveorganization - one that reflects the inherently recursive strategies that peopleuse in reasoning (i.e., in supporting or denying propositions).
These strategiesare recurslve because they contain subtasks that call in turn for otherpropositions to be supported or denied.
One way to accomplish this is to choseand invoke another strategy.
The kinds of strategies we have in mind are thingslike:o Simple Backward Chaining - to show that Q is true, find a set ofpropositions P1,.. .
,Pk from whose simultaneous satisfaction Q follows.
Foreach Pi, show that it follows.
Hence Q must be true.o Simple Case Analysis - to show that Q is true, find some proposit ion P fromwhich Q follows, ~ndependent of P's truth value.
Assume P and show that Qfollows.
Assume ~P and show the same.
Since either P or ~P must be true, Qmust be true.
(Alternatively, to show Q ~s false, find some P from which ~Qfollows, independent of P's truth value.
Assume P and show ~Q follows.
Dothe same for -P. Since P or ~P, ~Q must be true - hence Q is false.
)o General Case Analysis - to show that Q is true, find some assertion P thatis partltionable into P1,...,Pk.
Assume each Pi in turn and show that Qfollows from Pi.
Since some Pi must be true given P is, Q must be true.
(This has the obvious complementary strategy for showing Q false.
)o Reduction ad Absurdum - to show that Q is false, find some proposit ion Pwhose both assertion and negation follow from Q.
Assume Q and show that Pfollows.
Show that ~P follows.
Since Q leads to both P and ~P, Q must befalse.
(Other strategies are noted in the full version of this paper.)
Wherever astrategy calls for showing "P follows" or "~P follows", there another strategy maybe chosen and invoked in support.
That such strategies are used in reasoning iswell-known.
What is significant where explanation and Justif ication are concernedis that where the strategy is clear from the text, the explanation orjustif ication is that much easier to follow.To see this, consider the following tale, whose humor follows in part fromthe recursive use of simple case analysis in support of successive alternatives.What is there to be frightened of__~?War was on the horizon.
Two students in the Yeshiva were discussing thesituation.
"I hope I'm not called," said one.
"I'm not the type for war.
I have thecourage of the spirit, but nevertheless I shrink from it.
""But what is there to be frightened about?"
asked the other.
"Let's analyzeit After all, there are two possibilities: either war will break out or itwon't.
If it doesn't, there's no cause for alarm.
If it does, there aretwo possibilities: either they take you or they don't take you.
If theydon't, alarm is needless.
And even if they do, there are two possibil ities:either you're given combat duty, or non-combatant duty.
If non-combatant,JUSTIFYING WHY 417what is there to be worried about?
And if combat duty, there are twopossibilities: you'll be wounded, or you won't.
Now if you're not wounded,you can forget your fears.
But even if you are wounded, there are twopossibilities: either you're wonded gravely or you're wounded slightly.
Ifyou're wounded slightly, your fear is nonsensical, and if you're woundedgravely, there are still two possibilitles: either you succumb and die, oryou don't succumb and you 1lye.
If you don't die, things are fine, and evenif you do die, there are two possibilities: either you will be buried in aJewish cemetery or you won't.
Now if you're buried in a Jewish cemetery,what Is there to worry about, and even if you are not ... but why beafraid?
There may not be any war at all!"
\[I\] p.63In this example, "there's no call for worry" is the Q meant to be proven.
Theinitial P being used to support Q independent of its truth value is "war willbreak out".
Assuming "P (i.e., war won't break out), then Q follows because"obviously" -P -> Q.
On the other hand, to show Q follows from assuming P, thespeaker invokes a simple case analysis strategy again, this time finding P'- "theytake you \[into the army\]" - meant to support Q independent of its truth value, andso forth.Our second claim is that the reasoning strategy used to prove someproposition (i.e., respond to some query) is not necessarily the best one to usein justifying the result to the user.
What one wants is to be able to use proofsto suggest an appropriate organization of supportable strategies that c~n beInstantlated to form the basis for an understandable justification.
Moore's"Blocks World" example \[8\] provides a good case in point.
In this example, thereare three blocks A,B and C. A is on B (On A B) and B is on C (On B C)'.
A isgreen (Green A), C is blue (Blue C) and B's color is not known.
It is also thecase that whatever is blue is not green and vice versa (ALL x .
Green x => -Bluex).
The question is"Is there a green block on a non-green block?
"(EXIST x,y .
Green x AND "Green y AND On x,y)Resolutlon Is the only slmple machine reasoning method that can find thecorrect answer "yes" to this problem.
(Simple backward-chalnlng orforward-deductlon systems require an additional procedure called "restrictedgoal/fact resolution".)
Converting the above facts and axioms to clause form andusing resolution, one proof goes as follows:(1) -Green x OR Green y OR "On x,y(2) Green A(3) Green y OR "On A,y(4) On A,B(5) Green B(6) Green y OR -On B,y(7) On B,C(8) Green C(9) -Green z OR -Blue z(i0) -Blue C(II) Blue C(12) NIL\[negation of theorem\]\[axiom\]\[resolving 1 and 2\]\[axiom\]\[resolving 3 and 4\]\[resolving I and 5\]\[axiom\]\[resolving 6 and 7\]\[axiom\]\[resolving 8 and 9\]\[axiom\]\[resolving I0 and 11\]What this proof does not make obvious is that the answer follows byconsidering all colors that B can take (that is, green and non-green).
Neitherdoes the proof make obvious that the answer follows in either case, even though adifferent situation holds.
That these are the elements of what people give inwhat they think of as understandable justifications can be seen in protoeals thatwe have collected of people justifying their answers to Moore's problem: most ofthem do so using a ~ case analysis strategy.
For example,418 B. WEBBER and A. JOSHI"Yes - it doesn't matter what color B is.
If it's green, then it is thegreen block on top of a nos-green block C. If it's not green, then A is thegreen block on top of a non-green block B.
"Our point is that while resolution theorem provers may be appropriatereasoning engines for data base systems, their proofs do not form a good basis forunderstandable Justifications.
Thus at least part of our research is aimed atdiscovering whether one could recognize in the proof tree of a theorem which ofthe above understandable reasoning strategies could be in justifying the resultand then construct an appropriate valid justification in terms of thosestrategies.III.
ConclusionThis paper  has repor ted  br ie f ly  on our research  on jus t i f i ca t ion .
I t  i s  anabbrev ia ted  vers ion  of our techn ica l  repor t  CIS-82-1,  which can be obta ined  bywriting to the authors.The authors would llke to thank Barbara Grosz for her helpful commentson previous drafts.REFERENCES\[1\] Ausubel ,  N. (ed . )
A T reasur~ of Jewish Fo lk lo re .
New York: CrownPub l i shers ,  1948.
(Abr idged ed i t ion  pub l i shed  by Bantam Books, 1980.
)\[2\] Cohen, R. "Investigation of Processing Strategies for the Structural Analyslsof Arguments".
Proc.
19th Annual ACL Meeting.
Stanford CA, June 1981.\[3\] Grosz, B. Th____eeRepresentatlon an___ddUs__ee of Foc____us In.
D i ~  Understanding.Technical Report 151.
SRI International, Menlo Park CA, 1977.\[4\] Kaplan, S.J.
Cooperative Responses from a Portable Natural Lan~ Data BaseQue~ System.
Ph.D. thesis.
Department of Computer and Information Science,University of Pennsylvania.\[5\] Mays, E. "Correcting Misconceptions about Data Base Structure".
Proc.3-CSCSI.
Victoria, B.C., May 1980.\[6\] Flays, E., Lanka, S., Joshl, A.K.
and Webber, B.L.
"Natural LanguageInteraction with Dynamic Knowledge Bases: Monitoring as Response".
Proc.8-1JCAI.
Vancouver, B.C., August 1981.\[7\] Mays, E., Joshi, A.K.
and Webber, B.L.
"Taking the Initiative in NaturalLanguage Data Base Interactions: Monitoring as Response".
Proc.
1982European Conference on Artificial Intelligence, Orsay, France, July 1982.\[8\] Moore, R. Reasoning from Incomplete Knowledge in a Procedural DeductionS s ~ .
Technical Report 347.
MIT Artlflcial Intelligence Lab.
Cambridge MA,1975.\[9\] Sacerdoti, E. A Structure for Plans and Behavior.
New York: Elsevler, 1977\[i0\] Sadock, J.
'~odus Brevis: The truncated argument".
Papers from the 13thChicago Linguistics Society Meeting, Chicago IL, 1977.\[II\] Welner, J.
"BLAH, A System which Explains its Reasoning."
ArtificialIntelllgence, 15, 19-48.
