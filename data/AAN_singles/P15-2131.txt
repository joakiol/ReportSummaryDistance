Proceedings of the 53rd Annual Meeting of the Association for Computational Linguisticsand the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 800?805,Beijing, China, July 26-31, 2015.c?2015 Association for Computational LinguisticsDialogue Management based on Sentence ClusteringWendong GeInstitute of Automation,Chinese Academy of Sciences,Beijing, Chinawendong.ge@ia.ac.cnBo XuInstitute of Automation,Chinese Academy of Sciences,Beijing, Chinaxubo@ia.ac.cnAbstractDialogue Management (DM) is a key is-sue in Spoken Dialogue System (SDS).Most of the existing studies on DM useDialogue Act (DA) to represent seman-tic information of sentence, which mightnot represent the nuanced meaning some-times.
In this paper, we model DM basedon sentence clusters which have morepowerful semantic representation abilitythan DAs.
Firstly, sentences are clusterednot only based on the internal informa-tion such as words and sentence structures,but also based on the external informationsuch as context in dialogue via Recurren-t Neural Networks.
Additionally, the DMproblem is modeled as a Partially Observ-able Markov Decision Processes (POMD-P) with sentence clusters.
Finally, exper-imental results illustrate that the proposedDM scheme is superior to the existing one.1 IntroductionDialogue Management (DM) is an important is-sue in Spoken Dialogue Systems (SDS).
(Paek etal., 2008) Most of the existing studies on DM usethe abstract semantic representation such as Dia-logue Act (DA) to represent the sentence intention.In (Bohus et al., 2009), authors propose a plan-based, task-independent DM framework, calledRavenClaw, which isolates the domain-specific as-pects of the dialogue control logic from domain-independent conversational skills.
(Daubigney etal., 2010) proposes a Kalman Temporal Differ-ences based algorithm to learn efficiently in an off-policy manner a strategy for a large scale dialoguesystem.
In (Emmanuel et al., 2013), authors pro-pose a scheme to utilize a socially-based rewardfunction for reinforcement learning and use it tofit the user adaptation issue for DM.
(Young et al.,2013) provides an overview of the current state ofthe art in the development of POMDP-based spo-ken dialog systems.
(Hao et al., 2014) presents adialog manager based on a log-linear probabilisticmodel and uses context-free grammars to imparthierarchical structure to variables and features.As we know, sentences in human-human dia-logues are extremely complicated.
The sentenceslabeled with the same DA might contain differ-ent extra meanings.
Thus, it is difficult for DAto represent the nuanced meaning of sentence indialogue.
In this paper, we propose a novel DMscheme based on sentence clustering.
The contri-butions of this work are as follows.?
Semantic representation of sentence in dia-logue is defined as sentence cluster whichcould represent more nuanced semantic in-formation than DA.
Sentence similarity forclustering is calculated via internal informa-tion such as words and sentence structuresand external information such as the dis-tributed representation of sentence (vector)from Recurrent Neural Networks (RNN).?
The DM problem is modeled as a POMD-P, where state is defined as sequence of sen-tence clusters, reward is defined as slot-fillingefficiency and sentence popularity, and statetransition probability is calculated by the pre-diction model based on RNN, consideringhistorical dialogue information sufficiently.The rest of this paper is organized as follows.In Section 2, system model is introduced.
Sec-tion 3 describes sentence clustering and predictionmodel based on RNN, and Section 4 models theDM problem as a POMDP.
Extensive experimen-tal results are provided in Section 5 to illustrate theperformance comparison, and Section 6 concludesthis study.800?A1: I need to record the quantity of clients.B1: Perhaps 3 persons.?
?A2: please tell me the number of clients.B2: Is it necessary?A3: Yes, I need to record this.B3: OK, 3 persons, maybe.
?request (client_quantity)I have to know how many persons will live in.It is necessary to record the number of clients....DA1Cluster 1request (client_quantity)DA1Do you mind telling me the quantity of clients?Please let me know how many persons will live in....Cluster 2Figure 1: sentence cluster vs. DAuserASR SentenceMatchingTTS SentenceSelectingDMSentence ClusteringDialogue Corpusvoiceofflinetext clusterclustertextvoiceonlineFigure 2: system model2 System ModelIn this paper, we establish a SDS via human-human dialogue corpus, where sentence clusterrather than DA is utilized to represent sentence in-tention due to its ability of catching finer-grainedsemantic information.
For example, Fig.
1shows some dialogue segments in hotel reserva-tion.
Both A1 and A2 could be labeled with ?re-quest (client quantity)?, because the aims of themare requesting the quantity of clients.
Howev-er, A1 has an extra meaning that it is a necessityfor the reception to record the quantity of clients,while A2 not, which might lead to different evo-lutions of dialogues.
Probably, we could add thisnecessity to the DA corresponding to A1 manual-ly, but it is infeasible for all the sentences to dis-tinguish the fine-grained semantic information byadding abstract symbol to DA.
Thus, in this paper,we automatically cluster all the sentences in dia-logues, and utilize sentence clusters to representsentence intentions, which has more powerful ca-pability to capture semantic information.The SDS based on sentence clustering could bedivided into offline stage and online stage, illus-trated in Fig.
2.In offline stage:Sentence Clustering: The sentence similarityis calculated based on not only internal informa-tion such as words and sentence structure, but alsoexternal information such as the distributed rep-resentation from RNN.
And then the sentences indialogue corpus are clustered into different tinygroups, which will be discussed in section 3.Hello, I want to reserve a double roomTwo double room.
Your check-in time?I need only one double room.I am sorry.
One double room.
OK.C27: 0.63C15: 0.37C15: 0.88C79: 0.12ASR+SMASR+SMC283C125TTS+SSTTS+SS...DMroom type double roomroom num 2... ...room type double roomroom num 1... ...slot fillingslot fillingUser:Machine:User:Machine:Figure 3: an online exampleDialogue Policy Training: We label the dia-logues in corpus with the sentence clusters gen-erated in the previous process.
Thus, these labeleddialogues could be utilized to train the optimal dia-logue policy with Reinforcement Learning, whichwill be introduced in section 4.In online stage:Automatic Speech Recognition (ASR): Whenreceiving user voice, ASRmodule transforms it in-to text (Vinyals et al., 2012).
As there might beambiguity and errors in ASR, it is difficult to ob-tain the exact text corresponding to the input voice.Thus, the distribution over possible texts is used torepresent the result of ASR.Sentence Matching (SM): the function of SMis to establish a mapping from the distribution overpossible texts to the distribution over possible sen-tence clusters.DM: Based on the distribution of clusters, D-M model updates the belief state in POMDP andselects the optimal action, namely the optimal ma-chine sentence cluster, according to the dialoguepolicy.
The relevant slots are also filled based onthe user and machine sentence clusters.Sentence Selection: This module selects themost appropriate sentence from the output ma-chine sentence cluster according to the user profilesuch as personality character (Ball et al., 2000).Text To Speech (TTS): This model transformsthe selected sentence text into the output voice asa response (Zen et al., 2007).Fig.
3 is a human-machine dialogue example inonline stage.3 Sentence Clustering based on RNNIn this section, we cluster the sentences for DMmodeling, which might be different from generalsentence clustering.
Sentence similarity for clus-tering are calculated from two aspects.
Firstly,it is calculated traditionally based on internal in-formation such as words and sentence structures,which is widely researched in (Li et al., 2006)(Achananuparp et al., 2008).
(Word embedding801...A4: Please tell me your phone number.B4: Well, my cellphone is broken.A5: I am sorry.
We need a phone number to contact you.Could you please give me your friend?s phone number?
?...A6: Please give me your phone number.B6: Unfortunately, I lost my cellphone.A7: I am sorry.
We need a phone number to contact you.Could you please tell me your friend?s phone number?...Figure 4: an example of sentence similarityand sentence parsing might be used for this cal-culation.)
Additionally, for DM-based sentenceclustering, the sentences that we intend to put intothe same cluster are not only the sentences withsimilar surface meaning, but also the sentenceswith similar intention (Semantics or Pragmatics),even if they might be different in surface meaningsometimes.
For example, illustrated in Fig.
4, B4and B6 are different in surface meaning, but theyhave similar intention, namely he or she might notprovide his or her phone number right now.
Thus,in the sentence clustering for DM modeling, theyshould be clustered into the same group.
It is diffi-cult to give a high similarity score between B4 andB6 only according to the internal information, butwe could observe that the sentences around themin the context are similar.
Thus, external informa-tion is also important to the sentence clustering forDM.
In the following, we will discuss the cluster-ing process.We denote the sentence cluster set as Ck={ck1, ck2, ?
?
?
, ckNkC}, and the dialogue set as Dk={dk1, dk2, ?
?
?
, dkNkD}in the k-th iteration.
Thus, thesteps of sentence clustering are:Step 1: Initially, we only utilize the internalinformation to cluster the sentences via AffinityPropagation (AP) algorithm (Brendan et al., 2007)and denote the clustering result as C0.
If C0isused to label the sentences in dialogues, the j-thdialogue could be denoted as a sequence of clus-ters, namely d0j={c01, c02, ?
?
?
, c0Ndj}.Step 2: In the k-th iteration, we use cluster setCkto label dialogue set Dk.Step 3: We utilize RNN to obtain the distribut-ed representation of sentence, illustrated in Fig.
5.The input of RNN is sentence cluster in each turn,namely ckt.
The input layer I (t) is the one-hot rep-resentation of ckt.
(Turian et al., 2010) (The size ofI (t) is equivalent to??Ck??.
There is only one 1 inI (t) corresponding to the cktposition, and otherelements are zeros.)
H (t) is defined as the hiddenlayer.
The output layer O (t) is the distributionover possible ckt+1, which could be calculated as!O t !H t!1H t "!2H t "!I t!1I t "!2I t "ktc1ktc "2ktc "U VWUUWFigure 5: RNN for sentence clusteringfollow.
(Mikolov et al., 2010){H (t) = f (UI (t) +WH (t ?
1))O (t) = g (VH (t))(1)where f (x) = 1/(1 + e?x) and g (xi) =exi/?Nei=1exi.
The parameters of this RNN couldbe trained by the Back Propagation Through Time(BPTT) algorithm.
(Mikolov, 2012) From RNN,we could obtain two significant results: one is thedistributed representation (vectors) of the sentenceclusters (U), which is used for sentence clustering;the other is the prediction model for sentence clus-ters, which is used for DM.Step 4: we calculate the sentence similaritybased on vectors obtained in Step 3, and combineit with the sentence similarity from internal infor-mation (weighted mean), in order to cluster the setCkvia AP algorithm, which is denoted as Ck+1.Step 5:?NC=?k+1i=k?kth+2NiCis defined asthe average number of clusters in the last kthiter-ation.
If?k+1i=k?kth+2??NiC??NC?
?< Nth, stop theiteration of clustering, or go to Step 2, where Nthis the variation threshold of quantity of clusters.Thus, in the last iteration, we get the cluster setC?k={c?k1, c?k2, ?
?
?
, c?kNkC}and prediction modelfor these sentence clusters.
We divide all the sen-tences in dialogue corpus into the sentence set spo-ken by customers and the sentence set spoken bycustomer service representatives, and then utilizeC?kto label them respectively, which is denoted asCu={cu1, cu2, ?
?
?
, cuNu}, namely the clusters ofuser sentences, and Cm={cm1, cm2, ?
?
?
, cmNm},namely the clusters of machine sentences.4 DM based on Sentence ClusteringThe dialogue process mentioned in section 2 couldbe formulized as follows, illustrated in Fig.
6.
Itis defined X = {x1, ?
?
?
, xT} as inner (or exac-t) sentence cluster corresponding to the user in-put in each turn, which is unobservable and xt?802txty1tx1ty1tx !1ty !?
?1te !
te 1teFigure 6: dialogue processCu.
E = {e1, ?
?
?
, eT} is defined as the inputvoice, which is observable to infer xtin each turn.Y = {y1, ?
?
?
, yT} is defined as the output clus-ter of machine, where yt?
Cm.
Thus, the DMproblem is to find out the optimal ytaccording to{e1, y1, ?
?
?
, et}.
In the following, the DM prob-lem is modeled as a POMDP.State in the t-th epoch is definedas the sequence of clusters, namelyst= {xt?
?, yt?
?, ?
?
?
, xt?1, yt?1, xt}, wherest?
S .
Action in the t-th epoch is defined asat= yt, where at?
A .
The state transitionprobability Pr {st+1|st, at} could be shown asPr {st+1|st, at}= Pr {xt+1|yt, xt, ?
?
?
, yt?
?, xt??
}(2)which is calculated by the prediction model basedon RNN in section 3.Observation is defined as ot= {et?
?, ?
?
?
, et},where ot?
O .
As {xt?
?, ?
?
?
, xt} in state stisunobservable, belief state is defined to representthe distribution over possible states, which is de-noted as b (t) ?
B.
According to (Kaelbling etal., 1998), the belief state updating could be repre-sented asbt+1(st+1) =Pr {ot+1|st+1, at} pst+1Pr {ot+1|bt, at}(3)where pst+1=?st?SPr {st+1|st, at} bt(st).According to Fig.
5, Pr {ot+1|st+1, at} could beshown asPr {ot+1|st+1, at}= Pr {ot+1|st+1}= Pr {et?
?+1, ?
?
?
, et+1|xt?
?+1, ?
?
?
, yt, xt+1}= Pr {et?
?+1, ?
?
?
, et+1|xt?
?+1, ?
?
?
, xt+1}=t+1?i=t?
?+1Pr {ei|xi}(4)However, it is difficult to obtain the probabili-ty Pr {et|xt}, as different people have differenthabits of expression and pronunciation.
Fortunate-ly, Pr {xt|et} could be estimated based on ASRand SM.
Thus, based on Bayes Rules, we have thefollowing equation.Pr {ei|xi} =Pr {xi|ei}Pr {ei}Pr {xi}(5)where Pr {xt} is the prior distribution of xtandcould be counted by corpus.
With (4) and (5), (3)could be rewritten asbt+1(st+1) =?
?
pst+1?t+1?i=t?
?+1Pr {xi|ei}t+1?i=t?
?+1Pr {xi}(6)where?
=?t+1i=t?
?+1Pr {ei}/Pr {ot+1|bt, at} (7)is a normalization constant.The reward function is defined asrt(st, at, st+1) = ?frf(st,at,st+1)+ ?prp(st,at,st+1)(8)where ?f+ ?p= 1 and rt(st, at, st+1) ?
R.Firstly, rf(st,at,st+1)stands for the number of un-filled slots that are filled by the sequence of sen-tence clusters corresponding to (st, at, st+1).
Thisslot-filling process could be achieved by a clas-sifier trained by the dialogues labeled with sen-tence clusters and slot-filling information.
(Input-s are cluster sequences, and outputs are filled s-lots.)
Additionally, rp(st,at,st+1)is defined as thenormalized quantity of st+1conditioned by standat, which could be counted in corpus and standsfor the popularity features of human-human dia-logues.
Thus, for the belief state, the reward func-tion could be represented asrt(bt, at) =?st+1?S?st?Srt(st, at, st+1)?
Pr (st+1|st, at) bt(st)(9)Therefore, if we define the policy as a mappingfrom belief state to action, namely ?
?
Z : B ?A , the POMDP-based DM problem is shown asmax??SE?
[T?t=1?rt(bt, at)]s.t.
bt+1(st+1) =?t+1?i=t??+1Pr{xi|ei}t+1?i=t??+1Pr{xi}?
?st?SPr {st+1|st, at} bt(st)(10)803where ?
is the time discount factor and 0 < ?
< 1.This problem is a MDP problem with continuousstates, which could be solved by the Natural Actorand Critic algorithm (Peters et al., 2008).5 Experimental ResultsIn this section, we compare the performances ofthe proposed Sentence Clustering based DialogueManagement (SCDM) scheme and the existing D-M scheme.
The existing scheme is designed ac-cording to (Young et al., 2013), where DA is uti-lized to represent the semantic information of sen-tence and the dialogue policy is trained via Rein-forcement Learning.
It is also an extrinsic (or end-to-end) evaluation to compare the semantic repre-sentation ability between sentence cluster and DA.In order to compare the performances of theDM schemes, we collect 171 human-human di-alogues in hotel reservation and utilize 100 dia-logues of them to establish a SDS.
The residual71 dialogues are used to establish a simulated userfor testing (Schatzmann et al., 2006).
We definethe slots requested from machine to user as ?roomtype?, ?room quantity?, ?checkin time?, ?check-out time?, ?client name?
and ?client phone?.
Wealso define the slots requested from users to ma-chine as ?hotel address = No.95 East St.?, ?roomtype set = single room, double room, and deluxeroom?, ?single room price = $80?, ?double roomprice = $100?, ?deluxe room price = $150?.
Thehotel reservation task could be considered as a pro-cess of exchanging the slot information betweenmachine and user to some extent.Fig.
7 illustrates the dialogue turn in the DMschemes, using different training corpus.
Here,we vary the size of training corpus from 10 dia-logues to 100 dialogues and define average turnas the average dialogue turn cost to complete thetask.
From this picture, we find out that the SCD-M scheme has lower average turn than the existingscheme, partly because the sentence are automati-cally clustered into many small groups that couldrepresent more nuanced semantic information thanDAs, partly because RNN could estimate next sen-tence cluster according to the vector in hidden lay-er that contains abundant historical dialogue in-formation.
As the number of sentence clusters isgreater than number of DAs, RNN could also solvethe scarcity problem and smoothing problem in thepredicting process.
Additionally, with the incre-ment of training dialogue size, the average turn10 20 30 40 50 60 70 80 90 1004567891011quantity of training dialoguesaverageturns oftesting dialoguesthe existing DM schemethe SCDM schemeFigure 7: comparison of average turnof dialogue decreases, which ought to be ascribedto the fact that more training data could let SD-S reach more states with more times and increasethe accuracy of the parameter estimation in RNNand POMDP.
Furthermore, with the increment oftraining dialogue size, the dialogue turn improve-ment of the proposed scheme turns less obvious,because the number of new sentence pattern de-ceases with the training size increment.6 ConclusionIn this paper, we focused on the DM scheme basedon sentence clustering.
Firstly, sentence cluster isdefined as the semantic representation of sentencein dialogue, which could describe more nauncedsentence intention than DA.
Secondly, RNN is es-tablished for sentence clustering, where sentencesimilarity is calculated not only based on the inter-nal information such as words and sentence struc-ture, but also based on the external informationsuch as context in dialogue.
Thirdly, the DM prob-lem is modeled as a POMDP, where the state isdefined as the sequence of sentence clusters andthe state transition probability is estimated by RN-N, considering the whole information of historicaldialogue.
Finally, the experimental results illus-trated that the proposed DM scheme is superior tothe existing one.AcknowledgmentsThis work is supported by the National Pro-gram on Key Basic Research Project (973 Pro-gram), basic theories and methods of Chinese Lan-guage Processing and Deep Computing in Inter-net environment, multi-lingual Automatic SpeechRecognition for complex environments.
(No.2013CB329302)804ReferencesDan Bohus, Alexander, I. Rudnicky.
2009.
The Raven-Claw dialog management framework: Architectureand systems Computer Speech and Language, vol.23, pages: 332-361, 2009.Emmanuel Ferreira, Fabrice Lefvre.
2013.
Social sig-nal and user adaptation in reinforcement learning-based dialogue management.
MLIS ?13, Aug, 2013.Brendan J. Frey, Delbert Dueck.
2007 Clustering byPassing Messages Between Data Points.
Science,2007.Ball, G., Breese, J.
2000.
Emotion and personalityin a conversational agent.
Embodied conversationalagents, pages: 189-219, 2000.Zen, H., Nose, T., Yamagishi, J., Sako, S., Masuko, T.,Black, A. W., Tokuda, K. 2007 The HMM-basedspeech synthesis system version 2.0.
In Proc.
6thISCA Workshop on Speech Synthesis, Aug, 2007.Schatzmann, J., Weilhammer, K., Stuttle, M., Young,S.
2006 A survey of statistical user simulation tech-niques for reinforcement-learning of dialogue man-agement strategies.
The knowledge engineering re-view, 21(02), 97-126, 2006.Turian, J., Ratinov, L., Bengio, Y.
2010 Word repre-sentations: a simple and general method for semi-supervised learning.
In Proceedings of the 48th an-nual meeting of the association for computationallinguistics, Jul, 2010.Peters, J., Schaal, S. 2008 Natural actor-critic.
Neuro-computinge, 71(7), 1180-1190, 2008.Kaelbling, L., Littman, M., and Cassandr, A.
1998Planning and acting in partially observable stochas-tic domains.
Artif.
Intell., vol.101, pages: 99-134,1998.Daubigney, L., Geist, M., Pietquin, O.
2012.
Off-policy learning in large-scale POMDP-based dia-logue systems.
EEE International Conference on A-coustics, Speech and Signal Processing (ICASSP).,pages: 4989-499, Mar, 2012.Vinyals, O., Ravuri, S. V., Povey, D. 2012.
Revis-iting Recurrent Neural Networks for robust ASR.2012 IEEE International Conference on Acoustics,Speech and Signal Processing (ICASSP), 2012.Achananuparp, P., Hu, X., Shen, X.
2008.
The evalua-tion of sentence similarity measures.
In Data Ware-housing and Knowledge Discovery, pages: 305-316,2008.Young, S., Gasic, M., Thomson, B., Williams, J. D.(2013).
2013.
Pomdp-based statistical spoken di-alog systems: A review.
Proceedings of the IEEE,101(5), pages: 1160-1179, 2013.Mikolov, T. 2012 Statistical language models based onneural networks.
Presentation at Google, MountainView, 2012.Mikolov, T., Karafit, M., Burget, L., Cernocky, J., Khu-danpur, S. 2010 Recurrent neural network basedlanguage model.
11th Annual Conference of theInternational Speech Communication Association,Sep, 2010.Paek, T., Pieraccini, R. 2008.
Automating spokendialogue management design using machine learn-ing: An industry perspective.
Speech communica-tion, 50(8), 716-729, 2008.Hao Tang, Watanabe, S., Marks, T. K., Hershey, J. R.2014.
Log-linear dialog manager.
IEEE Interna-tional Conference on Acoustics, Speech and SignalProcessing (ICASSP), May, 2014.Li Y, McLean D, Bandar Z A, et al.
2006.
Sen-tence similarity based on semantic nets and corpusstatistics.
Knowledge and Data Engineering, IEEETransactions on, 18(8), 1138-1150, 2006.805
