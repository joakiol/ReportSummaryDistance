Proceedings of the 7th Linguistic Annotation Workshop & Interoperability with Discourse, pages 159?167,Sofia, Bulgaria, August 8-9, 2013. c?2013 Association for Computational LinguisticsAnimacy Annotation in the Hindi TreebankItisree Jena, Riyaz Ahmad Bhat, Sambhav Jain and Dipti Misra SharmaLanguage Technologies Research Centre, IIIT-Hyderabad, India{itisree|riyaz.bhat|sambhav.jain}@research.iiit.ac.in, dipti@iiit.ac.inAbstractIn this paper, we discuss our efforts to anno-tate nominals in the Hindi Treebank with thesemantic property of animacy.
Although thetreebank already encodes lexical informationat a number of levels such as morph and partof speech, the addition of animacy informa-tion seems promising given its relevance tovaried linguistic phenomena.
The suggestionis based on the theoretical and computationalanalysis of the property of animacy in the con-text of anaphora resolution, syntactic parsing,verb classification and argument differentia-tion.1 IntroductionAnimacy can either be viewed as a biological prop-erty or a grammatical category of nouns.
In astrictly biological sense, all living entities are ani-mate, while all other entities are seen as inanimate.However, in its linguistic sense, the term is syn-onymous with a referent?s ability to act or instigateevents volitionally (Kittila?
et al 2011).
Althoughseemingly different, linguistic animacy can be im-plied from biological animacy.
In linguistics, themanifestation of animacy and its relevance to lin-guistic phenomena have been studied quite exten-sively.
Animacy has been shown, cross linguisti-cally, to control a number of linguistic phenomena.Case marking, argument realization, topicality ordiscourse salience are some phenomena, highly cor-related with the property of animacy (Aissen, 2003).In linguistic theory, however, animacy is not seenas a dichotomous variable, rather a range capturingfiner distinctions of linguistic relevance.
Animacyhierarchy proposed in Silverstein?s influential arti-cle on ?animacy hierarchy?
(Silverstein, 1986) ranksnominals on a scale of the following gradience: 1stpers> 2nd pers> 3rd anim> 3rd inanim.
Several suchhierarchies of animacy have been proposed follow-ing (Silverstein, 1986), one basic scale taken from(Aissen, 2003) makes a three-way distinction as hu-mans > animates > inanimates.
These hierarchies canbe said to be based on the likelihood of a referent ofa nominal to act as an agent in an event (Kittila?
etal., 2011).
Thus higher a nominal on these hierar-chies higher the degree of agency/control it has overan action.
In morphologically rich languages, thedegree of control/agency is expressed by case mark-ing.
Case markers capture the degree of control anominal has in a given context (Hopper and Thomp-son, 1980; Butt, 2006).
They rank nominals on thecontinuum of control as shown in (1)1.
Nominalsmarked with Ergative case have highest control andthe ones marked with Locative have lowest.Erg > Gen > Inst > Dat > Acc > Loc (1)Of late the systematic correspondences betweenanimacy and linguistic phenomena have been ex-plored for various NLP applications.
It has beennoted that animacy provides important informa-tion, to mention a few, for anaphora resolution(Evans and Orasan, 2000), argument disambiguation(Dell?Orletta et al 2005), syntactic parsing (?vre-lid and Nivre, 2007; Bharati et al 2008; Ambati etal., 2009) and verb classification (Merlo and Steven-1Ergative, Genitive, Instrumental, Dative, Accusative andLocative in the given order.159son, 2001).
Despite the fact that animacy could playan important role in NLP applications, its annota-tion, however, is not usually featured in a treebankor any other annotated corpora used for developingthese applications.
There are a very few annotationprojects that have included animacy in their anno-tation manual, following its strong theoretical andcomputational implications.
One such work, mo-tivated by the theoretical significance of the prop-erty of animacy, is (Zaenen et al 2004).
Theymake use of a coding scheme drafted for a para-phrase project (Bresnan et al 2002) and presentan explicit annotation scheme for animacy in En-glish.
The annotation scheme assumes a three-waydistinction, distinguishing Human, Other animatesand Inanimates.
Among the latter two categories?Other animates?
is further sub-categorized intoOrganizations and Animals, while the category of?Inanimates?
further distinguishes between con-crete and non-concrete, and time and place nomi-nals.
As per the annotation scheme, nominals areannotated according to the animacy of their referentsin a given context.
Another annotation work thatincludes animacy for nominals is (Teleman, 1974),however, the distinction made is binary between hu-man and non-human referents of a nominal in agiven context.
In a recent work on animacy annota-tion, Thuilier et al(2012) have annotated a multi-source French corpora with animacy and verb se-mantics, on the lines of (Zaenen et al 2004).
Apartfrom the manual annotation for animacy, lexical re-sources like wordnets are an important source of thisinformation, if available.
These resources usuallycover animacy, though indirectly (Fellbaum, 2010;Narayan et al 2002).
Although a wordnet is aneasily accessible resource for animacy information,there are some limitations on its use, as discussedbelow:1.
Coverage: Hindi wordnet only treats commonnouns while proper nouns are excluded (exceptfamous names) see Table 1.
The problem is se-vere where the domain of text includes moreproper than common nouns, which is the casewith the Hindi Treebank as it is annotated onnewspaper articles.2.
Ambiguity: Since words can be ambiguous, theanimacy listed in wordnet can only be used inpresence of a high performance word sense dis-ambiguation system.
As shown in Table 2, only38.02% of nouns have a single sense as listed inHindi Wordnet.3.
Metonymy or Complex Types: Domains likenewspaper articles are filled with metonymicexpressions like courts, institute names, coun-try names etc, that can refer to a building, a ge-ographical place or a group of people depend-ing on the context of use.
These words are notambiguous per se but show different aspects oftheir semantics in different contexts (logicallypolysemous).
Hindi wordnet treats these typesof nouns as inanimate.Nominals in HTB Hindi WordNet Coverage78,136 65,064 83.27%Table 1: Coverage of Hindi WordNet on HTB Nominals.HTB Nominals Single Unique Sensewith WN Semantics in Hindi WordNet65,064 24,741 (38.02%)Table 2: Nominals in HTB with multiple sensesGiven these drawbacks, we have included ani-macy information manually in the annotation of theHindi Treebank, as discussed in this work.
In therest, we will discuss the annotation of nominal ex-pressions with animacy and the motivation for thesame, the discussion will follow as: Section 2 givesa brief overview of the Hindi Treebank with all itslayers.
Section 3 motivates the annotation of nom-inals with animacy, followed by the annotation ef-forts and issues encountered in Section 4.
Section5 concludes the paper with a discussion on possiblefuture directions.2 Description of the Hindi TreebankIn the following, we give an overview of the HindiTreebank (HTB), focusing mainly on its dependencylayer.
The Hindi-Urdu Treebank (Palmer et al2009; Bhatt et al 2009) is a multi-layered andmulti-representational treebank.
It includes threelevels of annotation, namely two syntactic levels andone lexical-semantic level.
One syntactic level is adependency layer which follows the CPG (Begum160et al 2008), inspired by the Pa?n.
inian grammati-cal theory of Sanskrit.
The other level is annotatedwith phrase structure inspired by the Chomskyan ap-proach to syntax (Chomsky, 1981) and follows a bi-nary branching representation.
The third layer of an-notation, a purely lexical semantic one, encodes thesemantic relations following the English PropBank(Palmer et al 2005).In the dependency annotation, relations aremainly verb-centric.
The relation that holds betweena verb and its arguments is called a kar.aka relation.Besides kar.aka relations, dependency relations alsoexist between nouns (genitives), between nouns andtheir modifiers (adjectival modification, relativiza-tion), between verbs and their modifiers (adver-bial modification including subordination).
CPGprovides an essentially syntactico-semantic depen-dency annotation, incorporating kar.aka (e.g., agent,theme, etc.
), non-kar.aka (e.g.
possession, purpose)and other (part of) relations.
A complete tag set ofdependency relations based on CPG can be found in(Bharati et al 2009), the ones starting with ?k?
arelargely Pa?n.
inian kar.aka relations, and are assignedto the arguments of a verb.
Figure 1 encodes the de-pendency structure of (5), the preterminal node is apart of speech of a lexical item (e.g.
NN,VM, PSP).The lexical items with their part of speech tags arefurther grouped into constituents called chunks (e.g.NP, VGF) as part of the sentence analysis.
The de-pendencies are attached at the chunk level, markedwith ?drel?
in the SSF format.
k1 is the agent ofan action (KAyA ?eat?
), whereas k2 is the object orpatient.
(5) s\@yA nSandhya-Ergsbapple-NomKAyAeat-Perf?
?Sandhya ate an apple.
?<Sentence id = ?1?>Offset Token Tag Feature structure1 (( NP <fs name=?NP?
drel=?k1:VGF?>1.1 s\@yA NNP<fs af=?s\@yA,n,f,sg,3,o,0,0?>1.2 n PSP <fs af=?n,psp,,,,,,?>))2 (( NP <fs name=?NP2?
drel=?k2:VGF?>2.1 sb NN <fs af=?sb,n,m,sg,3,d,0,0?>))3 (( VGF<fs name=?VGF?>3.1 KAyA VM <fs af=?KA,v,m,sg,any,,yA,yA?>))</Sentence>Figure 1: Annotation of an Example Sentence in SSF.Despite the fact that the Hindi Treebank alreadyfeatures a number of layers as discussed above, therehave been different proposals to enrich it further.Hautli et al(2012) proposed an additional layer tothe treebank, for the deep analysis of the language,by incorporating the functional structure (orf-structure) of Lexical Functional Grammar whichencodes traditional syntactic notions such as sub-ject, object, complement and adjunct.
Dakwale etal.
(2012) have also extended the treebank withanaphoric relations, with a motive to develop a datadriven anaphora resolution system for Hindi.
Giventhis scenario, our effort is to enrich the treebankwith the animacy annotation.
In the followingsections, we will discuss in detail, the annotation ofthe animacy property of nominals in the treebankand the motive for the same.3 Motivation: In the Context ofDependency ParsingHindi is a morphologically rich language, gram-matical relations are depicted by its morphologyvia case clitics.
Hindi has a morphologicallysplit-ergative case marking system (Mahajan, 1990;Dixon, 1994).
Case marking is dependent on theaspect of a verb (progressive/perfective), transitivity(transitive/intransitive) and the type of a nominal(definite/indefinite, animate/inanimate).
Giventhis peculiar behavior of case marking in Hindi,arguments of a verb (e.g.
transitive) have a numberof possible configurations with respect to the casemarking as shown in the statistics drawn fromthe Hindi Treebank released for MTPIL HindiDependency parsing shared task (Sharma et al2012) in Table 3.
Almost in 15% of the transitiveclauses, there is no morphological case marker onany of the arguments of a verb which, in the contextof data driven parsing, means lack of an explicitcue for machine learning.
Although, in other casesthere is a case marker, at least on one argument of averb, the ambiguity in case markers (one-to-manymapping between case markers and grammaticalfunctions as presented in Table 4) further worsensthe situation (however, see Ambati et al(2010) andBhat et al(2012) for the impact of case markers onparsing Hindi/Urdu).
Consider the examples from161(6a-e), the instrumental se is extremely ambiguous.It can mark the instrumental adjuncts as in (6a),source expressions as in (6b), material as in (6c),comitatives as in (6d), and causes as in (6e).K2-Unmarked K2-MarkedK1-Unmarked 1276 741K1-Marked 5373 966Table 3: Co-occurrence of Marked and Unmarked verb argu-ments (core) in HTB.n/ne ko/ko s/se m\/meN pr/par kA/kaa(Ergative) (Dative) (Instrumental) (Locative) (Locative) (Genitive)k1(agent) 7222 575 21 11 3 612k2(patient) 0 3448 451 8 24 39k3(instrument) 0 0 347 0 0 1k4(recipient) 0 1851 351 0 1 4k4a(experiencer) 0 420 8 0 0 2k5(source) 0 2 1176 12 1 0k7(location) 0 1140 308 8707 3116 19r6(possession) 0 3 1 0 0 2251Table 4 : Distribution of case markers across case function.
(6a) mohn nMohan-ErgcAbF skey-InsttaAlAlock-NomKolAopen?
?Mohan opened the lock with a key.?
(6b) gFtaA nGeeta-ErgEd?F sDelhi-InstsAmAnluggage-Nomm\gvAyAprocure?
?Geeta procured the luggage from Delhi.?
(6c) m EtakAr nsculptor-Ergp(Tr sstone-Instm Etaidol-NombnAyFmake?
?The sculptor made an idol out of stone.?
(6d) rAm kFRam-Gen[yAm sShyaam-InstbAtatalk-Nomh  Ihappen?
?Ram spoke to Shyaam.?
(6e) bAErf srain-InstkI Psl\many crops-NomtabAhdestroyho gyF\happen-Perf?
?Many crops were destroyed due to the rain.?
(7) EcEwyAbird-NomdAnAgrain-Nomc  g rhF h{devour-Prog?
?A bird is devouring grain.
?A conventional parser has no cue for the disam-biguation of instrumental case marker se in exam-ples (6a-e) and similarly, in example (7), it?s hardfor the parser to know whether ?bird?
or ?grain?
isthe agent of the action ?devour?.
Traditionally, syn-tactic parsing has largely been limited to the useof only a few lexical features.
Features like POS-tags are way too coarser to provide deep informa-tion valuable for syntactic parsing while on the otherhand lexical items often suffer from lexical ambi-guity or out of vocabulary problem.
So in oder toassist the parser for better judgments, we need tocomplement the morphology somehow.
A carefulobservation easily states that a simple world knowl-edge about the nature (e.g.
living-nonliving, arti-fact, place) of the participants is enough to disam-biguate.
For Swedish, ?vrelid and Nivre (2007) and?vrelid (2009) have shown improvement, with an-imacy information, in differentiation of core argu-ments of a verb in dependency parsing.
Similarlyfor Hindi, Bharati et al(2008) and Ambati et al(2009) have shown that even when the training datais small simple animacy information can boost de-pendency parsing accuracies, particularly handlingthe differentiation of core arguments.
In Table 5,we show the distribution of animacy with respect tocase markers and dependency relations in the anno-tated portion of the Hindi Treebank.
The high rateof co-occurrence between animacy and dependencyrelations makes a clear statement about the role an-imacy can play in parsing.
Nominals marked withdependency relations as k1 ?agent?, k4 ?recipient?,k4a ?experiencer?
are largely annotated as humanwhile k3 ?instrument?
is marked as inanimate,which confirms our conjecture that with animacyinformation a parser can reliably predict linguisticpatterns.
Apart from parsing, animacy has been re-ported to be beneficial for a number of natural lan-guage applications (Evans and Orasan, 2000; Merloand Stevenson, 2001).
Following these computa-tional implications of animacy, we started encodedthis property of nominals explicitly in our treebank.In the next section, we will present these efforts fol-162lowed by the inter-annotator agreement studies.Human Other-Animates Inanimatek1n/ne (Erg) 2321 630 108ko/ko (Dat/Acc) 172 8 135s/se (Inst) 6 0 14m\/me (Loc) 0 0 7pr/par (Loc) 0 0 1kA/kaa (Gen) 135 2 99?
(Nom) 1052 5 3072k2n/ne (Erg) 0 0 0ko/ko (Dat/Acc) 625 200 226s/se (Inst) 67 0 88m\/me (Loc) 2 0 6pr/par (Loc) 5 0 37kA/kaa (Gen) 15 0 14?
(Nom) 107 61 2998k3n/ne (Erg) 0 0 0ko/ko (Dat/Acc) 0 0 0s/se (Inst) 2 0 199m\/me (Loc) 0 0 0pr/par (Loc) 0 0 0kA/kaa (Gen) 0 0 0?
(Nom) 0 0 20k4n/ne (Erg) 0 0 0ko/ko (Dat/Acc) 597 0 13s/se (Inst) 53 0 56m\/me (Loc) 0 0 0pr/par (Loc) 0 0 0kA/kaa (Gen) 0 0 0?
(Nom) 7 0 8k4an/ne (Erg) 0 0 0ko/ko (Dat/Acc) 132 0 8s/se (Inst) 4 0 2m\/me (Loc) 0 0 0pr/par (Loc) 0 0 0kA/kaa (Gen) 1 0 0?
(Nom) 56 0 1k5n/ne (Erg) 0 0 0ko/ko (Dat/Acc) 0 0 0s/se (Inst) 7 0 460m\/me (Loc) 0 0 1pr/par (Loc) 0 0 0kA/kaa (Gen) 0 0 0?
(Nom) 0 0 2k7n/ne (Erg) 0 0 0ko/ko (Dat/Acc) 4 0 0s/se (Inst) 3 0 129m\/me (Loc) 0 1977 1563pr/par (Loc) 66 0 1083kA/kaa (Gen) 0 0 8?
(Nom) 5 0 1775r6n/ne (Erg) 0 0 0ko/ko (Dat/Acc) 0 0 0s/se (Inst) 1 0 0m\/me (Loc) 0 0 0pr/par (Loc) 0 0 0kA/kaa (Gen) 156 80 605?
(Nom) 13 3 25Table 5: Distribution of semantic features with respectto case markers and dependency relations a.ak1 ?agent?, k2 ?patient?, k3 ?instrument?, k4 ?recipient?,k4a ?experiencer?, k5 ?source?, k7 ?location?, r6 ?possession?4 Animacy AnnotationFollowing Zaenen et al(2004), we make a three-way distinction, distinguishing between Human,Other Animate and In-animate referents of anominal in a given context.
The animacy of a ref-erent is decided based on its sentience and/or con-trol/volitionality in a particular context.
Since, pro-totypically, agents tend to be animate and patientstend to be inanimate (Comrie, 1989), higher ani-mates such as humans, dogs etc.
are annotated assuch in all contexts since they frequently tend to beseen in contexts of high control.
However, loweranimates such as insects, plants etc.
are anno-tated as ?In-animate?
because they are ascribedless or no control in human languages like inan-imates (Kittila?
et al 2011).
Non-sentient refer-ents, except intelligent machines and vehicles, areannotated as ?In-animate?
in all contexts.
Intel-ligent machines like robots and vehicles, although,lack any sentience, they possess an animal like be-havior which separates them from inanimate nounswith no animal resemblance, reflected in human lan-guage as control/volitionality.
These nouns unlikehumans and other higher animates are annotated asper the context they are used in.
They are anno-tated as ?Other animate?
only in their agentiveroles.
Nominals that vary in sentience in varyingcontexts are annotated based on their reference in agiven context as discussed in Subsection 4.2.
Thesenominals include country names referring to geo-graphical places, teams playing for the country, gov-ernments or their inhabitants; and organizations in-cluding courts, colleges, schools, banks etc.
Un-like Zaenen et al(2004) we don?t further categorize?Other Animate?
and ?In-animate?
classes.
We163don?t distinguish between Organizations and Ani-mals in ?Other Animate?
and Time and Place in?In-animates?.The process of animacy annotation in the HindiTreebank is straight forward.
For every chunk in asentence, the animacy of its head word is capturedin an ?attribute-value?
pair in SSF format, asshown in Figure 3.
Hitherto, around 6485 sentence,of the Hindi Treebank, have been annotated withthe animacy information.<Sentence id = ?1?>Offset Token Tag Feature structure1 (( NP <fs name=?NP?
drel=?k1:VGF?semprop=?human?>1.1 mohn NNP <fs af=?mohn,n,m,sg,3,d,0,0?>1.2 n PSP <fs af=?n,psp,,,,,,?
name=?n?>))2 (( NP <fs name=?NP2?
drel=?k4:VGF?semprop=?other-animate?>2.1 Eb?F NN <fs af=?Eb?F,n,f,sg,3,d,0,0?>2.2 ko PSP <fs af=?ko,psp,,,,,,?
name=?ko?>))3 (( NP <fs name=?NP3?
drel=?k3:VGF?semprop=?inanimate?>3.1 botal NN <fs af=?botal ,n,f,sg,3,d,0,0?>3.2 s PSP <fs af=?s,psp,,,,,,?>))4 (( NP <fs name=?NP4?
drel=?k2:VGF?semprop=?inanimate?>4.1 d D NN <fs af=?d D,n,m,sg,3,d,0,0?>))5 (( VGF <fs name=?VGF?>5.1 EplAyA VM <fs af=?EplA,v,m,sg,any,,yA,yA?>))</Sentence>Figure 3: Semantic Annotation in SSF.
(8) mohn nMohan-ErgEb?F kocat-Datbotal sbottle-Instd Dmilk-NomEplAyAdrink-Perf?
?Mohan fed milk to the cat with a bottle.
?In the following, we discuss some of the interest-ing cross linguistic phenomena which added somechallenge to the annotation.4.1 PersonificationPersonification is a type of meaning extensionwhereby an entity (usually non-human) is givenhuman qualities.
Personified expressions are an-notated, in our annotation procedure, as Human,since it is the sense they carry in such contexts.However, to retain their literal sense, two attributesare added.
One for their context bound sense(metaphorical) and the other for context free sense(literal).
In example (9), waves is annotated withliteral animacy as In-animante and metaphoricanimacy as Human, as shown in Figure 4 (offset2).<Sentence id = ?1?>Offset Token Tag Feature structure1 (( NP <fs name=?NP?
drel=?k7p:VGF?
>1.1 sAgr NNC <fs af=?sAgr,n,m,sg,3,d,0,0?>1.2 taV NN <fs af=?taV,n,m,sg,3,d,0,0?>1.3 pr PSP <fs af=?pr,psp,,,,,,?>))2 (( NP <fs name=?NP2?
drel=?k1:VGF?semprop=?inanimate?metaphoric=?human?>2.1 lhr\ NN <fs af=?lhr\,n,f,pl,3,d,0,0?>))3 (( VGF <fs name=?VGF?>3.1 nAc VM <fs af=?nAc,v,any,any,any,,0,0?>3.2 rhF VAUX <fs af=?rhF,v,f,sg,any,,ya,ya?>3.3 h{\ AUX <sf AF=?h{\,v,any,pl,1,,he,he?>))</Sentence>Figure 4: Semantic Annotation in SSF.
(9) sAgr taV prsea coast-Loclhr\waves-NomnAc rhF h{\dance-Prog?
?Waves are dancing on the sea shore.
?4.2 Complex TypesThe Hindi Treebank in largely built on newspa-per corpus.
Logically polysemous expressions(metonymies) such as government, court,newspaper etc.
are very frequent in news re-porting.
These polysemous nominals can exhibitcontradictory semantics in different contexts.
Inexample (10a), court refers to a person (judge) ora group of persons (jury) while in (10b) it is abuilding (see Pustejovsky (1996) for the semanticsof complex types).
In our annotation procedure,such expressions are annotated as per the sense orreference they carry in a given context.
So, in caseof (10a) court will be annotated as Human whilein (10b) it will be annotated as In-animante.
(10a) adAlta ncourt-Ergm  kdm kAcase-GenP{\slAdecision-Noms  nAyAdeclare-Perf?
?The court declared its decision on the case.
?164(10b) m{\I-NomadAlta m\court-Loch ?be-Prs?I am in the court.
?4.3 Inter-Annotator AgreementWe measured the inter-annotator agreement on aset of 358 nominals (?50 sentences) using Cohen?skappa.
We had three annotators annotating the samedata set separately.
The nominals were annotatedin context i.e., the annotation was carried consider-ing the role and reference of a nominal in a partic-ular sentence.
The kappa statistics, as presented inTable 6, show a significant understanding of anno-tators of the property of animacy.
In Table 7, wereport the confusion between the annotators on thethree animacy categories.
The confusion is high for?Inanimate?
class.
Annotators don?t agree on thiscategory because of its fuzziness.
As discussed ear-lier, although ?Inanimate?
class enlists biologicallyinanimate entities, some entities may behave like an-imates in some contexts.
They may be sentient andhave high linguistic control in some contexts.
Thedifficulty in deciphering the exact nature of the ref-erence of these nominals, as observed, is the reasonbehind the confusion.
The confusion is observed fornouns like organization names, lower animates andvehicles.
Apart from the linguistically and contextu-ally defined animacy, there was no confusion, as ex-pected, in the understanding of biological animacy.Annotators ?ann1-ann2 0.78ann1-ann3 0.82ann2-ann3 0.83Average ?
0.811Table 6: Kappa StatisticsHuman Other-animate InanimateHuman 71 0 14Other-animate 0 9 5Inanimate 8 10 241Table 7: Confusion Matrix5 Conclusion and Future WorkIn this work, we have presented our efforts to enrichthe nominals in the Hindi Treebank with animacyinformation.
The annotation was followed by theinter-annotator agreement study for evaluating theconfusion over the categories chosen for annotation.The annotators have a significant understanding ofthe property of animacy as shown by the higher val-ues of Kappa (?).
In future, we plan to continue theanimacy annotation for the whole Hindi Treebank.We also plan to utilize the annotated data to builda data driven automatic animacy classifier (?vrelid,2006).
From a linguistic perspective, an annotationof the type, as discussed in this paper, will also be ofgreat interest for studying information dynamics andsee how semantics interacts with syntax in Hindi.6 AcknowledgmentsThe work reported in this paper is supported by theNSF grant (Award Number: CNS 0751202; CFDANumber: 47.070).
2ReferencesJudith Aissen.
2003.
Differential object marking:Iconicity vs. economy.
Natural Language & Linguis-tic Theory, 21(3):435?483.B.R.
Ambati, P. Gade, S. Husain, and GSK Chaitanya.2009.
Effect of minimal semantics on dependencyparsing.
In Proceedings of the Student Research Work-shop.B.R.
Ambati, S. Husain, J. Nivre, and R. Sangal.
2010.On the role of morphosyntactic features in Hindi de-pendency parsing.
In Proceedings of the NAACLHLT 2010 First Workshop on Statistical Parsing ofMorphologically-Rich Languages, pages 94?102.
As-sociation for Computational Linguistics.R.
Begum, S. Husain, A. Dhwaj, D.M.
Sharma, L. Bai,and R. Sangal.
2008.
Dependency annotation schemefor Indian languages.
In Proceedings of IJCNLP.
Cite-seer.Akshar Bharati, Samar Husain, Bharat Ambati, SambhavJain, Dipti Sharma, and Rajeev Sangal.
2008.
Two se-mantic features make all the difference in parsing ac-curacy.
Proceedings of ICON, 8.2Any opinions, findings, and conclusions or recommenda-tions expressed in this material are those of the author(s) and donot necessarily reflect the views of the National Science Foun-dation.165A.
Bharati, D.M.
Sharma, S. Husain, L. Bai, R. Begum,and R. Sangal.
2009.
AnnCorra: TreeBanks for IndianLanguages Guidelines for Annotating Hindi TreeBank(version?2.0).R.A.
Bhat, S. Jain, and D.M.
Sharma.
2012.
Experi-ments on Dependency Parsing of Urdu.
In Proceed-ings of TLT11 2012 Lisbon Portugal, pages 31?36.Edic?es Colibri.R.
Bhatt, B. Narasimhan, M. Palmer, O. Rambow, D.M.Sharma, and F. Xia.
2009.
A multi-representationaland multi-layered treebank for hindi/urdu.
In Pro-ceedings of the Third Linguistic Annotation Workshop,pages 186?189.
Association for Computational Lin-guistics.Joan Bresnan, Jean Carletta, Richard Crouch, MalvinaNissim, Mark Steedman, Tom Wasow, and Annie Za-enen.
2002.
Paraphrase analysis for improved genera-tion, link project.Miriam Butt.
2006.
The dative-ergative connection.
Em-pirical issues in syntax and semantics, 6:69?92.N.
Chomsky.
1981.
Lectures on Government and Bind-ing.
Dordrecht: Foris.Bernard Comrie.
1989.
Language universals and lin-guistic typology: Syntax and morphology.
Universityof Chicago press.Praveen Dakwale, Himanshu Sharma, and Dipti MSharma.
2012.
Anaphora Annotation in Hindi Depen-dency TreeBank.
In Proceedings of the 26th PacificAsia Conference on Language, Information, and Com-putation, pages 391?400, Bali,Indonesia, November.Faculty of Computer Science, Universitas Indonesia.Felice Dell?Orletta, Alessandro Lenci, Simonetta Mon-temagni, and Vito Pirrelli.
2005.
Climbing thepath to grammar: A maximum entropy model of sub-ject/object learning.
In Proceedings of the Workshopon Psychocomputational Models of Human LanguageAcquisition, pages 72?81.
Association for Computa-tional Linguistics.R.M.W.
Dixon.
1994.
Ergativity.
Number 69.
Cam-bridge University Press.Richard Evans and Constantin Orasan.
2000.
Improv-ing anaphora resolution by identifying animate entitiesin texts.
In Proceedings of the Discourse Anaphoraand Reference Resolution Conference (DAARC2000),pages 154?162.Christiane Fellbaum.
2010.
WordNet.
Springer.A.
Hautli, S. Sulger, and M. Butt.
2012.
Adding an an-notation layer to the Hindi/Urdu treebank.
LinguisticIssues in Language Technology, 7(1).Paul J Hopper and Sandra A Thompson.
1980.
Tran-sitivity in grammar and discourse.
Language, pages251?299.Seppo Kittila?, Katja Va?sti, and Jussi Ylikoski.
2011.Case, Animacy and Semantic Roles, volume 99.
JohnBenjamins Publishing.A.K.
Mahajan.
1990.
The A/A-bar distinction and move-ment theory.
Ph.D. thesis, Massachusetts Institute ofTechnology.Paola Merlo and Suzanne Stevenson.
2001.
Auto-matic verb classification based on statistical distribu-tions of argument structure.
Computational Linguis-tics, 27(3):373?408.Dipak Narayan, Debasri Chakrabarty, Prabhakar Pande,and Pushpak Bhattacharyya.
2002.
An experience inbuilding the indo wordnet-a wordnet for hindi.
In FirstInternational Conference on Global WordNet, Mysore,India.Lilja ?vrelid and Joakim Nivre.
2007.
When word or-der and part-of-speech tags are not enough ?
Swedishdependency parsing with rich linguistic features.
InProceedings of the International Conference on RecentAdvances in Natural Language Processing (RANLP),pages 447?451.Lilja ?vrelid.
2006.
Towards robust animacy classifica-tion using morphosyntactic distributional features.
InProceedings of the Eleventh Conference of the Euro-pean Chapter of the Association for ComputationalLinguistics: Student Research Workshop, pages 47?54.
Association for Computational Linguistics.Lilja ?vrelid.
2009.
Empirical evaluations of animacyannotation.
In Proceedings of the 12th Conference ofthe European Chapter of the Association for Compu-tational Linguistics (EACL).M.
Palmer, D. Gildea, and P. Kingsbury.
2005.
Theproposition bank: An annotated corpus of semanticroles.
volume 31, pages 71?106.
MIT Press.M.
Palmer, R. Bhatt, B. Narasimhan, O. Rambow, D.M.Sharma, and F. Xia.
2009.
Hindi Syntax: Annotat-ing Dependency, Lexical Predicate-Argument Struc-ture, and Phrase Structure.
In The 7th InternationalConference on Natural Language Processing, pages14?17.J.
Pustejovsky.
1996.
The Semantics of Complex Types.Lingua.Dipti Misra Sharma, Prashanth Mannem, Joseph van-Genabith, Sobha Lalitha Devi, Radhika Mamidi, andRanjani Parthasarathi, editors.
2012.
Proceedings ofthe Workshop on Machine Translation and Parsing inIndian Languages.
The COLING 2012 OrganizingCommittee, Mumbai, India, December.Michael Silverstein.
1986.
Hierarchy of features andergativity.
Features and projections, pages 163?232.Ulf Teleman.
1974.
Manual fo?r grammatisk beskrivningav talad och skriven svenska.
Studentlitteratur.166Juliette Thuilier, Laurence Danlos, et al2012.
Seman-tic annotation of French corpora: animacy and verbsemantic classes.
In LREC 2012-The eighth interna-tional conference on Language Resources and Evalu-ation.Annie Zaenen, Jean Carletta, Gregory Garretson, JoanBresnan, Andrew Koontz-Garboden, Tatiana Nikitina,M Catherine O?Connor, and Tom Wasow.
2004.
Ani-macy Encoding in English: why and how.
In Proceed-ings of the 2004 ACL Workshop on Discourse Anno-tation, pages 118?125.
Association for ComputationalLinguistics.167
