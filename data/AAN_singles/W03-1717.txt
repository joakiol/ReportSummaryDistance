Learning Verb-Noun Relations to Improve ParsingAndi WuMicrosoft ResearchOne Microsoft Way, Redmond, WA 98052andiwu@microsoft.comAbstractThe verb-noun sequence in Chinese oftencreates ambiguities in parsing.
These ambi-guities can usually be resolved if we knowin advance whether the verb and the nountend to be in the verb-object relation or themodifier-head relation.
In this paper, we de-scribe a learning procedure whereby suchknowledge can be automatically acquired.Using an existing (imperfect) parser with achart filter and a tree filter, a large corpus,and the log-likelihood-ratio (LLR) algo-rithm, we were able to acquire verb-nounpairs which typically occur either in verb-object relations or modifier-head relations.The learned pairs are then used in the pars-ing process for disambiguation.
Evaluationshows that the accuracy of the originalparser improves significantly with the use ofthe automatically acquired knowledge.1 IntroductionComputer analysis of natural language sentences isa challenging task largely because of   the ambigui-ties in natural language syntax.
In Chinese, thelack of inflectional morphology often makes theresolution of those ambiguities even more difficult.One type of ambiguity is found in the verb-nounsequence which can appear in at least two differentrelations, the verb-object relation and the modifier-head relation, as illustrated in the followingphrases.
(1)   ??
??
?
?
?dengji     shouxu     de   feiyongregister  procedure  DE  expense?the expense of the registration procedure?
(2) ??
??
?
?
?banli      shouxu    de   feiyonghandle procedure DE  expense?the expense of going through the procedure?In (1), the verb-noun sequence ???
???
is anexample of the modifier-head relation while ??????
in (2) is an example of the verb-object rela-tion.
The correct analyses of these two phrases aregiven in Figure 1 and Figure 2, where ?RELCL?stands for ?relative clause?
:Figure 1.
Correct analysis of (1)Figure 2.
Correct analysis of (2)However, with the set of grammar rules thatcover the above phrases and without any semanticor collocational knowledge of the words involved,there is nothing to prevent us from the wronganalyses in Figure 3 and Figure 4.Figure 3.
Wrong analysis of (1)Figure 4.
Wrong analysis of (2)To rule out these wrong parses, we need toknow that ??
is a typical modifier of??
while??
typically takes ??
as an object.
The ques-tion is how to acquire such knowledge automati-cally.
In the rest of this paper, we will present alearning procedure that learns those relations byprocessing a large corpus with a chart-filter, a tree-filter and an LLR filter.
The approach is in thespirit of Smadja (1993) on retrieving collocationsfrom text corpora, but is more integrated with pars-ing.
We will show in the evaluation section howmuch the learned knowledge can help improvesentence analysis.2 The Learning ProcedureThe syntactic ambiguity associated with the verb-noun sequence can be either local or global.
Thekind of ambiguity we have observed in (1) and (2)is global in nature, which exists even if this nounphrase is plugged into a larger structure or com-plete sentence.
There are also local ambiguitieswhere the ambiguity disappears once the verb-noun sequence is put into a broader context.
In thefollowing examples, the sentences in (3) and (4)can only receive the analyses in Figure 5 and Fig-ure 6 respectively.
(3)  ?
?
?
?
??
??
?zhe shi xin  de    dengji  shouxuthis be new DE register procedure?This is a new registration procedure.?
(4)   ?
?
?
??
??
?ni    bu   bi     banli   shouxuyou  not must handle procedure?You don?t have to go through the procedure.
?Figure 5.
Parse tree of (3)Figure 6.
Parse tree of (4)In the processing of a large corpus, sentenceswith global ambiguities only have a randomchance of being analyzed correctly, but sentenceswith local ambiguities can often receive correctanalyses.
Although local ambiguities will createsome confusion in the parsing process, increase thesize of the parsing chart, and slow down process-ing, they can be resolved in the end unless we runout of resources (in terms of time and space) be-fore the analysis is complete.
Therefore, thereshould be sufficient number of cases in the corpuswhere the relationship between the verb and thenoun is clear.
An obvious strategy we can adopthere is to learn from the clear cases and use thelearned knowledge to help resolve the unclearcases.
If a verb-noun pair appears predominantlyin the verb-object relationship or the modifier headrelationship throughout the corpus, we should pre-fer this relationship everywhere else.A simple way to learn such knowledge is by us-ing a tree-filter to collect all instances of eachverb-noun pair in the parse trees of a corpus,counting the number of times they appear in eachrelationship, and then comparing their frequenciesto decide which relationship is the predominantone for a given pair.
Once we have the informa-tion that ????
is typically a modifier of ???
?and ????
typically takes ????
as an object, forinstance, the sentence in (1) will only receive theanalysis in Figure 1 and (2) only the analysis inFigure 2.
However, this only works in idealizedsituations where the parser is doing an almost per-fect job, in which case no learning would be neces-sary.
In reality, the parse trees are not alwaysreliable and the relations extracted from the parsescan contain a fair amount of noise.
It is not hard toimagine that a certain verb-noun pair may occuronly a couple of times in the corpus and they aremisanalyzed in every instance.
If such noise is notfiltered out, the knowledge we acquire will misleadus and minimize the benefit we get from this ap-proach.An obvious solution to this problem is to ignoreall the low frequency pairs and keep the high fre-quency ones only, as wrong analyses tend to berandom.
But the cut-off point is difficult to set ifwe are only looking at the raw frequencies, whoserange is hard to predict.
The cut-off point will betoo low for some pairs and too high for others.
Weneed a normalizing factor to turn the raw frequen-cies into relative frequencies.
Instead of asking?which relation is more frequent for a given pair?
?,the question should be ?of all the instances of agiven verb-noun pair in the corpus, which relationhas a higher percentage of occurrence??.
Thenormalizing factor should then be the total count ofa verb-noun pair in the corpus regardless of thesyntactic relations between them.
The normalizedfrequency of a relation for a given pair is thus thenumber of times this pair is assigned this relationin the parses divided by this normalizing factor.For example, if ??
??
occurs 10 times in thecorpus and is analyzed as verb-object 3 times andmodifier-head 7 times, the normalized frequenciesfor these two relations will be 30% and 70% re-spectively.
What we have now is actually theprobability of a given pair occurring in a given re-lationship.
This probability may not be very accu-rate, given the fact that the parse trees are notalways correct, but it should a good approximation,assuming that the corpus is large enough and mostof the potential ambiguities in the corpus are localrather than global in nature.But how do we count the number of verb-nounpairs in a corpus?
A simple bigram count will un-justly favor the modifier-head relation.
While theverb and the noun are usually adjacent when theverb modifies the noun, they can be far apart whenthe noun is the object of the verb, as illustrated in(5).
(5) ??
??
??
?
??
?
?tamen zhengzai  banli  qu   taiwan     canjiathey       PROG  handle go Taiwan participate????
??
??
??
?dishijiujie         guoji          jisuan    yuyanxue19th            international compute linguistics??
?
??
?huiyi      de     shouxuconference DE  procedure?They are going through the procedures forgoing to Taipei for  the 19th International Con-ference on Computational Linguistics.
?To get a true normalizing factor, we must countall the potential dependencies, both local and long-distance.
This is required also because the tree-filter we use to collect pair relations consider bothlocal and long-distance dependencies as well.Since simple string matching is not able to get thepotential long-distance pairs, we resorted to the useof a chart-filter.
As the parser we use is a chartparser, all the potential constituents are stored inthe chart, though only a small subset of those willend up in the parse tree.
Among the constituentscreated in the chart for the sentence in (5), for in-stance, we are supposed to find [??]
and [?????????????????????
]which are adjacent to each other.
The fact that ??
is the head of the second phrase then makes??
adjacent to ??.
We will therefore be able toget one count of ??
followed by ??
from (5)despite the long span of intervening words betweenthem.
The use of the chart-filter thus enables us tomake our normalizing factor more accurate.
Theprobability of a given verb-noun pair occurring in agiven relation is now the total count of this relationin the parse trees throughout the corpus divided bythe total count of all the potential relations found inall the charts created during the processing of thiscorpus.The cut-off point we finally used is 50%, i.e.
apair+relation will be kept in our knowledge base ifthe probability obtained this way is more than50%.
This may seem low, but it is higher than wethink considering the fact that verb-object andmodifier-head are not the only relations that canhold between a verb and a noun.
In (6), for exam-ple, ??
is not related to ??
in either way inspite of their adjacency.
(6)   ??
?
??
??
??
?
?tamen qu shanghai   banli     shouxu   suoxuthey   go Shanghai handle procedure need?
??
??
?de gongzheng      cailiaoDE   notarize        material?They went to Shanghai to handle the nota-rized material needed for the procedure.
?We will still find the ??
??
pair in thechart, but it is not expected to appear in either theverb-object relation or modifier-head relation inthe parse tree.
Therefore, the baseline probabilityfor any pair+relation might be far below 50% andmore than 50% is a good indicator that a given pairdoes typically occur in a given relation.
We canalso choose to keep all the pairs with their prob-abilities in the knowledge base and let the prob-abilities be integrated into the probability of thecomplete parse tree at the time of parse ranking.The results we obtained from the above proce-dure are quite clean, in the sense that most of thepairs that are classified into the two types of rela-tions with a probability greater than 50% are cor-rect.
Here are some sample pairs that we learned.Verb-Object:??
??
test - truth??
??
allocate - recourses??
??
manage - business??
??
offer - love??
??
cheat - pedestriansModifier-Head:??
??
testing - standard??
??
allocation - plan??
??
management - mode??
??
offering - spirit??
??
cheating - behaviorHowever, there are pairs that are correct but not?typical?
enough, especially in the verb-object re-lations.
Here are some examples:??
??
have - meaning??
??
have - impact??
??
have - color??
??
have - function??
??
have - effect?These are truly verb-object relations, but we maynot want to keep them in our knowledge base forthe following reasons.
First of all, the verbs insuch cases usually can take a wide range of objectsand the strength of association between the verband the object is weak.
In other words, the objectsare not ?typical?.
Secondly, those verbs tend notto occur in the modifier-head relation with a fol-lowing noun and we gain very little in terms ofdisambiguation by storing those pairs in theknowledge base.
To prune away those pairs, weused the log-likelihood-ratio algorithm (Dunning,1993) to compute the degree of association be-tween the verb and the noun in each pair.
Pairswhere there is high ?mutual information?
betweenthe verb and noun would receive higher scoreswhile pairs where the verb can co-occur with manydifferent nouns would receive lower scores.
Pairswith association scores below a certain thresholdwere then thrown out.
This not only makes theremaining pairs more ?typical?
but helps to cleanout more garbage.
The resulting knowledge basetherefore has higher quality.3 EvaluationThe knowledge acquired by the method describedin the previous section is used in subsequent sen-tence analysis to prefer those parses where theverb-noun sequence is analyzed in the same way asspecified in the knowledge base.
When processinga large corpus, what we typically do is analyzingthe corpus twice.
The first pass is the learningphase where we acquire additional knowledge byparsing the corpus.
The knowledge acquired isused in the second pass to get better parses.
This isone example of the general approach of ?improv-ing parsing by parsing?, as described in (Wu et al2002).To find out how much the learned knowledgecontributes to the improvement of parsing, we per-formed a human evaluation.
In the evaluation, weused our existing sentence analyzer (Heidorn 2000,Jensen et al1993, Wu and Jiang 1998) to process acorpus of 271,690 sentences to learn the verb-nounrelations.
We then parsed the same sentences firstwithout the additional knowledge and then with theacquired knowledge.
Comparing the outputs, wefound that 16,445 (6%) of the sentences had differ-ent analyses in the two passes.
We then randomlyselected 500 sentences from those ?diff?
sentencesand presented them to a linguist from an independ-ent agency who, given two different parses of thesame sentence, was asked to pick the parse shejudged to be more accurate.
The order in whichthe parses were presented was randomized so thatthe evaluator had no idea as to which tree was fromthe first pass and which one from the second pass.The linguist?s judgment showed that, with theadditional knowledge that we acquired, 350 (70%)of those sentences parsed better with the additionalknowledge, 85 (17%) parsed worse, and 65 (13%)had parses that were equally good or bad.
In otherwords, the accuracy of sentence analysis improvedsignificantly with the learning procedure discussedin this paper.Here is an example where the parse became bet-ter when the automatically acquired knowledge isused.
Due to space limitation, only the parses of afraction of the sentence is given here:(7)  ?
??
??
??
?
?yao  zunzhao  guojia   ceshi   biaozhunwant follow    nation  testing  standard?
(You) must follow the national testingstandards.
?Because of the fact that??
is ambiguous be-tween a verb (?follow?)
and a preposition (?in ac-cordance with?
), this sentence fragment got theparse tree in Figure 7 before the learned knowledgewas used, where??
was misanalyzed as the ob-ject of??
:Figure 7: old parse of (7)During the learning process, we acquired ???-???
as a typical pair where the two words are inthe modifier-head relationship.
Once this pair wasadded to our knowledge base, we got the correctparse, where ??
is analyzed as a verb and?
?as a modifier of ??
:Figure 8: New tree of (7)We later inspected the sentences where theparses became worse and found two sources for theregressions.
The main source was of course errorsin the learned results, since they had not beenmanually checked.
The second source was an en-gineering problem: the use of the acquired knowl-edge required the use of additional memory andconsequently exceeded some system limitationswhen the sentences were very long.4 Future workThe approach described in this paper can be ap-plied to the learning of many other typical syntac-tic relations between words.
We have already usedit to learn noun-noun pairs where the first noun is atypical modifier of the second noun.
This hashelped us to rule out incorrect parses where thetwo nouns were not put into the same constituent.Other relations we have been trying to learn in-clude:?
Noun-noun pairs where the two nouns are inconjunction (e.g.
??
??
?bride and bride-groom?);?
Verb-verb pairs where the two verbs are inconjunction (e.g.
??
??
?investigate andstudy?);?
Adjective-adjective pairs where two adjectivesare in conjunction (e.g.
??
??
?young andbeautiful?);?
Noun-verb pairs where the noun is a typicalsubject of the verb.Knowledge of this kind, once acquired, will benefitnot only parsing, but other NLP applications aswell, such as machine translation and informationretrieval.In terms of parsing, the benefit we get there issimilar to what we get in lexicalized statisticalparsing where parsing decisions can be based onspecific lexical items.
However, the training of astatistical parser requires a tree bank which is ex-pensive to create while our approach does not.
Ourapproach does require an existing parser, but thisparser does not have to be perfect and can be im-proved as the learning goes on.
Once the parser isreasonably good, what we need is just raw text,which is available in large quantities.5 ConclusionWe have shown in this paper that parsing qualitycan be improved by using the parser as an auto-matic learner which acquires new knowledge in thefirst pass to help analysis in the second pass.
Wedemonstrated this through the learning of typicalverb-object and modifier-head relations.
With theuse of a chart-filter, a tree-filter and the LLR algo-rithm, we are able to acquire such knowledge withhigh accuracy.
Evaluation shows that the qualityof sentence analysis can improve significantly withthe help of the automatically acquired knowledge.ReferencesDunning, T. 1993.
Accurate methods for the statisticsof surprise and coincidence.
Computational Linguis-tics, 19(1): 61-74.Heidorn, G. E. 2000.
Intelligent writing assistance, in AHandbook of Natural Language Processing: Tech-niques and Applications for the Processing of Lan-guage as Text, Dale R., Moisl H., and Somers H. eds.,Marcel Dekker, New York, pp.
181-207.Jensen, K., G. Heidorn and S. Richardson.
1993.
Natu-ral Language Processing: the PLNLP Approach?.Kluwer Academic Publishers, Boston.Smadja, F. 1993.
Retrieving collocations from text:Xtract.
Computational Linguistics, 19(1): 143-177.Wu, Andi, J. Pentheroudakis and Z. Jiang, 2002.
Dy-namic lexical acquisition in Chinese sentence analy-sis.
In Proceedings of the 19th InternationalConference on Computational Linguistics, pp.
1308-1312, Taipei, Taiwan.Wu, Andi, J. and Z. Jiang, 1998.
Word segmentation insentence analysis, in Proceedings of 1998 Interna-tional Conference on Chinese Information Process-ing, pp.
46-51.169-180, Beijing, China.
