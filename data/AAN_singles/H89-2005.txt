SUMMARY OF SESSION 2:Spoken Language Systems IChairperson- P. PriceThis session included descriptions of Spoken Language Systems under development at BBN Systemsand Technologies, Carnegie Mellon University, Massachusetts Institute of Technology and Unisys.
Thetopics covered a variety of issues including semantic interpretation (BBN), modeling "noise words" forspontaneous (vs. read) speech (CMU), dialogue management (Unisys) and systems issues (MIT andUnisys).Dave Stallard presented a survey of the natural anguage understanding effort at BBN.
The principal topicpresented was the change in formalism for semantic interpretation from a Montague-style rule-for-rulemirror of syntax to a unification framework, as has been used at various sites, including SRI and TI.Wayne Ward presented results in dealing with "noise" in speech.
The "noise" in question includedpause-filler words, mouth sounds, paper rustling, etc.
The technique for dealing with the noise was simplyto model these noises as words and to train them as other words are trained in the CMU SPHINX system.The result did not seem to affect performance much for "clean" speech (speech without these "words")and dramatically reduced the error rates for speech containing these "words".
These are encouragingresults for spoken language systems.The MIT Voyager system was presented principally in the form of a videotape that showed a complete SLSsystem for getting directions concerning the Harvard-MIT area: a subject speaks a sentence which isrecognized by the SUMMIT system, sent to TINA for interpretation and then sent to the VOYAGER back-end for execution.
The system is not yet real-time, but represents an important first step in developingspoken language systems.Lynette Hirschman presented an analysis of the Unisys experience in porting the PUNDIT system,originally designed for message processing, to a query-answering system for the VOYAGER application.The resulting architecture includes a general dialogue manager which can be used for a variety ofinteractive applications to maintain and control discourse coherency.
Lynette also presented the lastpaper in the session: Computational Requirement for a Spoken Language System, in which shepresented ways of parallelizing parsing steps and the resulting effects on computation.37
