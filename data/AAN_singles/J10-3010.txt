Query Rewriting Using MonolingualStatistical Machine TranslationStefan Riezler?GoogleYi Liu?
?GoogleLong queries often suffer from low recall in Web search due to conjunctive term matching.
Thechances of matching words in relevant documents can be increased by rewriting query terms intonew terms with similar statistical properties.
We present a comparison of approaches that deployuser query logs to learn rewrites of query terms into terms from the document space.
We showthat the best results are achieved by adopting the perspective of bridging the ?lexical chasm?between queries and documents by translating from a source language of user queries into atarget language of Web documents.
We train a state-of-the-art statistical machine translationmodel on query-snippet pairs from user query logs, and extract expansion terms from the queryrewrites produced by the monolingual translation system.
We show in an extrinsic evaluation ina real-world Web search task that the combination of a query-to-snippet translation model witha query language model achieves improved contextual query expansion compared to a state-of-the-art query expansion model that is trained on the same query log data.1.
IntroductionInformation Retrieval (IR) applications have been notoriously resistant to improvementattempts by Natural Language Processing (NLP).
With a few exceptions for specializedtasks,1 the contribution of part-of-speech taggers, syntactic parsers, or ontologies ofnouns or verbs has been inconclusive.
In this article, instead of deploying NLP toolsor ontologies, we apply NLP ideas to IR problems.
In particular, we take a viewpointthat looks at the problem of the word mismatch between queries and documents inWeb search as a problem of translating from a source language of user queries into atarget language of Web documents.
We concentrate on the task of query expansion byquery rewriting.
This task consists of adding expansion terms with similar statisticalproperties to the original query in order to increase the chances of matching words inrelevant documents, and also to decrease the ambiguity of the query that is inherentin natural language.
We focus on a comparison of models that learn to generate query?
Brandschenkestrasse 110, 8002 Zu?rich, Switzerland.
E-mail: riezler@gmail.com.??
1600 Amphitheatre Parkway, Mountain View, CA.
E-mail: yliu@google.com.1 See for example Sable, McKeown, and Church (2002), who report improvements in text categorization byusing tagging and parsing for the task of categorizing captioned images.Submission received: 19 June 2009; revised submission received: 4 March 2010; accepted for publication:12 May 2010.?
2010 Association for Computational LinguisticsComputational Linguistics Volume 36, Number 3rewrites from large amounts of user query logs, and use query expansion in Web searchfor an extrinsic evaluation of the produced rewrites.
The experimental query expansionsetup used in this article is simple and direct: For a given set of randomly selectedqueries, n-best rewrites are produced.
From the changes introduced by the rewrites,expansion terms are extracted and added as alternative terms to the query, leaving theranking function untouched.Figure 1 shows expansions of the queries herbs for chronic constipation and herbs formexican cooking using AND and OR operators.
Conjunctive matching of all query termsis the default, and indicated by the AND operator.
Expansion terms are added usingthe OR operator.
The example in Figure 1 illustrates the key requirements to successfulquery expansion, namely, to find appropriate expansions in the context of the query.While remedies, medicine, or supplement are appropriate expansions in the context of thefirst query, they would cause a severe query drift if used in the second query.
In thecontext of the second query, spices is an appropriate expansion for herbs, whereas thisexpansion would again not work for the first query.The central idea behind our approach is to combine the orthogonal informationsources of the translation model and the language model to expand query terms incontext.
The translation model proposes expansion candidates, and the query languagemodel performs a selection in the context of the surrounding query terms.
Thus, incombination, the incessant problems of term ambiguity and query drift can be solved.One of the goals of this article is to show that existing SMT technology is readilyapplicable to this task.
We apply SMT to large parallel data of queries on the sourceside, and snippets of clicked search results on the target side.
Snippets are short textfragments that represent the parts of the result pages that are most relevant to thequeries, for example, in terms of query term matches.
Although the use of snippetsinstead of the full documents makes our approach efficient, it introduces noise becausetext fragments are used instead of full sentences.
However, we show that state-of-the-art statistical machine translation (SMT) technology is in fact robust and flexible enoughto capture the peculiarities of the language pair of user queries and result snippets.We evaluate our system in a comparative, extrinsic evaluation in a real-world Websearch task.
We compare our approach to the expansion system of Cui et al (2002)that is trained on the same user logs data and has been shown to produce significantimprovements over the local feedback technique of Xu and Croft (1996) in a standardevaluation on TREC data.
Our extrinsic evaluation is done by embedding the expansionsystems into a real-world search engine, and comparing the two systems based onthe search results that are triggered by the respective query expansions.
Our resultsshow that the combination of translation and language model of a state-of-the-artSMT model produces high-quality rewrites and outperforms the expansion model ofCui et al (2002).In the following, we will discuss related work (Section 2) and quickly sketchCui et al (2002)?s approach (Section 3).
Then we will recapitulate the essentials ofFigure 1Search queries herbs for chronic constipation and herbs for mexican cooking integrating expansionterms into OR-nodes in conjunctive matching.570Riezler and Liu Query Rewriting Using Monolingual Statistical Machine Translationstate-of-the-art SMT and describe how to adapt an SMT system to the query expansiontask (Section 4).
Results of the extrinsic experimental evaluation are presented in Sec-tion 5.
The presented results are based on earlier results presented in Riezler, Liu, andVasserman (2008), and extended by deeper analyses and further experiments.2.
Related WorkStandard query expansion techniques such as local feedback, or pseudo-relevance feed-back, extract expansion terms from the topmost documents retrieved in an initial re-trieval round (Xu and Croft 1996).
The local feedback approach is costly and can lead toquery drift caused by irrelevant results in the initial retrieval round.
Most importantly,though, local feedback models do not learn from data, in contrast to the approachesdescribed in this article.Recent research in the IR community has increasingly focused on deploying userquery logs for query reformulations (Huang, Chien, and Oyang 2003; Fonseca et al2005; Jones et al 2006), query clustering (Beeferman and Berger 2000; Wen, Nie, andZhang 2002; Baeza-Yates and Tiberi 2007), or query similarity (Raghavan and Sever1995; Fitzpatrick and Dent 1997; Sahami and Heilman 2006).
The advantage of these ap-proaches is that user feedback is readily available in user query logs and can efficientlybe precomputed.
Similarly to this recent work, our approach uses data from user querylogs, but as input to a monolingual SMT model for learning query rewrites.The SMT viewpoint has been introduced to the field of IR by Berger and Lafferty(1999) and Berger et al (2000), who proposed to bridge the ?lexical chasm?
by a retrievalmodel based on IBM Model 1 (Brown et al 1993).
Since then, ranking models basedon monolingual SMT have seen various applications, especially in areas like QuestionAnswering where a large lexical gap between questions and answers has to be bridged(Berger et al 2000; Echihabi and Marcu 2003; Soricut and Brill 2006; Riezler et al 2007;Surdeanu, Ciaramita, and Zaragoza 2008; Xue, Jeon, and Croft 2008).
Whereas mostapplications of SMT ideas to IR problems used translation system scores for (re)rankingpurposes, only a few approaches use SMT to generate actual query rewrites (Riezler,Liu, and Vasserman 2008).
Similarly to Riezler, Liu, and Vasserman (2008), we use SMTto produce actual rewrites rather than for (re)ranking, and evaluate the rewrites in aquery expansion task that leaves the ranking model of the search engine untouched.Lastly, monolingual SMT has been established in the NLP community as a usefulexpedient for paraphrasing, that is, the task of reformulating phrases or sentences intosemantically similar strings (Quirk, Brockett, and Dolan 2004; Bannard and Callison-Burch 2005).
Although the use of the SMT in paraphrasing goes beyond pure ranking toactual rewriting, SMT-based paraphrasing has to our knowledge not yet been appliedto IR tasks.3.
Query Expansion by Query?Document Term CorrelationsThe query expansion model of Cui et al (2002) is based on the principle that if queriescontaining one term often lead to the selection of documents containing another term,then a strong relationship between the two terms can be assumed.
Query terms anddocument terms are linked via sessions in which users click on documents in theretrieval result for the query.
Cui et al define a session as follows:session := <query text>[clicked document]*571Computational Linguistics Volume 36, Number 3According to this definition, a link is established if at least one user clicks on a documentin the retrieval results for a query.
Because query logs contain sessions from differentusers, an aggregation of clicks over sessions will reflect the preferences of multiple users.Cui et al (2002) compute the following probability distribution of document words wdgiven query words wq from counts over clicked documents D aggregated over sessions:P(wd|wq) =?DP(wd|D)P(D|wq) (1)The first term in Equation (1) is a normalized tfidf weight of the document term inthe clicked document, and the second term is the relative cooccurrence of the clickeddocument and query term.Because Equation (1) calculates expansion probabilities for each term separately,Cui et al (2002) introduce the following cohesion formula that respects the whole queryQ by aggregating the expansion probabilities for each query term:CoWeightQ(wd) = ln(?wq?QP(wd|wq) + 1) (2)In contrast to local feedback techniques (Xu and Croft 1996), Cui et al (2002)?salgorithm allows us to precompute term correlations off-line by collecting counts fromquery logs.
This reliance on pure frequency counting is both a blessing and a curse:On the one hand it allows for efficient non-iterative estimation, but on the other handit makes the implicit assumption that data sparsity will be overcome by countingfrom huge data sets.
The only attempt at smoothing that is made in this approach isshifting the burden to words in the query context, using Equation (2), when Equation (1)assigns zero probability to unseen pairs.
Nonetheless, Cui et al (2002) show significantimprovements over the local feedback technique of Xu and Croft (1996) in an evaluationon TREC data.4.
Query Expansion Using Monolingual SMT4.1 Linear Models for SMTThe job of a translation system is defined in Och and Ney (2004) as finding the Englishstring e?
that is a translation of a foreign string f using a linear combination of featurefunctions hm(e, f) and weights ?m as follows:e?
= arg maxeM?m=1?mhm(e, f)As is now standard in SMT, several complex features such as lexical translation modelsand phrase translation models, trained in source-target and target-source directions, arecombined with language models and simple features such as phrase and word counts.In the linear model formulation, SMT can be thought of as a general tool for computingstring similarities or for string rewriting.572Riezler and Liu Query Rewriting Using Monolingual Statistical Machine Translation4.2 Word AlignmentThe relationship of translation model and alignment model for source language stringf = f J1 and target string e = eI1 is via a hidden variable describing an alignment mappingfrom source position j to target position aj:P( f J1|eI1) =?aJ1P( f J1, aJ1|eI1)The alignment aJ1 contains so-called null-word alignments aj = 0 that align source wordsto the empty word.In our approach, ?sentence aligned?
parallel training data are prepared by pairinguser queries with snippets of search results clicked for the respective queries.
Thetranslation models used are based on a sequence of word alignment models, whereas inour case three Model-1 iterations and three HMM iterations were performed.
Anotherimportant adjustment in our approach is the setting of the null-word alignment proba-bility to 0.9 in order to account for the difference in sentence length between queries andsnippets.
This setting improves alignment precision by filtering out noisy alignmentsand instead concentrating on alignments with high support in the training data.4.3 Phrase ExtractionStatistical estimation of alignment models is done by maximum-likelihood estimationof sentence-aligned strings {(fs, es) : s = 1, .
.
.
, S}.
Because each sentence pair is linkedby a hidden alignment variable a = aJ1, the optimal ??
is found using unlabeled-data log-likelihood estimation techniques such as the EM algorithm:??
= arg max?S?s=1?ap?
(fs, a|es)The (Viterbi-)alignment a?J1 that has the highest probability under a model is defined asfollows:a?J1 = arg maxaJ1p??
( fJ1, aJ1|eI1)Because a source?target algnment does not allow a source word to be aligned with twoor more target words, source?target and target?source alignments can be combined viavarious heuristics to improve both recall and precision of alignments.In our application, it is crucial to remove noise in the alignments of queries tosnippets.
In order to achieve this, we symmetrize Viterbi alignments for source?targetand target?source directions by intersection only.
That is, given two Viterbi alignmentsA1 = {(aj, j)| aj > 0} and A2 = {(i, bi)| bi > 0}, the alignments in the intersection are de-fined as A = A1 ?
A2.
Phrases are extracted as larger blocks of aligned words from thealignments in the intersection, as described in Och and Ney (2004).573Computational Linguistics Volume 36, Number 34.4 Language ModelingLanguage modeling in our approach deploys an n-gram language model that assignsthe following probability to a string wL1 of words:P(wL1 ) =L?i=1P(wi|wi?11 )?L?i=1P(wi|wi?1i?n+1)Estimation of n-gram probabilities is done by counting relative frequencies of n-gramsin a corpus of user queries.
Remedies for sparse data problems are achieved by varioussmoothing techniques, as described in Brants et al (2007).The most important departure of our approach from standard SMT is the use of alanguage model trained on queries.
Although this approach may seem counterintuitivefrom the standpoint of the noisy-channel model for SMT (Brown et al 1993), it fitsperfectly into the linear model.
Whereas in the first view a query language modelwould be interpreted as a language model on the source language, in the linear modeldirectionality of translation is not essential.
Furthermore, the ultimate task of a querylanguage model in our approach is to select appropriate phrase translations in thecontext of the original query for query expansion.
This is achieved perfectly by anSMT model that assigns the identity translation as most probable translation to eachphrase.
Descending the n-best list of translations, in effect the language model picksalternative non-identity translations for a phrase in context of identity-translations ofthe other phrases.Another advantage of using identity translations and word reordering in our ap-proach is the fact that, by preferring identity translations or word reorderings overnon-identity translations of source phrases, the SMT model can effectively abstain fromgenerating any expansion terms.
This will happen if none of the candidate phrasetranslations fits with high enough probability in the context of the whole query, asassessed by the language model.5.
Evaluating Query Expansion in a Web Search Task5.1 DataThe training data for the translation model and the correlation-based model consist ofpairs of queries and snippets for clicked results taken from query logs.
Representingdocuments by snippets makes it possible to create a parallel corpus that contains data ofroughly the same ?sentence?
length.
Furthermore, this makes iterative training feasible.Queries and snippets are linked via clicks on result pages, where a parallel sentence pairis introduced for each query and each snippet of its clicked results.
This yields a data setof 3 billion query?snippet pairs from which a phrase-table of 700 million query?snippetphrase translations is extracted.
A collection of data statistics for the training data isshown in Table 1.
The language model used in our experiment is a trigram languagemodel trained on English queries in user logs.
n-grams were cut off at a minimumfrequency of 4.
Data statistics for resulting unique n-grams are shown in Table 2.574Riezler and Liu Query Rewriting Using Monolingual Statistical Machine TranslationTable 1Statistics of query?snippet training data.query?snippet query snippetpairs words wordstokens 3 billion 8 billion 25 billionavg.
length - 2.6 8.3Table 2Statistics of unique n-grams in language model.1-grams 2-grams 3-grams9 million 1.5 billion 5 billion5.2 Query Expansion SetupThe setup for our extrinsic evaluation deploys a real-world search engine, google.com,for a comparison of expansions from the SMT-based system, the correlation-based sys-tem, and the correlation-based system using the language model as additional filter.
Allexpansion systems are trained on the same set of parallel training data.
SMT modulessuch as the language model and the translation models in source?target and target?source directions are combined in a uniform manner in order to give the SMT andcorrelation-based models the same initial conditions.The expansion terms used in our experiments were extracted as follows: Firstly,a set of 150,000 randomly extracted 3+ word queries was rewritten by each of thesystems.
For each system, expansion terms were extracted from the 5-best rewrites, andstored in a table that maps source phrases to target phrases in the context of the fullqueries.
For example, Table 3 shows unique 5-best translations of the SMT system for thequeries herbs for chronic constipation and herbs for mexican cooking.
Phrases that are newlyintroduced in the translations are highlighted in boldface.
These phrases are extractedfor expansion and stored in a table that maps source phrases to target phrases in thecontext of the query from which they were extracted.
When applying the expansionTable 3Unique 5-best phrase-level translations of queries herbs for chronic constipation and herbs formexican cooking.
Terms extracted for expansion are highlighted in boldface.
(herbs , herbs) (for , for) (chronic , chronic) (constipation , constipation)(herbs , herb) (for , for) (chronic , chronic) (constipation , constipation)(herbs , remedies) (for , for) (chronic , chronic) (constipation , constipation)(herbs , medicine) (for , for) (chronic , chronic) (constipation , constipation)(herbs , supplements) (for , for) (chronic , chronic) (constipation , constipation)(herbs , herbs) (for , for) (mexican , mexican) (cooking , cooking)(herbs , herbs) (for , for) (cooking , cooking) (mexican , mexican)(herbs , herbs) (for , for) (mexican , mexican) (cooking , food)(mexican , mexican) (herbs , herbs) (for , for) (cooking , cooking)(herbs , spices) (for , for) (mexican , mexican) (cooking , cooking)575Computational Linguistics Volume 36, Number 3table to the same 150,000 queries that were input to the translation, expansion phrasesare included in the search query via an OR-operation.
An example search query thatuses the SMT-based expansions from Table 3 is shown in Figure 1.In order to evaluate Cui et al (2002)?s correlation-based system in this setup, werequired the system to assign expansion terms to particular query terms.
The best resultswere achieved by using a linear interpolation of scores in Equation (2) and Equation (1).Equation (1) thus introduces a preference for a particular query term to the whole-query score calculated by Equation (2).
Our reimplementation uses unigram and bigramphrases in queries and expansions.
Furthermore, we use Okapi BM25 instead of tfidf inthe calculation of Equation (1) (see Robertson, Walker, and Hancock-Beaulieu 1998).In addition to SMT and correlation-based expansion, we evaluate a system that usesthe query language model to rescore the rewrites produced by the correlation-basedmodel.
The intended effect is to filter correlation-based expansions by a more effectivecontext model than the cohesion model proposed by Cui et al (2002).Because expansions from all experimental systems are done on top of the sameunderlying search engine, we can abstract away from interactions with the underlyingsystem.
Rewrite scores or translation probabilities were only used to create n-best listsfor the respective systems; the ranking function of the underlying search engine was leftuntouched.5.3 Experimental EvaluationThe evaluation was performed by three independent raters.
The raters were presentedwith queries and 10-best search results from two systems, anonymized, and presentedrandomly on left or right sides.
The raters?
task was to evaluate the results on a 7-pointLikert scale, defined as:?1.5: much worse?1.0: worse?0.5: slightly worse0: about the same0.5: slightly better1.0: better1.5: much betterTable 4 shows evaluation results for all pairings of the three expansion systems.For each pairwise comparison, a set of 200 queries that has non-empty, different re-sult lists for both systems is randomly selected from the basic set of 150,000 queries.The mean item score (averaged over queries and raters) for the experiment that com-pares the correlation-based model with language model filtering (corr+lm) againstthe correlation-based model (corr) shows a clear win for the experimental system.Table 4Comparison of query expansion systems on the Web search task with respect to a 7-pointLikert scale.experiment corr+lm SMT SMTbaseline corr corr corr+lmmean item score 0.264 ?
0.095 0.254 ?
0.09125 0.093 ?
0.0850576Riezler and Liu Query Rewriting Using Monolingual Statistical Machine TranslationAn experiment that compares SMT-based expansion (SMT) against correlation-basedexpansions (corr) results in a clear preference for the SMT model.
An experiment thatcompares the SMT-based expansions (SMT) against the correlation-based expansionsfiltered by the language model (corr+lm) shows a smaller, but still statistically signifi-cant, preference for the SMT model.
Statistical significance of result differences has beencomputed with a paired t-test (Cohen 1995), yielding statistical significance at the 95%level for the first two columns in Table 4, and statistical significance at the 90% level forthe last column in Table 4.Examples for SMT-based and correlation-based expansions are given in Table 5.The first five examples show the five biggest wins in terms of mean item score for theSMT system over the correlation-based system.
The second set of examples shows thefive biggest losses of the SMT system compared to the correlation-based system.
Oninspection of the first set, we see that SMT-based expansions such as henry viii restaurantportland, maine, or ladybug birthday ideas, or top ten restaurants, vancouver, achieve achange in retrieval results that does not result in a query drift, but rather in improvedretrieval results.
The first and fifth result are wins for the SMT system because of non-sensical expansions by the baseline correlation-based system.
A closer inspection of thesecond set of examples shows that the SMT-based expansion terms are all clearly relatedto the source terms, but not synonymous.
In the first example, shutdown is replacedby reboot or restart which causes a demotion of the top result that matches the queryexactly.
In the second example, passport is replaced by the related term visa in the SMT-based expansion.
The third example is a loss for SMT-based expansion because of areplacement of the specific term debian by the more general term linux.
The correlation-based expansions how many tv 30 rock in the fourth example, and lampasas county sheriffTable 55-best and 5-worst expansions from SMT system and corr system with mean item score.query SMT expansions corr expansions scorebroyhill conference - broyhill - welcome; 1.5center boone boone - welcomeHenry VIII Menu menu - restaurant, portland - six; 1.3Portland, Maine restaurants menu - englandladybug birthday parties - ideas, ladybug - kids 1.3parties partytop ten dining, dining - restaurants dining - 10 1.3vancouverinternational communication - international 1.3communication in communications, skills communication -veterinary medicine collegeSCRIPT TO SHUTDOWN SHUTDOWN - - ?1.0NT 4.0 shutdown, reboot, restartapplying U.S. passport passport - visa applying - home ?1.0configure debian debian - linux; configure - ?1.0to use dhcp configure - install configuringhow many episodes episodes - season, episodes - tv; ?0.83of 30 rock?
series many episodes -wikipedialampasas county department - office department - home ?0.83sheriff department577Computational Linguistics Volume 36, Number 3home in the fifth example directly hit the title of relevant Web pages, while the SMT-based expansion terms do not improve retrieval results.
However, even from thesenegative examples it becomes apparent that the SMT-based expansion terms are clearlyrelated to the query terms, and for a majority of cases this has a positive effect.
Incontrast, the terms introduced by the correlation-based system are either only vaguelyrelated or noise.Similar results are shown in Table 6 where the five best and five worst examplesfor the comparison of the SMT model with the corr+lm model are listed.
The wins forthe SMT system are achieved by synonymous or closely related terms (make - build,create; layouts - backgrounds; contractor - contractors) or terms that properly disambiguateambiguous query terms: For example, the term vet in the query dr. tim hammond, vetis expanded by the appropriate term veterinarian in the SMT-based expansion, whereasthe correlation-based expansion to vets does not match the query context.
The lossesof the SMT-based system are due to terms that are only marginally related.
Furthermore,the expansions of the correlation-based model are greatly improved by language modelfiltering.
This can be seen more clearly in Table 7, which shows the five best and worstresults from the comparison of correlation-based models with and without languagemodel filtering.
Here the wins by the filtered model are due to filtering non-sensicalexpansions or too general expansions by the unfiltered correlation-based model ratherthan promoting new useful expansions.We attribute the experimental result of a significant preference for SMT-based ex-pansions over correlation-based expansions to the fruitful combination of translationmodel and language model provided by the SMT system.
The SMT approach can beviewed as a combined system that proposes already reasonable candidate expansionsvia the translation model, and filters them by the language model.
We may find acertain amount of non-sensical expansion candidates at the phrase translation level ofthe SMT system.
However, a comparison with unfiltered correlation-based expansionsshows that the candidate pool of phrase translations of the SMT model is of higherquality, yielding overall better results after language model filtering.
This can be seenTable 65-best and 5-worst expansions from SMT system and corr+lm system with mean item score.query SMT expansions corr+lm expansions scorehow to make bombs make - build, create make - book 1.5dominion power va - dominion - virginia 1.3purple myspace layouts - backgrounds purple - free 1.167layouts myspace - freedr.
tim hammond, vet vet - veterinarian, vet - vets 1.167veterinary, hospitaltci general contractor contractor - contractors - 1.167health effects of tea - coffee - ?1.5drinking too much teatomahawk wis - wis - wisconsin ?1.0bike rallyapprentice tv show - tv - com ?1.0super nes roms roms - emulator nes - nintendo ?1.0family guy family - genealogy clips - video ?1.0clips hitler578Riezler and Liu Query Rewriting Using Monolingual Statistical Machine TranslationTable 75-best and 5-worst expansions from corr system and corr+lm system with mean item score.query corr+lm expansions corr expansions scoreouter cape - cape - home; 1.5health services health - home;services - homeHenry VII Menu - menu - england; 1.5Portland, Maine portland - sixeasing to relieve gallbladder - gallstone gallbladder - disease, 1.333gallbladder pain gallstones, gallstoneguardian angel picture - picture - lyrics 1.333view full episodes episodes - watch naruto - tv 1.333of narutoiditarod 2007 schedule iditarod 2007 - race - ?1.540 inches plus inches plus - review inches - calculator ?1.333Lovell sisters review lovell sisters - website - ?1.333smartparts ion Review smartparts ion - reviews review - pbreview ?1.167canon eos rebel epinion - com - ?1.167xt slr + epinionfrom inspecting Table 8 which shows the most probable phrase translations that areapplicable to the queries herbs for chronic constipation and herbs for mexican cooking.
Thephrase tables include identity translations and closely related terms as most probabletranslations for nearly every phrase.
However, they also clearly include noisy and non-related terms.
Thus an extraction of expansion terms from the phrase table alone wouldnot allow the choice of the appropriate term for the given query context.
This can beattained by combining the phrase translations with a language model: As shown inTable 3, the 5-best translations of the full queries attain a proper disambiguation of thesenses of herbs by replacing the term with remedies, medicine, and supplements for the firstTable 8Phrase translations for source strings herbs for chronic constipation and herbs for mexican cooking.herbs herbs, herbal, medicinal, spices, supplements, remediesherbs for herbs for, herbs, herbs and, with herbsherbs for chronic herbs for chronic, and herbs for chronic, herbs forfor chronic for chronic, chronic, of chronicfor chronic constipation for chronic constipation, chronic constipation, for constipationchronic chronic, acute, patients, treatmentchronic constipation chronic constipation, of chronic constipation,with chronic constipationconstipation constipation, bowel, common, symptomsfor mexican for mexican, mexican, the mexican, of mexicanfor mexican cooking mexican food, mexican food and, mexican glossarymexican mexican, mexico, the mexicanmexican cooking mexican cooking, mexican food, mexican, cookingcooking cooking, culinary, recipes, cook, food, recipe579Computational Linguistics Volume 36, Number 3Table 9Correlation-based expansions for queries herbs for chronic constipation and herbs for mexicancooking.query terms n-best expansionsherbs com treatment encyclopediachronic interpret treating comconstipation interpret treating comherbs for medicinal support womenfor chronic com gold encyclopediachronic constipation interpret treatingherbs cooks recipes commexican recipes com cookscooking cooks recipes comherbs for medicinal women supportfor mexican cooks com allrecipesquery, and with spices for the second query.
Table 9 shows the top three correlation-based expansion terms assigned to unigrams and bigrams in the queries herbs forchronic constipation and herbs for mexican cooking.
Expansion terms are chosen by overallhighest weight and shown in boldface.
Relevant expansion terms such as treatmentor recipes that would disambiguate the meaning of herbs are in fact in the candidatelist; however, the cohesion score promotes general terms such as interpret or com asbest whole-query expansions.
Although language model filtering greatly improves thequality of correlation-based expansions, overall the combination of phrase translationsand language model produces better results than the combination of correlation-basedexpansions and language model.
This is confirmed by the pairwise comparison of theSMT and corr+lm systems shown in Table 4.6.
ConclusionWe presented a view of the term mismatch problem between queries and Web doc-uments as a problem of translating from a source language of user queries to a tar-get language of Web documents.
We showed that a state-of-the-art SMT model canbe applied to parallel data of user queries and snippets for clicked Web documents,and showed improvements over state-of-the-art probabilistic query expansion.
Ourexperimental evaluation showed firstly that state-of-the-art SMT is robust and flexibleenough to capture the peculiarities of query?snippet translation, thus questioning theneed for special-purpose models to control noisy translations as suggested by Lee et al(2008).
Furthermore, we showed that the combination of translation model and lan-guage model significantly outperforms the combination of correlation-based model andlanguage model.
We chose to take advantage of the access the google.com search engineto evaluate the query rewrite systems by query expansion embedded in a real-wordsearch task.
Although this conforms with recent appeals for more extrinsic evaluations(Belz 2009), it decreases the reproducability of the evaluation experiment.In future work, we hope to apply SMT-based rewriting to other rewriting tasks suchas query suggestions.
Also, we hope that our successful application of SMT to query580Riezler and Liu Query Rewriting Using Monolingual Statistical Machine Translationexpansion might serve as an example and perhaps open the doors for new applicationsand extrinsic evaluations of related NLP approaches such as paraphrasing.ReferencesBaeza-Yates, Ricardo and Alessandro Tiberi.2007.
Extracting semantic relations fromquery logs.
In Proceedings of the 13thACM SIGKDD Conference on KnowledgeDiscovery and Data Mining (KDD?07),San Jose, CA, pages 76?85.Bannard, Colin and Chris Callison-Burch.2005.
Paraphrasing with bilingual parallelcorpora.
In Proceedings of the 43rd AnnualMeeting of the Association for ComputationalLinguistics (ACL?05), Ann Arbor, MI,pages 597?604.Beeferman, Doug and Adam Berger.
2000.Agglomerative clustering of a searchengine query log.
In Proceedings of the 6thACM SIGKDD International Conference onKnowledge Discovery and Data Mining(KDD?00), Boston, MA, pages 407-416.Belz, Anja.
2009.
That?s nice ... what can youdo with it?
Computational Linguistics,35(1):111?118.Berger, Adam and John Lafferty.
1999.Information retrieval as statisticaltranslation.
In Proceedings of the 22ndACM SIGIR Conference on Research andDevelopment in Information Retrieval(SIGIR?99), Berkeley, CA, pages 222-229.Berger, Adam L., Rich Caruana, David Cohn,Dayne Freitag, and Vibhu Mittal.
2000.Bridging the lexical chasm: Statisticalapproaches to answer-finding.
InProceedings of the 23rd ACM SIGIRConference on Research and Developmentin Information Retrieval (SIGIR?00),Athens, Greece, 192?199.Brants, Thorsten, Ashok C. Popat, Peng Xu,Franz J. Och, and Jeffrey Dean.
2007.
Largelanguage models in machine translation.In Proceedings of the Conference on EmpiricalMethods in Natural Language Processing(EMNLP?07), Prague Czech Republic,pages 858?867.Brown, Peter F., Stephen A. Della Pietra,Vincent J. Della Pietra, and Robert L.Mercer.
1993.
The mathematics ofstatistical machine translation: Parameterestimation.
Computational Linguistics,19(2):263?311.Cohen, Paul R. 1995.
Empirical Methods forArtificial Intelligence.
The MIT Press,Cambridge, MA.Cui, Hang, Ji-Rong Wen, Jian-Yun Nie,and Wei-Ying Ma.
2002.
Probabilisticquery expansion using query logs.In Proceedings of the 11th InternationalWorld Wide Web conference (WWW?02),Honolulu, HI, pages 325?332.Echihabi, Abdessamad and Daniel Marcu.2003.
A noisy-channel approach toquestion answering.
In Proceedings of the41st Annual Meeting of the Associationfor Computational Linguistics (ACL?03),Sapporo, Japan, pages 16?23.Fitzpatrick, Larry and Mei Dent.
1997.Automatic feedback using past queries:Social searching?
In Proceedings of the 20thAnnual International ACM SIGIR Conferenceon Research and Development in InformationRetrieval (SIGIR?97), Philadelphia, PA,pages 306?313.Fonseca, Bruno M., Paulo Golgher, BrunoPossas, Berthier Ribeiro-Neto, and NivioZiviani.
2005.
Concept-based interactivequery expansion.
In Proceedings of the 14thConference on Information and KnowledgeManagement (CIKM?05), Bremen, Germany,pages 696?703.Huang, Chien-Kang, Lee-Feng Chien, andYen-Jen Oyang.
2003.
Relevant termsuggestion in interactive Web search basedon contextual information in query sessionlogs.
Journal of the American Society forInformation Science and Technology,54(7):638?649.Jones, Rosie, Benjamin Rey, Omid Madani,and Wiley Greiner.
2006.
Generating querysubstitutions.
In Proceedings of the 15thInternational World Wide Web conference(WWW?06), Edinburgh, Scotland,pages 387?396.Lee, Jung-Tae, Sang-Bum Kim, Young-InSong, and Hae-Chang Rim.
2008.
Bridginglexical gaps between queries and questionson large online QA collections withcompact translation models.
In Proceedingsof the Conference on Empirical Methods inNatural Language Processing (EMNLP?08),Honolulu, HI, pages 410?418.Och, Franz Josef and Hermann Ney.
2004.The alignment template approachto statistical machine translation.Computational Linguistics, 30(4):417?449.Quirk, Chris, Chris Brockett, and WilliamDolan.
2004.
Monolingual machinetranslation for paraphrase generation.
InProceedings of the 42nd Annual Meeting of theAssociation for Computational Linguistics(ACL?04), Barcelona, Spain, pages 142?149.Raghavan, Vijay V. and Hayri Sever.
1995.On the reuse of past optimal queries.
InProceedings of the 18th Annual International581Computational Linguistics Volume 36, Number 3ACM SIGIR Conference on Research andDevelopment in Information Retrieval(SIGIR?95), Seattle, WA, pages 344?350.Riezler, Stefan, Yi Liu, and AlexanderVasserman.
2008.
Translating queries intosnippets for improved query expansion.In Proceedings of the 22nd InternationalConference on Computational Linguistics(COLING?08), Manchester, England,pages 737?744.Riezler, Stefan, Alexander Vasserman,Ioannis Tsochantaridis, Vibhu Mittal, andYi Liu.
2007.
Statistical machine translationfor query expansion in answer retrieval.
InProceedings of the 45th Annual Meeting of theAssociation for Computational Linguistics(ACL?07), Prague Czech Republic, Vol.
1,pages 464?471.Robertson, Stephen E., Steve Walker, andMicheline Hancock-Beaulieu.
1998.Okapi at TREC-7.
In Proceedings of theSeventh Text REtrieval Conference(TREC-7), Gaithersburg, MD,pages 253?264.Sable, Carl, Kathleen McKeown, andKenneth W. Church.
2002.
NLP foundhelpful (at least for one text categorizationtask).
In Proceedings of the 2002 Conferenceon Empirical Methods in Natural LanguageProcessing (EMNLP?02), Philadelphia, PA,pages 172?179.Sahami, Mehran and Timothy D. Heilman.2006.
A Web-based kernel function formeasuring the similarity of short textsnippets.
In Proceedings of the 15thInternational World Wide Web conference(WWW?06), Edinburgh, Scotland,pages 377-386.Soricut, Radu and Eric Brill.
2006.
Automaticquestion answering using the Web:Beyond the factoid.
Journal of InformationRetrieval - Special Issue on Web InformationRetrieval, 9:191?206.Surdeanu, M., M. Ciaramita, andH.
Zaragoza.
2008.
Learning to rankanswers on large online QA collections.
InProceedings of the 46th Annual Meeting of theAssociation for Computational Linguistics(ACL?08), Columbus, OH, pages 719?727.Wen, Ji-Rong, Jian-Yun Nie, and Hong-JiangZhang.
2002.
Query clustering using userlogs.
ACM Transactions on InformationSystems, 20(1):59?81.Xu, Jinxi and W. Bruce Croft.
1996.Query expansion using local andglobal document analysis.
In Proceedingsof the 30th Annual International ACMSIGIR Conference on Research andDevelopment in Information Retrieval(SIGIR?07), Zurich, Switzerland,pages 4?11.Xue, Xiaobing, Jiwoon Jeon, and Bruce Croft.2008.
Retrieval models for question andanswer archives.
In Proceedings of the 31stAnnual International ACM SIGIR Conferenceon Research and Development in InformationRetrieval (SIGIR?08), Singapore,pages 475?482.582
