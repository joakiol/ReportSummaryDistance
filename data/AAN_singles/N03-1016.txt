A* Parsing: Fast Exact Viterbi Parse SelectionDan KleinComputer Science DepartmentStanford UniversityStanford, CA 94305-9040klein@cs.stanford.eduChristopher D. ManningComputer Science DepartmentStanford UniversityStanford, CA 94305-9040manning@cs.stanford.eduAbstractWe present an extension of the classic A* searchprocedure to tabular PCFG parsing.
The use of A*search can dramatically reduce the time required tofind a best parse by conservatively estimating theprobabilities of parse completions.
We discuss vari-ous estimates and give efficient algorithms for com-puting them.
On average-length Penn treebank sen-tences, our most detailed estimate reduces the to-tal number of edges processed to less than 3% ofthat required by exhaustive parsing, and a simplerestimate, which requires less than a minute of pre-computation, reduces the work to less than 5%.
Un-like best-first and finite-beam methods for achievingthis kind of speed-up, an A* method is guaranteed tofind the most likely parse, not just an approximation.Our parser, which is simpler to implement than anupward-propagating best-first parser, is correct for awide range of parser control strategies and maintainsworst-case cubic time.1 IntroductionPCFG parsing algorithms with worst-case cubic-timebounds are well-known.
However, when dealing withwide-coverage grammars and long sentences, even cu-bic algorithms can be far too expensive in practice.
Twoprimary types of methods for accelerating parse selec-tion have been proposed.
Roark (2001) and Ratnaparkhi(1999) use a beam-search strategy, in which only the bestn parses are tracked at any moment.
Parsing time is lin-ear and can be made arbitrarily fast by reducing n. Thisis a greedy strategy, and the actual Viterbi (highest proba-bility) parse can be pruned from the beam because, whileit is globally optimal, it may not be locally optimal at ev-ery parse stage.
Chitrao and Grishman (1990), Caraballoand Charniak (1998), Charniak et al (1998), and Collins(1999) describe best-first parsing, which is intended fora tabular item-based framework.
In best-first parsing,one builds a figure-of-merit (FOM) over parser items,and uses the FOM to decide the order in which agendaitems should be processed.
This approach also dramat-ically reduces the work done during parsing, though it,too, gives no guarantee that the first parse returned is theactual Viterbi parse (nor does it maintain a worst-case cu-bic time bound).
We discuss best-first parsing further insection 3.3.Both of these speed-up techniques are based on greedymodels of parser actions.
The beam search greedilyprunes partial parses at each beam stage, and a best-firstFOM greedily orders parse item exploration.
If we wishto maintain optimality in a search procedure, the obviousthing to try is A* methods (see for example Russell andNorvig, 1995).
We apply A* search to a tabular item-based parser, ordering the parse items based on a com-bination of their known internal cost of construction anda conservative estimate of their cost of completion (seefigure 1).
A* search has been proposed and used forspeech applications (Goel and Byrne, 1999, Corazza etal., 1994); however, it has been little used, certainly in therecent statistical parsing literature, apparently because ofdifficulty in conceptualizing and computing effective ad-missible estimates.
The contribution of this paper is todemonstrate effective ways of doing this, by precomput-ing grammar statistics which can be used as effective A*estimates.The A* formulation provides three benefits.
First, itsubstantially reduces the work required to parse a sen-tence, without sacrificing either the optimality of the an-swer or the worst-case cubic time bounds on the parser.Second, the resulting parser is structurally simpler than aFOM-driven best-first parser.
Finally, it allows us to eas-ily prove the correctness of our algorithm, over a broadrange of control strategies and grammar encodings.In this paper, we describe two methods of construct-ing A* bounds for PCFGs.
One involves context sum-marization, which uses estimates of the sort proposed inCorazza et al (1994), but considering richer summaries.The other involves grammar summarization, which, toour knowledge, is entirely novel.
We present the esti-mates that we use, along with algorithms to efficientlycalculate them, and illustrate their effectiveness in a tab-ular PCFG parsing algorithm, applied to Penn Treebanksentences.Edmonton, May-June 2003Main Papers , pp.
40-47Proceedings of HLT-NAACL 2003wordsS:[0,n]startX?
?DT:[0,1] NN:[1,2] VBZ:[2,3]startS:[0,3]NP:[0,2]VP:[0,2](a) (b)Figure 1: A* edge costs.
(a) The cost of an edge X is a com-bination of the cost to build the edge (the Viterbi inside score?)
and the cost to incorporate it into a root parse (the Viterbioutside score ?).
(b) In the corresponding hypergraph, we haveexact values for the inside score from the explored hyperedges(solid lines), and use upper bounds on the outside score, whichestimate the dashed hyperedges.2 An A* AlgorithmAn agenda-based PCFG parser operates on parse itemscalled edges, such as NP:[0,2], which denote a grammarsymbol over a span.
The parser maintains two data struc-tures: a chart or table, which records edges for which(best) parses have already been found, and an agenda ofnewly-formed edges waiting to be processed.
The coreloop involves removing an edge from the agenda andcombining that edge with edges already in the chart tocreate new edges.
For example, NP:[0,2] might be re-moved from the agenda, and, if there were a rule S ?
NPVP and VP:[2,8] was already entered into the chart, theedge S:[0,8] would be formed, and added to the agenda ifit were not in the chart already.The way an A* parser differs from a classic chartparser is that, like a best-first parser, agenda edges areprocessed according to a priority.
In best-first parsing,this priority is called a figure-of-merit (FOM), and isbased on various approximations to P (e|s), the frac-tion of parses of a sentence s which include an edge e(though see Goodman (1997) for an alternative notion ofFOM).
Edges which seem promising are explored first;others can wait on the agenda indefinitely.
Note thateven if we did know P (e|s) exactly, we still would notknow whether e occurs in any best parse of s. Nonethe-less, good FOMs empirically lead quickly to good parses.Best-first parsing aims to find a (hopefully good) parsequickly, but gives no guarantee that the first parse discov-ered is the Viterbi parse, nor does it allow one to recog-nize the Viterbi parse when it is found.In A* parsing, we wish to construct priorities whichwill speed up parsing, yet still guarantee optimality (thatthe first parse returned is indeed a best parse).
With acategorical CFG chart parser run to exhaustion, it doesnot matter in what order one removes edges from theagenda; all edges involved in full parses of the sentencewill be constructed at some point.
A cubic time boundfollows straightforwardly by simply testing for edge exis-tence, ensuring that we never process an edge twice.
WithPCFG parsing, there is a subtlety involved.
In addition toknowing whether edges can be constructed, we also wantto know the scores of edges?
best parses.
Therefore, werecord estimates of best-parse scores, updating them asbetter parses are found.
If, during parsing, we find a new,better way to construct some edge e that has previouslybeen entered into the chart, we may also have found a bet-ter way to construct any edges which have already beenbuilt using e. Best-first parsers deal with this by allowingan upward propagation, which updates such edges?
scores(Caraballo and Charniak, 1998).
If run to exhaustion, alledges?
Viterbi scores will be correct, but the propagationdestroys the cubic time bound of the parser, since in effecteach edge can be processed many times.In order to ensure optimality, it is sufficient that, forany edge e, all edges f which are contained in a bestparse of e get removed from the agenda before e itselfdoes.
If we have an edge priority which ensures this or-dering, we can avoid upward propagation entirely (andomit the data structures involved in it) and still be surethat each edge leaves the agenda scored correctly.
If thegrammar happens to be in CNF, one way to do this is togive shorter spans higher priority than longer ones; thispriority essentially gives the CKY algorithm.Formally, assume we have a PCFG G and a sentences = 0wn (we place indices as fenceposts between words).An inside parse of an edge e = X :[i, j] is a derivation inG from X to iwj .
Let ?G(e, s) denote the log-probabilityof a best inside parse of e (its Viterbi inside score).1 Wewill drop the G, s, and even e when context permits.
Ourparser, like a best-first parser, maintains estimates b(e, s)of ?
(e, s) which begin at ?
?, only increase over time,and always represent the score of the best parses of theiredges e discovered so far.
Optimality means that for anye, b(e, s) will equal ?G(e, s) when e is removed from theagenda.If one uses b(e, s) to prioritize edges, we show in Kleinand Manning (2001a), that the parser is optimal over ar-bitrary PCFGs, and a wide range of control strategies.This is proved using an extension of Dijkstra?s algorithmto a certain kind of hypergraph associated with parsing,shown in figure 1(b): parse items are nodes in the hyper-graph, hyperarcs take sets of parse items to their resultitem, and hyperpaths map to parses.
Reachability fromstart corresponds to parseability, and shortest paths toViterbi parses.1Our use of inside score and outside score evokes the samepicture as talk about inside and outside probabilities, but notethat in this paper inside and outside scores always refer to (abound on) the maximum (Viterbi) probability parse inside oroutside some edge, rather than to the sum for all such parses.Estimate SX SXL SXLR TRUESummary (1,6,NP) (1,6,NP,VBZ) (1,6,NP,VBZ,?,?)
(entire context)Best Tree SPPIN?NPNP,?NPDT?JJ?NN?VPVBD?.
?SVPVBZVBZNPNPPPIN?NPDT?NNP?NNP?NNP?NNP?SVPVBZVBZNPNPNP,,CC?NPDT?JJ?NN?,?SSVPVBZVBZNPNP,,NPPRPPRPVPVBZVBZNPDTDTNNNN..Score ?11.3 ?13.9 ?15.1 ?18.1(a) (b) (c) (d)Figure 2: Best outside parses given richer summaries of edge context.
(a ?
SX) Knowing only the edge state (NP) and the left andright outside spans, (b ?
SXL) also knowing the left tag, (c ?
SXLR) left and right tags, and (d ?
TRUE) the entire outside context.The hypergraph shown in figure 1(b) shows a parse ofthe goal S:[0,3] which includes NP:[0,2].2 This parse canbe split into an inside portion (solid lines) and an outsideportion (dashed lines), as indicated in figure 1(a).
Theoutside portion is an outside parse: formally, an outsideparse of an edge X :[i, j] in sentence s = 0wn is a deriva-tion from G?s root symbol to w0iXwjn.
We use ?G(e, s)to denote the score of a best outside parse of e.Using b(e, s) as the edge priority corresponds to a gen-eralization of uniform cost search on graphs (Russell andNorvig, 1995).
In the analogous generalization of A*search, we add to b(e, s) an estimate a(e, s) of the com-petion cost ?G(e, s) (the cost of the dashed outside parse)to focus exploration on regions of the graph which appearto have good total cost.A* search is correct as long as the estimate a satis-fies two conditions.
First, it must be admissible, meaningthat it must not underestimate the actual log-probabilityrequired to complete the parse.
Second, it must be mono-tonic, meaning that as one builds up a tree, the combinedlog-probability ?
+ a never increases.
The proof of thisis very similar to the proof of the uniform-cost case inKlein and Manning (2001a), and so we omit it for spacereasons (it can be found in Klein and Manning, 2002).Concretely, we can use b + a as the edge priority, pro-vided a is an admissible, monotonic estimate of ?.
Wewill still have a correct algorithm, and even rough heuris-tics can dramatically cut down the number of edges pro-cessed (and therefore total work).
We next discuss severalestimates, describe how to compute them efficiently, andshow the edge savings when parsing Penn treebank WSJsentences.3 A* Estimates for ParsingWhen parsing with a PCFG G, each edge e = X :[i, j]spans some interval [i, j] of the sentence and is labeled2The example here shows a bottom-up construction of aparse tree.
However, the present algorithm and estimates workjust as well for top-down chart parsing, given suitable activeitems as nodes; see (Klein and Manning, 2001a).by some grammar symbol (or state) X .
Our presentationassumes that G is a binarized grammar, and so in gen-eral X may be either a complete state like NP that wasin an original n-ary grammar, or an intermediate state,like an Earley dotted rule, that is the result of implicit orexplicit grammar binarization.
For the edge e, its yieldin s = 0wn is the sequence of terminals that it spans(iwj).
Its context is its state X along with the rest ofthe terminals of sentence (0wiXjwn).
Scores are log-probabilities; lower cost is higher log-probability.
So, ?>?or ?better?
will mean higher log-probability.3.1 Context Summary EstimatesOne way to construct an admissible estimate is to sum-marize the context in some way, and to find the score ofthe best parse of any context that fits that summary.
Letc(e, s) be the context of e in s. Let ?
be a summary func-tion of contexts.
We can then use the context summaryestimate:a?
(e, s) = max(e?,s?):?(c(e?,s?))=?
(c(e,s))?G(e?, s?)
?
?G(e, s)That is, we return the exact Viterbi outside score for somecontext, generally not the actual context, whose summarymatches the actual one?s summary.
If the number of sum-maries is reasonable, we can precompute and store theestimate for each summary once and for all, then retrievethem in constant time per edge at parse time.If we give no information in the summary, the estimatewill be constantly 0.
This is the trivial estimate NULL,and corresponds to simply using inside estimates b aloneas priorities.
On the other extreme, if each context hada unique summary, then a(e, s) would be ?G(e, s) itself.This is the ideal estimate, which we call TRUE.
In prac-tice, of course, precomputing TRUE would not be feasi-ble.33Note that our ideal estimate is not P (e|s) like the idealFOM, rather it is P (Tg,e)/P (Te) (where Tg,e is a best parse ofthe goal g among those which contain e, and Te is a best parseof e over the yield of e).
That is, we are not estimating parserchoice probabilities, but parse tree probabilities.We used various intermediate summaries, some illus-trated in figure 2.
S1 specifies only the total number ofwords outside e, while S specifies separately the numberto the left and right.
SX also specifies e?s label.
SXL andSXR add the tags adjacent to e on the left and right re-spectively.
S1XLR includes both the left and right tags,but merges the number of words to the left and right.4As the summaries become richer, the estimates becomesharper.
As an example, consider an NP in the context?VBZ NP , PRP VBZ DT NN .?
shown in figure 2.5 Thesummary SX reveals only that there is an NP with 1 wordto the left and 6 the right, and gives an estimate of ?11.3.This score is backed by the concrete parse shown in fig-ure 2(a).
This is a best parse of a context compatible withwhat little we specified, but very optimistic.
It assumesvery common tags in very common patterns.
SXL addsthat the tag to the left is VBZ, and the hypothesis that theNP is part of a sentence-initial PP must be abandoned;the best score drops to ?13.9, backed by the parse in fig-ure 2(b).
Specifying the right tag to be ?,?
drops the scorefurther to ?15.1, given by figure 2(c).
The actual bestparse is figure 2(d), with a score of ?18.1.These estimates are similar to quantities calculated inCorazza et al (1994); in that work, they are interestedin the related problem of finding best completions forstrings which contain gaps.
For the SX estimate, forexample, the string would be the edge?s label and two(fixed-length) gaps.
They introduce quantities essentiallythe same as our SX estimate to fill gaps, and their one-word update algorithms are similarly related to those weuse here.
The primary difference here is in the applicationof these quantities, not their calculation.3.2 Grammar Projection EstimatesThe context summary estimates described above use localinformation, combined with span sizes.
This gives theeffect that, for larger contexts, the best parses which backthe estimates will have less and less to do with the actualcontexts (and hence will become increasingly optimistic).Context summary estimates do not pin down the exactcontext, but do use the original grammar G. For grammarprojection estimates, we use the exact context, but projectthe grammar to some G?
which is so much simpler that itis feasible to first exhaustively parse with G?
and then usethe result to guide the search in the full grammar G.Formally, we have a projection pi which maps gram-mar states of G (that is, the dotted rules of an Earley-styleparser) to some reduced set.
This projection of states in-duces a projection of rules.
If a set R = {r} of rules inG collide as the rule r?
in G?, we give r?
the probability4Merging the left and right outside span sizes in S1XLR wasdone solely to reduce memory usage.5Our examples, and our experiments, use delexicalized sen-tences from the Penn treebank.Grammar StateProjection NP CC NP ?
?
CC NP CC NPNULL X X XSX NP X NP ?
?
X NP X NPXBAR NP CC NP?F X CC X ?
?
CC X CC XTRUE NP CC NP ?
?
CC NP CC NPFigure 3: Examples of grammar state images under severalgrammar projections.P (r?)
= maxr?R P (r).
Note that the resulting grammarG?
will not generally be a proper PCFG; it may assignmore than probability 1 to the set of trees it generates.
Infact, it will usually assign infinite mass.
However, all thatmatters for our purposes is that every tree in G projectsunder pi to a tree in G?
with the same or higher probabil-ity, which is true because every rule in G does.
There-fore, we know that ?G(e, s) ?
?G?
(e, s).
If G?
is muchmore compact than G, for each new sentence s, we canfirst rapidly calculate api = ?G?
for all edges, then parsewith G.The identity projection ?
returns G and therefore a?
isTRUE.
On the other extreme, a constant projection givesNULL (if any rewrite has probability 1).
In between, wetried three other grammar projection estimates (examplesin figure 3).
First, consider mapping all terminal states toa single terminal token, but not altering the grammar inany other way.
If we do this projection, then we get theSX estimate from the last section (collapsing the termi-nals together effectively hides which terminals are in thecontext, but not their number).
However, the resultinggrammar is nearly as large as G, and therefore it is muchmore efficient to use the precomputed context summaryformulation.
Second, for the projection XBAR, we triedcollapsing all the incomplete states of each complete stateto a single state (so NP?
?
CC NP and NP?
?
PP wouldboth become NP?).
This turned out to be ineffective, sincemost productions then had merged probability 1.For our current grammar, the best estimate of this typewas one we called F, for filter, which collapsed all com-plete (passive) symbols together, but did not collapse anyterminal symbols.
So, for example, a state like NP?
?
CCNP CC NP would become X?
?
CC X CC X (see section 3.3for a description of our grammar encodings).
This esti-mate has an interesting behavior which is complementaryto the context summary estimates.
It does not indicatewell when an edge would be moderately expensive to in-tegrate into a sentence, but it is able to completely elimi-nate certain edges which are impossible to integrate intoa full parse (for example in this case maybe the two CCtags required to complete the NP are not present in thefuture context).A close approximation to the F estimate can also becomputed online especially quickly during parsing.
SinceTRUES1SSXSXRSXLSXMLRS1XLRFBBFNULLunionsqunionsqunionsqTRUESXSXL SXRFNULLCONTEXT SUMMARYGRAMMAR PROJECTION(a) (b)Figure 4: (a) The A* estimates form a lattice.
Lines indicatesubsumption, unionsq indicates estimates which are the explicit joinof lower estimates.
(b) Context summary vs. grammar projec-tion estimates: some estimates can be cast either way.we are parsing with the Penn treebank covering gram-mar, almost any (phrasal) non-terminal can be built overalmost any span.
As discussed in Klein and Manning(2001b), the only source of constraint on what edges canbe built where is the tags in the rules.
Therefore, an edgewith a label like NP?
?
CC NP CC NP can essentially bebuilt whenever (and only whenever) two CC tags are inthe edge?s right context, one of them being immediatelyto the right.
To the extent that this is true, F can be ap-proximated by simply scanning for the tag configurationrequired by a state?s local rule, and returning 0 if it ispresent and ??
otherwise.
This is the method we usedto implement F; exactly parsing with the projected gram-mar was much slower and did not result in substantialimprovement.It is worth explicitly discussing how the F estimate dif-fers from top-down grammar-driven filtering standardlyused by top-down chart parsers; in the treebank grammar,there is virtually no top-down filtering to be exploited(again, see Klein and Manning (2001b)).
In a left-to-rightparse, top-down filtering is a prefix licensing condition; Fis more of a sophisticated lookahead condition on suf-fixes.The relationships between all of these estimates areshown in figure 4.
The estimates form a join lattice (fig-ure 4(a)): adding context information to a merged con-text estimate can only sharpen the individual outside es-timates.
In this sense, for example S ?
SX.
The latticetop is TRUE and the bottom is NULL.
In addition, theminimum (unionsq) of a set of admissible estimates is still anadmissible estimate.
We can use this to combine our ba-sic estimates into composite estimates: SXMLR = unionsq (SXL,SXR) will be valid, and a better estimate than either SXLor SXR individually.
Similarly, B is unionsq (SXMLR, S1XLR).There are other useful grammar projections, which arebeyond the scope of this paper.
First, much recent statisti-cal parsing work has gotten value from splitting grammarOriginal Rules Outside-Trie Rules Inside-Trie RulesNP ?
DT JJ NN 0.3 NP ?
XNP?
?
NN NN 0.4 NP ?
XDT JJ NN 0.3NP ?
DT NN NN 0.1 XNP?
?
NN ?
DT JJ 0.75 NP ?
XDT NN NN 0.1XNP?
?
NN ?
DT NN 0.25 XDT JJ ?
DT JJ 1.0XDT NN ?
DT NN 1.0Figure 5: Two trie encodings of rules.0102030405060708090100NULL S SX SXLS1XLRSXRSXMLR BEdgesBlockedO-TriesI-TriesFigure 6: Fraction of edges saved by using various estimatemethods, for two rule encodings.
O-TRIE is a deterministicright-branching trie encoding (Leermakers, 1992) with weightspushed left (Mohri, 1997).
I-TRIE is a non-deterministic left-branching trie with weights on rule entry as in Charniak et al(1998).states, such as by annotating nodes with their parent andeven grandparent categories (Johnson, 1998).
This anno-tation multiplies out the state space, giving a much largergrammar, and projecting back to the unannotated state setcan be used as an outside estimate.
Second, and perhapsmore importantly, this technique can be applied to lexicalparsing, where the state projections are onto the delex-icalized PCFG symbols and/or onto the word-word de-pendency structures.
This is particularly effective whenthe tree model takes a certain factored form; see Kleinand Manning (2003) for details.3.3 Parsing PerformanceFollowing (Charniak et al, 1998), we parsed unseen sen-tences of length 18?26 from the Penn Treebank, using thegrammar induced from the remainder of the treebank.6We tried all estimates described above.Rules were encoded as both inside (I) and outside (O)tries, shown in figure 5.
Such an encoding binarizes thegrammar, and compacts it.
I-tries are as in Charniak etal.
(1998), where NP?
DT JJ NN becomes NP ?
XDT JJNN and XDT JJ ?
DT JJ, and correspond to dropping theportion of an Earley dotted rule after the dot.7 O-tries,as in Leermakers (1992), turn NP?
DT JJ NN into NP ?XNP?
?
NN NN and XNP?
?
NN ?
DT JJ, and correspond to6We chose the data set used by Charniak and coauthors, soas to facilitate comparison with previous work.
We do howeveracknowledge that many of our current local estimates are lesseffective on longer spans, and so would work less well on 40?50 word sentences.
This is an area of future research.7In Charniak et al (1998), the binarization is in the reversedirection; we binarize into a left chain because it is the standarddirection implicit in chart parsers?
dotted rules, and the directionmakes little difference in edge counts.0%10%20%30%40%50%60%70%80%90%100%0 2000 4000 6000 8000 10000Edges ProcessedSentencesParsedBFSXFBSXRSXLSXSFigure 7: Number of sentences parsed as more edges are ex-panded.
Sentences are Penn treebank sentences of length 18?26parsed with the treebank grammar.
A typical number of edgesin an exhaustive parse is 150,000.
Even relatively simple A*estimates allow substantial savings.dropping the portion which precedes the dot.
Figure 6shows the overall savings for several estimates of eachtype.
The I-tries were superior for the coarser estimates,while O-tries were superior for the finer estimates.
Inaddition, only O-tries permit the accelerated version ofF, since they explicitly declare their right requirements.Additionally, with I-tries, only the top-level intermedi-ate rules have probability less than 1, while for O-tries,one can back-weight probability as in (Mohri, 1997), alsoshown in figure 5, enabling sub-parts of rare rules to bepenalized even before they are completed.8 For all sub-sequent results, we discuss only the O-trie numbers.Figure 8 lists the overall savings for each context sum-mary estimate, with and without F joined in.
We see thatthe NULL estimate (i.e., uniform cost search) is not veryeffective ?
alone it only blocks 11% of the edges.
But itis still better than exhaustive parsing: with it, one stopsparsing when the best parse is found, while in exhaustiveparsing one continues until no edges remain.
Even thesimplest non-trivial estimate, S, blocks 40% of the edges,and the best estimate BF blocks over 97% of the edges, aspeed-up of over 35 times, without sacrificing optimalityor algorithmic complexity.For comparison to previous FOM work, figure 7shows, for an edge count and an estimate, the propor-tion of sentences for which a first parse was found us-ing at most that many edges.
To situate our results, theFOMs used by (Caraballo and Charniak, 1998) require10K edges to parse 96% of these sentences, while BF re-quires only 6K edges.
On the other hand, the more com-plex, tuned FOM in (Charniak et al, 1998) is able to parseall of these sentences using around 2K edges, while BFrequires 7K edges.
Our estimates do not reduce the to-tal edge count quite as much as the best FOMs can, butthey are in the same range.
This is as much as one couldpossibly expect, since, crucially, our first parses are al-8However, context summary estimates which include thestate compensate for this automatically.Estimate Savings w/ Filter Storage PrecompNULL 11.2 58.3 0K noneS 40.5 77.8 2.5K 1 minSX 80.3 95.3 5M 1 minSXL 83.5 96.1 250M 30 minS1XLR 93.5 96.5 500M 480 minSXR 93.8 96.9 250M 30 minSXMLR 94.3 97.1 500M 60 minB 94.6 97.3 1G 540 minFigure 8: The trade-off between online savings and precompu-tation time.ways optimal, while the FOM parses need not be (andindeed sometimes are not).9 Also, our parser never needsto propagate score changes upwards, and so may be ex-pected to do less work overall per edge, all else beingequal.
This savings is substantial, even if no propaga-tion is done, because no data structure needs to be cre-ated to track the edges which are supported by each givenedge (for us, this represents a factor of approximately2 in memory savings).
Moreover, the context summaryestimates require only a single table lookup per edge,while the accelerated version of F requires only a rapidquadratic scan of the input per sentence (less than 1% ofparse time per sentence), followed by a table lookup peredge.
The complex FOMs in (Charniak et al, 1998) re-quire somewhat more online computation to assemble.It is interesting that SXR is so much more effective thanSXL; this is primarily because of the way that the ruleshave been encoded.
If we factor the rules in the otherdirection, we get the opposite effect.
Also, when com-bined with F, the difference in their performance dropsfrom 10.3% to 0.8%; F is a right-filter and is partiallyredundant when added to SXR, but is orthogonal to SXL.3.4 Estimate SharpnessA disadvantage of admissibility for the context summaryestimates is that, necessarily, they are overly optimisticas to the contents of the outside context.
The larger theoutside context, the farther the gap between the true costand the estimate.
Figure 9 shows average outside esti-mates for Viterbi edges as span size increases.
For smalloutside spans, all estimates are fairly good approxima-tions of TRUE.
As the span increases, the approximationsfall behind.
Beyond the smallest outside spans, all of thecurves are approximately linear, but the actual value?sslope is roughly twice that of the estimates.
The gapbetween our empirical methods and the true cost growsfairly steadily, but the differences between the empiricalmethods themselves stay relatively constant.
This reflects9In fact, the bias from the FOM commonly raises the bracketaccuracy slightly over the Viterbi parses, but that difference nev-ertheless demonstrates that the first parses are not always theViterbi ones.
In our experiments, non-optimal pruning some-times bought slight per-node accuracy gains at the cost of aslight drop in exact match.-40-35-30-25-20-15-10-502 4 6 8 10 12 14 16 18OutsideSpanAverageA*EstimateSSXSXRBTRUEFigure 9: The average estimate by outside span length for var-ious methods.
For large outside spans, the estimates differ byrelatively constant amounts.the nature of these estimates: they have differing local in-formation in their summaries, but all are equally ignorantabout the more distant context elements.
The various lo-cal environments can be more or less costly to integrateinto a parse, but, within a few words, the local restric-tions have been incorporated one way or another, and theestimates are all free to be equally optimistic about theremainder of the context.
The cost to ?package up?
thelocal restrictions creates their constant differences, andthe shared ignorance about the wider context causes theirsame-slope linear drop-off.
This suggests that it wouldbe interesting to explore other, more global, notions ofcontext.
We do not claim that our context estimates arethe best possible ?
one could hope to find features of thecontext, such as number of verbs to the right or numberof unusual tags in the context, which would partition thecontexts more effectively than adjacent tags, especially asthe outside context grows in size.3.5 Estimate ComputationThe amount of work required to (pre)calculate contextsummary estimates depends on how easy it is to effi-ciently take the max over all parses compatible with eachcontext summary.
The benefit provided by an estimatewill depend on how well the restrictions in that summarynail down the important features of the full context.Figure 10 shows recursive pseudocode for the SX es-timate; the others are similar.
To precalculate our A*estimates efficiently, we used a memoization approachrather than a dynamic programming approach.
This re-sulted in code comparable in efficiency, but which wassimpler to reason about, and, more importantly, allowedus to exploit sparseness when present.
For example withleft-factored trie encodings, 76% of (state, right tag) com-binations are simply impossible.
Tables which mappedarguments to returned results were used to memoize eachprocedure.
In our experiments, we forced these tables tobe filled in a precomputation step, but depending on thesituation it might be advantageous to allow them to fillas needed, with early parses proceeding slowly while theoutsideSX(state, lspan, rspan)if (lspan+rspan == 0)if state is the root then 0 else ?
?score = ?
?% could have a left siblingfor sibsize in [0,lspan-1]for (x?y state) in grammarcost = insideSX(y,sibsize)+outsideSX(x,lspan-sibsize,rspan)+logP (x?y state)score = max(score,cost)% could have a right siblingfor sibsize in [0,rspan-1]for (x?state y) in grammarcost = insideSX(y,sibsize)+outsideSX(x,lspan,rspan-sibsize)+logP (x?state y)score = max(score,cost)return score;insideSX(state, span)if (span == 0)if state is a terminal then 0 else ?
?score = ?
?% choose a split pointfor split in [1,span-1]for (state?x y) in grammarcost = insideSX(x,split)+insideSX(y,span-split)+logP (state?x y)score = max(score,cost)return score;Figure 10: Pseudocode for the SX estimate in the case wherethe grammar is in CNF.
Other estimates and more general gram-mars are similar.tables populate.With the optimal forward estimate TRUE, the actualdistance to the closest goal, we would never expand edgesother than those in best parses, but computing TRUE is ashard as parsing the sentence in the first place.
On theother hand, no precomputation is needed for NULL.
Inbetween is a trade off of space/time requirements for pre-computation and the online savings during the parsing ofnew sentences.
Figure 8 shows the average savings ver-sus the precomputation time.10 Where on this curve onechooses to be depends on many factors; 9 hours may betoo much to spend computing B, but an hour for SXMLRgives nearly the same performance, and the one minuterequired for SX is comparable to the I/O time to read thePenn treebank in our system.The grammar projection estimate F had to be recom-puted for each sentence parsed, but took less than 1% ofthe total parse time.
Although this method alone was lesseffective than SX (only 58.3% edge savings), it was ex-tremely effective in combination with the context sum-mary methods.
In practice, the combination of F and SXis easy to implement, fast to initialize, and very effective:10All times are for a Java implementation running on a 2GB700MHz Intel machine.one cuts out 95% of the work in parsing at the cost ofone minute of precomputation and 5 Mb of storage foroutside estimates for our grammar.4 Extension to Other ModelsWhile the A* estimates given here can be used to accel-erate PCFG parsing, most high-performance parsing hasutilized models over lexicalized trees.
These A* methodscan be adapted to the lexicalized case.
In Klein and Man-ning (2003), we apply a pair of grammar projection esti-mates to a lexicalized parsing model of a certain factoredform.
In that model, the score of a lexicalized tree is theproduct of the scores of two projections of that tree, oneonto unlexicalized phrase structure, and one onto phrasal-category-free word-to-word dependency structure.
Sincethis model has a projection-based form, grammar projec-tion methods are easy to apply and especially effective,giving over three orders of magnitude in edge savings.The total cost per sentence includes the time required fortwo exhaustive PCFG parses, after which the A* searchtakes only seconds, even for very long sentences.
Evenwhen a lexicalized model is not in this factored form, itstill admits factored grammar projection bounds; we arecurrently investigating this case.5 ConclusionsAn A* parser is simpler to build than a best-first parser,does less work per edge, and provides both an optimalityguarantee and a worst-case cubic time bound.
We havedescribed two general ways of constructing admissibleA* estimates for PCFG parsing and given several specificestimates.
Using these estimates, our parser is capable offinding the Viterbi parse of an average-length Penn tree-bank sentence in a few seconds, processing less than 3%of the edges which would be constructed by an exhaustiveparser.Acknowledgements.We would like to Joshua Goodman and Dan Melamedfor advice and discussion about this work.
This paperis based on work supported by the National ScienceFoundation (NSF) under Grant No.
IIS-0085896,by the Advanced Research and Development Activity(ARDA)?s Advanced Question Answering for Intelligence(AQUAINT) Program, by an NSF Graduate Fellowship tothe first author, and by an IBM Faculty Partnership Awardto the second author.ReferencesSharon A. Caraballo and Eugene Charniak.
1998.
New figuresof merit for best-first probabilistic chart parsing.
Computa-tional Linguistics, 24:275?298.Eugene Charniak, Sharon Goldwater, and Mark Johnson.
1998.Edge-based best-first chart parsing.
In Proceedings of theSixth Workshop on Very Large Corpora, pages 127?133.Morgan Kaufmann.Mahesh V. Chitrao and Ralph Grishman.
1990.
Statistical pars-ing of messages.
In Proceedings of the DARPA Speech andNatural Language Workshop, Hidden Valley, PA, pages 263?266.
Morgan Kaufmann.Michael Collins.
1999.
Head-Driven Statistical Models forNatural Language Parsing.
Ph.D. thesis, University of Penn-sylvania.Anna Corazza, Renato De Mori, Roberto Gretter, and GiorgioSatta.
1994.
Optimal probabilistic evaluation functions forsearch controlled by stochastic context-free grammars.
IEEETransactions on Pattern Analysis and Machine Intelligence,16(10):1018?1027.Vaibhava Goel and William J. Byrne.
1999.
Task dependent lossfunctions in speech recognition: A-star search over recogni-tion lattices.
In Eurospeech-99, pages 1243?1246.Joshua Goodman.
1997.
Global thresholding and multiple-passparsing.
In EMNLP 2, pages 11?25.Mark Johnson.
1998.
PCFG models of linguistic tree represen-tations.
Computational Linguistics, 24:613?632.Dan Klein and Christopher D. Manning.
2001a.
Parsing and hy-pergraphs.
In Proceedings of the 7th International Workshopon Parsing Technologies (IWPT-2001).Dan Klein and Christopher D. Manning.
2001b.
Parsing withtreebank grammars: Empirical bounds, theoretical models,and the structure of the Penn treebank.
In ACL 39/EACL 10,pages 330?337.Dan Klein and Christopher D. Manning.
2002.
A* parsing:Fast exact Viterbi parse selection.
Technical Report dbpubs/2002-16, Stanford University, Stanford, CA.Dan Klein and Christopher D. Manning.
2003.
Fast exact in-ference with a factored model for natural language parsing.In Advances in Neural Information Processing Systems, vol-ume 15.
MIT Press.Rene?
Leermakers.
1992.
A recursive ascent Earley parser.
In-formation Processing Letters, 41:87?91.Mehryar Mohri.
1997.
Finite-state transducers in language andspeech processing.
Computational Linguistics, 23(4):269?311.Adwait Ratnaparkhi.
1999.
Learning to parse natural languagewith maximum entropy models.
Machine Learning, 34:151?175.Brian Roark.
2001.
Probabilistic top-down parsing and lan-guage modeling.
Computational Linguistics, 27:249?276.Stuart J. Russell and Peter Norvig.
1995.
Artificial Intelligence:A Modern Approach.
Prentice Hall, Englewood Cliffs, NJ.
