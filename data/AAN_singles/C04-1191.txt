Inferring parts of speech for lexical mappings via the Cyc KBTom O?Hara?, Stefano Bertolo, Michael Witbrock, Bj?rn Aldag,Jon Curtis, with Kathy Panton, Dave Schneider, and Nancy Salay?Computer Science DepartmentNew Mexico State UniversityLas Cruces, NM 88001tomohara@cs.nmsu.eduCycorp, Inc.Austin, TX 78731{bertolo,witbrock,aldag}@cyc.com{jonc,panton,daves,nancy}@cyc.comAbstractWe present an automatic approach to learn-ing criteria for classifying the parts-of-speechused in lexical mappings.
This will fur-ther automate our knowledge acquisition sys-tem for non-technical users.
The criteria forthe speech parts are based on the types ofthe denoted terms along with morphologicaland corpus-based clues.
Associations amongthese and the parts-of-speech are learned us-ing the lexical mappings contained in the Cycknowledge base as training data.
With over30 speech parts to choose from, the classifierachieves good results (77.8% correct).
Ac-curate results (93.0%) are achieved in thespecial case of the mass-count distinction fornouns.
Comparable results are also obtainedusing OpenCyc (73.1% general and 88.4%mass-count).1 IntroductionIn semantic lexicons, the term lexical mapping de-scribes the relation between a concept and a phraseused to refer to it (Onyshkevych and Nirenburg,1995; Burns and Davis, 1999).
Lexical mappingsinclude associated syntactic information, in partic-ular, part of speech information for phrase head-words.
The term lexicalize will refer to the processof producing these mappings, which are referredto as lexicalizations.
Selecting the part of speechfor the lexical mapping is required so that properinflectional variations can be recognized and gen-erated for the term.
Although producing lexi-calizations is often a straightforward task, thereare many cases that can pose problems, especiallywhen fine-grained speech part categories are used.For example, the headword ?painting?
is a verbin the phrase ?painting for money?
but a nounin the phrase ?painting for sale.?
In cases likethis, semantic or pragmatic criteria, as opposedto syntactic criteria only, are necessary for deter-mining the proper part of speech.
The headwordpart of speech is important for correctly identifyingphrasal variations.
For instance, the first term canalso occur in the same sense in ?paint for money.
?However, this does not hold for the second case,since ?paint for sale?
has an entirely different sense(i.e., a substance rather than an artifact).When lexical mappings are produced by naiveusers, such as in DARPA?s Rapid Knowledge For-mation (RKF) project, it is desirable that tech-nical details such as the headword part of speechbe inferred for the user.
Otherwise, often complexand time-consuming clarification dialogs might benecessary in order to rule out various possibilities.For example, Cycorp?s Dictionary Assistant wasdeveloped for RKF in order to allow non-technicalusers to specify lexical mappings from terms intothe Cyc knowledge base (KB).
Currently, when anew type of activity is described, the user is askeda series of questions about the ways of referring tothe activity.
If the user enters the phrase ?paintingfor money,?
the system asks whether the phrases?paint for money?
and ?painted for money?
aresuitable variations in order to determine whether?painting?
should be treated as a verb.
Users findsuch clarification dialogs distracting, since they aremore interested in entering domain rather than lin-guistic knowledge.
Regardless, it is often very diffi-cult to produce prompts that make the distinctionintelligible to a linguistically naive user.A special case of the lexicalization speech partclassification is the handling of the mass-count dis-tinction.
Having the ability to determine if a con-cept takes a mass or count noun is useful not onlyfor parsing, but also for generation of grammat-ical English.
For example, automatically gener-Collection: PhysicalDeviceMicrotheory: ArtifactGVocabularyMtisa: ExistingObjectTypegenls: Artifact ComplexPhysicalObjectSolidTangibleProductMicrotheory: ProductGMtisa: ProductTypeFigure 1: Type definition for PhysicalDevice.ated web pages (e.g., based on search terms) oc-casionally produce ungrammatical term variationsbecause this distinction is not addressed properly.Although learner dictionaries provide informa-tion on the mass-count distinction, they are notsuitable for this task because different senses of aword are often conflated in the definitions for thesake of simplicity.
In cases like this, the word orsense might be annotated as being both count andmass, perhaps with examples illustrating the dif-ferent usages.
This is the case for ?chicken?
fromthe Cambridge International Dictionary of English(Procter, 1995), defined as follows:a type of bird kept on a farm for its eggs orits meat, or the meat of this bird which iscooked and eatenThis work describes an approach for automati-cally inferring the parts of speech for lexical map-pings, using the existing lexical assertions in theCyc KB.
We are specifically concerned with select-ing parts of speech for entries in a semantic lexi-con, not about determining parts of speech in con-text.
After an overview of the Cyc KB in the nextsection, Section 3 discusses the approach taken toinferring the part of speech for lexicalizations.
Sec-tion 4 then covers the classification results.
This isfollowed by a comparison to related work in Section5.2 Cyc knowledge baseIn development since 1984, the Cyc knowledge base(Lenat, 1995) is the world?s largest formalized rep-resentation of commonsense knowledge, contain-ing over 120,000 concepts and more than a mil-lion axioms.1 Cyc?s upper ontology describesthe most general and fundamental of distinctions(e.g., tangibility versus intangibility).
The lowerontology contains facts useful for particular appli-cations, such as web searching, but not necessar-ily required for commonsense reasoning (e.g., that1These figures and the results discussed later arebased on Cyc KB version 576 and OpenCyc KB version567.?Dubya?
refers to President GeorgeW.Bush).
TheKB also includes a broad-coverage English lexiconmapping words and phrases to terms throughoutthe KB.
A subset of the Cyc KB including parts ofthe English lexicon has been made freely availableas part of OpenCyc (www.opencyc.org).2.1 OntologyCentral to the Cyc ontology is the concept collec-tion, which corresponds to the familiar notion ofa set, but with membership intensionally defined(so distinct collections can have identical members,which is impossible for sets).
Every object in theCyc ontology is a member (or instance, in Cycparlance) of one or more collections.
Collectionmembership is expressed using the predicate (i.e.,relation-type) isa, whereas collection subsumptionis expressed using the transitive predicate genls(i.e., generalization).
These predicates correspondto the set-theoretic notions element of and subsetof respectively and thus are used to form a partiallyordered hierarchy of concepts.
For the purposes ofthis discussion, the isa and genls assertions on aCyc term constitute its type definition.Figure 1 shows the type definition for Physi-calDevice, a prototypical denotatum term for countnouns.
The type definition of PhysicalDevice indi-cates that it is a collection that is a specializationof Artifact, etc.
As is typical for terms referred toby count nouns, it is an instance of the collectionExistingObjectType.Figure 2 shows the type definition for Water, aprototypical denotation for mass nouns.
Althoughthe asserted type information for Water does notconvey any properties that would suggest a massnoun lexicalization, the genls hierarchy of collec-tions does.
In particular, the collection Chemical-CompoundTypeByChemicalSpecies is known to bea specialization of the collection ExistingStuffType,via the transitive properties of genls.
Thus, byvirtue of being an instance of ChemicalCompound-TypeByChemicalSpecies, Water is known to be aninstance of ExistingStuffType.
This illustrates thatthe decision procedure for the lexical mappingspeech parts needs to consider not only asserted,but also inherited collection membership.2.2 English lexiconNatural language lexicons are integrated directlyinto the Cyc KB (Burns and Davis, 1999).
Thoughseveral lexicons are included in the KB, the Englishlexicon is the only one with general coverage.
Themapping from nouns to concepts is done using oneof two general strategies, depending on whether theCollection: WaterMicrotheory: UniversalVocabularyMtisa: ChemicalCompoundTypeByChemicalSpeciesMicrotheory: UniversalVocabularyMtgenls: IndividualMicrotheory: NaivePhysicsVocabularyMtgenls: OxideFigure 2: Type definition for Water.mapping is from a name or a common noun phrase.Several different binary predicates indicate name-to-term mappings, with the name represented as astring.
For example,(nameString HEBCompany ?HEB?
)A denotational assertion maps a phrase into aconcept, usually a collection.
The phrase is spec-ified via a lexical word unit (i.e., lexeme concept)with optional string modifiers.
The part of speechis specified via one of Cyc?s SpeechPart constants.Syntactic information, such as the wordform vari-ants and their speech parts, is stored with the Cycconstant for the word unit.
For example, Device-TheWord, the Cyc constant for the word ?device,?has a single syntactic mapping since the pluralform is inferable:Constant: Device-TheWordMicrotheory: GeneralEnglishMtisa: EnglishWordposForms: CountNounsingular: ?device?The simplest type of denotational mapping asso-ciates a particular sense of a word with a conceptvia the denotation predicate.
For example,(denotation Device-Word CountNoun 0PhysicalDevice)This indicates that sense 0 of the count noun ?de-vice?
refers to PhysicalDevice via the associatedwordforms ?device?
and ?devices.
?To account for phrasal mappings, three addi-tional predicates are used, depending on the lo-cation of the headword in the phrase.
Theseare compoundString, headMedialString, and mul-tiWordString for phrases with the headword at thebeginning, the middle, and the end, respectively.For example,(compoundString Buy-TheWord (?down?
)Verb BuyDown)UsagePredicate OpenCyc CycmultiWordString 1123 24606denotation 2080 16725compoundString 318 2226headMedialString 200 942total 3721 44499Table 1: Denotational predicate usage in CycEnglish lexicon.
This excludes slang and jargon.UsageSpeechPart OpenCyc CycCountNoun 2041 21820MassNoun 566 9993Adjective 262 6460Verb 659 2860AgentiveNoun 81 1389ProperCountNoun 16 906Adverb 50 310ProperMassNoun 1 286GerundiveNoun 7 275other 39 185total 3721 44499Table 2: Most common speech parts in deno-tational assertions.
The other entry covers 20infrequently used cases.This states that ?buy down?
refers to BuyDown,as do ?buys down,?
?buying down,?
and ?boughtdown?
based on the inflections of the verb ?buy.
?Table 1 shows the frequency of the various pred-icates used in the denotational assertions, exclud-ing lexicalizations that involve technical, informalor slang terms.
Table 2 shows the most frequentspeech parts from these assertions.
This showsthat nearly 50% of the cases use CountNoun forthe headword speech part and that about 25% useMassNoun.
This subset of the denotational asser-tions forms the basis of the training data used inthe mass versus count noun classifier, as discussedlater.
Twenty other speech parts used in the lexi-con are not shown.
Several of these are quite spe-cialized (e.g., QuantifyingIndexical) and not verycommon, mainly occurring in fixed phrases.
Thefull speech part classifier handles all categories.3 Inference of default part ofspeechOur method of inferring the part of speech for lexi-calizations is to apply machine learning techniquesover the lexical mappings from English words orphrases to Cyc terms.
For each target denota-tum term, the corresponding types and general-izations are extracted from the ontology.
This in-cludes terms for which the denotatum term is aninstance or specialization, either explicitly assertedor inferable via transitivity.
For simplicity, theseare referred to as ancestor terms.
The associa-tion between the lexicalization parts of speech andthe common ancestor terms forms the basis for themain criteria used in the lexicalization speech partclassifier and the special case for the mass-countclassifier.
In addition, this is augmented with fea-tures indicating whether known suffixes occur inthe headword as well as with corpus statistics.3.1 Cyc ancestor term featuresThere are several possibilities in mapping the Cycancestor terms into a feature vector for use inmachine learning algorithms.
The most directmethod is to have a binary feature for each pos-sible ancestor term, but this would require aboutten thousand features.
To prune the list of poten-tial features, frequency considerations can be ap-plied, such as taking the most frequent terms thatoccur in type definition assertions.
Alternatively,the training data can be analyzed to see which ref-erence terms are most correlated with the classifi-cations.For simplicity, the frequency approach is usedhere.
The most-frequent 1024 atomic terms are se-lected, excluding terms used for bookkeeping pur-poses (e.g., PublicConstant, which mark terms forpublic releases of the KB); half of these terms aretaken from the isa assertions, and the other halffrom the genls assertions.
These are referred toas the reference terms.
For instance, ObjectTypeis a type for 21,108 of the denotation terms (outof 44,449 cases), compared to 20,283 for StuffType.These occur at ranks 13 and 14, so they are bothincluded.
In contrast, SeparationEvent occurs only185 times as a generalization term at rank 522, soit is pruned.
See (O?Hara et al, 2003) for moredetails on extracting the reference term features.3.2 Morphology and corpus-basedfeaturesIn English, the suffix for a word can provide a goodclue as to the speech part of a word.
For exam-ple, agentive nouns commonly end in ?-or?
or ?-er.
?Features to account for this are derived by seeingwhether the headword ends in one of a predefinedset of suffixes and adding the suffix as a value toan enumerated feature variable corresponding tosuffixes of the given length.
Currently, the suffixesFeature Search Patternsingular ?singular?plural ?plural?count ?many ?plural??
or ?several ?plural?
?mass ?much ?singular??
or ?several ?singular?
?verb ?must ?head??
or ?could ?head?
?adverb ?did ?head??
or ?do ?head??
or?does ?head??
or ?so ?head??
or?has ?head?
been?
or ?have ?head?
been?adjective ?more ?head??
or ?most ?head??
or?very ?head?
?Figure 3: Corpus pattern templates for part-of-speech clues.
The placeholders refer to word-forms derived from the headword: ?plural?
and?singular?
are derived via morphology; ?head?
usesthe headword as is.used are the most-common two to four letter se-quences found in the headwords.Often the choice of speech parts for lexicaliza-tions reflects idiosyncratic usages rather than justunderlying semantics.
To account for this, a set offeatures is included that is based on the relativefrequency that the denotational headword occursin contexts that are indicative of each of the mainspeech parts: singular, plural, count, mass, verbal,adjectival, and adverbial.
See Figure 3.
These pat-terns were determined by analyzing part-of-speechtagged text and seeing which function words co-occur predominantly in the immediate context forwords of the given grammatical category.
Notethat high frequency function words such as ?to?were not considered because they are usually notindexed for information retrieval.These features are derived as follows.
Givena lexical assertion (e.g., (denotation Hound-TheWord CountNoun 0 Dog)), the headword isextracted and then the plural or singular variantwordform is derived for use in the pattern tem-plates.
Corpus checks are done for each, producinga vector of frequency counts (e.g., ?29, 17, 0, 0, 0,0, 0?).
These counts are then normalized and thenused as numeric features for the machine learningalgorithm.
Table 3 shows the results for the houndexample and with a few other cases.3.3 Sample criteriaWe use decision trees for this classification.
Partof the motivation is that the result is readily in-terpretable and can be incorporated directly byknowledge-based applications.
Decision trees areinduced in a process that recursively splits thetraining examples based on the feature that parti-Head Sing Plural Count Mass Verb Adv Adjhound .630 .370 0 0 0 0 0book .613 .371 .011 .001 0 .002 .001wood .577 .418 0 .004 0 .001 .001leave .753 .215 0 0 .024 .008 0fast .924 .003 0 .003 .001 .043 .027stormy .981 0 0 0 0 0 .019Table 3: Sample relative frequency valuesfrom corpus checks.if (genls Event) and(genls not ?
{ConsumingFoodOrDrink,SeasonOfYear, QualitativeTimeOfDay,SocialGathering, PrecipitationProcess,SimpleRepairing, ConflictEvent,SomethingAppearingSomewhere}) and(isa not PhysiologicalConditionType) and(f-Plural ?
0.245) thenif (Suffix ?
{ine, een} then Verbif (Suffix ?
{ile, ent} then CountNounif (Suffix = ing) then MassNounif (Suffix = ion) thenif (f-Mass > 0.026) then MassNounelse Verbif (Suffix = ite) then CountNounif (Suffix ?
{ide, ure, ous} then Verbif (Suffix = ive) and(genls Perceiving) then MassNounelse CountNounif (Suffix = ate) thenif (not genls InformationStore) and(f-Count ?
0.048) and(f-Adverb ?
0.05) thenif (gens Translocation) then MassNounelse CountNounFigure 4: Sample rule from the generalspeech part classifier.tions the current set of examples to maximize theinformation gain (Witten and Frank, 1999).
This iscommonly done by selecting the feature that min-imizes the entropy of the distribution (i.e., yieldsleast uniform distribution).
A fragment of the de-cision tree is shown to give an idea of the criteriabeing considered in the speech part classification.See Figure 4.
In this example, the semantic typesmostly provide exceptions to associations inferredfrom the suffixes, with corpus clues used occasion-ally for differentiation.4 Evaluation and resultsTo test out the performance of the speech part clas-sification, 10-fold cross validation is applied to eachconfiguration that was considered.
Except as notedbelow, all the results are produced using Weka?sJ4.8 classifier (Witten and Frank, 1999), whichis an implementation of Quillian?s C4.5 (Quinlan,1993) decision tree learner.
Other classifiers wereconsidered as well (e.g., Naive Bayes and nearestneighbor), but J4.8 generally gave the best overallresults.4.1 Results for mass-count distinctionTable 4 shows the results for the special case mass-count classification.
This shows that the systemachieves an accuracy of 93.0%, an improvementof 24.4 percentage points over the standard base-line of always selecting the most frequent case (i.e.,count noun).
Other baselines are included for com-parison purposes.
For example, using the head-word as the sole feature (just-headwords) performsfairly well compared to the system based on Cyc;but, this classifier would lack generalizability, re-lying simply upon table lookup.
(In this case, thedecision tree induction process ran into memoryconstraints, so a Naive Bayes classifier was usedinstead.)
In addition, a system only based onthe suffixes (just-suffixes) performs marginally bet-ter than always selecting the most common case.Thus, morphology alone would not be adequate forthis task.
The OpenCyc version of the classifieralso performs well.
This illustrates that sufficientdata is already available in OpenCyc to allow forgood approximations for such classifications.
Notethat for the mass-count experiments and for theexperiments discussed later, the combined systemover full Cyc leads to statistically significant im-provements compared to the other cases.4.2 Results for general speech partclassificationRunning the same classifier setup over all speechparts produces the results shown in Table 5.
Theoverall result is not as high, but there is a similarimprovement over the baselines.
Relying solely onsuffixes or on corpus checks performs slightly bet-ter than the baseline.
Using headwords performswell, but again that amounts to table lookup.
Interms of absolute accuracy it might seem that thesystem based on OpenCyc is doing nearly as wellas the system based on full Cyc.
This is somewhatmisleading, since the distribution of parts of speechis simpler in OpenCyc, as shown by the lower en-tropy value (Jurafsky and Martin, 2000).5 Related workThere has not been much work in the automatic de-termination of the preferred lexicalization part ofspeech, outside of work related to part-of-speechtagging (Brill, 1995), which concentrates on theDataset CharacteristicsOpenCyc CycInstances 2607 30676Classes 2 2Entropy 0.76 0.90Accuracy FiguresOpenCyc CycBaseline 78.3 68.6Just-headwords 87.5 89.3Just-suffixes 78.3 71.9Just-corpus 78.2 68.6Just-terms 87.4 90.5Combination 88.4 93.0Table 4: Mass-count classification over Cyclexical mappings.
Instances is size of the train-ing data.
Classes is the number of choices.
En-tropy characterizes distribution uniformity.
Base-line uses more frequent case.
The just-X en-tries incorporate a single type: headwords fromlexical mapping, suffixes of headword, corpus co-occurrence of part-of-speech indicators; and Cycreference terms.
Combination uses all features ex-cept for the headwords.
For Cyc, it yields a statis-tically significant improvement over the others atp < .01 using a paired t-test.Dataset CharacteristicsOpenCyc CycInstances 3721 44499Classes 16 34Entropy 1.95 2.11Accuracy FiguresOpenCyc CycBaseline 54.9 48.6Just-headwords 61.6 73.8Just-suffixes 55.6 53.0Just-corpus 63.1 49.0Just-terms 68.2 71.3Combination 73.1 77.8Table 5: Full speech part classification overCyc lexical mappings.
All speech parts in Cycare used.
See Table 4 for legend.sequences of speech tags rather than the defaulttags.
Brill uses an error-driven transformation-based learning approach that learns lists for trans-forming the initial tags assigned to the sentence.Unknown words are handled basically via rulesthat change the default assignment to anotherbased on the suffixes of the unknown word.
Ped-ersen and Chen (1995) discuss an approach toinferring the grammatical categories of unknownwords using constraint solving over the propertiesof the known words.
Toole (2000) applies decisiontrees to a similar problem, distinguishing commonnouns, pronouns, and various types of names, usinga framework analogous to that commonly appliedin named-entity recognition.In work closer to ours, Woods (2000) describesan approach to this problem using manually con-structed rules incorporating syntactic, morpholog-ical, and semantic tests (via an ontology).
Forexample, patterns targeting specific stems are ap-plied provided that the root meets certain semanticconstraints.
There has been clustering-based workin part-of-speech induction, but these tend to tar-get idiosyncratic classes, such as capitalized wordsand words ending in ?-ed?
(Clark, 2003).The special case of classifying the mass-countdistinction has received some attention.
Bond andVatikiotis-Bateson (2002) infer five types of count-ability distinctions using NT&T?s Japanese to En-glish transfer dictionary, including the categoriesstrongly countable, weakly countable, and pluralonly.
The countability assigned to a particularsemantic category is based on the most commoncase associated with the English words mappinginto the category.
Our earlier work (O?Hara et al,2003) just used semantic features as well but ac-counted for inheritance of types, achieving 89.5%with a baseline of 68.2%.
Schwartz (2002) uses thefive NT&T countability distinctions when taggingword occurrences in a corpus (i.e., word tokens),based primarily on clues provided by determiners.Results are given in terms of agreement rather thanaccuracy; compared to NT&T?s dictionary there isabout 90% agreement for the fully or strong count-able types and about 40% agreement for the weaklycountable or uncountable types, with half of thetokens left untagged for countability.
Baldwin andBond (2003) apply sophisticated preprocessing toderive a variety of countability clues, such as gram-matical number of modifiers, co-occurrence of spe-cific types of determiners and pronouns, and spe-cific types of prepositions.
They achieve 94.6% ac-curacy using four categories of countability, includ-ing two categories for types of plural-only nouns.Since multiple assignments are allowed, negativeagreement is considered as well as positive.
Whenrestricted to just count versus mass nouns, the ac-curacy is 89.9% (personal communication).
Notethat, as with Schwartz, the task is different fromours and that of Bond and Vatikiotis-Bateson: weassign countability to word/concept pairs insteadof just to words.6 Conclusion and future workThis paper shows that an accurate decision pro-cedure (93.0%) accounting for the mass-count dis-tinction can be induced from the lexical mappingsin the Cyc KB.
The full speech part classifier pro-duces promising results (77.8%), considering thatit is a much harder task, with over 30 categories tochoose from.
The features incorporate semantic in-formation, in particular Cyc?s ontological types, inaddition to syntactic information (e.g., headwordmorphology).Future work will investigate how the classifierscan be generalized for classifying word usages incontext, rather than isolated words.
This couldcomplement existing part-of-speech taggers by al-lowing for more detailed tag types, such as forcount and agentive nouns.A separate area for future work will be to ap-ply the techniques to other languages.
For exam-ple, minimal changes to the classifier setup wouldbe required to handle Romance languages, suchas Italian.
The version of the classifier that justuses Cyc reference terms could be applied as is,given lexical mappings for the language.
For thecombined-feature classifier, we would just need tochange the list of suffixes and the part-of-speechpattern templates (from Figure 3).AcknowledgementsThe lexicon work at Cycorp has been supported in partby grants from NIST, DARPA (e.g., RKF), and ARDA(e.g., AQUAINT).
At NMSU, the work was facilitatedby a GAANN fellowship from the Department of Edu-cation and utilized computing resources made possiblethrough MII Grants EIA-9810732 and EIA-0220590.ReferencesTimothy Baldwin and Francis Bond.
2003.
Learn-ing the countability of English nouns from cor-pus data.
In Proc.
ACL-03.Francis Bond and Caitlin Vatikiotis-Bateson.2002.
Using an ontology to determine Englishcountability.
In Proc.
COLING-2002, pages 99?105.
Taipei.Eric Brill.
1995.
Transformation-based error-driven learning and natural language processing:A case study in part of speech tagging.
Compu-tational Linguistics, 21(4):543?565.Kathy J. Burns and Anthony B. Davis.
1999.Building and maintaining a semantically ade-quate lexicon using Cyc.
In Evelyn Viegas, ed-itor, Breadth and Depth of Semantic Lexicons,pages 121?143.
Kluwer, Dordrecht.Alexander Clark.
2003.
Combining distributionaland morphological information for part of speechinduction.
In Proceedings of EACL 2003.Daniel Jurafsky and James H. Martin.
2000.Speech and Language Processing.
Prentice Hall,Upper Saddle River, New Jersey.D.
B. Lenat.
1995.
Cyc: A large-scale investmentin knowledge infrastructure.
Communications ofthe ACM, 38(11).Tom O?Hara, Nancy Salay, Michael Witbrock,Dave Schneider, Bjoern Aldag, Stefano Bertolo,Kathy Panton, Fritz Lehmann, Matt Smith,David Baxter, Jon Curtis, and Peter Wagner.2003.
Inducing criteria for mass noun lexicalmappings using the Cyc KB, and its extensionto WordNet.
In Proc.
Fifth International Work-shop on Computational Semantics (IWCS-5).B.
Onyshkevych and S. Nirenburg.
1995.
A lexiconfor knowledge-based MT.
Machine Translation,10(2):5?57.Ted Pedersen and Weidong Chen.
1995.
Lexi-cal acquisition via constraint solving.
In Proc.AAAI 1995 Spring Symposium Series.Paul Procter, editor.
1995.
Cambridge Interna-tional Dictionary of English.
Cambridge Uni-versity Press, Cambridge.J.
Ross Quinlan.
1993.
C4.5: Programs for Ma-chine Learning.
Morgan Kaufmann, San Mateo,California.Lane O.B.
Schwartz.
2002.
Corpus-based acquisi-tion of head noun countability features.
Master?sthesis, Cambridge University, Cambridge, UK.Janine Toole.
2000.
Categorizing unknown words:Using decision trees to identify names and mis-spellings.
In Proc.
ANLP-2000.Ian H. Witten and Eibe Frank.
1999.
DataMining: Practical Machine Learning Tools andTechniques with Java Implementations.
MorganKaufmann, San Francisco, CA.W.
Woods.
2000.
Aggressive morphology for ro-bust lexical coverage.
In Proc.
ANLP-00.
