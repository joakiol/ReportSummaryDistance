Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 909?919,Edinburgh, Scotland, UK, July 27?31, 2011. c?2011 Association for Computational LinguisticsCache-based Document-level Statistical Machine TranslationZhengxian Gong1 Min Zhang2 Guodong Zhou1*1 School of Computer Science and TechnologySoochow University, Suzhou, China 2150062 Institute for Infocomm Research, Singapore 138632{zhxgong, gdzhou}@suda.edu.cn mzhang@i2r.a-star.edu.sgAbstractStatistical machine translation systems areusually trained on a large amount of bilingualsentence pairs and translate one sentence at atime, ignoring document-level information.
Inthis paper, we propose a cache-based approachto document-level translation.
Since cachesmainly depend on relevant data to supervisesubsequent decisions, it is critical to fill thecaches with highly-relevant data of a reasonablesize.
In this paper, we present three kinds ofcaches to store relevant document-level infor-mation: 1) a dynamic cache, which stores bilin-gual phrase pairs from the best translationhypotheses of previous sentences in the testdocument; 2) a static cache, which stores rele-vant bilingual phrase pairs extracted from simi-lar bilingual document pairs (i.e.
sourcedocuments similar to the test document andtheir corresponding target documents) in thetraining parallel corpus; 3) a topic cache, whichstores the target-side topic words related withthe test document in the source-side.
In particu-lar, three new features are designed to explorevarious kinds of document-level information inabove three kinds of caches.
Evaluation showsthe effectiveness of our cache-based approachto document-level translation with the perfor-mance improvement of 0.81 in BLUE scoreover Moses.
Especially, detailed analysis anddiscussion are presented to give new insights todocument-level translation.1 IntroductionDuring last decade, tremendous work has beendone to improve the quality of statistical machine__________________* Corresponding author.translation (SMT) systems.
However, there is stilla huge performance gap between the state-of-the-art SMT systems and human translators.
Bond(2002) suggested nine ways to improve machinetranslation by imitating the best practices of humantranslators (Nida, 1964), with parsing the entiredocument before translation as the first priority.However, most SMT systems still treat parallelcorpora as a list of independent sentence-pairs andignore document-level information.Document-level information can and should beused to help document-level machine translation.At least, the topic of a document can help choosespecific translation candidates, since when takenout of the context from their document, somewords, phrases and even sentences may be ratherambiguous and thus difficult to understand.
Anoth-er advantage of document-level machine transla-tion is its ability in keeping a consistent translation.However, document-level translation has drawnlittle attention from the SMT research community.The reasons are manifold.
First of all, most of pa-rallel corpora lack the annotation of documentboundaries (Tam, 2007).
Secondly, although it iseasy to incorporate a new feature into the classicallog-linear model (Och, 2003), it is difficult to cap-ture document-level information and model it viasome simple features.
Thirdly, reference transla-tions of a test document written by human transla-tors tend to have flexible expressions in order toavoid producing monotonous texts.
This makes theevaluation of document-level SMT systems ex-tremely difficult.Tiedemann (2010) showed that the repetitionand consistency are very important when modelingnatural language and translation.
He proposed toemploy cache-based language and translationmodels in a phrase-based SMT system for domain909adaptation.
Especially, the cache in the translationmodel dynamically grows up by adding bilingualphrase pairs from the best translation hypotheses ofprevious sentences.
One problem with the dynamiccache is that those initial sentences in a test docu-ment may not benefit from the dynamic cache.Another problem is that the dynamic cache may beprone to noise and cause error propagation.
Thisexplains why the dynamic cache fails to much im-prove the performance.This paper proposes a cache-based approach fordocument-level SMT using a static cache and adynamic cache.
While such a approach applies toboth phrase-based and syntax-based SMT, this pa-per focuses on phrase-based SMT.
In particular,the static cache is employed to store relevant bilin-gual phrase pairs extracted from similar bilingualdocument pairs (i.e.
source documents similar tothe test document and their target counterparts) inthe training parallel corpus while the dynamiccache is employed to store bilingual phrase pairsfrom the best translation hypotheses of previoussentences in the test document.
In this way, ourcache-based approach can provide useful data atthe beginning of the translation process via thestatic cache.
As the translation process continues,the dynamic cache grows and contributes more andmore to the translation of subsequent sentences.Our motivation to employ similar bilingual doc-ument pairs in the training parallel corpus is simple:a human translator often collects similar bilingualdocument pairs to help translation.
If there aretranslation pairs of sentences/phrases/words insimilar bilingual document pairs, this makes thetranslation much easier.
Given a test document, ourapproach imitates this procedure by first retrievingsimilar bilingual document pairs from the trainingparallel corpus, which has often been applied inIR-based adaptation of SMT systems (Zhao etal.2004; Hildebrand et al2005; Lu et al2007) andthen extracting bilingual phrase pairs from similarbilingual document pairs to store them in a staticcache.However, such a cache-based approach may in-troduce many noisy/unnecessary bilingual phrasepairs in both the static and dynamic caches.
In or-der to resolve this problem, this paper employs atopic model to weaken those noisy/unnecessarybilingual phrase pairs by recommending the de-coder to choose most likely phrase pairs accordingto the topic words extracted from the target-sidetext of similar bilingual document pairs.
Just like ahuman translator, even with a big bilingual dictio-nary, is often confused when he meets a sourcephrase which corresponds to several possible trans-lations.
In this case, some topic words can helpreduce the perplexity.
In this paper, the topic wordsare stored in a topic cache.
In some sense, it hasthe similar effect of employing an adaptive lan-guage model with the advantage of avoiding theinterpolation of a global language model with aspecific domain language model.The rest of this paper is organized as follows.Section 2 reviews the related work.
Section 3presents our cache-based approach to document-level SMT.
Section 4 presents the experimentalresults.
Session 5 gives new insights on cache-based document-level translation.
Finally, weconclude this paper in Section 6.2 Related workThere are only a few studies on document-levelSMT.
Representative work includes Zhao et al(2006), Tam et al (2007), Carpuat (2009).Zhao et al (2006) assumed that the parallel sen-tence pairs within a document pair constitute amixture of hidden topics and each word pair fol-lows a topic-specific bilingual translation model.
Itshows that the performance of word alignment canbe improved with the help of document-level in-formation, which indirectly improves the quality ofSMT.Tam et al (2007) proposed a bilingual-LSAmodel on the basis of a parallel document corpusand built a topic-based language model for eachlanguage.
By automatically building the corres-pondence between the source and target languagemodels, this method can match the topic-basedlanguage model and improve the performance ofSMT.Carpuat (2009) revisited the ?one sense per dis-course?
hypothesis of Gale et al (1992) and gave adetailed comparison and analysis of the ?one trans-lation per discourse?
hypothesis.
However, shefailed to propose an effective way to integrate doc-ument-level information into a SMT system.
Forexample, she simply recommended some transla-tion candidates to replace some target words in thepost-process stage.In principle, the cache-based approach can bewell suited for document-level translation.
Basical-910ly, the cache is analogous to ?cache memory?
inhardware terminology, which tracks short-termfluctuation (Iyer et al, 1999).
As the cachechanges with different documents, the document-level information should be capable of influencingSMT.Previous cache-based approaches mainly pointto cache-based language modeling (Kuhn and Mori,1990), which uses a large global language model tomix with a small local model estimated from recenthistory data.
However, applying such a languagemodel in SMT is very difficult due to the risk ofintroducing extra noise (Raab, 2007).For cache-based translation modeling, Nepveuet al (2004) explored user-edited translations inthe context of interactive machine translation.
Tie-demann (2010) proposed to fill the cache with bi-lingual phrase pairs from the best translationhypotheses of previous sentences in the test docu-ment.
Both Nepveu et al (2004) and Tiedemann(2010) also explored traditional cache-based lan-guage models and found that a cache-based lan-guage model often contributes much more than acache-based translation model.3 Cache-based document-level SMTGiven a test document, our system works as fol-lows:1) clears the static, topic and dynamic cacheswhen switching to a new test document dx;2) retrieves a set of most similar bilingual docu-ment pairs dds for dx from the training parallelcorpus using the cosine similarity with tf-idfweighting;3) fills the static cache with bilingual phrase pairsextracted from dds;4) fills the topic cache with topic words extractedfrom the target-side documents of dds;5) for each sentence in the test document, trans-lates it using cache-based SMT and conti-nuously expands the dynamic cache withbilingual phrase pairs obtained from the besttranslation hypothesis of the  previous sen-tences.In this way, our cache-based approach can pro-vide useful data at the beginning of the translationprocess via the static cache.
As the translationprocess continues, the dynamic cache grows andcontributes more and more to the translation ofsubsequent sentences.
Besides, the possibility ofchoosing noisy/unnecessary bilingual phrase pairsin both the static and dynamic caches is wakenedwith the help of the topic words in the topic cache.In particular, only the most similar document pairis used to construct the static cache and the topiccache unless specified.In this section, we first introduce the basicphrase-based SMT system and then present ourcache-based approach to achieve document-levelSMT with focus on constructing the caches (static,dynamic and topic) and designing their corres-ponding features.3.1 Basic phrase-based SMT systemIt is well known that the translation process ofSMT can be modeled as obtaining the best transla-tion e of the source sentence f by maximizing fol-lowing posterior probability (Brown et al, 1993):)()|(maxarg)|(maxarg ePefPfePe lmeebest ==  (1)where P(e|f) is a translation model and Plm is a lan-guage model.Our system adopted Moses (a state-of-artphrase-based SMT system) as a baseline, whichfollows Koehn et al (2003) and mainly adopts sixgroups of popular features: 1) two phrase transla-tion probabilities (two directions): Pphr(e|f) andPphr(f|e); 2) two word translation probabilities (twodirections) : Pw(e|f) and Pw(f|e); 3) one languagemodel (target language): LM(e); 4) one phrase pe-nalty (target language): PP(f); 5) one word penalty(target language):WP(e); 6) a lexicalized reorder-ing model.
Besides, the log-linear model as de-scribed in (Och and Ney, 2003) is employed tolinearly interpolate these features for obtaining thebest translation according to the formula (2):)},(max{arg1fehe mMmmbest ?== l   (2)where hm(e , f) is a feature function, and ?m is theweight of hm(e , f)  optimized by a discriminativetraining method on a held-out development data.In principle, a phrase-based SMT system canprovide the best phrase segmentation and align-ment that cover a bilingual sentence pair.
Here, asegmentation of a sentence into K phrases is de-fined as:(f~e)?
?
(f , e , ~)      (3)where tuple (f , e ) refers to a phrase pair, and ~indicates corresponding alignment information.9113.2 Dynamic CacheOur dynamic cache is mostly inspired by Tiede-mann (2010), which adopts a dynamic cache tostore relevant bilingual phrase pairs from the besttranslation hypotheses of previous sentences in thetest document.
In particular, a specific feature isincorporated S      to capture useful document-level information in the dynamic cache:?
?==-?=?>>=<<= Ki icKiiiicccccache ffIefefeIfeS11)(),,()|((4)where ie-?
is a decay factor to avoid the depen-dence of the feature?s contribution on the cachesize.
Given <ec, fc> an existing phrase pair in thedynamic cache and <ei,fi> a phrase pair in a newhypothesis, if ( ei=ec ?
fi=fc ) is true (i.e.
full match-ing), function I(.)
returns 1 , otherwise 0.One problem with the dynamic cache in Tiede-mann (2010) is that it continuously updates theweight of a phrase pair in the dynamic cache.
Thismay cause noticeable computational burden withthe increasing number of phrase pairs in the dy-namic cache.
In addition, as a source phrase (fc)may occur many times in the dynamic cache, theweights for related phrase pairs may degrade se-verely and thus his decoder needs a decay factor,which is difficult to optimize.
Finally, Tiedemann(2010) only allowed full matching.
This largelylowers down the probability of hitting the dynamiccache and thus much affects its effectiveness.To overcome above problems, we only employthe bilingual phrase pairs in the dynamic cache toinform the decoder whether one bilingual phrasepair exists in the dynamic cache or not, which isslightly similar to (Nepveu et al 2004) ,thus avoid-ing extra computational burden and the fine-tuningof the decay factor.
In particular, following newfeature is incorporated to better explore the dynam-ic cache:   = ?
dpairmatch(e , f )        (5)where dpairmatch(  ,  )    = ?????
1   (e = e ?
f = f )                       ?
e  = e ?
f  = f ??
e ?> 3    ?
e = e  ?
f = f  ??
e ?> 3 0    otherHere, F  is called the dynamic cache feature.Assume (ec,fc ) is a phrase pair in the dynamiccache and (ei,fi) is a phrase pair candidate for anew hypothesis.
Besides full matching, we intro-duce a symbol of ?^?
for sub-phrase, such as e   fora sub-phrase of ei and  e   for a sub-phrase of e  , toallow partial matching.
Finally, F  measures theoverall value of a target candidate f  by summingover the scores of K phrase pairs.Obviously, F  rewards both full matching andpartial matching.
In order to avoid too much noise,we put some constraints on the number of words inthe target phrase of <ec,fc> or <ei,fi>, such as ?
e ?> 3 , where " ?? "
measures the number ofnon-blank characters in a phrase.
For example, ifphrase pair ?, ?
?||| and reduced?
occurs in thecache, phrase pair ?,|||and?
is not rewarded becausesuch shorter phrase pairs occur frequently and maylargely degrade the effect of the cache.
In accor-dance, the dynamic cache only contains phrasepairs whose target phrases contain 4 or more non-blank characters.3.3 Static CacheIn Tiedemann (2010), initial sentences in a testdocument fail to benefit from the dynamic cachedue to the lack of contents in the dynamic cache atthe beginning of the translation process.
To over-come this problem, a static cache is included tostore relevant bilingual phrase pairs extracted fromsimilar bilingual document pairs in the trainingparallel corpus.
In particular, a static cache feature F  is designed to capture useful information in thestatic cache in the same way as the dynamic cachefeature, shown in Formula (5).For this purpose, all the document pairs in thetraining parallel corpus are aligned at the phraselevel using 2-fold cross-validation.
That is, weadopt 50% of the training parallel corpus to train amodel using Moses and apply the model to enforcephrase alignment of the remaining training data,and vice versa.
Here, the enforcement is done byguaranteeing the occurrence of the target phrasecandidate of a source phrase in the sentence pair.Besides, all the words pairs trained on the wholetraining parallel corpus are included in both foldsto ensure at least one possible translation.
Finally,the phrase pairs in the best translation hypothesisof a sentence pair is retrieved from the decoder.
Inthis way, we can extract a set of phrase pairs foreach bilingual document pairs.Given a test document, we first find a set of sim-ilar source documents by computing the Cosinesimilarity using the TF-IDF weighting scheme andtheir corresponding target documents, from thetraining parallel corpus.
Then, the phrase pairs ex-912tracted from these similar bilingual document pairsare collected into the static cache.
To avoid noise,we filter out those phrase pairs which occur lessthan two times in the training parallel corpus.??
||| exports??
||| slowdown??
||| stock market??
||| leading??
||| exchange??
||| vitality??
||| speed up the????
||| economists??
??
||| export growth??
??
||| various reasons??
??
||| a well-known international??
???
||| congressional committee?
??
?
??
||| pessimistic predictions??
??
?
??
||| maintain a certain growth??
??
??
||| a drop in the dollar exchange rateTable 1: Phrase pairs extracted from a document pairwith an economic topicSimilar to the dynamic cache, we only considerthose phrase pairs whose target phrases contain 4or more non-blank characters to avoid noise.
Wedo not deliberately remove long phrase pairs.
It ispossible to use these long phrase pairs if our testdocument is very similar to one training documentpair.
Table 1 shows some bilingual phrase pairsextracted from a document pair, which reports apiece of news about ?impact on slowdown in USeconomic growth?.
Obviously, these phrase pairsare closely related to economics.3.4 Topic CacheBoth the dynamic and static caches may still intro-duce noisy/unnecessary bilingual phrase pairs evenwith constraints on the length of phrases and theiroccurrence frequency in the training parallel cor-pus.
In order to resolve this problem, this paperadopts a topic cache to store relevant topic wordsand employs a topic cache feature to weaken thosenoisy/unnecessary phrase pairs.Given w  is a topic word in the topic cache, thetopic cache feature F  is designed as follows:   =  topicexist(e , f )          (6)where topicexist(e , f ) =   1   (w ?
e )                                    0    otherHere, the target phrase which contains a topic word w  will be rewarded.
w  is derived by a topic mod-el, LDA (Latent Dirichlet Allocation).
This is dif-ferent from the previous work (Tam, 2007), whichmainly interpolated a topic language model with ageneral language model and added additional twoadaptive lexicon probabilities in his phrase table.In principle, LDA is a probabilistic model oftext data, which provides a generative analog ofPLSA (Blei et al, 2003), and is primarily meant toreveal hidden topics in text documents.
Like mostof the text mining techniques, LDA assumes thatdocuments are made up of words and the orderingof the words within a document is unimportant (i.e.the ?bag-of-words?
assumption).Figure 1 shows the principle of LDA, where ?
isthe parameter of the uniform Dirichlet prior on theper-document topic distributions, ?
is the parame-ter of the uniform Dirichlet prior on the per-topicword distribution, ?i is the topic distribution fordocument i, zij is the topic for the jth word in doc-ument i, and wij is the specific word.
Among allvariables, wij is the only observable variable withall the other variables latent.
In particular, K de-notes the number of topics considered in the modeland ?
is a K*V (V is the dimension of the vocabu-lary) Markov matrix each line of which denotes theword distribution of a topic.
The inner plate over zand w illustrates the repeated sampling of topicsand words until N words have been generated for document d. The plate surrounding ?
illustrates thesampling of a distribution over topics for eachdocument d for a total of M documents.
The platesurrounding ?
illustrates the repeated sampling ofword distributions for each topic z until K topicshave been generated.We use a LDA tool1 to build a topic model usingthe target-side documents in the training parallelcorpus.
Using LDA, we can obtain the topic distri-bution of each word w, namely p(z|w) for topic z ?K.
Moreover, using the obtained word topic dis-tributions, we can infer the topic distribution of anew document, namely p(z|d) for each topic z ?K.Given a test document, we first find the mostsimilar source document from the training data in1 http://www.arbylon.net/projects/Figure 1: LDA913the same way as done in the static cache.
After that,we retrieve its corresponding target document.Then, the topic of the target document is deter-mined by its major topic, with the maximum p(z|d).Finally, we load some topic words correspondingto this topic z into the topic cache.
In particular,our LDA model deploy the setting of K=15, ?=0.5and ?=0.1.
Besides, only top 1000 topic words arereserved for each topic.
Table 2 shows top 10 topicwords for five topics.Topic 1 Topic 2 Topic 3 Topic4 Topic5companycorporationlimitedmanagerboardbranchcompaniesltdbusinesspersonnelarmyarmedmilitaryofficersforcesunitstroopsforcesoldierspolicepartyrepresentsstudytheoryleadershippoliticalcadresspeechcomradecentralbushunitedadminis-trationpolicypresidentclintonofficesecretarypowellrelationselectionolympicgamesvotesbidgorepresi-dentialpartywonspeechTable 2: Topic words extracted from target-side doc-uments4 ExperimentationWe have systematically evaluated our cache-basedapproach to document-level SMT on the Chinese-English translation task.4.1 Experimental SettingHere, we use SRI language modeling toolkit totrain a trigram general language model on Englishnewswire text, mostly from the Xinhua portion ofthe Gigaword corpus (2007) and performed wordalignment on the training parallel corpus usingGIZA++(Och and Ney,2000) in two directions.
Forevaluation, the NIST BLEU script (version 13)with the default setting is used to calculate theBleu score (Papineni et al 2002), which measurescase-insensitive matching of n-grams with n up to4.
To see whether an improvement is statisticallysignificant, we also conduct significance tests us-ing the paired bootstrap approach (Koehn, 2004)2.In this paper, ?
***?, ?
**?, and ?*?
denotep-values less than or equal to 0.01, in-between(0.01, 0.05), and bigger than 0.05, which meansignificantly better, moderately better and slightlybetter, respectively.2 http://www.ark.cs.cmu.edu/MTIn this paper, we use FBIS as the training data,the 2003 NIST MT evaluation test data as the de-velopment data, and the 2005 NIST MT test dataas the test data.
Table 3 shows the statistics ofthese data sets (with document boundaries anno-tated).Corpus Sentences DocumentsRole NameTrain FBIS 239413 10353Dev NIST2003 919 100Test NIST2005 1082 100Table 3: Corpus statisticsIn particular, the sizes of the static, topic anddynamic caches are fine-tuned to 2000, 1000 and5000 items, respectively.
For the dynamic cache,we only keep those most recently-visited items,while for the static cache; we always keep the mostfrequently-occurring items.4.2 Experimental ResultsTable 4 shows the contribution of various caches inour cache-based document-level SMT system.
Thecolumn of ?BLEU_W?
means the BLEU scorecomputed over the whole test set and ?BLEU_D?corresponds to the average BLEU score over sepa-rated documents.System BLEU onDev(%)BLEU on Test(%)BLEU_W NIST BLEU_DMoses 29.87 25.76 7.784 25.08Fd 29.90 26.03 (*) 7.852 25.39Fd+Fs 30.29 26.30 (**) 7.884 25.86Fd+Ft 30.11 26.24 (**) 7.871 25.74Fd+Fs+Ft 30.50 26.42 (***) 7.896 26.11Fd+Fs+Ftwith merg-ing- 26.57 (***) 7.901 26.32Table 4: Contribution of various caches in our cache-based document-level SMT system.
Note that signific-ance tests are done against Moses.Contribution of dynamical cache (Fd)Table 4 shows that the dynamic cache slightly im-proves the performance by 0.27 (*) in BLEU_W.This is similar to Tiedemann (2010).
However,detailed analysis indicates that the dynamic cachedoes have negative effect on about one third ofdocuments, largely due to the instability of the dy-namic cache at the beginning of translating a doc-ument.
Figure 2 shows the distribution of the914BLEU_D difference of 100 test documents (sortedby BLEU_D).
It shows that about 55% of testdocuments benefit from the dynamic cache.Contribution of static cache (Fs)Table 4 shows that the combination of the staticcache with the dynamic cache further improves theperformance by 0.27(*) in BLEU_W.
This sug-gests the effectiveness of the static cache in elimi-nating the instability of the dynamic cache whentranslating first few sentences of a test document.Together, the dynamic and static caches much im-prove the performance by 0.54 (**) in BLEU_Wover Moses.
Figure 3 shows the distribution of theBLEU_D difference of 100 test documents (sortedby BLEU_D), with more positive effect on thoseborderline documents, compared to Figure 2.Contribution of topic cache (Ft)Table 4 shows that the topic cache has comparableeffect on improving the performance as the staticcache when combined with the dynamic cache(0.48 vs. 0.54 in BLEU_W).
Figure 4 shows theeffectiveness of combining the dynamic and topiccaches (sorted by BLEU_D).However, detailed analysis shows that the topiccache and the static cache are quite complementaryby contributing on different test documents, largelydue to that while the static cache tends to keeptranslation consistent, the topic cache plays like adocument-specific language model.
This is justi-fied by Table 4 that the combination of the dynam-ic, static and topic caches significantly improve theperformance by 0.66 (***) in BLEU_W, and byFigure 5 that about 75% of test documents benefitfrom the combination of the three caches (sortedby BLEU_D).Contribution of merging phrase pairs of similardocument pairsHere, the number of similar documents we adopt isdifferent from previous experiments.
In the pre-vious experiments, we only cache bilingual phrasepairs extracted from the most similar document.Here, we merge phrase pairs for several most simi-lar documents (5 at most) which have the sametopic.Figure 2: Contribution of employing the dynamiccache on different test documents-8.00%-6.00%-4.00%-2.00%0.00%2.00%4.00%6.00%8.00%1 8 15 22 29 36 43 50 57 64 71 78 85 92 99fd-mosesFigure 3: Contribution of combining the dynamic andstatic cache on different test documents-6.00%-4.00%-2.00%0.00%2.00%4.00%6.00%1 8 15 22 29 36 43 50 57 64 71 78 85 92 99fd+fs-mosesFigure 4: Contribution of combining the dynamicand topic caches-6.00%-4.00%-2.00%0.00%2.00%4.00%6.00%8.00%10.00%1 7 13 19 25 31 37 43 49 55 61 67 73 79 85 91 97fd+ft-mosesFigure 5: Contribution of combining the three caches-4.00%-2.00%0.00%2.00%4.00%6.00%8.00%10.00%1 9 17 25 33 41 49 57 65 73 81 89 97fd+fs+ft-moses915Table 4 shows that employing this trick can fur-ther improve the performance by 0.15 in BLEU_W.As a result, the cache-based approach significantlyimprove the performance by 0.81 (***) inBLEU_W over Moses.5 DiscussionIn this section, we explore in more depth why thestatic cache can help the dynamic cache, someconstrained factors which impact the effectivenessof our cache-based approach.Effectiveness of the static cacheWe investigate why the static cache affects the per-formance.
Basically, it is difficult for the dynamiccache to capture such similar information in thestatic cache.In principle, the static cache can both influencethe initial and subsequent sentences; however sub-sequent ones can be affected by multiple caches.
Inorder to give an insight of the static cache, we eva-luate its effectiveness on the first sentence for eachtest document.
Figure 6 shows the contribution ofthe static cache on translating these first sentences(y-axis shows BLEU value of the first sentence foreach test document).
It notes that the most BLEUscores of them are zeros because of the length limi-tation of first sentences.Furthermore, we count the hit (matching) fre-quency of the static cache for each test documents.Since we use 1 or 0 for the static cache feature, it iseasy to retrieve its effect for each test document.Our statistics shows that the hit frequency on staticcache fluctuates between 5 and 18 for each testdocument.
Without the static cache, the hit fre-quency of the dynamic cache is 504 on whole testsets, this figure increases to 685 with the staticcache.
This means that the static cache significant-ly enlarges the effectiveness of the dynamic cacheby including more relevant phrase pairs to the dy-namic cache, largely due to the positive impact ofthe static cache on the initial sentences of each testdocument.Size of topic cacheTable 5 shows the impact of the topic cache whenthe number of the retained topic words for eachtopic increases from 500 to 2000.
It shows that toomore topic words actually harm the performance,due to the increase of noise.
1000 topic wordsseem a lot largely due to that we didn?t do stem-ming for our topic modeling since we hope to in-troduce some tense information of them in thefuture.Number of topic words BLEU_W500 26.27700 26.311000 26.421500 26.232000 26.19Table 5: Impact of the topic cache sizeInfluenced translationsIn order to explore how our cache-based systemimpacts on translation results, we manually in-spected 5 documents respectively which is im-proved or degraded in translation quality comparedto the baseline Moses output.
Those documentshave 107 sentences in sum.The good effectiveness of each kind of cachecan be observed by the example 1 and 2 showed inTable 6.
Both the example 1 and 2 come from thesame document whose ?BLEU_D?
score exceedsMoses with 8.4 point.
The example 1 benefits fromthe topic cache which contains the item of ?action?.The example 2 benefits from the static cache whichcontains a phrase pair of  ???
||| promised to?while Moses use ?commitment?
for ????
, whichmay be the reason for  missing the part of ?primeminister?
in Moses output.
Furthermore, due to thephrase pair of ???
?
?||| the ceasefire agree-ment?
existing in our static cache, our decoderkeeps using ?ceasefire?
to translate ????
in thewhole document while Moses randomly use ?cea-sefire?
or ?cease-fire?
for this translation.Figure 6: Contribution of the static cache on the firstsentence of each test document(i.e.
with empty dynamic cache)00.10.20.30.40.50.60.70.80.90 20 40 60 80 100 120Fd FdFs9161 ??
??
?
??
??
?
?
??
?
??
, ??
?
??
??
??
?Moses: official forecasts said that preparatory work will be carried out in july and then launched a political maneuver .Ours:   official forecasts said that preparatory work will be carried out in july , then began a political action .Reference: officials expected that "preparations would take place until July, after which political action will begin".2 ??
?
?
?
, ?????
?
, ???
??
??
??
?
?
?
????
??
??
??
??
, ??
?
??
?
??
, ???
?
?
??
?
????
?
?
??
??
?
?Moses: on this point , said that israeli commitment to the palestinian authorities to respect the cease-fire agreement ,where they are well under control , israel will stop its military actions against palestinians .Ours: on this point , said that israeli prime minister promised to respect the ceasefire agreement , the palestinian au-thorities to properly control their areas and israel will stop its military actions against palestinians .Reference:For this point , MENA said Israeli Prime Minister Sharon has promised to " stop Israeli military operationsagainst the Palestinians insofar as they continue to respect the ceasefire deal and control their territory .
"3 17 ?
?
??
3000 ?
?
??
?
???
?
??
??
??
?
?
???
??
?
????
?
????
?????
?
??
??
?
??
??
?
??
??
???
??
???
?
??
?
??
???
??
??
?Moses: on the evening , nearly 3,000 residents in the downtown square of the weapons held by the municipal govern-ment , watched a song and dance soiree , having colorful lighting disguise of ancient buildings around the square , sing-ing and dancing famous artists staged different regions of ethnic song and dance .Ours: later on, nearly 3,000 residents in the downtown square to watch the government of having a song and danceperformances were held under the disguise of colorful lighting around the square , a famous ancient buildings and localartists of different ethnic song and dance .Reference: On the night of the 17th , nearly 3,000 residents watched a wonderful gala of songs and dances , organizedby the municipal government , at Plaza da Armas .
Colorful lights lighted up ancient architecture around the plaza .Famous artists including singers and dancers staged performances of national songs and dances of different regions .4 ??
?
??
??
?
?
??
?
?
?
2.14 ????
??
?
2600 ?
????
?
?
??
?
???
800?
??
?
?
?
??
???
?
31% ?Moses: at lima 's urban area from the beginning of 2600 square to 2.14 million square kilometers , while the popula-tion has increased to 8 percent of the country 's total , about 31% .Ours: lima , the urban area from the beginning of 2600 square kilometers to 2.14 million square kilometers , but alsoincreased to about 8 million population , the country 's total population of about 31% .Reference: The area of Lima city has expanded to more than 2,600 square kilometers from the original 2.14 square ki-lometers when the city was founded , while the population has increased to around 8 million , roughly accounting for31% of the nation's total .Table 6: Positive and negative examplesThe example 3 and 4 also come from the samedocument however whose performance degradeswith 2.17 point.
We don?t think the translationquality for example 4 in our system is worse thanMoses.
However, the translation quality for exam-ple 3 in our system is very bad and especiallyshowed on ?re-ordering?.
We found this sentencedid not match any item in our static cache and top-ic cache.
Although this phenomenon also happensin other documents, but this is the most typicalnegative example among these documents.Document-specific characteristicsIt seems that using the same weight for the wholetest sets (all documents) is not very reasonable.Actually, if we can determine those negative doc-uments which are not suitable for the cache-basedapproach, our cache-based approach may gainmuch improvement.
Tiedemann (2010) exploredthe correlation to document length, baseline per-formance and source document repetition.
Howev-er, it seems that there are no obvious rules to filterout those negative documents.
Besides, there maybe two more document-specific factors: repetitionof the reference text and document style.Tiedemann (2010) only considered the repetitionof the test text in the source side.
Since BLEUscore is computed against the reference text, therepetition in the reference text may greatly influ-ence the performance of our cache-based approachto document-level SMT.
As for document style, itis quite possible that a document may contain sev-eral topics.
Therefore, it may be useful to tracksuch change over topics and refresh various cacheswhen there is a topic change.
We will leave theabove issues to the future work.6 ConclusionWe have shown that our cache-based approachsignificantly improves the performance with thehelp of various caches, such as the dynamic, staticand topic caches, although the cache-based ap-917proach may introduce some negative impact onBLEU scores for certain documents.In the future, we will further explore how to re-flect document divergence during training and dy-namically adjust cache weights according todifferent documents.There are many useful components in trainingdocuments, such as named entity, event and co-reference.
In this experiment, we only adopt theflat data in our cache.
However, the structured datamay improve the correctness of matching and thuseffectively avoid noise.
We will explore more ef-fective ways to pick up various kinds of useful in-formation from the training parallel corpus toexpand our cache-based approach.
Besides, we willresort to comparable corpora to enlarge our cache-based approach to document-level SMT.AcknowledgmentsThis research was supported by Projects 90920004,60873150, and 61003155 under the National Natu-ral Science Foundation of China, Project20093201110006 under the Specialized ResearchFund for the Doctoral Program of Higher Educa-tion of China.ReferencesDavid M. Blei, Andrew Y. Ng, and Michael I. Jordan.2003.
Latent Dirichlet Allocation.
Journal of machineLearning Research 3, pages 993?1022.Francis Bond.
2002.
Toward a Science of MachineTranslation.
Asian Association of Machine Transla-tion (AAMT) Journal, N0.22, Tokyo, Japan, pages12-20.PF Brown, SA Della Pietra, VJ Della Pietra, RL Merc-er.1992.The Mathematics of Statistical MachineTranslation: Parameter Estimation.
ComputationalLinguistics.
19(2):263-309.Marine Carpuat.
2009.
One Translation per Discourse.In Proc.
of the NAACL HLT workshop on SemanticEvaluation, pages 19-26.John DeNero, Alexandre Buchard-C?ot?e, and DanKlein.
2008.
Sampling Alignment Structure under aBayesian Translation Model.
In Proc.
of EMNLP2008, pages 314?323, Honolulu, October.William A. Gale, Kenneth W. Church, and David Ya-rowsky.
1992.
One Sense per Discourse.
In Proceed-ings of the workshop on Speech and NaturalLanguage, Harriman, NY.Almut Silja Hildebrand, Matthias Eck, Stephan Vo-gel,and Alex Waibel.
2005.
Adaptation of the Trans-lation Model for Statistical Machine Translationbased on Information Retrieval.
Proceedings ofEAMT 2005:133-142.Rukmini M. Iyer and Mari Ostendorf.
1999.
ModelingLong Distance Dependence in Language:TopicMixtures Versus Dynamic Cache Models.
IEEETransactions on speech and audio processing, 7(1).Philipp Koehn, Franz Josef Och ,and DanielMarcu.2003.Statistical Phrase-Based Translation.
Proceedings ofthe 2003 Conference of the North American Chapterof the Association for Computational Linguistics onHuman Language Technology, pages 48-54.Philipp Koehn.2004.Statistical Significance Tests forMachine Translation Evaluation.
In Proc.
of EMNLP2004,  pages 388?395.Roland Kuhn and Renato De Mori.
1990.
A Cache-based Natural Language Model for Speech Recogni-tion.
IEEE Transactions on Pattern Analysis and Ma-chine Intelligence,12(6):570-583.Yajuan Lu, Jin Huang, and Qun Liu.
2007.
Improvingstatistical machine translation performance by train-ing data selection and optimization.
In Proc.
ofEMNLP 2007,pages 343?350, Prague, Czech Repub-lic, June.Daniel Marcu and William Wong.
2002.
A phrase-basedJoint Probability Model for Statistical MachineTranslation.
In Proc.
of  EMNLP 2002, July.Laurent Nepveu, Guy Lapalme, Philippe Langlais andGeorge Foster.2004.
Adaptive Language and Trans-lation Models for Interactive Machine Translation.
InProc.
of EMNLP 2004, pages 190-197.Eugene A. Nida.
1964.
Toward a Science of Translating.Leiden, Netherlands:E.J.Brill.Franz Josef Och.
2003.
Minimum Error Rate Training inStatistical Machine Translation.
In Proc.
of ACL,pages 160?167.Franz Josef Och and Hermann Ney.
2000.
ImprovedStatistical Alignment Models.
In Proc.
of ACL, pages440?447.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-jing Zhu.
2002.
BLEU: A Method for AutomaticEvaluation of Machine Translation.
In Proc.
ofACL02, pages 311?318.Martin Raab.
2007.
Language Modeling for MachineTranslation.
VDM Verlag, Saarbrucken, Germany.918G.
Salton and C. Buckley.
1988.
Term-weighting Ap-proaches in Automatic Text Retrieval.
InformationProcessing and management,24(5):513-523,1988.Yik-Cheung Tam, Ian Lane and Tanja Schultz.
2007.Bilingual ISA-based Adaptation for Statistical Ma-chine Translation.
Machine Translation, 28:187-207.Jorg Tiedemann.
2010.
Context Adaptation in StatisticalMachine Translation Using Models with Exponen-tially Decaying Cache.
In Proc.
of the 2010 work-shop on domain adaptation for Natural LanguageProcessing, ACL 2010, pages 8-15.Joern Wuebker and Arne Mauser and Hermann Ney.2010.
Training Phrase Translation Models with Leav-ing-One-Out.
In Proc.
of ACL, pages 475-484.Bing Zhao, Matthias Eck, and Stephan Vogel.2004.Language Model Adaptation for Statistical Ma-chine Translation with Structured Query Models.
InCOLING 2004, Geneva, August.Bing Zhao and Eric P. Xing .2006.
BiTAM:BilingualTopic Ad-Mixture Models for Word Alignment.
InProc.
of ACL2006.919
