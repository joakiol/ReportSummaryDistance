Structural Ambiguity and Conceptual RelationsPhilip ResnikComputer and Information ScienceUniversity of Pennsylvania200 South 33rd StreetPhiladelphia, PA, 19104 USAresn ik  @ l inc.c is .upenn.eduABSTRACTLexical co-occurrence statistics are becoming widely usedin the syntactic analysis of unconstrained text.
However, anal-yses based solely on lexical relationships suffer from sparse-ness of data: it is sometimes necessary to use a less informedmodel in order to reliably estimate statistical parameters.
Forexample, the "lexical association" strategy for resolving am-biguous prepositional phrase attachments \[Hindle and Rooth.1991\] takes into account only the attachment si e (a verb or itsdirect object) and the preposition, ignoring the object of thepreposition.We investigated an extension of the lexical association strat-egy to make use of noun class information, thus permitting adisambiguation strategy to take more information i to account.Although in preliminary experiments he extended strategy didnot yield improved performance over lexical association alone.a qualitative analysis of the results suggests that the problemlies not in the noun class information, but rather in the multi-plicity of classes available for each noun in the absence of sensedisambiguation.
This suggests several possible revisions of ourproposal.1.
P re ference  St ra teg iesPrepositional phrase attachment is a paradigmatic caseof the structural ambiguity problems faced by natural lan-guage parsing systems.
Most models of grammar will notconstrain the analysis of such attachments in exampleslike (1): the grammar simply specifies that a preposi-tional phrase such as on computer theft can be attachedin several ways, and leaves the problem of selecting thecorrect choice to some other process.
(1) a.
Eventually, Mr. Stoll was invited to both theCIA and NSA to brief high-ranking officerson computer theft.b.
Eventually, Mr. Stoll was invited to both theClA and NSA \[to brief \[high-ranking officerson computer theft\]\].c.
Eventually, Mr. Stoll was invited to boththe CIA and NSA \[to brief \[high-rankingollicers\] \[on computer theft\]\].As \[Church and Patil, 1982\] point out, the number of anal-yses given combinations of such "all ways ambiguous"constructions grows rapidly even for sentences of quiteMarti A. HearstComputer Science Division465 Evans HallUniversity of California, BerkeleyBerkeley, CA 94720 USAmart i  @ cs .berke ley.edureasonable ngth, so this other process has an importantrole to play.Discussions of sentence processing have focused pri-marily on structurally-based preference strategies uchas right association and minimal attachment \[Kimball,1973; Frazier, 1979; Ford et al, 1982\]; \[Hobbs and Bear,1990\], while acknowledging the importance of seman-tics and pragmatics in attachment decisions, propose twosyntactically-based attachment rules that are meant o begeneralizations of those structural strategies.Others, however, have argued that syntactic onsider-ations alone are insumcient for determining prepositionalphrase attachments, suggesting instead that preference r -lationships among lexical items are the crucial factor.
Forexample:\[Wilks et aL, 1985\] argue that the right attachmentrules posited by \[Frazier, 1979\] are incorrect forphrases in general, and supply counterexarnples.They further argue that lexical preferences alone assuggested by \[Ford et al, 1982\] are too simplistic,and suggest instad the use of preference semantics.In the preference semantics framework, attachmentrelations of phrases are determined by comparing thepreferences manating from all the entities involvedin the attachment, until the best mutual fit is found.Their CASSEX system represents he various mean-ings of the preposition in terms of (a) the preferredsemantic lass of the noun or verb that proceeds thepreposition (e.g., move, be, strike), (b) the case of thepreposition (e.g., instrument, time, loc.static), and(c) the preferred semantic lass of the head noun ofthe prepositional phrase (e.g., physob, event).
Thedifficult part of this method is the identification ofpreference relationships and particularly determin-ing the strengths of the preferences and how theyshould interact.
(See also discussion in \[Schubert,19841.
)lDahlgren and McDowell, 1986\] also suggests usingpreferences based on hand-built knowledge aboutthe prepositions and their objects, specifying asim-pler set of rules than those of \[Wilks et al, 1985\].58She argues that the knowledge is needed lot un-derstanding the text as well as for parsing it.
LikeCASSE.X, this system requires considerable ffortto provide hand-encoded preference information.?
\[Jensen and Binot, 1987\] resolve prepositionalphrase attachments by using preferences obtainedby applying aset of heuristic rules to dictionary def-initions.
The rules match against lexico-syntacticpatterns in the definitions - -  for example, if con-fronted with the sentence She ate a fish with a fork,the system evaluates eparately the plausibility ofthe two proposed constructs eat with fork and fishwith fork based on how well the dictionary supportseach.
By making use of on-line dictionaries, theauthors hope to create a system that will scale up;however, they report no overall evaluation.An empirical study by \[Whittemore eta/., 1990\] sup-ports the main premise of these proposals: they observethat in naturally-occurring data, lexical preferences (e.g.,arrive at, flight to) provide more reliable attachmentpredictions than structural strategies.
Unfortunately, itseems clear that, outside of restricted omains, hand-encoding of preference rules will not suffice for uncon-strained text.
Information gleaned from dictionaries mayprovide a solution, but the problem of how to weight andcombine preferences remains.2.
Lex iea l  Assoc ia t ion\[Hindle and Rooth, 1991\] offer an alternative methodfor discovering and using lexical attachment preferences,based on corpus-based lexical co-occurrence statistics.In this section, we briefly summarize their proposal andexperimental results.An "instance" of ambiguous prepositional phrase at-tachment is taken to consist of a verb, its direct object,a preposition, and the object of the preposition.
Further-more, only the heads of the respective phrases are consid-ered; so, for example, the ambiguous attachment in (1)would be construed as the 4-tuple (brief, officer,on,theft).
1We will refer to its elements as v, n 1, p, and n2, respec-tively.The attachment s rategy is based on an assessment ofbow likely the preposition is, given each potential attach-ment site; that is, a comparison of the values Pr(/,inl)and Pr(p\[v).
For (1), one would expect Pr(on\[bri~f)to be greater than Pr(on\[o~fficer), eflecting the intuitionthat briefX on Y is more plausible as a verb phrase thano.~icer on Z is as a noun phrase.Hindle and Rooth extracted their training data from acorpus of Associated Press news stories.
A robust parser!
Verbs aad nou~xr?
reduced to their root form, F, hence officerratherthan o~cen.\[Hindle, 1983\] was used to construct a table in whicheach row contains the head noun of each noun phrase, thepreceding verb (if the noun phrase was the verb's directobject), and the following preposition, if any occurred.Attachment decisions for the training data in the tablewere then made using a heuristic procedure - -  for ex-ample, given spare it from, the procedure will count thisrow as an instance of spare from rather than it from, sincea prepositional phrase cannot be attached to a pronoun.Not all the data can be assigned with such certainty: am-biguous cases in the training data were handled either byusing statistics collected from the unambiguous cases, bysplitting the attachment between the noun and the verb,or by defaulting to attachment to the noun.Given an instance of ambiguous prepositional phraseattachment from the test set, the lexical association pro-cedure for guessing attachments u ed the t-score \[Churchet aL, 1991\] to assess the direction and significance ofthe difference between Pr(p\[n 1) and Pr(plv) - -  t will bepositive, zero, or negative according to whether Pr(pln 1)is greater, equal to, or less than Pr(plv), respectively,and its magnitude indicates the level of confidence in thesignificance of this difference.On a set of test sentences held out from the trainingdata, the lexical association procedure made the correctattachment 78.3% of the time.
For choices with a highlevel of confidence (magnitude of t greater than 2.1, about70% of the time), correct attachments were made 84.5%of the time.3.
P repos i t iona l  Ob jec tsThe lexical association strategy performs quite well,despite the fact that the object of the preposition is ig-nored.
However, Hindle and Rooth note that neglectingthis information can hurt in some cases.
For instance,the lexical association strategy is presented with exactlythe same information in (2a) and (2b), and is thereforeunable to distinguish them.
(2) a. Britain reopened its embassy in December.b.
Britain reopened its embassy in Teheran.In addition, \[Hearst and Church, in preparation\] have con-ducted a pilot study in which human subjects are asked toguess prepositional phrase attachments despite the omis-sion of the direct object, the object of the preposition,or both.
The results of this study, though preliminary,suggest hat the object of the preposition contributes anamount of information comparable tothat contributed bythe direct object; more important, for some prepositions,the object of the preposition appears to be more informa-tive.Thus, there appears to be good reason to incorporatethe object of the preposition i lexicai association calcula-tions.
The difficulty, of course, is that the data are far too59sparse to permit he most obvious extension.
Attempts tosimply compare Pr(p, n21nl) against Pr(p, n21v) usingthe t-score fail dismally?4.
Word  C lassesWe are faced with a well-known tradeoff: increas-ing the number of words attended to by a statistical lan-guage model will in general tend to increase its accuracy,but doing so increases the number of probabilities to beestimated, leading to the need for larger (and often im-'practically larger) sets of training data in order to obtainaccurate stimates.
One option is simply to pay attentionto fewer words, as do Hindle and Rooth.
Another possi-bility, however, is to reduce the number of parameters bygrouping words into equivalence classes, as discussed,for example, by \[Brown et al, 1990\].\[Resnik, 1992\] discusses the use of word classesin discovering lexical relationships, demonstrating thatWordNet \[Beckwith et al, 1991; Miller, 1990\], abroad-coverage, hand-constructed l xical database, provides areasonable foundation upon which to build class-basedstatistical algorithms.
Here we briefly describe WordNet,and in the following section describe its use in resolvingprepositional phrase attachment ambiguity.WordNet is a large lexical database organized as a setof word taxonomies, one for each of four parts of speech(noun, verb, adjective, and adverb).
In the noun taxon-omy, the only one used here, each word is mapped to a setof word classes, corresponding roughly to word senses,which Miller et al term synonym sets.
For example, theword paper is a member of synonym sets \[newspaper, pa.per\] and \[composition, paper, report, theme\], among oth-ers.
For notational convenience, we will refer to eachsynonym set by its first word, sometimes together with aunique identifier - -  for example (paper, 2241323 ) and(newspaper, 2202048).3The classes in the taxonomy form the nodes of asemantic network, with links to superordinates, subor-dinates, antonyms, members, parts, etc.
In this workonly the superordinate/subordinate (i.e., IS-A) links areused w for example, (newspaper ,  2202048)  is a sub-class of (press,2200204),  which is a subclass of(print.media, 2200360), and so forth.Denoting the set of words subsumed by a class c (thatis, the set of all words that are a member of c or anysubordinate class) as words(c), the frequency of a classcan be estimated as follows:f(c)---- ~ /(n) (I).ewo.t,(c)2This experiment was attempted using expected likelihood esti-mates, as in \[Hindle and Rooth, 1991l, with data extracted from thePenn Treebank as dem:ribed below.3These identifiers differ depending upon the version of WordNetused; the wock desaribed inthis paper was done using version 1.2.Owing to multiple inheritance and word sense ambiguity,equation (1) represents only a coarse estimate - -  for ex-ample, each occurrence of a word contributes equally tothe count of all classes of which it is a member.
However,\[Resnik, 1992\] estimated class frequencies in a similarfashion with acceptable r sults.5.
Conceptua l  Assoc ia t ionIn what follows, we propose to extend Hindle andRooth's lexical association method to take advantage ofknowledge about word-class memberships, following astrategy one might call conceptual association.
From apractical point of view, the use of word classes reducesthe sparseness ofthe training data, permitting us to makeuse of the object of the preposition, and also decreasesthe sensitivity of the attachment s rategy to the specificsof the training corpus.
From a more philosophical pointof view, using a strategy based on conceptual rather thanpurely lexical relationships accords with our intuitionthat, at least in many cases, much of the work clone bylexical statistics is a result of the semantic relationshipsthey indirectly encode.Our proposal for conceptual ssociation is to calculatea measure of association using the classes to which thedirect object and object of the preposition belong, andto select the attachment site for which the evidence ofassociation is strongest.
The use of classes introducestwo sources of ambiguity.
The first, shared by lexicalassociation, is word sense ambiguity: just as lexically-based methods conflate multiple senses of a word into thecount of a single token, here each word may be mappedto many different classes in the WordNet axonomy.
Sec-ond, even for a single sense, a word may be classifiedat many levels of abstraction - - for example, even inter-preted solely as a physical object (ratber than a monetaryunit),penny may be categorized as a (coin,  3566679),(cash,3566144), (money, 3565439), and SO forth onup to (possession, 11572 ).In our experiments, we adopted the simplest possibleapproach: we consider each classification of the nounsas a source of evidence about association, and combinethese sources of evidence to reach a single attachmentdecision.Algorithm 1.
Given (v, nl ,  p, n2),I.
Let C1 = {c J nl E words(c)}Let C2 = {c \] n2 E words(c)} = {c2.1 ..... c2.N}2.
For i from l to N,cl,i = argmax l(c; p, c2.i)c?C1I F = I(cl,i;p, C2,i )60I~' = I(v;p, c2,i)3.
For i from 1 to N,= freq(el,~, r', c2,i) I~= freq(v,r,, e2,~) I~4.
Compute apaired samples t-test for a difference ofthe means of ,5"' and S ~ .
Let "confidence" be thesignificance of the test with N - 1 degrees offreedom.5.
Select attachment tonl or v according to whether tis positive or negative, respectively.Step 1 of the algorithm establishes the range of pos-sible classifications for nl and n2.
For example, if thealgorithm is trying to disambiguate(3) But they foresee little substantial progress inexports...the word export can be classified alter-natively as (export, 248913), (commerce, 244370),(group_action, 241055), and (act, 10812).In step 2, each candidate classification for n2 is heldfixed, and a classification for n l is chosen that maxi-rnizes the association (as measured by mutual informa-tion) between the noun-attachment site and the preposi-tional phrase.
In effect, this answers the question, "If wewere to categorize n2 in this way, what would be the bestclass to use for niT'  This is done for each classificationof n2, yielding N different class-based interpretations for(nl,p,n2).
I~ is the noun-attachment association scorefor the ith interpretation.
Correspondingly, there are Ninterpretations 1~' for (v,p,n2).At this point, each of the N classifications for nl(progress) and n2 (export) provides one possible interpre-tation of (foresee,progress,in,export), and each of theseinterpretations provides associational evidence in favorof one attachment choice or the other.
How are thesesources of evidence to be combined?As a first effort, we have proceeded as follows.
Eachof the values for I/~ and I/' are not equally reliable: val-ues calculated using classes low in the taxonomy involvelower frequencies than those using higher-level classes.In an attempt to assign more credit to scores calculatedusing higher counts, we weight each of the mutual infor-marion scores by the corresponding trigram frequencythus in step 3 the association score for noun-attachmentis calculated as the product of f(el,i, P, e2,i) I~.
The cor-responding verb-attachment score is f(v, p, c2.~) I~'.
Thisleaves us with a table like the following:J s ;  I(situation} in (exp,z, rt } 67.4 39.8(rise) in (commerce) 178.3 23.8(advance) in (group_at=ion) 104.9 19"9 I(advance) in (act) 149.5 40.6 JIn step 4 the N different sources of evidence are com-bined: a t.test for the difference of the means is per-formed, treating ~ and S" as paired samples (see, e.g.,\[Woods et al, 1986\]).
In step 5 the resulting value of tdetermines the choice of attachment si e, as well as an es-timate of how significant the difference isbetween the twoalternatives.
(For this example, t(3) = 3.57,p < 0.05,yielding the correct choice of attachment.)6.
Combin ing  S t ra teg iesIn addition to evaluating the performance of the con-ceptual association strategy in isolation, it is natural tocombine the predictions of the lexical and conceptual s-sociation strategies to make a single prediction.
Althoughwell-founded strategies for combining the predictions ofmultiple models do exist in the speech recognition liter-ature \[Jelinek and Mercer, 1980; Katz, 1987\], we havechosen a simpler "backing off"' style procedure:Algorithm 2.
Given (v, nl, p, n2),1.
Calculate an attachment decision usingAlgorithm 1.2.
If significance < 0.1, use this decision,3.
Otherwise, use iexical association.7.
Exper imenta l  Resu l ts7.1.
Exper iment  1An experiment was conducted to evaluate the perfor-mance of the lexical association, conceptual ssociation,and combined strategies.
The corpus used was a collec-tion of parses from articles in the 1988-89 Wall StreetJournal, found as part of the Penn Treebank.
This corpusis an order of magnitude smaller than the one used byHindle and Rooth in their experiments, but it providesconsiderably ess noisy data, since attachment decisionshave been performed automatically b  the Fidditch parser\[Hindle, 1983\] and then corrected by hand.A test set of 201 ambiguous prepositional phrase at-tachment instances was set aside.
After acquiring attach-ment choices on these instances from a separate judge(who used the full sentence context in each case), the testset was reduced by eliminating sentences for which theseparate judge disagreed with the Treebank, leaving a testset of 174 instances.
4#Of the 348 nouns appearing a.~ part of the test set.
12 were notcovered by WordNet ; these were clas.~ified by default L~ members offile WordNet cl~?s (ant i ty, 23 ~ 3 ).61Lexical counts for relevant prepositional phrase at-tachments (v,p,n2 and nl,p,n2) were extracted from theparse trees in the corpus; in addition, by analogy with Hin-die and Rooth's training procedure, instances of verbs andnouns that did not have a prepositional phrase attachedwere counted as occurring with the "null prepositionalphrase."
A set of clean-up steps included reducing verbsand nouns to their root forms, mapping to lowercase, sub-stituting the word someone for nouns not in WordNet hatwere part-of-speech-tagged as proper names, substitutingthe word amount for the token % (this appeared as a headnoun in phrases uch as rose 10 %), and expanding monthabbreviations such as Jan. to the full month name.The results of the experiment are as follows:I I ~ I c^ I ?
?MB~N~D I\[ %Correct \[ 81.6 \] 77.6 I 82.2 \]When the individual strategies were constrained to an-swer only when confident (Itl > 2.1 for lexical associa-tion, p <.
1 for conceptual association), they performedas follows:\[ sr~rvx~v \]ANSWERED (%) \] ACCURACY (%) \]I..A ,44.3 92.8 \[t CA 67.2 84.6The performance of lexical association in this experi-ment is striking: despite the reduced size of the trainingcorpus in comparison to \[Hindle and Rooth, 1991\], per-formance xceeds previous results ~ and although fewertest cases produce confident predictions (as might be ex-pected given generally lower counts), when the algorithmis confident it performs very well indeed.The performance of the conceptual association strat-egy seems reasonable, though it is clearly overshadowedby the performance of the lexical association strategy.The tiny improvement on lexical association by the com-bined strategy suggests that including the conceptual as-sociation strategy may improve performance overall, butfurther investigation is needed to determine whether sucha conclusion is warranted; the experiments described inthe following two sections bear on this issue.7.2.
Experiment 2Although the particular class-based strategy imple-mented here might not provide great leaps in performanceat least as judged on the basis of Experiment 1one might expect that a strategy based upon a domain-independent semantic taxonomy would provide a greaterdegree of robustness, reducing dependence of the attach-ment strategy on the training corpus.We set out to test this supposition by consideringthe performance of the various associational ttachmentstrategies when tested on data from a corpus other thanthe one on which they were trained.
First, we tested per-formance on a test set drawn from the same genre.
Ofthe test cases drawn by Hindle and Rooth from the As-sociated Press corpus, we took the first 200; eliminatingthose sentences for which Hindle and Rooth's two humanjudges could not agree on an attachment reduced the setto 173.
Several minor clean-up steps were taken to makethis test set consistent with our training data: if the objectof the preposition was a complementizer o other wordintroducing a sentence (e.g.
begin debate on whether),it was replaced with the word something; proper names(e.g.
Bush) were replaced with someone; some numberswere replaced with year or atnount, (e.g.
1911 and 0, re-spectively); and "compound" prepositions were replacedby a "normal" preposition consistent with what appearedin the full sentence (e.g.
by_about was replaced with byfor the phrase oumumbered losers by about 6 to 5).The results of the experiment are as follows:\[ % Correct 169.9172.3172.8  \]When the individual strategies were constrained to an-swer only when confident:\[ STRATEGY \[ ANSWERED (%) ACCURACY (%)LA 31.8 80.0CA 49.7 77.9The conceptual association strategy, not being as de-pendent on the specific lexical items in the training andtest sets, sustains a somewhat higher level of overall per-formance, although once again the lexical associationstrategy performs well when restricted to the relativelysmall set of predictions that it can make with confidence.7.3.
Experiment 3Wishing to pursue the paradigm of cross-corpus test-ing further, we conducted a third experiment in whichthe training set was extracted from the Penn Treebank'sparsed version of the Brown corpus \[Francis and Kucera,1982\], testing on the Wall Street Journal test set of Ex-periment 1.The results of the experiment are as follows:I I I c^ II%Co~=t 177.6173.6179.3 IWhen the individual strategies were constrained toanswer only when confident:I s ^rmv I ANSWERa, ACCUSer59.2 81.662In this experiment it is surprising that all the strategiesperform as well as they do.
However, the pattern of re-sults leads us to conjecture that the conceptual ssociationstrategy, taken in combination with the lexical associa-tion strategy, may permit us to make more effective use ofgeneral, corpus-independent semantic relationships thandoes the lexical association strategy alone.8.
Qua l i ta t ive  Eva luat ionThe overall performance ofthe conceptual ssociationstrategy tends to be worse than that oflexical association,and the combined strategy ields at best a marginal im-provement.
However, several comments are in order.First, the results in the previous ection demonstratethat conceptual ssociation isdoing some work: when thestrategies are constrained to answer only when confident,conceptual association achieves a 50-60% increase incoverage over lexical association, at the cost of a 3-9%decrease in accuracy.Second, it is clear that class information is provid-ing some measure of resistance to sparseness of data.As mentioned earlier, adding the object of the preposi-tion without using noun classes leads to hopelessly sparsedata - -  yet the performance ofthe conceptual ssociationstrategy is far from hopeless.
In addition, examination ofwhat the conceptual association strategy actually did onspecific examples shows that in many cases it is success-fully compensating for sparse data.
(,4) To keep his schedule on track, he flies twopersonal secretaries in from Little Rock toaugment his staff in Dallas,For example, verb augment and preposition i  never co-occur in the WSJ training corpus, and neither do nounstaff and preposition i ; as a result, the lexical associationstrategy makes an incorrect choice for the ambiguousverb phrase in (,4).
However, the conceptual ssociationstrategy makes the correct decision on the basis of the-following classifications:augment .
.
S"(gathering) in (dallas) 38.18.,(people} in (urban.area~(personnel) in (region).
(personnel) in (geo..area)(people} in (city)(personnel) in (location)1200.21314.62106.051161.22320.8545.5428.4623.3826.8o28.6122.83Third, mutual information appears to be a success-ful way to select appropriate classifications for the directobject, given a classification of the object of the prepo-sition (see step 2 in Algorithm 1).
For example, de-spite the fact that staff belongs to 25 classes in WordNet- -  including ( rnus ica l _notat ion ,  23325281 and( rod ,  1613297),  for instance - -  the classes to whichit assigned in the above table seem appropriate given thecontext of (4).Finally, it is clear that our method for combiningsources of evidence - -  the paired t-test in step 4 of Al-gorithm 1 - -  is hurting performance in many instancesbecause (a) it gives equal weight to likely and unlikelyclassifications of the object of the preposition, and (b) thesignificance of the test is overestimated when the objectof the preposition belongs to many different classes.
(5) Goodrich's vinyl-products segment reportedoperating pn~t for the quarter of $30.
l mil-lion.For example, given the ambiguous attachment high-lighted in (5), the contribution of the time-relatedclassifications ofquarter ((t ime_period, 4 0142 63),(ttrne, 9819), etc.)
is swamped by numerous otherclassifications in which quttrter is interpreted as a physi-cal object (coin, animal part), a number (fraction, rationalnumber), a unit of weight (for measuring rain), and soforth.
As a result, the conceptual association strategycomes up with the wrong attachment and identifies itsdecision as a confident one.9.
Conc lus ionsThe conceptual association strategy described hereleaves room for a number of improvements.
The useof mutual information as an association measure, and theweighting of the mutual information score in order to biasthe computation i favor of large counts, warrant furtherconsideration - - mutual information has been criticizedfor, among other things, its poor behavior given low fre-quencies, and an alternative measures of association mayprove better.In addition, as noted in the previous section, com-bining evidence using the paired t-test is problematic,essentially because of word-sense ambiguity.
One al-ternative might be to perform sense disambiguation iadvance - -  the results of \[Yarowsky, 1993\] demonstratethat a significant reduction in the number of possiblenoun classifications i possible using only very limitedsyntactic ontext, rather than global word co-occurrencestatistics.
Another elated alternative would be to select asingle best classification - -  for example, using the mea-sure of selectional ssociation proposed in \[Resnik, 1993\]- -  rather than considering all possible classifications.Another possibility to investigate is the incorporationof structurally-based attachment strategies along withlexical and conceptual association.
Such a fusion ofstructural and iexical preference strategies i suggested in\[Whittemore et al, 1990\], and \[Weischedel taL, 1989\]63have found that a structural strategy ("closest attach-ment") performs well in combination with a class-basedstrategy, although they use a relatively small, domain-specific taxonomy of classes and assume ach word hasa pointer to a unique class.Still another direction for future work involves theapplication of similar techniques to other problems likeprepositional phrase attachment for which the resolu-tion of ambiguities would seem to require some formof semantic knowledge.
'The problems discussed in\[Church and Patil, 1982\] - -  including ambiguous prepo-sitional phrase attachment, noun-noun modification, andcoordination m would seem to form a natural classof problems to investigate in this manner.
Althoughthere will always be ambiguities that can be resolvedonly by appeal to complex inferences or highly domain-dependent facts, we believe the combination of domain-independent, knowledge-based resources uch as Word-Net with corpus-based statistics may provide the seman-tic power necessary for solving many instances of suchproblems, without the need for general reasoning aboutworld knowledge.Re ferences\[Beckwith et al, 1991\] Richard Beckwith, Christiane Fell-baum, Derek Gross, and George Miller.
WordNet: Alexical database organized on psycholinguistic principles.In Uri Zernik, editor, LexicalAcquisition: FExploiting On-Line Resources to Build a Lexicon, pages 211-232.
Erl-baum, 1991.\[Brown et aL, 1990\] Peter F. Brown, Vincent J. Delia Pietra,Peter V. deSouza, and Robert L. Mercer.
Class-basedn-gram models of natural anguage.
In Proceedings ofthe IBM Natural Language ITL, pages 283-298, Paris,France, March 1990.\[Church and Patil, 1982\] Kenneth W. Church and RameshPatil.
Coping with syntactic ambiguity or how to putthe block in the box on the table.
American Journal ofComputational Linguistics, 8(3-.4): 139-149, 1982.\[Claureh eta/., 1991\] Kenneth Church, William Gale, PatrickHanks, and Donald Hindle.
Using statistics in lexical anal-ysis.
In Uri Zernik, editor, Lexical Acquisition: Exploit-ing On .Line Resources to Build a Lexicon, pages 116..-164.Erlbaum, 1991.\[Dalalgren and McDowell, 1986\] K. Dahlgren and J. McDow-ell.
Using commonsense knowledge to disambiguateprepositional phrase modifiers.
In AAAI-86, pages 589-593, 1986.\[Ford et aL, 1982\] Marilyn Ford, Joan Bresnan, and RonaldKaplan.
A competence-based theory of syntactic closure.In Joan Bresnan, editor, The Mental Representation ofGranunatical Relations.
MIT Press, 1992.\[Francis and Kucera, 1982\] W. Francis and H. Kucera.
Fre-quency Analysis of Engluh Usage.
Houghton Mifflin Co.:New York, 1982.\[Frazier, 1979\] L. Fra.zier.
On comprehending Sentences: Syn-tactic Parsing Strategies.
PhD thesis, University of Mas-sachusetts.
1979.\[Hearst and Church.
in preparation\] Marti A. Hearst and Ken-neth W. Church.
An investigation of the use of lexi-cal associations for prepositional phrase attachment, (inpreparation).\[Hindle and Rooth.
1991\] D. Hindle and M. Rooth.
Structuralambiguity and lexical relations.
In Proceedings of the29th Annual Meeting of the Association for ComputationalLinguistics, June 1991.
Berkeley, California.\[Hindle, 1983\] Donald Hindle.
User manual for Fidditch, adeterministic parser.
Technical memorandum 7590-142,Naval Research Laboratory, 1983.\[Hobbs and Bear, 1990\] Jerry R. Hobbs and John Bear.
Twoprinciples of parse preference.
In Proceedings of 13thCOLING.
pages 162-167, Helsinki, 1990.\[Jelinekand Mercer, 1980\] Frederick Jelinek and Robert L.Mercer.
Interpolated estimation of Markov source pa-rameters from sparse data.
In Proceedings of the Work-shop on Pattern Recognition i Practice, Amsterdam, TheNetherlands: North-Holland, May 1980.\[Jensen and Binot, 1987\] Karen Jensen and Jean-Louis Binot.Disambiguating prepositional phrase attachments by us-ing on-line dictionary definitions.
American Journal ofComputational Linguistics, 13(3):251-260, 1987.\[Kate., 1987\] Slavs M. Katz.
Estimation of probabilities fromsparse data for the langauge model component ofa speechrecognizer.
IEEE Transactions on Acoustics, Speech andSignal Processing.
ASSP-35(3):400--401, March 1987.\[Kimball.
1973\] John Kimball.
Seven principles of surfacestructure parsing in natural anguage.
Cognition, 2:15-47, 1973.\[Miller, 1990\] George Miller.
Wordnet: An on-line lexicaldatabase.
International Journal of Lexicography, 3(4),1990.
(Special Issue).\[Resnik, 1992\] Philip Resnik.
WordNet and distributionalanalysis: A class-based approach to lexical discovery.
InAAAI Workshop on Statistically-based NLP Techniques,San Jose, California.
July 1992.\[Resnik, 1993\] Philip Resnik.
Semantic lasses and syntacticambiguity.
ARPA Workshop on Human Language Tech-nology, March 1993.
Princeton.\[Schubert, 1984\] Lenhart Schubert.
On parsing preferences.In COLING-84, 1984.\[Weischedel tal., 1989\] Ralph Weischedel, Marie Meteer,Richard Schwartz, and Jeff Palmucci.
Coping with ambi-guity and unknown words through probabilistic models.ms., 1989.\[Whittemore etal., 1990\] Greg Whittemore, Kathleen Fen'sea,and Hans Brunner.
Empirical study of predictive powersof simple attachment schemes for post-modifier p eposi-tional phrases.
In Proceedings ofthe 28th Annual Meetingof the Association for Computational Linguistics, pages23-30, 1990.
Pittsburgh, Pennsylvania.\[Wilks etaL, 1985\] Yorick Wilks, Xiuming Huang, and DanFass.
Syntax, preference and right attachment.
In IJCAi-85, pages 779-784.
1985.\[Woods et al.
1986\] Anthony Woods, Paul Fletcher, andArthur Hughes.
Statistics in Language Studies.
Cam-bridge Textbooks in Linguistics.
Cambridge UniversityPress: Cambridge, England.
1986.\[Yarowsky, 1993\] David Yarowsky.
One sense per coUoca-lion.
ARPA Workshop on Human Language Technology,March 1993.
Princeton.64
