Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 510?518,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsSubword Variation in Text Message ClassificationRobert MunroDepartment of LinguisticsStanford UniversityStanford, CA 94305rmunro@stanford.eduChristopher D. ManningDepartment of Computer ScienceStanford UniversityStanford, CA 94305manning@stanford.eduAbstractFor millions of people in less resourced re-gions of the world, text messages (SMS) pro-vide the only regular contact with their doc-tor.
Classifying messages by medical labelssupports rapid responses to emergencies, theearly identification of epidemics and everydayadministration, but challenges include text-brevity, rich morphology, phonological vari-ation, and limited training data.
We presenta novel system that addresses these, workingwith a clinic in rural Malawi and texts in theChichewa language.
We show that model-ing morphological and phonological variationleads to a substantial average gain of F=0.206and an error reduction of up to 63.8% for spe-cific labels, relative to a baseline system opti-mized over word-sequences.
By comparison,there is no significant gain when applying thesame system to the English translations of thesame texts/labels, emphasizing the need forsubword modeling in many languages.
Lan-guage independent morphological models per-form as accurately as language specific mod-els, indicating a broad deployment potential.1 IntroductionThe whole world is texting, but rarely in English.Africa has seen the greatest recent uptake of cell-phones, with an 8-fold increase over the last 5 yearsand saturation possible in another 5 (Buys et al,2009).
This is a leapfrog technology ?
for the ma-jority of new users cellphones are the only form ofremote communication, surpassing landlines, (non-mobile) internet access and even grid electricity,with costs making texts the dominant communica-tion method.
This has led social development orga-nizations to leverage mobile technologies to supporthealth (Leach-Lemens, 2009), banking (Peevers etal., 2008), access to market information (Jagun et al,2008), literacy (Isbrandt, 2009) and emergency re-sponse (Munro, 2010).
The possibility to automatemany of these services through text-classification ishuge, as are the potential benefits ?
those with theleast resources have the most to gain.However, the data presents many challenges, astext messages are brief, most languages have richmorphology, spellings may be overly-phonetic, andthere is often limited training data.
We partneredwith a medical clinic in rural Malawi and Front-lineSMS:Medic, whose text message managementsystems serve a patient population of over 2 millionin less developed regions of the world.
The systemallows remote community health workers (CHWs)to communicate directly with more qualified medi-cal staff at centralized clinics, many for the first time.We present a short-message classification sys-tem that incorporates morphological and phono-logical/orthographic variation, with substantial im-provements over a system optimized on word-sequences alone.
The average gain is F=0.206 withan error reduction of up to 63.8% for specific labels.For 6 of the 9 labels this more than doubles the accu-racy.
By comparison, there is not a significant gainin accuracy when applying the same system to theEnglish translations of the same texts/labels, empha-sizing the need for modeling subword structures, butalso highlighting why morphology has been periph-eral in text classification until now.5102 Language and dataChichewa is a Bantu language with about 13 mil-lion speakers in Southern Africa including 65%of Malawians.
We limit examples to the nouns:odwala ?patient?, mankhwala ?medicine?
; verb: fun?want?
; and the 1st person pronoun/marker: ndi-?I?.
Chichewa is closely related to many neighbor-ing languages ?
more than 100 million people couldrecognize ndifuna as ?I want?.The morphological complexity is average withabout 2-3 morpheme boundaries per word, but this isrich and complex compared to estimates for English,Spanish and Chinese with average of 0.33, 0.85 and0.01 morpheme boundaries per word.
A typical verbis ndimakafunabe, ?I am still wanting?, consistingof six morphemes, ndi-ma-ka-fun-a-be, expressing:1st person Subject; present tense; noun-class (gen-der) agreement with the Object; ?want?
; verb part-of-speech; and incompletive aspect.2.1 LabelsThe text messages are coded for 0-9 labels in 3groupings (with counts):Administrative: related to the clinic:1.
Patient-related (394)2.
Clinic-admin: meetings, supplies etc (169)3.
Technological: phone-credit, batteries etc (21)Requests: from Community Health Workers:4.
Response: any action requested by CHW (124)5.
Request for doctor (62)6.
Medical advice: CHW asking for advice (23)Illness: changes of interest to monitoring bodies:7.
TB: tuberculosis (44)8.
HIV: HIV, AIDS and/or treatments (45)9.
Death: reported death of a patient (30)The groupings correspond to the three main stake-holders of the messages: the clinic itself, interestedin classifying messages according to internal work-practices; the Community Health Workers and theirpatients, acting as the direct care-givers outside theclinic; and broader bodies like the World Health Or-ganization who are interested in monitoring diseasesand early identification of epidemics (biosurveil-lance).
The labels are the three most frequent labelsrequired by each of these user groups.We analyzed 4 months of texts messages with ap-proximately 1,500 labels from 600 messages, con-sisting of 8,000 words and 30,000 morphemes.While this is small, the final system is being pilotedat a clinic in rural Malawi, where users can definenew labels at any time according to changing work-practices, new diseases etc.
If more than 4 monthsof manually labeling were required it could limit theutility and user acceptance.All the messages were translated into English bya medical practitioner, allowing us to make cross-linguistic comparisons of our system.2.2 VariationThe variation in the data is large.
There are >40forms for ?patient?
and only 32% are odwala.
Of therest, >50% occur only once.
The variation resultsfrommorphology: ndi-odwala; phonology: odwara,ndiwodwala, and compounding: ndatindidziwewod-wala.
There are also >10 spellings for the Englishborrowing: patient, pachenti etc, and 3 for the syn-onym matenda.Similarly, there are >20 forms for ?medicine?.For fun ?want?, there are >30 forms with >80% oc-curing only once.
There are >200 forms containingndi and no one form accounts for more than 5% ofthe instances.The co-occurrence of ndi and fun within a word isa strong non-redundant predictor for several labels,but >75% of forms occur only once and >85% ofthe forms are non-contiguous, as above and in themost frequent ndi-ma-funa ?I currently want?.By contrast, in the English translations ?needing?occurs just once but all other forms of ?patient?,?medicine?
and ?
(I) want/need?
are frequent.This brief introduction to the language and datashould make it clear that specialized methods are re-quired for modeling variation in text messages, es-pecially in many languages where text messaging isthe dominant form of digital communication.3 Morphological modelsWe compared language specific and language inde-pendent morphological models, comparing 3 meth-ods (with ndimafuna as an example):Stemmed: {ndi, fun}Segmented: {ndi, ma, fun, a}Morph-config: {ndi-ma, ndi-fun, ndi-a, ma-fun...}511We also looked at character ngrams, as used by Hi-dalgo et al (2006) for morphological variation inEnglish and Spanish.
The results converged withthose of the segmented model, which is not surpris-ing as the most frequent features would be simi-lar and increasing data items would overcome thesparcity.
We leave more sophisticated characterngram modeling for future work.3.1 Language specificFor the language specific morphological modelswe implemented a morphological parser as a setof context-free grammars for all possible prefixesand suffixes according to the formal definitions ofChichewa morphology in Mchombo (2004).We identified stems by parsing potential prefixesand suffixes, segmenting a word w into n mor-phemes wm,0, .
.
.
, wm,n?1 leaving a stem ws withlength len(ws) and corpus frequency of f(ws), suchthat len(ws) > 0 (ie, there must be a stem).
Wheremultiple parses could be applied, we minimizedlen(ws), then maximized n.3.2 Language independentFor the language independent morphological mod-els we adapted the word-segmenter of Goldwa-ter, Griffiths and Johnson (2009), to morphologicalparsing (see Related Work for other algorithms wetested/considered).
It was suited to our task becausea) it is largely nonparametric, meaning that it canbe deployed as a black-box before language-specificproperties are known b) it favored recall over preci-sion (see the Results for discussion) and c) using asegmentation algorithm, rather than explicitly mod-eling morphology, also addresses compounds.This model uses a Hierarchical Dirichlet Process(HDP) (Teh et al, 2005).
Every morpheme in thecorpusmi is drawn from a distributionGwhich con-sists of possible morphemes (the affixes and stems)and probabilities associated with each morpheme.
Gis generated from a Dirichlet Process (DP) distri-bution DP (?0, P0), with morphemes sampled fromP0 and their probabilities determined by a concen-tration parameter ?0.
The context-sensitive modelwhere Hm is the DP for a specific morpheme is:mi|mi?1 = m,Hm?Hm ?mHm|?1, G ?DP (?1, G) ?mG|?0, P ?DP (?0, P0)Note that this part of our model is identical to thebigram HDP in Goldwater et al (2009), except thatwe possess a set of morphemes, not words.
Becauseword boundaries are already marked in the major-ity of the messages, we constrain the model to treatall existing word boundaries in the corpus as mor-pheme boundaries, thus constraining the model tomorpheme and compound segmentation.Unlike word-segmentation, not all tokens in themorpheme lexicon are equal, as we want to modelstems separately from affixes in the stemmed mod-els.
We assume a) the free morphemes (stems andthrough compounding) are the least frequent andtherefore have the lowest final probability, P (m), inthe HDP model; and b) each word w must have atleast one free morpheme, the stem ws (ws 6= ?
).1The token-optimal process for identifyingstems is straightforward and efficient.
Thewords are sorted by the argmin probabilitiesof P (wm,0), .
.
.
, P (wm,n?1).
For each wordw, unless ws can be identified by a previouslyobserved free morpheme, ws is identified asargmin(P (wm,0), .
.
.
, P (wm,n?1)) and ws isadded to our lexicon of free morphemes.
This algo-rithm iterates over the words with one extra pass tomark all free morphemes in each word (assumingthat there might be compounds we missed on thefirst pass).
The cost, where M is the total numberof morphemes and W the total number of words, isO(log(W ) +M).This process has the potential to miss free mor-phemes that only happened to occur in compoundswith less-probable stems, but this did not occur inour data.4 Phonological/Orthographic ModelsWe compared three models of phonologi-cal/orthographic variation:Chichewa: Chichewa specificScript: Roman script specificIndep: language independentWe refer to these using the term ?phonology?
verybroadly.
The majority of the variation stems from1Note that identifying stems must be a separate step ?
if weallowed multiple free morphemes for each word to enter thelexicon without penalty in the HDP model it would converge ona zero-penalty distribution where all morphemes were free.512the phonology, but also from phonetic variation asexpressed in a given writing system, and variation inthe writing system itself arising from fluent speakerswith varying literacy.4.1 Chichewa specificFor the language specific normalization, we applieda set of heuristics to the data, based on the varia-tion given in (Paas, 2005) and our own knowledgeof how Bantu languages are expressed in Romanscripts.
The heuristics were used to normalize allalternates, eg: {iwo ?
i?o} and {r ?
l}, resultingin ndiwodwara ?
ndiodwala.The heuristics represented forms for phonemeswith the same potential place of articulation (?c/k?
),forms with an adjacent place-of-articulation that arecommon phonological alternates (?l/r?, ?e,i?
), voic-ing alternations (?s/z?
), or language-internal phono-logical processes like the insertion of a glide be-tween vowels that the morphology has made adja-cent (like we pronounce but don?t spell in ?go(w)ing?in English).We also implemented hard-coded acronym-recovery methods for acronyms associated with the?Illness?
labels: ?HIV?, ?TB?, ?AIDS?, ?ARV?.4.2 Script specificThe script specific techniques used the same sets ofalternates in the language specific model, but nor-malized such that the heuristic H was applied toa word w in the corpus C resulting in an alternatew?, iff w?
?
C. This method limits the alternatesto those whose existence is supported by the data.It is therefore more conservative than the previousmethod.For more general acronym identification, weadapted the method of Schwartz & Hearst (2003).We created a set of candidate acronyms by iden-tifying capitalized sequences in non-capitalizedcontexts and period-delimited single character se-quences.
All case-insensitive sequences that weresegmented by consistent non-alphabetic characterswere then identified as acronyms, provided that theyended in a non-alphabetic character.
We could notdefine a similar acronym-start boundary, as pre-fixes were often added to acronyms, even when theacronyms themselves contained spaces, eg: ?aT.
B.?.4.3 Language independentFor complete language independence we applied anoise-reduction algorithm to the stream of charac-ters in order to learn the heuristics that representedpotential phonological alternates by identifying allminimal pairs of characters sequences (sequencesthat alternated by one character, include the absenceof a character).Given all sequences of characters, we identifiedall pairs of sequences of length > l that differedby one character c1, where c1 could be null.
Wethen ranked the pairs of alternating sequences by de-scending length and applied a threshold t, selectingthe t longest sequences, creating alternating patternsfrom all pairs.
Regardless of l or t, the resultingheuristics did not resemble those in 4.1 or 4.2.We did not implement any acronym identificationmethods, for obvious reasons.5 ResultsThe results are compared to a baseline system op-timized over word sequences (words and ngramsbut no subword modeling).
All results presentedhere are from a MaxEnt model using a leave-one-out cross-validation.For the English translations of the texts there wasno phonological/orthographic variation beyond thatresulting from morphology, so we only applied thelanguage independent morphological models.5.1 MorphologyWith the exception of the unsupervised stemming,all the morphological models led to substantial gainsin accuracy.
As Table 1 shows, the most accu-rate system used the language specific segmenta-tion, with an average accuracy of F=0.476, a macro-average gain of 22.4%.The greatest increase in accuracy occured whereverbs were the best predictors ?
the words with themost complex morphology.
The ?Response?
labelshowed the greatest relative gain in accuracy forthose with a non-zero baseline, where the accuracyincreased 4-fold from F=0.113 to F=0.442.
It is ex-pected that a label predicated on requests for actionshould rely on the isolation of verb stems, but thisis still a very substantial gain.
In contrast to this391.2% gain in accuracy for Chichewa, the gain for513Baseline Stemmed Segmented Morph-Config GainLabel Chich Indep Chich Indep Chich Indep Best FinalPatient-related 0.830 0.842 0.735 0.857 0.832 0.851 0.867 +3.7 +3.7Clinic-admin 0.358 0.490 0.295 0.612 0.561 0.577 0.580 +25.5 +22.2Technological 0 0 0 0.320 0.174 0.320 0.091 +32.0 +09.1Response 0.113 0.397 0.115 0.440 0.477 0.459 0.442 +36.4 +32.9Request for doctor 0.121 0.312 0.090 0.505 0.395 0.477 0.375 +38.4 +25.4Medical advice 0 0 0 0.083 0.160 0.083 0.083 +16.0 +08.3HIV 0.379 0.597 0 0.554 0.357 0.484 0.351 +21.8 (-2.8)TB 0.235 0.357 0 0.414 0.200 0.386 0.327 +17.8 +09.2Death 0.235 0.333 0.229 0.500 0.667 0.462 0.723 +48.8 +48.8Average.
0.252 0.370 0.163 0.476 0.425 0.455 0.427 +22.4 +17.4Table 1: Morphology results: F-values for leave-one-out cross-validation comparing different morphological models.Indep = language independent, Chich = specific to Chichewa, ( ) = not significant (?
> 0.05, ?2), Final = Gain of the?Morph-Config, Indep?
model over the Baseline.English, while still relying on the isolation of verbstems, only increased the accuracy by 5.4%.The unsupervised stemming underperformed thebaseline model by 8.9%, due to over-segmentation.Compared to the Chichewa stemmer, we estimatethat the unsupervised stemmer had 90-95% recalland 40-50% precision, resulting in over-stemmed to-kens.
However, this seemed to be favor the seg-mented and morph-config models, as unnecessarysegmentation can be recovered when the tokensare sequenced or re-configured, with the supervisedmodel arriving at the optimal weights for each can-didate token or sequence.
This can be seen by com-paring the stemmed and morph-config results forthe Chichewa-specific and language independent re-sults.
The difference in stemming is 20.7% but forthe morph-config models it is only 2.8%.
A loss insegmentation recall could not be recovered in thesame way, as adjacent non-segmented morphemeswill remain one token.
This leads us to conclude thatrecall should be weighted more highly than preci-sion in unsupervised morphological models appliedto supervised classification tasks.5.2 PhonologyFor the phonological models the results in Table 2show that the script-specific model was the most ac-curate with an average of F=0.443, a gain of 19.1%over the baseline.There are correlations between morphologicalvariation and phonological variation, with the gainssimilar for each label in Table 1 and Table 2.
Thisis because much phonological variation often arisesfrom the morphology, as in ndiwodwala where theglide w is pronounced and variably written be-tween the vowels made adjacent through morphol-ogy.
It is also because more morphologically com-plex words are longer and simply have more poten-tial for phonological and written variation.
The weregreater gains in identifying the ?TB?
and ?HIV?
la-bels here than in the morphological models as theresult of acronym identification.The language independent model did not performwell.
Despite changing the data considerably, therewas little change in the accuracy, indicating that thechanges it made were largely random with respectto the target concepts.
The most frequent alterna-tions in large contexts were noun-class prefixes dif-fering by a single character, which has the potentialto change the meaning, and this seemed to negateany gains from normalization.While language independent results would havebeen ideal, a system with script-specific assump-tions is realistic.
It is likely that text messages areregularly sent in 1000s of languages but less than10 scripts, and our definition of ?script specific?would be considered ?language independent?
else-where.
For example, in the Morpho Challenge (see514Baseline Model GainLabel Chichewa Script Indep Best FinalPatient-related 0.830 0.842 0.848 0.838 (+1.8) (+1.8)Clinic-admin 0.358 0.511 0.594 0.358 +23.6 +23.6Technological 0 0.091 0.091 0 +9.1 +9.1Response 0.113 0.420 0.473 0.207 +36.0 +36.0Request for doctor 0.121 0.154 0.354 0 +23.3 +23.3Medical advice 0 0.375 0.222 0.121 +37.5 +22.2HIV 0.379 0.508 0.492 0.379 +12.9 +11.3TB 0.235 0.327 0.492 0.235 +25.7 +25.7Death 0.235 0.333 0.421 0.235 +18.6 +18.6Average 0.252 0.396 0.443 0.264 +19.1 +19.1Table 2: Phonological results: F-values for leave-one-out cross-validation comparing different phonological models.Chichewa = Chichewa specific heuristics, Script = specific to Roman scripts, Indep = language independent, ( ) = notsignificant (?
> 0.05, ?2), Final = Gain of the ?Script?
model over the Baseline.Related Work) Arabic data was converted to Ro-man script, and it is likely that the methods could beadapted with some success to any alphabetic script.5.3 Combined resultsTable 3 gives the final results, comparing the sys-tems over the original text messages and the Englishtranslations of the same messages.
The most accu-rate results were achieved by applying the phono-logical normalization before the morphological seg-mentation, giving a (macro) average of 0.459 whichis an increase of 20.6% over the baseline.
Theincrease in accuracy was not cumulative ?
thecombined system outperforms both the standalonephonological and morphological systems, but with acomparatively modest gain.The final English system is 9.2% more accuratethan the final Chichewa system, but the Chichewasystem has closed the gap considerably as the En-glish baseline system was 25.7% more accurate thanthe baseline Chichewa system.
Assuming that thepotential accuracy is approximately equal (givenboth languages are encoding exactly the same infor-mation) we conclude that we have made substantialgains in accuracy but there are further large gains tobe made.
Therefore, while we have not solved theproblem of text message classification in morpho-logically rich languages, we have been able to makepromising gains in an exciting new area of research.5.4 Practical effectivenessThe FrontlineSMS system currently allows users tofilter messages by keywords, similar to many emailclients.
Because of the large number of variants perword this is sub-optimal in many languages.
We de-fined a second baseline to model an idealized versionof the current system that assumes oracle knowledgeof the keyword/label and the optimal order in whichto apply rules created from this knowledge.
The onlyconstraint was that we excluded words that occurredonly once.
In essence, it is a MaxEnt model that in-cludes seen test items and assigns a label accordingto the single strongest feature for each test item.Here, we evaluated the systems according toMicro-F, recall and precision, as these give a bet-ter gauge of the frequency of error per incomingtext, and therefore the usability for someone need-ing to correct mislabeled texts.
We also calculatedthe Micro-F for each label/non-label decision to giveexact figures per classification decision.
The resultsare in Table 4.
The Micro-F is 0.684 as compared to0.403 for the keyword system.
The higher precisionis also promising, indicating that when we assign alabel we are more often correct.
By adjusting theprecision and recall through label confidence thresh-olds, 90% precision can be achieved with 35.3% re-call.2 In terms of usability, the Label/no-Label re-2We confirmed significance relative to confidence by ROCanalysis ?
results omitted for space.515Chichewa EnglishLabel Baseline Final Sys Gain Baseline Final Sys GainPatient-related 0.830 0.847 (+1.7) 0.878 0.878 0Clinic-admin 0.358 0.624 +26.6 0.682 0.717 (+3.4)Technological 0 0.174 +17.4 0.174 0.320 +14.6Response 0.113 0.476 +36.3 0.573 0.555 (-1.8)Request for doctor 0 0.160 +16.0 0.160 0.357 +19.7Medical advice 0.121 0.500 +37.9 0.560 0.580 (+2.0)HIV 0.379 0.357 (-2.2) 0.414 0.576 +16.2TB 0.235 0.351 +11.6 0.557 0.533 (-2.4)Death 0.235 0.638 +40.3 0.591 0.439 -15.2Average 0.252 0.459 +20.6 0.510 0.551 +4.1Micro F 0.593 0.684 +9.1 0.728 0.737 (+0.9)Table 3: Final Results, comparing the systems in Chichewa and the English translations.sults are very promising, reducing errors from 1 in 4to 1 in 20.The learning rates in Figure 1 show that the learn-ers are converging on accurate models after only see-ing a handful of text messages.
This figure alsomakes it clear that subword processing gives rela-tively little gain to the English translations.
Thedisparity between the final model and the baselinewidens as more items are seen, indicating that thefailure of the word-optimal baseline model is not justdue to a lack of training items.5.5 Other models investigatedMuch recent work in text classification has been inmachine-learning, comparing models over constantfeatures.
We tested SVMs and joint learning strate-gies.
The gains were significant but small and didnot closed the gap between systems with and with-out subword modeling.
We therefore omit these forspace and scope.However, one interesting result came from ex-tending the feature space with topics derived fromLatent Dirichlet Allocation (LDA) using similarmethods to Ramage et al (2009).
This producedsignificant gains (micro-F=0.029), halving the re-maining gap with the English system, but onlywhen the topics were derived from modeling non-contiguous morpheme sequences, not words-aloneor segmented morphemes.
We found that the differ-ent surface forms of each word cooccurred less oftenthan chance (0.46 as often as chance for the differentforms of odwala) forming disjunctive distributions.We suspect that this acts as a bias against robust un-supervised clustering of the different forms.6 Related WorkTo our best knowledge, no prior researchers haveworked on subword models for text message cate-gorization, or any NLP task with the Chichewa, butwe build on many recent developments in computa-tional morphology and NLP for Bantu languages.Badenhorst et al (2009) found substantial varia-tion in a speech recognition corpus for 9 SouthernBantu languages, where accurate models could alsobe built with limited data.
Morphological segmenta-tion improved Swahili-English machine translationin De Pauw et al (2009), even in the absense ofgold standard reference segmentations, as was thecase here.
The complexity and necessity of model-ing non-contiguous morphemes in Bantu languagesis discussed by Pretorius et al (2009).Computational morphology (Goldsmith, 2001;Creutz, 2006; Kurimo et al, 2008; Johnson andGoldwater, 2009; Goldwater et al, 2009) has be-gun to play a prominent role in machine transla-tion and speech recognition for morphologically richlanguages (Goldwater and McClosky, 2005; Tach-belie et al, 2009).
In the current-state-of-the-art, acombination of the ParaMor (Monson et al, 2008)and Morfessor (Creutz, 2006) algorithms achieved5160.650.75 0.450.5510%100%Chichewa BaselineChichewa FinalEnglish BaselineEnglish FinalFigure 1: The learning rate, comparing micro-F for theChichewa and English systems on different training setsizes.
A random stratified sample was used for subsets.the most accurate results in 2008 Morpho ChallengeWorkshop (Kurimo et al, 2008).
ParaMor assumesa single affix and is not easily adapted to more com-plex morphologies, but we were able to test and eval-uate Morfessor and the earlier Linguistica (Gold-smith, 2001).
Both were more accurate for segmen-tation than our adaptation of Goldwater et al (2009),but with lower recall.
For the reasons discussed inSection 5.3 this meant less accuracy in classification.Goldwater et al have also used the Pitman-Yor algo-rithm for morphological modeling (Goldwater et al,2006).
In results too recent to test here, Pitman-Yorhas been used for segmentation with accuracy com-parable to the HDPmodel but with greater efficiency(Mochihashi et al, 2009).
Biosurveillance systemscurrently use simple rule-based pre-processing forsubword models.
Dara et al (2008) found only mod-est gains, although the data was limited to English.For text message classification, prior work is lim-ited to identifying SPAM (Healy et al, 2005; Hi-dalgo et al, 2006; Cormack et al, 2007), wherespecialized algorithms and feature representationswere also found to improve accuracy.
For writtenvariation, Kobus et al (2008) focussed on SMS-specific abbreviations in French.
Unlike their data,SMS-specific abbreviations were not present in ourdata.
This is consistent with the reports on SMSpractices in the related isiXhosa language (Deumertand Masinyana, 2008), but it may also be becausethe data we used contained professional communi-cations not personal messages.Label class Label/No-LabelKWF Final KWF FinalF-val 0.403 0.684 0.713 0.950Prec.
0.265 0.796 0.570 0.972Rec.
0.842 0.599 0.953 0.929Table 4: Micro-F, precision and recall, compared with theoracle keyword system.
KWF = Oracle Keyword Filter.7 ConclusionsWe have demonstrated that subword modeling inChichewa leads to significant gains in classifyingtext messages according to medical labels, reducingthe error from 1 in 4 to 1 in 20 in a system that shouldgeneralize to other languages with similar morpho-logical complexity.The rapid expansion of cellphone technologieshas meant that digital data is now being generatedin 100s, if not 1000s, of languages that have notpreviously been the focus of language technologies.The results here therefore represent just one of alarge number of potential new applications for short-message classification systems.AcknowledgementsThank you to FrontlineSMS:Medic and the healthcare workers they partner with.
The first author wassupported by a Stanford Graduate Fellowship.ReferencesJaco Badenhorst, Charl van Heerden, Marelie Davel, andEtienne Barnard.
2009.
Collecting and evaluatingspeech recognition corpora for nine Southern Bantulanguages.
In The EACLWorkshop on Language Tech-nologies for African Languages.Piet Buys, Susmita Dasgupta, Timothy S. Thomas, andDavidWheeler.
2009.
Determinants of a digital dividein Sub-Saharan Africa: A spatial econometric analysisof cell phone coverage.
World Development, 37(9).Gordon V. Cormack, Jose?
Mara Go?mez Hidalgo, and En-rique Puertas Sa?nz.
2007.
Feature engineering formobile (SMS) spam filtering.
In The 30th annual in-ternational ACM SIGIR conference on research anddevelopment in information retrieval.Mathias Creutz.
2006.
Induction of the Morphology ofNatural Language: Unsupervised Morpheme Segmen-tation with Application to Automatic Speech Recogni-tion.
Ph.D. thesis, University of Technology, Helsinki.517Jagan Dara, John N. Dowling, Debbie Travers, Gre-gory F. Cooper, and Wendy W. Chapman.
2008.Evaluation of preprocessing techniques for chief com-plaint classification.
Journal of Biomedical Informat-ics, 41(4):613?23.Ana Deumert and Sibabalwe Oscar Masinyana.
2008.Mobile language choices: the use of English and isiX-hosa in text messages (SMS) evidence from a bilin-gual South African sample.
English World-Wide,29(2):117?147.John Goldsmith.
2001.
Unsupervised learning of themorphology of a natural language.
ComputationalLinguistics, 27(2):153?198.Sharon Goldwater and David McClosky.
2005.
Improv-ing statistical MT through morphological analysis.
InHuman Language Technology Conference and Confer-ence on Empirical Methods in Natural Language Pro-cessing.Sharon Goldwater, Thomas L. Griffiths, and Mark John-son.
2006.
Interpolating between types and tokens byestimating power-law generators.
Advances in NeuralInformation Processing Systems, 18.Sharon Goldwater, Thomas L. Griffiths, and Mark John-son.
2009.
A bayesian framework for word segmen-tation: Exploring the effects of context.
Cognition,112(1):21?54.Matt Healy, Sarah Jane Delany, and Anton Zamolotskikh.2005.
An assessment of case-based reasoning forShort Text Message Classification.
In The 16th IrishConference on Artificial Intelligence & Cognitive Sci-ence.Jose?
Mara Go?mez Hidalgo, Guillermo Cajigas Bringas,Enrique Puertas Sa?nz, and Francisco Carrero Garca.2006.
Content based SMS spam filtering.
In ACMsymposium on Document engineering.Scott Isbrandt.
2009.
Cell Phones in West Africa: im-proving literacy and agricultural market informationsystems in Niger.
White paper: Projet Alphabe?tisationde Base par Cellulaire.Abi Jagun, Richard Heeks, and Jason Whalley.
2008.The impact of mobile telephony on developing countrymicro-enterprise: A Nigerian case study.
InformationTechnologies and International Development, 4.Mark Johnson and Sharon Goldwater.
2009.
Improvingnonparameteric Bayesian inference: experiments onunsupervised word segmentation with adaptor gram-mars.
In Human Language Technologies.Catherine Kobus, Franc?ois Yvon, and Gee?raldineDamnati.
2008.
Normalizing SMS: are twometaphorsbetter than one?
In The 22nd International Confer-ence on Computational Linguistics.Mikko Kurimo, Matti Varjokallio, and Ville Turunen.2008.
Unsupervised morpheme analysis.
In MorphoChallenge Workshop, Finland.
Helsinki University ofTechnology.Carole Leach-Lemens.
2009.
Using mobile phones inHIV care and prevention.
HIV and AIDS Treatment inPractice, 137.Sam Mchombo.
2004.
The Syntax of Chichewa.
Cam-bridge University Press, New York, NY.Daichi Mochihashi, Takeshi Yamada, and Naonori Ueda.2009.
Bayesian unsupervised word segmentation withnested Pitman-Yor language modeling.
In The 47thAnnual Meeting of the Association for ComputationalLinguistics.ChristianMonson, Jaime Carbonell, Alon Lavie, and LoriLevin.
2008.
ParaMor: finding paradigms across mor-phology.
Lecture Notes in Computer Science, 5152.Robert Munro.
2010.
Haiti Emergency Response: thepower of crowdsourcing and SMS.
In Haiti Crisis Re-lief 2.0, Stanford, CA.Steven Paas.
2005.
English Chichewa-Chinyanja Dictio-nary.
Mvunguti Books, Zomba, Malawi.Guy De Pauw, Peter Waiganjo Wagacha, and Gilles-Maurice de Schryver.
2009.
The SAWA Corpus: aparallel corpus of English - Swahili.
In The EACLWorkshop on Language Technologies for African Lan-guages.Gareth Peevers, Gary Douglas, and Mervyn A. Jack.2008.
A usability comparison of three alternative mes-sage formats for an SMS banking service.
Interna-tional Journal of Human-Computer Studies, 66.Rigardt Pretorius, Ansu Berg, Laurette Pretorius, andBiffie Viljoen.
2009.
Setswana tokenisation and com-putational verb morphology: Facing the challenge ofa disjunctive orthography.
In The EACL Workshop onLanguage Technologies for African Languages.Daniel Ramage, David Hall, Ramesh Nallapati, andChristopher D. Manning.
2009.
Labeled LDA: Asupervised topic model for credit attribution in multi-labeled corpora.
In Proceedings of the 2009 Confer-ence on Empirical Methods in Natural Language Pro-cessing, Singapore.Ariel S. Schwartz and Marti A. Hearst.
2003.
A sim-ple algorithm for identifying abbreviation definitionsin biomedical texts.
In The Pacific Symposium on Bio-computing, University of California, Berkeley.Martha Yifiru Tachbelie, Solomon Teferra Abate, andWolfgang Menzel.
2009.
Morpheme-based languagemodeling for amharic speech recognition.
In The 4thLanguage and Technology Conference.Yee Whye Teh, Michael I. Jordan, Matthew J. Beal, andDavid M. Blei.
2005.
Hierarchical Dirichlet pro-cesses.
In Advances in Neural Information ProcessingSystems, 17.518
