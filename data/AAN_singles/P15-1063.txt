Proceedings of the 53rd Annual Meeting of the Association for Computational Linguisticsand the 7th International Joint Conference on Natural Language Processing, pages 645?655,Beijing, China, July 26-31, 2015. c?2015 Association for Computational LinguisticsOmnia Mutantur, Nihil Interit: Connecting Past with Present by Find-ing Corresponding Terms across TimeYating Zhang*, Adam Jatowt*, Sourav S Bhowmick+, Katsumi Tanaka**School of Informatics, Kyoto University+School of Computer Engineering, Nanyang Technological University{zhang,adam,tanaka}@dl.kuis.kyoto-u.ac.jpassourav@ntu.edu.sgAbstractIn the current fast-paced world, people tend topossess limited knowledge about things fromthe past.
For example, some young users maynot know that Walkman played similar func-tion as iPod does nowadays.
In this paper, weapproach the temporal correspondence prob-lem in which, given an input term (e.g., iPod)and the target time (e.g.
1980s), the task is tofind the counterpart of the query that existedin the target time.
We propose an approachthat transforms word contexts across timebased on their neural network representations.We then experimentally demonstrate the ef-fectiveness of our method on the New YorkTimes Annotated Corpus.1 IntroductionWhat music device 30 years ago played similarrole as iPod does nowadays?
Who are today?sBeatles?
Who was a counterpart of President Chi-rac in 1988?
These and many other similar ques-tions may be difficult to answer by average users(especially, by young ones).
This is because peo-ple tend to possess less knowledge about the pastthan about the contemporary time.In this work we propose an effective method tosolve the problem of finding counterpart termsacross time.
In particular, for an input pair of aterm (e.g., iPod) and the target time (e.g.
1980s),we find the corresponding term that existed in thetarget time (walkman).
We consider temporalcounterparts to be terms which are semanticallysimilar, yet, which existed in different time.Knowledge of temporal counterparts can helpto alleviate the problem of terminology gap for us-ers searching within temporal document collec-tions such as archives.
For example, given a user?squery and the target time frame, a new modifiedquery that represents the same meaning could besuggested to improve search results.
Essentially,it would mean letting searchers use the knowledgethey possess on the current world to performsearch within unknown collections such as onescontaining documents from the distant past.
Fur-thermore, solving temporal correspondence prob-lem can help timeline construction, temporal sum-marization, reference forecasting and can have ap-plications in education.The problem of temporal counterpart detectionis however not trivial.
The key difficulty comesfrom the change of the entire context that resultsin low overlap of context across time.
In otherwords, it is difficult to find temporal counterpartterms by directly comparing context vectorsacross time.
This fact is nicely portrayed by theLatin proverb: ?omnia mutantur, nihil interit?
(inEnglish: ?everything changes, nothing perishes?
)which indicates that there are no completely staticthings, yet, many things and concepts are still sim-ilar across time.
Another challenge is the lack oftraining data.
If we have had enough training pairsof input terms and their temporal counterparts,then it would have become possible to representthe task as a typical machine learning problem.However, it is difficult to collect multiple trainingpairs over various domains and for arbitrary time.In view of the challenges mentioned above, wepropose an approach that transforms term repre-sentations from one vector space (e.g., one de-rived from the present documents) to another vec-tor space (e.g., one obtained from the past docu-ments).
Terms in both the vector spaces are repre-sented by the distributed vector representation(Mikolov et al 2013a; Mikolov et al 2013c).
Ourmethod then matches the terms by comparingtheir relative positions in the vector spaces of dif-ferent time periods alleviating the problem of lowoverlap between word contexts over time.
It alsodoes not require to manually prepare seed pairs oftemporal counterparts.
We further improve thismethod by automatically generating referencepoints that more precisely represent target termsin the form of local graphs.
In result, our approachconsists of finding global and local correspond-ence between terms over time.645To sum up, we make the following contribu-tions in this paper: (1) we propose an efficientmethod to find temporal counterparts by trans-forming the representation of terms within differ-ent temporal spaces, (2) we then enhance theglobal correspondence method by consideringalso the local context of terms (local correspond-ence) and (3) we perform extensive experimentson the New York Times Annotated Corpus(Sandhaus, 2008), including the search from thepresent to the past and vice versa, which prove theeffectiveness of our approach.2 Global  Correspondence Across TimeLet the base time denoted as TB mean the time pe-riod associated with the input term and let the tar-get time, TT, mean the time period in which wewant to find this term?s counterparts.
Typically,for users, the base time is the present time and thetarget time is some selected time period in thepast.
Note however, that we do not impose any re-striction on the order and the distance of the bothtimes.
Hence, it is possible to search for presentcounterparts of terms that existed in the past.In our approach we first represent all the termsin the base time and in the target time within theirrespective semantic vector spaces, ?B and ?T.Then, we construct a transformation matrix tobridge the two vector spaces.
Algorithm 1 sum-marizes the procedures needed to compute theglobal transformation.
We will explain it in Sec-tion 2.1 and 2.2.Algorithm 1 Overview of Global TransformationInput: query q, base time TB and target time TT1.
Construct word representation model forcorpus in the base time, D(TB), and in thetarget time, D(TT).
(Section 2.1)2.
Construct transformation matrix M be-tween D(TB) and D(TT) by first collectingCFTs as training pairs and then learning Musing Eq.
1.
(Section 2.2)3.
Rank the words in target time by their cor-respondence scores (Eq.
2)Output: ranked list of temporal counterparts2.1 Vector space word representationsDistributed representation of words by neuralnetwork was first proposed by Rumelhart et al(1986).
More recently, Mikolov et al (2013a,2013c) introduced the Skip-gram model whichutilizes a simplified neural network architecturefor learning vector representations of words fromunstructured text data.
We apply this model due toits advantages: (1) it can capture precise semanticword relationships; (2) due to the simplified neu-ral network architecture, the model can easilyscale to millions of words.
After applying theSkip-gram model, the documents in the base time,D(TB), are converted to a m?p matrix where n isthe vocabulary size and p are the dimensions offeature vectors.
Similarly, the documents in thetarget time, D(TT), are represented as a n?q matrix(as shown in Fig.
1).Figure 1: Word vector representations for the baseand the target time.2.2 Transformation across vector spacesOur goal is to compare words in the base time andthe target time in order to find temporal counter-parts.
However, it is impossible to directly com-pare words in two different semantic vectorspaces, as the features in both spaces have no di-rect correspondence between each other (as can beseen in Fig.
1).
To solve this problem, we proposeto train a transformation matrix in order to buildthe connection between different vector spaces.The key idea is that the relative positions of wordsin each vector space should remain more or lessstable.
In other words, a temporal counterpartterm should have similar relative position in itsown vector space as the position of the queriedterm in the base time space.
Fig.
2 conceptuallyportrays this idea as the correspondence betweenthe context of Walkman and the context of iPod(only two dimensions are shown for simplicity).Figure 2: Conceptual view of the across-timetransformation by matching similar relative geo-metric positions in each space.Our task is then to train the transformation ma-trix to automatically ?rotate?
the base vector spacebase time(e.g.
2003-2007)target time(e.g.
1987-1991)tVector SpaceRepresentationTraining by usingSkip-gram modelTraining by usingSkip-gram modelbase time(e.g.
2003-2007)target time(e.g.
1987-1991)walkmancassettemusiciP dmp3music646into the target vector space.
Suppose we have Kpairs of temporal counterparts {(?1, w1),?,(?k,wk,)} where ?i is a base time term and wi is itscounterpart in the target time.
Then the transfor-mation matrix ?
can be computed by minimizingthe differences between ??
?i and wi as given inEq.
1.
The latter part of Eq.
1 is added as regular-ization to overcome the problem of overfitting.
In-tuitively, matrix M is obtained by making sure thatthe sum of Euclidean 2-norms between trans-formed query vectors and their counterparts isminimal on K seed query-counterpart pairs.
Eq.1is used for solving regularized least squares prob-lem (?
equals to 0.02).22122minarg MwMMKi iiM??
????
??
(1)However, as mentioned before, the other chal-lenge is that the training pairs are difficult to beobtained.
It is non-trivial to prepare large enoughtraining data that would also cover various do-mains and any possible combinations of the baseand target time periods.
We apply here a simpletrick that performs reasonably well.
We selectterms that (a) have the same syntactic forms in thebase and the target time periods and (b) are fre-quent in the both time periods.
Such CommonFrequent Terms (CFTs) are then used as the train-ing data.
Essentially, we assume here that veryfrequent terms (e.g., man, women, water, dog, see,three) change their meanings only to small extent.The reasoning is that the more frequently the wordis used, the harder is to change its dominant mean-ing (or the longer time it takes to make the mean-ing shift) as the word is commonly used by manypeople.
The phenomenon that words used moreoften in everyday language had evolved moreslowly has been observed in several languages in-cluding English, Spanish, Russian and Greek(Pargel et al, 2007; Lieberman et al 2007).
Then,using the common frequent terms as the trainingpairs, we solve Eq.
1 as the least squares problem.Note that the number of CFTs is heuristically de-cided.
In Sec.
5 we discuss transformation perfor-mance with regards to different numbers of CFTs.After obtaining matrix ?, we can then trans-form the base time term, q, first by multiplying itsvector representation with the transformation ma-trix ?, and then by calculating the cosine similar-ity between such transformed vector and the vec-tors of all the terms in the target time.
We call theresult of this similarity comparison the corre-spondence score between the input term q in thebase time and a given term w in the target time(see Eq.
2).
A term which has the highest corre-spondence score could be then considered as tem-poral counterpart of q.?
?
?
?wqMwqenceCorrespond ,cos, ??
(2)3 Local Correspondence across TimeThe method described above computes ?globalsimilarity?
between terms across time.
In result,the discovered counterparts can be similar to thequery term for variety of reasons, some of whichmay not always lead to the best results.
For in-stance, the global transformation finds VCR as thetemporal counterpart of iPod in 1980s simply be-cause both of them can have recording and play-back functions.
Macintosh is another term judgedto be strongly corresponding to iPod since bothare produced by Apple.
Clearly, although VCRand Macintosh are somewhat similar to iPod, theyare far from being its counterparts.
The globaltransformation, as presented in the previous sec-tion, may thus fail to find correct counterparts dueto neglecting fundamental relations between aquery term and its context.Inspired by these observations, we propose an-other method for leveraging the informative con-text terms of an input query term called referencepoints.
They are used to help mapping the queryto its correct temporal counterpart by consideringthe relation between the query and the referencepoints.
We call this kind of similarity matching aslocal correspondence in contrast to global corre-spondence described in Sec.
2.
In the followingsub-sections, we first introduce the desired char-acteristics of the reference points and we then pro-pose three computation methods for selectingthem.
Finally, we describe how to find temporalcounterparts using the selected reference points.Algorithm 2 shows the process of computing thelocal transformation.Algorithm 2 Overview of Local TransformationInput: query q, base time TB and target time TT1.
Construct the local graph of q by detectingthe reference points in the context of q.
(Section 3.1)2.
Compute similarity of the local graph of qwith all the local graphs of candidate tem-poral counterparts in the target time.
(Sec-tion 3.2)3.
Rank the candidate temporal counterpartsin the target time by graph similarity score(Eq.
4).Output: ranked list of temporal counterparts6473.1 Reference points detectionReference points are terms in the query?s contextwhich help to build connection between the queryand its temporal counterparts.
Reference pointsshould have at least some of the following charac-teristics: (a) have high relation with the query (b)be sufficiently general and (c) be independentfrom each other.Note that it does not mean that the selected ref-erence point should have exactly same surfaceform across time.
Let us consider the previous ex-ample query iPod and 1980s as the target time.The term music could be a candidate referencepoint for this query.
Its temporal counterpart hasexactly the same syntax form in the target time(music).
However, mp3 could be another refer-ence point.
Even though mp3 did not exist in1980s, it can still be referred to storage devices atthe target time such as cassette or disk helpingthus to find the correct counterparts of iPod, thatis, walkman and CD player.Since different reference points will lead to dif-ferent answers, we propose three methods for se-lecting the reference points.
Each one considersthe previously mentioned characteristics of refer-ence points to different extent.
Note that, if neces-sary, the choice of the references points can be leftto users.Term co-occurrence.
The first approach satis-fies the reference points?
characteristics of beingrelated to the query.
To select reference points us-ing this approach we rank context terms by multi-plying two factors: tf(c) and relatedness(q,c),where tf(c) is the frequency of a context term c,while relatedness(q,c) is the relation strength of qand c measured by the ?2 test.
The test is con-ducted based on the hypothesis thatP(c|q)=P(c|q?
), according to which the term c hasthe same probability of occurring in documentscontaining query q and in the documents not con-taining q.
We then use the inverse of the p-valueobtained from the test as relatedness(q,c).Lexico-syntactic patterns.
As the second ap-proach we propose using hypernyms of terms.This corresponds to the characteristic of referencepoints to be general words.
General terms are pre-ferred rather than specific or detailed ones sincethe former are more probable to be associated withcorrect temporal counterparts1 .
This is becausedetailed or specific terms are less likely to havecorresponding terms in the target time.
To detect1 We have experimented with hyponyms and coordinateterms used as reference points and found the results areworse than when using hypernyms.hypernyms on the fly, we adopt the method pro-posed by Ohshima et al (2010) that uses bi-direc-tional lexico-syntactic patterns due to its highspeed and the lack of requirements for using ex-ternal ontologies.
The latter is important since, tothe best of our knowledge, there are no ready on-tology resources for arbitrary periods in the past(e.g., there seems to be no Wordnet for the past).Semantic clustering.
The last method choosesreference points from clusters of context terms.The purpose of applying clustering is to avoidchoosing semantically similar reference points.Clustering helps to select typical terms from dif-ferent sematic clusters to provide diverse informa-tive context.For grouping the context terms we utilize thebisecting k-means algorithm.
It is superior over k-means and the agglomerative approach (Steinbachet al, 2000) in terms of accuracy.
The procedureof bisecting k-means is to, first, select a cluster tosplit and then to utilize the basic k-means to formtwo sub-clusters.
These two steps are repeated un-til the desired number of clusters is obtained.
Thedistance between any two terms w1, w2 is the in-verse of cosine similarity between their vectorrepresentations.
),cos(1),( 2121 wwwwDist ??
(3)3.2 Local graph matchingFormulation.
The local graph of query q is astar shaped graph, denoted as SqFB, in which q isthe internal node, and the set of reference points,?B = {f1, f2,?, fu}, are leaf nodes where u is thenumber of reference points.
Our objective is tofind a local graph SwFT in the target vector spacethat is most similar to SqFB in the base vector space.w denotes here the temporal counterpart of q andFT is the set of terms in the target vector space thatcorresponds to FB.Algorithm.
Step (1): to compare the similaritybetween two graphs in different vector spaces,every node (i.e.
term) in SqFB is required to betransformed first to allow for comparison underthe same vector space.
So the transformed vectorrepresentation of q becomes ?
?q and FB is trans-formed to {?
?f1, ?
?f2 ?, ?
?fu} (recall that ?
isthe transformation matrix).
Step (2): for each nodein SqFB, we then choose the top k candidate termswith the highest correspondence score in the tar-get space.
Note that we would need to perform k?ku648combinations of nodes (or candidate local graphs)in total, to find the best graph with the highestgraph similarity.
The computation time becomesthen an issue as the number of comparisons growsin polynomial way with the increase in the numberof candidate terms.
However, we manage to re-duce the number of combinations to k?k?u by as-suming the reference points be independent ofeach other.
Then, for every selected candidatetemporal counterpart, we only choose the set ofcorresponding terms FT which maximizes the cur-rent graph similarity.
By default we set k equal to1000.
The process is shown in Algorithm 3.Algorithm 3 Local Graph MatchingInput: local graph of q, SqFBW = top k corresponding terms of q (by Eq.
2)FF = {top k corresponding terms of each f inreference points FB={ f0, f1, ?, fu}} (by Eq.
2)for w = W[1:k] do:sum_cos = 0  # total graph similarity scorefor F = FF[1:u] do:max_cos = 0 # current maximum similar-ityfor c = F[1:k] do:find c which maximizes current graphsimilarityend forsum_cos += max_cosend forend forsort W by sum_cos of each w in W.Output: sorted W as ranked list of temporalcounterpartsGraph similarity computation.
To computethe similarity of two star shaped graphs, we takeboth the semantic and relational similarities intoconsideration.
Fig.
3 conceptually portrays thisidea.
Since all the computation is done under thesame vector space (after transformation), the se-mantic meaning is represented by the absolute po-sition of the term, that is, by its vector representa-tion in the vector space.
On the other hand, the re-lation is described by the difference of two termvectors.
Finally, the graph similarity functiong(SqFB,SwFT) is defined as the combination of therelational similarity function, h(SqFB,SwFT), and se-mantic similarity function, z(SqFB,SwFT), as follows:)),cos(),cos(max()(max)1(),(),()1(),(,,??????????????????TTBBTTBBTBTBTBTBFfFfTBFfFffwfqFwFqFwFqFwFqwqffRRSSzSShSSg????
(4)where RqfB is the difference of vectors between qand fB in FB represented as [q-fB].
RwfT is the differ-ence of vectors between w and fT in FT, [w-fT],where fT is selected from k candidates correspond-ing terms of fB.
fT maximizes the cosine similaritybetween [q- fB] and [w- fT].
?
is set to 0.5 by de-fault.
Intuitively, SqFB is a graph composed ofquery and its reference points, while SwFT is agraph containing candidate word w and its refer-ence points.
The first maximum in Eq.
4 finds foreach reference point in the base time, fB, the top-kcandidate terms corresponding to fB in the targettime.
Next, it finds within k such fT that similaritybetween [q- fB] and [w- fT] is maximum (relationalsimilarity).
The second maximum in Eq.
4 is sameas the first one with the exception that it computesthe semantic similarity instead of the relationalsimilarity.
The two summations in Eq.
4 aggregateboth the similarity scores over all the referencepoints.Figure 3: The concept of computing semantic andrelational similarity in matching local graphs.4 Experimental Setup4.1 Training setsFor the experiments we use the New York TimesAnnotated Corpus (Sandhaus, 2008).
This datasetcontains over 1.8 million newspaper articles pub-lished between 1987 and 2007.
We first divide itinto four parts according to article publicationtime: [1987-1991], [1992-1996], [1997-2001] and[2002-2007].
Each time period contains thenaround half a million articles.
We next train themodel of distributed vector representation sepa-rately for each time period.
The vocabulary sizeof the entire corpus is 360k, while the vocabularysize of each time period is around 300k.In the experiments, we first focus on the pair oftime periods separated by the longest time gap,that is, [2002, 2007] as the base time and [1987,1991] as the target time.
We also repeat the exper-iment using more recent target time: [1992, 1996].base time(e.g.
2003-2007)ipodp3musicappletarget time(e.g.
1987-1991)musiccassettewalkmansonysemantic similarityrelational similarity649Table 1: Example results where q is the input term and tc is the matching temporal counterpart.
Thenumbers are the ranks of the correct temporal counterpart in the results ranked by each method.
Sincewe output only the top 1000 results, ranks lower than 1000 are represented as 1000+.4.2 Test setsAs far as we know there is no standard test benchfor temporal correspondence finding.
We then hadto manually create test sets containing queries inthe base time and their correct temporal counter-parts in the target time.
In this process we usedexternal resources including the Wikipedia, aWeb search engine and several historical text-books.
The test terms cover three types of entities:persons, locations and objects.The examples of the test queries and their tem-poral counterparts for [1987, 1991] are shown inTable 1 where q denotes the input term and tc isthe correct counterpart.
Note that the expected an-swer is not required to be single neither exhaus-tive.
For example, there can be many answers forthe same query term, such as letter, mail, fax, allbeing commonly used counterparts in 1980s foremail.
Furthermore, as we do not care for recall inthis research, we do not require all the correctcounterpart terms to be found.
In total, there are95 pairs of terms (query and its counterpart) re-sulting from 54 input query terms for the task ofmapping [2002, 2007] with [1987, 1991], and 50term pairs created from 25 input query terms formatching [2002, 2007] and [1992, 1996].4.3 Evaluation measures and baselinesWe use the Mean Reciprocal Rank (MRR) as amain metric to evaluate the ranked search resultsfor each method.
MRR is expressed as the meanof the inverse ranks for each test where a correctresult appears.
It is calculated as follows:???
Ni irankNMRR 111  (5)where ranki is the rank of a correct counterpart atthe i-th test.
N is the number of query-answerpairs.
MRR?s values range between [0,1].
Thehigher the value, the more correct the method is.Besides MRR, we also report precision @1, @5,@10 and @20.
They are equal to the rates of testsin which the correct counterpart term tc was foundin the top 1, 5, 10 and 20 results, respectively.Baselines.
We prepare three baselines:(1) Bag of words approach (BOW) withouttransformation: this method directly compares thecontext of the query in the base time with the con-text of the candidate term in the target time.
Weuse it to examine whether the distributed vectorrepresentation and transformation are necessary.
(2)  Latent Semantic Indexing (LSI) withouttransformation (LSI-Com): we first merge thedocuments in the base time and the documents inthe target time.
Then, we train LSI (Deerwester,1988) on such combined collection to representeach term by the same distribution of detected top-ics.
We next search for the terms that exist in thetarget period and that are also semantically similarto the queried terms by comparing their vectorq[2002,2007]tc[1987,1991]BOW(baseline)LSI-Com(baseline)LSI-Tran(baseline)GT(proposed)LT-Cooc(proposed)LT-Lex(proposed)LT-Clust(proposed)Putin Yeltsin 1000+ 252 353 24 1 1 1Chirac Mitterrand 1000+ 8 1 7 19 1 3iPod Walkman 1000+ 20 131 3 13 1 16Merkel Kohl 1000+ 1000+ 537 142 76 7 102Facebook Usenet 1000+ 1000+ 1000+ 1 1 1 1Linux Unix 1000+ 11 1 20 1 1 1email letter 1000+ 1000+ 464 1 35 1 17email mail 1000+ 1 9 7 2 6 11email fax 1000+ 1000+ 10 3 1 4 2Pixar Tristar 1000+ 549 1 1 1 1 1Pixar Disney 1000+ 4 4 3 2 2 4Serbia Yugoslavia 1000+ 15 1000+ 1 1 1 1mp3 compact disk 1000+ 56 44 58 17 19 22Rogge Samaranch 1000+ 4 22 42 82 34 44Berlin Bonn 1000+ 43 265 62 40 48 56Czech Czechoslovakia 1000+ 1 3 4 3 7 4USB floppy disk 1000+ 209 1000+ 20 1 1 4spam junk mail 1000+ 1000+ 37 5 61 1 1Kosovo Yugoslavia 1000+ 59 1000+ 14 10 6 11650representations.
The purpose of using LSI-Com isto check the need for the transformation over time.
(3) Latent Semantic Indexing (LSI) withtransformation (LSI-Tran): we train two LSImodels separately on the documents in the basetime and the documents in the target time.
Thenwe train the transformation matrix in the sameway as we did for our proposed methods.
Lastly,for a given input query, we compare its trans-formed vector representation with terms in the tar-get time.
LSI-Tran is used to investigate if LSI canbe an alternative for the vector representation un-der our transformation scenario.Proposed Methods.
All our methods use theneural network based term representation.
Thefirst one is the method without considering the lo-cal context graph called GT (see Sec.
2).
By test-ing it we want to investigate the necessity of trans-forming the context of the query in the target time.We also test the three variants of the proposedapproach that applies the local graph (explained inSec.
3).
The first one, LT-Lex, constructs the lo-cal graph by using the hypernyms of terms.
LT-Cooc applies term co-occurrence to select the ref-erence points.
Finally, LT-Clust clusters the con-text terms by their semantic meanings and selectsthe most common term from each cluster.4.4 Parameter settingsWe set the parameters as follows:(1) num_of_dim: we experimentally set the num-ber of dimensions of the Skip-gram model and thenumber of topics of LSI to be 200.
(2) num_of_CFTs: we utilize the top 5% (18kwords) of Common Frequent Terms to train thetransformation matrix.
We have tried other num-bers but we found 5% to perform best (see Fig.
4).
(3) u: the number of reference points (same as thenumber of semantic clusters) is set to be 5.
Ac-cording to the results, we found that increasing thenumber of reference points does not always im-prove the results.
The performance depends ratheron whether the reference points are generalenough, as too detailed ones hurt the results.5 Experimental ResultsFirst, we look at the results of finding temporalcounterparts in [1987, 1991].
The average scoresfor each method are shown in Table 2.
Table 1shows detailed results for few example queries.The main finding is that all our methods outper-form the baselines when measured by MRR andby the precisions at different ranks.
In the follow-ing subsections we discuss the results in detail.5.1 Context change over timeThe first observation is that the task is quite diffi-cult as evidenced by extremely poor performanceof the bag of words approach (BOW).
The correctanswers in BOW approach are usually found atranks 10k-30k (recall that the vocabulary size is360k).
This suggests little overlap in the contextsof query and counterpart terms.
The fact that allour methods outperform the baselines suggeststhat the across-time transformation is helpful.5.2 Using local context graphWe can observe from Table 2 that, in general, us-ing the local context graph improves the results.The best performing approach, LT-Lex, improvesGT method, which uses only global similaritymatching, by 24% when measured using MRR.
Itincreases the precision at certain levels of topranks, especially, at the top 1, where it boosts theperformance by 44%.
LT-Lex uses the hyper-nyms of query as reference points in the localgraph.
This suggests that using generalized con-text terms as reference points is most helpful forfinding correct temporal counterparts.
On theother hand, LT-Cooc and LT-Clust usually fail toimprove GT.
It may be because the term co-oc-currence and semantic clustering approaches de-tect less general terms that tend to capture too de-tailed information which is then poorly related tothe temporal counterpart.
For example, LT-Coocdetects {music, Apple, computer, digital, iTunes}as the reference points of the query iPod.
Whilemusic is shared by iPod?s counterpart (walkman)and Apple can be considered analogical to Sony,other terms (i.e., computer, digital, iTunes) are ra-ther too specific and unique for iPod.5.3 Using neural network modelWhen comparing the results of LSI-Com andLSI-Tran in Table 2, we can see that using thetransformation does not help LSI to enhance theperformance but, on the contrary, it makes the re-sults worse.Method MRR P@1 P@5 P@10 P@20BOW 4.1E-5 0 0 0 0LSI-Com 0.206 15.8 27.3 29.5 38.6LSI-Tran 0.112 7.9 13.6 21.6 22.7GT 0.298 16.8 44.2 56.8 73.7LT-Cooc 0.283 18.8 35.3 50.6 62.4LT-Lex 0.369 24.2 49.5 63.2 71.6LT-Clust 0.285 14.7 42.1 55.1 65.2Table 2: Results of searching from present to past(present: 2002-2007; past: 1987-1991).651Yet, as discussed above, applying the transfor-mation is good idea in the case of the Neural Net-work Model.
We believe the reason for this is be-cause it is difficult to perform the global transfor-mation between topics underling the dimensionsof LSI, in contrast to transforming ?semantic di-mensions?
of Neural Network Model.5.4 Effect of the number of CFTsFig.
4 shows MRR results for different numbersof Common Frequent Terms (CFTs) when apply-ing GT method.
Note that the level of 0.10% (thefirst point) corresponds to using 658 stop words asseed pairs.
As mentioned before, 5% of CFTs al-lows to obtain the best results.Figure 4: Results of MRR for GT method depend-ing on number of used CFTs.5.5 Searching from past to presentWe next analyze the case of searching from thepast to the present.
This scenario may apply to thecase of a user (perhaps, an older person) who pos-sesses knowledge about the past term but does notknow its modern counterparts.Table 3 shows the performance.
We can seethat, again, all our approaches outperform all thebaselines using all the measures.
LT-Lex is thebest performing approach, when measured byMRR and P@1 and P@20.
LT-Cooc this time re-turns the best results at P@5 and P@10.Method MRR P@1 P@5 P@10 P@20BOW 3.4E-5 0 0 0 0LSI-Com 0.181 13.2 19.7 28.9 35.5LSI-Tran 0.109 5.3 17.1 21.1 23.7GT 0.226 15.2 27.3 33.3 45.5LT-Cooc 0.231 14.7 30.7 36 46.7LT-Lex 0.235 16.7 28.8 31.8 48.5LT-Clust 0.228 13.6 28.8 31.8 47Table 3: Average scores of searching from past topresent (present: 2002-2007; past: 1987-1991).The objective of testing the search from the pastto present is to prove our methods work in bothdirections.
As for now, we can only conclude theperformance is asymmetrical.
Yet, we might spec-ulate that, along with the increase in distance,searching from past to present could be harder dueto present world becoming relatively more diversewhen seen from the distant past.5.6 Results using different time periodFinally, we perform additional experiment usinganother target time period [1992, 1996] to verifywhether our approach is still superior on differenttarget time.
For the experiment we use the bestperforming baseline listed in Table 2, LSI-Com,and the best proposed approach, LT-Lex, as wellas GT.
The results are shown in Tables 4 and 5.LT-Lex outperforms the other baselines in boththe search from the present to the past (Table 4)and from the past to the present (Table 5).
Notethat since the query-answers pairs for [1992,1996] are different than ones for [1987, 1991],their results cannot be directly compared.Method MRR P@1 P@5 P@10 P@20LSI-Com 0.115 10.6 14.9 21.3 23.4GT 0.132 8.5 27.7 40.4 53.2LT-Lex 0.169 10.6 34.1 48.9 55.3Table 4: Results of searching from present to past(present: 2002-2007; past: 1992-1996).Method MRR P@1 P@5 P@10 P@20LSI-Com 0.148 11.6 18.6 23.3 30.2GT 0.184 11.6 23.3 30.2 44.2LT-Lex 0.212 14 28 32.6 44.2Table 5: Results of searching from past to present(present: 2002-2007; past: 1992-1996).5.7 Confidence of ResultsThe approach described in this paper will al-ways try to output some matching terms to a queryin the target time period.
However in some cases,no term corresponding to the one in the base timeexisted in the target time (e.g.
when the semanticconcept behind the term was not yet born or, onthe contrary, it has already felt out of use).
For ex-ample, junk mail may not have any equivalent intexts created around 1800s.
A simple solution tothis problem would be to use Eqs.
2 and 4 to serveas measures of confidence behind each result inorder to decide whether the found counterpartsshould or not be shown to users.
Note howeverthat the scores returned by Eqs.
2 and 4 need to befirst normalized according to the distance betweenthe target time and the base time periods.00.050.10.150.20.250.30.350.00% 2.00% 4.00% 6.00% 8.00% 10.00% 12.00% 14.00% 16.00%MRRforGTmethodercentage of used CFTs6526 Related WorkTemporal changes in word meaning have been animportant topic of study within historical linguis-tics (Aitchison, 2001; Campbell 2004; Labov,2010; Hughes, 1988).
Some researchers employedcomputational methods for analyzing changes inword senses over time (Mihalcea and Nastase,2012; Kim et al, 2014; Jatowt and Duh, 2014;Kulkarni et al, 2015).
For example, Mihalcea andNastase (2012) classified words to one of threepast epochs based on words?
contexts.
Kim et al(2014) and Kulkarni et al (2015) computed thedegree of meaning change by applying neural net-works for word representation.
Jatowt and Duh(2014) used also sentiment analysis and word paircomparison for meaning change estimation.
Ourobjective is different as we search for correspond-ing terms across time, and, in our case, temporalcounterparts can have different syntactic forms.Some works considered computing term simi-larity across time (Kalurachchi et al, 2010; Kan-habua et al 2010; Tahmasebi et al 2012, Berber-ich et al 2009).
Kalurachchi et al (2010) pro-posed to discover semantically identical tempo-rally altering concepts by applying associationrule mining, assuming that the concepts referredby similar events (verbs) are semantically related.Kanhabua et al (2010) discovered the change ofterms through the comparison of temporal Wik-ipedia snapshots.
Berberich et al (2009) ap-proached the problem by introducing a HMMmodel and measuring the across-time sematicsimilarity between two terms by comparing thecontexts captured by co-occurrence measures.Tahmasebi et al (2012) improved their approachby first detecting the periods of name change andthen by analyzing the contexts during the changeperiods to find the temporal co-references of dif-ferent names.
There are important differences be-tween those works and ours.
First, the previousworks mainly focused on detecting changes of thenames of the same, single entity over time.
For ex-ample, the objective was to look for the previousname of Pope Benedict (i.e.
Joseph Ratzinger) orthe previous name of St. Petersburg (i.e.
Lenin-grad).
Second, these approaches relied on apply-ing the co-occurrence statistics according to theintuition that if two terms share similar contexts,then these terms are semantically similar.
In ourwork, we do not require the context to be literallysame but to have the same meaning.Transfer Learning (Pan et al, 2010) is relatedto some extent to our work.
It has been mainlyused in tasks such as POS tagging (Blitzer et al,2006), text classification (Blitzer et al, 2007; Linget al, 2008; Wang et al, 2011; Xue et al, 2008),learning to rank (Cai et al, 2011; Gao et al, 2010;Wang et al, 2009) and content-based retrieval(Kato et al, 2012).
The temporal correspondenceproblem can be also understood as a transferlearning as it is a search process that uses samplesin the base time for inferring correspondent in-stances existing in the target time.
However, thedifference is that we do not only consider thestructural correspondence but we also utilize thesemantic similarity across time.The idea of distance-preserving projections isalso used in automatic translation (Mikolov et al,2013b).
Our research problem is however moredifficult and is still unexplored.
In the traditionallanguage translation, languages usually sharesame concepts, while in the across-time transla-tion concepts evolve and thus may be similar butnot always same.
Furthermore, the lack of trainingdata is another key problem.7  Conclusions and Future WorkThis work approaches the problem of finding tem-poral counterparts as a way to build a ?bridge?across different times.
Knowing correspondingterms across time can have direct usage in sup-porting search within longitudinal document col-lections or be helpful for constructing evolutiontimelines.
We first discuss the key challenge ofthe temporal counterpart detection ?
the fact thatcontexts of terms change, too.
We then proposethe global correspondence method using transfor-mation between two vector spaces.
Based on this,we then introduce more refined approach of com-puting the local correspondence.
Through experi-ments we demonstrate that the local correspond-ence using hypernyms outperforms both the base-lines and the global correspondence approach.In the future, we plan to test our approachesover longer time spans and to design the way toautomatically ?explain?
temporal counterparts byoutputting ?evidence?
terms for clarifying thesimilarity between the counterparts.AcknowledgmentsWe thank Makoto P. Kato for valuable comments.This work was supported in part by Grants-in-Aidfor Scientific Research (Nos.
15H01718,15K12158) from MEXT of Japan and by the JSTResearch Promotion Program Sakigake: ?Analyz-ing Collective Memory and Developing Methodsfor Knowledge Extraction from Historical Docu-ments?.653ReferencesJ.
Aitchison, Language Change, Progress or Decay?Cambridge University Press, 2001.K.
Berberich, S. J. Bedathur, M. Sozio and G. Weikum,Bridging the Terminology Gap in Web ArchiveSearch, In Proc.
of WebDB?09, 2009.J.
Blitzer, M. Dredze, and F. Pereira.
Biographies, Bol-lywood, Boom-boxes and Blenders: Domain Adap-tion for Sentiment Classification.
In Proc.
of ACL,pages 440-447, 2007.J.
Blitzer, R. McDonald, and F. Pereira.
Domain adap-tion with structural correspondence learning.
InProceedings of the 2006 conference on empiricalmethods in natural language processing.
Associa-tion for Computational Linguistics (EMNLP),pages 120-128, 2006.P.
Cai, W. Gao, A. Zhou et al Relevant knowledgehelps in choosing right teacher: active query selec-tion for ranking adaptation.
In Proceedings of the34th international ACM SIGIR conference on Re-search and development in Information Retrieval,pages 115-124, 2001.L.
Campbell, Historical Linguistics, 2nd edition, MITPress, 2004.S.
Deerwester et al, Improving Information Retrievalwith Latent Semantic Indexing, In Proceedings ofthe 51st Annual Meeting of the American Societyfor Information Science, 25, pages 36?40, 1988.W.
Gao, P. Cai, K.F.
Wong et al Learning to rank onlyusing training data from related domain.
In Pro-ceedings of the 33rd international ACM SIGIR con-ference on Research and development in infor-mation retrieval, pages 162-169, 2010.G.
Hughes, Words in Time: A Social History of theEnglish Vocabulary.
Basil Blackwell, 1988.A.
Jatowt and K. Duh.
A framework for analyzing se-mantic change of words across time.
In Proc.
ofJCDL, pages 229-238, 2014.A.
Kalurachchi, A. S. Varde, S. Bedathur, G. Weikum,J.
Peng and A. Feldman, Incorporating Terminol-ogy Evolution for Query Translation in Text Re-trieval with Association Rules, In Proceedings ofthe 19th ACM international Conference on Infor-mation and Knowledge Management (CIKM),pages 1789-1792, 2010.N.
Kanhabua, K. N?rv?g, Exploiting Time-based Syn-onyms in Searching Document Archives, In Pro-ceedings of the 10th annual joint conference onDigital libraries (JCDL), pages 79-88, 2010.M.
P. Kato, H. Ohshima and K. Tanaka.
Content-basedRetrieval for Heterogeneous Domains: DomainAdaption by Relative Aggregation Points.
In Pro-ceedings of the 35th international ACM SIGIR con-ference on Research and development in infor-mation retrieval, pages 811-820, 2012.Y.
Kim, Y-I.
Chiu, K. Hanaki, D. Hegde and S. Petrov.Temporal Analysis of Language through NeuralLanguage Models.
In Proceedings of the ACL 2014Workshop on Language Technologies and Compu-tational Social Science, pp.
61-65, 2014.V.
Kulkarni, R. Al-Rfou, B. Perozzi, and S. Skiena.2014.
Statistically Significant Detection of Lin-guistic Change.
In Proc.
of WWW, pages 625-635,2015.W.
Labov.
Principles of Linguistic Change (Social Fac-tors), Wiley-Blackwell, 2010.E.
Lieberman, J.-B.
Michel, J. Jackson, T. Tang, M. A.Nowak.
Quantifying the evolutionary dynamics oflanguage.
Nature, 449, 713-716, 2007.X.
Ling, W. Dai, G. R. Xue, Q. Yang and Y. Yu.
Spec-tral domain-transfer learning.
In Proceedings of the14th ACM SIGKDD international conference onKnowledge discovery and data mining, pages 488-496, 2008.R.
Mihalcea, and V. Nastase, ?Word Epoch Disambig-uation: Finding How Words Change Over Time?
inProceedings of ACL (2) 2012, pp.
259-263, 2012.T.
Mikolov, K. Chen, G. Corrado and J.
Dean.
EfficientEstimation of Word Representations in VectorSpace.
In ICLR Workshop, 2013a.T.
Mikolov, QV.
Le, I. Sutskever.
Exploiting similari-ties among languages for machine translation.CoRR, abs/1309.4168, 2013b.T.
Mikolov, I. Sutskever, K. Chen, G. Corrado, and J.Dean.
Distributed Representation of Phrases andTheir Compositionality.
In Advances in Neural In-formation Processing Systems (NIPS), pages 3111-3119, 2013c.H.
Ohshima and K. Tanaka.
High-speed Detection ofOntological Knowledge and Bi-directional Lexico-Syntactic Patterns from the Web.
Journal of Soft-ware, 5(2): 195-205, 2010.S.
Pan and Q. Yang.
A survey on transfer learning.IEEE Transactions on Knowledge and Data Engi-neering, 22(10): 1345-1359, 2010.M.
Pargel, Q. D. Atkinson and A. Meade.
Frequency ofword-use predicts rates of lexical evolution654throughout Indo-European history.
Nature, 449,717-720, 2007.D.
E. Rumelhart, G. E. Hinton, R.J. Williams.
Learninginternal representations by error propagation.
Cali-fornia Univ, San Diego La Jolla Inst.
For CognitiveScience, 1985.E.
Sandhaus.
The New York Times Annotated CorpusOverview.
The New York Times Company, Re-search and Development, pp.
1-22, 2008.https://catalog.ldc.up-enn.edu/docs/LDC2008T19/new_york_times_an-notated_corpus.pdfM.
Steinbach, G. Karypis, V. Kumar.
A comparison ofdocument clustering techniques.
In Proc.
of KDDworkshop on text mining.
2000, 400(1): 525-526.N.
Tahmasebi, G. Gossen, N. Kanhabua, H. Holzmann,and T. Risse.
NEER: An Unsupervised Method forNamed Entity Evolution Recognition, In Proc.
ofColing, pages 2553-2568, 2012.H.
Wang, H. Huang, F. Nie, and C. Ding.
Cross-lan-guage web page classification via dual knowledgetransfer using nonnegative matrix tri-factorization.In Proceedings of the 34th international ACMSIGIR conference on Research and development inInformation Retrieval, pages 933-942, 2011.B.
Wang, J. Tang, W. Fan, S. Chen, Z. Yang and Y. Liu.Heterogeneous cross domain ranking in latentspace.
In Proceedings of the 18th ACM conferenceon Information and knowledge management(CIKM), pages 987-996, 2009.G.
Xue, W. Dai, Q. Yang, and Y. Yu.
Topic-bridged plsafor cross-domain text classification.
In Proceedingsof the 31st annual international ACM SIGIR con-ference on Research and development in infor-mation retrieval, pages 627-634, 2008.655
