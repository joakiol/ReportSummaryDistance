COLING 82, J. Horeck) (?d,)North-Holland Publishing Company?
Academia, 1982A Parser Which Learns the Application Orderof Rewriting RulesMakoto Nagao, Jun-ichi NakamuraDepartment of Electrical EngineeringKyoto UniversitySakyo, KyotoJapan0.
IntroductionThe efficiency of syntactic analy-sis by using a set of rewriting rulesis greatly influenced by the order orthe arrangement of the rules for theapplication.
There are some trialswhich subdivide the set of rules intosubsets and specify the sequence ofrule applications, thus avoiding theuseless rule applicagions \[i\].
But thesubdivision of the rule set and thespecification of the sequence of ruleapplications are not so easy for theestablishment of the most efficient a-nalysis system.We have developed a rewriting rulesystem which can manipulate arbitrarylist of trees.
The control mechanism ofthis system can adjust the weight ofthe rewriting rules, and can analyzethe most plausible sentential structuref t, thus realizing the fast syntac-t analysis.
The system learns (so tos\[ ) the weight of importance of thereutiting rules during the analysis of~input sentences.I.
Objectives of the ParserWe designed a new syntactic analy-sis system (a parser) with the follow-ing objectives.
(i) The function of rewriting rulesmust be powerful enough to handle alist of trees and to express trans-formational rules,(2) All the possible sentential struc-tures must be obtained for an inputsentence in the sequence that themost plausible one is analyzedfirst.
(3) The analysis must be efficient e-nough for practical applications.
(4) The syntactic parser must have alearning mechanism as to the ap-plication sequences of rewritingrules to obtain the efficiency ofanalysis.2.
Method of AnalysisThe input data for this parser isassumed as a word sequence which is theoutput of a morphological analysis.
Theoutput from this parser is a treestructure.
The analysis is controlledby the best-first graph-searchingtechnique about the rule applications.2.1.
Description of Rewriting RulesThe rewriting rules transform alist of trees into a list of trees.
Anexample of the rewriting rule in thisparser is shown in Fig.
1.
It showsthat if there is a symbol sequence com-posed of a tree not-V(erb), a treeN(oun) P(hrase), a treeC(ase-particle), and a treenot-A(dverbial)-P(article) in thisorder, this is transformed into a treeNP-C.NP-C Y/~  ~--- X NP C YNP C (not V) (not AP)NP: Noun Phrase C:Case-particleV: Verb AP: Adverbial-ParticleFig.
1 An example of the rewritingruleThe right side of rewriting rulesis a matching pattern which is to befound in the given input symbol string.Table 1 shows the function symbols todescribe the matching patterns.
Byusing these function symbols, it ispossible to specify the repetition ofpattern elements, to assign data to avariable, and so on.
Tt is also253254 M. NAGAO and .L NAKAMURApossible to check the input data  byusing user-defined functions.
Thesefunctions enable us to describe complexsyntactic functions, semantic rela-tions, and many heuristic checks.From ?#(%F fn a l  .
.
.
an(%# at xl .
, .
xnTable I Function symbols of thematching patternsI FunctionMatch an arbitrary tree?Hatch any number ofarbitrary trees.)
Evaluate function= fnwhose arguments are aCorresponding tree, al,?.., and an.
When theValue is not NIL, matchingsucceed.)
Match any  number o4 listsof matching patterns xl?
.. xn.
Trees are assignedto variable at.
(%A xl ... xn)  Matching succeeds if allxl, ..., xn are matched toa tree.
(%O xl ... xn\] Matching succeeds if one(%N x)of xl, .
?., xn is matchedto a tree.Matching succeeds if x isnot matched to a tree.Table 2 Function symbols of thecreation patternsForm Functionat If at is a variable, thenits value, otherwise atitsel~o( *F  fn x l  .
.
xn)  The va lue  Of the funct ion :fn whose arguments are xl,?
- - t  xn .
(*S at x) The value of a generationOf x assigned to thevariable at?The left side of rewriting rulesis a creation pattern of new syntacticstructures.
Table 2 shows the functionsymbols for structure creation.
User -defined functions can also be used tocheck certain relations in this crea-tion pattern.
We can generate anarbitrary tree structure by this re-writ ing rule system.NP-Ct NP.-CJ NP-Ck VF.
F -c i  ~ --~c sP -c i  NF-CJ NF-Ck VENP-C~ NP-Ck VP NP-C: Noun Phrase+ Case-partlcleNP-Ct MP-C~ ~ }  VP: Verb PhraseS: SentenceNP-Ck VPFig.
2 An  example of generatingthree left sides from a right sideAs shown in Fig.
2, we can specifyarbitrary numbers of structures in theleft side for the same right side in arewriting rule.Each rewriting rule has a weight{basic score) and a function(fittedness function).
The basic scoreis a static weighting measure which ~e-flects the importance of a rule co~-pared to the other ruleG of the samecategory.
The basic score is adjustedby a learning process which will be ex-plained in section 3.
The ' f i ttednessfunction gives a dynamic weightingmeasure which expresses the fittednessof the rule appl ication to a sententialstructure.
The function is a user-defined one which can use the data inboth the right side and the left sidesof the rewriting rules.The basic score and the f ittednessfunction are used for the sequence con-trol of rule applications in the best-first graph-searching, which is the es-sential strategy to get the mostplausible structural analysis first.2.2.
Flow of AnalysisFig.
3 shows an intermediatestructure in the cOurse of a sentenceanalysis.
( NP-CDat isetvP TENSE )IVSh te sur U(specify)Fig.
3 The structure of a sentenceduring the analysis {LOT)This structure is represented by alist of trees.
We call this structureas a LOT {List of Trees).
An analysisstep is an appl ication of a rewritingrule to a LOT as shown in Fig.
4. whichchanges the content of the LOT.
( ~ c{ NP CIN( NF-CNF CINv TENSE )NP <- - -  NV TENSE )~N~-C <--- NF CV TENSE }Fig.
4 Progress of an analysisPARSER LEARNING ORDER OF REWRITING RULES 255To obtain the result of an analy-sis one by one in the order ofplausibility, we use the best-firstgraph-searchlng technique.
If we regarda LOT as a node in a search graph, thenew LOT created by the application of arewriting rule to an old LOT is a sis-tee node.
When several rules are ap-plicable to a LOT or the rule hasseveral left sides, the same number ofsister nodes are created from one moth-er node.
The progress of analysis canbe represented by an expansion tree (ingeneral, by a graph) as shown in Fig.5.I(A  ZI /%) LOT - node/ ~ ~- ...
Application of( A /k ) (Zi A )  rewriting rule/ ~ \ ... / "%'~... = expans?on(~)F ig .
5 Search treeThis tree can be regarded as asearch tree.
We expand the node whichhas the highest evaluation value (thescore assigned to the LOT} first.
Theexpansion is the application of a re-writing rule to a LOT.
The evaluationvalue is obtained by the summation ofthe following four values:(1) the evaluation value of the mothernode.
(2 the basic score which is attachedto the applied rule.
(3) he value obtained from thet ittedness function which ~ isattached to the applied rule.
(4) the score of the sentential pattern(SP.
which will be explained insection 2.5), if it matches to theLOT.Analysis is executed by principleof the best-first gr aph-sear'chingtechnique as follows=(i) Find the LOT which has the highestevaluation value.
(2) Apply rewriting rules to the se-lected LOT.
(3) If a rule is applicable, create newnodes (LOTs).
(4) Assign the new evaluation values tothe new LOTs by the above method.
(The initial LOT value is thesummation of the scores attached towords.
)(5) Go to (1).2.3.
Application of Rewriting Rules.The detail of the rule applicationsequence to a LOT which is selected bythe best-first graph-searchingtechnique is the following order=(1) From left elements of the LOT.
{2) FrOm the rule which has the longestright side.
(3) From the rule whose basic score isthe largest.
( A B{I} ( X ~ Z }(2) ( X' Y' )(3) ( x- )(4) ( x Y z ){5) ( X' Y' )(6) ( X" )(7) ( X' Y' )(8) ( X" )(9) ( x -  )C D ) <- - -LOTapp l i ca t ionorder  ofrewr i t ingrulesFig.
6 An example of the applicationorder of rewriting rulesFig.
6 shows a simple example ofthe rule application when rewritingrules have (x Y Z), (X Y ), and (X")as their right side, and (X"), and theselected LOT is {A B C D).
First (A BC) is matched with (X Y Z).
If thematching is not successful, (A B) ismatched with {X w yW).
Tf the matchingis not successful, {A) is matched with(X").
If the matching is not successfulagain, {B C D) is matched with (X Y Z),and so on.To speed up the rule applications,matching patterns which are right sidesof rewriting rules are reconstructed ina tree structure such as shown in Fig.7.original reconstructedrewriting rules rewriting rulesrl ( A B C ) A ->B ->Cr2 (A  B D) - -> I ~ Dr3 (A  E )r4 ( F G ) F ->GFig.
7 Reconstruction of rewritingrulesIn Fig.
7, if the first element of theLOT does not match with A, we do notneed to test the rules rl - r3.
So therule r4 alone is tested for the ap-plication.
By this reconstruction, thenumber  of rules which are to be appliedto a LOT is decreased qrately.256 M. NAGAO and J. NAKAMURA2.4.
Pruning RuleThis parser is essential ly abottom-up parser, and there are casesthat unnecessary expansions are ex-ecuted.
To minimize such unnecesseryexpansions, we introduced a mechanismof pruning such unnecessary nodes bycertain pruning ~ules.
For example, inthe analysis of Japanese svntenc~there must be ~ome verb phrase= (%~) tothe right of a noun phrase (ME}, so %~euse the pruning rule shown in Fig.
8.It ~,atches with LOT, if LOT consists ofsc~e trees, a tree N, NP or NP-C~ andtrees which are not V, V-DA or VP inthis order.
(# (%0 (?
N #) (?
NP #) (?
N~-C ~))(%# NIL (%N (%0 (?
V #)(?
V-DA #)(?
~ #)))) )(There must be V, ~.DA or VP in ~h~~igh~: of N, NP or NP-Co)?igo 8 An example of the pruning ru!eThe p~un!ng rules are described bymatching patterns just the same as theright side of re~rit!ng rules?
They arematched with the whole LOT at the timethat a LOT is created.
If a pruningrule matches with the LOT, the node ispruned.2.5.
Sententlal Patternsententlal pattern (SP} expressesthe global structure of a sentence.Fig.
9 shows examples of SPo(I) ( S -OBJ i  NP  V -DA TENSE ) : - i(2) ( NP-Ck  S -OBJ j  NP V -DA TENSE ) : +1(a) Sentent ia l  pat te rns(i) ( S -OBJ i  MP V -DA TENSE )NP-Ck  NP-Cm VEI  TENSE(2) ( NP -Ck  S-OB ._Jj NP V -DA TENSE )NP-Cm VPI TENSE(b) Corresponding LOTs( NE-Ck T~P-Cm VPI TENSE V.-DA "TENSE )(c) Original LOTFig.
9 Examples of Sententlal PatternE(sp)The top two lines are the LOTswhich are intermediate structures froman input sentence:(NP-Ck NP-Cm VPI T~SE NP V-DA TENSE)JSEUPDTE-pEogram Ha Source-program-l lbrary Wo Shuselsuru(modify)Dataset-uti l l ty Dears(Is).
(JSEUPDTE program is a Datasetuti l ity which modifies source programlibraries.
)Each element of sentential pattern is agrm~matlcal category name, not a treestructure.
The elements of a sententialpattern are compared with the sequenceof grammatical category names in anode.
SP (1) ~p~esents  that NP-Ck(JSEUPDTE-progr~,I-H~) is related to VP1(the first embedded verb, Shuselsuru(mcdify)}.
SP (2) represents that NP-CkIs related to V-DA (main verb DA (is))oThe ~a,:,~er assigns ~P-sco~s andSP-rule to a sentential Fattern.
SP-score is a number such as shown in Fig.~.
~his $~presses the plausibi l i ty ofthe styl~s of sentences?
in this exmn-p).C: SP (i) is assigned the numericalv?~ue: -I~ and SP (2) is essggned thevalue: +!~ as the SP-sco~:eo These t~ovaiue~ mean that~ when th~ main verb isV-~A, th~ first NP-C ha?
tendency tobe related to the main verb rather thanto the first embedded verb.
This SP-score is added to the evaluation valueexplained in section 2.2.
Therefore~ a-nalysis (1) takes precedence over anal-,s is  (2) in hhis case.
( NP-C ~ C VP TENSE ) : SP( ( rule-i 2 )' rule--2 1 ) : SP-rule( rule-3 i )( ru!e-4 ! )
)Fig.
i0 An exmaple of SP-rule~!
'Igo i0 shows an example of SP-ruleo The sentential pattern whose SP-score is posit ive has at least onecorrect analysls.
And a sequence ofrule appllcatlon~ to the sententlalstructure is guaranteed.
S~-rules rep-resent this sequence.
However, it isnot evident whether the sententlalpattern whose SP-score is negative hascorrect analyses, because it has atleast one incorrect analysis.
So we donot attach any SP-rule to it.SP-rule in Fig.
I0 shows that wecan get a correct analysis, if we applyrule-i - rule-4 to the  LOT.
Fig.
11shows this process of rule applica-tions.
The sequential rule applicationof these four rules Is equivalent to aPARSER LEARNING ORDER OF REWRITING RULES 257rewriting rule shown in Fig.
12.
Butthe rewriting rules Of the form shownin Fig.
10 are much better because thesemantic check functions can be easilyintroduced to the simpler rules such asthose in Fig.
i0 rather than to suchcomplex rules as those in Fig.
12.NP-C NP C VP TENSE )I .... NP-C <--- NP C ( rule-I )NP-C NP-C VP TENSE }| .... S-NUCL <--- NP-C NP-C VP ( rule-2S-NUCL TENSE )| .... S-OBJ <--- S-NUCL TENSE ( rule-3 }S-OBJ ).... S <--- S-OBJ ( rule-4 )S }Pig.
11 An example of the SP-ruleapplicationSiS-OBJ<-  NP-C NP C VP TENSES-NUCL TENSE~ NI~.C VPANP CFig.
12 An example of the equivalentrewriting ruleEach LOT is compared to sententialpatterns from the first element of theLOT.
The LOT is regarded as matched ifthe first part of the LOT matches a The parser changes the scores ofsentential pattern, rewriting rules and SP-scores in thefollowing way~3.
Supervised Learning of Basic Scores, (i) Increase the scores of the rewrit-SP-scores and SP-rules ing rules and SP-scores on the pathI from the root node to the success-To increase the eff iciency of the ful node, and those on the pathesanalysis, the parser controls basic which flow into the successfulscores attached to rewriting rules, pathes.SP-scores and SP-rules.
It is not easy (2) Decrease the scores of the rewrit-for rule writers to assign scores to ing rules and SP-scores on therewriting rules and to sentential f irst arcs of the pathes which flowpatterns, and also to write SP-rules out the successful pathes.for a sentential pattern.
We tried to SP-rules are gathered for eachadjust these scores and to get SP-rules sentential pattern on the successfulby the supervised learning in which the pathes by using the information in theuser teaches the correctness of an a- search graph.nalysis to the parser.Fig.
13 shows an example of a 4.
Result  of Seme Experimentssearch graph when a sentence is ana-lyzed.
Each node of the search graph The sample sentences to be and-corresponds to a LOT.
Each arc lyzed are taken fro~ a computer manualcorresponds to a rule application.
We in Japanese.
About 150 sentences arecan regard the LOTs on the path from used for the experiments.
Conjunctionthe root node to the successful node as structures of noun phrases areuseful structures, and the rewriting el iminated from these sentences.
Amongrules on the path as useful rules forthe future analysis of similar senten-tial structure.
On the other hand, oth-er LOTs and rewriting rules in thesearch graph are regarded as useless tothe future us~e;  But ~e nodes andarcs \[i\] in Fig.
13 are not the directreason of the failure.
The direct causefor the failure comes from the nodesand ~cs  \[ii\] in Pig.
13.act e~d~s1/  / ii/.
- '~--:  / ./~failed ~t  ~d~ s ~  failed~z ~it ing  RuleSP: Sententlal PatternFig.
13 Relat ion ~t~en the stateof the expa~ion  andfailure or success of the analysis258 M. NAGAO and J. NAKAM~ltA150 sentences, 20 sentences are usedfor the supervised learning.
These areselected ran&:mly.
The rewrfting rulesare  c reated  f rom the  gra lmar  proposedby Okutsu \[2\].
The number of rewritingrules is 54.
The re~rlting rules inthis experiment do not have the seman-tic check functions for s~pllclty.They are prepared to get the syntacticstructures for a sentence.4.1.
Experiment I - Learning of BasicScores of Rewriting Rules.To see  the  e f f i c iency  improvemento f  the  ana lys i s  f rom the  cont r ibut iono?
basic scores, SP-scOres and SP-rulesare not used.
The initial order of  therewriting rules is determined by randomnumbers.
The initial basic scores areset the same value I for all rules.
Weadjusted basic scores 4 times, everytime after 20 sentences for learningare analysed.
We corpared  the CPU-tlmesof the 2nd, 3rd and 4th analyses to theCPU-tlme of the let analysis.
The re-sult i s  shown in  Table 3.Table 3 Effect of  basic scores12nd/let 3rd/Ist 4th/Istmax.|  99.37~ 102.10% 108.78%averaq~ 94.62% 96,75~ 96.47%mln.| 87.69% 87?88% 89.49%(The values are the ratio o?
th(2PO-t ime per  word.
)Table 3 tells us  that the basic scoresof rewriting rule~ are not ~o usefulfor the improvement of the efficiencyo?
analysis.
The learned order o?
re -writing rules does not have a slgnlf~-cant tendency.
The reason Is that thestructure of natural languages is re-cursive and the relative order of rulesare more important to the anslysls thanthe over-all ordering, so that the ba-sic scores cannot express the relativeorder.4.2.
Experiment 2 - The Effec~ ofSP-sonres and SP-rulesThe learning of the SP~scores andSP-rules are done by enalys~ng the se~of sample sentences once (20 Sentencesselected amon 9 153 sentences r~n~ly} .Then the analysis of the set o~ 3~mpAesentences (153 sentences) is d~e wit/~and without using SP-soo~e~ ~ S~-ru les .
The resu l t  o f  the  exper iment  i sin  Tab le  4.Table 4 Effect of SP-scores andSP-ruleeoYhe  same SP not the same SPnu~Lbersentences~ 42 111max.
| 26.06~ 108.63%average \[ 19.23t 67.36%min.
| 1.03% 9.46%(The values are the ratio of th~analysis time with SP-scoree and S~rules to the analysis time withoulthem.
)About 200 sententlal patterns areextracted frc, n the 20 sample sentencesfor learning.
SP-zules are very usefulfor the sentences which have the samesententlal patterns, because the ze-writing rules and their applicationsequence in the analysis of the senten-tlal pattern can be obtained from SP-rules which are defined from the pastanalysis, and no more trial search isnecessary.
27.5% o?
sample sentenceshave the same ssntentlal patterns asthe sentences foe learning.
Th is  n~ansthat s(~e documents l~ke a computermanual contain very  similar se~ences.Sententlal patterns and SP-rules areuseful ?or the analysis o?
such docu-ments.5.
ConclusionThe experiments to examine theeffect of lea~nlng are performed.
Theresults of ~he experiment shows thatSP-rules a~ very useful.
Th~s ~eansthat ~hls p~Eser can learn the s~yle ofthe sentences an~ can increase the ef-?1c~ncy  of &nalyels when the senten-tlal structures o?
the texts in thepartlcular field are  ~est r i c ted .This parser is implemente~ ~ LZSPon ~ACOM M-2O0 in Com~uter Cen~eE o?Kyoto University.Reference~\[I\] Boltet, C., Aut~t lc  ~rc~uct~n ofCF an~ CS-a~ly~ using.
A Generalsc len~I f lque  ~u ~ I ~  deGr~;~eble,  I%79o\[2~ Okut~u, ~.
~ Sei~el ~ Ipp~o ~un~o-
