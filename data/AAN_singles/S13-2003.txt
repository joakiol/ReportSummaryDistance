Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on SemanticEvaluation (SemEval 2013), pages 15?19, Atlanta, Georgia, June 14-15, 2013. c?2013 Association for Computational LinguisticsHeidelTime: Tuning English and Developing Spanish Resourcesfor TempEval-3Jannik Stro?tgen Julian Zell Michael GertzInstitute of Computer Science, Heidelberg UniversityIm Neuenheimer Feld 348, 69120 Heidelberg, Germany{stroetgen,gertz}@uni-hd.de, j.zell@stud.uni-heidelberg.deAbstractIn this paper, we describe our participation inthe TempEval-3 challenge.
With our multi-lingual temporal tagger HeidelTime, we ad-dressed task A, the extraction and normaliza-tion of temporal expressions for English andSpanish.
Exploiting HeidelTime?s strict sep-aration between source code and language-dependent parts, we tuned HeidelTime?s ex-isting English resources and developed newSpanish resources.
For both languages, weachieved the best results among all partici-pants for task A, the combination of extractionand normalization.
Both the improved Englishand the new Spanish resources are publiclyavailable with HeidelTime.1 IntroductionThe task of temporal annotation, which is addressedin the TempEval-3 challenge, consists of three sub-tasks: (A) the extraction and normalization of tem-poral expressions, (B) event extraction, and (C) theannotation of temporal relations (UzZaman et al2012).
This makes sub-task A, i.e., temporal tag-ging, a prerequisite for the full task of temporal an-notating documents.
In addition, temporal taggingis important for many further natural language pro-cessing and understanding tasks, and can also be ex-ploited for search and exploration scenarios in infor-mation retrieval (Alonso et al 2011).In the context of the TempEval-2 challenge (Ver-hagen et al 2010), we developed our temporal tag-ger HeidelTime (Stro?tgen and Gertz, 2010), whichachieved the best results for the extraction and nor-malization of temporal expressions for English doc-uments.
For our work on multilingual informationretrieval (e.g., Stro?tgen et al(2011)), we extendedHeidelTime with a focus on supporting the simpleintegration of further languages (Stro?tgen and Gertz,2012a).
For TempEval-3, we now tuned Heidel-Time?s English resources and developed new Span-ish resources to address both languages that are partof TempEval-3.
As the evaluation results demon-strate, HeidelTime outperforms the systems of allother participants for the full task of temporal tag-ging by achieving high quality results for the extrac-tion and normalization for English and Spanish.The remainder of the paper is structured as fol-lows: We explain HeidelTime?s system architecturein Section 2.
Section 3 covers the tuning of Heidel-Time?s English and the development of the Spanishresources.
Finally, we discuss the evaluation resultsin Section 4, and conclude the paper in Section 5.2 HeidelTimeHeidelTime is a multilingual, cross-domain tempo-ral tagger.
So far, it can process English, Ger-man, and Dutch text.
In previous work, we an-alyzed domain-dependent challenges and demon-strated that domain-sensitive strategies for normal-izing temporal expressions result in significant nor-malization improvements when switching betweennews- and narrative-style documents (Stro?tgen andGertz, 2012b).
Although TempEval-3 only ad-dresses news documents, the tuned English and newSpanish resources can be used to process news andalso narrative-style documents such as Wikipedia ar-ticles with high extraction and normalization quality.15Architecture of HeidelTime.
HeidelTime is arule-based system with a strict separation betweensource code and language-dependent resources.While the strategies for processing different do-mains are part of the source code, resources con-sist of files for (i) patterns, (ii) normalizations, and(iii) rules.
They are read by HeidelTime?s resourceinterpreter and thus have to be developed based onHeidelTime?s well-defined rule syntax.The pattern files contain words and phrases,which are typically used to express temporal ex-pressions, e.g., names of months.
The normaliza-tion files contain normalization information aboutthe patterns, e.g., the value of a specific month?sname.
Finally, the rule files contain rules for date,time, duration, and set expressions.All rules have an extraction part and a normal-ization part.
The extraction part, in which the pat-tern resources can be used for generalization, de-fines the expressions that have to be matched in adocument.
The normalization part normalizes thecontext-independent content of the expression usingthe normalization resources.
While explicit tempo-ral expressions (e.g., May 1st, 2013) can directlybe fully normalized, underspecified (November) andrelative (today, two weeks ago) expressions can onlybe normalized in an underspecified manner.
The fullnormalization depends on the domain of the docu-ment that is to be processed and the context of theexpression.
For this, HeidelTime applies domain-sensitive strategies to normalize such expressionsduring its disambiguation phase, which is called af-ter the extraction and the normalization phases.The TempEval-3 data is from the news domain.Here, HeidelTime usually uses the document cre-ation time as reference time.
The temporal relationto it is identified based on the tense in the sentence.1Preprocessing.
HeidelTime requires sentence, to-ken, and part-of-speech information.
For this, theTreeTagger (Schmid, 1994) is used.
Since there isa Spanish model for the TreeTagger, adding Spanishpreprocessing capabilities to HeidelTime was fairlyeasy.
A wrapper for the TreeTagger is also part ofthe UIMA HeidelTime kit described next.1For further details on HeidelTime?s rule syntax, its domain-dependent normalization strategies, and its architecture in gen-eral, we refer to Stro?tgen and Gertz (2012a).UIMA HeidelTime kit.
For processing Temp-Eval-3 data, we used the UIMA version of Heidel-Time, developed a collection reader and a CAS con-sumer to read and write TempEval-3 input and out-put data, and added both components to our UIMAHeidelTime kit.
This makes HeidelTime?s evalua-tion results reproducible on the training and test sets.3 HeidelTime for TempEval-3In TempEval-3, we participated with one Spanishand three English runs: For Spanish, we used ournewly developed resources.
For English, we used(i) HeidelTime 1.2, which was released in May2012, (ii) a version containing several bug fixes andimprovements, which were implemented indepen-dently from TempEval-3, and (iii) HeidelTime withits new English resources tuned for TempEval-3.In general, our goal when developing HeidelTimeresources is to achieve high quality normalization re-sults.
Thus, we only want to extract temporal ex-pressions which can be normalized correctly withhigh probability ?
an issue, which will be furtherlooked at in the discussion in the evaluation section.Before that, we next describe language-independentadaptations to HeidelTime.
Then, we present thetuning of the English resources (Section 3.2) and thedevelopment of the Spanish resources (Section 3.3).3.1 General HeidelTime AdaptationsWe performed the following language-independentchanges to HeidelTime:(i) Weekday normalization: In news-style doc-uments, extracted weekdays that are equal to theweekday of the document creation time (dct) arenow normalized to the date of the dct independentof the tense in the sentence.
(ii) Century/decade normalization: So far, decadeand century expressions were not correctly normal-ized by HeidelTime according to TimeML, e.g.,?199X?
instead of ?199?
for ?the 1990s?.The first change is based on the intuitive assump-tion that information in news-style documents istemporally focused around the dct.
In addition,this assumption is supported by the English and theSpanish training data.
The second change is relatedto the annotation standard.
Both changes can thusbe generalized in a language-independent manner.163.2 Tuning HeidelTime?s English ResourcesThree training corpora were provided by the orga-nizers: the Aquaint and TimeBank gold standardcorpora, and a large corpus referred to as silver stan-dard, which was created by merging results of threetools (Llorens et al 2012).
After a brief analysis,we decided not to use the silver standard due to therather low annotation quality.
Motivated by observa-tions in the gold standard corpora, we performed thefollowing English-specific modifications in additionto the general adaptations described above:(i) REF-value expressions: expressions normal-ized to past, present, or future are not consistentlyannotated in the training data.
Since such expres-sions are rather less valuable for further tasks andto avoid false positives, we removed some of thosepatterns from the resources.
(ii) Ambiguous expressions: We added negativerules for expressions such as may, march, and fall tofilter them out if they do not refer to a date.
(iii) Article/modifier: We allowed some morecombinations of articles and modifiers.Note that HeidelTime was already a state-of-the-art tool for English temporal tagging so that thechanges are rather minor.3.3 Developing Spanish ResourcesIn this section, we explain the resource develop-ment process for Spanish.
Then, we detail language-specific challenges we faced during this process.Resource Development Process.
So far, therewere no HeidelTime resources for Spanish, and wethus started the development from scratch.
(i) Preprocessing: As mentioned in Section 2, weuse the TreeTagger with its Spanish module for sen-tence, token, and part-of-speech annotation.
(ii) Translation of pattern files: Starting with Hei-delTime?s English pattern resources, we developedthe Spanish pattern resources.
The goal was that allpatterns that are frequently used to express tempo-ral expressions are included in the resources.
Notethat it is not important that the patterns are contextindependent.
The context in which a pattern shouldoccur can be defined within the rules.
(iii) Translation of normalization files: Similar tothe patterns, we translated the English normalizationfiles and adapted them to the new Spanish patterns.
(iv) Rule Development: Based on the Englishrules for dates, times, durations, and sets, we de-veloped similar Spanish rules.
Using the Spanishtraining corpus to check for partially matching pat-terns, false positives, false negatives, and incorrectnormalizations, we then iteratively adapted the rules,but also the pattern and normalization resources.Challenges.
Spanish as a Romance language isrich in inflection.
Nouns, adjectives, and determin-ers are inflected with respect to number and gender.During the development of the pattern and normal-ization resources, this had to be taken into account.As for nouns, there are many inflection forms ofverbs in Spanish, e.g., to represent tense.
Whileverbs are usually not part of temporal expressions,the inflection of verbs has to be considered for thenormalization of ambiguous expressions such as ellunes (Monday) or junio (June).
As mentionedabove, in news-style documents, HeidelTime usesthe tense of the sentence to determine the relationto the reference time, i.e., to decide whether the ex-pression refers to a previous or upcoming date.The tense is determined using part-of-speech in-formation, and, if necessary, pattern information ofwords with specific part-of-speech tags.
For eachlanguage, this information is defined in the patternresources.
Unfortunately, the Spanish tag-set of theTreeTagger module does not contain tags coveringtense information, e.g., all finite lexical verbs aretagged as VLfin.
Thus, we created regular expres-sion patterns to match typical inflection patterns rep-resenting tense information and check words taggedas verbs by the tagger for these patterns.However, due to the ambiguity of the Spanish in-flection, we can only add patterns to detect futuretense.
If no tense is identified, the year is set to theyear of the reference time.
As detailed in the discus-sion of the evaluation results described in Section 4,identifying the correct relation to the reference timeis a frequent source of normalization errors.4 Evaluation ResultsMeasures.
For the extraction task, precision (P),recall (R), and f1-score (F1) are used for strict andrelaxed matching.
The value F1 and type F1 mea-sures combine relaxed matching with correct nor-malization.
Systems are ranked by value F1 (value).17strict match relaxed match normalizationa) Aquaint P R F1 P R F1 value typetuned 80.17 81.69 80.92 90.85 92.57 91.7 72.37 83.32bug-fixed 77.56 81.17 79.32 88.28 92.40 90.30 70.21 82.031.2 73.32 81.17 77.05 83.46 92.40 87.70 67.87 79.67b) TimeBank P R F1 P R F1 value typetuned 85.39 84.15 84.76 92.16 90.83 91.49 79.01 88.74bug-fixed 83.17 82.70 82.94 90.86 90.35 90.60 76.24 87.781.2 82.89 82.62 82.76 90.72 90.43 90.57 76.39 87.75c) Spanish P R F1 P R F1 value typenew 90.53 81.26 85.65 96.23 86.38 91.04 84.10 89.40Table 1: Results on training data ranked by value F1.Results on Training Data.
Table 1 shows the re-sults on the Aquaint (a), TimeBank (b), and Spanishtraining corpora (c).
On both English corpora, Hei-delTime?s TempEval-3 tuned version outperformsthe other two versions.
The big differences betweenthe two English corpora are rather due to the betterannotation quality of TimeBank than due to differentchallenges in the documents of the two corpora.TempEval-3 Evaluation.
The evaluation resultson the test data are presented in Table 2.
For English,HeidelTime?s TempEval-3 tuned version achievesthe best results, and all three HeidelTime versionsoutperform the systems of the eight other partici-pating teams with a total number of 21 submissions(task A ranking measure value F1).
For comparison,the results of the next best system (NavyTime) islisted in Table 2(a).
For Spanish, we highly outper-form the other two systems, as shown in Table 2(b).Discussion.
In order to be able to interpret Hei-delTime?s results on the training and test data, weperformed an error analysis (TimeBank and Spanishtraining corpus).
The most important findings are:(i) For a rule-based system, HeidelTime?s recallis relatively low (many false negatives; FN).
How-ever, note that several FN are intentional.
55% and29% of 117 and 149 FN in the English and Span-ish training corpora are due to imprecise expressions(some time; the latest period).
These are difficultto normalize correctly, e.g., some time can refer toseconds or years.
To guarantee high quality normal-ization, we do not extract expressions that cannot benormalized correctly with high probability.
(ii) There is a trade-off between precision and re-call due to expressions referring to past, present, orfuture (X REF).
These are annotated either only insome contexts or inconsistently throughout the train-strict match relaxed match normalizationa) English P R F1 P R F1 value typetuned 83.85 78.99 81.34 93.08 87.68 90.30 77.61 82.09bug-fixed 80.77 76.09 78.36 90.00 84.78 87.31 72.39 79.101.2 80.15 76.09 78.07 89.31 84.78 86.99 72.12 78.81next best* 78.72 80.43 79.57 89.36 91.30 90.32 70.97 80.29b) Spanish P R F1 P R F1 value typeHeidelTime 90.91 80.40 85.33 96.02 84.92 90.13 85.33 87.47TipSemB 88.51 77.39 82.57 93.68 81.91 87.40 71.85 82.04jrc-1/2 65.83 39.70 49.53 86.67 52.26 65.20 50.78 62.70Table 2: TempEval-3 task A evaluation results ranked byvalue F1 (* next best: NavyTime).ing data, and thus result in FN (21%/en; 34%/es) andfalse positives (43% of 98 FP in English training and43%/es of 35 FP in Spanish training corpora).
(iii) The main sources for incorrect value normal-ization of underspecified expressions (Feb. 1; Mon-day) are wrongly detected reference times or rela-tions to them (e.g., due to wrong tense identifica-tion), annotation errors in the corpora (e.g., last weekannotated as WXX instead of the week it is referringto), granularity errors (e.g., a year ago can refer to aday, month, quarter, or year), and ambiguities (e.g.,the year can be a duration or a specific year).
(iv) Some expressions in the Spanish test set wereextracted and normalized correctly although no sim-ilar expressions exist in the Spanish training data.Here, the Spanish resources highly benefited fromthe high quality English resources as starting pointof the development process, and from HeidelTime?slanguage-independent normalization strategies.
(v) A reoccurring error in the English test setis that HeidelTime matches and normalizes expres-sions such as two days earlier while only two daysshould be annotated according to TimeML.
This re-sults in a relaxed match with false type and value.5 Conclusions & Ongoing WorkIn this paper, we presented HeidelTime?s results inthe TempEval-3 temporal tagging task.
For both lan-guages, English and Spanish, we achieved the bestresults of all participants (value F1).
We showed thatadding a new language to HeidelTime can result inhigh quality temporal tagging of the new language.Currently, we are working on improving the Span-ish tense detection to better normalize underspec-ified temporal expressions.
Furthermore, we willmake available HeidelTime resources for Arabic,Italian, and Vietnamese (HeidelTime, 2013).18ReferencesOmar Alonso, Jannik Stro?tgen, Ricardo Baeza-Yates, andMichael Gertz.
2011.
Temporal Information Re-trieval: Challenges and Opportunities.
In Proceedingsof the 1st International Temporal Web Analytics Work-shop (TWAW 2011), pages 1?8.HeidelTime.
2013. http://code.google.com/p/heideltime/.Hector Llorens, Naushad UzZaman, and James F. Allen.2012.
Merging Temporal Annotations.
In 19th Inter-national Symposium on Temporal Representation andReasoning, TIME 2012, pages 107?113.Helmut Schmid.
1994.
Probabilistic Part-of-Speech Tag-ging Using Decision Trees.
In Proceedings of the In-ternational Conference on New Methods in LanguageProcessing.Jannik Stro?tgen and Michael Gertz.
2010.
HeidelTime:High Quality Rule-Based Extraction and Normaliza-tion of Temporal Expressions.
In Proceedings of the5th International Workshop on Semantic Evaluation(SemEval?10), pages 321?324.Jannik Stro?tgen and Michael Gertz.
2012a.
Multilingualand Cross-domain Temporal Tagging.
Language Re-sources and Evaluation, Online first.Jannik Stro?tgen and Michael Gertz.
2012b.
TemporalTagging on Different Domains: Challenges, Strate-gies, and Gold Standards.
In Proceedings of the 8thInternational Conference on Language Resources andEvaluation, pages 3746?3753.Jannik Stro?tgen, Michael Gertz, and Conny Junghans.2011.
An Event-centric Model for Multilingual Doc-ument Similarity.
In Proceeding of the 34rd Interna-tional ACM SIGIR Conference on Research and De-velopment in Information Retrieval (SIGIR?11), pages953?962.Naushad UzZaman, Hector Llorens, James F. Allen,Leon Derczynski, Marc Verhagen, and James Puste-jovsky.
2012.
TempEval-3: Evaluating Events,Time Expressions, and Temporal Relations.
CoRR,abs/1206.5333.Marc Verhagen, Roser Sauri, Tommaso Caselli, andJames Pustejovsky.
2010.
SemEval-2010 Task13: TempEval-2.
In Proceedings of the 5th In-ternational Workshop on Semantic Evaluation (Sem-Eval?10), pages 57?62.19
