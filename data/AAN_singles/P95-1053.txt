Conciseness through Aggregation in Text GenerationJ ames  ShawDept .
of Computer  Sc ienceCo lumbia  Un ivers i tyNew York,  NY  10027, USAshaw~cs, columbia, eduAbst ractAggregating different pieces of similar in-formation is necessary to generate conciseand easy to understand reports in techni-cal domains.
This paper presents a generalalgorithm that combines imilar messagesin order to generate one or more coherentsentences for them.
The process is not astrivial as might be expected.
Problems en-countered are briefly described.1 Mot ivat ionAggregation is any syntactic process that allows theexpression of concise and tightly constructed textsuch as coordination or subordination.
By using theparallelism of syntactic structure to express imilarinformation, writers can convey the same amountof information in a shorter space.
Coordinationhas been the object of considerable research (for anoverview, see (van Oirsouw87)).
In contrast o lin-guistic approaches, which are generally analytic, thetreatment of coordination in this paper is from asynthetic point of view - -  text generation.
It raisesissues such as deciding when and how to coordinate.An algorithm for generating coordinated sentences iimplemented in PLANDoc (Kukich et al93; McKe-own et ah94), an automated ocumentation system.PLANDoc generates natural language reportsbased on the interaction between telephone planningengineers and LEIS-PLAN 1, a knowledge based sys-tem.
Input to PLANDoc is a series of messages, orsemantic functional descriptions (FD, Fig.
1).
EachFD is an atomic decision about telephone quipmentinstallation chosen by a planning engineer.
The do-main of discourse is currently limited to 31 mes-sage types, but user interactions include many vari-ations and combinations of these messages.
Insteadof generating four separate messages as in Fig.
2,PLANDoc combines them and generates the follow-ing two sentences: "This refinement activated DLCfor CSAs 3122 and 3130 in the first quarter of 19941LEIS is a registered trademark of Bell Communica-tions Research, Piscataway, NJ.and ALL-DLC for CSA 3134 in 1994 Q3.
It alsoactivated DSS-DLC for CSA 3208 in 1994 Q3.
"2 System Arch i tec tureFig.
3 is an overview of PLANDoc's architecture.Input to the message generator comes from LEIS-PLAN tracking files which record user's actions dur-ing a planning session.
The ontologizer adds hier-archical structure to messages to facilitate furtherprocessing.
The content planner organizes the over-all narrative and determines the linear order of themessages.
This includes combining atomic messagesinto aggregated messages, choosing cue words, anddetermining paraphrases that maintain focus andensure coherence.
Finally the FUF/SURGE pack-age (Elhadad91; Robin94) lexicalizes the messagesand maps case roles into syntactic roles, builds theconstituent structure of the sentence, ensures agree-ment, and generates the surface sentences.3 Combin ing  St ra tegyBecause PLANDoc can produce many paraphrasesfor a single message, aggregation during the syntac-tic phase of generation would be difficult; semanti-cally similar messages would already have differentsurface forms.
As a result, aggregation i PLANDocis carried out at the content planning level using se-mantic FDs.
Three main criteria were used to designthe combining strategy:1. domain  independence:  the algorithm shouldbe applicable in other domains.2.
generat ing  the  most  concise text :  it shouldavoid repetition of phrases to generate shortesttext.
((cat message)(admin ((PLANDoc-message-name RDA)(runid r - reg l ) ) )(class refinement)(action act ivat ion)(equipment-type a l l -d lc )(csa-s i te  3134)(date ((year 1994) (quarter 3))))Figure h Output of the Message Generator329This ref inement act ivated ALL-DLC for  CSA 3134 in 1994 Q3.This refinement act ivated DLC for  CSA 3130 in 1994 Q1.This refinement act ivated DSS-DLC for CSA 3208 in 1994 Q3.This refinement act ivated DLC for  CSA 3122 in 1994 Q1.Equipment: El= ALL-DLC, E2= DLC, E3= DSS-DLCSite: SI= CSA 3122, $2= CSA 3130, $3= CSA 3134, $4= CSA 3208Date: DI= 1994 Q1, D2= 1994 Q3Figure 2: Unaggregated Text Output(El $3 D2)(E2 $2 D1)(E3 S4 D2)(E2 S1D1)LEIS- \[ MessagePLAN , Generator(C) (C)Ontologizer(FUF) ~ Contentplanner(Lisp) , Lexica/izer(FUF)Figure 3: PLANDoc System ArchitectureSurfaceGenerator(SURGE)PLANDocNarrative(text)3. avo idance  of  over ly -complex  sentences :  itshould not generate sentences that are too com-plex or ambiguous for readers.The first aggregation step is to identify semanticallyrelated messages.
This is done by grouping messageswith the same action attribute.
Then the system at-tempts to generate concise and unambiguous textfor each action group separately.
This reduces theproblem size from tens of messages into much smallersizes.
Though this heuristic disallows the combina-tion of messages with different actions, the messagesin each action group already contain enough infor-mation to produce quite complex sentences.The system combines the maximum number of re-lated messages to meet the second design criterion-generating the most concise text.
But such combi-nation is blocked when a sentence becomes too com-plex.
A bottom-up 4-step algorithm was developed:1.
Sor t ing:  putting similar messages right next toeach other.2.
Merg ing  Same At t r ibute :  combining adja-cent messages that only have one distinct at-tribute.3.
Ident i ty  De le t ion :  deletion of identical com-ponents across messages.4.
Sentence  Break ing :  determining sentencebreaks.3.1 S tep  h Sor t ingThe system first ranks the attributes to determinewhich are most similar across messages with thesame action.
For each potential distinct attribute,the system calculates its rank using the formulam - d, where m is the number of messages and dis the number of distinct attributes for that par-ticular attribute.
The rank is an indicator of howsimilar an attr ibute is across the messages.
Com-bining messages according to the highest rankingattr ibute ensures that minimum text will be gen-erated for these messages.
Based on the ranking,the system reorders the messages by sorting, which(E2 S1D1) (El S3 D2) (E2 S1D1)(E2 $2 D1) (E2 S1D1) (E2 S2 D1)(El $3 D2) --> (E2 $2 D1) --> (El $3 D2)(E3 $4 D2) (E3 $4 D2) (E3 $4 D2)by Site by Equipment by DateFigure 4: Step 1.
Sortingputs the messages that have the same attribute rightnext to each other.
In Fig.
2, equipment has rank1 because it has 3 distinct equipment values - ALL-DLC, DLC, and DSS-DLC; date has rank 2 becauseit has two distinct date values - 1994 Q1 and 1994Q3; site has rank 0.
Attribute class and action (Fig.1) are ignored because they are always the same atthis stage.
When two attributes have the same rank,the system breaks the tie based on a priority hierar-chy determined by the domain experts.
Because thefinal sorting operation dominates the order of theresulting messages, PLANDoc sorts the message listfrom the lowest rank attribute to the highest.
In thiscase, the ordering for sorting is site, equipment, andthen date.
The resulting message list after sortingeach attribute is shown in Fig.
4.3.2 S tep  2: Merg ing  Same At t r ibuteThe list of sorted messages is traversed.
When-ever there is only one distinct attr ibute betweentwo adjacent messages, they are merged into onemessage with a conjoined attribute, which is alist of the distinct attributes from both messages.What about messages with two or more distinct at-tributes?
Merging two messages with two or moredistinct attributes will result in a syntactically validsentence but with an undesirable meaning: "*Thisrefinement activated ALL-DLC and DSS-DLC forCSAs 3122 and 3130 in the third quarter of 1993.
"By tracking which attribute is compound, a thirdmessage can be merged into the aggregate messageif it also has the same distinct attribute.
Continuefrom Step 1, (E2 S1 D1) and (E2 $2 D1) are mergedbecause they have only one distinct attribute, site.A new FD, (E2 (S1 $2) D1), is assembled to replace330those two messages.
Note that although (El $3 D2)and (E3 $4 D2) have the date in common, they arenot combined because they have more than one dis-tinct attribute, site and equipment.Step 2 is applied to the message list recursivelyto generate possible crossing conjunction, as in thefollowing output which merges four messages: "Thisrefinement activated ALL-DLC and DSS-DLC forCSAs 3122 and 3130 in the third quarter of 1993.
"Though on the outset this phenomenon seems un-likely, it does happen in our domain.3.3 S tep  3: Ident i ty  De le t ionAfter merging at step 2, the message list left in anaction group either has only one message, or it hasmore than one message with at least two distinctattributes between them.
Instead of generating twoseparate sentences for (E2 (S1 $2) D1) and (El $3D2), the system realizes that both the subject andverb are the same, thus it uses deletion on identity togenerate "This refinement activated DLC for CSAs3122 and 3130 in 1994 Q1 and \[this refinement ac-tivated\] ALL-DLC for CSA 3134 in 1994 Q3."
Foridentical attributes across two messages (as shownin the bracketed phrase), a "deletion" feature is in-serted into the semantic FD, so that SURGE willsuppress the output.3.4 Step 4: Sentence  BreakApplying deletion on identity blindly to the wholemessage list might make the generated text incom-prehensible because readers might have to recovertoo much implicit information from the sentence.As a result, the combining algorithm must have away to determine when to break the messages intoseparate sentences that are easy to understand andunambiguous.How much information to pack into a sentencedoes not depend on grammaticality, but on coher-ence, comprehensibility, and aesthetics which arehard to formalize.
PLANDoc uses a heuristic thatalways joins the first and second messages, and con-tinues to do so for third and more if the distinctattributes between the messages are the same.
Thisheuristics results in parallel syntactic structure andthe underlying semantics can be easily recovered.Once the distinct attributes are different from thecombined messages, the system starts a new sen-tence.
Using the same example, (E2 (S1 $2) D1) and(El $3 D2) have three distinct attributes.
They arecombined because they are the first two messages.Comparing the third message (E3 $4 D2) to (El $3D2), they have different equipment and site, but notdate, so a sentence break will take place betweenthem.
Aggregating all three messages together willresults in questionable output.
Because of the par-allel structure created between the first 2 messages,readers are expecting a different date when readingthe third clause.
The second occurrence of "1994Q3" in the same sentence does not agree with read-ers' expectation thus potentially confusing.4 Future  D i rec t ionsIn this paper, I have described a general algorithmwhich not only reduces the amount of the text pro-duced, but also increases the fluency of the text.While other systems do generate conjunctions, theydeal~vith restricted cases such as conjunction of sub-jects and predicates(Dalianis~zHovy93).
There areother interesting problems in aggregations.
Gener-ating marker words to indicate relationships in con-joined structures, such as "respectively", is anothershort term goal.
Extending the current aggregationalgorithm to be more general is currently being in-vestigated, such as combining related messages withdifferent actions.5 AcknowledgementsThe author thanks Prof. Kathleen McKeown, andDr.
Karen Kukich at Bellcore for their advice andsupport.
This research was conducted while sup-ported by Bellcore project ~CU01403301A1, andunder the auspices of the Columbia University CATin High Performance Computing and Communica-tions in Healthcare, a New York State Center forAdvanced Technology supported by the New YorkState Science and Technology Foundation.Re ferencesDalianis, Hercules, and Hovy, Edward.
1993.
Ag-gregation in Natural Language Generation.
InProceedings of the Fourth European Workshop onNatural Language Generation, Pisa, Italy.Elhadad, Michael.
1991.
FUF: The universal unifier- user manual, version 5.0.
Tech Report CUCS-038-91, Columbia Univ.Robin, Jacques.
1994.
Revision-Based Generationof Natural Language Summaries Providing Histor-ical Background: Corpus-based analysis, design,implementation and evaluation.
Ph.D. thesis,Computer Science Department, Columbia Univ.Kukieh, K., McKeown, K., Morgan, N., Phillips, J.,Robin, J., Shaw, J., and Lim, :I.
1993.
User-NeedsAnalysis and Design Methodology for an Auto-mated Documentation Generator.
In Proceedingsof the Fourth Bellcore/BCC Symposium on User-Centered Design, Piseataway, NJ.McKeown, Kathleen, Kukich, Karen, and Shaw,James.
1994.
Practical Issues in Automatic Doc-umentation Generation.
In Proceedings of the ~,thConference on Applied Natural Language Process-ing, Stuttgart, p.7-14.van Oirsouw, Robert.
1987.
The Syntax of Coordi-nation Beckenham: Croom Helm.331
