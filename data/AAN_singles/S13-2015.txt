Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on SemanticEvaluation (SemEval 2013), pages 88?92, Atlanta, Georgia, June 14-15, 2013. c?2013 Association for Computational LinguisticsUTTime: Temporal Relation Classification using Deep Syntactic FeaturesNatsuda LaokulratThe University of Tokyo3-7-1 Hongo, Bunkyo-ku,Tokyo, Japannatsuda@logos.t.u-tokyo.ac.jpMakoto MiwaThe University of Manchester131 Princess Street,Manchester, M1 7DN, UKmakoto.miwa@manchester.ac.ukYoshimasa TsuruokaThe University of Tokyo3-7-1 Hongo, Bunkyo-ku,Tokyo, Japantsuruoka@logos.t.u-tokyo.ac.jpTakashi ChikayamaThe University of Tokyo3-7-1 Hongo, Bunkyo-ku,Tokyo, Japanchikayama@logos.t.u-tokyo.ac.jpAbstractIn this paper, we present a system, UTTime,which we submitted to TempEval-3 for TaskC: Annotating temporal relations.
The sys-tem uses logistic regression classifiers and ex-ploits features extracted from a deep syntacticparser, including paths between event words inphrase structure trees and their path lengths,and paths between event words in predicate-argument structures and their subgraphs.
UT-Time achieved an F1 score of 34.9 basedon the graphed-based evaluation for Task C(ranked 2nd) and 56.45 for Task C-relation-only (ranked 1st) in the TempEval-3 evalua-tion.1 IntroductionTemporal annotation is the task of identifying tem-poral relationships between pairs of temporal enti-ties, namely temporal expressions and events, withina piece of text.
The temporal relationships are im-portant to support other NLP applications such astextual entailment, document summarization, andquestion answering.
The temporal annotation taskconsists of several subtasks, including temporal ex-pression extraction, event extraction, and temporallink identification and relation classification.In TempEval-3, there are three subtasks of thetemporal annotation process offered, i.e., Task A:Temporal expression extraction and normalization,Task B: Event extraction, and Task C: Annotatingtemporal relations.
This paper presents a systemto handle Task C. Based on the annotated data pro-vided, this subtask requires identifying pairs of tem-poral entities and classifying the pairs into one of the14 relation types according to TimeML (Pustejovskyet al 2005), i.e., BEFORE, AFTER, IMMEDIATELY BE-FORE, IMMEDIATELY AFTER, INCLUDES, IS INCLUDED,DURING, DURING INVERSE, SIMULTANEOUS, IDENTITY,BEGINS, BEGUN BY, END, and ENDED BY.The motivation behind our work is to utilize syn-tactic and semantic relationships between a pair oftemporal entities in the temporal relation classifica-tion task, since we believe that these relationshipsconvey the temporal relation.
In addition to generalfeatures, which are easily extracted from sentences(e.g., part of speech tags, lemmas, synnonyms), weuse features extracted using a deep syntactic parser.The features from the deep parser can be divided intotwo groups: features from phrase structure trees andfeatures from predicate-argument structures.
Thesefeatures are only applicable in the case that the tem-poral entities appear in the same sentence, so we useonly the general features for inter-sentence relations.Predicate-argument structure expresses semanticrelations between words.
This information can beextracted from a deep syntactic parser.
Featuresfrom predicate-argument structures can capture im-portant temporal information (e.g., prepositions oftime) from sentences effectively.The remaining part of this paper is organized asfollows.
We explain our approach in detail in Sec-tion 2 and then show the evaluation and results inSection 3.
Finally, we conclude with directions forfuture work in Section 4.2 ApproachOur system, UTTime, is based on a supervised ma-chine learning approach.
UTTime performs twotasks; TLINK identification and classification.
In88other words, UTTime identifies pairs of temporal en-tities and classifies these pairs into temporal relationtypes.2.1 TLINK identificationA pair of temporal entities that have a temporal rela-tion is called a TLINK.
The system first determineswhich pairs of temporal entities are linked by usinga ruled-based approach as a baseline approach.All the TempEval-3?s possible pairs of temporalentities are extracted by a set of simple rules; pairsof temporal entities that satisfy one of the followingrules are considered as TLINKs.?
Event and document creation time?
Events in the same sentence?
Event and temporal expression in the same sen-tence?
Events in consecutive sentences2.2 TLINK classificationEach TLINK is classified into a temporal relationtype.
We use a machine learning approach for thetemporal relation classification.
Two L2-regularizedlogistic regression classifiers, LIBLINEAR (Fan etal., 2008), are used; one for event-event TLINKs,and another one for event-time TLINKs.
In additionto general features at different linguistic levels, fea-tures extracted by a deep syntactic parser are used.The general features we employed are:?
Event and timex attributesAll attributes associated with events (class,tense, aspect, modality, and polarity) andtemporal expressions (type, value, func-tionInDocument, and temporalFunction) areused.
For event-event TLINKs, we also usetense/class/aspect match, tense/class/aspect bi-grams as features (Chambers et al 2007).?
Morphosyntactic informationWords, part of speech tags, lemmas within awindow before/after event words are extractedusing Stanford coreNLP (Stanford NLP Group,2012).?
Lexical semantic informationFigure 1: Phrase structure treeSynonyms of event word tokens from WordNetlexical database (Fellbaum, 1998) are used asfeatures.?
Event-Event informationFor event-event TLINKs, we usesame sentence feature to differentiate pairsof events in the same sentence from pairs ofevents from different sentences (Chambers etal., 2007).In the case that temporal entities of a particu-lar TLINK are in the same sentence, we extracttwo new types of sentence-level semantic informa-tion from a deep syntactic parser.
We use the Enjuparser (Miyao and Tsujii, 2008).
It analyzes syn-tactic/semantic structures of sentences and providesphrase structures and predicate-argument structures.The features we extract from the deep parser are?
Paths between event words in the phrase struc-ture tree, and up(?)/down(?)
lengths of paths.We use 3-grams of paths as features instead offull paths since these are too sparse.
An ex-ample is shown in Figure 1.
In this case, thepath between the event words, estimates andworth, is VBZ?, VX?, VP?, VP?, VP, PP?, PX?, IN?.The 3-grams of the path are, therefore, {VBZ?-VX?-VP?, VX?-VP?-VP?, VP?-VP?-VP, VP?-VP-PP?,VP-PP?-PX?, PP?-PX-?-IN?}.
The up/down path89Figure 2: Predicate argument structurelengths are 4 (VBZ?, VX?, VP?, VP?)
and 3 (PP?,PX?, IN?)
respectively.?
Paths between event words in predicate-argument structure, and their subgraphs.For the previous example, we can express therelations in predicate-argument structure repre-sentation as?
verb arg12: estimate (she, properties)?
prep arg12: worth (estimate, dollars)In this case, the path between the event words,estimates and worth, is?prep arg12:arg1.
Thatis, the type of the predicate worth is prep arg12and it has estimate as the first argument (arg1).The path from estimate to worth is in reversedirection (?
).The next example sentence, John saw mary be-fore the meeting, gives an idea of a more com-plex predicate-argument structure as shownin Figure 2.
The path between the eventwords, saw and meeting is ?prep arg12:arg1,prep arg12:arg2.We use (v, e, v) and (e, v, e) tuples of theedges and vertices on the path as features.For example, in Figure 2, the (v,e,v) tuplesare (see, ?prep arg12:arg1, before) and (be-fore, prep arg12:arg2, meeting).
In the sameway, the (e,v,e) tuple is (?prep arg12:arg1,before, prep arg12:arg2).
The subgraphsof (v, e, v) and (e, v, e) tuples are alsoused, including (see, ?prep arg12:arg1,*), (*, ?prep arg12:arg1, before), (*,?prep arg12:arg1, *), (*, prep arg12:arg2,meeting), (before, prep arg12:arg2, *), (*,prep arg12:arg2, *), (*, before, prep arg12:arg2),(?prep arg12:arg1, before, *), (*, before, *).From the above example, the features from pred-icate argument structure can properly capture thepreposition before.
It can also capture a preposi-tion from a compound sentence such as John metMary before he went back home.
The path betweenthe event words met and went are (?conj arg12:arg1,conj arg12:arg2) and the (v, e, v) and (e, v, e)tuples are (met, ?conj arg12:arg1, before), (before,conj arg12:arg2, went), and (?prep arg12:arg1, be-fore, prep arg12:arg2).2.3 Hybrid approachThe rule-based approach described in Section 2.1produces many unreasonable and excessive links.We thus use a machine learning approach to filterout those unreasonable links by training the modelin Section 2.2 with an additional relation type, UN-KNOWN, for links that satisfy the rules in Section2.1 but do not appear in the training data.In this way, for Task C, we first extract all the linksthat satisfy the rules and classify the relation types ofthose links.
After classifying temporal relations, weremove the links that are classified as UNKNOWN.3 EvaluationThe scores are calculated by the graph-based eval-uation metric proposed by UzZaman and Allen(2011).
We trained the models with TimeBank andAQUAINT corpora.
We also trained our models onthe training set with inverse relations.
The perfor-mance analysis is based on 10-fold cross validationon the development data.3.1 Task CIn Task C, a system has to identify appropriate tem-poral links and to classify each link into one tempo-ral relation type.
For Task C evaluation, we comparethe results of the models trained with and without thefeatures from the deep parser.
The results are shownin Table 1.
The rule-based approach gives a very lowprecision.3.2 Task C-relation-onlyTask C-relation-only provides a system with all theappropriate temporal links and only needs the sys-tem to classify the relation types.
Since our goal is toexploit the features from the deep parser, in Task C-relation-only, we measured the contribution of thosefeatures to temporal relation classification in Table2.90Features F1 P Rgen.
(rule) 22.51 14.32 52.58gen.
+ ph.
+ pas.
(rule) 22.61 14.30 54.01gen.
+ ph.
+ pas.
(hyb.)
33.52 36.23 31.19gen.
+ ph.
+ pas.
(hyb.
+ inv.)
39.53 37.56 41.70Table 1: Result of Task C. (rule: rule-based approach,hyb.
: hybrid approach, gen.: general features, ph.
:phrasestructure tree features, pas.
:predicate-argument structurefeatures, and inv.
: Inverse relations are used for training.
)Features F1 P Rgen.
64.42 64.59 64.25gen.
+ ph.
65.24 65.42 65.06gen.
+ pas.
66.40 66.55 66.25gen.
+ ph.
+ pas.
66.39 66.55 66.23gen.
+ ph.
+ pas.
(inv.)
65.30 65.39 65.20Table 2: Result of Task C-relation-only.
(gen.:general features, ph.
:phrase structure tree features,pas.
:predicate-argument structure features, and inv.
: In-verse relations are used for training.
)The predicate-argument-structure features con-tributed to the improvement more than those ofphrase structures in both precision and recall.
Thereason is probably that the features from phrasestructures that we used did not imply a temporal re-lation of events in the sentence.
For instance, thesentence ?John saw Mary before the meeting?
gives ex-actly the same path as of the sentence ?John sawMaryafter the meeting?.3.3 Results on test dataTables 3 and 4 show the results on the test data,which were manually annotated and provided by theTempEval-3 organizer.
We also show the scores ofthe other systems in the tables.
For the evaluationon the test data, we used the models trained withgeneral features, phrase structure tree features, andpredicate-argument structure features.UTTime-5 ranked 2nd best in Task C. Interest-ingly, training the models with inverse relations im-proved the system only when using the hybrid ap-proach.
This means that the inverse relations did notimprove the temporal classification but helped thesystem filter out unreasonable links (UNKNOWN)in the hybrid approach.
As expected, the ruled-basedapproach got a very high recall score at the expenseof precision.
UTTime-1, although it achieved the F1Approach F1 P Rrule (UTTime-1) 24.65 15.18 65.64rule + inv (UTTime-3) 24.28 15.1 61.99hyb.
(UTTime-4) 28.81 37.41 23.43hyb.
+ inv.
(UTTime-5) 34.9 35.94 33.92cleartk 36.26 37.32 35.25NavyTime 31.06 35.48 27.62JU-CSE 26.41 21.04 35.47KUL-KULTaskC 24.83 23.35 26.52Table 3: Result of Tack C on test data.
(rule: rule-basedapproach, hyb.
: hybrid approach, and inv.
: Inverse rela-tions are used for training.
)Approach F1 P Rgen.
+ ph.
+ pas.
(UTTime-1) 56.45 55.58 57.35gen.
+ ph.
+ pas.
(UTTime-2) 54.26 53.2 55.36gen.
+ ph.
+ pas.
(inv.)
(UTTime-3) 54.7 53.85 55.58NavyTime 46.83 46.59 47.07JU-CSE 34.77 35.07 34.48Table 4: Result of Task C-relation-only on test data.(gen.
: general features, ph.
:phrase structure tree features,pas.
:predicate-argument structure features, and inv.
: In-verse relations are used for training.
)score of only 24.65, got the highest recall among allthe systems.For Task C-relation-only, we achieved the highestF1 score, precision, and recall.
UTTime-2 basicallyhad the same models as that of UTTime-1, but weput different weights for each relation type.
The re-sults show that using the weights did not improvethe score in graph-based evaluation.4 ConclusionThe system, UTTime, identifying temporal links andclassifying temporal relation, is proposed.
The linkswere identified based on the rule-based approachand then some links were filtered out by a classi-fier.
The filtering helped improve the system consid-erably.
For the relation classification task, the fea-tures extracted from phrase structures and predicate-argument structures were proposed, and the featuresimproved the classification in precision, recall, andF-score.In future work, we hope to improve the classifica-tion performance by constructing timegraphs (Millerand Schubert, 1999), so that the system can use in-formation from neighbor TLINKs as features.91ReferencesJames Pustejovsky, Robert Ingria, Roser Saur?
?, Jose?Castan?o, Jessica Littman, Rob Gaizauskas, AndreaSetzer, Graham Katz, Inderjeet Mani 2005.
The spec-ification language TimeML.
The Language of Time: Areader, pages 545?557Stanford Natural Language Processing Group.
2012.Stanford CoreNLP.Christiane Fellbaum.
1998.
WordNet: An ElectronicLexical Database.
Cambridge, MA: MIT Press.Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-RuiWang, and Chih-Jen Lin.
2008.
LIBLINEAR: A Li-brary for Large Linear Classification.Nathanael Chambers, Shan Wang and Dan Jurafsky.2007.
Classifying Temporal Relations betweenEvents.
In ACL 2007, pages 173?176.Yusuke Miyao and Jun?ichi Tsujii.
2008.
Feature ForestModels for Probabilistic HPSG Parsing.
In Computa-tional Linguistics.
34(1).
pages 35?80, MIT Press.Naushad UzZaman and James F. Allen.
2011.
TemporalEvaluation.
In ACL 2011, pages 351?356.Stephanie A. Miller and Lenhart K. Schubert.
1999.Time Revisited.
In Computational Intelligence 6,pages 108?118.92
