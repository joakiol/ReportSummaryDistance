Proceedings of SSST-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 57?66,October 25, 2014, Doha, Qatar.
c?2014 Association for Computational LinguisticsExpanding the Language model in a low-resource hybrid MT systemGeorge Tambouratzis Sokratis Sofianopoulos Marina VassiliouILSP, Athena R.C ILSP, Athena R.C ILSP, Athena R.Cgiorg_t@ilsp.gr s_sofian@ilsp.gr mvas@ilsp.grAbstractThe present article investigates the fusion ofdifferent language models to improve transla-tion accuracy.
A hybrid MT system, recently-developed in the European Commission-funded PRESEMT project that combines ex-ample-based MT and Statistical MT princi-ples is used as a starting point.
In this article,the syntactically-defined phrasal languagemodels (NPs, VPs etc.)
used by this MT sys-tem are supplemented by n-gram languagemodels to improve translation accuracy.
Forspecific structural patterns, n-gram statisticsare consulted to determine whether the pat-tern instantiations are corroborated.
Experi-ments indicate improvements in translationaccuracy.1 IntroductionCurrently a major part of cutting-edge researchin MT revolves around the statistical machinetranslation (SMT) paradigm.
SMT has been in-spired by the use of statistical methods to createlanguage models for a number of applicationsincluding speech recognition.
A number of dif-ferent translation models of increasing complex-ity and translation accuracy have been developed(Brown et al., 1993).
Today, several packages fordeveloping statistical language models are avail-able for free use, including SRI (Stolke et al.,2011), thus supporting research into statisticalmethods.
A main reason for the widespreadadoption of SMT is that it is directly amenable tonew language pairs using the same algorithms.An integrated framework (MOSES) has beendeveloped for the creation of SMT systems(Koehn et al., 2007).
The more recent develop-ments of SMT are summarised by Koehn (2010).One particular advance in SMT has been the in-tegration of syntactically motivated phrases inorder to establish correspondences betweensource language (SL) and target language (TL)(Koehn et al., 2003).
Recently SMT has beenenhanced by using different levels of abstractione.g.
word, lemma or part-of-speech (PoS), in fac-tored SMT models so as to improve SMT per-formance (Koehn & Hoang, 2007).The drawback of SMT is that SL-to-TL paral-lel corpora of the order of millions of tokens arerequired to extract meaningful models for trans-lation.
Such corpora are hard to obtain, particu-larly for less resourced languages.
For this rea-son, SMT researchers are increasingly investigat-ing the extraction of information from monolin-gual corpora, including lexica (Koehn & Knight,2002 & Klementiev et al., 2012), restructuring(Nuhn et al., 2012) and topic-specific informa-tion (Su et al., 2011).As an alternative to pure SMT, the use of lessspecialised but more readily available resourceshas been proposed.
Even if such approaches donot provide a translation quality as high as SMT,their ability to develop MT systems with verylimited resources confers to them an importantadvantage.
Carbonell et al.
(2006) have proposedan MT method that requires no parallel text, butrelies on a full-form bilingual dictionary and adecoder using long-range context.
Other systemsusing low-cost resources include METIS(Dologlou et al., 2003) and METIS-II (Markan-tonatou et al., 2009), which are based only onlarge monolingual corpora to translate SL texts.Another recent trend in MT has been towardshybrid MT systems, which combine characteris-tics from multiple MT paradigms.
The idea isthat by fusing characteristics from different para-digms, a better translation performance can beattained (Wu et al., 2005).
In the present article,the PRESEMT hybrid MT method using pre-dominantly monolingual corpora (Sofianopouloset al., 2012 & Tambouratzis et al., 2013) is ex-tended by integrating n-gram information to im-prove the translation accuracy.
The focus of thearticle is on how to extract, as comprehensivelyas possible, information from monolingual cor-pora by combining multiple models, to allow ahigher quality translation.A review of the base MT system is performedin section 2.
The TL language model is then de-tailed, allowing new work to be presented in sec-tion 3.
More specifically, via an error analysis, n-gram based extensions are proposed to augment57the language model.
Experiments are presentedin section 4 and discussed in section 5.2 The hybrid MT methodology in briefThe PRESEMT methodology can be brokendown into the pre-processing stage, the post-processing stage and two translation steps eachof which addresses different aspects of the trans-lation process.
The first translation step estab-lishes the structure of the translation by perform-ing a structural transformation of the source sidephrases based on a small bilingual corpus, tocapture long range reordering.
The second stepmakes lexical choices and performs local wordreordering within each phrase.
By dividing thetranslation process in these two steps the chal-lenging task of both local and long distance reor-dering is addressed.Phrase-based SMT systems give accuratetranslations for language pairs that only require alimited number of short-range reorderings.
Onthe contrary, when translating between languageswith free word order, these models prove ineffi-cient.
Instead, reordering models need to be built,which require large parallel training data, asvarious reordering challenges must be tackled.2.1 Pre-processingThis involves PoS tagging, lemmatising andshallow syntactic parsing (chunking) of thesource text.
In terms of resources, the methodol-ogy utilises a bilingual lemma dictionary, an ex-tensive TL monolingual corpus, annotated withPoS tags, lemmas and syntactic phrases (chunks),and a very small parallel corpus of 200 sen-tences, with tagged and lemmatised source sideand tagged, lemmatised and chunked target side.The bilingual corpus provides samples of thestructural transformation from SL to TL.
Duringthis phase, the translation methodology ports thechunking from the TL- to the SL-side, alleviatingthe need for an additional parser in SL.
An ex-ample of the pre-processing stage is shown inFigure 1, for a sentence translated from Greek toEnglish.
For this sentence, the chunk structure isshown at the bottom part of Figure 1.2.2 Structure SelectionStructure selection transforms the input text us-ing the limited bilingual corpus as a structuralknowledge base, closely resembling the ?transla-tion by analogy?
aspect of EBMT systems (Hut-chins, 2005).
Using available structural informa-tion, namely the order of syntactic phrases, thePoS tag of the head token of each phrase and thecase of the head token (if available), we retrievethe most similar source side sentence from theparallel corpus.
Based on the alignment informa-tion from the bilingual corpus between SL andTL, the input sentence structure is transformed tothe structure of the target side translation.For the retrieval of the most similar sourceside sentence, an algorithm from the dynamicprogramming paradigm is adopted (Sofianopou-los et al., 2012), treating the structure selectionprocess as a sequence alignment, aligning theinput sentence to an SL side sentence from thealigned parallel corpus and assigning a similarityscore.
The implementation is based on the Smith-Waterman algorithm (Smith and Waterman,1981), initially proposed for similarity detectionbetween protein sequences.
The algorithm findsthe optimal local alignment between the two in-put sequences at clause level.The similarity of two clauses is calculated bytaking into account the edit operations (replace-ment, insertion or removal) that must be appliedto the input sentence in order to transform it to asource side sentence from the corpus.
Each ofthese operations has an associated cost, consid-ered as a system parameter.
The parallel corpussentence that achieves the highest similarityscore is the most similar one to the input sourcesentence.
For the example of Figure 1, the com-parison of the SL sentence structure to the paral-lel corpus is schematically depicted in Figure 2.The resulting TL sentence structure is shown inFigure 3 in terms of phrase types and heads. 	!"#$%&'()*)+,&&-(./0')'$12&$)3.*1$14'+1.-5'46%&4&-+&(1-/'2.7%./8%&&9:.-+&4+'-+4!
;<=<=<=<=<	=!#>?
@<'(ABC=D@<'466ABCA-.AB0EC= ?
@<2*ABC=D@<-.ABC=D@<'466AB	CA-6ABFEC=!    Figure 1.
Pre-processing of sentence (its gloss insquare brackets) into a chunk sequence.58 6:                           Figure 2.
Comparing sentence structure to paral-lel corpus templates, to determine the best-matching SL structure (here, the 4th entry).#>?
@<'(ABC=D@<'466ABCA-.AB0EC= ?
@<2*ABC=D@<-.ABC=D@<'466AB	CA-6ABFEC=!       '(2: <%*AB'$%&'()C=6:<1-AB./CA--AB0')C= 6:<--AB3.
*1$14'+1.-C=2: <22AB6%&4&-+C=6:<1-AB1-CA--AB8%&&9C=!Figure 3.
SL-to-TL Structure transformationbased on the chosen parallel corpus template.2.3 Translation equivalent selectionThis second translation step performs word trans-lation disambiguation, local word reorderingwithin each syntactic phrase as well as additionand/or deletion of auxiliary verbs, articles andprepositions.
All of the above are performed byusing a syntactic phrase model extracted from apurely monolingual TL corpus.
The final transla-tion is produced by the token generation compo-nent, since all processing during the translationprocess is lemma-based.Each sentence contained within the text to betranslated is processed separately, so there is noexploitation of inter-sentential information.
Thefirst task is to select the correct TL translation ofeach word.
The second task involves establishingthe correct word order within each phrase.
Foreach phrase of the sentence being translated, thealgorithm searches the TL phrase model for simi-lar phrases.
All retrieved TL phrases are com-pared to the phrase to be translated.
The com-parison is based on the words included, their tagsand lemmas and any other morphological fea-tures (case, number etc.).
The stable-marriagealgorithm (Gale & Shapley, 1962) is applied forcalculating the similarity and aligning the wordsof a phrase pair.This word reordering process is performed si-multaneously with the translation disambigua-tion, using the same TL phrase model.
Duringword reordering the algorithm also resolves is-sues regarding the insertion or deletion of articlesand other auxiliary tokens.
Though translationequivalent selection implements several taskssimultaneously, it produces encouraging resultswhen translating from Greek (a free-word orderlanguage) to English (an SVO language).2.4 Post-processingIn this stage, a token generator is applied to thelemmas of the translated sentences together withthe morphological features of their equivalentsource words, to produce the final word forms.2.5 Comparison of the method to SMTIn the proposed methodology, the structure selec-tion step performs long distance reordering with-out resorting to syntactic parsers and withoutemploying any rules.
In phrase-based SMT, longdistance reordering is performed by either usingSL syntax, with the use of complex reorderingrules, or by using syntactic trees.The similarity calculation algorithms used inthe two translation steps of the proposed methodare of a similar nature to the extraction of trans-lation models in factored-based SMT.
In SMT,different matrices are created for each model (i.e.one for lemmas and another one for PoS tags),while in the methodology studied here lemmasand tags are handled at the same time.The main advantage of the method studiedhere is its ability to create a functioning MT sys-tem with a parallel corpus of only a few sen-tences (200 sentences in the present experi-ments).
On the contrary, it would not be possibleto create a working SMT with such a corpus.3 Information extraction from themonolingual corpus3.1 Standard indexed phrase modelThe TL monolingual corpus is processed to ex-tract two complementary types of information,both employed at the second phase of the transla-tion process (cf.
sub-section 2.3).
The first im-plements a disambiguation between multiplepossible translations, while the second providesthe micro-structural information to establish to-ken order in the final translation.59Both these types of information are extractedfrom one model.
More specifically, during pre-processing of the corpus, a phrase model is es-tablished that provides the micro-structural in-formation on the translation output, to determineintra-phrasal word order.
The model is stored ina file structure, where a separate file is createdfor phrases according to their (i) type, (ii) headand (iii) head PoS tag.The TL phrases are then organised in a hashmap that allows the storage of multiple values foreach key, using as a key the three aforemen-tioned criteria.
For each phrase the number ofoccurrences within the corpus is also retained.Each hash map is stored independently in a filefor very fast access by the search algorithm.
As aresult of this process hundreds of thousands offiles are generated, one for each combination ofthe three aforementioned criteria.
Each file is ofa small size and thus can be retrieved quickly.For creating the model used here, a corpus of30,000 documents has been processed for theTL, where each document contains a concatena-tion of independent texts of approximately1MByte in size.
The resulting phrase model con-sists of 380,000 distinct files, apportioned into12,000 files of adjectival chunks, 348,000 ofnoun chunks, 17,000 of verb chunks and 3,000 ofadverbial chunks.
A sample of the indexed filecorresponding to verb phrases with head ?help?
isshown in Figure 4.Occurrences Phrase structure1 41448 help (VV)2 29575 to(TO) help(VV)3 5896 will(MD) help(VV)4 4795 can(MD) help(VV)5 2632 have(VHD) help(VVN)Figure 4.
Example of indexed file for ?help?.3.2 Error analysis on translation outputIn Table 1, the translation accuracy attained bythe proposed hybrid approach in comparison toestablished systems is displayed.
The proposedmethod occupies the middle ground between thetwo higher performing SMT-based systems(Bing and Google) and the Systran and World-Lingo commercial systems.Though the BLEU score of the proposedmethod is 0.17 BLEU points lower than theGoogle score, the proposed method achieveswhat is a respectable score with a parallel corpusof only 200 sentences.
Though the exact re-sources for Google or Bing are not disclosed, it iswidely agreed that they are at least 3 orders ofmagnitude larger (very likely even more) justify-ing the lower scores achieved by the proposedlow-resource method.Number of sentences 200 Resources stand.Reference translations 1 Language pair EL?ENMetricsMT config.BLEU NIST Me-teor TERPRESEMT-baseline 0.3462 6.974 0.3947 51.05Google 0.5259 8.538 0.4609 42.23Bing 0.4974 8.279 0.4524 34.18SYSTRAN 0.2930 6.466 0.3830 49.72WorldLingo 0.2659 5.998 0.3666 50.63Table 1.
Values of performance metrics for data-set1, using the baseline version of the proposedmethod and other established systems.The n-gram method proposed in this article forsupplementary language modelling is intended toidentify recurring errors in the output or to verifytranslation choices made by the indexed mono-lingual model.
The errors mainly concern gen-eration of tokens out of lemmata, positioning oftokens within phrases as well as disambiguationchoices.
An indicative list of errors encounteredfor Greek to English translation follows:Article introduction & deletion: Given thatthere is no 1:1 mapping between Greek and Eng-lish concerning the use of the definite article, it isessential to check whether it is correctly intro-duced in specific cases (e.g.
before propernames).Generation of verb forms: Specific errors ofthe MT system involve cases of active/passivevoice mismatches between SL and TL and depo-nent verbs, i.e.
active verbs with mediopassivemorphology.
For example, the Greek deponentverb "???????"
(come) is translated to ?be come?by the system token generation component thattakes into account the verb?s passive morphologyin SL.
This erroneous translation should be cor-rected to ?come?, i.e.
the auxiliary verb ?be?must be deleted.In-phrase token order: The correct orderingof tokens within a given phrase (which occasion-ally fails to be established by the proposed sys-tem) can be verified via the n-gram model.Prepositional complements: When translat-ing the prepositional complement of a verb (cf.
?depend + on?
), it is often the case that the incor-rect preposition is selected during disambigua-tion, given that no context information is avail-60able.
The n-gram model may be accessed toidentify the appropriate preposition.Double preposition: Prepositions appearingin succession within a sentence need to be re-duced to one.
For instance, the translation of theNP ?????
??
????????
???
pi??????????
(= duringthe siege) results in a prepositional sequence(?during of?)
due to the translation of the indi-vidual parts as follows:????
??
????????
= during???
= of thepi?????????
= siegeIn this example a single preposition is needed.3.3 Introducing n-gram modelsA new model based on n-gram appearances isintended to supplement phrase-based informationalready extracted from the monolingual corpus(cf.
section 3.1).
As the monolingual corpus isalready lemmatised, both lemma and token-basedn-grams are extracted.
To simplify processing,no phrase-boundary information is retained in then-gram models.One issue is how the n-gram model will becombined with the indexed phrase model of thehybrid MT algorithm.
The new n-gram modelcan be applied at the same stage of the transla-tion process.
Alternatively, n-grams can be ap-plied after the indexed phrase model, for verifi-cation or revision of the translation produced byusing the indexed corpus.
Then, the indexedphrase model generates a first translation, whichrepresents a hypothesis Hi, upon which a numberof tests are performed.
If the n-gram model cor-roborates this hypothesis, no modification is ap-plied, whilst if the n-gram likelihood estimateslead to the rejection of the hypothesis, the trans-lation is revised accordingly.Having adopted this set-up, the main task is tospecify the hypotheses to be tested.
To that end,a data-driven approach based on the findings ofthe error analysis (cf.
section 3.2) is used.The creation of the TL n-gram model isstraightforward and employs the publicly avail-able SRILM tool (Stolke et al., 2011) to extractn-gram probabilities.
Both 2-gram and 3-grammodels have been extracted, creating both token-based and lemma-based models to support que-ries in factored representation levels.
The n-grammodels have used 20,000 documents in English,each document being an assimilation of web-posted texts with a cumulative size of 1 Mbyte(harvested without any restrictions in terms ofdomain).
Following a pre-processing to removewords with non-English characters, the final cor-pus contains a total of 707.6 million tokens andforms part of the EnTenTen corpus1.
When cre-ating both 2-grams and 3-grams, Witten-Bellsmoothing is used and all n-grams with less than5 occurrences are filtered out to reduce the modelsize.
Each n-gram model contains circa 25 mil-lion entries, which are the SRILM-derived loga-rithms of probabilities.3.4 Establishing translation hypothesesA set of hypotheses has been established basedon the error analysis, to improve the translationquality.
Each hypothesis is expressed by amathematical formula which checks the likeli-hood of an n-gram, via either the lemma-based n-gram model (the relevant entry being denoted asp_lem(), i.e.
the probability of the n-gram oflemmas) or the token-based model (the relevantentry being denoted as p_tok).
The relevant 2-gram or 3-gram model is consulted depending onwhether the number of arguments is 2 or 3.Hypothesis H1: This hypothesis checks for theexistence of a deponent verb, i.e.
verb which is inpassive voice in SL but has an active voice trans-lation.
Instead of externally providing a list ofdeponent verbs in Greek, the n-gram model isused to determine translations for which the verbis always in active voice, by searching the fre-quency-of-occurrence in the TL corpus.
As anexample of a correct rejection of hypothesis H1,consider the verb ??????????
[to sleep] which istranslated by the hybrid MT system into ?beslept?
as in SL this verb has a medio-passivemorphology.
As the pattern ?be slept?
is ex-tremely infrequent in the monolingual corpus,hypothesis H1 is rejected and lemma ?be?
is cor-rectly deleted, to translate ??o???????
into?sleep?.
The corresponding hypothesis is:H1 :p_lem (A,B)>thres_h1,where Lem (A)=?be?
and PoS(B) =?VVN?If the aforementioned hypothesis does nothold, (i.e.
the probability of the 2-gram formedby the auxiliary verb with lemma B is very rare)then H1 is rejected and the auxiliary verb is de-leted, as expressed by the following formula:If (H1 == false) then {A, B} ?
{B}Hypothesis H2: This hypothesis checks the in-clusion of an article, within a trigram of wordforms.
If this hypothesis is rejected based on n-gram evidence, the article is deleted.
Hypothesis1http://www.sketchengine.co.uk/documentation/wiki/Corpora/enTenTen61H2 is expressed as follows, where thres_h2 is aminimum threshold margin:H2: min{p_lem(A,the),p_lem(the,B)} - p_lem(A;B) <thres_h2An example of correctly rejecting H2 is for tri-gram {see, the, France}, which is revised to {see,France}.If (H2 == false) then {A, the, B} ?
{A, B}Hypothesis H3: This hypothesis is used to han-dle cases where two consecutive prepositionsexist (for prepositions the PoS tag is ?IN?).
Inthis case one of these prepositions must be de-leted, based on the n-gram information.
Thisprocess is expressed as follows:H3 : max((p_lem(A;B),p_lem(A,C)), where PoS(A)==?IN?& PoS(B)==?IN?If (H3==TRUE) then {A, B, C} ?
{A, C} or {B, C}Hypothesis H4: This hypothesis checks if thereexists a more suitable preposition than the onecurrently selected for a given trigram {A, B, C},where PoS(B) = ?IN?.
H4 is expressed as:H4: p_lem(A,B,C)-max(p_lem(A,D,C)>thres_h4 ,for all D where PoS{D}==?IN?.If this hypothesis is rejected, B is replaced byD:If (H4==FALSE) then ({A,B,C} ?
{A,D,C}Hypothesis H5: This hypothesis checks if for abigram, the wordforms might be replaced by thecorresponding lemmas, as the wordform-basedpattern is too infrequent.
This is formulated as:H5: p_tok(A,B)- p_tok(lem(A),lem(B)) > thres_h5An example application would involve proc-essing bigram {can, is} and revising it into thecorrect {can, be} by rejecting H5:If (H5==FALSE) then {A,B } ?
{lem(A),lem(B)}Similarly, H5 can revise the plural form ?in-formations?
to the correct ?information?.Hypothesis H6: This hypothesis also handlesarticle deletion, by studying however bigrams,rather than trigrams, (cf.
H1).
This hypothesis isthat the bigram frequency exceeds a giventhreshold value (thres_6).H6 :p_lem(2-gram(A, B))>thres_h6, where PoS(A)=?DT?If H6 is rejected, the corresponding article isdeleted, as indicated by the following formula:If (H6==FALSE) then {A,B} ?
{B}4 Objective Evaluation Experiments4.1 Experiment designThe experiments reported in the present articlefocus on the Greek ?
English language pair, thereason being that this is the language pair forwhich the most extensive experimentation hasbeen reported for the PRESEMT system (Tam-bouratzis et al., 2013).
Thus, improvements inthe translation accuracy will be more difficult toattain.
Two datasets are used to evaluate transla-tion accuracy, a development set (dataset1) and atest set (dataset2), each containing 200 sentencesof length ranging from 7 to 40 tokens.
These setsof sentences are readily available for downloadover the project website2.
Two versions of thebilingual lexicon have been used, a base versionand an expanded one.Both sets are manually translated by Greek na-tive speakers and then cross-checked by Englishnative speakers, with one reference translationper sentence.
A range of evaluation metrics areemployed, namely BLEU (Papineni et al., 2002),NIST (NIST 2002), Meteor (Denkowski and La-vie, 2011) and TER (Snover et al., 2006).4.2 Experimental resultsThe exact sequence with which hypotheses aretested affects the results of the translation, sinceonly one hypothesis is allowed to be applied toeach sentence token at present.
This simplifiesthe evaluation of the hypotheses?
effectiveness.As a result, hypotheses are applied in strict order(i.e.
first H1, then H2 etc.).
The threshold valuesof Table 2 were settled upon via limited experi-mentation using sentences from dataset1.Hypothesis testing was applied to both data-sets.
Notably, dataset1 has been used in the de-velopment of the MT systems and thus the re-sults obtained with dataset2 should be consideredthe most representative ones, as they are com-2www.presemt.eu62pletely unbiased and the set of sentences wasunseen before the experiment and was onlytranslated once.
The number of times each hy-pothesis is tested for each dataset is quoted inTable 3, for both the standard (denoted as?stand?)
and the enriched resources (?enrich?
).Parameter name hypothesis Exper.valuethres_h1 (H1) chk4 -4.50thres_h2 (H2)chk5 -4.00thres_h4 (H4)Ch k8 1.50thres_h5 (H5)chk2 1.50thres_h6 (H6)Ch k11 -5.50Table 2.
Parameter values for experimentsHypothesis activations per experimentdataset 1 dataset 2Resource stand.
enrich.
stand.
enrichH1 6 6 13 10H2 1 1 0 0H3 2 3 3 3H4 7 8 9 8H5 68 68 62 68H6 32 32 32 44Table 3.
Tested hypotheses per datasetSince the first four hypotheses are only acti-vated a few times each, when reporting the re-sults, the applications of hypotheses H1 to H4are grouped together.
As hypotheses 5 and 6 aretested more frequently, the application of eachone of them is reported separately.Number of sentences 200 Resources stand.Reference transla-tions 1Languagepair EL?ENMetrics MT config.BLEU NIST Meteor TERBaseline 0.3462 6.974 0.3947 51.05H1 to H4 0.3479 6.985 0.3941 50.84H1 to H5 0.3503 7.006 0.3944 50.80H1 to H6 0.3517 7.049 0.3935 50.42Table 4.
Metric scores for dataset1, using thestandard language resources, for the baseline sys-tem and for different hypotheses.In Table 4, the results are depicted for the fourMT objective evaluation metrics, when usingdataset 1.
For each metric, the configuration giv-ing the highest score is depicted in boldface.
Ascan be seen, the best BLEU score is obtainedwhen checking all 6 hypotheses, and the sameapplies to NIST and TER.
On the contrary, forMeteor the best result is obtained without resort-ing to the n-gram model information.
Still thedifference in Meteor scores is minor (less than0.3%).
The improvements in BLEU, NIST andTER are respectively +1.6%, +1.0% and -1.2%over the baseline, when using all 6 hypotheses.Furthermore, as the number of hypotheses to betested increases, the performance for all threemetrics is improved.Number of sentences 200 Resources enrich.Reference transla-tions 1Languagepair EL?ENMetrics MT config.BLEU NIST Meteor TERBaseline 0.3518 7.046 0.3997 50.14H1 to H4 0.3518 7.054 0.3990 50.00H1 to H5 0.3541 7.094 0.3995 49.72H1 to H6 0.3551 7.135 0.3984 49.37Table 5.
Metric scores for dataset1, using en-riched language resources, for different systems.In Table 5, the same experiment is repeatedusing an enriched set of lexical resources includ-ing a bilingual lexicon with higher coverage.
No-tably, on a case-by-case comparison, the scoresin Table 5 are higher than those of Table 4, con-firming the benefits of using enriched lexicalresources.
Focusing on Table 5, and comparingthe MT configurations without and with hy-pothesis testing, the results obtained are qualita-tively similar to those of Table 4.
Again, the bestscores for Meteor are obtained when no hypothe-ses are tested.
On the other hand, for the othermetrics the n-gram modeling coupled with hy-pothesis testing results in an improvement to thescores obtained.
The improvements obtainedamount to approximately 1.0% for each one ofBLEU, NIST and TER, over the baseline systemscores indicating a measurable improvement.In Tables 6 and 7, the respective experimentsare reported, using dataset 2 instead of dataset 1,with (i) standard and (ii) enriched lexical re-sources.
With standard resources (Table 6), con-sistent improvements are achieved as more hy-potheses are activated, for both BLEU and NIST.In the case of Meteor, the best performance isobtained when no hypotheses are activated, butonce again the Meteor score varies minimally(by less than 0.2%).
On the contrary, the im-provement obtained by activating hypothesis-checking is equal to 3.0% (BLEU), 1.4% (NIST)and 1.2% (TER).
As can be seen, the improve-ment for previously unused dataset2 is propor-tionally larger than for dataset1.63Number of sentences 200 Resources stand.Reference transla-tions 1Languagepair EL?ENMetrics MT config.BLEU NIST MeteorBaseline 0.2747 6.193 0.3406 BaselineH1 to H4 0.2775 6.217 0.3403 H1 to H4H1 to H5 0.2815 6.246 0.3400 H1 to H5H1 to H6 0.2837 6.280 0.3401 H1 to H6Table 6.
Metric scores for dataset2, using stan-dard language resources, for different systems.Number of sentences 200 Resources enrich.Reference transla-tions 1 Language pair EL?ENMetrics MT config.BLEU NIST Meteor TERBaseline 0.3008 6.541 0.3784 55.21H1 to H4 0.3059 6.569 0.3790 54.96H1 to H5 0.3105 6.593 0.3791 54.75H1 to H6 0.3096 6.643 0.3779 54.64Table 7.
Metric scores for dataset2, using en-riched language resources, for different systems.Using the enriched resources, as indicated inTable 7, the best results for BLEU and Meteorare obtained with hypotheses 1 to 5, while forNIST and TER the best results are obtained whenall six hypotheses are tested.
In the case of Me-teor any improvement is marginal (of the orderof 0.2%).
The improvements of the other metricsare more substantial, being 3.3% for BLEU,1.6% for NIST and 1.0% for TER.A statistical analysis has been undertaken todetermine whether the additional n-gram model-ling improves significantly the translation scores.More specifically, paired t-tests were carried outto determine whether the difference in translationaccuracy was statistically significant, comparingthe MT accuracy obtained with all six hypothe-ses versus the baseline system.
Two populationswere formed by scoring independently eachtranslated sentence with each one of the NIST,BLEU and TER metrics, for dataset2.
It wasfound that when using the standard resources (cf.Table 6), the translations were scored by TER tobe significantly better when using the 6 hypothe-ses, in comparison to the baseline system, whilefor BLEU and NIST the translations for the 2systems were equivalent (at a 0.05 confidencelevel).
When using the enriched resources, nostatistically significant difference was detectedfor any metric at a 0.05 confidence level, butsignificant differences were detected for all 3metrics at a 0.10 confidence level (cf.
Table 7).5 DiscussionAccording to the experimental results, the addi-tion of a new model in the hybrid MT system hascontributed to an improved translation quality.These improvements have been achieved using alimited experimentation time and only a few hy-potheses on what is an extensively developedlanguage pair, for the proposed MT methodol-ogy.
It is likely that as the suite of hypotheses isincreased, larger improvements in objective met-rics can be obtained.When applying the hypotheses, the initial sys-tem translation is available both at token-leveland at lemma-level.
Out of the 6 hypothesestested here, 5 involve token-based informationand only one involves lemmas.
If additional hy-potheses are added operating on lemmas, a fur-ther improvement is expected.Notably, the new n-gram modelling requiresno collection or annotation of additional re-sources.
The use of an established softwarepackage (SRILM) for assembling an n-gram da-tabase, via which hypotheses are rejected or con-firmed, results in a straightforward implementa-tion.
In addition, multiple models can be effec-tively combined to improve translation accuracyby investigating different language aspects.An interesting point is that the n-gram modelscreated are factored (i.e.
including information atboth lemma and token level).
Thus, differenttypes of queries may be supported, to improvetranslation quality.6 Future workThe experiments reported here have shown thatimprovements can be achieved, without specify-ing in detail the templates searched for, but al-lowing for more general formulations.One aspect which should be addressed in fu-ture work concerns evaluation.
Currently, this islimited to objective metrics.
Still it is well-worthinvestigating the extent to which translation im-provement is reflected by subjective metrics,which are the preferred instrument for qualityevaluation (Callison-Burch at al., 2011).In addition, it is possible to achieve furtherimprovements if the hypothesis templates aremade more detailed, by supplementing the lexi-cal information by detailed PoS information.Tests performed so far have used empirically-set parameter values for the hypotheses.
It is pos-sible to adopt a systematic methodology such asMERT or genetic algorithms to optimise the ac-tual values of the hypotheses parameters.64Another observation concerns the manner inwhich the two distinct language models are ap-plied.
In the present article, n-grams are used tocorrect a translation already established via thephrase indexed model, having a second-level,error-checking role.
It is possible, however, torevise the mode of application of the languagemodels, so that instead of a sequential applica-tion, the two model families are consulted at thesame time.
This leads to an MT system that ex-ploits the information from multiple models con-currently, and is the focus of future research.AcknowledgementsThe research leading to these results has receivedfunding from the POLYTROPON project(KRIPIS-GSRT, MIS: 448306).ReferencesChris Callison-Burch, Philip Koehn, ChristofMonz, and Omar F. Zaidan.
2011.
Findings ofthe 2011Workshop on Statistical MachineTranslation.
Proceedings of the 6th Workshopon Statistical Machine Translation, pp.
22?64,Edinburgh, Scotland, UK, July 30?31, 2011.Jaime Carbonell, Steve Klein, David Miller, Mi-chael Steinbaum, Tomer Grassiany, andJochen Frey.
2006.
Context-Based MachineTranslation.
Proceedings of the 7th Confer-ence of the Association for Machine Transla-tion in the Americas, pages 19-28.Michael Denkowski and Alon Lavie.
2011.
Me-teor 1.3: Automatic Metric for Reliable Opti-mization and Evaluation of Machine Transla-tion Systems.
EMNLP 2011 Workshop on Sta-tistical Machine Translation, Edinburgh, Scot-land, pp.
85-91.Yannis Dologlou, Stella Markantonatou, OlgaYannoutsou, Soula Fourla, and Nikos Ioan-nou.
2003.
Using Monolingual Corpora forStatistical Machine Translation: The METISSystem.
Proceedings of the EAMT-CLAW?03Workshop, Dublin, Ireland, 15-17 May, pp.61-68.David Gale and Lloyd S. Shapley.
1962.
CollegeAdmissions and the Stability of Marriage.American Mathematical Monthly, Vol.
69, pp.9-14.John Hutchins.
2005.
Example-Based MachineTranslation: a Review and Commentary.
Ma-chine Translation, Vol.
19, pp.197-211.Alexandre Klementiev, Ann Irvine, Chris Calli-son-Burch and David Yarowsky.
2012.
To-ward Statistical Machine Translation withoutParallel Corpora.
Proceedings of EACL2012,Avignon, France, 23-25 April, pp.
130-140.Philip Koehn.
2010.
Statistical Machine Transla-tion.
Cambridge University Press, Cambridge.Philipp Koehn and Kevin Knight.
2002.
Learninga Translation Lexicon from Monolingual Cor-pora.
Proceedings of the ACL-02 workshop onUnsupervised lexical acquisition, Vol.9, pp.9-16.Philipp Koehn, Franz Josef Och, and DanielMarcu, Statistical Phrase-Based Translation,Proceedings of HLT/NAACL-2003 Confer-ence, Vol.1, pp.48-54.Philip Koehn, Hieu Hoang, Alexandra Birch,Chris Callison Burch, Marcello Federico, Ni-cola Bertoldi, Brooke Cowan, Wade Shen,Christine Moran, Richard Zens, Chris Dyer,Ondrej Bojar, Alexandra Constantin, and EvanHerbst.
2007.
Moses: Open Source Toolkit forStatistical Machine Translation.
Proceedingsof the ACL-2007 Demo & Posters Sessions,Prague, June 2007, pp.
177-180.Philipp Koehn, and Hieu Hoang.
2007.
FactoredTranslation Models.
Proceedings of the 2007Joint Conference on Empirical Methods inNatural Language Processing and Computa-tional Natural Language Learning, Prague,Czech Republic, pp.
868-876.Stella Markantonatou, Sokratis Sofianopoulos,Olga Yannoutsou, and Marina Vassiliou.2009.
Hybrid Machine Translation for Low-and Middle- Density Languages.
LanguageEngineering for Lesser-Studied Languages, S.Nirenburg (ed.
), pp.243-274.
IOS Press.ISBN: 978-1-58603-954-7NIST 2002.
Automatic Evaluation of MachineTranslation Quality Using n-gram Co-occurrences Statistics.Malte Nuhn, Arne Mauser, and Hermann Ney.2012.
Deciphering Foreign Language byCombining Language Models and ContextVectors.
Proceedings of the 50th AnnualMeeting of the Association for ComputationalLinguistics, Jeju, Korea, Vol.1, pp.156-164.65Kishore Papineni, Salim Roukos, Todd Ward,and Wei-Jing Zhu.
2002.
BLEU: A Methodfor Automatic Evaluation of Machine Transla-tion.
40th Annual Meeting of the Associationfor Computational Linguistics, Philadelphia,USA, pp.
311-318.Temple F. Smith, and Michael S. Waterman.1981.
Identification of Common MolecularSubsequences.
Journal of Molecular Biology,Vol.
147, pp.
195-197.Matthew Snover, Bonnie Dorr, RichardSchwartz, Linnea Micciulla, and John Mak-houl.
2006.
A Study of Translation Edit Ratewith Targeted Human Annotation.
In Proceed-ings of the 7th Conference of the Associationfor Machine Translation in the Americas,Cambridge, Massachusetts, USA, pp.
223-231.Sokratis Sofianopoulos, Marina Vassiliou, andGeorge Tambouratzis.
2012.
Implementing alanguage-independent MT methodology.
InProceedings of the First Workshop on Multi-lingual Modeling, held within the ACL-2012Conference, Jeju, Republic of Korea, 13 July,pp.1-10.George Tambouratzis, Sokratis Sofianopoulos,and Marina Vassiliou (2013) Language-independent hybrid MT with PRESEMT.
InProceedings of HYTRA-2013 Workshop, heldwithin the ACL-2013 Conference, Sofia, Bul-garia, 8 August, pp.
123-130.Vladimir I. Levenshtein (1966): Binary codescapable of correcting deletions, insertions, andreversals.
Soviet Physics Doklady, Vol.
10, pp.707?710.Peter F. Brown, Stephen A. Della Pietra, VincentJ.
Della Pietra, and Robert L. Mercer (1993)The Mathematics of Statistical MachineTranslation: Parameter Estimation, Computa-tional Linguistics.Andreas Stolcke, Jing Zheng, Wen Wang, andVictor Abrash (2011) SRILM at Sixteen: Up-date and Outlook.
Proceedings of IEEE Auto-matic Speech Recognition and UnderstandingWorkshop, December 2011.Jinsong Su, Hua Wu, Haifeng Wang, YidongChen, Xiaodong Shi, Huailin Dong, and QunLiu (2012) Translation Model Adaptation forStatistical Machine Translation with Monolin-gual Topic Information.
Proceedings ofACL2012, Jeju, Republic of Korea, pp.
459-468.Dekai Wu (2005) MT model space: Statisticalversus compositional versus example-basedmachine translation.
Machine Translation,Vol.
19, pp.
213-227.66
