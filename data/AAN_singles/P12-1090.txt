Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 854?863,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsClassifying French Verbs Using French and English Lexical ResourcesIngrid FalkUniversite?
de Lorraine/LORIA,Nancy, Franceingrid.falk@loria.frClaire GardentCNRS/LORIA,Nancy, Franceclaire.gardent@loria.frJean-Charles LamirelUniversite?
de Strasbourg/LORIA,Nancy, Francejean-charles.lamirel@loria.frAbstractWe present a novel approach to the automaticacquisition of a Verbnet like classification ofFrench verbs which involves the use (i) ofa neural clustering method which associatesclusters with features, (ii) of several super-vised and unsupervised evaluation metrics and(iii) of various existing syntactic and semanticlexical resources.
We evaluate our approachon an established test set and show that itoutperforms previous related work with an F-measure of 0.70.1 IntroductionVerb classifications have been shown to be usefulboth from a theoretical and from a practical perspec-tive.
From the theoretical viewpoint, they permitcapturing syntactic and/or semantic generalisationsabout verbs (Levin, 1993; Kipper Schuler, 2006).From a practical perspective, they support factorisa-tion and have been shown to be effective in variousNLP (Natural language Processing) tasks such as se-mantic role labelling (Swier and Stevenson, 2005) orword sense disambiguation (Dang, 2004).While there has been much work on automaticallyacquiring verb classes for English (Sun et al, 2010)and to a lesser extent for German (Brew and Schulteim Walde, 2002; Schulte im Walde, 2003; Schulteim Walde, 2006), Japanese (Oishi and Matsumoto,1997) and Italian (Merlo et al, 2002), few studieshave been conducted on the automatic classificationof French verbs.
Recently however, two proposalshave been put forward.On the one hand, (Sun et al, 2010) applieda clustering approach developed for English toFrench.
They exploit features extracted from a largescale subcategorisation lexicon (LexSchem (Mes-siant, 2008)) acquired fully automatically from LeMonde newspaper corpus and show that, as for En-glish, syntactic frames and verb selectional prefer-ences perform better than lexical cooccurence fea-tures.
Their approach achieves a F-measure of55.1 on 116 verbs occurring at least 150 times inLexschem.
The best performance is achieved whenrestricting the approach to verbs occurring at least4000 times (43 verbs) with an F-measure of 65.4.On the other hand, Falk and Gardent (2011)present a classification approach for French verbsbased on the use of Formal Concept Analysis (FCA).FCA (Barbut and Monjardet, 1970) is a sym-bolic classification technique which permits creatingclasses associating sets of objects (eg.
French verbs)with sets of features (eg.
syntactic frames).
Falkand Gardent (2011) provide no evaluation for theirresults however, only a qualitative analysis.In this paper, we describe a novel approach to theclustering of French verbs which (i) gives good re-sults on the established benchmark used in (Sun etal., 2010) and (ii) associates verbs with a featureprofile describing their syntactic and semantic prop-erties.
The approach exploits a clustering methodcalled IGNGF (Incremental Growing Neural Gaswith Feature Maximisation, (Lamirel et al, 2011b))which uses the features characterising each clusterboth to guide the clustering process and to label theoutput clusters.
We apply this method to the datacontained in various verb lexicons and we evalu-854ate the resulting classification on a slightly modifiedversion of the gold standard provided by (Sun et al,2010).
We show that the approach yields promisingresults (F-measure of 70%) and that the clusteringproduced systematically associates verbs with syn-tactic frames and thematic grids thereby providingan interesting basis for the creation and evaluationof a Verbnet-like classification.Section 2 describes the lexical resources used forfeature extraction and Section 3 the experimentalsetup.
Sections 4 and 5 present the data used forand the results obtained.
Section 6 concludes.2 Lexical Resources UsedOur aim is to accquire a classification which coversthe core verbs of French, could be used to supportsemantic role labelling and is similar in spirit to theEnglish Verbnet.
In this first experiment, we there-fore favoured extracting the features used for clus-tering, not from a large corpus parsed automatically,but from manually validated resources1.
These lexi-cal resources are (i) a syntactic lexicon produced bymerging three existing lexicons for French and (ii)the English Verbnet.Among the many syntactic lexicons available forFrench (Nicolas et al, 2008; Messiant, 2008; Kups?c?and Abeille?, 2008; van den Eynde and Mertens,2003; Gross, 1975), we selected and merged threelexicons built or validated manually namely, Dico-valence, TreeLex and the LADL tables.
The result-ing lexicon contains 5918 verbs, 20433 lexical en-tries (i.e., verb/frame pairs) and 345 subcategorisa-tion frames.
It also contains more detailed syntac-tic and semantic features such as lexical preferences(e.g., locative argument, concrete object) or thematicrole information (e.g., symmetric arguments, assetrole) which we make use of for clustering.We use the English Verbnet as a resource for asso-ciating French verbs with thematic grids as follows.We translate the verbs in the English Verbnet classesto French using English-French dictionaries2.
To1Of course, the same approach could be applied to corpusbased data (as done e.g., in (Sun et al, 2010)) thus making theapproach fully unsupervised and directly applicable to any lan-guage for which a parser is available.2For the translation we use the following resources: Sci-Fran-Euradic, a French-English bilingual dictionary, built andimproved by linguists (http://catalog.elra.info/deal with polysemy, we train a supervised classifieras follows.
We first map French verbs with EnglishVerbnet classes: A French verb is associated withan English Verbnet class if, according to our dictio-naries, it is a translation of an English verb in thisclass.
The task of the classifier is then to producea probability estimate for the correctness of this as-sociation, given the training data.
The training setis built by stating for 1740 ?French verb, EnglishVerbnet class?
pairs whether the verb has the the-matic grid given by the pair?s Verbnet class3.
Thisset is used to train an SVM (support vector machine)classifier4.
The features we use are similar to thoseused in (Mouton, 2010): they are numeric and arederived for example from the number of translationsan English or French verb had, the size of the Verb-net classes, the number of classes a verb is a memberof etc.
The resulting classifier gives for each ?Frenchverb, English VN class?
pair the estimated probabil-ity of the pair?s verb being a member of the pair?sclass5.
We select 6000 pairs with highest proba-bility estimates and obtain the translated classes byassigning each verb in a selected pair to the pair?sclass.
This way French verbs are effectively asso-ciated with one or more English Verbnet thematicgrids.3 Clustering Methods, Evaluation Metricsand Experimental Setup3.1 Clustering MethodsThe IGNGF clustering method is an incrementalneural ?winner-take-most?
clustering method be-longing to the family of the free topology neu-ral clustering methods.
Like other neural freetopology methods such as Neural Gas (NG) (Mar-tinetz and Schulten, 1991), Growing Neural Gas(GNG) (Fritzke, 1995), or Incremental GrowingNeural Gas (IGNG) (Prudent and Ennaji, 2005),the IGNGF method makes use of Hebbian learningproduct_info.php?products_id=666), Google dic-tionary (http://www.google.com/dictionary) andDicovalence (van den Eynde and Mertens, 2003).3The training data consists of the verbs and Verbnet classesused in the gold standard presented in (Sun et al, 2010).4We used the libsvm (Chang and Lin, 2011) implementationof the classifier for this step.5The accuracy of the classifier on the held out random testset of 100 pairs was of 90%.855(Hebb, 1949) for dynamically structuring the learn-ing space.
However, contrary to these methods, theuse of a standard distance measure for determining awinner is replaced in IGNGF by feature maximisa-tion.
Feature maximisation is a cluster quality metricwhich associates each cluster with maximal featuresi.e., features whose Feature F-measure is maximal.Feature F-measure is the harmonic mean of FeatureRecall and Feature Precision which in turn are de-fined as:FRc(f) =?v?cW fv?c?
?C?v?c?W fv, FPc(f) =?v?cW fv?f ?
?Fc,v?cW f?vwhere W fx represents the weight of the feature f forelement x and Fc designates the set of features as-sociated with the verbs occuring in the cluster c. Afeature is then said to be maximal for a given clus-ter iff its Feature F-measure is higher for that clusterthan for any other cluster.The IGNGF method was shown to outperformother usual neural and non neural methods for clus-tering tasks on relatively clean data (Lamirel et al,2011b).
Since we use features extracted from man-ually validated sources, this clustering techniqueseems a good fit for our application.
In addition,the feature maximisation and cluster labeling per-formed by the IGNGF method has proved promisingboth for visualising clustering results (Lamirel et al,2008) and for validating or optimising a clusteringmethod (Attik et al, 2006).
We make use of theseprocesses in all our experiments and systematicallycompute cluster labelling and feature maximisationon the output clusterings.
As we shall see, this per-mits distinguishing between clusterings with simi-lar F-measure but lower ?linguistic plausibility?
(cf.Section 5).
This facilitates clustering interpretationin that cluster labeling clearly indicates the associa-tion between clusters (verbs) and their prevalent fea-tures.
And this supports the creation of a Verbnetstyle classification in that cluster labeling directlyprovides classes grouping together verbs, thematicgrids and subcategorisation frames.3.2 Evaluation metricsWe use several evaluation metrics which bear on dif-ferent properties of the clustering.Modified Purity and Accuracy.
Following (Sunet al, 2010), we use modified purity (mPUR);weighted class accuracy (ACC) and F-measure toevaluate the clusterings produced.
These are com-puted as follows.
Each induced cluster is assignedthe gold class (its prevalent class, prev(C)) to whichmost of its member verbs belong.
A verb is then saidto be correct if the gold associates it with the preva-lent class of the cluster it is in.
Given this, purity isthe ratio between the number of correct gold verbsin the clustering and the total number of gold verbsin the clustering6:mPUR =?C?Clustering,|prev(C)|>1 |prev(C) ?
C|VerbsGold?Clustering,where VerbsGold?Clustering is the total number of goldverbs in the clustering.Accuracy represents the proportion of gold verbsin those clusters which are associated with a goldclass, compared to all the gold verbs in the clus-tering.
To compute accuracy we associate to eachgold class CGold a dominant cluster, ie.
the clusterdom(CGold) which has most verbs in common withthe gold class.
Then accuracy is given by the follow-ing formula:ACC =?C?Gold |dom(C) ?
C|VerbsGold?ClusteringFinally, F-measure is the harmonic mean of mPURand ACC.Coverage.
To assess the extent to which a cluster-ing matches the gold classification, we additionallycompute the coverage of each clustering that is, theproportion of gold classes that are prevalent classesin the clustering.Cumulative Micro Precision (CMP).
As pointedout in (Lamirel et al, 2008; Attik et al, 2006), un-supervised evaluation metrics based on cluster la-belling and feature maximisation can prove veryuseful for identifying the best clustering strategy.Following (Lamirel et al, 2011a), we use CMP toidentify the best clustering.
Computed on the clus-tering results, this metrics evaluates the quality of aclustering w.r.t.
the cluster features rather than w.r.t.6Clusters for which the prevalent class has only one elementare ignored856to a gold standard.
It was shown in (Ghribi et al,2010) to be effective in detecting degenerated clus-tering results including a small number of large het-erogeneous, ?garbage?
clusters and a big number ofsmall size ?chunk?
clusters.First, the local Recall (Rfc ) and the local Preci-sion (P fc ) of a feature f in a cluster c are defined asfollows:Rfc =|vfc ||V f |P fc =|vfc ||Vc|where vfc is the set of verbs having feature f in c, Vcthe set of verbs in c and V f , the set of verbs withfeature f .Cumulative Micro-Precision (CMP) is then de-fined as follows:CMP =?i=|Cinf |,|Csup|1|Ci+|2?c?Ci+,f?Fc Pfc?i=|Cinf |,|Csup|1Ci+where Ci+ represents the subset of clusters of Cfor which the number of associated verbs is greaterthan i, and: Cinf = argminci?C |ci|, Csup =argmaxci?C |ci|3.3 Cluster display, feature f-Measure andconfidence scoreTo facilitate interpretation, clusters are displayed asillustrated in Table 1.
Features are displayed indecreasing order of Feature F-measure (cf.
Sec-tion 3.1) and features whose Feature F-measure isunder the average Feature F-measure of the over-all clustering are clearly delineated from others.
Inaddition, for each verb in a cluster, a confidencescore is displayed which is the ratio between the sumof the F-measures of its cluster maximised featuresover the sum of the F-measures of the overall clustermaximised features.
Verbs whose confidence scoreis 0 are considered as orphan data.3.4 Experimental setupWe applied an IDF-Norm weighting scheme(Robertson and Jones, 1976) to decrease the influ-ence of the most frequent features (IDF component)and to compensate for discrepancies in feature num-ber (normalisation).C6- 14(14) [197(197)]??
?-Prevalent Label ?
= AgExp-Cause0.341100 G-AgExp-Cause0.274864 C-SUJ:Ssub,OBJ:NP0.061313 C-SUJ:Ssub0.042544 C-SUJ:NP,DEOBJ:Ssub********************0.017787 C-SUJ:NP,DEOBJ:VPinf0.008108 C-SUJ:VPinf,AOBJ:PP.
.
.
[**de?primer 0.934345 4(0)] [affliger 0.879122 3(0)][e?blouir 0.879122 3(0)] [choquer 0.879122 3(0)][de?cevoir 0.879122 3(0)] [de?contenancer 0.8791223(0)] [de?contracter 0.879122 3(0)] [de?sillusionner0.879122 3(0)] [**ennuyer 0.879122 3(0)] [fasciner0.879122 3(0)] [**heurter 0.879122 3(0)] .
.
.Table 1: Sample output for a cluster produced withthe grid-scf-sem feature set and the IGNGF clusteringmethod.We use K-Means as a baseline.
For each cluster-ing method (K-Means and IGNGF), we let the num-ber of clusters vary between 1 and 30 to obtain apartition that reaches an optimum F-measure and anumber of clusters that is in the same order of mag-nitude as the initial number of Gold classes (i.e.
11classes).4 Features and DataFeatures In the simplest case the features arethe subcategorisation frames (scf) associated to theverbs by our lexicon.
We also experiment with dif-ferent combinations of additional, syntactic (synt)and semantic features (sem) extracted from the lex-icon and with the thematic grids (grid) extractedfrom the English Verbnet.The thematic grid information is derived from theEnglish Verbnet as explained in Section 2.
The syn-tactic features extracted from the lexicon are listedin Table 1(a).
They indicate whether a verb acceptssymmetric arguments (e.g., John met Mary/John andMary met); has four or more arguments; combineswith a predicative phrase (e.g., John named Marypresident); takes a sentential complement or an op-tional object; or accepts the passive in se (similar tothe English middle voice Les habits se vendent bien /The clothes sell well).
As shown in Table 1(a), these857(a) Additional syntactic features.Feature related VN classSymmetric arguments amalgamate-22.2, correspond-36.14 or more arguments get-13.5.1, send-11.1Predicate characterize-29.2Sentential argument correspond-36.1, characterize-29.2Optional object implicit theme (Randall, 2010), p. 95Passive built with se theme role (Randall, 2010), p. 120(b) Additional semantic features.Feature related VN classLocation role put-9.1, remove-10.1, .
.
.Concrete object hit-18.1 (eg.
INSTRUMENT)(non human role) other cos-45.4 .
.
.Asset role get-13.5.1Plural role amalgamate-22.2, correspond-36.1Table 2: Additional syntactic (a) and semantic (b) fea-tures extracted from the LADL and Dicovalence re-sources and the alternations/roles they are possibly re-lated to.features are meant to help identify specific Verbnetclasses and thematic roles.
Finally, we extract foursemantic features from the lexicon.
These indicatewhether a verb takes a locative or an asset argumentand whether it requires a concrete object (non hu-man role) or a plural role.
The potential correlationbetween these features and Verbnet classes is givenin Table 1(b).French Gold Standard To evaluate our approach,we use the gold standard proposed by Sun et al(2010).
This resource consists of 16 fine grainedLevin classes with 12 verbs each whose predomi-nant sense in English belong to that class.
Sinceour goal is to build a Verbnet like classificationfor French, we mapped the 16 Levin classes of theSun et al (2010)?s Gold Standard to 11 Verbnetclasses thereby associating each class with a the-matic grid.
In addition we group Verbnet semanticroles as shown in Table 4.
Table 3 shows the refer-ence we use for evaluation.Verbs For our clustering experiments we use the2183 French verbs occurring in the translations ofthe 11 classes in the gold standard (cf.
Section 4).Since we ignore verbs with only one feature thenumber of verbs and ?verb, feature?
pairs consideredmay vary slightly across experiments.AgExp Agent, ExperiencerAgentSym Actor, Actor1, Actor2Theme Theme, Topic, Stimulus, PropositionPredAtt Predicate, AttributeThemeSym Theme, Theme1, Theme2Patient PatientPatientSym Patient, Patient1, Patient2Start Material (transformation), Source (motion,transfer)End Product (transformation), Destination (mo-tion), Recipient (transfer)LocationInstrumentCauseBeneficiaryTable 4: Verbnet role groups.5 Results5.1 Quantitative AnalysisTable 4(a) includes the evaluation results for all thefeature sets when using IGNGF clustering.In terms of F-measure, the results range from 0.61to 0.70.
This generally outperforms (Sun et al,2010) whose best F-measures vary between 0.55 forverbs occurring at least 150 times in the training dataand 0.65 for verbs occurring at least 4000 times inthis training data.
The results are not directly com-parable however since the gold data is slightly dif-ferent due to the grouping of Verbnet classes throughtheir thematic grids.In terms of features, the best results are ob-tained using the grid-scf-sem feature set with an F-measure of 0.70.
Moreover, for this data set, the un-supervised evaluation metrics (cf.
Section 3) high-light strong cluster cohesion with a number of clus-ters close to the number of gold classes (13 clustersfor 11 gold classes); a low number of orphan verbs(i.e., verbs whose confidence score is zero); and ahigh Cumulated Micro Precision (CMP = 0.3) indi-cating homogeneous clusters in terms of maximis-ing features.
The coverage of 0.72 indicates that ap-proximately 8 out of the 11 gold classes could bematched to a prevalent label.
That is, 8 clusters werelabelled with a prevalent label corresponding to 8distinct gold classes.In contrast, the classification obtained using thescf-synt-sem feature set has a higher CMP for theclustering with optimal mPUR (0.57); but a lowerF-measure (0.61), a larger number of classes (16)858AgExp, PatientSymamalgamate-22.2: incorporer, associer, re?unir, me?langer, me?ler, unir, assembler, combiner, lier, fusionnerCause, AgExpamuse-31.1: abattre, accabler, briser, de?primer, consterner, ane?antir, e?puiser, exte?nuer, e?craser, ennuyer, e?reinter, inonderAgExp, PredAtt, Themecharacterize-29.2: appre?hender, concevoir, conside?rer, de?crire, de?finir, de?peindre, de?signer, envisager, identifier, montrer, percevoir, repre?senter, ressen-tirAgentSym, Themecorrespond-36.1: coope?rer, participer, collaborer, concourir, contribuer, associerAgExp, Beneficiary, Extent, Start, Themeget-13.5.1: acheter, prendre, saisir, re?server, conserver, garder, pre?server, maintenir, retenir, louer, affre?terAgExp, Instrument, Patienthit-18.1: cogner, heurter, battre, frapper, fouetter, taper, rosser, brutaliser, e?reinter, maltraiter, corrigerother cos-45.4: me?langer, fusionner, consolider, renforcer, fortifier, adoucir, polir, atte?nuer, tempe?rer, pe?trir, fac?onner, formerAgExp, Location, Themelight emission-43.1 briller, e?tinceler, flamboyer, luire, resplendir, pe?tiller, rutiler, rayonner, scintillermodes of being with motion-47.3: trembler, fre?mir, osciller, vaciller, vibrer, tressaillir, frissonner, palpiter, gre?siller, trembloter, palpiterrun-51.3.2: voyager, aller, errer, circuler, courir, bouger, naviguer, passer, promener, de?placerAgExp, End, Thememanner speaking-37.3: ra?ler, gronder, crier, ronchonner, grogner, bougonner, maugre?er, rouspe?ter, grommeler, larmoyer, ge?mir, geindre, hurler,gueuler, brailler, chuchoterput-9.1: accrocher, de?poser, mettre, placer, re?partir, re?inte?grer, empiler, emporter, enfermer, inse?rer, installersay-37.7: dire, re?ve?ler, de?clarer, signaler, indiquer, montrer, annoncer, re?pondre, affirmer, certifier, re?pliquerAgExp, Themepeer-30.3: regarder, e?couter, examiner, conside?rer, voir, scruter, de?visagerAgExp, Start, Themeremove-10.1: o?ter, enlever, retirer, supprimer, retrancher, de?barasser, soustraire, de?compter, e?liminerAgExp, End, Start, Themesend-11.1: envoyer, lancer, transmettre, adresser, porter, expe?dier, transporter, jeter, renvoyer, livrerTable 3: French gold classes and their member verbs presented in (Sun et al, 2010).and a higher number of orphans (156).
That is, thisclustering has many clusters with strong feature co-hesion but a class structure that markedly differsfrom the gold.
Since there might be differences instructure between the English Verbnet and the the-matic classification for French we are building, thisis not necessarily incorrect however.
Further inves-tigation on a larger data set would be required to as-sess which clustering is in fact better given the dataused and the classification searched for.In general, data sets whose description includessemantic features (sem or grid) tend to produce bet-ter results than those that do not (scf or synt).
Thisis in line with results from (Sun et al, 2010) whichshows that semantic features help verb classifica-tion.
It differs from it however in that the seman-tic features used by Sun et al (2010) are selectionalpreferences while ours are thematic grids and a re-stricted set of manually encoded selectional prefer-ences.Noticeably, the synt feature degrades perfor-mance throughout: grid,scf,synt has lower F-measure than grid,scf; scf,synt,sem than scf,sem;and scf,synt than scf.
We have no clear explanationfor this.The best results are obtained with IGNGF methodon most of the data sets.
Table 4(b) illustratesthe differences between the results obtained withIGNGF and those obtained with K-means on thegrid-scf-sem data set (best data set).
Although K-means and IGNGF optimal model reach similar F-measure and display a similar number of clusters,the very low CMP (0.10) of the K-means modelshows that, despite a good Gold class coverage(0.81), K-means tend to produce more heteroge-neous clusters in terms of features.Table 4(b) also shows the impact of IDF featureweighting and feature vector normalisation on clus-tering.
The benefit of preprocessing the data appearsclearly.
When neither IDF weighting nor vector nor-malisation are used, F-measure decreases from 0.70to 0.68 and cumulative micro-precision from 0.30to 0.21.
When either normalisation or IDF weight-ing is left out, the cumulative micro-precision dropsby up to 15 points (from 0.30 to 0.15 and 0.18) andthe number of orphans increases from 67 up to 180.859(a) The impact of the feature set.Feat.
set Nbr.
feat.
Nbr.
verbs mPUR ACC F (Gold) Nbr.
classes Cov.
Nbr.
orphans CMP at opt (13cl.
)scf 220 2085 0.93 0.48 0.64 17 0.55 129 0.28 (0.27)grid, scf 231 2085 0.94 0.54 0.68 14 0.64 183 0.12 (0.12)grid, scf, sem 237 2183 0.86 0.59 0.70 13 0.72 67 0.30 (0.30)grid, scf, synt 236 2150 0.87 0.50 0.63 14 0.72 66 0.13 (0.14)grid, scf, synt, sem 242 2201 0.99 0.52 0.69 16 0.82 100 0.50 (0.22)scf, sem 226 2183 0.83 0.55 0.66 23 0.64 146 0.40 (0.26)scf, synt 225 2150 0.91 0.45 0.61 15 0.45 83 0.17 (0.22)scf, synt, sem 231 2101 0.89 0.47 0.61 16 0.64 156 0.57 (0.11)(b) Metrics for best performing clustering method (IGNGF) compared to K-means.
Feature set is grid, scf, sem.Method mPUR ACC F (Gold) Nbr.
classes Cov.
Nbr.
orphans CMP at opt (13cl.
)IGNGF with IDF and norm.
0.86 0.59 0.70 13 0.72 67 0.30 (0.30)K-means with IDF and norm.
0.88 0.57 0.70 13 0.81 67 0.10 (0.10)IGNGF, no IDF 0.86 0.59 0.70 17 0.81 126 0.18 (0.14)IGNGF, no norm.
0.78 0.62 0.70 18 0.72 180 0.15 (0.11)IGNGF, no IDF, no norm.
0.87 0.55 0.68 14 0.81 103 0.21 (0.21)Table 5: Results.
Cumulative micro precision (CMP) is given for the clustering at the mPUR optimum and in paran-theses for 13 classes clustering.That is, clusters are less coherent in terms of fea-tures.5.2 Qualitative AnalysisWe carried out a manual analysis of the clusters ex-amining both the semantic coherence of each cluster(do the verbs in that cluster share a semantic com-ponent?)
and the association between the thematicgrids, the verbs and the syntactic frames providedby clustering.Semantic homogeneity: To assess semantic ho-mogeneity, we examined each cluster and soughtto identify one or more Verbnet labels character-ising the verbs contained in that cluster.
Fromthe 13 clusters produced by clustering, 11 clus-ters could be labelled.
Table 6 shows these elevenclusters, the associated labels (abbreviated Verbnetclass names), some example verbs, a sample sub-categorisation frame drawn from the cluster max-imising features and an illustrating sentence.
Ascan be seen, some clusters group together severalsubclasses and conversely, some Verbnet classes arespread over several clusters.
This is not necessar-ily incorrect though.
To start with, recall that weare aiming for a classification which groups togetherverbs with the same thematic grid.
Given this, clus-ter C2 correctly groups together two Verbnet classes(other cos-45.4 and hit-18.1) which share the samethematic grid (cf.
Table 3).
In addition, the featuresassociated with this cluster indicate that verbs inthese two classes are transitive, select a concrete ob-ject, and can be pronominalised which again is cor-rect for most verbs in that cluster.
Similarly, clusterC11 groups together verbs from two Verbnet classeswith identical theta grid (light emission-43.1 andmodes of being with motion-47.3) while its associ-ated features correctly indicate that verbs from bothclasses accept both the intransitive form without ob-ject (la jeune fille rayonne / the young girl glows, uncheval galope / a horse gallops) and with a prepo-sitional object (la jeune fille rayonne de bonheur /the young girl glows with happiness, un cheval ga-lope vers l?infini / a horse gallops to infinity).
Thethird cluster grouping together verbs from two Verb-net classes is C7 which contains mainly judgementverbs (to applaud, bless, compliment, punish) butalso some verbs from the (very large) other cos-45.4class.
In this case, a prevalent shared feature isthat both types of verbs accept a de-object that is,a prepositional object introduced by ?de?
(Jean ap-plaudit Marie d?avoir danse?
/ Jean applaudit Mariefor having danced; Jean de?gage le sable de la route /Jean clears the sand of the road).
The semantic fea-tures necessary to provide a finer grained analysis oftheir differences are lacking.Interestingly, clustering also highlights classeswhich are semantically homogeneous but syntac-tically distinct.
While clusters C6 and C10 both860contain mostly verbs from the amuse-31.1 class(amuser,agacer,e?nerver,de?primer), their features in-dicate that verbs in C10 accept the pronominal form(e.g., Jean s?amuse) while verbs in C6 do not (e.g.,*Jean se de?prime).
In this case, clustering highlightsa syntactic distinction which is present in French butnot in English.
In contrast, the dispersion of verbsfrom the other cos-45.4 class over clusters C2 andC7 has no obvious explanation.
One reason mightbe that this class is rather large (361 verbs) and thusmight contain French verbs that do not necessarilyshare properties with the original Verbnet class.Syntax and Semantics.
We examined whether theprevalent syntactic features labelling each clusterwere compatible with the verbs and with the seman-tic class(es) manually assigned to the clusters.
Ta-ble 6 sketches the relation between cluster, syntac-tic frames and Verbnet like classes.
It shows for in-stance that the prevalent frame of the C0 class (man-ner speaking-37.3) correctly indicates that verbs inthat cluster subcategorise for a sentential argumentand an AOBJ (prepositional object in ?a`?)
(e.g., Jeanbafouille a` Marie qu?il est amoureux / Jean stam-mers to Mary that he is in love); and that verbsin the C9 class (characterize-29.2) subcategorise foran object NP and an attribute (Jean nomme Mariepre?sidente / Jean appoints Marie president).
In gen-eral, we found that the prevalent frames associatedwith each cluster adequately characterise the syntaxof that verb class.6 ConclusionWe presented an approach to the automatic classi-fication of french verbs which showed good resultson an established testset and associates verb clusterswith syntactic and semantic features.Whether the features associated by the IGNGFclustering with the verb clusters appropriately car-acterise these clusters remains an open question.
Wecarried out a first evaluation using these featuresto label the syntactic arguments of verbs in a cor-pus with thematic roles and found that precision ishigh but recall low mainly because of polysemy: theframes and grids made available by the classificationfor a given verb are correct for that verb but not forthe verb sense occurring in the corpus.
This sug-gests that overlapping clustering techniques need toC0 speaking: babiller, bafouiller, balbutierSUJ:NP,OBJ:Ssub,AOBJ:PPJean bafouille a` Marie qu?il l?aime / Jean stammers to Mary that he isin loveC1 put: entasser, re?pandre, essaimerSUJ:NP,POBJ:PP,DUMMY:REFLLoc, PluralLes de?chets s?entassent dans la cour / Waste piles in the yardC2 hit: broyer, de?molir, fouetterSUJ:NP,OBJ:NPT-NhumCes pierres broient les graines / These stones grind the seeds.other cos: agrandir, alle?ger, amincirSUJ:NP,DUMMY:REFLles ae?roports s?agrandissent sans arre?t / airports grow constantlyC4 dedicate: s?engager a`, s?obliger a`,SUJ:NP,AOBJ:VPinf,DUMMY:REFLCette promesse t?engage a` nous suivre / This promise commits you tofollowing usC5 conjecture: penser, attester, agre?erSUJ:NP,OBJ:SsubLe me?decin atteste que l?employe?
n?est pas en e?tat de travailler / Thephysician certifies that the employee is not able to workC6 amuse: de?primer, de?contenancer, de?cevoirSUJ:Ssub,OBJ:NPSUJ:NP,DEOBJ:SsubTravailler de?prime Marie / Working depresses MarieMarie de?prime de ce que Jean parte / Marie depresses because of Jean?sleavingC7 other cos: de?gager, vider, drainer, sevrerjudgementSUJ:NP,OBJ:NP,DEOBJ:PPvider le re?cipient de son contenu / empty the container of its contentsapplaudir, be?nir, bla?mer,SUJ:NP,OBJ:NP,DEOBJ:SsubJean blame Marie d?avoir couru / Jean blames Mary for runnigC9 characterise: promouvoir, adouber, nommerSUJ:NP,OBJ:NP,ATB:XPJean nomme Marie pre?sidente / Jean appoints Marie presidentC10 amuse: agacer, amuser, enorgueillirSUJ:NP,DEOBJ:XP,DUMMY:REFLJean s?enorgueillit d?e?tre roi/ Jean is proud to be kingC11 light: rayonner,clignoter,cliqueterSUJ:NP,POBJ:PPJean clignote des yeux / Jean twinkles his eyesmotion: aller, passer, fuir, glisserSUJ:NP,POBJ:PPglisser sur le trottoir verglace?
/ slip on the icy sidewalkC12 transfer msg: enseigner, permettre, interdireSUJ:NP,OBJ:NP,AOBJ:PPJean enseigne l?anglais a` Marie / Jean teaches Marie English.Table 6: Relations between clusters, syntactic frames andVerbnet like classes.be applied.We are also investigating how the approach scalesup to the full set of verbs present in the lexicon.
BothDicovalence and the LADL tables contain rich de-tailed information about the syntactic and semanticproperties of French verbs.
We intend to tap on thatpotential and explore how well the various semanticfeatures that can be extracted from these resourcessupport automatic verb classification for the full setof verbs present in our lexicon.861ReferencesM.
Attik, S. Al Shehabi, and J.-C. Lamirel.
2006.
Clus-tering Quality Measures for Data Samples with Mul-tiple Labels.
In Databases and Applications, pages58?65.M.
Barbut and B. Monjardet.
1970.
Ordre et Classifica-tion.
Hachette Universite?.C.
Brew and S. Schulte im Walde.
2002.
Spectral Clus-tering for German Verbs.
In Proceedings of the Con-ference on Empirical Methods in Natural LanguageProcessing, pages 117?124, Philadelphia, PA.C.
Chang and C. Lin.
2011.
LIBSVM: A library forsupport vector machines.
ACM Transactions on Intel-ligent Systems and Technology, 2:27:1?27:27.
Soft-ware available at http://www.csie.ntu.edu.tw/?cjlin/libsvm.H.
T. Dang.
2004.
Investigations into the role of lexicalsemantics in word sense disambiguation.
Ph.D. thesis,U.
Pennsylvannia, US.I.
Falk and C. Gardent.
2011.
Combining Formal Con-cept Analysis and Translation to Assign Frames andThematic Role Sets to French Verbs.
In AmedeoNapoli and Vilem Vychodil, editors, Concept Latticesand Their Applications, Nancy, France, October.B.
Fritzke.
1995.
A growing neural gas network learnstopologies.
Advances in Neural Information Process-ing Systems 7, 7:625?632.M.
Ghribi, P. Cuxac, J.-C. Lamirel, and A. Lelu.
2010.Mesures de qualite?
de clustering de documents : priseen compte de la distribution des mots cle?s.
In NicolasBe?chet, editor, E?valuation des me?thodes d?Extractionde Connaissances dans les Donne?es- EvalECD?2010,pages 15?28, Hammamet, Tunisie, January.
FatihaSa??s.M.
Gross.
1975.
Me?thodes en syntaxe.
Hermann, Paris.D.
O. Hebb.
1949.
The organization of behavior: aneuropsychological theory.
John Wiley & Sons, NewYork.K.
Kipper Schuler.
2006.
VerbNet: A Broad-Coverage,Comprehensive Verb Lexicon.
Ph.D. thesis, Universityof Pennsylvania.A.
Kups?c?
and A. Abeille?.
2008.
Growing treelex.
InAlexander Gelbkuh, editor, Computational Linguis-tics and Intelligent Text Processing, volume 4919 ofLecture Notes in Computer Science, pages 28?39.Springer Berlin / Heidelberg.J.-C. Lamirel, A. Phuong Ta, and M. Attik.
2008.
NovelLabeling Strategies for Hierarchical Representation ofMultidimensional Data Analysis Results.
In AIA -IASTED, Innbruck, Autriche.J.
C. Lamirel, P. Cuxac, and R. Mall.
2011a.
A newefficient and unbiased approach for clustering qualityevaluation.
In QIMIE?11, PaKDD, Shenzen, China.J.-C. Lamirel, R. Mall, P. Cuxac, and G. Safi.
2011b.Variations to incremental growing neural gas algo-rithm based on label maximization.
In Neural Net-works (IJCNN), The 2011 International Joint Confer-ence on, pages 956 ?965.B.
Levin.
1993.
English Verb Classes and Alternations:a preliminary investigation.
University of ChicagoPress, Chicago and London.T.
Martinetz and K. Schulten.
1991.
A ?Neural-Gas?Network Learns Topologies.
Artificial Neural Net-works, I:397?402.P.
Merlo, S. Stevenson, V. Tsang, and G. Allaria.
2002.A multilingual paradigm for automatic verb classifica-tion.
In ACL, pages 207?214.C.
Messiant.
2008.
A subcategorization acquisition sys-tem for French verbs.
In Proceedings of the ACL-08: HLT Student Research Workshop, pages 55?60,Columbus, Ohio, June.
Association for ComputationalLinguistics.C.
Mouton.
2010.
Ressources et me?thodes semi-supervise?es pour l?analyse se?mantique de textes enfran cais.
Ph.D. thesis, Universite?
Paris 11 - Paris SudUFR d?informatique.L.
Nicolas, B. Sagot, E?.
de La Clergerie, and J. Farre?.2008.
Computer aided correction and extension of asyntactic wide-coverage lexicon.
In Proc.
of CoLing2008, Manchester, UK, August.A.
Oishi and Y. Matsumoto.
1997.
Detecting the orga-nization of semantic subclasses of Japanese verbs.
In-ternational Journal of Corpus Linguistics, 2(1):65?89,october.Y.
Prudent and A. Ennaji.
2005.
An incremental grow-ing neural gas learns topologies.
In Neural Networks,2005.
IJCNN ?05.
Proceedings.
2005 IEEE Interna-tional Joint Conference on, volume 2, pages 1211?1216.J.
H. Randall.
2010.
Linking.
Studies in Natural Lan-guage and Linguistic Theory.
Springer, Dordrecht.S.
E. Robertson and K. S. Jones.
1976.
Relevanceweighting of search terms.
Journal of the AmericanSociety for Information Science, 27(3):129?146.S.
Schulte im Walde.
2003.
Experiments on the Auto-matic Induction of German Semantic Verb Classes.Ph.D.
thesis, Institut fu?r Maschinelle Sprachverar-beitung, Universita?t Stuttgart.
Published as AIMS Re-port 9(2).S.
Schulte im Walde.
2006.
Experiments on the au-tomatic induction of german semantic verb classes.Computational Linguistics, 32(2):159?194.L.
Sun, A. Korhonen, T. Poibeau, and C. Messiant.
2010.Investigating the cross-linguistic potential of verbnet:style classification.
In Proceedings of the 23rd In-ternational Conference on Computational Linguistics,862COLING ?10, pages 1056?1064, Stroudsburg, PA,USA.
Association for Computational Linguistics.R.
S. Swier and S. Stevenson.
2005.
Exploitinga verb lexicon in automatic semantic role labelling.In HLT/EMNLP.
The Association for ComputationalLinguistics.K.
van den Eynde and P. Mertens.
2003.
La valence :l?approche pronominale et son application au lexiqueverbal.
Journal of French Language Studies, 13:63?104.863
