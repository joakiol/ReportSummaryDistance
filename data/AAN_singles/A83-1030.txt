SPEECH IbrrERFACES: SESSION IN~ODUCTIONDouglas L. Hogan13625 Middlevale LaneSilver Spring, ~m 20906ABSTRACT II CURRENT TECHNOLOGYThe speech interface is the natural one forthe human user and is beginning to be used in alimited way in many applications.
Some of theseapplications are experimental; still others haveachieved the status of cost-effective utility.
Abrief summary of the current state-of-the-art ofspeech input and output are presented.
The twopapers in the session represent specific examplesof current work.
Some comments on the need forlinguistically oriented development conclude thepaper.I INTRODUCTIONOver the past four decades it has often beenfelt that the solution to the problem of "machinerecogni t ion of speech" is ".. just around thecorner."
When the sound spectrograph was invented(a l itt le less than forty years ago) engineers,acoust ic ians,  phoneticists,  and l inguists  werecertain that the mysteries of speech were about tobe unveiled.
When powerfu l  computers  could bebrought to bear (say - twenty years ago) there wasa renewed feeling that such tools would providethe ~eans to a near term solution.
When artifi-cial intelligence was the buzzword (a little overten years ago) it was clear that now the solutionof the recognition problem was at hand.
Where arewe today?
A number of modest, and modest lypriced, speech recognit ion systems are on themarket and in use.
This has come about becausetechnology has permitted some brute force methodsto be used and because simple applications havebeen found to be cost effective.In speech output systems a similar patternhas emerged.
Crude synthesizers such as the~askins pattern playback of thirty years ago werecapable of evoking "correct" responses from lis-teners.
Twenty-five years ago it was thought thatreading machines for the blind could be construc-ted by concatenat ing words.
Twenty  years agoformant synthesizers sounded extremely naturalwhen their control  was a "copy" of a naturalutterance.
Modern synthesizers are one one-thou-sandth the size and cost; they stil l  only soundnatural  when a human utterance is analyzed andthen resynthesized as a complete entity.
Conca-tenatin 8 words is still no better, though cheaper,than it was twenty years ago.A.
Speech InputThere are now several  speech recogni t ionsystems on the market which are intended to recog-nize isolated words and which have been trainedfor an individual speaker.
The vocabulary sizesare on the order of 100 words are phrases.
Accu-racy is always quoted at "99+%."
These recogni-zers use a form of template  match ing wi th in  aspace which has the dimensions of features versustime.
The "true" accuracy is a function of thevocabulary size, the degree of cooperativeness ofthe speaker, and the innate dissimilarity of thevncab ulary.
Since the systems are recogniz ingknown words by known speakers the major source ofvaria billty in successive words is the time axis.The same word may (and will) be spoken at differ-ent speaking rates.
Unfortunately,  d i f ferentspeaking rates do not result  in a l inear speedchange in all parts of a word; the voiced por-tions of the word, loosely speaking the vowels,respond more to speed change; the unvoiced por-tions of the word, loosely the consonants, re-spond less to speed change.
As a result, a non-linear time adjustment is desired when matchingtemplates.
This sort of time adjustment is car-ried out wi th a mathemat ica l  process known asdynamic programming which permits exploration ofall plausible non-linear matches at the expenseof (approximately)  squaring the compu rat ionalcomplexity in contrast to the comblna torlal com-putat ional  growth that would otherwise  be re-quired.
The medium and high performance speechrecognizers usually contain some form of dynamicprogramming.
In some cases more than one levelof dynamic  programming is used to provide forrecognition of short sequences of words.The actual use of these recognizers has de-veloped a number of consequences.
Many of them,including the first paper in this session involvethe use of speech recognition during hands-and-eyes busy operations.
These appl icat ions wi l lalmost always be interactive in nature; the systemresponse may be visual or aural.
Prompt responsesaying what the system "heard" is crucial  forimproving the speaker's performance.
A coopera-tive speaker clearly adapts to the system.
Todate, many applications are found where a restric-ted interactive speech dialog is useful and eco-nomical.
At this time the speech recogni t ion178mechanism i s  re la t ive ly  inexpens ive;  the expens ivecomponent is the initial cost of developing thedialog for the appl lcaClon and interfacing therecognition element Co the host computer system.At the present tlme recognition is not accom-plished in units smaller than the word.
It hasbeen hoped chat it might be poss ib le  to segmentspeech in to  phonemes.
These would be recogn ized ,a lbe i t  wi th  some er rors ;  the s t r ings  of phonemeswould then be matched wi th  a lex icon .
To date ,adequate segmentat ion  for  th i s  sor t  of  approachhas not  been ach ieved .
In fac t ,  in  cont inuousf luent  speech good word boundar ies  are  not  read i lyfound by any algorithmic means.B.
Speech OutputThere are re la t ive ly  few speech synthes izersin  the  pure  sense  of  the  word.
There  are  manyspeech output  dev ices  which produce speech as theinverse of a previously formed analysis process.The ana lys i s  may have been performed by encodln&techniques in the tlme domain; alternatively, itmay be the result of soma form of extract ing avocal source or excitation function and a vocaltract descrlptlou.
When the analysis is performedon a whole phrase the prosodic features of thei nd ivdua l  u t te r ing  the phrase are preserved;  thespeech  sounds  natura l .
When ind iv idua l  wordsproduced by such an ana lys l s - synthes ls  p rocess  areconcatenated the speech does not sound natura l .In any event ,  the  process  descr ibed  abovedoes not allow fo r  the open ended case,  synthes isof  unres t r i c ted  text .
This p rocess  requ i res  thata number of  s teps  be car r ied  out  in a sat i s fac toryway.
F i r s t ,  o r thograph ic  text  must  be in ter -preted;  e.g.
we read "NFL" as a sequence of  th reewords  but  we pronounce  the word "FORTRAN', weautomat ica l ly  expand out  the abrev ia t ion  "St . "
,etc.
Second, the orthography must be converted Copronunciation, a distinctly non-trlvial task inEn~llsh.
This is normally accomplished by a setof rules together with a table of exceptions tothose rules.
Although pronouncing dictionaries doexist in machine form, they are still coo largefor random access memory technology, although thlswil l  not be t rue  in the reasonably near future.Proper  nouns, especial ly names of people andplaces, will often not be amenable to the rulesfor normal English.
Third, the pronunciation ofthe word must be mapped into sequences drawn froman inventory of smaller units.
At various timesthese units have been allophones, phonemes, dl-phones (phoneme pairs), demlsyllables, and sylla-bles.
The units are connected with procedureswhich range from concatenat ion  to smooth in terpo-la t ion .
F ina l ly ,  i t  i s  necessary  to develop sat -i s fac tory  prosody for  a whole phrase or sentence.Th is  i s  normal ly  in terpreted  as prov id in& thein fo rmat ion  about in f lec t ion ,  t iming,  and s t ress .This f ina l  s tep  is  the one in which the greates td i f f i cu l ty  ex is ts  at the present  t ime and whichpresents  the s t rongest  bar  to natura l  sound ingspeech.
The second paper  in thls session dealswlth the development of stress rules for prosody,one component of =he overall problem.llI LINGUISTIC NEEDS IN SPEECH INTERFACESA, Current ResearchMoat of the current high end work in speechrecognition attempts Co c6nstrain the allowablesequence of words by the application of some kindof grammar.
This may be a very artificial gram-mar, for example the interaction wlch an airlinereservation system.
Other research efforts at-tempt Co develop models of the language through aninformat ion cheoretlc analysis.
Coming fullcircle we find words being analyzed as a Markovprocess; Merkov, of course, was analyzing languagewhen he developed thls "mathematically defined"procese .Normal iz ing recognit ion to the speaker isbeing approached in two ways.
The first, cur-rently being explored at the word reco&nit lonlevel consists of developing enough samples ofeach word from many speakers so chat clusteringtechniques wil l  permit the speaker space to bespanned with a dozen or so examples.
The secondapproach attempts to enroll a speaker in a recog-nlt lon system by speaking "enough" text so tha~the system is able to develop a model of thatperson 's  speech.In research on speech synthesis considerableattention is now being &iven to try, by analysis,to determine rules for prosody.
Application ofthese rules requires grammatical analysis of thetext which is to be converted co speech.8.
The FutureAs both of the speech interface tasks becomemore and more open-ended It is clear thatsat isfactory performance wil l  require verysubstantial aid from linguistic reseacrh.
In thecase of recognition this is necessary to reducethe number of hypotheses that must be explored atany given point in a stream of unknown words.
Inthe case of text-to-speech, understandin~ of whatiS being said will contribute to producing morenatural and acceptable speech.IV FURTHER READINGThe reference below surveys the currentstate-of-the art more deeply than can be presentedhere.
It also calls out the need for Increasedapplication of lln&ulstlc information to speechinterface development as well as providln~ anextensive set of references for those of you whowould llke Co dig deeper.Flanagan, James L., Talking with Computers: Syn-thesis and Reco~nitlon of Speech by Machines,IEEE Trans.
on Biomed.
En&.)
BME~29, No.4, pp223-232 (April 1982).179
