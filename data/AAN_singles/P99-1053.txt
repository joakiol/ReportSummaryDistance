A Syntactic Framework for Speech Repairs and Other DisruptionsMark G. Core and Lenhart K. SchubertDepartment ofComputer ScienceUniversity of RochesterRochester, NY 14627mcore, schubert@cs, rochester, eduAbstractThis paper presents a grammatical nd pro-cessing framework for handling the repairs,hesitations, and other interruptions in nat-ural human dialog.
The proposed frame-work has proved adequate for a collection ofhuman-human task-oriented dialogs, both ina full manual examination ofthe corpus, andin tests with a parser capable of parsing someof that corpus.
This parser can also correcta pre-parser speech repair identifier resultingin a 4.8% increase in recall.1 Motivat ionThe parsers used in most dialog systemshave not evolved much past their originsin handling written text even though theymay have to deal with speech repairs, speak-ers collaborating to form utterances, andspeakers interrupting each other.
This isespecially true of machine translators andmeeting analysis programs that deal withhuman-human dialog.
Speech recognizershave started to adapt to spoken dialog (ver-sus read speech).
Recent language mod-els (Heeman and Allen, 1997), (Stolcke andShriberg, 1996), (Siu and Ostendorf, 1996)take into account the fact that word co-occurrences may be disrupted by editingterms 1 and speech repairs (take the tankerI mean the boxcar).These language models detect repairs asthey process the input; however, like pastwork on speech repair detection, they do not1Here, we define diting terms as a set of 30-40words that signal hesitations (urn) and speech re-pairs (I mean) and give meta-comments on the ut-terance (right).specify how speech repairs hould be handledby the parser.
(Hindle, 1983) and (Bear etal., 1992) performed speech repair identifi-cation in their parsers, and removed the cor-rected material (reparandum) from consider-ation.
(Hindle, 1983) states that repairs areavailable for semantic analysis but providesno details on the representation to be used.Clearly repairs should be available for se-mantic analysis as they play a role in di-alog structure.
For example, repairs cancontain referents that are needed to inter-pret subsequent text: have the engine takethe oranges to Elmira, urn, I mean, takethem to Corning.
(Brennan and Williams,1995) discusses the role of fillers (a type ofediting term) in expressing uncertainty and(Schober, 1999) describes how editing termsand speech repairs correlate with planningdifficultly.
Clearly this is information thatshould be conveyed to higher-level reasoningprocesses.
An additional advantage to mak-ing the parser aware of speech repairs is thatit can use its knowledge of grammar and thesyntactic structure of the input to correct er-rors made in pre-parser repair identification.Like Hindle's work, the parsing architec-ture presented below uses phrase structureto represent the corrected utterance, but italso forms a phrase structure tree con,rain-ing the reparandum.
Editing terms are con-sidered separate utterances that occur insideother utterances.
So for the partial utter-ance, take the ban- um the oranges, threeconstituents would be produced, one for urn,another for take the ban-, and a third for takethe oranges.Another complicating factor of dialog is413the presence of more than one speaker.
Thispaper deals with the two speaker case, butthe principles presented should apply gener-ally.
Sometimes the second speaker needs tobe treated independently as in the case ofbackchannels (um-hm) or failed attempts tograb the floor.
Other times, the speakers in-teract to collaboratively form utterances orcorrect each other.
The next step in lan-guage modeling will be to decide whetherspeakers are collaborating or whether a sec-ond speaker is interrupting the context witha repair or backchannel.
Parsers must beable to form phrase structure trees aroundinterruptions uch as backchannels as wellas treat interruptions as continuations of thefirst speaker's input.This paper presents a parser architecturethat works with a speech repair identify-ing language model to handle speech repairs,editing terms, and two speakers.
Section 2details the allowable forms of collaboration,interruption, and speech repair in our model.Section 3 gives an overview of how this modelis implemented in a parser.
This topic is ex-plored in more detail in (Core and Schubert,1998).
Section 4 discusses the applicabilityof the model to a test corpus, and section5 includes examples of trees output by theparser.
Section 6 discusses the results of us-ing the parser to correct he output of a pre-parser speech repair identifier.2 What  is a DialogFrom a traditional parsing perspective, atext is a series of sentences to be analyzed.An interpretation for a text would be a se-ries of parse trees and logical forms, one foreach sentence.
An analogous view is oftentaken of dialog; dialog is a series of "utter-ances" and a dialog interpretation is a se-ries of parse trees and logical forms, one foreach successive utterance.
Such a view eitherdisallows editing terms, repairs, interjectedacknowledgments and other disruptions, orelse breaks semantically complete utterancesinto fragmentary ones.
We analyze dialogin terms of a set of utterances covering allthe words of the dialog.
As explained below,utterances can be formed by more than onespeaker and the words of two utterances maybe interleaved.We define an utterance here as a sen-tence, phrasal answer (to a question), edit-ing term, or acknowledgment.
Editing termsand changes of speaker are treated specially.Speakers are allowed to interrupt hemselvesto utter an editing term.
These editingterms are regarded as separate utterances.At changes of speaker, the new speaker may:1) add to what the first speaker has said,2) start a new utterance, or 3) continue anutterance that was left hanging at the lastchange of speaker (e.g., because of an ac-knowledgment).
Note that a speaker maytry to interrupt another speaker and suc-ceed in uttering a few words but then giveup if the other speaker does not stop talk-ing.
These cases are classified as incompleteutterances and are included in the interpre-tation of the dialog.Except in utterances containing speech re-pairs, each word can only belong to one ut-terance.
Speech repairs are intra-utterancecorrections made by either speaker.
Thereparandum is the material corrected by therepair.
We form two interpretations of anutterance with a speech repair.
One inter-pretation includes all of the utterance up tothe reparandum end but stops at that point;this is what the speaker started to say, andwill likely be an incomplete utterance.
Thesecond interpretation is the corrected utter-ance and skips the reparandum.
In the ex-ample, you should take the boxcar I meanthe tanker to Coming; the reparandum is theboxcar.
Based on our previous rules the edit-ing term I mean is treated as a separate ut-terance.
The two interpretations producedby the speech repair are the utterance, youshould take the tanker to Coming, and theincomplete utterance, you should take theboxcar.3 Dialog ParsingThe modifications required to a parserto implement his definition of dialog arerelatively straightforward.
At changes of414speaker, copies are made of all phrasehypotheses (arcs in a chart parser, forexample) ending at the previous changeof speaker.
These copies are extended tothe current change of speaker.
We will usethe term contribution (contr) here to referto an uninterrupted sequence of words byone speaker (the words between speakerchanges).
In the example below, considerchange of speaker (cos) 2.
Copies of allphrase hypotheses ending at change ofspeaker 1 are extended to end at change ofspeaker 2.
In this way, speaker A can forma phrase from contr-1 and contr-3 skippingspeaker B's interruption, or contr-1, contr-2,and contr-3 can all form one constituent.
Atchange of speaker 3, all phrase hypothesesending at change of speaker 2 are extendedto end at change of speaker 3 except thosehypotheses that were extended from the pre-vious change of speaker.
Thus, an utterancecannot be formed from only contr-1 andcontr-4.
This mechanism implements therules for speaker changes given in section 2:at each change of speaker, the new speakercan either build on the last contribution,build on their last contribution, or start anew utterance.A: contr-1 contr-3B: contr-2 contr-4cos  1 2 3These rules assume that changes ofspeaker are well defined points of time,meaning that words of two speakers do notoverlap.
In the experiments of this paper,a corpus was used where word endings weretime-stamped (word beginnings are unavail-able).
These times were used to impose anordering; if one word ends before another itis counted as being before the other word.Clearly, this could be inaccurate given thatwords may overlap.
Moreover, speakers maybe slow to interrupt or may anticipate thefirst speaker and interrupt early.
However,this approximation works fairly well as dis-cussed in section 4.Other parts of the implementation are ac-complished through metarules.
The termmetarule is used because these rules act noton words but grammar ules.
Consider theediting term metarule.
When an editingterm is seen 2, the metarule extends copiesof all phrase hypotheses ending at the edit-ing term over that term to allow utterancesto be formed around it.
This metarule (andour other metarules) can be viewed declar-atively as specifying allowable patterns ofphrase breakage and interleaving (Core andSchubert, 1998).
This notion is differentfrom the traditional linguistic conception ofmetarules as rules for generating new PSRsfrom given PSRs.
~ Procedurally, we canthink of metarules as creating new (discon-tinuous) pathways for the parser's traversalof the input, and this view is readily imple-mentable.The repair metarule, when given the hypo-thetical start and end of a reparandum (sayfrom a language model such as (Heeman andAllen, 1997)), extends copies of phrase hy-potheses over the reparandum allowing thecorrected utterance to be formed.
In case thesource of the reparandum information gavea false alarm, the alternative of not skippingthe reparandum is still available.For each utterance in the input, the parserneeds to find an interpretation that startsat the first word of the input and ends atthe last word.
4 This interpretation may havebeen produced by one or more applicationsof the repair metarule allowing the interpre-tation to exclude one or more reparanda.
Foreach reparandum skipped, the parser needsto find an interpretation of what the userstarted to say.
In some cases, what the userstarted to say is a complete constituent: take2The parser's lexicon has a list of 35 editing termsthat activate the editing term metarule.3For instance, a traditional way to accommodateediting terms might be via a metarule,X -> Y Z ==> X -> Y editing-term Z, where Xvaries over categories and Y and Z vary over se-quences of categories.
However, this would producephrases containing editing terms as constituents,whereas in our approach editing terms are separateutterances.4In cases of overlapping utterances, it will takemultiple interpretations (one for each utterance) toextend across the input.415the oranges I mean take the bananas.
Other-wise, the parser needs to look for an incom-plete interpretation ending at the reparan-dum end.
Typically, there will be many suchinterpretations; the parser searches for thelongest interpretations and then ranks thembased on their category: UTT > S > VP >PP, and so on.
The incomplete interpreta-tion may not extend all the way to the startof the utterance in which case the processof searching for incomplete interpretations isrepeated.
Of course the search process is re-stricted by the first incomplete constituent.If, for example, an incomplete PP is foundthen any additional incomplete constituentwould have to expect a PP.Figure 1 shows an example of this processon utterance 62 from TRAINS dialog d92a-1.2 (Heeman and Allen, 1995).
Assumingperfect speech repair identification, the re-pair metarule will be fired from position 0to position 5 meaning the parser needs tofind an interpretation starting at position 5and ending at the last position in the input.This interpretation (the corrected utterance)is shown under the words in figure 1.
Theparser then needs to find an interpretationof what the speaker started to say.
Thereare no complete constituents ending at posi-tion 5.
The parser instead finds the incom-plete constituent ADVBL -> adv ?
ADVBL.Our implementation is a chart parser and ac-cordingly incomplete constituents are repre-sented as arcs.
This arc only covers the wordthrough so another arc needs to be found.The arc S ->  S ?
ADVBL expects an ADVBLand covers the rest of the input, completingthe interpretation of what the user startedto say (as shown on the top of figure 1).
Theediting terms are treated as separate utter-ances via the editing term metarule.4 Verification of theFrameworkTo test this framework, data was examinedfrom 31 TRAINS 93 dialogs (Heeman andAllen, 1995), a series of human-human prob-lem solving dialogs in a railway transporta-tion domain.
5 There were 3441 utterances, 619189 words, 259 examples of overlappingutterances, and 495 speech repairs.The framework presented above coveredall the overlapping utterances and speechrepairs with three exceptions.
Orderingthe words of two speakers strictly byword ending points neglects the fact thatspeakers may be slow to interrupt or mayanticipate the original speaker and inter-rupt early.
The latter was a problem inutterances 80 and 81 of dialog d92a-l.2as shown below.
The numbers in the lastrow represent imes of word endings; forexample, so ends at 255.5 seconds into thedialog.
Speaker s uttered the complementof u's sentence before u had spoken the verb.80 u: so the total is81 s: five255.5 255.56 255.83 256 256.61However, it is important o examine thecontext following:82 s: that is rights: okay83 u: five84 s: so total is fiveThe overlapping speech was confusingenough to the speakers that they felt theyneeded to reiterate utterances 80 and 81 inthe next utterances.
The same is true of theother two such examples in the corpus.
Itmay be the case that a more sophisticatedmodel of interruption will not be necessaryif speakers cannot follow completions thatlag or precede the correct interruption area.5 The Dialog ParserImplementat ionIn addition to manually checking the ad-equacy of the framework on the citedTRAINS data, we tested a parser imple-SSpecifically, the dialogs were d92-1 throughd92a-5.2 and d93-10.1 through d93-14.16This figure does not count editing term utter-ances nor utterances started in the middle of anotherspeaker's utterance.416broken-SS -> S eADVBLbroken-ADVBLS ADVBL -> adv ?
ADVBLadv UTT UTI"s: we will take them through um let us see do we want to take them through to Dansvilleaux NP VPSFigure 1: Utterance 62 of d92a-1.2mented as discussed in section 3 on the samedata.
The parser was a modified version ofthe one in the TRIPS dialog system (Fer-guson and Allen, 1998).
Users of this sys-tem participate in a simulated evacuationscenario where people must be transportedalong various routes to safety.
Interactionsof users with TRIPS were not investigatedin detail because they contain few speech re-pairs and virtually no interruptions.
T But,the domains of TRIPS and TRAINS are sim-ilar enough to allow us run TRAINS exam-ples on the TRIPS parser.One problem, though, is the grammat-ical coverage of the language used in theTRAINS domain.
TRIPS users keep theirutterances fairly simple (partly because ofspeech recognition problems) while humanstalking to each other in the TRAINS do-main felt no such restrictions.
Based on a100-utterance t st set drawn randomly fromthe TRAINS data, parsing accuracy is 62% 8However, 37 of these utterances are one word~The low speech recognition accuracy encouragesusers to produce short, carefully spoken utterancesleading to few speech repairs.
Moreover, the systemdoes not speak until the user releases the speech in-put button, and once it responds will not stop talk-ing even if the user interrupts the response.
Thisvirtually eliminates interruptions.8The TRIPS parser does not always return aunique utterance interpretation.
The parser wascounted as being correct if one of the interpretationsit returned was correct.
The usual cause of failurewas the parser finding no interpretation.
Only 3 fail-ures were due to the parser eturning only incorrectinterpretations.long (okay, yeah, etc.)
and 5 utterances werequestion answers (two hours, in Elmira);thus on interesting utterances, accuracy is34.5%.
Assuming perfect speech repair de-tection, only 125 of the 495 corrected speechrepairs parsed.
9Of the 259 overlapping utterances, 153were simple backchannels consisting onlyof editing terms (okay, yeah) spoken by asecond speaker in the middle of the firstspeaker's utterance.
If the parser's grammarhandles the first speaker's utterance thesecan be parsed, as the second speaker's in-terruption can be skipped.
The experimentsfocused on the 106 overlapping utterancesthat were more complicated.
In only 24of these cases did the parser's grammarcover both of the overlapping utterances.One of these examples, utterances utt39and 40 from d92a-3.2 (see below), involvesthree independently formed utterances thatoverlap.
We have omitted the beginning ofs's utterance, so that would be five a.m. forspace reasons.
Figure 2 shows the syntacticstructure of s's utterance (a relative clause)under the words of the utterance, u's twoutterances are shown above the words offigure 2.
The purpose of this figure is toshow how interpretations can be formedaround interruptions by another speakerand how these interruptions themselvesform interpretations.
The specific syntactic9In 19 cases, the parser eturned interpretation(s)but they were incorrect but not included in the abovefigure.417UTTu: and then I go back to Avon s: via DansvilleUTTFigure 3: Utterances 132 and 133 from d92a-5.2structure of the utterances is not shown.Typically, triangles are used to representa parse tree without showing its internalstructure.
Here, polygonal structures mustbe used due to the interleaved nature of theutterances.s: when it would get to bathu:  okay how about o dansvilleFigure 3 is an example of a collaborativelybuilt utterance, utterances 132 and 133 fromd92a-5.2, as shown below, u's interpretationof the utterance (shown below the words infigure 3) does not include s's contributionbecause until utterance 134 (where u uttersright) u has not accepted this continuation.u: and then I go back to avons: via dansville6 Rescoring a Pre-parserSpeech Repair IdentifierOne of the advantages of providing speechrepair information to the parser is that theparser can then use its knowledge of gram-mar and the syntactic structure of the inputto correct speech repair identification errors.As a preliminary test of this assumption, weused an older version of Heeman's languagemodel (the current version is described in(Heeman and Allen, 1997)) and connectedit to the current dialog parser.
Because theparser's grammar only covers 35% of inputsentences, corrections were only made basedon global grammaticality.The effectiveness of the language modulewithout the parser on the testing corpus isshown in table 1. i?
The testing corpus con-i?Note, current versions of this language modelperform significantly better.sisted of TRAINS dialogs containing 541 re-pairs, 3797 utterances, and 20,069 words, iiFor each turn in the input, the languagemodel output the n-best predictions it made(up to 100) regarding speech repairs, part ofspeech tags, and boundary tones.The parser starts by trying the languagemodel's first choice.
If this results in an in-terpretation covering the input, that choiceis selected as the correct answer.
Otherwisethe process is repeated with the model's nextchoice.
If all the choices are exhausted andno interpretations are found, then the firstchoice is selected as correct.
This approachis similar to an experiment in (Bear et al,1992) except that Bear et al were more in-terested in reducing false alarms.
Thus, ifa sentence parsed without the repair then itwas ruled a false alarm.
Here the goal isto increase recall by trying lower probabilityalternatives when no parse can be found.The results of such an approach on the testcorpus are listed in table 2.
Recall increasesby 4.8% (13 cases out of 541 repairs) show-ing promise in the technique of rescoring theoutput of a pre-parser speech repair iden-tifier.
With a more comprehensive gram-mar, a strong disambiguation system, andthe current version of Heeman's languagemodel, the results should get better.
Thedrop in precision is a worthwhile tradeoff asthe parser is never forced to accept positedrepairs but is merely given the option of pur-suing alternatives that include them.Adding actual speech repair identification(rather than assuming perfect identification)gives us an idea of the performance improve-ment (in terms of parsing) that speech repairhandling brings us.
Of the 284 repairs cor-rectly guessed in the augmented model, 79parsed, i2 Out of 3797 utterances, this meansthat 2.1% of the time the parser wouldhave failed without speech repair informa-nSpecifically the dialogs used were d92-1 throughd92a-5.2; d93-10.1 through d93-10.4; and d93-11.1through d93-14.2.
The language model was neversimultaneously trained and tested on the same data.i2In 11 cases, the parser eturned interpretation(s)but they were incorrect and not included in theabove figure.418s: when itUTT UTTwould u: o~ay s: g e ~ l eS \[rel\]Figure 2: Utterances 39 and 40 of d92a-3.2repairs correctly guessedfalse alarmsmissedrecallprecision27121527050.09%55.76%Table 1: Heeman's Speech Repair Resultsrepairs correctly guessedfalse alarmsmissedrecallprecision28437125752.50%43.36%Table 2: Augmented Speech Repair Resultstion.
Although failures due to the gram-mar's coverage are much more frequent (38%of the time), as the parser is made more ro-bust, these 79 successes due to speech re-pair identification will become more signifi-cant.
Further evaluation is necessary to testthis model with an actual speech recognizerrather than transcribed utterances.7 ConclusionsTraditionally, dialog has been treated asa series of single speaker utterances, withno systematic allowance for speech repairsand editing terms.
Such a treatment can-not adequately deal with dialogs involvingmore than one human (as appear in ma-chine translation or meeting analysis), andwill not allow single user dialog systems toprogress to more natural interactions.
Thesimple set of rules given here allows speakersto collaborate to form utterances and pre-vents an interruption such as a backchannelresponse from disrupting the syntax of an-other speaker's utterance.
Speech repairs arecaptured by parallel phrase structure trees,and editing terms are represented asseparateutterances occurring inside other utterances.Since the parser has knowledge of gram-mar and the syntactic structure of the input,it can boost speech repair identification per-formance.
In the experiments of this paper,the parser was able to increase the recall ofa pre-parser speech identifier by 4.8%.
An-other advantage of giving speech repair in-formation to the parser is that the parsercan then include reparanda in its output anda truer picture of dialog structure can beformed.
This can be crucial if a pronoun an-tecedent is present in the reparandum as inhave the engine take the oranges to Elmira,urn, I mean, take them to Coming.
In ad-dition, this information can help a dialogsystem detect uncertainty and planning dif-ficultly in speakers.The framework presented here is sufficientto describe the 3441 human-human utter-ances comprising the chosen set of TRAINSdialogs.
More corpus investigation is neces-sary before we can claim the framework pro-vides broad coverage of human-human dia-log.
Another necessary test of the frameworkis extension to dialogs involving more thantwo speakers.Long term goals include further inves-tigation into the TRAINS corpus and at-tempting full dialog analysis rather than ex-perimenting with small groups of overlap-ping utterances.
Another long term goal isto weigh the current framework against apurely robust parsing approach (Ros~ andLevin, 1998), (Lavie, 1995) that treats outof vocabulary/grammar phenomena in thesame way as editing terms and speech re-pairs.
Robust parsing is critical to a parser419such as the one described here which has acoverage of only 62% on fluent utterances.In our corpus, the speech repair to utter-ance ratio is 14%.
Thus, problems due tothe coverage of the grammar are more thantwice as likely as speech repairs.
However,speech repairs occur with enough frequencyto warrant separate attention.
Unlike gram-mar failures, repairs are generally signalednot only by ungrammaticality, but also bypauses, editing terms, parallelism, etc.
; thusan approach specific to speech repairs houldperform better than just using a robust pars-ing algorithm to deal with them.AcknowledgmentsThis work was supported in part by NationalScience Foundation grants IRI-9503312 and5-28789.
Thanks to James Allen, Peter Hee-man, and Amon Seagull for their help andcomments on this work.ReferencesJ.
Bear, J. Dowding, and E. Shriberg.
1992.Integrating multiple knowledge sourcesfor detection and correction of repairs inhuman-computer dialog.
In Proc.
of the30th annual meeting of the Associationfor Computational Linguistics (A CL-92),pages 56-63.S.
E. Brennan and M. Williams.
1995.
Thefeeling of another's knowing: Prosody andfilled pauses as cues to listeners about themetacognitive states of speakers.
Journalof Memory and Language, 34:383-398.M.
Core and L. Schubert.
1998.
Implement-ing parser metarules that handle speechrepairs and other disruptions.
In D. Cook,editor, Proc.
of the 11th InternationalFLAIRS Conference, Sanibel Island, FL,May.G.
Ferguson and J. F. Allen.
1998.
TRIPS:An intelligent integrated problem-solvingassistant.
In Proc.
of the National Confer-ence on Artificial Intelligence (AAAI-98),pages 26-30, Madison, WI, July.P.
Heeman and J. Allen.
1995. the TRAINS93 dialogues.
TRAINS Technical Note94-2, Department of Computer Science,University of Rochester, Rochester, NY14627-0226.Peter A. Heeman and James F. Allen.
1997.Intonational boundaries, speech repairs,and discourse markers: Modeling spokendialog.
In Proc.
of the 35 th Annual Meet-ing of the Association for ComputationalLinguistics, pages 254-261, Madrid, July.D.
Hindle.
1983.
Deterministic parsing ofsyntactic non-fluencies.
In Proc.
of the21st annual meeting of the Associationfor Computational Linguistics (A CL-83),pages 123-128.A.
Lavie.
1995.
GLR*: A Robust GrammarFocused Parser for Spontaneously SpokenLanguage.
Ph.D. thesis, School of Com-puter Science, Carnegie Mellon University,Pittsburgh, PA.C.
P. Ross and L. S. Levin.
1998.
An in-teractive domain independent approach torobust dialogue interpretation.
In Proc.
ofthe 36 th Annual Meeting of the Associa-tion for Computational Linguistics, Mon-treal, Quebec, Canada.M.
Schober.
1999.
Speech disfluenciesin spoken language systems: A dialog-centered approach.
In NSF Human Com-puter Interaction Grantees' Workshop(HCIGW 99), Orlando, FL.M.-h. Siu and M. Ostendorf.
1996.
Model-ing disfluencies in conversational speech.In Proceedings of the ,~rd InternationalConference on Spoken Language Process-ing (ICSLP-96), pages 386-389.Andreas Stolcke and Elizabeth Shriberg.1996.
Statistical anguage modeling forspeech disfluencies.
In Proceedings ofthe International Conference on Audio,Speech and Signal Processing (ICASSP),May.420
