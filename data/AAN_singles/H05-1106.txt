Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural LanguageProcessing (HLT/EMNLP), pages 843?850, Vancouver, October 2005. c?2005 Association for Computational LinguisticsParadigmatic Modiability Statistics for the Extractionof Complex Multi-Word TermsJoachim WermterJena UniversityLanguage & Information EngineeringJULIE LabFriedrich-Schiller-Universit?at JenaF?urstengraben 30D-07743 Jena, Germanyjoachim.wermter@uni-jena.deUdo HahnJena UniversityLanguage & Information EngineeringJULIE LabFriedrich-Schiller-Universit?at JenaF?urstengraben 30D-07743 Jena, Germanyudo.hahn@uni-jena.deAbstractWe here propose a new method which setsapart domain-specific terminology fromcommon non-specific noun phrases.
Itis based on the observation that termino-logical multi-word groups reveal a con-siderably lesser degree of distributionalvariation than non-specific noun phrases.We define a measure for the observableamount of paradigmatic modifiability ofterms and, subsequently, test it on bigram,trigram and quadgram noun phrases ex-tracted from a 104-million-word biomedi-cal text corpus.
Using a community-widecurated biomedical terminology system asan evaluation gold standard, we show thatour algorithm significantly outperformsa variety of standard term identificationmeasures.
We also provide empirical ev-idence that our methodolgy is essentiallydomain- and corpus-size-independent.1 IntroductionAs we witness the ever-increasing proliferation ofvolumes of medical and biological documents, theavailable dictionaries and terminological systemscannot keep up with this pace of growth and, hence,become more and more incomplete.
What?s worse,the constant stream of new terms is increasingly get-ting unmanageable because human curators are inthe loop.
The costly, often error-prone and time-consuming nature of manually identifying new ter-minology from the most recent literature calls foradvanced procedures which can automatically assistdatabase curators in the task of assembling, updat-ing and maintaining domain-specific controlled vo-cabularies.
Whereas the recognition of single-wordterms usually does not pose any particular chal-lenges, the vast majority of biomedical or any otherdomain-specific terms typically consists of multi-word units.1 Unfortunately these are much moredifficult to recognize and extract than their singletoncounterparts.
Moreover, although the need to assem-ble and extend technical and scientific terminologiesis currently most pressing in the biomedical domain,virtually any (sub-)field of human research/expertisein which we deal with terminologically structuredknowledge calls for high-performance terminologyidentification and extraction methods.
We want totarget exactly this challenge.2 Related WorkThe automatic extraction of complex multi-wordterms from domain-specific corpora is already anactive field of research (cf., e.g., for the biomedi-cal domain Rindflesch et al (1999), Collier et al(2002), Bodenreider et al (2002), or Nenadic?
etal.
(2003)).
Typically, in all of these approachesterm candidates are collected from texts by vari-ous forms of linguistic filtering (part-of-speech tag-ging, phrase chunking, etc.
), through which candi-dates obeying various linguistic patterns are iden-tified (e.g., noun-noun, adjective-noun-noun com-binations).
These candidates are then submitted tofrequency- or statistically-based evidence measures1Nakagawa and Mori (2002) claim that more than 85% ofdomain-specific terms are multi-word units.843(such as the C-value (Frantzi et al, 2000)), whichcompute scores indicating to what degree a candi-date qualifies as a term.
Term mining, as a whole,is a complex process involving several other com-ponents (orthographic and morphological normal-ization, acronym detection, conflation of term vari-ants, term context, term clustering; cf.
Nenadic?
et al(2003)).
Still, the measure which assigns a termhoodvalue to a term candidate is the essential buildingblock of any term identification system.For multi-word automatic term recognition(ATR), the C-value approach (Frantzi et al, 2000;Nenadic?
et al, 2004), which aims at improving theextraction of nested terms, has been one of the mostwidely used techniques in recent years.
Other po-tential association measures are mutual information(Damerau, 1993) and the whole battery of statisti-cal and information-theoretic measures (t-test, log-likelihood, entropy) which are typically employedfor the extraction of general-language collocations(Manning and Schu?tze, 1999; Evert and Krenn,2001).
While these measures have their statisticalmerits in terminology identification, it is interestingto note that they only make little use of linguisticproperties inherent to complex terms.2More linguistically oriented work on ATR byDaille (1996) or on term variation by Jacquemin(1999) builds on the deep syntactic analysis of termcandidates.
This includes morphological and head-modifier dependency analysis and thus presupposesaccurate, high-quality parsing which, for sublan-guages at least, can only be achieved by a highlydomain-dependent type of grammar.
As sublan-guages from different domains usually reveal a highdegree of syntactic variability among each other(e.g., in terms of POS distribution, syntactic pat-terns), this property makes it difficult to port gram-matical specifications to different domains.Therefore, one may wonder whether there arecross-domain linguistic properties which might bebeneficial to ATR and still could be accounted forby only shallow syntactic analysis.
In this paper,we propose the limited paradigmatic modiability ofterms as a criterion which meets these requirementsand will elaborate on it in detail in Subsection 3.3.2A notable exception is the C-value method which incorpo-rates a term?s likelihood of being nested in other multi-wordunits.3 Methods and Experiments3.1 Text CorpusWe collected a biomedical training corpus of ap-proximately 513,000 MEDLINE abstracts using thefollowing query composed of MESH terms fromthe biomedical domain: transcription factors, bloodcells and human.3 We then annotated the result-ing 104-million-word corpus with the GENIA part-of-speech tagger4 and identified noun phrases (NPs)with the YAMCHA chunker (Kudo and Matsumoto,2001).
We restrict our study to NP recognition(i.e., determining the extension of a noun phrase butrefraining from assigning any internal constituentstructure to that phrase), because the vast majority oftechnical or scientific terms surface as noun phrases(Justeson and Katz, 1995).
We filtered out a num-ber of stop words (determiners, pronouns, measuresymbols, etc.)
and also ignored noun phrases withcoordination markers (?and?, ?or?, etc.
).5n-gram cut-off NP term candidateslength tokens typesno cut-off 5,920,018 1,055,820bigrams c ?
10 4,185,427 67,308no cut-off 3,110,786 1,655,440trigrams c ?
8 1,053,651 31,017no cut-off 1,686,745 1,356,547quadgrams c ?
6 222,255 10,838Table 1: Frequency distribution for noun phrase term candi-date tokens and types for the MEDLINE text corpusIn order to obtain the term candidate sets (see Ta-ble 1), we counted the frequency of occurrence ofnoun phrases in our training corpus and categorizedthem according to their length.
For this study, we re-stricted ourselves to noun phrases of length 2 (wordbigrams), length 3 (word trigrams) and length 4(word quadgrams).
Morphological normalization ofterm candidates has shown to be beneficial for ATR(Nenadic?
et al, 2004).
We thus normalized the nom-3MEDLINE (http://www.ncbi.nlm.nih.gov) is thelargest biomedical bibliographic database.
For information re-trieval purposes, all of its abstracts are indexed with a controlledindexing vocabulary, the Medical Subject Headings (MESH,2004).4http://www-tsujii.is.s.u-tokyo.ac.jp/GENIA/postagger/5Of course, terms can also be contained within coordinativestructures (e.g., ?B and T cell?).
However, analyzing their in-herent ambiguity is a complex syntactic operation, with a com-paratively marginal benefit for ATR (Nenadic?
et al, 2004).844inal head of each noun phrase (typically the right-most noun in English) via the full-form UMLS SPE-CIALIST LEXICON (UMLS, 2004), a large repositoryof both general-language and domain-specific (med-ical) vocabulary.
To eliminate noisy low-frequencydata (cf.
also Evert and Krenn (2001)), we defineddifferent frequency cut-off thresholds, c, for the bi-gram, trigram and quadgram candidate sets and onlyconsidered candidates above these thresholds.3.2 Evaluating Term Extraction QualityTypically, terminology extraction studies evaluatethe goodness of their algorithms by having theirranked output examined by domain experts whoidentify the true positives among the ranked can-didates.
There are several problems with such anapproach.
First, very often only one such expertis consulted and, hence, inter-annotator agreementcannot be determined (as, e.g., in the studies ofFrantzi et al (2000) or Collier et al (2002)).
Fur-thermore, what constitutes a relevant term for a par-ticular domain may be rather difficult to decide ?even for domain experts ?
when judges are just ex-posed to a list of candidates without any further con-text information.
Thus, rather than relying on adhoc human judgment in identifying true positives ina candidate set, as an alternative we may take al-ready existing terminolgical resources into account.They have evolved over many years and usually re-flect community-wide consensus achieved by expertcommittees.
With these considerations in mind, thebiomedical domain is an ideal test bed for evaluat-ing the goodness of ATR algorithms because it hostsone of the most extensive and most carefully curatedterminological resources, viz.
the UMLS METATHE-SAURUS (UMLS, 2004).
We will then take the mereexistence of a term in the UMLS as the decision cri-terion whether or not a candidate term is also recog-nized as a biomedical term.Accordingly, for the purpose of evaluating thequality of different measures in recognizing multi-word terms from the biomedical literature, we as-sign every word bigram, trigram, and quadgram inour candidate sets (see Table 1) the status of beinga term (i.e., a true positive), if it is found in the2004 edition of the UMLS METATHESAURUS.6 For6We exclude UMLS vocabularies not relevant for molecularbiology, such as nursing and health care billing codes.example, the word trigram ?long terminal repeat?is listed as a term in one of the UMLS vocabular-ies, viz.
MESH (2004), whereas ?t cell response?is not.
Thus, among the 67,308 word bigram candi-date types, 14,650 (21.8%) were identified as trueterms; among the 31,017 word trigram candidatetypes, their number amounts to 3,590 (11.6%), whileamong the 10,838 word quadgram types, 873 (8.1%)were identified as true terms.73.3 Paradigmatic Modifiability of TermsFor most standard association measures utilized forterminology extraction, the frequency of occurrenceof the term candidates either plays a major role(e.g., C-value), or has at least a significant impacton the assignment of the degree of termhood (e.g.,t-test).
However, frequency of occurrence in a train-ing corpus may be misleading regarding the deci-sion whether or not a multi-word expression is aterm.
For example, taking the two trigram multi-word expressions from the previous subsection, thenon-term ?t cell response?
appears 2410 times inour 104-million-word MEDLINE corpus, whereasthe term ?long terminal repeat?
(long repeating se-quences of DNA) only appears 434 times (see alsoTables 2 and 3 below).The linguistic property around which we built ourmeasure of termhood is the limited paradigmaticmodiability of multi-word terminological units.
Amulti-word expression such as ?long terminal re-peat?
contains three token slots in which slot 1 isfilled by ?long?, slot 2 by ?terminal?
and slot 3 by?repeat?.
The limited paradigmatic modiability ofsuch a trigram is now defined by the probability withwhich one or more such slots cannot be filled byother tokens.
We estimate the likelihood of preclud-ing the appearance of alternative tokens in particularslot positions by employing the standard combina-tory formula without repetitions.
For an n-gram (ofsize n) to select k slots (i.e., in an unordered selec-tion) we thus define:C(n, k) = n!k!(n?
k)!
(1)7As can be seen, not only does the number of candidatetypes drop with increasing n-gram length but also the propor-tion of true terms.
In fact, their proportion drops more sharplythan can actually be seen from the above data because the vari-ous cut-off thresholds have a leveling effect.845For example, for n = 3 (word trigram) and k = 1and k = 2 slots, there are three possible selectionsfor each k for ?long terminal repeat?
and for ?t cellresponse?
(see Tables 2 and 3).
k is actually a place-holder for any possible token (and its frequency)which fills this position in the training corpus.n-gram freq P -Mod (k=1,2)long terminal repeat 434 0.03k slots possible selections sel freq modselk = 1 k1 terminal repeat 460 0.940long k2 repeat 448 0.970long terminal k3 436 0.995mod1 =0.91k = 2 k1 k2 repeat 1831 0.23k1 terminal k3 1062 0.41long k2 k3 1371 0.32mod2 =0.03Table 2: P -Mod and k-modifiabilities for k = 1 and k = 2for the trigram term ?long terminal repeat?n-gram freq P -Mod (k=1,2)t cell response 2410 0.00005k slots possible selections sel freq modselk = 1 k1 cell response 3248 0.74t k2 response 2665 0.90t cell k3 27424 0.09mod1 =0.06k = 2 k1 k2 response 40143 0.06k1 cell k3 120056 0.02t k2 k3 34925 0.07mod2 =0.00008Table 3: P -Mod and k-modifiabilities for k = 1 and k = 2for the trigram non-term ?t cell response?Now, for a particular k (1 ?
k ?
n; n = length ofn-gram), the frequency of each possible selection,sel, is determined.
The paradigmatic modifiabilityfor a particular selection sel is then defined by then-gram?s frequency scaled against the frequency ofsel.
As can be seen in Tables 2 and 3, a lower fre-quency induces a more limited paradigmatic modifi-ability for a particular sel (which is, of course, ex-pressed as a higher probability value; see the columnlabeled modsel in both tables).
Thus, with s beingthe number of distinct possible selections for a par-ticular k, the k-modiability, modk, of an n-gramcan be defined as follows (f stands for frequency):modk(n-gram) :=s?i=1f(n-gram)f(seli, n-gram)(2)The paradigmatic modiability, P -Mod, of an n-gram is the product of all its k-modifiabilities:8P -Mod(n-gram) :=n?k=1modk(n-gram) (3)Comparing the trigram P -Mod values for k =1, 2 in Tables 2 and 3, it can be seen that the term?long terminal repeat?
gets a much higher weightthan the non-term ?t cell response?, although theirmere frequency values suggest the opposite.
This isalso reflected in the respective list rank (see Subsec-tion 4.1 for details) assigned to both trigrams by thet-test and by our P -Mod measure.
While ?t cell re-sponse?
has rank 24 on the t-test output list (whichdirectly reflects its high frequency), P -Mod assignsrank 1249 to it.
Conversely, ?long terminal repeat?is ranked on position 242 by the t-test, whereas itoccupies rank 24 for P -Mod.
In fact, even lower-frequency multi-word units gain a prominent rank-ing, if they exhibit limited paradigmatic modifiabil-ity.
For example, the trigram term ?porphyria cu-tanea tarda?
is ranked on position 28 by P -Mod,although its frequency is only 48 (which results inrank 3291 on the t-test output list).
Despite its lowerfrequency, this term is judged as being relevant forthe molecular biology domain.9 It should be notedthat the termhood values (and the corresponding listranks) computed by P -Mod also include k = 3 and,hence, take into account a reasonable amount of fre-quency load.
As can be seen from the previous rank-ing examples, still this factor does not override theparadigmatic modifiability factors of the lower ks.On the other hand, P -Mod will also demote trueterms in their ranking, if their paradigmatic modifi-ability is less limited.
This is particularly the case ifone or more of the tokens of a particular term oftenoccur in the same slot of other equal-length n-grams.For example, the trigram term ?bone marrow cell?occurs 1757 times in our corpus and is thus rankedquite high (position 31) by the t-test.
P -Mod, how-ever, ranks this term on position 550 because the to-8Setting the upper limit of k to n (e.g., n = 3 for trigrams)actually has the pleasant side effect of including frequency inour modifiability measure.
In this case, the only possible selec-tion k1k2k3 as the denominator of Formula (2) is equivalent tosumming up the frequencies of all trigram term candidates.9It denotes a group of related disorders, all of which arisefrom a deficient activity of the heme synthetic enzyme uropor-phyrinogen decarboxylase (URO-D) in the liver.846ken ?cell?
also occurs in many other trigrams andthus leads to a less limited paradigmatic modifiabil-ity.
Still, the underlying assumption of our approachis that such a case is more an exception than the ruleand that terms are linguistically more ?frozen?
thannon-terms, which is exactly the intuition behind ourmeasure of limited paradigmatic modifiability.3.4 Methods of EvaluationAs already described in Subsection 3.2, standardprocedures for evaluating the quality of termhoodmeasures usually involve identifying the true posi-tives among a (usually) arbitrarily set number of them highest ranked candidates returned by a particu-lar measure, a procedure usually carried out by a do-main expert.
Because this is labor-intensive (besidesbeing unreliable), m is usually small, ranging from50 to several hundreds.10 By contrast, we choosea large and already consensual terminology to iden-tify the true terms in our candidate sets.
Thus, weare able to dynamically examine various m-highestranked samples, which, in turn, allows for the plot-ting of standard precision and recall graphs for theentire candidate set.
We thus provide a more reli-able evaluation setting for ATR measures than whatis common practice in the literature.We compare our P -Mod algorithm against thet-test measure,11 which, of all standard measures,yields the best results in general-language collo-cation extraction studies (Evert and Krenn, 2001),and also against the widely used C-value, whichaims at enhancing the common frequency of occur-rence measure by making it sensitive to nested terms(Frantzi et al, 2000).
Our baseline is defined by theproportion of true positives (i.e., the proportion ofterms) in our bi-, tri- and quadgram candidate sets.This is equivalent to the likelihood of finding a truepositive by blindly picking from one of the differentsets (see Subsection 3.2).10Studies on collocation extraction (e.g., by Evert and Krenn(2001)) also point out the inadequacy of such evaluation meth-ods.
In essence, they usually lead to very superficial judgmentsabout the measures under scrutiny.11Manning and Schu?tze (1999) describe how this measurecan be used for the extraction of multi-word expressions.4 Results and Discussion4.1 Precision/Recall for Terminology ExtractionFor each of the different candidate sets, we incre-mentally examined portions of the ranked outputlists returned by each of the three measures we con-sidered.
The precision values for the various por-tions were computed such that for each percent pointof the list, the number of true positives found (i.e.,the number of terms) was scaled against the overallnumber of candidate items returned.
This yields the(descending) precision curves in Figures 1, 2 and 3and some associated values in Table 4.Portion of Precision scores of measuresranked listconsidered P -Mod t-test C-value1% 0.82 0.62 0.62Bigrams 10% 0.53 0.42 0.4120% 0.42 0.35 0.3430% 0.37 0.32 0.31baseline 0.22 0.22 0.221% 0.62 0.55 0.54Trigrams 10% 0.37 0.29 0.2820% 0.29 0.23 0.2330% 0.24 0.20 0.19baseline 0.12 0.12 0.121% 0.43 0.50 0.50Quadgrams 10% 0.26 0.24 0.2320% 0.20 0.16 0.1630% 0.18 0.14 0.14baseline 0.08 0.08 0.08Table 4: Precision scores for biomedical term extraction atselected portions of the ranked listFirst, we observe that, for the various n-gramcandidate sets examined, all measures outperformthe baselines by far, and, thus, all are potentiallyuseful measures for grading termhood.
Still, theP -Mod criterion substantially outperforms all othermeasures at almost all points for all n-grams exam-ined.
Considering 1% of the bigram list (i.e., the first673 candidates) precision for P -Mod is 20 pointshigher than for the t-test and the C-value.
At 1%of the trigram list (i.e., the first 310 candidates),P -Mod?s lead is 7 points.
Considering 1% of thequadgrams (i.e., the first 108 candidates), the t-testactually leads by 7 points.
At 10% of the quadgramlist, however, the P -Mod precision score has over-taken the other ones.
With increasing portions of allranked lists considered, the precision curves start toconverge toward the baseline, but P -Mod maintainsa steady advantage.84700.20.40.60.81100908070605040302010Portion of ranked list (in %)Precision: P-ModPrecision: T-testPrecision: C-valueRecall: P-ModRecall: T-testRecall: C-valueBaseFigure 1: Precision/Recall for bigram biomedical term extrac-tion00.20.40.60.81100908070605040302010Portion of ranked list (in %)Precision: P-ModPrecision: T-testPrecision: C-valueRecall: P-ModRecall: T-testRecall: C-valueBaseFigure 2: Precision/Recall for trigram biomedical term ex-traction00.20.40.60.81100908070605040302010Portion of ranked list (in %)Precision: P-ModPrecision: T-testPrecision: C-valueRecall: P-ModRecall: T-testRecall: C-valueBaseFigure 3: Precision/Recall for quadgram biomedical term ex-tractionThe (ascending) recall curves in Figures 1, 2 and3 and their corresponding values in Table 5 indicatewhich proportion of all true positives (i.e., the pro-portion of all terms in a candidate set) is identified bya particular measure at a certain point of the rankedlist.
For term extraction, recall is an even better indi-cator of a particular measure?s performance becausefinding a bigger proportion of the true terms at anearly stage is simply more economical.Recall Portion of Ranked Listscores ofmeasures P -Mod t-test C-value0.5 29% 35% 37%0.6 39% 45% 47%Bigrams 0.7 51% 56% 59%0.8 65% 69% 72%0.9 82% 83% 85%0.5 19% 28% 30%Trigrams 0.6 27% 38% 40%0.7 36% 50% 53%0.8 50% 63% 66%0.9 68% 77% 84%0.5 20% 28% 30%0.6 26% 38% 40%Quadgrams 0.7 34% 49% 53%0.8 45% 62% 65%0.9 61% 79% 82%Table 5: Portions of the ranked list to consider for selectedrecall scores for biomedical term extractionAgain, our linguistically motivated terminologyextraction algorithm outperforms its competitors,and with respect to tri- and quadgrams, its gain iseven more pronounced than for precision.
In order toget a 0.5 recall for bigram terms, P -Mod only needsto winnow 29% of the ranked list, whereas the t-testand C-value need to winnow 35% and 37%, respec-tively.
For trigrams and quadgrams, P -Mod onlyneeds to examine 19% and 20% of the list, whereasthe other two measures have to scan almost 10 ad-ditional percentage points.
In order to obtain a 0.6,0.7, 0.8 and 0.9 recall, the differences between themeasures narrow for bigram terms, but they widensubstantially for tri- and quadgram terms.
To obtaina 0.6 recall for trigram terms, P -Mod only needs towinnow 27% of its output list while the t-test andC-value must consider 38% and 40%, respectively.For a level of 0.7 recall, P -Mod only needs to an-alyze 36%, while the t-test already searches 50% ofthe ranked list.
For 0.8 recall, this relation is 50%848(P -Mod) to 63% (t-test), and at recall point 0.9,68% (P -Mod) to 77% (t-test).
For quadgram termidentification, the results for P -Mod are equally su-perior to those for the other measures, and at recallpoints 0.8 and 0.9 even more pronounced than fortrigram terms.We also tested the significance of differences forthese results, both comparing P -Mod vs. t-test andP -Mod vs. C-value.
Because in all cases the rankedlists were taken from the same set of candidates (viz.the set of bigram, trigram, and quadgram candidatetypes), and hence constitute dependent samples, weapplied the McNemar test (Sachs, 1984) for statis-tical testing.
We selected 100 measure points in theranked lists, one after each increment of one percent,and then used the two-tailed test for a confidence in-terval of 95%.
Table 6 lists the number of significantdifferences for these measure points at intervals of10 for the bi-, tri-, and quadgram results.
For the bi-gram differences between P -Mod and C-value, allof them are significant, and between P -Mod andt-test, all are significantly different up to measurepoint 70.12 Looking at the tri- and quadgrams, al-though the number of significant differences is lessthan for bigrams, the vast majority of measure pointsis still significantly different and thus underlines thesuperior performance of the P -Mod measure.# of # of significant differences comparingmeasure P -Mod withpoints t-test C-val t-test C-val t-test C-val10 10 10 9 9 3 320 20 20 19 19 13 1330 30 30 29 29 24 2440 40 40 39 39 33 3350 50 50 49 49 43 4360 60 60 59 59 53 5370 70 70 69 69 63 6380 75 80 79 79 73 7390 84 90 89 89 82 83100 93 100 90 98 82 91bigrams trigrams quadgramsTable 6: Significance testing of differences for bi-, tri- andquadgrams using the two-tailed McNemar test at 95% confi-dence interval12As can be seen in Figures 1, 2 and 3, the curves start tomerge at the higher measure points and, thus, the number ofsignificant differences decreases.4.2 Domain Independence and Corpus SizeOne might suspect that the results reported abovecould be attributed to the corpus size.
Indeed, thetext collection we employed in this study is ratherlarge (104 million words).
Other text genres and do-mains (e.g., clinical narratives, various engineeringdomains) or even more specialized biological sub-domains (e.g., plant biology) do not offer such aplethora of free-text material as the molecular biol-ogy domain.
To test the effect a drastically shrunkencorpus size might have, we assessed the terminologyextraction methods for trigrams on a much smaller-sized subset of our original corpus, viz.
on 10 millionwords.
These results are depicted in Figure 4.00.20.40.60.81100908070605040302010Portion of ranked list (in %)Precision: P-ModPrecision: T-testPrecision: C-valueRecall: P-ModRecall: T-testRecall: C-valueBaseFigure 4: Precision/Recall for trigram biomedical term ex-traction on the 10-million-word corpus (cutoff c ?
4, with6,760 term candidate types)The P -Mod extraction criterion still clearly out-performs the other ones on that 10-million-word cor-pus, both in terms of precision and recall.
We alsoexamined whether the differences were statisticallysignificant and applied the two-tailed McNemar teston 100 selected measure points.
Comparing P -Modwith t-test, most significant differences could be ob-served between measure points 20 and 80, with al-most 80% to 90% of the points being significantlydifferent.
These significant differences were evenmore pronounced when comparing the results be-tween P -Mod and C-value.5 ConclusionsWe here proposed a new terminology extractionmethod and showed that it significantly outperforms849two of the standard approaches in distinguishingterms from non-terms in the biomedical literature.While mining scientific literature for new termino-logical units and assembling those in controlled vo-cabularies is a task involving several components,one essential building block is to measure the de-gree of termhood of a candidate.
In this respect, ourstudy has shown that a criterion which incorporatesa vital linguistic property of terms, viz.
their lim-ited paradigmatic modiability, is much more pow-erful than linguistically more uninformed measures.This is in line with our previous work on general-language collocation extraction (Wermter and Hahn,2004), in which we showed that a linguistically mo-tivated criterion based on the limited syntagmaticmodifiability of collocations outperforms alternativestandard association measures as well.We also collected evidence that the superiority ofthe P -Mod method relative to other term extractionapproaches holds independent of the underlying cor-pus size (given a reasonable offset).
This is a crucialfinding because other domains might lack large vol-umes of free-text material but still provide sufficientcorpus sizes for valid term extraction.
Finally, sincewe only require shallow syntactic analysis (in termsof NP chunking), our approach might be well suitedto be easily portable to other domains.
Hence, wemay conclude that, although our methodology hasbeen tested on the biomedical domain only, there areessentially no inherent domain-specific restrictions.Acknowledgements.
This work was partly supported bythe European Network of Excellence ?Semantic Mining inBiomedicine?
(NoE 507505).ReferencesOlivier Bodenreider, Thomas C. Rindflesch, and Anita Burgun.2002.
Unsupervised, corpus-based method for extending abiomedical terminology.
In Stephen Johnson, editor, Pro-ceedings of the ACL/NAACL 2002 Workshop on ?NaturalLanguage Processing in the Biomedical Domain?, pages 53?60.
Philadelphia, PA, USA, July 11, 2002.Nigel Collier, Chikashi Nobata, and Jun?ichi Tsujii.
2002.
Au-tomatic acquisition and classification of terminology using atagged corpus in the molecular biology domain.
Terminol-ogy, 7(2):239?257.Be?atrice Daille.
1996.
Study and implementation of com-bined techniques for automatic extraction of terminology.
InJudith L. Klavans and Philip Resnik, editors, The Balanc-ing Act: Combining Statistical and Symbolic Approaches toLanguage, pages 49?66.
Cambridge, MA: MIT Press.Fred J. Damerau.
1993.
Generating and evaluating domain-oriented multi-word terms from text.
Information Process-ing & Management, 29(4):433?447.Stefan Evert and Brigitte Krenn.
2001.
Methods for thequalitative evaluation of lexical association measures.
InACL?01/EACL?01 ?
Proceedings of the 39th Annual Meet-ing of the Association for Computational Linguistics and the10th Conference of the European Chapter of the ACL, pages188?195.
Toulouse, France, July 9-11, 2001.Katerina T. Frantzi, Sophia Ananiadou, and Hideki Mima.2000.
Automatic recognition of multi-word terms: The C-value/NC-value method.
International Journal on DigitalLibraries, 3(2):115?130.Christian Jacquemin.
1999.
Syntagmatic and paradigmatic rep-resentations of term variation.
In Proceedings of the 37rdAnnual Meeting of the Association for Computational Lin-guistics, pages 341?348.
College Park, MD, USA, 20-26June 1999.John S. Justeson and Slava M. Katz.
1995.
Technical terminol-ogy: Some linguistic properties and an algorithm for identi-fication in text.
Natural Language Engineering, 1(1):9?27.Taku Kudo and Yuji Matsumoto.
2001.
Chunking with supportvector machines.
In NAACL?01, Language Technologies2001 ?
Proceedings of the 2nd Meeting of the North Amer-ican Chapter of the Association for Computational Linguis-tics, pages 192?199.
Pittsburgh, PA, USA, June 2-7, 2001.Christopher D. Manning and Hinrich Schu?tze.
1999.
Foun-dations of Statistical Natural Language Processing.
Cam-bridge, MA; London, U.K.: Bradford Book & MIT Press.Hiroshi Nakagawa and Tatsunori Mori.
2002.
A simple butpowerful automatic term extraction method.
In COMPU-TERM 2002 ?
Proceedings of the 2nd International Work-shop on Computational Terminology, pages 29?35.
Taipei,Taiwan, August 31, 2002.Goran Nenadic?, Irena Spasic?, and Sophia Ananiadou.
2003.Terminology-driven mining of biomedical literature.
Bioin-formatics, 19(8):938?943.Goran Nenadic?, Sophia Ananiadou, and John McNaught.
2004.Enhancing automatic term recognition through recognitionof variation.
In COLING 2004 ?
Proceedings of the 20th In-ternational Conference on Computational Linguistics, pages604?610.
Geneva, Switzerland, August 23-27, 2004.Thomas C. Rindflesch, Lawrence Hunter, and Alan R. Aronson.1999.
Mining molecular binding terminology from biomed-ical text.
In AMIA?99 ?
Proceedings of the Annual Sym-posium of the American Medical Informatics Association,pages 127?131.
Washington, D.C., November 6-10, 1999.Lothar Sachs.
1984.
Applied Statistics: A Handbook of Tech-niques.
New York: Springer, 2nd edition.MESH.
2004.
Medical Subject Headings.
Bethesda, MD: Na-tional Library of Medicine.UMLS.
2004.
Unified Medical Language System.
Bethesda,MD: National Library of Medicine.Joachim Wermter and Udo Hahn.
2004.
Collocation extrac-tion based on modifiability statistics.
In COLING 2004 ?Proceedings of the 20th International Conference on Com-putational Linguistics, pages 980?986.
Geneva, Switzerland,August 23-27, 2004.850
