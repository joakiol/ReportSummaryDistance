Proceedings of the 7th Linguistic Annotation Workshop & Interoperability with Discourse, pages 149?158,Sofia, Bulgaria, August 8-9, 2013. c?2013 Association for Computational LinguisticsDeveloping Parallel Sense-tagged Corpora with WordnetsFrancis Bond, Shan Wang,Eshley Huini Gao, Hazel Shuwen Mok, Jeanette Yiwen TanLinguistics and Multilingual Studies, Nanyang Technological Universitybondieee.orgAbstractSemantically annotated corpora play animportant role in natural language pro-cessing.
This paper presents the resultsof a pilot study on building a sense-taggedparallel corpus, part of ongoing construc-tion of aligned corpora for four languages(English, Chinese, Japanese, and Indone-sian) in four domains (story, essay, news,and tourism) from the NTU-MultilingualCorpus.
Each subcorpus is first sense-tagged using a wordnet and then thesesynsets are linked.
Upon the completionof this project, all annotated corpora willbe made freely available.
The multilingualcorpora are designed to not only providedata for NLP tasks like machine transla-tion, but also to contribute to the studyof translation shift and bilingual lexicogra-phy as well as the improvement of mono-lingual wordnets.1 IntroductionLarge scale annotated corpora play an essen-tial role in natural language processing (NLP).Over the years with the efforts of the commu-nity part-of-speech tagged corpora have achievedhigh quality and are widely available.
In com-parison, due to the complexity of semantic an-notation, sense tagged parallel corpora developslowly.
However, the growing demands in morecomplicated NLP applications such as informa-tion retrieval, machine translation, and text sum-marization suggest that such corpora are in greatneed.
This trend is reflected in the construc-tion of two types of corpora: (i) parallel cor-pora: FuSe (Cyrus, 2006), SMULTRON (Volket al 2010), CroCo ( ?Culo et al 2008), German-English parallel corpus (Pad?
and Erk, 2010), Eu-roparl corpus (Koehn, 2005), and OPUS (Ny-gaard and Tiedemann, 2003; Tiedemann and Ny-gaard, 2004; Tiedemann, 2009, 2012) and (ii)sense-tagged monolingual corpora: English cor-pora such as Semcor (Landes et al 1998); Chi-nese corpora, such as the crime domain of SinicaCorpus 3.0 (Wee and Mun, 1999), 1 million wordcorpus of People?s Daily (Li et al 2003), threemonths?
China Daily (Wu et al 2006); Japanesecorpora, such as Hinoki Corpus (Bond et al 2008)and Japanese SemCor (Bond et al 2012) andDutch Corpora such as the Groningen MeaningBank (Basile et al 2012).
Nevertheless, almost noparallel corpora are sense-tagged.
With the excep-tion of corpora based on translations of SemCor(Bentivogli et al 2004; Bond et al 2012) sense-tagged corpora are almost always monolingual.This paper describes ongoing work on the con-struction of a sense-tagged parallel corpus.
It com-prises four languages (English, Chinese, Japanese,and Indonesian) in four domains (story, essay,news, and tourism), taking texts from the NTU-Multilingual Corpus (Tan and Bond, 2012).
Forthese subcorpora we first sense tag each textmonolingually and then link the concepts acrossthe languages.
The links themselves are typed andtell us something of the nature of the translation.The annotators are primarily multilingual studentsfrom the division of linguistics and multilingualstudies (NTU) with extensive training.
In this pa-per we introduce the planned corpus annotationand report on the results of a completed pilot: an-notation and linking of one short story: The Ad-venture of the Dancing Men in Chinese, Englishand Japanese.
All concepts that could be werealigned and their alignments annotated.The paper is structured as follows.
Section 2reviews existing parallel corpora and sense taggedcorpora that have been built.
Section 3 introducesthe resources that we use in our annotation project.The annotation scheme for the multilingual cor-pora is laid out in Section 4.
In Section 5 we report149in detail the results of our pilot study.
Section 6presents our discussion and future work.2 Related WorkIn recent years, with the maturity of part-of-speech(POS) tagging, more attention has been paid tothe practice of getting parallel corpora and sense-tagged corpora to promote NLP.2.1 Parallel CorporaSeveral research projects have reported annotatedparallel corpora.
Among the first major efforts inthis direction is FuSe (Cyrus, 2006), an English-German parallel corpus extracted from the EU-ROPARL corpus (Koehn, 2005).
Parallel sen-tences were first annotated mono-lingually withPOS tags and lemmas; related predicates (e.g.a verb and its nominalization are then linked).SMULTRON (Volk et al 2010) is a parallel tree-bank of 2,500 sentences from different genres:a novel, economy texts from several sources, auser manual and mountaineering reports.
Mostof the corpus is German-English-Swedish paral-lel text, with additional texts in French and Span-ish.
CroCo ( ?Culo et al 2008) is a German-English parallel and comparable corpus of a dozentexts from eight genres, totaling approximately1,000,000 words.
Each sentence is annotated withphrase structures and grammatical functions, andwords, chunks and phrases are aligned across par-allel sentences.
This resource is limited to twolanguages, English and German, and is not sys-tematically linked to any semantic resource.
Pad?and Erk (2010) have conducted a study of transla-tion shifts on a German-English parallel corpus of1,000 sentences from EUROPARL annotated withsemantic frames from FrameNet and word align-ments.
Their aim was to measure the feasibility offrame annotation projection across languages.The above corpora have been used for study-ing translation shift.
Plain text parallel corpora arealso widely used in NLP.
The Europarl corpus col-lected the parallel text in 11 official languages ofthe European Union (i.e.
Danish, German, Greek,English, Spanish, Finnish, French, Italian, Dutch,Portuguese, and Swedish) from proceedings of theEuropean Parliament.
Each language is composedof about 30 million words (Koehn, 2005).
Newerversions have even more languages.
OPUS v0.1contains the documentation of the office packageOpenOffice with a collection of 2,014 files in En-glish and five translated texts, namely, French,Spanish, Swedish, German and Japanese.
Thiscorpus consists of 2.6 million words (Nygaard andTiedemann, 2003; Tiedemann and Nygaard, 2004;Tiedemann, 2012).
However, when we examinedthe Japanese text, we found the translations are of-ten from different versions of the software and notsynchronized very well.2.2 Sense Tagged CorporaSurprisingly few languages have sense tagged cor-pora.
In English, Semcor was built by annotat-ing texts from the Brown Corpus using the senseinventory of WordNet 1.6 (Fellbaum, 1998) andhas been mapped to subsequent WordNet versions(Landes et al 1998).
The Defense Science Or-ganization (DSO) corpus annotated the 191 mostfrequent and ambiguous nouns and verbs from thecombined Brown Corpus and Wall Street JournalCorpus using WordNet 1.5.
The 191 words com-prise of 70 verbs with an average sense number of12 and 121 nouns with an average sense numberof 7.8.
The verbs and nouns respectively accountfor approximately 20% of all verbs and nouns inany unrestricted English text (Ng and Lee, 1996).The WordNet Gloss Disambiguation Project usesPrinceton WordNet 3.0 (PWN) to disambiguate itsown definitions and examples.1In Chinese, Wee and Mun (1999) reported theannotation of a subset of Sinica Corpus 3.0 usingHowNet.
The texts are news covering the crimedomain with 30,000 words.
Li et al(2003) an-notated the semantic knowledge of a 1 millionword corpus from People?s Daily with dependencygrammar.
The corpus include domains such aspolitics, economy, science, and sports.
(Wu et al2006) described the sense tagged corpus of PekingUniversity.
They annotated three months of thePeople?s Daily using the Semantic Knowledge-base of Contemporary Chinese (SKCC)2.
SKCCdescribes the features of a word through attribute-value pairs, which incorporates distributional in-formation.In Japanese, the Hinoki Corpus annotated 9,835headwords with multiple senses in Lexeed: aJapanese semantic lexicon (Kasahara et al 2004)To measure the conincidence of tags and difficultydegree in identifying senses, each word was anno-tated by 5 annotators (Bond et al 2006).1http://wordnet.prineton.edu/glosstag.shtml2http://l.pku.edu.n/l_sem_dit/150We only know of two multi-lingual sense-tagged corpora.
One is MultiSemCor, which isan English/Italian parallel corpus created basedon SemCor (Landes et al 1998).
MultiSemCoris made of 116 English texts taken from SemCorwith their corresponding 116 Italian translations.There are 258,499 English tokens and 267,607Italian tokens.
The texts are all aligned at the wordlevel and content words are annotated with POS,lemma, and word senses.
It has 119,802 Englishwords semantically annotated from SemCor and92,820 Italian words are annotated with senses au-tomatically transferred from English (Bentivogliet al 2004).
Japanese SemCor is another transla-tion of the English SemCor, whose senses are pro-jected across from English.
It takes the same textsin MultiSemCor and translates them into Japanese.Of the 150,555 content words, 58,265 are sensetagged either as monosemous words or by pro-jecting from the English annotation (Bond et al2012).
The low annotation rate compared to Mul-tiSemCor reflects both a lack of coverage in theJapanese wordnet and the greater typological dif-ference.Though many efforts have been devoted to theconstruction of sense tagged corpora, the major-ity of the existing corpora are monolingual, rel-atively small in scale and not all freely available.To the best of our knowledge, no large scale sense-tagged parallel corpus for Asian languages exists.Our project will fill this gap.3 ResourcesThis section introduces the wordnets and corporawe are using for the annotation task.3.1 WordnetsPrinceton WordNet (PWN) is an English lexicaldatabase created at the Cognitive Science Labo-ratory of Princeton University.
It was developedfrom 1985 under the direction of George A. Miller.It groups nouns, verbs, adjective and adverbs intosynonyms (synsets), most of which are linked toother synsets through a number of semantic rela-tions.
(Miller, 1998; Fellbaum, 1998).
The versionwe use in this study is 3.0.A number of wordnets in various languageshave been built based on and linked to PWN.
TheOpen Multilingual Wordnet (OMW) project3 cur-3http://www.asta-net.jp/~kuribayashi/multi/rently provides 22 wordnets (Bond and Paik, 2012;Bond and Foster, 2013).
The Japanese and Indone-sian wordnets in our project are from OMW pro-vided by the creators (Isahara et al 2008, NurrilHirfana et al 2011).The Chinese wordnet we use is a heavily re-vised version of the one developed by SoutheastUniversity (Xu et al 2008).
This was automat-ically constructed from bilingual resources withminimal hand-checking.
It has limited coverageand is somewhat noisy, we have been revising itand use this revised version for our annotation.3.2 Multilingual CorpusThe NTU-multilingual corpus (NTU-MC) is com-piled at Nanyang Technological University.
Itcontains eight languages: English (eng), Man-darin Chinese (cmn), Japanese (jpn), Indonesian(ind), Korean, Arabic, Vietnamese and Thai (Tanand Bond, 2012).
We selected parallel datafor English, Chinese, Japanese, and Indonesianfrom NTU-MC to annotate.
The data are fromfour genres, namely, short story (two SherlockHolmes?
Adventures), essay (Raymond, 1999),news (Kurohashi and Nagao, 2003) and tourism(Singapore Tourist Board, 2012).
The corpus sizesare shown in Table 1.
We show the number ofwords and concepts (open class words tagged withsynsets) only for English, the other languages arecomparable in size.4 Annotation Scheme for MultilingualCorporaThe annotation task is divided into two phases:monolingual sense annotation and multilingualconcept alignment.4.1 Monolingual Sense AnnotationFirst, the Chinese, Japanese and Indonesian cor-pora were automatically tokenized and taggedwith parts-of-speech.
Secondly, concepts weretagged with candidate synsets, with multiword ex-pressions allowing a skip of up to 3 words.
Anymatch with a wordnet entry was considered a po-tential concept.These were then shown to annotators to eitherselect the appropriate synset, or point out a prob-lem.
The interface for doing sense annotation isshown in Figure 1.In Figure 1, the concepts to be annotated areshown as red and underlined.
When clicking on151Genre Text Sentences Words ConceptsEng Cmn Jpn Ind Eng EngStory The Adventure of the Dancing Men 599 606 698 ?
11,200 5,300The Adventure of the Speckled Band 599 612 702 ?
10,600 4,700Essay The Cathedral and the Bazaar 769 750 773 ?
18,700 8,800News Mainichi News 2,138 2,138 2,138 ?
55,000 23,200Tourism Your Singapore (web site) 2,988 2,332 2,723 2,197 74,300 32,600Table 1: Multilingual corpus sizeFigure 1: Tagging the sense of cane.a concept, its WordNet senses appear to the rightof a screen.
The annotator chooses between thesesenses or a number of meta-tags: e, s, m, p, u.Their meaning is explained below.e error in tokenization???
should be?
?three-toed should be three - toeds missing sense (not in wordnet)I program in python ?the computer language?COMMENT: add link to existing synset<06898352-n ?programming language?m bad multiword(i) if the lemma is a multiword, this tag meansit is not appropriate(ii) if the lemma is single-word, this tagmeans it should be part of a multiwordp POS that should not be tagged (article,modal, preposition, .
.
.
)u lemma not in wordnet but POS open class(tagged automatically)COMMENT: add or link to existing synsetMissing senses in the wordnets were a majorissue when tagging, especially for Chinese andJapanese.
We allowed the annotators to add candi-date new senses in the comments; but these werenot made immediately available in the tagging in-terface.
As almost a third of the senses were miss-ing in Chinese and Japanese, this slowed the anno-tators down considerably.Our guidelines for adding new concepts or link-ing words to existing cover four cases:= When a word is a synonym of an exist-ing word, add =synset to the comment:e.g.
for laidback, it is a synonym of02408011-a ?laid-back, mellow?, so we add=02408011-a to the comment for laidback.< When a word is a hyponym/instance of152an existing word, mark it with <synset:For example, python is a hyponym of06898352-n programming language, so weadd <06898352-n to python!
Mark antonyms with !synset.?
If you cannot come up with a more specificrelationship, just say the word is related insome way to an existing synset with ?synset;and add more detail in the comment.Finally, we have added more options for theannotators: prn (pronouns) and seven kinds ofnamed entities: org (organization); loc (location);per (person); dat (date/time); num (number); oth(other) and the super type nam (name).
These ba-sically follow Landes et al(1998, p207), with theaddition of number, date/time and name.
Name isused when automatically tagging, it should be spe-cialized later, but is useful to have when aligning.Pronouns include both personal and indefinite-pronouns.
Pronouns are not linked to their mono-lingual antecedents, just made available for cross-lingual linking.4.2 Multilingual Concept AlignmentWe looked at bitexts: the translated text and itssource (in this case English).
Sentences werealready aligned as part of the NTU-MultilingualCorpus.
The initial alignment was done automat-ically: concepts that are tagged with the samesynset or related synsets (one level of hyponymy)are directly linked.
Then the sentence pairs arepresented to the annotator, using the interfaceshown in Figure 2.In the alignment interface, when you hover overa concept, its definition from PWN is shown in apop-up window at the top.
Clicking concepts inone language and then the other produces a can-didate alignment: the annotator then choses thekind of alignment.
After concepts are aligned theyare shown in the same color.
Both bell and ??
m?nl?ng ?door bell?
have the same synset, sothey are linked with =.
Similarly, Watson and ??
Hu?she?ng ?Watson?
refer to the same person,so they are also connected with =.
However, ringin the English sentence is a noun while the corre-sponding Chinese word?
xia?ng ?ring?
is a verb;so they are linked with the weaker type ?.We found three issues came up a lot during theannotation: (i) Monolingual tag errors; (ii) mul-tiword expression not tagged; (iii) Pronouns nottagged.
(i) In some cases, the monolingual tag wasnot the best choice.
Looking at the tagging inboth languages often made it easier to choose be-tween similar monolingual tags, and the annota-tors found themselves wanting to retag a numberof entries.
(ii) It was especially common for it to becomeclear that things should have been tagged as mul-tiword expressions.
Consider kuchi-wo hiraku?speak?
in (1).
(1) Said he suddenlya.
????ho-muzuHolmes?gaNOM??totsuzensuddenly?kuchimouth?woACC?
?hirakuopen?Holmes opens his mouth suddenly?This was originally tagged as ?open mouth?
butin fact it is a multiword expression with the mean-ing ?say?, and is parallel in meaning to the originalEnglish text.
As this concept is lexicalized, the an-notator grouped the words together and tagged thenew concept to the synset 00941990-v ?express inspeech?.
The concepts were then linked togetherwith ?.
It is hard for the monolingual annotatorto consistently notice such multiword expressions:however, the translation makes them more salient.
(iii) It was often the case that an open classword in one language would link to a closed classword in the other, especially to a pronoun.
Wesee this in (1) where he in English links to ho-muzu ?Holmes?
in Japanese.
In order to capturethese correspondences, we allowed the annotatorto also tag named entities, pronouns and interrog-atives.
From now on we will tag these as part ofthe initial monolingual alignment.We tagged the links between concepts with thetypes shown in Table 2.5 Pilot Study ResultsA pilot study was conducted using the first storytext: The Adventure of the Dancing Men, a Sher-lock Holmes short story (Conan Doyle, 1905).The Japanese version was translated by OtokichiMikami and Yu Okubu;4 we got the translated ver-sion of Chinese from a website which later disap-peared.
Using English text as the source language,the Japanese and Chinese texts were aligned and4http://www.aozora.gr.jp/ards/000009/ard50713.html153Figure 2: Interface for aligning concepts.manually sense-tagged with reference to their re-spective wordnets.
The number of words and con-cepts for each language is shown in Table 3.English Chinese JapaneseSentences 599 680 698Words 11,198 11,325 13,483Concepts 5,267 4,558 4,561Excluding candidate concepts rejected by the annotators.Table 3: Concepts in Dancing MenThe relationships between words were taggedusing the symbols in in Table 2.
The difficult casesare similar relation and translation equivalent rela-tion.
Due to translation styles and language diver-gence, some concepts with related meaning can-not be directly linked.
We give examples in (2)through (4).
(2) ?How on earth do you know that??
I asked.a.
???????ittaion+earth??,????doushitewhy??sonothat??=?koto=wothing=ACC???????toQUOT?=?watashi=wame=TOP??=?
?kiki=kaesuask=return?Why on earth do you know that thing??
I askin return.In (2), compared to ask in English, the Japanesekikikaesu has the additional meaning of ?in re-turn?
: it is a hyponym.
We marked their relationas ?
(similar in meaning).We introduced a new class ?
to indicate com-binations of words or phrases that are translationequivalents of the original source but are not lex-icalized enough to be linked in the wordnet.
Oneexample is shown in (3).
(3) be content with my word154Type Example= same concept say ???
iu ?say??
hypernym wash ??????
araiotosu ?wash out?
?2 2nd level dog ???
doubutsu ?animal??
hyponym sunlight ??
hikari ?light?
?n nth level?
similar notebook ????
memochou ?notepad?dulla ????
kusumu ?darken??
equivalent be content with my word ???????????-?
?believe in my words?!
antonym hot ???=??
samu=ku nai ?not cold?# weak ant.
not propose to invest ???????
omoi=todomaru ?hold back?Table 2: Translation Equivalence Typesa.
????=?watakushi=nome=of??=?kotoba=woword=ACC?
?=?shinji=tebelieve=ing?believe in my words?In this case shinjite ?believe?
is being used toconvey the same pragmatic meaning as contentwith but they are not close enough in meaning thatwe want to link them in the lexicon.
(4) shows some further issues in non-directtranslation.
(4) I am sure that I shall sayh noithing j of the kindk .a.
????iyaiyaby+no+means?,,???sonnakthat+kindk+of?
?koto jthing j?waTOP?
?-?iwah-nisayh-NEGi?yoyo?no no, I will not say that kind of thing?Sayh noithing j of the kindk becomes roughly?noti sayh that kindk of thing j?.
All the elementsare there, but they are combined in quite a differentstructure and some semantic decomposition wouldbe needed to link them.
Chinese and Japanese donot use negation inside the NP, so this kind of dif-ference is common.
Tagging was made more com-plicated by the fact that determiners are not part ofwordnet, so it is not clear which parts of the ex-pression should be tagged.Though there are many difficult cases, the mostcommon case was for two concepts to share thesame synset and be directly connected.
Forexample, notebook is tagged with the synset06415419-n, defined as ?a book with blank pagesfor recording notes or memoranda?.
In theJapanese version, this concept is translated into???
bibouroku ?notebook?, with exactly the samesynset (06415419-n).
Hence, we linked the wordswith the = symbol.The number of link types after the first roundof cross-lingual annotation (eng-jpn, eng-cmn) issummarized in Table 4.
In the English-Japaneseand English-Chinese corpora, 51.38% and 60.07%of the concepts have the same synsets: that is,slightly over half of the concepts can be directlytranslated.
Around 5% of the concepts in the twocorpora are linked to words close in the hierar-chy (hyponym/hypernym).
There were very fewantonyms (0.5%).
Similar relations plus transla-tion equivalents account for 42.85% and 34.74%in the two corpora respectively.
These parts arethe most challenging for machine translation.In this first round, when the annotator attemptedto link concepts, it was sometimes the case thatthe translation equivalent was a word not excludedfrom wordnet by design.
Especially common wascases of common nouns in Japanese and Chinesebeing linked to pronouns in English.
In studyinghow concepts differ across languages, we considerthese of interest.
We therefore expanded our tag-ging effort to include pronouns.6 Discussion and Future WorkThe pilot study showed clearly that cross-lingualannotation was beneficial not just in finding inter-esting correspondences across languages but alsoin improving the monolingual annotation.
In par-ticular, we found many instances of multiword ex-pressions that had been missed in the monolingualannotation.
Using a wordnet to sense tag a corpusis extremely effective in improving the quality ofthe wordnet, and tagging and linking parallel text155Type Eng-Jpn Eng-Cmnlinked 2,542 2,535= 1,416 51.58 1,712 60.07?
990 36.07 862 30.25?
186 6.78 128 4.49?
75 2.73 94 3.30?2 8 0.81 13 1.51?
63 2.30 39 1.37?2 10 1.01 18 2.09!
1 0.04 2 0.07# 14 0.51 13 0.46unlinked 2,583 1,898Table 4: Analysis of linksis an excellent way to improve the quality of themonolingual annotation.
Given how many prob-lems we found in both wordnet and corpus whenwe went over the bilingual annotation, we hypoth-esize that perhaps one of the reasons WSD is cur-rently so difficult is that the gold standards are notyet fully mature.
They have definitely not yet gonethrough the series of revisions that many syntacticcorpora have, even though the tagging scheme isfar harder.For this project, we improved our annotationprocess in two major ways:(i) We expanded the scope of the annotationto include pronouns and named entities interrog-atives.
These will now be tagged from the mono-lingual annotation stage.
(ii) We improved the tool to make it possible toadd new entries directly to the wordnets, so thatthey are available for tagging the remaining text.Using the comments to add new sense was a badidea: synset-ids were cut and pasted, often with acharacter missing, and annotators often mistypedthe link type.
In addition, for words that appearedmany times, it was tedious to redo it for each word.We are now testing an improved interface whereannotators add new words to the wordnet directly,and these then become available for tagging.
As aquality check, the new entries are reviewed by anexpert at the end of each day, who has the optionof amending the entry (and possibly re-tagging).We are currently tagging the remaining textsshown in Table 1, with a preliminary releasescheduled for September 2013.
For this we arealso investigating ways of improving the auto-matic cross-lingual annotation: using word levelalignments; using global translation models andby relaxing the mapping criteria (in particularallowing linking across parts of speech throughderivational links).
When we have finished, wewill also link the Japanese to the Chinese, usingEnglish as a pivot.
Finally, we will go through thenon-aligned concepts, and analyze why they can-not be aligned.In future work we intend to also add struc-tural semantic annotation to cover issues such asquantification.
Currently we are experimentingwith Dependency Minimal Recursion Semantics(DMRS: Copestake et al 2005; Copestake, 2009)and looking at ways to also constrain these cross-linguistically (Frermann and Bond, 2012).An interesting further extension would be tolook at a level of discourse marking.
This wouldbe motivated by those translations which cannotbe linked at a lower level.
In this way we wouldbecome closer to the Groningen Meaning Bank,which annotates POS, senses, NE, thematic roles,syntax, semantics and discourse (Basile et al2012).7 ConclusionsThis paper presents preliminary results from anongoing project to construct large-scale sense-tagged parallel corpora.
Four languages are cho-sen for the corpora: English, Chinese, Japanese,and Indonesia.
The annotation scheme is dividedinto two phrases: monolingual sense annotationand multilingual concept alignment.
A pilot studywas carried out in Chinese, English and Japanesefor the short story The Adventure of the Danc-ing Men.
The results show that in the English-Japanese and English-Chinese corpora, over halfof the concepts have the same synsets and thuscan be easily translated.
However, 42.85% and34.74% of the concepts in the two corpora can-not be directly linked, which suggests it is hard formachine translation.
All annotated corpora will bemade freely available through the NTU-MC, in ad-dition, the changes made to the wordnets will bereleased through the individual wordnet projects.AcknowledgmentsThis research was supported in part by the MOETier 1 grant Shifted in Translation ?
An EmpiricalStudy of Meaning Change across Languages.156ReferencesValerio Basile, Johan Bos, Kilian Evang, andNoortje Venhuizen.
2012.
Developing a largesemantically annotated corpus.
In Proceedingsof the Eighth International Conference on Lan-guage Resources and Evaluation (LREC 2012),pages 3196?3200.
Istanbul, Turkey.Luisa Bentivogli, Pamela Forner, and EmanuelePianta.
2004.
Evaluating cross-language an-notation transfer in the MultiSemCor corpus.In 20th International Conference on Computa-tional Linguistics: COLING-2004, pages 364?370.
Geneva.Francis Bond, Timothy Baldwin, RichardFothergill, and Kiyotaka Uchimoto.
2012.Japanese SemCor: A sense-tagged corpus ofJapanese.
In Proceedings of the 6th GlobalWordNet Conference (GWC 2012), pages56?63.
Matsue.Francis Bond and Ryan Foster.
2013.
Linking andextending an open multilingual wordnet.
In 51stAnnual Meeting of the Association for Compu-tational Linguistics: ACL-2013.
Sofia.Francis Bond, Sanae Fujita, and Takaaki Tanaka.2006.
The Hinoki syntactic and semantictreebank of Japanese.
Language Resources andEvaluation, 40(3?4):253?261.
URL http://dx.doi.org/10.1007/s10579-007-9036-6,(Special issue on Asian language technology;re-issued as DOI s10579-008-9062-z due toSpringer losing the Japanese text).Francis Bond, Sanae Fujita, and Takaaki Tanaka.2008.
The Hinoki syntactic and semantictreebank of Japanese.
Language Resources andEvaluation, 42(2):243?251.
URL http://dx.doi.org/10.1007/s10579-008-9062-z,(Re-issue of DOI 10.1007/s10579-007-9036-6as Springer lost the Japanese text).Francis Bond and Kyonghee Paik.
2012.
A surveyof wordnets and their licenses.
In Proceedingsof the 6th Global WordNet Conference (GWC2012).
Matsue.
64?71.Arthur Conan Doyle.
1905.
The Return of Sher-lock Homes.
George Newnes, London.
ProjectGutenberg www.gutenberg.org/files/108/108-h/108-h.htm.Ann Copestake.
2009.
Slacker semantics: Whysuperficiality, dependency and avoidance ofcommitment can be the right way to go.
InProceedings of the 12th Conference of the Eu-ropean Chapter of the ACL (EACL 2009), pages1?9.
Athens.Ann Copestake, Dan Flickinger, Carl Pollard, andIvan A.
Sag.
2005.
Minimal Recursion Seman-tics.
An introduction.
Research on Languageand Computation, 3(4):281?332.Oliver ?Culo, Silvia Hansen-Schirra, Stella Neu-mann, and Mihaela Vela.
2008.
Empiricalstudies on language contrast using the English-German comparable and parallel CroCo corpus.In Proceedings of Building and Using Com-parable Corpora, LREC 2008 Workshop, Mar-rakesh, Morocco, volume 31, pages 47?51.Lea Cyrus.
2006.
Building a resource for studyingtranslation shifts.
In Proceedings of The Sec-ond International Conference on Language Re-sources and Evaluation (LREC-2006).Christine Fellbaum, editor.
1998.
WordNet: AnElectronic Lexical Database.
MIT Press.Lea Frermann and Francis Bond.
2012.
Cross-lingual parse disambiguation based on seman-tic correspondence.
In 50th Annual Meeting ofthe Association for Computational Linguistics:ACL-2012, pages 125?129.
Jeju, Korea.Hitoshi Isahara, Francis Bond, Kiyotaka Uchi-moto, Masao Utiyama, and Kyoko Kanzaki.2008.
Development of the Japanese WordNet.In Sixth International conference on LanguageResources and Evaluation (LREC 2008).
Mar-rakech.Kaname Kasahara, Hiroshi Sato, Francis Bond,Takaaki Tanaka, Sanae Fujita, Tomoko Kana-sugi, and Shigeaki Amano.
2004.
Construc-tion of a Japanese semantic lexicon: Lexeed.In IPSG SIG: 2004-NLC-159, pages 75?82.Tokyo.
(in Japanese).Philipp Koehn.
2005.
Europarl: A parallel corpusfor statistical machine translation.
In MT Sum-mit X.Sadao Kurohashi and Makoto Nagao.
2003.
Build-ing a Japanese parsed corpus ?
while improv-ing the parsing system.
In Anne Abeill?, edi-tor, Treebanks: Building and Using Parsed Cor-pora, chapter 14, pages 249?260.
Kluwer Aca-demic Publishers.Shari Landes, Claudia Leacock, and ChristianeFellbaum.
1998.
Building semantic concor-157dances.
In Fellbaum (1998), chapter 8, pages199?216.Mingqin Li, Juanzi Li, Zhendong Dong, Zuoy-ing Wang, and Dajin Lu.
2003.
Building alarge Chinese corpus annotated with seman-tic dependency.
In Proceedings of the sec-ond SIGHAN workshop on Chinese languageprocessing-Volume 17, pages 84?91.
Associa-tion for Computational Linguistics.George Miller.
1998.
Foreword.
In Fellbaum(1998), pages xv?xxii.Nurril Hirfana Mohamed Noor, Suerya Sapuan,and Francis Bond.
2011.
Creating the openWordnet Bahasa.
In Proceedings of the 25th Pa-cific Asia Conference on Language, Informationand Computation (PACLIC 25), pages 258?267.Singapore.Hwee Tou Ng and Hian Beng Lee.
1996.
Inte-grating multiple knowledge sources to disam-biguate word sense: An exemplar-based ap-proach.
In Proceedings of the 34th annual meet-ing on Association for Computational Linguis-tics, pages 40?47.Lars Nygaard and J?rg Tiedemann.
2003.
OPUS?
an open source parallel corpus.
In Proceed-ings of the 13th Nordic Conference on Compu-tational Linguistics.Sebastian Pad?
and Katrin Erk.
2010.Translation shifts and frame-semanticmismatches: A corpus analysis.
Ms:http://www.nlpado.de/~sebastian/pub/papers/ijl10_pado_preprint.pdf.Eric S. Raymond.
1999.
The Cathedral & theBazaar.
O?Reilly.Singapore Tourist Board.
2012.
Your Singapore.Online: www.yoursingapore.om.
[Accessed2012].Liling Tan and Francis Bond.
2012.
Building andannotating the linguistically diverse NTU-MC(NTU-multilingual corpus).
International Jour-nal of Asian Language Processing, 22(4):161?174.J?rg Tiedemann.
2009.
News from OPUS ?a collection of multilingual parallel corporawith tools and interfaces.
In N. Nicolov,K.
Bontcheva, G. Angelova, and R. Mitkov,editors, Recent Advances in Natural LanguageProcessing, volume 5, pages 237?248.
JohnBenjamins, Amsterdam/Philadelphia.J?rg Tiedemann.
2012.
Parallel data, tools andinterfaces in OPUS.
In Proceedings of theEight International Conference on LanguageResources and Evaluation (LREC?12), pages2214?2218.J?rg Tiedemann and Lars Nygaard.
2004.
TheOPUS corpus ?
parallel and free.
In In Pro-ceeding of the 4th International Conference onLanguage Resources and Evaluation (LREC-4).Martin Volk, Anne G?hring, Torsten Marek, andYvonne Samuelsson.
2010.
SMULTRON (ver-sion 3.0) ?
The Stockholm MULtilingual par-allel TReebank.
http://www.l.uzh.h/researh/paralleltreebanks_en.html.Gan Kok Wee and Tham Wai Mun.
1999.
Generalknowledge annotation based on how-net.
Com-putational Linguistics and Chinese LanguageProcessing, 4(2):39?86.Yunfang Wu, Peng Jin, Yangsen Zhang, and Shi-wen Yu.
2006.
A chinese corpus with wordsense annotation.
In Computer Processing ofOriental Languages.
Beyond the Orient: TheResearch Challenges Ahead, pages 414?421.Springer.Renjie Xu, Zhiqiang Gao, Yuzhong Qu, andZhisheng Huang.
2008.
An integrated approachfor automatic construction of bilingual Chinese-English WordNet.
In 3rd Asian Semantic WebConference (ASWC 2008), pages 302?341.158
