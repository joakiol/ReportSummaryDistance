Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 233?236,Columbus, Ohio, USA, June 2008. c?2008 Association for Computational LinguisticsActive Learning with ConfidenceMark Dredze and Koby CrammerDepartment of Computer and Information ScienceUniversity of PennsylvaniaPhiladelphia, PA 19104{mdredze,crammer}@cis.upenn.eduAbstractActive learning is a machine learning ap-proach to achieving high-accuracy with asmall amount of labels by letting the learn-ing algorithm choose instances to be labeled.Most of previous approaches based on dis-criminative learning use the margin for choos-ing instances.
We present a method for in-corporating confidence into the margin by us-ing a newly introduced online learning algo-rithm and show empirically that confidenceimproves active learning.1 IntroductionSuccessful applications of supervised machinelearning to natural language rely on quality labeledtraining data, but annotation can be costly, slow anddifficult.
One popular solution is Active Learning,which maximizes learning accuracy while minimiz-ing labeling efforts.
In active learning, the learningalgorithm itself selects unlabeled examples for anno-tation.
A variety of techniques have been proposedfor selecting examples that maximize system perfor-mance as compared to selecting instances randomly.Two learning methodologies dominate NLP ap-plications: probabilistic methods ?
naive Bayes,logistic regression ?
and margin methods ?
sup-port vector machines and passive-aggressive.
Activelearning for probabilistic methods often uses uncer-tainty sampling: label the example with the lowestprobability prediction (the most ?uncertain?)
(Lewisand Gale, 1994).
The equivalent technique for mar-gin learning associates the margin with predictioncertainty: label the example with the lowest margin(Tong and Koller, 2001).
Common intuition equateslarge margins with high prediction confidence.However, confidence and margin are two distinctproperties.
For example, an instance may receivea large margin based on a single feature which hasbeen updated only a small number of times.
Anotherexample may receive a small margin, but its featureshave been learned from a large number of examples.While the first example has a larger margin it haslow confidence compared to the second.
Both themargin value and confidence should be consideredin choosing which example to label.We present active learning with confidence us-ing a recently introduced online learning algo-rithm called Confidence-Weighted linear classifica-tion.
The classifier assigns labels according to aGaussian distribution over margin values instead ofa single value, which arises from parameter confi-dence (variance).
The variance of this distributionrepresents the confidence in the mean (margin).
Wethen employ this distribution for a new active learn-ing criteria, which in turn could improve other mar-gin based active learning techniques.
Additionally,we favor the use of an online method since onlinemethods have achieved good NLP performance andare fast to train ?
an important property for inter-active learning.
Experimental validation on a num-ber of datasets shows that active learning with con-fidence can improve standard methods.2 Confidence-Weighted Linear ClassifiersCommon online learning algorithms, popular inmany NLP tasks, are not designed to deal withthe particularities of natural language data.
Fea-233ture representations have very high dimension andmost features are observed on a small fraction of in-stances.
Confidence-weighted (CW) linear classifi-cation (Dredze et al, 2008), a new online algorithm,maintains a probabilistic measure of parameter con-fidence leading to a measure of prediction confi-dence, potentially useful for active learning.
Wesummarize CW learning to familiarize the reader.Parameter confidence is formalized with a distri-bution over weight vectors, specifically a Gaussiandistribution with mean ?
?
RN and diagonal co-variance ?
?
RN?N .
The values ?j and ?j,j repre-sent knowledge of and confidence in the parameterfor feature j.
The smaller ?j,j , the more confidencewe have in the mean parameter value ?j .A model predicts the label with the highest prob-ability, maxy?
{?1} Prw?N (?,?)
[y(w ?
x) ?
0] .The Gaussian distribution over parameter vectors winduces a univariate Gaussian distribution over theunsigned-margin M = w ?
x parameterized by ?,?
and the instance x: M ?
N (M,V ), where themean is M = ?
?
x and the variance V = x>?x.CW is an online algorithm inspired by the PassiveAggressive (PA) update (Crammer et al, 2006) ?which ensures a positive margin while minimizingparameter change.
CW replaces the Euclidean dis-tance used in the PA update with the KL divergenceover Gaussian distributions.
It also replaces the min-imal margin constraint with a minimal probabilityconstraint: with some given probability ?
?
(0.5, 1]a drawn classifier will assign the correct label.
Thisstrategy yields the following objective solved oneach round of learning:(?i+1,?i+1) = min DKL (N (?,?)
?N (?i,?i))s.t.
Pr [yi (?
?
xi) ?
0] ?
?
,where (?i,?i) are the parameters on round i and(?i+1,?i+1)are the new parameters after update.The constraint ensures that the resulting parameterswill correctly classify xi with probability at least ?.For convenience we write ?
= ?
?1 (?
), where ?
isthe cumulative function of the normal distribution.The optimization problem above is not convex, buta closed form approximation of its solution has thefollowing additive form: ?i+1 = ?i+?iyi?ixi and?
?1i+1 = ?
?1i + 2?i?xix>i for,?i=?(1+2?Mi)+?(1+2?Mi)2?8?
(Mi?
?Vi)4?Vi.Each update changes the feature weights ?, and in-creases confidence (variance ?
always decreases).3 Active Learning with ConfidenceWe consider pool based active learning.
An activelearning algorithm is given a pool of unlabeled in-stances U = {xi}ni=1, a learning algorithm A and aset of labeled examples initially set to be L = ?
.
Oneach round the active learner uses its selection crite-ria to return a single instance xi to be labeled by anannotator with yi ?
{?1,+1} (for binary classifica-tion).
The instance and label are added to the labeledset L ?
L ?
{(xi, yi)} and passed to the learningalgorithm A, which in turn generates a new model.At the end of labeling the algorithm returns a classi-fier trained on the final labeled set.
Effective activelearning minimizes prediction error and the numberof labeled examples.Most active learners for margin based algorithmsrely on the magnitude of the margin.
Tong andKoller (2001) motivate this approach by consider-ing the half-space representation of the hypothesisspace for learning.
They suggest three margin basedactive learning methods: Simple margin, MaxMinmargin, and Ratio margin.
In Simple margin, the al-gorithm predicts an unsigned margin M for each in-stance in U and returns for labeling the instance withthe smallest margin.
The intuition is that instancesfor which the classifier is uncertain (small margin)provide the most information for learning.
Activelearning based on PA algorithms runs in a similarfashion but full SVM retraining on every round isreplaced with a single PA update using the new la-beled example, greatly increasing learning speed.Maintaining a distribution over prediction func-tions makes the CW algorithm attractive for ac-tive learning.
Instead of using a geometricalquantity (?margin?
), it use a probabilistic quan-tity and picks the example whose label is pre-dicted with the lowest probability.
Formally,the margin criteria, x = argminz?U (w ?
z),is replaced with a probabilistic criteria x =argminz?U |(Prw?N (?i,?i) [sign(w ?
z) = 1])?
12 | .234The selection criteria naturally captures the notionthat we should label the example with the highestuncertainty.
Interestingly, we can show (omitted dueto lack of space) that the probabilistic criteria can betranslated into a corrected geometrical criteria.
Inpractice, we can compute this normalized margin asM?
= M/?V .
We call this selection criteria ActiveConfident Learning (ACL).4 EvaluationTo evaluate our active learning methods we useda similar experimental setup to Tong and Koller(2001).
Each active learning algorithm was giventwo labeled examples, one from each class, for ini-tial training of a classifier, and remaining data as un-labeled examples.
On each round the algorithm se-lected a single instance for which it was then giventhe correct label.
The algorithm updated the onlineclassifier and evaluated it on held out test data tomeasure learning progress.We selected four binary NLP datasets for evalu-ation: 20 Newsgroups1 and Reuters (Lewis et al,2004) (used by Tong and Koller) and sentiment clas-sification (Blitzer et al, 2007) and spam (Bickel,2006).
For each dataset we extracted binary uni-gram features and sentiment was prepared accord-ing to Blitzer et al (2007).
From 20 Newsgroupswe created 3 binary decision tasks to differentiatebetween two similar labels from computers, sci-ence and talk.
We created 3 similar problems fromReuters from insurance, business services and re-tail distribution.
Sentiment used 4 Amazon domains(book, dvd, electronics, kitchen).
Spam used thethree users from task A data.
Each problem had2000 instances except for 20 Newsgroups, whichused between 1850 and 1971 instances.
This created13 classification problems across four tasks.Each active learning algorithm was evaluated us-ing a PA (with slack variable c = 1) or CW classifier(?
= 1) using 10-fold cross validation.
We eval-uated several methods in the Simple margin frame-work: PA Margin and CW Margin, which select ex-amples with the smallest margin, and ACL.
As abaseline we included selecting a random instance.We also evaluated CW and a PA classifier trained onall training instances.
Each method was evaluated by1http://people.csail.mit.edu/jrennie/20Newsgroups/labeling up to 500 labels, about 25% of the trainingdata.
The 10 runs on each dataset for each problemappear in the left and middle panel of Fig.
1, whichshow the test accuracy after each round of activelearning.
Horizontal lines indicate CW (solid) andPA (dashed) training on all instances.
Legend num-bers are accuracy after 500 labels.
The left panel av-erages results over 20 Newsgroups, and the middlepanel averages results over all 13 datasets.To achieve 80% of the accuracy of training on alldata, a realistic goal for less than 100 labels, PAMargin required 93% the number of labels of PARandom, while CW Margin needed only 73% ofthe labels of CW Random.
By using fewer labelscompared to random selection baselines, CW Mar-gin learns faster in the active learning setting as com-pared with PA.
Furthermore, adding confidence re-duced labeling cost compared to margin alone.
ACLimproved over CW Margin on every task and afteralmost every round; it required 63% of the labels ofCW Random to reach the 80% mark.We computed the fraction of labels CW Marginand ACL required (compared to CW Random) toachieve the 80% accuracy mark of training with alldata.
The results are summarized in the right panelof Fig.
1, where we plot one point per dataset.
Pointsabove the diagonal-line demonstrate the superiorityof ACL over CW Margin.
ACL required fewer la-bels than CW margin twice as often as the oppositeoccurred (8 vs 4).
Note that CW Margin used morelabels than CW Random in three cases, while ACLonly once, and this one time only about a dozen la-bels were needed.
To conclude, not only does CWMargin outperforms PA Margin for active-learning,CW maintains additional valuable information (con-fidence), which further improves performance.5 Related WorkActive learning has been widely used for NLP taskssuch as part of speech tagging (Ringger et al, 2007),parsing (Tang et al, 2002) and word sense disam-biguation (Chan and Ng, 2007).
Many methods relyon entropy-based scores such as uncertainty sam-pling (Lewis and Gale, 1994).
Others use marginbased methods, such as Kim et al (2006), who com-bined margin scores with corpus diversity, and Sas-sano (2002), who considered SVM active learning235100 150 200 250 300 350 400 450 500Labels0.650.700.750.800.850.900.95TestAccuracy20 NewsgroupsPA Random (82.53)CW Random (92.92)PA Margin (88.06)CW Margin (95.39)ACL (95.51) 100 150 200 250 300 350 400 450 500Labels0.750.800.850.90TestAccuracyAllPA Random (81.30)CW Random (86.67)PA Margin (83.99)CW Margin (88.61)ACL (88.79) 0.2 0.4 0.6 0.8 1.0 1.2 1.4ACL Labels0.20.40.60.81.01.21.4CW MarginLabelsReuters20 NewsgroupsSentimentSpamFigure 1: Results averaged over 20 Newsgroups (left) and all datasets (center) showing test accuracy over activelearning rounds.
The right panel shows the amount of labels needed by CW Margin and ACL to achieve 80% of theaccuracy of training on all data - each points refers to a different dataset.for Japanese word segmentation.
Our confidencebased approach can be used to improve these tasks.Furthermore, margin methods can outperform prob-abilistic methods; CW beats maximum entropy onmany NLP tasks (Dredze et al, 2008).A theoretical analysis of margin based methodsselected labels that maximize the reduction of theversion space, the hypothesis set consistent with thetraining data (Tong and Koller, 2001).
Another ap-proach selects instances that minimize the future er-ror in probabilistic algorithms (Roy and McCallum,2001).
Since we consider an online learning algo-rithm our techniques can be easily extended to on-line active learning (Cesa-Bianchi et al, 2005; Das-gupta et al, 2005; Sculley, 2007).6 ConclusionWe have presented techniques for incorporating con-fidence into the margin for active learning and haveshown that CW selects better examples than PA, apopular online algorithm.
This approach creates op-portunities for new active learning frameworks thatdepend on margin confidence.ReferencesS.
Bickel.
2006.
Ecml-pkdd discovery challengeoverview.
In The Discovery Challenge Workshop.J.
Blitzer, M. Dredze, and F. Pereira.
2007.
Biographies,bollywood, boom-boxes and blenders: Domain adap-tation for sentiment classification.
In ACL.Nicolo` Cesa-Bianchi, Ga?bor Lugosi, and Gilles Stolt.2005.
Minimizing regret with label efficient predic-tion.
IEEE Tran.
on Inf.
Theory, 51(6), June.Y.
S. Chan and H. T. Ng.
2007.
Domain adaptation withactive learning for word sense disambiguation.
In As-sociation for Computational Linguistics (ACL).K.
Crammer, O. Dekel, J. Keshet, S. Shalev-Shwartz,and Y.
Singer.
2006.
Online passive-aggressive al-gorithms.
JMLR, 7:551?585.S.
Dasgupta, A.T. Kalai, and C. Monteleoni.
2005.
Anal-ysis of perceptron-based active learning.
In COLT.Mark Dredze, Koby Crammer, and Fernando Pereira.2008.
Confidence-weighted linear classification.
InICML.S.
Kim, Yu S., K. Kim, J-W Cha, and G.G.
Lee.
2006.Mmr-based active machine learning for bio named en-tity recognition.
In NAACL/HLT.D.
D. Lewis and W. A. Gale.
1994.
A sequential algo-rithm for training text classifiers.
In SIGIR.D.
D. Lewis, Y. Yand, T. Rose, and F. Li.
2004.
Rcv1:A new benchmark collection for text categorization re-search.
JMLR, 5:361?397.E.
Ringger, P. McClanahan, R. Haertel, G. Busby,M.
Carmen, J. Carroll, K. Seppi, and D. Lonsdale.2007.
Active learning for part-of-speech tagging: Ac-celerating corpus annotation.
In ACL Linguistic Anno-tation Workshop.N.
Roy and A. McCallum.
2001.
Toward optimal activelearning through sampling estimation of error reduc-tion.
In ICML.Manabu Sassano.
2002.
An empirical study of activelearning with support vector machines for japaneseword segmentation.
In ACL.D.
Sculley.
2007.
Online active learning methods for fastlabel-efficient spam filtering.
In CEAS.M.
Tang, X. Luo, and S. Roukos.
2002.
Active learningfor statistical natural language parsing.
In ACL.S.
Tong and D. Koller.
2001.
Supprt vector machineactive learning with applications to text classification.JMLR.236
