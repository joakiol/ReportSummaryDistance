DICTIONARIES, DICTIONARY GRAMMARS AND DICTIONARY ENTRY PARSINGMary S. NeffIBM T. J. Watson Research Center, P. O.
Box 704, Yorktown Heights, New York 10598Branimir K. BoguraevIBM T. J. Watson Research Center, P. O.
Box 704, Yorktown Heights, New York 10598;Computer Laboratory, University of Cambridge, New Museums Site, Cambridge CB2 3QGComputerist: ...
But, great Scott, what about structure?
You can't just bang that lot into a machinewithout structure.
Half a gigabyte of sequential fi e ...Lexicographer: Oh, we know all about structure.
Take this entry for example.
You see here italicsas the typical ambiguous tructural element marker, being apparently used as an undefinedphrase-entry lemrna, but in fact being the subordinate ntry headword address preceding thesmall-cap cross-reference h adword address which is nested within the gloss to a defined phraseentry, itself nested within a subordinate (bold lower-case letter) sense section in the second branchof a forked multiple part of speech main entry.
Now that's typical of the kind of structural re-lationship that must be made crystal-clear in the eventual database.from "Taking the Words out of His Mouth" --Edmund Weiner on computerising the Oxford English Dictionary(The Guardian, London, March, 1985)ABSTRACTWe identify two complementary p.ro.cesses in.
theconversion of machine-readable dmUonanes intolexical databases: recovery of the dictionarystructure from the typographical markings whichpersist on the dictionary distribution tapes andembody the publishers' notational conventions;followed by making explicit all of the codified andellided information packed into individual entries.We discuss notational conventions and tape for-mats, outline structural properties of dictionaries,observe a range of representational phenomenaparticularly relevant to dictionary parsing, andderive a set of minimal requirements for a dic-tionary grammar formalism.
We present a gen-eral purpose dictionary entry parser which uses aformal notation designed to describe the structureof entries and performs a mapping from the flatcharacter stream on the tape to a highly struc-tured and fully instantiated representation f thedictionary.
We demonstrate the power of theformalism by drawing examples from a range ofdictionary sources which have been processedandconverted into lexical databases.I.
INI"RODUCTIONMachine-readable dictionaries (MRD's) axe typi,tally ayailable in the form of publisherstypesetting tapes, and consequently are repres-ented by a fiat character stream where lexical dataproper is heavily interspersed with special (con-trol) characters.
These map to the font changesand other notational conventions used in theprinted form of the dictionary and designed topack, and present in a codified compact visualformat, as much lexical data as possible.To make maximal use of MRD's, it is necessaryto make their data, as well as structure, fully ex-~ licit, in a data base format that lends itself to exible querying.
However, since none of thelexical data base (LDB) creation efforts to datefully addresses both of these issues, they fail tooffer a general framework for processing the widerange of dictionary resources available inmachine-readable form.
As one extreme, theconversion of an MRD into an LDB may becarried out by a 'one-off" program -- such as, forexample, used for the Longman Dictionary ofContemporary English (LDOCE) and describedin Bogtbr_ aev and Briscoe, 1989.
While the re-suiting LDB is quite explicit and complete withrespect o the data in the source, all knowledgeof the dictionary structure is embodied in theconversion program.
On the other hand, moremodular architectures consisting of a parser anda _grammar -- best exemplified by Kazman's(1986) analysis of the Oxford English Dictionary(OED) -- do not deliver the structurally rich andexplicit LDB ideally required for easy and un-constrained access to the source data.The majority of computational lexicographyprojects, in fact, fall in the first of the categoriesabove, in that they typically concentrate on theconversion of a single dictlonarv into an LDB:examples here include the work l~y e.g.
Ahlswedeet al, 1986, on The Webster's Seventh NewCollegiate Dictionary; Fox et a/., 1988, on TheCollins English Dictionary; Calzolari and Picchi,1988, on H Nuovo Dizionario Italiano Garzanti;van der Steen, 1982, and Nakamura, 1988, onLDOCE.
Even work based on multiple diction-aries (e.g.
in bilingual context: see Calzolari andPicchi, 1986) appear to have used specializedprograms for eac~ dictionary source.
In addition,not an uncommon property of the LDB's citedabove is their incompleteness with respect o theoriginal source: there is a tendency_ to extract, ina pre-processing phase, only some fragments (e.g.91part of speech information or definition fields)while ignoring others (e.g.
etymology, pronun-ciation or usage notes).We have built a Dictionary Entry Parser (DEP)together with grammars for several different dic-tionaries.
Our goal has been to create a generalmechanism for converting to a common LDBformat a wide range of MRD's demonstrating awide range of phenomena.
In contrast o theOED project, where the data in the dictionary isonly tagged to indicate its structural character-istics, we identify ,two processes which are crucialfor the 'unfolding, or making explicit, the struc-ture of an MRD: identification of the structuralmarkers, followed by their interpretation i con-text resulting in detailed parse trees for individualentries.
Furthermore, unlike the tagging of theOED, carried out in several passes over the dataand using different grammars (in order to copewith the highly complex, idiosyncratic and am-biguous nature of dictionary entries), we employa parsing engine exploiting unification and back-tracking, and using a single grammar consistingof three different sets of rules.
The advantagesof handling the structural complexities of MRDsources and deriving corresponding LDB s in oneoperation become clear below.While DEP has been described in general termsbefore (Byrd et al, 1987; Neff eta/ .
,  1988), thispaper draws on our experience in parsing theCollins German-English / Collins English-German(CGE/CEG) and LDOCE dictionaries, whichrepresent wo very different ypes of machine-readable sources vis-~t-vis format of thetypesetting tapes and notational conventions ex-ploited by the lexicographers.
We examine moreclosely some of the phenomena encountered inthese dictionaries, trace their implications forMRD-to-LDB parsing, show how they motivatethe design of the DEP grammar formalism, anddiscuss treatment of typical entry configurations.2.
STRUCTURAL PROPERTIES OF MRD'SThe structure of dictionary entries is mostly im-plicit in the font codes and other special charac-ters controlling the layout of an entry on theprinted page; furthermore, data is typically com-pacted to save space in print, and it is commonfor different fields within an entry to employ rad-ically different compaction schemes andabbreviatory devices.
For example, the notationT5a, b,3 stands for the LDOCE grammar codesT5a;T5b;T3 (Boguraev and Briscoe, 1989, pres-ent a detailed escription of the grammar codingsystem in this dictionary), and many adverbs arestored as run-ons of the adjectives, using theabbreviatory convention ~ly (the same conven-tion appliesto ce~a~o types of atfixation in gen-eral: er, less, hess, etc.).
In CGE, Germancompounds with a common first element appeargrouped together under it:Kinder-: .~.ehor m children's choir; --doe nt children's \[village; -ehe  f child marriage.
IDictionaries often factor out common substringsin data fields as in the following LDOCE andCEG entries:ia.cu.bLtor ...a machine for a keeping eggs warm untilthey HATCH b keeping alive babies that are too smallto live and breathe inordinary airFigure I. Def'mition-initial common fragmentBankrott m -(e)6, -e bankruptcy; (fig) breakdown,collapse; (moralisch) bankruptcy.
~ machen tobecome or go bankrupt; den - anmelden or ansagen orerld~ren todeclare oneself bankrupt.Figure 2.
Definition-final common fragmentFurthermore, a variety of conventions exists formaking text fragments perfo.,rm more than onefunction (the capitalization o f '  HATCH above,for instance, signals a close conceptual link withthe word being defined).
Data of this sort is notvery useful to an LDB user without explicit ex-pansion and recovery of compacted headwordsand fragments of entries.
Parsing a dictionary tocreate an LDB that can be easily queried by auser or a program therefore implies not only tag-g~ag the data in the entry, but also recoveringellided information, both in form and content.There are two broad types of machine-readablesource, each requiring a different strategy for re-covery of implicit structure and content of dic-tionary entries.
On the one hand tapes mayconsist of a character stream with no explicitstructure markings (as OED and the Collins bi-linguals exemplify); all of their structure is iml~li.edin the font changes and the overall syntax ot theentry.
On the other hand, sources may employmixed r~presentation, i corporating both globalrecord delhniters and local structure ncoded infont change codes and/or special character se-quences (LDOCE and Webster s Seventh).Ideally, all MRD's should be mapped onto LDBstructures of the same type, accessible with a sin-~le query language that preserves the user s intui-tion about tile structure of lexical data (Neff eta/., 1988; Tompa, 1986), Dictionary entries canbe naturally represented as shallov~ hierarchieswith a variable number of instances of certainitems at each level, e.g.
multiple homographswithin an entry or multiple senses within ahomograph.
The usual inlieritance mechanismsassociated with a hierarchical orgardsation of datanot only ensure compactness of representation,but also fit lexical intuitions.
The figures overleafshow sample entries from CGE ,and LDOCE andtheir LDBforms with explicitly unfolded struc-ture.Within the taxonomy of normal forms .
(NF) de-freed by relational data base theo~, dictionaryentries are 'unnormalized relations in which at-tributes can contain other relations, rather thansimple scalar values; LDB's, therefore, cannot becorrectly viewed as relational data bases (see Neffet al, 1988).
Other kinds of hierarchically struc-tured data similarly fall outside of the relational92.
't~le \[...\] n (a) Titel m (also Sport); (of chapter)Uberschrift f ;  (Film) Untertitel m; (form of address)Am'ede f. what -- do yon give a bishop?
wie redet orspricht man ?inen Bischof an?
(b) (Jur) (right)(Rechts)anspruch (to auf + acc), Titel (spec) m;(document) Eigentumsurkunde f.entry+-hc:l~: titlet?
-$uper t 'K~.
.
.+-pos : n~-s lns?
-seflsflclm: a+-  t ran  ._qroupl +-t ranI ?~rd:  TitelI +-gendmr: mI +Sin :  also SportI?
- t ran_g  roupI : -~_r lo te :  of chapterII ?
-word :  (lberschriftI ?
-gender :  fI+-tran_.groupI +-domain:  FilmI ?-t r imI +-woPd: UntertitelI + -~r :  mI?-tran~r~3upI +-usaglt_note:  form of addressI ?-?ranI +- 'NON:  Ant?de I +-gender :  f+-co l locat?-source :  what -- ?o you give a bishop?
* -~rget?-~ease :  wie redet /or/ sprichtman ?inert Bischof an?
?-$11~1?-$ensl lum: b+-domain: Jur?-?r-an_group?-usag l_not i :  rightt - t ra in?
-Nord:  Rechtsanspruch? '
-Nord :  Anspruch+-comlmmmtI ?
-~r4)co~p: toI +-~Poomp:  auf + acc?-gef~Br :  me -?ran+-word:  Titel+-sty le :  spec?-~nd l r :  m?-?ran group?-usage_note :  document?-?ran+-Nord:  Eigentumsurkunde?-gender :  fFigure 3.
LDB for a CEG entryNF mould; indeed recently there have been ef-forts to design a generalized ata model whichtreats fiat relations, lists, and hierarchical struc-Ures uniformly (Dadam et al, 1986).
Our LDBrmat and Lexical Query l_anguage (LQL) sup-port the hierarchical model for dictionary data;the output of the .parser, similar to the examplesin Figure 3 and Figure 4, is compacted, encoded,and loaded into an LDB.nei.~,.ce/'nju:s~ns II 'nu:-: n I a person or an?real thatannoys or causes trouble, PEST: Don't make anuisance of yourself."
sit down and be quiet!
2 an actionor state of affairs which causes trouble, offence, orunpleasantness: What a nuisance!
I've forgotten myticket 3 Commit no nuisance (as a notice in a publicplace) Do not use this place as a a lavatory b aT IP  ~ent ry?
-I'wJb#: nuisanceI+-SUlmPhom?-pr in t  foist1: nui.sanceI +-primawI ?-peon s t r i r~ j :  "nju:sFns II "nu:-+-syncat :  nI+-sensa_def+-sense_no: 1?
-darnI ?
- imp l i c i t _x r fI I +-to: pestI ?
-de f  s t r i l~ :  a person or animal that| annoys or causes trouble:I pest?-example?-eX s t r i l~ :  Don't make a nuisance ofyourself: sit down an?be quiet/?
- sense_def?
- s lmse .no: 2+.-defnI ?
-de f_s t r ing :  an action or state of affairs\[ which causes trouble, offence.I or unpleasantness+-example?
-ex_s t r i r lg :  What a nuisanceli've forgotten my ticket+-sense_def?-sense no: 3?-de~ -?-h?~ j~rase :  Commit no nuisance+-qua i l ?
le t :  as a notice in a public place+-sub de fnI aI +-def_s t r i l~ :  Do not use this placeI as a lavatory?-~.~b_dlfn+-seq_no: b?--defn* - i .~ l i?
i t _x r fI * - to :  tipI ?-h?~ no :  4?-dQf s\]ril~J~: Do not use this placeas a tipFigure 4.
LDB for an LDOCE entry3.
DEP GRAMMAR FORMALISMThe choice of the hierarchical model for the rep-resentation of the LDB entries (and thus theoutput of DEP) has consequences for the parsingmechanism.
For us, parsing involves determiningthe structure of all the data, retrieving implicitinformation to make it explicit, reconstructingellided information, and filling a (recursive) tem-plate, without any data loss.
This contrasts witha strategy that fills slots in predefmed (and finite)sets of records for a relational system, often dis-carding information that does not fit.In order to meet these needs, the formalism fordictionary entry grammars must meet at leastthree criteria, in addition to being simply a nota-tional device capable of describing any particular93dictionary format.
Below we outline the basicrequirements for such a formalism.3.1 Effects of contextThe graham,_ .~ formalism should be capable ofhandling mildly context sensitive' input streams,as structurally identical items may have widelydiffering functions depending on both local andglobal contexts.
For example, parts of speech,field labels, paraphrases o f  cultural items, andmany other dictionary fragments all appear in theCEG in italics, but their context defines theiridentity and, consequently, their interpretation.Thus, in the example entry in Figure 3 above,m, (also Sport), (of chapter), and (spec) acquirethe very different labels of pos, do ,  in,us=g=_not=, and sty1.=.
In addition, to distin-t~ish between domain labels, style labels, dialectels, and usage notes, the rules must be able totest candidate lements against a closed set ofitems.
Situations like this, involving subsidiaryapplication of auxiliary procedures (e.g.
stringmatching, or dictionary lookup required for anexample below), require that the rules be allowedto selectively invoke external functions.The assignment of labels discussed above is basedon what we will refer to in the rest of this paperasglobal context.
In procedural terms, this isdefined as the expectations of a particular gram-mar fragment, reflected in the names of the asso-dated rides, which will be activated on a givenpare through the grammar.
Global context is adynamic notion, best thought of as a 'snapshot'of the state of the parser at any_ point of process-ing an entry.
In contrast, local context is definedby finite-length patterns of input tokens, arid hasthe effect of Identifying typographic ' lues to thestructure of an entry.
Finally, immediate contextreflects v.ery loc~ character patte12as which tendt 9 drive the initial segmentatmn ot the 'raw' tapecharacter stream and its fragmentation i tostructure- and information-carrying tokens.These three notions underlie our approach tostructural analysis of dictionaries andare funda-mental to the grammar formalism design.3.2 Structure manipulationThe formalism should allow operations on the(partial) structures delivered during parsing, andnot as.separate ree transtormations once proc-essing is complete.
This is needed, for instance,in order to handle a variety of scoping phenom-ena (discussed in section 5 below), factor outitems common to more than one fragment withinthe same entry, and duplicate (sub-)trees as com-plete LDB representatmns ~ being fleshed out.Consider the CEG entry for abutment":I abutment \[.,.\] n (Archit) Fltigel- or Wangenmauer f. IHere, as well as in "title" (Figure 3), a copy ofthe gender marker common to both translatmnsneeds to migrate back to the ftrst tram.
In addi-tion, a copy of the common second compoundelement -mauer also needs to migrate (note thate  _   : abutmentI?-superhom, I .
-$ens?-  t Pan_group+- t ranI +- iNord:  F/OgelmauerI *-~nd=r: f?-t ran+.-t,K)rd : Wangenmauer?-gender :  fidentifying this needs a separate noun compoundparser augmented with dictionary lookup).An example of structure duplication is illustratedby our treatment of (implicit) cross-references inLDOCE, where a link between two closely re-lated words is indicated by having one of {hemtypeset in small capitals embedded in, a definitionof the other (e.g.
"PEST' and "TIP' in the deft-nitions of "nuisance" in Figure 4).
The dualpurpose such words serve requires them to appearon at least two different nodes in the final LDBstructure: ?~f_string and implicit_xrf.
In or-der to perform the required transformations, theformalism must provide an explicitdle on partial structures, as they are beingbuilt by the parser, together with operationswhich can mariipulate them -- both in terms ofstructure decomposition a d node migration.In general, the formalism must be able to dealwitli discontinuous constituents, a problem notdissimilar to the problems of discontinuous con-stituents in natural language parsing; however indictionaries like the ones we discuss the phe-nomena seem less regular (if discontinuous con-stituents can be regarded as regular at all).3.3 Graceful failureThe nature of the information contained in dic-tionaxies is such that certain fields within entriesdo not use any conventions or formal systems topresent heir data.
For instance, the "USAGE"notes in LDOCE can be arbitrarily complex andunstructured.
.
fragments, .c?mbining straaght extwith a vanety of notattonal devices (e.g.
fontchanges, item highlighting and notes segmenta-tion) in such a way that no principled structuremay be imposed on them.
Consider, for example,the annotation of "loan":loan 2 v ........ esp.
AmE to give (someone) the use of,lend ........ USAGE It is perfectly good AmE to useloan in the meamng of lend: He loaned me ten dollars.The word is often used m BrE, esp.
in the meaning 'tolend formally for a long period': He loaned h/scollection of pictures to the public GALLERY but manypeople do not like it to be used simply in the meaningof lend in BrE...Notwithstanding its complexity, we would stilllike to be able to process the complete ntry, re-covering as much as we can from the regularlyencoded information and only 'skipping' over itstruly unparseable fragment(s).
Consequently, theformalism and the underlying processing flame-94work should incorporate a suitable mechanismfor explicitly handling such data, systematicallyoccumng in dictionaries.The notion of .graceful failure is, in fact, best re-garded as 'seledive parsing'.
Such a mechanismhas the additional benefit of allowing the incre-mental development of dictionary grammars with(eventually) complete coverage, and arbit .r-~.rydepth of analysis, of the source data: a particulargrammar might choose, for instance, to treat ev-erything but the headword, part of speech, andpronunciation as 'junk', and concentrate onelaborate parsing of the pron.u:n, ciation fields,while still being able to accept all input withouthaving to assign any structure to most of it.4.
OVERVIEW OF DEPDEP uses as input a collection of 'raw'typesetting images of entries from a dictionary0.e.
a typesetting .tape.
with begin-end' bounda-ries of entries explicitly marked) and, by consult-ing an externally supplied .gr-qmmar s.p~."
c forthat particular dictionary, produces explicit struc-tural representations for the individual entries,which are either displayed or loaded into an LDB.The system consists of a rule compiler, a parsingnDg~Be, a dictionary entry template generator, anloader, and various development facilities,all in a PROLOG shell.
User-written PROLOGfunctions and primitives are easily added to thesystem.
The fdrmalism and rule compiler use theModular Logic Grammars of McCo/'d (1987) asa point of d~ure ,  but they have been sub-stantially modified and extended to reflect he re-quirements of parsing dictionary entries.The compiler accepts three different kinds of rulescorresponding to the three phases of dictionaryentry analysis: tokenization, retokenization, andproper.
Below we present informallyghts of the grammar formalism.4.1 TokenizationUnlike in sentence parsing, where tokenization(or lexical analysis) is driven entirely by blanksand punctuation, the DEP grammar writer ex-plicitly defines token delimiters and token substi-tutions.
Tokenixation rules specify a one-to-onemapping from a character substring to a rewritetoken; the mapping is applied whenever thespecified substring is encountered in the originaltypesetting tape character stream, and is onlysensitive to immediate context.
Delimiters areusually font change codes and other special char-acters or symbols; substitutions axe atoms (e.g.i ta l _cor rec t ion ,  f i e ld_m)  or structured termsbe.g.
fmt l  i ta l i c  l, ~!
"1"  I).
Tokenizationreaks the source character stream into a mixtureof tokens and strings; the former embody thenotational conventions employed by the printeddictionary, and are used by tlae parser to assignstructure to an entry; the latter carry the textual(lexical) content of the dictionary.
Some samplerules for the LDOCE machine-readable source,marking the beginning and end of font changes,or making explicit special print symbols, areshown below (to facilitate readability, (*AS) re-presents the hexadecimal symbol x'AS' ) .do l im(  " (~ i ) " ,  font (  i~a l i c  } ).do l ia (  " (UCA)" ,  font (  beg in l  saml l _caps  ) I ) .dol im(I I{~mS) i i f~r~t ( end( smal l _caps  ) ) ).do l im!"
(~)" ,  i ta l  cor rec t ion) .de l i l l (  "Oq lO)" ,  hy l~ in_mark  ).Immediate context, as well as local string rewrite," can be specified by more elaborate tokenizationrules, in which two additional arguments pecifystrings to be 'glued' to the strings on the left andright of the token delimiter, respectively.
ForCEG, for instance, we havedot iml" .
>u4<",  f~t ;~ l ; )>~) .<? '
) .
de l im(  ":>u~<",de l im(  ">uS<", font (  roman ) ).Tokenization opeEates recursively on the stringfragments formed by an active rule; thus, appli-catton of the first two rules above to the stnng,,mo~.
:~a,: ~r~" results in the following tokenl ist: "xxx"  .
lad .
font lbo ld )  , "y~?
".4.2 RetokenizationLonger_-range (but still local) context sensitivity~is irfiplemented via retokenization, the effect otwhich is the 'normalization' of the token list.Retokenization rules conform to a general rewriteformat -- a pattern on the left-hand side definesa context as a sequence of (explicit or variableplace holder) tokens, in which the token listshould be adlusted as indicated by the right-handside -- and can be used to .perform a range ofcleaning up tasks before parsing proper.Streamlining the token list.
Tokens without in-formation- or structure-bearing content; such asassociated with the codes for fialic correction orthin space, are removed:i ta l  cor rec t ion  : ,Seg <:> ?Seg.Superfluous font control characters can be simplydeleted, when they follow or precede certaindata-can'ying tokens which also incorporatetypesetting information (such as a homogra.phsuperscript symbol or a pronunciation markerindicating the be~finning of the scope of a pho-netic font):rk  font !
phonet ic  ) < ?
rk .supl N) < ?
R(Re)adjusting the token list.
New tokens can beintroduced in place of certain token sequences:bra  : font t i ta l i c )  <=> beg in l res t r i c~ ion) .f~ ' t t ( r~m~'t )  : ke t  < ?
~wl ( r~st r i c t i~ 'b ) .Reconstruction of string segments.
Where theinitial (blind) tokenization has produced spuriouslragraentation, string sewnents can be suitablyreconstructed.
For instance, a hyphen-delimitedsequence of syllables in place o f  the print formof a headword, created by tokeni~ation on~, - rg ) ,  can be 'glued' back as follows:*Sy l _ l  : ~ mark : +$ 1 Zt s t rxngpTSyl  1 ) : $s~r~ngp( S?1 2 )<=> w~oin(Seg, S~1_1. '
.
.
.
.
.$y l _2 .n : l " It~ .This rule demonstrates a characteristic property.of the DEP formalism, discussed in more detail95later: arbitrary Prolog predicates can be invokedto e.g.
constrain rule application or manipulatestrings.
Thus, the rule oialy applies to string to-kens surrounding a hyphen character; it manu-factures, by string concatenation, a new segmentwhich replaces the triggering pattern.Further segmentation.
Often strings need to besplit, with new tokens inserted between thepseces, to correct infelicities in the tapes, or toinsert markers between recognizably distinct con-tiguous segments that appear in the same font.The rule below implements the CGE/CEG con-vention that a swung dash is an implicit switchto bold if the current font is not bold already.font IX}  : $ ( -X=bo ld)  : ?E : t s t r ingp lE}tcm~=at(  A ,B ,E  ) t concat  ( "  ~ ' , re ,B} :<=> rant (X)  : ?A : font (bo ld}  : +B.Dealing with irregular input.
Rules that rear-range tokens are o~ten eeded to correct errors inthe tapes.
In CEG/CGE, parentheses surround-ing italic items often appear (erroneously) in aroman font.
A suite ofiaxles detaches the strayparentheses from the surrounding tokens, movesthem around the font marker, and glues them tothe item to which they belong.+E : $s t r i r~p iE )  : t?oncat ( " )  "~E1,E I<=> t0 )n- : +El .
/ *  detach  * /font (F )  : " ) "  < ?
., ),o : : re toKen(  font (  F ) ) .
/ *  move * /+E : Ss t r i r tg l= iE )  : " ) "  : toc~:at (E , " ) "~E1}<:> ?E l .
/~  g luo  * /eot~um invokes retokenization recursively on thesublist beginning with fontt e) and including alltokens to its right.
In p "nneiple, the three rulescan be subsumed by a single one; in practice,separate rules also 'catch' other types of  errone-ous or nots), input.Although retokenization is conceptually a sepa-rate process, it is interleaved in practice withtokemzation, bringing imp .rovements in perform-ance.
Upon completion, the tape stream corre-sponding, for instance, to the LDOCE entrynon-trivial manipulation of (partial) trees, as im-plicit and/or ellided information packed in thebntries is being recovered and reor-gaxxized.
Pars-ing is a top-down depth-first operation, and onlythe first successful parse is used.
This strategy,augmented by a 'junk collection' mechanism(discussed below) to recover from parsing failures,turns out to be adequate for handling all of thephenomena encountered while assigning struc-tural descriptions to dictionary entries.Dictionary grammars follow the basic notationalconventions of logic grammars; .however, we useadditional operators tailored to the structure ma-nipulation requirements of dictionary parsing.
InpLrticular, the right-hand side of grammar ulesadmits the use of-four different types ot operators,designed to deal with token list consumption, to-ken list manipulation, structure assignment, and(local) tree transformations.
These operatorssuitably modify the expansions of grammar rules;ultimately, all rules are compiled into Prolog.Token consumption.
Tokens axe removed fromthe token list by the + and - operators; + also as-signs them as terminal nodes under the head ofthe invoking rule.
Typically, delimiters intro-duced by tokenization (and retokenization) areremoved once they serve their primary functionof identifying local context; string segments of thetoken list are assigned labels and migrate to ap-propriate places in the final structural represen-iation ot an entry.
A simple rule for the part ofspeech fields in CEG (Figure 3) would be:l os  : :>- fznt l  i ta l i c )  = +Sag.A structured term stpos, "n" .n i l )  is built as aresult of the rule consuming, for instance, the to-ken "n", Rule names are associated with attri-butes in the LDB representation for a dictionaryentry; structures built by rules are pairs of thefo rm s i re ,  V i i= l ,  where velt~ is a list of oneor more elements (strings or further structures'returned' by reeunively invoked rules).au.tit.fi?
;??
'tistik, adj suffering from AUTISMI:  Iautistic chlld/behaviour -- ...ally adv \ [Wa4\] IF<wt is t i c<F<>wO~O} t i tC*80}~icP<C:  " f i s tZ kH<adj<S<OOOO<O<suf qer  ing  f rom{~CA)aut i sm?~B){*SA)  : ?u~6}aut i s t i c  ch i ld rm~behav iour (~)  R<OZ<R<-nmlZy<R<><adv<N~<is converted into the following token list:maHtarf ld  ~ .
p@ maHter  .pro~_wmrker  -~sd_--rkerdo~ markerfont .T~,  in l  ml l  caps  ) }.~t  ..1-1 .
bag in~e~m) .
"aut i s t i c ""au- t i s - t i c ""C : " t l s t l k "  -adp 0"0000""su f fe r ing  f rom""a~ut i~a#'"amtist i?ah i ld /be~v iour""01"Token list manipulation.
Adjustment of the to-ken list may be required in, for instance, simplecases of recovering ellided information or reor-dering tokens in the input stream.
This isachieved by the tm and ir~x operators, whichrespectively insert single, or sequences of, tokensinto the token list at the current position; and the++ operator, which inserts tokens (or arbitrarytree fragments) directly into the structure underconstruction.
Assuming a global variable, .rod,bound to the headword of the current entry, andthe ability to invoke a Prolog string concat-enation tunction trom within a rule (~a the *operator; see below), abbreviated morphologicalderivations tored as run-ons might be recovered ~l~ e ltlqc~rin~dor iv  | .
"aut i s t i (a l l y "  by :!
dor iv  ) .
f ld_sep  .
"adv"f ld_sep  .
"Ha4"  .
f ld_sep  .
run_on  =:>- rurmn mark  : - fon~lbo ld}  : -Sag  : ..e~x~=~l,,-,,~ X, Seg)wi .
I  X .
su f f i x )4.3 Pars ing  t~,n~' l : te ,m, : l ,  x ,  Oer iv l++Ooriv.
Parsing proper makes use of unification andbacktrracking to handle identification of segments (i tin is separately defined to test for membershipby context, and is heavily augmented with some of a closed class of suffixes.
)96Structure assignment.
The ++ operator can onlyassign arbitrary structures directly to the node inthe tree which is currently under construction.
Amore general mechanism for retaining structuresfor future use is provided by allowing variables tobe (optionally) associated with grammar ules: inthis way the grammar writer can obtain an ex-plicit handle on tree fragments, in contrast o tlaedefault situation where each rule implicitly'returns' the structure it constructs to its caller.The following rule, for example, provides a skel-eton treatment o the situation exemplified inFigure 4, where a definition-initial substring iscommon to more than one sub-definition:dofs = ?
(Sag)  :ss t jxka fs (X)  ==> subdof (X)  : opt (subdofs (X) ) .subdof (X)  ==>- font (bo ld )  :sd  le t te r  : - font l  ro l~n)  :~ncat lX ,  Seg,  DefSt r~ng)  :i ns (DefSt r ing)  : do f_s t rxng .S d :F le t te r  ==> *Sag ~ver i~(Seg ,  "abe" ) .de  _s i r ing  =:> +Sag ~ es t r ingp(Seg) .The defs rule removes the defmition-irtitial stringsegment and passes: it on to the repeatedly in-voked ~ s .
This manufactures the completedefinition string by concatenating the commoninitial segment, available as an argumentinstantiated two levels higher, with the continua-tion string specific to any given sub-definition.Tree transformations.
The ability to refer, byname, to fragments of the tree being constructedby an active grammar ule, allows arbitrary treetransformations using the complementary opera-tors -z. and +~..
They can only be applied tonon-terminal grammar ules, and require the ex-plicit specification of a place-holder variable as arule argument; this is bound to the structureconstructed by the rule.
The effect of these op-erators on the tree fragments constructed by therules they modify is to prevent heir incorporationinto the local tree (in the case of -z), to explicitlysplice it in (in the case of ?z), or simply to captureit (z).
The use of this mechanism in conjunctionwith the structure naming facility allows bothpermanent deletion of nodes, as well as theirpractically unconstrained migration between, andwithin, different levels of grammar (thus imple-menting node raising and reordering).
It is alsopossible to write a rule which builds no structure(the utility of such rules, in particular for con-trolling token consumption and junk collection,is discussed in section 5).Node-raising is illustrated by the grammar frag-ment below, which might be used to deal withcertain collocation phenomena.
Sometimes dic-tionaries choose to explain a word in the courseof defining .another elated word by arbitrarily in-setting mm~-entnes in their defmitmns:lach.ry.mal 'l~kfimal adj \[Wa51 of or concerning tearsof the organ (lach~mai gland/'_ ./) of the body thatproduces themThe potentially complex structure associated withthe embedded entry specification does not belongto the definition string, and should be factoredout as a separate node moved to a higher level ofthe tree, or even used to create a new tree entirely.The rule for parsi.n.g the definition fields of anentry makes a provmon for embedded entries; thestructure built as an ~ entry is bound tothe str,ac argument in the aofn rule.
The -z op-erator prevents the ~_ent ry  node frombeing incorporated as a daughter to ae~n: how-ever, by finification, it beghas its ,mi',gr, ation'upwards' through the tree, till it is 'caught by theentry rule several evels ~gher and inserted (via?
x) in its logically appropnate place.entry : :>  head : ton  : pos  : code  :de fn(  Em~f led  ) :+Xembedded_ent ry l  Embedded ) .cka fn(St r I J c )  ==>-Seg l  : Sst r ingp(Seg l )  :-Ze~=~KJded ent ry (  S t ruc  )-Seg2 : $s~r ingp(  Seg2 )$concat  { Seg l ,S~2,De?Str ing  ) :*+OefSt r ing .embedded_ent ry  ==>-bra  : .
.
.
.
.
.
.
.
: - ke t .Capturing generalizations / execution control.The expressive power of the system is further en-hanced by allowing optionality (via the opt oper-ator), alternations (I) and conditional constructsin the gra'--:nar ules; the latter are useful both formore co~:::,.,ct rule specification and to controlbacktracking while parsing.
Rule applicationmay be constrained by  arbitrary tests (revoked,as Prolog predicates, via a t operator), and as t r ing  operator is available for sampling localcontext.
The mechanism of escaping to Prolog,the motivation for which we discuss below, canalso be invoked when arbitrary manipulation oflexical data -- ranging from e.g.
simple stringprocessing to complex morphological analysis --Is required during parsing.Tree structures.
Additional control over theshape of dictionary" entry trees is provided byhaving two types of non-terminal nodes: weakand strong ones.
The difference is in the explicitpresence or absence of nodes, corresponding tothe rule names, in the final tree: a structure frag-ment manufactu~d by a weak non-terminal iseffectively spliced into the higher level structure,without an intermediate level of naming.
Onecommon use of such a device is the 'flattening'of branching constructions, typically built by re-cursive rules: the declarations t r~; , - ,~_nontermina ls  ( c le fs  .
subde?
.
n i l  1.when applied to the sub-definitions fragmentabove, would lead to the creation of a group ofsister ~ f  nodes, immediately dominated bv aaefs node.
Another use of the distinction be-wcteen weak and strong non-terminals is the ef-ive mapping from typographically identicalentry segments to appropriately named structurefragments, with global context driving the nameassignment.
Thus, assuming a weak label rulewhich captures the label string for further testing,analysis of the example labels discussed in 3.1could be achieved as follows (also see Figure 3):97l abe l lX I  =:> -beg in l res t r i c t ion}  : .
?X :$s t r i r~p(X \ ]  : -endf resxr i c t ion l .t r~n ==> opt  I doamin  I s ty le  I d iaZ  Iusaga_note  -) : word.~o~en ==> labe l tX}  i , i , ,X ,  ~_!ab) .
==> labe l (X  } S i sa l  X ,  lab \ ] .d ia l  = ?
l abe l lX}  $ i sa lX ,  d ia l - lab) .usagenote  ==> labe l lX ) .Such a mechanism captures g~aeralities intypograp~tc conventions employed across anygiven dictionary, and yet preserves the distinct,name spaces required for a meaningful unfoldingof a dictionary entry structure.5.
RANGE OF PHENOMENA TO HANDLEBelow we describe some typical phenomena en-countered in the dictionaries we have parsed anddiscuss their treatment.5.1 Messy token lists: controlling tokenconsumptionThe unsystematic encoding of font changes be-fore, as well as after, punctuation marks (com-mas, semicolons, parentheses) causes blindtokenization to remove punctuation marks fromthe data to which they are visually and concep-tually attached.
As already discussed (see 4.2),most errors of this nature can be corrected byretokenization.
Similarly, the confusing effectsof another pervasive rror, namely the occurrenceof consecuti, e font changes, can be avoided byhaving a retokenization rule simply remove allbut the last one.
In general, context sensitivity ishandled by (re)adjusting the token list;retokenization, however, is only sensitive to localcontext.
Since global context cannot be deter-mined unequivob.ally till parsing, the grammarwriter is given complete control over the con-sumption and addition of tokens as parsing pro-ceeds from left to right -- this allows formotivated recovery of ellisions, as well as dis-carding of tokens in local transformations.For instance, spurious occurrences of a fontmarker before a print symbol such as an openingparenthesis, which is not affected by a font dec-' laration, clearly cannot be removed by aretokenization rulefont !
roman\] : b ra  <=> bra .
(The marker may be genuinely closing a fontsegment prior to a different entry fragment whichcommences with, e.g., a left parenthesis).
Instead,a grammar rule anticipating a br~ token within itsscope can readiust he token list using either of:.
.
.
==> .
.
.
: - font l roman)  : -b ra  : ins lb r -a ) .. .
.
==> .
.
.
: - fant l roman l  : s t r ing lbra .
* \ ] .
(The $*ri-e operator tests for a token list withbr~ as its first element.
)5.2 The Peter-1 principle: scoping phenomenaConsider the entry for "Bankrott" in Figure 2.Translations haring the label (fig) ("breakdown,collapse ') are grOUl>ed together ~6ith commas andseparated from other lists with semicolons.
Therestnctlon (context or label) precedes the llst andcan be said to scope 'right' to the next semicolon.We place the righ-t-scoping labels or context un-der the (semicolon-delimited) t~,n_group as sisternodes to the multiple (comma-delimited) tr--~nodes (see also the representation of "title" inFigure 3).
Two principles ate at work here:meiintaining implicit e~dence of synonymyamong terms in the target langtmge responds tothe "do not discard anything" philosophy; placingcommon data items as high as possible in the tree(the 'Peter-minus-1 princaple') is in the spirit ofFlickinger et al (1985), and implements thenotion of placing a t~a l  node at the hi~.
estposition hi tlae tree wlaere its value is valid incombination with the values at or below its sisternodes.
The latter principle also motivates ets ofrules like~rm~ ==> " '"  pr~n .
.
.
: homograph .
.
.
.==> prat tused to account for entries in English where thepronunciation differs for different homographs.5.3 Tribal memory: rule variablesSome compaction or notational conventions indictionaries require a mechanism for a rule to re,-member (part of) its ancestry or know its sister sdescendants.
Consider the l~roblem of determin-ing the scope of gender or labels immediatelyfollowing variants of the headword:Advolmturbfiro nt (Sw),  Advokaturskanzlei f (Aus)lawyer's offize.Tippfr~ein t ( lnf), ~ppse f -, -n ( pej ) typist.Alchemic ( esp Aus) , Akhimief alchemy.The first two entries show forms differing, re-spectively, in dialect and gender, and register andgender.
The third illustrates other combinations.The rule accounting for labels after a variant mustknow whether items of like type have alreadybeen found after the hcadword, since items beforethe variant belong to the headword, differentitems of identical type following both belong in.-dividuaUy, and all the rest are common to botla.This 'tribal' memory is implemented using rulevariables:ent ry  : :>  .
.
.
( I d ia l  : $ (N :d ia l ) )  I(N=f - ,~d ia l} )  :.
.
.
: opt (subhm~lN) |  .
.
.
.subhamdlN} ==> opt (  $ (N=nod ia l )  :opt ld ia l )  ) : .
.
.
.In addition to enforcing rule constraints viaunification, rule arguments also act as 'channels'for node raising and as a mcchanisrn for control-ling rule behaviour depending on invocationcontext.This latter need stems from a pervasive phenom-enon in dictionaries: the notational conventionsfor a logical unit within an entry persist acrossdifferent contexts, and the sub-grammar for sucha unit should be aware of the environment i isactivated in.
Implicit cross-references in LDOCEare consistently introduced by fontl s ta l l  csos \],independent of whether the runnin 8 text is a de-fmiuon (roman font), example (italic), or an era-98bedded phrase or idiom (bold); by enforcing thereturn to the font active before the invocation ofi aq ) i io i t=xr f ,  we  a l low the  analysis of cross-references to be shared:imp l i c i t  xr f t  X )  ==> -1Font( beg in (  s ta l l  cams ) )- : .
.
.
: -?ont (X) .
-df  tx*  ==> .
.
.
imp l i c i t  x r f l roaan)  : .
.
.
.ex - tx t  =ffi> imp l i c i t -x r f ( i ta l i c )id_-_tx* ==> .
.
.
imp l io i t -xv f l  bo ld )  .
.
.
.
.5.4 Unpacking, duplication and movement ofstructures: node migrationThe whole range of phenomena requiring explicitmanipulation of entry fragment rees is handledby the mechanisms for node raising, reordering,and deletion.
Our analysis of implicit cross-references in LDOCE factors them out as sepa-rate structural units participatingin the make-upof a word sense definition, as well as reconstructsa 'text image' of the definition text, with just theorthography of the cross-reference it m 'splicedin' (see Figure 4).darn  ==> .dof_segs.!
O_St r ing)  .
:ooT_szr ingCD_St  r t r ig  J.c lef  segs lS t r _ l )  = ?
de f_nugget (Seg)( d~f  segs lS t r  O)S t r -O  : " "  ) -t con(~*(  Seg ,St r_O ,S t r _ l  ) .de f_nugget (P t r  ) ==> 7. ia tP l i c i t  xr?
(s (  imp l iE i t  x r f ,  .s (  to ,  P t r .R i l  ) .
Resx  ) ) .de f_nuggot !
Seg ) ==> -Seg  : Ss t r ingpt  Seg ).de f_s t r lng i  Dof )  ==> ?+Oef .The rules build a definition string from any se-quence of substrings or lexical items used ascross-references: by invoking the appropriatede?_nusmat rule, the simple segments are retainedonly for splicing the complete definition text;cross-reference pointers are extracted from thestructural representation of an implicit eross-reference;  and  i tml i c i t .
_xe f  nodes are propagatedup to a sister position to the dab_string.
Thestring image is built incrementally (by string con-catenation, as the individual a-?_nutmts areparsed); ultim, ately the ~?_str i r~ rule simplyincorporates tt into the structure for ae~.
De-claring darn, def str ing and impl ic i t_xrf  to bestrong non-terminals ultimately results in a deanstructure similar to the one illustrated inFigure 4.Copying and lateral migration of common genderlabels in CEG translations, exemplified by title'(Figure 3) and "abutment" (section 3.2), makesa differ r- ent use of the ?z operator.
To capture theleftward scope of gender labels, in contrast tocommon (right-scoping) context labels, we create,for each noun translatton (tran), a gender nodewith an empty value.
The comma-delimited *rannodes are collected by a recursive weak non-terminal *fans rule.t rams ==> t ran(G)  : opt (  - ca  : t rans (G)  ) .t ran(G)  :=> .
.
.
word  .
.
.
:opt (  -Zoenektr!
G ) ) : *7.gendor(  G ) .The (conditional) removal of gander" in the sec-ond rule followed by (obligatory) insertion of a~ne~r node captures the gender if present and'digs a hole' for it if absent.
Unification on thelast iteration of tear~ fills the holes.Noun compound fragments, as in "abutment"can be copied and migrated forward or backwardusing the same mechknism.
Since we have notimplemented the noun compound parsing mech-amsm required for identification of segments tobe copied, we have temporized by naming thefragments needing partners alt_.=?x or alt_sex.5.5 Conflated lexical entries: homographunpackingWe have implemented a mechanism to allowcreation of additional entries out of a single one,for example from orthographic, dialect, ormorphological variants of the original headword.Some CGE examples were given in sections 2and5.3 above.
To handle these, the rules build thesecond entry inside the main one and manufac-ture cross reference information for both mainform and variant, in anticipation of the imple-mentation of a splitting mechanism.
Examplesof other types appear in both CGE and CEG:vampire \[...\] n (lit) Vampir, Blutsauger (old~ m; (fig)Vampir m. - hat Vampir, Blutsauger (old) m.wader \[...\] n (a) (Orn) Watvogel m. (b) ~s pl (boots)Watstiefel pl.house in cpd~ HaLts-; ~ arrest n Hausarrest m; ~ boatn Hausboot n~ - baund adj ans Haus gefesselt; ....house:.
--hunt vi auf Haussuche sein; they have started--hunting sic haben angefangen, ach einem Haus zusuchen; -hunt ing n Haussuche n; ....The conventions for morphological vari,'ants, usedheavily in e.g.
LDOCE and Webster s Seventh,are different and would require a different mech-anism.
We have not yet developed a generalizedrule mechanism for ordering any kind of split;indeed we do not know if it ts possible, given thewide variation ~, seemingly aa hoc conventionsfor 'sneaking in logically separate ntries into re-lated headword efinitions: the case of "lachrymalgland" in 4.3 is iust one instance of this phe-nomena; below we list some more conceptuallysimilar, but notationally different, examples,demonstrating the embedding of homographs inthe variant, run-on, word-sense and examplefields of LDOCE.daddy long.legs .da~i lo t~ jz  also (/'m/) crane fly -- n... a type of flying insect with long legsac.rLmo.ny ... n bitterness, as of manner or language-- -nious ~,kri'maunias/ adj: an acrimonious quarrel ---niously advcrash  I ... v ... 6 infml also gatecrash -- to join (a party)without having been invited ...folk et.y.mol.o.gy ,,..'--~ n the changing of straage orforeign words so that they become like quite commonones: some people say ~parrowgrass instead ofASPARAGUS: that ia an example of folk etymology995.6 Notational promiscuity: selectivetokenizationOften distinctly different data items appear con-tiguous in the same font: the grammar codes ofLDOCE (section 2) are just one example.
Suchrun-together segments clearly need their owntokenization rules, which can only be appliedwhen they are located during parsing.
Thus,commas and parentheses take on special meaningin the string "X(to be)l,7", indicating, respec-tively, ellision of data and optionality of p~ase.This is a different interpretation from e.g.
alter-nation (consider the meaning of "adj, noun")orthe enclosing of italic labels m parentheses (Fig-ure 3).
Submission of a string token to furthertokemzation is best done by revoking a specialpurpose pattern matching module; thus we avoidglobal (and blind) tokenization on common (andambiguous) characters such as punctuationmarks.
The functionality required for selectivetokenization is provided'by a ~e primitive;below we demonstrate he construction of a listof sister synca* nodes from a segment like "n,v, adj", repetitively invoking oa)-~a) to break astring into two substrings eparated by a comma:-Seg  : $s t r i  ( ) :sy r~ats  ==> $t~rse(Hd. "
~n~.Re~s .n i l ,  Se9)  :ins1(  Hd.
Rest .n i l  ) :s t syncat  ?
,~a:  : opt tsyncats ) .
== t in (  Seg, por to fspeec :h  1.5.7 Parsing failures: junk collectionThe systematic rregularity of dictionary data (seesection 3.3) is only one problem when parsingdictionary entries.
Parsing failures in general arecommon during .gr-,~maar development; morespecifically, they tmght arise due to the format ofan entry segment being beyond (easy) capturingwithin the grammar formalism, or requiring non-trivial external functionality (such as compoundword parsing or noun/verb phrase analysis).Typically, external procedures o~.
rate on a newlyconstructed string token which represents a'packed' unruly token list.
AlternaUvely, if noformat need be assigned to the input, the graxn.
-mar should be able to 'skip over' the tokens m thelist, collecting them under a 'junk' node.If data loss is not an issue for a specific applica-tion, there is no need even to collect tokens fromirregular token lists; a simple rule to skip overUSAGE fields might be wntten asusacje ==> -usage  nmrk : use  f ie ld .use f ie ld  ==> -U ToKen : Snotiee~d u f ie ld}  :opt (  use_ f  ie ld  ).
-(Rules like these, building no structure, are espe-cially convenient when extensive reorganizatmnof tile token list is required -- typically in casesof grammar-driven token reordering or token de-letion without token consumption.
)In order to achieve skipping over unparseable in-put without data loss, we have implemented aootleztive rule class.
The structure built by suchrules the (transitive) concatenation of all thecharacter strings in daughter segments.
Copingwith gross irregularities is achieved by picking upany number of tokens and 'packing' them to-ther.
This strategy is illustrated by a grammarphrases conjoined with italic 'or' in examplesentences and/or their translations ( ee Figure 3).The italic conjunction is surrounded by slashes inthe resulting collected string as an audit trail.
Theextra argument o e~n$ ehforces, following thestrategy outlined in section 5.3, rule applicationonly m the correct font context.s t ron~nontermina ls  ( source  .
ta rg  .
h i l l .co l le~ives  !con j  .
n i l  ).source  ==> ?on~(bo\].d).r~ ==> (:~rl..11 rOlllilr~ J.
-IX )  : :>  -TOr t~|X)  +~ - fo r t~( i~ l  1}  :44'* / "  4,"Or"  ~ ++"/  "- font  I X ) +Seg.Finally, for the most complex cases of truly ir-regular input, a mechanism exists for constrainingjuiak collection to operate only as a last resort andonly at the point at which parsing can go no fur-ther.5.8 Augmenting the power of the formalism:escape to PrologSeveral of the mechanisms described above, suchas contextual control of token consumption (sec-tion 5.1), explicit structure handling (5.4), or se-lective toke/fization (5.6), are implemented as?
separate Prolo~z modules.
Invoking such extemaifunctionality from the grammar ules allows thenatural integration of the form- and content-recovery procedures into the top-down processof dictionary entry analysis.
The utility of thisdevice should be clear from the examples o far.Such escape to the underlying implementationlanguage goes against he grain of recent devel-opments of declarative gran3m_ ar formalisms.
(theprocedural ramifications of, for instance, beingable to call arbitrary LISP functions from the arcsof an ATN grammar have been discussed atlength: see, for instance, the opening chapters inWhitelock et al, 1987).
However, we feel justi-fied in augmenting, the .
.
.
.
.
formalism in such a way,as we are dealing with input which Is different mnature from, and on occasions possibly morecomplex than, straight natural anguage.
Unho-mogeneous mixtures of heavily formal notationsand annotations in totally free format, inter-spersed with (occasionally incomplete) fragmentsof natural anguage phrases, can easily defeat anyattempts at 'cleafi' parsing.
Since the DEP sys-tem is designed to deal with an open-ended setof dictionaries, it must be able to corffront a sim-ilarly open-ended set of notational conventionsand abbreviatory devices.
Furthermore.
dealingin full with some of these notations requires ac-cess to mechanisms and theories well beyond thepower of any grammar formalism: consider, forstance, what is involved in analyzing pronun-ciation fields in a dictionary, where alternativepronunciation patterns are marked only forsyllable(s) which differ from the primar3 ~pronun-caation (as in arch.bish.op: /,a:tfbiDp II ,at-/);where the pronunciation string itself ts notmarked for syllable structure; and where the as-signment of syllable boundaries i far from trivial(as in fas.cist: /'f=ej'a,st/)!1006.
CURRENT STATUSThe run-time environment of DEP includesgr .ammar debugging utilities, and a number ofopttons.
All facilities have been implemented,except where noted.
We have very detailedgrammars for CGE (parsing 98% of the entries),CEG (95%), and LDOCE (93%); less detailedgrammars for Webster s Seventh (98%), and bothlaalves of the Collins French Dictionary (approxi-mately 90%).The Dictionary Entry Parser is an integra.1, partof a larger system designed to recover dictionarystructure to an arbitrary depth of detail, convertthe resulting trees into LDB records, and makethe data av/tilable to end users via a flexible andpowerful lexical query language (LQL).
Indeed,we have built LDB's for all dictionaries we haveparsed; further development of LQL and the ex-ploitation of the LDB's via query for a numberof lexical studies are separate projects.Finally, we note that, in the light of recent effortsto develop an interchange standard for (Englishmono-lingual) dictionaries (Amsler and Tompa,1988), DEP acquires additional relevance, sinceit can be used, given a suitable annotation of thegrammar rules for the machine-readable source,to transduce a typesetting tape into an inter-changeable dictionary source, available to a largeruser commumty.ACILNOWLEDGEMENTS .We would like to thank Roy Byrd, JudithKlavans and Beth Levin for many discussionsconcerning the Dictionary Entry Parser system ingeneral, and this paper in particular.
Any re-maining errors are ours, and ours only.REFERENCESAhlswede, T, M Evens, K Rossi and J MarkowitzW1986) "Building a Lexical Database by Parsingebster's Seventh New Collegiate Dictionary '~,Advances in Lexicology, Second Annual Confer-ence of the UW Centre for the New OxfordEnglish Dictionary, 65-  78.Amsler, R and F Tompa (1988) "AnSGML-Based Standard for English MonolingualDictionaries", Information in Text, Fourth An-nual Conference of the L'W Centre for the NewOxford English Dictionary, 61-  79.Boguraev, B, and E Briscoe (Eds) (1989) Com-putational Lexicography for Natural LanguageProcessing, Longman, Harlow..~yrd, R, N Calzolari, M Chodorow, J Klavans,Neff and O Rizk (1987) "Tools and Methodsfor Computational Lexicology", ComputationalLinguistics, vol.
13(3 - 4), 219 - 240.Calzolari~ N and E Picchi (1986) "A Project fora Bilingual Lexical Database System", Advancesin Lexicology, Second ~ua l  Conference of theL.
'W Centre for the New Oxford English Dic-tionary, 79-  92.Calzolari, N and E Picchi (1988) "Acquisition ofSemantic Information from an On-LineDictionary.
", Proceedings of the 12th Interna-tional Conference on Computational Linguistics,87-  92.Collins (1980) Collins German Dictionary:German- English, English- German, CollinsPublishers, Glasgow.Gaxzanti (1984) II Nuovo Dizionario ItalianoGarzanti, Garzanti, Milano.Longman (1978) Longman Dictionary of Con-temporary English, Longman Group, London.Dadam, P, K Kuespert, F Andersen, H Blanken,R Erbe, J Guenauer, V Lure, P Pistor and GWalsh (1986) "A DBMS Prototype to SupportExtended NF2 Relations: An ~tegrated View onFlat Tables and Hierarchies, Proceedings ofA CM SIGMOD'86: International Conference onManagement of Data, 356- 367.Flickinger, D, C Pollard, T Wasow (1985)"Structure Sharing in Lexical Representation",Proceedings of the 23rd Annual Meeting of theAssociation for Computational Linguistics,262- 267.Fox, E, T Nutter, T Alhswede, M Evens and JMarkowitz (1988) "Building a Large Thesaurusfor Information Retrieval", Proceedings of theSecond Conference on Applied Natural LanguageProcessing, 101 - 108.Kazman, R (1986) "Structuring the Text of theOxford Engl!s,h Dictionary through Finite StateTransduction , University of Waterloo TechnicalReport No.
TR - 86-  20.McCord, M (1987} "Natural Language Process-ing and Prolog", m A Walker, MMcCord,  JSowa and W Wilson (Eds) Knowledge Systemsand ' Prolog, Addison-Wesley, Waltham,Massachusetts, 291 - 402.Nakamura, J and Makoto N (1988) "Extractionof Semantic Information from an Ordinary Eng-lish Dictionary and Its Evaluation", Proceedingsof the 12th International Conference on Computa-tional Linguistics, 459 - 464.Neff, M, R Byrd and O Rizk (1988) "Creat~gand Querying Hierarchical Lexical Data Bases ,Proceedings df the Second Conference on AppliedNatural Language Processing, 84- 93.van der Steen, G J (1982) "A Treatment of Que-ries in Large Text Corpora", in S Johansson (Ed)Computer Corpora in English LanguageResearch, Norwegian Computing Centre for theHumanities, Bergen, 49 - 63".Tompa, F (1986) "'Database Design for a Dic-tionary of the Future', University of Waterloo,unpublished.W7 (1967) Webster's Seventh New CollegiateDictionary, C.&C.
Merriam Company,Springfield, Massachussetts.Whitelock, P, M Wood, H Somers, R Johnsonand P Bennett (Eds) (1987) Linguistic Theory andComputer Applications, Academic Press, NewYork.101
