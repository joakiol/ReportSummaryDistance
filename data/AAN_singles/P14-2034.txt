Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 206?211,Baltimore, Maryland, USA, June 23-25 2014. c?2014 Association for Computational LinguisticsWord Segmentation of Informal Arabic with Domain AdaptationWill Monroe, Spence Green, and Christopher D. ManningComputer Science Department, Stanford University{wmonroe4,spenceg,manning}@stanford.eduAbstractSegmentation of clitics has been shown toimprove accuracy on a variety of ArabicNLP tasks.
However, state-of-the-art Ara-bic word segmenters are either limited toformal Modern Standard Arabic, perform-ing poorly on Arabic text featuring dialectalvocabulary and grammar, or rely on lin-guistic knowledge that is hand-tuned foreach dialect.
We extend an existing MSAsegmenter with a simple domain adapta-tion technique and new features in orderto segment informal and dialectal Arabictext.
Experiments show that our systemoutperforms existing systems on newswire,broadcast news and Egyptian dialect, im-proving segmentation F1score on a recentlyreleased Egyptian Arabic corpus to 95.1%,compared to 90.8% for another segmenterdesigned specifically for Egyptian Arabic.1 IntroductionSegmentation of words, clitics, and affixes is essen-tial for a number of natural language processing(NLP) applications, including machine translation,parsing, and speech recognition (Chang et al, 2008;Tsarfaty, 2006; Kurimo et al, 2006).
Segmentationis a common practice in Arabic NLP due to the lan-guage?s morphological richness.
Specifically, cliticseparation has been shown to improve performanceon Arabic parsing (Green and Manning, 2010) andArabic-English machine translation (Habash andSadat, 2006).
However, the variety of Arabic di-alects presents challenges in Arabic NLP.
DialectalArabic contains non-standard orthography, vocab-ulary, morphology, and syntax.
Tools that dependon corpora or grammatical properties that only con-sider formal Modern Standard Arabic (MSA) donot perform well when confronted with these differ-ences.
The creation of annotated corpora in dialec-tal Arabic (Maamouri et al, 2006) has promotedthe development of new systems that support di-alectal Arabic, but these systems tend to be tailoredto specific dialects and require separate efforts forEgyptian Arabic, Levantine Arabic, Maghrebi Ara-bic, etc.We present a single clitic segmentation modelthat is accurate on both MSA and informal Arabic.The model is an extension of the character-levelconditional random field (CRF) model of Greenand DeNero (2012).
Our work goes beyond theirsin three aspects.
First, we handle two Arabic ortho-graphic normalization rules that commonly requirerewriting of tokens after segmentation.
Second,we add new features that improve segmentation ac-curacy.
Third, we show that dialectal data can behandled in the framework of domain adaptation.Specifically, we show that even simple feature spaceaugmentation (Daum?, 2007) yields significant im-provements in task accuracy.We compare our work to the original Green andDeNero model and two other Arabic segmenta-tion systems: the MADA+TOKAN toolkit v. 3.1(Habash et al, 2009) and its Egyptian dialect vari-ant, MADA-ARZ v. 0.4 (Habash et al, 2013).
Wedemonstrate that our system achieves better perfor-mance across the board, beating all three systemson MSA newswire, informal broadcast news, andEgyptian dialect.
Our segmenter achieves a 95.1%F1segmentation score evaluated against a gold stan-dard on Egyptian dialect data, compared to 90.8%for MADA-ARZ and 92.9% for Green and DeN-ero.
In addition, our model decodes input an orderof magnitude faster than either version of MADA.Like the Green and DeNero system, but unlikeMADA and MADA-ARZ, our system does not relyon a morphological analyzer, and can be applieddirectly to any dialect for which segmented trainingdata is available.
The source code is available inthe latest public release of the Stanford Word Seg-menter (http://nlp.stanford.edu/software/segmenter.shtml).2062 Arabic Word Segmentation ModelA CRF model (Lafferty et al, 2001) defines a distri-bution p(Y|X; ?
), whereX = {x1, .
.
.
, xN} is theobserved input sequence andY = {y1, .
.
.
, yN} isthe sequence of labels we seek to predict.
Greenand DeNero use a linear-chain model with X asthe sequence of input characters, and Y?chosenaccording to the decision ruleY?= argmaxYN?i=1?>?
(X, yi, .
.
.
, yi?3, i) .where ?
is the feature map defined in Section 2.1.Their model classifies each yias one of I (contin-uation of a segment), O (whitespace outside anysegment), B (beginning of a segment), or F (pre-grouped foreign characters).Our segmenter expands this label space in orderto handle two Arabic-specific orthographic rules.In our model, each yican take on one of the sixvalues {I,O,B,F,RewAl,RewTa}:?
RewAl indicates that the current character,which is always the Arabic letter ?
l, starts anew segment and should additionally be trans-formed into the definite article ?
@ al- whensegmented.
This type of transformation occursafter the prefix ?
li- ?to?.?
RewTa indicates that the current character,which is always the Arabic letterH t, is acontinuation but should be transformed intothe letter?
h when segmented.
Arabic orthog-raphy rules restrict the occurrence of?
h tothe word-final position, writing it instead asH t whenever it is followed by a suffix.2.1 FeaturesThe model of Green and DeNero is a third-order(i.e., 4-gram) Markov CRF, employing the follow-ing indicator features:?
a five-character window around the currentcharacter: for each ?2 ?
?
?
2 and 1 ?
i ?N , the triple (xi+?, ?, yi)?
n-grams consisting of the current characterand up to three preceding characters: foreach 2 ?
n ?
4 and n ?
i ?
N ,the character-sequence/label-sequence pair(xi?n+1.
.
.
xi, yi?n+1.
.
.
yi)?
whether the current character is punctuation?
whether the current character is a digit?
the Unicode block of the current character?
the Unicode character class of the current char-acterIn addition to these, we include two other types offeatures motivated by specific errors the originalsystem made on Egyptian dialect development data:?
Word length and position within a word: foreach 1 ?
i ?
N , the pairs (`, yi), (a, yi), and(b, yi), where `, a, and b are the total lengthof the word containing xi, the number of char-acters after xiin the word, and the number ofcharacters before xiin the word, respectively.Some incorrect segmentations produced bythe original system could be ruled out with theknowledge of these statistics.?
First and last two characters of the currentword, separately influencing the first twolabels and the last two labels: for eachword consisting of characters xs.
.
.
xt, the tu-ples (xsxs+1, xt?1xt, ysys+1, ?begin?)
and(xsxs+1, xt?1xt, yt?1yt, ?end?).
This set offeatures addresses a particular dialectal Arabicconstruction, the negation A?
m?a- + [verb] +?
-sh, which requires a matching prefix andsuffix to be segmented simultaneously.
Thisfeature set alo allows themodel to take into ac-count other interactions between the beginningand end of a word, particularly those involvingthe definite article ?
@ al-.A notable property of this feature set is that it re-mains highly dialect-agnostic, even though our ad-ditional features were chosen in response to errorsmade on text in Egyptian dialect.
In particular,it does not depend on the existence of a dialect-specific lexicon or morphological analyzer.
As aresult, we expect this model to perform similarlywell when applied to other Arabic dialects.2.2 Domain adaptationIn this work, we train our model to segment Arabictext drawn from three domains: newswire, whichconsists of formal text in MSA; broadcast news,which contains scripted, formal MSA as well asextemporaneous dialogue in a mix of MSA and di-alect; and discussion forum posts written primarilyin Egyptian dialect.207F1(%) TEDEval (%)Model Training Data ATB BN ARZ ATB BN ARZGD ATB 97.60 94.87 79.92 98.22 96.81 87.30GD +BN+ARZ 97.28 96.37 92.90 98.05 97.45 95.01+Rew ATB 97.55 94.95 79.95 98.72 97.45 87.54+Rew +BN 97.58 96.60 82.94 98.75 98.18 89.43+Rew +BN+ARZ 97.30 96.09 92.64 98.59 97.91 95.03+Rew+DA +BN+ARZ 97.71 96.57 93.87 98.79 98.14 95.86+Rew+DA+Feat +BN+ARZ 98.36 97.35 95.06 99.14 98.57 96.67Table 1: Development set results.
GD is the model of Green and DeNero (2012).
Rew is support fororthographic rewrites with the RewAl and RewTa labels.
The fifth row shows the strongest baseline,which is the GD+Rew model trained on the concatenated training sets from all three treebanks.
DA isdomain adaptation via feature space augmentation.
Feat adds the additional feature templates describedin section 2.1.
ATB is the newswire ATB; BN is the Broadcast News treebank; ARZ is the Egyptiantreebank.
Best results (bold) are statistically significant (p < 0.001) relative to the strongest baseline.The approach to domain adaptation we use isthat of feature space augmentation (Daum?, 2007).Each indicator feature from the model describedin Section 2.1 is replaced by N + 1 features inthe augmented model, where N is the number ofdomains from which the data is drawn (here, N =3).
These N + 1 features consist of the originalfeature and N ?domain-specific?
features, one foreach of theN domains, each of which is active onlywhen both the original feature is present and thecurrent text comes from its assigned domain.3 ExperimentsWe train and evaluate on three corpora: parts 1?3 ofthe newswire Arabic Treebank (ATB),1the Broad-cast News Arabic Treebank (BN),2and parts 1?8of the BOLT Phase 1 Egyptian Arabic Treebank(ARZ).3These correspond respectively to the do-mains in section 2.2.
We target the segmentationscheme used by these corpora (leaving morphologi-cal affixes and the definite article attached).
For theATB, we use the same split as Chiang et al (2006).For each of the other two corpora, we split the datainto 80% training, 10% development, and 10% testin chronological order by document.4We train theGreen and DeNero model and our improvementsusing L-BFGS with L2regularization.1LDC2010T13, LDC2011T09, LDC2010T082LDC2012T073LDC2012E{93,98,89,99,107,125}, LDC2013E{12,21}4These splits are publicly available athttp://nlp.stanford.edu/software/parser-arabic-data-splits.shtml.3.1 Evaluation metricsWe use two evaluation metrics in our experiments.The first is an F1precision-recall measure, ignoringorthographic rewrites.
F1scores provide a moreinformative assessment of performance than word-level or character-level accuracy scores, as over 80%of tokens in the development sets consist of onlyone segment, with an average of one segmentationevery 4.7 tokens (or one every 20.4 characters).The second metric we use is the TEDEval met-ric (Tsarfaty et al, 2012).
TEDEval was devel-oped to evaluate joint segmentation and parsing5in Hebrew, which requires a greater variety of or-thographic rewrites than those possible in Arabic.Its edit distance-based scoring algorithm is robustenough to handle the rewrites produced by bothMADA and our segmenter.We measure the statistical significance of differ-ences in these metrics with an approximate ran-domization test (Yeh, 2000; Pad?, 2006), withR = 10,000 samples.3.2 ResultsTable 1 contains results on the development setfor the model of Green and DeNero and our im-provements.
Using domain adaptation alone helpsperformance on two of the three datasets (with a sta-tistically insignificant decrease on broadcast news),and that our additional features further improve5In order to evaluate segmentation in isolation, we converteach segmented sentence from both the model output andthe gold standard to a flat tree with all segments descendingdirectly from the root.208F1(%) TEDEval (%)ATB BN ARZ ATB BN ARZMADA 97.36 94.54 78.35 97.62 96.96 86.78MADA-ARZ 92.83 91.89 90.76 91.26 91.10 90.39GD+Rew+DA+Feat 98.30 97.17 95.13 99.10 98.42 96.75Table 2: Test set results.
Our final model (last row) is trained on all available data (ATB+BN+ARZ).
Bestresults (bold) are statistically significant (p < 0.001) relative to each MADA version.ATB BN ARZMADA 705.6 ?
5.1 472.0 ?
0.8 767.8 ?
1.9MADA-ARZ 784.7 ?
1.6 492.1 ?
4.2 779.0 ?
2.7GD+Rew+DA+Feat 90.0 ?
1.0 59.5 ?
0.3 72.7 ?
0.2Table 3: Wallclock time (in seconds) for MADA, MADA-ARZ, and our model for decoding each ofthe three development datasets.
Means and standard deviations were computed for 10 independent runs.MADA and MADA-ARZ are single-threaded.
Our segmenter supports multithreaded execution, but thetimes reported here are for single-threaded runs.segmentation on all datasets.
Table 2 shows thesegmentation scores our model achieves when eval-uated on the three test sets, as well as the results forMADA and MADA-ARZ.
Our segmenter achieveshigher scores than MADA and MADA-ARZ on alldatasets under both evaluation metrics.
In addi-tion, our segmenter is faster than MADA.
Table 3compares the running times of the three systems.Our segmenter achieves a 7x or more speedup overMADA and MADA-ARZ on all datasets.4 Error AnalysisWe sampled 100 errors randomly from all errorsmade by our final model (trained on all threedatasets with domain adaptation and additional fea-tures) on the ARZ development set; see Table 4.These errors fall into three general categories:?
typographical errors and annotation inconsis-tencies in the gold data;?
errors that can be fixed with a fuller analysisof just the problematic token, and thereforerepresent a deficiency in the feature set; and?
errors that would require additional context orsophisticated semantic awareness to fix.4.1 Typographical errors and annotationinconsistenciesOf the 100 errors we sampled, 33 are due to typo-graphical errors or inconsistencies in the gold data.We classify 7 as typos and 26 as annotation incon-sistencies, although the distinction between the twois murky: typos are intentionally preserved in thetreebank data, but segmentation of typos varies de-pending on how well they can be reconciled withstandard Arabic orthography.
Four of the seventypos are the result of a missing space, such as:?
??AJ??AK.Q??yashar-bi-?l-lay?al??
?staysawakeat-night?
(Q?D?yashar + K.bi- + ??AJ??
@ al-lay?al??)??
@ AJJ???
?amilatn?a-?an ?madeus?
(I???
?amilat + AJ -n?a +?
@ ?an)The first example is segmented in the Egyptian tree-bank but is left unsegmented by our system; thesecond is left as a single token in the treebank but issplit into the above three segments by our system.Of the annotation inconsistencies that do not in-volve typographical errors, a handful are segmen-tation mistakes; however, in the majority of thesecases, the annotator chose not to segment a wordfor justifiable but arbitrary reasons.
In particular, afew colloquial ?filler?
expressions are sometimesnot segmented, despite being compound Arabicwords that are segmented elsewhere in the data.These include AJK.P rabbin?a ?
[our] Lord?
(oath);A?YJ?
?indam?a ?when?/?while?
; and ?J?g khall?
?-k ?keep?/?stay?.
Also, tokens containing foreignwords are sometimes not segmented, despite car-rying Arabic affixes.
An example of this isQ??
?209Category # of errorsAbnormal gold data 33Typographical error 7Annotation inconsistency 26Need full-token features 36Need more context 31B?
wl?a 5AJ -n?a: verb/pron 7? -y: nisba/pron 4other 15Table 4: Counts of error categories (out of 100randomly sampled ARZ development set errors).wamistur ?andMister [English]?, which could besegmented as ?
wa- +Q??
mistur.4.2 Features too localIn 36 of the 100 sampled errors, we conjecture thatthe presence of the error indicates a shortcomingof the feature set, resulting in segmentations thatmake sense locally but are not plausible given thefull token.
Two examples of these are:???KQ???
wafit.ar?
?qah ?and in the way?
seg-mented as ?
wa- +??KQ??
fit.ar?
?qah (correctanalysis is ?
wa- + ?
fi- +??KQ?
t.ar??qah).Q??
ft.r ?break?/?breakfast?
is a common Ara-bic root, but the presence of?
q should indi-cate that Q??
ft.r is not the root in this case.?
????EB?
wal?ayuhimmhum ?and it?s not im-portant to them?
segmented as ?
wa- + ?li- +?
?EA -ayuhimm + ?
? -hum (correctanalysis is ?
wa- + B l?a +?
?Eyuhimm +?
? -hum).
The 4-character window ?KB l?ayhoccurs commonly with a segment boundaryafter the ?
l, but the segment?
?EA -ayuhimmis not a well-formed Arabic word.4.3 Context-sensitive segmentations andmultiple word sensesIn the remaining 31 of 100 errors, external contextis needed.
In many of these, it is not clear how toaddress the error without sophisticated semanticreasoning about the surrounding sentence.One token accounts for five of these errors: B?wl?a, which in Egyptian dialect can be analyzed as?
wa- + B l?a ?and [do/does] not?
or as B?
wall?a?or?.
In a few cases, either is syntactically correct,and the meaning must be inferred from context.Two other ambiguities are a frequent cause oferror and seem to require sophisticated disambigua-tion.
The first is AJ -n?a, which is both a first personplural object pronoun and a first person plural pasttense ending.
The former is segmented, while thelatter is not.
An example of this is the pair AJ???
?ilmun?a ?our knowledge?
(???
?ilmu + AJ -n?a) ver-sus AJ???
?alimn?a ?we knew?
(one segment).
Theother is ? -y, which is both a first person singularpossessive pronoun and the nisba adjective ending(which turns a noun into an adjective meaning ?ofor related to?
); only the former is segmented.
Oneexample of this distinction that appeared in the de-velopment set is the pair ??????
mawd.?u???
?mytopic?
(?????
mawd.
?u?+ ? -y) versus??????mawd.?u??
?y ?topical?, ?objective?.5 ConclusionIn this paper we demonstrate substantial gains onArabic clitic segmentation for both formal anddialectal text using a single model with dialect-independent features and a simple domain adap-tation strategy.
We present a new Arabic segmenterwhich performs better than tools employing sophis-ticated linguistic analysis, while also giving im-pressive speed improvements.
We evaluated oursegmenter on broadcast news and Egyptian Arabicdue to the current availability of annotated data inthese domains.
However, as data for other Arabic di-alects and genres becomes available, we expect thatthe model?s simplicity and the domain adaptationmethod we use will allow the system to be appliedto these dialects with minimal effort and without aloss of performance in the original domains.AcknowledgmentsWe thank the three anonymous reviewers, andReut Tsarfaty for valuable correspondence regard-ing TEDEval.
The second author is supportedby a National Science Foundation Graduate Re-search Fellowship.
This work was supported bythe Defense Advanced Research Projects Agency(DARPA) Broad Operational Language Transla-tion (BOLT) program through IBM.
Any opinions,findings, and conclusions or recommendations ex-pressed in this material are those of the author(s)and do not necessarily reflect the view of DARPAor the US government.210ReferencesPi-Chuan Chang, Michel Galley, and Christopher D.Manning.
2008.
Optimizing Chinese word segmen-tation for machine translation performance.
InWMT.David Chiang, Mona T. Diab, Nizar Habash, OwenRambow, and Safiullah Shareef.
2006.
Parsing Ara-bic dialects.
In EACL.Hal Daum?, III.
2007.
Frustratingly easy domain adap-tation.
In ACL.Spence Green and John DeNero.
2012.
A class-basedagreement model for generating accurately inflectedtranslations.
In ACL.Spence Green and Christopher D. Manning.
2010.
Bet-ter Arabic parsing: Baselines, evaluations, and anal-ysis.
In COLING.Nizar Habash and Fatiha Sadat.
2006.
Arabic prepro-cessing schemes for statistical machine translation.In NAACL, Short Papers.Nizar Habash, Owen Rambow, and Ryan Roth.
2009.MADA+TOKAN: A toolkit for Arabic tokenization,diacritization, morphological disambiguation, POStagging, stemming and lemmatization.
In MEDAR.Nizar Habash, Ryan Roth, Owen Rambow, Ramy Es-kander, and Nadi Tomeh.
2013.
Morphological anal-ysis and disambiguation for dialectal Arabic.
InHLT-NAACL.Mikko Kurimo, Antti Puurula, Ebru Arisoy, Vesa Si-ivola, Teemu Hirsim?ki, Janne Pylkk?nen, TanelAlum?e, and Murat Saraclar.
2006.
Unlimitedvocabulary speech recognition for agglutinative lan-guages.
In HLT-NAACL.John D. Lafferty, Andrew McCallum, and FernandoC.
N. Pereira.
2001.
Conditional random fields:Probabilistic models for segmenting and labeling se-quence data.
In ICML.Mohamed Maamouri, Ann Bies, Tim Buckwalter,Mona Diab, Nizar Habash, Owen Rambow, andDalila Tabessi.
2006.
Developing and using a pilotdialectal Arabic treebank.
In LREC.Sebastian Pad?, 2006.
User?s guide to sigf:Significance testing by approximate randomisa-tion.
http://www.nlpado.de/~sebastian/software/sigf.shtml.Reut Tsarfaty, Joakim Nivre, and Evelina Andersson.2012.
Joint evaluation of morphological segmenta-tion and syntactic parsing.
In ACL, Short Papers.Reut Tsarfaty.
2006.
Integrated morphological andsyntactic disambiguation for Modern Hebrew.
InCOLING-ACL.Alexander Yeh.
2000.
More accurate tests for the statis-tical significance of result differences.
In COLING.211
