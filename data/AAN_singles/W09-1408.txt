Proceedings of the Workshop on BioNLP: Shared Task, pages 59?67,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsA memory?based learning approach to event extraction in biomedical textsRoser Morante, Vincent Van Asch, Walter DaelemansCNTS - Language Technology GroupUniversity of AntwerpPrinsstraat 13B-2000 Antwerpen, Belgium{Roser.Morante,Walter.Daelemans,Vincent.VanAsch}@ua.ac.beAbstractIn this paper we describe the memory-based ma-chine learning system that we submitted to theBioNLP Shared Task on Event Extraction.
We mod-eled the event extraction task using an approach thathas been previously applied to other natural lan-guage processing tasks like semantic role labelingor negation scope finding.
The results obtained byour system (30.58 F-score in Task 1 and 29.27 inTask 2) suggest that the approach and the systemneed further adaptation to the complexity involvedin extracting biomedical events.1 IntroductionIn this paper we describe the memory-based ma-chine learning system that we submitted to theBioNLP shared task on event extraction1.
The sys-tem operates in three phases.
In the first phase, eventtriggers and entities other than proteins are detected.In the second phase, event participants and argu-ments are identified.
In the third phase, postprocess-ing heuristics select the best frame for each event.Memory-based language processing (Daelemansand van den Bosch, 2005) is based on the idea thatNLP problems can be solved by reuse of solved ex-amples of the problem stored in memory.
Givena new problem, the most similar examples are re-trieved, and a solution is extrapolated from them.As language processing tasks typically involve many1Web page: http://www-tsujii.is.s.u-tokyo.ac.jp/GENIA/SharedTask/index.htmlsubregularities and (pockets of) exceptions, it hasbeen argued that memory-based learning is at anadvantage in solving these highly disjunctive learn-ing problems compared to more eager learning thatabstract from the examples, as the latter eliminatesnot only noise but also potentially useful exceptions(Daelemans et al, 1999).The BioNLP Shared Task 2009 takes alinguistically-motivated approach, which is re-flected in the properties of the shared task definition:rich semantics, a text-bound approach, and decom-position of linguistic phenomena.
Memory-basedalgorithms have been successfully applied in lan-guage processing to a wide range of linguistic tasks,from phonology to semantic analysis.
Our goal wasto investigate the performance of a memory?basedapproach to the event extraction task, using onlythe information available in the training corpus andmodelling the task applying an approach similar tothe one that has been applied to tasks like semanticrole labeling (Morante et al, 2008) or negationscope detection (Morante and Daelemans, 2009).In Section 2 we briefly describe the task.
Section3 reviews some related work.
Section 4 presents thesystem, and Section 5 the results.
Finally, some con-clusions are put forward in Section 6.2 Task descriptionThe BioNLP Shared Task 2009 on event extrac-tion consists of recognising bio-molecular events inbiomedical texts, focusing on molecular events in-volving proteins and genes.
An event is defined as arelation that holds between multiple entities that ful-fil different roles.
Events can participate in one type59of events: regulation events.The task is divided into the three subtasks listedbelow.
We participated in subtasks 1 and 2.?
Task 1: event detection and characterization.
Thistask involves event trigger detection, event typing,and event participant recognition.?
Task 2: event argument recognition.
Recognitionof entities other than proteins and the assignment ofthese entities as event arguments.?
Task 3: recognition of negations and speculations.The task did not include a named entity recogni-tion subtask.
A gold standard set of named entityannotations for proteins was provided by the organ-isation.
A dataset based on the publicly availableportion of the GENIA (Collier et al, 1999) corpusannotated with events (Kim et al, 2008) and of theBioInfer (Pyysalo et al, 2007) corpus was providedfor training, and held-out parts of the same corporawere provided for development and testing.The inter-annotator agreement reported for theGenia Event corpus is 56% strict match2, whichmeans that the event type is the same, the clue ex-pressions are overlapping and the themes are thesame.
This low inter-annotator agreement is an in-dicator of the complexity of the task.
Similar lowinter-annotator agreement rates (49.00 %) in identi-fication of events have been reported by Sasaki et al(2008).3 Related workIn recent years, research on text mining in thebiomedical domain has experienced substantialprogress, as shown in reviews of work done in thisfield (Krallinger and Valencia, 2005; Ananiadou andMcNaught, 2006; Krallinger et al, 2008b).
Somecorpora have been annotated with event level infor-mation of different types: PropBank-style frames(Wattarujeekrit et al, 2004; Chou et al, 2006),frame independent roles (Kim et al, 2008), andspecific roles for certain event types (Sasaki et al,2008).
The focus on extraction of event frames us-ing machine learning techniques is relatively newbecause there were no corpora available.2We did not find inter-annotator agreement measures inthe paper that describes the corpus (Kim et al, 2008), but inwww-tsujii.is.s.u-tokyo.ac.jp/T-FaNT/T-FaNT.files/Slides/Kim.pdf.Most work focuses on extracting biological rela-tions from corpora, which consists of finding asso-ciations between entities within a text phrase.
Forexample, Bundschus et al (2008) develop a Condi-tional Random Fields (CRF) system to identify re-lations between genes and diseases from a set ofGeneRIF (Gene Reference Into Function) phrases.A shared task was organised in the framework ofthe Language Learning in Logic Workshop 2005 de-voted to the extraction of relations from biomedicaltexts (Ne?dellec, 2005).
Extracting protein-proteininteractions has also produced a lot of research, andhas been the focus of the BioCreative II competi-tion (Krallinger et al, 2008a).As for event extraction, Yakushiji et al (2001)present work on event extraction based on full-parsing and a large-scale, general-purpose grammar.They implement an Argument Structure Extractor.The parser is used to convert sentences that describethe same event into an argument structure for thisevent.
The argument structure contains argumentssuch as semantic subject and object.
Informationextraction itself is performed using pattern matchingon the argument structure.
The system extracts 23 %of the argument structures uniquely, and 24% withambiguity.
Sasaki et al (2008) present a supervisedmachine learning system that extracts event framesfrom a corpus in which the biological process E. coligene regulation was linguistically annotated by do-main experts.
The frames being extracted specifyall potential arguments of gene regulation events.Arguments are assigned domain-independent roles(Agent, Theme, Location) and domain-dependentroles (Condition, Manner).
Their system works inthree steps: (i) CRF-based named entity recogni-tion to assign named entities to word sequences; (ii)CRF-based semantic role labeling to assign seman-tic roles to word sequences with named entity labels;(iii) Comparison of word sequences with event pat-terns derived from the corpus.
The system achieves50% recall and 20% precision.We are not aware of work that has been carriedout on the data set of the BioNLP Shared Task 2009before the task took place.604 System descriptionWe developed a supervised machine learning sys-tem.
The system operates in three phases.
In the firstphase, event triggers and entities other than proteinsare detected.
In the second phase, event participantsand arguments are identified.
In the third phase,postprocessing heuristics select the best frame foreach event.
Parameterisation of the classifiers usedin Phases 1 and 2 was performed by experiment-ing with sets of parameters on the development set.We experimented with manually selected parame-ters and with parameters selected by a genetic algo-rithm, but the parameters found by the genetic algo-rithm did not yield better results than the manuallyselected parametersAs a first step, we preprocess the corpora with theGDep dependency parser (Sagae and Tsujii, 2007)so that we can use part-of-speech tags and syntac-tic information as features for the machine learner.GDep is a a dependency parser for biomedical texttrained on the Tsujii Lab?s GENIA treebank.
Thedependency parser predicts for every word the part-of-speech tag, the lemma, the syntactic head, andthe dependency relation.
In addition to these regulardependency tags it also provides information aboutthe IOB-style chunks and named entities.
The clas-sifiers use the output of GDep in addition to somefrequency measures as features.We represent the data into a columns format, fol-lowing the standard format of the CoNLL SharedTask 2006 (Buchholz and Marsi, 2006), in whichsentences are separated by a blank line and fieldsare separated by a single tab character.
A sentenceconsists of tokens, each one starting on a new line.4.1 Phase 1: Entity DetectionIn the first phase, a memory based classifier pre-dicts for every word in the corpus whether it is anentity or not and the type of entity.
In this set-ting, entity refers to what in the shared task def-inition are events and entities other than proteins.Classes are defined in the IOB-style3 in order tofind entities that span over multiple words.
Figure1 shows a simplified version of a sentence in whichhigh level is a Positive Regulation event that spansover multiple tokens and proenkephalin is a Pro-3I stands for ?inside?, B for ?beginning?, and O for ?outside?.tein.
The Protein class does not need to be predictedby the classifier because this information is pro-vided by the Task organisers.
The classes predictedare: O, {B,I}-Entity, {B,I}-Binding, {B,I}-Gene Ex-pression, {B,I}-Localization, {B,I}-Negative Regula-tion, {B,I}-Positive Regulation, {B,I}-Phosphorylation,{B,I}-Protein Catabolism, {B,I}-Transcription.Token Class Token ClassUpon O which Oactivation O correlate O, O with OT O high B-Positive regulationlymphocyte O level I-Positive regulationaccumulate O of Ohigh O proenkephalin B-Proteinlevel O mRNA Oof O in Othe O the Oneuropeptide O cell Oenkephalin O .
OFigure 1: Instance representation for the entity de-tection classifier.We use the IB1 memory?based classifier as im-plemented in TiMBL (version 6.1.2) (Daelemanset al, 2007), a supervised inductive algorithm forlearning classification tasks based on the k-nearestneighbor classification rule (Cover and Hart, 1967).The memory-based learning algorithm was param-eterised in this case by using modified value differ-ence as the similarity metric, gain ratio for featureweighting, using 7 k-nearest neighbors, and weight-ing the class vote of neighbors as a function of theirinverse linear distance.
For training we did not usethe entire set of instances from the training data.
Wedownsampled the instances keeping 5 negative in-stances (class label O) for every positive instance.Instances to be kept were randomly selected.
Thefeatures used by this classifier are the following:?
About the token in focus: word, chunk tag, namedentity tag as provided by the dependency parser,and, for every entity type, a number indicating howmany times the focus word triggered this type of en-tity in the training corpus.?
About the context of the token in focus: lemmasranging from the lemma at position -4 until thelemma at position +3 (relative to the focus word);part-of-speech ranging from position -1 until posi-tion +1; chunk ranging from position -1 until posi-tion +1 relative to the focus word; the chunk be-61fore the chunk to which the focus word belongs;a boolean indicating if a word is a protein or notfor the words ranging from position -2 until posi-tion +3.Class label Precision Recall F-scoreB-Gene expression 59.32 60.23 59.77B-Regulation 30.41 33.58 31.91B-Entity 40.21 41.49 40.84B-Positive regulation 41.16 46.25 43.56B-Binding 57.76 53.14 55.36B-Negative regulation 42.94 48.67 45.63I-Negative regulation 7.69 3.33 4.65I-Positive regulation 14.29 13.24 13.74B-Phosphorylation 75.68 71.80 73.68I-Regulation 14.29 10.00 11.77B-Transcription 48.78 59.70 53.69I-Entity 20.00 16.13 17.86B-Localization 75.00 60.00 66.67B-Protein catabolism 73.08 100.00 84.44O 97.66 97.62 97.64Table 1: Results of the entity detection classifier.Entities that are not in the table have a precision andrecall of 0.Table 1 shows the results4 of this first step.
Allclass labels with a precision and recall of 0 are leftout.
The overall accuracy is 95.4%.
This high ac-curacy is caused by the skewness of the data in thetraining corpus, which contains a higher proportionof instances with class label O.
Instances with thisclass are correctly classified in the development test.B-Protein catabolism and B-Phosphorylation get thehighest scores.
The reason why these classes gethigher scores can be that the words that trigger theseevents are less diverse.4.2 Phase 2: predicting the arguments andparticipants of eventsIn the second phase, another memory-based clas-sifier predicts the participants and arguments of anevent.
Participants have the main role in the eventand arguments are entities that further specify theevent.
In (1), for the event phosphorylation the sys-tem has to find that STAT1, STAT3, STAT4, STAT5a,and STAT5b are participants with the role Theme andthat tyrosine is an argument with the role Site.4In this section we provide results on development data be-cause the gold test data have not been made available.
(1) IFN-alpha enhanced tyrosine phosphorylationof STAT1, STAT3, STAT4, STAT5a, andSTAT5b.We use the IB1 algorithm as implemented inTiMBL (version 6.1.2) (Daelemans et al, 2007).The classifier was parameterised by using gain ratiofor feature weighting, overlap as distance metrics,11 nearest neighbors for extrapolation, and normalmajority voting for class voting weights.For this classifier, instances represent combina-tions of an event with all the entities in a sentence,for as many events as there are in a sentence.
Entitiesinclude entities and events.
We use as input the out-put of the classifier in Phase 1, so only events andentities classified as such in Phase 1, and the goldproteins will be combined.
Events can have partici-pants and arguments in a sentence different that theirsentence.
We calculated that in the training corpusthese cases account for 5.54% of the relations, anddecided to restrict the combinations at the sentencelevel.
For the sentence in (1) above, where tyrosine,phosphorylation, STAT1, STAT3, STAT4, STAT5a,and STAT5b are entities and of those only phospho-rylation is an event, the instances would be producedby combining phosphorylation with the seven enti-ties.The features used by this classifier are the follow-ing:?
Of the event and of the combined entity: first word,last word, type, named entity provided by GDep,chain of lemmas, chain of part-of-speech (POS)tags, chain of chunk tags, dependency label of thefirst word, dependency label of the last word.?
Of the event context and of the combined entity con-text: word, lemma, POS, chunk, and GDep namedentity of the five previous and next words.?
Of the context between event and combined entity:the chain of chunks in between, number of tokens inbetween, a binary feature indicating whether eventis located before or after entity.?
Others: four features indicating the parental rela-tion between the first and last words of the eventand the first and last words of the entity.
The valuesfor this feature are: event father, event ancestor, en-tity father, entity ancestor, none.
Five binary fea-tures indicating if the event accepts certain roles(Theme, Site, ToLoc, AtLoc, Cause).62Table 2 shows the results of this classifier per typeof participant (Cause, Site, Theme) and type of ar-gument (AtLoc, ToLoc).
Arguments are very infre-quent, and the participants are skewed towards theclass Theme.
Classes Site and Theme score high F1,and in both cases recall is higher than precision.
Thefact that the classifier overpredicts Sites and Themeswill have a negative influence in the final scores ofthe full system.
Further research will focus on im-proving precision.Part/Arg Total Precision Recall F1Cause 61 28.88 21.31 24.52Site 20 54.83 85.00 66.66Theme 683 55.50 72.32 62.80AtLoc 1 25.00 100.00 40.00ToLoc 4 75.00 75.00 75.00Table 2: Results of finding the event participants andarguments.Table 3 shows the results of finding the event par-ticipants and arguments per event type, expressed interms of accuracy on the development corpus.
Causeis easier to predict for Positive Regulation events,Site is the easiest class to predict, taking into ac-count that AtLoc and ToLoc occur only 5 times intotal, and Theme can be predicted successfully forTranscription and Gene Expression events, whereasit gets lower scores for Regulation, Binding, andPositive Regulation events.Event Arguments/ParticipantsType Cause Site Theme AtLoc ToLocBinding - 100.00 56.00 - -Gene Expr.
- - 89.95 - -Localization - - 73.07 100.00 75.00- Regulation 11.11 0.00 75.00 - -Phosphorylation 0.00 100.00 70.83 - -+ Regulation 27.77 90.90 56.77 - -Protein Catab.
- - 60.00 - -Regulation 13.33 0.00 46.87 - -Transcription - - 94.44 - -Table 3: Results of finding the event participants andarguments per event type (accuracy).Table 4 shows the results of finding the event par-ticipants that are Entity and Protein per type of eventfor events that are not regulations.
Entity scores highin all cases, whereas Protein scores high for Tran-scription and Gene Expression events and low forBinding events.Event Arg./Part.
TypeType Entity ProteinBinding 100.00 56.00Gene Expr.
- 89.90Localization 80.00 73.07Phosphorylation 100.00 68.00Protein Catab.
- 60.00Transcription - 94.44Table 4: Results of finding the event participants andarguments that are Entity and Protein per event type(accuracy).Table 5 shows the results of finding the partic-ipants and arguments of regulation events.
In thecase of regulation events, Entity is easier to classifywith Positive Regulation events, and Protein withNegative Regulation events.
In the cases in whichevents are participants of regulation events, Bind-ing, Gene Expression and Phosphorylation are easierto classify with Positive Regulation events, Local-ization with Regulation events, Protein Catabolismwith Negative Regulation events, and Transcriptionis easy to classify in all cases.Arg./Part.
Event TypeType Regulation + Regulation -RegulationEntity 0.00 90.90 0.00Protein 17.85 38.88 45.45Binding - 75.00 66.66Gene Expr.
66.66 90.47 75.00Localization 100.00 80.00 75.00Phosphorylation 0.00 44.44 0.00Protein Catab.
0.00 40.00 100.00Transcription 100.00 92.85 100.00Table 5: Results of finding event arguments and par-ticipants for regulation events (accuracy).From the results of the system in this phase we canextract some conclusions: data are skewed towardsthe Theme class; Themes are not equally predictablefor the different types of events, they are betterpredictable for Gene Expression and Transcription;Proteins are more difficult to classify when they areThemes of regulation events; and Transcription andLocalization events are easier to predict as Themesof regulation events, compared to the other types ofevents that are Themes of regulation events.
This63suggests that it could be worth experimenting witha classifier per entity type and with a classifier perrole, instead of using the same classifier for all typesof entities.4.3 Phase 3: heuristics to select the best frameper eventPhases 1 and 2 aimed at identifying events and can-didates to event participants.
However, the purposeof the task is to extract full frames of events.
For asentence like the one in (1) above, the system has toextract the event frames in (2).
(2) 1.
Phosphorylation (phosphorylation): Theme(STAT1) Site (tyrosine)2.
Phosphorylation (phosphorylation): Theme(STAT3) Site (tyrosine)3.
Phosphorylation (phosphorylation): Theme(STAT5a) Site (tyrosine)4.
Phosphorylation (phosphorylation): Theme(STAT4) Site (tyrosine)5.
Phosphorylation (phosphorylation): Theme(STAT5b) Site (tyrosine)It is necessary to apply heuristics in order to buildthe event frames from the output of the second clas-sifier, which for the sentence in (1) above shouldcontain the predictions in (3).
(3) 1. phosphorylation STAT1 : Theme2.
phosphorylation STAT3 : Theme3.
phosphorylation STAT5a : Theme4.
phosphorylation STAT4 : Theme5.
phosphorylation STAT5b : Theme6.
phosphorylation tyrosine : SiteThus, in the third phase, postprocessing heuristicsdetermine which is the frame of each event.4.3.1 Specific heuristics for each type of eventThe system contains different rules for each of the5 types of participants (Cause, Site, Theme, AtLoc,ToLoc).
The text entities are the entities defined dur-ing Phase 2.
An event is created for every text entityfor which the system predicted at least one partic-ipant or argument.
To illustrate this we can take alook at the predictions for the Gene Expression eventin (4) where the identifiers starting by T refer to en-tities in the text.
The prediction would results in theevents listed in (5).
(4) Gene expression=Theme:T11=Theme:T12=Theme:T13(5) E1 Gene expression:T23 Theme:T11E2 Gene expression:T23 Theme:T12E3 Gene expression:T23 Theme:T13Gene expression, Transcription, and Proteincatabolism.
These type of events have only aTheme.
Therefore, an event frame is created for ev-ery Theme predicted for events that belong to thesetypes.Localization.
A Localization event can have oneTheme and 2 arguments: AtLoc and ToLoc.
ALocalization event with more than one predictedTheme will result in as many frames as predictedThemes.
The arguments are passed on to everyframe.Binding.
A Binding event can have multipleThemes and multiple Site arguments.
If the systempredicts more than one Theme for a Binding event,the heuristics first check if these Themes are in a co-ordination structure.
Coordination checking consistsof checking whether the word ?and?
can be foundbetween the Themes.
Coordinated Themes will giverise to separate frames.
Every participant and looseTheme is added to all created event lines.
This caseapplies to the sentence in (6)(6) When we analyzed the nature of STATproteins capable of binding to IL-2Ralpha,pim-1, and IRF-1 GAS elements after cytokinestimulation, we observed IFN-alpha-inducedbinding of STAT1, STAT3, and STAT4, but notSTAT5 to all of these elements.The frames that should be created for this sen-tence listed in (7).
(7) 1.
Binding (binding): Theme(STAT4)Theme2(IRF-1) Site2(GAS elements)2.
Binding (binding): Theme(STAT3)Theme2:(IL-2Ralpha) Site2(GAS elements)3.
Binding (binding): Theme(STAT3)Theme2(IRF-1) Site2(GAS elements)4.
Binding (binding): Theme(STAT4)Theme2(pim-1) Site2(GAS elements)5.
Binding (binding): Theme(STAT1)Theme2(IL-2Ralpha) Site2(GAS elements)646.
Binding (binding): Theme(STAT4)Theme2(IL-2Ralpha) Site2(GAS elements)7.
Binding (binding): Theme(IL-2Ralpha)Site(GAS elements)8.
Binding (binding): Theme(pim-1) Site(GASelements)9.
Binding (binding): Theme(STAT1)Theme2(IRF-1) Site2(GAS elements)10.
Binding (binding): Theme(STAT3)Theme2(pim-1) Site2(GAS elements)11.
Binding (binding): Theme(IRF-1) Site(GASelements)12.
Binding (binding): Theme(STAT1)Theme2(pim-1) Site2(GAS elements)Phosphorylation.
A Phosphorylation event canhave one Theme and one Site.
Multiple Themes forthe same event will result in multiple frames.
TheSite argument will be added to every frame.Regulation, Positive regulation, and Negativeregulation.
A Regulation event can have a Theme,a Cause, a Site, and a CSite.
For Regulation eventsthe system uses a different approach when creatingnew frames.
It first checks which of the participantsand arguments occurs the most frequent in a predic-tion and it creates as many separate frames as areneeded to give every participant/argument its ownframe.
The remaining participants/arguments areadded to the nearest frame.
For this type of eventa new frame can be created not only for multipleThemes but also for e.g.
multiple Sites.
The purposeof this strategy is to increase the recall of Regulationevents.4.3.2 PostprocessingAfter translating predictions into frames somecorrections are made.1.
Every Theme and Cause that is not a Protein isthrown away.2.
Every frame that has no Theme is providedwith a default Theme.
If no Protein is foundbefore the focus word, the closest Protein afterthe word is taken as the default Theme.3.
Duplicates are removed.5 ResultsThe official results of our system for Task 1 are pre-sented in Table 6.
The best F1 score are for Gene Ex-pression and Protein Catabolism events.
The lowestresults are for all the types of regulation events andfor Binding events.
Binding events are more diffi-cult to predict correctly because they can have morethan one Theme.Total Precision Recall F1Binding 347 12.97 31.03 18.29Gene Expr.
722 51.39 68.96 58.89Localization 174 20.69 78.26 32.73Phosphorylation 135 28.15 67.86 39.79Protein Catab.
14 64.29 42.86 51.43Transcription 137 24.82 41.46 31.05Regulation 291 8.93 23.64 12.97+Regulation 983 11.70 31.68 17.09-Regulation 379 11.08 29.85 16.15TOTAL 3182 22.50 47.70 30.58Table 6: Official results of Task 1.
ApproximateSpan Matching/Approximate Recursive Matching.The official results of our system for Task 2 arepresented in Table 7.
Results are similar to the re-sults of Task 1 because there are not many more ar-guments than participants.
Recognising argumentswas the additional goal of Task 2 in relation toTask 1.Total Precision Recall F1Binding 349 11.75 28.28 16.60Gene Expr.
722 51.39 68.96 58.89Localization 174 17.82 67.39 28.18Phosphorylation 139 15.83 39.29 22.56Protein Catab.
14 64.29 42.86 51.43Transcription 137 24.82 41.46 31.05Regulation 292 8.56 22.73 12.44+Regulation 987 11.35 30.85 16.59-Regulation 379 11.08 29.20 15.76TOTAL 3193 21.52 45.77 29.27Table 7: Official results of Task 2.
ApproximateSpan Matching/Approximate Recursive Matching.Results obtained on the development set are a lit-tle bit higher.
For Task1 an overall F1 of 34.78 andfor Task 2 33.54.For most event types precision and recall are un-balanced, the system scores higher in recall.
Fur-ther research should focus on increasing precisionbecause the system is predicting false positives.
Itwould be possible to add a step in order to fil-ter out the false positives by comparing word se-quences with event patterns derived from the cor-pus, which is an approach taken in the system bySasaki et al (2008) .65In the case of Binding events, both precision andrecall are low.
There are two explanations for this.In the first place, the first classifier misses almosthalf of the binding events.
As an example, forthe sentence in (8.1), the gold standard identifies asbinding event the multiwords binds as a homodimerand form heterodimers, whereas the system identi-fies two binding events for the same sentence, bindsand homodimer, none of which is correct becausethe correct one is the multiword unit.
For the sen-tence in (8.2), the gold standard identifies as bindingevents bind, form homo-, and heterodimers, whereasthe system identifies only binds.
(8) 1.
The KBF1/p50 factor binds as a homodimer but canalso form heterodimers with the products of othermembers of the same family, like the c-rel and v-rel(proto)oncogenes.2.
A mutant of KBF1/p50 (delta SP), unable to bind toDNA but able to form homo- or heterodimers, has beenconstructed.From the sentence in (8.1) above the eight framesin (9) should be extracted, whereas the system ex-tracts only the frames in (10), which are incorrectbecause the events have not been correctly identi-fied.
(9) 1.
Binding(binds as a homodimer) : Theme(KBF1)2.
Binding(binds as a homodimer) : Theme(p50)3.
Binding(form heterodimers) : Theme(KBF1)Theme2(c-rel)4.
Binding(form heterodimers) : Theme(p50)Theme2(v-rel)5.
Binding(form heterodimers) : Theme(p50)Theme2(c-rel)6.
Binding(form heterodimers) : Theme(KBF1)Theme2(v-rel)7.
Binding(bind) : Theme(p50)8.
Binding(bind) : Theme(KBF1)(10) 1.
Binding(binds) : Theme(v-rel)2.
Binding(homodimer) : Theme(c-rel)The complexity of frame extraction of Bindingevents contrasts with the less complex extraction offrames for Gene Expression events, like the one insentence (11), where expression has been identifiedcorrectly by the system as an event and the frame in(12) has been correctly extracted.
(11) Thus, c-Fos/c-Jun heterodimers might contribute to therepression of DRA gene expression.
(12) Gene Expression(expression) : Theme(DRA)6 ConclusionsIn this paper we presented a supervised machinelearning system that extracts event frames frombiomedical texts in three phases.
The system partic-ipated in the BioNLP Shared Task 2009, achievingan F-score of 30.58 in Task 1, and 29.27 in Task 2.The frame extraction task was modeled applying thesame approach that has been applied to tasks like se-mantic role labeling or negation scope detection, inorder to check whether such an approach would besuitable for a frame extraction task.
The results ob-tained for the present task do not compare to resultsobtained in the mentioned tasks, where state of theart F-scores are above 80.Extracting biomedical event frames is more com-plex than labeling semantic roles because of severalreasons.
Semantic roles are mostly assigned to syn-tactic constituents, predicates have only one frameand all the arguments belong to the same frame.
Incontrast, in the biomedical domain one event canhave several frames, each frame having differentparticipants, the boundaries of which do not coin-cide with syntactic constituents.The system presented here can be improved inseveral directions.
Future research will concentrateon increasing precision in general, and precision andrecall of binding events in particular.
Analysing indepth the errors made by the system at each phasewill allow us to find the weaker aspects of the sys-tem.
From the results of the system in the secondphase we could draw some conclusions: data areskewed towards the Theme class; Themes are notequally predictable for the different types of events;Proteins are more difficult to classify when they areThemes of regulation events; and Transcription andLocalization events are easier to predict as Themesof regulation events, compared to the other types ofevents that are Themes of regulation events.
We planto experiment with a classifier per entity type andwith a classifier per role, instead of using the sameclassifier for all types of entities.
Additionally, theeffects of the postprocessing rules in Phase 3 will beevaluated.66AcknowledgmentsOur work was made possible through financial sup-port from the University of Antwerp (GOA projectBIOGRAPH).
We are grateful to two anonymous re-viewers for their valuable comments.ReferencesS.
Ananiadou and J. McNaught.
2006.
Text Mining forBiology and Biomedicine.
Artech House Books, Lon-don.S.
Buchholz and E. Marsi.
2006.
CoNLL-X shared taskon multilingual dependency parsing.
In Proc.
of the XCoNLL Shared Task, New York.
SIGNLL.M.
Bundschus, M. Dejori, M. Stetter, V. Tresp, and H-P Kriegel.
2008.
Extraction of semantic biomedi-cal relations from text using conditional random fields.BMC Bioinformatics, 9.W.C.
Chou, R.T.H.
Tsai, Y-S. Su, W. Ku, T-Y Sung, andW-L Hsu.
2006.
A semi-automatic method for an-notating a biomedical proposition bank.
In Proc.
ofACL Workshop on Frontiers in Linguistically Anno-tated Corpora 2006, pages 5?12.N.
Collier, H.S.
Park, N. Ogata, Y. Tateisi, C. Nobata,T.
Sekimizu, H. Imai, and J. Tsujii.
1999.
The GE-NIA project: corpus-based knowledge acquisition andinformation extraction from genome research papers.In Proc.
of EACL 1999.T.
M. Cover and P. E. Hart.
1967.
Nearest neighborpattern classification.
Institute of Electrical and Elec-tronics Engineers Transactions on Information The-ory, 13:21?27.W.
Daelemans and A. van den Bosch.
2005.
Memory-based language processing.
Cambridge UniversityPress, Cambridge, UK.W.
Daelemans, A.
Van den Bosch, and J. Zavrel.
1999.Forgetting exceptions is harmful in language learning.Machine Learning, Special issue on Natural LanguageLearning, 34:11?41.W.
Daelemans, J. Zavrel, K. Van der Sloot, and A. Vanden Bosch.
2007.
TiMBL: Tilburg memory basedlearner, version 6.1, reference guide.
Technical ReportSeries 07-07, ILK, Tilburg, The Netherlands.J.D.
Kim, T. Ohta, and J. Tsujii.
2008.
Corpus annotationfor mining biomedical events from literature.
BMCBioinformatics, 9:10.M.
Krallinger and A. Valencia.
2005.
Text-mining andinformation-retrieval services for molecular biology.Genome Biology, 6:224.M.
Krallinger, F. Leitner, C. Rodriguez-Penagos, andA.
Valencia.
2008a.
Overview of the protein?proteininteraction annotation extraction task of BioCreativeII.
Genome Biology, 9(Suppl 2):S4.M.
Krallinger, A. Valencia, and L. Hirschman.
2008b.Linking genes to literature: text mining, informa-tion extraction, and retrieval applications for biology.Genome Biology, 9(Suppl 2):S8.R.
Morante and W. Daelemans.
2009.
A metalearningapproach to processing the scope of negation.
In Pro-ceedings of CoNLL 2009, Boulder, Colorado.R.
Morante, W. Daelemans, and V. Van Asch.
2008.
Acombined memory-based semantic role labeler of En-glish.
In Proc.
of the CoNLL 2008, pages 208?212,Manchester, UK.C.
Ne?dellec.
2005.
Learning language in logic ?
genicinteraction extraction challenge.
In Proc.
of Learn-ing Language in Logic Workshop 2005, pages 31?37,Bonn.S.
Pyysalo, F. Ginter, J. Heimonen, J. Bjo?rne, J. Boberg,J.
Ja?rvinen, and T. Salakoski.
2007.
BioInfer: a corpusfor information extraction in the biomedical domain.BMC Bioinformatics, 8(50).K.
Sagae and J. Tsujii.
2007.
Dependency parsing anddomain adaptation with lr models and parser ensem-bles.
In Proc.
of CoNLL 2007 Shared Task, EMNLP-CoNLL, pages 82?94, Prague.
ACL.Y.
Sasaki, P. Thompson, P. Cotter, J. McNaught, andS.
Ananiadou.
2008.
Event frame extraction basedon a gene regulation corpus.
In Proc.
of Coling 2008,pages 761?768.T.
Wattarujeekrit, P.K.
Shah, and N. Collier.
2004.PASBio: predicate-argument structures for event ex-traction in molecular biology.
BMC Bioinformatics,5:155.A.
Yakushiji, Y. Tateisi, Y. Miyao, and J. Tsujii.
2001.Event extraction from biomedical papers using a fullparser.
In Pac Symp Biocomput.67
