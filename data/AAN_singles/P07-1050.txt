Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 392?399,Prague, Czech Republic, June 2007. c?2007 Association for Computational Linguisticsk-best Spanning Tree ParsingKeith HallCenter for Language and Speech ProcessingJohns Hopkins UniversityBaltimore, MD 21218keith hall@jhu.eduAbstractThis paper introduces a Maximum Entropydependency parser based on an efficient k-best Maximum Spanning Tree (MST) algo-rithm.
Although recent work suggests thatthe edge-factored constraints of the MST al-gorithm significantly inhibit parsing accu-racy, we show that generating the 50-bestparses according to an edge-factored modelhas an oracle performance well above the1-best performance of the best dependencyparsers.
This motivates our parsing ap-proach, which is based on reranking the k-best parses generated by an edge-factoredmodel.
Oracle parse accuracy results arepresented for the edge-factored model and1-best results for the reranker on eight lan-guages (seven from CoNLL-X and English).1 IntroductionThe Maximum Spanning Tree algorithm1 was re-cently introduced as a viable solution for non-projective dependency parsing (McDonald et al,2005b).
The dependency parsing problem is nat-urally a spanning tree problem; however, effi-cient spanning-tree optimization algorithms assumea cost function which assigns scores independentlyto edges of the graph.
In dependency parsing, thiseffectively constrains the set of models to thosewhich independently generate parent-child pairs;1In this paper we deal only with MSTs on directed graphs.These are often referred to in the graph-theory literature asMax-imum Spanning Arborescences.these are known as edge-factored models.
Thesemodels are limited to relatively simple featureswhich exclude linguistic constructs such as verbsub-categorization/valency, lexical selectional pref-erences, etc.2In order to explore a rich set of syntactic fea-tures in the MST framework, we can either approx-imate the optimal non-projective solution as in Mc-Donald and Pereira (2006), or we can use the con-strained MST model to select a subset of the setof dependency parses to which we then apply less-constrained models.
An efficient algorithm for gen-erating the k-best parse trees for a constituency-based parser was presented in Huang and Chiang(2005); a variation of that algorithm was used forgenerating projective dependency trees for parsingin Dreyer et al (2006) and for training in McDonaldet al (2005a).
However, prior to this paper, an effi-cient non-projective k-best MST dependency parserhas not been proposed.3In this paper we show that the na?
?ve edge-factoredmodels are effective at selecting sets of parses onwhich the oracle parse accuracy is high.
The or-acle parse accuracy for a set of parse trees is thehighest accuracy for any individual tree in the set.We show that the 1-best accuracy and oracle accu-racy can differ by as much as an absolute 9% whenthe oracle is computed over a small set generated byedge-factored models (k = 50).2Labeled edge-factored models can capture selectional pref-erence; however, the unlabeled models presented here are lim-ited to modeling head-child relationships without predicting thetype of relationship.3The work of McDonald et al (2005b) would also benefitfrom a k-best non-projective parser for training.392ROOTtwoshareahousealmostdevoidoffurniture.Figure 1: A dependency graph for an English sen-tence in our development set (Penn WSJ section 24):Two share a house almost devoid of furniture.The combination of two discriminatively trainedmodels, a k-best MST parser and a parse treereranker, results in an efficient parser that includescomplex tree-based features.
In the remainder of thepaper, we first describe the core of our parser, thek-best MST algorithm.
We then introduce the fea-tures that we use to compute edge-factored scoresas well as tree-based scores.
Following, we outlinethe technical details of our training procedure and fi-nally we present empirical results for the parser onseven languages from the CoNLL-X shared-task anda dependency version of the WSJ Penn Treebank.2 MST in Dependency ParsingWork on statistical dependency parsing has utilizedeither dynamic-programming (DP) algorithms orvariants of the Edmonds/Chu-Liu MST algorithm(see Tarjan (1977)).
The DP algorithms are gener-ally variants of the CKY bottom-up chart parsing al-gorithm such as that proposed by Eisner (1996).
TheEisner algorithm efficiently (O(n3)) generates pro-jective dependency trees by assembling structuresover contiguous words in a clever way to minimizebook-keeping.
Other DP solutions use constituency-based parsers to produce phrase-structure trees, fromwhich dependency structures are extracted (Collinset al, 1999).
A shortcoming of the DP-based ap-proaches is that they are unable to generate non-projective structures.
However, non-projectivity isnecessary to capture syntactic phenomena in manylanguages.McDonald et al (2005b) introduced a model fordependency parsing based on the Edmonds/Chu-Liualgorithm.
The work we present here extends theirwork by exploring a k-best version of the MST algo-rithm.
In particular, we consider an algorithm pro-posed by Camerini et al (1980) which has a worst-case complexity of O(km log(n)), where k is thenumber of parses we want, n is the number of wordsin the input sentence, and m is the number of edgesin the hypothesis graph.
This can be reduced toO(kn2) in dense graphs4 by choosing appropriatedata structures (Tarjan, 1977).
Under the modelsconsidered here, all pairs of words are consideredas candidate parents (children) of another, resultingin a fully connected graph, thus m = n2.In order to incorporate second-order features(specifically, sibling features), McDonald et al pro-posed a dependency parser based on the Eisner algo-rithm (McDonald and Pereira, 2006).
The second-order features allow for more complex phrasal rela-tionships than the edge-factored features which onlyinclude parent/child features.
Their algorithm findsthe best solution according to the Eisner algorithmand then searches for the single valid edge changethat increases the tree score.
The algorithm iter-ates until no better single edge substitution can im-prove the score of the tree.
This greedy approxi-mation allows for second-order constraints and non-projectivity.
They found that applying this methodto trees generated by the Eisner algorithm usingsecond-order features performs better than applyingit to the best tree produced by the MST algorithmwith first-order (edge-factored) features.In this paper we provide a new evaluation of theefficacy of edge-factored models, k-best oracle re-sults.
We show that even when k is small, theedge-factored models select k-best sets which con-tain good parses.
Furthermore, these good parsesare even better than the parses selected by the bestdependency parsers.2.1 k-best MST AlgorithmThe k-best MST algorithm we introduce in this pa-per is the algorithm described in Camerini et al(1980).
For proofs of complexity and correctness,we defer to the original paper.
This section is in-tended to provide the intuitions behind the algo-rithm and allow for an understanding of the key data-structures necessary to ensure the theoretical guar-antees.4A dense graph is one in which the number of edges is closeto the number of edges in a fully connected graph (i.e., n2).393B C49851110115v1v2v3R4-2-35-101-5v4v3Rv1v2v1v210v1v21011v4v1v2v3v1v2v3v3v4v3-2v1v2v4v3v4v3-25-7-4-3v5Re32e23eR2eR1e13e314-2-35-101-5v4v3Re32e23eR2eR1e13e314-2-35-101-5v4v3Re32e23eR2eR1e13e31eR1eR2eR3v1v2v4v3v1v2v4v3v548851110115v1v2v3R-7-4-3v5ReR1eR2eR3v5R-3eR1e23e31e31Gv1v2v4v3v5S1S2S3S4S5S6S7Figure 2: Simulated 1-best MST algorithm.Let G = {V,E} be a directed graphwhere V = {R, v1, .
.
.
, vn} and E ={e11, e12, .
.
.
, e1n, e21, .
.
.
, enn}.
We refer toedge eij as the edge that is directed from vi intovj in the graph.
The initial dependency graph inFigure 2 (column G) contains three regular nodesand a root node.Algorithm 1 is a version of the MST algorithmas presented by Camerini et al (1980); subtleties ofthe algorithm have been omitted.
Arguments Y (abranching5) and Z (a set of edges) are constraints onthe edges that can be part of the solution, A. Edgesin Y are required to be in the solution and edges in5A branching is a subgraph that contains no cycles and nomore than one edge directed into each node.Algorithm 1 Sketch of 1-best MST algorithmprocedure BEST(G, Y, Z)G = (G ?
Y )?
ZB = ?C = V5: for unvisited vertex vi ?
V domark vi as visitedget best in-edge b ?
{ejk : k = i} for viB = B ?
b?
(vi) = b10: if B contains a cycle C thencreate a new node vn+1C = C ?
vn+1make all nodes of C children of vn+1 in CCOLLAPSE all nodes of C into vn+115: ADD vn+1 to list of unvisited verticesn = n + 1B = B ?
Cend ifend for20: EXPAND C choosing best way to break cyclesReturn best A = {b ?
E|?v ?
V : ?
(v) = b}and Cend procedureZ cannot be part of the solution.
The branching Cstores a hierarchical history of cycle collapses, en-capsulating embedded cycles and allowing for an ex-panding procedure, which breaks cycles while main-taining an optimal solution.Figure 2 presents a view of the algorithm whenrun on a three node graphs (plus a specified rootnode).
Steps S1, S2, S4, and S5 depict the process-ing of lines 5 to 8, recording in ?
the best input edgesfor each vertex.
Steps S3 and S6 show the process ofcollapsing a cycle into a new node (lines 10 to 16).The main loop of the algorithm processes eachvertex that has not yet been visited.
We look up thebest incoming edge (which is stored in a priority-queue).
This value is recorded in ?
and the edge isadded to the current best graph B.
We then checkto see if adding this new edge would create a cyclein B.
If so, we create a new node and collapse thecycle into it.
This can be seen in Step S3 in Figure 2.The process of collapsing a cycle into a node in-volves removing the edges in the cycle from B, andadjusting the weights of all edges directed into anynode in the cycle.
The weights are adjusted so thatthey reflect the relative difference of choosing thenew in-edge rather than the edge in the cycle.
Instep S3, observe that edge eR1 had a weight of 5, butnow that it points into the new node v4, we subtractthe weight of the edge e21 that also pointed into v1,394which was 10.
Additionally, we record in C the re-lationship between the new node v4 and the originalnodes v1 and v2.This process continues until we have visited alloriginal and newly created nodes.
At that point, weexpand the cycles encoded in C. For each node notoriginally in G (e.g., v5, v4), we retrieve the edge erpointing into this node, recorded in ?.
We identifythe node vs to which er pointed in the original graphG and set ?
(vs) = er.Algorithm 2 Sketch of next-best MST algorithmprocedure NEXT(G, Y, Z,A,C)?
?
+?for unvisited vertex v doget best in-edge b for v5: if b ?
A?
Y thenf ?
alternate edge into vif swapping f with b results in smaller ?
thenupdate ?, let e?
fend if10: end ifif b forms a cycle thenResolve as in 1-bestend ifend for15: Return edge e and ?end procedureAlgorithm 2 returns the single edge, e, of the 1-best solution A that, when removed from the graph,results in a graph for which the best solution is thenext best solution after A. Additionally, it returns?, the difference in score between A and the nextbest tree.
The branching C is passed in from Algo-rithm 1 and is used here to efficiently identify alter-nate edges, f , for edge e.Y and Z in Algorithms 1 and 2 are used to con-struct the next best solutions efficiently.
We callGY,Z a constrained graph; the constraints being thatY restricts the in-edges for a subset of nodes: foreach vertex with an in-edge in Y , only the edge ofY can be an in-edge of the vertex.
Also, edges inZ are removed from the graph.
A constrained span-ning tree for GY,Z (a tree covering all nodes in thegraph) must satisfy: Y ?
A ?
E ?
Z.Let A be the (constrained) solution to a (con-strained) graph and let e be the edge that leads to thenext best solution.
The third-best solution is eitherthe second-best solution to GY,{Z?e} or the second-best solution to G{Y ?e},Z .
The k-best ranking al-gorithm uses this fact to incrementally partition thesolution space: for each solution, the next best eitherwill include e or will not include e.Algorithm 3 k-best MST ranking algorithmprocedure RANK(G, k)A,C ?
best(E, V, ?, ?
)(e, ?)?
next(E, V, ?, ?, A, C)bestList?
A5: Q?
enqueue(s(A)?
?, e, A,C, ?, ?
)for j ?
2 to k do(s, e, A,C, Y, Z) = dequeue(Q)Y ?
= Y ?
eZ?
= Z ?
e10: A?, C?
?
best(E, V, Y, Z?)bestList?
A?e?, ??
?
next(E, V, Y ?, Z,A?, C?)Q?
enqueue(s(A)?
?
?, e?, A?, C?, Y ?, Z)e?, ??
?
next(E, V, Y, Z?, A?, C?
)15: Q?
enqueue(s(A)?
?
?, e?, A?, C?, Y, Z?
)end forReturn bestListend procedureThe k-best ranking procedure described in Algo-rithm 3 uses a priority queue, Q, keyed on the firstparameter to enqueue to keep track of the horizonof next best solutions.
The function s(A) returns thescore associated with the tree A.
Note that in eachiteration there are two new elements enqueued rep-resenting the sets GY,{Z?e} and G{Y ?e},Z .Both Algorithms 1 and 2 run inO(m log(n)) timeand can run in quadratic time for dense graphs withthe use of an efficient priority-queue6 (i.e., basedon a Fibonacci heap).
Algorithm 3 runs in con-stant time, resulting in anO(km log n) algorithm (orO(kn2) for dense graphs).3 Dependency ModelsEach of the two stages of our parser is based on a dis-criminative training procedure.
The edge-factoredmodel is based on a conditional log-linear modeltrained using the Maximum Entropy constraints.3.1 Edge-factored MST ModelOne way in which dependency parsing differs fromconstituency parsing is that there is a fixed amount ofstructure in every tree.
A dependency tree for a sen-tence of n words has exactly n edges,7 each repre-6Each vertex keeps a priority queue of candidate parents.When a cycles is collapsed, the new vertex inherits the union ofqueues associated with the vertices of the cycle.7We assume each tree has a root node.395senting a syntactic or semantic relationship, depend-ing on the linguistic model assumed for annotation.A spanning tree (equivalently, a dependency parse)is a subgraph for which each node has one in-edge,the root node has zero in-edges, and there are no cy-cles.Edge-factored features are defined over the edgeand the input sentence.
For each of the n2 par-ent/child pairs, we extract the following features:Node-type There are three basic node-type fea-tures: word form, morphologically reducedlemma, and part-of-speech (POS) tag.
TheCoNLL-X data format8 describes two part-of-speech tag types, we found that features derivedfrom the coarse tags are more reliable.
We con-sider both unigram (parent or child) and bigram(composite parent/child) features.
We refer toparent features with the prefix p- and child fea-ture with the prefix c-; for example: p?pos,p?form, c?pos, and c?form.
In our model weuse both word form and POS tag and includethe composite form/POS features: p?form/c?pos and p?pos/c?form.Branch A binary feature which indicates whetherthe child is to the left or right of the parentin the input string.
Additionally, we providecomposite features p?pos/branch and p?pos/c?pos/branch.Distance The number of words occurring betweenthe parent and child word.
These distances arebucketed into 7 buckets (1 through 6 plus an ad-ditional single bucket for distances greater than6).
Additionally, this feature is combined withnode-type features: p?pos/dist, c?pos/dist, p?pos/c?pos/dist.Inside POS tags of the words between the parentand child.
A count of each tag that occurs isrecorded, the feature is identified by the tag andthe feature value is defined by the count.
Addi-tional composite features are included combin-ing the inside and node-type: for each type tithe composite features are: p?pos/ti, c?pos/ti,p?pos/c?pos/ti.8The 2006 CoNLL-X data format can be found on-line at:http://nextens.uvt.nl/?conll/.Outside Exactly the same as the Inside feature ex-cept that it is defined over the features to theleft and right of the span covered by this parent-child pair.Extra-Feats Attribute-value pairs from the CoNLLFEATS field including combinations with par-ent/child node-types.
These features representword-level annotations provided in the tree-bank and include morphological and lexical-semantic features.
These do not exist in the En-glish data.Inside Edge Similar to Inside features, but onlyincludes nodes immediately to left and rightwithin the span covered by the parent/childpair.
We include the following features whereil and ir are the inside left and right POS tagsand ip is the inside POS tag closest to the par-ent: il/ir, p?pos/ip, p?pos/il/ir/c?pos,Outside Edge An Outside version of the InsideEdge feature type.Many of the features above were introduced inMcDonald et al (2005a); specifically, the node-type, inside, and edge features.
The number of fea-tures can grow quite large when form or lemma fea-tures are included.
In order to handle large trainingsets with a large number of features we introduce abagging-based approach, described in Section 4.2.3.2 Tree-based Reranking ModelThe second stage of our dependency parser is areranker that operates on the output of the k-bestMST parser.
Features in this model are not con-strained as in the edge-factored model.
Manyof the model features have been inspired by theconstituency-based features presented in Charniakand Johnson (2005).
We have also included featuresthat exploit non-projectivity where possible.
Thenode-type is the same as defined for the MST model.MST score The score of this parse given by thefirst-stage MST model.Sibling The POS-tag of immediate siblings.
In-tended to capture the preference for particularimmediate siblings such as modifiers.Valency Count of the number of children for eachword (indexed by POS-tag of the word).
These396counts are bucketed into 4 buckets.
For ex-ample, a feature may look like p?pos=VB/v=4,meaning the POS tag of the parent is ?VB?
andit had 4 dependents.Sub-categorization A string representing the se-quence of child POS tags for each parent POS-tag.Ancestor Grandparent and great grandparent POS-tag for each word.
Composite features are gen-erated with the label c?pos/p?pos/gp?pos andc?pos/p?pos/ggp?pos (where gp is the grand-parent and ggp is the great grand-parent).Edge POS-tag to the left and right of the subtree,both inside and outside the subtree.
For exam-ple, say a subtree with parent POS-tag p?posspans from i to j, we include composite out-side features: p?pos/ni?1?pos/nj+1?pos, p?pos/ni?1?pos, p?pos/nj+1?pos; and compositeinside features: p?pos/ni+1?pos/nj?1?pos, p?pos/ni+1?pos, p?pos/nj?1?pos.Branching Factor Average number of left/rightbranching nodes per POS-tag.
Additionally, weinclude a boolean feature indicating the overallleft/right preference.Depth Depth of the tree and depth normalized bysentence length.Heavy Number of dominated nodes per POS-tag.We also include the average number of nodesdominated by each POS-tag.4 MaxEnt TrainingWe have adopted the conditional Maximum Entropy(MaxEnt) modeling paradigm as outlined in Char-niak and Johnson (2005) and Riezler et al (2002).We can partition the training examples into indepen-dent subsets, Ys: for the edge-factored MST models,each set represents a word and its candidate parents;for the reranker, each set represents the k-best treesfor a particular sentence.
We wish to estimate theconditional distribution over hypotheses in the set yi,given the set: p(yi|Ys) =exp(Pk ?kfik)Pj:yj?Ysexp(Pk?
?k?fjk?
),where fik is the kth feature function in the modelfor example yi.4.1 MST TrainingOur MST parser training procedure involves enu-merating the n2 potential tree edges (parent/childpairs).
Unlike the training procedure employed byMcDonald et al (2005b) and McDonald and Pereira(2006), we provide positive and negative examplesin the training data.
A node can have at most oneparent, providing a natural split of the n2 trainingexamples.
For each node ni, we wish to estimatea distribution over n nodes9 as potential parents,p(vi, eji|e i), the probability of the correct parent ofvi being vj given the set of edges associated withits candidate parents e i.
We call this the parent-prediction model.4.2 MST BaggingThe complexity of the training procedure is a func-tion of the number of features and the number of ex-amples.
For large datasets, we use an ensemble tech-nique inspired by Bagging (Breiman, 1996).
Bag-ging is generally used to mitigate high variance indatasets by sampling, with replacement, from thetraining set.
Given that we wish to include someof the less frequent examples and therefore are notnecessarily avoiding high variance, we partition thedata into disjoint sets.For each of the sets, we train a model indepen-dently.
Furthermore, we only allow the parame-ters to be changed for those features observed in thetraining set.
At inference time, we apply each modelto the training data and then combine the predictionprobabilities.p??
(yi|Ys) = maxmp?m(yi|Ys) (1)p??
(yi|Ys) =1M?mp?m(yi|Ys) (2)p??
(yi|Ys) =(?mp?m(yi|Ys))1/M(3)p??
(yi|Ys) =M?m1p?m (yi|Ys)(4)Equations 1, 2, 3, and 4 are the maximum, aver-age, geometric mean, and harmonic mean, respec-tively.
We performed an exploration of these on the9Recall that in addition to the n?1 other nodes in the graph,there is a root node for which we know has no parents.397development data and found that the geometric meanproduces the best results (Equation 3); however, weobserved only very small differences in the accuracyamong models where only the combination functiondiffered.4.3 Reranker TrainingThe second stage of parsing is performed by ourtree-based reranker.
The input to the reranker is alist of k parses generated by the k-best MST parser.For each input sentence, the hypothesis set is the kparses.
At inference time, predictions are made in-dependently for each hypothesis set Ys and thereforethe normalization factor can be ignored.5 Empirical EvaluationThe CoNLL-X shared task on dependency parsingprovided data for a number of languages in a com-mon data format.
We have selected seven of theselanguages for which the data is available to us.
Ad-ditionally, we have automatically generated a depen-dency version of the Penn WSJ treebank.10 As weare only interested in the structural component of aparse in this paper, we present results for unlabeleddependency parsing.
A second labeling stage can beapplied to get labeled dependency structures as de-scribed in (McDonald et al, 2006).In Table 1 we report the accuracy for seven ofthe CoNLL languages and English.11 Already, atk = 50, we see the oracle rate climb as much as9.25% over the 1-best result (Dutch).
Continuing toincrease the size of the k-best lists adds to the oracleaccuracy, but the relative improvement appears to beincreasing at a logarithmic rate.
The k-best parser isused both to train the k-best reranker and, at infer-ence time, to select a set of hypotheses to rerank.
Itis not necessary that training is done with the samesize hypothesis set as test, we explore the matchedand mismatched conditions in our reranking experi-ments.10The Penn WSJ treebank was converted using the con-version program described in (Johansson and Nugues, 2007)and available on the web at: http://nlp.cs.lth.se/pennconverter/11The Best Reported results is from the CoNLL-X competi-tion.
The best result reported for English is the Charniak parser(without reranking) on Section 23 of the WSJ Treebank usingthe same head-finding rules as for the evaluation data.Table 2 shows the reranking results for the set oflanguages.
For each language, we select model pa-rameters on a development set prior to running onthe test data.
These parameters include a featurecount threshold (the minimum number of observa-tions of a feature before it is included in a model)and a mixture weight controlling the contribution ofa quadratic regularizer (used in MaxEnt training).For Czech, German, and English, we use the MSTbagging technique with 10 bags.
These test resultsare for the models which performed best on the de-velopment set (using 50-best parses).We see minor improvements over the 1-best base-line MST output (repeated in this table for compar-ison).
We believe this is due to the overwhelmingnumber of parameters in the reranking models andthe relatively small amount of training data.
Inter-estingly, increasing the number of hypotheses helpsfor some languages and hurts the others.6 ConclusionAlthough the edge-factored constraints of MSTparsers inhibit accuracy in 1-best parsing, edge-factored models are effective at selecting high accu-racy k-best sets.
We have introduced the Cameriniet al (1980) k-best MST algorithm and have shownhow to efficiently train MaxEnt models for depen-dency parsing.
Additionally, we presented a uni-fied modeling and training setting for our two-stageparser; MaxEnt training is used to estimate the pa-rameters in both models.
We have introduced aparticular ensemble technique to accommodate thelarge training sets generated by the first-stage edge-factored modeling paradigm.
Finally, we have pre-sented a reranker which attempts to select the besttree from the k-best set.
In future work we wishto explore more robust feature sets and experimentwith feature selection techniques to accommodatethem.AcknowledgmentsThis work was partially supported by U.S. NSFgrants IIS?9982329 and OISE?0530118.
We thankRyan McDonald for directing us to the Camerini etal.
paper and Liang Huang for insightful comments.398Language Best Oracle AccuracyReported k = 1 k = 10 k = 50 k = 100 k = 500Arabic 79.34 77.92 80.72 82.18 83.03 84.47Czech 87.30 83.56 88.50 90.88 91.80 93.50Danish 90.58 89.12 92.89 94.79 95.29 96.59Dutch 83.57 81.05 87.43 90.30 91.28 93.12English 92.36 85.04 89.04 91.12 91.87 93.42German 90.38 87.02 91.51 93.39 94.07 95.47Portuguese 91.36 89.86 93.11 94.85 95.39 96.47Swedish 89.54 86.50 91.20 93.37 93.83 95.42Table 1: k-best MST oracle results.
The 1-best results represent the performance of the parser in isolation.Results are reported for the CoNLL test set and for English, on Section 23 of the Penn WSJ Treebank.Language Best Reranked AccuracyReported 1-best 10-best 50-best 100-best 500-bestArabic 79.34 77.61 78.06 78.02 77.94 77.76Czech 87.30 83.56 83.94 84.14 84.48 84.46Danish 90.58 89.12 89.48 89.76 89.68 89.74Dutch 83.57 81.05 82.01 82.91 82.83 83.21English 92.36 85.04 86.54 87.22 87.38 87.81German 90.38 87.02 88.24 88.72 88.76 88.90Portuguese 91.36 89.38 90.00 89.98 90.02 90.02Swedish 89.54 86.50 87.87 88.21 88.26 88.53Table 2: Second-stage results from the k-best parser and reranker.
The Best Reported and 1-best fields arecopied from table 1.
Only non-lexical features were used for the reranking models.ReferencesLeo Breiman.
1996.
Bagging predictors.
Machine Learning,26(2):123?140.Paolo M. Camerini, Luigi Fratta, and Francesco Maffioli.
1980.The k best spanning arborescences of a network.
Networks,10:91?110.Eugene Charniak and Mark Johnson.
2005.
Coarse-to-fine n-best parsing and MaxEnt discriminative reranking.
In Pro-ceedings of the 43rd Annual Meeting of the Association forComputational Linguistics.Michael Collins, Lance Ramshaw, Jan Hajic?, and ChristophTillmann.
1999.
A statistical parser for Czech.
In Pro-ceedings of the 37th annual meeting of the Association forComputational Linguistics, pages 505?512.Markus Dreyer, David A. Smith, and Noah A. Smith.
2006.Vine parsing and minimum risk reranking for speed and pre-cision.
In Proceedings of the Tenth Conference on Compu-tational Natural Language Learning.Jason Eisner.
1996.
Three new probabilistic models for de-pendency parsing: An exploration.
In Proceedings of the16th International Conference on Computational Linguistics(COLING), pages 340?345.Liang Huang and David Chiang.
2005.
Better k-best parsing.In Proceedings of the 9th International Workshop on ParsingTechnologies.Richard Johansson and Pierre Nugues.
2007.
Extendedconstituent-to-dependency conversion for English.
In Pro-ceedings of NODALIDA 2007, Tartu, Estonia, May 25-26.To appear.Ryan McDonald and Fernando Pereira.
2006.
Online learningof approximate dependency parsing algorithms.
In Proceed-ings of the Annual Meeting of the European Association forComputational Linguistics.Ryan McDonald, Koby Crammer, and Fernando Pereira.2005a.
Online large-margin training of dependency parsers.In Proceedings of the 43nd Annual Meeting of the Associa-tion for Computational Linguistics.Ryan McDonald, Fernando Pereira, Kiril Ribarov, and JanHajic?.
2005b.
Non-projective dependency parsing usingspanning tree algorithms.
In Proceedings of Human Lan-guage Technology Conference and Conference on EmpiricalMethods in Natural Language Processing, pages 523?530,October.Ryan McDonald, Kevin Lerman, and Fernando Pereira.
2006.Multilingual dependency parsing with a two-stage discrimi-native parser.
In Conference on Natural Language Learning.Stefan Riezler, Tracy H. King, Ronald M. Kaplan, RichardCrouch, John T. III Maxwell, and Mark Johnson.
2002.Parsing the Wall Street Journal using a lexical-functionalgrammar and discriminative estimation techniques.
In Pro-ceedings of the 40th Annual Meeting of the Association forComputational Linguistics.
Morgan Kaufmann.R.E.
Tarjan.
1977.
Finding optimal branchings.
Networks,7:25?35.399
