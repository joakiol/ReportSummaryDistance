Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1477?1487,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsArgument Inference from Relevant Event Mentions in ChineseArgument ExtractionPeifeng Li, Qiaoming Zhu, Guodong Zhou*School of Computer Science & TechnologySoochow University, Suzhou, 215006, China{pfli, qmzhu, gdzhou}@suda.edu.cnAbstractAs a paratactic language, sentence-levelargument extraction in Chinese suffersmuch from the frequent occurrence ofellipsis with regard to inter-sentencearguments.
To resolve such problem, thispaper proposes a novel global argumentinference model to explore specificrelationships, such as Coreference,Sequence and Parallel, among relevantevent mentions to recover those inter-sentence arguments in the sentence,discourse and document layers whichrepresent the cohesion of an event or atopic.
Evaluation on the ACE 2005Chinese corpus justifies the effectivenessof our global argument inference modelover a state-of-the-art baseline.1 IntroductionThe task of event extraction is to recognize eventmentions of a predefined event type and theirarguments (participants and attributes).Generally, it can be divided into two subtasks:trigger extraction, which aims to identifytrigger/event mentions and determine their eventtype, and argument extraction, which aims toextract various arguments of a specific event andassign the roles to them.
In this paper, we focuson argument extraction in Chinese eventextraction.
While most of previous studies inChinese event extraction deal with Chinesetrigger extraction (e.g., Chen and Ji, 2009a; Qinet al, 2010; Li et al, 2012a, 2012b), there areonly a few on Chinese argument extraction (e.g.,Tan et al, 2008; Chen and Ji, 2009b).
Followingprevious studies, we divide argument extractioninto two components, argument identificationand role determination, where the formerrecognizes the arguments in a specific eventmention and the latter classifies these argumentsby roles.With regard to methodology, most of previousstudies on argument extraction recast it as aSemantic Role Labeling (SRL) task and focus onintra-sentence information to identify thearguments and their roles.
However, argumentextraction is much different from SRL in thesense that, while the relationship between apredicate and its arguments in SRL can bemainly decided from the syntactic structure, therelationship between an event trigger and itsarguments are more semantics-based, especiallyin Chinese, as a paratactic (e.g., discourse-drivenand pro-drop) language with the wide spread ofellipsis and the open flexible sentence structure.Therefore, some arguments of a specific eventmention are far away from the trigger and how torecover those inter-sentence arguments becomesa challenging issue in Chinese argumentextraction.
Consider the following discourse(from ACE 2005 Chinese corpus) as a sample:D1: ???????????????
20 ?????????????(E1)?????(E2)?????????????(E3)???????
(The Palestinian National Authoritydenied any involvement in the bomb attack (E2)occurred in the Gaza Strip on the morning of the20th, which killed (E1) two Israelites.
?
Theyclaimed that they will be investigating thisattack (E3).)
- From CBS20001120.1000.0823In above discourse, there are three eventmentions, one kill (E1) and two Attack (E2, E3).While it is relatively easy to identify 20???
(morning of 20th), ????
(Gaza Strip) and ??
(bomb) as the Time, Place and Instrumentroles in E2 by a sentence-based argument1477extractor, it is really challenging to recognizethese entities as the arguments of its coreferedmention E3 since to reduce redundancy in aChinese discourse, the later Chinese sentencesomit many of these entities already mentioned inprevious sentences.
Similarly, it is hard torecognize ??????
(two Israelites) as theTarget role for event mention E2 and identify??
(bomb) as the Instrument role for eventmention E1.
An alternative way is to employvarious relationships among relevant eventmentions in a discourse to infer those inter-sentence arguments.The contributions of this paper are:1) We propose a novel global argumentinference model, in which various kinds ofevent relations are involved to infer morearguments on their semantic relations.2) Different from Liao and Grishman (2010)and Hong et al (2011), which only considerdocument-level consistency, we propose amore fine-gained consistency model toenforce the consistency in the sentence,discourse and document layers.3) We incorporate argument semantics into ourglobal argument inference model to unify thesemantics of the event and its arguments.The rest of this paper is organized as follows.Section 2 overviews the related work.
Section 3describes a state-of-the-art Chinese argumentextraction system as the baseline.
Section 4introduces our global model in inferring thoseinter-sentence arguments.
Section 5 reportsexperimental results and gives deep analysis.Finally, we conclude our work in Section 6.2 Related WorkAlmost all the existing studies on argumentextraction concern English.
While some applypattern-based approaches (e.g., Riloff, 1996;Califf and Mooney, 2003; Patwardhan and Riloff,2007; Chambers and Jurafsky, 2011), the othersuse machine learning-based approaches (e.g.,Grishman et al, 2005; Ahn, 2006; Patwardhanand Riloff, 2009; Lu and Roth, 2012), most ofwhich rely on various kinds of features in thecontext of a sentence.
In comparison, there areonly a few studies exploring inter-sentenceinformation or argument semantics (e.g., Liaoand Grishman, 2010; Hong et al, 2011; Huangand Riloff, 2011, 2012).Compared with the tremendous work onEnglish event extraction, there are only a fewstudies (e.g., Tan et al, 2008; Chen and Ji, 2009b;Fu et al, 2010; Qin et al, 2010; Li et al, 2012)on Chinese event extraction with focus on eitherfeature engineering or trigger expansion, underthe same framework as English triggeridentification.
In additional, there are only veryfew of them focusing on Chinese argumentextraction and almost all aim to featureengineering and are based on sentence-levelinformation and recast this task as an SRL-styletask.
Tan et al (2008) introduce multiple levelsof patterns to improve the coverage in Chineseargument classification.
Chen and Ji (2009b)apply various kinds of lexical, syntactic andsemantic features to address the special issues inChinese argument extraction.
Fu et al (2010) usea feature weighting scheme to re-weight variousfeatures for Chinese argument extraction.
Li et al(2012b) introduce more refined features to thesystem of Chen and Ji (2009b) as their baseline.Specially, several studies have successfullyincorporated cross-document or document-levelinformation and argument semantics into eventextraction, most of them focused on English.Yangarber et al (2007) apply a cross-document inference mechanism to refine localextraction results for the disease name, locationand start/end time.
Mann (2007) proposes someconstraints on relationship rescoring to imposethe discourse consistency on the CEO?s personalinformation.
Chambers and Jurafsky (2008)propose a narrative event chain which arepartially ordered sets of event mentions centeredaround a common protagonist and this chain canrepresent the relationship among the relevantevent mentions in a document.Ji and Grishman (2008) employ a rule-basedapproach to propagate consistent triggers andarguments across topic-related documents.
Liaoand Grishman (2010) mainly focus on employingthe cross-event consistency information toimprove sentence-level trigger extraction andthey also propose an inference method to inferthe arguments following role consistency in adocument.
Hong et al (2011) employ thebackground information to divide an entity typeinto more cohesive subtypes to create the bridgebetween two entities and then infer argumentsand their roles using cross-entity inference on thesubtypes of entities.
Huang and Rillof (2012)propose a sequentially structured sentenceclassifier which uses lexical associations anddiscourse relations across sentences to identifyevent-related document contexts and then applyit to recognize arguments and their roles on therelation among triggers and arguments.14783 BaselineIn the task of event extraction as defined in ACEevaluations, an event is defined as a specificoccurrence involving participants (e.g., Person,Attacker, Agent, Defendant) and attributes (e.g.,Place, Time).
Commonly, an event mention istriggered via a word (trigger) in a phrase orsentence which clearly expresses the occurrenceof a specific event.
The arguments are the entitymentions involved in an event mention with aspecific role, the relation of an argument to anevent where it participates.
Hence, extracting anevent consists of four basic steps, identifying anevent trigger, determining its event type,identifying involved arguments (participants andattributes) and determining their roles.As the baseline, we choose a state-of-the-artChinese event extraction system, as described inLi et al (2012b), which consists of four typicalcomponents: trigger identification, event typedetermination, argument identification and roledetermination.
In their system, the former twocomponents, trigger identification and event typedetermination, are processed in a joint model,where the latter two components are run in apipeline way.
Besides, the Maximum-Entropy(ME) model is employed to train individualcomponent classifiers for above four components.This paper focuses on argument identificationand role determination.
In order to provide astronger baseline, we introduce more refinedfeatures in such two components, besides thoseadopted in Li et al (2012b).
Following is a list offeatures adopted in our baseline.1) Basic features: trigger, POS (Part Of Speech)of the trigger, event type, head word of theentity, entity type, entity subtype;2) Neighbouring features: left neighbouringword of the entity + its POS, right neighbourword of the entity + its POS, left neighbourword of the trigger + its POS, right neighbourword of the trigger + its POS;3) Dependency features: dependency path fromthe entity to the trigger, depth of thedependency path;4) Syntactic features: path from the trigger to theentity, difference of the depths of the triggerand entity, place of the entity (before triggeror after trigger), depth of the path from thetrigger to the entity, siblings of the entity;5) Semantic features: semantic role of the entitytagged by an SRL tool (e.g., ARG0, ARG1)(Li et al, 2010), sememe of trigger in Hownet(Dong and Dong, 2006).4 Inferring Inter-Sentence Argumentson Relevant Event MentionsIn this paper, a global argument inference modelis proposed to infer those inter-sentencearguments and their roles, incorporating withsemantic relations between relevant eventmention pairs and argument semantics.4.1 MotivationIt?s well-known that Chinese is a paratacticlanguage, with an open flexible sentencestructure and often omits the subject or the object,while English is a hypotactic language with astrict sentence structure and emphasizes oncohesion between clauses.
Hence, there are twoissues in Chinese argument extraction, associatedwith its nature of the paratactic language.The first is that many arguments of an eventmention are out of the event mention scope sinceellipsis is a common phenomenon in Chinese.We call them inter-sentence arguments in thispaper.
Table 1 gives the statistics of intra-sentence and inter-sentence arguments in theACE 2005 Chinese corpus and it shows that20.8% of the arguments are inter-sentence oneswhile this figure is less than 1% of the ACE 2005English corpus.
The main reason of thatdifference is that some Chinese arguments areomitted in the same sentence of the trigger sinceChinese is a paratactic language with the widespread of ellipsis.
Besides, a Chinese sentencedoes not always end with a full stop.
In particular,a comma is used frequently as the stop sign of asentence in Chinese.
We detect sentenceboundaries, relying on both full stop and commasigns, since in a Chinese document, comma canbe also used to sign the end of a sentence.
Inparticular, we detect sentence boundaries on fullstop, exclamatory mark and question mark firstly.Then, we identify the sentence boundaries oncomma, using a binary classifier with a set oflexical and constituent-based syntactic features,similar to Xue and Yang (2010).Category Number#Arguments 8032#Inter-sentence 1673(20.8%)#Intra-sentence 6359(79.2%)Table 1.
Statistics: Chinese argument extractionwith regard to intra- sentence and inter-sentencearguments.The second issue is that the Chinese wordorder in a sentence is rather agile for the open1479flexible sentence structure.
Hence, different wordorders can often express the same semantics.
Forexample, a Die event mention ?Three persondied in this accident.?
can be expressed in manydifferent orders in Chinese, such as ??????????
?, ?????????
?, ??????????
?, etc.In a word, above two issues indicate thatsyntactic feature-based approaches are limited inidentifying Chinese arguments and it will lead tolow recall in argument identification.
Therefore,employing those high level information tocapture the semantic relation, not only thesyntactic structure, between the trigger and itslong distance arguments is the key to improvethe performance of the Chinese argumentidentification.
Unfortunately, it is really hard tofind their direct relations since they alwaysappear in different clauses or sentences.
Analternative way is to link the different eventmentions with their predicates (triggers) and usethe trigger as a bridge to connect the argumentsto the trigger in another event mention indirectly.Hence, the semantic relations among eventmentions are helpful to be a bridge to identifythose inter-sentence arguments.4.2 Relations of Event Mention PairsIn a discourse, most event mentions aresurrounding a specific topic.
It?s obvious thatthose mentions have the intrinsic relationships toreveal the essential structure of a discourse.Those relevant semantics-based relations arehelpful to infer the arguments for a specifictrigger mention when the syntactic relations inChinese argument extraction are not as effectiveas that in English.
In this paper, we divide therelations among relevant event mentions intothree categories: Coreference, Sequence andParallel.An event may have more than one mention ina document and coreference event mentions referto the same event, as same as the definition in theACE evaluations.
Those coreference eventmentions always have the same arguments androles.
Therefore, employing this relation caninfer the arguments of an event mention fromtheir Coreference ones.
For example, we canrecover the Time, Place and Instrument for E3via its Coreference mention E2 in discourse D1,mentioned in Section 1.Li et al (2012a) find out that sometimes twotrigger mentions are within a Chinese wordwhose morphological structure is Coordination.Take the following sentence as a sample:D2: ??
17 ????????????(E4)?
(E5)?????
(A 12-year-old youngerhijacked a bus and then stabbed (E4) a womanto death (E5).)
- From ZBN20001218.0400.0005In D2, ??
(stab a person to death) is atrigger with the Coordination structure and canbe divided into two single-morpheme words ?
(stab) and ?
(die) while the former triggers anAttack event and the latter refers to a Die one.It?s interesting that they share all arguments inthis sentence.
The relation between those eventmentions whose triggers merge a Chinese wordor share the subject and the object are Parallel.For the errors in the syntactic parsing, the secondsingle-morpheme trigger is often assigned awrong tag (e.g., NN, JJ) and this leads to theerrors in the argument extraction.
Therefore,inferring the arguments of the second single-morpheme trigger from that of the first one basedon Parallel relation is also an available way torecover arguments.Like that the topic is an axis in a discourse, therelations among those relevant event mentionswith the different types is the bone to link theminto a narration.
There are a few studies on usingthe event relations in NLP (e.g., summarization(Li et al, 2006), learning narrative event chains(Chambers and Jurafsky, 2007)) to ensure itseffectiveness.
In this paper, we define two typesof Sequence relations of relevant event mentions:Cause and Temporal for their high probabilitiesof sharing arguments.The Cause relation between the eventmentions are similar to that in the PennDiscourse TreeBank 2.0 (Prasad et al, 2008).For example, an Attack event often is the causeof an Die or Injure event.
Our Temporal relationis limited to those mentions with the same orrelevant event types (e.g., Transport and Arrest)for the high probabilities of sharing arguments.Take the following discourse as a sample:D3: ??????(E6)??????????????(E7)?????????????
(These prisoners left (E6) Tindouf, a westerncity of Algeria, and went (E7) to Agadir, asouthwestern city of Morocco.)
- FromXin20001215.2000.0158In D3, there are two Transport mentions and itis natural to infer ????
(Agadir) as theDestination role of E6 and???
(Tindouf) asthe Origin role of E7 via their Sequence relation.14804.3 Identifying Relations of Event MentionPairsCurrently, there are only few studies focusing onsuch area (e.g., Ahn, 2006; Chamber andJurafsky, 2007; Huang and Rillof, 2012; Do et al,2012) and their approaches cannot be introducedto our system directly for the language natureand the different goal.
We try to achieve a higheraccuracy in this stage so that our argumentinference can recover more true arguments.Inspired by Li and Zhou (2012), we also usethe morphological structure to identify theParallel relation.
Two parallel event mentionswith the adjacent trigger mentions w1 and w2 mustsatisfy follows two conditions:1) Morph(w1,w2) is Coordination2) jiTwHMTwHM ji ???
)(,)( 21where Morph(w1,w2) is a function to recognizethe morphological structure of joint word w1w2,HM(wi) is to identify the head morpheme 1  inword wi and Ti is the set of the head morphemeswith ith event type.
These constraints areenlightened by the fact that only Chinese wordswith Coordination structure can be divided intotwo new words and each word can trigger anevent with the different event type 2 .
Theimplementation of Morph(w1,w2) and HM(w) aredescribed in Li and Zhou (2012).The Coreference relation is divided into twotypes: Noun-based Coreference (NC) and Event-based Coreference (EC) while the former alwaysuses a verbal noun to refer to an event mentionedin current or previous sentence and the latter isthat an event is mentioned twice or more actually.For example, the relation between E2 and E3 inD1 is NC while the trigger of E3 is only a verbalnoun without any direct arguments and it refersto E2.We adopt a simple rule to recognize those NCrelations: for each event mention whose trigger isa noun and doesn?t act as the subject/object, weregard their relation as NC if there is anotherevent mention with the same trigger in current orprevious sentence.Inspired by Ahn (2006), we use the followingconditions to infer the EC relations between twoevent mentions with the same event type:1) Their trigger mentions refer to the sametrigger;2) They have at least one same or similar1 It acts as the governing semantic element in a Chineseword.2 If they have the same event type, they will be regarded asa single event mention.subject/object;3) The score of cosine similarity of two eventmentions is more than a threshold3.Finally, for the Sequence relation, instead ofidentifying and classifying the relations clearlyand correctly, our goal is to identify whetherthere are relevant event mentions in a longsentence or two adjacent short sentences whoshare arguments.
Algorithm 1 illustrates aknowledge-based approach to identify theSequence event relation in a discourse for anytwo trigger mentions tri1 and tri2 as follows:Algorithm 11: input: tri1 and tri2 and their type et1 and et22:  output: whether their relation is Sequence3:  begin4:      hm1 ?HM(tri1);  hm2 ?HM(tri2)5:  MP ?FindAllMP(hm1,et1,hm2,et2)6:     for any mpi in MP7:         if ShareArg(mpi) is true then8:             return true   // Sequence9:        end if10:    end for11:    return false12:  endIn algorithm 1, HM(tri) is to identify the headmorpheme in trigger tri and FindAllMP(hm1, et1,hm2, et2) is to find all event mention pairs in thetraining set which satisfy the condition that theirhead morphemes are hm1 and hm2, and theirevent types are et1 and et2 respectively.
Besides,ShareArg(mpi)is used to identify whether theevent mention pair mpi sharing at least oneargument.
In this algorithm, since the relationson the event types are too coarse, we introduce amore fine-gained Sequence relation both on theevent types and the head morphemes of thetriggers which can divide an event type intomany subtypes on the head morpheme.
Li andZhou (2012) have ensured the effectiveness ofusing head morpheme to infer the triggers andour experiment results also show it is helpful foridentifying relevant event mentions which aimsto the higher accuracy.4.4 Global Argument Inference ModelOur global argument inference model iscomposed of two steps: 1) training two sentence-based classifiers: argument identifier (AI) androle determiner (RD) that estimate the score of acandidate acts as an argument and belongs to a3 The threshold is tuned to 0.78 on the training set.1481specific role following Section 3.
2) Using thescores of two classifiers and the event relationsin a sentence, a discourse or a document, weperform global optimization to infer thosemissing or long distance arguments and theirroles.To incorporate those event relations with ourglobal argument inference model, we regard adocument as a tree and divide it into three layers:document, discourse and sentence.
A documentis composed of a set of the discourses while adiscourse contains three sentences.
Since almostall arguments (~98%) of a specific event mentionin the ACE 2005 Chinese corpus appear in thesentence containing the specific event mentionand its two adjacent sentences (previous and nextsentences), we only consider these threesentences as a discourse to simplify the processof identifying the scope of a discourse.We incorporate different event relations intoour model on the different layer and the goal ofour global argument inference model is toachieve the maximized scores over a documenton its three layers and two classifiers: AI and RD.The score of document D is defined as))1))(,(1(),(()1())1))((1()(((maxarg,,, ,,, ,,, ,,, ,,,^><><?
?>< ><?>< ><?
??
?>< ><?>< ><???++?+??+=?
?
?
?
??
?
?
?mZmZDmZmZDDiI iIjiS jiSkjiT kjiTZA RmZZIZZIDiI iIjiS jiSkjiT kjiTZAYXYREfYREfXEfXEfD??(1)}1,0{..
?ZXts                                          (2)}1,0{, ?>< mZY                                  (3)RmYX mZZ ???
>< ,                       (4)?
?RmmZZ YX ><= ,                               (5)where Ii is the ith discourses in document D;S<i,j> is the jth sentences in discourse Ii; T<i,j,k> isthe kth event mentions in sentence S<i,j>; A<i,j,k,l>is the lth candidate arguments in event mentionT<i,j,k>; Z is used to denote <i,j,k,l>; fI(EZ) is thescore of AI identifying entity mention EZ as anargument, where EZ is the lth entity of the kthevent mention of the jth sentence of the ithdiscourse in document D. fD(EZ, Rm) is the scoreof RD assigning role Rm to argument EZ.
Finally,XZ and Y<Z,m> are the indicators denoting whetherentity EZ is an argument and whether the role Rmis assigned to entity EZ respectively.
Besides, Eq.4 and Eq.
5 are the inferences to enforce that:1) if an entity belongs to a role, it must be anargument;2) if a entity is an argument of a specific eventmention, it must have a role.Parallel relation: Sentence-basedoptimization is used to incorporate the Parallelrelation of two event mentions into our modeland they share all arguments in a sentence.
Sincedifferent event type may have different role set,each role in a specific event should be mapped tothe corresponding role in its Parallel event whenthey have the different event type.
For example,the argument ???
17 ?????
(A 12-year-old younger) in D2 acts as the Attacker role inthe Attack event and the Agent role in the Dieevent.
We learn those role-pairs from the trainingset and Table 2 shows part of the role relationslearning from the training set.Event type pair Role pairAttack-Die Attacker-Agent; Target-Victim;?Injure-Die Agent-Agent; Victim-Victim;?Transport-DemonstrateArtifact-Entity;Destination-Place;?Table 2.
Part of role-pairs for those eventmention pairs with Parallel relation.To infer the arguments and their roles on theParallel relation, we enforce the consistency onthe role-pair as follows:><><?><><><><><><><><><><=?>?<??????????
?=',',,,,,'',,',',,,,,,,,',',,,,',',',,,,,,',,lkjilkjihethetkjilkjikjilkjijikjikjiijiimlkjimlkjiEERPmmTATASTTISDIYY(6)where'hh etetRP ?
is the set of role-pairs betweentwo Parallel event mention eth and eth?
and><>< = ',',,,,, lkjilkji EE  means they refer to thesame entity mention.
With the transitivitybetween the indicators X and Y, Eq.
6 alsoenforces the consistency on X<i,j,k,l> and X<i,j,k?,l?>.Coreference relation: Since the NC and ECrelcation between two event mentions aredifferent in the event expression, we introducethe discourse-based optimization for the formerand document-based optimization for the latter.For two NC mentions, we ensure that thesucceeding mentions can inherit the argumentsform the previous one.
To enforce thisconsistency, we just replace all fI(EZ) and fD(EZ,Rm) of the succeeding event mention with that ofthe previous one, since the previous one have themore context information.As for two EC event mentions, algorithm 2shows how to create the constraints for our1482global argument inference model to inferarguments and roles.Algorithm 21: input: two event mentions T, T?
and theirarguments set A and A?2:  output: the constraints set C3:  begin4:       for each argument a in A do5:            a?
?FindSim(a)6:    if a???
then7:                 ),( 'aa YYyConsistencCC ?
?8:             end if9:        end for10: endIn algorithm 2, the function FindSim(a) isused to find a similar candidate argument a?
inA?
for a.
If it?s found, we enforce the consistencyof argument a and a?
in the role by usingConsistency(Ya,Ya?)
where Ya  and Ya?
are theindicators in Eq.
1.
To evaluate the similaritybetween two candidates a and a?, we regard themas similar ones when they are the same word orin the same entity coreference chain.
We use acoreference resolution tool to construct the entitycoreference chains, as described in Kong et al(2010).Sequence relation: For any two eventmentions in a discourse, we use the event typepair with their head morphemes (e.g., Attack:?
(burst) - Die:?
(die), Trial-Hearing:?
(trial) -Sentence:?
(sentence)) to search the training setand then obtain the probabilities of sharing thearguments as mentioned in algorithm 1.
Wedenoted Pro<et,et?,HM(tri),HM(tri?
),Rm,Rm?> as theprobability of the trigger mentions tri and tri?
(their event types are et and et?
respectively.
)sharing an argument whose roles are Rm and Rm?respectively.
We propose following discourse-based constraint to enforce the consistencybetween the roles of two arguments, which arerelated semantically, temporally, causally orconditionally, based on the probability of sharingan argument and the absolute value of thedifference between the scores of RD:??>>=?????=><><><><><><><><><><><><),(),(),),'(),(,',(Pr',,?'',',',,,,'',',',,,,',',',,,,',,',',',',,,,,mlkjiDmlkjiDmmlkjilkjijikjijikjiijijiimlkjimlkjiREfREfRRtriHMtriHMetetoEERmmSTSTISSDIYY???????
(7)where ?
and ?
are the thresholds learned from thedevelopment set; tri and tri?
are triggers of kthand k?th event mention whose event types are etand et?
in S<i,j> and S<i,j?> respectively.4.5 Incorporating Argument Semantics intoGlobal Argument Inference ModelWe also introduce the argument semantics,which represent the semantic relations ofargument-argument pair, argument-role pair andargument-trigger pair, to reflect the cohesioninside an event.
Hong et al (2011) found out thatthere is a strong argument and role consistency inthe ACE 2005 English corpus.
Thoseconsistencies also occur in Chinese and theyreveal the relation between the trigger and itsarguments, and also explore the relation betweenthe argument and its role.
Besides, those entitiesact as non-argument also have the consistencywith high probabilities.To let the global argument inference modelcombine those knowledges of argumentsemantics, we compute the prior probabilitiesP(X<i,j>=1) and P(Y<i,j,m>=1) that entity enjoccurrs in a specific event type eti as anargument and its role is Rm respectively.
Toovercome the sparsity of the entities, we clusterthose entities into more cohesive subtypefollowing Hong et al (2011).
Hence, followingthe independence assumptions described byBerant et al (2011), we modify the fI(EZ) andfD(EZ,Rm)in Eq.
1 as follows:)0()|1(1()1()|1(log)( ==?===ZZZZZZZI XPFXPXPFXPEf     (8))0()|1(1()1()|1(log),(,,,,,,==?===><><><><><><mZmZmZmZmZmZmZD XPFXPXPFYPREf (9)where )|1( ZZ FXP =  and )|1( ,, ><>< = mZmZ FYPare the probabilities from the AI and ADrespectively while FZ and F<Z,m> are the featurevectors.
Besides, )1( , =>< mZXP  and )1( =ZXPare the prior probabilities learning from thetraining set.5 ExperimentationIn this section, we first describe the experimentalsettings and the baseline, and then evaluate ourglobal argument inference model incorporatingwith relevant event mentions and argumentsemantics to infer arguments and their roles.5.1 Experimental Settings and BaselineFor fair comparison, we adopt the sameexperimental settings as the state-of-the-art eventextraction system (Li et al 2012b) and all the1483evaluations are experimented on the ACE 2005Chinese corpus.
We randomly select 567documents as the training set and the remaining66 documents as the test set.
Besides, we reserve33 documents in the training set as thedevelopment set and use the ground truth entities,times and values for our training and testing.
Asfor evaluation, we also follow the standards asdefined in Li et al (2012b).
Finally, all thesentences in the corpus are divided into wordsusing a Chinese word segmentation tool(ICTCLAS) 1  with all entities annotated in thecorpus kept.
We use Berkeley Parser 2  andStanford Parser 3  to create the constituent anddependency parse trees.
Besides, the ME tool(Maxent) 4  is employed to train individualcomponent classifiers and lp_solver5 is used toconstruct our global argument inference model.Besides, all the experiments on argumentextraction are done on the output of the triggerextraction system as described in Li et al(2012b).
Table 3 shows the performance of thebaseline trigger extraction system and Line 1 inTable 4 illustrates the results of argumentidentification and role determination based onthis system.TriggeridentificationEvent typedeterminationP(%) R(%) F1 P(%) R(%) F174.4 71.9 73.1 71.4 68.9 70.2Table 3.
Performance of the baseline on triggeridentification and event type determination.5.2 Inferring Arguments on Relevant EventMentions and Argument SemanticsWe develop a baseline system as mentioned inSection 3 and Line 2 in Table 4 shows that itslightly improves the F1-measure by 0.9% overLi et al (2012b) due to the incorporation of morerefined features.
This result indicates thelimitation of syntactic-based feature engineering.Before evaluating our global argumentinference model, we should identify the eventrelations between two mentions in a sentence, adiscourse or a document.
The experimentalresults show that the accuracies of identifyingNC, EC, Parallel and Sequence relation are80.0%, 72.4%, 88.5% and 87.7% respectively.Those results ensure that our simple methods are1http://ictclas.org/2 http://code.google.com/p/berkeleyparser/3 http://nlp.stanford.edu/software/lex-parser.shtml4 http://mallet.cs.umass.edu/5 http://lpsolve.sourceforge.net/5.5/effective.
Our statistics on the development setshows almost 65% of the event mentions areinvolved in those Correfrence, Parallel andSequence relations, which occupy 63%, 50%, 9%respectively6.
Most of the exceptions are isolatedevent mentions.SystemArgumentidentificationArgument roledeterminationP(%) R(%) F1 P(%) R(%) F1Li et al(2012b) 59.1 57.2 58.1 55.8 52.1 53.9Baseline 60.5 57.6 59.0 55.7 53.0 54.4BIM 59.3 60.1 59.7 54.4 55.2 54.8BIM+RE 60.2 65.6 62.8 55.0 60.0 57.4BIM+RE+AS 62.9 66.1 64.4 57.2 60.2 58.7Table 4.
Performance comparison of argumentextraction on argument identification and roledetermination.Once the classifier AI and RD are trained, wewould like to apply our global argumentinference model to infer more inter-sentencearguments and roles.
To achieve an optimalsolution, we formulate the global inferenceproblem as an Integer Linear Program (ILP),which leads to maximize the objective function.ILP is a mathematical method for constraint-based inference to find the optimal values for aset of variables that maximize an objectivefunction in satisfying a certain number ofconstraints.
In the literature, ILP has been widelyused in many NLP applications (e.g., Barzilayand Lapata, 2006; Do et al, 2012; Li et al,2012b).For our systems, we firstly evaluate theperformance of our basic global argumentinference model (BIM) with the Eq.
2?5 whichenforce the consistency on AI and RD and thenintroduce the inference on the relevant eventmentions (RE) and argument semantics (AS) toBIM.
Table 4 shows their results and we can findout that:1) BIM only slightly improves the performancein F1-measure, as the result of more increasein recall (R) than decrease in precision (P).This suggests that those constraints justenforcing the consistency on AI and RD is noteffective enough to infer more arguments.2) Compared to the BIM, our model BIM+REenhances the performance of argumentidentification and role determination by 3.1%and 2.6% improvement in F1-measurerespectively.
This suggests the effectiveness6 20% of the mentions belongs to both Coreference andSequence relations.1484of our global argument inference model onthe relevant event mentions to infer inter-sentence arguments.
Table 5 shows thecontributions of the different event relationswhile the Sequence relation gains the highestimprovement of argument identification androle determination in F1-measure respectively.ConstraintArgumentidentificationArgument roledeterminationP(%) R(%) F1 P(%) R(%) F1BIM 59.3 60.1 59.7 54.4 55.2 54.8+Parallel +0.6 +0.7 +0.6 +0.4 +0.6 +0.5+NC +0.0 +0.8 +0.4 -0.2 +0.6 +0.2+EC +0.6 +1.2 +0.9 +0.5 +1.0 +0.7+ Sequence -0.3 +2.8 +1.2 -0.2 +2.6 +1.1Table 5.
Contributions of different eventrelations on argument identification and roledetermination.
(Incremental)3) Our model BIM+ER+AS gains 1.6%improvement for argument identification, and1.3% for role determination.
The resultsensure that argument semantics not only canimprove the performance of argumentidentification, but also is helpful to assign acorrect role to an argument in roledetermination.Table 3 shows 25.6% of trigger mentionsintroduced into argument extraction are pseudoones.
If we use the golden trigger extraction, ourexploration shows that the precision and recall ofargument identification can be up to 78.6% and88.3% respectively.
Table 6 shows theperformance comparison of argument extractionon AI and RD given golden trigger extraction.Compared to the Baseline, our system improvesthe performance of argument identification androle determination by 6.4% and 5.8%improvement in F1-measure respectively, largelydue to the dramatic increase in recall of 10.9%and 10.4%.SystemArgumentidentificationArgument roledeterminationP(%) R(%) F1 P(%) R(%) F1Baseline 76.2 77.4 76.8 70.4 72.0 71.2Model2 78.6 88.3 83.2 72.3 82.4 77.0Table 6.
Performance comparison of argumentidentification and type determination.
(Goldentrigger extraction)5.3 DiscussionThe initiation of our paper is that syntacticfeatures play an important role in currentmachine learning-based approaches for Englishevent extraction, however, their effectiveness ismuch reduced in Chinese.
So the improvement ofour model for English event extraction is muchless than that of Chinese.
However, our modelcan be an effective complement of the sentence-level English argument extraction systems sincethe performance of argument extraction is stilllow in English and using discourse-levelinformation is a way to improve its performance,especially for those event mentions whosearguments spread in complex sentences.Moreover, our exploration shows that ourglobal argument inference model can mine thosearguments within a long distance which are un-annotated as arguments of a special eventmention in the corpus since the annotators justtagged arguments in a narrow scope or omitted afew arguments.
Actually, they are the true onesto our knowledge and  are more than 30.6% ofthose pseudo arguments inferred by our model.This ensures that our global argument inferencemodel and those relations among event mentionsis helpful to argument extraction.6 ConclusionIn this paper we propose a global argumentinference model to extract those inter-sentencearguments due to the nature of Chinese that it is adiscourse-driven pro-drop language with thewide spread of ellipsis and the open flexiblesentence structure.
In particular, we incorporatevarious kinds of event relations and the argumentsemantics into the model in the sentence,discourse and document layers which representthe cohesion of an event or a topic.
Theexperimental results ensure that our globalargument inference model outperforms the state-of-the-art system.In future work, we will focus on introducingmore semantic information and cross-documentinformation into the global argument inferencemodel to improve the performance of argumentextraction.AcknowledgmentsThe authors would like to thank threeanonymous reviewers for their comments on thispaper.
This research was supported by theNational Natural Science Foundation of Chinaunder Grant No.
61070123, No.
61272260 andNo.
61273320, the National 863 Project of Chinaunder Grant No.
2012AA011102.
The co-authortagged with ?*?
is the corresponding author.1485ReferencesDavid Ahn.
2006.
The Stages of Event Extraction.
InProc.
COLING/ACL 2006 Workshop onAnnotating and Reasoning about Time and Events.Pages 1-8, Sydney, Australia.Regina Barzilay and Miralla Lapata.
2006.Aggregation via Set Partitioning for NaturalLanguage Generation.
In Proc.
NAACL 2006,pages 359-366, New York City, NY.Jonathan Berant, Ido Dagan and Jacob Goldberger.2011.
Global Learning of Typed Entailment Rules.In Proc.
ACL 2011, pages 610-619, Portland, OR.Mary Elaine Califf and Raymond J. Mooney.
2003.Bottom-up Relational Learning of PatternMatching rules for Information Extraction.
Journalof Machine Learning Research, 4:177?210.Nathanael Chambers and Dan Jurafsky.
2008.Unsupervised Learning of Narrative Event Chains.In Proc.
ACL 2008, pages 789-797, Columbus, OH.Nathanael Chambers and Dan Jurafsky.
2011.Template-based Information Extraction without theTemplates.
In Proc.
ACL 2011, pages 976-986,Portland, OR.Zheng Chen and Heng Ji.
2009a.
Can One LanguageBootstrap the Other: A Case Study on EventExtraction.
In Proc.
NAACL/HLT 2009 Workshopon Semi-supervised Learning for Natural LanguageProcessing, pages 66-74, Boulder, Colorado.Zheng Chen and Heng Ji.
2009b.
Language SpecificIssue and Feature Exploration in Chinese EventExtraction.
In Proc.
NAACL HLT 2009, pages209-212, Boulder, Colorado.Zhengdong Dong and Qiang Dong.
2006.
HowNetand the Computation of Meaning.
World ScientificPub Co. Inc.Quang Xuan Do, Wei Lu and Dan Roth.
2012.
JointInference for Event Timeline Construction.
In Proc.EMNLP 2012, pages 677-687, Jeju, Korea.Jianfeng Fu, Zongtian Liu, Zhaoman Zhong andJianfang Shan.
2010.
Chinese Event ExtractionBased on Feature Weighting.
InformationTechnology Journal, 9: 184-187.Ralph Grishman, David Westbrook and Adam Meyers.2005.
NYU?s English ACE 2005 SystemDescription.
In Proc.
ACE 2005 EvaluationWorkshop, Gaithersburg, MD.Yu Hong, Jianfeng Zhang, Bin Ma, Jianmin Yao,Guodong Zhou and Qiaoming Zhu.
2011.
UsingCross-Entity Inference to Improve Event Extraction.In Proc.
ACL 2011, pages 1127-1136, Portland,OR.Ruihong Huang and Ellen Riloff.
2011.
Peeling Backthe Layers: Detecting Event Role Fillers inSecondary Contexts, In Proc.
ACL 2011, pages1137-1147, Portland, OR.Ruihong Huang and Ellen Riloff.
2012.
ModelingTextual Cohesion for Event Extraction.
In Proc.AAAI 2012, pages 1664-1770, Toronto, Canada.Heng Ji and Ralph Grishman.
2008.
Refining EventExtraction through Cross-Document Inference.
InProc.
ACL 2008, pages 254-262, Columbus, OH.Fang Kong, Guodong Zhou, Longhua Qian andQiaoming Zhu.
2010.
Dependency-drivenAnaphoricity Determination for CoreferenceResolution.
In Proc.
COLING 2010, pages 599-607,Beijing, China.Junhui Li, Guodong Zhou and Hwee Tou Ng.
2010.Joint Syntactic and Semantic Parsing of Chinese.In Proc.
ACL 2010, pages 1108-1117, Uppsala,Sweden.Peifeng Li, Guodong Zhou, Qiaoming Zhu and LibinHou.
2012a.
Employing Compositional Semanticsand Discourse Consistency in Chinese EventExtraction.
In Proc.
EMNLP 2012, pages 1006-1016, Jeju, Korea.Peifeng Li, Qiaoming Zhu, Hongjun Diao andGuodong Zhou.
2012b.
Joint Modeling of TriggerIdentification and Event Type Determination inChinese Event Extraction.
In Proc.
COLING 2012,pages 1635-1652, Mumbai, India.Peifeng Li and Guodong Zhou.
2012.
EmployingMorphological Structures and Sememes forChinese Event Extraction.
In Proc.
COLING 2012,pages 1619-1634, Mumbai, India.Wenjie Li, Mingliu Wu, Qin Lu, Wei Xu and ChunfaYuan.
2006.
Extractive Summarization using Inter-and Intra- Event Relevance.
In Proc.COLING/ACL 2006, pages 369-376, Sydney,Australia.Shasha Liao and Ralph Grishman.
2010.
UsingDocument Level Cross-Event Inference to ImproveEvent Extraction.
In Proc.
ACL 2010, pages 789-797, Uppsala, Sweden.Wei Lu and Dan Roth.
2012.
Automatic EventExtraction with Structured Preference Modeling.In Proc.
ACL 2012, pages 835-844, Jeju, Korea.Gideon Mann.
2007.
Multi-document RelationshipFusion via Constraints on Probabilistic Databases.In Proc.
HLT/NAACL 2007, pages 332-229,Rochester, NY.Siddharth Patwardhan and Ellen Riloff.
2007.Effective Information Extraction with SemanticAffinity Patterns and Relevant Regions.
In Proc.EMNLP/CoNLL 2007, pages 717-727, Prague,Czech Republic.Siddharth Patwardhan and Ellen Riloff.
2009.
AUnified Model of Phrasal and Sentential Evidence1486for Information Extraction.
In Proc.
EMNLP 2009,pages 151-160, Singapore.Rashmi Prasad, Nikhil Dinesh, Alan Lee, EleniMiltsakaki, Livio Robaldo, Aravind Joshi andBonnie Webber.
2008.
The Penn DiscourseTreebank 2.0.
In Proc.
LREC 2008, pages 2961-2968, Marrakech, Morocco.Bing Qin, Yanyan Zhao, Xiao Ding, Ting Liu andGuofu Zhai.
2010.
Event Type Recognition Basedon Trigger Expansion.
Tsinghua Science andTechnology, 15(3): 251-258, Beijing, China.Ellen Riloff.
1996.
Automatically GeneratingExtraction Patterns from Untagged Text.
In Proc.AAAI 1996, pages 1044?1049, Portland, OR.Hongye Tan, Tiejun Zhao, Jiaheng Zheng.
2008.Identification of Chinese Event and TheirArgument Roles.
In Proc.
2008 IEEE InternationalConference on Computer and InformationTechnology Workshops, pages 14-19, Sydney,Australia.Nianwen Xue and Yaqin Yang.
2010.
ChineseSentence Segmentation as Comma Classification.In Proc.
ACL 2010, pages 631-635, Uppsala,Sweden.Roman Yangarber, Clive Best, Peter von Etter, FlavioFuart, David Horby and Ralf Steinberger.
2007.Combining Information about Epidemic Threatsfrom Multiple Sources.
In Proc.
RANLP 2007Workshop on Multi-source, MultilingualInformation Extraction and Summarization, pages41-48, Borovets, Bulgaria.1487
