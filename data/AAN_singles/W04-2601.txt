OntoSem Methods for Processing Semantic EllipsisMarjorie McShane, Stephen Beale and Sergei NirenburgInstitute for Language and Information TechnologiesUniversity of Maryland Baltimore County{marge,sbeale,sergei}@umbc.eduAbstractThis paper describes various types of semanticellipsis and underspecification in natural lan-guage, and the ways in which the meaning ofsemantically elided elements is reconstructedin the Ontological Semantics (OntoSem) textprocessing environment.
The description cov-ers phenomena whose treatment in OntoSemhas reached various levels of advancement:fully implemented, partially implemented, anddescribed algorithmically outside of imple-mentation.
We present these research resultsat this point ?
prior to full implementation andextensive evaluation ?
for two reasons: first,new descriptive material is being reported;second, some subclasses of the phenomena inquestion will require a truly long-term effortwhose results are best reported in installments.1IntroductionSyntactic ellipsis ?
the non-expression of syntacticallyobligatory elements ?
has been widely studied in com-putational (not to mention other branches of) linguistics,largely because accounting for missing syntactic ele-ments is a crucial aspect of achieving a full parse, andparsing is required for many approaches to NLP.1 Muchless attention has been devoted to what we will call se-mantic ellipsis, or the non-expression of elements that,while not syntactically obligatory, are required for a fullsemantic interpretation of a text.2 Naturally, semanticellipsis is important only in truly knowledge-rich ap-1 Examples of NLP efforts to resolve syntactic ellipsis in-clude Hobbs and Kehler 1997; Kehler and Shieber 1997;and Lappin 1992, among many others.2 Some of the types of semantic underspecification treatedhere are described in the literature (e.g., Pustejovsky 1995)in theoretical terms, not as heuristic algorithms.
This is due,in large part, to a lack of knowledge sources for semanticreasoning in those contributions.proaches to NLP, which few current non-toy systemspursue.All definitions of ellipsis derive from a stated orimplied notion of completeness.
Taking, again, the ex-ample of syntactic ellipsis, this means that obligatoryverbal arguments must be overt, auxiliary verbs musthave complements, etc.
?
all of which is defined inlexico-grammatical terms.
But even if a text is devoid ofsyntactic gaps, much remains below the surface, easilyinterpretable by people but not directly observable.Typical examples of semantically underspecifiedelements are pronouns and indexicals (e.g., here, now,yesterday), whose real-world anchors must be clarifiedin a fully developed semantic representation (i.e., yes-terday has a concrete meaning only if one knows whentoday is).
Pronouns and indexicals, though often diffi-cult to resolve, have one advantage over the cases to bediscussed here: the trigger that further semantic specifi-cation need be carried out is the word itself, and theinventory of such words is well known.By contrast, the semantically underspecified cases inthe following examples are more subtle:(1) After boosting employment the past few years,Aluminum Co. of America won't be doing anyhiring this fall beyond replacing those who leave.
(2) Mitchell said he planned to work late tonight tocomplete the legislation.
(3) Civilians invited into the prison by the admini-stration to help keep the peace were unable tostanch the bloodshed.The categories of semantic ellipsis illustrated by theseexamples can be described as follows.
(1) shows refer-ence resolution that relies on the reconstruction of asemantically elided category: i.e., to understand whothose refers to, one must understand that the implicitobject of hire is ?employees?, and that the elided head ofthe NP with those as its determiner also refers to em-ployees (albeit a different real-world set of employees).
(2) illustrates semantic event ellipsis in configurationscontaining modal/aspectual + OBJECT: i.e., the meaningof complete the legislation is actually complete writingthe legislation.
(3) illustrates lexical patterns with pre-dictable event ellipsis: e.g., invite <person> to  <loca-tion> means ?invite someone to come/go to thelocation.?
These examples, which illustrate the types ofsemantic ellipsis to be discussed below, require specialtreatment in our ontological semantic (OntoSem) textprocessing system, since its goal is to automaticallyproduce fully specified semantic representations of un-restricted text that can then be used in a wide variety ofapplications.23A Snapshot of the OntoSem Environ-mentOntoSem is a text-processing environment that takes  asinput unrestricted raw text and carries out preprocess-ing, morphological analysis, syntactic analysis, and se-mantic analysis, with the results of semantic analysisrepresented as formal text-meaning representations(TMRs) that can then be used as the basis for many ap-plications.
Text analysis relies on:?
The OntoSem language-independent ontology, whichis written using a metalanguage of description andcurrently contains around 5,500 concepts, each ofwhich is described by an average of 16 properties.?
An OntoSem lexicon for each language processed,which contains syntactic and semantic zones (linkedusing variables) as well as calls to ?meaning proce-dures?
(i.e., programs that carry out procedural se-mantics, see McShane et al forthcoming) whenapplicable.
The semantic zone most frequently refersto ontological concepts, either directly or with prop-erty-based modifications, but can also describe wordmeaning extra-ontologically, for example, in terms ofmodality, aspect, time, etc.
The current English lexi-con contains approximately 12K senses, including allclosed-class items and the most frequent verbs, as in-dicated by corpus analysis.?
An onomasticon, or lexicon of proper names, whichcontains approximately 350,000 entries and is grow-ing daily using automated extraction techniques.?
A fact repository, which contains real-world factsrepresented as numbered ?remembered instances?
ofontological concepts (e.g., SPEECH-ACT-3366 is the3366th instantiation of the concept SPEECH-ACT in theworld model constructed during the processing ofsome given text(s)).?
The OntoSem text analyzers, which cover preprocess-ing, syntactic analysis, semantic analysis, and creationof TMRs.?
The TMR language, which is the metalanguage forrepresenting text meaning.A very simple example of a TMR, reflecting themeaning of the sentence The US won the war, is as fol-lows:WIN-3AGENT  NATION-213THEME  WAR-ACTIVITY-7This TMR is headed by a WIN event ?
in fact, it is the 3rdinstantiation of the concept WIN (WIN-3) in the world?snapshot?
being built during the processing of thegiven text(s).
Its agent is NATION-213, which refers tothe United States of America in our fact repository.
Thetheme of the event is the 7th instantiation of WAR-ACTIVITY in this text.
Details of this approach to textprocessing can be found, e.g., in Nirenburg and Raskin2004, Beale et al2003, Nirenburg et al2003a,b.
Theontology itself, a brief ontology tutorial, and an exten-sive lexicon tutorial can be viewed athttp://ilit.umbc.edu.Since OntoSem text processing attempts to do it all?
meaning that any phenomenon in any language we areprocessing is within the purview of our approach ?
workon any given problem is carried out in spiral fashion:first at a rough grain size, then at a finer grain size witheach iterative improvement of the system.
In order bothto drive and to organize work, we develop a ?microthe-ory?
for each aspect of text processing we treat: e.g., wehave microtheories of mood, time, reference resolution,and many more.
One of the benefits of conceiving workon a given topic in terms of a microtheory is that con-ceptual, algorithmic progress can occur separately fromits realization in a specific application.
This does notimply a disconnect between algorithms and implementa-tions ?
quite the opposite: all algorithms are devised forthe OntoSem environment, relying on the types ofknowledge and processing it can currently provide orrealistically promises to provide.
Within this frame-work, a ?big picture?
of long-term work on a giventopic is often clarified before all details of implementa-tion, or complete knowledge support, become available.In this paper we present initial results of our work onthe microtheory of semantic ellipsis and underspecifica-tion, some of whose contributing phenomena can cur-rently be well-handled in OntoSem and others of whichwill require long-term research and development efforts.Reference Resolution that Relies on theReconstruction of a Semantically ElidedAntecedentThe reference resolution task in NLP has widely cometo be understood in very narrow terms ?
as linking pro-nouns to their overt textual antecedents (a focus fueledby MUC and other similar competitions; see Sundheim1995).
However, the scope of reference-related prob-lems is actually much broader (see, e.g., McShane andNirenburg 2002 and McShane forthcoming).
In this sec-tion we describe a number of cases in which referenceresolution requires knowledge of semantically elidedcategories.
That is, we are not talking simply about re-covering a semantically elided category in its own right,we are talking about recovering it in order to support thecorrect analysis of another category in the text.Consider the challenge of resolving the reference ofthose in example (1): After boosting employment thepast few years, Aluminum Co. of America won't be do-ing any hiring this fall beyond replacing those wholeave.
?Those?
refers to an unspecified set of employees.The ellipsis of the head noun employees (or any syno-nym of it) is licensed by the fact that the notion of ?em-ployees?
is implicitly introduced into the discourse bythe use of the word hire in the preceding clause (in theway described below).
The real-world set of employeesinstantiated by the verb hire is not the same as the real-world set of employees referred to by the ?those?
NP.However, as this corpus-derived example shows,coreference at the level of concepts rather than instancescan, in fact, license ellipsis.3Most reference resolution programs  rely on shallow,stochastic methods and limit potential antecedents toovert textual elements; such programs would fail to re-solve this case of reference.
The OntoSem referenceresolution programs, by contrast, include ontologicalknowledge in the search space of antecedents and, ac-cordingly, can resolve such references.
To make clearhow this is done, a few more words about ontologicalspecification and TMRs are necessary.Fillers of properties in the OntoSem ontology can beconcepts, literals, numbers or ranges of numbers.
Asmall excerpt from the ontological specification of HIREis as follows.HIREAGENT    sem    SOCIAL-ROLEdefault   BUSINESS-ROLErelaxable-to   CORPORATIONTHEME  sem   SOCIAL-ROLELOCATION   sem   PLACEdefault   BUILDINGThe fillers for ontological properties can be specified onvarious facets, including: sem, which indicates typicalselectional restrictions; default, which indicates the de-3 It is noteworthy that many elliptical phenomena permitmatching at the conceptual rather than instance-based level.For example, in Russian one can say the equivalent of Theywere selling stocks at a good rate so I bought, in which casethe direct object of ?bought?
is elided and understood to rep-resent some subset of the original set of stocks being sold(see McShane forthcoming for details).fault filler(s), if any (i.e., this is more tightly constrainedthan sem); and relaxable-to, which shows acceptablerelaxation of typical selectional restrictions.
So, whereasthe most typical AGENT of hiring is somebody in a busi-ness role (children of BUSINESS-ROLE include MANAGER,CHAIRMAN, VP-CORPORATION and others) it is perfectlynormal for any person in a social role to hire someone(e.g., I, as a homeowner, can hire a gardener), and evencorporations can be metonymically said to hire people.As concerns the THEME of hiring, it is always a personin a social role, and no defaults or extensions to thatspecification are required.
(Note that SOCIAL-ROLE is achild of HUMAN in the ontology.
)When a concept is instantiated in a TMR, its entiredescription becomes part of the TMR, and any propertyfillers actually provided by the text are indicated usingthe value facet.
Fillers on the value facet are appendedwith an instance number, just like the main concept be-ing instantiated.
So an excerpt from the instantiation ofHIRE (minus over a dozen properties that are not as-signed specific values from the text) in the TMR forsentence (1) is as follows, with information explicit inthe text shown in boldface:HIRE-47AGENT sem    SOCIAL-ROLEdefault   BUSINESS-ROLErelaxable-to   CORPORATIONvalue   CORPORATION-4165THEME sem   SOCIAL-ROLEIn other words, the fact that certain properties of a con-cept are not overtly mentioned in a text does not meanthat the properties themselves or information about theirtypical fillers is stricken from the TMR: this informationis available in the TMR, just as it is available to a per-son when he is interpreting a text.The OntoSem algorithm for resolving the referenceof those can be briefly outlined as follows:1.
From the list of candidate antecedents that is gener-ated during the processing of each sentence, ex-clude those with incompatible grammatical features(in this case, those in the singular).2 Compare potential antecedents using (a) weightedheuristics of the same type as are used in most sto-chastic reference resolution programs, based on fea-tures such as text distance, grammatical function,etc, and (b) comparison of the semantic similaritybetween those (as suggested by the selectional re-strictions imposed by its selecting verb) and eachantecedent.The two key differences between our approach and sto-chastic ones are that, for us, semantic comparison is aheavily weighted heuristic, and implicit properties ofTMR-instantiated concepts are accessible in the searchspace.
In example (1), this means that the THEME ofHIRE, which is semantically specified as SOCIAL-ROLE, isa potential source of the semantics of those.
Since thereare no other viable candidates to supply the elided se-mantic content, SOCIAL-ROLE will be understood as theconceptual head of the NP whose determiner is those.Continuing with the example of HIRE, consider ex-ample (4) which, like all examples cited in this paper,was drawn from a news corpus.
(4) Although early placement statistics show that hiringby Wall Street has declined dramatically, studentsare not exactly flocking to the factory floor.
For ex-ample, preliminary statistics show that hiring by in-vestment banks has been cut in half, from 22% ofgraduates in 1987 to 11% this year.The practical need for resolving the semantic ellipsis ofthe theme of hire in this passage becomes clear whenone seeks to interpret the phrase from 22% of graduatesin 1987 to 11% this year.
Syntactically speaking, thisphrase is difficult to parse, as it is appended to the mainclause in a rather ?telegraphic?
way: i.e., it is doubtfulthat most parsers have a rule to specifically target thissentence structure (ours does not).
Interpreting thisphrase relies primarily on semantics, i.e., an understand-ing that the graduates are coreferential with the semanti-cally elided object of hire.In OntoSem, difficult cases of parsing are handledusing what we call ?recovery?
procedures.
If a perfectparse cannot be arrived at in the initial run of the parser?
where the most typical syntactic dependency struc-tures are sought ?
the parser can invoke several levels ofrecovery rules, as needed (see Beale et al 2003 for de-tails).
Among these recovery rules is the option to applythe semantics of a constituent to the nascent TMR with-out recourse to its syntactic function.
This type of re-covery reflects our general desire to leverage semanticknowledge more and rely on syntax less.An excerpt from the core of the TMR for the secondsentence in (4) will look as follows (with COMMERCIAL-BANK-8 representing the string investment banks):HIRE-50AGENT  sem    SOCIAL-ROLEdefault   BUSINESS-ROLErelaxable-to   CORPORATIONvalue   COMMERCIAL-BANK-8THEME sem   SOCIAL-ROLEAnd the TMR for the syntactically unattached compo-nent, from 22% of graduates in 1987 to 11% this year,will look as follows (from and to have lexical sensesthat indicate the start-value and end-value of a rangewhen their complement is a number):START-VALUEDOMAIN  SOCIAL-ROLE-977AGENT-OF  GRADUATE-COLLEGERANGE   .22YEAR   1987END-VALUEDOMAIN  SOCIAL-ROLE-978AGENT-OF GRADUATE-COLLEGERANGE   .11YEAR   find-anchor-year ; a call to a proce-dural semantics programIn short, the head of the core TMR expects a  SOCIAL-ROLE as the THEME of HIRE, and the domain of the syn-tactically unattached segment of the sentence is namelya SOCIAL-ROLE.
The direct, and correct, hypothesis is tolink the unattached TMR fragment namely to the fillerof the THEME of HIRE, which is exactly what our seman-tic analyzer does.Cases in which semantically elided elements arecrucial to the interpretation of other sentence elementsare not rare.
Another example taken from the same do-main of hiring (we remain in this domain only for sim-plicity of exposition) is shown in (5).
(5) For one thing, in 20 states and the District of Co-lumbia, it's illegal to discriminate in hiring or pro-motions on the basis of marital status.In order to interpret the connection of marital status tothe rest of the proposition, one must corefer the HUMANin the DOMAIN of the concept MARITAL-STATUS to theimplicit THEME of HIRE and PROMOTE.LEGALITY-ATTRIBUTE-4DOMAIN sem   SOCIAL-EVENTvalue  DISCRIMINATE-23RANGE sem  YES, NOvalue  NODISCRIMINATE-23AGENT  sem    HUMANrelaxable-to  CORPORATIONORGANIZATIONTHEME sem    MENTAL-OBJECTvalue    HIRE-65PROMOTE-53BENEFICIARY sem   HUMANrelaxable-to  CORPORATIONORGANIZATIONCAUSED-BY sem   EVENTVALUE  MARITAL-STATUS-1MARITAL-STATUS-1DOMAIN HUMANRANGE  SINGLE, MARRIED, WIDOWED, DIVORCEDAs these examples show, there is a concrete, corpus-attested need to resolve many instances of semanticellipsis, namely, the need to use implicit information asthe antecedent for coreferring categories.4Semantic Event Ellipsis in Configura-tions Containing a Modal/Aspectual +OBJECTIn English and many other languages, modals and as-pectuals can take nominal complements.
Those com-plements can, semantically, be of two types: OBJECTsand EVENTs.
If the syntactic object semantically repre-sents an EVENT, then there is no semantic ellipsis, as inThe delegates began the conversation at noon, whosesimplified TMR is as follows:SPEECH-ACT-35333PHASE  beginAGENT  DELEGATE-2223TIME  12.00In other words, since conversation is mapped to theevent SPEECH-ACT, it naturally has a PHASE and anAGENT and a TIME and there is no semantic ellipsis.
Ex-amples of this type are frequent in texts, as shown byexamples (5)-(7):(5) Dataproducts has since started a restructuring thatstarted the still-raging bidding wars(6) Nomura started a credit-card venture with Ameri-can Express Co.(7) The spokesman said Maxicare hopes to completethe reorganization by early 1990If the syntactic object semantically represents anOBJECT, then the semantics of the implied verb must berecovered.
For OntoSem text processing, two subtypesof such cases are important: those in which the objectrefers to an institution, program, etc., and the elidedverb predictably means ?initiate, found?, and those inwhich the object refers to something else and the verbalsemantics must be inferred based on the meaning of theovert categories.
Examples of the first subtype includethe following:(8) She'll be the first one to leave it and start a fourthparty.
(9) Brazil started an ethanol program about 15 yearsago.
(10) Quebecor started the Philadelphia Journal.The OntoSem lexicon contains a number of lexicalsenses of start, finish, etc.
that cover such cases: e.g.,one sense specifies the THEME to be an ORGANIZATION,and heads the semantic description with the conceptFOUND-ORGANIZATION; another specifies the THEME tobe a MENTAL-OBJECT and heads the semantic descriptionwith INVENT (as in ?He started a new semantic theory?
).This type of semantic ellipsis is discussed more fully inSection 5.The second subtype requires procedural semanticanalysis to recover the meaning of the implied event.Examples of such contexts include the following:(11) Mitchell said he planned to work late tonight tocomplete the legislation [elided WRITE].
(12) He conscripted 700,000 slaves to finish the GreatWall [elided BUILD].
(13) Most service businesses can complete their bookswithin three weeks after a period has ended[elided BOOKKEEPING].
(14) Next Inc.... has finished the first version of itsoperating-system software [elided DESIGN-SOFTWARE].
(15) Manufacturers Hanover this week started a newseries of ads that push "Power Savings" [elidedBROADCAST].The OntoSem lexical sense that covers these contextsincludes a procedural attachment called seek-event-specification, which attempts to dynamically recover themeaning of the semantically elided events.
That is, itseeks concepts for which the meaning of the subject anddirect object provided in the text are most specificallyconstrained.
For example, in (11), the program will seekan EVENT for which the default AGENT is SENATOR(Mitchell was a senator at the time4) and the defaultTHEME is BILL-LEGISLATIVE; and in (12), the program4 We can expect that earlier in the text he was referred to us-ing a more complete appellation which either overtly de-scribed him as a senator or provided sufficient informationfor our reference-resolution program to link him to his fact-repository entry, where his SOCIAL-ROLE of SENATOR islisted.
Reference resolution using fact-repository informa-tion has been implemented but not widely tested yet.
Theproblem of identifying him as the same person that has justbeen elected Chairman of Disney is outside of the purviewof this paper.will seek an EVENT for which AGENT is SLAVE and thedefault THEME is WALL (the basic ontological mappingof Great Wall, though a number of properties are de-fined in its fact repository entry, like LOCATION: China,LENGTH: 5000 km).
If more than one match is found, alloptions are retained in the TMR for possible later dis-ambiguation based on further context.
If no matches arefound using the default facet, matches using the semfacet are sought.
In the worst case (the maximal level ofsemantic relaxation), the only thing the semantic ana-lyzer can say about the elided EVENT is that there is,indeed, an unspecified EVENT that has the text-specifiedAGENT and THEME.Two points must be emphasized: a) the OntoSemlexicon records our expectations that dynamic semantic-ellipsis resolution will be necessary in certain types ofcontexts, which can be specified based on reference toontological types of OBJECTS; and b) the resolution ofsemantic event ellipsis is supported by the property-defined relationships between ontological OBJECTs andEVENTs.5 Lexical Patterns with Predictable EventEllipsisOntological semantics has practical aims, which means,among other things, that extending the lexicon to in-clude complex entities and thus bypass the need fortheir runtime compositional semantic treatment is avalid methodological option.
A good case in point is thelexicalization of common cases of semantic ellipsis.Like any lexicalization, this does not offer full cover-age; however, like all lexicalization, it does provideconcrete information about concrete phenomena thatcan be immediately exploited.
Here we present just afew examples of the lexicalized treatment of semanticellipsis as an illustration of our omnivorous approach toimproving the overall quality of text processing.The verb invite, when followed by a prepositionalphrase or adverb indicating location (or destination)directly or metonymically, actually means ?invite tocome/go to that place?
; the verb of motion is semanti-cally elided.
Examples include (16)-(19):(16) Civilians invited into the prison by the admini-stration to help keep the peace were unable tostanch the bloodshed.
(17) ?If they invited us back tomorrow to govern themainland, frankly we would hesitate," Vice For-eign Minister John H. Chang told a U.S. gover-nor's delegation.
(18) All 13 OPEC oil ministers were invited to themeeting.
(19) He often is one of a handful of top aides invitedinto the Oval Office for the informal sessions atwhich President Bush likes to make sensitive for-eign-policy decisions.The lexicon sense that covers this use of invite in (16)and (18) is as follows, in presentation format (the lexi-con sense that covers (17) has an adverb of loca-tion/destination instead of a PP):invite-v2def  ?+ pp of destination, implies ?invite to come?
?ex ?She invited him to Paris?syn-strucsubject      root $var1  cat nv               root $var0directobject   root $var2    cat npp-adjunct    root $var3    cat preproot (or to onto into on)obj     root $var4   cat nsem-strucINVITEAGENT    value ^$var1THEME    MOTION-EVENTDESTINATION   value ^$var4AGENT   value ^$var2^$var3  null-sem +The syntactic structure (syn-struc) says that this sense oflike requires a subject, direct object and PP, and that thePP must be headed by the word to, onto, into or on.
Thesemantic structure (sem-struc) is headed by an INVITEevent, whose AGENT is the subject of the clause (notethe linked variables) and whose theme is a MOTION-EVENT.
The AGENT and DESTINATION of the MOTION-EVENT are the meanings of the direct object and preposi-tional object, respectively, of the input clause.
(Wegloss over formal aspects of the entry that are tangentialto the current discussion.)
Note that there is no verb ofmotion in the input text: MOTION-EVENT is lexicallyspecified since it is a predictable semantically elidedaspect of meaning in the given configuration.Another lexical item for which we can predict a par-ticular type of semantic ellipsis is forget.
When the di-rect object of forget semantically represents aPHYSICAL-OBJECT, there is an elided TAKE event, asshown in (20).
(20) ?This is the slowest day I've seen this year,?
saidPeter Canelo, a market strategist at Bear StearnsCos.
?I've only had one call all day from a realinvestor and he just forgot his umbrella.
?Thus, the OntoSem lexicon has a special sense for for-get + PHYSICAL-OBJECT  that is selected by the semanticanalyzer in contexts like (20).Obviously, a lexicon that anticipates instances ofsemantic ellipsis must be quite detailed and, as a result,relatively expensive to build.
The OntoSem lexicon fallsinto both of these categories.
However, expensive doesnot mean prohibitive, and we believe that the ultimateutility of such a knowledge resource will fully justify itscompilation.
The rate of acquisition for open-classwords and phrases in OntoSem depends primarily on thetype of entity being acquired, be it argument-taking ornot.
A conservative estimate for lexical acquisition forOntoSem, based on a recent acquisition drive, is as fol-lows:?
acquisition of argument-taking word and phrasesenses: 6 words/hr * 6 hrs./day * 5 days/week *50 weeks/yr = 9,000 senses/year?
acquisition of non-argument-taking word andphrase senses (about 5 times as fast): 9000 * 5 =45,000 senses/yearAccording to these estimates, and considering that manymore words are non-argument-taking than are argu-ment-taking, we might realistically expect to increasethe size of the lexicon by around 100,000 senses peryear if given 3 full-time acquirers supported by one full-time ontology developer.
In short, large volumes ofhigh-quality knowledge can be achieved in real time.67EvaluationIn response to the current evaluation standards in NLP(which are more suited to and informative for stochas-tic-based systems than knowledge-based ones), we haverecently developed a novel evaluation methodology thatassigns scores as well as blame for errors to variousaspects of the TMRs generated during OntoSem textprocessing.
While percentage scores for correct vs. in-correct results can provide a general evaluation of sys-tem function, it is blame assignment that drivesdevelopment.
Blame assignment is determined by proc-essing each sentence multiple times: first without man-ual intervention, then with the correction ofpreprocessor errors, then with the correction of syntaxerrors.
The rationale behind these loops of correctionand reevaluation is that ?low level?
mistakes like pre-processor errors or lack of coverage of some syntacticconstruction require different development action thanmore weighty (from our point of view) errors in seman-tic interpretation that might result from gaps in knowl-edge, insufficient reasoning engines, etc.The first experiment with our new evaluation regimeproduced the following results (reported on in detail inNirenburg et al 2004): the analyzer was shown to carryout word sense disambiguation at over 90% and seman-tic dependency determination at 87% on the basis ofcorrect syntactic analysis and on sentences of an aver-age length of over 25 words with 1.33 unknown wordson average per input sentence.
Outstanding errors insemantic analysis were due, in most cases, to non-literaluse of language (which is one of our topics of ongoinginvestigation).
Although this first formal experimentwas limited to WSD and semantic dependencies, testingof other modules ?
like those for reference resolutionand ellipsis ?
will soon be added to the formal evalua-tion regime.
At this stage, evaluation work is slow, butwe are well into the development of an evaluation andcorrection environment that promises to significantlyspeed up both evaluation and system enhancement.Closing ThoughtsThe type of work presented in this paper might betermed a practical, progressive long-term effort.The work is practical because it is being carried outwithin a working system that: (a) uses non-toy, real text-oriented knowledge resources ?
lexical and ontological?
that are being built not in the hope that someday somesystem might be able to use them, but because they areuseful right now in the system under construction; (b)has processors that cover all levels of text analysis, frompreprocessing raw input text to creating semantic text-meaning representations of it; (c) has been and contin-ues to be used in applications as diverse as machinetranslation, information extraction, summarization andquestion answering.
In short, the work that we carry outon any given aspect of text processing answers a needencountered in real applications, and does so in a con-crete, implemented and further implementable way.The work is progressive in the sense that the loop ofalgorithm development and integration in each new ver-sion of the working system is continuous.
We find itimportant, tactically, to view issues in natural languagefrom a broad perspective first, with development ofpractical ?microtheories?
for their treatment progressingas need demands and resources permit.
What we try notto do is artificially exclude from our purview those as-pects of phenomena that are not easily treated at thepresent state of the art.
Instead, we include such aspectsin our algorithms to the degree possible and make surethat they are modified as soon as an advance is made inresource acquisition or algorithm fusion (e.g., incorpo-rating stochastic methods if and when knowledge-basedones fail to produce a single, unambiguous semanticrepresentation, as in the case of weighted heuristics forreference resolution).The work is long term because we know that high-quality text processing cannot be achieved in the shortterm.
If a phenomenon exists in a language we are proc-essing, it is, by definition, within our purview.
Our ul-timate aim: an intelligent agent able to communicate noless fluently than you or I and in possession of human-level background knowledge about the world and lan-guage.
Of course, this goal will not be realized in ourlifetimes, unless adequate resources are allocated to thistask and its subtasks.
However, a solid foundation thatin principle can accommodate any and all later needs oflanguage processing is what we are attempting to de-velop while at the same time developing working appli-cations.ReferencesStephen Beale, Sergei Nirenburg and MarjorieMcShane.
2003.
Just-in-time grammar.
Proceedingsof the 2003 International Multiconference in Com-puter Science and Computer Engineering, Las Ve-gas, Nevada.Jerry R. Hobbs and Andrew Kehler.
1997.
A theory ofparallelism and the case of VP ellipsis.
Proceedingsof the 35th  Annual Meeting of the Association forComputational Linguistics, Madrid, Spain.Andrew Kehler and Stuart Shieber.
1997.
Anaphoricdependencies in ellipsis.
Computational Linguistics,23(3): 457-466.Shalom Lappin.
1992.
The syntactic basis of ellipsisresolution.
Proceedings of the Stuttgart EllipsisWorkshop, 1-47.Marjorie McShane.
Forthcoming.
A Theory of Ellipsis.Oxford University Press.Marjorie McShane, Stephen Beale and Sergei Niren-burg.
Forthcoming.
Some meaning procedures ofOntological Semantics.
Proceedings of LREC 2004,Lisbon, Portugal.Marjorie McShane and Sergei Nirenburg.
2002.
Refer-ence and ellipsis in Ontological Semantics.
Memo-randa in Computer and Cognitive Science, MCCS-02-329.
The Computing Research Laboratory, NewMexico State University.Sergei Nirenburg, Marjorie McShane and StephenBeale.
2003a.
Enhancing recall in information ex-traction through Ontological Semantics.
Proceedingsof the Workshop on Ontologies and Information Ex-traction, Bucharest, Romania, August 2003.Sergei Nirenburg, Marjorie McShane and StephenBeale.
2003b.
Operative strategies in OntologicalSemantics.
Proceedings of HLT-NAACL-03 Work-shop on Text Meaning, Edmonton, Alberta, Canada,June 2003.Sergei Nirenburg and Victor Raskin.
2004 (forthcom-ing).
Ontological Semantics, the MIT Press, Cam-bridge, Mass.Sergei Nirenburg, Stephen Beale and MarjorieMcShane.
2004.
Evaluating the Performance of theOntoSem Semantic Analyzer.
Submitted to ACL-04.James Pustejovsky.
The Generative Lexicon.
The MITPress, Cambridge, Mass.Roger Schank and Robert Abelson.
1977.
Scripts,Plans, Goals, and Understanding: An Inquiry intoHuman Knowledge Structures.
L. Erlbaum Associ-ates, New York.Beth Sundheim.
1995.
The MUC coreference task defi-nition v. 3.0.
Proceedings of the 6th Message Under-standing Conference.
