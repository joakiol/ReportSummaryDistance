Unsupervised Learning of Arabic Stemming using a Parallel CorpusMonica Rogati?Computer Science Department,Carnegie Mellon Universitymrogati@cs.cmu.eduScott McCarleyIBM TJ WatsonResearch Centerjsmc@watson.ibm.comYiming YangLanguage Technologies Institute,Carnegie Mellon Universityyiming@cs.cmu.eduAbstractThis paper presents an unsupervised learn-ing approach to building a non-English(Arabic) stemmer.
The stemming modelis based on statistical machine translationand it uses an English stemmer and a small(10K sentences) parallel corpus as its soletraining resources.
No parallel text isneeded after the training phase.
Mono-lingual, unannotated text can be used tofurther improve the stemmer by allow-ing it to adapt to a desired domain orgenre.
Examples and results will be givenfor Arabic , but the approach is applica-ble to any language that needs affix re-moval.
Our resource-frugal approach re-sults in 87.5% agreement with a state ofthe art, proprietary Arabic stemmer builtusing rules, affix lists, and human anno-tated text, in addition to an unsupervisedcomponent.
Task-based evaluation usingArabic information retrieval indicates animprovement of 22-38% in average pre-cision over unstemmed text, and 96% ofthe performance of the proprietary stem-mer above.1 IntroductionStemming is the process of normalizing word vari-ations by removing prefixes and suffixes.
From an?Work done while a summer intern at IBM TJ Watson Re-search Centerinformation retrieval point of view, prefixes and suf-fixes add little or no additional meaning; in mostcases, both the efficiency and effectiveness of textprocessing applications such as information retrievaland machine translation are improved.Building a rule-based stemmer for a new, arbitrarylanguage is time consuming and requires expertswith linguistic knowledge in that particular lan-guage.
Supervised learning also requires large quan-tities of labeled data in the target language, and qual-ity declines when using completely unsupervisedmethods.
We would like to reach a compromiseby using a few inexpensive and readily available re-sources in conjunction with unsupervised learning.Our goal is to develop a stemmer generator thatis relatively language independent (to the extent thatthe language accepts stemming) and is trainable us-ing little, inexpensive data.
This paper presentsan unsupervised learning approach to non-Englishstemming.
The stemming model is based on statisti-cal machine translation and it uses an English stem-mer and a small (10K sentences) parallel corpus asits sole training resources.A parallel corpus is a collection of sentence pairswith the same meaning but in different languages(i.e.
United Nations proceedings, bilingual newspa-pers, the Bible).
Table 1 shows an example that usesthe Buckwalter transliteration (Buckwalter, 1999).Usually, entire documents are translated by humans,and the sentence pairs are subsequently aligned byautomatic means.
A small parallel corpus can beavailable when native speakers and translators arenot, which makes building a stemmer out of suchcorpus a preferable direction.Arabic Englishm$rwE Altqryr Draft reportwAkdt mmvlp zAm-byA End ErDhAlltqryr An bldhAy$hd tgyyrAt xTyrpwbEydp Almdy fyAlmydAnyn Al-syAsy wAlAqtSAdyIn introducing the report,the representative of Zam-bia emphasised that hercountry was undergoingserious and far-reachingchanges in the politicaland economic field.Table 1: A Tiny Arabic-English Parallel CorpusWe describe our approach towards reaching thisgoal in section 2.
Although we are using resourcesother than monolingual data, the unsupervised na-ture of our approach is preserved by the fact thatno direct information about non-English stemmingis present in the training data.Monolingual, unannotated text in the target lan-guage is readily available and can be used to furtherimprove the stemmer by allowing it to adapt to a de-sired domain or genre.
This optional step is closer tothe traditional unsupervised learning paradigm andis described in section 2.4, and its impact on stem-mer quality is described in 3.1.4.Our approach (denoted by UNSUP in the rest ofthe paper) is evaluated in section 3.1 by compar-ing it to a proprietary Arabic stemmer (denoted byGOLD).
The latter is a state of the art Arabic stem-mer, and was built using rules, suffix and prefix lists,and human annotated text.
GOLD is an earlier ver-sion of the stemmer described in (Lee et al, ).The task-based evaluation section 3.2 comparesthe two stemmers by using them as a preprocessingstep in the TREC Arabic retrieval task.
This sectionalso presents the improvement obtained over usingunstemmed text.1.1 Arabic detailsIn this paper, Arabic was the target language but theapproach is applicable to any language that needsaffix removal.
In Arabic, unlike English, both pre-fixes and suffixes need to be removed for effectivestemming.
Although Arabic provides the additionalchallenge of infixes, we did not tackle them becausethey often substantially change the meaning.
Irregu-lar morphology is also beyond the scope of this pa-per.
As a side note for readers with linguistic back-ground (Arabic in particular), we do not claim thatthe resulting stems are units representing the entireparadigm of a lexical item.
The main purpose ofstemming as seen in this paper is to conflate the to-ken space used in statistical methods in order to im-prove their effectiveness.
The quality of the result-ing tokens as perceived by humans is not as impor-tant, since the stemmed output is intended for com-puter consumption.1.2 Related WorkThe problem of unsupervised stemming or morphol-ogy has been studied using several different ap-proaches.
For Arabic, good results have been ob-tained for plural detection (Clark, 2001).
(Gold-smith, 2001) used a minimum description lengthparadigm to build Linguistica, a system for whichthe reported accuracy for European languages is cca.83%.
Note that the results in this section are not di-rectly comparable to ours, since we are focusing onArabic.A notable contribution was published by Snover(Snover, 2002), who defines an objective function tobe optimized and performs a search for the stemmedconfiguration that optimizes the function over allstemming possibilities of a given text.Rule-based stemming for Arabic is a problemstudied by many researchers; an excellent overviewis provided by (Larkey et al, ).Morphology is not limited to prefix and suffix re-moval; it can also be seen as mapping from a word toan arbitrary meaning carrying token.
Using an LSIapproach, (Schone and Jurafsky, ) obtained 88% ac-curacy for English.
This approach also deals withirregular morphology, which we have not addressed.A parallel corpus has been successfully used be-fore by (Yarowsky et al, 2000) to project part ofspeech tags, named entity tags, and morphology in-formation from one language to the other.
For a par-allel corpus of comparable size with the one usedin our results, the reported accuracy was 93% forFrench (when the English portion was also avail-able); however, this result only covers 90% of thetokens.
Accuracy was later improved using suffixtrees.
(Diab and Resnik, 2002) used a parallel corpusfor word sense disambiguation, exploiting the factthat different meanings of the same word tend to betranslated into distinct words.2 ApproachFigure 1: Approach OverviewOur approach is based on the availability of thefollowing three resources:?
a small parallel corpus?
an English stemmer?
an optional unannotated Arabic corpusOur goal is to train an Arabic stemmer using theseresources.
The resulting stemmer will simply stemArabic without needing its English equivalent.We divide the training into two logical steps:?
Step 1: Use the small parallel corpus?
Step 2: (optional) Use the monolingual corpusThe two steps are described in detail in the fol-lowing subsections.2.1 Step 1: Using the Small Parallel CorpusFigure 2: Step 1 IterationIn Step 1, we are trying to exploit the Englishstemmer by stemming the English half of the paral-lel corpus and building a translation model that willestablish a correspondence between meaning carry-ing substrings (the stem) in Arabic and the Englishstems.For our purposes, a translation model is a matrixof translation probabilities p(Arabic stem| Englishstem) that can be constructed based on the smallparallel corpus (see subsection 2.2 for more details).The Arabic portion is stemmed with an initial guess(discussed in subsection 2.1.1)Conceptually, once the translation model is built,we can stem the Arabic portion of the parallel corpusby scoring all possible stems that an Arabic wordcan have, and choosing the best one.
Once the Ara-bic portion of the parallel corpus is stemmed, we canbuild a more accurate translation model and repeatthe process (see figure 2).
However, in practice, in-stead of using a harsh cutoff and only keeping thebest stem, we impose a probability distribution overthe candidate stems.
The distribution starts out uni-form and then converges towards concentrating mostof the probability mass in one stem candidate.2.1.1 The Starting PointThe starting point is an inherent problem for un-supervised learning.
We would like our stemmer togive good results starting from a very general initialguess (i.e.
random).
In our case, the starting pointis the initial choice of the stem for each individualword.
We distinguish several solutions:?
No stemming.This is not a desirable starting point, since affixprobabilities used by our model would be zero.?
Random stemmingAs mentioned above, this is equivalent to im-posing a uniform prior distribution over thecandidate stems.
This is the most general start-ing point.?
A simple language specific rule - if availableIf a simple rule is available, it would provide abetter than random starting point, at the cost ofreduced generality.
For Arabic, this simple rulewas to use Al as a prefix and p as a suffix.
Thisrule (or at least the first half) is obvious evento non-native speakers looking at transliteratedtext.
It also constitutes a surprisingly high base-line.2.2 The Translation Model ?We adapted Model 1 (Brown et al, 1993) to ourpurposes.
Model 1 uses the concept of alignmentbetween two sentences e and f in a parallel corpus;the alignment is defined as an object indicating foreach word ei which word fj generated it.
To ob-tain the probability of an foreign sentence f given theEnglish sentence e, Model 1 sums the products ofthe translation probabilities over all possible align-ments:Pr(f |e) ??
{a}m?j=1t(fj|eaj )The alignment variable ai controls which Englishword the foreign word fi is aligned with.
t(f |e) issimply the translation probability which is refinediteratively using EM.
For our purposes, the transla-tion probabilities (in a translation matrix) are the fi-nal product of using the parallel corpus to train thetranslation model.To take into account the weight contributed byeach stem, the model?s iterative phase was adaptedto use the sum of the weights of a word in a sentenceinstead of the count.2.3 Candidate Stem ScoringAs previously mentioned, each word has a list ofsubstrings that are possible stems.
We reduced theproblem to that of placing two separators inside eachArabic word; the ?candidate stems?
are simply thesubstrings inside the separators.
While this mayseem inefficient, in practice words tend to be short,and one or two letter stems can be disallowed.An initial, naive approach when scoring the stemwould be to simply look up its translation probabil-ity, given the English stem that is most likely to beits translation in the parallel sentence (i.e.
the En-glish stem aligned with the Arabic stem candidate).Figure 3 presents scoring examples before normal-ization.
?Note that the algorithm to build the translation model isnot a ?resource?
per se, since it is a language-independent algo-rithm.English Phrase: the advisory committeeArabic Phrase: Alljnp AlAst$ArypTask: stem AlAst$ArypChoices ScoreAlAst$Aryp 0.2AlAst$Aryp 0.7AlAst$Aryp 0.8AlAst$Aryp 0.1......Figure 3: Scoring the StemHowever, this approach has several drawbacksthat prevent us from using it on a corpus other thanthe training corpus.
Both of the drawbacks beloware brought about by the small size of the parallelcorpus:?
Out-of-vocabulary words: many Arabic stemswill not be seen in the small corpus?
Unreliable translation probabilities for low-frequency stems.We can avoid these issues if we adopt an alternateview of stemming a word, by looking at the prefixand the suffix instead.
Given the word, the choiceof prefix and suffix uniquely determines the stem.Since the number of unique affixes is much smallerby definition, they will not have the two problemsabove, even when using a small corpus.
These prob-abilities will be considerably more reliable and area very important part of the information extractedfrom the parallel corpus.
Therefore, the score of acandidate stem should be based on the score of thecorresponding prefix and the suffix, in addition tothe score of the stem string itself:score(?pas??)
= f(p) ?
f(a) ?
f(s)where a = Arabic stem, p = prefix, s=suffixWhen scoring the prefix and the suffix, we couldsimply use their probabilities from the previousstemming iteration.
However, there is additional in-formation available that can be successfully used tocondition and refine these probabilities (such as thelength of the word, the part of speech tag if givenetc.
).English Phrase: the advisory committeeArabic Phrase: Alljnp AlAst$ArypTask: stem AlAst$ArypChoices ScoreAlAst$Aryp 0.8AlAst$Aryp 0.7AlAst$Ary 0.6AlAst$Aryp 0.1......Figure 4: Alternate View: Scoring the Prefix andSuffix2.3.1 Scoring ModelsWe explored several stem scoring models, usingdifferent levels of available information.
Examplesinclude:?
Use the stem translation probability alonescore = t(a|e)where a = Arabic stem, e = corresponding wordin the English sentence?
Also use prefix (p) and suffix (s) conditionalprobabilities; several examples are given in ta-ble 2.Probability con-ditioned onScoring Formulathe candidate stem t(a|e) ?
p(p,s|a)+p(s|a)?p(p|a)2the length of theunstemmed Arabicword (len)t(a|e) ?p(p,s|len)+p(s|len)?p(p|len)2the possible pre-fixes and/or suf-fixest(a|e) ?
p(s|Spossible) ?p(p|Ppossible)the first and lastlettert(a|e)?p(s|last)?p(p|first)Table 2: Example Scoring ModelsThe first two examples use the joint probabilityof the prefix and suffix, with a smoothing back-off(the product of the individual probabilities).
Scor-ing models of this form proved to be poor perform-ers from the beginning, and they were abandoned infavor of the last model, which is a fast, good approx-imation to the third model in Table 2.
The last twomodels successfully solve the problem of the emptyprefix and suffix accumulating excessive probability,which would yield to a stemmer that never removedany affixes.
The results presented in the rest of thepaper use the last scoring model.2.4 Step 2: Using the Unlabeled MonolingualDataThis optional second step can adapt the trained stem-mer to the problem at hand.
Here, we are movingaway from providing the English equivalent, and weare relying on learned prefix, suffix and (to a lesserdegree) stem probabilities.
In a new domain or cor-pus, the second step allows the stemmer to learn newstems and update its statistical profile of the previ-ously seen stems.This step can be performed using monolingualArabic data, with no annotation needed.
Eventhough it is optional, this step is recommended sinceits sole resource can be the data we would need tostem anyway (see Figure 5).Arabic ArabicStemmedStemmerUnstemmedFigure 5: Step 2 DetailStep 1 produced a functional stemming model.We can use the corpus statistics gathered in Step 1to stem the new, monolingual corpus.
However, thescoring model needs to be modified, since t(a|e) isno longer available.
By removing the conditioning,the first/last letter scoring model we used becomesscore = p(a) ?
p(s|last) ?
p(p|first)The model can be updated if the stem candidatescore/probability distribution is sufficiently skewed,and the monolingual text can be stemmed iterativelyusing the new model.
The model is thus adapted tothe particular needs of the new corpus; in practice,convergence is quick (less than 10 iterations).3 Results3.1 Unsupervised Training and TestingFor unsupervised training in Step 1, we used a smallparallel corpus: 10,000 Arabic-English sentencesfrom the United Nations(UN) corpus, where the En-glish part has been stemmed and the Arabic translit-erated.For unsupervised training in Step 2, we used alarger, Arabic only corpus: 80,000 different sen-tences in the same dataset.The test set consisted of 10,000 different sen-tences in the UN dataset; this is the testing set usedbelow unless specified.We also used a larger corpus ( a year of AgenceFrance Press (AFP) data, 237K sentences) for Step 2training and testing, in order to gauge the robustnessand adaptation capability of the stemmer.
Since theUN corpus contains legal proceedings, and the AFPcorpus contains news stories, the two can be seen ascoming from different domains.3.1.1 Measuring Stemmer PerformanceIn this subsection the accuracy is defined as agree-ment with GOLD.
GOLD is a state of the art, pro-prietary Arabic stemmer built using rules, suffix andprefix lists, and human annotated text, in additionto an unsupervised component.
GOLD is an ear-lier version of the stemmer described in (Lee et al,).
Freely available (but less accurate) Arabic lightstemmers are also used in practice.When measuring accuracy, all tokens are consid-ered, including those that cannot be stemmed bysimple affix removal (irregulars, infixes).
Note thatour baseline (removing Al and p, leaving everythingunchanged) is higher that simply leaving all tokensunchanged.For a more relevant task-based evaluation, pleaserefer to Subsection 3.2.3.1.2 The Effect of the Corpus Size: How littleparallel data can we use?We begin by examining the effect that the size ofthe parallel corpus has on the results after the firststep.
Here, we trained our stemmer on three dif-ferent corpus sizes: 50K, 10K, and 2K sentences.The high baseline is obtained by treating Al and pas affixes.
The 2K corpus had acceptable results (ifthis is all the data available).
Using 10K was sig-nificantly better; however the improvement obtainedwhen five times as much data (50K) was used wasinsignificant.
Note that different languages mighthave different corpus size needs.
All other resultsFigure 6: Results after Step 1 : Corpus Size Effectin this paper use 10K sentences.3.1.3 The Knowledge-Free Starting Point afterStep 1Figure 7: Results after Step 1 : Effect of Knowingthe Al+p ruleAlthough severely handicapped at the beginning,the knowledge-free starting point manages to narrowthe performance gap after a few iterations.
Knowingthe Al+p rule still helps at this stage.
However, theperformance gap is narrowed further in Step 2 (seefigure 8), where the knowledge free starting pointbenefitted from the monolingual training.3.1.4 Results after Step 2: Different CorporaUsed for AdaptationFigure 8 shows the results obtained when aug-menting the stemmer trained in Step 1.
Two dif-ferent monolingual corpora are used: one from thesame domain as the test set (80K UN), and one froma different domain/corpus, but three times larger(237K AFP).
The larger dataset seems to be moreuseful in improving the stemmer, even though thedomain was different.Figure 8: Results after Step 2 (Monolingual Corpus)The baseline and the accuracy after Step 1 are pre-sented for reference.3.1.5 Cross-Domain RobustnessFigure 9: Results after Step 2 : Using a DifferentTest SetWe used an additional test set that consisted of10K sentences taken from AFP, instead of UN as inprevious experiments shown in figure 8 .
Its pur-pose was to test the cross-domain robustness of thestemmer and to further examine the importance ofapplying the second step to the data needing to bestemmed.Figure 9 shows that, even though in Step 1 thestemmer was trained on UN proceedings, the re-sults on the cross-domain (AFP) test set are compa-rable to those from the same domain (UN, figure 8).However, for this particular test set the baseline wasmuch higher; thus the relative improvement with re-spect to the baseline is not as high as when the unsu-pervised training and testing set came from the samecollection.3.2 Task-Based Evaluation : ArabicInformation RetrievalTask Description:Given a set of Arabic documents and an Arabicquery, find a list of documents relevant to the query,and rank them by probability of relevance.We used the TREC 2002 documents (severalyears of AFP data), queries and relevance judg-ments.
The 50 queries have a shorter, ?title?
compo-nent as wel as a longer ?description?.
We stemmedboth the queries and the documents using UNSUPand GOLD respectively.
For comparison purposes,we also left the documents and queries unstemmed.The UNSUP stemmer was trained with 10K UNsentences in Step 1, and with one year?s worth ofmonolingual AFP data (1995) in Step 2.Evaluation metric: The evaluation metric usedbelow is mean average precision (the standard IRmetric), which is the mean of average precisionscores for each query.
The average precision of asingle query is the mean of the precision scores aftereach relevant document retrieved.
Note that aver-age precision implicitly includes recall information.Precision is defined as the ratio of relevant docu-ments to total documents retrieved up to that pointin the ranking.ResultsFigure 10: Arabic Information Retrieval ResultsWe looked at the effect of different testing con-ditions on the mean average precision for the 50queries.
In Figure 10, the first set of bars uses thequery titles only, the second set adds the descrip-tion, and the last set restricts the results to one year(1995), using both the title and description.
Wetested this last condition because the unsupervisedstemmer was refined in Step 2 using 1995 docu-ments.
The last group of bars shows a higher relativeimprovement over the unstemmed baseline; how-ever, this last condition is based on a smaller sampleof relevance judgements (restricted to one year) andis therefore not as representative of the IR task as thefirst two testing conditions.4 Conclusions and Future WorkThis paper presents an unsupervised learning ap-proach to building a non-English (Arabic) stemmerusing a small sentence-aligned parallel corpus inwhich the English part has been stemmed.
No paral-lel text is needed to use the stemmer.
Monolingual,unannotated text can be used to further improve thestemmer by allowing it to adapt to a desired domainor genre.
The approach is applicable to any languagethat needs affix removal; for Arabic, our approachresults in 87.5% agreement with a proprietary Ara-bic stemmer built using rules, affix lists, and hu-man annotated text, in addition to an unsupervisedcomponent.
Task-based evaluation using Arabic in-formation retrieval indicates an improvement of 22-38% in average precision over unstemmed text, and93-96% of the performance of the state of the art,language specific stemmer above.We can speculate that, because of the statisticalnature of the unsupervised stemmer, it tends to fo-cus on the same kind of meaning units that are sig-nificant for IR, whether or not they are linguisticallycorrect.
This could explain why the gap betheenGOLD and UNSUP is narrowed with task-basedevaluation and is a desirable effect when the stem-mer is to be used for IR tasks.We are planning to experiment with different lan-guages, translation model alternatives, and to extendtask-based evaluation to different tasks such as ma-chine translation and cross-lingual topic detectionand tracking.5 AcknowledgementsWe would like to thank the reviewers for their help-ful observations and for identifying Arabic mis-spellings.
This work was partially supported bythe Defense Advanced Research Projects Agencyand monitored by SPAWAR under contract No.N66001-99-2-8916.
This research is also spon-sored in part by the National Science Foundation(NSF) under grants EIA-9873009 and IIS-9982226,and in part by the DoD under award 114008-N66001992891808.
However, any opinions, views,conclusions and findings in this paper are those ofthe authors and do not necessarily reflect the posi-tion of policy of the Government and no official en-dorsement should be inferred.ReferencesP.
Brown, S. Della Pietra, V. Della Pietra, and R. Mer-cer.
1993.
The mathematics of machine translation:Parameter estimation.
In Computational Linguistics,pages 263?311.Tim Buckwalter.
1999.
Buckwalter transliteration.http://www.cis.upenn.edu/?cis639/arabic/info/translit-chart.html.Alexander Clark.
2001.
Learning morphology with pairhidden markov models.
In ACL (Companion Volume),pages 55?60.Mona Diab and Philip Resnik.
2002.
An unsupervisedmethod for word sense tagging using parallel corpora.In Proceedings of the 40th Annual Meeting of the As-sociation for Computational Linguistics (ACL), pages255?262, July.John Goldsmith.
2001.
Unsupervised learning of themorphology of a natural language.
In ComputationalLinguistics.Leah Larkey, Lisa Ballesteros, and Margaret Connell.Improving stemming for arabic information retrieval:Light stemming and co-occurrence analysis.
In SIGIR2002, pages 275?282.Young-Suk Lee, Kishore Papineni, Salim Roukos, Os-sama Emam, and Hany Hassan.
Language modelbased arabic word segmentation.
In To appear in ACL2003.Patrick Schone and Daniel Jurafsky.
Knowledge-free in-duction of morphology using latent semantic analy-sis.
In 4th Conference on Computational Natural Lan-guage Learning, Lisbon, 2000.Matthew Snover.
2002.
An unsupervised knowledgefree algorithm for the learning of morphology in natu-ral languages.
Master?s thesis, Washington University,May.David Yarowsky, Grace Ngai, and Richard Wicentowski.2000.
Inducing multilingual text analysis tools via ro-bust projection across aligned corpora.
