NAACL-HLT 2012 Workshop on Future directions and needs in the Spoken Dialog Community: Tools and Data, pages 13?14,Montre?al, Canada, June 7, 2012. c?2012 Association for Computational LinguisticsTowards Situated CollaborationDan Bohus, Ece Kamar, Eric HorvitzMicrosoft ResearchOne Microsoft WayRedmond, WA, 98052, USA{dbohus,eckamar,horvitz@microsoft.com}AbstractWe outline a set of key challenges for dialogmanagement in physically situated interactivesystems, and propose a core shift in perspec-tive that places spoken dialog in the context ofthe larger collaborative challenge of managingparallel, coordinated actions in the openworld.Multiple models for dialog management have beenproposed, studied, and evaluated in the researchcommunity (i.a.
Allen et al 2001; Bohus and Rud-nicky, 2009; Rich and Sidner, 1998; Traum andLarsson, 2003; Williams and Young, 2007).
In theprocess, a diverse set of problems have come tolight and have been pursued.
These include thechallenges of modeling initiative in interaction,contextual interpretation and processing, the man-agement of uncertainty, grounding, error handlingand recovery, turn-taking and, more recently, in-cremental processing in dialog systems.
Analysesof existing approaches (Allen et.
al, 2001; Church-er et.
al, 1997; McTear 2002; Paek and Pieraccini,2008) reveal a constellation of benefits but alsoshortcomings along multiple dimensions, where nosingle technique provides the benefits of all.While taking incremental, focused steps is im-portant for making progress within a mature disci-pline, we believe that the current scope andconceptual borders of work in spoken dialog con-strains thinking about possibilities and gets in theway of achieving breakthrough advances.
Researchto date on dialog management has focused almostexclusively on dyadic settings, where a single userinteracts with a system over a relatively narrow,speech-only channel.
Characteristics of this domi-nant and shared worldview on dialog research havedriven modeling and architectural choices, and of-ten done so in an implicit, hidden manner.
For in-stance, dialog is often viewed as a collection ofdialog moves that are timed in a relatively well-structured, sequential fashion.
As a consequence,dialog management models typically operate on a?per-turn?
basis: inputs are assumed to arrive se-quentially and are processed one at a time; for eachreceived input, discourse understanding is per-formed, and a corresponding response is generated.In reality, interactions among actors situated inthe open, physical world depart deeply from com-mon assumptions made in spoken dialog researchand bring into focus an array of important, newchallenges (Horvitz, 2007; Bohus and Horvitz,2010; Bohus, Horvitz, Kanda et al, eds., 2010).We describe some of the challenges with respect todialog management, and re-frame this problem asan instance of the larger collaborative challenge ofmanaging parallel, coordinated actions amidst adynamically changing physical world.As an example, consider a robot that has beengiven the responsibility of greeting, interacting,and escorting visitors in a building.
In this setting,reasoning about the actors, objects and events andrelationships in the scene can play a critical role inunderstanding and organizing the interactions.
Thesurrounding environment provides rich, continu-ously streaming situational context that is relevantfor determining the best way an agent might con-tribute to interactions.
Because the situational con-text can evolve asynchronously with respect toturns in the conversation, systems that operate inthe open world must be able to plan continuously,13in stream, rather than on a ?per-turn?
basis.
Inter-action and collaboration in these settings is bestviewed as a flow of coordinated, parallel actions.The sequential structure of turns in dyadic interac-tions is but one example of such coordination, fo-cused solely on linguistic actions.
However, tosuccessfully interact and collaborate with multipleparticipants in physically situated settings, an agentmust be able to recognize, plan, and produce bothlinguistic and non-linguistic actions, and reasonabout potentially complex patterns of coordinationbetween actions, in-stream?as they are being pro-duced by the participants in the collaboration.We argue that attaining the dream of fluid,seamless spoken language interaction with ma-chines requires a fundamental shift in how we viewdialog management.
First, we need to move fromper-turn to continual in-stream planning.
Second,we need to move from reasoning about sequentialactions to reasoning about parallel and coordinat-ed actions and their influence on states in theworld.
And third, we need models that can trackand leverage the streaming situational context,from noisy observations, to make decisions abouthow to best contribute to collaborations.Spoken dialog is an important channel for ex-pressing coordinative information.
However, weneed to recognize and begin to tackle head on thelarger challenge of situated collaborative activitymanagement.
We understand that taking this per-spective introduces new complexities?and thatsome of our colleagues will view diving into thelarger problems in advance of solving simpler onesas being unwise.
However, we believe that wemust embrace the larger goals to make significantprogress on the struggles with the simpler ones,and that the investment in solving challenges withphysically situated collaboration will have eventualpayoffs in enabling progress in spoken dialog.Making progress on the broader challenge re-quires technical innovations, tools, and data.
Con-sider for instance one sub-problem of belieftracking in these systems: continuously updatingbeliefs over the state of the collaborative activityand the situational context requires the develop-ment of new types of models that can combinestreaming evidence about context collectedthrough sensors, with discrete evidence about theactions performed or the turns spoken collectedthrough speech, gesture or other action-recognitioncomponents.
In addition, progress hinges on identi-fying a set of relevant problem domains, and coor-dinating efforts in the community to collect data,and comparatively evaluate proposed approaches.New tools geared towards analysis, visualizationand debugging with streaming multimodal data arealso required.We propose a core shift of perspective and as-sociated research agenda for moving from dialogmanagement to situated collaborative activitymanagement.
We invite discussion on these ideas.ReferencesAllen, J.F., Byron, D.K., Dzikovska, M., Ferguson, G.,Galescu, L., and Stent, A.
2001.
Towards Conversa-tional Human-Computer Interaction, AI Magazine,22(3)Bohus, D., and Rudnicky, A.
2009.
The Ravenclaw dia-log management framework: Architecture and sys-tems, in Computer, Speech and Language, 23(3).Bohus, D., and Horvitz, E. 2010.
On the Challenges andOpportunities of Physically Situated Dialog, AAAISymposium on Dialog with Robots, Arlington, VA.Bohus, D., Horvitz, E., Kanda, T., Mutlu, B., Raux, A.,editors, 2010.
Special Issue on ?Dialog with Robots?,AI Magazine 32(4).Churcher, G. E., Atwell, E.S, and Souter, C. 1997 Dia-logue Management Systems: a Survey and Overview,Technical Report, University of Leeds, Leeds, UK.Horvitz, E., 2007.
Reflections on Challenges and Prom-ises of Mixed-Initiative Interaction, AI Magazine 28,pp.
19-22.McTear, M.F.
2002.
Spoken dialogue technology: ena-bling the conversational user interface, ACM Compu-ting Surveys, 34(1):90-169.Paek, T., and Pierracini, R. 2008.
Automating SpokenDialogue Management design using machine learn-ing: An industry perspective, Speech Communica-tion, 50(8-9):716-729.Rich, C., and Sidner, C.L.
1998.
Collagen: A Collabora-tion Manager for a Collaborative Interface Agent,User Modelling and User Assisted Interaction, 7(3-4):315-350, Kluwer Academic Publishers.Traum, D., and Larsson, S. 2003.
The Information StateApproach to Dialogue Management.
Current andNew Directions in Discourse and Dialogue, TextSpeech and Language Technology, 22:325-353.Williams, J., and Young, S., 2007.
Partially ObservableMarkov Decisions Processes for Spoken Dialog Sys-tems, Computer, Speech and Language, 21(2).Young, S. 2006.
Using POMDPs for Dialog Manage-ment, in Proc.
of SLT-2006, Palm Beach, Aruba.14
