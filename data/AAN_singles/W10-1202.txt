Proceedings of the NAACL HLT 2010 Workshop on Semantic Search, pages 10?18,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsExperts?
Retrieval with Multiword-Enhanced Author Topic ModelNikhil Johri Dan Roth Yuancheng TuDept.
of Computer Science Dept.
of LinguisticsUniversity of Illinois at Urbana-Champaign{njohri2,danr,ytu}@illinois.eduAbstractIn this paper, we propose a multiword-enhanced author topic model that clusters au-thors with similar interests and expertise, andapply it to an information retrieval system thatreturns a ranked list of authors related to a key-word.
For example, we can retrieve EugeneCharniak via search for statistical parsing.The existing works on author topic model-ing assume a ?bag-of-words?
representation.However, many semantic atomic concepts arerepresented by multiwords in text documents.This paper presents a pre-computation step asa way to discover these multiwords in the cor-pus automatically and tags them in the term-document matrix.
The key advantage of thismethod is that it retains the simplicity andthe computational efficiency of the unigrammodel.
In addition to a qualitative evaluation,we evaluate the results by using the topic mod-els as a component in a search engine.
We ex-hibit improved retrieval scores when the docu-ments are represented via sets of latent topicsand authors.1 IntroductionThis paper addresses the problem of searching peo-ple with similar interests and expertise without in-putting personal names as queries.
Many existingpeople search engines need people?s names to do a?keyword?
style search, using a person?s name as aquery.
However, in many situations, such informa-tion is impossible to know beforehand.
Imagine ascenario where the statistics department of a univer-sity invited a world-wide known expert in Bayesianstatistics and machine learning to give a keynotespeech; how can the department head notify all thepeople on campus who are interested without spam-ming those who are not?
Our paper proposes a solu-tion to the aforementioned scenario by providing asearch engine which goes beyond ?keyword?
searchand can retrieve such information semantically.
Thedepartment head would only need to input the do-main keyword of the keynote speaker, i.e.
Bayesianstatistics, machine learning, and all professors andstudents who are interested in this topic will beretrieved.
Specifically, we propose a Multiword-enhanced Author-Topic Model (MATM), a proba-bilistic generative model which assumes two stepsof generation process when producing a document.Statistical topical modeling (Blei and Lafferty,2009a) has attracted much attention recently due toits broad applications in machine learning, text min-ing and information retrieval.
In these models, se-mantic topics are represented by multinomial distri-bution over words.
Typically, the content of eachtopic is visualized by simply listing the words in or-der of decreasing probability and the ?meaning?
ofeach topic is reflected by the top 10 to 20 words inthat list.
The Author-Topic Model (ATM) (Steyverset al, 2004; Rosen-Zvi et al, 2004) extends the ba-sic topical models to include author information inwhich topics and authors are modeled jointly.
Eachauthor is a multinomial distribution over topics andeach topic is a multinomial distribution over words.Our contribution to this paper is two-fold.
Firstof all, our model, MATM, extends the original ATMby adding semantically coherent multiwords into theterm-document matrix to relax the model?s ?bag-of-10words?
assumption.
Each multiword is discoveredvia statistical measurement and filtered by its part ofspeech pattern via an off-line way.
One key advan-tage of tagging these semantic atomic units off-line,is the retention of the flexibility and computationalefficiency in using the simpler word exchangeablemodel, while providing better interpretation of thetopics author distribution.Secondly, to the best of our knowledge, this isthe first proposal to apply the enhanced author topicmodeling in a semantic retrieval scenario, wheresearching people is associated with a set of hid-den semantically meaningful topics instead of theirnames.
While current search engines cannot sup-port interactive and exploratory search effectively,search based on our model serves very well to an-swer a range of exploratory queries about the doc-ument collections by semantically linking the inter-ests of the authors to the topics of the collection, andultimately to the distribution of the words in the doc-uments.The rest of the paper is organized as follows.
Wepresent some related work on topic modeling, theoriginal author-topic model and automatic phrasediscovery methods in Sec.
2.
Then our model is de-scribed in Sec.
3.
Sec.
4 presents our experimentsand the evaluation of our method on expert search.We conclude this paper in Sec.
5 with some discus-sion and several further developments.2 Related WorkAuthor topic modeling, originally proposedin (Steyvers et al, 2004; Rosen-Zvi et al, 2004), isan extension of another popular topic model, LatentDirichlet Allocation (LDA) (Blei et al, 2003), aprobabilistic generative model that can be used toestimate the properties of multinomial observationsvia unsupervised learning.
LDA represents eachdocument as a mixture of probabilistic topics andeach topic as a multinomial distribution over words.The Author topic model adds an author layer overLDA and assumes that the topic proportion of agiven document is generated by the chosen author.Both LDA and the author topic model assumebag-of-words representation.
As shown by manyprevious works (Blei et al, 2003; Steyvers et al,2004), even such unrealistic assumption can actu-ally lead to a reasonable topic distribution with rel-atively simple and computationally efficient infer-ence algorithm.
However, this unigram represen-tation also poses major handicap when interpretingand applying the hidden topic distributions.
Theproposed MATM is an effort to try to leverage thisproblem in author topic modeling.
There have beensome works on Ngram topic modeling over the orig-inal LDA model (Wallach, 2006; Wang and McCal-lum, 2005; Wang et al, 2007; Griffiths et al, 2007).However, to the best of our knowledge, this paperis the first to embed multiword expressions into theauthor topic model.Many of these Ngram topic models (Wang andMcCallum, 2005; Wang et al, 2007; Griffiths etal., 2007) improves the base model by adding a newindicator variable xi to signify if a bigram shouldbe generated.
If xi = 1, the word wi is gener-ated from a distribution that depends only on theprevious word to form an Ngram.
Otherwise, it isgenerated from a distribution only on the topic pro-portion (Griffiths et al, 2007) or both the previouswords and the latent topic (Wang and McCallum,2005; Wang et al, 2007).
However, these complexmodels not only increase the parameter size to Vtimes larger than the size of the original LDA modelparameters (V is the size of the vocabulary of thedocument collection) 1, it also faces the problem ofchoosing which word to be the topic of the potentialNgram.
In many text retrieval tasks, the humongoussize of data may prevent us using such complicatedcomputation on-line.
However, our model retainsthe computational efficiency by adding a simple tag-ging process via pre-computation.Another effort in the current literature to interpretthe meaning of the topics is to label the topics viaa post-processing way (Mei et al, 2007; Blei andLafferty, 2009b; Magatti et al, 2009).
For example,Probabilistic topic labeling (Mei et al, 2007) firstextracts a set of candidate label phrases from a refer-ence collection and represents each candidate label-ing phrase with a multinomial distribution of words.Then KL divergence is used to rank the most prob-able labels for a given topic.
This method needs notonly extra reference text collection, but also facing1LDA collocation models and topic Ngram models also haveparameters for the binomial distribution of the indicator variablexi for each word in the vocabulary.11the problem of finding discriminative and high cov-erage candidate labels.
Blei and Lafferty (Blei andLafferty, 2009b) proposed a method to annotate eachword of the corpus by its posterior word topic distri-bution and then cast a statistical co-occurrence anal-ysis to extract the most significant Ngrams for eachtopic and visualize the topic with these Ngrams.However, they only applied their method to basicLDA model.In this paper, we applied our multiword extensionto the author topic modeling and no extra referencecorpora are needed.
The MATM, with an extra pre-computing step to add meaningful multiwords intothe term-document matrix, enables us to retain theflexibility and computational efficiency to use thesimpler word exchangeable model, while providingbetter interpretation of the topics and author distri-bution.3 Multiword-enhanced Author-TopicModelThe MATM is an extension of the original ATM(Rosen-Zvi et al, 2004; Steyvers et al, 2004) bysemantically tagging collocations or multiword ex-pressions, which represent atomic concepts in doc-uments in the term-document matrix of the model.Such tagging procedure enables us to retain compu-tational efficiency of the word-level exchangeabil-ity of the orginal ATM while provides more sensi-ble topic distributions and better author topic coher-ence.
The details of our model are presented in Al-gorithm 1.3.1 Beyond Bag-of-Words TaggingThe first for loop in Algorithm 1 is the procedureof our multiword tagging.
Commonly used ngrams,or statistically short phrases in text retrieval, orso-called collocations in natural language process-ing have long been studied by linguistics in vari-ous ways.
Traditional collocation discovery meth-ods range from frequency to mean and variance,from statistical hypothesis testing, to mutual infor-mation (Manning and Schtze, 1999).
In this pa-per, we use a simple statistical hypothesis testingmethod, namely Pearson?s chi-square test imple-mented in Ngram Statistic Package (Banerjee andPedersen, 2003), enhanced by passing the candidatephrases through some pre-defined part of speechpatterns that are likely to be true phrases.
Thisvery simple heuristic has been shown to improve thecounting based methods significantly (Justenson andKatz, 1995).The ?2 test is chosen since it does not assume anynormally distributed probabilities and the essenceof this test is to compare the observed frequencieswith the frequencies expected for independence.
Wechoose this simple statistic method since in manytext retrieval tasks the volume of data we see al-ways makes it impractical to use very sophisticatedstatistical computations.
We also focus on nominalphrases, such as bigram and trigram noun phrasessince they are most likely to function as semanticatomic unit to directly represent the concepts in textdocuments.3.2 Author Topic ModelingThe last three generative procedures described in Al-gorithm 1 jointly model the author and topic infor-mation.
This generative model is adapted directlyfrom (Steyvers et al, 2004).
Graphically, it can bevisualized as shown in Figure 1.Figure 1: Plate notation of our model: MATMThe four plates in Fiture 1 represent topic (T), au-thor (A), document (D) and Words in each document(Nd) respectively.
Each author is associated with amultinomial distribution over all topics, ~?a and eachtopic is a multinomial distribution over all words, ~?t.Each of these distribution has a symmetric Dirichletprior over it, ~?
and ~?
respectively.
When generat-ing a document, an author k is first chosen accordingto a uniform distribution.
Then this author choosesthe topic from his/her associated multinomial distri-bution over topics and then generates a word fromthe multinomial distribution of that topic over the12words.Algorithm 1: MATM: A,T ,D,N are fourplates as shown in Fig.
1.
The first for loop is theoff-line process of multiword expressions.
Therest of the algorithm is the generative process ofthe author topic modeling.Data: A,T ,D,Nfor all documents d ?
D doPart-of-Speech tagging ;Bigram extraction ;Part-of Speech Pattern Filtering ;Add discovered bigrams into N ;for each author a ?
A dodraw a distribution over topics:~?a ?
DirT (~?)
;for each topic t ?
T dodraw a distribution over words:~?t ?
DirN (~?)
;for each document d ?
D and k authors ?
d dofor each word w ?
d dochoose an author k ?
uniformly;draw a topic assignment i given theauthor: zk,i|k ?
Multinomial(?a) ;draw a word from the chosen topic:wd,k,i|zk,i ?
Multinomial(?zk,i) ;MATM includes two sets of parameters.
The Ttopic distribution over words, ?t which is similar tothat in LDA.
However, instead of a document-topicdistribution, author topic modeling has the author-topic distribution, ?a.
Using a matrix factorizationinterpretation, similar to what Steyvers, Griffiths andHofmann have pointed out for LDA (Steyvers andGriffiths, 2007) and PLSI (Hofmann, 1999), a word-author co-occurrence matrix in author topic modelcan be split into two parts: a word-topic matrix ?and a topic-author matrix ?.
And the hidden topicserves as the low dimensional representation for thecontent of the document.Although the MATM is a relatively simple model,finding its posterior distribution over these hiddenvariables is still intractable.
Many efficient ap-proximate inference algorithms have been used tosolve this problem including Gibbs sampling (Grif-fiths and Steyvers, 2004; Steyvers and Griffiths,2007; Griffiths et al, 2007) and mean-field vari-ational methods (Blei et al, 2003).
Gibbs sam-pling is a special case of Markov-Chain Monte Carlo(MCMC) sampling and often yields relatively sim-ple algorithms for approximate inference in high di-mensional models.In our MATM, we use a collapsed Gibbs sam-pler for our parameter estimation.
In this Gibbssampler, we integrated out the hidden variables ?and ?
as shown by the delta function in equation 2.This Dirichlet delta function with a M dimentionalsymmetric Dirichlet prior is defined in Equation 1.For the current state j, the conditional probabilityof drawing the kth author Kkj and the ith topic Zijpair, given all the hyperparameters and all the obe-served documents and authors except the current as-signment (the exception is denoted by the symbol?j), is defined in Equation 2.?M (?)
=?(?M)?
(M?)
(1)P (Zij ,Kkj |Wj = w,Z?j ,K?j ,W?j , Ad, ~?, ~?)??(nZ+~?)?(nZ,?j+~?)?(nK+~?)?(nK,?j+~?
)= nwi,?j+ ~?w?Vw=1 nwi,?j+V ~?wnik,?j+~?i?Ti=1 nik,?j+T ~?i(2)And the parameter sets ?
and ?
can be interpretedas sufficient statistics on the state variables of theMarkov Chain due to the Dirichlet conjugate priorswe used for the multinomial distributions.
The twoformulars are shown in Equation 3 and Equation 4 inwhich nwi is defined as the number of times that theword w is generated by topic i and nik is defined asthe number of times that topic i is generated by au-thor k. The Gibbs sampler used in our experimentsis from the Matlab Topic Modeling Toolbox 2.?w,i =nwi + ~?w?Vw=1 nwi + V ~?w(3)?k,i =nik + ~?i?Ti=1 nik + T ~?i(4)2http://psiexp.ss.uci.edu/research/programs data/toolbox.htm134 Experiments and AnalysisIn this section, we describe the empirical evaluationof our model qualitatively and quantitatively by ap-plying our model to a text retrieval system we callExpert Search.
This search engine is intended to re-trieve groups of experts with similar interests and ex-pertise by inputting only general domain key words,such as syntactic parsing, information retrieval.We first describe the data set, the retrieval systemand the evaluation metrics.
Then we present the em-pirical results both qualitatively and quantitatively.4.1 DataWe crawled from ACL anthology website and col-lected seven years of annual ACL conference papersas our corpus.
The reference section is deleted fromeach paper to reduce some noisy vocabulary, suchas idiosyncratic proper names, and some coding er-rors caused during the file format conversion pro-cess.
We applied a part of speech tagger3 to tagthe files and retain in our vocabulary only contentwords, i.e., nouns, verbs, adjectives and adverbs.The ACL anthology website explicitly lists eachpaper together with its title and author information.Therefore, the author information of each paper canbe obtained accurately without extracting from theoriginal paper.
We transformed all pdf files to textfiles and normalized all author names by eliminatingtheir middle name initials if they are present in thelisted names.
There is a total of 1,326 papers in thecollected corpus with 2, 084 authors.
Then multi-words (in our current experiments, the bigram collo-cations) are discovered via the ?2 statistics and partof speech pattern filtering.
These multiwords arethen added into the vocabulary to build our model.Some basic statistics about this corpus is summa-rized in Table 1.Two sets of results are evaluated use the retrievalsystem in our experiments: one set is based on un-igram vocabulary and the other with the vocabularyexpanded by the multiwords.4.2 Evaluation on Expert SearchWe designed a preliminary retrieval system to eval-uate our model.
The functionality of this search is3The tagger is from:http://l2r.cs.uiuc.edu/?cogcomp/software.phpACL Corpus StatisticsYear range 2003-2009Total number of papers 1,326Total number of authors 2,084Total unigrams 34,012Total unigram and multiwords 205,260Table 1: Description of the ACL seven-year collection inour experimentsto associate words with individual authors, i.e., werank the joint probability of the query words and thetarget author P (W,a).
This probability is marginal-ized over all topics in the model to rank all authorsin our corpus.
In addition, the model assumes thatthe word and the author is conditionally indepen-dent given the topic.
Formally, we define the rankingfunction of our retrieval system in Equation 5:P (W,a) =?wi?i?tP (wi, a|t)P (t)=?wi?i?tP (wi|t)P (a|t)P (t) (5)W is the input query, which may contain one ormore words.
If a multiword is detected within thequery, it is added into the query.
The final score isthe sum of all words in this query weighted by theirinverse document frequency ?i The inverse docu-ment frequency is defined as Equation 6.?i =1DF (wi)(6)In our experiments, we chose ten queries whichcovers several most popular research areas in com-putational linguistics and natural language process-ing.
In our unigram model, query words are treatedtoken by token.
However, in our multiword model,if the query contains a multiword inside our vocabu-lary, it is treated as an additional token to expand thequery.
For each query, top 10 authors are returnedfrom the system.
We manually label the relevanceof these 10 authors based on the papers they submit-ted to these seven-year ACL conferences collectedin our corpus.
Two evaluation metrics are used tomeasure the precision of the retrieving results.
Firstwe evaluate the precision at a given cut-off rank,namely precision at K with K ranging from 1 to 10.14We also calculate the average precision (AP) foreach query and the mean average precision (MAP)for all the 10 queries.
Average precision not onlytakes ranking as consideration but also emphasizesranking relevant documents higher.
Different fromprecision at K, it is sensitive to the ranking and cap-tures some recall information since it assumes theprecision of the non-retrieved documents to be zero.It is defined as the average of precisions computedat the point of each of the relevant documents in theranked list as shown in equation 7.AP =?nr=1(Precision(r)?
rel(r))?relevant documents(7)Currently in our experiments, we do not have apool of labeled authors to do a good evaluation ofrecall of our system.
However, as in the web brows-ing activity, many users only care about the first sev-eral hits of the retrieving results and precision at Kand MAP measurements are robust measurementsfor this purpose.4.3 Results and AnalysisIn this section, we first examine the qualitative re-sults from our model and then report the evaluationon the external expert search.4.3.1 Qualitative Coherence AnalysisAs have shown by other works on Ngram topicmodeling (Wallach, 2006; Wang et al, 2007; Grif-fiths et al, 2007), our model also demonstrated thatembedding multiword tokens into the simple authortopic model can always achieve more coherent andbetter interpretable topics.
We list top 15 wordsfrom two topics of the multiword model and uni-gram model respectively in Table 2.
Unigram topicscontain more general words which can occur in ev-ery topic and are usually less discriminative amongtopics.Our experiments also show that embedding themultiword tokens into the model achieves betterclustering of the authors and the coherence betweenauthors and topics.
We demonstrate this qualita-tively by listing two examples respectively from themultiword models and the unigram model in Table 3.For example, for the topic on dependency pars-ing, unigram model missed Ryan-McDonald and theranking of the authors are also questionable.
FurtherMultiWord Model Unigram ModelTOPIC 4 Topic 51coreference-resolution resolutionantecedent antecedenttreesubstitution-grammars pronouncompletely pronounspronoun isresolution informationangry antecedentscandidate anaphorextracted syntacticfeature semanticpronouns coreferencemodel anaphoraperceptual-cooccurrence definitecertain-time modelanaphora-resolution onlyTOPIC 49 Topic 95sense sensesenses sensesword-sense disambiguationtarget-word wordword-senses contextsense-disambiguation ontextnouns ambiguousautomatically accuracysemantic-relatedness nounsdisambiguation unsupervisedprovided targetambiguous-word predominantconcepts samplelexical-sample automaticallynouns-verbs meaningTable 2: Comparison of the topic interpretation from themultiword-enhanced and the unigram models.
Qualita-tively, topics with multiwords are more interpretable.quantitative measurement is listed in our quantita-tive evaluation section.
However, qualitatively, mul-tiword model seems less problematic.Some of the unfamiliar author may not be easy tomake a relevance judgment.
However, if we traceall the papers the author wrote in our collected cor-pus, many of the authors are coherently related to thetopic.
We list all the papers in our corpus for threeauthors from the machine translation topic derivedfrom the multiword model in Table 4 to demonstratethe coherence between the author and the relatedtopic.
However, it is also obvious that our modelmissed some real experts in the corresponding field.15MultiWord Model Unigram ModelTopic 63 Topic 145 Topic 23 Topic 78Word Word Word Wordtranslation dependency-parsing translation dependencymachine-translation dependency-tree translations headlanguage-model dependency-trees bilingual dependenciesstatistical-machine dependency pairs structuretranslations dependency-structures language structuresphrases dependency-graph machine dependenttranslation-model dependency-relation parallel orderdecoding dependency-relations translated wordscore order monolingual leftdecoder does quality doesAuthor Author Author AuthorShouxun-Lin Joakim-Nivre Hua-Wu Christopher-ManningDavid-Chiang Jens-Nilsson Philipp-Koehn Hisami-SuzukQun-Liu David-Temperley Ming-Zhou Kenji-SagaePhilipp-Koehn Wei-He Shouxun-Lin Jens-NilssonChi-Ho-Li Elijah-Mayfield David-Chiang Jinxi-XuChristoph-Tillmann Valentin-Jijkoun Yajuan-Lu Joakim-NivreChris-Dyer Christopher-Manning Haifeng-Wang Valentin-JijkounG-Haffari Jiri-Havelka Aiti-Aw Elijah-MayfieldTaro-Watanabe Ryan-McDonald Chris-Callison-Burch David-TemperleyAiti-Aw Andre-Martins Franz-Och Julia-HockenmaierTable 3: Two examples for topic and author coherece from multiword-enhanced model and unigram model.
Top 10words and authors are listed accordingly for each model.For example, we did not get Kevin Knight for themachine translation topic.
This may be due to thelimitation of our corpus since we only collected pa-pers from one conference in a limited time, or be-cause usually these experts write more divergent onvarious topics.Another observation in our experiment is thatsome experts with many papers may not be rankedat the very top by our system.
However, they havepretty high probability to associate with several top-ics.
Intuitively this makes sense, since many of thesefamous experts write papers with their students invarious topics.
Their scores may therefore not be ashigh as authors who have fewer papers in the corpuswhich are concentrated in one topic.4.3.2 Results from Expert SearchOne annotator labeled the relevance of the re-trieval results from our expert search system.
Theannotator was also given all the paper titles of eachcorresponding retrieved author to help make the bi-nary judgment.
We experimented with ten queriesand retrieved the top ten authors for each query.We first used the precision at K for evaluation.
wecalculate the precision at K for both of our multi-word model and the unigram model and the resultsare listed in Table 5.
It is obvious that at every rankposition, the multiword model works better than theunigram model.
In order to focus more on relevantretrieval results, we then calculate the average preci-sion for each query and mean average precision forboth models.
The results are in Table 6.When only comparing the mean average precision(MAP), the multiword model works better.
How-ever, when examining the average precision of eachquery within these two models, the unigram modelalso works pretty well with some queries.
How thequery words may interact with our model deservesfurther investigation.5 Discussion and Further DevelopmentIn this paper, we extended the existing author topicmodel with multiword term-document input and ap-plied it to the domain of expert retrieval.
Althoughour study is preliminary, our experiments do return16Author Papers from ACL(03-09)Shouxun-LinLog-linear Models for Word AlignmentMaximum Entropy Based Phrase Reordering Model for Statistical Machine TranslationTree-to-String Alignment Template for Statistical Machine TranslationForest-to-String Statistical Translation RulesPartial Matching Strategy for Phrase-based Statistical Machine TranslationDavid-ChiangA Hierarchical Phrase-Based Model for Statistical Machine TranslationWord Sense Disambiguation Improves Statistical Machine TranslationForest Rescoring: Faster Decoding with Integrated Language ModelsFast Consensus Decoding over Translation ForestsPhilipp-KoehnFeature-Rich Statistical Translation of Noun PhrasesClause Restructuring for Statistical Machine TranslationMoses: Open Source Toolkit for Statistical Machine TranslationEnriching Morphologically Poor Languages for Statistical Machine TranslationA Web-Based Interactive Computer Aided Translation ToolTopics in Statistical Machine TranslationTable 4: Papers in our ACL corpus for three authors related to the ?machine translation?
topic in Table 3.Precision@KK Multiword Model Unigram Model1 0.90 0.802 0.80 0.803 0.73 0.674 0.70 0.655 0.70 0.646 0.72 0.657 0.71 0.648 0.71 0.669 0.71 0.6610 0.70 0.64Table 5: Precision at K evaluation of the multiword-enhanced model and the unigram model.promising results, demonstrating the effectivenessof our model in improving coherence in topic clus-ters.
In addition, the use of the MATM for expertretrieval returned some useful preliminary results,which can be further improved in a number of ways.One immediate improvement would be an exten-sion of our corpus.
In our experiments, we consid-ered only ACL papers from the last 7 years.
If weextend our data to cover papers from additional con-ferences, we will be able to strengthen author-topicassociations for authors who submit papers on thesame topics to different conferences.
This will alsoallow more prominent authors to come to the fore-front in our search application.
Such a modifica-Average Precision (AP)Query Multi.
Mod.
Uni.
Mod.Language Model 0.79 0.58Unsupervised Learning 1.0 0.78Supervised Learning 0.84 0.74Machine Translation 0.95 1.0Semantic Role Labeling 0.81 0.57Coreference Resolution 0.59 0.72Hidden Markov Model 0.93 0.37Dependency Parsing 0.75 0.94Parsing 0.81 0.98Transliteration 0.62 0.85MAP: 0.81 0.75Table 6: Average Precision (AP) for each query and MeanAverage Precision (MAP) of the multiword-enhancedmodel and the unigram model.tion would require us to further increase the model?scomputational efficiency to handle huge volumes ofdata encountered in real retrieval systems.Another further development of this paper is theaddition of citation information to the model as alayer of supervision for the retrieval system.
For in-stance, an author who is cited frequently could havea higher weight in our system than one who isn?t,and could occur more prominently in query results.Finally, we can provide a better evaluation of oursystem through a measure of recall and a simplebaseline system founded on keyword search of pa-per titles.
Recall can be computed via comparison toa set of expected prominent authors for each query.17AcknowledgmentsThe research in this paper was supported by the Mul-timodal Information Access & Synthesis Center atUIUC, part of CCICADA, a DHS Science and Tech-nology Center of Excellence.ReferencesS.
Banerjee and T. Pedersen.
2003.
The design, im-plementation, and use of the Ngram Statistic Package.In Proceedings of the Fourth International Conferenceon Intelligent Text Processing and Computational Lin-guistics, pages 370?381.D.
Blei and J. Lafferty.
2009a.
Topic models.
In A. Sri-vastava and M. Sahami, editors, Text Mining: Theoryand Applications.
Taylor and Francis.D.
Blei and J. Lafferty.
2009b.
Visualiz-ing topics with multi-word expressions.
Inhttp://arxiv.org/abs/0907.1013.D.
Blei, A. Ng, and M. Jordan.
2003.
Latent dirichletallocation.
Journal of Machine Learning Research.T.
Griffiths and M. Steyvers.
2004.
Finding scientifictopic.
In Proceedings of the National Academy of Sci-ence.T.
Griffiths, M. Steyvers, and J. Tenenbaum.
2007.
Top-ics in semantic representation.
Psychological Review.T.
Hofmann.
1999.
Probabilistic latent semantic index-ing.
In Proceedings of SIGIR.J.
Justenson and S. Katz.
1995.
Technical terminology:some linguistic properties and an algorithm for inden-tification in text.
Natural Language Engineering.D.
Magatti, S. Calegari, D. Ciucci, and F. Stella.
2009.Automatic labeling of topics.
In ISDA, pages 1227?1232.Christopher D. Manning and Hinrich Schtze.
1999.Foundations of Statistical Natural Language Process-ing.
Cambridge, Massachusetts.Q.
Mei, X. Shen, and C. Zhai.
2007.
Automatic la-beling of multinomial topic models.
In Proceedingsof the 13th ACM SIGKDD international conferenceon Knowledge discovery and data mining, pages 490?499.M.
Rosen-Zvi, T. Griffiths, M. Steyvers, and P. Smyth.2004.
the author-topic model for authors and docu-ments.
In Proceedings of UAI.M.
Steyvers and T. Griffiths.
2007.
Probabilistic topicmodels.
In Handbook of Latent Semantic Analysis.Lawrence Erlbaum Associates.M.
Steyvers, P. Smyth, and T. Griffiths.
2004.
Proba-bilistic author-topic models for information discovery.In Proceedings of KDD.H.
Wallach.
2006.
Topic modeling; beyond bagof words.
In International Conference on MachineLearning.X.
Wang and A. McCallum.
2005.
A note on topical n-grams.
Technical report, University of Massachusetts.X.
Wang, A. McCallum, and X. Wei.
2007.
Topical n-grams: Phrase and topic discoery with an applicationto information retrieval.
In Proceedings of ICDM.18
