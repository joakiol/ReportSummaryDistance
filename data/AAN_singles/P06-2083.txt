Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 643?650,Sydney, July 2006. c?2006 Association for Computational LinguisticsA Term Recognition Approach to Acronym RecognitionNaoaki Okazaki ?Graduate School of InformationScience and TechnologyThe University of Tokyo7-3-1 Hongo, Bunkyo-ku, Tokyo113-8656 Japanokazaki@mi.ci.i.u-tokyo.ac.jpSophia AnaniadouNational Centre for Text MiningSchool of InformaticsManchester UniversityPO Box 88, Sackville Street, ManchesterM60 1QD United KingdomSophia.Ananiadou@manchester.ac.ukAbstractWe present a term recognition approachto extract acronyms and their definitionsfrom a large text collection.
Parentheti-cal expressions appearing in a text collec-tion are identified as potential acronyms.Assuming terms appearing frequently inthe proximity of an acronym to bethe expanded forms (definitions) of theacronyms, we apply a term recognitionmethod to enumerate such candidates andto measure the likelihood scores of theexpanded forms.
Based on the list ofthe expanded forms and their likelihoodscores, the proposed algorithm determinesthe final acronym-definition pairs.
Theproposed method combined with a lettermatching algorithm achieved 78% preci-sion and 85% recall on an evaluation cor-pus with 4,212 acronym-definition pairs.1 IntroductionIn the biomedical literature the amount of terms(names of genes, proteins, chemical compounds,drugs, organisms, etc) is increasing at an astound-ing rate.
Existing terminological resources andscientific databases (such as Swiss-Prot1, SGD2,FlyBase3, and UniProt4) cannot keep up-to-datewith the growth of neologisms (Pustejovsky et al,2001).
Although curation teams maintain termino-logical resources, integrating neologisms is verydifficult if not based on systematic extraction and?Research Fellow of the Japan Society for the Promotionof Science (JSPS)1http://www.ebi.ac.uk/swissprot/2http://www.yeastgenome.org/3http://www.flybase.org/4http://www.ebi.ac.uk/GOA/collection of terminology from literature.
Termidentification in literature is one of the major bot-tlenecks in processing information in biology as itfaces many challenges (Ananiadou and Nenadic,2006; Friedman et al, 2001; Bodenreider, 2004).The major challenges are due to term variation,e.g.
spelling, morphological, syntactic, semanticvariations (one term having different termforms),term synonymy and homonymy, which are all cen-tral concerns of any term management system.Acronyms are among the most productive typeof term variation.
Acronyms (e.g.
RARA)are compressed forms of terms, and are usedas substitutes of the fully expanded termforms(e.g., retinoic acid receptor alpha).
Chang andSchu?tze (2006) reported that, in MEDLINE ab-stracts, 64,242 new acronyms were introduced in2004 with the estimated number being 800,000.Wren et al (2005) reported that 5,477 documentscould be retrieved by using the acronym JNKwhile only 3,773 documents could be retrieved byusing its full term, c-jun N-terminal kinase.In practice, there are no rules or exact patternsfor the creation of acronyms.
Moreover, acronymsare ambiguous, i.e., the same acronym may re-fer to different concepts (GR abbreviates both glu-cocorticoid receptor and glutathione reductase).Acronyms also have variant forms (e.g.
NF kappaB, NF kB, NF-KB, NF-kappaB, NFKB factor fornuclear factor-kappa B).
Ambiguity and variationpresent a challenge for any text mining system,since acronyms have not only to be recognised, buttheir variants have to be linked to the same canon-ical form and be disambiguated.Thus, discovering acronyms and relating themto their expanded forms is important for terminol-ogy management.
In this paper, we present a termrecognition approach to construct an acronym dic-643tionary from a large text collection.
The proposedmethod focuses on terms appearing frequently inthe proximity of an acronym and measures thelikelihood scores of such terms to be the expandedforms of the acronyms.
We also describe an algo-rithm to combine the proposed method with a con-ventional letter-based method for acronym recog-nition.2 Related WorkThe goal of acronym identification is to extractpairs of short forms (acronyms) and long forms(their expanded forms or definitions) occurring intext5.
Currently, most methods are based on let-ter matching of the acronym-definition pair, e.g.,hidden markov model (HMM), to identify short/-long form candidates.
Existing methods of short-/long form recognition are divided into patternmatching approaches, e.g., exploring an efficientset of heuristics/rules (Adar, 2004; Ao and Takagi,2005; Schwartz and Hearst, 2003; Wren and Gar-ner, 2002; Yu et al, 2002), and pattern mining ap-proaches, e.g., Longest Common Substring (LCS)formalization (Chang and Schu?tze, 2006; Taghvaand Gilbreth, 1999).Schwartz and Hearst (2003) implemented an al-gorithm for identifying acronyms by using paren-thetical expressions as a marker of a short form.A character matching technique was used, i.e.
allletters and digits in a short form had to appear inthe corresponding long form in the same order, todetermine its long form.
Even though the core al-gorithm was very simple, the authors report 99%precision and 84% recall on the Medstract goldstandard6.However, the letter-matching approach is af-fected by the expressions in the source text andsometimes finds incorrect long forms such asacquired syndrome and a patient with humanimmunodeficiency syndrome7 instead of the cor-rect one, acquired immune deficiency syndromefor the acronym AIDS.
This approach also en-counters difficulties finding a long form whoseshort form is arranged in a different word order,e.g., beta 2 adrenergic receptor (ADRB2).
To5This paper uses the terms ?short form?
and ?long form?hereafter.
?Long form?
is what others call ?definition?,?meaning?, ?expansion?, and ?expanded form?
of acronym.6http://www.medstract.org/7These examples are obtained from the actual MED-LINE abstracts submitted to Schwartz and Hearst?s algorithm(2003).
An author does not always write a proper definitionwith a parenthetic expression.improve the accuracy of long/short form recogni-tion, some methods measure the appropriatenessof these candidates based on a set of rules (Ao andTakagi, 2005), scoring functions (Adar, 2004), sta-tistical analysis (Hisamitsu and Niwa, 2001; Liuand Friedman, 2003) and machine learning ap-proaches (Chang and Schu?tze, 2006; Pakhomov,2002; Nadeau and Turney, 2005).Chang and Schu?tze (2006) present an algorithmfor matching short/long forms with a statisticallearning method.
They discover a list of abbrevia-tion candidates based on parentheses and enumer-ate possible short/long form candidates by a dy-namic programming algorithm.
The likelihood ofthe recognized candidates is estimated as the prob-ability calculated from a logistic regression withnine features such as the percentage of long-formletters aligned at the beginning of a word.
Theirmethod achieved 80% precision and 83% recall onthe Medstract corpus.Hisamitsu and Niwa (2001) propose a methodfor extracting useful parenthetical expressionsfrom Japanese newspaper articles.
Their methodmeasures the co-occurrence strength between theinner and outer phrases of a parenthetical expres-sion by using statistical measures such as mutualinformation, ?2 test with Yate?s correction, Dicecoefficient, log-likelihood ratio, etc.
Their methoddeals with generic parenthetical expressions (e.g.,abbreviation, non abbreviation paraphrase, supple-mentary comments), not focusing exclusively onacronym recognition.Liu and Friedman (2003) proposed a methodbased on mining collocations occurring before theparenthetical expressions.
Their method creates alist of potential long forms from collocations ap-pearing more than once in a text collection andeliminates unlikely candidates with three rules,e.g., ?remove a set of candidates Tw formed byadding a prefix word to a candidate w if the num-ber of such candidates Tw is greater than 3?.
Theirapproach cannot recognise expanded forms occur-ring only once in the corpus.
They reported a pre-cision of 96.3% and a recall of 88.5% for abbrevi-ations recognition on their test corpus.3 Methodology3.1 Term-based long-form identificationWe propose a method for identifying the longforms of an acronym based on a term extrac-tion technique.
We focus on terms appearing fre-644factor 1 (TTF-1)transcriptiontransciptiontransriptionthyroidthyroidtissue specific nkx2thyroidthyroidexpression ofco-expression ofregulation of thecontainingexpressedstained foridentification ofencodinggeneexaminedexploreincreasedstudiedits...... ........................................................................................................................ ......216 2182132091133111111111111factor5one1protein114 231 factor21nuclearthyroid...... 1* These candidates are spelling mistakes    found in the MEDLINE abstracts.Figure 1: Long-form candidates for TTF-1.quently in the proximity of an acronym in a textcollection.
More specifically, if a word sequenceco-occurs frequently with a specific acronym andnot with other surrounding words, we assume thatthere is a relationship8 between the acronym andthe word sequence.Figure 1 illustrates our hypothesis taking theacronym TTF-1 as an example.
The tree consistsof expressions collected from all sentences withthe acronym in parentheses and appearing beforethe acronym.
A node represents a word, and a pathfrom any node to TTF-1 represents a long-formcandidate9.
The figure above each node showsthe co-occurrence frequency of the correspondinglong-form candidate.
For example, long-form can-didates 1, factor 1, transcription factor 1, and thy-roid transcription factor 1 co-occur 218, 216, 213,and 209 times respectively with the acronym TTF-1 in the text collection.Even though long-form candidates 1, factor1 and transcription factor 1 co-occur frequentlywith the acronym TTF-1, we note that theyalso co-occur frequently with the word thyroid.Meanwhile, the candidate thyroid transcriptionfactor 1 is used in a number of contexts (e.g.,expression of thyroid transcription factor 1,expressed thyroid transcription factor 1, geneencoding thyroid transcription factor 1, etc.
).Therefore, we observe this to be the strongestrelationship between acronym TTF-1 and its8A sequence of words that co-occurs with an acronymdoes not always imply the acronym-definition relation.
Forexample, the acronym 5-HT co-occurs frequently with theterm serotonin, but their relation is interpreted as a synony-mous relation.9The words with function words (e.g., expression of, reg-ulation of the, etc.)
are combined into a node.
This is dueto the requirement for a long-form candidate discussed later(Section 3.3).A large collection of textContextual sentencesfor acronymsAcronym dictionaryShort-formminingLong-formminingLong-formvalidationRaw textSentences witha specific acronymAll sentences withany acronymsAcronyms andexpanded formsFigure 2: System diagram of acronym recognitionlong-form candidate thyroid transcription factor 1in the tree.
We apply a number of validation rules(described later) to the candidate pair to makesure that it has an acronym-definition relation.
Inthis example, the candidate pair is likely to bean acronym-definition relation because the longform thyroid transcription factor 1 contains allalphanumeric letters in the short form TTF-1.Figure 1 also shows another notable character-istic of long-form recognition.
Assuming that theterm thyroid transcription factor 1 has an acronymTTF-1, we can disregard candidates such as tran-scription factor 1, factor 1, and 1 since they lackthe necessary elements (e.g., thyroid for all can-didates; thyroid transcription for candidates fac-tor 1 and 1; etc.)
to produce the acronym TTF-1.
Similarly, we can disregard candidates suchas expression of thyroid transcription factor 1 andencoding thyroid transcription factor 1 since theycontain unnecessary elements (i.e., expression ofand encoding) attached to the long-form.
Hence,once thyroid transcription factor 1 is chosen asthe most likely long form of the acronym TTF-1, we prune the unlikely candidates: nested can-didates (e.g., transcription factor 1); expansions(e.g., expression of thyroid transcription factor 1);and insertions (e.g., thyroid specific transcriptionfactor 1).3.2 Extracting acronyms and their contextsBefore describing in detail the formalization oflong-form identification, we explain the wholeprocess of acronym recognition.
We divide theacronym extraction task into three steps (Figure2):1.
Short-form mining: identifying and extract-ing short forms (i.e., acronyms) in a collec-tion of documents2.
Long-form mining: generating a list ofranked long-form candidates for each short645Acronym Contextual sentence... .... .... .. .
.... ..HML Hard metal lung diseases (HML) are rare, and complexto diagnose.HMM Heavy meromyosin (HMM) from conditioned heartshad a higher Ca++-ATPase activity than from controls.HMM Heavy meromyosin (HMM) and myosin subfragment 1(S1) were prepared from myosin by using low concen-trations of alpha-chymotrypsin.HMM Hidden Markov model (HMM) techniques are used tomodel families of biological sequences.HMM Hexamethylmelamine (HMM) is a cytotoxic agentdemonstrated to have broad antitumor activity.HMN Hereditary metabolic neuropathies (HMN) are markedby inherited enzyme or other metabolic defects.... ... .. ..... .. ....... .
.......Table 1: An example of extracted acronyms andtheir contextual sentences.form by using a term extraction technique3.
Long-form validation: extracting short/longform pairs recognized as having an acronym-definition relation and eliminating unneces-sary candidates.The first step, short-form mining, enumerates allshort forms in a target text which are likely to beacronyms.
Most studies make use of the follow-ing pattern to find candidate acronyms (Wren andGarner, 2002; Schwartz and Hearst, 2003):long form ?(?
short form ?
)?Just as the heuristic rules described in Schwartzand Hearst (Schwartz and Hearst, 2003), we con-sider short forms to be valid only if they consist ofat most two words; their length is between two toten characters; they contain at least an alphabeticletter; and the first character is alphanumeric.
Allsentences containing a short form in parenthesisare inserted into a database, which returns all con-textual sentences for a short form to be processedin the next step.
Table 1 shows an example of thedatabase content.3.3 Formalizing long-form mining as a termextraction problemThe second step, long-form mining, generates alist of long-form candidates and their likelihoodscores for each short form.
As mentioned previ-ously, we focus on words or word sequences thatco-occur frequently with a specific acronym andnot with any other surrounding words.
We dealwith the problem of extracting long-form candi-dates from contextual sentences for an acronymin a similar manner as the term recognition taskwhich extracts terms from the given text.
For thatpurpose, we used a modified version of the C-value method (Frantzi and Ananiadou, 1999).C-value is a domain-independent method forautomatic term recognition (ATR) which com-bines linguistic and statistical information, empha-sis being placed on the statistical part.
The lin-guistic analysis enumerates all candidate terms ina given text by applying part-of-speech tagging,candidate extraction (e.g., extracting sequencesof adjectives/nouns based on part-of-speech tags),and a stop-list.
The statistical analysis assignsa termhood (likelihood to be a term) to a candi-date term by using the following features: the fre-quency of occurrence of the candidate term; thefrequency of the candidate term as part of otherlonger candidate terms; the number of these longercandidate terms; and the length of the candidateterm.The C-value approach is characterized by theextraction of nested terms which gives preferenceto terms appearing frequently in a given text butnot as a part of specific longer terms.
This is a de-sirable feature for acronym recognition to identifylong-form candidates in contextual sentences.
Therest of this subsection describes the method to ex-tract long-form candidates and to assign scores tothe candidates based on the C-value approach.Given a contextual sentence as shown in Ta-ble 1, we tokenize a contextual sentence bynon-alphanumeric characters (e.g., space, hyphen,colon, etc.)
and apply Porter?s stemming algo-rithm (Porter, 1980) to obtain a sequence of nor-malized words.
We use the following pattern toextract long-form candidates from the sequence:[:WORD:].
*$ (1)Therein: [:WORD:] matches a non-functionword; .
* matches an empty string or any word(s)of any length; and $ matches a short form of thetarget acronym.
The extraction pattern accepts aword or word sequence if the word or word se-quence begins with any non-function word, andends with any word just before the correspondingshort form in the contextual sentence.
We havedefined 113 function words such as a, the, of, we,and be in an external dictionary so that long-formcandidates cannot begin with these words.Let us take the example of a contextual sen-tence, ?we studied the expression of thyroid tran-scription factor-1 (TTF-1)?.
We extract the fol-lowing substrings as long form candidates (wordsare stemmed): 1; factor 1; transcript factor 1; thy-roid transcript factor 1; expression of thyroid tran-script factor 1; and studi the expression of thyroid646Candidate Length Freq Score Validadriamycin 1 727 721.4 oadrenomedullin 1 247 241.7 oabductor digiti minimi 3 78 74.9 odoxorubicin 1 56 54.6 Leffect of adriamycin 3 25 23.6 Eadrenodemedullated 1 19 17.7 oacellular dermal matrix 3 17 15.9 opeptide adrenomedullin 2 17 15.1 Eeffects of adrenomedullin 3 15 13.2 Eresistance to adriamycin 3 15 13.2 Eamyopathic dermatomyositis 2 14 12.8 ovincristine (vcr) and adriamycin 4 11 10.0 Edrug adriamycin 2 14 10.0 Ebrevis and abductor digiti minimi 5 11 9.8 Eminimi 1 83 5.8 Ndigiti minimi 2 80 3.9 Nright abductor digiti minimi 4 4 2.5 Eautomated digital microscopy 3 1 0.0 madrenomedullin concentration 2 1 0.0 NValid = { o: valid, m: letter match, L: lacks necessary letters, E: expansion,N: nested, B: below the threshold }Table 2: Long-form candidates for ADM.transcript factor 1.
Substrings such as of thyroidtranscript factor 1 (which begins with a functionword) and thyroid transcript (which ends prema-turely before the short form) are not selected aslong-form candidates.We define the likelihood LF(w) for candidate wto be the long form of an acronym:LF(w) = freq(w)??t?Twfreq(t)?
freq(t)freq(Tw) .
(2)Therein: w is a long-form candidate; freq(x) de-notes the frequency of occurrence of a candidatex in the contextual sentences (i.e., co-occurrencefrequency with a short form); Tw is a set of nestedcandidates, long-form candidates each of whichconsists of a preceding word followed by the can-didate w; and freq(Tw) represents the total fre-quency of such candidates Tw.The first term is equivalent to the co-occurrencefrequency of a long-form candidate with a shortform.
The second term discounts the co-occurrence frequency based on the frequency dis-tribution of nested candidates.
Given a long-formcandidate t ?
Tw, freq(t)freq(Tw) presents the occurrenceprobability of candidate t in the nested candidateset Tw.
Therefore, the second term of the formulacalculates the expectation of the frequency of oc-currence of a nested candidate accounting for thefrequency of candidate w.Table 2 shows a list of long-form candidates foracronym ADM extracted from 7,306,153 MED-LINE abstracts10.
The long-form mining step10 52GB XML files (from medline05n0001.xml tomedline05n0500.xml)extracted 10,216 unique long-form candidatesfrom 1,319 contextual sentences containing theacronym ADM in parentheses.
Table 2 arrangeslong-form candidates with their scores in de-sending order.
Long-form candidates adriamycinand adrenomedullin co-occur frequently with theacronym ADM.Note the huge difference in scores betweenthe candidates abductor digiti minimi and minimi.Even though the candidate minimi co-occurs morefrequently (83 times) than abductor digiti minimi(78 times), the co-occurrence frequency is mostlyderived from the longer candidate, i.e., digiti min-imi.
In this case, the second term of Formula2, the occurrence-frequency expectation of expan-sions for minimi (e.g., digiti minimi), will have ahigh value and will therefore lower the score ofcandidate minimi.
This is also true for the can-didate digiti minimi, i.e., the score of candidatedigiti minimi is lowered by the longer candidateabductor digiti minimi.
In contrast, the candidateabductor digiti minimi preserves its co-occurrencefrequency since the second term of the formula islow, which means that each expansion (e.g, brevisand abductor digiti minimi, right abductor digitiminimi, ...) is expected to have a low frequency ofoccurrence.3.4 Validation rules for long-form candidatesThe final step of Figure 2 validates the extractedlong-form candidates to generate a final set ofshort/long form pairs.
According to the scorein Table 2, adriamycin is the most likely long-form for acronym ADM.
Since the long-formcandidate adriamycin contains all letters in theacronym ADM, it is considered as an authenticlong-form (marked as ?o?
in the Valid field).
Thisis also true for the second and third candidate(adrenomedullin and abductor digiti minimi).The fourth candidate doxorubicin looks inter-esting, i.e., the proposed method assigns a highscore to the candidate even though it lacks the let-ters a and m, which are necessary to form the cor-responding short form.
This is because doxoru-bicin is a synonymous term for adriamycin and de-scribed directly with its acronym ADM.
In this pa-per, we deal with the acronym-definition relationalthough the proposed method would be applica-ble to mining other types of relations marked byparenthetical expressions.
Hence, we introduce aconstraint that a long form must cover all alphanu-647# [ V a r i a b l e s ]# s f : t h e t a r g e t s h o r t?form .# c a n d i d a t e s : long?form c a n d i d a t e s .# r e s u l t : t h e l i s t o f d e c i s i v e long?f o rms .# t h r e s h o l d : t h e t h r e s h o l d o f cu t?o f f .# S o r t long?form c a n d i d a t e s i n d e s c e n d i n g o r d e rc a n d i d a t e s .
s o r t ( # o f s c o r e s .key=lambda l f : l f .
s c o r e , r e v e r s e =True )# I n i t i a l i z e r e s u l t l i s t as empty .r e s u l t = [ ]# Pick up a lo ng form one by one from c a n d i d a t e s .f o r l f in c a n d i d a t e s :# Apply a cu t?o f f based on termhood s c o r e .# Al low c a n d i d a t e s w i t h l e t t e r match ing .
.
.
.
.
( a )i f l f .
s c o r e < t h r e s h o l d and not l f .
match :c o n t in u e# A long?form must c o n t a i n a l l l e t t e r s .
.
.
.
.
.
( b )i f l e t t e r r e c a l l ( s f , l f ) < 1 :c o n t in u e# Apply p r u n i n g o f r e d u n d a n t l ong form .
.
.
.
.
.
( c )i f r e d u n d a n t ( r e s u l t , l f ) :c o n t in u e# I n s e r t t h i s l ong form t o t h e r e s u l t l i s t .r e s u l t .
append ( l f )# Outpu t t h e d e c i s i v e long?f o rms .p r i n t r e s u l tFigure 3: Pseudo-code for long-form validation.meric letters in the short form.The fifth candidate effect of adriamycin is anexpansion of a long form adriamycin, which hasa higher score than effect of adriamycin.
As wediscussed previously, the candidate effect of adri-amycin is skipped since it contains unnecessaryword(s) to form an acronym.
Similarly, we prunethe candidate minimi because it forms a part of an-other long form abductor digiti minimi, which hasa higher score than the candidate minimi.
The like-lihood score LF (w) determines the most appro-priate long-form among similar candidates sharingthe same words or lacking some words.We do not include candidates with scores be-low a given threshold.
Therefore, the proposedmethod cannot extract candidates appearing rarelyin the text collection.
It depends on the applica-tion and considerations of the trade-off betweenprecision and recall, whether or not an acronymrecognition system should extract such rare longforms.
When integrating the proposed methodwith e.g., Schwartz and Hearst?s algorithm, wetreat candidates recognized by the external methodas if they pass the score cut-off.
In Table 2, forexample, candidate automated digital microscopyis inserted into the result set whereas candidateadrenomedullin concentration is skipped since itis nested by candidate adrenomedullin.Figure 3 is a pseudo-code for the long-form val-idation algorithm described above.
A long-formRank Parenthetic phrase # contextual # uniquesentence long-forms1 CT 30,982 1712 PCR 25,387 393 HIV 19,566 134 LPS 18,071 515 MRI 16,966 186 ELISA 16,527 257 SD 15,760 1658 BP 14,860 1459 DA 14,518 12910 CSF 14,035 3411 CNS 13,573 4712 IL 13,423 6013 PKC 13,414 1114 TNF-ALPHA 12,228 1415 HPLC 12,211 1616 ER 12,155 14017 RT-PCR 12,153 2118 TNF 12,145 1319 LDL 11,960 2420 5-HT 11,836 20.. .... ... ..?
(overall 50 acronyms) 600,375 4,212Table 3: Statistics on our evaluation corpus.candidate is considered valid if the following con-ditions are met: (a) it has a score greater thana threshold or is nominated by a letter-matchingalgorithm; (b) it contains all letters in the corre-sponding short form; and (c) it is not nested, ex-pansion, or insertion of the previously chosen longforms.4 EvaluationSeveral evaluation corpora for acronym recogni-tion are available.
The Medstract Gold StandardEvaluation Corpus, which consists of 166 aliaspairs annotated to 201 MEDLINE abstracts, iswidely used for evaluation (Chang and Schu?tze,2006; Schwartz and Hearst, 2003).
However, theamount of the text in the corpus is insufficient forthe proposed method, which makes use of statisti-cal features in a text collection.
Therefore, we pre-pared an evaluation corpus with a large text collec-tion and examined how the proposed algorithm ex-tracts short/long forms precisely and comprehen-sively.We applied the short-form mining describedin Section 3 to 7,306,153 MEDLINE abstracts10.Out of 921,349 unique short-forms recognized bythe short-form mining, top 50 acronyms11 appear-ing frequently in the abstracts were chosen for our11We have excluded several parenthetical expressions suchas II (99,378 occurrences), OH (37,452 occurrences), andP<0.05 (23,678 occurrences).
Even though they are enclosedwithin parentheses, they do not introduce acronyms.
We havealso excluded a few acronyms such as RA (18,655 occur-rences) and AD (15,540 occurrences) because they have manyvariations of their expanded forms to prepare the evaluationcorpus manually.648evaluation corpus.
We asked an expert in bio-informatics to extract long forms from 600,375contextual sentences with the following criteria:a long form with minimum necessary elements(words) to produce its acronym is accepted; a longform with unnecessary elements, e.g., magneticresonance imaging unit (MRI) or computed x-raytomography (CT), is not accepted; a misspelledlong-form, e.g., hidden markvov model (HMM),is accepted (to separate the acronym-recognitiontask from a spelling-correction task).
Table 3shows the top 20 acronyms in our evaluation cor-pus, the number of their contextual sentences, andthe number of unique long-forms extracted.Using this evaluation corpus as a gold standard,we examined precision, recall, and f-measure12 oflong forms recognized by the proposed algorithmand baseline systems.
We compared five sys-tems: the proposed algorithm with Schwartz andHearst?s algorithm integrated (PM+SH); the pro-posed algorithm without any letter-matching algo-rithm integrated (PM); the proposed algorithm butusing the original C-value measure for long-formlikelihood scores (CV+SH); the proposed algo-rithm but using co-occurrence frequency for long-form likelihood scores (FQ+SH); and Schwartzand Hearst?s algorithm (SH).
The threshold for theproposed algorithm was set to four.Table 4 shows the evaluation result.
The best-performing configuration of algorithms (PM+SH)achieved 78% precision and 85% recall.
TheSchwartz and Hearst?s (SH) algorithm obtained agood recall (93%) but misrecognized a numberof long-forms (56% precision), e.g., the kineticsof serum tumour necrosis alpha (TNF-ALPHA)and infected mice lacking the gamma interferon(IFN-GAMMA).
The SH algorithm cannot gathervariations of long forms for an acronym, e.g.,ACE as angiotensin-converting enzyme level, an-giotensin i-converting enzyme gene, angiotensin-1-converting enzyme, angiotensin-converting, an-giotensin converting activity, etc.
The proposedmethod combined with the Schwartz and Hearst?salgorithm remedied these misrecognitions basedon the likelihood scores and the long-form vali-dation algorithm.
The PM+SH also outperformedother likelihood measures, CV+SH and FQ+SH.12We count the number of unique long forms, i.e., countonce even if short/long form pair ?HMM, hidden markovmodel?
occurs more than once in the text collection.
ThePorter?s stemming algorithm was applied to long forms be-fore comparing them with the gold standard.Method Precision Recall F-measurePM+SH 0.783 0.849 0.809CV+SH 0.722 0.838 0.765FQ+SH 0.716 0.800 0.747SH 0.555 0.933 0.681PM 0.815 0.140 0.216Table 4: Evaluation result of long-form recogni-tion.The proposed algorithm without Schwartz andHearst?s algorithm (PM) identified long forms themost precisely (81% precision) but misses a num-ber of long forms in the text collection (14% re-call).
The result suggested that the proposed likeli-hood measure performed well to extract frequentlyused long-forms in a large text collection, butcould not extract rare acronym-definition pairs.We also found the case where PM missed a set oflong forms for acronym ER which end with rate,e.g., eating rate, elimination rate, embolic rate,etc.
This was because the word rate was used witha variety of expansions (i.e., the likelihood scorefor rate was not reduced much) while it can bealso interpreted as the long form of the acronym.Even though the Medstract corpus is insuffi-cient for evaluating the proposed method, we ex-amined the number of long/short pairs extractedfrom 7,306,153 MEDLINE abstracts and also ap-pearing in the Medstract corpus.
We can neithercalculate the precision from this experiment norcompare the recall directly with other acronymrecognition methods since the size of the sourcetexts is different.
Out of 166 pairs in Medstractcorpus, 123 (74%) pairs were exactly covered bythe proposed method, and 15 (83% in total) pairswere partially covered13.
The algorithm missed 28pairs because: 17 (10%) pairs in the corpus werenot acronyms but more generic aliases, e.g., alphatocopherol (Vitamin E); 4 (2%) pairs in the cor-pus were incorrectly annotated (e.g, long form inthe corpus embryo fibroblasts lacks word mouse toform acronym MEFS); and 7 (4%) long forms aremissed by the algorithm, e.g., the algorithm recog-nized pair protein kinase (PKR) while the correctpair in the corpus is RNA-activated protein kinase(PKR).13Medstract corpus leaves unnecessary elements attachedto some long-forms such as general transcription factor iib(TFIIB), whereas the proposed algorithm may drop the un-necessary elements (i.e.
general) based on the frequency.
Weregard such cases as partly correct.6495 ConclusionIn this paper we described a term recognition ap-proach to extract acronyms and their definitionsfrom a large text collection.
The main contributionof this study has been to show the usefulness ofstatistical information for recognizing acronyms inlarge text collections.
The proposed method com-bined with a letter matching algorithm achieved78% precision and 85% recall on the evaluationcorpus with 4,212 acronym-definition pairs.A future direction of this study would be toincorporate other types of relations expressedwith parenthesis such as synonym, paraphrase,etc.
Although this study dealt with the acronym-definition relation only, modelling these relationswill also contribute to the accuracy of the acronymrecognition, establishing a methodology to distin-guish the acronym-definition relation from othertypes of relations.ReferencesEytan Adar.
2004.
SaRAD: A simple and robust ab-breviation dictionary.
Bioinformatics, 20(4):527?533.Sophia Ananiadou and Goran Nenadic.
2006.
Auto-matic terminology management in biomedicine.
InSophia Ananiadou and John McNaught, editors, TextMining for Biology and Biomedicine, pages 67?97.Artech House, Inc.Hiroko Ao and Toshihisa Takagi.
2005.
ALICE: Analgorithm to extract abbreviations from MEDLINE.Journal of the American Medical Informatics Asso-ciation, 12(5):576?586.Olivier Bodenreider.
2004.
The Unified Medical Lan-guage System (UMLS): Integrating biomedical ter-minology.
Nucleic Acids Research, 32:267?270.Jeffrey T. Chang and Hinrich Schu?tze.
2006.
Abbre-viations in biomedical text.
In S. Ananiadou andJ.
McNaught, editors, Text Mining for Biology andBiomedicine, pages 99?119.
Artech House, Inc.Katerina T. Frantzi and Sophia Ananiadou.
1999.
TheC-value / NC-value domain independent method formulti-word term extraction.
Journal of Natural Lan-guage Processing, 6(3):145?179.Carol Friedman, Hongfang Liu, Lyuda Shagina,Stephen Johnson, and George Hripcsak.
2001.Evaluating the UMLS as a source of lexical knowl-edge for medical language processing.
In AMIASymposium, pages 189?193.Toru Hisamitsu and Yoshiki Niwa.
2001.
Extract-ing useful terms from parenthetical expression bycombining simple rules and statistical measures: Acomparative evaluation of bigram statistics.
In Di-dier Bourigault, Christian Jacquemin, and Marie-C L?Homme, editors, Recent Advances in Compu-tational Terminology, pages 209?224.
John Ben-jamins.Hongfang Liu and Carol Friedman.
2003.
Miningterminological knowledge in large biomedical cor-pora.
In 8th Pacific Symposium on Biocomputing(PSB 2003), pages 415?426.David Nadeau and Peter D. Turney.
2005.
A su-pervised learning approach to acronym identifica-tion.
In 8th Canadian Conference on Artificial In-telligence (AI?2005) (LNAI 3501), page 10 pages.Serguei Pakhomov.
2002.
Semi-supervised maximumentropy based approach to acronym and abbrevia-tion normalization in medical texts.
In 40th AnnualMeeting of the Association for Computational Lin-guistics (ACL), pages 160?167.Youngja Park and Roy J. Byrd.
2001.
Hybrid text min-ing for finding abbreviations and their definitions.
In2001 Conference on Empirical Methods in NaturalLanguage Processing (EMNLP), pages 126?133.Martin F. Porter.
1980.
An algorithm for suffix strip-ping.
Program, 14(3):130?137.James Pustejovsky, Jose?
Castan?o, Brent Cochran, Ma-ciej Kotecki, and Michael Morrell.
2001.
Au-tomatic extraction of acronym meaning pairs fromMEDLINE databases.
MEDINFO 2001, pages 371?375.Ariel S. Schwartz and Marti A. Hearst.
2003.
A simplealgorithm for identifying abbreviation definitions inbiomedical text.
In Pacific Symposium on Biocom-puting (PSB 2003), number 8, pages 451?462.Kazem Taghva and Jeff Gilbreth.
1999.
Recogniz-ing acronyms and their definitions.
InternationalJournal on Document Analysis and Recognition (IJ-DAR), 1(4):191?198.Jonathan D. Wren and Harold R. Garner.
2002.Heuristics for identification of acronym-definitionpatterns within text: towards an automated con-struction of comprehensive acronym-definition dic-tionaries.
Methods of Information in Medicine,41(5):426?434.Jonathan D. Wren, Jeffrey T. Chang, James Puste-jovsky, Eytan Adar, Harold R. Garner, and Russ B.Altman.
2005.
Biomedical term mappingdatabases.
Database Issue, 33:D289?D293.Hong Yu, George Hripcsak, and Carol Friedman.
2002.Mapping abbreviations to full forms in biomedicalarticles.
Journal of the American Medical Informat-ics Association, 9(3):262?272.650
