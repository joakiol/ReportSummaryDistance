PRIORITY  UNION AND GENERAL IZAT IONIN D ISCOURSE GRAMMARSClaire Grover ,  Chr i s  Brew,  Suresh  Manandhar, Marc MoensHCRC Language Techno logy  GroupThe Univers i ty of  Edinburgh2 Bucc leuch  P laceEd inburgh  EH8 9LW, UKIn ternet :  C. Grover?ed.
ac .
ukAbst ractWe describe an implementation in Carpenter's ty-ped feature formalism, ALE, of a discourse gram-mar of the kind proposed by Scha, Polanyi,et al We examine their method for resolvingparallelism-dependent anaphora and show thatthere is a coherent feature-structural rendition ofthis type of grammar which uses the operationsof prwrity union and generalization.
We describean augmentation of the ALE system to encompassthese operations and we show that an appropriatechoice of definition for priority union gives the de-sired multiple output for examples of vP-ellipsiswhich exhibit a strict/sloppy ambiguity.1 D iscourse  GrammarWorking broadly within the sign-based paradigmexemplified by HPSG (Pollard and Sag in press)we have been exploring computational issues fora discourse level grammar by using the ALE sy-stem (Carpenter 1993) to implement a discoursegrammar.
Our central model of a discourse gram-mar is the Linguistic Discourse Model (LDM) mostoften associated with Scha, Polanyi, and their co-workers (Polanyi and Scha 1984, Scha and Polanyi1988, Priist 1992, and most recently in Priist, Schaand van den Berg 1994).
In LDM rules are defi-ned which are, in a broad sense, unification gram-mar rules and which combine discourse constitu-ent units (DCUS).
These are simple clauses whosesyntax and underresolved semantics have been de-termined by a sentence grammar but whose fullyresolved final form can only be calculated by theirintegration into the current discourse and its con-text.
The rules of the discourse grammar act toestablish the rhetorical relations between constitu-ents and to perform resolution of those anaphorswhose interpretation can be seen as a function ofdiscourse coherence (as opposed to those whoseinterpretation relies on general knowledge).For illustrative purposes, we focus here on Prfist'srules for building one particular type of rhetoricalrelation, labelled "list" (Priist 1992).
His centralthesis is that for DCUs to be combined into a listthey must exhibit a degree of syntactic-semanticparallelism and that this parallelism will stronglydetermine the way in which some kinds of anaphorare resolved.
The clearest example of this is vP-ellipsis as in (la) but Priist also claims that thesubject and object pronouns in (lb) and (lc) areparallelism-dependent a aphors when they occurin list structures and must therefore be resolved tothe corresponding fully referential subject/objectin the first member of the list.
(1) a. Hannah likes beetles.
So does Thomas.b.
Hannah likes beetles.
She also likescaterpillars.c.
Hannah likes beetles.
Thomas hatesthem.
(2) is Priist's list construction rule.
It is intendedto capture the idea that a list can be constructedout of two DCUs, combined by means of connec-tives such as and and or.
The categories in Priist'srules have features associated with them.
In (2)these features are sere (the unresolved semanticinterpretation of the category), consem (the con-textually resolved semantic interpretation), andschema (the semantic information that is com-mon between the daughter categories).
(2) list \ [sere:  el  T~ ((Cl ?
'$2) RS2),schema : C1 ?
$2\] ----4DCUI \[ sem : Sl ,consem : C1\] +DCU2 \[sere : ~S2,consem : ((Cl ~'$2) ~$2)\]Conditions:C1  $2 is a characteristic generalization f C1and S~; R E {and, or .... }.Priist calls the operation used to calculate the va-lue for schema the most specific common deno-minator (MSCD, indicated by the symbol ?).
TheMSCD of C1 and $2 is defined as the most specificgeneralization of C1 that can unify with 5'2.
It isessential that the result should be contentful to adegree that confirms that the list structure is anappropriate analysis, and to this end Pr/ist impo-ses the condition that the value of schema should17be a characteristic generalization of the informa-tion contributed by the two daughters.
There isno formal definition of this notion; it would re-quire knowledge from many sources to determinewhether sufficient informativeness had been achie-ved.
However, assuming that this condition is met,Priist uses the common information as a source forresolution of underspecified elements in the seconddaughter by encoding as the value of the seconddaughter's consem the unification of the result ofMSCD with its pre-resolved semantics (the formula((Ca / $2) Iq $2)).
So in Priist's rule the MSCDoperation plays two distinct roles, first as a test forparallelism (as the value of the mother's chema)and second as a basis for resolution (in the com-posite operation which is the value of the seconddaughter's consem) .
There are certain problemswith MSCD which we claim stem from this attemptto use one operation for two purposes, and our pri-mary concern is to find alternative means of achie-ving Prfist's intended analysis.2 An  ALE  Discourse GrammarFor our initial exploration into using ALE for dis-course grammars we have developed a small dis-course grammar whose lexical items are completesentences (to circumvent he need for a sentencegrammar) and which represents the semantic on-tent of sentences using feature structures of typeevent whose sub-types are indicated in the follo-wing part of the type hierarchy:event (3)agentiveplus_patient prop-artemot-att action believe assumelike hate kick catchIn addition we have a very simplified semantics ofnoun phrases where we encode them as of typeentity with the subtypes indicated below:(4) entityanimatehuman animalfemale male insect..4"-.,hannah jessy thomas am brother beetle bee cater- pillarSpecifications of which features are appropriate forwhich type give us the following representations ofthe semantic ontent of the discourse units in (1):(5) a. Hannah likes beetles\[ AGENT hannah \]PATIENT beetlelikeb.
So does Thomas\[ AGENT thomas \]agentivec.
She also likes caterpillars\[ AGENT female \]PATIENT caterpillarliked.
Thomas hates them\[ AGENT thomas \]PATIENT entityhate2.1 Ca lcu la t ing  Common GroundThe SCHEMA feature encodes the information thatis common between daughter Dcus and Prtist usesMSCD to calculate this information.
A feature-structural definition of MSCD would return as aresult the most specific feature structure which isat least as general as its first argument but whichis also unifiable with its second argument.
Forthe example in (lc), the MSCD operation would begiven the two arguments in (5a) and (5d), and (6)would be the result.
(6) \[ AGENT human \]PATIENT beetleemot_at tWe can contrast the MSCD operation with anoperation which is more commonly discussed inthe context of feature-based unification systems,namely generalization.
This takes two feature-structures as input and returns a feature struc-ture which represents the common information inthem.
Unlike MSCD, generalization is not asym-metric, i.e.
the order in which the arguments arepresented oes not affect the result.
The genera-lization of (5a) and (5d) is shown in (7).
(7) \[ AGENT human \]PATIENT entityemot_at tIt can be seen from this example that the MSCDresult contains more information than the genera-lization result.
Informally we can say that it seemsto reflect the common information between thetwo inputs after the parallelism-dependent a a-phor in the second sentence has been resolved.
Thereason it is safe to use MSCD in this context is pre-cisely because its use in a list structure guarantees18that the pronoun in the second sentence will beresolved to beetle.
In fact the result of MSCD inthis case is exactly the result we would get if wewere to perform the generalization of the resolvedsentences and, as a representation of what the twohave in common, it does seem that this is more de-sirable than the generalization of the pre-resolvedforms.If we turn to other examples, however, we discoverthat MSCD does not always give the best results.The discourse in (8) must receive a constituentstructure where the second and third clauses arecombined to form a contrast pair and then thiscontrast pair combines with the first sentence toform a list.
(Prfist has a separate rule to buildcontrast pairs but the use of MSCD is the same asin the list rule.
)(8) Hannah likes ants.
Thomas likes bees butJessy hates them.
(9) fAGENT hanna~\[._PATIENT insect_.JlikeAGENT hannah~ \[AGENT human~PATIENT ant _\] PATIENT bee _Jlike e ~ATIENT bee \[ \[-PATIENT entity Ilike hateThe tree in (9) demonstrates the required struc-ture and also shows on the mother and interme-diate nodes what the results of MSCD would be.
Aswe can see, where elements of the first argumentof  MSCD are more specific than the correspondingelements in the second, then the more specific oneoccurs in the result.
Here, this has the effect thatthe structure \[like, AGENT hannah, PATIENT ins-ect \] is somehow claimed to be common groundbetween all three constituents even though this isclearly not the case.Our solution to this problem is to dispense withthe MSCD operation and to use generalization i -stead.
However, we do propose that generalizationshould take inputs whose parallelism dependentanaphors have already been resolved.
1 In the caseof the combination of (5a) and (5d), this will give1As described in the next section, we use priorityunion to resolve these anaphors in both lists and con-trasts.
The use of generalization as a step towardschecking that there is sufficient common ground is sub-sequent o the use of priority ration as the resolutionmechanism.exactly the same result as MSCD gave (i.e.
(6)),but for the example in (8) we will get different re-sults, as the tree in (10) shows.
(Notice that therepresentation of the third sentence is one wherethe anaphor is resolved.)
The resulting generaliza-tion, \[emot_att, AGENT human, PATIENT insect\], isa much more plausible representation of the com-mon information between the three DCUs than theresults of MSCD.
(10) fAGENT huma~\[_PATIENT insect~ATIENT ant ..J \[_PATIENT bee _Jlike e ~LPATIENT bee _\] \[_PATIENT bee ._\]like hate2.2 Resolution of Parallel AnaphorsWe have said that MSCD plays two roles in Pr/ist'srules and we have shown how its function in cal-culating the value of SCHEMA can be better servedby using the generalization operation instead.
Weturn now to the composite operation indicated in(2) by the formula ((C, /S~)NS2).
This com-posite operation calculates MSCD and then unifiesit back in with the second of its arguments in or-der to resolve any parallelism-dependent a aphorsthat might occur in the second DCU.
In the discus-sion that follows, we will refer to the first DcU inthe list rule as the source and to the second DCUas the target (because it contains a parallelism-dependent anaphor which is the target of our at-tempt to resolve that anaphor).In our ALE implementation we replace Pr/ist'scomposite operation by an operation which has oc-casionally been proposed as an addition to feature-based unification systems and which is usually re-ferred to either as default unification or as priorityunion.
2 Assumptions about the exact definition ofthis operation vary but an intuitive description ofit is that it is an operation which takes two featurestructures and produces a result which is a mergeof the information in the two inputs.
However,the information in one of the feature structures is"strict" and cannot be lost or overridden while theinformation in the other is defensible.
The opera-tion is a kind of union where the information inthe strict structure takes priority over that in the~See, for example, Bouma (1990), Calder (1990),Carpenter (1994), Kaplan (1987).19default structure, hence our preference to refer toit by the name priority union.
Below we demon-strate the results of priority union for the exam-ples in ( la) - ( lc ) .
Note that the target is the strictstructure and the source is the defeasible one.
(11) Hannah likes beetles.
So does Thomas.Source: 5aTarget: 5bPriority\[ AGENT th?mas \]Union: PATIENT beetle like(12) Hannah likes beetles.
She also likes caterpillars.Source: 5aTarget: 5c\[ AGENT hannah 1Priority PATIENT caterpillarUnion: like(13) Hannah likes beetles.
Thomas hates them.Source: 5aTarget: 5dAGENT thomas \]Priority PATIENT beetleUnion:hateFor these examples priority union gives us exactlythe same results as Priist's composite operation.We use a definition of priority union provided byCarpenter (1994) (although note that his name forthe operation is "credulous default unification").It is discussed in more detail in Section 3.
The pri-ority union of a target T and a source S is definedas a two step process: first calculate a maximalfeature structure S' such that S' E S, and thenunify the new feature structure with T.This is very similar to PriJst's composite opera-tion but there is a significant difference, however.For Priist there is a requirement that there shouldalways be a unique MSCD since he also uses MSCDto calculate the common ground as a test for par-allelism and there must only be one result for thatpurpose.
By contrast, we have taken Carpenter'sdefinition of credulous default unification and thiscan return more than one result.
We have strongreasons for choosing this definition even thoughCarpenter does define a "skeptical default unifi-cation" operation which returns only one result.Our reasons for preferring the credulous versionarise from examples of vP-ellipsis which exhibit anambiguity whereby both a "strict" and a "sloppy"reading are possible.
For example, the second sen-tence in (14) has two possible readings which canbe glossed as "Hannah likes Jessy's brother" (thestrict reading) and "Hannah likes her own bro-ther" (the sloppy reading).
(14) Jessy likes her brother.
So does Hannah.The situations where the credulous version of theoperation will return more than one result arisefrom structure sharing in the defeasible featurestructure and it turns out that these are exactlythe places where we would need to get more thanone result in order to get the strict/sloppy ambi-guities.
We illustrate below:(15) Jessy likes her brother.
So does Hannah.Source: AGENTPATIENTlike~\]jessy \] \[\] \]brotherTarget: \[ AGENT hannah \]agentivePriorityUnion: " AGENTPATIENTlike\[\] hannah 1 \[ nl\]brotherAGENTPATIENTlikehannah \] \[brotherHere priority union returns two results, one wherethe structure-sharing information in the source hasbeen preserved and one where it has not.
As theexample demonstrates, this gives the two readingsrequired.
By contrast, Carpenter's keptical de-fault unification operation and Priist's compositeoperation return only one result.2.3 Higher Order Unif icat ionThere are similarities between our implementa-tion of Prfist's grammar and the account of vP-ellipsis described by Dalrymple, Shieber and Pe-reira (1991) (henceforth DSP).
DSP gives anequational characterization of the problem of vp-ellipsis where the interpretation of the targetphrase follows from an initial step of solving anequation with respect to the source phrase.
If afunction can be found such that applying that fun-ction to the source subject results in the source in-terpretation, then an application of that functionto the target subject will yield the resolved inter-pretation for the target.
The method for solvingsuch equations is "higher order unification".
(16)shows all the components of the interpretation ofthe example in (11).20(16) Hannah likes beetles.
So does Thomas.Source:Target (T):Equation:Solution:Apply to T:like(hannah, beetle)P ( thomas )P ( hannah ) = like(hannah, beetle)P = ~x.like(x, beetle)like(thomas, beetle)A prerequisite to the DSP procedure is the esta-blishment of parallelism between source and targetand the identification of parallel subparts.
For ex-ample, for (16) it is necessary both that the twoclauses Hannah likes beetles and So does Thomasshould be parallel and that the element hannahshould be identified as a parallel element.
DSPindicate parallel elements in the source by meansof underlines as shown in (16).
An underlined ele-ment in the source is termed a 'primary occur-rence' and DSP place a constraint on solutions toequations requiring that primary occurrences beabstracted.
Without the identification of hannahas a primary occurrence in (16), other equationsderiving from the source might be possible, for ex-ample (17) :(17) a. P(beetle) = like(hannah, beetle)b. P(like) = like(hannah, beetle)The DSP analysis of our strict/sloppy example in(14) is shown in (18).
The ambiguity follows fromthe fact that there are two possible solutions to theequation on the source: the first solution involvesabstraction of just the primary occurrence ofjessy,while the second solution involves abstraction ofboth the primary and the secondary occurrences.When applied to the target these solutions yieldthe two different interpretations:(18) JessySource:Target:Equation:Sol.1 ($1):Sol.2 (S2):Apply SI:Apply $2:likes her brother.
So does Hannah.like(jessy, brother-of (jessy)P( hannah )P(jessy) = like(jessy, brother-of (jessy)P = ~x.like(x, brother-of(jessy))e = Ax.like(x, brother-of(x))like(hannah, brother-of (jessy)like(hannah, brother-of(hannah))DSP claim that a significant attribute of their ac-count is that they can provide the two readings instrict/sloppy ambiguities without having to postu-late ambiguity in the source.
They claim this asa virtue which is matched by few other accountsof vP-ellipsis.
We have shown here, however, thatan account which uses priority union also has noneed to treat the source as ambiguous.Our results and DSP's also converge where thetreatment of cascaded ellipsis is concerned.
Forthe example in (19) both accounts find six rea-dings although two of these are either extremelyimplausible or even impossible.
(19) John revised his paper before the teacherdid, and Bill did too.DSP consider ways of reducing the number ofreadings and, similarly, we are currently explo-ring a potential solution whereby some of the re-entrancies in the source are required to be trans-mitted to the result of priority union.There are also similarities between our accountand the DSP account with respect to the esta-blishment of parallelism.
In the DSP analysis thedetermination of parallelism is separate from anda prerequisite to the resolution of ellipsis.
Howe-ver, they do not actually formulate how paralle-lism is to be determined.
In our modification ofPrfist's account we have taken the same step asDSP in that we separate out the part of the fea-ture structure used to determine parallelism fromthe part used to resolve ellipsis.
In the generalspirit of Priist's analysis, however, we have takenone step further down the line towards determi-ning parallelism by postulating that calculatingthe generalization of the source and target is afirst step towards showing that parallelism exists.The further condition that Prfist imposes, that thecommon ground should be a characteristic genera-lization, would conclude the establishment of par-allelism.
We are currently not able to define thenotion of characteristic generalization, so like DSPwe do not have enough in our theory to fully imple-ment the parallelism requirement.
In contrast othe DSP account, however, our feature structuralapproach does not involve us having to explicitlypair up the component parts of source and target,nor does it require us to distinguish primary fromsecondary occurrences.2.4 Paral le l ismIn the DSP approach to vP-ellipsis and in our ap-proach too, the emphasis has been on semanticparallelism.
It has often been pointed out, howe-ver, that there can be an additional requirement ofsyntactic parallelism (see for example, Kehler 1993and Asher 1993).
Kehler (1993) provides a use-ful discussion of the issue and argues convincinglythat whether syntactic parallelism is required de-pends on the coherence relation involved.
As theexamples in (20) and (21) demonstrate, semanticparallelism is sufficient o establish a relation likecontrast but it is not sufficient for building a co-herent list.
(20) The problem was looked into by John, butno-one else did.
(21) *This problem was looked into by John,and Bill did too.For a list to be well-formed both syntactic andsemantic parallelism are required:21(22) John looked into this problem, and Bill didtoo.In the light of Kehler's claims, it would seem thata more far-reaching implementation of our prio-rity union account would need to specify how theconstraint of syntactic parallelism ight be imple-mented for those constructions which require it.An nPSG-style sign, containing as it does all typesof linguistic information within the same featurestructure, would lend itself well to an account ofsyntactic parallelism.
If  we consider that the DTRSfeature in the sign for the source clause containsthe entire parse tree including the node for thevP which is the syntactic antecedent, then waysto bring together the source vP and the target be-gin to suggest hemselves.
We have at our disposalboth unification to achieve re-entrancy and the op-tion to use priority union over syntactic subpartsof the sign.
In the light of this, we are confidentthat it would be possible to articulate a more ela-borate account of vp-ellipis within our frameworkand that priority union would remain the opera-tion of choice to achieve the resolution.3 Extens ions  to  ALEIn the previous sections we showed that Prfist'sMSCD operation would more appropriately be re-placed by the related operations of generalizationand priority union.
We have added generalizationand priority union to the ALE system and in thissection we discuss our implementation.
We haveprovided the new operations as a complement tothe definite clause component of ALE.
We chosethis route because we wanted to give the gram-mar writer explicit control of the point at whichthe operations were invoked.
ALE adopts a sim-ple eROLOG-like execution strategy rather thanthe more sophisticated control schemes of systemslike CUF and TFS (Manandhar 1993).
In princi-ple it might be preferable to allow the very gene-ral deduction strategies which these other systemssupport, since they have the potential to support amore declarative style of grammar-writing.
Unfor-tunately, priority union is a non-monotonic ope-ration, and the consequences of embedding suchoperations in a system providing for flexible exe-cution strategies are largely unexplored.
At leastat the outset it seems preferable to work within aframework in which the grammar writer is requi-red to take some of the responsibility for the orderin which operations are carried out.
Ultimately wewould hope that much of this load could be takenby the system, but as a tool for exploration ALEcertainly suffices.3.1 Priority Union in ALEWe use the following definition of priority union,based on Carpenter's definition of credulous de-fault unification:(23) punion(T,S) = {unify(T,S') IS' K Sis maximal such that unify(T,S') is defined}punion(T,S) computes the priority union o f t  (tar-get; the strict feature structure) with S (source;the defeasible feature structure).
This definitionrelies on Moshier's (1988) definition of atomic fea-ture structures, and on the technical result thatany feature structure can be decomposed into aunification of a unique set of atomic feature struc-tures.
Our implementation is a simple procedura-lization of Carpenter's declarative definition.
Firstwe decompose the default feature structure into aset of atomic feature structures, then we search forthe maximal subsets required by the definition.We illustrate our implementation f priority unionin ALE with the example in (15): Source is the de-fault input, and Target is the strict input.
Thehierarchy we assume is the same as shown in (3)and (4).
Information about how features are asso-ciated with types is as follows:?
The type agentive introduces the feature AGENTwith range type human.?
The type plus-patient introduces the feature PA-T IENT with range type human.?
The type brother introduces the featureBROTHER-OF with range type human.?
The types jessy and hannah introduce no fea-tures.In order to show the decomposition into ato-mic feature structures we need a notation to re-present paths and types.
We show paths likethis: PATIENTIBROTHER-OF and in order to sti-pulate that the PATIENT feature leads to a struc-ture of type brother, we include type informa-tion in this way: (PATIENW/brother)\[(BROTHER-of~human).
We introduce a special feature (*)to allow specification of the top level type of thestructure.
The structures in (15) decompose intothe following atomic components.
(24) Default input:( AGENT / jessy) ( D 1 )(PATIENT/brother)I(BROTHER-OF/jessy) (D2)AGENT ---~ PATIENTIBROTHER-OF (D3)(*/like) (D4)Strict input:(AGENT~hannah) (S 1 )( * / agentive) ($2)Given the type hierarchy the expressions above ex-pand to the following typed feature structures:22(25)Default input:\[ AGENT jessy \]agentiveAGENTPATIENTplus-patientAGENTPATIENTplus-patientAGENT human \]PATIENT entitylikehuman 1brotherhuman \] \]brother(D1)(D2)(D3)(D4)Strict input:\[ AGENT hannah \]agentive (s1,s2)We can now carry out the following steps in orderto generate the priority union.1.
Add (94) to the strict input.
It cannot conflict.2.
Note that it is impossible to add (D1) to thestrict input.3.
Non-deterministically add either (92) or (93)to the strict input.4.
Note that the results are maximal in each casebecause it is impossible to add both (D2) and(D3) without causing a clash between the dis-joint atomic types hannah and jessy.5.
Assemble the results into feature structures.
Ifwe have added (D3) the result will be (26) andif we have added (D2) the result will be (27).
(26) Result 1:" AGENT \[\] hannah \]PATIENT \[BROTHER-OF \ [ \ ]  \] \] brotherlike(27) Result 2:AGENTPATIENTlikehannah \]\[BROTHER-OFjessy\]brotherIn order to make this step-by-step description intoan algorithm we have used a breadth-first searchroutine with the property that the largest sets aregenerated first.
We collect answers in the order inwhich the search comes upon them and carry outsubsumption checks to ensure that all the answerswhich will be returned are maximal.
These checksreduce to checks on subset inclusion, which can bereasonably efficient with suitable set representati-ons.
Consistency checking is straightforward be-cause the ALE system manages type informationin a manner which is largely transparent to theuser.
Unification of ALE terms is defined in such away that if adding a feature to a term results in aterm of a new type, then the representation of thestructure is specialized to reflect this.
Since prio-rity union is non-deterministic we will finish witha set of maximal consistent subsets.
Each of thesesubsets can be converted irectly into ALE termsusing ALE's built-in predicate add_to/5.
The re-sulting set of ALE terms is the (disjunctive) resultof priority union.In general we expect priority union to be a com-putationally expensive operation, since we cannotexclude pathological cases in which the system hasto search an exponential number of subsets in thesearch for the maximal consistent elements whichare required.
In the light of this it is fortunatethat our current discourse grammars do not re-quire frequent use of priority union.
Because ofthe inherent complexity of the task we have fa-voured correctness and clarity at the possible ex-pense of efficiency.
Once it becomes establishedthat priority union is a useful operation we canbegin to explore the possibilities for faster imple-mentations.3.2 General izat ion in ALEThe abstract definition of generalization stipulatesthat the generalization of two categories i the lar-gest category which subsumes both of them.
Mos-hier (1988) has shown that generalization can bedefined as the intersection of sets of atomic fea-ture structures.
In the previous section we outli-ned how an ALE term can be broken up into atomicfeature structures.
All that is now required is theset intersection operation with the addition thatwe also need to cater for the possibility that ato-mic types may have a consistent generalization.1.
For P and Q complex feature structuresGen(P,Q) =~!
{Path: C I Path: A E Pand Path : B E Q } where C is the mostspecific type which subsumes both A and B.2.
For A and B atomic types Gen(A, B) =dr Cwhere C is the most specific type which subsu-mes both A and B.In ALE there is always a unique type for the gene-ralization.
We have made a small extension to theALE compiler to generate a table of type genera-lizations to assist in the (relatively) efficient com-putation of generalization.
To illustrate, we showhow the generalization of the two feature structu-res in (28) and (29) is calculated.23(28)(29)Hannah likes ants.AGENT hannah \]PATIENT antlikeJessy laughs.\ [AGENT jessy \]laughThese decompose into the atomic componentsshown in (30) and (31) respectively.
(30) (*/like)(AGENT/hannah)(PATIENT/ant)(31) (*/Za.gh)(AGENT/jessy)These have only the AGENT path in common alt-hough with different values and therefore the ge-neralization is the feature structure correspondingto this path but with the generalization of the ato-mic types hannah and jessy as value:(32) \[ AGENT female \]agentive4 Conc lus ionIn this paper we have reported on an implemen-tation of a discourse grammar in a sign-based for-malism, using Carpenter's Attribute Logic Engine(aLE).
We extended the discourse grammar andALE to incorporate the operations of priority unionand generalization, operations which we use forresolving parallelism dependent anaphoric expres-sions.
We also reported on a resolution mecha-nism for verb phrase ellipsis which yields sloppyand strict readings through priority union, and weclaimed some advantages of this approach over theuse of higher-order unification.The outstanding unsolved problem is that of esta-blishing parallelism.
While we believe that gene-ralization is an appropriate formal operation toassist in this, we still stand in dire need of a con-vincing criterion for judging whether the genera-lization of two categories i sufficiently informativeto successfully establish parMlelism.AcknowledgementsThis work was supported by the EC-funded projectLRE-61-062 "Towards a Declarative Theory of Dis-course" and a longer version of the paper is availablein Brew et al(1994).
We have profited from discus-sions with Jo Calder, Dick Crouch, Joke Dorrepaal,Claire Gardent, Janet Hitzeman, David Millward andHub Prfist.
Andreas Schhter helped with the imple-mentation work.
The Human Communication Rese-arch Centre (HCRC) is supported by the Economicand Social Research Council (UK).ReferencesAsher, N. (1993) Reference to Abstract Objects in Di-scourse.
Dordrecht: Kluwer.Bouma, G. (1990) Defaults in Unification Grammar.In Proceedings of the 28th ACL, pp.
165-172, Uni-versity of Pittsburgh.Brew, C. et al(1994) Discourse Representation.
De-liverable B+ of LRE-61-062: Toward a DeclarativeTheory of Discourse.Calder, J. H. R. (1990) An Interpretation of Paradig-matic Morphology.
PhD thesis, Centre for CognitiveScience, University of Edinburgh.Carpenter, B.
(1993) ALE.
The Attribute Logic En-gine user's guide, version ~.
Laboratory for Com-putational Linguistics, Carnegie Mellon University,Pittsburgh, Pa.Carpenter, B.
(1994) Skeptical and credulous defaultunification with applications to templates and inhe-ritance.
In T. Briscoe et al eds., Inheritance, De-faults, and the Lexicon, pp.
13-37.
Cambridge: Cam-bridge University Press.Dalrymple, M., S. Shieber and F. Pereira (1991) El-lipsis and higher-order unification.
Linguistics andPhilosophy 14(4), 399-452.Kaplan, R. M. (1987) Three seductions of computa-tional psycholinguistics.
In P. J. Whitelock et aleds., Linguistic Theory and Computer Applications,pp.
149-188.
London: Academic Press.Kehler, A.
(1993) The effect of establishing coherencein ellipsis and anaphora resolution.
In Proceedingsof the 31st ACL, pp.
62-69, Ohio State University.Manandhar, S. (1993) CUF in context.
In J. Dbrre, ed.,Computational Aspects of Constraint-Based Lingui-stics Description.
DYANA-2 Deliverable.Moshier, D. (1988) Extensions to Unification Gram-mar for the Description of Programming Languages.PhD thesis, Department of Mathematics, Universityof California, Los Angeles.Polanyi, L. and R. Scha (1984) A syntactic approachto discourse semantics.
In Proceedings of the tOthColing and the 22nd ACL, pp.
413-419, StanfordUniversity.Pollard, C. and I.
A.
Sag (in press) Head-DrivenPhrase Structure Grammar.
Chicago, Ill.: Univer-sity of Chicago Press and CSLI Publications.Priist, H. (1992) On Discourse Structuring, VP Ana-phora and Gapping.
PhD thesis, Universiteit vanAmsterdam, Amsterdam.Pr/Jst, H., R. Scha and M. van den Berg (1994} Dis-course grammar and verb phrase anaphora.
Lingui-stics and Philosophy.
To appear.Scha, R. and L. Polanyi (1988) An augmented contextfree grammar for discourse.
In Proceedings of the12th Coling, pp.
573-577, Budapest.24
