TIPSTER PHASE I FINAL REPORTBill Caid, Stephen Gallant, Joel Carleton, David SudbeckHNC, Inc.5501 Obedin DriveSan Diego, CA 92121(619) 546-8877.
DESCRIPT ION OF  SYSTEM USEDIN  24-MONTH EVALUATION1.0 Techn ica l  ApproachOverview: During Phase I of the TIPSTER program,HNC developed a unique approach to machine learning ofsimilarity of meaning.
This approach, embodied in asystem called "MatchPlus", exploits this learnedsimilarity of meaning for concept-based text retrieval,routing and visualization of textual information.MatchPlus uses an information representation schemecalled "context vectors" to encode similarity of usage.Key attributes of the context vector approach are asfollows:Words, documents, and queries are represented bycontext vectors.
A context vector encodes arepresentation f the meaning of a word, query, ordocument as a high-dimension, fixed length, realvector.Elements of the context vector, called "features",define a "meaning space" used for classification andretrieval of documents.
The selection of features isautomatically determined by the system and definesthe "frame of reference" for the formation of thecontext vectors.
The direction of the context vectorprovides an encoding of the meaning of theassociated text.A context vector is assigned to each unique word andphrase in the system lexicon during systeminitialization.
Word and phrase context vectors arethen learned from free text based on the context oftheir occurrences in the training text using aconstrained self organization technique.
Thislearning is fully automatic: no external knowledgebases, dictionaries or thesauri are needed for learningthe vectors.Once trained, vectors for words with similar usage inthe training text (for example NASA and SpaceShuttle) will point in approximately the samedirection.
Vectors for words with unrelated usage(like NASA and peanut) will be approximatelyorthogonal.
The degree of similarity of usage isanalogous to similarity of direction.Word and phrase context vectors are used to formcontext vectors for documents and  queries.Document and query context vectors are computed asthe weighted sum of the context vectors associatedwith stems and phrases in the document or query.Long documents may be split and represented byseveral vectors.
Document context vectors arenormalized to prevent long documents from beingfavored over short documents.
When complete, eachdocument's context vector contains an estimate of themeaning of the document relative to the currentfeature set.The context vector epresentation scheme offers a numberof advantages.
Documents can be classified (clustered),retrieved, and routed by computing conventionalgeometric distances.
This is because documents hat havesimilar context vectors (i.e., point in roughly the samedirection) will have similar information content.
SimpleEuclidean distance measurements between sets of contextvectors are a measure of similarity of meaning.Additionally, since all tokens in the system (words,queries, and documents) have the same vectorrepresentation, these comparisons of similarity can becarried out at any level of detail: word, sentence,paragraph, document, or set of documents.
This providesa mechanism for automatically finding high relevance"hot spots" within a document.
The hot spot detectionfeature is referred to as "highlighting".
Highlighting canbe performed at both the paragraph-within-a-documentand word-within-a-paragraph levels.69Document retrieval is performed by simply findingdocuments having context vectors that are close to thequery context vector.
A document's relevance to thequery is determined by comparing the dot product of thequery context vector with that of the document's contextvector.
A large dot product implies strong relevance tothe query.
The documents in the retrieval list are rankedaccording to the magnitude of the dot products.Routing is performed in a similar fashion.
The contextvector for each incoming document is compared to thecontext vector of each routing query, and if the dotproduct exceeds the similarity threshold, the document isrouted to the user(s) associated with that query.Context vectors can be used alone or in combination witha Boolean filter, thus the name "MatchPlus".
Using acompound query approach, MatchPlus can augment andenhance existing Boolean search systems because themost relevant documents are at the top of the retrievallist.
In this mode, MatchPlus will provide relevance-ranked documents within the set of documents that meetthe Boolean filter criterion, thus helping to reduceinformation overload common to Boolean-based systems.Features: The key features of the MatchPlus approachfrom a user's perspective are as follows:Documents are retrieved based on meaning ratherthan word match and are ranked based on relevanceto the query.
MatchPlus will find related ocumentseven if the key word is not present in thosedocuments.?
The unified representation approach allows the entiretext of documents o be used as a search query.Adaptive learning by steering (refining) the querycontext vector using relevance feedback can quicklyimprove the quality of a query.?
The system learns similarity of meaning from usageand can track the evolving meaning of terms.?
Easy-to-use graphical query interface is based on XWindows/MOTIF.Architecture: Key attributes of the current MatchPlussystem architecture are:Allows operation on very large corpora (in excess of107 documents) in networked and/or distributedprocessing environments.
Allows heterogeneouscorpus contents and formats.Supports Boolean, context, and relevance feedbackquery modes, and can be integrated with existing"key word" match systems to provide performanceimprovements and relevance rankings.?
Extendible and hardware-independent architecturethat provides easy-to-use graphical user interface.Summary of Conclusions: The research conducted uringPhase I of the TIPSTER program has resulted in the followingconclusions:?
The context vector approach to text representation isviable.Matchplus, which exploits the concept of "similarityof use", is fully automatic.
Demonstration ofMatchPlus's ability to learn "similarity of use" hasbeen demonstrated in the legal, medical and scientificdomain as well as in foreign languages such asSpanish and Japanese.MatchPlus's vector representation provides adetailed explanation capability that can be utilized toanswer basic informational questions uch as:1.
Why was this document retrieved?2.
What section of the document is mostrelevant?3.
What is the commonalty with this group ofdocuments?.
What is the relationship of this concept withthe rest of the text and what, if any, are thesenses in which it is used?5.
Has this concept changed or has it been usedin a different context over time?Next Steps: To fully exploit the context vectorrepresentation further esearch is required in these generalare  as:?
Use of context vectors in non-text domains such asimages.Refinement of the clustering technique to improveretrieval and routing performance and speed as wellas automated subject indexing, visualization, andword sense disambiguation.?
Continued participation in TREC evaluations andcontinued in-house retrieval and routing testing in an70effort to understand how MatchPlus's conceptretrieval system can be improved for informationretrieval and routing.Related Research: The MatchPlus context vectorapproach appears to be directly extensible to text in alllanguages and domains.
Concepts for further extendingthe approach to provide content-addressable access forimage, video, sound, and sensor data have also beendeveloped.
Rome Labs (USAF) funded furtherdevelopment of the HNC context vector-based approachas part of the Automated Librarian SBIR contract.
PhaseII of this SBIR, called Image Content AddressableRetrieval System (ICARS) will extend the context vectorapproach to the image domain.
The context vectorrepresentation can also provide a vehicle for visualizationof the information content of free text.
Any word or setof words has a vector epresentation.
As such, graphicalrepresentations of information content can be achievedbased on the context vector representation.
HNC iscurrently developing a text information visualizationsystem as part of non-TIPSTER, ORD-sponsoredactivities.
When complete, this system, calledDOCUVERSE, will have the capability to perform icon-based browsing of text as well as graphically displayeddirected queries.Current Deployment Status: Preliminary prototype testversions of MatchPlus have been in use at Wright-Patterson AFB (FASTC) for over one year.
MatchPlus isalso being evaluated at USAIA (FSTC) and otheragencies for analysis of classified data.
HNC hasreceived a contract o develop a prototype MatchPlussystem for a large legal publishing firm.
Current planscall for the evaluation of MatchPlus as part of the USPatent and Trademark Office Automated Patent Systemupgrade effort.
The current implementation of theMatchPlusITIPSTER system is based on the C languageand uses X Windows/MOTIF as the graphical userinterface.I.
I Processing Flow and Key ModulesI.
I .
I  MatchPlus Functional OverviewHNC's approach to the TIPSTER text retrieval androuting problem is called "MatchPlus".
MatchPlus is aneural network-based approach to the problem of free textretrieval, classification and routing.
The key technicalfeature of MatchPlus is the representation of words,documents, and queries by "context vectors".
A contextvector encodes a representation f the meaning of a word,query or document as a high-dimension, fixed length, realvector.
Context vectors for new words are "learned" fromthe text corpus using a process called "bootstrapping".Using the bootstrapping technique, MatchPlus learns theusage of words and meanings of documents that containthose words by using only the text corpus.Once bootstrapping is complete, the resulting wordcontext vectors are then used to form a "document contextvector" for each document in the corpus.
Documentcontext vectors are computed as the weighted sum of thecontext vectors associated with stems and word groups inthe document.Documents can be classified, retrieved and routed bycomputing conventional geometric distances.
SimpleEuclidean distance between sets of context vectors are ameasure of similarity of meaning.
Thus, documentretrieval is performed by simply finding documents thatare "close" to the query context vector.
Documentrelevance to the query is assessed via a dot product of thequery context vector with each document context vector.Large dot products imply strong relevance to the query.The retrieval list is ranked according to magnitude of thedot product.Routing is performed in a similar fashion.
Contextvectors are computed for incoming documents andcompared to each routing query.
If the dot productexceeds the similarity threshold, the document is routedto the user(s) associated with that query.Context vector similarity assessment techniques can beused alone or in combination with a "Boolean filter", thusthe name "MatchPlus".
Using a compound queryapproach, MatchPlus can augment and enhance xistingBoolean search systems since the most relevantdocuments are at the top of the retrieval ist.
In thismode, MatchPlus will provide relevance-rankeddocuments within the set of documents that meet theBoolean filter criterion, thus helping to reduce"information overload" common to Boolean-basedsystems.The key attributes of the MatchPlus system architectureare :?
Design accommodates very large corpus (more than 1million documents).?
Architecture supports operation in a distributed CPUenvironment.71?
Provisions for heterogeneous format corpus built intosystem.?
X Windows/MOTIF GUI under Sun/OS.The sections below provide a more in-depth examinationof the MatchPlus system.
This discussion will "walk-through" the operation of the system in each high levelmode and will trace the processing that occurs to a querywhen a retrieval is performed.1.1.2 MatchPlus Operating ModesThe MatchPlus ystem operates in three main modes:?
System Generation?
Retrieval?
RoutingThe system generation mode provides initialization andmaintenance apabilities and is used to "teach" the systemthe meanings of words given a training corpus of text.Once the meanings of the stem words have been derived,these are used to compute document context vectors.Retrieval mode allows the user to enter queries to theMatchPlus system and find documents that meet thequery specification(s).Routing mode, as the name implies, provided routingservices for incoming documents.
In a sense, routing isthe inverse of retrieval.
In retrieval, there is one queryand many documents that might apply to the query.
Inrouting, there is one document and many routing queriesthat may apply to the document.In order to provide a better basis for understanding theoperation of the MatchPlus system, the key datastructures used by the MatchPlus ystem will be describedprior to the detailed explanation of the operating modes.1.1.3 Key Data Structures and Control FilesAn object oriented design was utilized during the designof the MatchPlus architecture.
Therefore, to gain a betterunderstanding of the operation of the system, adescription of these data objects is required.
MatchPlusmakes use of several "key" data structures.
Thesestructures are key in the sense that many softwarecomponents use the information contained within thesestructures.
These data structures are described below.
Inan effort to standardize and reuse software components,"access routines" and "standard packages" have beendeveloped.
These packages provide a common formatinterface to widely used facilities such as hash tables,linked lists, etc.
Since these data structures areconventional data structures and are not TIPSTERspecific, they will not be discussed...1.1.3.1 Corpus Description Data StructureThe corpus description (CD) data structure, as it's nameimplies, carries information about where documents thatcomprise the corpus are located, how they are formatted,etc.
The CD is used to compress the amount ofinformation that is required to completely describe thecorpus of text to the system.
In general, there are norestrictions about the number of documents per file, thenumber of files per directory or the number of directoriesthat comprise the corpus.
The only restriction is that onedocument cannot span a file.
A schematic of the CD isshown in Figures 1A and lB.
As can be seen from thefigure, the CD contains a number of sub-objects.
Thesesub-objects are:The root object is of type "tCorpus" and contains aseries of base addresses and lengths of each of theother object arrays.
Additionally, it also contains thenumber of elements (dimension) of the contextvectors used by the system.The array of objects of type "tDocDescr" containinformation about each specific document in thecorpus.
This information includes the (internal)document ID, start FSEEK address, length in bytes, acode for the file that contains the document, a statusand a pointer to the document context vector.
Thereis one object of type tDocDescr for each document inthe corpus.The array of objects of type "tFileDescr" containsinformation about the files that comprise the corpus.There is one object for each file.
This objectcontains information such as which host in a networkcontains the file, a code for the fully qualified Unixpath for the file, a pointer to the file name, a tag toindicate how the file will be deformatted and pointersto the deformatting functions and/or deformattingscript file name.
Using this scheme, all documents ina file must have the same format.
However, each filein the corpus can have a different format if desired.72ICorpus#DocumentspDocDescrStart ~ '#FilespFileDesoStart tF#HostspHostListStart 0"#PathspPathListStart#Elements in CV.
 .
.
 "  tDodgescrcDocld (ticiFileld.tFileI~:rcFilelDtHoslList~ 1  pS~-IostOpSzHostt!cDocOffsetdgoctengthcDocStatuspDocPortCV< Repealed OnceFor EadlDocument >!cDoddiFileldcDocOffsetdgocLengthcDoc.Statu siHostldiPathld (1~\[ pSzfileName ?I1~ ~pSzS~ptR leNameO(Need PaBe) |epDocPortCV 0"cFilelDiHosUdiPathld)SzRleName 0"cDeformatTa8pProcDeforrnat ?pSzSoipffileName ? pSzHost#1-k)ststPathListI pSzPath0pSzPathlI pSzPath#pathsDekxningProcedureDefonmttingScript AleFigure 1A.
Corpus Description Data StructurePointed to by tDocPartCVtD?cDescr ?
~ /  iTreel3ucketld \[ tCV' _1 , -  / " i  , ent,?
Unkedlstof / pCVArray IIF~ I Element2tO/Element \[_objects.
~ ~  pNextCVElement J i?
End of ist (k \[ Element N asn,~ed by NNN ~ I<null> pointer.
??
One obiect inlist fox each I:X:X'tof ckx:umenLiTreeBucketldcDocPartOffsetcDocPanLengthpCVArray< null >iE, oo,0 i Element 1Element 2lI E, ne.tN I?
lbere is at least onetl~PartCV obiect foreach document?
Depending on tbedocument lenglh theremay be multiple contextvectors per document.?
Diagram to left depictsdata structure for a dngledocument with multipleconte~a vectors.?
Number of dements inthe context vector is listedin the tCorpus structureFigure lB.
Corpus Description Data Structure (cont.
).73The array of objects of type "tHostList" contains alist of character strings with the host ID.
This featurewould only be required in a distributedimplementation.The "tPathList" object is an array of character stnngsthat contain the paths to each data file in the corpus.Using this approach all files could reside in the samedirectory.
Alternatively, they could each reside in aseparate directory or some intermediate combination.1.1.3.2 Stem Information Data StructureThe Stemlnfo (SI) data structure contains informationabout the stem words that comprise the corpus and isshown in Figure 2.
Access through the SI data structure isvia the HNC-common "hashing package".
In addition toa standard hashing function, this package provides a keycapability: caching.
The hashing package has a provisionto allow the hashed objects to be either memory residentor "cached".
If the objects are to be cached, a compiletime parameter allows the user to determine how manyobjects will be kept in memory.
This provision allows theapplication to control the amount of virtual memory usedduring execution.
This is a key capability, since Sun/OShas a fixed upper bound of 500 Mb for virtual memoryusage for a single task.
Without the caching capability,MatchPlus would consume well over a gigabyte in virtualmemory during the generation of the system!Like the CD data structure, SI is composed of a series ofsub-objects.
These sub-objects are:The root object is of type "tStemlnfoDescr" andcontains a pointer to the hash description object andthe total number of unique stems found in the corpus.The "tHashDescr" object contains information aboutthe hashing function that provides access to theindividual stems.
This information includes a pointerto the hash table, page sizes and status flags, apointer to the hashing key comparison function andpaging control function and a pointer to the hashtable itself.The hash table is of type "tStemHashTable" andconsists of an array of pointers to the stemdescription objects.The information about each stem is contained in the"tStemDescr" object and contains a pointer to thestem string, the stem status, a count of the number ofdocuments that contain the stem (used fornormalization), a pointer to the context vector for thisstem and a pointer to the inverted index entries forthis stem.The stem context vector, like all context vectorswithin MatchPlus, is of type "tCV".
This is an arrayof floating point vector elements that encode the"meaning" of the stem as learned from the trainingcorpus.The inverted index entries for each stem arecontained in a linked list.
The objects in the linkedlist are of type "tDocList" and are managed by theHNC-standard linked list package.
The objects in thelinked list contain the document ID and number ofoccurrences of the stem in that document.
Thedocument ID is used as an index in the CD datastructure.I ~ I .
k "~,A  " .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
I : I !/I :e=::, F/f,':=" .....
I --"== -r -=- -d l. .
.
.
.
.
- -  .
.
.
.
.
.
.
- - ?
,~Figure 2.
StemInfo Data Structure74# /* @(#)system op_info.file 1.4 6/11/92 */# Note: the following is my current hought, if you have any Qs# please let me know, we can discuses about it# 6/1/92:PQ# This file will be updated by calling update_system_op_info_file0# previous_last_doc_num and total doc num will be updated by calling# update system_op_info_file n the end od Func.
InitializeCorpusDescr# Retrieval:#retrieval11000Start always FIRST_DOCINX3-IIDDENEnd always last doe num# process key# Previous last doc number,dunng retrieval,it always 1# Last doe number in current corpus#Generate DocList operation range definition# Start doe number and end doe number will be updated# by calling InitializeCorpusDescr when system_op is (1) or (2)# (1) regenerate_system:# (2) add_more_docs :# (3) within_this_range:inverted indexregenerate_system11000Start = 1, End = last doc numStart = previous last doe num, End = last_doc_numStart = user_define, End = user_define# process key# regenerate_system,add_more_does or witMn_this range# Start of doe number# End of doe numberFigure 3.
System.Op.Info.File1.1.3.3 System Operational Info FileThe system operational information file (SOIF), shown inFigure 3, is not a data structure, but a simple flat ASCIIfile that controls system generation and maintenanceoperations.
This file allows control of the range ofoperations performed by the system expressed using theinternal document ID.
Specifically, this file allowscontrol of the range of documents used for:s Retrieval operations?
Formation of the corpus description data structure?
Generation of stem hash table entries and theassociated stem information file?
Bootstrapping?
Generation of document context vectorsIn general, the only difference between a "new" systemgeneration and an incremental update (maintenance) isthe range of documents involved in the operation.1.1.4 System Generation OverviewGeneration of the MatchPlus system consists of foursteps.
If a "ground-zero" system build is beingperformed, all steps must be performed.
For incrementalbuilds and maintenance, step 2 may be omitted orperformed on a subset of the whole corpus.
These foursteps are detailed below.?
Initialize Primary Tables: This step initializestables that are used as part of other operations.Specifically, this step performs the following actions:Allocates the Corpus Descnption data structure.Using control information provided by the SOIFand other files, this step writes the documentstart and length information into the CorpusDescription structures.75Reads the stop word list file and generates andsaves the stop word hash table.Reads the stemming exception list file andgenerates and saves the exception word hashtable.Reads the stem word group file and generatesand saves the stem word group hash table (notyet implemented).- Reads the core stem list and loads this data intothe Stemlnfo data structure.Form Secondarv Tables: This step derivesinformation from the training corpus as specified bythe System.Op.Info.File.
Actions performed in thisstep are:Load data into the Stemlnfo data structure.
Thisoperation consists of building the stem list andassociated hash table, sorting the stemoccurrence information and forming the invertedindex.
The resulting information in the Stemlnfostructure is saved to disk.Pre-bootstrap (if double bootstrapping isspecified) or loading core stem context vectorsinto the Stemlnfo structure.Bootstrapping.
This operation will make twocomplete passes through the corpus to determinethe stem context vector for non-core words basedon their usage in the training corpus.
Theresulting learned stem context vectors are storedin the Stemlnfo structure and then the completedStemInfo data structure is saved to disk.Compute Document Context Vectors: This operationforms context vectors for all documents in the corpus.Unlike the bootstrap operation where a subset of thecorpus can be used for training and stem contextvector generation, all documents that are to beretrieved must have a context vector calculated.Context vectors for documents are calculated fromthe context vectors of the stems that comprise thedocument.
The resulting vector is normalized suchthat the system does not "favor" long documents overshort ones.Generate Cluster Tree: This operation forms thedocument context vector cluster tree.
This capabilitywill result in a centroid-consistent cluster tree that isused to reduce document retrieval times.1.1 .5  Document  Ret r ieva lDocument retrieval is implemented in two sets ofprocessing steps and is shown in Figure 4.
The first set ofsteps is initialization and consists of the following:?
Stemlnfo data structure is restored from disk (if notalready memory resident).Stop word, exception word and word group hashtables are restored from disk (if not already memoryresident).?
Cluster tree is restored from disk (if not alreadymemory resident).The second set of processing steps is event drivenoperation and consists of the following steps:Query processing is performed.
The user mayspecify a topic to be automatically processed or mayinvoke interactive mode such that queries are enteredvia the X Windows GUI.Retrieval query processing module processes andparses the query into Boolean and contextcomponents.?
Query components are saved to disk for possible lateruse .A query context vector is formed from the querycomponents.
Boolean and context erms are treatedequally in this step.For the specified Boolean query terms, the invertedindex is used to determine which documents containthese terms.
A list of documents that meet theBoolean filter is formed.The query context vector is used in conjunction withthe cluster tree to find context-relevant documentsvia the dot product operation.
A ranked list isformed.The Boolean list and the context-relevant lists aremerged and an aggregate list is formed.
This list issorted.When the user selects a document for display on theGUI, the document is deformatted (if needed) anddisplayed on the screen.76- ~  Stettl Infolmatkm ?
I Ii I ~c : :~n, J .
.
L .
I  1 I ~ Ilh.l ~ , - -  i1,,-~ I?
Gue~yI _ I I _ _ .
___S_ l  cente, t ~  ~ eoae~nI ~t~ I .
w~ ?
~ ~ ~it~.,~,J I Hera ~ U~ I I ~ Ural Tal:les l ?
and ~ (~J~y CV II I Tal:l~ C~J~y ~ / l~ , 4  P'I Doaa.mt  & II -~ 1  Coqxl$T~ D~atpUonFigure 4.
Document Retrieval1.1.6 Document  Rout ingDocument routing is, in a sense, the inverse of retrieval.In retrieval, there is one query and may documents.
Inrouting, there are many queries and one document.
Theprocess flow for document routing is shown in Figure 5.This flow shares many processing components with theretrieval flow.
Routing is broken down into three mainoperations:Initialization; The initialization operation restores alldata structures and tables as needed.
This includesCorpus Description, StemInfo, and the stop word,exception word and word group hash tables.Ouerv Processing: This operation is divided intoGUI and topic query processing.
If interactive modeis selected, the GUI is used to assemble a routingquery.
If topic mode is selected, the specified topictext is read.
Queries used for document retrieval canalso be restored and used for routing.
For theselected mode, the query is parsed into Boolean andcontext erms and a similarity threshold, to be usedfor route/no-route decisions.
A routing contextvector is then computed using both the Boolean andcontext terms.
'ntis query processing step isperformed for each routing query to be used in thesystem.
The routing information (context vector,Boolean terms and match threshold) is stored in atable along with the user ID of the route.Document Routing: For each document to be routed,the following steps are performed:If required, the document is deformatted into theMatchPlus-internal format.Document preprocessing is performed: stopwords are removed, stemming exceptions areidentified and stems are produced.77\] Stem Inform ationRestore I StemInfonnatlon RautlI Pro~e~Topic Topic ~ ~\[ Processing I .J\[oo,_LI ool ld IRestore ~ Wold Lists JtTables ~ and Tables -Boolean QueryRestoreSaved Context Quer?QueryBooleanQueryI ?ins~kCoNtext RoutingQuery cv " - -=1m ?
/?
I I YtComp, r CV', I 'qv  IILlC?mpa:eCV's?
loot P oduct - I -~ , - I I ,  I ,oo, P,o.c I - - I  i I I I "  c I or.M, I or NN)  I?
'hr~'ho'd I F~x l r~I kl Boolean D~cum~t CV COln pal~ to?
I Filter "thresholdI-T P~processe d Oolllnl en t~le~nine I DocumentDispositia~J,Documentto CorpusText OescriptianFigure S. Document RoutingAdditionally, a context vector for thepreprocessed document is computed.For each routing query in the system:The preprocessed document is passedthrough the Boolean filter operation to see ifthe filter criteria is met for this routingquery.The dot product of the routing query contextvector and the document context vector iscomputed.The Boolean filter is passed or the dotproduct threshold is exceeded, then thedocument is routed to the user associatedwith this routing query.If  specified, the document is added to the corpus,Corpus Description and Stemlnfo data structures.1.2 System ThroughputBuilding the MatchPlus system can be broken down intothree main areas: inverted index generation, learning ofstem context vectors, and generation of document contextvectors.
The approximate times to build the system aswell as the retrieval time are given in Table 1.
Thehardware is a Sun Sparc 10 with 512 megabytes of RAM.BUILD STAGE TIMEInverted Index Generation -10,000 documets anhourStem Context Vector Learning -2000 documents anhourGeneration of Document -25,000 documents anVectors hourRetrieval -3000 documents perCPU secondTable 1.
System Build TimesIt should be noted that the stem context vector learningdoes not need to be applied to the entire data set.
For theTIPSTER 24 month evaluation the system was onlytrained (i.e.
learning of stem context vectors) on 80,000documents (approximately 40 hours).For the TIPSTER tests the use of a boolean filter greatlyincreased the retrieval speed.
Instead of ranking theentire database using the document context vectors a78broad boolean filter would return a small subset (50,000-100,000 documents) which would then be ranked bycontext vector.
Another approach the MatchPlus systemutilizes to speed up retrievals is the use of clustering(refer to section 4.0 for a discussion of clustering).
HNChas been successful in speeding up retrievals by a factorof 20 with no degradation i  performance by utilizingdocument clusters.1.3 Key InnovationsDuring Phase I of the TIPSTER project he HNC team,through its research and experimentation, has formedsome highly significant conclusions.
These conclusionsnot only encompass the main' objective of TIPSTERphase I, text retrieval and routing, but address muchlarger issues involving the processing of information.The major conclusions and innovations are as follows:Context vector approach to text informationrepresentation is viable.
The assertion that a vectorspace model can be utilized to retrieve from large(gigabyte) heterogeneous databases has been proven.In addition the use of initial hand entered contextvectors is unnecessary and in fact does NOT performas well as a fully automatic approach.
Unforeseenuses for context vectors have also been discovered.These include document clustering, word sensedisambiguation, visualization, image retrieval, andautomated hyperlinks in a hypertext environment.?
Fully automated learning of similarity of usage hasbeen demonstrated.
Even very low frequency words(e.g.
last names) are trained such that they areassociated with logical "concepts".
This is doneautomatically with no thesauri or knowledge base,only the relationships as they occur in the text areused.
Beyond the obvious benefit for retrievingdocuments and investigating word relationships,other possible applications of "similarity of usage" isin the analysis of how particular concepts evolve andchange over time.
For example a person's name mayalways be mentioned with a certain company, but ifnew text were added in which the name appearedwith a different company this change in relationshipwould trigger an alarm for an analyst.
Refer toFigures 6 and 7 for examples of automated learningfor specific words (referred to as "stem trees").
Thetext to the right of the bar graph is an example of thecontext in which a specific word is found in the text.?
Context Vector representation is languageindependent.
MatchPlus uses no language dependentknowledge basis (e.g.
WordNet, thesauri).
Small(10-20 meg) systems have been built both in Spanishand Kanji and the "learning" of similarity of usewitnessed in English carried over to the otherlanguages.Conventional neural networks can be effectivelyapplied to context vector operations.
In a routingenvironment basic networks can be trained and haveshown to give a 20 % improvement over adhocmethods.
Additionally, clustering algorithms havebeen utilized to perform automated word sensedisambiguation a d document clustering.
Automatedword sense disambiguation with context vectors hasbenefits beyond information retrieval such asmachine translation.
Document clustering also hasfurther applications in visualization and automatedsubject indexing.Constrained learning law (bootstrapping)promotes learning stability.
Constraining thegeometry of the vector space can produce a stablesolution independent of the number of training passesthrough the corpus.2.
SYSTEM GOALSThe primary goal of the HNC's MatchPluslTIPSTEReffort was to apply advanced adaptive and neural networktechniques to improve the state of the art in text retrievaland routing technology.
More specifically HNC sought odesign a vector space model for text that encodes arepresentation f similarity of meaning.
To reach thisgoal HNC developed an adaptive technique to learnsimilarity of meaning for words using only free text asexamples.
Once the similarity of meaning was encodedin a vector epresentation the MatchPlus system neededto exploit the learned relationships to provide improvedprecision and recall over current echniques.
In additionit was HNC's intent to apply neural network learningalgorithms to automatically improve queries based onuser feedback.The MatchPlusITIPSTER effort had a number ofsecondary goals.
These included the development of agenetic representation for word similarity that could beexploited for other uses (e.g.
visualization, key wordextortion), use of a minimum of human knowledge forsystem generation and retrieval (e.g.
dictionaries,thesauri), and the creation of a basis for multi-media ndmulti-language capabilities.79chernobylchernobyl ^reactaccid^cher nobyi&asterdam^radiaccid^nudeardemonslratacddAreactmaksimovtelethonradiophobgraves\[nuclearnuclear^reactscherbackhumankindscherl3aktaraperentembnudear ^lmW~0.1 0.2 0.3 0.4 0.5 0.6Det~eduot0.7 0.8 0.9Figure 6.
"Stem Tree" for ChernobylhezbollahamalsyrmmOil~aWmughntyehumbrellmlllSawshiyahsohllhallaJfadlallahlutddalhzealotshiitsecetfunclamentlariatSl~lllOngodmoslem ^shiit0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 IDot ProductFigure 7.
"Stem Tree" for Hezbollah803.
EVOLUTION OF THE SYSTEMAt the start of the 2 year TIPSTER project HNC hadnothing more than a preliminary prototype that embodiedthe conceptual idea for the use of context vectors forinformation retrieval.
The original prototype was built onless than 500 documents.
Throughout he TIPSTERprogram the original MatchPlus system underwent asignificant amount of changes and enhancements.
Thegoals of these changes and enhancements are explained insection 2.
The evolution of the system was driven byboth the performance on the TIPSTER data (i.e.
recalland precision umbers) as well as a software design thatenabled the processing of gigabytes of text such as theTIPSTER collection.
Some of the major software designstrategies implemented for processing large databases arelisted as follows:?
Caching algorithms to prevent the overflow of virtualmemory.?
File splitting for files that span more than a singlediskHeap data structures to quickly get the top "N"documents from a collection of "M" documents giventhat "N" is much smaller than "M".?
Internal memory management to prevent excessivememory allocation and memory freeing.?
Use of clustering to prevent searches on the entiredatabase.?
Re-ordering of document vectors by cluster to reducethe number of disk seeks thus, speeding up retrieval.Changes and enhancements not related to the size of thedata, but rather the goal of learning similarity of use in avector representation a d exploiting that representationwere made in various areas.
Those areas and theenhancements or changes made are as follows (fordetailed results of the enhancements refer to section 4):1) Preprocessing?
Addition of word phrases.?
Use of a stemming exception list prevents wordssuch as "army" from being stemmed to "arm")2) Bootstrapping?
Use of a fully automated learning algorithm (i.e.the use of the manually entered core stemcontext vectors from the original system wasreplaced by a fully automated learningtechnique.?
Use of a batch update for the training of stemcontext vectors.?
Ability to transplant he learned relationshipsfrom one corpora to another and suffer nodegradation i performance.?
Ability to automatically disambiguate wordsgiven only free text examples.?
Improvement over original stem context vectorlearning law that provides adjustable constraintsand comes to stability.3) Generation of Document Context Vectors?
Ability to cluster documents.4) Query Processing?
Use of broad boolean filters?
Automated parsing of the TIPSTER topics whichprovides optimum performance.?
Relevance feedback to improve an originaladhoc query.5) Routing?
Use of perceptron learning to create a routingquery given a set of relevance judgments6) Graphical User Interface?
Word, paragraph and document highlighter toquickly get to the most relevant information.?
Simplistic method for user relevance feedback* Automated subject index?
Examination of learned relationships (i.e.
stemtrees)?
Document headline display to quickly scan a setof retrievals81?
Ability to process natural language queries.4.
EXPERIMENTS & PERFORMANCEA number of research areas were identified as possiblecandidates for improvements in MatchPlus performance.These areas covered a wide range of processes includingpreprocessing, learning and query formation.
HNCutilized the official retrieval results from the documentdetection runs sent in for the 12 month, 18 month and 24month evaluations.
These evaluations consisted of a setof 150 topics and 3 CD-ROMs with about 1 gigabyte ofdocument data each.
The document data consisted of theWall Street Journal, San Jose Mercury News, APNewswire, Information from Computer Selected disks,Federal Register, U.S.
Patents and short abstracts from theDepartment of Energy.
These sources had a variedlength, a varied writing style, a varied level of editing anda varied vocabulary.
In addition to utilizing the officialtest collection, the HNC team created subsets of theTIPSTER corpus.
These subsets contained exhaustiverelevance judgments for each of the topics (either judgedinternally or judged by the TIPSTER relevance assessors)and varied in size.
A 1,000 document corpus (~10megabytes), 10,000 document corpus (~60 megabytes),30,000 document corpus (-120 megabytes), and a 80,000document corpus (-320 megabytes) all containingselections from the AP Newswire, Wall Street Journal,Federal Registry and the Department of Energy wereutilized for testing.
In addition to the recall (number ofrelevant items retrieved / total number of relevant itemsin collection) and precision (number of relevant itemsretrieved / total number of items retrieved) numbersobtained from the evaluation code and the test collectionsmentioned above, HNC analyzed the quality of thelearned relationships via the "stem trees" (refer to figures6 and 7).
By evaluating the effectiveness ofMatchPlus tolearn similarity of use as well retrieval performance HNCwas able to meet wo goals: superior etrieval and routingperformance and the ability to learn similarity of use.4.1 P reprocess ing  TestsPreprocessing consists of scanning each document forindividual tokens.
Each token (delineated by a space, tab,comma, etc.)
is then stemmed (i.e.
endings such as "ed"and "ing" are removed).
Stemming serves the function oftreating words such as "run" "runs" and "running" as thesame stem (word) as well as greatly decreasing the size ofthe data structures.
A stemming exception list isconsulted (to remove stemming errors such as stemming"army" to "arm") as well as a stop word list.
The stopword list removes frequently used word such as "and" and"the" that contribute little to the overall meaning of thetext.The Use of word pairs (e.g.
"white house") wasinvestigated.
The list was manually generated bypresenting all two word combinations that were found inthe text to an analyst who determined if it was a validword pair.
Our investigations found it was best to splitthe word pairs into their individual words.
For example if"white house" was found in the corpus or the query therewould be three different context vectors used for thecalculations, one for "white" one for "house" and one forthe word pair "white house".
The use of word pairs inboth the bootstrapping and the query processing ave animprovement of 10%-15%.Use of classical IR tools such as stop word lists andstemming improved performance.
Eliminating stopwords, stemming and stemming exception words caused adecrease in performance of 12%.Late in the project HNC was able to experiment with ahead list from Compton's New Media.
A sample of thislist is in Table 2.taketalltangletooktallertangleweedtakentallesttanglestakingtangledTable 2.
Encyclopedia Britanica Head ListReplacing the MatchPlus baseline stemmer (the Lovinsstemmer) with the head list gave no improvement inretrieval performance.
On the TIPSTER tests the headlist did get equivalent performance to the baselinestemmer.
It is interesting that the list did not help more.As seen in Table 2, the two words "took" and "take" aretreated as a single word while the baseline stemmer(which simply removes suffixes) would treat these asdifferent words.
It seems that with the context vectorapproach if terms such as "take" and "took" are used insimilar ways in the text the context vector learningapproach will encode that, likewise, if they are used indissimilar ways the context vectors for the two words willnot point in the same direction.
If in preprocessing, thetwo words are treated as a single word (e.g.
take is thesame as took) the context vector learning will never begiven the chance to determine if in fact the two words areused in a similar fashion.824.2 Boots t rap ing  Tests  4 .2 .2  F reez ing  Core  Context  Vectors  Tes tsMajor effort was spent experimenting and researching thevector learning law.
The main objectives were superiorretrieval performance and the ability to automaticallylearn similarity of use for any domain and corpus size.The following are the major experimental reas and theconclusions reached.4.2.1 Automat ic  Representat ion  TestsThe key discovery of Phase I was the ability toautomatically learn a vector representation for wordsusing only free text examples.
MatchPlus's originalapproach used a set of 940 core context vectors.
Eachcore word was compared to a set of 80 features (words).On a scale from -5.0 to +5.0 the amount of "similarity" or"relation" was entered.
For example if the core wordwere "protein" and the features were "agriculture","DNA", etc.
its feature vector might look like Table 3.Core Feature Feature Feature Feature etc.Word 1 2 3 4agriculture DNA electronics human ....protein 2.0 4.0 0.0 1.0 .....man 0.0 2.0 0.0 4.0 .....Table 3.
Manually enter context vector for word"protein"An additional 200 random elements (floating pointnumbers) were augmented to the 80 manually enteredfeatures.
All 280 feature elements were then modifiedaccording to the bootstrap aigorithm.
To investigate the"benefit" of the manually entered core context vectors thefeatures were replaced by random numbers, making theentire context vector (280 features) completely random.This approach gave a 3% to 6% improvement over thehand entered set on a subset of the TIPSTER corpus.The creation of hand entered vectors are time consuming,corpus dependent and language dependent.
The fullbenefits of hand entry are certainly contingent on the setof core words and the set of features that are chosen.
Amore domain specific set of manual context vectors maybe of some benefit but with the broad range of featuresand the heterogeneity of the tipster corpus, hand entrygives no apparent retrieval improvement.
MatchPlus'sability to learn word relationships from random initialvectors without hand entered context vectors is a keydiscovery that enables the MatchPlus system to work invirtually any subject domain and any language.The motive for "freezing" (i.e.
not allowing the handentered context vectors to be modified duringbootstrapping) was to prevent the collapsing of the vectorspace.
The original bootstrapping algorithm modifiedword vectors uch that each vector pointed in more or lessthe same direction.
This collapsing phenomenon resultedin words and ultimately documents residing in a muchrestricted vector space.
Individual words and documentswere indistinguishable.
The hypothesis was if the handentered context vectors were sufficiently spread out andkept constant this would prevent the vectors fromcollapsing.
Due to the limited number of hand enteredvectors (940) and the observation that similarity of useencoded manually was drastically different from thesimilarity of use learned automatically duringbootstrapping "freezing" hand entered context vectors didnot prove successful.4.2.3 S taged  Boots t rapp ing  TestsIt was thought a staged approach to vector learning mayimprove performance.
The conjecture was that wordswithin a certain frequency range should be trained tostability, then use these vectors to train words withinanother frequency.
The original bootstrapping algorithmmade two passes through the entire corpus.
On the firstpass only words that appeared in corpus 3 times or morewere modified.
All remaining words were modified onthe second iteration.
Further experiments involved up to4 passes with varying frequency thresholds for stemmodification on any single iteration.
These experimentsproved to give no significant change in performance.
Infact, the current implementation performs two passesthrough the corpus modifying everything on each pass.Performance after one iteration is only slightly worse(2%-3%) than two iterations while a third iteration givesa slight improvement (2%-3%) and levels off with morethan three passes through the corpus.4.2.4 Vector  S ize  (D imens ionaf i ty )  Tes tsThe choice of the number of features (vector elements)for each stem was 280.
Investigations a  to the number offeatures actually utilized was performed in various ways.Using subsets of the TIPSTER corpus (1,000, 10,000 and30,000 documents) in which relevance judgments wereavailable the vector size was both increased anddecreased.
Since document context vectors arerepresented in the same space as the word context vectorsthe dimensionality was the same.
The results of the83experiments are given in Table 4.
Each entry is incomparison to the baseline of 280 features.VectorDimensionMatch FilteredQuery50 r 12 % -47 %140 -8 % -24 %280 0 % 0%512 +5 % +4 %Coniext Vectoronly QueryTable 4.
Vector Dimension vs. Retrieval PerformanceTo further give evidence as to whether or not alldimensions of the vectors were being utilized an eigananalysis was performed on the 1,000 document corpus.All the stem context vectors (approximately 16,000) weremultiplied creating a 280 by 280 symmetric matrix.
Asingular value decomposition was then performed todetermine if the vectors panned the entire space.
Figure8 plots the eiganvalues for a 280 dimensional system andfigure 9 plots the eigenvalues for a 512 dimensionalsystem.
It is clear that the 280 features are spanning thespace, any fewer would cause the stem vectors to overlapeach other and, as evidenced in Table 4, cause adegradation i performance.
Figure 9 indicates that 512dimensions i perhaps too large for this size corpus.ud3836343230I50 100 150 200 250Learned Features Indic esFigure 8.
Eigen Analysis of 280 Dimension StemContext Vectors300250150N lO050100 200 300 400 500 600Learned Features IndicesFigure 9.
Eigen Analysis of 512 Dimension StemContext VectorsEmpirical tests showed that increasing the vector sizeimproves recall.
For the TIPSTER 24 month evaluationthe precision (number of relevant documentsretrieved/total number of documents retrieved) for a 280feature vector versus a 512 feature vector showed littledifference while the recall (number of relevant documentsretrieved/total number of relevant documents) increasedapproximately 5%.4.2.5 Thesaurus Training TestsHNC obtained an electronic thesaurus in an attempt oencode the relationships found in the thesaurus into thevector space model.
The reasoning behind thisexperiment is as follows.
The bootstrapping algorithm isdesigned to encode word relationships in a vector spacemodel using examples from free text.
If a pre-existingknowledge base (e.g.
thesaurus) were used as an initialtraining example this may help the MatchPlus system inlearning word relationships.
The thesaurus trainingvectors would act as an initial starting point for trainingon the TIPSTER corpus much like the hand enteredcontext vectors did.
Past information retrieval programshave used thesauri for query expansion.
MatchPlustrained on the thesaurus, which did exhibit very goodstem trees, then using the trained vectors trained on theTIPSTER corpus.
In one experiment thesaurus wordswere allowed to be bootstrapped (trained) by the corpus.This gave a degradation i performance (10%-15%) overour baseline system.
An alternate approach to thesaurustraining involved "freezing" the stems that were trainedby the thesaurus during bootstrapping.
There was asignificant degradation in performance (40%-50%).Through the use of stem tree analysis after thesaurustraining and after the TIPSTER corpus training it becameapparent hat "similarity of use" is NOT the same assynonymy.
Referring to the stem trees in figure 6 and84figure 7, it is clear that the related "concepts" to both"Chernobyl" and "Hezbollah" are much more thansynonyms.
The stem trees reveal the "true" meaning ofconcepts as they are used in the training data.4.2.6 Training Window Size TestsThe original bootstrapping algorithm used as its windowvector three words on either side of the "target" updatestem (refer to figure 10).
These stems were summed upusing a Gaussian distributed weight and applied to the"target" stem.
There was no consideration paid tosentence and paragraph boundaries (i.e.
the windowvectors could be part of another sentence or paragraph).Only the document boundaries were used (i.e.
thewindow for a "target" update stem did NOT carry overinto the next document).
The conjecture was that like asingle document, each sentence contained a complete ideaor concept.
Likewise a paragraph contained a uniqueconcept and if these "concepts" were treated asindividual documents the system would perform better.Tests were run in which bootstrapping occurred onsentence and paragraph markers (i.e.
the window did notuse words to the right or left of the target update stem ifthey began or ended a sentence or paragraph).
Using onlyparagraph boundaries as well as sentence and paragraphboundaries made little difference in performance.
Usingan early version of the bootstrapping algorithm there wasa slight improvement in performance (2%-4%).
Althoughwith the latest bootstrapping implementation there is asmall degradation i  performance (less than 1%).
Ourconjecture that each sentence and each paragraph containsunique "concepts" is incorrect for the TIPSTER corpus.While some of the document sets do not containparagraph markers (Department of Energy, FederalRegistry) it is apparent hat even when there existparagraph markers they do not express complete thoughtsbut are inserted for aesthetic reasons.4.2.7 Batched Learning TestsA learning law experiment hat proved to improveretrieval performance significantly for all size builds(1,000 documents, 10,000 documents, etc.)
was thebatching of the adjustment that was to be made to eachstem.
The original algorithm would make immediateupdates as it encountered each stem in the corpus.
Forexample if the word "stock" was the first word in the firstdocument its initial random context vector would getmodified by the neighboring words.
When "stock" wasencountered again in the document or in one of the nextdocuments either as a target for updating or as aneighboring word contributing to a target stem's update,the "altered" context vector was used.
This created a"smearing" condition in which the context vector for anyword was continually being changed and other stems usedthese "intermediate" changes when calculating theirneighborhoods.
Batching was implemented to removethis condition.
The algorithm was modified such thateach update that was to be applied to any stem was storedbut never actually applied to the target word until the endof the iteration (i.e.
when all the documents wereprocessed).
This "batching" technique provided a morestable algorithm in that each word context vectorremained the same as it became a target for updates and aneighbor, contributing to another word's update.
Table 5shows performance improvement with batching forvarious corpus izes.CORPUS SIZE PERFORMANCE CHANGElk +25 %10k +22 %30k +19 %Table 5.
Batching vs. Non-Batching PerformanceI--INC did experiment with batching the updates on thedocument boundaries as opposed to the entire corpus butthat did not provide as big an improvement as the fullbatching.As mentioned above, the learning algorithm uses awindow size when calculating a neighborhood for a targetword.
The original approach used 3 words to the left ofthe target and 3 words to the right of the target.
Variousother window widths were tried including using the entiresentence as the window (again with the conjecture thatcomplete concepts are contained in a single sentence).The results indicate a window width of 3 words workswell but further investigations with alternate weightingsneed to be conducted (i.e.
Gaussian weight is applied toneighboring stems which causes the closest words inproximity to the target word to have the largest weight).Table 6 has some comparisons for various window widthsizes against he baseline of 3 words on either side thatwere run on the lk corpus.85WINDOW SIZE PERFORMANCE CHANGE4 words -2 %5 words -5 %entire sentence I -1%Table 6.
Window Size Experiment.sMany experiments were conducted that involvedtransplanting a set of stem context vectors from onecorpus to another.
For example a set of vectors trainedfrom a 1,000 document subset could be transplanted intoa 10,000 document system.
There are approximately16,000 unique stems in the 1,000 document corpus and60,000 stems in the 10,000 document corpus.
During atransplant the trained context vectors for each stem arecopied into the corresponding stem for the 10,000document build.
The stems not found in the 1,000document build are set to zero since they are untrained(experiments were conducted in which the untrained stemcontext vectors were initialized to random numbers andthe retrieval performance indicated it was better to setthem to zero so they have no affect when generatingdocument context vectors).
Once the transplant iscomplete the document context vectors are calculated.The results of various transplant experiments arepresented in Table 7.Type of CorpusTransplantlk transplanted into 1Ok10k transplanted into 30kTransplant Performance-7.0 % prec., -0.6 %recall-3.2 % prec., -2.1% recallTable 7.
Transplant ResultsGiven these encouraging results and the amount of timerequired to bootstrap the entire TIPSTER collection,various subsets of the TIPSTER corpus were trained andtransplanted into the entire collection.
It has becomeapparent that when working with gigabyte corpus sizes itis important to train on a sufficiently large portion of thetext.
A 10,000 document subset (45 meg) and an80,0000 document subset (320 meg) were used fortraining and transplanted into CD's 1 and 2 of theTIPSTER collection.
The official results (avg.
prec andtotal relevant) are given in Table 8.Training Set Precision RelevantSize Documents10k documents .2648 724080k documents .2837 (+4 %) 7541 (+7 %)Table 8.
Transplant Results for CD's 1 and 2 fromTIPSTER CollectionIt seems contradictory that the results in Table 6 indicateit is possible to get "near" baseline performance bytransplanting from a smaller corpus while Table 7indicates performance can suffer from a smaller corpustraining and transplant.
If one looks at the percent ofuntrained stems in the above tests it becomes apparentthat 10,000 documents (45 meg) is not large enough tocharacterize the first two CD's (1,200 meg, 740,000documents).
The percentages are presented in Table 9.Donor and Recipient ofTransplantlk to lOkPercent of TrainedVectors32 %10k to 30k 21%10k to CD's 1 and 2(1,200k)80k to CD's 1 and 2. .
.
.
.
(1,200k)7%23 %Table 9.
Percent of Trained Vectors for VariousTransplantsMost of the transplanting experiments involvedtransplanting a smaller training set into a larger set.Some tests were conducted where the training set was thesame size and larger than the "target" set and the resultsindicated that only a small (less than 3%) degradation iperformance is detected.
This result indicates that asufficiently large and sufficiently domain compatible (i.e.wall street journal transplanted into associated press,NOT wall street journal transplanted into New EnglandMedical Journal) can be transplanted continuously,eliminating the need to bootstrap new documents, thusgreatly increasing the speed of building new systems orupdating existing systems.
For existing systems, whennew data needs to be added it is sufficient to simplycreate adocument context vector for each new document.4.2.8 Word Sense DisambiguationLate in the project the concept of "word sense"disambiguation was investigated.
"Word sense"86disambiguation refers to finding all the "senses" in whicha word is used.
For example the word "star" may be usedin the context of "the moon and the stars", or in thecontext of "star wars and the Strategic Defense Initiative",or "movie star".
These senses can be disambiguated fromthe text as well as the query resulting in improvedretrieval performance.
This process is completelyautomatic and uses no thesauri or knowledge bases.
Theword sense disarnbiguation uses a k-means clusteringalgorithm to cluster a given set of context vectors.
If, forexample the word "virus" is to be disambiguated eachneighborhood window (i.e.
the 3 words on either side of"virus") is calculated.
Then each of these neighborhoodvectors (the number of vectors is simply the frequency ofthe word "virus" in the corpus) are given to the k-meansclustering algorithm with a pre-specified number ofresulting clusters.
Once these clusters have beencalculated they can be used in various ways.
Duringdocument context vector generation the appropriate senseof the word can be calculated by taking the neighborhoodcontext vector found in the document and calculating thedot products with the centroids of each of the clusters forthe word.
The closest cluster would then be used whencalculating the document context vector.
In an identicalfashion the "best" sense could be automaticallydetermined in a query.
Given the following query:"movie stars who are in cowboy films" it would beexpected that the cluster involving "movie stars" wouldbe used and NOT the cluster involving "the moon and thestars".
Evidence supporting the above claim can be foundin Table 10.
The Wall Street Journal from 1990 through1992 was used.
The example shows the list of 4 clustersthat have been calculated for the word "virus".
Theclusters are listed in order of dot product (highest dotproduct is first) with the word "internet".
It is clear thecorrect sense would have been determined if the querywere "internet, virus".Sense1 computervirus2 mixup3 methy-lpredin4 hivRelated Related Related RelatedWord 1 Word 2 Word 3 Word 4computertransmitsecreteimmun-deficiencymichel-angelotobaccorecombineinfectportablecomputergeneticnecrosretrovirusTable I0.
Word Senses for "virus" in the Context of"internet"There has been limited testing with "word sense"disambiguation.
Using the TIPSTER collection and thetopic queries the performance is slightly better (less than5 %) than our baseline system which does not utilize theword senses.
Future experiments include using more thanone word sense for queries and/or documents, overspecifying the number of clusters wanted then running a"combiner" to determine the appropriate number of sensesfor each word on an individual basis (this has been donefor document clustering with some success, see sectionsbelow), re-bootstrapping after the word senses have beencalculated, only modifying the sense that matches closestwith the window context vector, and using alternateclustering algorithms that automatically determine thenumber of clusters.4.2.9 Learn ing  Law TestsOne of the most important experiments involved the wayin which the word context vectors were updated.
Morespecifically the point at which the update was made andthe weight applied to that update were investigated.
Theoriginal earning technique used a "moving average" typeof approach with a positional weighting.
The "window"(i.e.
the 3 words on either side of the target stem) wascomputed using the Gaussian weighting function.
Thiswindow vector was then added to the unnormalized targetstem and the resulting vector was normalized (refer toFigure 10).i l l1.0GaussianWeightingFunction G(i)i=-3 i=-21=-1 i=0 1=1i=21=3Now is \[ th~ time for \[ all I8oodmento \[ cometo .
.
.Neighbors Target NeighborsFigure 10.
Original Bootstrap Window CalculationThe "moving average" approach produced modest resultsas evaluated by the TIPSTER tests.
Further investigationsindicated the algorithm was not moving the stem contextvectors a sufficient amount in the direction of their"window".
This could be perceived when looking at thelearned relationships for a specific word.
This "stem tree"calculation uses a single stem and calculates the dotproduct with every other stem in the corpus and producesa list in order of stems that are closest o the specifiedstem.
The list produced after training was very similar tothe list produced before training, using the initial randomcontext vectors.
The new approach applies a constraint to87the geometry of the vector space.
The constraint willdete~nine how close any target can get to its neighbors.The influence of each neighbor on the target isdetermined individually by Euclidean distance.
Theoriginal implementation ly used the weighted sum ofneighborhood stem context vectors.
The amount of theeffective rror and the corresponding change in position isdetermined by the co-importance of the neighbor and thetarget.
"Overtraining" resulting in poor performance, acharacteristic of the original approach, is eliminated whenconstraints are applied to the learning law.4.3 Document Context Vector GenerationThe approach to document vector generation is to simplyadd up each of the stems, weighted by the inversedocument frequency (IDF) weight (see Figure 11).D?cCVk = Z:=, wi(StemCV~ )w i = log(~ N)n iFigure 11.
Document vector equation4.3.1 Weighting TestsVarious weighting techniques were experimented with.One approach was to eliminate the IDF weightcompletely and use a fiat weighting scheme.
Like theapproach found in Figure 11 if a word is repeated a greatdeal throughout the document its vector is continuallyadded to the document causing the document vector topoint in the same direction as the repeated stem (i.e.overly biased toward the high frequency stems),regardless of the other words present in the document.
Avariation to the IDF weighting was experimented with.Instead of adding the stem each time it is encountered inthe document, he stem vector is added once and given aweight equal to the log of the frequency of the stem in thedocument (Chris Buckley reported an improvement overIDF weighting using this approach - See TREC2Conference, Aug 30, 1993).
Once again, this did notprove to be beneficial with regards to the TIPSTER testsbut in terms of solving the problem of a single stem"overpowering" the other stems in the document vectorrepresentation it has proved successful.
A final attempt atalternative document generation weighting used theimportance factor formula that was used in thebootstrapping algorithm.
This too did not provide asignificant change in performance.
The original approach(the IDF weighting) does seem to give the bestperformance on the TIPSTER tests over the variationstried by HNC and others.
Table 11 provides a summaryof the performance r sults for the 10k corpus.WEIGHTING ' PERFORMANCE CHANGEIDF 0%Flat -1.8 %Modified IDF -2.7 %Importance -3.8 %Table 11.
Document Weighting Experiments4.3.2 Document Clustering TestsDocument clustering uses the same algorithm as wordsense disambiguation (K-means).
Each document has acontext vector.
When document clustering is performedthe number of clusters is pre-specified.
Each documentvector is put into one of these clusters.The initial motivation behind document clustering was toimprove retrieval speed.
Although the results arepreliminary, it is apparent hat retrieval time can begreatly reduced.
As the number of clusters earched for aretrieval goes down the retrieval speed also goes down.Obviously as the number of clusters earched is decreasedthe system's recall goes down.
Early tests on the 10,000document subset of the TIPSTER corpus indicate that byonly looking at 500 documents from the top "n" clusters(variable number of clusters are searched for each topic)there is less than a 5% degradation i  recall and precision.For the non-cluster system 10,000 dot products arerequired for each query while the clustered system onlyrequires 500 dot products for each query.An extremely noteworthy discovery involving documentclustering is an automated cluster explanation capabilitythat is inherent in the context vector approach.
By takingthe centroid vector of each of the resulting documentclusters and "dotting" them (i.e.
calculating the dotproduct) with every word and word phrase in the corpusthe system can automatically elucidate the meaning of thecluster (i.e.
what the documents in the cluster are about).would be used for all topics regardless of the number ofwords contained in the "concept" section (the averagenumber of words in the concepts ection is -25).
Therelative threshold would'require "x" percent of the wordsfrom the "concepts" section to appear in a document88Cluster 1iCluster 2 Cluster 3 Cluster 4 Cluster 5launch at&t snow commando interfacemaiden sprint gust guerilla specifictitan cable shower shiite portablepayload " transmit appalachians lebanon architecturepad fcc dakato gunman processornavigation tariff wisconsin insurgent logicshuttle mci wyoming moslem programmingrocket gte scatter afghan databasenavstar fiber thunderstorm manilla graphgooch transmitted commuter alih diagnosticnasa coaxial lake dash softwareunmanned marketplace buffalo hezbollah prologorbit distance minnesota islamabad maintenancebooster optic eastem fled hardwaredelt phone upper mujahedeen interactatl copper idaho palestin concursatellite breakup picket pakistan functionspace Its nebraska vorontsov computerchallenger deregulation wind wound querydiscovery competition valley beirut languageTable 12.
Document Cluster Closest StemsThis can be used to aid in visualization and in creatingautomated subject indexes.
An example of the clusterexplanation is given in Table 12.
This sample was takenfrom the 1,000 document test system which was clusteredinto 20 groups (5 of the clusters are presented in thetable).4.4 Query ProcessingThe TIPSTER evaluations consisted of 150 topicdescriptions ( ee appendix C for an example).
Numerousexperiments were conducted to come up with the optimalautomated parsing strategy for all the topics over all ofthe TIPSTER corpus.
Additional experiments involvedalternative weighting schemes and relevance feedback.4.4.1 Boolean FiltersThe MatchPlus system works best in conjunction with agross boolean filter (i.e.
specifying many terms with asmall match requirement).
Given the structure of thetopic queries, it was apparent the "concepts" portion ofthe topic would be a likely candidate for the booleanfilter.
This in fact did turn out to be the best approach.The two match threshold approaches were an absolutethreshold and a relative threshold.
The absolute thresholdwould use the same threshold for all the topics.
Forexample if the threshold were 4 the system would firstretrieve all the documents hat had at least 4 of the wordscontained in the "concepts" section of the topicdescription.
Once those documents were retrieved theywere ranked by dot product between their documentvectors and the query context vector.
The threshold of 4before it was retrieved.
This threshold, like the absolutethreshold, was swept and it was determined that aconstant hreshold of 3 (4 was slightly better for verylarge corpora) performed the best.4.4.2 Query WeightingAs is the case when generating document context vectors,query context vectors are a weighted sum of each of theindividual query stem vectors.
Again, there were variousexperiments odetermine the best weighting scheme.
Theoriginal approach used the traditional tf*idf weighting (tfbeing the term frequency in the query).
The importance89factor equation was experimented with as well as thevariation of the tf*idf weight, log(tf)*idf, which wasdescribed as giving better performance for other IRsystems (see Buckley, TREC2, Aug 30, 1993).
As wasfound for generating document context vectors, theoriginal approach proved to be the best.4.4.3 Query  Expans ionThe idea of query expansion was experimented withduring TIPSTER Phase I.
Traditional adhoc queryexpansions involved adding words from a thesaurus or apreset knowledge base such as WordNet.
For example ifthe query were "dog" the terms "canine" and "pooch"might be automatically added to the query.
MatchPlus'sapproach was to augment query terms with terms that thesystem had automatically determined were related.
Mostlikely these terms would NOT be simply synonyms but"concepts" that are related or found in similar documents.For example if the query were "NASA" the top 8 relatedterms added to the original query would be: "spaceshuttle, unpiloted, challenger, unmanned, payload,booster, launch, rocket".
This automated query expansionproved to be unsuccessful.
It is apparent that the originalquery term(s) already have, encoded in them, the relatedterms that were used to augment the query.
The vectorfor "NASA" is already "close" to terms such as "spaceshuttle" and "rocket" so documents with only these twoterms and NOT NASA will be retrieved.
This "built in"query expansion is one of the benefits of the vector spacemodel and such things as a thesaurus and WordNet(which have not been successful for query expansion inthe TIPSTER tests) are not necessary.
Future researchneeds to be done with regard to augmenting query termswith their related words.
For example the augmentedterms could be used to broaden and enrich the booleanfilter, or the terms could be selected and de-selected by auser in a feedback situation.4.4.4 Re levance  FeedbackThe use of relevance feedback for adhoc queries provedto be a success.
The experiment consisted of taking thetop 20 documents retrieved for each query and making arelevance judgment.
The context vectors for the relevantdocuments were then added back into the original queryvector and the new query was used to retrieve the rest ofthe documents.
This approach gave a 3 % to 5 % increasein performance over our baseline scores.4.4.5 Vector  On ly  QueryAn extremely encouraging experiment involved using acontext vector query with NO boolean filter.
The entiretopic (excluding the domain and definitions ections) wasused in creating this automatic adhoc query.
As reportedin the tipster 24 month proceedings the context vectorquery with no boolean matching only performed 3 %worse for relevant documents and 8 % on precision.
Thecomparison is with a similarly formed query but with theadditional requirement that documents with at least 4 ofthe terms in the "concept" section of the topic be presentin the document for it to be retrieved.
This resultindicates that good retrieval performance can be obtainedusing only the context vector approach.
No invertedindex (used in calculating boolean "hits") is necessary,greatly reducing the system build time and the systemstorage requirements.4.5 Rout ing  Exper imentsThe vector space model lends itself very nicely toconventional neural network training algorithms.
One ofthose algorithms, the single cell perceptron learning,proved to be very useful in the routing environment.There were two approaches experimented with using theperceptron algorithm.
The first, the "stem weighting"approach calculated weights for each of the query termsfor each topic description.
The input for the network wasthe dot product between each query term and a previouslyjudged document (either elevant or not relevant for thatparticular topic query), and the relevance judgment.
Anexample input is given in Table 13.surrogate mother court case relevanceDoc I .3 .4 .7 .9 0Doc 2 .8 .7 .5 .2 1Table 13, Stem Weighting Input for Perceptron LearningThe output consists of weights for each of the query termswhich are applied when adding up each of the queryterms to form the final query vector.
For the examplegiven in Table 12 one would expect he weight for theterm "case" to be low because it did not play a significantpart in retrieving the relevant document but did contributesignificantly in retrieving the non-relevant document.The second approach that utilizes the perceptron etworkis the "full context vector" method.
The input consists ofa judged document context vector (280 floating pointvalues) and the relevance judgment.
The network returns90with 280 weights that are directly inputted into the querycontext vector.
The stem weighting approach performedbetter than the "full context vector" approach.
This ismost likely due to the fact the "full context vector"approach required many more training examples (i.e.relevance judgments) because it was calculating 280weights while the "stem weighting" was calculating onaverage 25 weights.
Although there were an abundancesof relevance judgments for each topic there were manymore examples of non-relevant documents than relevantdocuments.The idea of combining different types of query runs (fromthe same system as well as from different systems) provedto be very successful.
This idea of "data fusion" wasinspired by the observation that any two TIPSTERretrieval runs came up with for the most part non-intersecting sets of documents.
Using information abouteach retrieval approach's performance (e.g.
"stemweighting" works better than an adhoc query) retrievallists were combined in two different ways.
The first waydetermined the best approach for each topic and used thatapproach to retrieve all the documents for that query.
Forexample, if the context vector only query (no booleanmatching) worked best for topic 51 then that query wasused to retrieve all the documents.
The second approach,which proved to work slightly better, combined ocumentlists for each topic by taking documents from eachretrieval approach (again, based on the accuracy weights)and combining them to create a single list.
For example,the top ranked retrieved ocument from the best approach("stem weighting") would be chosen first, the top rankeddocument for the second best approach would be next,etc.. An experiment using the latter combining methodshowed that by combining the best single retrieval runfrom the University of Massachusetts INQUERY systemwith MatchPlus's best run the single best performance byany single participant in TREC and TIPSTER could beimproved 5 %.5.
EVALUATION SUMMARY5.1 ResultsFor TIPSTER Phase I 24-month evaluation HNCsubmitted 5 adhoc and 5 routing runs.
The results for theadhoc runs which were run on Disks 1 & 2 and usedtopics 101-150 are given in Table 14.Run Relevan Relative Prec.
@ Relativet Docs Perf.
100 Perf.1 7205 0.0 % .4520 0.0 %2 7173 -0.4 % .4748 +5.0 %3 7504 +4.1% .4616 +2.1%4 7202 0.0 % .4464 -1.2 %I5 6926 I -3.9 % .4128 -8.7 %Table 14.
Adhoc Retrieval ResultsThe total number of relevant documents for the adhocwas 11,657.
For each of the topics 101-150, 1000documents were retrieved.
The 5 different run types aredescribed as follows:.
Totally automated, use entire topic with a matchthreshold of 4 terms on the concepts ection (baselinesystem).
The training size was 320 megabytes of text.. Use run 1 for first 20 retrievals, read these documentsand mark relevant ones.
Add context vectors forrelevant documents to original query context vectorand retrieve remaining 980 documents.
The trainingsize was 320 megabytes of text..
Same query type as run 1 but the system uses a largercontext vector size (512 dimensions versus 280dimensions).
The training size was 320 megabytes oftext..
Same as run 3 but a smaller corpus was used for thelearning of the context vectors.
The training size was45 megabytes of text.5.
Context Vector only query (i.e.
No boolean matchfilter).
The training size was 320 megabytes of text.91The routing results which were run on Disk 3 and topics51-100 are given in Table 15.Run \[ Relevan Relative Prec.
@ Relativet Docs Perf.
100 Perf.
!1 5752 0.0 % .4128 0.0 %2 6531 +11.9 % .4748 +13.1%3 5966 +3.6 % .4616 +4.9 %4 6436 +10.6 % .4464 +7.5 %5 5950 +3.3 % .4520 +8.7 %Table 15.
Routing Retrieval ResultsThe total number of relevant documents for the routingwas 10,489.
For each of the topics 51-100, 1000documents were retrieved.
Runs 1,2 and 4 used atechnique called "data fusion".
Multiple query types wereused then the resulting retrieval ists were combined toproduce a single list of documents.
The following werethe query types used for combining (refer to section 4,routing for details of routing techniques):?
Stem weighting (neural network training)?
Full context vector weighting (neural networktraining)?
Adhoc automated query, boolean filter (Runs 1 and 2only)?
Adhoc automated query, context vector only (Run 4only)The 5 different run types are described as follows:1 Stem weighting for entire run.2.
Data fusion 1: combines 4 different types ofretrievals inside each topic.3.
Adhoc query, fully automatic with a match thresholdof 4 terms on the concepts ection.4.
Use same approach as Run 1 but include a contextvector only query as one of the query types.. Data fusion 2: combines 4 different ypes of adhocand routing approaches by topic (i.e.
the same queryapproach is used for retrieving all the documents fora particular topic).5.2 Interpretation of ResultsIncreasing the size of the vector training set improvesperformance.
Adhoc run 3 was trained on 320 megabytesof data while run 4 was trained on 45 megabytes.
Thereis nearly a 5% improvement with the increased amount oftraining data.Increasing the vector size from 280 dimensions to 512dimensions helps performance.
For the larger vector sizeMatchPlus performed 5% better on the number ofrelevant documents and 8% better for precision at I00documents.
The increased imensionality provided moredistinguishability between document context vectors thusfewer non-relevant documents were retrieved.A probabilistic combination of multiple runs givessuperior performance to any single query formationtechnique.
The best combination run (Route run 2) gaveover a 10% improvement for both precision and recallover the best single routing method (Route run 1).For further details regarding "unofficial" results fromnumerous experiments refer to the section on"Experiments and Performance".92
