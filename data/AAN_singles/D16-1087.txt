Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 899?905,Austin, Texas, November 1-5, 2016. c?2016 Association for Computational LinguisticsNamed Entity Recognition for Novel Types by Transfer LearningLizhen Qu1,2, Gabriela Ferraro1,2, Liyuan Zhou1,Weiwei Hou1, Timothy Baldwin1,31 DATA61, Australia2 The Australian National University3 The University of Melbourne{lizhen.qu,gabriela.ferraro,joe.zhou}@data61.csiro.auhouvivid2013@gmail.com, tb@ldwin.netAbstractIn named entity recognition, we often don?thave a large in-domain training corpus or aknowledge base with adequate coverage totrain a model directly.
In this paper, we pro-pose a method where, given training data in arelated domain with similar (but not identical)named entity (NE) types and a small amount ofin-domain training data, we use transfer learn-ing to learn a domain-specific NE model.
Thatis, the novelty in the task setup is that we as-sume not just domain mismatch, but also labelmismatch.1 IntroductionThere are two main approaches to named entity recog-nition (NER): (i) build sequence labelling modelssuch as conditional random fields (CRFs) (Lafferty etal., 2001) on a large manually-labelled training cor-pus (Finkel et al, 2005); and (ii) exploit knowledgebases to recognise mentions of entities in text (Rizzoand Troncy, 2012; Mendes et al, 2011).
For manysocial media-based or security-related applications,however, we cannot assume that we will have ac-cess to either of these.
An alternative is to have asmall amount of in-domain training data and accessto large-scale annotated data in a second domain, andperform transfer learning over both the features andlabel set.
This is the problem setting in this paper.NER of novel named entity (NE) types poses twokey challenges.
First is the issue of sourcing labelledtraining data.
Handcrafted features play a key rolein supervised NER models (Turian et al, 2010), butif we have only limited training amounts of trainingdata, we will be hampered in our ability to reliablylearn feature weights.
Second, the absence of targetNE types in the source domain makes transfer diffi-cult, as we cannot directly apply a model trained overthe source domain to the target domain.
Alvaradoet al (2015) show that even if the NE label set isidentical across domains, large discrepancies in thelabel distribution can lead to poor performance.Despite these difficulties, it is possible to transferknowledge between domains, as related NE typesoften share lexical and context features.
For example,the expressions give lectures and attend tutorials of-ten occur near mentions of NE types PROFESSORand STUDENT.
If only PROFESSOR is observedin the source domain but we can infer that the twoclasses are similar, we can leverage the training datato learn an NER model for STUDENT.
In practice,differences between NE classes are often more sub-tle than this, but if we can infer, for example, thatthe novel NE type STUDENT aligns with NE typesPERSON and UNIVERSITY, we can compose thecontext features of PERSON and UNIVERSITY toinduce a model for STUDENT.In this paper, we propose a transfer learning-basedapproach to NER in novel domains with label mis-match over a source domain.
We first train an NERmodel on a large source domain training corpus, andthen learn the correlation between the source and tar-get NE types.
In the last step, we reuse the modelparameters of the second step to initialise a linear-chain CRF and fine tune it to learn domain-specificpatterns.
We show that our methods achieve up to160% improvement in F-score over a strong baseline,based on only 125 target-domain training sentences.8992 Related workThe main scenario where transfer learning has beenapplied to NER is domain adaptation (Arnold et al,2008; Maynard et al, 2001; Chiticariu et al, 2010),where it is assumed that the label set Y is the samefor both the source and target corpora, and only thedomain varies.
In our case, however, both the domainand the label set differ across datasets.Similar to our work, Kim et al (2015) use transferlearning to deal with NER data sets with differentlabel distributions.
They use canonical correlationanalysis (CCA) to induce label representations, andreduce the problem to one of domain adaptation.
Thissupports two different label mappings: (i) to a coarselabel set by clustering vector representations of theNE types, which are combined with mention-levelpredictions over the target domain to train a targetdomain model; and (ii) between labels based on thek nearest neighbours of each label type, and fromthis transferring a pre-trained model from the sourceto the target domain.
They showed their automaticlabel mapping strategies attain better results thana manual mapping, with the pre-training approachachieving the best results.
Similar conclusions werereached by Yosinski et al (2014), who investigatedthe transferability of features from a deep neural net-work trained over the ImageNet data set.
Sutton andMcCallum (2005) investigated how the target taskaffects the source task, and demonstrated that decod-ing for transfer is better than no transfer, and jointdecoding is better than cascading decoding.Another way of dealing with a lack of annotatedNER data is to use distant supervision by exploitingknowledge bases to recognise mentions of entities(Ling and Weld, 2012; Dong et al, 2015; Yosef etal., 2013; Althobaiti et al, 2015; Yaghoobzadeh andSchu?tze, 2015).
Having a fine-grained entity typol-ogy has been shown to improve other tasks such as re-lation extraction (Ling and Weld, 2012) and questionanswering (Lee et al, 2007).
Nevertheless, for manysocial media-based or security-related applications,we don?t have access to a high-coverage knowledgebase, meaning distant supervision is not appropriate.3 Transfer Learning for NEROur proposed approach TransInit consists of threesteps: (1) we train a linear-chain CRF on a largesource-domain corpus; (2) we learn the correlationbetween source NE types and target NE types usinga two-layer neural network; and (3) we leverage theneural network to train a CRF for target NE types.Given a word sequence x of length L, an NERsystem assigns each word xi a label yi ?
Y , wherethe label space Y includes all observed NE types anda special category O for words without any NE type.Let (x,y) be a sequence of words and their labels.
Alinear-chain CRF takes the form:1ZL?l=1exp(Wff(yl,x) +Wgg(yl?1, yl)), (1)where f(yl,x) is a feature function depending onlyon x, and the feature function g(yl?1, yl) capturesco-occurrence between adjunct labels.
The featurefunctions are weighted by model parameters W, andZ serves as the partition function for normalisation.The source domain model is a linear-chain CRFtrained on a labelled source corpus.
The co-occurrence of target domain labels is easy to learndue to the small number of parameters (|Y |2).
Mostlysuch information is domain specific so that it is un-likely that the co-occurrence of two source typescan be matched to the co-occurrence of the two tar-get types.
However the feature functions f(yl,x)capture valuable information about the textual pat-terns associated with each source NE type.
Withoutg(yl?1, yl), the linear-chain CRF is reduced to a lo-gistic regression (LR) model:?
(y?,xi;Wf ) =exp(Wf.y?f(y?i ,xi))?y?Y exp(Wf.yf(y,xi)).
(2)In order to learn the correlation between sourceand target types, we formulate it as a predictive taskby using the unnormalised probability of source typesto predict the target types.
Due to the simplifica-tion discussed above, we are able to extract a linearlayer from the source domain, which takes the formai = Wsxi, where Ws denotes the parameters off(yl,x) in the source domain model, and each aiis the unnormalised probability for each source NEtype.
Taking ai as input, we employ a multi-class LRclassifier to predict target types, which is essentiallyp(y?|a) = ?
(y?,ai;Wt), where y?
is the observedtype.
From another point of view, the whole architec-ture is a neural network with two linear layers.900We do not add any non-linear layers betweenthese two linear layers because we otherwise endup with saturated activation functions.
An activa-tion function is saturated if its input values are itsmax/min values (Glorot and Bengio, 2010).
Takingtanh(x) as an example, ?tanh(z)?z = 1 ?
tanh2(z).If z is, for example, larger than 2, the correspond-ing derivative is smaller than 0.08.
Assume thatwe have a three-layer neural network where zi de-notes the input of layer i, tanh(z) is the middlelayer, and L(zi?2) is the loss function.
We thenhave ?L(zi?2)?zi?2 = ?L?zi+1 ?
tanh(zi?1)?zi?1?zi?1?zi?2 .
If the tanhlayer is saturated, the gradient propagated to the lay-ers below will be small, and no learning based onback propagation will occur.If no parameter update is required for the bottomlinear layer, we will also not run into the issue ofsaturated activation functions.
However, in our ex-periments, we find that parameter update is neces-sary for the bottom linear layer because of covariateshift (Sugiyama et al, 2007), which is caused by dis-crepancy in the distribution between the source andtarget domains.
If the feature distribution differs be-tween domains, updating parameters is a straightfor-ward approach to adapt the model for new domains.Although the two-layer neural network is capableof recognising target NE types, it has still two draw-backs.
First, unlike a CRF, it doesn?t include a labeltransition matrix.
Second, the two-layer neural net-work has limited capacity if the domain discrepancyis large.
If we rewrite the two-layer architecture in acompact way, we obtain:p(y?|x) = ?(y?,xi;WtWs).
(3)As the equation suggests, if we minimize the negativelog likelihood, the loss function is not convex.
Thus,we could land in a non-optimal local minimum usingonline learning.
The pre-trained parameter matrixWs imposes a special constraint that the computedscores for each target type are a weighted combina-tion of updated source type scores.
If a target typeshares nothing in common with source types, thepre-trained Ws does more harm than good.In the last step, we initialise the model parametersof a linear-chain CRF for f(yl,x) using the modelparameters from the previous step.
Based on thearchitecture of the NN model, we can collapse thetwo linear transformations into one by:Wf = WtWs, (4)while initialising the other parameters of the CRFto zero.
After this transformation, each initialisedparameter vector Wf.y is a weighted linear combina-tion of the updated parameter vectors of the sourcetypes.
Compared to the second step, the loss func-tion we have now is convex because it is exactly alinear-chain CRF.
Our previous steps have providedguided initialization of the parameters by incorpo-rating source domain knowledge.
The model alsohas significantly more freedom to adapt itself to thetarget types.
In other words, collapsing the two ma-trices simplifies the learning task and removes theconstraints imposed by the pre-trained Ws.Because the tokens of the class O are generallyseveral orders of magnitude more frequent than thetokens of the NE types, and also because of covariateshift, we found that the predictions of the NN mod-els are biased towards the class O (i.e.
a non-NE).As a result, the parameters of each NE type will al-ways include or be dominated by the parameters ofO after initialisation.
To ameliorate this effect, werenormalise Wt before applying the transformation,as in Equation (4).
We do not include the parametersof the source class O when we initialise parametersof the NE types, while copying the parameters of thesource class O to the target class O.
In particular, leto be the index of source domain class O.
For eachparameter vector Wti?
of NE type, we set W tio = 0.For the parameter vector for the target class O, weset only the element corresponding to the weight be-tween source type O and target class O to 1, andother elements to 0.Finally, we fine-tune the model over the target do-main by maximising log likelihood.
The trainingobjective is convex, and thus the local optimum isalso the global optimum.
If we fully train the model,we will achieve the same model as if we trained fromscratch over only the target domain.
As the knowl-edge of the source domain is hidden in the initialweights, we want to keep the initial weights as longas they contribute to the predictive task.
Therefore,we apply AdaGrad (Rizzo and Troncy, 2012) withearly stopping based on development data, so thatthe knowledge of the source domain is preserved asmuch as possible.90118 54 125 268 553 1123 4543 18222Training size0.00.20.40.60.81.0F1-MeasureBOWEmbedLabelEmbedCCATransInit(a) Target: I2B2, Source: BBN18 54 125 268 553 1123 4543 18222Training size0.00.20.40.60.81.0F1-MeasureBOWEmbedLabelEmbedCCATransInit(b) Target: I2B2, Source: CoNLL18 54 125 268 553 1123 4543 18222Training size0.00.20.40.60.81.0F1-MeasureBOWEmbedLabelEmbedCCATransInit(c) Target: CADEC, Source: CoNLLFigure 1: Macro-averaged F1 results across all novel classes on different source/target domain combinations4 Experimental Setup4.1 DatasetsWe use CADEC (Karimi et al, 2015) and I2B2(Ben Abacha and Zweigenbaum, 2011) as target cor-pora with the standard training and test splits.
Fromeach training set, we hold out 10% as the devel-opment set.
As source corpora, we adopt CoNLL(Tjong Kim Sang and De Meulder, 2003) and BBN(Weischedel and Brunstein, 2005).In order to test the impact of the target domaintraining data size on results, we split the training setof CADEC and I2B2 into 10 partitions based on a logscale, and created 10 successively larger training setsby merging these partitions from smallest to largest(with the final merge resulting in the full training set).For all methods, we report the macro-averaged F1over only the NE classes that are novel to the targetdomain.4.2 BaselinesWe compare our methods with the following twoin-domain baselines, one cross-domain data-basedmethod, and three cross-domain transfer-basedbenchmark methods.BOW: an in-domain linear-chain CRF with hand-crafted features, from Qu et al (2015).Embed: an in-domain linear-chain CRF with hand-crafted features and pre-trained word embeddings,from Qu et al (2015).LabelEmbed: take the labels in the source and tar-get domains, and determine the alignment based onthe similarity between the pre-trained embeddingsfor each label.CCA: the method of Kim et al (2015), where aone-to-one mapping is generated between source andtarget NE classes using CCA and k-NN (see Sec-tion 2).TransDeepCRF: A three-layer deep CRF.
The bot-tom layer is a linear layer initialised with Ws fromthe source domain-trained CRF.
The middle layer isa hard tanh function (Collobert et al, 2011).
Thetop layer is a linear-chain CRF with all parametersinitialised to zero.TwoLayerCRF: A two-layer CRF.
The bottomlayer is a linear layer initialised with Ws fromthe source domain-trained CRF.
The top layer is alinear-chain CRF with all parameters initialised tozero.We compare our method with one variation, whichis to freeze the parameters of the bottom linear layerand update only the parameters of the LR classifierwhile learning the correlation between the source andtarget types.4.3 Experimental ResultsFigure 1 shows the macro-averaged F1 of noveltypes between our method TransInit and the threebaselines on all target corpora.
The evaluation re-sults on CADEC with BBN as the source corpus arenot reported here because BBN contains all types ofCADEC.
From the figure we can see that TransInitoutperforms all other methods with a wide marginon I2B2.
When CoNLL is taken as the source cor-pus, despite not sharing any NE types with I2B2,several target types are subclasses of source types:DOCTOR and PATIENT w.r.t.
PERSON, and HOS-902PITAL w.r.t.
ORGANIZATION.In order to verify if TransInit is able to capturesemantic relatedness between source and target NEtypes, we inspected the parameter matrix Wt of theLR classifier in the step of learning type correlations.The corresponding elements in Wt indeed receivemuch higher values than the semantically-unrelatedNE type pairs.
When less than 300 target trainingsentences are used, these automatically discoveredpositive correlations directly lead to 10 times higherF1 scores for these types than the baseline Embed,which does not have a transfer learning step.
SinceTransInit is able to transfer the knowledge of multi-ple source types to related target types, this advantageleads to more than 10% improvement in terms of F1score on these types compared with LabelEmbed,given merely 268 training sentences in I2B2.
Wealso observe that, in case of few target training exam-ples, LabelEmbed is more robust than CCA if thecorrelation of types can be inferred from their names.We study the effects of transferring a large num-ber of source types to target types by using BBN,which has 64 types.
Here, the novel types of I2B2w.r.t.
BBN are DOCTOR, PATIENT, HOSPITAL,PHONE, and ID.
For these types, TransInit success-fully recognises PERSON as the most related typeto DOCTOR, as well as CARDINAL as the mostrelated type to ID.
In contrast, CCA often fails toidentify meaningful type alignments, especially forsmall training data sizes.CADEC is definitely the most challenging taskwhen trained on CoNLL, because there is no se-mantic connection between two of the target NEtypes (DRUG and DISEASE) and any of the sourceNE types.
In this case, the baseline LabelEmbedachieves competitive results with TransInit.
Thissuggests that the class names reflect semantic corre-lations between source and target types, and there arenot many shared textual patterns between any pair ofsource and target NE types in the respective datasets.Even with a complex model such as a neural net-work, the transfer of knowledge from the source typesto the target types is not an easy task.
Figure 2 showsthat with a three-layer neural network, the wholemodel performs poorly.
This is due to the fact thatthe hard tanh layer suffers from saturated functionvalues.
We inspected the values of the output hidden18 54 125 268 553 1123 4543 18222Training size0.00.20.40.60.81.0F1-MeasureDeepCRFTwoLayerCRFTransInit_NonUpdateTransInitFigure 2: Difficulty of Transfer.
The source model istrained on BBN.units computed by Wsx on a random sample of tar-get training examples before training on the targetcorpora.
Most values are either highly positive ornegative, which is challenging for online learningalgorithms.
This is due to the fact that these hid-den units are unnormalised probabilities producedby the source domain classifier.
Therefore, remov-ing the hidden non-linear-layer layer leads to a dra-matic performance improvement.
Moreover, Figure 2also shows that further performance improvement isachieved by reducing the two-layer architecture intoa linear chain CRF.
And updating the hidden layersleads to up to 27% higher F1 scores than not updatingthem in the second step of TransInit, which indicatesthat the neural networks need to update lower-levelfeatures to overcome the covariate shift problem.5 ConclusionWe have proposed TransInit, a transfer learning-based method that supports the training of NER mod-els across datasets where there are mismatches indomain and also possibly the label set.
Our methodwas shown to achieve up to 160% improvement inF1 over competitive baselines, based on a handful ofin-domain training instances.AcknowledgmentsThis research was supported by NICTA, funded bythe Australian Government through the Departmentof Communications and the Australian ResearchCouncil through the ICT Centre of Excellence Pro-gram.903ReferencesMaha Althobaiti, Udo Kruschwitz, and Massimo Poesio.2015.
Combining minimally-supervised methods forarabic named entity recognition.
Transactions of theAssociation for Computational Linguistics, 3:243?255.Julio Cesar Salinas Alvarado, Karin Verspoor, and Timo-thy Baldwin.
2015.
Domain adaption of named entityrecognition to support credit risk assessment.
In Aus-tralasian Language Technology Association Workshop2015.Andrew Arnold, Ramesh Nallapati, and W. William Co-hen.
2008.
Exploiting feature hierarchy for transferlearning in named entity recognition.
In Proceedingsof ACL-08: HLT, pages 245?253.Asma Ben Abacha and Pierre Zweigenbaum.
2011.
Med-ical entity recognition: A comparison of semantic andstatistical methods.
In Proceedings of BioNLP 2011Workshop, pages 56?64.Laura Chiticariu, Rajasekar Krishnamurthy, Yunyao Li,Frederick Reiss, and Shivakumar Vaithyanathan.
2010.Domain adaptation of rule-based annotators for named-entity recognition tasks.
In Proceedings of the 2010Conference on Empirical Methods in Natural LanguageProcessing, pages 1002?1012.Ronan Collobert, Jason Weston, Le?on Bottou, MichaelKarlen, Koray Kavukcuoglu, and Pavel Kuksa.
2011.Natural language processing (almost) from scratch.Journal of Machine Learning Research, 12:2493?2537.Li Dong, Furu Wei, Hong Tan, Sun, Ming Zhou, andKe Xu.
2015.
A hybrid neural model for type classi-fication of entity mentions.
In Twenty-Fourth Interna-tional Joint Conference on Artificial Intelligence (IJ-CAI), pages 1243?1249.Jenny Rose Finkel, Trond Grenager, and Christopher Man-ning.
2005.
Incorporating non-local information intoinformation extraction systems by Gibbs sampling.
InProceedings of the 43rd Annual Meeting on Associationfor Computational Linguistics, pages 363?370.Xavier Glorot and Yoshua Bengio.
2010.
Understandingthe difficulty of training deep feedforward neural net-works.
In Proceedings of the Thirteenth InternationalConference on Artificial Intelligence and Statistics (AIS-TATS 2010), pages 249?256.Sarvnaz Karimi, Alejandro Metke-Jimenez, MadonnaKemp, and Chen Wang.
2015.
Cadec: A corpus ofadverse drug event annotations.
Journal of BiomedicalInformatics, 55:73?81.Young-Bum Kim, Karl Stratos, Ruhi Sarikaya, and Min-woo Jeong.
2015.
New transfer learning techniquesfor disparate label sets.
In Proceedings of the 53rdAnnual Meeting of the Association for ComputationalLinguistics and the 7th International Joint Conferenceon Natural Language Processing of the Asian Feder-ation of Natural Language Processing, (ACL 2015),pages 473?482.John Lafferty, Andrew McCallum, and Fernando Pereira.2001.
Conditional random fields: Probabilistic modelsfor segmenting and labeling sequence data.
In Proceed-ings of the 18th International Conference on MachineLearning, pages 282?289.Changki Lee, Yi-Gyu Hwang, and Myung-Gil Jang.
2007.Fine-grained named entity recognition and relation ex-traction for question answering.
In Proceedings of the30th Annual International ACM SIGIR Conference onResearch and Development in Information Retrieval,pages 799?800.Xiao Ling and Daniel S. Weld.
2012.
Fine-grained entityrecognition.
In Proceedings of the 26th AAAI Confer-ence on Artificial Intelligence.Diana Maynard, Valentin Tablan, Cristian Ursu, HamishCunningham, and Yorick Wilks.
2001.
Named en-tity recognition from diverse text types.
In RecentAdvances in Natural Language Processing 2001 Con-ference.Pablo N Mendes, Max Jakob, Andre?s Garc?
?a-Silva, andChristian Bizer.
2011.
DBpedia spotlight: sheddinglight on the web of documents.
In Proceedings ofthe 7th International Conference on Semantic Systems,pages 1?8.Lizhen Qu, Gabriela Ferraro, Liyuan Zhou, Weiwei Hou,Nathan Schneider, and Timothy Baldwin.
2015.
Bigdata small data, in domain out-of domain, known wordunknown word: The impact of word representationson sequence labelling tasks.
In Proceedings of the19th Conference on Computational Natural LanguageLearning (CoNLL 2015), pages 83?93.Giuseppe Rizzo and Raphae?l Troncy.
2012.
NERD: aframework for unifying named entity recognition anddisambiguation extraction tools.
In Proceedings of theDemonstrations at the 13th Conference of the Euro-pean Chapter of the Association for ComputationalLinguistics, pages 73?76.Masashi Sugiyama, Matthias Krauledat, and Klaus-RobertMu?ller.
2007.
Covariate shift adaptation by importanceweighted cross validation.
Journal of Machine Learn-ing Research, 8:985?1005.Charles Sutton and Andrew McCallum.
2005.
Composi-tion of conditional random fields for transfer learning.In Proceedings of the Conference on Human LanguageTechnology and Empirical Methods in Natural Lan-guage Processing, HLT ?05, pages 748?754.Erik F. Tjong Kim Sang and Fien De Meulder.
2003.
In-troduction to the CoNLL-2003 shared task: Language-independent named entity recognition.
In Proceedingsof CoNLL-2003, pages 142?147.904Joseph Turian, Lev Ratinov, and Yoshua Bengio.
2010.Word representations: a simple and general method forsemi-supervised learning.
In Proceedings of the 48thannual meeting of the association for computationallinguistics, pages 384?394.Ralph Weischedel and Ada Brunstein.
2005.
BBN pro-noun coreference and entity type corpus.
LinguisticData Consortium.Yadollah Yaghoobzadeh and Hinrich Schu?tze.
2015.Corpus-level fine-grained entity typing using contextualinformation.
In Proceedings of the 2015 Conferenceon Empirical Methods in Natural Language Processing(EMNLP 2015), pages 715?725.Mohamed Amir Yosef, Sandro Bauer, Johannes Hoffart,Marc Spaniol, and Gerhard Weikum.
2013.
HYENA-live: Fine-grained online entity type classification fromnatural-language text.
In Proceedings of the 51st An-nual Meeting of the Association for Computational Lin-guistics: System Demonstrations, pages 133?138.Jason Yosinski, Jeff Clune, Yoshua Bengio, and Hod Lip-son.
2014.
How transferable are features in deep neuralnetworks?
In Advances in Neural Information Process-ing Systems 27, pages 3320?3328.905
