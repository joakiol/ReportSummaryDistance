Language Technology for Closely Related Languages and Language Variants (LT4CloseLang), pages 36?46,October 29, 2014, Doha, Qatar.c?2014 Association for Computational LinguisticsExploiting Language Variants Via Grammar Parsing HavingMorphologically Rich InformationQaiser AbbasFachbereich SprachwissenschaftUniversit?at Konstanz78457 Konstanz, Germanyqaiser.abbas@uni-konstanz.deAbstractIn this paper, the development and evalua-tion of the Urdu parser is presented alongwith the comparison of existing resourcesfor the language variants Urdu/Hindi.
Thisparser was given a linguistically richgrammar extracted from a treebank.
Thiscontext free grammar with sufficient en-coded information is comparable with thestate of the art parsing requirements formorphologically rich and closely relatedlanguage variants Urdu/Hindi.
The ex-tended parsing model and the linguisti-cally rich grammar together provide uspromising parsing results for both the lan-guage variants.
The parser gives 87% off-score, which outperforms the multi-pathshift-reduce parser for Urdu and a simpleHindi dependency parser with 4.8% and22% increase in recall, respectively.1 IntroductionAn Urdu invariant of Hindavi came into existenceduring the muslim rule from 1206 AD to 1858AD (Khan, 2006).
They used Persian/Urdu scriptfor Urdu in contrast to the Devanagari script forHindavi.
The informal versions of the two lan-guage variants are quite similar, in fact so sim-ilar that they can really be called dialects of asame language.
Loose examples would be how aSpanish speaker could comprehend Portuguese orSwedish speaker could comprehend Norwegian.However the formal version of the two languageswill be much more different as Urdu vocabulary isinfluenced heavily from Persian, Arabic and Turk-ish whilst the emphasis in Hindi is on Sanskrit.Urdu became a literary language after existence ofan increasing number of literature during the 18thand the 19th century (McLane, 1970).
Urdu/Hindiis the national language of Pakistan and an officiallanguage in India.
According to a report by theSIL Ethnologue (Lewis, 2013), Urdu/Hindi has456.2 million speakers in the whole world.Getting state of the art parsing results for mor-phologically rich languages (MRLs) is a challengeto date.
According to Tsarfaty et al.
(2010; 2013),without proper handling of morphological entitiesin the sentences, promising results for MRLs cannot be achieved.
Complex morphosyntactic in-teractions may impose constraints, which lead toexplicit encoding of such information.
The bestbroad coverage and robust parsers to date havegrammars extracted from treebanks and the depthof information encoded in an annotation corre-lates with the parsing performance (Tsarfaty et al.,2013).To fulfill the encoding of information in anannotation, a treebank for Urdu known as theURDU.KON-TB treebank with sufficient encodedinformation at morphological, POS, syntactic andfunctional level was constructed (Abbas, 2012).Its annotation was found reliable according to theKrippendorffs ?
values achieved in (Abbas, 2014)but its reliability or the suitability for machinelearning (ML) can be evaluated with the develop-ment of an Urdu parser presented in Section 3.
Acontext free grammar (CFG) is extracted from theURDU.KON-TB treebank computationally.
Thedevelopment procedure and the depth of encodedinformation in the grammar is presented in Section2.
The grammar is then given to an extended dy-namic programming parsing model known as theEarley parsing algorithm (Earley, 1970).
The ex-tended parsing model for Urdu is then called asthe Urdu parser and given in Section 3.
This al-gorithm is language independent and is capableto parse the MRLs like the CKY (Cocke-Kasami-Younger) parsing algorithm as advocated in (Tsar-faty et al., 2013) and (Abbas et al., 2009).
Issuesfaced during the parsing are discussed in Section4.
By applying a rich grammar along with the ex-36tended parsing model, promising results obtainedare discussed in Section 5.
Conclusions along withthe future directions are presented in Section 6.Similarly, the related work of language variants isdescribed in Section 1.1, which set a path towardsthe construction of the Urdu parser.1.1 Related WorkIn the Urdu ParGram project (Butt and King,2007), the XLE1parser is in use.
The encodingof LFG grammar in XLE interface is not a sim-ple task.
Such a grammar can be encoded onlyby those persons who have expertise in theoreti-cal linguistics as well.
The team of the ParGramproject has made a tremendous effort in this re-gard.
This project of Urdu LFG grammar develop-ment is still in progress and the parser evaluationresults are not available yet.
Similarly, the parserfor evaluation of the NU-FAST treebank (Abbaset al., 2009) used a built in utility available in theinference engine of the Prolog to parse the Urdusentences.
This utility can only be used if youhave a definite clause grammar (DCG) or proba-bilistic definite clause grammar (PDCG).
In thiswork, a parser was not designed but a built-in pro-log parser was used, due to which it was not con-sidered to be the candidate for comparison.A simple dependency parser for Hindi was de-veloped by Bharati et al.
(2009).
The parser useda grammar oriented approach, which was designedon the basis of Paninian grammatical model (Be-gum et al., 2008; Bharati et al., 1995).
The annota-tion scheme was designed on the basis of chunks,intra-chunks and karakas2.
This scheme (Be-gum et al., 2008) of dependency structure (DS)is different from the annotation scheme (Abbas,2012; Abbas, 2014) of phrase structure (PS) andthe hyper dependency structure (HDS) of theURDU.KON-TB treebank along with the differentdata sets used.
As compared to phrase/constituentstructure, the dependency structure lacks in infor-mation at non-terminal nodes (Bharati et al., 2008)and often the information at POS level.
This infor-mation can also be provided at dependency anno-tation but people are stick to the standard norms.The Hindi treebank is rich in functional informa-tion as compared to morphological, POS and syn-tactical information.
Due to differences in the de-1http://www2.parc.com/isl/groups/nltt/xle/2Karakas are the syntactico-semantic relations betweenthe verbs and other related constituents in a sentence (Bharatiet al., 1996)signs of the simple dependency parser for Hindiand the Urdu parser, only performance results arecompared and presented in Section 5.Ali and Hussain used the MaltParser with its de-fault settings in Urdu dependency parser (Ali andHussain, 2010).
When somebody performs ex-periments with MaltParser with its default settingsthen such evaluation results are advised not to becompared according to MaltParser license.3Thesame exercise for parsing Hindi was performedin (Agrawal et al., 2013), but it was clearly men-tioned in the work that MaltParser was used forerror detection in the annotation of Hindi/Urdutreebank (HUTB).4Similarly, the Urdu sentenceswere parsed in (Bhat et al., 2012b) using the sameMaltParser.
The experiments were performed toidentify the parsing issues of Urdu and a devel-opment of parser was not claimed.
Moreover,these data-driven systems are highly criticized ona given set of annotated corpus because they arenot able to observe all morphological variants of aword form from it (Tsarfaty et al., 2013).A multi-path shift-reduce parsing algorithm wasproposed in (Jiang et al., 2009) for Chinese.
Lateron, this algorithm was used for Urdu parsing byMukhtar et al.
(2012b).
A probabilistic contextfree grammar (PCFG) developed in (Mukhtar etal., 2011) was given to the multi-path shift-reduceUrdu parsing model.
A multi-path shift-reduceparser for Urdu has some limitations.
It takes aPOS tagged sentence as input and is not able toparse sentences without the POS tagging.
Thestack used has a fixed memory size, which is notreliable and it can overflow during the parsingof long sentences.
A PCFG used in this parsingmodel is ambiguous (Mukhtar et al., 2012a).
Boththe fixed memory size and the ambiguous gram-mar can resist the parsing of long sentences,thatswhy the parser could not parse the sentenceswith length more than 10 words (Mukhtar et al.,2012b).
In this work, the results were not evalu-ated properly by using some measure e.g.
PAR-SEVAL.
A number of 74 sentences having lengthnot more than 10 words were parsed successfullyfrom 100 sentences, which were then quoted as a74% of accuracy.
The raw corpus used in the de-velopment of this parser is partially the same ascompared to the Urdu parser (Section 3).
A com-parative study made is detailed in Section 5.3http://www.maltparser.org/4http://faculty.washington.edu/fxia/treebank/37Figure 1: A verb V example from the URDU.KON-TB treebank2 SetupThe URDU.KON-TB treebank having phrasestructure (PS) and the hyper dependency struc-ture (HDS) annotation with rich encoded informa-tion (Abbas, 2012; Abbas, 2014) is used for thetraining of the Urdu parser discussed in Section 3.The treebank has a semi-semantic POS (SSP) tagset, a semi-semantic syntactic (SSS) tag set and afunctional (F) tag set.
The morphological infor-mation in the labeling of the parsers lexicon canbe explained by discussing the POS tag set of theURDU.KON-TB treebank.The SSP tag set hierarchy has 22 main tag cate-gories which are divided into sub-categories basedon morphology and semantics.
In Figure 1, an ex-ample of only a verb V is given.
A dot ?.?
symbolis used for the representation of morphology andsemantics at POS level.
In Figure 1, the hierarchyof tag labels for verb V is divided into three lev-els of depth.
The first level contains only one la-bel to distinguish a verb V from other POS labels.The second level contains 11 subcategories of Vto represent different morphological or functionalforms e.g.
V.COP (V as a copula verb (Abbas andRaza, 2014)), V.IMPERF (V has an imperfectiveform (Butt and Rizvi, 2010; Butt and Ramchand,2001)), V.INF (V has an infinitive form (Butt,1993; Abbas and Nabi Khan, 2009)), etc.
Thethird level contains further 25 subcategories to rep-resent the morphological information in depth e.g.V.COP.IMPERF (copula verb has an imperfectiveform), V.COP.PERF (copula verb has a perfectiveform), V.COP.ROOT (copula verb has a ROOTform), V.COP.PAST (copula verb has a past tense),V.LIGHT.PAST (light verb has a past tense (Buttand Rizvi, 2010; Butt, 2003)), etc.
These types ofcombinations are also possible in case of an auxil-iary verb as described in (Abbas, 2014).
This shortdiscussion is about the idea of morphological andfunctional information encoded at POS level.
Thislexical information can be passed up to the syn-tactical level because the lexical items have somerelationship with other lexical items in a sentence.The detail of syntactic (SSS) and functional (F) tagsets can be seen in (Abbas, 2012).A stack based extraction Algorithm 1 was de-signed to extract a context free grammar (CFG)from the URDU.KON-TB treebank.
The CFG ob-tained is then given to the Urdu parser (Section 3)for sentence parsing.3 Urdu ParserThe URDU.KON-TB treebank is a manually an-notated set of 1400 parsed sentences, which werethen recorded in a text file on a computer in theform of 1400 bracketed sentences.
Initial twentybracketed-sentences from each hundred were sep-arated in another text file, whose total 280 sen-tences were then used for the development of atest suite.
The test suite was further divided intotwo halves representing test data and held out dataresulting in 140 sentences in each half.The held out data was used in the developmentof the Urdu parser, while the test data was used forthe evaluation of results after the completion of theUrdu parser.
From the first residual text file with1120 bracketed sentences, a context free grammar(CFG) was extracted using a stack based extrac-tion module given in Algorithm 1.
The CFG wasthen processed by the Urdu parser to produce agrammar database with unique productions.
Dur-ing this process, production type (TYPE) labeling38as lexical (L) and non-lexical (NL) at the end ofeach production was done.
The productions hav-ing only the lexical items at their right hand side(RHS) were labelled as L and the productions con-taining non-lexical items on their RHS only werelabelled as NL.
The purpose of this labeling is toprovide an already processed mechanism, throughwhich the Urdu parser can identify a productiontype L or NL speedily without checking it thor-oughly.Algorithm 1 A CFG extraction algorithmInput: A input and an empty output file1: (Sentence, Top, Counter)?
02: Read: InputString3: while InputString 6= Input.EOF () do .
Loop until end of file4: if InputString = $ then5: Print: + + Sentence6: Read: InputString .
Read a string from an input file7: Write: \n \n .
Writing two newlines in output file8: (Stack[0], StrArray[0])?
?
.
Initializing stack and array9: (Top, Counter)?
0 .
Initializing stack and array variables10: end if11: if InputString 6= ?)?
then12: Stack[Top]?
InputString;Top++13: else .
When ?)?
comes14: Top?
?15: while Stack[Top] 6= ?(?
do16: StrArray[Counter] = Stack[Top]17: Stack[Top] = ?
; Counter ++; Top?
?18: end while19: Counter ?
?20: Stack[Top] = StrArray[Counter]21: Top++ and Check = Counter22: while Counter ?
0 do23: if Counter = Check then24: Write: StrArray[Counter] ?
;StrArray[Counter] = ?25: else26: Write: StrArray[Counter] + ??
;StrArray[Counter] = ?27: end if28: Counter ?
?29: end while30: Write: \n; Counter = 0 .
In output file31: end if32: Read: InputString .
Read a string from an input file33: end whileOutput: An output file having complete CFG productions for each sentenceWithout handling the issues discussed in Sec-tion 4, the Earley?s algorithm simply was notable to provide the state of the art evaluation re-sults for Urdu.
These issues caused the pars-ing discontinuities, due to which extensions aremade on the basic algorithm.
The extended ver-sion of the Urdu parser is depicted in Algorithm2.
The grammar database of the Urdu parserhas three fields in the form of a left hand side(LHS), a RHS and a TYPE.
After taking a sen-tence as input, variables are initialized along witha starting value of the chart as ROOT @ S. Inplace of a dot symbol ???
used in the Earley al-gorithm, here an ?@?
symbol is used becausethe dot symbol is extensively used in the hier-archal annotation of the URDU.KON-TB tree-bank, from which the grammar productions areextracted.
The working of the algorithm is simi-lar to the Earley?s algorithm except the modifica-tions in the PREDICTOR(), SCANNER() anda COMPLETER() presented in Sections 4.1, 4.2and 4.7, respectively.
Besides these some addi-tional functions are introduced like an EDITOR()for an automatic editing of discontinuous parses,a BUILDER() for building the parse trees anda BACKPOINTER() for calculating the back-pointers.Algorithm 2 Urdu Parser1: function URDU-PARSER(grammar)2: Input: Sentence .
reading a sentence3: (id, fi, fj, fid)?
04: chart[0].add(?id?, ?ROOT @ S?, ?0,0?, ?
?, ?Seed?
)5: for i?
0 to LENGTH(sentence[]) do6: scannerF lag ?
false, id?
17: Print: chart[i] ?
(StateId, Rule, @Position, BackPointer, Op-eration)8: for j ?
0 to ChartSize[i] do .
Loop for chart entries9: currentRule?
chart[i].getRule(j).split(?
?
)10: (tempString, index) ?
(string-after-@, @Position) incurrentRule11: if tempString = ?
?
then12: call COMPLETER() .
calling completer procedure13: else14: rs?
All grammar rules with LHS = tempString15: if rs.next() 6= false then .
checking rs is not empty16: call PREDICTOR() .
calling predictor procedure17: else18: call SCANNER()19: end if20: end if21: if scannerF lag=false & j+1=chartSize[i] &i 6=LENGTH(sentence[]) then22: call EDITOR()23: end if24: end for25: end for26: call BUILDER()27: end functionDuring processing ofCOMPLETER(), PREDICTOR() andSCANNER(), some sort of parsing disconti-nuities can happen.
To check these types ofphenomena, an EDITOR() will come into an ac-tion and it will remove all the faulty states and thecharts causing discontinuity up to a right choice ofparsing as discussed in Section 4.6.
At the end ofexternal loop, the generated parsed-solutions havebeen stored in the form of the charts with entries,but not in the form of parsed trees.
To representparsed solutions in the form of bracketed parsedtrees, a BUILDER() function will be executed,which will construct the parsed trees of solutionsby manipulating the back-pointers calculated inthe COMPLETER() function.
The BUILDER()is able to display all parsed solutions of a givensentence as discussed in Section 4.4 and then theAlgorithm 2 for the Urdu parser is exited withthe complete generation of charts and bracketedparsed trees.
The algorithms called by the Urdu39parser are discussed briefly in Section 4 alongwith their issues.4 Issues Analysis and Their EvaluationThrough Extensions4.1 Eliminating L Type Useless PredictionsEarley?s Predictor() adds useless productions incharts which causes the Urdu parser to end up witha discontinuous parse for a given sentence.
Sup-pose, the current token to be parsed in an inputsentence is a proper noun?Ag ?Khan?
and there isa NL type production NP?
@ N.PROP N.PROPresiding in the current chart of the parser, whereN.PROP is the tag for proper noun.
The ?
@?symbol before a non-terminal on the RHS of theproduction is the case of predictor and the non-extended PREDICTOR() adds all the available Ltype productions of N.PROP into the chart fromthe grammar, even they are not required.
Onlythe relevant production N.PROP ?
@?Ag hasto be added in the chart.
This addition of irrele-vant/useless productions is also true for other lex-ical items e.g.
adjectives, personal pronouns, casemarkers, etc.
These useless additions cause thewastage of time and increase the chance of mis-leading direction towards a discontinuous parse.To resolve this issue, the PREDICTOR() of theexisting Earley?s Algorithm is modified in theUrdu parser as follows.When the main parsing Algorithm 2 calls theextended PREDICTOR() then it checks the typeof production either as NL or L in contrast of theEarley algorithm.
The handling of NL type pro-ductions is same but in dealing of L type of pro-ductions, the PREDICTOR() is introduced withanother condition, which enforces the predictor toadd only the relevant productions into the respec-tive charts.
It matches the token at the RHS ofthe predicted-production with the current token inan input sentence.
This condition eliminates thelimited possibility of misleading direction towardsthe discontinuous state.
The wastage-time factoris reduced to O(n) after the removal of irrelevantmatching, where n is the number of tokens in aninput sentence.4.2 Irrelevant POS SelectionIn the Earley?s parsing algorithm, theScanner() only matches the RHS of theL type production with the current token in agiven sentence and causes a selection of L typeproduction with the wrong POS.
For example, theverb ??f?is?
has different tags in the grammar.
Itcan act as an auxiliary in a sentence with presenttense e.g.
VAUX.PRES ?
??f.
It can behave asa copula verb e.g.
V.COP.PRES ?
?
?fand it canalso act as a main verb e.g.
V.PRES ?
??f.
Thisconcept of having more than one tag is true forother lexical items.
So, if this L type productionVAUX.PRES?
@ ?
?fis existed in a current chartas right candidate then the Scanner() of theEarley algorithm can select other available pro-ductions from the grammar due to a check on theRHS only.
This can cause the wrong solution or adiscontinuous state during the parsing.
To removethis issue, the Scanner() is extended in thesame way as was done with the PREDICTOR()in Section 4.1.
At this level, this solution solvesthe issue described below, but it is completed inSection 4.6.When the SCANNER() is called, it extracts arelevant L type production from the grammar af-ter matching the LHS and the RHS completely.
Itadds only the true L type production in a new chartafter checking three additional conditions.
At first,it checks that the chart number is not exceeding thelength of a sentence.
At second, it checks that thetoken in the current processing L type productionis equal to the current token in a given sentence.After that if the scannerFlag is false, then thenew entry of the matched L type production isadded into the new chart.
During this process, thescannerFlag is set to a true value along witha record of some variables fi, fj, and fid,which will be used in the EDITOR() discussedin Section 4.6.
By introducing this modification,the possibility of wrong selection of the produc-tion from the grammar is abandoned.
An issuerelated to this problem is still remained, which isaddressed and resolved in Section 4.6.4.3 Back-Pointers CalculationEarley parsing algorithm is a generator or a rec-ognizer and hence can not produce the parse treesor the bracketed trees.
To produce the parse treesor the bracketed trees, an unimplemented idea ofback-pointers by Earley (1968) is implementedand presented in Algorithm 3.
To understand thecalculation of the back pointers, a sentence givenin example 1 is parsed from the Urdu parser.
Thecharts generated through the Urdu parser are de-picted in Figure 2.
Only the relevant states are dis-40played as can be inferred from the non-sequentialvalues of the STATEID column.
The columnDOT-POSITION is basically the position of ?
@?in productions.Algorithm 3 Back Pointer1: function BACKPOINTER(previousRule, dummy@Position, i, chartSize, chart)2: backPointer ?
?
?3: tempIndex?
previousRule.indexOf(?@?
)4: tempIndex?
tempIndex-1 .
subtracting index5: NT ?
previousRule.get(tempIndex)6: k ?
dummy@Position[0]7: for l?
i to k step -1 do .
loop for backward backpointers8: if tempIndex > 0 then9: for m?
0 to chartSize[l]-1 do10: pString ?
chart[l].getRule(m).split(?
?
)11: cRule.add(pString[]) .
store pString in cRule12: tIndex?
cRule.indexOf(?@?
)13: if (NT = cRule[0]) & (tIndex+1 = SIZE(cRule)) then14: backPointer ?
(l + ?-?
+chart[l].getStateId(m) +?
?+backPointer)15: dummy@P = chart[l].get@Position(m).split(?,?).
getting ?@?
position16: l?
dummy@P [0] .
updating loop counter l17: l?
l + 118: tempIndex?
tempIndex-119: NT ?
previousRule[tempIndex]20: break21: else22: cRule.clear()23: end if24: end for25: else26: break27: end if28: end for29: end function(1) ??f?P?Q??
?A?fE??
?K.Q?X A??
@untheir/P.PERSkAof/CMzikrreference/NbHIalso/PT.INTFyahANhere/ADV.SPTzarUrIessential/ADJ.MNRhEis/V.COP.PRES?Their reference is also essential here?The COMPLETER() calls the Algorithm 3 ofBACKPOINTER() to calculate the values of theback-pointers.
For example, during the process-ing of a production KP.POSS P.PERS @ CMat STATEID 3 in chart 1 of Figure 2, a pro-cessed non-terminal P.PERS before the ?@?
inthe RHS of the production is located in thechart 1 at 0thposition.
The located ?1-0?
valueof the backPointer is then displayed by theCOMPLETER() in the same state of the chart.The rest of the back pointers are calculated in thesame way.
These back-pointers are further usedin building the bracketed parse trees discussed inSections 4.4 and 4.7.4.4 Building Bracketed Parse TreesThe possible bracketed parse trees are evaluatedand displayed by the BUILDER() function dis-played in Algorithm 4.
Both the BUILDER() andAlgorithm 4 Builder1: function BUILDER(Sentence[], chartSize[], chart[])2: num=0, chartN = LENGTH(Sentence[])3: for count ?
chartSize[LENGTH(Sentence[]]-1 to 0 step -1do4: dummystr ??S?
and rule ?chart[chartN ].getRule(count).split(?
?
)5: if rule[0] = dummystr then6: num = num+ 17: bp.add(chartN+?-?+chart[chartN ].getStateId(count))8: end if9: end for10: tree[]?
new BTree[num]11: for i?
0 to SIZE(bp)-1 do12: tree[i].build(bp.get(i), chart) .
building tree with pointers13: end for14: for i?0 to SIZE(bp)-1 do15: tree[i].prepare(chart)16: end for17: for i?0 to SIZE(bp)-1 do .
loop for displaying all parsed trees18: bracketedSentenceLength ?
tree[i].getSize() andleft?
019: if bracketedSentenceLength > 0 then20: Print : Bracketed Parse Tree ?+(i+1)+?
of ?+SIZE(bp)+?21: for j ?0 to bracketedSentenceLength-1 do22: if tree[i].getString(j) = ?(?
then23: left = left+ 1 and Print : newline24: for tab?0 to left-1 do25: Print : eight spaces26: end for27: Print : tree[i].getString(j)28: else if tree[i].getString(j) = ?)?
then29: left = left?
1 and Print : tree[i].getString(j)30: else31: Print : space+tree[i].getString(j)+space32: end if33: end for34: end if35: end for36: end functionthe BACKPOINTER() contribute to shift our Al-gorithm 2 from a generator to a parser in contrastof the Earley?s algorithm.
After displaying chartentries in Figure 2 for a sentence given in exam-ple 1, the Urdu parser calls the BUILDER().
Atfirst, it locates all the solution productions fromthe last chart and stores their back-pointers in alist e.g.
?8-1?
value for the solution productionROOT S @ in the last chart of Figure 2.
A userdefined method build() is called then.
Thismethod builds an unformatted intermediate brack-eted parse tree with the interlinked back-pointersfrom the chart states and reveals the leaf nodesonly as ( 8-1 ( 4-1 ( 2-2 ( 1-0?
@ ) ( 2-0 A? )
) ( 3-0 Q?X )( 4-0 ???K.)
) ( 5-1 ( 5-0 ?A?fE) ) ( 6-1 ( 6-0 ?P?Q?? )
) ( 7-1( 7-0 ?
?f) ) ( 8-0 . )
).
This intermediate parse tree canbe understood well by looking at the given back-pointers in the respective chart states.Another user defined method prepare() pre-pares the intermediate parse tree into a com-plete unformatted parse tree as ( S ( NP.NOM-SUB( KP.POSS ( P.PERS?
@ ) ( CM A? )
) ( N Q?X ) ( PT.INTF ???K.)
) ( ADVP-SPT-MODF ( ADV.SPT ?A?fE) ) ( ADJP-MNR-41Figure 2: A back-pointer calculation example of the Urdu parserPLINK ( ADJ.MNR ?P?Q?? )
) ( VCMAIN ( V.COP.PRES?
?f) ) ( M.S . )
) .
This prepare() method only re-places the back-pointers with the LHS of the rele-vant productions.
Finally, the bracketed parse treeis displayed in a formatted way as depicted in Fig-ure 3.Figure 3: An output of the BUILDER() method4.5 Empty ProductionsEmpty productions are divided into two cate-gories.
The first one is related to diacritic produc-tions and the second one is related to non-diacriticproductions.
It can cause the discontinuity duringthe parsing because the lexical item may or maynot present for both the categories in a given sen-tence.
Only the first category of diacritic produc-tions is discussed here to provide an idea about theissues related to empty productions.In modern Urdu, the diacritics may or may notappear in the text e.g.HAJk H.@ AbE h2ayAt ?Thewater of life?
andAJ.KQ?K taqrIban ?almost?.
Thefirst example is related to compound words andthe second one is an independent word.
The zErE-Iz3Afat (a diacritic for addition) under the last let-ter H.b of the first word in the first example isstill in use in the modern Urdu writing.
Similaris the case of tanwin (a diacritic for final post-nasalization) on the last letter@ a in the secondexample.
There are also other diacritics in use aswell e.g.
zEr, zabar, pEsh, taSdId, etc.In the grammar of the Urdu parser, a DIAtag is used to represent the diacritics e.g.
DIA?
*, where ?*?
represents the absence of a di-acritic or an empty production.
During parsing,a compound word may or may not appear witha diacritic e.g.???Q?fD?
Sehr makkah ?The city of42Makkah?.
This example has two words Q?fD?
Sehr?city?
and the ???
makkah ?Makkah?, but the dia-critic is absent between the two words.
In suchcases, its presence is by default understood by thenative speakers.
The production extracted fromthe grammar to handle this compound word isthe NP-SPT ?
@ N.SPT DIA N.PROP.SPT.
Af-ter processing of the first word Sehr/N.SPT bythe SCANNER(), the production becomes NP-SPT ?
N.SPT @ DIA N.PROP.SPT.
Now, thePREDICTOR() deals this DIA empty produc-tion implicitly by moving the ?@?
ahead andadds the updated production NP-SPT ?
N.SPTDIA @ N.PROP.SPT in the same chart.
Sim-ilarly, the second word makkah/N.PROP.SPT isprocessed by the SCANNER() and the productionfinal state becomes like this NP-SPT ?
N.SPTDIA N.PROP.SPT @.
The problem with this so-lution adopted from (Aycock and Horspool, 2002)is that it performs the transaction silently with thecompound words and also with the non-compoundwords at such positions where it is not needed.
Forexample, If this is the case as discussed then thesolution is perfect, but in the case of the non com-pound words, if two independent words Q??
gHar?The house?
and ???
makkah ?Makkah?
appear inthe same position like compound words e.g.
??f?????
Q??
gHar makkah mEN hE ?The house is inMakkah?, then this solution can not identify thecontext and it applies the transaction in the sameway due to the same POS tagging of gHar and theSehr.
This solution causes frequent discontinuityduring the parsing and its property of self deci-sion at the irrelevant places makes the things moreworse.Due to high frequency of the DIA produc-tions in the grammar, the proposed solution (Ay-cock and Horspool, 2002) was implemented inthe PREDICTOR() but the results found were notpromising.
So, an explicit method to represent theabsent value has been chosen, through which anasterisk ?*?
is usually typed in a given sentence torepresent the absence of the diacritics, arguments,lexical items, etc.
At present, due to this explicitapproach, the Urdu parser is jelling with the gram-mar without any issue related to empty produc-tions.4.6 Lexical Dynamic BehaviorThe issue is related to a class of words whichhas the following attributes like the homonym,homograph, homophone, heteronym and the pol-ysemes.
A strict definition is considered to theseattributes, that means at least the words have thesame spelling.
The case of homonym words in astrict sense is discussed here and the same conceptis applicable on other attributes as well.For example, the word ??
kI is a homonym inUrdu.
It can behave in two ways e.g.
a pos-sessive case marker and a verb.
Being a posses-sive case marker, it contains a possessive meaning?of?
in 2.
On the other hand, it contains a mean-ing of ?did?
in 3.
In the grammar, this word hasdifferent POS tags as a case marker (CM), a per-fective verb (V.PERF) and a perfective light verb(V.LIGHT.PERF).
Suppose the word ?kI?
actuallycomes as a V.PERF at the end of a given sen-tence.
For its processing, the Scanner() canpick up the wrong choice with the CM and theV.LIGHT.PERF, if these choices are available inthe current chart at earlier positions as comparedto the right choice.
Due to this wrong selection,the relevant productions of a verb will not be com-pleted in the next chart and the parser will go intothe discontinuous state.
To address this issue, theScanner() of the Earley algorithm is modified,which records the failed state in variables fi, fjand fid.
These failed states are then utilized bythe EDITOR() in Algorithm 5, which is calledby the Urdu parser to heal this discontinuous state.The failed chart and the states are deleted first.
Af-ter skipping the wrong choice e.g.
the CM?
??
ina chart, the next choice from available homonymsis selected and tried to parse.
In this way, the nextchoice V.PERF ?
??
is located and the ithandjthloop variables of the Urdu parser are set to thatchoice for further processing.
Continuing in thisway, the parser finally gets a direction towards theoptimal solution.Algorithm 5 Editor1: function EDITOR(i, id, fi, fj, fid, chart, chartSize)2: Drop and re-initialize chart[i+ 1]3: for z ?
i to fi+1 step -1 do4: Drop and re-initialize chart[z]5: end for6: rule?
chart[fi].getRule(fj).split(?
?)
.
splitting rule with space7: for z ?
0 to chartSize[fi]-1 do8: temprule?
chart[fi].getRule(z).split(?
?
)9: if temprule[2] = rule[2] then10: if !
(temprule[0] = rule[0]) then11: j ?
z ?
1, i?
fi, id?
z12: break13: end if14: end if15: end for16: end function(2) H.AJ?
??
AJ?
?k.43jUlIA=kIJulia.Fem.Sg=PosskitAbbook.Fem.Sg?The book of Julia?
(3) ??f??HAK.
?K@ ? ?
@us=nEhe.Sg=ErgEkabAttalk.Fem.SgkIdo.Perf.SghEbe.Pres.Sg?He did a talk?4.7 Subordinate Clause LimitationsBasically, the issue is related to conjunctedsub-sentences or the subordinate clause, whenthe number of conjuncted sub-sentences becomesgreater than one.
The issue does not appearoften and it is related to the NL type productions,specially the conjuncted sub-sentences denotedby SBAR as below.
A sentence of 23 tokenswith two conjuncted sub-sentences highlightedwith the SBAR is an evidence of this issue.During the processing of a production for thesentence marker M.S ?
- @ in the last (23rd)chart, the order of the complete productionsshould be as follows.
The ?@?
at the end rep-resents the complete status of the productions.M.S?
- @SBAR?
C.SBORD NP.NOM-SUB SBARADVP-MNR-MODF NP.NOM-MNR-OBJVCMAIN M.S @S?
KP-INST-MODF KP.DAT-SUB NP.NOM-OBJVCMAIN SBAR @But, unfortunately, the parser went into a dis-continuous state during the processing of the lastchart with the following productions.M.S?
- @SBAR?
C.SBORD NP.NOM-SUB SBARADVP-MNR-MODFNP.NOM-MNR-OBJ VCMAIN M.S @SBAR?
C.SBORD NP.NOM-SUB SBAR @ADVP-MNR-MODFNP.NOM-MNR-OBJ VCMAIN M.SADVP-MNR-MODF?
@ ADV.MNRUp to completion of the first SBAR ?
.
.
.
@production, the parser performed well.
ThenCompleter() went back to search anotherproduction which contained an incomplete non-terminal SBAR having ?@?
before it e.g.
@SBAR.
The Completer() made a fault therein chart 12 in the presence of wrong choices athigher precedence.
It found an incomplete SBARproduction.
After moving the ?@?
forward, itadded the updated production in the last chartas can be seen in the given productions.
After-wards, the PREDICTOR() became activated byseeing the ?@?
before the ADVP-MNR-MODFand the parser went into a wrong direction.
Toresolve this issue, it is needed to allow the Ear-ley?s Completer() to go back further until asuccessful parse.
The description of the extendedCompleter() is as follows.When the Urdu parser called theCOMPLETER(), it first sets thecompleterCheck flag to false, which willbe used to back track a right choice amongthe NL type productions.
After calculatingthe back-pointers, the updated productionentry is then added and printed by settingthe completerCheck to true.
If thecompleterCheck is found to be true andthe chart number is less than the length of asentence then a solution has been found andthere is no need to go back.
However, if thecompleterCheck is found to be true and thechart number is greater or equal to the length of asentence then the COMPLETER() is allowed toback track by setting its flag to its default value.5 ResultsThe division of training and test data is discussedin Section 3.
To make the test data more valu-able and reliable for results, the beginning ten sen-tences from each hundred of 1400 sentences of theURDU.KON-TB treebank were selected.
The testdata so contained 140 sentences in all.
In test data,the minimum, average and the maximum lengthis found to be 5, 13.73 and 46 words per sentence.All items which can exists in a normal text are con-sidered e.g.
punctuation, null elements, diacrit-ics, headings, regard titles, Hadees (the statementsof prophets), antecedents and anaphors within asentence, and others except the unknown words,which will be dealt in future.
The PARSEVALmeasures are used to evaluate the results.
ThePARSEVAL measures are calculated in two wayswhich are depicted in Table 1.At first, the values as per columns headings inTable 1 are calculated on the basis of constituentsfor each individual sentence.
Then these valuesare stored in a text file with these headings.
Thevalues existed in each column of the text file aresummed up and then divided by the total numberof 140 values in each column.
The results thus ob-tained are recorded in a row A-1 of Table 1 on av-erage basis.
Similarly, all the values in the Length,Matched, Gold and the Test columns are summedup individually from that text file and their sumsare recorded as can be seen in row T-2 of the table.Their respective results for the Precision, Recall,F-score and the Crossing Brackets are calculated44Sentences Length Matched Gold Test Precision Recall F-score CrossingA-1 140 13.73 17 22 18 0.952 0.811 0.848 2T-2 140 1922 2449 3107 2531 0.968 0.788 0.869 329Table 1: Evaluation results of the Urdu parserfrom these sums, which is a standard method ofcalculation.The Urdu parser outperforms the simple Hindidependency parser by Bharati et al.
(2009) withan additional recall of 22%.
In (Bharati et al.,2009), only precision and recall percentages aregiven.
Thats why only the precision and recallpercentages of labeled attachment (LA) are com-pared.
For chunks, intra-chunks and karakas, theprecision percentages of LA (LA-P) achieved bythe simple Hindi dependency parser are 82.3%,71.2% and 74.1%, respectively.
The average ofthese LA-P percentages is 75.9%, which is 20.9%less precision than the Urdu parser in row T-2.Similarly, Hindi dependency parser achieved LArecalls in case of chunks, intra-chunks and karakasas 65.4%, 58.2% and 46.7% respectively.
The av-erage of these percentages is calculated as 56.8%,which is now the final LA recall percentage of theHindi dependency parser.
For comparison, the re-call percentage of the Urdu parser used is men-tioned in row T-2 as 78.8%.
The values obtainedfor the language variant parsers concludes that theUrdu parser outperforms the simple Hindi depen-dency parser with 22% increase in recall.Multi-path shift-reduce parser (Mukhtar et al.,2012b) for Urdu parsed 74 sentences successfullyout of 100 and it was then reported as a 74% of ac-curacy.
This evaluation is very weak because thesuccessful parsed sentences were not comparedwith the gold standard.
Recall is a value obtainedthrough dividing the Matched constituents withthe constituents available in the Gold data.
As re-call percentage in our case is 78.8%, so we cansay that the Urdu parser beats the multi-path shift-reduce parser with a 4.8% increase in recall.
Onthe other hand, from the first 100 sentences of thetest data, the Urdu parser provides 89 sentenceswith parsed solutions.
Comparatively, the Urduparser has 15% more accuracy than the Multi-pathshift-reduce parser, but the parsed solutions werenot compared with the Gold data.
So, by consider-ing the safe side, we can repeat our argument thatthe Urdu parser beats the multi-path shift-reduceparser with a 4.8% increase in recall.6 ConclusionThe extended Urdu parser with rich encoded in-formation in the form of a grammar is a state ofthe art parsing candidate for morphologically richlanguage variant Urdu.
After removal of issues,the output of the parser is so directed, speedy andrefined in a sense that no extra or the irrelevant Ltype productions can be introduced by the Urduparser.
It is really hard now that the Urdu parserwill select a wrong choice of production.
If it hap-pens then the Urdu parser has a tendency to correctitself automatically.
These all features enables theUrdu parser comparable or better than the state ofthe art in the domain of both the language vari-ants.
Urdu parser can help the linguists analyze theUrdu sentences computationally and can be usefulin Urdu language processing and machine learn-ing domains.
By using this parser, the limited sizeof the URDU.KON-TB treebank can also be in-creased.
This can be done after getting the partialparsed trees of unknown sentences.
These partialparsed trees can be corrected and then importedinto the URDU.KON-TB treebank.AcknowledgmentI would like to express my sincere gratitude to mySupervisor Prof. Dr. Miriam Butt for her moti-vation, enthusiasm, and immense knowledge.
Herguidance helped me in all the time of this work.ReferencesQaiser Abbas and A Nabi Khan.
2009.
Lexical Func-tional Grammar For Urdu Modal Verbs.
In Emerg-ing Technologies, 2009.
ICET 2009.
InternationalConference on, pages 7?12.
IEEE.Qaiser Abbas and Ghulam Raza.
2014.
A Com-putational Classification Of Urdu Dynamic CopulaVerb.
International Journal of Computer Applica-tions, 85(10):1?12, January.Qaiser Abbas, Nayyara Karamat, and Sadia Niazi.2009.
Development Of Tree-Bank Based Prob-abilistic Grammar For Urdu Language.
Interna-tional Journal of Electrical & Computer Science,9(09):231?235.Qaiser Abbas.
2012.
Building A Hierarchical An-notated Corpus Of Urdu: The URDU.KON-TB45Treebank.
Lecture Notes in Computer Science,7181(1):66?79.Qaiser Abbas.
2014.
Semi-Semantic Part Of SpeechAnnotation And Evaluation.
In Proceedings of 8thACL Linguistic Annotation Workshop, pages 75?81,Dublin, Ireland.
Association for Computational Lin-guistics.Bhasha Agrawal, Rahul Agarwal, Samar Husain, andDipti M Sharma.
2013.
An Automatic ApproachTo Treebank Error Detection Using A DependencyParser.
In Computational Linguistics and IntelligentText Processing, pages 294?303.
Springer.Wajid Ali and Sarmad Hussain.
2010.
Urdu Depen-dency Parser: A Data-Driven Approach.
In Pro-ceedings of Conference on Language and Technol-ogy (CLT10).John Aycock and R Nigel Horspool.
2002.
PracticalEarley Parsing.
The Computer Journal, 45(6):620?630.Rafiya Begum, Samar Husain, Arun Dhwaj,Dipti Misra Sharma, Lakshmi Bai, and RajeevSangal.
2008.
Dependency Annotation Scheme ForIndian Languages.
In IJCNLP, pages 721?726.Akshar Bharati, Vineet Chaitanya, Rajeev Sangal,and KV Ramakrishnamacharyulu.
1995.
Natu-ral Language Processing: A Paninian Perspective.Prentice-Hall of India New Delhi.Akshar Bharati, Medhavi Bhatia, Vineet Chaitanya,and Rajeev Sangal.
1996.
Paninian GrammarFramework Applied To English.
Technical report,Technical Report TRCS-96-238, CSE, IIT Kanpur.Akshar Bharati, Samar Husain, Dipti Misra Sharma,and Rajeev Sangal.
2008.
A Two-Stage ConstraintBased Dependency Parser For Free Word Order Lan-guages.
In Proceedings of the COLIPS Interna-tional Conference on Asian Language Processing2008 (IALP).Akshar Bharati, Mridul Gupta, Vineet Yadav, KarthikGali, and Dipti Misra Sharma.
2009.
Simple ParserFor Indian Languages In A Dependency Framework.In Proceedings of the Third Linguistic AnnotationWorkshop, pages 162?165.
Association for Compu-tational Linguistics.Riyaz Ahmad Bhat, Sambhav Jain, and Dipti MisraSharma.
2012b.
Experiments On Dependency Pars-ing Of Urdu.
In In Proceedings of The 11th Interna-tional Workshop on Treebanks and Linguistic Theo-ries (TLT11).Miriam Butt and Tracy Holloway King.
2007.
UrduIn A Parallel Grammar Development Environment.Language Resources and Evaluation, 41(2):191?207.Miriam Butt and Gillian Ramchand.
2001.
ComplexAspectual Structure In Hindi/Urdu.
M. Liakata, B.Jensen, & D. Maillat, Eds, pages 1?30.Miriam Butt and Jafar Rizvi.
2010.
Tense And AspectIn Urdu.
Layers of Aspect.
Stanford: CSLI Publica-tions.Miriam Butt.
1993.
Hindi-Urdu Infinitives As NPs.South Asian Language Review: Special Issue onStudies in Hindi-Urdu, 3(1):51?72.Miriam Butt.
2003.
The Light Verb Jungle.
In Work-shop on Multi-Verb Constructions.Jay Clark Earley.
1968.
An Efficient Context-FreeParsing Algorithm.
Ph.D. thesis, Carnegie MellonUniversity, Pittsburgh, PA, USA.
AAI6907901.Jay Earley.
1970.
An Efficient Context-Free ParsingAlgorithm.
Communications of the ACM, 13(2):94?102.Wenbin Jiang, Hao Xiong, and Qun Liu.
2009.
Mu-tipath Shift-Reduce Parsing With Online Training.CIPS-ParsEval-2009 shared task.Abdul Jamil Khan.
2006.
Urdu/Hindi: An ArtificialDivide: African Heritage, Mesopotamian Roots, In-dian Culture & Britiah Colonialism.
Algora Pub.Gary F. Simons & Charles D. Fennig Lewis, M. Paul.2013.
Ethnologue: Languages Of The World, 17thEdition.
Dallas: SIL International.John R McLane.
1970.
The Political Awakening InIndia.
Prentice Hall.Neelam Mukhtar, Mohammad Abid Khan, and Fa-tima Tuz Zuhra.
2011.
Probabilistic Context FreeGrammar For Urdu.
Linguistic and Literature Re-view, 1(1):86?94.Neelam Mukhtar, Mohammad Abid Khan, and Fa-tima Tuz Zuhra.
2012a.
Algorithm For DevelopingUrdu Probabilistic Parser.
International journal ofElectrical and Computer Sciences, 12(3):57?66.Neelam Mukhtar, Mohammad Abid Khan, Fatima TuzZuhra, and Nadia Chiragh.
2012b.
ImplementationOf Urdu Probabilistic Parser.
International Journalof Computational Linguistics (IJCL), 3(1):12?20.Reut Tsarfaty, Djam?e Seddah, Yoav Goldberg, SandraKuebler, Marie Candito, Jennifer Foster, YannickVersley, Ines Rehbein, and Lamia Tounsi.
2010.Statistical Parsing Of Morphologically Rich Lan-guages (SPMRL): What, How And Whither.
In Pro-ceedings of the NAACL HLT 2010 First Workshopon Statistical Parsing of Morphologically-Rich Lan-guages, pages 1?12.
Association for ComputationalLinguistics.Reut Tsarfaty, Djam?e Seddah, Sandra K?ubler, andJoakim Nivre.
2013.
Parsing MorphologicallyRich Languages: Introduction To The Special Issue.Computational Linguistics, 39(1):15?22.46
