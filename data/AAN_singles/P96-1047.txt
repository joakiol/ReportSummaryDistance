Subdeletion in Verb Phrase EllipsisPaul G. DoneckerVillanova University800 Lancaster AvenueVillanova, PA 19085donecker@monet.vill.eduAbstractThis paper stems from an ongoing researchproject ~on verb phrase llipsis.
The project'sgoals are to implement a verb phrase ellipsisresolution algorithm, automatically test thealgorithm on corpus data, then automaticallyevaluate the algorithm against human-generatedanswers.
The paper will establish the currentstatus of the algorithm based on this automaticevaluation, categorizing current problemsituations.
An algorithm to handle one of theseproblems, the ease of subdeletion, will bedescribed and evaluated.
The algorithm attemptsto detect and solve subdeletion by locatingadjuncts of similar types in a verb phrase llipsisand corresponding antecedent.1.
IntroductionA verb phrase ellipsis (VPE) exists when asentence has an auxiliary verb but no verb phrase(VP).
For example, in the sentence "Gather yerosebuds while ye may," "may" is the beginning of aVPE.
Its antecedent is "gather ye rosebuds."
Theresearch described inthis paper is part of a project oautomate he resolution of VPE occurrences, and alsoto automate he evaluation of the success of the VPEresolution (Hardt 1995).Based on these evaluations of the algorithm,several distinct categories oferror situations have beendetermined.
We have focused on errors in which theprogram selects the correct head verb as antecedent.These cases can be divided into the followingcategories: 1) too much material included from theantecedent, 2) not enough much material includedfrom the antecedent, 3) discontinuous antecedents, and4) miscellaneous.For a subset of case 1, subdeletion, an algorithmderived from (Lappin and McCord, 1990) is evaluated1 This research was supported in part by NSFCareer Grant, no.
IRI-9502257.in regard to the Brown Corpus.2.
BackgroundPrevious studies on evaluating discourseprocessing (e.g., Walker, 1989; Hobbs, 1978) haveinvolved subjectively examining test cases todetermine correctness.
With the development ofresources uch as the Penn Treebank (Marcus,Santorini, and Marcinkiewicz, 1993), it has becomepossible to automate mpirical tests of discourseprocessing systems to obtain a more objectivemeasure of their success.
Towards this end, analgorithm was implemented in a Common Lispprogram called VPEAL (Verb Phrase EllipsisAntecedent Locator) (Hardt, 1995), drawing on thePenn Treebank as input.
The portion of the PennTreebank examined--the Brown Corpus, about amillion words--contains about 400 VPEs.Furthermore, to automatically evaluate thealgorithm, utilities were developed to automaticallytest the output of VPEAL for correctness.
The mostrecent version of VPEAL contained 18 sub-parts forranking and choosing antecedents.
Testing theprogram's performance involved finding thepercentage ofcorrect antecedents found by any or allof these algorithms.
This was achieved by havinghuman coders read plain text versions of the parsedpassages, marking what they felt to be the antecedent.Antecedents selected by VPEAL were consideredcorrect if they matched the antecedents selected by thecoders.The remainder of this paper will describe thecategories of errors observed, then describe anapproach to reducing one category of errors.3.
Categories of ErrorsThe most recent version of VPEAL correctlyselects 257 out of 380 antecedents from the BrownCorpus.
We have divided the categories into thefollowing categories:A.
Incorrect verb: 90 cases.
In these cases,VPEAL selected an incorrect head verb for the348antecedent.
The causes of these errors are beingevaluated.B.
Incorrect antecedent but correct verb: 33 cases.VPEAL selected the correct verb to head theantecedent, but the selected antecedent was eitherincomplete or included incorrect information.
Thesecases can be further divided into: 1) too much materialincluded from the antecedent, 2) not enough muchmaterial included from the antecedent, 3)discontinuous antecedents, and 4) miscellaneous.These subcategories are described below.1.
Too much material is included from theantecedent: 11cases.Example (excerpt from Penn Treebank):produce humorous effects in his novels and talesas they did in the writing of Longstreet andHooper and HarrisVPE: didVPEAL's antecedent: produce humorous effects in hisnovels and talesCoder's antecedent: produce humorous effectsNormally, an entire verb phrase is selected as theantecedent.
Inthese cases, though, part of the selectedantecedent was not required by the VPE.
The mostcommon situation (6 cases), as in the above xample,was subdeletion--when theVPE structure contains anoun phrase or prepositional phrase which substitutesfor a corresponding structure in the antecedent verbphrase.2.
Not enough material is included from theantecedent: 10 cases.Example (excerpt from Penn Treebank):But even if we can not see the repulsivecharacteristics n this new image of America,foreigners canVPE: canVPEAL's antecedent: see the repulsive characteristicsCoder's antecedent: see the repulsive characteristics nthis new image of AmericaBy default, only text contained by the selectedverb phrase is included in the antecedent.
In thesecases, however, human coders have selected text thatis adjacent to but not parsed as contained by the verbphrase as part of the antecedent.
I  can be argued thatthese errors are not the fault of the VPEALalgorithm--that if ext is parsed as not being a part ofthe verb phrase then it should still not be includedwhen the verb phrase is chosen as the antecedent.
Ifthe above prepositional phrase "in this new image ofAmerica" were parsed as part of the verb phrase-- asindeed it should have been--then the algorithm wouldhave derived the correct antecedent.3.
Discontinuous antecedents--the correctantecedent is split into two parts: 5 cases.Example (excerpt from Penn Treebank):representing asI do today my wifeVPE: doVPEAL's antecedent: representingCoder's antecedent: representing my wifeThis situation is similar to B2 in that theantecedent is incorrect because text not contained bythe selected verb phrase should be included in theantecedent.
In these cases, however, the reason theomitted text is not contained by the antecedent verbphrase is that an interposing phrase (in the exampleabove, the VPE itself) occurs in the middle of theantecedent.4.
Miscellaneous: 7 cases.4.
Improving Performance in the Case ofSubdeletionIn this section an algorithm is described to reducethe errors in error category B 1 caused by subdeletion.Subdeletion is probably the most straightforward ofthe error categories.
The problem category occurredwhen prepositional phrases and noun phrases in theantecedent verb phrases were unnecessary because ofanalogous phrases adjacent to the VPE.
The proposedsolution was to check whether the VPE has a sisternode that is a prepositional phrase or noun phrase.
Ifit does, and a phrase of the same type exists as a sisternode to the head verb in the antecedent, then thephrase in the antecedent is removed.
This isessentially the strategy outlined by Lappin andMcCord (1990).
Following are the specific steps toimplementing the algorithm:1.
Check if there are any prepositional phrases ornoun phrases that are sister nodes to the antecedenthead verb.2.
Check if there are any prepositional phrases ornoun phrases that are sister nodes to the VPE headverb.3.
If a prepositional phrase or noun phrase isfound in step 1, and a phrase of the same type is found349in step 2, then remove the phrase found in step 1 fromthe antecedent.For example, refer to the example from error caseB.
1.
Step 1 would locate the noun phrase "humorouseffects" and the prepositional phrase "in his novels andtales" as sister nodes to the antecedent head verb"produce.
"Step 2 would locate the prepositional phrase "inthe writing of Longstreet and Hooper and Harris" as asister node to the VPE head verb "did.
"Step 3 would determine that a prepositionalphrase xists after both the antecedent's head verb andthe VPE and therefore would delete "in his novels andtales" from the antecedent, resulting in the correctantecedent, "produce humorous effects.
"This algorithm will correctly handle the 6 cases ofsubdeletion i the Brown Corpus.
However, examplescan be constructed for which this algorithm does notaccount.
In the sentence "Julie drove to school onFriday, and Laura did on Saturday," for example, theVPE is "did" and the correct antecedent is "drove toschool."
In this example, two prepositionalphrases--"to school" and "on Friday"--follow theanteeedent's head verb "drove."
A prepositionalphrase, "on Saturday," also exists following the VPE'shead verb.
Following the above algorithm, bothprepositional phrases "to school" and "on Friday"would be deleted, resulting in an incorrect antecedent.The algorithm makes no provisions for casescontaining multiple prepositional phrases and nounphrases.
Fortunately, such situations eem rare, asnone were found in the Brown Corpus.More significantly, the algorithm also assumesthat analogous phrases following the antecedent andVPE always implies ubdeletion.
That is, it assumesthat prepositional phrases or noun phrases followingthe VPE always implies that like phrases hould bedeleted from the antecedent.
Again, it is possible toimagine acounterexample, for example, "Dad stayedin the Hilton like Morn did in Pittsburgh."
Here, theabove algorithm would incorrectly remove theprepositional phrase "in the Hilton.
"The expectation was that these counter exampleswould be less frequent than the cases in which thealgorithm would correctly remove unwanted text.
Amanual sampling of VPEs in the Brown Corpusshowed this to be true.
When the algorithm wasimplemented, however, the number of correct answersimproved to 258, an increase of 1.
In addition tosolving the 6 cases of subdeletion, the algorithm350inlxoduced 5 errors; each of these new errors involveda noun phrase or prepositional phrase in the VPE thatdid not require the deletion of a counterpart in theantecedent.
For example, one of the newly introducederrors occurred in the fragment "...creaking inthe fogas it had for thirty years."
The prepositional phrase"for thirty years" in the VPE caused the removal ofthe phrase "in the fog" from the antecedent, eventhough the phrases are not parallel in meaning.These results imply that the structure of asentence alone is insufficient to detect subdeletion.
Itis possible, however, that a larger sample of relevantexamples would suggest the best choice (to delete ornot to delete) in the absence of additional information.Towards these ends, other corpora in the PennTreebank will be examined with VPEAL.
Also, newerversions of the Treebank include semantic tags toadjunct phrases which will aid in preventing themisidentification f subdeletion described above.5.
ConclusionImproving the results of the VPEAL program isan iterative process.
We have categorized the errorsoccurring in VPEAL.
An algorithm for solving theerror category of subdeletion was described andexamined.
Potential problem situations for thealgorithm were also presented.
Empirical evaluationof the algorithm indicates that a purely syntacticapproach to detecting subdeletion is probablyinsufficient.
Additional approaches tothe problem ofsubdeletion were suggested.
Other cases of errors willbe likewise valuated.BibliographyHardt, Daniel.
1995.
An empirical approach to VPellipsis,Hobbs, Jerry.
1978.
Resolving pronoun references.Lingua, 44:311-388.Lappin, Shalom and Michael McCord.
1990.Anaphora Resolution in Slot Grammar.Computational Linguistics, 16(4).Marcus, Mitchell P., Beatrice Santorini, and MaryAnn Marcinkiewicz.
1993.
Building a largeannotated corpus of english: The penn treebank.Computational Linguistics, 19(2).Walker, Marilyn.
1989.
Evaluating discourseprocessing algorithms.
In Proceedings, 27thAnnual Meeting of the ACL, Vancouver, Canada.
