Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 13?18,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsQuickView: NLP-based Tweet SearchXiaohua Liu ?
?, Furu Wei ?, Ming Zhou ?, Microsoft QuickView Team ?
?School of Computer Science and TechnologyHarbin Institute of Technology, Harbin, 150001, China?Microsoft Research AsiaBeijing, 100190, China?
{xiaoliu, fuwei, mingzhou,qv}@microsoft.comAbstractTweets have become a comprehensive repos-itory for real-time information.
However, itis often hard for users to quickly get informa-tion they are interested in from tweets, ow-ing to the sheer volume of tweets as well astheir noisy and informal nature.
We presentQuickView, an NLP-based tweet search plat-form to tackle this issue.
Specifically, it ex-ploits a series of natural language process-ing technologies, such as tweet normalization,named entity recognition, semantic role label-ing, sentiment analysis, tweet classification, toextract useful information, i.e., named entities,events, opinions, etc., from a large volumeof tweets.
Then, non-noisy tweets, togetherwith the mined information, are indexed, ontop of which two brand new scenarios are en-abled, i.e., categorized browsing and advancedsearch, allowing users to effectively accesseither the tweets or fine-grained informationthey are interested in.1 IntroductionTweets represent a comprehensive fresh informa-tion repository.
However, users often have diffi-culty finding information they are interested in fromtweets, because of the huge number of tweets as wellas their noisy and informal nature.
Tweet search,e.g., Twitter 1, is a kind of service aiming to tacklethis issue.
Nevertheless, existing tweet search ser-vices provide limited functionality.
For example, inTwitter, only a simple keyword-based search is sup-1http://twitter.com/ported, and the returned list often contains meaning-less results.This demonstration introduces QuickView, whichemploys a series of NLP technologies to extractuseful information from a large volume of tweets.Specifically, for each tweet, it first conducts nor-malization, followed by named entity recognition(NER).
Then it conducts semantic role labeling(SRL) to get predicate-argument structures, whichare further converted into events, i.e., triples of whodid what.
After that, it performs sentiment analysis(SA), i.e., extracting positive or negative commentsabout something/somebody.
Next, tweets are clas-sified into predefined categories.
Finally, non-noisytweets together with the mined information are in-dexed.On top of the index, QuickView enables two brandnew scenarios, allowing users to effectively accessthe tweets or fine-grained information mined fromtweets.Categorized Browsing.
As illustrated in Figure1(a), QuickView shows recent popular tweets, enti-ties, events, opinions and so on, which are organizedby categories.
It also extracts and classifies URLlinks in tweets and allows users to check out popularlinks in a categorized way.Advanced Search.
As shown in Figure 1(b), Quick-View provides four advanced search functions: 1)search results are clustered so that tweets about thesame/similar topic are grouped together, and foreach cluster only the informative tweets are kept;2) when the query refers to a person or a company,two bars are presented followed by the words thatstrongly suggest opinion polarity.
The bar?s width13is proportional to the number of associated opin-ions; 3) similarly, the top six most frequent wordsthat most clearly express event occurrences are pre-sented; 4) users can search tweets with opinionsor events, e.g., search tweets containing any posi-tive/negative opinion about ?Obama?
or any eventinvolving ?Obama?.The implementation of QuickView requires adapt-ing existing NLP components trained on formaltexts, which often performs poorly on tweets.
Forexample, the average F1 of the Stanford NER(Finkel et al, 2005) drops from 90.8% (Ratinovand Roth, 2009) to 45.8% on tweets, while Liu etal.
(2010) report that the F1 score of a state-of-the-art SRL system (Meza-Ruiz and Riedel, 2009)falls to 42.5% on tweets as apposed to 75.5% onnews.
However, the adaptation of those componentsis challenging, owing to the lack of annotated tweetsand the inadequate signals provided by a noisy andshort tweet.
Our general strategy is to leverage ex-isting resources as well as unsupervised or semi-supervised learning methods to reduce the labelingefforts, and to aggregate as much evidence as pos-sible from a broader context to compensate for thelack of information in a tweet.This strategy is embodied by various componentswe have developed.
For example, our NER com-ponent combines a k-nearest neighbors (KNN) clas-sifier, which collects global information across re-cently labeled tweets with a Conditional RandomFields (CRF) labeler, which exploits informationfrom a single tweet and the gazetteers.
Both theKNN classifier and the CRF labeler are repeatedlyretrained using the results that they have confidentlylabeled.
The SRL component caches and clustersrecent labeled tweets, and aggregates informationfrom the cluster containing the tweet.
Similarly, theclassifier considers not only the current tweet butalso its neighbors in a tweet graph, where two tweetsare connected if they are similar in content or have atweet/retweet relationship.QuickView has been internally deployed, and re-ceived extremely positive feedback.
Experimentalresults on a human annotated dataset alo indicatethe effectiveness of our adaptation strategy.Our contributions are summarized as follows.1.
We demonstrate QuickView, an NLP-basedtweet search.
Different from existing methods,it exploits a series of NLP technologies to ex-tract useful information from a large volumeof tweets, and enables categorized browsingand advanced search scenarios, allowing usersto efficiently access information they are inter-ested in from tweets.2.
We present core components of QuickView, fo-cusing on how to leverage existing resourcesand technologies as well as how to make upfor the limited information in a short and oftennoisy tweet by aggregating information from abroader context.The rest of this paper is organized as follows.
Inthe next section, we introduce related work.
In Sec-tion 3, we describe our system.
In Section 4, weevaluate our system.
Finally, Section 5 concludesand presents future work.2 Related WorkInformation Extraction Systems.
Essentially,QuickView is an information extraction (IE) system.However, unlike existing IE systems, such as Evita(Saur??
et al, 2005), a robust event recognizer for QAsystem, and SRES (Rozenfeld and Feldman, 2008),a self-supervised relation extractor for the web, ittargets tweets, a new genre of text, which are shortand informal, and its focus is on adapting existing IEcomponents to tweets.Tweet Search Services.
A couple of tweet searchservices exist, including Twitter, Bing social search2 and Google social search 3.
Most of them provideonly keyword-based search interfaces, i.e., return-ing a list of tweets related to a given word/phrase.In contrast, our system extracts fine-grained in-formation from tweets and allows a new end-to-end search experience beyond keyword search, suchas clustering of search results, and search withevents/opinions.NLP Components.
The NLP technologies adoptedin our system , e.g., NER, SRL and classification,have been extensively studied on formal text butrarely on tweets.
At the heart of our system isthe re-use of existing resources, methodologies as2http://www.bing.com/social3http://www.google.com/realtime14(a) A screenshot of the categorized browsing scenario.
(b) A screenshot of the advanced search scenario.Figure 1: Two scenarios of QuickView.well as components, and the the adaptation of themto tweets.
The adaptation process, though varyingacross components, consists of three common steps:1) annotating tweets; 2) defining the decision con-text that usually involves more than one tweet, suchas a cluster of similar tweets; and 3) re-training mod-els (often incrementally) with both conventional fea-tures and features derived from the context definedin step 2.3 System DescriptionWe first give an overview of our system, then presentmore details about NER and SRL, as two represen-tative core components, to illustrate the adaptationprocess.3.1 OverviewArchitecture.
QuickView can be divided into fourparts, as illustrated in Figure 2.
The first part in-cludes a crawler and a buffer of raw tweets.
Thecrawler repeatedly downloads tweets using the Twit-ter APIs, and then pre-filters noisy tweets usingsome heuristic rules, e.g., removing a tweet if it istoo short, say, less than 3 words, or if it containsany predefined banned word.
At the moment, wefocus on English tweets, so non-English tweets arefiltered as well.
Finally, the un-filtered are put intothe buffer.The second part consists of several tweet extrac-tion pipelines.
Each pipeline has the same configura-tion, constantly fetching a tweet from the raw tweetbuffer, and conducting the following processes se-15Figure 2: System architecture of QuickView.quentially: 1) normalization; 2) parsing includingpart-of-speech (POS), chunking, and dependencyparsing; 3) NER; 4) SRL; 5) SA and 6) classifica-tion.
The normalization model identifies and cor-rects ill-formed words.
For example, after normal-ization, ?loooove?
in ??
?
?
I loooove my icon?
?
?
?will be transformed to ?love?.
A phrase-based trans-lation system without re-ordering is used to imple-ment this model.
The translation table includes man-ually compiled ill/good form pairs, and the languagemodel is a trigram trained on LDC data 4 usingSRILM (Stolcke, 2002).
The OpenNLP 5 toolkitis directly used to implement the parsing model.In future, the parsing model will be re-trained us-ing annotated tweets.
The SA component is imple-mented according to Jiang et al (2011), which incor-porates target-dependent features and considers re-lated tweets by utilizing a graph-based optimization.The classification model is a KNN-based classifierthat caches confidently labeled results to re-train it-self, which also recognizes and drops noisy tweets.4http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp ?cata-logId=LDC2005T125http://sourceforge.net/projects/opennlp/Each processed tweet, if not identified as noise, isput into a shared buffer for indexing.The third part is responsible for indexing andquerying.
It constantly takes from the indexingbuffer a processed tweet, which is then indexed withvarious entries including words, phrases, metadata(e.g., source, publish time, and account), named en-tities, events, and opinions.
On top of this, it answersany search request, and returns a list of matched re-sults, each of which contains both the original tweetand the extracted information from that tweet.
Weimplement an indexing/querying engine similar toLucene 6 in C#.
This part also maintains a cache ofrecent processed tweets, from which the followinginformation is extracted and indexed: 1) top tweets;2) top entities/events/opinions in tweets; and 3)top accounts.
Whether a tweet/entity/event/opinionranks top depends on their re-tweeted/mentionedtimes as well as its publisher, while whether an ac-count is top relies on the number of his/her followersand tweets.The fourth part is a web application that returnsrelated information to end users according to theirbrowsing or search request.
The implementation ofthe web application is organized with the model-view-control pattern so that other kinds of user in-terfaces, e.g., a mobile application, can be easily im-plemented.Deployment.
QuickView is deployed into 5 work-stations 7 including 2 processing pipelines, as illus-trated in Table 1.
The communication between com-ponents is through TCP/IP.
On average, it takes 0.01seconds to process each tweet, and in total about10 million tweets are indexed every day.
Note thatQuickView?s processing capability can be enhancedin a straightforward manner by deploying additionalpipelines.3.2 Core ComponentsBecause of limited space, we only discuss two corecomponents of QuickView: NER and SRL.NER.
NER is the task of identifying mentions ofrigid designators from text belonging to named-entity types such as persons, organizations and loca-tions.
Existing solutions fall into three categories: 1)6http://lucene.apache.org/java/docs/index.html7Intelr Xeonr 2.33 CPU 5140 @2.33GHz, 4G of RAM,OS of Windows Server 2003 EnterpriseX64 version16Table 1: Current deployment of QuickView.Workstation Hosted components#1 Crawler,Raw tweet buffer#2, 3 Process pipeline#4 Indexing Buffer, Indexer/Querier#5 Web applicationthe rule-based (Krupka and Hausman, 1998); 2) themachine learning based (Finkel and Manning, 2009;Singh et al, 2010); and 3) hybrid methods (Janscheand Abney, 2002).
With the availability of annotatedcorpora, such as ACE05, Enron and CoNLL03, thedata-driven methods become the dominating meth-ods.
However, because of domain mismatch, cur-rent systems trained on non-tweets perform poorlyon tweets.Our NER system takes three steps to addressthis problem.
Firstly, it defines those recently la-beled tweets that are similar to the current tweetas its recognition context, under which a KNN-based classifier is used to conduct word level clas-sification.
Following the two-stage prediction ag-gregation methods (Krishnan and Manning, 2006),such pre-labeled results, together with other con-ventional features used by the state-of-the-art NERsystems, are fed into a linear CRF models, whichconducts fine-grained tweet level NER.
Secondly,the KNN and CRF model are repeatedly retrainedwith an incrementally augmented training set, intowhich highly confidently labeled tweets are added.Finally, following Lev Ratinov and Dan Roth(2009), 30 gazetteers are used, which cover commonnames, countries, locations, temporal expressions,etc.
These gazetteers represent general knowledgeacross domains, and help to make up for the lack oftraining data.SRL.
Given a sentence, the SRL component identi-fies every predicate, and for each predicate furtheridentifies its arguments.
This task has been exten-sively studied on well-written corpora like news, anda couple of solutions exist.
Examples include: 1)the pipelined approach, i.e., dividing the task intoseveral successive components such as argumentidentification, argument classification, global infer-ence, etc., and conquering them individually (Xue,2004; Koomen et al, 2005); 2) sequentially labelingbased approach (Ma`rquez et al, 2005), i.e., label-ing the words according to their positions relativeto an argument (i.e., inside, outside, or at the be-ginning); and 3) Markov Logic Networks (MLN)based approach (Meza-Ruiz and Riedel, 2009),i.e., simultaneously resolving all the sub-tasks usinglearnt weighted formulas.
Unsurprisingly, the per-formance of the state-of-the-art SRL system (Meza-Ruiz and Riedel, 2009) drops sharply when appliedto tweets.The SRL component of QuickView is based onCRF, and uses the recently labeled tweets that aresimilar to the current tweet as the broader context.Algorithm 1 outlines its implementation, where:train denotes a machine learning process to get alabeler l, which in our work is a linear CRF model;the cluster function puts the new tweet into a clus-ter; the label function generates predicate-argumentstructures for the input tweet with the help of thetrained model and the cluster; p, s and cf denote apredicate, a set of argument and role pairs related tothe predicate and the predicted confidence, respec-tively.
To prepare the initial clusters required by theSRL component as its input, we adopt the predicate-argument mapping method (Liu et al, 2010) toget some automatically labeled tweets, which (plusthe manually labeled tweets) are then organized intogroups using a bottom-up clustering procedure.It is worth noting that: 1) our SRL componentuses the general role schema defined by PropBank,which includes core roles such as A0, A1 (usuallyindicating the agent and patient of the predicate, re-spectively), and auxiliary roles such as AM-TMPand AM-LOC (representing the temporal and loca-tion information of the predicate, respectively); 2)only verbal predicates are considered, which is con-sistent with most existing SRL systems; and 3) fol-lowing Ma`rquez et al (2005), it conducts word levellabeling.4 EvaluationOverall Performance.
We provide a textbox in thehome page of QuickView to collect feedback.
Wehave got 165 feedbacks, of which 85.5% are posi-tive.
The main complaint is related to the quality ofthe extracted information.Core Components.
We manually labeled the POS,17Algorithm 1 SRL of QuickView.Require: Tweet stream i;clusters cl;output stream o.1: Initialize l, the CRF labeler: l = train(cl).2: while Pop a tweet t from i and t ?= null do3: Put t to a cluster c: c = cluster(cl, t).4: Label t with l:(t, {(p, s, cf)}) = label(l, c, t).5: Update cluster c with labeled results(t, {(p, s, cf)}).6: Output labeled results (t, {(p, s, cf)}) to o.7: end while8: return o.NER, SRL and SA information for about 10,000tweets, based on which the NER and SRL com-ponents are evaluated.
Experimental results showthat: 1) our NER component achieves an averageF1 of 80.2%, as opposed to 75.4% of the baseline,which is a CRF-based system similar to Ratinov andRoth?s (2009) but re-trained on annotated tweets;and 2) our SRL component gets an F1 of 59.7%, out-performing both the state-of-the-art system (Meza-Ruiz and Riedel, 2009) (42.5%) and the system ofLiu et al (2010) (42.3%), which is trained on au-tomatically annotated news tweets (tweets reportingnews).5 Conclusions and Future workWe have described the motivation, scenarios, archi-tecture, deployment and implementation of Quick-View, an NLP-based tweet search.
At the heart ofQuickView is the adaptation of existing NLP tech-nologies, e.g., NER, SRL and SA, to tweets, a newgenre of text, which are short and informal.
Wehave illustrated our strategy to tackle this challeng-ing task, i.e., leveraging existing resources and ag-gregating as much information as possible from abroader context, using NER and SRL as case stud-ies.
Preliminary positive feedback suggests the use-fulness of QuickView and its advantages over exist-ing tweet search services.
Experimental results ona human annotated dataset indicate the effectivenessof our adaptation strategy.We are improving the quality of the core compo-nents of QuickView by labeling more tweets and ex-ploring alternative models.
We are also customizingQuickView for non-English tweets.
As it progresses,we will release QuickView to the public.ReferencesJenny Rose Finkel and Christopher D. Manning.
2009.Nested named entity recognition.
In EMNLP, pages141?150.Jenny Rose Finkel, Trond Grenager, and ChristopherManning.
2005.
Incorporating non-local informationinto information extraction systems by gibbs sampling.In ACL, pages 363?370.Martin Jansche and Steven P. Abney.
2002.
Informa-tion extraction from voicemail transcripts.
In EMNLP,pages 320?327.Long Jiang, Mo Yu, Ming Zhou, and Xiaohua Liu.
2011.Target-dependent twitter sentiment classification.
InACL.Peter Koomen, Vasin Punyakanok, Dan Roth, and Wen-tau Yih.
2005.
Generalized inference with multi-ple semantic role labeling systems.
In CONLL, pages181?184.Vijay Krishnan and Christopher D. Manning.
2006.
Aneffective two-stage model for exploiting non-local de-pendencies in named entity recognition.
In ACL, pages1121?1128.George R. Krupka and Kevin Hausman.
1998.
Isoquest:Description of the netowlTM extractor system as usedin muc-7.
In MUC-7.Xiaohua Liu, Kuan Li, Bo Han, Ming Zhou, Long Jiang,Zhongyang Xiong, and Changning Huang.
2010.
Se-mantic role labeling for news tweets.
In Coling, pages698?706.Llu?
?s Ma`rquez, Pere Comas, Jesu?s Gime?nez, and NeusCatala`.
2005.
Semantic role labeling as sequentialtagging.
In CONLL, pages 193?196.Ivan Meza-Ruiz and Sebastian Riedel.
2009.
Jointlyidentifying predicates, arguments and senses usingmarkov logic.
In NAACL, pages 155?163.Lev Ratinov and Dan Roth.
2009.
Design challengesand misconceptions in named entity recognition.
InCoNLL, pages 147?155.Benjamin Rozenfeld and Ronen Feldman.
2008.
Self-supervised relation extraction from the web.
Knowl.Inf.
Syst., 17:17?33, October.Roser Saur?
?, Robert Knippen, Marc Verhagen, and JamesPustejovsky.
2005.
Evita: A robust event recognizerfor qa systems.
In EMNLP, pages 700?707.Sameer Singh, Dustin Hillard, and Chris Leggetter.
2010.Minimally-supervised extraction of entities from textadvertisements.
In HLT-NAACL, pages 73?81.Andreas Stolcke.
2002.
SRILM ?
an extensible languagemodeling toolkit.
In ICSLP, volume 2, pages 901?904.Nianwen Xue.
2004.
Calibrating features for seman-tic role labeling.
In In Proceedings of EMNLP 2004,pages 88?94.18
