R. Dale et al (Eds.
): IJCNLP 2005, LNAI 3651, pp.
378 ?
389, 2005.?
Springer-Verlag Berlin Heidelberg 2005Discovering Relations Between Named Entitiesfrom a Large Raw Corpus Using TreeSimilarity-Based ClusteringMin Zhang1, Jian Su1, Danmei Wang1,2, Guodong Zhou1, and Chew Lim Tan21 Institute for Infocomm Research,21 Heng Mui Keng Terrace, Singapore 119613{mzhang, sujian, stuwang, zhougd}@i2r.a-star.edu.sg2 Department of Computer Science,National University of Singapore,Singapore, 117543tancl@comp.nus.edu.sgAbstract.
We propose a tree-similarity-based unsupervised learning method toextract relations between Named Entities from a large raw corpus.
Our methodregards relation extraction as a clustering problem on shallow parse trees.
First,we modify previous tree kernels on relation extraction to estimate the similaritybetween parse trees more efficiently.
Then, the similarity between parse trees isused in a hierarchical clustering algorithm to group entity pairs into differentclusters.
Finally, each cluster is labeled by an indicative word and unreliableclusters are pruned out.
Evaluation on the New York Times (1995) corpusshows that our method outperforms the only previous work by 5 in F-measure.It also shows that our method performs well on both high-frequent and less-frequent entity pairs.
To the best of our knowledge, this is the first work to use atree similarity metric in relation clustering.1   IntroductionThe relation extraction task identifies various semantic relations such as location,affiliation, revival and so on between entities from text.
For example, the sentence?George Bush is the president of the United States.?
conveys the semantic relation?President?, between the entities ?George Bush?
(PERSON) and ?the United States?(GPE1).
The task of relation extraction was first introduced as part of the TemplateElement task in MUC6 and formulated as the Template Relation task in MUC7 [1].Most work at MUC [1] was rule-based, which tried to use syntactic and semanticpatterns to capture the corresponding relations by means of manually written linguis-tic rules.
The major drawback of this method is the poor adaptability and the poorrobustness in handling large-scale or new domain data due to two reasons.
First, ruleshave to be rewritten for different tasks or when porting to different domains.
Second,generating rules manually is quite labor- and time-consuming.1GPE is an acronym introduced by the ACE (2004) program to represent a Geo-Political Entity--- an entity with land and a government.Discovering Relations Between Named Entities from a Large Raw Corpus 379Since then, various supervised learning approaches [2,3,4,5] have been explored ex-tensively in relation extraction.
These approaches automatically learn relation patternsor models from a large annotated corpus.
To decrease the corpus annotation require-ment, some researchers turned to weakly supervised learning approaches [6,7], whichrely on a small set of initial seeds instead of a large annotated corpus.
However, there isno systematic way in selecting initial seeds and deciding an ?optimal?
number of them.Alternatively, Hasegawa et al [8] proposed a cosine similarity-based unsupervisedlearning approach for extracting relations from a large raw corpus.
The context wordsin between the same entity pairs in different sentences are used to form word vectors,which are then clustered according to the cosine similarity.
This approach does notrely on any annotated corpus and works effectively on high-frequent entity pairs [8].However, there are two problems in this approach:?
The assumption that the same entity pairs in different sentences have the samerelation.?
The cosine similarity measure between the flat feature vectors, which only con-sider the words between entities.In this paper, we propose a tree similarity-based unsupervised learning approachfor relation extraction.
In order to resolve the above two problems in Hasegawa et al[8], we assume that the same entity pairs in different sentences can have differentrelation types.
Moreover, rather than the cosine similarity measure, a similarity func-tion over parse trees is proposed to capture much larger feature spaces instead of thesimple word features.The rest of the paper is organized as follows.
In Section 2, we discuss the proposedtree-similarity-based clustering algorithm.
Section 3 shows the experimental result.Section 4 compares our work with the previous work.
We conclude our work with asummary and an outline of the future direction in Section 5.2   Tree Similarity-Based Unsupervised LearningWe use the shallow parse tree as the representation of relation instances, and regardrelation extraction as a clustering problem on shallow parse trees.
Our method con-sists of three steps:1) Calculating the similarity between two parse trees using a tree similarity func-tion;2) Clustering relation instances based on the similarities using a hierarchicalclustering algorithm;3) Labeling each cluster using indicative words as its relation type, and pruningout unreliable clusters.In this section, we introduce the parse tree representation for a relation instance,define the tree similarity function, and describe the clustering algorithm.2.1   Parse Tree Representation for Relation InstanceA parse tree T is a set of node {p1?pn}, which are connected hierarchically.
Here, anode pi includes a set of features { f1,?, f4} as follows:380 M. Zhang et al?
Head Word ( 1f ): for a leaf (or terminal) node, it is the word itself of the leafnode; for a non-terminal node, it is a ?Head Word?
propagated from a leafnode.
This feature defines the main meaning of the phrase or the sub-tree rootedby the current node.?
Node Tag ( 2f ): for a leaf node, it is the part-of-speech of this node; for a non-terminal node, it is a phrase name, such as Noun Phrase (NP), Verb Phrase (VP).This feature defines the linguistic category of this node.?
Entity Type ( 3f )2:it indicates the entity type which can be PER, COM or GPEif the current node refers to a Named Entity.?
Relation Order ( 4f ): it is used to differentiate asymmetric relations, e.g., ?Abelongs to B?
or ?B belongs to A?.These features are widely-adopted in Relation Extraction task.
In the parse tree repre-sentation, we denote by .i jfp  the jthfeature of node ip , by [ ]ip j   the jthchild ofnode ip , and by [ ]ip C  the set of all children of node ip , i.e., [ ] [ ]i ip j p?
C .2.2   Tree Similarity FunctionInspired by the special property of kernel-based methods3, we extend the tree kernelsin Zelenko et al [3] to a novel tree similarity measure function, and apply the abovetree similarity function to unsupervised learning for relation extraction.
Mostly, inprevious work, kernels are used in supervised learning algorithms such as SVM, Per-ceptron and PCA (Collins and Duffy, 2001).
In our approach, the hierarchical cluster-ing algorithm is adopted, this allows us to explore more robust and powerful similar-ity functions, other than a proper kernel function4.A similarity function returns a normalized, symmetric similarity score in the range[0, 1].
Especially, our tree similarity function 1 2( , )K T T over two trees 1T  and 2T , withthe root nodes 1r  and 2r , is defined as follows:1 2 1 2 1 2 1 2( , ) ( , ) * ( , ) ( [ ], [ ]){ }CK T T m s Kr r r r r r= + c c                                   (1)where,2For the features of ?Entity Type?, please refer to the literature ACE [22] for details.3As an alternative to the feature-based method [5], the advantage of kernels [9] is that they canreplace any dot product between input points in a high dimensional feature space.
Comparedwith the feature-based method, the kernel method displays several unique characteristics,such as implicitly mapping the feature space from low-dimension to high-dimension, and ef-fectively modeling structure data.
A few kernels over structured data have been proposed inNLP study [10-16].
Zelenko et al [3] and Culotta et al [4] explored tree kernels with SVM[9] for relation extraction.
We study the tree kernels from similarity measure viewpoints.4A function is a kernel function if and only if the function is symmetric and positive semi-definite [3, 9].Discovering Relations Between Named Entities from a Large Raw Corpus 381?
, )( i jm p p is a matching function over the features of two tree nodes ip  and jp .In this paper, only the node tag feature ( 2f ) is considered:2 2, )  1      if .
.
(0     otherwisejii jf fp pm p p??
=??
?=                                                (2)The binary function (1) means that two nodes are matched only if they sharethe same Node Tag.?
1 2( , )p ps  is a similarity function between two nodes ip  and jp :1 13 31 1&if, else ifother features matchno match.
.1.
.
( ) 0.5       .
.0.250i ji jjii jp f p fp f p fp p f fp ps?
=??=?????
?= =?????
(3)where the values of the weights are assigned empirically according to the discrimina-tive ability of the feature types.
Function (3) measures the similarity between twonodes according to the weights of matched features.?
CK  is the similarity function over the two children node sequences 1[ ]p cand 2[ ]p c :1 2 1 2, , ( ) ( )( [ ], [ ]) ( [ ], [ ])argmax { }C l lK p p K p p==a b a bc c a b                              (4)1 2 21( )1( [ ], [ ]) ( [ ], [ ])liK p p K p p== ?
i iaa ba b                                             (5)where a and b are two index sequences, i.e., a is a sequence  1 10 ... [ ]ma a p< < ?
| |C  andl(a) is the length of sequence a, and likewise for b.
The node set1 1 1[ ] { [ ], ..., [ ]}p p p= 1 ma a a  is the subset of 1[ ]p c , 1 1[ ] [ ]p p?a c , 1[ ]p ai is the ithnode of1[ ]p a , and likewise for 2p .We define 1 2( , )K T T in terms of the similarity function 1 2( , )r rs  between the par-ent nodes and the similarity function CK  over the two children node sequences 1[ ]r cand 2[ ]r c .
Formula (5) defines the similarity between two node sequences by sum-ming up the similarity of each corresponding node pair.
CK  in Formula (4) searchesout such two children node subsequences 1[ ]p a and 2[ ]p b , which has the maximumnode sequence similarity among all the possible combining pairs of node subse-quences.
Given the similarity scores of all children node pairs, Formula (4) can be382 M. Zhang et aleasily resolved by the dynamic programming (DP) algorithm5.
By traversing the twotrees from top to down and applying the DP algorithm layer by layer, the parse treesimilarity 1 2( , )K T T defined by Formula (1) is obtained.
Due to the DP algorithm, thedefined tree similarity function is computable in O(mn), where m and n are the num-ber of nodes in the two trees, respectively.
The matching function , )( i jm p p in For-mula (2) can narrow down the search space during similarity calculation, since thesub-trees with unmatched root nodes are unnecessary to be further explored.Fig.
1.
Sub-structure with maximum similarityFrom the above discussion, we can see that our defined tree similarity function istrying to detect the two trees?
maximum isomorphic sub-structures.
The similarityscore between the maximum isomorphic sub-structures is returned as the value of thesimilarity function.
Fig.
1 illustrates the sub-structures with the maximum similaritybetween two trees.
Among the all matched sub-structures, only the sub-structurescircled by the dashed lines are the isomorphic sub-structures with the maximum simi-larity.
The similarity score between the sub-structures is obtained by summing up thesimilarity score between the corresponding matched nodes.Finally, since the size of the input parse tree is not constant, the similarity score isnormalized as follows:1 21 1 2 21 2( , )( , )* ( , )?
( , ) K T TK T T K T TK T T =                (6)The value of 1 2?
( , )K T T ranges from 0 to 1.
In particular, 1 2?
( , )K T T =1 if and onlyif 1 2T T= .
For example, given two parse trees A and B, and A is a subtree of B, thenunder Formula (1), K(A, B) = K(A, A).
However, after the normalization through5A well-known application of Dynamic Programming is to compute the edit distance betweentwo character strings.
Let us regard a node as a character and a node sequence as a characterstring.
Then given the similarity  score between nodes, Formula (4) can be resolved using DPalgorithm in the same way as that of strings.
Due to space limitation, the implementationdeatils are not discussed here.Discovering Relations Between Named Entities from a Large Raw Corpus 383Equation (6), we can get ?
?
( , ) ( , ) 1K A B K A A< = .
In this way, we can differentiate suchtwo cases.According to the Formula (1) to (5), the similarity function 1 2( , )K T T  over the twotrees in Fig.
1 is computed as follows:1 2 ([NP, VP], [NP, VP])([bought, NP], [sold, NP, yesterday])1 bought sold (NP, NP)= 1+0.25+0.25+ ([a, red, car]( , ) (S,S) *{ (S,S) }0.25 (NP, NP) (VP, VP)0.25 0.25 (Paul, Smith) 0.25( , )cccK T T m s KK KKKK KK= += += + += + + +++, [the, flat])1.5 a the car flat( , ) ( , )2K K= + +=The above similarity score is more than one.
This is because we did not normalizethe score using Formula (6).2.3   Tree Similarity Based Unsupervised LearningOur method consists of five steps:1) Named Entity (NE) tagging and sentence parsing: Detailed and accurate NEtypes provide more effective information for relation discovery.
Here we use Sekine?sNE tagger [20], where 150 hierarchical types and subtypes of Named Entities aredefined [21].
This NE tagger has also been adopted by Hasegawa et al [8].
Besides,Collin?s parser [18] is adopted to generate shallow parse trees.2) Similarity calculation: The similarity between two relation instances is definedbetween two parse trees.
However, the state-of-the-art of parser is always error-prone.Therefore, we only use the minimum span parse tree including the NE pairs whencalculating the similarity function [4].
Please note that the two entities may not be theleftmost or rightmost node in the sub-tree.3) NE pairs clustering: Clustering of NE pairs is based on the similarity score gener-ated by the tree similarity function.
Rather than k-means [17], we used a bottom-uphierarchical clustering method so that there is no need to determine the number ofclusters in advance.
This means that we are not restricted to the limited types of rela-tions defined in MUC [1] or ACE [22].
Therefore, more substantial existing relationscan be discovered.
We adopt the group-average clustering algorithm [17] since itproduces the best performance compared with the complete-link and single-link algo-rithms in our study.4) Cluster labeling: In our study, we label each cluster by the most frequent ?HeadWord?
in this cluster.
As indicated in subsection 2.1, the ?Head Word?
of root nodedefines the main meaning of a parse tree.
This way, the ?Head Word?
of the root384 M. Zhang et alnode of the minimum span tree naturally characterizes the relation between this NEpair in this tree.
Thus, we simply count the frequency of the ?Head Word?
of the rootnode in the cluster, and then chose the most frequent ?Head Word?
as the relationtype of the cluster.5) Cluster pruning: Unreliable clusters may be generated due to various reasonssuch as divergent relation type distributions and the fact that most of the entity pairsinside this cluster are totally unrelated.
Therefore, pruning is necessary and done inour approach using two criteria.
Firstly, if the most frequent ?Head Word?
occursless than a predefined percentage in this cluster, which means that the relation typedefined by this ?Head Word?
is not significant statistically, the cluster is pruned out.Secondly, we prune out the clusters whose NE pair number is below a predefinedthreshold because such clusters may not be representative enough for this relation.3   Experiments3.1   Experimental SettingTo verify our proposed method and establish proper comparison with Hasegawa et al[8], we use the same corpus ?The New York Times (1995)?, and evaluate our work onthe same two kinds of NE pairs: COMPANY-COMPANY (COM-COM) andPERSON-GPE (PER-GPE) as Hasegawa et al in [8].
First, we iterate over all pairs ofNamed Entities occurring in the same sentence to generate potential relation in-stances.
Then, according to the co-occurrence frequency of NE pairs, all the relationinstances are grouped into three categories:1) High frequent instances with the co-occurrence frequency not less than 30.
Inthis category, only the relation instances, which satisfy the all criteria of Ha-segawa et al [8]6, are kept for final experiment.
By doing so, this categorydata is the same as the entire experimental set used by Hasegawa et al [8].2) Intermediate frequent instances with the co-occurrence frequency between 5and 30.
In this category, only two distinct NE pairs are randomly picked ateach frequency for final evaluation due to the large number of such NE pairs.3) Less frequent instances with the co-occurrence frequency not more than 5.
Inthis category, twenty distinct NE pairs are randomly picked at each fre-quency for final evaluation due to the similar reason as 2).Table 1 reports the statistics of the entire evaluation corpus7 which is manuallytagged.
Table 2 reports the percentage of the NE pairs which carry more than onerelation types when occurring at different relation instances.
The numbers inside pa-rentheses in Table 1 and Table 2 correspond to the statistical values of the NE pair?PER-GPE?, while the numbers outside parentheses are related to the NE pair ?COM-COM?.
Table 2 shows that at least 9.88% of distinct NE pairs have more than one6To discover reliable relations, Hasegawa et al [8] sets five conditions to generate relationinstance set.
NE pair co-occurrence more than 30 times is one of the five conditions.7Due to the parsing errors and NE tagging errors, the actual number of relation instances isless than the theory number that we should pick up.Discovering Relations Between Named Entities from a Large Raw Corpus 385relation types in the test corpus.
Thus it is reasonable and necessary to assume thateach occurrence of NE pairs forms one individual relation instance.Table 1.
Statistics on the manually annotated evaluation dataCategory byfrequency# of instances # of distinct NE pairs    # of relationtypesHigh 8931 (13205) 65 (177) 10 (38)Intermediate 672  (783) 38 (41) 6 (7)Less 276  (215) 76 (81) 5 (8)Table 2.
% of distinct NE pairs with more than one relation types on the evaluation dataCategory by frequency % of NE pairs have more than one relationsHigh  15.4   (12.99)Intermediate 28.9   (24.4)Less 11.8   (9.88)3.2   Evaluation MeasuresAll the experiments are carried out against the manually annotated evaluation corpus.We adopt the same criteria as Hasegawa et al [8] to evaluate the performance of ourmethod.
Grouping and labeling are evaluated separately.
For grouping evaluation, allthe single NE pair clusters are labeled as non-relation while all the other clusters arelabeled as the most frequent relation type counted in this cluster.
For each individualrelation instance, if the manually assigned relation type is the same as its cluster label,the grouping of this relation instance is counted as correct, otherwise, are counted asincorrect.
Recall (R), Precision (P) and F-measure (F) are adopted as the main per-formance measure for grouping [8].
For labeling evaluation, a cluster is labeled cor-rectly only if the labeling relation type, represented by most frequent ?Head Word?of the root node of the minimal-span subtree, is the same as the cluster label gotten inthe grouping process.3.3   Experimental ResultsLike other applications using clustering algorithms, the performance of the proposedmethod also depends on the threshold of the clustering similarity.
Here this thresholdis used to truncate the hierarchical tree, so that the different clusters are generated.When the threshold is set to 1, then each individual relation instance forms one uniquegroup; when the threshold is set to 0, then the all relation instance form one big group.Table 3 reports the evaluation results of grouping, where the best F-measures and thecorresponding similarity thresholds are listed.
We can see that our method not onlyachieves good performance on the high-frequent data, but also performs well on the386 M. Zhang et alintermediate and less-frequent data.
The higher frequency, the higher performance.Since the best thresholds of the two NE cases are the almost same, we just fix theuniversal threshold as the one used in ?PER-GPE?
case in each category.Table 3.
Performance evaluation of Grouping phase, the numbers inside parentheses corre-spond to the evaluation score of ?PER-GPE?
while the numbers outside parentheses are relatedto ?COM-COM?.Performance Category by fre-quencyF P (%) R (%)ThresholdHigh 80 (87) 82 (90) 78 (84) 0.28 (0.29)Intermediate 74 (76) 87 (84) 64 (69)  0.32 (0.30)Less   62 (65) 75 (77) 53 (56)  0.36 (0.35)Table 4.
Best performance comparison in the high-frequent data (F)Our approach  Hasegawa et al [8]PER-GPE 87 82COM-COM 80 77Table 4 compares the performances of the proposed method and Hasegawa et al[8], where the best F-measures on the same high-frequent data are reported.
Table 4shows that our method outperforms the previous approach by 5 and 3 F-measures inclustering NE pairs of ?PER-GPE?
and ?COM-COM?, respectively.An interesting phenomenon is that the best threshold is set to be just above 0 forthe cosine similarity in Hasegawa et al [8].
This means that each word feature vectorof each combination of NE pairs in the same cluster shares at least one word in com-mon --- and most of these common words were pertinent to the relations [8].
This alsoprevents them from working well on less-frequent data [8].
In contrast, for the simi-larity function in our approach, the best threshold is much greater than 0.
The differ-ence between the two thresholds implies that the similarity function over the parsetrees can capture more common structured features than the word feature vectors can.This is also the reason why our method is effective on both high and less-frequent data.It is not surprising that we do have that a few identical NE pairs, occurring in dif-ferent relation instances, are grouped into different relation sets.
For example, the NEpairs ?General Electric Co. and NBC?, in one sentence ?General Electric Co., whichbought NBC in 1986, will announce a new marketing plan.
?, is grouped into the rela-tion set ?M&A?, but in another sentence ?Prime Star Partners and General ElectricCo., parent of NBC, has signed up 430,000 subscribers.
?, is grouped into anotherrelation set ?parent?.
Among all the NE pairs that carry more than one relation types,41.8% of them are grouped correctly using our tree similarity function.Discovering Relations Between Named Entities from a Large Raw Corpus 387The performance of grouping is the upper bound of the performances of labelingand pruning.
In the final, there are 146 PER-GPE clusters and 95 COM-COM clustersare generated after grouping.
Out of which, only 57 PER-GPE clusters and 42 COM-COM clusters are labeled correctly before pruning.
This is because that a large por-tion of the non-relation clusters are labeled as one kind of true relations.
After prun-ing, 117 PER-GPE clusters and 84 COM-COM clusters are labeled correctly.
This isbecause lots of the non-relation clusters are labeled correctly by the pruning process,so we can say that pruning is a non-relation labeling process, which greatly improvesthe performance of labeling.The experimental results discussed above suggest that our proposed method is aneffective solution for discovering relation from a large raw corpus.4   DiscussionsIt would be interesting to review and summarize how the proposed method deals withthe relation extraction issue differently from other related works.
Table 5 in the nextpage summarizes the differences between our method and Hasegawa et al [8].Table 5.
The differences between our method and Hasegawa et al [8]Our approach  Hasegawa et al [8]SimilarityMeasuretree similarity over parsetree structurescosine similarity between thecontext word feature vectorsAssumption No Yes (The same entity pairs indifferent sentences have thesame relation)Labeling the most frequent ?HeadWord?
of the root node ofsub-treethe most frequent contextwordPruning Yes (We present two prun-ing criterion)NoData Frequency effective on both high andless-frequent dataeffective only on high-frequent dataIn addition, since our tree similarity function has benefited from the relation treekernels of Zelenko et al [3], let us compare our similarity measure function with theirrelation kernel function [3] from the viewpoint of computational efficiency.
Zelenkoet al [3] defined the first parse tree kernels for relation extraction, and then thisrelation tree kernels were extended to dependency tree kernels by Culotta et al [4].Their tree kernels sum up the similarity scores among all possible subsequences ofchildren nodes with matching parents, and give a penalty to longer sequences.
Their388 M. Zhang et altree kernels are closely related to the convolution kernels [12].
But, by doing so, lotsof sub-trees will be considered again and again.
An extreme case occurs when twotree structures are identical.
In that situation all the sub-trees will be consideredexhaustedly, even if the sub-tree is a part of other bigger sub-trees.
We use the maxi-mum score in Formula (4) instead of the summation in our approach.
With our ap-proach, the entire tree is only considered once.
The replacement of summation withmaximization reduces the computational time greatly.5   Conclusions and Future DirectionsWe modified the relation tree kernels [3] to be a tree similarity measure function byreplacing the summation over all possible subsequences of children nodes withmaximization, and used it in clustering for relation extraction.
The experimental resultshowed much improvement over the previous best result [8] on the same test corpus.It also showed that our method is high effective on both high-frequent and less-frequent data.
Our work demonstrated the effectiveness of combining the tree similar-ity measure with unsupervised learning for relation extraction.Although our method shows good performance, there are still other aspects of theproposed method worth discussing here.
Without additional knowledge, relation de-tecting and relation labeling are still not easy to be resolved, especially in less-frequent data.
We expect that using additional easily-acquired knowledge can im-prove the performance of the proposed method.
For example, we can introduce theWordNet [19] thesaurus information into Formula (3) to obtain more accurate nodesimilarities and resolve data sparse problem.
We can also use the same resource toimprove the labeling scheme and find more abstract relation types like the definitionsused in ACE program [22].References1.
MUC.
1987-1998.
The nist MUC website:  http://www.itl.nist.gov/iaui/894.02/related_projects/muc/2.
Miller, S., Fox, H., Ramshaw, L. and Weischedel, R. 2000.
A novel use of statistical pars-ing to extract information from text.
Proceedings of NAACL-003.
Zelenko, D., Aone, C. and Richardella, A.
2003.
Kernel Methods for Relation Extraction.Journal of Machine Learning Research.
2003(2):1083-11064.
Culotta, A. and Sorensen, J.
2004.
Dependency Tree Kernel for Relation Extraction.
Pro-ceeding of ACL-045.
Kambhatla, N. 2004.
Combining Lexical, Syntactic, and Semantic Features with Maxi-mum Entropy Models for Extracting Relations.
Proceeding of ACL-04, Poster paper.6.
Agichtein, E. and Gravano, L. 2000.
Snow-ball: Extracting Relations from Large Plain-text Collections.
Proceedings of the Fifth ACM International Conference on Digital Li-braries.7.
Stevenson, M. 2004.
An Unsupervised WordNet-based Algorithm for Relation Extraction.Proceedings of the 4th LREC workshop "Beyond Named Entity: Semantic Labeling forNLP tasks"Discovering Relations Between Named Entities from a Large Raw Corpus 3898.
Hasegawa, T., Sekine, S. and Grishman, R. 2004.
Discovering Relations among NamedEntities from Large Corpora.
Proceeding of ACL-049.
Vapnik, V. 1998.
Statistical Learning Theory.
John Wiley10.
Collins, M. and Duffy, N. 2001.
Convolution Kernels for Natural Language.
Proceeding ofNIPS-0111.
Collins, M. and Duffy, N. 2002.
New Ranking Algorithm for Parsing and Tagging: Kernelover Discrete Structure, and the Voted Perceptron.
Proceeding of ACL-02.12.
Haussler, D. 1999.
Convolution Kernels on Discrete Structures.
Technical Report UCS-CRL-99-10, University of California13.
Lodhi, H., Saunders, C., Shawe-Taylor, J., Cristianini, N. and Watkins, C. 2002.
Text clas-sification using string kernel.
Journal of Machine Learning Research, 2002(2):419-44414.
Suzuki, J., Hirao, T., Sasaki Y. and Maeda, E. 2003.
Hierarchical Directed Acyclic GraphKernel: Methods for Structured Natural Language Data.
Proceedings of ACL-0315.
Suzuki, J., Isozaki, H. and Maeda, E. 2003.
Convolution Kernels with Feature Selectionfor Natural Language Processing Tasks.
Proceedings of ACL-0416.
Moschitti, A.
2004.
A study on Convolution Kernels for Shallow Semantic Parsing.
Pro-ceedings of ACL-0417.
Manning, C. and Schutze, H. 1999.
Foundations of Statistical Natural Language Process-ing.
The MIT Press: 500-52718.
Collins, M. 1999.
Head-Driven Statistical Models for Natural Language Parsing.
Ph.D.Thesis.
University of Pennsylvania19.
Fellbaum, C. 1998.
WordNet: An Electronic Lexical Database and some of its Applica-tions.
Cambridge, MA: MIT Press.20.
Sekine, S. 2001.
OAK System (English Sentence Analysis).
Http://nlp.cs.nyu.edu/oak21.
Sekine, S., Sudo, K. and Nobata, C. 2002.
Extended named entity hierarchy.
Proceedingsof LREC-0222.
ACE.
2004.
The Automatic Content Extraction (ACE) Projects.
http://www.ldc.upenn.edu/Projects/ACE/
