Some Notes  on the Complex i ty  of Dialogues *J an  A lexandersson  Pau l  He is terkampDFKI  GmbH, Stuhlsatzenhausweg 3, DaimlerChrysler AGD-66123 Saarbrficken, Wilhelm-Runge-Str.
11Germany D-89081 Ulm, Germanyj anal@dfki, de paul.
heisterkamp?DaimlerChrysler, comAbst ractThe purpose of this paper is twofold.First, we describe some complexityaspects of spoken dialogue.
It isshown that, given the internal set-ting of our dialogue system, it is im-possible to test even a small percent-age of the theoretically possible ut-terances in a reasonable amount oftime.
An even smaller part of pos-sible dialogues can thus be tested.Second, an approach for early test-ing of the dialogue manager of a dia-logue system, without the completesystem being put together, is de-scribed.
'C1 In t roduct ionOn the one hand, it is important for the de-velopers of a dialogue system that the systemis robust (i.e., it does not fail or loop), easyto use and is efficient.
On the other hand, thetesting of a dialogue system is cumbersomeand expensive.
Factors like the effectivenessand naturalness of the system, as well as ro-bustness are problematic to evaluate.
Whiletest suites for analysis components have beenaround for a while, their counterparts for di-alogue managers (henceforth DM) are (to ourknowledge) non existent.
Evaluation as suchhas been target for a lot of rm3earch.
Recentlymore or less automatic testing and evaluationThe authors wishes to thank Raft Engel for helpwith the ~plementation a d Norbert Reithinger,Tilmau Becket, Christer Samuelsson and ThorstenBrantz for comments on earlier drafts and fruitful dis-cussions.methods has been proposed (e.g.
(Eckert etal., 1998; Scheffier and Young, 2000; Lin andLee, 2000)).A special problem for the development andtesting of a DM is that one often has towait until the whole system (including speechrecognizer(s) and synthesis, parser/generatoretc.)
has been integrated.
Moreover, to testthe complete system one usually has to putpeople (e.g.
the system developers or betatesters) in front of the system, feeding it with"appropriate input."
Using the developers ofthe system as testers has the potential dis-advantage that the system will just be testedwith the type of phenomena or dialogues thedeveloper has in mind.
(S)he also has knowl-edge about the internals of the system andthis can influence the testing in unpredictableways (Araki and Doshita, 1997).
Another im-portant factor for the testing of DMs con-cerned with spoken input is speech recogni-tion errors and their effects on the input.As we started this project, the followinggoals and experiences guided us:?
It is cumbersome to test the DM withthe complete system at hand.
Althoughthis testing is necessary, we would like tominimize  the test effort necessary.?
We must reach a status of the DM whereit is as error  free as possible.
Theremust not be any technical bugs in theprogram itseff as well as logical bugs, orput in other words: The DM must notfail on any input.?
Peop le  behave  weird (Eckert eta l .
,1995).
To us there is no hard border-line between legal moves and non legal160moves in a dialogue.
Some moves makemore sense than others, but can the userbe obliged to say only certain things ata certain point in a conversation?
Wethink not!
A dialogue system should beable to react on any input, how weird itmight be.?
Speech Recognizers makes errors.For our dialogue system with a large vo-cabnlary, the recognition rate drops tobetween 70 and 80% for certain problem-atic speakers.
Consequently every fourthor fifth word can be wrong.
An averageuser contribution contains 5words in theapplication we refer to here (Ehrlich etal., 1997), not including single-word ut-terances in the calculation.Thus, every utterance may contain afalsely recognized word that may or maynot be important for parsing or semanticconstruction.To overcome some of the problems tatedabove and to find errors as early as possi-ble during the course of developing a dialoguesystem, we have developed a validation tool- VALDIA - for the automatic testing of theDM.
The overall goal we had in mind was tobe able to obtain a status of the DM such thatit at least does not contain any loops or otherfatal (trivial) dialogue strategy errors.
To be-come independent of the completion statusof the overall system, we decided to peel theinterfacing components (parser, generator,...)away from the DM.
We now view the DM asa black box.
This black box is then fed withrandom generated input in some interface lan-guage and we observe how the DM reacts onthe given input.
An important prerequisite isof course that the interface between the anal-ysis component and the DM is defined.At this point we would like to emphasizethat our dialogue system is not modeled with"finite state dialogue structure" and "allow-able syntax" for each state as described in(Scheffier and Young, 2000).
In our view sucha system is simple to test, since the systemwill just recognize those utterances it is de-signed to process.
In such a scenario ne canuse the dialogue model for, e.g., enumeratingevery possible dialogue or generate "coher-ent" dialogues.
On the other hand, our sys-tem puts no limits on what is allowed to say ata certain point in the dialogue, which makesthe task of automatic testing non-trivial.Ideally one would want to perform an ex-haustive testing the DM with, say, all possibledialogues, i.e., sequences ofuser contributionsand the respective system reactions.
Usercontributions are supposed to have a maxi-mum length in terms of semantic items.
Aninvestigation of the complexity of the numberof possible utterances (in terms of combina-tions of semantic expressions) and resultingpossible dialogues howed that for our DM,the testing task is so complex that the uni-verse of possible semantic expressions cannotbe tested in a reasonable amount of time (seeSection ??
).Looking at the complexity of the task oneis tempted to ask - "is it possible to exhaus-tively produce all possible dialogues of a cer-tain length?"
Or maybe more interesting:"can we feed the DM with all the generateddialogues?"
In (Levin and Pieracciui, 1997)a sketch of a method to find good dialoguestrategies was put forward.
The authors ar-gue that a dialogue system can be modeledin terms of a state space, an act ion set anda strategy.
They show how one could auto-matically find an optimal strategy by feedingthe system with all possible dialogues, or inour terminology sequences of user contribu-tions.
We took the natural continuation ofthis: to automatically generate user contribu-tions or dialogues and feed them to the sys-tem, and then let the system find the optimalstrategy itself.
In this paper we explore someaspects and limitations of such an approachby analyzing the complexity of dialogues.
Wewill, for instance, show that even if a dialoguemanager can process one or ten or even onehundred user contribution(s) per second wecannot find an optimal strategy based on ex-haustive search - the search space is simplytoo large!The paper starts with a brief description ofthe architecture of the DM and the test envi-161I Speaker ~IAucllo ~ independent I woral -xn Speech LatticeRecognitionI -I Audlo Syn.t,h : Synthesis -Parsingenotion I fDialogManagerFigure 1: Schematic architecture for our dialogue system.ronment for VALDIA, and a description of itsinput format.
We then discuss the complexityof an utterance, continuing with the complex-ity of dialogues.
Finally, VALDIA is describedin more detail and then the paper is closed bya discussion of relevant results and papers.2 Arch i tec tureThe dialogue system to which we first appliedVALDIA (Heister~mp and McGlashan, 1996;Ehrlich et al, 1997) was designed for answer-ing questions about and/or selling insurancesin the domain of car insurances.
In case of.failure or problems with the dialogue, the sys-tem passes the customer to a human opera-tor.
The architecture of the system includesan HMM-based speaker independent speechrecognizer, an island parser, DM, generatorand synthesizer as depicted in figure 1.
Thesystem also includes a data base which is ac-cessed for the retrieval of domain specific in-formation.
It is important for this paper thatthe speech recognizer is not limited to "al-lowed user contributions" but outputs a wordhypotheses lattice or the best; chain which isprocessed by an island parser.
Thus, the in-put to the DM might, depending on recogni-tion quality, consist of arbitrary sequences ofsemantic expressions.
A basic requirement isthat the DM is not allowed to fail on any ofthese inputs.For testing, we peel the interfacing compo-nents away from the DM and regard the DMas a black box.
It is assumed that we senda piece of input to the DM which then re-acts in a way we can observe (for instance byreturnlng/generating some output).
We as-sume that the DM has no notion of time.
Thismean.q that to test the DM, we simply have tofeed it with input and wait for it to acknowl-edge this by sending a responsive output re-quest.
In looking at the response, however,we have to be sensitive to effects like timeout(e.g., the DM is "thinking" too long) and/orloops (e.g., the DM outputs the same item allthe time).
Although in (Levin and Pieraccini,1997) the utterances triggering the actions arenot mentioned at all, this is very important.In general we don't know which utterance willtrigger a certz.in action when the DM is in acertain state, or if the DM needs an utter-ante at all to perform another action.
As theexhaustive validation criteria for the DM donot allow us to assume any insight into theDM itself, we have to simply feed it with allpossible sequences of utterances.Our test architecture is shown in figure 2.We connect o the DM at the same place asthe analysis.
We also watch the output sentto the generator.
Additionally we watch theprocess tatus of the DM, that is we notice ifthe DM fails or breaks.
In that case we canrestart he DM and continue the testing.3 Complex i tyThis section puts forward some notes on thecomplexity of dialogue.
We are aware that thediscussion and the results are not necessar-162ValDia s,~,~,mtic i "~l= !l|!|s ?|Black BoxIIIIiDialog @ )Manager|!
!|m|i|m iFigure 2: Schematic architecture for ValDia.ily generalizable because they depend on therepresentation f the input formalism to theDM.
However, we were certainly surprised bythe results ourselves and it has consequencesfor the degree of coverage and testing one canachieve.
For our dialogue system the seman-tic representation formalism is simple.
It con-sists of propositional content represented assequences of semantic objects the SIL 1 repre-sentation language (McGlashan et al, 1994).Here is one example: "Ein Audi 80 AvantQuattro mit ber 100 PS" "An Audi 80 Sta-tion Wagon Jx4 with over 100 hp"\[ \[type : car_type,\[l;hemake : manu?
acturer ,value :aud?\],\[thetype: type_name,value: achtzig\],\[theversion: version_name,value: avant\],\[thespecial?eature :feature_name,value : quattro\],def : indef\],\[type: power,themeasuretype : ps,thevalue: \[type: number,cvalue: 125,modus: \[rel : above\] \],modus : Ire1: with\] \] \]This representation is motivated by the factthat the analysis component is an island1 Semantic Interface Languageparser (Hanrieder, 1996), and can thus findislands or sequences of semantic objects.3.1 The complexi ty  of  an ut teranceThe basic entity is a semantic object (S)which is an atomic item treated by the DM.The DM knows about (and thus can treat orreact on) M different semantic objects.
Ex-amples of a semantic object are cmc_type,power, greet ing ,  bye, in teger ,  and year.We will not pay attention to the fact that a se-mantic item could be instantiated with, e.g., astreet name - in the navigation domain thereexist about 42,000 different names of citiesin Germany, and Berlin has 11,500 differentstreet names - but we could of course extendthe discussion below (on the cost of complex-ity).We call a user contribution an utterance.We assume that an utterance U is a (possi-bly empty) sequence of semantic objects.
Thiscan of course be relaxed to sequences or treesin some algebra, but for this discussion it suf-rices to deal with sequences - as we will see,the complexity is "complex enough" with thisassumption.
A sentence can consist of max Onumber of semantic objects.
An utterance isa multi-set in the real system, but for this dis-cussion we assume an utterance is not.
Eachsemantic object can therefore appear at mostone time.
Given the definitions above we cannow compute the number of possible utter-ances \[ U \[: All sequences of a certain length163l areWe therefore haveIvlFor one of our dialogue models, concernedwith car insurance, we have M = 25 andO = 9.
That  is, 25 different semantic ob-jects and we allow for a maximum of 9 se-mantic items (arbitrarily chosen by estimateof breath length) in one utterance:{ U I = 1.9.109Now, if we would like to test whether ourDM can treat all utterances or not, we willhave to wait quite a while: Suppose our DMcan process 10 utterances per second, thenwe can process 10-60-60  = 36000 utter-ances per hour, 36000 - 24 = 864000 utter-ances per day, 7.
864000 = 6048000 per week,or 864000.
365 = 315360000 utterances peryear.
To process all possible utterances wewould need more than six years!..
:, Obviously, the current parameters of thesystem make the complexity of the numberof utterances intractable in realistic settings.Figure 3 shows how different parameter set-t ing affects the cardinality of utterances fordifferent values of M. The (logarithmic) y-axis represents the cardinality of utterances,and the (linear) x-axis the maximal numberof semantic items in one utterance.
As can beseen, for our DM, we will have to limit, e.g.,the number of semantic items to 6 per utter-ance if we want to test all utterances in oneweek.3.2 The  complex i ty  o f  d ia logueA dialogue can - at least theoretically - con-sist of a sequence of the same utterance.Many of the dialogues will of course be non-cooperative and very lmnatural  or, put inother words, not legal.
But, as indicatedabove, it is important o us tlhat the DM doesnot fail on any input.
To generate all possi-ble dialogues I D I of a certain length L, wetherefore have:IDl=lvl.lul.....Iv!=L times IuJ LFor our scenario 15 user contributions arenot unnatural, so for L = 15 and the fig-ures above, we have I D I ~ 1014?
which willtake quite a while to process 2.
Even ff we re-strict the length of the dialogues to 2, we get1.9 ?
109 ?
1.9 ?
109 = 3.6 ?
l018 theoreticallypossible dialogues and can thus process justan infinitely small part of them.3.3 ConsequencesNow, suppose we randomly select some dia-logues out of the set of possible ones.
Whiletesting the DIALOGUE MANAGER with themwe thereby encounter a certain number of (oreven zero) errors, it is interesting to be able tosay something about how error-free the DMis.
For this discussion, it is important hatby viewing the DM as a black box, we cannot do anything more than assuming the er-rors to be distributed according to the nor-real distribution.
Moreover, we can only ap-ply this reasoning if we do a large numberof observations.
The figures below may -depending on the theoretical number of di-alogues - not be valid.
By using the approx-hnation of the normal distribution we knowthat if we tested N = 10000 dialogues andreceived errors in DM in, say, 250 of the di-alogues (-,z f = 2so = 0.025), we can say Y~6that the DM contains (with a degree of con-fidence of 95%)= = s*  1.96 ?
=0.025 .1 .96  ?0.025 :t: 0.003percent errors.In case no errors were found we getE=0: t= l -96?v ioo0o =0=t=0.2The exact number is 218467145894026153006277149050004422653349789248729589853552333475097?413049977260703865149482807002256877156526344377571018487670988739143 :-)164le+09le+08le+07le+0610000010000Z1000100101complexity utterances4 6 8 10Sem Objects/UtteranceFigure 3: Utterance Complexity.Here we have to use a trick: Instead we sup-pose we found one error, and thus/ = 1/10000 = O.O001yielding,/o.b0o~?
(1-o.oool) E = 0.0001 :i: 1.96 x v 10000 =1.96 ?
10 -4 ~ 1.0- 10 -6we can at least say that we are 95% confidentthat the DM will in less than1.96.10 -4 + 1.0.10 -6 = 1.97- 10-4%cases raise an error.4 VALDIA - The  Imp lementat ionTo allow for intelligent esting, we decided toimplement our test tool in using the followingthree parts:?
the core test engine,?
the interface to the DM (implemented inOZ/MOZARTa) ,  andaThe reason for using OZ is manifold: OZ fea-tures threads, multiple platforms (UNIX/LINUX andWindows), nniRcation, a Td/Tk library, and finally itcomes for fzee.
See hl;tp://www .mozart-oz.
org?
a graphical editor for the definitionof stochastic automata (implemented inTc l /Tk) ,The core test engine uses the definition ofstochastic automata  to create sequences of se-mantic expressions to be sent to the DM.
Itrecords both the input and the output to andfrom the DM and checks for special messages(e.g.
end of dialogue), crashes, if the DM isemitt ing the same response all the time, orother events events that indicate erroneousbehaviour of the DM.
It also creates test pro-files and checkpoint files to enable interrup-tion and restart of test runs.The interface handles the connection be-tween VALDIA and the DM.
It realizes aTCP/ IP  connection to and from the DM.
Incase parallel test runs are made, it can alsohandle different processes.The motivation for the stochastic automa-ton editor and, at the same time, the mainfeature of VALDLA (see Figure 4) is that itallows for the design of utterances or even di-alogues or utterance sequences, and thus testspecific areas in the space of theoretically pos-sible dialogues.
The dialogue system devel-165Figure 4: Screen shot of the automata editoroper can interactively define the automata,using the pointing device to draw the statesan the transitions.
In each state, it is possi-ble to change the constraints for the defini-tion of a SIL expression.
More precisely wechange the probalrility of the alternatives of(a part of) an expression.
The arcs betweenthe states are augmented with probabilitieswhich guide state transitions in a stochasticm~uner, thus creating certain sequences bypreference, without completely excluding oth-ers.
In Figure 5 the left row contaius the basicsemantic entities, the middle the probability,and the right one the number of occurrencesfor that particular semantic item in each ut-terance.
For the semantic items the variableparts are linked to another window where the ....their instantiations are described.
The con-straints are semi-automatically derived fromthe definition of the interface specification forthe DM.
The reason for "semi-automatically"and not automatically is that we have hadno time to write a generic function for this.But, basically the derivation is straightfor-ward.
Consequently we can design interestingutterance sequences, according to, e.g., expe-riences gained during WOZ-experhnents-166Figure 5: Part of the constraints of an utteranceFinally, by using just one state and noconstraints, we can, of course, produce com-pletely arbitrary utterance sequences.During the testing of the dialogue managerwe can run the system in two modes.
Thefirst - exhaustive mode - generates all se-quences of dialogues by enumerating all di-alogues.
This is based on the enumerationof all possible utterances in each state.
Theexhaustive mode can be used when we knowthat the complexity of the automaton (andutterances) is testable - VALDIA can com-pute the number of dialogues and computean upper time limit based on the computa-tional power of the DM.
In the second mode -Monte Carlo mode - the utterance generationin each state as well as the change of state israndom.
In this way we randomly wa.lk~ theautomaton and randomly generate utteranceprofiles.
This has been proven useful in thecases where we number of possible dialoguesto large is for exhaustive t sting.Notice that we can not pay any attentionto legal moves.
VALDIA has (i) no knowledgeabout what a legal move is, and (ii) no possi-bility to react on the response from the DM.Therefore the "legal moves" and "coopera-tiveness" is non existent concepts here.
But,this is what we want: People behave weird!Our speech recognizer produces errors!
And167most important: We have to live with this,and must not fail on any input!5 F i r s t  Resu l tsDuring the development of VALDIA we havedetected several errors in the implementationof our DM.
Most of the errors where logical er-rors of the kind "Now that's a combination ofthings we didn't cover."
e.g., the co-occurenceof good_bye and request_ repet i t ion  i auser utterance led to a goal conflict in theDM that caused it to hang, as did the non-exclusive handling of disjunction in "It's older(or) younger than 5 years", etc.Additionally we discovered that the DM insome of the test runs crashed ~ffter about 500(l) dialogues due to erroneous memory han-dling.
This is something one would never de-tect during normal testing with a full system,but immediately after delivering the system.VALDIA produces huge amounts of (huge)trace files.
Analyzing these is at present apain as big as testing the complete dialoguesystem.
Consequently, we will have to de-velop functionality for condensing the traceinformation.6 Conc lus ion-The project VALDIA has produced useful in-sights into the complexity of dialogue: Spokendialogue is very complex!
Exhaustive testingof a DM is for some scenarios/dialogue modelsimpossible.
The results were obtained uringthe development of a test program for a DM.Purpose of the testing was to be able to in-tegrate a DM into the dialogue system whichcontained as few errors as possible.
We wouldlike to highlight the following points:?
VALDIA has proven its usefulness in thatit is able to detect errors in the imple-mentation of DMs before', it is integratedinto the complete dialogue system.
Dur-ing the testing we encountered, in addi-tion to logical bugs, errors which wouldnever be detected uring normal testingwith the complete dialogue system.?
By including the automata into Vm.,-DIA it is possible to concentrate he test-ing on "interesting utterance sequences"and, despite the huge universe of theoret-ically possible dialogues, obtain a statusof the DM which for certain tasks is welltested.It is simple to adapt for the testingof a new DM.
Technically the onlything that has to changed is the def-inition/constraints of the definition ut-terances.
This is at present a semi-automatic process.
Conceptually the au-tomata has to be defined, unless onewants to test in Monte Carlo mode.In the current implementation VALDIAuses about 10% of the processing timecompared to the DM.
Thus VALDIA cancontrol between 5 and 10 instances of theDM depending on available resources inthe net.VALDIA is platform independent.
At oursite, we are using a mixture of differ-ent types of computers, both PCs run-ning under Windows/Linux and UNIXmachines.
Depending on load, we areflexible to utilize any of the free resourcesfor the testing.We are currently in the process of adaptingVALDIA for a new scenario.
For this DM in-put consists of grammatical structures, ratherthan sets of semantic objects.
Since the VAL-DIA project started, interesting research re-sults have emerged and there are lot of thingsthat remain to be done.
Amongst those, wewill pay attention to at least the following top-ics:The current implementation of VALDIAhas no means of react on the output fromthe DM.
For intelligent testing this has tobe incorporated into the system.
Possiblefuture directions are described in (Eckertet al, 1998), (Schefiler and Young, 2000)and (Lin and Lee, 2000).
In, e.g., (Eck-eft et al, 1998) VALDIA is replaced by ansimulated user, and the authors describea statistical method for reacting on sys-tem responses.168* We have to develop a tool for semi-automatically anaJyzing the trace filesproduced by VALDIA.
Possible futurefeatures are just saving the files of thosedialogues/utterances which resulted inan error.Re ferencesMasabiro Araki and Shuji Doshita.
1997.
Au-tomatic evaluation environment for spoken di-alogue systems.
In Elisabeth Maler, MarionMast, and Susann LuperFoy, editors, Re-vised papers from the ECAL96 Workshop inBudapest, Hungary on Dialogue Processing inSpoken Language Systems, Heidelberg, Au-gust.
Lecture Notes in Artificial InteUigence,Springer-Verlag.Wieland Eckert, Elmar N5th, Heinrich Niemann,and Ernst-G/inter Schukat-Talamazzini.
1995.Real users behave weird - experiences made col-lecting large human-machine-dialog c rpora.
InPaul Dalsgaard, Lars Bo Larsen, Louis Boves,and Ib Thomsen, editors, Proceedings oS ESCATutorial and Research Workshop on Spoken Di-alogue Systems '95, VigsS, Denmark.Wieland Eckert, Esther Levin, and Roberto Pier-accini.
1998.
Automatic Evaluation of Spo-ken Dialogue System.
Technical report, AT&T.Technical Report Nr.
TR98.9.1.Ute Ehrlich, Gerhard Hanrieder, Ludwig Hitzen-berger, Paul Heisterkarnp, Klaus Mecklenburg,and Peter Regel-Brietzmann.
1997.
Access -automated call center through speech under-standing system.
In Proceedings of Eurospeech'97, Rhodes.Gerhard Hanrieder.
1996.
InkrementellesParsing gesproehener Sprache mit einerlinksassoziativen Unifikationsgrammatik~Ph.D.
thesis, Universit~it Erlangen-N~u'nberg.http://www.infix.com - ISBN 3.-89838-140-4.Paul Heisterkamp and Scott McGlashan.
1996.Units of Dialogue Management: An Example.In Proceedings of ICSLP-96, Philadelphia, PA,October.Esther Levin and Roberto Pieraccini.
1997.
Astochastic model of computer-human interac-tion for learning dialogue strategies.
In Pro-ceedings of EuroSpeech-gZ Rhodes.Bor-schen Lin and Lin-shan Lee.
2000.
Fun-damental performance analysis for spoken di-alogue system based on a quantitative simula-tion approach.
In Proceedings of ICASSP-2OO0,Istanbul, Turkey, June 5-9.Scott McGlashan, Francois Andry, and GerhardNiedermalr.
1994.
A Proposal for SIL.
Tech-nical report, University of Surrey, CAP SOGETI,and Siemens AG, March.
SUNDIAL report.Konrad Scheffier and Steve Young.
2000.Probablistic simulation of human-machine di-alogues.
In Proceedings o\] ICASSP-2000, Is-tanbul, Turkey, June 5--9.169
