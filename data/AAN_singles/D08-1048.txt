Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 457?465,Honolulu, October 2008. c?2008 Association for Computational LinguisticsAutomatic induction of FrameNet lexical unitsMarco Pennacchiotti(?
), Diego De Cao(?
), Roberto Basili(?
), Danilo Croce(?
), Michael Roth(?)(?)
Computational LinguisticsSaarland UniversitySaarbru?cken, Germany{pennacchiotti,mroth}@coli.uni-sb.de(?)
DISPUniversity of Roma Tor VergataRoma, Italy{decao,basili,croce}@info.uniroma2.itAbstractMost attempts to integrate FrameNet in NLPsystems have so far failed because of its lim-ited coverage.
In this paper, we investigate theapplicability of distributional and WordNet-based models on the task of lexical unit induc-tion, i.e.
the expansion of FrameNet with newlexical units.
Experimental results show thatour distributional and WordNet-based modelsachieve good level of accuracy and coverage,especially when combined.1 IntroductionMost inference-based NLP tasks require a largeamount of semantic knowledge at the predicate-argument level.
This type of knowledge allows toidentify meaning-preserving transformations, suchas active/passive, verb alternations and nominal-izations, which are crucial in several linguistic in-ferences.
Recently, the integration of NLP sys-tems with manually-built resources at the predi-cate argument-level, such as FrameNet (Baker etal., 1998) and PropBank (Palmer et al, 2005) hasreceived growing interest.
For example, Shen andLapata (2007) show the potential improvement thatFrameNet can bring on the performance of a Ques-tion Answering (QA) system.
Similarly, severalother studies (e.g.
(Bar-Haim et al, 2005; Garoufi,2007)) indicate that frame semantics plays a centralrole in Recognizing Textual Entailment (RTE).
Un-fortunately, most attempts to integrate FrameNet orsimilar resources in QA and RTE systems have sofar failed, as reviewed respectively in (Shen and La-pata, 2007) and (Burchardt and Frank, 2006).
Thesestudies indicate limited coverage as the main reasonof insuccess.
Indeed, the FrameNet database onlycontains 10,000 lexical units (LUs), far less thanthe 210,000 entries in WordNet 3.0.
Also, framesare based on more complex information than wordsenses, so that their manual development is muchmore demanding (Burchardt et al, 2006; Subiratsand Petruck, 2003).Therefore, there is nowadays a pressing need toadopt learning approaches to extend the coverageof the FrameNet lexicon by automatically acquiringnew LUs, a task we call LU induction, as recentlyproposed at SemEval-2007 (Baker et al, 2007).
Un-fortunately, research in this area is still somehowlimited and fragmentary.
The aim of our study isto pioneer in this field by proposing two unsuper-vised models for LU induction, one based on dis-tributional techniques and one using WordNet as asupport; and a combined model which mixes thetwo.
The goal is to investigate to what extent distri-butional and WordNet-based models can be used toinduce frame semantic knowledge in order to safelyextend FrameNet, thus limiting the high costs ofmanual annotation.In Section 2 we introduce the LU induction taskand present related work.
In Sections 3, 4 and 5 wepresent our distributional, WordNet-based and com-bined models.
Then, in Section 6 we report experi-mental results and comparative evaluations.
Finally,in Section 7 we draw final conclusions and outlinefuture work.2 Task Definition and Related WorkAs defined in (Fillmore, 1985), a frame is a con-ceptual structure modeling a prototypical situation,evoked in texts through the occurrence of its lex-ical units.
A lexical unit (LU) is a predicate thatlinguistically expresses the situation of the frame.Lexical units of the same frame share semantic ar-guments.
For example the frame KILLING has lex-ical units such as assassin, assassinate, blood-bath,fatal, murderer, kill, suicide that share semantic ar-guments such as KILLER, INSTRUMENT, CAUSE,VICTIM.
Building on this frame-semantic model,the Berkeley FrameNet project (Baker et al, 1998)has been developing a frame-semantic lexicon for457the core vocabulary of English since 1997.
Thecurrent FrameNet release contains 795 frames andabout 10,000 LUs.
Part of FrameNet is also a cor-pus of 135,000 annotated example sentences fromthe British National Corpus (BNC).LU induction is a fairly new task.
Formally,it can be defined as the task of assigning ageneric lexical unit not yet present in the FrameNetdatabase (hereafter called unknown LU) to the cor-rect frame(s).
As the number of frames is verylarge (about 800) the task is intuitively hard to solve.A further complexity regards multiple assignments.Lexical units are sometimes ambiguous and can thenbe mapped to more than one frame (for examplethe word tea could map both to FOOD and SO-CIAL EVENT).
Also, even unambiguous words canbe assigned to more than one frame ?
e.g.
child mapsto both KINSHIP and PEOPLE BY AGE.LU induction is relevant to many NLP tasks, suchas the semi-automatic creation of new FrameNets,and semantic role labelling.
LU induction has beenintegrated at SemEval-2007 as part of the Frame Se-mantic Structure Extraction shared task (Baker etal., 2007), where systems are requested to assignthe correct frame to a given LU, even when theLU is not yet present in FrameNet.
Johansson andNugues (2007) approach the task as a machine learn-ing problem: a Support Vector Machine trained onexisting LUs is applied to assign unknown LUs tothe correct frame, using features derived from theWordNet hierarchy.
Tested on the FrameNet goldstandard, the method achieves an accuracy of 0.78,at the cost of a low coverage of 31% (i.e.
many LUsare not assigned).
Johansson and Nugues (2007)also experiment with a simple model based on stan-dard WordNet similarity measures (Pedersen et al,2004), achieving lower performance.
Burchardt andcolleagues (2005) present Detour, a rule-based sys-tem using words in a WordNet relation with the un-known LU to find the correct frame.
The systemachieves an accuracy of 0.39 and a coverage of 87%.Unfortunately this algorithm requires the LU to bepreviously disambiguated, either by hand or usingcontextual information.In a departure from previous work, our first modelleverages distributional properties to induce LUs, in-stead of relying on pre-existing lexical resources asWordNet.
This guarantees two main advantages.First, it can predict a frame for any unknown LU,while WordNet based approaches can be appliedonly to words having a WordNet entry.
Second, itallows to induce LUs in languages for which Word-Net is not available or has limited coverage.
Oursecond WordNet-based model uses sense informa-tion to characterize the frame membership for un-known LU, by adopting a semantic similarity mea-sure which is sensitive to all the known LUs of aframe.3 Distributional modelThe basic idea behind the distributional approach isto induce new LUs by modelling existing frames andunknown LUs in a semantic space, where they arerepresented as distributional co-occurrence vectorscomputed over a corpus.Semantic spaces are widely used in NLP for rep-resenting the meaning of words or other lexical en-tities.
They have been successfully applied in sev-eral tasks, such as information retrieval (Salton et al,1975) and harvesting thesauri (Lin, 1998).
The intu-ition is that the meaning of a word can be describedby the set of textual contexts in which it appears(Distributional Hypothesis (Harris, 1964)), and thatwords with similar vectors are semantically related.In our setting, the goal is to find a semantic spacemodel able to capture the notion of frame ?
i.e.
theproperty of ?being characteristic of a frame?.
Insuch a model, an unknown LU is induced by firstcomputing the similarity between its vector and thevectors of the existing frames, and then assigning theLU to the frame with the highest similarity.3.1 Assigning unknown LUs to framesIn our model, a LU l is represented by a vector ~lwhose dimensions represent the set of contexts Cof the semantic space.
The value of each dimen-sion is given by the co-occurrence value of the LUwith a contextual feature c ?
C, computed over alarge corpus using an association measure.
We ex-periment with two different association measures:normalized frequency and pointwise mutual infor-mation.
We approximate these measures by usingMaximum Likelihood Estimation, as follows:458F (l, c) =MLE |l, c||?, ?|MI(l, c) =MLE |l, c||?, ?||?, c||l, ?|(1)where |l, c| denotes the co-occurrence countsof the pair (l, c) in the corpus, |?, c| =?l?L |l, c|, |l, ?| =?c?C |l, c| and finally |?, ?| =?l?L,c?C |l, c|.A frame f is modeled by a vector ~f , representingthe distributional profile of the frame in the seman-tic space.
We here assume that a frame can be fullydescribed by the set of its lexical units F .
We imple-ment this intuition by computing ~f as the weightedcentroid of the set F , as follows:~f =?l?Fwlf ?~l (2)where wlf is a weighting factor, accounting forthe relevance of a given lexical unit with respect tothe frame, estimated as:wlf = |l|?l?F|l|(3)where |l| denotes the counts of l in the corpus.From a more cognitive perspective, the vector ~f rep-resents the prototypical lexical unit of the frame.Given the set of all framesN and an unknown lex-ical unit ul, we assign ul to the frame fmaxul whichis distributionally most similar ?
i.e.
we intuitivelymap an unknown lexical unit to the frame whoseprototypical lexical unit ~f has the highest similaritywith ~ul:fmaxul = argmaxf?N simD(~ul, ~f) (4)In our model, we used the traditional cosine simi-larity:simcos(ul, f) =~ul ?
~f|~ul| ?
|~f |(5)3.2 Choosing the spaceDifferent types of contexts C define spaces with dif-ferent semantic properties.
We are here looking fora space able to capture the properties which charac-terise a frame.
The most relevant of these propertiesis that LUs in the same frame tend to be either co-occurring or substitutional words (e.g.
assassin/killor assassinate/kill) ?
i.e.
they are either in paradig-matic and syntagmatic relation.
In an ideal space,a high similarity value simD would be then givenboth to assassinate/kill and to assassin/kill.
We ex-plore three spaces which seem to capture the aboveproperty well:Word-based space: Contexts are words appear-ing in a n-window of the lexical unit.
Such spacesmodel a generic notion of semantic relatedness.Two LUs close in the space are likely to be re-lated by some type of generic semantic relation,either paradigmatic (e.g.
synonymy, hyperonymy,antonymy) or syntagmatic (e.g.
meronymy, concep-tual and phrasal association).1Syntax-based space: Contexts are syntactic re-lations (e.g.
X-VSubj-man where X is the LU), asdescribed in (Pado?, 2007).
These spaces are goodat modeling semantic similarity.
Two LUs close inthe space are likely to be in a paradigmatic relation,i.e.
to be close in a is-a hierarchy (Budanitsky andHirst, 2006; Lin, 1998; Pado?, 2007).
Indeed, as con-texts are syntactic relations, targets with the samepart of speech are much closer than targets of differ-ent types.Mixed space: In a combination of the two abovespaces, contexts are words connected to the LU by adependency path of at most length n. Unlike word-based spaces, contexts are selected in a more princi-pled way: only syntactically related words are con-texts, while other (possibly noisy) material is filteredout.
Unlike syntax-based spaces, the context c doesnot explicitly state the type of syntactic relation withthe LU: this usually allows to capture both paradig-matic and syntagmatic relations.4 WordNet-based modelIn a departure from previous work, our WordNet-based model does not rely on standard WordNet sim-ilarity measures (Pedersen et al, 2004), as thesemeasures can only be applied to pairs of words,while we here need to capture the meaning of wholeframes, which typically consist of larger sets of LUs.Our intuition is that senses able to evoke a frame canbe detected via WordNet, by jointly considering theWordNet synsets activated by all LUs of the frame.We implement this intuition in a weakly-supervised model, where each frame f is repre-sented as a set of specific sub-graphs of the WordNet1See (Pado?, 2007; Sahlgren, 2006) for an in depth analysis.459hyponymy hierarchy.
As different parts of speechhave different WordNet hierarchies, we build a sub-graph for each of them: Snf for nouns, Svf for verbsand Saf for adjectives.2 These sub-graphs repre-sent the lexical semantic properties characterizingthe frame.
An unknown LU ul of a given part ofspeech is assigned to the frame whose correspond-ing sub-graph is semantically most similar to one ofthe senses of ul:fmaxul = argmaxf?N simWN (ul, f) (6)where simWN is a WordNet-based similaritymeasure.
In the following subsections we will de-scribe how we build sub-graphs and model the sim-ilarity measure for the different part of speech.Figure 1 reports an excerpt of the noun sub-graph for the frame PEOPLE BY AGE, cover-ing the suitable senses of its nominal LUs{adult, baby, boy, kid, youngster, youth}.
Therelevant senses (e.g.
sense 1 of youth out of the 6potential ones) are generally selected, as they sharethe most specific generalizations in WordNet withthe other words.Nouns.
To compute similarity for nouns we adoptconceptual density (cd) (Agirre and Rigau, 1996),a semantic similarity model previously applied toword sense disambiguation tasks.Given a frame f and its set of nominal lexicalunits Fn, the nominal subgraph Snf is built as fol-lows.
All senses of all words in Fn are activatedin WordNet.
All hypernyms Hnf of these senses arethen retrieved.
Every synset ?
?
Hnf is given a cdscore, representing the density of the WordNet sub-hierarchy rooted at ?
in representing the set of nounsFn.
The intuition behind this model is that the largerthe number of LUs in Fn that are generalized by ?
is,the better it captures the lexical semantics intendedby the frame f .
Broader generalizations are penal-ized as they give rise to bigger hierarchies, not wellcorrelated with the full set of targets Fn.To build the final sub-graph Snf , we apply thegreedy algorithm proposed by Basili and colleagues(2004).
It first computes the set of WordNet synsetsthat generalize at least two LUs in Fn, and then se-lects the subset of most dense ones Snf ?
Hnf that2Our WordNet model does not cover the limited number ofLUs which are not nouns, verbs or adjectives.cover Fn.
If a LU has no common hypernym withother members of Fn, it is not represented in Snf , andits similarity is set to 0 .
Snf disambiguates words inFn as only the lexical senses with at least one hyper-nym in Snf are considered.Figure 1 shows the nominal sub-graph automati-cally derived using conceptual density for the framePEOPLE BY AGE.
The word boy is successfully dis-ambiguated, as its only hypernym in the sub-graphrefers to its third sense (a male human offspring)which correctly maps to the given frame.
Noticethat this model departs from the first sense heuris-tics largely successful in word sense disambigua-tion: most frames in fact are characterized by nonpredominant senses.
The only questionable disam-biguation is for the word adult: the wrong sense(adult mammal) is selected.
However, even in thesecases, the cd values are very low (about 10?4), sothat they do not impact much on the quality of theresulting inference.Figure 1: The noun sub-graph for the frame PEO-PLE BY AGE as evoked by a subset of the words.
Sensenumbers #n refers to WordNet 2.0.Using this model, LU induction is performed asfollows.
Given an unknown lexical unit ul, for eachframe f ?
N we first build the sub-graph Snf fromthe set Fn ?
{ul}.
We then compute simWN (f, ul)as the maximal cd of any synset ?
?
Snf that gener-alizes one of the lexical senses of ul.
In the examplebaby would receive a score of 0.117 according to itsfirst sense in WordNet 2.0 (?baby,babe,infant?).
Ina final step, we assign the LU to the most similarframe, according to Eq.
6Verbs and Adjectives.
As the conceptual densityalgorithm can be used only for nouns, we apply dif-ferent similarity measures for verbs and adjectives.460For verbs we exploit the co-hyponymy relation:the sub-graph Svf is given by all hyponyms of allverbs Fv in the frame f .
Similarity simWN (f, ul)is computed as follows:simWN (ul, f) =??????
?1 iff ?K ?
F such that|K| > ?
AND?l ?
K, l is a co-hyponym of ul?
otherwise(7)As for adjectives, WordNet does not provide a hy-ponymy hierarchy.
We then compute similarity sim-ply on the basis of the synonymy relation, as fol-lows:simWN (ul, f) =??
?1 iff ?l ?
F such thatl is a synonym of ul?
otherwise(8)5 Combined modelThe methods presented so far use two independentinformation sources to induce LUs: distributionalsimilarity simD and WordNet similarity simWN .We also build a joint model, leveraging both ap-proaches: we expect the combination of differentinformation to raise the overall performance.
Wehere choose to combine the two approaches using asimple back-off model, that uses the WordNet-basedmodel as a default and backs-off to the distributionalone when no frame is proposed by the former.
Theintuition is that WordNet should guarantee the high-est precision in the assignment, while distributionalsimilarity should recover cases of low coverage.6 ExperimentsIn this section we present a comparative evaluationof our models on the task of inducing LUs, in aleave-one-out setting over a reference gold standard.6.1 Experimental SetupOur gold standard is the FrameNet 1.3 database,containing 795 frames and a set L of 7,522 uniqueLUs (in all there are 10,196 LUs possibly assignedto more than one frame).
Given a lexical unit l ?
L,we simulate the induction task by executing a leave-one-out procedure, similarly to Burchardt and col-leagues (2005).
First, we remove l from all its origi-nal frames.
Then, we ask our models to reassign it tothe most similar frame(s) f , according to the simi-larity measure3.
We repeat this procedure for all lex-ical units.
Though our experiment is not completelyrealistic (we test over LUs already in FrameNet), ithas the advantage of a reliable gold standard pro-duced by expert annotators.
A second, more re-alistic, small-scale experiment is described in Sec-tion 6.2.We compute accuracy as the fraction of LUs in Lthat are correctly re-assigned to the original frame.Accuracy is computed at different levels k: a LU l iscorrectly assigned if its gold standard frame appearsamong the best-k frames f ranked by the model us-ing the sim(l, f) measure.
As LUs can have morethan one correct frame, we deem as correct an as-signment for which at least one of the correct framesis among the best-k.We also measure coverage, intended as the per-centage of LUs that have been assigned to at leastone frame by the model.
Notice that when nosense preference can be found above the threshold ?,the WordNet-based model cannot predict any frame,thus decreasing coverage.We present results for the following models andparametrizations (further parametrizations have re-vealed comparable performance).Dist-word : the word-based space described inSection 3.
Contextual features correspond to theset of the 4,000 most frequent words in the BNC.4The association measure between LUs and contextsis the pointwise mutual information.
Valid contextsfor LUs are fixed to a 20-window.Dist-syntax : the syntax-based space describedin Section 3.
Context features are the 10,000 mostfrequent syntactic relations in the BNC5.
As associ-ation measure we apply log-likelihood ratio (Dun-ning, 1993) to normalized frequency.
Syntactic rela-tions are extracted using the Minipar parser.Dist-mixed : the mixed space described in Sec-3In the distributional model, we recompute the centroids foreach frame f in which the LU appeared, applying Eq.
2 to theset F ?
{l}.4We didn?t use the FrameNet corpus directly, as it is toosmall to obtain reliable statistics.5Specifically, we use the minimum context selection func-tion and the plain path value function described in Pado (2007).461tion 3.
As for the Dist-word model, contextual fea-tures are 4,000 and pointwise mutual information isthe association measure.
The maximal dependencypath length for selecting each context word is 3.Syntactic relations are extracted using Minipar.WNet-full : the WordNet based model describedin Section 4.WNet-bsense : this model is computed as WNet-full but using only the most frequent sense for eachLU as defined in WordNet.Combined : the combined method presented inSection 5.
Specifically, it uses WNet-full as a defaultand Dist-word as back-off.Baseline-rnd : a baseline model, randomly as-signing LUs to frames.Baseline-mostfreq : a model predicting as best-kframes the most likely ones in FrameNet ?
i.e.
thosecontaining the highest number of LUs.6.2 Experimental ResultsTable 1 reports accuracy and coverage results for thedifferent models, considering only 6792 LUs withfrequency higher than 5 in the BNC, and frameswith more than 2 lexical units (to allow better gen-eralizations in all models).
Results show that all ourmodels largely outperform both baselines, achievinga good level of accuracy and high coverage.
Inparticular, accuracy for the best-10 frames is highenoungh to support tasks such as the semi-automaticcreation of new FrameNets.
This claim is supportedby a further task-driven experiment, in which weasked 3 annotators to assign 60 unknown LUs (fromthe Detour system log) to frames, with and withoutthe support of the Dist-word model?s predictions assuggestions6.
We verified that our model guaranteean annotation speed-up of 25% ?
i.e.
in average anannotator saves 25% of annotation time by usingthe system?s suggestions.Distributional vs. WordNet-based models.WordNet-based models are significantly better thandistributional ones, for several reasons.
First, distri-butional models acquire information only from thecontexts in the corpus.
As we do not use a FrameNetannotated corpus, there is no guarantee that the us-age of a LU in the texts reflects exactly the semantic6For this purpose, the dataset is evenly split in two parts.properties of the LU in FrameNet.
In the extremecases of polysemous LUs, it may happen that thetextual contexts refer to senses which are not ac-counted for in FrameNet.
In our study, we explicitlyignore the issue of polisemy, which is a notoriouslyhard task to solve in semantics spaces (see (Schu?tze,1998)), as the occurrences of different word sensesneed to be clustered separately.
We will approachthe problem in future work.
The WordNet-basedmodel suffers from the problem of polisemy to amuch lesser extent, as all senses are explicitly rep-resented and separated in WordNet, including thoserelated to the FrameNet gold standard.A second issue regards data sparseness.
The vec-torial representation of LUs with few occurrences inthe corpus is likely to be semantically incomplete,as not enough statistical evidence is available.
Par-ticularly skewed distributions can be found whensome frames are very rarely represented in the cor-pus.
A more in-depth descussion on these two issuesis given later in this section.Regarding the WordNet-based models, WNet-fullin most cases outperforms WNet-bsense.
The firstsense heuristic does not seem to be as effective asin other tasks, such as Word Sense Disambigua-tion.
Although sense preferences (or predominance)across two general purpose resources, such as Word-Net and FrameNet, should be a useful hint, the con-ceptual density algorithm seems to produce betterdistributions (i.e.
higher accuracy), especially whenseveral solutions are considered.
Indeed, for manyLUs the first WordNet sense is not the one repre-sented in the FrameNet database.As for distributional models, results show that theDist-word model performs best.
In general, syntac-tic relations (Dist-syntax model) do not help to cap-ture frame semantic properties better than a simplewindow-based approach.
This seems to indicate thatLUs in a same frame are related both by paradig-matic and syntagmatic relations, in accordance tothe definition given in Section 3.2 ?
i.e.
they aremostly semantically related, but not similar.Coverage.
Distributional models show a coverage15% higher than WordNet-based ones.
Indeed, as faras corpus evidence is available (i.e.
the unknown LUappears in the corpus), distributional methods are al-ways able to predict a frame.
WordNet-based mod-462MODEL B-1 B-2 B-3 B-4 B-5 B-6 B-7 B-8 B-9 B-10 COVERAGEDist-word 0.27 0.36 0.42 0.46 0.49 0.51 0.53 0.55 0.56 0.57 95%Dist-syntax 0.22 0.29 0.34 0.38 0.41 0.44 0.46 0.48 0.50 0.51 95%Dist-mixed 0.25 0.35 0.40 0.44 0.47 0.49 0.51 0.53 0.54 0.56 95%WNet-full 0.47 0.59 0.65 0.69 0.72 0.73 0.75 0.76 0.77 0.78 80%WNet-bsense 0.52 0.61 0.64 0.66 0.67 0.68 0.69 0.69 0.70 0.70 72%Combined 0.43 0.54 0.60 0.64 0.66 0.68 0.70 0.71 0.72 0.73 95%Baseline-rnd 0.02 0.03 0.05 0.06 0.08 0.10 0.11 0.12 0.14 0.15Baseline-mostfreq 0.02 0.05 0.07 0.08 0.10 0.11 0.13 0.14 0.15 0.17Table 1: Accuracy and coverage of different models on best-k ranking with frequency threshold 5 and frame threshold2els cannot make predictions in two specific cases.First, when the LU is not present in WordNet.
Sec-ond, when the function simWN does not has suffi-cient relational information to find a similar frame.This second factor is particularly evident for adjec-tives, as Eq.
8 assigns a frame only when a synonymof the unknown LU is found.
It is then not surpris-ing that 68% of the missed assignment are indeedadjectives.Results for the Combined model suggest thatthe integration of distributional and WordNet-basedmethods can offer a viable solution to the cover-age problem, as it achieves an accuracy comparableto the pure WordNet approaches, while keeping thecoverage high.Figure 2: Dist-word model accuracy at different LU fre-quency cuts.Data Sparseness.
A major issue when using dis-tributional approaches is that words with low fre-quency tend to have a very sparse non-meaningfulrepresentation in the vector space.
This highly im-pacts on the accuracy of the models.
To measurethe impact of data sparseness, we computed the ac-curacy at different frequency cuts ?
i.e.
we excludeLUs below a given frequency threshold from cen-troid computation and evaluation.
Figure 2 reportsthe results for best-10 assignment at different cuts,for the Dist-word model.
As expected, accuracy im-proves by excluding infrequent LUs.
Only at a fre-quency cut of 200 performance becomes stable, asstatistical evidence is enough for a reliable predic-tion.
Yet, in a real setting the improvement in accu-racy implies a lower coverage, as the system wouldnot classify LUs below the threshold.
For example,by discarding LUs occurring less than 200 times inthe corpus, we obtain a +0.12 improvement in accu-racy, but the coverage decreases to 57%.
However,uncovered LUs are also the most rare ones and theirrelevance in an application may be negligible.Lexical Semantics, Ambiguity and Plausible As-signments.
The overall accuracies achieved byour methods are ?pessimistic?, in the sense that theyshould be intended as lower-bounds.
Indeed, a qual-itative analysis of erroneous predictions reveals thatin many cases the frame assignments produced bythe models are semantically plausible, even if theyare considered incorrect in the leave-one-out test.Consider for example the LU guerrilla, assigned inFrameNet to the frame PEOPLE BY VOCATION.
Ourmixed model proposes as two most similar framesMILITARY and TERRORISM, which could still beconsidered plausible assignment.
The same holdsfor the LU caravan, for which the most similarframe is VEHICLE, while in FrameNet the LU is as-signed only to the frame BUILDINGS.
These casesare due to the low FrameNet coverage, i.e LUs arenot fully annotated and they appear only in a subsetof their potential frames.
The real accuracy of our463models is therefore expected to be higher.To explore the issue, we carried out a qualita-tive analysis of 5 words (i.e.
abandon.v, accuse.v,body.n, charge.v and partner.n).
For each of them,we randomly picked 60 sentences from the BNCcorpus, and asked two human annotators to assignto the correct frame the occurrence of the word inthe given sentence.
For 2 out of 5 words, no framecould be found for most of the sentences, suggestingthat the most frequent frames for these words weremissing from FrameNet7.
We can then conclude that100% accuracy cannot be considered as the upper-bound of our experiment, as word usage in texts isnot well reflected in the FrameNet modelling.Further experiments.
We also tested our modelson a realistic gold-standard set of 24 unknown LUsextracted from the SemEval-2007 corpus (Baker etal., 2007).
These are words not present in FrameNet1.3 which have been assigned by human annotatorsto an existing frame8.
WNet-full achieves an accu-racy of 0.25 for best-1 and 0.69 for best-10, with acoverage of 67%.
A qualitative analysis showed thatthe lower performance wrt to our main experiment isdue to higher ambiguity of the LUs (e.g.
we assigntea to SOCIAL EVENT instead of FOOD).Comparison to other approaches.
We compareour models to the system presented by Johans-son and Nugues (2007) and Burchardt and col-leagues (2005).
Johansson and Nugues (2007) eval-uate their machine learning system using 7,000unique LUs to train the Support Vector Machine, andthe remaining LUs as test.
They measure accuracy atdifferent coverage levels.
At 80% coverage accuracyis about 0.42, 10 points below our best WordNet-based system.
At 90% coverage, the system showsan accuracy below 0.10 and is significantly out-performed by both our distributional and combinedmethods.
These results confirm that WordNet-basedapproaches, while being highly accurate wrt dis-tributional ones, present strong weaknesses as faras coverage is concerned.
Furthermore, Johanssonand Nugues (2007) show that their machine learn-7Note that the need of new frames to account for seman-tic phenomena in free texts has been also demonstrated by theSemEval-2007 competition.8The set does not contain 4 LUs which have no frame inFrameNet.ing approach outperforms a simple approach basedon WordNet similarity: thus, our results indirectlyprove that our WordNet-based method is more ef-fective than the application of the similarity measurepresented in (Pedersen et al, 2004).We also compare our results to those reportedby Burchardt and colleagues (2005) for Detour.Though the experimental setting is slightly different(LU assignment is done at the text-level), they usethe same gold standard and leave-one-out technique,reporting a best-1 accuracy of 0.38 and a coverageof 87%.
Our WordNet-based models significantlyoutperform Detour on best-1 accuracy, at the cost oflower coverage.
Yet,our combined model is signifi-cantly better both on accuracy (+5%) and coverage(+8%).
Also, in most cases Detour cannot predictmore than one frame (best-1), while our accuraciescan be improved by relaxing to any best-k level.7 ConclusionsIn this paper we presented an original approach forFrameNet LU induction.
Results show that mod-els combining distributional and WordNet informa-tion offer the most viable solution to model the no-tion of frame, as they allow to achieve a reasonabletrade-off between accuracy and coverage.
We alsoshowed that in contrast to previous work, simple se-mantic spaces are more helpful than complex syn-tactic ones.
Results are accurate enough to supportthe creation and the development of new FrameNets.As future work, we will evaluate new types ofspaces (e.g.
dimensionality reduction methods) toimprove the generalization capabilities of the spacemodels.
We will also address the data sparseness is-sue, by testing smoothing techniques to better modellow frequency LUs.
Finally, we will implementthe presented models in a complex architecture forsemi-supervised FrameNets development, both forspecializing the existing English FrameNet in spe-cific domains, and for creating new FrameNets inother languages.AcknowledgementsThis work has partly been funded by the German Re-search Foundation DFG (grant PI 154/9-3).
Thanksto Richard Johansson and Aljoscha Burchardt forproviding the data of their systems.464ReferencesE.
Agirre and G. Rigau.
1996.
Word Sense Disam-biguation using Conceptual Density.
In Proceedingsof COLING-96, Copenhagen, Denmark.Collin F. Baker, Charles J. Fillmore, and John B. Lowe.1998.
The Berkeley FrameNet project.
In Proceed-ings of COLING-ACL, Montreal, Canada.Collin Baker, Michael Ellsworth, and Katrin Erk.
2007.SemEval-2007 Task 19: Frame Semantic StructureExtraction.
In Proceedings of the Fourth InternationalWorkshop on Semantic Evaluations (SemEval-2007),pages 99?104, Prague, Czech Republic, June.Roy Bar-Haim, Idan Szpektor, and Oren Glickman.2005.
Definition and Analysis of Intermediate Entail-ment Levels.
In ACL-05 Workshop on Empirical Mod-eling of Semantic Equivalence and Entailment, AnnArbor, Michigan.R.
Basili, M. Cammisa, and F.M.
Zanzotto.
2004.
Asemantic similarity measure for unsupervised semanticdisambiguation.
In Proceedings of LREC-04, Lisbon,Portugal.Alexander Budanitsky and Graeme Hirst.
2006.
Eval-uating WordNet-based measures of semantic distance.Computational Linguistics, 32(1):13?47.Aljoscha Burchardt and Anette Frank.
2006.
Approx-imating Textual Entailment with LFG and FrameNetFrames.
In Proceedings of PASCAL RTE2 Workshop.Aljoscha Burchardt, Katrin Erk, and Anette Frank.
2005.A WordNet Detour to FrameNet.
In Sprachtech-nologie, mobile Kommunikation und linguistische Re-sourcen, volume 8 of Computer Studies in Languageand Speech.
Peter Lang, Frankfurt/Main.Aljoscha Burchardt, Katrin Erk, Anette Frank, AndreaKowalski, Sebastian Pado?, and Manfred Pinkal.
2006.The SALSA corpus: a German corpus resource forlexical semantics.
In Proceedings of LREC, Genova,Italy.Ted Dunning.
1993.
Accurate methods for the statisticsof surprise and coincidence.
Computational Linguis-tics, 18(1):61?74.Charles J. Fillmore.
1985.
Frames and the semantics ofunderstanding.
Quaderni di Semantica, 4(2):222?254.K.
Garoufi.
2007.
Towards a better understanding ofapplied textual entailment: Annotation and evaluationof the rte-2 dataset.
M.Sc.
thesis, saarland university.Zellig Harris.
1964.
Distributional structure.
In Jer-rold J. Katz and Jerry A. Fodor, editors, The Phi-losophy of Linguistics, New York.
Oxford UniversityPress.Richard Johansson and Pierre Nugues.
2007.
UsingWordNet to extend FrameNet coverage.
In Proceed-ings of the Workshop on Building Frame-semantic Re-sources for Scandinavian and Baltic Languages, atNODALIDA, Tartu, Estonia, May 24.Dekang Lin.
1998.
Automatic retrieval and clustering ofsimilar word.
In Proceedings of COLING-ACL, Mon-treal, Canada.Sebastian Pado?.
2007.
Cross-Lingual Annotation Projec-tion Models for Role-Semantic Information.
SaarlandUniversity.M.
Palmer, D. Gildea, and P. Kingsbury.
2005.
TheProposition Bank: An Annotated Corpus of SemanticRoles.
Computational Linguistics, 31(1).Ted Pedersen, Siddharth Patwardhan, and Jason Miche-lizzi.
2004.
WordNet::Similarity - Measuring the Re-latedness of Concept.
In Proc.
of 5th NAACL, Boston,MA.Magnus Sahlgren.
2006.
The Word-Space Model.
De-partment of Linguistics, Stockholm University.G.
Salton, A. Wong, and C. Yang.
1975.
A vector spacemodel for automatic indexing.
Communications of theACM, 18:613620.Hinrich Schu?tze.
1998.
Automatic Word Sense Discrim-ination.
Computational Linguistics, 24(1):97?124.Dan Shen and Mirella Lapata.
2007.
Using semanticroles to improve question answering.
In Proceedingsof EMNLP-CoNLL, pages 12?21, Prague.C.
Subirats and M. Petruck.
2003.
Surprise!
SpanishFrameNet!
In Proceedings of the Workshop on FrameSemantics at the XVII.
International Congress of Lin-guists, Prague.465
