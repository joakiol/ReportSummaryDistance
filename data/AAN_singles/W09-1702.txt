Proceedings of the NAACL HLT Workshop on Unsupervised and Minimally Supervised Learning of Lexical Semantics, pages 10?17,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsUtilizing Contextually Relevant Terms in Bilingual Lexicon ExtractionAzniah IsmailDepartment of Computer ScienceUniversity of YorkYork YO10 5DD UKazniah@cs.york.ac.ukSuresh ManandharDepartment of Computer ScienceUniversity of YorkYork YO10 5DD UKsuresh@cs.york.ac.ukAbstractThis paper demonstrates one efficient tech-nique in extracting bilingual word pairs fromnon-parallel but comparable corpora.
Insteadof using the common approach of taking highfrequency words to build up the initial bilin-gual lexicon, we show contextually relevantterms that co-occur with cognate pairs can beefficiently utilized to build a bilingual dictio-nary.
The result shows that our models usingthis technique have significant improvementover baseline models especially when highest-ranked translation candidate per word is con-sidered.1 IntroductionBilingual lexicons or dictionaries are invaluableknowledge resources for language processing tasks.The compilation of such bilingual lexicons remainsas a substantial issue to linguistic fields.
In gen-eral practice, many linguists and translators spendhuge amounts of money and effort to compile thistype of knowledge resources either manually, semi-automatically or automatically.
Thus, obtaining thedata is expensive.In this paper, we demonstrate a technique that uti-lizes contextually relevant terms that co-occur withcognate pairs to expand an initial bilingual lexi-con.
We use unannotated resources that are freelyavailable such as English-Spanish Europarl corpus(Koehn, 2005) and another different set of cognatepairs as seed words.We show that this technique is able to achievehigh precision score for bilingual lexicon extractedfrom non-parallel but comparable corpora.
Ourmodel using this technique with spelling similarityapproach obtains 85.4 percent precision at 50.0 per-cent recall.
Precision of 79.0 percent at 50.0 percentrecall is recorded when using this technique withcontext similarity approach.
Furthermore, by usinga string edit-distance vs. precision curve, we alsoreveal that the latter model is able to capture wordsefficiently compared to a baseline model.Section 2 is dedicated to mention some of the re-lated works.
In Section 3, the technique that we usedis explained.
Section 4 describes our experimentalsetup followed by the evaluation results in Section5.
Discussion and conclusion are in Section 6 and 7respectively.2 Related WorkKoehn and Knight (2002) describe few potentialclues that may help in extracting bilingual lexi-con from two monolingual corpora such as identi-cal words, similar spelling, and similar context fea-tures.
In reporting our work, we treat both identicalword pairs and similar spelling word pairs as cog-nate pairs.Koehn and Knight (2002) map 976 identicalword pairs that are found in their two monolin-gual German-English corpora and report that 88.0percent of them are correct.
They propose to re-strict the word length, at least of length 6, to in-crease the accuracy of the collected word pairs.Koehn and Knight (2002) mention few related worksthat use different measurement to compute the sim-ilarity, such as longest common subsequence ratio(Melamed, 1995) and string edit distance (Mann10and Yarowski, 2001).
However, Koehn and Knight(2002) point out that majority of their word pairsdo not show much resemblance at all since theyuse German-English language pair.
Haghighi et al(2008) mention one disadvantage of using edit dis-tance, that is, precision quickly degrades with higherrecall.
Instead, they propose assigning a feature toeach substring of length of three or less for eachword.For approaches based on contextual features orcontext similarity, we assume that for a word thatoccurs in a certain context, its translation equivalentalso occurs in equivalent contexts.
Contextual fea-tures are the frequency counts of context words oc-curring in the surrounding of target word W. A con-text vector for each W is then constructed, with onlycontext words found in the seed lexicon.
The contextvectors are then translated into the target languagebefore their similarity is measured.Fung and Yee (1998) point out that not only thenumber of common words in context gives somesimilarity clue to a word and its translation, but theactual ranking of the context word frequencies alsoprovides important clue to the similarity between abilingual word pair.
This fact has motivated Fungand Yee (1998) to use tfidf weighting to compute thevectors.
This idea is similar to Rapp (1999) whoproposed to transform all co-occurrence vectors us-ing log likelihood ratio instead of just using thefrequency counts of the co-occurrences.
These val-ues are used to define whether the context words arehighly associated with the W or not.Earlier work relies on a large bilingual dictionaryas their seed lexicon (Rapp, 1999; Fung and Yee,1998; among others).
Koehn and Knight (2002)present one interesting idea of using extracted cog-nate pairs from corpus as the seed words in orderto alleviate the need of huge, initial bilingual lex-icon.
Haghighi et al (2008), amongst a few oth-ers, propose using canonical correlation analysis toreduce the dimension.
Haghighi et al(2008) onlyuse a small-sized bilingual lexicon containing 100word pairs as seed lexicon.
They obtain 89.0 percentprecision at 33.0 percent recall for their English-Spanish induction with best feature set, using top-ically similar but non-parallel corpora.3 The Utilizing TechniqueMost works in bilingual lexicon extraction use listsof high frequency words that are obtained fromsource and target language corpus to be their sourceand target word lists respectively.
In our work, weaim to extract a high precision bilingual lexicon us-ing different approach.
Instead, we use list of con-textually relevant terms that co-occur with cognatepairs.Figure 1: Cognate pair extractionThese cognate pairs can be derived automaticallyby mapping or finding identical words occur in twohigh frequency list of two monolingual corpora (seeFigure 1).
They are used to acquire list of sourceword Ws and target word Wt.
Ws and Wt are contex-tually relevant terms that highly co-occur with thecognate pairs in the same context.
Thus, log likeli-hood measure can be used to identify them.Next, bilingual word pairs are extracted amongwords in these Ws and Wt list using either contextsimilarity or spelling similarity.
Figure 2 showssome examples of potential bilingual word pairs,of Ws and Wt, co-occurring with identical cognatepairs of word ?civil?.As we are working on English-Spanish languagepair, we extract bilingual lexicon using string editdistance to identify spelling similarity between Ws11and Wt.
Figure 3 outlines the algorithm usingspelling similarity in more detail.Using the same Ws and Wt lists, we extract bilin-gual lexicon by computing the context similarity be-tween each {Ws,Wt} pair.
To identify the contextsimilarity, the relation between each {Ws, Wt} paircan be detected automatically using a vector similar-ity measure such as cosine measure as in (1).
The Aand B are the elements in the context vectors, con-taining either zero or non-zero seed word values forWs and Wt, respectively.Cosine similarity = cos(?)
= A?B||A|| ?
||B|| (1)The cosine measure favors {Ws,Wt} pairs thatshare the most number of non-zero seed word val-ues.
However, one disadvantage of this measure isthat the cosine value directly proportional to the ac-tual Ws and Wt values.
Even though Ws and Wtmight not closely correlated with the same set ofseed words, the matching score could be high if Wsor Wt has high seed word values everywhere.
Thus,we transform the context vectors from real valueinto binary vectors before the similarity is computed.Figure 4 outlines the algorithm using context simi-larity in more detail.In the algorithm, after the Ws and Wt lists are ob-tained, each Ws and Wt units is represented by theircontext vector containing log likelihood (LL) valuesof contextually relevant words, occurring in the seedlexicon, that highly co-occur with the Ws and Wt re-spectively.
To get this context vector, for each Wsand Wt, all sentences in the English or Spanish cor-pora containing the respective word are extracted toform a particular sub corpus, e.g.
sub corpus soci-ety is a collection of sentences containing the sourceword society.Using window size of a sentence, the LL valueof term occurring with the word Ws or Wt in theirrespective sub corpora is computed.
Term that ishighly associated with the Ws or Wt is called con-textually relevant term.
However, we consider eachterm with LL value higher than certain threshold(e.g.
threshold ?
15.0) to be contextually relevant.Contextually relevant terms occurring in the seedlexicon are used to build the context vector for theFigure 2: Bilingual word pairs are found within contextof cognate word civilFigure 3: Utilizing technique with spelling similarity12Figure 4: Utilizing technique with context similarityWs or Wt respectively.
For example, word participa-tion and education occurring in the seed lexicon arecontextually relevant terms for source word society.Thus, they become elements of the context vector.Then, we transform the context vectors, from realvalue into binary, before we compute the similaritywith cosine measure.4 Experimental Setup4.1 DataFor source and target monolingual corpus, we de-rive English and Spanish sentences from parallel Eu-roparl corpora (Koehn, 2005).?
We split each of them into three parts; year1996 - 1999, year 2000 - 2003 and year 2004- 2006.?
We only take the first part, about 400k sen-tences of Europarl Spanish (year 1996 - 1999)and 2nd part, also about 400k from EuroparlEnglish (year 2000 - 2003).
We refer the partic-ular part taken from the source language corpusas S and the other part of the target languagecorpus as T.This approach is quite common in order to ob-tain non-parallel but comparable (or same domain)corpus.
Examples can be found in Fung and Che-ung (2004), followed by Haghighi et al (2008).For corpus pre-processing, we only use sentenceboundary detection and tokenization on raw text.We decided that large quantities of raw text requir-ing minimum processing could also be considered asminimal since they are inexpensive and not limited.These should contribute to low or medium densitylanguages for which annotated resources are limited.We also clean all tags and filter out stop words fromthe corpus.4.2 EvaluationWe extracted our evaluation lexicon from Word Ref-erence?
free online dictionary .
For this work, theword types are not restricted but mostly are con-tent words.
We have two sets of evaluation.
In one,we take high ranked candidate pairs where Ws couldhave multiple translations.
In the other, we only con-sider highest-ranked Wt for each Ws.
For evalua-tion purposes, we take only the top 2000 candidateranked-pairs from the output.
From that list, onlycandidate pairs with words found in the evaluationlexicon are proposed.
We use F1-measure to evalu-ate proposed lexicon against the evaluation lexicon.The recall is defined as the proportion of the highranked candidate pairs.
The precision is given as thenumber of correct candidate pairs divided by the to-tal number of proposed candidate pairs.4.3 Other SetupsThe following were also setup and used:?
List of cognate pairsWe obtained 79 identical cognate pairs from the?from website http://www.wordreference.com13top 2000 high frequency lists of our S and T butwe chose 55 of these that have at least 100 con-textually relevant terms that are highly associ-ated with each of them.?
Seed lexiconWe also take a set of cognate pairs to be ourseed lexicon.
We defined the size of a smallseed lexicon ranges between 100 to 1k wordpairs.
Hence, our seed lexicon containing 700cognate pairs are still considered as a small-sized seed lexicon.
However, instead of acquir-ing this set of cognate pairs automatically, wecompiled the cognate pairs from a few Learn-ing Spanish Cognates websites ?.
This ap-proach is a simple alternative to replace the10-20k general dictionaries (Rapp, 1999; Fungand McKeown, 2004) or automatic seed words(Koehn and Knight, 2002; Haghighi et al,2008).
However, this approach can only beused if the source and target language are fairlyrelated and both share lexically similar wordsthat most likely have same meaning.
Other-wise, we have to rely on general bilingual dic-tionaries.?
Stop listPreviously (Rapp, 1999; Koehn and Knight,2002; among others) suggested filtering outcommonly occurring words that do not helpin processing natural language data.
This ideasometimes seem as a negative approach to thenatural articles of language, however variousstudies have proven that it is sensible to do so.?
Baseline systemWe build baseline systems using basic contextsimilarity and spelling similarity features.5 Evaluation ResultsFor the first evaluation, candidate pairs are rankedafter being measured either with cosine for contextsimilarity or edit distance for spelling similarity.
Inthis evaluation, we take the first 2000 of {Ws, Wt}candidate pairs from the proposed lexicon where Wsmay have multiple translations or multiple Wt.
SeeTable 1.?such as http://www.colorincolorado.org andhttp://www.language-learning-advisor.comSetting P0.1 P0.25 P0.33 P0.5 Best-F1ContextSim (CS) 42.9 69.6 60.7 58.7 49.6SpellingSim (SS) 90.5 74.2 69.9 64.6 50.9(a) from baseline modelsSetting P0.1 P0.25 P0.33 P0.5 Best-F1E-ContextSim (ECS) 78.3 73.5 71.8 64.0 51.2E-SpellingSim (ESS) 95.8 75.6 71.8 63.4 51.5(b) from our proposed modelsTable 1: Performance of baseline and our model for top2000 candidates below certain threshold and rankedSetting P0.1 P0.25 P0.33 P0.5 Best-F1ContextSim-Top1 (CST) 58.3 61.2 64.8 55.2 52.6SpellingSim-Top1 (SST) 84.9 66.4 52.7 34.5 37.0(a) from baseline modelsSetting P0.1 P0.25 P0.33 P0.5 Best-F1E-ContextSim-Top1 (ECST) 85.0 81.1 79.7 79.0 57.1E-SpellingSim-Top1 (ESST) 100.0 93.6 91.6 85.4 59.0(b) from our proposed modelsTable 2: Performance of baseline and our model for top2000 candidates of top 1Using either context or spelling similarity ap-proach on S and T (labeled ECS and ESS respec-tively), our models achieved about 51.2 percent ofbest F1 measure.
Those are not a significant im-provement with only 1.0 to 2.0 percent error reduc-tion over the baseline models (labeled CS and SS).For the second evaluation, we take the first 2000of {Ws, Wt} pairs where Ws may only have the high-est ranked Wt as translation candidates (See Table2).
This time, both of our models (with contextsimilarity and spelling similarity, labeled ECST andESST respectively) yielded almost 60.0 percent ofbest F1 measure.
It is noted that using ESST alonerecorded a significant improvement of 20.0 percentin the F1 score compared to SST baseline model.ESST obtained 85.4 percent precision at 50.0 per-cent recall.
Precision of 79.0 percent at 50.0 percentrecall is recorded when using ECST.
However, theECST has not recorded a significant difference overCST baseline model (57.1 and 52.6 percent respec-tively) in the second evaluation.
The overall perfor-mances, represented by precision scores for different14Figure 5: String Edit Distance vs.
Precision curverange of recalls, for these four models are illustratedin Appendix A.It is important to see the inner performance of theECST model with further analysis.
We present astring edit distance value (EDv) vs. precision curvefor ECST and CST in Figure 5 to measure the per-formance of the ECST model in capturing bilingualpairs with less similar orthographic features, thosethat may not be captured using spelling similarity.The graph in Figure 5 shows that even thoughCST has higher precision score than ECST at EDvof 2, it is not significant (the difference is less than5.0 percent) and the spelling is still similar.
On theother hand, precision for proposed lexicon with EDvabove 3 (where the Ws and the proposed translationequivalent Wt spelling becoming more dissimilar)using ECST is higher than CST.
The most significantdifference of the precision is almost 35.0 percent,where ECST achieved almost 75.0 percent precisioncompared to CST with 40.0 percent precision at EDvof 4.
It is followed by ECST with almost 50.0 per-cent precision compared to CST with precision lessthan 35.0 percent, offering about 15.0 percent preci-sion improvement at EDv of 5.6 DiscussionAs we are working on English-Spanish languagepair, we could have focused on spelling similar-ity feature only.
Performance of the model usingthis feature usually record higher accuracy other-wise they may not be commonly occurring in a cor-pus.
Our models with this particular feature haverecorded higher F1 scores especially when consid-ering only the highest-ranked candidates.We also experiment with context similarity ap-proach.
We would like to see how far this approachhelps to add to the candidate scores from our corpusS and T. The other reason is sometimes a correct tar-get is not always a cognate even though a cognatefor it is available.
Our ECST model has not recordedsignificant improvement over CST baseline model inthe F1-measure.
However, we were able to show thatby utilizing contextually relevant terms, ECST gath-ers more correct candidate pairs especially when itcomes to words with dissimilar spelling.
This meansthat ECST is able to add more to the candidate scorescompared to CST.
Thus, more correct translationpairs can be expected with a good combination ofECST and ESST.The following are the advantages of our utilizingtechnique:?
Reduced errors, hence able to improve preci-sion scores.?
Extraction is more efficient in the contextualboundaries (see Appendix B for examples).?
Context similarity approach within our tech-nique has a potential to add more to the can-didate scores.Yet, our attempt using cognate pairs as seed words ismore appropriate for language pairs that share largenumber of cognates or similar spelling words withsame meaning.
Otherwise, one may have to rely onbilingual dictionaries.There may be some possible supporting strate-gies, which we could use to help improve furtherthe precision score within the utilizing technique.For example, dimension reduction using canonicalcorrelation analysis (CCA), resemblance detection,measure of dispersion, reference corpus and furthernoise reduction.
However, we do not include a re-ranking method, as we are using collection of cog-nate pairs instead of a general bilingual dictionary.Since our corpus S and T is in similar domain, wemight still not have seen the potential of this tech-nique in its entirety.
One may want to test the tech-nique with different type of corpora for future works.15Nevertheless, we are still concerned that manyspurious translation equivalents were proposed be-cause the words actually have higher correlationwith the input source word compared to the realtarget word.
Otherwise, the translation equivalentsmay not be in the boundaries or in the corpus fromwhich translation equivalents are to be extracted.Haghighi et al(2008) have reported that the mostcommon errors detected in their analysis on top 100errors were from semantically related words, whichhad strong context feature correlations.
Thus, theissue remains.
We leave all these for further discus-sion in future works.7 ConclusionWe present a bilingual lexicon extraction techniquethat utilizes contextually relevant terms that co-occur with cognate pairs to expand an initial bilin-gual lexicon.
We show that this utilizing techniqueis able to achieve high precision score for bilinguallexicon extracted from non-parallel but comparablecorpora.
We demonstrate this technique using unan-notated resources that are freely available.Our model using this technique with spelling sim-ilarity obtains 85.4 percent precision at 50.0 percentrecall.
Precision of 79.0 percent at 50.0 percent re-call is recorded when using this technique with con-text similarity approach.
We also reveal that thelatter model with context similarity is able to cap-ture words efficiently compared to a baseline model.Thus, we show contextually relevant terms that co-occur with cognate pairs can be efficiently utilizedto build a bilingual dictionary.ReferencesCranias, L., Papageorgiou, H, and Piperidis, S. 1994.A matching technique in Example-Based MachineTranslation.
In International Conference On Compu-tational Linguistics Proceedings, 15th conference onComputational linguistics, Kyoto, Japan.Diab, M., and Finch, S. 2000.
A statistical word-leveltranslation model for comparable corpora.
In Proceed-ings of the Conference on Content-based multimediainformation access (RIAO).Fung, P., and Cheung, P. 2004.
Mining very non-parallelcorpora: Parallel sentence and lexicon extraction viabootstrapping and EM.
In Proceedings of the 2004Conference on Empirical Method in Natural LanguageProcessing (EMNLP), Barcelona, Spain.Fung, P., and Yee, L.Y.
1998.
An IR Approach forTranslating New Words from Nonparallel, Compara-ble Texts.
In Proceedings of COLING-ACL98, Mon-treal, Canada, 1998.Fung, P., and McKeown, K. 1997.
Finding TerminologyTranslations from Non-parallel Corpora.
In The 5thAnnual Workshop on Very Large Corpora, Hong Kong,Aug 1997.Haghighi, A., Liang, P., Berg-Krikpatrick, T., and Klein,D.
2008.
Learning bilingual lexicons from monolin-gual corpora.
In Proceedings of The ACL 2008, June15 -20 2008, Columbus, OhioKoehn, P. 2005.
Europarl: a parallel corpus for statisticalmachine translation.
In MT SummitKoehn, P., and Knight , K. 2001.
Knowledge sourcesfor word-level translation models.
In Proceedings ofthe Conference on Empirical Methods in Natural Lan-guage Processing (EMNLP).Koehn, P., and Knight , K. 2002.
Learning a translationlexicon from monolingual corpora.
In Proceedings ofACL 2002, July 2002, Philadelphia, USA, pp.
9-16.Rapp, R. 1995.
Identifying word translations in non-parallel texts.
In Proceedings of ACL 33, pages 320-322.Rapp, R. 1999.
Automatic identification of word transla-tions from unrelated English and German corpora.
InProceedings of ACL 37, pages 519-526.16Appendix A.
Precision scores with different recallsAppendix B.
Some examples of effective extraction via utilizing technique17
