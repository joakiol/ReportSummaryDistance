Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 369?372,Suntec, Singapore, 4 August 2009. c?2009 ACL and AFNLPPredicting Unknown Time Argumentsbased on Cross-Event PropagationPrashant Gupta Heng JiIndian Institute of InformationTechnology AllahabadComputer Science Department, Queens College andthe Graduate Center, City University of New YorkAllahabad, India, 211012 New York, NY, 11367, USAgreatprach@gmail.com hengji@cs.qc.cuny.eduAbstractMany events in news articles don?t includetime arguments.
This paper describes twomethods, one based on rules and the otherbased on statistical learning, to predict the un-known time argument for an event by thepropagation from its related events.
The re-sults are promising ?
the rule based approachwas able to correctly predict 74% of the un-known event time arguments with 70% preci-sion.1 IntroductionEvent time argument detection is important tomany NLP applications such as textual inference(Baral et al, 2005), multi-document text summa-rization (e.g.
Barzilay e al., 2002), temporalevent linking (e.g.
Bethard et al, 2007; Cham-bers et al, 2007; Ji and Chen, 2009) and templatebased question answering (Ahn et al, 2006).
It?sa challenging task in particular because abouthalf of the event instances don?t include explicittime arguments.
Various methods have been ex-ploited to identify or infer the implicit time ar-guments (e.g.
Filatova and Hovy, 2001; Mani etal., 2003; Lapata and Lascarides, 2006; Eidelman,2008).Most of the prior work focused on the sen-tence level by clustering sentences into topicsand ordering sentences on a time line.
However,many sentences in news articles include multipleevents with different time arguments.
And it wasnot clear how the errors of topic clustering tech-niques affected the inference scheme.
Thereforeit will be valuable to design inference methodsfor more fine-grained events.In addition, in the previous approaches the lin-guistic evidences such as verb tense were mainlyapplied for inferring the exact dates of implicittime expressions.
In this paper we are interestedin those more challenging cases in which anevent mention and all of its coreferential eventmentions do not include any explicit or implicittime expressions; and therefore its time argumentcan only be predicted based on other related e-vents even if they have different event types.2 Terminology and TaskIn this paper we will follow the terminology de-fined in the Automatic Content Extraction(ACE)1 program:entity: an object or a set of objects in one of thesemantic categories of interest: persons, locations,organizations, facilities, vehicles and weapons.event: a specific occurrence involving participants.The 2005 ACE evaluation had 8 types of events,with 33 subtypes; for the purpose of this paper, wewill treat these simply as 33 distinct event types.
Incontrast to ACE event extraction, we exclude ge-neric, negative, and hypothetical events.event mention: a phrase or sentence within whichan event is described.event argument: an entity involved in an eventwith some specific role.event time: an exact date normalized from time ex-pressions and a role to indicate that an event occursbefore/after/within the date.For any pair of event mentions <EMi, EMj>, if:?
EMi includes a time argument time-arg;?
EMj and its coreferential event mentionsdon?t include any time arguments;The goal of our task is to determine whethertime-arg can be propagated into EMj or not.3 MotivationThe events in a news document may contain atemporal or locative dimension, typical about anunfolding situation.
Various situations are evolv-ing, updated, repeated and corrected in differentevent mentions.
Here later information mayoverride earlier more tentative or incomplete1 http://www.nist.gov/speech/tests/ace/369events.
As a result, different events with particu-lar types tend to occur together frequently, forexample, the chains of ?Conflict?Life-Die/Life-Injure?
and ?Justice-Convict ?
Justice-Charge-Indict/Justice-Trial-Hearing?
often appear withinone document.
To avoid redundancy, the newswriters rarely provide time arguments for all ofthese events.
Therefore, it?s possible to recoverthe time argument of an event by gleaningknowledge from its related events, especially ifthey are involved in a pre-cursor/consequence orcausal relation.
We present two examples as fol-lows.?
Example 1For example, we can propagate the time ?Sunday(normalized into ?2003-04-06?)?
from a ?Con-flict-Attack?
EMi to a ?Life-Die?
EMj becausethey both involve ?Kurdish/Kurds?
:[Sentence including EMi]Injured Russian diplomats and a convoy of Amer-ica's Kurdish comrades in arms were among unin-tended victims caught in crossfire and friendly fireSunday.
[Sentence including EMj]Kurds said 18 of their own died in the mistakenU.S.
air strike.?
Example 2This kind of propagation can also be applied be-tween two events with similar event types.
Forexample, in the following we can propagate?Saturday?
from a ?Justice-Convict?
event to a?Justice-Sentence?
event because they both in-volve arguments ?A state security court/state?and ?newspaper/Monitor?
:[Sentence including EMi]A state security court suspended a newspaper criti-cal of the government Saturday after convicting itof publishing religiously inflammatory material.
[Sentence including EMj]The sentence was the latest in a series of state ac-tions against the Monitor, the only English lan-guage daily in Sudan and a leading critic of condi-tions in the south of the country, where a civil warhas been waged for 20 years.4 ApproachesBased on these motivations we have developedtwo approaches to conduct cross-event propaga-tion.
Section 4.1 below will describe the rule-based approach and section 4.2 will present thestatistical learning framework respectively.4.1 Rule based PredictionThe easiest solution is to encode rules based onconstraints from event arguments and positionsof two events.
We design three types of rules inthis paper.If  EMi has an event type typei and includes anargument argi with role rolei, while EMj has anevent type typej and includes an argument argjwith role rolej, they are not from two temporallyseparate groups of Justice events {Release-Parole,Appeal, Execute, Extradite, Acquit, Pardon} and{Arrest-Jail, Trial-Hearing, Charge-Indict, Sue,Convict, Sentence, Fine}2, and they match one ofthe following rules, then we propagate the timeargument between them.?
Rule1: Same-Sentence PropagationEMi and EMj are in the same sentence andonly one time expression exists in the sen-tence; This follows the within-sentence infer-ence idea in (Lapata and Lascarides, 2006).?
Rule2: Relevant-Type Propagationargi is coreferential with argj;typei= ?Conflict?, typej= ?Life-Die/Life-Injure?;rolei=?Target?
and rolej=?Victim?, orrolei=rolej=?Instrument?.?
Rule3: Same-Type Propagationargi is coreferential with argj, typei= typej,rolei= rolej, and they match one of the Time-Cue event type and argument role combina-tions in Table 1.Event Typei Argument RoleiConflict Target/Attacker/CrimeJustice Defendant/Crime/PlantiffLife-Die/Life-Injure VictimLife-Be-Born/Life-Marry/Life-DivorcePerson/EntityMovement-Transport Destination/OriginTransaction Buyer/Seller/Giver/RecipientContact Person/EntityPersonnel Person/EntityBusiness Organization/EntityTable 1.
Time-Cue Event Types andArgument RolesThe combinations shown in Table 1 above arethose informative arguments that are specificenough to indicate the event time, thus they are2 Statistically there is often a time gap between thesetwo groups of events.370called ?Time-Cue?
roles.
For example, in a?Conflict-Attack?
event, ?Attacker?
and ?Tar-get?
are more important than ?Person?
to indi-cate the event time.
The general idea is similar toextracting the cue phrases for text summarization(Edmundson, 1969).4.2 Statistical Learning based PredictionIn addition, we take a more general statisticalapproach to capture the cross-event relations andpredict unknown time arguments.
We manuallylabeled some ACE data and trained a MaximumEntropy classifier to determine whether topropagate the time argument of EMi to EMj ornot.
The features in this classifier are most de-rived from the rules in the above section 4.1.Following Rule 1, we build the following twofeatures:?
Feature1: Same-SentenceF_SameSentence: whether EMi and EMj arelocated in the same sentence or not.?
Feature2: Number of Time ArgumentsF_TimeNum: if F_SameSentence = true, thenassign the number of time arguments in thesentence, otherwise assign the feature value as?Empty?.For all the Time-Cue argument role pairs inRule 2 and Rule 3, we construct a set of features:?
Feature Set3: Time-Cue Argument RoleMatchingF_CueRoleij: Construct a feature for any pairof Time-Cue role types Rolei and Rolej in Rule2 and 3, assign the feature value as follows:if the argument argi in EMi has a role Roleiand the argument argj has a role Rolej:if argi and argj are coreferential thenF_CueRoleij = Coreferential,else F_CueRoleij = Non-Coreferential.else F_CueRoleij = Empty.5 Experimental ResultsIn this section we present the results of applyingthese two approaches to predict unknown eventtime arguments.5.1 Data and Answer-Key AnnotationWe used 47 newswire texts from ACE 2005training corpora to train the Maximum Entropyclassifier, and conduct blind test on a separate setof 10 ACE 2005 newswire texts.
For each docu-ment we constructed any pair of event mentions<EMi, EMj> as a candidate sample if EMi in-cludes a time argument while EMj and itscoreferential event mentions don?t include anytime arguments.
We then manually labeled?Propagate/Not-Propagate?
for each sample.
Theannotation for both training and test sets took onehuman annotator about 10 hours.
We asked an-other annotator to label the 10 test texts sepa-rately and the inter-annotator agreement is above95%.
There are 485 ?Propagate?
samples and617 ?Not-Propagate?
samples in the training set;and in total 212 samples in the test set.5.2 Overall PerformanceTable 2 presents the overall Precision (P), Recall(R) and F-Measure (F) of using these two differ-ent approaches.Method P (%) R (%) F(%)Rule-based 70.40 74.06 72.18Statistical Learning 72.48 50.94 59.83Table 2.
Overall PerformanceThe results of the rule-based approach arepromising: we are able to correctly predict 74%of the unknown event time arguments at about30% error rate.
The most common correctlypropagated pairs are:?
From Conflict-Attack to Life-Die/Life-Injure?
From Justice Convict to Justice-Sentence/Justice-Charge-Indict?
From Movement-Transport  to Contact-Meet?
From Justice-Charge-Indict  to Justice-Convict5.3 DiscussionFrom Table 2 we can see that the rule-based ap-proach achieved 23% higher recall than the sta-tistical classifier, with only 2% lower precision.The reason is that we don?t have enough trainingdata to capture all the evidences from differentTime-cue roles.
For instance, for the Example 2in section 3, Rule 3 is able to predict the timeargument of the ?Justice-Sentence?
event as?Saturday (normalized as 2003-05-10)?
becausethese two events share the coreferential Time-cue?Defendant?
arguments ?newspaper?
and ?Moni-tor?.
However, there is only one positive samplematching these conditions in the training corpora,and thus the Maximum Entropy classifier as-signed a very low confidence score for propaga-tion.
We have also tried to combine these twoapproaches in a self-training framework ?
addingthe results from the propagation rules as addi-tional training data and re-train the Maximum371Entropy classifier, but it did not provide furtherimprovement.The spurious errors made by the predictionrules reveal both the shortcomings of ignoringevent reporting order and the restricted matchingon event arguments.For example, in the following sentences:[Context Sentence]American troops stormed a presidential palace andother key buildings in Baghdad as U.S. tanks rum-bled into the heart of the battered Iraqi capital onMonday amid the thunder of gunfire and explo-sions?
[Sentence including EMj]At the palace compound, Iraqis shot <instru-ment>small arms</instrument> fire from a clocktower, which the U.S. tanks quickly destroyed.
[Sentence including EMi]The first one was on Saturday and triggered in-tense <instrument>gun</instrument> battles,which according to some U.S. accounts, left at least2,000 Iraqi fighters dead.The time argument ?Saturday?
was mistakenlypropagated from the ?Conflict-Attack?
event?battles?
to ?shot?
because they share the sameTime-cue role ?instrument?
(?small arms/gun?
).However, the correct time argument for the?shot?
event should be ?Monday?
as indicated inthe ?gunfire/explosions?
event in the previouscontext sentence.
But since the ?shot?
eventdoesn?t share any arguments with ?gun-fire/explosions?, our approach failed to obtainany evidence for propagating ?Monday?.
In thefuture we plan to incorporate the distance andevent reporting order as additional features andconstraints.Nevertheless, as Table 2 indicates, the rewardsof using propagation rules outweigh the risksbecause it can successfully predict a lot of un-known time arguments which were not possibleusing the traditional time argument extractiontechniques.6 Conclusion and Future WorkIn this paper we described two approaches topredict unknown time arguments based on theinference and propagation between related events.In the future we shall improve the confidenceestimation of the Maximum Entropy classifier sothat we could incorporate dynamic features fromthe high-confidence time arguments which havealready been predicted.
We also plan to test theeffectiveness of this system in textual inference,temporal event linking and event coreferenceresolution.
We are also interested in extendingthese approaches to the setting of cross-document, so that we can predict more time ar-guments based on the background knowledgefrom related documents.AcknowledgmentsThis material is based upon work supported bythe Defense Advanced Research Projects Agencyunder Contract No.
HR0011-06-C-0023 via 27-001022, and the CUNY Research EnhancementProgram and GRTI Program.ReferencesDavid Ahn, Steven Schockaert, Martine De Cock andEtienne Kerre.
2006.
Supporting Temporal Ques-tion Answering: Strategies for Offline Data Collec-tion.
Proc.
5th International Workshop on Infer-ence in Computational Semantics (ICoS-5).Regina Barzilay, Noemie Elhadad and KathleenMcKeown.
2002.
Inferring Strategies for SentenceOrdering in Multidocument Summarization.
JAIR,17:35-55.Chitta Baral, Gregory Gelfond, Michael Gelfond andRichard B. Scherl.
2005.
Proc.
AAAI'05 Workshopon Inference for Textual Question Answering.Steven Bethard, James H. Martin and Sara Klingen-stein.
2007.
Finding Temporal Structure in Text:Machine Learning of Syntactic Temporal Relations.International Journal of Semantic Computing(IJSC), 1(4), December 2007.Nathanael Chambers, Shan Wang and Dan Jurafsky.2007.
Classifying Temporal Relations BetweenEvents.
Proc.
ACL2007.H.
P. Edmundson.
1969.
New Methods in AutomaticExtracting.
Journal of the ACM.
16(2):264-285.Vladimir Eidelman.
2008.
Inferring Activity Time inNews through Event Modeling.
Proc.
ACL-HLT2008.Elena Filatova and Eduard Hovy.
2001.
AssigningTime-Stamps to Event-Clauses.
Proc.
ACL 2001Workshop on Temporal and Spatial InformationProcessing.Heng Ji and Zheng Chen.
2009.
Cross-documentTemporal and Spatial Person Tracking SystemDemonstration.
Proc.
HLT-NAACL 2009.Mirella Lapata and Alex Lascarides.
2006.
LearningSentence-internal Temporal Relations.
Journal ofArtificial Intelligence Research 27. pp.
85-117.Inderjeet Mani, Barry Schiffman and Jianping Zhang.2003.
Inferring Temporal Ordering of Events inNews.
Proc.
HLT-NAACL 2003.372
