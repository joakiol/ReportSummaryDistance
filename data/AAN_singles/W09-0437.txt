Proceedings of the Fourth Workshop on Statistical Machine Translation , pages 224?232,Athens, Greece, 30 March ?
31 March 2009. c?2009 Association for Computational LinguisticsA Systematic Analysis of Translation Model Search SpacesMichael Auli, Adam Lopez, Hieu Hoang and Philipp KoehnUniversity of Edinburgh10 Crichton StreetEdinburgh, EH8 9ABUnited Kingdomm.auli@sms.ed.ac.uk, alopez@inf.ed.ac.uk, h.hoang@sms.ed.ac.uk, pkoehn@inf.ed.ac.ukAbstractTranslation systems are complex, andmost metrics do little to pinpoint causes oferror or isolate system differences.
We usea simple technique to discover inductionerrors, which occur when good transla-tions are absent from model search spaces.Our results show that a common prun-ing heuristic drastically increases induc-tion error, and also strongly suggest thatthe search spaces of phrase-based and hi-erarchical phrase-based models are highlyoverlapping despite the well known struc-tural differences.1 IntroductionMost empirical work in translation analyzes mod-els and algorithms using BLEU (Papineni et al,2002) and related metrics.
Though such met-rics are useful as sanity checks in iterative sys-tem development, they are less useful as analyti-cal tools.
The performance of a translation systemdepends on the complex interaction of several dif-ferent components.
Since metrics assess only out-put, they fail to inform us about the consequencesof these interactions, and thus provide no insightinto the errors made by a system, or into the de-sign tradeoffs of competing systems.In this work, we show that it is possible to ob-tain such insights by analyzing translation sys-tem components in isolation.
We focus on modelsearch spaces (?2), posing a very simple question:Given a model and a sentence pair, does the searchspace contain the sentence pair?
Applying thismethod to the analysis and comparison of French-English translation using both phrase-based andhierarchical phrase-based systems yields surpris-ing results, which we analyze quantitatively andqualitatively.?
First, we analyze the induction error of amodel, a measure on the completeness of thesearch space.
We find that low weight phrasetranslations typically discarded by heuristicpruning nearly triples the number of refer-ence sentences that can be exactly recon-structed by either model (?3).?
Second, we find that the high-probability re-gions in the search spaces of phrase-basedand hierarchical systems are nearly identical(?4).
This means that reported differences be-tween the models are due to their rankings ofcompeting hypotheses, rather than structuraldifferences of the derivations they produce.2 Models, Search Spaces, and ErrorsA translation model consists of two distinct ele-ments: an unweighted ruleset, and a parameteri-zation (Lopez, 2008a; 2009).
A ruleset licensesthe steps by which a source string f1...fI may berewritten as a target string e1...eJ .
A parameter-ization defines a weight function over every se-quence of rule applications.In a phrase-based model, the ruleset is simplythe unweighted phrase table, where each phrasepair fi...fi?/ej ...ej?
states that phrase fi...fi?
inthe source can be rewritten as ej ...ej?
in the tar-get.
The model operates by iteratively apply-ing rewrites to the source sentence until eachsource word has been consumed by exactly onerule.
There are two additional heuristic rules:The distortion limit dl constrains distances overwhich phrases can be reordered, and the transla-tion option limit tol constrains the number of tar-get phrases that may be considered for any givensource phrase.
Together, these rules completelydetermine the finite set of all possible target sen-tences for a given source sentence.
We call this setof target sentences the model search space.The parameterization of the model includes allinformation needed to score any particular se-224quence of rule applications.
In our phrase-basedmodel, it typically includes phrase translationprobabilities, lexical translation probabilities, lan-guage model probabilities, word counts, and co-efficients on the linear combination of these.
Thecombination of large rulesets and complex param-eterizations typically makes search intractable, re-quiring the use of approximate search.
It is im-portant to note that, regardless of the parameteri-zation or search used, the set of all possible outputsentences is still a function of only the ruleset.Germann et al (2004) identify two types oftranslation system error: model error and searcherror.1 Model error occurs when the optimalpath through the search space leads to an incorrecttranslation.
Search error occurs when the approxi-mate search technique causes the decoder to selecta translation other than the optimum.Given the decomposition outlined above, itseems clear that model error depends on param-eterization, while search error depends on approx-imate search.
However, there is no error type thatclearly depends on the ruleset (Table 1).
We there-fore identify a new type of error on the ruleset: in-duction error.
Induction error occurs when thesearch space does not contain the correct targetsentence at all, and is thus a more fundamentaldefect than model error.
This is difficult to mea-sure, since there could be many correct transla-tions and there is no way to see whether they areall absent from the search space.2 However, if weassume that a given reference sentence is groundtruth, then as a proxy we can simply ask whetheror not the model search space contains the refer-ence.
This assumption is of course too strong, butover a sufficiently large test set, it should correlatewith metrics which depend on the reference, sinceunder most metrics, exactly reproducing the ref-erence results in a perfect score.
More loosely, itshould correlate with translation accuracy?evenif there are many good translations, a model whichis systematically unable to produce any referencesentences from a sufficiently large test sample isalmost certainly deficient in some way.3 Does Ruleset Pruning Matter?The heuristic translation option limit tol controlsthe number of translation rules considered per1They also identify variants within these types.2It can also be gamed by using a model that can generateany English word from any French word.
However, this isnot a problem for the real models we investigate here.ruleset induction errorparameterization model errorsearch search errorTable 1: Translation system components and theirassociated error types.100 101 102 10300.20.40.60.8Translation OptionsPhrase Probabilityp(e|f)Figure 1: Distribution p(f |e) of the English trans-lation options for the French word proble`me.source span.
It plays a major role in keeping thesearch space manageable.
Ignoring reordering, thecomplexity of the search in a phrase-based modelis O(ntol), where n is the number of French spans.Therefore tol has a major effect on efficiency.Tight pruning with tol is often assumed withoutquestion to be a worthwhile tradeoff.
However,we wish to examine this assumption more closely.Consider the French word proble`me.
It has 288different translation options in the phrase tableof our French-English phrase-based system.
Thephrase translation probability p(e|f) over theseoptions is a familiar Zipf distribution (Figure 1).The most likely candidate translation for the wordis problem with a probability of 0.71, followed byissue with a much smaller probability of 0.12.
Fur-ther down, we find challenge at rank 25, obsta-cle at 44 and dilemma at rank 105.
Depending onthe context, these might be perfectly good transla-tions.
However, with a typical tol of 20, most ofthese options are not considered during decoding.Table 2 shows that 93.8% of rules are availableduring decoding with the standard tol setting andonly about 0.1% of French spans of the entire rule-set have more than 20 translation options.
It seemsas if already most of the information is availablewhen using the default limit.
However, a tol of20 can clearly exclude good translations as illus-trated by our example.
Therefore we hypothesizethe following: Increasing the translation optionlimit gives the decoder a larger vocabulary whichin turn will decrease the induction error.
We sup-225tol Ruleset Size French Spans20 93.8 99.950 96.8 100.0100 98.3 100.0200 99.2 100.0400 99.7 100.0800 99.9 100.0All 100.0 100.0Table 2: Ruleset size expressed as percentage ofavailable rules when varying the limit of transla-tion options tol per English span and percentageof French spans with up to tol translations.port this hypothesis experimentally in ?5.4.4 How Similar are Model Search Spaces?Most work on hierarchical phrase-based transla-tion focuses quite intently on its structural differ-ences from phrase-based translation.?
A hierarchical model can translate discon-tiguous groups of words as a unit.
A phrase-based model cannot.
Lopez (2008b) gives in-direct experimental evidence that this differ-ence affects performance.?
A standard phrase-based model can reorderphrases arbitrarily within the distortion limit,while the hierarchical model requires somelexical evidence for movement, resorting tomonotone translation otherwise.?
While both models can indirectly modelword deletion in the context of phrases, thehierarchical model can delete words usingnon-local context due to its use of discontigu-ous phrases.The underlying assumption in most discussionsof these models is that these differences in theirgenerative stories are responsible for differencesin performance.
We believe that this assumptionshould be investigated empirically.In an interesting analysis of phrase-based andhierarchical translation, Zollmann et al (2008)forced a phrase-based system to produce the trans-lations generated by a hierarchical system.
Unfor-tunately, their analysis is incomplete; they do notperform the analysis in both directions.
In ?5.5 weextend their work by requiring each system to gen-erate the 1-best output of the other.
This allows usto see how their search spaces differ.5 ExperimentsWe analyse rulesets in isolation, removing the in-fluence of the parametrization and heuristics asmuch as possible for each system as follows: First,we disabled beam search to avoid pruning basedon parametrization weights.
Second, we requireour decoders to generate the reference via disal-lowing reference-incompatible hypothesis or chartentries.
This leaves only some search restrictionssuch as the distortion limit for the phrase-basedsystem for which we controlled, or the maximumnumber of source words involved in a rule appli-cation for the hierarchical system.5.1 Experimental SystemsOur phrase-based system is Moses (Koehn et al,2007).
We set its stack size to 105, disabled thebeam threshold, and varied the translation optionlimit tol.
Forced translation was implemented bySchwartz (2008) who ensures that hypothesis area prefix of the reference to be generated.Our hierarchical system is Hiero (Chiang,2007), modified to construct rules from a smallsample of occurrences of each source phrase intraining as described by Lopez (2008b).
Thesearch parameters restricting the number of rulesor chart entries as well as the minimum thresholdwere set to very high values (1050) to prevent prun-ing.
Forced translation was implemented by dis-carding rules and chart entries which do not matchthe reference.5.2 Experimental DataWe conducted experiments in French-Englishtranslation, attempting to make the experimentalconditions for both systems as equal as possible.Each system was trained on French-English Eu-roparl (Koehn, 2005), version 3 (40M words).
Thecorpus was aligned with GIZA++ (Och and Ney,2003) and symmetrized with the grow-diag-final-and heuristic (Koehn et al, 2003).
A trigramlanguage model with modified Kneser-Ney dis-counting and interpolation was used as producedby the SRILM toolkit (Stolcke, 2002).
Systemswere optimized on the WMT08 French-Englishdevelopment data (2000 sentences) using mini-mum error rate training (Och, 2003) and testedon the WMT08 test data (2000 sentences).
Rulesbased on unaligned words at the edges of foreignand source spans were not allowed unless other-wise stated, this is denoted as the tightness con-22620 50 100 200 400 800 All101520253035Translation Option LimitReachability(%)dl=6dl=7dl=8dl=9dl=10dl=11dl=12dl=13dl=14dl=15dl=16Figure 2: Coverage for phrase-based referencealigned translation on test data when varying thetranslation option and the distortion limits (dl).straint.
Ayan and Dorr (2006) showed that undercertain conditions, this constraint could have sig-nificant impact on system performance.
The max-imum phrase lengths for both the hierarchical andphrase-based system were set to 7.
The distortionlimit (dl) for the phrase-based system was set to6 unless otherwise mentioned.
All other settingswere left at their default values as described byChiang (2007) and Koehn et al (2007).5.3 Metric: Reference ReachabilityWe measure system performance in terms of ref-erence reachability, which is the inverse of in-duction error: A system is required to be able toexactly reproduce the reference, otherwise we re-gard the result as an error.5.4 Analysis of Ruleset PruningIn ?3 we outlined the hypothesis that increas-ing the number of English translation options perFrench span can increase performance.
Here wepresent results for both phrase-based and hierar-chical systems to support this claim.5.4.1 Quantitative ResultsFigure 2 shows the experimental results whenforcing our phrase-based system to generate un-seen test data.
We observe more than 30% in-crease in reachability from tol = 20 to tol = 50for all dl ?
6 which supports our hypothesis thatincreasing tol by a small multiple can have a sig-nificant impact on performance.
With no limit ontol, reachability nearly triples.French Spans Number of Translationsdes 3006les 2464la 1582de 1557en 1428de la 1332fait 1308une 1303a` 1291le 1273d?
1271faire 1263l?
1111c?
est 1109a` la 1053, 1035Table 3: French spans with more than 1000 trans-lation options.Notably, the increase stems from the small frac-tion of French spans (0.1%) which have more than20 translation options (Table 2).
There are only16 French spans (Table 3) which have more than1000 translation options, however, utilising thesecan still achieve an increase in reachability of upto 5%.
The list shown in Table 3 includes commonarticles, interpuncutation, conjunctions, preposi-tions but also verbs which have unreliable align-ment points and therefore a very long tail of lowprobability translation options.
Yet, the largest in-crease does not stem from using such unreliabletranslation options, but rather when increasing tolby a relatively small amount.The increases we see in reachability are pro-portional to the size of the ruleset: The high-est increases in ruleset size can be seen betweentol = 20 and tol = 200 (Table 2), similarly, reach-ability performance has then the largest increase.For higher tol settings both the increases of rulesetsize and reachability are smaller.Figure 3 plots the average number of words persentence for the reachable sentences.
The averagesentence length increases by up to six words whenusing all translation options.
The black line repre-sents the average number of words per sentence ofthe reference set.
This shows that longer and morecomplex sentences can be generated when usingmore translation options.Similarly, for our hierarchical system (see Fig-22720 50 100 200 400 800 All14161820222426283032Translation Option LimitAverageNumber of Words per Sentencedl=6dl=7dl=8dl=9dl=10dl=11dl=12dl=13dl=14dl=15dl=16ReferenceFigure 3: Average number of words per sen-tence for the reachable test data translations of thephrase-based system (as shown in Figure 2).25 50 100 200 400 800 1600 3200 6400 12800 Inf510152025303540Sample Limit (SL)Reachability(%)Figure 4: Coverage for hierarchical referencealigned translation on test data when varying thenumber of matching French samples (sl) drawnfrom the training data.
The baseline setting issl = 300.ure 4) we find that reachability can be more thandoubled when drawing a richer ruleset sample thanin the baseline setting.
Those results are not di-rectly comparable to the phrase-based system dueto the slightly different nature of the parameterswhich were varied: In the phrase-based case wehave tol different English spans per French span.In the hierarchical system it is very likely to haveduplicate French spans in the sample drawn fromtraining data.
Yet, the trend is the same and thussupports our claim.5.4.2 Qualitative ResultsWe were interested how the performance increasecould be achieved and therefore looked into whichkind of translation options were involved when atranslation was generable with a higher tol setting.One possibility is that the long tail of translationoptions includes all kinds of English spans thatmatch some part of the reference but are simplyan artifact of unreliable alignment points.We looked at the first twenty translations pro-duced by our phrase-based system under dl = 10which could not be generated with tol = 20 butwith tol = 50.
The aim was to find out whichtranslation options made it possible to reach thereference under tol = 50.We found that nearly half (9) involved transla-tion options which used a common or less com-mon translation of the foreign span.
The first fourtranslations in Table 4 are examples for that.
Whenallowing unaligned words at the rule edges it turnsout that even 13 out of 20 translations are based onsound translation options.The remaining sentences involved translationoptions which were an artifact of unreliable align-ment points.
An example rule is la / their, whicherroneously translates a common determiner intoan equally common adjective.
The last translationin Figure 4 involves such a translation option.This analysis demonstrates that the performanceincrease between tol = 20 to tol = 50 is to aconsiderable extent based on translation optionswhich are meaningful.5.5 Analysis of Mutual ReachabilityThe aim of this analysis was to find out by howmuch the high-probability search spaces of thephrase-based and hierarchical models differ.
Thenecessary data was obtained via forcing each sys-tem to produce the 1-best translation of the othersystem denoted as the unconstrained translation.This unconstrained translation used the standardsetting for the number of translation options.We controlled for the way unaligned wordswere handled during rule extraction: The phrase-based system allowed unaligned words at theedges of phrases while the hierarchical system didnot.
We varied this condition for the phrase-basedsystem.
The distortion limit of the phrase-basedsystem was set to 10.
This is equal to the maxi-mum span a rule can be applied within the hierar-chical system.We carried out the same experiment forGerman-English and English-German translationwhich serve as examples for translating into a mor-228S: je voterai en faveur du projet de re`glement .R: i will vote to approve the draft regulation .O: i shall be voting in favour of the draft regulation .S: ... il npeut y avoir de de?lai transitoire en matie`re de respect des re`gles de?mocratiques .R: ... there can be no transitional period for complying with democratic rules .O: ... there can be no transitional period in the field of democratic rules .S: je souhaite aux ne?gociateurs la poursuite du succe`s de leur travail dans ce domaine important .R: i wish the negotiators continued success with their work in this important area .O: i wish the negotiators the continuation of the success of their work on this important area .S: mais commencons par les points positifs .R: but let us begin with the good news .O: but let us begin with the positive points .S: ... partage la plupart des conclusions que tire le rapporteur .R: ... share the majority of conclusions that he draws .O: ... share most of the conclusions that is the rapporteur .Table 4: Example translations which could be generated with tol = 50 but not with tol = 20.
For eachtranslation the source (S), reference (R) and the unconstrained output (O) are shown.
Bold phrases marktranslation options which were not available under tol = 20.phologically simpler and more complex languagerespectively.
The test and training sets for theselanguages are similarly sized and are from theWMT08 shared task.5.5.1 Quantitative ResultsTable 5 shows the mutual reachability perfor-mance for our phrase-based and hierarchical sys-tem.
The hierarchical system can generate almostall of the 1-best phrase-based translations, partic-ularly when unaligned words at rule edges are dis-allowed which is the most equal condition we ex-perimented with.
The phrase-based reachabilityfor English-German using tight rulesets is remark-ably low.
We found that this is because the hi-erarchical model allows unaligned words aroundgaps under the tight constraint.
This makes it veryhard for the phrase-based system to reach the hi-erarchical translation.
However, the phrase-basedsystem can overcome this problem when the tight-ness constraint is loosened (last row in Table 5).Table 6 shows the translation performance mea-sured in BLEU for both systems for normal un-constrained translation.
It can be seen that the dif-ference is rather marginal which is in line with ourreachability results.We were interested why certain translations ofone system were not reachable by the other sys-tem.
The following two subsections describeour analysis of these translations for the French-English language pair.Translation Direction fr-en de-en en-deHt ?
Pt 99.40 97.65 98.50Ht ?
Pnt 95.95 93.95 94.30Pt ?
Ht 93.75 92.30 82.95Pnt ?
Ht 97.55 97.55 96.30Table 5: Mutual reachability performance forFrench-English (fr-en), German-English (de-en)and Enlgish-German (en-de).
P?
H denotes howmany hierarchical (H) high scoring outputs can bereached by the phrase-based (P) system.
The sub-scripts nt (non-tight) and t (tight) denote the useof rules with unaligned words or not.5.5.2 Qualitative Analysis of UnreachableHierarchical TranslationsWe analysed the first twenty translations withinthe set of unreachable hierarchical translationswhen disallowing unaligned words at rule edges tofind out why the phrase-based system fails to reachthem.
Two aspects were considered in this anal-ysis: First, the successful hierarchical derivationand second, the relevant part of the phrase-basedruleset which was involved in the failed forcedtranslation i.e.
how much of the input and the ref-erence could be covered by the raw phrase-pairsavailable to the phrase-based system.Within the examined subset, the majority ofsentences (14) involved hierarchical rules whichcould not be replicated by the phrase-based sys-229System fr-en de-en en-dePhrase-based 31.96 26.94 19.96Hierarchical 31.62 27.18 20.20Difference absolute 0.34 0.24 0.24Difference (%) 1.06 0.90 1.20Table 6: Performance for phrase-based and hier-archical systems in BLEU for French-English (fr-en), German-English (de-en) and English-German(en-de).tem.
We described this as the first structural dif-ference in ?4.
Almost all of these translations(12 out of 14) could not be generated becauseof the third structural difference which involvedrule that omits the translation of a word withinthe French span.
An example is the rule X ?estX 1 ordinaireX 2 /isX 1 X 2 which omits a trans-lation for the French word ordinaire in the Englishspan.
For this particular subset the capability ofthe hierarchical system to capture long-distancereorderings did not make the difference, but ratherthe ability to drop words within a translation rule.The phrase-based system cannot learn manyrules which omit the translation of words becausewe disallowed unaligned words at phrase edges.The hierarchical system has the same restriction,but the constraint does not prohibit rules whichhave unaligned words within the rule.
This allowsthe hierarchical system to learn rules such as theone presented above.
The phrase-based systemcan learn similar knowledge, although less gen-eral, if it is allowed to have unaligned words atthe phrase edges.
In fact, without this constraint13 out of the 20 analysed rules can be generatedby the phrase-based system.Figure 5 shows a seemingly simple hierarchi-cal translation which fails to be constructed by thephrase-based system: The second rule applicationinvolves both the reordering of the translation ofpostaux and the omittance of a translation for con-currence.
This translation could be easily capturedby a phrase-pair, however, it requires that the train-ing data contains exactly such an example whichwas not the case.
The closest rule the phrase-basedrulestore contains is des services postaux / postalservices which fails since it does not cover all ofthe input.
This is an example for when the gen-eralisation of the hierarchical model is superior tothe phrase-based approach.5.5.3 Qualitative Analysis of UnreachablePhrase-based TranslationsThe size of the set of unreachable phrase-basedtranslations is only 0.6% or 12 sentences.
Thismeans that almost all of the 1-best outputs of thephrase-based translations can be reached by the hi-erarchical system.
Similarly to above, we analysedwhich words of the input as well as which wordsof the phrase-based translation can be covered bythe available hierarchical translation rules.We found that all of the translations were notgenerable because of the second structural differ-ence we identified in ?4.
The hierarchical rule-set did not contain a rule with the necessary lex-ical evidence to perform the same reordering asthe phrase-based model.
Figure 6 shows a phrase-based translation which could not be reached bythe hierarchical system because a rule of the formX ?
e?lectoralesX 1 /X 1 electoral would be re-quired to move the translation of e?lectorales (elec-toral) just before the translation of re?unions (meet-ings).
Inspection of the hierarchical ruleset revealsthat such a rule is not available and so the transla-tion cannot be generated.The small size of the set of unreachable phrase-based translations shows that the lexically in-formed reordering mechanism of the hierarchicalmodel is not a large obstacle in generating most ofthe phrase-based outputs.In summary, each system can reproduce nearlyall of the highest-scoring outputs of the other sys-tem.
This shows that the 1-best regions of bothsystems are nearly identical despite the differ-ences discussed in ?4.
This means that differencesin observed system performance are probably at-tributable to the degree of model error and searcherror in each system.6 Related Work and Open QuestionsZhang et al (2008) and Wellington et al (2006)answer the question: what is the minimal gram-mar that can be induced to completely describe atraining set?
We look at the related question ofwhat a heuristically induced ruleset can translatein an unseen test set, considering both phrase- andgrammar-based models.
We also extend the workof Zollmann et al (2008) on Chinese-English, per-forming the analysis in both directions and provid-ing a detailed qualitative explanation.Our focus has been on the induction error ofmodels, a previously unstudied cause of transla-230Source: concurrence des services postauxReference: competition between postal servicesHierarchical: postal servicesDeviation:( [0-4: @S -> @X?1 | @X?1 ]( [0-4: @X -> concurrence @X?1 postaux | postal @X?1 ] postal( [1-3: @X -> des services | services ] services)))Figure 5: Derivation of a hierarchical translation which cannot be generated by the phrase-based system,in the format of Zollmann et al (2008).
The parse tree contains the outputs (shaded) at its leaves in infixorder and each non-leaf node denotes a rule, in the form: [ Source-span: LHS?RHS ].Source: ceux qui me disaient cela faisaient par exemple re`fe`rence a` certaines desre?unions e?lectorales auxquelles ils avaient assiste?
.Phrase-based: those who said to me that were for example refer to some of whichthey had been electoral meetings .Reference: they referred to some of the election meetings , for example , thatthey had gone to .Figure 6: Phrase-based translation which cannot be reached by the hierarchical system because no rule toperform the necessary reordering is available.
Marked sections are source and reference spans involvedin the largest possible partial hierarchical derivation.tion errors.
Although the results described hereare striking, our exact match criterion for reach-ability is surely too strict?for example, we re-port an error if even a single comma is missing.One solution is to use a more tolerant criterionsuch as WER and measure the amount of devia-tion from the reference.
We could also maximizeBLEU with respect to the reference as in Dreyer etal.
(2007), but it is less interpretable.7 Conclusion and Future WorkSparse distributions are common in natural lan-guage processing, and machine translation is noexception.
We showed that utilizing more of theentire distribution can dramatically improve thecoverage of translation models, and possibly theiraccuracy.
Accounting for sparsity explicitly hasachieved significant improvements in other areassuch as in part of speech tagging (Goldwater andGriffiths, 2007).
Considering the entire tail is chal-lenging, since the search space grows exponen-tially with the number of translation options.
Afirst step might be to use features that facilitatemore variety in the top 20 translation options.
Amore elaborate aim is to look into alternatives tomaximum likelihood hood estimation such as inBlunsom and Osborne (2008).Additionally, our expressiveness analysis showsclearly that the 1-best region of hierarchical andphrase-based models is nearly identical.
Dis-counting cases in which systems handle unalignedwords differently, we observe an overlap of be-tween 96% and 99% across three language pairs.This implies that the main difference between themodels is in their parameterization, rather than inthe structural differences in the types of transla-tions they can produce.
Our results also suggestthat the search spaces of both models are highlyoverlapping: The results for the 1-best region al-low the conjecture that also other parts of thesearch space are behaving similarly since it ap-pears rather unlikely that spaces are nearly disjointwith only the 1-best region being nearly identical.In future work we aim to use n-best lists or latticesto more precisely measure search space overlap.We also aim to analyse the effects of the modeland search errors for these systems.AcknowledgementsThis research was supported by the EuromatrixProject funded by the European Commission (6thFramework Programme).
The experiments wereconducted using the resources provided by theEdinburgh Compute and Data Facility (ECDF).Many thanks to the three anonymous reviewers forvery helpful comments on earlier drafts.231ReferencesN.
F. Ayan and B. Dorr.
2006.
Going beyond AER:An extensive analysis of word alignments and theirimpact on MT.
In Proc.
of ACL-COLING, pages 9?16, Jul.P.
Blunsom and M. Osborne.
2008.
Probabilistic infer-ence for machine translation.
In Proc.
of EMNLP.D.
Chiang.
2007.
Hierarchical phrase-based transla-tion.
Computational Linguistics, 33(2):201?228.M.
Dreyer, K. B.
Hall, and S. P. Khudanpur.
2007.Comparing reordering constraints for SMT using ef-ficient BLEU oracle computation.
In Proc.
of Work-shop on Syntax and Structure in Statistical Transla-tion, pages 103?110, Apr.U.
Germann, M. Jahr, K. Knight, D. Marcu, and K. Ya-mada.
2004.
Fast and optimal decoding for machinetranslation.
Artificial Intelligence, 154(1?2):127?143, Apr.S.
Goldwater and T. Griffiths.
2007.
A fully Bayesianapproach to unsupervised part-of-speech tagging.
InProc.
of ACL, pages 744?751, Prague, Czech Re-public, June.P.
Koehn, F. J. Och, and D. Marcu.
2003.
Statisticalphrase-based translation.
In Proc.
of HLT-NAACL,pages 48?54, Morristown, NJ, USA.P.
Koehn, H. Hoang, A.
B. Mayne, C. Callison-Burch,M.
Federico, N. Bertoldi, B. Cowan, W. Shen,C.
Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin,and E. Herbst.
2007.
Moses: Open source toolkitfor statistical machine translation.
In Proc.
of ACLDemonstration Session, pages 177?180, Jun.P.
Koehn.
2005.
Europarl: A parallel corpus for statis-tical machine translation.
In MT Summit.A.
Lopez.
2008a.
Statistical machine translation.ACM Computing Surveys, 40(3).A.
Lopez.
2008b.
Tera-scale translation models viapattern matching.
In Proc.
of COLING, pages 505?512, Aug.A.
Lopez.
2009.
Translation as weighted deduction.In Proc.
of EACL.F.
J. Och and H. Ney.
2003.
A systematic comparisonof various statistical alignment models.
Computa-tional Linguistics, 29(1):19?51.F.
J. Och.
2003.
Minimum error rate training in sta-tistical machine translation.
In Proc.
of ACL, pages160?167, Morristown, NJ, USA.K.
Papineni, S. Roukos, T. Ward, and W. jing Zhu.2002.
BLEU: A method for automatic evaluationof machine translation.
In Proc.
of ACL, pages 311?318.L.
Schwartz.
2008.
Multi-source translation methods.In Proc.
of AMTA, October.A.
Stolcke.
2002.
SRILM ?
an extensible languagemodeling toolkit.
In Proc.
Int.
Conf.
Spoken Lan-guage Processing (ICSLP 2002).B.
Wellington, S. Waxmonsky, and I. D. Melamed.2006.
Empirical lower bounds on the complexityof translational equivalence.
In Proc.
of ACL, pages977?984, Morristown, NJ, USA.H.
Zhang, D. Gildea, and D. Chiang.
2008.
Extractingsynchronous grammar rules from word-level align-ments in linear time.
In Proc.
of COLING, pages1081?1088, Manchester, UK.A.
Zollmann, A. Venugopal, F. Och, and J. Ponte.2008.
A systematic comparison of phrase-based, hi-erarchical and syntax-augmented statistical MT.
InProc.
of COLING.232
