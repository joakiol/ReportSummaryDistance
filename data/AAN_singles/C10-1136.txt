Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 1209?1217,Beijing, August 2010Build Chinese Emotion LexiconsUsing A Graph-based Algorithm and Multiple ResourcesGe Xu, Xinfan Meng, Houfeng WangKey Laboratory of Computational Linguistics (Peking University), Ministry of EducationInstitute of Computational Linguistics, Peking University{xuge, mxf, wanghf}@pku.edu.cnAbstractFor sentiment analysis, lexicons play animportant role in many related tasks.
Inthis paper, aiming to build Chinese emo-tion lexicons for public use, we adopted agraph-based algorithm which ranks wordsaccording to a few seed emotion words.The ranking algorithm exploits the simi-larity between words, and uses multiplesimilarity metrics which can be derivedfrom dictionaries, unlabeled corpora orheuristic rules.
To evaluate the adoptedalgorithm and resources, two independentjudges were asked to label the top wordsof ranking list.It is observed that noise is almost un-avoidable due to imprecise similarity met-rics between words.
So, to guaranteethe quality of emotion lexicons, we usean iterative feedback to combine man-ual labeling and the automatic ranking al-gorithm above.
We also compared ournewly constructed Chinese emotion lexi-cons (happiness, anger, sadness, fear andsurprise) with existing counterparts, andrelated analysis is offered.1 IntroductionEmotion lexicons have a great impact on the re-sults of related tasks.
With high-quality emo-tion lexicons, systems using simple methodscan achieve competitive performance.
However,to manually build an emotion lexicon is time-consuming.
Many research works in building lex-icons use automatic methods to assist the buildingprocedure.
Such works commonly rank words bythe similarities to a set of seed words, then thosewords with high ranking scores are more likely tobe added to the final lexicons or used as additionalseed words.For Chinese, emotion lexicons are scarce re-sources.
We can get a small set of emotion wordsfrom semantic dictionary (such as CCD, HowNet,synonym dictionaries) or directly from related pa-pers (Xu and Tao, 2003) (Chen et al , 2009), but itis often not sufficient for practical systems.
Xu etal.
(2008) constructed a large-scale emotion on-tology dictionary, but it is not publicly availableyet.In this paper, we adopted a graph-based algo-rithm to automatically rank words according to afew seed words.
Similarity between words can beutilized and multiple resources are used to boostperformance.
Combining manual labeling withautomatic ranking through an iterative feedbackframework, we can produce high-quality emotionlexicons.
Our experiments focused on Chinese,but the method is applicable to any other languageas long as suitable resources exist.The remainder of this paper is organized as fol-lows.
In Section 2, related works are introduced.In Section 3, we describe a graph-based algorithmand how to incorporate multiple resources.
Sec-tion 4 gives the details of applying the algorithmon five emotions and shows how to evaluate the re-sults.
Section 5 focuses on how to build and evalu-ate emotion lexicons, linguistic consideration andinstruction for identifying emotions are also in-cluded.
Finally, conclusion is made in Section 6.12092 Related workRiloff and Shepherd (1997) presented a corpus-based method that can be used to build seman-tic lexicons for specific categories.
The input tothe system is a small set of seed words for a cat-egory and a representative text corpus.
The out-put is a ranked list of words that are associatedwith the category.
An approach proposed by (Tur-ney, 2002) for the construction of polarity startedwith a few positive and negative seeds, then useda similarity method (pointwise mutual informa-tion) to grow this seed list from web corpus.Our experiments are similar with these works, butwe use a different ranking method and incorpo-rate multiple resources.
To perform rating infer-ence on reviews, Goldberg and Zhu (2006) cre-ated a graph on both labeled and unlabeled re-views, and then solved an optimization problemto obtain a smooth rating function over the wholegraph.
Rao and Ravichandran (2009) used threesemi-supervised methods in polarity lexicon in-duction based on WordNet, and compared themwith corpus-based methods.
Encouraging resultsshow methods using similarity between words canimprove the performance.
Wan and Xiao (2009)presented a method to use two types of similaritybetween sentences for document summarization,namely similarity within a document and simi-larity between documents.
The ranking methodin our paper is similar to the ones used in abovethree papers, which fully exploit the relationshipbetween any pair of sample points (both labeledand unlabeled).
When only limited labeled dataare available, such method achieves significantlybetter predictive accuracy over other methods thatignore the unlabeled examples during training.Xu et al (2008) at first formed a taxonomy foremotions, under which an affective lexicon ontol-ogy exploiting various resources was constructed.The framework of ontology is filled by the com-bination of manual classification and automaticmethods?To our best knowledge, this affectivelexicon ontology is the largest Chinese emotion-oriented dictionary.3 Our method3.1 A graph-based algorithmFor our experiments, we chose the graph-based al-gorithm in (Zhou et al , 2004) which is transduc-tive learning and formulated as follows:Given a point set ?
= {x1, ..., xl, xl+1, ..., xn},the first l points xi(i ?
l) are labeled and the re-maining points xu(l+1 ?
u ?
n) unlabeled.
Thegoal is to rank the unlabeled points.Let F denotes an n-dimensional vector whoseelements correspond to ranking scores on the dataset ?.
Define another n-dimensional vector Y withYi = 1 if xi is labeled and Yi = 0 otherwise.
Ydenotes the initial label assignment.The iterative algorithm is shown in the follow-ing:Algorithm 1 A graph-based algorithm1.
Construct the weight matrix W and set Wii tozero to avoid self-reinforcement.
W is domain-dependent.2.
Construct the similarity matrix S =D1/2WD1/2 using symmetric normalization.
Dis a diagonal matrix with Dii = ?jWij .3.
Iterate F (t + 1) = ?SF (t) + (1 ?
?
)Y untilconvergence, where ?
is a parameter in (0, 1), andF (0) = Y .
We clamp labeled points to 1 aftereach iteration.4.
Let F ?
denote F (t) when the iteration con-verges.In our experiments, labeled points are seedemotion words, Sij denotes the similarity betweenith word and jth word.
In an iteration, each wordabsorbs label information from other words.
Moresimilar two words are, more influence they haveon each other.
The label information (initiallyfrom seed emotion words) will propagate along S.The final output F ?
contains ranking scores for allwords, and a score indicates how similar the cor-responding word is to the seed emotion words.The implementation of the iterative algorithmis theoretically simple, which only involves ba-sic matrix operation.
Compared with meth-ods which do not exploit the relationship be-tween samples, experiments showing advantagesof graph-based learning methods can be found1210in (Rao and Ravichandran, 2009),(Goldberg andZhu, 2006),(Tong et al , 2005),(Wan and Xiao,2009),(Zhu and Ghahramani, 2002) etc.
When la-beled data are scarce, such graph-based transduc-tive learning methods are especially useful.3.2 Incorporate multiple resourcesFor building the emotion lexicons, we are facedwith lots of resources, such as semantic dictio-naries, labeled or unlabeled corpora, and somelinguistic experiences which can be presented asheuristic rules.
Naturally we want to use theseresources together, thus boosting the final perfor-mance.
In graph-base setting, such resources canbe used to construct the emotion-oriented similar-ity between words, and similarities will be repre-sented by matrices.The schemes to fuse similarity matrices are pre-sented in (Sindhwani et al , 2005), (Zhou andBurges, 2007), (Wan and Xiao, 2009) and (Tong etal.
, 2005) etc.
In our paper, not aiming at compar-ing different fusion schemes, we used a linear fu-sion scheme to fuse different similarities matricesfrom different resources.
The scheme is actuallya convex combination of matrices, with weightsspecified empirically.The fusion of different similarity matricesfalls in the domain of multi-view learning.
Awell-known multi-view learning method is Co-Training, which uses two views (two resources)to train two interactive classifiers (Blum andMitchell, 1998).
Since we focus on building emo-tion lexicons using multiple resources (multipleviews), those who want to see the advantages ofmulti-view learning over learning with one viewcan refer to (Blum and Mitchell, 1998), (Sind-hwani et al , 2005), (Zhou and Burges, 2007),(Wan and Xiao, 2009) and (Tong et al , 2005)etc.4 ExperimentsWe use the method in section 3 to rank for eachemotion with a few seed emotion words.
Once weimplement the ranking algorithm 1, the main workresides in constructing similarity matrices, whichare highly domain-dependent.4.1 Construct similarity matricesHere, we introduce how to construct four sim-ilarity matrices used in building emotion lexi-cons.
Three of them are based on cooccurrence ofwords; the fourth matrix is from a heuristic rule.We use ictclas3.01 to perform word segmenta-tion and POS tagging.In our experiments, the number of words in-volved in ranking is 935062, so theoretically, thematrices are 93506 ?
93506.
If the similarity be-tween any pair of words is considered, the compu-tation becomes impractical in both time and spacecost.
So we require that each word has at most500 nearest neighbors.Four matrices are constructed as follows:4.1.1 Similarity based on a unlabeled corpusThe unlabeled corpus used is People?sDaily3(?
?
?
?1997?2004).
After wordsegmentation and POS tagging, we chose threePOS?s (i,a,l)4.
The nouns were not includedto limit the scale of word space.
We set thecooccurrence window to a sentence, and removedthe duplicate occurrences of words.
Any pair ofwords in a sentence will contribute a unit weightto the edge which connects the pair of words.4.1.2 Similarity based on a synonymdictionaryWe used the Chinese synonym dictionary (??????????
?5) for this matrix.
Inthis dictionary, the words in a synonym set arepresented in one line and separated by spaces, sothere is no need to perform word segmentationand POS tagging.
Any pair of words in one linewill contribute a unit weight to the edge whichconnects the pair of words.4.1.3 Similarity based on a semanticdictionaryWe used The Contemporary Chinese Dictio-nary (??????)
to construct the third simi-1downloaded from http://www.ictclas.org/2Words are selected after word segmentation and POStagging, see section 4.1.1?4.1.3 for selection of words in de-tails.3http://icl.pku.edu.cn/4i=Chinese idiom, a=adjective, l=Chinese phrase5http://ir.hit.edu.cn/1211larity matrix.
Since word segmentation may seg-ment the entries of the dictionary, we extracted allthe entries in the dictionary and store them in a filewhose words ictclas3.0 was required not to seg-ment.
Furthermore, for an entry in the dictionary,the example sentences or phrases appearing in itsgloss may contain many irrelevant words in termsof emotions, so they were removed from the gloss.After word segmentation and POS tagging6, weset the cooccurrence window to one line (an en-try and its gloss without example sentences orphrases), and removed the duplicate occurrencesof words.
An entry and any word in the modi-fied gloss will contribute a unit weight to the edgewhich connects the pair of words.
This construct-ing was a bit different, since we did not considerthe similarity between words in modified gloss.4.1.4 similarity based on a heuristic ruleIn Chinese, a word is composed of one or sev-eral Chinese characters.
A Chinese character isnormally by itself an independent semantic unit,so the similarity between two words can be in-ferred from the character(s) that they share.
Forexample, the Chinese word ?
(happy) appearsin the word ??
(readily).
Since ??
and ?share one Chinese character, they are regarded assimilar.
Naturally, the larger the proportion thattwo words share, the more similar they are.
Inthis way, the fourth weighted matrix was formed.To avoid incurring noises, we exclude the caseswhere one Chinese character is shared, with theexception that the Chinese character itself is oneof the two Chinese words.4.1.5 Fusion of four similarity matricesAfter processing all the lines (or sentences), theweighted matrices are normalized as in algorithm1, then four similarity matrices are linearly fusedwith equal weights (1/4 for each matrix).4.2 Select seed emotion wordsIn our experiments, we chose emotions of happi-ness, sadness, anger, fear and surprise which arewidely accepted as basic emotions7.
Empirically,6since we do not segment entries in this dictionary, allPOS?s are possible7Guidelines for identifying emotions is in section 5, be-fore that, we understand emotions through common sense.we assigned each emotion with seed words givenin Table 1.Emotion Seed words?
(happiness) ??,??,??,??,????,??,???
(anger) ??,??,??,??,?
?, ?
?, ?
?, ?
?, ??,??,??,????,????,?????
(sadness) ??,??,??,??,??,??,??,??,???
?, ?
?, ???
?, ??,??,??,????,?????
(fear) ?
?, ?
?, ?
?, ???
?, ?
?, ?
?, ?
?, ??,????,?????
(surprise) ?
?, ????
,?
?, ??,??,??,?,????,??,?
?Table 1: Seed emotion words4.3 Evaluation of our methodWe obtained five ranking lists of words using themethod in section 3.
Following the work of (Riloffand Shepherd, 1997), we adopted the followingevaluation setting.To evaluate the quality of emotion ranking lists,each list was manually rated by two persons inde-pendently.
For each emotion, we selected the top200 words of each ranking list and presented themto judges.
We presented the words in random or-der so that the judges had no idea how our systemhad ranked the words.
The judges were asked torate each word on a scale from 1 to 5 indicatinghow strongly it was associated with an emotion, 0indicating no association.
We allowed the judgesto assign -1 to a word if they did not know whatit meant.
For the words rated as -1, we manuallyassigned ratings that we thought were appropriate.The results of judges are shown in figures 1-5.In these figures, horizontal axes are the number ofreviewed words in ranking lists and vertical axesare number of emotion words found (with 5 dif-ferent strength).
The curve labeled as > x meansthat it counts the number of words which are rated12120 50 100 150 200020406080100120140160words reviewedemotionwords found>0>1>2>3>4Figure 1: happiness0 50 100 150 200020406080100120140160words reviewedemotionwords found>0>1>2>3>4Figure 2: angergreater than x by either judge.Curves (> 0, > 1, > 2) display positive slopeseven at the end of the 200 words, which impliesthat more emotion words would occur if morethan 200 words are reviewed.
By comparison,curves (> 3, > 4) tend to be flat when they areclose to the right side, which means the cost ofidentifying high-quality emotion words will in-crease greatly as one checks along the ranking listin descendent order.It is observed that words which both judges as-sign 5 are few.
In surprise emotion, the numberis even 0.
Such results may reflect that emotionis harder to identify compared with topical cate-gories in (Riloff and Shepherd, 1997).0 50 100 150 200020406080100120140160180words reviewedemotionwords found>0>1>2>3>4Figure 3: sadness0 50 100 150 200020406080100120140words reviewedemotionwords found>0>1>2>3>4Figure 4: fear0 50 100 150 200020406080100120words reviewedemotionwords found>0>1>2>3>4Figure 5: surpriseFrom the semantic dictionary, our methodfound many low-frequency emotion words such as?
(pleasant, glad),??
(surprise and happy),??
(sad), or those used in Chinese dialects such as??
(fear), ??
(angry).
Such emotion wordsare necessary for comprehensive emotion lexi-cons.Because more POS?s than adjectives and verbsare included in our experiments, some emotionwords such as the noun ??
(unexpected win-ner),and the adverb ??
(to one?s surprise) arealso spotted, which to some extent implies thegenerality of our method.5 Construct emotion lexiconsThe above section introduced a method to rankwords with a few seed emotion words.
How-ever, to build emotion lexicons requires that wemanually remove the noises incurred by the au-tomatic ranking method.
Accordingly, guide-lines for identifying emotions are needed, and alsosome linguistic consideration in identifying emot-ing words should be given.12135.1 An iterative feedback to denoiseIn our experiments, we observed that noises in-curred by similarity matrices are almost unavoid-able.
For example, in the unlabeled corpus, ????
(state visits) always co-occurred with ??
(happy) or??
(happy), so in happiness emo-tion, ????
acquired a high ranking position(174th); in terms of the heuristic rule, ??
(ex-pected) shares two Chinese characters with ????
(unexpected, surprised), however they haveopposite meaning because??
(exceed, beyond)is a negative word.
??
unfavorably ranked high(88th) in surprise emotion; from the semantic dic-tionary, the gloss of??
(Chinese Spring Festivalpictures) contains??
(happy), thus in happinessemotion,??
ranked high (158th).So after each ranking of an emotion, in the de-scendent order of ranking scores, we manually re-vised some scores in about top 500.
Several crite-ria (see 5.2 and 5.3) were given to guide if a wordhas a specified emotion.
For those words surelybearing the specified emotion, we assigned 1 tothem ,and left others unchanged.
Seeing the wordsnewly revised to be 1 as new seed emotion words,we run the ranking algorithm again.
After suchfeedback was repeated 2?3 times, we collectedall the words labeled with 1 to form the final emo-tion lexicons.
In (Zhou et al , 2004), the authoralso suggested such iterative feedback to extendthe query (seed) set and improve the ranking out-put.
Commonly, the size of an emotion lexicon issmall, so we do not have to check too many words.The human revising procedure is sensitive toannotators?
background.
To improve the qualityof the emotion lexicons, experts with linguistic orpsychology background will help.Furthermore, the ranking algorithm used in ourpaper is clearly sensitive to the initial seed words,but since we adopt an iterative feedback frame-work, the words not appearing in the initial setof seed words will show up in next iteration withhigh ranking scores.
We also performed experi-ments which selected emotion seed words basedon the Chinese synonym dictionary and the emo-tion words in (Chen et al , 2009), similar resultswere found.5.2 Guidelines for identifying emotionsThe same as (Chen et al , 2009), we used the def-inition that emotion is the felt awareness of bod-ily reactions to something perceived or thought.Also, we were highly influenced by the structureof the affective lexicon presented by (Ortony etal.
, 1987), and used the Affective states andAffective-Behavioral conditions in the structure toidentify emotion words in our paper8.With such guidelines,??
(cowardice, relatesmore to external evaluation) is not an emotionalword of fear.
We also intentionally distinguish be-tween emotions and expression of emotions.
Forexample, ??
(laugh), ??
(haw-haw) are seenas expression of happiness and??
(tremble) asof fear, but not as emotion words.
In addition,we try to distinguish between an emotion and thecause of an emotion, see 5.3 for an example.For each emotion, brief description is given asbelow9:1.
Happiness?the emotional reaction to some-thing that is satisfying.2.
Anger?do not satisfy the current situationand have a desire to fight or change the situa-tion.
Often there exists a target for this emo-tion.3.
Sadness?an emotion characterized by feel-ings of disadvantage, loss, and helplessness.Sadness often leads to cry.4.
Fear?the emotional response to a perceivedthreat.
Fear almost always relates to futureevents, such as worsening of a situation, orcontinuation of a situation that is unaccept-able.5.
Surprise?the emotional reaction to some-thing unexpected.5.3 Linguistic consideration for identifyingemotion wordsIf a word has multiple senses, we only consider itsemotional one(s).
For example,??
(as a verb, itmeans be angry, but means vitality or spirits as anoun) will appear in the emotion lexicon of anger.8According to (Ortony et al , 1987), surprise should notbe seen as a basic emotion for it relates more to cognition.However, our paper focuses on the building of emotion lexi-cons, not the disputable issue of basic emotions9we mainly referred to http://en.wikipedia.org/wiki1214If one sense of a word is the combination of emo-tions, the word will appear in all related emotions.We mainly consider four POS?s, namely nouns,verbs, adjectives and adverb10.
If a word has mul-tiple POS?s, we normally consider its POS withstrongest emotion (Empirically, we think the emo-tion strength ranks in decedent order as following:adjectives, verbs, adverbs, nouns.).
So we con-sider the verb of??
(fear) when it can be usedas a noun and a verb in Chinese.
The??
exam-ple above also applies here.For each of four POS?s, instruction for emotionidentification is given as below:Nouns: For example,??
(rage, anger),??
(joy or jubilation), ??
(an unexpected winner)are selected as emotion words.
We distinguish be-tween an emotion and the cause of an emotion.For example, calamity often leads to sadness, butdoes not directly contain the emotion of sadness.??
appears in the surprise lexicon because webelieve it contains surprise by itself.Adverbs: The adverbs selected into emotionlexicons contain the emotions by themselves.
Forexample,??
(unexpectedly),???
(cheerily),???
(angrily), ??
(unexpectedly), ???
(sadly) etc.Verbs: As in (Ortony et al , 1987), Chi-nese emotion verbs also fall into at least two dis-tinct classes, causatives and noncausatives.
Bothclasses are included in our emotion lexicons.
Forexample, ???
(be angry), ??
(fear) arenoncausative verbs, while ??
(enrage), ??
(to make someone surprised) are causative ones.Probably due to the abundant usage of ??/??/??
(to make someone) etc., causative emo-tion verbs are few compared to noncausative onesin Chinese.Adjective?Quite a lot of emotion words fall inthis POS, since adjectives are the natural expres-sion of internal states of humans.
For example,??
(happy),??
(surprised),??
(angry) etc.For any word that it is hard to identify at firstsight, we used a search tool11 to retrieve sentences10For Chinese idioms, we only considered those used asthese four POS?s, omitted those used as a statement, suchas????
(an army burning with righteous indignation isbound to win)11provided by Center for Chinese Linguistics of PekingUniversity, http://ccl.pku.edu.cnwhich contain the word, and then identify if theword is emotional or not by its usage in the sen-tences.5.4 Comparison with existing Chineseemotion resources???????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
?Table 2: The emotion lexicon of surpriseUnder the guidelines for manually identifyingemotion words, we finally constructed five Chi-nese emotion lexicons using the iterative feed-back.
The newly constructed emotion lexiconswere also reported as resources together with ourpaper.
The emotion lexicon of surprise is shownin Table 2.
In this part, we compare our lexiconswith the following counterparts, see Table 3.Ours1 in the table is the final emotion lexicons,and Ours2 is the abridged version that excludesthe words of single Chinese character and Chineseidioms.Chinese Concept Dictionary (CCD) is aWordNet-like semantic lexicon(Liu et al , 2003).1215?
?
?
?
?CCD nouns 22 27 38 46 10(Xu and Tao, 2003) 45 12 28 21 12(Chen et al , 2009) 28 34 28 17 11(Xu et al , 2008) 609 187 362 182 47Ours1 95 118 97 106 99Ours2 52 77 72 57 65Table 3: Compare various emotion lexiconsWe only considered the noun network which isrichly developed in CCD, as in other semantic dic-tionaries.
For each emotion, we chose its synsetas well as the synsets of its hypernym and hy-ponym(s).
In fact, most of words in the emotionnouns extracted can be used as verbs or adjectivesin Chinese.
However, since CCD is not designedfor emotion analysis, words which are expressionof emotions such as??
(cry) or evaluation suchas??
(cowardice) were included.Selecting nouns and verbs, Xu and Tao (2003)offered an emotion taxonomy of 390 emotionwords.
The taxonomy contains 24 classes of emo-tions and excludes Chinese idioms.
By our in-spection to the offered emotion words in this tax-onomy, the authors tried to exclude expression ofemotions, evaluation and cause of emotions fromemotions, which is similar with our processing12.Ours2 is intentionally created to compare with thisemotion taxonomy.Based on (Xu and Tao, 2003), Chen et al(2009) removed the words of single Chinese char-acter; let two persons to judge if a word is anemotional one and only those agreed by the twopersons were seen as emotion words.
It is worthnoting that Chen et al (2009) merges?
(anger)and?
(fidget) in (Xu and Tao, 2003) to form the?
(anger) lexicon, thus??
(dislike) appears inanger lexicon.
However, we believe??
(dislike)is different with?
(anger), and should be put intoanother emotion.
Also, we distinguish between?
(hate) and?
(anger).Xu et al (2008) constructed a large-scale affec-tive lexicon ontology.
Given the example wordsin their paper, we found that the authors did notintentionally exclude the expression of emotionssuch as????
(literally, red face and ear),???
(literally, be smiling).
Such criteria of iden-12Xu and Tao (2003) included words such as ??/??
(be willing to),??
(be careful) in their happiness lexicon,which we think should not be classified into happiness.tifying emotion words may partially account forthe large size of their emotion resources.6 Conclusion and future workIn this paper, aiming to build Chinese emotion lex-icons, we adopt a graph-based algorithm and in-corporate multiple resources to improve the qual-ity of lexicons and save human labor.
This is aninitial attempt to build Chinese emotion lexicons,the quality of constructed emotion lexicons is farfrom perfect and is supposed to be improved stepby step.The method in this paper can be further ex-tended to subjectivity/polarity classification andother non-sentimental tasks such as word similar-ity computing, and can be also adapted to otherlanguages.
The more resources we use, the morehuman cost can be saved and the higher the qual-ity of built emotion lexicons is.In the future work, we want to construct otheremotion lexicons such as ?
(like, love), ?
(dis-like),?
(desire) etc.
using the same method.Acknowledgement This research is supportedby National Natural Science Foundation of China(No.60973053, No.90920011)ReferencesA.
Blum and T. Mitchell.
1998.
Combining labeledand unlabeled data with co-training?
In Proceed-ings of the 11th Annual Conference on Computa-tional Learning Theory, 92-100.Ying Chen, Sophia Y. M. Lee, and Churen Huang.2009.
A Cognitive-based Annotation System forEmotion Computing.
Proceedings of the Third Lin-guistic Annotation Workshop (LAW III).Andrew B. Goldberg, Xiaojin Zhu.
2006.
Seeingstars when there aren?t many stars: graph-basedsemi-supervised learning for sentiment categoriza-tion.
Proceedings of TextGraphs: the First Work-shop on Graph Based Methods for Natural Lan-guage Processing on the First Workshop on GraphBased Methods for Natural Language Processing.Y.
Liu and et al 2003.
The CCD Construction Modeland Its Auxiliary Tool VACOL.
Applied Linguis-tics, 45(1):83-88.A.
Ortony, G. L. Clore, and M. A. Foss.
1987.
The ref-erential structure of the affective lexicon.
CognitiveScience, 11, 341-364.1216Delip Rao and D. Ravichandran.
2009.
Semisuper-vised polarity lexicon induction.
Proceedings of the12th Conference of the European Chapter of the As-sociation for Computational Linguistics, 675-682.Ellen Riloff and Jessica Shepherd.
1997.
A Corpus-Based Approach for Building Semantic Lexicons.In Proceedings of the Second Conference on Em-pirical Methods in Natural Language Processing,pages 117-124.V.
Sindhwani, P. Niyogi, and M. Belkin.
2005.
Aco-regularization approach to semisupervised learn-ing with multiple views.
Proc.
ICML Workshop onLearning with Multiple views.H.
Tong, J.
He, M. Li, C. Zhang, and W. Ma.
2005.Graph based multi-modality learning.
In Proceed-ings of the 13th Annual ACM international Con-ference on Multimedia.
MULTIMEDIA ?05.
ACM,New York, NY, 862-871.Peter D. Turney.
2002.
Thumbs up or thumbs down?Semantic orientation applied to unsupervised classi-fication of reviews.
ACL 2002, 417-424.Xiaojun Wan and Jianguo Xiao.
2009.
Graph-BasedMulti-Modality Learning for Topic-Focused Mul-tiDocument Summarization.
IJCAI 2009, 1586-1591.Linhong Xu, Hongfei Lin, Yu Pan, Hui Ren and Jian-mei Chen.
2008.
Constructing the Afective LexiconOntology.
JOURNAL OF THE CHINA SOCIETYF0R SCIENTIFIC AND TECHNICAL INFORMA-TION Vo1.27 No.2, 180-185.X.
Y. Xu, and J. H. Tao.
2003.
The study of affectivecategorization in Chinese.
The 1st Chinese Confer-ence on Affective Computing and Intelligent Inter-action.
Beijing, China.Hongbo Xu, Tianfang Yao, and Xuanjing Huang.2009.
The second Chinese Opinion Analysis Eval-uation(in Chinese).
COAE 2009.D.
Zhou, O. Bousquet, T. Lal, J. Weston, and B.Scholkopf.
2004.
Learning with local and globalconsistency.
Advances in Neural Information Pro-cessing Systems 16.
MIT Press, Cambridge, MA.
.D.
Zhou and C. J. C. Burges.
2007.
Spectral cluster-ing and transductive learning with multiple views.Proceedings of the 24th international conference onMachine learning.X.
Zhu and Z. Ghahramani.
2002.
Learning fromlabeled and unlabeled data with label propagation.Technical Report CMUCALD02107.
CMU.1217
