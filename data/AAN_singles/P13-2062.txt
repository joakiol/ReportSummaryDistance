Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 346?351,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsAutomatically Predicting Sentence Translation DifficultyAbhijit Mishra?, Pushpak Bhattacharyya?, Michael Carl??
Department of Computer Science and Engineering, IIT Bombay, India{abhijitmishra,pb}@cse.iitb.ac.in?
CRITT, IBC, Copenhagen Business School, Denmark,mc.ibc@cbs.dkAbstractIn this paper we introduce Translation Dif-ficulty Index (TDI), a measure of diffi-culty in text translation.
We first de-fine and quantify translation difficulty interms of TDI.
We realize that any mea-sure of TDI based on direct input by trans-lators is fraught with subjectivity and ad-hocism.
We, rather, rely on cognitive ev-idences from eye tracking.
TDI is mea-sured as the sum of fixation (gaze) andsaccade (rapid eye movement) times ofthe eye.
We then establish that TDI iscorrelated with three properties of the in-put sentence, viz.
length (L), degree ofpolysemy (DP) and structural complexity(SC).
We train a Support Vector Regres-sion (SVR) system to predict TDIs fornew sentences using these features as in-put.
The prediction done by our frame-work is well correlated with the empiri-cal gold standard data, which is a repos-itory of < L,DP, SC > and TDI pairsfor a set of sentences.
The primary use ofour work is a way of ?binning?
sentences(to be translated) in ?easy?, ?medium?
and?hard?
categories as per their predictedTDI.
This can decide pricing of any trans-lation task, especially useful in a scenariowhere parallel corpora for Machine Trans-lation are built through translation crowd-sourcing/outsourcing.
This can also pro-vide a way of monitoring progress of sec-ond language learners.1 IntroductionDifficulty in translation stems from the fact thatmost words are polysemous and sentences can belong and have complex structure.
While length ofsentence is commonly used as a translation diffi-culty indicator, lexical and structural properties ofa sentence also contribute to translation difficulty.Consider the following example sentences.1.
The camera-man shot the policemanwith a gun.
(length-8)2.
I was returning from my old officeyesterday.
(length-8)Clearly, sentence 1 is more difficult to processand translate than sentence 2, since it has lexicalambiguity (?Shoot?
as an act of firing a shot ortaking a photograph?)
and structural ambiguity(Shot with a gun or policeman with a gun?).
Toproduce fluent and adequate translations, effortshave to be put to analyze both the lexical and syn-tactic properties of the sentences.The most recent work on studying translationdifficulty is by Campbell and Hale (1999) whoidentified several areas of difficulty in lexis andgrammar.
?Reading?
researchers have focused ondeveloping readability formulae, since 1970.
TheFlesch-Kincaid Readability test (Kincaid et al,1975), the Fry Readability Formula (Fry, 1977)and the Dale-Chall readability formula (Chall andDale, 1999) are popular and influential.
These for-mulae use factors such as vocabulary difficulty (orsemantic factors) and sentence length (or syntac-tic factors).
In a different setting, Malsburg etal.
(2012) correlate eye fixations and scanpathsof readers with sentence processing.
While theseapproaches are successful in quantifying readabil-ity, they may not be applicable to translation sce-narios.
The reason is that, translation is notmerely a reading activity.
Translation requiresco-ordination between source text comprehensionand target text production (Dragsted, 2010).
Tothe best of our knowledge, our work on predictingTDI is the first of its kind.The motivation of the work is as follows.
Cur-rently, for domain specific Machine Translationsystems, parallel corpora are gathered throughtranslation crowdsourcing/outsourcing.
In such346Figure 1: Inherent sentence complexity and per-ceived difficulty during translationa scenario, translators are paid on the basis ofsentence length, which ignores other factors con-tributing to translation difficulty, as stated above.Our proposed Translation Difficulty Index (TDI)quantifies the translation difficulty of a sentenceconsidering both lexical and structural proper-ties.
This measure can, in turn, be used to clus-ter sentences according to their difficulty levels(viz.
easy, medium, hard).
Different payment andschemes can be adopted for different such clusters.TDI can also be useful for training and evalu-ating second language learners.
For example, ap-propriate examples at particular levels of difficultycan be chosen for giving assignments and monitor-ing progress.The rest of the paper is organized in the fol-lowing way.
Section 2 describes TDI as func-tion of translation processing time.
Section 3 ison measuring translation processing time througheye tracking.
Section 4 gives the correlation oflinguistic complexity with observed TDI.
In sec-tion 5, we describe a technique for predicting TDIsand ranking unseen sentences using Support Vec-tor Machines.
Section 6 concludes the paper withpointers to future work.2 Quantifying Translation DifficultyAs a first approximation, TDI of a sentence canbe the time taken to translate the sentence, whichcan be measured through simple translation exper-iments.
This is based on the assumption that moredifficult sentences will require more time to trans-late.
However, ?time taken to translate?
may notbe strongly related to the translation difficulty fortwo reasons.
First, it is difficult to know whatfraction of the total translation time is actuallyspent on the translation-related-thinking.
For ex-ample, translators may spend considerable amountof time typing/writing translations, which is ir-relevant to the translation difficulty.
Second, thetranslation time is sensitive to distractions fromthe environment.
So, instead of the ?time takento translate?, we are more interested in the ?timefor which translation related processing is carriedout by the brain?.
This can be termed as the Trans-lation Processing Time (Tp).
Mathematically,Tp = Tp comp + Tp gen (1)Where Tp comp and Tp gen are the processing timesfor source text comprehension and target text gen-eration respectively.
The empirical TDI, is com-puted by normalizing Tp with sentence length.TDI = Tpsentencelength (2)Measuring Tp is a difficult task as translators of-ten switch between thinking and writing activities.Here comes the role of eye tracking.3 Measuring Tp by eye-trackingWe measure Tp by analyzing the gaze behaviorof translators through eye-tracking.
The rationalebehind using eye-tracking is that, humans spendtime on what they see, and this ?time?
is corre-lated with the complexity of the information beingprocessed, as shown in Figure 1.
Two fundamentalcomponents of eye behavior are (a) Gaze-fixationor simply, Fixation and (b) Saccade.
The formeris a long stay of the visual gaze on a single loca-tion.
The latter is a very rapid movement of theeyes between positions of rest.
An intuitive feelfor these two concepts can be had by consider-ing the example of translating the sentence Thecamera-man shot the policeman with a gun men-tioned in the introduction.
It is conceivable thatthe eye will linger long on the word ?shot?
whichis ambiguous and will rapidly move across ?shot?,?camera-man?
and ?gun?
to ascertain the clue fordisambiguation.The terms Tp comp and Tp gen in (1) can now belooked upon as the sum of fixation and saccadicdurations for both source and target sentences re-spectively.Modifying 1Tp =?f?Fsdur(f) +?s?Ssdur(s)+?f?Ftdur(f) +?s?Stdur(s)(3)347Figure 2: Screenshot of Translog.
The circles rep-resent fixations and arrow represent saccades.Here, Fs and Ss correspond to sets of fixations andsaccades for source sentence and Ft and St corre-spond to those for the target sentence respectively.dur is a function returning the duration of fixationsand saccades.3.1 Computing TDI using eye-trackingdatabaseWe obtained TDIs for a set of sentences fromthe Translation Process Research Database (TPR1.0)(Carl, 2012).
The database contains trans-lation studies for which gaze data is recordedthrough the Translog software1(Carl, 2012).
Fig-ure 2 presents a screendump of Translog.
Out ofthe 57 available sessions, we selected 40 transla-tion sessions comprising 80 sentence translations2.Each of these 80 sentences was translated fromEnglish to three different languages, viz.
Span-ish, Danish and Hindi by at least 2 translators.The translators were young professional linguistsor students pursuing PhD in linguistics.The eye-tracking data is noisy and often ex-hibits systematic errors (Hornof and Halverson,2002).
To correct this, we applied automatic er-ror correction technique (Mishra et al, 2012) fol-lowed by manually correcting incorrect gaze-to-word mapping using Translog.
Note that, gaze andsaccadic durations may also depend on the transla-tor?s reading speed.
We tried to rule out this effectby sampling out translations for which the vari-ance in participant?s reading speed is minimum.Variance in reading speed was calculated after tak-ing a samples of source text for each participantand measuring the time taken to read the text.After preprocessing the data, TDI was com-puted for each sentence by using (2) and (3).Theobserved unnormalized TDI score3 ranges from0.12 to 0.86.
We normalize this to a [0,1] scale1http://www.translog.dk220% of the translation sessions were discarded as it wasdifficult to rectify the gaze logs for these sessions.3Anything beyond the upper bound is hard to translate andcan be assigned with the maximum score.Figure 3: Dependency graph used for computingSCusing MinMax normalization.If the ?time taken to translate?
and Tp werestrongly correlated, we would have rather opted?time taken to translate?
for the measurement ofTDI.
The reason is that ?time taken to translate?is relatively easy to compute and does not requireexpensive setup for conducting ?eye-tracking?
ex-periments.
But our experiments show that thereis a weak correlation (coefficient = 0.12) between?time taken to translate?
and Tp.
This makes usbelieve that Tp is still the best option for TDI mea-surement.4 Relating TDI to sentence featuresOur claim is that translation difficulty is mainlycaused by three features: Length, Degree of Poly-semy and Structural Complexity.4.1 LengthIt is the total number of words occurring in a sen-tence.4.2 Degree of Polysemy (DP)The degree of polysemy of a sentence is the sum ofsenses possessed by each word in the Wordnet nor-malized by the sentence length.
Mathematically,DPsentence =?w?W Senses(w)length(sentence) (4)Here, Senses(w) retrieves the total number sensesof a word P from the Wordnet.
W is the set ofwords appearing in the sentence.4.3 Structural Complexity (SC)Syntactically, words, phrases and clauses are at-tached to each other in a sentence.
If the attach-ment units lie far from each other, the sentencehas higher structural complexity.
Lin (1996) de-fines it as the total length of dependency links inthe dependency structure of the sentence.348Figure 4: Prediction of TDI using linguistic prop-erties such as Length(L), Degree of Polysemy(DP) and Structural Complexity (SC)Example: The man who the boy attackedescaped.Figure 3 shows the dependency graph for theexample sentence.
The weights of the edges cor-respond how far the two connected words lie fromeach other in the sentence.
Using Lin?s formula,the SC score for the example sentence turns out tobe 15.Lin?s way of computing SC is affected by sen-tence length since the number of dependency linksfor a sentence depends on its length.
So we nor-malize SC by the length of the sentence.
Afternormalization, the SC score for the example givenbecomes 15/7 = 2.144.4 How are TDI and linguistic featuresrelatedTo validate that translation difficulty depends onthe above mentioned linguistic features, we triedto find out the correlation coefficients betweeneach feature and empirical TDI.
We extractedthree sets of sample sentences.
For each sample,sentence selection was done with a view to vary-ing one feature, keeping the other two constant.The Correlation Coefficients between L, DP andSC and the empirical TDI turned out to be 0.72,0.41 and 0.63 respectively.
These positive correla-tion coefficients indicate that all the features con-tribute to the translation difficulty.5 Predicting TDIOur system predicts TDI from the linguistic prop-erties of a sentence as shown in Figure 4.The prediction happens in a supervised settingthrough regression.
Training such a system re-quires a set sentences annotated with TDIs.
Inour case, direct annotation of TDI is a difficult andunintuitive task.
So, we annotate TDI by observ-Kernel(C=3.0) MSE (%) CorrelationLinear 20.64 0.69Poly (Deg 2) 12.88 0.81Poly (Deg 3) 13.35 0.78Rbf (default) 13.32 0.73Table 1: Relative MSE and Correlation with ob-served data for different kernels used for SVR.ing translator?s behavior (using equations (1) and(2))instead of asking people to rate sentences withTDI.We are now prepared to give the regression sce-nario for predicting TDI.5.1 Preparing the datasetOur dataset contains 80 sentences for which TDIhave been measured (Section 3.1).
We divided thisdata into 10 sets of training and testing datasets inorder to carry out a 10-fold evaluation.
DP and SCfeatures were computed using Princeton Wordnet4and Stanford Dependence Parser5.5.2 Applying Support Vector RegressionTo predict TDI, Support Vector Regression (SVR)technique (Joachims et al, 1999) was preferredsince it facilitates multiple kernel-based methodsfor regression.
We tried using different kernels us-ing default parameters.
Error analysis was doneby means of Mean Squared Error estimate (MSE).We also measured the Pearson correlation coeffi-cient between the empirical and predicted TDI forour test-sets.Table 1 indicates Mean Square Error percent-ages for different kernel methods used for SVR.MSE (%) indicates by what percentage the pre-dicted TDIs differ from the observed TDIs.
In oursetting, quadratic polynomial kernel with c=3.0outperforms other kernels.
The predicted TDIs arewell correlated with the empirical TDIs.
This tellsus that even if the predicted scores are not as ac-curate as desired, the system is capable of rankingsentences in correct order.
Table 2 presents exam-ples from the test dataset for which the observedTDI (TDIO) and the TDI predicted by polynomialkernel based SVR (TDIP ) are shown.Our larger goal is to group unknown sentencesinto different categories by the level of transla-4http://www.wordnet.princeton.edu5http://www.nlp.stanford.edu/software/lex-parser.html349Example L DP SC TDIO TDIP Error1.
American Express recentlyannounced a second roundof job cuts.
10 10 1.8 0.24 0.23 4%2.
Sociology is a relativelynew academic discipline.
7 6 3.7 0.49 0.53 8%Table 2: Example sentences from the test dataset.tion difficulty.
For that, we tried to manually as-sign three different class labels to sentences viz.easy, medium and hard based on the empiricalTDI scores.
The ranges of scores chosen for easy,medium and hard categories were [0-0.3], [0.3-0.75] and [0.75-1.0] respectively (by trial and er-ror).
Then we trained a Support Vector Rank(Joachims, 2006) with default parameters usingdifferent kernel methods.
The ranking frameworkachieves a maximum 67.5% accuracy on the testdata.
The accuracy should increase by addingmore data to the training dataset.6 ConclusionThis paper introduces an approach to quantify-ing translation difficulty and automatically assign-ing difficulty levels to unseen sentences.
It estab-lishes a relationship between the intrinsic senten-tial properties, viz., length (L), degree of polysemy(DP) and structural complexity (SC), on one handand the Translation Difficulty Index (TDI), on theother.
Future work includes deeper investigationinto other linguistic factors such as presence of do-main specific terms, target language properties etc.and applying more sophisticated cognitive analy-sis techniques for more reliable TDI score.
Wewould like to make use of inter-annotator agree-ment to decide the boundaries for the translationdifficulty categories.
Extending the study to differ-ent language pairs and studying the applicabilityof this technique for Machine Translation QualityEstimation are also on the agenda.AcknowledgmentsWe would like to thank the CRITT, CBS group fortheir help in manual correction of TPR data.
Inparticular, thanks to Barto Mesa and Khristina forhelping with Spanish and Danish dataset correc-tions.ReferencesCampbell, S., and Hale, S. 1999.
What makes a textdifficult to translate?
Refereed Proceedings of the23rd Annual ALAA Congress.Carl, M. 2012.
Translog-II: A Program for Record-ing User Activity Data for Empirical Reading andWriting Research In Proceedings of the Eight In-ternational Conference on Language Resources andEvaluation, European Language Resources Associ-ation (ELRA)Carl, M. 2012 The CRITT TPR-DB 1.0: A Databasefor Empirical Human Translation Process Research.AMTA 2012 Workshop on Post-Editing Technologyand Practice (WPTP-2012).Chall, J. S., and Dale, E. 1995.
Readability revisited:the new Dale-Chall readability formula Cambridge,Mass.
: Brookline Books.Dragsted, B.
2010.
Co-ordination of reading andwrit-ing processes in translation.
Contribution to Trans-lation and Cognition, Shreve, G. and Angelone,E.(eds.
)Cognitive Science Society.Fry, E. 1977 Fry?s readability graph: Clarification,validity, and extension to level 17 Journal of Read-ing, 21(3), 242-252.Hornof, A. J. and Halverson, T. 2002 Cleaning up sys-tematic error in eye-tracking data by using requiredfixation locations.
Behavior Research Methods, In-struments, and Computers, 34, 592604.Joachims, T., Schlkopf, B. ,Burges, C and A.
Smola(ed.).
1999.
Making large-Scale SVM LearningPractical.
Advances in Kernel Methods - SupportVector Learning.
MIT-Press, 1999,Joachims, T. 2006 Training Linear SVMs in Lin-ear Time Proceedings of the ACM Conference onKnowledge Discovery and Data Mining (KDD).Kincaid, J. P., Fishburne, R. P., Jr., Rogers, R. L., andChissom, B. S. 1975.
Derivation of New Read-ability Formulas (Automated Readability Index, FogCount and Flesch Reading Ease Formula) for NavyEnlisted Personnel Millington, Tennessee: NavalAir Station Memphis,pp.
8-75.350Lin, D. 1996 On the structural complexity of naturallanguage sentences.
Proceeding of the 16th Inter-national Conference on Computational Linguistics(COLING), pp.
729733.Mishra, A., Carl, M, Bhattacharyya, P. 2012 Aheuristic-based approach for systematic error cor-rection of gaze datafor reading.
In MichaelCarl, P.B.and Choudhary, K.K., editors, Proceedings of theFirst Workshop on Eye-tracking and Natural Lan-guage Processing, Mumbai, India.
The COLING2012 Organizing Committeevon der Malsburg, T., Vasishth, S., and Kliegl, R. 2012Scanpaths in reading are informative about sen-tence processing.
In MichaelCarl, P.B.
and Choud-hary, K.K., editors, Proceedings of the First Work-shop on Eye-tracking and Natural Language Pro-cessing, Mumbai, India.
The COLING 2012 Orga-nizing Committee351
