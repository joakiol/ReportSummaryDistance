Proceedings of the EMNLP 2014 Workshop on Arabic Natural Langauge Processing (ANLP), pages 143?147,October 25, 2014, Doha, Qatar.
c?2014 Association for Computational LinguisticsFast and Robust Arabic Error Correction SystemMichael N. NawarComputer Engineering DepartmentCairo UniversityGiza, Egyptmichael.nawar@eng.cu.edu.egMoheb M. RaghebComputer Engineering DepartmentCairo UniversityGiza, Egyptmoheb.ragheb@eng.cu.edu.egAbstractIn this paper we describe the implementationof an Arabic error correction system devel-oped for the EMNLP2014 shared task on au-tomatic error correction for Arabic text.
Weproposed a novel algorithm, where we findsome correction rules and calculate theirprobability based on the training data, theywe rank the correction rules, then we applythem on the text to maximize the overall F-score for the provided data.
The systemachieves and F-score of 0.6573 on the test da-ta.1 IntroductionTraditional techniques in text correction is thegeneration of a large set of candidates for an in-correct word using different approaches likeenumerating all possible candidates in edit dis-tance of one.
Then, all the candidates are rankedsuch that the best candidates are ranked on thetop of the list.
Finally, the best candidate is cho-sen to replace incorrect word.The traditional techniques are slow, since thegeneration of a large set of candidates is timeconsuming task.
Also, it doesn?t take into con-sideration the overall score of the system.
While,in this paper we apply a novel technique in au-tomatic error correction, where we take into con-sideration the correction rules, not the variants.In the propose technique, we order corrections tobe applied on text to maximize the F-score.This shared task was on automatic Arabic textcorrection.
For this task, the Qatar Arabic Lan-guage Bank (QALB) corpus (Mohit et.
al, 2014)was provided.
The QALB corpus contains a pre-processed input text with some features extractedand the corrected output.
The main issue in theshared task, that the tools used for the extractionof the provided features wasn?t provided.
So, wehad a choice, to create an algorithm that can dealwith missing features, or to generate our own setof features.
Finally, we have chosen to generateour own set of features.The proposed framework could be describedas a probabilistic rule-based framework.
Duringthe training of this framework, we extractedsome rules and assign a probability to each ruleas shown later in section 3.
The extracted rulesare then sorted based on their probabilities.
Andduring the test, we apply the rules from the high-est probability to the lowest probability one byone, on the entire test data till a stopping criteriais satisfied.
During the algorithm we have somekind of heuristic to estimate the F-score aftereach rule is apply.
The stopping criteria for thealgorithm is that the estimated F-score start todecrease.This paper is organized as follow, in section 2,an overview of the related work in the field oferror correction is discussed.
In section 3, theproposed system and its main components areexplained.
The evaluation process is presented insection 4.
Finally, concluding remarks and futurework are presented in section 5.2 Related WorkMost of the work done in the field automatic er-ror correction for text, is made for English lan-guage (Kukich, 1992; Golding and Roth, 1999;Carlson and Fette, 2007; Banko and Brill, 2001).Arabic spelling correction has also received con-siderable interest, Ben Othmane Zribi and BenAhmed, (2003) have proposed a new aiming toreduce the number of proposals given by auto-matic Arabic spelling correction tools, whichhave reduced the proposals by about 75%.
Had-dad and Yaseen (2007) took into considerationthe complex nature of the Arabic language andthe effect of the root-pattern relationship to lo-143cate, reduce and rank the most probable correc-tion candidates in Arabic derivative words toimprove the process of error detection and cor-rection.
Hassan et al.
(2008) used a finite stateautomata to propose candidates corrections, thenassign a score to each candidate and choose thebest correction in the context.
Shaalan et al.
(2010) developed an error correction system toArabic learners.
Alkanhal et al.
(2012) have de-veloped an error correction system and they em-phasized on space insertion and deletion.
Zag-houani et al.
(2014) provided a large scale da-taset for the task of automatic error correction forArabic text.3 The Proposed SystemThe main system idea is explained by the al-gorithm, in figure 1.
The algorithm has two in-puts: the set of sentences that need to be modi-fied T[1..n], and the set of correction rulesC[1..m] that could be applied to text.
The algo-rithm has one single output: the set of modifiedsentences T?[1..n].
The algorithm could be divid-ed into two main component: the initializationand the main loop.Figure 1: Proposed AlgorithmFirst, the initialization part of the algorithmstarts from line 1 to line 8.
In the first line, thesentences are copied from T[1..n] to T?[1..n].
Inline number 2, the number of errors in the test setT[1..n] is expected using the rate of errors in thetrain set (#error / #words).
In lines 3 to 8, thevariables used in the algorithm are initialized tozero.The main loop of the algorithm starts fromline 9 to line 20.
In line 9, the loop begins, andthe sentences are copied from T[1..n] to T?
[1..n]and the F-score is copied to old F-score, in lina-rae 10 and 11.
Then the first not applied correc-tion with the highest probability to be correct iscorrect is chosen in line 12.
In line 13, the cor-rection is applied on the text T[1..n].
Then wecalculate the number of changes between T[1..n]and T?
[1..n], in line 14.
And based on the ex-pected number of changes, we update the ex-pected number of performed edits in line 14.
Al-so, we update the expected number of the correctedits based on the number of change and theprobability of a change to be correct in line 15.In lines 17 to 19, we calculate the expected pre-cision, recall and F-score based on the expectedgold edits, performed edits, and correct edits cal-culated at lines 2, 14, and 15.
If the F-score ishigher than the old F-score, which means thatapplying the correction c on the text T[1..n] willincrease the expected F-score, then go to line 9and start a new iteration in the loop.
And if the F-score is lower than the old F-score, which meansthat applying the correction c on the text T[1..n]will decrease the expected F-score, then exit theloop and return the modified text T?
[1..n].After we have discussed the main idea of algo-rithm, in the following subsections we will dis-cuss some of the extracted corrections rules andthe calculation of the probability of each rule.These rules and their probabilities are compiledby analyzing the training data.3.1 Morphological Analyzer CorrectionsRulesWe used a morphological analyzer, BAMA-v2.0 (Buckwalter Arabic morphological analyzerversion 2.0) (Buckwalter, 2010), in the extractionof a correction rule.
This rule will be used tosolve the errors caused by the exchange betweensome characters like: (??
?, ?A?
), (??
?, ?>?
), (???,?<?)
and (??
?, ?h?
), (??
?, ?p?)
and (??
?, ?y?),(??
?, ?Y?
).RULE: We analyze a word with the morpho-logical analyzer, if all the solutions of the wordhave the same form that is different from theInput: T[1..n], C[1..m]Output: T?
[1..n]1: T?
= T2: Gold Edits = #Words in Test * # Gold Edits inTrain / # Words in Train3: Correct Edits = 04: Performed Edits = 05: Precision = 06: Recall = 07: Old F-score = 08: F-score = 09: Do10: T?
=  T11: Old F-score =  F-score12: Get next correction ?c?
with the highestprobability ?p?
from C13:  Apply the correction ?c?
on T14:  N = number of changes between T andT?15:  Performed Edits = Performed Edits + N16:  Correct Edits = Correct Edits + p * N17:  Precision = Correct Edits / PerformedEdits18:  Recall = Correct Edits / Gold Edits19:  F-score = 2*Precision*Recall / (Preci-sion+Recall)20: while F-score > Old F-score do21: return T?144word, then change the word by the solutionsform.For example, the word (?????
?, ?AHmd?
),when the word is analyzed by the morphologicalanalyzer, there are 2 different solutions, 14 areproper noun (?????
?, ?>Hmd?, ?Ahmed?)
and theremaining 6 of them are verb (?
????
?, ?>Hmd?, ?Ipraise?).
Since all the solution of the word(?????
?, ?AHmd?)
have the form (??????,?>Hmd?
), then we will change (?????
?, ?AHmd?
)to (?????
?, ?>Hmd?).
Another example, the word(?????
?, ?AmAm?
), when the word is analyzed bythe morphological analyzer, there are 24 differ-ent solutions, 12 of them have the form (??????,?>mAm?
), and the other 12 have the form (??????,?<mAm?
), so we leave it unchanged.To calculate the correctness probability of therule, we apply the following rule to all the train-ing set, then we calculate the number of correctedits, and the number of performed edits, finallywe calculate the probability as the ratio betweenthe correct and the performed edits.3.2 Colloquial to Arabic Corrections RulesTo convert the colloquial Arabic words to Ar-abic words, we have compiled some rules asshown below:RULE: Replace a word or a phrase by a spe-cific word or phrase from a list extracted fromthe training set provided in Qalb shared task(Mohit et.
al, 2014).From example replace the word (?????
?, ?AH-nA?, ?we?)
by the word (????
?, ?nHn?, ?we?
).RULE: Replace a word or phrase with a spe-cific word or phrase based on its context.RULE: Replace a word or phrase with a spe-cific pattern to another word or phrase.From example replace the word (??????
?,?bylEb?, ?is playing?)
by the word (?????
?,?ylEb?, ?is playing?
).The correctness probability of each rule is theratio between the correct and the performed editswhen this rule is applied on the train data.3.3 The Single Character Spelling ErrorsCorrectionThe single character spelling errors are divid-ed into four main subcategories:  replace charac-ter by another character, insert character, deletecharacter, and transpose two adjacent characters.For these four errors, we have conducted fourtypes of rules.RULE 1: We analyze a word with the mor-phological analyzer, if it is outside the corpus,and it not defined in the correct words in qalbcorpus (the words that don?t change) try tochange one character by a specific character, ifthe new word is recognized by the morphologicalanalyzer or it is inside the corpus, then changethe word and keep the new solution.For example, if we have a word (?????,?bEZ?)
and a rule that change the character (???,?Z?)
to (??
?, ?D?).
And the word (?????,?bED?)
is recognized by the morphological ana-lyzer, then we change the word (????
?, ?bEZ?)
to(????
?, ?bED?).
Another example, if we havethe word (????
?, ?bEZ?)
and a rule that changethe character (??
?, ?E?)
to (??
?, ?g?).
And theword (????
?, ?bgZ?)
is not recognized by themorphological analyzer and it is outside the Qalbcorpus, then we don?t change the word.RULE 2: We analyze a word with the mor-phological analyzer, if it is outside the corpus,and it not defined in the correct words in qalbcorpus (the words that don?t change) try to insertone specific character between a pair of specificcharacters, if the new word is recognized by themorphological analyzer or it is inside the corpus,then change the word and keep the new solution.RULE 3: We analyze a word with the mor-phological analyzer, if it is outside the corpus,and it not defined in the correct words in qalbcorpus (the words that don?t change) try to deleteone specific character from a triplet of specificcharacters, if the new word is recognized by themorphological analyzer or it is inside the corpus,then change the word and keep the new solution.RULE 4: We analyze a word with the mor-phological analyzer, if it is outside the corpus,and it not defined in the correct words in Qalbcorpus (the words that don?t change) try to re-place a pair of characters to the transpose of thepair of characters, if the new word is recognizedby the morphological analyzer or it is inside thecorpus, then change the word and keep the newsolution.The correctness probability of each rule is theratio between the correct and the performed editswhen this rule is applied on the train data, and itdiffers from one character to another (i.e.
the twoexamples in rule 1, will have different correct-ness probabilities based on the training data).3.4 The Space Insertion Errors CorrectionThe space insertion error correction is the pro-cess of splitting an incorrect word to multiplecorrect word.RULE: If there is a character concatenated af-ter taa marbouta (??
?, ?p?
), insert a space betweenthem.145RULE: If the word starts with negation parti-cle, split negation particle from it.RULE: If the word starts with vocative parti-cle, split vocative particle from it.RULE: If the word starts with vocative parti-cle, split vocative particle from it.RULE: We analyze a word with the morpho-logical analyzer, if it is outside the corpus, and itnot defined in the correct words in Qalb corpus(the words that don?t change) try to find the longsubstring from the word, that keep another sub-string, where both of them are recognized by themorphological analyzer.The correctness probability of each rule is theratio between the correct and the performed editswhen this rule is applied on the train data.3.5 The Space Deletion Errors CorrectionThe space deletion errors correction is the pro-cess of merging multiple tokens into one correctword.RULE: Merge conjunction particles, withtheir succeeding token.RULE: If two out of corpus tokens could bemerged to an inside the corpus word, then mergethem.The correctness probability of each rule is theratio between the correct and the performed editswhen this rule is applied on the train data.3.6 Punctuation Errors CorrectionsThe punctuation errors are hard to correct be-cause they depends on the meaning of the sen-tence, and require almost full understanding ofthe sentence.
However, we have conducted somerules for the punctuation, for example:RULE: If the sentence doesn?t end with apunctuation point from (?.
?, ?!
?, ?
??
), then add apoint at the end of the sentence.RULE: Insert a punctuation mark before acertain word.For example, insert a semicolon before theword (????
?, ?l>nH?, ?because he?
).The correctness probability of each rule is theratio between the correct and the performed editswhen this rule is applied on the train data.3.7 Syntactic Errors CorrectionsThe syntactic errors is one of the most difficulterror to correct.
For this task we apply a simplekind of a grammatical analyzer to assign simplegrammatical tag to some words.
One simplegrammatical system, is the one to determine gen-itive noun.
Nouns are genitive mainly if they oc-cur after a preposition, or if they are possessives(definite noun after indefinite noun) or if they areadjectives of genitive nouns, or if they are con-junction with genitive noun.RULE: Plural and Dual genitive nouns thatend with (???
?, ?wn?)
or (???
?, ?An?)
should endwith (???
?, ?yn?
).The correctness probability of each rule is theratio between the correct and the performed editswhen this rule is applied on the train data.3.8 Additional Corrections RulesFinally, we generated some rules that presentthe data on a correct format as the training dataand we will assign their correctness probabilitymanually to be equal to 1.RULE: Remove kashida (tatweel) from text.RULE: Replace ?*?
if between parenthesis bythe Arabic character (??
?, ?*?
).RULE: If a character is repeated consecutive-ly more than twice inside a word, remove theextra characters except if the word consists ofonly one char like (??????
?, ?hhhhh?
).RULE: Write a comma between two numbers.4 Evaluation of the SystemFor the evaluation of the system, we used theM2 scorer by Dahlmeier and Ng (2012).
Whenwe evaluated the system with the developmentdataset, we have reached an F-score of 0.6817;and when the system is evaluated the test dataset,we have reached and F-score of 0.6573.The proposed algorithm is very fast comparedto traditional error correction algorithm.
In tradi-tional error correction algorithm, you generate allpossible variants of an incorrect word, then yourank the solutions and choose the best solution.But, in the proposed algorithm, you rank therules during the training time, and you apply onerule at the time until you find an appropriate so-lution of an incorrect word.For example, let?s consider single characterreplace spelling error, if the incorrect wordlength is five characters, so you need to make((28-1)*5) iterations to generate all possible vari-ants of a word, while in the proposed algorithmyou generate one variant at the time, and youmight stop after that.5 ConclusionIn this paper we have presented a novel andfast algorithm for the automatic text correctionfor Arabic.
The proposed algorithm has a goodF-score, and the system has the potential to befurther improved.
As a future work, the punctua-146tion error correction might need to be further im-proved.
And the expected number of gold edits,could be improved or calculated on the sentencelevel.
And finally, the rules used in the frame-work could be extended by further analysis of thetraining data.ReferencesMohamed I. Alkanhal, Mohammed A. Al-Badrashiny,Mansour M. Alghamdi, and Abdulaziz O. AlQab-bany.
2012.
Automatic Stochastic Arabic SpellingCorrection with Emphasis on Space Insertions andDeletions.
IEEE Transactions on Audio, Speech& Language Processing, 20:2111?2122.Michele Banko and Eric Brill, 2001.
Scaling to veryvery large corpora for natural language disambigu-ation.
In Proceedings of 39th Annual Meetingof the Association for Computational Linguis-tics.
Toulouse, France.Chiraz Ben Othmane Zribi and Mohammed Ben Ah-med.
2003.
Efficient Automatic Correction of Mis-spelled Arabic Words Based on Contextual Infor-mation.
In Proceedings of the Knowledge-Based Intelligent Information and EngineeringSystems Conference, Oxford, UK.Tim Buckwalter.
2010.
Buckwalter Arabic Morpho-logical Analyzer Version 2.0.
Linguistic Data Con-sortium, University of Pennsylvania, 2002.
LDCCatalog No.
: LDC2004L02.
ISBN 1-58563-324-0.Andrew Carlson and Ian Fette.
2007.
Memory-basedcontext-sensitive spelling correction at web scale.In Proceedings of the IEEE International Con-ference on Machine Learning and Applica-tions (ICMLA).Daniel Dahlmeier and Hwee Tou Ng.
2012.
Betterevaluation for grammatical error correction.
InProceeding of the 2012 Conference of theNorth American Chapter of the Associationfor Computational Linguistics: Human Lan-guage Technologies.Andrew R. Golding and Dan Roth.
1999.
A Winnowbased approach to context-sensitive spelling cor-rection.
Machine Learning, 34(1-3):107?130.Bassam Haddad and Mustafa Yaseen.
2007.
Detectionand Correction of Non-Words in Arabic: A HybridApproach.
International Journal of ComputerProcessing Of Languages (IJCPOL).Ahmed Hassan, Sara Noeman, and Hany Hassan.2008.
Language Independent Text Correction usingFinite State Automata.
In Proceedings of the In-ternational Joint Conference on Natural Lan-guage Processing (IJCNLP 2008).Karen Kukich.
1992.
Techniques for AutomaticallyCorrecting Words in Text.
ACM Computing Sur-veys, 24(4).Behrang Mohit, Alla Rozovskaya, Nizar Habash,Wajdi Zaghouani, and Ossama Obeid, 2014.
TheFirst shared Task on Automatic Text Correction forArabic.
In Proceedings of EMNLP workshopon Arabic Natural Language Processing.
Do-ha, Qatar.Khaled Shaalan, Rana Aref, and Aly Fahmy.
2010.An approach for analyzing and correcting spellingerrors for non-native Arabic learners.
In Proceed-ings of Informatics and Systems (INFOS).Wajdi Zaghouani, Behrang Mohit, Nizar Habash, Os-sama Obeid, Nadi Tomeh, Alla Rozovskaya, NouraFarra, Sarah Alkuhlani, and Kemal Oflazer.
2014.Large Scale Arabic Error Annotation: Guidelinesand Framework.
In Proceedings of the Ninth In-ternational Conference on Language Re-sources and Evaluation (LREC?14), Reykjavik,Iceland.147
