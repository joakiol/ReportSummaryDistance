Proceedings of the 6th Workshop on Statistical Machine Translation, pages 496?500,Edinburgh, Scotland, UK, July 30?31, 2011. c?2011 Association for Computational LinguisticsHierarchical Phrase-Based MT at the Charles Universityfor the WMT 2011 Shared TaskDaniel ZemanCharles University in Prague, Institute of Formal and Applied Linguistics (?FAL)Univerzita Karlova v Praze, ?stav form?ln?
a aplikovan?
lingvistiky (?FAL)Malostransk?
n?m?st?
25, Praha, CZ-11800, Czechiazeman@ufal.mff.cuni.czAbstractWe describe our experiments with hier-archical phrase-based machine translationfor the WMT 2011 Shared Task.
Wetrained a system for all 8 translation di-rections between English on one side andCzech, German, Spanish or French onthe other side, though we focused slightlymore on the English-to-Czech direction.We provide a detailed description of ourconfiguration and data so the results arereplicable.1 IntroductionWith so many official languages, Europe is a par-adise for machine translation research.
One of thelargest bodies of electronically available paralleltexts is being nowadays generated by the EuropeanUnion and its institutions.
At the same time, theEU also provides motivation and boosts potentialmarket for machine translation outcomes.Most of the major European languages belongto one of the following three branches of theIndo-European language family: Germanic, Ro-mance or Slavic.
Such relatedness is responsiblefor many structural similarities in European lan-guages, although significant differences still ex-ist.
Within the language portfolio selected for theWMT shared task, English, French and Spanishseem to be closer to each other than to the rest.German, despite being genetically related to En-glish, differs in many properties.
Its word or-der rules, shifting verbs from one end of the sen-tence to the other, easily create long-distance de-pendencies.
Long German compound words arenotorious for increasing out-of-vocabulary rate,which has led many researchers to devising un-supervised compound-splitting techniques.
Also,uppercase/lowercase distinction is more importantbecause all German nouns start with an uppercaseletter by the rule.Czech is a language with rich morphology (bothinflectional and derivational) and relatively freeword order.
In fact, the predicate-argument struc-ture, often encoded by fixed word order in English,is usually captured by inflection (especially thesystem of 7 grammatical cases) in Czech.
Whilethe free word order of Czech is a problem whentranslating to English (the text should be parsedfirst in order to determine the syntactic functionsand the English word order), generating correct in-flectional affixes is indeed a challenge for English-to-Czech systems.
Furthermore, the multitudeof possible Czech word forms (at least order ofmagnitude higher than in English) makes the datasparseness problem really severe, hindering bothdirections.There are numerous ways how these issuescould be addressed.
For instance, parsing andsyntax-aware reordering of the source-languagesentences can help with the word order differ-ences (same goal could be achieved by a reorder-ing model or a synchronous context-free grammarin a hierarchical system).
Factored translation, asecondary language model of morphological tagsor even a morphological generator are some of thepossible solutions to the poor-to-rich translation is-sues.Our goal is to run one system under as simi-lar conditions as possible to all eight translationdirections, to compare their translation accuraciesand see why some directions are easier than others.Future work will benefit from knowing what arethe special processing needs for a given languagepair.
The current version of the system does not in-clude really language-specific techniques: we nei-ther split German compounds, nor do we addressthe peculiarities of Czech mentioned above.
Still,comparability of the results is limited, as the qual-ity and quantity of English-Czech data differs fromthat of the other pairs.4962 The Translation SystemOur translation system belongs to the hierarchi-cal phrase-based class (Chiang, 2007), i.e.
phrasepairs with nonterminals (rules of a synchronouscontext-free grammar) are extracted from sym-metrized word alignments and subsequently usedby the decoder.
We use Joshua, a Java-based open-source implementation of the hierarchical decoder(Li et al, 2009), release 1.3.1Word alignment was computed using the firstthree steps of the train-factored-phrase-model.perl script packed with Moses2 (Koehn etal., 2007).
This includes the usual combination ofword clustering using mkcls3 (Och, 1999), two-way word alignment using GIZA++4 (Och andNey, 2003), and alignment symmetrization usingthe grow-diag-final-and heuristic (Koehn et al,2003).For language modeling we use the SRILMtoolkit5 (Stolcke, 2002) with modified Kneser-Ney smoothing (Kneser and Ney, 1995; Chen andGoodman, 1998).We use the Z-MERT implementation of mini-mum error rate training (Zaidan, 2009).
The fol-lowing settings have been used for Joshua and Z-MERT (for the sake of reproducibility, we keep theoriginal names of the options; for their detailed ex-planation please refer to the documentation avail-able on-line at the Joshua project site).
-ipi is thenumber of intermediate initial points per Z-MERTiteration.?
Grammar extraction:maxPhraseSpan=10 maxPhraseLength=5maxNonterminals=2 maxNontermi-nalSpan=2 requireTightSpans=trueedgeXViolates=true sentenceIni-tialX=true sentenceFinalX=trueruleSampleSize=300?
Language model order: 6 (hexagram)?
Decoding: span_limit=10 fuzz1=0.1fuzz2=0.1 max_n_items=30 rela-tive_threshold=10.0 max_n_rules=50rule_relative_threshold=10.01http://sourceforge.net/projects/joshua/2http://www.statmt.org/moses/3http://fjoch.com/mkcls.html4http://fjoch.com/GIZA++.html5http://www-speech.sri.com/projects/srilm/?
N-best decoding: use_unique_nbest=trueuse_tree_nbest=falseadd_combined_cost=true top_n=300?
Z-MERT: -m BLEU 4 closest -maxIt 5-ipi 203 Data and Pre-processing PipelineWe applied our system to all eight language pairs.From the data point of view the experimentswere even more constrained than the organizersof the shared task suggested.
We used neitherthe French/Spanish-English UN corpora nor the109 French-English corpus.
For 7 translation di-rections we used the Europarl ver6 and News-Commentary ver6 corpora6 for training.
The targetside of the corporawas our only source ofmonolin-gual data for training the language model.
Table 1shows the size of the training data.For the English-Czech direction, we usedCzEng 0.9 (Bojar and ?abokrtsk?, 2009)7 as ourmain parallel corpus.
Following CzEng authors?request, we did not use sections 8* and 9* reservedfor evaluation purposes.In addition, we also used the EMEA corpus8(Tiedemann, 2009).9Czech was also the only language where weused extra monolingual data for the languagemodel.
It was the set provided by the organizers ofWMT 2010 (13,042,040 sentences, 210,507,305tokens).We use a slightly modified tokenization rulescompared to CzEng export format.
Most notably,we normalize English abbreviated negation andauxiliary verbs (?couldn?t?
?
?could not?)
andattempt at normalizing quotation marks to distin-guish between opening and closing one followingproper typesetting rules.The rest of our pre-processing pipeline matchesthe processing employed in CzEng (Bojar and?abokrtsk?, 2009).10 We use ?supervised truecas-ing?, meaning that we cast the case of the lemmato the form, relying on our morphological analyz-ers and taggers to identify proper names, all other6Available for download at http://www.statmt.org/wmt11/translation-task.html using the link ?Parallelcorpus training data?.7http://ufal.mff.cuni.cz/czeng/8http://urd.let.rug.nl/tiedeman/OPUS/EMEA.php9Unfortunately, the EMEA corpus is badly tokenized onthe Czech side with fractional numbers split into several to-kens (e.g.
?3, 14?).
We attempted to reconstruct the originaldetokenized form using a small set of regular expressions.497Corpus SentPairs Tokens xx Tokens encs-en 583,124 13,224,596 15,397,742de-en 1,857,087 48,834,569 51,243,594es-en 1,903,562 54,488,621 52,369,658fr-en 1,920,363 61,030,918 52,686,784en-cs 7,543,152 79,057,403 89,018,033Table 1: Number of sentence pairs and tokens forevery language pair in the parallel training cor-pus.
Languages are identified by their ISO 639codes: cs = Czech, de =German, en = English, es =Spanish, fr = French.
The en-cs line describes theCzEng + EMEA combined corpus, all other linescorrespond to the respective versions of EuroParl+ News Commentary.words are lowercased.Note that in some cases the grammar extractionalgorithm in Joshua fails if the training corpus con-tains sentences that are too long.
Removing sen-tences of 100 or more tokens (per advice by Joshuadevelopers) effectively healed all failures.11The News Test 2008 data set12 (2051 sentencesin each language) was used as development datafor MERT.
BLEU scores reported in this paperwere computed on the News Test 2011 set (3003sentences each language).
We do not use the NewsTest 2009 and 2010.4 ExperimentsAll BLEU scores were computed directly byJoshua on the News Test 2011 set.
Note thatthey differ from what the official evaluation scriptwould report, due to different tokenization.4.1 Baseline ExperimentsThe set of baseline experiments with all translationdirections involved running the system on lower-cased News Commentary corpora.
Word align-ments were computed on lowercased 4-characterstems.
A hexagram language model was trainedon the target side of the parallel corpus.In the en-cs case, word alignments were com-puted on lemmatized version of the parallel cor-10Due to the subsequent processing, incl.
parsing, the tok-enization of English follows PennTreebenk style.
The ratherunfortunate convention of treating hyphenated words as sin-gle tokens increases our out-of-vocabulary rate.11Table 1 presents statistics before removing the long sen-tences.12http://www.statmt.org/wmt11/translation-task.htmlpus.
Hexagram language model was trained onthe monolingual data.
Truecased data were usedfor training, as described above; the BLEU scoreof this experiment in Table 2 is computed on true-cased system output.Direction BLEUJ BLEUl BLEUten-cs 0.1274 0.141 0.123en-de 0.1324 0.128 0.052en-es 0.2756 0.274 0.221en-fr 0.2727 0.212 0.174cs-en 0.1782 0.178 0.137de-en 0.1957 0.187 0.137es-en 0.2630 0.255 0.197fr-en 0.2471 0.248 0.193Table 2: Lowercased BLEU scores of the baselineexperiments on News Test 2011 data: BLEUJ iscomputed by the system, BLEUl is the officialevaluation by matrix.statmt.org (it differs be-cause of different tokenization).
BLEUt is offi-cial truecased evaluation.An interesting perspective on the models is pro-vided by the feature weights optimized duringMERT.
We can see in Table 3 that translationmodels are trusted significantly more than lan-guage models for the en-de, de-en and es-en di-rections.
In fact, the language model has a low rel-ative weight in all language pairs but en-cs, whichwas the only pair where we used a significantamount of extra monolingual data.
In the future,we should probably use the Gigaword corpus forthe to-English directions.Setup LM Pt0 Pt1 Pt2 WPen-cs 1.0 1.04 0.84 ?0.06 ?1.19en-de 1.0 2.60 0.57 0.47 ?3.17en-es 1.0 1.67 0.81 0.60 ?2.96en-fr 1.0 1.41 0.92 0.53 ?2.80cs-en 1.0 1.48 0.94 1.08 ?4.55de-en 1.0 2.28 1.11 0.34 ?2.88es-en 1.0 2.26 1.67 0.23 ?0.84fr-en 1.0 1.89 1.32 0.13 ?0.04Table 3: Feature weights are relative to the weightof LM , the score by the language model.
Thenthere are the three translation features: Pt0 =P (e|f), Pt1 = Plex(f |e) and Pt2 = Plex(e|f).WP is the word penalty.4984.2 EfficiencyThe machines on which the experiments were con-ducted are 64bit Intel Xeon dual core 2.8 GHzCPUs with 32 GB RAM.Word alignment of each parallel corpus was themost resource-consuming subtask.
It took between12 and 48 hours, though it could be cut to one halfby running both GIZA++ directions in parallel.The time needed for data preprocessing and train-ing of the language model was negligible.
Paral-lelized grammar extraction took 19 processors forabout an hour.
For decoding the test data were splitinto 20 chunks that were processed in parallel.
OneMERT iteration, including decoding, took from 30minutes to 1 hour.Training of large models requires some carefulengineering.
The grammar extraction easily con-sumes over 20 GB memory so it is important tomake sure Java really has access to it.
The de-coder must use the SWIG-linked SRILM librarybecause Java-based language modeling is too slowand memory-consuming.4.3 Supervised TruecasingOur baseline experiments operated on lowercaseddata, except for en-cs, where truecased word formswere obtained using lemmas from morphologicalannotation (note that guessing of the true case isonly needed for the sentence-initial token, otherwords can just be left in their original form).As contrastive runs we applied the supervisedtruecasing to other directions as well.
We usedthe Mor?e tagger for English lemmatization, Tree-Tagger for German and two simple rule-based ap-proaches to Spanish and French lemmatization.All these tools are embedded in the TectoMT anal-ysis framework (?abokrtsk?
et al, 2008).The results are in Table 4.
BLEUt has increasedin all cases w.r.t.
the baseline results.4.4 Alignment on LemmasOnce we are able to lemmatize all five languageswe can also experiment with word alignmentsbased on lemmas.
Table 5 shows that the differ-ences in BLEU are insignificant.5 ConclusionWe have described the hierarchical phrase-basedSMT system we used for the WMT 2011 sharedtask.
We discussed experiments with large dataDirection BLEUJ BLEUl BLEUten-cs 0.1191 0.126 0.119en-de 0.1337 0.131 0.127en-es 0.2573 0.276 0.265en-fr 0.2591 0.211 0.189cs-en 0.1692 0.180 0.168de-en 0.1885 0.191 0.178es-en 0.2446 0.260 0.236fr-en 0.2243 0.245 0.221Table 4: Results of experiments with supervisedtruecasing.
Note that training on truecased corpusslightly influenced even the lowercased BLEU (cf.with Table 2).
This is because probabilities of to-kens that may appear both uppercased and lower-cased (with different meanings) have changed, andthus different translation may have been chosen.Direction BLEUJ l4 BLEUJ lmen-cs 0.1191 0.1193en-de 0.1337 0.1318en-es 0.2573 0.2590en-fr 0.2591 0.2592cs-en 0.1692 0.1690de-en 0.1885 0.1892es-en 0.2446 0.2452fr-en 0.2243 0.2244Table 5: Results of experiments with word align-ment computed on different factors.
BLEUJ l4 isthe score computed by Joshua on lowercased testdata for the original experiments (alignment basedon lowercased 4-character prefixes).
BLEUJ lmis the corresponding score for alignment based onlemmas.from the point of view of both the translation ac-curacy and efficiency.
We used moderately-sizedtraining data and took advantage from their ba-sic linguistic annotation (lemmas).
The truecasingtechnique helped us to better target named entities.AcknowledgementsThe work on this project was supported by thegrant P406/11/1499 of the Czech Science Founda-tion (GA?R).ReferencesOnd?ej Bojar and Zden?k ?abokrtsk?.
2009.
Czeng0.9: Large parallel treebank with rich annotation.499The Prague Bulletin of Mathematical Linguistics,92:63?83.Stanley F. Chen and Joshua Goodman.
1998.
An em-pirical study of smoothing techniques for languagemodeling.
In Technical report TR-10-98, ComputerScience Group, Harvard, MA, USA, August.
Har-vard University.David Chiang.
2007.
Hierarchical Phrase-Based Translation.
Computational Linguistics,33(2):201?228.Reinhard Kneser and Hermann Ney.
1995.
Im-proved backing-off for m-gram language modeling.In Proceedings of the IEEE International Confer-ence on Acoustics, Speech and Signal Processing,pages 181?184, Los Alamitos, California, USA.IEEE Computer Society Press.Philipp Koehn, Franz Josef Och, and Daniel Marcu.2003.
Statistical phrase-based translation.
InNAACL ?03: Proceedings of the 2003 Conferenceof the North American Chapter of the Associationfor Computational Linguistics on Human LanguageTechnology, pages 48?54, Morristown, NJ, USA.Association for Computational Linguistics.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran,Richard Zens, Chris Dyer, Ond?ej Bojar, AlexandraConstantin, and Evan Herbst.
2007.
Moses: OpenSource Toolkit for Statistical Machine Translation.In Proceedings of the 45th Annual Meeting of theAssociation for Computational Linguistics Compan-ion Volume Proceedings of the Demo and Poster Ses-sions, pages 177?180, Praha, Czechia, June.
Associ-ation for Computational Linguistics.Zhifei Li, Chris Callison-Burch, Sanjeev Khudanpur,and Wren Thornton.
2009.
Decoding in Joshua:Open Source, Parsing-Based Machine Translation.The Prague Bulletin of Mathematical Linguistics,91:47?56, 1.Franz Josef Och andHermannNey.
2003.
A systematiccomparison of various statistical alignment models.Computational Linguistics, 29(1):19?51.Franz Josef Och.
1999.
An efficient method for deter-mining bilingual word classes.
In Proceedings of theNinth Conference of the European Chapter of the As-sociation for Computational Linguistics (EACL?99),pages 71?76, Bergen, Norway, June.
Association forComputational Linguistics.Andreas Stolcke.
2002.
Srilm ?
an extensible languagemodeling toolkit.
In Proceedings of InternationalConference on Spoken Language Processing, Den-ver, Colorado, USA.J?rg Tiedemann.
2009.
News from opus ?
a collectionof multilingual parallel corpora with tools and inter-faces.
InRecent Advances in Natural Language Pro-cessing (vol.
V), pages 237?248.
John Benjamins.Zden?k ?abokrtsk?, Jan Pt?
?ek, and Petr Pajas.
2008.TectoMT: Highly modular MT system with tec-togrammatics used as transfer layer.
In ACL 2008WMT: Proceedings of the Third Workshop on Statis-tical Machine Translation, pages 167?170, Colum-bus, OH, USA.
Association for Computational Lin-guistics.Omar F. Zaidan.
2009.
Z-mert: A fully configurableopen source tool for minimum error rate training ofmachine translation systems.
The Prague Bulletin ofMathematical Linguistics, 91:79?88.500
