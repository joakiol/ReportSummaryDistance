Dynamic Strategy Selection in Flexible ParsingJaime G. Carbonell and Philip J. HayesCarnegie-Mellon UniversityPittsburgh, PA 15213AbstractRobust natural language interpretation requires strong semantic domainmodels, "fall-soff" recovery heuristics, and very flexible controlstructures.
Although single-strategy parsers have met with a measure ofsuccess, a multi.strategy approach is shown to provide a much higherdegree of flexibility, redundancy, and ability to bring task-specific domainknowledge (in addition to general linguistic knowledge) to bear on bothgrammatical and ungrammatical input.
A parsing algorithm is presentedthat integrates several different parsing strategies, with case-frameinstantiation dominating.
Each of these parsing strategies exploitsdifferent types of knowledge; and their combination provides a strongframework in which to process conjunctions, fragmentary input, andungrammatical structures, as well as less exotic, grammatically correctinput.
Several specific heuristics for handling ungrammatical input arepresented within this multi-strategy framework.1.
IntroductionWhen people use language spontaneously, they o~ten do not respectgrammatical niceties.
Instead of producing sequences of grammaticallywell-formed and complete sentences, they often miss out or repeat wordsor phrases, break off what they are .saying and rephrase or replace it,speak in fragments, or use otherwise incorrect grammar.
While otherpeople generally have little trouble co'reprehending ungrammaticalutterances, most' natural language computer systems are unable toprocess errorful input at all.
Such inflexibility in parsing is a seriousimpediment to the use of natural language in interactive computersystems.
Accordingly, we \[6\] and other researchers includingWemchedel and Black \[14\], and Kwasny and Sondhelmer \[9\], haveattempted to produce flexible parsers, i.e.
parsers that can acceptungrammatical input, correcting the errors whan possible, andgenerating several alternative interpretations if appropriate.While different in many ways, all these approaches to flexible parsingoperate by applying a uniform parsing process to a uniformlyrepresented grammar.
Because of the linguistic performance problemsinvolved, this uniform procedure cannot be as simple and elegant as theprocedures followed by parsers based on a pure linguistic competencemodel, such as Parsifal \[10\].
Indeed, their parsing procedures mayinvolve several strategies that are applied in a predetermined order whenthe input deviates from the grammar, but the choice of strategy neverdepends on the specific type of construction being parsed.
In light ofexperience with our own flexible parser, we have come to believe thatsuch uniformity is not conducive to good flexible parsing.
Rather, thestrategies used should be dynamically selected according to the type ofconstruction being parsed.
For instance, partial.linear pattern matchingmay be well suited to the flexible parsing of idiomatic phrases, orspecialized noun phrases such as names, dates, or addresses (see also\[5\]), but case constructions, such as noun phrases with trailingprepositional phrases, or imperative phrases, require case-orientedparsing strategies.
The undedying principle is simple: The ap~rol~riateknowledge must be brought to bear at the right time -- and itmust not interfere at other times.
Though the initial motivation forthis approach sprang from the r~eeds of flexible parsing, suchconstruction.specific techniques can provide important benefits evenwhen no grammatical deviations are encountered, as we will show.
Thisobservation may be related to the current absence of any single universalparsing strategy capable of exploiting all knowledge sources (althoughELI \[12\] and its offspring \[2\] are efforts in this direction).Our objective here is not to create the ultimate parser, but to build avery flexible and robust taak.oriented parser capable of exploiting allrelevant domain knowledge as well as more general syntax andsemantics.
The initial application domain for the parser is the centralcomponent of an interface to various computer subsystems (or tools).This interface and, therefore the parser, should be adaptable to newtools by substituting domain-specific data bases (called "tooldescriptions") that govern the behaviorof the interface, including theinvocation of parsing strategies, dictionanes and concepts, rather thanrequiring any domain adaptations by the interface system itself.With these goals in mind, we proceed to give details of the kinds ofdifficulties that a uniform parsing strategy can lead to, and show howdynamically-selected construction.specific techniques can help.
We lista number of such specific strategies, then we focus on our initialimplementation of two of these strategies and the mechanism thatdynamically selects between them while pm'alng task-oriented naturallanguage imperative constructions.
Imperatives were chosen largelybecause commands and queries given to a task-oriented naturallanguage front end often take that form \[6\].2.
Problems with a Uniform Parsing StrategyOur present flexible parser, which we call RexP, is intended to parsecorrectly input that correaponds to a fixed grammar, and also to deal withinput that deviates from that grammar by erring along certain classes ofcommon ungrammaticalities.
Because of these goals, the parser isbased on the combination of two uniform parsing strategies: bottom-upparsing and pattern.matching.
The choice of a bottom.up rather then atop-down strategy was based on our need to recognize isolated sentencefragments, rather than complete sentences, and to detect restarts andcontinuations after interjections.
However, since completely bottom-upstrategies lead to the consideration of an unnecessary number ofalternatives in correct input, the algorithm used allowed some of theeconomies of top-dOwn parsing for non-deviant input.
Technicallyspeaking, this made the parser left-corner rather than bottom-up.
Wechose to use a grammar of linear patterns rather than, say, a transitionnetwork because pattern.matching meshes well with bottom-up parsingby allowing lookup of a pattern from the presence in the input of any ofits constituents; because pattern-matching facilitates recognition ofutterances with omissions and substitutions when patterns arerecognized on the basis of partial matches; and because pattern.matching is necessary for the recognition of idiomatic phrases.
Moredetails of the iustifications for these choices can be found in \[6\].1This research was .sponsored in Dart by the Defense Advanced R~Jeerc~ PromctsAgency (DE)O), ARPA Ck'1:ler NO.
35S7.
momtored by the Air Force Avmntcs Laboratoryun0er contract F33615.78-C-1551.
anti in part by the Air Force Office o( ?-,'mntifi?Research under Contract F49620-79-C-0143.
The views aria cor, clusm.s ?ontmneO in thisdocument are those Of the authors and shou~ not be inte.rDreleo as tepreser~ting theofficial DOhCle~ ?qther exl)resse0 or ,replied.
o!
DARPA, Ihe Air Force Office ol Scisn,ficResearch or the US government.FlexP has been tested extensively in conjunction with a gracefullyinteracting interface to an electronic mail system \[1\].
"Gracefullyinteracting" means that the interface appears friendly, supportive, androbust to its user.
In particular, graceful interaction requires the systemto tolerate minor input errors and typos, so a flexible parser is animbortant component of such an interface.
While FlexP performed thistask adeduately, the experience turned up some problems related to the143major theme of this paper.
These problems are all derived from theincomparability between the uniform nature of The grammarrepresentation and the kinds of flexible parsing strategies required todeal with the inherently non-uniform nature of some languageconstructions.
In particular:.
?Oifferent elements in the pattern of a single grammar rulecan serve raclically different functions and/or exhibitdifferent ease of recognition.
Hence, an efficient parsingstrategy should react to their apparent absence, for instance,in quite different ways.?
The representation of a single unified construction at thelanguage level may require several linear patterns at thegrammar level, making it impossible to treat that construction?
with the integrity required for adecluate flexible parsing.The second problem is directly related to the use of a pattern-matchinggrammar, but the first would arise with any uniformly representedgrammar applied by a uniform parsing strategy.For our application, these problems manifested themselves mostmarkedly by the presence of case constructions in the input language.Thus.
our examples and solution methOds will be in terms of integratingcase-frame instantiat=on with other parsing strategies.
Consider, forexample, the following noun phrase with a typical postnominal caseframe:"the messages from Smith aDout ADA pragmasdated later than Saturday".The phrase has three cases marked by "from", "about", and "dated laterthan".
This Wpe of phrase is actually used in FlexP's current grammar,and the basic pattern used to recognize descriptions of messages is:<?determiner  eMassageAd,1 ~4essagoHoad ?NOlsageC8$o)which says that a message description iS an optional (?)
determiner.followed by an arbitrary number (') of message adjectives followed by amessage head word (i.e.
a word meaning "r~essage").
followed by anarbitrary number of message cases, in the example.
"the" is thedeterminer, there are no message adjectives.
"messages" is themessage head word.
and there are three message cases: "from Smith".?
'about ADA pragmas", end "dated later than".
(~=cause each case hasmore than one component, each must be recognized by a separatepattern:<',Cf tom I~erson><~'.abou t Subject><~,s tnce Data>Here % means anything in the same word class, "dated later than", forinstance, is eauivalent o "since" for this purpOSe.These patterns for message descr~tions illustrate the two problemsmentioned above: the elementS of the .case patterns have radicallydifferent functions - The first elements are case markers, and the secondelements are the actual subconcepts for the case.
Since case indicatorsare typically much more restriCted in expression, and therefore mucheasier to recognize than Their corresponding subconc~ts, a plausiblestrategy for a parser that "knows" about case constructions is to scaninput for the case indicators, and then parse the associated subconceptstop-down.
This strategy is particularly valuable if one of the subconceptsis malformed or of uncertain form, such as the subject case in ourexample.
Neither "ADA" nor "pragmas" is likely to be in the vocabularyof our system, so the only way the end of the subject field can bedetected is by the presence of the case indicator "from" which follows iLHowever, the present parser cannot distinguish case indicators fromcase fillers - both are just elements in a pattern with exactly the samecomputational status, and hence it cannot use this strategy.The next section describes an algorithm for flexibly parsing caseconstructions.
At the moment, the algorithm works only on a mixture ofcase constructions and linear patterns, but eventually we envisage anumber of specific parsing algorithms, one for each of a number ofconstruction types, all working together to provide a more completeflexible parser.Below, we list a number of the parsing strategies that we envisagemight be used.
Most of these strategies exploit the constrained task.-oriented nature of the input language:?
Case-Frame Instantiation is necessary to parse generalimperative constructs and noun phrases with posThominalmodifiers.
This method has been applied before with somesuccess to linguistic or conceptual cases \[12\] in moregeneral parsing tasks.
However, it becomes much morepowerful and robust if domain-dependent constraints amongthe cases can be exploited.
For instance, in a file-management system, the command "Transfer UPDATE.FORto the accounts directory" can be easily parsed if theinformation in the unmarked case of transfer ("ulXlate.for" inour example) is parsed by a file-name expert, and thedestination case (flagged by "to") is parsed not as a physicallocation, but a logical entity ins=de a machine.
The latterconstraint enables one to interpret "directory" not as aphonebook or bureaucratic agency, but as a reasonabledestination for a file in a computer.?
Semantic Grammars \[8\] prove useful when there are waysof hierarchically clustering domain concepts intofunctionally useful categories for user interaction.
Semanticgrammars, like case systems, can bring domain knowledgeto bear in dissmbiguatmg word meaningS.
However, thecentral problem of semantic grammars is non-transferabilityto other domains, stemming from the specificity of thesemantic categorization hierarchy built into the grammarrules.
This problem is somewhat ameliorated if thistechnique is applied only tO parsing selected individualphrases \[13\], rather than being res0onsible for the entireparse.
Individual constituents, such as those recognizing theinitial segment of factual queries, apply in may domains,whereas a constituent recognizing a clause about filetransfer is totally domain specific.
Of course, This restriction"calls for a different parsing strategy at the clause andsentence level.?
(Partial) Pattern Matching on strings, using non.terminalsemantic.grammar constituents in the patterns, proves to bean interesting generalization of semantic grammars.
Thismethod is particularly useful when the patterns and semanticgrammar non-terminal nodes interleave in a hierarchicalfashion.e Transformations to Canonical Form prove useful bothfor domain-dependent and domain.independent constructs.For instance, the following rule transforms possessives into"of" phrases, which we chose as canonical:\['<ATTRZBUTE> tn possess ive form.<VALUE> lag l t fmate  fo r  a t t r ibute \ ]->\[<VALUE> "OF" <ATTRZBUTE> In stipple fo r l l \ ]Hence, the parser need only consider "of" constructions("file's destination" => "destinaUon of file").
Thesetransforms simplify the pattern matcher and semanticgrammar application process, especially when transformedconstructions occur in many different contextS.
Arudimentary form of string transformation was present inPARRY \[11 \].e Target-specif ic methods may be invoked toportions of sentences not easdy handlecl by The more generalmethods.
For instance, if a case-grammar determines thatthe case just s=gnaled is a proper name, a special name-expert strategy may be called.
This expe~ knows that nantes144can contain unknown words (e.g., Mr. Joe Gallen D'Aguila isobviously a name with D'Aguila as the surname) but subjectto ordering constraints and morphological preferences.When unknown words are encountered in other positions ina sentence, the parser may try morphologicaldecomposition, spelling correction, querying the user, ormore complex processes to induce the probable meaning ofunknown words, such as the project-and-integrate chniquedescribed in \[3\].
Clearly these unknown.word strategiesought to be suppressed in parsing person names.3.
A Case-Oriented Parsing StrategyAs part of our investigations in tosk-oriented parsing, we haveimplemented (in edditio,n to FlexP) a pure case-frame parser exploitingdomain-specific ase constraints stored in a declarative data structure,and a combination pattern-match, semantic grammar, canonical-transform parser, All three parsers have exhibited a measure of success,but more interestingly, the strengths of one method appear to overlapwith the weaknesses of a different method.
Hence, we are workingtowards a single parser that dynamically selects its parsing strategy tosuit the task demands.Our new parser is designed primarily for task domains where theprevalent forms of user input are commands and queries, both expressedin imperative or pseudo-imperative constructs.
Since in imperativeconstructs the initial word (or phrase), establishes the case.frame for theentire utterance, we chose the case-frame parsing strategy as priman/.In order to recognize an imperative command, and to instantiate eachcase, other parsing strategies are invoked.
Since the parser knows whatcan fill.a particular case, it can choosethe parsing strategy best suitedfor linguistic constructions expressing that type of information.Moreover, it can pass any global constraints from the case frame or fromother instantiated cases to the subsidiary parsers .
thus reducingpotential ambiguity, speeding the parse, and enhancing robustness.Consider our multi-strategy parsing algorithm as described below.Input is assumed to be in the imperative form:1.
Apply string PATTERN-MATCH to the initial segment of theinput using only the patterns previously indexed ascorresponding to command words/phrases in imperativeconstructions.
Patterns contain both optional constituentsand non.terminal symbols that expand according to asemantic grammar.
(E.g., "copy" and "do a file transfer" aresynonyms for the same command in a file managementsystem.)2.
Access the CASE.FRAME associated with the command justrecognized, and push it onto the context stack.
In the aboveexample, the case.frame is indexed under the token<COPY),, which was output by the pattern matcller, The caseframe consists of list of pairs (\[case.marker\] \[case-filler.information\[, ...).3.
Match the input with the case rharkers using the PATTERN-MATCH system descriOecl above."
If no match occurs,assume the input corresponds to the unmarked case (or thefirst unmarked case, if more than one is present), andproceed to the next step.4.
Apply the Darsin(7 strategy indicated by the type of constructexpected as a case filler.
Pass any available case constraintsto the suO-f~arser.
A partial list of parsing strategies indicatedby expected fillers is:?
Sub-imperative -- Case.frame parser, starting withthe command-identification pattern match above.?
Structured-object (e.g., a concept withsubattributes) .- Case-frame parser, starting with thepattern-marcher invoked on the list of patternscorresponding to the names (or compound names) ofthe semantically permissible structured objects,followed by case-frame parsing of any presentsubattributes.?
Simple Object .- Apply the pattern matcher, usingonly the patterns indexed as relevant in the case-filler-information field.Special Object -- Apply the .parsing strategyapplicable to that type of special object (e.g., propernames, dates, quoted strings, stylized technical jargon,etc...)None of the above -- (Errorful input or parserdeficiency) Apply the graceful recovery techniquesdiscussed below.5.
If an embedded case frame is.
activated, push it onto thecontext stack.6.
When a case filler is instantiated, remove the <case.marker),<case-filler-information> pair from the list of active cases inthe appropriate case frame, proceed to the next case-marker, and repeat the process above until the inputterminates.7, ff all the cases in a case frame have been instantiated, popthe context stack until that case frame is no longer in it.
(Completed frames typically re~de at the top of the stack.)8.
If there is more than One case frame on the stack whentrying to parse additional inpuL apply the followingprocedure:?
If the input only matches a case marker in one frame,proceed to instantiste the corresponding case-filler asoutlined above.
Also, if the matched c8~e marker is noton the most embedded case frame (i.e., at the top ofthe context stack), pop the stack until the frame whosecase marker was matched appears at the top of thestack.?
If no case markers are matched, attempt to parseunmarked cases, starting with the most deeolyembedded case frame (the top of the context stack)and proceeding outwards.
If one is matched, pop thecontext stack until the corresponding case frame is atthe top.
Then, instantiats the case filler, remove thecase from the active case frame, and proceed tO parseadditional input.
If more then one unmarked casematches the input, choose the most embedded one(i.e., the most recent context) and save the stats of theparse on the global history stack.
(This soggeat '= anambiguity that cannot be resolved with the informationat hand.)?
If the input matches more than one case marker in thecontext stack, try to parse the case filler via theindexed parsing strategy for each filler.information slotcorresponding to a matched case marker.
If more thenone case filler parses (this is somewhat rare sJtustion -indicating underconstrained case frames or trulyambiguous input) save the stats in the global historystack arid pursue the parse assuming the mOst deeplyembeded constituent, \[Our case.frame attachmentheuristic favors the most }ocal attachment permitted bysemantic case constraints.\]145g.
If a conjunction or disjunction occurs in the input, cyclethrough the context stack trying to parse the right-hand sideof the conjunction as filling the same case as the left handside.
If no such parse is feasible, interpret the conjunctionas top-level, e.g, as two instances of the same imperative, ortwo different imperatives, ff more than one parse results,interact with the user to disaml~iguate.
To illustrate thissimple process, consider.
"Transfer the programs written by Smith and Jones to ...""Transfer the programs written in Fortran and the censusdata files to ...""Transfer the prOgrams written in Fortran and delete ..."The scope of the first conjunction is the "author"subattribute of program, whereas the scope of the secondconiunction is the unmarked "obieot" case of the thrustoraction.
Domain knowledge in the case-filler information ofthe "ob)ect" case in the "transfer" imperative inhibits"Jones" from matching a potential object for electronic filetransfer, Similarly "Census data files" are inhibited frommatching the "author" subattribute of a prOgram.
Thusconjunctions in the two syntactically comparable examplesare scoped differently by our semantic-scoping rule relyingon domain-specific ase information.
"Delete" matches noactive case filler, and hence it is parsed as the initial SegmentOf a second conjoined utterance.
Since "delete" is a knownimperative, this parse succeeds.10.
If the Darser fails to Darse additional input, pop the globalhistory stack and pursue an alternate parse.
If the stack isempty, invoke the graceful recovery heuristics.
Here theDELTA-MIN method \[4\] can be applied to improve upondepth.first unwinding of the stack in the backtrackingpro,:_ ~,s_l__11.
If the end of the input is reached, and the global hiMo;y stackis not empty, pursue the alternate parses.
If any survive tothe end of the input (this should hot be the case unless trueamt~iguity exists), interact with the user to select theappropriate parse (see \[7).\]The need for embeded case structures and ambiguity resolution basedon domain-dependent semantic expectations of the case fillers isillustrated by the following paJr of sentences:"Edit the Drograms in Forlran""Edit the programs in Teco""Fortran" fills the language attribute of "prOgram", but cannot fill eitherthe location or instrument case of Edit (both of which can be signa~d by"in").
In the second sentence, however, "Teed" fills the instrument caseof the veYO "edit"  and none of the attributes of "program".
Thisdisembiguation is significant because in the first example the userspecified which programs (s)he wants to edit, whereas in the secondexample (s)he specified how (s)he wants to edit them.The algorithm Drseented is sufficient to parse grammatical input.
Inaddition, since it oper-,tes in a manner specifically tailored to caseconstructions, it is easy to add medifications dealing with deviant input.Currently, the algorithm includes the following steps that deal withungrammaticality:12.
If step 4 fails.
Le.
a filler of appropriate type cannot be parsedat that position in the inDut, then repeat step 3 at successivepoints in the input until it produces'a match, and continuethe regular algorithm from there.
Save all words notmatched on a SKIPPED list.
This step tal~es advantage of thefact that case markers are often much easier to recognizethan case fillers to realign the parser if it gets out of step withthe input (because of unexpected interjections, or otherspurious or missing won:is).13.
It wor(ls are on SKIPPED at the end of the parse, and casesremain unfilled in the case frames that were on the contextMack at the time the words were skipped, then try tO parseeach of the case fillers against successive positions of theskipped sequences.
This step picks up cases for which themasker was incorrect or gadoled.14.
if worOs are Mill on SKIPPED attempt he same matches, butrelax the pstlern matching procedures involved.15.
If this still does not account for all the input, interact with theuser by asking cluestions focussed on the uninterprsted Dartof the input.
The same focussed interaction techniclue(discussed in \[7\]) is used to resolve semantic ambiguities inthe inpuL16.
If user intersction proves impractical, apply the project-and-integrate method \[3\] to narrow down the meanings ofunknown words by exploiting syntactic, semantic andcontextual cues.These flexible paring steps rely on the construction-specific 8SDe?~ ofthe basic algorithm, and would not be easy to emulate in either asyntactic ATN parser or one based on a gum semantic gnlmmer.A further advantage of our rn ixed .s tn l~ approach is that the top.level case structure, in es~mce, partitions the semantic worlddynamically into categories according to the semanbc constraints On theactive case fillers.
Thus, when a pattern matcfler is invoked to parle therecipient case of a file-transfer case frlmle, it need Only consider I::~terns(and semantc.gramrnm" constructs) that correspond to logical locationsinsole a computer.
This form Of eXl~"ts~n-drMm I~u~ing in restricteddomains adds a two-fold effect to its rcbusmes??
Many smmous  parses are .ever generatod (bemnmopatterns yielding petentisfly spurious matches are neverin inappropriate contexts,)?
Additional knowledge (such as additional ~ grammarrules, etc.)
can be added without a corresponding linearinc~ in parso time since the coes.frames focus onlyupon the relevant sul3sat of patterns and rules.
Th.
Ink theefficiency of the system may actually inormme with theaddition of more domain knowledge (in effect shebang thecase fnmmes to further rssmct comext).
Thle pehm~ior ~it Do.
ib is  to incrementally build the ~ wWtout the ever-present fesr theta new extension may mal~ ltm entire pemerfail due to 8n unexl:)ected application of that extension in thewrong context.In closing, we note that the algorithm ~ above does notmer~ion interaction with morphotogicai de?ompoaltion or 81:XMllngcorrection.
LexicaJ processing is particularly important for robustParsing; indeed, based On our limited eXl::~rienca, lexicaJ-level errcra m'ea significant source of deviant input.
The recognition and handling oflexical-deviation phenomena, such as abbreviations and mies~Hlings,must be integrated with the more usual morDhotogical analySbl.
Some ofthese topics are discussed indeoendently in \[6\], However, in t l .
'p r igresilient morDhologicaJ analysis with the algorithm we have outlined is aproblem we consider very important and urgent if we are to construct ?practical flexible parser.4.
ConclusionTo summarize, uniform i~mng procedures applied to uniformgrammars are less than adeduate for par ing ungrammatical inpuL Asour experience with such an approach s~ows, the uniform methods areunable to take full advantage of domain knowledge, differing structurWroles (e.g,, case markers and.
case fillers), and relative eese ofidentification among the various constituents in different types of146constrl, ctions.
Instead, we advocate integrating a number of differentparSing strategies tailored to each type of construction as dictated by the?oplication domain.
The parser should dynamically select parsingstrategies according to what type of construction it expects in the courseof the parse.
We described a simple algorithm designed along theselines that makes dynamic choices between two parsing strategies, onedesigned for case constructions and the other for linear patterns.
Whilethis dynamic selection coproach was suggested by the needs of flexibleparSing, it also seemed to give our trial implementation significantefficiency advantages over single-strategy approaches for grammaticalinput.5.
References1.
Ball, J. E. and Hayes, P.J.
Representation of Task-IndependentKnowledge in a Gracefully Interacting User Interface.
Pro?.
1st AnnualMeeting of the American Association for Artificial Intelligence, AmericanAssoc.
for Artificial Intelligence, Stanford University, August, 1980, pp.116-120.2.
Birnbaum, L and Selfridge, M. Conceptual Analysis in NaturalLanguage.
In Inside Computer Understanding, R. Schank andC.
Riesbeck, Eds., New ~lersey: Edbaum Assoc., 1980, pp.
318-353,3.
Carbonell, J. G. Towards a Self.Extending Parser.
Proceedings ofthe 17th Meeting of the Association for Computational Linguistics, ACL-79, 1979, pp.
3-7.4.
Carbonell, J. G. A.MIN: A Search-Control Method for Information-Gathering Problems.
Proceedings of the First AAAI Conference, AAAI.80, August, 1980.?
5.
GerShman, A. V. Knowledge.Beset/Parsing.
Ph.D.
Th., YaleUniversity, April 1979.
Computer Sci.
Dept.
report # 1566.
Hayes, P. J. and Mouradian, G. V. Rexible Parsing.
Proc.
of 18thAnnual Meeting of the Assoc.
for Comput.
Ling., Philadelphia,June, 1980, pp.
97.103.7.
Hayes P. J.
Focused Interaction in Fiexible Parsing.
Carnegie.MellonUniverSity Computer Science Department, 1981.8.
Hendrix, G. G., Sacerdoti, E. D. and Slocum, J.
Developing a NaturalLanguage Interface to Complex Data.
Tech.
Rept.
Artificial IntelligenceCenter., SRI International, 1976.9.
Kwasny, S. C. and Sondheimer, N. K. Ungrammaticality and Extra-Grammaticality in Natural Language Understanding Systems.
Proc.
of17th Annual Meeting of the Assoc.
for Comput.
Ling., La Jolla, Ca.,August, 1979, PP.
19-23.10.
Marcus, M. A.. A Theory of Syntactic Recognition for NaturalLanguage.
MIT Press, Cambridge, Mass., 1980.1 1.
Parkison.
R. C., Colby, K. M., and Faught, W. S. "ConversationalLanguage Comprehension Using Integrated Pattern.Matching andParsing."
Artificia/Intelligence 9 (1977), 111-134.12.
Riesbeck.
C. and Schank.
R, C. Comprehension by Computer:.Exl:ectation.aased Analysis of Sentences in Context.
Tech.
Rept.
78,Computer Science Department, Yale University, 1976:13.
Waltz, D. L. and Goodman.
A.
B.
Writing a Natural Language OatsBase System.
IJCAIVproc, IJCAI-77, 1977, pp.
144-150.14.
We~schedel, R. M. and Black, J.
Responding to PotentiallyUnl:arseable Serttences, Tech.
Rept.
79/3, Dept.
of Computer andInformation Sciences, UniverSity of Delaware, 1979.147
