Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 825?835,Edinburgh, Scotland, UK, July 27?31, 2011. c?2011 Association for Computational LinguisticsRelation Acquisition using Word Classes and Partial PatternsStijn De Saeger??
Kentaro Torisawa?
Masaaki Tsuchida?
Jun?ichi Kazama?Chikara Hashimoto?
Ichiro Yamada?
Jong Hoon Oh?
Istva?n Varga?
Yulan Yan??
Information Analysis Laboratory, National Institute ofInformation and Communications Technology, 619-0289 Kyoto, Japan{stijn,torisawa,kazama,ch,rovellia,istvan,yulan}@nict.go.jp?
Information and Media Processing Laboratories, NEC Corporation, 630-0101 Nara, Japanm-tsuchida@cq.jp.nec.com?
Human & Information Science Research Division,NHK Science & Technology Research Laboratories, 157-8510 Tokyo, Japanyamada.i-hy@nhk.or.jpAbstractThis paper proposes a semi-supervised rela-tion acquisition method that does not rely onextraction patterns (e.g.
?X causes Y?
forcausal relations) but instead learns a combi-nation of indirect evidence for the target re-lation ?
semantic word classes and partialpatterns.
This method can extract long tailinstances of semantic relations like causalityfrom rare and complex expressions in a largeJapaneseWeb corpus?
in extreme cases, pat-terns that occur only once in the entire cor-pus.
Such patterns are beyond the reach of cur-rent pattern based methods.
We show that ourmethod performs on par with state-of-the-artpattern based methods, and maintains a rea-sonable level of accuracy even for instancesacquired from infrequent patterns.
This abil-ity to acquire long tail instances is crucial forrisk management and innovation, where an ex-haustive database of high-level semantic rela-tions like causation is of vital importance.1 IntroductionPattern based relation acquisition methods rely onlexico-syntactic patterns (Hearst, 1992) for extract-ing relation instances.
These are templates of natu-ral language expressions such as ?X causes Y ?
thatsignal an instance of some semantic relation (i.e.,causality).
Pattern based methods (Agichtein andGravano, 2000; Pantel and Pennacchiotti, 2006b;Pas?ca et al, 2006; De Saeger et al, 2009) learn many?
This work was done when all authors were at the NationalInstitute of Information and Communications Technology.such patterns to extract new instances (word pairs)from the corpus.However, since extraction patterns are learned us-ing statistical methods that require a certain fre-quency of observations, pattern based methods failto capture relations from complex expressions inwhich the pattern connecting the two words is rarelyobserved.
Consider the following sentence:?Curing hypertension alleviates the deteriora-tion speed of the renal function, thereby lower-ing the risk of causing intracranial bleeding?Humans can infer that this sentence expresses acausal relation between the underlined noun phrases.But the actual pattern connecting them, i.e., ?Cur-ing X alleviates the deterioration speed of the re-nal function, thereby lowering the risk of causingY ?, is rarely observed more than once even in a 108page Web corpus.
In the sense that the term pat-tern implies a recurring event, this expression con-tains no pattern for detecting the causal relation be-tween hypertension and intracranial bleeding.
Thisis what we mean by ?long tail instances?
?
wordsthat co-occur infrequently, and only in sparse extrac-tion contexts.Yet an important application of relation extractionis mining the Web for so-called unknown unknowns?
in the words of D. Rumsfeld, ?things we don?tknow we don?t know?
(Torisawa et al, 2010).
Inknowledge discovery applications like risk manage-ment and innovation, the usefulness of relation ex-traction lies in its ability to find many unexpectedremedies for diseases, causes of social problems,and so on.
To give an example, our relation extrac-825tion system found a blog post mentioning Japaneseautomaker Toyota as a hidden cause of Japan?s de-flation.
Several months later the same connectionwas made in an article published in an authoritativeeconomic magazine.We propose a semi-supervised relation extractionmethod that does not rely on direct pattern evidenceconnecting the two words in a sentence.
We arguethat the role of binary patterns can be replaced by acombination of two types of indirect evidence: se-mantic class information about the target relationand partial patterns, which are fragments or sub-patterns of binary patterns.
The intuition is this: ifa sentence like the example sentence above containssome wordX belonging to the class of medical con-ditions and another word Y from the class of trau-mas, and X matches the partial pattern ?.
.
.
causingX?, there is a decent chance that this sentence ex-presses a causal relation between X and Y .
Weshow that just using this combination of indirectevidence we can pick up semantic relations withroughly 50% precision, regardless of the complexityor frequency of the expression in which the wordsco-occur.
Furthermore, by combining this idea witha straightforward machine learning approach, theoverall performance of our method is on par withstate-of-the-art pattern based methods.
However,our method manages to extract a large number ofinstances from sentences that contain no pattern thatcan be learned by pattern induction methods.Our method is a two-stage system.
Figure 1presents an overview.
In Stage 1 we apply a state-of-the-art pattern based relation extractor to a Webcorpus to obtain an initial batch of relation instances.In Stage 2 a supervised classifier is built from vari-ous components obtained from the output of Stage1.
Given the output of Stage 1 and access to aWeb corpus, the Stage 2 extractor is completelyself-sufficient, and the whole method requires nosupervision other than a handful of seed patternsto start the first stage extractor.
The whole proce-dure is therefore minimally supervised.
Semanticword classes and partial patterns play a crucial rolethroughout all steps of the process.We evaluate our method on three relation acqui-sition tasks (causation, prevention and material re-lations) using a 600 million Japanese Web page cor-Figure 1: Proposed method: data flow.pus (Shinzato et al, 2008) and show that our sys-tem can successfully acquire relations from bothfrequent and infrequent patterns.
Our system ex-tracted 100,000 causal relations with 84.6% preci-sion, 50,000 prevention relations with 58.4% preci-sion and 25,000 material relations with 76.1% preci-sion.
In the extreme case, we acquired several thou-sand word pairs co-occurring only in patterns thatappear once in the entire corpus.
We call such pat-terns single occurrence (SO) patterns.
Word pairsthat co-occur only with SO patterns represent thetheoretical limiting case of relations that cannot beacquired using existing pattern based methods.
Inthis sense our method can be seen as complemen-tary with pattern based approaches, and merging ourmethod?s output with that of a pattern based methodmay be beneficial.2 Stage 1 ExtractorThis section introduces our Stage 1 extractor: thepattern based method from (De Saeger et al, 2009),which we call CDP for ?class dependent patterns?.We give a brief overview below, and refer the readerto the original paper for a more comprehensive ex-planation.CDP takes a set of seed patterns as input, and au-tomatically learns new class dependent patterns asparaphrases of the seed patterns.
Class dependentpatterns are semantic class restricted versions of or-dinary lexico-syntactic patterns.
Existing methodsuse class independent patterns such as ?X causesY ?
to learn causal relations betweenX and Y .
Classdependent patterns however place semantic class re-826strictions on the noun pairs they may extract, like?Yaccidents causes Xincidents?.
The accidents andincidents subscripts specify the semantic class of theX and Y slot fillers.These class restrictions make it possible to distin-guish between multiple senses of highly ambiguouspatterns (so-called ?generic?
patterns).
For instance,given the generic pattern ?Y by X?, if we restrictY and X in to the semantic classes of injuries andaccidents (as in ?death by drowning?
), the class de-pendent pattern ?Yinjuries by Xaccidents?
becomes avalid paraphrase of ?X causes Y ?
and can safely beused to extract causal relations, whereas other classdependent versions of the same generic pattern (e.g.,?Yproducts byXcompanies?, as in ?iPhone by Apple?
)may not.CDP ranks each noun pair in the corpus accord-ing to a score that reflects its likelihood of beinga proper instance of the target relation, by calcu-lating the semantic similarity of a set of seed pat-terns to the class dependent patterns this noun pairco-occurs with.
The output of CDP is a list of nounpairs ranked by score, together with the highest scor-ing class dependent pattern each noun pair co-occurswith.
This list becomes the input to Stage 2 of ourmethod, as shown in Figure 1.
We adopted CDP asStage 1 extractor because, besides having generallygood performance, the class dependent patterns pro-vide the two fundamental ingredients for Stage 2 ofour method ?
the target semantic word classes for agiven relation (in the form of the semantic class re-strictions attached to patterns), and partial patterns.To obtain fine-grained semantic word classes weused the large scale word clustering algorithm from(Kazama and Torisawa, 2008), which uses the EMalgorithm to compute the probability that a word wbelongs to class c, i.e., P (c|w).
Probabilistic cluster-ing defines no discrete boundary between membersand non-members of a semantic class, so we simplyassume w belongs to c whenever P (c|w) ?
0.2.
Forthis work we clustered 106 nouns into 500 classes.Finally, we adopt the structural representation ofpatterns introduced in (Lin and Pantel, 2001).
Allsentences in our corpus are dependency parsed, andpatterns consist of words on the path of dependencyrelations connecting two nouns.3 Stage 2 ExtractorWe use CDP as our Stage 1 extractor, and the topN noun pairs along with the class dependent pat-terns that extract them are given as input to Stage 2,which represents the main contribution of this work.As shown in Figure 1, Stage 2 consists of three mod-ules: a candidate generator, a training data gener-ator and a supervised classifier.
The training datagenerator builds training data for the classifier fromthe top N output of CDP and sentences retrievedfrom the Web corpus.
This classifier then scores andranks the candidate relations generated by the can-didate relation generator.
We introduce each modulebelow.Candidate Generator This module generatessentences containing candidate word pairs for thetarget relation from the corpus.
It does so using thesemantic class restrictions and partial patterns ob-tained from the output of CDP.
The set of all seman-tic class pairs obtained from the class dependent pat-terns that extracted the topN results become the tar-get semantic class pairs from which new candidateinstances are generated.
We extract all sentencescontaining a word pair belonging to one of the targetclass pairs from the corpus.From these sentences we keep only those that con-tain a trace of evidence for the target semantic re-lation.
For this we decompose the class dependentpatterns from the Stage 1 extractor into partial pat-terns.
As mentioned previously, patterns consist ofwords on the path of dependency relations connect-ing the two target words in a syntactic tree.
To obtainpartial patterns we split this dependency path into itstwo constituent branches, each one leading from theleaf word (i.e.
variable) to the syntactic head of thepattern.
For example, ?X subj??
causes obj??
Y ?
issplit into two partial patterns ?X subj??
causes?
and?causes obj??
Y ?.
These partial patterns capture thepredicate structures in binary patterns.1 We discardpartial patterns with syntactic heads other than verbsor adjectives.The candidate genarator retrieves all sentencesfrom the corpus in which two nouns belonging toone of the target semantic classes co-occur and1 In Japanese, case information is encoded in post-positionsattached to the noun.827where at least one of the nouns matches a partial pat-tern.
As shown in Figure 1, these sentences and thecandidate noun pairs they contain (called (noun pair,sentence) triples hereafter) are submitted to the clas-sifier for scoring.
Restricting candidate noun pairsby this combination of semantic word classes andpartial pattern matching proved to be quite powerful.For instance, in the case of causal relations we foundthat close to 60% of the (noun pair, sentence) triplesproduced by the candidate generator were correct(Figure 6).Training Data Generator As shown in Figure 1,the (noun pair, sentence) triples used as training datafor the SVM classifier were generated from the topresults of the Stage 1 extractor and the corpus.
Weconsider the noun pairs in the top N output of theStage 1 extractor as true instances of the target re-lation (even though they may contain erroneous ex-tractions), and retrieve from the corpus all sentencesin which these noun pairs co-occur and that matchone of the partial patterns mentioned above.
In ourexperiments we set N to 25, 000.
We randomly se-lect positive training samples from this set of (nounpair, sentence) triples.Negative training samples are also selected ran-domly, as follows.
If one member of the target nounpair in the positive samples above matches a partialpattern but the other does not, we randomly replacethe latter by another noun found in the same sen-tence, and generate this new (noun pair, sentence)triple as a negative training sample.
In the causalrelation experiments this approach had about 5%chance of generating false negatives ?
noun pairscontained in the top N results of the Stage 1 extrac-tor.
Such samples were discarded.
Our experimen-tal results show that this scheme works quite well inpractice.
We randomly sample M positive and neg-ative samples from the autogenerated training datato train the SVM.
M was empirically set to 50,000in our experiments.SVM Classifier We used a straightforward fea-ture set for training the SVM classifier.
Becauseour classifier will be faced with sentences contain-ing long and infrequent patterns where the distancebetween the two target nouns may be quite large,we did not try to represent lexico-syntactic patternsas features but deliberately restricted the feature setto local context features of the candidate noun pairin the target sentence.
Concretely, we looked at bi-grams and unigrams surrounding both nouns of thecandidate relation, as the local context around thetarget words may contain many telling expressionslike ?increase in X?
or ?X deficiency?
which are use-ful clues for causal relations.
Also, in Japanese caseinformation is encoded in post-positions attached tothe noun, which is captured by the unigram features.In addition to these base features, we include thesemantic classes to which the candidate noun pairbelongs, the partial patterns they match in this sen-tence, and the infix words inbetween the target nounpair.
Note that this feature set is not intended tobe optimal beyond the actual claims of this paper,and we have deliberately avoided exhaustive fea-ture engineering so as not to obscure the contribu-tion of semantic classes and partial pattern to ourapproach.
Clearly an optimal classifier will incorpo-rate many more advanced features (see GuoDong etal.
(2005) for a comprehensive overview), but evenwithout sophisticated feature engineering our clas-sifier achieved sufficient performance levels to sup-port our claims.
An overview of the feature set isgiven in Table 1.
The relative contribution of eachtype of features is discussed in section 4.
In prelim-inary experiments we found a polynomial kernel ofdegree 3 gave the best results, which suggests the ef-fectiveness of combining different types of indirectevidence.The SVM classifier outputs (noun pair, sentence)triples, ranked by SVM score.
To obtain the finaloutput of our method we assign each unique nounpair the maximum score from all (noun pair, sen-tence) triples it occurs in, and discard all other sen-tences for this noun pair.
In section 4 below we eval-uate the acquired noun pairs in the context of thesentence that maximizes their score.4 EvaluationWe demonstrate the effectiveness of semantic wordclasses and partial pattern matching for relation ex-traction by showing that the method proposed in thispaper performs at the level of other state-of-the-artrelation acquisition methods.
In addition we demon-strate that our method can successfully extract re-lation instances from infrequent patterns, and we828Feature type Description Number of featuresMorpheme features Unigram and bigram morphemes surrounding both target words.
554,395POS features Coarse- and fine-grained POS tags of the noun pair and morpheme features.
2,411Semantic features Semantic word classes of the target noun pair.
1000 (500 classes ?2)Infix word features Morphemes found inbetween the target noun pair.
94,448Partial patterns Partial patterns matching the target noun pair.
86Table 1: Feature set used in the Stage 2 classifier, and their number for the causal relation experiments.explore several criteria for what constitutes an in-frequent pattern ?
including the theoretical limit-ing case of patterns observed only once in the en-tire corpus.
These instances are impossible to ac-quire by pattern based methods.
The ability to ac-quire relations from extremely infrequent expres-sions with decent accuracy demonstrates the utilityof combining semantic word classes with partial pat-tern matching.4.1 Experimental SettingWe evaluate our method on three semantic relationacquisition tasks: causality, prevention and mate-rial.
Two concepts stand in a causal relation whenthe source concept (the ?cause?)
is directly or indi-rectly responsible for the subsequent occurrence ofthe target concept (its ?effect?).
In a prevention rela-tion the source concept directly or indirectly acts toavoid the occurrence of the target concept, and in amaterial relation the source concept is a material oringredient of the target concept.For our experiments we used the latest versionof the TSUBAKI corpus (Shinzato et al, 2008),a collection of 600 million Japanese Web pagesdependency parsed by the Japanese dependencyparser KNP2.
In our implementation of CDP, lexico-syntactic patterns consist of words on the path con-necting two nouns in a dependency parse tree.
Wediscard patterns from dependency paths longer than8 constituent nodes.
Furthermore, we estimated pat-tern frequencies in a subset of the corpus (50 millionpages, or 1/12th of the entire corpus) and discardedpatterns that co-occur with less than 10 unique nounpairs in this smaller corpus.
These restrictions donot apply to the proposed method, which can extractnoun pairs connected by patterns of arbitrary length,even if found only once in the corpus.
For our pur-2 http://nlp.kuee.kyoto-u.ac.jp/nl-resource/knp.htmlpose we treat dependency paths whose observed fre-quency is below this threshold as insufficiently fre-quent to be considered as ?patterns?.
This thresholdis of course arbitrary, but in section 4 we show thatour results are not affected by these implementationdetails.We asked three human judges to evaluate ran-dom (noun pair, sentence) triples, i.e.
candidatenoun pairs in the context of some corpus sentencein which they co-occur.
If the judges find the sen-tence contains sufficient evidence that the target re-lation holds between the candidate nouns, they markthe noun pair correct.
To evaluate the performanceof each method we use two evaluation criteria: strict(all judges must agree the candidate relation is cor-rect) and lenient (decided by the judges?
majorityvote).
Over all experiments the interrater agreement(Kappa) ranged between 0.57 and 0.82 with an aver-age of 0.72, indicating substantial agreement (Lan-dis and Koch, 1977).4.1.1 Methods ComparedWe compare our results to two pattern basedmethods: CDP (the Stage 1 extractor) and Espresso(Pantel and Pennacchiotti, 2006a).Espresso is a popular bootstrapping based methodthat uses a set of seed instances to induce extractionpatterns for the target relation and then acquire newinstances in an iterative bootstrapping process.
Ineach iteration Espresso performs pattern induction,pattern ranking and selection using previously ac-quired instances, and uses the newly acquired pat-terns to extraction new instances.
Espresso com-putes a reliability score for both instances and pat-terns based on their pointwise mutual information(PMI) with the top-scoring patterns and instancesfrom the previous iteration.3 We refer to (Pantel and3 In our implementation of Espresso we found that, despitethe many parameters for controlling the bootstrapping process,82930%40%50%60%70%80%90%100%0 10K 20K 30K 40K 50K 60K 70K 80K 90K 100KProposed (L)Proposed (S)Prop.
w/o CDP (L)Prop.
w/o CDP (S)Prop.
w/o pattern (L)Prop.
w/o pattern (S)Espresso (L)Espresso (S)CDP (L)CDP (S)Figure 2: Precision of acquired relations (causality).
Land S denote lenient and strict evaluation.Pennacchiotti, 2006a) for a more detailed descrip-tion.For all methods compared we rank the acquirednoun pairs by their score and evaluated 500 randomsamples from the top 100,000 results.
For noun pairsacquired by CDP and Espresso we select the patternthat extracted this noun pair (in the case of Espresso,the pattern with the highest PMI for this noun pair),and randomly select a sentence in which the nounpair co-occurs with that pattern from our corpus.
Forthe proposed method we evaluate noun pairs in thecontext of the (noun pair, sentence) triple with thehighest SVM score.4.2 Results and DiscussionThe performance of each method on the causality,prevention and material relations are shown in Fig-ures 2, 3 and 4 respectively.
In the causality exper-iments (Figure 2) the proposed method performs onpar with CDP for the top 25,000 results, both achiev-ing close to 90% precision.
But whereas CDP?s per-it remains very difficult to prevent semantic drift (Komachi etal., 2008) from occurring.
One small adjustment to the al-gorithm stabilized the bootstrapping process considerably andgave overall better results.
In the pattern induction step (sec-tion 3.2 in (Pantel and Pennacchiotti, 2006a)), Espresso com-putes a reliability score for each candidate pattern based on theweighted PMI of the pattern with all instances extracted so far.As the number of extracted instances increases this dispropor-tionally favours high frequency (i.e.
generic) patterns, so in-stead of using all instances for computing pattern reliability weonly use the m most reliable instances from the previous iter-ation, which were used to extract the candidate patterns of thecurrent iteration (m = 200, like the original).0%10%20%30%40%50%60%70%80%90%100%0 10K 20K 30K 40K 50K 60K 70K 80K 90K 100KProposed (L)Proposed (S)Prop.
w/o CDP (L)Prop.
w/o CDP (S)Prop.
w/o pattern (L)Prop.
w/o pattern (S)Espresso (L)Espresso (S)CDP (L)CDP (S)Figure 3: Precision of acquired relations (prevention).
Land S denote lenient and strict evaluation.0%10%20%30%40%50%60%70%80%90%100%0 10K 20K 30K 40K 50K 60K 70K 80K 90K 100KProposed (L)Proposed (S)Prop.
w/o CDP (L)Prop.
w/o CDP (S)Prop.
w/o pattern (L)Prop.
w/o pattern (S)Espresso (L)Espresso (S)CDP (L)CDP (S)Figure 4: Precision of acquired relations (material).
Land S denote lenient and strict evaluation.formance drops from there our method maintainsthe same high precision throughout (84.6%, lenient).Both our method and CDP outperform Espresso bya large margin.For the prevention relation (Figure 3), precisionis considerably lower for all methods except the top10,000 of CDP (82% precision, lenient).
The pro-posed method peaks at around 20,000 results (67%precision, lenient) and performance remains more orless constant from there on.
The proposed methodovertakes CDP?s performance around the top 45,000mark, which suggests that combining the results ofboth methods may be beneficial.In the material relations the proposed methodslightly outperforms both pattern based methodsin the top 10,000 results (92% precision, lenient).830However for this relation our method produced only35,409 instances.
The reason is that the top 25,000results of CDP were all extracted by just 12 patterns,and these contained many patterns whose syntactichead is not a verb or adjective (like ?Y rich in X?
or?Y containing X?).
Only 12 partial patterns were ob-tained, which greatly reduced the output of the pro-posed method.
Taking into account the high perfor-mance of CDP for material relations, this suggeststhat for some relations our method?s N and M pa-rameters could use some tuning.
In conclusion, inall three relations our method performs at a levelcomparable to state-of-the-art pattern based meth-ods, which is remarkable given that it only uses in-direct evidence.Dealing with Difficult Extractions How does ourmethod handle noun pairs that are difficult to ac-quire by pattern based methods?
The graphs marked?Prop.
w/o CDP?
(Proposed without CDP) in Fig-ures 2 , 3 and 4 show the number and precision ofevaluated samples from the proposed method that donot co-occur in our corpus with any of the patternsthat extracted the top N results of the first stage ex-tractor.
These graphs show that our method is notsimply regenerating CDP?s top results but actuallyextracts many noun pairs that do not co-occur in pat-terns that are easily learned.
Figure 2 shows thatroughly two thirds of the evaluated samples are inthis category, and that their performance is not sig-nificantly worse than the overall result.
The sameconclusion holds for the prevention results (Figure3), where over 80% of the proposed method?s sam-ples are noun pairs that do not co-occur with eas-ily learnable patterns.
Their precision is about 5%worse than all samples from the proposed method.For material relations (Figure 4) about half of allevaluated samples are in this category, but their pre-cision is markedly worse compared to all results.For genuinely infrequent patterns, the graphsmarked ?Prop.
w/o pattern?
(Proposed without pat-tern) in Figures 2 , 3 and 4 show the number andprecision of noun pairs evaluated for the proposedmethod that were acquired from sentences withoutany discernible pattern.
As explained in section 4above, these constitute noun pairs co-occurring in asentence in which the path of dependency relationsconnecting them is either longer than 8 nodes or can051015201 2 32 1024 32768 1.05x106 3.36x107% of all samples# of noun pairs co-occurring with patternsPattern frequency, CDPPattern frequency, ProposedPattern frequency, EspressoFigure 5: Frequencies of patterns in the evaluation data(causation).extract fewer than 10 noun pairs in 50 million Webpages.
Note that in theory it is possible that thesenoun pairs could not be acquired by pattern basedmethods due to this threshold ?
patterns must beable to extract more than 10 different noun pairs ina subset of our corpus, while the proposed methoddoes not have this constraint.
So at least in the-ory, pattern based methods might be able to acquireall noun pairs obtained by our method by loweringthis threshold.
To see that this is unlikely to be thecase, consider Figure 5, which shows the pattern fre-quency of the patterns induced by CDP and Espressofor the causality experiment.
The x-axis representspattern frequency in terms of the number of uniquenoun pairs a pattern co-occurs with in our corpus (ona log scale), and the y-axis shows the percentage ofsamples that was extracted by patterns of a given fre-quency.4 Figure 5 shows that for the pattern basedmethods, the large majority of noun pairs was ex-tracted by patterns that co-occur with several thou-sand different noun pairs.
Extrapolating the originalfrequency threshold of 10 nounpairs to the size ofour entire corpus roughly corresponds to about 120distinct noun pairs (10 times in 1/12th of the entirecorpus).
In Figure 5, the histograms for the patternbased methods CDP and Espresso start around 1000noun pairs, which is far above this new lowerbound.4 In the case of CDP we ignore semantic class restrictionson the patterns when comparing frequencies.
For Espresso, themost frequent pattern (?Y by X?
at the 24,889,329 data pointon the x-axis) extracted up to 53.8% of the results, but the graphwas cut at 20% for readability.831Causality???????
??????????????????????????????????????????[????]?????
?Because ?catecholamine?
causes a rapid increase of heart rate, the change of circulation inside the blood vessels leads to blood vesseldisorders and promotes [thrombus generation].?????
???????????????????????????????????
[????]????????????
?When we injected Xylocaine during a ?tachycardia seizure?, the patient suddenly lost consciousness and fell into a fit of [convulsions].????????
?????????
?????????
[???]???????????????(.
.
. )
The reason is that by taking a lot of ?animal proteins?
the causative agents of [tragomaschalia] increase.*????????????
??????
??????????????????????
[???]?
* [Radon] heightens the (body?s) antioxidative function and is effective for eliminating activated oxygen, which is a cause of aging and?lifestyle-related?
diseases.Prevention????????????????????
????
??????????????[???]????????????
?Because the fatty meat of tuna contains DHA and ?EPA?
in abundance, it is effective for preventing [neuralgia].???????
?????
???????
[????]????????
?If you use ?nitrogen gas?
instead of air you may prevent [dust explosions].???????????
???????
????????????????????????
[???]??????????
?In ancient Europe ?orthosiphon aristatus?
tea was called a ?diet tea?, and supposedly it helps preventing triglycerides and [adult diseases].
* ??
????????????????????????
[????]????????
* (It) is something that prevents [scratches] on the screen if the ?calash?
gets stuck between the screens during storage.Table 2: Causality and Prevention relations acquired from Single Occurrence (SO) patterns.
?X?
and [Y] indicate therelation instance?s source and target words, and ?*?
indicates erroneous extractions.Thus, pattern based methods naturally tend to inducepatterns that are much more frequent than the rangeof patterns our method can capture, and it is unlikelythat this is a result of implementation details like pat-tern frequency threshold.The precision of noun pairs in the category ?Prop.w/o pattern?
is clearly lower than the overall re-sults, but the graphs demonstrate that our methodstill handles these difficult cases reasonably well.The 500 samples evaluated contained 155 such in-stances for causality, 403 for prevention and 276 formaterial.
For prevention, the high ratio of these nounpairs helps explain why the overall performance waslower than for the other relations.Finally, the theoretical limiting case for patternbased algorithms consists of patterns that only co-occur with a single noun pair in the entire corpus(single occurrence or SO patterns).
Pattern basedmethods learn new patterns that share many nounpairs with a set of reliable patterns in order to extractnew relation instances.
If a noun pair that co-occurswith a SO pattern also co-occurs with more reliablepatterns there is no need to learn the SO pattern.
Ifthat same noun pair does not co-occur with any otherreliable pattern, the SO pattern is beyond the reachof any pattern induction method.
Thus, SO patternsare effectively useless for pattern based methods.For the 500 samples evaluated from the causalityand prevention relations acquired by our method wefound 7 causal noun pairs that co-occur only in SOpatterns and 29 such noun pairs for prevention.
Theprecision of these instances was 42.9% and 51.7%respectively.
In total we found 8,716 causal nounpairs and 7,369 prevention noun pairs that co-occuronly with SO patterns.
Table 2 shows some examplerelations from our causality and prevention experi-ments that were extracted from SO patterns.
To con-clude, our method is able to acquire correct relationseven from the most extreme infrequent expressions.Semantic Classes, Partial Patterns or Both?
Inthe remainder of this section we look at how thecombination of semantic word classes and partialpatterns benefits our method.
For each relation weevaluated 1000 random (noun pair, sentence) triplessatisfying the two conditions from section 3 ?matching semantic class pairs and partial patterns.Surprisingly, the precision of these samples was59% for causality, 40% for prevention and 50.4%for material, showing just how compelling these twotypes of indirect evidence are in combination.To estimate the relative contribution of eachheuristic we compared our candidate generationmethod against two baselines.
The first baselineevaluates the precision of random noun pairs from83250607080901000  200  400  600  800  1000precision(%)(noun pair, sentence) triples ranked by scoreBase features onlyAll minus semantic classesAll minus infix wordsAll minus partial patternsAll featuresFigure 6: Contribution of feature sets (causality).304050607080901000  200  400  600  800  1000precision(%)(noun pair, sentence) triples ranked by scoreBase features onlyAll minus semantic classesAll minus infix wordsAll minus partial patternsAll featuresFigure 7: Contribution of feature sets (prevention).the target semantic classes that co-occur in a sen-tence.
The second baseline does the same for thesecond heuristic, selecting random sentences con-taining a noun pair that matches some partial pat-tern.
Evaluating 100 samples for causality and pre-vention, we found the precision of the semantic classbaseline was 16% for causality and 5% for preven-tion.
The pattern fragment baseline gave 9% forcausality and 22% for prevention.
This is consid-erably lower than the precision of random samplesthat satisfy both the semantic class and partial pat-tern conditions, showing that the combination of se-mantic classes and partial patterns is more effectivethan either one individually.Finally, we investigated the effect of the variousfeature sets used in the classifier.
Figures 6, 7 and8 show the results for the respective semantic re-lations.
The ?Base features?
graph shows the per-304050607080901000  200  400  600  800  1000precision(%)(noun pair, sentence) triples ranked by scoreBase features onlyAll minus semantic classesAll minus infix wordsAll minus partial patternsAll featuresFigure 8: Contribution of feature sets (material).formance the unigram, bigram and part-of-speechfeatures.
?All features?
uses all features in Table1.
The other graphs show the effect of removingone type of features.
These graphs suggest that thecontribution of the individual feature types (seman-tic class information, partial patterns or infix words)to the classification performance is relatively minor,but in combination they do give a marked improve-ment over the base features, at least for some rela-tions like causation and material.
In other words,the main contribution of semantic word classes andpartial patterns to our method?s performance lies notin the final classification step but seems to occur atearlier stages of the process, in the candidate andtraining data generation steps.5 Related WorkUsing lexico-syntactic patterns to extract semanticrelations was first explored by Hearst (Hearst, 1992),and has inspired a large body of work on semi-supervised relation acquisition methods (Berlandand Charniak, 1999; Agichtein and Gravano, 2000;Etzioni et al, 2004; Pantel and Pennacchiotti,2006b; Pas?ca et al, 2006; De Saeger et al, 2009),two of which were used in this work.Some researchers have addressed the sparse-ness problems inherent in pattern based methods.Downey et al (2007) starts from the output ofthe unsupervised information extraction system Tex-tRunner (Banko and Etzioni, 2008), and uses lan-guage modeling techniques to estimate the reliabil-ity of sparse extractions.
Pas?ca et al (2006) alle-833viates pattern sparseness by using infix patterns thatare generalized using classes of distributionally sim-ilar words.
In addition, their method employs clus-tering based semantic similarities to filter newly ex-tracted instances in each iteration of the bootstrap-ping process.
A comparison with our method wouldhave been instructive, but we were unable to imple-ment their method because the original paper con-tains insufficient detail to allow replication.There is a large body of research in the super-vised tradition that does not use explicit pattern rep-resentations ?
kernel based methods (Zelenko etal., 2003; Culotta, 2004; Bunescu and Mooney,2005) and CRF based methods (Culotta et al, 2006).These approaches are all fully supervised, whereasin our work the automatic generation of candi-dates and training data is an integral part of themethod.
An interesting alternative is distant super-vision (Mintz et al, 2009), which trains a classi-fier using an existing database (Freebase) containingthousands of semantic relations, with millions of in-stances.
We believe our method is more general, asdepending on external resources like a database ofsemantic relations limits both the range of seman-tic relations (i.e., Freebase contains only relationsbetween named entities, and none of the relationsin this work) and languages (i.e., no resource com-parable to Freebase exists for Japanese) to whichthe technology can be applied.
Furthermore, it isunclear whether distant supervision can deal withnoisy input such as automatically acquired relationinstances.Finally, inference based methods (Carlson et al,2010; Schoenmackers et al, 2010; Tsuchida et al,2010) are another attempt at relation acquisition thatgoes beyond pattern matching.
Carlson et al (2010)proposed a method based on inductive logic pro-gramming (Quinlan, 1990).
Schoenmackers et al(2010) takes relation instances produced by Tex-tRunner (Banko and Etzioni, 2008) as input and in-duces first-order Horn clauses, and new instances areinfered using a Markov Logic Network (Richardsonand Domingo, 2006; Huynh and Mooney, 2008).Tsuchida et al (2010) generated new relation hy-potheses by substituting words in seed instanceswith distributionally similar words.
The differencebetween these works and ours lies in the treatmentof evidence.
While the above methods learn infer-ence rules to acquire new relation instances from in-dependent information sources scattered across dif-ferent Web pages, our method takes the other optionof working with all the clues and indirect evidence asingle sentence can provide.
In the future, a combi-nation of both approaches may prove beneficial.6 ConclusionWe have proposed a relation acquisition method thatis able to acquire semantic relations from infrequentexpressions by focusing on the evidence provided bysemantic word classes and partial pattern matchinginstead of direct extraction patterns.
We experimen-tally demonstrated the effectiveness of this approachon three relation acquisition tasks, causality, preven-tion and material relations.
In addition we showedour method could acquire a significant number ofrelation instances that are found in extremely infre-quent expressions, the most extreme case of whichare single occurrence patterns, which are beyondthe reach of existing pattern based methods.
We be-lieve this ability is of crucial importance for acquir-ing valuable long tail instances.
In future work wewill investigate whether the current framework canbe extended to acquire inter-sentential relations.ReferencesEugene Agichtein and Luis Gravano.
2000.
Snowball:extracting relations from large plain-text collections.In Proc.
of the fifth ACM conference on Digital li-braries, pages 85?94.Michele Banko and Oren Etzioni.
2008.
The tradeoffsbetween open and traditional relation extraction.
InProc.
of the 46th ACL-08:HLT, pages 28?36.Matthew Berland and Eugene Charniak.
1999.
Find-ing parts in very large corpora.
In Proceedings of the37th Annual Meeting of the Association for Computa-tional Linguistics, pages 57?64, College Park, Mary-land, USA, June.Razvan C. Bunescu and Raymond J. Mooney.
2005.
Ashortest path dependency kernel for relation extrac-tion.
In Proceedings of the Conference on HumanLanguage Technology and Empirical Methods in Nat-ural Language Processing (HLT ?05), pages 724?731.Andrew Carlson, Justin Betteridge, Bryan Kisiel, BurrSettles, Estevam R. Hruschka Jr., and Tom M.Mitchell.
2010.
Toward an architecture for neverend-ing language learning.
In Proc of the 24th AAAI, pages1306?1313.834Aron Culotta, Andrew McCallum, and Jonathan Betz.2006.
Integrating probabilistic extraction models anddata mining to discover relations and patterns in text.In Human Language Technology Conference of theNorth American Chapter of the Association of Com-putational Linguistics (HLT/NAACL), pages 296?303.Aron Culotta.
2004.
Dependency tree kernels for rela-tion extraction.
In In Proceedings of the 42nd AnnualMeeting of the Association for Computational Linguis-tics (ACL-04, pages 423?429.Stijn De Saeger, Kentaro Torisawa, Jun?ichi Kazama,Kow Kuroda, and Masaki Murata.
2009.
Large ScaleRelation Acquisition Using Class Dependent Patterns.In Proc.
of the 9th International Conference on DataMining (ICDM), pages 764?769.Doug Downey, Stefan Schoenmackers, and Oren Etzioni.2007.
Sparse information extraction: Unsupervisedlanguage models to the rescue.
In Proceedings of the45th Annual Meeting of the Association for Computa-tional Linguistics (ACL2007).Oren Etzioni, Michael Cafarella, Doug Downey, StanleyKok, Ana-Maria Popescu, Tal Shaked, Stephen Soder-land, Daniel Weld, and Alexander Yates.
2004.
Web-scale information extraction in KnowItAll.
In Proc.
ofthe 13th international conference on World Wide Web(WWW04), pages 100?110.Zhou GuoDong, Su Jian, Zhang Jie, and Zhang Min.2005.
Exploring various knowledge in relation extrac-tion.
In Proc.
of the 43rd Annual Meeting on Associ-ation for Computational Linguistics, ACL ?05, pages419?444.Marti Hearst.
1992.
Automatic acquisition of hyponymsfrom large text corpora.
In Proc.
of the 14th In-ternational Conference on Computational Linguistics(COLING?92), pages 539?545.Tuyen N. Huynh and Raymond J. Mooney.
2008.Discriminative structure and parameter learning formarkov logic networks.
In Proc.
of the 25th ICML,pages 416?423.Jun?ichi Kazama and Kentaro Torisawa.
2008.
Inducinggazetteers for named entity recognition by large-scaleclustering of dependency relations.
In Proc.
of the46th Annual Meeting of the Association for Compu-tational Linguistics: Human Language Technologies(ACL-08: HLT), pages 407?415.Mamoru Komachi, Taku Kudo, Masashi Shimbo, andYuji Matsumoto.
2008.
Graph-based analysis of se-mantic drift in espresso-like bootstrapping algorithms.In Proc.
of EMNLP?08.
Honolulu, USA, pages 1011?1020.Dekang Lin and Patrick Pantel.
2001.
Dirt - discoveryof inference rules from text.
In Proc.
of the ACMSIGKDD Conference on Knowledge Discovery andData Mining, pages 323?328.Mike Mintz, Steven Bills, Rion Snow, and Daniel Juraf-sky.
2009.
Distant supervision for relation extractionwithout labeled data.
In Proc.
of the Joint Conferenceof the 47th Annual Meeting of the ACL and the 4thInternational Joint Conference on Natural LanguageProcessing of the AFNLP, pages 1003?1011.Marius Pas?ca, Dekang Lin, Jeffrey Bigham, Andrei Lif-chits, and Alpa Jain.
2006.
Names and Similarities onthe Web: Fact Extraction in the Fast Lane.
In Proc.
ofthe COLING-ACL06, pages 809?816.Patrick Pantel and Marco Pennacchiotti.
2006a.Espresso: Leveraging generic patterns for automati-cally harvesting semantic relations.
In Proc.
of the21st International Conference on Computational Lin-guistics and 44th Annual Meeting of the Associa-tion for Computational Linguistics (COLING-ACL-06,pages 113?120.Patrick Pantel and Pennacchiotti Pennacchiotti, Marco.2006b.
Espresso: Leveraging generic patterns for au-tomatically harvesting semantic relations.
In Proc.
ofthe COLING-ACL06, pages 113?120.J.
R. Quinlan.
1990.
Learning logical definitions fromrelations.
Machine Learning, 5(3):239?266.Matthew Richardson and Pedro Domingo.
2006.Markov logic networks.
Machine Learning, 26:107?136.Stefan Schoenmackers, Oren Etzioni, Daniel S. Weld,and Jesse Davis.
2010.
Learning first-order hornclauses from web text.
In Proc.
of EMNLP2010, pages1088?1098.Keiji Shinzato, Tomohide Shibata, Daisuke Kawahara,Chikara Hashimoto, and Sadao Kurohashi.
2008.TSUBAKI: An open search engine infrastructure fordeveloping new information access.
In Proc.
of IJC-NLP, pages 189?196.Kentaro Torisawa, Stijn De Saeger, Jun?ichi Kazama,Asuka Sumida, Daisuke Noguchi, Yasunari Kakizawa,Masaaki Murata, Kow Kuroda, and Ichiro Yamada.2010.
Organizing the web?s information explosion todiscover unknown unknowns.
New Generation Com-puting, 28(3):217?236.Masaaki Tsuchida, Stijn De Saeger, Kentaro Torisawa,Masaki Murata, Jun?ichi Kazama, Kow Kuroda, andHayato Ohwada.
2010.
Large scale similarity-basedrelation expansion.
In Proc of the 4th IUCS, pages140?147.Dmitry Zelenko, Chinatsu Aone, and AnthonyRichardella.
2003.
Kernel methods for relationextraction.
Journal of Machine Learning Research,pages 1083?1106.835
