Tutorials, NAACL-HLT 2013, pages 10?12,Atlanta, Georgia, June 9 2013. c?2013 Association for Computational LinguisticsSemantic Role LabelingMartha Palmer?, Ivan Titov?, Shumin Wu?
?University of Colorado?Saarland UniversityMartha.Palmer@colorado.edutitovian,wushumin@gmail.com1 OverviewThis tutorial will describe semantic role labeling, the assignment of semantic rolesto eventuality participants in an attempt to approximate a semantic representationof an utterance.
The linguistic background and motivation for the definition ofsemantic roles will be presented, as well as the basic approach to semantic roleannotation of large amounts of corpora.
Recent extensions to this approach thatencompass light verb constructions and predicative adjectives will be included,with reference to their impact on English, Arabic, Hindi and Chinese.
Currentproposed extensions such as Abstract Meaning Representations and richer eventrepresentations will also be touched on.Details of machine learning approaches will be provided, beginning with fullysupervised approaches that use the annotated corpora as training material.
Theimportance of syntactic parse information and the contributions of different featurechoices, including tree kernels, will be discussed, as well as the advantages anddisadvantages of particular machine learning algorithms and approaches such asjoint inference.
Appropriate considerations for evaluation will be presented as wellas successful uses of semantic role labeling in NLP applications.We will also cover techniques for exploiting unlabeled corpora and transfer-ring models across languages.
These include methods, which project annotationsacross languages using parallel data, induce representations solely from unlabeledcorpora (unsupervised methods) or exploit a combination of a small amount of hu-man annotation and a large unlabeled corpus (semi-supervised techniques).
Wewill discuss methods based on different machine learning paradigms, includinggenerative Bayesian models, graph-based algorithms and bootstrapping style tech-niques.102 OutlineI.
Introduction, background and annotation?
Motivation ?
who did what to whom?
Linguistic Background?
Basic Annotation approach?
Recent extensions?
Language Specific issues with English, Arabic, Hindi and Chinese?
Semlink ?
Mapping between PropBank, VerbNet and FrameNet.?
The next step ?
Events and Abstract Meaning RepresentationsII.
Supervised Machine Learning for SRL?
Identification and Classification?
Features (tree kernel, English vs. Chinese)?
Choice of ML method and feature combinations (kernel vs feature space)?
Joint Inference?
Impact of Parsing?
Evaluation?
Applications (including multi-lingual)III.
Semi-supervised and Unsupervised Approaches?
Cross-lingual annotation projection methods and direct transfer of SRL mod-els across languages?
Semi-supervised learning methods?
Unsupervised induction?
Adding supervision and linguistic priors to unsupervised methods113 Speaker BiosMartha Palmer1 is a Professor of Linguistics and Computer Science, and a Fel-low of the Institute of Cognitive Science at the University of Colorado.
Her currentresearch is aimed at building domain-independent and language independent tech-niques for semantic interpretation based on linguistically annotated data, such asProposition Banks.
She has been the PI on NSF, NIH and DARPA projects forlinguistic annotation (syntax, semantics and pragmatics) of English, Chinese, Ko-rean, Arabic and Hindi.
She has been a member of the Advisory Committee forthe DARPA TIDES program, Chair of SIGLEX, Chair of SIGHAN, a past Presi-dent of the Association for Computational Linguistics, and is a Co-Editor of JNLEand of LiLT and is on the CL Editorial Board.
She received her Ph.D. in ArtificialIntelligence from the University of Edinburgh in 1985.Ivan Titov2 joined the Saarland University as a junior faculty and head of aresearch group in November 2009, following a postdoc at the University of Illi-nois at Urbana-Champaign.
He received his Ph.D. in Computer Science from theUniversity of Geneva in 2008 and his master?s degree in Applied Mathematicsand Informatics from the St. Petersburg State Polytechnic University (Russia) in2003.
His research interests are in statistical natural language processing (modelsof syntax, semantics and sentiment) and machine learning (structured predictionmethods, latent variable models, Bayesian methods).Shumin Wu is a Computer Science PhD student (advised by Dr. MarthaPalmer) at the University of Colorado.
His current research is aimed at developingand applying semantic mapping (aligning and jointly inferring predicate-argumentstructures between languages) to Chinese dropped-pronoun recovery/alignment,automatic verb class induction, and other applications relevant to machine transla-tion.1http://verbs.colorado.edu/?mpalmer/2http://people.mmci.uni-saarland.de/?titov/12
