Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 41?45,Avignon, France, April 23 - 27 2012. c?2012 Association for Computational LinguisticsA Computer Assisted Speech Transcription SystemAlejandro Revuelta-Mart?
?nez, Luis Rodr?
?guez, Ismael Garc?
?a-VareaComputer Systems DepartmentUniversity of Castilla-La ManchaAlbacete, Spain{Alejandro.Revuelta,Luis.RRuiz,Ismael.Garcia}@uclm.esAbstractCurrent automatic speech transcription sys-tems can achieve a high accuracy althoughthey still make mistakes.
In some scenar-ios, high quality transcriptions are neededand, therefore, fully automatic systems arenot suitable for them.
These high accuracytasks require a human transcriber.
How-ever, we consider that automatic techniquescould improve the transcriber?s efficiency.With this idea we present an interactivespeech recognition system integrated witha word processor in order to assists userswhen transcribing speech.
This system au-tomatically recognizes speech while allow-ing the user to interactively modify the tran-scription.1 IntroductionSpeech has been the main mean of communica-tion for thousands of years and, hence, is the mostnatural human interaction mode.
For this reason,Automatic Speech Recognition (ASR) has beenone of the major research interests within the Nat-ural Language Processing (NLP) community.Although current speech recognition ap-proaches (which are based on statistical learningtheory (Jelinek, 1998)) are speaker independentand achieve high accuracy, ASR systems are notperfect and transcription errors rise drasticallywhen considering large vocabularies, dealingwith noise environments or spontaneous speech.In those tasks (as for example, automatic tran-scription of parliaments proceedings) whereperfect recognition results are required, ASRcan not be fully reliable so far and, a humantranscriber has to check and supervise theautomatically generated transcriptions.In the last years, cooperative systems, wherea human user and an automatic system work to-gether, have gain growing attention.
Here wepresent a system that interactively assists a humantranscriber when using an ASR software.
Theproposed tool is fully embedded into a widelyused and open source word processor and it relieson an ASR system that is proposing suggestions tothe user in the form of practical transcriptions forthe input speech.
The user is allowed to introducecorrections at any moment of the discourse and,each time an amendment is performed, the sys-tem will take it into account in order to propose anew transcription (always preserving the decisionmade by the user, as can be seen in Fig.
1).
Therationale behind this idea is to reduce the humanuser?s effort and increase efficiency.Our proposal?s main contribution is that it car-ries out an interactive ASR process, continuallyproposing new transcriptions that take into ac-count user amendments to increase their useful-ness.
To our knowledge, no current transcriptionpackage provides such an interactive process.2 Theoretical BackgroundComputer Assisted Speech Recognition (CAST)can be addressed by extending the statistical ap-proach to ASR.
Specifically, we have an inputsignal to be transcribed x and the user feedbackin the form of a fully correct transcription pre-fix p (an example of a CAST session is shownin Fig.
1).
From this, the recognition system hasto search for the optimal completion (suffix) s?
as:s?
= argmaxsPr(s | x,p)= argmaxsPr(x | p, s) ?
Pr(s | p) (1)41where, as in traditional ASR, we have an acous-tic model Pr(x | p, s) and a language modelPr(s | p).
The main difference is that, here,part of the correct transcription is available (pre-fix) and we can use this information to improvethe suffix recognition.
This can be achieved byproperly adapting the language model to accountfor the user validated prefix as it is detailed in(Rodr?
?guez et al 2007; Toselli et al 2011).As was commented before, the main goal ofthis approach is to improve the efficiency of thetranscription process by saving user keystrokes.Off-line experiments have shown that this ap-proach can save about 30% of typing effort whencompared to the traditional approach of off-linepost-editing results from an ASR system.3 Prototype DescriptionA fully functional prototype, which implementsthe CAST techniques described in section 2, hasbeen developed.
The main goal is to provide acompletely usable tool.
To this end, we have im-plemented a tool that easily allows for organiz-ing and accessing different transcription projects.Besides, the prototype has been embedded into awidely used office suite.
This way, the transcribeddocument can be properly formatted since all thefeatures provided by a word processor are avail-able during the transcription process.3.1 Implementation IssuesThe system has been implemented following amodular architecture consisting of several compo-nents:?
User interface.
Manages the graphical fea-tures of the prototype user interface.?
Project management: Allows the user todefine and deal with transcription projects.These projects are stored in XML files con-taining parameters such as input files to betranscribed, output documents, etc.?
System controller.
Manages communicationamong all the components.?
OpenOffice integration: This subsystem pro-vides an appropriate integration between theCAST tool and the OpenOffice1 softwaresuite.
The transcriber has, therefore, full ac-cess to a word processor functionality.1www.openoffice.org?
Speech manager: Implements audio play-back and synchronization with the ASR out-comes.?
CAST engine: Provides the interactive ASRsuggestion mechanism.This architecture is oriented to be flexible andportable so that different scenarios, word proces-sor software or ASR engines can be adopted with-out requiring big changes in the current imple-mentation.
Although this initial prototype worksas a standalone application the followed designshould allow for a future ?in the cloud?
tool,where the CAST engine is located in a server andthe user can employ a mobile device to carry outthe transcription process.With the purpose of providing a real-time sys-tem response, CAST is actually performed overa set of word lattices.
A lattice, representing ahuge set of hypotheses for the current utterance,is initially used to parse the user validated prefixand then to search for the best completion (sug-gestion).3.2 System Interface and UsageThe prototype has been designed to be intuitivefor professional speech transcribers and generalusers; we expect most users to quickly get usedto the system without any previous experience orexternal assistance.The prototype features and operation mode aredescribed in the following items:?
The initial screen (Fig.
2) guides the user onhow to address a transcription project.
Here,the transcriber can select one of the threemain tasks that have to be performed to ob-tain the final result.?
In the project management screen (Fig.
3),the user can interact with the current projectsor create a new one.
A project is a set ofinput audio files to be transcribed along withthe partial transcription achieved and someother related parameters.?
Once the current project has been selected, atranscription session is started (Fig.
4).
Dur-ing this session, the application looks like astandard OpenOffice word processor incor-porating CAST features.
Specifically, theuser can perform the following operations:42utteranceITER-0 prefix ( )ITER-1suffix (Nine extra soul are planned half beam discovered these years)validated (Nine)correction (extrasolar)prefix (Nine extrasolar)ITER-2suffix (planets have been discovered these years)validated (planets have been discovered)correction (this)prefix (Nine extrasolar planets have been discovered this)FINALsuffix (year)validated (#)prefix (Nine extrasolar planets have been discovered this year)Figure 1: Example of a CAST session.
In each iteration, the system suggests a suffix based on the input utteranceand the previous prefix.
After this, the user can validate part of the suggestion and type a correction to generatea new prefix that can be used in the next iteration.
This process is iterated until the full utterance is transcribed.The user can move between audio segmentsby pressing the ?fast forward?
and ?rewind?buttons.
Once the a segment to be tran-scribed has been chosen, the ?play?
buttonstarts the audio replay and transcription.
Thesystem produces the text in synchrony withthe audio so that the user can check in ?realtime?
the proposed transcription.
As soon asa mistake is produced, the transcriber can usethe ?pause?
button to interrupt the process.Then, the error is corrected and by pressing?play?
again the process is continued.
Atthis point, the CAST engine will use the useramendment to improve the rest of the tran-scription.?
When all the segments have been tran-scribed, the final task in the initial screen al-lows the user to open the OpenOffice?s PDFexport dialog to generate the final document.A video, showing the prototype operationmode, can be found on the following website:www.youtube.com/watch?v=vc6bQCtYVR4.4 Conclusions and Future WorkIn this paper we have presented a CAST systemwhich has been fully implemented and integratedinto the OpenOffice word processing software.The implemented techniques have been tested of-fline and the prototype has been presented to a re-duced number of real users.Preliminary results suggest that the systemcould be useful for transcribers when high qual-ity transcriptions are needed.
It is expected tosave effort, increase efficiency and allow inexperi-enced users to take advantage of ASR systems allalong the transcription process.
However, theseresults should be corroborated by performing aformal usability evaluation.Currently, we are in the process of carrying outa formal usability evaluation with real users thathas been designed following the ISO/IEC 9126-4(2004) standard according to the efficiency, effec-tiveness and satisfaction characteristics.As future work, it will be interesting to considerconcurrent collaborative work at both, project andtranscription levels.
Other promising line is toconsider a multimodal user interface in order toallow users to control the playback and transcrip-tion features using their own speech.
This hasbeen explored in the literature (Rodr?
?guez et al2010) and would allow the system to be used indevices with constrained interfaces such as mo-bile phones or tablet PCs.AcknowledgmentsWork supported by the EC (ERDF/ESF) andthe Spanish government under the MIPRCV?Consolider Ingenio 2010?
program (CSD2007-00018), and the Spanish Junta de Comunidadesde Castilla-La Mancha regional government un-der projects PBI08-0210-7127 and PPII11-0309-6935.43Figure 2: Main window prototype.
The three stages of a transcription project are shown.Figure 3: Screenshot of the project management window showing a loaded project.
A project consists of severalaudio segments, each of them is stored in a file so that the user can easily add or remove files when needed.
Inthis screen the user can choose the current working segments.Figure 4: Screenshot of a transcription session.
This shows the process of transcribing one audio segment.
In thisfigure, all the text but the last incomplete sentence has already been transcribed and validated.
The last partialsentence, shown in italics, is being produced by the ASR system while the transcriber listen to the audio.
Assoon as an error is detected the user momentarily interrupts the process to correct the mistake.
Then, the systemwill continue transcribing the audio according to the new user feedback (prefix).44ReferencesISO/IEC 9126-4.
2004.
Software engineering ?Product quality ?
Part 4: Quality in use metrics.F.
Jelinek.
1998.
Statistical Methods for SpeechRecognition.
The MIT Press, Cambridge, Mas-sachusetts, USA.Luis Rodr?
?guez, Francisco Casacuberta, and EnriqueVidal.
2007.
Computer assisted transcription ofspeech.
In Proceedings of the 3rd Iberian confer-ence on Pattern Recognition and Image Analysis,Part I, IbPRIA ?07, pages 241?248, Berlin, Heidel-berg.
Springer-Verlag.Luis Rodr?
?guez, Ismael Garc?
?a-Varea, and Enrique Vi-dal.
2010.
Multi-modal computer assisted speechtranscription.
In Proceedings of the 12th Interna-tional Conference on Multimodal Interfaces and the7th International Workshop on Machine Learningfor Multimodal Interaction, ICMI-MLMI.A.H.
Toselli, E. Vidal, and F. Casacuberta.
2011.
Mul-timodal Interactive Pattern Recognition and Appli-cations.
Springer.45
