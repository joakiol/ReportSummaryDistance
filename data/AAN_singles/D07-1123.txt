Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL 2007, pp.
1134?1138,Prague, June 2007. c?2007 Association for Computational LinguisticsIncremental Dependency Parsing Using Online LearningRichard Johansson and Pierre NuguesDepartment of Computer Science, Lund University, Sweden{richard, pierre}@cs.lth.seAbstractWe describe an incremental parser thatwas trained to minimize cost over sen-tences rather than over individual parsing ac-tions.
This is an attempt to use the advan-tages of the two top-scoring systems in theCoNLL-X shared task.In the evaluation, we present the perfor-mance of the parser in the Multilingual task,as well as an evaluation of the contributionof bidirectional parsing and beam search tothe parsing performance.1 IntroductionThe two best-performing systems in the CoNLL-Xshared task (Buchholz and Marsi, 2006) can be clas-sified along two lines depending on the method theyused to train the parsing models.
Although theparsers are quite different, their creators could re-port near-tie scores.
The approach of the top sys-tem (McDonald et al, 2006) was to fit the modelto minimize cost over sentences, while the second-best system (Nivre et al, 2006) trained the model tomaximize performance over individual decisions inan incremental algorithm.
This difference is a nat-ural consequence of their respective parsing strate-gies: CKY-style maximization of link score and in-cremental parsing.In this paper, we describe an attempt to unify thetwo approaches: an incremental parsing strategy thatis trained to maximize performance over sentencesrather than over individual parsing actions.2 Parsing Method2.1 Nivre?s ParserWe used Nivre?s algorithm (Nivre et al, 2006),which is a variant of the shift?reduce parser.
Likethe regular shift?reduce, it uses a stack S and a listof input words W , and builds the parse tree incre-mentally using a set of parsing actions (see Table 1).It can be shown that Nivre?s parser creates projec-tive and acyclic graphs and that every projective de-pendency graph can be produced by a sequence ofparser actions.
In addition, the worst-case number ofactions is linear with respect to the number of wordsin the sentence.2.2 Handling Nonprojective Parse TreesWhile the parsing algorithm produces projectivetrees only, nonprojective arcs can be handled usinga preprocessing step before training the model and apostprocessing step after parsing the sentences.The projectivization algorithm (Nivre and Nils-son, 2005) iteratively moves each nonprojective arcupward in the tree until the whole tree is projective.To be able to recover the nonprojective arcs afterparsing, the projectivization operation replaces thelabels of the arcs it modifies with traces indicatingwhich links should be moved and where attach to at-tach them (the ?Head+Path?
encoding).
The modelis trained with these new labels that makes it pos-sible to carry out the reverse operation and producenonprojective structures.2.3 Bidirectional ParsingShift-reduce is by construction a directional parser,typically applied from left to right.
To make bet-ter use of the training set, we applied the algorithmin both directions as Johansson and Nugues (2006)and Sagae and Lavie (2006) for all languages exceptCatalan and Hungarian.
This, we believe, also hasthe advantage of making the parser less sensitive towhether the language is head-initial or head-final.We trained the model on projectivized graphsfrom left to right and right to left and used a vot-ing strategy based on link scores.
Each link was as-signed a score (simply by using the score of the laor ra actions for each link).
To resolve the conflicts1134Table 1: Nivre?s parser transitions where W is the initial word list; I , the current input word list; A, thegraph of dependencies; and S, the stack.
(n?, n) denotes a dependency relations between n?
and n, where n?is the head and n the dependent.Actions Parser actions ConditionsInitialize ?nil, W, ?
?Terminate ?S, nil, A?Left-arc ?n|S, n?|I,A?
?
?S, n?|I, A ?
{(n?, n)}?
??n??(n?
?, n) ?
ARight-arc ?n|S, n?|I,A?
?
?n?|n|S, I,A ?
{(n, n?)}?
??n??(n?
?, n?)
?
AReduce ?n|S, I,A?
?
?S, I, A?
?n?
(n?, n) ?
AShift ?S, n|I, A?
?
?n|S, I,A?between the two parses in a manner that makes thetree projective, single-head, rooted, and cycle-free,we applied the Eisner algorithm (Eisner, 1996).2.4 Beam SearchAs in our previous parser (Johansson and Nugues,2006), we used a beam-search extension to Nivre?soriginal algorithm (which is greedy in its originalformulation).
Each parsing action was assigned ascore, and the beam search allows us to find a bet-ter overall score of the sequence of actions.
Inthis work, we used a beam width of 8 for Catalan,Chinese, Czech, and English and 16 for the otherlanguages.3 Learning Method3.1 OverviewWe model the parsing problem for a sentence x asfinding the parse y?
= arg maxy F (x, y) that max-imizes a discriminant function F .
In this work, weconsider linear discriminants of the following form:F (x, y) = w ??
(x, y)where ?
(x, y) is a numeric feature representationof the pair (x, y) and w a vector of feature weights.Learning F in this case comes down to assigninggood weights in the vector w.Machine learning research for similar prob-lems have generally used margin-based formula-tions.
These include global batch methods suchas SVMstruct (Tsochantaridis et al, 2005) as wellas online methods such as the Online Passive-Aggressive Algorithm (OPA) (Crammer et al,2006).
Although the batch methods are formulatedvery elegantly, they do not seem to scale well tothe large training sets prevalent in NLP contexts ?we briefly considered using SVMstruct but train-ing was too time-consuming.
The online methodson the other hand, although less theoretically ap-pealing, can handle realistically sized data sets andhave successfully been applied in dependency pars-ing (McDonald et al, 2006).
Because of this, weused the OPA algorithm throughout this work.3.2 ImplementationIn the online learning framework, the weight vectoris constructed incrementally.
At each step, it com-putes an update to the weight vector based on thecurrent example.
The resulting weight vector is fre-quently overfit to the last examples.
One way toreduce overfitting is to use the average of all suc-cessive weight vectors as the result of the training(Freund and Schapire, 1999).Algorithm 1 shows the algorithm.
It uses an?aggressiveness?
parameter C to reduce overfitting,analogous to the C parameter in SVMs.
The algo-rithm also needs a cost function ?, which describeshow much a parse tree deviates from the gold stan-dard.
In this work, we defined ?
as the sum of linkcosts, where the link cost was 0 for a correct depen-dency link with a correct label, 0.5 for a correct linkwith an incorrect label, and 1 for an incorrect link.The number of iterations was 5 for all languages.For a sentence x and a parse tree y, we definedthe feature representation by finding the sequence?
?S1, I1?
, a1?
, ?
?S2, I2?
, a2?
.
.
.
of states and theircorresponding actions, and creating a feature vectorfor each state/action pair.
The discriminant functionwas thus written?
(x, y) ?w =?i?
(?Si, Ii?
, ai) ?wwhere ?
is a feature function that assigns a feature1135Algorithm 1 The Online PA Algorithminput Training set T = {(xt, yt)}Tt=1Number of iterations NRegularization parameter CCost function ?Initialize w to zerosrepeat N timesfor (xt, yt) in Tlet y?t = arg maxy F (xt, y) +??
(yt, y)let ?t = min(C, F (xt,y?t)?F (xt,yt)+??(yt,y?t)??(x,yt)??
(x,y?t)?2)w ?
w + ?t(?
(x, yt)??
(x, y?t))return waveragevector to a state ?Si, Ii?
and the action ai taken inthat state.
Table 2 shows the feature sets used in?
for all languages.
In principle, a kernel couldalso be used, but that would degrade performanceseverely.
Instead, we formed a new vector by com-bining features pairwisely ?
this is equivalent to us-ing a quadratic kernel.Since the history-based feature set used in theparsing algorithm makes it impossible to use inde-pendence to factorize the scoring function, an ex-act search to find the best-scoring action sequence(arg maxy in Algorithm 1) is not possible.
How-ever, the beam search allows us to find a reasonableapproximation.4 ResultsTable 3 shows the results of our system in the Mul-tilingual task.4.1 Compared to SVM-based Local ClassifiersWe compared the performance of the parser witha parser based on local SVM classifiers (Johanssonand Nugues, 2006).
Table 4 shows the performanceof both parsers on the Basque test set.
We see thatwhat is gained by using a global method such asOPA is lost by sacrificing the excellent classifica-tion performance of the SVM.
Possibly, better per-formance could be achieved by using a large-marginbatch method such as SVMstruct.Table 2: Feature sets.ar ca cs el en eu hu it tr zhFine POS top ?
?
?
?
?
?
?
?
?
?Fine POS top-1 ?
?
?
?
?
?
?Fine POS list ?
?
?
?
?
?
?
?
?
?Fine POS list-1 ?
?
?
?
?
?
?
?
?
?Fine POS list+1 ?
?
?
?
?
?
?
?
?
?Fine POS list+2 ?
?
?
?
?
?
?
?
?
?Fine POS list+3 ?
?
?
?
?
?POS top ?
?
?
?
?
?
?
?
?
?POS top-1 ?POS list ?
?
?
?
?
?
?
?
?
?POS list-1 ?
?
?
?
?
?POS list+1 ?
?
?
?
?
?
?
?
?
?POS list+2 ?
?
?
?
?
?
?
?POS list+3 ?
?
?
?
?
?
?
?Features top ?
?
?
?
?
?
?
?Features list ?
?
?
?
?
?
?
?Features list-1 ?
?
?
?
?Features list+1 ?
?
?
?
?
?
?Features list+2 ?
?
?
?
?Word top ?
?
?
?
?
?
?
?
?Word top-1 ?
?Word list ?
?
?
?
?
?
?
?
?
?Word list-1 ?
?
?
?
?
?Word list+1 ?
?
?
?Lemma top ?
?
?
?
?
?Lemma list ?
?
?
?
?Lemma list-1 ?
?Relation top ?
?Relation top left ?
?
?
?
?Relation top right ?
?
?
?
?Relation list right ?Word top left ?Word top right ?Word list left ?POS top left ?
?POS top right ?
?
?POS list left ?
?
?
?
?
?
?
?Features top right ?Features first left ?
?Table 3: Summary of results.Languages Unlabeled LabeledArabic 80.91 71.76Basque 80.41 75.08Catalan 88.34 83.33Chinese 81.30 76.30Czech 77.39 70.98English 81.43 80.29Greek 79.58 72.77Hungarian 75.53 71.31Italian 81.55 77.55Turkish 84.80 78.46Average result 81.12 75.78Table 4: Accuracy by learning method.Learning Method AccuracyOPA 75.08SVM 75.5311364.2 Beam WidthTo investigate the influence of the beam width on theperformance, we measured the accuracy of a left-to-right parser on a development set for Basque (15%of the training data) as a function of the width.
Ta-ble 5 shows the result.
We see clearly that wideningthe beam considerably improves the figures, espe-cially in the lower ranges.Table 5: Accuracy by beam width.Width Accuracy2 72.014 74.186 75.058 75.3012 75.494.3 DirectionWe also investigated the contribution of the bidirec-tional parsing.
Table 6 shows the result of this exper-iment on the Basque development set (the same 15%as in 4.2).
The beam width was 2 in this experiment.Table 6: Accuracy by parsing direction.Direction AccuracyLeft to right 72.01Right to left 71.02Bidirectional 74.48Time did not allow a full-scale experiment, butfor all languages except Catalan and Hungarian, thebidirectional parsing method outperformed the uni-directional methods when trained on a 20,000-wordsubset.
However, the gain of using bidirectionalparsing may be more obvious when the treebank issmall.
For all languages except Czech, left-to-rightoutperformed right-to-left parsing.5 DiscussionThe paper describes an incremental parser that wetrained to minimize the cost over sentences, ratherthan over parsing actions as is usually done.
Itwas trained using the Online Passive-Aggressivemethod, a cost-sensitive online margin-based learn-ing method, and shows reasonable performance andreceived above-average scores for most languages.The performance of the parser (relative the otherteams) was best for Basque and Turkish, which weretwo of the smallest treebanks.
Since we found thatthe optimal number of iterations was 5 for Basque(the smallest treebank), we used this number for alllanguages since we did not have time to investigatethis parameter for the other languages.
This mayhave had a detrimental effect for some languages.We think that some of the figures might be squeezedslightly higher by optimizing learning parametersand feature sets.This work shows that it was possible to combineapproaches used by Nivre?s and McDonald?s parsersin a single system.
While the parser is outperformedby a system based on local classifiers, we still hopethat the parsing and training combination describedhere opens new ways in parser design and eventuallyleads to the improvement of parsing performance.AcknowledgementsThis work was made possible because of the anno-tated corpora that were kindly provided to us: (Hajic?et al, 2004; Aduriz et al, 2003; Mart?
et al, 2007;Chen et al, 2003; B?hmov?
et al, 2003; Marcus etal., 1993; Johansson and Nugues, 2007; Prokopidiset al, 2005; Csendes et al, 2005; Montemagni et al,2003; Oflazer et al, 2003)ReferencesA.
Abeill?, editor.
2003.
Treebanks: Building and UsingParsed Corpora.
Kluwer.I.
Aduriz, M. J. Aranzabe, J. M. Arriola, A. Atutxa,A.
Diaz de Ilarraza, A. Garmendia, and M. Oronoz.2003.
Construction of a Basque dependency treebank.In Proc.
of the 2nd Workshop on Treebanks and Lin-guistic Theories (TLT), pages 201?204.A.
B?hmov?, J.
Hajic?, E.
Hajic?ov?, and B. Hladk?.
2003.The PDT: a 3-level annotation scenario.
In Abeill?
(Abeill?, 2003), chapter 7, pages 103?127.S.
Buchholz and E. Marsi.
2006.
CoNLL-X shared taskon multilingual dependency parsing.
In CoNLL-X.K.
Chen, C. Luo, M. Chang, F. Chen, C. Chen, C. Huang,and Z. Gao.
2003.
Sinica treebank: Design criteria,representational issues and implementation.
In Abeill?
(Abeill?, 2003), chapter 13, pages 231?248.1137K.
Crammer, O. Dekel, J. Keshet, S. Shalev-Schwartz,and Y.
Singer.
2006.
Online passive-aggressive algo-rithms.
JMLR, 2006(7):551?585.D.
Csendes, J. Csirik, T. Gyim?thy, and A. Kocsor.
2005.The Szeged Treebank.
Springer.J.
Eisner.
1996.
Three new probabilistic models for de-pendency parsing: An exploration.
In Proceedings ofICCL.Y.
Freund and R. E. Schapire.
1999.
Large margin clas-sification using the perceptron algorithm.
MachineLearning, 37(3):277?296.J.
Hajic?, O.
Smr?, P. Zem?nek, J.
?naidauf, and E. Be?ka.2004.
Prague Arabic dependency treebank: Develop-ment in data and tools.
In Proc.
of the NEMLAR In-tern.
Conf.
on Arabic Language Resources and Tools,pages 110?117.R.
Johansson and P. Nugues.
2006.
Investigating multi-lingual dependency parsing.
In CoNLL-X.R.
Johansson and P. Nugues.
2007.
Extendedconstituent-to-dependency conversion for English.
InProc.
of the 16th Nordic Conference on ComputationalLinguistics (NODALIDA).M.
Marcus, B. Santorini, and M. Marcinkiewicz.
1993.Building a large annotated corpus of English: the PennTreebank.
Computational Linguistics, 19(2):313?330.M.
A.
Mart?, M.
Taul?, L. M?rquez, and M. Bertran.2007.
CESS-ECE: A multilingual and multilevelannotated corpus.
Available for download from:http://www.lsi.upc.edu/?mbertran/cess-ece/.R.
McDonald, K. Lerman, and F. Pereira.
2006.
Multi-lingual dependency parsing with a two-stage discrimi-native parser.
In CoNLL-X.S.
Montemagni, F. Barsotti, M. Battista, N. Calzolari,O.
Corazzari, A. Lenci, A. Zampolli, F. Fanciulli,M.
Massetani, R. Raffaelli, R. Basili, M. T. Pazienza,D.
Saracino, F. Zanzotto, N. Nana, F. Pianesi, andR.
Delmonte.
2003.
Building the Italian Syntactic-Semantic Treebank.
In Abeill?
(Abeill?, 2003), chap-ter 11, pages 189?210.J.
Nivre and J. Nilsson.
2005.
Pseudo-projective depen-dency parsing.
In Proceedings of ACL-05.J.
Nivre, J.
Hall, J. Nilsson, G. Eryig?it, and S. Marinov.2006.
Labeled pseudo-projective dependency parsingwith support vector machines.
In CoNLL-X.K.
Oflazer, B.
Say, D. Zeynep Hakkani-T?r, and G. T?r.2003.
Building a Turkish treebank.
In Abeill?
(Abeill?, 2003), chapter 15, pages 261?277.P.
Prokopidis, E. Desypri, M. Koutsombogera, H. Papa-georgiou, and S. Piperidis.
2005.
Theoretical andpractical issues in the construction of a Greek depen-dency treebank.
In Proc.
of the 4th Workshop on Tree-banks and Linguistic Theories (TLT), pages 149?160.K.
Sagae and A. Lavie.
2006.
Parser combination byreparsing.
In Proceedings of the HLT-NAACL.I.
Tsochantaridis, T. Joachims, T. Hofmann, and Y. Al-tun.
2005.
Large margin methods for structured andinterdependent output variables.
JMLR, 6:1453?1484.1138
