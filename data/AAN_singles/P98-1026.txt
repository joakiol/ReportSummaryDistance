Separating Surface Order and Syntactic Relationsin a Dependency GrammarNorber t  BrSkerUniversitiit Stut tgartAzenbergstr.
12D-70174 StuttgartNOBI~IMS.
UNI-STUTTGART.
DEAbst rac tThis paper proposes decoupling the dependencytree from word order, such that surface orderingis not determined by traversing the dependencytree.
We develop the notion of a word order do-main structure, which is linked but structurallydissimilar to the syntactic dependency tree.
Theproposal results in a lexicalized, declarative, andformally precise description of word order; fea-tures which lack previous proposals for depen-dency grammars.
Contrary to other lexicalizedapproaches to word order, our proposal does notrequire lexical ambiguities for ordering alterna-tives.1 In t roduct ionRecently, the concept of valency has gained con-siderable attention.
Not only do all linguis-tic theories refer to some reformulation of thetraditional notion of valency (in the form of 0-grid, subcategorization list, argument list, or ex-tended domain of locality); there is a growingnumber of parsers based on binary relations be-tween words (Eisner, 1997; Maruyama, 1990).Given this interest in the valency concept,and the fact that word order is one of themain difference between phrase-structure basedapproaches (henceforth PSG) and dependencygrammar (DG), it is valid to ask whether DGcan capture word order phenomena without re-course to phrasal nodes, traces, slashed cate-gories, etc.
A very early result on the weakgenerative quivalence ofcontext-free grammarsand DGs suggested that DGs are incapable ofdescribing surface word order (Gaifman, 1965).This result has recently been critizised to applyonly to impoverished DGs which do not properlyrepresent formally the expressivity of contempo-rary DG variants (Neuhaus & Br6ker, 1997).Our position will be that dependency re-lations are motivated semantically (Tesni~re,1959), and need not be projective (i.e., maycross if projected onto the surface ordering).
Weargue for so-called word order domains, consist-ing of partially ordered sets of words and associ-ated with nodes in the dependency tree.
Theseorder domains constitute a tree defined by set in-clusion, and surface word order is determined bytraversing this tree.
A syntactic analysis there-for consists of two linked, but dissimilar trees.Sec.
2 will briefly review approaches to wordorder in DG.
In Sec.
3, word order domains willbe defined, and Sec.
4 introduces a modal logicto describe dependency structures.
Sec.
5 ap-plies our approach to the German clause andSec.
6 relates it to some PSG approaches.2 Word Order  in DGA very brief characterization of DG is thatit recognizes only lexical, not phrasal nodes,which are linked by directed, typed, binary rela-tions to form a dependency tree (Tesni~re, 1959;Hudson, 1993).
The following overview of DGflavors shows that various mechanisms (globalrules, general graphs, procedural means) aregenerally employed to lift the limitation of pro-jectivity and discusses some shortcomings ofthese proposals.Funct iona l  Generat ive Descr ipt ion  (Sgallet al, 1986) assumes a language-independentunderlying order, which is represented as a pro-jective dependency tree.
This abstract represen-tation of the sentence is mapped via orderingrules to the concrete surface realization.
Re-cently, Kruijff (1997) has given a categorial-style formulation of these ordering rules.
Heassumes associative categorial operators, per-muting the arguments to yield the surface or-dering.
One difference to our proposal is that174we argue for a representational account of wordorder (based on valid structures representingword order), eschewing the non-determinism in-troduced by unary operators; the second differ-ence is the avoidance of an underlying structure~which stratifies the theory and makes incremen-tal processing difficult.Mean ing-Text  Theory  (Melc'fik, 1988) as-sumes seven strata of representation.
The rulesmapping fi'om the unordered ependency treesof surface-syntactic representations onto the an-notated lexeme sequences of deep-morphologicalrepresentations include global ordering ruleswhich allow discontinuities.
These rules havenot yet been formally specified (Melc'~tk &Pertsov, 1987p.1870.Word  Grammar  (WG, Hudson (1990)) isbased on general graphs instead of trees.
Theordering of two linked words is specified togetherwith their dependency relation, as in the propo-sition "object of verb follows it".
Extrac-tion of, e.g., objects is analyzed by establish-ing an additional dependency called visitorbetween the verb and the extractee, which re-quires the reverse order, as in "v i s i to r  ofverb precedes it".
This results in inconsis-tencies, since an extracted object must followthe verb (being its ob ject )  and at the same timeprecede it (being its v i s i to r ) .
The approachcompromises the semantic motivation of depen-dencies by adding purely order-induced epen-dencies.
WG is similar to our proposal in that italso distinguishes a propositional meta languagedescribing the graph-based analysis structures.Dependency  Unif ication Grammar(DUG, Hellwig (1986)) defines a tree-likedata structure for the representation f syntac-tic analyses.
'Using morphosyntactic featureswith special interpretations, a word definesabstract positions into which modifiers aremapped.
Partial orderings and even discon-tinuities can thus be described by allowing amodifier to occupy a position defined by sometransitive head.
The approach requires that theparser interpretes several features pecially, andit cannot restrict the scope of discontinuities.Slot Grammar  (McCord, 1990) employs anumber of rule types, some of which are ex-clusively concerned with precedence.
So-calledhead/slot and slot/slot ordering rules describethe precedence in projective trees, referring toarbitrary predicates over head and modifiers.Extractions (i.e., discontinuities) are merelyhandled by a mechanism built into the parser.3 Word  Order  DomainsSummarizing the previous discussion, we requirethe following of a word order description for DG:?
not to compromise the semantic motivationof dependencies,?
to be able to restrict discontinuities to cer-tain constructions and delimit their scope,?
to be lexicalized without requiring lexicalambiguities for the representation f order-ing alternatives,?
to be declarative (i.e., independent of ananalysis procedure), and?
to be formally precise and consistent.The subsequent definition of an order domainstructure and its linking to the dependency treesatisify these requirements.3.1 The  Order  Domain  S t ructureA word order domain is a set of words, general-izing the notion of positions in DUG.
The cardi-nality of an order domain may be restricted toat most one element, at least one element, or -by conjunction - to exactly one element.
Eachword is associated with a sequence of order do-mains, one of which must contain the word itself,and each of these domains may require that itselements have certain features.
Order domainscan be partially ordered based on set inclusion:If an order domain d contains word w (whichis not associated with d), every word w ~ con-tained in a domain d ~ associated with w is alsocontained in d; therefor, d~ C d for each d ~ asso-ciated with w. This partial ordering induces atree on order domains, which we call the orderdomain structure.Take the example of German "Den Mann hatder Junge gesehen" ("the manAGe - has - theboyNoM - seen").
Its dependency tree is shownin Fig.l, with word order domains indicatedby dashed circles.
The finite verb, "hat", de-fines a sequence of domains, <dl, d2, d3>, whichroughly correspond to the topological fields inthe German main clause.
The nouns "Mann"175' ,, sub j_~.~_~.
", :d3',,' 'C.
"derJunge; '.ge~ehen.,,,, : .den Mann-., " ' .
. "
'Figure 1: Dependency Tree and Order Domainsfor "Den Mann hat der Junge gesehen"dld,4 hat d 5 d 6Mann Junge gesehenFigure 2: Order Domain Structure for "DenMann hat der Junge gesehen"aud "Junge" and the participle "gesehen" eachdefine one order domain (d4,cl5,d6, resp.).
Setinclusion gives rise to the domain structure inFig.2, where the individual words are attachedby dashed lines to their including domains (dland d4 collapse, being identical).
13.2 Sur face  Order ingHow is the surface order derived from an or-der domain structure?
First of all, the orderingof domains is inherited by their respective le-ments, i.e., "Mann" precedes (any element of)d2, '!hat" follows (any element of) dl, etc.Ordering within a domain, e.g., of "hat" andd6, or d5 and d6, is based on precedence pred-icates (adapting the precedence predicates ofWG).
There are two different ypes, one order-ing a word w.r.t, any other element of the do-main it is associated with (e.g., "hat" w.r.t, d6),and another ordering two modifiers, referring tothe dependency relations they occupy (d5 andd6, referring to subj and vpart) .
A verb like"hat" introduces two precedence predicates, re-quiring other words to follow itself and the par-ticiple to follow subject and object, resp.
: 2"hat" ~ (<.
A (vpart) >{subj,obj})~Note that in this case, we have not a single rootedtree, but rather an ordered sequence of trees (by virtueof ordering dl, d2, and d3) as domain structure.
In gen-eral, we assume the sentence period to govern the finiteverb and to introduce a single domain for the completesentence.2For details of the notation, please refer to Sec.
4.Informally, the first conjunct is satisfied byany domain in which no word precedes "hat",and the second conjunct is satisfied by any do-main in which no subject or object follows aparticiple.
The domain structure in Fig.2 satis-fies these restrictions ince nothing follows theparticiple, and because "den Mann" is not an el-ement of d2, which contains "hat".
This is an im-portant interaction of order domains and prece-dence predicates: Order domains define scopesfor precedence predicates.
In this way, we takeinto account that dependency trees are flatterthan PS-based ones 3 and avoid the formal in-consistencies noted above for WG.3.3 L inking Domain  Structure andDependency  TreeOrder domains easily extend to discontinuousdependencies.
Consider the non-projective treein Fig.1.
Assuming that the finite verb gov-erns the participle, no projective dependencybetween the object "den Mann" and the partici-ple "gesehen" can be established.
We allow non-projectivity by loosening the linking between de-pendency tree and domain structure: A modi-fier (e.g., "Mann") may not only be inserted intoa domain associated with its direct head ("gese-hen"), but also into a domain of a transitive head("hat"), which we will call the positional head.The possibility of inserting a word into a do-main of some trausitive head raises the ques-tions of how to require contiguity (as neededin most cases), and how to limit the distancebetween the governor and the modifier in thecase of discontinuity.
From a descriptive view-point, the syntactic onstruction is often cited todetermine the possibility and scope of disconti-nuities (Bhatt, 1990; Matthews, 1981).
In PS-based accounts, the construction is representedby phrasal categories, and extraction is lim-ited by bounding nodes (e.g., Haegeman (1994),Becker et al (1991)).
In dependency-based ac-counts, the construction is represented by thedependency relation, which is typed or labelledto indicate constructional distinctions which areconfigurationally defined in PSG.
Given this cor-respondence, it is natural to employ dependen-cies in the description of discontinuities as fol-3Note that each phrasal level in PS-based trees definesa scope for linear precedence rules, which only apply tosister nodes.176lows: For each modifier of a certain head, a setof dependency t pes is defined which may linkthe direct head and the positional head of themodifier ("gesehen" and "hat", resp.).
If this setis empty, both heads are identical and a con-tiguous attachment results.
The impossibility ofextraction from, e.g., a finite verb phrase mayfollow from the fact that the dependency embed-ding finite verbs, propo, may not appear on anypath between a direct and a positional head.
44 The  Descr ip t ion  LanguageThis section sketches a logical language describ-ing the dependency structure.
It is based onmodal ogic and owes much to work of Blackburn(1994).
As he argues, standard Kripke modelscan be regarded as directed graphs with nodeannotations.
We will use this interpretation torepresent dependency structures.
Dependenciesand the mapping from dependency tree to orderdomain structure are described by modal opera-tors, while simple properties such as word class,features, and cardinality of order domains aredescribed by modal propositions.4.1 Model  S t ructuresIn the following, we assume a set of words, l/Y,ordered by a precedence r lation, -<, a set ofdependency t pes, T), a set of atomic featurevalues .4, and a set of word classes, C. Wedefine a family of dependency relations Rd CW ?
~42, d E :D and for convenience abbreviatethe union UdET~ Rd as R:D.Def: A dependency tree is a tuple(W, Wr, R~, VA, Vc), where R~ forms a tree overVP rooted in Wr, VA : V~ ~ 2 A maps words tosets of features, and V?
: 1/~ ~ C maps words toword classes.Def: An order domain (over W) m is a set ofwords from ~) where VWl,W2,W3 E VV : (wl -<w2-<w3Awl EmAw3 Era) ~ w2 E m.Def: An order domain structure (over W) f14is a set of order domains where Vm, m ~ E .
?4 :mMm ~ = OVm C m'Vm ~ C m.4One review pointed out that some verbs may allowextractions, i.e., that this restriction is lexical, not uni-versal.
This fact can easily be accomodated because thepossibility of discontinuity (and the dependency t pesacross which the modifier may be extracted) is describedin the lexical entry of the verb.
In fact, a universal re-striction could not even be stated because the treatmentis completely lexicalized.Def: A dependency structure T is atuple (VV, Wr, R~, VA, Vc, .A4, VM > where(I,V, wr, Rz~, VA, VC> is a dependency tree, A4is an order domain structure over ~V, andVAa : V~ ~ .All n maps words to order domainsequences.Additionally, we require for a dependencystructure four more conditions: (1) Each word wis contained in exactly one of the domains fromV~(w) ,  (2) all domains in V~(w)  are pairwisedisjoint, (3) each word (except w~) is containedin at least two domains, one of which is associ-ated with a (transitive) head, and (4) the (par-tial) ordering of domains (as described by VM)is consistent with the precedence of the wordscontained in the domains (see (Brhker, 1997) formore details).4.2 The Language ?
:~Fig.3 defines the logical language /:~ used todescribe dependency structures.
Although theyhave been presented ifferently, they can eas-ily be rewritten as (multimodal) Kripke models:The dependency relation Rd is represented asmodality (d> and the mapping from a word toits ith order domain as modality o~.5 All otherformulae denote properties of nodes, and can beformulated as unary predicates - most evidentfor word class and feature assignment.
For theprecedence predicates <.
and <~, there are in-verses >.
and >~.
For presentation, the relationplaces C 142 x 142 has been introduced, whichholds between two words iff the first argumentis the positional head of the second argument.A more elaborate definition of dependencystructures and ?~ defines two more dimensions,a feature graph mapped off the dependency treemuch like the proposal of Blackburn (1994), anda conceptual representation based on termino-logical logic, linking content words with refer-ence objects and dependencies with conceptualroles.5 The German ClauseTraditionally, the German main clause is de-scribed using three topological fields; the ini-tial and middle fields are separated by the fi-nite (auxiliary) verb, and the middle and the5The modality O~ can be viewed as an abbreviationof o~ O~,  composed of a mapping from a word to its ithorder domain and from that domain to all its elements.177Syntax (valid formulae) Semantics (satisfaction relation)c ?
?v, Vc ?
C T,wa ?
?v, Va ?
A T,w<d) ?
?
?v,  Vd ?
79,?
?
?v  T ,w<.
6 ?v, T,w<~ ?
?9, V6c_79$~ ?
?v, VTcDoi single ?
ED, Vi ?
$V ,%4o~filled ?
?D, Vi ?
~VD~a?
?D,  V i ?$V ,a ?A?^?
?
?~, V?,?
?
?v-~?
6.?~, V?
?
?vT, wT, wT, wT, wT, ivT, wT, w~cka<d) ?:?
* c = Yc(w):?
* a e Y (w):?~ 3w' 6 142 : wRdW' A T, w' ~ ?
:~  3m ?
M : (V.~(w) = ( .
.
.m.
.
.
)^Vw' ?
m : (w = w' Vw -< w')):?~ ~3w' ,w" ,w ''' ?
W : places(w',w)Aplaces(w', w") A w'" R6w A w'" "< w$6 :?~ 3w',w" ?
~42 : wRvwAplaces(w", w) A w" R;w' o !
{ w'?
(,,,11  ^\]o~s ing le  :?t, w' ~Bw" : (w"RT)w'n,, < 1w" e -k ob f i l l ed  I 1t:3~a :?
* Vw' ?
Oi(V.M(w)) : T ,w'  k a~?A?
:?~,T ,w~?andT,  w~?--,?
:?
?, not T, w ~ ?Figure 3: Syntax and Semantics of Ev FormulaeVfin ~ ol(single A filled) A OLinit ial \[1\]A O L (middle A norel) \[2\]A 0 3 single A D L (final A norel) \[3\]A V2 ?~ (middleA <, A\[3~norel) \[4\]A VEnd ?~ (middleA >,) \[5\]A Vl ?~ (initial A norel) \[6\]Figure 4: Domain Description of finite verbs"hat" A Vfin \[7\]A (subj)("Junge" A 1"0) \[8\]A(vpart) ("gesehen" A S0 \[9\]A ~final A >{subj,obj} \[i0\]A (ob j ) ( "Mann"  A t{vpart})) \[11\]Figure 5: Hierachical Structurefinal fields by infinite verb parts such as sepa-rable prefixes or participles.
We will generalizethis field structure to verb-initial and verb-finalclauses as well, without going into the linguisticmotivation due to space limits.The formula in Fig.4 states that all finiteverbs (word class Vfin 6 C) define three orderdomains, of which the first requires exactly oneelement with the feature in i t ia l  \[1\], the secondallows an unspecified number of elements withfeatures middle and nore l  \[2\], and the third al-lows at most one element with features f ina land nore l  \[3\].
The features in i t ia l ,  middle,and f ina l  6 .4 serve to restrict placement ofcertain phrases in specific fields; e.g., no reflex-ive pronouns can appear in the final field.
Thenore l  6 .4 feature controls placement of a rela-tive NP or PP, which may appear in the initialfield only in verb-final clauses.
The order typesare defined as follows: In a verb-second clause(feature V2), the verb is placed at the beginning(<.)
of the middle field (middle), and the el-ement of the initial field cannot be a relativephrase (o~nore l  in \[4\]).
In a verb-final clause(VEnd), the verb is placed at the end (>.)
of themiddle field, with no restrictions for the initialfield (relative clauses and non-relative verb-finalclauses are subordinated to the noun and con-junction, resp.)
\[5\].
In a verb-initial clause (Vl),the verb occupies the initial field \[6\].The formula in Fig.5 encodes the hierarchicalstructure from Fig.1 and contains lexical restric-tions on placement and extraction (the surface isused to identify the word).
Given this, the ordertype of "hat" is determined as follows: The par-ticiple may not be extraposed (~final in \[10\];a restriction from the lexical entry of "hat"), itmust follow "hat" in d2.
Thus, the verb can-not be of order type VEnd, which would requireit to be the last element in its domain (>.
in\[5\]).
"Mann"  is not adjacent o "gesehen", butmay be extracted across the dependency vpart(${vpart} in \[11\]), allowing its insertion intoa domain defined by "hat".
It cannot precede"hat" in d2, because "hat" must either begin d2(due to <.
in \[4\]) or itself go into dl.
But dl al-lows only one phrase (s ing le) ,  leaving only thedomain structure from Fig.2, and thus the ordertype V2 for "hat".1786 Compar i son  to  PSG ApproachesOne feature of word order domains is that theyfactor ordering alternatives from the syntactictree, much like feature annotations do for mor-phological alternatives.
Other lexicalized gram-mars collapse syntactic and ordering informa-tion and are forced to represent ordering alterna-tives by lexical ambiguity, most notable L-TAG(Schabes et al, 1988) and some versions of CG(Hepple, 1994).
This is not necessary in ourapproach, which drastically reduces the searchspace for parsing.This property is shared by the proposal ofReape (1993) to associate HPSG signs with se-quences of constituents, also called word or-der domains.
Surface ordering is determinedby the sequence of constituents associated withthe root node.
The order domain of a mothernode is the sequence union of the order domainsof the daughter nodes, which means that therelative order of elements in an order domainis retained, but material from several domainsmay be interleaved, resulting in discontinuities.Whether an order domain allows interleavingwith other domains is a parameter of the con-stituent.
This approach is very similar to oursin that order domains eparate word order fromthe syntactic tree, but there is one importantdifference: Word order domains in HPSG do notcompletely free the hierarchical structure fromordering considerations, because discontinuity isspecified per phrase, not per modifier.
For ex-ample, two projections are required for an NP,the lower one for the continuous material (de-terminer, adjective, noun, genitival and prepo-sitional attributes) and the higher one for thepossibly discontinuous relative clause.
This de-pendence of hierarchical structure on ordering isabsent from our proposal.We may also compare our approach with theprojection architecture of LFG (Kaplan & Bres-nan, 1982; Kaplan, 1995).
There is a close sim-ilarity of the LFG projections (c-structure andf-structure) to the dimensions used here (orderdomain structure and dependency tree, respec-tively).
C-structure and order domains repre-sent surface ordering, whereas f-structure anddependency tree show the subcategorization rvalence requirements.
What is more, these pro-jections or dimensions are linked in both ac-counts by'an element-wise mapping.
The dif-ference between the two architectures lies in thelinkage of the projections or dimensions: LFGmaps f-structure off c-structure.
In contrast,the dependency relation is taken to be primi-tive here, and ordering restrictions are taken tobe indicators or consequences of dependency re-lations (see also BrSker (1998b, 1998a)).7 Conc lus ionWe have presented an approach to word or-der for DG which combines traditional notions(semantically motivated ependencies, topolog-ical fields) with contemporary techniques (log-ical description language, model-theoretic se-mantics).
Word order domains are sets of par-tially ordered words associated with words.
Aword is contained in an order domain of its head,or may float into an order domain of a transi-tive head, resulting in a discontinuous depen-dency tree while retaining a projective orderdomain structure.
Restrictions on the floatingare expressed in a lexicalized fashion in terms ofdependency relations.
An important benefit isthat the proposal is lexicalized without revertingto lexical ambiguity to represent order variation,thus profiting even more from the efficiency con-siderations discussed by Schabes et al (1988).It is not yet clear what the generative capac-ity of such lexicalized iscontinuous DGs is, butat least some index languages (such as anbnc n)can be characterized.
Neuhaus & BrSker (1997)have shown that recognition and parsing of suchgrammars is A/'7~-complete.
A parser operatingon the model structures is described in (Hahnet al, 1997).Re ferencesBecket, T., A. Joshi & O. Rainbow (1991).
Long-Distance scrambling and tree-adjoining gram-mar.
In Proc.
5th Conf.
of the European Chap-ter of the ACL, pp.
21-26.Bhatt, C. (1990).
Die syntaktische Struktur derNominalphrase im Deutschen.
Studien zurdeutschen Grammatik 38.
Tfibingen: Narr.Blackburn, P. (1994).
Structures, Languages andTranslations: The Structural Approach to Fea-ture Logic.
In C. Rupp, M. Rosner & R. John-son (Eds.
), Constraints, Language and Compu-tation, pp.
1-27.
London: Academic Press.BrSker, N. (1997).
Eine Dependenzgrammatikzur Kopplung heterogener Wissenssysteme aufmodallogischer Basis.
Dissertation, DeutschesSeminar, Universit~it Freiburg.179BrSker, N. (1998a).
How to define a context-freebackbone for DGs: An experiment in gram-mar conversion.
In Proc.
o\] the COLING-A CL'98 workshop "Processing of Dependency-based Grammars".
Montreal/CAN, Aug 15,1998.BrSker, N. (1998b).
A Projection Architecture forDependency Grammar and How it Comparesto LFG.
In Proc.
1998 Int'l Lexical-FunctionalGrammar Conference.
(accepted as alternatepaper) Brisbane/AUS: Jun 30-Jul 2, 1998.Eisner, J.
(1997).
Bilexical Grammars and a Cubic-Time Probabilistic Parser.
In Proc.
of Int'lWorkshop on Parsing Technologies, pp.
54-65.Boston/MA: MIT.Gaifman, H. (1965).
Dependency Systems andPhrase Structure Systems.
Information andControl, 8:304-337.Haegeman, L. (1994).
Introduction to Governmentand Binding.
Oxford/UK: Basil Blackwell.Hahn, U., P. Neuhaus & N. BrSker (1997).
Message-Passing Protocols for Real-World Parsing -An Object-Oriented Model and its PreliminaryEvaluation.
In Proc.
Int'l Workshop on ParsingTechnology, pp.
101-112.
Boston/MA: MIT,Sep 17-21, 1997.Hellwig, P. (1986).
Dependency Unification Gram-mar.
In Proc.
I1th Int'l Conf.
on Computa-tional Linguistics, pp.
195-198.Hepple, M. (1994).
Discontinuity and the LambekCalculus.
In Proc.
15th Int'l Conf.
on Compu-tational Linguistics, pp.
1235-1239.
Kyoto/JP.Hudson, R. (1990).
English Word Grammar.
Ox-ford/UK: Basil Blackwell.Hudson, R. (1993).
Recent developments in depen-dency theory.
In J. Jacobs, A. v. Stechow,W.
Sternefeld & T. Vennemann (Eds.
), Syn-tax.
Ein internationales Handbuch zeitgenSssis-cher Forsehung, pp.
329-338.
Berlin: Walter deGruyter.Kaplan, R. (1995).
The formal architecture ofLexical-Functional Grammar.
In M. Dalrym-ple, R. Kaplan, J. I. Maxwell &: A. Zae-nen (Eds.
), Formal Issues in Lexical-FunctionalGrammar, pp.
7-27.
Stanford University.Kaplan, R. & J. Bresnan (1982).
Lexical-FunctionalGrammar: A Formal System for GrammaticalRepresentation.
In J. Bresnan & R.
Kaplan(Eds.
), The Mental Representation of Gram-matical Relations, pp.
173-281.
Cambridge,MA: MIT Press.Kruijff, G.-J.
v. (1997).
A Basic Dependency-BasedLogical Grammar.
Draft Manuscript.
Prague:Charles University.Maruyama, H. (1990).
Structural Disambiguationwith Constraint Propagation.
In Proc.
28thAnnual Meeting of the ACL, pp.
31-38.
Pitts-burgh/PA.Matthews, P. (1981).
Syntax.
Cambridge Text-books in Linguistics, Cambridge/UK: Cam-bridge Univ.
Press.McCord, M. (1990).
Slot Grammar: A System forSimpler Construction of Practical Natural Lan-guage Grammars.
In R. Studer (Ed.
), NaturalLanguage and Logic, pp.
118-145.
Berlin, Hei-delberg: Springer.Melc'hk, I.
(1988).
Dependency Syntax: Theory andPractice.
Albany/NY: State Univ.
Press of NewYork.Melc'hk, I.
& N. Pertsov (1987).
Surlace Syntaxof English: A Formal Model within the MTTFramework.
Philadelphia/PA: John Benjamins.Neuhaus, P. &: N. BrSker (1997).
The Complexity ofRecognition of Linguistically Adequate Depen-dency Grammars.
In Proc.
35th Annual Meet-ing of the A CL and 8th Conf.
of the EA CL, pp.337-343.
Madrid, July 7-12, 1997.Reape, M. (1993).
A Formal Theory of Word Order:A Case Study in West Germanic.
Doctoral Dis-sertation.
Univ.
of Edinburg.Schabes, Y., A. Abeille & A. Joshi (1988).
ParsingStrategies with 'Lexicalized' Grammars: Appli-cation to TAGs.
In Proc.
12th Int'l Con\].
onComputational Linguistics, pp.
578-583.Sgall, P., E. Hajicova & J. Panevova (1986).
TheMeaning of the Sentence in its Semantic andPragmatic Aspects.
Dordrecht/NL: D.Reidel.Tesni&e, L. (1959).
Elemdnts de syntaxe structurale.Paris: Klincksiek.180
