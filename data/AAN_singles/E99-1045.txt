Proceedings of EACL '99Encoding a Parallel Corpus for Automat ic  TerminologyExtract ionJohann GamperEuropean Academy Bolzano/BozenWeggensteinstr.
12/A, 39100 Bolzano/Bozen, Italyj gamper@eurac, eduAbstractWe present a status report about anongoing research project in the fieldof (semi-)automatic terminology acquisi-tion at the European Academy Bolzano.The main focus will be on encoding atext corpus, which serves as a basis forapplying term extraction programq.1 IntroductionText corpora are valuable resources in all areasdealing with natural anguage processing in oneform or another.
Terminology is one of thesefields, where researchers explore domain-specificlanguage material to investigate rminological is-sues.
The manual acquisition of terminologicaldata from text material is a very work-intensiveand error-prone task.
Recent advances in auto-matic corpus analysis favored a modern form ofterminology acquisition: (1) a corpus is a col-lection of language material in machine-readableform and (2) computer programs can the cor-pus for terminologically relevant information andgenerate lists of term candidates which have tobe post-edited by humans.
The following projectCATEx adopts this approach.2 The CATEx ProjectDue to the equal status of the Italian and the Ger-man language in South Tyrol, legal and admin-istrative documents have to be written in bothlanguages.
A prerequisite for high quality trans-lations is a consistent and comprehensive bilingualterminology, which also forms the basis for an in-dependent German legal language which reflectsthe Italian legislation.
The first systematic effortin this direction was initiated a few years ago atthe European Academy Bolzano/Bozen with thegoal to compile an Italian/German legal and ad-ministrative t rminology for South Tyrol.The CATEx (C_omputer A_.ssisted TerminologyE___~raction) project emerged from the need to sup-port and improve, both qualitatively and quan-titatively, the manual acquisition of terminologi-cal data.
Thus, the main objective of CATEx isthe development of a computational framework for(semi-)antomatic erminology acquisition, whichconsists of four modules: a parallel text corpus,term-extraction programs, a term bank linked tothe text corpus, and a user-interface for browsingthe corpus and the term bank.3 Building a Parallel Text CorpusBuilding the text corpus comprises the followingtasks: corpus design, preprocessing, encoding pri-mary data, and encoding linguistic information.3.1 Corpus Design and PreprocessingCorpus design selects a collection of texts whichshould be included in the corpus.
An importantcriteria is that the texts represent a realistic modelof the language to be studied (Bowker, 1996).
Inits current form, our corpus contains only one sortof texts, namely the bilingual version of Italianlaws such as the Civil Code.
A particular featureof our corpus, which contains both German andItalian translations, is the structural equivalenceof the original text and its translation down to thesentence level, i.e.
each sentence in the originaltext has a corresponding one in the translation.The corpus is one of the largest special anguagecorpora.
It contains ca.
5 Mio.
words and 35,898(66,934) different Italian (German) word forms.In the preprocessing phase we correct (mainlyOCR) errors in the raw text material and producea unified electronic version in such a way as tosimplify the programs for consequent annotation.3.2 Encoding Pr imary Data andLinguistic AnnotationCorpus encoding successively enriches the rawtext material with explicitly encoded informa-275Proceedings of EACL '99tion.
We apply the Corpus Encoding Standard(CES), which is an application of SGML and pro-vides guidelines for encoding corpora that are usedin language ngineering applications (Ide et al,1996).
CES distinguishes primary data (raw textmaterial) and linguistic annotation (informationresulting from linguistic analyses of the raw texts).Primary data encoding covers the markup ofrelevant objects in the raw text material.
It com-prises documentation i formation (bibliographicinformation, etc.)
and structural information(sections, lists, footnotes, references, etc.).
Thesepieces of information are required to automati-cally extract the source of terms, e.g.
"CodiceCivile, art.
12".
Structural information helps alsoto browse the corpus; this is important in our case,since the corpus will be linked to the terminolog-ical database.Encoding linguistic annotation enriches the pri-mary data with information which results fromlinguistic analyses of these data.
We consider thesegmentation of texts into sentences and words,the assignment/disambiguation of lemmas andpart-of-speech (POS) tags, and word alignment.Due to the structural equivalence of our paral-lel texts, we can easily build a perfectly sentence-aligned corpus which is useful for word alignment.The above mentioned linguistic information is re-quired for term extraction, which is mainly in-spired by the work in (Dagan and Church, 1997).The monolingual recognition of terms is based onPOS patterns which characterize valid terms andthe recognition of translation equivalents i basedon bilingual word alignment.
Lemmas abstractfrom singular/plural variations, which is useful foralignment and term recognition.4 D iscuss ionThe general approach we adopted in the prepro-cessing and primary data encoding phases wasto pass the raw texts through a sequence of fil-ters.
Each filter adds some small pieces of newinformation and writes a logfile in case of doubt.The output and the logfile in turn are used toimprove the filter programs in order to minimizemanual post-editing.
This modular bootstrappingapproach as advantages over huge parameteriz-able programs: filters are relatively simple and canbe partially reused or easily adapted for texts withdifferent formats; tuning the filters becomes lesscomplex; when recovering from a previous tagethe loss of work is minimized.
The filters havebeen implemented in Perl which, due to its pat-tern matching mechanism via regular expressions,is a very powerful language for such applications.For the linguistic annotation we use the MUL-TEXT tools available from http://www.lpl.univ-aix.fr/projects/multext.
We already have exten-sive experience with the tokenlzer MtSeg whichdistinguishes 11 classes of tokens, such as abbrevi-ations, dates, various punctuations, etc.
The cus-tomization of MtSeg via language-specific resourcefiles has been done in a bootstrapping process im-ilar to the filter programs.
An evaluation of 10%of the Civil Code (~ 28,000 words) revealed onlyone type of tokenization error: a full stop that isnot part of an abbreviation and is followed by anuppercase letter is recognized as end-of-sentencemarker, e.g.
in "6.
Absatz".
This kind of error isunavoidable in German if we refuse to mark suchpatterns as compounds.Currently we are preparing the lemmatizationand the POS tagging by using MtLex.
MtLex isequipped with an Italian and a German lexiconwhich contain 138,823 and 51,010 different wordforms respectively.
To include the 15,013 (58,217)new Italian (German) word forms in our corpusthe corresponding lexicons have been extended.The creation of the Italian lexicon took 2 MM.Future work will include the completion of thelinguistic annotation.
The MULTEXT tagger Mr-Tag will be used for the disambiguation of POStags.
Word alignment still requires the studyof various approaches, e.g.
(Dagan et al, 1993;Melamed, 1997).
Finally, we are working on a so-phisticated interface to navigate through paralleldocuments to disseminate the text corpus beforeterminology extraction has been completed.ReferencesLynne Bowker.
1996.
Towards a corpus-based approach to terminography.
Terminol-ogy, 3(1):27-52.Ido Dagan and Kenneth W. Church.
1997.
Ter-might: Coordinating humans and machinesin bilingual terminology acquisition.
MachineTranslation, 12:89-107.Ido Dagan, Kenneth W. Church, and William A.Gale.
1993.
Robust bilingual word alignmentfor machine aided translation.
In Proceedingsof the Workshop on Very Large Corpora: Aca-demic and Industrial Perspectives, pages 1-8.Nancy Ide, Greg Priest-Dorman, and JeanV~ronis.
1996.
Corpus encoding standard.
Seehttp://www.cs.vassar.edu/CES/.I.
Dan Melamed.
1997.
A portable algorithm formapping bitext correspondence.
In Proceedingsof ACL/EACL-97, pages 302-312.276
