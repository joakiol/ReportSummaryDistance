Inducing Lexico-Structural Transfer Rules from Parsed Bi-textsBenoit Lavoie, Michael White, and Tanya KorelskyCoGenTex, Inc.840 Hanshaw RoadIthaca, NY 14850, USAbenoit,mike,tanya@cogentex.comAbstractThis paper describes a novel approachto inducing lexico-structural transferrules from parsed bi-texts using syn-tactic pattern matching, statistical co-occurrence and error-driven filtering.We present initial evaluation results anddiscuss future directions.1 IntroductionThis paper describes a novel approach to inducingtransfer rules from syntactic parses of bi-texts andavailable bilingual dictionaries.
The approachconsists of inducing transfer rules using the fourmajor steps described in more detail below: (i)aligning the nodes of the parses; (ii) generatingcandidate rules from these alignments; (iii) order-ing candidate rules by co- occurrence; and (iv) ap-plying error-driven filtering to select the final setof rules.Our approach is based on lexico-structuraltransfer (Nasr et.
al., 1997), and extends recentwork reported in (Han et al, 2000) about Koreanto English transfer in particular.
Whereas Han etal.
focus on high quality domain-specific transla-tion using handcrafted transfer rules, in this workwe instead focus on automating the acquisition ofsuch rules.Our approach can be considered a generaliza-tion of syntactic approaches to example-basedmachine translation (EBMT) such as (Nagao,1984; Sato and Nagao, 1990; Maruyama andWatanabe, 1992).
While such approaches usesyntactic transfer examples during the actualtransfer of source parses, our approach insteaduses syntactic transfer examples to induce generaltransfer rules that can be compiled into a transferdictionary for use in the actual translation process.Our approach is similar to the recent work of(Meyers et al, 1998) where transfer rules are alsoderived after aligning the source and target nodesof corresponding parses.
However, it also differsfrom (Meyers et al, 1998) in several importantpoints.
The first difference concerns the contentof parses and the resulting transfer rules; in (Mey-ers et al, 1998), parses contain only lexical labelsand syntactic roles (as arc labels), while our ap-proach uses parses containing lexical labels, syn-tactic roles, and any other syntactic informationprovided by parsers (tense, number, person, etc.
).The second difference concerns the node align-ment; in (Meyers et al, 1998), the alignment ofsource and target nodes is designed in a way thatpreserves node dominancy in the source and tar-get parses, while our approach does not have suchrestriction.
One of the reasons for this differenceis due to the different language pairs under study;(Meyers et al, 1998) deals with two languagesthat are closely related syntactically (Spanish andEnglish) while we are dealing with languages thatsyntactically are quite divergent, Korean and En-glish (Dorr, 1994).
The third difference is in theprocess of identification of transfer rules candi-dates; in (Meyers et al, 1998), the identificationis done by using the exact tree fragments in thesource and target parse that are delimited by thealignment, while we use all source and target treesub-patterns matching a subset of the parse fea-tures that satisfy a customizable set of alignmentconstraints and attribute constraints.
The fourththird difference is in the level of abstraction oftransfer rules candidates; in (Meyers et al, 1998),the source and target patterns of each transfer ruleare fully lexicalized (except possibly the terminalnodes), while in our approach the nodes of trans-fer rules do not have to be lexicalized.Section 2 describes our approach to trans-fer rules induction and its integration with datapreparation and evaluation.
Section 3 describesthe data preparation process and resulting data.Section 4 describes the transfer induction processin detail.
Section 5 describes the results of our ini-tial evaluation.
Finally, Section 6 concludes witha discussion of future directions.2 Overall ApproachIn its most general form, our approach to transferrules induction includes three different processes,data preparation, transfer rule induction and eval-uation.
An overview of each process is providedbelow; further details are provided in subsequentsections.The data preparation process creates the fol-lowing resources from the bi-texts:?
A training set and a test set of source andtarget parses for the bi-texts, post-processedinto a syntactic dependency representation.?
A baseline transfer dictionary, which may in-clude (depending upon availability) lexicaltransfer rules extracted from the bi-texts us-ing statistical methods, lexical transfer rulesfrom existing bilingual dictionaries, and/orhandcrafted lexico-structural transfer rules.The transfer induction process induces lexico-structural transfer rules from the training set ofcorresponding source and target parses that, whenadded to the baseline transfer dictionary, producetransferred parses that are closer to the corre-sponding target parses.
The transfer inductionprocess has the following steps:?
Nodes of the corresponding source and tar-get parses are aligned using the baselinetransfer dictionary and some heuristics basedon the similarity of part-of-speech and syn-tactic context.?
Transfer rule candidates are generated basedon the sub-patterns that contain the corre-sponding aligned nodes in the source and tar-get parses.?
The transfer rule candidates are orderedbased on their likelihood ratios.?
The transfer rule candidates are filtered, oneat a time, in the order of the likelihood ra-tios, by removing those rule candidates thatdo not produce an overall improvement inthe accuracy of the transferred parses.The evaluation process has the following steps:?
Both the baseline transfer dictionary and theinduced transfer dictionary (i.e., the baselinetransfer dictionary augmented with the in-duced transfer rules) are applied to the testset in order to produce two sets of transferredparses, the baseline set and the (hopefully)improved induced set.
For each set, the dif-ferences between the transferred parses andtarget parses are measured, and the improve-ment in tree accuracy is calculated.?
After performing syntactic realization on thebaseline set and the induced set of trans-ferred parses, the differences between theresulting translated strings and the targetstrings are measured, and the improvementin string accuracy is calculated.?
For a subset of the translated strings, humanjudgments of accuracy and grammaticalityare gathered, and the correlations betweenthe manual and automatic scores are calcu-lated, in order to assess the meaningfulnessof the automatic measures.3 Data Preparation3.1 Parsing the Bi-textsIn our experiments to date, we have used a cor-pus consisting of a Korean dialog of 4183 sen-tences and their English human translations.
Weran off-the-shelf parsers on each half of the cor-pus, namely the Korean parser developed by Yoonet al (1997) and the English parser developed byCollins (1997).
Neither parser was trained on ourcorpus.We automatically converted the phrase struc-ture output of the Collins parser into the syntac-tic dependency representation used by our syn-tactic realizer, RealPro (Lavoie and Rambow,1997).
This representation is based on the deep-syntactic structures (DSyntS) of Meaning-TextTheory (Mel?c?uk, 1988).
The important featuresof a DSyntS are as follows:?
a DSyntS is an unordered tree with labelednodes and labeled arcs;?
a DSyntS is lexicalized, meaning that thenodes are labeled with lexemes (uninflectedwords) from the target language;?
a DSyntS is a dependency structure and not aphrase- structure structure: there are no non-terminal nodes, and all nodes are labeledwith lexemes;?
a DSyntS is a syntactic representation,meaning that the arcs of the tree are la-beled with syntactic relations such as SUB-JECT (represented in DSyntSs as I), ratherthan conceptual or semantic relations such asAGENT;?
a DSyntS is a deep syntactic representation,meaning that only meaning-bearing lexemesare represented, and not function words.Since the output of the Yoon parser is quite sim-ilar, with the exception of its treatment of syn-tactic relations, we have used its output as is.The DSyntS representations for two correspond-ing Korean1 and English sentences are illustratedin Figure 1.In examining the outputs of the two parserson our corpus, we found that about half of theparse pairs contained incorrect dependency as-signments, incomplete lemmatization or incom-plete parses.
To reduce the impact of such pars-ing errors in our initial experiments, we have pri-marily focused on a higher quality subset of 1763sentence pairs that were selected according to thefollowing criteria:?
Parse pairs where the source or target parsecontained more than 10 nodes were rejected,1Korean is represented in romanized format in this paper.
(S1) {i} {Ci-To-Reul} {Ta-Si} {Po-Ra}.this + map-accusative + again + look-imp(D1) {po} [class=vbma ente={ra}] (s1 {ci-to} [class=nnin2 ppca={reul}] (s1 {i} [class=ande])s1 {ta-si} [class=adco2])(S2) Look at the map again.
(D2) look [class=verb mood=imp] (attr at [class=preposition] (ii map [class=common_noun article=def])attr again [class=adverb])Figure 1: Syntactic dependency representationsfor corresponding Korean and English sentencessince these usually contained more parse er-rors than smaller parses.?
Parse pairs where the source or target parsecontained non-final punctuation were re-jected; this criterion was based on our ob-servation that in most such cases, the sourceor target parses contained only a fragmentof the original sentence content (i.e., one orboth parsers only parsed what was on oneside of an intra-sentential punctuation mark).We divided this higher quality subset into train-ing and test sets by randomly choosing 50% ofthe 1763 higher quality parse pairs (described inSection 3.1) for inclusion in the training set, re-serving the remaining 50% for the test set.
Theaverage numbers of parse nodes in the training setand test set were respectively 6.91 and 6.11 nodes.3.2 Creating the Baseline TransferDictionaryIn the general case, any available bilingual dic-tionaries can be combined to create the base-line transfer dictionary.
These dictionaries mayinclude lexical transfer dictionaries extractedfrom the bi-texts using statistical methods, exist-ing bilingual dictionaries, or handcrafted lexico-structural transfer dictionaries.
If probabilistic in-formation is not already associated with the lexi-cal entries, log likelihood ratios can be computedand added to these entries based on the occur-rences of these lexical items in the parse pairs.In our initial experiments, we decided to focuson the scenario where the baseline transfer dic-@KOREAN:{po} [class=vbma] (s1 $X [ppca={reul}])@ENGLISH:look [class=verb] (attr at [class=preposition] (ii $X))@-2xLOG_LIKELIHOOD: 12.77Figure 2: Transfer rule for English lexicalizationand preposition insertion@KOREAN:$X [class=vbma ente={ra}]@ENGLISH:$X [class=verb mood=imp]@-2xLOG_LIKELIHOOD: 33.37Figure 3: Transfer rule for imperative formstionary is created from lexical transfer entries ex-tracted from the bi-texts using statistical methods.To simulate this scenario, we created our baselinetransfer dictionary by taking the lexico-syntactictransfer dictionary developed by Han et al (2000)for this corpus and removing the (more general)rules that were not fully lexicalized.
Starting withthis purely lexical baseline transfer dictionary en-abled us to examine whether these more generalrules could be discovered through induction.4 Transfer Rule InductionThe induced lexico-structural transfer rules arerepresented in a formalism similar to the one de-scribed in Nasr et al (1997), and extended to alsoinclude log likelihood ratios.
Figures 2 and 3illustrate two entry samples that can be used totransfer a Korean syntactic representation for ci-to-reul po-ra to an English syntactic representa-tion for look at the map.
The first rule lexicalizesthe English predicate and inserts the correspond-ing preposition while the second rule inserts theEnglish imperative attribute.
This formalism usesnotation similar to the syntactic dependency nota-tion shown in Figure 1, augmented with variablearguments prefixed with $ characters.4.1 Aligning the Parse NodesTo align the nodes in the source and target parsetrees, we devised a new dynamic programmingalignment algorithm that performs a top-down,bidirectional beam search for the least cost map-ping between these nodes.
The algorithm is pa-rameterized by the costs of (1) aligning two nodeswhose lexemes are not found in the baseline trans-fer dictionary; (2) aligning two nodes with dif-fering parts of speech; (3) deleting or inserting anode in the source or target tree; and (4) aligningtwo nodes whose relative locations differ.To determine an appropriate part of speech costmeasure, we first extracted a small set of parsepairs that could be reliably aligned using lexicalmatching alone, and then based the cost measureon the co-occurrence counts of the observed partsof speech pairings.
The remaining costs were setby hand.As a result of the alignment process, alignmentid attributes (aid) are added to the nodes of theparse pairs.
Some nodes may be in alignmentwith no other node, such as English prepositionsnot found in the Korean DSyntS.4.2 Generating Rule CandidatesCandidate transfer rules are generated using threedata sources:?
the training set of aligned source and targetparses resulting from the alignment process;?
a set of alignment constraints which identifythe subtrees of interest in the aligned sourceand target parses (Section 4.2.1);?
a set of attribute constraints which determinewhat parts of the aligned subtrees to includein the transfer rule candidates?
source andtarget patterns (Section 4.2.2).The alignment and attribute constraints are nec-essary to keep the set of candidate transfer rulesmanageable in size.4.2.1 Alignment constraintsFigure 4 shows an example alignment constraint.This constraint, which matches the structural pat-terns of the transfer rule illustrated in Figure 2,uses the aid alignment attribute to indicate that@KOREAN:$X1 [aid=$1] ($R1 $X2 [aid=$2])@ENGLISH:$Y1 [aid=$1] ($R2 $Y2 ($R3 $Y3 [aid=$2]))Figure 4: Alignment constraintin a Korean and English parse pair, any sourceand target sub-trees matching this alignment con-straint (where $X1 and $Y1 are aligned or havethe same attribute aid values and where $X2 and$Y3 are aligned) can be used as a point of depar-ture for generating transfer rule candidates.
Wesuggest that alignment constraints such as this onecan be used to define most of the possible syntac-tic divergences between languages (Dorr, 1994),and that only a handful of them are necessary fortwo given languages (we have identified 11 gen-eral alignment constraints necessary for Korean toEnglish transfer so far).4.2.2 Attribute constraintsAttribute constraints are used to limit the spaceof possible transfer rule candidates that can begenerated from the sub-trees satisfying the align-ment constraints.
Candidate transfer rules mustsatisfy all of the attribute constraints.
Attributeconstraints can be divided into two types:?
independent attribute constraints, whosescope covers only one part of a candidatetransfer rule and which are the same for thesource and target parts;?
concurrent attribute constraints, whosescope extends to both the source and targetparts of a candidate transfer rule.The examples of an independent attribute con-straint and of a concurrent attribute constraint aregiven in Figure 5 and Figure 6 respectively.
Aswith the alignment constraints, we suggest that arelatively small number of attribute constraints isnecessary to generate most of the desired rules fora given language pair.Each node of a candidate transfer rule must have its relationattribute (relationship with its governor) specified if it is aninternal node, otherwise this relation must not be specified:e.g.$X1 ( $R $X2 )Figure 5: Independent attribute constraintIn a candidate transfer rule, inclusion of the lexemes of twoaligned nodes must be done concurrently:e.g.$X [aid=$1]and$Y [aid=$1]e.g.
[aid=$1]and[aid=$1]Figure 6: Concurrent attribute constraint4.3 Ordering Rule CandidatesIn the next step, transfer rule candidates are or-dered as follows: first, by their log likelihood ra-tios (Manning and Schutze, 1999: 172-175); sec-ond, any transfer rule candidates with the samelog likelihood ratio are ordered by their speci-ficity.4.3.1 Rule ordering by log likelihood ratioWe calculate the log likelihood ratio, log ?, ap-plied to a transfer rule candidate as indicated inFigure 7.
Note that log ?
is a negative value,and following (Manning and Schutze, 1999), weassign -2 log ?
to the transfer rule.
Note alsothat in the definitions of C1, C2, and C12 we arecurrently only considering one occurrence or co-occurrence of the source and/or target patterns perparse pair, while in general there could be morethan one; in our initial experiments these defini-tions have sufficed.4.3.2 Rule ordering by specificityIf two or more candidate transfer rules have thesame log likelihood ratio, ties are broken by aspecificity heuristic, with the result that more gen-eral rules are ordered ahead of more specific ones.The specificity of a rule is defined to be the fol-lowing sum: the number of attributes found inthe source and target patterns, plus 1 for each forlog ?
=logL(C12, C1, p) + logL(C2 ?
C12, N ?
C1, p)?
logL(C12, C1, p1)?
logL(C2?C12, N ?C1, p2)where, not counting attributes aid,?
C1 = number of source parses containing at least oneoccurrence of C?s source pattern?
C2 = number of target parses containing at least oneoccurrence of C?s target pattern?
C12 = number of source and target parse pairs contain-ing at least one co-occurrence of C?s source patternand C?s target pattern satisfying the alignment con-straints?
N = number of source and target parse pairs?
P = C2/N ;?
P1 = C12/C1;?
P2 = (C2 ?
C12)/(N ?
C1);?
L(k, n, x) = xk(1?
x)n?kFigure 7: Log likelihood ratios for transfer rulecandidateseach lexeme attribute and for each dependency re-lationship.
In our initial experiments, this simpleheuristic has been satisfactory.4.4 Filtering Rule CandidatesOnce the candidate transfer rules have been or-dered, error-driven filtering is used to select thosethat yield improvements over the baseline trans-fer dictionary.
The algorithm works as follows.First, in the initialization step, the set of acceptedtransfer rules is set to just those appearing in thebaseline transfer dictionary, and the current er-ror rate is established by applying these transferrules to all the source structures and calculatingthe overall difference between the resulting trans-ferred structures and the target parses.
Then, in asingle pass through the ordered list of candidates,each transfer rule candidate is tested to see if itreduces the error rate.
During each iteration, thecandidate transfer rule is provisionally added tothe current set of accepted rules and the updatedset is applied to all the source structures.
If theoverall difference between the transferred struc-tures and the target parses is lower than the cur-rent error rate, then the candidate is accepted and@KOREAN:{po} [class=vbma ente={ra}] (s1 $X [ppca={reul}])@ENGLISH:look [class=verb mood=imp] (attr at [class=preposition] (ii $X))@-2xLOG_LIKELIHOOD: 11.40Figure 8: Transfer rule for English imperativewith lexicalization and preposition insertionthe current error rate is updated; otherwise, thecandidate is rejected and removed from the cur-rent set.4.5 Discussion of Induced RulesExperimentation with the training set of 882 parsepairs described in Section 3.1 produced 12467source and target sub-tree pairs using the align-ment constraints, from which 20569 transfer rulescandidate were generated and 7565 were acceptedafter filtering.
We expect that the number ofaccepted rules per parse pair will decrease withlarger training sets, though this remains to be ver-ified.The rule illustrated in Figure 3 was accepted asthe 65th best transfer rule with a log likelihoodratio of 33.37, and the rule illustrated in Figure 2was accepted as the 189th best transfer rule can-didate with a log likelihood ratio of 12.77.
An ex-ample of a candidate transfer rule that was not ac-cepted is the one that combines the features of thetwo rules mentioned above, illustrated in Figure 8.This transfer rule candidate had a lower log like-lihood ratio of 11.40; consequently, it is only con-sidered after the two rules mentioned above, andsince it provides no further improvement uponthese two rules, it is filtered out.In an informal inspection of the top 100 ac-cepted transfer rules, we found that most of themappear to be fairly general rules that would nor-mally be found in a general syntactic-based trans-fer dictionary.
In looking at the remaining rules,we found that the rules tended to become increas-ingly corpus-specific.5 Initial Evaluation5.1 ResultsIn an initial evaluation of our approach, we ap-plied both the baseline transfer dictionary andthe induced transfer dictionary (i.e., the baselinetransfer dictionary augmented with the transferrules induced from the training set) to the test halfof the 1763 higher quality parse pairs described inSection 3.1, in order to produce two sets of trans-ferred parses, the baseline set and the induced set.For each set, we then calculated tree accuracy re-call and precision measures as follows:Tree accuracy recall The tree accuracy recallfor a transferred parse and a correspond-ing target parse is determined the by C/Rq,where C is the total number of features (at-tributes, lexemes and dependency relation-ships) that are found in both the nodes ofthe transferred parse and in the correspond-ing nodes in the target parse, and Rq is thetotal number of features found in the nodesof the target parse.
The correspondence be-tween the nodes of the transferred parse andthe nodes of the target parse is determinedwith alignment information obtained usingthe technique described in Section 4.1.Tree accuracy precision The tree accuracy pre-cision for a transferred parse and a corre-sponding target parse is determined the byC/Rt, where C is the total number of fea-tures (attributes, lexemes and dependencyrelationships) that are found in both thenodes of the transferred parse and in the cor-responding nodes in the target parse, and Rtis the total number of features found in thenodes of the transferred parse.Table 1 shows the tree accuracy results, wherethe f-score is equally weighted between recall andprecision.
The results illustrated in Table 1 indi-cate that the transferred parses obtained using in-duction were moderately more similar to the tar-get parses than the transferred parses obtained us-ing the baseline transfer, with about 15 percentimprovement in the f-score.Recall Precision F-ScoreBaseline 37.77 46.81 41.18Induction 55.35 58.20 55.82Table 1: Tree accuracy results5.2 DiscussionAt the time of writing, the improvements in treeaccuracy do not yet appear to yield apprecia-ble improvements in realization results.
Whileour syntactic realizer, RealPro, does produce rea-sonable surface strings from the target depen-dency trees, despite occasional errors in parsingthe target strings and converting the phrase struc-ture trees to dependency trees, it appears that thetree accuracy levels for the transferred parses willneed to be higher on average before the improve-ments in tree accuracy become consistently visi-ble in the realization results.
At present, the fol-lowing three problems represent the most impor-tant obstacles we have identified to achieving bet-ter end-to-end results:?
Since many of the test sentences requiretransfer rules for which there are no similarcases in the set of training sentences, it ap-pears that the relatively small size of our cor-pus is a significant barrier to better results.?
Some performance problems with the cur-rent implementation have forced us to makeuse of a perhaps overly strict set of alignmentand attribute constraints.
With an improvedimplementation, it may be possible to findmore valuable rules from the same trainingdata.?
A more refined treatment of rule conflicts isneeded in order to allow multiple rules toaccess overlapping contexts, while avoidingthe introduction of multiple translations ofthe same content in certain cases.6 Conclusion and Future DirectionsIn this paper we have presented a novel approachto transfer rule induction based on syntactic pat-tern co-occurrence in parsed bi-texts.
In an initialevaluation on a relatively small corpus, we haveshown that the induced syntactic transfer rulesfrom Korean to English lead to a modest increasein the accuracy of transferred parses when com-pared to the target parses.
In future work, wehope to demonstrate that a combination of consid-ering a larger set of transfer rule candiates, refin-ing our treatment of rule conflicts, and making useof more training data will lead to further improve-ments in tree accuracy, and, following syntacticrealization, will yield to significant improvementsin end-to-end results.AcknowledgementsWe thank Richard Kittredge for helpful discus-sion, Daryl McCullough and Ted Caldwell fortheir help with evaluation, and Chung-hye Han,Martha Palmer, Joseph Rosenzweig and Fei Xiafor their assistance with the handcrafted Korean-English transfer dictionary and the conversion ofphrase structure parses to syntactic dependencyrepresentations.
This work has been partially sup-ported by DARPA TIDES contract no.
N66001-00-C-8009.ReferencesMichael Collins.
1997.
Three generative, lexicalisedmodels for statistical parsing.
In Proceedings of the35th Meeting of the Association for ComputationalLinguistics (ACL?97), Madrid, Spain.Bonnie Dorr.
1994.
Machine translation divergences:A formal description and proposed solution.
Com-putational Linguistics, 20(4):597?635.C.
Han, B. Lavoie, M. Palmer, O. Rambow, R. Kit-tredge, T. Korelsky, N. Kim, and M. Kim.
2000.Handling structural divergences and recoveringdropped arguments in a Korean-English machinetranslation system.
In Proceedings of the FourthConference on Machine Translation in the Ameri-cas (AMTA?00), Misin Del Sol, Mexico.Benoit Lavoie and Owen Rambow.
1997.
RealPro ?a fast, portable sentence realizer.
In Proceedings ofthe Conference on Applied Natural Language Pro-cessing (ANLP?97), Washington, DC.C.
D. Manning and H. Schutze.
1999.
Foundationsof Statistical Natural Language Processing.
MITPress.H.
Maruyama and H. Watanabe.
1992.
Tree coversearch algorithm for example-based translation.
InProceedings of the Fourth International Conferenceon Theoretical and Methodological Issues in Ma-chine Translation (TMI?92), pages 173?184.Y.
Matsumoto, H. Hishimoto, and T. Utsuro.
1993.Structural matching of parallel texts.
In Proceed-ings of the 31st Annual Meetings of the Associationfor Computational Linguistics (ACL?93), pages 23?30.Igor Mel?c?uk.
1988.
Dependency Syntax.
State Uni-versity of New York Press, Albany, NY.A.
Meyers, R. Yangarber, R. Grishman, C. Macleod,and A. Moreno-Sandoval.
1998.
Deriving transferrules from dominance-preserving alignments.
InProceedings of COLING-ACL?98, pages 843?847.Makoto Nagao.
1984.
A framework of a mechan-ical translation between Japenese and English byanalogy principle.
In A. Elithorn and R. Banerji,editors, Artificial and Human Intelligence.
NATOPublications.Alexis Nasr, Owen Rambow, Martha Palmer, andJoseph Rosenzweig.
1997.
Enriching lexical trans-fer with cross-linguistic semantic features.
In Pro-ceedings of the Interlingua Workshop at the MTSummit, San Diego, California.S.
Sato and M. Nagao.
1990.
Toward memory-based translation.
In Proceedings of the 13th Inter-national Conference on Computational Linguistics(COLING?90), pages 247?252.Fei Xia and Martha Palmer.
2001.
Converting depen-dency structures to phrase structures.
In Notes ofthe First Human Language Technology Conference,San Diego, California.J.
Yoon, S. Kim, and M. Song.
1997.
New parsingmethod using global association table.
In Proceed-ings of the 5th International Workshop on ParsingTechnology.
