IS-G: The Comparison of Different Learning Techniques for the Selection ofthe Main Subject ReferencesBernd BohnetUniversity of StuttgartVisualization and Interactive Systems GroupUniversita?tstr.
58, 70569 Stuttgart, Germanybohnet@informatik.uni-stuttgart.deAbstractThe GREC task of the Referring ExpressionGeneration Challenge 2008 is to select appro-priate references to the main subject in giventexts.
This means to select the correct type ofthe referring expressions such as name, pro-noun, common, or elision (empty).
We employfor the selection different learning techniqueswith the aim to find the most appropriate onefor the task and the used attributes.
As train-ing data, we use the syntactic category of thesearched referring expressions and addition-ally gathered data from the text itself.1 IntroductionThe training data of the GREC task consists ofWikipedia articles from five domains.
The arti-cles are about People, Cities, Countries, Rivers, andMountains.
An XML annotation replaces the orig-inal referring expressions in the articles with a setof alternative experssions which could be inserted inthe empty space in order to complete the text.
Thetraining data additionally consists of the original re-ferring expressions.
From the annotations, we usefor the training the syntactic category (SYNCAT) forthe searched referring expression.The annotation allows us easily to access addi-tional data.
One of the values that we calculate isthe distance (DIST) to the last referring expression.The idea behind this value is that the references be-comes with increasing distance unclear because ofother content in the text and therefore, to provide ashort form such as a pronoun is not enough or wouldbe even misleading.
Of cause there might be otherreasons to use the name too.
The next information,we use is the count (POS) of the referring expres-sion in the text.
Because we expect that the first re-ferring expression is in most cases the name of themain subject and at the end of a text, it might beused less frequent.
Then we use the type of the last(LAST) used referring expression in the text.
Thismight be a good candidate because people want toavoid consecutive repetitions of the same word.
Thedisadvantage of this attribute is that it is based itselfon the classification of its predecessor and therefore,on insecure information.
Finally, we use a seconddistance measure which provides the information ifthe last referring expression was in the same sen-tence (SENT).2 Comparison of Learning TechniquesWe tried several machine learning techniques andselected among them the three bests that areBayesian Networks with the attribute selectionmethod K2 (Cooper and Herskovits, 1992), decisiontrees C4.5 (Quinlan, 1993), and Multi Layer Percep-trons with a sigmoid function (Minsky and Papert,1969).
For the comparison with the three machinelearning techniques, we provide in Table 1 a baseline where we chose the type with the most occur-rences in the training data of the domain.Table 2 shows the results for the Bayesian Net-work.
The results are significant better then the baseline results.
Table 3 shows the results of C4.5.
Theresults are close to the results of the Bayesian Net-work.
An advantage of decision trees is that theyprovide some explanation.
A part of the decisiontree is shown in Figure 1.
The part selects a refer-192Set Most frequent type AccuracyCities name 0.47Countries name 0.45Mountains name 0.39People pronoun 0.61Rivers name 0.43Total ?
0.47Table 1: Base LineSet Cities Cou.
Mount.
Peo.
Ri.
TotalAcc 0.48 0.62 0.63 0.673 0.7 0.62Table 2: Results for Bayesian Networks (K2)ring expression in the case that the last expressionwas already within the same sentences.Set Cities Cou.
Mount.
Peo.
Ri.
TotalAcc 0.545 0.63 0.641 0.673 0.7 0.638Table 3: Results for C4.5The uppercase words are the attributes followedby the value for the branch.
If the value of a distinctinstance is in the range of the value then the algo-rithms chooses the branch until it reaches a leaf.
Theleafs are labelled with the result of the decision andwith information of an evaluation that provides theinformation how many training instances (cases) areclassified correct / wrong.
Interesting for the caseare the following observations:?
The text writers chose nearly always (>99%)an other referring expression than the name.?
They select more frequent pronouns and an eli-sions (empty) compared to common names.?
The writers select common names in case of ahigh distance to the last referring expression.Table 4 shows the results for the Multi LayerPerceptron, which performed best compared to theother learning techniques.3 ConclusionWe calculated the information gain of each attributeto get an overview of the relevance of the attributes.The most releveant attribute is DIST (0.32) followedby POS (0.24), LAST (0.239), SENT (0.227), andSYNCAT (0.19).SENT = true?
SYNCAT = subj-det?
?
DIST <= 158: pronoun (103.0/8.0)?
?
DIST > 158: common (4.0/1.0)?
SYNCAT = np-subj?
?
DIST <= 33: pronoun (32.0/15.0)?
?
DIST > 33?
?
?
LAST = common?
?
?
?
DIST <= 123: empty (25.0/5.0)?
?
?
?
DIST > 123: common (2.0/1.0)?
?
?
LAST = pronoun: empty (69.0/22.0)?
?
?
LAST = name?
?
?
?
POS <= 2: empty (17.0/2.0)?
?
?
?
POS > 2?
?
?
?
?
POS <= 15?
?
?
?
?
?
DIST <= 79?
?
?
?
?
?
?
DIST <= 39: pronoun (3.0)?
?
?
?
?
?
?
DIST > 39: empty (46.0/15.0)?
?
?
?
?
?
DIST > 79?
?
?
?
?
?
?
POS <= 5: pronoun (3.0)?
?
?
?
?
?
?
POS > 5?
?
?
?
?
?
?
?
POS <= 11?
?
?
?
?
?
?
?
?
DIST <= 113: common (4.0/1.0)?
?
?
?
?
?
?
?
?
DIST > 113: name (2.0/1.0)?
?
?
?
?
?
?
?
POS > 11: pronoun (2.0)?
?
?
?
?
POS > 15: common (2.0)?
?
?
LAST = empty: pronoun (5.0/1.0)?
SYNCAT = np-obj?
?
DIST <= 109?
?
?
POS <= 9: pronoun (23.0/12.0)?
?
?
POS > 9: common (10.0/4.0)?
?
DIST > 109: common (17.0/3.0)SENT = false...Figure 1: Part of the decision treeThe results of all three learning techniques aresignificant better than the base line which has in av-erage an accuracy of 0.47.
The multi layer percep-tron provides the best results with an average accu-racy of 0.66.ReferencesG.
F. Cooper and E. Herskovits.
1992.
A BayesianMethod for the Induction of Probabilistic Networksfrom Data.
In Machine Learning 9.M.
Minsky and S. Papert.
1969.
Perceptrons.
MIT Press.J.
R. Quinlan.
1993.
C4.5 Programs for Machine Learn-ing.
Morgan Kaufmann, California.Set Cities Cou.
Mount.
Peo.
Ri.
TotalAcc 0.545 0.64 0.65 0.668 0.8 0.66Table 4: IS-G: Multi Layer Perceptron193
