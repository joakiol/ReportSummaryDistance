Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 1?11,Austin, Texas, November 1-5, 2016. c?2016 Association for Computational LinguisticsSpan-Based Constituency Parsing with a Structure-Label System andProvably Optimal Dynamic OraclesJames Cross and Liang HuangSchool of EECS, Oregon State University, Corvallis, OR, USA{james.henry.cross.iii, liang.huang.sh}@gmail.comAbstractParsing accuracy using efficient greedy transi-tion systems has improved dramatically in re-cent years thanks to neural networks.
Despitestriking results in dependency parsing, how-ever, neural models have not surpassed state-of-the-art approaches in constituency parsing.To remedy this, we introduce a new shift-reduce system whose stack contains merelysentence spans, represented by a bare min-imum of LSTM features.
We also designthe first provably optimal dynamic oracle forconstituency parsing, which runs in amortizedO(1) time, compared to O(n3) oracles forstandard dependency parsing.
Training withthis oracle, we achieve the best F1 scores onboth English and French of any parser thatdoes not use reranking or external data.1 IntroductionParsing is an important problem in natural languageprocessing which has been studied extensively fordecades.
Between the two basic paradigms of pars-ing, constituency parsing, the subject of this paper,has in general proved to be the more difficult thandependency parsing, both in terms of accuracy andthe run time of parsing algorithms.There has recently been a huge surge of interestin using neural networks to make parsing decisions,and such models continue to dominate the state ofthe art in dependency parsing (Andor et al, 2016).In constituency parsing, however, neural approachesare still behind the state-of-the-art (Carreras et al,2008; Shindo et al, 2012; Thang et al, 2015); seemore details in Section 5.To remedy this, we design a new parsing frame-work that is more suitable for constituency parsing,and that can be accurately modeled by neural net-works.
Observing that constituency parsing is pri-marily focused on sentence spans (rather than indi-vidual words, as is dependency parsing), we proposea novel adaptation of the shift-reduce system whichreflects this focus.
In this system, the stack consistsof sentence spans rather than partial trees.
It is alsofactored into two types of parser actions, structuraland label actions, which alternate during a parse.The structural actions are a simplified analogue ofshift-reduce actions, omitting the directionality ofreduce actions, while the label actions directly as-sign nonterminal symbols to sentence spans.Our neural model processes the sentence once foreach parse with a recurrent network.
We representparser configurations with a very small number ofspan features (4 for structural actions and 3 for labelactions).
Extending Wang and Chang (2016), eachspan is represented as the difference of recurrent out-put from multiple layers in each direction.
No pre-trained embeddings are required.We also extend the idea of dynamic oracles fromdependency to constituency parsing.
The latter issignificantly more difficult than the former due to F1being a combination of precision and recall (Huang,2008), and yet we propose a simple and extremelyefficient oracle (amortizedO(1) time).
This oracle isproved optimal for F1 as well as both of its compo-nents, precision and recall.
Trained with this oracle,our parser achieves what we believe to be the bestresults for any parser without reranking which wastrained only on the Penn Treebank and the FrenchTreebank, despite the fact that it is not only linear-time, but also strictly greedy.We make the following main contributions:?
A novel factored transition parsing systemwhere the stack elements are sentence spansrather than partial trees (Section 2).?
A neural model where sentence spans are rep-resented as differences of output from a multi-layer bi-directional LSTM (Section 3).?
The first provably optimal dynamic oracle for1constituency parsing which is also extremelyefficient (amortized O(1) time) (Section 4).?
The best F1 scores of any single-model, closedtraining set, parser for English and French.We are also publicly releasing the source code forone implementation of our parser.12 Parsing SystemWe present a new transition-based system for con-stituency parsing whose fundamental unit of com-putation is the sentence span.
It uses a stack in asimilar manner to other transition systems, exceptthat the stack contains sentence spans with no re-quirement that each one correspond to a partial treestructure during a parse.The parser alternates between two types of ac-tions, structural and label, where the structural ac-tions follow a path to make the stack spans corre-spond to sentence phrases in a bottom-up manner,while the label actions optionally create tree brack-ets for the top span on the stack.
There are only twostructural actions: shift is the same as other transi-tion systems, while combine merges the top two sen-tence spans.
The latter is analogous to a reduce ac-tion, but it does not immediately create a tree struc-ture and is non-directional.
Label actions do createa partial tree on top of the stack by assigning one ormore non-terminals to the topmost span.Except for the use of spans, this factored approachis similar to the odd-even parser from Mi and Huang(2015).
The fact that stack elements do not have tobe tree-structured, however, means that we can cre-ate productions with arbitrary arity, and no binariza-tion is required either for training or parsing.
Thisalso allows us to remove the directionality inherentin the shift-reduce system, which is at best an im-perfect fit for constituency parsing.
We do followthe practice in that system of labeling unary chainsof non-terminals with a single action, which meansour parser uses a fixed number of steps, (4n?
2) fora sentence of n words.Figure 1 shows the formal deductive system forthis parser.
The stack ?
is modeled as a list of strictlyincreasing integers whose first element is always1code: https://github.com/jhcross/span-parserinput: w0 .
.
.
wn?1axiom: ?0, [0], ?
?goal: ?2(2n?
1), [0, n], t?sh?z, ?
|j, t?
?z + 1, ?
|j |j+1, t?
j < n, even zcomb?z, ?
| i |k |j, t?
?z + 1, ?
| i |j, t?
even zlabel-X ?z, ?
| i |j, t?
?z + 1, ?
| i |j, t ?
{ iXj}?
odd znolabel?z, ?
| i |j, t?
?z + 1, ?
| i |j, t?
z<(4n?1), odd zFigure 1: Deductive system for the Structure/Label transitionparser.
The stack ?
is represented as a list of integers where thespan defined by each consecutive pair of elements is a sentencesegment on the stack.
Each X is a nonterminal symbol or anordered unary chain.
The set t contains labeled spans of theform iXj , which at the end of a parse, fully define a parse tree.zero.
These numbers are word boundaries which de-fine the spans on the stack.
In a slight abuse of no-tation, however, we sometimes think of it as a list ofpairs (i, j), which are the actual sentence spans, i.e.,every consecutive pair of indices on the stack, ini-tially empty.
We represent stack spans by trapezoids(iSome text and the symbol or scaled1j) in th figures to emphasize that they may ornot have tree stucture.The parser alternates between structural actionsand label actions according to the parity of the parserstep z.
In even steps, it takes a structural action, ei-ther combining the top two stack spans, which re-quires at least two spans on the stack, or introducinga new span of unit length, as long as the entire sen-tence is not already represented on the stackIn odd steps, the parser takes a label action.
Onepossibility is labeling the top span on the stack, (i, j)with either a nonterminal label or an ordered unarychain (since the parser has only one opportunity tolabel any given span).
Taking no action, designatednolabel, is also a possibility.
This is essentially anull operation except that it returns the parser to aneven step, and this action reflects the decision that(i, j) is not a (complete) labeled phrase in the tree.In the final step, (4n ?
2), nolabel is not allowed2SVPSVPNPNN4 fish 5VBG3 eatingVBP2 likeMD1 doNPPRP0 Isteps structural action label action stack after bracket1?2 sh(I/PRP) label-NP 0Some text and the symbol or scaled11 0NP13?4 sh(do/MD) nolabel 0Some text and the symbol or scaled11Some text and the symbol or scaled125?6 sh(like/VBP) nolabel 0Some text and the symbol or scaled11Some text and the symbol or scaled12Some text and the symbol or scaled137?8 comb nolabel 0Some text and the symbol or scaled11Some text and the symbol or scaled139?10 sh(eating/VBG) nolabel 0Some text and the symbol or scaled11Some text and the symbol or scaled13Some text and the symbol or scaled1411?12 sh(fish/NN) label-NP 0Some text and the symbol or scaled11Some t xt and the symbol or scaled13Some text and the symbol or scaled14Some text and the ymbol or scaled15 4NP513?14 comb label-S-VP 0Some text and the symbol or scaled11Some t xt and the symbol or scaled13Some text and the symbol or scaled15 3S5, 3VP515?16 comb label-VP 0Some text and the symbol or scaled11Some t xt and the symbol or scaled15 1VP517?18 comb label-S 0Some text and the symbol or scaled15 0S5(a) gold parse tree (b) static oracle actionsFigure 2: The running example.
It contains one ternary branch and one unary chain (S-VP), and NP-PRP-I and NP-NN-fish arenot unary chains in our system.
Each stack is just a list of numbers but is visualized with spans here.since the parser must produce a tree.Figure 2 shows a complete example of applyingthis parsing system to a very short sentence (?I dolike eating fish?)
that we will use throughout thissection and the next.
The action in step 2 is label-NP because ?I?
is a one-word noun phrase (partsof speech are taken as input to our parser, thoughit could easily be adapted to include POS taggingin label actions).
If a single word is not a completephrase (e.g., ?do?
), then the action after a shift isnolabel.The ternary branch in this tree (VP?MD VBP S)is produced by our parser in a straightforward man-ner: after the phrase ?do like?
is combined in step7, no label is assigned in step 8, successfully delay-ing the creation of a bracket until the verb phrase isfully formed on the stack.
Note also that the unaryproduction in the tree is created with a single action,label-S-VP, in step 14.The static oracle to train this parser simply con-sists of taking actions to generate the gold treewith a ?short-stack?
heuristic, meaning combine firstwhenever combine and shift are both possible.3 LSTM Span FeaturesLong short-term memory networks (LSTM) are atype of recurrent neural network model proposed byHochreiter and Schmidhuber (1997) which are veryeffective for modeling sequences.
They are ableto capture and generalize from interactions amongtheir sequential inputs even when separated by along distance, and thus are a natural fit for analyz-ing natural language.
LSTM models have proved tobe a powerful tool for many learning tasks in naturallanguage, such as language modeling (Sundermeyeret al, 2012) and translation (Sutskever et al, 2014).LSTMs have also been incorporated into parsingin a variety of ways, such as directly encoding an en-tire sentence (Vinyals et al, 2015), separately mod-eling the stack, buffer, and action history (Dyer etal., 2015), to encode words based on their characterforms (Ballesteros et al, 2015), and as an elementin a recursive structure to combine dependency sub-trees with their left and right children (Kiperwasserand Goldberg, 2016a).For our parsing system, however, we need a wayto model arbitrary sentence spans in the context ofthe rest of the sentence.
We do this by representingeach sentence span as the elementwise difference ofthe vector outputs of the LSTM outputs at differenttime steps, which correspond to word boundaries.If the sequential output of the recurrent network forthe sentence is f0, ..., fn in the forward direction andbn, ..., b0 in the backward direction then the span(i, j) would be represented as the concatenation ofthe vector differences (fj ?
fi) and (bi ?
bj).The spans are represented using output from bothbackward and forward LSTM components, as canbe seen in Figure 3.
This is essentially the LSTM-Minus feature representation described by Wang andChang (2016) extended to the bi-directional case.
Ininitial experiments, we found that there was essen-tially no difference in performance between usingthe difference features and concatenating all end-3?s?
I do like eating fish ?/s?0f0b01f1b12f2b23f3b34f4b45f5b5Figure 3: Word spans are modeled by differences in LSTMoutput.
Here the span 3 eating fish 5 is represented by the vectordifferences (f5 ?
f3) and (b3 ?
b5).
The forward differencecorresponds to LSTM-Minus (Wang and Chang, 2016).point vectors, but our approach is almost twice asfast.This model allows a sentence to be processedonce, and then the same recurrent outputs can beused to compute span features throughout the parse.Intuitively, this allows the span differences to learnto represent the sentence spans in the context of therest of the sentence, not in isolation (especially truefor LSTM given the extra hidden recurrent connec-tion, typically described as a ?memory cell?).
Inpractice, we use a two-layer bi-directional LSTM,where the input to the second layer combines theforward and backward outputs from the first layerat that time step.
For each direction, the componentsfrom the first and second layers are concatenated toform the vectors which go into the span features.
SeeCross and Huang (2016) for more details on this ap-proach.For the particular case of our transition con-stituency parser, we use only four span features todetermine a structural action, and three to determinea label action, in each case partitioning the sentenceexactly.
The reason for this is straightforward: whenconsidering a structural action, the top two spans onthe stack must be considered to determine whetherthey should be combined, while for a label action,only the top span on the stack is important, since thatis the candidate for labeling.
In both cases the re-maining sentence prefix and suffix are also included.These features are shown in Table 1.The input to the recurrent network at each timestep consists of vector embeddings for each wordAction Stack LSTM Span FeaturesStructural ?
| i |k |j 02iSome text and the symbol or scaled1kSome text and the symbol or scaled1j2nLabel ?
| i |j 02iSome text and the symbol or scaled1j2nTable 1: Features used for the parser.
No label or tree-structurefeatures are required.and its part-of-speech tag.
Parts of speech are pre-dicted beforehand and taken as input to the parser,as in much recent work in parsing.
In our experi-ments, the embeddings are randomly initialized andlearned from scratch together with all other networkweights, and we would expect further performanceimprovement from incorporating embeddings pre-trained from a large external corpus.The network structure after the the span featuresconsists of a separate multilayer perceptron for eachtype of action (structural and label).
For each ac-tion we use a single hidden layer with rectified linear(ReLU) activation.
The model is trained on a per-action basis using a single correct action for eachparser state, with a negative log softmax loss func-tion, as in Chen and Manning (2014).4 Dynamic OracleThe baseline method of training our parser is whatis known as a static oracle: we simply generate thesequence of actions to correctly parse each trainingsentence, using a short-stack heuristic (i.e., combinefirst whenever there is a choice of shift and com-bine).
This method suffers from a well-documetedproblem, however, namely that it only ?prepares?the model for the situation where no mistakes havebeen made during parsing, an inevitably incorrectassumption in practice.
To alleviate this problem,Goldberg and Nivre (2013) define a dynamic oracleto return the best possible action(s) at any arbitraryconfiguration.In this section, we introduce an easy-to-computeoptimal dynamic oracle for our constituency parser.We will first define some concepts upon which thedynamic oracle is built and then show how optimalactions can be very efficiently computed using thisframework.
In broad strokes, in any arbitrary parserconfiguration c there is a set of brackets t?
(c) fromthe gold tree which it is still possible to reach.
Byfollowing dynamic oracle actions, all of those brack-ets and only those brackets will be predicted.4Even though proving the optimality of our dy-namic oracle (Sec.
4.3) is involved, computing theoracle actions is extremely simple (Secs.
4.2) andefficient (Sec.
4.4).4.1 Preliminaries and NotationsBefore describing the computation of our dynamicoracle, we first need to rigorously establish the de-sired optimality of dynamic oracle.
The structure ofthis framework follows Goldberg et al (2014).Definition 1.
We denote c `?
c?
iff.
c?
is the resultof action ?
on configuration c, also denoted func-tionally as c?
= ?(c).
We denote ` to be the unionof `?
for all actions ?
, and `?
to be the reflexive andtransitive closure of `.Definition 2 (descendant/reachable trees).
We de-note D(c) to be the set of final descendant treesderivable from c, i.e., D(c) = {t | c `?
?z, ?, t?
}.This set is also called ?reachable trees?
from c.Definition 3 (F1).
We define the standard F1 metricof a tree t with respect to gold tree tG as F1(t) =2rpr+p , where r = |t?tG||tG| , p =|t?tG||t| .The following two definitions are similar to thosefor dependency parsing by Goldberg et al (2014).Definition 4.
We extend the F1 function to config-urations to define the maximum possible F1 from agiven configuration: F1(c) = maxt1?D(c) F1(t1).Definition 5 (oracle).
We can now define the desireddynamic oracle of a configuration c to be the set ofactions that retrain the optimal F1:oracle(c) = {?
| F1(?
(c)) = F1(c)}.This abstract oracle is implemented by dyna(?)
inSec.
4.2, which we prove to be correct in Sec.
4.3.Definition 6 (span encompassing).
We say span(i, j) is encompassed by span (p, q), notated (i, j) (p, q), iff.
p ?
i < j ?
q.Definition 7 (strict encompassing).
We say span(i, j) is strictly encompassed by span (p, q), notated(i, j) ?
(p, q), iff.
(i, j)  (p, q) and (i, j) 6= (p, q).We then extend this relation from spans to brackets,and notate iXj ?
pYq iff.
(i, j) ?
(p, q).0S51VP53S/VP54NP50Some text and the symbol or scaled11Some text and the symbol or scaled12Some text and th sym l or scaled14 5I do like eating fishFigure 4: Reachable brackets (w.r.t.
gold tree in Fig.
1) forc = ?10, [0, 1, 2, 4], {0NP1}?
which mistakenly combines?like eating?.
Trapezoids indicate stack spans (the top one inred), and solid triangles denote reachable brackets, with left(c)in blue and right(c) in cyan.
The next reachable bracket,next(c) = 1VP5, is in bold.
Brackets 3VP5 and 3S5 (in dot-ted triangle) cross the top span (thus unreachable), and 0NP1 isalready recognized (thus not in reach(c) either).We next define a central concept, reachablebrackets, which is made up of two parts, the left onesleft(c) which encompass (i, j) without crossing anystack spans, and the right ones right(c) which arecompletely on the queue.
See Fig.
4 for examples.Definition 8 (reachable brackets).
For any configu-ration c = ?z, ?
| i |j, t?, we define the set of reach-able gold brackets (with respect to gold tree tG) asreach(c) = left(c) ?
right(c)where the left- and right-reachable brackets areleft(c)={pXq ?
tG | (i, j) ?
(p, q), p ?
?
| i}right(c)={pXq ?
tG | p ?
j}for even z, with the ?
replaced by  for odd z.Special case (initial): reach(?0, [0], ??)
= tG.The notation p ?
?
| i simply means (p, q) doesnot ?cross?
any bracket on the stack.
Remember ourstack is just a list of span boundaries, so if p coin-cides with one of them, (p, q)?s left boundary is notcrossing and its right boundary q is not crossing ei-ther since q ?
j due to (i, j) ?
(p, q).Also note that reach(c) is strictly disjoint from t,i.e., reach(c) ?
t = ?
and reach(c) ?
tG ?
t. SeeFigure 6 for an illustration.5Definition 9 (next bracket).
For any configurationc = ?z, ?
| i |j, t?, the next reachable gold bracket(with respect to gold tree tG) is the smallest reach-able bracket (strictly) encompassing (i, j):next(c) = min?
left(c).4.2 Structural and Label OraclesFor an even-step configuration c = ?z, ?
| i | j, t?,we denote the next reachable gold bracket next(c)to be pXq, and define the dynamic oracle to be:dyna(c) =?????
{sh} if p = i and q > j{comb} if p < i and q = j{sh, comb} if p < i and q > j(1)As a special case dyna(?0, [0], ??)
= {sh}.Figure 5 shows examples of this policy.
The keyinsight is, if you follow this policy, you will not missthe next reachable bracket, but if you do not followit, you certainly will.
We formalize this fact below(with proof omitted due to space constraints) whichwill be used to prove the central results later.Lemma 1.
For any configuration c, for any ?
?dyna(c), we have reach(?
(c)) = reach(c); for any?
?
/?
dyna(c), we have reach(?
(c)) ( reach(c).The label oracles are much easier than struc-tural ones.
For an odd-step configuration c =?z, ?
| i | j, t?, we simply check if (i, j) is a validspan in the gold tree tG and if so, label it accord-ingly, otherwise no label.
More formally,dyna(c) ={{label-X} if some iXj ?
tG{nolabel} otherwise (2)4.3 CorrectnessTo show the optimality of our dynamic oracle, webegin by defining a special tree t?
(c) and show thatit is optimal among all trees reachable from config-uration c. We then show that following our dynamicoracle (Eqs.
1?2) from c will lead to t?
(c).Definition 10 (t?(c)).
For any configuration c =?z, ?, t?, we define the optimal tree t?
(c) to includeall reachable gold brackets and nothing else.
Moreformally, t?
(c) = t ?
reach(c).configuration oraclestatic dynamic0Some t xt and t e symbol or scaled11Some text and the symbol or scaled12Some text and the symbol or scaled13 comb {comb, sh}I do like 1?52Some text and the symbol or scaled130Some text and the symbol or scaled11Some text and the sym ol or scaled13undef.
{sh}I do liket={..., 1VP3}1?5Some text and the symbol or scaled130Some text and the symbol or scaled11Some te t and the symbol or scaled12Som t xt and th sym l or scaled14 {comb, sh}I do like eating 1?52Some text and the symbol or scaled140Some text and the symbol or scaled11Some text and the symbol or scaled12Some text and the sym ol or scaled14Some text and the symbol o scaled15 {comb}I do like eating fish 1?54Some text and the symbol or scaled1Figure 5: Dynamic oracle with respect to the gold parse inFig.
2.
The last three examples are off the gold path with strikeout indicating structural or label mistakes.
Trapezoids denotestack spans (top one in red) and the blue triangle denotes thenext reachable bracket next(c) which is 1VP5 in all cases.We can show by induction that t?
(c) is attainable:Lemma 2.
For any configuration c, the optimal treeis a descendant of c, i.e., t?
(c) ?
D(c).The following Theorem shows that t?
(c) is indeedthe best possible tree:Theorem 1 (optimality of t?).
For any configura-tion c, F1(t?
(c)) = F1(c).Proof.
(SKETCH) Since t?
(c) adds all possible addi-tional gold brackets (the brackets in reach(c)), it isnot possible to get higher recall.
Since it adds no in-correct brackets, it is not possible to get higher pre-t tG reach(c)t?
(c) = t ?
reach(c)Figure 6: The optimal tree t?
(c) adds all reachable bracketsand nothing else.
Note that reach(c) and t are disjoint.6cision.
Since F1 is the harmonic mean of precisionand recall, it also leads to the best possible F1.Corollary 1.
For any c = ?z, ?, t?, for any t?
?D(c) and t?
6= t?
(c), we have F1(t?)
< F1(c).We now need a final lemma about the policydyna(?)
(Eqs.
1?2) before proving the main result.Lemma 3.
From any c = ?z, ?, t?, for any action?
?
dyna(c), we have t?(?
(c)) = t?(c).
For anyaction ?
?
/?
dyna(c), we have t?(?
?
(c)) 6= t?(c).Proof.
(SKETCH) By case analysis on even/odd z.We are now able to state and prove the main the-oretical result of this paper (using Lemma 3, Theo-rem 1 and Corollary 1):Theorem 2.
The function dyna(?)
in Eqs.
(1?2) sat-isfies the requirement of a dynamic oracle (Def.
5):dyna(c) = oracle(c) for any configuration c.4.4 Implementation and ComplexityFor any configuration, our dynamic oracle can becomputed in amortized constant time since thereare only O(n) gold brackets and thus bounding|reach(c)| and the choice of next(c).
After eachaction, next(c) either remains unchanged, or inthe case of being crossed by a structural action ormislabeled by a label action, needs to be updated.This update is simply tracing the parent link tothe next smallest gold bracket repeatedly until thenew bracket encompasses span (i, j).
Since thereare at most O(n) choices of next(c) and there areO(n) steps, the per-step cost is amortized constanttime.
Thus our dynamic oracle is much faster thanthe super-linear time oracle for arc-standard depen-dency parsing in Goldberg et al (2014).5 Related WorkNeural networks have been used for constituencyparsing in a number of previous instances.
Forexample, Socher et al (2013) learn a recursivenetwork that combines vectors representing partialtrees, Vinyals et al (2015) adapt a sequence-to-sequence model to produce parse trees, Watanabeand Sumita (2015) use a recursive model applyinga shift-reduce system to constituency parsing withNetwork architectureWord embeddings 50Tag embeddings 20Morphological embeddings?
10LSTM layers 2LSTM units 200 / directionReLU hidden units 200 / action typeTraining settingsEmbedding intialization randomTraining epochs 10Minibatch size 10 sentencesDropout (on LSTM output) p = 0.5ADADELTA parameters ?
= 0.99,  = 1?
10?7Table 2: Hyperparameters.
?French only.beam search, and Dyer et al (2016) adapt the Stack-LSTM dependency parsing approach to this task.Durrett and Klein (2015) combine both neural andsparse features for a CKY parsing system.
Our ownprevious work (Cross and Huang, 2016) use a recur-rent sentence representation in a head-driven tran-sition system which allows for greedy parsing butdoes not achieve state-of-the-art results.The concept of ?oracles?
for constituency parsing(as the tree that is most similar to tG among all pos-sible trees) was first defined and solved by Huang(2008) in bottom-up parsing.
In transition-basedparsing, the dynamic oracle for shift-reduce depen-dency parsing costs worst-case O(n3) time (Gold-berg et al, 2014).
On the other hand, after the sub-mission of our paper we became aware of a paral-lel work (Coavoux and Crabbe?, 2016) that also pro-posed a dynamic oracle for their own incrementalconstituency parser.
However, it is not optimal dueto dummy non-terminals from binarization.6 ExperimentsWe present experiments on both the Penn EnglishTreebank (Marcus et al, 1993) and the French Tree-bank (Abeille?
et al, 2003).
In both cases, all state-action training pairs for a given sentence are usedat the same time, greatly increasing training speedsince all examples for the same sentence share thesame forward and backward pass through the recur-rent part of the network.
Updates are performedin minibatches of 10 sentences, and we shuffle thetraining sentences before each epoch.
The resultswe report are trained for 10 epochs.7The only regularization which we employ duringtraining is dropout (Hinton et al, 2012), which isapplied with probability 0.5 to the recurrent outputs.It is applied separately to the input to the secondLSTM layer for each sentence, and to the input tothe ReLU hidden layer (span features) for each state-action pair.
We use the ADADELTA method (Zeiler,2012) to schedule learning rates for all weights.
Allof these design choices are summarized in Table 2.In order to account for unknown words duringtraining, we also adopt the strategy described byKiperwasser and Goldberg (2016b), where wordsin the training set are replaced with the unknown-word symbol UNK with probability punk = zz+f(w)where f(w) is the number of times the word ap-pears in the training corpus.
We choose the pa-rameter z so that the training and validation cor-pora have approximately the same proportion of un-known words.
For the Penn Treebank, for exam-ple, we used z = 0.8375 so that both the validationset and the (rest of the) training set contain approx-imately 2.76% unknown words.
This approach washelpful but not critical, improving F1 (on dev) byabout 0.1 over training without any unknown words.6.1 Training with Dynamic OracleThe most straightforward use of dynamic oracles totrain a neural network model, where we collect allaction examples for a given sentence before updat-ing, is ?training with exploration?
as proposed byGoldberg and Nivre (2013).
This involves parsingeach sentence according to the current model and us-ing the oracle to determine correct actions for train-ing.
We saw very little improvement on the Penntreebank validation set using this method, however.Based on the parsing accuracy on the training sen-tences, this appears to be due to the model overfittingthe training data early during training, thus negatingthe benefit of training on erroneous paths.Accordingly, we also used a method recently pro-posed by Ballesteros et al (2016), which specifi-cally addresses this problem.
This method intro-duces stochasticity into the training data parses byrandomly taking actions according to the softmaxdistribution over action scores.
This introduces re-alistic mistakes into the training parses, which wefound was also very effective in our case, leadingto higher F1 scores, though it noticeably sacrificesrecall in favor of precision.This technique can also take a parameter ?
to flat-ten or sharpen the raw softmax distribution.
The re-sults on the Penn treebank development set for var-ious values of ?
are presented in Table 3.
We weresurprised that flattening the distribution seemed tobe the least effective, as training accuracy (takinginto account sampled actions) lagged somewhat be-hind validation accuracy.
Ultimately, the best resultswere for ?
= 1, which we used for final testing.Model LR LP F1Static Oracle 91.34 91.43 91.38Dynamic Oracle 91.14 91.61 91.38+ Explore (?=0.5) 90.59 92.18 91.38+ Explore (?=1.0) 91.07 92.22 91.64+ Explore (?=1.5) 91.07 92.12 91.59Table 3: Comparison of performance on PTB development setusing different oracle training approaches.6.2 Penn TreebankFollowing the literature, we used the Wall StreetJournal portion of the Penn Treebank, with stan-dard splits for training (secs 2?21), development(sec 22), and test sets (sec 23).
Because our pars-ing system seamlessly handles non-binary produc-tions, minimal data preprocessing was required.
Forthe part-of-speech tags which are a required input toour parser, we used the Stanford tagger with 10-wayjackknifing.Table 4 compares test our results on PTB to arange of other leading constituency parsers.
De-spite being a greedy parser, when trained using dy-namic oracles with exploration, it achieves the bestF1 score of any closed-set single-model parser.6.3 French TreebankWe also report results on the French treebank, withone small change to network structure.
Specifically,we also included morphological features for eachword as input to the recurrent network, using a smallembedding for each such feature, to demonstratethat our parsing model is able to exploit such ad-ditional features.We used the predicted morphological features,part-of-speech tags, and lemmas (used in place ofword surface forms) supplied with the SPMRL 20148Closed Training & Single Model LR LP F1Sagae and Lavie (2006) 88.1 87.8 87.9Petrov and Klein (2007) 90.1 90.3 90.2Carreras et al (2008) 90.7 91.4 91.1Shindo et al (2012) 91.1?Socher et al (2013) 90.4Zhu et al (2013) 90.2 90.7 90.4Mi and Huang (2015) 90.7 90.9 90.8?Watanabe and Sumita (2015) 90.7Thang et al (2015) (A*) 90.9 91.2 91.1?
*Dyer et al (2016) (discrim.)
89.8?
*Cross and Huang (2016) 90.0?
*static oracle 90.7 91.4 91.0?
*dynamic/exploration 90.5 92.1 91.3External/Reranking/Combo?Henderson (2004) (rerank) 89.8 90.4 90.1McClosky et al (2006) 92.2 92.6 92.4Zhu et al (2013) (semi) 91.1 91.5 91.3Huang (2008) (forest) 91.7?Vinyals et al (2015) (WSJ)?
90.5?Vinyals et al (2015) (semi) 92.8?Durrett and Klein (2015)?
91.1?Dyer et al (2016) (gen.
rerank.)
92.4Table 4: Comparison of performance of different parsers onPTB test set.
?Neural.
*Greedy.
?External embeddings.Parser LR LP F1Bjo?rkelund et al (2014)?,?
82.53Durrett and Klein (2015)?
81.25Coavoux and Crabbe?
(2016) 80.56static oracle 83.50 82.87 83.18dynamic/exploration 81.90 84.77 83.31Table 5: Results on French Treebank.
?reranking, ?external.data set (Seddah et al, 2014).
It is thus possible thatresults could be improved further using an integratedor more accurate predictor for those features.
Ourparsing and evaluation also includes predicting POStags for multi-word expressions as is the standardpractice for the French treebank, though our resultsare similar whether or not this aspect is included.We compare our parser with other recent work inTable 5.
We achieve state-of-the-art results even incomparison to Bjo?rkelund et al (2014), which uti-lized both external data and reranking in achievingthe best results in the SPMRL 2014 shared task.6.4 Notes on ExperimentsFor these experiments, we performed very little hy-perparameter tuning, due to time and resource con-traints.
We have every reason to believe that per-formance could be improved still further with suchtechniques as random restarts, larger hidden lay-ers, external embeddings, and hyperparameter gridsearch, as demonstrated by Weiss et al (2015).We also note that while our parser is very accu-rate even with greedy decoding, the model is eas-ily adaptable for beam search, particularly since theparsing system already uses a fixed number of ac-tions.
Beam search could also be made considerablymore efficient by caching post-hidden-layer featurecomponents for sentence spans, essentially using theprecomputation trick described by Chen and Man-ning (2014), but on a per-sentence basis.7 Conclusion and Future WorkWe have developed a new transition-based con-stituency parser which is built around sentencespans.
It uses a factored system alternating betweenstructural and label actions.
We also describe a fastdynamic oracle for this parser which can determinethe optimal set of actions with respect to a goldtraining tree in an arbitrary state.
Using an LSTMmodel and only a few sentence spans as features, weachieve state-of-the-art accuracy on the Penn Tree-bank for all parsers without reranking, despite usingstrictly greedy inference.In the future, we hope to achieve still better re-sults using beam search, which is relatively straight-forward given that the parsing system already usesa fixed number of actions.
Dynamic programming(Huang and Sagae, 2010) could be especially pow-erful in this context given the very simple featurerepresentation used by our parser, as noted also byKiperwasser and Goldberg (2016b).AcknowledgmentsWe thank the three anonymous reviewers for com-ments, Kai Zhao, Lemao Liu, Yoav Goldberg, andSlav Petrov for suggestions, Juneki Hong for proof-reading, and Maximin Coavoux for sharing theirmanuscript.
This project was supported in partby NSF IIS-1656051, DARPA FA8750-13-2-0041(DEFT), and a Google Faculty Research Award.9ReferencesAnne Abeille?, Lionel Cle?ment, and Franc?ois Toussenel.2003.
Building a treebank for french.
In Treebanks,pages 165?187.
Springer.Daniel Andor, Chris Alberti, David Weiss, AliakseiSeveryn, Alessandro Presta, Kuzman Ganchev, SlavPetrov, and Michael Collins.
2016.
Globally normal-ized transition-based neural networks.
Proceedings ofACL.Miguel Ballesteros, Chris Dyer, and Noah A Smith.2015.
Improved transition-based parsing by modelingcharacters instead of words with lstms.
arXiv preprintarXiv:1508.00657.Miguel Ballesteros, Yoav Goldberg, Chris Dyer, andNoah A Smith.
2016.
Training with explorationimproves a greedy stack-lstm parser.
arXiv preprintarXiv:1603.03793.Anders Bjo?rkelund, Ozlem Cetinoglu, Agnieszka Falen-ska, Richa?rd Farkas, Thomas Mueller, WolfgangSeeker, and Zsolt Sza?nto?.
2014.
Introducing the ims-wroc?aw-szeged-cis entry at the spmrl 2014 sharedtask: Reranking and morpho-syntax meet unlabeleddata.
In Proceedings of the First Joint Workshopon Statistical Parsing of Morphologically Rich Lan-guages and Syntactic Analysis of Non-Canonical Lan-guages, pages 97?102.Xavier Carreras, Michael Collins, and Terry Koo.
2008.Tag, dynamic programming, and the perceptron forefficient, feature-rich parsing.
In Proceedings of theTwelfth Conference on Computational Natural Lan-guage Learning, pages 9?16.
Association for Compu-tational Linguistics.Danqi Chen and Christopher D Manning.
2014.
Afast and accurate dependency parser using neural net-works.
In Empirical Methods in Natural LanguageProcessing (EMNLP).Maximin Coavoux and Beno?
?t Crabbe?.
2016.
Neuralgreedy constituent parsing with dynamic oracles.
Pro-ceedings of ACL.James Cross and Liang Huang.
2016.
Incremental pars-ing with minimal features using bi-directional lstm.Proceedings of ACL.Greg Durrett and Dan Klein.
2015.
Neural crf parsing.Proceedings of ACL.Chris Dyer, Miguel Ballesteros, Wang Ling, AustinMatthews, and Noah A Smith.
2015.
Transition-baseddependency parsing with stack long short-term mem-ory.
Empirical Methods in Natural Language Process-ing (EMNLP).Chris Dyer, Adhiguna Kuncoro, Miguel Ballesteros, andNoah A Smith.
2016.
Recurrent neural network gram-mars.
Proceedings of HLT-NAACL.Yoav Goldberg and Joakim Nivre.
2013.
Trainingdeterministic parsers with non-deterministic oracles.Transactions of the association for ComputationalLinguistics, 1:403?414.Yoav Goldberg, Francesco Sartorio, and Giorgio Satta.2014.
A tabular method for dynamic oracles intransition-based parsing.
Trans.
of ACL.James Henderson.
2004.
Discriminative training of aneural network statistical parser.
In Proceedings ofACL.Geoffrey E. Hinton, Nitish Srivastava, Alex Krizhevsky,Ilya Sutskever, and Ruslan Salakhutdinov.
2012.
Im-proving neural networks by preventing co-adaptationof feature detectors.
CoRR, abs/1207.0580.Sepp Hochreiter and Ju?rgen Schmidhuber.
1997.
Longshort-term memory.
Neural computation, 9(8):1735?1780.Liang Huang and Kenji Sagae.
2010.
Dynamic program-ming for linear-time incremental parsing.
In Proceed-ings of ACL 2010.Liang Huang.
2008.
Forest reranking: Discriminativeparsing with non-local features.
In Proceedings of theACL: HLT, Columbus, OH, June.Eliyahu Kiperwasser and Yoav Goldberg.
2016a.
Easy-first dependency parsing with hierarchical tree lstms.arXiv preprint arXiv:1603.00375.Eliyahu Kiperwasser and Yoav Goldberg.
2016b.
Sim-ple and accurate dependency parsing using bidi-rectional LSTM feature representations.
CoRR,abs/1603.04351.Mitchell P Marcus, Mary Ann Marcinkiewicz, and Beat-rice Santorini.
1993.
Building a large annotated cor-pus of english: The penn treebank.
Computational lin-guistics, 19(2):313?330.David McClosky, Eugene Charniak, and Mark Johnson.2006.
Reranking and self-training for parser adapta-tion.
In Proceedings of the 21st International Con-ference on Computational Linguistics and the 44thannual meeting of the Association for ComputationalLinguistics, pages 337?344.
Association for Computa-tional Linguistics.Haitao Mi and Liang Huang.
2015.
Shift-reduce con-stituency parsing with dynamic programming and postag lattice.
In Proceedings of the 2015 Conferenceof the North American Chapter of the Association forComputational Linguistics: Human Language Tech-nologies.Slav Petrov and Dan Klein.
2007.
Improved inferencefor unlexicalized parsing.
In Proceedings of HLT-NAACL.Kenji Sagae and Alon Lavie.
2006.
A best-first prob-abilistic shift-reduce parser.
In Proceedings of theCOLING/ACL on Main conference poster sessions,pages 691?698.
Association for Computational Lin-guistics.10Djame?
Seddah, Sandra Ku?bler, and Reut Tsarfaty.
2014.Introducing the spmrl 2014 shared task on parsingmorphologically-rich languages.
In Proceedings of theFirst Joint Workshop on Statistical Parsing of Mor-phologically Rich Languages and Syntactic Analysisof Non-Canonical Languages, pages 103?109.Hiroyuki Shindo, Yusuke Miyao, Akinori Fujino, andMasaaki Nagata.
2012.
Bayesian symbol-refined treesubstitution grammars for syntactic parsing.
In Pro-ceedings of the 50th Annual Meeting of the Associationfor Computational Linguistics: Long Papers-Volume1, pages 440?448.
Association for Computational Lin-guistics.Richard Socher, John Bauer, Christopher D Manning, andAndrew Y Ng.
2013.
Parsing with compositional vec-tor grammars.
In ACL (1), pages 455?465.Martin Sundermeyer, Ralf Schlu?ter, and Hermann Ney.2012.
Lstm neural networks for language modeling.In INTERSPEECH, pages 194?197.Ilya Sutskever, Oriol Vinyals, and Quoc V Le.
2014.Sequence to sequence learning with neural networks.In Advances in neural information processing systems,pages 3104?3112.Le Quang Thang, Hiroshi Noji, and Yusuke Miyao.2015.
Optimal shift-reduce constituent parsing withstructured perceptron.Oriol Vinyals, ?ukasz Kaiser, Terry Koo, Slav Petrov,Ilya Sutskever, and Geoffrey Hinton.
2015.
Grammaras a foreign language.
In Advances in Neural Informa-tion Processing Systems, pages 2755?2763.Wenhui Wang and Baobao Chang.
2016.
Graph-baseddependency parsing with bidirectional lstm.
In Pro-ceedings of ACL.Taro Watanabe and Eiichiro Sumita.
2015.
Transition-based neural constituent parsing.
Proceedings of ACL-IJCNLP.David Weiss, Chris Alberti, Michael Collins, and SlavPetrov.
2015.
Structured training for neural networktransition-based parsing.
In Proceedings of ACL.Matthew D. Zeiler.
2012.
ADADELTA: an adaptivelearning rate method.
CoRR, abs/1212.5701.Muhua Zhu, Yue Zhang, Wenliang Chen, Min Zhang, andJingbo Zhu.
2013.
Fast and accurate shift-reduce con-stituent parsing.
In ACL (1), pages 434?443.11
