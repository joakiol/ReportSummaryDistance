Proceedings of the Fourth Workshop on Teaching Natural Language Processing, pages 56?60,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsTreebanking for Data-driven Research in the ClassroomJohn Lee, Ying Cheuk Hui, Yin Hei KongHalliday Centre for Intelligent Applications of Language StudiesDepartment of Chinese, Translation and LinguisticsCity University of Hong Kong{jsylee,yingchui,yhkong}@cityu.edu.hkAbstractData-driven research in linguistics typicallyinvolves the processes of data annotation, datavisualization and identification of relevant pat-terns.
We describe our experience in incorpo-rating these processes at an undergraduatecourse on language information technology.Students collectively annotated the syntacticstructures of a set of Classical Chinese poems;the resulting treebank was put on a platformfor corpus search and visualization; finally, us-ing this platform, students investigated re-search questions about the text of the treebank.1 IntroductionTreebanks are now increasingly used as peda-gogical tools (Crane et al 2012), chiefly in twoways.
On the one hand, in linguistics courses,students may use existing treebanks to performquantitative analysis on syntactic patterns.
Onthe other, in language courses, students may an-notate syntactic structures to reinforce grammati-cal concepts, creating new treebanks.
In this pa-per, we describe our experience in integratingthese two processes into a research project in anundergraduate course, and discuss its benefitsand challenges.The project formed part of a course entitled?Language Information Technology?.
With noprevious training, students collectively annotatedthe dependency structures of a portion of theThree Hundred Tang Poems, a popular antholo-gy of Classical Chinese poems.
The instructoredited the annotations, compiled them into a de-pendency treebank, and made it available forsearch and visualization on a web-based inter-face.
Then, in a research assignment, studentstackled questions on Chinese poetry with thistreebank, which they had created with their ownhands.Combining the creation of a treebank with itsuse in a research assignment has many benefits.With respect to pedagogy, the assignmentdemonstrates to students the practical rationalefor treebanks; the treebanking exercise familiar-ized students with the data and annotationscheme, helping them perform better on the as-signment.
With respect to longer-term effects,students perceive their own, tangible contributionto a field of scholarly research, in the form oflinguistic annotations that are reusable by otherscholars.
The hands-on practice of a novel re-search methodology --- data-driven study in lin-guistics and literature --- should encourage themto apply it in their future fields of study.The rest of the paper is organized as follows.Section 2 outlines previous use of treebanks inthe classroom.
Section 3 describes how ourcourse was structured.
Section 4 explains howstudents created the treebank, which formed thebasis of the research assignment discussed insection 5.
Section 6 presents the lessons learnedand concludes.2 Previous WorkMany current systems support the use of linguis-tic corpora for teaching and learning.
One ofmany examples, the Visual Interactive SyntaxLearning (VISL) system allows students tosearch, view, construct and label parse trees(Bick, 2005).
The GATE system similarly facili-tates corpus annotation, but it can also perform avariety of NLP tasks including POS tagging andparsing (Bontcheva et al 2002).These systems facilitate pedagogical use oftreebanks in two main ways.
First, students vis-ualize parse trees and search for linguistic struc-tures on existing treebanks.
These functions56support empirical and quantitative analysis oflinguistic phenomena.
Second, students also usetheir editing environment to create new depend-ency annotations on text, as exercises in learninga new language.
The resulting treebank can thenbe made available for all scholars.The latter type of usage has been implementedin Classics courses at six American universities.Students made dependency annotations on a Lat-in or Greek text, which the instructor then recon-ciled.
The results contributed to the Latin andAncient Greek Dependency Treebanks that arebeing compiled at the Perseus Project.
In a studyon 13 students, who had received limited train-ing, the inter-annotator accuracy averaged 54.5%(Bamman & Crane, 2010).Treebanking itself has also been taught in acourse (Volk et al 2005).
Another notable casewhere students collectively created new linguis-tic resources has been reported at a graduatecourse in multilingual grammar engineering(Bender, 2007).
Each student developed agrammar for automatic parsing of a new lan-guage.
Over time, students?
work was found tobe effective in bringing feedback to the coregrammar, and to facilitate empirical research oncross-linguistic comparisons.A significant novelty in our course design isthat, after students create new annotations for atreebank, they share the data with the rest of theclass, and apply the freshly compiled treebankfor linguistic research.
We now describe howthese two processes were implemented.3 Course StructureThe project described in this paper was integrat-ed into ?Language Information Technology?, anundergraduate course offered at the Departmentof Chinese, Translation and Linguistics at CityUniversity of Hong Kong.
In the past semester,44 students were enrolled.
All majored in theChinese language.
As can be expected in a hu-manities department, the students had no tech-nical background or experience in natural lan-guage processing.
While some had previouslytaken linguistics courses, none was familiar withdependency grammar or its annotation scheme.The course lasted for 13 weeks; weekly meet-ings consisted of a one-hour lecture and a two-hour tutorial or practicum.
Roughly one half ofthis course was devoted to the treebanking pro-ject.
In the first week, part-of-speech (POS) tag-ging was introduced, with English as the exam-ple language.
During the practicum, studentsreviewed POS concepts with exercises and Stan-ford?s online tagger1.
In the second, dependencytrees were introduced, again using examples inEnglish.
Lectures in the third and fourth weeksturned the attention to Chinese POS and depend-ency trees, using respectively the schemes de-fined at the Penn Chinese Treebank (Xue et al2005) and Stanford (Chang et al 2009).
Duringthe practicums, adaptations to these schemes forClassical Chinese (Lee, 2012; Lee & Kong,2012) were presented.
In the fifth week, the webinterface for searching and visualizing treebanks,which would later be used for a research assign-ment (see section 5), was demonstrated.
Also,students were assigned individual texts for POStagging and dependency labeling (see section 4).The practicum was devoted to discussions ondifficulties in annotation.The annotations were due two weeks later.After editing by the instructor, the treebank wasposted on the aforementioned web interface, andthe assignment was released.
Overall, each stu-dent received 15 hours of class time in prepara-tion for the treebanking project.4 Treebank AnnotationThe first task of the students, described in thissection, is to annotate dependency structures of aset of Classical Chinese texts.
The newly createdtreebank would then be used in a second task, tobe discussed in the next section.4.1 Choice of MaterialAmong the various literary genres, poetry enjoysperhaps the most elevated status in the ClassicalChinese tradition.
320 poems from the TangDynasty, considered the golden age for poetry,have been grouped together in an anthology re-ferred to as the Three Hundred Tang Poems.This anthology is perhaps the most well-knownin the canon of Classical Chinese literature, andis featured without exception in the Chinese cur-riculum in secondary schools.For the treebanking project, this corpus is ide-al because it is both non-toy and not prohibitive-ly difficult.
As well-known literary heritage, thiscorpus lends interesting and significant questionsto the research assignment (section 5).
Moreo-ver, unlike many other Chinese Classics, thesepoems are relatively simple to analyze, with eachline containing not more than 7 characters.
Allstudents can be expected to have previous expo-1 http://nlp.stanford.edu:8080/parser/57sure to some of the poems.
Finally, since the textis of such central importance, the resulting tree-bank is likely to be relevant to other scholars.
Itis especially motivating for students that theirefforts would have an impact long after they re-ceive their grades for the course.4.2 Annotation Set-up and ResultsEach of the 44 students was assigned four differ-ent poems from the Three Hundred Tang Poemsfor annotation, with a total of 144 characters.The instructor manually corrected the studentannotations.
Using the corrected version as goldstandard, the students achieved 68.1% labeledattachment score (LAS)2.
The quality of indi-vidual students?
annotations varied widely, fromthe lowest LAS at less than 10%, to the top stu-dent who scored more than 95%.
Students wereallowed to discuss their annotations with the in-structor, but the correct annotations were neverdisclosed to them.Part-of-speech tagging.
The students achieved93.9% accuracy for POS tagging, which com-pares reasonably with the agreement rate of95.1% among two annotators reported on similartexts in (Lee, 2012).
The tags with the highesterror rates are shown in Table 1.
The most fre-quent pairs of confusion are among the tags VA(predicative adjectives), AD (adverbs), and JJ(attributive adjectives).The lack of morphology in Classical Chineselikely contributed to the confusion between ADand JJ.
Consider the phrase ?/AD xian ?relaxed?
?/VV zuo ?sit?, the first two characters from theline ?????
?while sitting relaxedly, [we]gossip about Emperor Xuan?.
Here, the wordxian ?relaxed?
is an adverb describing the mannerof zuo ?sit?
; however, the same form can alsoserves as an adjective, perhaps leading a studentto tag it as JJ.Even more frequent is the confusion betweenJJ and VA.  A typical example is the phrase ?/NN zhu ?candle?
?/NN ying ?shadow?
?/VAshen ?becomes dark?, the last three characters inthe line ???????
?the shadow of thecandle on the mica screen becomes dark?.
De-spite hints from the word order, the student mis-takenly considered shen ?becomes dark?
as anattributive, rather than predicative, adjective.2 As a comparison, two heavily trained annotatorsachieved 91.2% agreement on similar texts (Lee andKong, 2012), and performance of automatic parserscan reach LAS at 75.6% (Lee and Wong, 2012).Tag Error rate Tag Error rateAD 20.1% M 13.8%P 20.0% LC 9.4%VA 19.1% CD 6.6%VC 16.1% JJ 4.4%PN 11.9%Table 1.
POS tags with the highest error rates.Head selection.
Among those characterswhose POS tags are correctly labeled, head se-lection is correct 81.8% of the time.
As shown inTable 2, among the various POS, students mostfrequently had difficulty selecting heads forverbs.
While there was a wide range of differentkinds of mistakes, the most common one is tomistakenly take a noun as head, using the de-pendency label vmod (verb modifier).Series of adverbs (AD) also turned out to beproblematic; a third of the errors with AD fellinto this case.
Consider the two adverbs bu andfu in the phrase ?/AD bu ?not?
?/AD fu ?again?
?/VV fan ?return?, the last three characters inthe line ??????
?once the crane leaves, itwill not return?.
By convention in the Stanfordframework (Chang et al 2009), the head of thefirst adverb, bu, is the verb fan and not its adverbneighbor to the right, fu.
This sort of error maybe considered technical mistakes, rather thangenuine misunderstanding of syntactic structure.Tag Error rate Tag Error rateVV 28.9% PN 9.6%AD 10.0% CD 7.1%NR 9.8% JJ 4.6%Table 2.
POS tags with the highest head selectionerror rates.
The top three tags, CC, AS and SP, wereomitted due to small sample size (only 3 each).Dependency labels.
When a wrong head is se-lected, the label was almost always also wrong.Among those words with the correct head, theaccuracy in dependency labeling was 88.6%.
Ta-ble 3 lists the labels with the lowest accuracy.Three kinds of common mistakes emerged.The top error involves the indirect object(iobj).
All four occurrences in the corpus weremisconstrued as direct objects.The second kind of error was due to unaware-ness of an implicit copula verb.
When a copula58exists or is implied, the label between the subjectand predicate should be topic (top) rather than(nsubj); and the label between the subject and anoun should be attributive (attr) rather than directobject (dobj).
Almost all mistakes with the labelstop and attr fell into this category.Third, as another technical mistake, studentsoften failed to use the label preposition object(pobj), and substituted it with the more commondirect object (dobj) instead.Label Error rate Label Error rateiobj 100.0% npadvmod 28.6%attr 55.0% nsubj 15.1%top 50.0% dobj 12.6%pobj 35.0% vmod 6.4%Table 3.
Dependency labels with the highest errorrates.5 Research AssignmentCombining the effort of the whole class, 176 ofthe 320 poems in the Three Hundred Tang Po-ems, comprising about 5000 characters, had beencompiled in a treebank.As a demonstration of the value of their anno-tations, a research assignment, with eight ques-tions on various linguistic aspects of the poems,was designed.
Before the release of the assign-ment, two preparatory steps were needed: theinstructor edited the students?
annotations into agold version, and imported the gold version ontoa web-based interface that allows searching foroccurrences of specific dependency relations.The user may specify the relevant child and/orhead word, or only their POS, and optionally alsothe dependency label.Most questions in the assignment requiredsearching for particular dependency relations andobserving the word usage therein.
For example,students were to find compound nouns where thehead noun is modified by the characters ?spring?or ?autumn?, two seasons that appear frequentlyin formulaic expressions to convey atmosphere(e.g., ?wind in the spring?, ?moon in the au-tumn?).
They were then to recognize the headnouns attested to be modified by both (?grass?,?sun?
and ?light?).
As another example, studentswere to identify all sentences where the usualSVO order had undergone word inversion, andcomment on those words that were intentionallygiven the emphasis.
Other questions addressedpivot constructions and onomatopoeia words.Average student performance on these questionsranges between 70% and 90%.Perhaps the most challenging question was onthe phenomenon of parallelism.
Classical Chi-nese poems are read in pairs of two lines, or cou-plets.
The two lines in a couplet are expected tohave similar syntactic structures, yet the natureand extent of this ?similarity?
remained an openquestion.
Taking 16 couplets from the treebankas samples, students were to explain any dis-symmetry in the pairs of dependency trees, andpoint out the most frequent differences.
About50% of the students offered ideas similar to theconclusions of a larger-scale study (Lee & Kong,in submission), i.e., that certain sets of POS tagsmay be considered acceptable as parallel (e.g.,numbers and adjectives), and that low-level syn-tactic structures need not be identical.6 Discussions and ConclusionsWe have described an undergraduate course onlanguage information technology where studentscollectively created a treebank, then applied it ina research assignment.This course design is demanding for the in-structor, who must correct a substantial amountof annotations, under time pressure to produce agold version for use in the assignment.
Moreo-ver, assignment questions may need to be adjust-ed, since the annotation results are not availablebeforehand.
It is also demanding for students,who must master the dependency annotationscheme quickly.The rewards of this design, however, are man-ifold for students, instructor and scholarship.First, annotation errors indicate areas where stu-dents?
grasp of grammar is weak, and thus in-formative for language teachers.
Second, someannotations reveal alternative syntactic interpre-tations, never thought of by the instructor, andcan contribute to studies on syntactic ambigui-ties.
Third, the resulting treebank can serve as alinguistic resource for all scholars.Most significantly, the research assignmentlets students reap the rewards of the newknowledge they had labored to create, providinga convincing demonstration of the practical valueof treebanking.
In future versions of the course,we hope to continue building this ?cycle of con-tributing and learning?
(Crane et al 2012),where students learn to contribute newknowledge, and share it with others so they cancollectively discover yet more knowledge.59AcknowledgmentsThis work was partially supported by a grantfrom the Early Career Scheme of the GeneralResearch Fund (#9041849) from the ResearchGrants Council of Hong Kong, and by a Teach-ing Development Grant (#6000349) from CityUniversity of Hong Kong.ReferencesDavid Bamman and Gregory Crane.
2010.
CorpusLinguistics, Treebanks and the Reinvention of Phi-lology.
In Informatik 2010, pages 542-551.Emily Bender.
2007.
Combining Research and Ped-agogy in the Development of a CrosslinguisticGrammar Resource.
Proc.
GEAF Workshop.Kalina Bontcheva, Hamish Cunningham, ValentinTablan, Diana Maynard, and Oana Hamza.
2002.Using GATE as an Environment for TeachingNLP.
Proc.
Workshop on Effective Tools andMethodologies for Teaching Natural LanguageProcessing and Computational Linguistics.Eckhard Bick.
2005.
Grammar for Fun: IT-basedGrammar Learning with VISL.
In: Henriksen, Pe-ter Juel (ed.
), CALL for the Nordic Languages.pp.49-64.Pi-Chuan Chang, Huihsin Tseng, Dan Jurafsky, andChristopher Manning.
2009.
Discriminative Reor-dering with Chinese Grammatical Relations Fea-tures.
Proc.
3rd Workshop on Syntax and Structurein Statistical Translation.Gregory Crane, Bridget Almas, Alison Babeu, LisaCerrato, Matthew Harrington, David Bamman, andHarry Diakoff.
2012.
Student Researchers, Citi-zen Scholars and the Trillion Word Library.
Proc.12th ACM/IEEE-CS Joint Conference on DigitalLibraries (JCDL).John Lee.
2012.
A Classical Chinese Corpus withNested Part-of-Speech Tags.
Proc.
Workshop onLanguage Technology for Cultural Heritage, So-cial Sciences, and Humanities (LaTeCH).John Lee and Yin Hei Kong.
2012.
A DependencyTreebank of Classical Chinese Poems.
Proc.
Con-ference of the North American Chapter of the As-sociation for Computational Linguistics (NAACL).John Lee and Tak-sum Wong, 2012.
Glimpses ofAncient China from Classical Chinese Poems.Proc.
24th International Conference on Computa-tional Linguistics (COLING).Martin Volk, Sofia Gustafson-Capkov?, David Hag-strand, and Heli Uibo.
2005.
Teaching Treebank-ing.
In: Nordisk Sprogteknologi.
Nordic LanguageTechnology.
?rbog for Nordisk SprogteknologiskForskningsprogram 2000-2004.
Museum Tuscu-lanums Forlag.
Copenhagen.
2005.Nianwen Xue, Fei Xia, Fu-Dong Chiou, and MarthaPalmer, 2005.
The Penn Chinese TreeBank: PhraseStructure Annotation of a Large Corpus.
NaturalLanguage Engineering 11:pp.207?238.60
