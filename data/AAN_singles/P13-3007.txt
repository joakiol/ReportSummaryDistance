Proceedings of the ACL Student Research Workshop, pages 46?51,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsText Classification based on the Latent Topics of Important Sentencesextracted by the PageRank AlgorithmYukari Ogura and Ichiro KobayashiAdvanced Sciences, Graduate School of Humanities and Sciences,Ochanomizu University2-1-1 Ohtsuka Bunkyo-ku Tokyo, 112-8610 JAPAN{ogura.yukari, koba}@is.ocha.ac.jpAbstractIn this paper, we propose a method to raise theaccuracy of text classification based on latenttopics, reconsidering the techniques necessaryfor good classification ?
for example, to de-cide important sentences in a document, thesentences with important words are usually re-garded as important sentences.
In this case,tf.idf is often used to decide important words.On the other hand, we apply the PageRank al-gorithm to rank important words in each doc-ument.
Furthermore, before clustering docu-ments, we refine the target documents by rep-resenting them as a collection of importantsentences in each document.
We then clas-sify the documents based on latent informa-tion in the documents.
As a clustering method,we employ the k-means algorithm and inves-tigate how our proposed method works forgood clustering.
We conduct experiments withReuters-21578 corpus under various condi-tions of important sentence extraction, usinglatent and surface information for clustering,and have confirmed that our proposed methodprovides better result among various condi-tions for clustering.1 IntroductionText classification is an essential issue in the fieldof natural language processing and many techniquesusing latent topics have so far been proposed andused under many purposes.
In this paper, we aimto raise the accuracy of text classification using la-tent information by reconsidering elemental tech-niques necessary for good classification in the fol-lowing three points: 1) important words extraction?
to decide important words in documents is a cru-cial issue for text classification, tf.idf is often used todecide them.
Whereas, we apply the PageRank al-gorithm (Brin et al 1998) for the issue, because thealgorithm scores the centrality of a node in a graph,and important words should be regarded as havingthe centrality (Hassan et al 2007).
Besides, the al-gorithm can detect centrality in any kind of graph,so we can find important words for any purposes.In our study, we express the relation of word co-occurrence in the form of a graph.
This is becausewe use latent information to classify documents, anddocuments with high topic coherence tend to havehigh PMI of words in the documents (Newman etal., 2010).
So, we construct a graph from a view-point of text classification based on latent topics.
2)Refinement of the original documents ?
we recom-pile the original documents with a collection of theextracted important sentences in order to refine theoriginal documents for more sensitive to be classi-fied.
3) Information used for classification ?
weuse latent information estimated by latent Dirichletallocation (LDA) (Blei et al 2003) to classify doc-uments, and compare the results of the cases usingboth surface and latent information.
We experimenttext classification with Reuters-21578 corpus; evalu-ate the result of our method with the results of thosewhich have various other settings for classification;and show the usefulness of our proposed method.2 Related studiesMany studies have proposed to improve the accu-racy of text classification.
In particular, in termsof improving a way of weighting terms in a docu-46ment for text classification, there are many studieswhich use the PageRank algorithm.
In (Hassan etal., 2007), they have applied a random-walk modelon a graph constructed based on the words whichco-occur within a given window size, e.g., 2,4,6,8words in their experiments, and confirmed that thewindows of size 2 and 4 supplied the most signif-icant results across the multiple data set they used.Zaiane et al(2002) and Wang et al(2005) haveintroduced association rule mining to decide impor-tant words for text classification.
In particular, Wanget alhave used a PageRank-style algorithm to rankwords and shown their method is useful for text clas-sification.
Scheible et al(2012) have proposed amethod for bootstrapping a sentiment classifier froma seed lexicon.
They apply topic-specific PageRankto a graph of both words and documents, and in-troduce Polarity PageRank, a new semi-supervisedsentiment classifier that integrates lexicon inductionwith document classification.
As a study related totopic detection by important words obtained by thePageRank algorithm, Kubek et al(2011) has de-tected topics in a document by constructing a graphof word co-occurrence and applied the PageRank al-gorithm on it.To weight words is not the issue for only text clas-sification, but also an important issue for text sum-marization, Erkan et al(2004) and Mihlcea et al(2004b; 2004a) have proposed multi-document sum-marization methods using the PageRank algorithm,called LexRank and TextRank, respectively.
Theyuse PageRank scores to extract sentences whichhave centrality among other sentences for generat-ing a summary from multi-documents.On the other hand, since our method is to clas-sify texts based on latent information.
The graphused in our method is constructed based on word co-occurrence so that important words which are sen-sitive to latent information can be extracted by thePageRank algorithm.
At this point, our attempt dif-fers from the other approaches.3 Techniques for text classification3.1 Extraction of important wordsTo decide important words, tf.idf is often adopted,whereas, another methods expressing various rela-tion among words in a form of a graph have beenproposed (2005; Hassan et al 2007).
In particular,(Hassan et al 2007) shows that the PageRank scoreis more clear to rank important words rather thantf.idf.
In this study, we refer to their method and usePageRank algorithm to decide important words.The PageRank algorithm was developed by (Brinet al 1998).
The algorithm has been used as thebasic algorithm of Google search engine, and alsoused for many application to rank target informationbased on the centrality of information represented inthe form of a graph.In this study, the important words are selectedbased on PageRank score of a graph which repre-sents the relation among words.
In other words, inorder to obtain good important sentences for classi-fication, it is of crucial to have a good graph (Zhuet al 2005) because the result will be considerablychanged depending on what kind of a graph we willhave for important words.
In this study, since weuse latent information for text classification, there-fore, we construct a graph representing the relationof words from a viewpoint topic coherence.
Ac-cording to (Newman et al 2010), topic coherenceis related to word co-occurrence.
Referring to theiridea, we construct a graph over words in the follow-ing manner: each word is a node in the graph, andthere is an undirected edge between every pair ofwords that appear within a three-sentence window ?to take account of contextual information for words,we set a three-sentence window.
We then apply thePageRank algorithm to this graph to obtain a scorefor every word which is a measurement of its cen-trality ?
the centrality of a word corresponds to theimportance of a word.
A small portion of a graphmight look like the graph in Figure 1.3.2 Refinement of target documentsAfter selecting important words, the important sen-tences are extracted until a predefined ratio of wholesentences in each document based on the selectedimportant words, and then we reproduce refineddocuments with a collection of extracted importantsentences.
An important sentence is decided by howmany important words are included in the sentence.The refined documents are composed of the impor-tant sentences extracted from a viewpoint of latentinformation, i.e., word co-occurrence, so they areproper to be classified based on latent information.47Figure 1: A graph of word cooccurrence3.3 Clustering based on latent topicsAfter obtaining a collection of refined documents forclassification, we adopt LDA to estimate the latenttopic probabilistic distributions over the target doc-uments and use them for clustering.
In this study,we use the topic probability distribution over docu-ments to make a topic vector for each document, andthen calculate the similarity among documents.3.4 Clustering algorithmstep.1 Important words determinationThe important words are decided based on tf.idfor PageRank scores.
As for the words decidedbased on PageRank scores, we firstly have tomake a graph on which the PargeRank algo-rithm is applied.
In our study, we construct agraph based on word co-occurrence.
So, im-portant words are selected based on the wordswhich have centrality in terms of word co-occurrence.
In particular, in our study we se-lect co-occurred words in each three sentencesin a document, taking account of the influenceof contextual information.step.2 Refinement of the target documentsAfter selecting the important words, we selectthe sentences with at least one of the wordswithin the top 3 PageRank score as importantsentences in each document, and then we re-produce refined documents with a collection ofthe extracted important sentences.step.3 Clustering based on latent topicsAs for the refined document obtained in step2, the latent topics are estimated by means ofLDA.
Here, we decide the number of latent top-ics k in the target documents by measuring thevalue of perplexity P (w) shown in equation(1).
The similarity of documents are measuredby the Jenshen-Shannon divergence shown inequation (2).P (w) = exp(?
1N?mnlog(?z?mz?zwmn))(1)Here, N is the number of all words in the targetdocuments, wmn is the n-th word in the m-thdocument; ?
is the topic probabilistic distribu-tion for the documents, and ?
is the word prob-abilistic distribution for every topic.DJS(P ||Q)= 12(?xP (x)logP (x)R(x) +?xlogQ(x)R(x) )where,R(x) = P (x) +Q(x)2 (2)4 ExperimentWe evaluate our proposed method by comparingthe accuracy of document clustering between ourmethod and the method using tf.idf for extracting im-portant words.4.1 Experimental settingsAs the documents for experiments, we use Reuters-21578 dataset 1 collected from the Reuters newswirein 1987.In our proposed method, the refined doc-uments consisting of important sentences extractedfrom the original documents are classified, there-fore, if there are not many sentences in a document,we will not be able to verify the usefulness of ourproposed method.
So, we use the documents whichhave more than 5 sentences in themselves.
Of the135 potential topic categories in Reuters-21578, re-ferring to other clustering study (Erkan, 2006; 2005;Subramanya et al 2008), we also use the most fre-quent 10 categories: i.e., earn, acq, grain, wheat,money, crude, trade, interest, ship, corn.
In the1http://www.daviddlewis.com/resources/testcollections/reuters21578/48sequel, we use 792 documents whose number ofwords is 15,835 for experiments ?
the 792 docu-ments are the all documents which have more than 5sentences in themselves in the corpus.
For each doc-ument, stemming and stop-word removal processesare adopted.
Furthermore, the hyper-parameters fortopic probability distribution and word probabilitydistribution in LDA are ?=0.5 and ?=0.5, respec-tively.
We use Gibbs sampling and the number ofiteration is 200.
The number of latent topics is de-cided by perplexity, and we decide the optimal num-ber of topics by the minimum value of the average of10 times trial, changing the number of topics rang-ing from 1 to 30.As the first step for clustering with our method,in this study we employ the k-means clustering al-gorithm because it is a representative and a simpleclustering algorithm.4.2 Evaluation methodFor evaluation, we use both accuracy and F-value,referring to the methods used in (Erkan, 2006).
Asfor a document di, li is the label provided to di bythe clustering algorithm, and ?i is the correct labelfor di.
The accuracy is expressed in equation (3).Accuracy =?ni=1 ?
(map (li) , ?i)n (3)?
(x, y) is 1 if x = y, otherwise 0. map (li) is thelabel provided to di by the k-means clustering algo-rithm.
For evaluation, the F-value of each categoryis computed and then the average of the F-values ofthe whole categories, used as an index for evalua-tion, is computed (see, equation (4)).F = 1|C|?ci?CF (ci) (4)As the initial data for the k-means clustering al-gorithm, a correct document of each category is ran-domly selected and provided.
By this, the cate-gory of classified data can be identified as in (Erkan,2006).4.3 Experiment resultsTo obtain the final result of the experiment, we ap-plied the k-means clustering algorithm for 10 timesfor the data set and averaged the results.
Here, in thecase of clustering the documents based on the topicprobabilistic distribution by LDA, the topic distribu-tion over documents ?
is changed in every estima-tion.
Therefore, we estimated ?
for 8 times and thenapplied the k-means clustering algorithm with each?
for 10 times.
We averaged the results of the 10trials and finally evaluated it.
The number of latenttopics was estimated as 11 by perplexity.
We used itin the experiments.
To measure the latent similarityamong documents, we construct topic vectors withthe topic probabilistic distribution, and then adoptthe Jensen-Shannon divergence to measures it, onthe other hand, in the case of using document vec-tors we adopt cosine similarity.Table 1 and Table 2 show the cases of with andwithout refining the original documents by recom-piling the original documents with the importantsentences.Table 1: Extracting important sentencesMethods Measure Accuracy F-valuePageRank Jenshen-Shannon 0.567 0.485Cosine similarity 0.287 0.291tf.idf Jenshen-Shannon 0.550 0.435Cosine similarity 0.275 0.270Table 2: Without extracting important sentencesSimilarity measure Accuracy F-valueJenshen-Shannon 0.518 0.426Cosine similarity 0.288 0.305Table 3, 4 show the number of words and sen-tences after applying each method to decide impor-tant words.Table 3: Change of number of wordsMethods 1 word 2 words 3 words 4 words 5 wordsPageRank 12,268 13,141 13,589 13,738 13,895tf ?
idf 13,999 14,573 14,446 14,675 14,688Furthermore, Table 5 and 6 show the accuracy andF-value of both methods, i.e., PageRank scores andtf.idf, in the case that we use the same number ofsentences in the experiment to experiment under thesame conditions.49Table 4: Change of number of sentencesMethods 1 word 2 words 3 words 4 words 5 wordsPageRank 1,244 1,392 1,470 1,512 1,535tf ?
idf 1,462 1,586 1,621 1,643 1,647Table 5: Accuracy to the number of topicsNum.
of topics 8 9 10 11 12PageRank 0.525 0.535 0.566 0.553 0.524tf.idf 0.556 0.525 0.557 0.550 0.5414.4 DiscussionWe see from the experiment results that as for themeasures based on the Jenshen-Shannon divergence,both accuracy and F-value of the case where refineddocuments are clustered is better than the case wherethe original documents are clustered.
We have con-ducted t-test to confirm whether or not there is sig-nificant difference between the cases: with and with-out extracting important sentences.
As a result, thereis significant difference with 5 % and 1 % level forthe accuracy and F-value, respectively.When extracting important sentences, althoughthe size of the document set to be clustered is smallerthan the original set, the accuracy increases.
So, itcan be said that necessary information for clusteringis adequately extracted from the original documentset.From this, we have confirmed that the documentsare well refined for better clustering by recompil-ing the documents with important sentences.
Wethink the reason for this is because only importantsentences representing the contents of a documentare remained by refining the original documents andthen it would become easier to measure the differ-ence between probabilistic distributions of topics ina document.
Moreover, as for extracting importantsentences, we confirmed that the accuracy of thecase of using PageRank scores is better than the caseof using tf.idf.
By this, constructing a graph basedon word co-occurrence of each 3 sentences in a doc-ument works well to rank important words, takingaccount of the context of the word.We see from Table 3 , 4 that the number of wordsand sentences decreases when applying PageRankscores.
In the case of applying tf.idf, the tf.idf valueTable 6: F-value to the number of topicsNum.
of topics 8 9 10 11 12PageRank 0.431 0.431 0.467 0.460 0.434tf.idf 0.466 0.430 0.461 0.435 0.445tends to be higher for the words which often ap-pear in a particular document.
Therefore, the ex-traction of sentences including the words with hightf.idf value may naturally lead to the extraction ofmany sentences.The reason for low accuracy in the case of us-ing cosine similarity for clustering is that it was ob-served that the range of similarity between docu-ments is small, therefore, the identification of differ-ent categorized documents was not well achieved.Table 5 and Table 6 show the accuracy and F-value to the number of latent topics, respectively.We see that both accuracy and F-value of the caseof using PageRank scores are better than those ofthe case of using tf.idf in the case of the numberof topics is 9,10,and 11.
In particular, the highestscore is made when the number of topics is 10 forboth evaluation measures ?
we think the reason forthis is because we used document sets of 10 cate-gories, therefore, it is natural to make the highestscore when the number of topics is 10.
So, we hadbetter look at the score of the case where the numberof topics is 10 to compare the ability of clustering.By the result, we can say that PageRank is better inrefining the documents so as they suit to be classifiedbased on latent information.5 ConclusionsIn this study, we have proposed a method of textclustering based on latent topics of important sen-tences in a document.
The important sentences areextracted through important words decided by thePageRank algorithm.
In order to verify the useful-ness of our proposed method, we have conductedtext clustering experiments with Reuters-21578 cor-pus under various conditions ?
we have adopted ei-ther PageRank scores or tf.idf to decide importantwords for important sentence extraction, and thenadopted the k-means clustering algorithm for thedocuments recompiled with the extracted importantsentences based on either latent or surface informa-50tion.
We see from the results of the experiments thatthe clustering based on latent information is gener-ally better than that based on surface information interms of clustering accuracy.
Furthermore, decidingimportant words with PageRank scores is better thanthat with tf.idf in terms of clustering accuracy.
Com-pared to the number of the extracted words in impor-tant sentences between PageRank scores and tf.idf,we see that the number of sentences extracted basedon PageRank scores is smaller than that based ontf.idf, therefore, it can be thought that more context-sensitive sentences are extracted by adopting PageR-ank scores to decide important words.As future work, since clustering accuracy will bechanged by how many sentences are compiled in arefined document set, therefore, we will consider amore sophisticated way of selecting proper impor-tant sentences.
Or, to avoid the problem of selectingsentences, we will also directly use the words ex-tracted as important words for clustering.
Moreover,at this moment, we use only k-means clustering al-gorithm, so we will adopt our proposed method toother various clustering methods to confirm the use-fulness of our method.ReferencesDavid M. Blei and Andrew Y. Ng and Michael I. Jordanand John Lafferty.
2003.
Latent dirichlet alcation,Journal of Machine Learning Research,Sergey Brin and Lawrence Page.
1998.
The Anatony ofa Large-scale Hypertextual Web Search Engine, Com-puter Networks and ISDN Systems, pages.
107?117.Gunes Erkan, 2004.
LexRank: Graph-based LexicalCentrality as Salience in Text Summarization Journalof Artificial Intelligence Research 22, pages.457-479Gunes Erkan.
2006.
Language Model-Based Docu-ment Clustering Using Random Walks, Association forComputational Linguistics, pages.479?486.Samer Hassan, Rada Mihalcea and Carmen Banea.
2007.Random-Walk Term Weighting for Improved Text Clas-sification, SIGIR ?07 Proceedings of the 30th annualinternational ACM SIGIR conference on Research anddevelopment in information retrieval, pages.829-830.Mario Kubek and Herwig Unger, 2011 Topic Detec-tion Based on the PageRank?s Clustering Property,IICS?11, pages.139-148,Rada Mihalcea.
2004.
Graph-based Ranking Algorithmsfor Sentence Extraction, Applied to Text Summariza-tion, Proceeding ACLdemo ?04 Proceedings of theACL 2004 on Interactive poster and demonstrationsessions Article No.
20.Rada Mihalcea and Paul Tarau 2004.
TextRank: Bring-ing Order into Texts, Conference on Empirical Meth-ods in Natural Language Processing.David Newman, Jey Han Lau, Karl Grieser, and Timo-thy Baldwin, 2010.
Automatic evaluation of topic co-herence, Human Language Technologies: The 2010Annual Conference of the North Ametican Chapter ofthe Association for Computational Linguistics, pages.100?108, Los Angeles.Christian Scheible, Hinrich Shutze.
2012.
BootstrappingSentiment Labels For Unannotated Documents WithPolarity PageRank, Proceedings of the Eight Interna-tional Conference on Language Resources and Evalu-ation.Amarnag Subramanya, Jeff Bilmes.
2008.
Soft-Supervised Learning for Text Classification Proceed-ings of the 2008 Conference on Empirical Methods inNatural Language Processing, pages.1090?1099, Hon-olulu.Wei Wang, Diep Bich Do, and Xuemin Lin.
2005.
TermGraph Model for Text Classification, Springer-VerlagBerlin Heidelberg 2005, pages.19?30.Osmar R. Zaiane and Maria-luiza Antonie.
2002.
Clas-sifying Text Documents by Associating Terms with TextCategories, In Proc.
of the Thirteenth AustralasianDatabase Conference (ADC?02), pages.215?222,X Zhu.
2005.
Semi-supervised learning with Graphs,Ph.D thesis, Carnegie Mellon University.51
