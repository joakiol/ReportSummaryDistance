Efficient Normal-Form Parsingfor Combinatory Categorial Grammar*Jason EisnerDept.
of Computer  and Informat ion ScienceUniversity of Pennsylvania200 S. 33rd St., Phi ladelphia,  PA 19104-6389, USAj e i sner@l inc ,  c i s .
upenn,  eduAbst rac tUnder categorial grammars that have pow-erful rules like composition, a simplen-word sentence can have exponentiallymany parses.
Generating all parses is ineffi-cient and obscures whatever true semanticambiguities are in the input.
This paperaddresses the problem for a fairly generalform of Combinatory Categorial Grammar,by means of an efficient, correct, and easyto implement normal-form parsing tech-nique.
The parser is proved to find ex-actly one parse in each semantic equiv-alence class of allowable parses; that is,spurious ambiguity (as carefully defined)is shown to be both safely and completelyeliminated.1 In t roduct ionCombinatory Categorial Grammar (Steedman,1990), like other "flexible" categorial grammars,suffers from spurious ambiguity (Wittenburg, 1986).The non-standard constituents hat are so crucial toCCG's analyses in (1), and in its account of into-national focus (Prevost ~ Steedman, 1994), remainavailable ven in simpler sentences.
This renders (2)syntactically ambiguous.
(1) a. Coordinat ion: \[\[John likes\]s/NP, and\[Mary pretends to like\]s/NP\], the biggaloot in the corner.b.
Extract ion: Everybody at this party\[whom \[John likes\]s/NP\] is a big galoot.
(2) a. John \[likes Mary\]s\NP.b.
\[.John likes\]s/N P Mary.The practical problem of "extra" parses in (2) be-comes exponentially worse for longer strings, whichcan have up to a Catalan number of parses.
An*This material is based upon work supported undera National Science Foundation Graduate Fellowship.
Ihave been grateful for the advice of Aravind Joshi, NoboKomagata, Seth Kulick, Michael Niv, Mark Steedman,and three anonymous reviewers.exhaustive parser serves up 252 CCG parses of (3),which must be sifted through, at considerable cost,in order to identify the two distinct meanings forfurther processing.
1(3) the galoot in the cornerNP\]N N (N\N)/NP NP\]N Nthat I said Mary(N\N)\](S/NP) S/(S\NP) (S\NP)\]$ S\](S\NP)pretends to(S\NP)\](Sin f \NP) (Sin f \NP)/(Sstem \NP)like(Sstem\NP)/NPThis paper presents a simple and flexible CCGparsing technique that prevents any such explosionof redundant CCG derivations.
In particular, it isproved in ?4.2 that the method constructs exactlyone syntactic structure per semantic reading--e.g.,just two parses for (3).
All other parses are sup-pressed by simple normal-form constraints that areenforced throughout the parsing process.
This ap-proach works because CCG's spurious ambiguitiesarise (as is shown) in only a small set of circum-stances.
Although similar work has been attemptedin the past, with varying degrees of success (Kart-tunen, 1986; Wittenburg, 1986; Pareschi & Steed-man, 1987; Bouma, 1989; Hepple & Morrill, 1989;KSnig, 1989; Vijay-Shanker & Weir, 1990; Hepple,1990; Moortgat, 1990; ttendriks, 1993; Niv, 1994),this appears to be the first full normal-form resultfor a categorial formalism having more than context-free power.2 Def in i t ions  and  Re la ted  WorkCCG may be regarded as a generalization f context-free grammar (CFG)--one where a grammar hasinfinitely many nonterminals and phrase-structurerules.
In addition to the familiar atomic nonter-minal categories (typically S for sentences, N for1Namely, Mary pretends to like the galoot in 168parses and the corner in 84.
One might try a statis-tical approach to ambiguity resolution, discarding thelow-probability parses, but it is unclear how to modeland train any probabilities when no single parse can betaken as the standard of correctness.79nouns, NP for noun phrases, etc.
), CCG allows in-finitely many slashed categories.
If z and y arecategories, then x /y  (respectively z \y)  is the cat-egory of an incomplete x that is missing a y at itsright (respectively left).
Thus verb phrases are an-alyzed as subjectless entences S\NP, while "Johnlikes" is an objectless entence or S/NP.
A complexcategory like ((S\NP) \ (S\NP))/N may be written asS\NP\(S\NP)/N, under a convention that slashes areleft-associative.The results herein apply to the TAG-equivalentCCG formalization given in (Joshi et M., 1991).
2In this variety of CCG, every (non-lexical) phrase-structure rule is an instance of one of the followingbinary-rule templates (where n > 0):(4) Forward generalized composition >Bn:;~/y y\[nzn''" \[2Z211Zl -'+ ;~\[nZn''" \]2Z211ZlBackward generalized composition <Bn:y l .
z .
.
.
-  12z2 Ilzl x\y x I .z .
.
.
.
12z llzlInstances with n -- 0 are called application rules, andinstances with n > 1 are called composition rules.
Ina given rule, x, y, z l .
.
.
z~ would be instantiated ascategories like NP, S/I~P, or S\NP\(S\NP)/N.
Each of\]1 through In would be instantiated as either / or \.A fixed CCG grammar need not include everyphrase-structure rule matching these templates.
In-deed, (Joshi et al, 1991) place certain restrictionson the rule set of a CCG grammar, including a re-quirement that the rule degree n is bounded over theset.
The results of the present paper apply to suchrestricted grammars and also more generally, to anyCCG-style grammar with a decidable rule set.Even as restricted by (Joshi et al, 1991), CCGshave the "mildly context-sensitive" expressive powerof Tree Adjoining Grammars (TAGs).
Most workon spurious ambiguity has focused on categorial for-malisms with substantially less power.
(Hepple,1990) and (Hendriks, 1993), the most rigorous piecesof work, each establish a normal form for the syn-tactic calculus of (Lambek, 1958), which is weaklycontext-free.
(Kbnig, 1989; Moortgat, 1990) havealso studied the Lambek calculus case.
(Hepple &Morrill, 1989), who introduced the idea of normal-form parsing, consider only a small CCG frag-ment that lacks backward or order-changing com-position; (Niv, 1994) extends this result but doesnot show completeness.
(Wittenburg, 1987) assumesa CCG fragment lacking order-changing or higher-order composition; furthermore, his revision of thecombinators creates new, conjoinable constituentsthat conventional CCG rejects.
(Bouma, 1989) pro-poses to replace composition with a new combina-tor, but the resulting product-grammar scheme as-2This formalization sweeps any type-raising into thelexicon, as has been proposed on linguistic grounds(Dowty, 1988; Steedman, 1991, and others).
It alsotreats conjunction lexically, by giving "and" the gener-alized category x \x /x  and barring it from composition.80signs different ypes to "John likes" and "Mary pre-tends to like," thus losing the ability to conjoin suchconstituents or subcategorize for them as a class.
(Pareschi & Steedman, 1987) do tackle the CCGcase, but (Hepple, 1987) shows their algorithm tobe incomplete.3 Overv iew o f  the  Pars ing  S t ra tegyAs is well known, general CFG parsing methodscan be applied directly to CCG.
Any sort of chartparser or non-deterministic shift-reduce parser willdo.
Such a parser repeatedly decides whether twoadjacent constituents, uch as S/NP and I~P/N, shouldbe combined into a larger constituent such as S/N.The role of the grammar is to state which combi-nations are allowed.
The key to efficiency, we willsee, is for the parser to be less permissive than thegrammar--for it to say "no, redundant" in somecases where the grammar says "yes, grammatical.
"(5) shows the constituents that untrammeledCCG will find in the course of parsing "John likesMary."
The spurious ambiguity problem is not thatthe grammar allows (5c), but that the grammar al-lows both (5f) and (5g)--distinct parses of the samestring, with the same meaning.
(5) a.
\[John\]s/(s\sp)b.
\[likes\](S\NP)/NpC.
\[John likes\]s/N Pd.
\[Mary\]N Pe.
\[likes Mary\]s\N Pf.
\[\[John likes\] Mary\]s ~ to be disallowedg, \[John \[likes Mary\]IsThe proposal is to construct all constituentsshown in (5) except for (5f).
If we slightly con-strain the use of the grammar ules, the parser willstill produce (5c) and (5d)--constituents hat areindispensable in contexts like (1)--while refusing tocombine those constituents into (5f).
The relevantrule S/I~P NP --* S will actually be blocked when itattempts to construct (5f).
Although rule-blockingmay eliminate an analysis of the sentence, as it doeshere, a semantically equivalent analysis uch as (5g)will always be derivable along some other route.In general, our goal is to discover exactly one anal-ysis for each <substring, meaning> pair.
By prac-ticing "birth control" for each bottom-up generationof constituents in this way, we avoid a populationexplosion of parsing options.
"John likes Mary" hasonly one reading semantically, sojust one of its anal-yses (5f)-(5g) is discovered while parsing (6).
Onlythat analysis, and not the other, is allowed to con-tinue on and be built into the final parse of (6).
(6) that galoot in the corner that thinks \[Johnlikes Mary\]sFor a chart parser, where each chart cell stores theanalyses of some substring, this strategy says thatall analyses in a cell are to be semantically distinct.
(Karttunen, 1986) suggests enforcing that propertydirectly--by comparing each new analysis semanti-cally with existing analyses in the cell, and refus-ing to add it if redundant--but (Hepple & Morrill,1989) observe briefly that this is inefficient for largecharts.
3 The following sections how how to obtaineffectively the same result without doing any seman-tic interpretation or comparison at all.4 A Normal Form for "Pure" CCGIt is convenient to begin with a special case.
Sup-pose the CCG grammar includes not some but allinstances of the binary rule templates in (4).
(Asalways, a separate lexicon specifies the possible cat-egories of each word.)
If we group a sentence's parsesinto semantic equivalence classes, it always turns outthat exactly one parse in each class satisfies the fol-lowing simple declarative constraints:(7) a.
No constituent produced by >Bn, anyn ~ 1, ever serves as the primary (left)argument to >Bn', any n' > 0.b.
No constituent produced by <Bn, anyn > 1, ever serves as the primary (right)argument to <Bn', any n' > 0.The notation here is from (4).
More colloquially,(7) says that the output of rightward (leftward) com-position may not compose or apply over anything toits right (left).
A parse tree or subtree that satisfies(7) is said to be in normal form (NF).As an example, consider the effect of these restric-tions on the simple sentence "John likes Mary."
Ig-noring the tags -OT, -FC, and -Be for the moment,(8a) is a normal-form parse.
Its competitor (85) isnot, nor is any larger tree containing (8b).
But non-3How inefficient?
(i) has exponentially many seman-tically distinct parses: n = 10 yields 82,756,612 parses(2?)
-- 48,620 equivalence classes.
Karttunen's in 10method must therefore add 48,620 representative parsesto the appropriate chart cell, first comparing each oneagainst all the previously added parses--of which thereare 48,620/2 on average--to ensure it is not semanticallyredundant.
(Additional comparisons are needed to rejectparses other than the lucky 48,620.)
Adding a parse cantherefore take exponential time.n(i) ... S/S S/S S/S S S\S S\S S\S ...Structure sharing does not appear to help: parses thatare grouped in a parse forest have only their syntacticcategory in common, not their meaning.
Karttunen's ap-proach must tease such parses apart and compare theirvarious meanings individually against each new candi-date.
By contrast, the method proposed below is purelysyntactic--just like any "ordinary" parser--so it neverneeds to unpack a subforest, and can run in polynomialtime.standard constituents are allowed when necessary:(8c) is in normal form (cf.
(1)).
(8) a. S-OTS / ( S ~ ~ I P - O TJohn (S\NP)/NP-OT ~P-OTI Ilikes Maryb.
.forward application blocked by (Ta)(eq,,i.alently, nofi~X..~itted b~ (10a ))S/NP-FC I~P-OT\[MaryS/(S"\NP)-OT (S\NP)/IIP-OTI IJohn likes81c.
N\N-OT(N\N) / (S/NP)-OT S/NP-FCI s ~ p  whomS/(  )/NP-OTI lJohn likesIt is not hard to see that (7a) eliminates all butright-branching parses of "forward chains" like A/BB/C C or A/B/C C/D D/E/F/G G/H, and that (Tb)eliminates all but left-branching parses of "backwardchains."
(Thus every functor will get its arguments,if possible, before it becomes an argument itself.
)But it is hardly obvious that (7) eliminates all ofCCG's spurious ambiguity.
One might worry aboutunexpected interactions involving crossing compo-sition rules like A/B B\C--~ A\C.
Significantly, itturns out that (7) really does suffice; the proof isin ?4.2.It is trivial to modify any sort of CCG parserto find only the normal-form parses.
No seman-tics is necessary; simply block any rule use thatwould violate (7).
In general, detecting violationswill not hurt performance by more than a constantfactor.
Indeed, one might implement (7) by modi-fying CCG's phrase-structure grammar.
Each ordi-nary CCG category is split into three categories thatbear the respective tags from (9).
The 24 templatesschematized in (10) replace the two templates of (4).Any CFG-style method can still parse the resultingspuriosity-free grammar, with tagged parses as in(8).
In particular, the polynomial-time, polynomial-space CCG chart parser of (Vijay-Shanker & Weir,1993) can be trivially adapted to respect the con-straints by tagging chart entries.
(9) -FC output of >Bn, some n > 1 (a forward composition rule)-BC output of <Bn, some n > 1 (a backward composition rule)-OT output of >B0 or <B0 (an application rule), or lexical item(10) a.
Forward application >BO: ~ x/y-OT y-Be t -'+ x--OTy-OT )b. Backward application <B0: y-Be ~ x\y-OT j" ~ x-OT9-O'1" )y l,,z,, l~z~ llz1-BC ---, x l,z,~..- \]2z2 llz1-FC c. Fwd.
composition >Bn (n > 1): x/y-OT Y Inz,~ 12z2 IlZl-OTd.
Bwd.
composition <Bn (n >_ 1): Y I,~z~ 12z2 Ilzl-BC ---, x Inz , ' ' "  I~.z2 Ilzl--BCy I ,z,  I~.z2 IlZl-OT x\y-OT(ii) a. Syn/sem for >Bn (n _> 0): =/y y ?
I .
z .
.
.
.f g ~Cl~C2...~Cn.f(g(Cl)(C2)'"(Cn))b. Syn/sem for <B, ( ,  > 0): y I.z.--- 12z2 - - *  x I .z.
.
.
.
12z2 \[lZXg f )~Cl~C2...ACn.f(g(Cl)(C2)''" (Cn))(12) a. A/C/FAIClD D/FAIB BICID DIE ElFb.
AIClFA/C/E E/FA/C/D D/EA/B B/C/DC.~y.l(g(h(k(~)))(y))A/c/FA/B B/C/Df g h kIt is interesting to note a rough resemblance be-tween the tagged version of CCG in (10) and thetagged Lambek cMculus L*, which (Hendriks, 1993)developed to eliminate spurious ambiguity from theLambek calculus L. Although differences betweenCCG and L mean that the details are quite different,each system works by marking the output of certainrules, to prevent such output from serving as inputto certain other rules.4.1 Semantic equivalenceWe wish to establish that each semantic equivalenceclass contains exactly one NF parse.
But what does"semantically equivalent" mean?
Let us adopt astandard model-theoretic view.For each leaf (i.e., lexeme) of a given syntax tree,the lexicon specifies a lexical interpretation from themodel.
CCG then provides a derived interpretationin the model for the complete tree.
The standardCCG theory builds the semantics compositionally,guided by the syntax, according to (11).
We maytherefore regard a syntax tree as a static "recipe" forcombining word meanings into a phrase meaning.82One might choose to say that two parses are se-mantically equivalent iff they derive the same phrasemeaning.
However, such a definition would makespurious ambiguity sensitive to the fine-grained se-mantics of the lexicon.
Are the two analyses ofVP/VP VP VP\VP semantically equivalent?
If thelexemes involved are "softly knock twice," then yes,as softly(twice(knock)) and twice(softly(knock)) ar-guably denote a common function in the semanticmodel.
Yet for "intentionally knock twice" this isnot the case: these adverbs do not commute, andthe semantics are distinct.It would be difficult to make such subtle distinc-tions rapidly.
Let us instead use a narrower, "inten-sional" definition of spurious ambiguity.
The trees in(12a-b) will be considered equivalent because theyspecify the same "recipe," shown in (12c).
No mat-ter what lexical interpretations f, g, h, k are fed intothe leaves A/B, B/C/D, D/E, E/F, both the trees endup with the same derived interpretation, amely amodel element that can be determined from f, g, h, kby calculating Ax~y.f(g(h(k(x)))(y)).By contrast, the two readings of "softly knocktwice" are considered to be distinct, since the parsesspecify different recipes.
That is, given a suitablyfree choice of meanings for the words, the two parsescan be made to pick out two different VP-type func-tions in the model.
The parser is therefore conser-vative and keeps both parses.
44.2 Normal - fo rm pars ing  is safe & completeThe motivation for producing only NF parses (asdefined by (7)) lies in the following existence anduniqueness theorems for CCG.Theorem 1 Assuming "pure CCG," where all pos-sible rules are in the grammar, any parse tree ~ is se-mantically equivalent to some NF parse tree NF(~).
(This says the NF parser is safe for pure CCG: wewill not lose any readings by generating just normalforms.
)Theorem 2 Given distinct NF trees a # o/ (on thesame sequence of leaves).
Then a and a t are notsemantically equivalent.
(This says that the NF parser is complete: generat-ing only normal forms eliminates all spurious ambi-guity.
)Detailed proofs of these theorems are available onthe cmp-lg archive, but can only be sketched here.Theorem 1 is proved by a constructive induction onthe order of a, given below and illustrated in (13):?
For c~ a leaf, put NF(c~) = a.?
(<R, ~, 3'> denotes the parse tree formed by com-bining subtrees/~, 7 via rule R.)If ~ = <R, fl, 7>, then take NF(c~) =<R, gF(f l) ,  NF(7)> , which exists by inductivehypothesis, unless this is not an NF tree.
Inthe latter case, WLOG, R is a forward rule andNF(fl) = <Q,~l,f lA> for some forward com-position rule Q.
Pure CCG turns out to pro-vide forward rules S and T such that a~ =<S, ill, NF(<T, ~2, 7>)> is a constituent andis semantically equivalent to c~.
Moreover, sincefll serves as the primary subtree of the NF treeNF(fl),/31 cannot be the output of forward com-position, and is NF besides.
Therefore a~ is NF:take NF(o 0 = o/.
(13) If NF(/3) not output of fwd.
composition,R R--* --* def= A = NF( )7 iF(Z) NF(7)R R _..+ - -#else ~ : ~ : :~7 NF~"7t(Hepple 8z Morrill, 1989; Hepple, 1990; Hendriks,1993) appear to share this view of semantic equivalence.Unlike (Karttunen, 1986), they try to eliminate onlyparses whose denotations (or at least A-terms) are sys-tematically equivalent, not parses that happen to havethe same denotation through an accident of the lexicon.83R S: :~  ~ def=Q-~7~1~1~' /72  NF ( /72~7)  = NF(~)This construction resembles a well-known normal-form reduction procedure that (Hepple & Morrill,1989) propose (without proving completeness) for asmall fragment of CCG.The proof of theorem 2 (completeness) is longerand more subtle.
First it shows, by a simple induc-tion, that since c~ and ~' disagree they must disagreein at least one of these ways:(a) There are trees/?, 3' and rules R # R' such that<R, fl, 7> is a subtree of a and <R',/3, 7> is asubtree of a'.
(For example, S/S S\S may forma constituent by either <Blx or >Blx.
)(b) There is a tree 7 that appears as a subtree ofboth c~ and cd, but combines to the left in onecase and to the right in the other.Either condition, the proof shows, leads to different"immediate scope" relations in the full trees ~ and ~'(in the sense in which f takes immediate scope over9 in f(g(x)) but not in f(h(g(x))) or g(f(z))) .
Con-dition (a) is straightforward.
Condition (b) splitsinto a case where 7 serves as a secondary argumentinside both cr and a', and a case where it is a primaryargument in c~ or a'.
The latter case requires consid-eration of 7's ancestors; the NF properties cruciallyrule out counterexamples here.The notion of scope is relevant because semanticinterpretations for CCG constituents can be writtenas restricted lambda terms, in such a way that con-stituents having distinct terms must have differentinterpretations in the model (for suitable interpreta-tions of the words, as in ?4.1).
Theorem 2 is provedby showing that the terms for a and a' differ some-where, so correspond to different semantic recipes.Similar theorems for the Lambek calculus werepreviously shown by (Hepple, 1990; ttendriks, 1993).The present proofs for CCG establish a result thathas long been suspected: the spurious ambiguityproblem is not actually very widespread in CCG.Theorem 2 says all cases of spurious ambiguitycan be eliminated through the construction givenin theorem 1.
But that construction merely en-sures a right-branching structure for "forward con-stituent chains" (such as h/B B/C C or h/B/C C/DD/E/F/G G/H), and a left-branching structure forbackward constituent chains.
So these familiarchains are the only source of spurious ambiguity inCCG.5 Extend ing  the  Approach  to"Rest r i c ted"  CCGThe "pure" CCG of ?4 is a fiction.
Real CCG gram-mars can and do choose a subset of the possible rules.For instance, to rule out (14), the (crossing) back-ward rule N/N ~I\N ---* I~/N must be omitted fromEnglish grammar.
(14) \[theNP/N \[\[bigN/N \[that likes John\]N\N \]N/NgalootN \]N\]NPIf some rules are removed from a "pure" CCGgrammar, some parses will become unavailable.Theorem 2 remains true (< 1 NF per reading).Whether theorem 1 (>_ 1 NF per reading) remainstrue depends on what set of rules is removed.
Formost linguistically reasonable choices, the proof oftheorem 1 will go through, 5 so that the normal-formparser of ?4 remains safe.
But imagine removingonly the rule B/a C --~ B: this leaves the string A/BB/C C with a left-branching parse that has no (legal)NF equivalent.In the sort of restricted grammar where theorem 1does not obtain, can we still find one (possibly non-NF) parse per equivalence class?
Yes: a differentkind of efficient parser can be built for this case.Since the new parser must be able to generate anon-NF parse when no equivalent NF parse is avail-able, its method of controlling spurious ambiguitycannot be to enforce the constraints (7).
The oldparser efused to build non-NF constituents; the newparser will refuse to build constituents that are se-mantically equivalent to already-built constituents.This idea originates with (Karttunen, 1986).However, we can take advantage of the core resultof this paper, theorems 1 and 2, to do Karttunen'sredundancy check in O(1) t ime--no worse than thenormal-form parser's check for -FC and -Be tags.
(Karttunen's version takes worst-case exponentialtime for each redundancy check: see footnote ?3.
)The insight is that theorems 1 and 2 estab-lish a one-to-one map between semantic equivalenceclasses and normal forms of the pure (unrestricted)CCG:(15) Two parses a, ~' of the pure CCG aresemantically equivalent iff they have thesame normal form: gF(a)  = gF(a').The NF function is defined recursively by ?4.2'sproof of theorem 1; semantic equivalence is alsodefined independently of the grammar.
So (15) ismeaningful and true even if a, a'  are produced bya restricted CCG.
The tree NF(a) may not be alegal parse under the restricted grammar.
How-ever, it is still a perfectly good data structure thatcan be maintained outside the parse chart, to serve5For the proof to work, the rules S and T must beavailable in the restricted grammar, given that R and Qare.
This is usually true: since (7) favors standard con-stituents and prefers application to composition, mostgrammars will not block the NF derivation while allow-ing a non-NF one.
(On the other hand, the NF parse ofA/B B/C C/D/E uses >B2 twice, while the non-NF parsegets by with >B2 and >B1.
)as a magnet for a's semantic class.
The proof oftheorem 1 (see (13)) actually shows how to con-struct NF(a) in O(1) time from the values of NF onsmaller constituents.
Hence, an appropriate parsercan compute and cache the NF of each parse in O(1)time as it is added to the chart.
It can detect redun-dant parses by noting (via an O(1) array lookup)that their NFs have been previously computed.Figure (1) gives an efficient CKY-style algorithmbased on this insight.
(Parsing strategies besidesCKY would Mso work, in particular (Vijay-Shanker& Weir, 1993).)
The management of cached NFs insteps 9, 12, and especially 16 ensures that duplicateNFs never enter the oldNFs array: thus any alter-native copy of a.nfhas the same array coordinatesused for a.nfitself, because it was built from identi-cal subtrees.The function Pre:ferableTo(~, r) (step 15) pro-vides flexibility about which parse represents itsclass.
P re ferab leTo  may be defined at whim tochoose the parse discovered first, the more left-branching parse, or the parse with fewer non-standard constituents.
Alternatively, P re ferab leTomay call an intonation or discourse module to pickthe parse that better reflects the topic-focus divi-sion of the sentence.
(A variant algorithm ignoresPreferableTo and constructs one parse forest perreading.
Each forest can later be unpacked into in-dividual equivalent parse trees, if desired.
)(Vijay-Shanker & Weir, 1990) also give a methodfor removing "one well-known source" of spuriousambiguity from restricted CCGs; ?4.2 above showsthat this is in fact the only source.
However, theirmethod relies on the grammaticality of certain inter-mediate forms, and so can fail if the CCG rules canbe arbitrarily restricted.
In addition, their methodis less efficient than the present one: it considersparses in pairs, not singly, and does not remove anyparse until the entire parse forest has been built.6 Extens ions  to  the  CCG Formal i smIn addition to the Bn ("generalized composition")rules given in ?2, which give CCG power equivalentto TAG, rules based on the S ("substitution") andT ("type-raising") combinators can be linguisticallyuseful.
S provides another rule template, used inthe analysis of parasitic gaps (Steedman, 1987; Sz-abolcsi, 1989):(16) a.
>s: x /y l l z  y l lz  ?
Ilz/ gb.
<S: y l lz  x \y I l z  --* x I lzAlthough S interacts with Bn to produce anothersource of spurious ambiguity, illustrated in (17), theadditional ambiguity is not hard to remove.
It canbe shown that when the restriction (18) is used to-gether with (7), the system again finds exactly one841.
fo r / :=  l ton2.
C\[i - 1, i\] := LexCats(word\[i\]) (* word i stretches from point i - 1 to point i *)3. for  width := 2 to n4.
for  start := 0 to n -  width5.
end := start + width6.
for  mid := start + 1 to end-  17. for  each parse tree ~ = <R,/9, 7> that could be formed by combining some/9 6 C\[start, miaq with some 7 e C\[mid, ena~ by a rule/~ of the (restricted) grammar8.
a.nf := NF(a) (* can be computed in constant ime using the .nf fields of fl, 7, andother constituents already in C. Subtrees are also NF trees.
*)9. ezistingNF := oldNFs\[~.nf .rule, c~.nf .leftchild.seqno, a.nf .rightchild.seqno\]10. i f  undefined(existingNF) (* the first parse with this NF *)11.
~.nf.seqno := (counter := counter + 1) (* number the new NF ~ add it to oldNFs *)12. oldNFs\[c~.nf rule, c~.nf .leflchild.seqno, a.nf .rightchild.seqno\] := a.nf13.
add ~ to C\[start, ena~14.
a.nf.currparse := c~15.
els i f  P re ferab leTo(a ,  ezistingNF.currparse) (* replace reigning parse?
*)16. a.nf:= existingNF (* use cached copy of NF, not new one *)17. remove a.nf.
currparse from C\[start, en~18.
add ~ to C\[start, enaq19.
~.nfocurrparse :=20.
return(a l l  parses from C\[0, n\] having root category S)Figure 1: Canonicalizing CCG parser that handles arbitrary restrictions on the rule set.
(In practice, asimpler normal-form parser will suffice for most grammars.
)parse from every equivalence class.
(17) a. VPo/NP (<Bx)VPI/NP (<Sx)VP2~P2/NP yesterdayfiled \[without-reading\]b. VPo/NP (<Sx)VP2/NP VP0\VP2/NP (<B2)VP I \V~VPI(18) a.
No constituent produced by >Bn, anyn _> 2, ever serves as the primary (left)argument to >S.b.
No constituent produced by <Bn, anyn > 2, ever serves as the primary (right)argument to <S.Type-raising presents a greater problem.
Vari-ous new spurious ambiguities arise if it is permit-ted freely in the grammar.
In principle one couldproceed without grammatical type-raising: (Dowty,1988; Steedman, 1991) have argued on linguisticgrounds that type-raising should be treated as amere lexical redundancy property.
That is, when-ever the lexicon contains an entry of a certain cate-85gory X, with semantics x, it also contains one with(say) category T/(T\X) and interpretation Ap.p(z).As one might expect, this move only sweeps theproblem under the rug.
If type-raising is lexical,then the definitions of this paper do not recognize(19) as a spurious ambiguity, because the two parsesare now, technically speaking, analyses of differentsentences.
Nor do they recognize the redundancy in(20), because--just as for the example "softly knocktwice" in ?4.1--it is contingent on a kind of lexicalcoincidence, namely that a type-raised subject com-mutes with a (generically) type-raised object.
Suchambiguities are left to future work.
(19) \[JohnNp lefts\NP\]S vs. \[Johns/(S\NP) lefts\NP\]S(20) \[S/(S\NPs) \[S\NPs/NPo/NP I T\(T/NPo)\]\]S/SIVS.
\[S/(S\NPs) S\NPs/NPo/NPI\] T\(T/NPO)\]S/S I7 ConclusionsThe main contribution of this work has been formal:to establish a normal form for parses of "pure" Com-binatory Categorial Grammar.
Given a sentence,every reading that is available to the grammar hasexactly one normal-form parse, no matter how manyparses it has in toto.A result worth remembering is that, althoughTAG-equivalent CCG allows free interaction amongforward, backward, and crossed composition rules ofany degree, two simple constraints serve to eliminateall spurious ambiguity.
It turns out that all spuri-ous ambiguity arises from associative "chains" suchas A/B B/C C or A/B/C C/D D/E\F/G G/H.
(Wit-tenburg, 1987; Hepple & Morrill, 1989) anticipatethis result, at least for some fragments of CCG, butleave the proof to future work.These normal-form results for pure CCG lead di-rectly to useful parsers for real, restricted CCGgrammars.
Two parsing algorithms have been pre-sented for practical use.
One algorithm finds onlynormal forms; this simply and safely eliminates spu-rious ambiguity under most real CCG grammars.The other, more complex algorithm solves the spu-rious ambiguity problem for any CCG grammar, byusing normal forms as an efficient ool for groupingsemantically equivalent parses.
Both algorithms aresafe, complete, and efficient.In closing, it should be repeated that the resultsprovided are for the TAG-equivalent Bn (general-ized composition) formalism of (Joshi et al, 1991),optionally extended with the S (substitution) rulesof (Szabolcsi, 1989).
The technique liminates allspurious ambiguities resulting from the interactionof these rules.
Future work should continue byeliminating the spurious ambiguities that arise fromgrammatical or lexical type-raising.Re ferencesGosse Bouma.
1989.
Efficient processing of flexiblecategorial grammar.
In Proceedings of the FourthConference of the European Chapter of the Associ-ation for Computational Linguistics, 19-26, Uni-versity of Manchester, April.David Dowty.
1988.
Type raising, functional com-position, and non-constituent conjunction.
In R.Oehrle, E. Bach and D. Wheeler, editors, Catego-rial Grammars and Natural Language Structures.Reidel.Mark Hepple.
1987.
Methods for parsing combina-tory categorial grammar and the spurious ambi-guity problem.
Unpublished M.Sc.
thesis, Centrefor Cognitive Science, University of Edinburgh.Mark Hepple.
1990.
The Grammar and Process-ing of Order and Dependency: A Categorial Ap-proach.
Ph.D. thesis, University of Edinburgh.Mark Hepple and Glyn Morrill.
1989.
Parsing andderivational equivalence.
In Proceedings of theFourth Conference of the European Chapter of theAssociation for Computational Linguistics, 10-18,University of Manchester, April.Herman Hendriks.
1993.
Studied Flexibility: Cate-gories and Types in Syntax and Semantics.
Ph.D.thesis, Institute for Logic, Language, and Compu-tation, University of Amsterdam.Aravind Joshi, K. Vijay-Shanker, and David Weir.1991.
The convergence ofmildly context-sensitivegrammar formalisms.
In Foundational Issues inNatural Language Processing, MIT Press.Lauri Karttunen.
1986.
Radical exicalism.
ReportNo.
CSLI-86-68, CSLI, Stanford University.E.
KSnig.
1989.
Parsing as natural deduction.
InProceedings of the 27lh Annual Meeting of the As-sociation for Computational Linguistics, Vancou-ver.J.
Lambek.
1958.
The mathematics of sen-tence structure.
American Mathematical Monthly65:154-169.Michael Moortgat.
1990.
Unambiguous proof repre-sentations for the Lambek Calculus.
In Proceed-ings of the Seventh Amsterdam Colloquium.Michael Niv.
1994.
A psycholinguistically moti-vated parser for CCG.
In Proceedings of the 32ndAnnual Meeting of the Association for Computa-tional Linguistics, Las Cruces, NM, June.Remo Paresehi and Mark Steedman.
A lazy way tochart parse with eombinatory grammars.
In Pro-ceedings of the P5th Annual Meeting of the As-sociation for Computational Linguistics, StanfordUniversity, July.Scott Prevost and Mark Steedman.
1994.
Specify-ing intonation from context for speech synthesis.Speech Communication, 15:139-153.Mark Steedman.
1990.
Gapping as constituent coor-dination.
Linguistics and Philosophy, 13:207-264.Mark Steedman.
1991.
Structure and intonation.Language, 67:260-296.Mark Steedman.
1987.
Combinatory grammars andparasitic gaps.
Natural Language and LinguisticTheory, 5:403-439.Anna Szabolcsi.
1989.
Bound variables in syntax:Are there any?
In R. Bartsch, J. van Benthem,and P. van Emde Boas (eds.
), Semantics and Con-textual Expression, 295-318.
Forts, Dordrecht.K.
Vijay-Shanker and David Weir.
1990.
Polyno-mial time parsing of combinatory ?ategorial gram-mars.
In Proceedings of the P8th Annual Meetingof the Association for Computational Linguistics.K.
Vijay-Shanker and David Weir.
1993.
Parsingsome constrained grammar formalisms.
Compu-tational Linguistics, 19(4):591-636.K.
Vijay-Shanker and David Weir.
1994.
The equiv-alence of four extensions of context-free gram-mars.
Mathematical Systems Theory, 27:511-546.Kent Wittenburg.
1986.
Natural Language Pars-ing with Combinatory Calegorial Grammar in aGraph-Unification-Based Formalism.
Ph.D. the-sis, University of Texas.Kent Wittenburg.
1987.
Predictive combinators:A method for efficient parsing of CombinatoryCategorial Grammars.
In Proceedings of the 25thAnnual Meeting of the Association for Computa-tional Linguistics, Stanford University, July.86
