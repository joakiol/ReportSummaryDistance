Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational NaturalLanguage Learning, pages 1379?1388, Jeju Island, Korea, 12?14 July 2012. c?2012 Association for Computational LinguisticsPart-of-Speech Tagging for Chinese-English Mixed Textswith Dynamic FeaturesJiayi Zhao?
Xipeng Qiu?
Shu Zhang?
Feng Ji?
Xuanjing Huang?School of Computer Science, Fudan University, Shanghai, China ?
?Fujitsu Research and Development Center, Beijing, China?zjy.fudan@gmail.com?
{xpqiu,fengji,xjhuang}@fudan.edu.cn?zhangshu@cn.fujitsu.com ?AbstractIn modern Chinese articles or conversations,it is very popular to involve a few Englishwords, especially in emails and Internet liter-ature.
Therefore, it becomes an important andchallenging topic to analyze Chinese-Englishmixed texts.
The underlying problem is howto tag part-of-speech (POS) for the Englishwords involved.
Due to the lack of speciallyannotated corpus, most of the English wordsare tagged as the oversimplified type, ?foreignwords?.
In this paper, we present a methodusing dynamic features to tag POS of mixedtexts.
Experiments show that our methodachieves higher performance than traditionalsequence labeling methods.
Meanwhile, ourmethod also boosts the performance of POStagging for pure Chinese texts.1 IntroductionNowadays, Chinese-English mixed texts areprevalent in modern articles or emails.
More andmore English words are used in Chinese texts asnames of organizations, products, terms and abbre-viations, such as ?eBay?, ?iPhone?, ?GDP?, ?An-droid?
etc.
On the other hand, it is also a commonphenomenon to use Chinese-English mixed textsin daily conversation, especially in communicationamong employers in large international corporations.There are some challenges for analyzing Chinese-English mixed texts:1.
How to define the POS tags for English wordsin these mixed texts.
Since the standard ofPOS tags for English and Chinese are different,we cannot use English POS to tag the Englishwords in mixed texts.2.
Due to lack of annotated corpus for mixed texts,most of the English words are tagged as ?for-eign words?, which is oversimplified.
So wecannot use them in further processing for thesyntactic and semantic analysis.3.
Most English words used in mixed texts are of-ten out-of-vocabulary (OOV), which thus in-creases the difficulties to tag them.Currently, the mainstream method of ChinesePOS tagging is joint segmentation & tagging withcross-labels, which can avoid the problem of errorpropagation and achieve higher performance on bothsubtasks(Ng and Low, 2004).
Each label is the cross-product of a segmentation label and a tagging la-bel, e.g.
{B-NN, I-NN, E-NN, S-NN, ...}.
The fea-tures are generated by position-based templates oncharacter-level.Since the main part of mixed texts is in Chineseand the role of English word is more like Chinese,we use Chinese POS tags (Xia, 2000) to tag Englishwords.
Since the categories of the most commonlyused English words are nouns, verbs and adjectives,we can use ?NN?, ?NR?, ?VV?, ?VA?, ?JJ?
to labeltheir POS tags.For the English proper nouns and verbs, thereare no significant differences in Chinese and En-glish POS tags except that English features pluraland tense forms.For the English nouns, these are some Englishnouns used as verbs, such as ???
[fan/VV]??
(Iadore him very much.)?
where ?fan?
means ?adore?and is used as a verb.For the English adjectives, there are two corre-sponding Chinese POS tags ?VA?
and ?JJ?.
For ex-ample, the roles of some English words in Table 1,1379Table 1: The POS tags of English Adjectives in MixedTextsChinese English?
?
?
[profes-sional/VA]?I am very profes-sional.???
[high/VA]?
Feel very high.??
[super/JJ] [star/NN] He is a super star.such as ?professional?
and ?high?, are different withtheir original ones.Therefore, the POS tagging for mixed texts cannotbe settled with simple methods, such as looking upin a dictionary.One of the main differences between Chinese andEnglish in POS tagging is that the two languageshave character-based features and word-based fea-tures respectively.
To ensure the consistency of tag-ging models, we prefer to use word-level informa-tion in Chinese, which is both useful for Chinese-English mixed texts and Chinese-only texts.
For in-stance, in a sentence ?X ??
Y ... (X or Y ...)?,the word Y ought to have the same POS tag as theword X .
Another example is that the word follow-ing a pronoun is usually a verb, and adjectives of-ten describe nouns.
Some related works show thatword-level features can improve the performance ofChinese POS tagging (Jiang et al 2008; Sun, 2011).In this paper, we propose a method to tag mixedtexts with dynamic features.
Our method combinesthese dynamic features, which are dynamically gen-erated at the decoding stage, with traditional staticfeatures.
For Chinese-English mixed texts, the tra-ditional features cannot yield a satisfied result due tolack of training data.
The proposed dynamic featurescan improve the performance by using the informa-tion of a word, such as POS tag or length of the wholeword, which is proven effective by experiments.The rest of the paper is organized as follows: Insection 2, we introduce the sequence labeling mod-els, thenwe describe our method of dynamic featuresin section 3 and analyze its complexity in section 4.Section 5 describes the training method.
The exper-imental results are manifested in section 6.
Finally,We review the relevant research works in section 7and conclude our work in section 8.2 Sequence Labeling ModelsSequence labeling is the task of assigning labelsy = y1, .
.
.
, yn to an input sequence x = x1, .
.
.
, xn.Given a sample x, we define the feature ?
(x, y).Thus, we can label x with a score function,y?
= argmaxyF (w,?
(x, y)), (1)where w is the parameter of function F (?
).For sequence labeling, the feature can be denotedas?k(yi, yi?1, x, i), where i stands for the position inthe sequence and k stands for the number of featuretemplates.we use online Passive-Aggressive (PA) algorithm(Crammer and Singer, 2003; Crammer et al 2006)to train the model parameters.
Following (Collins,2002), the average strategy is used to avoid the over-fitting problem.3 Dynamic FeaturesThe form of traditional features is shown in Table2, where C represents a Chinese character, and Trepresents the character-based tag.
The subscript iindicates its position related to the current character.Table 2: Traditional Feature TemplatesCi, T0(i = ?2,?1, 0, 1, 2)Ci, Cj , T0(i, j = ?2,?1, 0, 1, 2 and i ?= j)T?1, T0Traditional features are generated by position-fixed templates.
Since the length of Chinese wordis unfixed, their meanings are incomplete.
We cat-egorize them as ?static?
features since they can becalculated before tagging (except ?T?1, T0?
).The form of dynamic features is shown in Table3, where WORD represents a Chinese word, andPOS (LEN ) is the POS tag (length) of the word.The subscript of dynamic feature template indicatesits position related to the current word.Table 4 shows an example.
If the current posi-tion is ?
Apple?, then {POS?1=CC, POS?2=NR,WORD?1=??
?, LEN?2=2}.
Since these featuresare unavailable before tagging, we call them ?dy-namic?
features.1380Table 3: Examples of Dynamic Feature TemplatesPOSi, POSj , T0(i, j = ?2,?1, 0 and i ?= j)POSi,WORDj , T0(i, j = ?2,?1, 0)WORDi, LENj , POSk, T0(i, j, k = ?2,?1, 0)?Dynamic features are more flexible because thenumber of involved characters is dependent on thelength of previous words.
Unlike static features, dy-namic features do not merely rely on the input se-quence C1:n, so the weights of dynamic features, inwhich POS/LEN are involved, can be trained byChinese-only texts and used by mixed texts, whichresolve the problem of the lack of training data.4 Tagging with Dynamic FeaturesIn the tagging stage, we use the current best resultto approximately calculate the unknown tag infor-mation.
For an input sequence C1:n, the current besttags from index 0 to i?1 can be calculated by Viterbialgorithm and they can be used to generate dynamicfeatures for index i.
The specific algorithm is shownin Algorithm 1.Here is an example to explain the time com-plexity of the dynamic features.
Normal templatexi?2xi?1yi requires to look for the positions ofi ?
2 and i ?
1 related to the current characterxi, but dynamic template posi?2posi?1yi needs toknow the pos tags of two words.
If the length ofwordi?1/wordi?2 is 2, then the positions of i?4, i?3, i?2, i?1 are needed to generate the dynamic fea-tures.For all dynamic features, it is unnecessary torepetitively calculate the POS/WORD/LEN ar-ray.
Apart from that one time calculation of the ar-ray, no distinction can be found between the timecomplexity of the dynamic features and the tradi-tional features.
For input C1:n, the time complexityisO(n?
[O(op.2)+(Ts.num+Td.num)?O(op.1)+O(op.4)]), n.b.
O(op.1) = O(op.3).
Universallythe dynamic features only require the information ofposition i ?
2 and i ?
1, so the time complexity ofcalculating the POS/WORD/LEN array can beignored as compared with the complexity of Viterbialgorithm and feature extraction.
The approximatealgorithm is thus faster than the Brute-Force way byinput : character sequence C1:nstatic templates Tsdynamic templates Tdnumber of labelsmtrans matrixMoutput: resultsMax & VpInitialize: weight matrixW (n?m)viterbi score matrix Vs (n?m)viterbi path matrix Vp (n?m)the index of current best labelMaxfor i = 1 ?
?
?n dofor ts in Ts do// create feature string Fs (Op.1)Fs = createFeature(C1:n, ts);W [i] += getWeightVector(Fs);end// create a list of <posk,wordk,lenk>// (k = 0,?1,?2 .
.
.)
(Op.2)dList = getCurrentBestPath(Max, Vp);for td in Td do// create dynamic features string Fd// (Op.3)Fd = createFeature(C1:n, td, dList);W [i] += getWeightVector(Fd);end// Update Vs[i], Vp[i] (Op.4)viterbi_OneStep(Vs[i?
1],W [i],M );Max = argmaxi(Vs[i]) ;endAlgorithm 1: Tagging Algorithm with DynamicFeaturesusing word-level information.5 TrainingGiven an example (x, y), y?
are denoted as the in-correct labels with the highest scorey?
= argmaxz ?=ywT?
(x, z).
(2)The margin ?
(w; (x, y)) is defined as?
(w; (x, y)) = wT?
(x, y)?
wT?
(x, y?).
(3)Thus, we calculate the hinge loss ?
(w; (x, y), (ab-breviated as ?w) by1381Table 4: Example for Chinese-English Mixed POS Tagging?
?
?
Apple ?
OS ?
?
?
?
?B-NR E-NR S-CC S-NR S-DEG S-NN B-NN E-NN B-VA E-VA S-PU?w ={0, ?
(w; (x, y)) > 11?
?
(w; (x, y)), otherwise (4)In round k, the new weight vector wk+1 is calcu-lated bywk+1 = argminw12||w?
wk||2 + C ?
?,s.t.
?
(w; (xk, yk)) <= ?
and ?
>= 0 (5)where ?
is a non-negative slack variable, and C isa positive parameter which controls the influence ofthe slack term on the objective function.Following the derivation in PA (Crammer et al2006), we can get the update rule,wk+1 = wk + ?k(?
(xk, yk)?
?
(xk, y?k)), (6)where?k = min(C,?wk??
(xk, yk)?
?
(xk, y?k)?2) (7)Our algorithm based on PA algorithm is shown inAlgorithm 2.6 ExperimentsWe implement our system based on FudanNLP1.We employ the commonly used label set {B, I, E,S} for the segmentation part of cross-labels.
{B,I, E} represent Begin, Inside, End of a multi-nodesegmentation respectively, and S represents a Singlenode segmentation.The F1 score is used for evaluation, which is theharmonic mean of precision P (percentage of pre-dict phrases that exactlymatch the reference phrases)and recallR (percentage of reference phrases that re-turned by system).The feature templates, which are used to extractfeatures, are listed in Table 5.
We set traditionalmethod (static features) as the baseline.
The detailedexperimental settings and results are reported in thefollowing subsections.1Available at http://code.google.com/p/fudannlp/input : training data sets:(xi, yi), i = 1, ?
?
?
, N , and parameters:C,Koutput: wKInitialize: wTemp?
0,w?
0;for k = 0 ?
?
?K ?
1 dofor i = 1 ?
?
?N doreceive an example (xi, yi);predict: y?i = argmaxy?wk,?
(xi, y)?
;if y?i ?= yi thenupdate wk+1 with Eq.
6;endendwTemp = wTemp+ wk+1 ;endwK = wTemp/K ;Algorithm 2: Training AlgorithmTable 5: Feature TemplatesStaticxi?2yi, xi?1yi, xiyi, xi+1yi, xi+2yixi?1xiyi, xi+1xiyi, xi?1xi+1yi,yi?1yiDynamicposi?2posi?1yi, posi?1posiyiposi?2wordi?1yi, posi?1wordiyiposi?1wordi?1yi, posiwordiyiwordi?2wordi?1yi, wordi?1wordiyiwordileniyi6.1 POS Tagging for Chinese-only TextsBefore the experiments onChinese-Englishmixedtexts, we evaluate the performance of our method onChinese-only texts.
We use the CTB dataset fromthe POS tagging task of the Fourth International Chi-nese Language Processing Bakeoff (SIGHAN Bake-off 2008)(Jin and Chen, 2008).
The details areshown in Table 6.The performance comparison on joint segmenta-tion & POS tagging is shown in Table 7.
Our methodobtains an error reduction of 6.7% over the baseline.The reason is that our dynamic features can utilize1382Table 6: POS Tagging Dataset in SIGHAN Bakeoff 2008Train Set Test Set(number) (number)Sentence 23444 2079WordTotal 642246 59955NN 168896 16793NR 42906 3970VV 92887 8641VA 9106 649JJ 15640 1581word-level information effectively and the featuretemplates are more flexible.Table 7: Performances of POS Tagging on Chinese-onlyTexts with Static and Dynamic FeaturesMethod P R F1Baseline 89.68 89.60 89.64Our 90.35 90.31 90.336.2 POS Tagging for Chinese-English MixedTextsWithout annotated corpus for Chinese-Englishmixed texts, we use synthetic data as the alternative.In Chinese-English mixed texts, English words ofnoun(NN/NR), verb(VV/VA) and adjective(JJ) cat-egories are the most commonly used, so we ran-domly transform a certain percentage of Chinesewords with these POS tags in the SIGHAN Bakeoff2008 dataset(Jin and Chen, 2008) into their Englishcounterparts.6.2.1 Synthetic DataBefore trying out an experiment, we first studyhow to generate the data of mixed texts.We use two ways to produce the synthetic data:?Respective Replacement?
and ?Unified Replace-ment?.Respective Replacement We replace the selectedChinese words into their corresponding Englishcounterparts.Unified Replacement We replace the selected Chi-nese words with a unified labelENG.
The rea-son we use the labelENG instead of real wordsis that we want to consider the context of thesewords but not the words themselves and over-come the problem of out-of-vocabulary (OOV)English words.For our experiments, we just select 5% of the Chi-nese nouns and verbs from SIGHAN dataset, and re-place them in the above two ways.
After replace-ment, the training and test data have 12780 and 1254English words, respectively.
5189 words are gener-ated by way of ?Respective Replacement?.
In thetest data, 326words are OOV, which comprises 25%of the whole vocabulary.
The information of gener-ated data is shown in Table 8.Table 8: The Synthetic Chinese-English Mixed DatasetHDataset Numbers of ENGNN VVH Train Set 8191 4589Test Set 842 412We use H1 to represent the dataset generated byway of ?Respective Replacement?, and H2 for thedataset by way of with ?Unified Replacement?.
Theexperimental results on these two datasets are shownin Table 9.Table 9: Performances of POS Tagging on Dataset H1and H2Method Dataset ENG OOV TotalF1 F1oov F1Baseline H1 73.60 54.91 88.93H2 77.59 73.93 89.11Our H1 75.60 54.60 89.79H2 79.82 77.61 89.81From Table 9, we can see that the ?UnifiedReplacement?
way is better than the ?RespectiveReplacement?
way for both the baseline and ourmethod.
The main reason is that the ?Unified Re-placement?
way can greatly improve the tagging per-formance of OOV words.6.2.2 Detail ComparisonsFor detail comparisons of all situations ofmixed texts, we design six synthetic datasets,A/B/C/D1/D2/E by randomly selecting 10% or15% of Chinese words (?NN/NR/VV/VA/JJ?)
in the1383above SIGHANBakeoff 2008 dataset, and replacingthem with English label ENG.The differences of these datasets are as following:?
Dataset A only contains English words withtags ?NN/VV?.?
Dataset B contains English words with tags?NN/VV/VA?.?
Dataset C contains one more tag ?NR?
thanDataset B.?
Datasets D1 and D2 contain one more tag ?JJ?than Dataset B.
The difference between D1andD2 is thatD2 has about 50%more Englishwords than D1 in training set.?
Dataset E contains English words with all thetags ?NN/NR/VV/VA/JJ?.The detailed information of datasetsA/B/C/D1/D2/E is shown in Table 10.Table 10: The Synthetic Chinese-English Mixed DatasetDataset Numbers of ENGNN NR VV VA JJA Train 16302 0 9007 0 0Test 1675 0 841 0 0B Train 16116 0 8882 906 0Test 1573 0 830 58 0C Train 16312 4057 9067 899 0Test 1549 400 795 61 0D1Train 16042 0 8957 855 1539Test 1588 0 845 58 150D2Train 23705 0 13154 1300 2211Test 1588 0 845 58 150E Train 16066 4162 9156 886 1547Test 1647 415 809 57 141The results are shown in Table 11.
On dataset E,our method achieves 6.78% higher performance ontagging ENG labels than traditional static features.This result is reasonable because our model can usemore flexible feature templates to extract featuresand reduce the problem of being dependent on spe-cific English words.Tables 12/13/14/15/16/17 show the detailed re-sults on datasets A/B/C/D1/D2/E.Table 11: Performances of POS Tagging on DatasetsA/B/C/D1/D2/EDataset Method ENG labels TotalF1 F1A Baseline 80.25 88.74Our 83.03 89.72B Baseline 76.72 88.51Our 80.54 89.55C Baseline 68.16 88.13Our 70.34 88.99D1Baseline 71.30 88.33Our 74.02 89.15D2Baseline 69.59 88.09Our 74.10 89.15E Baseline 61.58 87.71Our 68.36 88.83Experiment on dataset A gets the best result be-cause ?NN?
and ?VV?
can be easily distinguished byits context.
Sometimes, ?VA?
has the similar contextwith ?VV?, experiment on datasetB shows its influ-ence.
The performances on datasetsB/C/E descendin turn.
The reason is that words with tag ?NN?
or?NR/JJ?
have the similar usage/contexts in Chinese.Since we use the same form ENG instead of realwords, there are no differences between these words,which leads to some errors.
Though the datasets isgenerated randomly, we can see our method performbetter on every dataset than the baseline.Table 12: Performances on Dataset APOS tag Method P R F1NN Baseline 84.36 86.33 85.33Our 85.37 89.91 87.58VV Baseline 71.45 68.13 69.75Our 77.53 69.32 73.20Table 13: Performances on Dataset BPOS tag Method P R F1NN Baseline 84.89 80.36 82.56Our 83.51 88.87 86.11VV Baseline 65.90 72.65 69.11Our 75.75 67.35 71.30VA Baseline 36.84 36.21 36.52Our 51.02 43.10 46.731384Table 14: Performances on Dataset CPOS tag Method P R F1NN Baseline 73.77 78.24 75.94Our 76.84 77.99 77.41VV Baseline 61.67 66.79 64.13Our 64.94 67.80 66.34NR Baseline 55.22 37.00 44.31Our 55.65 50.50 52.95VA Baseline 63.64 34.43 44.68Our 60.00 39.34 47.52Table 15: Performances on DatasetD1POS tag Method P R F1NN Baseline 77.15 81.42 79.23Our 76.70 88.54 82.20VV Baseline 67.53 64.50 65.98Our 79.65 59.76 68.29JJ Baseline 25.00 18.00 20.93Our 22.92 14.67 17.89VA Baseline 36.00 31.03 33.33Our 28.57 37.93 32.59Table 16: Performances on DatasetD2POS tag Method P R F1NN Baseline 79.11 74.87 76.93Our 79.29 82.68 80.95VV Baseline 55.77 72.78 65.64Our 69.17 70.89 70.02JJ Baseline 27.27 12.00 16.67Our 34.38 22.00 26.83VA Baseline 37.21 27.59 31.68Our 52.17 20.69 29.636.3 POS Tagging for Mixed Texts with a RealDatasetTo investigate the actual performance, we collecta real dataset from Web, which consists of 142 rep-resentative Chinese-English mixed sentences.
Thisdataset contains 4, 238 Chinese characters and 275English words.
Since we focus on the performancefor English words, we only label the POS tags of theEnglish words.
Table 18 shows some examples inthe real dataset of mixed texts.Table 17: Performances on Dataset EPOS tag Method P R F1NN Baseline 72.41 68.85 70.59Our 71.18 84.88 77.43VV Baseline 63.65 59.09 61.28Our 76.19 55.38 64.14JJ Baseline 28.57 25.53 26.97Our 30.21 20.57 24.47VA Baseline 44.83 45.61 45.22Our 60.42 50.88 55.24NR Baseline 38.03 52.05 43.95Our 52.01 46.75 49.24Table 18: Examples in Real Dataset of Mixed Texts??
[Ninja Cloud/NR] ?????
[NinjaBlocks/NR] ?
?
[Facebook/NR]?
[Twit-ter/NR]?[Dropbox/NR]?????
?By using [Ninja Cloud/NR], [NinjaBlocks/NR] can connect to [Facebook/NR],[Twitter/NR], [Dropbox/NR].??
[follow/VV]????????
?You should [follow/VV] this man?s work.??????????
[COOL/VA]?...
very [COOL/VA]!The information of the real dataset is shown in Ta-ble 19.
If all involved English words are tagging as?NN?, the precision is just 56%.Table 19: The Numbers of English Words with DifferentTags in Dataset RDataset NN VV VA NRR 154 58 28 35Since there is no noun-modifier ?JJ?
in our col-lected data.
We use the models trained on datasetB and C to tag the real data.
The results are shownin Table 20.
The difference between model B andC is that model B regards all words with tag ?NR?as ?NN?.
Since it is difficult to distinguish between?NR?
and ?NN?
merely according to the context,model B performs better than model C.The detail results of model B and C are shown inTable 21 and 22.1385Table 20: Performances of POS Tagging on RModel Method ENGF1B Baseline 74.91Our 82.55C Baseline 70.91Our 74.91Table 21: Performances of Model B on Dataset RPOS tag Method P R F1NN Baseline 88.62 78.31 83.15Our 91.67 87.30 89.43VV Baseline 48.31 74.14 58.50Our 60.53 79.31 68.66VA Baseline 78.95 53.57 63.83Our 84.21 57.14 68.09Table 22: Performances of Model C on Dataset RPOS tag Method P R F1NN Baseline 80.25 81.82 81.03Our 84.56 81.82 83.17VV Baseline 54.88 77.59 64.29Our 61.25 84.48 71.01VA Baseline 84.62 39.29 53.66Our 88.24 53.57 66.67NR Baseline 56.52 37.14 44.83Our 55.17 45.71 50.007 Related WorksIn recent years, POS tagging has undergone greatdevelopment.
The mainstream method is to regardPOS tagging as sequence labeling problems (Ra-biner, 1990; Xue, 2003; Peng et al 2004; Ng andLow, 2004).However, the analysis of Chinese-English mixedtexts is rarely involved in previous literature.
Inthe aspect of the general multilingual POS tagging,most works focus on modeling cross-lingual corre-lations and tagging multilingual POS on respectivemonolingual texts, not on mixed texts (Cucerzan andYarowsky, 2002; Yarowsky et al 2001; Naseem etal., 2009).Since we choose to use dynamic word-level fea-tures to improve the performance of POS tagging,we also review some works on word-level features.Semi-Markov Conditional Random Fields (semi-CRF) (Sarawagi and Cohen, 2004) is a model inwhich segmentation task is implicitly included intothe decoding algorithm.
In this model, feature rep-resentation would be more flexible than traditionalCRFs, since features can be extracted from the previ-ous/the next segmentation within a window of vari-able size.
The problem of this approach lies in thatthe decoding algorithm depends on the predefinedwindow size to exploit the boundaries of segmenta-tions but not the real length of words.Bunescu (2008) presents an improved pipelinemodel in which the output of the previous subtasksare considered as hidden variables, and the hiddenvariables together with their probabilities denotingthe confidence are used as probabilistic features inthe next subtasks.
One shortcoming of this methodis inefficiency caused by the calculation of marginalprobabilities of features.
The other disadvantagesof the pipeline method are error propagation and theneed of separate training of different subtasks in thepipeline.
Another disadvantage of pipeline methodis error propagation.Jiang et al(2008) proposes a cascaded linearmodel for joint Chinese word segmentation and POStagging.
With a character-based perceptron as thecore, combinedwith real-valued features such as lan-guage models, the cascaded model can efficientlyutilize knowledge sources that are inconvenient toincorporate into the perceptron directly.
However,they use POS tags or word information in a Brute-Force way, which may suffer from the problem oftime complexity.Sun (2011) presents a stacked sub-word model forjoint Chinese word segmentation and POS tagging.By merging the outputs of the three predictors (in-cluding one word-based segmenter) into sub-wordsequences, rich contextual features can be approx-imately derived.
The experiments are conducted toshow the effectiveness of using word-based informa-tion.The difference between the above methods andours is that our word-level features are dynamicallygenerated in the decoding stage without exhaustiveor preprocessed word segmentation.13868 ConclusionIn this paper, we focus on Chinese-English mixedtexts and use dynamic features for POS tagging.To overcome the problem of the lack of annotatedcorpus on mixed texts, our features use both lo-cal and non-local information and take advantage ofthe characteristics of Chinese-English mixed texts.The experiments demonstrate the effectiveness ofour method.
It should be noted that our method isalso effective for the mixed texts of Chinese and anyforeign languages since we use ?Unified Replace-ment?.For future works, we plan to improve our approx-imate tagging algorithm to reduce error propagation.In addition, we will refer to an English dictionaryto generate some useful features to distinguish be-tween ?NR?
and ?NN?
in Chinese-English mixedtexts and add some statistical features derived fromEnglish resources, such as the most common tag ofeach English word.
We would also like to investi-gate these features in more applications of naturallanguage processing, such as name entity recogni-tion, information extraction, etc.AcknowledgementsWe would like to thank the anonymous reviewersfor their valuable comments.
We also thanks AmyZhou for her help in spell and grammar checking.This work was funded by NSFC (No.61003091 andNo.61073069), 863 Program (No.2011AA010604)and 973 Program (No.2010CB327900).ReferencesRazvan C. Bunescu.
2008.
Learning with probabilisticfeatures for improved pipeline models.
In EMNLP,pages 670?679.
ACL.Michael Collins.
2002.
Discriminative training methodsfor hidden markov models: theory and experimentswith perceptron algorithms.
In Proceedings of theACL-02 conference on Empirical methods in naturallanguage processing - Volume 10, EMNLP ?02, pages1?8, Stroudsburg, PA, USA.
Association for Compu-tational Linguistics.Koby Crammer and Yoram Singer.
2003.
Ultraconser-vative online algorithms for multiclass problems.
J.Mach.
Learn.
Res., 3:951?991, March.Koby Crammer, Ofer Dekel, Joseph Keshet, ShaiShalev-Shwartz, and Yoram Singer.
2006.
Onlinepassive-aggressive algorithms.
J. Mach.
Learn.
Res.,7:551?585, December.Silviu Cucerzan and David Yarowsky.
2002.
Boot-strapping a multilingual part-of-speech tagger in oneperson-day.
In proceedings of the 6th conference onNatural language learning - Volume 20, COLING-02, pages 1?7, Stroudsburg, PA, USA.
Association forComputational Linguistics.Wenbin Jiang, Liang Huang, Qun Liu, and Yajuan L?.2008.
A cascaded linear model for joint chinese wordsegmentation and part-of-speech tagging.
In Kath-leen McKeown, Johanna D. Moore, Simone Teufel,James Allan, and Sadaoki Furui, editors, ACL, pages897?904.
The Association for Computer Linguistics.C.
Jin and X. Chen.
2008.
The fourth international chi-nese language processing bakeoff: Chinese word seg-mentation, named entity recognition and chinese postagging.
In Sixth SIGHAN Workshop on Chinese Lan-guage Processing, page 69.T.
Naseem, B. Snyder, J. Eisenstein, and R. Barzilay.2009.
Multilingual part-of-speech tagging: Two unsu-pervised approaches.
Journal of Artificial IntelligenceResearch, 36(1):341?385.H.T.
Ng and J.K. Low.
2004.
Chinese part-of-speechtagging: One-at-a-time or all-at-once?
word-based orcharacter-based.
In Proceedings of EMNLP, volume2004, page 277.Fuchun Peng, Fangfang Feng, and Andrew McCallum.2004.
Chinese segmentation and new word detectionusing conditional random fields.
In Proceedings of the20th international conference on Computational Lin-guistics, COLING ?04, Stroudsburg, PA, USA.
Asso-ciation for Computational Linguistics.Lawrence R. Rabiner.
1990.
Readings in speech recog-nition.
chapter A tutorial on hidden Markov mod-els and selected applications in speech recognition,pages 267?296.
Morgan Kaufmann Publishers Inc.,San Francisco, CA, USA.Sunita Sarawagi and William W. Cohen.
2004.
Semi-markov conditional random fields for information ex-traction.
In NIPS.Weiwei Sun.
2011.
A stacked sub-word model forjoint chinese word segmentation and part-of-speechtagging.
In Dekang Lin, Yuji Matsumoto, and RadaMihalcea, editors, ACL, pages 1385?1394.
The Asso-ciation for Computer Linguistics.F.
Xia.
2000.
The part-of-speech tagging guidelines forthe Penn Chinese Treebank (3.0).N.
Xue.
2003.
Chinese word segmentation as charactertagging.
Computational Linguistics and Chinese Lan-guage Processing, 8(1):29?48.D.
Yarowsky, G. Ngai, and R. Wicentowski.
2001.
In-ducing multilingual text analysis tools via robust pro-jection across aligned corpora.
In Proceedings of1387the first international conference on Human languagetechnology research, pages 1?8.
Association for Com-putational Linguistics.1388
