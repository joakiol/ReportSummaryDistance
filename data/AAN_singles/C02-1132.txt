Probabilistic Models of Verb-Argument StructureDaniel GildeaDept.
of Computer and Information ScienceUniversity of Pennsylvaniadgildea@cis.upenn.eduAbstractWe evaluate probabilistic models of verb argumentstructure trained on a corpus of verbs and their syn-tactic arguments.
Models designed to represent pat-terns of verb alternation behavior are compared withgeneric clustering models in terms of the perplexityassigned to held-out test data.
While the special-ized models of alternation do not perform as well,closer examination reveals alternation behavior rep-resented implicitly in the generic models.1 IntroductionRecent research into verb-argument structure hashas attempted to acquire the syntactic alternationbehavior of verbs directly from large corpora.
Mc-Carthy (2000), Merlo and Stevenson (2001), andSchulte im Walde (2000) have evaluated their sys-tems?
accuracy against human judgments of verbclassification, with the comprehensive verb classesof Levin (1993) often serving as a gold standard.Another area of research has focused on automaticclustering algorithms for verbs and their argumentswith the goal of finding groups of semantically re-lated words (Pereira et al, 1993; Rooth et al, 1999),without focusing specifically on alternation behav-ior.
We aim to bring these strands of research to-gether with a unified probabilistic model of verb ar-gument structure incorporating alternation behavior.Unraveling the mapping between syntactic func-tions such as subject and object and semantic rolessuch as agent and patient is an important pieceof the language understanding problem.
Learn-ing the alternation behavior of verbs automaticallyfrom unannotated text would significantly reducethe amount of labor needed to create text under-standing systems, whether that labor takes the formof writing lexical entries or of annotating semanticinformation to train statistical systems.Our use of generative probabilistic models of ar-gument structure also allows for language modelingapplications independent of semantic interpretation.Language models based on head-modifier lexicaldependencies in syntactic trees have been shown tohave lower perplexity than n-gram language modelsand to reduce word-error rates for speech recogni-tion (Chelba and Jelinek, 1999; Roark, 2001).
In-corporating semantic classes and verb alternationbehavior could improve such models?
performance.Automatically derived word clusters are used in thestatistical parsers of Charniak (1997) and Mager-man (1995).
Incorporating alternation behavior intosuch models might improve parsing results as well.This paper focuses on evaluating probabilisticmodels of verb-argument structure in terms of howwell they model unseen test data, as measured byperplexity.
We will examine maximum likelihoodbigram and trigram models, clustering models basedon those of Rooth et al (1999), as well as a newprobabilistic model designed to capture alternationsin verb-argument structure.2 Capturing Alternation BehaviorAutomatic clustering of co-occurrences of verbs andtheir direct objects was first used to induce se-mantically related classes of both verbs and nouns(Pereira et al, 1993).
Rooth et al (1999) usedthe Expectation Maximization algorithm to performsoft clustering by optimizing the parameters of afairly simple probability model, which considers theverb and noun to be independent given the unob-served cluster variable c:P (v; n) =XcP (c)P (vjc)P (njc)In Rooth et al (1999), the variable v represented notonly the lexical verb but also its syntactic relation tothe noun: either direct object, subject of an intransi-tive, or subject of a transitive verb.However, the relationship between the underly-ing, semantic arguments of a verb and the syntac-tic roles in a sentence is not always straightforward.Many verbs exhibit alternations in their syntacticbehavior, as shown by the following examples:(1) The Federal Reserve increased rates by 1/4%.
(2) Interest rates have increased sharply over thepast year.The noun rates appears as the syntactic objectof the verb increase in the first sentence, butas its subject in the second sentence, where theverb is used intransitively, that is, without an ob-ject.
One of the clusters found by the model ofRooth et al (1999) corresponded to ?verb of scalarchange?
such as increase, rise, and decrease.
Themodel places both subject-of-intransitive-increaseand direct-object-of-increase in this class, but doesnot explicitly capture the fact that these to valuesrepresent different uses of the same verb.The phenomenon of verb argument alternationshas been most comprehensively studied by Levin(1993), who catalogs over 3,000 verbs into classesaccording to which alternations they participate in.A central thesis of Levin?s work is that a verb?s syn-tactic alternations are related to its semantics, andthat semantically related verb will share the samealternations.
For example, the alternation of exam-ples 1 and 2 is shared by verbs such as decrease anddiminish.Table 1 gives the most common nouns occurringas arguments of selected verbs in our corpus, show-ing how alternation behavior shows up in corpusstatistics.
The verbs open and increase, classifiedby Levin and others as exhibiting a causative al-ternation between transitive and intransitive usages,share many of the same nouns in direct object andsubject-of-intransitive positions, as we would ex-pect.
For example, number, cost, and rate occuramong the ten most common nouns in both posi-tions for increase, and themselves seem semanti-cally related.
For open, the first three words in eitherposition are the same.
For the verb play, on the otherhand, classified as an ?object-drop?
verb by Merloand Stevenson (2001), we would expect overlap be-tween the subject of transitive and intransitive uses.This is in fact the case, with child, band, and teamappearing among the top ten nouns for both posi-tions.
However, play also exhibits an alternation be-tween the direct object and subject of intransitivepositions for music, role, and game.
These two setsof nouns seem to fill different semantic roles of theverb, the first set being agents and the second be-ing themes.
This example illustrate the complex in-teraction between verb sense and alternation behav-ior: ?The band played?
and the ?The music played?are considered to belong to different senses of playby WordNet (Fellbaum, 1998) and other word senseinventories.
However, it is interesting to note thatnouns from both the broad senses of play, ?play agame?
and ?play music?, participate in both alter-nations.
An advantage of our EM-based soft clus-tering algorithm is that it can assign a verb to mul-tiple clusters; ideally, we would hope that a verb?sclusters would correspond to its senses.We expect verbs which take similar sets of argu-ment fillers to be semantically related, and to par-ticipate in the same alternations.
This idea has beenused by McCarthy (2000) to identify verbs partici-pating in specific alternations by looking for over-lap between nouns used in different positions, andby using WordNet to classify role fillers into se-mantic categories.
Schulte im Walde (2000) usesan EM-based automatic clustering of verbs to at-tempt to derive Levin classes from unlabeled data.As in McCarthy (2000), the nouns are classified us-ing WordNet.
However, the appearance of the samenoun in different syntactic positions is not explicitlycaptured by the probability model used for cluster-ing.This observation motivated a new probabilisticmodel of verb argument structure designed to ex-plicitly capture alternation behavior.
In addition toan unobserved cluster variable c, we introduce a sec-ond unobserved variable r for the semantic role ofan argument.
The role r is dependent on both thecluster c to which our verb-noun pair belongs, andthe syntactic slot s in which the noun is found, andthe probability of an observed triple P (v; s; n) is es-timated as:Xc;rP (c)P (vjc)P (sjc)P (rjc; s)P (njr; c)The noun is independent of the verb given the clus-ter variable, as before, and the noun is independentof the syntactic slot s given the cluster c and the se-mantic role r. The semantic role variable r can taketwo values, with P (rjc; s) representing the mappingfrom syntax to semantic role for a cluster of verbs.We expect the clusters to consist of verbs that notonly appear with the same set of nouns, but share thesame mapping from syntactic position to semanticrole.
For example increase and decrease might be-long to same cluster as they both appear frequentlyVerb Object Subj of Intransitive Subj of Transitiveclose door door troopeyes eyes doormouth mouth policefirebreak exhibition gunmanway shop womanpossibility show mangate trial guardaccount conference soldierwindow window oneshop gate companyincrease risk number governmentnumber proportion increaseshare population useprofit rate effectlead pressure salepressure amount levelrate cost presencelikelihood sale Partychance rates Labourcost profit bankplay part child bandrole band factorgame team Englandhost role childmusic player peoplecard game womanpiano smile mantennis people teamparts music allguitar boy groupTable 1: Examples from the corpus: most common arguments for selected verbswith rate, number, and price in both the direct ob-ject and subject of intransitive slots, and would as-sign the same value of r to both positions.
The verblower might belong to a different cluster because,although it appears with the same nouns, they ap-pear as the direct object but not as the subject.The Expectation Maximization algorithm is usedto train the model from the corpus, iterating over anExpectation step in which expected values for thetwo unobserved variables c and r are calculated foreach observation in the training data, and a Maxi-mization step in which the parameter of each of thefive distributions P (c), P (vjc), P (sjc), P (rjc; s),and P (njn; c) are set to maximize the likelihood ofthe data given the expectations for c and r.3 The DataFor our experiments we used a version of the BritishNational Corpus parsed with the statistical parser ofCollins (1997).
Subject and direct object relationswere extracted by searching for NP nodes domi-nated by S and VP nodes respectively.
The headwords of the resulting subject and object nodes werefound using the deterministic headword rules em-ployed by the parsing model.
The individual obser-vations of our dataset are noun-verb pairs of threetypes: direct object, subject of a verb with an ob-ject, and subject of a verb without an object.
As aresult, the subject and object relations of the sameoriginal sentence are considered independently byall of the models we examine.Direct object noun phrases were assigned thefunction tags of the Treebank-2 annotation style(Marcus et al, 1994) in order to distinguish nounphrases such as temporal adjuncts from true directobjects.
For example, in the sentence ?He ate yes-terday?, yesterday would be assigned the Temporaltag, and therefore not considered a direct object forour purposes.
Similarly, in the sentence ?Interestrates rose 2%?, 2% would be assigned the Extenttag, and this instance of rise would be consideredintransitive.Function tags were assigned using a simple prob-ability model trained on the Wall Street Journal datafrom the Penn Treebank, in a technique similar tothat of Blaheta and Charniak (2000).
The modelpredicts the function tag conditioned on the verb andhead noun of the noun phrase:P (f jv; n) =(~P (f jv; n) (v; n) 2 T12~P (f jv) +12~P (f jn) otherwisewhere f ranges over the function tags defined (Mar-cus et al, 1994), or the null tag.
Only cases assignedthe null tag by this model were considered true di-rect objects.
Evaluated on the binary task of whetherto assign a function tag to noun phrases in objectposition, this classifier was correct 95% of the timeon held-out data from the Wall Street Journal.
Bynever assigning a function tag, one would achieve85% accuracy.
While we have no way to evaluateits accuracy on the British National Corpus, certainsystematic errors are apparent.
For example, whileit classifies 2% as an Extent in ?Interest rates in-creased 2%?, it assigns no tag to crack in ?The dooropened a crack?.
This type of error leads to the ap-pearance of door as a subject on transitive uses ofopen in Table 1.Both verbs and nouns were lemmatized using theXTAG morphological dictionary (XTAG ResearchGroup, 2001).
As we wished to focus on alternationbehavior, verbs that were used intransitively than90% of the time were excluded from the data; weenvision that they would be handled by a separateprobability model.
Pronouns were excluded fromthe dataset, as were verbs and nouns that occurredfewer than 10 times, resulting in a vocabulary of4,456 verbs and 17,345 nouns.
The resulting datasetconsisted of 1,372,111 triples of verb, noun, andsyntactic relation.
Of these, 90% were used as train-ing material, 5% were used as a cross-validation setfor setting linear interpolation and deterministic an-nealing parameters, and 5% were used as test datafor the results reported below.4 The ModelsWe compare performance of a number of probabil-ity models for our verb argument data in order toexplore the dependencies of the data and the impactof clustering.
Graphical representations of the clus-tering models are shown in Figure 1.Unigram Baseline: This model assumes completeindependence of the verb, syntactic slot, andnoun, and serves to provide a baseline for thecomplexity of the task:P1(v; s; n) = P (v)P (s)P (n)Bigram: This model predicts both the noun andsyntactic slot conditioned on the verb, but in-dependently of one another:P2(v; s; n) = P (v)P (sjv)P (njv)Trigram: This is simply the empirical distributionover triples of verb, slot, and noun:P3(v; s; n) = P (v; s; n)Three-way Aspect: Following Hofmann andPuzicha (1998), we refer to EM-based cluster-ing as the aspect model, where different valuesof the cluster variable are intended to representabstract ?aspects?
of the data.
The simplestversion of the clustering model predicts verb,slot, and noun independently given the clustervariable c:Pc(v; s; n) = P (c)P (vjc)P (sjc)P (njc)with all four component distributions being es-timated by EM training.Verb-Slot Aspect: This is the model of Rooth et al(1999), in which the verb and slot are com-bined into one atomic variable before the as-pect model is trained:Pcvs= P (c)P (v; sjc)P (njc)Noun-Slot Aspect: A variation on the above modelcombines the slot with the noun, rather than theverb:Pcns= P (c)P (vjc)P (n; sjc)Alternation: This model, described in more detailabove, introduces a new unobserved variable rfor the semantic role of the noun, which cantake two values:Palt= P (c)P (vjc)P (sjc)P (rjs; c)P (njr; c)                                                                                clusterverb slot noun                                                        clusterverb,slot noun                                                                           verbnounslotrolecluster                                                  clusterverb noun,slotAlternationVerb-Slot AspectThree-way AspectNoun-Slot AspectFigure 1: Graphical models: shading represents observed variables, arrows probabilistic dependencies.Fixed Alternation: This model is designed to in-corporate the assumption that the semanticroles of the subject and object of the same verbmust be different.
The independence assump-tions are identical to those of the simple alter-nation model:Palt2= P (c)P (vjc)P (sjc)P (rjs; c)P (njr; c)but the probability P (rjs; c) is only trained fors = subj-intrans.
The model is constrained toassign one value of the role variable to directobjects, P (r = 0js = obj) = 1 and the otherrole to subjects of transitives: P (r = 1js =subj-trans) = 1.5 ResultsPerplexity results on held-out test data for each ofthe models are shown in Table 2.
Because models2, 3, 5, and 6 will assign zero probability to certainpairs of values not seen in the training data, theywere combined with the unigram baseline model inorder to obtain a perplexity over the entire test setcomparable to the other models.
This was doneusing linear interpolation, with the interpolationweight optimized on the cross-validation data.
Per-plexity is the geometric mean of the reciprocal ofthe probability assigned by the model to each tripleof verb, noun, and slot in the test data:PP = e 1NPilog P (vi;ni;si)For the single-variable clustering models (4, 5and 6) 128 values were allowed for the clustervariable c. For the two-variable clustering mod-els (7 and 8), 64 values for c and 2 values for theunobserved semantic roles variable r were used,making for a total of 128 distributions over nouns(P (njr; c)) but only 64 over verbs (P (vjc)).
The to-tal number of parameters for each model is shown inTable 2.
Because deterministic annealing was usedto smooth the probability distributions for each clus-ter and prevent overfitting the training data, the per-plexities obtained were relatively insensitive to thenumber of clusters used.Of the clustering models, the Verb-Slot Aspectmodel did the best, with a perplexity of 2.31M.
It isperhaps surprising how close the Three-way Aspectmodel came, with a perplexity of 2.41M, despite thefact that it models the noun as being independentof the syntactic position for a given verb.
One ex-planation for this is that nouns in fact occur in allthree positions more frequently than we would ex-pect from traditional accounts of alternation behav-ior.
This is shown in our corpus examples of Table1 by the high frequency of door as a subject of antransitive use of open.
Even in the traditional al-ternation pattern where a noun occurs in two of thethree positions, the Three-way Aspect model maydo better at capturing this overlap, even though itwill mistakenly assign probability mass to the samenouns appearing in the third syntactic position, thando models 5 and 6, which are not able to generalizeModel Test Perplexity Total Parameters1.
Unigram Baseline 5.50M 20,6512.
Bigram 2.95M 57.64M3.
Trigram 2.55M 172.88M4.
Three-way Aspect 2.41M 2.64M5.
Verb-Slot Aspect 2.31M 3.47M6.
Noun-Slot Aspect 2.66M 6.56M7.
Alternation 2.57M 2.43M8.
Fixed Alternation 2.60M 2.43M9.
Trigram+Verb-Slot Aspect 2.06M 176.36MTable 2: Comparison of probability modelsat all across the different arguments of a given verb.The models specifically designed to capture alter-nation behavior (7 and 8) did not do as well as thegeneric clustering models.
One explanation is thatthe unconstrained models are able to fit the data bet-ter by clustering together specific arguments of dif-ferent verbs even when the two verbs do not sharethe same alternation behavior.
Examining the clus-ters found by the Verb-Slot Aspect shows that it infact seems to find alternation behavior for specificverbs despite the model?s inability to explicitly rep-resent alternation.
In many cases, two roles of thesame verb are assigned to the same cluster.
Exam-ples of the top ten members of sample clusters areshown in Table 3.
Examining the sample verbs ofTable 1, we see that the model assigns the directobject and subject of intransitive slots of open tothe same cluster, implicitly representing the verb?salternation behavior, and in fact does the same forthe semantically related verbs close and shut.
Sim-ilarly, the direct object and subject of intransitiveslots of increase are assigned to the same cluster.However, in an example of how the model can clus-ter semantically related verbs that do not share thesame alternation behavior, the direct object slot ofreduce and the subject of transitive slot of exceedare groups together with increase.
Of particular in-terest is the verb play, for which the model assignsone cluster to each of the alternation patterns notedin Table 1.
Cluster 18 represents the alternation be-tween direct object and subject of intransitive seenwith part, game, and music, while cluster 92 rep-resents the agent relation expressed by subjects ofboth transitive and intransitive sentences.The final line of Table 2 represents an interpola-tion of the best n-gram and best clustering model,which further reduces perplexity to 2.06 million.6 ConclusionWe have attempted to learn the mapping from syn-tactic position to semantic role in an unsupervisedmanner, and have evaluated the results in terms ofour systems?
success as language model for unseendata.
The models designed to explicit represent verbalternation behavior did not perform as well by thismetric as other, simpler probability models.A perspective on this work can be gained by com-parison with attempts at unsupervised learning ofother natural language phenomena including part-of-speech tagging (Merialdo, 1994) and syntacticdependencies (Carroll and Charniak, 1992; Paskin,2001).
While models trained using the ExpectationMaximization algorithm do well at fitting the data,the results may not correspond to the human analy-ses they were intended to learn.
Language does notexist in the abstract, but conveys information aboutthe world, and the ultimate goal of grammar induc-tion is not just to model strings but to extract thisinformation.
This suggests that although the proba-bility models constrained to represent verb alterna-tion behavior did not achieve the best perplexity re-sults, they may be useful as part of an understandingsystem which assigns semantic roles to arguments.The implicit representation of alternation behaviorin our generic clustering model also suggests usingits clusters to initialize a more complex model capa-ble of assigning semantic roles.Acknowledgments This work was undertakenwith funding from the Institute for Research in Cog-nitive Science at the University of Pennsylvania andDoD Grant MDA904-00C-2136.ReferencesDon Blaheta and Eugene Charniak.
2000.
Assigningfunction tags to parsed text.
In Proceedings of the 1stAnnual Meeting of the North American Chapter of theACL (NAACL), pages 234?240, Seattle, Washington.Cluster Id Verb-Slot Noun Cluster Id Verb-Slot Noun57 door open-obj 18 part play-objmouth open-subj-intrans role form-objeyes close-obj lip take-objfirebreak close-subj-intrans game bite-objgate shut-subj-intrans basis play-subj-intransshop slam-subj-intrans host lick-objwindow shut-obj parts curl-subj-intransway knock-obj music see-objexhibition reach-obj card constitute-obj47 number increase-subj-intrans 92 people play-subj-intransamount require-obj man win-subj-intranssupply reduce-obj child take-subj-translevel increase-obj woman make-subj-transrate exceed-subj-trans one need-subj-transtooth need-obj the play-subj-transincome include-obj band see-subj-transrisk affect-obj group get-subj-intransactivity show-obj team manage-subj-intransTable 3: Sample Clusters from Verb-Slot Aspect ModelGlenn Carroll and Eugene Charniak.
1992.
Two experi-ments on learning probabilistic dependency grammarsfrom corpora.
In Workshop Notes for Statistically-Based NLP Techniques, pages 1?13.
AAAI.Eugene Charniak.
1997.
Statistical parsing with acontext-free grammar and word statistics.
In AAAI-97, pages 598?603, Menlo Park, August.
AAAI Press.Ciprian Chelba and Frederick Jelinek.
1999.
Recogni-tion performance of a structured language model.
InEUROSPEECH.Michael Collins.
1997.
Three generative, lexicalisedmodels for statistical parsing.
In Proceedings of the35th ACL, pages 16?23, Madrid, Spain.Christiane Fellbaum, editor.
1998.
WordNet: An Elec-tronic Lexical Database.
MIT Press, Cambridge,Massachusetts.Thomas Hofmann and Jan Puzicha.
1998.
Statisticalmodels for co-occurrence data.
Memo, Massachus-setts Institute of Technology Artificial IntelligenceLaboratory, February.Beth Levin.
1993.
English Verb Classes And Alter-nations: A Preliminary Investigation.
University ofChicago Press, Chicago.David Magerman.
1995.
Statistical decision-tree modelsfor parsing.
In Proceedings of the 33rd ACL, Cam-bridge, Massachusetts.Mitchell P. Marcus, Grace Kim, Mary Ann Marcin-kiewicz, Robert MacIntyre, Ann Bies, Mark Fergu-son, Karen Katz, and Britta Schasberger.
1994.
ThePenn Treebank: Annotating predicate argument struc-ture.
In ARPA Human Language Technology Work-shop, pages 114?119, Plainsboro, NJ.
Morgan Kauf-mann.Diana McCarthy.
2000.
Using semantic preferences toidentify verbal participation in role switching alterna-tions.
In Proceedings of the 1st NAACL, pages 256?263, Seattle, Washington.Bernard Merialdo.
1994.
Tagging English text witha probabilistic model.
Computational Linguistics,20(2):155?172.Paola Merlo and Suzanne Stevenson.
2001.
Auto-matic verb classification based on statistical distribu-tion of argument structure.
Computational Linguis-tics, 27(3), September.Mark Paskin.
2001.
Grammatical bigrams.
In T. Di-etterich, S. Becker, and Z. Gharahmani, editors, Ad-vances in Neural Information Processing Systems(NIPS) 14.
MIT Press.Fernando Pereira, Naftali Tishby, and Lillian Lee.
1993.Distributional clustering of English words.
In Pro-ceedings of the 31st ACL, pages 183?190, Columbus,Ohio.
ACL.Brian Roark.
2001.
Probabilistic top-down parsingand language modeling.
Computational Linguistics,27(2):249?276.Mats Rooth, Stefan Riezler, Detlef Prescher, Glenn Car-roll, and Franz Beil.
1999.
Inducing a semanticallyannotated lexicon via EM-based clustering.
In Pro-ceedings of the 37th Annual Meeting of the ACL, pages104?111, College Park, Maryland.Sabine Schulte im Walde.
2000.
Clustering verbs se-mantically according to their alternation behaviour.
InIn Proceedings of the 18th International Conferenceon Computational Linguistics (COLING-00), pages747?753, Saarbru?cken, Germany.XTAG Research Group.
2001.
A lexicalized tree adjoin-ing grammar for English.
Technical Report IRCS-01-03, IRCS, University of Pennsylvania.
