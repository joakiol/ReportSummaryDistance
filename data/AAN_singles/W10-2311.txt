Proceedings of the 2010 Workshop on Graph-based Methods for Natural Language Processing, ACL 2010, pages 69?73,Uppsala, Sweden, 16 July 2010. c?2010 Association for Computational LinguisticsMuLLinG: multilevel linguistic graphs for knowledge extractionVincent ArcherLaboratoire I3S (?quipe RL), Universit?
de Nice Sophia AntipolisSophia Antipolis, Francevincent.archer@unice.frAbstractMuLLinG is a model for knowledge extrac-tion  (especially  lexical  extraction  from cor-pora), based on multilevel graphs.
Its aim isto allow large-scale data acquisition, by mak-ing  it  easy  to  realize  automatically,  andsimple to configure by linguists with limitedknowledge  in  computer  programming.
InMuLLinG, each new level represents the in-formation  in  a  different  manner  (more  andmore abstract).
We also introduce several as-sociated operators, written to be as generic aspossible.
They are independent of what nodesand  edges  represent,  and  of  the  task  toachieve.
Consequently,  they  allow  the  de-scription of a complex extraction process as asuccession of simple graph manipulations.
Fi-nally,  we present  an experiment of colloca-tion extraction using MuLLinG model.1 IntroductionNatural language processing systems often pro-duce low-quality results, because of ambiguitiesand particular linguistic phenomena.
One majorreason is the lack of linguistic data needed to de-tect these phenomena or to solve ambiguities.
Tofill this lack, new linguistic resources should beproduced.
It could be done quickly with automat-ic processes, but quality would be unsatisfactory;on the contrary, manual work by linguists allowsprecise results, but takes lot of time.
To get bothrapidity  and  precision, we  must  combine  ma-chine and human abilities,  by giving automaticprocessing tools to linguists, and allowing themto guide the process.
Existing tools are often toocentered on a task, and require too much know-ledge in computer programming: they are not ap-propriate  for  linguists  with  few  knowledge  incoding.
We should thus develop generic tools.In this article, we first focus on how to makethe resource gathering easier.
Then, we introduceMuLLinG,  our  multilevel  graph  model  for  lin-guistic extraction, with several associated opera-tions.
Finally,  we present an application of thatmodel on collocation extraction.2 Knowledge extractionThere  are  several  manners  to  collect  resourceswith automatic processes (machine learning, col-laborative interfaces, etc.).
We focus here on (lin-guistic  and  statistic)  extraction  of  candidates.More precisely, our goal is to facilitate the large-scale production of candidates by extraction.2.1 Simplify programmingMaking a particular extraction task is not easy, asthere is often no dedicated tool.
It forces to writead  hoc  tools  (most  of  the  time  not  unveiled).Moreover, ad hoc tools are not written to be uni-versal.
They generally depend on the data model,it is therefore difficult or impossible to use a newresource with a different format (such as an ana-lysis from an other parser).
To be really useful,an  extraction  tool  should  be  generic (able  tohandle different data models) and easy to under-stand and to use.
The data model on which thetool  rely  must  be  simple,  expressive  (complexstructure should be represented easily), and uni-versal (for monolingual or multilingual corpora,dictionaries, etc.).
It should also provide simplegeneric,  task-independent,  high-level  operationsthat can be combined to describe a complex task.We choose to introduce a graph-based model.Graphs  are  understandable  quickly by humans,easy to use in automatic processes, and flexibleenough  to  represent  various  data  types.
Usinggraphs for knowledge extraction is quite classic.They can represent relations between words (pro-duced by dependency analysers  from corpora),and be used to produce semantically close terms(Widdows & Dorrow, 2002) or to group similarn-tuples (Hassan et al, 2006).
Graphs also can be69generated from dictionaries, and used to produceknowledge  bases  (Richardson  et  al.,  1998)  orproximity information (Gaume et al, 2006).2.2 Existing graph modelsInfluenced by ?existential graphs?
(Peirce, 1931-1935) where relations between elements are rep-resented by nodes,  ?conceptual  graphs?
(Sowa,1976) are bipartite graphs with two node types:concepts and conceptual relations (edges only as-sociate relations and concepts).
That relation ma-terialization is useful, as it allows to handle eas-ily n-ary relations, without hypergraphs.Another  interesting  network  is  the  ?lexicalsystem?
one  (Polgu?re,  2006),  defined  as  ori-ented,  weighted,  unhierarchical  and,  above  all,heterogeneous: there is no constraint on what ismodelized (it could be terms, meanings, colloca-tions, etc.).
It avoids the separation between dic-tionary-like  and network-like  lexical  databases,and shows the same representation can be usedfor each kind of data and relation.Finally, graphs can be multilevel, to representdifferent kinds of information.
Links are gener-ally allowed only in a same level or between twoadjacent levels, like in ?hypertexts?
(Agosti andCrestani,  1993)  made  of  three  specified  levels(documents, terms, concepts), or in Multi-LevelAssociation  Graphs  (Witschel,  2007)  in  whichthere is  no constraint  on the number  of levels.We believe that the use of several levels to rep-resent various content types is pertinent in an ex-traction process, as it allows to handle both theoccurrences of terms, and the terms themselves.3 MuLLinG modelWe introduce  MuLLinG (Multi-Level LinguisticGraph), our own graph model.
Divided in severalordered and distinct levels, it contains two kindsof edges:  intra-level ones (between nodes fromsame level) and inter-level ones (from a node onlevel i to a node on level i+1).
Intra-level edgesare  not  unique  (several  edges  are  allowedbetween two nodes): every level is a multigraph.On the contrary, a node can be the source of onlyone inter-level edge; this association means thatthe target node (on the superior level) is a moreglobal  representation  of  the  source  node  (itdefines a hierarchy of precision).Finally, in order to allow the heterogeneity ofrepresented data, nodes and intra-level edges cancarry any attribute (with no limit on kind or num-ber).
Figure 1 shows an example of a MuLLinGgraph, in which 1st level contains occurrences ofwords,  2nd level  contains lemmas,  and 3rd levelcontains synonymy classes.3.1 DefinitionMore precisely, a MuLLinG graph is an orientedmultigraph  ( )EVn a,a?,A,F,E,V,=G  (for  nlevels) where:?
V: set of  nodes, made of  n disjoint sub-sets nVV ,,1 ?
(for the n levels);?
E: set of intra-level edges, made of n dis-joint subsets nEE ,,1 ?
; A: set of functions{ }niVVE iiii ,,1: ?????
associatingan edge and its two extremities;?
F: set of inter-level edges, in n-1 disjointsets  11 ,, ??
nFF  defined  as( ){ }x=y|VVyx,=F +iii ?1??
;  ?
:  setof functions { }niVV +iii ,,1: 1 ????
, as-sociating a node (on a given level) and anode on the superior level);?
{ }VV ?Vf=a ?
: ,  { }EE ?Ef=a ?
:( EV ?,?
are  alphabets  for  attributes  ofobjects from E and V) model attributes.3.2 Associated operatorsTo manipulate  MuLLinG graphs,  we  introduceseveral  operations,  designed for their  particularstructure.
Some  of  them allow elementary ma-nipulations:  add  or  delete  a  node  or  an  edge,clean a node (delete all  edges of which it  is  asource or a target),  delete a node and its ?des-cendants?
(the nodes linked  to it  by inter-leveledges,  and  their  own  descendants).
There  areFigure 1.
Example of 3-level MuLLinG graph70also operations to compute measures, to realize aconditional  manipulation on nodes or edges (itcan be use to  filter the graph, by deleting nodesdepending on the value of a given attribute).
Allthese  basic  operations  should  not  be  directlyused, but rather be called by more elaborate ones.These operations (modifying the graph struc-ture) take parameters fixed by the user: the level,the filtering function (which graph elements areconcerned by the operation?
),  and computationfunctions (to produce attribute values for newlycreated  elements).
Graph  coherence  is  guaran-teed if the user provides correct parameters.Emergence is  the  essential  operation  associ-ated with MuLLinG.
Its aim is to generate a su-perior level, by grouping elements (from the ini-tial  level)  in  equivalence classes.
In  the  newlycreated level, each node (resp.
edge) represent aequivalence class of nodes (resp.
edges) from theinitial  level.
The  identification  of  equivalenceclasses is a parameter of the emergence (the userprovides it).
The operation goes in two steps:?
node  emergence:  for  each  equivalenceclass of nodes, it creates a node on the su-perior  level  to  represent  this  class  (andeach  node  in  the  class  is  linked  to  thenewly created node);  figure  2 shows theemergence of nodes representing equival-ence classes containing all occurrences ofa same word;?
edge emergence: each edge added on thesuperior level between nodes A and B de-pict a set of equivalent edges between anelement  of  A class  and an element  of  Bclass; in figure 2, equivalent  u and  u' aregrouped in a sole edge U, whereas s and t(not  equivalent)  are  represented  by  twodistinct edges S and T.Finally,  some  other  operations  have  beendefined to mix information from two graphs in athird  one.
The  intersection contain  elements(nodes, edges) present in both graphs, with uni-fication of identical elements.
The union containall elements from the two graphs, with unifica-tion of identical elements.
The difference containall  elements  from  the  first  graph  that  are  notidentical to an element from the second one.It is essential to recognize the identity betweentwo nodes  or  two edges:  identity  functions areparameters  for  these  ?mix?
operations,  andshould be provided by the user.
Among paramet-ers, there are also, depending on the case, func-tions for fusion (production of attributes for uni-fied nodes or edges) or  copy (production of at-tributes for elements present in only one graph).To handle n-ary relations, we also provide acomplex version  of  MuLLinG,  where  relationscan  be  materialized.
In  that  case,  a  relation  isrepresented  by  a  standard  node  and  numberedargument  edges linking  that  node  to  the  argu-ments of the relation.
It also allows the represent-ation of relations between relations themselves.We made an implementation of MuLLinG as aC++ library1, based on  Boost (open-source C++libraries),  especially for graph access and itera-tions.
It can read and write MuLLinG graphs inGraphML format (Brandes et al, 2001).4 Application to collocation extraction4.1 Extraction processWe realized several  experiments  using our lib-rary.
We remind the reader that our goal was notto obtain the more efficient method for extrac-tion, but rather to introduce tools for simplifyingthe programming of extraction tasks.
We presenthere  experiments  about  collocation  extraction.Collocations are particular expressions where aterm is chosen arbitrarily, depending on the other1 Available at http://mulling.ligforge.imag.fr/ (underCeCILL free software license)Figure 2.
Two-steps emergence (nodes, then edges)71term,  to  express  a  particular  meaning  (like  in?driving rain?, where ?driving?
is used to expressintensity).
As  the  choice  differs  between  lan-guages2, it causes big issues to machine transla-tion  systems  (which  lack  resources  to  handlethem  correctly).
In  our  experiment,  the  initialgraph is made of relations produced by a depend-ency analyzer, on 1st level.Firstly,  we use the  filtering operator to keeponly pertinent relations (nouns modified by ad-jectives,  like in figure 3,  or  verbs modified byadverbs), according to the analyzer.
There are re-lations between term occurrences on 1st level, butwe want relations between terms themselves: wegenerate them on 2nd level using emergence.
Sowe proceed node emergence by considering thatnodes with same attribute ?lemma?
are equival-ent,  then  edge  emergence by  considering  thatedges expressing a modification are equivalent.The ?collocation?
candidates are all  2nd-leveledges  created  during  the  emergence.
To  rankthem,  we  use  the  computation operation  (withoccurrence and co-occurrence frequencies) to fixan association measure on those nodes.
Figure 3shows  an  example  of  a  MuLLinG graph  afteremergence and computation operations.To facilitate the description, our library con-tains  lots  of  pre-defined  generic  functions.
Byexample, a filter (used as a parameter of emer-gence)  can  be  based  on  an  excepted  value,  athreshold, etc.
We also described numerous asso-ciation measures; for now, new ones should bewritten in the C++ program.We used our library to carry out the extractionas described previously, with LeMonde95 corpus(news articles) analyzed by Xerox's XIP parser.Thanks to MuLLinG structure, it is very easy toget al potential collocations (heavy/driving rain):these are the relations of which it is the source.2By example, a ?heavy smoker?
is big in French (?grosfumeur?)
and strong in German (?starker Raucher?
).Experiments verb-adverb noun-adjectiveLevel 1 nodes 1 155 824 1 319 474edges 1 780 759 2 009 051Level 2 nodes 6 813 33 132edges 144 586 273 655Table  1.
Nodes and edges produced during ex-periments on collocation extraction4.2 Advantages and drawbacksWith MuLLinG library,  we  reproduced  exactlysome experiments  on collocation extraction wemade before (with ad hoc programs): results areobviously coherent.
The production is currentlyslightly  slower  (around  20%  more  time)  butspeed  is  not  crucial,  and  could  be  optimized.MuLLinG has  a  great  advantage while  writingthe program: it only calls functions (and declareparameters).
Consequently, task description withour library is much faster (source lines of codeare divided by 5), it also avoids errors.
It requiresless knowledge in programming, so it is far moreaccessible.
Nevertheless, usability should still beimproved:  we  must  describe  a  high-level  lan-guage (we believe it  should be a request  one).Furthermore, there is no constraint on input re-sources,  so  programs  could  easily  be  re-usedwith other relations (from other parsers).
Finally,as  graphs  with  millions  of  elements  can  reachRAM limits, we plan to allow database storage.We also made bilingual  experiments  on col-locations,  taking  advantage  of  MuLLinG com-plex version to materialize monolingual ?colloc-ation?
nodes, and to describe bilingual relationsbetween collocations as edges between them.5 ConclusionFacing the lack of tools for extraction of lexicalknowledge, we looked for a new one, simple andgeneric.
We  specified  MuLLinG,  multilevelgraph model (with no constraint on the data), as-sociated with several simple manipulation opera-tions (which could be combined to realize com-plex tasks).
The ensuing tool allows to programlinguistic tasks in a resource-independent  man-ner, simpler and more efficient.
One major pro-spect of this work concerns its implementation.As  explained  before,  we  must  provide  a  high-level  language.
It  is also necessary to facilitatethe import and to optimize memory management.In order to provide a less NLP-centered tool, weshould extend it  with new operations, and withalgorithms related to classic problems of graphtheory.
It  would  also  be  interesting  to  interactwith semantic web tools (RDF/SPARQL).Figure 3.
Collocations extraction with emergence(on 2nd level) and computation operations72ReferencesMaristella Agosti and Fabio Crestani.
1993.
A Meth-odology for the Automatic Construction of a Hy-pertext for  Information Retrieval.
In  Proceedingsof 1993 ACM Symposium on Applied Computing,745-753.Ulrik Brandes, Markus Eiglsperger, Ivan Herman, Mi-chael  Himsolt  and  M.  Scott  Marshall.
2001.GraphML Progress Report - Structural Layer Pro-posal.
In  Proceedings  of  9th  International  Sym-posium Graph Drawing (GD'01), 501-512.Hany  Hassan,  Ahmed  Hassan  and  Sara  Noeman.2006.
Graph based  semi-supervised  approach  forinformation  extraction.
In  Proceedings  of  HLT-NAACL-07 Workshop on Textgraphs-06, 9-16.Bruno  Gaume,  Karine  Duvignau  and  Martine  Van-hove.
2008.
Semantic associations and confluencesin  paradigmatic  networks.
In  Martine  Vanhove(Ed.
),  From  Polysemy  to  Semantic  Change  To-wards a typology of lexical semantic associations,John Benjamins, 233-264.Charles Sanders Peirce.
1931-1935.
Collected Papersof C. S. Peirce (C. Hartshorne & P. Weiss, eds.
),Cambridge: Harvard University Press.Alain Polgu?re.
2006.
Structural Properties of LexicalSystems:  Monolingual  and Multilingual  Perspect-ives.
In  Proceedings of Workshop on MultilingualLanguage  Resources  and  Interoperability  (COL-ING/ACL 2006), 50-59.Stephen D. Richardson, William B. Dolan, and LucyVanderwende.
1998.
MindNet:  acquiring  andstructuring semantic information from text.
In Pro-ceedings of COLING 1998.
1098-1102.John F. Sowa.
1976.
Conceptual graphs for a databaseinterface.
IBM Journal of Research and Develop-ment 20:4, 336-357.Dominic Widdows and Beate Dorow.
2002.
A GraphModel  for  Unsupervised  Lexical  Acquisition.
InProceedings of  19th International Conference onComputational  Linguistics(COLING 2002).
1093-1099.Hans  Friedrich  Witschel.
2007.
Multi-level  Associ-ation Graphs - A New Graph-Based Model for In-formation  Retrieval.
In  Proceedings  of  HLT-NAACL-07 Workshop on Textgraphs-07, 9-16.73
