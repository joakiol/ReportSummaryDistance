Proceedings of the ACL-HLT 2011 System Demonstrations, pages 92?96,Portland, Oregon, USA, 21 June 2011. c?2011 Association for Computational LinguisticsMultimodal Menu-based Dialogue with Speech Cursor in DICO II+Staffan LarssonUniversity of GothenburgSwedensl@ling.gu.seAlexander BermanTalkamatic ABSwedenalex@talkamatic.seJessica VillingUniversity of GothenburgSwedenjessica@ling.gu.seAbstractThis paper describes Dico II+, an in-vehicledialogue system demonstrating a novel com-bination of flexible multimodal menu-baseddialogueand a ?speech cursor?
which enablesmenu navigation as well as browsing long listusing haptic input and spoken output.1 IntroductionDico is a multimodal in-car dialogue system appli-cation, originally developed in the DICO (with cap-ital letters) project by Volvo Technology AB andthe University of Gothenburg.
Dico is built on topof the GoDiS dialogue system platform (Larsson,2002), which in turn is implemented using TrindiKit(Traum and Larsson, 2003).The main goal of the original Dico application(Olsson and Villing, 2005), (Villing and Larsson,2006) was to develop an interface that is less dis-tracting for the driver, and thus both safer and easierto use than existing interfaces.
(Larsson and Villing,2009) described the Dico II system resulting fromwork in the DICO project.
Since then, the Dicodemonstrator has been further developed.In this paper, we describe the Dico II+ demon-strator which introduces a novel combination offlexible Multimodal Menu-Based Dialogue and aSpeech Cursor which together enable flexible multi-modal interaction without the need for looking at thescreen.
In the following, we will first argue for theusefulness of in-vehicle dialogue systems.
We willthen briefly present the GoDiS platform which DicoII+ is based on, as well as some aspects of flexibledialogue enabled by the GoDiS dialogue manager.2 In-vehicle dialogue systemsVoice interaction is a very natural means of com-munication for humans, and enabling spoken inter-action with technologies may thus make it easierand less cognitively demanding for people to in-teract with machines.
However, this requires thatthe spoken interaction is similar to ordinary spokenhuman-human dialogue.
A problem with availablein-vehicle voice control technologies is that they arenot flexible enough in terms of the interaction strate-gies and modalities offered to the user.3 GoDiS features in DicoGoDiS (Larsson, 2002) is an experimental di-alogue system implementing a theory of Issue-Based Dialogue Management based on Ginzburg?sconcept of Questions Under Discussion (QUD).GoDiS is implemented using the TrindiKit, a toolkitfor implementing dialogue move engines and dia-logue systems based on the Information State ap-proach (Traum and Larsson, 2003).
GoDiS hasbeen adapted to several different dialogue types, do-mains, and languages, including menu-based mul-timodal dialogue when acting as an interface to anmp3 player (Hjelm et al, 2005).The GoDiS dialogue manager allows the userto interact more flexibly and naturally with menu-based interfaces to devices.
General dialogue man-agement issues such as accommodation, task switch-ing and grounding are handled by the application-independent dialogue manager.
Re-using these tech-nologies in new applications enables rapid prototyp-ing of advanced dialogue applications.923.1 AccommodationThe applications in Dico II+ are based on exist-ing menu interfaces, using a method for convertingmenus into dialogue plans (see below).
While it ispossible for the novice user to let the system takeinitiative and guide the user through the menus step-by-step, expert users might prefer to use accommo-dation strategies enabling the user to skip throughthe menus and getting right to the point.
Two exam-ples are shown below.Ex.
1:S: ?What do you want to do?
Go to thephonebook, manage settings, or...?U: ?Call Lisa?s home number?S: ?OK.
Calling Lisa?s home number.?Ex.
2:U: ?Lisa?s home number?S: ?OK.
Do you want to change the num-ber or make a call?
?U: ?Make a call.
?S: ?OK.
Calling Lisa?s home number.
?3.2 Multiple simultaneous tasks and taskswitchingGoDiS enables arbitrarily nested subdialogues.
Itis possible to start one dialogue to perform a task,and then start a subdialogue before the first task iscompleted.
When the second task is completed thesystem automatically returns to the first task, and ex-plicitly signals this.
This gives the user freedom toswitch task at any time:Ex.
3:U: ?Change Lisa?s home number.
?S: ?Okay.
Let?s see.
What phone numberdo you want instead?
?U: ?Check my messages.
?S: ?You have got this message.
Hi!I have got a new home number, it is(031)234567.
Best regards, Lisa.
?S: ?Returning to change an entry.
Whatphone number do you want instead?
?U: ?oh three one twentythree fourtyfivesixtyseven.
?U: ?Okay.
Changing Lisa?s home num-ber to oh three one two three four five sixseven.
?3.3 Feedback and groundingThe GoDiS dialogue manager provides general feed-back strategies to make sure that the dialogue part-ners have contact, that the system can can hear whatthe user says, understands the words that are spoken(semantic understanding), understands the meaningof the utterance (pragmatic understanding) and ac-cepts the dialogue moves performed in utterances.As an example, the single user utterance ?Lisa?may result in positive feedback on the semantic levelbut negative on the pragmatic, resulting in a systemutterance consisting of two feedback moves and aclarification question: ?Lisa.
I don?t quite under-stand.
Do you want to make a call, change an entryin the phonebook, or delete an entry from the phone-book?
?4 Multimodal menu-based dialogueDico II+ implemented a concept of MultimodalMenu-based Dialogue (MMD).
Technologies forMMD in menu-based applications have already beendeveloped for other GoDiS applications (Hjelm etal., 2005) and the ideas behind these solutions werere-implemented and significantly improved in Dico.A common argument for using spoken interactionin a car context is that the driver should be able touse a system without looking at a screen.
However,there are many situations where current technologyrequires the user to look at a screen at some pointin the interaction.
The idea behind MMD is that theuser should be able to switch between and combinemodalities freely across and within utterances.
Thismakes it possible to use the system using speechonly, using traditional GUI interaction only, or us-ing a combination of the two.MMD enables integrated multimodality for userinput, meaning that a single contribution can useseveral input modalities, e.g.
?Call this contact[click]?
where the [click] symbolises haptic input(e.g.
a mouse click) which in this case selects a spe-cific contact.
For output, MMD uses parallel mul-93timodality, i.e., output is generally rendered bothas speech and as GUI output.
To use speech only,the user can merely ignore the graphical output andnot use the haptic input device.
To enable interac-tion using GUI only, speech input and output can beturned on or off using a button which toggles be-tween ?speech on?
and ?speech off?
mode.The GUI used in Dico II+ is a generic graphi-cal interface for the GoDiS system, developed byTalkamatic AB with graphical adaptations for Dico.It represents GoDiS dialogue moves graphically asmenus using a refined version of the conversionschema presented in (Larsson et al, 2001) .
Forexample, alternative questions are represented asmultiple choice menus, and wh-questions are rep-resented as scrollable lists.
Conversely, haptic userinput from the GUI is interpreted as dialogue moves.Selecting an action in a multiple-choice menu cor-responds to making a request move, and selectingan item in a scrollable list corresponds to an answermove.5 Speech CursorThis section describes an important addition to theGoDiS dialogue manager and Dico demonstrator,which enables the user to use spoken interaction incombination with haptic input to access all func-tionality (including browsing long lists) without everhaving to look at the screen.
In combination withthe flexible dialogue capabilities of the GoDiS dia-logue manager, and the concept of MMD, we believethat a Speech Cursor provides a powerful and user-friendly way of interacting with menu-based inter-faces in cognitively demanding environments suchas the in-vehicle environment.5.1 The problemA common argument for using spoken interactionin a car context is that the driver should be able touse a system without looking at a screen.
However,there are many situations where current technologyrequires the user to look at a screen at some pointin the interaction.
This was true also for Dico IIin the case of browsing lists; for example, to findout which contacts were listed in the phonebook, theuser would at some point have to look at the screen.Imagine that the user wants to select a song froma song database, and that the user has made restric-tions filtering out 30 songs from the database.
Thedialogue system asks the user which of the songs shewants to hear displaying them in a list on the screen.The user must now either look at the screen anduse a scroll-wheel or similar to select a song, or lookat the screen to see which songs are available, andthen speak the proper song title.
This means thatpart of the point of using spoken interaction in thecar is lost.
The example discusses car use, but isapplicable any time when the user cannot or doesnot want to look at a screen, for instance when usinga cellphone walking in a city, or when using a webapplication on a portable device.An existing interaction strategy for addressing theproblems of browsing lists is to allow a kind of meta-dialogue, where the system verbally presents a num-ber of items (for instance 5) from the list, then askingthe user if she or he would like to hear the subse-quent 5 items, until the list has been read in its en-tirety or until the users responds negatively.
Whilethis strategy in principle solves the problem, it israther time-consuming compared to browsing thelist using a screen and a haptic input device (suchas a scroll-wheel); this may decrease the perceivedusability of the voice interface in comparison withtraditional GUI-based interaction.Some existing voice interaction systems use atechnology to establish understanding which con-sists of displaying the top N best recognition hy-potheses to the user, each one associated with a num-ber, together with a verbal request to the user tosay the number corresponding to the desired result.This situation, however, requires the user to look ata screen, and is arguably quite unnatural.5.2 The solution: Speech CursorDico II+ requires a haptic menu navigation de-vice, such as a mouse (trackball, touch pad,TrackPointTM ) with buttons, pointers and drivers,keyboard with arrow keys, or jog dial/shuttle wheel.A typical in-vehicle menu navigation device consistsof three or four buttons (UP, DOWN, OK and possi-ble BACK).Every time a new item gets focus, the systemreads out a voice icon - a spoken representation ofthe item.
This representation can be textual, in-tended to be realised using a TTS, or in the form94of audio data, to be played directly.
Every time anew element gets focus, all any ongoing voice out-put is interrupted by the voice icon for the elementin focus.6 Combining flexible dialogue and SpeechCursorCombining flexible dialogue processing with theSpeech Cursor concept1 enables interaction wherethe user may freely choose between using domain-level spoken utterances (requests, confirmations,questions, answers etc.)
and using the Speech Cur-sor.
This is an improvement over existing technol-ogy in that it offers a greater variety of interactionstyles which can be freely chosen and combined bythe user, as well as offering flexible dialogue inter-action.
Specifically, it provides flexible spoken dia-logue interaction in combination with user-friendlybrowsing of long lists without the need for lookingat the screen.Here is a walk-through of a sample interaction:Ex.
4:U: ?I want to listen to Madonna?
(This ut-terance uses accommodation to allow theuser to supply unrequested information)S: ?There are 3 songs by Madonna.
Whatsong do you want??
(Showing list of allsongs by Madonna: ?Like a Prayer?, ?LaIsla Bonita?, ?Music?, ...)U: [DOWN]S: ?Like a Prayer from the album Like aPrayer?
(?Like a Prayer?
is highlighted)U: [DOWN]S: ?La Isla Bonita from the album TrueBlue?
(?La Isla Bonita?
is highlighted)U: [DOWN]S: ?Music from the alb+?
(?Music?
ishighlighted)U: [UP]S: ?Like a Prayer?1The combination of a (simple or flexible) spoken dialoguesystem and the voice cursor technology is patent pending.U: [OK]S: ?OK, playing Like a Prayer.
?Here is a further example:Ex.
5:U: ?I want to add an ABBA song?S: ?What album??
(Shows ?Waterloo?and ?Arrival)U: [DOWN]S: ?Wat...?U: [DOWN]S: ?Arrival?U: [OK]S: ?what song??
(Shows ?Mamma Mia?and ?Money Money Money?
)U: ?Mamma Mia?A promotional demo film showing interactionssimilar to the above is available2, courtesy of Talka-matic AB.AcknowledgmentsThe work reported here was funded DICO, Vinnovaproject P28536-1.
Additional funding was providedby Talkamatic AB, and by CLT, the Centre of Lan-guage Technology at the University of Gothenburg.Dico II+ was implemented by the authors, FredrikKronlid, Peter Ljunglo?f and Andreas Wiberg.
Theauthors gratefully acknowledge the assistance ofVolvo Technology AB and the DICO project group.The GoDiS system is the property of TalkamaticAB.ReferencesDavid Hjelm, Ann-Charlotte Forslund, Staffan Larsson,and Andreas Wallentin.
2005.
DJ GoDiS: Multimodalmenu-based dialogue in an asychronous isu system.
InClaire Gardent and Bertrand Gaiffe, editors, Proceed-ings of the ninth workshop on the semantics and prag-matics of dialogue.2www.youtube.com/watch?v=yvLcQOeBAJE95Staffan Larsson and Jessica Villing.
2009.
Multimodalmenu-based dialogue in dico ii.
In Jens Edlund,Joakim Gustafson, Anna Hjalmarsson, and GabrielSkantze, editors, Proceedings of DiaHolmia, 2009Workshop on the Semantics and Pragmatics of Dia-logue.Staffan Larsson, Robin Cooper, and Stina Ericsson.2001.
menu2dialog.
In Proceedings of the 2nd IJCAIWorkshop on Knowledge and Reasoning in PracticalDialogue Systems, pages 41?45.Staffan Larsson.
2002.
Issue-based Dialogue Manage-ment.
Ph.D. thesis, Go?teborg University.Anna Olsson and Jessica Villing.
2005.
Dico - a dialoguesystem for a cell phone.
Master?s thesis, Departmentof Linguistics, Goteborg University.David Traum and Staffan Larsson.
2003.
The informa-tion state approach to dialogue management.
In Ron-nie Smith and Jan Kuppevelt, editors, Current and NewDirections in Discourse & Dialogue.
Kluwer Aca-demic Publishers.Jessica Villing and Staffan Larsson.
2006.
Dico - a mul-timodal in-vehicle dialogue system.
In D. Schlangenand R. Fernandez, editors, Proceedings of the 10thworkshop on the semantics and pragmatics of dia-logue.96
