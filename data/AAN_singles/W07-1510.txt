Proceedings of the Linguistic Annotation Workshop, pages 57?60,Prague, June 2007. c?2007 Association for Computational LinguisticsQuerying multimodal annotation: A concordancer for GeMMartin ThomasCentre for Translation StudiesUniversity of LeedsUK, LS2 9JTm.thomas@leeds.ac.ukAbstractThis paper presents a multimodal corpus ofcomparable pack messages and the concor-dancer that has been built to query it.
Thedesign of the corpus and its annotation isintroduced.
This is followed by a descrip-tion of the concordancer?s interface, imple-mentation and concordance display.
Finally,some ideas for future work are outlined.1 IntroductionThis paper introduces a multimodal concordancer1that has been developed to investigate variation be-tween messages on fast-moving consumer goodspackaging from China, Taiwan and the UK.
Theneed to develop such a concordancer arises from thefact that these pack messages are themselves mul-timodal.
While they communicate through whatTwyman (1985) calls the visual channel, messagesare realized using a combination of three modes(verbal, schematic, pictorial).
Moreover, the verbalcomponents of visual messages are modulated andsegmented through typography (Waller, 1987).It is assumed that this multimodality will havecomplex implications for cross-linguistic variationwithin the genre of pack messages.
The specific na-ture of these implications is not yet known, but vari-ation in the construal of textual meaning and cohe-sion would seem to offer a good starting point forinvestigation.
However, using purely linguistic an-notation and a monomodal concordancer to analyzesuch material could reveal only part of the picture.1http://corpus.leeds.ac.uk/?martin/An existing annotation scheme, developed by theGenre and Multimodality (GeM) project2, is well-suited to my needs.
In addition to information abouttheir verbal and visual realization, the scheme pro-vides a mechanism for encoding the rhetorical rela-tions between message components.However, existing tools for multimodal analysisdo not support simultaneous investigation of verbal,visual and rhetorical phenomena.
While Baldry?s(2004) multimodal concordancer supports multilay-ered analysis of video data, his approach does notsupport the segmentation of still visual layouts, letalone consideration of specific typographical real-izations.
From an altogether different perspective,the database developed as part of the TypographicDesign for Children3 project does allow access tosuch typographic information, but does not relatethis directly to the linguistic realization of messages.Their multimodal realization makes pack mes-sages a rich testing ground for the new concordancerand Chinese and English offer great potential forlooking at multimodal cross-linguistic variation.
Ty-pographic resources are constrained by the writingsystem of a given language: Chinese offers varietyin reading directions and a consistent footprint foreach character; English offers a range of case dis-tinctions and a predictable reading direction.2 Corpus designI take each pack as a text: through the messagesby which it is realized, it ?functions as a unity withrespect to its environment?
(Halliday and Hasan,2http://www.purl.org/net/gem/3http://www.kidstype.org/571976).
In the corpus, each text constitutes a record.Each record consists of a set of files.
These includethe transcribed and annotated pack messages, andphotographs of each pack face.
In the future, packmetadata will be added to describe the product cat-egory to which the pack belongs, the product name,brand owner, variety and so on.
I will also recordthe location and date of purchase of each sample.This will support query constraints at the level ofthe record (e.g.
packs of a certain size) and will fa-cilitate comparisons across time as well as across lo-cales, or markets.Packs are represented in the corpus in an un-opened state.
As far as possible, every messageon each face of the pack which is visible in thisstate is recorded.
There are good reasons for this.Sinclair (1991) makes the point that the differencesacross specific parts of a text may constitute regu-larity within a genre.
In the context of investigationinto cross-linguistic variation within a single genre,this observation seems particularly apt.The selection of packs for inclusion in the corpuswill be made in cooperation with an industrial part-ner.
Packs will be selected from product categoriesin which the partner is active, or seeks to participate,in all three locales.
A combination of popular localbrands as well as locally established global brandswill be selected.
Thus the packs will be comparablecommercially as well as in terms of the communica-tive functions that they perform.3 Corpus annotationThe GeM scheme is described comprehensively byHenschel (2003).
It implements stand-off annota-tion in four XML layers.
The base layer segmentsthe document.
The resulting base units are cross-referenced by layers which describe layout, rhetori-cal structure and navigation.Within the layout layer, there are three main sec-tions: layout segmentation (each layout unit con-tains one or more base units), realization informa-tion and a description of the layout structure of thedocument.
These components allow a comprehen-sive picture of the typographic realization of themessages to be built, from details such as font fam-ily and colour to information about the compositionof each pack and the location, spacing and framingof chunks of layout units.Rhetorical relations between annotated units areexpressed in terms of Rhetorical Structure Theory(Mann and Thompson, 1987).
In the GeM imple-mentation, RST has been extended to accommodatethe graphical elements found in multimodal texts.RST annotation provides a way to identify patternsin the construction of messages and to make com-parisons across the corpus.
It might be that moreRST relations of a specific type, e.g.
elaboration,are found in messages from a particular locale.
Suchobservations might support or contest claims, suchas that packs from developing markets convention-ally carry more information about how to use theproduct.
In combination with the layout layer it willalso be possible to look for patterns in the choice ofsemiotic mode used to realize messages involvingspecific types of relation, such as evidence.In sum, the aim of the annotation is not to supportlow-level lexicogrammatical analysis, but rather tofacilitate the uncovering of patterns in the linguisticand typographical realization of pack messages andto relate these to semantic values expressed in termsof RST relations.
Such patterns may reflect local de-sign conventions and language-dependent strategiesfor ensuring textual cohesion.So far annotation has begun with several UK andTaiwan packs.
All annotation has been performedmanually and has proved costly in terms of time.
Infuture it is hoped that at least some annotations maybe generated through the conversion of digital copiesof designs obtained directly from brand owners.The pilot annotations have identified a number ofways in which the GeM scheme will need to be ex-tended to accommodate the genre of pack messagesand important aspects of Chinese typography: thelists of colours and font families enumerated in theDTD are not sufficiently extensive or delicate andthere is no mechanism in the layout annotation layerto record the orientation and reading direction oftext.4 The prototype concordancer4.1 Design aims and system overviewThe concordancer is an established tool for linguis-tic analysis.
Concordance lines, which show in-stances of a key word in their immediate contexts,58Figure 1: Multimodal concordancer interfacehave proved useful in uncovering patterns of usageand variation that may not be apparent either fromreading individual texts or from consulting referenceresources, such as dictionaries and grammars.My aim was to develop a similar tool to supportmultimodal analysis.
Such a tool should be ableto combine questions relating to the verbal compo-nents of messages with those relating to the typo-graphic resources through which they are realized.
Itshould do this in such a way that queries can easilybe built and modified.
To this end, a user interface isneeded.
Finally, the concordancer should be usablewithout the need for local installation of specialistclient software.In order to meet these requirements, I adopteda web-based client-server model.
The user inter-face is shown in Figure 1.
The concordancer isimplemented in Perl as a CGI script.
XPath ex-pressions are used to identify matches from amongthe XML-annotated packs and to handle cross-references across annotation layers.Using the concordancer interface to build a queryis a process of moving from the general to the spe-cific.
By default, all constraints are relaxed: submit-ting a query with these selections will return everyannotated message in the corpus.
More usefully, se-lections can be made to constrain the set of recordssearched and the linguistic, typographic, and picto-rial realization properties of messages to match.4.2 Search criteriaThe search criteria are grouped into high- and low-level selections.
I will introduce the high-level se-lections first.Locale and category selections control the set ofrecords to be processed.Given the notion of generic regularity in the dif-ferences between different parts of texts, it seemedsensible to allow queries to be constrained by packface.
Looking at the front of a shampoo bottle mightbe seen as akin to looking at the abstract of an aca-demic paper.
This is a step towards implementingmore specific constraints about the on-pack positionof messages.
The pack face constraint, as with mostof the remaining selections, is implemented in anXPath expression.
The remaining high-level selec-tions constrain the type of encoded element to in-clude in the search.The first group of low-level selections relate tospecific font properties.The colours used to realize messages are de-scribed in the corpus using hexadecimal RGBtriplets.
While this affords precision in annotation, italso means that some calculation is required to sup-port searching.
The current approach is to take anycolour selected by the user from the menu and calcu-late the distance between this and the RGB value foreach candidate match.
If this distance falls withinthe tolerance specified by the user, the colour is con-sidered to match.
Thus a search for greenmaymatchRGB values representing various hues.Finally, all matching layout units are cross-referenced with the base units that they realize.
If theuser specified a pattern to match (a string or regularexpression), this is tested against the string value ofthe base unit.4.3 Concordance displayThe final options on the interface control the dis-play of the resulting concordance.
In the pilot an-notations, an English gloss for each Chinese packmessage is recorded as an XML comment.
Theseglosses may be reproduced in the concordance.
Theother display options control whether to display thebase unit preceding and/or following the match.Figure 2 shows the results of a query generatedfrom the selections shown in Figure 1.
This is asearch for verbal messages on the front of packswhich are realized in a large font.
Unsurprisingly,in each case, this returns the product name which isconventionally salient.Details about the search query are given above the59Figure 2: Multimodal concordance exampleconcordance.
Depending on the specific query, thismay include selections for locale and product cat-egory, the XPath expression which identifies candi-date layout realization units, the colour selection andthe search string or regular expression.Information relating to each match is then dis-played.
As in a traditional concordancer, matchesare presented together with the context in which theyare found.
Optionally, this context includes the pre-ceding and following base units.
Moreover, the no-tion of context is extended to include the visual en-vironment in which each match is found.
The colourused on-pack to realize the matching message is re-used in the presentation of the match.
A thumbnailimage of the pack face on which the match is foundis also presented, as is information about the typo-graphic realization of the match, taken from the lay-out annotation.
Links are provided to high resolu-tion photographs and to each annotation layer for thepack from which the match is retrieved.The display of the thumbnail is a step towardsa more specific indication of the position of eachmatch on the pack.
In the future, I hope to use in-formation from the layout annotation to generate avisual representation of the layout chunk in whicheach match is found.The number of matches found is given below theconcordance.5 Conclusions and future workThe prototype concordancer is rather slow: it takesjust under a minute to process and print every unitin the pilot corpus and the time taken will increaseas more packs are added.
But it works.
It has alsobeen tested with files taken from the original GeMcorpus.
Once they have been renamed, followingthe conventions used by the concordancer, the legacyfiles integrate seamlessly into the new corpus.As noted above, there is scope for further devel-opment in a number of areas.
The pilot corpus needsto be populated with more packs.
The GeM annota-tion scheme requires modification in certain details.It might also be useful to add an annotation layer torecord translations of the string values of base unitsrather than using XML comments for this.As for the concordancer, support for queries basedon the rhetorical relations between message compo-nents is the next major step.
Other planned function-ality includes the generation of typographically real-ized layout chunks which contain query matches andthe calculation of collocation statistics which may becompared across sets of records.Finally, more work is needed to see whether theconcordancer is useful for the kind of analyticalwork it has been developed to support.ReferencesAnthony P. Baldry.
2004.
Phase and transition, type andinstance: patterns in media texts seen through a multi-modal concordancer.
In Kay O?Halloran, editor, Mul-timodal discourse analysis: Systemic-functional per-spectives.
Continuum, London.M.A.K.
Halliday and Ruqaiya Hasan.
1976.
Cohesion inEnglish.
Longman, London.Renate Henschel, 2003.
GeM Annotation Manual Ver-sion 2.
GeM Project.William Mann and Sandra Annear Thompson.
1987.Rhetorical structure theory: A theory of text organiza-tion.
Technical report, Information Sciences Institute,Los Angeles.John Sinclair.
1991.
Corpus, concordance, collocation.Oxford University Press, Oxford.Michael Twyman.
1985.
Using pictorial language:A discussion of the dimensions of the problem.
InThomas Walker and Robert Duffy, editors, DesigningUsable Texts, chapter 11.
Academic Press, Orlando,Florida.Robert Waller.
1987.
The Typographic Contribution toLanguage.
Ph.D. thesis, University of Reading.60
