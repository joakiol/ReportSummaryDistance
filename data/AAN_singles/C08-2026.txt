Coling 2008: Companion volume ?
Posters and Demonstrations, pages 103?106Manchester, August 2008Range concatenation grammars for translationAnders S?gaardUniversity of Potsdamsoegaard@ling.uni-potsdam.deAbstractPositive and bottom-up non-erasing bi-nary range concatenation grammars (Boul-lier, 1998) with at most binary predicates((2,2)-BRCGs) is a O(|G|n6) time strictextension of inversion transduction gram-mars (Wu, 1997) (ITGs).
It is shownthat (2,2)-BRCGs induce inside-out align-ments (Wu, 1997) and cross-serial discon-tinuous translation units (CDTUs); bothphenomena can be shown to occur fre-quently in many hand-aligned parallel cor-pora.
A CYK-style parsing algorithm isintroduced, and induction from aligmentstructures is briefly discussed.Range concatenation grammars (RCG) (Boul-lier, 1998) mainly attracted attention in the for-mal language community, since they recognize ex-actly the polynomial time recognizable languages,but recently they have been argued to be usefulfor data-driven parsing too (Maier and S?gaard,2008).
Bertsch and Nederhof (2001) present theonly work to our knowledge on using RCGs fortranslation.
Both Bertsch and Nederhof (2001)and Maier and S?gaard (2008), however, onlymake use of so-called simple RCGs, known to beequivalent to linear context-free rewrite systems(LCFRSs) (Weir, 1988; Boullier, 1998).
Our strictextension of ITGs, on the other hand, makes useof the ability to copy substrings in RCG deriva-tions; one of the things that makes RCGs strictlymore expressive than LCFRSs.
Copying enablesus to recognize the intersection of any two transla-tions that we can recognize and induce the unionc?
2008.
Licensed under the Creative CommonsAttribution-Noncommercial-Share Alike 3.0 Unported li-cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).Some rights reserved.of any two alignment structures that we can in-duce.
Our extension of ITGs in fact introducestwo things: (i) A clause may introduce any num-ber of terminals.
This enables us to induce mul-tiword translation units.
(ii) A clause may copy asubstring, i.e.
a clause can associate two or morenonterminals A1, .
.
.
Anwith the same substringand thereby check if the substring is in the inter-section of the languages of the subgrammars withstart predicate names A1, .
.
.
An.The first point is motivated by studies suchas Zens and Ney (2003) and simply reflectsthat in order to induce multiword translationunits in this kind of synchronous grammars, itis useful to be able to introduce multiple ter-minals simultaneously.
The second point givesus a handle on context-sensitivity.
It meansthat (2,2)-BRCGs can define translations such as{?anbmcndm, anbmdmcn?
| m,n ?
0}, i.e.
atranslation of cross-serial dependencies into nestedones; but it also means that (2,2)-BRCGs inducea larger class of alignment structures.
In fact theset of alignment structures that can be induced isclosed under union, i.e.
any alignment structurecan be induced.
The last point is of practical in-terest.
It is shown below that phenomena such asinside-out alignments and CDTUs, which cannotbe induced by ITGs, but by (2,2)-BRCGs, occurfrequently in many hand-aligned parallel corpora.1 (2,2)-BRCGs and ITGs(2,2)-BRCGs are positive RCGs (Boullier, 1998)with binary start predicate names, i.e.
?
(S) = 2.
InRCG, predicates can be negated (for complemen-tation), and the start predicate name is typicallyunary.
The definition is changed only for aestheticreasons; a positive RCG with a binary start predi-cate name S is turned into a positive RCG with a103unary start predicate name S?
simply by adding aclause S?
(X1X2) ?
S(X1,X2).Definition 1.1 (Positive RCGs).
A positive RCGis a 5-tuple G = ?N,T, V, P, S?.
N is a finiteset of predicate names with an arity function ?
:N ?
Z?, T and V are finite sets of, resp., ter-minal and variables.
P is a finite set of clausesof the form ?0?
?1.
.
.
?m, where and eachof the ?i, 0 ?
i ?
m, is a predicate of theform A(?1, .
.
.
, ??(A)).
Each ?j?
(T ?
V )?,1 ?
j ?
?
(A), is an argument.
S ?
N is thestart predicate name with ?
(S) = 2.Note that the order of RHS predicates in a clauseis of no importance.
Three subclasses of RCGs areintroduced for further reference: An RCG G =?N,T, V, P, S?
is simple iff for all c ?
P , it holdsthat no variable X occurs more than once in theLHS of c, and if X occurs in the LHS then itoccurs exactly once in the RHS, and each argu-ment in the RHS of c contains exactly one vari-able.
An RCG G = ?N,T, V, P, S?
is a k-RCGiff for all A ?
N, ?
(A) ?
k. Finally, an RCGG = ?N,T, V, P, S?
is said to be bottom-up non-erasing iff for all c ?
P all variables that occur inthe RHS of c also occur in its LHS.A positive RCG is a (2,2)-BRCG iff it is a 2-RCG, if an argument of the LHS predicate containsat most two variables, and if it is bottom-up non-erasing.The language of a (2,2)-BRCG is basedon the notion of range.
For a string pair?w1.
.
.
wn, vn+2.
.
.
vn+1+m?
a range is a pair ofindices ?i, j?
with 0 ?
i ?
j ?
n or n < i ?j ?
n + 1 + m, i.e.
a string span, which de-notes a substring wi+1.
.
.
wjin the source stringor a substring vi+1.
.
.
vjin the target string.
Onlyconsequtive ranges can be concatenated into newranges.
Terminals, variables and arguments ina clause are bound to ranges by a substitutionmechanism.
An instantiated clause is a clause inwhich variables and arguments are consistently re-placed by ranges; its components are instantiatedpredicates.
For example A(?g .
.
.
h?, ?i .
.
.
j?)
?B(?g .
.
.
h?, ?i+1 .
.
.
j ?
1?)
is an instantiation ofthe clause A(X1, aY1b) ?
B(X1, Y1) if the tar-get string is such that vi+1= a and vj= b. Aderive relation =?
is defined on strings of instan-tiated predicates.
If an instantiated predicate is theLHS of some instantiated clause, it can be replacedby the RHS of that instantiated clause.
The lan-guage of a (2,2)-BRCG G = ?N,T, V, P, S?
isthe set L(G) = {?w1.
.
.
wn, vn+2.
.
.
vn+1+m?
|S(?0, n?, ?n + 1, n + 1 + m?)?=?
?
}, i.e.
aninput string pair ?w1.
.
.
wn, vn+2.
.
.
vn+1+m?
isrecognized iff the empty string can be derived fromS(?0, n?, ?n + 1, n+ 1 +m?
).Theorem 1.2 ((Boullier, 2000)).
The recognitionproblem of bottom-up non-erasing k-RCG can besolved in time O(|G|nd) where d = maxcj?P(kj+vj) where cjis the jth clause in P , kjis the arity ofits LHS predicate, and vjis the number of differentvariables in that LHS predicate.It follows immediately that the recognitionproblem of (2,2)-BRCG can be solved in timeO(|G|n6), since kjcan be at most 2, and vjcanbe at most 4.Example 1.3.
Consider the (2,2)-BRCG G =?
{S0, S1, S2}, {a, b, c, d, e, f, g, h}, {X1,X2, Y1,Y2}, P, S0?
with P the following set of clauses:S0(X1, Y1) ?
S1(X1, Y1)S2(X1, Y1)S1(X1d, Y1Y2) ?
A0(X1, Y2)E(Y1)A0(X1c, Y1h) ?
A1(X1, Y1)A1(aX1, g) ?
B(X1)S2(aX1, Y1Y2) ?
T0(X1, Y1)G(Y2)T0(X1d, Y1f) ?
T1(X1, Y1)T1(bX1, e) ?
C(X1)B(b) ?
?
C(c) ?
?E(ef) ?
?
G(gh) ?
?which when words that are recognized simulta-neously are aligned, induces the alignment:a b c de f g hby inducing the alignments in the, resp., S1andS2derivations:a b c de f g ha b c de f g hExample 1.4.
Consider the (2,2)-BRCG G =?
{Ss, S0, S?0, S1, S?1, A,B,C,D}, {a, b, c, d}, {X1,X2, Y1, Y2}, P, Ss?
with P the following set ofclauses:Ss(X1, Y1) ?
S0(X1, Y1)S?0(X1, Y1)S0(X1X2, Y1) ?
S1(X1, Y1)D(X2)S1(aX1c, abY1) ?
S1(X1, Y1)S1(X1, Y1Y2) ?
B(X1)C(Y1)D(Y2)S?0(X1X2, Y1) ?
S?1(X2, Y1)A(X1)S?1(bX1d, Y1cd) ?
S?1(X1, Y1)S?1(X1, Y1Y2) ?
C(X1)A(Y1)B(Y2)A(aX1) ?
A(X1) A(?)
?
?B(bX1) ?
B(X1) B(?)
?
?C(cX1) ?
C(X1) C(?)
?
?D(dX1) ?
D(X1) D(?)
?
?Note that L(G) = {?anbmcndm, (ab)n(cd)m?
|m,n ?
0}.104Since the component grammars in ITGs arecontext-free, Example 1.4 shows that there is atleast one translation not recognizable by ITGs thatis recognized by a (2,2)-BRCG; {anbmcndm |m,n ?
0} is known to be non-context-free.
ITGstranslate into simple (2,2)-BRCGs in the follow-ing way; see Wu (1997) for a definition of ITGs.The left column is ITG production rules; the rightcolumn their translations in simple (2,2)-BRCGs.A?
[BC] A(X1X2, Y1Y2)?
B(X1, Y1)C(X2, Y2)A?
?BC?
A(X1X2, Y1Y2)?
B(X1, Y2)C(X2, Y1)A?
e | f A(e, f)?
?A?
e | ?
A(e, ?)?
?A?
?
| f A(?, f)?
?It follows immediately thatTheorem 1.5.
(2,2)-BRCGs are strictly more ex-pressive than ITGs.2 Alignment capacityZens and Ney (2003) identify a class of alignmentstructures that cannot be induced by ITGs, butthat can be induced by a number of similar syn-chronous grammar formalisms, e.g.
synchronoustree substitution grammar (STSG) (Eisner, 2003).Inside-out alignments (Wu, 1997), such as theone in Example 1.3, cannot be induced by any ofthese theories; in fact, there seems to be no usefulsynchronous grammar formalisms available thathandle inside-out alignments, with the possibleexceptions of synchronous tree-adjoining gram-mars (Shieber and Schabes, 1990), Bertsch andNederhof (2001) and generalized multitext gram-mars (Melamed et al, 2004), which are all waymore complex than ITG, STSG and (2,2)-BRCG.Nevertheless, Wellington et al (2006) report that5% of the sentence pairs in an aligned paral-lel Chinese?English corpus contained inside-outalignments.
Example 1.3 shows that (2,2)-BRCGsinduce inside-out alignments.An even stronger motivation for using (2,2)-BRCG for translation is the existence of cross-serial DTUs (CDTUs).
Informally, a CDTU is aDTU such that there is a part of another DTU in itsgap.
Here?s a simple example:a b c de fNeither ITGs nor STSGs can induce CDTUs;ITGs cannot induce DTUs with multiple gaps(MDTUs) either.
Our experiments are summarizedin Figure 1.
Overall the results show that handlingCDTUs is important for alignment error rates.3 Parsing and induction from alignmentsA CYK-style algorithm is presented for (2,2)-BRCG in Figure 2; it is assumed, w.l.o.g, that ifthe same variable occurs twice in the LHS of aclause, the clause is of the form A0(X1, Y1) ?A1(X1, Y1)A2(X1, Y1).
It modifies the originalCYK algorithm (Younger, 1967) in four ways: (i)It uses two charts; one for the source string (s) andone for the target string (t).
(ii) Pairs of nontermi-nals and integers (A, ?
), rather than just nontermi-nals, are stored in the cells of the chart (l. 2,4,6,7).Integers represent derivation steps at which non-terminals are inserted.
(iii) Multiple terminals areallowed (l. 2,6,7).
(iv) If a clause is copying, thesame two cells in the chart are visited twice (l. 4).Note that the variable ?
in insertion, e.g.
in l. 4/1, isthe current derivation step, but ?iin look-up, e.g.
inl.
4/2, is the derivation step in which the associatednonterminal was added to the chart.The overall runtime of this algorithm is inO(|G|n6), since it has, for branching clauses, sixembedded loops that iterate over the string, i.e.
thefour for loops and the two ?s in Figure 2.The induction problem from alignments can bereduced to the induction problem for ITGs by sim-ply unravelling the alignment structures.
The sim-plest algorithm for doing this assumes that align-ments are sequences of translation units, and con-siders each at a time.
If a gap is found, the trans-lation unit is a DTU and is moved to a new align-ment structure.
The complexity of the algorithmis quadratic in the length of the input sentences,i.e.
linear in the size of the alignment structure,and for a sentence pair ?w1.
.
.
wn, v1.
.
.
vm?
theITG induction algorithm has to consider at mostmin(n+m)2aligment structures.4 ConclusionA new class of grammars for syntax-based ma-chine translation was presented; while its recogni-tion problem remains solvable in time O(|G|n6),the grammars induce frequently occurring align-ment configurations that cannot be induced bycomparable classes of grammars in the literature.A parsing and an induction algorithm were pre-sented.105Sent.
TUs DTUs CDTUs MDTUs CDTUs/Sent.English?French: 100 937 95 36 11 36%English-Portuguese: 100 939 100 52 3 52%English?Spanish: 100 950 90 26 7 26%Portuguese?French: 100 915 77 19 3 19%Portuguese?Spanish: 100 991 80 40 3 40%Spanish?French: 100 975 74 24 8 24%Figure 1: Statistics for six 100-sentence hand-aligned Europarl bitexts (Graca et al, 2008).BUILD(s, [w1.
.
.
wn]), (t, [v1.
.
.
vm])1 for j ?
1 to n, for j?
?
1 tom2 do s(i?
1, j), t(i?
?
1, j?)?
{(A, ?)
| A(wi.
.
.
wj, vi?.
.
.
vj?)?
?
?
P}3 for k?
(j ?
1) to 0, for k?
?
(j?
?
1) to 04 do s(k, j), t(k?, j?)?
{(A, ?)
| A(X1, Y1)?
B(X1, Y1)C(X1, Y1) ?
P,(B, ?1), (C, ?2) ?
s(k, j), (B, ?1), (C, ?2) ?
t(k?, j?
)}5 for l?
(j ?
2) to 0, for l?
?
(j?
?
2) to 06 do s(l, j), t(l?, j?)?
{(A, ?)
| A(?1X1?2X2?3, ?1Y1?2Y2?3)?
B(X1, Y1)C(X2, Y2) ?
P,?i.
(B, ?1) ?
s(l + |?1|, i), (C, ?2) ?
s(i+ |?2|, j ?
|?3|), ?1= wl+1.
.
.
wl+|?1|,?2= wi+1.
.
.
wi+|?2|, ?3= wj?|?3|.
.
.
wj,?i?.
(B, ?1) ?
t(l?+ |?1|, i?
), (C, ?2) ?
t(i?+ |?2|, j??
|?3|), ?1= vl?+1.
.
.
vl?+|?1|,?2= vi?+1.
.
.
vi?+|?2|, ?3= vj??|?3|.
.
.
vj?
}7 do s(l, j), t(l?, j?)?
{(A, ?)
| A(?1X1?2X2?3, ?1Y1?2Y2?3)?
B(X1, Y1)C(X2, Y2) ?
P,?i.
(B, ?1) ?
s(l + |?1|, i), (C, ?2) ?
s(i+ |?2|, j ?
|?3|), ?1= wl+1.
.
.
wl+|?1|,?2= wi+1.
.
.
wi+|?2|, ?3= wj?|?3|.
.
.
wj,?i?.
(C, ?2) ?
t(l?+ |?1|, i?
), (B, ?1) ?
t(i?+ |?2|, j??
|?3|), ?1= vl?+1.
.
.
vl?+|?1|,?2= vi?+1.
.
.
vi?+|?2|, ?3= vj??|?3|.
.
.
vj?
}8 if (S, ?1) ?
s(0, n), (S, ?1) ?
t(0, m) then return success else failureFigure 2: CYK-style parsing algorithm for (2,2)-BRCG.ReferencesBertsch, Eberhard and Mark-Jan Nederhof.
2001.
On thecomplexity of some extensions of RCG parsing.
In Pro-ceedings of the 7th International Workshop on ParsingTechnologies, pages 66?77, Beijing, China.Boullier, Pierre.
1998.
Proposal for a natural language pro-cessing syntactic backbone.
Technical report, INRIA, LeChesnay, France.Boullier, Pierre.
2000.
A cubic time extension of context-freegrammars.
Grammars, 3(2?3):111?131.Eisner, Jason.
2003.
Learning non-isomorphic tree mappingsfor machine translation.
In Proceedings of the 41st AnnualMeeting of the Association for Computational Linguistics,pages 205?208, Sapporo, Japan.Graca, Joao, Joana Pardal, Lu?sa Coheur, and Diamantino Ca-seiro.
2008.
Building a golden collection of parallel multi-language word alignments.
In Proceedings of the 6th In-ternational Conference on Language Resources and Eval-uation, Marrakech, Morocco.Maier, Wolfgang and Anders S?gaard.
2008.
Treebanks andmild context-sensitivity.
In Proceedings of the 13th Con-ference on Formal Grammar, Hamburg, Germany.Melamed, Dan, Giorgio Satta, and Benjamin Wellington.2004.
Generalized multitext grammars.
In Proceedingsof the 42nd Annual Meeting of the Association for Compu-tational Linguistics, pages 661?668, Barcelona, Spain.Shieber, Stuart and Yves Schabes.
1990.
Synchronous tree-adjoining grammars.
In Proceedings of the 13th Con-ference on Computational Linguistics, pages 253?258,Helsinki, Finland.Weir, David.
1988.
Characterizing mildly context-sensitivegrammar formalisms.
Ph.D. thesis, University of Pennsyl-vania, Philadelphia, Pennsylvania.Wellington, Benjamin, Sonjia Waxmonsky, and DanMelamed.
2006.
Empirical lower bounds on the complex-ity of translational equivalence.
In Proceedings of the 44thAnnual Conference of the Association for ComputationalLinguistics, pages 977?984, Sydney, Australia.Wu, Dekai.
1997.
Stochastic inversion transduction gram-mars and bilingual parsing of parallel corpora.
Computa-tional Linguistics, 23(3):377?403.Younger, Daniel.
1967.
Recognition and parsing of context-free languages in time n3.
Information and Control,10(2):189?208.Zens, Richard and Hermann Ney.
2003.
A comparative studyon reordering constraints in statistical machine translation.In Proceedings of the 41st Annual Meeting on Associationfor Computational Linguistics, pages 144?151, Sapporo,Japan.106
