Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 385?392,Sydney, July 2006. c?2006 Association for Computational LinguisticsA Bottom-up Approach to Sentence Orderingfor Multi-document SummarizationDanushka Bollegala Naoaki Okazaki ?Graduate School of Information Science and TechnologyThe University of Tokyo7-3-1, Hongo, Bunkyo-ku, Tokyo, 113-8656, Japan{danushka,okazaki}@mi.ci.i.u-tokyo.ac.jpishizuka@i.u-tokyo.ac.jpMitsuru IshizukaAbstractOrdering information is a difficult butimportant task for applications generat-ing natural-language text.
We presenta bottom-up approach to arranging sen-tences extracted for multi-document sum-marization.
To capture the association andorder of two textual segments (eg, sen-tences), we define four criteria, chronol-ogy, topical-closeness, precedence, andsuccession.
These criteria are integratedinto a criterion by a supervised learningapproach.
We repeatedly concatenate twotextual segments into one segment basedon the criterion until we obtain the overallsegment with all sentences arranged.
Ourexperimental results show a significant im-provement over existing sentence orderingstrategies.1 IntroductionMulti-document summarization (MDS) (Radevand McKeown, 1999) tackles the informationoverload problem by providing a condensed ver-sion of a set of documents.
Among a numberof sub-tasks involved in MDS, eg, sentence ex-traction, topic detection, sentence ordering, infor-mation extraction, sentence generation, etc., mostMDS systems have been based on an extractionmethod, which identifies important textual seg-ments (eg, sentences or paragraphs) in source doc-uments.
It is important for such MDS systemsto determine a coherent arrangement of the tex-tual segments extracted from multi-documents inorder to reconstruct the text structure for summa-rization.
Ordering information is also essential for?Research Fellow of the Japan Society for the Promotionof Science (JSPS)other text-generation applications such as Ques-tion Answering.A summary with improperly ordered sen-tences confuses the reader and degrades the qual-ity/reliability of the summary itself.
Barzi-lay (2002) has provided empirical evidence thatproper order of extracted sentences improves theirreadability significantly.
However, ordering aset of sentences into a coherent text is a non-trivial task.
For example, identifying rhetoricalrelations (Mann and Thompson, 1988) in an or-dered text has been a difficult task for computers,whereas our task is even more complicated: toreconstruct such relations from unordered sets ofsentences.
Source documents for a summary mayhave been written by different authors, by differentwriting styles, on different dates, and based on dif-ferent background knowledge.
We cannot expectthat a set of extracted sentences from such diversedocuments will be coherent on their own.Several strategies to determine sentence order-ing have been proposed as described in section 2.However, the appropriate way to combine thesestrategies to achieve more coherent summaries re-mains unsolved.
In this paper, we propose fourcriteria to capture the association of sentences inthe context of multi-document summarization fornewspaper articles.
These criteria are integratedinto one criterion by a supervised learning ap-proach.
We also propose a bottom-up approachin arranging sentences, which repeatedly concate-nates textual segments until the overall segmentwith all sentences arranged, is achieved.2 Related WorkExisting methods for sentence ordering are di-vided into two approaches: making use of chrono-logical information (McKeown et al, 1999; Lin385and Hovy, 2001; Barzilay et al, 2002; Okazakiet al, 2004); and learning the natural order of sen-tences from large corpora not necessarily based onchronological information (Lapata, 2003; Barzi-lay and Lee, 2004).
A newspaper usually dissem-inates descriptions of novel events that have oc-curred since the last publication.
For this reason,ordering sentences according to their publicationdate is an effective heuristic for multidocumentsummarization (Lin and Hovy, 2001; McKeownet al, 1999).
Barzilay et al (2002) have proposedan improved version of chronological ordering byfirst grouping sentences into sub-topics discussedin the source documents and then arranging thesentences in each group chronologically.Okazaki et al (2004) have proposed an algo-rithm to improve chronological ordering by re-solving the presuppositional information of ex-tracted sentences.
They assume that each sen-tence in newspaper articles is written on the basisthat presuppositional information should be trans-ferred to the reader before the sentence is inter-preted.
The proposed algorithm first arranges sen-tences in a chronological order and then estimatesthe presuppositional information for each sentenceby using the content of the sentences placed beforeeach sentence in its original article.
The evaluationresults show that the proposed algorithm improvesthe chronological ordering significantly.Lapata (2003) has suggested a probabilisticmodel of text structuring and its application to thesentence ordering.
Her method calculates the tran-sition probability from one sentence to the nextfrom a corpus based on the Cartesian product be-tween two sentences defined using the followingfeatures: verbs (precedent relationships of verbsin the corpus); nouns (entity-based coherence bykeeping track of the nouns); and dependencies(structure of sentences).
Although she has notcompared her method with chronological order-ing, it could be applied to generic domains, not re-lying on the chronological clue provided by news-paper articles.Barzilay and Lee (2004) have proposed con-tent models to deal with topic transition in do-main specific text.
The content models are formal-ized by Hidden Markov Models (HMMs) in whichthe hidden state corresponds to a topic in the do-main of interest (eg, earthquake magnitude or pre-vious earthquake occurrences), and the state tran-sitions capture possible information-presentationorderings.
The evaluation results showed thattheir method outperformed Lapata?s approach by awide margin.
They did not compare their methodwith chronological ordering as an application ofmulti-document summarization.As described above, several good strate-gies/heuristics to deal with the sentence orderingproblem have been proposed.
In order to integratemultiple strategies/heuristics, we have formalizedthem in a machine learning framework and haveconsidered an algorithm to arrange sentences us-ing the integrated strategy.3 MethodWe define notation a ?
b to represent that sen-tence a precedes sentence b.
We use the term seg-ment to describe a sequence of ordered sentences.When segment A consists of sentences a1, a2, ...,am in this order, we denote as:A = (a1 ?
a2 ?
... ?
am).
(1)The two segments A and B can be ordered eitherB after A or A after B.
We define the notationA ?
B to show that segment A precedes segmentB.Let us consider a bottom-up approach in arrang-ing sentences.
Starting with a set of segments ini-tialized with a sentence for each, we concatenatetwo segments, with the strongest association (dis-cussed later) of all possible segment pairs, intoone segment.
Repeating the concatenating willeventually yield a segment with all sentences ar-ranged.
The algorithm is considered as a variationof agglomerative hierarchical clustering with theordering information retained at each concatenat-ing process.The underlying idea of the algorithm, a bottom-up approach to text planning, was proposed byMarcu (1997).
Assuming that the semantic units(sentences) and their rhetorical relations (eg, sen-tence a is an elaboration of sentence d) are given,he transcribed a text structuring task into the prob-lem of finding the best discourse tree that satisfiedthe set of rhetorical relations.
He stated that globalcoherence could be achieved by satisfying localcoherence constraints in ordering and clustering,thereby ensuring that the resultant discourse treewas well-formed.Unfortunately, identifying the rhetorical rela-tion between two sentences has been a difficult386aA B C Db c dE = (b a)G = (b a c d)F = (c d)SegmentsSentencesf (associationstrength)Figure 1: Arranging four sentences A, B, C, andD with a bottom-up approach.task for computers.
However, the bottom-up algo-rithm for arranging sentences can still be appliedonly if the direction and strength of the associa-tion of the two segments (sentences) are defined.Hence, we introduce a function f(A ?
B) to rep-resent the direction and strength of the associationof two segments A and B,f(A ?
B) ={ p (if A precedes B)0 (if B precedes A) , (2)where p (0 ?
p ?
1) denotes the associationstrength of the segments A and B.
The associa-tion strengths of the two segments with differentdirections, eg, f(A ?
B) and f(B ?
A), are notalways identical in our definition,f(A ?
B) 6= f(B ?
A).
(3)Figure 1 shows the process of arranging foursentences a, b, c, and d. Firstly, we initialize foursegments with a sentence for each,A = (a), B = (b), C = (c), D = (d).
(4)Suppose that f(B ?
A) has the highest value ofall possible pairs, eg, f(A ?
B), f(C ?
D), etc,we concatenate B and A to obtain a new segment,E = (b ?
a).
(5)Then we search for the segment pair with thestrongest association.
Supposing that f(C ?
D)has the highest value, we concatenate C and D toobtain a new segment,F = (c ?
d).
(6)Finally, comparing f(E ?
F ) and f(F ?
E), weobtain the global sentence ordering,G = (b ?
a ?
c ?
d).
(7)In the above description, we have not definedthe association of the two segments.
The previ-ous work described in Section 2 has addressed theassociation of textual segments (sentences) to ob-tain coherent orderings.
We define four criteria tocapture the association of two segments: chronol-ogy; topical-closeness; precedence; and succes-sion.
These criteria are integrated into a functionf(A ?
B) by using a machine learning approach.The rest of this section explains the four criteriaand an integration method with a Support VectorMachine (SVM) (Vapnik, 1998) classifier.3.1 Chronology criterionChronology criterion reflects the chronological or-dering (Lin and Hovy, 2001; McKeown et al,1999), which arranges sentences in a chronologi-cal order of the publication date.
We define the as-sociation strength of arranging segments B after Ameasured by a chronology criterion fchro(A ?
B)in the following formula,fchro(A ?
B)=??????
?1 T(am) < T(b1)1 [D(am) = D(b1)] ?
[N(am) < N(b1)]0.5 [T(am) = T(b1)] ?
[D(am) 6= D(b1)]0 otherwise.
(8)Here, am represents the last sentence in segmentA; b1 represents the first sentence in segment B;T (s) is the publication date of the sentence s;D(s) is the unique identifier of the document towhich sentence s belongs: and N(s) denotes theline number of sentence s in the original docu-ment.
The chronological order of arranging seg-ment B after A is determined by the comparisonbetween the last sentence in the segment A and thefirst sentence in the segment B.The chronology criterion assesses the appropri-ateness of arranging segment B after A if: sen-tence am is published earlier than b1; or sentenceam appears before b1 in the same article.
If sen-tence am and b1 are published on the same day butappear in different articles, the criterion assumesthe order to be undefined.
If none of the aboveconditions are satisfied, the criterion estimates thatsegment B will precede A.3.2 Topical-closeness criterionThe topical-closeness criterion deals with the as-sociation, based on the topical similarity, of two387a1a2.... .. .. .... .. ....... ....... ... ...... .. .., .... ... ........ .. .. .... .. ....... ....... ... ...... .. .., .... ... ....a3a4.... .. .. .... .. ....... ....... ... ...... .. .., .... ... ........ .. .. .... .. ....... ....... ... ...... .. .., .... ... ....b1b2b3b3b2b1 Pb1 Pb2 Pb3.... .. .. .... .. ....... ....... ... ...... .. .., .... ... ........ .. .. .... .. ....... ....... ... ...... .. .., .... ... ........ .. .. .... .. ....... ....... ... ...... .. .., .... ...
....Segment A?Segment BOriginal articlefor sentence b Original articlefor sentence b2 Original articlefor sentence b31maxaveragemaxmaxFigure 2: Precedence criterionsegments.
The criterion reflects the ordering strat-egy proposed by Barzilay et al(2002), whichgroups sentences referring to the same topic.
Tomeasure the topical closeness of two sentences, werepresent each sentence with a vector whose ele-ments correspond to the occurrence1 of the nounsand verbs in the sentence.
We define the topicalcloseness of two segments A and B as follows,ftopic(A ?
B) = 1|B|?b?Bmaxa?Asim(a, b).
(9)Here, sim(a, b) denotes the similarity of sentencesa and b, which is calculated by the cosine similar-ity of two vectors corresponding to the sentences.For sentence b ?
B, maxa?A sim(a, b) choosesthe sentence a ?
A most similar to sentence b andyields the similarity.
The topical-closeness crite-rion ftopic(A ?
B) assigns a higher value whenthe topic referred by segment B is the same as seg-ment A.3.3 Precedence criterionLet us think of the case where we arrange seg-ment A before B.
Each sentence in segment Bhas the presuppositional information that shouldbe conveyed to a reader in advance.
Given sen-tence b ?
B, such presuppositional informationmay be presented by the sentences appearing be-fore the sentence b in the original article.
How-ever, we cannot guarantee whether a sentence-extraction method for multi-document summa-rization chooses any sentences before b for a sum-mary because the extraction method usually deter-1The vector values are represented by boolean values, i.e.,1 if the sentence contains a word, otherwise 0.a1a2.... .. .. .... .. ....... ....... ... ...... .. .., .... ... ........ .. .. .... .. ....... ....... ... ...... .. .., .... ... ....a3 .... .. .. .... .. ....... ....... ... ...... .. .., .... ... ....bb2b3a3a2a1 S a1 S a2 S a3.
... ...... .. .., .... ... ........ .. .. .... .. ....... ....... ... ...... .. .., .... ... ........ .. .. .... .. ....... ....... ... ...... .. .., .... ...
....Segment A?Segment BOriginal articlefor sentence a1 Original articlefor sentence a2 Original articlefor sentence a3maxaveragemaxmax.... .. .. .... .. ....... ......1Figure 3: Succession criterionmines a set of sentences, within the constraint ofsummary length, that maximizes information cov-erage and excludes redundant information.
Prece-dence criterion measures the substitutability of thepresuppositional information of segment B (eg,the sentences appearing before sentence b) as seg-ment A.
This criterion is a formalization of thesentence-ordering algorithm proposed by Okazakiet al (2004).We define the precedence criterion in the fol-lowing formula,fpre(A ?
B) = 1|B|?b?Bmaxa?A,p?Pbsim(a, p).
(10)Here, Pb is a set of sentences appearing before sen-tence b in the original article; and sim(a, b) de-notes the cosine similarity of sentences a and b(defined as in the topical-closeness criterion).
Fig-ure 2 shows an example of calculating the prece-dence criterion for arranging segment B after A.We approximate the presuppositional informationfor sentence b by sentences Pb, ie, sentences ap-pearing before the sentence b in the original arti-cle.
Calculating the similarity among sentences inPb and A by the maximum similarity of the pos-sible sentence combinations, Formula 10 is inter-preted as the average similarity of the precedentsentences ?Pb(b ?
B) to the segment A.3.4 Succession criterionThe idea of succession criterion is the exact op-posite of the precedence criterion.
The successioncriterion assesses the coverage of the succedent in-formation for segment A by arranging segment B388abcdPartitioning pointsegment before thepartitioning pointsegment after thepartitioning pointPartitioningwindowFigure 4: Partitioning a human-ordered extractinto pairs of segmentsafter A:fsucc(A ?
B) = 1|A|?a?Amaxs?Sa,b?Bsim(s, b).
(11)Here, Sa is a set of sentences appearing after sen-tence a in the original article; and sim(a, b) de-notes the cosine similarity of sentences a and b(defined as in the topical-closeness criterion).
Fig-ure 3 shows an example of calculating the succes-sion criterion to arrange segments B after A. Thesuccession criterion measures the substitutabilityof the succedent information (eg, the sentences ap-pearing after the sentence a ?
A) as segment B.3.5 SVM classifier to assess the integratedcriterionWe integrate the four criteria described aboveto define the function f(A ?
B) to representthe association direction and strength of the twosegments A and B (Formula 2).
More specifi-cally, given the two segments A and B, functionf(A ?
B) is defined to yield the integrated asso-ciation strength from four values, fchro(A ?
B),ftopic(A ?
B), fpre(A ?
B), and fsucc(A ?
B).We formalize the integration task as a binary clas-sification problem and employ a Support VectorMachine (SVM) as the classifier.
We conducted asupervised learning as follows.We partition a human-ordered extract into pairseach of which consists of two non-overlappingsegments.
Let us explain the partitioning processtaking four human-ordered sentences, a ?
b ?c ?
d shown in Figure 4.
Firstly, we place thepartitioning point just after the first sentence a.Focusing on sentence a arranged just before thepartition point and sentence b arranged just afterwe identify the pair {(a), (b)} of two segments(a) and (b).
Enumerating all possible pairs of twosegments facing just before/after the partitioningpoint, we obtain the following pairs, {(a), (b ?c)} and {(a), (b ?
c ?
d)}.
Similarly, segment+1 : [fchro(A ?
B), ftopic(A ?
B), fpre(A ?
B), fsucc(A ?
B)]?1 : [fchro(B ?
A), ftopic(B ?
A), fpre(B ?
A), fsucc(B ?
A)]Figure 5: Two vectors in a training data generatedfrom two ordered segments A ?
Bpairs, {(b), (c)}, {(a ?
b), (c)}, {(b), (c ?
d)},{(a ?
b), (c ?
d)}, are obtained from the parti-tioning point between sentence b and c. Collect-ing the segment pairs from the partitioning pointbetween sentences c and d (i.e., {(c), (d)}, {(b ?c), (d)} and {(a ?
b ?
c), (d)}), we identify tenpairs in total form the four ordered sentences.
Ingeneral, this process yields n(n2?1)/6 pairs fromordered n sentences.
From each pair of segments,we generate one positive and one negative traininginstance as follows.Given a pair of two segments A and B arrangedin an order A ?
B, we calculate four values,fchro(A ?
B), ftopic(A ?
B), fpre(A ?
B),and fsucc(A ?
B) to obtain the instance withthe four-dimensional vector (Figure 5).
We labelthe instance (corresponding to A ?
B) as a posi-tive class (ie, +1).
Simultaneously, we obtain an-other instance with a four-dimensional vector cor-responding to B ?
A.
We label it as a negativeclass (ie, ?1).
Accumulating these instances astraining data, we obtain a binary classifier by usinga Support Vector Machine with a quadratic kernel.The SVM classifier yields the association direc-tion of two segments (eg, A ?
B or B ?
A) withthe class information (ie, +1 or ?1).
We assignthe association strength of two segments by usingthe class probability estimate that the instance be-longs to a positive (+1) class.
When an instanceis classified into a negative (?1) class, we set theassociation strength as zero (see the definition ofFormula 2).4 EvaluationWe evaluated the proposed method by using the3rd Text Summarization Challenge (TSC-3) cor-pus2.
The TSC-3 corpus contains 30 sets of ex-tracts, each of which consists of unordered sen-tences3 extracted from Japanese newspaper arti-cles relevant to a topic (query).
We arrange theextracts by using different algorithms and evaluate2http://lr-www.pi.titech.ac.jp/tsc/tsc3-en.html3Each extract consists of ca.
15 sentences on average.389Table 1: Correlation between two sets of human-ordered extractsMetric Mean Std.
Dev Min MaxSpearman 0.739 0.304 -0.2 1Kendall 0.694 0.290 0 1Average Continuity 0.401 0.404 0.001 1the readability of the ordered extracts by a subjec-tive grading and several metrics.In order to construct training data applica-ble to the proposed method, we asked two hu-man subjects to arrange the extracts and obtained30(topics) ?
2(humans) = 60 sets of orderedextracts.
Table 1 shows the agreement of the or-dered extracts between the two subjects.
The cor-relation is measured by three metrics, Spearman?srank correlation, Kendall?s rank correlation, andaverage continuity (described later).
The meancorrelation values (0.74 for Spearman?s rank cor-relation and 0.69 for Kendall?s rank correlation)indicate a certain level of agreement in sentenceorderings made by the two subjects.
8 out of 30extracts were actually identical.We applied the leave-one-out method to the pro-posed method to produce a set of sentence or-derings.
In this experiment, the leave-out-outmethod arranges an extract by using an SVMmodel trained from the rest of the 29 extracts.
Re-peating this process 30 times with a different topicfor each iteration, we generated a set of 30 ex-tracts for evaluation.
In addition to the proposedmethod, we prepared six sets of sentence orderingsproduced by different algorithms for comparison.We describe briefly the seven algorithms (includ-ing the proposed method):Agglomerative ordering (AGL) is an orderingarranged by the proposed method;Random ordering (RND) is the lowest anchor,in which sentences are arranged randomly;Human-made ordering (HUM) is the highestanchor, in which sentences are arranged bya human subject;Chronological ordering (CHR) arranges sen-tences with the chronology criterion definedin Formula 8.
Sentences are arranged inchronological order of their publication date;Topical-closeness ordering (TOP) arranges sen-tences with the topical-closeness criterion de-fined in Formula 9;0 20 40 60 80 100UnacceptablePoorAcceptablePerfectHUMAGLCHRRND%Figure 6: Subjective gradingPrecedence ordering (PRE) arranges sentenceswith the precedence criterion defined in For-mula 10;Suceedence ordering (SUC) arranges sentenceswith the succession criterion defined in For-mula 11.The last four algorithms (CHR, TOP, PRE, andSUC) arrange sentences by the corresponding cri-terion alone, each of which uses the associationstrength directly to arrange sentences without theintegration of other criteria.
These orderings areexpected to show the performance of each expertindependently and their contribution to solving thesentence ordering problem.4.1 Subjective gradingEvaluating a sentence ordering is a challengingtask.
Intrinsic evaluation that involves humanjudges to rank a set of sentence orderings is a nec-essary approach to this task (Barzilay et al, 2002;Okazaki et al, 2004).
We asked two human judgesto rate sentence orderings according to the follow-ing criteria.
A perfect summary is a text that wecannot improve any further by re-ordering.
An ac-ceptable summary is one that makes sense and isunnecessary to revise even though there is someroom for improvement in terms of readability.
Apoor summary is one that loses a thread of thestory at some places and requires minor amend-ment to bring it up to an acceptable level.
An un-acceptable summary is one that leaves much to beimproved and requires overall restructuring ratherthan partial revision.
To avoid any disturbance inrating, we inform the judges that the summarieswere made from a same set of extracted sentencesand only the ordering of sentences is different.Figure 6 shows the distribution of the subjectivegrading made by two judges to four sets of order-ings, RND, CHR, AGL and HUM.
Each set of or-390Teval = (e ?
a ?
b ?
c ?
d)Tref = (a ?
b ?
c ?
d ?
e)Figure 7: An example of an ordering under evalu-ation Teval and its reference Tref .derings has 30(topics) ?
2(judges) = 60 ratings.Most RND orderings are rated as unacceptable.Although CHR and AGL orderings have roughlythe same number of perfect orderings (ca.
25%),the AGL algorithm gained more acceptable order-ings (47%) than the CHR alghrotihm (30%).
Thisfact shows that integration of CHR experts withother experts worked well by pushing poor order-ing to an acceptable level.
However, a huge gapbetween AGL and HUM orderings was also found.The judges rated 28% AGL orderings as perfectwhile the figure rose as high as 82% for HUMorderings.
Kendall?s coefficient of concordance(Kendall?s W ), which asses the inter-judge agree-ment of overall ratings, reported a higher agree-ment between the two judges (W = 0.939).4.2 Metrics for semi-automatic evaluationWe also evaluated sentence orderings by reusingtwo sets of gold-standard orderings made for thetraining data.
In general, subjective grading con-sumes much time and effort, even though wecannot reproduce the evaluation afterwards.
Theprevious studies (Barzilay et al, 2002; Lapata,2003) employ rank correlation coefficients suchas Spearman?s rank correlation and Kendall?s rankcorrelation, assuming a sentence ordering to bea rank.
Okazaki et al (2004) propose a metricthat assess continuity of pairwise sentences com-pared with the gold standard.
In addition to Spear-man?s and Kendall?s rank correlation coefficients,we propose an average continuity metric, whichextends the idea of the continuity metric to contin-uous k sentences.A text with sentences arranged in proper orderdoes not interrupt a human?s reading while movingfrom one sentence to the next.
Hence, the qual-ity of a sentence ordering can be estimated by thenumber of continuous sentences that are also re-produced in the reference sentence ordering.
Thisis equivalent to measuring a precision of continu-ous sentences in an ordering against the referenceordering.
We define Pn to measure the precision ofTable 2: Comparison with human-made orderingMethod Spearman Kendall Averagecoefficient coefficient ContinuityRND -0.127 -0.069 0.011TOP 0.414 0.400 0.197PRE 0.415 0.428 0.293SUC 0.473 0.476 0.291CHR 0.583 0.587 0.356AGL 0.603 0.612 0.459n continuous sentences in an ordering to be evalu-ated as,Pn = mN ?
n+ 1 .
(12)Here, N is the number of sentences in the refer-ence ordering; n is the length of continuous sen-tences on which we are evaluating; m is the num-ber of continuous sentences that appear in both theevaluation and reference orderings.
In Figure 7,the precision of 3 continuous sentences P3 is cal-culated as:P3 = 25?
3 + 1 = 0.67.
(13)The Average Continuity (AC) is defined as thelogarithmic average of Pn over 2 to k:AC = exp(1k ?
1k?n=2log(Pn + ?)).
(14)Here, k is a parameter to control the range of thelogarithmic average; and ?
is a small value in caseif Pn is zero.
We set k = 4 (ie, more than fivecontinuous sentences are not included for evalua-tion) and ?
= 0.01.
Average Continuity becomes0 when evaluation and reference orderings shareno continuous sentences and 1 when the two or-derings are identical.
In Figure 7, Average Conti-nuity is calculated as 0.63.
The underlying idea ofFormula 14 was proposed by Papineni et al (2002)as the BLEU metric for the semi-automatic evalu-ation of machine-translation systems.
The origi-nal definition of the BLEU metric is to compare amachine-translated text with its reference transla-tion by using the word n-grams.4.3 Results of semi-automatic evaluationTable 2 reports the resemblance of orderings pro-duced by six algorithms to the human-made oneswith three metrics, Spearman?s rank correlation,Kendall?s rank correlation, and Average Continu-ity.
The proposed method (AGL) outperforms the3910.00.10.20.30.40.50.60.70.8AGLCHRSUCPRETOPRND8765432Preci s i on PnLength nFigure 8: Precision vs unit of measuring continu-ity.rest in all evaluation metrics, although the chrono-logical ordering (CHR) appeared to play the majorrole.
The one-way analysis of variance (ANOVA)verified the effects of different algorithms for sen-tence orderings with all metrics (p < 0.01).
Weperformed Tukey Honest Significant Differences(HSD) test to compare differences among these al-gorithms.
The Tukey test revealed that AGL wassignificantly better than the rest.
Even though wecould not compare our experiment with the prob-abilistic approach (Lapata, 2003) directly due tothe difference of the text corpora, the Kendall co-efficient reported higher agreement than Lapata?sexperiment (Kendall=0.48 with lemmatized nounsand Kendall=0.56 with verb-noun dependencies).Figure 8 shows precision Pn with differentlength values of continuous sentence n for the sixmethods compared in Table 2.
The number ofcontinuous sentences becomes sparse for a highervalue of length n. Therefore, the precision valuesdecrease as the length n increases.
Although RNDordering reported some continuous sentences forlower n values, no continuous sentences could beobserved for the higher n values.
Four criteria de-scribed in Section 3 (ie, CHR, TOP, PRE, SUC)produce segments of continuous sentences at allvalues of n.5 ConclusionWe present a bottom-up approach to arrange sen-tences extracted for multi-document summariza-tion.
Our experimental results showed a signif-icant improvement over existing sentence order-ing strategies.
However, the results also impliedthat chronological ordering played the major rolein arranging sentences.
A future direction of thisstudy would be to explore the application of theproposed framework to more generic texts, suchas documents without chronological information.AcknowledgmentWe used Mainichi Shinbun and Yomiuri Shinbunnewspaper articles, and the TSC-3 test collection.ReferencesRegina Barzilay and Lillian Lee.
2004.
Catching thedrift: Probabilistic content models, with applicationsto generation and summarization.
In HLT-NAACL2004: Proceedings of the Main Conference, pages113?120.Regina Barzilay, Noemie Elhadad, and Kathleen McK-eown.
2002.
Inferring strategies for sentence order-ing in multidocument news summarization.
Journalof Artificial Intelligence Research, 17:35?55.Mirella Lapata.
2003.
Probabilistic text structuring:Experiments with sentence ordering.
Proceedings ofthe annual meeting of ACL, 2003., pages 545?552.C.Y.
Lin and E. Hovy.
2001.
Neats:a multidocumentsummarizer.
Proceedings of the Document Under-standing Workshop(DUC).W.
Mann and S. Thompson.
1988.
Rhetorical structuretheory: Toward a functional theory of text organiza-tion.
Text, 8:243?281.Daniel Marcu.
1997.
From local to global coherence:A bottom-up approach to text planning.
In Proceed-ings of the 14th National Conference on ArtificialIntelligence, pages 629?635, Providence, Rhode Is-land.Kathleen McKeown, Judith Klavans, Vasileios Hatzi-vassiloglou, Regina Barzilay, and Eleazar Eskin.1999.
Towards multidocument summarization byreformulation: Progress and prospects.
AAAI/IAAI,pages 453?460.Naoaki Okazaki, Yutaka Matsuo, and MitsuruIshizuka.
2004.
Improving chronological sentenceordering by precedence relation.
In Proceedingsof 20th International Conference on ComputationalLinguistics (COLING 04), pages 750?756.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
Bleu:a method for automatic eval-uation of machine translation.
Proceedings of the40th Annual Meeting of the Association for Compu-tational Linguistics (ACL), pages 311?318.Dragomir R. Radev and Kathy McKeown.
1999.Generating natural language summaries from mul-tiple on-line sources.
Computational Linguistics,24:469?500.V.
Vapnik.
1998.
Statistical Learning Theory.
Wiley,Chichester, GB.392
