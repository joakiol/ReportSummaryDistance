Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 1153?1160,Sydney, July 2006. c?2006 Association for Computational LinguisticsTime Period Identification of Events in TextTaichi Noro?
Takashi Inui??
Hiroya Takamura?
Manabu Okumura?
?Interdisciplinary Graduate School of Science and EngineeringTokyo Institute of Technology4259 Nagatsuta-cho, Midori-ku, Yokohama, Kanagawa, Japan?
?Japan Society for the Promotion of Science?Precision and Intelligence Laboratory, Tokyo Institute of Technology{norot, tinui}@lr.pi.titech.ac.jp,{takamura, oku}@pi.titech.ac.jpAbstractThis study aims at identifying when anevent written in text occurs.
In particular,we classify a sentence for an event intofour time-slots; morning, daytime, eve-ning, and night.
To realize our goal, wefocus on expressions associated withtime-slot (time-associated words).
How-ever, listing up all the time-associatedwords is impractical, because there arenumerous time-associated expressions.We therefore use a semi-supervisedlearning method, the Na?ve Bayes classi-fier backed up with the ExpectationMaximization algorithm, in order to it-eratively extract time-associated wordswhile improving the classifier.
We alsopropose to use Support Vector Machinesto filter out noisy instances that indicatesno specific time period.
As a result of ex-periments, the proposed method achieved0.864 of accuracy and outperformedother methods.1 IntroductionIn recent years, the spread of the internet has ac-celerated.
The documents on the internet haveincreased their importance as targets of businessmarketing.
Such circumstances have evokedmany studies on information extraction from textespecially on the internet, such as sentimentanalysis and extraction of location information.In this paper, we focus on the extraction of tem-poral information.
Many authors of documentson the web often write about events in their dailylife.
Identifying when the events occur providesus valuable information.
For example, we canuse temporal information as a new axis in theinformation retrieval.
From time-annotated text,companies can figure out when customers usetheir products.
We can explore activities of usersfor marketing researches, such as ?What dopeople eat in the morning?
?, ?What do peoplespend money for in daytime?
?Most of previous work on temporal processingof events in text dealt with only newswire text.
Inthose researches, it is assumed that temporal ex-pressions indicating the time-period of events areoften explicitly written in text.
Some examples ofexplicit temporal expressions are as follows: ?onMarch 23?, ?at 7 p.m.?.However, other types of text including webdiaries and blogs contain few explicit temporalexpressions.
Therefore one cannot acquire suffi-cient temporal information using existing meth-ods.
Although dealing with such text as web dia-ries and blogs is a hard problem, those types oftext are excellent information sources due totheir overwhelmingly huge amount.In this paper, we propose a method for estimat-ing occurrence time of events expressed in in-formal text.
In particular, we classify sentencesin text into one of four time-slots; morning, day-time, evening, and night.
To realize our goal, wefocus on expressions associated with time-slot(hereafter, called time-associated words), such as?commute (morning)?, ?nap (daytime)?
and?cocktail (night)?.
Explicit temporal expressionshave more certain information than the time-associated words.
However, these expressionsare rare in usual text.
On the other hand, al-though the time-associated words provide usonly indirect information for estimating occur-rence time of events, these words frequently ap-pear in usual text.
Actually, Figure 2 (we willdiscuss the graph in Section 5.2, again) showsthe number of sentences including explicit tem-1153poral expressions and time-associated words re-spectively in text.
The numbers are obtainedfrom a corpus we used in this paper.
We can fig-ure out that there are much more time-associatedwords than explicit temporal expressions in blogtext.
In other words, we can deal with wide cov-erage of sentences in informal text by ourmethod with time-associated words.However, listing up all the time-associatedwords is impractical, because there are numeroustime-associated expressions.
Therefore, we use asemi-supervised method with a small amount oflabeled data and a large amount of unlabeled data,because to prepare a large quantity of labeleddata is costly, while unlabeled data is easy to ob-tain.
Specifically, we adopt the Na?ve Bayesclassifier backed up with the Expectation Maxi-mization (EM) algorithm (Dempster et al, 1977)for semi-supervised learning.
In addition, wepropose to use Support Vector Machines to filterout noisy sentences that degrade the performanceof the semi-supervised method.In our experiments using blog data, we ob-tained 0.864 of accuracy, and we have showneffectiveness of the proposed method.This paper is organized as follows.
In Section2 we briefly describe related work.
In Section 3we describe the details of our corpus.
The pro-posed method is presented in Section 4.
In Sec-tion 5, we describe experimental results and dis-cussions.
We conclude the paper in Section 6.2 Related WorkThe task of time period identification is newand has not been explored much to date.Setzer et al (2001) and Mani et al (2000)aimed at annotating newswire text for analyzingtemporal information.
However, these previouswork are different from ours, because these workonly dealt with newswire text including a lot ofexplicit temporal expressions.Tsuchiya et al (2005) pursued a similar goalas ours.
They manually prepared a dictionarywith temporal information.
They use the hand-crafted dictionary and some inference rules todetermine the time periods of events.
In contrast,we do not resort to such a hand-crafted material,which requires much labor and cost.
Our methodautomatically acquires temporal informationfrom actual data of people's activities (blog).Henceforth, we can get temporal informationassociated with your daily life that would be notexisted in a dictionary.3 CorpusIn this section, we describe a corpus made fromblog entries.
The corpus is used for training andtest data of machine learning methods mentionedin Section 4.The blog entries we used are collected by themethod of Nanno et al (2004).
All the entries arewritten in Japanese.
All the entries are split intosentences automatically by some heuristic rules.In the next section, we are going to explain?time-slot?
tag added at every sentence.3.1 Time-Slot TagThe ?time-slot?
tag represents when an eventoccurs in five classes; ?morning?, ?daytime?,?evening?, ?night?, and ?time-unknown?.
?Time-unknown?
means that there is no temporal in-formation.
We set the criteria of time-slot tags asfollows.Morning: 04:00--10:59from early morning till before noon, breakfastDaytime: 11:00--15:59from noon till before dusk, lunchEvening: 16:00--17:59from dusk till before sunsetNight: 18:00--03:59from sunset till dawn, dinnerNote that above criteria are just interpreted asrough standards.
We think time-slot recognizedby authors is more important.
For example, in acase of ?about 3 o'clock this morning?
we judgethe case as ?morning?
(not ?night?)
with the ex-pression written by the author ?this morning?.To annotate sentences in text, we used two dif-ferent clues.
One is the explicit temporal expres-sions or time-associated words included in thesentence to be judged.
The other is contextualinformation around the sentences to be judged.The examples corresponding to the former caseare as follows:Example 1a.
I went to post office by bicycle in the morning.b.
I had spaghetti at restaurant at noon.c.
I cooked stew as dinner on that day.Suppose that the two sentences in Example 2appear successively in a document.
In this case,we first judge the first sentence as morning.
Next,we judge the second sentence as morning by con-textual information (i.e., the preceding sentenceis judged as morning), although we cannot knowthe time period just from the content of the sec-ond sentence itself.11544.2 Na?ve Bayes Classifier Example 21.
I went to X by bicycle in the morning.
In this section, we describe multinomial modelthat is a kind of Na?ve Bayes classifiers.
2.
I went to a shop on the way back from X.A generative probability of example x  given acategory  has the form: c3.2 Corpus StatisticsWe manually annotated the corpus.
The numberof the blog entries is 7,413.
The number of sen-tences is 70,775.
Of 70,775, the number of sen-tences representing any events1 is 14,220.
Thefrequency distribution of time-slot tags is shownin Table 1.
We can figure out that the number oftime-unknown sentences is much larger than theother sentences from this table.
This bias wouldaffect our classification process.
Therefore, wepropose a method for tackling the problem.
( ) ( ) ( ) ( )( )?= wxwNxwNcwPxxPcxP,|!,|,?
(1)where ( )xP  denotes the probability that a sen-tence of length x  occurs,  denotes thenumber of occurrences of w  in text( xwN , )x .
The oc-currence of a sentence is modeled as a set of tri-als, in which a word is drawn from the wholevocabulary.In time-slot classification, the x  is correspondto each sentence, the c  is correspond to one oftime-slots in {morning, daytime, evening, night}.Features are words in the sentence.
A detaileddescription of features will be described in Sec-tion 4.5.morning 711daytime 599evening 207night 1,035time-unknown 11,668Total 14,2204.3 Incorporation of Unlabeled Data withthe EM AlgorithmTable 1: The numbers of time-slot tags.The EM algorithm (Dempster et al, 1977) is amethod to estimate a model that has the maximallikelihood of the data when some variables can-not be observed (these variables are called latentvariables).
Nigam et al (2000) proposed a com-bination of the Na?ve Bayes classifiers and theEM algorithm.4 Proposed Method4.1 Basic IdeaSuppose, for example, ?breakfast?
is a strongclue for the morning class, i.e.
the word is atime-associated word of morning.
Thereby wecan classify the sentence ?I have cereal forbreakfast.?
into the morning class.
Then ?cereal?will be a time-associated word of morning.Therefore we can use ?cereal?
as a clue of time-slot classification.
By iterating this process, wecan obtain a lot of time-associated words withbootstrapping method, improving sentence clas-sification performance at the same time.Ignoring the unrelated factors of Eq.
(1), weobtain( ) ( ) ( )?
?wxwNcwPcxP ,|,| ,?
(2)( ) ( ) ( ) ( )??
?wxwNccwPcPxP .|| ,?
(3)We express model parameters as ?
.If we regard c  as a latent variable and intro-duce a Dirichlet distribution as the prior distribu-tion for the parameters, the Q-function (i.e., theexpected log-likelihood) of this model is definedas:To realize the bootstrapping method, we usethe EM algorithm.
This algorithm has a theoreti-cal base of likelihood maximization of incom-plete data and can enhance supervised learningmethods.
We specifically adopted the combina-tion of the Na?ve Bayes classifier and the EMalgorithm.
This combination has been proven tobe effective in the text classification (Nigam etal., 2000).
( ) ( )( ) ( )( ) ( ) ( ) ,|log,|log|, ?????????+=???
?wxwNDx ccwPcPcxPPQ ????
(4)where ( ) ( ) ( )( )( )?
?
???
c w cwPcPP 11 | ???
.
?
is auser given parameter and D  is the set of exam-ples used for model estimation.1 The aim of this study is time-slot classification ofevents.
Therefore we treat only sentences expressingan event.We obtain the next EM equation from this Q-function:1155Figure 1: The flow of 2-step classification.E-step:( ) ( ) ( )( ) ( ),,|| ,||,| ?= c cxPcPcxPcPxcP ?????
(5)M-step:( ) ( ) ( )( ) ,1 ,|1 DC xcPcP Dx +?+?= ?
??
??
(6)( )( ) ( ) ( )( ) ( ) ( ) ,,,|1 ,,|1|?
???
?+?+?=w DxDxxwNxcPWxwNxcPcwP????
(7)where C  denotes the number of categories, Wdenotes the number of features variety.
For la-beled example x , Eq.
(5) is not used.
Instead, ( )?,| xcP  is set as 1.0 if c  is the category of x ,otherwise 0.Instead of the usual EM algorithm, we use thetempered EM algorithm (Hofmann, 2001).
Thisalgorithm allows coordinating complexity of themodel.
We can realize this algorithm by substi-tuting the next equation for Eq.
(5) at E-step:( ) ( ) ( ){ }( ) ( ){ } ,,|| ,||,| ?= c cxPcPcxPcPxcP ???????
(8)where ?
denotes a hyper parameter for coordi-nating complexity of the model, and it is positivevalue.
By decreasing this hyper-parameter ?
, wecan reduce the influence of intermediate classifi-cation results if those results are unreliable.Too much influence by unlabeled data some-times deteriorates the model estimation.
There-fore, we introduce a new hyper-parameter( 10 ??
)??
which acts as weight on unlabeleddata.
We exchange the second term in the right-hand-side of Eq.
(4) for the next equation:( ) ( ) ( ) ( )( ) ( ) ( ) ( ) ,|log,||log,|,,?
???
????????????+???????
?ulDx wxwNcDx wxwNccwPcPxcPcwPcPxcP??
?where lD  denotes labeled data, uD  denotesunlabeled data.
We can reduce the influence ofunlabeled data by decreasing the value of ?
.We derived new update rules from this new Q-function.
The EM computation stops when thedifference in values of the Q-function is smallerthan a threshold.4.4 Class Imbalance ProblemWe have two problems with respect to ?time-unknown?
tag.The first problem is the class imbalance prob-lem (Japkowicz 2000).
The number of time-unknown time-slot sentences is much larger thanthat of the other sentences as shown in Table 1.There are more than ten times as many time-unknown time-slot sentences as the other sen-tences.Second, there are no time-associated words inthe sentences categorized into ?time-unknown?.Thus the feature distribution of time-unknowntime-slot sentences is remarkably different fromthe others.
It would be expected that they ad-versely affect proposed method.There have been some methodologies in orderto solve the class imbalance problem, such asZhang and Mani (2003), Fan et al (1999) andAbe et al (2004).
However, in our case, we haveto resolve the latter problem in addition to theclass imbalance problem.
To deal with two prob-lems above simultaneously and precisely, wedevelop a cascaded classification procedure.SVMNB + EMStep 2Time-SlotClassifiertime-slot = time-unknowntime-slot = morning, daytime, evening, nighttime-slot = morningtime-slot = daytimetime-slot = morning, daytime, evening, night, time-unknown Step1Time-UnknownFiltertime-slot = nighttime-slot = evening11564.5 Time-Slot Classification MethodIt?s desirable to treat only ?time-known?
sen-tences at NB+EM process to avoid the above-mentioned problems.
We prepare another classi-fier for filtering time-unknown sentences beforeNB+EM process for that purpose.
Thus, we pro-pose a classification method in 2 steps (MethodA).
The flow of the 2-step classification is shownin Figure 1.
In this figure, ovals represent classi-fiers, and arrows represent flow of data.The first classifier (hereafter, ?time-unknown?filter) classifies sentences into two classes;?time-unknown?
and ?time-known?.
The ?time-known?
class is a coarse class consisting of fourtime-slots (morning, daytime, evening, andnight).
We use Support Vector Machines as aclassifier.
The features we used are all wordsincluded in the sentence to be classified.The second classifier (time-slot classifier)classifies ?time-known?
sentences into fourclasses.
We use Na?ve Bayes classifier backed upwith the Expectation Maximization (EM) algo-rithm mentioned in Section 4.3.The features for the time-slot classifier arewords, whose part of speech is noun or verb.
Theset of these features are called NORMAL in therest of this paper.
In addition, we use informationfrom the previous and the following sentences inthe blog entry.
The words included in such sen-tences are also used as features.
The set of thesefeatures are called CONTEXT.
The features inCONTEXT would be effective for estimatingtime-slot of the sentences as mentioned in Ex-ample2 in Section 3.1.We also use a simple classifier (Method B) forcomparison.
The Method B classifies all time-slots (morning ~ night, time-unknown) sentencesat just one step.
We use Na?ve Bayes classifierbacked up with the Expectation Maximization(EM) algorithm at this learning.
The features arewords (whose part-of-speech is noun or verb)included in the sentence to be classified.5 Experimental Results and Discussion5.1 Time-Slot Classifier with Time-Associated Words5.1.1 Time-Unknown FilterWe used 11.668 positive (time-unknown) sam-ples and 2,552 negative (morning ~ night) sam-ples.
We conducted a classification experimentby Support Vector Machines with 10-fold crossvalidation.
We used TinySVM2 software pack-age for implementation.
The soft margin parame-ter is automatically estimated by 10-fold crossvalidation with training data.
The result is shownin Table 2.Table 2 clarified that the ?time-unknown?
fil-ter achieved good performance; F-measure of0.899.
In addition, since we obtained a high re-call (0.969), many of the noisy sentences will befiltered out at this step and the classifier of thesecond step is likely to perform well.Accuracy 0.878Precision 0.838Recall 0.969F-measure 0.899Table 2: Classification result ofthe time-unknown filter.5.1.2 Time-Slot ClassificationIn step 2, we used ?time-known?
sentences clas-sified by the unknown filter as test data.
We con-ducted a classification experiment by Na?veBayes classifier + the EM algorithm with 10-foldcross validation.
For unlabeled data, we used64,782 sentences, which have no intersectionwith the labeled data.
The parameters, ?
and ?
,are automatically estimated by 10-fold crossvalidation with training data.
The result is shownin Table 3.Accuracy MethodNORMAL CONTEXTExplicit 0.109Baseline 0.406NB 0.567 0.464NB + EM 0.673 0.670Table 3: The result of time-slot classifier.2 http://www.chasen.org/~taku/software/TinySVM1157Table 4: Confusion matrix of output.morning daytime evening nightrank word p(c|w) word p(c|w) word p(c|w) word p(c|w)1 this morning 0.729 noon 0.728 evening 0.750 last night 0.7022 morning 0.673 early after noon 0.674 sunset 0.557 night 0.6893 breakfast 0.659 afternoon 0.667 academy 0.448 fireworks 0.6884 early morning 0.656 daytime 0.655 dusk 0.430 dinner 0.6845 before noon 0.617 lunch 0.653 Hills 0.429 go to bed 0.6646 compacted snow 0.603 lunch 0.636 run on 0.429 night 0.6417 commute 0.561 lunch break 0.629 directions 0.429 bow 0.6348 --- 0.541 lunch 0.607 pinecone 0.429 overtime 0.6069 parade 0.540 noon 0.567 priest 0.428 year-end party 0.60310 wake up 0.520 butterfly 0.558 sand beach 0.428 dinner 0.57411 leave harbor 0.504 Chinese food 0.554 --- 0.413 beach 0.57212 rise late 0.504 forenoon 0.541 Omori 0.413 cocktail 0.57013 cargo work 0.504 breast-feeding 0.536 fan 0.413 me 0.56214 alarm clock 0.497 nap 0.521 Haneda 0.412 Tomoyuki 0.56015 --- 0.494 diaper 0.511 preview 0.402 return home 0.55716 sunglow 0.490 Japanese food 0.502 cloud 0.396 close 0.55517 wheel 0.479 star festival 0.502 Dominus 0.392 stay up late 0.55118 wake up 0.477 hot noodle 0.502 slip 0.392 tonight 0.54919 perm 0.474 pharmacy 0.477 tasting 0.391 night 0.53420 morning paper 0.470 noodle 0.476 nest 0.386 every night 0.521Table 5: Time-associated words examples.In Table 3, ?Explicit?
indicates the result by asimple classifier based on regular expressions 3including explicit temporal expressions.
Thebaseline method classifies all sentences intonight because the number of night sentences isthe largest.
The ?CONTEXT?
column shows theresults obtained by classifiers learned with thefeatures in CONTEXT in addition to the features3 For example, we classify sentences matching follow-ing regular expressions into morning class:[(gozen)(gozen-no)(asa) (asa-no)(am)(AM)(am-no)(AM-no)][456789(10)] ji, [(04)(05)(06)(07)(08)(09)]ji, [(04)(05)(06)(07) (08) (09)]:[0-9]{2,2},[456789(10)][(am)(AM)].?
?gozen?, ?gozen?no?
means before noon.
?asa?,?asa-no?
means morning.
?ji?
means o?clock.
?in NORMAL.
The accuracy of the Explicitmethod is lower than the baseline.
This meansexisting methods based on explicit temporal ex-pressions cannot work well in blog text.
The ac-curacy of the method 'NB' exceeds that of thebaseline by 16%.
Furthermore, the accuracy ofthe proposed method 'NB+EM' exceeds that ofthe 'NB' by 11%.
Thus, we figure out that usingunlabeled data improves the performance of ourtime-slot classification.In this experiment, unfortunately, CONTEXTonly deteriorated the accuracy.
The time-slot tagsof the sentences preceding or following the targetsentence may still provide information to im-prove the accuracy.
Thus, we tried a sequentialtagging method for sentences, in which tags areoutput of time-slot classifiermorning daytime evening night time-unknownsummorning 332 14 1 37 327 711daytime 30 212 1 44 312 599evening 4 5 70 18 110 207night 21 19 4 382 609 1035time-slottagtime-unknown 85 66 13 203 11301 11668sum 472 316 89 684 12659 142201158predicted in the order of their occurrence.
Thepredicted tags are used as features in the predic-tion of the next tag.
This type of sequential tag-ging method regard as a chunking procedure(Kudo and Matsumoto, 2000) at sentence level.We conducted time-slot (five classes) classifica-tion experiment, and tried forward tagging andbackward tagging, with several window sizes.We used YamCha4, the multi-purpose text chun-ker using Support Vector Machines, as an ex-perimental tool.
However, any tagging directionand window sizes did not improve the perform-ance of classification.
Although a chunkingmethod has possibility of correctly classifying asequence of text units, it can be adversely biasedby the preceding or the following tag.
The sen-tences in blog used in our experiments would nothave a very clear tendency in order of tags.
Thisis why the chunking-method failed to improvethe performance in this task.
We would like totry other bias-free methods such as ConditionalRandom Fields (Lafferty et al, 2001) for futurework.5.1.3 2-step ClassificationFinally, we show an accuracy of the 2-step clas-sifier (Method A) and compare it with those ofother classifiers in Table 6.
The accuracies arecalculated with the equation:.In Table 6, the baseline method classifies allsentences into time-unknown because the num-ber of time-unknown sentences is the largest.Accuracy of Method A (proposed method) ishigher than that of Method B (4.1% over).
Theseresults show that time-unknown sentences ad-versely affect the classifier learning, and 2-stepclassification is an effective method.Table 4 shows the confusion matrix corre-sponding to the Method A (NORMAL).
Fromthis table, we can see Method A works well forclassification of morning, daytime, evening, andnight, but has some difficulty in4 http://www.chasen.org/~taku/software/YamChaTable 6: Comparison of the methods for fiveclass classificationFigure 2: Change of # sentences that have time-associated words: ?Explicit?
indicates the num-ber of sentences including explicit temporal ex-pressions, ?NE-TIME?
indicates the number ofsentences including NE-TIME tag.classification of time-unknown.
The 11.7% ofsamples were wrongly classified into ?night?
or?unknown?.We briefly describe an error analysis.
Wefound that our classifier tends to wrongly classifysamples in which two or more events are writtenin a sentence.
The followings are examples:Example 3a.
I attended a party last night, and I got backon the first train in this morning because theparty was running over.b.
I bought a cake this morning, and ate it afterthe dinner.5.2 Examples of Time-Associated WordsTable 5 shows some time-associated words ob-tained by the proposed method.
The words aresorted in the descending order of the value of ( )wcP | .
Although some consist of two or threewords, their original forms in Japanese consist ofone word.
There are some expressions appearingmore than once, such as ?dinner?.
Actually theseexpressions have different forms in Japanese.Meaningless (non-word) strings caused by mor-Method Conclusive accuracyExplicit 0.833Baseline 0.821Method A (NORMAL) 0.864Method A (CONTEXT) 0.862Method B 0.8230100020003000400050001 10 20 30 40 50 60 70 80 90 100# time-associated words (N-best)#sentencesincludingtime-associatedwordsExplicitNE-TIME# time-unknown sentences correctly classi-fied by the time-unknown filter# known sentences correctly classi-fied by the time-slot classifier +# sentences with a time-slot tag value1159phological analysis error are presented as thesymbol ?---?.
We obtained a lot of interestingtime-associated words, such as ?commute (morn-ing)?, ?fireworks (night)?, and ?cocktail (night)?.Most words obtained are significantly differentfrom explicit temporal expressions and NE-TIME expressions.Figure 2 shows the number of sentences in-cluding time-associated words in blog text.
Thehorizontal axis represents the number of time-associated words.
We sort the words in the de-scending order of  and selected the top Nwords.
The vertical axis represents the number ofsentences including any N-best time-associatedwords.
We also show the number of sentencesincluding explicit temporal expressions, and thenumber of sentences including NE-TIME tag(Sekine and Isahara, 1999) for comparison.
Theset of explicit temporal expressions was ex-tracted by the method described in Section 5.1.2.We used a Japanese linguistic analyzer ?Cabo-Cha( wcP | )5 ?
to obtain NE-TIME information.
Fromthis graph, we can confirm that the number oftarget sentences of our proposed method is largerthan that of existing methods.6 ConclusionIn our study, we proposed a method for identify-ing when an event in text occurs.
We succeededin using a semi-supervised method, the Na?veBayes Classifier enhanced by the EM algorithm,with a small amount of labeled data and a largeamount of unlabeled data.
In order to avoid theclass imbalance problem, we used a 2-step classi-fier, which first filters out time-unknown sen-tences and then classifies the remaining sen-tences into one of 4 classes.
The proposedmethod outperformed the simple 1-step method.We obtained 86.4% of accuracy that exceeds theexisting method and the baseline method.ReferencesNaoki Abe, Bianca Zadrozny, John Langford.
2004.An Iterative Method for Multi-class Cost-sensitiveLearning.
In Proc.
of the 10th.
ACM SIGKDD,pp.3?11.Arthur P. Dempster, Nan M. laird, and Donald B.Rubin.
1977.
Maximum likelihood from incom-plete data via the EM algorithm.
Journal of the5 http://chasen.org/~taku/software/cabocha/Royal Statistical Society Series B, Vol.
39, No.
1,pp.1?38.Wei Fan, Salvatore J. Stolfo, Junxin Zhang, Philip K.Chan.
1999.
AdaCost: Misclassification Cost-sensitive Boosting.
In Proc.
of ICML, pp.97?105.Thomas Hofmann.
2001.
Unsupervised learning byprobabilistic latent semantic analysis.
MachineLearning, 42:177?196.Nathalie Japkowicz.
2000.
Learning from ImbalancedData Sets: A Comparison of Various Strategies.
InProc.
of the AAAI Workshop on Learning from Im-balanced Data Sets, pp.10 ?15.Taku Kudo, Yuji Matsumoto.
2000.
Use of SupportVector Learning for Chunking Identification, InProc of the 4th CoNLL, pp.142?144.John Lafferty, Andrew McCallum, and FernandoPereira.
2001.
Conditional random fields: Probabil-istic models for segmenting and labeling sequencedata, In Proc.
of ICML, pp.282?289.Inderjeet Mani, George Wilson 2000.
Robust Tempo-ral Processing of News.
In Proc.
of the 38th ACL,pp.69?76.Tomoyuki Nanno, Yasuhiro Suzuki, Toshiaki Fujiki,Manabu Okumura.
2004.
Automatically Collectingand Monitoring Japanese Weblogs.
Journal forJapanese Society for Artificial Intelligence ?Vol.19, No.6, pp.511?520.
(in Japanese)Kamal Nigam, Andrew McCallum, Sebastian Thrun,and Tom Mitchell.
2000.
Text classification fromlabeled and unlabeled documents using EM.
Ma-chine Learning, Vol.
39, No.2/3, pp.103?134.Satoshi Sekine, Hitoshi Isahara.
1999.
IREX projectoverview.
Proceedings of the IREX Workshop.Andrea Setzer, Robert Gaizauskas.
2001.
A PilotStudy on Annotating Temporal Relations in Text.In Proc.
of the ACL-2001 Workshop on Temporaland Spatial Information Processing, Toulose,France, July, pp.88?95.Seiji Tsuchiya, Hirokazu Watabe, Tsukasa Kawaoka.2005.
Evaluation of a Time Judgement TechniqueBased on an Association Mechanism.
IPSG SIGTechnical Reports?2005-NL-168, pp.113?118.
(inJapanese)Jianping Zhang, Inderjeet Mani.
2003. kNN Approachto Unbalanced Data Distributions: A Case Studyinvolving Information Extraction.
In Proc.
ofICML Workshop on Learning from ImbalancedDatasets II., pp.42?48.1160
