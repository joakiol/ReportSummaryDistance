Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 20?25,Berlin, Germany, August 7-12, 2016. c?2016 Association for Computational LinguisticsImplicit Polarity and Implicit Aspect Recognition in Opinion MiningHuan-Yuan Chen and Hsin-Hsi ChenDepartment of Computer Science and Information EngineeringNational Taiwan University, Taipei, Taiwanr04922009@ntu.edu.tw; hhchen@ntu.edu.twAbstractThis paper deals with a double-implicit prob-lem in opinion mining and sentiment analysis.We aim at identifying aspects and polarities ofopinionated statements not consisting of opin-ion words and aspect terms.
As a case study,opinion words and aspect terms are first ex-tracted from Chinese hotel reviews, and thengrouped into positive (negative) clusters andaspect term clusters.
We observe that an im-plicit opinion and its neighbor explicit opiniontend to have the same aspect and polarity.
Un-der the observation, we construct an implicitopinions corpus annotated with aspect classlabels and polarity automatically.
Aspect andpolarity classifiers trained by using this cor-pus is used to recognize aspect and polarity ofimplicit opinions.1 IntroductionOpinions are classified into explicit and implicitones depending on the subjectivity and objectivity(Liu, 2012; Zhang and Liu, 2014).
It is more chal-lenging to detect implicit opinions than explicitones due to the lack of explicit opinion words inthe sentences.
Aspects refer to facets of the targetentities in opinions.
They are also categorized intoexplicit and implicit ones depending on the occur-rences of aspect terms.
Recognizing implicit as-pects in implicit opinions is much more challeng-ing because both opinion words and aspect termsare absent in opinionated statements.Implicit opinions often describe the situations atwhich persons concern in their reviews.
(S1) and(S2) are two examples selected from positive andnegative rating rows respectively in hotel reviews.They do not mention any explicit opinion wordsand aspect terms.
The situation of ?many restau-rants nearby?
infers the convenience for eating,while the situation of ?a lot of ants?
infers the dirt-iness of a room.
The implicit opinion describes notonly the situation at which customers feel, but alsoinfers the reason why they have such feelings.
Im-plicit opinions are positive in (S1) and negative in(S2), and the implied aspects are location andcleanness.
(S1) ????????
(There are many restau-rants nearby.
)(S2) ?????????
(There are a lot ofants in the room.
)The implicit opinions may be subjective in somecases.
For example, (S1) may be placed in negativerating row in a hotel review.
Its implicit interpreta-tion will become ?There are many restaurantsnearby, and thus the air pollution is severe and thesmell of the air is very bad.
?People may describe a situation first, and thenreveal their attitudes and judgments.
(S3) is an ex-ample.
The first clause (only ten meters to thesubway entrance) describes a situation, while thesecond clause (the location is good) is an explicitopinion.
In Chinese review, an explicit opinion canalso be specified before a situation description.
(S4)is an example.
In both cases, the polarity and theaspect of the situation are consistent with those ofthe explicit opinions.
(S3) ??????????????
(Onlyten meters to the subway entrance, good location.
)(S4) ?????????????????
(Location is good, within walking distance of threeMRTs around.
)This paper aims at extracting implicit opinionsand identifying their implicit aspects and polarity.We will extract opinions from Chinese hotel re-views, then transfer polarity and aspect from ex-plicit expressions to the corresponding implicitopinions, and train aspect and polarity classifiers.We evaluate the performance of polarity and as-pect recognition on implicit opinions.Almost all previous approaches identify implicitaspects in explicit opinions.
They extract opinionwords from opinionated sentences, regard them as20implicit aspect clues, and find aspects throughopinion word-aspect term mapping.
The lack ofopinion words in implicit opinions results in no in-dicators in mapping.
To the best of our knowledge,this paper is the first one to resolve a double-implicit problem in opinion mining and sentimentanalysis.This paper is organized as follows.
Section 2gives a survey on implicit aspect recognition inopinion mining and sentiment analysis.
Section 3constructs an implicit opinions corpus labelledwith aspect classes and polarity automatically.
Sec-tion 4 presents classifiers for implicit polarity andimplicit aspect recognition.
Section 5 shows anddiscusses the experimental results.2 Related WorkHu and Liu (2004) present the first feature-basedopinion summarization system.
They point out ex-plicit and implicit product features, and extract ex-plicit features by using association miner and prun-ing strategies.
The opinionated sentences alongwith their polarity are listed under individual prod-uct features.
Popescu and Etzioni (2005) introducean opinion extraction system OPINE.
OPINE ex-tracts explicit product features based on Point-wiseMutual Information.
This work does not discussthe implicit feature generation.
Liu et al (2005)present an association mining approach to extractboth explicit and implicit features in their opinionobserver, but the implicit features discussed occurexplicitly in an overt form, e.g., [MB] indicates aproduct feature <memory>.Su et al (2008) define an implicit feature as theproduct feature which does not occur explicitly,but can be inferred from the surrounding opinionword.
They propose a mutual reinforcement ap-proach to cluster product features and opinionwords simultaneously, and extract implicit featuresbased on opinion words.
In the subsequent work,different methodologies are proposed to identifythe association between opinion words and aspectterms (called also product features), thus implicitaspects are inferred from opinion word-aspect termmapping (Bagheri et al, 2013).Zhen et al (2011) propose a two-phase co-occurrence association rule mining approach.
Yu etal.
(2011) generate a review hierarchy based on as-pects.
Implicit aspect of a review can be deter-mined by the cosine similarity of the review vectorand the vector for each aspect node in the reviewhierarchy.
Zeng and Li (2013) regard identificationof implicit features as a classification problem, andconsider reviews for each clustered opinion-pair astraining set.
Wang et al (2013) employ five collo-cation methods including frequency, PMI, fre-quency?PMI, t-test and chi-square test to measurethe association between opinion words and aspectterms.Cruz et al (2014) manually annotate implicitaspects and implicit aspect indicators (IAI) on thecustomer review datasets in Hu and Liu (2004),and employ Conditional Random Fields to recog-nize IAI.
Poria et al (2014) identify implicit aspectclues (IACs) in a document.
Both approaches es-tablish IAI (IAC) and aspect mapping.Mukherjee and Liu (2012) propose two statisti-cal models to deal with aspect categorization prob-lem.
They use hotel reviews from tripadvisor.com,and point out categorizing aspects is a subjectivetask.
Total 9 major aspects based on commonsenseknowledge, including Dining, Staff, Maintenance,Check In, Cleanliness, Comfort, Amenities, Loca-tion and Value for Money, are considered.
Kim etal.
(2013) further analyze general aspects and spe-cific aspects, and discuss how aspect structure ishelpful.
Zhao et al (2015) present a fine-grainedcorpus for sentiment analysis.Our work is different from the previous ones intwo-fold: (1) opinion is implicit, so that no opinionwords can be used as clues; and (2) aspect is im-plicit, so that no aspect terms can be found.
The di-rect opinion word and aspect mapping is not feasi-ble in implicit polarity and implicit aspect recogni-tion.
We focus on the construction of an implicitopinions corpus for double-implicit recognition.The aspect categorization is not the major concern.3 Constructing Implicit Opinions CorpusThis section first defines the implicit opinions, col-lects a Chinese hotel dataset, identifies opinion andaspect clusters from the dataset, and constructs im-plicit opinion corpus labelled with aspect class andpolarity.3.1 Definitions of Implicit OpinionsA sentence in a review can be partitioned into sev-eral segments separated by punctuation marks.
The21following show four possible types of segmentsbased on the occurrences of opinion words and as-pect terms, where + and - denote occurrence andnon-occurrence.
Segments of types (T1) and (T2)contain explicit opinion words, while segments oftypes (T3) and (T4) contain no opinion words.They appear together with and without aspectterms.
(T1)  (+opinion word, +aspect term)e.g., ????
(location is good)(T2)  (+opinion word, -aspect term)e.g., ???
(very cheap)(T3)  (-opinion word, +aspect term)e.g., ????
(location)(T4)  (-opinion word,-aspect term)e.g., ????????????
(Justtwo minutes to Yau Ma Tei MRT Station)Segments of either type can not only appear in-dividually, but also can be combined with othertypes of segments to form a sentence.
Segments oftypes (T1) and (T2) are opinionated.
Segments oftype (T3) are opinionated implicitly when they ap-pear in positive/negative rating row.
Segments oftype (T4) can be opinionated or non-opinionated.
Itis interpreted as an opinionated segment clearlywhen it is placed in rating row individually.
(S5) is a sentence consisting of 5 segments oftypes T3, T2, T1, T4 and T3, respectively.
The 4thsegment, i.e., feeling a little like shanty towns, is adouble-implicit opinion.
Its polarity and aspect(negative and environment) can be inferred fromthe 3rd segment, i.e., the surrounding environmentis really bad.
(S5) [T3???????]?[T2??????]?
[T1 ?????????]?[T4????????]?
[T3 ??????]?
([T3 hotel in the alley]?
[T2 security is no problem]?
[T1 but the surround-ing environment is really bad]?
[T4 feeling a littlelike shanty towns]?
[T3 no hotels around])In this paper, we deal with opinionated segmentsof type (T4).
On the one hand, we extract pairs ofsegments of types T1-T4 or T4-T1 from a Chinesehotel review dataset.
The segments of type T4 willbe annotated with opinion words and aspect termsextracted from their paired segments of type T1.The segments of type T4 along with their annota-tions form a training corpus.
On the other hand, thetest segments of types (T4) will be labelled withpolarity and aspect by polarity and aspect classifi-ers.At first glance, we do not need to perform theclassification task on T4 segments since we can di-rectly use polarity and aspect of T1 segments.
Thescenario is just for test purpose because we do nothave large-scale manually-labelled data.
In the lat-ter experiments, we will also consider the cases ofT4 segments existing individually in rating rows.That will reflect the real situations.3.2 Extraction of Implicit OpinionsOpinion words and aspect terms are the indicatorsto define the four types (T1)-(T4).
As a case study,we collect a Chinese hotel review dataset frombooking.com.
It consists of 144,158 positive re-views and 113,844 negative reviews about 20,973hotels from 49 international cities.
Here only Chi-nese reviews are kept.
We use Stanford NLP toolsto segment, POS tag, and parse all the reviews.At first, we construct an opinion dictionary fromthis dataset.
Words of POS tags VA, VV, AD, andJJ are candidates of opinion words.
We adopt Chi-square test and point-wise mutual information tofilter out less confident words from the candidateset, respectively.
We examine the union of the re-maining words manually and construct an opiniondictionary consisting of 374 positive and 408 nega-tive opinion words.Then, we construct an aspect dictionary basedon opinion words.
A word meeting the followingfour conditions is regarded as an aspect term can-didate: (1) its POS is NN, (2) it occurs at least 100times, (3) it is accompanied with an opinion wordwithin the same segment, and (4) their dependencyis nsubj.
We examine 183 proposed candidatesmanually and construct an aspect dictionary con-sisting of 153 aspect terms.In an extreme case, a review does not containany opinion words and aspect terms.
It may be asingle segment or multiple segments of type T4.Reviews are listed under positive and negative rat-ing rows, so we know their polarity, but not aspect.Table 1 shows the statistics of such kinds of re-views in the hotel dataset.
Interestingly, 2.07% ofpositive reviews are pure T4, and 7.29% of nega-tive reviews are pure T4.
That demonstrates dou-ble-implicit is a practical issue and customers tendto express negative opinions implicitly.
The pure22single multiple total# pure T4 (positive reviews) 2,266 717 2,983# pure T4 (negative reviews) 5,847 2,451 8,298Table 1: Statistics of pure T4 reviews.T1 T2 T3 T4total 192,353 161,863 257,831 303,357ratio 21.01% 17.68% 28.17% 33.14%Table 2:  Statistics of segment types.T4 reviews set consisting of single segments onlyis called PT4S hereafter.Table 2 shows the statistics of segments of typesT1, T2, T3, and T4.
Only 21.01% of segments con-tain both opinion words and aspect terms, and33.14% of segments do not contain any opinionwords and aspect terms.
We further examine thetype combinations of two successive segments.There are 103 possible punctuation marks betweenany two segments, including common ones like??
?, ??
?, ??
?, and ?!
?, and some special oneslike ?~~~?.
To avoid misinterpretation of the spe-cial marks, we considers only those segment pairslinked by commas.
Moreover, to obtain an auto-matically labelled dataset, the ambiguous sequenceof segments, X-T4-Y, where X and Y of types T1,T2, or T3, are removed.
Total 31,136 T4-T1/T1-T4segment pairs remain.
They are used to derive animplicit opinions corpus for learning and testingpolarity classifier and aspect classifiers.
This dataset is called T41 hereafter.In most of the cases we observed, segment oftype T2 or T3 does not pass its aspect or opinion tonearby segments of type T4.
(S6) is an example ofa triple of segments of type T1-T4-T3, which in-troduces ambiguity between aspect and opinion as-signment.
The aspect of segment of type T1, i.e.,the equipment, competes with that of segment oftype T3, the toilet.
In this case, the safety depositbox, which is the undetected aspect of the segmentof type T4, and the toilet are two sub-aspects of theequipment.
The latter two clauses are supplemen-tary description of the first clause.
(S6) ?????????????????????
(The equipment is old, the safety depositbox is hard to use, and the toilet sometimes stuckswhile refilling.
)This work bases on the postulation ?
say, an im-plicit opinion and its neighbor explicit opiniontending to have the same aspect and polarity, toconstruct a training corpus automatically.
We ran-domly sampled 1% of pairs of segments of typeT1-T4 or T4-T1 in a training corpus (see Section 4)to verify whether our assumption holds.
In this set-up, we discard clauses that contain parsing errorsand those are too short to represent both aspectsand opinions.
The result is promising.
On average,70.46% of the pairs follow the observation.
In par-ticular, the pairs keep the property more often (i.e.,74.51%) when the polarity of T1 is negative.4 Double-Implicit Opinion AnalysisWe assign polarity and aspect of a T4-type seg-ment in T41 dataset based on the information fromits paired T1-type segment.
Negation in the T1-type segment will reverse the polarity.
To avoiddata sparseness, 153 aspect terms are partitionedinto 10 aspect classes based on common senseknowledge, including food, hotel, price, room, in-ternet, staff, services, facilities, neighborhood, andgeneral.
The criterion in the selection of the cate-gory of aspects is not the major concern in this pa-per.
For example, facilities and services may bemerged into the same aspect category.
The 31,136labelled T4-type segments in T41 dataset are di-vided into training and test sets consisting of23,352 and 7,784 segments, respectively.Figure 1 shows the segment length distributionof T41-train, T41-test, T41, and PT4S datasets.The length is measured by number of Chinesewords in a segment.
X-axis and Y-axis denotelength of segments and ratio, respectively.
Seg-ments in PT4S dataset are shorter than those inT41 dataset.
Segments of 2 and 3 words occupy48.61%.
Table 3 shows the polarity distribution inthese datasets.
Because T41 dataset is divided intoT41-train and T41-test datasets uniformly, theirpolarity distribution is the same, i.e., positive:Figure 1: Length distribution in experimental datasets.00.050.10.150.20.250.31 2 3 4 5 6 7 8 ?9T41-trainT41-testT41PT4S23T41 T41-train T41-test PT4Spositive 79.64% 79.63% 79.68% 27.93%negative 20.36% 20.37% 20.32% 72.07%Table 3:  Polarity distribution in experimental datasets.
(%) BOW linearW2VlinearBOWRBFW2VRBFW2VCNNT41-test (p) 78.55 73.67 81.54 79.76 85.04PT4S (p) 77.30 77.64 72.01 72.22 67.96MicroAvg 77.91 75.69 76.67 75.91 76.32T41-test (a) 43.25 41.50 46.35 46.13 55.90Table 4:  Accuracy of implicit polarity and aspect recognition.negative=4:1.
Comparatively, positive:negative=1:2.58 in PT4S dataset.
The two test sets bias to-ward different polarities.We employ T41-train dataset to train binary po-larity classifier and 10-way aspect classifiers, andtest on T41-test dataset.
We also explore T41 da-taset to train polarity classifier, and test on PT4Sdataset.
T41-testing evaluates both implicit polarityand implicit aspect recognition.
Note the groundtruth is generated automatically.
PT4S-testingevaluates implicit polarity only based on the hu-man-annotated ground truth.We consider bag of words (BOW) and wordvectors generated by word2vec (W2V) as features,where word vectors are pre-trained by using thepart-of-tagged Chinese sentences extracted fromthe ClueWeb09 dataset (CMU, 2009; Yu et al,2012).
Moreover, we adopt SVM with linear ker-nel and SVM with RBF kernel learning algorithmsin Scikit-Learn library (Pedregosa et al, 2011), andrun cross-validation multiple times on the trainingset to facilitate a grid search on hyperparameterswith F-measure as the metric to optimize.Besides, we also explore Convolutional NeuralNetworks (CNN) (Kim, 2014).
Table 4 summariz-es the accuracy of implicit polarity and implicit as-pect recognition, where (p) and (a) after datasetdenote polarity and aspect performance of that da-taset, respectively.
CNN achieves the best implicitpolarity and aspect recognition in T41-test dataset.However, its implicit polarity accuracy is de-creased to 67.96%.
It may be due to overfitting insmall amount of training data.
Different dropoutrates (Srivastava et al, 2014) can be explored.SVM with linear kernel (BOW) gets the best microaverage accuracy (77.91%) in implicit polarityrecognition.Figure 2 shows the accuracies of the implicit po-larity recognition on segments of different lengths.Figure 2: Accuracies of segments of different lengths.It is challenging to predict the implicit polarity andaspect for segments of very short length.
Figure 1depicts one-word segments occupy 5%-10%.
Oneword segment like ????
(Mong Kok) is ambigu-ous.
If we neglect such segments, the micro aver-age accuracy in implicit polarity recognition usingSVM with linear kernel (BOW) is increased to79.94%, and the accuracy in implicit aspect recog-nition (10-way classification) becomes 46.01%.5 Conclusion and Future WorkIn this paper, we address the double-implicit issuein opinion mining and sentiment analysis, and pro-pose a protocol to derive a labelled corpus for im-plicit polarity and implicit aspect analysis.
SVMwith linear kernel (BOW) is robust in implicit po-larity recognition.
Ten-way classification for im-plicit aspect recognition still has space to improve.This work bases on the aspect-and-polarity-transfer postulation to construct a training corpusautomatically.
We randomly sample T4 segmentsfrom T4-T1 or T1-T4 pairs and check them manu-ally.
We find that 70.46% of the pairs follow theobservation.
The experimental setup is reasonablefor evaluation with PT4S dataset because it is la-belled by users themselves.
To derive a more relia-ble training set, distinguishing if T4 is non-opinionated needs to be investigated further.Moreover, we neglect the cases T4-X (X-T4),where X is either T2 or T3, in the selection oftraining set.
It is also challenging when either opin-ion word or aspect term is absent from the cuesegment.
In this paper, we provide some case stud-ies of these scenarios, but how to utilize the partialinformation in implicit polarity and implicit aspectrecognition is a future work.24AcknowledgmentsThis research was partially supported by Ministryof Science and Technology, Taiwan, under grantMOST-102-2221-E-002-103-MY3.
We thank theanonymous reviewers for their constructive com-ments to revise this paper.ReferencesArjun Mukherjee and Bing Liu.
2012.
Aspect Extractionthrough Semi-Supervised Modeling, Proceedings ofthe 50th Annual Meeting of the Association for Com-putational Linguistics, pages 339?348.Ayoub Bagheria, Mohamad Saraeeb, and Franciska deJong.
2013.
Care More about Customers: Unsuper-vised Domain-independent Aspect Detection for Sen-timent Analysis of Customer Reviews, Knowledge-Based Systems, 52:201?213.CMU.
2009.
ClueWeb09, http://lemurproject.org/clue-web09.php/.Ivan Cruz, Alexander Gelbukh, and Grigori Sidorov.2014.
Implicit Aspect Indicator Extraction for As-pect-based Opinion Mining, International Journal ofComputational Linguistics and Applications,5(2):135-152.Minqing Hu and Bing Liu.
2004.
Mining and Summa-rizing Customer Reviews, Proceedings of the ACMSIGKDD International Conference on KnowledgeDiscovery and Data Mining, pages 168?177.Yoon Kim.
2014.
Convolutional Neural Networks forSentence Classification, Proceedings of the 2014Conference on Empirical Methods in Natural Lan-guage Processing (EMNLP), pages 1746?1751.Suin Kim, Jianwen Zhang, Zheng Chen, Alice Oh, andShixia Liu.
2013.
A Hierarchical Aspect-SentimentModel for Online Reviews, Proceedings of the Twen-ty-Seventh AAAI Conference on Artificial Intelli-gence, pages 526?533.Bing Liu.
2012.
Sentiment Analysis and Opinion Min-ing.
Morgan & Claypool Publishers.Bing Liu, Minqing Hu, and Junsheng Cheng.
2005.Opinion Observer: Analyzing and Comparing Opin-ions, Proceedings of the 14th International Confer-ence on World Wide Web, pages 1024?1025.Fabian Pedregosa, Gael Varoquaux, Alexandre Gram-fort, Vincent Michel, Bertrand Thirion, OlivierGrisel, Mathieu Blondel, Peter Prettenhofer, RonWeiss, Vincent Dubourg, Jake Vanderplas, AlexandrePassos, David Cournapeau, Matthieu Brucher, Mat-thieu Perrot, and Edouard Duchesnay.
2011.Scikitlearn: Machine learning in Python.
Journal ofMachine Learning Research, 12:2825?2830.Ana-Maria Popescu and Oren Etzioni.
2005.
ExtractingProduct Features and Opinions from Reviews, Pro-ceedings of Conference on Empirical Methods inNatural Language Processing, pages 3?28.Soujanya Poria, Erik Cambria, Lun-Wei Ku, Chen Guiand Alexander Gelbukh.
2014.
A Rule-Based Ap-proach to Aspect Extraction from Product Reviews,Proceedings of the Second Workshop on NaturalLanguage Processing for Social Media (SocialNLP),pages 28?37.Nitish Srivastava, Georey Hinton, Alex Krizhevsky, IlyaSutskever, and Ruslan Salakhutdinov.
2014.
Dropout:A Simple Way to Prevent Neural Networks fromOverfitting, Journal of Machine Learning Research,15, pages, 1929?1958.Qi Su, Xinying Xu, Honglei Guo, Zhili Guo, Xian Wu,Xiaoxun Zhang, Bin Swen, and Zhong Su.
2008.Hidden Sentiment Association in Chinese Web Opin-ion Mining, Proceedings of International Conferenceon World Wide Web, pages 959?968.Wei Wang, Hua Xu, and Wei Wan.
2013.
Implicit Fea-ture Identification via Hybrid Association Rule Min-ing, Expert Systems with Applications, 40(9): 3518?3531.Jianxing Yu, Zheng-Jun Zha, Meng Wang, Kai Wang,and Tat-Seng Chua.
2011.
Domain-Assisted ProductAspect Hierarchy Generation: Towards HierarchicalOrganization of Unstructured Consumer Reviews,Proceedings of the Conference on Empirical Methodsin Natural Language Processing, pages 140?150.Lingwei Zeng and Fang Li.
2013.
A Classification-Based Approach for Implicit Feature Identification,Proceedings of the China National Conference onComputational Linguistics, LNAI 8202, pages 190?202.Lei Zhang and Bing Liu.
2014.
Aspect and Entity Ex-traction for Opinion Mining, Data Mining andKnowledge Discovery for Big Data, Studies in BigData, 1, pages 1-40.Yanyan Zhao, Bing Qin, and Ting Liu.
2015.
Creating aFine-Grained Corpus for Chinese Sentiment Analy-sis, IEEE Intelligent Systems, 30(1):36?43.Chi-Hsin Yu, Yi-jie Tang, and Hsin-Hsi Chen.
2012.Development of a Web-Scale Chinese Word N-gramCorpus with Parts of Speech Information, Proceed-ings of 8th International Conference on LanguageResources and Evaluation, pages 320?324.Hai Zhen, Kuiyu Chang, and Jung-jae Kim.
2011.
Im-plicit Feature Identification via Co-occurrence Asso-ciation Rule Mining, Proceedings of 12th Interna-tional Conference on Computational Linguistics andIntelligent Text Processing, pages 393?404.25
