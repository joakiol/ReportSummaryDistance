Proceedings of the 3rd Workshop on Hybrid Approaches to Translation (HyTra) @ EACL 2014, pages 87?95,Gothenburg, Sweden, April 27, 2014. c?2014 Association for Computational LinguisticsExtracting Multiword Translationsfrom Aligned Comparable DocumentsReinhard Rapp Serge SharoffAix-Marseille Universit?, Laboratoired'Informatique FondamentaleF-13288 Marseille, FranceUniversity of LeedsCentre for Translation StudiesLeeds, LS2 9JT, UKreinhardrapp@gmx.de S.Sharoff@leeds.ac.ukAbstractMost previous attempts to identify trans-lations of multiword expressions usingcomparable corpora relied on dictionariesof single words.
The translation of a mul-tiword was then constructed from thetranslations of its components.
In con-trast, in this work we try to determine thetranslation of a multiword unit by analyz-ing its contextual behaviour in alignedcomparable documents, thereby not pre-supposing any given dictionary.
Whereaswith this method translation results forsingle words are rather good, the resultsfor multiword units are considerablyworse.
This is an indication that the typeof multiword expressions considered hereis too infrequent to provide a sufficientamount of contextual information.
Thusindirectly it is confirmed that it shouldmake sense to look at the contextual be-haviour of the components of a multi-word expression individually, and tocombine the results.1 IntroductionThe task of identifying word translations fromcomparable text has received considerable atten-tion.
Some early papers include Fung (1995) andRapp (1995).
Fung (1995) utilized a context het-erogeneity measure, thereby assuming that wordswith productive context in one language translateto words with productive context in another lan-guage, and words with rigid context translate intowords with rigid context.
In contrast, the under-lying assumption in Rapp (1995) was that wordswhich are translations of each other show similarco-occurrence patterns across languages.
Thisassumption is effectively an extension of Harris'(1954) distributional hypotheses to the multilin-gual case.This work was further elaborated in some bynow classical papers, such as Fung & Yee (1998)and Rapp (1999).
Based on these papers, thestandard approach is to start from a dictionary ofseed words, and to assume that the words occur-ring in the context of a source language wordhave similar meanings as the words occurring inthe context of its target language translation.There have been suggestions to eliminate theneed for the seed dictionary.
However, most at-tempts, such as Rapp (1995), Diab & Finch(2000) and Haghighi et al.
(2008) did not work toan extent that the results would be useful forpractical purposes.
Only recently a more pro-mising approach has been investigated: Schafer& Yarowsky (2002), Hassan & Mihalcea (2009),Prochasson & Fung (2011) and Rapp et al.
(2012) look at aligned comparable documentsand deal with them in analogy to the treatment ofaligned parallel sentences, i.e.
effectively doing aword alignment in a very noisy environment.This approach has been rather successful and itwas possible to improve on previous results.
Thisis therefore the approach which we will pursue inthe current paper.However, in contrast to the above mentionedpapers the focus of our work is on multiwordexpressions, and we will compare the perform-ance of our algorithm when applied to multiwordexpressions and when applied to single words.There has been some previous work on identi-fying the translations of multiword units usingcomparable corpora, such as Robitaille et al.
(2006), Babych et al.
(2007), Daille & Morin(2012); Delpech et al.
(2012).
However, none ofthis work utilizes aligned comparable documents,and the underlying assumption is that the transla-tion of a multiword unit can be determined bylooking at its components individually, and bymerging the results.In contrast, we try to explore whether thetranslation of a multiword unit can be determinedsolely by looking at its contextual behavior, i.e.whether it is possible to also apply the standardapproach as successfully used for single words.The underlying fundamental question is whetherthe meaning of a multiword unit is determined by87the contextual behavior of the full unit, or by thecontextual behavior of its components (or by amix of both).
But multiword expressions are ofcomplex nature, as expressed e.g.
by Moon(1998): "there is no unified phenomenon to de-scribe but rather a complex of features that inter-act in various, often untidy, ways and represent abroad continuum between non-compositional (oridiomatic) and compositional groups of words.
"The current paper is an attempt to systematicallyapproach one aspect of this complexity.2 ApproachOur approach is based on the usual assumptionthat there is a correlation between the patterns ofword-co-occurrence across languages.
However,instead of presupposing a bilingual dictionary itonly requires pre-aligned comparable documents,i.e.
small or medium sized documents alignedacross languages which are known to deal withsimilar topics.
This could be, for example, news-paper articles, scientific papers, contributions todiscussion groups, or encyclopaedic articles.
AsWikipedia is a large resource and readily avail-able for many languages, we decided to base ourstudy on this encyclopaedia.
The Wikipediashave the so-called interlanguage links which aremanually inserted by the authors and connectarticles referring to the same headword in differ-ent languages.Given that each Wikipedia community con-tributes in its own language, only occasionally anarticle connected in this way will be an exacttranslation of a foreign language article, and inmost cases the contents will be rather different.On the positive side, the link structure of the in-terlanguage links tends to be quite dense.
Forexample, of the 1,114,696 German Wikipediaarticles, 603,437 have a link to the correspondingEnglish Wikipedia article.2.1 Pre-processing and MWE extractionWe used the same versions of Wikipedia as inRapp et al.
(2012) and used the same processing.After download, each Wikipedia was minimallyprocessed to extract the plain text contents of thearticles.
In this process all templates, e.g.
'infoboxes', as well as tables were removed, andwe kept only the webpages with more than 500characters of running text (including whitespace).
Linguistic processing steps included to-kenisation, tagging and lemmatisation using thedefault UTF-8 versions of the respective Tree-Tagger resources (Schmid, 1994).From the pre-processed English and GermanWikipedia, we extracted the multiword expres-sions using two simple principles, a negativePOS filter and a containment filter.
The negativePOS filter operates in a rule-based fashion on thecomplete list of n-grams by removing the un-likely candidates according to a set of con-straints, such as the presence of determiners orprepositions at the edges of expressions, see asimilar method used by (Justeson & Katz, 1995).With some further extensions this was also usedto produce the multiword lists for the dictionaryof translation equivalents (Babych et al., 2007).We did not use positive shallow filters.
Thesewould need to capture the relatively complexstructure of the noun, verb and prepositionalphrases, while avoiding noise.
This can oftenlead to a lack of recall when more complex con-structions cannot be captured.
In contrast, nega-tive shallow filters simply avoid obvious noise,while passing other multiword expressions(MWEs) through, which are very often legiti-mate syntactic constructions in a language inquestion.
For example, the following Englishfilters1 rejected personal pronouns (PP) and con-junctions (CC) at the edges of expressions (usingthe Penn Treebank tagset as implemented byTreetagger):^[^ ]+~~PP |~~PP$^[^ ]+~~CC |~~CC$Similarly, any MWE candidates including propernouns (NP) and numerals (CD) were discarded:~~NP~~CDIn the end, this helps in improving the recall ratewhile using a relatively small number of pat-terns: 18 patterns were used for English, 11 forGerman.The containment filter further rejects MWEsby removing those that regularly occur as a partof a longer acceptable MWE.
For example,graphical user is an acceptable expression pass-ing through the POS filter, but it is rejected bythe containment filter since the overwhelmingmajority of its uses are in the containing MWEgraphical user interface (1507 vs 1304 uses inWikipedia, since MWEs are still possible, e.g.,graphical user environment).1We use here the standard notation for regular ex-pressions as implemented in Perl (Friedl, 2002).
Forexample, '^' means 'beginning of line' and '$' means'end of line'.88English keyterms for 'Airbus 320 family'Score f Keyterm34.88 4 final_JJ assembly_NN31.22 3 firm_NN order_NN30.73 3 series_NN aircraft_NN29.07 4 flight_NN control_NN27.38 3 wing_NN area_NN23.26 3 final_JJ approach_NN22.19 2 lose_VV life_NN20.63 6 passenger_NN and_CC crew_NN17.54 2 first_JJ derivative_NN17.34 2 fly-by-wire_NN flight_NN control_NN16.63 3 flight_NN deck_NN16.41 2 crew_NN die_VV15.08 2 pilot_NN error_NN14.98 2 passenger_NN capacity_NN14.38 2 turbofan_NN engine_NN14.03 2 development_NN cost_NN12.30 2 maiden_JJ flight_NN11.54 2 direct_JJ competition_NN10.75 2 overall_JJ length_NN10.39 2 overrun_VV the_DT runway_NN9.54 2 flight_NN control_NN system_NN9.31 2 fuel_NN consumption_NN8.63 2 roll_VV out_RP7.86 3 crew_NN member_NN7.54 2 crew_NN on_IN board_NN7.33 2 bad_JJ weather_NN6.63 2 landing_NN gear_NNGerman keyterms for 'Airbus-A320-Familie'Score f Keyterm155.25 20 Triebwerk62.88 4 Fly-by-Wire-System59.76 8 Erstflug57.67 8 Absturz43.79 4 Endmontage43.70 4 Hauptfahrwerk41.77 4 Tragfl?gel36.52 8 Unfall35.90 6 Ungl?ck33.25 3 Abfluggewicht33.10 5 Auslieferung30.01 3 Treibstoffverbrauch29.00 2 Triebwerkstyp28.51 2 Zwillingsreifen18.20 2 Absturz_NN verursachen_VV16.28 3 Passagier_NN Platz_NN16.23 2 Triebwerk_NN antreiben_VV13.41 2 Steuerung_NN d_AR Flugzeug_NN12.52 2 Absturz_NN f?hren_VV11.68 2 Rumpf_NN befinden_VV8.59 2 Insasse_NN ums_AP Leben_NN8.55 2 Zeitpunkt_NN d_AR Ungl?ck_NNTable 1.
English and German keyterms for 'Airbus 320 fam-ily' (lists truncated).
Score = log-likelihood score; f = occur-rence frequency of keyterm; NN = noun; VV = verb; AR =article; AP = article+preposition; JJ = adjective; CC = con-junction; RP = preposition.2.2 Keyterm extractionAs the aligned English and German Wikipediadocuments are typically not translations of eachother, we cannot apply the usual procedures andtools as available for parallel texts (e.g.
the Gale& Church sentence aligner and the Giza++ wordalignment tool).
Instead we conduct a two stepprocedure:1.
We first extract salient terms (single word ormultiword) from each of the documents.2.
We then align these terms across languagesusing an approach inspired by a connectionist(Rumelhart & McClelland, 1987) Winner-Takes-It-All Network.
The respective algo-rithm is called WINTIAN and is described inRapp et al.
(2012) and in Rapp (1996).For term extraction, the occurrence frequency ofa term in a particular document is compared toits average occurrence frequency in all Wikipe-dia documents, whereby a high discrepancy indi-cates a strong keyness.
Following Rayson &Garside (2000), we use the log-likelihood scoreto measure keyness, since it has been shown tobe robust to small numbers of instances.
Thisrobustness is important as many Wikipedia arti-cles are rather short.This procedure leads to multiword keyterms asexemplified in Table 1 for the Wikipedia entryAirbus A320 family.
Because of compounding inGerman, many single-word German expressionsare translated into multiword expressions in Eng-lish.
So we chose to include single-word expres-sions into the German candidate list for align-ment with English multiwords.One of the problems in obtaining multiwordkeyterms from the Wikipedia articles is relativedata sparseness.
Usually, the frequency of anindividual multiword expression within a Wiki-pedia article is between 2 and 4.
Therefore wehad to use a less conservative threshold of 6.63(1% significance level) rather than the morestandard 15.13 (0.01% significance level) for thelog-likelihood score (see Rayson & Garside,2000, and http://ucrel.
lancs.ac.uk/llwizard.html).2.3 Term alignmentThe WINTIAN algorithm is used for establishingterm alignments across languages.
As a moredetailed technical description is given in Rapp etal.
(2012) and in Rapp (1996), we only brieflydescribe this algorithm here, thereby focusing onthe neural network analogy.
The algorithm canbe considered as an artificial neural networkwhere the nodes are all English and German89terms occurring in the keyterm lists.
Each Eng-lish term has connections to all German terms.The connections are all initialized with values ofone when the algorithm is started, but will serveas a measure of the translation probabilities afterthe completion of the algorithm.
One after theother, the network is fed with the pairs of corre-sponding keyterm lists.
Each German term acti-vates the corresponding German node with anactivity of one.
This activity is then propagatedto all English terms occurring in the correspond-ing list of keyterms.
The distribution of the activ-ity is not equal, but in proportion to the connect-ing weights.
This unequal distribution has noeffect at the beginning when all weights are one,but later on leads to rapid activity increases forpairs of terms which often occur in correspond-ing keyterm lists.
The assumption is that theseare translations of each other.
Using Hebbianlearning (Rumelhart & McClelland, 1987) theactivity changes are stored in the connections.We use a heuristic to avoid the effect that fre-quent keyterms dominate the network: Whenmore than 50 of the connections to a particularEnglish node have weights higher than one, theweakest 20 of them are reset to one.
This wayonly translations which are frequently confirmedcan build up high weights.It turned out that the algorithm shows a robustbehaviour in practice, which is important as thecorresponding keyterm lists tend to be very noisyand, especially for multiword expressions, inmany cases may contain hardly any terms thatare actually translations of each other.
Reasonsare that corresponding Wikipedia articles are of-ten written from different perspectives, that thevariation in length can be considerable acrosslanguages, and that multiword expressions tendto show more variability with regard to theirtranslations than single words.3 Results and evaluation3.1 Results for single wordsIn this subsection we report on our previous re-sults for single words (Rapp et al., 2012) as theseserve as a baseline for our new results concern-ing multiword units.The WINTIAN algorithm requires as inputvocabularies of the source and the target lan-guage.
For both English and German, we con-structed these as follows: Based on the keywordlists for the respective Wikipedia, we counted thenumber of occurrences of each keyword, andthen applied a threshold of five, i.e.
all keywordswith a lower frequency were eliminated.
The rea-soning behind this is that rare keywords are ofnot much use due to data sparseness.
This re-sulted in a vocabulary size of 133,806 for Eng-lish, and of 144,251 for German.Using the WINTIAN algorithm, the Englishtranslations for all 144,251 words occurring inthe German vocabulary were computed.
Table 2shows the results for the German word Stra?e(which means street).For a quantitative evaluation we used theML1000 test set comprising 1000 English-German translations (see Rapp et al., 2012).
Weverified in how many cases our algorithm hadassigned the expected translation (as provided bythe gold standard) the top rank among all133,806 translation candidates.
(Candidates areall words occurring in the English vocabulary.
)This was the case for 381 of the 1000 items,which gives us an accuracy of 38.1%.
Let usmention that this result refers to exact matcheswith the word equations in the gold standard.
Asin reality due to word ambiguity other transla-tions might also be acceptable (e.g.
for Stra?enot only street but also road would be accept-able), these figures are conservative and can beseen as a lower bound of the actual performance.GIVEN GERMANWORD Stra?eEXPECTEDTRANSLATION streetLL-SCORE TRANSLATION1 215.3 road2 148.2 street3 66.0 traffic4 46.0 Road5 42.6 route6 34.6 buildingTable 2.
Computed translations for Stra?e.3.2 Results for multiword expressionsIn analogy to the procedure for single words, forthe WINTIAN algorithm we also needed to de-fine English and German vocabularies of multi-word terms.
For English, we selected all multi-word terms which occurred at least three times inthe lists of English key terms, and for Germanthose which occurred at least four times in thelists of German key terms.
This resulted in simi-lar sized vocabularies of 114,796 terms for Eng-lish, and 131,170 for German.
Note that thethreshold for German had to be selected highernot because German has more inflectional vari-ants (which does not matter as we are working90with lemmatized data), but because - other thanthe English - the German vocabulary also in-cludes unigrams.
The reason for this is that Ger-man is highly compositional, so that Englishmultiword units are often translated by Germanunigrams.Using the WINTIAN algorithm, the Englishtranslations for all 131,170 words occurring inthe German multiword vocabulary were com-puted, and in another run the German translationsfor all 114,796 English words.
Table 3 showssome sample results.For a quantitative evaluation, we did not havea gold standard at hand.
As multiword expres-sions show a high degree of variability with re-gard to their translations, so that it is hard tocome up with all possibilities, we first decidednot to construct a gold standard, but instead did amanual evaluation.
For this purpose, we ran-domly selected 100 of the German multiwordexpressions with an occurrence frequency abovenine, and verified their computed translations(i.e.
the top ranked item for each) manually.
Wedistinguished three categories: 1) Acceptabletranslation; 2) Associatively related to an accept-able translation; 3) Unrelated to an acceptabletranslation.English ?
Germanhusband_NN and_CC wife_NNRank Aktivity Translation1 2.98 Eheleute2 1.09 Voraussetzung3 1.08 Kirchenrecht4 0.76 Trennung5 0.35 Mann6 0.24 Kirche7 0.08 Mischehe8 0.08 DiakonGerman ?
EnglishEheleuteRank Aktivity Translation1 3.01 husband_NN_and_CC_wife_NN2 1.26 married_JJ_couple_NN3 1.02 civil_JJ_law_NN4 1.02 equitable_JJ_distribution_NN5 1.02 community_NN_property_NN6 0.52 law_NN_jurisdiction_NN7 0.05 racing_NN_history_NN8 0.05 great_JJ_female_JJTable 3.
Sample results for translation directions EN ?
DEand DE ?
EN.We also did the same computation for the reverselanguage direction, i.e.
for English to German.The results are listed in Table 4.
These resultsindicate that our procedure, although currentlystate of the art for single words, does not workwell for multiword units.
We investigated thedata and located the following problems:?
The problem of data sparseness is, on average,considerably more severe for multiword ex-pressions than it is for single words.?
Although the English and the German vocabu-lary each contain more than 100,000 items,their overlap is still limited.
The reason is thatthe number of possible multiword units is veryhigh, far higher than the number of words in alanguage.?
We considered only multiword units up tolength three, but in some cases this may notsuffice for an acceptable translation.?
In the aligned keyterm lists, only rarely correcttranslations of the source language terms oc-cur.
Apparently the reason is the high variabil-ity of multiword translations.Hereby he last point seems to have a particularlysevere negative effect on translation quality.However, all of these findings are of fundamen-tal nature and contribute to the insight that atleast for our set of multiword expressions com-positionality seems to be more important thancontextuality.German ?
EnglishJudgment Num-berExample taken from actualdataAcceptable 5 Jugendherberge ?youth_NN hostel_NNAssociation 38 Maischeg?rung ?oak_NN barrel_NNUnacceptable 57 Stachelbeere ?horror_NN film_NNEnglish ?
GermanJudgment Num-berExample taken from actualdataAcceptable 6 amino_NN acid_NN ?Aminos?ureAssociation 52 iron_NN mine_NN ?
Ei-senerzUnacceptable 42 kill_VV more_JJ ?
Welt-meistertitel_NN im_APSchwergewicht_NNTable 4.
Quantitative results involving MWEs.913.3 Large scale evaluationAs a manual evaluation like the one describedabove is time consuming and subjective, wethought about how we could efficiently come upwith a gold standard for multiword expressionswith the aim of conducting a large scale auto-matic evaluation.
We had the idea to determinethe correspondences between our English andGerman MWEs via translation information asextracted from a word-aligned parallel corpus.Such data we had readily at hand from a pre-vious project called COMTRANS.
During thisproject we had constructed a large bilingual dic-tionary of bigrams, i.e.
of pairs of adjacent wordsin the source language.
For constructing the dic-tionary, we word-aligned the English and Ger-man parts of the Europarl corpus.
For this pur-pose, using Moses default settings, we combinedtwo symmetric runs of Giza++, which considera-bly improves alignment quality.
Then we deter-mined and extracted for each English bigram theGerman word or word sequence which had beenused for its translation.
Discontinuities of one orseveral word positions were allowed and wereindicated by the wildcard ?*?.
As the above me-thod for word alignment produces many unjusti-fied empty assignments (i.e.
assignments where asource language word pair is erroneously as-sumed to have no equivalent in the target lan-guage sentence), so that the majority of these isincorrect, all empty assignments were removedfrom the dictionary.In the dictionary, for each source languageword pair its absolute frequency and the absoluteand relative frequencies of its translation(s) aregiven.
To filter out spurious assignments, thresh-olds of 2 for the absolute and 10% for the rela-tive frequency of a translation were used.
Theresulting dictionary is available online.2  Table 5shows a small extract of the altogether 371,590dictionary entries.
Alternatively, we could havestarted from a Moses phrase table, but it was eas-ier for us to use our own data.Although the quality of our bigram dictionaryseems reasonably good, it contains a lot of itemswhich are not really interesting multiword ex-pressions (e.g.
arbitrary word sequences such ascredible if or the discontinuous word sequenceson the target language side).
For this reason wefiltered the dictionary using the lists of Wikipe-2http://www.ftsk.uni-mainz.de/user/rapp/comtrans/There click on "Dictionaries of word pairs" and thendownload "English - German".dia-derived multiword expressions as describedin section 2.1.
These contained 418,627 items forEnglish and 1,212,341 candidate items for Ger-man (the latter included unigram compounds).That is, in the dictionary those items were re-moved where either the English side did notmatch any of the English MWEs, or where theGerman side did not match any of the Germancandidates.This intersection resulted in a reduction of ourbigram dictionary from 371,590 items to 137,701items.
Table 6 shows the results after filtering theitems listed in Table 5.
Note that occasionallyreasonable MWEs are eliminated if they happennot to occur in Wikipedia, or if the algorithm forextracting the MWEs does not identify them.The reduced dictionary we considered as anappropriate gold standard for the automatic eval-uation of our system.ENGLISH BIGRAM GERMAN TRANSLATIONcredible if  dann glaubw?rdig * wenncredible if  glaubhaft * wenncredible if  glaubw?rdig * wenncredible in  in * Glaubw?rdigkeitcredible in  in * glaubw?rdigcredible investigation  glaubw?rdige Untersuchungcredible labelling  glaubw?rdige Kennzeichnungcredible manner  glaubw?rdigcredible military  glaubw?rdige milit?rischecredible military  glaubw?rdigen milit?rischencredible only  nur dann glaubw?rdigcredible partner  glaubw?rdiger Partnercredible policy  Politik * glaubw?rdigcredible policy  glaubw?rdige Politikcredible reports  glaubw?rdige Berichtecredible response  glaubw?rdige Antwortcredible solution  glaubw?rdige L?sungcredible system  glaubw?rdiges Systemcredible threat  glaubhafte Androhungcredible to  f?r * glaubw?rdigcredible to  glaubw?rdigTable 5.
Extract from the COMTRANS bigram dictionary.ENGLISH BIGRAM GERMAN TRANSLATIONcredible investigation glaubw?rdige Untersuchungcredible only nur dann glaubw?rdigcredible policy glaubw?rdige Politikcredible response glaubw?rdige Antwortcredible solution glaubw?rdige L?sungcredible system glaubw?rdiges Systemcredible threat glaubhafte Androhungcredible to glaubw?rdigTable 6.
Extract from the bigram dictionary after filtering.92As in section 3.2, the next step was to applythe keyword extraction algorithm to the Englishand the German Wikipedia documents.
Herebyonly terms occurring in the gold standard dic-tionary were taken into account.
But it turned outthat, when using the same log-likelihood thresh-old as in section 3.2, only few keyterms wereassigned: on average less than one per document.This had already been a problem in 3.2, but itwas now considerably more severe as this timethe MWE lists had been filtered, and as the filter-ing had been on the basis of another type of cor-pus (Europarl rather than Wikipedia).This is why, after some preliminary experi-ments with various thresholds, we finally de-cided to disable the log-likelihood threshold.
In-stead, on the English side, all keyterms from thegold standard were used if they occurred at leastonce in the respective Wikipedia document.
Onthe German side, as here we had many unigramcompounds which tend to be more stable andtherefore more repetitive than MWEs, we usedthe keyterms if the occurred at least twice.
Thisway for most documents we obtained at least afew keyterms.When running the WINTIAN algorithm on theparallel keyword lists, in some cases reasonableresults were obtained.
For example, for the direc-tion English to German, the system translatesinformation society with Informationsgesell-schaft, and education policy with Bildungs-politik.
As WINTIAN is symmetric and canlikewise produce a dictionary in the opposite di-rection, we also generated the results for Germanto English.
Here, among the good examples, areTelekommunikationsmarkt, which is translated astelecommunications market, and Werbekam-pagne, which is translated as  advertising cam-paign.
However, these are selected examplesshowing that the algorithm works in principle.Of more interest is the quantitative evaluationwhich is based on thousands of test words anduses the gold standard dictionary.
For English toGerman we obtained an accuracy of 0.77% ifonly the top ranked word is taken into account,i.e.
if this word matches the expected translation.This improves to 1.6% if it suffices that the ex-pected translation is ranked among the top tenwords.
The respective figures for German toEnglish are 1.41% and 2.04%.The finding that German to English performsbetter can be explained by the fact that other thanEnglish German is a highly inflectional lan-guage.
That is, when generating translations it ismore likely for German that an inflectional vari-ant not matching the gold standard translation isranked first, thus adversely affecting perform-ance.A question more difficult to answer is why theresults based on the gold standard are considera-bly worse than the ones reported in section 3.2which were based on human judgment.
We seethe following reasons:?
The evaluation in section 3.2 used only asmall sample so might be not very reliable.Also, other than here, it considered onlysource language words with frequenciesabove nine.?
Unlike the candidate expressions, the goldstandard data is not lemmatized on the targetlanguage side.?
The hard string matching used for the gold-standard-based evaluation does not allow forinflectional variants.?
The gold-standard-based evaluation usedterms resulting from the intersection of termlists based on Wikipedia and Europarl.
It isclear that this led to a reduction of averageterm frequency (if measured on the basis ofWikipedia), thus increasing the problem ofdata sparseness.?
As for the same reason the log-likelihoodthreshold had to be abandoned, on averageless salient terms had to be used.
This islikely to additionally reduce accuracy.?
For many terms the gold standard lists sev-eral possible translations.
In the current im-plementation of the evaluation algorithmonly one of them is counted as correct.
3However, in the human evaluation any rea-sonable translation was accepted.?
Some reasonable MWE candidates extractedfrom Wikipedia are not present in the goldstandard, for example credible evidence,credible source, and credible witness are notfrequent enough in Europarl to be selectedfor alignment.We should perhaps mention that it would be pos-sible to come up with better looking accuraciesby presenting results for selected subsets of thesource language terms.
For example, one couldconcentrate on terms with particularly good cov-3This can be justified because an optimal algorithmshould provide all possible translations of a term.
Ifonly some translations are provided, only partialcredit should be given.
But this is likely to averageout over large numbers, so the simple version seemsacceptable.93erage.
Another possibility would be to considerMWEs consisting of nouns only.
This we actu-ally did by limiting source and target languagevocabulary (of MWEs) to compound nouns.
Theresults were as follows:English to German (top 1):  1.81%English to German (top 10):  3.75%German to English (top 1):  2.03%German to English (top 10):  3.16%As can be seen, these results look somewhat bet-ter.
But this is only for the reason that translatingcompound nouns appears to be a comparativelyeasier task on average.4 Conclusions and future workWe have presented a method for identifying termtranslations using aligned comparable docu-ments.
Although it is based on a knowledge poorapproach and does not presuppose a seed lexi-con, it delivers competitive results for singlewords.A disadvantage of our method is that it pre-supposes that the alignments of the comparabledocuments are known.
On the other hand, thereare methods for finding such alignments auto-matically not only in special cases such asWikipedia and newspaper texts, but also in thecase of unstructured texts (although these meth-ods may require a seed lexicon).Concerning the question from the introduc-tion, namely whether the translation (and conse-quently also the meaning) of a multiword unit isdetermined compositionally or contextually, ouranswer is as follows: For the type of multiwordunits we were investigating, namely automati-cally extracted collocations, our results indicatethat looking at their contextual behavior usuallydoes not suffice.
The reasons seem to be thattheir contextual behavior shows a high degree ofvariability, that their translations tend to be lesssalient than those of single words, and that theproblem of data sparseness is considerably moresevere.It must be seen, however, that there are manytypes of multiword expressions, such as idioms,metaphorical expressions, named entities, fixedphrases, noun compounds, compound verbs,compound adjectives, and so on, so that our re-sults are not automatically applicable to all ofthem.
Therefore, in future work we intend tocompare the behavior of different types of mul-tiword expressions (e.g.
multiword named enti-ties and short phrases such as those used inphrase-based machine translations) and to quan-tify in how far their behavior is compositional orcontextual.AcknowledgmentThis research was supported by a Marie CurieIntra European Fellowship within the 7th Euro-pean Community Framework Programme.ReferencesBabych, B., Sharoff, S., Hartley, A., and Mudraya, O.(2007).
Assisting Translators in Indirect LexicalTransfer.
Proceedings of the 45th Annual Meetingof the Association for Computational LinguisticsACL 2007, Prague, Czech Republic.Daille, B.; Morin, E. (2012).
Revising the composi-tional method for terminology acquisition fromcomparable corpora.
Proceedings of Coling 2012,Mumbai.Delpech, E.; Daille, B.; Morin, E., Lemaire, C.(2012).
Extraction of domain-specific bilinguallexicon from comparable corpora: compositionaltranslation and ranking.
Proceedings of Coling2012, Mumbai.Diab, M., Finch, S. (2000): A statistical wordleveltranslation model for comparable corpora.
In: Pro-ceedings of the Conference on Content-Based Mul-timedia Information Access (RIAO).Friedl, J.
(2002).
Mastering Regular Expressions.O'Reilly.Fung, P. (1995).
Compiling bilingual lexicon entriesfrom a non-parallel English-Chinese corpus.
In:Proceedings of the  Third Annual Workshop on Ve-ry Large Corpora, Boston, Massachusetts.
173-183.Fung, P.; Yee, L. Y.
(1998).
An IR approach fortranslating new words from nonparallel, compara-ble texts.
Proceedings of  COLING/ACL 1998,Montreal, Canada.
414-420.Haghighi, A., Liang, P., Berg-Kirkpatrick, T., Klein,D.
(2008): Learning bilingual lexicons from mono-lingual corpora.
In: Proceedings of ACL-HLT2008, Columbus, Ohio.
771-779.Harris, Z.S.
(1954).
Distributional structure.
Word,10(23), 146?162.Hassan, S., Mihalcea, R. (2009): Cross-lingual seman-tic relatedness using encyclopedic knowledge.
In:Proceedings of EMNLP.Justeson, J.S.
; Katz, S.M.
(1995).
Techninal terminol-ogy: some linguistic properties and an algorithm foridentification in text.
Natural Language  Engineer-ing, 1(1): 9?27.Moon, R.E.
1998.
Fixed Expressions and Idioms inEnglish: A Corpus-based Approach.
Oxford: Clar-endon Press.94Prochasson, E., Fung, P. (2011).
Rare word transla-tion extraction from aligned comparable docu-ments.
In: Proceedings of ACL-HLT.
Portland .Rapp, R. (1995).
Identifying word translations in non-parallel texts.
In: Proceedings of the 33rd AnnualMeeting of the ACL.
Cambridge, MA, 320-322.Rapp, R. (1996).
Die Berechnung von Assoziationen.Hildesheim: Olms.Rapp, R. (1999).
Automatic identification of wordtranslations from unrelated English and Germancorpora.
Proceedings of the 37th Annual Meeting ofthe Association for Computational Linguistics, Col-lege Park, Maryland.
519?526.Rapp, R., Sharoff,  S., Babych, B.
(2012).
Identifyingword translations from comparable documentswithout a seed lexicon.
In: Proceedings of the 8thLanguage Resources and Evaluation Conference,LREC 2012, Istanbul.Rayson, P.; Garside, R. (2000).
Comparing corporausing frequency profiling.
Proceedings of theWorkshop on Comparing Corpora (WCC '00 ), Vol-ume 9, 1?6.Robitaille, X., Sasaki, Y., Tonoike, M., Sato, S., Utsu-ro, T. (2006).
Compiling French-Japanese termi-nologies from the web.
In: Proceedings of the 11thConference of EACL, Trento, Italy, 225-232.Rumelhart, D.E.
; McClelland, J.L.
(1987).
ParallelDistributed Processing.
Explorations in the Micro-structure of Cognition.
Volume 1: Foundations.MIT Press.Schafer, C., Yarowsky, D (2002).
: Inducing transla-tion lexicons via diverse similarity measures andbridge languages.
In: Proceedings of CoNLL.Schmid, H. (1994).
Probabilistic part-of-speech tag-ging using decision trees.
International Conferenceon New Methods in Language Processing, 44?49.95
