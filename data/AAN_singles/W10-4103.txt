Classical Chinese Sentence SegmentationHen-Hsen Huang?, Chuen-Tsai Sun?
and Hsin-Hsi Chen?
?Department of Computer Science and Information Engineering, National Taiwan University, Taipei, Taiwan?Department of Computer Science, National Chiao Tung University, Hsinchu, Taiwanhhhuang@nlg.csie.ntu.edu.tw ctsun@cis.nctu.edu.tw hhchen@csie.ntu.edu.twAbstractSentence segmentation is a fundamentalissue in Classical Chinese languageprocessing.
To facilitate reading andprocessing of the raw Classical Chinesedata, we propose a statistical method tosplit unstructured Classical Chinese textinto smaller pieces such as sentences andclauses.
The segmenter based on theconditional random field (CRF) model istested under different tagging schemesand various features including n-gram,jump, word class, and phonetic informa-tion.
We evaluated our method on fourdatasets from several eras (i.e., from the5th century BCE to the 19th century).Our CRF segmenter achieves an F-scoreof 83.34% and can be applied on a varie-ty of data from different eras.1 IntroductionChinese word segmentation is a well-known andwidely studied problem in Chinese languageprocessing.
In Classical Chinese processing, sen-tence segmentation is an even more vexing issue.Unlike English and other western languages,there is no delimiter marking the end of the wordin Chinese.
Moreover, not only is there a lack ofdelimiters between the words, almost all pre-20th century Chinese is written without anypunctuation marks.
Figure 1 shows photocopiesof printed and hand written documents from the19th century.
Within any given paragraph, theChinese characters are printed as evenly spacedcharacters, with nothing to separate words fromwords, phrases from phrases, and sentences fromsentences.
Thus, inside a paragraph, explicitboundaries of sentences and clauses are lacking.In order to understand the structure, readers ofClassical Chinese have to manually identifythese boundaries during the reading.
Thisprocess is called Classical Chinese sentencesegmentation, or Judo (??
).For example, the opening lines of the Daoistclassic Zhuangzi originally lacked segmentation:?/north ?/ocean ?/have?/fish ?/it ?/name?/is ?/Kun (a kind of big fish) ?/Kun ?/of?/big ?/not ?/know ?/how ?/thousand ?/mile  ?/exclamationThe meaning of the text is hard to interpretwithout segmentation.
Below is the identical textas segmented by a human being.
It is clearlymore readable.???
?/in the north ocean there is a fish????
/its name is Kun??
?/the size of the Kun?????
?/I don?t know how manythousand miles the fish isHowever, sentence segmentation in ClassicalChinese is not a trivial problem.
Classical Chi-nese sentence segmentation, like Chinese wordsegmentation, is inherently ambiguous.
Individ-uals generally perform sentence segmentation ininstinctive ways.
To identify the boundaries ofsentences and clauses, they primarily rely ontheir experience and sense of the language ratherthan on a systematic procedure.
It is thus diffi-cult to construct a set of rules or practical proce-dures to specify the segmentation of the infinitevariety of Classical Chinese sentences.Figure 1.
A Printed Page (Left) and a Hand Written Manuscript (Right) from the 19th Century.Because of the importance of sentence seg-mentation, beginning in the 20th century, someeditions of the Chinese classics have been labor-intensively segmented and marked with modernpunctuation.
However, innumerable documentsin Classical Chinese from the centuries of Chi-nese history remain to be segmented.
To aid inprocessing these documents, we propose an au-tomated Classical Chinese sentence segmenta-tion approach that enables completion of seg-mentation tasks quickly and accurately.
To con-struct the sentence segmenter for Classical Chi-nese, the popular sequence tagging models, con-ditional random field (CRF) (Lafferty et al,2001), are adopted in this study.The rest of this paper is organized as follows.First, we describe the Classical Chinese sentencesegmentation problem in Section 2.
In Section 3,we review the relevant literature, including sen-tence boundary detection (SBD) and Chineseword segmentation.
In Section 4, we introducethe tagging schemes along with the features, andshow how the sentence segmentation problemcan be transformed into a sequence taggingproblem and decoded with CRFs.
In Section 5,the experimental setup and data are described.
InSection 6, we report the experimental results anddiscuss the properties and the challenges of theClassical Chinese sentence segmentation prob-lem.
Finally, we conclude the remarks in Section7.2 Problem DescriptionThe outcomes of Classical Chinese sentencesegmentation are not well-defined in linguisticsat present.
In general, the results of segmentationconsist of sentences, clauses, and phrases.
Forinstance, in the segmented sentence ????
/???
/ ????????
?, ?????
(?themists on the mountains like wild horses?)
and?????
(?the dust in the air?)
are phrases, and ??????????
(?the living creatures blowtheir breaths at each other?)
is a clause.
Asentence such as ??????????
(?I donot believe it because it is ridiculous.?)
is a shortsentence itself, and does not require anysegmentation.
For a given text, there is no strictrule to determine at which level thesegmentation should be performed.
For instance,the opening lines of the Daoist classic Daodejingis ??????????????
(?The waythat can be spoken is not the eternal way.
Thename that can be given is not the eternal name.?
)which is usually segmented as ????
/ ??
?/ ???
/ ???
?, but may also be segmentedas ??
/ ??
/ ???
/ ?
/ ??
/ ???
?.Either segmentation is reasonable.In this paper, we do not distinguish among thethree levels of segmentation.
Instead, our systemlearns directly from the human-segmented cor-pus.
After training, our system will be adapted toperform human-like segmentation automatically.Further, we do not distinguish the various out-comes of Classical Chinese sentence segmenta-tion.
Instead, for the sake of convenience, everyproduct of the segmentation process is termed?clause?
in the following sections.3 Related WorkBesides Classical Chinese, sentence boundarydetection (SBD) is also an issue in English andother western languages.
SBD in written textsand speech represents quite different problems.For written text, the SBD task is to distinguishperiods used as the end-of-sentence indicator(full stop) from other usages, such as parts ofabbreviations and decimal points.
By contrast,the task of SBD in speech is closely related tothe task of Classical Chinese sentence segmenta-tion.
In speech processing, the outcome ofspeech recognizers is a sequence of words, inwhich the punctuation marks are absence, andthe sentence boundaries are thus lacking.
To re-cover the syntactic structure of the originalspeech, SBD is required.Like Classical Chinese sentence segmentation,the task of SBD in speech is to determine whichof the inter-word boundaries in the stream ofwords should be marked as end-of-sentence, andthen to divide the entire word sequence into in-dividual sentences.
Empirical methods are com-monly employed to deal with this problem.
Suchmethods involve many different sequence labe-ling models including HMMs (Shriberg et al,2000), maximum entropy (Maxent) models (Liuet al, 2004), and CRFs (Liu et al, 2005).Among these, a CRF model used in Liu et al(2005) offered the lowest error rate.Chinese word segmentation is a problemclosely related to Classical Chinese sentencesegmentation.
The former identifies the bounda-ries of the words in a given text, while the latteridentifies the boundaries of the sentences, claus-es, and phrases.
In contrast to sentences andclauses, the length of Chinese words is shorter,and the variety of Chinese words is more limited.Despite the minor unknown words, most of thefrequent words can be handled with a dictionarypredefined by Chinese language experts or ex-tracted from the corpus automatically.
However,it is impossible to maintain a dictionary of theinfinite number of sentences and clauses.
Forthese reasons, the Classical Chinese sentencesegmentation problem is more challenging.Methods of Chinese word segmentation canbe mainly classified into heuristic rule-basedapproaches, statistical machine learning ap-proaches, and hybrid approaches.
Hybrid ap-proaches combine the advantages of heuristicand statistical approaches to achieve better re-sults (Gao et al, 2003; Xue, 2003; Peng et al,2004).Xue (2003) transformed the Chinese wordsegmentation problem into a tagging problem.For a given sequence of Chinese characters, theauthor applies a Maxent tagger to assign eachcharacter one of four positions-of-character(POC) tags, and then coverts the tagged se-quence into a segmented sequence.
The fourPOC tags used in Xue (2003) denote the posi-tions of characters within a word.
For example,the first character of a word is tagged ?leftboundary?, the last character of a word is tagged?right boundary?, the middle character of a wordis tagged ?middle?, and a single character thatforms a word by itself is tagged ?single-character-word?.
Once the given sequence istagged, the boundaries of words are also re-vealed, and the task of segmentation becomesstraightforward.
However, the Maxent modelsused in Xue (2003) suffer from an inherent thelabel bias problem.
Peng et al(2004) uses theCRFs to address this issue.
The tags used inPeng et al(2004) are of only two types, ?start?and ?non-start?, in which the ?start?
tag denotesthe first character of a word, and the charactersin other positions are given the ?non-start?
tag.The closest previous works to Classic Chinesesentence segmentation are Huang (2008) andZhang et al (2009).
Huang combined the Xue?stagging scheme (i.e., 4-tag set) and CRFs to ad-dress the Classical Chinese sentence segmenta-tion problem and reported an F-score of 80.96%averaged over various datasets.
A similar workby Zhang et al reported an F-score of 71.42%.4 MethodsConditional random field is our tagging model,and the implementation is CrfSgd 1.31 providedby L?on Bottou.
As denoted by the tool name,the parameters in this implementation are opti-mized using Stochastic Gradient Descent (SGD)which convergences much faster than the com-mon optimization algorithms such as L-BFGSand conjugate gradient (Vishwanathan, et al,2006).
To construct the sentence segmenter on1 http://leon.bottou.org/projects/sgdCRF, the tagging scheme and the feature func-tions play the crucial roles.4.1 Tagging SchemesIn the previous works (Huang, 2008; Zhang etal., 2009), POC tags used in Chinese word seg-mentation (Xue, 2003) are converted to denotethe positions of characters within a clause.
The4-tag set is redefined as L (?the left boundary ofa clause?
), R (?the right boundary of a clause?
),M (?the middle character of a clause?
), and S (?asingle character forming a clause?).
For example,the sentence ???????????????????
should be tagged as follows.
?/L ?/M ?/M ?/R ?/L ?/M ?/M ?/R ?/L ?/M ?/R ?/L ?/M ?/M ?/M ?/M ?/RWe can easily split the sentence into clauses bymaking a break after each character tagged Rand S and obtain the final outcome ?????
/????
/ ???
/ ??????
?.In this work, more tagging schemes are expe-rimented.
The basic tagging scheme for segmen-tation is 2-tag set in which only two types of tags,?start?
and ?non-start?, are used to label the se-quence.
The segmented fragments (clauses) forsentence segmentation are usually much longerthan those for word segmentation.
Thus, we addmore middle states into the 4-tag set to modelthe nature of long fragments.
The Markov chainof our tagging scheme is shown in Figure 2,where L2, L3, ?, Lk are the additional states toextend Xue?s 4-tag set.
In our experiments, vari-ous k values are tested.
If the k value is 1, thescheme is identical to the one used in the twoprevious works (Zhang et al, 2009; Huang,2008).
The 2-tag set, 4-tag set, 5-tag set and theircorresponding examples are listed in Table 1.With the tagging scheme, the Classical Chinesesentence segmentation task is transformed into asequence labeling or tagging task.4.2 FeaturesDue to the flexibility of the feature function in-terface provided by CRFs, we apply various fea-ture conjunctions.
Besides the n-gram characterpatterns, the phonetic information and the part-Figure 2.
Markov Chain of Our Tagging Scheme.Tag set Tags Example2-tag S: Start ??????
?N: Non-Start ??????
?4-tag(k=1)L1: Left-end ??????
?M: Middle ??????
?R: Right-end ??????
?S: Single ?
/ ???
?5-tag(k=2)L1: Left-end ??????
?L2: Left-2nd ??????
?M: Middle ??????
?R: Right-end ??????
?S: Single ?
/ ???
?Table 1.
Examples of Tag Sets.of-speech (POS) are also included.
The pronun-ciation of each Chinese character is labeled inthree ways.
The first one is Mandarin PhoneticSymbols (MPS), also known as Bopomofo,which is a phonetic system for Modern Chinese.The initial/final/tone of each character can beobtained from its MPS label.However, Chinese pronunciation varies in thethousands of years, and the pronunciation ofModern Chinese is much different from theClassical Chinese.
For this reason, two AncientChinese phonetic systems, Fanqie (??)
andGuangyun (??
), are applied to label the cha-racters.
The pronunciation of a target character isrepresented by two characters in the Fanqie sys-tem.
The first character indicates the initial ofthe target character, and the second characterindicates the combination of the final and thetone.
The Guangyun system is in a similar man-ner with a smaller phonetic symbol set.
Thereare 8,157 characters in our phonetic dictionaryand the statistics are shown in Table 2.The POS information is also considered.
It isdifficult to construct a Classical Chinese POSSystem #Initials #Finals #TonesMPS 21 36 5Fanqie 403 1,054Guangyun 43 203Table 2.
Phonetic System Statistics.POS # Characters ExamplesBeginning 60 ?, ?, ?Middle 50 ?, ?End 45 ?, ?, ?, ?Interjection 20 ?, ?, ?, ?Table 3.
Four Types of POS.tagger at this moment.
Instead, we collectedthree types of particles that are usually placed atthe beginning, at the middle, and at the end ofClassical Chinese clauses.
In addition, the inter-jections which are usually used at the end ofclauses are also collected.
Some examples aregiven in Table 3.
The five feature sets and thefeature templates are shown in Table 4.5 ExperimentsThere are three major sets of experiments.
In the1st set of experiments, we test different taggingschemes for Classical Chinese sentence segmen-tation.
In the 2nd set of experiments, all kinds offeature sets and their combinations are tested.The performances of the first two sets of expe-riments are evaluated by 10-fold cross-validationon four datasets which cross both eras and con-texts.
In the 3rd set of experiments, we train thesystem on one dataset, and test it on the others.In last part of the experiments, the generality ofthe datasets and the toughness of our system aretested (Peng et al, 2004).
The cut-off thresholdfor the features is set to 2 for all the experiments.In other words, the features occur only once inthe training set will be ignored.
The other op-tions of CrfSgd remain default.5.1 DatasetsThe datasets used in the evaluation are collectedfrom the corpora of the Pre-Qin and Han Dynas-ties (the 5th century BCE to the 1st century BCE)and the Qing Dynasty (the 17th century CE tothe 20th century CE).
Chinese in the 19th cen-tury is fairly different from Chinese in the erabefore 0 CE.
In ancient Chinese, the syntax ismuch simpler, the sentences are shorter, and thewords are largely composed of a single character.Those are unlike later and more modern Chinese,where word segmentation is a serious issue.Given these properties, the task of segmentingFeature Set Template FunctionCharacter ??
,?2 ?
?
?
2 Unigrams???
?+1 ,?2 ?
?
?
1 Bigrams????+1?
?+2,?2 ?
?
?
0 Trigrams???
?+2 ,?2 ?
?
?
0 JumpsPOS ???_?
(?0)  Current character serves as a clause-beginning particle.???_?
(?0) Current character serves as a clause-middle particle.???_?
(?0) Current character serves as a clause-end particle.???_?
(?0) Current character serves as an interjection.MPS ?_?
(?0) The initial of current character in MPS.?_?
(?0) The final of current character in MPS.?_?
(?0) The tone of current character in MPS.?_?(??1)?_?(??1)?_?
(?0) The connection between successive characters.Fanqie ?_?
(?0) The initial of current character in Fanqie.?_?
(?0) The final and the tone of current character in Fanqie.?_?(??1)?_?
(?0) The connection between successive characters.Guangyun ?_?
(?0) The initial of the current character in Guangyun.?_?
(?0) The final and the tone of current character in Guan-gyun.?_?(??1)?_?
(?0) The connection between successive characters.Table 4.
Feature Templates.Corpus Author Era #  of dataentries# ofcharactersSize of cha-racter setAverage # ofcharacters/clauseZuozhuan Zuo Qiuming 500 BCE 3,381 195,983 3,238 4.145Zhuangzi Zhuangzi 300 BCE 1,128 65,165 2,936 5.183Shiji Qian Sima 100 BCE 4,778 503,890 4,788 5.049Qing Documents Qing DynastyOfficials19thcentury1,000 111,739 3,147 7.199Table 5.
Datasets and Statistics.ancient Chinese sentences is easier than that ofsegmenting later Chinese ones.
Thus, we col-lected texts from the pre-Qin and Han period,and from the late Qing Dynasty closer to thepresent, to show that our system can handleClassical Chinese as it has evolved across a spanof two thousand years.A summary of the four datasets is listed inTable 5.
The Zuozhuan is one of earliest histori-cal works, recording events of China in theSpring and Autumn Period (from 722 BCE to481 BCE).
The book Zhuangzi was named afterits semi-legendary author, the Daoist philoso-pher Zhuangzi, who lived around the 4th centuryBCE.
The book consists of stories and fables, inwhich the philosophy of the Dao is propounded.The Shiji, known in English as The Records ofthe Grand Historian, was written by Qian Simain the 1st century BCE.
It narrates Chinese histo-ry from 2600 BCE to 100 BCE.
The Shiji is notonly an extremely long book of more than500,000 characters, but also the chief historicalwork of ancient China, exerting an enormousinfluence on subsequent Chinese literature andhistoriography.The three ancient works are the most impor-tant classics of Chinese literature.
We fetchedwell-segmented electronic editions of theseworks from the online database of the Instituteof History and philology of the Academia Sinica,Taiwan.2 Each work was partitioned into para-graphs forming a single data entry, which actedas the basic unit of training and testing.
The da-taset of Qing documents is selected from theQing Palace Memorials (??)
related to Taiwanwritten in the 19th century.
These documentswere kindly provided by the Taiwan HistoryDigital Library and have also been human-segmented and stored on electronic media (Chenet al, 2007).
We randomly selected 1,000 para-graphs from them as our dataset.2http://hanji.sinica.edu.tw5.2 Evaluation MetricsFor Classical Chinese sentence segmentation, wedefine the precision P as the ratio of the bounda-ries of clauses which are correctly segmented toall segmented boundaries, the recall R as the ra-tio of correctly segmented boundaries to all ref-erence boundaries, and the score F as the har-monic mean of precision and recall:?
=?
?
?
?
2?
+ ?Dataset Precision Recall F-ScoreZuozhuan 100% 32.80% 42.73%Zhuangzi 100% 19.84% 29.83%Shiji 100% 14.11% 20.63%Qing Doc.
100% 33.08% 41.42%Average 100% 24.96% 33.65%Table 6.
Performance of Majority-Class Baseline.Tag Set Precision Recall F-Score2-tag set 85.00% 82.16% 82.92%4-tag set 85.11% 82.13% 82.95%5-tag set 85.26% 82.36% 83.18%7-tag set 84.47% 82.18% 82.74%Baseline 100% 24.96% 33.65%Table 7.
Comparison between Tagging Schemes.Features Precision Recall F-ScoreCharacter 85.26% 82.36% 83.18%POS 61.04% 40.35% 43.93%MPS 65.31% 54.00% 56.31%Fanqie 80.96% 76.80% 77.95%Guangyun 73.11% 69.13% 69.59%POS +Fanqie81.07% 74.91% 76.77%Character+ Fanqie85.43% 82.52% 83.34%Character+ POS +Fanqie85.67% 81.70% 82.98%Table 8.
Comparison between Feature Sets.Dataset Precision Recall F-ScoreZuozhuan 92.83% 91.56% 91.79%Zhuangzi 81.02% 78.87% 79.34%Shiji 80.79% 78.10% 78.99%Qing Doc.
87.07% 81.53% 83.24%Average 85.43% 82.52% 83.34%Table 9.
Performance on Four Datasets.6 ResultsOur baseline is a majority-class tagger whichalways regards the whole paragraph as a singlesentence (i.e., never segments).
In Table 6, theperformance of the baseline is given.
In the 1stset of experiments, four tagging schemes aretested while the feature set is Character.
The re-sults are shown in Table 7.
In the table, each ofthe precision, the recall, and the F-score are av-eraged over the four datasets for each scheme.The results show that the CRF with the 5-tag setis superior to the 4-tag set used in previousworks.
However, the performance is degradedwhen the k is larger.In the 2nd set of experiments, the tag schemeis fixed to the 5-tag set and a number of featureset combinations are tested.
The results areshown in Table 8.
The performance of MPS issignificantly inferior to the other two phoneticsystems.
As expected, the pronunciation of Clas-sical Chinese is much different from that ofModern Chinese, thus the Ancient Chinese pho-netic systems are more suitable for this work.The Fanqie has a surprisingly performance closeto the Character.
However, performance of thecombination of Character and Fanqie is similarto the performance of Character only model.This result indicates that the phonetic informa-tion is an important clue to Classical Chinesesentence segmentation but such information ismostly already covered by the characters.
Be-sides, the simple POS features do not help a lot.The higher precision and the lower recall of thePOS features show that the particles such as ?/?/?/?
is indeed a clue to segmentation, butdoes not catch enough cases.The best performance comes from the com-bination of Character and Fanqie with the 5-tagset.
We use this configuration as our final tagger.The performances of our tagger for each datasetare given in Table 9.
The result shows that ourtagger achieves fairly good performance on theZuozhuan segmentation, while obtaining accept-able performance overall.
Because the 19th cen-tury Chinese is more complex than ancient Chi-nese, what we had assumed was that segmenta-tion of the Qing documents would more difficult.However, the results indicate that our assump-tion does not seem to be true.
Our tagger per-forms the sentence segmentation on the Qingdocuments well, even better than on the Zhuang-zi and on the Shiji.
The issues of longer clausesand word segmentation described earlier in thispaper do not significantly affect the performanceof our system.In the last experiments, our system is trainedand tested on different datasets, and the resultsare presented in Table 10, where the trainingdatasets are in the rows and the test datasets arein the columns, and the F-scores of the segmen-tation performance are shown in the inner entries.As expected, the results of segmentation tasksacross datasets are significantly poorer than thesegmentation in the first two experiments.These results indicate that our system main-tains its performance on a test dataset differingfrom the training dataset, but the difference inwritten eras between the test dataset and trainingdataset cannot be very large.
Among all datasets,Shiji is the best training dataset.
As training onShiji and testing on the two other ancient corpo-ra Zuozhuan and Zhuangzi, the performances ofour CRF segmenter are not bad.Training Set Testing SetZuozhuan Zhuangzi Shiji Qing doc.
AverageZuozhuan  72.04% 59.12% 38.85% 56.67%Zhuangzi 63.70%  52.51% 42.75% 52.99%Shiji 76.27% 75.46%  44.11% 65.28%Qing doc.
52.68% 53.13% 42.61%  49.47%Average 64.22% 66.88% 51.41% 41.90%Table 10.
F-score of Segmentation cross the Datasets.7 ConclusionOur Classical Chinese sentence segmentation isimportant for many applications such as textmining, information retrieval, corpora research,and digital archiving.
To aid in processing suchkind of data, an automatic sentence segmenta-tion system is proposed.
Different taggingschemes and various features are introduced andtested.
Our system was evaluated using threesets of experiments.
Five main results are de-rived.
First, the CRF segmenter achieves an F-score of 91.79% in the best case and 83.34% inoverall performance.
Second, a little longer tag-ging scheme improves the performance.
Third,the phonetic information, especially sourcedfrom Fanqie, is an important clue for ClassicalChinese sentence segmentation and may be use-ful in the related tasks.
Fourth, our method per-forms well on data from various eras.
In the ex-periments, texts from both 500 BCE and the19th century were well-segmented.
Last, theCRF segmenter maintains a certain level of per-formance in situations which the test data andthe training data differ in authors, genres, andwritten styles, but eras in which they were pro-duced are sufficiently close.ReferencesChen, Szu-Pei, Jieh Hsiang, Hsieh-Chang Tu, andMicha Wu.
2007.
On Building a Full-Text DigitalLibrary of Historical Documents.
In Proceedingsof the 10th International Conference on AsianDigital Libraries, Lecture Notes in ComputerScience, Springer-Verlag 4822:49-60.Gao, Jianfeng, Mu Li, and Chang-Ning Huang.
2003.Improved Source-Channel Models for ChineseWord Segmentation.
In Proceedings of the 41stAnnual Meeting of the Association for Computa-tional Linguistics, 272-279.Huang, Hen-Hsen.
2008.
Classical Chinese SentenceDivision by Sequence Labeling Approaches.
Mas-ter?s Thesis, National Chiao Tung University,Hsinchu, Taiwan.Lafferty, John, Andrew McCallum, and FernandoPereira.
2001.
Conditional Random Fields: Proba-bilistic Models for Segmentation and Labeling Se-quence Data.
In Proceedings of the 18th Interna-tional Conference on Machine Learning, 282-289.Liu, Yang, Andreas Stolcke, Elizabeth Shriberg, andMary Harper.
2004.
Comparing and CombiningGenerative and Posterior Probability Models:Some Advances in Sentence Boundary Detectionin Speech.
In Proceedings of the Conference onEmpirical Methods in Natural LanguageProcessing.Liu, Yang, Andreas Stolcke, Elizabeth Shriberg, andMary Harper.
2005.
Using Conditional RandomFields for Sentence Boundary Detection in Speech.In Proceedings of the 43rd Annual Meeting of theAssociation for Computational Linguistics, 451-458.
Ann Arbor, Mich., USA.Peng, Fuchun, Fangfang Feng, and Andrew McCal-lum.
2004.
Chinese Segmentation and New WordDetection using Conditional Random Fields.
InProceedings of the 20th International Conferenceon Computational Linguistics, 562-568.Shriberg, Elizabeth, Andreas Stolcke, Dilek Hakkani-T?r, and G?khan T?r.
2000.
Prosody-Based Au-tomatic Segmentation of Speech into Sentencesand Topics.
Speech Communication, 32(1-2):127-154.Vishwanathan, S. V. N., Nicol N. Schraudolph, MarkW.
Schmidt, and Kevin P. Murphy.
2006.
Accele-rated training of conditional random fields withstochastic gradient methods.
In Proceedings of the23th International Conference on Machine Learn-ing, 969?976.
ACM Press, New York, USA.Xue, Nianwen.
2003.
Chinese Word Segmentation asCharacter Tagging.
Computational Linguistics andChinese Language Processing, 8(1):29-48.Zhang, Hel, Wang Xiao-dong, Yang Jian-yu, andZhou Wei-dong.
2009.
Method of Sentence Seg-mentation and Punctuating for Ancient Chinese.Application Research of Computers, 26(9):3326-3329.
