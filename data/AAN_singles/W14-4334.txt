Proceedings of the SIGDIAL 2014 Conference, pages 254?256,Philadelphia, U.S.A., 18-20 June 2014.c?2014 Association for Computational LinguisticsA Demonstration of Dialogue Processing in SimSensei KioskFabrizio Morbini, David DeVault, Kallirroi Georgila,Ron Artstein, David Traum, Louis-Philippe MorencyUSC Institute for Creative Technologies12015 Waterfront Dr., Playa Vista, CA 90094{morbini,devault,kgeorgila,artstein,traum,morency}@ict.usc.eduAbstractThis demonstration highlights the dia-logue processing in SimSensei Kiosk, avirtual human dialogue system that con-ducts interviews related to psychologi-cal distress conditions such as depression,anxiety, and post-traumatic stress disorder(PTSD).
The dialogue processing in Sim-Sensei Kiosk allows the system to con-duct coherent spoken interviews of humanusers that are 15-25 minutes in length,and in which users feel comfortable talk-ing and openly sharing information.
Wepresent the design of the individual dia-logue components, and show examples ofnatural conversation flow between the sys-tem and users, including expressions ofempathy, follow-up responses and contin-uation prompts, and turn-taking.1 IntroductionThis demonstration highlights the dialogue pro-cessing in SimSensei Kiosk, a virtual human di-alogue system that conducts interviews related topsychological distress conditions such as depres-sion, anxiety, and post-traumatic stress disorder(PTSD) (DeVault et al., 2014).
SimSensei Kioskhas two main functions ?
a virtual human calledEllie (pictured in Figure 1), who converses with auser in a spoken, semi-structured interview, and amultimodal perception system which analyzes theuser?s behavior in real time to identify indicatorsof psychological distress.The system has been designed and devel-oped over two years using a series of face-to-face, Wizard-of-Oz, and automated system stud-ies involving more than 350 human participants(Scherer et al., 2013; DeVault et al., 2013; DeVaultet al., 2014).
Agent design has been guided bytwo overarching goals: (1) the agent should makeFigure 1: Ellie, the virtual human interviewer inSimSensei Kiosk.the user feel comfortable talking and openly shar-ing information, and at the same time (2) the agentshould create interactional situations that supportthe automatic assessment of verbal and nonver-bal behaviors correlated with psychological dis-tress.
During an interview, the agent presents aset of questions which have been shown in usertesting to support these goals.
Since the main in-terview questions and their order are mostly fixed,dialogue management concentrates on providingappropriate verbal feedback behaviors to keep theuser engaged, maintain a natural and comfort-able conversation flow, and elicit continuationsand elaborations from the user.The agent is implemented using a modular ar-chitecture (Hartholt et al., 2013).
Dialogue pro-cessing, which is the focus of this demonstration,is supported by individual modules for speechrecognition, language understanding and dialoguemanagement (see Section 2).
The agent?s lan-guage and speech are executed by selecting frompre-recorded audio clips.
Additional agent mod-ules include nonverbal behavior generation, whichmatches appropriately timed body movements tothe agent?s speech; character animation in a vir-tual 3D environment; and rendering in a game en-254gine.
The perception system analyzes audio andvideo in real time to identify features such as headposition, gaze direction, smile intensity, and voicequality.
DeVault et al.
(2014) provides details onall the agent?s modules.2 Overview of Dialogue Processing2.1 ASR and NLU componentsUnlike many task-oriented dialogue domains, in-terview dialogues between SimSensei Kiosk andparticipants are naturally open-ended.
People tendto respond to interview stimuli such as ?what?sone of your most memorable experiences??
withidiosyncratic stories and events from their lives.The variability in the vocabulary and content ofparticipants?
answers to such questions is so largethat it makes the ASR task very challenging.
Fur-thermore, continuous ASR is employed to ensurethat participants feel comfortable interacting withthe system without being distracted by having touse a push-to-talk microphone.
The use of con-tinuous ASR necessitates the development of spe-cific policies for turn-taking (see Section 2.2).
Inthis demonstration, voice activity detection andspeech recognition are performed using Pocket-Sphinx (Huggins-Daines et al., 2006).Because of the open-ended participants?
re-sponses, for NLU, we cannot simply construct asmall semantic ontology and expect to cover themajority of meanings that will be expressed byusers.
Thus, this is an application in which thedialogue policy needs to be able to create a senseof engagement, continuation, and empathy despiterelatively shallow and limited understanding ofuser speech.
SimSensei Kiosk currently uses 4statistically trained utterance classifiers to capturedifferent aspects of user utterance meaning.The first NLU classifier identifies generic di-alogue act types, including statements, yes-noquestions, wh-questions, yes and no answers, andseveral others.
This classifier is trained usingthe Switchboard DAMSL corpus (Jurafsky et al.,1997) using a maximum entropy model.The second NLU classifier assigns positive,negative, or neutral valence to utterances, in or-der to guide Ellie?s expression of empathy.
Weuse SentiWordNet 3.0 (Baccianella et al., 2010), alexical sentiment dictionary, to assign valence toindividual words spoken by users (as recognizedby the ASR); the valence assigned to an utteranceis based primarily on the mean valence scores ofOpening Rapport Building PhaseEllie What are some things you really like about LA?
(top level question)User I love the weather, I love the palm trees, I love thebeaches, there?s a lot to do here.Diagnostic PhaseEllie Have you noticed any changes in your behavior orthoughts lately?
(top level question)User Yes.Ellie Can you tell me about that?
(continuation prompt)User I?m having a lot more nightmares now uh can?tsleep have haven?t really been eating uh trying toeat.
.
.
I have to force down food um just feelinglike an emotional wreck.Ellie I?m sorry to hear that.
(empathy response)Ellie What are you like when you don?t sleep well?
(follow-up question)User Irritable, emotional, it just adds to my overallstress um [long pause]Ellie What.
.
.
(Ellie speaks after the participant?s longpause)User Can?t concentrate uh I uh.
.
.
(the participant startsspeaking while Ellie is speaking)Ellie I?m sorry please continue.
(Ellie realizes that shehas interrupted the participant and apologizes)Positive Closing PhaseEllie How would your best friend describe you?
(toplevel question)User As caring, as fun because most of the time whenI?m around my best friends I?m happy and I?m funloving.
I joke around with them a lot and uh I dobetter when I?m around my friends.
.
.Figure 2: Examples of Ellie?s interview phases.the individual words in the utterance.The third NLU classifier supports domain-specific small talk by recognizing a handful ofspecific anticipated responses to Ellie?s rapport-building questions.
For example, when Ellie asksusers where they are from, this classifier detectsthe names of commonly mentioned cities and re-gions using keyphrase spotting.The fourth NLU classifier identifies domain-specific dialogue acts, and supports Ellie?s follow-up responses to specific questions, such as ?howclose are you to your family??.
This maximumentropy classifier is trained using face-to-face andWizard-of-Oz data to detect specific responsessuch as assertions of closeness.2.2 Dialogue ManagementEllie currently uses about 100 fixed utterances intotal in the automated system.
She employs 60 toplevel interview questions (e.g., ?do you travel a255lot??
), plus some follow-up questions (e.g., ?whatdo you enjoy about traveling??)
and a range ofbackchannels (e.g., ?uh huh?
), empathy responses(e.g., ?that?s great?, ?I?m sorry?
), and continua-tion prompts (e.g., ?tell me more about that?
).The dialogue policy is implemented using theFLoReS dialogue manager (Morbini et al., 2012).The policy groups interview questions into threephases (opening rapport building, diagnostic, pos-itive closing ?
ensuring that the participant leaveswith positive feelings).
Questions are generallyasked in a fixed order, with some branching basedon responses to specific questions.Rule-based subpolicies determine what Ellie?sfollow-up responses will be for each of her top-level interview questions.
The rules for follow-upsare defined in relation to the four NLU classifiersand the duration of user speech (measured in sec-onds).
These rules trigger continuation promptsand empathy responses under specific conditions.The turn-taking policy supports our design goalto encourage users to openly share informationand to speak at length in response to Ellie?s open-ended questions.
In this domain, users often pausebefore or during their responses to think abouttheir answers to Ellie?s personal questions.
Theturn-taking policy is designed to provide ampletime for users to consider their responses, and tolet users take and keep the initiative as much aspossible.
Ellie?s turn-taking decisions are basedon thresholds for user pause duration, i.e., howmuch time the system should wait after the userhas stopped speaking before Ellie starts speaking.These thresholds are tuned to the face-to-face andWizard-of-Oz data to minimize Ellie?s interrup-tion rate, and are extended dynamically when El-lie detects that she has interrupted the participant.This is to take into account the fact that some peo-ple tend to use longer pauses than others.Examples of the three interview phases and ofEllie?s subdialogue policies (top level and follow-up questions, continuation prompts, empathy re-sponses, and turn-taking) are given in Figure 2.3 Demonstration SummaryThe demonstration will feature a live interac-tion between Ellie and a participant, showing El-lie?s real-time understanding and consequent pol-icy actions.
Live dialogues will highlight Ellie?sstrategies for questioning, follow-up continuationprompts, displays of empathy, and turn-taking,similar to the example in Figure 2.
The demon-stration will illustrate how these elements work to-gether to enable Ellie to carry out extended inter-views that also provide information relevant to theautomatic assessment of indicators of distress.AcknowledgmentsThe effort described here is supported by DARPAunder contract W911NF-04-D-0005 and the U.S.Army.
Any opinion, content or information pre-sented does not necessarily reflect the position orthe policy of the United States Government, andno official endorsement should be inferred.ReferencesS.
Baccianella, A. Esuli, and F. Sebastiani.
2010.
Sen-tiWordNet 3.0: An enhanced lexical resource forsentiment analysis and opinion mining.
In Proceed-ings of LREC.D.
DeVault, K. Georgila, R. Artstein, F. Morbini, D.Traum, S. Scherer, A. Rizzo, and L.-P. Morency.2013.
Verbal indicators of psychological distress ininteractive dialogue with a virtual human.
In Pro-ceedings of SIGDIAL.D.
DeVault, R. Artstein, G. Benn, T. Dey, E. Fast,A.
Gainer, K. Georgila, J. Gratch, A. Hartholt, M.Lhommet, G. Lucas, S. Marsella, F. Morbini, A.Nazarian, S. Scherer, G. Stratou, A. Suri, D. Traum,R.
Wood, Y. Xu, A. Rizzo, and L.-P. Morency.
2014.SimSensei Kiosk: A virtual human interviewer forhealthcare decision support.
In Proceedings of AA-MAS.A.
Hartholt, D. Traum, S. Marsella, A. Shapiro, G.Stratou, A. Leuski, L.-P. Morency, and J. Gratch.2013.
All together now, introducing the virtual hu-man toolkit.
In Proceedings of IVA.D.
Huggins-Daines, M. Kumar, A. Chan, A.W.
Black,M.
Ravishankar, and A.I.
Rudnicky.
2006.
Pocket-Sphinx: A free, real-time continuous speech recog-nition system for hand-held devices.
In Proceedingsof ICASSP.D.
Jurafsky, E. Shriberg, and D. Biasca.
1997.
Switch-board SWBD-DAMSL Shallow-Discourse-FunctionAnnotation Coders Manual, Draft 13.F.
Morbini, D. DeVault, K. Sagae, J. Gerten, A. Nazar-ian, and D. Traum.
2012.
FLoReS: A forward look-ing reward seeking dialogue manager.
In Proceed-ings of IWSDS.S.
Scherer, G. Stratou, M. Mahmoud, J. Boberg,J.
Gratch, A. Rizzo, and L.-P. Morency.
2013.
Au-tomatic behavior descriptors for psychological dis-order analysis.
In Proceedings of IEEE Conferenceon Automatic Face and Gesture Recognition.256
