Coling 2010: Poster Volume, pages 1238?1246,Beijing, August 2010Semi-Supervised WSD in Selectional Preferenceswith Semantic RedundancyXuri TANG1,5  , Xiaohe CHEN1 , Weiguang QU2,3 and Shiwen YU41.
School of Chinese Language and Literature, Nanjing Normal University{xrtang,chenxiaohe5209}@126.com2.
Jiangsu Research Center of Information Security & Privacy Technology3.
School of Computer Science, Nanjing Normal Universitywgqu_nj@163.com4.
Institute of Computational Linguistics , Peking Universityyusw@pku.edu.cn5.
College of Foreign Studies, Wuhan Textile UniversityAbstractThis paper proposes a semi-supervisedapproach for WSD in Word-Classbased selectional preferences.
Theapproach exploits syntagmatic andparadigmatic semantic redundancy inthe semantic system and usesassociation computation and minimumdescription length for the task of WSD.Experiments on Predicate-Objectcollocations and Subject-Predicatecollocations with polysemouspredicates in Chinese show that theproposed approach achieves a precisionwhich is 8% higher than the semantic-association based baseline.
The semi-supervised nature of the approachmakes it promising for constructinglarge scale selectional preferenceknowledge base.1 IntroductionThis paper addresses word sensedisambiguation (WSD) which is required inthe construction of selectional preference (SP)knowledge database.
In previous literature ofSP, four different types of formalizationmodels are explicitly or implicitly employed.Two types are distinguished in Li andAbe(1998):Word Model: ?=),|( rvnP     (1)Class Model: ?=),|( rvCP         (2)where v stands for verb, n for noun, C for thesemantic class of n, r for the grammaticalrelation between v and n, and P for thepreference strength.
Most of theresearches(Resnik 1996; Li and Abe 1998;Ciaramita and Johnson 2000; Brockmann andLapata 2003; Light and Greiff 2002) uses theclass model, and a few(Erk 2007) uses theword model.
The other two types of model aregiven as below:Class-Only Model: ?=),|( rCCP vn        (3)Word-Class Model: ?=),,|,( rCvCnP vn  (4)where ,  are semantic classes for thenoun and verb respectively.
Class-Only modelconsiders solely the semantic classes, whileWord-Class model considers both words andsemantic classes.
Agirre and Martinez(2001)and Zheng et al2007) adopted the Class-onlyModel in research, while in McCarthy andCarroll(2003) and Merlo and Stevenson(2001)the Word-Class Model is employed.nC vCAmong the four models, the Word-ClassModel is the type which possesses the mostgranulated knowledge and is the most potentialin applications.
McCarthy and Carroll(2003)reports that the Word-Class Model performswell in unsupervised WSD.
In other NLP taskssuch as metaphor recognition, this model maybe indispensable.
For instance, to distinguishthe  predicate verb  ???(float)?
in  Ex(1a) asEx.
1a.?
?
?
?leaf floats b.?
?
?
?price floats1238literal and Ex(1b) as metaphorical requiresdifferent interpretations of the verb.The present research is concerned withWSD as in the Word-Class model.
Particularly,it aims at disambiguating predicates in subject-predicate (Subj-Pred) and predicate-object(Pred-Obj) constructions.
The motivationsbehind the research are two folds.
Firstly,semi-supervised and unsupervised WSD in SPare not fully explored.
Merlo andStevenson(Merlo and Stevenson 2001)employs supervised learning from largeannotated corpus, which is difficult to obtain.One known unsupervised learning approachfor WSD in SP is McCarthy and Carroll(2003)which addresses the issue via conditionalprobability.
The other motivation derives fromthe fact few research is done on selectionalpreferences in languages other than English, asis stated in Brockmann and Lapata(2003).
Forinstance, studies on construction of SPknowledge database in Chinese can only befound in Wu et al2005), Zhen et al2007), Jiaand Yu(2008) and some others.The basic idea of the approach proposed forWSD in the paper is that the most acceptableinterpretation of senses for a givenconstruction is the pair of senses whichencodes the most redundant information in thesemantic system of the language.
Twoprinciples, namely Syntagmatic RedundancyPrinciple and Paradigmatic RedundancyPrinciple, are proposed in the paper to capturethe intuition.
Two corresponding devices areemployed to model the two principles:Association for Syntagmatic RedundancyPrinciple and Minimum Description Length forParadigmatic Redundancy Principle.
Twoexperiments are conducted in the paper.
Thefirst is based on semantic association,achieving a 61.98% precision for predicates inSubj-Preds and 62.54% in Pred-Objs.
Thisexperiment is used as baseline as the approachis also used in McCarthy and Carroll(2003) forverb and adjective disambiguation.
In thesecond experiment, both semantic associationand MDL are employed, the precision of WSDamounts to 69.88% and 69.09% for predicatesin Subj-Preds and Pred-Objs respectively,indicating that a combination of the twodevices are fairly effective in disambiguatingword senses for SP.The rest of the paper is organized as below.The second part gives further illustration of therationale for the approach.
The third partdescribes the procedure and the fourth partdiscusses the experiment result.
The thesisconcludes with some speculations in furtherresearches.2 Rationale2.1 Task FormalizationConsider a Subj-Pred or Pred-Objcollocation C=< , > , where  isthe word of predicate and  is the word ofargument.
has M senses, denoted by set.
has N senses, denoted by .The possible interpretation of C has M*Npossibilities, denoted by={ | =< , >},where  is called a sense collocation.
Thetask of WSD is to search for a particular sensecollocation in  and assign it to C as itsinterpretation.
At the initial stage, each sensecollocation in  is considered to have aneven number of frequency, namely.
Accordingly, for each, , For each, .predWarg ?CSCS)M?sf ipred(s i 1)arg =argWWijij?)
=N/predWargSjsargargM/1predWargS?/(1 Npredf (predSSC =(f ij?ipredsargs i ?WS predij?=SargSipreds)?2.2 Syntagmatic Redundancy PrincipleSyntagmatic Redundancy Principle (SRP)can be stated as following: among all possiblesense collocations for a word collocation, themost appropriate is the one in which sensesexhibit the most redundant informationbetween each other.The syntagmatic redundancy betweenwords has been noticed very early by linguistsand has been applied in WSD.
Firth(1957)argues that there exists ?mutual expectancy?between words in collocations, and themeaning of word is partially encoded in itsjuxtaposition.
Lyons(1977:261) comments thatPorzig has noticed in 1934 the ?essentialmeaning relation?
between words ofcollocations like ?dog barks?
and ?tree fells?1239and emphasizes that the meanings ofcollocationally restricted lexemes such as?bark?
and ?fell?
can only be explained bytaking into account the collocates they occurwith.
This notion is also employed inYarowsky(1995) for WSD, in which the key isthe ?one-sense-per-collocation?
statement.McCarthy and Carroll(2003) also uses thistype of redundancy for disambiguation in SP.SRP can be explained as a statisticcorrelation between  and .
The moreco-relevant these two senses are, the morelikely the pair is to be accepted as theappropriate interpretation.
This can bedescribed as below:preds args),(maxarg argjipredij ssAssoc=?
(5)where is the function forsense association.
Four methods can beconsidered for association computation:conditional probability (Formula 6 and 7),Lift(Han and Kamber 2006:261) (Formula 8),All-Confidence(Han and Kamber 2006:263)(Formula 9) and cosine (Formula 10).
Notethat two versions of conditional probability areconsidered, as are denoted in Formula 6 and 7.The first version, Cond-Prob 1, takes argumentsense as condition, while the second versionCond-Prob 2 takes predicate sense as condition.
),( argjipred ssAssoc)(),()|(argargarg jijpredjipred spsspssp =             (6))(),()|( argarg ipredijpredjpredispsspssp =                 (7))(*)(),(),(argargarg jipredjipredjipred spspsspsslift =              (8)))(),(max(),(),(_argargarg jpredijipredjipred cfsfssfssconfall =         (9))(*)(),(),(cosargargarg jipredjipredjipredspspsspssine =            (10)2.3 Paradigmatic Redundancy PrincipleParadigmatic Redundancy Principle (PRP)can be stated as following: among all possiblesense collocations for a word collocation, themost appropriate is the one which is alsoimplicitly or explicitly expressed by othersynonymous, metonymic or metaphorical wordcollocations.Ex(2) illustrates the explicit redundancy insynonymous and metaphorical ways, in whichthe sense collocation ?
[Price| ?
?
][QuantityChange|??]?
is expressed by fiveword collocations, each with a differentpredicate : ??
(change), ??
(float), ??(adjust),??
(go up and down), ??
(alter).Ex 2.a.???
?price changes     b.???
?price floats     c.?
?
?
?price adjustsd.?
?
?
?SULFHJRHVXSDQGGRZQe.
???
?price altersEx(3) reveals the implicit redundancy inmetonymic way, in which the meaning ??
(human) ?
?
(is eased)?
is implicitlyexpressed in all the six collocations,established by  semantic relatedness among thearguments ?????
(Maradona)?, ???
(student)?, ???
(work)?, ???
(labour)?, ???
(driving)?, and ???
(life)?.Ex 3.a.??????
?Maradona is eased         b.??
??
?Student is easedc.????
?work is eased               d.??
??
?labour is easede.??
??
?driving is eased             f.????
?Life is easedTo apply PRP, WSD in SP is casted as anissue of model selection.
Given a set of wordcollocations , the process of WSD is toassign to each word collocation one sensecollocation from a number of possibilities.Those assigned sense collocations form a set,or a model for ?
.
The goal of WSD in SP isto select from all those models the one whichbest interprets ?
.
For this purpose, MiminumDescription Length(Barron et al 1998; Michell2003; MacKay 2003) can be used.
MDLselects models by relying on induction biasbased on Occam?s Razor, which stipulates thatthe simplest solution is usually the correct one.One way to interpret MDL in Bays?
analysis isas below(Michell 2003:124):?
)|()(minarg' mDLmLm DM +=            (11)In (11)?
is the model descriptionlength when model m  is considered,is the data description length whenmodel  is used for description.
The modelwith minimum length is the best model.
)(mLM)|( mDLDm1240For model description length, we haveadopted the method used in (Li and Abe 1998)which considers only the size of the model:)log(21)()( NmsizemLM?=                   (12)where size(m) is the number of sensecollocation contained in model m , and N isthe number of word collocation inconsideration.
In this study, the set of wordcollocation with the same predicate word,denoted by ?
, is used as the unit for modeldescription length calculation instead of thewhole corpus, so as to reduce computationcomplexity.
Accordingly, each wordcollocation in ?
can be assigned one and onlyone sense collocation in the model m , out ofall the potential sense collocations as isexplained in section 2.1.Data description length is calculated onmodel and , as is denoted in formulas(13),  (14)  and (15) below.
The  calculation  ism ?????=?=?
))(log())(log()|(2NumfpmLijij??(13)??+=mklijijijijklijwfff??????
?,),(*)()()(         (14)?????
?==><><=kpredkprediljlkpredjipredklijssssrelssssrelwipredpredargargargargs if                                 0s if                ),(),,,(),( ??
(15)based on the probability of sense collocation, which in turn is calculated on amodified frequency of the collocation>=< jipredij ss arg,?
)( ijf ?
.The frequency is modified by counting theexplicit occurrence of the sense collocationitself and the implicit occurrence expressed byother sense collocations in ?
.
This idea isequivalent to enlarge the corpus by 1 fold, thusthe overall collocation number is the two timesof the original number.The modified frequency is a sum of twoparts, denoted in formula (14).
The first part is, the frequency of .
The second part isthe weighted frequency of .
The weight isdetermined by the relatedness of the sensecollocation  and all the other sensecollocation in the model m. According tothis formula, if the sense collocation is foundto be more similar to other sense collocations,it should obtain a higher modified frequency,and thus more likely to be the correct one forthe word collocation.
)( ijf ?ij?ij?ij?kl?The way to calculate the weight is given informula (15).
If two sense collocations haveidentical predicate sense, namely ,then the weight between the two sensecollocations is measured by rel , thesemantic relatedness between the argumentsense and .
Otherwise, 0 is returned.There are different ways to measure senserelatedness.
The present study has usedsemantic similarity based on HowNet(Liu andi 2002) to calculate the semantic relatedness.kpredi s=preds),( argarglj ssjsarg lsargL3 ProcedureFigure 1 maps out the procedure for WSD inSP in the present study.
The procedure isdivided into two phases: data collection anddisambiguation.
The collocation data arecollected from three sources: Sketch Engine,Collocation Dictionary and HowNet Examples.Two types of collocation data are collected:subject-predicate collocations (Subj-Pred) andpredicate-object collocations (Pred-Obj) fromSketch Engine and Collocation Dictionary.Collocation Retriever reduces HowNetexamples into Subj-Preds and Pred-Objs usingsimple heuristic methods.
As a result, about70,000 subject-predicate collocations and106,000 predicate-object collocations areobtained.Figure 1.
WSD ProcedureIn disambiguation phase, two devices areemployed to filter out unlikely sensecollocations: Association-Based SenseCollocation Filter, following SRP, and MDL-Based Sense Collocation Filter, following PRP.Colloc Dict.HowNet ExamplesMDL-Based Sense Colloc FilterAssoc-Based Sense Colloc FilterCollocation RetrieverData CombinationSketch EngineOutput1241In this phase, Subj-Preds and Pred-Objs areprocessed independently but following thesame route.Each phase alone can perform WSDindependently.
Accordingly, two experimentsare conducted to evaluate the method proposedin this paper.
The first experiment usesassociation-based filter for word sensedisambiguation, which is also used as thebaseline.
The approach is also used in(McCarthy and Carroll 2003) to disambiguateverbs and adjectives in collocations.
To beparticular, the method used by McCarthy andCarroll(2003) is formula (6).
The secondexperiment is based on the result of the firstone so as to observe the improvement obtainedby MDL-Based approach.
In the secondexperiment, unsupervised and semi-supervisedWSD are also investigated by including someannotated collocations in the evaluation data.Two corpora are constructed for evaluation.One corpus is a set of 1034 subject-predicateconstructions.
The other is a set of 1841predicate-object constructions.
Both aremanually annotated by the authors with sensedefinitions defined in HowNet(Dong 2006).All together there are 52 highly ambiguouspredicates involved in the study.4 Experiments and Discussion4.1 Collocation RetrieverThe major task in data collocation is inCollocation Retriever, which retrievescollocations from HowNet examples.
Ex(4)gives a partial entry structure in HowNet,Ex 4.W_C=??E_C=??~???~????????~DEF=[change|?
]in which W_C stands for Chinese Word, DEFfor definition, E_C for Examples of Chinese,and the wave ?~?
for the word in question.From E_C, possible Subj-Preds such as ???
(public opinion) ??
(floats)?, ???(index)??(floats)?
can be retrieved, in which thesense of ???(float)?
is annotated with DEF.But there are also noises.
A simple heuristicmethod is applied to automatically filter outunwanted collocations.
The heuristic methodchecks whether the collocation retrieved fromHowNet share possible sense collocations withcollocations in Collocation Dictionary.
If yes,it is accepted as a collocation of the type,otherwise, it is rejected.
Procedures are givenbelow:(a) Use Subj-Pred collocations and Pred-Objcollocations in Collocation Dictionary to buildsense collocation set edSubj Pr??
and Objed?
?Pr ;(b) For each example sentence in E_C,segment it using ICTCLAS1 to obtain an arrayof words.
Words before ?~?
forms potentialSubj-Pred collocations and Wordsafter form potential Pred-Obj collocations.edSubj Pr?
?ObjedB ?Pr(c) For each or ,construct possible sense collocation setedSubja Pr???
edSubjBb Pr??a?
orb?
, if ??????
edSubja Pror ?????
?Objedb Pr , addit as a Subj-Pred collocation or Pred-Objcollocation.Evaluation on partial retrieved collocationsshows that about 70% of obtained collocationsare valid collocations, while about 30% areerrors.
Thus manual edition has been appliedto rid those invalid collocations.4.2 Association-Based FilterAssociation-Based Sense Collocation Filterfilters out those sense collocations that are veryunlikely to be the right interpretation for aword collocation.
Table 1 gives associationcomputation result for the six senses related tothe predicate ?
?
(rough)?
in Subj-Predcollocation ???
(personality) ?
(rough)?.The 2nd , 3rd, 4th, and 6th are very unlikelyinterpretations and should be filtered, while the5th seems to be the most appropriate.Table 1.
Association-Based Filter ExampleNo.Pred Sense Arg Sense Assoc.
Dgr1 [Behavior|??][careless|??]
0.00192 [Behavior|??][coarse|?]
0.00023 [Behavior|??][hoarse|??]
0.00044 [Behavior|??][roughly|??]
0.00025 [Behavior|??][vulgar|?]
0.00716 [Behavior|??][widediameter|?]
0.0002Following the procedure in Figure 1, to filterout those unlikely sense collocations, average1 A Chinese segmentation system, please refer tohttp://www.ictclas.org for further information.1242association value is used as the filter and thosebelow the average are dropped and those aboveare chosen for MDL-Based Filter.
In Table 1,the average is 0.0017, and the 1rd and 5th arechosen.However, in order to obtain a baseline andto decide which association computationmodel to use, we have followed the definitionin Formula 5 and perform WSD test bychoosing the sense collocation with highestassociation as the correct sense tags.
for usedthis step solely for WSD, as is defined inFormula 4.
Table 2 gives the experimentresults for Subj-Pred and Pred-Obj collocationswith all the association computation modelsdenoted in Formula 6-10.Table 2.
WSD Result by AssociationSubj-Pred(%) Pred-Obj(%)Cond-Prob 1 61.98 62.54Cond-Prob 2 55.15 42.4Lift 63.09 40.84All_Conf 56.16 48.54Cosine 58.83 55.72One interesting phenomenon about all thefive models is null-invariance.
In selectingmodels for association computation, null-invariance is an important feature to beconsidered(Han and Kamber 2006).
A modelwith null-invariance is not influenced byadditional irrelevant data and thus is morestable.
In the experiment, the model Lift is theonly one not featured with null-invariance.
Theexperiments show that Lift is not stable indifferent collocation types, achieving highprecision in Subj-Pred but low precision inPred_Obj.A second interesting phenomenon iscollocation directionality exposed by theexperiments, which can be observed in the twomodels of conditional probability: Cond-Prob1, with argument as condition, and Cond-Prob2, with predicate as condition.
Directionality incollocation has been noticed earlier in someresearches, for example Qu(2008).
Ourexperiment shows that when using Cond-Prob1, we are able to get a precision of 61.98% and62.54% for Subj-Pred and Pred-Objrespectively, while Cond-Prob 2 gets a muchlower precision.
This fact can be interpretedthat arguments tend to have a strongerselectional preference strength, and thepossible selection range is comparativelynarrower, while predicates have weakerselectional preference strength and a widerselectional range.4.3 MDL-Based FilterMDL-Based Filter takes as input result fromAssociation-Based Filter using Cond-Prob 1for association computation and averageassociation as filter.
Table 3 and 4 give thefinal experiment outcome for Pred-Obj andSubj-Pred constructions and individualpredicates.It can be seen in Table 3 that MDL-BasedFilter Several inferences can be made from theexperiments.
Firstly, comparison betweenAssociation-Based WSD (Table 2) and MDLWSD (Table 3) shows that MDL can improveoverall performance up to 8%.
As is mentionedearlier, Association-Based WSD is used asbaseline in the present study.
Given the factthat the average number of senses for word inquestion is fairly high, the improvement isconsidered as significant.Table 3.
General WSD Results2Ave.N.O.S.Assoc.WSD (%)MDLWSD (%)Subj-Pred 4.16 61.98 69.09Pred-Obj 5.03 62.54 69.88Analysis on the individual predicates inTable 4 gives a clearer picture of WDL-basedWSD.
Firstly, it can be seen that MDL isespecially effective when the demarcation ofword senses is clear-cut.
Predicate words suchas ???
(quiet)?, ???
(dirty)?, ???(difficult)?
in Subj-Preds and ???
(beat)?,???(touch)?
and ???(break)?
in Pred-Objsare successfully disambiguated in Table 4.These words generally have 2 or 3 senses, andthe   senses    generally    differ    in   terms   ofabstractness and concreteness, as is indicatedin table 5.
This is due to the fact that thearguments in these collocations are clearlydelimitated in HowNet and this delimitation iswell captured by the modified frequencycalculation defined in formula (14).
Via theformula, the concrete sense collocations can2 In Table 3 and 4, Ave. N.O.S stands for average numberof senses of predicates, N.O.S stands for number ofsenses of the predicate, Assoc.
WSD stands forAssociation-based WSD, and MDL WSD stands forMDL-based WSD.1243Table 4.
Detailed WSD Experiment ResultsResults for Pred-Obj.
Results for Subj-Pred.Pred.N.O.SAssoc.WSD(%)MDLWSD(%)Pred.N.O.S.Assoc.WSD(%)MDLWSD(%)?
(v) 5 69.23 80.77 ??
(a) 2 61.14 92.00?
(v) 14 70.59 70.59 ?
(v) 2 72.73 86.36?
(v) 6 56.25 90.62 ??
(a) 2 47.83 58.7??
(v) 3 72.22 88.89 ?
(a/v) 5 52.17 78.26?
(v) 9 50 60.53 ??
(a) 3 56.76 81.08?
(v) 8 86.67 93.33 ?
(a) 5 40 40?
(v) 5 68.75 62.5 ??
(v) 2 55.17 41.38??
(v) 3 73.91 81.16 ??
(a) 3 75.76 93.94?
(v) 17 55.93 44.07 ?
(a) 4 96.3 66.67??
(v) 3 80.36 78.57 ??
(a) 3 47.37 42.11??
(v) 2 66.67 92.31 ?
(a) 6 88.24 88.24??
(v) 2 57.14 80.95 ?
(a) 6 46 60?
(v) 6 76.27 79.66 ??
(v) 3 44.44 44.44??
(v) 3 83.33 100 ??
(a) 2 38.46 65.38?
(v) 8 63.64 63.64 ??
(a) 2 93.33 53.33?
(v) 3 77.14 80 ??
(v) 3 85.19 88.89??
(v) 2 88.24 100 ?
(a) 10 50 50??
(v) 2 83.87 80.65 ??
(v) 2 60.53 63.16?
(v) 9 61.84 68.42 ?
(a/v) 9 39.66 53.45??
(v) 3 40.28 51.39 ?
(a) 6 59.46 51.35?
(v) 4 48.08 53.85 ?
(v) 6 48.72 74.36??
(v) 3 73.49 73.49 ??
(v) 3 48.15 44.44??
(v) 2 15.32 40 ??
(a) 2 88.57 57.14??
(v) 2 84.91 83.02 ?
(a) 6 68.18 40.91?
(v) 3 86.54 85.58 ?
(v) 8 52.03 65.04?
(v) 4 72.51 72.99 ??
(a) 2 95.35 95.35Table 5.
Word Sense DistinctionPred Concrete  Sense Abstract Sense(s)??
[quiet|?]
[calm|??],[peaceful|?]??
[dirty|?]
[despicable|??],[immoral|???]??
[difficult|?]
[poor|?]??
[beat|?]
[MakeBetter|??],[cultivate|??]??
[touch|?]
[excite|??]??
[break|??]
[obstruct|??
]increase the  modified  frequency  of  concretesense collocations, and the abstract sensecollocation can increase the modifiedfrequency of abstract sense collocations, thusleading to the clear demarcation of abstractsenses and concrete senses.The role of semantic relevance can also beclearly noticed in the predicates which have adecreased precision in MDL in Table 4.
ViaParadigmatic Redundancy Principle, theinformation encoded in one collocation arediffused to other collocations.
Consequently,errors can be diffused.
This explains why theprecisions of some predicates such as ??
(sink)?, ???
(dumb)?, ???(dark)?
in Subj-Pred and ??
(open)?, ??(harness)?
in Pred-Objs decrease after MDL.
Further analysisshows that this is because MDL has diffusedthe errors produced by Association Filter.
Forinstance, at Association Filter phase, thecollocation ???
(box) ?(sink)?
is assignedwith the only sense collocation ?[tool|??
][very| ?
]?
and all other potential sensecollocations are filtered.
When MDL is applied,other collocations such as ???
(machine) ?
(heavy)?, ???(pick)?
(heavy)?, ???(chaw)?
(heavy)?, ???
(basket) ?
(heavy)?, ???
(box) ?
(heavy)?, ???
(furniture) ?
(heavy)?,in which the arguments are tightly correlatedwith that of ???
(box) ?(sink)??
all takesthe sense ?[very|?
]?, thus leading to thedecrease of precision.The diffusion of senses can also best seen inthe comparison between those predicateswhose WSD are semi-supervised and thosewhose WSD are not supervised.
Somepredicates have collocations successfullyretrieved from HowNet examples in which theword sense is already identified.
Thesecollocations are diffused in MDL filtering andplay important roles in improving precision,while some other predicates do not have suchresource.
In Table 4, those unsupervisedpredicates are ???
(fall)?, ??
(collapse)?, ???
(exquisite)?, ???
(dumb)?, ???(wide)?,???
(develop)?
in Subj-Preds and ???
(spread)?, ???
(brush)?, ???
(get into)?,??
(bring)?, and ???(mar)?
in Pred-Objs.The other predicates are semi-supervised.
Ascan be seen in Table 4, most of theseunsupervised predicates generally have aprecision of 40%-60%, while those semi-supervised predicates enjoy are much higherprecision between 50%-100%.
The explanation1244for the result is straight forward.
When onesense collocation of one word collocation iscorrectly identified, by way of ParadigmaticRedundancy Principle, the sense collocationwhich is similar to the correctly identified willhave a higher modified frequency and is thussingled out as the best choice.
This feature ofMDL has great significance in the process ofannotating large scale collocation data.
Withonly a small number of annotated collocationsfor each predicate, a fairly high precision canbe achieved for all the rest of the data throughMDL.5 ConclusionThe present paper believes that the Word-Class Model gives the fullest description forselectional preference and thus makes effortsto disambiguate predicates in selectionalpreferences.
From the perspective of semanticsystem, two principles of semantic redundancy,namely the Syntagmatic Redundancy Principleand Paradigmatic Redundancy Principle, areproposed in the paper and are applied in WSDin SP via Association Computation andMinimum Description Length.
Theexperiments show that the approach proposedis fairly encouraging in disambiguation ofpolysemous predicates, especially under semi-supervised conditions when a small portion ofdata is annotated.
With such a tool, we are ableto build large scale selectional preferenceknowledge database based on Word-ClassModels, which can be applied in various tasks,of which metaphor recognition is the particularone we bear in mind.AcknowledgementThis work is supported by Chinese NationalFund of Social Science under Grant07BYY050 and Chinese National ScienceFund under Grant 60773173 and ChineseNational Fund of Social Science under Grant10CYY021.
We are also grateful to theautonomous reviewers for their valuableadvice and suggestions.ReferencesAgirre, E., and D. Mart?nez.
2001.
Learning class-to-class selectional preferences.
Paper read atProceedings of the Conference on NaturalLanguage Learning, at Toulouse, France.Barron, A. R., J. Rissanen, and B. Yu.
1998.
TheMinimum Description Length Principle incoding and modeling.
IEEE Transactions onInformation Theory 44 (6):2743-2760.Brockmann, C., and M. Lapata.
2003.
Evaluatingand combining approaches to selectionalpreference acquisition.
Paper read at Proceedingsof the European Association for ComputationalLinguistics, at Budapest, Hungary.Ciaramita, M., and M. Johnson.
2000.
Explainingaway ambiguity: Learning verb selectionalpreference with Bayesian networks.
InProceedingsofthe18thInternationalConferenceonComputationalLinguistics (COLING 2000), 187-193.Dong, Z.
2006.
HowNet and the Computation ofMeaning.
River Edge, NJ: World Scientific.Erk, K. 2007.
A Simple, Similarity-based Model forSelectional Preferences.
Paper read atProceedings of the 45th Annual Meeting of theAssociation of Computational Linguistics, atPrague, Czech Republic.Firth, J. R. 1957.
A Synopsis of Linguistic Theory,1930-1955.
In Studies in Linguistic Analysis.Oxford: Blackwell, 1-32.Han, J., and M. Kamber.
2006.
Data Ming:Concepts and Techniques.
Singapore: Elsevier.Jia Yuxiang and Yu Shiwen.
2008.
AutomaticAcquisition of Selectional Preference and ItsApplication to Metaphor Processing.
Paper readat the Fourth National Student Conference onComputationl Linguistics, at Taiyuan, Shangxi,China.Li, H., and N. Abe.
1998.
Generalizing CaseFrames Using a Thesaurus and the MDLPrinciple.
Computational Linguistics 24 (2):217-244.Light, M., and W. Greiff.
2002.
Statistical modelsfor the induction and use of selectionalpreferences.
Cognitive Science 87:1-13.Liu, Qun and Li Sujian.
2002.
Word SimilarityComputation Based on HowNet.
In Proceedingsof the 3rd Chinese Lexical Semantics.
Taibei,China.Lyons, J.
1977.
Semantics.
Cambridge: CambridgeUniversity Press.1245MacKay, D. J. C. 2003.
Information Theory,Inference, and Learning Algorithms.
Cambridge:Cambridge University Press.McCarthy, D., and J. Carroll.
2003.
DisambiguatingNouns, Verbs, and Adjectives UsingAutomatically Acquired Selectional Preferences.Computational Linguistics 29 (4):639-654.Merlo, P., and S. Stevenson.
2001.
Automatic VerbClassification Based on Statistical Distributionsof Argument Structure.
ComputationalLinguistics 27 (3):374-408.Michell, Tom M.. Machine Learning.
Translated byZen Huajun and Zhang Yinkui.
Beijing: ChinaMachine Press.Resnik, P. 1996.
Selectional constraints: aninformation-theoretic model and itscomputational realization.
Cognition 61:127-159.Qu, Weiguang.
2008.
Lexical SenseDisambiguation in Modern Chinese.
Beijing:Science Press.Wu, Yunfang, Duan Huiming and Yu Shiwen.
2005.Verb?s Selectional Preference on Object.
Spokenand Written Language in Practice 2005(2):121-128.Yarowsky, D. 1995.
Unsupervised Word SenseDisambiguation Rivaling Supervised Methods.Paper read at Proceedings of the 33rd AnnualMeeting of the Association for ComputationalLinguistics, at Cambridge, MA.Zheng, Xuling, Zhou Changle, Li Tangqiu andChen Yidong.
2007.
Automatic Acquisition ofChinese Semantic Collocation Rules Based onAssociation Rule Mining Technique.
Journal ofXiamen University (Natural Science) 46(3):331-336.1246
