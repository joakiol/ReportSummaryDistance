Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 953?963,Denver, Colorado, May 31 ?
June 5, 2015.c?2015 Association for Computational LinguisticsProsodic boundary information helps unsupervised word segmentationBogdan Ludusan, Gabriel Synnaeve and Emmanuel DupouxLaboratoire de Sciences Cognitives et PsycholinguistiqueEHESS / ENS / CNRS29 rue d?Ulm, 75005 Paris, Francebogdan.ludusan@ens.fr, gabriel.synnaeve@gmail.com,emmanuel.dupoux@gmail.comAbstractIt is well known that prosodic information isused by infants in early language acquisition.In particular, prosodic boundaries have beenshown to help infants with sentence and word-level segmentation.
In this study, we extendan unsupervised method for word segmen-tation to include information about prosodicboundaries.
The boundary information usedwas either derived from oracle data (hand-annotated), or extracted automatically witha system that employs only acoustic cuesfor boundary detection.
The approach wastested on two different languages, English andJapanese, and the results show that boundaryinformation helps word segmentation in bothcases.
The performance gain obtained for twotypologically distinct languages shows the ro-bustness of prosodic information for word seg-mentation.
Furthermore, the improvementsare not limited to the use of oracle informa-tion, similar performances being obtained alsowith automatically extracted boundaries.1 IntroductionProsodic information is thought to play a fundamen-tal role in early language acquisition, and provideinfants with rich structural information about theirlanguage (Christophe et al, 1997).
In particular,prosody has been claimed to help infants find wordboundaries (Christophe and Dupoux, 1996).
New-borns are able discriminate between disyllables thatcontains vs. does not contain a phonological phraseboundary (Christophe et al, 1994; Christophe et al,2001), showing that they are able to encode the cor-responding prosodic cues.
Nine-month olds showevidence of parsing utterances into prosodic units,and show ?surprise?
when a pause is inappropriatelyinserted inside as opposed to between these units(Jusczyk et al, 1992; Gerken et al, 1994).
Ten to 13month olds show evidence of using prosodic units toparse utterances into words, as they fail to recognizea familiar word if it appears to straddle a prosodicboundary (Gout et al, 2004).Curiously enough, however, prosody is not usedvery much in unsupervised models of language ac-quisition, and in particular, in models of word seg-mentation.
Most such models use text as input, andapply some form of lexical optimization.
For in-stance, Brent and Cartwright (1996) used a Min-imal Description Length Principle to optimize thesize of the description of a corpus.
State of the artsystems use hierarchical Bayesian models (Goldwa-ter et al, 2009) which parse a corpus into wordsor other linguistic units with a bias to reuse pre-viously parsed elements.
Adaptor Grammars is ageneric framework which enables to formulate suchBayesian models within an overarching architecturebased on probabilistic context free grammars (John-son et al, 2007).
Such models have been used tostudy the role of linguistic information such as syl-labic structure (Johnson and Goldwater, 2009), mor-phology (Johnson, 2008), function words (Johnsonet al, 2014), as well as the role of non-linguisticcontext (Synnaeve et al, 2014).
To our knowledge,only one paper studied the role of prosodic informa-tion (B?orschinger and Johnson, 2014).
In this study,the authors used the role of word stress in constrain-ing word segmentation (as in stress languages, thereis only one main stress per word).953Here, we test whether prosodic boundaries coulddirectly help symbolic word segmentation by pro-viding some word boundaries ?for free?, as this wasalready shown to be true in the case of signal-basedterm discovery systems (Ludusan et al, 2014).
Be-ing a feasibility study, we will use gold prosodicboundaries in order to quantify what is the maxi-mum gain we can expect using this type of informa-tion.
In addition to that, we test whether prosodicboundaries automatically derived from the speechsignal (Ludusan and Dupoux, 2014) could also pro-vide a performance gain.
As this study relies onthe existence of prosodic information (either gold,or derived from speech), we did not use the standardcorpora used in these studies (the Bernstein-Ratnercorpus), but introduced three new corpora, two inEnglish and one in Japanese.The paper is structured as follows: In the nextsections we introduce the systems employed in thisstudy - the prosodic boundary detection system insection 2 and the word segmentation procedure insection 3.
Next, we present the datasets used in theexperiments, with the results obtained being illus-trated in section 5.
The paper will conclude with ageneral discussion and some final remarks.2 Prosodic annotationThere are numerous studies in the speech process-ing literature focusing on the detection of prosodicboundaries (e.g.
Wightman and Ostendorf (1991),Ananthakrishnan and Narayanan (2008), Huang etal.
(2008), Jeon and Liu (2009), just to name afew).
While the approaches taken vary betweenthese studies, they tend to use either supervisedlearning, thus needing large, prosodically annotatedcorpora, or higher level information (syntactic, lex-ical, etc) which would also require further annota-tions.
Since unsupervised word segmentation is aprocess that requires low resources (only symbolictranscription), we have decided to use for the auto-matic detection of prosodic boundaries a previouslyproposed method which employs only acoustic cuesthat can be extracted from the speech signal (Ludu-san and Dupoux, 2014).The algorithm takes into consideration fouracoustic cues which had been shown, in the lan-guage acquisition literature, to be used by young in-fants for the recognition of prosodic boundaries.
Thecues correspond to the following phenomena thatoccur next to prosodic breaks: silent pauses, finallengthening, initial strengthening and F0 reset.
Theacoustic cues were extracted at the syllable level andthey include: the duration of the pause following thesyllable (pause cue), the syllable nucleus duration(nucleus cue), the distance between the nucleus on-set of the current syllable and that of the followingone (onset cue) and the difference between the F0end value of the current syllable and the F0 begin-ning value of the following syllable (F0 reset cue).The nucleus and onset cues are computed for all thesyllables, the later being a combination of the nu-cleus cue, pause cue and the onset of the followingsyllable, which is the domain of the initial strength-ening phenomenon.
The pause cue is set to 0 forsyllables not followed by a silence pause, while F0reset is only computed for syllables which are at alocal minimum for F0, otherwise it is set to 0.
Then,for each individual cue function except pause, weconsidered only the values which were local max-ima, the other values being set to 0.Once a numerical value for each of the cues is ob-tained, they are standardized between 0 and 1 andcombined in a detector function, by summing themup.
The local maxima of the detector function arethen obtained and the syllables corresponding to themaxima will be considered as prosodic boundarycandidates.
Next, a thresholding of these values isapplied and all the right-hand boundaries of the syl-lables greater or equal to this threshold are markedas prosodic boundaries.
This operation is followedby a second step in which prosodic boundaries aremarked based on a different rule, rule that we wouldcall conjunction of cues.
This rule was inspired bythe results of several studies in the infant literature(Seidl, 2007; Wellmann et al, 2012) showing thatmost prosodic boundaries tend to be marked by morethan one acoustic cue.
Taking these findings into ac-count, we could also mark as prosodic boundaries allsyllables which are signalled by at least two differ-ent cues, regardless of the value of these cues.
Thus,by employing the conjunction of cues we can give ahigher weight to a group of cues which, by appear-ing together, mark more reliably the presence of aboundary, in the hope that it would increase recallwithout decreasing too much the precision.954Figure 1: Speech waveform and corresponding detector function employed for prosodic boundary detection of thephrase: ?My tape machine records well, but the knobs are too small, the buttons are flimsy and the counter misplaced?
(for details, see (Ludusan and Dupoux, 2014)).The parameters of the algorithm: the combinationof cues, the cut-off threshold and the combinationof conjunction of cues are obtained on a hold-outset, by aiming to maximize the performance of thesystem on that particular set.The prosodic boundary detection procedure is il-lustrated in Figure 1 for the following utterance:?My tape machine records well, but the knobs aretoo small, the buttons are flimsy and the countermisplaced?.
The waveform of the speech signal isshown in the upper panel, with prosodic boundariesmarked with dashed lines.
In the lower panel are thevalues of the computed detector function, for eachsyllable, and the contribution of each of the cues to-wards the value of the function (the asterisk denotesthe position of the syllable nucleus).
The syllablescorresponding to local maxima of the detector func-tion (syllables 2, 4, 7, 10, 13, 17, 19, 21 and 25)would be considered as possible candidates for theposition of a prosodic boundary.
Provided that theirvalue is higher than the decision threshold, they willbe marked as actual boundaries.
For example, if thethreshold is set to the first percentile of the function,all the candidates will be kept, for the 50th percentileonly syllables 10, 13, 17 and 25 will be considered,while a threshold equal to the value of the 100th per-centile will leave only syllable 13 to be marked as aboundary.
If we also use what we called conjunc-tion of cues, and we set the cues to be the nucleusand the onset, syllables 10, 13, 22 and 25 will bemarked as boundary placeholders, regardless of thefact they are or not a local maximum or they pass ornot over the decision threshold.3 Word segmentation models3.1 Adaptor grammarsAdaptor Grammars (AGs) are an extension of prob-abilistic context-free grammars (PCFGs) that learnprobability of entire subtrees as well as probabil-ities of rules (Johnson et al, 2007).
A PCFG(N,W,R, S, ?)
consists of a start symbol S, N andW disjoints sets of nonterminals and terminal sym-bols respectively.
R is a set of rules producing ele-ments of N or W .
Finally, ?
is a set of distributionsover the rules RX,?X ?
N (RXare the rules thatexpand X).
An AG (N,W,R, S, ?, A,C) extendsthe above PCFG with a subset (A ?
N ) of adaptednonterminals, each of them (X ?
A) having an as-sociated adaptor (CX?
C).
An AG defines a dis-955tribution over trees GX,?X ?
N ?W .
If X /?
A,then GXis defined exactly as for a PCFG:GX=?X?Y1...Yn?RX?X?Y1...YnTDX(GY1.
.
.
GYn)With TDX(G1.
.
.
Gn) the distribution over treeswith root node X and each subtree ti?
Gii.i.d.If X ?
A, then there is an additional indirection(composition) with the distribution HX:GX=?X?Y1...Yn?RX?X?Y1...YnTDX(HY1.
.
.
HYn)HX?
CX(GX)We used CXadaptors following the Pitman-Yorprocess (PYP) (Perman et al, 1992; Teh, 2006) withparameters a and b.
The PYP generates (Zipfian)type frequencies that are similar to those that oc-cur in natural language (Goldwater et al, 2011).Metaphorically, if there are n customers and m ta-bles, the n+ 1th customer is assigned to table zn+1according to (?kis the Kronecker delta function):zn+1|z1.
.
.
zn?ma+ bn+ b?m+1+m?k=1nk?
an+ b?kFor an AG, this means that adapted non-terminals(X ?
A) either expand to a previously generatedsubtree (T (X)k) with probability proportional tohow often it was visited (nk), or to a new subtree(T (X)m+1) generated through the PCFG with prob-ability proportional to ma+ b.3.2 Grammars including prosodic informationThe baseline that we are using is commonly calledthe ?Colloc3-Syll?
model (Johnson and Goldwater,2009) and is reported at 87% token F-score on thestandard Brent version of the Bernstein-Ratner cor-pus corpus.
It posits that sentences are composed of3 hierarchical levels of collocations, the lower levelbeing collocations of words, and words are com-posed of syllables.
Goldwater et al (2009) showedhow an assumption of independence between words(a unigram model) led to under-segmentation.
So,above the Word level, we take the collocations (co-occurring sequences) of words into account.Sentence?
Colloc3+Colloc3?
Colloc2+Colloc2?
Colloc1+Colloc1?Word+Word?
StructSyllwhere the rule Colloc2 ?
Colloc1+is imple-mented by:Colloc2?
Collocs1Collocs1?
Colloc1Collocs1?
Colloc1 Collocs1Word splits into general syllables and initial- orfinal- specific syllables in StructSyll.
In English,syllables consist of onsets or codas (producing con-sonants), and nuclei (vowels).
Onsets, nuclei andcodas are adapted, thus allowing this model to mem-orize sequences or consonants or sequences of vow-els, dependent on their position in the word.
Conso-nants and vowels are the pre-terminals, their deriva-tion is specified in the grammar into phonemes ofthe language.
In Japanese, syllables are adapted andare composed either of (Consonant-)Vowel(-Nasal)or Nasal.
Phonemes are annotated either as conso-nant, vowel, or nasal (the moraic nasal /N/).To allow for these grammars to use the prosodicinformation, we modify them so that prosodicboundaries are considered as breaks at a given levelof collocations (or words).
For instance we describebelow how we change a Colloc3-Syll grammar tomake use of the prosodic boundaries information atthe lower level of collocations (Colloc1), by usingthe terminal symbols ?|?
(the rest is unchanged):Colloc2?
Collocs1Collocs1?
Colloc1Collocs1?
Colloc1 | Collocs1Collocs1?
Colloc1 Collocs1Colloc1?Word+We produced and tested grammars which incor-porated these prosodic boundary annotations at dif-ferent levels, from Collocs3 down to Word level.956Figure 2: Colloc3-Syll based grammars scores on the BU and CSJ datasets.
We show the best results without prosodicannotation, with hand-annotated prosody information (oracle), and with automatically derived annotations that maxi-mize either F-score, precision, or recall of prosodic boundaries.4 MaterialsThe experiments were performed on two distinctlanguages: English and Japanese.
For English, wehave chosen the Boston University radio news (BU)corpus (Ostendorf et al, 1995) and the LUCID cor-pus (Baker and Hazan, 2010).
The first one, theBU corpus, consists of broadcast news recorded byprofessional speakers and is widely used in speechprosody research.
Here, we only used the prosodyannotated portion of the corpus, containing about 3hours of recordings, labelled for accent tones andprosodic breaks following the ToBI standard forAmerican English (Silverman et al, 1992).
Level 3and level 4 break indices, corresponding to interme-diate and intonational phrase boundaries, were con-sidered in this work.
The recordings belonging to 6speakers were used for the experiments, while thosebelonging to one speaker were employed as a devel-opment set, for setting the parameters of the auto-matic boundary detection algorithm.
The evaluationset was divided into utterances, at pauses longer orequal to 200 ms, giving in total 2,273 utterances hav-ing 27,980 tokens.While the BU corpus has the advantage of beingannotated for prosodic boundaries, and thus beingable to provide us with an upper bound of the perfor-mance increase that the prosodic information couldbring, it is not large enough to give state-of-the-artresults using AG.
For this, we have taken a largecorpus of spontaneous interactions, the LUCID cor-pus, and used it in connection to automatically de-tected prosodic boundaries.
Due to the more spon-taneous nature of these materials, we have definedutterances as being stretches of speech bounded bypauses at least 500 ms long.
Since durational infor-mation is needed for the detection of the prosodicboundaries, the corpus was force aligned using theUPenn aligner (Yuan and Liberman, 2008).
Fromthe utterances obtained we have excluded all utter-ances containing hesitations or words not present inthe dictionary of the aligner.
Thus, a total of 21,649utterances were eventually used in the experiments,corresponding to 118,640 tokens.For Japanese, a subpart of the core of the Corpusof Spontaneous Japanese (CSJ) was used (Maekawa,2003).
It contains more than 18 hours of academicrecordings from 70 speakers and it was annotatedfor prosodic boundaries using the X-JToBI standard(Maekawa et al, 2002).
Oracle level 2 and level 3prosodic breaks (accentual and intonational phrases)were used in this study as well as automatically ob-tained boundaries.
The data set aside for the settingof parameters belongs to 5 speakers, with the record-ings of the rest of the speakers used for the evalua-tion.
We used the utterance markings provided withthe corpus, the evaluation set containing 21,974 ut-terances and 195,744 tokens.While previous studies on word segmentationhave focused on infant-directed speech (IDS), weemploy here corpora of adult-directed speech.
Thereason behind this choice is the fact that IDS corpora957Model F-score Precision RecallmaxFscore .608 .705 .535maxPrecision .391 .986 .244maxRecall .496 .377 .724Table 1: Automatic prosodic boundary annotation perfor-mance on the BU corpus.are not, generally, annotated for prosody.
We wouldexpect that experiments on ADS would improve lessover the baseline, when compared to those run onIDS, due to its less exaggerated prosody and its re-duced number of prosodic boundaries.
Thus, anyimprovement found on ADS, would be found alsoon IDS.The corpora used have all been transcribed pho-netically, but, for the purpose of this paper, we havetransformed this phonetic annotation into a phone-mic one.
For the English databases the mappingsproposed by Lee and Hon (1989) were employed,with two notable exceptions: vowels /er/ and /axr/were mapped to the phonemes /ah/ and /r/, while thesyllabic consonants /el/, /em/ and /en/ were mappedto the label /ah/ and their corresponding consonant(/l/, /m/ or /n/).
For Japanese, we employed the samemappings used by Boruta (2011).5 ResultsThe prosodic boundary procedure on the BU and theCSJ used oracle segmental (phonetic) information,while phonemes were force-aligned from word-levelannotation for the LUCID.
The prosodic boundarieswere evaluated with the classic measurements: pre-cision, recall and F-score.
The word segmentationtoken F-scores were obtained every 10 epochs (forless correlation due to the sampler) during the 100epochs (BU corpus), or the 200 epochs (LUCID andCSJ corpora) centered around the point of conver-gence, and their mean and standard deviation com-puted.
The convergence point was determined bysmoothing the prior probability of the grammar witha sliding window and choosing the epoch where thenegative log probability was the lowest.5.1 EnglishThe best parameters of the prosodic boundary detec-tion system were searched for on the developmentset left aside for this purpose.
The F-score of theFigure 3: Colloc3-Syll based grammars scores on theBU dataset, comparing results without prosodic annota-tion, with those obtained by automatic prosodic bound-aries that maximize F-score, added at different levels inthe grammar.system was maximized and the best combination ofcues and conjunction of cues were pause+onset andpause+nucleus, respectively.
For these settings,we then determined the threshold values which gavethe best F-score, precision and recall for boundarydetection, which were further used to run the algo-rithm on the evaluation set.
The results obtained onthe evaluation set for the systems trying to maximizeF-score (maxFscore), precision (maxPrecision)or recall (maxRecall) are presented in Table 1.The word segmentation method was then run withthe grammars defined in section 3.2, with and with-out prosodic boundary information.
For the prosodyenhanced cases, both oracle and automatic bound-aries were employed.
The best results obtained onthe BU corpus, for each of the five settings, are il-lustrated on the left side of Figure 2.
It appears thatall cases that employ prosodic information improveover the baseline, with oracle boundaries giving a7% absolute performance gain.Next, we looked in more detail at the behaviourof the best system that uses automatic boundaries(maxFscore).
We present the token F-score ob-tained by this system for the different levels of thegrammar where the prosodic information is added.Although we obtained improvements on the BUcorpus, for all cases when prosodic information wasused, the overall results are far from state-of-the art958Figure 4: Colloc3-Syll based grammars scores on theLUCID dataset, comparing results without prosodic an-notation, with those obtained by automatic prosodicboundaries that maximize precision, added at differentlevels in the grammar.performance, due to the relatively small size of thecorpus.
For this reason, we chose to test on a big-ger English corpus, LUCID.
While this corpus isindeed larger, it has the disadvantage of not beingprosodically annotated.
Thus, we investigated onlythe cases when automatically determined prosodicboundaries are employed.
The detection of prosodicboundaries used the same parameters obtained onthe BU corpus but, since no prosodic annotation ex-ists, we were not able to perform the same evaluationof the boundaries, as we did for BU.The token F-scores for the best prosodic bound-ary setting (maxPrecision) are displayed in Figure4.
These results are closer to the state-of-the-art forEnglish, which stand at 87% token F-score.
Con-trary to the results on the BU corpus, the prosodyenhanced system improves over the baseline onlywhen the boundary information is added at Colloc2or Colloc3 level (best gain: 0.8% absolute value).While the improvements brought here tend to bequite small, compared to those obtained for BU, weare closer to ceiling value on LUCID and also thequality of the automatic boundaries might be lower,due to the different type of speech on which the pa-rameters of the model were found.With the Adaptor Grammar tending to slightlyover-segment the results, the inclusion of prosodyat Word or Colloc1 has increased the precisionModel F-score Precision RecallmaxFscore .469 .533 .418maxPrecision .398 .781 .267maxRecall .431 .353 .552Table 2: Automatic prosodic boundary annotation perfor-mance on the CSJ corpus.slightly, at the expense of a significantly lower re-call, and thus a lower overall F-score.
This over-segmentation trait was instead much more pro-nounced for the BU corpus, where the increase inprecision was accompanied only by a slight decreasein recall, brought the two measures closer together,and thus has maximized the F-score.5.2 JapaneseThe same procedure for parameter detection as forthe BU corpus was applied and the best cues ob-tained were pause+ onset, while the best combi-nation of conjunction of cues was pause+f0Reset.Table 2 illustrates the prosodic boundary results ob-tained on the CSJ evaluation set, for the systemsmaximizing F-score, precision and recall, respec-tively.Since oracle prosodic information was availablefor this corpus, we were able to compare the perfor-mance of the baseline to that of the oracle and au-tomatic boundaries enhanced system.
This compar-ison is displayed in Figure 2, right hand side.
Hav-ing a sizable corpus, the results are more similar tothe state-of-the-art for Japanese, reported in (Four-tassi et al, 2013) (55%).
Increases in performancecan be observed when hand-labelled prosody is in-troduced (12.3% absolute value), and also when au-tomatic boundaries (maxPrecision) are employed(10% absolute value).Similarly to the previous experiments, we displayin Figure 5 the comparison between the baseline andthe best system employing automatic boundaries(maxPrecision), for the different levels where theinformation is added.
It shows that prosody helps,regardless of the level where prosody is used, al-though it appears to favour the lower collocation lev-els.959Figure 5: Colloc3-Syll based grammars scores on theCSJ dataset, comparing results without prosodic annota-tion, with those obtained by automatic prosodic bound-aries that maximize precision, added at different levels inthe grammar.6 Discussion and ConclusionsWe have investigated the use of prosodic bound-ary information for unsupervised word discovery ina multilingual setting.
We showed that prosodicboundaries can improve word segmentation acrossboth languages even when automatically determinedboundaries are used.
We also illustrated that the wayin which to integrate prosody into word segmen-tation is not homogeneous across corpora, both interms of the level of collocation where these bound-aries are introduced, and in terms of the balance be-tween precision and recall, when it comes to usingautomatic boundaries.For the first issue, the results on BU suggest thatWord or Colloc1 would be the best level, those onLUCID show that either Colloc2 or Colloc3 wouldgive the best performance, while the scores on CSJfavors Colloc1 or Colloc2.
But, if we were todiscard the results on BU, due to its heavy over-segmentation and its small size, and use the collo-cation level giving the most balanced scores on theother two datasets, it appears that Colloc2 wouldbe the common denominator.
Besides giving themost balanced token scores it also gives the mostbalanced boundary scores, striking a good compro-mise between the under-segmentation produced byadding the prosody at lower levels and the over-segmentation tendency for boundaries introduced athigher levels.To investigate the second issue, a closer look tothe tables presenting the evaluation of the automaticboundaries (Table 1 and Table 2) is needed.
The bestword segmentation scores on BU were obtained forthe maxFscore system, but we can observe that thecondition also has a high precision (.705).
At thesame time, the best score on CSJ was obtained forthe maxPrecision system, the maxFscore sys-tem (with a precision of .533) giving no improve-ment over the baseline (see Figure 2).
Furthermore,maxRecall, which has very low precisions, seemsto behave similar to, or below the baseline, for bothdatasets.
Thus, it appears that a relatively high preci-sion for the prosodic boundaries is needed to obtainimprovements in word segmentation and, once thiscondition is fulfilled, any increase in recall wouldincrease the gain over the baseline.Further evidence supporting this can be foundwhen performing a word-based evaluation of theautomatic prosodic boundaries obtained.
For theBU and CSJ corpora, we computed the percentageof word boundaries found, out of the total wordboundaries in the corpora, and the proportion ofincorrect word boundaries from the total numberof boundaries found (see Table 3).
It shows thatthe systems that bring improvements over the base-line (maxFscore and maxPrecision for BU, andmaxPrecision for CSJ) have a relatively low rateof false alarms (lower than 6%).
At the sametime, the increase in performance can be obtainedeven without a high coverage of the corpus, themaxPrecision models achieving this with a cov-erage lower than 10%.Since all the resuls reported in this paper wereobtained using the state-of-the-art Adaptor Gram-mar model, Colloc3?Syll, we also verified thatour results are generalizable across different mod-els.
We created several AG models, by varyingthe following settings in the grammar: using eitherone or three collocation levels, and having knowl-edge or not of the syllabic structure.
This gave us,besides the already tested Colloc3?
Syll model,three new models: Colloc3?noSyll, Colloc?Sylland Colloc?noSyll, which were all tested on theCSJ.
When evaluating the token F-score obtainedusing these models, we can see improvements for allthe models, regardless of the nature of the prosodic960Corpus Model % found % incorrBUoracle 100 0maxPrecision 7.0 0.1maxFscore 20.3 5.7maxRecall 40.4 34.2CSJoracle 100 0maxPrec 9.9 0.04maxFscore 21.0 23.5maxRecall 32.8 51.3Table 3: Word boundary-based evaluation of the threesystems used for prosodic boundary detection.
We reportthe percentage of correct word boundaries found and thenumber of incorrect boundaries found, as a percentage ofall boundaries found.boundaries used.Before closing, we note that prosody seem tohelps differentially the segmentation of the two lan-guages we tested.
In Japanese we found improve-ments reaching 10 percentage points in F-score,whereas the improvements in English were moremodest (5 points for the BU, 1 point for the LU-CID), when automatic boundaries are used.
Thiscould be due to differences in the segmentationproblem across these two languages.
Indeed, wordsin Japanese are in their majority composed of severalsyllables, and many words contain embedded words,making the segmentation problem intrinsically moredifficult than in English, for which the large majorityof words are monosyllabic (Fourtassi et al, 2013).
Itis possible that prosody particularly helps those lan-guages with a polysyllabic lexicon, by helping pre-vent over-segmentation.While the current work examined the use ofprosodic boundaries for word segmentation in twolanguages, we would like to extend the study to morelanguages.
We would expect a similar behaviouralso for other languages, but it would be interest-ing to investigate the interaction between boundaryinformation and collocation level for other typolog-ically distinct languages.
Also, we have employedhere oracle segmental information for the automaticdetection of prosodic boundaries.
In the future weplan to completely automatize the process, by em-ploying segmental durations obtained with signal-based methods for speech segmentation.
Finally,prosody was introduced here by way of a discretesymbol, forcing us to make a binary decision.
Amore integrated model would enable to associateprosodic break with a probability distribution, overacoustic features, thereby achieving the joint learn-ing of segmentation and prosody.AcknowledgmentsThe authors would like to thank the three anony-mous reviewers for their insightful comments.
Theresearch leading to these results was funded bythe European Research Council (ERC-2011-AdG-295810 BOOTPHON).
It was also supported bythe Agence Nationale pour la Recherche (ANR-10-LABX-0087 IEC, ANR-10-IDEX-0001-02 PSL*),the Fondation de France, the?Ecole des Neuro-sciences de Paris, and the R?egion?Ile-de-France(DIM cerveau et pens?ee).ReferencesSankaranarayanan Ananthakrishnan and ShrikanthNarayanan.
2008.
Automatic prosodic event detec-tion using acoustic, lexical, and syntactic evidence.Audio, Speech, and Language Processing, IEEETransactions on, 16(1):216?228.Rachel Baker and Valerie Hazan.
2010.
LUCID: a cor-pus of spontaneous and read clear speech in British En-glish.
In Proceedings of DiSS-LPSS Joint Workshop,pages 3?6.Benjamin B?orschinger and Mark Johnson.
2014.
Explor-ing the role of stress in Bayesian word segmentationusing Adaptor Grammars.
Transactions of the Associ-ation for Computational Linguistics, 2:93?104.Luc Boruta.
2011.
Indicators of allophony and phone-mehood.
Ph.D. thesis, Paris-Diderot University.Michael Brent and Timothy Cartwright.
1996.
Distribu-tional regularity and phonotactics are useful for seg-mentation.
Cognition, 61:3?125.Anne Christophe and Emmanuel Dupoux.
1996.
Boot-strapping lexical acquisition: The role of prosodicstructure.
The Linguistic Review, 13(3-4):383?412.Anne Christophe, Emmanuel Dupoux, JosianeBertoncini, and Jacques Mehler.
1994.
Do in-fants perceive word boundaries?
An empirical studyof the bootstrapping of lexical acquisition.
Journal ofthe Acoustical Society of America, 95:1570?1580.Anne Christophe, Teresa Guasti, Marina Nespor, Em-manuel Dupoux, and Brit van Ooyen.
1997.
Reflec-tions on prosodic bootstrapping: its role for lexical andsyntactic acquisition.
Language and Cognitive Pro-cesses, 12:585?612.961Anne Christophe, Jacques Mehler, and N?uria Sebasti?an-Gall?es.
2001.
Perception of prosodic boundary corre-lates by newborn infants.
Infancy, 2(3):385?394.Abdellah Fourtassi, Benjamin B?orschinger, Mark John-son, and Emmanuel Dupoux.
2013.
Whyisenglish-soeasytosegment?
In CMCL 2013.LouAnn Gerken, Peter Jusczyk, and Denise Mandel.1994.
When prosody fails to cue syntactic structure:9-month-olds?
sensitivity to phonological versus syn-tactic phrases.
Cognition, 51(3):237?265.Sharon Goldwater, Thomas Griffiths, and Mark John-son.
2009.
A Bayesian framework for word segmen-tation: Exploring the effects of context.
Cognition,112(1):21?54.Sharon Goldwater, Thomas Griffiths, and Mark Johnson.2011.
Producing power-law distributions and damp-ing word frequencies with two-stage language mod-els.
Journal of Machine Learning Research, 12:2335?2382.Ariel Gout, Anne Christophe, and James Morgan.
2004.Phonological phrase boundaries constrain lexical ac-cess II.
Infant data.
Journal of Memory and Language,51(4):548?567.Jui-Ting Huang, Mark Hasegawa-Johnson, and ChilinShih.
2008.
Unsupervised prosodic break detection inMandarin speech.
In Proc.
of Speech Prosody, pages165?168.Je Hun Jeon and Yang Liu.
2009.
Semi-supervised learn-ing for automatic prosodic event detection using co-training algorithm.
In Proceedings of the Joint Con-ference of the 47th Annual Meeting of the ACL andthe 4th International Joint Conference on Natural Lan-guage Processing of the AFNLP, pages 540?548.Mark Johnson and Sharon Goldwater.
2009.
Improvingnonparameteric Bayesian inference: experiments onunsupervised word segmentation with adaptor gram-mars.
In Proceedings of Human Language Technolo-gies: The 2009 Annual Conference of the North Ameri-can Chapter of the Association for Computational Lin-guistics, pages 317?325.Mark Johnson, Thomas Griffiths, and Sharon Goldwa-ter.
2007.
Adaptor grammars: A framework for speci-fying compositional nonparametric bayesian models.Advances in neural information processing systems,19:641.Mark Johnson, Anne Christophe, Emmanuel Dupoux,and Katherine Demuth.
2014.
Modelling functionwords improves unsupervised word segmentation.
InProceedings of the 52nd Annual Meeting of the Associ-ation for Computational Linguistics (Volume 1: LongPapers), pages 282?292.Mark Johnson.
2008.
Unsupervised word segmentationfor Sesotho using adaptor grammars.
In Proceedingsof the Tenth Meeting of ACL Special Interest Groupon Computational Morphology and Phonology, pages20?27.Peter Jusczyk, Kathy Hirsh-Pasek, Deborah Kemler-Nelson, Lori Kennedy, Amanda Woodward, and JuliePiwoz.
1992.
Perception of acoustic correlates of ma-jor phrasal units by young infants.
Cognitive Psychol-ogy, 24(2):252?293.Kai-Fu Lee and Hsiao-Wuen Hon.
1989.
Speaker-independent phone recognition using hidden Markovmodels.
Acoustics, Speech and Signal Processing,IEEE Transactions on, 37(11):1641?1648.Bogdan Ludusan and Emmanuel Dupoux.
2014.
To-wards low-resource prosodic boundary detection.
InProceedings of SLTU, pages 231?237.Bogdan Ludusan, Guillaume Gravier, and EmmanuelDupoux.
2014.
Incorporating prosodic boundariesin unsupervised term discovery.
In Proceedings ofSpeech Prosody, pages 939?943.Kikuo Maekawa, Hideaki Kikuchi, Yosuke Igarashi, andJennifer Venditti.
2002.
X-JToBI: an extended J-ToBIfor spontaneous speech.
In Proceedings of INTER-SPEECH, pages 1545?1548.Kikuo Maekawa.
2003.
Corpus of SpontaneousJapanese: Its design and evaluation.
In ISCA &IEEE Workshop on Spontaneous Speech Processingand Recognition.Mari Ostendorf, Patti Price, and Stefanie Shattuck-Hufnagel.
1995.
The Boston University radio newscorpus.
Linguistic Data Consortium, pages 1?19.Mihael Perman, Jim Pitman, and Marc Yor.
1992.Size-biased sampling of Poisson point processes andexcursions.
Probability Theory and Related Fields,92(1):21?39.Amanda Seidl.
2007.
Infants use and weighting ofprosodic cues in clause segmentation.
Journal ofMemory and Language, 57:24?48.Kim Silverman, Mary Beckman, John Pitrelli, Mari Os-tendorf, Colin Wightman, Patti Price, Janet Pierrehum-bert, and Julia Hirschberg.
1992.
TOBI: a standard forlabeling English prosody.
In Proceedings of ICSLP,pages 867?870.Gabriel Synnaeve, Isabelle Dautriche, BenjaminB?orschinger, Mark Johnson, and Emmanuel Dupoux.2014.
Unsupervised word segmentation in context.
InProceedings of COLING 2014, the 25th InternationalConference on Computational Linguistics: TechnicalPapers, pages 2326?2334.Yee Whye Teh.
2006.
A hierarchical Bayesian languagemodel based on Pitman-Yor processes.
In Proceedingsof the 21st International Conference on ComputationalLinguistics and the 44th annual meeting of the Associ-ation for Computational Linguistics, pages 985?992.962Caroline Wellmann, Julia Holzgrefe, Hubert Trucken-brodt, Isabell Wartenburger, and Barbara H?ohle.
2012.How each prosodic boundary cue matters: evidencefrom German infants.
Frontiers in psychology, 3.Colin Wightman and Mari Ostendorf.
1991.
Automaticrecognition of prosodic phrases.
In Proceedings ofAcoustics, Speech, and Signal Processing, 1991 Inter-national Conference on, pages 321?324.Jiahong Yuan and Mark Liberman.
2008.
Speaker iden-tification on the SCOTUS corpus.
In Proceedings ofAcoustics ?08.963
