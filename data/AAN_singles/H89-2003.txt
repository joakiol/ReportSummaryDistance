TIMING MODELS FOR PROSODY AND CROSS-WORDCOARTICULATION IN CONNECTED SPEECHMary E. BeckmanDepartment of LinguisticsOhio State UniversityColumbus, OH 43210ABSTRA~Gauging durations of acoustic intervals is useful for recognizing the phrasingand stress pattern of an utterance.
It aids in the recognit ion of segmentsthat are differentiated by duration, and it can improve segment recognition ingeneral because knowing the stress and phrasing reduces the vocabulary searchspace.
However, models of speech timing that compute acoustic segment lengthscannot capture spectral dynamics, and they rapidly become unwieldy inconnected speech, where many effects interact to determine interval durations.I wil l  review two results from recent work on art iculatory dynamics thatsuggest a more workable alternative.
Browman and Goldstein have developed ageneral model of the timing of articulatory gestures.
Using this model theycan describe many ass imi lat ions and apparent deletions of segments at wordboundaries in terms of simple manipulat ions of intergestural  timing, anaccount which should be useful for predict ing the lenit ion pattern and forinterpreting the resulting spectra in order to recover the underly ing form.Beckman, Edwards, and Fletcher have applied Browman and Goldstein's model inexamining art iculatory correlates of global tempo decrease, phrase-f inalposition, and sentence accent.
Their data show that these three differentlengthening effects are functionally distinct and suggest that the kinematicsof formant transit ions and ampl i tude curves can be used for dist inguishingamong the effects to parse the prosodic organization of an utterance.INTRODUCTIONVarlation in timing is one of the most pervasive features of speech.
It playsa role at all levels.
A particular pattern of vowel lengthening, for example,can cue the segmental contrast between \[ae\] and \[El in 'bad' versus 'bed' andbetween the following \[d\] and \[t\] in 'bad' versus 'bat' (e.g., Nooteboom 1973;Klatt 1976; Raphael 1972).
In speech synthesis, manipulat ing the t imingpattern by changing the lengths of acoustic segments can also alter theperceived stress pattern or intonational phrasing of an utterance (e.g., Fry1958; Klatt 1979; Scott 1982).
It is hardly surprising, therefore, thatknowledge of segment durations can improve speech recognition.
For example,Deng, Lennig, and Mermelstein (1989) have shown that information about vowelinterval durations dramatically increases recognition rates in a Hidden MarkovModel isolated-word recognit ion system.
Similarly, Lieberman (1960) showed12that vowel-interval durations augmented by rudimentary RMS amplitude measurescan identify stressed syllables.
Using interval durations to parse the stresspattern in this way can drastical ly reduce the search space in large-vocabulary isolated-word recognit ion systems (Waibel 1988).
Knowing thestress pattern should prove even more crucial to recognit ion of connectedutterances, because of the way that stress interacts phonologically with thephrasing to cue the prosodic organizat ion of the utterance into words andlarger phonological  units (Nespor and Vogel 1986; Beckman, de Jong, andEdwards 1987).
An accurate prediction of assimilations, deletions, and otherlenitlon rules across word boundaries also depends on the phonologoicalphrasing (Nespor and Vogel 1982; Zek and Inkelas 1987).If knowledge just of acoustic interval durations can aid recognition in bothisolated words and connected speech, what if we were to use finer measures oftiming?
There are many indications that knowledge of the temporal structurewithin acoustic segments could improve recognition even more.
For example, inaddition to being longer and having a lower first formant, \[i\] (as in 'beat')differs from \[I\] (as in 'bit') in having a faster, shorter second formanttransit ion that starts later in the syllable (Neary and Assman 1986).
Othertense-lax vowel pairs also show this difference in spectral kinematics.Similarly, in addit ion to being shorter in overall duration before a word-final voiceless obstruent, vowels tend to have shorter, faster first-formanttransit ions (Summers 1987).
A better understanding of the control of suchtiming patterns in speech production could lead to more accurate accounts ofthe kinematic differences and to more wieldy predictions of interactions amongthe many factors that influence segment-interval duration.In the last decade, we have made tremendous advances toward a betterunderstanding of timing control by looking in detail at the kinematics of thearticulatory gestures involved in producing speech.
Fol lowing a proposal byFowler  et al (1980), speech scientists have worked at applying a generalmodel of motor control orglnally developed to account for such things as thecoordinat ion of f lexor and extensor muscles in maintain ing gait acrossdifferent terrains and speeds or the coordination of shoulder and elbow jointsin different reaching tasks (e.g.
Ostry, Keller, and Parush 1983; Kelso et al1985; Saltzman 1986).Two recent results of this work seem particularly relevant to achieving betterrecognition models.
One is Browman and Goldstein's (1987) application of theirtask-dynamlc model to explain many common lenitlons across word boundaries incasual or fast speech.
The other is Beckman, Edwards, and Fletcher's (1989)appl icat ion of the model in understanding the control of three differentlengthening effects associated with slow tempo, phrase-f inal  position, andnuclear sentence stress.
In the next two sections, I will describe these tworesults and their implications for speech recognition in more detail.13CROSS-WORD LEHITIONS AND THE GESTURAL SCOREOne of the biggest problems in recognizing connected speech is coarticulationacross word boundaries.
This coarticulation can cause a drastic restructuringof the spectral character ist ics of segments at the edges of words.
Finalsegments can change by assimilation to the following word's initial segment,and they can even be seemingly deleted, as shown in the examples in (1), whichare taken from Brown (1977) and Catford (1977).
(i)* a. assimilations/dhls shap/ ->/huhndruhd paUndz/ ->\[dhlshshap\]\[huhndruhbpaUndz\]'this shop''hundred pounds'b.
deletion/muhst bi/ -> \[muhsbi\] 'must be'c.
deletion and assimlation/graUnd prEshR/ -> \[graUmprEshR\] 'ground pressure'Such lenit ions are ubiquitous in casual or fast speech and are not uncommoneven in fluent read speech.
They can occur within the word as well as at wordboundaries, as in the assimilative devoicing or deletion of the first vowel in\[ptEIto\] for 'potato' or the apparent delet ion of the medial  \[t\] in \[twEni\]for 'twenty'.In these examples, we have described the lenit ions as if they were discretechanges in the symbolic representation of the segment string.
If the lenitionsare approximated by an al lophonic analysis in this way, the word- internalcases could be accounted for in isolated-word recognition systems by encodingall common patterns as variant pronunciat ions in the lexicon.
This could beaccomplished, for example, by providing separate spectral  templates* Here and elsewhere, I use the following ARPABET-Iike substitutions for thestandard phonetic symbols:\[I\] = high front lax vowel\[E\] = mid front lax vowel\[ae\] = low front vowel\[U\] = high back lax vowel\[0\] = low-mld back lax vowel\[uh\] = mid-central or reduced vowel ("carrot" or schwa)\[R\] = rhotaclzed mid-central vowel (i.e., syllabic \[r\])\[sh\] = voiceless alveopalatal stop\[zh\] = voiced alveopalatal stop\[dh\] = voiced interdental fricative\[th\] = voiceless interdental fricative\[D\] = flap14for each variant pronunciation or by listing alternate paths in an allophonlc-segment-based HHM model (Kopec and Bush 1985).
Lenltlons across wordboundaries in connected speech can also be handled by pre-compiling alternateHHM paths for every possible transit ion (Bush and Kopec 1987), but this isfeasible only when the vocabulary size is very small.
Thus, cross-wordsegment lenitions cause a particular problem for large-vocabulary recognitionsystems even when explicit phonetic knowledge is incorporated in the form ofallophonlc variants for acoustic segments.A possible solution is to base the lexical representat ion of the al lophonesnot on alternate paths through discrete phonological ly unanalyzed acousticintervals, but rather on alternate specifications of acoustic features in afeature-based recognition system (Stevens 1986).
The ass imi lat lon of \[s\] to\[sh\] in 'this shop' could then be handled by an expl icit  ass imi lat ion rulethat changes the acoustic features associated with the \[s\] segment from\[+anterior\] to \[-anterior\] in the context of the following \[-anterior\] segmentin the fol lowing word.
The apparent deletion of the \[t\] in 'must be',similarly, could be handled by a rule deleting the features associated with\[t\] stop release in the context of a fo l lowing obstruent segment.
If thissolution is adopted, the problem reduces to that of discovering the correctassimilation and deletion rules and the optimal acoustic feature system forstating these rules.A disadvantage of this approach is that these coarticulatory assimilations anddeletions look like a motley array of discrete rules when described in termsof feature changes and deletions.
Among the ways that models of articulatoryk inematics might contribute to speech recognit ion is in providing a moreexplanatory account of these cross-word lenitlons, an account that betterpredicts the patterns of assimilation and apparent deletion that are likely tooccur in any given context.
Browman and Goldstein (1987) have suggested anaccount of common lenltion patterns that unifies assimilations and deletionsinto a single process.The basis for Browman and Goldstein's account is the gestural score.
Browmanand Goldsteln, in conjuct ion with Saltzman and other col leagues at HasklnsLaboratories, have developed a task-dynamlc model in which utterances arerepresented as a principled orchestration of invariant artlculatory gestures.The gestures are modeled as target-speclfic movements in a second-order linearspring-mass system.
The orchestration specifies a given phasing for a gesturerelative to the relevant surrounding gestures.
The \[t\] of 'must be', forexample, is represented as an overdamped gesture of a given stiffness andunderlying amplitude specified for the task of making a complete closure withthe tongue tip near the alveolar ridge.
This alveolar closing gesture isspecified as concurrent with either a ballistic abductive glottal gesture or atotally adductlve glottal stop gesture, and as occuring at some time relativeto the opening gesture from the word- in i t ia l  \[m\] into the \[uh\] vowel.
The\[b\], s imi lar ly is composed of a labial closing gesture coupled to a glottalapproximation gesture, with the two gestures specified to occur at some timerelative to the oral and glottal gestures of the preceding \[t\].15Under this account, the apparent delet ion of the It\] can be modeled as theendpoint of a continuum of lesser to greater overlap between the tongue-tlpgesture in the \[t\] and the labial gesture in the \[b\].
If the two gesturesoverlap to any extent, the release of \[t\] tongue-tip closure will be masked bythe \[b\] labial closure.
That is, the usual aerodynamic consequences of theIt\] release -- namely, the burst, will be prevented by the closure upstream.In extreme cases, not just the release of the \[t\] but the entire tongue-t ipgesture can be hidden by the labial gesture, as Browman and Goldsteln haveshown in their examination of the movements of the tongue tip and lower llpand other movement traces recorded at the Tokyo X-ray mlcrobeam system(Kiritanl et al 1975).
Nolan (1989) shows s imi lar  cases of overlap betweendental and velar gestures as evident in patterns of contact measured by anelectro-palatograph.
In sequences such as 'late calls', the tongue-t lpcontact for the word-final It\] can overlap to a greater or lesser extent withthe tongue-body contact for the following word-inltial \[k\].In Browman and Goldstein's task-dynamlc model, ass imi lat ions such as theapparent substitution of \[sh\] for \[s\] in 'this shop', can also be specified asoverlap.
The two tongue-tlp constriction gestures for the fricatives overlapin time in the same way as the It\] and \[hi of 'must be'.
In this case,however, the overlap involves the same vocal tract subsystem.
Therefore, thekinematic consequence of the overlap is not a "hiding" of one gesture by theother, but a spatio-temporal "blending" of the two gestures, resulting in anuninterrupted \[sh\]-like spectral pattern.Thus, examination of the artlculatory patterns provides a single explanatoryaccount of the motley array of cross-word lenltion patterns.
Both the apparentsegment deletions and the feature assimilations can be described by a commonart iculatory mechanism.
It seems likely that the same mechanism also wi l laccount for various sorts of manner lenltions, such as the flapping of \[t\] and\[d\] and stop consonants being produced as fricatives.
In the gestural score,these will probably be represented as undershoot of the temporal or spatialtarget for the consonant when the consonant's closing gesture is blended withthe opening gesture for the following vowel.
That is, flapping and frlcatlonare probably simply two more examples of gestural overlap.One advantage of this account is that the continuous phase settings of thegestural score correctly predict that there wi l l  be varying degrees ofoverlap, result ing in varying degrees of spectral masking by the fo l lowingsegment, unlike in the all-or-none segment deletion and assimilative feature-changing accounts.
Since human l isteners apparently can use the residualspectral information of the preceding vowel-formant transition to perceive thedifferent between a deleted \[t\] in 'late calls' and no \[t\] in 'lake calls'(Nolan 1989), this is a desirable outcome.
In a recognit ion system based onall-or-none feature changes, by contrast, near minimal pairs such as these canonly be dist inguished if there is d isamblguat lng syntactic or semanticinformation in the context.Finally, the gestural score account makes all types of segmental lenltlon fallout from manipulations of the timing pattern, and when combined with a model16of the articulatory correlates of tempo change and prosodic structure, shouldprovide a better prediction of when lenitlons will occur.
That is, lenitionsshould occur more frequently at tempi and in prosodic contexts wherearticulatory gestures are phased more closely together.THE KINEMATICS OF TEMPO, PHRASING, AND ACCENTWhile Browman and Goldsteln have not yet provided an account of articulatorycorrelates of prosodic structure within their task-dynamlc model, there isother recent work that suggests how several effects can be described using thegestural score.
Such a description is obviously important, for many reasons.A first obvious reason is that the cross-word ass imi lat ions and deletionsdiscussed in the preceding section are blocked by certain sorts of prosodicphrase boundaries.
For example, the word-f lnal  \[s\] in 'this' would notassimilate to the following \[sh\] in any typical intonational phrasing for 'Sothe question is this: should we do it or not?
'An even more general reason for want ing a better descr ipt ion of theart iculatory correlates of prosodic structure is that stress and phrasinginteract with segmental duration patterns in ways that are very difficult tocapture in computational models of acoustic interval durations (see, e.g., vanSanten and Olive 1989; Riley 1989).
Yet human perceivers clearly use thet iming patterns of an utterance to parse the segments, stress pattern,prosodic structure, and overal l  tempo.
It seems unlikely that in doing so,they perform the complicated computations that interval-based models use topredict the segment interval durations.
A better model of speech timing couldprovide evidence as to what is actual ly being perceived when the t imingpatterns of an utterance are parsed to provide the perceptual cues tosegmental and suprasegmental structures.Work by Beckman, Edwards, and Fletcher (1989) suggests that art lculatorykinematics can differentiate global tempo change from phrase-flnal lengthen-ing, and both of these from the lengthening effect of accent or stress.
Welooked at the durations, displacements, and peak velocit ies for opening-gestures and closing gestures in the sentence-intial \[pap\] sequences in thesentences in (2):(2) a.
Pop, opposing the question strongly, refused to answer it.b.
Poppa, posing the question loudly, refused to answer it.c.
Poppa posed the question loudly, and then refused to answer it.The underlining in (2) indicates the test sequences.
In (2a), the sequence isfinal to an intonation phrase, whereas in (2b) it is not final.
The sequencein (2b), in turn contrasts to the sequence in (2c) in bearing the nuclearaccent in its phrase.We had several speakers repeat these utterances at three self-selectedspeaking rates, and measured the k inematics of the jaw-opening and closinggestures into and out of the low vowel \[a\].
We found that slowing down tempo17overall  works essentlal ly by changing the stiffness of the art lculatorysystem.
Both the opening gestures and the closing gestures have smaller peakvelocit ies at s lower tempi, with essential ly no change in displacement.Phrase-flnal lengthening looks llke slowing down tempo, but localized to theclosing gesture.
The lengthening associated with accent, by contrast, did notsignificantly change the speed of either gesture.
Instead it seemed that theaccented vowel was longer because the closing gesture was later relative tothe opening gesture.
In terms of Browman and Goldsteln's gestural score,accentual lengthening is a phase shift that lessens the overlap between thevowel gesture and the following \[p\] gesture.This last result confirms the findings of Summers (1987), who compared theartlculatory kinematics of accentual lengthening with the effects of voicingin a fo l lowing final stop.
The durat ion and velocity patterns he found foraccent are similar to those in our experiment, whereas the effect of voicingwas more similar to those of our final lengthening; the closing gesture out ofthe vowel was slower before a voiced stop.
Voicing differed from finallengthening in affecting displacement slightly as well as velocity; the jawdid not open as far before the voiced stop.This work has implications for the ways in which acoustic timing patterns canbe used to recognize stress and prosodic phrasing.
Other things being equal,jaw opening is correlated with first formant frequency and overall amplitude.Low vowels, with more open jaw positions, have higher first formants andgreater amplitudes than high vowels, with less open jaw position.
In keepingwith these correlation, Summers (1987) found that the first formant was lowerin \[a\] and \[ae\] before \[b\], as expected from the lesser jaw opening there.
Ina later perception experiment involving syllables synthesized to mimic  thefirst formant patterns in his product ion experiment, he found that firstformant frequency and transit ion speed could cue the dif ference between afollowing voiced versus voiceless stop.Given our results concerning accent and final lengthening, then, we wouldexpect that final lengthening should effect longer, s lower f i rst - formanttransitions, whereas accent should not.
Accent, on the other hand, should beassociated with a greater average volume over the syllable nucleus, whereasfinal lengthening should result in gradually decreasing ampl i tude after anearly loudness peak.
We are testing these predict ions in exper imentspresently underway.
If they are borne out, then tracking formant kinematicsand ampl i tude contours over a syllable should help interpret its overallduration pattern.
A recognition system that incorporated these results wouldhave much better recognition of the stress and phrasing pattern, with all theimprovements in segmental recognition which that entails.AcknowledgementsThis material is based upon work supported by the National Science Foundationunder Grant No.
and IRI-8902142.
Any opinions, findings, and conclusionsor recommendations expressed in this publication are those of the author and18do not necessarily reflect the views of the National Science Foundation orof the other co-Pl's on Grant No.
IRI-8902142.
The discussion of task-dynamic models represented in this paper benefited by conversations withCatherine Browman, Louis Goldstein, and Elliot Saltzman.
(However, theauthor alone is responsible for any errors in the understanding of theirwork.)
The work on kinematic correlates of tempo, final lengthening, andaccent was done in collaboration with Jan Edwards and Janet Fletcher and wassupported by the NSF under Grants No.
IRI-861752 and IRI-8858109 to MaryBeckman and Grant No.
IRI-8617873 to Jan Edwards.ReferencesBeckman, M., De Jong, K., and Edwards, J.
(1987).
The surface phonology ofstress clash in English.
Paper presented at the 62nd Annual Meeting ofthe Linguistic Society of America, San Francisco, 27-30 December.Beckman, M., Edwards, J., and Fletcher, J.
(1989).
Prosodic structure andtempo in a sonority model of articulatory dynamics.
Paper presented atthe Second Conference on Laboratory Phonology, University of Edinburgh,30 June-4 July, 1989.Browman, C., and Goldstein, L. (1987).
Tiers in articulatory phonology, withsome implications for casual speech.
Paper presented at the FirstConference in Laboratory Phonology.
\[Written version to appear in J.Kingston and M. Beckman, eds., (1990) Papers in_Laboratory Phonology I_~_Between the Grammar and the Physics of Speech.
Cambridge: CambridgeUniversity Press.\]Brown, G. (1977).
Listening to_Spoken English.
London: Longman.Bush, M.A., and Kopec, G.E.
(1987).
Network-based connected digit recognition.IEEE Transactions on_ Acoustics, Speech and Signal Processing 35.Catford, J.C. (1977).
Fundamental Problems in Phonetics.
Bloomington, IN:Indiana University Press.Fowler, C.A., Rubin, P., Remez, R.E., and Turvey, M.T.
(1980).
Implicationsfor speech production of a skilled theory of action.
In B.
Butterworth,ed., Language Production I. London: Academic Press.Fry, D.B.
(1958).
Experiments in the perception of stress.
Languag eSpeech I, 126-152.andKelso, J.A.S., Vatlkiotis-Bateson, E., Saltzman, E.L., and Kay, B.
(1985).
Aqualitative dynamic analysis of relterant speech production: Phaseportraits, kinematics, and dynamic modeling.
Journal of the AcousticalSociety of America 77, 266-280.19Klatt, D.H. (1979).
Synthesis by rule of segmental durations in Englishsentences.
In B. Lindblom and S. 0hman, eds., Frontiers of SpeechCommunication Research, 287-400.
Academic Press.Klatt, D.H. (1976).
Linguistic uses of segmental duration in English:Acoustic and perceptual evidence.
Journal of the Acoustical Society ofAmerica 59, 1208-1221.Kiritani, S., Itoh, K., and Fujimura, O.
(1975).
Tongue-pellet tracking by acomputer-controlled X-ray mlcrobeam system.
Journal of the AcousticalSociety of America 57, 1516-1520.Kopec, G.E., and Bush, M.A.
(1985).
Network-based isolated digit recognitionusing vector quantization.
IEEE transactions o_~Acoustics Speech andSignal Processing 33, 850-867.Neary, T., and Assman, P. (1986).
Modeling the role of inherent spectralchange in vowel identification.
Journal of the Acoustical Societ F o fAmerica 80, 1297-1308.Nespor, M., and Vogel, I.
(1982).
Prosodic domains of external sandhi rules,In H. van der Hulst and N. Smith, eds., The Structure of Phon01ogicalRepresentations, Part I. Dordrecht: Foris.Nespor, M., and Vogel, I.
(1986).
Prosodic Phono!og ~.
Foris.Nolan, F. (1989).
The descr ipt ive  role of segments:  Ev idence fromassimilation.
Paper presented at the Second Conference on LaboratoryPhonology, University of Edinburgh, 30 June-4 July, 1989.Nooteboom, S.G. (1973).
The perceptual reality of some prosodic durations.Journal of Phonetics I, 25-45.Ostry, D.J., Keller, E., and Parush, A.
(1983).
Similarities in the control ofspeech articulators and the limbs: Kinematics of tongue dorsum movementin speech.
Journal of Experlmenta!
Psychology: Human Perception andPerformance 9, 622-636Raphael, L.J.
(1972).
Preceding vowel duration as a cue to the voicingcharacteristics of word-final consonants in English.
Journal of theAcoustical Society of America 51, 1296-1303.Riley, M.D.
(1989).
Statistical tree-based modeling of phonetic segmentdurations.
Journal of the Acoustical Society of America, 85, Suppl.
i,S44.Saltzman, E. (1986).
Task dynamic coordination of the speech articulators: apreliminary model.
In H. Heuer and C. Fromm, eds., Generation andModulation of Action Patterns (Experimental Brain Research Series I5),129-144.
New York: Springer-Verlag.20Scott, D. R. (1982).
Durat ion as a cue to the perception of a phrase boundary.Journal of the Acoustical Society of America 71, 996-1007.Stevens, K.N.
(1986).
Models of speech recognit ion II: a feature-based modelof speech recognition.
In P. Mermelstein, ed., Proceedings of theMontreal Satell ite Symposium on Speech Recognltlon (Twelth InternationCongress of Acoustlcs), 67-68.Summers, W.V.
(1987).
Effects of stress and flnal-consonant voicing on vowelproduction: Art iculatory and acoustic analyses.
Journal of theAcoustical Society of America 82, 847-863.Summers, W.V.
(1988).
F1 structure provides information for flnal-consonantvoicing.
Journal of the Acoustical Society of America 84, 485-492.van Santen, J.P.H.
(1989).
Diagnostic tests of segmental duration models.Journal of the Acoustical Society of America, 85, Suppl.
I, $43.Walbel, A.
(1988).
Prosody and Speech Recognition.
Morgan Kaufmann.Zek, D., and Inkelas, S. (1987).
Phonological phrasing and the reduction offunction words.
Paper presented at the 62nd Annual Meeting of theLinguistic Society of America, San Francisco, 27-30 December.21
