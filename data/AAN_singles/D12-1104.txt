Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational NaturalLanguage Learning, pages 1135?1145, Jeju Island, Korea, 12?14 July 2012. c?2012 Association for Computational LinguisticsPATTY: A Taxonomy of Relational Patterns with Semantic TypesNdapandula Nakashole, Gerhard Weikum, Fabian SuchanekMax Planck Institute for InformaticsSaarbru?cken, Germany{nnakasho,weikum,suchanek}@mpi-inf.mpg.deAbstractThis paper presents PATTY: a large resourcefor textual patterns that denote binary relationsbetween entities.
The patterns are semanti-cally typed and organized into a subsumptiontaxonomy.
The PATTY system is based on ef-ficient algorithms for frequent itemset miningand can process Web-scale corpora.
It har-nesses the rich type system and entity popu-lation of large knowledge bases.
The PATTYtaxonomy comprises 350,569 pattern synsets.Random-sampling-based evaluation shows apattern accuracy of 84.7%.
PATTY has 8,162subsumptions, with a random-sampling-basedprecision of 75%.
The PATTY resourceis freely available for interactive access anddownload.1 IntroductionMotivation.
WordNet (Fellbaum 1998) is one of themost widely used lexical resources in computer sci-ence.
It groups nouns, verbs, and adjectives into setsof synonyms, and arranges these synonyms in a tax-onomy of hypernyms.
WordNet is limited to singlewords.
It does not contain entire phrases or pat-terns.
For example, WordNet does not contain thepattern X is romantically involved with Y.
Just likewords, patterns can be synonymous, and they cansubsume each other.
The pattern X is romanticallyinvolved with Y is synonymous with the pattern X isdating Y.
Both are subsumed by X knows Y. Patternsfor relations are a vital ingredient for many appli-cations, including information extraction and ques-tion answering.
If a large-scale resource of relationalpatterns were available, this could boost progress inNLP and AI tasks.Yet, existing large-scale knowledge bases aremostly limited to abstract binary relationships be-tween entities, such as ?bornIn?
(Auer 2007; Bol-lacker 2008; Nastase 2010; Suchanek 2007).
Thesedo not correspond to real text phrases.
Only the Re-Verb system (Fader 2011) yields a larger number ofrelational textual patterns.
However, no attempt ismade to organize these patterns into synonymouspatterns, let ale into a taxonomy.
Thus, the pat-terns themselves do not exhibit semantics.Goal.
Our goal in this paper is to systematicallycompile relational patterns from a corpus, and to im-pose a semantically typed structure on them.
Theresult we aim at is a WordNet-style taxonomy ofbinary relations.
In particular, we aim at patternsthat contain semantic types, such as ?singer?
sings?song?.
We also want to automatically generalizesyntactic variations such as sings her ?song?
andsings his ?song?, into a more general pattern sings[prp] ?song?
with POS tag [prp].
Analogously butmore demandingly, we want to automatically inferthat the above patterns are semantically subsumedby the pattern ?musician?
performs on ?musicalcomposition?
with more general types for the entityarguments in the pattern.Compiling and organizing such patterns is chal-lenging for the following reasons.
1) The numberof possible patterns increases exponentially with thelength of the patterns.
For example, the string ?Amysings ?Rehab??
can give rise to the patterns ?singer?sings ?song?, ?person?
sings ?artifact?, ?person?
[vbz] ?entity?, etc.
If wildcards for multiple wordsare allowed (such as in ?person?
sings * ?song?
), thenumber of possible patterns explodes.
2) A pattern1135can be semantically more general than another pat-tern (when one relation is implied by the other re-lation), and it can also be syntactically more gen-eral than another pattern (by the use of placehold-ers such as [vbz]).
These two subsumption ordershave a non-obvious interplay, and none can be ana-lyzed without the other.
3) We have to handle patternsparseness and coincidental matches.
If the corpusis small, e.g., the patterns ?singer?
later disliked hersong ?song?
and ?singer?
sang ?song?, may apply tothe same set of entity pairs in the corpus.
Still, thepatterns are not synonymous.
4) Computing mutualsubsumptions on a large set of patterns may be pro-hibitively slow.
Moreover, due to noise and vaguesemantics, patterns may even not form a crisp tax-onomy, but require a hierarchy in which subsump-tion relations have to be weighted by statistical con-fidence measures.Contributions.
In this paper, we present PATTY, alarge resource of relational patterns that are arrangedin a semantically meaningful taxonomy, along withentity-pair instances.
More precisely, our contribu-tions are as follows:1) SOL patterns: We define an expressive fam-ily of relational patterns, which combines syntac-tic features (S), ontological type signatures (O), andlexical features (L).
The crucial novelty is the addi-tion of the ontological, semantic dimension to pat-terns.
When compared to a state-of-the-art patternlanguage, we found that SOL patterns yield higherrecall while achieving similar precision.2) Mining algorithms: We present efficient andscalable algorithms that can infer SOL patterns andsubsumptions at scale, based on instance-level over-laps and an ontological type hierarchy.3) A large Lexical resource:.
On the Wikipe-dia corpus, we obtained 350,569 pattern synsetswith 84.7% precision.
We make our pat-tern taxonomy available for further research atwww.mpi-inf.mpg.de/yago-naga/patty/ .The paper is structured as follows.
Section 2 dis-cusses related work.
Section 3 outlines the basicmachinery for pattern extraction.
Section 4 intro-duces our SOL pattern model.
Sections 5 and 6present the syntactic and semantic generalization ofpatterns.
Section 7 explains how to arrange the pat-terns into a taxonomy.
Section 8 reports our experi-mental findings.2 Related WorkA wealth of taxonomic knowledge bases (KBs)about entities and their semantic classes have be-come available.
These are very rich in terms ofunary predicates (semantic classes) and their entityinstances.
However, the number of binary relations(i.e., relation types, not instances) in these KBs isusually small: Freebase (Bollacker 2008) has a fewthousand hand-crafted relations.
WikiNet (Nastase2010) has automatically extracted ca.
500 relationsfrom Wikipedia category names.
DBpedia (Auer2007) has automatically compiled ca.
8000 namesof properties from Wikipedia infoboxes, but theseinclude many involuntary semantic duplicates suchas surname and lastname.
In all of these projects,the resource contains the relation names, but not thenatural language patterns for them.
The same is truefor other projects along these lines (Navigli 2010;Philpot 2008; Ponzetto 2007; Suchanek 2007).In contrast, knowledge base projects that auto-matically populate relations from Web pages alsolearn surface patterns for the relations: examplesare TextRunner/ReVerb (Banko 2007; Fader 2011),NELL (Carlson 2010; Mohamed11), Probase (Wu2011), the dynamic lexicon approach by (Hoffmann2010; Wu 2008), the LDA-style clustering approachby (Yao 2011), and projects on Web tables (Li-maye 2010; Venetis 2011).
Of these, only TextRun-ner/ReVerb and NELL have made large pattern col-lections publicly available.ReVerb (Fader 2011) constrains patterns to verbsor verb phrases that end with prepositions, whilePATTY can learn arbitrary patterns.
More impor-tantly, all methods in the TextRunner/ReVerb familyare blind to the ontological dimension of the enti-ties in the patterns.
Therefore, there is no notion ofsemantic typing for relation phrases as in PATTY.NELL (Carlson 2010) is based on a fixed setof prespecified relations with type signatures, (e.g.,personHasCitizenship: ?person?
?
?country?
), andlearns to extract suitable noun-phrase pairs from alarge Web corpus.
In contrast, PATTY discovers pat-terns for relations that are a priori unknown.1136In OntExt (Mohamed11), the NELL architecturewas extended to automatically compute new re-lation types (beyond the prespecified ones) for agiven type signature of arguments, based on a clus-tering technique.
For example, the relation mu-sicianPlaysInstrument is found by clustering pat-tern co-occurrences for the noun-phrase pairs thatfall into the specific type signature ?musician?
??musicinstrument?.
This technique works for onetype signature at a time, and does not scale up tomining a large corpus.
Also, the technique is notsuitable for inferring semantic subsumptions.
Incontrast, PATTY efficiently acquires patterns fromlarge-scale corpora and organizes them into a sub-sumption hierarchy.Class-based attribute discovery is a special caseof mining relational patterns (e.g., (Alfonseca 2010;Pasca 2007; Pasca 2008; Reisinger 2009)).
Given asemantic class, such as movies or musicians, the taskis to determine relevant attributes, such as cast andbudget for movies, or albums and biography for mu-sicians, along with their instances.
Unlike PATTY?spatterns, the attributes are not typed.
They comewith a prespecified type for the domain, but withoutany type for the range of the underlying relation.There are further relation-centric tasks in NLPand text mining that have commonalities with ourendeavor, but differ in fundamental ways.
TheSemEval-2010 task on classification of semantic re-lations between noun-phrase pairs (Hendrickx 2010)aimed at predicting the relation for a given sentenceand pair of nominals, but used a fixed set of prespec-ified relations.
Another task in this research avenueis to characterize and predict the argument types fora given relation or pattern (Kozareva 2010; Nakov2008).
This is closer to KB population and less re-lated to our task of discovering relational patternsand systematically organizing them.From a linguistic perspective, there is amplework on patterns for unary predicates of the formclass(entity).
This includes work on entailment ofclasses, i.e., on is-a and subclassOf relationships.Entailment among binary predicates of the form re-lation(entity1, entity2) has received less attention(Lin 2001; Chklovski 2004; Hashimoto 2009; Be-rant 2011).
These works focus solely on verbs, whilePATTY learns arbitrary phrases for patterns.Several lexical resources capture verb categoriesand entailment: WordNet 3.0 (Fellbaum 1998) con-tains about 13,000 verb senses, with troponymy andentailment relations; VerbNet (Kipper 2008) is a hi-erarchical lexicon with more than 5,000 verb sensesin ca.
300 classes, including selectional preferences.Again, all of these resources focus solely on verbs.ConceptNet 5.0 (Havasi 2007) is a thesaurus ofcommonsense knowledge built as a crowdsourcingendeavor.
PATTY, in contrast, is constructed fullyautomatically from large corpora.
Automatic learn-ing of paraphrases and textual entailment has re-ceived much attention (see the survey of (Androut-sopoulos 2010)), but does not consider fine-grainedtyping for binary relations, as PATTY does.3 Pattern ExtractionThis section explains how we obtain basic textualpatterns from the input corpus.
We first apply theStanford Parser (Marneffe 2006) to the individualsentences of the corpus to obtain dependency paths.The dependency paths form a directed graph, withwords being nodes and dependencies being edges.For example, the sentence ?Winehouse effortlesslyperformed her song Rehab.?
yields the following de-pendency paths:nsubj(performed-3, Winehouse-1)advmod(performed-3, effortlessly-2)poss(Rehab-6, her-4)nn(Rehab-6, song-5)dobj(performed-3, Rehab-6)While our method also works with patterns obtainedfrom shallow features such as POS tags, we foundthat dependency paths improve pattern extractionprecision especially on long sentences.We then detect mentions of named entities in theparsed corpus.
For this purpose, we use a dictio-nary of entities.
This can be any resource that con-tains named entities with their surface names and se-mantic types (Auer 2007; Suchanek 2007; Hoffart2011; Bollacker 2008).
In our experiments, we usedthe YAGO2 knowledge base (Hoffart 2011).
Wematch noun phrases that contain at least one propernoun against the dictionary.
For disamiguation, we1137use a simple context-similarity prior, as describedin (Suchanek 2009).
We empirically found that thistechnique has accuracy well above 80% (and higherfor prominent and thus frequently occurring enti-ties).
In our example, the entity detection yields theentities Amy Winehouse and Rehab (song).Whenever two named entities appear in the samesentence, we extract a textual pattern.
For this pur-pose, we traverse the dependency graph to get theshortest path that connects the two entities.
In theexample, the shortest path between ?Winehouse?and ?Rehab?
is: Winehouse nsubj performed dobjRehab.
In order to capture only relations that referto subject-relation-object triples, we only considershortest paths that start with subject-like dependen-cies, such as nsubj, rcmod and partmod.
To re-flect the full meaning of the patterns, we expand theshortest path with adverbial and adjectival modifiers,for example the advmod dependency.
The sequenceof words on the expanded shortest path becomes ourfinal textual pattern.
In the example, the textual pat-tern is Amy Winehouse effortlessly performed Rehab(song).4 SOL Pattern ModelTextual patterns are tied to the particular surfaceform of the text.
Therefore, we transform the textualpatterns into a new type of patterns, called syntactic-ontologic-lexical patterns (SOL patterns).
SOL pat-terns extend lexico-syntactic patterns by ontologicaltype signatures for entities.
The SOL pattern lan-guage is expressive enough to capture fine-grainedrelational patterns, yet simple enough to be dealtwith by efficient mining algorithms at Web scale.A SOL pattern is an abstraction of a textual pat-tern that connects two entities of interest.
It is asequence of words, POS-tags, wildcards, and onto-logical types.
A POS-tag stands for a word of thepart-of-speech class.
We introduce the special POS-tag [word], which stands for any word of any POSclass.
A wildcard, denoted ?, stands for any (pos-sibly empty) sequence of words.
Wildcards are es-sential to avoid overfitting of patterns to the corpus.An ontological type is a semantic class name (suchas ?singer?)
that stands for an instance of that class.Every pattern contains at least two types, and theseare designated as entity placeholders.A string and a pattern match, if there is an order-preserving bijection from sequences of words in thestring to items in the pattern, so that each item canstand for the respective sequence of words.
For ex-ample, the pattern ?person?
?s [adj] voice * ?song?matches the strings ?Amy Winehouse?s soft voicein ?Rehab??
and ?Elvis Presley?s solid voice in hissong ?All shook up??.
The type signature of a pat-tern is the pair of the entity placeholders.
In the ex-ample, the type signature is person ?
song.
Thesupport set of a pattern is the set of pairs of entitiesthat appear in the place of the entity placeholdersin all strings in the corpus that match the pattern.In the example, the support set of the pattern couldbe {(Amy,Rehab), (Elvis, AllShookUp)}.
Eachpair is called a support pair of the pattern.Pattern B is syntactically more general than pat-tern A if every string that matches A also matchesB.
Pattern B is semantically more general than Aif the support set of B is a superset of the supportset of A.
If A is semantically more general than Band B is semantically more general than A, the pat-terns are called synonymous.
A set of synonymouspatterns is called a pattern synset.
Two patterns, ofwhich neither is semantically more general than theother, are called semantically different.To generate SOL patterns from the textual pat-terns, we decompose the textual patterns into n-grams (n consecutive words).
A SOL pattern con-tains only the n-grams that appear frequently in thecorpus and the remaining word sequences are re-placed by wildcards.
For example, in the sentence?was the first female to run for the governor of?might give rise to the pattern * the first female * gov-ernor of, if ?the first female?
and ?governor of?
arefrequent in the corpus.To find the frequent n-grams efficiently, we applythe technique of frequent itemset mining (Agrawal1993; Srikant 1996): each sentence is viewed as a?shopping transaction?
with a ?purchase?
of severaln-grams, and the mining algorithm computes the n-gram combinations with large co-occurrence sup-port1.
These n-grams allow us to break down a sen-1Our implementation restricts n-grams to length 3 and usesup to 4 n-grams per sentence1138tence into wildcard-separated subsequences, whichyields an SOL pattern.
We generate multiple pat-terns with different types, one for each combinationof types that the detected entities have in the under-lying ontology.We quantify the statistical strength of a pattern bymeans of its support set.
For a given pattern p withtype signature t1 ?
t2, the support of p is the sizeof its support set.
For confidence, we compare thesupport-set sizes of p and an untyped variant pu ofp, in which the types ?t1?
and ?t2?
are replaced bythe generic type ?entity?.
We define the confidenceof p as the ratio of the support-set sizes of p and pu.5 Syntactic Pattern GeneralizationAlmost every pattern can be generalized into a syn-tactically more general pattern in several ways: byreplacing words by POS-tags, by introducing wild-cards (combining more n-grams), or by generaliz-ing the types in the pattern.
It is not obvious whichgeneralizations will be reasonable and useful.
Weobserve, however, that generalizing a pattern maycreate a pattern that subsumes two semantically dif-ferent patterns.
For example, the generalization?person?
[vb] ?person?
subsumes the two semanti-cally different patterns ?person?
loves ?person?
and?person?
hates ?person?.
This means that the patternis semantically meaningless.Therefore, we proceed as follows.
For every pat-tern, we generate all possible generalizations.
If ageneralization subsumes multiple patterns with dis-joint support sets, we abandon the generalized pat-tern.
Otherwise, we add it to our set of patterns.6 Semantic Pattern GeneralizationThe main difficulty in generating semantic subsump-tions is that the support sets may contain spuriouspairs or be incomplete, thus destroying crisp set in-clusions.
To overcome this problem, we designeda notion of a soft set inclusion, in which one set Scan be a subset of another set B to a certain degree.One possible measure for this degree is the confi-dence, i.e., the ratio of elements in S that are in B,deg(S ?
B) = |S ?
B|/|S|.
However, if a supportset S has only few elements due to sparsity, it maybecome a subset of another support setB, even if thetwo patterns are semantically different.
Therefore,one has to take into account also the support, i.e., thesize of the set S. Traditionally, this is done through aweighted trade-off between confidence and support.To avoid the weight tuning, we instead deviseda probabilistic model.
We interpret S as a randomsample from the ?true?
support set S?
that the patternwould have on an infinitely large corpus.
We wantto estimate the ratio of elements of S?
that are inB.
This ratio is a Bernoulli parameter that can beestimated from the ratio of elements of the sample Sthat are in B.
We compute the Wilson score interval[c ?
d, c + d] (Brown 2001) for the sample.
Thisinterval guarantees that with a given probability (seta priori, usually to ?
= 95%), the true ratio falls intothe interval [c ?
d, c + d].
If the sample is small, dis large and c is close to 0.5.
If the sample is large,d decreases and c approaches the naive estimation|S ?
B|/|S|.
Thereby, the Wilson interval centernaturally balances the trade-off between confidenceand the support.
Hence we define deg(S ?
B) = c.This estimator may degrade when the sample sizeis too small We can alternatively use a conservativeestimator deg(S ?
B) = c?d, i.e., the lower boundof the Wilson score interval.
This gives a low scoreto the case where S ?
B if we have few samples (Sis small).7 Taxonomy ConstructionWe now have to arrange the patterns in a semantictaxonomy.
A baseline solution would compare ev-ery pattern support set to every other pattern supportset in order to determine inclusion, mutual inclusion,or independence.
This would be prohibitively slow.For this reason, we make use of a prefix-tree for fre-quent patterns (Han 2005).
The prefix-tree storessupport sets of patterns.
We then developed an algo-rithm for obtaining set intersections from the prefix-tree.7.1 Prefix-Tree ConstructionSuppose we have pattern synsets and their supportsets as shown in Table 1.
An entity pair in a supportset is denoted by a letter.
For example, in the sup-port set for the pattern ?Politican?
was governorof ?State?, the entry ?A,80?
may denote the entity1139ID Pattern Synset & Support SetsP1 ?Politician?
was governor of ?State?A,80 B,75 C,70P2 ?Politician?
politician from ?State?A,80 B,75 C,70 D,66 E,64P3 ?Person?
daughter of ?Person?F,78 G,75 H,66P4 ?Person?
child of ?Person?I,88 J,87 F,78 G,75 K,64Table 1: Pattern Synsets and their Support SetsRootA p1,p2BCDp1,p2p1,p2p2E p2FGHp3 IJFp4G p4K p4p4p4 p3 p3Figure 1: Prefix-Tree for the Synsets in Table 1.pair Arnold Schwarzenegger, California, with an oc-currence frequency 80.
The contents of the supportsets are used to construct a prefix-tree, where nodesare entity pairs.
If synsets have entity pairs in com-mon, they share a common prefix; thus the sharedparts can be represented by one prefix-path in thetree.
This enables subsumptions to be directly ?readoff?
from the tree, while representing the tree in acompact manner.
To increase the chance of sharedprefixes, entity pairs are inserted into the tree in de-creasing order of occurrence frequency.The prefix-tree of support sets is a prefix-tree aug-mented with synset information stored at the nodes.Each node (entity pair) stores the identifiers of thepattern sysnets whose support sets contain that en-tity pair.
In addition, each node stores a link to thenext node with the same entity pair.Figure 1 shows the tree for the pattern synsetsin Table 1.
The left-most path contains synsets P1and P2.
The two patterns have a prefix in common,thus they share the same path.
This is reflected bythe synsets stored in the nodes in the path.
SynsetsP2 and P3 belong to two different paths due to dis-similar prefixes although they have common nodes.Instead, their common nodes are connected by thesame-entity-pair links shown as dotted lines in Fig-ure 1.
These links are created whenever the entitypair already exists in the tree but with a prefix differ-ent from the prefix of the synset being added to thetree.
The size of the tree is at most the total num-ber of entity pairs making up the supports sets of thesynsets.
The height of the tree is at most the size ofthe the largest support set.7.2 Mining Subsumptions from the Prefix-TreeTo efficiently mine subsumptions from the prefix-tree, we have to avoid comparing every path to everyother path as this introduces the same inefficienciesthat the baseline approach suffers from.From the construction of the tree it follows thatfor any node Ni in the tree, all paths containing Nican be found by following node Ni?s links includ-ing the same-entity-pair links.
By traversing the en-tire path of a synset Pi, we can reach all the patternsynsets sharing common nodes with Pi.
This leadsto our main insight: if we start traversing the treebottom up, starting at the last node in P ?is supportset, we can determine exactly which paths are sub-sumed by Pi.
Traversing the tree this way for allpatterns gives us the sizes of the support set intersec-tion.
The determined intersection sizes can then beused in the Wilson estimator to determine the degreeof semantic subsumption and semantic equivalenceof patterns.7.3 DAG ConstructionOnce we have generated subsumptions between re-lational patterns, there might be cycles in the graphwe generate.
We ideally want to remove the minimaltotal number of subsumptions whose removal resultsin an a directed acyclic graph (DAG).
This task isrelated to the minimum feedback-arc-set problem:given a directed graph, we want to remove the small-est set of edges whose removal makes the remaininggraph acyclic.
This is a well known NP-hard prob-lem (Kann 1992).
We use a greedy algorithm for1140removing cycles and eliminating redundancy in thesubsumptions, thus effectively constructing a DAG.Starting with a list of subsumption edges ordered bydecreasing weights, we construct the DAG bottom-up by adding the highest-weight subsumption edge.This step is repeated for all subsumptions, where weadd a subsumption to the DAG only if it does notintroduce cycles or redundancy.
Redundancy occurswhen there already exists a path, by transitivity ofsubsumptions, between pattern synsets linked by thesubsumption.
This process finally yields a DAG ofpattern synsets ?
the PATTY taxonony.8 Experimental Evaluation8.1 SetupThe PATTY extraction and mining algorithms wererun on two different input corpora: the New YorkTimes archive (NYT) which includes about 1.8 Mil-lion newspaper articles from the years 1987 to 2007,and the English edition of Wikipedia (WKP), whichcontains about 3.8 Million articles (as of June 21,2011).
Experiments were carried out, for each cor-pus, with two different type systems: a) the type sys-tem of YAGO2, which consists of about 350,000 se-mantic classes from WordNet and the Wikipedia cat-egory system, and b) the two-level domain/type hier-archy of Freebase which consists of 85 domains anda total of about 2000 types within these domains.All relational patterns and their respective entitypairs are stored in a MongoDB database.
We evalu-ated PATTY along four dimensions: quality of pat-terns, quality of subsumptions, coverage, and de-sign alternatives.
These dimensions are discussedin the following four subsections.
We also per-formed an extrinsic study to demonstrate the use-fulness of PATTY for paraphrasing the relationsof DBpedia and YAGO2.
In terms of runtimes,he most expensive part is the pattern extraction,where we identify pattern candidates through de-pendency parsing and perform entity recognitionon the entire corpus.
This phase runs about aday for Wikipedia a cluster.
All other phases ofthe PATTY system take less than an hour.
Allexperimental data is available on our Web site atwww.mpi-inf.mpg.de/yago-naga/patty/.8.2 Precision of Relational PatternsTo assess the precision of the automatically minedpatterns (patterns in this section always mean patternsynsets), we sampled the PATTY taxonomy for eachcombination of input corpus and type system.
Weranked the patterns by their statistical strength (Sec-tion 4), and evaluated the precision of the top 100pattern synsets.
Several human judges were showna sampled pattern synset, its type signature, and afew example instances, and then stated whether thepattern synset indicates a valid relation or not.
Eval-uators checked the correctness of the type signature,whether the majority of patterns in the synset is rea-sonable, and whether the instances seem plausible.If so, the synset was flagged as meaningful.
The re-sults of this evaluation are shown in column four ofTable 2, with a 0.9-confidence Wilson score inter-val (Brown 2001).
In addition, the same assessmentprocedure was applied to randomly sampled synsets,to evaluate the quality in the long tail of patterns.The results are shown in column five of Table 2.
Forthe top 100 patterns, we achieve above 90% preci-sion for Wikipedia, and above 80% for 100 randomsamples.Corpus Types Patterns Top 100 RandomNYTYAGO2 86,982 0.89?0.06 0.72?0.09Freebase 809,091 0.87 ?0.06 0.71?0.09WKPYAGO2 350,569 0.95?0.04 0.85?0.07Freebase 1,631,531 0.93?0.05 0.80?0.08Table 2: Precision of Relational PatternsFrom the results we make two observations.
First,Wikipedia patterns have higher precision than thosefrom the New York Times corpus.
This is becausesome the language in the news corpus does not ex-press relational information; especially the news onstock markets produced noisy patterns picked up byPATTY.
However, we still manage to have a preci-sion of close to 90% for the top 100 patterns andaround 72% for random sample on the NYT cor-pus.
The second observation is that the YAGO2type system generally led to higher precision thanthe Freebase type system.
This is because YAGO2has finer grained, ontologically clean types, whereasFreebase has broader categories with a more liberal1141assignment of entities to categories.8.3 Precision of SubsumptionsWe evaluated the quality of the subsumptions byassessing 100 top-ranked as well as 100 randomlyselected subsumptions.
As shown in Table 3, alarge number of the subsumptions are correct.
TheWikipedia-based PATTY taxonomy has a random-sampling-based precision of 75%.Corpus Types # Edges Top 100 RandomNYTYAGO2 12,601 0.86?0.07 0.68?0.09Freebase 80,296 0.89?0.06 0.41?0.09WKPYAGO2 8,162 0.83?0.07 0.75?0.07Freebase 20,339 0.85?0.07 0.62?0.09Table 3: Quality of SubsumptionsExample subsumptions from Wikipedia are:?
?person?
nominated for ?award?
=?person?
winner of ?award??
?person?
?
s wife ?person?
=?person?
?s widow ?person?8.4 CoverageTo evaluate the coverage of PATTY, we would needa complete ground-truth resource that contains allpossible binary relations between entities.
Unfor-tunately, there is no such resource2.
We tried toapproximate such a resource by manually compil-ing all binary relations between entities that ap-pear in Wikipedia articles of a certain domain.
Wechose the domain of popular music, because it offersa plethora of non-trivial relations (such as addict-edTo(person,drug), coveredBy(musician,musician),dedicatedSongTo(musician,entity))).
We consideredthe Wikipedia articles of five musicians (Amy Wine-house, Bob Dylan, Neil Young, John Coltrane, NinaSimone).
For each page, two annotators hand-extracted all relationship types that they would spotin the respective articles.
The annotators limitedthemselves to relations where at least one argumenttype is ?musician?.
Then we formed the intersectionof the two annotators?
outputs (i.e., their agreement)2Lexical resources such as WordNet contain only verbs, butnot binary relations such as is the president of.
Other resourcesare likely incomplete.as a reasonable gold standard for relations identifi-able by skilled humans.
In total, the gold-standardset contains 163 relations.We then compared our relational patterns to therelations included in four major knowledge bases,namely, YAGO2, DBpedia (DBP), Freebase (FB),and NELL, limited to the specific domain of music.Table 4 shows the absolute number of relations cov-ered by each resource.
For PATTY, the patterns werederived from the Wikipedia corpus with the YAGO2type system.gold standard PATTY YAGO2 DBP FB NELL163 126 31 39 69 13Table 4: Coverage of Music RelationsPATTY covered 126 of the 163 gold-standard re-lations.
This is more than what can be found in largesemi-curated knowledge bases such as Freebase,and twice as much as Wikipedia-infobox-based re-sources such as DBpedia or YAGO offer.
SomePATTY examples that do not appear in the other re-sources at all are:?
?musician?
PRP idol ?musician?
for the relationhasMusicalIdol?
?person?
criticized by ?organization?
forcritizedByMedia?
?person?
headliner ?artifact?
for headlinerAt?
?person?
successfully sued ?person?
for suedBy?
?musician?
wrote hits for ?musician?
for wrote-HitsFor,This shows (albeit anecdotically) that PATTY?s pat-terns contribute added value beyond today?s knowl-edge bases.8.5 Pattern Language AlternativesWe also investigated various design alternatives tothe PATTY pattern language.
We looked at threemain alternatives: the first is verb-phrase-centricpatterns advocated by ReVerb (Fader 2011), the sec-ond is the PATTY language without type signatures(just using sets of n-grams with syntactic general-izations), and the third one is the full PATTY lan-guage.
The results for the Wikipedia corpus and the1142Reverb-style patterns PATTY without types PATTY full# Patterns 5,996 184,629 350,569Patterns Precision 0.96?0.03 0.74?0.08 0.95?0.04# Subsumptions 74 15,347 8,162Subsumptions Precision 0.79 ?0.09 0.58?0.09 0.83?0.07# Facts 192,144 6,384,684 3,890,075Facts Precision.
0.86 ?0.07 0.64?0.09 0.88 ?0.06Table 5: Results for Different Pattern Language AlternativesRelation Paraphrases Precision Sample ParaphrasesDBPedia/artist 83 0.96?0.03 [adj] studio album of, [det] song by .
.
.DBPedia/associatedBand 386 0.74?0.11 joined band along, plays in .
.
.DBPedia/doctoralAdvisor 36 0.558?0.15 [det] student of, under * supervision .
.
.DBPedia/recordLabel 113 0.86?0.09 [adj] artist signed to, [adj] record label .
.
.DBPedia/riverMouth 31 0.83?0.12 drains into, [adj] tributary of .
.
.DBPedia/team 1,108 0.91?0.07 be * traded to, [prp] debut for .
.
.YAGO/actedIn 330 0.88?0.08 starred in * film, [adj] role for .
.
.YAGO/created 466 0.79?0.10 founded, ?s book .
.
.YAGO/isLeaderOf 40 0.53?0.14 elected by, governor of .
.
.YAGO/holdsPoliticalPosition 72 0.73?0.10 [prp] tenure as, oath as .
.
.Table 6: Sample Results for Relation ParaphrasingYAGO2 type system are shown in Table 5; preci-sion figures are based on the respective top 100 pat-terns or subsumption edges.
We observe from theseresults that the type signatures are crucial for pre-cision.
Moreover, the number of patterns, subsump-tions and facts found by verb-phrase-centric patterns(ReVerb (Fader 2011)), are limited in recall.
Gen-eral pattern synsets with type signatures, as newlypursued in this paper, substantially outperform theverb-phrase-centric alternative in terms of patternand subsumption recall while yielding high preci-sion.8.6 Extrinsic Study: Relation ParaphrasingTo further evaluate the usefulness of PATTY, we per-formed a study on relation paraphrasing: given a re-lation from a knowledge base, identify patterns thatcan be used to express that relation.
Paraphrasingrelations with high-quality patterns is important forpopulating knowledge bases and counters the prob-lem of semantic drifting caused by ambiguous andnoisy patterns.We considered relations from two knowledgebases, DBpedia and YAGO2, focusing on relationsthat hold between entities and do not include literals.PATTY paraphrased 225 DBpedia relations with atotal of 127,811 patterns, and 25 YAGO2 relationswith a total of 43,124 patterns.
Among these weevaluated a random sample of 1,000 relation para-phrases.
Table 6 shows precision figures for someselected relations, along anecdotic example patterns.Some relations are hard to capture precisely.
ForDBPedia/doctoralAdvisor, e.g., PATTY picked uppatterns like ?worked with?
as paraphrases.
Theseare not entirely wrong, but we evaluated them asfalse because they are too general to indicate themore specific doctoral advisor relation.Overall, however, the paraphrasing precision ishigh.
Our evaluation showed an average precisionof 0.76?0.03 across all relations.9 Conclusion and Future DirectionsThis paper presented PATTY, a large resource of textpatterns.
Different from existing resources, PATTYorganizes patterns into synsets and a taxonomy, sim-ilar in spirit to WordNet.
Our evaluation showsthat PATTY?s patterns are semantically meaning-ful, and that they cover large parts of the relationsof other knowledge bases.
The Wikipedia-basedversion of PATTY contains 350,569 pattern synsetsat a precision of 84.7%, with 8,162 subsumptions,at a precision of 75%.
The PATTY resource is1143freely available for interactive access and downloadat www.mpi-inf.mpg.de/yago-naga/patty/.Our approach harnesses existing knowledge basesfor entity-type information.
However, PATTY is nottied to a particular choice for this purpose.
In fact,it would be straightforward to adjust PATTY to us-ing surface-form noun phrases rather than disam-biguated entities, as long as we have means to inferat least coarse-grained types (e.g., person, organiza-tion, location).
An interesting future direction is tostudy this generalized setting.
We would also liketo investigate the enhanced interplay of informationextraction and pattern extraction, and possible appli-cations for question answering.ReferencesIon Androutsopoulos, Prodromos Malakasiotis: A Sur-vey of Paraphrasing and Textual Entailment Methods.Journal of Artificial Intelligence Research 38: 135?187, 2010Rakesh Agrawal, Tomasz Imielinski, Arun N. Swami:Mining Association Rules between Sets of Items inLarge Databases.
SIGMOD Conference 1993Enrique Alfonseca, Marius Pasca, Enrique Robledo-Arnuncio: Acquisition of instance attributes via la-beled and related instances.
SIGIR 2010So?ren Auer, Christian Bizer, Georgi Kobilarov, JensLehmann, Richard Cyganiak, Zachary G. Ives: DBpe-dia: A Nucleus for a Web of Open Data.
ISWC 2007,data at http://dbpedia.orgMichele Banko, Michael J. Cafarella, Stephen Soderland,Matthew Broadhead, Oren Etzioni: Open InformationExtraction from the Web.
IJCAI 2007Jonathan Berant, Ido Dagan, Jacob Goldberger: GlobalLearning of Typed Entailment Rules.
ACL 2011Kurt D. Bollacker, Colin Evans, Praveen Paritosh, TimSturge, Jamie Taylor: Freebase: a collaborativelycreated graph database for structuring human knowl-edge.
SIGMOD Conference 2008, data at http://freebase.comLawrence D. Brown, T.Tony Cai, Anirban Dasgupta: In-terval Estimation for a Binomial Proportion.
StatisticalScience 16: 101?133, 2001Andrew Carlson, Justin Betteridge, Bryan Kisiel, BurrSettles, Estevam R. Hruschka Jr., Tom M. Mitchell.Toward an Architecture for Never-Ending LanguageLearning.
AAAI 2010, data at http://rtw.ml.cmu.edu/rtw/Timothy Chklovski, Patrick Pantel: VerbOcean: Miningthe Web for Fine-Grained Semantic Verb Relations.EMNLP 2004; data available at http://demo.patrickpantel.com/demos/verbocean/Anthony Fader, Stephen Soderland, Oren Etzioni:Identifying Relations for Open Information Extrac-tion.
EMNLP 2011, data at http://reverb.cs.washington.eduChristiane Fellbaum (Editor): WordNet: An ElectronicLexical Database.
MIT Press, 1998Jiawei Han, Jian Pei , Yiwen Yin : Mining frequent pat-terns without candidate generation.
SIGMOD 2000.Chikara Hashimoto, Kentaro Torisawa, Kow Kuroda,Stijn De Saeger, Masaki Murata, Jun?ichi Kazama:Large-Scale Verb Entailment Acquisition from theWeb.
EMNLP 2009Catherine Havasi, Robert Speer, and Jason Alonso.
Con-ceptNet 3: a Flexible, Multilingual Semantic Net-work for Common Sense Knowledge, RANLP 2007;data available at http://conceptnet5.media.mit.edu/Iris Hendrickx, Su Nam Kim, Zornitsa Kozareva, PreslavNakov, Diarmuid O Seaghdha, Sebastian Pado, MarcoPennacchiotti, Lorenza Romano, Stan Szpakowicz:SemEval-2010 Task 8: Multi-Way Classification ofSemantic Relations Between Pairs of Nominals, 5thACL International Workshop on Semantic Evaluation,2010; data available at http://www.isi.edu/?kozareva/downloads.htmlJohannes Hoffart, Fabian Suchanek, Klaus Berberich,Edwin Lewis-Kelham, Gerard de Melo, Ger-hard Weikum: YAGO2: Exploring and Query-ing World Knowledge in Time, Space, Con-text, and Many Languages.
WWW 2011, data athttp://yago-knowledge.orgRaphael Hoffmann, Congle Zhang, Daniel S. Weld:Learning 5000 Relational Extractors.
ACL 2010Vigo Kann: On the approximability of NP-complete opti-mization problems.
PhD thesis, Department of Numer-ical Analysis and Computing Science, Royal Instituteof Technology, Stockholm.
1992.Karin Kipper, Anna Korhonen, Neville Ryant,Martha Palmer, A Large-scale Classification ofEnglish Verbs, Language Resources and Evalua-tion Journal, 42(1): 21-40, 2008, data available athttp://verbs.colorado.edu/?mpalmer/projects/verbnet/downloads.htmlZornitsa Kozareva, Eduard H. Hovy: Learning Argu-ments and Supertypes of Semantic Relations UsingRecursive Patterns.
ACL 2010Girija Limaye, Sunita Sarawagi, Soumen Chakrabarti:Annotating and Searching Web Tables Using Entities,Types and Relationships.
PVLDB 3(1): 1338-1347(2010)Dekang Lin, Patrick Pantel: DIRT: discovery of inferencerules from text.
KDD 20011144Marie-Catherine de Marneffe, Bill MacCartney andChristopher D. Manning.
Generating Typed Depen-dency Parses from Phrase Structure Parses.
LREC2006.Thahir Mohamed, Estevam R. Hruschka Jr., Tom M.Mitchell: Discovering Relations between Noun Cat-egories.
EMNLP 2011Ndapandula Nakashole, Martin Theobald, GerhardWeikum: Scalable Knowledge Harvesting with HighPrecision and High Recall.
WSDM 2011Preslav Nakov, Marti A. Hearst: Solving Relational Simi-larity Problems Using the Web as a Corpus.
ACL 2008Vivi Nastase, Michael Strube, Benjamin Boerschinger,Ca?cilia Zirn, Anas Elghafari: WikiNet: A Very LargeScale Multi-Lingual Concept Network.
LREC 2010,data at http://www.h-its.org/english/research/nlp/download/wikinet.phpRoberto Navigli, Simone Paolo Ponzetto: BabelNet:Building a Very Large Multilingual Semantic Net-work.
ACL 2010 data at http://lcl.uniroma1.it/babelnet/Marius Pasca, Benjamin Van Durme: What You Seek IsWhat You Get: Extraction of Class Attributes fromQuery Logs.
IJCAI 2007Marius Pasca, Benjamin Van Durme: Weakly-SupervisedAcquisition of Open-Domain Classes and Class At-tributes from Web Documents and Query Logs.
ACL2008Andrew Philpot, Eduard Hovy, Patrick Pantel: TheOmega Ontology, in: Ontology and the Lexicon,Cambridge University Press, 2008, data at http://omega.isi.edu/Simone Paolo Ponzetto, Michael Strube: Deriving aLarge-Scale Taxonomy from Wikipedia.
AAAI 2007,data at http://www.h-its.org/english/research/nlp/download/wikitaxonomy.phpJoseph Reisinger, Marius Pasca: Latent Variable Modelsof Concept-Attribute Attachment.
ACL/AFNLP 2009Ramakrishnan Srikant, Rakesh Agrawal: Mining Se-quential Patterns: Generalizations and PerformanceImprovements.
EDBT 1996Fabian M. Suchanek, Gjergji Kasneci, Gerhard Weikum:YAGO: a Core of Semantic Knowledge.
WWW 2007Fabian M. Suchanek, Mauro Sozio, Gerhard Weikum:SOFIE: a self-organizing framework for informationextraction.
WWW 2009Lin Sun, Anna Korhonen: Hierarchical Verb ClusteringUsing Graph Factorization.
EMNLP 2011Petros Venetis, Alon Y. Halevy, Jayant Madhavan, MariusPasca, Warren Shen, Fei Wu, Gengxin Miao, ChungWu: Recovering Semantics of Tables on the Web.PVLDB 4(9): 528-538, 2011Tom White: Hadoop: The Definitive Guide, 2nd Edition.O?Reilly, 2010.Fei Wu, Daniel S. Weld: Automatically refining the wiki-pedia infobox ontology.
WWW 2008Wentao Wu, Hongsong Li, Haixun Wang, Kenny Q. Zhu:Towards a Probabilistic Taxonomy of Many Concepts.Technical Report MSR-TR-2011-25, Microsoft Re-search, 2011Limin Yao, Aria Haghighi, Sebastian Riedel, AndrewMcCallum: Structured Relation Discovery using Gen-erative Models.
EMNLP 2011Jun Zhu, Zaiqing Nie, Xiaojiang Liu, Bo Zhang, Ji-RongWen: StatSnowball: a statistical approach to extractingentity relationships.
WWW 20091145
