Proceedings of the Workshop on Distributional Semantics and Compositionality (DiSCo?2011), pages 38?42,Portland, Oregon, 24 June 2011. c?2011 Association for Computational LinguisticsShared task system description: Measuring the Compositionality ofBigrams using Statistical MethodologiesTanmoy Chakraborty, Santanu Pal, Tapabrata Mondal, Tanik Saikh,Sivaji BandyopadhyayDepartment of Computer Science and EngineeringJadavpur Universityits_tanmoy@yahoo.co.in, santanu.pal.ju@gmail.com,tapabratamondal@gmail.com, tanik4u@gmail.com,sivaji_cse_ju@yahoo.comAbstractThe measurement of relativecompositionality of bigrams is crucial toidentify Multi-word Expressions(MWEs) in Natural LanguageProcessing (NLP) tasks.
The articlepresents the experiments carried out aspart of the participation in the sharedtask ?Distributional Semantics andCompositionality (DiSCo)?
organized aspart of the DiSCo workshop in ACL-HLT 2011.
The experiments deal withvarious collocation based statisticalapproaches to compute the relativecompositionality of three types ofbigram phrases (Adjective-Noun, Verb-subject and Verb-object combinations).The experimental results in terms of bothfine-grained and coarse-grainedcompositionality scores have beenevaluated with the human annotated goldstandard data.
Reasonable results havebeen obtained in terms of average pointdifference and coarse precision.1 IntroductionThe present work examines the relativecompositionality of Adjective-Noun (ADJ-NN;e.g., blue chip), Verb-subject (V-SUBJ; wherenoun acting as a subject of a verb, e.g., nameimply) and Verb-object (V-OBJ; where nounacting as an object of a verb, e.g., beg question)combinations using collocation based statisticalapproaches.
Measuring the relativecompositionality is useful in applications such asmachine translation where the highly non-compositional collocations can be handled in aspecial way (Hwang and Sasaki, 2005).Multi-word expressions (MWEs) aresequences of words that tend to co-occur morefrequently than chance and are eitheridiosyncratic or decomposable into multiplesimple words (Baldwin, 2006).
Decidingidiomaticity of MWEs is highly important formachine translation, information retrieval,question answering, lexical acquisition, parsingand language generation.
Compositionalityrefers to the degree to which the meaning of aMWE can be predicted by combining themeanings of its components.
Unlike syntacticcompositionality (e.g.
by and large), semanticcompositionality is continuous (Baldwin, 2006).Several studies have been carried out fordetecting compositionality of noun-noun MWEsusing WordNet hypothesis (Baldwin et al,2003), verb-particle constructions usingstatistical similarities (Bannard et al, 2003;McCarthy et al, 2003) and verb-noun pairsusing Latent Semantic Analysis (Katz andGiesbrecht, 2006).Our contributions are two-fold: firstly, weexperimentally show that collocation basedstatistical compositionality measurement canassist in identifying the continuum ofcompositionality of MWEs.
Secondly, we showthat supervised weighted parameter tuningresults in accuracy that is comparable to the bestmanually selected combination of parameters.382 Proposed MethodologiesThe present task was to identify the numericaljudgment of compositionality of individualphrase.
The statistical co-occurrence featuresused in this experiment are described.Frequency:  If two words occur togetherquite frequently, the lexical meaning of thecomposition may be different from thecombination of their individual meanings.
Thefrequency of an individual phrase is directlyused in the following methods.Point-wise Information (PMI): Aninformation-theoretic motivated measure fordiscovering interesting collocations is point-wisemutual information (Church and Hanks, 1990).It is originally defined as the mutual informationbetween particular events X and Y and in ourcase the occurrence of particular words, asfollows:  = log,. ?
log,.   1PMI represents the amount of informationprovided by the occurrence of the eventrepresented by X about the occurrence of theevent represented by Y.T-test:  T-test has been widely used forcollocation discovery.
This statistical test tells usthe probability of a certain constellation(Nugues, 2006).
It looks at the mean andvariance of a sample of measurements.
The nullhypothesis is that the sample is drawn from adistribution with mean.
T-score is computedusing the equation (2):,  = ,  ?
 !
",  + ""?
$,%&'(')* +$,% ??????
.
.
2In both the equations (1) and(2), C(x) andC(y) are respectively the frequencies of word Xand word Y in the corpus, C(X,Y) is thecombined frequency of the bigrams <X Y> andN is the total number of tokens in the corpus.Mean value of P(X,Y) represents the averageprobability of the bigrams <X Y>.
The bigramcount can be extended to the frequency of wordX when it is followed or preceded by Y in thewindow of K words (here K=1).Perplexity: Perplexity is defined as 2H(X)        2.$ = 2&?
 0123 4 ????
.
3where H(X) is the cross-entropy of X.
Here, X isthe candidate bigram whose value is measuredthroughout the corpus.
Perplexity is interpretedas the average ?branching factor?
of a word: thestatistically weighted number of words thatfollow a given word.
As we see from equation(4), Perplexity is equivalent to entropy.
The onlyadvantage of perplexity is that it results innumbers more comprehensible for humanbeings.
Here, perplexity is measured at bothroot level and surface level.Chi-square test: The t-test assumes thatprobabilities are approximately normallydistributed, which may not be true in general(Manning and Sch?tze, 2003).
An alternativetest for dependence which does not assumenormally distributed probabilities is the ?2-test(pronounced ?chi-square test?).
In the simplestcase, this 2 test is applied to a 2-by-2 table asshown below:X = new X ?
newY= companies n11(newcompanies)n12(e.g., oldcompanies)Y ?companiesn21(e.g., newmachines)n22(e.g., oldmachines)Table 1: A 2-by-2 table showing the dependenceof occurrences of new and companiesEach variable in the above table depicts itsindividual frequency, e.g., n11 denotes thefrequency of the phrase ?new companies?.The idea is to compare the observedfrequencies in the table with the expectedfrequencies when the words occurindependently.
If the difference betweenobserved and expected frequencies is large, thenwe can reject the null hypothesis ofindependence.
The equation for this test isdefined below: 6= 78998?
8989899 + 89899 + 8989+ 889 + 8  4where 8?
@ = ?
?AA7 ??
A@A7 ?
7N is the number of tokens in the corpus.393 Used Corpora and DatasetThe system has used the WaCkypedia_EN 1corpora which are a 2009 dump of the EnglishWikipedia (about 800 million tokens).
Thecorpus was POS-tagged and lemmatizedfollowed by full dependency parsing.
The totalnumber of candidate items for each relation typeextracted from the corpora is: ADJ-NN (144,102), V-SUBJ (74, 56), V-OBJ (133, 96).
Thefirst number within brackets is the number ofitems with fine-grained score, while the secondnumber refers to the number of items withcoarse grained score.
These candidate phrasesare split into 40% training, 10% validation and50% test sets.
The training data set consists ofthree columns: relation (e.g., EN_V_OBJ),phrase (e.g., provide evidence) and judgmentscore (e.g.
"38" or "high").
Scores wereaveraged over valid judgments per phrase andnormalized between 0 and 100.
These numericalscores are used for the Average Point Differencescore.
For coarse-grained score, phrases withnumerical judgments between 0 and 33 as?low?, 34 to 66 as ?medium?
and 66 and overgot the label "high".4 System ArchitectureThe candidate items for each relation type areput in a database.
For each candidate, all thestatistical co-occurrence feature values likefrequency, PMI, T-test, Perplexity (root andsurface levels) and Chi-square tests arecalculated.
The final fine-grained scores arecomputed as the simple average and weightedaverage of the individual statistical co-occurrence scores.
Another fine-grained score isbased on the T-test score that performed best onthe training data.
Coarse-grained scores areobtained for all the three fine-grained scores.1http://wacky.sslmit.unibo.it/5 Weighted CombinationThe validation data is used as thedevelopment data set for our system.
Theweighted average of the individual statistical co-occurrence scores is calculated by assigningdifferent weights to each co-occurrence featurescore.
The weights are calculated from thetraining data using the average point differenceerror associated with the co-occurrence feature.The feature which gives minimum error score isassigned the higher weight.
For each co-occurrence feature score i, if the error on thetraining data is ei, the weight Wi assigned to theco-occurrence feature score i is defined as:C?
=  100 ?
??
100 ?
??
5The individual co-occurrence feature scores arenormalized to be in the range of 0 to 1 beforecalculating the weighted sum.Note that, when measuring coarse-precision,the fine-grained scores are bucketed into threebins as explained in Section 3.6 Evaluation MetricsThe system output is evaluated using thefollowing evaluation metrics:Average Point Difference (APD): the meanerror (0 to 100) is measured by computing theaverage difference of system score and test datascore.
The minimum value implies the minimumerror and the maximum accuracy of the system.Coarse Precision (CP): the test data scores arebinned into three grades of compositionality(non-compositional, somewhat compositional,and fully-compositional), ordering the output byscore and optimally mapping the system outputto the three bins.Errors PMI T test Perx-RootPerx-SurfacechisquareAverage WeightedAverageAPD 29.35 24.25 35.23 31.4 36.57 21.22 21.20CP 0.31 0.60 0.48 0.42 0.45 0.57 0.62Table 2: Evaluation results on different approaches on validation data40SystemSpearmanrhoKendall?sTauAverage Point Difference (APD) Coarse Precision (CP)ALL ADJ-NNV-SUBJV-OBJALL ADJ-NNV-SUBJV-OBJBaseline 0.20 0.20 32.82 34.57 29.83 32.34 0.297 0.288 0.300 0.308RUN-1 0.33 0.23 22.67 25.32 17.71 22.16 0.441 0.442 0.462 0.425RUN-2 0.32 0.22 22.94 25.69 17.51 22.60 0.458 0.481 0.462 0.425RUN-3 -0.04 -0.03 25.75 30.03 26.91 19.77 0.475 0.442 0.346 0.600Table 3: Overall System results on test setSpearman's rho coefficient: it is used toestimate strength and direction of associationbetween two ordinal level variables (i.e., goldstandard results and system results).
It can rangefrom -1.00 to 1.00.Kendall?s tau rank coefficient: it is a measureof rank correlation, i.e., the similarity of theorderings of the gold standard results and thesystem results.
This coefficient must be in therange from -1 (complete disagreement) to 1(complete agreement).7 Experimental ResultsThe system has been trained using the trainingdata set with their fine-grained score.
Theevaluation results on the validation set areshown in Table 2.
It is observed that T-test givesthe best results on the validation data set interms of precision.
Based on the validation setresults, three procedural approaches are run andthree results are reported on the test data.RUN-1 (Weighted Combination):  Theseresults are obtained from the weightedcombination of individual scores.
Both theperplexity measures are not useful to makesignificant gain over the compositionalitymeasure.
For the rank combination experiments,the best co-occurrence measures, i.e., PMI, Chi-square and T-test are considered.
For theweighted combination, the results are reportedfor the weight triple (0.329, 0.309, 0.364) forPMI, Chi-square and T-test respectively.RUN-2 (Average Combination): Theseresults are reported by simply averaging thevalues obtained from the five measures.RUN-3 (Best Scoring Measure: T-test): TheT-test results are observed as the best scoringmeasure used in this experiment.When calculating the coarse-grained score thecompositionality of each phrase is tagged as?high?, ?medium?
or ?low?
discussed in Section 3.The final test data set has been evaluated onthe gold standard data developed by theorganizers and the results on the three submittedruns are described in Table 3.
The positive valueof Spearman?s rho coefficient implies that thesystem results are in the same direction with thegold standard results; while the Kandell?s tauindicates the independence of the system valuewith the gold standard data.
As expected, Table3 shows that the weighted average score (Run 1)gives better accuracy for all phrases based on theAPD scores.
On the other hand, the T-test results(Run 3) give high accuracy for the coarseprecision calculation while it is in the lastposition for ADP scores.8 ConclusionsWe have demonstrated the usefulness ofstatistical evidences to indicate the continuum ofcompositionality of the bigrams, i.e., adjective-noun, verb-subject and verb-objectcombinations.
The coarse precision can beimproved if three ranges of numerical values canbe tuned properly and the size of the three binscan be varied significantly.
As part of our futuretask, we plan to use other statistical collocation-based methods (e.g.
Log-likelihood ratio,Relative frequency ratios etc.
).AcknowledgementThe work has been carried out with support from?Indian Language to Indian Language MachineTranslation (ILMT) System Phrase II?, fundedby DIT, Govt.
of India.41ReferencesYoung-Sook Hwang and Yutaka Sasaki.
2005.Context-dependent SMT model using bilingualverb-noun collocation.
In proceedings of 43rdAnnual Meeting of association for CompositionalLinguistics (ACL?
05).T.
Baldwin.
2006.
Compositionality and MWEs: Sixof one, half a dozen of the other?
In proceedings ofthe MWE workshop.
ACL.T.
Baldwin, C. Bannard, T. Tanaka, and D.Widdows.
2003.
An empirical model of MWEdecomposability.
In proceedings of the MWEworkshop.
ACL.C.
Bannard, T. Baldwin, and A. Lascarides.
2003.
Astatistical approach to the semantics of verb-particles.
In proceedings of the MWE workshop.ACL.G.
Katz and E. Giesbrecht.
2006.
Automaticidentification of non-compositional MWEs usinglatent semantic analysis.
In proceedings of theMWE workshop.
ACL.Church, K. W. and Hanks, P. 1990.
Word associationnorms, mutual information and lexicography.Computational Linguistics, 16(1):22-29Christopher D. Manning and Hinrich Sch?tze,.
2003.Foundations of Statistical Natural LanguageProcessing, The MIT Press, Cambridge,Massachusetts, London, England.Pierre M. Nugues.
2006.
An Introduction toLanguage Processing with Perl and Prolog,Springer.42
