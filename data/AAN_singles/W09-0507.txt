Proceedings of EACL 2009 Workshop on Semantic Representation of Spoken Language - SRSL 2009, pages 50?57,Athens, Greece, 30 March 2009. c?2009 Association for Computational LinguisticsDeeper spoken language understanding for man-machine dialogue onbroader application domains: a logical alternative to concept spottingJeanne VillaneauUEB (Universite?
Europe?enne de Bretagne)VALORIAFrancevillanea@univ-ubs.frJean-Yves AntoineUniversite?
Franc?ois Rabelais - ToursLIFranceJean-Yves.Antoine@univ-tours.frAbstractLOGUS is a French-speaking spoken lan-guage understanding (SLU) system whichcarries out a deeper analysis than thoseachieved by standard concept spotters.
Itis designed for multi-domain conversa-tional systems or for systems that areworking on complex application domains.Based on a logical approach, the sys-tem adapts the ideas of incremental ro-bust parsing to the issue of SLU.
The pa-per provides a detailed description of thesystem as well as results from two evalu-ation campaigns that concerned all of cur-rent French-speaking SLU systems.
Theobserved error rates suggest that our log-ical approach can stand comparison withconcept spotters on restricted applicationdomains, but also that its behaviour ispromising for larger domains.
The ques-tion of the generality of the approach isprecisely addressed by our current inves-tigations on a new task: SLU for an emo-tional robot companion for young hospitalpatents.1 IntroductionDespite the indisputable advances of automaticspeech recognition (ASR), highly spontaneousspeech remains an important barrier to the widespreading of speech based applications.
The goalof spontaneous speech understanding remains fea-sible, provided the interaction between the userand the system is restricted to a task-oriented di-alogue (restricted vocabulary).
Present research isinvestigating mixed or user initiated dialogue forless restricted tasks.
It is the purpose of this paper,which focuses on spontaneous speech understand-ing in such complex applications.Generally speaking, information speech dia-logue systems are based on the same architecture.At first, a speech recognizer processes the speechsignal and provides a string (or a lattice) of wordsthat should correspond to the spoken sentence.Then, this string is parsed by a spoken languageunderstanding module (SLU) in order to build asemantic representation that represents its propo-sitional meaning.
Finally, this semantic structureis sent to a dialogue manager which controls theinteraction with the user (database interrogation,dialogue management, answer generation).
Theanswers to the user can be displayed on screenand/or through a message generated by a text-to-speech synthesis.
This paper focuses on the SLUmodule of such a dialogue system.
On the whole,SLU has to cope with two main difficulties:?
speech recognition errors: highly sponta-neous speech remains hard to recognize forcurrent ASR systems (Zue et al, 2000).Therefore, the SLU module has to work ona strongly corrupted string of words.?
spoken disfluencies: filled pauses, repetitionsand repairs make the parsing of conversa-tional spoken language significantly harder toachieve (Heeman, Allen, 2001).In order to overcome those difficulties, most SLUsystems follow a selective strategy which comesdown to a simple concept spotting: they restrictthe semantic analysis to a mapping of the sentencewith the main expectations of the user in relationwith the task (Minker W. et al, 1999; Bangalore S.et al, 2006).
Consider, for instance, an air trans-port information system and the following spokenutterance:(1) Cou- could you list me the flights uh thescheduled flights for Tenerife Tenerife TenerifeNorth pleaseSatisfying the speaker?s goals only requires de-tecting the nature of their requests (list flights) andthe required destination (Tenerife North).
Those50two concepts (list, Tenerife North) will fill a shal-low semantic frame which is supposed to repre-sent the useful meaning of the sentence.
Suchtask-driven approaches meet, to a great extent, theneeds of SLU in terms of robustness, since theyonly involve a partial analysis of the sentence.Whether the processing is based on a statistical ora knowledge-based approach, several evaluationcampaigns proved that concept spotting is suitablefor spoken language understanding, provided theapplication task is sufficiently restricted.
How-ever, concept spotters suffer from noticeable limi-tations:?
Although they resist gracefully speech recog-nition errors, they are not able to detect theireventual presence, since they do not considerthe global structure of the sentence.
This lim-itation can be particularly penalizing whenthe error is related to a key element, for ex-ample when the error prevents the system todetermine the type (dialogue act) of the ut-terance.
Indeed, concept spotters often baseSLU on the initial characterization of thequestion type.
When analyzing the errorsof his statistical concept spotter, Minker hasshown that the correct identification of thequestion type is a key issue in terms of finalrobustness (Minker W. et al, 1999).?
Since they are based on the identification ofrather flat semantic frames, these approacheshardly succeed in representing complex syn-tactic relations such as overlapping coordi-nate phrases or negations.?
Although it is well known that generality isan important issue for SLU, this questionis generally approached in term of technicalportability from one (narrow) task to another.Now, one should wonder whether conceptspotting is still suitable on larger applicationdomains.
It seems that the robustness of thespotting process depends strongly on the de-gree of lexical ambiguity of the consideredtask.
For instance, Bousquet has shown thatthe concept error rate of her stochastic spot-ter is two times higher on ambiguous wordsthan on non ambiguous ones (Bousquet et al,2003).Such considerations tend to show that to applyconcept spotting to more complex tasks could bedifficult.
Such observations are well known (Zech-ner K., 1998; Van Noord et al, 1999), and no-ticeable attempts have already been done to reacha deeper semantic analysis.
However, statisticalor knowledge-based concept spotting remains theprevailing paradigm in SLU, mainly because ofengineering motivations (quick and easy build-ing).
On the contrary, we have decided to de-velop a SLU system (LOGUS1) which carries outa complete analysis of the utterance while keep-ing the robustness of standard concept spotting ap-proaches.
The system, which is based on a logi-cal approach, adapts the ideas of incremental ro-bust parsing (A?
?t-Mokhtar S., 2002; Basili, 2003)to the issue of speech conversational systems.
Insection 2, we will describe the system into de-tail.
Then, section 3 will present results from dif-ferent evaluation campaigns in which we partici-pated.
These experiments concerned standard re-stricted tasks (hotel reservation for instance) forwhich concept spotting is well adapted.
As a re-sult, this section does not aim to prove a supe-riority of our approach, but simply to show thatthis deeper processing is able to keep a satisfac-tory robustness, by comparison with prevailing ap-proaches.
Finally, we give in section 4 a brief de-scription on our present work concerning the inte-gration of LOGUS in a conversational robot whichis dedicated to general interaction with childrenwho are in hospital for a long-stay.
This exam-ple will illustrate the portability abilities of our ap-proach on complex application tasks, in additionwith our previous works on general tourism infor-mation.2 Description of the LOGUS systemThe task of a SLU is to turn a sequence or a graphof words into a semantic representation; so a SLUsystem has to perform a translation from naturallanguage to a formal target language.
This sectionbegins with the description of the formal languagechosen for the LOGUS system.
We then explainthe basic principles of parsing and its main steps.2.1 Semantic representationWhen it comes to the choice of a target languagefor the system, the following points must be takeninto account.?
We want to implement automatic understand-ing in application domains where predefined1LOGical Understanding System.51semantic frames are not sufficient to repre-sent all the possible queries (Van Noord et al,1999).
Furthermore, any SLU aims at pro-viding results usable by a dialogue manager:the target language must reconcile simplicitywith precision.?
This semantic representation must obviouslyextend to a pragmatic one.
That means that itshould involve the characterization of the di-alogue acts related to the speech turn (AustinJ.-L., 1962).We have chosen a formalism compatible withthese constraints and inspired by the illocutionarylogic of D. Vanderveken (Vanderveken D., 1981).In this formalism, the form of an elementary illo-cutionary act is F(P) where F is the illocutionaryforce, and P its propositional content.The LOGUS system thus provides a logical for-mula as the semantic representation of an utter-ance.
A language act contains clues about the in-tentions of the speaker: it is labelled illocutionaryforce, while the propositional content is a structurebuilt with the domain objects and their propertieswhich is called an object string.The following example shows a single speechturn uttered for a tourism information system:(2) j?ai re?serve?
une chambre dans un deuxe?toiles l?ho?tel euh l?ho?tel Rex pour y aller d?icicomment est-ce que je peux faire (I booked a roomin a two-star hotel in the hotel hum in the Rex hotelfrom here how can I go at there)This turn expresses two different language acts,which is quite usual in conversational speech:a piece of information (I booked a room...) isfollowed by the user question (... how can I go....Such complex speech turns are difficult to analyzefor concept spotters, since they usually basethe parsing on one language act detection.
Thelogical formula LOGUS provides is split into twolanguage acts: (information act) and (questionhow).
The second act is interpreted by the systemin the context of the first one:((information act)(of (reservation [])(hotel [(ident.
(name ?Rex?
)),(star (int 2))])))((question how)(to go [(to (contextual location [])),(from (hotel [(ident.
(name ?Rex?
))]))]))In the formula, reservation, hotel and to go areobject labels; (ident.
(name ?Rex?
)), (star (int 2))are properties.
The two objects of labels reserva-tion and hotel are linked with the generic relationof, which indicates a subordination relation.
It isthe main relation, (in addition with logical coordi-nations and, or and not) which is used for buildingcomplex object strings.2.2 General system architectureIncremental parsing methodology is used for textparsing in order to combine efficiency with robust-ness (A?
?t-Mokhtar S., 2002).
With LOGUS, wetried to show that such methods can be extendedto spoken language parsing.The system has to parse out-of-grammar con-structions but spoken language studies have shownthat minimal syntactic structures are generally pre-served in repairs and false-starts (Mc Kelvie D.,1998).
We have thus chosen to carry out anincremental bottom-up parsing, where words aregradually combined.
At the beginning, the parsergroups words according to mainly syntactic rulesin order to form minimal chunks that correspondto basic concepts of the application domain.
Then,as word group size increases, their meaning be-comes more precise, enough to relax syntactic cri-teria and thereby overcome the problem of out-of-grammar sentences.The general architecture of the system is shownin Figure 1.
The parsing is essentially split intothree stages.
The first stage is chunking (Ab-ney S., 1991) where grammatical words are linkedto the lexical words to which they are referred.The following stage gradually builds links be-tween the chunks in order to detect semantic re-lations between the corresponding concepts, andthe last one achieves a contextual interpretation(anaphoric resolution for instance).
The processof building links between chunks and contextualunderstanding uses a domain ontology.Only one formalism is used during these pars-ing stages.
It is designed to distinguish syntax andsemantics and to preserve genericity of the pars-ing rules.
Each component is specified by a listof what we can call definitions; each of them is atriplet < C, R, T > whereC: is a syntactic label, called syntactic category:for example adjective, (verb 1 present).R: points out the semantic function of the compo-nent.
It is called semantic role: for exampleobject, (prop price) where prop is for prop-erty.52?
level 1?
level 2?
level 3?
semantic kerneldependenciescontextual understandingchunk dependencieschunkingword sequencedomainontologylexiconlogical formulaFigure 1: General architecture of the LOGUS sys-temT: is the semantic translation.
It is an elementof the logical formula built by the system.
Itbelongs thus to the target language.The first two triplet elements, C and R, arewidely domain independent.
A basic principle isto define parsing rules from these elements in or-der to preserve the genericity of the system.
Eachparsing rule combines two or three triplets in orderto build a new result triplet.2.3 ChunkingOur experiments with LOGUS have clearly shownthat chunking is effective for spoken language,provided the chunks are very short: more pre-cisely, errors made at the speech recognition levelmake it dangerous to link objects or properties ac-cording to pure syntactic criteria, without check-ing these links with semantic criteria.
Thereforethe chunks built by LOGUS include only one con-tent word: we call them minimal chunks.
Chunk-ing is based on the principle of linking functionwords to the near content word.The formalism used in this step is inspired byCategorial Grammars of the AB type2, whoserules are generalized from the first two elements ofthe constituent triplets.
Function words have def-initions in which syntactic category and semanticrole are fractional.
In such definitions, the seman-tic translation is a ?-abstraction (in the ?-calculusmeaning)3.
The semantic translation of the re-sult triplet is achieved by applying this abstrac-tion to the semantic translation of the un-fractionaltriplet.
Formally, the following two rules are ap-plied, where F is an abstraction:< CA/CB, RA/RB, F >, < CB, RB, SB >?
< CA, RA, (F SB) >< CB, RB, SB >,< CB\CA, RB\RA, F >?
< CA, RA, (F SB) >2The formalism can be expressed in terms of pregroupformalism too (Lambek J., 1999).3LOGUS is implemented in ?Prolog, a logic programminglanguage whose terms are ?-terms with simple types.In the following example only one definition isshown for each component (gn is for nominalgroup).trois (three) e?toiles (stars)C adj num adj num\gnR (prop nb) (prop nb)\(prop nb star)S (int 3) ?x.
(star x)By applying the second rule, we obtain the fol-lowing chunk:?trois e?toiles?
(three stars)<gn, (prop nb star), (star (int 3))>.The semantic translation of the result tripletis obtained by ?-reduction of the ?-term(?x.
(star x) (int 3)).
For example, the utterance(3) ?
`A l?ho?tel Caumartin quels sont le les tar-ifs pour pour une chambre double?
(In Caumartinhotel what are the the prices for for a double room)is segmented into six chunks during the chunkingstage.
Their semantic translations are:[1] (hotel []),[2] (identity (name ?Caumartin?
))]),[3] (what (interrogation)), [4] (price []),[5] (room []), [6] (size double).At the end of the chunking process, the deter-miner le and the first occurrence of the prepositionpour are deleted because they are fragments with-out semantic content.
Deletions such as these area first way of dealing with repairs.2.4 Domain ontologyThe limited scope of the application domainmakes it possible to describe exhaustively thepragmatic and semantic domain knowledge.
A do-main ontology specifies how objects and proper-ties can be compounded.
The handled processingsare expected to be generic while using a domaindependent ontology: to achieve that, the ontologyis defined by generic predicates whose domain ob-jects and domain properties are the arguments.For example, the possibility of building the con-ceptual relation of between two objects (cf.
2.1)is defined by the predicate is sub object whosearguments are two object labels: so the relationis sub object(room, hotel) expresses a part-wholerelation possibility between such two objects.2.5 Chunk dependenciesChunk dependencies are built by an incrementalprocess which is compound of several successivestages.
Each stage is based on rewriting rules53which are specified from the first two componentsof the constituent triplets and from the generic on-tology predicates.
They are thus not specific to thedomain of application, what assures, to a certainextent, the genericity of the process.Consider for instance the following rule, whichleads to the binding of two consecutive chunkswhich share a meronomic (part of) relation:< C1, object, O1 >, < C2, object, O2 >- O1 simple object of label Et1- O2 object string of label Et2- is sub object(Et1, Et2)< C, object, (of O1 O2) >where C is obtained by composing C1 and C2.As an illustration, this rule will form a com-plex object (of (price []) (room [(size double)]))from the initial two chunks (price []) and (room(size double)).
This rule is completely generic andshould apply on any task.
The knowledge spe-cific to the task intervenes only on the definition ofthe predicate is sub object.
As a result, one couldspeak of procedural genericity to qualify our sys-tem.As long as possible, the first processing stagestry to respect syntactic criteria.
However, in pres-ence of spoken disfluencies or speech recogni-tion errors, it is likely that the utterance is out-of-grammar.
Therefore, since the detected linksbetween chunks make the meaning of the linkedchunks more specific, the next stage tries to detectchunk dependencies more on more on semantic orpragmatic features only.
Subsequently, studyingdependencies between the components makes itpossible to eliminate some components, especiallyin the case of word recognition errors.As an illustration, Figure 2 shows how links aregradually built during the parsing stage of utter-ance (3) (cf.
section 2.3).
The chunks are in rect-angular boxes in dotted lines.The first step of chunk binding links the first twochunks into the object:(hotel [(ident.
(name ?Caumartin?
))]).The second step links the object (room []) withthe property (size (double)) to obtain the object(room [(size double)]).
Then, the two objects priceand room are linked with the conceptual relation ofto obtain (of (price []) (room [(size double)])) andthis object string is connected to the language act:(question what).
The position of the prepositionalphrase a` l?hotel Caumartin is not usual in Frenchsyntagmatic ordering.
It is indeed an example ofextraposition which is not accepted by the syn-tactic constraints considered by the system.
As aresult, the conceptual relation of, which links theobject of label room with the object (hotel [ident.
(name ?Caumartin?)])
is built later, when theseconstraints are relaxed.2.6 Contextual understandingMany sentences are elliptical and incomplete in adialogue.
Therefore, it is necessary to use the cur-rent context of the task and the dialogue historyin order to complete their understanding.
The ob-jectives of the contextual understanding in LOGUSare thus close to the objectives of the authors of theOntoSem system (McShane M., 2005): the com-pletion of semantic fragments.
Reference resolu-tion is thereby extended to a more general comple-tion of the semantic representation.While syntactic anaphora criteria are generallyrespected in texts, anaphora gender and numberare frequently broken in spoken language.
More-over, gender and number morphological marks arehardly perceptible in spoken French.
They aretherefore very often corrupted by speech recogni-tion errors.
So, in the LOGUS system, anaphoraresolution is based on the same principles as therest of the parsing: combining syntactic and se-mantic criteria.
Both nominal and pronominalanaphora (with definite expressions) are consid-ered during this contextual interpretation stage.Completion is based on the concept of objectstring.
A property or an object may be completedby an ?over-object?
of the context, if the ontologymakes it possible to do so.
For example, the ob-ject price of the sentence ?quel est le tarif?
(whatis the price) is automatically completed in(of (price []) (of (room []) (hotel [(name ?Rex?
)]))if the object string (of (room []) (hotel [(name?Rex?)]))
is an object string which is part of theprevious utterance.3 Evaluations and resultsLOGUS is a French-speaking system.
It took partin the two evaluation campaigns that were carriedout in the last year designed for French spokenlanguage understanding: the GDR-I3 challenge-based campaign and the MEDIA project.3.1 The GDR-I3 campaignLOGUS took part in the challenge-based cam-paign, held by the GDR-I3 consortium of the54questionwhat[a l hotel] [Caumartin] [quels sont]identity[les tarifs]price[pour unechambre]room[double]sizedoubleofof:level 3: level2name"Caumartin"pourand le and elimination of: level 1hotelprocessAfter chunkingconceptchunk conceptual relationFigure 2: Characterization of chunk dependencies : example on the utterance ?
a` l?hotel Caumartin quelssont le les tarifs pour pour une chambre double?
(in Caumartin hotel what are the the prices for for adouble room.French CNRS research agency (Antoine et al,2002).
We won?t describe here in detail the re-sults of this campaign, since it concerned a for-mer version of LOGUS.
It seems however in-teresting to analyse the distribution of the errorsmade by LOGUS to have an idea of the benefitsof our approach.
The evaluation corpus was di-vided among several tests which were respectivelyrelated to a specific difficulty: speech recognitionerrors, speech repairs and other disfluences, and fi-nally messages of a structural complexity (embed-ded coordination or subordination, for instance)significantly higher than those usually met in stan-dard ATIS-like application domains.The distribution of the concept error rates of theLOGUS SLU system is the following:Speech recognition: 9.5%Complex structures: 9.8%Repairs: 15%It should be noted here that the robustness ofLOGUS decreases rather gracefully on complexmessages, while SLU systems based on conceptspotting meet real difficulties on such utterances.For instance, Cacao (Bousquet-Vernhettes et al,1999; Bousquet-Vernhettes et al, 2003) is a con-cept spotter which participated to the GDR-I3campaign.
It has been shown that most of its er-rors resulted from its difficulties to resolve lexicalambiguities in complex sentences.
This observa-tion suggests that our logical deep parsing shouldfulfill better than concept spotting the needs ofcomplex application domains such as general pur-pose tourist information or collaborative plan-ning (Allen J. et al, 2002), or even multi-domainapplications (Dzikovska M. et al, 2005).
Unfortu-natedly, French evaluation campaigns have neverinvestigated such difficult tasks.3.2 The MEDIA projectMEDIA-EVALDA was an evaluation campaignhold by the French Ministry of Research.
It con-cerned all the French laboratory working on SLU.Once again, this evaluation investigated a ratherrestricted application domain: hotel reservation.It is well known that concept spotters fit succes-fully such simple tasks.
Nevertheless, we decidedto take part in this evaluation in order to see towhich extent LOGUS should be compared to stan-dard concept spotters in such disavantageous con-ditions.Participants defined reservation scenarios whichwere used to build a corpus made up of 1250recorded dialogues.
Recording used a WOZ sys-tem simulating vocal tourist phone server (Dev-illers et al, 2004).
The MEDIA corpus, whichis made up of real-life French spontaneous dia-logues, is surely to become a benchmark referencefor French contextual SLU.The evaluation paradigm forced every partici-pant to convert his own semantic representationinto a common reference, which relies-on an at-tribute/value frame: each utterance is divided intosemantic segments, aligned on the sentence, andeach segment is represented by a triplet: (mode,attribute, value).
Relations between attributes arerepresented by their order in the representation andthe composed attribute names.Nine systems participated to this first campaign.An error was count for any difference with oneof the elements of the reference (mode, attribute55System 1 2 3 4 (LOGUS) 5Approach conceptspottingconceptspottingsyntacticdeep parsinglogicaldeep parsingconceptspottingError rate 29.0% 30.3% 36.3% 37.8% 41.3%Table 1: MEDIA results.or value).
Table 1 summarises the results of thebest five systems.
At first glance, one should findthe reported error rates rather deceptive.
How-ever, one must realize that the test corpus involvedhighly spontaneous conversational speech, withvery frequent speech disfluences.
As a result,these results should be compared, for instance,to ASR errors rates observed on the SWITCH-BOARD corpus (Greenberg S. et al, 2000).LOGUS was ranked fourth and its robustnesswas rather close to the best participants.
Now,if you consider that the systems ranked 1st, 2ndand 5th were using a concept spotter, these re-sults shows that our approach can bear compar-ison with standard approaches even on this task.These encouraging performances suggest that it ispossible to achieve a deep understanding of con-versational speech while respecting at the sametime some robustness requirements: our approachseems indeed competitive even in a domain whereconcept spotters are known to be very efficient.
Toour mind, the interest of our approach is that thisrobustness should remain on larger application do-mains.
We are precisely trying to test this gener-icity by adapting LOGUS to a wider applicationdomain in the framework of the Emotirob project.4 Genericity and portability experimentWe are currently testing the portability of ourapproach by adapting LOGUS to a really differ-ent task, which corresponds to an unrestrictedapplication domain, general purpose understand-ing of child language, with additional emotionalstate detection.
The whole project, supported byANR (National French Research Agency), aimsat achieving a robot companion which can inter-act with sick or disabled young children with thehelp of facial expressions.
Although the robotdoes not have to react to every speech act of thechild, we have to deal with spoken understandingin an unrestricted domain.
Fortunately, the age ofthe children involved (3-5) implies a restricted vo-cabulary.
This work is still in progress.
Our firstinvestigations suggest however that LOGUS is asuitable understanding system for the pursued pur-pose: since there will never be significant corporarelated to this kind of task, we can?t use statisti-cal methods.
Moreover, because of the generic-ity of LOGUS, the main part of the analysis canbe reused without important changes.
Thus, three-month work was enough to build a first prototypeof the system and the problem is restricted to themain problem of this project: building an ontologywhich models the cognitive and emotional worldof young children.The generality of the used formalism makes itpossible to include an emotional component byturning the triplet structure into a quadruplet struc-ture.
Of course, composition rules have to in-clude this new component.
We are currently work-ing on the computation of the emotional statesfrom both prosodic and lexical cues.
Whereasmany works have investigated a prosodic-baseddetection (Devillers et al, 2005), word-based ap-proaches remain quite original.
Our hypothesis isthat emotion is compositional, e.g.
that is pos-sible to compute the global emotion carried by asentence from the emotion of every content word.This calculation depends obviously of the seman-tic structure of the utterance: our system willprecisely benefit from the characterization of thechunk dependencies carried on by LOGUS.
For themoment being, we are working on the definition ofa complete lexical norm of emotional values fromchildren of 3, 5 and 7 years.
This norm will beestablished in collaboration with psycholinguistsfrom Montpellier University, France.5 ConclusionWhen we started implementing the LOGUS sys-tem, one of our objectives was to achieve robustparsing of spontaneous spoken language whilemaking the application domain much wider thanis currently done.
Logical formalisms are not usu-ally viewed as efficient tools for pragmatic appli-cations.
The promising results of LOGUS showthat they can be brought into interesting new ap-proaches.56Another objective was to have a rather genericsystem, despite the use of a domain-based seman-tic knowledge.
We have fulfilled this constraintthrough the definition of generic predicates aswell as generic rules working on semantic tripletsor quadruplets which makes it possible to havegeneric chunk linking rules.
The performances ofLOGUS show that a deeper understanding can bearcomparison with concept spotting approaches.ReferencesAbney S. 1991.
Parsing by Chunks.
Principle BasedParsing.
R. Berwick, S. Abney and C. Tenny Eds.Kluwer Academix Publishers.A?
?t-Mokhtar S., Chanod J.-P. and Roux C. 2002.Robustness beyond Shallowness: Incremental DeepParsing.
Natural Language Engineering, 8 (2-3):p. 121?144.Allen J. and Ferguson G. 2002.
Human-Machine Col-laborative Planning.
Proc.
of the 3rd InternationalNASA Workshop on Planning and Scheduling forSpace, Houston, TX.Antoine J.-Y.
et al 2002.
Predictive and Ob-jective Evaluation of Speech Understanding: the?challenge?
evaluation campaign of the I3 speechworkgroup of the french CNRS.
Proceedings ofthe LREC 2002, 3rd International Conference onLanguage Resources and Evaluation, Las Palmas,Spain.Austin J.-L. 1962.
How to do things with words.
Ox-ford.Bangalore S., Hakkani-Tu?r D. and Tu?r G. 2006.
Spe-cial issue on Spoken Language Understanding inConversational Systems.
Speech Communication.48.Basili R. and Zanzotto F.M.
2003.
Parsing engineeringand empirical robustness.
Natural Language Engi-neering.
8 (2-3).Bousquet-Vernhettes C., Bouraoui J.-L. andVigouroux N. 2003.
Language Model Study forSpeech Understanding.
Proc.
Internationnal Work-shop on Speech and Computer (SPECOM?2003) ,Moscow, Russia, p. 205?208.Bousquet-Vernhettes C., Privat R. and Vigouroux N.2003.
Error handling in spoken dialogue systems:toward corrective dialogue.
ISCA workshop on Er-ror Handling in Spoken Dialogue Systems, Chteau-d?Oex-Vaud, Suisse, p. 41?45.Bousquet-Vernhettes C., Vigouroux N. and Pe?rennouG.
1999.
Stochastic Conceptual Model for Spo-ken Language Understanding.
Proc.
InternationnalWorkshop on Speech and Computer (SPECOM?99) ,Moscow, Russia, p. 71?74.Devillers L. et al 2004.
The French Evalda-Mediaproject: the evaluation of the understanding ca-pabilities of Spoken Language Dialogue Systems.Proceedings of the LREC 2004, 4rd InternationalConference on Language Resources and Evaluation,Lisboa, Portugal.Devillers L., Vidrascu, L. and Lamel, L. 2005.
Chal-lenges in real-life emotion annotation and machinelearning based detection.
Neural Networks, 18, p.407-422.Dzikovska M., Swift M. and Allen J. and de Beau-mont W. 2005.
Generic parsing for multi-domainsemantic interpretation.
Proc.
9th InternationalWorkshop on Parsing Technologies (IWPT05)), Van-couver BC.Greenberg S. and Chang, S. 2000.
Linguistic dissec-tion of switchboard-corpus automatic speech recog-nition systems.
Proc.
ISCA Workshop on AutomaticSpeech Recognition: Challenges for the New Mil-lennium, Paris, France.Heeman P. and Allen J.
2001.
Improving robustnessby modeling spontaneous events.
Robustness in lan-guage and speech technology, Kluwer Academics.Dordrecht, NL.
p. 123?152.Lambek J.
1999.
Type grammars revisited.
LogicalAspects of Computational Linguistics, A. Lecomte,F.
Lamarche and G. Perrier (eds), LNAI 1582,Springer, Berlin, p. 1?27.Mc Kelvie D. 1998.
The syntax of disfluency in spon-taneous spoken language.
HCRC Research Paper,HCRC/RP-95.McShane M. 2005.
Semantics-based resolution offragments and underspecified structures.
TraitementAutomatique des Langues, 46(1): p. 163?184.Minker W., Waibel A. and Mariani J.. 1999.
Stochas-tically based semantic analysis.
Kluwer Ac., Ams-terdam, The Netherlands.Vanderveken D. 2001.
Universal Grammar andSpeech act Theory.
Essays in Speech Act The-ory.
Eds J. Benjamin, D. Vanderveken and S. Kubo,p.
25?62.van Noord G., Bouma G. and Koeling R. and NederhofM.
1999.
Robust grammatical analysis for spokendialogue systems.
Natural Language Engineering.5(1): p. 45?93.Zechner K. 1998.
Automatic construction of framerepresentations for spontaneous speech in unre-stricted domains.
COLING-ACL?1998.
Montreal,Canada.
p. 1448?1452.Zue V., Seneff S., Glass J., Polifrini J., Pao C., HazenT.J.
and Hetherington L. 2000.
Jupiter: a telephone-based conversational interface for weather informa-tion.
IEEE Transactions on speech and audio pro-cessing.
8(1).57
