Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 206?209,Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational LinguisticsJU: A Supervised Approach to Identify Semantic Relations from PairedNominalsSantanu Pal         Partha Pakray             Dipankar Das          Sivaji BandyopadhyayDepartment of Computer Science & Engineering, Jadavpur University, Kolkata, Indiasantanupersonal1@gmail.com,parthapakray@gmail.com,dipankar.dipnil2005@gmail.com,sivaji_cse_ju@yahoo.comAbstractThis article presents the experiments carriedout at Jadavpur University as part of theparticipation in Multi-Way Classification ofSemantic Relations between Pairs of Nomi-nals in the SemEval 2010 exercise.
Separaterules for each type of the relations are iden-tified in the baseline model based on theverbs and prepositions present in the seg-ment between each pair of nominals.
Inclu-sion of WordNet features associated withthe paired nominals play an important rolein distinguishing the relations from eachother.
The Conditional Random Field (CRF)based machine-learning framework isadopted for classifying the pair of nominals.Application of dependency relations,Named Entities (NE) and various types ofWordNet features along with several com-binations of these features help to improvethe performance of the system.
Error analy-sis suggests that the performance can be im-proved by applying suitable strategies todifferentiate each paired nominal in an al-ready identified relation.
Evaluation resultgives an overall macro-averaged F1 score of52.16%.1 IntroductionSemantic Relations describe the relations betweenconcepts or meanings that are crucial but hard toidentify.
The present shared task aims to developthe systems for automatically recognizing semanticrelations between pairs of nominals.
Nine relationssuch as Cause-Effect, Instrument-Agency, Product-Producer, Content-Container, Entity-Origin, En-tity-Destination, Component-Whole, Member-Collection and Message-Topic are given for Se-mEval-2010 Task #8 (Hendrix et al, 2010).
Therelation that does not belong to any of the nine re-lations is tagged as Other.
The first five relationsalso featured in the previous SemEval-2007 Task#4.The present paper describes the approach ofidentifying semantic relations between pair ofnominals.
The baseline system is developed basedon the verbs and prepositions present in the senten-tial segment between the two nominals.
SomeWordNet (Miller, 1990) features are also used inthe baseline for extracting the relation specific at-tributes (e.g.
Content type hypernym feature usedfor extracting the relation of Content-Container).The performance of the baseline system is limiteddue to the consideration of only the verb andpreposition words in between the two nominalsalong with a small set of WordNet features.
Hence,the Conditional Random Field (CRF) (McCallumet al, 2001) based framework is considered to ac-complish the present task.
The incorporation ofdifferent lexical features (e.g.
WordNet hyponyms,Common-parents, distance), Named Entities (NE)and syntactic features (direct or transitive depend-ency relations of parsing) has noticeably improvedthe performance of the system.
It is observed thatnominalization feature plays an effective role foridentifying as well as distinguishing the relations.The test set containing 2717 sentences is evaluatedagainst four different training sets.
Some of therelations, e.g.
Cause-Effect, Member-Collectionperform well in comparison to other relations in allthe four test results.
Reviewing of the confusionmatrices suggests that the system performance canbe improved by reducing the errors that occur indistinguishing the two individual nominals in eachrelation.The rest of the paper is organized as follows.The pre-processing of resources and the baselinesystem are described in Section 2 and Section 3respectively.
Development of CRF-based model isdiscussed in Section 4.
Experimental results along206with error analysis are specified in Section 5.
Fi-nally Section 6 concludes the paper.2 Resource Pre-ProcessingThe annotated training corpus containing 8000 sen-tences was made available by the respective taskorganizers.
The objective is to evaluate the effec-tiveness of the system in terms of identifying se-mantic relations between pair of nominals.
Therule-based baseline system is evaluated against thewhole training corpus.
But, for in-house experi-ments regarding CRF based framework, the devel-opment data is prepared by randomly selecting 500sentences from the 8000 training sentences.
Rest7500 sentences are used for training of the CRF-model.
The format of one example entry in trainingfile is as follows.
"The system as described above has its greatestapplication in an arrayed <e1>configuration</e1>of antenna <e2>elements</e2>.
"Component-Whole (e2, e1)Comment: Not a collection: there is structurehere, organisation.Each of the training sentences is annotated bythe paired nominals tagged as <e1> and <e2>.The relation of the paired nominals and a commentportion describing the detail of the input type fol-lows the input sentence.The sentences are filtered and passed throughStanford Dependency Parser (Marneffe et al,2006) to identify direct as well as transitive de-pendencies between the nominals.
The direct de-pendency is identified based on the simultaneouspresence of both nominals, <e1> as well as <e2>in the same dependency relation whereas the tran-sitive dependencies are verified if <e1> and <e2>are connected via one or more intermediate de-pendency relations.Each of the sentences is passed through a Stan-ford Named Entity Recognizer (NER)1 for identi-fying the named entities.
The named entities arethe useful hints to separately identify the relationslike Entity-Origin and Entity-Destination fromother relations as the Origin and Destination enti-ties are tagged by the NER frequently than otherentities.Different seed lists are prepared for differenttypes of verbs.
For example, the lists for causal1  http://nlp.stanford.edu/software/CRF-NER.shtmland motion verbs are developed by processing theXML files of English VerbNet (Kipper-Schuler,2005).
The list of the causal and motion verbs areprepared by collecting the member verbs if theircorresponding class contain the semantic type?CAUSE?
or ?MOTION?.
The other verb lists areprepared manually by reviewing the frequency ofverbs in the training corpus.
The WordNet stem-mer is used to identify the root forms of the verbs.3 Baseline ModelThe baseline model is developed based on thesimilarity clues present in the phrasal pattern con-taining verbs and prepositions.
Different rules areidentified separately for the nine different rela-tions.
A few WordNet features such as hypernym,meronym, distance and Common-Parents areadded into the rule-based baseline model.
Some ofthe relation specific rules are mentioned below.For example, if any of the nominals containtheir meronym property as ?whole?
and if the hy-pernym tree for one of the nominals contains theword ?whole?, the relation is identified as a Com-ponent-Whole relation.
But, the ordering of thenominals <e1> and <e2> is done based on thecombination of ?has?, ?with?
and ?of?
with otherword level components.The relations Cause-Effect, Entity-Destinationare identified based on the causal verbs (cause,lead etc.)
and motion verbs (go, run etc.)
respec-tively.
One of the main criteria for extracting theserelations is to verify the presence of causal andmotion verbs in between the text segment of <e1>and <e2>.
Different types of specific relaters (as,because etc.)
are identified from the text segmentas well.
It is observed that such specific causal re-laters help in distinguishing other relations fromCause-Effect.If one of the nominals is described as instrumenttype in its hypernym tree, the corresponding rela-tion is identified as Instrument-Agency but the baselevel filtering criterion is applied if both the nomi-nals belong to instrument type.
On the other hand,if any of the nominals belong to the hypernym treeas content or container or hold type, it returns therelation Content-Container as a probable answer.Similarly, if both of them belong to the same type,the condition is fixed as false criterion for that par-ticular category.
The nominals identified as thepart of collective nouns and associated with207phrases like "of", "in", "from" between <e1> and<e2> contain the relation of Member-Collection.The relations e.g.
Message-Topic uses seed list ofverbs that satisfy the communication type in thehypernym tree and Product-Producer relation con-cerns the hypernym feature as Product type.But, the identification of the proper ordering ofthe entities in the relation, i.e., whether the relationis valid between <e1, e2> or <e2, e1> is done byconsidering the passive sense of the sentence withthe help of the keyword ?by?
as well as by somepassive dependency relations.The evaluation of the rule-based baseline sys-tem on the 8000 training data gives an average F1-score of 22.45%.
The error analysis has shown thatuse of lexical features only is not sufficient to ana-lyze the semantic relation between two nominalsand the performance can be improved by adoptingstrategies for differentiating the nominals of a par-ticular pair.4 CRF-based ModelTo improve the baseline system performance,CRF-based machine learning framework(McCallum et al, 2001) is considered for classify-ing the semantic relations that exist among the or-dered pair of nominals.
Identification of appropri-ate features plays a crucial role in any machine-learning framework.
The following features areidentified heuristically by manually reviewing thecorpus and based on the frequency of differentverbs in different relations.?
11 WordNet features (Synset, Synonym,Gloss, Hyponym, Nominalization, Holo-nym, Common-parents, WordNet distance,Sense ID, Sense count, Meronym)?
Named Entities (NE)?
Direct Dependency?
Transitive Dependency?
9 separate verb list containing relation spe-cific verbs, each for 9 different semanticrelationsDifferent singleton features and their combinationsare generated from the training corpus.
Instead ofconsidering the whole sentence as an input to theCRF-based system, only the pairs of nominals arepassed for classification.
The previous and nexttoken of the current token with respect to each ofthe relations are added in the template to identifytheir co-occurrence nature that in turn help in theclassification process.
Synsets containing synony-mous verbs of the same and different senses areconsidered as individual features.4.1 Feature AnalysisThe importance of different features varies accord-ing to the genre of the relations.
For example, theCommon-parents WordNet feature plays an effec-tive role in identifying the Content-Container andProduct-Producer relations.
If the nominals in apair share a common Sense ID and Sense Countthen this is considered as a feature.
The combina-tion of multiple features in comparison with a sin-gle feature generally shows a reasonable perform-ance enhancement of the present classification sys-tem.
Evaluation on the development data for thevarious feature combinations has shown that thenominalization feature effectively performs for allthe relations.
WordNet distance feature is used forcapturing the relations like Content-Container andComponent-Whole.
The direct and transitive de-pendency syntactic features contribute in identify-ing the relation as well as identify the ordering ofthe entities <e1> and <e2> in the relation.The Named-Entity (NE) relation plays an impor-tant role in distinguishing the relations, e.g., Entity-Origin and Entity-Destination from other relations.The person tagged NEs have been excluded fromthe present task as such NEs are not present in theEntity-Origin and Entity-Destination relations.
Ithas been observed that the relation specific verbssupply useful clues to the training phrase for dif-ferentiating relations among nominals.The system is trained on 7500 sentences and theevaluation is carried out on 500 development sen-tences achieving an F1-Score of 57.56% F1-Score.The tuning on the development set has been carriedout based on the performance produced by theindividual features that effectively containsWordNet relations.
In addition to that, thecombination of dependency features with verbfeature plays an contributory role on the systemevaluation results.208Table 1: Precision, Recall and F1-scores (in %) of semantic relations in (9+1) way directionality-based evaluation5 Experimental ResultsThe active feature list is prepared after achievingthe best possible F1-score of 61.82% on the devel-opment set of 500 sentences.
The final training ofthe CRF-based model is carried out on four differ-ent sets containing 1000, 2000, 4000 and 8000 sen-tences.
These four training sets are prepared byextracting sentences from the beginning of thetraining corpus and the final evaluation is carriedout on 2717 test sentences as provided by the or-ganizers.
The results on the four test sets termed asTD1, TD2, TD3 and TD4 are shown in Table 1.The error analysis is done based on the informationpresent in the confusion matrices.
The fewer occur-rence of Entity-Destination (e2, e1) instance in thetraining corpus plays the negative role in identify-ing the relation.
Mainly, the strategy used for as-signing the order among the entities, i.e., either<e1, e2> or <e2, e1> in the already identified re-lations is the main cause of errors of the system.The Entity-Origin, Product-Producer and Mes-sage-Topic relations suffer from overlapping prob-lem with other relations.
Each of the tested nomi-nal pairs is tagged with more than one relation.But, selecting the first output tag produced by CRFis considered as the final relational tag for each ofthe nominal pairs.
Hence, a distinguishing strategyneeds to be adopted for fine-grained selection.6 Conclusion and Future TaskIn our approach to automatic classification of se-mantic relations between nominals, the systemachieves its best performance using the lexical fea-ture such as nominalization of WordNet and syn-tactic information such as dependency relations.These facts lead us to conclude that semantic fea-tures from WordNet, in general, play a key role inthe classification task.
The present system aims forassigning class labels to discrete word level entitiesbut the context feature is not taken into considera-tion.
The future task is to evaluate the performanceof the system by capturing the context present be-tween the pair of nominals.ReferencesAndrew McCallum, Fernando Pereira and JohnLafferty.
2001.
Conditional Random Fields: Prob-abilistic Models for Segmenting and labeling Se-quence Data.
ICML-01, 282 ?
289.George A. Miller.
1990.
WordNet: An on-line lexicaldatabase.
International Journal of Lexicography,3(4): 235?312.Karin Kipper-Schuler.
2005.
VerbNet.
A broad-coverage, comprehensive verb lexicon.
Ph.D. thesis,University of Pennsylvania, Philadelphia, PA.Marie-Catherine de Marneffe, Bill MacCartney, andChristopher D. Manning.
2006.
Generating TypedDependency Parses from Phrase Structure Parses.
(LREC 2006).Iris Hendrickx, Su Nam Kim, Zornitsa Kozareva,Preslav Nakov, Diarmuid ?O S?eaghdha, SebastianPadok , Marco Pennacchiotti, Lorenza Romano, StanSzpakowicz.
2010.
SemEval-2010 Task 8: Multi-Way Classification of Semantic Relations BetweenPairs of Nominals.
5th SIGLEX Workshop.TD1 TD2 TD3 TD4 RelationsPrec.
Recall F1 Prec.
Recall F1 Prec.
Recall F1 Prec.
Recall F1Cause-Effect 76.33 65.85 70.70 78.55 65.85 71.64 79.86 68.90 73.98 79.26 72.26 75.60Component-Whole 49.25 31.41 38.36 48.76 37.82 42.60 50.77 42.31 46.15 58.40 49.04 53.31Content-Container 31.35 30.21 30.77 37.93 34.38 36.07 40.65 32.81 36.31 51.15 34.90 41.49Entity-Destination 37.58 62.67 46.98 43.43 63.36 51.53 43.09 63.01 51.1847.07 60.62 52.99Entity-Origin 62.50 46.51 53.33 61.95 49.22 54.86 60.18 52.71 56.20 64.02 53.10 58.05Instrument-Agency 19.46 23.08 21.11 21.18 27.56 23.96 26.43 23.72 25.00 32.48 24.36 27.84Member-Collection 50.97 67.81 58.20 54.82 70.82 61.80 59.93 72.53 65.63 66.80 71.67 69.15Message-Topic 41.70 41.38 41.54 50.23 42.15 45.83 52.81 46.74 49.59 57.78 49.81 53.50Product-Producer 52.94 7.79 13.58 48.94 9.96 16.55 59.09 16.88 26.26 53.17 29.00 37.54Other 21.10 27.09 23.72 24.48 33.70 28.36 26.28 37.44 30.88 26.64 42.07 32.62Average F1 score 42.62 44.98 47.81 52.16209
