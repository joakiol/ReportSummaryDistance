Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 13?18,Baltimore, Maryland, USA, June 23-25 2014.c?2014 Association for Computational LinguisticsProbabilistic Labeling for Efficient Referential Grounding based onCollaborative DiscourseChangsong Liu, Lanbo She, Rui Fang, Joyce Y. ChaiDepartment of Computer Science and EngineeringMichigan State UniversityEast Lansing, MI 48824{cliu, shelanbo, fangrui, jchai}@cse.msu.eduAbstractWhen humans and artificial agents (e.g.robots) have mismatched perceptions ofthe shared environment, referential com-munication between them becomes diffi-cult.
To mediate perceptual differences,this paper presents a new approach us-ing probabilistic labeling for referentialgrounding.
This approach aims to inte-grate different types of evidence from thecollaborative referential discourse into aunified scheme.
Its probabilistic labelingprocedure can generate multiple ground-ing hypotheses to facilitate follow-up dia-logue.
Our empirical results have shownthe probabilistic labeling approach sig-nificantly outperforms a previous graph-matching approach for referential ground-ing.1 IntroductionIn situated human-robot dialogue, humans androbots have mismatched capabilities of perceivingthe shared environment.
Thus referential commu-nication between them becomes extremely chal-lenging.
To address this problem, our previouswork has conducted a simulation-based study tocollect a set of human-human conversation datathat explain how partners with mismatched per-ceptions strive to succeed in referential commu-nication (Liu et al, 2012; Liu et al, 2013).
Ourdata have shown that, when conversation partnershave mismatched perceptions, they tend to makeextra collaborative effort in referential commu-nication.
For example, the speaker often refersto the intended object iteratively: first issuing aninitial installment, and then refashioning till thehearer identifies the referent correctly.
The hearer,on the other hand, often provides useful feedbackbased on which further refashioning can be made.This data has demonstrated the importance of in-corporating collaborative discourse for referentialgrounding.Based on this data, as a first step we developeda graph-matching approach for referential ground-ing (Liu et al, 2012; Liu et al, 2013).
This ap-proach uses Attributed Relational Graph to cap-ture collaborative discourse and employs a state-space search algorithm to find proper ground-ing results.
Although it has made meaning-ful progress in addressing collaborative referen-tial grounding under mismatched perceptions, thestate-space search based approach has two ma-jor limitations.
First, it is neither flexible to ob-tain multiple grounding hypotheses, nor flexibleto incorporate different hypotheses incrementallyfor follow-up grounding.
Second, the search al-gorithm tends to have a high time complexity foroptimal solutions.
Thus, the previous approachis not ideal for collaborative and incremental di-alogue systems that interact with human users inreal time.To address these limitations, this paper de-scribes a new approach to referential groundingbased on probabilistic labeling.
This approachaims to integrate different types of evidence fromthe collaborative referential discourse into a uni-fied probabilistic scheme.
It is formulated un-der the Bayesian reasoning framework to easilysupport generation and incorporation of multi-ple grounding hypotheses for follow-up processes.Our empirical results have shown that the prob-abilistic labeling approach significantly outper-forms the state-space search approach in bothgrounding accuracy and efficiency.
This new ap-proach provides a good basis for processing col-laborative discourse and enabling collaborative di-alogue system in situated referential communica-tion.132 Related WorkPrevious works on situated referential groundinghave mainly focused on computational models thatconnect linguistic referring expressions to the per-ceived environment (Gorniak and Roy, 2004; Gor-niak and Roy, 2007; Siebert and Schlangen, 2008;Matuszek et al, 2012; Jayant and Thomas, 2013).These works have provided valuable insights onhow to manually and/or automatically build keycomponents (e.g., semantic parsing, groundingfunctions between visual features and words, map-ping procedures) for a situated referential ground-ing system.
However, most of these works onlydealt with the interpretation of single referring ex-pressions, rather than interrelated expressions incollaborative dialogue.Some earlier work (Edmonds, 1994; Heemanand Hirst, 1995) proposed a symbolic reasoning(i.e.
planning) based approach to incorporate col-laborative dialogue.
However, in situated settingspure symbolic approaches will not be sufficientand new approaches that are robust to uncertain-ties need to be pursued.
DeVault and Stone (2009)proposed a hybrid approach which combined sym-bolic reasoning and machine learning for inter-preting referential grounding dialogue.
But their?environment?
was a simplistic block world andthe issue of mismatched perceptions was not ad-dressed.3 DataPreviously, we have collected a set of human-human dialogues on an object-naming task (Liuet al, 2012).
To simulate mismatched perceptionsbetween a human and an artificial agent, two par-ticipants were shown different versions of an im-age: the director was shown the original imagecontaining some randomly placed objects (e.g.,fruits), and the matcher was shown an impov-erished version of the image generated by com-puter vision.
They were instructed to communi-cate with each other to figure out the identities ofsome ?named?
objects (only known to the direc-tor), such that the matcher could also know whichobject has what name.Here is an example excerpt from this dataset:D1: there is basically a cluster of four objects in the upperleft, do you see that (1)M: yes (2)D: ok, so the one in the corner is a blue cup (3)1D stands for the director; M stands for the matcher.M: I see there is a square, but fine, it is blue (4)D: alright, I will just go with that, so and then right underthat is a yellow pepper (5)M: ok, I see apple but orangish yellow (6)D: ok, so that yellow pepper is named Brittany (7)M: uh, the bottom left of those four?
Because I do see ayellow pepper in the upper right (8)D: the upper right of the four of them?
(9)M: yes (10)D: ok, so that is basically the one to the right of the bluecup (11)M: yeah (12)D: that is actually an apple (13)As we can see from this example, both the direc-tor and the matcher make extra efforts to overcomethe mismatched perceptions through collaborativedialogue.
Our ultimate goal is to develop com-putational approaches that can ground interrelatedreferring expressions to the physical world, andenable collaborative actions of the dialogue agent(similar to the active role that the matcher playedin the human-human dialogue).
For the time be-ing, we use this data to evaluate our computa-tional approach for referential grounding, namely,replacing the matcher by our automatic system toground the director?s referring expressions.4 Probabilistic Labeling for ReferenceGrounding4.1 System OverviewOur system first processes the data using auto-matic semantic parsing and coreference resolu-tion.
For semantic parsing, we use a rule-basedCCG parser (Bozsahin et al, 2005) to parse eachutterance into a formal semantic representation.For example, the utterance ?a pear is to the rightof the apple?
is parsed as[a1, a2] , [Pear(a1), Apple(a2), RightOf(a1, a2)]which consists of a list of discourse entities (e.g.,a1and a2) and a list of first-order-logic predicatesthat specify the unary attributes of these entitiesand the binary relations between them.We then perform pairwise coreference resolu-tion on the discourse entities to find out the dis-course relations between entities from different ut-terances.
Formally, let aibe a discourse entity ex-tracted from the current utterance, and aja dis-course entity from a previous utterance.
We train amaximum entropy classifier2(Manning and Klein,2The features we use for the classification include the dis-tance between aiand aj, the determiners associated withthem, the associated pronouns, the syntactic roles, the ex-tracted unary properties, etc.142003) to predict whether aiand ajshould refer tothe same object (i.e.
positive) or to different ob-jects (i.e.
negative).Based on the semantic parsing and pairwisecoreference resolution results, our system fur-ther builds a graph representation to capture thecollaborative discourse and formulate referentialgrounding as a probabilistic labeling problem, asdescribed next.4.2 Graph RepresentationWe use an Attributed Relational Graph (Tsai andFu, 1979) to represent the referential groundingdiscourse (which we call the ?dialogue graph?).
Itis constructed based on the semantic parsing andcoreference resolution results.
The dialogue graphcontains a set A of N nodes:A = {a1, a2, .
.
.
, aN}in which each node airepresents a discourse en-tity from the parsing results.
And for each pairof nodes aiand ajthere can be an edge aiajthatrepresents the physical or discourse relation (i.e.coreference) between the two nodes.Furthermore, each node aican be assigned a setof ?attributes?
:xi={x(1)i, x(2)i, .
.
.
, x(K)i}which are used to specify information about theunary properties of the corresponding discourseentity.
Similarly, each edge aiajcan also be as-signed a set of attributes xijto specify informa-tion about the binary relations between two dis-course entities.
The node attributes are from thesemantic parsing results, i.e., the unary proper-ties associated to a discourse entity.
The edge at-tributes can be either from parsing results, suchas a spatial relation between two entities (e.g.,RightOf(a1, a2)); Or from pairwise coreferenceresolution results, i.e., two entities are coreferen-tial (coref = +) or not (coref = ?
).Besides the dialogue graph that represents thelinguistic discourse, we build another graph to rep-resent the perceived environment.
This graph iscalled the ?vision graph?
(since this graph is builtbased on computer vision?s outputs).
It has a set ?of M nodes:?
= {?1, ?2, .
.
.
, ?M}in which each node ?
?represents a physical ob-ject in the scene.
Similar to the dialogue graph,the vision graph also has edges (e.g., ????
), nodeattributes (e.g.,?x?)
and edge attributes (e.g.,?x??
).Note that the attributes in the vision graph mostlyhave numeric values extracted by computer visionalgorithms, whereas the attributes in the dialoguegraph have symbolic values extracted from the lin-guistic discourse.
A set of ?symbol groundingfunctions?
are used to bridge between the hetero-geneous attributes (described later).Given these two graph representations, referen-tial grounding then can be formulated as a ?nodelabeling?
process, that is to assign a label ?itoeach node ai.
The value of ?ican be any of theM node labels from the set ?.4.3 Probabilistic Labeling AlgorithmThe probabilistic labeling algorithm (Christmas etal., 1995) is formulated in the Bayesian frame-work.
It provides a unified evidence-combiningscheme to integrate unary attributes, binary rela-tions and prior knowledge for updating the label-ing probabilities (i.e.
P (?i= ??)).
The algo-rithm finds proper labelings in an iterative manner:it first initiates the labeling probabilities by consid-ering only the unary attributes of each node, andthen updates the labeling probability of each nodebased on the labeling of its neighbors and the rela-tions with them.Initialization:Compute the initial labeling probabilities:P(0)(?i= ??)
=P (ai| ?i= ??
)?P (?i= ??)????
?P (ai| ?i= ??
)?P (?i= ??
)in which?P (?i= ??)
is the prior probability oflabeling aiwith ??.
The prior probability can beused to encode any prior knowledge about possi-ble labelings.
Especially in incremental process-ing of the dialogue, the prior can encode previ-ous grounding hypotheses, and other informationfrom the collaborative dialogue such as confirma-tion, rejection, or replacement.P (ai| ?i= ??)
is called the ?compatibility co-efficient?
between aiand ?
?, which is computedbased on the attributes of aiand ??
:P (ai| ?i= ??)
= P (xi| ?i= ??)?
?kP(x(k)i| ?i= ??
)and we further define15P(x(k)i| ?i= ??
)= p(x(k)i| x?(k)?)=p(x?(k)?|x(k)i)p(x(k)i)?x(k)j?L(k)p(x?
(k)?|x(k)j)p(x(k)j)where L(k)is the ?lexicon?
for the k-th attribute ofa dialogue graph node, e.g., for the color attribute:L(k)= {red, green, blue, .
.
.
}and p(x?
(k)?| x(k)i)is what we call a ?symbolgrounding function?, i.e., the probability of ob-serving x?
(k)?given the word x(k)i.
It judges thecompatibilities between the symbolic attribute val-ues from the dialogue graph and the numeric at-tribute values from the vision graph.
These sym-bol grounding functions can be either manuallydefined or automatically learned.
In our currentwork, we use a set of manually defined ground-ing functions motivated by previous work (Gor-niak and Roy, 2004).Iteration:Once the initial probabilities are calculated, thelabeling procedure iterates till all the labelingprobabilities have converged or the number of it-erations has reached a specified limit.
At each it-eration and for each possible labeling, it computesa ?support function?
as:Q(n)(?i= ??)
=?j?Ni????
?P(n)(?j= ??
)P (aiaj| ?i= ?
?, ?j= ??
)and updates the probability of each possible label-ing as:P(n+1)(?i= ??)
=P(n)(?i=??)Q(n)(?i=??)?????P(n)(?i=??)Q(n)(?i=??
)The support function Q(n)(?i= ??)
expresseshow the labeling ?i= ?
?at the n-th itera-tion is supported by the labeling of ai?s neigh-bors3, taking into consideration the binary rela-tions that exist between aiand them.
Similar tothe node compatibility coefficient, the edge com-patibility coefficient between aiajand ???
?,3The set of indices Niis defined as:Ni= {1, 2, .
.
.
, i?
1, i+ 1, .
.
.
, N}Top-1 Top-2 Top-3Random7.7% 15.4% 23.1%GuessaS.S.S.
19.1% 19.7% 21.3%P.L.
24.9% 36.1% 45.0%Gainb5.8% 16.4% 23.7%(p < 0.01) (p < 0.001) (p < 0.001)P.L.
using66.4% 74.8% 81.9%annotatedcoreferenceaEach image contains an average of 13 objects.bp-value is based on the Wilcoxon signed-ranktest (Wilcoxon et al, 1970) on the 62 dialogues.Table 1: Comparison of the reference groundingperformances of a random guess baseline, Prob-abilistic Labeling (P.L.)
and State-Space Search(S.S.S.
), and P.L.
using manually annotated coref-erence.namely the P (aiaj| ?i= ?
?, ?j= ??)
for com-puting Q(n)(?i= ??
), is also based on the at-tributes of the two edges and their correspondingsymbol grounding functions.
So we also man-ually defined a set of grounding functions foredge attributes such as the spatial relation (e.g.,RightOf , Above).
If an edge is used to encodethe discourse relation between two entities (i.e.,the pairwise coreference results), the compatibilitycoefficient can be defined as (suppose edge aiajencodes a positive coreference relation betweenentities aiand aj):P (aiaj= + | ?i= ?
?, ?j= ??)=P(?i=??,?j=?
?|aiaj=+)P (aiaj=+)P(?i=??,?j=??
)which can be calculated based on the results fromthe coreference classifier (Section 4.1).5 Evaluation and DiscussionOur dataset has 62 dialogues, each of which con-tains an average of 25 valid utterances from thedirector.
We first applied the semantic parser andcoreference classifier as described in Section 4.1to process each dialogue, and then built a graphrepresentation based on the automatic processingresults at the end of the dialogue.
On average, a di-alogue graph consists of 33 discourse entities fromthe director?s utterances that need to be grounded.We then applied both the probabilistic label-ing algorithm and the state-space search algorithmto ground each of the director?s discourse entitiesonto an object perceived from the image.
The av-eraged grounding accuracies of the two algorithms16are shown in the middle part of Table 1.
The firstcolumn of Table 1 shows the grounding accura-cies of the algorithm?s top-1 grounding hypothesis(i.e., ?i= argmax?
?P (?i= ??)
for each i).
Thesecond and third column then show the ?accura-cies?
of the top-2 and top-3 hypotheses4, respec-tively.As shown in Table 1, probabilistic labeling(i.e.
P.L.)
significantly outperforms state-spacesearch (S.S.S.
), especially with regard to produc-ing meaningful multiple grounding hypotheses.The state-space search algorithm actually only re-sults in multiple hypotheses for the overall match-ing, and it fails to produce multiple hypothesesfor many individual discourse entities.
Multiplegrounding hypotheses can be very useful to gen-erate responses such as clarification questions ornonverbal feedback (e.g.
pointing, gazing).
Forexample, if there are two competing hypotheses,the dialogue manager can utilize them to gener-ate a response like ?I see two objects there, areyou talking about this one (pointing to) or that one(pointing to the other)??.
Such proactive feedbackis often an effective way in referential communi-cation (Clark and Wilkes-Gibbs, 1986; Liu et al,2013).The probabilistic labeling algorithm not onlyproduces better grounding results, it also runsmuch faster (with a running-time complexity ofO(MN2),5comparing to O(N4)of the state-space search algorithm6).
Figure 1 shows the av-eraged running time of the state-space search al-gorithm on a Intel Core i7 1.60GHz CPU with16G RAM computer (the running time of the prob-abilistic labeling algorithm is not shown in Fig-ure 1 since it always takes less than 1 second torun).
As we can see, when the size of the dialoguegraph becomes greater than 15, state-space searchtakes more than 1 minute to run.
The efficiency ofthe probabilistic labeling algorithm thus makes itmore appealing for real-time interaction applica-tions.Although probabilistic labeling significantlyoutperforms the state-space search, the groundingperformance is still rather poor (less than 50%)4The accuracy of the top-2/top-3 grounding hypotheses ismeasured by whether the ground-truth reference is includedin the top-2/top-3 hypotheses.5M is the number of nodes in the vision graph and N isthe number of nodes in the dialogue graph.6Beam search algorithm is applied to reduce the exponen-tial O(MN)to O(N4).Figure 1: Average running time of the state-spacesearch algorithm with respect to the number ofnodes to be grounded in a dialogue graph.even for the top-3 hypotheses.
With no surprise,the coreference resolution performance plays animportant role in the final grounding performance(see the grounding performance of using manuallyannotated coreference in the bottom part of Ta-ble 1).
Due to the simplicity of our current coref-erence classifier and the flexibility of the human-human dialogue in the data, the pairwise coref-erence resolution only achieves 0.74 in precisionand 0.43 in recall.
The low recall of coreferenceresolution makes it difficult to link interrelated re-ferring expressions and resolve them jointly.
So itis important to develop more sophisticated coref-erence resolution and dialogue management com-ponents to reliably track the discourse relationsand other dynamics in the dialogue to facilitate ref-erential grounding.6 ConclusionIn this paper, we have presented a probabilistic la-beling based approach for referential grounding insituated dialogue.
This approach provides a uni-fied scheme for incorporating different sources ofinformation.
Its probabilistic scheme allows eachinformation source to present multiple hypothesesto better handle uncertainties.
Based on the in-tegrated information, the labeling procedure thenefficiently generates probabilistic grounding hy-potheses, which can serve as important guidancefor the dialogue manager?s decision making.
Infuture work, we will utilize probabilistic labelingto incorporate information from verbal and non-verbal communication incrementally as the dia-logue unfolds, and to enable collaborative dia-logue agents in the physical world.AcknowledgmentsThis work was supported by N00014-11-1-0410from the Office of Naval Research and IIS-1208390 from the National Science Foundation.17ReferencesCem Bozsahin, Geert-Jan M Kruijff, and MichaelWhite.
2005.
Specifying grammars for openccg: Arough guide.
Included in the OpenCCG distribution.William J. Christmas, Josef Kittler, and Maria Petrou.1995.
Structural matching in computer visionusing probabilistic relaxation.
Pattern Analysisand Machine Intelligence, IEEE Transactions on,17(8):749?764.Herbert H Clark and Deanna Wilkes-Gibbs.
1986.Referring as a collaborative process.
Cognition,22(1):1?39.David DeVault and Matthew Stone.
2009.
Learning tointerpret utterances using dialogue history.
In Pro-ceedings of the 12th Conference of the EuropeanChapter of the Association for Computational Lin-guistics, pages 184?192.
Association for Computa-tional Linguistics.Philip G Edmonds.
1994.
Collaboration on referenceto objects that are not mutually known.
In Pro-ceedings of the 15th conference on Computationallinguistics-Volume 2, pages 1118?1122.
Associationfor Computational Linguistics.Peter Gorniak and Deb Roy.
2004.
Grounded seman-tic composition for visual scenes.
J. Artif.
Intell.Res.
(JAIR), 21:429?470.Peter Gorniak and Deb Roy.
2007.
Situated lan-guage understanding as filtering perceived affor-dances.
Cognitive Science, 31(2):197?231.Peter A Heeman and Graeme Hirst.
1995.
Collabo-rating on referring expressions.
Computational Lin-guistics, 21(3):351?382.Krishnamurthy Jayant and Kollar Thomas.
2013.Jointly learning to parse and perceive: Connectingnatural language to the physical world.
Transac-tions of the Association of Computational Linguis-tics, 1:193?206.Changsong Liu, Rui Fang, and Joyce Chai.
2012.
To-wards mediating shared perceptual basis in situateddialogue.
In Proceedings of the 13th Annual Meet-ing of the Special Interest Group on Discourse andDialogue, pages 140?149, Seoul, South Korea, July.Association for Computational Linguistics.Changsong Liu, Rui Fang, Lanbo She, and Joyce Chai.2013.
Modeling collaborative referring for situatedreferential grounding.
In Proceedings of the SIG-DIAL 2013 Conference, pages 78?86, Metz, France,August.
Association for Computational Linguistics.Christopher Manning and Dan Klein.
2003.
Opti-mization, maxent models, and conditional estima-tion without magic.
In Proceedings of the 2003Conference of the North American Chapter of theAssociation for Computational Linguistics on Hu-man Language Technology: Tutorials - Volume 5,NAACL-Tutorials ?03, pages 8?8, Stroudsburg, PA,USA.
Association for Computational Linguistics.Cynthia Matuszek, Nicholas FitzGerald, Luke Zettle-moyer, Liefeng Bo, and Dieter Fox.
2012.
Ajoint model of language and perception for groundedattribute learning.
In John Langford and JoellePineau, editors, Proceedings of the 29th Interna-tional Conference on Machine Learning (ICML-12),ICML ?12, pages 1671?1678, New York, NY, USA,July.
Omnipress.Alexander Siebert and David Schlangen.
2008.
Asimple method for resolution of definite referencein a shared visual context.
In Proceedings of the9th SIGdial Workshop on Discourse and Dialogue,pages 84?87.
Association for Computational Lin-guistics.Wen-Hsiang Tsai and King-Sun Fu.
1979.
Error-correcting isomorphisms of attributed relationalgraphs for pattern analysis.
Systems, Man and Cy-bernetics, IEEE Transactions on, 9(12):757?768.Frank Wilcoxon, SK Katti, and Roberta A Wilcox.1970.
Critical values and probability levels for thewilcoxon rank sum test and the wilcoxon signedrank test.
Selected tables in mathematical statistics,1:171?259.18
