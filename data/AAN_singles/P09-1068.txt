Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 602?610,Suntec, Singapore, 2-7 August 2009. c?2009 ACL and AFNLPUnsupervised Learning of Narrative Schemas and their ParticipantsNathanael Chambers and Dan JurafskyStanford University, Stanford, CA 94305{natec,jurafsky}@stanford.eduAbstractWe describe an unsupervised system for learn-ing narrative schemas, coherent sequences or setsof events (arrested(POLICE,SUSPECT), convicted(JUDGE, SUSPECT)) whose arguments are filledwith participant semantic roles defined over words(JUDGE = {judge, jury, court}, POLICE = {police,agent, authorities}).
Unlike most previous work inevent structure or semantic role learning, our sys-tem does not use supervised techniques, hand-builtknowledge, or predefined classes of events or roles.Our unsupervised learning algorithm uses corefer-ring arguments in chains of verbs to learn both richnarrative event structure and argument roles.
Byjointly addressing both tasks, we improve on pre-vious results in narrative/frame learning and inducerich frame-specific semantic roles.1 IntroductionThis paper describes a new approach to event se-mantics that jointly learns event relations and theirparticipants from unlabeled corpora.The early years of natural language processing(NLP) took a ?top-down?
approach to languageunderstanding, using representations like scripts(Schank and Abelson, 1977) (structured represen-tations of events, their causal relationships, andtheir participants) and frames to drive interpreta-tion of syntax and word use.
Knowledge structuressuch as these provided the interpreter rich infor-mation about many aspects of meaning.The problem with these rich knowledge struc-tures is that the need for hand construction, speci-ficity, and domain dependence prevents robust andflexible language understanding.
Instead, mod-ern work on understanding has focused on shal-lower representations like semantic roles, whichexpress at least one aspect of the semantics ofevents and have proved amenable to supervisedlearning from corpora like PropBank (Palmer etal., 2005) and Framenet (Baker et al, 1998).
Un-fortunately, creating these supervised corpora is anexpensive and difficult multi-year effort, requiringcomplex decisions about the exact set of roles tobe learned.
Even unsupervised attempts to learnsemantic roles have required a pre-defined set ofroles (Grenager and Manning, 2006) and often ahand-labeled seed corpus (Swier and Stevenson,2004; He and Gildea, 2006).In this paper, we describe our attempts to learnscript-like information about the world, includingboth event structures and the roles of their partic-ipants, but without pre-defined frames, roles, ortagged corpora.Consider the following Narrative Schema, to bedefined more formally later.
The events on the leftfollow a set of participants through a series of con-nected events that constitute a narrative:A search BA arrest BD convict BB plead CD acquit BD sentence BA = PoliceB = SuspectC = PleaD = JuryEvents RolesBeing able to robustly learn sets of relatedevents (left) and frame-specific role informationabout the argument types that fill them (right)could assist a variety of NLP applications, fromquestion answering to machine translation.Our previous work (Chambers and Jurafsky,2008) relied on the intuition that in a coherent text,any two events that are about the same participantsare likely to be part of the same story or narra-tive.
The model learned simple aspects of nar-rative structure (?narrative chains?)
by extractingevents that share a single participant, the protag-onist.
In this paper we extend this work to rep-resent sets of situation-specific events not unlikescripts, caseframes (Bean and Riloff, 2004), andFrameNet frames (Baker et al, 1998).
This papershows that verbs in distinct narrative chains can bemerged into an improved single narrative schema,while the shared arguments across verbs can pro-vide rich information for inducing semantic roles.6022 BackgroundThis paper addresses two areas of work in eventsemantics, narrative event chains and semanticrole labeling.
We begin by highlighting areas inboth that can mutually inform each other througha narrative schema model.2.1 Narrative Event ChainsNarrative Event Chains are partially ordered setsof events that all involve the same shared par-ticipant, the protagonist (Chambers and Jurafsky,2008).
A chain contains a set of verbs represent-ing events, and for each verb, the grammatical rolefilled by the shared protagonist.An event is a verb together with its constellationof arguments.
An event slot is a tuple of an eventand a particular argument slot (grammatical rela-tion), represented as a pair ?v, d?
where v is a verband d ?
{subject, object, prep}.
A chain is a tu-ple (L,O) where L is a set of event slots and O isa partial (temporal) ordering.
We will write eventslots in shorthand as (X pleads) or (pleads X) for?pleads, subject?
and ?pleads, object?.
Below isan example chain modeling criminal prosecution.L = (X pleads), (X admits), (convicted X), (sentenced X)O = {(pleads, convicted), (convicted, sentenced), ...}A graphical view is often more intuitive:admitspleadssentencedconvicted(X admits)(X pleads)(convicted X)(sentenced X)In this example, the protagonist of the chainis the person being prosecuted and the other un-specified event slots remain unfilled and uncon-strained.
Chains in the Chambers and Jurafsky(2008) model are ordered; in this paper rather thanaddress the ordering task we focus on event and ar-gument induction, leaving ordering as future work.The Chambers and Jurafsky (2008) modellearns chains completely unsupervised, (albeit af-ter parsing and resolving coreference in the text)by counting pairs of verbs that share corefer-ring arguments within documents and computingthe pointwise mutual information (PMI) betweenthese verb-argument pairs.
The algorithm createschains by clustering event slots using their PMIscores, and we showed this use of co-referring ar-guments improves event relatedness.Our previous work, however, has two majorlimitations.
First, the model did not expressany information about the protagonist, such as itstype or role.
Role information (such as knowingwhether a filler is a location, a person, a particularclass of people, or even an inanimate object) couldcrucially inform learning and inference.
Second,the model only represents one participant (the pro-tagonist).
Representing the other entities involvedin all event slots in the narrative could potentiallyprovide valuable information.
We discuss both ofthese extensions next.2.1.1 The Case for ArgumentsThe Chambers and Jurafsky (2008) narrativechains do not specify what type of argument fillsthe role of protagonist.
Chain learning and clus-tering is based only on the frequency with whichtwo verbs share arguments, ignoring any featuresof the arguments themselves.Take this example of an actual chain from anarticle in our training data.
Given this chain of fiveevents, we want to choose other events most likelyto occur in this scenario.huntuseaccusesuspectsearchflycharge?One of the top scoring event slots is (fly X).
Nar-rative chains incorrectly favor (fly X) because it isobserved during training with all five event slots,although not frequently with any one of them.
Anevent slot like (charge X) is much more plausible,but is unfortunately scored lower by the model.Representing the types of the arguments canhelp solve this problem.
Few types of argumentsare shared between the chain and (fly X).
How-ever, (charge X) shares many arguments with (ac-cuse X), (search X) and (suspect X) (e.g., criminaland suspect).
Even more telling is that these argu-ments are jointly shared (the same or coreferent)across all three events.
Chains represent coherentscenarios, not just a set of independent pairs, so wewant to model argument overlap across all pairs.2.1.2 The Case for Joint ChainsThe second problem with narrative chains is thatthey make judgments only between protagonist ar-guments, one slot per event.
All entities and slots603in the space of events should be jointly consideredwhen making event relatedness decisions.As an illustration, consider the verb arrest.Which verb is more related, convict or capture?A narrative chain might only look at the objectsof these verbs and choose the one with the high-est score, usually choosing convict.
But in thiscase the subjects offer additional information; thesubject of arrest (police) is different from that ofconvict (judge).
A more informed decision preferscapture because both the objects (suspect) andsubjects (police) are identical.
This joint reason-ing is absent from the narrative chain model.2.2 Semantic Role LabelingThe task of semantic role learning and labelingis to identify classes of entities that fill predicateslots; semantic roles seem like they?d be a goodmodel for the kind of argument types we?d liketo learn for narratives.
Most work on semanticrole labeling, however, is supervised, using Prop-bank (Palmer et al, 2005), FrameNet (Baker etal., 1998) or VerbNet (Kipper et al, 2000) asgold standard roles and training data.
More re-cent learning work has applied bootstrapping ap-proaches (Swier and Stevenson, 2004; He andGildea, 2006), but these still rely on a hand la-beled seed corpus as well as a pre-defined set ofroles.
Grenegar and Manning (2006) use the EMalgorithm to learn PropBank roles from unlabeleddata, and unlike bootstrapping, they don?t need alabeled corpus from which to start.
However, theydo require a predefined set of roles (arg0, arg1,etc.)
to define the domain of their probabilisticmodel.Green and Dorr (2005) use WordNet?s graphstructure to cluster its verbs into FrameNet frames,using glosses to name potential slots.
We differ inthat we attempt to learn frame-like narrative struc-ture from untagged newspaper text.
Most sim-ilar to us, Alishahi and Stevenson (2007) learnverb specific semantic profiles of arguments us-ing WordNet classes to define the roles.
We learnsituation-specific classes of roles shared by multi-ple verbs.Thus, two open goals in role learning include(1) unsupervised learning and (2) learning theroles themselves rather than relying on pre-definedrole classes.
As just described, Chambers and Ju-rafsky (2008) offers an unsupervised approach toevent learning (goal 1), but lacks semantic roleknowledge (goal 2).
The following sections de-scribe a model that addresses both goals.3 Narrative SchemasThe next sections introduce typed narrative chainsand chain merging, extensions that allow us tojointly learn argument roles with event structure.3.1 Typed Narrative ChainsThe first step in describing a narrative schema is toextend the definition of a narrative chain to includeargument types.
We now constrain the protagonistto be of a certain type or role.
A Typed NarrativeChain is a partially ordered set of event slots thatshare an argument, but now the shared argumentis a role defined by being a member of a set oftypes R. These types can be lexical units (such asobserved head words), noun clusters, or other se-mantic representations.
We use head words in theexamples below, but we also evaluate with argu-ment clustering by mapping head words to mem-ber clusters created with the CBC clustering algo-rithm (Pantel and Lin, 2002).We define a typed narrative chain as a tuple(L,P,O) with L and O the set of event slotsand partial ordering as before.
Let P be a set ofargument types (head words) representing a singlerole.
An example is given here:L = {(hunt X), (X use), (suspect X), (accuse X), (search X)}P = {person, government, company, criminal, ...}O = {(use, hunt), (suspect, search), (suspect, accuse) ... }3.2 Learning Argument TypesAs mentioned above, narrative chains are learnedby parsing the text, resolving coreference, and ex-tracting chains of events that share participants.
Inour new model, argument types are learned simul-taneously with narrative chains by finding salientwords that represent coreferential arguments.
Werecord counts of arguments that are observed witheach pair of event slots, build the referential setfor each word from its coreference chain, and thenrepresent each observed argument by the most fre-quent head word in its referential set (ignoring pro-nouns and mapping entity mentions with personpronouns to a constant PERSON identifier).As an example, the following contains fourworker mentions:But for a growing proportion of U.S. workers, the troubles re-ally set in when they apply for unemployment benefits.
Manyworkers find their benefits challenged.604L = {X arrest, X charge, X raid, X seize,X confiscate, X detain, X deport }P = {police, agent, authority, government}Figure 1: A typed narrative chain.
The four toparguments are given.
The orderingO is not shown.The four bolded terms are coreferential and(hopefully) identified by coreference.
Our algo-rithm chooses the head word of each phrase andignores the pronouns.
It then chooses the mostfrequent head word as the most salient mention.In this example, the most salient term is workers.If any pair of event slots share arguments from thisset, we count workers.
In this example, the pair (Xfind) and (X apply) shares an argument (they andworkers).
The pair ((X find),(X apply)) is countedonce for narrative chain induction, and ((X find),(X apply), workers) once for argument induction.Figure 1 shows the top occurring words acrossall event slot pairs in a criminal scenario chain.This chain will be part of a larger narrativeschema, described in section 3.4.3.3 Event Slot Similarity with ArgumentsWe now formalize event slot similarity with argu-ments.
Narrative chains as defined in (Chambersand Jurafsky, 2008) score a new event slot ?f, g?against a chain of size n by summing over thescores between all pairs:chainsim(C, ?f, g?)
=nXi=1sim(?ei, di?
, ?f, g?)
(1)where C is a narrative chain, f is a verb withgrammatical argument g, and sim(e, e?)
is thepointwise mutual information pmi(e, e?).
Grow-ing a chain by one adds the highest scoring event.We extend this function to include argumenttypes by defining similarity in the context of a spe-cific argument a:sim(?e, d?
,?e?, d?
?, a) =pmi(?e, d?
,?e?, d??)
+ ?
log freq(?e, d?
,?e?, d?
?, a)(2)where ?
is a constant weighting factor andfreq(b, b?, a) is the corpus count of a filling thearguments of events b and b?.
We then score theentire chain for a particular argument:score(C, a) =n?1Xi=1nXj=i+1sim(?ei, di?
, ?ej , dj?
, a) (3)Using this chain score, we finally extendchainsim to score a new event slot based on theargument that maximizes the entire chain?s score:chainsim?
(C, ?f, g?)
=maxa(score(C, a) +nXi=1sim(?ei, di?
, ?f, g?
, a))(4)The argument is now directly influencing eventslot similarity scores.
We will use this definitionin the next section to build Narrative Schemas.3.4 Narrative Schema: Multiple ChainsWhereas a narrative chain is a set of event slots,a Narrative Schema is a set of typed narrativechains.
A schema thus models all actors in a setof events.
If (push X) is in one chain, (Y push) isin another.
This allows us to model a document?sentire narrative, not just one main actor.3.4.1 The ModelA narrative schema is defined as a 2-tuple N =(E,C) with E a set of events (here defined asverbs) and C a set of typed chains over theevent slots.
We represent an event as a verb vand its grammatical argument positions Dv ?
{subject, object, prep}.
Thus, each event slot?v, d?
for all d ?
Dv belongs to a chain c ?
Cin the schema.
Further, each c must be unique foreach slot of a single verb.
Using the criminal pros-ecution domain as an example, a narrative schemain this domain is built as in figure 2.The three dotted boxes are graphical represen-tations of the typed chains that are combined inthis schema.
The first represents the event slots inwhich the criminal is involved, the second the po-lice, and the third is a court or judge.
Although ourrepresentation uses a set of chains, it is equivalentto represent a schema as a constraint satisfactionproblem between ?e, d?
event slots.
The next sec-tion describes how to learn these schemas.3.4.2 Learning Narrative SchemasPrevious work on narrative chains focused on re-latedness scores between pairs of verb arguments(event slots).
The clustering step which builtchains depended on these pairwise scores.
Narra-tive schemas use a generalization of the entire verbwith all of its arguments.
A joint decision can bemade such that a verb is added to a schema if bothits subject and object are assigned to chains in theschema with high confidence.For instance, it may be the case that (Ypull over) scores well with the ?police?
chain in605police,agentcriminal,suspectguilty,innocentjudge,juryarrestchargeconvictsentencearrestchargeconvictpleadsentencepolice,agentjudge,juryarrestchargeconvictpleadsentencecriminal,suspectFigure 2: Merging typed chains into a single unordered Narrative Schema.figure 3.
However, the object of (pull over A)is not present in any of the other chains.
Policepull over cars, but this schema does not have achain involving cars.
In contrast, (Y search) scoreswell with the ?police?
chain and (search X) scoreswell in the ?defendant?
chain too.
Thus, we wantto favor search instead of pull over because theschema is already modeling both arguments.This intuition leads us to our event relatednessfunction for the entire narrative schema N , notjust one chain.
Instead of asking which event slot?v, d?
is a best fit, we ask if v is best by consideringall slots at once:narsim(N, v) =?d?Dvmax(?, maxc?CNchainsim?
(c, ?v, d?))
(5)whereCN is the set of chains in our narrativeN .
If?v, d?
does not have strong enough similarity withany chain, it creates a new one with base score ?.The ?
parameter balances this decision of addingto an existing chain in N or creating a new one.3.4.3 Building SchemasWe use equation 5 to build schemas from the setof events as opposed to the set of event slots thatprevious work on narrative chains used.
In Cham-bers and Jurafsky (2008), narrative chains add thebest ?e, d?
based on the following:maxj:0<j<mchainsim(c, ?vj , gj?)
(6)where m is the number of seen event slots in thecorpus and ?vj , gj?
is the jth such possible eventslot.
Schemas are now learned by adding eventsthat maximize equation 5:maxj:0<j<|v|narsim(N, vj) (7)where |v| is the number of observed verbs and vjis the jth such verb.
Verbs are incrementally addedto a narrative schema by strength of similarity.arrestchargeseizeconfiscatedefendant, nichols,smith, simpsonpolice, agent,authorities, governmentlicenseimmigrant, reporter,cavalo, migrant, aliendetaindeportraidFigure 3: Graphical view of an unordered schemaautomatically built starting from the verb ?arrest?.A ?
value that encouraged splitting was used.4 Sample Narrative SchemasFigures 3 and 4 show two criminal schemaslearned completely automatically from the NYTportion of the Gigaword Corpus (Graff, 2002).We parse the text into dependency graphs and re-solve coreferences.
The figures result from learn-ing over the event slot counts.
In addition, figure 5shows six of the top 20 scoring narrative schemaslearned by our system.
We artificially required theclustering procedure to stop (and sometimes con-tinue) at six events per schema.
Six was chosenas the size to enable us to compare to FrameNetin the next section; the mean number of verbs inFrameNet frames is between five and six.
A low?
was chosen to limit chain splitting.
We built anew schema starting from each verb that occurs inmore than 3000 and less than 50,000 documentsin the NYT section.
This amounted to approxi-mately 1800 verbs from which we show the top20.
Not surprisingly, most of the top schemas con-cern business, politics, crime, or food.5 Frames and RolesMost previous work on unsupervised semanticrole labeling assumes that the set of possible606A produce BA sell BA manufacture BA *market BA distribute BA -develop BA ?
{company, inc, corp, microsoft,iraq, co, unit, maker, ...}B ?
{drug, product, system, test,software, funds, movie, ...}B trade CB fell CA *quote BB fall CB -slip CB rise CA ?
{}B ?
{dollar, share, index, mark, currency,stock, yield, price, pound, ...}C ?
{friday, most, year, percent, thursdaymonday, share, week, dollar, ...}A boil BA slice BA -peel BA saute BA cook BA chop BA ?
{wash, heat, thinly, onion, note}B ?
{potato, onion, mushroom, clove,orange, gnocchi }A detain BA confiscate BA seize BA raid BA search BA arrest BA ?
{police, agent, officer, authorities,troops, official, investigator, ... }B ?
{suspect, government, journalist,monday, member, citizen, client, ... }A *uphold BA *challenge BA rule BA enforce BA *overturn BA *strike down BA ?
{court, judge, justice, panel, osteen,circuit, nicolau, sporkin, majority, ...}B ?
{law, ban, rule, constitutionality,conviction, ruling, lawmaker, tax, ...}A own BA *borrow BA sell BA buy back BA buy BA *repurchase BA ?
{company, investor, trader, corp,enron, inc, government, bank, itt, ...}B ?
{share, stock, stocks, bond, company,security, team, funds, house, ... }Figure 5: Six of the top 20 scored Narrative Schemas.
Events and arguments in italics were markedmisaligned by FrameNet definitions.
* indicates verbs not in FrameNet.
- indicates verb senses not inFameNet.foundconvictacquitdefendant, nichols,smith, simpsonjury, juror, court,judge, tribunal, senatesentencedeliberatedeadlockedFigure 4: Graphical view of an unordered schemaautomatically built from the verb ?convict?.
Eachnode shape is a chain in the schema.classes is very small (i.e, PropBank roles ARG0and ARG1) and is known in advance.
By con-trast, our approach induces sets of entities that ap-pear in the argument positions of verbs in a nar-rative schema.
Our model thus does not assumethe set of roles is known in advance, and it learnsthe roles at the same time as clustering verbs intoframe-like schemas.
The resulting sets of entities(such as {police, agent, authorities, government}or {court, judge, justice}) can be viewed as a kindof schema-specific semantic role.How can this unsupervised method of learningroles be evaluated?
In Section 6 we evaluate theschemas together with their arguments in a clozetask.
In this section we perform a more qualitativeevalation by comparing our schema to FrameNet.FrameNet (Baker et al, 1998) is a database offrames, structures that characterize particular sit-uations.
A frame consists of a set of events (theverbs and nouns that describe them) and a setof frame-specific semantic roles called frame el-ements that can be arguments of the lexical unitsin the frame.
FrameNet frames share commonali-ties with narrative schemas; both represent aspectsof situations in the world, and both link semanti-cally related words into frame-like sets in whicheach predicate draws its argument roles from aframe-specific set.
They differ in that schemas fo-cus on events in a narrative, while frames focus onevents that share core participants.
Nonetheless,the fact that FrameNet defines frame-specific ar-gument roles suggests that comparing our schemasand roles to FrameNet would be elucidating.We took the 20 learned narrative schemas de-scribed in the previous section and used FrameNetto perform qualitative evaluations on three aspectsof schema: verb groupings, linking structure (themapping of each argument role to syntactic sub-ject or object), and the roles themselves (the set ofentities that constitutes the schema roles).Verb groupings To compare a schema?s eventselection to a frame?s lexical units, we first mapthe top 20 schemas to the FrameNet frames thathave the largest overlap with each schema?s sixverbs.
We were able to map 13 of our 20 narra-tives to FrameNet (for the remaining 7, no framecontained more than one of the six verbs).
Theremaining 13 schemas contained 6 verbs each fora total of 78 verbs.
26 of these verbs, however,did not occur in FrameNet, either at all, or withthe correct sense.
Of the remaining 52 verb map-pings, 35 (67%) occurred in the closest FrameNetframe or in a frame one link away.
17 verbs (33%)607occurred in a different frame than the one chosen.We examined the 33% of verbs that occurred ina different frame.
Most occurred in related frames,but did not have FrameNet links between them.For instance, one schema includes the causal verbtrade with unaccusative verbs of change like riseand fall.
FrameNet separates these classes of verbsinto distinct frames, distinguishing motion framesfrom caused-motion frames.Even though trade and rise are in differentFrameNet frames, they do in fact have the narra-tive relation that our system discovered.
Of the 17misaligned events, we judged all but one to be cor-rect in a narrative sense.
Thus although not exactlyaligned with FrameNet?s notion of event clusters,our induction algorithm seems to do very well.Linking structure Next, we compare aschema?s linking structure, the grammaticalrelation chosen for each verb event.
We thusdecide, e.g., if the object of the verb arrest (arrestB) plays the same role as the object of detain(detain B), or if the subject of detain (B detain)would have been more appropriate.We evaluated the clustering decisions of the 13schemas (78 verbs) that mapped to frames.
Foreach chain in a schema, we identified the frameelement that could correctly fill the most verb ar-guments in the chain.
The remaining argumentswere considered incorrect.
Because we assumedall verbs to be transitive, there were 156 arguments(subjects and objects) in the 13 schema.
Of these156 arguments, 151 were correctly clustered to-gether, achieving 96.8% accuracy.The schema in figure 5 with events detain, seize,arrest, etc.
shows some of these errors.
The objectof all of these verbs is an animate theme, but con-fiscate B and raid B are incorrect; people cannotbe confiscated/raided.
They should have been splitinto their own chain within the schema.Argument Roles Finally, we evaluate thelearned sets of entities that fill the argument slots.As with the above linking evaluation, we first iden-tify the best frame element for each argument.
Forexample, the events in the top left schema of fig-ure 5 map to the Manufacturing frame.
ArgumentB was identified as the Product frame element.
Wethen evaluate the top 10 arguments in the argumentset, judging whether each is a reasonable filler ofthe role.
In our example, drug and product are cor-rect Product arguments.
An incorrect argument istest, as it was judged that a test is not a product.We evaluated all 20 schemas.
The 13 mappedschemas used their assigned frames, and we cre-ated frame element definitions for the remaining 7that were consistent with the syntactic positions.There were 400 possible arguments (20 schemas,2 chains each), and 289 were judged correct for aprecision of 72%.
This number includes Personand Organization names as correct fillers.
A moreconservative metric removing these classes resultsin 259 (65%) correct.Most of the errors appear to be from parsingmistakes.
Several resulted from confusing objectswith adjuncts.
Others misattached modifiers, suchas including most as an argument.
The cookingschema appears to have attached verbal argumentslearned from instruction lists (wash, heat, boil).Two schemas require situations as arguments, butthe dependency graphs chose as arguments thesubjects of the embedded clauses, resulting in 20incorrect arguments in these schema.6 Evaluation: ClozeThe previous section compared our learned knowl-edge to current work in event and role semantics.We now provide a more formal evaluation againstuntyped narrative chains.
The two main contribu-tions of schema are (1) adding typed argumentsand (2) considering joint chains in one model.
Weevaluate each using the narrative cloze test as in(Chambers and Jurafsky, 2008).6.1 Narrative ClozeThe cloze task (Taylor, 1953) evaluates human un-derstanding of lexical units by removing a randomword from a sentence and asking the subject toguess what is missing.
The narrative cloze is avariation on this idea that removes an event slotfrom a known narrative chain.Performance is mea-sured by the position of the missing event slot in asystem?s ranked guess list.This task is particularly attractive for narrativeschemas (and chains) because it aligns with oneof the original ideas behind Schankian scripts,namely that scripts help humans ?fill in the blanks?when language is underspecified.6.2 Training and Test DataWe count verb pairs and shared arguments overthe NYT portion of the Gigaword Corpus (years1994-2004), approximately one million articles.6081995 1996 1997 1998 1999 2000 2001 2002 2003 200410001050110011501200125013001350Training Data from 1994?XRankedPositionNarrative Cloze TestChain Typed Chain Schema Typed SchemaFigure 6: Results with varying sizes of trainingdata.We parse the text into typed dependency graphswith the Stanford Parser (de Marneffe et al, 2006),recording all verbs with subject, object, or prepo-sitional typed dependencies.
Unlike in (Chambersand Jurafsky, 2008), we lemmatize verbs and ar-gument head words.
We use the OpenNLP1 coref-erence engine to resolve entity mentions.The test set is the same as in (Chambers and Ju-rafsky, 2008).
100 random news articles were se-lected from the 2001 NYT section of the GigawordCorpus.
Articles that did not contain a protagonistwith five or more events were ignored, leaving atest set of 69 articles.
We used a smaller develop-ment set of size 17 to tune parameters.6.3 Typed ChainsThe first evaluation compares untyped againsttyped narrative event chains.
The typed modeluses equation 4 for chain clustering.
The dottedline ?Chain?
and solid ?Typed Chain?
in figure 6shows the average ranked position over the test set.The untyped chains plateau and begin to worsenas the amount of training data increases, but thetyped model is able to improve for some time af-ter.
We see a 6.9% gain at 2004 when both linestrend upwards.6.4 Narrative SchemaThe second evaluation compares the performanceof the narrative schema model against single nar-rative chains.
We ignore argument types and useuntyped chains in both (using equation 1 instead1http://opennlp.sourceforge.net/of 4).
The dotted line ?Chain?
and solid ?Schema?show performance results in figure 6.
NarrativeSchemas have better ranked scores in all data sizesand follow the previous experiment in improvingresults as more data is added even though untypedchains trend upward.
We see a 3.3% gain at 2004.6.5 Typed Narrative SchemaThe final evaluation combines schemas with ar-gument types to measure overall gain.
We eval-uated with both head words and CBC clustersas argument representations.
Not only do typedchains and schemas outperform untyped chains,combining the two gives a further performanceboost.
Clustered arguments improve the re-sults further, helping with sparse argument counts(?Typed Schema?
in figure 6 uses CBC argu-ments).
Overall, using all the data (by year 2004)shows a 10.1% improvement over untyped narra-tive chains.7 DiscussionOur significant improvement in the cloze evalua-tion shows that even though narrative cloze doesnot evaluate argument types, jointly modeling thearguments with events improves event cluster-ing.
Likewise, the FrameNet comparison suggeststhat modeling related events helps argument learn-ing.
The tasks mutually inform each other.
Ourargument learning algorithm not only performsunsupervised induction of situation-specific roleclasses, but the resulting roles and linking struc-tures may also offer the possibility of (unsuper-vised) FrameNet-style semantic role labeling.Finding the best argument representation is animportant future direction.
The performance ofour noun clusters in figure 6 showed that while theother approaches leveled off, clusters continuallyimproved with more data.
The exact balance be-tween lexical units, clusters, or more general (tra-ditional) semantic roles remains to be solved, andmay be application specific.We hope in the future to show that a range ofNLU applications can benefit from the rich infer-ential structures that narrative schemas provide.AcknowledgmentsThis work is funded in part by NSF (IIS-0811974).We thank the reviewers and the Stanford NLPGroup for helpful suggestions.609ReferencesAfra Alishahi and Suzanne Stevenson.
2007.
A com-putational usage-based model for learning generalproperties of semantic roles.
In The 2nd EuropeanCognitive Science Conference, Delphi, Greece.Collin F. Baker, Charles J. Fillmore, and John B. Lowe.1998.
The Berkeley FrameNet project.
In ChristianBoitet and Pete Whitelock, editors, ACL-98, pages86?90, San Francisco, California.
Morgan Kauf-mann Publishers.David Bean and Ellen Riloff.
2004.
Unsupervisedlearning of contextual role knowledge for corefer-ence resolution.
Proc.
of HLT/NAACL, pages 297?304.Nathanael Chambers and Dan Jurafsky.
2008.
Unsu-pervised learning of narrative event chains.
In Pro-ceedings of ACL-08, Hawaii, USA.Marie-Catherine de Marneffe, Bill MacCartney, andChristopher D. Manning.
2006.
Generating typeddependency parses from phrase structure parses.
InProceedings of LREC-06, pages 449?454.David Graff.
2002.
English Gigaword.
LinguisticData Consortium.Rebecca Green and Bonnie J. Dorr.
2005.
Frame se-mantic enhancement of lexical-semantic resources.In ACL-SIGLEX Workshop on Deep Lexical Acqui-sition, pages 57?66.Trond Grenager and Christopher D. Manning.
2006.Unsupervised discovery of a statistical verb lexicon.In EMNLP.Shan He and Daniel Gildea.
2006.
Self-training andco-training for semantic role labeling: Primary re-port.
Technical Report 891, University of Rochester.Karin Kipper, Hoa Trang Dang, and Martha Palmer.2000.
Class-based construction of a verb lexicon.In Proceedings of AAAI-2000, Austin, TX.Martha Palmer, Daniel Gildea, and Paul Kingsbury.2005.
The proposition bank: A corpus annotatedwith semantic roles.
Computational Linguistics,31(1):71?106.Patrick Pantel and Dekang Lin.
2002.
Document clus-tering with committees.
In ACM Conference on Re-search and Development in Information Retrieval,pages 199?206, Tampere, Finland.Roger C. Schank and Robert P. Abelson.
1977.
Scripts,plans, goals and understanding.
Lawrence Erl-baum.Robert S. Swier and Suzanne Stevenson.
2004.
Unsu-pervised semantic role labelling.
In EMNLP.Wilson L. Taylor.
1953.
Cloze procedure: a new toolfor measuring readability.
Journalism Quarterly,30:415?433.610
