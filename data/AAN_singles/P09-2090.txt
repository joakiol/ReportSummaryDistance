Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 357?360,Suntec, Singapore, 4 August 2009.c?2009 ACL and AFNLPArabic Cross-Document Coreference DetectionAsad Sayeed,1,2Tamer Elsayed,1,2Nikesh Garera,1,6David Alexander,1,3Tan Xu,1,4Douglas W. Oard,1,4,5David Yarowsky,1,6Christine Piatko11Human Language Technology Center of Excellence, Johns Hopkins University, Baltimore,MD, USA?2Dept.
of Computer Science, University of Maryland, College Park, MD,USA?3BBN Technologies, Cambridge, MA, USA?4College of Information Studies,University of Maryland, College Park, MD, USA?5UMIACS, University of Maryland, CollegePark, MD, USA?6Dept.
of Computer Science, Johns Hopkins University, Baltimore, MD, USA{asayeed,telsayed}@cs.umd.edu, ngarera@cs.jhu.edu, dalexand@bbn.com,{tanx,oard}@umd.edu, yarowsky@cs.jhu.edu, Christine.Piatko@jhuapl.eduAbstractWe describe a set of techniques for Ara-bic cross-document coreference resolu-tion.
We compare a baseline system ofexact mention string-matching to ones thatinclude local mention context informationas well as information from an existingmachine translation system.
It turns outthat the machine translation-based tech-nique outperforms the baseline, but localentity context similarity does not.
Thishelps to point the way for future cross-document coreference work in languageswith few existing resources for the task.1 IntroductionOur world contains at least two noteworthyGeorge Bushes: President George H. W. Bush andPresident George W. Bush.
They are both fre-quently referred to as ?George Bush.?
If we wishto use a search engine to find documents aboutone of them, we are likely also to find documentsabout the other.
Improving our ability to find alldocuments referring to one and none referring tothe other in a targeted search is a goal of cross-document entity coreference detection.
Here wedescribe some results from a system we built toperform this task on Arabic documents.
We baseour work partly on previous work done by Baggaand Baldwin (Bagga and Baldwin, 1998), whichhas also been used in later work (Chen and Mar-tin, 2007).
Other work such as Lloyd et al (Lloyd,2006) focus on techniques specific to English.The main contribution of this work to cross-document coreference lies in the conditions underwhich it was done.
Even now, there is no large-scale resource?in terms of annotated data?forcross-document coreference in Arabic as there isin English (e.g.
WebPeople (Artiles, 2008)).
Thus,we employed techniques for high-performanceprocessing in a resource-poor environment.
Weprovide early steps in cross-document coreferencedetection for resource-poor languages.2 ApproachWe treat cross-document entities as a set of graphsconsisting of links between within-document enti-ties.
The graphs are disjoint.
Each of our systemsproduces a list of such links as within-documententity pairs (A,B).
We obtain within-documententities by running the corpus through a within-document coreference resolver?in this case, Seriffrom BBN Technologies.To create the entity clusters, we use a union-find algorithm over the pairs.
If links (A,B)and (C,B) appear in the system output, then{A,B,C} are one entity.
Similarly, if (X,Y )and (Z, Y ) appear in the output, then it will findthat {X,Y, Z} are one entity.
If the algorithmlater discovers link (B,Z) in the system output, itwill decide that {A,B,C,X, Y, Z} are an entity.This is efficiently implemented via a hash tablewhose keys and values are both within-documententity IDs, allowing the implementation of easily-searched linked lists.2.1 The baseline systemThe baseline system uses a string matching cri-terion to determine whether two within-documententities are similar enough to be considered as partof the same cross-document entity.
Given within-document entities A and B, the criterion is imple-mented as follows:1.
Find the mention strings {a1, a2, .
.
.}
and357{b1, b2, .
.
.}
of A and B, respectively that arethe longest for that within-document entityin the given document.
(There may be morethan one longest mention of equal length fora given entity.)2.
If any longest mention strings anand bmexistsuch that an= bm(exact string match), thenA and B are considered to be part of the samecross-document entity.
Otherwise, they areconsidered to be different entities.When the system decides that two within-document entities are connected as a single cross-document entity, it emits a link between within-document entities A and B represented as the pair(A, B).
We maintain a list of such links, but weomit all links between within-document entities inthe same document.The output of the system is a list of pairwiselinks.
The following two experimental systemsalso produce lists of pairwise links.
Union is per-formed between the baseline system?s list and thelists produced by the other systems to create listsof pairs that include the information in the base-line.
However, each of the following systems?outputs are merged separately with the baseline.By including the baseline results in each system,we are able to clarify the potential of each addi-tional technique to improve performance over atechnique that is cheap to run under any circum-stances, especially given that our experiments arefocused on increasing the number of links in anArabic context where links are likely to be dis-rupted by spelling variations.2.2 Translingual projectionWe implement a novel cross-language approachfor Arabic coreference resolution by expandingthe space of exact match comparisons to approxi-mate matches of English translations of the Arabicstrings.
The intuition for this approach is that of-ten the Arabic strings of the same named entitymay differ due to misspellings, titles, or aliasesthat can be corrected in the English space.
TheEnglish translations were obtained using a stan-dard statistical machine translation system (Chi-ang, 2007; Li, 2008) and then compared using analias match.The algorithm below describes the approach,applied to any Arabic named entities that fail thebaseline string-match test:1.
For a given candidate Arabic named entitypair (A,B), we project them into English bytranslating the mentions using a standard sta-tistical machine translation toolkit.
Using theprojected English pair, say, (A?, B?)
we per-form the following tests to determine whetherA and B are co-referent:(a) We do an exact string-match test in theEnglish space using the projected enti-ties (A?, B?).
The exact string match testis done exactly as in the baseline system,using the set of longest named entities intheir respective co-reference chains.
(b) If (A?, B?)
fail in the exact string-matchtest as in the baseline, then we testwhether they belong to a list of high con-fidence co-referent named-entity pairs1precomputed for English using alias-lists derived from Wikipedia.
(c) If (A?, B?)
fails (a) and (b) then (A,B)is deemed as non-coreferent.While we hypothesize that translingual projectionvia English should help in increasing recall sinceit can work with non-exact string matches, it mayalso help in increasing precision based on the as-sumption that a name of American or English ori-gin might have different variants in Arabic and thattranslating to English can help in merging thosevariants, as shown in figure 1.?????
???????????????????????????????(Ms.
Aisha)(Aisha)(Clenton)(Clinton)(Cilinton)AishaAishaClintonClintonClintonTranslatevia SMTFigure 1: Illustration of translingual projectionmethod for resolving Arabic named entity stringsvia English space.
The English strings in paren-theses indicate the literal glosses of the Arabicstrings prior to translation.2.3 Entity context similarityThe context of mentions can play an important rolein merging or splitting potential coreferent men-1For example: (Sean Michael Waltman, Sean Waltman)are high confidence-matches even though they are not anexact-string match.358tions.
We hypothesize that two mentions in twodifferent documents have a good chance of refer-ring to the same entity if they are mentioned incontexts that are topically very similar.
A way ofrepresenting a mention context is to consider thewords in the mention?s neighborhood.
The con-text of a mention can be defined as the words thatsurround the mention in a window of n (50 in ourexperiments) tokens centered by the mention.
Inour experiments, we used highly similar contextsto link mentions that might be coreferent.Computing context similarity between everypair of large number of mentions requires a highlyscalable and efficient mechanism.
This can beachieved using MapReduce, a distributed comput-ing framework (Dean, 2004)Elsayed et al (Elsayed, 2008) proposed an ef-ficient MapReduce solution for the problem ofcomputing the pairwise similarity matrix in largecollections.
They considered a ?bag-of-words?model where similarity of two documents diand djis measured as follows: sim(di, dj) =?t?di?djwt,di?
wt,dj, where w(t, d) is the weightof term t in document d. A term contributes toeach pair that contains it.
The list of documentsthat contain a term is what is contained in the post-ings of an inverted index.
Thus, by processingall postings, the pairwise similarity matrix can becomputed by summing term contributions.
We usethe MapReduce framework for two jobs, invertedindexing and pairwise similarity.Elsayed et al suggested an efficient df-cut strat-egy that eliminates terms that appear in many doc-uments (having high df ) and thus contribute lessin similarity but cost in computation (e.g., a 99%df-cut means that the most frequent 1% of theterms were discarded).
We adopted that approachfor computing similarities between the contextsof two mentions.
The processing unit was rep-resented as a bag of n words in a window sur-rounding each mention of a within-document en-tity.
Given a relatively small mention context, weused a high df-cut value of 99.9%.3 ExperimentsWe performed our experiments in the context ofthe Automatic Content Extraction (ACE) eval-uation of 2008, run by the National Instituteof Standards and Technology (NIST).
The eval-uation corpus contained approximately 10,000documents from the following domains: broad-cast conversation transcripts, broadcast news tran-scripts, conversational telephone speech tran-scripts, newswire, Usenet Newsgroup/DiscussionGroups, and weblogs.
Systems were required toprocess the large source sets completely.
For per-formance measurement after the evaluation, NISTselected 412 of the Arabic source documents outof the larger set (NIST, 2008).For development purposes we used the NISTACE 2005 Arabic data with within-documentground truth.
This consisted of 1,245 documents.We also used exactly 12,000 randomly selecteddocuments from the LDC Arabic Gigaword ThirdEdition corpus, processed through Serif.
The Ara-bic Gigaword corpus was used to select a thresh-old of 0.4956 for the context similarity techniquevia inspection of (A,B) link scores by a nativespeaker of Arabic.It must be emphasized that there was no groundtruth available for this task in Arabic.
Performingthis task in the absence of significant training orevaluation data is one emphasis of this work.3.1 Evaluation measuresWe used NIST?s scoring techniques to evaluate theperformance of our systems.
Scoring for the ACEevaluation is done using an scoring script providedby NIST which produces many kinds of statistics.NIST mainly uses a measure called the ACE value,but it also computes B-cubed.B-Cubed represents the task of finding cross-document entities in the following way: if a userof the system is searching for a particular Bushand finds document D, he or she should be able tofind all of the other documents with the same Bushin them as links from D?that is, cross-documententities represent graphs connecting documents.Bagga and Baldwin are able to define precision,recall, and F-measure over a collection of docu-ments in this way.The ACE Value represents a score similar toB-Cubed, except that every mention and within-document entity is weighted in NIST?s specifica-tion by a number of factors.
Every entity is worth 1point, a missing entity worth 0, and attribute errorsare discounted by multiplying by a factor (0.75 forCLASS, 0.5 for TYPE, and 0.9 for SUBTYPE).Before scoring can be accomplished, the enti-ties found by the system must be mapped ontothose found in the reference provided by NIST.The ACE scorer does this document-by-document,359selecting the mapping that produces the highestscore.
A description of the evaluation method andentity categorization is available at (NIST, 2008).3.2 Results and discussionThe results of running the ACE evaluation scripton the system output are shown in table 1.
Thetranslingual projection system achieves higherscores than all other systems on all measures.
Al-though it achieves only a 2 point improvementover the baseline ACE value, it should be notedthat this represents a substantial number of at-tributes per cross-document entity that it is gettingright.Thresh B-Cubed ACESystem hold Prec Rec F Val.Baseline 37.5 44.1 40.6 19.2TrnsProj 38.4 44.8 41.3 21.2CtxtSim 0.2 37.6 35.2 36.4 15.9CtxtSim 0.3 37.4 43.8 40.3 18.9CtxtSim 0.4 37.5 44.1 40.6 19.3CtxtSim 0.4956 37.5 44.1 40.6 19.3CtxtSim 0.6 37.5 44.1 40.6 19.2Table 1: Scores from ACE evaluation script.On the other hand, as the context similaritythreshold increases, we notice that the B-Cubedmeasures reach identical values with the baselinebut never exceed it.
But as it decreases, it losesB-Cubed recall and ACE value.While two within-document entities whoselongest mention strings match exactly and are le-gitimately coreferent are likely to be mentioned inthe same contexts, it seems that a lower (more lib-eral) threshold introduces spurious links and cre-ates a different entity clustering.Translingual projection appears to include linksthat exact string matching in Arabic does not?part of its purpose is to add close matches to thosefound by exact string matching.
It is able to in-clude these links partly because it allows access toresources in English that are not available for Ara-bic such as Wikipedia alias lists.4 Conclusions and Future WorkWe have evaluated and discussed a set of tech-niques for cross-document coreference in Arabicthat can be applied in the absence of significanttraining and evaluation data.
As it turns out, anapproach based on machine translation is slightlybetter than a string-matching baseline, across allmeasures.
It worked by using translations fromArabic to English in order to liberalize the string-matching criterion, suggesting that using furthertechniques via English to discover links may bea fruitful future research path.
This also seemsto suggest that a Bagga and Baldwin-style vector-space model may not be the first approach to pur-sue in future work on Arabic.However, varying other parameters in the con-text similarity approach should be tried in orderto gain a fuller picture of performance.
One ofthem is the df-cut of the MapReduce-based sim-ilarity computation.
Another is the width of theword token window we used?we may have usedone that is too tight to be better than exact Arabicstring-matching.ReferencesJavier Artiles and Satoshi Sekine and Julio Gonzalo2008.
Web People Search?Results of the first eval-uation and the plan for the second.
WWW 2008.A.
Bagga and B. Baldwin.
1998.
Entity-based cross-document coreferencing using the vector spacemodel.
COLING-ACL 1998.Y.
Chen and J. Martin.
2007.
Towards robust unsuper-vised personal name disambiguation.
EMNLP.D.
Chiang.
2007.
Hierarchical phrase-based transla-tion.
Computational Linguistics, 33(2).J.
Dean and S. Ghemawat.
2004.
MapReduce: Simpli-fied Data Processing on Large Clusters.
OSDI.T.
Elsayed and J. Lin and D. W. Oard.
2008.
Pair-wise Document Similarity in Large Collections withMapReduce.
ACL/HLT.Z.
Li and S. Khudanpur.
2008.
A Scalable Decoder forParsing-based Machine Translation with EquivalentLanguage Model State Maintenance.
ACL SSST.L.
Lloyd and Andrew Mehler and Steven Skiena.
2006.Identifying Co-referential Names Across Large Cor-pora.
Combinatorial Pattern Matching.NIST.
2008.
Automatic Content Extraction 2008 Eval-uation Plan (ACE08).360
