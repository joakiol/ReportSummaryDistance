Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 451?455,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsRecognizing Partial Textual EntailmentOmer Levy?
Torsten Zesch?
Ido Dagan?
Iryna Gurevych??
Natural Language Processing Lab ?
Ubiquitous Knowledge Processing LabComputer Science Department Computer Science DepartmentBar-Ilan University Technische Universita?t DarmstadtAbstractTextual entailment is an asymmetric rela-tion between two text fragments that de-scribes whether one fragment can be in-ferred from the other.
It thus cannot cap-ture the notion that the target fragmentis ?almost entailed?
by the given text.The recently suggested idea of partial tex-tual entailment may remedy this problem.We investigate partial entailment under thefaceted entailment model and the possibil-ity of adapting existing textual entailmentmethods to this setting.
Indeed, our resultsshow that these methods are useful for rec-ognizing partial entailment.
We also pro-vide a preliminary assessment of how par-tial entailment may be used for recogniz-ing (complete) textual entailment.1 IntroductionApproaches for applied semantic inference overtexts gained growing attention in recent years,largely triggered by the textual entailment frame-work (Dagan et al, 2009).
Textual entailment isa generic paradigm for semantic inference, wherethe objective is to recognize whether a textual hy-pothesis (labeled H) can be inferred from anothergiven text (labeled T ).
The definition of textualentailment is in some sense strict, in that it requiresthat H?s meaning be implied by T in its entirety.This means that from an entailment perspective, atext that contains the main ideas of a hypothesis,but lacks a minor detail, is indiscernible from anentirely unrelated text.
For example, if T is ?mus-cles move bones?, and H ?the main job of musclesis to move bones?, then T does not entail H , andwe are left with no sense of how close (T,H) wereto entailment.In the related problem of semantic text similar-ity, gradual measures are already in use.
The se-mantic text similarity challenge in SemEval 2012(Agirre et al, 2012) explicitly defined differentlevels of similarity from 5 (semantic equivalence)to 0 (no relation).
For instance, 4 was definedas ?the two sentences are mostly equivalent, butsome unimportant details differ?, and 3 meant that?the two sentences are roughly equivalent, butsome important information differs?.
Though thismodeling does indeed provide finer-grained no-tions of similarity, it is not appropriate for seman-tic inference for two reasons.
First, the term ?im-portant information?
is vague; what makes one de-tail more important than another?
Secondly, simi-larity is not sufficiently well-defined for sound se-mantic inference; for example, ?snowdrops bloomin summer?
and ?snowdrops bloom in winter?may be similar, but have contradictory meanings.All in all, these measures of similarity do not quitecapture the gradual relation needed for semanticinference.An appealing approach to dealing with therigidity of textual entailment, while preserving themore precise nature of the entailment definition, isby breaking down the hypothesis into components,and attempting to recognize whether each one isindividually entailed by T .
It is called partial tex-tual entailment, because we are only interested inrecognizing whether a single element of the hy-pothesis is entailed.
To differentiate the two tasks,we will refer to the original textual entailment taskas complete textual entailment.Partial textual entailment was first introducedby Nielsen et al (2009), who presented a ma-chine learning approach and showed significantimprovement over baseline methods.
Recently, apublic benchmark has become available throughthe Joint Student Response Analysis and 8th Rec-ognizing Textual Entailment (RTE) Challenge inSemEval 2013 (Dzikovska et al, 2013), on whichwe focus in this paper.Our goal in this paper is to investigate the ideaof partial textual entailment, and assess whether451existing complete textual entailment methods canbe used to recognize it.
We assume the facetmodel presented in SemEval 2013, and adapt ex-isting technologies to the task of recognizing par-tial entailment (Section 3).
Our work further ex-pands upon (Nielsen et al, 2009) by evaluatingthese adapted methods on the new RTE-8 bench-mark (Section 4).
Partial entailment may also fa-cilitate an alternative divide and conquer approachto complete textual entailment.
We provide an ini-tial investigation of this approach (Section 5).2 Task DefinitionIn order to tackle partial entailment, we need tofind a way to decompose a hypothesis.
Nielsen etal.
(2009) defined a model of facets, where eachsuch facet is a pair of words in the hypothesisand the direct semantic relation connecting thosetwo words.
We assume the simplified model thatwas used in RTE-8, where the relation between thewords is not explicitly stated.
Instead, it remainsunstated, but its interpreted meaning should corre-spond to the manner in which the words are relatedin the hypothesis.
For example, in the sentence?the main job of muscles is to move bones?, thepair (muscles, move) represents a facet.
While it isnot explicitly stated, reading the original sentenceindicates that muscles is the agent of move.Formally, the task of recognizing faceted entail-ment is a binary classification task.
Given a text T ,a hypothesis H , and a facet within the hypothesis(w1, w2), determine whether the facet is either ex-pressed or unaddressed by the text.
Nielsen et alincluded additional classes such as contradicting,but in the scope of this paper we will only tend tothe binary case, as was done in RTE-8.Consider the following example:T: Muscles generate movement in the body.H: The main job of muscles is to move bones.The facet (muscles, move) refers to the agent rolein H , and is expressed by T .
However, the facet(move, bones), which refers to a theme or directobject relation in H , is unaddressed by T .3 Recognizing Faceted EntailmentOur goal is to investigate whether existing entail-ment recognition approaches can be adapted torecognize faceted entailment.
Hence, we speci-fied relatively simple decision mechanisms over aset of entailment detection modules.
Given a textand a facet, each module reports whether it rec-ognizes entailment, and the decision mechanismthen determines the binary class (expressed or un-addressed) accordingly.3.1 Entailment ModulesCurrent textual entailment systems operate acrossdifferent linguistic levels, mainly on lexical infer-ence and syntax.
We examined three representa-tive modules that reflect these levels: Exact Match,Lexical Inference, and Syntactic Inference.Exact Match We represent T as a bag-of-wordscontaining all tokens and lemmas appearing in thetext.
We then check whether both facet lemmasw1, w2 appear in the text?s bag-of-words.
Exactmatching was used as a baseline in previous rec-ognizing textual entailment challenges (Bentivogliet al, 2011), and similar methods of lemma-matching were used as a component in recogniz-ing textual entailment systems (Clark and Harri-son, 2010; Shnarch et al, 2011).Lexical Inference This feature checks whetherboth facet words, or semantically related words,appear in T .
We use WordNet (Fellbaum, 1998)with the Resnik similarity measure (Resnik, 1995)and count a facet term wi as matched if the sim-ilarity score exceeds a certain threshold (0.9, em-pirically determined on the training set).
Both w1and w2 must match for this module?s entailmentdecision to be positive.Syntactic Inference This module builds uponthe open source1 Bar-Ilan University Textual En-tailment Engine (BIUTEE) (Stern and Dagan,2011).
BIUTEE operates on dependency trees byapplying a sequence of knowledge-based transfor-mations that converts T into H .
It determines en-tailment according to the ?cost?
of generating thehypothesis from the text.
The cost model can beautomatically tuned with a relatively small train-ing set.
BIUTEE has shown state-of-the-art per-formance on previous recognizing textual entail-ment challenges (Stern and Dagan, 2012).Since BIUTEE processes dependency trees,both T and the facet must be parsed.
We thereforeextract a path in H?s dependency tree that repre-sents the facet.
This is done by first parsing H ,and then locating the two nodes whose words com-pose the facet.
We then find their lowest commonancestor (LCA), and extract the path P from w1 to1cs.biu.ac.il/?nlp/downloads/biutee452w2 through the LCA.
This path is in fact a depen-dency tree.
BIUTEE can now be given T and P(as the hypothesis), and try to recognize whetherthe former entails the latter.3.2 Decision MechanismsWe started our experimentation process by defin-ing Exact Match as a baseline.
Though very sim-ple, this unsupervised baseline performed surpris-ingly well, with 0.96 precision and 0.32 recall onexpressed facets of the training data.
Given itsvery high precision, we decided to use this mod-ule as an initial filter, and employ the others forclassifying the ?harder?
cases.We present all the mechanisms that we tested:Baseline ExactBaseLex Exact ?
LexicalBaseSyn Exact ?
SyntacticDisjunction Exact ?
Lexical ?
SyntacticMajority Exact ?
(Lexical ?
Syntactic)Note that since every facet that Exact Matchclassifies as expressed is also expressed by Lexi-cal Inference, BaseLex is essentially Lexical Infer-ence on its own, and Majority is equivalent to themajority rule on all three modules.4 Empirical Evaluation4.1 Dataset: Student Response AnalysisWe evaluated our methods as part of RTE-8.
Thechallenge focuses on the domain of scholasticquizzes, and attempts to emulate the meticulousmarking process that teachers do on a daily basis.Given a question, a student?s response, and a refer-ence answer, the task of student response analysisis to determine whether the student answered cor-rectly.
This task can be approximated as a specialcase of textual entailment; by assigning the stu-dent?s answer as T and the reference answer as H ,we are basically asking whether one can infer thecorrect (reference) answer from the student?s re-sponse.Recall the example from Section 2.
In this case,H is a reference answer to the question:Q: What is the main job of muscles?T is essentially the student answer, though it isalso possible to define T as the union of both thequestion and the student answer.
In this work, wechose to exclude the question.There were two tracks in the challenge: com-plete textual entailment (the main task) and partialUnseen Unseen UnseenAnswers Questions DomainsBaseline .670 .688 .731BaseLex .756 .710 .760BaseSyn .744 .733 .770Disjunction .695 .655 .703Majority .782 .765 .816Table 1: Micro-averaged F1 on the faceted Sci-EntsBank test set.entailment (the pilot task).
Both tasks made use ofthe SciEntsBank corpus (Dzikovska et al, 2012),which is annotated at facet-level, and provides aconvenient test-bed for evaluation of both partialand complete entailment.
This dataset was splitinto train and test subsets.
The test set has 16,263facet-response pairs based on 5,106 student re-sponses over 15 domains (learning modules).
Per-formance was measured using micro-averaged F1,over three different scenarios:Unseen Answers Classify new answers to ques-tions seen in training.
Contains 464 student re-sponses.Unseen Questions Classify new answers toquestions that were not seen in training, but otherquestions from the same domain were.
Contains631 student responses.Unseen Domains Classify new answers to un-seen questions from unseen domains.
Contains4,011 student responses.4.2 ResultsTable 1 shows the F1-measure of each configu-ration in each scenario.
There is some variancebetween the different scenarios; this may be at-tributed to the fact that there are much fewer Un-seen Answers and Unseen Questions instances.
Inall cases, Majority significantly outperformed theother configurations.
While BaseLex and BaseSynimprove upon the baseline, they seem to make dif-ferent mistakes, in particular false positives.
Theirconjunction is thus a more conservative indicatorof entailment, and proves helpful in terms of F1.All improvements over the baseline were foundto be statistically significant using McNemar?s testwith p < 0.01 (excluding Disjunction).
It is alsointeresting to note that the systems?
performancedoes not degrade in ?harder?
scenarios; this is a re-sult of the mostly unsupervised nature of our mod-ules.453Unfortunately, our system was the only submis-sion in the partial entailment pilot track of RTE-8, so we have no comparisons with other sys-tems.
However, the absolute improvement fromthe exact-match baseline to the more sophisticatedMajority is in the same ballpark as that of the bestsystems in previous recognizing textual entailmentchallenges.
For instance, in the previous recogniz-ing textual entailment challenge (Bentivogli et al,2011), the best system yielded an F1 score of 0.48,while the baseline scored 0.374.
We can thereforeconclude that existing approaches for recognizingtextual entailment can indeed be adapted for rec-ognizing partial entailment.5 Utilizing Partial Entailment forRecognizing Complete EntailmentEncouraged by our results, we ask whether thesame algorithms that performed well on thefaceted entailment task can be used for recogniz-ing complete textual entailment.
We performed aninitial experiment that examines this concept andsheds some light on the potential role of partial en-tailment as a possible facilitator for complete en-tailment.We suggest the following 3-stage architecture:1.
Decompose the hypothesis into facets.2.
Determine whether each facet is entailed.3.
Aggregate the individual facet results and de-cide on complete entailment accordingly.Facet Decomposition For this initial investiga-tion, we use the facets provided in SciEntsBank;i.e.
we assume that the step of facet decompositionhas already been carried out.
When the datasetwas created for RTE-8, many facets were extractedautomatically, but only a subset was selected.
Thefacet selection process was done manually, as partof the dataset?s annotation.
For example, in ?themain job of muscles is to move bones?, the facet(job, muscles) was not selected, because it was notcritical for answering the question.
We refer to theissue of relying on manual input further below.Recognizing Faceted Entailment This step wascarried out as explained in the previous sections.We used the Baseline configuration and Majority,which performed best in our experiments above.In addition, we introduce GoldBased that uses thegold annotation of faceted entailment, and thusUnseen Unseen UnseenAnswers Questions DomainsBaseline .575 .582 .683Majority .707 .673 .764GoldBased .842 .897 .852BestComplete .773 .745 .712Table 2: Micro-averaged F1 on the 2-way com-plete entailment SciEntsBank test set.provides a certain upper bound on the perfor-mance of determining complete entailment basedon facets.Aggregation We chose the simplest sensible ag-gregation rule to decide on overall entailment: astudent answer is classified as correct (i.e.
it en-tails the reference answer) if it expresses eachof the reference answer?s facets.
Although thisheuristic is logical from a strict entailment per-spective, it might yield false negatives on this par-ticular dataset.
This happens because tutors maysometimes grade answers as valid even if theyomit some less important, or indirectly implied,facets.Table 2 shows the experiment?s results.
Thefirst thing to notice is that GoldBased is not per-fect.
There are two reasons for this behavior.First, the task of student response analysis is onlyan approximation of textual entailment, albeit agood one.
This discrepancy was also observedby the RTE-8 challenge organizers (Dzikovska etal., 2013).
The second reason is because some ofthe original facets were filtered when creating thedataset.
This caused both false positives (whenimportant facets were filtered out) and false neg-atives (when unimportant facets were retained).Our Majority mechanism, which requires thatthe two underlying methods for partial entailmentdetection (Lexical Inference and Syntactic Infer-ence) agree on a positive classification, bridgesabout half the gap from the baseline to the goldbased method.
As a rough point of comparison,we also show the performance of BestComplete,the winning entry in each setting of the RTE-8main task.
This measure is not directly compara-ble to our facet-based systems, because it did notrely on manually selected facets, and due to somevariations in the dataset size (about 20% of the stu-dent responses were not included in the pilot taskdataset).
However, these results may indicate the454prospects of using faceted entailment for completeentailment recognition, suggesting it as an attrac-tive research direction.6 Conclusion and Future WorkIn this paper, we presented an empirical attemptto tackle the problem of partial textual entail-ment.
We demonstrated that existing methods forrecognizing (complete) textual entailment can besuccessfully adapted to this setting.
Our experi-ments showed that boolean combinations of thesemethods yield good results.
Future research mayadd additional features and more complex fea-ture combination methods, such as weighted sumstuned by machine learning.
Furthermore, ourwork focused on a specific decomposition model?
faceted entailment.
Other flavors of partial en-tailment should be investigated as well.
Finally,we examined the possibility of utilizing partial en-tailment for recognizing complete entailment in asemi-automatic setting, which relied on the man-ual facet annotation in the RTE-8 dataset.
Ourpreliminary results suggest that this approach isindeed feasible, and warrant further research onfacet-based entailment methods that rely on fully-automatic facet extraction.AcknowledgementsThis work has been supported by the Volk-swagen Foundation as part of the Lichtenberg-Professorship Program under grant No.
I/82806,and by the European Community?s SeventhFramework Programme (FP7/2007-2013) undergrant agreement no.
287923 (EXCITEMENT).We would like to thank the Minerva Foundationfor facilitating this cooperation with a short termresearch grant.ReferencesEneko Agirre, Daniel Cer, Mona Diab, and AitorGonzalez-Agirre.
2012.
SemEval-2012 Task 6:A pilot on semantic textual similarity.
In Proceed-ings of the 6th International Workshop on SemanticEvaluation, in conjunction with the 1st Joint Con-ference on Lexical and Computational Semantics,pages 385?393, Montreal, Canada.Luisa Bentivogli, Peter Clark, Ido Dagan, Hoa Dang,and Danilo Giampiccolo.
2011.
The seventh pascalrecognizing textual entailment challenge.
Proceed-ings of TAC.Peter Clark and Phil Harrison.
2010.
Blue-lite: aknowledge-based lexical entailment system for rte6.Proc.
of TAC.Ido Dagan, Bill Dolan, Bernardo Magnini, and DanRoth.
2009.
Recognizing textual entailment: Ratio-nale, evaluation and approaches.
Natural LanguageEngineering, 15(4):i?xvii.Myroslava O Dzikovska, Rodney D Nielsen, and ChrisBrew.
2012.
Towards effective tutorial feedbackfor explanation questions: A dataset and baselines.In Proceedings of the 2012 Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics: Human Language Technologies,pages 200?210.
Association for Computational Lin-guistics.Myroslava O. Dzikovska, Rodney Nielsen, Chris Brew,Claudia Leacock, Danilo Giampiccolo, Luisa Ben-tivogli, Peter Clark, Ido Dagan, and Hoa TrangDang.
2013.
Semeval-2013 task 7: The joint stu-dent response analysis and 8th recognizing textualentailment challenge.
In *SEM 2013: The FirstJoint Conference on Lexical and Computational Se-mantics, Atlanta, Georgia, USA, 13-14 June.
Asso-ciation for Computational Linguistics.Christiane Fellbaum, editor.
1998.
WordNet: An Elec-tronic Lexical Database.
MIT Press, Cambridge,MA.Rodney D Nielsen, Wayne Ward, and James H Mar-tin.
2009.
Recognizing entailment in intelligenttutoring systems.
Natural Language Engineering,15(4):479?501.Philip Resnik.
1995.
Using information content toevaluate semantic similarity in a taxonomy.
In Pro-ceedings of the 14th International Joint Conferenceon Artificial Intelligence (IJCAI 1995), pages 448?453.Eyal Shnarch, Jacob Goldberger, and Ido Dagan.
2011.A probabilistic modeling framework for lexical en-tailment.
In Proceedings of the 49th Annual Meet-ing of the Association for Computational Linguis-tics: Human Language Technologies, pages 558?563, Portland, Oregon, USA, June.
Association forComputational Linguistics.Asher Stern and Ido Dagan.
2011.
A confidencemodel for syntactically-motivated entailment proofs.In Proceedings of the 8th International Conferenceon Recent Advances in Natural Language Process-ing (RANLP 2011), pages 455?462.Asher Stern and Ido Dagan.
2012.
Biutee: A mod-ular open-source system for recognizing textual en-tailment.
In Proceedings of the ACL 2012 SystemDemonstrations, pages 73?78, Jeju Island, Korea,July.
Association for Computational Linguistics.455
