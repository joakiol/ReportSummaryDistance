SIMULATING CHILDREN'S NULL SUBJECTS:AN EARLY LANGUAGE GENERATION MODELCaro le  T. BosterDepar tment  of  L inguist ics,  Box U-145Un ivers i ty  of  Connect icutStorrs,  CT 06269-1145, USAtenny@uconnvm.uconn.eduAbstractThis paper eports work in progress on a sentencegeneration model which attempts to emulate certainlanguage output patterns of children between theages of one and one-half and three years.
Inparticular, the model addresses the issue of whymissing or phonetically "null" subjects appear asoften as they do in the speech of young English-speaking children.
It will also be used to examinewhy other patterns of output appear in the speech ofchildren learning languages uch as Italian andChinese.
Initial findings are that an outputgenerator successfully approximates the null-subjectoutput patterns found in English-speaking childrenby using a 'processing overload' metric alone;however, eference to several parameters elated todiscourse orientation and agreement morphology isnecessary in order to account for the differingpatterns of null arguments appearing cross-linguistically.
Based on these findings, it is arguedthat the 'null-subject phenomenon" is due to thecombined effects of limited processing capacity andearly, accurate parameter setting.1 ~ PROBLEMIt is well known among researchers in languageacquisition that young children just beginning tospeak English frequently omit subjects, in linguisticcontexts where subjects are considered mandatory inthe adult language.
Other major structuralcomponents such as verbs and direct objects are alsoomitted occasionally; however, the frequency atwhich children omit mandatory object NPs tends tobe much lower than the rate at which they omitsubjects.
For example, P. Bloom's (1990) analysis ofearly speech transcripts of Adam, Eve and Sarah(Brown, 1973) from the CHILDES database(MacWhinney and Snow, 1985), indicates that thesechildren omitted subjects from obligatory contexts55% of the time on average, whereas obligatoryobjects were dropped at rates averaging only 9%.But by around age 2 1/2, or when the mean lengthof utterance (MLU) exceeds approximately 2.0morphemes, the percentage of null subjects drops offto a level about equal to the level of null objects.The reason for the so-called null-subjectphenomenon in early child English has been widelydebated in the literature.
Different theories, thoughthey vary greatly in detail, generally fall into twobroad categories: processing accounts andparameter-setting accounts.
The general claim ofthose who favor a processing account is that thephenomenon (in English) is caused by severelimitations in the child's sentence-processing ormemory capacity.
It is known that young children'sutterances are much shorter on average thanadults', that their sentence l ngth increases steadilywith age, and that other components ofa sentenceare also routinely omitted, which could be evidenceof processing limitations.
Yet some who argue for astrictly grammatical explanation (including Hyams(1986), Hyams and Wex\]er (1993)) claim that thedifferential patterns of null subjects over null objectscannot be accounted for by any existing processingaccount, and instead take this as evidence that the'unmarked' setting for the relevant parameter(s)related to null subjects is (+pro-drop); variousaccounts are offered for how children learninglanguages that do not permit null subjectsultimately make the switch to the correct parameterValue.Others, including Valian (1991) and Rizzi (1994)have noted differences in the frequency of early nullsubjects depending on their position in a sentence;they tend to be omitted in matrix but not embeddedclauses, and in sentence-initial position but not aftera moved wh-element.
This observation has beenused to argue for a different grammaticalexplanation of the null-subject stage.
BothLillo-Martin (1991) and Rizzi (1994), for example,argue that the initial value of the parameters is setto (- pro-drop); Lillo-Martin claims that the matrixsubject is outside the domain where the pro-dropparameters are applied initially, while Rizzi claimsthat the matrix CP is considered optional at an earlystage in acquisition.
Further evidence which maysupport either this approach or a 'combined'processing and parameters account includes thehigher percentages and different patterns of pro-drop and topic-drop found in the speech of childrenlearning Italian, a pro-drop language (Valian, 1991)and Chinese, which allows 'topic-drop' (Wang et.
al.,3221992), as compared to English-speaking children ofthe same age and MLU.
Processing constraintsshould remain the same for children around theglobe, so it is not clear that processing alone canaccount for the different distributions of nullsexhibited by 2-year olds learning English, Italian,and Chinese.
However, the crosslinguisticdifferences also argue against the claim that allchildren start out with the relevant parameter(s)initially set to (+pro-drop).2 THE MODELFELICITY, a sentence generation model thatemulates early child language output, has beendesigned in order to determine whether the 'null-subject' phenomenon i  early child language canbest be accounted for by an incorrect initial settingof certain parameters, by processing limitations, orby an interaction between parameter setting andprocessing.
FELICITY assumes a modularapproach, following Garrett (1975), in which theintended message goes through three processingmodules to yield three levels of output: semantic,then syntactic, then phonetic.
The modelincorporates several standard assumptions ofPrinciples-and-Parameters theory including X'structure-building capacity (Chomsky, 1981), head-complement ordering parameters, and severalparameters currently thought o be relevant o thenull-subject phenomenon.
Following the ContinuityHypothesis (Pinker, 1984), the model has thepotential capacity for producing a full clausalstructure from the beginning; the structure-buildingmechanism is presumed to be innate.
It is alsoassumed, following the VP-internal SubjectHypothesis (Koopman and Spertiche (1988) andothers) that the subject is initially generated withinthe VP.
An algorithm controlling processingcapacity, similar in principle to that proposed byGibson (1991) to account for processing overloadeffects in adult sentence processing, will limitstructure-building and dictate maximum "holding'capacity before a sentence is output.
The lexiconwill initially include all words used productively intranscripts of an English-speaking child at age 1;7;lexical entries will include information aboutcategory, pronunciation, obligatory and optionalcomplements, and selectional restrictions on thosecomplements.
All parameters will be binary.
Theycan be assigned either value initially and can bereset; reference to any given parameter can also beswitched on or off.
The processing capacity of themodel can also be adjusted, and the lexicon can beupdated.The model will be able to produce a sentencewith a specific meaning or intent (as childrenpresumably do), if it is given certain data about heintended proposition; this data will comprise asemantic representation containing a verb, its theta-grid (i.e.
agent, experiencer, goal and/or theme),information about time frame or tense, person andnumber, mood, negation, and whether or notarguments have been identified previously in thediscourse.
When making direct comparisons of themodel's performance with children's actualutterances, the data that is input to the model willbe coded on the basis of inferences about what thechild 'intended' to say based not only on actualtranscribed output but also from the situation, priordiscourse, and possibly caregiver's report (cf.
L.Bloom (1970) on 'rich interpretation' of children'sutterances).Syntactic processing proceeds as follows: Beginstructure-building at the level of the matrix CP, butvia a recursive phrase-building process.
Phrase-building begins by merging a complement phrasewith its X ?
head (after the complement phrase hasbeen built) to form an intermediate or X' level ofstructure.
This unit is then combined with itsspecifier to form a 'maximal' phrase or XP.
Lexicalitems are inserted as soon as the appropriate X ?heads (or XPs, for pro-forms) become available.Each time a structural unit is built, and each timea lexical entry is inserted, the processing load isincremented; when the max imum load is exceeded,the model abandons processing and outputs thewords currently in the buffer.$ INITIAL APPLICATIONFELICITY's output will be compared to actualoutput from a longitudinal sample of severalEnglish-speaking children's early utterances, usingtranscripts available on the CHILDES database.The initial lexicon will be constructed based on theproductive vocabulary of a given child from her firsttranscript.
The 'processing limit' will be set at agiven maximum, such that the model's MLUapproximates that of the child in the transcript; healgorithm will be fine-tuned to determine how muchrelative weight or processing 'cost' should beassigned to (a) lexical lookup to getsubcategorization i formation for the verb; (b)building of a structural unit; and (c) retrieval ofphonological information.
The sentence-generationprocedures will be run under two conditions, oncewith parameter-checking enabled and then withparameter-checking disabled.
Additional runs willtry to emulate the child's output patterns duringsubsequent transcripts, after augmenting themodel's lexicon with new words found in the child'svocabulary and adjusting the processing limitupward so that the output matches the child's newMLU.
Statistical comparisons will be made betweenthe model's and the children's performance (at323comparable MLU levels) including percentages ofnull subjects and null objects in the output,percentages of overt nominalsubjects (full NPs) vs.overt pronominal subjects, percentages of othersentence components omitted, and amount ofvariability in utterance l ngths.4 PRELIMINARY F INDINGSInitial trials indicate that, once the processing-complexity algorithm is tuned appropriately,FELICITY can approximate he null~subject outputpatterns found in English-speaking children with noreference to parameter values.
Indeed, because themodel builds complements before specifiers, itproduces a much higher incidence of null subjectsthan null objects using a proceseing-overload metricalone.
Furthermore, it yields a higher incidence ofnulls in matrix sentences than in embedded clauses,and within a clause it only omits subjects in initialposition, not after a moved wh-element or topic.However, it appears that the model will also need toreference parameter values if it is to account for thepatterns observed in the speech of children learninglanguages which d_oo allow null arguments;processing constraints alone will not explain thedifferent croselin~mistic distributions ofnulls.5 FUTURE APPLICATIONSOnce FELICITY's processing metric is fine-tuned forEnglish, it can be used to emulate argumentomission patterns hown in other languages likeItalian and Chinese, to test various parametrictheories.
If the relevant parameters involved are asgiven in Lillo-Martin (1991), for example, FELICITYshould be able to emulate the relatively high level ofnull-subject usage by Italian-speaking childrenreported in Valian (1991) by simply switchingcertain subparameters related to Null PronounLicensing (NPL) and Null Pronoun Identification(NTI) to positive for an Italian child at age 2, whilekeeping processing constraints at the same levelsthat were established for English-speaking children.The model should also be able to emulate the higherpercentages of null subjects and null objects found inthe output of Chinese-speaking children inexperiments reported in Wang et.
al.
(1992) bysimply switching the Discourse Oriented (DO)parameter to positive, while leaving the NPL andNPI parameters set at the default (negative) values.FELICITY can also be used to address theoriespertaining to other aspects of language acquisitionthat appear slightly later in development, such asthe appearance of subject-auxiliary inversion inyes/no and wh-questions, and the emergence ofTense and Agreement features.
Futureenhancements to the model are planned with theseapplications in mind.ACKNOWLEDGMENTSThis material is based upon work supported undera National Science Foundation Graduate ResearchFellowship.
Thanks go to my committee membersDiane Lillo-Martin, Stephen Crain, Ted Gibson andHoward Lasnik, and to two anonymous reviewers forhelpful comments on an earlier draft.REFERENCESBloom, L. (1970).
Language development: Form andfunction in emerging rammars.
Cambridge,Mass.
: MIT Press,Bloom, P. (1990).
Subjectless entences in childlanguage.
Linguistic Inauiry, ~ 491-504.Brown, R. (1973).
Afirst language: The early stages.Cambridge, Mass.
: Harvard University Press.Chomsky, N. (1981).
Lectures on government andbinding.
Dordrecht: Foris.Garrett, M. F. (1975).
The analysis of sentenceproduction.
In G. Bower (Ed.
), P .sychology oflearning and motivation (Vol.
9).
New York:Academic Press.Gibson, E. A. F. (1991).
A computational theory ofhuman linguistic processing: Memorylimitations and processing breakdown \[Doctoraldissertation\].
Pittsburgh: Carnegie MellonUniversity.Hyams, N. M. (1986).
Language acquisition and thetheory of parameters.
Dordrecht: D. ReidelPublishing Company.Hyams, N., & Wex\]er, K. (1993).
On thegrammatical basis of null subjects in childlanguage.
Linguistic InQuiry, 24, 421-459.Koopman, H., & Sportiche, D. (1988).
Subjects \[Ms.\].Los Angeles: UCLA.Lillo-Martin, D. C. (1991).
Universal Grammar andAmerican Sign Language: Setting the NullArgument Parameters.
Dordrecht: KluwerAcademic Publishers.MacWhinney, B., & Snow, C. (1985).
The ChildLanguage Data Exchange System.
Journal ofChild Language, 12, 271-296.Pinker, S. (1984).
Language learnability andlanguage development.
Cambridge, Mass.
:Harvard University Press.Rizzi, L. (1994).
Early null subjects and root nullsubjects.
In T. Hoekstra & B. D. Schwartz?
(Eds.
), Language acquisition studies ingenerat ive grammar (pp.
151-176).Amsterdam/Philadelphia: John Benjamins.Valian, V. (1991).
Syntactic subjects in the earlyspeech of American and Italian children.Cognition, ~ 21-81.Wang, Q., Lillo-Martin, D., Best, C. T., & Levitt, A.(1992).
Null subject versus null object: Someevidence from the acquisition of Chinese andEnglish.
Language Acquisition, ~ 221-254.324
