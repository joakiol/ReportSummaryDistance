Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1374?1384,October 25-29, 2014, Doha, Qatar.c?2014 Association for Computational LinguisticsFormalizing Word Sampling for Vocabulary Predictionas Graph-based Active LearningYo Ehara?National Institute ofInformation and CommunicationsTechnologyehara@nict.go.jpYusuke MiyaoNational Institute ofInformaticsyusuke@nii.ac.jpHidekazu OiwaIssei SatoHiroshi NakagawaThe University of Tokyo{oiwa,sato}@r.dl.itc.u-tokyo.ac.jpnakagawa@dl.itc.u-tokyo.ac.jpAbstractPredicting vocabulary of second languagelearners is essential to support their lan-guage learning; however, because of thelarge size of language vocabularies, wecannot collect information on the entirevocabulary.
For practical measurements,we need to sample a small portion ofwords from the entire vocabulary and pre-dict the rest of the words.
In this study, wepropose a novel framework for this sam-pling method.
Current methods rely onsimple heuristic techniques involving in-flexible manual tuning by educational ex-perts.
We formalize these heuristic tech-niques as a graph-based non-interactiveactive learning method as applied to a spe-cial graph.
We show that by extending thegraph, we can support additional function-ality such as incorporating domain speci-ficity and sampling from multiple corpora.In our experiments, we show that our ex-tended methods outperform other methodsin terms of vocabulary prediction accuracywhen the number of samples is small.1 IntroductionPredicting the vocabulary of second languagelearners is essential to support them when they arereading.
Educational experts have been continu-ously studying methods for measuring the size ofa learner?s vocabulary, i.e., the number of words?The main body of this work was done when the firstauthor was a Ph.D. candidate in the University of Tokyo andthe paper was later greatly revised when the first author wasa JSPS (Japan Society for the Promotion of Science) researchfellow (PD) at National Institute of Informatics.
See http://yoehara.com/ for details.the learner knows, over the decades (Meara andBuxton, 1987; Laufer and Nation, 1999).
Eharaet al.
(2012) formalized a more fine-grained mea-surement task called vocabulary prediction.
Thegoal of this task is to predict whether a learnerknows a given word based on only a relativelysmall portion of his/her vocabulary.
This vocabu-lary prediction task can be further used for predict-ing the readability of texts.
By predicting vocab-ulary unknown to readers and showing the mean-ing of those specific words to readers, Ehara et al.
(2013) showed that the number of documents thatlearners can read increases.Word sampling is essential for vocabulary pre-diction.
Because of the large size of language vo-cabularies, we usually cannot collect informationon the entire vocabulary.
For practical measure-ments, we inevitably need to sample a small por-tion of words from the entire vocabulary and thenpredict the rest.
We refer to this sampling tech-nique as word sampling.Word sampling can greatly affect the perfor-mance of vocabulary prediction.
For example, ifwe consider only short everyday general domainwords such as ?cat?
and ?dog?
as samples, the restof the vocabulary is difficult to predict since learn-ers likely know most of these words.
To more ac-curately measure a learner?s vocabulary, we ide-ally must sample words that are representative ofthe entire set of words.
More specifically, we wishto sample words such that if a learner knows thesewords, he/she is likely to know the rest of thewords in the given vocabulary, and vice versa.To our knowledge, however, all current studieshave relied on a simple heuristic method.
In thisheuristic method, educational experts first some-how create groups of words with the aim that thewords in a group are of similar difficulty for learn-1374ers.
To create groups of words, the experts typi-cally make use of word frequencies and sometimesmanually reclassify words based on experience.Next, a fixed number of words are randomly sam-pled from each group via a uniform distribution.We call this approach heuristic word sampling.In this study, we propose a novel frameworkthat formalizes word sampling as non-interactivegraph-based active learning based on weightedgraphs.
In our approach, nodes of a graph corre-spond to words, whereas the edge weights showhow similar the difficulty levels of a word pairare.
Unlike interactive active learning algorithmsused in the NLP community, which use expert an-notators?
human labels for sampling nodes, non-interactive active learning algorithms exclude ex-pert annotators?
human labels from the protocol(Ji and Han, 2012; Gu and Han, 2012).
Givena weighted graph and using only its structure,without human labels, these algorithms samplenodes that are important for classification with al-gorithms called label propagation.
Excluding an-notators?
human labels from the protocol is bene-ficial for educational purposes since learners canshare the same set of sampled words via, for ex-ample, printed handouts.Formalizing the current methods as non-interactive graph-based active learning enables usto extend the sampling methods with additionalfunctionality that current methods cannot han-dle without applying burdensome manual heuris-tics because we can flexibly design the weightedgraphs fed to the active learning algorithms.
In ourframework, this extension is achieved by extend-ing the graph, namely, our framework can handledomain specificity and multiple corpora.Domains are important when one wants to mea-sure the vocabulary of learners.
For example, con-sider measuring non-native English speakers tak-ing computer science graduate courses.
We maywant to measure their English vocabulary with anemphasis on computer science rather than theirgeneral English vocabulary.
However, such anextension is impossible via current methods, andthus it is desirable to sample algorithms to be ableto handle domain specificity.
Our framework canincorporate domain specificity between words inthe form of edges between such words.Handling multiple corpora is important whenwe cannot single out which corpus we should relyon.
The current technique used by educationalexperts to handle multiple corpora is to heuristi-cally integrate multiple frequency lists from mul-tiple corpora into a single list of words; however,such manual integration is burdensome.
Thus, au-tomatic integration is desirable.
Our frameworkconverts multiple corpora into graphs, mergesthese graphs together, and then samples from themerged graph.Our contributions as presented in this paper aresummarized as follows:1.
We formalize word sampling for vocabularyprediction as graph-based active learning.2.
Based on this formalization, we can performmore flexible word sampling that can handledomain specificity and multiple corpora.The remaining parts of this paper are orga-nized as follows.
In ?2, we explain the problemsetting in detail.
We first explain how existingheuristic word sampling works and how it relieson the cluster assumption from the viewpoint ofgraphs.
Then, we introduce existing graph-basednon-interactive active learning methods.
In ?3,we show that the existing heuristic word samplingis merely a special case of a non-interactive ac-tive learning method (Gu and Han, 2012).
Pre-cisely, the existing sampling is identical to the casewhere a special graph called a ?multi-completegraph?
is fed to a non-interactive active learningmethod.
Since this method can take any weightedgraphs other than this special graph, this imme-diately leads to a way of devising new samplingmethods by modifying graphs.
?4 explains exactlyhow we can modify graphs for improving activelearning.
?5 evaluates the proposed method bothquantitatively and qualitatively, and ?6 concludesour paper.2 Problem Setting2.1 Heuristic Word SamplingA simple vocabulary estimation technique intro-duced by educational experts is to use the fre-quency rank of words in a corpus based on theassumption that learners using words with similarfrequency ranks have a similar vocabulary (Lauferand Nation, 1999).
In accordance with this as-sumption, they first group words by frequencyranks in a corpus and then assume that words ineach group have a similar vocabulary status.
Forexample, they sampled words as follows:13751.
Rank words by frequency in a corpus.2.
Group words with frequency ranks from 1 to1, 000 as Level 1000, words with frequencyranks from 1, 001 to 2, 000 as Level 2000,and so on.3.
Take 18 samples from Level 1000, another 18samples from Level 2000, and so on.The rationale behind this method is to treathigh-ranked and low-ranked words separatelyrather than sample words from the entire vocabu-lary.
After sampling words, this sampling methodcan be used for various measurements; for exam-ple, Laufer and Nation (1999) used this methodto estimate the size of the learners?
vocabularyby simply adding 1, 000 ?Correctly answered words18foreach level.2.2 Cluster AssumptionIn the previous subsection, we noted that existingword sampling methods rely on the assumptionthat words with similar frequency ranks are knownto learners whose familiar words are similar eachother.
This assumption is known as the cluster as-sumption in the field of graph studies (Zhou et al.,2004).To further describe the cluster assumption, wefirst define graphs.
A graph G = (V, E) consistsof a set of nodes (vertices) V and a set of edges E .Here, each node has a label, and each edge has aweight.
A label denotes the category of its corre-sponding node.
For example, in binary classifica-tion, a label is taken from {+1,?1}.
A weight isa real value; when the weight of an edge is large,we describe the edge as being heavy.The cluster assumption is an assumption thatheavily connected nodes in a graph should havesimilar labels.
In other words, the cluster as-sumption states that weights of edges and labelsof nodes should be consistent.We explain how the cluster assumption relatesto our task.
In our application, each node corre-sponds to a word.
Labels of the nodes in a graphdenote the vocabulary of a learner.
If he/she knowsa word, the label of the node corresponding to theword is +1; if not, the label is ?1.
The clusterassumption in our application is that the heavierthe edge, the higher the similarity between usersfamiliar with the two words.In this manner, existing word sampling meth-ods implicitly assume cluster assumption.
Thisis therefore the underlying approach for reducingthe word sampling problem into graph-based ac-tive learning.
Since graphs allow for more flexiblemodeling by changing the weights of edges, weexpect that more flexible word sampling will beenabled by graph-based active learning.2.3 Label PropagationSince the graph-based active learning algorithmsare based on label propagation algorithms, we willexplain them first.
Basically, given a weightedgraph, label propagation algorithms classify theirnodes in a weakly supervised manner.
While thegraph-based active learning algorithm that we aretrying to use (Gu and Han, 2012) does not use la-bel propagation algorithms?
outputs directly, it istuned to be used with a state-of-the-art label prop-agation method called Learning with Local andGlobal Consistency (LLGC) (Zhou et al., 2004).Label propagation algorithms predict the labelsof nodes from a few manually supervised labelsand graph weights.
To this end, label propaga-tion algorithms follow the following steps.
First,humans label a small subset of the nodes in thegraph.
This subset of nodes is called the set of la-beled nodes, and the remaining nodes are calledunlabeled nodes.
Second, label propagation al-gorithms propagate labels to the unlabeled nodesbased on edge weights.
The rationale behind la-bel propagation algorithms lies in cluster assump-tion; as label propagation algorithms assume thattwo nodes connected by a heavily weighted edgeshould have similar labels, more heavily weightededges should propagate more labels.We formalize Learning with Local and GlobalConsistency (LLGC) (Zhou et al., 2004), oneof the state-of-the-art label propagation methods.Here, for simplicity, suppose that we want to per-form binary classification of nodes.
Let N be thetotal number of nodes in a graph.
Then, we de-note labels of each node by ydef= (y1, .
.
.
, yN)>.For unlabeled nodes, yiis set to 0.
For labelednodes, yiis set to +1 if the learner knows a word,?1 if not.
We also introduce a label propagation(LP) score vector f = (f1, .
.
.
, fN)>.
This LPscore vector is the output of label propagation andis real-valued.
To obtain the classification resultfrom this real-valued LP score vector for an un-labeled node (word) i, the learner is predicted toknow the word i if fi> 0, and he/she is predictedto be unfamiliar with the word if fi?
0.1376Next, we formally define a normalized graph-Laplacian matrix, which is used for penalizationbased on the cluster assumption.
Let an N ?
N-sized square matrix W be a weighted adjacencymatrix of G. W is symmetric and non-negativedefinite; its diagonal elements Wi,i= 0 andall other elements are non-negative1.
The graphLaplacian of a normalized graph, known as a nor-malized graph Laplacian matrix, is defined asLnormWdef= I?D?12WWD?12W.
Here, DWis definedas a diagonal matrix whose diagonal element is(DW)i,idef=?|V|j=1Wi,j, and I denotes the iden-tity matrix of the appropriate size.
Note that anormalized graph Laplacian LnormWdepends on theweighted adjacency matrix W.Then, LLGC can be formalized as a simple op-timization problem as shown in Equation 1.minf?f ?
y?22+ ?f>LnormWf (1)Equation 1 consists of two terms.
Intuitively,the first term tries to make the LP score vector, thefinal output f , as close as possible to the given la-bels y.
The second term is designed to meet thecluster assumption: it penalizes the case wheretwo nodes with heavy edges have very differentLP scores.
?
> 0 is the only hyper-parameter ofLLGC: it determines how strong the penalizationbased on the cluster assumption should be.
Thus,in total, Equation 1 outputs an LP score vector fconsidering both the labeled input y and the clus-ter assumption of the given graph W: the heav-ier an edge, the closer the scores of the two nodesconnected by the edge becomes.2.4 Graph-based active learning algorithmsAn important categorization of graph-based activelearning for applications is whether it is interactiveor non-interactive.
Here, interactive approachesuse human labels during the learning process; theypresent a node for humans to label, and based onthis label, the algorithms compute the next node tobe presented to the humans.
Thus, in interactivealgorithms, human labeling and computations ofthe next node must run concurrently.Non-interactive algorithms do not use humanlabels during the learning process.
Given theentire graph, these algorithms sample important1While all elements of a non-negative definite matrix arenot necessarily non-negative, we define all elements of Was non-negative here, following the definition of Zhou et al.
(2004).nodes for label propagation algorithms.
Here, im-portant nodes are the ones that minimize estimatedclassification error of label propagation when thenodes are labeled.
Note that, unlike active learningused in the NLP community, non-interactive activelearning algorithms exclude expert annotators?
hu-man labels from the protocol.
While they excludeexpert annotators, they are still regarded as activelearning methods in the machine learning commu-nity since they try to choose such nodes that arebeneficial for classification (Ji and Han, 2012; Guand Han, 2012).For educational purposes, non-interactive algo-rithms are preferred over interactive algorithms.The main drawback of interactive algorithms isthat they must run concurrently with the hu-man labeling.
For our applications, this meansthat the vocabulary tests for vocabulary predictionmust always be computerized.
In contrast, non-interactive algorithms allow us to have vocabularytests printed in the form of handouts, so we focuson non-interactive algorithms throughout this pa-per.Compared with interactive algorithm studies,such as Zhu et al.
(2003), graph-based non-interactive active learning algorithms have beenintroduced in recent years.
There has been a sem-inal paper on non-interactive algorithms (Ji andHan, 2012).
We used Gu and Han?s algorithm be-cause it reports higher accuracy for many taskswith competitive computation times over Ji andHan?s algorithm (Gu and Han, 2012).These active learning methods share two basicrules although their objective functions are dif-ferent.
First, these methods tend to select glob-ally important nodes, also known as hubs.
A no-table example of global importance is the num-ber of edges.
Second, these methods tend toavoid sampling nodes that are heavily connectedto previously sampled nodes.
This is due to clus-ter assumption, the assumption that similar nodesshould have similar labels, which suggests that it isredundant to select nodes close to previously sam-pled nodes; the labels of such nodes should be reli-ably predicted from the previously sampled nodes.Gu and Han?s algorithm, which is the algorithmwe used, also follows these rules.
In this algo-rithm, when considering the k-th sample, for everynode i in the current set of not-yet-chosen nodes, ascore score(k, i) is calculated, and the node withthe highest score is chosen.
First, the score is de-1377signed to be large if the i-th node is globally im-portant.
In the algorithm, the global importanceof a node is measured by an eigenvalue decompo-sition of the normalized graph-Laplacian, Lnorm.Transformed from the graph?s adjacency matrix,this matrix stores the graph?s global information.Second, the score is designed to be smaller if thei-th node is close to one of the previously samplednodes.Score score (k, i) is defined as follows.
Weperform eigenvalue decomposition beforehand.LnormW= U?U>, uiis the transpose of the i-throw of U, and ?iis its corresponding eigenvalue.score (k, i)def=(H?1kui)>?
?1(H?1kui)1 + u>iH?1kui(2)In Equation 2, Hkpreserves information of theprevious k ?
1 samples.
First, H0is a diag-onal matrix whose i-th diagonal element is de-fined as1(?
?i+1)2?1where ?
is a hyper-parameter.H0weighs the score of globally important nodesthrough the eigenvalue decomposition.
Second,Hkis updated such that the scores of the nodesdistant from the previously taken samples arehigher.
The precise update formula of Hkfollows.ik+1is the index of the node sampled at k + 1-thround.
For the derivation of this formula, see Guand Han (2012).H?1k+1= H?1k?
(H?1kuik+1) (H?1kuik+1)>1 + u>ik+1H?1kuik+1(3)Hyper-parameter ?
determines how strong thecluster assumption should be; the larger the value,the more strongly the algorithm avoids selectingnodes near previously selected samples over thegraph.
Note that ?
is inherited from the LLGC2algorithm (Zhou et al., 2004), i.e., the label prop-agation algorithm that Gu and Han?s algorithm isbased on.
From the optimization viewpoint, ?
de-termines the degree of penalization.Remember that the score has nothing to do withthe LP scores described in ?2.3.
score is usedto choose nodes used for training in the graph-based non-interactive active learning.
LP scoresare later used for classification by label propaga-tion algorithms that use the chosen training nodes.Throughout this paper, when we mean LP scores,we explicitly write ?LP scores?.
All the otherscores mean score.2Learning with Local and Global Consistency.Figure 1: Converting frequency list into multiple-complete graph.3 Formalizing heuristic word samplingas graph-based active learningFigure 1 shows how to formalize a word frequencylist into a multiple complete graph.
The word fre-quency list is split into clusters, and each clusterforms a complete graph.
Each node in a graph cor-responds to a word.
By gathering all the completegraphs, a multiple complete graph can be formed.Multiple complete graph GT,nis defined as agraph of T complete graphs, each of which con-sists of n nodes fully connected within the nnodes.
An example of a multiple complete graphcan be seen in Figure 2.
We can define theTn ?
Tn adjacency matrix for multiple com-plete graphs.
Wcompleteallis defined as follows:Wcompletealldef=?????
?Wcomplete0 ?
?
?
00..................00 ?
?
?
0 Wcomplete??????(4)Wcompletedef=???????
?0 1 ?
?
?
1 11 0 1 ?
?
?
1... 1......1......11 1 ?
?
?
1 0????????
(5)We can see that Wcompleteallis a block-diagonalmatrix where each block is a n ?
n matrix,Wcomplete.Heuristic word sampling can be rewritten intonon-interactive active learning on graphs.
Supposethere are T groups, each of which has n words,and we want to sample n0words from each.
In1378Figure 2: Example of multi-complete graph, where Theorem 3.1 holds true.
Here, T = 4, n = 5, andk = 10; 10 light blue (light) nodes have already been sampled, and 10 blue (dark) nodes remain; the11-th node is sampled uniformly randomly from the nodes within the red rectangles.heuristic word sampling, for each group from Tgroups, n0words are sampled from the n wordsin the group uniformly randomly.
Thus, there areTn0words in total.Since heuristic word sampling takes a nodefrom each of the T groups, T concurrent samplingprocesses are involved.
For simplicity, we furtherexpress the same sampling using only one sam-pling process from the entire graph as follows:?
For every round, we sample words uniformlyrandomly from the remaining words of thegroups where the number of samples selectedin previous rounds is least.Figure 2 shows an example of this samplingprocess.
Here, the second and third groups fromthe left are the groups in which the number of pre-viously selected nodes is the least.
This is becausethey have only two previously selected nodes,while the others have three.
Thus, in the figure, theremaining words of the groups are the nodes withred rectangles.
Randomly sampling one node fromthe nodes with red rectangles means sampling anode from the second or third group.
We call theset of nodes in a graph from which samples will betaken in the next round a seed pool.
Thus, in Fig-ure 2, the set of nodes with red rectangles is theseed pool.
Nodes that have already been sampledare taken out of the current seed pool.Next, we more formally explain the seed poolconcept.
We start sampling nodes from a multiplecomplete graph via the algorithm presented by Guand Han.
The initial seed pool is set to all nodesin the graph, i.e., V .
We sample one node in eachround; thus, k ?
|V| nodes are selected by the k-th round.
Let t ?
T be the index of the completegraph in the multiple complete graph.
Then, thefollowing theorem holds with  being a small pos-itive value that substitutes the 0 eigenvalues in theeigen decomposition.Theorem 3.1 Let 0 <  < 1 and n ?
{2, 3, 4, .
.
.}.
Then, among T complete graphs,k mod T complete graphs have bkTc + 1 sam-ples, and the remaining graphs have bkTc sam-ples3.
Moreover, the (k + 1)-th sample is takenuniformly randomly from the remaining completegraphs.In Theorem 3.1,  > 0 is a substitute for the0 eigenvalue of LW4.
Since  is a substitute forthe 0 eigenvalue, it is rational to assume 1 > .Also, remember that n is the number of nodes inone complete graph.
The algorithm stops whenk = Tn0+ 1, i.e., at the Tn0+ 1-th round whenthere are no remaining nodes to sample.
Figure 2shows an example of Theorem 3.1.A proof of this theorem is presented in the sup-plementary material.
Briefly, in a multiple com-plete graph, the score of a node depends only onthe complete graph or the cluster that the nodebelongs to.
Thus, we only have to consider onecomplete graph in which k is the number of nodesthat have been already chosen.
Then, mathe-matical induction proves that, within one com-plete graph, all the not-yet-chosen nodes have thesame score(k, i).
Second, we have to show thatthe score always decreases by taking a sample,i.e., score(k, i) > score(k + 1, i).
By a longbut straightforward calculation, we can expressscore(k, i) by using only ?, , n, and k. Then, bysubstituting the formula to score(k, i), we obtainscore(k, i)?
score(k + 1, i) > 0.4 Extending GraphsIn the previous section, we explained how to for-malize heuristic word sampling as active learn-ing on multiple complete graphs.
This formaliza-3Here, both k and T are non-negative integers.
Thus,k%T denotes the remainder of the division of k by T , andbkTc is the quotient of the division.4In Gu and Han?s algorithm, they substitute the 0 eigen-value with a small positive value , and they set  = 10?6.1379Figure 3: Example of merging two graphs.tion can lead to better active learning by extend-ing these graphs.
In this section, we describe suchgraph extensions.We extend graphs by merging graphs.
Figure 3shows how to merge graphs.
We define ?merging?two weighted graphs as creating a weighted graphwhose adjacency matrix is the sum of the two ad-jacency matrices of the two weighted graphs.
Thissuggests that an edge of the merged graph is sim-ply the sum of the corresponding edges of the twoweighted graphs.The merged graph is expected to inherit thecharacteristics of its original graphs.
Thus, ap-plying graph-based active learning to the mergedgraph is expected to sample nodes in accordancewith the characteristics of its original graphs.For example, if we merge a graph representingdomain-specific relations and a multiple completegraph representing difficulty grouping of words,active learning from the resulting merged graphis expected to sample words considering both do-main specificity and difficulty grouping of words.For another example, suppose we merge twomultiple complete graphs created from frequencylists from two different corpora.
Then, activelearning from the resulting merged graph is ex-pected to sample words taking into account fre-quency lists from both corpora.5 EvaluationWe evaluate our proposed method both quantita-tively and qualitatively.
In the quantitative eval-uation, we measure the prediction accuracy ofgraphs.
Note that the heuristic word samplingmethod is identical to using Gu and Han?s algo-rithm with a multiple complete graph; however,our proposed graphs have enriched relations be-tween words.
In the qualitative evaluation, we ex-plain in detail what words are appropriate as train-ing examples for vocabulary prediction by pre-senting sampled examples.5.1 Quantitative evaluationTo evaluate the accuracy of vocabulary prediction,we used the dataset that Ehara et al.
(2010) andEhara et al.
(2012) used.
This dataset was gleanedfrom questionnaires answered by 15 English as asecond language (ESL) learners.
Every learnerwas asked to answer how well he/she knew 11,999English words.
The data was collected in January2009.
One learner was unpaid, whereas the other15 learners were paid.
We used the data from the15 paid learners since the data from the unpaidlearner was noisy.
Most of the learners were na-tive Japanese speakers and graduate students.
Be-cause most of the learners in this dataset were na-tive Japanese speakers, words from SVL 12,000(SPACE ALC Inc., 1998) were used for the learn-ers in this dataset.
Note that SVL 12,000 is a col-lection of 12,000 words that are deemed importantfor Japanese learners of English, as judged by na-tive English teachers.Next, we required frequency lists for the wordsthat appeared in the dataset.
To create frequencylists, lemmatization is important because the num-ber of word types depends on the method usedto lemmatize the words.
Note that in the field ofvocabulary measurement, lemmatization is mainlyperformed by ignoring conjugation (Nation andBeglar, 2007).
Lemmatizing the dataset resultedin a word list of 8,463 words.
We adjusted the sizeof the word list to a round 8,000 by removing 463randomly chosen words.
Note that all constituentwords were labeled by the 15 ESL learners.We created the following four graphs by span-ning edges among the 8, 000 words.BNC multi-complete This graph corresponds toheuristic word sampling and served as ourbaseline.
It is a multiple complete graphcomprising eight complete graphs, each ofwhich consisted of 1,000 words based on thesorted frequency list from the British Na-tional Corpus (BNC).
We chose the BNC be-cause the method presented by Nation andBeglar was based on it (Nation and Beglar,2007).
Note that all edge weights are set to 1.BNC+domain To form this graph, edges rep-resenting domain specificity are added tothe ?BNC multi-complete?
graph.
For do-main specificity, we used domain information1380from WordNet 3.0.5First, we extracted 102domain-specific words under the ?computer?domain among the 8,000 words and createda complete graph consisting of these domain-specific words.
The edge weights of the com-plete graph were set to 1.
Next, we simplymerged6the complete graph consisting of thedomain-specific words with the ?BNC multi-complete?
graph.BNC+COCA In addition to the ?BNC multi-complete?
graph, edges based on another cor-pus, the Corpus of Contemporary AmericanEnglish (COCA), were introduced.
We firstcreated the COCA multi-complete graph, amultiple complete graph consisting of eightcomplete graphs, each of which consisted of1,000 words based on the sorted frequencylist using COCA.
The edge weights of theCOCA multi-complete graph were set to 1.Next, we merged the BNC multi-completeand COCA multi-complete graphs to formthe ?BNC + COCA graph?.BNC+domain+COCA This graph is the graphproduced by merging the ?BNC + domain?and ?BNC + COCA?
graphs.Note that our experiment setting differed fromthe usual label propagation setting used for semi-supervised learning because the purpose of ourtask differed.
In the usual label propagation set-ting, the ?test?
nodes (data) are prepared sepa-rately from the training nodes to determine howaccurately the algorithm can classify forthcomingor unseen nodes.
However, in our setting, therewere no such forthcoming words.
Of course, therewill always be words that do not emerge, even in alarge corpus; however, such rare words are too dif-ficult for language learners to identify, and manyare proper nouns, which are not helpful for mea-suring the vocabulary of second language learners.Therefore, our focus here is to measure howwell the learners know a fixed set of words, thatis, the given 8,000 words.
Even if an algorithmcan achieve high accuracy for words outside thisfixed set, we have no way of evaluating it usingthe pooled annotations.
Here, we want to measure,from a fixed number of samples (e.g., 50), how ac-curately an algorithm can predict a learner?s vo-5We used the NLTK toolkit http://nltk.org/ to extract thedomain information.6Definition of how to merge two graphs is in ?4.Figure 4: Results of our quantitative experiments.Vertical axis denotes accuracy, and horizontal axisshows number of samples, i.e., training words.cabulary for the entire 8,000 words.
Thus, wedefine accuracy to be the number of words thateach algorithm finds correctly divided by the vo-cabulary size.
We set hyper-parameter ?
to 0.01as Gu and Han (2012) did.
Note that this hyper-parameter is reportedly not sensitive to accuracy(Zhou et al., 2011).Figure 4 and Table 1 show the results of theexperiment over the different datasets.
The ver-tical axis in the figure denotes accuracy, whereasthe horizontal axis denotes the number of samples,i.e., training words.
Note that the accuracy is av-eraged over 15 learners and that LLGC is used forclassification unless otherwise specified.
For ex-ample, ?BNC multi-complete?
indicates that sam-ples taken from the BNC multi-complete graph areused for training, and LLGC is used for classifica-tion.
Note that ?BNC + domain + COCA (SVM)?uses a support vector machine (SVM) for classifi-cation, and ?BNC + domain + COCA (LR)?
useslogistic regression (LR) for classification.
Amongmany supervised machine learning methods, wechose SVM and LR because SVM is widely usedin the NLP community, and LR was used for the-oretical reasons (Ehara et al., 2012; Ehara et al.,2013).SVM and LR require features of a wordfor classification while LLGC requires aweighted graph of words.
Since the graph?BNC+domain+COCA?
is made from threefeatures, namely the word frequencies of BNC1381Table 1: Results of our quantitative experiments.
LLGC is used for classification unless otherwise spec-ified.
Bold letters indicate top accuracy.
Asterisks (*) indicate that values are statistically significantagainst baseline, heuristic sampling, i.e., ?BNC multi-complete?
(using sign test p < 0.01).10 15 20 30 40 50BNC multi-complete 64.15 (%) 67.54 73.73 73.66 74.92 74.82BNC+domain 65.27 71.88 72.88 75.02 76.03 * 75.95BNC+COCA 73.45 74.10 74.57 74.90 74.96 75.29BNC+domain+COCA 75.23 * 75.71 * 75.18 * 75.35 * 75.47 76.44 *BNC+domain+COCA (SVM) 58.99 57.74 60.44 70.79 69.29 74.46BNC+domain+COCA (LR) 60.29 61.74 59.27 69.17 70.63 73.42and COCA corpora and whether a word is in thecomputer domain, we used these features for thefeatures of SVM and LR in this experiment for afair comparison.
When using word frequencies forfeatures, we used the logarithm of raw frequenciessince it is reported to work well (Ehara et al.,2013).
SVM and LR are also known to heavilydepend on a hyper-parameter called C, whichdetermines the strength of regularization.
Wetried C = 0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 20.0, 50.0,and 100.0 for each of SVM and LR where the sizeof training data is 50 and chose the C value thatperforms best.
As a result, we set C = 5.0 forSVM and C = 50.0 for LR.
Note that this settingis advantageous for SVM and LR compared toLLGC because the hyper-parameters of SVMand LR are tuned while LLGC?s hyper-parameterremains untuned.
For the implementation of SVMand LR, we used the ?scikit-learn?
package inPython7.We first observed that our proposed methodsconstantly outperform the baseline, heuristic wordsampling, i.e., ?BNC multi-complete?
in Table 1.This indicates that we successfully obtained bet-ter accuracy by formalizing heuristic word sam-pling as active learning and extending graphs.
InTable 1, the accuracy of the top-ranked methods(shown using bold letters) is statistically signif-icantly better than the accuracy of ?BNC multi-complete?
(using the sign test p < 0.01).We then observed that ?BNC multi-complete?and ?BNC + domain?
show competitive accuracywith sample sizes from 10 to 20; furthermore,?BNC + domain?
is slightly better than ?BNCmulti-complete?
with sample sizes ranging from30 to 50 (statistically significant p < 0.01 usingsign test).
Next, we note that there is a trade-offbetween domain and word frequency when choos-7http://scikit-learn.org/stable/ing samples.
More specifically, if we select toomany words from the domain, the measurement ofthe general English ability of learners can be in-accurate; conversely, if we select too many wordsfrom the corpus-based word frequency list, whilethe general English ability of learners is accu-rately measured, we may obtain no informationon the learner?s vocabulary for the targeted do-main.
The competitive or slightly better accuracyof ?BNC + domain?
over ?BNC multi-complete?shows that ?BNC + domain?
could successfullyintegrate domain information into the frequency-based groups without deteriorating measurementsof general English ability.We also observe that ?BNC + COCA?
greatlyoutperforms ?BNC multi-complete?
when thenumber of samples is 10.
This shows that the inte-gration of the two corpora, BNC and COCA (i.e.,?BNC + COCA?
), successfully increases the accu-racy when there are only a small number of sam-ples.
?BNC + domain + COCA?
achieves the best ac-curacy of all the graphs except when the numberof samples is 40.
This indicates that the domaininformation and the information from the COCAcorpus helped one another to improve the accuracybecause ?BNC + domain?
and ?BNC + COCA?
in-troduce different types of domain information into?BNC multi-complete.
?Finally, we observe that ?BNC + domain +COCA (SVM)?
and ?BNC + domain + COCA(LR)?
perform worse than LLGC over the samedataset for all sample sizes, particularly when thesize of the training data is small.
Since LLGC isa semi-supervised classifier while SVM and LRare not, SVM and LR perform poorly for smallamounts of training data.
This result shows thatLLGC is appropriate for this task compared toSVM because, in this task, an increase in the size1382Table 2: Computer-related samples in top 30 sam-ples.Name Num.
ofSamplesExamplesBNC multi-complete0 -BNC+domain 5 input, client, field,background, regis-terBNC+COCA 0 -BNC+domain+COCA3 drive, client, com-mandof training data directly leads to an increased bur-den on the human learners.5.2 Qualitative evaluationIn this subsection, we qualitatively evaluate ourresults to determine the types of nodes that aresampled when domain specificity is introduced.Specifically, we evaluate what words are selectedas samples in the ?BNC + domain?
graph.As noted above, in the ?BNC + domain?
graph,the computer science domain is introduced into?BNC multi-complete?
to measure learners?
vo-cabulary with a specific emphasis on the computerscience domain.
Thus, it is desirable that somewords in the computer science domain are sam-pled from the ?BNC + domain?
graph; otherwise,we need to predict the learners?
vocabulary forthe computer science domain from general wordsrather than those in the computer science domain,which is extremely difficult.Table 2 shows the number of words in the com-puter science domain sampled in the first 30 sam-ples.
Note that only ?BNC + domain?
and ?BNC+ domain + COCA?
select samples from the com-puter science domain.
This indicates that in theother two methods, to measure vocabulary withan emphasis on the computer science domain, weneed to predict learners?
vocabulary from the gen-eral words, which is almost impossible with only30 samples.
Furthermore, it is interesting to notethat ?BNC + domain?
and ?BNC + domain +COCA?
select different samples from the com-puter science domain, except for the word ?client,?although originally the same computer science do-main wordlist was introduced to both graphs.Since ?BNC + domain?
achieves competitiveor slightly better accuracy than ?BNC multi-complete?
in the quantitative analysis and thequalitative analysis, we conclude that our methodcan successfully introduce domain specificity intothe sampling methodology without reducing accu-racy.6 ConclusionIn this study, we propose a novel sampling frame-work that measures the vocabulary of second lan-guage learners.
We call existing sampling meth-ods heuristic sampling.
This approach to samplingranks words from a single corpus by frequency andcreates groups of 1,000 words.
Next, tens of wordsare sampled from each group.
This method as-sumes that the relative difficulty of all 1,000 wordsis the same.In this paper, we introduce a novel samplingmethod by showing that the existing heuristic sam-pling approach is simply a special case of a graph-based active learning algorithm by Gu and Han(2012) applied to a special graph.
We also pro-pose a method to extend this graph to enable us tohandle domain specificity of words and multiplecorpora, which are difficult or impossible to han-dle using current methods.We evaluate our method both quantitatively andqualitatively.
In our quantitative evaluation, theproposed method achieves higher prediction accu-racy compared with the current approach to vo-cabulary prediction.
This suggests that our pro-posed method can successfully make use of do-main specificity and multiple corpora for pre-dicting vocabulary.
In our qualitative evaluation,we examine the words sampled by our proposedmethod and observe that targeted domain-specificwords are successfully sampled.For our future work, because the graph usedin this paper was constructed manually, we planto automatically create a graph suitable for activelearning and classification.
There are several algo-rithms that create graphs from feature-based rep-resentations of words, but these have never beenused for active learning of this task.AcknowledgmentsThis work was supported by the Grant-in-Aid forJSPS Fellows (JSPS KAKENHI Grant Number12J09575).1383ReferencesYo Ehara, Nobuyuki Shimizu, Takashi Ninomiya, andHiroshi Nakagawa.
2010.
Personalized readingsupport for second-language web documents by col-lective intelligence.
In Proceedings of the 15th in-ternational conference on Intelligent user interfaces(IUI 2010), pages 51?60, Hong Kong, China.
ACM.Yo Ehara, Issei Sato, Hidekazu Oiwa, and Hiroshi Nak-agawa.
2012.
Mining words in the minds of secondlanguage learners: learner-specific word difficulty.In Proceedings of the 24th International Confer-ence on Computational Linguistics (COLING 2012),Mumbai, India, December.Yo Ehara, Nobuyuki Shimizu, Takashi Ninomiya, andHiroshi Nakagawa.
2013.
Personalized readingsupport for second-language web documents.
ACMTransactions on Intelligent Systems and Technology,4(2).Quanquan Gu and Jiawei Han.
2012.
Towards activelearning on graphs: An error bound minimizationapproach.
In Proceedings of the IEEE InternationalConference on Data Mining (ICDM) 2012.Ming Ji and Jiawei Han.
2012.
A variance minimiza-tion criterion to active learning on graphs.
In Pro-ceedings of the 15th international conference on Ar-tificial Intelligence and Statistics (AISTATS).Batia Laufer and Paul Nation.
1999.
A vocabulary-size test of controlled productive ability.
Languagetesting, 16(1):33?51.Paul Meara and Barbara Buxton.
1987.
An alterna-tive to multiple choice vocabulary tests.
LanguageTesting, 4(2):142?154.Paul Nation and David Beglar.
2007.
A vocabularysize test.
The Language Teacher, 31(7):9?13.SPACE ALC Inc. 1998.
Standard vocabulary list12,000.Dengyong Zhou, Oliver Bousquet, Thomas Navin Lal,Jason Weston, and Bernhard Sch?olkopf.
2004.Learning with local and global consistency.
In Pro-ceedings in 18th Annual Conference on Neural In-formation Processing Systems (NIPS), pages 321?328.Xueyuan Zhou, Mikhail Belkin, and Nathan Srebro.2011.
An iterated graph laplacian approach for rank-ing on manifolds.
In Proceedings of 17th ACMSIGKDD Conference on Knowledge Discovery andData Mining (KDD), pages 877?885.Xiaojin Zhu, John Lafferty, and Zoubin Ghahra-mani.
2003.
Combining active learning and semi-supervised learning using gaussian fields and har-monic functions.
In Proceedings of ICML 2003workshop on The Continuum from Labeled to Unla-beled Data in Machine Learning and Data Mining.1384
