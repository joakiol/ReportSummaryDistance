Proceedings of the 10th International Workshop on Finite State Methods and Natural Language Processing, pages 99?107,Donostia?San Sebastia?n, July 23?25, 2012. c?2012 Association for Computational LinguisticsFinite-state acoustic and translation model composition in statisticalspeech translation: empirical assessmentAlicia Pe?rez(1), M. Ine?s Torres(2)(1)Dep.
Computer Languages and Systems(2)Dep.
Electricidad y Electro?nicaUniversity of the Basque Country UPV/EHUBilbao (Spain)(1)alicia.perez@ehu.es(2)manes.torres@ehu.esFrancisco CasacubertaInstituto Tecnolo?gico de Informa?ticaUniversidad Polite?cnica de ValenciaValencia (Spain)fcn@iti.upv.esAbstractSpeech translation can be tackled bymeans of the so-called decoupled ap-proach: a speech recognition system fol-lowed by a text translation system.
Themajor drawback of this two-pass decod-ing approach lies in the fact that the trans-lation system has to cope with the er-rors derived from the speech recognitionsystem.
There is hardly any cooperationbetween the acoustic and the translationknowledge sources.
There is a line of re-search focusing on alternatives to imple-ment speech translation efficiently: rang-ing from semi-decoupled to tightly in-tegrated approaches.
The goal of inte-gration is to make acoustic and transla-tion models cooperate in the underlyingdecision problem.
That is, the transla-tion is built by virtue of the joint ac-tion of both models.
As a side-advantageof the integrated approaches, the transla-tion is obtained in a single-pass decod-ing strategy.
The aim of this paper isto assess the quality of the hypothesesexplored within different speech transla-tion approaches.
Evidence of the perfor-mance is given through experimental re-sults on a limited-domain task.1 IntroductionStatistical speech translation (SST) was typ-ically implemented as a pair of consecutivesteps in the so-called decoupled approach: withan automatic speech recognition (ASR) systemplaced before to a text-to-text translation sys-tem.
This approach involves two independentdecision processes: first, getting the most likelystring in the source language and next, get-ting the expected translation into the target lan-guage.
Since the ASR system is not an idealdevice it might make mistakes.
Hence, the texttranslation system would have to manage withthe transcription errors.
Being the translationmodels (TMs) trained with positive samples ofwell-formed source strings, they are very sensi-tive to ill-formed strings in the source language.Hence, it seems ambitious for TMs to aspire tocope with both well and ill formed sentences inthe source language.1.1 Related workRegarding the coupling of acoustic and trans-lation models, there are some contributions inthe literature that propose the use of semi-decoupled approaches.
On the one hand, in(Zhang et al, 2004), SST is carried out by99an ASR placed before a TM with an addi-tional stage that would re-score the obtained hy-potheses within a log-linear framework gather-ing features from both the ASR system (lexiconand language model) and the TM (eg.
distor-tion, fertility) and also additional features (POS,length etc.
).On the other hand, in (Quan et al, 2005), theN-best hypotheses derived from an ASR sys-tem were next translated by a TM, finally, a laststage would re-score the hypotheses and makea choice.
Within the list of the N-best hypothe-ses typically a number of them include some n-grams that are identical, hence, the list results tobe an inefficient means of storing data.
Alterna-tively, in (Zhou et al, 2007) the search spaceextracted from the ASR system, represented asa word-graph (WG), was next explored by a TMfollowing a multilayer search algorithm.Still, a further approach can be assumedin order to make the graph-decoding com-putationally cheaper, that is, confusion net-works (Bertoldi et al, 2007).
Confusion-networks implement a linear approach of theword-graphs, however, as a result, dummy hy-potheses might be introduced and probabili-ties mis-computed.
Confusion networks tradedoff between the accuracy and storage ability ofword-graphs for decoding time.
Indeed, in (Ma-tusov and Ney, 2011) an efficient means of do-ing the decoding with confusion networks waspresented.
Note that these approaches follow atwo-pass decoding strategy.The aforementioned approaches imple-mented phrase-based TMs within a log-linearframework.
In this context, in (Casacubertaet al, 2008) a fully integrated approach wasexamined.
Under this approach, the translationwas carried out in a single-pass decoding,involving a single decision process in whichacoustic and translations models cooperated.This integration paradigm, was earlier proposedin (Vidal, 1997), showing that a single-passdecoding was enough to carry out SST.Finally, in (Pe?rez et al, 2010) several SST de-coding approaches including decoupled, N-bestlists and integrated were compared.
Neverthe-less, the paper focused on the potential scope ofthe approaches, comparing the theoretical upperthreshold of their performance.1.2 ContributionAll the models assessed in this work relay uponexactly the same acoustic and translation mod-els.
It is the combination of them on whichwe are focusing.
In brief, the aim of this pa-per is to compare different approaches to carryout speech translation decoding.
The compari-son is carried out using exactly the same under-lying acoustic and translation models in orderto allow to make a fair comparison of the abil-ities inherent to the decoding strategy.
Apartfrom the decoupled and semi-decoupled strate-gies we also focus on the fully-integrated ap-proach.
While the fully integrated approach al-lows to provide the most-likely hypothesis, weexplored a variant: an integrated architecturewith a re-scoring LM that provided alternativesderived from the integrated approach and usedre-scoring to make the final decision.
Not onlyan oracle-evaluation is provided as an upper-threshold of the experiments but also an experi-mental set-up to give empirical evidence.The paper is arranged as follows: Section 2introduces the formulation of statistical speechtranslation (SST); Section 3 describes differ-ent approaches to put into practice SST, plac-ing emphasis on the assumptions behind eachof them.
Section 4 is devoted to assess experi-mentally the performance of each approach.
Fi-nally, in Section 5 the concussions drawn fromthe experiments are summarized.1002 Statistical speech translationThe goal of speech translation, formulated un-der the probabilistic framework, is to find themost likely string in the target language (?t)given the spoken utterance in the source lan-guage.
Speech signal in the source languageis characterized in terms of an array of acousticfeatures in the source language, x.
The decisionproblem involved is formulated as follows:t?
= arg maxtP (t|x) (1)In this context, the text transcription in thesource language (denoted as s) is introduced asa hidden variable and Bayes?
rule applied:t?
= arg maxt?sP (x|s, t)P (s, t) (2)Assuming P (x|s, t) ?
P (x|s), and using themaximum term involved in the sum as an ap-proach to the sum itself for the sake of compu-tational affordability, we yield to:t?
?
arg maxtmaxsP (x|s)P (s, t) (3)As a result, the expected translation is builtrelying upon both a translation model (P (s, t))and an acoustic model in the source language(P (x|s)).
This approach requires the joint co-operation of both models to implement the de-cision problem since the maximum over s con-cerns both of them.2.1 Involved modelsBeing the goal of this paper to compare differ-ent techniques to combine acoustic and trans-lation models, it is important to keep constantthe underlying models while varying the strate-gies to combine them.
Before to delve into thecomposition strategies and due to the fact thatsome combination strategies are based on thefinite-state topology of the models, a summaryof the relevant features of the underlying mod-els is given in this section.2.1.1 Translation modelThe translation model used in this workto tackle all the approaches consists of astochastic finite-state transducer (SFST) en-compassing phrases in the source and tar-get languages together with a probability ofjoint occurrence.
The SFST (T ) is a tupleT = ?
?,?, Q, q0, R, F, P ?, where:?
is a finite set of input symbols;?
is a finite set of output symbols;Q is a finite set of states;q0 ?
Q is the initial state;R ?
Q ?
?+ ?
??
?
Q is a set of transi-tions.
(q, s?, t?, q?)
?
R, represents a tran-sition from the state q ?
Q to the stateq?
?
Q, with the source phrase s?
?
?+ andproducing the substring t?
?
?
?, where t?might consist of zero or more target words(|t?| ?
0);F : Q?
[0, 1] is a final state probability;P : R?
[0, 1] is a transition probability;Subject to the stochastic constraint:?q ?
Q F (q) +?s?,t?,q?P (q, s?, t?, q?)
= 1 (4)For further reading on formulation and prop-erties of these machines turn to (Vidal et al,2005).The SFST can be understood as a statisticalbi-language implemented by means of finite-state regular grammar (Casacuberta and Vidal,2004) (in the same way as a stochastic finite-state automaton can be used to model a sin-gle language): A = ?
?, Q, q0, R, F, P ?, being?
?
?+ ???
a finite-set of bilingual-phrases.Likewise, bilingual n-gram models can be in-ferred in practice (Marin?o et al, 2006).1012.1.2 Acoustic modelsThe acoustic model consists of a mapping oftext-transcriptions of lexical units in the sourcelanguage and their acoustic representation.
Thatcomprises the composition of: 1) a lexicalmodel consisting of a mapping between the tex-tual representation with their phone-like repre-sentation in terms of a left-to-right sequence;and 2) an inventory of phone-like units con-sists of a typical three-state hidden Markovmodel (Rabiner, 1989).
Thus, acoustic modellays on the composition of two finite-state mod-els (depicted in Figure 1)./T/ /j/ /e/ /l/ /o/cielo(a) Phonetic representation of a text lexical unit/T//j//e/(b) HMM phone-like unitsFigure 1: Acoustic model requires composingphone-like units within phonetic representationof lexical units.3 Decoding strategiesIn the previous section the formulation of SSTwas summarized.
Let us now turn into prac-tice and show the different strategies exploredto combine acoustic and translation models totackle SST.
The approaches accounted are: de-coupled, semi-decoupled and integrated archi-tectures.
While the former two are imple-mentable by virtue of alternative TMs, the latteris achieved thanks to the integration allowed byfinite-state framework.
Thus, in order to com-pare the combination rather than the TMs them-selves, all of the combinations shall be put inpractice using the same SFST as TM.3.1 Decoupled approachPossibly the most widely used approach totackle speech translation is the so-called serial,cascade or decoupled approach.
It consists ofa text-to-text translation system placed after anASR system.
This process is formally stated as:t?
?
arg maxtmaxsP (x|s)P (s)P (t|s) (5)In practice, previous expression is imple-mented in two independent stages as follows:1st stage: an ASR system would find themost likely transcription (?s):s?
?
arg maxsP (x|s)P (s) (6)2nd stage next, given the expected string inthe source language (?s), a TM would find themost likely translation:t?
?
arg maxtP (t|?s) = arg maxtP (?s, t) (7)The TM involved in eq.
(7) can be based oneither posterior or joint-probability as the dif-ference between both of them is a normaliza-tion term that does not intervene in the maxi-mization process.
The second stage has to copewith expected transcription of speech (?s) whichdoes not necessarily convey the exact referencesource string (s).
That is, the ASR might intro-duce errors in the source string to be translatedin the next stage.
However, the TMs are typ-ically trained with correct source-target pairs.Thus, transcription errors are seldom foreseeneven in models including smoothing (Martin etal., 1999).
In addition, TMs are extremely sen-sitive to the errors in the input, in particular tosubstitutions (Vilar et al, 2006).This architecture represents a suboptimalmeans of contending with SST as referred ineq.
(3).
This approach barely takes advantage ofthe involved knowledge sources, namely, acous-tic and translation models.1023.2 Semi-Decoupled approachOccasionally, the most probable translationdoes not result to be the most accurate one withrespect to a given reference.
That is, it mighthappen that hypotheses with a slightly lowerprobability than that of the expected hypothesisturn to be more similar to the reference than theexpected hypothesis.
This happens due to sev-eral factors, amongst others, due to the sparsityof the data with which the model was trained.In brief, some sort of disparity between theprobability of the hypotheses and their qualitymight arise in practice.
The semi-decoupled ap-proach arose to address this issue.
Hence, ratherthan translating a single transcription hypothe-sis, a number of them are provided by the ASRto the TM, and it is the latter that makes the de-cision giving as a result the most likely transla-tion.
The decoupled approach is implementedin two steps, and so is it the semi-decoupled ap-proach.
Details on the process are as follows:1st stage: for a given utterance in the sourcelanguage, an ASR system, laying on sourceacoustic model and source language model(LM), would provide a search sub-space.
Thissub-space is traced in the search process for themost likely transcription of speech but withoutgetting rid of other highly probable hypotheses.For what us concern, this sub-space is rep-resented in terms of a graph of words in thesource language (S).
The word-graph gath-ers the hypotheses with a probability within athreshold with respect to the optimal hypothesisat each time-frame as it was formulated in (Neyet al, 1997).
The obtained graph is an acyclicdirected graph where the nodes are associatedwith word-prefixes of a variable length, and theedges join the word sequences allowed in therecognition process with an associated recogni-tion probability.
The edges consist of the acous-tic and language model probabilities as the ASRsystem handles throughout the trellis.2nd stage: translating the hypotheses withinS (the graph derived in the 1st stage) allows totake into account alternative translations for thegiven spoken utterance.
The searching spacebeing explored is limited by the source stringsconveyed by S .
The combination of the recog-nition probability with the translation probabil-ity results in a score that accounts both recogni-tion and translation likelihood:t?
?
arg maxtmaxs?SP (s)P (s, t) (8)Thus, acoustic and translation models wouldone re-score the other.All in all, this semi-decoupled approach re-sults in an extension of the decoupled one.It accounts alternative transcriptions of speechin an attempt to get good quality transcrip-tions (rather than the most probable transcrip-tion as in the case of the decoupled approach).Amongst all the transcriptions, those with highquality are expected to provide the best qualityin the target language.
That is, by avoiding er-rors derived from the transcription process, theTM should perform better, and thus get transla-tions of higher quality.
Note that finally, a singletranslation hypothesis is selected.
To do so, thehighest combined probability is accounted.3.3 Fully-integrated approachFinite-state framework (by contrast to otherframeworks) makes a tight composition of mod-els possible.
In our case, of acoustic and trans-lation finite-state models.
The fully-integratedapproach, proposed in (Vidal, 1997), encfom-passed acoustic and translation models within asingle model.
To develop the fully-integratedapproach a finite-state acoustic model on thesource language (A) providing the text tran-scription of a given acoustic utterance (A :103X ?
S) can be composed with a text transla-tion model (T ) that provides the translation of agiven text in the source language (T : S ?
T )and give as a result a transducer (Z = A ?
T )that would render acoustic utterances in thesource language to strings in the target lan-guage.
For the sake of efficiency in terms ofspatial cost, the models are integrated on-the-flyin the same manner as it is done in ASR (Ca-seiro and Trancoso, 2006).The way in which integrated architecture ap-proaches eq.
(3) is looking for the most-likelysource-target translation pair as follows:?
(s, t) = arg max(s,t)P (s, t)P (x|s) (9)That is, the search is driven by bilingual phrasesmade up of acoustic elements in the sourcelanguage integrated within bilingual phrases ofwords together with target phrases.Then, the expected translation would simplybe approached as the target projection of ?
(s, t),the expected source-target string (also knownas the lower projection); and likewise, the ex-pected transcription is obtained as a side-resultby the source projection (aka upper projection).It is well-worth mentioning that this approachimplements fairly the eq.
(3) without furtherassumptions rather than those made in the de-coding stage such as Viterbi-like decoding withbeam-search.
All in all, acoustic and translationmodels cooperate to find the expected transla-tion.
Moreover, it is carried out in a single-passdecoding strategy by contrast to either decou-pled or semi-decoupled approaches.3.4 Integrated WG and re-scoring LMThe fully-integrated approach looks for thesingle-best hypothesis within the integratedacoustic-and-translation network.
Followingthe reasoning of Section 3.2, the most likelypath together with other locally close paths inthe integrated searching space can be extractedand arranged in terms of a word graph.
Whilethe WG derived in Section 3.2 was in sourcelanguage, this one would be bilingual.Given a bilingual WG, the lower-side net(WG.l) can be extracted keeping the topol-ogy and the associated probability distributionswhile getting rid of the input string of each tran-sition, this gives as a result the projection ofthe WG in the target language.
Next, a targetlanguage model (LM) would help to make thechoice for the most likely hypothesis amongstthose in the WG.l.t?
?
arg maxtPWG.l(t)PLM (t) (10)In other words, while in Section 3.2 the trans-lation model was used to re-score alternativetranscriptions of speech whereas in this ap-proach a target language models re-scores al-ternative translations provided by the bilingualWG.
Note that this approach, as well as thesemi-decoupled one, entail a two-pass decodingstrategy.
Both rely upon two models: the for-mer focused on the source language WG, thisone focuses on the target language WG.4 ExperimentsThe aim of this section is to assess empir-ically the performance each of the four ap-proaches previously introduced: decoupled,semi-decoupled, fully-integrated and integratedWG with re-scoring LM.
The four approachesdiffer on the decoding strategy implemented tosort out the decision problem, but all of themrely on the very same knowledge sources (thatis, the same acoustic and translation model).The main features of the corpus used to carryout the experimental layout are summarized inTable 1.
The training set was used to infer the104TM consisting of an SFST and the test set to as-sess the SST decoding approaches.
The test setconsisted of 500 training-independent pairs dif-ferent each other, each of them was uttered byat least 3 speakers.Spanish BasqueTrain Sentences 15,000Running words 191,000 187,000Vocabulary 702 1,135Test Sentences 1,800Hours of speech 3.0 3.5Table 1: Main features of the Meteus corpus.The performance of each experiment is as-sessed through well-known evaluation met-rics, namely: bilingual evaluation under-study(BLEU) (Papineni et al, 2002), word error-rate(WER), translation edit rate (TER).4.1 ResultsThe obtained results are given in Table 2.
Theperformance of the most-likely or single-besttranslation derived by either decoupled or fully-integrated architectures is shown in the first rowof Tables 2a and 2b respectively.
The per-formance of the semi-decoupled and integratedWG with re-scoring LM is shown in the sec-ond row.
The highest performance achievableby both the semi decoupled approach and theintegrated WG with re-scoring LM is given inthe third row.
To do so, an oracle evaluation ofthe alternatives was carried out and the score as-sociated to the best choice achievable was givenas in (Pe?rez et al, 2010).
Since the oracle evalu-ation provides an upper threshold of the qualityachievable, the scope of each decoupled or in-tegrated approaches can be assessed regardlessof the underlying decoding algorithms and ap-proaches.
The highest performance achievableis reflected in the last row of Tables 2a and 2b.4.2 DiscussionWhile the results with two-pass decoding strate-gies (either decoupled or semi-decoupled ap-proach) require an ASR engine, integrated ap-proaches have the ability to get both the sourcestring together with its translation.
This is whywe have make a distinction between ASR-WERin the former and source-WER in the latter.Nevertheless, our aim focuses on translationrather than on recognition.The results show that semi-decoupled ap-proach outperforms the decoupled one.
Simi-larly, the approach based on the integrated WGwith the re-scoring target LM outperforms theintegrated approach.
As a result, exploring dif-ferent hypotheses and making the selection witha second model allows to make refined deci-sions.
On the other hand, comparing the firstrow of the Table 2a with the first row of the Ta-ble 2b (or equally the second row of the formerwith the second row of the latter), we concludethat slightly better performance can be obtainedwith the integrated approach.Finally, comparing the third row of both Ta-ble 2a and Table 2b, the conclusion is that theeventual quality of the hypotheses within the in-tegrated approach are significantly better thanthose in the semi-decoupled approaches.
Thatis, what we can learn is that the integrated de-coding strategy keeps much better hypothesesthan the semi-decoupled one throughout the de-coding process.
Still, while good quality hy-potheses exist within the integrated approach,the re-scoring with a target LM used to selecta single hypothesis from the entire network hasnot resulted in getting the best possible hypoth-esis.
Oracle evaluation shows that the integratedapproach offers a leeway to achieve improve-ments in the quality, yet, alternative strategieshave to be explored.105ASR targetWER BLEU WER TERD 1-best 7.9 40.8 50.3 47.7SD 7.9 42.2 47.6 44.7SD tgt-oracle 7.5 57.6 36.2 32.8(a) Decoupled and semi-decoupledsource targetWER BLEU WER TERI 1-best 9.6 40.9 49.6 46.8I WG + LM 9.3 42.6 46.7 43.9I tgt-oracle 6.6 64.0 32.2 28.5(b) Integrated and integrated WG with LMTable 2: Assessment of SST approaches decoupled (2a) and integrated (2b) respectively.5 ConclusionsDifferent approaches to cope with the SST de-coding methodology were explored, namely,decoupled approach, semi-decoupled approach,fully-integrated approach and integrated ap-proach with a re-scoring LM.
The first two fol-low a two-pass decoding strategy and focus onexploring alternatives in the source language;while the integrated one follows a single-passdecoding and present tight cooperation betweenacoustic and translation models.All the experimental layouts used exactly thesame translation and acoustic models differingonly on the methodology used to overcome thedecision problem.
In this way, we can assertthat the differences lay on the decoding strate-gies rather than on the models themselves.
Notethat implementing all the models in terms offinite-state models allows to build both decou-pled and integrated approaches.Both decoupled and integrated decoding ap-proaches aim at finding the most-likely transla-tion under different assumptions.
Occasionally,the most probable translation does not result tobe the most accurate one with respect to a givenreference.
On account of this, we turned to ana-lyzing alternatives and making use of re-scoringtechniques on both approaches in an attemptto make the most accurate hypothesis emerge.This resulted in semi-decoupled and integrated-WG with re-scoring target LM approaches.What we can learn from the experimentsis that integrating the models allow to keepgood quality hypotheses in the decoding pro-cess.
Nevertheless, the re-scoring model hasnot resulted in being able to make the most ofthe integrated approach.
In other words, thereare better quality hypotheses within the word-graph rather than that selected by the re-scoringtarget LM.
Hence, further work should be fo-cused on other means of selecting hypothesesfrom the integrated word-graph.However, undoubtedly significantly betterperformance can be reached from the inte-grated decoding strategy than from the semi-decoupled one.
It seems as though knowledgesources modeling the syntactic differences be-tween source and target languages should betackled in order to improve the performance,particularly in our case, a strategy for furtherwork could go on the line of the recently tack-led approach (Durrani et al, 2011).AcknowledgmentsThis work was partially funded by theSpanish Ministry of Science and Innovation:through the T?
?mpano (TIN2011-28169-C05-04)and iTrans2 (TIN2009-14511) projects; alsothrough MIPRCV (CSD2007-00018) projectwithin the Consolider-Ingenio 2010 program;by the Basque Government to PR&ST researchgroup (GIC10/158, IT375-10), and by the Gen-eralitat Valenciana under grants ALMPR (Prom-eteo/2009/01) and GV/2010/067.106References[Bertoldi et al2007] N. Bertoldi, R. Zens, and M.Federico.
2008.
Efficient speech translation byconfusion network decoding.
IEEE InternationalConference on Acoustics, Speech and Signal Pro-cessing, pg.
1696?1705[Casacuberta and Vidal2004] F. Casacuberta and E.Vidal.
2004.
Machine translation with in-ferred stochastic finite-state transducers.
Compu-tational Linguistics, 30(2): pg.
205?225.
[Casacuberta et al2008] F. Casacuberta, M. Fed-erico, H. Ney, and E. Vidal.
2008.
Recent effortsin spoken language translation.
IEEE Signal Pro-cessing Magazine, 25(3): pg.
80?88.
[Caseiro and Trancoso2006] D. Caseiro and I. Tran-coso.
2006.
A specialized on-the-fly algo-rithm for lexicon and language model composi-tion.
IEEE Transactions on Audio, Speech &Language Processing, 14(4): pg.
1281?1291.
[Durrani et al2011] N. Durrani, H. Schmid, and A.Fraser.
2011.
A joint sequence translation modelwith integrated reordering.
In 49th Annual Meet-ing of the Association for Computational Linguis-tics: Human Language Technologies, pg.
1045?1054[Marin?o et al2006] J.
B. Marin?o, R. E. Banchs, J. M.Crego, A. de Gispert, P. Lambert, J.
A. R. Fonol-losa, and M. R. Costa-jussa`.
2006.
N-gram-based machine translation.
Computational Lin-guistics, 32(4): pg.
527?549[Martin et al1999] S. C. Martin, H. Ney, andJ.
Zaplo.
1999.
Smoothing methods in maxi-mum entropy language modeling.
IEEE Interna-tional Conference on Acoustics, Speech, and Sig-nal Processing , vol.
1, pg.
545?548[Matusov and Ney2011] E. Matusov and H. Ney.2011.
Lattice-based ASR-MT interface forspeech translation.
IEEE Transactions on Audio,Speech, and Language Processing, 19(4): pg.
721?732[Ney et al1997] H. Ney, S. Ortmanns, and I. Lin-dam.
1997.
Extensions to the word graph methodfor large vocabulary continuous speech recogni-tion.
IEEE International Conference on Acous-tics, Speech, and Signal Processing, vol.
3, pg.1791 ?1794[Papineni et al2002] K. Papineni, S. Roukos, T.Ward, and W.-J.
Zhu.
2002.
Bleu: a method forautomatic evaluation of machine translation.
An-nual Meeting on Association for ComputationalLinguistics, pg.
311?318[Pe?rez et al2010] A. Pe?rez, M. I. Torres, and F.Casacuberta.
2010.
Potential scope of a fully-integrated architecture for speech translation.
An-nual Conference of the European Association forMachine Translation, pg.
1?8[Quan et al2005] V. H. Quan, M. Federico, and M.Cettolo.
2005.
Integrated n-best re-ranking forspoken language translation.
European Conver-ence on Speech Communication and Technology,Interspeech, pg.
3181?3184.
[Rabiner1989] L.R.
Rabiner.
1989.
A tutorial onhidden markov models and selected applicationsin speech recognition.
Proceedings of the IEEE,77(2): pg.
257?286[Vidal et al2005] E. Vidal, F. Thollard, C. de laHiguera, F. Casacuberta, and R. C. Carrasco.2005.
Probabilistic finite-state machines - part II.IEEE Transactions on Pattern Analysis and Ma-chine Intelligence, 27(7): pg.
1026?1039[Vidal1997] E. Vidal.
1997.
Finite-state speech-to-speech translation.
International Conference onAcoustic, Speech and Signal Processing, vol.
1,pg.
111?114[Vilar et al2006] David Vilar, Jia Xu, Luis FernandoD?Haro, and H. Ney.
2006.
Error Analysis ofMachine Translation Output.
International Con-ference on Language Resources and Evaluation,pg.
697?702[Zhang et al2004] R. Zhang, G. Kikui, H. Ya-mamoto, T. Watanabe, F. Soong, and W. K. Lo.2004.
A unified approach in speech-to-speechtranslation: integrating features of speech recog-nition and machine translation.
InternationalConference on Computational Linguistics, pg.1168-1174[Zhou et al2007] B. Zhou, L. Besacier, and Y. Gao.2007.
On efficient coupling of ASR and SMT forspeech translation.
IEEE International Confer-ence on Acoustics, Speech and Signal Processing,vol.
4, pg.
101?104107
