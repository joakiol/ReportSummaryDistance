Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 17?24,New York, June 2006. c?2006 Association for Computational LinguisticsImproved Statistical Machine Translation Using ParaphrasesChris Callison-Burch Philipp Koehn Miles OsborneSchool of InformaticsUniversity of Edinburgh2 Buccleuch PlaceEdinburgh, EH8 9LWcallison-burch@ed.ac.ukAbstractParallel corpora are crucial for trainingSMT systems.
However, for many lan-guage pairs they are available only invery limited quantities.
For these lan-guage pairs a huge portion of phrases en-countered at run-time will be unknown.We show how techniques from paraphras-ing can be used to deal with these oth-erwise unknown source language phrases.Our results show that augmenting a state-of-the-art SMT system with paraphrasesleads to significantly improved coverageand translation quality.
For a trainingcorpus with 10,000 sentence pairs we in-crease the coverage of unique test set un-igrams from 48% to 90%, with more thanhalf of the newly covered items accuratelytranslated, as opposed to none in currentapproaches.1 IntroductionAs with many other statistical natural language pro-cessing tasks, statistical machine translation (Brownet al, 1993) produces high quality results when am-ple training data is available.
This is problematic forso called ?low density?
language pairs which do nothave very large parallel corpora.
For example, whenwords occur infrequently in a parallel corpus param-eter estimates for word-level alignments can be in-accurate, which can in turn lead to inaccurate phrasetranslations.
Limited amounts of training data canfurther lead to a problem of low coverage in thatmany phrases encountered at run-time are not ob-served in the training data and therefore their trans-lations will not be learned.Here we address the problem of unknown phrases.Specifically we show that upon encountering an un-known source phrase, we can substitute a paraphrasefor it and then proceed using the translation of thatparaphrase.
We derive these paraphrases from re-sources that are external to the parallel corpus thatthe translation model is trained from, and we areable to exploit (potentially more abundant) parallelcorpora from other language pairs to do so.In this paper we:?
Define a method for incorporating paraphrasesof unseen source phrases into the statistical ma-chine translation process.?
Show that by translating paraphrases weachieve a marked improvement in coverage andtranslation quality, especially in the case of un-known words which to date have been left un-translated.?
Argue that while we observe an improvementin Bleu score, this metric is particularly poorlysuited to measuring the sort of improvementsthat we achieve.?
Present an alternative methodology for targetedmanual evaluation that may be useful in otherresearch projects.2 The Problem of Coverage in SMTStatistical machine translation made considerableadvances in translation quality with the introduc-tion of phrase-based translation (Marcu and Wong,2002; Koehn et al, 2003; Och and Ney, 2004).
By170 1020 3040 5060 7080 9010010000  100000  1e+06  1e+07TestSetItemswithTranslations(%)Training Corpus Size (num words)unigramsbigramstrigrams4-gramsFigure 1: Percent of unique unigrams, bigrams, tri-grams, and 4-grams from the Europarl Spanish testsentences for which translations were learned in in-creasingly large training corporaincreasing the size of the basic unit of translation,phrase-based machine translation does away withmany of the problems associated with the originalword-based formulation of statistical machine trans-lation (Brown et al, 1993).
For instance, with multi-word units less re-ordering needs to occur since lo-cal dependencies are frequently captured.
For exam-ple, common adjective-noun alternations are mem-orized.
However, since this linguistic informationis not explicitly and generatively encoded in themodel, unseen adjective noun pairs may still be han-dled incorrectly.Thus, having observed phrases in the past dramat-ically increases the chances that they will be trans-lated correctly in the future.
However, for any giventest set, a huge amount of training data has to be ob-served before translations are learned for a reason-able percentage of the test phrases.
Figure 1 showsthe extent of this problem.
For a training corpuscontaining 10,000 words translations will have beenlearned for only 10% of the unigrams (types, nottokens).
For a training corpus containing 100,000words this increases to 30%.
It is not until nearly10,000,000 words worth of training data have beenanalyzed that translation for more than 90% of thevocabulary items have been learned.
This problemis obviously compounded for higher-order n-grams(longer phrases), and for morphologically richer lan-guages.encargarnos to ensure, take care, ensure thatgarantizar guarantee, ensure, guaranteed, as-sure, providedvelar ensure, ensuring, safeguard, makingsureprocurar ensure that, try to, ensure, endeavourtoasegurarnos ensure, secure, make certainusado usedutilizado used, use, spent, utilizedempleado used, spent, employeeuso use, used, usageutiliza used, uses, used, being usedutilizar to use, use, usedTable 1: Example of automatically generated para-phrases for the Spanish words encargarnos and us-ado along with their English translations which wereautomatically learned from the Europarl corpus2.1 Handling unknown wordsCurrently most statistical machine translation sys-tems are simply unable to handle unknown words.There are two strategies that are generally employedwhen an unknown source word is encountered.
Ei-ther the source word is simply omitted when pro-ducing the translation, or alternatively it is passedthrough untranslated, which is a reasonable strategyif the unknown word happens to be a name (assum-ing that no transliteration need be done).
Neither ofthese strategies is satisfying.2.2 Using paraphrases in SMTWhen a system is trained using 10,000 sentencepairs (roughly 200,000 words) there will be a num-ber of words and phrases in a test sentence which ithas not learned the translation of.
For example, theSpanish sentenceEs positivo llegar a un acuerdo sobre losprocedimientos, pero debemos encargar-nos de que este sistema no sea susceptiblede ser usado como arma pol?
?tica.may translate asIt is good reach an agreement on proce-dures, but we must encargarnos that thissystem is not susceptible to be usado aspolitical weapon.18what is more, the relevant cost dynamic is completely under controlim ?brigen ist die diesbez?gliche kostenentwicklung v?llig  unter kontrollewe owe it to the taxpayers to keep in checkthe costswir sind es den steuerzahlern die kosten zu habenschuldig  unter kontrolleFigure 2: Using a bilingual parallel corpus to extract paraphrasesThe strategy that we employ for dealing with un-known source language words is to substitute para-phrases of those words, and then translate the para-phrases.
Table 1 gives examples of paraphrases andtheir translations.
If we had learned a translation ofgarantizar we could translate it instead of encargar-nos, and similarly for utilizado instead of usado.3 Acquiring ParaphrasesParaphrases are alternative ways of expressing thesame information within one language.
The auto-matic generation of paraphrases has been the focusof a significant amount of research lately.
Manymethods for extracting paraphrases (Barzilay andMcKeown, 2001; Pang et al, 2003) make use ofmonolingual parallel corpora, such as multiple trans-lations of classic French novels into English, or themultiple reference translations used by many auto-matic evaluation metrics for machine translation.Bannard and Callison-Burch (2005) use bilin-gual parallel corpora to generate paraphrases.
Para-phrases are identified by pivoting through phrases inanother language.
The foreign language translationsof an English phrase are identified, all occurrencesof those foreign phrases are found, and all Englishphrases that they translate back to are treated as po-tential paraphrases of the original English phrase.Figure 2 illustrates how a German phrase can beused as a point of identification for English para-phrases in this way.The method defined in Bannard and Callison-Burch (2005) has several features that make it anideal candidate for incorporation into statistical ma-chine translation system.
Firstly, it can easily be ap-plied to any language for which we have one or moreparallel corpora.
Secondly, it defines a paraphraseprobability, p(e2|e1), which can be incorporated intothe probabilistic framework of SMT.3.1 Paraphrase probabilitiesThe paraphrase probability p(e2|e1) is definedin terms of two translation model probabilities:p(f |e1), the probability that the original Englishphrase e1 translates as a particular phrase f in theother language, and p(e2|f), the probability that thecandidate paraphrase e2 translates as the foreign lan-guage phrase.
Since e1 can translate as multiple for-eign language phrases, we marginalize f out:p(e2|e1) =?fp(f |e1)p(e2|f) (1)The translation model probabilities can be com-puted using any standard formulation from phrase-based machine translation.
For example, p(e2|f)can be calculated straightforwardly using maximumlikelihood estimation by counting how often thephrases e and f were aligned in the parallel corpus:p(e2|f) ?count(e2, f)?e2 count(e2, f)(2)There is nothing that limits us to estimating para-phrases probabilities from a single parallel corpus.We can extend the definition of the paraphrase prob-ability to include multiple corpora, as follows:p(e2|e1) ?
?c?C?f in c p(f |e1)p(e2|f)|C|(3)where c is a parallel corpus from a set of paral-lel corpora C. Thus multiple corpora may be used19by summing over all paraphrase probabilities calcu-lated from a single corpus (as in Equation 1) andnormalized by the number of parallel corpora.4 Experimental DesignWe examined the application of paraphrases to dealwith unknown phrases when translating from Span-ish and French into English.
We used the pub-licly available Europarl multilingual parallel corpus(Koehn, 2005) to create six training corpora for thetwo language pairs, and used the standard Europarldevelopment and test sets.4.1 BaselineFor a baseline system we produced a phrase-basedstatistical machine translation system based on thelog-linear formulation described in (Och and Ney,2002)e?
= argmaxep(e|f) (4)= argmaxeM?m=1?mhm(e, f) (5)The baseline model had a total of eight featurefunctions, hm(e, f): a language model probabil-ity, a phrase translation probability, a reverse phrasetranslation probability, lexical translation probabil-ity, a reverse lexical translation probability, a wordpenalty, a phrase penalty, and a distortion cost.
Toset the weights, ?m, we performed minimum errorrate training (Och, 2003) on the development set us-ing Bleu (Papineni et al, 2002) as the objective func-tion.The phrase translation probabilities were deter-mined using maximum likelihood estimation overphrases induced from word-level alignments pro-duced by performing Giza++ training on each of thethree training corpora.
We used the Pharaoh beam-search decoder (Koehn, 2004) to produce the trans-lations after all of the model parameters had beenset.When the baseline system encountered unknownwords in the test set, its behavior was simply to re-produce the foreign word in the translated output.This is the default behavior for many systems, asnoted in Section 2.1.4.2 Translation with paraphrasesWe extracted all source language (Spanish andFrench) phrases up to length 10 from the test anddevelopment sets which did not have translations inphrase tables that were generated for the three train-ing corpora.
For each of these phrases we gener-ated a list of paraphrases using all of the parallel cor-pora from Europarl aside from the Spanish-Englishand French-English corpora.
We used bitexts be-tween Spanish and Danish, Dutch, Finnish, French,German, Italian, Portuguese, and Swedish to gener-ate our Spanish paraphrases, and did similarly forthe French paraphrases.
We manage the parallelcorpora with a suffix array -based data structure(Callison-Burch et al, 2005).
We calculated para-phrase probabilities using the Bannard and Callison-Burch (2005) method, summarized in Equation 3.Source language phrases that included names andnumbers were not paraphrased.For each paraphrase that had translations in thephrase table, we added additional entries in thephrase table containing the original phrase and theparaphrase?s translations.
We augmented the base-line model by incorporating the paraphrase probabil-ity into an additional feature function which assignsvalues as follows:h(e, f1) =????
?p(f2|f1) If phrase table entry (e, f1)is generated from (e, f2)1 OtherwiseJust as we did in the baseline system, we performedminimum error rate training to set the weights of thenine feature functions in our translation model thatexploits paraphrases.We tested the usefulness of the paraphrase fea-ture function by performing an additional experi-ment where the phrase table was expanded but theparaphrase probability was omitted.4.3 EvaluationWe evaluated the efficacy of using paraphrases inthree ways: by calculating the Bleu score for thetranslated output, by measuring the increase in cov-erage when including paraphrases, and through a tar-geted manual evaluation of the phrasal translationsof unseen phrases to determine how many of thenewly covered phrases were accurately translated.20causasAlignment ToolforcitizensoftreatmenttheininequalityanddiscriminationcombatsarticleThereasonsthetherein.listedlasporciudadanoslosdedesigualtratoelycombateart?culoElenenumeradasmismo.eldiscriminaci?nlaFigure 3: Test sentences and reference translationswere manually word-aligned.
This allowed us toequate unseen phrases with their corresponding En-glish phrase.
In this case enumeradas with listed.Although Bleu is currently the standard metric forMT evaluation, we believe that it may not meaning-fully measure translation improvements in our setup.By substituting a paraphrase for an unknown sourcephrase there is a strong chance that its translationmay also be a paraphrase of the equivalent targetlanguage phrase.
Bleu relies on exact matches ofn-grams in a reference translation.
Thus if our trans-lation is a paraphrase of the reference, Bleu will failto score it correctly.Because Bleu is potentially insensitive to the typeof changes that we were making to the translations,we additionally performed a focused manual evalu-ation (Callison-Burch et al, 2006).
To do this, hadbilingual speakers create word-level alignments forthe first 150 and 250 sentence in the Spanish-Englishand French-English test corpora, as shown in Figure3.
We were able to use these alignments to extractthe translations of the Spanish and French words thatwe were applying our paraphrase method to.Knowing this correspondence between foreignphrases and their English counterparts allowed us todirectly analyze whether translations that were be-ing produced from paraphrases remained faithful tothe meaning of the reference translation.
When pro-The article combats discrimination and inequalityin the treatment of citizens for the reasons listedtherein.The article combats discrimination and the dif-ferent treatment of citizens for the reasons men-tioned in the same.The article fights against uneven and the treatmentof citizens for the reasons enshrined in the same.The article is countering discrimination and theunequal treatment of citizens for the reasons thatin the same.Figure 4: Judges were asked whether the highlightedphrase retained the same meaning as the highlightedphrase in the reference translation (top)ducing our translations using the Pharaoh decoderwe employed its ?trace?
facility, which tells whichsource sentence span each target phrase was derivedfrom.
This allowed us to identify which elementsin the machine translated output corresponded to theparaphrased foreign phrase.
We asked a monolin-gual judge whether the phrases in the machine trans-lated output had the same meaning as of the refer-ence phrase.
This is illustrated in Figure 4.In addition to judging the accuracy of 100 phrasesfor each of the translated sets, we measured howmuch our paraphrase method increased the cover-age of the translation system.
Because we focuson words that the system was previously unable totranslate, the increase in coverage and the transla-tion quality of the newly covered phrases are thetwo most relevant indicators as to the efficacy of themethod.5 ResultsWe produced translations under five conditions foreach of our training corpora: a set of baselinetranslations without any additional entries in thephrase table, a condition where we added the trans-lations of paraphrases for unseen source words alongwith paraphrase probabilities, a condition where weadded the translations of paraphrases of multi-wordphrases along with paraphrase probabilities, and twoadditional conditions where we added the transla-tions of paraphrases of single and multi-word para-phrase without paraphrase probabilities.21Spanish-English French-EnglishCorpus size 10k 20k 40k 80k 160k 320k 10k 20k 40k 80k 160k 320kBaseline 22.6 25.0 26.5 26.5 28.7 30.0 21.9 24.3 26.3 27.8 28.8 29.5Single word 23.1 25.2 26.6 28.0 29.0 30.0 22.7 24.2 26.9 27.7 28.9 29.8Multi-word 23.3 26.0 27.2 28.0 28.8 29.7 23.7 25.1 27.1 28.5 29.1 29.8Table 2: Bleu scores for the various training corpora, including baseline results without paraphrasing, resultsfor only paraphrasing unknown words, and results for paraphrasing any unseen phrase.
Corpus size ismeasured in sentences.Corpus size 10k 20k 40k 80k 160k 320k 10k 20k 40k 80k 160k 320kSingle w/o-ff 23.0 25.1 26.7 28.0 29.0 29.9 22.5 24.1 26.0 27.6 28.8 29.6Multi w/o-ff 20.6 22.6 21.9 24.0 25.4 27.5 19.7 22.1 24.3 25.6 26.0 28.1Table 3: Bleu scores for the various training corpora, when the paraphrase feature function is not included5.1 Bleu scoresTable 2 gives the Bleu scores for each of these con-ditions.
We were able to measure a translation im-provement for all sizes of training corpora, underboth the single word and multi-word conditions, ex-cept for the largest Spanish-English corpus.
For thesingle word condition, it would have been surprisingif we had seen a decrease in Bleu score.
Because weare translating words that were previously untrans-latable it would be unlikely that we could do anyworse.
In the worst case we would be replacing oneword that did not occur in the reference translationwith another, and thus have no effect on Bleu.More interesting is the fact that by paraphrasingunseen multi-word units we get an increase in qual-ity above and beyond the single word paraphrases.These multi-word units may not have been observedin the training data as a unit, but each of the compo-nent words may have been.
In this case translatinga paraphrase would not be guaranteed to receivedan improved or identical Bleu score, as in the singleword case.
Thus the improved Bleu score is notable.Table 3 shows that incorporating the paraphraseprobability into the model?s feature functions plays acritical role.
Without it, the multi-word paraphrasesharm translation performance when compared to thebaseline.5.2 Manual evaluationWe performed a manual evaluation by judging theaccuracy of phrases for 100 paraphrased translationsfrom each of the sets using the manual word align-ments.1 Table 4 gives the percentage of time thateach of the translations of paraphrases were judgedto have the same meaning as the equivalent targetphrase.
In the case of the translations of single wordparaphrases for the Spanish accuracy ranged fromjust below 50% to just below 70%.
This numberis impressive in light of the fact that none of thoseitems are correctly translated in the baseline model,which simply inserts the foreign language word.
Aswith the Bleu scores, the translations of multi-wordparaphrases were judged to be more accurate thanthe translations of single word paraphrases.In performing the manual evaluation we were ad-ditionally able to determine how often Bleu was ca-pable of measuring an actual improvement in trans-lation.
For those items judged to have the samemeaning as the gold standard phrases we couldtrack how many would have contributed to a higherBleu score (that is, which of them were exactlythe same as the reference translation phrase, or hadsome words in common with the reference trans-lation phrase).
By counting how often a correctphrase would have contributed to an increased Bleuscore, and how often it would fail to increase theBleu score we were able to determine with what fre-quency Bleu was sensitive to our improvements.
Wefound that Bleu was insensitive to our translation im-provements between 60-75% of the time, thus re-1Note that for the larger training corpora fewer than 100paraphrases occurred in the first 150 and 250 sentence pairs.22Spanish-English French-EnglishCorpus size 10k 20k 40k 80k 160k 320k 10k 20k 40k 80k 160k 320kSingle word 48% 53% 57% 67%?
33%?
50%?
54% 49% 45% 50% 39%?
21%?Multi-word 64% 65% 66% 71% 76%?
71%?
60% 67% 63% 58% 65% 42%?Table 4: Percent of time that the translation of a paraphrase was judged to retain the same meaning as thecorresponding phrase in the gold standard.
Starred items had fewer than 100 judgments and should not betaken as reliable estimates.Size 1-gram 2-gram 3-gram 4-gram10k 48% 25% 10% 3%20k 60% 35% 15% 6%40k 71% 45% 22% 9%80k 80% 55% 29% 12%160k 86% 64% 37% 17%320k 91% 71% 45% 22%Table 5: The percent of the unique test set phraseswhich have translations in each of the Spanish-English training corpora prior to paraphrasinginforcing our belief that it is not an appropriate mea-sure for translation improvements of this sort.5.3 Increase in coverageAs illustrated in Figure 1, translation models sufferfrom sparse data.
When only a very small paral-lel corpus is available for training, translations arelearned for very few of the unique phrases in a testset.
If we exclude 451 words worth of names, num-bers, and foreign language text in 2,000 sentencesthat comprise the Spanish portion of the Europarltest set, then the number of unique n-grams in textare: 7,331 unigrams, 28,890 bigrams, 44,194 tri-grams, and 48,259 4-grams.
Table 5 gives the per-centage of these which have translations in each ofthe three training corpora, if we do not use para-phrasing.In contrast after expanding the phrase table usingthe translations of paraphrases, the coverage of theunique test set phrases goes up dramatically (shownin Table 6).
For the first training corpus with 10,000sentence pairs and roughly 200,000 words of text ineach language, the coverage goes up from less than50% of the vocabulary items being covered to 90%.The coverage of unique 4-grams jumps from 3% to16% ?
a level reached only after observing moreSize 1-gram 2-gram 3-gram 4-gram10k 90% 67% 37% 16%20k 90% 69% 39% 17%40k 91% 71% 41% 18%80k 92% 73% 44% 20%160k 92% 75% 46% 22%320k 93% 77% 50% 25%Table 6: The percent of the unique test set phraseswhich have translations in each of the Spanish-English training corpora after paraphrasingthan 100,000 sentence pairs, or roughly three mil-lion words of text, without using paraphrases.6 Related WorkPrevious research on trying to overcome data spar-sity issues in statistical machine translation haslargely focused on introducing morphological anal-ysis as a way of reducing the number of types ob-served in a training text.
For example, Nissen andNey (2004) apply morphological analyzers to En-glish and German and are able to reduce the amountof training data needed to reach a certain levelof translation quality.
Goldwater and McClosky(2005) find that stemming Czech and using lemmasimproves the word-to-word correspondences whentraining Czech-English alignment models.
Koehnand Knight (2003) show how monolingual texts andparallel corpora can be used to figure out appropriateplaces to split German compounds.Still other approaches focus on ways of acquiringdata.
Resnik and Smith (2003) develop a methodfor gathering parallel corpora from the web.
Oardet al (2003) describe various methods employedfor quickly gathering resources to create a machinetranslation system for a language with no initial re-sources.237 DiscussionIn this paper we have shown that significant gains incoverage and translation quality can be had by inte-grating paraphrases into statistical machine transla-tion.
In effect, paraphrases introduce some amountof generalization into statistical machine translation.Whereas before we relied on having observed a par-ticular word or phrase in the training set in order toproduce a translation of it, we are no longer tied tohaving seen every word in advance.
We can exploitknowledge that is external to the translation modelabout what words have similar meanings and usethat in the process of translation.
This method isparticularly pertinent to small data conditions, whichare plagued by sparse data problems.In future work, we plan to determine how muchdata is required to learn useful paraphrases.
The sce-nario described in this paper was very favorable tocreating high quality paraphrases.
The large numberof parallel corpora between Spanish and the otherlanguages present in the Europarl corpus allowedus to generate high quality, in domain data.
Whilethis is a realistic scenario, in that many new officiallanguages have been added to the European Union,some of which do not yet have extensive parallel cor-pora, we realize that this may be a slightly idealizedscenario.Finally, we plan to formalize our targeted manualevaluation method, in the hopes of creating a eval-uation methodology for machine translation that ismore thorough and elucidating than Bleu.AcknowledgmentsThank you to Alexandra Birch and Stephanie Van-damme for creating the word alignments.ReferencesColin Bannard and Chris Callison-Burch.
2005.
Para-phrasing with bilingual parallel corpora.
In ACL-2005.Regina Barzilay and Kathleen McKeown.
2001.
Extract-ing paraphrases from a parallel corpus.
In ACL-2001.Peter Brown, Stephen Della Pietra, Vincent Della Pietra,and Robert Mercer.
1993.
The mathematics of ma-chine translation: Parameter estimation.
Computa-tional Linguistics, 19(2):263?311, June.Chris Callison-Burch, Colin Bannard, and JoshSchroeder.
2005.
Scaling phrase-based statisti-cal machine translation to larger corpora and longerphrases.
In Proceedings of ACL.Chris Callison-Burch, Miles Osborne, and PhilippKoehn.
2006.
Re-evaluating the role of bleu in ma-chine translation.
In Proceedings of EACL.Sharon Goldwater and David McClosky.
2005.
Improv-ing statistical MT through morphological analysis.
InProceedings of EMNLP.Philipp Koehn and Kevin Knight.
2003.
Empirical meth-ods for compound splitting.
In Proceedings of EACL.Philipp Koehn, Franz Josef Och, and Daniel Marcu.2003.
Statistical phrase-based translation.
In Proceed-ings of HLT/NAACL.Philipp Koehn.
2004.
Pharaoh: A beam search decoderfor phrase-based statistical machine translation mod-els.
In Proceedings of AMTA.Philipp Koehn.
2005.
A parallel corpus for statisticalmachine translation.
In Proceedings of MT-Summit.Daniel Marcu and William Wong.
2002.
A phrase-based,joint probability model for statistical machine transla-tion.
In Proceedings of EMNLP.Sonja Nissen and Hermann Ney.
2004.
Statisti-cal machine translation with scarce resources usingmorpho-syntatic analysis.
Computational Linguistics,30(2):181?204.Doug Oard, David Doermann, Bonnie Dorr, Daqing He,Phillip Resnik, William Byrne, Sanjeeve Khudanpur,David Yarowsky, Anton Leuski, Philipp Koehn, andKevin Knight.
2003.
Desperately seeking Cebuano.In Proceedings of HLT-NAACL.Franz Josef Och and Hermann Ney.
2002.
Discrimina-tive training and maximum entropy models for statis-tical machine translation.
In Proceedings of ACL.Franz Josef Och and Hermann Ney.
2004.
The align-ment template approach to statistical machine transla-tion.
Computational Linguistics.Franz Josef Och.
2003.
Minimum error rate training forstatistical machine translation.
In Proceedings of ACL.Bo Pang, Kevin Knight, and Daniel Marcu.
2003.Syntax-based alignment of multiple translations: Ex-tracting paraphrases and generating new sentences.
InProceedings of HLT/NAACL.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
Bleu: A method for automatic evalu-ation of machine translation.
In Proceedings of ACL.Philip Resnik and Noah Smith.
2003.
The web as a par-allel corpus.
Computational Linguistics, 29(3):349?380, September.24
