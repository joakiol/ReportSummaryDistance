Anaphora Resolution in Multi-Person DialoguesPrateek Jain and Manav Ratan Mital and Sumit Kumar and Amitabha Mukerjee and Achla M. RainaIndian Institute of Technology Kanpur,Kanpur 208016 INDIA{pjain,sumit,manavrm,amit,achla}@iitk.ac.inAbstractAnaphora resolution for dialogues is a difficultproblem because of the several kinds of com-plex anaphoric references generally present indialogic discourses.
It is nevertheless a criti-cal first step in the processing of any such dis-course.
In this paper, we describe a system foranaphora resolution in multi-person dialogues.This system aims to bring together a wide arraysyntactic, semantic and world knowledge basedtechniques used for anaphora resolution.
Inthis system, the performance of the heuristics isoptimized for specific dialogues using geneticalgorithms, which relieves the programmer ofhand-crafting the weights of these heuristics.
Inour system, we propose a new technique basedon the use of anaphora chains to enable reso-lution of a large variety of anaphors, includingplural anaphora and cataphora.1 IntroductionAnaphoric references abound in natural language dis-courses and their resolution has often been identified asthe first step towards any serious discourse processing re-lated tasks.
However, any comprehensive anaphora reso-lution scheme is expected to entail the use of rich seman-tic and pragmatic knowledge representation and process-ing, and is, therefore, a complex problem.
As a result ofsuch problems, several heuristics-based approaches havebeen developed and adopted over the years to achieve par-tial solutions to the problem.The pioneering work in the area of anaphora resolu-tion was done by Hobbs (Jerry R. Hobbs, 1978) whodesigned several early syntactic and semantic heuristicsfor the same.
(Hirst, 1981) discusses several early ap-proaches to anaphora resolution in discourses.
(Denber,1998) and (Lappin and Leass, 1994) describe several syn-tactic heuristics for reflexive, reciprocal and pleonasticanaphora, among others.
Often domain-specific heuris-tics are used for anaphora resolution and fine tuned toperform well on a limited corpus, such as in (Mitkov,1998).
(Ng and Cardie, 2002) proposes a machine learn-ing approach to Anaphora Resolution but generally sta-tistical learning approaches suffer from the problems ofsmall corpuses and corpus dependent learning.
A moregeneral and comprehensive overview of state-of-the-artin anaphora resolution is given in (Mitkov, 1999) and alsoin (Mitkov et al, 2001).Few systems have been developed that are specificallyaimed at the task of anaphora resolution in discourses.ROSANA, an algorithm for anaphora resolution that fo-cuses on robustness against information deficiency in theparsed output, is described in (Stuckardt, 2001).
MARS,the Mitkov Anaphora Resolution System, is another au-tomatic, knowledge-poor anaphora resolution system thathas been implemented for several languages includingEnglish, Bulgarian and Japanese.In this paper, we describe the design and implementa-tion of Jepthah1, a rule-based system for resolving a widevariety of anaphora occurring in multi-person dialoguesin English.
In this system, we integrate several differentknowledge-poor constraints and heuristics, and operatethem over a naive character model of the entire dialogueto perform effective anaphora resolution.
In addition tousing standard heuristics, we have developed our own se-mantic and pragmatic heuristics, specific to dialogue sit-uations, that operate on this character model.
There isa weight assigned to each of these heuristics and theseweights are fine-tuned using a learning mechanism im-plemented by genetic algorithms.
We use the linguisticfeature of anaphoric chains, present in dialogues, to re-solve a relatively large class of anaphora.1name of a wise Isreali judge in the Bible2 JepthahIn Jepthah, we adopt an integrated approach towards re-solving various different kinds of anaphors occurring indialogue situations.
In this approach we fuse togetherseveral heuristics with a new kind of computational lin-guistic insight ?
that of the deployment of anaphorachains and we develop a graph-based technique for han-dling the resolution of various anaphors.
An anaphorachain may be described as a referential chain compris-ing series of mutually co-referential anaphoric elements,generally of more than one type, headed by a referentialelement.The class of anaphors that we aim to resolve isfairly large and includes pronouns, reflexives and deic-tic anaphors.
In terms of distribution, we are dealing withanaphors in subject, object and modifier positions, pos-sessive reflexive, and cataphora.
It is may be mentionedhere that we deal only with unambiguous cases of pluralpronouns, such as both of us, two of you, etc.
These arethe cases in which the domain of the pronouns is clearlyquantified, unlike the case of such instances as all of usor they, etc.2.1 Graph-theoretic ApproachThe entire operation is centered around a graph formu-lation of the resolution problem in the perspective of thedialogue.
We extract all the nouns and pronouns presentin the dialogue.
Assume there are n nouns and p pro-nouns in the dialogue.
Let the ith noun be represented asNi, with i ?
n and that Pi represents the ith pronoun,with i ?
p. Now, we construct a graph representation forthe problem as follows.
Let G be the graph that we areinterested in formulating, comprising of a node for everyNi and Pj .Let NGi be the node corresponding to the nounNi and PGj be the node corresponding to the pronoun Pj .Thus, we can split the set of vertices of this graph VG intotwo parts, the set consisting of NGi , ?i ?
n and the setconsisting of PGj , ?j ?
p. The set of edges EG for thisgraph G comprises of two types of directed edges and isconstructed as follows.
Construct a set of edges E1 whichincludes a directed edge Ei?j from PGi to NGj , for allpairs PGi and NGj .
The other set E2 includes a directededge E?i?j from PGi to PGj for all pair of nodes PGi andPGj such that i 6= j.
Clearly, we have EG = E1 ?
E2.
Letus define a property L on the paths in this graph as fol-lows ?
a path p satisfies the property L iff it consists of asequence of edges Ei ?
EG (i ?
length(p)) with exactlyone edge Ef from the set E1 and the condition that this isthe last edge in the sequence, i.e., Elength(p) ?
Ef .Intuitively, this graph represents the set of possibleanaphor-antecedent relationships.
The set of possible ref-erents of an anaphor represented by the node PGi in thegraph G consists of all possible distinct nodes NGk thatcan be reached from PGi using paths that satisfy the prop-erty L. Let this set be represented as Si.
Note herethat paths as above of length ?
2 represent anaphoricchains present in the dialogue.
One or more edges inthese paths are from one anaphor to another and representco-reference amongst these anaphors.
The antecedentspace of an anaphor Pi consists of all nouns and pronounswhose corresponding nodes in the graph G are reachablefrom PGi by traversing a single edge belonging to EG.Now, the idea here is to process this antecedent space andrank all the nodes in Si to determine the most likely an-tecedent for the anaphor Pi.
This ranking is done by at-taching weights to the edges present in the graph.Every edge is awarded a particular weight (less than1.0), that is evaluated for every edge using a set of heuris-tics described in section 2.4.
The rank of each node NGkin the set Si is determined by the total weight Wik for thatnode.
Wik is computed as follows ?
let the weight Wp ofeach path p be defined as the product of the weights ofall the edges lying on that path.
Then, Wik is the sum ofthe weights of all the paths from PGi to NGk , i.e.,?p Wp.Hence, for anaphora resolution, we need to basically de-sign an algorithm or a function to compute the weight foreach edge in the graph.2.2 System DesignThe input dialogue is passed to the front end which com-prises of the Stanford Serialized Parser and PoS tagger.The parser gives the best parse for every input sentence,each of which are then subsequently processed.
In thefirst step we extract all the proper nouns present in thedialogue and initialize our character model base and thegraph G that was explained in section 2.1.
We thentake the sequence of parses corresponding to each sub-sequent dialogue by a speaker and process them sequen-tially.
Techniques for anaphora resolution are then ap-plied in two phases.
In the first phase, a set of constraintsis applied to this graph, to prune out edges that representany unfeasible co-references.
In the second phase, a setof heuristics are applied to award weights to edges repre-senting these relationships.
After the processing is overand all weights have been obtained, the permissible an-tecedents for each anaphor are ranked and the most likelyantecedent for each is outputted.
In case there is a plu-ral anaphor, with quantification over x nouns, the top xlikely antecedents are outputted.While processing the dialogue, a naive character build-ing is implemented.
This is done mainly by focusing onthe verbs in the sentences.
The subject and object nounsassociated with these verbs are selected and their relation-ship is put in the character model base associated with thespeaker of the corresponding dialogue.
The system main-tains an apriori knowledge base with it containing infor-mation like ontology and functionalities of several nouns.This combination of apriori and assimilated knowledgeis then used to apply certain semantic and pragmatic con-straints/heuristics on the graph, as shown in the followingsections.2.3 ConstraintsWe apply the set of restrictions prior to the set of prefer-ences, thereby narrowing down the candidate set as earlyas possible.
The list of constraints that implement theserestrictions in Jepthah are listed as follows ?1.
Deictic Constraint: This is a set of simple con-straints that are specific to dialogue settings becausein such settings we can have the concept of framesof reference with regard to the various speakers in-volved in the dialogue action.2.
Non-coreference (Mitkov, 1999): Syntactic fea-tures present in a sentence often lend themselvesto be expressed as constraints on anaphora refer-ence.
These features are captured by our non-coreference constraints which stipulate that certainpairs of anaphor and noun phrases within the samesentence cannot refer to the same antecedent.3.
Gender, Number and Person Agreement: This isa low level constraint which requires that anaphorsand their antecedents must agree in gender, numberand person respectively.4.
Constraint on Reflexive Pronoun: A reflexive pro-noun such as himself, herself, etc must refer to thesubject or the object of the verb in whose clause itlies.
In case of ellipsis, however, it may refer to thesubject or object of the next higher verb to which theclause is attached.5.
Semantic Consistency (Mitkov, 1999): This con-straint enforces same semantics of the antecedent asthe anaphor under consideration.2.4 HeuristicsEach preference or heuristic, has a certain weight andawards certain points to every anaphor-antecedent rela-tionship.
These points are a measure of the likelihood ofthat anaphor-antecedent relationship.
The weight of anedge is the sum total of the weights awarded by each in-dividual heuristic to the anaphor-antecedent relationship.The heuristics used in our system are enumerated as fol-lows ?1.
Definiteness (Lappin and Leass, 1994): Accord-ing to this heuristic, nouns that are preceded by ademonstrative pronoun or a definite article are morelikely to be antecedents and are awarded highercredibilities.2.
Non-prepositional NP (Lappin and Leass, 1994):This heuristic states that a noun phrase which occurswithin a prepositional phrase is less probable to bean antecedent to an anaphor and consequently, it isawarded less credibility.3.
Pleonastic (Lappin and Leass, 1994): This heuris-tic is based on the observation that there exist somesyntactic patterns such that every it anaphor occur-ring in any of those patterns must be pleonastic.4.
Syntactic Parallelism (Lappin and Leass, 1994):As per this heuristic, preference is given to nounphrases with the same syntactic function as theanaphor.5.
Recency (Mitkov, 1999): This is a very simpleheuristic according to which, everything else beingcomparable, a higher credibility is awarded to theantecedent nearer to the anaphor.6.
Semantic Parallelism (Lappin and Leass, 1994):This heuristic gives preference to those noun phraseswhich have the same semantic role as the anaphorin question.
This is a useful heuristic and can beimplemented by a system that can identify semanticroles.7.
Pragmatic Heuristics: We use certain pragmaticheuristics that we have identified to be very spe-cific to dialogue settings.
These are of the followingkinds?
If one speaker asks a question, then the nextspeaker is likely to be the antecedent of the youthat may occur in the former?s sentence.?
If a speaker makes an exclamation then he islikely to be the antecedent of the you in thespeech of the speaker just before him.8.
Naive Character Building: This refers to a naivecharacter model that we have used to implement arestricted knowledge-based representation of the di-alogue, woven around all the noun entities that arepresent in the dialogue.
To this end, we use a certainamount of world knowledge that is present aprioriwith the system, in the form of ontology and func-tionality of possible noun entities.
For instance, weassociate actions with each character based on theirsubject object relationship with the verbs that occurin the dialogues.
Now for an anaphor we see if apossible antecedent has functionality of the actionassociated with the anaphor, implied by the verb ofthe sentence.
if it is so, we then give higher credibil-ity to this particular antecedent.Table 1: ResultsCorpus % AccuracyShaw?s play - Pygmalion 62Shaw?s play - Man and Superman 67Hand-Crafted Dialogue I 83Hand-Crafted Dialogue II 812.5 Learning approachIn most systems ((Mitkov, 1998),(Lappin and Leass,1994)) the weights that are assigned for differentanaphor-antecedent relationships are programmer depen-dent.
Fixing these values in a adhoc fashion can clearlygive rise to unstable behaviour.
In our work, we usemanually tagged corpora to evaluate the effectivenessof a given weight assignment; these can then be tunedusing Genetic Algorithms(Goldberg, 1989).
We use 2-point crossover and mutation which are used in StandardGenetic Algorithm for Real Variables(Deb and Kumar,1995).3 ResultsWe used our system for anaphora resolution in the fol-lowing types of dialogue corpora:?
Dialogues written manually, woven broadly in a stu-dent environment?
Fragments from the plays by the writer G. B. ShawOur System gave nearly 65% accuracy on Shaw?s playsand almost 80% accuracy on our own ?hand crafted?
dia-logues [Table:1].
In the table, the name ?hand-crafted di-alogues?
refers to sample dialogues that the authors wrotethemselves to test the performance of the system.The genetic algorithms that we use help in fine-tuningweights according to the particular corpus, and show ap-preciable increase in accuracy.4 ConclusionsWe have implemented an automatic, knowledge-basedanaphora resolution system that works for dialogic dis-courses.
The lack of availability of any standard corpora(Mitkov, 1999) is a major drawback in case of anaphoraresolution systems in general and those for dialogues inparticular.
The original contribution of this system ismainly two-fold.
First, the anaphora resolution systemthat we have implemented uses an innovative graph tech-nique, based on the idea of anaphora chaining, that makesit possible to resolve such references as cataphora andplural anaphora.
Secondly, we give an algorithm whichuses naive character building to apply various semanticand world-knowledge based heuristics to the process ofanaphora resolution.
The results obtained from the sys-tem indicate a fairly high accuracy, though an extensiveevaluation of the various resolution algorithms as well asthe system as a whole remains to be done.ReferencesK.
Deb and A. Kumar.
1995.
Real-coded genetic al-gorithms with simulated binary crossover: Studies onmultimodal and multiobjective problems.
ComplexSystems, 9(6):431?454.M.
Denber.
1998.
Automatic resolution of anaphora inenglish.
Technical report, Eastman Kodak Co., Imag-ing Science Division.D.
E. Goldberg.
1989.
Genetic Algorithms in Search,Optimization, and Machine Learning.
Addison-Wesley Publishing Company, Reading, MA.Graeme Hirst.
1981.
Discourse-oriented anaphoraresolution in natural language understanding: A re-view?.
American Journal of Computational Linguis-tics, 7(2):85?98, April-June.Jerry R. Hobbs.
1978.
Resolving pronoun references.Lingua, 44:311?338.Shalom Lappin and Herbert J. Leass.
1994.
An algo-rithm for pronominal anaphora resolution.
Computa-tional Linguistics, 20(4):535?561.Ruslan Mitkov, Branimir Boguraev, and Shalom Lappin.2001.
An Introduction to the Special Issue on Com-putational Anaphora Resolution.
Computational Lin-guistics, 27(4).Ruslan Mitkov.
1998.
Robust pronoun resolution withlimited knowledge.
In COLING-ACL, pages 869?875.R.
Mitkov.
1999.
Anaphora Resolution: The Stateof the Art.
Working paper (Based on the COL-ING?98/ACL?98 tutorial on anaphora resolution).Vincent Ng and Claire Cardie.
2002.
Combining sampleselection and error-driven pruning for machine learn-ing of coreference rules.
In Proceedings of the 2002Conference on Empirical Methods in Natural Lan-guage Processing, Association for Computational Lin-guistics.Roland Stuckardt.
2001.
Design and Enhanced Evalua-tion of a Robust Anaphor Resolution Algorithm.
Com-putational Linguistics, 27(4):479?506, December.
