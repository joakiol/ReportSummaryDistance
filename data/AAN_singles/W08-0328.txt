Proceedings of the Third Workshop on Statistical Machine Translation, pages 179?182,Columbus, Ohio, USA, June 2008. c?2008 Association for Computational LinguisticsUsing Moses to Integrate Multiple Rule-Based Machine Translation Enginesinto a Hybrid SystemAndreas Eisele1,2, Christian Federmann2, Herve?
Saint-Amand1,Michael Jellinghaus1, Teresa Herrmann1, Yu Chen11: Saarland University, Saarbru?cken, Germany2: DFKI GmbH, Saarbru?cken, GermanyAbstractBased on an architecture that allows to com-bine statistical machine translation (SMT)with rule-based machine translation (RBMT)in a multi-engine setup, we present new resultsthat show that this type of system combinationcan actually increase the lexical coverage ofthe resulting hybrid system, at least as far asthis can be measured via BLEU score.1 Introduction(Chen et al, 2007) describes an architecture thatallows to combine statistical machine translation(SMT) with one or multiple rule-based machinetranslation (RBMT) systems in a multi-engine setup.It uses a variant of standard SMT technology to aligntranslations from one or more RBMT systems withthe source text and incorporated phrases extractedfrom these alignments into the phrase table of theSMT system.
Using this approach it is possible toemploy a vanilla installation of the open-source de-coder Moses1 (Koehn et al, 2007) to find good com-binations of phrases from SMT training data withthe phrases derived from RBMT.
A similar methodwas presented in (Rosti et al, 2007).This setup provides an elegant solution to thefairly complex task of integrating multiple MT re-sults that may differ in word order using only stan-dard software modules, in particular GIZA++ (Ochand Ney, 2003) for the identification of buildingblocks and Moses for the recombination, but theauthors were not able to observe improvements in1see http://www.statmt.org/moses/terms of BLEU score.
A closer investigation re-vealed that the experiments had suffered from a cou-ple of technical difficulties, such as mismatches incharacter encodings generated by different MT en-gines and similar problems.
This motivated us tore-do these experiments in a somewhat more sys-tematic way for this year?s shared translation task,paying the required attention to all the technical de-tails and also to try it out on more language pairs.2 System ArchitectureFor conducting the translations, we use a multi-engine MT approach based on a ?vanilla?
MosesSMT system with a modified phrase table as a cen-tral element.
This modification is performed by aug-menting the standard phrase table with entries ob-tained from translating the data with several rule-based MT systems.
The resulting phrase table thuscombines statistically gathered phrase pairs withphrase pairs generated by linguistic rules.Basing its decision about the final translation onthe obtained ?combined?
phrase table, the SMT de-coder searches for the best translation by recombin-ing the building blocks that have been contributed bythe different RBMT systems and the original SMTsystem trained on Europarl data.A sketch of the overall architecture is given inFig.
1, where the lighter parts represent the mod-ules and data sets used in purely statistical MT,and the darker parts are the additional modules anddata sets derived from the rule-based engines.
Thelast word in the proposed setup is thus given to theSMT decoder, which can recombine (and potentiallyalso tear apart) linguistically well-formed constructs179ModelLanguagePhrasetableCombinedAlignment,PhraseExtractionDecoderSMTRule?basedMT enginesParallelCorpusSourceTextTargetTextMonolingualCorpusHypothesesCountingSmoothingFigure 1: Hybrid architecture of the systemfrom the rule-based engines?
output.2.1 The Combined Phrase TableThe combined phrase table is built from the orig-inal Moses phrase table and separate phrase tablesfor each of the RBMT systems that are used in oursetup.
Since the original phrase table is createdduring the training process of the Moses decoderwith the Europarl bilingual corpus as training ma-terial, it comprises general knowledge about typicalconstructions and vocabulary from the Europarl do-main.
Therefore, a standard Moses SMT system is,in principle, well adapted for input from this do-main.
However, it will have problems in dealingwith vocabulary and structures that did not occur inthe training data.
The additional phrase tables aregenerated separately for each RBMT system fromthe source text and its translation by the respectivesystem.
By using a combined phrase table that in-cludes the original Moses phrase table as well as thephrase tables from the RBMT systems, the hybridsystem can both handle a wider range of syntacticconstructions and exploit knowledge that the RBMTsystems possess about the particular vocabulary ofthe source text.3 Implementation3.1 MT Systems and Knowledge SourcesApart from the Moses SMT system, we used aset of six rule-based MT engines that are partlyavailable via web interfaces and partly installed lo-cally.
The web interfaces are provided by Al-tavista Babelfish (based on Systran), SDL, ProMTand Lucy (a recent offspring of METAL).
All ofthem deliver significantly different output trans-lations.
Locally installed systems are OpenLo-gos (for German?English, English?Spanish andEnglish?French) and translatePro by lingenio (forGerman?English).
The language model for our pri-mary setup is based on the Europarl corpus whereasthe English Gigaword corpus served as training datafor a contrastive setup that was created for the trans-lation direction German?English only.3.2 Alignment of RBMT outputAs already mentioned above, the construction of theRBMT system specific phrase tables is a major partof the overall system architecture.
Such an RBMTphrase table is generated from a bilingual corpusconsisting of the input text and its translation bythe respective RBMT system.
Because this corpushas the mere size of the text to be translated, it usu-ally is not big enough to ensure the statistical meth-ods for phrase table building of the Moses system towork.
Therefore, we create the alignments betweenthe RBMT input and output with help of another tool(Theison, 2007) that is based on knowledge learnedin a previously conducted training phase with an ap-propriately bigger corpus.
On the basis of the align-ments created in this manner, the Moses trainingscript provides a phrase table that consists of thesource text vocabulary.
These steps are carried outfor each one of the six RBMT systems leading tosix source text specific phrase tables which are thencombined with the original Moses phrase table.3.3 Combination of Phrase TablesThe combination process basically consists of theconcatenation of the Moses phrase table and the pre-viously created RBMT phrase tables with one mi-nor adjustment: The phrase table resulting from thiscombination now also features additional columnsindicating which system each phrase table entryoriginated from.
For each new source text, theRBMT phrase tables have to be created from scratchand incorporated into a new combined phrase table.3.4 TuningThe typical process for creating an SMT system withthe Moses toolkit includes a tuning step in which180Europarl NewsCommentaryde-en en-de fr-en en-fr es-en en-es de-en en-de fr-en en-fr es-en en-esSMT 22.81 19.78 24.18 21.62 31.68 24.46 14.24 9.75 11.60 12.24 17.27 14.48Hybrid 27.85 20.75 28.12 28.82 33.15 32.31 17.36 13.57 17.66 20.71 22.16 22.55RBMT1?
13.34 11.09 ??
17.19 ??
18.63 14.90 12.34 ??
15.11 ??
17.13RBMT2 16.19 12.06 ??
??
??
??
16.66 13.64 ??
??
??
?
?RBMT3 16.32 10.88 18.18 20.38 19.32 20.89 16.88 12.53 17.20 18.82 19.00 19.98RBMT4 15.58 12.09 19.00 22.20 18.99 21.69 17.41 13.93 17.73 20.85 19.14 21.70RBMT5 15.58 9.54 21.36 12.98 18.47 20.59 15.99 11.05 18.65 19.49 20.50 20.02RBMT6 13.96 9.44 17.16 18.91 18.01 19.18 15.08 10.41 16.86 17.82 18.70 19.97Table 1: Performance of baseline SMT system, our system and RBMT systems (BLEU scores)the system searches for the best weight configura-tion for the columns in the phrase table while givena development set to be translated, and correspond-ing reference translations.
In our hybrid setup, it isequally essential to conduct tuning since the com-bined phrase table we use contains 7 more columnsthan the original Moses phrase table.
All thesecolumns are given the same default weight initiallyand thus still need be to be tuned to more meaning-ful values.
From this year?s Europarl developmentdata the first 200 sentences of each of the data setsdev2006, test2006, test2007 and devtest2006 wereconcatenated to build our development set.
This setof 800 sentences was used for Minimum Error RateTraining (Och, 2003) to tune the weights of our sys-tem with respect to BLEU score.4 ResultsIn order to be able to evaluate our hybrid approachesin contrast to stand-alone rule-based approaches, wealso calculated BLEU scores for the translationsconducted by the RBMT systems used in the hy-brid setup.
Our hybrid system is compared to a SMTbaseline and all the 6 RBMT systems that we used.Table 1 shows the evaluation of all the systems interms of BLEU score (Papineni et al, 2002) with thebest score highlighted.
The empty cells in the tableindicate the language pairs which are not availablein the corresponding systems2.
The SMT system isthe one upon which we build the hybrid system.
Ac-cording to the scores, the hybrid system producesbetter results than the baseline SMT system in all2The identities of respective RBMT systems are not revealedin this paper.
RBMT1 is evaluated on the partial results pro-duced due to some technical problems.cases.
The difference between our system and thebaseline is more significant for out-of-domain tests,where gaps in the lexicon tend to be more severe.Figure 2 illustrates an example of how the hy-brid system differs from the baseline SMT systemand how it benefits from the RBMT systems.
Theexample lists the English translations of the sameGerman sentence (from News Commentary test set)from different systems involved in our experiment.Neither the word ?Pentecost?
nor its German trans-lation ?Pfingsten?
has appeared in the training cor-pus.
Therefore, the SMT baseline system cannottranslate the word and chooses to leave the wordas it is whereas all the RBMT systems translate theword correctly.
The hybrid system appears to havethe corresponding lexicon gap covered by the ex-tra entries produced by the RBMT systems.
On theother side, these additional entries may not alwaysbe helpful.
The errors in RBMT outputs can be sig-nificant noise that destroys the correct informationin the SMT system.
In the example translation pro-duced by the hybrid system, there is a comma miss-ing after ?in addition?, which appears to be frequentin the RBMT outputs.5 OutlookThe results reported in this paper are still somewhatpreliminary in the sense that many possible (includ-ing some desirable) variants of the setup could notbe tried out due to lack of time.
In particular, wethink that the full power of our approach on out-of-domain test data can only be exploited with thehelp of large language models trained on out-of-domain text, but could not yet try this systematically.Furthermore, the presence of multiple instances of181Source Daru?ber hinaus gibt es je zwei Feiertage zu Ostern, Pfingsten, und Weihnachten.Reference In addition, Easter, Pentecost, and Christmas are each two-day holidays.Moses In addition, there are two holidays, pfingsten to Easter, and Christmas.Hybrid In addition there are the two holidays to Easter, Pentecost and Christmas.RBMT1 Furthermore there are two holidays to Easter, Pentecost and Christmas .RBMT2 Furthermore there are two holidays each at Easter, Pentecost and Christmas.RBMT3 In addition there are each two holidays to Easters, Whitsun, and Christmas.RBMT4 In addition, there is two holidays to Easter, Pentecost, and Christmas.RBMT5 Beyond that there are ever two holidays to Easter, Whitsuntide, and Christmas.RBMT6 In addition it gives two holidays apiece to easter, Pentecost, and Christmas.Figure 2: German-English translation examplesthe same phrase pair (with different weight) in thecombined phrase table causes the decoder to gen-erate many instances of identical results in differ-ent ways, which increases computational effort andsignificantly decreases the number of distinct casesthat are considered during MERT.
We suspect that amodification of our scheme that avoids this problemwill be able to achieve better results, but experimentsin this direction are still ongoing.The approach presented here combines thestrengths of multiple systems and is different fromrecent work on post-correction of RBMT output aspresented in (Simard et al, 2007; Dugast et al,2007), which focuses on the improvement of a sin-gle RBMT system by correcting typical errors viaSMT techniques.
These ideas are independent and asuitable combination of them could give rise to evenbetter results.AcknowledgmentsThis work was supported by the EuroMatrix projectfunded by the European Commission (6th Frame-work Programme).
We thank Martin Kay, HansUszkoreit, and Silke Theison for interesting discus-sions and practical help, and two anonymous re-viewers for hints to improve the paper.ReferencesYu Chen, Andreas Eisele, Christian Federmann, EvaHasler, Michael Jellinghaus, and Silke Theison.
2007.Multi-engine machine translation with an open-sourceSMT decoder.
In Proceedings of WMT07, pages 193?196, Prague, Czech Republic, June.
Association forComputational Linguistics.Lo?
?c Dugast, Jean Senellart, and Philipp Koehn.
2007.Statistical post-editing on SYSTRAN?s rule-basedtranslation system.
In Proceedings of WMT07, pages220?223, Prague, Czech Republic, June.
Associationfor Computational Linguistics.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran, RichardZens, Chris Dyer, Ondrej Bojar, Alexandra Con-stantin, and Evan Herbst.
2007.
Moses: Open sourcetoolkit for statistical machine translation.
In Proc.
ofACL Demo and Poster Sessions, pages 177?180, Jun.Franz Josef Och and Hermann Ney.
2003.
A system-atic comparison of various statistical alignment mod-els.
Computational Linguistics, 29(1):19?51, Mar.Franz Josef Och.
2003.
Minimum error rate training forstatistical machine translation.
In Proceedings of ACL,Sapporo, Japan, July.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
Bleu: A method for automatic evalu-ation of machine translation.
In Proceedings of ACL.Antti-Veikko Rosti, Necip Fazil Ayan, Bing Xiang, Spy-ros Matsoukas, Richard Schwartz, and Bonnie J. Dorr.2007.
Combining translations from multiple machinetranslation systems.
In Proceedings of the Conferenceon Human Language Technology and North Americanchapter of the Association for Computational Linguis-tics Annual Meeting (HLT-NAACL?2007), pages 228?235, Rochester, NY, April 22-27.Michel Simard, Nicola Ueffing, Pierre Isabelle, andRoland Kuhn.
2007.
Rule-based translation withstatistical phrase-based post-editing.
In Proceedingsof WMT07, pages 203?206, Prague, Czech Republic,June.
Association for Computational Linguistics.Silke Theison.
2007.
Optimizing rule-based machinetranslation output with the help of statistical methods.Diploma thesis, Saarland University.182
