Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 10?17,Avignon, France, April 23 - 27 2012. c?2012 Association for Computational LinguisticsThe Role of Emotional Stability in Twitter ConversationsFabio CelliCLIC-CIMeCUniversity of Trentofabio.celli@unitn.itLuca RossiLaRiCAUniversity of Urbinoluca.rossi@uniurb.itAbstractIn this paper, we address the issue of howdifferent personalities interact in Twitter.
Inparticular we study users?
interactions usingone trait of the standard model known as the?Big Five?
: emotional stability.
We collecteda corpus of about 200000 Twitter posts andwe annotated it with an unsupervised person-ality recognition system.
This system exploitslinguistic features, such as punctuation andemoticons, and statistical features, such as fol-lowers count and retweeted posts.
We testedthe system on a dataset annotated with per-sonality models produced from human judge-ments.
Network analysis shows that neuroticusers post more than secure ones and have thetendency to build longer chains of interactingusers.
Secure users instead have more mutualconnections and simpler networks.1 Introduction and BackgroundTwitter is one of the most popular micro-bloggingweb services.
It was founded in 2006, and allowsusers to post short messages up to 140 characters oftext, called ?tweets?.Following the definition in Boyd and Ellison(2007), Twitter is a social network site, but is sharessome features with blogs.
Zhao and Rosson (2009)highlights the fact that people use twitter for a va-riety of social purposes like keeping in touch withfriends and colleagues, raising the visibility of theirinterests, gathering useful information, seeking forhelp and relaxing.
They also report that the waypeople use Twitter can be grouped in three broadclasses: people updating personal life activities,people doing real-time information and people fol-lowing other people?s RSS feeds, which is a way tokeep informed about personal intersts.According to Boyd et al (2010), there are manyfeatures that affect practices and conversations inTwitter.
First of all, connections in Twitter are di-rected rather than mutual: users follow other users?feeds and are followed by other users.
Public mes-sages can be addressed to specific users with thesymbol @.
According to Honeycutt and Herring(2009) this is used to reply to, to cite or to includesomeone in a conversation.
Messages can be markedand categorized using the ?hashtag?
symbol #, thatworks as an aggregator of posts having somethingin common.
Another important feature is that postscan be shared and propagated using the ?retweet?option.
Boyd et al (2010) emphasize the fact thatretweeting a post is a means of participating in a dif-fuse conversation.
Moreover, posts can be marked asfavorites and users can be included into lists.
Thosepractices enhance the visibility of the posts or theusers.In recent years the interest towards Twitter raisedin the scientific community, especially in Informa-tion Retrieval.
For example Pak and Paroubek(2010) developed a sentiment analysis classifierfrom Twitter data, Finin et al (2010) performedNamed Entity Recognition on Twitter using crowd-sourcing services such as Mechanical Turk1 andCrowdFlower2, and Zhao et al (2011) proposed aranking algorithm for extracting topic keyphrasesfrom tweets.
Of course also in the personality recog-1https://www.mturk.com/mturk/welcome2http://crowdflower.com10nition field there is a great interest towards the anal-ysis of Twitter.
For example Quercia et al (2011)analyzed the correlations between personality traitsand the behaviour of four types of users: listeners,popular, hi-read and influential.In this paper, we describe a personality recog-nition tool we developed in order to annotate datafrom Twitter and we analyze how emotional stabil-ity affects interactions in Twitter.
In the next sec-tion, given an overview of personality recognitionand emotional stability, we will describe our person-ality recognition system in detail and we present thedataset we collected from Twitter.
In the last twosections we report and discuss the results of the ex-periment and we provide some provisional conclu-sions.2 Personality Recognition2.1 Definition of Personality and EmotionalStabilityPersonality is a complex of attributes that charac-terise a unique individual.
Psychologists, see for ex-ample Goldberg (1992), formalize personality alongfive traits known as the ?Big Five?, a model intro-duced by Norman (1963) that has become a stan-dard over the years.
The five traits are the following:Extraversion (sociable vs shy); Emotional stabil-ity (calm vs insecure); Agreeableness (friendly vsuncooperative); Conscientiousness (organized vscareless); Openness (insightful vs unimaginative).Among all the 5 traits, emotional stability plays acrucial role in social networks.
Studying offline so-cial networks, Kanfer and Tanaka (1993) report thatsecure (high emotional stability) subjects had morepeople interacting with them.
Moreover, Van Zalk etal.
(2011) reports that youths who are socially anx-ious (low emotional stability) have fewer friends intheir network and tend to choose friends who are so-cially anxious too.
We will test if it is true also inonline social networks.2.2 Previous Work and State of the ArtComputational linguistics community started to payattention to personality recognition only recently.A pioneering work by Argamon et al (2005) clas-sified neuroticism and extraversion using linguisticfeatures such as function words, deictics, appraisalexpressions and modal verbs.
Oberlander and Now-son (2006) classified extraversion, emotional sta-bility, agreeableness and conscientiousness of blogauthors?
using n-grams as features.
Mairesse et al(2007) reported a long list of correlations betweenbig5 personality traits and 2 feature sets, one fromlinguistics (LIWC, see Pennebaker et al (2001) fordetails) and one from psychology (RMC, see Colt-heart (1981)).
Those sets included features suchas punctuation, length and frequency of words used.They obtained those correlations from psychologi-cal factor analysis on a corpus of Essays (see Pen-nebaker and King (1999) for details) annotated withpersonality, and developed a supervisd system forpersonality recognition available online as a demo3.In a recent work, Iacobelli et al (2011) tested dif-ferent feature sets, extracted from a corpus of blogs,and found that bigrams and stop words treated asboolean features yield very good results.
As is statedby the authors themselves, their model may overfitthe data, since the n-grams extracted are very few ina very large corpus.
Quercia et al (2011) predictedpersonality scores of Twitter users by means ofnetwork statistics like following count and retweetcount, but they report root mean squared error, notaccuracy.
Finally Golbeck et al (2011) predicted thepersonality of 279 users from Facebook using eitherlinguistic.
such as word and long-word count, andextralinguistic features, such as friend count and thelike.
The State-of-the-art in personality recognitionE.Stab.
Arg05 Ob06 Mai07 Ia11 Gol11acc 0.581 0.558 0.573 0.705 0.531Table 1: State-of-the-Art in Personality Recognition fromlanguage for the emotional stability trait.is reported in table 1.
Argamon (Arg05) and Ober-lander (Ob06) use naive bayes, Mairesse (Mai07)and Iacobelli (Ia11) use support vector machines andGolbeck (Gol11) uses M5 rules with a mix of lin-guistic and extralinguistic features.2.3 Description of the UnsupervisedPersonality Recognition ToolGiven a set of correlations between personality traitsand some linguistic or extralinguistic features, we3http://people.csail.mit.edu/francois/research/personality/demo.html11are able to develop a system that builds models ofpersonality for each user in a social network sitewhose data are publicly available.
In our system per-sonality models can take 3 possible values: secure(s), neurotic (n) and omitted/balanced (o), indicat-ing that a user do not show any feature or shows boththe features of a neurotic and a secure user in equalmeasure.
Many scholars provide sets of correlationsbetween some cues and the traits of personality for-malized in the big5.
In our system we used a fea-ture set taken partly from Mairesse et al (2007) andpartly from Quercia et al (2011).
The former pro-vides a long list of linguistic cues that correlate withpersonality traits in English.
The latter provides thecorrelations between personality traits and the countof following, followers, listed and retweeted.We selected the features reported in table 2, sincethey are the most frequent in the dataset for whichwe have correlation coefficients with emotional sta-bility.Features Corr.
to Em.
Stab.
fromexclam.
marks -.05* Mai07neg.
emot.
-.18** Mai07numbers .05* Mai07pos.
emot.
.07** Mai07quest.
marks -.05* Mai07long words .06** Mai07w/t freq.
.10** Mai07following -.17** Qu11followers -.19** Qu11retweeted -.03* Qu11Table 2: Features used in the system and their Pearson?scorrelation coefficients with personality traits as reportedin Mairesse et al (2007) and Quercia et al (2011).
* = psmaller than .05 (weak correlation), ** = p smaller than.01 (strong correlation)Exclamation marks: the count of !
in a post;negative emoticons: the count of emoticons ex-pressing negative feelings in a post; numbers: thecount of numbers in the post; positive emoticons:the count of emoticons expressing positive feelingsin a post; question marks: the count of ?
in a post;long words: count of words longer than 6 charac-ters in the post; word/token frequency: frequencyof repeated words in a post, defined aswt =repeated wordspost word countfollowing count: the count of users followed; fol-lowers count: the count of followers; retweetedcount: the amount of user?s posts retweeted.The processing pipeline, as shown in figure 1, isdivided in three steps: preprocess, process and eval-uation.Figure 1: Unsupervised Personality Recognition Systempipeline.In the preprocessing phase the system randomlysamples a predefined number of posts (in this case2000) in order to capture the average occurrence ofeach feature.
In the processing phase the systemgenerates one personality model per post matchingfeatures and applying correlations.
If the systemfinds feature values above the average, it incrementsor decrements the score associated to emotional sta-bility, depending on a positive or negative correla-tion.
The list of all features used and their correla-tions with personality traits provided by Mairesse etal.
(2007) (Mai07) and Quercia et al (2011) (Qu11),is reported in table 2.In order to evaluate the personality models gen-erated, the system compares all the models gener-ated for each post of a single user and retrieves onemodel per user.
This is based on the assumption that12one user has one and only one complex personality,and that this personality emerges at a various levelsfrom written text, as well as from other extralinguis-tic cues.
The system provides confidence and vari-ability as evaluation measures.
Confidence gives ameasure of the consistency of the personality model.It is defined asc =tpMwhere tp is the amount of personality models (forexample ?s?
and?s?, ?n?
and ?n?
), matching whilecomparing all posts of a user and M is the amountof the models generated for that user.
Variabilitygives information about how much one user tendsto write expressing the same personality traits in allthe posts.
It is defined asv =cPwhere c is confidence score and P is the count ofall user?s posts.
The system can evaluate personal-ity only for users that have more than one post, theother users are discarded.Our personality recognition system is unsuper-vised.
This means that it exploits correlations in or-der to build models and does not require previouslyannotated data to modelize personality.
Since theevaluation is performed directly on the dataset weneed to test the system before using it.
In the fol-lowing section we describe how we tested system?sperformance.2.4 Testing the Unsupervised PersonalityRecognition ToolWe run two tests, the first one to evaluate the accu-racy in predicting human judges on personality, andthe second one to evaluate the performance of thesystem on Twitter data.
In the first one, we com-pared the results of our system on a dataset, calledPersonage (see Mairesse and Walker (2007)), an-notated with personality ratings from human judges.Raters expressed their judgements on a scale from 1(low) to 7 (high) for each of the Big Five personal-ity traits on English sentences.
In order to obtain agold standard, we converted this scale into our three-values scheme applying the following rules: if valueis greater or equal to 5 then we have ?s?, if value is4 we have ?o?
and if value is smaller or equal to 3we have ?n?.
We used a balanced set of 8 users (20sentences per user), we generated personality mod-els automatically and we compared them to the goldstandard.
We obtained an accuracy of 0.625 over amajority baseline of 0.5, which is in line with thestate of the art.In the second test we compared the output of oursystem to the score of Analyzewords4, an online toolfor Twitter analysis based on LIWC features (seePennebaker et al (2001)).
This tool does not providebig5 traits but, among others, it returns scores for?worried?
and ?upbeat?, and we used those classesto evaluate ?n?
and ?s?
respectively.
We randomlyextracted 18 users from our dataset (see section 3 fordetails), 10 neurotics and 8 secure, and we manuallychecked whether the classes assigned by our systemmatched the scores of Analyzewords.
Results, re-p r f1n 0.8 0.615 0.695s 0.375 0.6 0.462avg 0.587 0.607 0.578Table 3: Results of test 2.ported in table 3, reveal that our system has a goodprecision in detecting worried/neurotic users.
Thebad results for upbeat/secure users could be due tothe fact that the class ?upbeat?
do not correspondperfectly to the ?secure?
class.
Overall the perfor-mance of our system is in line with the state of theart.3 Collection of the DatasetThe corpus, called ?Personalitwit2?, was collectedstarting from Twitter?s public timeline5.
The sam-pling procedure is depicted in figure 2.We sampled data from December 25th to 28th,2011 but most of the posts have a previous post-ing date since we also collected data from userpages, where 20 recent tweets are displayed in re-verse chronological order.
For each public user,sampled from the public timeline, we collected thenicknames of the related users, who had a conver-sation with the public users, using the @ symbol.We did this in order to capture users that are in-cluded in social relationships with the public users.4http://www.analyzewords.com/index.php5http://twitter.com/public timeline13Figure 2: Data sampling pipeline.We excluded from sampling all the retweeted postsbecause they are not written by the user themselvesand could affect linguistic-based personality recog-nition.
The dataset contains all the following in-formation for each post: username; text; post date;user type (public user or related user); user retweetcount; user following count; user followers count;user listed count; user favorites count; total tweetcount; user page creation year; time zone; relatedusers (users who replied to the sampled user); replyscore (rp), defined asrp =page reply countpage post countand retweet score (rt), defined asrt =page retweet countpage post countmin median mean maxtweets 3 5284 12246 582057following 0 197 838 320849followers 0 240 34502 17286123listed 0 1 385 539019favorites 0 7 157 62689Table 4: Summary of Personalitwit2.Figure 3: Frequency distribution of users per language.From the top: Arabic, Bahasa, Chinese, Czech, Dutch,English, French, German, Greek, Hebrew, Hindi, Italian,Japanese, Korean, Malay, Norwegian, Portuguese, Rus-sian, Slovene, Spanish, Swedish, Thai, Turkish, Uniden-tified.In the corpus there are 200000 posts, more than13000 different users and about 7800 ego-networks,where public users are the central nodes and re-lated users are the edges.
We annotated the corpuswith our personality recognition system.
The aver-age confidence is 0.601 and the average variabilityis 0.049.
A statistical summary of the data we col-lected is reported in table 4, the distribution of usersper language is reported in figure 3.
We kept onlyEnglish users (5392 egonetworks), discarding all theother users.4 Experiments and DiscussionFrequency distribution of emotional stability trait inthe corpus is as follows: 56.1% calm users, 39.2%neurotic users and 4.7% balanced users.We run a first experiment to check whether neu-rotic or calm users tend to have conversations withother users with the same personality trait.
To thispurpose we extracted all the ego-networks anno-tated with personality.
We automatically extracted14Figure 4: Relationships between users with the same per-sonality traits.the trait of the personality of the ?public-user?
(thecenter of the network) and we counted how manyedges of the ego-network have the same personal-ity trait.
The users in the ego-network are weighted:this means that if a ?public-user?
had x conversa-tions with the same ?related-user?, it is counted xtimes.
The frequency is defined asfreq =trait countegonetwork nodes countwhere the same trait is between the public-user andthe related users.
The experiment, whose results arereported in figure 4, shows that there is a generaltendency to have conversations between users thatshare the same traits.We run a second experiment to find which person-ality type is most incline to tweet, to retweet and toreply.
Results, reported in figure 5, show that neu-rotic users tend to post and to retweet more than sta-ble users.
Stable users are slightly more inclined toreply with respect to neurotic ones.In order to study if conversational practicesamong users with similar personality traits mightgenerate different social structure, we applied a so-cial network analysis to the collected data throughthe use of the Gephi software6.
We analysed sepa-rately the network of interactions between neuroticusers (n) and calm users (s) to point out any person-ality related aspect of the emerging social structure.Visualisations are shown in figure 6.Due to the way in which data have been acquired6http://www.gephi.orgFigure 5: Relationships between emotional stability andTwitter activity.- starting from the users randomly displayed on theTwitter public timeline - there is a large number ofscattered networks made of few interactions.
Never-theless the extraction of the ego networks allowedus to detect a rather interesting phenomena: neu-rotic users seem to have the tendency to build longerchains of interacting users while calm users have thetendency to build mutual connections.The average path length value of neurotic usersis 1.551, versus the average path length measuredon the calm users of 1.334.
This difference resultsin a network diameter of 6 for the network made ofonly neurotic users and of 5 for the network made15Figure 6: Social structures of stable (s) and neurotic (n)users.of secure users.
A single point of difference in thenetwork diameter produces a neurotic network muchmore complex than the calm network.
While thisdifference might be overlooked in large visualisa-tions due to the presence of many minor clusters ofnodes it becomes evident when we focus only on thegiant component of the two networks in figure 7.The giant components are those counting the ma-jor part of nodes and can be used as an exam-ple of the most complex structure existing withina network.
As it should appear clear neurotic net-work contains more complex interconnected struc-tures than calm network even if, as we claimed be-fore, have on average smaller social networks.5 Conclusions and Future WorkIn this paper, we presented an unsupervised systemfor personality recognition and we applied it suc-Figure 7: Giant components of stable (s) and neurotic (n)users.cessfully on a quite large and richly annotated Twit-ter dataset.
Results confirm some offline psycholog-ical findings in the social networks online, for ex-ample the fact that neurotic people tend to choosefriends who are also neurotic.We also confirm the fact that neurotic users havesmaller social networks at the level of a single user,but they tend to build longer chains.
This meansthat a tweet propagated in ?neurotic networks?
hashigher visibility.
We also found that neurotic usershave the highest posting rate and retweet score.In the future we should change the sampling set-tings in order to capture larger networks.
It would bealso very interesting to explore how other person-ality traits affect user?s behaviour.
To this purposewe need to improve the personality recognition sys-tem and we would benefit from topic identification,which is another growing field of research.16ReferencesAmichai-Hamburger, Y. and Vinitzky, G. 2010.
Socialnetwork use and personality.
In Computers in HumanBehavior.
26(6).
pp.
1289?1295.Argamon, S., Dhawle S., Koppel, M., Pennebaker J. W.2005.
Lexical Predictors of Personality Type.
In Pro-ceedings of Joint Annual Meeting of the Interface andthe Classification Society of North America.
pp.
1?16.Bastian M., Heymann S., Jacomy M. 2009.
Gephi: anopen source software for exploring and manipulatingnetworks.
In Proceedings of International AAAI Con-ference on Weblogs and Social Media.
pp.
1?2.Boyd, D. Golder, S. and Lotan, G. 2010.
Tweet, Tweet,Retweet: Conversational Aspects of Retweeting onTwitter.
In Proceedings of HICSS-43.
pp.
1?10.Boyd, D. and Ellison, N. 2007.
Social Network Sites:Definition, history, and scholarship.
In Journal ofComputer-Mediated Communication 13(1).
pp.
210?230.Celli, F., Di Lascio F.M.L., Magnani, M., Pacelli, B., andRossi, L. 2010.
Social Network Data and Practices:the case of Friendfeed.
Advances in Social Comput-ing, pp.
346?353.
Series: Lecture Notes in ComputerScience, Springer, Berlin.Coltheart, M. 1981.
The MRC psycholinguistic database.In Quarterly Journal of Experimental Psychology,33A, pp.
497?505.Finin, T., Murnane, W., Karandikar, A., Keller, N., Mar-tineau, J., Dredze, M. 2010.
Annotating named entitiesin Twitter data with crowdsourcing.
In Proceedings ofthe NAACL HLT 2010 Workshop on Creating Speechand Language Data with Amazon?s Mechanical Turk(CSLDAMT ?10).
pp.
80?88.Golbeck, J. and Robles, C., and Turner, K. 2011.
Predict-ing Personality with Social Media.
In Proceedings ofthe 2011 annual conference extended abstracts on Hu-man factors in computing systems, pp.
253?262.Golbeck, J. and Hansen, D.,L.
2011.
Computing politicalpreference among twitter followers.
In Proceedings ofCHI 2011: pp.
1105?1108.Goldberg, L., R. The Development of Markers for the BigFive factor Structure.
1992.
In Psychological Assess-ment, 4(1).
pp.
26?42.Honeycutt, C., and Herring, S. C. 2009.
Beyond mi-croblogging: Conversation and collaboration via Twit-ter.
In Proceedings of the Forty-Second Hawaii Inter-national Conference on System Sciences.
pp 1?10.Kanfer, A., Tanaka, J.S.
1993.
Unraveling the Web ofPersonality Judgments: The Inuence of Social Net-works on Personality Assessment.
Journal of Person-ality, 61(4) pp.
711?738.Iacobelli, F., Gill, A.J., Nowson, S. Oberlander, J. Largescale personality classification of bloggers.
2011.
InLecture Notes in Computer Science (6975), pp.
568?577.Mairesse, F., and Walker, M.. PERSONAGE: PersonalityGeneration for Dialogue.
2007.
In Proceedings of the45th Annual Meeting of the Association for Computa-tional Linguistics (ACL), pp.496?503.Mairesse, F. and Walker, M. A. and Mehl, M. R., andMoore, R, K. 2007.
Using Linguistic Cues for theAutomatic Recognition of Personality in Conversationand Text.
In Journal of Artificial intelligence Research,30.
pp.
457?500.Norman, W., T. 1963.
Toward an adequate taxonomy ofpersonality attributes: Replicated factor structure inpeer nomination personality rating.
In Journal of Ab-normal and Social Psychology, 66. pp.
574?583.Oberlander, J., and Nowson, S. 2006.
Whose thumb isit anyway?
classifying author personality from we-blog text.
In Proceedings of the 44th Annual Meetingof the Association for Computational Linguistics ACL.pp.
627?634.Pak, A., Paroubek P. 2010.
Twitter as a corpus for senti-ment analysis and opinion mining.
In Proceedings ofLREC 2010. pp.
1320?1326.Pennebaker, J. W., King, L. A.
1999.
Linguistic styles:Language use as an individual difference.
In Journalof Personality and Social Psychology, 77, pp.
1296?1312.Pennebaker, J. W., Francis, M. E., Booth, R. J.
2001.Inquiry and Word Count: LIWC 2001.
Lawrence Erl-baum, Mahwah, NJ.Platt, J.
1998.
Machines using Sequential Minimal Op-timization.
In Schoelkopf, B., Burges, C., Smola, A.
(ed), Advances in Kernel Methods, Support VectorLearning.
pp.
37?49.Quercia, D. and Kosinski, M. and Stillwell, D., andCrowcroft, J.
2011.
Our Twitter Profiles, Our Selves:Predicting Personality with Twitter.
In Proceedings ofSocialCom2011.
pp.
180?185.Van Zalk, N., Van Zalk, M., Kerr, M. and Stattin, H. 2011.Social Anxiety as a Basis for Friendship Selection andSocialization in Adolescents?
Social Networks.
Jour-nal of Personality, 79: pp.
499?526.Zhao, D., Rosson, M.B.
2009.
How and why people Twit-ter: The role that micro-blogging plays in informalcommunication at work.
In Proceedings of GROUP2009 pp.
243?252.Zhao, W.X., Jiang, J., He, J., Song, Y., Achananuparp, P.,Lim, E.P., Li, X.
2011.
Topical keyphrase extractionfrom Twitter.
In Proceedings of the 49th Annual Meet-ing of the Association for Computational Linguistics:Human Language Technologies - Volume 1 (HLT ?11).pp.
379?388.17
