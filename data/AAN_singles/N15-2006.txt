Proceedings of NAACL-HLT 2015 Student Research Workshop (SRW), pages 40?47,Denver, Colorado, June 1, 2015.c?2015 Association for Computational LinguisticsExploring Relational Features and Learning under Distant Supervision forInformation Extraction TasksAjay NageshDept.
of Computer Science and Engineering, IIT Bombay.Faculty of Information Technology, Monash University.ajaynagesh@cse.iitb.ac.inAbstractInformation Extraction (IE) has become an in-dispensable tool in our quest to handle the datadeluge of the information age.
IE can broadlybe classified into Named-entity Recognition(NER) and Relation Extraction (RE).
In thisthesis, we view the task of IE as finding pat-terns in unstructured data, which can eithertake the form of features and/or be specifiedby constraints.
In NER, we study the cate-gorization of complex relational1features andoutline methods to learn feature combinationsthrough induction.
We demonstrate the effi-cacy of induction techniques in learning : i)rules for the identification of named entities intext ?
the novelty is the application of induc-tion techniques to learn in a very expressivedeclarative rule language ii) a richer sequencelabeling model ?
enabling optimal learning ofdiscriminative features.
In RE, our investiga-tions are in the paradigm of distant supervi-sion, which facilitates the creation of large al-beit noisy training data.
We devise an infer-ence framework in which constraints can beeasily specified in learning relation extractors.In addition, we reformulate the learning ob-jective in a max-margin framework.
To thebest of our knowledge, our formulation is thefirst to optimize multi-variate non-linear per-formance measures such as F?for a latentvariable structure prediction task.1 IntroductionMost of the content that we come across in thedigital media in the form of emails, blogs, web-pages, enterprise data and so on are authored in nat-ural language and have very little structure to them.With the dawn of the information age, we produce acolossal amount of unstructured data everyday.
This1Terminology is borrowed from logic, where relational logicis more powerful than propositional logic with the inclusion ofquantifiers, but is a subset of first-order logicpresents an enormous challenge for machines to pro-cess, curate, search and reason in such data.The process of automatically identifying and dis-ambiguating entities, their attributes and relation-ships in unstructured data sources is termed as In-formation Extraction (IE).
IE facilitates a rich andstructured representation of data, enabling down-stream applications to process unstructured docu-ments like a standard database.
The richness presentin natural language text, presupposition of worldknowledge and the rapid rate of content creationmakes IE a highly challenging task.
As a result,it has been a very active area of research in thecomputational linguistics community for over twodecades (Sarawagi, 2008).A few of the challenges faced when performinginformation extraction: (i) Entity Disambiguation:Jeff Bezos and Bezos refer to the same en-tity.
Washington could be either a city, a state,or a person depending on the context.
(ii) ScopeResolution: Certain Entities such as Washingtonin ?Washington Post?
should not be labeledas a location name because the entire textual spanis an organization name (iii) Type Disambiguation:In the sentence, ?
England beat Australia 2 - 0?.England and Australia are sports organiza-tions.
(iv) Relation mention detection: The co-occurrence of Obama and US in a sentence is nota sure indication that the President relation (ob-tained from a database of facts) is expressed in it.1.1 Contributions of the thesisThe problem of Information Extraction can beviewed as that of finding patterns in the data.
Thesepatterns can either take the form of features or canbe specified as constraints on the search space.Data-driven Patterns : Feature CombinationsLet us suppose that we are given a set of basic fea-tures (e.g.
Caps - a capitalized token; LastName -occurrence in a dictionary of last-names).
Named-40Figure 1: Patterns as Feature CombinationsFigure 2: Patterns as Constraintsentities can be discovered by learning combinationsof such features.
For instance, ?if a span of text con-tains two tokens, Caps followed by LastName, thenit is most probably a person named entity?.
We con-sider the previous statement as a pattern, leading toa named-entity.Figure 1 depicts some of the basic features, anumber of patterns (basic feature combinations) andthe entities in text that can potentially match withthese patterns.
Named-entity recognition (NER)can immensely benefit from such patterns, someof which are domain-specific and others, domain-independent.
Several patterns are non-trivial com-binations of basic features.
For instance, ?if alocation name overlaps with an organization,then it is not a location named-entity?.
(e.g.Washington in Washington Post).These patterns are very large in number and wecould define them as feature classes.
The set of fea-tures defined by them form a feature space.
Sincethe number patterns are many and we are not surewhich ones are triggered in a given piece of text, wewould like to learn / induce such patterns.In this thesis, we study the categorization of thefeature classes.
We also define various methods tolearn feature combinations through induction.
Thefeatures induced are consumed by a rule-based NERsystem to learn compact and ?interpretable?
rulesthat have a reasonable accuracy.
We also demon-strate the use of these features in max-margin basedsequence labeling models.User-Specified Patterns : ConstraintsConsider the problem of identifying relationshipsbetween entities in text.
Here we can look at pat-terns as constraints that need to be enforced on rela-tions extracted.
Some of these are listed in Figure 2.They are few compared to the entity recognition caseand can be specified by the user to restrict the searchspace.For instance, we would like to enforce the follow-ing constraint: For a Prime-minister relation,the first argument has to be a person and the sec-ond argument has to be a country .In this thesis, we look at a specific paradigm ofrelation extraction called distant supervision (Mintzet al, 2009).
The goal is to learn relation extrac-tion models by aligning facts in a database (Figure 2)to sentences in a large unlabeled corpus.
Since theindividual sentences are not hand labeled, the factsin the database act as ?weak?
or ?distant?
labels,and hence, the learning scenario is termed as dis-tantly supervised.
We look at ways in which con-straints can be specified while learning relation ex-tractors in this setting.
We formulate an integer lin-ear programming-based framework to facilitate theaddition of constraints.Existing distant supervision-based systems are of-ten trained by optimizing performance measures(such as conditional log-likelihood or error rate) thatare not directly related to the task-specific non-linearperformance measure, e.g., the F1-score.
We presenta novel max-margin learning approach to optimizenon-linear performance measures for distantly su-41pervised relation extraction models.2 Learning for Named-Entity ExtractionSeveral problems in Machine Learning are im-mensely benefited from a rich structural representa-tion of the data (Flach and Lachiche, 1999; Roth andYih, 2001).
Specifically, the tasks in InformationExtraction are relation-intensive and the usage of re-lational features has been shown to be quite effectivein practice (Califf, 1998; Roth and Yih, 2001).
Inthis section, we define categories of predicates anddiscuss the complexity-based classification of rela-tional features followed by techniques to induce fea-tures in several of these categories.Feature Space CategorizationThe relational features are in a language that issimilar in expressive power as first order definiteclauses (Horn, 1951).
Predicates are defined on tex-tual spans.
The head predicate is the class label of atextual span.We define two types of body predicates, namely,relation and basic feature predicates.
A rela-tion predicate is a binary predicate that representsthe relationship between two spans of text.
E.g.overlaps(X,Y).
A basic feature predicate is an as-sertion of a situation or a property of a span or a sub-span.
For example, FirstName(X) states that thespan of text X occurs in a dictionary of first names.We illustrate each of these feature classes with anexample of a typical definite clause belonging to thefeature class.1.
Simple Conjuncts (SCs):Org(X) :- OrgGazeteer(X),CapsWord(X).e.g.
Microsoft2.
Candidate Definition Features (CDs) : These con-sist of the two following feature classes.
(a) Absolute Features (AFs): non-overlappingevidence predicates chained by relationpredicates.person-AF(X) :- contains(X, X1),FirstNameDict(X1), CapsWord(X1),before(X1,X2), contains(X, X2),CapsWord(X2).
e.g.
: Sachin Tendulkar(b) Composite Features (CFs): Defined as aconjunction of two AFs that share the samehead predicate.person(X) :- person-AF (X),leftContext(X, 1, L2),Salutation(L2).
e.g.
: Mr. SachinTendulkar (note the presence of contextualclues such as salutation)3.
Candidate Refinement Features (CRs): The bodyof the clause is defined by head predicates thatbelong to different class labels, and can containnegations in the body (hence, not a definite clause)Loc(X) :- Loc1(X),org1(Y),?overlaps(X,Y).A span of text is a location, ?if it matches a locationfeature and does not overlap with an organizationfeature?.
e.g.
: Washington in ?Washington Post?will not be marked as a location, due to this feature.2.1 Feature Induction in a Rule-based SettingRule-based systems for NER achieve state-of-the-artaccuracies (Chiticariu et al, 2010).
However, man-ually building and customizing rules is a complexand labor-intensive process.
In this work, we outlinean approach that facilitates the process of buildingcustomizable rules for NER through rule induction.Given a set of basic feature predicates and an an-notated document collection, our goal is to gener-ate with reasonable accuracy an initial set of rulesthat are interpretable and thus can be easily refinedby a human developer.
Our contributions include (i)an efficient rule induction process in a declarativerule language, (ii) usage of induction biases to en-hance rule interpretability, and (iii) definition of ex-tractor complexity as a first step to quantify the inter-pretability of an extractor.
We present initial promis-ing results with our system and study the effect of in-duction bias and customization of basic features onthe accuracy and complexity of induced rules.
Wedemonstrate through experiments that the inducedrules have good accuracy and low complexity, ac-cording to our complexity measure.Our induction system is modeled on a four-stagemanual rule development process since the overallstructure of the induced rules must be similar inspirit to that which a developer who follows bestpractices would write.
The stages of rule develop-ment and the corresponding phases of induction aresummarized in Figure 3.
In our system, we combineseveral induction techniques such as least generalgeneralization (LGG), iterative clustering, proposi-tional rule learning in order to induce NER rulesin a declarative rule language known as AnnotationQuery Language (AQL).
A brief overview of thesalient aspects of our induction system is presented42Figure 3: Correspondence between Manual Rule devel-opment and Rule InductionFigure 4: Relative Least General Generalizationin the following paragraphs.Background Knowledge.
We represent each exam-ple in the form of first order definite clauses, in con-junction with relevant background knowledge.
Thisbackground knowledge will serve as input to our in-duction system.Clustering and RLGG.
The first phase of induc-tion uses a combination of clustering and rel-ative least general generalization (RLGG) tech-niques (Nienhuys-Cheng and Wolf, 1997; Muggle-ton and Feng, 1992).
Using clustering, we groupthe examples based on the similarity of their back-ground knowledge.
This process is interleaved byRLGG where we take a set of examples and findtheir generalization that is analogous to the least up-per bound.
We recursively find pairwise-RLGGs ofall examples in a cluster.
At the end of this phase,we have a number of CD features.The representation of an example and the RLGGprocedure is shown in Figure 4.Propositional Rule Learning.
In the second phase,we begin by forming a structure known as the span-view table.
Broadly speaking, this is an attribute-value table formed by all the features induced in thefirst phase along with the textual spans generated bythem.
The attribute-value table is used as input to apropositional rule learner such as JRIP to learn accu-rate compositions of a useful (as determined by thelearning algorithm) subset of the CD features.
Thisforms the second phase of our system.
The ruleslearnt from this phase are in the space of CR fea-tures.Induction Biases.
At various phases, several in-duction biases are introduced to enhance the inter-pretability of rules.
These biases capture the exper-tise gleaned from manual rule development and con-strain the search space in our induction system.Extractor Complexity.
Since our goal is to gener-ate extractors with manageable complexity, we mustintroduce a quantitative measure of extractor com-plexity, in order to (1) judge the complexity of theextractors generated by our system, and (2) reducethe search space considered by the induction system.To this end, we define a simple complexity score thatis a function of the number of rules, and the numberof predicates in the body of each rule of the extrac-tor.
Our simple notion of rule length is motivated byexisting literature in the area of database systems.AQL and SystemT : Advantages.
The hypothesislanguage of our induction system is AQL, and weemploy SystemT as the theorem prover.
SystemTprovides a very fast rule execution engine and is cru-cial to our induction system because we test multi-ple hypotheses in the search for the more promisingones.
AQL provides a very expressive rule repre-sentation language that has proven to be capable ofencoding all the paradigms that any rule-based rep-resentation can encode.
The dual advantages of richrule-representation and execution efficiency are themain motivations behind our choice.We experimented with three different starting setsof basic feature predicates (with increasing accu-racy and complexity) and observed that the com-plexity of the final set of induced rules is directlyproportional to that of the initial set, both in termsof accuracy and complexity.
We compared our in-duced set of rules with the manual rules.
We achieveupto 75% accuracy of the state-of-the-art manualrules with a decrease in extractor complexity of upto61%.
For a more detailed exposition of the systemand discussion of experiments, please refer to ourwork (Nagesh et al, 2012).432.2 Feature Induction in a Max-margin SettingIn this piece of work, we view the problem of NERfrom the perspective of sequence labeling.
The goalis to investigate the effectiveness of using relationalfeatures in the input space of a max-margin based se-quence labeling model.
Our work is based on Struc-tHKL (Nair et al, 2012) and standard StructSVMformulations.
We propose two techniques to learn aricher sequence labeling model by using relationalfeatures discussed above.In one technique, we leverage an existing systemthat is known to learn optimal feature conjunctions(SCs) in order to learn relational features such asAFs and CFs.
To achieve this, we propose a two-step process : (i) enumerate a good set of AFs usingexisting induction techniques (ii) use the StructHKLframework, which learns optimal conjunctions tolearn CFs.In the other technique, we leverage theStructSVM framework.
We define a subse-quence kernel to implicitly capture the relationalfeatures and reformulate the training objective.Our experiments in sequence labeling tasks rein-force the importance of induction bias and the needfor interpretability to achieve high-quality NERrules, as observed in the experiments of our previ-ous work on rule induction.3 Learning for Relation ExtractionIn the second part of the thesis, we investigateanother important problem in IE, namely, rela-tion extraction.
The task of extracting relationalfacts that pertains to a set of entities from natu-ral language text is termed as relation extraction.For example, given a natural language sentence,?On Friday, President Barack Obama defendedhis administration?s mass collection of telephoneand Internet records in the United States?, we caninfer the relation, President(Barack Obama,United States) between the entities BarackObama and United States.Our framework is motivated by distant supervi-sion for learning relation extraction models (Mintzet al, 2009).
Prior work casts this problem as amulti-instance multi-label learning problem (Hoff-mann et al, 2011; Surdeanu et al, 2012).
It is multi-instance because for a given entity-pair, only the la-bel of the bag of sentences that contains both entities(aka mentions) is given.
It is multi-label because abag of mentions can have multiple labels.
The inter-dependencies between relation labels and (hidden)mention labels are modeled by a Markov RandomField (Hoffmann et al, 2011).3.1 Constrained Distant SupervisionVarious models have been proposed in recent litera-ture to align the facts in the database to their men-tions in the corpus.
In this work, we discuss andcritically analyze a popular alignment strategy calledthe ?at least one?
heuristic.
We provide a simple,yet effective relaxation to this strategy.Our work extends the work by Hoffmann et al(2011).
We formulate the inference procedures intraining as integer linear programming (ILP) prob-lems and implement the relaxation to the ?at leastone ?
heuristic through a soft constraint in this for-mulation.
This relaxation is termed as ?noisy-or?.The idea is to model the situation where a fact ispresent in the database but it is not instantiated inthe text.Additionally, our inference formulation enablesus to model additional type of constraints such as se-lectional preferences of arguments.
Empirically, wedemonstrate that this simple strategy leads to a betterperformance under certain settings when comparedto the existing approaches.
For additional details,please refer to our paper (Nagesh et al, 2014).3.2 Distant Supervision in a Max-marginSettingRich models with latent variables are popular inmany problems in natural language processing.
Forinstance, in IE, one needs to predict the relation la-bels that an entity-pair can take based on the hiddenrelation mentions, i.e., the relation labels for occur-rences of the entity-pair in a given corpus.
Thesemodels are often trained by optimizing performancemeasures (such as conditional log-likelihood or er-ror rate) that are not directly related to the task-specific non-linear performance measure, e.g., theF1-score.
However, better models may be trainedby optimizing the task-specific performance mea-sure while allowing latent variables to adapt theirvalues accordingly.Large-margin methods have been shown to be a44compelling approach to learn rich models detailingthe inter-dependencies among the output variables.Some methods optimize loss functions decompos-able over the training instances (Taskar et al, 2003;Tsochantaridis et al, 2004) compared to others thatoptimize non-decomposable loss functions (Ranjbaret al, 2013; Tarlow and Zemel, 2012; Rosenfeldet al, 2014; Keshet, 2014).
They have also beenshown to be powerful when applied to latent vari-able models when optimizing for decomposable lossfunctions (Wang and Mori, 2011; Felzenszwalb etal., 2010; Yu and Joachims, 2009).In this work (Haffari et al, 2015), we describea novel max-margin learning approach to opti-mize non-linear performance measures for distantly-supervised relation extraction models.
Our approachcan be generally used to learn latent variable mod-els under multivariate non-linear performance mea-sures, such as F?-score.Our approach involves solving the hard-optimization problem in learning by interleavingConcave-Convex Procedure with dual decomposi-tion.
Dual decomposition allowed us to solve thehard sub-problems independently.
A key aspectof our approach involves a local-search algorithmthat has led to a speed-up of 7,000 times in ourexperiments over an exhustive search baselineproposed in previous work (Ranjbar et al, 2012;Joachims, 2005).Our work is the first to make use of max-margintraining in distant supervision of relation extractionmodels.
We demonstrate the effectiveness of ourproposed method compared to two strong baselinesystems which optimize for the error rate and con-ditional likelihood, including a state-of-the-art sys-tem by Hoffmann et al (2011).
On several data con-ditions, we show that our method outperforms thebaseline and results in up to 8.5% improvement inthe F1-score.4 ConclusionOur thesis can be summarized as shown in Figure 5.The broad theme of each work along with its pub-lication forum is indicated.
In the entity extractionsetting, we work in the paradigm of relational fea-ture space exploration, and in the relation extrac-tion setting, our research has been in the paradigmFigure 5: Thesis Summaryof learning under distant supervision.The design of our feature induction approach isaimed at producing accurate rules that can be un-derstood and refined by humans, by placing specialemphasis on low complexity and efficient computa-tion of the induced rules.
According to our com-plexity measure, the induced rules have good ac-curacy and low complexity.
While our complexitymeasure informs the biases in our system and leadsto simpler, smaller extractors, it captures extrac-tor interpretability only to a certain extent.
There-fore, we believe more work is required to devise amore comprehensive quantitative measure for inter-pretability.
Another interesting direction of futurework, is the designing of human-computer interac-tion experiments, to present the induced rules to amanual rule-developer and evaluating the quality ofrules induced.In the distantly supervised relation extraction, ourILP formulation provides a good framework to addnew types of constraints to the problem.
In the fu-ture, we would like to experiment with other con-straints such as modeling the selectional preferencesof entity types.Our max-margin framework for distant supervi-sion provided a way to optimize F1score whiletraining the model.
Although we solved thehard optimization problem with an efficient dual-decomposition formulation, our algorithms do notscale very well to large datasets.
As part of futurework, we would like to investigate distributed opti-mization algorithms as an extension to our solutions.In addition, we would like to maximize other per-formance measures, such as area under the curve,for information extraction models.
We would also45like to explore our approach for other latent variablemodels in NLP, such as those in machine translation.ReferencesMary Elaine Califf.
1998.
Relational Learning Tech-niques for Natural Language Information Extraction.Ph.D.
thesis, Department of Computer Sciences, Uni-versity of Texas, Austin, TX, August.
Also appears asArtificial Intelligence Laboratory Technical Report AI98-276.Laura Chiticariu, Rajasekar Krishnamurthy, YunyaoLi, Frederick Reiss, and Shivakumar Vaithyanathan.2010.
Domain adaptation of rule-based annotators fornamed-entity recognition tasks.
In EMNLP.Pedro F. Felzenszwalb, Ross B. Girshick, David A.McAllester, and Deva Ramanan.
2010.
Object detec-tion with discriminatively trained part-based models.IEEE Trans.
Pattern Anal.
Mach.
Intell., 32(9):1627?1645.Peter Flach and Nicolas Lachiche.
1999.
1bc: a first-order bayesian classifier.
In Proceedings Of the 9thInternational workshop on Inductive Logic Program-ming, Volume 1634 of Lecture Notes in Artificial Intel-ligence, pages 92?103.
Springer-Verlag.Gholamreza Haffari, Ajay Nagesh, and Ganesh Ramakr-ishnan.
2015.
Optimizing multivariate performancemeasures for learning relation extraction models.
InHuman Language Technologies: Conference of theNorth American Chapter of the Association of Com-putational Linguistics, Proceedings, May 31 - Jun 5,2015, Denver, Colorado, USA.
The Association forComputational Linguistics.Raphael Hoffmann, Congle Zhang, Xiao Ling, LukeZettlemoyer, and Daniel S. Weld.
2011.
Knowledge-based weak supervision for information extraction ofoverlapping relations.
In Proceedings of the 49th An-nual Meeting of the Association for ComputationalLinguistics: Human Language Technologies - Volume1, HLT ?11, pages 541?550, Stroudsburg, PA, USA.Association for Computational Linguistics.Alfred Horn.
1951.
On sentences which are true of directunions of algebras.
The Journal of Symbolic Logic,16(1):pp.
14?21.T.
Joachims.
2005.
A support vector method for multi-variate performance measures.
In International Con-ference on Machine Learning (ICML), pages 377?384.Joseph Keshet.
2014.
Optimizing the measure of perfor-mance in structured prediction.
In Sebastian Nowozin,Peter V. Gehler, Jeremy Jancsary, and Christoph H.Lampert, editors, Advanced Structured Prediction.The MIT Press.Mike Mintz, Steven Bills, Rion Snow, and Dan Jurafsky.2009.
Distant supervision for relation extraction with-out labeled data.
In Proceedings of the Joint Confer-ence of the 47th Annual Meeting of the ACL, ACL ?09,pages 1003?1011, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.Stephen Muggleton and C. Feng.
1992.
Efficient induc-tion in logic programs.
In ILP.Ajay Nagesh, Ganesh Ramakrishnan, Laura Chiticariu,Rajasekar Krishnamurthy, Ankush Dharkar, and Push-pak Bhattacharyya.
2012.
Towards efficient named-entity rule induction for customizability.
In Proceed-ings of the 2012 Joint Conference on Empirical Meth-ods in Natural Language Processing and Computa-tional Natural Language Learning, EMNLP-CoNLL?12, pages 128?138, Stroudsburg, PA, USA.
Associa-tion for Computational Linguistics.Ajay Nagesh, Gholamreza Haffari, and Ganesh Ramakr-ishnan.
2014.
Noisy or-based model for relation ex-traction using distant supervision.
In Proceedings ofthe 2014 Conference on Empirical Methods in NaturalLanguage Processing (EMNLP), Doha, Qatar, Octo-ber.
Association for Computational Linguistics.Naveen Nair, Amrita Saha, Ganesh Ramakrishnan, andShonali Krishnaswamy.
2012.
Rule ensemble learn-ing using hierarchical kernels in structured outputspaces.
In AAAI.Shan-Hwei Nienhuys-Cheng and Ronald de Wolf.
1997.Foundations of Inductive Logic Programming.Mani Ranjbar, Arash Vahdat, and Greg Mori.
2012.Complex loss optimization via dual decomposition.
In2012 IEEE Conference on Computer Vision and Pat-tern Recognition, Providence, RI, USA, June 16-21,2012, pages 2304?2311.Mani Ranjbar, Tian Lan, Yang Wang, Stephen N. Robi-novitch, Ze-Nian Li, and Greg Mori.
2013.
Opti-mizing nondecomposable loss functions in structuredprediction.
IEEE Trans.
Pattern Anal.
Mach.
Intell.,35(4):911?924.Nir Rosenfeld, Ofer Meshi, Amir Globerson, and DanielTarlow.
2014.
Learning structured models with theauc loss and its generalizations.
In Proceedings ofthe 17th International Conference on Artificial Intel-ligence and Statistics (AISTATS).D.
Roth and W. Yih.
2001.
Propositionalization of rela-tional learning: An information extraction case study.Number UIUCDCS-R-2001-2206.Sunita Sarawagi.
2008.
Information extraction.
Found.Trends databases, 1(3):261?377, March.Mihai Surdeanu, Julie Tibshirani, Ramesh Nallapati, andChristopher D. Manning.
2012.
Multi-instance multi-label learning for relation extraction.
In Proceed-ings of the 2012 Joint Conference on Empirical Meth-46ods in Natural Language Processing and Computa-tional Natural Language Learning, EMNLP-CoNLL?12, pages 455?465, Stroudsburg, PA, USA.
Associa-tion for Computational Linguistics.Daniel Tarlow and Richard S Zemel.
2012.
Structuredoutput learning with high order loss functions.
In Pro-ceedings of the 15th Conference on Artificial Intelli-gence and Statistics.Benjamin Taskar, Carlos Guestrin, and Daphne Koller.2003.
Max-margin markov networks.
In NIPS.Ioannis Tsochantaridis, Thomas Hofmann, ThorstenJoachims, and Yasemin Altun.
2004.
Support vec-tor machine learning for interdependent and structuredoutput spaces.
In Proceedings of the twenty-first inter-national conference on Machine learning, ICML ?04,pages 104?, New York, NY, USA.
ACM.Yang Wang and Greg Mori.
2011.
Hidden part mod-els for human action recognition: Probabilistic versusmax margin.
IEEE Trans.
Pattern Anal.
Mach.
Intell.,33(7):1310?1323.Chun-Nam John Yu and Thorsten Joachims.
2009.Learning structural svms with latent variables.
In Pro-ceedings of the 26th Annual International Conferenceon Machine Learning, ICML 2009, Montreal, Quebec,Canada, June 14-18, 2009, page 147.47
