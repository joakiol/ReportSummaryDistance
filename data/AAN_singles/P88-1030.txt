DEDUCTIVE PARSING WITH MULTIPLE LEVELS OF REPRESENTATION.
*Mark Johnson,Brain and Cognitive Sciences, M.I.T.ABSTRACTThis paper discusses a sequence of deductiveparsers, called PAD1 - PAD5, that utilize anaxiomatizat ion of the principles andparameters of GB theory, including a restrictedtransformational component (Move-a).
PAD2uses an inference control strategy based on the"freeze" predicate of Prolog-II, while PAD3 - 5utilize the Unfold-Fold transformation totransform the original axiomatization i to aform that functions as a recursive descent Prologparser for the fragment.INTRODUCTIONThis paper reports on several deductive parsersfor a fragment of Chomsky's Government andBinding theory (Chomsky 1981, 1986; VanRiemsdijk and Williams 1984).
These parserswere constructed to illustrate the 'Parsing asDeduction' approach, which views a parser asa specialized theorem-prover which usesknowledge of a language (i.e.
its grammar) as aset of axioms from which information about theutterances of that language (e.g.
theirstructural descriptions) can be deduced.
Thisapproach directly inspired by the seminalpaper by Pereira and Warren (1983).
Johnson(1988a) motivates the Parsing as Deductionapproach in more detail than is possible here,and Johnson (1988b) extends the techniquespresented in this paper to deal with a morecomplex fragment.Steven Abney, Bob Berwick, Nelson Correa,Tim Hickey, Elizabeth Highleyman, Ewan Klein,Peter Ludlow, Martin Kay, Fernando Pereira andWhitman Richards all made helpful suggestionsregarding this work, although all responsibility forerrors remains my own.
The research reported herewas supported by a grant by the SystemsDevelopment Foundation to the Center for theStudy of Language and Information at StanfordUniversity and a Postdoctoral Fellowship awarded bythe Fairchild Foundation through the Brain andCognitive Sciences Department at MIT.In this paper I describe a sequence of modeldeductive parsers, called PAD1 - PAD5, for afragment of GB theory.
These parsers are notdesigned for practical application, but simplyto show that GB deductive parsers can actuallybe built.
These parsers take PF representationsas their input and produce LF representations astheir output.
They differ from most extant GBparsers in that they make explicit use of thefour levels of representation that GB attributesto an utterance - namely D-structure, S-structure, PF and LF - and the transformationalrelationship that holds between them.
A"grammar" for these parsers consists entirely ofa set of parameter values that parameterizethe principles of GB theory - thus the parsersdescribed here can be regarded as "principle-based' (Berwick 1987) - and the parsers' top-level internal structure transparently reflects(some of) the principles of that theory; X" and@ theory apply at D-structure, Case theoryapplies at S-structure, Move-or is stated as arelation between D- and S-structure, and LF-movement  relates S-structure and LF.
Inparticular, the constraints on S-structures thatresult from the interaction of Move-c~ withprinciples constraining D-structure (i.e.
X' and@ theories) are used constructively throughoutthe parsingprocess.The PAD parsers are designed to directlymirror the deductive structure of GB theory.Intuitively, it seems that deductive parsersshould be able to mirror theories with a richinternal deductive structure; these parsers howthat to a first approximation this is in fact thecase.
For example, the PAD parsers have nodirect specification of a 'rule' of Passive, ratherthey deduce the relevant properties of thePassive construction fi'om the interaction of Otheory, Move-a, and Case theory.It must be stressed that the PAD parsers areonly 'model' Parsers.
The fragment of Englishthey accept could only be called 'restricted'.They have no account of WH-movement, andMove-a  is restricted to apply to lexicalcategories, for example, and they incorporatenone of the principles of Bounding Theory.241However, the techniques u ed to construct theseparsers are general, and they should extend to amore substantial fragment.A SKETCH OF GB THEORYIn the remainder of this section I sketch theaspects of GB theory relevant to the discussionbelow; for more detail the reader should consultone of the standard texts (e.g.
Van Riemsdijkand Williams 1986).
GB theory posits fourdistinct representations of an utterance, D-structure, S-structure, PF and LF.
To a firstapproximation, D-structure representsconfigurationally the thematic or predicate-argument s ructure of the utterance, S-structurerepresents he utterance's surface constituentstructure, PF represents its phonetic form, andLF ("Logical Form") is a configurationalrepresentation of the scopal relationshipsbetween the quantificational elements presentin the utterance.
The PF and LF representationsconstitute the interface between language andother cognitive systems external to thelanguage module (Chomsky 1986, p. 68).
Forexample, the PF representation "Everybody isloved" together with the D-structure, S-structure and LF representations shown inFigure 1 might constitute a well-formedquadruple for English.INFL" INFL ~/ \~"  / \~-FL"/ \ vP  nbeV NP beV NPilo~,ed everybody lo~,edD-structure INFL" S-structuren Npi / \v  pbe V NPiFigure 1: Representations of GB Theory.In order for such a quadruple to be well-formedit must satisfy all of the principles of grammar;e.g.
the D-structure and S-structure must berelated by Move(z, the D-structure must satisfyX'-theory and @-theory, etc.
This is shownschematically in Figure 2, where the shadedrounded boxes indicate the four levels ofrepresentation, the boxes indicate relationsthat must hold simultaneously between pairs ofstructures, and the ellipses designate propertiesthat must hold of a single structure.
Thisdiagram is based on the organization of GBtheory sketched by Van Riemsdijk andWilliams (1986, p. 310), and represents theorganization of principles and structuresincorporated in the parsers discussed below.~i!
Ph?netic i~~orm (PF) ~ - LHgure 2: (Some of) The Principles of GBTheory.The principles of grammar are parameterized;the set of structures they admit depends on thevalue of these parameters.
These principlesare hypothesised to be innate (and henceuniversally true of all human languages, thusthey are often called "Universal Grammar'), sothe extra knowledge that a human requires inorder to know a language consists entirely of thevalues (or settings) of the parameters plus thelexicon for the language concerned.
The syntaxof the English fragment accepted by the parsersdiscussed below is completely specified by thefollowing list of parameters.
The first twoparameters determine the X' component, hethird parameter determines the Move-czrelation, and the fourth parameter identifiesthe direction of Case assignment.
(1) headFirst.specFirst.movesInSyntax(np).rightwardCaseAssignment.I conclude this section with some brief remarkson the computational problems involved inconstructing a GB parser.
It seems that one canonly construct a practical GB parser bysimultaneously using constraints from all of theprinciples of grammar mentioned above(excepting LF-Movement), but this involvesbeing able to "invert" Move-cz 'on the fly'.Because of the difficulty of doing this, most242implementations of GB parsers ignore Move-orentirely and reformulate X' and @ Theories othat they apply at S-structure instead of D-structure, even though this weakens theexplanatory power of the theory andcomplicates the resulting grammar, asChomsky (1981) points out.
The work reportedhere shows that it is possible to invert a simpleformulation of Move-(x "on the fly', suggestingthat it is possible to build parsers that takeadvantage of the D-structure/S-structuredistinction offered by GB theory.PARSING AS DEDUCTIONAs just outlined, GB theory decomposes acompetent user's knowledge of a languagepossessed into two components: (i) the universalcomponent (Univeral Grammar), and (ii) a setof parameter values and a lexicon, whichtogether constitute the knowledge of thati~articular language above and beyond theuniversal component.
The relationship betweenthese two components of a human's knowledgeof a language and the knowledge of theutterances of that language that they inducecan be formally described as follows: we regardUniversal Grammar as a logical theory, i.e.
adeductively closed set of statements expressedin a specialized logical language, and thelexicon and rarameter values that constitutethe specific knowledge of a human languagebeyond Universal Grammar as a set of formulaein that logical language.
In the theory of ofUniversal Grammar, these formulae implystatements describing the linguistic propertiesof utterances of that human language; thesestatements constitute knowledge of utterancesthat the parser computes.The parsers presented below compute instancesof the 'parse" relation, which is true of a PF-LFpair if and only if there is a D-structure and anS-structure such that the D-structure, S-structure, PF, LF quadruple is well-formed withrespect o all of the (pararneterized) principlesof grammar.
For simplicity, the 'phonology"relation is approximated here by the S-structure 'yield' function.
Specifically, theinput to the language processor are PFrepresentations and that the processor producesthe corresponding LF representations as output.The relationship between the parametersettings and lexicon to the 'parse' relation issketched in Figure 3.Knowledge of the LanguageParameter Settingsheadfirst.specFirst.moveslnSyntax(np).rightwardCaseAssignment.LexiconthetaAssigner(love).thetaAssigner(loved).nonThetaAssigner(sleep).
* l *~ imply in the theory of Universal GrammarKnowledge of Utterances of the Language.parse(\[everybody,-s,love,somebody\],\[ everybodyi \[ sornebodyj \[I" \[NP ei \] \[I' \[I -s\]\[V" \[V" \[V love\] \[NP ej \]\]\]\]\]\]\])parse(\[everybody,-s,love,somebody\],\[ somebodyj \[ everybodyi \[I" \[NP ei \] \[I' \[I -s\]\[V" \[V' \[V love\] \[NP ej \]\]\]\]\]\]\]).
t o l lFigure 3: Knowledge of a Language and itsUtterances.It is important to emphasise that the choice oflogical language and the properties ofutterances computed by the parser are madehere simply on the basis of their familiarityand simplicity: no theoretical significanceshould be attached to them.
I do not claim thatfirst-order logic is the 'language of the mind',nor that the knowledge of utterances computedby the human language processor are instancesof 'parse' relation (see Berwick and Weinberg1984 for further discussion of this last poinO.To construct a deductive parser for GB one buildsa specialized theorem-prover for UniversalGrammar that relates the parameter valuesand lexicon to the 'parse' relation, provides itwith parameter settings and a lexicon ashypotheses, and uses it to derive theconsequences of these hypotheses that describethe utterance of interest.
The UniversalGrammar inference ngine used in the PADparsers is constructed using a Horn-clausetheorem-prover (a Prolog interpreter).
TheHorn-clause theorem-prover is provided withan axiomatization ~/of the theory of Universal243Grammar as well as the hypotheses 9/" thatrepresent the parameter settings and lexicon.Since a set of hypotheses ~rimply a consequenceF in the theory of Universal Grammar if andonly if H u ?./implies F in first-order logic, aHorn -c lause  theorem-prover  us ingaxiomatization ?2 is capable of deriving theconsequences of af that follow in the theory ofUniversal Grammar.
Thus the PAD parsershave the logical structure diagrammed inFigure 4.Knowledge of LanguageAxiomatization of Universal Grammarparse(String, LF) :-xBar(infl2,DS), theta(infl2,0,DS),moveAlpha(DS,\[\],SS,\[\]),caseFilter(infl2,0,SS),phonology(String/\[\],SS),lfMovement(SS,LF).Parameter Settings + Lexiconheadfirst.. .
?thetaAssigner(love).?
.
....... ~ imply in First-order Logic .....................Knowledge of Utterances of the Language.parse(\[ everybody,-s,love,somebody\],\[ everybodyi \[ semebodyj \[I" \[NP ei \] \[I" \[I -s\]Iv" Iv' Iv love\] \[NP ej \]\]\]\]l\]\]).
?
?
.
?
?Figure 4: The Structure of the PAD Parsers.The clause defining the 'parse" relation given inFigure 4 as part of the axiomatization of GBtheory is the actual Prolog definition of 'parse'used in the PAD1 and PAD2 parsers.
Thus thetop-level structure of the knowledge oflanguage mployed by the PAD parsers mirrorsthe top-level structure of GB theory.Ideally the internal structure of the variousprinciples of grammar should reflect theinternal organization of the principles of GB(e.g.
Case assigment should be defined in termsof Government), but for simplicity theprinciples are axiomatized irectly here.
Forreasons of space a complete description of theall of the principles is not given here; howevera sketch of one of the principles, the CaseFilter, is given in the remainder of this section.The other principles are implemented in asimiliar fashion.The Case Filter as formulated in PAD appliesrecursively throughout the S-structure,associating each node with one of the threeatomic values ass, rec or 0.
These valuesrepresent the Case properties of the node theyare associated with; a node associated withthe property ass must be a Case assigner, a nodeassociated with the property rec must becapable of being assigned Case, and a nodeassociated with the property 0 must be neutralwith respect to Case.
The Case Filterdetermines if there is an assignment of thesevalues to nodes in the tree consistent with theprinciples of Case assignment.
A typicalassignment of Case properties to the nodes of anS-structure in English is shown in 5, where theCase properties of a node are depicted by theboldface annotations on that node.
1INFL" : 0NP : rec INFL' : asseverybody INFL: ass VP: 0i !be / V ' : 0V :0  NP:0I Iloved eFigure 5: Case Properties.The Case Filter is parameterizeci with respectto the predicates 'rightwardCaseAssignment'and qeftwardCaseAssignment'; if these arespecified as parameter settings of the languageconcerned, ~the Case Filter permits Caseassigners and receivers to appear in therelevant linear order.
The lexicon containsdefinitions of the one-place predicates'noC.ase', "assignsCase' and 'needsCase' whichhold of lexical items with the relevant1 These annotations are reminiscent of thecomplex feature bundles associated with categoriesin GPSG (Gazdar et.
al.
1986).
The formulation herediffers from the complex feature bundle approachin that the values associated with nodes by the CaseFilter are not components of that node's categorylabel, and hence are invisible to other principles ofgrammar.
Thus this formulation imposes aninformational encapsulation of the principles ofgrammar that the complex feature approach doesnot.244property; these predicates are used by the CaseFilter to ensure the associations of Caseproperties with lexical items are valid.Specifically, the Case Filter liscences thefollowing structures:(2a) a constituent with no Case properties mayhave a Case assigner and a Case receiveras daughters iff they are in theappropriate order for the languageconcerned,(2b) a constituent with no Case properties mayhave any number of daughters with noCase properties,(2c) a constituent with Case property C may berealized as a lexical item W if W ispermitted by the lexicon to have Caseproperty C, and(2d) INFL' assign Case to its left if its INFLdaughter is a Case assigner.This axiomatization of Universal Grammartogether with the parameter values andlexicon for English is used as the axiom set of aProlog interpreter to produce the parser calledPAD1.
Its typical behaviour is shown below.
2:parse(\[everybody, - s, love, somebody\], IF)LF = everybody::i^somebody::j^infl2:\[np:i,infll:\[infl: # (- s), vp:\[vl:\[v: # love, np.~\]\]\]\]LF = somebody:.-j^everybody::i^infl2:\[np:i,infll:\[infl: # (- s), vp:\[vl:\[v:.
# love, np.
'j\]\]\]\]No  (more) solutions:parse(\[harry, be, Ioved\], LF)LF = infl2:\[np: # harry, infll:\[infl: # be,vp:\[vl:\[v: # loved, np:\[\]\]\]\]\]No  (more) solutionsAN ALTERNATIVE CONTROL STRUCTUREBecause it uses the SLD inference controlstrategy of Prolog with the axiomatization ofUniversal Grammar shown above, PAD1functions as a 'generate and test' parser.Specifically, it enumerates all D-structuresthat satisfy X'-theory, filters those that failto satisfy O-theory, computes the corresponding2 For the reasons explained below, the X'principle used in this run of parser was restricted toallow only finitely many D-structures.S-structures using Move-(z, removes all S-structures that fail to satisfy the Case Filter,and only then determines if the terminal stringof the S-structure is the string it was given toparse.
Since the X' principle admits infinitelymany D-structures the resulting procedure isonly a semi-decision procedure, i.e.
the parseris not guaranteed to terminate onungrammatical input.Clearly the PAD1 parser does not use itsknowledge of language in an efficient manner.It would be more efficient o co-routine betweenthe principles of grammar, checking eachexisting node for well-formedness with respectto these principles and ensuring that theterminal string of the partially constructed S-structure matches the string to be parsed beforecreating any additional nodes.
Because theParsing as Deduction framework conceptuallyseparates the knowledge used by the processorfrom the manner in which that knowledge isused, we can use an inference control strategythat applies the principles of grammar in themanner just described.
The PAD2 parserincorporates the same knowledge of language asPAD1 (in fact textually identical), but it usesan inference control strategy inspired by the'freeze' predicate of Prolog-II (Cohen 1985,Giannesini et.
al.
1986)to achieve this goal.The control strategy used in PAD2 allowsinferences using specified predicates to bedelayed until specified arguments to thesepredicates are at least partially instantiated.When some other application of an inferencerule instantiates such an argument the currentsequence of inferences is suspended and thedelayed inference performed immediately.Figure 6 lists the predicates that are delayedin this manner, and the argument hat theyrequire to be at least partially instantiatedbefore inferences using them will proceed.Predicate Delayed onX' theoryO theoryMove-uCase FilterPhonologyLF-MovementD-structureD-st~'uctureS-structureS-structurenot delayedS-structureFigure 6: The Control Strategy of PAD2.With this control strategy the parsing processproceeds as follows.
Inferences using the X', O,245Case, Move-a and LF-movement principles areimmediately delayed since the relevantstructures are uninstantiated.
The 'phonology"principle (a simple recursive tree-walkingpredicate that collects terminal items) is notdelayed, so the parser begins performinginferences associated with it.
Theseinstantiate the top node of the S-structure, sothe delayed inferences resulting from the CaseFilter, Move-a  and LF-movement areperformed.
The inferences associated withMove-a  result in the instantiation of the topnode(s) of the D-structure, and hence thedelayed inferences associated with the X" andO principles are also performed.
Only after allof the principles have applied to the S-structure node instantiated by the "phonology"relation and the corresponding D-structurenode(s) instantiated by Move-a are any furtherinferences associated with the 'phonology"relation performed, causing the instantiation offurther S-structure nodes and the repetition ofthe cycle of activation and delaying.Thus the PAD2 parser simultaneously constructsD-structure, S-structure and LF representationsin a top-down left-to-right fashion, functioningin effect as a recursive descent parser.
This toi>-down behaviour is not an essential property of aparser such as PAD2; using techniques based onthose described by Pereira and Shieber (1987)and Cohen and Hickey (1987) it should bepossible to construct parsers that use the sameknowledge of language in a bottom-up fashion.TRANSFORMING THE AXIOMATIZATIONIn this section I sketch a programtransformation which transforms the originalaxiomatization of the grammar to anequivalent axiomatization that in effectexhibits this 'co-routining' behaviour whenexecuted using Prolog's SLD inference controlstrategy.
Interestingly, a data-flow analysis ofthis transformed axiomatization (viewed as aProlog program) justi f ies a furthertransformation that yields an equivalentprogram that avoids the construction of D-structure trees altogether.
The resultingparsers, PAD3 - PADS, use the same parametersettings and lexicon as PAD1 and PAD2, andthey provably compute the same PF-LFrelationship as PAD2 does.
The particulartechniques used to construct these parsersdepend on the internal details of theformulation of the principles of grammaradopted here - specifically on their simplerecursive structure - and I do not claim thatthey will generalize to more extensiveformulations of these principles.Recall that the knowledge of a languageincorporated in PAD1 and PAD2 consists of twoseparate components, (i) parameter values anda lexicon, and (ii) an axiomatization U of thetheory of Universal  Grammar.
Theaxiomatization U specifies the deductivelyclosed set of statements that constitute thetheory of Universal Grammar, and clearly anyaxiomatization U' equivalent o U (i.e.
onewhich defines the same set of statements)defines exactly the same theory of UniversalGrammar.
Thus the original axiomatization Uof Universal Grammar used in the PAD parserscan be replaced with any equivalentaxiomatization U' and the system will entailexactly the same knowledge of the utterances ofthe language.
A deductive parser using U' inplace of U may perform a differer~ce sequence ofinference steps but ultimately it will infer anidentical set of consequences (ignoring non-termination).The PAD3 parser uses the same parametervalues and lexicon as PAD1 and PAD2, but ituses a reaxiomatization f Universal Grammarobtained by applying the Unfo ld /Fo ldtransformation described and proven correct byTamaki and Sato (1984) and Kanamori andHoriuchi (1988).
Essentially, the Unfold/Foldtransformation is used here to replace asequence of predicates each of whichrecursively traverses the same structure by asingle predicate recursive on that structure thatrequires every node in that structure to meet alof the constraints imposed by the originalsequence of predicates.
In the PAD3 parser theX', @, Move-a, Case and Phonology principlesused in PAD1 and PAD2 are folded andreplaced by the single predicate 'p" that holdsof exactly the D-structure, S-structure PFtriples admitted by the conjunction of theoriginal principles.Because the reaxiomatization technique usedhere replaces the original axiomatization ofPAD1 and PAD2 with an equivalent one (in thesense of the minimum Herbrand modelsemantics), the PAD3 parser provably infers246exactly the same knowledge of language asPAD1 and PAD2.
Because PAD3's knowledge ofthe principles of grammar that relate D-structure, S-structure and PF is now representedby the single recursive predicate 'p' that checksthe well-formedness of a node with respect oall of the relevant principles, PAD3 exhibitsthe 'co-routining" behaviour of PAD2 ratherthan the 'generate and test" behaviour ofPAD1, even when used with the standard SLDinference control strategy of Prolog.
3PAD3 constructs D-structures, just as PAD1 andPAD2 do.
However, a simple analysis of thedata dependencies in the PAD3 program showsthat in this particular case no predicate usesthe D-structure value returned by a call topredicate 'p' (even when 'p' calls itselfrecursively, the D-structure value returned isignored).
Therefore replacing the predicate 'p'with a predicate 'pl '  exactly equivalent to 'p'except that it avoids construction of any D-structures does not affect he set of consequencesof these axioms.
4 The PAD4 parser is exactlythe same as the PAD3 parser, except hat ituses the predicate 'pl '  instead of "p', so ittherefore computes exactly the same PF - LFrelationship as all of the other PAD parsers,but it avoids the construction ofany D-structurenodes.
That is, the PAD4 parser makes use ofexactly the same parameter settings andlexicon as the other PAD parsers, and it usesthis knowledge to compute xactly the sameknowledge of utterances.
It differs from theother PAD parsers in that it does not use thisknowledge to explicitly construct a D-structurerepresentation f the utterance it is parsing.This same combination of the Unfold/Foldtransformation followed data dependencyanalysis can also be performed on all of theprinciples of grammar simultaneously.
The3 Although in terms of control strategy PAD3is very similiar to PAD2, it is computationally muchmore efficient than PAD2, because it is executeddirectly, whereas PAD2 is interpreted by the meta-interpreter with the 'delay" control structure.4 The generation of the predicate "pl' fromthe predicate 'p' can be regarded an example ofstatic garbage-collection (I thank T. Hickey for thisobservation).
Clearly, a corresponding run-timegarbage collection operation could be performed onthe nodes of the partially constructed D-structuresin PAD2.Unfold/Fold transformation produces apredicate in which a data-dependencyanalysis identifies both D-structure and S-structure values as ignored.
The PAD5 parseruses the result ing predicate as itsaxiomatization of Universal Grammar, thusPAD5 is a parser which uses exactly the sameparameter values and lexicon as the earlierparsers to compute exactly the same PF-LFrelationship as these parsers, but it does sowithout explictly constructing either D-structures or S-structure~To summarize, this section presents three newparsers.
The first, PAD3, utilized a re-axiomatization of Universal Grammar, whichwhen coupled with the SLD inference controlstrategy of Prolog resulted in a parser thatconstructs D-structures and S-structures 'inparallel', much like PAD2.
A data dependencyanalysis of the PAD3 program revealed thatthe D-structures computed were never used, andPAD4 exploits this fact to avoid theconstruction of D-structures entirely.
Thetechniques used to generate PAD4 were alsoused to generate PADS, which avoids theexplicit construction ofboth D-structures and S-structures.CONCLUSION.In this paper I described several deductiveparsers for GB theory.
They knowledge oflanguage that they used incorporated the to Wlevel structure of GB theory,  thusdemonstrating that parsers can actually bebuilt that directly reflect the structure of thistheory.This work might be extended in several ways.First, the fragment of English covered by theparser could be extended to include a widerrange of linguistic phenomena.
It would beinteresting to determine if the techniquesdescribed here to axiomatize the principles ofgrammar and to reaxiomatize UniversalGrammar to avoid the construction of D-structures could be used on this enlargedfragment - a program transformation forreaxiomatizing a more general formulation ofMove-ct is given in Johnson (1988b).Second, the axiomatization f the principles ofUniversal Grammar could be reformulated toincorporate the 'internal' deductive structure of247the components of GB theory.
For example, onemight define c-command or goverment asprimitives, and define the principles in termsof these.
It would be interesting todetermine ifa deductive parser can take advantage of thisinternal deductive structure in the same waythat the PAD parsers utilized the deductiverelationships between the various principles ofgrammar.Third, it would be interesting to investigate heperformance of parsers using various inferencecontrol strategies.
The co-routining strategyemployed by PAD2 is of obvious interest, as areits deterministic and non-deterministic bottom-up and left-corner variants.
These only scratchthe surface of possibilities, ince the Parsing asDeduction framework allows one to straight-forwardly formulate control strategiessensitive tO the various principles of grammar.For example, it is easy to specify inferencecontrol strategies that delay all computationsconcerning particular principles (e.g.
bindingtheory) until the end of the parsing process.Fourth, one might attempt to developspecialized logical languages that arecapabale of expressing knowledge of languagesand knowledge of utterances in a more succinctand computationally useful fashion than thefirst-order languages.BIBLIOGRAPHYBerwick, R. (1987) Principle-based Parsing.MIT Artificial Intell igence LaboratoryTechnical Report No.
972.
Also to appear inThe Processing of Linguistic Structure, The MITPress, Cambridge, Mass.Berwick, R. and A. Weinberg.
(1984) TheGrammatical Basis of Linguistic Performance.The MIT Press, Cambridge, Mass.Chomsky, N. (1981) Lectures on Government andBinding.
Foris, Dordrect.Chomsky, N. (1986) Knowledge of Language,Its Nature, Origin and Use.
Praeger, New York.Cohen, J.
(1985) Describing Prolog by itsInterpretation and Compilation.
C. ACM.28:12, p. 1311-1324.Cohen, J. and T. Hickey.
(1987) Parsing andCompiling Using Prolog.
ACM Trans.Programming Languages and Systems.
9:2, p.125-163.Gazdar, G., E. Klein, G. Pullum and I.
Sag.
(1985) Generalized Phrase Structure Grammar.Basil Blackwell, Oxford.Giannesini, F., H. Kanoni, R. Pasero, and M. v.Caneghem.
Prolog.
Addison-Wesley, Reading,Mass.
1986.Johnson, M. (1988a) Parsing as Deduction, theUse of Knowledge of Language, ms.Johnson, M. (1988b) Computing with Move-ausing the Unfold-Fold Transformation, ms.Kanamori, T. and K. Horiuchi (1988)Construction of Logic Programs Based onGeneralized Unfold/Fold Rules, in Lassez, ed.,Proceedings of the Fourth InternationalConference of Logic Programming, p. 744 - 768,The MIT Press, Cambridge, Mass.Pereira, F. and S. Shieber.
(1987) Prolog andNatural Language Processing.
CSLI LectureNotes Series, d is t r ibuted by ChicagoUniversity Press.
Chicago.Pereira, F. and D. Warren.
(1983) Parsing asDeduction.
In Proceedings of the 21st AnnualMeeting of the Association for ComputationalUnguistics, MIT, Cambridge, Mass.Tamaki, H. and T. Sato.
(1984) Unfold/FoldTransformation of Logic Programs.
InProceedings of the Second International LogicProgramming Conference, p. 127-138, UppsalaUniversity, Uppsala, Sweden.Van Riernsdijk, H. and E. Williams.
(1986)Introduction to the Theory of Grammar.
TheMIT Press, Cambridge, Mass.248
