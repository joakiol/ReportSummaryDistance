A New Pattern Matching Approach to the Recognition of PrintedArabicAli M. OBAIDDepartment ofMeasurement and Information SystemsTechnical University of BudapestI-1-1521 Budapest, Mfiegyetem rkp.
9.e-mail: obaid@mmt.bme.huAbstractThe paper presents a new segmentation-freeapproach to the Arabic optical characterrecognition.
Extended with a suitable pre-and post-processing the method offers asimple and fast framework to develop a fullOCR system.
The method was developedprimarily for the Naskhi font, it is howeverrobust and flexible and can be easilyextended.IntroductionThe most difficult problem in Arabic opticalcharacter recognition (AOCR) is to decide howto handle the cursiveness of the text.
Thus whilethe segmentation is relatively simple in printedRoman texts, it is still an open question inArabic.
In most of the reported AOCR researchthe segmentation is considered the main sourceof recognition errors, see e.g.
A1-Badr (1995).
Inaddition, the presence of ligatures, especiallythose composed from dotted characters, adds tothe problem so much, that until recently theywere almost entirely omitted from the research.For a review of some of the problems of AOCRsee Fig.
1.AOCR followed the main approaches tried inRoman OCR research, consequently it focusedfor a long time on the issue of segmentation.Although various segmentation algorithms hadbeen devised, see e.g.
Amin (1989), cursivenessintroduced serious problems, difficult tocompensate even by additional processing.
Theapplication of advanced techniques, like neuralnetworks, fuzzy techniques and hidden Markovmodels did not bring the expected breakthrough,due to the inherent segmentation problems, seeWalker (1993).
Recently, A1-Badr (1995)attempted to avoid segmentation at all.
Usingmorphological operators he tried to recognize atleast a part of a word and then the entire wordby searching a large data-base of references.
Thescheme was handicapped however by theextensive Arabic vocabulary.1 The Outline of the ApproachThe proposed approach can dispense with thetraditional segmentation, and in advancedversion even with the segmentation i to sub-words and text lines.
The basic idea is that notevery component of an character is essential tothe OCR-process.
Consequently, computingfeatures from non-informative segmentswouldn't contribute to the recognition.
Contraryto the traditional segmentation where words arescanned looking for segment boundaries, inpresented approach special points are identifiedin the interior of the characters.
These pointsserve as references for configurations of sensors(referred to as focal points and N-markersrespectively) designed to identify the essentialcharacter strokes.
By distributing enoughmarkers over a character, a letter or a group ofletters (ligature) can be positively detected.
Theapproach is related to some early ideas of theOCR of the isolated Roman characters (N-tuplesand Character Loci), see Ullman (1969).For all of the practical purposes the presentedmethod must be extended with obligatory and106optional processing steps.
The scanned textshould be treated for minor noise removal, skewcorrected and normalized.
In the basic algorithmtext lines and words should be separated, thenthinned and smoothed.
The method should becompleted with symbolic rules resolving theresidual ambiguities of the kernel method.The present research was aimed at therecognition of printed Arabic, widely used inbooks and renown periodicals.
Such texts areprinted almost entirely in so-called Naskhi font,sometimes even identified with the printedArabic.
Various typesetting sources introducehowever variations to the basic Naskhi shapes,which means further problems in therecognition.
The tackled AOCR problem ishence, on the one hand, restricted to a singlealbeit extensively used font.
On the other handminor font variations and a wide spectrum ofligatures are treated.
We aimed also at a methodrobust enough to handle degraded text andadaptable to other fonts if required.2 N-MarkersAs an example let us consider the isolatedcharacters 'Waw' and 'Qaf (Fig.
2.).
Both shapesposses loops and tails, however the topology oftails differ.
Let us assume that a suitable focalpoint (the junction below the loop) is alreadydetected.
Then the presence or the absence of atail can be measured by placing marker m,below the junction on the expected path of thetail.
That way we attempted to restrict he classof shapes to both 'Waw' and 'Qat'.
Anothermarker m,, placed well to the left, willdistinguish now between them.
Interpreting thepresence of the shape fragment under themarkers in terms of logical functions we haveaccordingly:'Qaf = (m, = YES) AND (m 2= YES), while'Waw' = (m t = YES) AND (mz= NOT).For a meaningful detection focal points shouldbe properly selected.
Such points (line ends,junctions and a number of special patterns)should be 'stable', i.e.
easy to detect, relativelyimmune to distortions and of pronouncedappearance in all of the investigated fontvariations.
Definition of the markers requiresfurther an uniform normalization of the textlines (chosen as 100 pixels high, which togetherwith the assumed minimal size of 12 point stillyields an acceptable quantization noise).Contrary to the schemes found in the literature(e.g.
Citing (1982)), classifying the shapes is notbased primarily on the shape similarity, butrather on focal points and marker (stroke)configurations instead.
E.g.
'initial Lanl' issimilar to 'medial Lam', yet their focal points aredifferent (a line end vs. a junction).Consequently, they belong to different classes.The rationale of this approach is that it allowsrecognition of multiple shapes by the samemarker configuration, making thus the treatmentof ligatures more straightforward.Consider for example the shape class in Fig.
3.It contains six shapes: four characters (initial,medial, terminal and isolated 'Hha') and twoligatures ('Lam+Hha' and 'Meem+Hha').
Awell developed 3-way junction is used as localpoint.
Markers m~, m,, m,, and m~ detect strokescommon to the class members.
Remainingmarkers are used to differentiate betweenparticular shapes.
For every shape Boolean testfunctions are defined, e.g.
:medial 'Hha' =-~ (mlvm2vm~vmTvms)A(ms^m,^ms^m,)where the logical value of m I depends whetherthe required stroke is present or not.For a moment N-markers configurations weredesigned manually by collecting sufficientnumber of thinned samples.
After choosing asuitable focal point the shapes weresuperimposed and aligned to show how muchthey vary.
Marker configurations were definedaround the designated focal point, by assigningmarkers to every critical line segment.
Theywere then iteratively tested and modified.3 Pre- and Post-ProcessingThe kernel of any OCR system are featureextraction and classification.
In practice theseoperations must be preceded by suitable107procedures collectively called pre-processing.
Inthe proposed system pre-processing includesminor noise removal, correction for skewness,line separation, ormalization of the text lines,word separation, dot extraction, thinning of theisolated words, and smoothing of the wordskeletons.Although the proposed method (by definingfocal point patterns in larger windows andintroducing approximate instead of exactmatching) could be applied to regular (non-thinned) words, focal points are much easier tofind along thinned skeletons.
Several thinningalgorithms are available in the literature, seeLam (1992).
The single dots are, however, acritical issue, and should be extracted beforethinning.
In time of development of the methodno satisfactory thinning algorithm could befound, consequently further processing(smoothing) of the skeleton was necessary.To complete the method a suitable post-processing is also required to correct recognitionerrors and side-effects introduced by pre-processing and classification.
In the proposedsystem post-processing is performed bysymbolic rules.
Redundancy removal rules areneeded due to the necessary trade-offs indesigning N-markers configurations.
Usingsimple rules is a more straightforward strategythan increasing the number of markers.
Dot and'Hamza ' association rules complete therecognition of shapes (especially ligatures),differentiated solely by the presence of dots or'Hamza'.
Ambiguity resolution rules handlecases when (in poor quality text) thinned imagesof 'Hamza' and three dots coincide.
FinallyCombining shapes rules connect subcharactersinto characters if necessary.4 Verification of the MethodFor the testing ten densely printed pages(including ligatures) were scanned, using liPScan Jet Ilcx Scanner at 300 dpi resolution,from a good quality book type-set in Naskhifont, Haekl (1983), together with two pages ofdegraded text taken from a magazine printed ona highly reflective and smooth paper, A1-Arabi(1996).
Due to the very low incidence of someof the ligatures, acollection of ligatures (2 pagesof unrelated words each containing at least oneligature) was prepared (.printed and scanned) fortesting purposes.
In addition, suitable files fromthe test repository of A1-Badr, see WWW inReferences, were also borrowed for testing.Frequent shapes showed recognition rates of95%-98%.
Testing for rare shapes (on artificialsamples) yielded similar results.
Recognitionrate for degraded image (filled loops) dropped,as expected.
Last test involved two degradedpages from the magazine.
To deal withdegradation, markers were enlarged from 1-dimline segments to 2-dim windows, coveringlarger portions of the strokes, without disturbinghowever their configuration relative to focalpoints and being that way more robust, yet stillselective enough (see Fig.
4.).
The methodyielded results comparable to those obtained forgood quality pages.
The only problem observedin the testing were loops.Time needed to process a full page (pre-processing, detection of focal points, worst-caseapplication of the markers, and post-processing)was estimated as app.
135 sec.
which wasequivalent to the recognition rate of 340characters/minute.
This result is promisingconsidering that it represented the lower limit ofperformance.5 Extensions to the MethodThe basic implementation does not exploit fullyother advantageous a pects of the N-markers.Treatment of elongation is easy, considering thatno focal points appear along an elongated lineand nothing disturbs the detection.
Most shapesinclude several possible focal points.
Inapplying markers, in the worst case, allcandidate focal points have to be considered.
Anintelligent selection of the focal points withrespect o their usefulness would considerablyspeed-up the process.Another possibility is to apply markers also overunthinned strokes.
To this purpose theprocessing of focal points should be extended,108as mentioned, to an approximate matching.
Afurther natural extension is shape extraction/tom a full non-segmented page.
Knowledge ofwhere the text line and word strokes are, is notessential.
Windows detecting focal points can beslid along the whole page in any direction, witha possible parallel implementation.A question to solve is at least a partialautomation of the manual designing of themarkers.
Efficient heuristic algorithm couldpossibly be developed, theoretically the problemis intractable due to the equivalence to the NP-complete N-tuple configuration problem, shownby Jung (1996).
Related question is theextension of the marker configurations to thenew fonts.
Although the target font was thewidely spread Naskhi, the concept of N-markersis not confined to this font alone.
One way ofextending the method is by constructing markersIbr new fonts in a manner describe above.Another approach could be to identify therelation between the fonts as a local nonlinearimage transform.
Then this transform could beused to detbrm the marker configurations to fitthe new shapes.ConclusionExperiments with N-markers show promisingresults.
The main source of errors in AOCR isavoided.
The method is intuitive and works withunified features.
Handling large and diverse setof shapes including ligatures is relatively easy.
'Shape similarity' is based on focal points,rather, than on the apparent visual similarity,which can lead to mistakes.
The accommodationof the possible variations of the font isstraightforward and is insensitive to thecharacter of the shape differences.
The methodis simple to implement and does not requirelengthy numerical computations.
The very ideais open to extensions and is relatively immuneto degradation of the text.
The primarydisadvantage of the basic (thinned words)technique is its dependency on the size andorientation of the text, redundancy of the focalpoints, sensitivity of the focal points todegradation, dependence on the thinned image.These problems can be largely solved byswitching to the unthirmed text processing,which is under investigation.
A question is theheuristic automation of the 'manual tuning' ofthe classes.
Finally some of the essentialprocessing steps of the method are illustrated inFig.
5.ReferencesAI-Arabi (1996) Ministry of Culture, Kuwait, April.A1-Badr B. and Haralick R. (1995) Segmentation-free word recognition with application to Arabic,in Proc.
of the IEEE 3rd Int.
Conf.
on DocumentAnalysis and Recognition - ICDAR'95, p. 355,August.Amin A. and Marl J.
(1989) Machine Recognitionand Correction of Printed Arabic Text, IEEETrans.
on Systems, Man and Cybernetics, vol.
19,no.5, pp.
1300, Sept/OcLChing Y. Suen (1982) Distinctive Features inAutomatic Recognition of HandprintedCharacters, Signal Processing, vol.
4, pp.
193-207.Haekl M. (1983) At the crossroads, Printing andPublishing Comp., Beirut, Lebanon.Jung D., Krishnamoorthy M., Nagy G. and ShapiraA.
(1996) N-Tuple Features for OCR revisited,IEEE Trans.
on Pattern Recognition and MachineIntelligence, vol.
18, no.
7, pp.
734-745, July.Lain L., Lee S,, and Suen C. (1992) ThinningMethodologies - a Comprehensive Survey, IEEETrans.
on PAMI, Vol.14, No.9, pp.
869-884, Sept.Ullman J.
(1969) Experiments with the N-mplemethod of Patter Recognition, IEEE Trans.
onComputers, vol.
18, no.12, pp.
1135-1137, Dec.Walker R. F., Bennamoun M. and Boashash B.
(1993) Comparative Results for Arabic CharacterRecognition Using Artificial Neural Networks, inProc.
of WoSPA'93, SPRC Workshop on SignalProcessing and its Applications, Dec., Brisbane,AustraliaWWWhttp:llge?rge'ee'washingt?n'edul~badrlARABIC'http:llgeorge.ee.washington.edu/-badrlSAIC109d ,..t., a ~ ,..r, d&.co:i:i:i:i:.
!
*J,O JFig.
1.
Problems encountered in the Arabic OCR:Difference between isolated and connectedcharacters; Character shapes differentiated only bydots; Variation in size: medial 'Seen' (fight) andterminal 'Lain' (left); Changing shape due toligation; Similarity of ligatures to the normalcharacters ('Lam'+'Ya' vs. isolated 'Lain', and'Lam'+medial 'Meem' vs. initial 'Lain'); Ligatureswith relatively small body and complicated otconstellations (from left to right: 'Ya'+'Jeem','Ta'+'Kha', 'Ya'+'Kha', 'Ta'+'Jeem', 'Noon'+'Jeem','Ba'+'Kha'); Minute variation in the Naskhi font;Elongation of words..m,m,  .......... S \ [  ........
?
:"iilL:::::: .
.
.
.
.
.
.
.
.
.m.~-~iJ,~7"//m,m ~ .
.
~ : ' ~  ~'.
!
: " :............... :.......... ?
~.x.
.................. ~..... x.f f i~n i2m3m4f f l s f f l~f f lT f f la  r g, , ,*  Laa~+Hha it~m~2 msM4~,sm6m 7 l t la  m~-*  I so la ted  Hh'a.~ .
,~ .~ ................... ~ .
; ,~  .................. ~ ,~.
.
.
.~  ............ :_..:>-~.~ ~k_-L. L ~ ,~J,,_.,,.Fig.
3.
One of the shape classes used in detection(composite shape and N-markers configuration,basic shapes, and test functions for two particularshapes).~:i:i:i: i: i: i: i: i: i:Fig.
4.
Extended markers to compensate distortionproblems.Focal PointsFig.
2.
Selective detection with focal points andmarkers (Qaf - left, and Qaw - fight)..110"iJ."
.'
.::::...
.
.
....?
)."
..f." ....::.
~.. ..., ..:...:: .," , /r' / ,"$.~oti T.db~ C~ptjg.1:~e Tet;m.'Fa' A\]~fT.dbts H~ loopm.. .... .
."
f~ : .
.
.
/ .
.
..... / , "  f?
.
f  ./" / ~ t" t?
:rS.dot : Crisp i Al~fCusp Lig.?
La.in+M .mIF (cusp AND cusp AND cusp ) THEN SeenIF (initial loop AND dot above) THEN inital FaFig.
5.
Essential phases of the proposed characterdetection: thinning, skeleton smoothing, detectingfocal points, applying markers, preliminaryclassification, applying symbolic rules.111
