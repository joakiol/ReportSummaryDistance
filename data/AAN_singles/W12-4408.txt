Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 57?60,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsEnglish-Korean Named Entity Transliteration Using SubstringAlignment and Re-ranking MethodsChun-Kai Wu?
Yu-Chun Wang?
Richard Tzong-Han Tsai?
?Department of Computer Science and Engineering,Yuan Ze University, Taiwan?Department of Computer Science and Information Engineering,National Taiwan University, Taiwans983301@mail.yzu.edu.tw d97023@csie.ntu.edu.twthtsai@saturn.yzu.edu.twAbstractIn this paper, we describe our approachto English-to-Korean transliteration task inNEWS 2012.
Our system mainly consistsof two components: an letter-to-phonemealignment with m2m-aligner,and translitera-tion training model DirecTL-p. We constructdifferent parameter settings to train severaltransliteration models.
Then, we use two re-ranking methods to select the best transliter-ation among the prediction results from thedifferent models.
One re-ranking method isbased on the co-occurrence of the translitera-tion pair in the web corpora.
The other one isthe JLIS-Reranking method which is based onthe features from the alignment results.
Ourstandard and non-standard runs achieves 0.398and 0.458 in top-1 accuracy in the generationtask.1 IntroductionNamed entity translation is a key problem in manyNLP research fields such as machine translation,cross-language information retrieval, and questionanswering.
Most name entity translation is based ontransliteration, which is a method to map phonemesor graphemes from source language into target lan-guage.
Therefore, named entity transliteration sys-tem is important for translation.In the shared task, we focus on English-Koreantransliteration.
We consider to transform the translit-eration task into a sequential labeling problem.
Weadopt m2m-aligner and DirecTL-p (Jiampojamarn etal., 2010) to do substring mapping and translitera-tion predicting, respectively.
With this approach (Ji-ampojamarn et al, 2010) achieved promising resultson NEWS 2010 transliteration tasks.
In order to im-prove the transliteration performance, we also applyseveral ranking techniques to select the best Koreantransliteration.This paper is organized as following.
In section2 we describe the main approach we use includinghow we deal with the data, the alignment and train-ing methods and our re-ranking techniques.
In sec-tion 3, we show and discuss our results on English-Korean transliteration task.
And finally the conclu-sion is in section 4.2 Our ApproachIn this section, we describe our approach forEnglish-Korean transliteration which comprises thefollowing steps:1.
Pre-processing2.
Letter-to-phoneme alignment3.
DirecTL-p training4.
Re-ranking results2.1 Pre-processingKorean writing system, namely Hangul, is alphabet-ical.
However, unlike western writing system withLatin alphabets, Korean alphabet is composed intosyllabic blocks.
Each Korean syllabic block repre-sent a syllable which has three components: initialconsonant, medial vowel and optionally final con-sonant.
Korean has 14 initial consonants, 10 medialvowels, and 7 final consonants.
For instance, the syl-labic block ???
(sin) is composed with three letters:57a initial consonant ???
(s), a medial vowel ???
(i),and a final consonant ???
(n).For transliteration from English to Korean , wehave to break each Korean syllabic blocks into twoor three Korean letters.
Then, we convert these Ko-rean letters into Roman letters according to RevisedRomanization of Korean for convenient processing.2.2 Letter-to-phoneme AlignmentAfter obtaining English and Romanized Koreanname entity pair, we generate the alignment betweeneach pair by using m2m-aligner.Since English orthography might not reflect its ac-tual phonological forms, it makes one-to-one char-acter alignment between English and Korean notpractical.Compared with traditional one-to-one alignment,the m2m-aligner overcomes two problems: One isdouble letters where two letters are mapped to onephoneme.
English may use several characters forone phoneme which is presented in one letter in Ko-rean, such as ?ch?
to ???
and ?oo?
to ???.
How-ever, one-to-one alignment only allows one letter tobe mapped to one phoneme, so it must have to addan null phoneme to achieve one-to-one alignment.It may interfere with the transliteration predictionmodel.The other problem is double phonemes problemwhere one letter is mapped to two phonemes.
Forexample, the letter ?x?
in the English name entity?Texas?
corresponds to two letters ???
and ??
?in Korean.
Besides, some English letters in theword might not be pronounced, like ?k?
in the En-glish word ?knight?.
We can eliminate this by pre-processing the data to find out double phonemes andmerge them into single phoneme.
Or we can addan null letter to it, but this may also disturb the pre-diction model.
While performing alignments, m2maligner allows us to set up the maximum length sub-string in source language (with the parameter x) andin target language (with the parameter y).
Thus,when aligning, we set both parameter x and y to twobecause we think there are at most 2 English lettersmapped to 2 Korean letters.
To capture more doublephonemes, we also have another parameter set withx = 1 and y = 2.As mentioned in previous section, Korean syl-labic block is composed of three or two letters.
Inorder to cover more possible alignments, we con-struct another alignment configurations to take nullconsonant into consideration.
Consequently, for anyKorean syllabic block containing two Korean letterswill be converted into three Roman letters with thethird one being a predefined Roman letter represent-ing null consonant.
We also have two set of param-eters for this change, that is x = 2, y = 3 and x = 1,y = 3.
The reason we increase both y by one is thatthere are three Korean letters for each word.2.3 DirecTL-p TrainingWith aligned English-Korean pairs, we can trainour transliteration model.
We apply DirecTL-p (Ji-ampojamarn et al, 2008) for our training and testingtask.
We train the transliteration models with differ-ent alignment parameter settings individually men-tioned in section 2.2.2.4 Re-ranking ResultsBecause we train several transliteration models withdifferent alignment parameters, we have to combinethe results from different models.
Therefore, there-ranking method is necessary to select the besttransliteration result.
For re-ranking, we proposetwo approaches.1.
Web-based re-ranking2.
JLIS-Reranking2.4.1 Web-based re-rankingThe first re-ranking method is based on the oc-currence of transliterations in the web corpora.
Wesend each English-Korean transliteration pair gen-erated by our transliteration models to Google websearch engine to get the co-occurrence count of thepair in the retrieval results.
But the result numbermay vary a lot, most of them will get millions ofresults while some will only get a few hundred.2.4.2 JLIS-RerankingIn addition to web-based re-ranking approach, wealso adopt JLIS-Reranking (Chang et al, 2010) tore-rank our results for the standard run.
For anEnglish-Korean transliteration pair, we can mea-sure if they are actual transliteration of each otherby observing the alignment between them.
Since58Table 1: Results on development data.Run Accuracy Mean F-score MRR MAPref1 (x = 2, y = 2) 0.488 0.727 0.488 0.4882 (x = 1, y = 2) 0.494 0.730 0.494 0.4943 (x = 1, y = 3, with null consonant) 0.452 0.713 0.452 0.4524 (x = 2, y = 3, with null consonant) 0.474 0.720 0.474 0.473Web-based Reranking 0.536 0.754 0.563 0.536JLIS-Reranking 0.500 0.737 0.500 0.500Table 2: Results on test dataRun Accuracy Mean F-score MRR MAPrefStandard (JLIS-Reranking) 0.398 0.731 0.398 0.397Non-standard (Web-based reranking) 0.458 0.757 0.484 0.458DirecTL-p model outputs a file containing the align-ment of each result, there are some features in theresults that we can use for re-ranking.
In our re-ranking approach, there are three features used inthe process: source grapheme chain feature, targetgrapheme chain feature and syllable consistent fea-ture.
These three feature are proposed in (Song etal., 2010).Source grapheme chain feature: This featurecan tell us that how the source characters are aligned.Take ?A|D|A|M?
for example, we will get threechains which are A|D, D|A and A|M.
With this fea-ture we may know the alignment in the source lan-guage.Target grapheme chain feature: Similar to theabove feature, it tell us how the target characters arealigned.
Take ?NG:A:n|D|A|M?
for example, whichis the Korean transliteration of ADAM, we will getthree chains which are n|D, D|A and A|M.
With thisfeature we may know the alignment in the target lan-guage.
?n?
is the predefined null consonant.Syllable consistent feature: We use this featureto measure syllable counts in both English and Ko-rean.
For English, we apply an Perl module1 to mea-sure the syllable counts.
And for Korean, we simplycount the number of syllabic blocks.
This featuremay guard our results, since a wrong prediction maynot have the same number of syllable.1http://search.cpan.org/?gregfast/Lingua-EN-Syllable-0.251/Syllable.pmOther than the feature vectors created by abovefeatures, there is one important field when trainingthe re-ranker, performance measure.
For this field,we give it 1 when we predict a correct result other-wise we give it 0 since we think it is useless to get apartially correct result.3 ResultTo measure the transliteration models with differentalignment parameters and the re-ranking methods,we construct several runs for experiments as follows.?
Run 1: m2m-aligner with parameters x = 2and y = 2.?
Run 2: m2m-aligner with parameters x = 1and y = 2.?
Run 3: m2m-aligner with parameters x = 1and y = 3 and add null consonants in the Ko-rean romanized representation.?
Run 4: m2m-aligner with parameters x = 2and y = 3 and add null consonants in the Ko-rean romanized representation.?
Web-based reranking: re-rank the results fromrun 1 to 4 based on Google search results.?
JLIS-Reranking: re-rank the results from run 1to 4 based on JLIS-rerakning features.Table 1 shows our results on the developmentdata.
As we can see in this table, Run 2 is better thanRun 1 by 6 NEs.
It may be that the data in develop59set are double phonemes.
And we also observe thatboth Run 1 and Run 2 is better than Run 3 and Run4, the reason may be that the extra null consonantdistract the performance of the prediction model.From the results, it shows that our re-rankingmethods can actually improve transliteration.Reranking based on web corpora can achieve betteraccuracy compared with web-based reranking.The JLIS-Reranking method slightly improve theaccuracy.
It could be that the features we useare not enough to capture the alignment betweenEnglish-Korean NE pair.Because the runs with re-ranking achieving bet-ter results, we submit the result on the test data withJLIS-Reranking as the standard run, and the resultwith the web-based re-ranking as the non-standardrun for our final results.
The results on the test dataset are shown in table 2.
The results also shows thatthe web-based re-ranking can achieve the best accu-racy up to 0.458.4 ConclusionIn this paper, we describe our approach to English-Korean named entity transliteration task for NEWS2012.
First, we decompose Korean word into Ko-rean letters and then romanize them into sequentialRoman letters.
Since a Korean word may not containthe final consonant, we also create some alignmentresults with the null consonant in romanized Koreanrepresentations.
After preprocessing the trainingdata, we use m2m-aligner to get the alignments fromEnglish to Korean.
Next, we train several translitera-tion models based on DirecTL-p with the alignmentsfrom the m2m-aligner.
Finally, we propose twore-ranking methods.
One is web-based re-rankingwith Google search engine.
We send the EnglishNE and its Korean transliteration pair our modelgenerates to Google to get the co-occurrence countto re-rank the results.
The other method is JLIS-reranking based on three features from the alignmentresults, including source grapheme chain feature,target grapheme chain feature, and syllable consis-tent feature.
In the experiment results, our methodachieves the good accuracy up to 0.398 in the stan-dard run and 0.458 in non-standard run.
Our resultsshow that the transliteration model with a web-basedre-ranking method can achieve better accuracy inEnglish-Korean transliteration.ReferencesMing-Wei Chang, Vivek Srikumar, Dan Goldwas-ser, andDan Roth.
2010.
Structured output learning with indi-rect supervision.
Proceeding of the International Con-ference on Machine Learning (ICML).Sittichai Jiampojamarn, Grzegorz Kondrak, and TarekSherif.
2007.
Applying many-to-many alignmentsand hidden markov models to letter-to-phoneme con-version.
Association for Computational Linguistics,pages 372?379.Sittichai Jiampojamarn, Colin Cherry, and GrzegorzKondrak.
2008.
Joint processing and discriminativetraining for letter-to-phoneme conversion.
Associationfor Computational Linguistics, pages 905?912.Sittichai Jiampojamarn, Kenneth Dwyer, Shane Bergsma,Aditya Bhargava, Qing Dou, Mi-Young Kim, andGrzegorz Kondrak.
2010.
Transliteration generationand mining with limited training resources.
Proceed-ings of the 2010 Named Entities Workshop, ACL 2010,pages 39?47.Yan Song, Chunyu Kit, and Hai Zhao.
2010.
Rerankingwith multiple features for better transliteration.
Pro-ceedings of the 2010 Named Entities Work-shop, ACL2010, pages 62?65.60
