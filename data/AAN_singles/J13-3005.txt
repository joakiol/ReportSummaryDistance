XMG: eXtensible MetaGrammarBeno?
?t Crabbe?
?INRIA - Universite?
Paris 7Denys Duchier?
?LIFO - Universite?
d?Orle?ansClaire Gardent?CNRS - LORIA, NancyJoseph Le Roux?LIPN - Universite?
Paris NordYannick Parmentier?LIFO - Universite?
d?Orle?ansIn this article, we introduce eXtensible MetaGrammar (XMG), a framework for specifyingtree-based grammars such as Feature-Based Lexicalized Tree-Adjoining Grammars (FB-LTAG)and Interaction Grammars (IG).
We argue that XMG displays three features that facilitateboth grammar writing and a fast prototyping of tree-based grammars.
Firstly, XMG is fullydeclarative.
For instance, it permits a declarative treatment of diathesis that markedly departsfrom the procedural lexical rules often used to specify tree-based grammars.
Secondly, the XMGlanguage has a high notational expressivity in that it supports multiple linguistic dimensions,inheritance, and a sophisticated treatment of identifiers.
Thirdly, XMG is extensible in that itscomputational architecture facilitates the extension to other linguistic formalisms.
We explainhow this architecture naturally supports the design of three linguistic formalisms, namely,FB-LTAG, IG, and Multi-Component Tree-Adjoining Grammar (MC-TAG).
We further showhow it permits a straightforward integration of additional mechanisms such as linguistic andformal principles.
To further illustrate the declarativity, notational expressivity, and extensibilityof XMG, we describe the methodology used to specify an FB-LTAG for French augmented with a?
UFR de Linguistique, Universite?
Paris Diderot-Paris 7, Case 7003, 2, F-75205 Paris Cedex 13, France.E-mail: bcrabbe@linguist.jussieu.fr.??
Laboratoire d?Informatique Fondamentale d?Orle?ans, Ba?timent IIIA, Rue Le?onard de Vinci, B.P.
6759,F-45067 Orle?ans Cedex 2, France.
E-mail: denys.duchier@univ-orleans.fr.?
Laboratoire LORIA - CNRS, Projet Synalp, Ba?timent B, BP 239, Campus Scientifique, F-54506Vand?uvre-Le`s-Nancy Cedex, France.
E-mail: gardent@loria.fr.?
Laboratoire d?Informatique de Paris Nord, UMR CNRS 7030, Institut Galile?e - Universite?
Paris-Nord, 99,avenue Jean-Baptiste Cle?ment, F-93430 Villetaneuse, E-mail: leroux@univ-paris13.fr.?
Laboratoire d?Informatique Fondamentale d?Orle?ans, Ba?timent IIIA, Rue Le?onard de Vinci, B.P.
6759,F-45067 Orle?ans Cedex 2, France.
E-mail: yannick.parmentier@univ-orleans.fr.Submission received: 27 March 2009; revised version received: 2 July 2012; accepted for publication:11 August 2012.doi:10.1162/COLI a 00144?
2013 Association for Computational LinguisticsComputational Linguistics Volume 39, Number 3unification-based compositional semantics.
This illustrates both how XMG facilitates themodeling of the tree fragment hierarchies required to specify tree-based grammars and of asyntax/semantics interface between semantic representations and syntactic trees.
Finally, webriefly report on several grammars for French, English, and German that were implementedusing XMG and compare XMG with other existing grammar specification frameworks fortree-based grammars.1.
IntroductionIn the late 1980s and early 1990s, many grammar engineering environments weredeveloped to support the specification of large computational grammars for naturallanguage.
One may, for instance, cite XLE (Kaplan and Newman 1997) for specifyingLexical-Functional Grammars (LFG), LKB (Copestake and Flickinger 2000) for speci-fying Head-driven Phrase Structure Grammars (HPSG), and DOTCCG (Baldridgeet al2007) for specifying Combinatory Categorial Grammars (CCG).
Concretely, suchenvironments usually rely on (i) a formal language used to describe a target com-putational grammar, and (ii) a processor for this language, which aims at generatingthe actual described grammar (and potentially at checking it, e.g., by feeding it toa parser).Although these environments were tailored for specific grammar formalisms, theyshare a number of features.
Firstly, they are expressive enough to characterize subsetsof natural language.
Following Shieber (1984), we call this feature weak completeness.Secondly, they are notationally expressive enough to relatively easily formalize importanttheoretical notions.
Thirdly, they are rigorous, that is, the semantics of their underlyinglanguage is well defined and understood.
Additionally, for an environment to be usefulin practice, it should be simple to use (by a linguist), and make it possible to detect errorsin the described target grammar.If we consider a particular type of computational grammar, namely, tree-basedgrammars?that is, grammars where the basic units are trees (or tree descriptions) ofarbitrary depth, such as Tree-Adjoining Grammar (TAG; Joshi, Levy, and Takahashi1975), D-Tree Grammar (DTG; Rambow, Vijay-Shanker, and Weir 1995), Tree DescriptionGrammars (TDG; Kallmeyer 1999) or Interaction Grammars (IG; Perrier 2000)?environments sharing all of the listed features are lacking.
As we shall see in Section 7of this article, there have been some proposals for grammar engineering environmentsfor tree-based grammar (e.g., Candito 1996; Xia, Palmer, and Vijay-Shanker 1999,but these lack notational expressivity.
This is partly due to the fact that tree-basedformalisms offer an extended domain of locality where one can encode constraintsbetween remote syntactic constituents.
If one wants to define such constraints whilegiving a modular and incremental specification of the grammar, one needs a high levelof notational expressivity, as we shall see throughout the article (and especially inSection 4).In this article, we present XMG (eXtensible MetaGrammar), a framework forspecifying tree-based grammars.
Focusing mostly on Feature-Based Lexicalized Tree-Adjoining Grammars (FB-LTAG) (but using Interaction Grammars [IG] and Multi-Component Tree-Adjoining Grammars [MC-TAG] to illustrate flexibility), we argue thatXMG departs from other existing computational frameworks for designing tree-basedgrammars in three main ways: First, XMG is a declarative language.
In other words, grammaticality isdefined in an order-independent fashion by a set of well-formedness592Crabbe?
et alXMG: eXtensible MetaGrammarconstraints rather than by procedures.
In particular, XMG permits afully declarative treatment of diathesis that markedly departs from theprocedural rules (called meta-rules or lexical rules) previously used tospecify tree-based grammars. Second, XMG is notationally expressive.
The XMG language supports fulldisjunction and conjunction of grammatical units, a modular treatmentof multiple linguistic dimensions, multiple inheritance of units, and asophisticated treatment of identifiers.
We illustrate XMG?s notationalexpressivity by showing (i) how it facilitates the modeling of the treefragment hierarchies required to specify tree-based grammars and (ii) howit permits a natural modeling of the syntax/semantics interface betweensemantic representations and syntactic trees as can be used in FB-LTAG. Third, XMG is extensible in that its computational architecture facilitates(i) the integration of an arbitrary number of linguistic dimensions (syntax,semantics, etc.
), (ii) the modeling of different grammar formalisms(FB-LTAG, MC-TAG, IG), and (iii) the specification of general linguisticprinciples (e.g., clitic ordering in French).The article is structured as follows.
Section 2 starts by giving a brief introductionto FB-LTAG, the grammar formalism we used to illustrate most of XMG?s features.
Thenext three sections then go on to discuss and illustrate XMG?s three main features?namely, declarativity, notational expressivity, and flexibility.
In Section 3, we focuson declarativity and show how XMG?s generalized disjunction permits a declarativeencoding of diathesis.
We then contrast the XMG approach with the procedural methodspreviously resorted to for specifying FB-LTAG.
Section 4 addresses notational expressiv-ity.
We present the syntax of XMG and show how the sophisticated identifier handlingit supports or permits a natural treatment (i) of identifiers in tree based hierarchiesand (ii) of the unification-based syntax/semantics interface often used in FB-LTAG.
InSection 5, we concentrate on extensibility.
We first describe the operational semanticsof XMG and the architecture of the XMG compiler.
We then show how these facilitatethe adaptation of the basic XMG language to (i) different grammar formalisms (IG,MC-TAG, FB-LTAG), (ii) the integration of specific linguistic principles such as cliticordering constraints, and (iii) the specification of an arbitrary number of linguisticdimensions.
In Section 6, we illustrate the usage of XMG by presenting an XMGspecification for the verbal fragment of a large scale FB-LTAG for French augmentedwith a unification-based semantics.
We also briefly describe the various other tree-based grammars implemented using XMG.
Section 7 discusses the limitations of otherapproaches to the formal specification of tree-based grammars, and Section 8 concludeswith pointers for further research.2.
Tree-Adjoining GrammarA Tree-Adjoining Grammar (TAG) consists of a set of auxiliary or initial elementarytrees and of two tree composition operations, namely, substitution and adjunction.Initial trees are trees whose leaves are either substitution nodes (marked with ?)
orterminal symbols (words).
Auxiliary trees are distinguished by a foot node (markedwith ) whose category must be the same as that of the root node.
Substitution inserts atree onto a substitution node of some other tree and adjunction inserts an auxiliary tree593Computational Linguistics Volume 39, Number 3NMarieMaryVVahasVSN?
VvuseenN?NJeanJohn?
?SNMarieMaryVVahasVvuseenNJeanJohnFigure 1Sample derivation of Marie a vu Jean ?Mary has seen John?
in a TAG.into a tree.
Figure 1 shows a toy TAG generating the sentence Marie a vu Jean ?Mary hasseen John?
and sketches its derivation.1Among existing variants of TAG, one commonly used in practice is Lexical-ized FB-LTAG (Vijay-Shanker and Joshi 1988).
A lexicalized TAG is such that eachelementary tree has at least one leaf labeled with a lexical item (word), whereas inan FB-LTAG, tree nodes are additionally decorated with two feature structures (calledtop and bottom).
These feature structures are unified during derivation as follows.
Onsubstitution, the top features of the substitution node are unified with the top features ofthe root node of the tree being substituted in.
On adjunction, the top features of the rootof the auxiliary tree are unified with the top features of the node where adjunction takesplace; and the bottom features of the foot node of the auxiliary tree are unified with thebottom features of the node where adjunction takes place.
At the end of a derivation,the top and bottom feature structures of all nodes in the derived tree are unified.Implementation of Tree-Adjoining Grammars.
Most existing implementations of TAGs fol-low the three-layer architecture adopted for the XTAG grammar (XTAG Research Group2001), a feature-based lexicalized TAG for English.
Thus the grammar consists of (i) aset of so-called tree schemas (i.e., elementary trees having a leaf node labeled with a referring to where to anchor lexical items2), (ii) a morphological lexicon associatingwords with lemmas, and (iii) a syntactic lexicon associating lemmas with tree schemas(these are gathered into families according to syntactic properties, such as the sub-categorization frame for verbs).
Figure 2 shows some of the tree schemas associatedwith transitive verbs in the XTAG grammar.
The tree corresponds (a) to a declarativesentence, (b) to a WH-question on the subject, (c) to a passive clause with a BY-agent,and (d) to a passive clause with a WH-object.
As can be seen, each tree schema containsan anchor node (marked with ).
During parsing this anchor node can be replaced byany word morphologically related to a lemma listed in the syntactic lexicon as anchor-ing the transitive tree family.This concept of tree family allows us to share structural information (tree schemas)between words having common syntactic properties (e.g., sub-categorization frames).There still remains a large redundancy within the grammar because many elementarytree schemas share common subtrees (large coverage TAGs usually consist of hun-dreds, sometimes thousands, of tree schemas).
An important issue when specifying1 The elementary trees displayed in this article conform to Abeille?
(2002), that is, we reject the use of a VPconstituent in French.2 As mentioned earlier, we describe lexicalized TAG, thus every tree schema has to contain at least oneanchor (node labeled ).594Crabbe?
et alXMG: eXtensible MetaGrammar(a) (b)SrNP0 ?
VPV NP1 ?SqNP0 ?
[wh +][]SrNPNAVPV NP1 ?
(c) (d)Sr [][mode 3]NP1 ?
VP[mode 3]?
?passive 1mode 2??V?
?passive 1 +mode 2 ppart??
[]PPPbyNP0 ?SqNP1 ?
[wh +][]Sr [][mode 3]NPNAVP[mode 3]?
?passive 1mode 2??V?
?passive 1 +mode 2 ppart??
[]PPPbyNP0 ?Figure 2Some tree schemas for English transitive verbs.such grammars is thus structure sharing.
Being able to share structural information isnecessary not only for a faster grammar development, but also for an easier grammarmaintenance (modifications to be applied to the tree schemas would be restricted toshared structures).
In the next section, we will see how XMG declarativity can beefficiently used to factorize TAGs.
In addition, Section 4 will show how XMG notationalexpressivity facilitates the specification of another commonly used tree sharing device,namely, inheritance hierarchies of tree fragments.Extending TAG with a Unification-Based Semantics.
To extend FB-LTAG with a compo-sitional semantics, Gardent and Kallmeyer (2003) propose to associate each elementarytree with a flat semantic representation.
For instance, in Figure 3, the trees3 for John, runs,and often are associated with the semantics l0:name(j,john), l1:run(e,s), and l2:often(x),respectively.
Importantly, the arguments of semantic functors are represented by uni-fication variables which occur both in the semantic representation of this functor andon some nodes of the associated syntactic tree.
Thus in Figure 3, the semantic index soccurring in the semantic representation of runs also occurs on the subject substitutionnode of the associated elementary tree.
The value of semantic arguments is then deter-mined by the unifications resulting from adjunction and substitution.
For instance, thesemantic index s in the tree for runs is unified during substitution with the semanticindex j labeling the root node of the tree for John.
As a result, the semantics of John oftenruns is {l0:name(j,john), l1:run(e,j), l2:often(e)}.Gardent and Kallmeyer?s (2003) proposal was applied to various semantic phe-nomena (Kallmeyer and Romero 2004a, 2004b, 2008).
Its implementation, however,3 Cx/Cx abbreviate a node with category C and a top/bottom feature structure including the feature-valuepair { index : x}.595Computational Linguistics Volume 39, Number 3NPjJohnl0:name(j,john)SgNP?s VPgfVferunsl1:run(e,s)VPxoften VP*xl2:often(x)?
l0:name(j,john), l1:run(e,j), l2:often(e)Figure 3A toy lexicalized FTAG with unification-based semantics (l0, l1, l2, e, and j are constants ands, f, g, x are unification variables).relies on having a computational framework that associates syntactic trees with flatsemantic formulae while allowing for shared variables between trees and formulae.
Inthe following sections, we will show how XMG notational expressivity makes it pos-sible to specify an FB-LTAG equipped with a unification-based semantics.3.
DeclarativityIn this section, we show how a phenomenon which is often handled in a proceduralway by existing approaches can be provided with a declarative specification in XMG.Concretely, we show how XMG supports a declarative account of diathesis that avoidsthe drawbacks of lexical rules (e.g., information erasing).
We start by presenting thelexical rule approach.
We then contrast it with the XMG account.3.1 Capturing Diathesis Using Lexical RulesFollowing Flickinger (1987), redundancy among grammatical descriptions is often han-dled using two devices: an inheritance hierarchy and a set of lexical rules.
Whereasthe inheritance hierarchy permits us to encode the sharing of common substructures,lexical rules (sometimes called meta-rules) permit us to capture relationships betweentrees by deriving new trees from already specified ones.
For instance, passive trees willbe derived from active ones.Although Flickinger?s (1987) approach was developed for HPSGs, several similarapproaches have been put forward for FB-LTAG (Vijay-Shanker and Schabes 1992;Becker 1993; Evans, Gazdar, and Weir 1995; XTAG Research Group 2001).
One importantdrawback of these approaches, however, is that they are procedural in that the order inwhich lexical rules apply matters.
For instance, consider again the set of trees givenin Figure 2.
In the meta-rule representation scheme adopted by Becker (1993), the basetree (a) would be specified in the inheritance hierarchy grouping all base trees, andthe derived trees (b, c, d) would be generated by applying one or more meta-rules onthis base tree.
Figure 4 sketches these meta-rules.
The left-hand side of the meta-ruleis a matching pattern replaced with the right-hand side of the meta-rule in the newlygenerated tree.
Symbol ???
denotes a meta-variable whose matching subtree in the inputis substituted in place of the variable in the output tree.
Given these, the tree family inFigure 2 is generated as follows: (b) and (c) are generated by application to the basetree (a) of the Wh-Subject and Passive meta-rules, respectively.
Further, (d) is generatedby applying first, the Wh-Subject meta-rule and second, the Passive meta-rule to thebase tree.596Crabbe?
et alXMG: eXtensible MetaGrammarPassive meta-rule Wh-Subject meta-ruleSr?1 NP?
VPV ?2 NP??
Sr [][mode 3]?2 NP?
VP[mode 3]?
?mode 2passive 1??V?
?passive 1 +mode 2 ppart??
[]PPPby?1 NP?Sr?2NP?
?
?1?
Sq?2NP?
?
[wh +][]SrNP?NA?1Figure 4Simplified meta-rules for passive and wh-subject extraction.More generally a meta-rule is a procedural device that, given a tree instance,generates a new tree instance by adding, suppressing (hence possibly substituting)information in grammatical units.
Prolo (2002) defines a set of meta-rules that canbe used to specify a large FB-LTAG for English.
Given an ordered set of meta-rules,however, there is no guarantee that the trees they derive are linguistically appropriateand that the derivation process terminates.
Thus, to ensure termination and consistency,Prolo needs to additionally provide rule ordering schemes (expressed as automata).3.2 XMG: Capturing Diathesis Using DisjunctionXMG provides an alternative account for describing tree sets such as that of Figure 2without lexical rules and without the related ordering constraints.
In essence, theapproach consists of enumerating trees by combining tree fragments using conjunctionand disjunction.More specifically, the tree set given in Figure 2 can be generated by combiningsome of the tree fragments sketched in Figure 5 using the following conjunctions anddisjunctions:4Subject ?
CanonicalSubject ?
Wh-NP-Subject (1)ActiveTransitiveVerb ?
Subject ?
ActiveVerb ?
CanonicalObject (2)PassiveTransitiveVerb ?
Subject ?
PassiveVerb ?
CanonicalByObject (3)TransitiveVerb ?
ActiveTransitiveVerb ?
PassiveTransitiveVerb (4)The first clause (Subject) groups together two subtrees representing the possi-ble realizations of a subject (canonical and wh).
The next two clauses define a treeset for active and passive transitive verbs, respectively.
The last clause defines theTransitiveVerb family as a disjunction of the two verb forms (passive or active).
In sum,the TransitiveVerb clause defines the tree set sketched in Figure 2 as a disjunction ofconjunctions of tree fragments.One of the issues of meta-rules reported by Prolo (2002) is the handling of featureequations.
For a number of cases (including subject relativization in passive trees),4 For now, let us consider that the tree fragments are combined in order to produce minimal trees bymerging nodes whose categories (and features) unify.
In the next section, we will see how to preciselycontrol node identification using either node variables or node constraints.597Computational Linguistics Volume 39, Number 3Canonical Subject ?
Wh-NP-Subject ?
Canonical Object ?
Wh-NP-Object ?SrNP?
VPSqNP?
[wh +][]SrNPNAVPVPV NP?SqNP?
[wh +][]SrVP NPNACanonical By Object ?
Wh By Object ?
Active Verb ?
Passive Verb ?VPV PPPbyNP?VPPPPbyNP?VSrVPVSr[][mode 3]VP[mode 3]?
?passive 1mode 2??V?
?passive 1 +mode 2 ppart??
[]Figure 5Tree fragments.ad hoc meta-rules are needed, for a unified tree transformation cannot be defined.
Ina declarative approach such as the one here, dealing with feature equations can bedone relatively easily.
Let us imagine that we now want to extend the trees of Figure 2with feature equations for subject?number agreement.
We can for instance do so bydefining the following tree fragment (the dashed line indicates that the VP node can bea descendant, not only a daughter, of the S node):5SubjAgreement ?
SNP?
[num 1][num 1]VP[num 1][num 1]Then we extend the definition of Subject as follows:Subject ?
SubjAgreement ?
( CanonicalSubject ?
Wh-NP-Subject ) (5)If we want to get further with the description of transitive verbs, for instance bytaking into account wh-objects and by-objects, this can be done as follows.
We firstdefine the elementary fragments Wh-NP-Object and Wh-By-Object (see Figure 5), andthen define the following additional combinations:6ActiveTransitiveVerb ?
CanonicalSubject ?
ActiveVerb ?
Wh-Np-Object (6)PassiveTransitiveVerb ?
CanonicalSubject ?
PassiveVerb ?
Wh-By-Object (7)5 Note that in XMG, it is not mandatory to define any tree structure inside SubjAgreement.
We could defineindependent NP and VP nodes, and associate them with variables, say n1 and n2.
n1 and n2 would thenbe exported and reused directly in the classes CanonicalSubject and Wh-NP-Subject, respectively.6 Note that these clauses only consider canonical subjects to avoid having both a Wh-subject and aWh-object.
This is not entirely satisfactory, as we would prefer to define a single abstraction over objects(as was done for subjects) and use it wherever possible.
There would then be another mechanism tocapture this exception and cause the invalid combination to fail (that is, the resulting tree description notto have any model).
Such a mechanism exists in XMG, and is called linguistic principle (see Section 5).598Crabbe?
et alXMG: eXtensible MetaGrammarEvans, Gazdar, and Weir (1995) argue for the necessity of using lexical rules forgrammatical description based on two arguments: (i) morphology is irregular and hasto be handled by a non-monotonic device and (ii) erasing rules such as the agentlesspassive (John eats an apple / An apple is eaten ) are needed to erase an argument fromthe canonical base tree.
Neither of these arguments holds here, however: The firstargument because we describe tree schema hence lexical and morphological issues areruled out; the second because agentless passive and, more generally, argument erasingconstructions can simply be defined by an additional clause such as:AgentlessPassiveTransitiveVerb ?
Subject ?
PassiveVerb (8)To summarize, using a declarative language to specify a tree-based grammar offersan adequate level of control on the structures being described while avoiding havingto deal with ordering and termination issues.
It facilitates grammar design and mainte-nance, by providing an abstract view on grammar trees, uniquely made of monotonic(no information removal) combinations of tree fragments.4.
Notational ExpressivityWe now focus on notational expressivity and show how XMG supports a directencoding of (i) distinct linguistic dimensions (here syntax, semantics and the syntax/semantics interface) and (ii) the various types of coreferences7 that arise in the devel-opment of tree-based grammars.The syntax of the XMG language can be formally defined as follows.Class ::= NameC1,...,Ckx1,...,xn ?
Content (9)Content ::= ?SYN, SEM, DYN?
| Name | Content ?
Content | Content ?
Content(10)SYN ::=n1 ?
n2 | n1 ?+ n2 | n1 ??
n2 | n1 ?
n2 | n1 ?+ n2 | n1 ??
n2 |n1[f1 : v1,..., fk : vk] | n1(c1 : cv1,..., cl : cvl) | n1 = n2 | x = Ci.y |n1 (c1 : cv1,..., cl : cvl) [f1 : v1,..., fk : vk] | SYN ?
SYN(11)SEM ::= li : p(E1,...,En) | li ?
hj | SEM ?
SEM (12)DYN ::= ?
f1 : v1,...,fn : vn ?
(13)Here and in what follows, we use the following notational conventions.
Ci denotevariables over class names; xi, x, and y are variables ranging over tree nodes or featurevalues; ni refer to node variables; f, fi are features and v, vi and feature values (constantsor variables); li, hj, p, and Ei are variables over semantic labels, semantic holes, predi-cates, and predicate arguments in flat semantic formulae, respectively.8 [ ] are used toassociate a node variable with some feature constraint.
( ) are used to associate a nodevariable with some property constraint (e.g., node colors, see Section 5).
ci and cvi denote7 By coreference, we mean the sharing of information between distinct elementary fragments of thegrammar specification.8 See Gardent and Kallmeyer (2003) for a detailed introduction to flat semantics.599Computational Linguistics Volume 39, Number 3a property constraint and a property constraint value, respectively.
Ci.y denotes the yvariable declared in class Ci and = is unification; ?
and ?
denote linear precedence andimmediate dominance relations between nodes.
Finally, +, ?
represent the transitive andtransitive-reflexive closure of a relation, respectively.The first two clauses of the formal definition here specify XMG classes and how theycombine.
The next three clauses define the languages supported for describing three lin-guistic dimensions, namely, syntax (SYN), semantics (SEM), and the syntax/semanticsinterface (called DYN for dynamic interface).
We now discuss each of these in moredetail starting bottom?up with the three linguistic dimensions and ending with thecontrol language that permits us to combine basic linguistic units into bigger ones.SYN.
The XMG formalism for syntax (copied here for convenience) is a tree descriptionlogic similar to that proposed by Vijay-Shanker and Schabes (1992) and Rogers andVijay-Shanker (1994) to describe tree-based grammars.SYN ::= n1 ?
n2 | n1 ?+ n2 | n1 ??
n2 | n1 ?
n2 | n1 ?+ n2 | n1 ??
n2 |n1[f1 : v1,..., fk : vk] | n1(c1 : cv1,..., cl : cvl) | n1 = n2 | x = Ci.y |n1 (c1 : cv1,..., cl : cvl) [f1 : v1,..., fk : vk] | SYN ?
SYNIt includes tree node variables, feature names, feature values, and feature variables.Tree node variables can be related by equality (node identification), precedence (imme-diate or non-immediate), and dominance (immediate or non-immediate).
Tree nodescan also be labeled with feature structures of depth 2, that is, sets of feature/valuepairs where feature values are either variables, constants (e.g., syntactic category), ornon-recursive feature structure (e.g., top and bottom feature structures).Here is a graphical illustration of how tree logic formulae can be used to describetree fragments: The depicted tree fragment is a model satisfying the given formula.n1 ?
n2 ?
n1 ?
n3 ?
n2 ?
n3?
n1[cat : S] ?
n2(mark : subst) [cat : NP] ?
n3[cat : VP]SNP?
VPOne distinguishing feature of the XMG tree language is the introduction of nodeconstraints (n1(c : cv)) that generalize Muskens and Krahmer?s (1998) use of positiveand negative node markings.
Concretely, node constraints are attribute-value matri-ces, which contain information to be used when solving tree descriptions to producegrammar trees.
In other words, node constraints are used to further restrict the setof models satisfying a tree description.
As an example of node constraint, considernode annotations in FB-LTAG (foot node, substitution node, null-adjunction, etc.).
Suchannotations can be used as node constraints to allow the description solver to applywell-formedness constraints (e.g., there is at most one foot node).Another interesting feature of XMG concerns the inclusion of the dot operator,which permits us to identify variables across classes in cases where name sharing cannotbe resorted to.
When a variable y is declared in a class C, the latter being instantiatedwithin a class D, y can be accessed from D by C.y (the identifier y still being availablein D?s namespace).600Crabbe?
et alXMG: eXtensible MetaGrammarSEM.
The semantic dimension supports a direct encoding of the flat semantic formulaeused by Gardent and Kallmeyer (2003):SEM ::= li : p(E1,...,En) | li ?
hj | SEM ?
SEMwhere li : p(E1,..., En) represents a predicate p with label li and arguments E1,..., En andli ?
hj is a scope constraint between label li and scope hj.
Expressions (predicate argu-ments Ei) can refer to semantic holes, constants (atomic values), or unification variables(written x, y hereafter).For instance, the following flat semantic formula can be used to underspecify themeaning of the sentence ?Every dog chases a cat?
:l0 : ?
(x, h1, h2) ?
l1 ?
h1 ?
l1 : Dog(x) ?
l2 ?
h2 ?
l2 : Chase(x, y)?
l3 : ?
(y, h3, h4) ?
l4 ?
h3 ?
l4 : Cat(y) ?
l2 ?
h4(14)This formula denotes the following two first-order logic formulae, thereby describingthe two possibles readings of this sentence.9l0 : ?
(x, l1, l3) ?
l1 : Dog(x) ?
l2 : Chase(x, y) ?
l3 : ?
(y, l4, l2) ?
l4 : Cat(y) (15)l0 : ?
(x, l1, l2) ?
l1 : Dog(x) ?
l2 : Chase(x, y) ?
l3 : ?
(y, l4, l0) ?
l4 : Cat(y) (16)DYN.
The DYN dimension generalizes Kinyon?s hypertag (Kinyon 2000) which isunified whenever two tree fragments are combined.
Similarly, in XMG the DYNdimension is a feature structure that is unified whenever two XMG classes are com-bined through inheritance or through conjunction (see the discussion on XMG controllanguage, subsequently).For instance, the following constraints ensure a coreference between the index Ioccurring in the syntactic dimension and the argument X occurring in the semanticdimension (indexsubject and arg1 are feature names, and E, I, X, and V local unificationvariables).C1 ?
Node [idx : I] ?
?indexsubject : I?
(17)C2 ?
L : P(E) ?
L : Theta1(E, X) ?
?arg1 : X?
(18)SubjectArg1 ?
C1 ?
C2 ?
?indexsubject : V, arg1 : V?
(19)More generally, the DYN dimension permits us to unify nodes and feature valuesthat belong to distinct classes and dimensions, and are thus often not related withinthe inheritance hierarchy.
As we shall see in Section 6, the DYN dimension permitsa modular account of the syntax/semantics interface in which linking constraints canbe stipulated separately and reused to specify the various diatheses.In other words, the DYN feature structure allows us to extend the scope of somespecific variables so that they can be unified with variables (or values) introducedin some other classes of the metagrammar.
This concept of scope extension can becompared with that of hook in Copestake, Lascarides, and Flickinger (2001).9 For more details on the interpretation of flat semantics and on its association with a grammar of naturallanguage, see Gardent (2008).601Computational Linguistics Volume 39, Number 3Control language.
The linguistic units (named Content here) defined by the linguist canbe abstracted and combined as follows:Class ::= NameC1,...,Ckx1,...,xn ?
ContentContent ::= ?SYN, SEM, DYN?
| Name | Content ?
Content | Content ?
ContentThe first clause states that the linguistic information encoded in Content is abstracted ina class named Name and that this class inherits classes C1,..., Ck and exports variablesx1,..., xn.
That is, XMG allows for abstraction, inheritance, and variable exports.
Bydefault, variables (referring to nodes and feature values) are local to a class.
Exportstatements extend the scope of a variable to all sub-classes, however.
An exportedvariable can also be accessed from outside its class in case of class instantiation (usingthe dot operator introduced earlier in this section).
The second clause states that anXMG class consists of a syntactic, a semantic, and a dynamic description (each of thempossibly empty), and that XMG classes can be combined by conjunction and disjunc-tion and reused through class instantiation.
The notation ?SYN, SEM, DYN?
representssimultaneous contributions (possibly empty) to all three dimensions.10The XMG control language differs from other frameworks used to specify tree-based grammars (Vijay-Shanker and Schabes 1992; Xia et al1998; Candito 1999)in two main ways.
First, it supports generalized conjunctions and disjunctions ofclasses.
As shown in Section 3, this permits us, inter alia, a declarative treatment ofdiathesis.Second, it allows for both local and exported variables.
As mentioned in Section 3, acommon way to share structure within a tree-based grammar is to define an inheritancehierarchy of either tree fragments (Evans, Gazdar, and Weir 1995) or tree descriptions(Vijay-Shanker and Schabes 1992; Candito 1996; Xia 2001).
When considering an FB-LTAG augmented with unification semantics, the hierarchy will additionally containsemantic representations and/or tuples made of tree fragments and semantic represen-tations.
In all cases, the question arises of how to handle identifiers across classes and,more specifically, how to share them.In Candito?s (1996) approach, tree nodes are referred to using constants so thatmultiple occurrences of the same node constant refer to the same node.
As pointed outin Gardent and Parmentier (2006), global names have several non-trivial shortcomings.First, they complicate grammar writing in that the grammar writer must remember thenames used and their intended interpretation.
Second, they fail to support multiple usesof the same class within one class.
For instance, in French, some verbs sub-categorizefor two prepositional phrases (PP).
A natural way of deriving the tree for such verbswould be to combine a verbal tree fragment with two instances of a PP fragment.
If,however, the nodes in the PP fragment are labeled with global names, then the twooccurrences of these nodes will be identified thereby blocking the production of theappropriate tree.11A less restrictive treatment of identifiers is proposed by Vijay-Shanker and Schabes(1992), where each tree description can be associated with a set of declared nodevariables and subsets of these node variables can be referred to by descriptions in the10 Although formally precise, this notation can be cumbersome.
In the interest of legibility we adoptthroughout the convention that SYN stands for ?SYN, , ?, SEM for ?
, SEM, ?, and DYN for ?
, , DYN?.11 An analogous situation may arise in English with ditransitive verbs requiring two direct objects.602Crabbe?
et alXMG: eXtensible MetaGrammarhierarchy that inherit from the description in which these node variables were declared.For instance, if entity A in the hierarchy declares such a special node variable X and Binherits from A, then X can be referred to in B using the notation A.X.12XMG generalizes Vijay-Shanker and Schabes?s (1992) approach by integrating anexport mechanism that can be used to extend the scope of a given identifier (nodeor feature value variable) to classes that inherit from the exporting class.
Thus ifclass B inherits from class A and class A exports variable X, then X is visible in Band its reuse forces identity.
If B inherits from several classes and two (or more) ofthese inherited classes export the same variable name X, then X is not directly visiblefrom B.
It can be accessed though using the dot operator.
First A is identified with alocal variable (e.g., T = A), then T.X can be used to refer to the variable X exportedby A.To summarize, XMG allows for local variables to be exported to sub-classes as wellas for prefixed variables?that is, variables that are prefixed (using the dot operator)with a reference to the class in which they are declared.
In this way, the pitfalls in-troduced by global names are avoided while providing enough expressivity to handlevariable coreference (via the definition of variable namespaces).
Section 6 will furtherillustrate the use of the various coreference devices made available by XMG showinghow they concretely facilitate grammar writing.Let us finally illustrate variable handling with XMG in the example of Figure 2.Recall that we define the trees of Figure 2 as the conjunctions and disjunctions of sometree fragments of Figure 5, such as:Subject ?
SubjAgreement ?
( CanonicalSubject ?
Wh-NP-Subject ) (20)CanonicalSubject can be defined as a tree description formula as follows (only variablesn2 and n3 are exported):CanonicalSubjectn2,n3 ?n1 ?
n2 ?
n1[cat : S] ?
n2(mark : subst) [cat : NP]?n1 ?
n3 ?
n3[cat : VP] ?
n2 ?
n3(21)The class Wh-NP-Subject is defined accordingly (i.e., by means of a slightly morecomplex tree description formula using the n2 and n3 variable identifiers to refer tothe nodes involved in subject agreement).
The class SubjAgreement is defined slightlydifferently (we do not impose any tree relation between the node concerned withnumber agreement):SubjAgreementn1,n2 ?n1 [[top : [num : x]] [bot : [num : x]]]?n2 [[top : [num : x]] [bot : [num : x]]](22)12 In fact, the notation used by Vijay-Shanker and Schabes (1992) is attr:X with attr an attribute variableranging over a finite set of attributes, to indicate special node variables that scope outside their class; andattr(A) to refer to such variables from outside the entity in which they were declared.
We use a differentnotation here to enforce consistency with the XMG notation.603Computational Linguistics Volume 39, Number 3We can then explicitly control the way the fragments combine as follows:Subject ?C1 = SubjAgreementn1,n2 ?C2 = ( CanonicalSubjectn2,n3 ?
Wh-NP-Subjectn2,n3 ) ?C1.n1 = C2.n2 ?
C1.n2 = C2.n3(23)In this example, we see how to constrain, via variable export and unification, somegiven syntactic nodes to be labeled with feature structures defined somewhere else inthe metagrammar.
We use XMG?s flexible management of variable scope to deal withnode coreference.
Compared with previous approaches on metagrammars such as thoseof Candito (1996), Xia (2001), having the possibility of handling neither only global noronly local variables, offers a high level of expressivity along with a precise control onthe structures being described.5.
ExtensibilityA third distinguishing feature of XMG is extensibility.
XMG is extensible in that(i) dimensions can be added and (ii) each dimension can be associated with its owninterpreter.
In order to support an arbitrary number of dimensions, XMG relies on adevice permitting the accumulation of an arbitrary number of types of literals, namely,Extensible Definite Clause Grammar (EDCG) (Van Roy 1990).
Once literals are accumu-lated according to their type (i.e., each type of literals is accumulated separately), theycan be fed to dedicated interpreters.
Because each of these sets of literals representsformulas of a description language, these interpreters are solvers whose role is tocompute models satisfying the accumulated formulas.Via this concept of separated dimensions, XMG allows us (i) to describe differentlevels of language (not only syntax, but also semantics and potentially morphology,13etc.
), and (ii) to define linguistic principles (well-formedness constraints to be applied onthe structures being described).
These principles depend either on the dimension (e.g.,scope constraints in flat semantics), the target formalism (e.g.
cooccurrence predicate-arguments in FB-LTAG), or the natural language (e.g., clitic ordering in Romance lan-guages) being described.In what follows, we start by showing how XMG handles dimensions independentlyfrom each other introducing EDCG (Section 5.1).
We then summarize the architectureof the XMG system (Section 5.2).
We finally show how different solvers can be usedto implement various constraints on each of these dimensions (Section 5.3).
In partic-ular, we discuss three kinds of extensions implemented in XMG: extension to severalgrammar formalisms, integration of explicit linguistic generalizations, and inclusion ofcolor-based node marking to facilitate grammar writing.5.1 XMG: Accumulating and Interpreting an Arbitrary Number of DescriptionsAccumulating (tree) descriptions.
First, let us notice that XMG is nothing other than a logiclanguage a` la Prolog (Duchier, Parmentier, and Petitjean 2012).
More precisely, an XMG13 Recently, XMG has been used to describe the morphology of verbs in Ikota, a Bantu language spoken inGabon (Duchier, Parmentier, and Petitjean 2012).604Crabbe?
et alXMG: eXtensible MetaGrammarspecification is a collection of Horn clauses, which contribute a declarative descriptionof what a computational tree grammar is.Logic Program XMG MetagrammarClause ::= Head ?
BodyBody ::= Fact | Head |Body ?
Body |Body ?
BodyQuery ::= HeadClass ::= Name ?
ContentContent ::= Description | Name |Content ?
Content |Content ?
ContentAxiom ::= NameRecall that the descriptions handled by XMG are in fact tuples of the form?SYN, SEM, DYN?.
An XMG class can thus describe, in a non-exclusive way, any of thesethree levels of description.
If one wants to add another level of description (i.e., anotherdimension), one needs to extend the arity of this tuple.
Before discussing this, let us firstsee how such tuples are processed by XMG.As mentioned earlier, XMG?s control language is comparable to Horn clauses.A common way to represent Horn clauses is by using Definite Clause Grammar(DCG) (Pereira and Warren 1980).
Concretely, a DCG is a rewriting system (namely, acontext-free grammar), where the symbols of the rewriting rules are equipped withpairs of unification variables (these are usually called difference list or accumulator)(Blackburn, Bos, and Striegnitz 2006, page 100).
As an illustration, consider the follow-ing toy example.s --> np,vp.
np --> det,n.vp --> v,np.
vp --> v.det --> [the].
det --> [a].n --> [cat].
n --> [mouse].v --> [eats].The string language described by this DCG can be obtained by submitting the querys(X,[]) where X is a unification variable to be bound with lists of facts (these being thesentences belonging to the string language).
As we can easily see, this language containsthe sentences ?a cat eats,?
?the cat eats,?
?a mouse eats,?
?the mouse eats,?
?a cat eats amouse,?
?a mouse eats a cat,?
and so on.Similarly, we can represent XMG classes as DCG clauses.
For instance, the combina-tions of syntactic fragments given in relations (1)?
(4) can be rewritten as DCG clausesas follows:subject --> canonicalSubject.subject --> whNpSubject.activeTransitiveVerb --> subject, activeVerb, canonicalObject.passiveTransitiveVerb --> subject, passiveVerb, canonicalByObject.transitiveVerb --> activeTransitiveVerb.transitiveVerb --> passiveTransitiveVerb.Disjunctions (e.g., the subject specification) translate to multiple clauses with iden-tical heads and conjunctions (e.g., activeTransitiveVerb) to a clause body.In our case, the terminal symbols of the underlying DCG are not just facts, buttuples of descriptions.
In other words, the DCG clause whose head is canonicalSubjectis associated with a tuple of the following form (the dots have to be replaced with605Computational Linguistics Volume 39, Number 3adequate descriptions, these can contain unification variables, whose scope is by defaultlocal to the clause):canonicalSubject --> [desc(syn(...),sem(...),dyn(...))].In order to allow for an extension of XMG to an arbitrary number of dimensions,instead of compiling XMG classes into a DCG whose accumulator stores tuples witha fixed arity, these classes are compiled into an EDCG (Van Roy 1990).
EDCG are DCGwith multiple accumulators.
In XMG, each dimension is thus allocated a dedicatedaccumulator in the underlying EDCG.Note that although the content of the various dimensions is accumulated separately,dimensions may nevertheless share information either via local unification variables(if the XMG class defines several dimensions locally), via exported unification vari-ables (in case of class instantiation or inheritance), or via the shared unification variablessupported by the DYN dimension.At the end of the EDCG execution, we obtain, for each axiom of the metagrammar(i.e., for each class name to be valuated), a list of description formulas per accumulator.These lists are grouped together into a tuple of lists of the following form (N is thenumber of dimensions, and consequently of accumulators):desc(accu1(L1),accu2(L2), ... ,accuN(LN))Each element (i.e., list Li) of such a tuple is a complete description of a given dimension,where shared variables have been unified (via unification with backtracking).Solving (tree) descriptions.
As illustrated earlier, interpreting XMG?s control language interms of an EDCG yields tuples whose arity is the number of dimensions defined bythe linguist, that is, triples of the form ?SYN, SEM, DYN?
if syntax, semantics, and thedynamic interface are described.For each dimension D, XMG includes a constraint solver SD that computes the set ofminimal models MD = SD(dD) satisfying the description (dD) of that dimension.
In otherwords, each dimension is interpreted separately by a specific solver.
For instance, thesyntactic dimension is handled by a tree description solver that produces, for a giventree description, the set of trees satisfying that description, whereas the solver for thesemantic dimension simply outputs the flat semantic representation (list of semanticliterals) built by the EDCG through accumulation.Note that, although solvers are distinct, the models computed in each dimensionmay nonetheless be coupled through shared variables.
In that case, these variables canconstrain the models computed by the respective solvers.
For instance, shared variablescan be used for the syntactic tree description solver to be parametrized by some valuecoming from the semantic input description.
Note that the output of the solving processis a Cartesian product of the sets of minimal models of each solver.
As a consequence,the worst case complexity of metagrammar compilation is that of the various solversassociated with relevant dimensions.In addition to having separate solvers for each dimension, the constraint-solvingapproach used in XMG permits us to modularize a given solver by combining differentprinciples.
Each such principle enforces specific constraints on the models satisfyingthe description of a given dimension.
For instance, for the syntactic dimension of anFB-LTAG, a set of principles is used to enforce that the structures produced by thecompiler are trees, and that these conform to the FB-LTAG formalism (e.g., there is notree having two foot nodes).606Crabbe?
et alXMG: eXtensible MetaGrammar5.2 ArchitectureThe XMG compiler14 consists of the following three modules: A compiler that parses XMG?s concrete syntax and compiles XMG classesinto clauses of an EDCG. A virtual machine (VM), which interprets EDCG.
This VM performsthe accumulation of dimensions along with scope management andidentifiers resolution.
This VM is basically a unification engine equippedwith backtracking, and which is extended to support EDCG.
Although itsarchitecture is inspired by the Warren Abstract Machine (A?
?t-Kaci 1991),it uses structure-sharing to represent and unify prolog terms, and, givena query on a class, processes the conjunctions, disjunctions, inheritance,and export statements related to that class to produce its full definition,namely, a tree description for the SYN dimension, a flat semantic formulafor the SEM dimension, and a feature structure for the DYN dimension. A constraint-solving phase that produces for each dimension the minimalmodels satisfying the input description as unfolded by the precedingtwo steps.As already mentioned, the first part is extensible in that new linguistic dimensionscan be added by specifying additional dedicated accumulators to the underlying EDCG.The second part is a unification engine that interprets EDCG while performing both termunification and polarized unification (i.e., unification of polarized feature structures, asdefined by Perrier [2000], and discussed in Section 5.3.1).
This extended unification isthe reason why XMG does not merely recourse to an existing Prolog engine to processEDCG, but relies on a specific VM instead.The third part is completely modular in that various constraint solvers can beplugged in depending on the requirements set by the dimensions used, and the chosengrammatical framework.
For instance, the SYN dimension is solved in terms of treemodels, and the SEM dimension is solved in terms of underspecified flat semanticformulae (i.e., the input semantics remains untouched modulo the unification of itsshared variables).Importantly, these additional solvers can be ?turned on/off?
(via a primitive of theXMG language) so that, for instance, the same processor can be used to compile anXMG specification for an FB-LTAG using linguistic principles such as those defined inthe next section (i.e., clitic ordering principle) or not.5.3 Three Extensions of XMGWe now show (i) how the modular architecture of the XMG compiler permits usto specify grammars for several tree-based linguistic formalisms; (ii) how it can beextended to enforce language specific constraints on the syntactic trees; and (iii) howadditional formal constraints (namely node marking) can be integrated to simplify nodeidentifications (and consequently grammar writing).14 The XMG compiler is open source software released under the terms of the CeCILL GPL-compliantlicence.
See http://sourcesup.renater.fr/xmg.607Computational Linguistics Volume 39, Number 3EqUpDownLeftRightFigure 6Partition of the nodes of tree models.5.3.1 TAG, MC-TAG, and IG: Producing Trees, Tree Sets, or Tree Descriptions.
XMG in-tegrates a generic tree solver that computes minimal tree models from tree descrip-tion logic formulae built on the language SYN introduced in Section 4.
This solverintegrates the dominance solving technique proposed by Duchier and Niehren (2000)and can be summarized as follows.
A minimal tree model is described in terms ofthe relative positions of its nodes.
For each node n in a minimal tree model T, theset of all the nodes of T can be partitioned in five subsets, depending on their po-sition relative to n. Hence, for each node variable n appearing in a tree description,it is first associated with an integer (called node id).
We then define the five setsof node ids (i.e., sets of integers) Downn, Upn, Leftn, Rightn, and Eqn referring to theids of the nodes located below, above, on the left, on the right, or identified with n,respectively (see Figure 6).
Note that we require that these sets are a partition of allnode ids.Using this set-based representation of a model, we translate each node relationfrom the input formula (built on the tree description language introduced in Section 4)into constraints on the sets of node ids that must hold in a valid model.
For instance,the sub-formula n1 ?+ n2, which states that node n1 strictly precedes node n2, istranslated into:n1 ?+ n2 ?
EqDownn1 ?
Leftn2 ?
EqDownn2 ?
Rightn1?Rightn2 ?
Rightn1 ?
Leftn1 ?
Leftn2(24)where15 EqDownx = Eqx unionmulti Downx for x ?
{n1, n2}.
In other words, in a valid minimaltree model, the set of nodes below or equal to n1 is included in the set of nodes (strictly)on the left of n2, the set of nodes below or equal to n2 is included in the set of nodes(strictly) on the right of n1, the set of nodes on the right of n2 is included in the set ofnodes on the right of n1, and finally the set of nodes on the left of n1 is included in theset of nodes on the left of n2.Once all input relations are translated into set constraints, the solver uses standardConstraint Satisfaction techniques (e.g., a first-fail exploration of the search tree) to find aset of consistent partitions.
Finally, the nodes of the models are obtained by consideringnodes with distinct Eqn.15 unionmulti represents disjoint union.608Crabbe?
et alXMG: eXtensible MetaGrammarFB-LTAG trees.
To support the specification of FB-LTAG trees, the XMG compiler extendsthe generic tree solver described here with a set of constraints ensuring that the trees arewell-formed TAG trees.
In effect, these constraints require the trees to be linear orderedtrees with appropriate decorations.
Each node must be labeled with a syntactic category.Leaf nodes are either terminal, foot, or substitution nodes.
There is at most one footnode per tree and the category of the foot node must be identical to that of the rootnode.
Finally, each tree must have at least one leaf node that is an anchor.MCTAG tree sets.
Where FB-LTAG consists of trees, MC-TAG (Weir 1988) consists of setsof trees.
To support the specification of MC-TAG, the sole extension needed concernsnode variables that are not dominated by any other node variable in the tree description.Whereas for FB-LTAG, these are taken to denote either the same root node or nodes thatare connected to some other node (i.e., uniqueness of the root), for MC-TAG they canbe treated as distinct nodes, thereby allowing for models that are sets of trees ratherthan trees (Parmentier et al2007).
In other words, the only modification brought to thetree description solver is that, in MC-TAG mode, it does not enforce the uniqueness ofa root node in a model.IG polarized tree descriptions.
IG (Perrier 2000) consist of tree descriptions whose nodevariables are labeled with polarized feature structures.
A polarized feature structure isa set of polarized feature triples (f, p, v) where f and v are standard features and featurevalues, respectively, and p is a polarity value in {?,?,=,?}.
Polarities are used toguide parsing in that a valid derivation structure must neutralize polarities.To support an XMG encoding of IG, two extensions are introduced, namely, (i) theability to output tree descriptions rather than trees, and (ii) the ability to write polarizedfeature structures.
The first extension is trivially realized by specifying a descriptionsolver that ensures that any output description has at least one tree model.
For thesecond point, the SYN language is extended to define polarized feature structures andthe unification engine to support unification of polarized features (for instance, a ?feature will unify with a neutral (=) feature to yield a ?
polarized feature value triple).5.3.2 Adding Specific Linguistic Constraints: The Case of Clitics.
XMG can be extendedto support specific constraints on tree descriptions (e.g., constraints on node linearorder), which make it possible to describe linguistic-dependent phenomena, such as,for instance, clitic ordering in French, at a meta-level (i.e., within the metagrammar).According to Perlmutter (1970), clitics are subject to two hard constraints.
First,they appear in front of the verb in a fixed order according to their rank (Exam-ples 25a and 25b).16 Second, two different clitics in front of the verb cannot have thesame rank (Example 25c).
(25) a. Jean le3 lui4 donne.
?John gives it to him.?b.
*Jean lui4 le3 donne.
*?John gives to him it.?c.
*Jean le3 la3 donne.
*?John gives it it.
?16 In (Examples 25a?c), the numbers on the clitics indicate their rank.609Computational Linguistics Volume 39, Number 3SN?
?+ V?
?V?Cl?3 ?+ V?V?Cl?4 ?+ V?SV?V?SN?
V?Cl?3 Cl?4 VSN?
V?Cl?4 Cl?3 VFigure 7Clitic ordering in French.To support a direct encoding of Perlmutter?s observation, XMG includes both anode uniqueness principle and a node ordering principle.
The latter allows us to labelnodes with some property (let us call it rank) whose value is an integer (for instance,one can define a node as n1(rank : 2)[cat : Cl]).
When solving tree descriptions, XMGfurther requires that in a valid tree model, (i) there are no two nodes with the samerank and (ii) sibling nodes labeled with a rank are linearly ordered according to theirrank.Accordingly, in the French grammar of Crabbe?
(2005), each node labeled with a cliticcategory is also labeled with a numerical node property representing its rank.17 XMGordering principle then ensures that the ill-formed tree crossed out in Figure 7 is notproduced.
Note that in Figure 7, every type of clitic is defined locally (i.e., in a separateclass), and that the interactions between these local definitions are handled by XMGusing this rank principle, to produce only one valid description (pictured to the right ofthe arrow).That is, XMG ordering constraints permit a simple, declarative encoding of theinteraction between clitics.
This again contrasts with systems based on lexical rules.
Asnoted by Perlmutter (1970), if clitics are assumed to be moved by transformations, thenthe order in which lexical rules apply this movement must be specified.To implement the uniqueness principle, one needs to express the fact that in a validmodel ?, there is only one node having a given property p (i.e., a parameter of theconstraint, here the value of the rank node property).
This can be done by introducing,for each node n of the description, a Boolean variable pn indicating whether the nodedenoting n in the model has this property or not (i.e., are there two nodes of identicalrank?).
Then, if we call V?p the set of integers referring to nodes having the property p ina model, we have: pn ?
(Eqn ?
V?p ) = ?.
Finally, if we represent pn being true with 1 andpn being false with 0,18 and we sum pn for each n in the model, we have that in a validmodel this sum is strictly lower than 2:?n??
pn < 2.To implement the ordering principle, one needs to express the fact that in a validmodel ?, two sibling nodes n1 and n2 having a given property p of type integer andof values p1 and p2, respectively, are such that the linear precedence between thesenodes conform to the natural order between p1 and p2.
This can be done by firstintroducing, for each pair of nodes n, m of the description, a Boolean variable bn,mindicating whether they have the same ancestors: bn,m ?
(Upn ?
Upm) = (Upn ?
Upm).For each pair of nodes that do so, we check whether they both have the property p,17 Recall that node properties are features whose values are used by the tree description solver in order torestrict the set of valid models.
These properties may not appear in the trees produced from the inputmetagrammar.
For instance, the rank property is not part of the FB-LTAG formalism, and thus does notappear in the FB-LTAG elementary trees produced by XMG.18 These integer representations are usually called reified constraints.610Crabbe?
et alXMG: eXtensible MetaGrammarand if this is the case, we add to the input description a strict precedence constraint onthese nodes according to their respective values of the property p:19bn,m ?
(pn < pm) ?
n ?+ m (26)bn,m ?
(pm < pn) ?
m ?+ n (27)5.3.3 Adding Color Constraints to Facilitate Grammar Writing.
To further ease grammardevelopment, XMG supports a node coloring mechanism that permits nameless nodeidentification (Crabbe?
and Duchier 2004), reminiscent of the polarity-based node iden-tification first proposed by Muskens and Krahmer (1998) and later used by Duchierand Thater (1999) and Perrier (2000).
Such a mechanism offers an alternative to explicitnode identification using equations between node variables.
The idea is to label nodevariables with a color property, whose value (either red, black, or white) can triggernode identifications.This mechanism is another parameter of the tree solver.
When in use, the validtree models must satisfy some color constraints, namely, they must only have red orblack nodes (no remaining white nodes; these have to be identified with some blacknodes).
As shown in the following table, node identification must observe the followingconstraints: A white node must be identified with a black node; a red node cannot beidentified with any other node; and a black node may be identified with one or morewhite nodes.20?B ?R ?W ?
?B ?
?
?B ?
?R ?
?
?
?
?W ?B ?
?W ??
?
?
?
?We now briefly describe how the constraint solver sketched in Section 5.3.1 wasextended to support colors.
As mentioned previously, in valid models all white nodesare identified with a black node (at most one black node per white node).
Consequently,there is a bijection from the red and black nodes of the tree description to the nodes ofthe model.
In order to take this bijection into account, we add a node variable RBn tothe five sets already associated with a node variable n from Section 5.1.
RBn denoteseither n if n is a black or red node, or the black node identified with n if n is a whitenode.
Note that all the node variables must be colored: the set of node variables in atree description can then be partitioned into three sets: Red, Black, and White.
Basically,we know that, for all nodes n, RBn ?
Eqn (this is what the bijection is about).
Againwe translate color information into constraints on node sets (these constraints help thegeneric tree solver by reducing the ambiguity for the Eqn sets):n ?
Red ?
(n = RBn) ?
(Eqn = {n}) (28)n ?
Black ?
(n = RBn) ?
(Eqn\{n} ?
White) (29)n ?
White ?
(RBn ?
Black) ?
(Eqn ?
Black = {RBn}) (30)19 In fact, rather than adding strict precedence constraints to the tree description, we directly add to thesolver their equivalent set constraints on Eq, Up, Left, Right, Down, introduced earlier.20 In other words, node colors can be seen as information on node saturation.611Computational Linguistics Volume 39, Number 3Node coloring offers an alternative to complex namespace management.
The mainadvantage of this particular identification mechanism is its economy: Not only is thereno longer any need to remember node identifiers, there is in fact no need to choose aname for node variables.It is worth stressing that the XMG node identification process is reduced to aconstraint-solving problem and so it is not a sequential process.
Thus the criticismsleveled by Cohen-Sygal and Wintner (2007, 2009) against non-associative constraintson node unification do not apply.Briefly, in their work, Cohen-Sygal and Wintner (2007, 2009) showed that anypolarity-based tree description formalism is not associative.
In other words, whendescribing trees in terms of combinations of polarized structures, the order in whichthe structures are combined matters (i.e., the output structures depend on the combi-nation order).
This feature makes such formalisms not appropriate for a modular andcollaborative grammar engineering, such as that of Cohen-Sygal and Wintner (2011) forUnification Grammar.In the XMG case, when using node colors, the tree description solver does notrely on any specific fragment combination order.
It computes all possible combinationorders.
In this context, the grammar designer cannot think in terms of sequences of nodeidentifications.
This would lead to tree overgeneration.Again, it is important to remember that tree solving computes any valid tree model,independently of any specific sequence of node identifications (all valid node identifica-tions are computed).
In this context, non-associativity of color-based node identificationis not an issue, but rather a feature, as it allows for a compact description of a largenumber of node identifications (and thus of tree structures).6.
Writing Grammars with XMGIn this section, we first provide a detailed example showing how XMG can be used tospecify the verbal trees of a large FB-LTAG for French extended with unification-basedsemantics.
We then give a brief description of several large- and middle-scale grammarsthat were implemented using XMG.6.1 SEMTAG: A large FB-LTAG for French Covering Syntax and SemanticsWe now outline the XMG specification for the verbal trees of SEMTAG, a large FB-LTAGfor French.
This specification further illustrates how the various features of XMG (e.g.,combined use of disjunction and conjunction, node colors) permit us to specify compactand declarative grammar descriptions.
We first discuss the syntactic dimension (SYN).We then go on to show how the semantic dimension (SEM) and the syntax/semanticinterface (DYN) are specified.6.1.1 The Syntactic Dimension.
The methodology used to implement the verbal fragmentof SEMTAG can be summarized as follows.
First, tree fragments are defined that rep-resent either a possible realization of a verb argument or a possible realization of theverb.
The verbal elementary TAG trees of SEMTAG are then defined by appropriatelycombining these tree fragments.To maximize structure sharing, we work with four levels of abstraction.
First, basictree fragments describing verb or verb argument realizations are defined.
Second, gram-matical functions are defined as disjunctions of argument realizations.
Third, verbaldiathesis alternatives are defined as conjunctions of verb realizations and grammatical612Crabbe?
et alXMG: eXtensible MetaGrammarCanonSubj ?S?WN?
?R V?W CanonObj ?S?WV?W N?
?RCanonIndirObj ?S?WV?W PP?RP?Ra`?RN?
?RCanonByObj ?S?WV?W PP?RP?Rpar?RN?
?RRelatSubj ?N?RN?R S?WN?
?R V?W WhObj ?S?RN?
?R S?WV?WWhByObj ?S?RPP?RP?Rpar?RN?
?RS?WWhIndirObj ?S?RPP?RP?Ra`?RN?
?RS?WActiveVerbForm?S?BV?B PassiveVerbForm?S?BV?BV?
?B V?BFigure 8Elementary tree fragments used as building blocks of the grammar (nodes are colored to controltheir identification when blocks are combined).functions.
Fourth, diathesis alternatives are gathered into tree families.
In the nextparagraphs, we explain each of these levels in more detail.Tree fragments.
Tree fragments are the basic building blocks used to define SEMTAG.These are the units that are shared and reused in the definition of many elementarytrees.
For instance, the fragment for a canonical subject will be used by all FB-LTAGelementary trees involving a canonical subject.As mentioned earlier, to specify the verbal elementary trees of SEMTAG, we beginby defining tree fragments which describe the possible syntactic realizations of the verbarguments and of the verb itself.
Figure 8 provides some illustrative examples of thesefragments.
Here and in the following, we omit the feature structures decorating the treesto facilitate reading.21To further factorize information and facilitate grammar maintenance, the basic treefragments are organized in an inheritance hierarchy.22 Figure 9 shows a partial view of21 See Crabbe?
(2005) for a complete description of SEMTAG tree fragments, including feature structures.22 Recall from Section 4 that inheritance is used to share namespaces.
Thus, (node or feature) variablesintroduced in a given class C can be directly reused in the sub-classes of C.613Computational Linguistics Volume 39, Number 3VerbalArgumentCanonSubj CanonComplCanonObj CanPPCanonIndirObj CanonByObjWhWhObj WhPPWhIndirObj WhByObjRelatSubjFigure 9Organization of elementary fragments in an inheritance hierarchy.this hierarchy illustrating how the tree fragments for argument realization depicted inFigure 8 are organized to maximize the sharing of common information.
The hierarchyclassifies the verbal arguments depicted in Figure 8 into four categories:1.
The canonical subject is a noun realized in front of the verb.2.
Canonical complements occur after the verb.
The canonical object is anoun phrase whereas prepositional complements are introduced byspecific prepositions, namely, a` for the canonical indirect object andpar for the canonical by object.3.
Wh-arguments (or questioned arguments) occur in front of a sentenceheaded by a verb.
A Wh-object is an extracted noun whereas questionedprepositional objects are extracted prepositional phrases that areintroduced by a specific preposition.4.
Finally, the relativized subject is a relative pronoun realized in frontof the sentence.
Extracted subjects in French cannot be realized at anunbounded distance from the predicate.Syntactic functions.
The second level of abstraction uses syntactic function names suchas Subject and Object to group together alternative ways in which a given syntacticfunction can be realized.
For instance, if we make the simplifying assumption that thepossible argument realizations are limited to those given in Figure 8, the Subject, Object,ByObject, and IndirectObject classes would be defined as follows.23Subject ?
CanonSubj ?
RelatSubj (31)Object ?
CanonObj ?
WhObj (32)ByObject ?
CanonByObj ?
WhByObj (33)IndirectObject ?
CanonIndirObj ?
WhIndirObj (34)That is, we define the Subject class as an abstraction for talking about the set of treefragments that represent the possible realizations of a subject argument?namely, in23 Note that, when these abstractions will be combined to describe for instance transitive verbs, thecombination of WhObj with WhByObj will be ruled out by using a uniqueness principle such asintroduced in Section 5.614Crabbe?
et alXMG: eXtensible MetaGrammarour restricted example, canonical and relativized subject.
Thus, the simplified Subjectclass defined in Equation (31) characterizes contexts such as the following:(35) a. Jean mange.
(canonical subject)?John eats.?b.
Le garc?on qui mange (relativized subject)?The boy who eats?Similarly, the IndirectObject class abstracts over the realization of an argument intro-duced by the preposition a` to the right of the verb (CanonIndirObj) or realized inextracted position (possibly realized at an unbounded distance from the predicate) asillustrated by the following examples:(36) a. Jean parle a` Marie.
(canonical indirect object)?John talks to Mary.?b.
A` qui Jean parle-t-il ?
(wh indirect object)?To whom is John talking ??c.
A` qui Pierre croit-il que Jean parle ?
(wh indirect object)?To whom Peter thinks that John talks ?
?This way of grouping tree fragments is reminiscent of the informal classification ofFrench syntactic functions presented by Iordanskaja and Mel?c?uk (2009) whereby eachsyntactic function is associated with a set of possible syntactic constructions.Diathesis alternations.
In this third level, we take advantage of the abstractions definedin the previous level to represent diathesis alternations.
Again, we are interested herein describing alternatives.
Diathesis alternations are those alternations of mappingbetween arguments and syntactic functions such as for instance the active/passivealternation.
In a diathesis alternation, the actual form of the verb constrains the waypredicate arguments are realized in syntax.
Thus, in the following example, it is con-sidered that both Examples (37a) and (37b) are alternative realizations of a predicateargument structure such as send(John, a letter).
(37) a. Jean envoie une lettre.
?John sends a letter.?b.
Une lettre est envoye?e par Jean.
?A letter is sent by John.
?The active/passive diathesis alternation captures the fact that if the verb is in theactive form, its two arguments are realized by a subject and an object whereas if theverb is in the passive form, then the arguments consist of a subject and a by-object.TransitiveDiathesis ?
(Subject ?
ActiveVerbForm ?
Object)?
(Subject ?
PassiveVerbForm ?
ByObject)(38)Finally a traditional case of ?erasing,?24 such as the agentless passive (or passivewithout agent) can be expressed in our language by adding an additional alternative24 It is often argued that a language of grammatical representation must be equipped with an ?erasingdevice?
like lexical rules because of phenomena such as the passive without agent.
In this framework itturns out that this kind of device is not needed because we do not grant any special status to base trees.615Computational Linguistics Volume 39, Number 3where the by-object or agentive complement is not expressed.
Thus Equation (39) is anaugmentation of (38) where we have added the agentless passive alternative (indicatedin boldface).TransitiveDiathesis ?
(Subject ?
ActiveVerbForm ?
Object)?
(Subject ?
PassiveVerbForm ?
ByObject)?
(Subject ?
PassiveVerbForm)(39)This methodology can be further augmented to implement an actual linking in themanner of Bresnan and Zaenen (1990).
For the so-called erasing cases, one can map the?erased?
predicative argument to an empty realization in syntax.
We refer the reader toCrabbe?
(2005) for further details.Tree families.
Finally, tree families are defined?that is, sets of trees capturing alternativerealizations of a given verb type (i.e., sub-categorization frame).
Continuing with thesimplified example presented so far, we can for instance define the tree family forverbs taking a nominal subject, a nominal object, and an indirect nominal object (i.e.,ditransitive verbs) as follows:DitransitiveFamily ?
TransitiveDiathesis ?
IndirectObject (40)The trees generated for such a family will, among others, handle the followingcontexts:25(41) a. Jean offre des fleurs a` Marie.
?John offers flowers to Mary.?b.
A` quelle fille Jean offre-t-il des fleurs ?
?To which girl does John offer flowers ??c.
Le garc?on qui offre des fleurs a` Marie.
?The boy who offers flowers to Mary.?d.
Quelles fleurs le garc?on offre-t-il a` Marie ?
?Which flowers does the boy offer to Mary ??e.
Les fleurs sont offertes par Jean a` Marie.
?The flowers are offered by John to Mary.?f.
Par quel garc?on les fleurs sont-elles offertes a` Marie ?
?By which boy are the flowers offered to Mary ?
?It is straightforward to extend the grammar with new families.
Thus, for instance,Equation (42) shows how to define the transitive family (for verbs taking a nominalsubject and a nominal object) and Equation (43), the intransitive one (alternatives of averb sub-categorizing for a nominal subject).TransitiveFamily ?
TransitiveDiathesis (42)IntransitiveFamily ?
Subject ?
ActiveVerbForm (43)25 Note that number and gender agreements are dealt with using coreferences between features labelingsyntactic nodes, see Crabbe?
(2005).616Crabbe?
et alXMG: eXtensible MetaGrammarSimilarly, tree families for non-verbal predicates (adjectives, nouns) can be definedusing the abstraction over grammatical functions defined for verbs.
For instance, the ex-amples in (44a?44b) can be captured using the adjectival trees defined in Equations (46)and (47), respectively, where Subject extends the definition of subject given above with aWh-subject, PredAdj combines a subject tree fragment with a tree fragment describing apredicative adjective, and PredAdjAObj extends a PredAdj tree fragment with a canonicala`-object.
(44) a. Jean est attentif.
Qui est attentif ?
L?homme qui est attentif?John is mindful.
Who is mindful ?
The man who is mindful?b.
Jean est attentif a` Marie.
Qui est attentif a` Marie ?
L?homme qui est attentif a`Marie?John is mindful of Mary.
Who is mindful of Mary ?
The man who is mindfulof Mary?Subject ?
CanonSubj ?
RelatSubj ?
WhSubj (45)PredAdj ?
Subject ?
AdjectivalForm (46)PredAdjAObj ?
PredAdj ?
CanonAObj (47)6.1.2 The Semantic Dimension and the Syntax/Semantic Interface.
We now show how toextend the XMG specification presented in the previous section to integrate aunification-based compositional semantics.
Three main changes need to be carried out:1.
Each elementary tree must be associated with a semantic formula.
This isdone using the SEM dimension.2.
The nodes of elementary trees must be labeled with the appropriatesemantic indices.
This involves introducing the correct attribute-value pairin the correct feature structure (top or bottom) on the appropriate node.3.
Syntax and semantics need to be synchronized?that is, variable sharingbetween semantic formulae and tree indices need to be enforced.
To thisend we use the DYN dimension.Informing the semantic dimension.
To associate each elementary tree with a formula rep-resenting the meaning of the words potentially anchoring that tree, we use the SEMdimension to specify a semantic schema.
For instance, the TransitiveFamily class definedin Equation (42) for verbs taking two nominal arguments is extended as follows:TransitiveFamily ?
TransitiveDiathesis ?
BinaryRel (48)where TransitiveDiathesis is the XMG class defined in Equation (39) to describe the set oftrees associated with transitive verbs and BinaryRel the class describing the followingsemantic schema:L : P(E) ?
L : Theta1(E, X) ?
L : Theta2(E, Y) (49)In this semantic schema, P, Theta1, and Theta2 are unification variables that becomeground when the tree is anchored with a specific word.
For instance, P, Theta1, andTheta2 are instantiated to eat, agent, and patient, respectively, when the anchor is ate (these617Computational Linguistics Volume 39, Number 3pieces of information?predicate, thematic roles?are associated with lemmas, locatedin the syntactic lexicon, and unified with adequate semantic variables via anchoringequations).
Further, X, Y, E, L are unification variables representing semantic arguments.As illustrated in Figure 3, these become ground during (or after) derivation as a sideeffect of the substitutions and adjunctions taking place when trees are combined.
Itis worth noting that by combining semantic schemas with diathesis classes, one suchspecification assigns the specified semantic schema to many trees, namely, all the treesdescribed by the corresponding diathesis class.
In this way, the assignment of semanticformulae to trees is relatively economical.
Indeed in SEMTAG, roughly 6,000 trees areassigned a semantic schema using a total of 75 schema calls.Co-indexing trees and formulae indices.
Assuming that tree nodes are appropriately deco-rated with semantic indices by the specification scheme described in the next paragraph,we now show how to enforce the correct mapping between syntactic and semanticarguments.
This is done in two steps.First, we define a set of interface constraints of the form ?indexF : V, argi : V?
whichare used to enforce the identification of the semantic index (indexF) labeling a given treenode with grammatical function F (e.g., F := subject) with the index (argi) representingthe i-th argument in a semantic schema.
For instance, the following constraints ensurea subject/arg1 mapping, that is, a coreference between the index labeling a subject nodeand the index representing the first argument of a semantic schema:C1 ?
Node [idx : I] ?
?indexsubject : I?C2 ?
L : P(E) ?
L : Theta1(E, X) ?
?arg1 : X?SubjectArg1 ?
C1 ?
C2 ?
?indexsubject : V, arg1 : V?
(50)Given such interface constraints, we refine the diathesis definitions so as to ensure thecorrect bindings.
For instance, the specification in Equation (38) is modified to:TransitiveDiathesis ?
TransitiveActive ?
TransitivePassiveTransitiveActive ?
(SubjectArg1 ?
ObjectArg2?Subject ?
ActiveVerbForm ?
Object)(51)and the passive diathesis is specified as:TransitivePassive ?
(SubjectArg2 ?
ByObjectArg1?Subject ?
PassiveVerbForm ?
ByObject)(52)Labeling tree nodes with semantic indices.
This scheme relies on the assumption that treenodes are appropriately labeled with semantic indices (e.g., the subject node must belabeled with a semantic index) and that these indices are appropriately named (arg1must denote the parameter representing the first argument of a binary relation andindexsubject the value of the index feature on a subject node).
As suggested by Gardent(2007), a complete semantic labeling of a TAG with the semantic features necessary618Crabbe?
et alXMG: eXtensible MetaGrammarto enrich this TAG with the unification-based compositional semantics sketched in theprevious section can be obtained by applying the following labeling principles:26Argument labeling: In trees associated with semantic functors, each argument nodeis labeled with a semantic index27 named after the grammatical function of theargument node (e.g., indexsubject for a subject node).Controller/Controllee: In trees associated with control verbs, the semantic index of thecontroller is identified with the value of the controlled index occurring on thesentential argument node.Anchor projection: The anchor node projects its index up to its maximal projection.Foot projection: A foot node projects its index up to the root.28As we shall now see, XMG permits a fairly direct encoding of these principles.The Argument Labeling principle states that, in the tree associated with a syntacticfunctor (e.g., a verb), each node representing a syntactic argument (e.g., the subjectnode) should be labeled with a semantic index named after the grammatical function ofthat node (e.g., indexsubject).29To specify this labeling, we define for each grammatical function Function ?
{Subject, Object, ByObject, IndirectObject, .
.
.
}, a semantic class FunctionSem which as-sociates with an (exported) node variable called FunctionNode the feature value pair[index : I] and a DYN constraint of the form ?indexFunction : I?.
For instance, the classSubjectSem associates the node SubjectNode with the feature value pair [index : I] andthe DYN constraint ?indexsubject : I?.SubjectSem ?
SubjectNode [index : I] ?
?indexsubject : I?
(53)Additionally, in the tree fragments describing the possible realizations of the grammat-ical functions, the (exported) variable denoting the argument node is systematicallynamed ArgNode.Finally, we modify the specification of the realizations of the grammatical functionsto import the appropriate semantic class and identify ArgNode and FunctionNode.
Forinstance, the Subject specification given above is changed to:Subject ?
SubjectSem ?
ArgNode = SubjectNode ?
(CanonSubj ?
RelatSubj ?
WhSubj)(54)26 The principles required to handle quantification are omitted.
We refer the reader to Gardent (2007) for amore extensive presentation of how semantics is implemented using XMG.27 For simplicity, we only mention indices.
To be complete, however, labels should also be used.28 The foot projection principle only applies to foot nodes that are not argument nodes (i.e., to modifieenodes).29 In other words, this argument labeling principle defines an explicit and normalized reference to anyrealization of a semantic argument.
Following FB-LTAG predicate?argument co-occurrence principle(Abeille?, Candito, and Kinyon 1999), we know that any elementary tree includes a leaf node for eachrealized semantic argument of its anchor.
This principle thus holds in any FB-LTAG.
Its implementation,however, is closely related to the architecture of the metagrammar; here we benefit from the fact thatverbal arguments are described in dedicated classes to reach a high degree of factorization.619Computational Linguistics Volume 39, Number 3E3E2E2E1E2E1E1EE1EE1E?
E?
?
E?
?
E?Depth 3 Depth 2 Depth 1SE2E1VPE1E?VE?ActiveVerbFormFigure 10Anchor/Foot projection.As a result, all ArgNode nodes in the tree descriptions associated with a subject realiza-tion are labeled with an index feature I whose global name is indexsubject.Value sharing between the semantic index of the controller (e.g., the subject ofthe control verb) and that of the controllee (e.g., the empty subject of the infinitivalcomplement) is enforced using linking constraints between the semantic index labelingthe controller node and that labeling the sentential argument node of the control verb.Control verb definitions then import the appropriate (object or subject control) linkingconstraint.The anchor (respectively, foot) projection principle stipulates the projection ofsemantic indices from the anchor (respectively, foot) node up to the maximal projection(respectively, root).
Concretely, this means that the top and bottom features of the nodeslocated on this path between the anchor (respectively, foot) and the maximal projection(respectively, root) all include an index feature whose value is shared between adjacentnodes (see variables Ei in Figure 10).30 Once the top and bottom structures are unified,so are the semantic indices along this path (modulo expected adjunctions realized onthe projection).To implement these principles, we define a set of anchor projection classes{Depth1, Depth2, Depth3} as illustrated in Figure 10.
We then ?glue?
these projectionskeletons onto the relevant syntactic trees by importing the skeletons in the syntactictree description and explicitly identifying the anchor node of the semantic projectionclasses with the anchor or foot node of these syntactic tree descriptions.
Because themodels must be trees, the nodes dominating the anchor node of the projection classwill deterministically be identified with those dominating the anchor or foot node ofthe trees being combined with.
For instance, for verbs, the class specifying the verbalspine (e.g., ActiveVerbForm, see Figure 10) equates the anchor node of the verbal spinewith that of the projection skeleton.
As a result, the verb projects its index up tothe root.6.1.3 Some Figures About SEMTAG.
As mentioned previously, SEMTAG is a large FB-LTAGfor French equipped with semantics (Gardent 2008); it extends the purely syntacticFTAG of Crabbe?
(2005) with a unification based compositional semantics as describedby Gardent and Kallmeyer (2003).31 The syntactic FTAG in essence implements Abeille?
?s(2002) proposal for an FB-LTAG-based modeling of French syntax.
FTAG containsaround 6,000 elementary trees built from 293 XMG classes and covers some 40 basic30 For sake of brevity, we write E2E1 for [bot : [index : E1] top : [index : E2]].
?
?
refers to the anchor / foot.31 FTAG and SEMTAG are freely available under the terms of the GPL-compliant CeCILL license, the formerat https://sourcesup.renater.fr/scm/viewvc.php/trunk/METAGRAMMARS/FrenchTAG/?root=xmg, andthe latter on request.620Crabbe?
et alXMG: eXtensible MetaGrammarverbal sub-categorization frames.
For each of these frames, FTAG defines a set ofargument alternations (active, passive, middle, neuter, reflexivization, impersonal,passive impersonal) and of argument realizations (cliticization, extraction, omission,permutations, etc.)
possible for this frame.
Predicative (adjectival, nominal, andprepositional) and light verb constructions are also covered as well as some commonsub-categorizing noun and adjective constructions.
Basic descriptions are provided forthe remaining constructions namely, adverbs, determiners, and prepositions.FTAG and SEMTAG were both evaluated on the Test Suite for Natural Language Pro-cessing (TSNLP) (Lehmann et al1996), using a lexicon designed specifically on the testsuite, hence reducing lexical ambiguity (Crabbe?
2005; Parmentier 2007).
This test suitefocuses on difficult syntactical phenomena, providing grammatical and ungrammaticalsentences.
These competence grammars accept 76% of the grammatical items, reject 83%of the ungrammatical items, and have an average ambiguity of 1.64 parses per sentence.To give an idea of the compilation time, under architectures made of a 2-Ghz processorwith 1 Gb of RAM, it takes XMG 10 minutes to compile the whole SEMTAG (recall thatthere is no semantic description solving, hence the compilation times between FTAGand SEMTAG do not differ).32Note that SEMTAG can be used for assigning semantic representations to sentenceswhen combined with an FB-LTAG parser and a semantic construction module as de-scribed by Gardent and Parmentier (2005, 2007).33 Conversely, it can be used to verbalizethe meaning denoted by a given semantic representation when coupled with the GenIsurface realizer described by Gardent and Kow (2007).6.2 Other Grammars Designed with XMGXMG has been used mainly to design FB-LTAG and IG for French or English.
Morerecently, it has also been used to design a FB-LTAG for Vietnamese and a TreeTupleMC-TAG for German.
We now briefly describe each of these resources.SemXTAG.
The English grammar, SEMXTAG (Alahverdzhieva 2008), reimplements theFB-LTAG developed for English at the University of Pennsylvania (XTAG ResearchGroup 2001) and extends it with a unification-based semantics.
It contains 1,017 treesand covers the syntactic fragment of XTAG, namely, auxiliaries, copula, raising andsmall clause constructions, topicalization, relative clauses, infinitives, gerunds, pas-sives, adjuncts, ditransitives (and datives), ergatives, it-clefts, wh-clefts, PRO con-structions, noun?noun modification, extraposition, determiner sequences, genitives,negation, noun?verb contractions, sentential adjuncts, imperatives, and resultatives.The grammar was tested on a handbuilt test-suite of 998 sentences illustrating thevarious syntactic constructions meant to be covered by the grammar.
All sentences inthe test suite can be parsed using the grammar.FrenchIG.
The extended XMG framework was used to design a core IG for Frenchconsisting of 2,059 tree descriptions compiled out of 448 classes (Perrier 2007).
Theresulting grammar is lexicalized, and its coverage was evaluated using the previouslymentioned TSNLP.
The French IG accepts 88% of the grammatical sentences and rejects32 As a comparison, about one hour was needed by Candito?s (1999) compiler to produce a French FB-LTAGcontaining about 1,000 tree schemas.33 As an alternative way to parse FB-LTAG grammars equipped with flat semantics such as those producedby XMG, one can use the Tu?bingen Linguistic Parsing Architecture (TuLiPA) (Kallmeyer et al2010).621Computational Linguistics Volume 39, Number 385% of the ungrammatical sentences, although the current version of the French IGdoes not yet cover all the syntactic phenomena presented in the test suite (for example,causative and superlative constructions).Vietnamese TAG.
The XMG language was used by Le Hong, N?Guyen, and Roussanaly(2008) to produce a core FB-LTAG for Vietnamese.
Their work is rather a proof of con-cept than a large-scale implementation.
They focused on Vietnamese?s categorizationframes, and were able to produce a TAG covering the following frames: intransitive(tree family N0V), transitive with a nominal complement (N0VN1), transitive with aclausal complement (N0VS1), transitive with modal complement (N0V0V1), ditransi-tive (N0VN1N2), ditransitive with a preposition (N0VN1ON2), ditransitive with a ver-bal complement (N0V0N1V1), ditransitive with an adjectival complement (N0VN1A),movement verbs with a nominal complement (N0V0V1N1), movement verbs with anadjectival complement (N0V0AV1), and movement ditransitive (N0V0N1V1N2).GerTT.
Another XMG-based grammar corresponds to the German MC-TAG ofKallmeyer et al(2008).
This grammar, called GerTT, is in fact an MC-TAG withTree Tuples (Lichte 2007).
This variant of MCTAG has been designed to model freeword order phenomena.
This is done by imposing node sharing constraints on MCTAGderivations (Kallmeyer 2005).
GerTT covers phenomena such as scrambling, coherentconstructions, relative clauses, embedded questions, copula verbs, complementizedsentences, verbs with various sub-categorization frames, nouns, prepositions, determin-ers, adjectives, and partly includes semantics.
It is made of 103 tree tuples, compiledfrom 109 classes.7.
Related WorkWe now compare XMG with existing environments for designing tree-based grammarsand briefly report on the grammars designed with these systems.7.1 Environments for Designing Tree-Based GrammarsCandito?s Metagrammar Compiler.
The concept of metagrammar was introduced byCandito (1996).
In her paper, Candito presented a compiler for abstract specificationsof FB-LTAG trees (the so-called metagrammars).
Such specifications are based on threedimensions, each of them being encoded in a separate inheritance hierarchy of linguisticdescriptions.
Dimension 1 describes canonical sub-categorization frames (e.g., transitive),the Dimension 2 describes redistributions of syntactic functions (e.g., active to passive),and Dimension 3 the tree descriptions corresponding to the realizations of the syntacticfunctions defined in Dimension 2.
This three-dimensional metagrammatical descriptionis then processed by a compiler to compute FB-LTAG tree schemas.
In essence, thesetree schemas are produced by associating a canonical sub-categorization frame (Dimen-sion 1) with a compatible redistribution schema (Dimension 2), and with exactly onefunction realization (Dimension 3) for each function required by the sub-categorizationframe.Candito?s (1996, 1999) approach improves on previous proposals by Vijay-Shankerand Schabes (1992) and Evans, Gazdar, and Weir (1995) in that it provides a linguisticallyprincipled basis for structuring the inheritance hierarchy.
As shown in Section 6.1,622Crabbe?
et alXMG: eXtensible MetaGrammarthe XMG definition of SEMTAG uses similar principles.
Candito?s approach differs,however, from the XMG account in several important ways: Much of the linguistic knowledge used to determine which classes tocombine is hard-coded in the compiler (unlike in XMG, there is no explicitcontrol on class combinations).
In other words, there is no clear separationbetween the linguistic knowledge needed to specify a high-level FB-LTAGdescription and the algorithm used to compile an actual FB-LTAG fromthis description.
This makes grammar extension and maintenance bylinguists extremely difficult. As in Vijay-Shanker and Schabes (1992) Evans, Gazdar, and Weir (1995),the linguistic description is non-monotonic in that some erasing classesare used to remove information introduced by other dimensions(e.g., agentless passive). The approach fails to provide an easy means to state exceptions.
Theseare usually encoded in the compiling algorithm. The tree description language used to specify classes in Dimension 3relies on global node variables.
Thus, two variables with identical namesintroduced in different classes are expected to refer to the same tree node.As argued in Section 4, this makes it hard to design large-scalemetagrammars.The LexOrg system.
An approach similar to Candito?s was presented by Xia et al(1998), Xia (2001), and Xia, Palmer, and Vijay-Shanker (2005, 2010).
As in Candito?sapproach, a TAG abstract specification relies on a three-dimensional description madeof, namely, sub-categorization frames, blocks, and lexical redistribution rules.
To com-pile this specification into a TAG, the system selects a canonical sub-categorizationframe, and applies some lexical redistribution rules to derive new frames and finallyselect blocks corresponding to the resulting frames.
These blocks contain tree descrip-tions using the logic of Rogers and Vijay-Shanker (1994).LexOrg suffers from similar limitations as Candito?s compiler.
Much of the lin-guistic knowledge is embedded in the compiling algorithm, making it difficult forlinguists to extend the grammar description and to handle exceptions.
Unlike in Can-dito?s framework, the tree description language uses local node variables and lets thetree description solver determine node identifications.
Although this avoids having tomemorize node names, this requires that the descriptions be constrained enough toimpose the required node identifications and prevent the unwanted ones.
In practice,this again complicates grammar writing.
In contrast, XMG provides an intermediatesolution which, by combining local variables with export declarations, avoids having tomemorize too many node variable names (only those local to the relevant sub-hierarchyneed memorizing) while allowing for explicit node identification.The Metagrammar Compiler of Gaiffe, Crabbe?, and Roussanaly.
Gaiffe, Crabbe?, andRoussanaly (2002) proposed a compiler for FB-LTAG that aims to remedy both the lackof a clear separation between linguistic information and compilation algorithm, andthe lack of explicit control on the class combinations prevalent in Candito (1996), Xiaet al(1998), and Xia (2001).
In their approach, the linguistic specification consists ofa single inheritance hierarchy of classes, each class containing a tree description.
The623Computational Linguistics Volume 39, Number 3description logic used is similar to Candito?s.
That is, global node names are used.
Totrigger class combinations, classes are labeled with two types of information: needs andresources.
The compiler selects all final classes of the hierarchy, performs all possiblecombinations, and only keeps those combinations that neutralize the stated needsand resources.
The tree descriptions contained in these neutral combinations are thensolved to produce the expected trees.Although this approach implements a clear separation between linguistic informa-tion and compilation algorithm, the fully automatic derivation of FB-LTAG trees fromthe inheritance hierarchy makes it difficult in practice to control overgeneration.
Incontrast, XMG?s explicit definitions of class combinations by conjunction, disjunction,and inheritance makes it easier to control the tree set that will be generated by thecompiler from the grammar specification.
Additionally, the issues raised by globalvariables remain (no way to instantiate twice a given class, and cumbersome definitionof variables in large metagrammars).The MGCOMP System.
More recently, Villemonte de la Clergerie (2005, 2010) proposed acompiler for FB-LTAG that aims at preserving a high degree of factorization in both theabstract grammar specification and the grammar which is compiled from it.
Thus, theMGCOMP system does not compute FB-LTAG elementary trees, but factorized trees.In MGCOMP, like in Gaiffe, Crabbe?, and Roussanaly?s (2002) approach, a meta-grammar consists of a single hierarchy of classes.
The classes are labeled with needs andresources, and final classes of the hierarchy are combined to compute tree descriptions.The main differences with Gaiffe, Crabbe?, and Roussanaly (2002), lies in the fact that(i) a description can include new factorizing operators, such as repetition (Kleene-staroperator), shuffling (interleaving of nodes), optionality, and disjunctions; and (ii) it offersnamespaces to specify the scope of variables.
MGCOMP?s extended tree descriptionsare not completely solved by the compiler.
Rather, it compiles underspecified trees (alsocalled factorized trees).
With this approach, a large grammar is much smaller in terms ofnumber of grammatical structures than a classical FB-LTAG.
As a result, the grammars itcompiles are only compatible with the DyALog parsing environment (Villemonte de LaClergerie 2005).
And, because the linguist designs factorized trees and not actual TAGtrees, debugging the metagrammar becomes harder.7.2 Resources Built Using Candito, Xia, and De La Clergerie?s SystemsCandito?s system has been used by Candito (1999) herself to design a core FB-LTAGfor French and Italian, and later by Barrier (2006) to design a FB-LTAG for adjectivesin French.
Xia?s system (LexOrg) has been used to semi-automatically generate XTAG(Xia 2001).
De La Clergerie?s system (MGCOMP) has been used to design a grammarfor French named FRMG (FRench MetaGrammar) (Villemonte de la Clergerie 2010).FRMG makes use of MGCOMP?s factorizing operators (e.g., shuffling operator), thusproducing not sensu stricto a FB-LTAG, but a factorized FB-LTAG.
FRMG is freelyavailable, contains 207 factorized trees (having optional branches, etc.)
built from 279metagrammatical classes, and covers 95% of the TSNLP.8.
ConclusionIn this article, we presented the eXtensible MetaGrammar framework and argued that,contrary to other existing grammar writing environments for tree-based grammar,624Crabbe?
et alXMG: eXtensible MetaGrammarXMG is declarative, extensible, and notationally expressive.
We believe that these fea-tures make XMG particularly appropriate for a fast prototyping of the kind of deeptree-based grammars that are used in applications requiring high precision in gram-mar modeling (e.g., language teaching, man/machine dialogue systems, data-to-textgeneration).The XMG language is documented on-line, and its compiler is open source soft-ware, freely available under the terms of the GPL-compliant CeCILL license.34 Manygrammars designed with XMG (FB-LTAG and IG for French and English, TT-MCTAGfor German) are also open-source and available on-line.35Future research will focus on extensibility.
So far, XMG has been used to design tree-based grammars for different languages.
We plan to extend XMG to handle other typesof formalisms36 such as dependency grammars, and to support dimensions other thansyntax and semantics such as for instance, phonology or morphology.
As mentionedhere, XMG offers a modular architecture, making it possible to extend it relatively easily.Nonetheless, in its current state, such extensions imply modifying XMG?s code.
We areexploring new extensions of the formalism, which would allow the linguist to dynam-ically define her/his metagrammar formalism (e.g., which principles or descriptions touse) depending on the target formalism.Another interesting question concerns cross-language grammar engineering.
So far,the metagrammar allows for dealing with structural redundancy.
As pointed out byKinyon et al(2006), a metagrammar can be used to capture generalizations acrosslanguages and is surely worth further investigating.Finally, we plan to extend XMG with features borrowed from Integrated De-velopment Environments (IDE) for programming languages.
Designing a grammaris, in some respect, similar to programming an application.
Grammar environmentsshould benefit from the same tools as those used for the development of applications(incremental compilation, debugger, etc.
).AcknowledgmentsWe are grateful to the three anonymousreviewers for their valuable comments.Any remaining errors are ours.ReferencesAbeille?, A.
2002.
Une grammaire e?lectroniquedu franc?ais.
CNRS Editions.Abeille?, A., M. Candito, and A. Kinyon.
1999.Ftag: current status and parsing scheme.In Proceedings of Vextal ?99, pages 283?292,Venice.A?
?t-Kaci, Hassan.
1991.
Warren?s AbstractMachine: A Tutorial Reconstruction.
MITPress, Cambridge, MA.Alahverdzhieva, Katya.
2008.
XTAG usingXMG.
Masters thesis, Nancy Universite?.Baldridge, Jason, Sudipta Chatterjee,Alexis Palmer, and Ben Wing.
2007.DotCCG and VisCCG: Wiki andprogramming paradigms for improvedgrammar engineering with OpenCCG.In Tracy Holloway King and Emily M.Bender, editors, Proceedings of the GrammarEngineering Across Framework Workshop(GEAF 07).
CSLI, Stanford, CA, pages 5?25.Barrier, Se?bastien.
2006.
Une me?tagrammairepour les noms pre?dicatifs du franc?ais :de?veloppement et expe?rimentations pour lesgrammaires TAG.
Ph.D. thesis, Universite?Paris 7.Becker, Tilman.
1993.
HyTAG: A New Typeof Tree Adjoining Grammars for HybridSyntactic Representation of Free Word OrderLanguage.
Ph.D. thesis, Universita?t desSaarlandes.34 See https://sourcesup.renater.fr/xmg.35 The French TAG and French and English IG are available on XMG?s website, and the German TreeTupleMC-TAG is available at http://www.sfs.uni-tuebingen.de/emmy/res.html.36 Preliminary work on cross-framework grammar engineering has been realized by Cle?ment and Kinyon(2003), who used Gaiffe et als compiler to produce both a TAG and a LFG from a given metagrammar.625Computational Linguistics Volume 39, Number 3Blackburn, Patrick, Johan Bos, and KristinaStriegnitz.
2006.
Learn Prolog Now!,volume 7 of Texts in Computing.
CollegePublications, London.Bresnan, Joan and Annie Zaenen.
1990.
Deepunaccusitivity in LFG.
In K. Dziwirek,P.
Farell, and E. Mejias-Bikandi, editors,Grammatical Relations: A Cross-TheoreticalPerspective.
CSLI publications, Stanford,CA, pages 45?57.Candito, Marie.
1996.
A principle-basedhierarchical representation of LTAGs.In Proceedings of the 16th InternationalConference on Computational Linguistics(COLING?96), pages 194?199, Copenhagen.Candito, Marie.
1999.
Repre?sentation modulaireet parame?trable de grammaires e?lectroniqueslexicalise?es : application au franc?ais et a`l?italien.
Ph.D. thesis, Universite?
Paris 7.Cle?ment, Lionel and Alexandra Kinyon.2003.
Generating parallel multilinguallfg-tag grammars from a metagrammar.In Proceedings of the 41st Annual Meeting ofthe Association for Computational Linguistics,pages 184?191, Sapporo.Cohen-Sygal, Yael and Shuly Wintner.
2007.The Non-Associativity of PolarizedTree-Based Grammars.
In Proceedings of theEighth International Conference on IntelligentText Processing and Computational Linguistics(CICLing-2007), pages 208?217, Mexico City.Cohen-Sygal, Yael and Shuly Wintner.
2009.Associative grammar combination operatorsfor tree-based grammars.
Journal of Logic,Language and Information, 18(3):293?316.Cohen-Sygal, Yael and Shuly Wintner.
2011.Towards modular development of typedunification grammars.
ComputationalLinguistics, 37(1):29?74.Copestake, Ann and Dan Flickinger.
2000.An open-source grammar developmentenvironment and broad-coverage Englishgrammar using HPSG.
In Proceedings of theSecond Conference on Language Resources andEvaluation (LREC-2000), Athens.Copestake, Ann, Alex Lascarides, and DanFlickinger.
2001.
An algebra for semanticconstruction in constraint-basedgrammars.
In Proceedings of 39th AnnualMeeting of the Association for ComputationalLinguistics, pages 140?147, Toulouse.Crabbe?, Benoit.
2005.
Repre?sentationinformatique de grammaires fortementlexicalise?es : Application a` la grammaired?arbres adjoints.
Ph.D. thesis, Universite?Nancy 2.Crabbe?, Beno?
?t and Denys Duchier.
2004.Metagrammar redux.
In Proceedings of theWorkshop on Constraint Solving for LanguageProcessing (CSLP 2004), pages 32?47,Copenhagen.Duchier, Denys, Brunelle Magnana Ekoukou,Yannick Parmentier, Simon Petitjean, andEmmanuel Schang.
2012.
Describingmorphologically-rich languages usingmetagrammars: A look at verbs in Ikota.In Workshop on ?Language Technology forNormalisation of Less-resourced Languages,?8th SALTMIL Workshop on MinorityLanguages and 4th Workshop on AfricanLanguage Technology, InternationalConference on Language Resources andEvaluation, LREC 2012, pages 55?60,Istanbul.Duchier, Denys and Joachim Niehren.
2000.Dominance constraints with set operators.In John W. Lloyd, Vero?nica Dahl, UlrichFurbach, Manfred Kerber, Kung-Kiu Lau,Catuscia Palamidessi, Lu?
?s Moniz Pereira,Yehoshua Sagiv, and Peter J. Stuckey,editors, Proceedings of the First InternationalConference on Computational Logic,volume 1861 of Lecture Notes in ComputerScience.
Springer, Berlin, pages 326?341.Duchier, Denys, Yannick Parmentier, andSimon Petitjean.
2012.
Metagrammars aslogic programs.
In International Conferenceon Logical Aspects of ComputationalLinguistics (LACL 2012).
Proceedings ofthe Demo Session, pages 1?4, Nantes.Duchier, Denys and Stefan Thater.
1999.Parsing with tree descriptions: Aconstraint-based approach.
In Proceedingsof the Sixth International Workshop onNatural Language Understanding and LogicProgramming (NLULP?99), pages 17?32,Las Cruces, NM.Evans, Roger, Gerald Gazdar, and DavidWeir.
1995.
Encoding lexicalized treeadjoining grammars with a nonmonotonicinheritance hierarchy.
In Proceedings of the33rd Annual Meeting of the Association forComputational Linguistics, pages 77?84,Cambridge, MA.Flickinger, Daniel.
1987.
Lexical Rules in theHierarchical Lexicon.
Ph.D. thesis, StanfordUniversity.Gaiffe, Bertrand, Beno?
?t Crabbe?, and AzimRoussanaly.
2002.
A new metagrammarcompiler.
In Proceedings of the SixthInternational Workshop on Tree AdjoiningGrammars and Related Frameworks (TAG+6),pages 101?108, Venice.Gardent, Claire.
2007.
Tree adjoininggrammar, semantic calculi and labellinginvariants.
In Proceedings of the InternationalWorkshop on Computational Semantics(IWCS), Tilburg.626Crabbe?
et alXMG: eXtensible MetaGrammarGardent, Claire.
2008.
Integrating aunification-based semantics in a largescale lexicalised tree adjoininig grammarfor French.
In Proceedings of the 22ndInternational Conference on ComputationalLinguistics (COLING?08), pages 249?256,Manchester.Gardent, Claire and Laura Kallmeyer.
2003.Semantic construction in feature-basedtree adjoining grammar.
In Proceedings ofthe 10th Conference of the European Chapter ofthe Association for Computational Linguistics,pages 123?130, Budapest.Gardent, Claire and Eric Kow.
2007.
Asymbolic approach to near-deterministicsurface realisation using tree adjoininggrammar.
In 45th Annual Meeting of theAssociation for Computational Linguistics,pages 328?335, Prague.Gardent, Claire and Yannick Parmentier.2005.
Large scale semantic construction fortree adjoining grammars.
In Proceedingsof the Fifth International Conferenceon Logical Aspects of ComputationalLinguistics (LACL?05), pages 131?146,Bordeaux.Gardent, Claire and Yannick Parmentier.2006.
Coreference Handling in XMG.In Proceedings of the 21st InternationalConference on Computational Linguistics and44th Annual Meeting of the Association forComputational Linguistics (COLING/ACL2006) Main Conference Poster Sessions,pages 247?254, Sydney.Gardent, Claire and Yannick Parmentier.2007.
SemTAG: A platform for specifyingtree adjoining grammars and performingTAG-based semantic construction.
InProceedings of the 45th Annual Meetingof the Association for ComputationalLinguistics Companion Volume Proceedingsof the Demo and Poster Sessions,pages 13?16, Prague.Iordanskaja, Lidija and Igor Mel?c?uk, 2009.Establishing an inventory of surface?syntactic relations: valence-controlledsurface-dependents of the verb in French.In A. Polgue`re and I.
A. Mel?duk, editors,Dependency in Linguistic Description.John Benjamins, Amsterdam,pages 151?234.Joshi, Aravind K., Leon S. Levy, and MasakoTakahashi.
1975.
Tree adjunct grammars.Journal of Computer and System Sciences,10(1):136?163.Kallmeyer, Laura.
1999.
Tree DescriptionGrammars and UnderspecifiedRepresentations.
Ph.D. thesis,Universita?t Tu?bingen.Kallmeyer, Laura.
2005.
Tree-localmulticomponent tree-adjoining grammarswith shared nodes.
ComputationalLinguistics, 31(2):187?226.Kallmeyer, Laura, Timm Lichte, WolfgangMaier, Yannick Parmentier, and JohannesDellert.
2008.
Developing a TT-MCTAG forGerman with an RCG-based parser.
InProceedings of the Sixth Language Resourcesand Evaluation Conference (LREC),pages 782?789, Marrakech.Kallmeyer, Laura, Wolfgang Maier, YannickParmentier, and Johannes Dellert.
2010.TuLiPA?Parsing extensions of TAG withrange concatenation grammars.
Bulletin ofthe Polish Academy of Sciences: TechnicalSciences, 58(3):377?392.Kallmeyer, Laura and Maribel Romero.2004a.
LTAG semantics for questions.In Proceedings of 7th International Workshopon Tree-Adjoining Grammar and RelatedFormalisms (TAG+7), pages 186?193,Vancouver.Kallmeyer, Laura and Maribel Romero.2004b.
LTAG semantics with semanticunification.
In Proceedings of 7thInternational Workshop on Tree-AdjoiningGrammar and Related Formalisms (TAG+7),page 155?162, Vancouver.Kallmeyer, Laura and Maribel Romero.2008.
Scope and situation binding inLTAG using semantic unification.Research on Language and Computation,6(1):3?52.Kaplan, Ronald and Paula Newman.
1997.Lexical resource reconciliation in the Xeroxlinguistic environment.
In Proceedingsof the ACL Workshop on ComputationalEnvironments for Grammar Developmentand Linguistic Engineering, pages 54?61,Madrid.Kinyon, Alexandra.
2000.
Hypertags.In Proceedings of the 18th InternationalConference on Computational Linguistics(COLING?00), pages 446?452, Saarbru?cken.Kinyon, Alexandra, Owen Rambow, TatjanaScheffler, SinWon Yoon, and Aravind K.Joshi.
2006.
The metagrammar goesmultilingual: A cross-linguistic look atthe v2-phenomenon.
In Proceedings ofthe Eighth International Workshop on TreeAdjoining Grammar and Related Formalisms,pages 17?24, Sydney.Le Hong, Phuong, Thi-Min-HuyenN?Guyen, and Azim Roussanaly.
2008.A metagrammar for Vietnamese.
InProceedings of the 9th International Workshopon Tree-Adjoining Grammar and RelatedFormalisms (TAG+9), Tu?bingen.627Computational Linguistics Volume 39, Number 3Lehmann, Sabine, Stephan Oepen, SylvieRegnier-Prost, Klaus Netter, Veronika Lux,Judith Klein, Kirsten Falkedal, FrederikFouvry, Dominique Estival, Eva Dauphin,Herve?
Compagnion, Judith Baur, LornaBalkan, and Doug Arnold.
1996.
TSNLP?Test suites for natural language processing.In Proceedings of the 16th InternationalConference on Computational Linguistics(COLING?96), pages 711?716, Copenhagen.Lichte, Timm.
2007.
An MCTAG with tuplesfor coherent constructions in German.In Proceedings of the 12th Conference onFormal Grammar (FG 2007), 12 pages,Dublin.Muskens, Reinhard and Emiel Krahmer.1998.
Description theory, LTAGs andUnderspecified Semantics.
In FourthInternational Workshop on Tree AdjoiningGrammars and Related Frameworks,pages 112?115, Philadelphia, PA.Parmentier, Yannick.
2007.
SemTAG: uneplate-forme pour le calcul se?mantique a` partirde Grammaires d?Arbres Adjoints.
Ph.D.thesis, Universite?
Henri Poincare?
- Nancy.Parmentier, Yannick, Laura Kallmeyer, TimmLichte, and Wolfgang Maier.
2007.
XMG:eXtending MetaGrammars to MCTAG.
InProceedings of the Workshop on High-LevelSyntactic Formalisms, 14th Conference onNatural Language Processing (TALN?2007),pages 473?482, Toulouse.Pereira, Fernando and David Warren.
1980.Definite clause grammars for languageanalysis?A survey of the formalismand a comparison to augmentedtransition networks.
ArtificialIntelligence, 13:231?278.Perlmutter, David.
1970.
Surface structureconstraints in syntax.
Linguistic Inquiry,1:187?255.Perrier, Guy.
2000.
Interaction grammars.In Proceedings of the 18th InternationalConference on Computational Linguistics(COLING 2000), pages 600?606,Saarbru?cken.Perrier, Guy.
2007.
A French interactiongrammar.
In Proceedings of the 6thConference on Recent Advances in NaturalLanguage Processing (RANLP 2007),pages 463?467, Borovets.Prolo, Carlos A.
2002.
Generating theXTAG English grammar using metarules.In Proceedings of the 19th InternationalConference on Computational Linguistics(COLING?2002), pages 814?820, Taipei.Rambow, Owen, K. Vijay-Shanker, andDavid Weir.
1995.
D-tree grammars.In Proceedings of the 33th Meeting of theAssociation for Computational Linguistics,pages 151?158, Cambridge, MA.Rogers, James and K. Vijay-Shanker.
1994.Obtaining trees from their descriptions:An application to tree-adjoininggrammars.
Computational Intelligence,10:401?421.Shieber, Stuart M. 1984.
The design of acomputer language for linguisticinformation.
In Proceedings of the TenthInternational Conference on ComputationalLinguistics, pages 362?366, Stanford, CA.Van Roy, Peter.
1990.
Extended DCGnotation: A tool for applicativeprogramming in prolog.
TechnicalReport UCB/CSD 90/583, Universityof California, Berkeley.Vijay-Shanker, K. and Aravind K. Joshi.1988.
Feature structures based treeadjoining grammars.
In Proceedingsof the 12th Conference on ComputationalLinguistics (COLING?88), pages 714?719,Budapest.Vijay-Shanker, K. and Yves Schabes.
1992.Structure sharing in lexicalized treeadjoining grammars.
In Proceedingsof the 14th International Conference onComputational Linguistics (COLING?92),pages 205?212, Nantes.Villemonte de La Clergerie, E?ric.
2005.DyALog: a tabular logic programmingbased environment for NLP.
In Proceedingsof 2nd International Workshop on ConstraintSolving and Language Processing (CSLP?05),pages 18?33, Barcelona.Villemonte de la Clergerie, E?ric.
2010.Building factorized TAGs withmeta-grammars.
In Proceedings ofthe 10th International Workshop onTree-Adjoining Grammar and RelatedFormalisms (TAG+10), pages 111?118,New Haven, CT.Weir, David J.
1988.
Characterizing MildlyContext-Sensitive Grammar Formalisms.Ph.D.
thesis, University of Pennsylvania.Xia, Fei.
2001.
Automatic Grammar Generationfrom Two Different Perspectives.
Ph.D. thesis,University of Pennsylvania.Xia, Fei, Martha Palmer, and K. Vijay-Shanker.
1999.
Toward semi-automatinggrammar development.
In Proceedings ofthe 5th Natural Language Processing PacificRim Symposium (NLPRS-99), pages 96?101,Beijing.Xia, Fei, Martha Palmer, and K. Vijay-Shanker.
2005.
Automatically generatingtree adjoining grammars from abstractspecifications.
Journal of ComputationalIntelligence, 21(3):246?287.628Crabbe?
et alXMG: eXtensible MetaGrammarXia, Fei, Martha Palmer, andK.
Vijay-Shanker.
2010.
Developingtree-adjoining grammars with lexicaldescriptions.
In Srinivas Bangalore andAravind Joshi, editors, Supertagging:Using Complex Lexical Descriptions inNatural Language Processing.
MIT Press,Cambridge, MA, pages 73?110.Xia, Fei, Martha Palmer, K. Vijay-Shanker,and Joseph Rosenzweig.
1998.
Consistentgrammar development using partial-treedescriptions for LTAGs.
In Proceedingsof the 4th International Workshop onTree Adjoining Grammar and RelatedFormalisms (TAG+ 1998), pages 180?183,Philadelphia, PA.XTAG Research Group.
2001.
A lexicalizedtree adjoining grammar for English.Technical Report IRCS-01-03, IRCS,University of Pennsylvania.629
