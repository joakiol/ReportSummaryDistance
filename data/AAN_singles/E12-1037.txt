Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 367?376,Avignon, France, April 23 - 27 2012. c?2012 Association for Computational LinguisticsUser Participation Prediction in Online ForumsZhonghua Qu and Yang LiuThe University of Texas at Dallas{qzh,yangl@hlt.utdallas.edu}AbstractOnline community is an important sourcefor latest news and information.
Accurateprediction of a user?s interest can help pro-vide better user experience.
In this paper,we develop a recommendation system foronline forums.
There are a lot of differ-ences between online forums and formal me-dia.
For example, content generated by usersin online forums contains more noise com-pared to formal documents.
Content topicsin the same forum are more focused thansources like news websites.
Some of thesedifferences present challenges to traditionalword-based user profiling and recommenda-tion systems, but some also provide oppor-tunities for better recommendation perfor-mance.
In our recommendation system, wepropose to (a) use latent topics to interpo-late with content-based recommendation; (b)model latent user groups to utilize informa-tion from other users.
We have collectedthree types of forum data sets.
Our experi-mental results demonstrate that our proposedhybrid approach works well in all three typesof forums.1 IntroductionInternet is an important source of information.
Ithas become a habit of many people to go to the in-ternet for latest news and updates.
However, not allarticles are equally interesting for different users.In order to intelligently predict interesting articlesfor individual users, personalized news recommen-dation systems have been developed.
There are ingeneral two types of approaches upon which rec-ommendation systems are built.
Content based rec-ommendation systems use the textual informationof news articles and user generated content to rankitems.
Collaborative filtering, on the other hand,uses co-occurrence information from a collectionof users for recommendation.During the past few years, online communityhas become a large part of internet.
More often,latest information and knowledge appear at on-line community earlier than other formal media.This makes it a favorable place for people seekingtimely update and latest information.
Online com-munity sites appear in many forms, for example,online forums, blogs, and social networking web-sites.
Here we focus our study on online forums.
Itis very helpful to build an automatic system to sug-gest latest information a user would be interestedin.
However, unlike formal news media, user gen-erated content in forums is usually less organizedand not well formed.
This presents a great chal-lenge to many existing news article recommenda-tion systems.
In addition, what makes online fo-rums different from other media is that users ofonline communities are not only the informationconsumers but also active providers as participants.Therefore in this study we develop a recommen-dation system to account for these characteristicsof forums.
We propose several improvements overprevious work:?
Latent topic interpolation: This is to addressthe issue with the word-based content repre-sentation.
In this paper we used Latent Dirich-let Allocation (LDA), a generative multino-mial mixture model, for topic inference insidethreads.
We build a system based on words367and latent topics, and linearly interpolate theirresults.?
User modeling: We model users?
participa-tion inside threads as latent user groups.
Eachlatent group is a multinomial distribution onusers.
Then LDA is used to infer the groupmixture inside each thread, based on whichthe probability of a user?s participation can bederived.?
Hybrid system: Since content and user-based methods rely on different informationsources, we combine the results from them forfurther improvement.We have evaluated our proposed method usingthree data sets collected from three representativeforums.
Our experimental results show that in allforums, by using latent topics information, systemcan achieve better accuracy in predicting threadsfor recommendation.
In addition, by modeling la-tent user groups in thread participation, further im-provement is achieved in the hybrid system.
Ouranalysis also showed that each forum has its nature,resulting in different optimal parameters in the dif-ferent forums.2 Related WorkRecommendation systems can help make informa-tion retrieving process more intelligent.
Generally,recommendation methods are categorized into twotypes (Adomavicius and Tuzhilin, 2005), content-based filtering and collaborative filtering.Systems using content-based filtering use thecontent information of recommendation items auser is interested in to recommend new items tothe user.
For example, in a news recommendationsystem, in order to recommend appropriate newsarticles to a user, it finds the most prominent fea-tures (e.g., key words, tags, category) in the docu-ment that a user likes, then suggests similar articlesbased on this ?personal profile?.
In Fabs system(Balabanovic and Shoham, 1997), Skyskill & We-bert system (Pazzani et al 1997), documents arerepresented using a set of most important wordsaccording to a weighting measure.
The most popu-lar measure of word ?importance?
is TF-IDF (termfrequency, inverse document frequency) (Saltonand Buckley, 1988), which gives weights to wordsaccording to its ?informativeness?.
Then, base onthis ?personal profile?
a ranking machine is appliedto give a ranked recommendation list.
In Fabs sys-tem, Rocchio?
algorithm (Rocchio, 1971) is usedto learn the average TF-IDF vector of highly rateddocuments.
Skyskill & Webert?s system uses NaiveBayes classifiers to give the probability of docu-ments being liked.
Winnow?s algorithm (Little-stone, 1988), which is similar to perception algo-rithm, has been shown to perform well when thereare many features.
An adaptive framework is intro-duced in (Li et al 2010) using forum commentsfor news recommendation.
In (Wu et al 2010),a topic-specific topic flow model is introduced torank the likelihood of user participating in a threadin online forums.Collaborative-filtering based systems, unlikecontent-based systems, predict the recommendingitems using co-occurrence information betweenusers.
For example, in a news recommendationsystem, in order to recommend an article to userc, the system tries to find users with similar tasteas c. Items favored by similar users would be rec-ommended.
Grundy (Rich, 1979) is known to beone of the first collaborative-filtering based sys-tems.
Collaborative filtering systems can be ei-ther model based or memory based (Breese et al1998).
Memory-based algorithms, such as (Del-gado and Ishii, 1999; Nakamura and Abe, 1998;Shardanand and Maes, 1995), use a utility functionto measure the similarity between users.
Then rec-ommendation of an item is made according to thesum of the utility values of active users that partic-ipate in it.
Model-based algorithms, on the otherhand, try to formulate the probability function ofone item being liked statistically using active userinformation.
(Ungar et al 1998) clustered sim-ilar users into groups for recommendation.
Dif-ferent clustering methods have been experimented,including K-means and Gibbs Sampling.
Otherprobabilistic models have also been used to modelcollaborative relationships, including a Bayesianmodel (Chien and George, 1999), linear regres-sion model (Sarwar et al 2001), Gaussian mix-ture models (Hofmann, 2003; Hofmann, 2004).
In(Blei et al 2001) a collaborative filtering appli-cation is discussed using LDA.
However in thismodel, re-estimation of parameters for the wholesystem is needed when a new item comes in.
In368this paper, we formulate users?
participation differ-ently using the LDA mixture model.Some previous work has also evaluated usinga hybrid model with both content and collabora-tive features and showed outstanding performance.For example, in (Basu et al 1998), hybrid featuresare used to make recommendation using inductivelearning.3 Forum DataWe have collected data from three forums in thisstudy.1 Ubuntu community forum is a technicalsupport forum; World of Warcraft (WoW) forum isabout gaming; Fitness forum is about how to livea healthy life.
These three forums are quite rep-resentative of online forums on the internet.
Us-ing three different types of forums for task eval-uation helps to demonstrate the robustness of ourproposed method.
In addition, it can show how thesame method could have substantial performancedifference on forums of different nature.
Users?behaviors in these three forums are very differ-ent.
Casual forums like ?Wow gaming?
have muchmore posts in each thread.
However its posts arethe shortest in length.
This is because discussionsinside these types of forums are more like casualconversation, and there is not much requirementon the user?s background, and thus there is moreuser participation.
In contrast, technical forumslike ?Ubuntu?
have fewer average posts in eachthread, and have the longest post length.
This isbecause a Question and Answer (QA) forum tendsto be very goal oriented.
If a user finds the threadis unrelated, then there will be no motivation forparticipation.Inside forums, different boards are created tocategorize the topics allowed for discussion.
Fromthe data we find that users tend to participate in afew selected boards of their choices.
To create adata set for user interest prediction in this study,we pick the most popular boards in each forum.Even within the same board, users tend to partici-pate in different threads base on their interest.
Weuse a user?s participation information as an indica-tion whether a thread is interesting to a user or not.Hence, our task is to predict the user participationin forum threads.
Note this approach could intro-1Please contact the authors to obtain the data.duce some bias toward negative instances in termsof user interests.
A users?
absence from a threaddoes not necessarily mean the user is not interestedin that thread; it may be a result of the user beingoffline by that time or the thread is too behind inpages.
As a matter of fact, we found most usersread only the threads on the first page during theirtime of visit of a forum.
This makes participationprediction an even harder task than interest predic-tion.In online forums, threads are ordered by the timestamp of their last participating post.
Provided withthe time stamp for each post, we can calculate theorder of a thread on its board during a user?s par-ticipation.
Figure 1 shows the distribution of postlocation during users?
participation.
We found thatmost of the users read only the posts on the firstpage.
In order to minimize the false negative in-stances from the data set, we did thread locationfiltering.
That is, we want to filter out messagesthat actually interest the user but do not have theuser?s participation because they are not on the firstpage.
For any user, only those threads appearing inthe first 10 entries on a page during a user?s visitare included in the data set.Figure 1: Thread position during users?
participation.In the pre-processing step of the experiment, firstwe use online status filtering discussed above toremove threads that a user does not see while of-fline.
The statistics of the boards we have used ineach forum are shown in Table 1.
The statisticsare consistent with the full forum statistics.
Forexample, users in technical forums tend to postless than casual forums.
We define active users asthose who have participated in 10 or more threads.Column ?Part.
@300?
shows the average number369of threads the top 300 users have participated in.?Filt.
Threads@300?
shows the average number ofthreads after using online filtering with a windowof 10.
Thread participation in ?Ubuntu?
forum isvery sparse for each user, having only 10.01% par-ticipating threads for each user after filtering.
?Fit-ness?
and ?Wow Forum?
have denser participation,at 18.97% and 13.86% respectively.4 Interesting Thread PredictionIn the task of interesting thread prediction, the sys-tem generates a ranked list of threads a user islikely to be interested in based on users?
past his-tory of thread participation.
Here, instead of pre-dicting the true interestedness, we predict the par-ticipation of the user, which is a sufficient condi-tion for interestedness.
This approach is also usedby (Wu et al 2010) for their task evaluation.
Inthis section, we describe our proposed approachesfor thread participation prediction.4.1 Content-based FilteringIn the content-based filtering approach, only con-tent of a thread is used as features for prediction.Recommendation through content-based filteringhas its deep root in information retrieval.
Here weuse a Naive Bayes classifier for ranking the threadsusing information based on the words and the la-tent topic analysis.4.1.1 Naive Bayes ClassificationIn (Pazzani et al 1997) Naive Bayesian classi-fier showed outstanding performance in web pagerecommendation compared to several other clas-sifiers.
A Naive Bayes classifier is a generativemodel in which words inside a document are as-sumed to be conditionally independent.
That is,given the class of a document, words are generatedindependently.
The posterior probability of a testinstance in Naive Bayes classifier takes the follow-ing form:P (Ci|f1..k) =1ZP (Ci)?jP (fj |Ci) (1)where Z is the class label independent normaliza-tion term, f1..k is the bag-of-word feature vectorfor the document.
Naive Bayes classifier is knownfor not having a well calibrated posterior probabil-ity (Bennett, 2000).
(Pavlov et al 2004) showedthat normalization by document length yieldedgood empirical results in approximating a well cal-ibrated posterior probability for Naive Bayes clas-sifier.
The normalized Naive Bayes classifier theyused is as follows:P (Ci|f1..k) =1ZP (Ci)?jP (fj |Ci)1|f | (2)In this equation, the probability of generat-ing each word is normalized by the length ofthe feature vector |f |.
The posterior probabil-ity P (interested|f1..k) from (normalized) NaiveBayes classifier is used for recommendation itemranking.4.1.2 Latent Topics based InterpolationBecause of noisy forum writing and limitedtraining data, the above bag-of-word model used innaive Bayes classifier may suffer from data sparsityissues.
We thus propose to use latent topic model-ing to alleviate this problem.
Latent Dirichlet Allo-cation (LDA) is a generative model based on latenttopics.
The major difference between LDA andprevious methods such as probabilistic Latent Se-mantic Analysis (pLSA) is that LDA can efficientlyinfer topic composition of new documents, regard-less of the training data size (Blei et al 2001).
Thismakes it ideal for efficiently reducing the dimen-sion of incoming documents.In an online forum, words contained in threadstend to be very noisy.
Irregular words, such asabbreviation, misspelling and synonyms, are verycommon in an online environment.
From our ex-periments, we observe that LDA seems to be quiterobust to these phenomena and able to captureword relationship semantically.
To illustrate thewords inside latent topics in the LDA model in-ferred from online forums, we show in Table 2 thetop words in 3 out of 20 latent topics inferred from?Ubuntu?
forum according to its multinomial dis-tribution.
We can see that variations of the samewords are grouped into the same topic.Since each post could be very short and LDA isgenerally known not to work well with short docu-ments, we concatenated the content of posts insideeach thread to form documents.
In order to builda valid evaluation configuration, only posts beforethe first time the testing user participated are usedfor model fitting and inference.370Forum Name Threads Posts Active Users Part.
@300 Filt.
Threads @300Ubuntu 185,747 940,230 1,700 464.72 4641.25Fitness 27,250 529,201 2,808 613.15 3231.04Wow Gaming 34,187 1,639,720 19,173 313.77 2264.46Table 1: Data statistics after filtering.Topic 1 Topic 2 Topic 3lol?d wine emaillol.
Wine mailimo.
game Thunderbird,?
fixme evolution-, stub sendlulz.
not emailslmao.
WINE gmailrofl.
play postfixTable 2: Example of LDA topics that capture wordswith different variations.After model fitting for LDA, the topic distri-butions on new threads can be inferred using themodel.
Compared to the original bag-of-word fea-ture vector, the topic distribution vector is not onlymore robust against noise, but also closer to hu-man interpretation of words.
For example in topic3 in Table 2, people who care about ?Thunder-bird?, an email client, are also very likely to showinterest in ?postfix?, which is a Linux email ser-vice.
These closely related words, however, mightnot be captured using the bag-of-word model sincethat would require the exact words to appear in thetraining set.In order to take advantage of the topic level in-formation while not losing the ?fine-grained?
wordlevel feature, we use the topic distribution as ad-ditional features in combination with the bag-of-word features.
To tune the contribution of topiclevel features in classifiers like Naive Bayes clas-sifiers, we normalize the topic level feature to alength of Lt = ?|f | and bag-of-word feature toLw = (1??
)|f |.
?
is a tuning parameter from 0 to1 that determines the proportion of the topic infor-mation used in the features.
|f | is from the originalbag-of-word feature vector.
The final feature vec-tor for each thread can be represented as:F = Lww1, ..., Lwwk ?
Lt?1, ..., Lt?T (3)where ?1, ..., ?t is the multinomial distribution oftopics for the thread.4.2 Collaborative FilteringCollaborative filtering techniques make predictionusing information from similar users.
It has ad-vantages over content-based filtering in that it cancorrectly predict items that are vastly different incontent but similar in concepts indicated by users?participation.In some previous work, clustering methods wereused to partition users into several groups, Then,predictions were made using information fromusers in the same group.
However, in the caseof thread recommendation, we found that users?interest does not form clean clusters.
Figure 2shows the mutual information between users afterdoing an average-link clustering on their pairwisemutual information.
In a clean clustering, intra-cluster mutual information should be high, whileinter-cluster mutual information is very low.
If so,we would expect that the figure shows clear rect-angles along the diagonal.
Unfortunately, from thisfigure it appears that users far away in the hierarchytree still have a lot of common thread participation.Here, we propose to model user similarity based onlatent user groups.4.2.1 Latent User GroupsIn this paper, we model users?
participation in-side threads as an LDA generative model.
Wemodel each user group as a multinomial distribu-tion.
Users inside each group are assumed to havecommon interests in certain topic(s).
A thread in anonline forum typically contains several such top-ics.
We could model a user?s participation in athread as a mixture of several different user groups.Since one thread typically attracts a subset of usergroups, it is reasonable to add a Dirichlet prior onthe user group mixture.The generative process is the same as the LDAused above for topic modeling, except now users371Figure 2: Mutual information between users in AverageLink Hierarchical clustering.are ?words?
and user groups are ?topics?.
UsingLDA to model user participation can be viewedas soft-clustering of users in a sense that one usercould appear in multiple groups at the same time.The generative process for participating users is asfollows.1.
Choose ?
?
Dir(?)2.
For each of N participating users, un:(a) Choose a group zn ?Multinomial(?
)(b) Choose a user un ?
p(un|zn)One thing worth noting is that in LDA model adocument is assumed to consist of many words.
Inthe case of modeling user participation, a threadtypically has far fewer users than words inside adocument.
This could potentially cause problemduring variable estimation and inference.
How-ever, we show that this approach actually workswell in practice (experimental results in Section 5).4.2.2 Using Latent User Groups forPredictionFor an incoming new thread, first the latentgroup distribution is inferred using collapsed GibbsSampling (Griffiths and Steyvers, 2004).
The pos-terior probability of a user ui participating in threadj given the user group distribution is as follows.P (ui|?j , ?)
=?k?TP (ui|?k)P (k|?j) (4)In the equation, ?k is the multinomial distributionof users in group k, T is the number of latent usergroups, and ?j is the group composition in threadj after inference using the training data.
In gen-eral, the probability of user ui appearing in threadj is proportional to the membership probabilitiesof this user in the groups that compose the partici-pating users.4.3 Hybrid SystemUp to this point we have two separate systems thatcan generate ranked recommendation lists based ondifferent factors of threads.
In order to generate thefinal ranked list, we give each item a score accord-ing to the ranked lists from the two systems.
Thenthe two scores are linearly interpolated using a tun-ing parameter ?
as shown in Equation 5.
The finalranked list is generated accordingly.Ci =(1?
?
)Scorecontent+ ?Scorecollaborative(5)We propose several different rescoring methodsto generate the scores in the above formula for thetwo individual systems.?
Posterior: The posterior probabilities of eachitem from the two systems are used directly asthe score.Scoredir = p(clike|itemi) (6)This way the confidence of ?how likely?
anitem is interesting is preserved.
However,the downside is that the two different sys-tems have different calibration on its posteriorprobability, which could be problematic whendirectly adding them together.?
Linear rescore: To counter the problem asso-ciated with posterior probability calibration,we use linear rescoring based on the rankedlist:Scorelin = 1?posiN(7)In the formula, posi is the position of item iin the ranked list, and N is the total numberof items being ranked.
The resulting score isbetween 0 and 1, 1 being the first item on thelist and 0 being the last.?
Sigmoid rescore: In a ranked list, usuallyitems on the top and bottom of the list have372higher confidence than those in the middle.That is to say more ?emphasis?
should be puton both ends of the list.
Hence we use a sig-moid function on the Scorelinear to capturethis.Scoresig =11 + e?l(Scorelin?0.5)(8)A sigmoid function is relatively flat on bothends while being steep in the middle.
In theequation, l is a tuning parameter that decideshow ?flat?
the score of both ends of the list isgoing to be.
Determining the best value for lis not a trivial problem.
Here we empiricallyassign l = 10.5 Experiment and EvaluationIn this section, we evaluate our approach empiri-cally on the three forum data sets described in Sec-tion 3.
We pick the top 300 most active users fromeach forum for the evaluation.
Among the 300users, 100 of them are randomly selected as the de-velopment set for parameter tuning, while the restis test set.
All the data sets are filtered using an on-line filter as previously described, with a windowsize of 10 threads.Threads are tokenized into words and filtered us-ing a simple English stop word list.
All wordsare then ordered by their occurrences multiplied bytheir inverse document frequencies (IDF).idfw = log|D||{d : w ?
d}|(9)The top 4,000 words from this list are then used toform the vocabulary.We used standard mean average precision(MAP) as the evaluation metric.
This standard in-formation retrieval evaluation metric measures thequality of the returned rank lists from a system.Entries higher in the rank are more accurate thanlower ones.
For an interesting thread recommenda-tion system, it is preferable to provide a short andhigh-quality list of recommendation; therefore, in-stead of reporting full-range MAP, we report MAPon top 10 relevant threads (MAP@10).
The reasonwhy we picked 10 as the number of relevant doc-ument for MAP evaluation is that users might nothave time to read too many posts, even if they arerelevant.During evaluation, a 3-fold cross-validation isperformed for each user in the test set.
In each fold,MAP@10 score is calculated from the ranked listgenerated by the system.
Then the average from allthe folds and all the users is computed as the finalresult.To make a proper evaluation configuration, foreach user, only posts up to the first participation ofthe testing user are used for the test set.5.1 Content-based ResultsHere we evaluate the performance of interestthread prediction using only features from text.First we use the ranking model with latent topicinformation only on the development set to deter-mine an optimal number of topics.
Empirically,we use hyper parameter ?
= 0.1 and ?
= 1/K(K is the number of topics).
We use the perfor-mance of content-based recommendation directlyto determine the optimal topic number K. We var-ied the latent topic number K from 10 to 100, andfound that the best performance was achieved us-ing 30 topics in all three forums.
Hence we useK = 30 for content based recommendation unlessotherwise specified.Next, we show how topic information can helpcontent-based recommendation achieve better re-sults.
We tune the parameter ?
described in Sec-tion 4.1.2 and show corresponding performances.We compare the performance using Naive Bayesclassifier, before and after normalization.
TheMAP@10 results on the test set are shown in Fig-ure 3 for three forums.
When ?
= 0, no latent topicinformation is used, and when ?
= 1, latent topicsare used without any word features.When using Naive Bayes classifier without nor-malization, we find relatively larger performancegain from adding topic information for the ?
val-ues of close to 0.
This phenomenon is probablybecause of the poor posterior probabilities of theNaive Bayes classifier, which are close to either 1or 0.For normalized Naive Bayes classifier, interpo-lating with latent topics based ranking yields per-formance improvement compared to word-basedresults consistently for the three forums.
In?Wow Gaming?
corpus, the optimal performanceis achieved with a relatively high ?
value (at around0.5), and it is even higher for the ?Fitness?
forum.373This means that the system relies more on the la-tent topics information.
This is because in these fo-rums, casual conversation contains more irregularwords, causing more severe data sparsity problemthan others.Between the two naive Bayes classifiers, wecan see that using normalized probabilities out-performs the original one in ?Wow Gaming?
and?Ubuntu?
forums.
This observation is consistentwith previous work (e.g., (Pavlov et al 2004)).However, we found that in ?Fitness Forum?, theperformance degrades with normalization.
Furtherwork is still needed to understand why this is thecase.5.2 Latent User Group ClassificationIn this section, collaborative filtering using latentuser groups is evaluated.
First, participating usersfrom the training set are used to estimate an LDAmodel.
Then, users participating in a thread areused to infer the topic distribution of the thread.Candidate threads are then sorted by the proba-bility of a target user?s participation according toEquation 4.
Note that all the users in the forum areused to estimate the latent user groups, but only thetop 300 active users are used in evaluation.
Here,we vary the number of latent user groups G from5 to 100.
Hyper parameters were set empirically:?
= 1/G, ?
= 0.1.Figure 4 shows the MAP@10 results using dif-ferent numbers of latent groups for the three fo-rums.
We compare the performance using latentgroups with a baseline using SVM ranking.
Inthe baseline system, users?
participation in a threadis used as a binary feature.
LibSVM with radiusbased function (RBF) kernel is used to estimate theprobability of a user?s participation.From the results, we find that ranking using la-tent groups information outperforms the baselinein almost all non-trivial cases.
In the case of?Ubuntu?
forum, the performance gain is less com-pared to other forums.
We believe this is becausein this technical support forum, the average userparticipation in threads is much less, thus makingit hard to infer a reliable group distribution in athread.
In addition, the optimal number of usergroups differs greatly between ?Fitness?
forum and?Wow Gaming?
forum.
We conjecture the reasonbehind this is that in the ?Fitness?
forum, usersXVHUZRUGFigure 5: Position of items with different #users and#words in a ranked list.
(red=0 being higher on theranked list and green being lower)may be interested in a larger variety of topics andthus the user distribution in different topics is notvery obvious.
In contrast, people in the gamingforum are more specific to the topics they are inter-ested in.It is known that LDA tends to perform poorlywhen there are too few words/users.
To have ageneral idea of how much user participation is?enough?
for decent prediction, we show a graph(Figure 5) depicting the relationships among thenumber of users, the number of words, and the po-sition of the positive instances in the ranked lists.In this graph, every dot is a positive thread instancein ?Wow Gaming?
forum.
Red color shows thatthe positive thread is indeed getting higher ranksthan others.
We observe that threads with around16 participants can already achieve a decent perfor-mance.5.3 Hybrid System PerformanceIn this section, we evaluate the performance of thehybrid system output.
Parameters used in each fo-rum data set are the optimal parameters found inthe previous sections.
Here we show the effect ofthe tuning parameter ?
(described in Section 4.3).Also, we compare three different scoring schemesused to generate the final ranked list.
Performanceof the hybrid system is shown in Table 3.We can see that the combination of the two sys-tems always outperforms any one model alone.3740.360.390.420.450.480.510.540  0.2  0.4  0.6  0.8  1MAP10GammaUbuntu ForumNaive BayesNormalized NB0.20.220.240.260.280.30  0.2  0.4  0.6  0.8  1MAP10GammaWow GamingNaive BayesNormalized NB0.10.20.30.40.50.60.70.80.910  0.2  0.4  0.6  0.8  1MAP10GammaFitness ForumNaive BayesNormalized NBFigure 3: Content-based filtering results: MAP@10 vs. ?
(contribution of topic-based features).0.140.160.180.20.221  10  100MAP10Number of GroupsUbuntu ForumLatent GroupSVM0.150.20.250.30.351  10  100MAP10Number of GroupsWow GamingLatent GroupSVM0.20.30.40.50.61  10  100MAP10Number of GroupsFitness ForumLatent GroupSVMFigure 4: Collaborative filtering results: MAP@10 vs. user group number.ForumContribution Factor ?0.0 1.0 OptimalUbuntu 0.523 0.198 0.534 (?
= 0.9)Wow 0.278 0.283 0.304 (?
= 0.1)Fitness 0.545 0.457 0.551 (?
= 0.85)Table 3: Performance of the hybrid system with differ-ent ?
values.This is intuitive since the two models use differ-ent information sources.
A MAP@10 score of 0.5means that around half of the suggested results dohave user participation.
We think this is a good re-sult considering that this is not a trivial task.We also notice that based on the nature of differ-ent forums, the optimal ?
value could be substan-tially different.
For example, in ?Wow gaming?forum where people participate in more threads, ahigher ?
value is observed which favors collabo-rative filtering score.
In contrast, in ?Ubuntu?
fo-rum, where people participate in far fewer threads,the content-based system is more reliable in threadprediction, hence a lower ?
is used.
This observa-tion also shows that the hybrid system is more ro-bust against differences among forums comparedwith single model systems.6 ConclusionIn this paper, we proposed a new system that canintelligently recommend threads from online com-munity according to a user?s interest.
The systemuses both content-based filtering and collaborative-filtering techniques.
In content-based filtering, wesolve the problem of data sparsity in online con-tent by smoothing using latent topic information.In collaborative filtering, we model users?
partici-pation in threads with latent groups under an LDAframework.
The two systems compliment eachother and their combination achieves better per-formance than individual ones.
Our experimentsacross different forums demonstrate the robustnessof our methods and the difference among forums.In the future work, we plan to explore how socialinformation could help further refine a user?s inter-est.ReferencesGediminas Adomavicius and Alexander Tuzhilin.2005.
Toward the next generation of recommendersystems: A survey of the state-of-the-art and possi-ble extensions.
IEEE TRANSACTIONS ON KNOWL-EDGE AND DATA ENGINEERING, 17(6):734?749.Marko Balabanovic and Yoav Shoham.
1997.375Fab: Content-based, collaborative recommendation.Communications of the ACM, 40:66?72.Chumki Basu, Haym Hirsh, and William Cohen.
1998.Recommendation as classification: Using social andcontent-based information in recommendation.
In InProceedings of the Fifteenth National Conference onArtificial Intelligence, pages 714?720.
AAAI Press.Paul N. Bennett.
2000.
Assessing the calibration ofnaive bayes?
posterior estimates.David Blei, Andrew Y. Ng, and Michael I. Jordan.2001.
Latent dirichlet alcation.
Journal of Ma-chine Learning Research, 3:2003.John S. Breese, David Heckerman, and Carl Kadie.1998.
Empirical analysis of predictive algorithms forcollaborative filtering.
pages 43?52.
Morgan Kauf-mann.Y H Chien and E I George, 1999.
A bayesian model forcollaborative filtering.
Number 1.Joaquin Delgado and Naohiro Ishii.
1999.
Memory-based weighted-majority prediction for recom-mender systems.Thomas L. Griffiths and Mark Steyvers.
2004.
Find-ing scientific topics.
Proceedings of the NationalAcademy of Sciences of the United States of Amer-ica, 101(Suppl 1):5228?5235, April.Thomas Hofmann.
2003.
Collaborative filtering viagaussian probabilistic latent semantic analysis.
InProceedings of the 26th annual international ACMSIGIR conference on Research and development ininformaion retrieval, SIGIR ?03, pages 259?266,New York, NY, USA.
ACM.Thomas Hofmann.
2004.
Latent semantic modelsfor collaborative filtering.
ACM Trans.
Inf.
Syst.,22(1):89?115.Qing Li, Jia Wang, Yuanzhu Peter Chen, and ZhangxiLin.
2010.
User comments for news recom-mendation in forum-based social media.
Inf.
Sci.,180:4929?4939, December.Nick Littlestone.
1988.
Learning quickly when irrele-vant attributes abound: A new linear-threshold algo-rithm.
In Machine Learning, pages 285?318.Atsuyoshi Nakamura and Naoki Abe.
1998.
Collab-orative filtering using weighted majority predictionalgorithms.
In Proceedings of the Fifteenth Interna-tional Conference on Machine Learning, ICML ?98,pages 395?403, San Francisco, CA, USA.
MorganKaufmann Publishers Inc.Dmitry Pavlov, Ramnath Balasubramanyan, ByronDom, Shyam Kapur, and Jignashu Parikh.
2004.Document preprocessing for naive bayes classifica-tion and clustering with mixture of multinomials.
InProceedings of the tenth ACM SIGKDD internationalconference on Knowledge discovery and data min-ing, KDD ?04, pages 829?834, New York, NY, USA.ACM.Michael Pazzani, Daniel Billsus, S. Michalski, andJanusz Wnek.
1997.
Learning and revising user pro-files: The identification of interesting web sites.
InMachine Learning, pages 313?331.Elaine Rich.
1979.
User modeling via stereotypes.Cognitive Science, 3(4):329?354.J.
Rocchio, 1971.
Relevance Feedback in InformationRetrieval.Gerard Salton and Christopher Buckley.
1988.
Term-weighting approaches in automatic text retrieval.In INFORMATION PROCESSING AND MANAGE-MENT, pages 513?523.Badrul Sarwar, George Karypis, Joseph Konstan, andJohn Reidl.
2001.
Item-based collaborative fil-tering recommendation algorithms.
In WWW ?01:Proceedings of the 10th international conference onWorld Wide Web, pages 285?295, New York, NY,USA.
ACM.Upendra Shardanand and Pattie Maes.
1995.
So-cial information filtering: Algorithms for automating?word of mouth?.
In CHI, pages 210?217.Lyle Ungar, Dean Foster, Ellen Andre, Star Wars,Fred Star Wars, Dean Star Wars, and Jason HiverWhispers.
1998.
Clustering methods for collabo-rative filtering.
AAAI Press.Hao Wu, Jiajun Bu, Chun Chen, Can Wang, Guang Qiu,Lijun Zhang, and Jianfeng Shen.
2010.
Modelingdynamic multi-topic discussions in online forums.
InAAAI.376
