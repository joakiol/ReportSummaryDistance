Proceedings of the MultiLing 2013 Workshop on Multilingual Multi-document Summarization, pages 50?54,Sofia, Bulgaria, August 9 2013. c?2013 Association for Computational LinguisticsThe UWB Summariser at Multiling-2013Josef SteinbergerUniversity of West BohemiaFaculty of Applied SciencesDepartment of Computer Science and Engineering, NTIS CentreUniverzitni 8, 30614 Plzen?, Czech Republicjstein@kiv.zcu.czAbstractThe paper describes our participation inthe Multi-document summarization task ofMultiling-2013.
The community initiativewas born as a pilot task for the Text Analy-sis Conference in 2011.
This year the cor-pus was extended by new three languagesand another five topics, covering in total15 topics in 10 languages.
Our summariseris based on latent semantic analysis and itis in principle language independent.
Itsresults on the Multiling-2011 corpus werepromising.
The generated summaries wereranked first in several languages based onvarious metrics.
The summariser with mi-nor changes was run on the updated 2013corpus.
Although we do not have the man-ual evaluation results yet the ROUGE-2score indicates good results again.
Thesummariser produced best summaries in 6from 10 considered languages accordingto the ROUGE-2 metric.1 IntroductionMulti-document summarization has received in-creasing attention during the last decade.
Thiswas mainly due to the requirement of news mon-itoring to reduce the big bulk of highly redun-dant news data.
More and more interest arisesfor approaches that will be able to be applied ona variety of languages.
The summariser shouldbe of high quality.
However, when applied ina highly multilingual environment, it has to beenough language-independent to guarantee simi-lar performance across languages.Given the lack of multilingual summarisationevaluation resources, the summarisation commu-nity started to discuss the topic at Text Analy-sis Conference (TAC1) 2010.
It resulted in the1http://www.nist.gov/tac/first multilingual shared task organised as part ofTAC 2011 ?
Multiling-2011 (Giannakopoulos etal., 2012).
Each group took an active role in thecreation of their language subcorpus.
Because nofreely available parallel corpus suitable for multi-document summarisation was found, news clus-ters from WikiNews (in English) needed to be firsttranslated to six other languages.
Three modelsummaries for each cluster were then written andboth model and peer summaries were manuallyevaluated.
For Multiling-2013, three new lan-guages were added (Chinese, Romanian and Span-ish) and 5 new topics (news clusters) were addedto the corpus.This article contains the description of oursystem based on latent semantic analysis (LSA)which participated in Multiling-2013.
We firstbriefly discuss the multi-document task in sec-tion 2.
Then we show our summarisation ap-proach based on LSA (Section 3).
The next sec-tion (4) compares the participating systems basedon the ROUGE-2 score.
Manually assigned scoreswere not available at the time of creation of thisreport.
We conclude by a discussion of possi-ble improvements of the method which requirelanguage-specific resources.2 Multi-document summarisation task atMultiling?13MultiLing-2013 is a community effort, a set of re-search tasks and a corresponding workshop whichcovers three summarisation tasks, focused on themultilingual aspect.
It aims to evaluate the appli-cation of (partially or fully) language-independentsummarization algorithms on a variety of lan-guages.The annotation part consisted of four phases.The first phase was to select English WikiNews ar-ticles about the same event and to create the topics.The articles were then manually translated to theother languages.
Model summaries were created50separately for each language by native speakers.In a certain time frame, participating groups rantheir summarisers and the automatic summarieswere then evaluated, both manually (on a 5-to-1scale) and automatically by ROUGE (Lin, 2004)and the AutoSummENG metric (Giannakopoulosand Karkaletsis, 2010).We participated with our summariser in themain multi-document task, which requires to gen-erate a single, fluent, representative summary froma set of 10 documents describing an event se-quence.
The language of the document set (topic)was within a given range of 10 languages (Arabic,Chinese, Czech, English, French, Greek, Hebrew,Hindi, Romanian and Spanish) and all documentsin a set share the same language.
The output sum-mary should be of the same language as its sourcedocuments.
The output summary should be 250words at most.
The corpus was extended to 15 top-ics (Chinese, French and Hindi subcorpora con-tained only 10 topics).3 LSA-based summarisation approachOriginally proposed by Gong and Liu (2002) andlater improved by Steinberger and Jez?ek (2004),this approach first builds a term-by-sentence ma-trix from the source, then applies Singular ValueDecomposition (SVD) and finally uses the result-ing matrices to identify and extract the most salientsentences.
SVD finds the latent (orthogonal) di-mensions, which in simple terms correspond to thedifferent topics discussed in the source.More formally, we first build matrix A whereeach column represents the weighted term-frequency vector of a sentence in a given set ofdocuments.
The weighting scheme we found towork best is using a binary local weight and anentropy-based global weight (for details see Stein-berger and Jez?ek (2009)).After that step Singular Value Decomposition(SVD) is applied to the above matrix as A =USVT , and subsequently matrix F = S ?
VT re-duced to r dimensions2 is derived.Sentence selection starts with measuring thelength of sentence vectors in matrix F computed asthe Euclidean norm.
The length of the vector (thesentence score) can be viewed as a measure for2The degree of importance of each ?latent?
topic is givenby the singular values and the optimal number of latent topics(i.e., dimensions) r can be fine-tuned on training data.
Ourprevious experiments led us to set r to 8% from the numberof sentences for 250-word summaries.importance of that sentence within the top clustertopics.The sentence with the largest score is selected asthe first to go to the summary (its correspondingvector in F is denoted as fbest).
After placing itin the summary, the topic/sentence distribution inmatrix F is changed by subtracting the informationcontained in that sentence:F(it+1) = F(it) ?fbest ?
fTbest|fbest|2 ?
F(it).
(1)The vector lengths of similar sentences are de-creased, thus preventing within summary redun-dancy.
After the subtraction of information inthe selected sentence, the process continues withthe sentence which has the largest score computedon the updated matrix F. The process is itera-tively repeated until the required summary lengthis reached.4 Experiments and resultsAlthough the approach works only with term co-occurrence, and thus it is completely language-independent, pre-processing plays an importantrole and greatly affects the performance.
Whengenerating the summaries for Multiling-2013 eacharticle was split into sentences.
We used theold DUC sentence splitter3, although a differentsentence-splitting character was used for Chinese.It was a simplification because the sentence split-ter should be adapted for each language (e.g.
adifferent list of abbreviations should be used orlanguage specific features should be added).
IfLSA is applied on a large matrix stopwords can befound in the first linear combination which couldbe then filtered out.
However, in our case we applyit on rather small matrices and stopwords couldaffect negatively the topic distribution.
Thus thesafer option is to filter them out.
This brings adependency on a language but, on the other hand,acquiring lists of stop-words for various languagesis not difficult.
Filtering these insignificant termsdoes not also slow down the system.
The stop-words were filtered out for all the languages ofMultiling.
The approach discussed in section 3was then used to select sentences until the re-quired summary length (250 words) has not beenreached.
Sentence order is important for event-based stories.
In the case of the Multiling corpus,3http://duc.nist.gov/duc2004/software/duc2003.breakSent.tar.gz51Language Topics Avg.
Model ID1 ID11 ID2 ID21 ID3 ID4 (rank/total) ID5 ID51 BaselineArabic 15 .137 .132 .132 .118 .105 .052 .167 (1/9) .105 .088 .086Chinese 10 .462 .430 .457 .212 .354 .354 (5/6) .867Czech 15 .195 .155 .166 .123 .151 .179 (1/6) .085English 15 .185 .161 .161 .147 .142 .083 .171 (1/9) .117 .101 .118French 10 .198 .201 .201 .166 .177 .214 (1/6) .130Greek 15 .111 .120 .124 .100 .112 .110 (4/6) .088Hebrew 15 .076 .088 .100 .076 .084 .092 (2/8) .087 .084 .072Hindi 10 .342 .125 .132 .123 .123 .129 (2/6) .114Romanian 15 .543 .147 .139 .120 .138 .166 (1/6) .098Spanish 15 .239 .198 .218 .180 .175 .228 (1/6) .164Avg.
rank 2.7 1.9 5.0 4.3 9 1.9 5.7 7.0 5.9Table 1: ROUGE-2 scores of the average model and paricipating systems.
Our LSA-based system is ID4and we report its rank from the total number of systems which submitted summaries for the particularlanguage.
We included the baseline (the start of a centroid article) and excluded the topline which usesmodel sentences.much attention has to be given to sentence order-ing because some topics contained articles spreadover a long period, even 5 years.
We did notperform any temporal analysis at sentence level.The sentences in the summary were ordered basedon the date of the article they came from.
Sen-tences from the same article followed their orderin the full text.
Even if they were sometimes outof context, when extracted, the adjacent sentencesat least dealt with the same (or temporary close)event.We analysed ROUGE scores which we receivedfrom the organisers.
We discuss here ROUGE-2(bigram) score, a traditionally used metric in sum-marisation evaluation (Table 1).
ROUGE-2 rankedour summariser on the top of the list for 6 from 10languages (Arabic, Czech, English, French, Ro-manian, Spanish).
System ID11 performed bettertwice (Hebrew and Hindi), there were three bet-ter systems in Greek and the baseline won in Chi-nese.
In the following, we will discuss the resultsfor each language separately.For Arabic, our system received the bestROUGE-2 score.
It was significantly better (atconfidence 95%) then 5 other systems, includingbaseline.
It performed on the same level as mod-els.It was our first attempt to run the summariseron Chinese.
We did not use any specific word-splitting tool and we considered each character tobe a context feature for LSA.
The ROUGE resultssay that the summariser was not that successfulcompared to the others.
It was significantly bet-ter than one system and worse than two and thebaseline which received suspiciously high score.We annotated the Czech part of the corpus, andtherefore the result of our system can be consid-ered only as another baseline for this language.It received the largest ROUGE-2 score, however,there was no significant difference among the topfour systems.For English, our system together with the fol-lowing systems ID1 and ID11 were significantlybetter than the rest.
A similar conclusion can bedriven by observing the French results.
In the caseof Greek only baseline performed poorly.
Ourapproach was ranked fourth although there weremarginal differences between the systems.
ForHebrew and Hindi system ID11 performed thebest, followed by our system.
For Romanian, anewly introduced language this year, our systemreceived a high score, however, a larger confidenceinterval did not show much significance.
For an-other newly-introduced language, Spanish, onlysystem ID11 was not significantly worse than oursystem.As a try to compare the systems across lan-guages, an average rank was computed.
(Comput-ing an average of absolute ROUGE-2 scores didnot seem to have sense.)
Our system and systemID11 received the best average rank: 1.9.For several languages (Arabic, French, He-brew), our summaries were better (not signif-icantly) then the average model according toROUGE-2.The AutoSummENG method (Giannakopoulosand Karkaletsis, 2010) gave results similar tothose of ROUGE.
The only difference was in Chi-52nese: ROUGE-2 ranked our system 5th, Auto-SummENG 1st.One question remains: are the ROUGE scorescorrelated with human grades?
Unfortunately, thehuman grades were not available at the time of thesystem reports submission.
However, because wewere managing annotation of the Czech subcorpuswe had access to human grades for that language.The system ranking provided by ROUGE mostlyagree with the human grades, reaching Pearsoncorrelation of .97 for the systems-only scenario.The human grades ranked our system as signifi-cantly better than any other submission in the caseof Czech.5 ConclusionThe evaluation indicates good results of our sum-mariser, mainly for European Latin-script lan-guages (Czech, English, French, Romanian andSpanish).
It could be connected to good-enoughpre-processing (sentence and word splitting).
Thelast two languages were added this year and thegood results show that the LSA-based summarisercan produce good summaries when run on an ?un-seen?
language.We experiment with several improvements ofthe method which require language-specific re-sources.
Entity detection can improve the LSAmodel by adding entity features as new rows inthe SVD input matrix (Steinberger et al 2007).From the Multiling-2013 languages we have de-veloped the NER tool only for 6 languages (Ara-bic, Czech, English, French, Romanian and Span-ish) so far (Pouliquen and Steinberger, 2009).
Acoreference- (anaphora-) resolution can help inchecking and rewriting the entity references in asummary (Steinberger et al 2007) although thereis usually a high dependency on the language (e.g.in the case of pronouns).Event extraction can detect important aspectsrelated to the category of the topic (e.g.
detect-ing victims in a topic about an accident) (Stein-berger et al 2011).
The aspect information canbe used in the model weighting or during sen-tence selection.
We have developed the tool for5 languages considered in Multiling-2013 (Ara-bic, Czech, English, French and Spanish).
Tem-poral analysis could improve sentence ordering ifa correct temporal mark, which contains informa-tion about time of a discussed event, is attached toeach summary sentence (Steinberger et al 2012).So far, we experimented with English, French andSpanish from the list of the Multiling languages.By compressing and/or rephrasing the saved spacein the summary could be filled in by the next mostsalient sentences, and thus the summary can covermore content from the source texts.
We havealready tried to investigate language-independentpossibilities in that direction (Turchi et al 2010).AcknowledgmentsThis work was supported by project ?NTIS - NewTechnologies for Information Society?, EuropeanCenter of Excellence, CZ.1.05/1.1.00/02.0090.ReferencesG.
Giannakopoulos and V. Karkaletsis.
2010.
Sum-marization system evaluation variations based on n-gram graphs.
In Proceedings of the Text AnalysisConference (TAC).G.
Giannakopoulos, M. El-Haj, B. Favre, M. Litvak,J.
Steinberger, and V. Varma.
2012.
Tac 2011 multi-ling pilot overview.
In Proceedings of the Text Anal-ysis Conference (TAC).
NIST.Y.
Gong and X. Liu.
2002.
Generic text summarizationusing relevance measure and latent semantic analy-sis.
In Proceedings of ACM SIGIR, New Orleans,US.C.-Y.
Lin.
2004.
ROUGE: a package for auto-matic evaluation of summaries.
In Proceedings ofthe Workshop on Text Summarization Branches Out,Barcelona, Spain.B.
Pouliquen and R. Steinberger.
2009.
Auto-matic construction of multilingual name dictionar-ies.
In Cyril Goutte, Nicola Cancedda, Marc Dymet-man, and George Foster, editors, Learning MachineTranslation.
MIT Press, NIPS series.J.
Steinberger and K. Jez?ek.
2004.
Text summarizationand singular value decomposition.
In Proceedingsof the 3rd ADVIS conference, Izmir, Turkey.J.
Steinberger and K. Jez?ek.
2009.
Update summa-rization based on novel topic distribution.
In Pro-ceedings of the 9th ACM Symposium on DocumentEngineering, Munich, Germany.J.
Steinberger, M. Poesio, M. Kabadjov, and K. Jez?ek.2007.
Two uses of anaphora resolution in summa-rization.
Information Processing and Management,43(6):1663?1680.
Special Issue on Text Summari-sation (Donna Harman, ed.).J.
Steinberger, H. Tanev, M. Kabadjov, and R. Stein-berger.
2011.
Aspect-driven news summarization.International Journal of Computational Linguisticsand Applications, 2(1-2).53J.
Steinberger, M. Kabadjov, R. Steinberger, H. Tanev,M.
Turchi, and V. Zavarella.
2012.
Towardslanguage-independent news summarization.
In Pro-ceedings of the Text Analysis Conference (TAC).NIST.M.
Turchi, J. Steinberger, M. Kabadjov, R. Steinberger,and N. Cristianini.
2010.
Wrapping up a summary:from representation to generation.
In Proceedingsof CLEF.54
