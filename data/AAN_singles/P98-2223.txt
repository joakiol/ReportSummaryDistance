A Pattern-based Machine Translation System Extended byExample-based ProcessingHideo Watanabe and Koichi TakedaIBM Research, Tokyo Research Laboratory1623-14 Shimotsuruma, Yamato, Kanagawa 242-8502, Japan{watanabe,takeda} @trl.ibm.co.jpAbst rac tIn this paper, we describe a machine translationsystem called PalmTree which uses the "pattern-based" approach as a fundamental framework.
Thepure pattern-based translation framework has sev-eral issues.
One is the performance due to usingmany rules in the parsing stage, and the other isinefficiency of usage of translation patterns due tothe exact-matching.
To overcome these problems,we describe several methods; pruning techniquesfor the former, and introduction of example-basedprocessing for the latter.1 In t roduct ionWhile the World-Wide Web (WWW) has quicklyturned the Internet into a treasury of informationfor every netizen, non-native English speakers nowface a serious problem that textual data are moreoften than not written in a foreign language.
Thishas led to an explosive popularity of machine trans-lation (MT) tools in the world.Under these circumstances, we developed a ma-chine translation system called PalmTree I whichuses the pattern-based translation \[6, 7\] formalism.The key ideas of the pattern-based MT is to em-ploy a massive collection of diverse transfer knowl-edge, and to select he best translation among thetranslation candidates (ambiguities).
This is a nat-ural extension of the example-based MT in the sensethat we incorporate not only sentential correspon-dences (bilingual corpora) but every other level oflinguistic (lexical, phrasal, and collocational) ex-pressions into the transfer knowledge.
It is also arule-based counterpart to the word n-grams of thestochastic MT since our patterns intuitively cap-tures the frequent collocations.Although the pattern-based MT framework ispromising, there are some drawbacks.
One is thespeed, since it uses many rules when parsing.
Theother is inefficiency of usage of translation patterns,1Using this system, IBM Japan releases a MT productcalled "Internet King of Translat ion" which can trans late anEnglish Web pages into Japanese.since it uses the exact-match when matching trans-lation patterns with the input.
We will describeseveral methods for accelerating the system perfor-mance for the former, and describe the extensionby using the example-based processing \[4, 8\] for thelatter.2 Pat tern -based  Trans la t ionHere, we briefly describe how the pattern-basedtranslation works.
(See \[6, 7\] for details.)
A trans-lation pattern is a pair of source CFG-rule and itscorresponding target CFG-rule.
The followings areexamples of translation patterns.
(pl) take:VERB:l a look at NP:2 =~ VP:IVP:I ?= NP:2 wo(dobj) miru(see):VERB:l(p2) NP:I VP:2 =v S:2 S:2 ?= NP:I ha VP:2(p3) PRON:I =~ NP:I NP:I ?
: PRON:IThe (pl) is a translation pattern of an Englishcolloquial phrase "take a look at," and (p2) and(p3) are general syntactic translation patterns.
Inthe above patterns, a left-half part (like "A B C =~D") of a pattern is a source CFG-rule, the right-half part (like "A ?
:= B C D") is a target CFG-rule,and an index number epresents correspondence ofterms in the source and target sides and is also usedto indicate a head term (which is a term having thesame index as the left-hand side 2 of a CFG-rule).Further, some features can be attached as matchingconditions for each term.The pattern-based MT engine performs a CFG-parsing for an input sentence with using sourcesides of translation patterns.
This is done by us-ing chart-type CFG-parser.
The target structure isconstructed by the synchronous derivation whichgenerates a target structure by combining targetsides of translation patterns which are used to makea parse.Figure 2 shows how an English sentence "Shetakes a look at him" is translated into Japanese.2we call the dest inat ion of an arrow of a CFG rule de-scription the left-hand side or LHS, on the other hand,  wecall the source side of an arrow the r ight-hand side or RHS.1369S .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
SVP .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
VP.........................NP .
.
.
.
.
.
.
.
.
.
.
.
.
.. -.. NP  ... NP NPpron verb det noun prep pron pron cm pron cm verb: "  \] : .
ha i wo miru She take a look at him : .. .
.
.
.
.
.
.  "
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.  "
.
.
.
.
.
.
.
.
.
.
: : .
: :  .
.
.
.
- .
.
.
.
.
.
.
.  "
.
.
.
.
.
- " i  .
.
.
.
.
.
.
.
.
"................................. .... :::: ........ , : : : : i  .... .... ......... i ...... ikanojo ha kare wo(she) (subj) (he) (dobj)Figure 1: Translation Example by Pattern-based MTmiru(see)In this figure, a dotted line represents the corre-spondence of terms in the source side and the tar-get side.
The source part of (p3) matches "She"and "him," the source part of (pl) matches a seg-ment consisting "take a look at" and a NP("him")made from (p3), and finally the source part of (p2)matches a whole sentence.
A target structure isconstructed by combining target sides of (pl), (p2),and (p3).
Several terms without lexical forms areinstantiated with translation words, and finally atranslated Japanese sentence "kanojo(she) ha(sub j)kare(he) wo(dobj) miru(see)" will be generated.3 Prun ing  Techn iquesAs mentioned earlier, our basic principle is touse many lexical translation patterns for produc-ing natural translation.
Therefore, we use moreCFG rules than usual systems.
This causes theslow-down of the parsing process.
We introducedthe following pruning techniques for improving theperformance.3.1 Lexical  Ru le  Preference Pr inc ip leWe call a CFG rule which has lexical terms inthe right-hand side (RHS) a lexical rule, otherwisea normal rule.
The lexical rule preference principle(or LRPP} invalidates arcs made from normal rulesin a span in which there are arcs made from bothnormal rules and lexical rules.Further, lexical rules are assigned cost so thatlexical rules which has more lexical terms are pre-ferred.For instance, for the span \[take, map\] of the fol-lowing input sentence,He takes a look at a map.if the following rules are matched,(rl) take:verb a look at NP(r2) take:verb a NP at NP(r3) take:verb NP at NP(r4) VERB NP PREP NPthen, (r4) is invalidated, and (rl),(r2), and (r3) arepreferred in this order.3.2 Le f t -Bound F ixed  Exc lus ive  Ru leWe generally use an exclusive rttle which invali-dates competitive arcs made from general rules fora very special expression.
This is, however, limitedin terms of the matching ability since it is usuallyimplemented as both ends of rules are lexical items.There are many expression such that left-end partis fixed but right-end is open, but these expressionscannot be expressed as exclusive rules.
Therefore,we introduce here a left-bound fixed exclusive (orLBFE) rule which can deal with right-end openexpressions.Given a span \[x y\] for which an LBFE rule matched,in a span \[i j\] such that i<x and x<j<y, and in allsub-spans inside \[x y\],1370x yFigure 2: The Effect of an LBFE Rule* Rules other than exclusive rules are not ap-plied, and?
Arcs made from non-exclusive rules are inval-idated.Fig.2 shows that an LBFE rule "VP ~= VERBNP ''3 matches an input.
In spans of (a),(b), and(c), arcs made from non-exclusive rules are inval-idated, and the application of non-exclusive rulesare inhibited.Examples of LBFE rules are as follows:NP ~ DET own NPNOUN +-- as many as NPNP ~ most of NP3.3 PreproeessingPreprocessing includes local bracketing of propernouns, monetary expressions, quoted expressions,Internet addresses, and so on.
Conversion of nu-meric expressions and units, and decomposition ofunknown hyphenated words are also included in thepreprocessing.
A bracketed span works like an ex-clusive rule, that is, we can ignore arcs crossing abracketed span.
Thus, accurate preprocessing notonly improved the translation accuracy, but it vis-ibly improved the translation speed for longer sen-tences.3.4 ExperimentsTo evaluate the above pruning techniques, wehave tested the speed and the translation qualityfor three documents.
Table 1 shows the speed totranslate documents with and without the abovepruning techniques.
4 The fourth row shows the3This is not an LBFE  rule in practice.4please note that  the t ime shown in this table wasrecorded about two years ago and the latest version is muchfaster.number of sentences tested with pruning which be-come worse than sentences without pruning andsentences with pruning which become better thanwithout pruning.This shows the speed with pruning is about 2times faster than one without pruning at the sametime the translation quality with pruning is kept inthe almost same level as one without pruning..4 Extens ion  by  Example -based  Pro -cess ingOne drawback of our pattern-based formalism isto have to use many rules in the parsing process.One of reasons to use such many rules is that thematching of rules and the input is performed by theexact-matching.
It is a straightforward i ea to ex-tend this exact-matching to fuzzy-matching so thatwe can reduce the number of translation patternsby merging some patterns identical in terms of thefuzzy-matching.
We made the following extensionsto the pattern-based MT to achieve this example-based processing.4.1 Example-based ParsingIf a term in a RHS of source part of a pattern hasa lexical-form and a corresponding term in the tar-get part, then it is called a \]uzzy-match term, oth-erwise an exact-match term.
A pattern writer canintentionally designate if a term is a fuzzy-matchterm or an exact-match term by using a double-quoted string (for fuzzy-match) or a single-quotedstring (for exact-match).For instance, in the following example, a wordmake is usually a fuzzy-match term since it has acorresponding term in the target side (ketsudan-suru), but it is a single-quoted string, so it is anexact-match term.
Words a and decision are exact-match terms since they has no corresponding termsin the target side.
'make':VERB:l  a decision =v VP: IVP: I  ~= ketsudan-suru:lThus, the example-based parsing extends theterm matching mechanism of a normal parsing asfollows: A term TB matches another matched-termTA (LexA,POsB) s if one of the following conditionsholds.
(1) When a term TB has both LexB and POSB,(1-1) LexB is the same as LeXA, and PosB isthe same as PosA.5A matched- term inherits a lexical-form of a term itmatches.1371Sample 1 Sample 2 Sample 3Num of Sentences 13 41 50Time with Pruning (sec.)
16 23 4420 48 67 Time without Pruning (sec.
)Num of Changed Sentences (Worse/Better) 1/2 5/4 4/6Table 1: Result of peformance experiment of pruning techniques(1-2) TB is a fuzzy-match term, the semanticdistance of LexB and LexA is smallerthan a criterion, and PosB is the sameas ROSA.
(2) When a term TB has only LexB,(2-1) LexB is the same as LeXA.
(2-2) LexB is a fuzzy-match term, the seman-tic distance of LexB and LexA is smallerthan a criterion.
(3) When TB has only PosB, then PosB is thesame as RosA.4.2 P r io r i t i za t ion  o f  Ru lesMany ambiguous results are given in the pars-ing, and the preference of these results are usuallydetermined by the cost value calculated as the sumof costs of used rules.
This example-based process-ing adds fuzzy-matching cost to this base cost.
Thefuzzy-matching cost is determined to keep the fol-lowing order.
(1-1) < (1-2),(2-1) < (2-2) < (3)The costs of (1-2) and (2-1) are determined bythe fuzzy-match criterion value, since we cannotdetermine which one of (1-2) and (2-1) is preferablein general.4.3 Mod i f i ca t ion  of  Target  Side of  Ru lesLexical-forms written in the target side may bedifferent from translation words of matched inputword, since the fuzzy-matching is used.
Therefore,we must modify the target side before constructinga target structure.Suppose that a RHS term tt in the target sideof a pattern has a lexical-form wt, tt has a corre-sponding term t, in the source side, and G matchesan input word wi.
If wt is not a translation wordof wi, then wt is replaced with translation words ofwi.4.4 Trans la t ion  ExampleFigure 3 shows a translation example by usingexample-based processing described above.In this example, the following translation pat-terns are used.
(p2) NP:I VP:2 =~ S:2 S:2 ?= NP:I ha VP:2(p3) PRON:I =~ NP:I NP:I ?
: PRON:I(p4) take:VERB:l a bus:2 =~ VP:IVP:I ?= basu:2 ni noru:VERB:lThe pattern (p4) matches a phrase "take a taxi,"since "taxi" and "bus" are semantically similar.
Bycombining target parts of these translation pat-terns, a translation "PRON ha basu ni noru" isgenerated.
In this translation, since "basu(bus)" isnot a correct ranslation of a corresponding sourceword "taxi," it is changed to a correct ranslationword "takusi(taxi)."
Further, PRON is instanti-ated by "watashi" which is a translation of "I.
"Then a correct translation "watashi ha takusi ninoru" is generated.5 D iscuss ionUnlike most of existing MT approaches that con-sist of three major components\[I, 2\] - analysis,transfer, and generation - the pattern-based MTis based on a synchronous model\[5, 3\] of transla-tion.
That is, the analysis of a source sentenceis directly connected to the generation of a targetsentence through the translation knowledge (i.e.,patterns).
This simple architecture makes it mucheasier to customize a system for improving trans-lation quality than the conventional MT, since themanagement of the ambiguities in 3-component ar-chitecture has to tackle the exponential combina-tion of overall ambiguities.
In this simple model,we can concentrate on a single module (a parserwith synchronous derivation), and manage most oftranslation knowledge in a uniform way as transla-tion patterns.Although it is easier to add translation patternsin our system than previous ystems, it is difficultfor non-experts to specify detailed matching condi-tions (or features).
Therefore, we made a patterncompiler which interprets a simple pattern which anon-expert writes and converts it into the full-scalepatterns including necessary matching conditions,1372(p3)(p2) S .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
S (p2)/ .
.
.
.
.
.
- .
.X  ............... ::::::::: : ......"'" "'" " .
.
.
.
.
.
.
.
.
.  "
NP  .
.
.
.
.
.
VP N~ /V \ [ ,~ ,  (P3' I / / i X4  )pron  verb  det  noun pron  cm noun cm verb? "
: ha basu  ni noru  I take  a taxi  ."
?
,o"" " : : (bus)  " :.
.
.
.
- .
.
.
, I o.. , I .
o ,.
?
.
?o .
.
.
.
.o  ?
?
o .
a ~o ???.. "
--... ...- -.
.... _.
..j" !
..-'~V V twatas i  ha takus i  ni(I) ( sub j )  ( tax i )Figure 3: Translation Example by Example-based Processingnoru( r ide)etc.
For instance, the following E-to-J simple pat-tern (a) is converted into a full-scale pattern (b) bythe pattern compiler.
6(a) \[VP\] hit a big shot = subarasii shotto wo utu(b) hit:verb:l a big shot =~ VP:IVP:I ?= subarsii shotto wo utu:verb:lShown in the above example, it is very easy for non-experts to write these simple patterns.
Thus, thispattern compiler enable non-experts o customize asystem.
In conventional MT systems, an expert isusually needed for each component (analysis, trans-fer, and generation).These advantages can reduce the cost of develop-ment and customization of a MT system, and canlargely contribute to rapidly improve the transla-tion quality in a short time.Further, we have shown the way to integrateexample-based processing and pattern-based MT.In addition to reduce the total number of transla-tion patterns, this combination enables us to makea more robust and human-like MT system thanksto the easy addition of translation pattern.6 Conc lus ionIn this paper, we have described a pattern-basedMT system called PalmTree.
This system can break6practically, some conditional features are attached intoverb terms.the current ceiling of MT technologies, and at thesame time satisfy three essential requirements ofthe current market: efficiency, scalability, and ease-of-use.We have described several pruning techniquesfor gaining better performance.
Further we de-scribed the integration of example-based processingand pattern-based MT, which enables us to makemore robust and human-like translation system.References\[1\] Nagao, M., Tsujii, J., and Nakamura, J., "The JapaneseGovernment Project of Machine Translation," Compu-tational Linguistics, 11(2-3):91-110, 1985.\[2\] Nirenberg, S. editor: Machine Translation - Theoreticaland Methodological Issues, Cambridge University Press,Cambridge, 1987.\[3\] Rambow, O., and Satta, S., "Synchronous Models ofLanguage," Proc.
of the 34th of ACL, pp.
116-123,June 1996.\[4\] Sato, S., and Nagao, M. "Toward Memory-based Trans-lation," Proc.
of 13th COLING, August 1990.\[5\] Shieber, S. M., and Schabes Y., "Synchronous Tree-Adjoining Grammars," Proc.
of the 13th COLING, pp.253-258, August 1990.\[6\] Takeda, K., "Pattern-Based Context-Free Grammarsfor Machine Translation," Proc.
of 34th ACL, pp.
144-151, June 1996.\[7\] Takeda, K., "Pattern-Based Machine Translation,"Proc.
of 16th COLING, Vol.
2, pp.
1155-1158, August1996.\[8\] Watanabe, H. "A Similarity-Driven Transfer System,"Proc.
of the 14th COLING, Vol.
2, pp.
770-776, 1992.1373
