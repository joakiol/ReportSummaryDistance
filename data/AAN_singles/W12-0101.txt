Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 1?9,Avignon, France, April 23 - 27 2012. c?2012 Association for Computational LinguisticsSemantic Web based Machine TranslationBettina Harriehausen-Mu?hlbauerUniversity of Applied SciencesDarmstadt, Germanybettina.harriehausen@h-da.deTimm HeussUniversity of Applied SciencesDarmstadt, GermanyTimm.Heuss@web.deAbstractThis paper describes the experimental com-bination of traditional Natural LanguageProcessing (NLP) technology with the Se-mantic Web building stack in order to ex-tend the expert knowledge required for aMachine Translation (MT) task.
Therefore,we first give a short introduction in the stateof the art of MT and the Semantic Weband discuss the problem of disambiguationbeing one of the common challenges inMT which can only be solved using worldknowledge during the disambiguation pro-cess.
In the following, we construct a sam-ple sentence which demonstrates the needfor world knowledge and design a proto-typical program as a successful solution forthe outlined translation problem.
We con-clude with a critical view on the developedapproach.1 IntroductionOver the past decades, Machine Translation (MT)has undergone various changes with regard tothe underlying technology.
Starting in the mid-dle of the last century with rule-based MT, afirst logical step was taken towards the end ofthe century, when statistical methods in NaturalLanguage Processing (NLP) gained overall im-portance, as the growing number of online avai-lable texts could be used as a basis for statisticalcomputations performed on these texts and trans-lations, which resulted in an enhancement of ex-isting rules, statistics and thus results.
The newfield of Statistical Machine Translation (SMT)was born and MT systems became increasinglybetter as more and more texts and translationswere available.
In parallel to the developments inMT, the Web has significantly grown and gainedimportance, especially in the recently definedfield of the Semantic Web.
After having acceptedstatistical methods as a promising change in MT,we believe that a next logical step will combineMT with Semantic Web technology, resulting ina new focus which can be called Semantic WebMachine Translation (SWMT).In this paper, we will develop our ideas step bystep and will demonstrate on a sample sentenceincluding a lexical ambiguity that our approachdoes not involve a costly disambiguation pro-cess on the basis of parsing online-dictionaries.Instead, we believe that modern InformationTechnology (IT) is aligned and committed to in-formation and its markup, as the W3C SemanticWeb technology stack1 demonstrates, and that wecan use the contained knowledge in our disam-biguation process without additional MT rules orstatistics being applied.2 Development and change of focus inMT : from the rule-based past to theweb-based future of MTTraditionally, most MT systems were rule-basedsystems built on electronic analysis and ge-neration grammars as well as a language-pair-dependent transfer component .
These Rule-basedMachine Translation (RBMT) systems always in-volved a careful and time-consuming develop-ment of grammatical rules.More recent development in MT has started touse the vast amount of texts and knowledge that isavailable online for translations based on statistics1http://semanticweb.org/wiki/Main_Page(URL last access 2011-12-18).1and probabilities, leading to a separate focus inMT, namely SMT.With the growing size of texts available in theweb, it is a logical next step to consider usingthe available knowledge in these texts to enhanceNLP applications, including MT, leading to a yetnew focus, which we call SWMT.In this chapter we will develop our idea bystarting with a look at how MT has developed overthe past decades, how it has made use of the ex-panding Web in recent years and where we seefurther potential in using existing knowledge forMT technology.2.1 Statistical Machine TranslationThe dream of automatically translating docu-ments from foreign languages into English, or be-tween any two languages, is one of the oldest pur-suits of NLP, being a subfield of artificial intel-ligence research.
Traditional MT systems com-puted translations primarily on the basis of ana-lysis and generation phrase-structure-rules, whichhad to be manually coded in a costly fashion.One of the leading users of SMT is Googleand Google Translate engineer Anton Andryeyev,who explains SMT?s essence as follows:?SMT generates translations based on patternsfound in large amounts of text.
[...] Instead oftrying to teach the machine all the rules of a lang-uage, SMT effectively lets computers discover therules for themselves.
It works by analysing mil-lions of documents that have already been trans-lated by humans [...].[...]
Key to SMT are the translation dictio-naries, patterns and rules that the program devel-ops.
It does this by creating many different pos-sible rules based on the previously translated doc-uments and then ranking them probabilistically.Google admits this approach to translation in-evitably depends on the amount of texts availablein particular languages [...].?
(Boothroyd 2011)Therefore, with the change of available re-sources and the growing number of natural lang-uage that is available in machine-readable for-mat as well as the growing number of users in-putting corrections to machine translations man-ually, thus allowing a direct and correct matchbetween source and target texts, we have enteredthis subfield of MT which focuses on a statisticalanalysis of texts, in which documents are trans-lated according to a probability distribution p(e|f)which states that a string e in the target languageis the translation of a string f in the source lang-uage.Philipp Koehn, being among the most popu-lar SMT researchers and developers, also high-lights today?s quality of SMT and the relevanceof the vast amounts of texts in the web, whichprovide the basis for SMT translations, by stating?Now, armed with vast amounts of example trans-lations and powerful computers, we can witnesssignificant progress toward achieving that dream.?
(Koehn et al 2012)The research field of statistical machine trans-lation is a rather new field.
In his commented bib-liography2 Koehn includes statistics about the dis-tribution of publications in the SMT field acrossthe years 1953 until 2008.
It is clearly shown thatonly a few publications appeared before the mil-lennium change and that SMT clearly became anissue of growing interest in the new millennium,with a peak in 2006.
Scientists working in theMT field suddenly became aware of the relevanceand potential provided by statistics in machinetranslation and computational linguistics in gen-eral.
Still in 2003, Knight & Koehn stated, that?the currently best performing statistical machinetranslation systems are still crawling at the bot-tom?, (Knight & Koehn 2004, p. 10), implyingthat most of the approaches hadn?t gone beyondsimple word to word translations yet and hadn?tincluded more advanced stages of NLP, like syn-tax or even semantics.
Among those who madeessential contributions to the field of SMT wasKevin Knight who stated in 1999 that ?We wantto automatically analyse existing human sentencetranslations, with an eye toward building generaltranslation rules we will use these rules to trans-late new texts automatically.?
(Knight 1999)The previous statements all point at the vastknowledge included in the just as vast amountsof texts available in digital form in the internet,partly in the form of human sentence translations.At the same time that MT started clearly mov-ing into using the Web to search for machine-readable texts and translations that could be usedin the expanding SMT field, Tim Berners-Lee(Berners-Lee & Hendler 2001) defined the know-ledge, that is included in the Web content, to ex-2http://www.statmt.org/book/bibliography/ (URL last access 2012-01-30).2pand the traditional WWW to become a SemanticWebAs we are looking at an expanded view of howto use the Web, and specifically the SemanticWeb, for our approach of MT, we would like todraw parallels between what has been said so farabout MT and the innovative possibilities that theSemantic Web provides for MT research.2.2 W3C Semantic WebThe World Wide Web (WWW) was once designedto be as simple, as decentralized and as interop-erable as possible (Berners-Lee 1999, 36f.).
TheWeb evolved and became a huge success, how-ever, information was limited to humans.
In or-der to make information available to machines,an extending and complementary set of technolo-gies was introduced in the new millennium bythe W3C, the Semantic Web3 (Berners-Lee &Hendler 2001).The base technology of the Semantic Web isthe data format Resource Description Framework(RDF).
Aligned to the so called AAA sloganthat ?Anyone can say Anything about Any topic?
(Allemang & Hendler 2008, p. 35), it defines astructure that is meant to ?be a natural way todescribe the vast majority of the data processedby machines?
(Berners-Lee & Hendler 2001).
Inaddition to the AAA slogan, a basic construc-tion paradigms of the Semantic Web is the OpenWorld Assumption - the fact that there is alwaysmore knowledge than we currently know; newknowledge can always be added later.RDF expresses meaning by encoding it in setsof triples (Berners-Lee & Hendler 2001), com-posed of subject, predicate and object, which are,in the N3-notation format4, likewise written downas triples::subject :predicate :objectWe see strong connections between MT and theW3C Semantic Web.A lot of ideas exist on how to augmentthe Resource Description Framework (RDF)- the base format of the Semantic Web -with natural language.
Since the beginning,RDF itself provided capacities for a ?human-readable version of a resource?s name?
(Guha3http://www.w3.org/standards/semanticweb/ (URL last access 2012-01-25).4http://www.w3.org/DesignIssues/Notation3.html (URL last access 2012-01-29).2004), rdfs:label, with an optional lang-uage notation following RFC-30665 (Klyne &Carroll 2004).
In addition to that, the Sim-ple Knowledge Organization System (SKOS)ontology features a small selection of uni-code labels for ?creating human-readable rep-resentations of a knowledge organization sys-tem?, skos:prefLabel, skos:altLabeland skos:hiddenLabel - but also remarksthat it ?does not necessarily indicate best practicefor the provision of labels with different languagetags?
(Miles 2008).Some alternatives developed to the approchesabove, to address limitations especially ofrdfs:label and to represent natural languagewithin semantic knowledge in a more sophisti-cated way, like the SKOS eXtension for Labels(SKOS-XL)6, Lemon7 and LexInfo8.And even in the area of wordnets, whichmight be considered as a more traditional NLPdomain, W3C Semantic Web technology playsa role, as approaches were developed to bridgethe gap between natural language representationswithin these wordnets and the design principlesof the Semantic Web (Graves & Gutierrez 2005).The conversion of Princeton WordNet9, forexample, to RDF/OWL is covered by a W3CWorking Draft (van Assem et al 2006) orthe GermaNet wordnet10 equivalent approach(Kunze & Lu?ngen 2007), adapting the ideas ofthe Princeton WordNet conversation.We decided to give a brief overview of thestate-of-the-art of SMT and the Semantic Web,as both areas of research are not only very newdevelopments but they share using information inthe Web for their applications and they both offerpromising enhancements to traditional, rule-basedMT technology.
Nevertheless, SMT and Seman-tic Web Technologies have fundamental differ-5http://www.ietf.org/rfc/rfc3066.txt(URL last access 2012-01-25).6http://www.w3.org/TR/skos-reference/skos-xl.html (URL last access 2012-01-26).7http://www.w3.org/International/multilingualweb/madrid/slides/declerck.pdf(URL last access 2012-01-31).8http://lexinfo.net/ (URL last access 2012-01-31).9http://wordnet.princeton.edu/ (URL lastaccess 2012-01-26).10http://www.sfs.uni-tuebingen.de/lsd/(URL last access 2012-01-26).3ences in that SMT, with systems like Moses11, Ba-bel Fish or Google compute their translations ona pure probability count of n-grams of differentlength in order to find the best translation by pick-ing the one that gives the highest probability.
Asthese systems have access to a growing text cor-pus, which is, as in the case of Moses, directly en-hanced by collecting manual corrections given byusers after the system has computed an inadequatetranslation, they become better with time.
Butexactly these statistically based computations areneither possible nor allowed in the Semantic Webbecause of the Open World Assumption.3 New idea: Enhancing NLP withSemantic Web technologyWith our new approach, we suggest to base MTon a newly defined set of rules, which differ bothfrom rules known from earlier MT approachesbut also from any rules that are applied in SMT.Our rules follow Tim Berners-Lees vision, in thatknowledge, once defined and formalized, is acces-sible in arbitrary ways.
As mentioned earlier, webelieve that modern IT follows the commitmentof information and it?s markup, and the SemanticWeb technology stack is a perfect implementationof that paradigm.To demonstrate our approach, we selected acommon and well known issue: The problem inmany areas of NLP is the ambiguity of naturallanguage on various levels, from word level tosentence level.
In many cases, strings can onlybe disambiguated on the basis of world or expertknowledge.
How else would a machine decide onwhether the prepositional phase is modifying theverb or the preceding noun in ?He eats fish with afork.?
vs. ?He eats fish with bones.??
Especiallywith translations, it is often crucial to understandthe source text correctly, as otherwise ambiguitiesmay result in incomprehensible target languagetranslations, as the examples below will demon-strate.The state of the art technology of the WorldWide Web to express information, facts and re-lations for both humans and machines is RDF.
Soit is not unlikely that nowadays expert knowledgeis encoded in that format, too.11Moses is a statistical machine translation system devel-oped by the Statistical MT Research group of University ofEdinburgh, http://www.statmt.org/moses/.Taking care of lacking expert knowledge withSemantic Web technology and thus extending ex-isting MT technology seems to be a promisingresearch area.
Instead of just combining RBMTwith SMT, we suggest to add the power of the Se-mantic Web to these existing technologies, as theprevious approaches were not able to extract anduse knowledge from the Web in their translationalgorithms and thus leave ambiguities unsolved.The previously quoted statements made it clearthat MT can only be enhanced on the basis ofa growing size of text.
We claim that the nextlogical step is to use this growing size of textnot only statistically, but in a well-defined waywhich is offered by Semantic Web technology.The power of our idea is the combination of astrong, proven technology with a popular, open,machine-readable data format.In order to demonstrate how our approach willenhance existing MT systems, we chose to usea variety of MT systems, some rule-based (e.g.PT12), other statistic-based (e.g.
Babel Fish,Google, and Moses) to compare their context-freetranslation results against our approach.
We usethose context-free translation results as a startingpoint for further processing with Semantic Webtechnology.
Traditional MT technology shouldtherefore not be replaced, but enhanced with se-mantics, to benefit from the advantages providedby the Web.In our sample scenario, the required worldknowledge for the sample sentence Pages byApple is better than Word by MS.is modelled as RDF instances.
We selected asimple file-based storage, with the actual trans-lations being stored as rdfs:labels13 whichare localized as defined in Best Common Practice4714 (BCP47).
To take advantage of the power-ful Semantic Web tool set, parts of the worldknowledge are not directly defined, but can beinferenced by Web Ontology Language (OWL)capacities.
The goal is to produce a semanticallygood translation for the given sentence.12Personal Translator 14 distributed by Linguatec.13http://www.w3.org/TR/rdf-schema/##ch_label (URL last access 2011-12-19).14http://www.rfc-editor.org/rfc/bcp/bcp47.txt (URL last access 2011-12-19).43.1 A sample scenarioThe first step is the construction of an expres-sive sample scenario where world knowledge iscritical for the MT.
We looked at the results anumber of different translation tools computed forour sample sentence: Google Translator15, BingTranslator16, an online demo of Philipp Koehn?sMoses17, Linguatec Personal Translator PT 1418(rule-based) and the reference translation in thispaper, Yahoo!
Babel Fish19.Research concluded with the following sen-tence, requiring the ?expert knowledge?
that avendor called Apple produced a product namedPages and a vendor called MS (very popu-lar shortform of Microsoft) a product namedWord:Pages by Apple is betterthan Word by MS.One important measure to stress the transla-tion service is to use ?indirect?
product names(Pages by Apple and not Apple Pages)to prevent them from deriving product namesfrom possible dictionary entries.
Another ?trap?was to abbreviate Microsoft with MS to irritatepossible n-gram-statistics.The resulting German translations of the sam-ple sentence were the following:Google Translator:Pages von Apple ist besserals Word MS.Bing Translator:Seiten von Apple ist besserals MS Word.Babel Fish:Seiten durch Apple ist besserals Wort durch Frau.Moses Machine Translation Demo:Seiten von Apple ist besserals Word von MS behandelt.15http://translate.google.de/ (URL last ac-cess 2011-12-18).16http://www.microsofttranslator.com/(URL last access 2011-12-18).17http://demo.statmt.org/index.php (URLlast access 2012-01-29).18http://www.linguatec.net/products/tr/pt (URL last access 2012-01-29).19http://de.babelfish.yahoo.com/ (URL lastaccess 2011-12-18).Personal Translator PT 14Paginiert von Apple istbesser als durch MSauszudru?cken.All translations failed, because they did nottake semantic relations into consideration.
This isa systematic issue in MT, demonstrating the ne-cessity of including world knowledge in the com-putation of the target translation.4 More examplesAs ambiguities are a common MT problem, thereare various examples where MT can be enhancedby world knowledge.Consider, for example, popular persons thathave ambiguous last names - like the politiciansGeorge W. Bush, Helmut Kohl20, Joschka Fis-cher21 to name a few.
MT systems are likelyto translate those names if they are not includedin dedicated expert dictionaries.
But thanks toprojects like DBpedia22, we already have theknowledge available in a Semantic Web accessi-ble format and could just use it.Another area that might benefit from a Seman-tic Web Machine Translation is the internation-alization of technical documents or handbooks,which usual deal with several termini technici.Once modelled in RDF, the required expert know-ledge is universally present and could aid thetranslation process as well.5 AnalysisWorld knowledge is the crucial point for the trans-lation quality of the selected sample sentences.It becomes obvious that in situations like this,with missing expert dictionaries, rule sets or lack-ing statistical tooling like N-grams, the translationquality is relatively low.
And this is not an unre-alistic scenario: There will always be uncoveredareas in expert dictionaries or missing statistics ina certain domain.In the given example, if we are looking at theBabel Fish translation, the translation engine wastotally mousetrapped as it translated the Appleproduct Pages with the obviously context free,20The proper name Kohl is also the German word for cab-bage.21Fischer means fisherman in German.22http://dbpedia.org/ (URL last access 2012-03-12).5German translation Seiten.
Furthermore, it in-terpreted MS as salutation and Word as the Ger-man Wort - all mistakes made caused by lexicalambiguities because of the lack of context know-ledge.6 ImplementationIn order to prove our idea, we have developeda prototypical application implementing a Se-mantic Web enhanced SMT.
One principal de-sign goal was to keep the program simple, butto apply state-of-the-art Semantic Web technol-ogy like RDF and the query language SPARQL,which are both W3C recommendations.Figure 1: Architectural overview of the involved com-ponents and exchanged tokens.And because of the powerful but easy to useJena Semantic Web Framework23, a prototype im-plementation is written in the Java programminglanguage.
The involved MT-components are:Trivial word dictionary Performs a one-by-oneword translation.
Entries are designed to re-flect the translation results of Babel Fish.Semantic Core Reads a file based RDF triplestore, executes SPARQL-queries and per-forms reasoning to inference new know-ledge.
Resulting text phrases may overridecertain results derived by dictionary entries.The following sections give more details aboutthe concrete implementation of those componentsand the overall execution logic.23http://jena.sourceforge.net/ (URL lastaccess 2011-12-19).6.1 Trivial word dictionaryTo fake Babel Fishs translation logic, a verysimplified dictionary is defined with the contentaligned at its online pendant.
As figure 2 shows,the context free translation is reproduced withword-by-word translations.English GermanApple ApfelPages SeitenWord Wortbetter besser...
...Figure 2: Simplified dictionary to reproduce BabelFishs simple and context free translation results.6.2 Semantic CoreThe much more interesting part is modelling theworld knowledge with Semantic Web technolo-gies.
Thereby, a simple file based RDF store isused.
The notation format is consistently N324,because of its very good human-readability.As mentioned in previous sections, worldknowledge about Apple and Microsoft iscrucial in this translation task.
So the first state-ments within the RDF store are about both ven-dors and the products they produce25::apple a :vendor, :trigger;rdfs:label "Apple";:produces :numbers , :pages ,:iphone .In this case, the instance :apple is definedto be of the types :vendor and :trigger.While the former type has no special meaningin this context, the latter is especially impor-tant: :trigger-instances mark significant key-words, indicating that additional world know-ledge should be loaded when they occur in asentence.
So in this example occurrence of theword Apple (rdfs:label of :apple) in thesource text triggers loading and parsing of the:apple instance and all uses of it within thestore.Furthermore, some products are defined to beproduced by :apple.24http://en.wikipedia.org/wiki/Notation3 (URL last access 2011-12-19).25For the sake of simplicity, all statements are alignedin the default namespace http://www.example.org/##.6The property :produces as well as its oppo-site :producedBy are defined as follows::produces rdfs:label "produces"@en-US, "produziert"@de-DE .
:producedby rdfs:label "by"@en-US, "von"@de-DE .Note that both properties have dual-language-labels.
This allows the program expressthe world knowledge :apple :produces:iphone in simple but natural English languageas well as in German.In the next step, both properties are semanti-cally connected as owl:inverseOf each other::produces owl:inverseOf :producedbyThis few statements already allow inferenc-ing - reasoning about information that is givenimplicitly.
So it is not only a fact that:apple :produces :iphone, but also af-ter OWL-inferencing the fact that :iphone:producedBy :apple - without having tostate that directly.Finally, the products get their proper names as-signed::numbers rdfs:label "Numbers" .
:word rdfs:label "Word" .
:windows rdfs:label "Windows" .
:pages rdfs:label "Pages" .This few lines form the knowledge base whichis, thanks to inferencing, sufficient to solve thetranslation task.
The following dictionary entriescan directly be read out of the RDF knowledgebase:Microsoft produces WindowsMS produces WindowsMicrosoft produces WordMS produces WordApple produces PagesApple produces NumbersBy evaluating the predicates :produces andinferencing the :producedBy statements, theknowledge base in addition contains the invertedentries:Word by MSWord by MicrosoftWord produced by MSWord produced by MicrosoftWindows by MSWindows by MicrosoftWindows produced by MSWindows produced by Microsoft6.3 Wiring it togetherAs mentioned before, the Semantic World Know-ledge should enhance traditional MT translations.Therefore, the program produces technically twotranslations of the sentence Pages by Appleis better than Word by MS.: The firsttranslation is done by the trivial dictionary, simplyby string-replacing English with German wordsaccording to figure 2.
The second translationfirst tries to find a better translation by checkingtrigger keywords, querying the RDF store for aknowledge, inferencing relationships and resolv-ing labels for the right language, before it contin-ues with the same word-by-word-replacing mech-anism like in the fist translation.Figure 3: The two translations produced by the pro-gram and their technological foundation.6.4 Program executionOur prototype simply executes both describedtranslations and print the result out.Source sentence:Pages by Apple is better thanWord by MS.Semantic Web enhanced translation:Pages von Apple ist besser alsWord von MS.7These simple lines, specially the ?SemanticWeb enhanced translation?, involve a lot of pro-cessing in the background which is not visibleto the user - except for his waiting time.
How-ever, a semantically correct translation solutionwas found.7 Critical view on the solutionWe feel we created something notable here.
How-ever, we stand at the very beginning of our re-search and have encountered corresponding is-sues.Surprisingly, implementation of the programlogic - especially the query mechanism - turnedout to be quite complicated, even for a simple sce-nario like in this case with a very limited corpus.As a result, the stepwise refinement of a transla-tion (trigger word, query of knowledge, inferencerelationships and multi-language-label resolution)consists of a lot SPARQL queries.
These queriesrequire some processing time and power, whichis both already notable in this tiny example.
Thisfinally leads to the conclusion that performancemight be a major withdraw of our approach, atleast for the current implementation.Another issue was connected to data format:the translation environment, especially the usageof RDF triples consisting of subject, predicate andobject, might be regarded to be too much alignedat the very special and constructed problematic ofonly a number of realtime problems.
Sentenceshave to be somehow split into triples, which isquite an artificial border - not to say a technicallimitation - of RDF.
Real world NLP surely doesnot fit into the tripartite simplifications of RDF,and the question is then how often real worldproblems would benefit from this solution.Another issue is the Open World Assumption,built into each Semantic Web component: Thereis no golden standard truth in the Semantic Weband therefore we will never be able to find the?best?
translation for a given sentence withinSPARQL-queries or inferencing results.
Prob-ably, our approach does not hold for providingcomplete translation solutions, but for givingvery qualified suggestions.
Some SMT tools, likeMoses, actually do work with suggestions.However, some of this issues might be solvedby applying more sophisticated NLP / MT tech-nology, like n-grams.
Besides these issues, theprogram works as expected and Semantic Webtechnology was successfully used to integrateworld knowledge into a MT process.
Thus, thetranslation gathered a better quality and it thus canbe stated that the experiment was successful.8 Related workThe project Monnet has, according to its missionstatement26, a similar idea to combine MT withSemantic Web technology.
However, results arestill pending or not publically accessible at thispoint.We also acknowledge the work by Elita andBirladeanu (2005), who outlined the combinationof the Semantic Web with Example Based Ma-chine Translation (EBMT), which is very muchrelated to our approach.
However, there are ma-jor differences: Elita and Birladeanu (2005) onlyapplied their technique on certain phrases of off-ical documents - sequences of words they call?fields?
(Elita & Birladeanu 2005, p. 14).
Ouridea is however to aid translation of complete sen-tences.
Another very important difference is theintensiveness of use of W3C technology.
UnlikeElita and Birladeanu (2005), we heavily use RDF,SPARQL and - probably the most promising mat-ter of fact - OWL reasoning and try to follow theSemantic Web standard tooling very strictly.9 OutlookAt this point in our research, we have not yet com-bined existing MT technology, especially SMT,with SWMT.
The combination of approaches hasyet to be explored, but existing MT technologiesand SWMT are certainly not mutually exclusiveand we suspect that a combination of MT ap-proaches will lead to yet even better results, es-pecially in cases where the translation quality isbased on world or expert knowledge.10 ConclusionIn the recent past, MT researchers have alreadydiscussed the combination of RBMT and SMT(Hutchins 2009, pp.
13-20).
We suggest toadd yet another possibility in MT to existing MTapproaches, namely a Semantic Web based MT(SWMT).26http://www.monnet-project.eu/Monnet/Monnet/English?init=true (URL last access2012-01-26).8In this paper we have taken a next logicalstep in MT technology by including not only thevast amounts of texts available in the Web to en-hance MT quality applying statistical computa-tions across online texts and translations, but go-ing one step further by looking at the power of andknowledge contained in the Semantic Web.By taking advantage of the knowledge in theWeb of the future, our approach of combiningSemantic Web technology with MT allows thisworld knowledge to be made available for ma-chine translations, thus enhancing challenges inMT, such as lexical ambiguities.
In our discussedsample sentences, we have shown that a solu-tion for the disambiguation would traditionally in-volve a costly disambiguation process or wouldbe left unsolved.
Using our SWMT approach, theMT quality benefits from world knowledge ex-tracted from the Semantic Web and by its tech-nology.This combination of MT with Semantic Webtechnology results in a new focus of MT whichwe suggest to be called Semantic Web based MT(SWMT).11 AcknowledgementsWe like to thank Rike Bacher from Linguatec andthe reviewers of the ESIRMT-HyTra conference2012 for their valuable hints.ReferencesAllemang, D. & Hendler, J.
(2008), Semantic Webfor the Working Ontologist: Effective Modeling inRDFS and OWL, Morgan Kaufmann.URL: http://www.amazon.com/Semantic-Web-Working-Ontologist-Effective/dp/0123735564Berners-Lee, T. (1999), Weaving the Web : The Origi-nal Design and Ultimate Destiny of the World WideWeb by its Inventor, HarperOne.URL: http://www.amazon.com/Weaving-Web-Original-Ultimate-Inventor/dp/0062515861Berners-Lee, T. & Hendler, J.
(2001), ?Scientific Amer-ican: The Semantic Web?, Scientific American,USA.
.URL: http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Scientific+American:+The+Semantic+Web\#3Boothroyd, D. (2011), ?Statistical machine translationto enable universal communication?
?.URL: http://www.newelectronics.co.uk/electronics-technology/statistical-machine-translation-to-enable-universal-communication/33008/Elita, N. & Birladeanu, A.
(2005), ?A first step in inte-grating an EBMT into the Semantic Web?.URL: www.mt-archive.info/MTS-2005-Elita.pdfGraves, A.
& Gutierrez, C. (2005), ?Data representa-tions for WordNet : A case for RDF?.URL: http://www.dcc.uchile.cl/?cgutierr/papers/wordnet-rdf.pdfGuha, R. (2004), ?RDF Vocabulary Description Lang-uage 1.0: RDF Schema?.URL: http://moodletest.ncnu.edu.tw/file.php/9506/references-2009/RDF\_schema\_1.pdfHutchins, J.
(2009), ?Multiple Uses of Machine Transla-tion and Computerised Translation Tools?, MachineTranslation pp.
13?20.URL: http://www.hutchinsweb.me.uk/Besancon-2009.pdfKlyne, G. & Carroll, J.
(2004), ?Resource descriptionframework (RDF): Concepts and abstract syntax?,Changes 10(February), 1?20.URL: http://www.mendeley.com/research/w3c-gibt-recommendation-fr-resource-description-framework-rdf-frei/Knight, K. (1999), A statistical MT tutorial workbook,in ?Prepared for the 1999 JHU Summer Workshop?.URL: http://www.snlp.de/prescher/teaching/2007/StatisticalNLP/bib/1999jhu.knight.pdfKnight, K. & Koehn, P. (2004), ?What?s New in Statis-tical Machine Translation?, Tutorial, HLT/NAACLpp.
1?89.URL: http://www.auai.org/uai2003/Knight-UAI-03.pdfKoehn, P., Osborne, M., Haddow, B., Auli, M., Buck,C., Dugast, L., Guillou, L., Hasler, E., Matthews,D., Williams, P., Wilson, O.
& Saint-Amand, H.(2012), ?Statistical Machine Translation at the Uni-versity of Edinburgh?.Kunze, C. & Lu?ngen, H. (2007), ?Repra?sentation undVerknu?pfung allgemeinsprachlicher und terminolo-gischer Wortnetze in OWL?, Zeitschrift fu?r Sprach-wissenschaft .Mark van Assem, V. U.
A., Aldo Gangemi, ISTC-CNR,R.
& Guus Schreiber, V. U.
A.
(2006), ?RDF/OWLRepresentation of WordNet?.URL: http://www.w3.org/TR/wordnet-rdf/Miles, A.
(2008), ?SKOS simple knowledge organiza-tion system reference?, W3C Recommendation .URL: http://www.mendeley.com/research/skos-simple-knowledge-organization-system-reference/9
