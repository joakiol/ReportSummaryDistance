Proceedings of the 2014 Joint Meeting of SIGMORPHON and SIGFSM, pages 19?28,Baltimore, Maryland USA, June 27 2014. c?2014 Association for Computational LinguisticsComparing Models of Phonotactics for Word SegmentationAbstractDevelopmental research indicates that infants use low-level statistical regularities, or pho-notactics, to segment words from continuous speech.
In this paper, we present a segmenta-tion framework that enables the direct com-parison of different phonotactic models for segmentation.
We compare a model using phoneme transitional probabilities, which have been widely used in computational models, to syllable-based bigram models, which have played a prominent role in the developmental literature.
We also introduce a novel estimation method, and compare it to other strategies for estimating the parameters of the phonotactic models from unsegmented data.
The results show that syllable-based models outperform the phoneme models, specifically in the context of improved unsu-pervised parameter estimation.
The syllable-based transitional probability model achieves a word token f-score of nearly 80%, the high-est reported performance for a phonotactic segmentation model with no lexicon.
1 Introduction One of the first language learning tasks infants must solve is the segmentation of fluent speech into words.
Extensive experimental work has demonstrated that infants are able to use phono-tactic restrictions (Jusczyk & Luce, 1994; Mattys et al., 1999; Mattys & Jusczyk, 2001) and other low-level statistical regularities (Saffran et al., 1996; Thiessen & Saffran, 2003; Pelucchi et al., 2009) to extract words from fluent speech before the age of one.
This work has shown that infants utilize these low-level statistical regularities to segment speech during the second half of the first year of life before they have developed ex-tensive vocabularies that could provide top-down lexical information to guide segmentation.
De-velopmental research indicates that on average infants know fewer than 100 word types during this period (Dale & Fenson, 1996; Daland & Pierrehumbert, 2011).
One statistical cue that has received a great deal of support in experimental work on infant speech segmentation is transitional probability calculated over syllables.
In foundational work, Saffran et al.
(1996) found that infants are able to segment words from continuous speech using statistical regularities between syllables.
Numer-ous subsequent studies have confirmed that in-fants can track transitional probabilities and use them to segment speech (Aslin et al., 1998; Thiessen & Saffran, 2003; Pelucchi et al., 2009).
Despite the extensive experimental literature demonstrating infants?
sensitivity to transitional probability in an artificial language learning set-ting, the utility of these statistical cues in a natu-ral language learning context is disputed.
Yang (2004) shows that a segmentation strategy rely-ing on transitional probabilities over syllables achieves very poor results on English child-directed speech, even when the input is perfectly syllabified.
Yang implements the local minimum segmentation strategy proposed by Saffran et al.
(1996) wherein word boundaries are posited at syllable transitions whenever the transitional probabilities at these positions are lower than at the neighboring transitions.
He reports that this strategy discovers a mere 23% of target words and posits incorrect words nearly 60% of the time.
Swingley (2005) argues that statistical cues calculated over syllables can provide sufficient information for infants to begin building an ini-tial lexicon.
However, the learning strategy ex-plored by Swingley is highly conservative, relia-bly detecting only a small proportion of target words in the input.
Overall, these results raise questions about whether syllable-based statistics can be reliably used to identify word boundaries in natural language data.Natalie M. Schrimpf Department of Linguistics Yale University natalie.schrimpf@yale.eduGaja Jarosz Department of Linguistics Yale University gaja.jarosz@yale.edu19While the experimental work emphasizes syl-lable-level transitional probability, recent com-putational modeling work and corpus analyses have primarily focused on the utility of pho-neme-level statistics.
A number of phonotactical-ly-based segmentation models, focusing on the discovery of word boundaries based on pho-neme-level statistics, have achieved more prom-ising results (Adriaans & Kager, 2010; Daland & Pierrehumbert, 2011; see also Brent, 1999).
For example, Brent (1999) showed that a local mini-mum strategy relying on phoneme bigrams cor-rectly extracts about 50% of word tokens in Eng-lish child-directed speech.
Corpus analyses of child-directed speech have also highlighted the information content of phoneme-level statistics (Hockema, 2006; Jarosz & Johnson, 2013).
Re-lated work has shown that phonotactic infor-mation can improve the performance of state-of-the-art segmentation models whose primary ob-jective is to discover the lexicon that underlies the regularities in the continuous speech signal.
Again, this work has largely emphasized pho-neme-level statistical cues (Blanchard & Heinz 2008, 2010), and those models that do rely on syllable structure (Johnson, 2008a; Johnson & Goldwater, 2009), do not directly encode sequen-tial statistics between adjacent syllables of the sort investigated in the infant literature.
Finally, some models assume computations are per-formed over syllables and that all word bounda-ries in the input are aligned with syllable bounda-ries, but provide no mechanism by which such language-specific syllabification principles could be learned (Yang, 2004; Swingley, 2005; Lignos & Yang, 2010).
Overall, the existing evidence clearly shows that there are phonotactic cues to word bounda-ries in spontaneous, child-directed speech.
How-ever, there are remaining questions regarding the exact nature of these cues, their reliability, and how they relate to the statistical cues explored in the infant word segmentation literature.
In this paper, we investigate the computational mecha-nisms underlying infants?
early speech segmenta-tion abilities relying on low-level statistical regu-larities, or phonotactics.
We present a computa-tional framework that permits the direct compari-son of segmentation predictions for alternative models of phonotactics.
In particular, we com-pare a standard phonotactic model relying on phoneme-level bigrams to two syllable-based phonotactic models relying on transitional prob-abilities.
Unlike previous models relying on syl-labified data (Yang, 2004; Swingley, 2005; Lig-nos & Yang, 2010), we do not assume that word boundaries align with syllable boundaries in the input.
Rather, we present a simple syllabification method that can be used to model phonotactic probability for arbitrary strings using statistics estimated from unsyllabified, unsegmented utter-ances.
We also compare the local minimum seg-mentation strategy (Saffran et al., 1996; Yang, 2004) to alternatives designed to deal with the challenges of unsupervised estimation of transi-tional probabilities from unsegmented input.
Our focus on the early phonotactic segmenta-tion stage differentiates our approach from many computational models emphasizing the discovery of the lexicon and higher-level language struc-ture (Brent, 1999; Venkataraman, 2001; Swin-gley, 2005; Johnson, 2008a; Goldwater et al., 2009; Johnson & Goldwater, 2009; Blanchard & Heinz 2008, 2010; Lignos & Yang, 2010).
It complements that of recent work investigating the use of phoneme-level statistical regularities for segmentation (Adriaans & Kager, 2010; Da-land & Pierrehumbert, 2011).
Our work differs from these latter approaches, however, in com-paring several phonotactic models, including ones relying on the syllable-based transitional probability statistics investigated in infant re-search.
Our work also contributes to existing segmentation work that assumes a syllabified input (Yang, 2004; Swingley, 2005; Lignos & Yang, 2010) by showing how many aspects of syllable structure can be inferred.
Our results reveal an interaction between es-timation strategy and the choice of phonotactic model.
The local minimum segmentation strate-gy works poorly in general for all models con-sidered, but the lowest performance is achieved by the syllable-based models.
However, when the same cues are used in the context of a simple, generative probability model with improved un-supervised parameter estimation, the syllable-based models substantially outperform the pho-neme-based models.
Indeed, the syllable-based transitional probability phonotactic model achieves a word token segmentation f-score of nearly 80%, which is the highest reported per-formance among purely phonotactically-based segmentation models (Adriaans & Kager, 2010; Daland & Pierrehumbert, 2011).
Indeed, this per-formance compares favorably with state-of-the-art segmentation models that involve learning of higher level regularities, such as the lexicon and collocations (Brent, 1999; Venkataraman, 2001; Johnson, 2008a; Goldwater et al., 2009; Johnson & Goldwater, 2009), and demonstrates that good20segmentation performance can be achieved by exploiting simple syllable-level phonotactic cues.
2 Segmentation Model The proposed segmentation model defines the probability of an utterance in terms of an abstract phonotactic probability component that assigns word well-formedness probabilities to phoneme strings.
The segmentation algorithm uses those probabilities to determine the maximum likeli-hood segmentation as defined by a simple gener-ative model.
Since the phonotactics and segmen-tation components are separate, they can be in-dependently modified.
This framework makes it possible to compare models of phonotactics while using the same segmentation strategy.
2.1 Probability Model The segmentation probability model relies on the phonotactic component to assign probabilities to potential words.
The probability of a segmenta-tion w is defined in terms of a simple unigram model by multiplying the probabilities of the words !!!!
posited in that segmentation.
1) !
!
!
!
!!
!
!
!
!!!
!!!!
!
!!
!is the probability assigned by the phono-tactic models, which will be defined in the next section.
The various phonotactic models change how exactly !
!
!
!is defined, but the segmenta-tion probability always depends directly on the word probabilities given by a particular phono-tactic model.
For example, for the utterance [l!k?tmi] ?lookatme?, the segmentation model compares different segmentations, such as [l!k#?#tmi] and [l!k#?t#mi] based on the pho-notactic well-formedness of the posited words.
2.2 Segmentation Algorithm The segmentation algorithm computes and out-puts the segmentation with the highest likeli-hood: !"#$!%!
!
!
.
The optimal segmenta-tion is found using dynamic programming, as in several previous proposals (Brent, 1999; Venka-taraman, 2001).
Given an input utterance, the model considers placing word boundaries at dif-ferent positions within the utterance without re-gard to phonotactics or syllable structure.
The phonotactic probability of each posited word is calculated independently as it is considered and used to update the probability of segmentations utilizing that word.
In this way, the segmentation component remains entirely divorced from thedetails of the phonotactic models.
Crucially, this means the full space of possible segmentations is considered by the segmentation model regardless of the phonotactic model, with no a priori re-strictions imposed by phonotactic or syllable constraints as to where boundaries are permitted.
3 Phonotactic Models We implement and compare several models of phonotactics that are utilized by the segmentation component described above.
While all models rely on transitional probabilities, or bigrams, as defined in (2), the unit of analysis varies between the models.
One model uses phonemes and pho-neme transitions, and two models incorporate syllable information: we use x to denote a gener-ic unit.
The model determines the probability of a word, !
!
!!!!
!
!
!
where !!
and !!!!
are the word boundary symbol #, by multiplying the probabilities of all bigrams in the word.
2) !
!
!
!
!
!!
!!
!!!!!!
!
The transitional probability for the sequence !!!!!
!
can be calculated using relative frequency estimates based on counts !
in the corpus.
3) !
!!
!!!!
!
!!!!!!!!!!!
!!!!
!
!
Section 4 describes strategies that we consider for estimating these parameters in an unsuper-vised way from unsegmented data where the on-ly word boundaries are those that coincide with utterance boundaries.
3.1 Phoneme Model The first phonotactic model is a standard pho-neme bigram model that determines the probabil-ity of a word by multiplying the phoneme bi-grams in the word (Jurafsky & Martin, 2008).
For example, to calculate the phonotactic proba-bility of the sequence [bot] as a word, this model multiplies together P(b|#)P(o|b)P(t|o)P(#|t).
3.2 Syllable-Based Models The other two phonotactic models use syllables rather than phonemes.
One model relies on tran-sitional probabilities over syllables, and the other uses onsets and rhymes as the unit of analysis.
3.2.1 Unsupervised Syllabification The syllabification method relies on the language universal principle of onset maximization to-21gether with an inventory of syllable onsets de-rived from the beginnings of utterances.
When syllabifying an intervocalic sequence of conso-nants, this method finds the longest legal onset aligned with the right edge and places any re-maining consonants in the coda of the previous syllable.
Thus, a sequence like [?tmi] would be syllabified as [?t.mi] in English since [m] but not [tm] occurs utterance-initially.
The only lan-guage-particular information required for this approach is knowledge of which phonemes are vowels (syllabic) and which are consonants, a limited type of information also assumed by oth-er syllable inference models for segmentation (Johnson, 2008a; Johnson & Goldwater, 2009).
As the segmentation component posits poten-tial words, they are passed to the phonotactic component for syllabification and phonotactic probability calculation.
This differs crucially from previous work assuming a fixed syllabifica-tion of the input corpus in which word bounda-ries always align with syllable boundaries (Yang, 2004; Swingley, 2005; Lignos & Yang, 2010).
In a setting in which syllabification must be in-ferred from unsegmented utterances, the learner must be capable of assigning syllabification more flexibly since word boundaries do not always align with the syllable boundaries that would be posited for the utterance as a whole.
For exam-ple, the universal onset maximization principle always parses singleton consonants VCV as the onsets V.CV rather than codas VC.V.
Therefore, without prior knowledge of word boundaries, the utterance [l!k?tmi] (?look at me?)
would be syl-labified as [l!.k?t.mi], and if the segmentation algorithm never considered words that misa-ligned with these syllable boundaries, it would never extract any vowel-initial words like ?at?.
Thus, a crucial feature of the current model is that syllabification takes place on a word-by-word basis as potential words are posited.
The resulting syllabification for the potential word is used by the syllable-based models to assign pho-notactic probability as discussed below.
3.2.2 Syllable Model The first syllable-based model is one in which bigram transitional probabilities are calculated over syllables.
These transitional probabilities are precisely those discussed earlier as having played a prominent role in the infant segmenta-tion literature.
The phonotactic probability of a posited word is calculated by multiplying thetransitional probabilities of all syllable bigrams in the word, including an assumed initial and final #.
For example, if the segmentation compo-nent posits a potential word such as [l!k?tmi] ?lookatme?, this sequence is first syllabified us-ing the procedure described earlier as [l!.k?t.mi].
Then the phonotactic probability of this potential word is calculated by multiplying together the syllable-based bigram probabilities: P(l!|#)P(k?t|l!)P(mi|k?t)P(#|mi).
As before, rel-ative frequency estimates calculated from un-segmented input data (automatically syllabified using the unsupervised syllabification method described earlier) provide a starting point for pa-rameter estimation.
Estimation strategies are dis-cussed in depth in Section 4.
3.2.3 Onset Rhyme Model In addition to the phoneme level and syllable level bigram models, we consider an intermedi-ate model that makes use of the main subconstit-uents of syllables: onsets and rhymes.
Recall that the syllabification procedure relies on identifying maximal onsets, whereas rhymes are composed of the remaining material in the syllable.
So the-se constituents are already available during the syllabification procedure, and this phonotactic model operates over these smaller constituents, rather than over entire syllables.
The syllable-based model operates over indivisible syllable units, while this models treats syllables as com-binations of smaller subconstituents.
Once a sequence is syllabified (separating on-sets and rhymes), this model uses bigrams over these units to determine word probabilities.
Con-sider again the potential word [l!k?tmi] ?lookatme?.
This sequence is first syllabified into onsets and rhymes as [l.!.k.?t.m.i].
Then its phonotactic probability is calculated by multiply-ing together the bigram probabilities: P(l|#)P(!|l)P(k|!)P(?t|k)P(m|?t)P(i|m)P(#|i).
As before, relative frequency estimates are calculat-ed from an (automatically syllabified) unseg-mented version of the input corpus.
4 Estimation Inferring the parameters of these models in an unsupervised way from unsegmented utterances presents a number of challenges.
First, a genera-tive model relying on these parameters must be able to accommodate elements and sequences of elements that have not previously been encoun-22tered.
This includes unseen phonemes, onsets, rhymes, syllables, and unseen sequences of these units.
A second difficulty for the generative model arises specifically in the context of seg-mentation due to the number of boundaries en-countered in the input data.
In an unsegmented corpus there are no boundaries within an utter-ance.
The only evidence for word boundaries comes from boundaries at the beginnings and ends of utterances.
The effect is that the total number of boundaries is lower than the number that must be inferred by the learner, and the overall probability of boundaries is underrepre-sented in the input data.
We considered several estimation methods to overcome these effects.
4.1 Local Minimum Strategy In previous research (Saffran et al., 1996) it has been suggested that word boundaries are placed at troughs in transitional probability so that a boundary is inserted between two elements when the transitional probability of those elements is lower than the probability of the neighboring transitions.
This strategy captures the fact that word boundaries are more likely to occur be-tween elements that have a low probability of occurring together.
Since this strategy does not incorporate transitional probabilities into a gen-erative segmentation model, it provides a simple way around the estimation challenges discussed above.
We include it for comparison to previous results relying on syllable-based transitional probabilities (Yang, 2004).
4.2 Adjusted Boundary Count Strategy We also introduce a novel, simple method for adjusting the estimates of transitional probabili-ties based on input data that underrepresents word boundaries.
This method directly adjusts the parameter estimates in order to increase the overall likelihood of word boundaries.
The main insight behind this estimation strategy is that ob-served bigram counts (of co-occurring pho-nemes, syllables, or onsets and rhymes) in the input data are overestimated since a proportion of them are in reality separated by word bounda-ries in the desired segmentation.
For a given pro-portion p# (a parameter of this estimation meth-od), the bigram counts of co-occurring elements (phonemes, syllables, or onsets/rhymes) are sys-tematically decreased by a factor of (1- p#) and for each context c, are reallocated to the transi-tional probability of P(# | c).
The formula below illustrates how this adjustment works for arbi-trary contexts c and proportion p#.
The probabil-ity of each possible element !!
that can follow c is decreased by a factor of p# as shown in (4).
The total probability taken away from all contin-uations of c is used to increase the probability of P(# | c) as shown in (5).
4) !
!!
!
!
!!!!!
!!!!!!!
!!
!
!!!
5) !
!
!
!
!!!!
!
!!!
!!!
!
!
!!!!
!!!
!!!!!!
!
!
Consider an example for the context x, with three bigrams observed in the input: c(xy) = 10, c(xz) = 6, and c(x#) = 4.
The relative frequency estimates for these transitional probabilities are 0.5, 0.3, and 0.2 respectively.
The adjusted count method takes away p# of the xy and xz counts and reallo-cates them to x#.
For p# = 0.5, for example, the new estimates would be 0.25, 0.15, and 0.6.
The adjustment works analogously for every context for each of the units of analysis.
4.3 Smoothing We also utilized rudimentary smoothing tech-niques to allow the generative model to deal with unknown sequences.
We chose a simple method that allocated non-zero probability to unseen se-quences while minimally disrupting the estimates computed using the adjusted boundary count strategy, since our primary concern was in ex-ploring the effects of this novel re-estimation strategy.
For all models, add-lambda smoothing (Jurafsky & Martin, 2008) with a value of 0.001 was used.
For the syllable-based models this total value was allocated to all unseen bigrams in or-der to avoid over-allocation of probability to the numerous combinations of unseen syllabic units.
4.4 Iterative Re-estimation After estimating the transitional probabilities from the unsegmented corpus, the above strate-gies can be used to compute the optimal segmen-tation of the input corpus in a single pass.
In ad-dition to the above strategies, we also investigat-ed a greedy, iterative re-estimation strategy that makes multiple passes through the corpus.
This estimation method takes the output of the above methods and uses it to re-estimate (smoothed and adjusted) parameters for the phonotactic models.
It then recomputes the optimal segmentation of the corpus based on the new parameters and re-peats until convergence.
This method is moti-vated by previous segmentation work highlight-ing the effectiveness of greedy re-estimation23techniques (Brent, 1999; Venkataraman, 2001; Goldwater et al., 2009; Johnson & Goldwater, 2009).
As noted in previous work, such greedy re-estimation has the potential to infer additional word boundaries based on commitments made to word boundaries on earlier passes.
5 Experiments 5.1 Corpus The experiments for all the models were run on the Brent (1999) version of the Bernstein-Ratner (1987) corpus of English child-directed speech consisting of phonetically transcribed utterances.
This corpus has been widely used for evaluating segmentation models.
Other models evaluated on this corpus include those of Brent (1999), Venka-taraman (2001), Blanchard and Heinz (2008), and Johnson and Goldwater (2009).
5.2 Evaluation Precision, recall, and f-scores of both word to-kens and boundaries were used to evaluate per-formance.
For the models with iterative re-estimation, the reported performance scores are taken from the iteration after convergence.
This typically happened after 5-10 iterations.
5.3 Results and Discussion Table 1 summarizes the word boundary and word token f-scores for all models, while Table 2 presents the precision and recall scores for the best-performing adjusted count models and the local minimum models.
Focusing first on the local minimum estima-teion strategy, there are several noteworthy ef-fects.
First, our results with local minima for the syllable-level transitional probabilities achieves very similar word token precision and recall to that reported by Yang (2004), who examined a different corpus of child-directed English.
The word token precision and recall of our model is 40.2% and 23.7%, respectively, while Yang re-ported 41.6% and 23.3%, respectively, for his experiments.
This corroborates Yang?s finding that the local minima estimation strategy for syl-lable-level transitional probabilities works very poorly, this time showing that this level of per-formance can be achieved with simultaneous in-ference of syllabification.
As Table 2 shows, the poor performance can be attributed to poor re-call, which the low boundary recall and high pre-cision illustrate most clearly.
As Yang discusses, the fatal flaw for this approach is that it categori-cally fails to segment monosyllabic words, whichaccount for an overwhelming majority of words in child-directed speech.
This is because local minima must, by definition, be separated by at least one transition with a higher bigram proba-bility, which is not treated as a boundary.
Indeed, the proportion of monosyllables is so high that a baseline strategy that simply posits word bounda-ries at all syllable boundaries achieves a word token f-score of 58.0% using the minimally-supervised syllabification procedure described here1.
The high performance of the monosyllabic baseline highlights the ineffectiveness of the lo-cal minimum strategy but also indicates that syl-lable structure provides a significant amount of information about word boundaries in English, even if this syllable structure is automatically inferred from unsegmented input using minimal prior knowledge.
Furthermore, our results with the phoneme bigram local minimum strategy (47.1% word token f-score) corroborate Brent?s (1999) finding that this method achieves a roughly 50% word token f-score (Brent did not provide exact num-bers).
The improvement in performance is not surprising given the above discussion about the prevalence of monosyllabic words: local minima defined over the smaller phoneme units do not automatically rule out the possibility of segment-ing short words.
We also demonstrate that the onset-rhyme model achieves performance similar to that of the syllable bigram model using the local minima strategy.
Finally, the results with iterative re-estimation show that further refine-ment of the posited word boundaries can lead to some improvement, but none of the local mini-mum models surpass 53% word token f-score, and the syllable-based models perform substan-tially worse.
Overall, these partial results are consistent with the trend suggested by previous work that the syllable-level bigrams examined in the infant studies provide little information about word boundaries in natural language data when the local minimum strategy is used.
However, a different picture emerges when the performance of the adjusted count strategy is considered.
The fact that the local minimum strategy is ineffectual is already clear from the comparison with the monosyllabic baseline; however, the results for the adjusted counts esti-mation strategy reveal that it is possible to ex-                                                 1 In contrast, Lignos & Yang (2010) report a word token f-score of 78.9% for this baseline for already syllabified in-put.
The difference between these baselines highlights how much more difficult the segmentation task is when the syl-labification must be inferred from unsegmented input.24p# = 0 p# = 0.35 p# = 0.5 p# = 0.6 p# = 0.75 p# = 0.99 LM  WF BF WF BF WF BF WF BF WF BF WF BF WF BF P 13.0 10.2 34.7 51.9 40.3 60.6 49.9 69.2 45.9 68.8 13.9 50.1 47.1 64.5 OR 15.4 17.9 28.7 43.3 37.1 55.8 42.2 62.0 58.4 76.0 52.3 71.4 27.9 44.1 S 10.7 3.1 12.7 8.6 14.2 12.4 15.9 16.3 20.7 26.1 74.1 84.1 29.8 51.0 P-IR 13.0 10.2 34.7 51.9 40.3 60.6 50.7 69.6 46.9 69.6 9.9 47.0 52.9 70.5 OR-IR 19.8 29.1 36.8 54.7 47.7 67.7 53.4 72.8 63.8 79.8 37.1 62.1 42.3 62.3 S-IR 10.9 3.8 13.3 10.5 15.2 15.0 16.8 18.7 23.1 31.4 79.8 88.0 27.2 43.9 Table 1: Word token (WF) and boundary (BF) f-scores for all models.
The columns in the first section of the table represent different settings of the p# parameter, with highest performance for each adjusted count model shown in bold.
p# values were selected to show a representative range of performance.
P = phoneme model; OR = onset-rhyme model; S = syllable model; IR = iterative re-estimation; LM = local minimum strategy.
The best performing local minimum model is shaded.
Adjusted Count Estimation Local Minimum Estimation  WP WR BP BR WP WR BP BR P-IR 50.3 51.1 68.8 70.4 53.4 52.4 71.5 69.5 OR-IR 63.8 63.8 79.9 79.8 44.2 40.5 66.5 58.6 S-IR 85.2 75.0 97.0 80.6 40.4 20.5 94.0 28.6 Table 2: Word precision (WP), word recall (WR), boundary precision (BP), and boundary recall (BR) scores for selected models.
For the adjusted count estimation models, the results for the best perform-ing parameter value are shown (P-IR: 0.6; OR-IR: 0.75; S-IR: 0.99).
extract substantially more information about word boundaries from syllable-based models when these cues are used in the context of a gen-erative model and better methods are used for unsupervised estimation of these parameters.
In fact, using the adjusted counts estimation method with the optimal parameter settings, the reverse trend is observed, wherein the phoneme-level bigrams perform worse than the syllable-based models, and syllable-level bigrams perform best of all, reaching word token f-scores of nearly 80%.
Crucially, both the onset-rhyme and the syllable bigram models achieve levels of perfor-mance that surpass the monosyllabic baseline.
In the case of the syllable bigram, the improvement in word token f-score is more than 20% when iterative re-estimation is used and more than 15% when segmentation is performed in only a single pass through the corpus.
The phoneme-based models perform about as well whether adjusted counts or local minimum estimation is used.
However, compensation for the underrepresentation of word boundaries in the input is crucial to the syllable-based models.
These models surpass the local minimum estima-tion models only when the p# parameter compen-sates sufficiently for the input bias against word boundaries.
As shown in Table 1, without any compensation (p# = 0), all models perform terri-bly.
This is because utterance boundaries provide very little evidence of word boundaries, and the models estimated directly from such input mas-sively undersegment.
It is only at higher settings of the parameter that performance improves.
As expected, the optimal parameter value increases with the granularity of the unit over which bi-grams are computed.
This makes sense since boundaries are more likely to fall between larger units than between smaller units.
Less expected is the fact that the optimal pa-rameter values are high compared to the empiri-cal rates of word boundaries in the true segmen-tation of the input corpus.
For example, the true rate of utterance-internal word boundaries is around 30% at the phoneme level, yet the opti-mal p# value for phoneme bigrams is around 60%.
The reason for this is that our generative model, like that of a number of previous models discussed in the literature (Brent, 1999; Venkata-raman, 2001; Goldwater et al., 2009), has an in-herent undersegmentation bias.
Due to the way the phonotactic models are defined, there is a cost for every additional word boundary posited in the segmentation.
This is because positing a boundary corresponds to the generation of an additional symbol, #, which otherwise does not have to be generated.
Since generating a # is never done with 100% probability, doing so al-25ways incurs a cost relative to a segmentation where no such # has to be generated.
The high optimal settings of the p#  parameter reflect this inherent bias and enable the estimation procedure to compensate not only for the underrepresenta-tion of word boundaries in the input but also for this bias in the generative model.
6 Conclusions We compared segmentation models that rely on phoneme transitions to models that make use of syllable structure.
The results indicate that sylla-ble-based statistics are valuable for segmenta-tion.
We also showed that it is possible to utilize this structure successfully with limited prior knowledge of the target language by using a simple syllabification strategy inferred from un-segmented utterances.
The performance of the syllable-based models also demonstrates that it is possible to achieve good segmentation results without the use of a lexicon.
Another contribu-tion of this work is a novel estimation procedure that addresses some challenges of unsupervised segmentation.
We showed that adjusting parame-ter estimates inferred from unsegmented input is essential for achieving good performance.
The strong performance of the syllable level bigram phonotactic model has a number of im-plications.
First, it demonstrates that the kind of statistical regularities that infants have been con-sistently shown to be sensitive to in artificial ex-perimental stimuli do provide a substantial amount of information about word boundaries in natural language data, at least in English.
This lends significant credibility to the claim that sen-sitivity to such statistical regularities plays a cru-cial role in infants?
early language development (contra Yang 2004).
This result also highlights the role that sensitivity to richer phonological information, beyond the level of phonemes, plays in language learning, a result that is echoed in much recent work on the modeling of phonotac-tic well-formedness of isolated words (Hayes & Wilson, 2008; Albright, 2009; Daland et al., 2011).
A consistent finding of this work has been that access to abstract structure and robust gener-alization mechanisms is crucial to the modeling of human phonotactic knowledge.
While our re-sults are compatible with these conclusions, our results cannot confirm that it is syllable structure per se that improves segmentation since the syl-lable-based models have several co-occurring advantages.
In addition to abstract structure, they can track longer and more complex dependen-cies.
Nonetheless, these results motivate further investigation into the role that richer models of phonotactics may play in word segmentation and into the precise mechanisms responsible for im-proved segmentation using syllable structure.
Particularly critical is exploration of phonotacti-cally-based segmentation models for languages besides English, for which phonotactic cues hold significant promise (Jarosz & Johnson, 2013) given the relatively low performance of state-of-the-art lexicon-building models (Johnson 2008b).
Another important direction for future work is investigating how early, phonotactically-based segmentation interacts with subsequent learning of higher-level structure, including the lexicon.
Johnson (2008a) and Johnson & Goldwater (2009) have already demonstrated that syllable structure provides valuable information in this context; however, their models relied on very different syllable regularities than those investi-gated here, and the consequences of these differ-ences should be explored in future work.
Goldwater et al.
(2009) showed that a number of proposed segmentation models have an under-segmentation bias that can be avoided by simul-taneously modeling statistical dependencies be-tween words.
They proposed a Bayesian prior to favor a smaller lexicon and showed that other-wise unigram models introduce a severe under-segmentation bias due to the possibility of matching empirical probabilities by memorizing utterances as words.
Note that the same is not true of syllable-based models since the hypothe-sis space does not permit memorization of utter-ances, and the size of the syllable inventory, un-like a lexicon, remains relatively stable under different segmentations.
Thus, the syllable-based models are not subject to the same kind of under-segmentation bias.
Interestingly, the syllable bi-gram model surpasses the performance of the word bigram model proposed by Goldwater et al.
(word token f-score 72.3) given sufficient com-pensation for its undersegmentation bias.
How-ever, this level of performance requires adjust-ment of the p# parameter to compensate for the cost of generating additional boundaries.
Alt-hough parameters are common in computational models (for example, Goldwater et al.
used a p# parameter to modulate the prior distributions in their Bayesian models), they do not provide a particularly satisfying explanation for why in-fants are compelled to break up the speech stream into smaller units (words).
Further work is needed to determine how undersegmentation biases are ultimately overcome by children.26References Adriaans, Frans and Kager, Ren?.
2010.
Adding gen-eralization to statistical learning: The induction of phonotactics from continuous speech.
Journal of Memory and Language 62(3): 311-331.
Albright, Adam.
2009.
Feature-based generalisation as a source of gradient acceptability.
Phonology, 26(1): 9-41.
Aslin, Richard N., Saffran, Jenny R., & Newport, Elissa L. 1998.
Computation of conditional proba-bility statistics by 8-month-old infants.
Psychologi-cal Science, 9, 321-324.
Bernstein-Ratner, Nan.
1987.
The phonology of par-ent child speech.
Children?s Language, 6: 159-174.
Blanchard, Daniel and Heinz, Jeffrey.
2008.
Improv-ing word segmentation by simultaneously learning phonotactics.
In Conll ?08: Proceedings of the 12th Conference on Computational Natural Language Learning.
Stroudsburg, PA: Association for Com-putational Linguistics.
Blanchard, Daniel, Heinz, Jeffrey and Golinkoff, Roberta.
2010.
Modeling the contribution of pho-notactic cues to the problem of word segmentation.
Journal of Child Language, 37(3): 487-511.
Brent, Michael R. 1999.
An efficient, probabilistically sound algorithm for segmentation and word dis-covery.
Machine Learning, 34(1-3): 71-105.
Daland, Robert and Pierrehumbert, Janet B.
2011.
Learning Diphone-Based Segmentation.
Cognitive science, 35(1).
Wiley Online Library.
119?155.
Daland, Robert, Hayes, Bruce, White, James, Garellek, Marc, Davis, Andrea and Norrmann, In-grid.
2011.
Explaining sonority projection effects.
Phonology, 28(2): 197-234.
Dale, P. S., & Fenson, L. 1996.
Lexical development norms for young children.
Behavior Research Methods, Instruments, & Computers, 28, 125-127.
Goldwater, Sharon, Griffiths, Thomas L. and Johnson, Mark.
2009.
A Bayesian framework for word seg-mentation: Exploring the effects of context.
Cogni-tion, 112(1): 21-54.
Hayes, Bruce & Wilson, Colin.
2008.
A maximum entropy model of phonotactics and phonotactic learning.
Linguistic Inquiry, 39(3): 379-440.
Hockema, Stephen A.
2006.
Finding Words in Speech: An Investigation of American English.
Language Learning and Development, 2(2).
Psy-chology Press.
119-146.
Jarosz, Gaja and Johnson, J. Alex.
2013.
The Rich-ness of Distributional Cues to Word Boundaries in Speech to Young Children.
Language Learning and Development, 9(2): 175-210.Johnson, Mark.
2008a.
Using adaptor grammars to identify synergies in the unsupervised acquisition of linguistic structure.
Proceedings of the 46th An-nual Meeting of the Association for Computational Linguistics.
Association for Computational Lin-guistics.
Johnson, Mark.
2008b.
Unsupervised Word Segmen-tation for Sesotho Using Adaptor Grammars.
Pro-ceedings of the 10th Meeting of ACL SIGMOR-PHON.
Columbus, OH: Association of Computa-tional Linguistics.
Johnson, Mark & Goldwater, Sharon.
2009.
Improv-ing nonparametric Bayesian inference: Experi-ments on unsupervised word segmentation with adaptor grammars.
In NAACL ?09: Proceedings of the Annual Conference of the North American Chapter of the Association for Computational Lin-guistics.
Boulder, CO: Association for Computa-tional Linguistics.
Jurafsky, Daniel & Martin, James H. 2008.
Speech and language processing, 2nd edition.
Upper Sad-dle River, NJ: Prentice-Hall.
Jusczyk, Peter W. & Luce, Paul A.
1994.
Infants?
Sensitivity to Phonotactic Patterns in the Native Language.
Journal of Memory and Language, 33(5): 630-645.
Lignos, Constantine and Yang, Charles.
2010.
Reces-sion Segmentation: Simpler Online Word Segmen-tation Using Limited Resources.
Proceedings of the Fourteenth Conference on Computational Nat-ural Language Learning.
(CoNLL '10).
Associa-tion for Computational Linguistics.
.
Mattys, Sven L. and Jusczyk, Peter W. 2000.
Phono-tactic cues for segmentation of fluent speech by in-fants.
Cognition, 78(2): 91-121.
Mattys, Sven L., Jusczyk, Peter W., Luce, Paul A., and Morgan, James L. 1999.
Phonotactic and pro-sodic effects on word segmentation in infants.
Cognitive psychology, 38(4): 465-494.
Newport, Elissa L. and Aslin, Richard N. 2004.
Learning at a distance I.
Statistical learning of non-adjacent dependencies.
Cognitive psychology, 48(2): 127-162.
Pelucchi, Bruna, Hay, Jessica F., and Saffran, Jenny R. 2009.
Learning in reverse: Eight-month-old in-fants track backward transitional probabilities.
Cognition, 113(2): 244-247.
Saffran, Jenny R., Aslin, Richard N., and Newport, Elissa L. 1996.
Statistical learning by 8-month-old infants.
Science, 274(5294): 1926-1928.
Swingley, Daniel.
2005.
Statistical clustering and the contents of the infant vocabulary.
Cognitive Psy-chology, 50(1): 86-32.27Thiessen, Erik D. and Saffran, Jenny R. 2003.
When cues collide: use of stress and statistical cues to word boundaries by 7-to 9-month-old infants.
De-velopmental psychology, 39(4): 706.
Venkataraman, Anand 2001.
A statistical model for word discovery in transcribed speech.
Computa-tional Linguistics, 27(3): 352-372.
Yang, Charles D. 2004.
Universal Grammar, statistics or both?
Trends in Cognitive Sciences, 8(10): 451-456.28
