Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics ?
Student Research Workshop, pages 86?92,Berlin, Germany, August 7-12, 2016.c?2016 Association for Computational LinguisticsImproving Dependency Parsing Using Sentence Clause ChartsVincent Kr??
?z and Barbora Hladk?aCharles UniversityFaculty of Mathematics and PhysicsInstitute of Formal and Applied Linguistics{kriz, hladka}@ufal.mff.cuni.czAbstractWe propose a method for improving thedependency parsing of complex sentences.This method assumes segmentation of in-put sentences into clauses and does not re-quire to re-train a parser of one?s choice.We represent a sentence clause structureusing clause charts that provide a layer ofembedding for each clause in the sentence.Then we formulate a parsing strategy asa two-stage process where (i) coordinatedand subordinated clauses of the sentenceare parsed separately with respect to thesentence clause chart and (ii) their depen-dency trees become subtrees of the finaltree of the sentence.
The object languageis Czech and the parser used is a maximumspanning tree parser trained on the PragueDependency Treebank.
We have achievedan average 0.97% improvement in the un-labeled attachment score.
Although themethod has been designed for the depen-dency parsing of Czech, it is useful forother parsing techniques and languages.1 IntroductionSyntactic parsing is an integral part of a complextext processing pipeline whose quality impacts theoverall performance of the text processing system.For illustration, we share our experience witha system focused on extracting semantic relationsfrom unstructured texts.
Namely, we have de-veloped the RExtractor system,1which processestexts by linguistically-aware tools and extracts en-tities and relations using queries over dependencytrees.
The language used for testing RExtrac-tor was Czech and the legal domain was chosen1The system is available on-line athttp://quest.ms.mff.cuni.cz:14280/to be explored in detail (Kr??
?z et al, 2014; Kr??
?zand Hladk?a, 2015).
We evaluated RExtractor onthe Czech Legal Text Treebank (CLTT) enrichedwith manually annotated entities and their rela-tions (Kr??
?z et al, 2016).
Because of the lackof any Czech gold legal-domain treebank, weused a parser trained on newspaper texts to parseCLTT.
The RExtractor system achieved precisionof 80.6% and recall of 63.2% and we identifiedthree sources of errors: (i) incorrect dependencytree (59.7%), (ii) missing or incorrectly formu-lated extraction query (38.3%), (iii) missing or in-correctly recognized entity (2.1%).One can see that the errors are caused mainlyby the insufficient quality of dependency parsing.The main reason why it happens is that newspa-per texts differ from legal texts in several languagephenomena influenced by the high frequency ofvery long sentences in legal texts.
Figure 1 pro-vides evidence of difficulty with dependency pars-ing long sentences ?
as the sentence length in-creases, the unlabeled attachment score decreases.The numbers are provided for two Czech depen-dency treebanks, namely the Prague DependencyTreebank with the development and evaluationtest subsets2(PDT, dtest, etest, resp.)
and theCzech Academic Corpus (CAC)3, see Bej?cek et al(2013) and Hladk?a et al (2008), resp.This paper describes our method how to useinformation about a sentence clause structure infull-scale dependency parsing.
Section 2 lists anumber of previous approaches to improve depen-dency parsing including selected works on pars-ing Czech.
The data and tools used in our experi-ments are summarized in Section 3.
We representsentence clause structures using clause charts de-fined and quantitatively studied in Section 4.
In2https://ufal.mff.cuni.cz/pdt3.03https://ufal.mff.cuni.cz/cac861-10 11-20 21-30 31-40 41-50 51+70.00%75.00%80.00%85.00%90.00%95.00%PDT dtestPDT etestCACSentence lengthUASFigure 1: The longer the sentence the lower the un-labeled attachment score.
The figures come fromexperiments run on the Prague Dependency Tree-bank and the Czech Academic Corpus.Section 5, we propose an original strategy to parsepairs of coordinated and subordinated clauses andapply it on the data.
Section 6 outlines our futureplans towards better parsing long sentences.2 Related WorkSeveral approaches which deal with the idea of di-viding the parsing process into several parts werepresented.
The idea of cascaded parsing exploitsa cascade of specialized parsers instead of havingone very complex general parser (Abney, 1996;Ciravegna and Lavelli, 1999).
The identificationof chunks, syntactically related non-overlappinggroups of words (Tjong Kim Sang and Buchholz,2000), was used mainly in shallow parsing strate-gies (Federici et al, 1996).
Clausal parsing wasdesigned to parse Hindi texts (Husain et al, 2011).However, there is no work on exploiting chunksfor full-scale parsing.
A very interesting approachdividing the parsing process into several parts hasbeen introduced in the XDG theory (Debusmannet al, 2005).
Most recent approaches to depen-dency parsing focus almost exclusively on im-proving full-scale parsing algorithms using mostlyneural networks (Pei et al, 2015; Weiss et al,2015; Zhu et al, 2015).We address the issue of parsing sentences thatare already segmented into clauses.
The ideas andconcepts of segmentation of Czech sentences arepresented by Kubo?n (2001), Kubo?n et al (2007),and Lopatkov?a and Holan (2009).
They presentthe concept of segments and show that it is possi-ble to draw the segmentation charts which reflectthe mutual position of segments in complex sen-tences without applying syntactic parsing of thewhole sentence first.
The method is based on theidentification of separators (segment boundaries)and their classification.Lopatkov?a et al (2012) show how clauses form-ing complex sentences can be identified based onthe sentence segment annotation.
In addition, theypresent the project aiming at building a collectionof Czech sentences enriched with manually anno-tated clauses and their relationships.
Kr?uza andKubo?n (2014) use this collection to develop anautomatic procedure for recognizing clauses andtheir mutual relationship.
Another automatic pro-cedure for clause identification over dependencytrees is introduced by Bej?cek et al (2013) achievedF-measure 97.51% and was used for the clause an-notation of the Prague Dependency Treebank.3 Data and ToolsWe experimented with two manually annotateddependency treebanks, namely the Prague Depen-dency Treebank 3.0 (PDT 3.0) and the Czech Aca-demic Corpus 2.0 (CAC 2.0).
Both corpora areenriched with the clause annotation done automat-ically using the procedure presented by Bej?cek etal.
(2013).Our goal is to beat the MST dependencyparser (McDonald et al, 2005) trained on the PDT3.0 train set.
Table 1 presents basic characteristicsof the two treebanks and the MST parser perfor-mance on them.Treebank Split Sent.
Tokens UAStrain 29,768 518,648 93.41PDT 3.0 dtest 4,042 70,974 84.50etest 4,672 80,923 84.32CAC 2.0 ?
24,709 493,306 82.68Table 1: Part of the treebank (Split), the number ofsentences (Sent.
), the number of tokens (Tokens)and the unlabeled attachment score (UAS) of MST.4 Clause ChartsA clause chart is defined to visualize relationshipsbetween clauses within the sentence and capturesthe layer of embedding of each individual clause.It is an m ?
n table where n is the number ofclauses in the sentence and m is the number of87layers.
A cell (i, j) stands for relationship betweenthe j-th clause and the i-th layer of embedding.
Itsvalue is initialized to the value of 0 correspondingto no relationship.We defined four rules for changing the cellvalue from 0 to 1, i.e., for assigning a layer ofembedding to each clause in the sentence: (1) Allmain clauses belong to the basic layer 0.
(2) Theclauses that depend on the clauses at the k-th layerbelong to the (k+1)-th layer.
(3) The coordinatedclauses and the clauses in apposition belong to thesame layer.
(4) The clauses in parentheses belongto the (k+1)-th layer with respect to the k-th layerof their adjacent clauses.Our definition is analogous to a segmentationchart defined by Lopatkov?a and Holan (2009).However, we handle the following situations dif-ferently: (1) subordinating conjunctions at the be-ginning of each clause are considered as bound-aries and are excluded from the clause; (2) clausessplit into two parts by an embedded subordinatedclause are considered as two different clauses.4.1 Generating Clause ChartsWe designed a simple procedure that generatesa clause chart from a dependency tree with theclause annotation.
Particularly, it generates aclause tree first and then a clause chart.We assume a dependency tree where each non-boundary node has a special attribute bearing theidentification of the clause it belongs to.
Thenodes with the same clause number belong to thesame clause and thus generating a clause chart isuniquely determined by the clause identification.A layer of embedding of the clause is defined asits depth in a sentence clause tree where its nodescontain tokens with the same clause identification.Figure 2 displays both the clause tree and theclause chart of the sample sentence presented in(Kubo?n et al, 2007):While failure is usually an orphan,the success tends to have many fathers,claiming eagerly that particularly theywere present at its conception.This sentence consists of four clauses delimitedby the boundaries printed in bold, namely while,that, and two commas.
In general, clause bound-aries are either a single token or a sequence oftokens.
Clause boundaries are not componentsof the clause tree.
They are displayed there for1-02345+07+373-22.+-%+849P-%DP5+73TT577+D5% 7+D8+P-d5+t-%.+1-DP547T2-0t0%e+5-e542.9-4D0T32-42.+DP5.+s545+94575%D+-D+0D7+T8%T59D08%sP025 C CDP-DB   1   B   0   B   1   B   2ASAnnclFigure 2: Clause tree (above), clause chart and itslinear representation (below).understanding a linear representation of a clausechart, see B1B0B1B2 where B stands for a clauseboundary and the numbers are the layers of clauseembedding.4.2 Exploring Clause ChartsWe explored PDT 3.0 and CAC 2.0 to study dif-ferent types of clause charts.
Table 2 providesstatistics for the five most frequent clause chartsthat occur in the treebanks.
For example, 14.4%of the sentences in PDT 3.0 and CAC 2.0 con-tain a main clause and a subordinated clause de-scribed with the 0B1 pattern.
Moreover, we mea-sure the MST parser performance on the sentenceshaving the given clause charts.
For example, MSTachieved UAS of 92.9% on the 0B1B0 sentencesin the PDT training data set.The texts in the treebanks come from newspa-pers.
Thus there is no surprise that the most fre-quent sentences in the treebanks are simple oneclause sentences (0).
They present more than halfof the data.
The second most frequent sentencestructure consists of one main clause and one sub-ordinated clause (0B1).
It is quite surprising thatthe parser processes these sentences better than theone clause sentences.
Even more, we observe de-crease in the parser performance on coordinationof two main clauses (i.e., on the 0B0 sentence).For curiosity?s sake, the most complex sentence88in the treebanks consists of 36 clauses and the0B1B2B3B4B5B6 clause chart is a chart with thehighest number of layers of embedding.0 0B10B00B1B00B1B2Rel.
freq.
50.1 14.5 8.0 3.6 2.5PDT train 93.6 95.8 92.9 92.9 95.9PDT dtest 85.7 88.2 82.3 81.7 90.0PDT etest 85.4 88.0 83.4 82.0 88.1CAC 2.0 84.1 85.7 81.0 79.7 87.3Table 2: Relative frequency of the five most fre-quent clause charts in PDT 3.0 and CAC 2.0 (Rel.freq.)
and the unlabeled attachment score of MSTevaluated on the particular subsets PDT train, PDTdtest, PDT etest, CAC 2.0.5 Methods and ExperimentsWe present a method for improving dependencyparsing of long sentences.
In particular, we formu-late an algorithm for parsing the two most frequentclause structures, namely coordinated clauses 0B0and governing and dependent clauses 0B1.
Theother types of clause structures are processed asusual using full-scale parsing.
The experimentsexploit an existing dependency parser trained oncomplete sentences, namely the MST parser ?
seeSection 3 for details.5.1 Parsing Coordinated ClausesGiven the clause chart representation, we canrecognize coordinated clauses in sentences in astraightforward way.
Thus, we consider neighbor-ing coordinated clauses C1, C2, .
.
.
, Cnon thesame layer (n > 1) and we propose the followingparsing strategy that we call clause chart parsing(CCP):1.
Using MST parse C1, C2, .
.
.
, Cnindividu-ally to get dependency trees T1, T2, .
.
.
, Tnwith the r1, r2, .
.
.
, rnroot nodes, respec-tively.2.
Create a sequence S = r1B1,2r2B2,3.
.
.
rnwhere Bi,i+1is a boundary between CiandCi+1.3.
Using MST parse the sequence S to get a de-pendency tree TS.4.
Build a final dependency tree so that the treesT1, .
.
.
, Tnbecome subtree of TS.For illustration, we assume the sentence Johnloves Mary and Linda hates Peter.
The sentenceconsists of two coordinated clauses C1= {Johnloves Mary}, C2= {Linda hates Peter} and oneclause boundary B1,2= {and}.
Therefore, theclause chart of the sentence is 0B0.
In Step 1,C1and C2are parsed to get T1and T2with theroot nodes r1= loves and r2= hates, resp.
In Step2, the sequence S = loves and hates is created.
InStep 3, S is parsed to get TSand, finally, in Step4, T1and T2become subtrees of TS.We evaluated the proposed parsing strategy onlyon the sentences having the 0B0 clause chart, i.e.,on the subsets of the treebank datasets.
Table 3presents the unlabeled attachment score achievedfor?
full-scale parsing, i.e., parsing complete sen-tences using MST (FS)?
parsing individual clauses instead of parsingcomplete sentences, i.e., MST performance ismeasured on individual clauses (Clauses)?
full-scale parsing using the CCP strategyWe observe that parsing performance measuredon complete sentences is the highest when pars-ing individual clauses.
Using the CCP method weachieved an average 1.36% improvement in UAS.Data Sent.
FS Clauses CCPPDT dtest 319 82.28 86.87 84.80PDT etest 352 83.43 87.16 84.67CAC 2.0 2,272 80.96 84.69 82.34Table 3: Parsing evaluation on the 0B0 sen-tences of three different parsing strategies: full-scale parsing (FS) using MST, parsing individ-ual clauses (Clauses), and full-scale parsing usingCCP (CCP).5.2 Parsing governing and dependent clausesTable 4 presents the unlabeled attachment scoreachieved for full-scale parsing and parsing indi-vidual clauses.We observe almost no improvement when pars-ing individual clauses.
Also, we observe that theparser performance on the 0B1 sentences is signif-icantly higher than the parser performance on the89Data Sent.
FS ClausesPDT dtest 604 88.24 88.23PDT etest 704 87.98 88.64CAC 2.0 3,669 85.68 85.76Table 4: Parsing evaluation on the 0B1 sentences.whole datasets, compare the FS column in Table 4and the UAS column in Table 1.Given this observation, we proposed the follow-ing strategy for parsing subordinated clauses andwe updated the CCP method as follows:1.
Find the longest sequence of neighboringsubordinated clauses C1, C2, .
.
.
, Cnso thatlayer(Ci+1) = layer(Ci) + 1 where layerstands for a layer of embedding in a clausechart.2.
Create a sequence S = C1B1,2C2B2,3.
.
.Cnwhere Bi,i+1is a boundary between CiandCi+1.3.
Using MST parse sequence S to get a depen-dency tree TS.Using the CCP strategy for parsing the 0B0and 0B1 sentences, we can parse the 0B1B0 sen-tences so that we apply the CCP strategy for sub-ordinated clauses first and subsequently for coor-dinated clauses.
Table 5 presents the comparisonof full-scale parsing and CCP.Data Sent.
FS CCPPDT dtest 166 81.72 82.98PDT etest 160 81.98 84.22CAC 2.0 885 79.68 80.84Table 5: Parsing evaluation on the 0B1B0 sen-tences.5.3 CCP as Full-scale ParsingWe have learned from the experiments that1.
it is efficient to parse coordinated clausesindividually and connect their trees subse-quently;2. it is effective to parse a sequence of govern-ing and dependent clauses at once.Therefore we proposed and evaluated a final al-gorithm for dependency parsing that exploits sen-tence clause charts and a given dependency parser.The algorithm works in iterations.
In each itera-tion, at least one layer of embedding in the clausechart is eliminated using the CCP strategy for 0B0and 0B1 clauses.Table 6 and Table 7 present the final comparisonof full-scale parsing and the CCP strategy.
Thefigures in Table 6 exclude simple sentences (one-clause sentences) from evaluation.
We achieved anaverage 0.97% improvement in UAS when parsingall the sentences in the treebanks.Data Sent.
FS CCPPDT dtest 2,044 83.93 84.72PDT etest 2,339 83.84 84.64CAC 2.0 12,756 81.99 83.42Table 6: Parsing evaluation on the sentences con-taining at least two clauses.Data Sent.
FS CCPPDT dtest 4,042 84.50 85.03PDT etest 4,672 84.32 84.87CAC 2.0 24,709 82.68 83.64Table 7: Final comparison of full-scale parsingand CCP.6 Future WorkOur motivation to address the task of parsing oflong sentences arises from a project of extractingentities and relations from legal texts.
We plan toapply the CCP strategy on the Czech Legal TextTreebank that contains significantly large numberof long sentences than PDT 3.0.
Consequently, wewill do an eccentric evaluation of the RExtractorsystem to see whether better parsing results influ-ence the extraction.A sentence clause structure used in our exper-iments was generated automatically.
However,the used procedure requires gold standard depen-dency trees on the input.
We plan to developan automatic procedure for obtaining the clausecharts.
This procedure will not require gold stan-dard dependency trees on the input.
Some ex-periments have been already done by Kr?uza andKubo?n (2009).
In addition, we see several differ-90ent approaches which could be implemented andevaluated.In the presented experiments, we used theparser trained on complete sentences.
However,the CCP strategy parses individual clauses in somesituations.
We believe that training a new modelespecially for clauses will bring a significant im-provement.
Another model could be trained forparsing sequences defined in Step 3 of proposedalgorithm from Section 5.1.Our parsing strategy is formulated to be lan-guage independent.
The English part of theCzech-English Prague Dependency Treebank con-tains the entire Penn Treebank that is enhancedwith segmentation of sentences into clauses.4Weplan to apply the CCP strategy on this dataset.7 ConclusionIn our pilot experiments, we showed that sentenceclause charts improve dependency parsing of longsentences.
We proposed a method that assumessegmentation of input sentences into clauses.
Hav-ing such annotation at hand, we represent sentenceclause structure using a clause chart that providesa layer of embedding for each clause in the sen-tence.Our parsing strategy does not need to re-train aparser of one?s choice.
Instead of that, we sepa-rately parse coordinated and subordinated clauseswith respect to the sentence clause chart and thenconnect their dependency trees.The object language of our experiments isCzech and the parser used is a maximum span-ning tree parser trained on the Prague DependencyTreebank.
We achieved an average 0.97% im-provement in the unlabeled attachment score.AcknowledgmentsWe gratefully acknowledge support from the SVVproject No.
SVV 260 333 and from the LIN-DAT/CLARIN Research Infrastructure project ofthe Ministry of Education, Youth and Sports ofthe Czech Republic No.
LM2015071.
This workhas also been using language resources developedand distributed by the LINDAT/CLARIN project.We thank three anonymous reviewers for their use-ful comments and remarks and we truly appreciatesuggestions provided by Kemal Oflazer.4http://ufal.mff.cuni.cz/pcedt2.0/en/ReferencesSteven Abney.
1996.
Partial Parsing via Finite-State Cascades.
Natural Language Engineering,2(04):337?344.Eduard Bej?cek, Eva Haji?cov?a, Jan Haji?c, Pavl??naJ?
?nov?a, V?aclava Kettnerov?a, Veronika Kol?a?rov?a,Marie Mikulov?a, Ji?r??
M?
?rovsk?y, Anna Nedoluzhko,Jarmila Panevov?a, Lucie Pol?akov?a, Magda?Sev?c?
?kov?a, Jan?St?ep?anek, and?S?arka Zik?anov?a.2013.
Prague Dependency Treebank 3.0.http://ufal.mff.cuni.cz/pdt3.0.Fabio Ciravegna and Alberto Lavelli.
1999.
FullText Parsing Using Cascades of Rules: An Informa-tion Extraction Perspective.
In Proceedings of theNinth Conference on European Chapter of the As-sociation for Computational Linguistics, EACL ?99,pages 102?109, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.Ralph Debusmann, Denys Duchier, and Andreas Ross-berg.
2005.
Modular Grammar Design with TypedParametric Principles.
Proceedings of FG-MOL2005.Stefano Federici, Simonetta Montemagni, and Vito Pir-relli.
1996.
Shallow Parsing and Text Chunking:a View on Underspecification in Syntax.
Cogni-tive Science Research Paper - University of SussexCSRP, pages 35?44.Barbora Vidov?a Hladk?a, Jan Haji?c, Ji?r??
Hana, JaroslavaHlav?a?cov?a, Ji?r??
M?
?rovsk?y, and Jan Raab.
2008.
TheCzech Academic Corpus 2.0 Guide.
The PragueBulletin of Mathematical Linguistics, (89):41?96.Samar Husain, Phani Gadde, Joakim Nivre, and RajeevSangal.
2011.
Clausal parsing helps data-drivendependency parsing: Experiments with Hindi.
InPProceedings of the 5th International Joint Con-ference on Natural Language Processing, page1279?1287, Chiang Mai, Thailand.Vincent Kr??
?z and Barbora Hladk?a.
2015.
RExtrac-tor: a Robust Information Extractor.
In Matt Gerber,Catherine Havasi, and Finley Lacatusu, editors, Pro-ceedings of the 2015 Conference of the North Amer-ican Chapter of the Association for ComputationalLinguistics: Demonstrations, pages 21?25, Denver,CO, USA.
Association for Computational Linguis-tics.Vincent Kr??
?z, Barbora Hladk?a, Martin Ne?cask?y, andTom?a?s Knap.
2014.
Data Extraction Using NLPTechniques and Its Transformation to Linked Data.In Human-Inspired Computing and Its Applications- 13th Mexican International Conference on Arti-ficial Intelligence, MICAI 2014, Tuxtla Guti?errez,Mexico, November 16-22, 2014.
Proceedings, PartI, pages 113?124.Old?rich Kr?uza and Vladislav Kubo?n.
2009.
Au-tomatic Extraction of Clause Relationships from a91Treebank.
In Alexander Gelbukh, editor, Compu-tational Linguistics and Intelligent Text Processing.10th International Conference, CICLing 2009, Mex-ico City, Mexico, March 1-7, 2009, Proceedings,volume 5449 of Lecture Notes in Computer Science,pages 195?206, Berlin / Heidelberg.
Springer.Old?rich Kr?uza and Vladislav Kubo?n.
2014.
Auto-matic Recognition of Clauses.
International Jour-nal of Computational Linguistics and Applications,5(1):125?138.Vincent Kr??
?z, Barbora Hladk?a, and Zde?nka Ure?sov?a.2016.
Czech Legal Text Treebank 1.0.
In Nico-letta Calzolari (Conference Chair), Khalid Choukri,Thierry Declerck, Marko Grobelnik, Bente Mae-gaard, Joseph Mariani, Asuncion Moreno, JanOdijk, and Stelios Piperidis, editors, Proceedings ofthe Tenth International Conference on Language Re-sources and Evaluation (LREC 2016), Paris, France,may.
European Language Resources Association(ELRA).Vladislav Kubo?n, Mark?eta Lopatkov?a, Martin Pl?atek,and Patrice Pognan.
2007.
A Linguistically-BasedSegmentation of Complex Sentences.
In David Wil-son and Geoffrey Sutcliffe, editors, Proceedings ofFLAIRS 2007 (20th International Florida ArtificialIntelligence Research Society Conference), pages368?373, Key West, FL, USA.
AAAI Press.Vladislav Kubo?n.
2001.
Problems of Robust Pars-ing of Czech.
Ph.D. thesis, Faculty of Mathematicsand Physics, Charles University in Prague, Prague,Czech Republic.Mark?eta Lopatkov?a and Tom?a?s Holan.
2009.
Seg-mentation Charts for Czech ?
Relations among Seg-ments in Complex Sentences.
In Adrian Dediu,Armand Ionescu, and Carlos Mart?
?n-Vide, editors,Language and Automata Theory and Applications.Third International Conference, LATA 2009, Tarrag-ona, Spain, April 2-8, 2009.
Proceedings, volume5457 of Lecture Notes in Computer Science, pages542?553, Berlin / Heidelberg.
Universitat Rovira iVirgili, Springer.Mark?eta Lopatkov?a, Petr Homola, and NataliaKlyueva.
2012.
Annotation of Sentence Struc-ture: Capturing the Relationship between Clauses inCzech Sentences.
Language Resources and Evalua-tion, 46(1):25?36.Ryan McDonald, Fernando Pereira, Kiril Ribarov, andJan Haji?c.
2005.
Non-Projective Dependency Pars-ing using Spanning Tree Algorithms.
In Proceed-ings of Human Language Technology Conferenceand Conference on Empirical Methods in NaturalLanguage Processing, pages 523?530, Vancouver,BC, Canada.
Association for Computational Lin-guistics.Wenzhe Pei, Tao Ge, and Baobao Chang.
2015.
An Ef-fective Neural Network Model for Graph-based De-pendency Parsing.
In Proceedings of the 53rd An-nual Meeting of the Association for ComputationalLinguistics and the 7th International Joint Confer-ence on Natural Language Processing (Volume 1:Long Papers), pages 313?322, Beijing, China, July.Association for Computational Linguistics.Erik F. Tjong Kim Sang and Sabine Buchholz.
2000.Introduction to the CoNLL-2000 Shared Task:Chunking.
In Proceedings of the 2nd Workshopon Learning Language in Logic and the 4th Con-ference on Computational Natural Language Learn-ing - Volume 7, CoNLL?00, pages 127?132, Strouds-burg, PA, USA.
Association for Computational Lin-guistics.David Weiss, Chris Alberti, Michael Collins, and SlavPetrov.
2015.
Structured Training for Neural Net-work Transition-Based Parsing.
In Proceedings ofthe 53rd Annual Meeting of the Association forComputational Linguistics and the 7th InternationalJoint Conference on Natural Language Processing(Volume 1: Long Papers), pages 323?333, Beijing,China, July.
Association for Computational Linguis-tics.Chenxi Zhu, Xipeng Qiu, Xinchi Chen, and XuanjingHuang.
2015.
A Re-ranking Model for Depen-dency Parser with Recursive Convolutional NeuralNetwork.
In Proceedings of the 53rd Annual Meet-ing of the Association for Computational Linguisticsand the 7th International Joint Conference on Natu-ral Language Processing (Volume 1: Long Papers),pages 1159?1168, Beijing, China, July.
Associationfor Computational Linguistics.92
