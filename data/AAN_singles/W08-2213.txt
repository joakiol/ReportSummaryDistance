Analysis of ASLMotion Capture Datatowards Identification ofVerb TypeEvguenia MalaiaJohn BornemanRonnie B. WilburPurdue University (USA)email: emalaya@purdue.eduAbstractThis paper provides a preliminary analysis of American Sign Languagepredicate motion signatures, obtained using a motion capture system, to-ward identification of a predicate?s event structure as telic or atelic.
Thepilot data demonstrates that production differences between signed pred-icates can be used to model the probabilities of a predicate belonging totelic or atelic classes based on their motion signature in 3D, using eithermaximal velocity achieved within the sign, or maximal velocity and mini-mal acceleration data from each predicate.
The solution to the problem ofcomputationally identifying predicate types in ASL video data could sig-nificantly simplify the task of identifying verbal complements, argumentsand modifiers, which compose the rest of the sentence, and ultimatelycontribute to solving the problem of automatic ASL recognition.155156 Malaia, Borneman, and Wilbur1 IntroductionIn recent work, we have provided preliminary data indicating that there is a significantdifference in the motion signatures of lexical predicate signs that denote telic and atelicevents (Wilbur and Malaia, 2008b,c,a; Malaia et al, 2008).
These results are empiri-cal evidence for direct mapping between sign language (ASL) phonology/kinematics,and semantic decomposition of predicates (the Event Visibility Hypothesis, or EVH(Wilbur, 2003, 2009)).
The present paper reviews this analysis of ASL predicate 3Dmotion signatures and considers further application of such data for computationalprocessing of ASL video streams, and automatic recognition of predicate type basedon 2D motion signatures.
Particular attention is paid to the contribution of the slopeof deceleration at the end of signs, and to the values of the maximum velocity andminimum acceleration achieved during the sign motion.
The focus of the study onpredicates is determined by the fact that each sentence or clause in natural languagesis built around a predicate.
Thus, a solution to the problem of identifying predicatetypes could significantly simplify the task of identifying verbal complements, argu-ments and modifiers, which compose the rest of the sentence.2 Modeling events in ASLLinguistic theory of verbal types has long observed universal correspondences be-tween verbalmeaning and syntactic behavior, including adverbialmodification (Tenny,2000), aspectual coercion (Smith, 1991), and argument structure alternations (Levin,1993; Ramchand, 2008).
Vendler (1967) proposed a system of four basic syntac-tically relevant semantic types of predicates: atelic States and Activities, and telicAchievements and Accomplishments.
The telic/atelic distinction is most clearly ana-lyzed in terms of the internal structure of events.
?Telic?
is understood as the propertyof linguistic predicates (events) containing a conceptual (semantic) endpoint.
In con-trast, ?atelic?
events do not contain such a point and have the potential to continueindefinitely.
Atelic events are homogenous, in that they may be divided into iden-tical intervals, each of which is an instance of the event itself, i.e.
?walking?
as aninstance of ?walking?.
Telic events are composed of at least two sub-events, one ofwhich is the final state, and are therefore heterogeneous (cannot be divided into iden-tical intervals).
The model was further developed by Pustejovsky (1991), with theprimary distinction between static sub-event type S(tate) and dynamic sub-event typeP(rocess).
Telic events with transitions to the final state were modeled as combinationsof non-identical sub-events (Table 1).Table 1: Pustejovsky?s predicate typologyPredicate type DefinitionActivity PState SAccomplishment P?
SAchievement S?
SMost recently, Ramchand (2008) has taken an event as the basis for hierarchicalcomposition of phrases that replace the traditional notion of Verb Phrase, therebyAnalysis of ASL Motion Capture Data towards Identification of Verb Type 157simplifying the interaction between the lexicon and the syntax, at least for dynamicevents.
This simplification has the potential to be very useful for automatic recogni-tion of predicate signs.
Ramchand divides events into a maximum of three hierarchi-cal phrases: an initiation phrase (InitP), a process phrase (ProcP), and a result phrase(ResP).
Each of these has an associated participant: InitP: Initiator; ProcP: Undergoer;and ResP: Resultee.
This eliminates traditional problems associated with determiningargument structure and thematic role assignment.
One or more of these phrases maybe identified by a single morpheme/word/sign.
As a result, the same event could berepresented by one word or an entire phrase, depending on the morphology of a partic-ular language.
Ramchand further demonstrate that expression of degrees of causation(direct or indirect) is related to whether a single morpheme identifies both [init] and[proc] (yielding interpretation as direct causation) or separate morphemes are needed(yielding indirect causation).
Similar effects with resultatives are found with singlemorpheme identification of [proc] and [res] as compared to separate morphemes.From this perspective we can analyze ASL signs in terms of the phrases they iden-tify.
In this paper we compare signs which identify at least [ResP] (telic events) withthose that do not (atelic events).1 The notion of event-based analysis of sententialsemantics and syntax was supported in general for ASL in Rathmann (2005), andfor Austrian Sign Language (Schalber, 2004, 2006).
Semantics of event type hasbeen shown to have a direct effect on available morphological modifications as well:Brentari (1998) notes that [delayed completive] aspect marking only applies to telicstems.
Wilbur (2009) demonstrates that some types of aspectual marking (continu-ative, durative) can only apply to atelic predicates.
Wilbur (2003) argued that thephonological structure of predicate signs in ASL shows event composition, and thatthe components are grammaticalized from universally available physics of motion andgeometry of space.
This Event Visibility Hypothesis (EVH) was formalized as ?move-ment which stops at points (p) in space maps semantically to the final State of telicevents (en) and its individual argument semantic variable (x)?.
In Ramchand?s terms,ResP can be seen in lexical predicates representing telic events by the way the move-ment comes to a stop.
This hypothesis was tested in the motion capture experimentdescribed below.3 Materials and methodsA group of 29 telic and 21 atelic ASL signs were randomized, and presented as a listvia Powerpoint five times through.
A native bilingual right-handed ASL signer worea Gypsy 3.0 wired motion capture suit (Figure 2).The signer viewed the powerpoint slides with stimuli and produced the list twicewith each sign in isolation, once with each sign in the carrier phrase ?SIGNXAGAIN?,and once sentence- medially ?SHE X TODAY?.
For each production the hands beganat rest, were raised for signing, and were returned to rest.
We report the data fromthe marker on the right wrist, as the dominant right hand carries most of the mean-ingful motion information in ASL (the non- dominant typically serves as ground orrepeats the movement of the dominant hand).
All signs selected for the experiment1As Ramchand notes, it is possible to get telic readings without ResP from bounded path complements.However this study uses lexical items, for which bounded path analyses have not yet been demonstrated,thus we treat them all as ResP items for expository purposes.158 Malaia, Borneman, and WilburinitP (vP)procPresPXPinitInitiatorUndergoerprocresResultee(Rheme)Figure 1: Ramchand?s Event Structure projec-tionFigure 2: Signer in motion cap-ture suitincluded motion of the wrist.
The data from the motion capture suit was recordedinto Motionbuilder software and exported as text data for further analysis.
The dataincluded frame numbers, and marker positions along the 3D axis in millimeters forall recorded frames.
Acquisition rates were 50 fps for kinematic data, and 30 fps forvideo data; the video also included an audio marker for alignment of the beginningof motion capture recording with the separate video recording.
The time course ofpredicate signing in the video was annotated using ELAN software (Max Planck In-stitute for Psycholinguistics).
The beginning of each predicate was marked once thedominant hand assumed appropriate handshape, and the end of each movement wasmarked at the final point of contact or maximal displacement in the lexical form of thesign.
All start/stop times were determined by a single coder with over two decades ex-perience measuring sign movement, with +/?
1 video frame precision.
The vectors forthe 3D location of the wrist marker were then imported into ELAN and aligned withvideo data using the audio marker.
In addition to raw displacement data, derivatives ofspeed (in m/s) and acceleration (in m/s2) were calculated in MATLAB and importedinto ELAN.
To minimize the difference in acquisition rates for video and kinematicdata, velocity and acceleration vectors were imported into ELAN, and peak changescorresponding to the actual motion capture data points were compared to the annota-tions.
This alignment was used to ensure the proper extraction of the motion capturedata corresponding to the target sign between the marked start and end locations.
Ad-ditionally, the error of measurement for each predicate was considered, evaluated asratio of frame duration vs. predicate duration expressed in percentage.
Consequently,predicates which spanned fewer than three video frames were discarded because ofhigh error margin.
For the rest of the predicates, the following metrics were calcu-lated:?
the maximal velocity (maxV);Analysis of ASL Motion Capture Data towards Identification of Verb Type 159?
the local minimum velocity following maxV (minV);?
the slope of the drop from maxV to minV (slope);?
the minimum acceleration (minA) following the maximum velocity;?
duration of the predicate (in frames);?
the frame location of maxV, minV, and minA.These metrics were chosen to allow for maximal homogeneity in predicate com-parison.
The metrics related to the start of the sign were avoided as linguisticallyunreliable, while using the local velocity minima mitigated the effect of data inter-polation in ELAN resulting from the frame difference between video recording andmotion capture recording.
The data were submitted to SPSS multivariate ANOVA todetermine the effect of telicity value (Telic vs. Atelic).4 Linguistic results and observationsThe data from the right wrist marker indicate that in all environments, the decelerationof telic signs is steeper than that of atelic signs (Table 2).Table 2: Deceleration slope for telic and atelic signs (* p< 0.05; ** p< 0.001)Deceleration Atelic mean Telic mean Telic/Atelic Ratio(mm/s2) (tokens used) (tokens used) and effect sizeIsolation 1 ?0.093 (13) ?0.136 (22) 1.46* F(1)= 4.528Isolation 2 ?0.123 (17) ?0.179 (23) 1.46* F(1)= 5.709Carrier Phrase ?0.118 (14) ?0.233 (22) 1.97** F(1)= 15.258Sentence ?0.14 (13) ?0.23 (18) 1.62* F(1)= 7.400The data support the Event Visibility Hypothesis in ASL, indicating that there is aproduction difference reflecting the semantic distinction of event type in predicates.
Itappears that ASL takes advantage of available perceptual distinctions to provide cuesto the viewer regarding the semantics of the predicate.
Telic predicates in generalhave a steeper deceleration slope, marking the end-state of telic events.
This decel-eration may correspond to what Klima and Bellugi (1979) referred to as ?end mark-ing?.
From the perspective of syntax-semantics interface modeling theory (Ramchand,2008;Wilbur, 2003), higher decelerations in motion signatures of telic ASL predicatesalso mark additional semantic arguments of the event, what Ramchand refers to as the?Resultee?.5 Development of metrics for computational identification ofpredicate types in ASLThe data from the four productions was compared in order to evaluate the consistencyof production.
The interval distribution of maxV and minA for all predicates, in bothcarrier phrases and in sentences, overlap (Figure 3), indicating that those two produc-tion conditions were not significantly different, and therefore this data could be pooledfor the purposes of statistical analysis.160 Malaia, Borneman, and Wilbursentencecarrier2.52.01.51.00.50-15-30-45-60maxVconditionminAInterval Plot of maxV, minA95% CI for the MeanFigure 3: Interval plots of maxV and minA in carrier phrases and sentences for allpredicates, displaying 95% confidence intervals for the mean values of the respectivemetricsA similar comparison of maxV intervals by predicate type of those produced inisolation (Figure 4) revealed significant discrepancies between the two instances ofproduction for atelic signs, possibly related to the attempt by the signer to reproducethe vocabulary form of the predicate.
Thus, isolation data was not used for the follow-ing analysis.A binary logistic regression was performed on the pooled data from both carrierphrase and sentence sign production, in order to search for the minimum number ofvariables that could be used to predict whether the signed predicate is telic or atelic.For this analysis the logit function was selected to calculate the predicted probabilities.Regression was first run with all of the measured variables from Section 3 includedin the model.
The variables with p-values above 0.05 threshold were rejected oneat a time, and the regression calculation re-run; the process was repeated until allpredictive variables in the model were below p=0.05.
The model was reduced to twosignificant predictors: maxV and minA (maximum velocity and deceleration).
Thefinal regression model is shown in equation (1) using the variable dependence shownin equation (2).PT = e?1+e?
(1)?
= ?4.46+2.63 (maxV)?0.097 (minA) (2)PT is the probability of a predicate being telic, based on measured values for maxVand minA.
Applying the above equation on the pooled data for carrier phrase andsentence production conditions (setting a 50% threshold so that PT > 0.5 predicts telic,and PT < 0.5 predicts atelic) ensures that 46 out of 56 telic predicates, and 32 out ofAnalysis of ASL Motion Capture Data towards Identification of Verb Type 161Type ConditiontelicatelicIsolation 2Isolation 1Isolation 2Isolation 12.52.01.51.00.5maxVInterval Plot of maxV95% CI for the MeanFigure 4: Interval plots of maxV in isolation productions 1 and 2 by predicate type44 atelic predicates can be identified correctly using only maxV and minA measures(Figure 5).However, comparing the coefficients of maxV (2.63) and minA (?0.097) in equa-tion (2) makes it apparent that the effect of the deceleration (minA) on the output of themodel is low.
A regression analysis using only the maxV measurement to determinethe predicate type yields a revised beta value as shown in equation (3).?
= ?4.19 + 3.71 (maxV) (3)Using this simplified equation on the pooled data ensures that 47 out of 56 telicpredicates, and 27 out of 44 atelic predicates can be identified correctly with a 50%probability threshold based only on maxV (Figure 6).Direct analysis of the maximum velocity (maxV) data supports both the originalmodel (eqn.
3) and the simplified model (eqn.
4).
Telic predicates have a significantlyhigher maxV mean and distribution than atelic predicates, as shown in Figure 7.
It isthis difference in the velocity distribution that allows for telic/atelic predictions basedon maxV measurements.6 ConclusionThe above pilot data analysis indicates that there exists a production difference inmaximal velocity and deceleration slope of ASL predicate signs reflecting seman-tic distinction of event type in ASL predicates.
From the linguistic standpoint, theovert difference in sign productionmaps onto an event-structural representation for thesyntax-semantics interface, which has implications for modeling the syntax-semanticsinterface in both signed and spoken languages.
Empirical evidence for Event Visibilityin signed languages demonstrated that individual meaningful features in signs (such asrapid deceleration to a stop) can combine to create patterns which merge the syntactic162 Malaia, Borneman, and Wilburtelicatelic1.00.80.60.40.20.0predicatetypeprobabilty0.5Telic likelihood (maxV, minA)Figure 5: Probabilities of correct predicate type identification based on maxV andminA data.
Data points represent the telic and atelic predicates, presented accord-ing to the probablility of their correct identification using equation (1) and variabledependence in equation (2)telicatelic1.00.80.60.40.20.0predicatetypeProbability of being telicTelic likelihood (maxV)Figure 6: Probabilities of correct predicate type identification based on only maxVdata.
Data points represent telic and atelic predicates, presented according to theprobability of their correct identification using revised beta value in equation (3).
Thecrosshairs represent the mean probability of correct predicate type identification foratelic (0.429) and telic (0.689) predicatesAnalysis of ASL Motion Capture Data towards Identification of Verb Type 163telicatelic2.52.01.51.00.5predicatetypemaxV95% CI for the MeanmaxV vs. predicate typeFigure 7: MaxV distribution for telic and atelic predicates in carrier phrases and sen-tences (pooled), displaying the mean values and 95% confidence intervalslevel of a sign with its phonological level ?
the phenomenon which can be utilizedfor machine translation of signed languages.For the purposes of computational approaches to sign recognition, the pilot datademonstrates that production differences between predicate types can be used to modelthe probabilities of specific predicate types occurring within the motion signature,based on either maximal velocity achieved within the sign, or maximal velocity andminimal acceleration data from each predicate.
However, as pilot data analysis shows,higher acquisition rates for video and motion capture data would be beneficial to takefull advantage of production differences in velocity and deceleration of different typesof ASL predicates.
Further research is needed to determine inter-signer variability inproduction differences between telic and atelic predicate signs, the reliability of maxi-mal velocity and minimal acceleration metrics, and development of additional metrics(possibly similar to ones used for spoken language phonology (Adams et al, 1993))which could rely on higher temporal resolution in data acquisition.Acknowledgments Motion capture was conducted at the Envision Center for DataPerceptualization at Purdue University.
We are grateful to Robin Shay, Gabriel Mas-ters, Nicoletta Adamo-Villani, and the Purdue and Indianapolis sign language commu-nities for their ongoing support of the Purdue Sign Language Linguistics Lab research.This work was supported by NSF Research in Disabilities Education grant #0622900and by NIH grant DC00524 to R.B.
Wilbur.ReferencesAdams, S., G. Weismer, and R. Kent (1993).
Speaking rate and speech movementvelocity profiles.
Journal of Speech and Hearing Research 36, 41?54.164 Malaia, Borneman, and WilburBrentari, D. (1998).
A prosodic model of sign language phonology.
Cambridge, MA:MIT Press.Klima, E. and U. Bellugi (1979).
The Signs of Language.
Cambridge, MA: HarvardUniversity Press.Levin, B.
(1993).
English Verb classes and alternations.
The Univ.
of Chicago Press.Malaia, E., R. Wilbur, and T. Talavage (2008).
Experimental evidence of event struc-ture effects on asl predicate production and neural processing.
In Proceedings ofthe 44th meeting of Chicago Linguistic Society, Chicago, IL.Pustejovsky, J.
(1991).
The syntax of event structure.
Cognition 41(1-3), 47?81.Ramchand, G. (2008).
Verb Meaning and the Lexicon: A First Phase Syntax.
Cam-bridge: Cambridge University Press.Rathmann, C. (2005).
Event Structure in American Sign Language.
Ph.
D. thesis,University of Texas at Austin.Schalber, K. (2004).
Phonological visibility of event structure in Austrian Sign Lan-guage: A comparison of ASL and ?GS.
Master?s thesis, Purdue University.Schalber, K. (2006).
Event visibility in Austrian Sign Language (?GS).
Sign Lan-guage & Linguistics 9, 207?231.Smith, C. (1991).
The Parameter of Aspect.
Dordrecht: Kluwer Academic Publishers.Tenny, C. (2000).
Core events and adverbial modification.
In Tenny and Pustejovsky(Eds.
), Events as grammatical objects.
Stanford, CA: CSLA Publications.Vendler, Z.
(1967).
Linguistics in Philosophy.
Cornell University Press, New York.Wilbur, R. (2003).
Representations of telicity in ASL.
Chicago Linguistic Soci-ety 39(1), 354?368.Wilbur, R. (2009).
Productive reduplication in ASL, a fundamentally monosyllabiclanguage.
to appear in Language Sciences.Wilbur, R. and E. Malaia (2008a).
Contributions of sign language research to ges-ture understanding: What can multimodal computational systems learn from signlanguage research.
International Journal of Semantic Computing 2(1), 1?15.Wilbur, R. and E. Malaia (2008b).
Event Visibility Hypothesis: motion capture evi-dence for overt marking of telicity in ASL.
In Linguistic Society of America AnnualMeeting.
Chicago: LSA.Wilbur, R. and E. Malaia (2008c).
From Encyclopedic Semantics to GrammaticalAspects: Converging Evidence from ASL and Co-Speech Gestures.
In DGfS an-nual meeting (AG 11, Gestures: A comparison of signed and spoken languages).Bamberg, Germany: DGfS.
