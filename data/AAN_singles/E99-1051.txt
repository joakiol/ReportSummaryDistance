Proceedings of EACL '99Robust and Flexible Mixed-Initiative Dialoguefor Telephone ServicesRelafio Gil, Jos~ ~ and Tapias, Daniel and Gancedo, Mar ia C.Charfuelan, Marcela ~ and Hern?ndez, Luis A.Speech Technology Group, Telefdnica Investigacihn y Desarrollo, S.A.C.
Emilio Vargas, 6 28043 - Madrid (Spain)Teh34.1.549500.
Fax:34.1.3367350. e-mail:jretanio@gaps.ssr.upm.esAbstractIn this work, we present an experimentalanalysis of a Dialogue System for the au-tomatization of simple telephone services.Starting from the evaluation of a preliminarversion of the system we 1 conclude the ne-cessity to desing a robust and flexible systemsuitable to have to have different dialoguecontrol strategies depending on the charac-teristics of the user and the performance ofthe speech recognition module.
Experimen-tal results following the PARADISE frame-work show an important improvement bothin terms of task success and dialogue costfor the proposed system.1 INTRODUCTIONIn this contribution we present some improve-ments on the design of a Dialogue ManagementSystem for the automatization of simple telephonetasks in a PABX environment (automatic namedialing, voice messaging, ... ).
From the pointof view of its functionality, our system is a verysimple one because there is no need of advancedPlan Recognition strategies or General ProblemSolving methods.
However we think that even forthese kind of dialogue sytems there is still a longway to demonstrate their usability in real situa-tions by the "general public".In our work we will concentrate on systemsdesigned for the telephone line and for a widerange of potential users.
Therefore our evalua-tions will be done taking into account different lev-els of speech recognition performance and user be-haviours.
In particular we will propose and eval-uate strategies directed to increase the robustnessagainst recognition errors and flexibility to dealwith a wide range of users.
We will use the PAR-ADISE evaluation framework (Walker et al, 1998)to analyze both task success and agent dialoguebehaviour elated to subjective user satisfaction.1~ Dep.
SSR.
ETSIT-UPM Spain2 ROBUST AND FLEXIBLESYSTEMFollowing the classification of Dialogue Systemsproposed by Allen (Allen, 1997), our baseline clia-logue system could be described as a system withtopic-based performance capabilities, adaptivesingle task, a minimal pair clarification/correctiondialogue manager and fixed mixed-initiative.One of the most important objectives of our di-alogue manager has been the implementation of acollaborative dialogue model.
So the system hasto be able to understand all the user actions, inwhatever order they appear, and even if the focusof the dialogue has been changed by the user.
Inorder to achieve this, we organize the informationin an information tree, controlled by a task knowl-edge interpreter and we let the data to partici-pate in driving the dialogue.
However, to controla mixed-initiative strategy we use three separatesources of information: the user data, the worldknowledge mbedded in the task structure and thegeneral dialogue acts.Therefore, from this preliminar evaluation ofthe system we found that in order to increaseits permormance two major points should be ad-dressed: a) robustness against recognition andparser errors, and b) more flexibility to be ableto deal with different user models.
We designedfour complementary strategies to improve its per-formance:1.
To estimate the performance of the speech recog-nition module.
This was done from a count onthe number of corrections during previous inter-actions with the same user.2.
To classify each user as belonging to group A or Bthat will be described later in the ExperimentalResults section.
This was done combining a nor-malized average number of utterances per taskand the amount of information in each utterance,especially at some particular dialogue points (forexample when answering to the question of ourprevious example).287Proceedings of EACL '993.
To include a control module that from the re-sults of steps 1 and 2 defines two different kindsof control management allowing a flexible mixed-initiative strategy: more user initiative for GroupA users and high recognition rates, and morerestictive strategies for Group B users and/or lowrecognition performance.All of these strategies have been included in oursystem as it is depicted in Figure 1.3 EXPERIMENTAL  RESULTSIn order to test the improvements over our originalsystem (described in (Alvarez et al, 1996)) we de-signed a simulated evaluation environment wherethe performance of the Speech Recognition Mod-ule (recognition rate) was artificially controlled.A Wizard of Oz simulation environment was de-signed to obtain different levels of recognition per-formance for a vocabulary of 1170 words: 96.4%word recognition rate for high performance and80% for low performance.
A pre-defined singlefixed mixed-initiative strategy was used in all thecases.We used an annotated ata base composed of50 dialogues with 50 different novice users and 6different simple telephone tasks in each dialogue:25 dialogues were simulated using 94.6% recogni-tion rate and 25 with 80%.
Performance resultswere obtained using the PARADISE evaluationframework (Walker et al, 1998), determining thecontributions of task success and dialogue cost touser satisfaction.
Therefore as task success mea-sure me obtained the Kappa coefficient while dia-logue cost measures were based on the number ofusers turns.
In this case it is important o pointout that as each tested dialogue is composed of aset of six different asks which have quantify differ-ent number of turns, the number of turns for eachtask was normalized to it's N(x)  = ~+----~ scoreO" xBoth Group High ASRLo ASR Hi ASR0.68 0.81 1 0.61User Turn 7.3 5.4 4.2 6.9Satisf 26.4 30.1 35 .4  25.2Table 1: Shows means results for both group in lowand high ASR.
And separately for each Group A andB, only in high ASR situationUser satisfaction in Table 1 was obtained as acumulative satisfaction score for each dialogue bysumming the scores of a set of questions imilart,o those proposed in (Walker et al, 1998).
TheANOVA for Kappa, the cost measure and user sat-isfaction demostrated a significant effect of ASRperformance.
As it could be predicted, we foundthat in all cases a low recognition rate correspondsto a dramatical decrease in the absolute numberof suscessfully completed tasks and an importantincrease in the average number of utterances.However we also found that in high ASR situ-ation the task success measure of Kappa was sur-prisingly low.A closer inspection of the dialogues in Table 1revealed that this low performance under highASR situations was due to the presence of twogroups of users.
A first group, Group A, showeda "fluent" interaction with the system, similar tothe one supposed by the mixed-initiative strategy(for example, as an answer to the question of thesystem "do you want to do any other task?
", theseusers could answer something like "yes, I wouldlike to send a message to John Smith").
Whilethe other group of users, Group B, exibited a veryrestrictive interaction with the system (for exam-ple, a short answer "yes" for the same question).As a conclusion of this first evaluation we foundthat in order to increase the permormance of ourbaseline system, two major points should be ad-dressed: a) robustness against recognition andparser errors, and b) more flexibility to be ableto deal with different user models.Therefore we designed an adaptive strategy toadapt our dialogue manager to Group A or B ofusers and to High and Low ASR situations.
Theadaptation was done based on linear discrimina-tion, as it is ilustrated in Figure 2, using both theaverage number of turns and recognition errorsfrom the two first tasks in each dialogue.Low ASRBoth Gr.0.71User Turn 7.2Satisfaction 26.9High ASR1 0.835.3 6.132.1 29.4Table 2: Shows means results for each Group in highASR situations and for both in low ASR.Table 2 shows mean results for each Group Aand B of users for High ASR performance, andfor all users in Low ASR situations.
These resultsshow a more stable behaviour of the system, thatis, less difference in performance between users ofGroup A and Group B and, although to a lowerextend, between high and low recognition rates.4 CONCLUSIONSThe main conclusion of the work is the necessityto design adaptive dialogue management strate-gies to make the system robust against recognitonperformance and different user behaviours.288Proceedings ofEACL '99ReferencesJames Allen.
1997.
Tutorial: Dialogue Modeling.uno, ACL/ERACL Workshop on Spoken Dia-logue System, Madrid, Spain.J.
Alvarez, J. Caminero, C. Crespo, andD.
Tapias.
1996.
The Natural Language Pro-cessing Module \]or a Voice Asisted Operator atTele\]oniea I?D.
uno, ICSLP '96, Philadelphia,USA.M.
Walker, D. Litman, C. Kamm, and A. Abella.1998.
Evaluating spoken dialog agents withPARADISE: Two case studies, uno, Computerspeech and language.289Proceedings of EACL '99\[PARSERTRAKERBASIC ACTSUSERS GROUPSSELECTORSYSTEMDEFINEDDIALOGGROUPS STRATEG~SELECTORBASIC ACTSBACKWARD USER INTENTIONSCO-REFERENCE PROCESSOR< y PROCESSOR\[ SE~'NTIC y> GATHERINGSPROCESSOR>\[ CORRECTION \]DETECTORI BEHAVIOUR USERACTS\[ = I"KNOWLEDGE> INTERPRETERTASK ACTSDIALOG ~ - - - -ACTSINTERPRETERDIALOG ACTSL f Historic }?
REQUEST-REPLY INFOP,$L~TIOF?
ACTUALIZATION OF DIALOG'S INFORMATION:'\\\]* REQU~T.REpLy DATA INFO~T~ON?
STORE DATA INFOI~MATIONTELEPHONE \]APLICATIONFigure 1: Modules of Robust and Flexible Mixed-Iniciative Dialoguer~12I0.
: : .
~,:: .
, . '
o  , .~ : : ; .
~ .
.
.
.I F i5 i0  15  20 % ERRORRATEFigure 2: User clasification290
