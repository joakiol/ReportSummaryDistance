Generation of Output Style Variation in the SAMMIE Dialogue SystemIvana Kruijff-Korbayova?, Ciprian GerstenbergerOlga KukinaSaarland University, Germany{korbay|gerstenb|olgak}@coli.uni-sb.deJan SchehlDFKI, Germanyjan.schehl@dfki.deAbstractA dialogue system can present itself and/oraddress the user as an active agent by meansof linguistic constructions in personal style, orsuppress agentivity by using impersonal style.We describe how we generate and control per-sonal and impersonal style variation in the out-put of SAMMIE, a multimodal in-car dialoguesystem for an MP3 player.
We carried out anexperiment to compare subjective evaluationjudgments and input style alignment behaviorof users interacting with versions of the sys-tem generating output in personal vs. imper-sonal style.
Although our results are consis-tent with earlier findings obtained with simu-lated systems, the effects are weaker.1 IntroductionOne of the goals in developing dialogue systems thatusers find appealing and natural is to endow the sys-tems with contextually appropriate output.
This en-compasses a broad range of research issues.
Ourpresent contribution concerns the generation of per-sonal and impersonal style.We define the personal/impersonal style di-chotomy as reflecting primarily a distinction withrespect to agentivity: personal style involves the ex-plicit realization of an agent, whereas impersonalstyle avoids it.
In the simplest way this is mani-fested by the presence of explicit reference to the di-alogue participants (typically by means of personalpronouns) vs. its absence, respectively.
More gen-erally, active voice and finite verb forms are typicalfor personal style, whereas impersonal style often,though not exclusively, employs passive construc-tions or infinite verb forms:(1) Typical personal style constructions:a. I found 20 albums.b.
You have 20 albums.c.
Please search for albums by The Beatles.
(2) Typical impersonal style constructions:a.
20 albums have been found.b.
There are 20 albums.c.
The database contains 20 albums.d.
20 albums found.The dialogue system SAMMIE developed in theTALK project uses either personal or impersonal out-put style, employing constructions such as (1a?1c)and (2a?2d), respectively, to manifest its own andthe user?s agentivity linguistically.
We ran an ex-periment to assess the effects of the system outputstyle on users?
judgments of the system?s usabilityand performance and on their input formulation.In Section 2 we review related work on systemoutput adaptation and previous experiments con-cerning the effect of system output style on users?judgments and style.
We describe the SAMMIE sys-tem and the generation of style variation in Sec-tion 3.
In Section 4 we describe our experiment andin Section 5 present the results.
In Section 6 we pro-vide a discussion and conclusions.2 Previous WorkAlthough recently developed dialogue systemsadapt their output to the users in various ways, this129usually concerns content selection rather than sur-face realization.
There is to our knowledge no sys-tem that varies the style of its output in the in-terpersonal dimension as we have done in SAM-MIE.
Work on animated conversational agents hasaddressed various issues concerning agents display-ing their personality, but this usually concerns emo-tional states and personality traits, rather than thepersonal/impersonal alteration.
(Isard et al, 2006)model personality and alignment in generated dia-logues between pairs of agents using OpenCCG andan over-generation and ranking approach, guided bya set of language models.
Their approach probablycould produce the personal/impersonal style varia-tion as an effect of personality or a side-effect ofsyntactic alignment.The question whether a system should generateoutput in personal or impersonal style has been ad-dressed by (Nass and Brave, 2005): They observethat agents that use ?I?
are generally perceived morelike a person than those that do not.
However, sys-tems tend to be more positively rated when consis-tent with respect to such parameters as personality,gender, ontology (human vs. machine), etc.
Onthe basis of an investigation of a range of user atti-tudes to their simulated system with a synthetic vs. arecorded voice, they conclude that a recorded voicesystem is perceived as more human-like and thus en-titled to use ?I?, whereas a synthetic-voice system isnot perceived as human enough to use ?I?
to refer toitself (Nass et al, 2006).Another question is whether system output styleinfluences users?
input formulation, as would be ex-pected due to the phenomenon of alignment, whichis generally considered a basic principle in naturallanguage dialogue (Garrod and Pickering, 2004).1Experiments targeting human-human conversa-tion show that speakers in spontaneous dialoguestend to express themselves in similar ways at lexi-cal and syntactic levels (e.g., (Hadelich et al, 2004;Garrod and Pickering, 2004).
Lexical and syntacticalignment is present in human-computer interaction,too.
(Brennan, 1996) suggested that users adoptsystem?s terms to avoid errors, expecting the sys-1This dialogue phenomenon goes under a variety of terms inthe literature, besides alignment, e.g., accommodation, adapta-tion, convergence, entrainment or shaping (used, e.g., by (Bren-nan and Ohaeri, 1994)).tem to be inflexible.
However, recent experimentsshow that alignment in human-computer interactionis also automatic and its strength is comparable tothat in human-human communication (Branigan etal., 2003; Pearson et al, 2006).Early results concerning users?
alignment to sys-tem output style in the interpersonal dimension arereported in (Brennan and Ohaeri, 1994): They dis-tinguish three styles: anthropomorphic (the systemrefers to itself using first person pronouns, like in(1a) above, fluent (complete sentences, but no self-reference) and telegraphic, like (2d).
They found nodifference in users?
perception of the system?s in-telligence across the different conditions.
However,they observed that the anthropomorphic group wasmore than twice as likely to refer to the computerusing the second person pronoun ?you?
and it usedmore indirect requests and conventional politenessthan the other groups.
They conclude that the an-thropomorphic style is undesirable for dialogue sys-tems because it encourages more complex user inputwhich is harder to recognize and interpret.The described experiments used either theWizard-of-Oz paradigm (Brennan and Ohaeri, 1994)or preprogrammed system output (Branigan et al,2003; Nass and Brave, 2005) and involved writtencommunication.
Such methods allow one to test as-sumptions about idealized human-computer interac-tion.
Experimenting with the SAMMIE system al-lows us to test whether similar effects arise in an in-teraction with an actual dialogue system, which isplagued, among other factors, by speech recognitionproblems.3 The SAMMIE SystemSAMMIE is a multimodal dialogue system developedin the TALK project with particular emphasis on mul-timodal turn-planning and natural language genera-tion to support intuitive mixed-initiative interaction.The SAMMIE system provides a multimodal in-terface to an in-car MP3 player through speech andhaptic input with a BMW iDrive input device, a but-ton which can be turned, pushed down and sidewaysin four directions.
System output is by speech and agraphical display integrated into the car?s dashboard.SAMMIE has a German and an English version withthe same functionality.130The MP3 player application offers a wide rangeof tasks: The user can control the currently playingsong, search and browse by looking for fields in theMP3 database (song, artist, album, etc.
), search andselect playlists and construct and edit them.
A sam-ple interaction is shown below (Becker et al, 2006).
(3) U: Show me the Beatles albums.S: I have these four Beatles albums.
[shows a listof album names]U: Which songs are on this one?
[selects the RedAlbum]S: The Red Album contains these songs [shows alist of the songs]U: Play the third one.S: [song ?From Me To You?
plays]The system puts the user in control of the inter-action.
Input can be given through any modalityand is not restricted to answers to system queries.On the contrary, the user can provide new tasks aswell as any information relevant to the current taskat any time.
This is achieved through modeling theinteraction as a collaborative problem solving (CPS)process, modeling the tasks and their progression asrecipes and a multimodal interpretation that fits anyuser input into the context of the current task (Blay-lock and Allen, 2005).
To support dialogue flexibil-ity, we model discourse context, the CPS state andthe driver?s attention state by an enriched informa-tion state (Kruijff-Korbayova?
et al, 2006a).3.1 System ArchitectureThe SAMMIE system architecture follows the classi-cal approach of a pipelined architecture with mul-timodal fusion and fission modules encapsulatingthe dialogue manager (Bunt et al, 2005).
Figure 1shows the modules and their interaction: Modality-specific recognizers and analysers provide seman-tically interpreted input to the multimodal fusionmodule (interpretation manager in Figure 1), that in-terprets them in the context of the other modalitiesand the current dialog context.
The dialogue man-ager decides on the next system move, based on itsCPS encoded task model, on the current context andalso on the results from calls to the MP3 database.The multimodal fission component then generatesthe system reaction on a modality-dependent levelFigure 1: SAMMIE system architecture.by selecting the content to present, distributing it ap-propriately over the available output modalities andfinally co-ordinating and synchronizing the output.Modality-specific output modules generate spokenoutput and an update of the graphical display.
Allmodules interact with the extended information statein which all context information is stored.Many tasks in the SAMMIE system are modeled bya rule-based approach.
Discourse modeling, inter-pretation management, dialogue management, turnplanning and linguistic planning are all based onthe production rule system PATE (Pfleger, 2004;Kempe, 2004).
For speech recognition, we use Nu-ance.
The spoken output is synthesized with theMary TTS (Schro?der and Trouvain, 2003).23.2 Generation of Natural Language Outputwith VariationTo generate natural language output in SAMMIE, wedeveloped a template-based generator.
It is imple-mented by a set of sentence planning rules in PATEto build the templates, and a set of XSLT transforma-tions for sentence realization, which yield the out-put strings.
German and English output is producedby accessing different dictionaries in a uniform way.The output is either plain text, if it is to be displayedin the graphical user interface (e.g., captions in ta-bles, written messages to the user) or it is text withmark-up for speech synthesis using the MaryXMLformat (Schro?der and Trouvain, 2003), if it is to bespoken by a speech synthesizer.2http://mary.dfki.de/131The SAMMIE generator can produce alternativerealizations for a given content that it receives as in-put from the turn planner.
The implemented rangeof system output variation involves the following as-pects, which have been determined by an analysisof a corpus of dialogues collected in a Wizard-of-Oz experiment using several wizards who were freeto formulate their responses to the users (Kruijff-Korbayova?
et al, 2006b):1.
Personal vs. impersonal style: Ich habe 3 Lieder ge-funden (I?ve found three songs) vs. 3 Lieder wurdengefunden (Three songs have been found);2.
Telegraphic vs. non-telegraphic style: 23 Alben ge-funden (23 albums found) vs. Ich habe 23 Albengefunden (I found 23 albums)3.
Reduced vs. non-reduced referring expressions: derSong ?Kinder An Die Macht?
(the song ?Kinder AnDie Macht?)
vs. der Song (the song) vs. ?KinderAn Die Macht?
(?Kinder An Die Macht?);4.
Lexical choice for (quasi-)synonyms: Song vs. Liedvs.
Titel (song vs. track)5.
Presence vs. absence of adverbs/adverbials: Ichspiele jetzt den Song (I?ll now play the song) vs. Ichspiele den Song (I?ll play the song).The generation of alternatives is achieved by con-ditioning the sentence planning and realization de-cisions.
The system can be set either to use onestyle consistently throughout a dialogue, or to alignto the user, i.e., mimic the user?s style on a turn-by-turn basis.
For the purpose of experimentingwith system output variation, the generator supportsthree sources of control for the available choices:(a) global (default) parameter settings (resulting inno variation); (b) random selection (resulting in ran-dom variation); (c) contextual information (resultingin variation based on the dialogue context).The contextual information used by the genera-tor to control realization includes (i) the groundingstatus of the content to be communicated (e.g., todecide for vs. against reducing a referring expres-sion); and (ii) linguistic features extracted from therecognized user input (e.g., to make the correspond-ing syntactic and lexical choices in the output).3.3 Personal/Impersonal Style VariationThe style variation in SAMMIE amounts to varyingbetween active voice for personal style and passivevoice or the ?es-gibt?
(?there is?)
construction forimpersonal style whenever applicable, as illustratedfor several typical dialogue moves below (where (i)always shows the impersonal, and (ii) the personalversion).
(4) Search result:3i.
Es gibt 20 Alben.There are 20 albums.ii.
Ich habe 20 Alben gefunden.I found 20 albums.Sie haben 20 Alben.
/ Du hast 20 Alben.You have 20 albumsWir haben 20 Alben.We have 20 albums.
(5) Song addition:i.
Der Titel Bittersweet Symphony wurde zuder Playliste 2 hinzugefu?gt.The track Bittersweet Symphony has beenadded to Playlist 2.ii.
Ich habe den Titel Bittersweet Symphony zuder Playliste 2 hinzugefu?gt.I added the track Bittersweer Symphony toPlaylist 2.
(6) Song playback:i.
Der Titel Ma?nner von Herbert Gro?nemeyerwird gespielt.The track Ma?nner by Herbert Gro?nemeyer isplaying.ii.
Ich spiele den Titel Ma?nner von HerbertGro?nemeyer.I am playing the track Ma?nner by HerbertGro?nemeyer.
(7) Non-understanding:i. Das wurde leider nicht verstanden.That has unfortunately not been understood.ii.
Das habe ich leider nicht verstanden.I have unfortunately not understood that.
(8) Clarification request:i. Welches von diesen acht Liedern?/Welchesvon diesen acht Liedern wird gewu?nscht?Which of these eight songs?
/ Which of theseeight songs is desired?ii.
Welches von diesen acht Liedern mo?chtest du/ mo?chten Sie ho?ren?Which of these eight songs would you like tohear?3When referring to the user, personal style has several vari-ants which differ in formality (formal and informal address) andfirst vs. second person reference.132Figure 2: Experiment setupThe personal/impersonal style variation is not ap-plicable for some dialogue moves, e.g., (9), and foroutput in telegraphic style.
(9) Song interpreter:Der Titel Bongo Girl ist von Nena.The track Bongo Girl is by Nena.4 ExperimentIn order to assess the effects of style manipulation inthe SAMMIE system, we ran an experiment in simu-lated driving conditions, comparing two versions ofthe system: one consistently using personal and theother impersonal style output.4 The experiment em-ployed the German version of SAMMIE.
The setup(see Figure 2), participants, procedure and collecteddata are described in detail in (Kruijff-Korbayova?and Kukina, 2008), and summarized below.There were 28 participants, all native speakersof German.
We balanced gender and backgroundwhen assigning them to the style conditions.
Theexperiment followed a fixed script for each partici-pant: welcome, instruction, warm-up driving, 2 trialand 11 experimental tasks, evaluation questionnaire,payment and farewell.
The participants were in-structed to use mainly spoken input, although theycould also use the iDrive button.
It took them about40 minutes to complete all the tasks.
The tasks in-volved exploring the contents of a database of about25 music albums and were of four types: (1) find-ing some specified title(s); (2) selecting some title(s)4For the time being we have not evaluated the version of thesystem aligning to the user?s style.satisfying certain constraints; (3) manipulating theplaylists by adding or removing songs and (4) free-use of the system.The experimental tasks were presented to eachparticipant in randomized order apart from the freeuse of the system, which was always the last task.The experimenter (E) repeated each task assignmenttwice to the participant, once in personal and oncein impersonal style, as shown in the example below.
(10) E: Bitte frage das System nach den Liedern von?Pur?.
Du willst also wissen welche Lieder von?Pur?
es gibt.E: Please ask the the system about the songs by?Pur?.
You would like to know which songs by?Pur?
there are.The questionnaire was based on (Nass and Brave,2005) and (Mutschler et al, 2007).
It containedquestions with a 6-point scale ranging from 1 (lowgrade) to 6 (high grade), such as How do you assessthe system in general: technical (1) ?
human-like(6); Communication with the system seemed to you:boring (1) ?
exciting (6); In terms of usability, thesystem is: inefficient (1) ?efficient(6).The recorded dialogues have been transcribed, thequestionnaire responses tabulated.
We manually an-notated the participants?
utterances (on average 95per session) with the following features for furtheranalysis:?
Construction type:Personal (+/-) Is the utterance a complete sen-tence in active voice or imperative formImpersonal (+/-) Is the utterance expressedby passive voice, infinite verb form (e.g.,?Lied abspielen?
(lit.
?song play?
)), or ex-pletive ?es-gibt?
(?there-is?)
constructionTelegraphic (+/-) Is the utterance expressedby a phrase, e.g., ?weiter?
(?next?)?
Personal pronouns: (+/-) Does the utterancecontain a first or second person pronoun?
Politeness marking: (+/-) Does the utterancecontain a politeness marker, such as ?bitte?(?please?
), ?danke?
(?thanks?)
and verbs insubjunctive mood (eg.
?ich ha?tte gerne?
)1335 ResultsThe results concerning users?
attitudes and align-ment are presented in detail in (Kruijff-Korbayova?and Kukina, 2008).
Here we summarize the signif-icant findings and provide an additional analysis ofthe influence of speech recognition problems.5.1 Style and Users?
AttitudesThe first issue addressed in the experiment waswhether the users have different judgments of thepersonal vs. impersonal version of the system.
Sincethe system used a synthetic voice, the judgmentswere expected to be more positive in the impersonalstyle condition (Nass and Brave, 2005).
Based onfactor analysis performed on attitudinal data fromthe user questionnaires we created the six indiceslisted below.
All indices were meaningful and reli-able.
(A detailed description of the indices includingthe contributing factors from the questionnaires canbe found in (Kruijff-Korbayova?
and Kukina, 2008).)1.
General satisfaction with the communicationwith the system (Cronbach?s ?=0.86)2.
Easiness of communication with the system(?=0.83)3.
Usability of the system (?=0.76)4.
Clarity of the system?s speech (?=0.88)5.
Perceived ?humanness?
of the system (?=0.69)6.
System?s perceived flexibility and creativity(?=0.78)We did not find any significant influence of sys-tem output style on users?
attitudes.
Only for per-ceived humanness of the system we found a weaktendency in the predicted direction (independentsamples test: t(25)=1.64, p=0.06 (one-tailed)), inline with the earlier observation that an interface thatrefers to itself by a personal pronoun is perceived tobe more human-like than one that does not (Nass andBrave, 2005).5.2 Style and AlignmentThe next issue we investigated was whether the usersformulated their input differently in the personal vs.impersonal system version.
For each dialogue ses-sion, we calculated the percentage of utterances con-taining the feature of interest relative to the totalnumber of user utterances in the session.In accordance with the expectation based on stylealignment in terms of agentivity, we observed a sig-nificant difference in the number of personal con-structions across style conditions (t(19)=1.8, p=0.05(one-tailed)).
But we did not find a significant dif-ference in the distribution of impersonal construc-tions.
Not surprisingly, there was also no signifi-cant difference in the distribution of telegraphic con-structions.
An unexpected finding was the higherproportion of telegraphic constructions than verb-containing ones within the impersonal style condi-tion (t(13)=3.5, p<0.001 (one-tailed)).
However, nosuch difference was found in the personal style con-dition.
Contrary to expectations, we also did not findany significant effect of style-manipulation on thenumber of personal pronouns, nor on the number ofpoliteness markers.Since alignment can also be seen as a processof gradual adjustment among dialogue participantsover time we compared the proportion of personal,impersonal and telegraphic constructions in the firstand second halves of the conversations for both styleconditions.
The only significant effect we found wasa decrease in the number of personal constructionsin the second halves of the impersonal style interac-tions (t(13)=2.5, p=0.02 (one-tailed)).5.3 Influence of Speech Recognition ProblemsUnlike an interaction in a Wizard-of-Oz simulationor similar, an interaction with a real system is boundto suffer from speech recognition problems.
There-fore, we made a post-hoc analysis with respect tohow much speech recognition difficulty the partici-pants experienced, in terms of the proportion of par-ticipant utterances not recognized by the system rel-ative to the total number of participant utterances ina session.On average, around 33% of participant utteranceswere not understood by the system.5 We classi-fied the participants into three groups according tothe performance of speech recognition they expe-rienced: the good group with less than 27% of in-put not understood (7 participants); the poor group5This is admittedly rather bad performance, nevertheless itmostly does not prevent the participants from getting their taskssuccessfully completed within a reasonable time, as was shownin an rigorous usability evaluation of the system in normal driv-ing conditions (Mutschler et al, 2007).134Figure 3: Judgments of the system by the ?good?
and ?poor?
speech recognition groupwith more than 37% of input not uderstood (7 par-ticipants); the average group (the remaining 14 par-ticipants).Speech Recognition and Attitudinal Data Wesuspected that speech recognition problems mightbe neutralizing a potential influence of style.
There-fore we contrasted the judgments on all six factorsbetween the good and the poor speech recognitiongroup (see Figure 3).
The ?good?
speech recognitiongroup showed higher satisfaction with the communi-cation (t(16)=1.9, p=0.04 (one-tailed)) and evaluatedthe clarity of the system?s speech better (t(16)= 2.0,p=0.03 (one-tailed)).
The good speech recognitiongroup also showed a tendency to assess the usabil-ity and flexibility of the system higher than the poorspeech recognition group (t(16)=1.71, p=0.05 andt(16)=1.61, p=0.06, respectively (marginally signif-icant results)).
The two groups did not differ withrespect to their judgments of the ease of commu-nication and perceived humanness of the system(t(16)=0.45, p=0.66 and t(16)=0.90, p=0.38).
Theseresults are not surprising.
They confirm that speechrecognition does have an effect on the user?s percep-tion of the system.Speech Recognition and Style Alignment Wealso checked post-hoc whether differences in the ex-perienced speech recognition performance had aninfluence on the style employed by the participants,again in terms of the proportion of utterances withpersonal, impersonal and telegraphic constructions,personal pronouns and politeness marking.
How-ever, we found no significant effect on the linguisticstructure of the participant input across the groups(politeness marking: F(2)=1.5, p=0.24; all otherFs<1 (ANOVA)).6 Discussion and ConclusionsWe presented the generation of personal/impersonalstyle variation in the SAMMIE multimodal dialoguesystem, and the results of an experiment evaluatingthe influence of the system output style on the users?subjective judgments and their formulation of input.Although our results are not conclusive, they pointat a range of issues for further research.Regarding users?
attitudes to the system, wefound no significant difference among the styles.This is similar to (Brennan and Ohaeri, 1994) whofound no difference in intelligence attributed to thesystem by the users, but it is at odds with the earlierfinding that a synthetic voice interface was judgedto be more useful when avoiding self-reference bypersonal pronouns (Nass and Brave, 2005).Whereas (Brennan and Ohaeri, 1994) used a flightreservation dialogue system, (Nass and Brave, 2005)used a phone-based auction system which read outan introduction and five object descriptions.
Thereare two points to note: First, the subjects heardsystem output that was a read out continuous textrather than turns in an interaction.
This may havereinforced the activation of particular style features.Second, the auction task may have sensibilized thesubjects to the distinction between subjective (thesystem?s) vs. objective information presentation,and thus make them more sensitive to whether thesystem presents itself as an active agent or not.Regarding the question whether users align theirstyle to that of the system, where previous experi-ments showed strong effects of alignment (Brennanand Ohaeri, 1994), our experiment shows some ef-fects, but some of the results are conflicting.
Onthe one hand, subjects interacting with the personalstyle version of the system used more personal con-structions than those interacting with the impersonalstyle version.
However, subjects in either condi-135tion did not show any significant difference with re-spect to the use of impersonal constructions or tele-graphic forms.
We also found a higher proportion oftelegraphic constructions than verb-containing oneswithin the impersonal style condition, but no suchdifference in the personal style.
Finally, when weconsidered alignment over time, we found no changein construction use in the personal style, whereas wefound a decrease in the use of personal constructionsin the impersonal style.
It is possible that divid-ing the interactions into three parts and comparingalignment in the first and the last part might lead tostronger results.That there is no difference in the use of tele-graphic constructions across conditions is not sur-prising.
Being just phrasal sentence fragments, theseconstructions are neutral with respect to style.
Butwhy does there seem to be an alignment effect forpersonal constructions and not for others?
One wayof explaining this is that (some of) the construc-tions that we counted as impersonal are common inboth styles.
Besides their deliberate use as meansto avoid explicit reference to oneself, they also havetheir normal, neutral usage, and therefore, some ofthe utterances that we classified as impersonal stylemay just be neutral formulations, rather than casesof distancing or ?de-agentivization?.
However, wecould not test this hypothesis, because we have notfound a way to reliably distinguish between neutraland marked, truly impersonal utterances.
This is anissue for future work.The difference between our results concerningalignment and those of (Brennan and Ohaeri, 1994)is not likely to be due to a difference in the degreeof interactivity (as with (Nass and Brave, 2005)).We now comment on other differences between oursystems, which might have contributed to the differ-ences in results.One aspect where we differ concerns our distinc-tion between personal and impersonal style, both inthe implementation of the SAMMIE system and inthe experiment: We include the presence/absenceof agentivity not only in the system?s reference toitself (akin to (Nass and Brave, 2005) and (Bren-nan and Ohaeri, 1994)), but also in addressing theuser.
This concept of the personal/impersonal dis-tinction was inspired by such differences observedin a study of instructional texts in several languages(Kruijff et al, 1999), where the latter dimension ispredominant.
The present experiment results makeit pertinent that more research into the motives be-hind expressing or suppressing agentivity in both di-mensions is needed.Apart from the linguistic design of the system?soutput, other factors influence users?
behavior andperception of the system, and thus might confoundexperiment results, e.g., functionality, design, er-gonomics, speech synthesis and speech recognition.A system with synthesized speech should be morepositively rated when it does not refer to itself as anactive agent by personal pronouns (Nass and Brave,2005).
(Brennan and Ohaeri, 1994) used a sys-tem with written interaction, the SAMMIE systememploys the MARY text-to-speech synthesis system(Schro?der and Trouvain, 2003) with an MBROLAdiphone synthesiser, which produces an acceptablethough not outstanding output quality.
Our post-hocanalysis showed a tendency towards better judge-ments of the system by the participants experienc-ing less speech recognition problems.
This is asexpected.
We did not find any statistically signif-icant effect regarding the style-related features weanalyzed.
A future experiment should address thepossibility of an interaction between system styleand speech recognition performance as both factorsmight be influencing the user simultaneously.One radical difference between our experimentand the earlier ones is that the users of the SAMMIEsystem are occupied by the driving task, and thusonly have a limited cognitive capacity left for theinteraction with the system.
This may make themless susceptible to the subtleties of style manipula-tion than would be the case if they were free of othertasks.
A possible future experiment could addressthis issue by including a non-driving condition.Finally, the SAMMIE system has also the style-alignment mode, where it mimics the user?s style onturn-to-turn basis.
We plan to present experimentalresults comparing the alignment-mode with the fixedpersonal/impersonal style in a future publication.AcknowledgmentsThis work was carried out in the TALK project(www.talk-project.org) funded by the EU as projectNo.
IST-507802 within the 6th Framework Program.136ReferencesT.
Becker, N. Blaylock, C. Gerstenberger, I.
Kruijff-Korbayova?, A. Korthauer, M. Pinkal, M. Pitz, P. Poller,and J. Schehl.
2006.
Natural and intuitive multimodaldialogue for in-car applications: The SAMMIE system.In Proceedings of ECAI, PAIS Special section.N.
Blaylock and J. Allen.
2005.
A collaborativeproblem-solving model of dialogue.
In L. Dybkj?rand W. Minker, editors, Proceedings of the 6th SIGdialWorkshop on Discourse and Dialogue, pages 200?211,Lisbon, September 2?3.H.
Branigan, M. Pickering, J. Pearson, J. F. McLean, andC.
Nass.
2003.
Syntactic alignment between com-puter and people: the role of belief about mental states.In Proceedings of the Annual Conference of the Cog-nitive Science Society.S.
Brennan and J.O.
Ohaeri.
1994.
Effects of mes-sage style on user?s attribution toward agents.
In Pro-ceedings of CHI?94 Conference Companion HumanFactors in Computing Systems, pages 281?282.
ACMPress.S.
Brennan.
1996.
Lexical entrainment in spontaneousdialogue.
In Proceedings of the International Sympo-sium on Spoken Dialogue (ISSD-96), pages 41?44.H.
Bunt, M. Kipp, M. Maybury, and W. Wahlster.
2005.Fusion and coordination for multimodal interactive in-formation presentation: Roadmap, architecture, tools,semantics.
In O.
Stock and M. Zancanaro, editors,Multimodal Intelligent Information Presentation, vol-ume 27 of Text, Speech and Language Technology,pages 325?340.
Kluwer Academic.S.
Garrod and M. Pickering.
2004.
Why is conversationso easy?
TRENDS in Cognitive Sciences, 8.K.
Hadelich, H. Branigan, M. Pickering, and M. Crocker.2004.
Alignment in dialogue: Effects of feedbackon lexical overlap within and between participants.In Proceedings of the AMLaP Conference.
Aix enProvence, France.Amy Isard, Carsten Brockmann, and Jon Oberlander.2006.
Individuality and alignment in generated di-alogues.
In Proceedings of the 4th InternationalNatural Language Generation Conference (INLG-06),pages 22?29, Sydney, Australia.Benjamin Kempe.
2004.
PATE a production rule sys-tem based on activation and typed feature structure ele-ments.
Bachelor Thesis, Saarland University, August.G.J.M.
Kruijff, I.
Kruijff-Korbayova?, J. Bateman,D.
Dochev, N. Gromova, T. Hartley, E. Teich,S.
Sharoff, L. Sokolova, and K. Staykova.
1999.Deliverable TEXS2: Specification of elaborated textstructures.
Technical report, AGILE Project, EUINCO COPERNICUS PL961104.I.
Kruijff-Korbayova?
and O. Kukina.
2008.
The effect ofdialogue system output style variation on users?
eval-uation judgements and input style.
In Proceedings ofSigDial?08, Columbus, Ohio.I.
Kruijff-Korbayova?, G. Amores, N. Blaylock, S. Eric-sson, G. Pe?rez, K. Georgila, M. Kaisser, S. Larsson,O.
Lemon, P. Mancho?n, and J. Schehl.
2006a.
De-liverable D3.1: Extended information state modeling.Technical report, TALK Project, EU FP6, IST-507802.Ivana Kruijff-Korbayova?, Tilman Becker, Nate Blaylock,Ciprian Gerstenberger, Michael Kaisser, Peter Poller,Verena Rieser, and Jan Schehl.
2006b.
The SAMMIEcorpus of multimodal dialogues with an MP3 player.In Proceedings of LREC, Genova, Italy.H.
Mutschler, F. Steffens, and A. Korthauer.
2007.
De-liverable D6.4: Final report on multimodal experi-ments Part I: Evaluation of the SAMMIE system.
Tech-nical report, TALK Project, EU FP6, IST-507802.C.
Nass and S. Brave, 2005.
Should voice interfaces say?I??
Recorded and synthetic voice interfaces?
claimsto humanity, chapter 10, pages 113?124.
The MITPress, Cambridge.C.
Nass, S. Brave, and L. Takayama.
2006.
Socializingconsistency: from technical homogeneity to humanepitome.
In P. Zhang & D. Galletta (Eds.
), Human-computer interaction in management information sys-tems: Foundations, pages 373?390.
Armonk, NY: M.E.
Sharpe.J.
Pearson, J. Hu, H. Branigan, M. J. Pickering, and C. I.Nass.
2006.
Adaptive language behavior in HCI: howexpectations and beliefs about a system affect users?word choice.
In CHI ?06: Proceedings of the SIGCHIconference on Human Factors in computing systems,pages 1177?1180, New York, NY, USA.
ACM.N.
Pfleger.
2004.
Context based multimodal fusion.
InICMI ?04: Proceedings of the 6th international confer-ence on Multimodal interfaces, pages 265?272, NewYork, NY, USA.
ACM Press.M.
Schro?der and J. Trouvain.
2003.
The German text-to-speech synthesis system MARY: A tool for research,development and teaching.
International Journal ofSpeech Technology, 6:365?377.137
