Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 77?80,New York, June 2006. c?2006 Association for Computational LinguisticsEvaluation of Utility of LSA for Word Sense DiscriminationEsther Levin Mehrbod Sharifi Jerry BallDept.
of  Computer Science Dept.
of  Computer Science Air Force Research LaboratoryCity College of New York City College of New York 6030 S Kent StreetNY, NY 10031 NY, NY 10031 Mesa, AZ 85212-6061esther@cs.ccny.cuny.edumehrbod@yahoo.com Jerry.Ball@mesa.afmc.af.milAbstractThe goal of the on-going project de-scribed in this paper is evaluation of theutility of Latent Semantic Analysis (LSA)for unsupervised word sense discrimina-tion.
The hypothesis is that LSA can beused to compute context vectors for am-biguous words that can be clustered to-gether ?
with each cluster correspondingto a different sense of the word.
In thispaper we report first experimental resulton tightness, separation and purity ofsense-based clusters as a function of vec-tor space dimensionality and using differ-ent distance metrics.1 IntroductionLatent semantic analysis (LSA) is a mathematicaltechnique used in natural language processing forfinding complex and hidden relations of meaningamong words and the various contexts in whichthey are found (Landauer and Dumais, 1997; Lan-dauer et al 1998).
LSA is based on the idea of as-sociation of elements (words) with contexts andsimilarity in word meaning is defined by similarityin shared contexts.The starting point for LSA is the construction of aco-occurrence matrix, where the columns representthe different contexts in the corpus, and the rowsthe different word tokens.
An entry ij in the matrixcorresponds to the count of the number of timesthe word token i appeared in context j.
Often theco-occurrence matrix is normalized for documentlength and word entropy (Dumais, 1994).The critical step of the LSA algorithm is to com-pute the singular value decomposition (SVD) ofthe normalized co-occurrence matrix.
If the matri-ces comprising the SVD are permuted such that thesingular values are in decreasing order, they can betruncated to a much lower rank.
According to Lan-dauer and Dumais (1997), it is this dimensionalityreduction step, the combining of surface informa-tion into a deeper abstraction that captures the mu-tual implications of words and passages anduncovers important structural aspects of a problemwhile filtering out noise.
The singular vectors re-flect principal components, or axes of greatestvariance in the data, constituting the hidden ab-stract concepts of the semantic space, and eachword and each document is represented as a linearcombination of these concepts.Within the LSA framework   discreet entities suchas words and documents are mapped into the samecontinuous low-dimensional parameter space, re-vealing the underlying semantic structure of theseentities and making it especially efficient for vari-ety of machine-learning algorithms.
Followingsuccessful application of LSA to information re-trieval other areas of application of the same meth-odology have been explored, including languagemodeling, word and document clustering, call rout-ing and semantic inference for spoken interfacecontrol (Bellegarda, 2005).The ultimate goal of the project described here isto explore the use of LSA for unsupervised identi-fication of word senses and for estimating wordsense frequencies from application relevant cor-pora following Sch?tze?s (1998) context-groupdiscrimination paradigm.
In this paper we describea first set of experiments investigating the tight-ness, separation and purity properties of sense-based clusters.772 Experimental SetupThe basic idea of the context-group discriminationparadigm adopted in this investigation is to inducesenses of ambiguous word from their contextualsimilarity.
The occurrences of an ambiguous wordrepresented by their context vectors are groupedinto clusters, where clusters consist of contextuallysimilar occurrences.
The context vectors in ourexperiments are LSA-based representation of thedocuments in which the ambiguous word appears.Context vectors from the training portion of thecorpus are grouped into clusters and the centroid ofthe cluster?the sense vector?is computed.
Am-biguous words from the test portion of the corpusare disambiguated by finding the closest sense vec-tor (cluster centroid) to its context vector represen-tation.
If sense labels are available for theambiguous words in the corpus, sense vectors aregiven a label that corresponds to the majority sensein their cluster, and sense discrimination accuracycan be evaluated by computing the percentage ofambiguous words from the test portion that weremapped to the sense vector whose label corre-sponds to the ambiguous word?s sense label.Our goal is to investigate how well the differentsenses of ambiguous words are separated in theLSA-based vector space.
With an ideal representa-tion the clusters of context vectors would be tight(the vectors in the cluster close to each other andclose to centroid of the cluster), and far away fromeach other, and each cluster would  be pure, i.e.,consisting of  vectors corresponding to words withthe same sense.
Since we don?t want the evaluationof the LSA-based representation to be influencedby the choice of clustering algorithm,  or the algo-rithm?s initialization and its parameter settings thatdetermine the resulting grouping, we took an or-thogonal approach to the problem: Instead ofevaluating the purity of the clusters based on geo-metrical position of vectors, we evaluate how well-formed the clusters based on sense labels are,  howseparated from each other  and tight they are.
Aswill be discussed below, performance evaluation ofsuch sense-based clusters results in an upper boundon  the performance that can be obtained by clus-tering algorithms such as EM or  K-means.3 ResultsWe used the line-hard-serve-interest cor-pus(Leacock et al 1993), with 1151 instances for 3noun senses of word ?Line?
: cord - 373,  division -374, and text - 404;  752 instances for 2 adjectivesenses of word ?Hard?
: difficult ?
376, not yield-ing to pressure or easily penetrated ?
376; 1292instances for 2 verb senses of word ?Serve?
: serv-ing a purpose, role or function or acting as ?
853,and providing service 439; and 2113 instances for3 noun senses of word ?Interest?
: readiness to giveattention - 361, a share in a company or business ?500, money paid for the use of money -1252.For all instances of an ambiguous word in the cor-pus   we computed the corresponding LSA contextvectors, and grouped them into clusters accordingto the sense label given in the corpus.
To evaluatethe inter-cluster tightness and intra-cluster separa-tion for variable-dimensionality LSA representa-tion we used the following measures:1.
Sense discrimination accuracy.
To computesense discrimination accuracy the centroid of eachsense cluster was computed using 90% of the data.We evaluated the sense discrimination accuracyusing the remaining 10% of the data reserved fortesting by computing for each test context vectorthe closest cluster centroid and comparing theirsense labels.
To increase the robustness of thisevaluation we repeated this computation 10 times,each time using a different 10% chunk for testdata, round-robin style.
The sense discriminationaccuracy estimated in this way constitutes an upperbound on the sense discrimination performance ofunsupervised clustering such as K-means or EM:The sense-based centroids, by definition, are thepoints with minimal average distance to all thesame-sense points in the training set, while thecentroids found by unsupervised clustering arebased on geometric properties of all context vec-tors, regardless of their sense label.2.
Average Silhouette Value.
The silhouette value(Rousseeuw, 1987) for each point is a measure ofhow similar that   point is to points in its own clus-ter vs. points in other clusters.
This measure rangesfrom +1, indicating points that are very distantfrom neighboring clusters, through 0, indicatingpoints that are not distinctly in one cluster oranother, to -1, indicating points that are probablyassigned to the wrong cluster.
To construct the sil-houette value for each vector i, S(i), the followingformula is used:78)}(),(max{))()(()(ibiaiaibiS ?= ,where a(i)  is an average distance  of i-object to allother objects in the same cluster and b(i) is aminimum of average distance of i-object to all ob-jects in other cluster (in  other words,  it is the av-erage distance to the points in closest clusteramong the other clusters).
The overall average sil-houette value is simply the average of the S(i) forall points in the whole dataset.Figure 1: Average discrimination accuracyFigure 1 plots the average discrimination accuracyas a function of LSA dimensionality for differentdistance/similarity measures, namely L2, L1 andcosine, for the 4 ambiguous words in the corpus.Note that the distance measure choice affects notonly the classification of a point to the cluster, butalso the computation of cluster centroid.
For L2and cosine measures the centroid is simply the av-erage of vectors in the cluster, while for L1 it is themedian, i.e., the value of i-th dimension of thecluster centroid vector is the median of values ofthe i-th dimension of all the vectors in the cluster.As can be seen from the sense discrimination re-sults in Fig.
1, cosine distance, the most frequentlyused distance measure in LSA applications, has thebest performance in for 3 out of 4 words in thecorpus.
Only for ?Hard?
does L1 outperforms co-sine for low values of LSA dimension.
As to theinfluence of dimensionality reduction on sense dis-crimination accuracy, our results show that (at leastfor the cosine distance) the accuracy does not peakat any reduced dimension, rather it increasesmonotonically, first rapidly and then reaching satu-ration as the dimension is increased from its lowestvalue (50 in our experiments) to the full dimensionthat corresponds to the number of contexts in thecorpus.These results suggest that the value of dimension-ality reduction is not in increasing the sense dis-crimination power of LSA representation, but inmaking the subsequent computations more effi-cient and perhaps enabling working with muchlarger corpora.
For every number of dimensionsexamined, the average sense discrimination accu-racy is significantly better than the baseline thatwas computed as the relative percentage of themost frequent sense of each ambiguous word in thecorpus.Figure 2 shows the average silhouette values forthe sense-based clusters as a function of the dimen-sionality of the underlying LSA?based vector rep-resentation for the 3 different distance metrics andfor the 4 words in the corpus.
The average silhou-ette value is close to zero, not varying significantlyfor the different number of dimensions and dis-tance measures.
Although the measured silhouettevalues indicate that the sense-based clusters are notvery tight, the sense-discrimination accuracy re-sults suggest that    they are sufficiently far fromeach other to guarantee relatively high accuracy.4 Summary and DiscussionIn this paper we reported on the first in a series ofexperiments aimed at examining the sense dis-crimination utility of LSA-based vector representa-tion of ambiguous words?
contexts.
Our evaluationof average silhouette values indicates that sense-79based clusters in the latent semantic space are notvery tight (their silhouette values are mostly posi-tive, but close to zero).
However, they are sepa-rated enough to result in sense discriminationaccuracy significantly higher than the baseline.
Wealso found that the cosine distance measure outper-forms L1 and L2, and that dimensionality reduc-tion for sense-based clusters does not improve thesense discrimination accuracy.Figure2: Average silhouette valuesThe clustering  examined in this paper is based onpre-established word sense labels, and the meas-ured accuracy  constitutes an upper bound on asense discrimination accuracy that can be obtainedby unsupervised clustering such as EM or segmen-tal K-means.
In the next phase of this investigationwe plan to do a similar evaluation for clusteringobtained without supervision by running K-meansalgorithm on the same corpus.
Since such cluster-ing is based on geometric properties of word vec-tors, we expect it to have a better tightness asmeasured by average silhouette value, but, at thesame time, lower sense discrimination accuracy.The experiments reported here are based on LSArepresentation computed using the whole docu-ment as a context for the ambiguous word.
In thefuture we plan to investigate the influence of thecontext size on sense discrimination performance.AcknowledgementsThe project described above is supported by grant?Using LSA to Compute Word Sense Frequencies?from Air Force Research Lab.
Its contents aresolely the responsibility of the authors and do notnecessarily represent the official views of theAFRL.5 ReferencesJ.R.
Bellegarda.
2005.
Latent Semantic Mapping,IEEE Signal Processing Magazine, 22(5):70-80.S.T.
Dumais.
1994.
Latent Semantic Indexing (LSI)and TREC-2, in Proc Second Text Retrieval Conf.
(TREC-2),  pp 104-105.T.K.
Landauer, S.T.
Dumais.
1997.
A solution toPlato's problem: The latent semantic analysis the-ory of acquisition, induction and representation ofknowledge, Psychological Review, 104(2):211-240.T.K.
Landauer, P. Foltz, and  D. Laham.
1998.Introduction to Latent Semantic Analysis.Discourse Processes, 25, 259-284.C.
Leacock, G. Towel, E. Voorhees.
1993.
Corpus-Based Statistical Sense Resolution, Proceedings ofthe ARPA Workshop on Human Language Tech-nology.P.J.
Rousseeuw.
1987.
Silhouettes: a graphicalaid to the interpretation and validation of clusteranalysis.
Journal of Computational and AppliedMathematics.
20.
53-65.H.
Sch?tze.
1998.
Automatic Word Sense Dis-crimination, Journal of Computational Linguistics,Volume 24, Number 280
