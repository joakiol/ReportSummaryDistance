Proceedings of the NAACL HLT 2010 First International Workshop on Formalisms and Methodology for Learning by Reading, pages 1?9,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsMachine Reading as a Process of Partial Question-AnsweringPeter Clark and Phil HarrisonBoeing Research & TechnologyThe Boeing Company, PO Box 3707, Seattle, WA 98124, USA{peter.e.clark,philip.harrison}@boeing.comAbstractThis paper explores the close relationship be-tween question answering and machine read-ing, and how the active use of reasoning toanswer (and in the process, disambiguate)questions can also be applied to reading de-clarative texts, where a substantial proportionof the text?s contents is already known to (rep-resented in) the system.
In question answer-ing, a question may be ambiguous, and it mayonly be in the process of trying to answer itthat the "right" way to disambiguate it be-comes apparent.
Similarly in machine reading,a text may be ambiguous, and may requiresome process to relate it to what is alreadyknown.
Our conjecture in this paper is thatthese two processes are similar, and that wecan modify a question answering tool to help"read" new text that augments existing systemknowledge.
Specifically, interpreting a newtext T can be recast as trying to answer, orpartially answer, the question "Is it true thatT?
", resulting in both appropriate disambigua-tion and connection of T to existing knowl-edge.
Some preliminary investigation suggeststhis might be useful for proposing knowledgebase extensions, extracted from text, to aknowledge engineer.1 IntroductionMachine reading is not just a task of languageprocessing, but an active interplay between knowl-edge and language; Prior knowledge should guideinterpretation of new text, and new interpretationsshould augment that prior knowledge.
Such inter-action is essential if ambiguities in language are tobe resolved "correctly" (with respect to what isknown), and if the resulting interpretations are tobe integrated with existing knowledge.
The maininsight of this paper is that this interaction is simi-lar to that required for knowledge-based questionanswering, which also requires searching a knowl-edge base (KB) for a valid interpretation of thequestion.
In our earlier work on question answer-ing (Clark and Harrison, 2010), we found thatsome disambiguation decisions for question inter-pretation could be deferred, to be resolved duringquestion answering, guided by what was found inthe KB.
In this paper, we show how a similar ap-proach can be applied to interpreting declarativetext, so that a similar interplay between languageand knowledge is achieved.
"Machine reading" itself is a loosely-defined no-tion, ranging from extracting selective facts to con-structing complex, inference-supportingrepresentations of text.
One approach for selectiveextraction is the use of semantic templates("scripts", "frames") to provide a set of roles (slots)and constraints on objects playing those roles (fill-ers) to be expected in text, and might be filled bymethods ranging from simply skimming text, e.g.,FRUMP (DeJong, 1979), to full language process-ing, e.g., (Dahlgren et al, 1991).
Other work haslooked at techniques for learning phrasal patternslikely to contain slot fillers (Riloff, 1996; Sekine,2006) or contain information semantically similarto a set of seed examples (Carlson et al 2009).At the other end of the spectrum, some systemsattempt a full understanding of text, i.e., have theambitious goal of building a complete representa-tion of the text's contents (e.g., Zadrozny 1991,Hobbs et al 1993).
A common thread of these ap-proaches is to search a space of alternative disam-biguations and elaborations and select the most1"coherent", based on criteria such as maximizingcoreference, minimizing redundancy, and avoidingcontradictions.
For example, Mulkar et al(2007)search for a set of abductive inferences on the(logical form of the) text that minimizes cost(maximizes coherence) of the result, where an ab-ductive inference might be a word sense orcoreference decision with an associated cost.
Simi-larly, Zadrozny and Jensen (1991) search a spaceof disambiguations when interpreting paragraphsby elaborating each alternative (using dictionarydefinitions) and selecting the most coherent basedon similar criteria.
Work on model building is in-spiring but also challenging due to the lack of con-straint on the final models (even with substantialdomain knowledge) and the difficulty of quantify-ing "coherence".Our work falls somewhere between these two.
Wedo not use templates for new knowledge, but ratheruse inference at run-time to identify what is knownand thus what to expect that the text might be say-ing.
However, unlike full model building ap-proaches, we assume that the majority of what isbeing read is already known (represented) in theKB, and thus the reading task is primarily one ofrecognizing that knowledge in the text, and extend-ing it with any new facts that are encountered.
Wemight term this a "model extension" approach; itcorresponds to Feigenbaum's (2003) challenge of,given the representation of a book, have a machineread a second book (about the same topic) and in-tegrate the new knowledge contained in that text.2 The ProblemOur work is in the context of cell biology, wherewe have a moderately sized1, hand-built knowl-edge base available containing formal representa-tions of biological structures and processesexpressed in first-order logic.
Our goal is to takeparagraphs of text about a topic partially coveredby the KB, and identify facts which are alreadyknown, facts which are new,  and  the  connections1 Specifically, it has detailed representations of entities andprocesses related to cell division, DNA replication, and pro-tein synthesis, containing approximately 250 domain-specificconcepts (built on top of a pre-existing library of approxi-mately 500 domain-general concepts), 120 relations (binarypredicates), and approximately 2000 axioms, built as part ofProject Halo (Gunning et al, 2010).Topic: prophaseInput Paragraph:In the cytoplasm, the mitotic spindle, consisting ofmicrotubules and other proteins, forms between thetwo pairs of centrioles as they migrate to oppositepoles of the cell.Output Axioms: (expressed in English)In all prophase events:a.
The mitotic spindle has parts the microtubuleand the protein.b.
The mitotic spindle is created between thecentrioles in the cytoplasm.c.
The centrioles move to the poles.Figure 1: The system?s behavior, showing known(normal font) and new (bold) facts identifiedfrom the text.
Note that the output is not just asimple recitation of the input, but a mixture ofknown and new axioms for the KB.between the two.
An example of the system?s out-put is shown in Figure 1.
In the Output Axioms inthat Figure, the normal font shows facts that thesystem has recognized as already known in theKB, while bold font shows new knowledge.
It isimportant to note that the output facts are not just asimple  recitation of the input, but have been inter-preted in the context of the KB.
For example in theinput paragraph:"the mitotic spindle, consisting of microtubules"has not been interpreted as describing some ?con-sisting?
event, but recognized (via use of para-phrases, described later) as referring to the has-part(mitotic-spindle01,microtubules01) element inthe representation of prophase in the KB, i.e., de-noting a "has part" relationship ((a) in Figure 1).Similarly,"the spindle forms"has not been interpreted as an organizing event(?form a team?)
nor as the spindle doing the form-ing (?the spindle forms something?
), but insteadbeen recognized as the result(create01,mitotic-spindle01) element in the representation of pro-phase in the KB, i.e., "forms" has been interpretedas this particular creation event in the representa-tion of prophase (b in Figure 1).
Doing this re-quires not just careful language processing; itrequires querying the knowledge base to see/infer2what is already known, and using this to guide theinterpretation.This process is similar to that needed for question-answering.
Consider giving a question form of(part of) the earlier paragraph to a question-answering system:(1) Is it true that the mitotic spindle consists ofmicrotubules?Again, the phrase "consists of" is ambiguous, andmay mean different things in different contexts.However, in the context of question-answering,there is a natural approach to disambiguating this:as the user is asking about what is in the KB, thena natural approach is to query the KB for relation-ships that hold between the mitotic spindle andmicrotubules, and see if any are a plausible inter-pretation of "consists of".
If there is one, then it islikely to be the interpretation that the user intended(assuming the user is not being deliberately ob-scure; we call this a "benevolent user" assump-tion).
If this happens, then the question-answeringsystem can answer "yes"; but more importantlyfrom a machine reading point of view, the systemhas also correctly disambiguated the original ques-tion and located the facts it mentions in the knowl-edge base as side-effects.
It is this process that wewant to apply to interpreting declarative texts, withthe change that unproven parts should be treated asnew assertions, rather than failed queries.3 ApproachBased on these observations, our approach is tointerpret a new text T by treating it as a question tothe KB asking whether the facts in T are alreadyknown.
By attempting to answer this question, thesystem resolves ambiguity for the known facts(namely, the resolution that leads to them beingrecognized is preferred).
For new facts, the systemfalls back on more traditional NLP modules, fil-tered by coarser-grained type constraints.
In addi-tion, the identification of known facts in the KBand the connection between the old facts and thenew facts provides anchor points for the new factsto be connected to.To implement this approach, we have used threeimportant features of our question-answering sys-tem, here reapplied to the task of text interpreta-tion:a.
The use of a large database of paraphrases toexplore alternative phrasings (hence alternativeinterpretations) of text;b.
Deferring word sense and semantic role com-mitment during initial language processing, tobe resolved later based on what is found in theKB;c. The use of standard disambiguation techniquesto process new facts not located in the KB.We now summarize these three features, then pre-sent the complete algorithm.3.1 ParaphrasesA relatively recent advance in NLP has been theautomatic construction of paraphrase databases(containing phrasal patterns with approximatelyequivalent meaning), built by finding phrases thatoccur in distributionally similar contexts (e.g.,Dras et al 2005).
To date, paraphrase databaseshave primarily been exploited for recognizing tex-tual entailment (e.g., Bentivogli et al, 2009).
Inour work, we take them in a new direction and ex-ploit them for language interpretation.We use the DIRT paraphrase database (Lin andPantel, 2001a,b), containing approximately 12 mil-lion automatically learned rules of the form:IF X relation Y THEN X relation' Ywhere relation is a path in the dependency tree be-tween constitutents X and Y, or equivalently (aswe use later) a chain of clauses:{p0(x0,x1), w1(x1), ?pn-1(x n-1,xn)}where pi is the syntactic relation between (non-prepositional) constituents xi and xi+1, and wi is theword used for xi.
An example from DIRT is:IF X is found in Y THEN X is inside YThe condition ?X is found in Y?
can be expressedas the clause chain:{ object-of(x,f), "find"(f), "in"(f,y) }We use DIRT to explore alternative interpretationsof the text, singling out those that help identify thefacts in the text that are already known in the KB.3.2 Deferred Sense CommitmentTwo common challenges for NLP are word sensedisambiguation (WSD) and semantic role labeling3(SRL).
While there are a number of existing toolsfor performing these tasks based on the linguisticcontext (e.g., Toutanova et al, 2008, Erk and Pado,2006), their performance is only moderate (e.g.,Agirre et al 2007).
The problem is accentuatedwhen trying to disambiguate in a way consistentwith a particular KB, because there is often a de-gree of subjectivity in how the knowledge engineerchose to represent the world in that KB (e.g.,whether some object is the "agent" or "instrument"or "site" of an activity is to a degree a matter ofviewpoint).
Trying to create a WSD or SRL mod-ule that reliably mimics the knowledge engineer?sdecision procedure is difficult.To address this, we defer WSD and SRL commit-ment during the initial text processing.
Instead,these ambiguities are resolved during the subse-quent stage of querying the KB to see if (some in-terpretion of) the text is already known.
One canview this as a trivial form of preserving under-specification (eg.
Pinkal, 1999) in the initial lan-guage processing, where the words themselvesdenote their possible meanings.3.3 Interpretation of New KnowledgeGiven some text, our system attempts to disam-biguate it by searching for (some interpretation of)its statements in the KB.
However, this will onlydisambiguate statements of facts that are alreadyknown.
For new facts, we fall back on traditionaldisambiguation methods, using a set of approxi-mately 100 hand-built rules for semantic role label-ling, and word sense disambiguation preferencestaken from WordNet sense frequency statistics andfrom the KB.
In addition, we use a simple filter todiscard apparently irrelevant/nonsensical assertionsby discarding those that use concepts unrelated tothe domain.
These are defined as those with wordswhose preferred WordNet sense falls under one ofa small number of hand-selected "non-biological"synsets (namely human_activity#n#1, mental_ob-ject#n#1, artifact#n#1, instrumentation#n#1, psy-chological_feature#n#1, device#n#1).
One mightalso be able to use a KB-guided approach to dis-ambiguation similar to that described for knownfacts, by (for example) looking for generalizationsof (interpretations of) new facts in the knowledgebase.
This is a direction for future exploration.4 Algorithm and Implementation4.1 Topics and ParticipantsFor now, we assume that all knowledge in the KBcan be represented by ?forall?exists??
state-ments, i.e., statements of the form:x isa(x,C) !y1..yn p1(v1,v2), ?, pq(vr,vs) [1](We will later discuss how this assumption can berelaxed).
pi are predicates in the KB?s ontology andeach vi is either a variable v"{x,y1,?,yn} or asymbol in the KB?s ontology.
We say clausespi(vj,vk) are about concept C, and that C is the topicof the clauses.
We also say that any instance yi thatis in some (possibly indirect) relationship to x is aparticipant in the representation of instance x of C.Thus all the yi in [1] are participants, plus theremay be additional participants implied by otheraxioms.
For some given instance X0 of C, we canidentify all the participants in the representation ofX0 by forward chaining from isa(X0,C) and col-lecting all the instances connected via some chainof predicates to X0.
We encode this using a par-ticipant(x,yi) relation2.
As this computation is po-tentially unbounded, we use a depth bound toheuristically limit this computation.4.2 Initial Language ProcessingAssume the system has a paragraph of text about atopic, and that it has identified what that topic is3.For example, consider that the topic is prophase (astep in cell division), and the paragraph is the sin-gle sentence:T: The mitotic spindle consists of hollow micro-tubules.Text is parsed using a broad coverage, phrasestructure parser (Harrison and Maxwell, 1986),followed by coreference resolution, producing a"syntactic" logical form, here:LF: "mitotic-spindle"(s), "consist"(c), "hollow"(h),"microtubule"(m), subject(c,s), "of"(c,m),modifier(m,h).2 We can formalize this by adding participant(x,yi) to the con-clusion in [1] for all yi, plus an axiom that participant is transi-tive.3 E.g., via some topic classification algorithm.
For our experi-ments here, we manually declare the topic.44.3 Semantic InterpretationTo interpret T the system then tries to answer, orpartially answer, the corresponding question:T: Is it true that the mitotic spindle consists of hol-low microtubules?Note that this question is in the context of the topic(prophase), and thus the mentioned objects are im-plicitly participants in prophase.
To do this, thesystem proceeds as follows, using a deductive rea-soning engine operating over the KB:(a) setup: create an instance X0 of the topic, i.e.,assert isa(X0,topic) in the KB, then find itsparticipants { y | participant(X0,y) }.
Next,bind one of the variables in the LF to a partici-pant that the variable's word might denote.
(b) query: for each clause in the LF with at leastone bound variable, iteratively query the KB tosee if some interpretation of those clauses areprovable i.e., already known.In this example, for setup (a) the system first cre-ates an instance X0 of prophase, i.e., assertsisa(X0,Prophase) in the KB, then finds its partici-pants Y0,...,Yn by querying for participant(X0,y).The participants Y0,Y1,?
will be instances of ob-jects and events known (in the KB) to be present inprophase, e.g., instances of Move, Centrosome,Elongate, Mitotic-Spindle, etc.
The system theninstantiates a variable in the LF, e.g., s in "mitotic-spindle"(s) with a participant that "mitotic spindle"might refer to, e.g., Y4, if Y4 is an instance of Mi-totic-Spindle.
The resulting LF looks:LF:"mitotic-spindle"(Y4),"consist"(c),"hollow"(h),"microtubule"(m), subject(c,Y4), "of"(c,m),modifier(m,h).For querying (b), the system uses the algorithm asfollows (on the next page):Y4:Mitotic-SpindleX0:ProphaseY0:Move Y1:CentrosomeY7:MicrotubuleY3:Elongate Y5:Polesubeventhas-part has-regionobjectobjectY8:Hollowshapeisa(Y4,Mitotic-Spindle), isa(Y8,Hollow), isa(Y7,Microtubule), has-part(Y4,Y7), shape(Y7,Y8).
"mitotic-spindle"(s), "consist"(c), "hollow"(h), "microtubule"(m), subject(c,s), "of"(c,m), modifier(m,h).isa(Y4,Mitotic-Spindle), "consist"(c), "hollow"(h), "microtubule"(m), subject(c,Y4), "of"(c,m), modifier(m,h)isa(Y4,Mitotic-Spindle), "hollow"(h), isa(Y7,Microtubule), has-part(Y4,Y7), modifier(Y7,h).isa(Y4,Mitotic-Spindle), ?part"(p), "hollow"(h), "microtubule"(m), subject(p,Y4), "of"(p,m), modifier(m,h).
(a)(b)(c)(d)(Graphical depiction of) (part of) the representation of Prophase:LF interpretation: New Knowledgehas-partY6:Create?Recognized Old KnowledgeFigure 2: The path found through the search space for an interpretation of the example sentence.
(a) setup(b) paraphrase substitution (c) interpretation of {subject-of(Y4,p),?part?(p),?of?
(p,m)} as has-part(Y4,m),preferred as it is provable from the KB, resulting in m=Y7 (d) interpretation of new knowledge (standardWSD and SRL tools).destinationY2:Eukaryotic-Cell?5repeatselect a clause chain Cu of ?syntactic?
clausesin the LF with at least 1 bound variableCu = {p(x,y)} or {w(x)} or{p1(x,z), w(z), p2(z,y)}select some interpretation C of Cu where:C is a possible interpretation of Cuor C'u is a possible paraphrase for Cu andC is a possible interpretation of C'utry prove C[bindings]  new-bindingsIf success:replace Cu with Cadd new-bindings to bindingsuntilas many clauses proved as possiblewhere:# A syntactic clause is a clause whose predicateis a word or syntactic role (subject, object,modifier, etc.)
All clauses in the initial LF aresyntactic clauses.# A clause chain is a set of "syntactic" clauses inthe LF of the form {p(x,y)} or {w(x)} or{p1(x,z), w(z), p2(z,y)}, where pi, w are wordsor syntactic roles (subject, modifier, etc).# A possible paraphrase is a possible substitu-tion of one syntactic clause chain with another,listed in the DIRT paraphrase database.# A possible interpretation of the singleton syn-tactic clause chain {w(x)} is isa(x,class),where class is a possible sense of word w.# A possible interpretation of a syntactic clausechain {p(x,y)} or {p1(x,z),w(z),p2(z,y)} isr(x,y), where r is a semantic relation corre-sponding to syntactic relation p (e.g., "in"(x,y)is-inside(x,y)) or word w (e.g., {subject-of(e,h), "have"(h), "of"(h,n)}  has-part(e,n)).Possible word-to-class and word-to-predicate map-pings are specified in the KB.As there are several points of non-determinism inthe algorithm, including the setup (e.g., whichclauses to select, which interpretation to explore),it is a search process.
Our current implementationuses most-instantiated-first query ordering plusbreadth-first search, although other implementa-tions could traverse the space in other ways.Figure 2 illustrates this procedure for the examplesentence.
The procedure iteratively replaces syn-tactic clauses with semantic clauses that corre-spond to an interpretation that is provable from theKB.
If all the clauses are proved, then the originaltext T is redundant; there exists an interpretationunder which it can be proved from the KB, and weassume under the benevolent user assumption thatthis is the interpretation that the user intended.If some syntactic clauses remain unproved, thenthey correspond to new knowledge, and a standardNLP pipeline is then used to interpret them.
In thisexample (Figure 2), the "hollow" modifier to themicrotubule Y7 was unproved, and was subse-quently interpreted by the NLP pipeline as theshape of the microtubule.
This new clause is con-verted into a (potential) addition to the KB byidentifying an axiom that concluded one of  theknown  connected facts (here, has-part(Y4,Y7)),and then proposing the new clause as an additionalconclusion of that axiom.
If there are no connectedclauses, it is instead proposed as a new axiomabout prophase.
The user can verify/reject thatproposal as he/she desires.5 IllustrationAn illustration of the system?s typical processingof a paragraph is shown in Figure 3.
As in Figure1, normal font shows facts recognized as alreadyknown, and bold shows new knowledge.
Againnote that the output facts are not a simple recitationof the input, but have been interpreted with respectto the KB.
For example, in (e), Create is the pre-ferred interpretation of "form", and in (d), has-partis the preferred interpretation of "consisting of", asthese result in the interpretation being provablefrom the KB.
Also note that new knowledge is an-chored to old, e.g., in (d), proteins are posited as anadditional part of the mitotic spindle participant ofprophase.There are several errors and meaningless state-ments in the output also.
For example, "somethingsignals" is not particularly helpful, and "the chro-mosome moves" is, although biologically correct, amisinterpretation of the original English "thechromosome is seen as...", with Move being a pos-sible interpretation of "see" (as in "I'll see you tothe door").
In addition some sentences were mis-parsed or unparsed, and some interpretations werediscarded as they involved non-biological con-cepts.
Many representational issues have beenskirted also, discussed shortly.6Topic: prophaseInput Paragraph:4During prophase, chromosomes become visible,the nucleolus disappears, the mitotic spindle forms,and the nuclear envelope disappears.
Chromo-somes become more coiled and can be viewed un-der a light microscope.
Each duplicatedchromosome is seen as a pair of sister chromatidsjoined by the duplicated but unseparated centro-mere.
The nucleolus disappears during prophase.In the cytoplasm, the mitotic spindle, consisting ofmicrotubules and other proteins, forms between thetwo pairs of centrioles as they migrate to oppositepoles of the cell.
The nuclear envelope disappearsat the end of prophase.
This signals the beginningof the substage called prometaphase.Output Axioms: (expressed in English)In all prophase events:d. The chromosome moves.e.
The chromatids are attached by the centro-mere.f.
The nucleolus disappears during the pro-phase.g.
The mitotic spindle has parts the microtubuleand the protein.h.
The mitotic spindle is created between thecentrioles in the cytoplasm.i.
The centrioles move to the poles.j.
The nuclear envelope disappears at the end.k.
Something signals.Figure 3: Illustration of the System?s Behavior6 Preliminary EvaluationTo make a preliminary assessment of how muchuseful information the system is producing, weconducted a small study.
10 paragraphs about pro-phase (from different Web sources) were runthrough the system (110 sentences in total).
Thesystem extracted 114 statements of which 23(20%) were interpreted as fully known (i.e., al-ready in the KB), 27 (24%) as partially newknowledge, and 64 (56%) as completely newknowledge.
The extracted statements were thenscored by a biologist as one of:c = correct; useful knowledge that should be inthe KB4 From http://www.phschool.com/science/biology_place/ bio-coach/mitosisisg/prophase.htmlq = questionable; not useful knowledge (mean-ingless, overly general, vague)i  =  incorrectThe results are shown in Table 1.Statements that are:FullyknownMixture ofknown & newFullynewCorrect 22 19 25Questionable 1 8 38Incorrect 0 0 1Table 1: Correctness of axioms proposed by thesystem.For the statements that mix old and new knowl-edge, 70% were judged correct, and for completelynew statements, 39% were judged correct.5 Thissuggests the system is at least producing some use-ful suggestions, and for the statements that mix oldand new knowledge, has identified the connectionpoints in the KB for the new facts.
Although thislevel of accuracy is too low for automation, it sug-gests the system might be a useful tool for helpinga knowledge engineer check that he/she has fullyencoded the contents of a passage when buildingthe KB, and performing those approved additionsautomatically.7 Discussion and ConclusionWe have described a method for reading "at thefringe" of what is known, leveraging existingknowledge to help in the reading process by treat-ing text interpretation as partial question answer-ing.
This approach is appropriate for situations inwhich a reasonable proportion of the text's contentis already known to (represented in) the KB.
Ourevaluation suggests that the approach has merit, atleast as an interactive knowledge acquisition tool.As we have suggested, existing knowledge canhelp guide and anchor interpretation, but to whatextent might it stifle the system from learninggenuinely new knowledge?
At present, our systemis unable to extend its own ontology (it can onlylearns axioms expressed using its existing ontol-ogy), and thus will skim over unrecognized words5 For the 1 statement already fully known but judged as ques-tionable, the score appears to be due to poor rendering in Eng-lish, the axiom being rendered as "The membrane breakdown."
rather than "The membrane breaks down.
".7even if those words reflect something new (withrespect to the KB) and important about the domain.The system is thus biased towards texts about con-cepts that it has at least heard of before (even if itknows little about them), expecting small, incre-mental additions of knowledge, rather than work-ing hard to untangle information about completelynovel topics.
It can learn about concepts it has al-ready heard of, but not, at present, learn new con-cepts.
While it would be simple to modify thesystem to treat any new word as a new concept,this may potentially overwhelm the system, and sosuch extensions would need to be made carefully.This is an area for future work.How large must the starting KB be?
Although itcan be missing (possibly many) axioms, we implic-itly assume that at least the basic ontology and themapping from words to concepts is reasonablycomplete (for the types of texts being considered),i.e., there is a good "skeleton" KB to add axiomsto.
Thus, methodologically, a first step for usingour system would be to create the initial ontologyand lexical mappings, e.g., via corpus analysis orusing an ontology learning tool  (Gomez-Perez andManzano-Macho, 2003).
Beyond that, the moreaxioms the starting KB has the better, as eachaxiom can potentially guide the interpretation of anew sentence.
In the limiting case, where there areno axioms (only the ontology and lexical map-pings), our system's behavior reverts to that of anormal, pipelined NLP interpreter (with the normalassociated problems).This work is still preliminary, and there are nu-merous other issues and limitations that need to beaddressed also.
Three notable issues are as follows:# Syntactic ambiguity: While we defer WSDand SRL commitment, our system is eagerlycommitting to a single parse during initial lan-guage processing, and that parse may bewrong.
An obvious extension is to similarlydefer some syntactic commitments until se-mantic interpretation, for example using anunderspecified or packed logical form (e.g.,Bobrow et al 2005) or exploring alternativeparses.# Interpretation of new knowledge: While ourapproach leverages the KB to interpret state-ments about known facts, and thus help findthe anchor points for new facts, those state-ments of new facts are still interpreted using atraditional pipelined approach, with all its as-sociated brittlenesses (as evidenced in the lastcolumn in Table 1).
Creative ways for usingthe KB to similarly help guide new fact inter-pretation are needed, for example searching theKB for generalizations or variants of thosefacts, and then preferring the interpretationsthey suggest.# Representational adequacy: Our work so farhas assumed a simple, deductive representa-tional framework of individual objects andevents, and correspondingly assumes the sameindividuality in language.
However the world,and language used to describe it, often goesbeyond this to include a miriad of representa-tionally difficult phenomena (sets, pairs, ag-gregates, conditionality, plausibility,constraints, etc.).
Our system largely skipsover such aspects, as it is unable to representthem.Despite these limitations, the picture of text inter-pretation as partial question-answering appears tobe a useful one, as it suggests a means by whichlanguage and knowledge can be connected.
We areoptimistic that it can be further developed and im-proved for better machine reading in the future.AcknowledgementsWe are grateful to Vulcan Inc. who partially sup-ported this work through Project Halo.ReferencesAgirre, E., Marquez, L., Wicentowski, R., Eds., 2007.Proceedings of the 4th International Workshop onSemantic Evaluations (SemEval), ACL, Prague,Czech Republic.Bentivogli, L., Dagan, I., Dang, Hoa, Giampiccolo, D.,Magnini, B.
2009.
The Fifth PASCAL RecognizingTextual Entailment Challenge.
In Proc Text AnalysisConference (TAC?09).Bobrow, D. G., Condoravdi, Crouch, R. Kaplan, R.Karttunen, L., King, L.T.H., de Paiva, V., Zaenen, A.2005.
A Basic Logic for Textual Inference.
In Pro-ceedings of the AAAI Workshop on Inference for Tex-tual Question Answering, Pittsburgh, PA.Carlson, A., Betteridge, J., Hruschka, E., Mitchell, T.2009.
Coupling Semi-Supervised Learning of Cate-8gories and Relations.
Proceedings of the NAACLHLT 2009 Workshop on Semi-supervised Learningfor Natural Language Processing.Clark, P., Harrison, P. 2010.
Exploiting Paraphraes andDeferred Sense Commitment to Interpret Questionsmore Reliably.
(Submitted).Dahlgren, K., Lord, C., Wada, H., McDowell, J., Sabler,E.
1991.
ITP: Description of the interpretext systemas used for MUC-3.
In Proc 3rd Message Under-standing Conference (MUC-3), pp163-170.DeJong, G. 1979.
Prediction and Substantiation: Twoprocesses that comprise understanding.
IJCAI?79,pp217-222.Dras, M., Yamamoto, K. (Eds).
2005.
Proc 3rd Interna-tionl Workshop of Paraphrasing.
South Korea.Erk, K., Pado, S. 2006.
Shalmaneser ?
a flexible toolboxfor semantic role assignment.
Proc LREC 2006,Genoa, Italy.Feigenbaum, E. 2003.
Some Challenges and GrandChallenges for Computational Intelligence.
Journalof ACM, 50 (1), pp 32-40.Gomez-Perez, A., Manzano-Macho, D. 2003.
"A Surveyof Ontology Learning Methods and Techniques",Technical Report, Univ Politecnica de Madrid (On-toWeb Deliverable 1.5, http://www.sti-innsbruck.at/fileadmin/documents/deliverables/Ontoweb/D1.5.pdf)Gunning, D., Greaves, M., Chaudhri, V. et al 2010.Project Halo Update ?
Progress Towards Digital Ar-istotle (Submitted).Harrison, P., Maxwell, M. 1986.
A New Implementa-tion of GPSG.
In Proc.
6th Canadian Conf on AI.Hobb, J., Stickel, M., Appelt, D., Martin, P. 1993.
Inter-pretation as Abudction.
In Artificial Intelligence 63(1-2), pp 69-142.Lin, D. and Pantel, P. 2001a.
Discovery of InferenceRules for Question Answering.
Natural LanguageEngineering 7 (4) pp 343-360.Lin, D. and Pantel, P. 2001b.
Discovery of InferenceRules in Text.
Proc ACM SIGKDD Conf on Know-eldge Discovery and Data Mining.Mulkar, R., Hobbs, J. Hovy, E. 2007.
Learning to ReadSyntactically Complex Biology Texts.
In Proc 8thInternational Symposium on Logical Formalizationsof Commonsense Reasoning (AAAI Spring Sympo-sium).Pinkal, M. 1999.
On Semantic Underspecification.
InBunt, H./Muskens, R.
(Eds.).
Proceedings of the 2ndInternational Workshop on Compuational Linguistics(IWCS 2).Riloff, E. 1996.
Automatically Generating ExtractionPatterns from Untagged Text.
Proc AAAI?96.Sekine, S. 2006.
On-Demand Information Extraction.Proc.
COLING-ACL.Toutanova, K., Haghighi, A., Manning, C. 2008.
AGlobal Joint Model for Semantic Role Labeling.Computational Linguistics, 34 (2).Zadrozny, W., Jensen, K. 1991.
Semantics of Para-graphs.
in Computational Linguistics 17 (2) pp171-209.9
