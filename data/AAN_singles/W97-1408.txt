Generating Referential Descriptions in Multimedia EnvironmentsHelmut HoracekUniversit~it des SaarlandesFB 14 InformatikD-66041 Saarbri.icken, Deutschlandhoracek@cs.uni-sb.deAbstractAll known algorithms dedicated to thegeneration of referential descriptions use naturallanguage alone to accomplish this communi-cative goal.
Motivated by some limitationsunderlying these algorithms and the resultingrestrictions in their scope, we attempt to extendthe basic schema of these procedures to multi-media environments, that is, to descriptionsconsisting of images and text.
We discussseveral issues in this enterprise, including thetransfer of basic ingredients to images and thehereby reinterpretation f language-specificconcepts, matters of choice in the generationprocess, and the extended application potentialin some typical scenarios.
Moreover, we sketchour intended area of application, the identifi-cation of a particular object in the large visuali-zation of mathematical proofs, which has somecharacteristic properties of each of thesescenarios.
Our achievement lies in extendingthe scope of techniques for generating refer-ential descriptions through the incorporation ofmultimedia components and in enhancing theapplication areas for these techniques.1 IntroductionAll known algorithms dedicated to the generation of refer-ential descriptions !
use natural language alone toaccomplish this communicative goal.
This task by itselfis difficult enough, as a variety of achievements obtainedthrough intensive research demonstrate:?
finding an adequate interpretation of minimalityconcerning the components of the referring expressionto be produced; this interpretation should satisfycomputational aswell as psychological requirements,The term 'referential description' is due to Donellan(Donellan, 1966).
This notion signifies a referringexpression can serve the purpose of letting the heareridentify a particular object out of a set of objectsassumed to be in the current focus of attention.?
achieving a reasonable coverage through integratingrelations to other referents, controlled recursion, andpsychologically motivated concepts, such as inferabi-lity and basic level categories into the description, and?
enabling flexible processing through measurementsthat allow for a widely free descriptor choice and thatensure xpressibility of the chosen set of descriptors innatural language terms in a reasonable way.Despite these achievements, all existing algorithms tillhave some serous limitations which originate from:1.
An implicit, simplifying assumptionThe addressee is not only assumed to understandfamiliar terms that appear in a description, but he/sheis also assumed to be able to recognize the associatedobject properties under all environmental conditions.2.
A crucial concept missingIn addition to identificational properties, also naviga-tional information would be urgently needed forobtaining comprehensible d scriptions (see (Reiter,Dale, 1992)).
In larger environments, when referentialdescriptions could easily become too complex, thealgorithms may easily fail to behave adequately.We believe that extending these algoithms to envir-onments where not only language xpressions, but alsoannotated images contribute to a referential descriptioncould not only make many descriptions simpler, but alsomore reliable (see the first item above) and wider applic-able (see the second item above).
In our enterprise to adaptthe basic schema underlying these algorithms to multi-media environments, we discuss everal issues, including?
the transfer of basic ingredients o images,?
the reinterpretation of language-specific concepts,?
matters of choice in the generation process, and?
the extended application potential of multimedia.This paper is organized as follows.
We first review themain concepts hared by the existing algorithms.
Then wedescribe how these concepts can be transferred to images,and we discuss their incorporation i to a process chemaunderlying the existing algorithms.
We also outline thepotential of extensions obtained through combining iden-tificational and navigational information.
Finally, wedemonstrate a typical example from the area of proofpresentation, which is our intended omain of application.2 Basics of Existing AlgorithmsBasically, the issue of producing a distinguishingdescription requires electing a set of descriptors accordingto criteria which reflect humans preferences and verbal-izing these descriptors while meeting natural languageconstraints.
Over the last decade, (Dale, 1989, Dale,Haddock, 1991, Reiter, 1990b, Dale, Reiter, 1995), andothers 2 have contributed to this issue (see the systemsNAOS (Novak, 1988), EPICURE (Dale, 1988), FN(Reiter, 1990a), and IDAS (Reiter, Dale, 1992)).Recently, we have introduced several improvements othese methods (Horacek, 1996, 1997).In some more detail, the goal is to produce a referringexpression that constitutes a distinguishing description,that is a description of the entity being referred to, but notto any other object in the current context set.
A contextset is defined as the set of entities the addressee iscurrently assumed to be attending to - the contrast set isthe same except o the intended referent; an equivalentterm is the set of potential distractors (McDonald, 1981).This is similar to the set of entities in the focus spaces ofthe discourse focus stack in Grosz and Sidner's theory ofdiscourse structure (Grosz, Sidner, 1986).
The existingalgorithms attempt o identify the intended referent bydetermining a set of descriptors attributed to that referent,that is, a set of attributes.
Some algorithms also includedescriptors in the description that are attributed to otherentities related to the original referent, that is, relationsfrom the point of view of the intended referent.
Attributesand relations by themselves are mere predicates which stillneed to be mapped onto proper lexical items, not neces-sarily in a simple one-to-one fashion.
Some of the asso-ciated problems and a proposal to systematically incor-porate this mapping are described in (Horacek, 1997).Viewed in procedural terms, the algorithms have toconsider three issues:1.
A cognitively motivated pre-selection of descriptors,which is based on psychologically motivated criteriathat should reflect human preferences.2.
The ultimate selection of descriptors, which canoverrule the cognitively motivated pre-selection ofthe next descriptor due to linguistic phenomena suchas implicature and due to other interference problemswith previously chosen descriptors.3.
Adequately expressing the chosen set of descriptors inlexical terms.The approach undertaken by Appelt and Kronfeld(Appelt, 1985a, Appelt, 1985b, Kronfeld, 1986,Appelt, Kronfeld, 1987) is very elaborate but it suffersfrom limited coverage, missing assessments of therelative benefit of alternatives, and notorious ineffi-ciency.The first two issues are rather well understood for attri-butes only, but not so much for relations.
The third issueis widely neglected - it is simply assumed that the chosenset of descriptors can be expressed adequately.For some time, there was a debate about various opti-mization criteria for comparing the suitability of alter-native sets of descriptors, but we feel this issue is settlednow in favor of the incremental lgorithm interpretation(Reiter, Dale, 1992): preferred escriptors are sequentiallyincluded in the referring expression to be producedprovided each descriptor leads to the exclusion of at leastone potential distractor.
In comparison to other interpre-tations, it is the weakest one; it has still polynomialcomplexity but it is independent of the number of attri-butes available for building a description.3 Concepts in Existing AlgorithmsAbstracting from details, the algorithms producing adistinguishing description rely on three basic concepts:?
the notion of a focus space, which delimits the scopein which referents and related entities are to be found,?
the notion of a descriptor, by which referents can bedescribed and ultimately identified,?
the notion of a context set, which helps distinguishingreferents from one another on the basis of sets ofdescriptors.In addition, a number of issues are taken into account bythese algorithms in one or another way:?
incorporating phenomena, such as basic-level cate-gories for objects and inferability of properties, suchas non-prototypicality of mentioned properties,?
search strategies and complexity considerations, suchas  interaction between pre-selection and ultimateselection and choices among local referent candidates(selecting among alternative relations as descriptors),?
adequate xpressibility of the chosen set of descriptors,in terms of naturally composed surface expressionsthat convey the intended meaning, thereby avoiding,for instance, scope ambiguities or misinterpretations.In the following, we attempt o transfer the basicconcepts to multimedia environments or, in case wherethis is not possible in a meaningful way, we propose areasonable r interpretation better suited to images.4 Transferring Basic ConceptsAs far as the notion of a focus space is concerned, thetransfer seems to work in a widely straightforwardmanner.
Given some image of a scenery in which someobject is to be identified, the focus space is simply theentire picture.
There is, however, a principled ifferencein the way how a focus space is established for concreteimages and for abstract language contexts: in a pureIIlanguage environment, the conversational settingdetermines which referents are considered to be within thefocus space, which may occasionally be unclear for a fewreferents.
In a multimedia environment, this depends onsome application properties.
If a specific picture consti-tutes the situational context, the area and the shape of thatpicture are precisely determined, as is the associated focusspace.
Otherwise, the precise boundaries of the image andthe associated focus space are subject to minor uncer-tainties, as in the abstract linguistic context.The next ingredient to consider are the descriptors,which reveal a fundamental difference between texts as anabstract medium and images as a concrete medium.
Trans-ferring the notion of a descriptor to images in a direct waywould lead to a very unnatural way of communicatingidentificational information by a picture, especially whenseveral descriptors are to be presented in sequence toachieve the ultimately intended identification goal.
Actingthis way would mean that all objects to which the firstdescriptor applies must be highlighted in some way, thenall to which also the second descriptor applies, and soforth.
Obviously, this procedure would be more confusingthan helpful to an observer.
Moreover, simply high-lighting the intended referent might do the job, but thisaction alone may not always work satisfactorily, if theintended referent is badly recognizable or even invisible.Because of the inadequacy of adapting the notion of adescriptor to images in a direct fashion, we consider analternative way of describing the intended referent: aregion of the picture where the intended referent can befound or, at least, whose identification helps in findingthe intended referent.
More precisely, a region can eitherbe the area minimally surrounding a specific object, or itcan merely be some connected area, specified by itssurroundings or by a pointer to a central position in thatarea.
In the first case, the area is precisely defined, but itmay be considerably vague in the second case.In some sense, regions and descriptors cover the focusspace in an orthogonal way: while the former cover aconnected area on a picture, the latter typically appearthere as a set of islands.
As opposed to that, a descriptorcovers a connected area in the abstract descriptor-referentspace, while a region typically appears there as a set ofislands.
In some occasions, locality descriptors may do asimilar job as regions, but this would probably be lesseffective in many cases, when multiple localitydescriptors are required.
As a consequence, the selection ofan adequate region differs in some crucial sense from theselection of an adequate descriptor: acandidate descriptoris chosen from a set of distinct alternatives, while deter-mining a candidate region is more a matter of accuracyand precision in terms of appropriately fixing the border-lines of the region which lies around the intended referentor some other entity related to it.
Altogether, a regiontypically comprises the equivalent of several descriptorsas far as the contribution to the identification task isconcerned: either a category of the object enclosed by theregion, accompanied by a set of further descriptors, ifnecessary, or a suitable combination of localitydescriptors.Once we have "reinterpreted" the notion of a descriptorin terms of regions as building elements of distinguishingdescriptions for images, we have to deal with regions incomputing the context set.
For this concept, extendingthe algorithm does not prove to be difficult.
Since both,descriptors and regions restrict he context set in view ofthe entire focus space or some previously restricted part ofit, although in a complementary way, the computation ofthe context set modified by a newly introduced regionworks analogously to the pure language nvironment.5 Changes in the AlgorithmsWhen extending the existing algorithms to multimediaenvironments, we discuss choices between regions anddescriptors as well as their coordination in the existingprocessing schema.
We first restrict our considerations tosingle images - allowing the incorporation of multipleimages might easily complicate matters o that temporalpresentation aspects additionally come into play, requiringthe design of animations.
Nevertheless, accomplishingthe communicative goal in an environment consisting ofa single image only is not always trivial in the sense thatthe intended referent just needs to be annotated orhighlighted in some way.
That entity may be invisible orbadly recognizable so that pointing at it is simplyimpossible or unlikely to convey the message properly.As far as the issues involved in composing adescription are concerned, some crucial differencesbetween the media considered exist.
Basic-level categoriesare exclusively relevant for language, and inferability is,apart from language, relevant for abstract images only.The expressibility issue, when being reinterpreted forregions of an image, yields problems, too, but they areentirely different from the expressibility problems inlanguage generation: for images, visibility and variousaspects of recognizability, such as sufficient degrees ofsalience in terms of shape, granularity, and brightnesscome into play.
Judging the adequacy of these aspects is atypical issue in presenting information by a picture and,hence, can be considered the visual counterpart ofexpressibility on the language side.When choosing between a descriptor and a region astwo candidates to focus on some portion of the envir-onment, some principled preferences seem to be plausiblewhen brevity of the resulting expression is envisioned:?
An 'exact' region, taken by a specific object, isprobably better conveyed by the picture component,especially if several similar objects are in the focus ofattention.?
However, if the object is either very small (almostinvisible) or extremely large (almost covering theentire focus space), choosing language as the mediumseems to be more appropriate.?
A 'generic' region, that is, a region which nearlyperfectly fits a locality descriptor (see (Gapp, 1995)for an operationalization f degrees of applicability),is better described by language, especially when someother region can be used more beneficially as acomponent of the referential description.?
For ordinary regions, however, images are generallythe preferred medium.In addition to the choice between a descriptor and aregion as the next ingredient for narrowing the focusspace, adequate coordination of the participating media isa crucial concern.
In our environment, this task is largelysimplified because of the restriction to a single image.However, at least some sort of annotation should begiven to support he coherence of the overall description.In more complex cases, several regions of an image needto be coordinated as well, which might even require theirtemporal synchronization.In addition to dealing with these local preference andchoice criteria, we need to incorporate the selectionamong descriptors and regions into a process whereseveral selections are made in a coordinated way until theintended referent is identified.
This process hould widelyfollow the schema based on the incremental algorithminterpretation of minimality of the number of descriptors.By adopting this schema, we maintain the psycholo-gically motivated search strategy and the reasonablecomputational complexity associated with that schema.Since descriptors and regions are fundamentallydifferent, a multimedia version of the algorithm requirestwo choice components o be designed, one for choosingthe best descriptor, and the other for choosing the bestregion.
In addition, a referee component could be designedto make the final decision.
Such choices could be repeateduntil a region has outscored its competing descriptor oruntil the communicative goal is accomplished.
This way,a region can describe the intended referent directly orindirectly, that is, in terms of other entities.
Becauseregions may have an entirely different contribution to therestriction of the focus space, a region is usually a properalternative to a descriptor, ather than a mere substitute.In view of the environment hat is given by acommon focus space, that is, by a single image, asimpler strategy may even turn out to be better: a regionconsidered most suitable is selected by the responsiblecomponent, and, if necessary, further descriptors areselected until the communicative goal is achieved.
Apartfrom these descriptors, the language part of thedescription should also entail a reference to the pictorialpart, such as an object category or a deictic reference tothat region.
Even if the region alone already accomplishesthe communicative goal, such a reference phrase shouldbe built, in order to clarify the purpose of highlightingthe region.
The rationale behind this strategy is that in asingle image one region is usually sufficient o restrictthe context set as much as possible by the pictorialcomponent.6 Extending the Algorithm's CoverageSo far, we have only considered environments consistingof a single image and language descriptions.
If we moveon to more complex environments in which severalimages may contribute to a description, we are definiti-vely leaving the scope of the existing algorithms, sincewe are not just facing a single focus space, but a set or achain of focus spaces (when considering only one imageat a time).
The connection among these focus spaces mayvary significantly according to the way how the corres-ponding images interact.
The following constellationsseem to be of interest:1.
An image and some sort of a focused partThere could be an image providing a global view of ascenery, combined with images presenting views onportions of that scenery that are invisible on theoverview.
The subsidiary images may present referentsbehind an obstacle, or inside some other object, orobjects only partially visible in the overview.Moreover, we could be confronted with an image thatshows some portion of a larger image (such as aportion of a large map), and the intended referent islocated in another part of the whole image.
In order tonavigate between disjoint portions of a picture, twostrategies eem to be promising: either presenting asequence of pictures that gives some impression ofscrolling, or presenting an overview first beforemoving on to the part that entails the intendedreferent.
In both cases, these images contribute tobridging differences in locality.2.
An abstracted view and some concrete imagesThere could be an abstract image providing anoverview of some sort (such as the map of a city) andseveral concrete images that refer to one or anotherpart of the abstract image (such as a group ofbuildings or a square in the city).
The abstract imagemay then be used to direct the addressee's attention toa particular area of the focus space, while the concreteimages upport he proper identification task.3.
Images in largely varying degrees of granularityThere could be an image providing an overview of alarge scenery in which individual objects appear in atoo small size to be recognizable.
In addition to thestrategy applied to the abstract overview and theconcrete images, a smoother transition seems to be apromising alternative.
Depending on the degree ofcondensation between the overview image and imagesthat present objects in an easily recognizable format,using a few images of intermediate size might be asuitable means to support orientation.In order to make these concepts more concrete, a lot oftesting in connection with concrete applications isrequired.
Moreover, it seems to be much harder to formu-late a reasonably concrete schematic procedure and suitablecriteria for a multimedia version of the algorithmsdiscussed, because images are associated with a higherdegree of freedom than language.
However, if we comparethe discussion in this section with the originalenvironment underlying the generation of referentialdescriptions, it becomes apparent that we have left thescope of what is commonly considered as the task ofgenerating referential descriptions in a number of places -but such an effect may easily happen in extending amethod to multimedia environments.7 Our Future Application AreaIn the near future, we intend to apply our approach tointerface a graphical component by which we canvisualize machine-generated mathematical proofs andrelated ata structures.
The task of our present interest, theidentification of a particular object in the trace of a proof,is one of the issues in presenting mathematical proofs inmultimedia environments.
In some occasions, evengroups of objects and their relations to one another maybe subject to identification, which constitutes anotherkind of extension to the algorithms for generating refer-ential descriptions.Proof presentation is realized within the mathematicalassistant 12~nega (Benzmiiller et al, 1997), an interactiveenvironment for proof development.
Within ~mega,automated prover components such as Otter (McCune,1994) can be called on problems considered as manageableby a machine.
The result is a proof tree which needs to befundamentally reorganized prior to presentation, becausethe refutation graph underlying the original proof is muchtoo detailed to be comprehensible to humans, even toexperts in mathematics.
Therefore, an appropriate l vel ofgranularity is selected by condensing roups of inferencesteps to yield proofs built from "macro-steps", which ismotivated by rules of the natural deduction calculus(Gentzen, 1935).
This is called the assertional level anddealt with in detail in (Huang, 1996).
A typical exampleof an assertion level step is e.g., the application of alemma.
Once a proof is transformed to the assertionallevel, it can be verbalized suitably by the Proverb System(Huang, Fiedler, 1996).
Another possibility to present aproof is to visualize the proof tree, which is the kind ofpresentation we address in this paper.Even at the assertional level, traces of machine-foundproofs may grow very large even for problem of mediumcomplexity.
Therefore, a number of measurements tosupport identification are required, for instance, movingfrom an overview of the proof tree to a focused part of it.Moreover, moving from abstract to concrete nvironmentsmay apply here to cases where the object to be identifiedlies in some detailed information about axioms ortheorems, to which some node in the trace gives access.The following Figures show the trace of a moderatelycomplex proof.
The proof demonstrates the truth of thefollowing axiom: the transitive closure of the union oftwo sets is identical to the transitive closure of the unionof the transitive closures of the two sets, in terms offormulas: (p u t~)* = (p* u ~*)*.
Figure 1 shows anoverview of the whole proof, and Figures 2 and 3 selectedportions of it, at a larger size.
While individual nodes arestill identifiable in the proof tree overview in Figure 1,the recognizability of nodes may easily be lost in largerproof trees, which motivates focusing on tree portions.Figure 1: An overview of a proof treeIn these proof trees, a root node represents the lemma tobe proved (a root node of a subtree represents omesupporting lemma), and the leaf nodes representassumptions, axioms, or coreferences to specific subtreesin the proof.
Moreover, proof derivations join nodes andtheir successors in upward direction.
The geometricfigures in the proof tree represent types of nodes: circlesstand for ordinary nodes, triangles for assumptions oraxioms, and squares for coreferences.
The annotations inthe Figures are made here by hand, to illustrate focusedsteps in the proof.
In the implementation, a formula asso-ciated with an individual node can be viewed by clickingon that node so that the formula appears in a separatewindow (though in a less convenient predicate-like formatrather than in the more common mathematical notation).In addition, the formulas are marked by numbers that alsoappear in the corresponding node of the proof tree.As an adds-on to this graphical presentation, we intendto incorporate a variety of interactive xplanation facil-ities.
One part of these facilities comprises various sortsof identification issues:?
one specific object in the proof tree,?
some formula or subformula ssociated with a specificnode in the proof tree; this constellation is an instanceof a concrete entity associated with some part of anabstract overview - see the second item in theextension categories introduced in Section 6,?
a formula associated with a specific node in the prooftree or some part of it, that is not shown in thevisible portion of the tree; this constellation is aninstance of a referent hat lies outside the scope of thefocus space - see the first item in the extensioncategories,?
some part of a formula associated with a specific nodein the proof tree, which appears in a too small size tobe recognizable; this is an instance of a referent whichneeds to be zoomed at to be recognizable - see thethird item in the extension categories.Moreover, multiple objects may be subject to any ofthe above identification issues.
In the following, we illus-trate these identification categories by a few examplesincluding suitable graphical displays and associated verbaldescriptions.Let us assume that the whole proof tree (as anoverview) is in the current focus of attention, and the userasks: "Where is the lemma '((x .~ y) ^  (y transitive))(x* G y)' used in the proof?"
As an answer, the regionswhere the three instantiations of this lemma appear in theproof are marked (see the arrows labeled by 1 in Figure1), and their instantiations are given as formulas in theassociated verbal description.
Moreover, the regions ofone or several of these instantiations could be illustratedby a focused picture, such as in Figure 2.
A suitableaccompanying verbal description would be: "That lemmais applied three times (see the annotations in the overviewlabeled by 1), one of these instantiations appears in thepart proving (p u o0" ~- (19" u t~ ) , where x is instan-tiated to c 1 and y is instantiated to (c I u c2)*, (see theannotation in the enhanced tree portion, corresponding tothe tree portions marked by 1 in the overview).
"If this description is followed by a subsequent question"How is the subset definition applied here?
", the pictorialpresentation needs to move to an adjacent portions of theproof tree, because the referent to be identified lies outsidethe subtree shown in Figure 2.
The overview is then,i((c I c_ (c I u c2)*) ^((C 1 U C2)* transitive))(c1" c (c~ u c2)*),iC l ~ (C l k..) C2)* 'q'---"Figure 2: A portion of a proof tree showing an axiom Figure 3: A portion of a proof tree showing a definitionshown again, and the annotation in Figure 3 providesadditional information, in terms of the instantiations ofthis definition.
A suitable verbalization would be "Thatlemma is proved in an adjacent part of the tree, where c Ic (c I w c2)* is proved, as indicated in the overview (seethe annotation labeled by 2 and the tree portion marked by2 in the overview).
The subset definition is instantiated toc I and (c I u c2)*, respectively.
"We believe that these moderate sketches alreadydemonstrate he usefulness of multimedia presentations inthe task envisioned.
Finally, these examples illustrate thefollowing observations:?
Choices between media become ven richer throughthe possibility to incorporate annotations, whichoffers itself in the domain of mathematics.?
The identification task is tightly interwoven withproviding additional, descriptive information, whichwe feel to be typical in realistic domains.?
While many of the details in proof presentation arehighly domain-specific, the general lines in identifyingobjects in multimedia environments are valid across anumber of domains.
However, a characteristic featurethat limits the generality and at the same time greatlyhelps in referring to portions of the proof tree is itsstrictly hierarchical organization, which may bepresent in some, but not in many other domains.In any case, future experience will tell us more aboutidentification techniques in multimedia environments,especially concerning the contribution of each presen-tation mode and their coordination, as well as aboutdegrees of domain-dependence and independence of thetechniques involved.8 ConclusionIn this paper, we have discussed multimedia extensions toalgorithms for generating referential descriptions.
In doingthis, we have reinterpreted major concepts used in thelanguage-specific algorithms for multimedia envir-onments, which has led to the introduction of regions toidentify portions of an image as a counterpart to thelanguage-specific descriptors.
In addition to incorporatingregions into a descriptions building process, we havecategorized some sorts of extensions to the basic form ofthis process, including the coordination of abstract andconcrete images, as well as images of varying size andgranularity.
We also have exemplified these extensions byapplying our techniques to aspects of the presentation ofmathematical proofs.
Even these preliminary examplesdemonstrate he enhanced application potential and theextended scope of our method.AcknowledgmentThe graphical proof visualization component by which theproof tree representations depicted in this paper areproduced has been designed and implemented by StephanHess.
Work on this component is going on.ReferencesDoug Appeit.
1985a.
Planning English ReferringExpressions.
Artificial Intelligence, 26:1-33.Doug Appelt.
1985b.
Some Pragmatic Issues in thePlanning of Definite and Indefinite ReferringExpressions.
In 23rd Annual Meeting of the Associationfor Computational Linguistics, pages 198-203.
Asso-ciation for Computational Linguistics, Morristown,New Jersey.Doug Appelt, and Amichai Kronfeld.
1987.
AComputational Model of Referring.
In Proceedings ofthe lOth International Joint Conference on ArtificialIntelligence, pages 640-647, Milano, Italy.Robert Dale.
1988.
Generating Referring Expressions in aDomain of Objects and Processes.
PhD Thesis, Centrefor Cognitive Science, University of Edinburgh.Robert Dale.
1989.
Cooking Up Referring Expressions.In 27th Annual Meeting of the Association for Compu-tational Linguistics, pages 68-75, Vancouver, Canada.Association for Computational Linguistics, Morris-town, New Jersey.Robert Dale, and Nick Haddock.
1991.
Generating Refer-ring Expressions Involving Relations.
In Proceedings ofthe European Chapter of the Association for Compu-tational Linguistics, pages 161-166, Berlin, Germany.Christoph Benzmi.iller, Lassaad Cheikhrouhou, DetlefFehrer, Armin Fiedler, Xiaorong Huang, ManfredKerber, Michael Kohlhase, Karsten Konrad, AndreasMeier, Erica Melis, Wolf Schaarschmidt, J6rgSiekmann, and Volker Sorge.
1997.
Omega: Towards aMathematical Assistant.
To appear in Proceedings ofConference on Automated Deduction, Perth, Australia.Robert Dale, and Ehud Reiter.
1995.
ComputationalInterpretations of the Gricean Maxims in the Generationof Referring Expressions.
Cognitive Science, 19:233-263.K.
Donellan.
1966.
Reference and Definite Description.Philosophical Review, 75:281-304.G.
Gentzen.
1935.
Untersuchungen i.iber das logischeSchliel3en.
Mathematische Z itschrift 39.Klaus-Peter Gapp.
1995.
Efficient Processing of SpatialRelations in General Object Localization Tasks.
InProceedings of the Eighth Australian Joint Conferenceon Artificial Intelligence, Canberra, Australia.Linguistics, pages 97-104, Pittsburgh, Pennsylvania.Association for Computational Linguistics, Morris-town, New Jersey.Ehud Reiter.
1990b.
Generating Descriptions that Exploita User's Domain Knowledge.
In R. Dale, C. Mellish,M.
Zock, editors, Current Issues in Natural LanguageGeneration, pages 257-285, Academic Press, New York.Barbara Grosz, and Candace Sidner.
1986.
Attention,Intention, and the Structure of Discourse.
Compu-tational Linguistics, 12:175-206.Helmut Horacek.
1996.
A New Algorithm for GeneratingReferring Expressions.
In Proceedings of the 8thEuropean Conference on Artificial Intelligence, pages577-581, Budapest, Hungary.Helmut Horacek.
1997.
An Algorithm for GeneratingReferential Descriptions With Flexible Interfaces.
In35th Annual Meeting of the Association for Compu-tational Linguistics, Madrid, Spain.
Association forComputational Linguistics, Morristown, New Jersey.Xiaorong Huang.
1996.
Translating machine-generatedresolution proofs into ND-proofs at the assertion level.In Proceedings of Pacific Rim Conference on ArtificialIntelligence, pages 399-410, LNAI 1114, Springer.Xiaorong Huang, and Armin Fiedler.
1996.
PresentingMachine-Found proofs.
In Proceedings of the 13thConference on Automated Deduction, pages 577-581,Budapest, Hungary.Ehud Reiter, and Robert Dale.
1992.
Generating DefiniteNP Referring Expressions.
In Proceedings of theInternational Conference on Computational Linguistics,Nantes, France.Amichai Kronfeld.
1986.
Donellan's Distinction and aComputational Model of Reference.
In 24th AnnualMeeting of the Association for ComputationalLinguistics, pages 186-191.
Association for Computa-tional Linguistics, Morristown, New Jersey.W.
McCune .1994.
Otter 3.0 Reference Manual andGuide.
Technical Report ANL-94/6, Argonne NationalLaboratory.David McDonald.
1981.
Natural Language Generation as aProcess of Decision Making Under Constartints.
PhDThesis, MIT.Hans-Joachim Novak.
1988.
Generating Referring Phrasesin a Dynamic Environment.
In M. Zock, G. Sabah,editors, Advances in Natural Language Generation, Vol.2, pages 76-85, Pinter publishers, London.Ehud Reiter.
1990a.
The Computational Complexity ofAvoiding Conversational Implicatures.
In 28th AnnualMeeting of the Association for Computational
