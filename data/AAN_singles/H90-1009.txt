Interactive Multimedia Explanation forEquipment Maintenance and RepairKathleen McKeown and Steven FeinerDepartment ofComputer Science450 Computer Science BuildingColumbia UniversityNew York, N.Y. 10027IntroductionCOMET (COordinated Multimedia ExplanationTestbed) is an experimental system that generates inter-active multimedia explanations of how to operate, main-tain.
and repair equipment.
Our research stresses thedynamic generation of the content and form of all materialpresented, addressing issues in the generation of text andgraphics, and in coordinating text and graphics in an in-tegrated presentmJon.COMET coDtain~ a static knowledge base describingobjects and plan for maintenance and repair, and adynamic knowledge source for diagnosing failures.
Amenu interface allows users to request explanations ofspecific procedures and to specify failure symptoms thatwill invoke a diagnostic omponent.
The diagnostic om-ponent can ask the user to carry out procedures thatCOMET will explain if requested.
In contrast o hyper-media systems that present previously authored material,COMET has underlying models of the user and context thatallow each aspect of the expl~nation generated tobe basedon the currant situation.In this paper we discuss recent progress on COMET,including the development of an interface for user input,the integration of its individual modules into a workingsystem, and further zesults in our work on the media coor-dinator, the text generator, and the graphics generator.System OverviewCOMET consists of the major components illustrated inFig.
1.
On receiving a request for an explanation, thecontent planner uses text plans, or schemas, to determinewhich information should be included from the underlyingknowledge sources in the explanation.
COMET uses threedifferent knowledge sources: a static representation f thedomain encoded in LOOM \[11\], a rule-base learned overtime \[2\], and a detailed geometric knowledge base neces-sary for the generation of graphics \[12\].
The content plan-ner produces the full content for the explanation,represented asa hierarchy of logical forms (LFs) \[I\], whichare passed to the media coordinator.
The media coor-dinator refines the LFs by adding directives indicatingwhich portions ate to be produced by each of a set ofmedia-specific generation systems.
The text generator andI gNOWt.E\]~EI~ReQ:  iwA~rl?
OYN&Ia~ CtL.F.k~NB~Figure 1: COMET system architecture.graphics generator each process the same LFs, producingfragments of text and graphics that are keyed to the LFsthey instantiate.
This output is combined by the medialayout component, which formats the final presentation forthe low-level rendering and typesetting software.
Much ofour work on COMET has been done in a maintenance andrepair domain for the US Army AN/PRC-119 portableradio receiver-trausmitter \[3\].Currently, the system runs in parallel on five Sun andl ip machines, one for each of COMET's mostcomputation-intensive modules, which communicatethrough pipes.
A user interacts with COMET through anX l l  menu interface, using menus that are created on the flyby the system.
At the highest level, the user can choose torequest an explanalion for an explidt repair proceduredirectly or can specify that troubleshooting help is needed.When help is requested, the underlying diagnostic systemis invoked and the user is asked to specify symptoms of thefailure from the menu shown in Fig.
2.
In the course ofFigure 2: Menu of symptoms.42Figure 3: One display from an explanation generated bydiagnosing the failure, COMET will ask the user to carryout certain troubleshooting procedures.
For example, ff theuser indicates a loss of memory in the radio, COMET willgenerate a multiple-step test procedure.
Each step is shownsequentially on the display.
The user can request an ex-planation of any step, or can move forward or backward inthe generated explanation, by using the menu interface.Figure 3 shows one display from an explanation generatedby COMET.Media CoordinationIn previous work [6] we focused on three features of ourmedia coordinator: the use of a common content descrip-tion language by each media-specific generator, allowinggoals and information to be mapped to media-specificresources; the ability to make a fine-grained ivision ofinformation between media; and the ability for informationexpressed in one medium only to influence the realizationof information in the other.
In this paper, we describe ourrecent advances in coordinzting sentence breaks with pic-ture breaks.Informal experiments hat we carded out when design-ing the media coordinator indicated that our subjectsstrongly prefer sentence breaks to coincide with picturebreaks [10].
While more than one sentence may appearwith a single picture, there was a strong objection to sen-tences that run across picture boundaries.
For example, inFig.
3, users would prefer a sentence break to correspond tothe two pictures: "Loosen the captive screws."
and "Pullthe holding battery cover plate off of the radio."
Coor-dinating sentence and picture breaks requires bidirectionalinteraction between the text and graphics generators sinceCOMET.graphical constraints on picture size may sometimes forcedelimitation of sentences, while grammatical constraints onsentence construction may sometimes control picture size.Our implementation of sentence-picture coordination in-volves three stages of processing.In the first stage of processing, text and graphicsgenerators separately annotate their own copies of the LFto indicate minimal sentence and picture break locations.In our current implementation, when the verb for the sen-tence is selected, the text generator annotates the LF toindicate the grammatical sentence with the smallest numberof constituents hat can be formed.
The lexicon containsthe required set of inherent roles for each verb; these arethe case roles that must be present o form a grammaticalsentence.
For example, when the verb "reinstall" isselected, there are two required inherent case roles, theagent and the medium (note that the agent can be omittedin imperative sentences).
Thus, the sentence "Reinstall theprimary battery.'"
is perfectly grammatical.
However, ifthe verb "return" is selected, there are three required in-herent case roles: agent, medium, and to-location.
Thus,while the sentence "Return the primary battery to theradio."
is acceptable, "Return the prirneay battery."
is notin this context.
The text generator will Annotate the LFcorresponding to these two sentences differently when theverb is selected.
If "reinstall" is selected, the attributesagent and medium are each annotated with an attributeindicating that it is required.
If "return" is selected, theto-ioc role is also annotated.In the second stage of processing, ff the text generatorhas a choice of verbs, it will check the graphics generator's43placement of picture brenks.
For example, if there is noreason to select "return" over "reinstall", then the textgenerator will read the graphics generator's copy of the LFby nnifying it with its own.
This has the effect of addingthe graphics annotations to the text generator's copy.
Iftwo pictures were used to express the action (e.g., one forthe installing action and a second to indicate the location),text would select "reinstall" and would generate a secondsentence to accompany the second picture that conveys thelocation (e.g., "Place it on the radio socket.").
However,if a single picture expressing both the installation actionand location were generated, then the verb "return" wouldbe selected and a single sentence would be generated toaccompany the picture.
We are in the process of im-plementing this second stage.In the third and final stage, the text generator will checkif there are conflicts between minimal sentence size and thegraphics generator's assignment of picture breaks.
Ifgraphics generates more than one picture for the infor-marion required for a minimal grammatical sentence, textwill attempt to select wo basic verbs that together conveythe meaning of the verb ori~nally selected, and that in-dividually coxrespond to the information in the two pic-tures.
For example, reinstalling the battery consists of firstplacing it on the radio and then snapping some latches.
Ifeach of these steps is portrayed in a separate picture, thentext can select he verbs "place" and "select" to conveythe compositional meaning of "reinstall" and generate twoseparate sentences.
This stage is also currently underdevelopment.Note that after text and graphics are generated withcoordinated breaks, it will be necessary to lay them out sothat relationships between corresponding material in dif-ferent media are clearly visible.
Although COMET's cur-rent media layout component does not take these relation-ships into account, we have begun to design a new one thatwill, building on our previous work on automated layout\[7\].Text GenerationOne focus in the text generation component has been onselection of appropriate vocabulary for the explanation.
Wehave developed a framework for lexical choice using theFtmctional Unification Formalism (FUF)\[9, 4, 5\].
In ad-dition, we have identified how previous discourse and theunderlying knowledge sources influence lexical choice andimplemented these influences as part of the lexieal chooser.The lexical chooser is part of the text surface generator.It receives its input from the media coordinator and passesits output to the surface generator, which containsCOMET's grammar and constructs the grammatical s xuc-ture of the sentence.
As output, the lexieal chooserproduces a list of pardally specified functional descriptions(PSFDs) that are passed as input to the surface generator.Thus, a PSFD is basically a lexicalized LF (using the spe-cial feature lex) that, in addition, specifies the overall gram-matieal form of that utterance ( .g., declarative).
COMET'sgrammar will enrich the PSFD with syntactic features toform a complete syntactic structure that is then linearizedto produce asentence.In the general case, the mapping between a LF and aPSFD is done as follows: each simple action in the LF ismapped onto a clause of the PSFD and each object descrip-tion in the LF onto a nominal 1of the clause.
The processof the action is mapped onto a verb of the clause.
Bothmappings are made by unifying the description with aFunctional Unification Lexicon (FUL).
However, whileunification in FUF is normally performed top-down,unification with a FUL is performed bottom-up, startingwith the most embedded sub-LFs.
This is because the lex-icalizations of the process roles sometimes constrain thepossible lexicalizations of the process itself (i.e., the verb).As an example, consider a case where semantic featuresin the knowledge base are used to select the verb of thesentence.
Fig.
4 presents two LFs of the concept c-turn,with c-channel-knob and c-radio-transmitter as the respec-tive mediums.
In this example, the input LF contains aprocess that is a c-turn.
In Fig.
4(a), the verb "to set" isselected because the medium (the object being turned) hasdiscrete settings, as is the case for the c-channel-knob.
InFig.
4(b), the medium does not have discrete settings, as isthe ease for the c-radio.transmitter, and the verb "to turn"is selected.For each example, the lexicon is st accessed to lex-icalize the object concepts embedded in the roles of thetop-level LF: c-channel-knob by "channel knob",c-radio-transmitter by "radio", c-position-1 by 'position1' and c-front-panel by "front-panel".
It is then accessedagain to lexicalize the process concept of the top-level LF:c-turn by "to set" in Fig.
4(a), where c-channel-knob is themedium and by "to turn" in Fig.
4(b), wherec-radio-transmitter is the medium.
In selecting the verb,the lexical chooser invokes a function that accesses theknowledge base to cheek whether the medium is an in-stance of a discrete knob or not.
If it is, the verb "to set"is chosen.
Otherwise, "to turn" is chosen.As illustrated in Fig.
5, this lexical choice is im-plemented by using a special feature of FUF termed CON-TROL in the FUL entry for the concept c-turn.
It allowsinvocation of an arbitrary LISP predicate during theunification process.
Only ff this predicate is satisfied willunification of the FD containing the CONTROL pairsucceed.
In this example, CONTROL is used to have FULdirectly query the knowledge base for additional infor-marion about he medium of c.turn.COMET's lexical chooser can also choose betweenwords based on context.
For example, it will choose theverb "reinstall" or "return" in place of "install" when itl i .e.
noun phrase,  p ronoun or  p roper  noun.44( (process-concept c-turn)(process-type action)(mood non-finite)(speech-act directive)(roles( (medium( (object-concept c-channel-knob)(quantif ication((definite yes) (countable yes)(ref-obj i) (ref-set i) ) )(ref-mode description) ) )(to-loc( (object-concept c-position-l)(ref-mode name) ) ) ) ) )(a) LF of "Set the channel knob to position 1.
"( (process-concept c-turn)(process-type action)(mood non-finite)(speech-act directive)(roles( (medium( (object-conceptc-radio-transmitter)(quantif ication((definite yes) (countable yes)(ref-obj I) (ref-set I) ) )(ref-mode description) ) )(on-loc( (object-concept c-front-panel)(quantif ication((definite yes) (countable yes)(ref-obj singular)(ref-set singular) ) )(ref-mode description) ) ) ) ) )(b) LF of "Turn the radio onto the front panel.
"Figure 4: Two LFs of the same concept with differentrole values.instructs the user to install an object hat it has previouslyinstructed the user to remove.
For each action that has aninverse action, COMET checks whether it has already in-structed the user to perform the inverse action in the currentexplanation.
If so, it will select a verb reflecting the in-verse.
Consider the partial set of instructions for troublesh-ooting loss of memory in Fig.
6.
With no previous dis-course, COMET selects the verb "install" to describe theinstallation for the holding battery.
However, after it hasinstructed the user to "remove" the primary battery and"pul l" the battery box away from the radio, COMETselects the verbs "reinstall" and "return" to lexicalize thesame installation process.The use of the unification algorithm for lexical choice isa novel approach that allows for the integration of varioustypes of constraints in a uniform formalism.
For example,in COMET, the choice of verb for a process has been con-strained simultaneously by its location in the domainhierarchy, by the semantic features of its role, and by thecontextual features of the previous discourse.
FUF also( ( (process-type action)(ALT( ( (process-concept c-turn); ; Is medium a type of discrete-knob?
(ALT; ; here the FUL invokes the;; knowledge base, LOOM( ( (control( (m~-~er  \[ c \[ discrete-knob(loon: : supe rconcept s( ^ rolesmediumobject-concept) ) \];; if \]cldiscrete-knob is a; ; superconcept select ' set"(verb( (lex 'set')(voice-class non-middle)(transitive-class transitive)))); ;else select 'turn'( (verb( (lex 'turn')(on-loc-prep 'onto" )(voice-class non-middle)(transitive-class transitive)\]Figure 5: Part of the FUL encoding the choice betweentwo verbsprovides a modular and declarative lexicon that is easilyextensible, and ultimately will allow for extensive inter-action between the lexieal chooser and grammar through auniform formalism.Graphics GenerationWork on graphics generation in COMET has con-centrated on the development ofan approach for generatingtechnical i lustrations of 3D objects, embodied in the rule-based graphics generator IBIS (Intent-Based IllustrationSystem) \[12\].
As in COMET's text generation component,all material is created on the fly, making it possible for theexplanation to be customized to the individual user andsituation.Each of IBIS's illustrations i  created by an illustrator,which designs its illustration to fulfill a set of communica-tive goals derived from the LF that is presented to it.
Theillustrator ealizes these goals by mating an illustrationthat includes a set of objects to be depicted and their at-Install the new holding battery.?
.
?Remove the primary battery: ... pull thebattery box away from the radio??
?
?Rei~Rdl the primary battery: Return theprimary battery to the radio, relnstall thebattery box, and snap the latches.Figure6: Influence of previous discourse onchoiceverb45Figure 7:tributes, a lighting specification that indicates how objectsare lit, and a viewing specification that indicates how the3D objects are to be projected onto the 2D display.
Indesigning an illnstration, the iUustrator elies on a set ofrules that form an illustration style.- .
.
.
.
.
.
, .
:  ........:................................,......-.......... :.....-.-.-.-.-.-.-.-.-.... : .
.
.
.
.
.
;.
;..-:.
:.., : .
: .
:  ;.
:4 .
:.
~.
:.
;.
:-: .
: .
: .
: .
:.
;-:-:.
:.
: .
: .
:-: .
: .
: - :- :- : .
:-: ,  :-:-: .
;-:-:-:-:-:-:.
: .
: .
: .
: .
:+  : .
: .
: .
: .
: .
:.
:, ;.
:.
: .
:, : .
:, :4 .
:.
:.
: .
:.
:.
: .
:.
: .
: .
:.
:.
: .
:-: .
:-:-: .
:.
:.
: .
:.
:.
:.
: .
:.
: ,  :-:.
: .
: .
:-: .
: .
: .
: .
: .
;.
: .
:.
: .
:.
: .
:.
:.
: .
:.
: .
:.
: .
: .
:.
: .
: .
: .
:.
: .
: .
~: ,  :.
:.
: ,  : .
: .
: , :Older version of Fig.
3 without constraints from previous picture generation.By default, IBIS attempts to express the contents of alogical form in a single illustration.
There are many situa-tions, however, in which this cannot be accomplished.
Forexample, an illustration may need to show two objects thatare not simultaneously visible from the same viewpoint.Alternatively, two objects to be included may be visible,but may be of sufficiently different size or distance fromthe viewpoint hat showing one in its entirety may neces-sitate showing the other at too small a size for it to belegible.
The objects to be depicted may even include thesame object at different points in time.
In all of thesecases, IBIS can generate composite illustrations, much asCOMET's text generator can create compound sentences.A composite illustration contains nested subpictures whoseobjects, lighting specification, or viewing specificationmay differ.
Each subpicture is generated by an illustratorthat is spawned by the parent picture's illustrator, and thatis given a subset of the parent illustrator's goals to fulfill[12].IBIS's rules have recently been expanded to deal withcertain cases in which an illustration's design should beinfluenced by previously generated illustrations.
One ex-ample of this is the incorporation of constraints frompreviously selected viewing specifications.
When tWo pic-tures are displayed in spatial or temporal sequence, smallchanges in viewing specification can be disconcerting, andmay appear to be the result of accidental, rather than inten-tional, camera movement.
For example, cinematographersoften use a rule of thumb that a change of viewingspecification corresponding to less than a 30 ?
rotationabout he object of interest is too small [8].
When generat-ing an illustration, IBIS takes into account he viewingspecification used in previous illustrations to avoid smallchanges.
Otherwise, attempts to optimize each viewingspecification for the individual illustration's goals wouldresult in a picture whose "locally optimal" viewingspecification would not be as effective in context of thosepictures already generated.IBIS designed the illustrations in Fig.
3, raking into ac-count he viewing specification of the left illustration whengenerating the right illustration.
In contrast, Fig.
7 includesan earlier version of the right illustration, created with arule base that does not incorporate these constraints on theviewing specification.
Note how the locally oplirnized sub-pictures of Fig.
7 look somewhat inconsistent when viewednext to each other.
Although IBIS currently completes theprocessing of each LF before starting on the next, it coulduse lookabead, as well as lookhehind, to delay making cer-tain decisions until additional information about succeed-ing illustrations i  known.
For example, this would allowan illustration's viewing specification to be based on thecontents of those illustrations that follow it, as well as thosethat precede it, maximizing the number of illustrations forwhich the same viewing specification could be used effec-tively.IBIS currently generates each illustration from scratch.We are currently redesigning its picture generation ap-46proach so that it can incrementally modify a design whensmall changes are made to the goals that an illuslrationmust satisfy.
For example, if the viewing specification ispartially specified as an input communicative goal, two il-lustrations' ets of communicative goals may differ only intheir viewing speeificafious.
Since IBIS runs on a machinethat can render a 3D shaded image in a fraction of asecond, ff an illustration's pecification can be incremen-tally regenerated fast enough, we can make possible simpleuser controUed animation.
For example, the user couldmove the camera round a set of objects to view them fromdifferent positions, while IBIS maintained constraints suchas legibility and visibility of designated objects.SummaryIn this paper, we described our most recent advances inCOMET.
These included the integration of individualcomponents and the addition of a menu-based user inter-face, yielding a fully operational testbed.
In the mediacoordinator, we have made progress towards the coordina-tion of picture and sentence breaks.
In the text generator,we focused on the problem of lexical choice, developing aframework for lexical choice using the Functional Unifica-tion Formalism and implementing influences from previousdiscourse and the underlying knowledge sources on lexicalchoice.
In the graphics generator, we implemented con-straints from previous (pictorial) discourse, and began workon incremental regeneration fillustrations.AcknowledgementsThis work is supported in part by the Defense AdvancedResearch Projects Agency under Contract N00039-84-C-0165, the Hewlett-Packard Company under its AlUniversity Grants Program, the Office of Naval Researchunder Contract N00014-82-K-0256, the National ScienceFoundation under Grant IRT-84-51438, and the New YorkState Center for Advanced Technology under ContractNYSSTF-CAT(88)-5.The development ofCOMET is an ongoing roup effortand has benefited from the contributions of Cliff Beshers(menu interface), Andrea Danyhik (learned rule base),Michael Elhadad (FUF), David Fox (text formatting com-ponent for media layout), Laura Gabbe (static knowledgebase and content planner), Jong IJm (static knowledge baseand content planner), Jacques Robin (lexical chooser),Doree Selignlann (IBIS), Tony Weida (static knowledgebase), Matt Kamerman (user model), and Christine Lom-bardi and Yumiko Fuknmoto (media coordinator).References1.
Allen, J.
Natural Language Understanding.
BenjaminCummings Publishing Company, Inc., Menlo Park, CA,1987.2.
Danyluk, A.
Finding New Rules for IncompleteTheories: Explicit biases for induction with contextual in-formation.
Proceedings of the Sixth InternationalWorkshop on Machine Learning, Ithaca, N.Y., June, 1989.3.
Department ofthe Army.
TM 11-5820-890-20-1 Tech-nical Manual: Unit Maintenance for Radio SetsAN/PRC-119 .
.
.
.
Headquarters, Department ofthe Army,June, 1986.4.
Rlhadad M. Extended Functional UnificationPr~rammars.
Columbia University, New York, NY,1989.5.
lRlhadad~ M. Types in Functional Unification Gram-mars.
Proceedings of the 28th meeting of the Associationfor Computational Linguistics, Pittsburgh, Pa, June, 1990.6.
Feiner, S.K.
and K.R.
McKeown.
Coo~inating Textand Graphics in Explanation Generation.
Proc.
AAAI 90,Boston, MA, July 29-August 3, 1990.7.
Feiner, S. A Grid-Based Approach to Automating Dis-play Layout.
Proc.
Graphics Interface '88, Edmonton,June, 1988, pp.
192-197.
(Palo Alto: Morgan Kaufxnann,1988).8.
Karp, P. and Feiner, S. Issues in the automated genera-tion of animated presentations.
Proc.
Graphics Interface'90, Halifax, Canada, May 14-18, 1990, pp.
39-48.9.
Kay, M. Functional Grammar.
Proceedings of the 5thmeeting of the Berkeley Linguistics Society, Berkeley Lin-guistics Society, 1979.10.
Lomhardi, C. Experiments for detemdning the assign-ment of information tomedia in COMET.
ColumbiaUniversity, New York, NY.11.
MacGregor, Robert and David Bfill.
LOOM Refer-ence Manual.
USC-ISI, Marina del Rey, CA, 1989.12.
Seligrnann, D.D., and Feiner, S. Specifying Com-posite I11uslrafions with Communicative Goals.
Proc.ACM Symposium on User Interface Software and Tech-nology, Williamsburg, VA, November 13-15, 1989, pp.1-9.47
