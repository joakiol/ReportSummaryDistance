Proceedings of Ninth Meeting of the ACL Special Interest Group in Computational Morphology and Phonology, pages 57?64,Prague, June 2007. c?2007 Association for Computational LinguisticsPhonological Reconstruction of a Dead LanguageUsing the Gradual Learning AlgorithmEric J. M. SmithDepartment of LinguisticsUniversity of Toronto130 St. George Street, Room 6076Toronto, Ont.
M5S 3H1Canadaeric.smith@utoronto.caAbstractThis paper discusses the reconstruction ofthe Elamite language?s phonology from itsorthography using the Gradual Learning Al-gorithm, which was re-purposed to ?learn?underlying phonological forms from surfaceorthography.
Practical issues are raised re-garding the difficulty of mapping betweenorthography and phonology, and Optimal-ity Theory?s neglected Lexicon Optimiza-tion module is highlighted.1 IntroductionThe purpose of this paper is to reconstruct thephonology of Elamite, an extinct language knownonly from written sources, whose phonology is cur-rently poorly understood.
Given that the mecha-nisms provided by Optimality Theory are powerfulenough for a language learner to acquire a naturallanguage given only overt forms, it should be possi-ble to apply the same mechanisms to ?learn?
Elamitephonology given only its orthography.The research described here was carried out withthe aid of a piece of software, nicknamed Grote-fend, which was developed as part of a larger re-search project into Elamite.1 The data used in thispaper consisted of the contents of the ElamischesWo?rterbuch (Hinz and Koch, 1987) marked up asXML with attributes such as morphology, cognates,1Grotefend was written in C++ using Trolltech?s Qt toolkit,and runs under Mac OS X.
The portions that implement theGradual Learning Algorithm (?4.3) were adapted from PaulBoersma?s Visual Basic source code for the OTSoft program,which was kindly provided by Bruce Hayes.semantics, corpus frequency, and chronology.
TheWo?rterbuch was used because it is the only sourcethat incorporates Elamite data from all historical pe-riods.
It also has the virtue of containing every sin-gle attested form known to the authors, which is par-ticularly useful for this project, since we have spe-cial interest in alternative spellings of given words.2 Elamite Language2.1 Historical and geographical contextElamite is an extinct language spoken in what is nowsouthwestern and central Iran.
Elamite-languagetexts dating from 2400 BCE until 360 BCE areattested, written in the cuneiform script borrowedfrom the Sumerians and Akkadians.2 Elamite hasno known linguistic affiliations, although a connec-tion to the Dravidian family has been proposed byMcAlpin (1982) and others.Since both the language and scribal practices arecertain to have changed over such a long time-span,this study will restrict itself to text from a single era.The Ach?menid Elamite period (539 BCE to 360BCE) was chosen, because this period contains thelargest volume of texts, and also because those textsare particularly rich in Old Persian names and loan-words that provide a useful starting point for esti-mating the phonology.2.2 The cuneiform writing systemAs part of their adaptation of cuneiform, theElamites abandoned most of the logographic ele-2Early texts from Elam using two other indigenous writingsystems are not well-enough understood to provide useful lin-guistic information.57ments found in Sumerian and Akkadian usage, mov-ing to an almost completely phonetic system, whichwould be a ?core syllabary?
in Sproat?s (2000) typol-ogy.
That is, each grapheme represents a syllable,but the system lacks graphemes to represent all ofthe language?s syllables.
This is particularly the casefor many ?CVC?
graphemes, which must be writ-ten using ?syllable telescoping?, where a ?CV-VC?combination is written, with the internal vowel beingrepeated.
For example, lacking a ?lan?
grapheme,the syllable /lan/ would have to be written ?la-an?3.Even when the ?CVC?
grapheme does exist, the?CV-VC?
writing is often preferred.2.3 Hypotheses to be testedThe strategy of this research is to use the techniquesof Optimality Theory to reconstruct the language?sphonology.
We will take the various hypotheses pre-sented by earlier authors and attempt to encapsulateeach in the form of an OT constraint.Altogether 30 separate hypotheses were evalu-ated, arranged into 11 major groupings.
Withineach grouping, the sub-hypotheses (which may ormay not be mutually exclusive) refer to a relatedcontext or related orthographic phenomenon.
Thispaper will largely restrict its discussion to only twoof the groupings: H3 (Geminate consonants) andH4 (Nasal vowels).4H3 Geminate consonantsH3a Geminate orthographies represent underlyinggeminate phonologies.H3b Geminate orthographies indicate voicelessness(Reiner, 1969).H3c Certain geminate spellings indicate a distinc-tion other than voicing, such as retroflex/alveolar(McAlpin, 1982).H4 Nasal vowelsH4a Alternations in the writing of nasals indicate3Or ?7?, but since the readership of this paper is un-likely to be familiar with cuneiform, all graphemes will be pre-sented in the traditional transliterated form used in Assyriology.4The full list of hypothesis groups also includes: H1 (In-terpretation of broken ?CV1-V2C?
writings), H2 (Voicing ofstops), H5 (Word-final vowels), H6 (Sibilants), H7 (Existenceof an /h/ phoneme), H8 (Existence of an /f/ or /v/ phoneme), H9(Existence of a /j/ phoneme), H10 (Existence of a /w/ phoneme),and H11 (Existence of an /e/ phoneme).
Full discussion of theresults for these hypotheses can be found in Smith (2004).the presence of nasal vowels (e.g.
/hu?ban/ ?
?hu-um-ban?, ?hu-ban?
).H4b Alternations in the writing of nasals can beexplained by underlying nasal consonants (e.g./humban/ ?
?hu-um-ban?, ?hu-ban?
).3 Theory of Writing SystemsThe discussion of Elamite orthography will beframed within the theory of writing systems pro-posed by Sproat (2000), whose core claim that ?par-ticular (sets of) linguistic elements license the oc-currence of (sets of) orthographic elements?.
Thedetails of which linguistic elements license whichorthographic ones are specific to any given combi-nation of spoken language and writing system.The licensing is implemented by a mapping func-tion, MORL?
?, whose input is the OrthographicallyRelevant Level (ORL), and whose output is theorthography(?).
In the case of Elamite, the rele-vant level is the surface phonology after the applica-tion of phonological processes such as assimilationand cluster simplification, so in Sproat?s schema,Elamite is classified as having a ?shallow?
ORL.54 Applying OT to OrthographyIn the normal application of Optimality Theory, theinput and the output are both the same type of lin-guistic entity.
However, in the problem dealt withhere, the relationship is between an input that isphonological and an output that is orthographic.
Thecomparison of phonological apples to orthographicoranges leads to complications that will be discussedin ?6.1.
All the modules of Optimality Theory mustbe adapted for use with orthography.4.1 BackgroundAs originally formulated, Optimality Theory can beconsidered as a set of three interconnected modules:GEN, H-EVAL, and Lexicon Optimization (Princeand Smolensky, 1993).
Together GEN and H-EVALcomprise the grammar proper.
For any given in-put, GEN generates a set of output candidates, andthese candidates are then evaluated against a set ofconstraints by the H-EVAL module.
Lexicon Opti-mization is not part of the grammar, but it provides5For instance, the noun kittin ?length?
is spelled ?ki-it-ti-im-ma?
when followed by the locative suffix -ma, while the 3SGobject prefix in- is written ?id?
before a verb like dunih ?I gave?.58a mechanism by which language learners can usethat grammar to determine underlying forms basedon the overt forms that are presented to them.Optimality Theory can be seen as a model for howa language learner acquires a natural language, pre-sented only with overt forms (Tesar and Smolensky,2000).
At first, the learner?s constraint rankings andunderlying forms will be inaccurate, but as more in-formation is presented the estimates of the under-lying forms become more accurate, which in turnimproves the constraint rankings, which further im-proves the estimates of the underlying forms, and soon.
In this study, the ?learner?
is the Grotefend soft-ware, which is presented with surface orthographyand attempts to deduce the phonology.4.2 Adaptation for orthographyThe GEN module must be adapted to generate plau-sible overt forms (i.e.
rival orthographies).
The gen-eral strategy for GEN is described in ?5, with thespecific details given in ?5.2.The constraints are used by a ranking algorithm(?4.3) that compares the rival orthographies fromGEN against underlying phonological forms in or-der to determine the number of constraint violations.In order to start the process, those underlying formshave to be seeded with reasonable initial estimates.If the word is a loanword, the initial estimate isbased on the Old Persian or Akkadian phonology.If there is no available loanword phonology, the ini-tial estimate is a direct transcription of the graphemevalues as if the word were being read in Akkadian.Once the constraints have been ranked, LexicalOptimization takes the orthographic forms and thenewly-ranked constraints, and calculates an esti-mated phonology for each of the forms.
At thispoint, the process can stop, or else it can proceedthrough another iteration of the ranking algorithm,using the new improved estimated phonologies asunderlying forms.4.3 Gradual Learning AlgorithmThe Gradual Learning Algorithm (Boersma, 1997;Boersma and Hayes, 2001) is an evolution of theConstraint Demotion algorithm (Tesar, 1995), butavoids the infinite-looping which can arise in Con-straint Demotion if underlying forms have more thanone overt form.
This limitation of Constraint Demo-tion is a serious one given the data from Elamite or-thography; not only are the orthographic forms sub-ject to considerable variation, but also this variationis a key piece of information in attempting to recon-struct the phonology.In the GLA, constraints each have a numeric rank-ing value associated with them.
It is no longer thecase that Constraint A consistently outranks Con-straint B; whenever a constraint is evaluated, a ran-dom ?noise?
factor is added to each of the rankingvalues, and an instantaneous constraint ordering isdetermined based on these adjusted values.
If theranking values for two constraints are far apart, thenoise is unlikely to alter the ordering, and the re-sults will be effectively the same as ordinary OT.
Ifthe ranking values for two constraints are close to-gether, the noise could put either constraint on top,but ties are avoided.In the GLA implementation within Grotefend, allconstraints start with ranking values of 100.00.
Witheach iteration of the algorithm, one of the observedforms is selected as an exemplar, and rivals (pro-duced by GEN) are compared against the observedexemplar form.
Whenever a rival beats the exemplarform, the constraint ranking values must be adjusted:all constraints that picked the wrong winner are pe-nalized (adjusted downwards), and all constraintsthat picked the right winner are rewarded (adjustedupwards).
The size of this adjustment is determinedby a variable called ?plasticity?, which starts at 2.00and is reduced gradually to 0.002 as the algorithmproceeds through its iterations.5 Implementation of GENThe purpose of GEN is to generate a set of plausi-ble overt forms consisting of the real form and a setof rivals which will lose out to the real form.
Inthis problem the overt forms are orthographies, sofor any underlying form the challenge is to gener-ate orthographic strings that compete with the realorthography, but which are ?wrong?
with respect toone or more of the constraints.5.1 BackgroundThere have been a number of computational imple-mentations of GEN, but the most promising one forour purposes was that of Heiberg (1999).
Heiberg?s59algorithm proceeds by choosing a starting point andthen adding constraints to the system.
As each con-straint is added, new candidates are generated usingwhat she calls ?relevant?
GEN operations.
A GENoperation is considered to be relevant for the currentconstraint if the operation could affect a candidate?sharmony relative to that constraint.
So for instance,if the constraint being added evaluates the [+back]feature, the only GEN operations that are relevantare those which affect [+back] or its associations.The candidates at each stage of the algorithm arenot fully formed, and are slowly refined as the con-straints are added to the system.
One advantage ofHeiberg?s algorithm is that it functions even if therelative rankings of the constraints are not known.
Ifthe constraint rankings are known, the algorithm canoperate more efficiently, by culling known losers,but knowing the rankings is not essential.5.2 Adaptation of GEN for orthographyGenerating all ?plausible?
orthographic candidatesfor a given form is computationally prohibitive.6So, borrowing Heiberg?s notion of ?relevant?
oper-ations, our approach is to generate candidates thatspecifically exercise one of the constraints in theconstraint system.Each of the hypothesis groups described in ?2.3refers to a particular orthographic context, and eachcontext has a miniature version of GEN to generateappropriately test-worthy rivals.
For example, themini-GEN function for context H3 is as follows:GEN H3 (Geminate consonants)Rule Whenever a geminate consonant is foundin the orthography, generate a rival with the non-geminate equivalent.Example ?hu-ut-ta?
?
{ ?hu-ta?
}6 Implementation of H-EVALThe H-EVAL module is responsible for the actualevaluations of the various candidates.
It takes anyoutput candidate produced by GEN, and counts theviolation marks for each of the constraints.6Initial experiments indicated that a moderately long stringof four graphemes would generate in the neighbourhood of18000 rivals.
It seemed unrealistic to evaluate tens of thousandsof rivals for each of the 8000+ forms in the database.umPHONSEMdivinity:da h uORTH u mas ?
damar a z d hria?Figure 1: Annotation graph for Ahuramazda?h ?
?du-ri-um-mas?-da?Each constraint is implemented as a functionwhich takes two inputs (an underlying form and asurface form), and produces as an output the num-ber of violations incurred by the comparing the twoinputs.
For full generality, both inputs are anno-tation graphs (Bird and Liberman, 1999; Sproat,2000) such as the one shown in Figure 1.
As imple-mented in Grotefend, the comparison involves onlythe PHON tier of the underlying form?s graph and theORTH tier of the surface form?s graph.Constraints were written to test each of the hy-potheses described in ?2.3.
Since there is no priorart in the area of constraints involving orthographyand phonology, they were developed in the moststraightforward way possible.
The implementationof these functions is described in ?6.2.6.1 Implementation of alignmentIn order to count violations, the two inputs mustbe properly aligned.
For an annotation graph tobe ?aligned?, every grapheme must be licensed bysome part of the phonology, and every phonememust be represented in the orthography.
Withoutsuch a licensing relationship, it is impossible tomake the comparisons needed to count constraint vi-olations.There is considerable previous work in the area ofalignment, most recently summarized by Kondrakand Sherif (2006).
The algorithm used in this studyis a similarity-based approach, not unlike ALINE(Kondrak, 2000).
It differs in some significant re-spects, notably the use of binary features.Determining the eligibility of two phonemes formatching requires a distance function.
The approachtaken was to assign a weight to each phonologicalfeature, and to calculate the distance as the sum ofthe weights of all features that differ between thetwo phonemes.
The full listing of feature weights isshown in Table 1.
The weighting values were deter-60Table 1: Feature weights for computing distancePhonological Feature Weightdelayed release, voice, labio-dental,anterior, distributed, strident1approximant, continuant, nasal, lateral,round, low, pharyngeal2syllabic, consonantal, constricted glot-tis, spread glottis, high, front, back4sonorant, place of articulation 8mined empirically, selecting the weightings that didthe best job of aligning the orthography for the OldPersian loanwords given by Hinz and Koch (1987).For the actual alignment, several approacheswere tried, but the most effective one was simplyto line up the consonants and let the vowels fallwhere they may.
For instance, the licensing of?du-ri-um-mas?-da?
in Figure 1 used the Old Persianphonology as the best available initial estimate forthe Elamite phonology, and proceeded as follows:?d?
is the divine determinative, and is licensedby the semantic tier of the annotation graph, so itdoes not need to be anchored to the phonology.?u?
is anchored at the left edge of the phonology.?ri?
starts at /r/, but has no clear right edge.
Theanchoring of /r/ sets a right boundary on the ?u?,which must therefore be licensed by the initial /ahu/of /ahuramazda?h/.?um?
right edge at phoneme /m/; since the ?um?
hasno clear left edge, the second /a/ of /ahuramazda?h/is left floating between the ?ri?
and the ?um?.
Sincethere is no clear choice between the two locations,the /a/ will be shared by ?ri?
and ?um?.?mas??
starts at /m/ and ends at /z/, which is suffi-ciently similar to match s?.
The /m/ will be shared by?um?
and ?mas??.?da?
starts at /d/; since ?da?
is the last grapheme, itmust be licensed by the remainder of the phonology.The general strategy of aligning consonantsproved to be an effective one.
In the working datasetof Ach?menid Elamite words, there were 3045 thatused Old Persian or Akkadian data to provide an ini-tial estimate of the underlying phonology.
The algo-rithm successfully aligned 2902 of those words, fora success rate of over 95%.6.2 Implementation of constraintsOnce the orthography has been successfully alignedwith the underlying phonology, it is possible toevaluate the forms for violations against all the con-straints in the system.
In terms of the tiers shown inannotation graphs like Figure 1, the constraints areperforming comparisons between the underlyingforms in the PHON tier and overt forms in the ORTHtier.
For example, the rules for calculating constraintviolations for H3 are as follows:H3a Geminate spellings indicate geminate pronun-ciations.Rule Count a violation if the orthography containsa geminate consonant not matched by a geminate inthe phonology.7Violation /ata/ ?
?at-ta?Non-violations /atta/ ?
?at-ta?, /atta/ ?
?a-ta?H3b Geminate spellings indicate voicelessness.Rule Count a violation if 1) the orthography con-tains an intervocalic geminate stop not matched by avoiceless stop in the phonology, or 2) the orthogra-phy contains an intervocalic non-geminate stop notmatched by a voiced stop in the phonology, or 3) thephonology contains an intervocalic voiceless stopnot matched by a geminate in the orthography, or 4)the phonology contains an intervocalic voiced stopnot matched by a non-geminate in the orthography.8Violations /duba:la/ ?
?du-ib-ba-la?, /garmapada/?
?dkar-ma-ba-tas?
?Non-violations /gauma:ta/ ?
?kam-ma-ad-da?,/babili/ ?
?ba-pi-li?H3c Certain geminate spellings indicate a distinc-tion other than voicing, such as retroflex/alveolar.Rule Count a violation if 1) the orthography con-tains a ?Vl-lV?
or ?Vr-rV?
sequence not matched bya retroflex in the phonology, or 2) the phonologycontains a /?/ or /?/ not matched by a ?Vl-lV?
or7The claim made by Grillot-Susini and Roche (1988) wasonly that a geminate orthography represents a geminate phonol-ogy; a non-geminate orthography could still conceal a geminatephonology.8Reiner (1969) restricted her claim about gemination repre-senting voicelessness to intervocalic stops.
Word-initial stopsand intervocalic non-stops were not relevant here.61?Vr-rV?
in the orthography.Violations /talu/ ?
?ta-al-lu?, /ta?u/ ?
?ta-lu?Non-violation /ta?u/ ?
?ta-al-lu?7 Implementation of Lexicon OptimizationGiven the set of constraints provided in ?6.2 andrankings determined by the Gradual Learning Algo-rithm (?4.3), it is now possible to move on to thefinal stage of the ?learning?
process: Lexicon Opti-mization, which is responsible for choosing the mostharmonic input form for any given output form.There has been surprisingly little literature de-voted to Lexicon Optimization, and discussions ofhow it might be implemented have been restricted totoy algorithms such as Ito?
et als (1995) ?tableau destableaux?.
Hence, a novel approach was devised,based on the observation that Lexicon Optimizationis a sort of mirror image of H-EVAL.
For H-EVAL,there exists a separate GEN module whose task isto generate the possible output candidates.
Clearly,Lexicon Optimization needs an equivalent module,but one that would generate a range of rival inputforms.
Since the GEN algorithm described in ?5.2uses a constraint-driven technique for generatingoutput candidates, it seems appropriate to also usea constraint-driven technique for generating inputcandidates.
Accordingly, this anti-GEN is imple-mented as a set of miniature anti-GENs, each ofwhich is responsible for generating ?relevant?
inputcandidates for one of the hypothesis groupings.
Forexample, the anti-GEN function for H3 is as follows:Anti-GEN H3 (Geminate consonants)Rule Whenever a geminate consonant is foundin the orthography, create input candidates withthe geminate phonology and the equivalent non-geminate phonology.
If the geminate orthography isa ?Vl-lV?
or ?Vr-rV?, also create an input candidatewith a ?retroflex?
phonology.9Example ?ta-al-lu?
?
{ /tallu/, /talu/, /ta?u/ }8 Results and DiscussionWe ran 40000 iterations of the Gradual LearningAlgorithm against the Ach?menid Elamite forms9McAlpin (1982) hedges on whether the phonology repre-sented by these geminates actually represents retroflexion, buthe then proceeds to discuss Proto-Elamo-Dravidian cognates asif this orthography actually did represent a retroflex articulation.Table 2: Final constraint rankings for H3 and H4Hypo-thesisConstraint RankingValueH4b NasalConsonants ?136.93H3b ?Geminate?=/Voiceless/ ?283.70H4a NasalVowels ?1434.77H3c ?Geminate?=/Retroflex/ ?1629.74H3a ?Geminate?=/Geminate/ ?3189.11found in the Elamisches Wo?rterbuch.
The final con-straint rankings for hypothesis groups H3 and H4 areshown in Table 2.10 The combination of constraints,GEN, and anti-GEN functions used by Grotefendtends to penalize constraints much more often thanit rewards them.
The absolute ranking values are notsignificant; what matters is their relative values.8.1 Results for H3 (Geminate consonants)The results for H3 strongly support the hypothesis(Reiner, 1969) that geminate orthographies are anattempt to indicate voicelessness; the opposing hy-pothesis (Grillot-Susini and Roche, 1988) that gem-inate orthographies represent geminate phonologiesended up being very heavily penalized.What was surprising was that hypothesis H3c, that?Vl-lV?
and ?Vr-rV?
geminates represent a sepa-rate phoneme from the non-geminate orthographies,ranked so poorly.
The problem here is a side-effectof the process for generating input candidates.Consider the Akkadian name Nabu?-kudurri-us.
ur;the ?ur-ri?
sequence that occurs in the variousspellings of this name would appear to be an idealcontext for evaluating H3c.
However, when gen-erating input candidates for Nabu?-kudurri-us.
ur, thevarious anti-GEN functions create 238 permutations(mostly permutations of voicing), but only four ofthose input candidates contain an /?/ phoneme, withthe rest having an /rr/ or an /r/.
Since the anti-GENfunction produces so few /?/ input candidates for the?ur-ri?
orthography, it is likely that the software willfind an /r/ in the underlying phonology, and willcount a violation against this constraint.The prejudice against /?/ and /?/ highlights the im-portance of having a fair and balanced anti-GEN10Results for the other nine groups are in Smith (2004).62PHON h ?)
d u ?ORTHhi is?in duPHON h ?)
d u ?ORTHhi is?in du1 H4a (nasal vowel) violation0 H4b (nasal consonant) violations0 H4a (nasal vowel) violations1 H4b (nasal consonant) violationFigure 2: Licensing of ?hi-in-du-is??
?Indian?function.
The proposal to be discussed in ?8.3 forcross-permuting the results of the constraint-specificanti-GEN functions would probably also improvethe results for this hypothesis.8.2 Results for H4 (Nasal vowels)The effectiveness of the constraints for evaluatingnasals was undermined by choices made in the align-ment algorithm.
Although constraint H4b (Nasal-Consonants) is ranked significantly higher than H4a(NasalVowels), this may be merely a side-effect ofthe alignment algorithm.Consider the word for ?Indian?, which shows upas ?hi-du-is?
?, ?hi-in-du-is?
?, or ?in-du-is??.
It is notunreasonable to postulate an underlying phonol-ogy of /h?
?duS/, based both on the range of writtenforms, and on the Old Persian phonology.
However,when the alignment algorithm attempts to deter-mine which phoneme sequences are licensing whichgraphemes, it has a difficult choice to make for the?in?
grapheme.
Licensing the vowel portion of ?in?is straightforward, but what should be done for theconsonant?
If the software assumes that the mostsalient features are [+consonantal] and [?syllabic],we get the first annotation graph shown in Figure2, but if the most salient features are [+nasal] and[+sonorant], we get the second graph.The choice of how to license the ?in?
graphememakes a difference for how the H4a and H4b con-straints are evaluated.
Using the weightings givenin Table 1, the software will align ?in?
with /?
?d/, be-cause the distance between /n/ and /d/ is less thanthat between /n/ and /??/.
Hence, the alignment algo-rithm chooses the first of the two annotation graphsgiven in Figure 2.
This has the result of prejudic-ing the learning algorithm in favour of H4b insteadof H4a.
Ideally, the alignment algorithm should beneutral with respect to the various constraints.The licensing of the ?in?
sign in this exampleis one case of several where it appears that us-ing phonological segments as the basis for licensingmay be the wrong thing to do.
It would be better tothink of the second portion of the ?in?
sign in ?hi-in-du-is??
as being licensed by a [+nasal] feature, with-out attempting to tie the feature down to either the/i/ or the /d/ segment.118.3 Discussion of Lexicon OptimizationThe generation of useful input candidates is limitedby the information that is available to us.
For allwe know, Elamite had an /W/ vowel, and Grotefendcould even generate input candidates that containedan /W/.
However, none of the constraints wouldweigh either for or against it, so there is no point ingenerating such an input candidate.
Consequently,the correct underlying form may well be inaccessi-ble to Lexicon Optimization.
At best, Lexicon Opti-mization can produce an estimated underlying formthat leaves as underspecified any features that can-not be verified by a corresponding constraint.
Thisis a limitation of Lexicon Optimization in general,not just of the implementation in Grotefend.One problem specific to our constraint-based gen-eration of input candidates is that the anti-GEN func-tions work in isolation from each other.
For exam-ple, when processing ?da-is?
?, the H1 (broken-vowel)anti-GEN produces /daiS/, /dajS/, /dES/, and /daS/.Separately, the H6 (sibilant) anti-GEN will produce/dais/, /daiS/, /daiz/, /daitS/, and /daits/.
Since thetwo functions operate independently, the softwarefails to generate a whole range of candidates.
Ifthe actual underlying phonology were /dEtS/, Grote-fendwould never find it, since that particular phonol-ogy will never be generated and presented to Lexi-con Optimization as a possible input candidate.
Amore sophisticated anti-GEN implementation wouldallow for the input candidates produced by one con-straint?s anti-GEN function to be further permuted11Sproat (2000) uses phonological segments to describe li-censing, but there is nothing in his theory that requires this; infact, he says that his use of segments is merely a ?shorthand?for a set of overlapping gestures.63by the anti-GEN function of another constraint.9 ConclusionsThis project represented an expedition into threelargely unexplored territories: the application of Op-timality Theory to orthography, the implementationof Lexicon Optimization in software, and the massanalysis of Elamite phonology.
All three presentedunanticipated challenges.The problem of implementing GEN algorithmi-cally appears to be at an early stage even in the pro-cessing of phonological data.
The constraint-drivenGEN adopted from Heiberg (1999) does appear to bea useful starting point for working with orthography.The determination of the mapping betweenphonology and orthography can have unexpectedconsequences for the evaluation of constraints.
Evenwhen properly aligned, implementing meaningfulconstraints to evaluate the mismatches betweenphonology and orthography proved to be surpris-ingly complex.
An alternative representation, licens-ing graphemes based on bundles of features ratherthan phonemes, might be more effective.The whole area of Lexicon Optimization has re-ceived surprisingly little mention in the literature ofOptimality Theory.
The notion that there must besome form of anti-GEN module to produce suitableinput candidates appears never to have been raisedat all.
The existence of anti-GEN is hardly specificto the study of orthography, but would seem to be anomission from Optimality Theory in general.The constraint-driven implementation of the anti-GEN function does seem like a promising strategy,although the details need work.
In particular, thereis a need for the outputs of the various constraint-specific anti-GENs to be permuted together in orderto produce all plausible input candidates.Elamite has always been problematic both due toits status as an isolate and because the available cluesend up being obscured by the writing system.
Sofar, we can claim that this computational analysisof the body of Elamite vocabulary has succeeded induplicating some of the tentative conclusions drawnfrom a century of hard work ?by hand?.ReferencesSteven Bird and Mark Liberman.
1999.
A formal frame-work for linguistic annotation.
Technical Report Tech-nical Report MS-CIS-99-01, Department of Computerand Information Science, University of Pennsylvania.Paul Boersma and Bruce Hayes.
2001.
Empirical testsof the gradual learning algorithm.
Linguistic Inquiry,32:45?86.Paul Boersma.
1997.
How we learn variation, option-ality, and probability.
Proceedings of the Instituteof Phonetic Sciences of the University of Amsterdam,21:43?58.Franc?oise Grillot-Susini and Claude Roche.
1988.Ele?ments de grammaire e?lamite.
Etudes elamites.
Edi-tions Recherche sur les civilisations, Paris.Andrea Heiberg.
1999.
Features in Optimality Theory:A computational model.
Ph.D. thesis, University ofArizona.Walther Hinz and Heidemarie Koch.
1987.
ElamischesWo?rterbuch.
D. Reimer, Berlin.Junko Ito?, Armin Mester, and Jaye Padgett.
1995.
NC:Licensing and underspecification in optimality theory.Linguistic Inquiry, 26(4):571?613.Grzegorz Kondrak and Tarek Sherif.
2006.
Evaluationof several phonetic similarity algorithms on the taskof cognate identification.
In Proceedings of the Work-shop on Linguistic Distances, pages 43?50.Grzegorz Kondrak.
2000.
A new algorithm for the align-ment of phonetic sequences.
In Proceedings of theFirst Meeting of the NAACL, pages 288?295.David W. McAlpin.
1982.
Proto-Elamo-Dravidian: Theevidence and its implications.
Transactions of theAmerican Philosophical Society, 71(3):1?155.Alan Prince and Paul Smolensky.
1993.
Optimality the-ory.
Rutgers Optimality Archive, #537.Erica Reiner.
1969.
The Elamite language.
Handbuchder Orientalistik I/II/1/2/2, pages 54?118.Eric J. M. Smith.
2004.
Optimality Theory and Orthog-raphy: Using OT to Reconstruct Elamite Phonology.M.A.
forum paper, University of Toronto.Richard Sproat.
2000.
A Computational Theory of Writ-ing Systems.
Cambridge University Press.Bruce Tesar and Paul Smolensky.
2000.
Learnability inOptimality Theory.
MIT Press, Cambridge, Mass.Bruce Tesar.
1995.
Computational Optimality Theory.Ph.D.
thesis, University of Colorado.64
