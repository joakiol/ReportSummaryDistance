The Lincoln Large-Vocabulary HMM CSR*Douglas B. PaulLincoln Laboratory, MITLexington, Ma.
02173ABSTRACTThe work described here focuses on recognition of theWall Street Journal (WSJ) pilot database \[17\], a new CSRdatabase which supports 5K, 20K, and up to 64K- word CSRtasks.
The original Lincoln Tied-Mixture HMM CSR was im-plemented using a time-synchronous beam-pruned search ofa static network\[14\] and does not extend well to this task be-cause the recognition network would be too large for currentlypractical workstations.
Therefore, the recognizer has beenconverted to a stack decoder-based search strategy\[I,7,16\].This decoder has been shown to function effectively on upto 64K-word recognition of continuous peech.
This paperdescribes the acoustic modeling techniques and the imple-mentation of the stack decoder used to obtain these results.INTRODUCTIONThe original Lincoln Tied-Mixture HMM CSR wasimplemented as a single-layer static network witha time-synchronous (TS) beam-pruned network-searchstrategy\[14\].
When used with a bigram language model(LM), this implementation generally requires an V ~ setof word interconnection links.
This is tractable forvocabulary sizes on the order of 1K, but becomes in-tractable for vocabulary sizes (V) of 5K or more words.This implementation also is incompatible with or in-tractable for many forms of LM, such as recursive ortrigram models.
A stack decoder \[1,7,16\] with fastmatch\[2,3,5\] is used here to overcome the limitations ofthe original decoder structure.Previous work focused on a 1K word task, ResourceManagement (RM)\[18\], which could be handled ade-quately with the TS decoder.
(The same decoder wasalso used on the ATIS task\[13\].)
However, only the stackdecoder was usable on the WSJ task.
While the theoryof the stack decoder is adequately established \[1,7,16\],many of the implementation details are still topics forresearch.
One topic of particular interest is fast matchtechniques and structures.
There are also a number ofpragmatic issues to be resolved for stack decoders and*This work was sponsored by the Defense Advanced ResearchProjects Agency.
The views expressed are those of the author anddo not reflect he official policy or position of the U.S. Government.tree searches in general.
(The stack decoder implementsa tree search.
)Once a functioning stack decoder was developed, it be-came possible to perform recognition experiments on theWSJ database.
This allowed both further debuggingand development of the stack decoder and explorationof acoustic modeling techniques.THE BASIC HMM SYSTEMThe basic system, with the exception of the decoder, isvery similar to the earlier Lincoln tied-mixture (TM)systems.
The system used here has two observationstreams (TM-2): mel-cepstra nd time differential mel-cepstra.
(Due to time limitations, the second differentialmel-cepstral observation stream used in the TS decoderfor SI tasks was not tested.)
The system uses Gaussiantied mixture \[4,6\] observation pdfs and treats each ob-servation stream as if it is statistically independent ofall others.
Triphone models \[20\] are used to model pho-netic coarticulation.
(Cross-word triphones, which area feature of the old TS decoder, will be implementedlater.)
These models are smoothed with reduced con-text phone models \[20\].
Each phone model is a threestate "linear" (no skip transitions) HMM.
The phonemodels are trained by the forward-backward algorithmusing an unsupervised monophone bootstrapping proce-dure.
The recognizer extrapolates (estimates) untrainedphone models, contains an adaptive background model,allows optional intermediate silences, and can use anyleft-to-right stochastic LM.
The LM module is interfacedvia a proposed CSR-NL interface\[ll\].THE STACK DECODERThe stack decoder is organized according to the descrip-tion in reference \[16\] and uses the long-span LM searchcontrol strategy.
The basic paradigm used by the stackdecoder is: remove the best theory from the stack, applythe fast matches (FM) to find a small number of poten-tial successor words, evaluate the log-likelihood of thesesuccessors with the detailed matchs (DM), and insert themost promising new theories back onto the stack\[2,3,5\]This paradigm requires that theories of different lengths399be compared.
Therefore, this system maintains a "least-upper-bound so-far" (lubsf) of all previously computedtheory output log-likelihoods.
(Acoustic log-likelihoodsand the lubsf are functions of time.)
The maximum ofthe difference between this lubsf and each theory outputlog-likelihood (StSc < 0) is used to determine the besttheory\[15,16\].
Theories whose StSc is less than a thresh-old are pruned from the stack.
Reference \[16\] definesa method for estimating the most likely theory outputtime, t_exit.
The stack entries are sorted by a major sorton t_exit and a minor sort on StSc.
Thus the theoriesare extended primarily on a time basis.THE FAST MATCHThe acoustic fast match (AFM) algorithm used here isan HMM phonetic tree generated from the vocabulary\[3\].The output log-likelihood of the current heory is inputto the root of the tree and the paths are evaluated usinga TS beam search.
If an output state's log-likelihoodexceeds a threshold, the corresponding word is activatedand the best score is recorded.
(All references to scoresin this paper refer to log-likelihoods.
)This tree search needs to be terminated to limit itscomputation.
The beam pruning threshold used in theAFM search is computed from an estimate of the upper-bound of the AFM state log-likelihoods (AFM-bound)and, when all states are pruned, the AFM terminates.This AFM-bound is computed by a reentrant phonetictree.
(Unlike the AFM tree, the leaves of this tree con-nect back to the root to provide a path for a word exitto enter the next word.
Thus the scores in the FM treedrop off after the word ends while the upper bound ofthe scores in the FM-bounding tree does not.)
This reen-trant tree is, in effect, an efficient implementation f ano-grammar recognizer whose only output of interest isthe AFM-bound.errors occur.
)Any of a number of phonetic units can be used in thesetrees: the goal is to minimize the total time requiredto compute the FMs and the DMs without increasingthe error rate over that of the DMs alone.
An elaborate(and expensive) FM will minimize the DM computationwhile a very cheap FM will result in a large amountof DM computation.
Any of a large number of pho-netic units can be used: triphones, left-diphones, right-diphones, monophones, upper bounding context phones,simplified network phones.
(An upper bounding contextphone is a diphone or monophone whose scores are anupper bound of all scores which would be produced bythe triphones covered by the context phone.
A simpli-fied network phone might collapse its states into fewerstates.)
The two trees need not use the same phoneticunits and each tree can also use a mix of phonetic units.One extreme would be triphone trees (maximally com-plex for a triphone based recognizer) and the other ex-treme would one-state monophone trees.
It is also possi-ble to use simplified observation pdfs to reduce the com-putation.
Each of these variations must be tested toevaluate the trade-offs.
The Lincoln system currentlyuses TM left-diphones in both trees.
Since TM pdfs arerelatively expensive to compute, they are cached to pre-vent recgmputation.Because the theories are searched in dominantly t_exitorder, it is possible to further educe the total AFM com-putation time by grouping all of theories on the stackwhich have t_exit's within a small time zone, add theiroutput likelihoods (for a full decode), and apply this sumas input to a single execution of the AFM tree search.
(Substitute maximum for sum to perform a Viterbi de-code.)
This single AFM computation may be somewhatmore expensive than the AFM computation for a singletheory, but it reduces the number of AFM executions.Once the AFM has completed, the LM fast match(LMFM) log-likelihoods are added to the AFM scoresand the result is compared to another threshold.
The setof words which survives the second threshold is passedto the DMs.
(If an expensive LM algorithm is used, in-expensive stimates of the log-likelihoods may be used inthe LMFM.
Since the N-gram LMs used in this effort arevery cheap to compute, the exact LM DM log-likelihoodwas used.
)If the FM-likelihood is guaranteed tobe greater than orequal to the DM-likelihood and the FM decision thresh-old is the DM lubsf, the FM will be admissible.
(An ad-missible FM is an FM which is guaranteed not to causeany search errors\[3\].
This statement also assumes thebeam pruning is generous enough that no FM-tree searchTHE DETAILED MATCHThe DM is implemented asa one-word-at-a-time beam-pruned TS ttMM applied to each word which survivesthe FMs.
The input likelihood for each word decodecomes from the output likelihood array in each stackentry.
(This theory output log-likelihood output musttime truncated in order to fit the important portion intothis finite array before inserting any new theory onto thestack.)
There is rarely any difficulty fitting the outputof a word into this array, but it may not be possible for acontinuing sound such as a zone of background (silence).This is handled by using "continuable" background mod-els.
The state of the background HMM is also stored onthe stack and a long background is modeled as a suc-cession of theories ending in background.
(Of course,400normal input is possible only for the first of this series ofbackground theories.
The later theories rely on the stateinformation.)
This also enables a theory to decide thata transition to background has occurred without waitingfor the next word to begin.In reference \[15\], a technique for eliminating theoriesfrom the stack which are "covered" by an "LM-future-equivalent" (LMF-equivaient) heory is proposed.
(Onetheory covers another if all entries in its output log-likelihood array are greater than those of the secondtheory at the corresponding times.)
Two theories areLMF-equivalent if the probabilities of all future wordsequences are the same for both theories.
Thus, foran N-gram LM, any theories which share the same N-1 final words are LMF-equivalent.
Any LMF-equivalentcovered theory can never beat its covering theory andtherefore can be eliminated.
This is analogous to apath join in a TS decoder.
The mechanism also servesto eliminate the poorer of two theories which differonly in optional inter-word backgrounds.
(Since op-tional inter-word backgrounds are not considered by theLM, they may be eliminated before determinating LMF-equivalence.)
For any limited left-context-span LM, thismechanism prevents the exponential theory growth thatcan occur in a tree search.The words passed to the DM by the FM are generallyacoustically similar and thus frequently share many ofthe triphones.
Therefore the same observation pdfs arelikely to be needed more than once.
As in the FM, theTM likelihoods are cached to minimize the cost of reuse.This stack decoder does not yet include cross-word pho-netic models.
It will be possible to add them to the sys-tem, but they will certainly increase the complexity ofthe acoustic DM and perhaps also of the AFM (depend-ing on the type of phonetic unit used in the AFM).
Sincethe system still has some known difficulties/bugs, the im-plementation of the cross-word phonetic models will bedelayed until these problems are under control.
Sincethe 5K word WSJ vocabulary already contains over 6Kword-internal triphones and cross-word triphone mod-els will greatly increase this number, practical machinesize limits dictate that clustered triphones \[9,10\] or lowercontext phonetic units, such as semiphones \[14\], be usedto reduce the memory required to implement cross-wordphonetic models.RECOGNIT ION RESULTSThe initial work developing and implementing the abovedescribed stack decoder was performed using the Re-source Management (RM) database\[18\].
The WSJ-pilotdatabase training and development-test data has onlybeen fully available for about 5 weeks (as of this writ-ing) and therefore the number of experiments hat havebeen performed on it is limited.
Where possible, resultswill be reported on the WSJ-pilot database, but someresults will be quoted from work performed on the RMdatabases.
All results must be considered preliminary,particularly since, as noted above, only non-cross-wordtriphones are being used and the recognizer has knownbut as yet unfixed algorithmic/implementation bugs.One result that became obvious very quickly after tran-sitioning to the WSJ data was that algorithmic decisionsmade on the RM data could be very inappropriate for theWSJ task (and presumably any similar large vocabularytask).
For instance, work on the RM task suggested thata triphone FM tree with a monophone FM-boundingtree was a good choice for the AFM.
This worked verywell for RM but rather slowly for WSJ.
The triphoneFM dominated the computation and was so slow that itslowed down the entire system.
The diphone trees men-tioned above were significantly faster for WSJ and stillworked very well for RM.
Similarly, the run-times aremuch longer and the recognition error rates are muchhigher for WSJ experiments indicating that it is a sig-nificantly harder task than RM.
The stack decoder isalso more than an order-of-magnitude faster than theTS decoder on an RM with a (full-branching) bigramLM task.A series of no-LM tests using RM training and test datawas performed to demonstrate he large vocabulary ca-pability of the stack decoder.
Since a dictionary was notavailable at the time this test was performed, a "tri-letter" dictionary was used (ie.
each three letter se-quence is used in the same fashion as one would usea triphone).
The recognizer used RM words augmentedwith WSJ words to achieve the desired vocabulary.
Overa vocabulary size range of 1K to 64K words, the systemran effectively with computation time proportional tothe square root of the vocabulary size.
The stack decoderused in this test contained a triphone-based FM and thusthis result is mostly indicative of the FM computationalrequirements.
This decoder was also demonstrated onthe 64K-word task using a perplexity 79 bigram LM.The stack decoder was tested on a variety of the con-ditions provided by the WSJ-pilot database (Table 1).Due to the limited time available and the immature stateof the decoder, only a subset of the available conditionscould be tested.
Since we were primarily interested intheperformance ofthe decoder, only closed vocabulary testswere performed.
(In a closed vocabulary test, all wordsin the test set are in the recognizer's vocabulary.)
Thelanguage models are N-gram back-off LMs\[8,12\].
The bi-gram models are "baseline" models and the dictionary is401a function word dependent triphone dictionary derivedfrom the "baseline" dictionary supplied by Dragon.
(Thebaseline components are standardized components sup-plied with the database\[17\].
)Inspection of the actual output of the system reveals anon-trivial number of malfunctions.
(The total effect ofthese problems on the results is probably less than 10%of the numbers in Table 1.)
In some cases, the likelihoodof the output sentence is less than the likelihood of thecorrect sentence.
This could be caused by a pruningerror (either FM or DM) or a bug in one (or more) ofthe routines.
Another problem which shows up is anincorrect likelihood for the output theory, probably dueto occasional errors in locating the most likely outputtime for a theory (t_ezit).Inspection of these results (Table 1) suggests several ob-'servations.
Comparison of lines 2 and 3 show a signifi-cant improvement (8.0% v. 10.1% word error) when 2400rather than 600 SD training sentences are used.
Thus,the "knee" in the function of performance vs. amountof training data is not reached by 600 SD training sen-tences.
Comparison of the LSD trained systems howsthe error rate to increase less than linearly with theperplexity: V=5K, p=44: 6.0%; V=5K, p=80: 8.0%;V=5K, p=l18: 10.5%; V=20K, p=158: 13.6%; andV=20K, p=236: 18.0%.RAPID SPEAKER ENROLLMENTThere are four basic methods of producing acoustic mod-els for speech recognition: static SI training, static SDtraining, rapid speaker enrollment, and recognition-timeadaptation.
The two static methods train the modelsusing prerecorded ata and do not change the modelsthereafter.
Rapid speaker enrollment records a smallamount of data from a speaker and uses the data toadapt an existing set of models.
Recognition-time adap-tation adapts the models to the speaker during the recog-nition process and may be supervised or unsuperviseddepending on whether or not the speaker corrects therecognition output.
We have added a rapid enrollmentmode to our TM trainer.The rapid enrollment algorithm used is: read an existingset of TM models into the trainer and adapt (train) onlythe Gaussians based upon the new data\[19\].
To date,only a few pilot experiments u ing one test speaker havebeen performed, shown in Table 2.
(The recognitionexperiments were performed using an obsolete versionof the recognizer with a higher error rate than the oneused to produce the database results, so the two tablesshould not be compared.)
These results uggest that theadaptation algorithm is operational, but are too statis-402tically weak to draw any firm conclusions.
They suggestthat another speaker's SD models may give poor ini-tial performance, but are improved significantly by therapid enrollment process.
Both SI models perform bet-ter initially, but are only improved a small amount bythe enrollment.
All three sets of rapid-enrolled modelsgave similar performance.
And, as usual, SD models,given enough training data, yield the best performance.DISCUSSION AND CONCLUSIONSThe results of these investigations suggest that the stackdecoder will be a viable competitor to time synchronousapproaches.
(This should come as no surprise since IBMhas had operational stack decoders for years\[l\].)
Theseresults also show that a number of additional strategies,such as covered LMF-equivalent theory elimination arenecessary to achieve useful speeds.
(In one test where abug prevented the covered LMF-equivalent theory elim-ination, a 4000 element stack overflowed after 10 CPUhours.
After the bug was fixed, the sentence decoded in10 minutes with a maximum stack size of less than 100.This much improvement while dramatic, was rare--thesystem with the bug successfully decoded many othersentences.)
Very few sentences require a stack size ex-ceeding a few hundred theories.
Several other tech-niques, such as efficient fast matches and sharing eachfast match across a group of theories--which can limitthe number of acoustic fast matches to less than one perinput observation were found to be important.
Tied mix-ture pdfs are expensive to compute and the caching ofthe pdfs is also vital to achieving adequate speeds.
Evenwith the caching, the pdf computation can be the singlemost expensive operation.The tests on rapid speaker enrollment reported here arelittle more than pilot tests for debugging purposes and nostrong conclusions can be drawn.
The results, however,show promise and will require more rigorous testing.So far, we have not addressed such issues as recognition-time speaker adaptation and language-model adaptation(ie.
handling out-of-vocabulary words at recognitiontime).
The current ests show error propagation not tobe a serious problem, so the initial reaction to an out-of-vocabulary word--a recognition error--should not causeproblems elsewhere in the input.
Nor have we had achance to test on the spontaneous data recorded as partof the WSJ-pilot database.The recognition results achieved on the WSJ-pilotdatabase are encouraging.
Even without cross-word pho-netic models (cross-word phonetic models halved our er-ror rates for RM using the TS decoder\[14\]), the errorrates are high enough to show the WSJ task to be verychallenging, but not so high that one is intimidated bythe task.
We hope to improve our future performance byfixing some of the bugs, by improving the quality of ourmodeling techniques, and by making the system moreable to adapt to its user and environment.REFERENCES1.
L. R. Bahl, F. Jelinek, and R. L. Mercer, "A Maxi-mum Likelihood Approach to Continuous Speech Recog-nition," IEEE Trans.
Pattern Analysis and Machine In-telligence, PAMI-5, March 1983.2.
L. Bahl, P. S. Gopalakrishnam, D. Kanevsky, D. Na-hamoo, "Matrix Fast Match: A Fast Method for Iden-tifying a Short List of Candidate Words for Decoding,"ICASSP 89, Glasgow, May 1989.3.
L. Bahl, S. V. De Gennaro, P. S. Gopalakrishnam, R. L.Mercer, "A Fast Approximate Acoustic Match for LargeVocabulary Speech Recognition," submitted to ASSP.4.
J.R. Bellegaxda nd D.H. Nahamoo, "Tied Mixture Con-tinuous Parameter Models for Large Vocabulary IsolatedSpeech Recognition," Proc.
ICASSP 89, Glasgow, May1989.5.
L. S. Gillick and R. Roth, "A Rapid Match Algorithmfor Continuous Speech Recognition," Proceedings June1990 Speech and Natural Language Workshop, MorganKanfmann Publishers, June, 1990.6.
X. D. I-Iuang and M.A.
Jack, "Semi-continuous Hid-den Markov Models for Speech Recognition," ComputerSpeech and Language, Vol.
3, 1989.7.
F. Jelinek, "A Fast Sequential Decoding Algorithm Us-ing a Stack," IBM J. Res.
Develop., vol.
13, November1969.8.
S. M. Katz, "Estimation of Probabilities from SparseData for the Language Model Component of a SpeechRecognizer," ASSP-35, pp 400-401, March 1987.9.
K. F. Lee, Automatic Speech Recognition: The Devel-opment o\] the SPHINX System, Kluwer Academic Pub-lishers, Norwell, MA, 1989.10.
D.B.
Paul and E. A. Martin, "Speaker Stress-ResistantContinuous Speech Recognition," Proc.
ICASSP 88,New York, NY, April 1988.11.
D. B. Paul, "A CSR-NL Interface Specification," Pro-ceedings October, 1989 DARPA Speech and NaturalLanguage Workshop, Morgan Kaufmann Publishers,October, 1989.12.
D. B. Paul, "Experience with a Stack Decoder-BasedHMM CSR and Back-Off N-Gram Language Models,"Proc.
DARPA Speech and Natural Language Workshop,Morgan Kaufmann Publishers, Feb. 1991.13.
D. B. Paul, "New Results with the Lincoln Tied-MixtureHMM CSR System," Proceedings Fourth DARPASpeech and Natural Language Workshop, Morgan Kanf-mann Publishers, February, 1991.14.
D. B. Paul, "The Lincoln Tied-Mixture HMM Contin-uous Speech Recognizer," ICASSP 91, Toronto, May1991.15.
D. B. Paul, "Algorithms for an Optimal A* Search andLinearizing the Search in the Stack Decoder," ICASSP91, Toronto, May 1991.16.
D. B. Paul, "An Efficient A* Stack Decoder Algorithmfor Continuous Speech Recognition with a StochasticLanguage Model," this proceedings.17.
D. B. Paul and J. M. Baker, "The Design for the WallStreet Journal-based CSR Corpus," this proceedings.18.
P. Price, W. Fisher, J. Bernstein, and D. Pallett, "TheDARPA 1000-Word Resource Management Databasefor Continuous Speech Recognition," ICASSP 88, NewYork, April 1988.19.
D. Rtischev, "Speaker Adaptation in a Large-Vocabulary Speech Recognition System," Masters The-sis, MIT, 1989.20.
R Schwartz, Y. Chow, O. Kimball, S. Roucos, M. Kras-ner, and J. Makhoul, "Context-Dependent Modeling forAcoustic-Phonetic Recognition of Continuous Speech,"Proc.
ICASSP 85, Tampa, FL, April 1985.403.2.3.4.5..7.
SI-848.
SI-129.
LSD10.
LSDTr.
sent Punct Vocab LM Perp Wd err (std dev)-\]LSD 2400LSD 2400SD (LSD)* 600LSD 2400SD 600SI-84 72007200720024002400VP 5K TG 44 6.0% (.5%)VP 5K BG 80 8.0% (.6%)VP 5K BG 80 10.1% (.6%)NVP 5K BG 118 10.5% (.7%)VP 5K BG 80 12.6% (.4%)VP 5K TG 44 15.0% (.8%)VP 5K BG 80 19.3% (.8%)VP 5K BG 80 21.7% (.8%)20K BG 236 18.0% (.8%)Table 1: WSJ Development Test Results: ?
LSD speaker subset of line 5; LSD=longitudinal SD (3 spkr subset of SD);SD: 12 speakers; SI-84: train on 84 speakers, test on 10 SI-test speakers; SI-12: trained on all 12 SD speakers, teston 10 SI-test speakers; VP=verbalized punctuation; NVP=non-verbalized punctuation; TG=trigram; BG=bigram;std dev=binomial standard eviation; The dictionary is a function-word ependent triphone dictionary.
All bigramlanguage models are the "baseline" models and all tests use a closed recognition vocabulary.LSD-2400 (test speaker)LSD-2400 (test speaker)LSD-2400 (non-test speaker)LSD-2400 (non-test speaker)SI-84SI-12SI-12noyesnoyesnoyesnoyes11%13%30%21%22%18%19%18%Standard LSD(control)Standard SI-84Standard SI-12Table 2: Rapid Enrollment Test Results: These are pilot results tested on one non-database peaker using an obsoleteversion of the stack decoder and a non-standard (biased) set of 20 short WSJ test sentences containing 168 words,so comparisons should not be made with the development test results.
The standard eviation of the error rates isabout 3%.
Enrollment was performed using the standard WSJ 40 adaptation sentences recorded by the test speaker.Test conditions: 1 speaker, VP, 5K, BG (p=80).404
