The GE NLToolset:A Software Foundat ion for Intel l igent Text ProcessingPau l  S. Jacobs  and  L i sa  F .
RauArt i f ic ia l  Inte l l igence ProgramCI'; Research  and Deve lopment  CenterSchenectady ,  NY  12301 USArau~crd .ge .com,  ps jacobsC~crd.ge.comMany obstacles tand in the way of computer pro-grams that could read and digest volumes of natu-ral language text.
The foremost of these difficultiesis the quantity and variety of knowledge about lan-guage and about the world that seems to be a pre-requisite for any substantial language understanding.In its most general form, the robust text processingproblem remains insurmountable; yet practical ap-plications of text processing are realizable throngha combination of knowledge representation a d lan-guage analysis strategies.This project note describes the GE NLToo~s~,:Tand its use in two text processing applications.
Inthe first, dornain, the system selects and analyzes to-ries about corporate mergers and acquisitions as theycome across a real-time news feed.
In the second do~main, the program uses naval operations messages tofill a 10--field template.
In both cases, users can asknatural language questions about, the contents of thetexts, and the system responds with direct answersalong with the original text.The GE NLTooLsET is a software foundation fortext processing.
The NL'I'OOLS~?
'r derives from aresearch effort aimed at preserving the capabilitiesof naturM language text processing across domains.The program achieves this transportability by usinga core knowledge base and lexicon that customizeseasily to new applications, along with a flexible textprocessing strategy tolerant of gaps in the program'sknowledge base.
Developed over the last four years,it runs in real time on a SUN TM workstation in Com-mon Lisp under UNIX TM.
It performs the followingt asks:?
The lexical analysis of the input characterstream, including names, dates, numbers, a, ndeorttractions.?
The separation of the raw news feed into storystructures, with separate headline, byline anddateline designations.?
A topic determination fbr each story, indicatingwhether it is about a corporate merger.?
The natural language analysis of each selectedstory using an integration of two interpretationstrategies--"bottom-up" linguistic analysis and"top-down" conceptual interpretation.o The storage and retrieval of conceptual represen-tations of the processed texts into and out of aknowledge base.The design of the NLTooLsET combines arti-ficial intelligence (AI) methods, especially naturallanguage processing, knowledge representation, andinformation retrieval techniques, with more robustbut superficial methods, such as lexical analysis andword-based text search.
This approach provides thebroad flmctionality of AI systems without sacrific-ing robnstness or processing speed.
In fact, thesystem has a throughput for real text greater thanany other text extraction system we have seen (e.g.,\[Sondheimer, 1986; Sundheim, 1990\]), while provid-ing knowledge-based capabilities uch as producinganswers to English questions and identifying key con-ceptual roles in the text (such as the suitor, target,and per-.share price of a merger offer).
The NL-TooLs~'r consists of roughly 50,000 lines of CommonLisp code.
It was developed entirely on SUN work-stations.1 Techn ica l  Overv iewThe NLTOoLSFT's design provides each system com-ponent with access to a rich hand-coded knowledgebase, but each component applies the knowledge se-lectively, avoiding the computation that a completeanalysis of each text would require.
The architectureof the system allows for levels of language analysis,f?om rough skimming \[Jacobs, 1990\] to in-depth con-ceptual i:nterpretation \[aacobs, 1987\].A custom-built 10,000 word-root lexicon and con-cept hierarchy provides a rich source of lexical infor-mation.
Entries are separated by their senses, andcontain special context clues to help in the sense-disambiguation process.
A morphological analyzercontains emantics for about 75 affixes, and can au-tomatically derive the meanings of inflected entriesnot separately represented in the lexicon.
Domain-specific words and phrases are added to the lexiconby connecting them to higher-level concepts and cat-egories present in the system's core lexicon and con~cept hierarchy.
This is one aspect of the NLTOOLSETthat makes it highly portable from one domain to an-other.The language analysis strategy used in the NL-TOOLSET combines full syntactic (bottom-up) pars-ing and conceptual expectation-driven (top-down)parsing.
Four knowledge sources, including syntacticand semantic information and domain knowledge, in-teract in a flexible manner.
This integration producesa more robust semantic analyzer that deals gracefullywith gaps in lexieal and syntactic knowledge, trans-1 373.~m i~ :.
'~:V& ~ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.Art i c le  Number :  4C lass l f l ca t ion :  Takeover~.A.
I IANNA CO.  ACQUIRES~RU(~( PLAST ICS  CO?CLEVELAND -D J -  M .A .
HANNA CO.  SA ID  IT:OMPI .ETED ITS  PREVIOUSLY  REPORTED ACQUIS IT ION OF~RUCK PLAST ICS  CO. ,  A POLYMER RES INS D ISTR IBUTOR9ASED NEAR CHICAGO,  FOR UNDISCLOSED TERMS.BRUCK HAS ANNUAL REVEHDE OF  ABOUT $ I00~ILL ION.-0 -  9 28  AM EDT 04-03-89: "?
;.
.
.
.
, ,i~mm.#m+<,i'.
II i III I -tc le  Mo.
: 20ar~%: Mayfair Super HarketsTA~ .
.
.
.AH:ic le Mo.
:  37Tar~%: Major RealtySuitor: Stoneridge*~*n~TICLE  4 STORY REPRESENTAT ION ~ *C -CORP-TAKEOVERR-SUBEVENT:  VERB_COMPLETE IR -TARGET:C -BUSINESS-ORGR-CO-SALES:  $ 100 ,000 ,000R-NAME:  Bruck  P las t i csR -SU ITOR:C -BUSINESS-0RGR-NAME:  M A HannaL9: Copper al~r N. ~, aay 131.80 dn .80 \]ly 124.50 da 1.50 platinu~ apr 526.00~0: I~r fa i r  9mrs lmyout p~posa l+~1: Burger k ing nyse opening prices~+2: Mca Inc opening delayed- order  ilbalance- last selsctronlcs outlook\]3: Poehl- bundesbank- in%erventlon!4: Ih, s rn ight  9 7- 8- 3- 4 "to~,- next g 7- 8- 3- 4 sloo%- next  9 7- 8- 3- 4 725: 7 C a zhr vs op net 9 c215: ~d~ C8~?.
za\]~ $ 9.75 ~ ~hr le~Jer ~ m ~  ~m~le%~27: CORP. c lasz  b ' s  last sale was 2 7- 8.+--  .,;,r, tn .m~m .
.
.
.
.
.
.
.
.
.
.
.
|,~6\] ~ne/ho~e/~culpto~/u2/~~upka/n l t2 .0 /Too l too l /~~.4/tooltool ~f ...:63 16631Ray Text .~"- - (3~ Tokenized Ar t i c le  "*JL,+tlcl.
No.
: 51 d\[,._.O~.d~J t ?-+o wv.
j ~ ~ ~ Ill .
.
.
.
'"Target: American Building Kaintenauce t / ' '~'  ' ++ - - - - - ~ - ~  - - - -  It ~m ~esUo~ +.99  = ~ ~ ~ .
.
.
.
-~|l~++m- .
.
.
.
.
.
__  _ - ,................ ~t~r  the article number: 4 ~ ~i+~+++~++:+~+++++++++~+~~++++i~+++~+~+++++++i+~++~++++++++++++~m+~.`~+++++~++++++~i+++i++i~+++~+++++++++++++++++~;+++P:++++~++++++++~+++++++++++~:~:++.~++++t+++~++~+++++++~.~'~+.~.~++~+++++i++++#~++++++~~~Figure h Sc lsoa in actionports easily to new domains, and fanilitates the ex-traction of information from texts \[Rau and Jacobs,1988\].Two prototype systems (both to be demonstratedat Coling) illustrate some of the capabilities of theNLTooLSET.
SC ISOR (System for Conceptual In-formation Summarization, Organization, and Re-trieval) reads financial news stories from a news ser-vice, selects stories about mergers and acquisitions,extracts key pieces of information from those sto-ries, and answers English questions about this infor-mation.
MUCK-I I  (a demonstration from a mes-sage understanding conference in 1989 \[Sundheim,1990\]) shows some of the same capabilities, includ-ing database generation, question answering, and au-tomatic alert, applied to a set of naval messages(OPREP-3).
Both systems process texts at a rateof hundreds of paragraphs per hour.
The customiza-tion of the NLTOoLSET to the MUCK-II  applica-tion, porting from the domain of corporate takeoversto naval operations, required only several weeks.2 SC ISORSCISOR is a customization of the NLTOOLSET tothe domain of news stories about mergers and acqui-sitions.
The program analyzes tories a.s they comeacross a live news feed, selecting the takeover storiesand applying a combination of top-down and bottom-up language analysis to identify conceptual roles inthe stories.
The result of this analysis is a single rep-resentation of each story that the program adds toa central knowledge base.
The conceptual retrievalcomponent accesses information from this knowledgebase by analyzing English questions in the same man-ner and matching the questions to the story represen-tations stored in the knowledge base.ScBoR provides the user with information in mul-tiple forms.
Users can browse the headlines and theoriginal texts.
A "hot window" continuously displaysthe target, suitor, and price of the latest takeoverstories, and flashes when a new takeover story comesacross the wire.
For more general information eeds,an "ask question" window allows the user to type insimple English questions (e. g., "What was offeredfor Polaroid?")
as well as query fragments (e. g.,374 2"acquisitions by Shamrock").Figure 1 shows a SUN screen during the opera-tion of SClsoR.
The "Master Control" window inthe lower right allows the user to open or access thevariou,'~ features of the system.
The "}Ieadlincs" and"Display Control" in the lower center show the head-lines of all stories (with headlines of takeover storiesin bold) and guide the selection of texts for browsing.The "Hot Window", or alert feature, is at the lowerleft, alerting users the instant a new, potentially rel-evant article comes across the news wire.
The "RawText" and "Trump Representation" windows at thetop display each selected story, showing key portionsof text in boldface with a summary of the languageanalysis in the upper right.More details on the system design and operation ofSCISOR can be found in \[Jacobs and Rau, 1990\].3 Per fo rmance  Eva lu t ionPerformance valuation of natural language systemsis a new problem, although the evaluation methodscan adopt some of the techniques of traditional infor-mation retrieval (IR) systelns.
It would be difficultand probably futile to perform a controlled study ofthe NLTOOLSET against a traditional IR system, fortwo reasons: (1) traditional IR systems are testedon ~bitrary, unconstrained texts, while natural an-guage systems till work only in constrained omains;(2) the NLTOOLSET performs many tasks other thandocument retrieval, such as extracting informationfrom stories and directly answering users' questions.Evaluation problems of the entire system stem fromthe unique functionality of the NLTOoLS~;T system.Document retrieval systems, even sophisticated oneslike RuBRIc\[Tong et al, 1986\], do not extract fea-tures from from the documents they retrieve; thus itis impossible to compare them to NI,TooLsET.
tfow-ever, we have performed some tests that do measurethe NLTooLS~T's accuracy in specific tasks.The government-sponsored MUCK-II evaluationis, to our knowledge, the most meaningful test of nat-ural language text processing, but the participants inthe MUCK-II evaluation agreed not to release thespecific results of the experiment.
Itowever, we willtry to summarize the status of performance valua-tion in general terms.
Evaluation of content-basedtext processing systems like SclsoP~ is not nearly asestablished as evaluation methods in information re-trieval.
There are many tasks to be tested in thisemerging type of system, including accuracy of ques-tion answering, helpfulness of alerts, and coverage ofstructured information (such as target and suitor).No mature methods exist for testing any of thesetasks.In spite of the problems with evaluating this sortof system, we would like to be informative abouthow our program performs.
As a rule, it can extractkey features from large sets of constrained texts with80-90% (combined recall and precision) accuracy.
Itcan achieve better results (and has) with more con-strained texts, but would also produce almost nothinguseful, say, in reading the entire Wall Street Jour-nal.
It is realistic to expect 90% accuracy for certainuseflfl, carefiflly-constructed asks, and unrealistic toexpect much higher than this 1.
Many ditficulties inreading texts appear when trying to achieve betterresults, but the most common limitation seems to bethe degree of real inference required for understand-ing.
In spite of its fairly sophisticated methods forcombining linguistic and world knowledge, the NL-TOOLSE'r really has very little of the latter.In a recent test of ScISOR, the program analyzedone day's worth of stories directly from the newswiresource.
Of the 729 stories, the filter achieved slightlyover 90% averaged recall and precision in its deter-mination of which stories were about mergers andacquisitions (69 in all).
Sclso~t correctly identifiedthe target and suitor in 90% of all the stories.
Whendollar-per-share amounts of offers were present in thestories, Sclso~t extracted this quantity correctly 79%of the time, and the total value of the offer 82% ofthe time.References\[DeJong, 1979\] Gerald DeJong.
Prediction and sub-stantiation: A new approach to natural languageprocessing.
Cognitive Science, 3(3):251---273, 1979.\[Jacobs and Ran, 1990\] Paul Jacobs and Lisa llau.SCISOR: A system tbr extracting information fromon-line news.
Communications of the Associa-tion for Computing Machinery, 35, (in.
$ubm.is-sion) 1990.\[Jacobs, 1987\] Paul S. Jacobs.
A knowledge frame-work tbr natural anguage analysis.
In Proceedingsof the Tenth International Joint Conference on Ar-tificial Intelligence, Milan, Italy, 1987.\[Jacobs, 1990\] P. Jacobs.
To parse or not to parse:Relation~driven text skimming.
In Proceedings ofthe Thirteenth Inter'national ConfereT~ce on Com-putational Linguistics, IIelsinki, Finland, 1990.\[Rau and Jacobs, 1988\] Lisa F. Rau and Paul S. Ja-cobs.
Integrating top-down and bottom-up strate-gies in a text processing system.
In Proceedings ofSecond Conference on Applied Natural LanguageProcessing, pages 129-135, Morristown, NJ, Feb1988.
ACL.\[Sondheimer, 1986\] N Sondheimer.
Proceedings ofDARPA's 1986 strategic computing natural lan-guage processing workshop.
Technical ReportISI/SR-86-172, University of Southern California,ISI, 1986.\[Sundheim, 1990\] Beth Sundheim.
Second messageunderstanding conference (MUCK-II) test report.Technical Report 1328, Naval Ocean Systems Cen-ter, San Diego, CA, 1990.\[Tong et al, 1986\] Richard M. Tong, L. A. Appel-baum, V. N. Askman, and J. F. Cunningham.RUBRIC iII: An object-oriented xpert system forinformation retrieval.
In Proceedings of the 2nd An-nual IEEE Symposium on Expert Systems in Gov-e~nrnent, W~hington, DC., October 1986.
IEEEComputer Society Press.1The I"l{UMP\[DeJong, 1979\] program, for comparisonpurposes, achieved 38% accuracy in one test on newswirestories.3 375
