ROBUST METHOD OF PRONOUN RESOLUTIONUS ING FULL-TEXT INFORMATIONTetsuya NasukawaIBM Research ,  Tokyo  Research  Laboratory1623-14,  Sh imotsuruma,  Yamato-sh i ,  Kanagawa-ken  242, JapanAbst ractA consistent text contains rich inforlnation for resolv-ing mnbiguities within its sentences.
Even simple syn-tactic information such as word occurrence and col-location patterns, which can be extra(:ted fi'om thetext without deep discourse analysis, lint)roves theaccuracy of sentence analysis.
Pronoml resolutionis a typical proceeding that utilizes this information.Through the use of this inforlnation, along with in-formation on the syntactic position of each candidate,93.8% of pronoun references were resolved correctlyin an experiment on computer mammls.1 In t roduct ionResolving t>ronoun reference is a diifieult task thatrequires consideration of both linguistic and cogni-tive aspects of a language.
As a linguistic phe-nomenon, the use of pronouns is treated a.s a co-referential prohlem in which both the antecedent andthe pronoun co-refer to some object.
From this pointof view, finding the object that is co-referred to bya pronoun is the main problem in t)ronoun resolu-tion, and much research as been devoted to focus-ing on or inferring the referent object by consider-ing the grammatical and semantic roles of each en-tity in the sentences \[Sidner, 1983; Brennan, 1987;Kameyama, 1993\].
This task is especially difficultwhen the referent object is not explicitly stated ina text, and common sense and deep inference are re-quired in order to figure out the object, sLs in the clas-sic problems descrit)ed by Charniak \[Charniak, 1973\].Since this approach of considering the grammaticaland semantic roles of each entity depends heavily onaccurate syntactic anMysis avd semantic analysis, itis not yet applicable to practicM systems.However, if we do not aim for perfect analy-sis, a simple syntactic-based heuristic rule for s-electing a correct antecedent from several candi-date noun phra~ses i)erforms quite well, especiMlyin technical documents uch as computer manual-s, in which we can usuMly expect an explMt an-tecedent within the same sentence or in a previoussentence.
In this domain, a correct ante(:edent canbe selected in ahnost 90% of all causes without anyworld knowledge other than simple semantic con-straints \[Hobbs, 1978; Walker, 1989; Lappin, 1990\].Moreover, several heuristic rules can be combinedto improve the accuracy of the analysis \[Rich, 1988;Carboi,ell, 1988\].This approach of resolving pronoun reference byapplying simple heuristic rules seeins to be ade.quatefor a practical naturM language processing system,yet in order to achieve a success ratio of over 90%,some kind of knowledge processing is required, suchas the use of world knowledge or deep inference mech-anisms for constructing and referring to a discoursestructure.
While the advantage of knowledge pro-cessing is widely recognized, this approach presup-poses a large quantity of knowledge resources, andleads to a knowledge acquisition bottleneck.
In or-der to solve this problem, wmous studies have beendone on methods of using on-line text databa~ses withless human intervention for word sense disambigua-tion attd structural disambiguation \[Jensen, 1987;Nagao, 1990; Uramoto, 1991; Hindle, 1993\].
Thesemethods can be applied to knowledge processing inpronoun resohltion; however, no research as yet re-veMed sutficient world knowledge to cover general1)roblems.
In other words, methods of using worldknowledge have not reached a level sufficiently ma-ture for them to be used in broad-coverage systems.This paper prol)oses a simple and robust approachthat utilizes inte.r-sentential information, extractedfrom a source text by means of a simple algorithm,to improve the accuracy of pronoun resolution.
Forexample, (:olloeation patterns within a text offer in-formation that eorrcsl)onds to ease frames in worldknowledge, and word frequency also gives informa-tion reh!wmt to the tot)it or focus of the subjects.Thus, instead of using outside knowledge resources,such information serves as world knowledge appropri-ate to the narrow domain of the source text.
The ef-fectiveness of each type of information extracted froma source text is evaluated in the light of the results ofexperiments on comlmter lnanuals.In the next section, we introduce three effectivefactors in the selection of an antecedent from candi-date noun phra.ses.
Then, in the third section, we1157specify the implementation of this method.
Finally,in the fourth section, we evaluate the effectiveness ofthis approach on the basis of the results of an exper-iment.2 Three  fac tors  for  eva luat ingsa l ience  in  cand idatesIn our approach, pronoun resolution basically consist-s of collecting candidate noun phrases and selectingthe most preferable candidate as the antecedent ofa pronoun by applying several rules to filter out in-appropriate candidates and to attach preferences toappropriate candidates.
Rules are divided into twotypes.
One type represents grammatical constraintsthat must be satisfied, such as number and genderagreement.
Since rules of this type can filter out i-nappropriate candidates, we apply them at an ear-ly stage of pronoun resolution.
The remaining rulesconstitute the other type, which attaches a preferenceto each candidate noun phrase.
After inappropriatecandidates have been filtered out by the former rules,the latter rules determine the most appropriate can-didate by measuring the sMience of each remainingcandidate noun phrase.
Thus, the latter rules are im-portant for selecting the exact antecedent from theremaining candidates and for improving the accuracyof pronoun resolution.In this section~ we describe three effective factorsthat utilize full-text information for measuring thesalience of each candidate noun phrase.
The reasonsfor their effectiveness are that  they cover many as-pects of linguistic phenomena nd that their inter-pretation is simple enough to be used in a practicalsystem.2.1 Collocation patterns within asource textIn previous approaches, semantic constraints havebeen among the most basic factors for filtering outcandidates that would be inappropriate as modifier-s of the modifiee of a pronoun.
However, in orderto apply semantic onstraints with broad coverage, alarge amount of knowledge is required.
For example,in processing a sample sentence provided by Hobbs\[Hobbs, 1978\],The castle in Camelot remained the resi-dence o/ the king until 536 when he movedit to London,the following knowledge must be supplied in order tofilter out the candidates 536, castle, and Camelot, andleave the correct antecedent, residence:?
Dates cannot move.?
Places cannot l~love.?
Large fixed objects cannot move.In order to apply this knowledge, we also prcsul)posea correct analysis that categorizes each nmm phraseas a date, place, large fixed object, and so on.
Sincemany of the words in these noun phrases have wordsense ambiguities, it is not practical to presupposethe correct application of such knowledge.
Assem-bling a large body of knowledge poses another majorproblem.instead of such worhl knowledge, collocation pat-terns (namely, modifiee-modifier relationships) ex-tracted from a discourse can be applied.
Since wordsense is usually unified within a discourse, and mostwords with the same lemma are frequently repeat-ed \[Gale, 1992; Nasukawa, 1993\], the collocation pat-terns in the same discourse provide valuable datafor determining whether a candidate can modify themodifiee of Ct pronoun.
For example, if the sentenceHe moved his residenceis found in the discourse, this information indicatesthat the word residence can be the object of the verbmove.
Thus~ the inh)rmation works as a selectionalconstraint that  the candidate can be an argument ofa predicate that dominates the pronoun.Moreover, since statements tend to be repeatedin a discourse, the existence of an identical colloca-tion pattern in a discourse may support selection ofthe candidate as the antecedent.
In this sense, thepreference for an identicM collocation pattern alsoreflects case role persistence preference and syntac-tic parM1elism preference, prolmsed by Carbonell andBrown \[Carbonell, 1988\].
The case role persistencerule prefers a candidate noun phrase that filled an i-dentical case role in an earlier sentence.
For example,after the sentenceMary gave an apple to Susan,Susan is referred to by her inJohn also gave her an apple,while Mary is referred to by she inShe also gave John an apple.The syntactic 1)arM1elism rule prefers a candidatenoun phrase that preserves its surface syntactic rolefrom the first of two or more coordinate clauses.
Forexample, in7158The girl scout leader paired Mary with.
Su-san, but she had paired her with Nancylast time,she refl,'rs to leader, and her refers to Mary,whereas inThe girl scout leader paired Mary with Su-san, but she had paired Nancy with herlast time,she refers go leader, ait(\[ her refers to ,S'usan.
By re-ferring to the i(lenticM collocation Iiatterns, we (:~utresolve all the pronouns in the above examples (:or-rectly.Since the idcntit ication of modifier-modifiee r lationshii)s is a basic feature of syntact ic analysis, a pro-cedure for identifying identical collocation patterns isnot a hard task, as long as M1 of the sentences areparsed by a single system and share a single l'orm~fl-ism for expressing modifier-modii iee r lationships.2.2 l~'equency of repetition in preced-ing sentencesA characteristic of the i)ronolnimflization on whi(:hthe centering apln'oach \[Sidner, 1983; Ilr(,mlan, 1987;Kameyama, 1993\] is l);Lsed is that  an object in focusis likely to hc pronomimtlized.
If this characteristicis expanded to all definite anaphoras,  which includedetinite noun phrases as well as pronouns, a candidatenoun phrase that is in focus inay be repeated as a def-inite noun phrase before it is pronomiilalized.
Thus,the frequen(:y in 1)receding sentences of a nouu i)hrasewith the same lemma ~s ~t candidate noun l)hr~use (:aabe an index for the preference with whi(:h it is selectedas the antecedent.
The 1)roeess for a.ssigning this 1)ref-erence consists of a simple string match that cheekswords with the same lcmma in preceding sentences.In addit ion, when the source text is marked upwith SGML or other su(-h tags, the roles of somephrases uch as titles mid headings call he easily re(>ognized, and words with such roles tend to representthe topics of the sentences fifth)wing them.
Thus, ~(\[-ditional preference can be assigned by checking thetags of each word.2.3 Syntactic positionAs shown by tIobtis \[ltobl)s, 1978\], a heuristic t'ule fa-voring subjects over objects l)erforlns remarkably wellin English text.
By traversing th(' surface parse treeof a sentence, a 1)referen(:e vMue can be provided foreach candidate noun phrase according to its syntact icposition.
This factor has mt advantage over other fa(>tors shown in 1)revious ubsections in the sense thatit: assigns a definite ranking for ea(:h candidate nounI)hrase, since ea(:h o(:eul)ies a syntact ic posit ion in atext.
Thus, this factor l)rovides a default value forthe l)reference of ea(;h (:an(lidate itOUlt t)hrase whenno oth('r factor provides wfiid information, and it isad('(luat(~ for a r(It)ust approach since it is basicallyassigned t)y traversing tho surface l)arse trees of asen t.enee.3 Imp lementat ionIn this sect;ion, we describe the actual imple-lnel ltation of (;he l)rottoUll resohltiott procedllre illml Fmglish-to-Japanese.
machine translat ion system,Shalt2 \[Takeda, 1992\].The procedure consists of two steps:1.
Extract ion of ca.ndidat(:s for an mltec(,dent2.
Selecti(m of I;he correct antece(tent fl'om thecandidates.\[11 or(let t(/ achieve ttigh(!r ac(;llracy itl l)rolloull res-olut ion with robust lirocessing, our straeegy consistsof1.
Extending a list of ( 'andidate noun ptm~scs otht~t it does noL ex(:lude a correct antecedent2.
\]leferring t() all information in the source textthat can be syntactical ly extracted without re-ferring to outside knowledge resources, in orde, rto sele(:t the corre('.t ante(:e(lent.3.1 Extraction of candidates' fo ensure that  the correct antecedent is in(:luded ina list of candidate noun t)hrases, candidates are ex-tra(:ted from exa(:tly two sentences with lninimum til-tering.
First, the system cheeks whether any nountihrases earlier in the same sentence satisfy the num--ber and gender constraints.
It then checks the t)reced -ing sentences in order of proximity until candidateshave bct}ll YOlllI(\[ ill exactly two sentell(:es.l)uring the extract ion of the candidates, the sys-tem filters out noun phrases that do not satisfy thenuml)er and gender constrmnts,  and Mso direct mod-ifiees of the pronoun and its arguments,  so that  anoll-reIlexive 1)rOllOlllt all(t its anl;eced(mt nlay not oc-cur in I:he same siml)lex sentence, as would be thecase if data were the antecedent of it in the followingsentenc(~;The device that writes onto a magneticdi.sk and reads data from it is called a diskdrive.11593.2 Selection of an antecedentIn our implementation, the preference values provid-ed by the algorithms described in the following para-graphs are combined into a single value, and the can-didate noun phrase with the largest preference valueis selected as the antecedent.Preference according to the existence of iden-tical col location patterns in the textAs a preference value that indicates the satisfactionof selectional constraints and repetition of an iden-tical statement, we assigned a constant value 3 fora candidate that has an identical collocation patternwith the modifiee of a pronoun within the source tex-t.
Furthermore, in order to extend the use of colloca-tion patterns as knowledge on seleetional constraints,an on-line synonym dictionary \[3\] is referred to, andthus a collocation pattern with a synonym can sup-port candidates other than exactly identical colloca-tion patterns.Preference according to the f requency  of rep-e t i t ion  in preceding sentencesIn order to provide a larger preference value for clos-er and more frequent occurrences of a lemma, thepreference value is given by the total score calculatedaccording to the following formula, for each appear-ance of a noun phrase with the same lemma as timcandidate noun phrase that is found within the tenpreceding sentences:1(Number of sentencea to the identical noun phrase)+1.Preference according to syntactic posit ionAmong the candidate noun phrases, a candidate in acloser sentence, or the one nearest he beginning ofthe same sentence is preferred.
Besides the left-to-right order within a sentence, a negative preferencevalue is given for tile distance (number of sentences)from the sentence that contains the pronoun to thesentence that contains the candidate.
While the orderof preference of candidates that is obtained in thismanner is similar to that given by the naive algorithmproposed by Hobbs \[Hobbs, 1978\], our algorithm ismuch simpler, and does not even require the resultsof syntactic analysis.3.3 ExampleFigure 1 gives an example of system output thatcontains data on the preference ofeach candidate an-tecedent for a pronoun in a sample text extractedf,'om the second chapter of a computer manual \[2\] inthe mam, er described in the previous paragraphs.In this figure, the number in brackets before eachsentence indicates the sentence number in the text.As shown by these numbers, the output consists ofeleven consecutive sentences, front the 104th to the114th in the second chapter of the manuM.
* The or-der of candidates following the messageCandidates for the referent of CFRAME106579("it") are :reflects tile order of preference values obtained by re-ferring to the positimt of each candidate.
As shownin this list, key is the most preferable candidate fromthe viewpoint of syntactic position.
In this candi-date list, CFRhMEwuwo indicates an instance of eachcontent word in the dis(:ourse.
Information on theposition and on tile whole sentence can be extract-ed from each of these CFlt.AMEs.
A number in arrow-head brackets next to CFRAMEu~uu~u, such as <ll3>,indicates the number of the sentence in which it oc-curs.
A number in parentheses, such as 0.48571432in key (0.48871432), indicates the preference valueobtained by referring to the frequency of repetition.
2Thus, from the viewpoint of the number of repeti-tions, cursor is the most preferable candidate for theaI, tecedent.
At the bottmn of this figure, informationon modifier-modifiee r lationships that support can-didates is shown.
In this case, there is a collocationpattern such that cursor modifies the verb reaches,which is the modifiee of tile pronoun it; tiros, thisinformation prefers cursor for the antecedent of it.Finally, after combination of all the preferences, cur-sor is selected as the most preferable antecedent ofit.4 Resu l tsWe.
examined 112 third-person pronouns in 1904 con-secutive sentences fl'om eight chapters of two differ-ent computer manuals.
One \[1\] is a typical computermanual for computer experts such as programmersand system operators, and the other \[2\] is a primerfor novice users of a computer.In this experiment, we excluded instances in whichit pronmninalizes a sentence, as indo it,those in which it refers to a syntactically recoverablethat-clmlse or to-infinitive clause, and those in which~In the sentences contained in Figure 1, the underlining andtile change of font for the target pronoun it were done by tileattthor.2Noun phrases with the same lemma referred to in the pre-ceding sentences are indicated by underlines.1160(104)(105)(lO6)(lO~)(108)(109)(11o)(111)(112)(11a)O14)All  four of the cursor movement keys are typematic;they kee t) repeating as long ~s they are held down.The Cursor Up key moves the cnrsor up one line.Like the other cnrsor movement keys, this key moves the cursor one line or manylines depending on how long you hold down the key.The Cursor Right key moves the cursor to the right.Hoht the key down.When the cursor reaches the right end of the line, it goes off the screen andreappears on the left side, one line bdow the line it was on.I f  the cursor is on the bottom line of the screen and is run M1 the way to the right,it goes off the screen and reappears in the upper left corner.The Cursor Left key mow's the cursor one position to the left.1told this key down.When it reaches the left end of tile line, it goes off the screen and reappears ontile rigtlt, one line above the line it was on.Candidates for the referent of CFRAMEIO6579("it") are:CFRAMEI06573<113> .... key (0.48571432)CFKAMEI06564<I12> .... Cursor Left key (0)CFKAME106565<l l i>  .
.
.
.
cursor  (1 .4337664)CFKAME106568<l12> .
.
.
.
left (0)>> With DIANA <<>> To support CFRAMElO6565(cursor) <<i with SAME-ATTACHMENT-CAND-MODIFIEE in:" When the cursor reaches the right end of the line,it goes off the screen and reappears on the left side,one line below the line it was on .
"(reaches<CFRhME106454> in SENTENCEIO6453<No.
IIO>)Fig.
1: Saml)le data h)r resolving the first pronoun it in sentence 114it occurs in a time or weather construction.
When anidentical pronoun is included in the candidate list, thesystem assmnes that these pronouns hare tile sameantecedent.
For example, we assumed that M1 theinstances of it inWhen it reaches the left end of the line,it goes off the screen and reappears on theright, one line above the line it was onhave the same antecedent.As a result of our strategy of enlarging the scopefor selection of cmtdidates, tile average nuinber of can-didate noun phrases was 4.1.Our algorithm chose a correct antecedent in 105(:a.ses, giving a success ratio of 93.8%.
In 28 of those112 cases, there was among the candidates an iden-tical t)ronoun that; referred to the same anteceden-t; thus, in 84 cases, antecedents were selected by e-valuating the syntactic position, frequency of repeti-tion, and collocation pattern of each candidate nounphrase.As shown in Table 1, without any information onrepetition or collocation patterns, the success rate ofselection based only on syntactic position was 82.7%,while tile success rate for selection based only on fre-quency of repetition was 60.7%.
This result indicatesthat pronominMized noun phrases were actually re-peated more than twice within ten consecutive sen-tences in over 60% of the cases.
Thus, preferenceaccording to the frequency of repetition contributedto the selection of the correct antecedent.
In 16 of the22 cases in which this information preferred a wrongcandidate noun phrase, the preference value was over-ridden by the negative preference value caused by asyntactic position far from tile sentence of the pro-noun, or by a larger preference assigned to some othercandidate with an identicM collocation pattern.Identical collocation patterns were found withinthe same chapter in 22 of 84 cases in which the pref-erence value was ev',duated in selecting all anteceden-t.
Although this is only 26.2% of the cases, collo-cation preference (lid not support any wrong candi-dates.
Moreover, in 50.0% of the 22 cases, anotherpreference value, either syntactic position or repeti-tion, supported a wrong candidate.
Therefore, pref-erence according to collocation pattern contributedto the selection of the correct antecedent.Table 2 shows the distances and directions of sell-1161Table 1: Correlation between correct selection and selection in accordance with each type of pret~renceNumber of c,~sesin which tile correctantecedent was selectedNumber of casesin which the wrongantecedent was selectedNulnber of caseswithout anyvalid informationSyntactic 69 15 0position (82.1%) (17.9%)Frequency of 51 22 11repetition (60.7%) (26.2%) (13.1%)Existence of 22 0 62sinfilar collocation (26.2%) (0%) (73.8%)Table 2: Distribution of information relative to a sentence that contains information for modification preferenceForwardBackwardDistance (number of sentences)Number of occurrencesDistance (number of sentences)Number of occurreuces10&-4  5 -L  I 4 - 21-51  10 I i11  116-20 211211 I 0 \[ 2 0tences in which a collocation pattern supporting acandidate noun phrase to modify the modifiee of tilepronoun was found.
The results indicate that such in-formation was extracted from a relatively small areaof a text.
In addition, relative collocation patternswere extracted from both previous and following sen-tences.Out of the 37 cases in which the identical collo-cation patterns were found, synonym relations wereused in seven cases (18.9%).5 ConclusionWe have proposed a robust method of pronoun res-olutimL that  refers to information within tile sourcetext in order to determine the preference value of eachnoun phrase that is a candidate for selection as theantecedent of a pronoun.
This approach is practicalin terms of the amount of knowledge it presupposesand the amount of computation it requires, since itbasically relies only on the surface information in atext, and is fl'ee fi'om the knowledge acquisition bot-tleneck.In experiments on computer manuals, we achieveda success rate of 93.8%.
A remarkable ~uspect of thisresult is that  we achieved it without referring to anyoutside knowledge resource except for the synonymrelations in an on-line synonym dictionary.
By com-bining heuristic rules to utilize wtrious informationextracted from M1 the sentences in the source text,high accuracy can be achieved in pronoun resolutionfor a practical naturM language processing system.Ti lt  advantages of this approach are that a simplealgorithm can extract information on syntactic posi-tion, repetition, and collocation pattervs hy referringto morphological informatiml within a source text,and that it does rot  even assume a correct syntac-tic analysis or depend ov the formalism of syntacticparse trees, since it does not rely on any grammaticalinformation except for modifier-nmdifiec relationship-s.
This at)proach is especially effective in technicaldocuments uch as computer manuMs or patent doe-uments in which words are use, d consistently in orderto avoid ambiguity, and in which identical collocationpatterns are frequently repeated in detailed descrip-tions of target objects or procedures.AcknowledgementsI would like to thank Michael McDonald for invalu-able hell) in proofreading this paper.
I would alsolike to thank Taijiro Tsutsumi, Masayuki Morohashi,Koichi Takeda, tIiroshi Maruyama, Hiroshi Nomiya-ma, Hideo Watanabe, Shiho Ogino, Naohiko Uramo-to, and the anonymous reviewers for their commeutsand suggestions.References\[Brennan, 1987\] Brennan, S. E., M. W. Friedman,and C. J. Pollard (1987).
A Centering Approachto Pronomls.
/:n Proceedings of A CL-8ZI '/62\[Carbonell, 1988\] Carbonell, J. G., and l.I.. D.Brown (1(,)88).
Anaphora Resolution: AMulti-Strategy At)proach.
in Proceedings ofCOLING-88.\[Charniak, 1973\] Char,dak, E. (1973)..lack andJanet in Search of a Theory of Knowledge.
/nProceedings of IJCAI-72.\[GMe, 1992\] Gale, W. A., K. W. Church, a.ltd D.Yarowsky (1992).
One Sense Per l)iscourse.
/nProceedings of the 4th DARPA 5'pecch and Nat-ural Language Workshop\[Hindle, 1993\] Hindle, D., ~md M. Rooth (1993).Strnctural Ambiguity and Lexieal Relations.Computational Linguistics, Vol.
19, No.
1.\[nobbs, 1978\] Ilobbs, J. R. (1978).
Resolving Pro-noun l/,eferenees.
Lingua, 4~'\[Jensen, 1987\] Jensen, K., and J.-I,.
Binot (1987).Disambiguating Prel)ositionaJ Phrase Attach-.ments by Using ()n-Line Dietioimry 1)eiinitions.Computational Linguistics, Vol.
13, No.
2- 4.\[Lal)pin , 1990\] Lapi)in , S., and M. McCord (1990).Anaphora ll~esolution in Sh)t Grammar.
Com-putational Linguistics, Vol.
16, No.
4.\[Kameyama, 1993\] Kameyama, M., R. Passonneau,and M. I)oesio (1993).
Temporal Centering.
InProceedings of A CL- 93.\[Nagao, 199(I\] Nagao, K. (1990).
Del)endency Amalyzer: A Knowle(lge-ba.sed A1)proaeh toStructural Disambiguation.
\[n Procecding.s ofCOLING-90.\[Nasuk~wa, 1993\] iasukawa, T. (1993).
l)iscourseConstraint in Computer Manuals.
In Proceed-ings of TM\[-93.\[Rich, 1988\] Rich, E.A.
and S. Lul)erFoy (1988).
AnArchiteeturc for AnaI)ttora Resolution.
In Pro-ceedings of ANLP-88.\[Sidner, 1983\] Sidner, C. L. (1983).
Focusing in theCoinprehension ofDefinite Anaphora.
In Com-putational Models of Discourse, M. Brady andR.
Bcrwick, cds., Cambridge, Mass.
: MITPress.\['\['~keda, 1992\] Ta.keda, K., N. Uramoto, T. Nwsukawa, and T. Tsutsmni (1992).
Shalt2 -a Syimuetric Machine Translation Systemwith Conceptual Transfer.
In Proceedings ofCOLING-92.\[Uramoto, 1991\] Uramoto, N. (J991).
Lexical andStructural Disambiguation Lrsing all Example-Base./n Proceedings of the 2nd Japan-AustraliaJoint Symposium on Natural Language Process-ing.\[Walker, 1989\] Walker, M. (1989).
Evaluating Dis-course Processing Algorithms.
In Proceedings ofA CL-89.\[1\] "IBM SAA bnagePlus Object DistributionManager MVS/ESA High-Speed Capture Sub-system Guide Version 2 Release 1.1," IBM Cor-1, (1991)\[2\] "IBM Application System/400 New User'sGuide Version 2," IBM Corp. (1992)\[3\] "The New Collins Thesaurus," Collins Publish-ers, Glasgow (1.984)1163
