Proceedings of the 14th European Workshop on Natural Language Generation, pages 61?71,Sofia, Bulgaria, August 8-9 2013. c?2013 Association for Computational LinguisticsGenerating and Interpreting Referring Expressions as Belief StatePlanning and Plan Recognition ?Dustin A. SmithMIT Media LabE15-358; 20 Ames St.Cambridge, MA USAdustin@media.mit.eduHenry LiebermanMIT Media LabE15-320F; 20 Ames St.Cambridge, MA USAlieber@media.mit.eduAbstractPlanning-based approaches to referenceprovide a uniform treatment of linguisticdecisions, from content selection to lexi-cal choice.
In this paper, we show howthe issues of lexical ambiguity, vague-ness, unspecific descriptions, ellipsis, andthe interaction of subsective modifiers canbe expressed using a belief-state plan-ner modified to support context-dependentactions.
Because the number of dis-tinct denotations it searches grows doubly-exponentially with the size of the refer-ential domain, we present representationaland search strategies that make generationand interpretation tractable.1 IntroductionPlanning-based approaches1 to reference are ap-pealing because they package a broad range oflinguistic decisions into actions that can be usedfor both generation and interpretation.
In sec-tion 2, we present linguistic issues and discusstheir implications for designing planning domainsand search algorithms.
In section 3, we describeAIGRE,2 our belief space planner, and explainhow it efficiently handles the issues from section2.
Lastly, we demonstrate AIGRE?s output fora suite of generation and interpretation tasks, andwalk through a trace of an interpretation task.1.1 The two linguistic reference tasksA linguistic act of referring aims to communi-cate the identity of an object, agent, event or col-lection thereof to an audience.
Depending on the?We thank Nicolas Bravo and Yin Fu Chen for their con-tributions to AIGRE; the three anonymous reviewers fortheir comments; and the sponsors of the MIT Media lab.1Throughout this paper planning is framed as a heuristicsearch problem.2Automatic interpretation and generation of referringexpressions.
In French, it means ?sour?.agent?s dialogue role, referring involves one of twotasks.
The speaker completes a referring expres-sion generation (REG) task: given a context setand a designated member of it called the target set,he produces a referring expression that allows thelistener to isolate the target from the rest of theelements in the context set, called the distractors(Dale and Reiter, 1995).
A listener completes areferring expression interpretation (REI) task:given a referring expression and an assumed con-text set, her goal is to infer the targets that thespeaker intended.1.2 Reference generation as planningMany approaches to REG (see (Krahmer and vanDeemter, 2012) for an overview) have focused ex-clusively on the sub-task of content determina-tion: given context and target sets, they search forcontent that distinguishes the targets from the dis-tractors.
This content is then passed to the nextmodule in an NLG pipeline (c.f.
(Reiter, 1994)) toultimately become a noun phrase embedded in alarger construct.These ?pipeline?
architectures prevent infor-mation from being shared between different lay-ers of linguistic analysis, contrary to evidencethat the layers interact (Altmann and Steedman,1988; Danlos and Namer, 1988; Stone and Web-ber, 1998; Krahmer and Theune, 2002; Horacek,2004).
As an alternative, one can take an inte-grated ?lexicalized approach,?
following (Stone etal., 2003; Koller and Stone, 2007; Garoufi andKoller, 2010; Koller et al 2010), in which eachlexical unit?s syntactic, semantic, and pragmaticcontributions are represented as a lexical entry.Lexicalized approaches presume that lexical en-tries can be designed to contain all of the syn-tactic and semantic ingredients required to syn-thesize a phrase or sentence.
As such, the REGproblem is reduced to choosing (i.e., content se-lection and lexical choice) and serializing lexical61units (putting them into a flat sequence), whichbears strong similarities to automated planning(Ghallab et al 2004).
Automated planners try tofind plans (sequences of actions), given (1) a fixedplanning domain that describes how the relevantaspects of the world are changed by actions, and(2) a problem instance: a description of the initialstate and the desired goal states.For planning-based approaches to reference, theset of actions defined by the planning domain isanalogous to a lexicon: each action correspondsto a lexical unit and is responsible for definingits semantic effects, along with the local syntacticand compositional constraints that are relevant tothe lexical unit (Appelt, 1985; Heeman and Hirst,1995; Koller and Stone, 2007; Koller et al 2010;Garoufi and Koller, 2011).1.3 Automated planning as heuristic searchWhen solving an instance of a planning prob-lem, planners internally generate a directed graphcalled a planning graph, where the nodes rep-resent hypothetical states and the labeled edgescorrespond to actions that represent valid transi-tions between the states.
A planning domain andan initial state thus characterize an implicit graphof all the possible states and transitions betweenthem, which is usually infeasible to enumerate.
Toavoid constructing parts of the planning graph thatare irrelevant to particular problem, planning tasksare often solved using heuristic search (Bonet andGeffner, 2001), which is the same framework un-derlying popular approaches to content selection(Bohnet and Dale, 2005).3 Heuristic search is use-ful for balancing costs (e.g.
the cost of a givenword) against benefits (e.g.
meeting the communi-cation goals): lower-cost4 solutions are inherentlypreferred.
The effectiveness of heuristic search isdetermined by the search algorithm and heuristicfunction, which gives a numerical estimation of agiven state?s distance to a goal state, h(s)?
[0, 1],that guides the search algorithm toward states thathave a lower estimated distance to a goal.The automated planning community has devel-oped domain-independent techniques for automat-ically deriving a heuristic function from the struc-3FULL BREVITY ALGORITHM is simply breadth-firstsearch; GREEDY ALGORITHM is best-first search; and theINCREMENTAL ALGORITHM is a best-first where actions aresorted by preferences (Bohnet and Dale, 2005)4If a plan?s cost is just its length, heuristic search willbake-in the brevity sub-maxim of Grice?s Cooperative Prin-ciple (Dale and Reiter, 1995).ture of a planning domain, provided it is encoded acertain way.
These approaches solve a simplifiedversion of the original planning problem, calcu-late each generated state?s minimal distance to agoal, and then use that distance as a lower-boundestimate in the heuristic function for the originalproblem (Bonet et al 1997; Hoffmann, 2001).
(Koller and Petrick, 2011; Koller and Hoff-mann, 2010) applied domain-independent plan-ners toward REG, but found them ?too slow to beuseful in real NLG applications.?
It is importantto note, however, that their results were for a spe-cific implementation of a planning domain and setof heuristic search techniques, of which there aremany variations (Edelkamp and Schroedl, 2011).For example, (Koller and Hoffmann, 2010) laterreported being able to speed a planner by makingits action proposal function more restrictive.1.4 Interpretation as plan recognitionIf generating a sentence can be modeled as a plan-ning problem, then interpretation can be modeledas plan recognition (Heeman and Hirst, 1995;Geib and Steedman, 2006).
Plan recognition canbe seen as an ?inversion?
the planning problem,and solved using planning techniques (Baker et al2007; Ram?
?rez and Geffner, 2010): Given an ini-tial state (context set), a sequence of partially ob-served actions (words), what are the most likelygoals (interpretations)?Moreover, addressing both generation and in-terpretation in tandem places a strong constrainton how the lexicon can be designed?an oth-erwise underconstrained knowledge engineeringproblem.
Because the same planning domain (lex-icon) is used for multiple problem instances, a rel-evant evaluation of a planning-based approach isits coverage of a range of various linguistic input(for REI tasks) and output (for REG tasks).
Onegoal of this paper is to analyze several problematicreferring expressions and draw conclusions fromhow they can be used to guide planning-based ap-proaches to REG and REI.2 Problems for Referring ExpressionsIn this section, we describe several linguistic is-sues using example referring expressions that areapplied to two visual referential domains: KIN-DLE (Figure 1) and CIRCLE (Figure 2).Imagine you are a clerk selling the Amazon Kin-dles in Figure 1.
Three separate customers ask you62Figure 1: The KINDLE referential domain contain-ing 5 items: k1, k2, k3, k4 and k5.to pass them:(R1) the big one(R2) the inexpensive ones(R3) a kindle touch2.1 The problem of lexical ambiguityThe problem with the referring expression (R1)is that it contains lexical ambiguity: did thecustomer intend the sense big1, which modifiesthe size attribute, or big2, which modifies thehard drive.size attribute?
Although one is muchmore likely, they are both mutually exclusive pos-sibilities Jthe big oneK = {k4} ?
{k5}.What does this mean for planning-based ap-proaches to REG and REI?
For generation, itmeans that some words can cause the listener todraw multiple interpretations?but only in certaincontexts (which provides an example of how wordmeanings draw from the context set).
For interpre-tation, this means that we need a way to representconflicting interpretations; and, if there are multi-ple interpretations for a given observed plan, weneed a way to pick among the alternative interpre-tations.2.2 The problem of gradable adjectivesReferring expression (R2) does not contain lexicalambiguity; however, it does suffer from vaguenessas a result of having a gradable adjective, ?inex-pensive,?
in the positive form modifying a pluralnoun, ?ones.?
Vagueness is problematic becauseit can lead to different interpretations dependingon how the listener determines whether a refer-ent is/a cluster of referents are INEXPENSIVE or?INEXPENSIVE (van Deemter, 2010).
If we as-sume vagueness comes down to the interpreter in-ferring the speaker?s implicit standard?a specificvalue of Price as a cut off, we can exhaust allpossibilities by considering all unique prices.
Atone extreme, only the cheapest Kindle is inexpen-sive, at the other extreme all of the Kindles areinexpensive (i.e.
the comparison class is a propersuperset of the KINDLE domain): (R2) has fourdistinct denotations: Jthe inexpensive onesK ={k1, k2} ?
{k1, k2, k3} ?
{k1, k2, k3, k5} ?
{k1, k2, k3, k5, k4}.
Like ambiguity, the use of avague lexical unit can cause multiple distinct in-terpretations, and these outcomes are a function ofthe available options in the context set at the timethe lexical unit is used.2.3 The problem of unspecific descriptionsReferring expression (R3) is problematic be-cause there are two possible denotationsJa kindle touchK = {k2} ?
{k3}5 but in away that differs subtly from having two mutexinterpretations like in (R1).
The indefinite article?a?
indicates that the speaker has not onlycommunicated a description that matches multipletargets, but also the authority to choose on hisbehalf.
Either {k2} or {k3} is acceptable.
Forplanning-based approaches, this means that weshould be able to represent a choice betweenmultiple alternative targets in an interpretation,and distinguish it from the mutex alternativescreated by vagueness and ambiguity.2.4 The problem of word orderingThis and the next problem use this CIRCLE refer-ence domain for their examples:c1 c2 c3Figure 2: The CIRCLE referential domain.Given the visual scene above, how would youinterpret the following referring expressions?
(R4) the biggest green shape(R5) the second biggest green circle(R6) the biggest(R7) the first one5Our use of the disjunction operator here is non-standard,but we are not familiar of alternative notation for this distinc-tion.63By incrementally evaluating each word in thesequence (R4), at the second word we have (R6)J?the biggest?K = {c3}.
If every word?s meaningswere combined by intersecting their denotations,adding the next word, J?green?K = {c1} ?
{c2} ?
{c1, c2}, would denote nothing: J?the biggest?K?J?green?K = ?.An incremental planning system should be ableto handle the non-monotonicity created by theseso-called subsective6 adjectives: (R4) should yieldan interpretation that is not included in (R6), eventhough (R6) is a prefix of (R4).
If the model ofREI aims to reflect human abilities, it should beable to incrementally process the words and switchbetween disjoint interpretations in real time, as thepsycholinguistic research suggests (Altmann andSteedman, 1988; Tanenhaus, 2007).Now, consider when multiple subsective adjec-tives occur before a noun, as in (R5).
Does ?sec-ond biggest?7 modify both J?green circle?K or justJ?circle?K?
This depends on who is interpreting:when we asked 108 self-reported native Englishspeakers on Mechanical Turk to interpret (R5)?the second biggest green circle?
the uncertaintywas high, but {c1} was favored over {c2} by 3:2odds.
An REI must decide whether it interprets onbehalf of an individual or population; and REG ap-proaches may want to avoid such expressions thatcan lead to conflicting interpretations.The issues raised by subsective adjectives canbe seen as symptoms of a more general problem:that of deciding how to combine the meanings ofindividual lexical units.
This is the responsibilityof a syntactic theory; its duty is to describe how thecombinatoric constraints on surface forms relatesto the ?evaluation order?
of their semantic parts.For planning-based approaches, the syntactic the-ory should be incremental, capable of producingan interpretation at any stage of processing, andinvertible, capable of being used in generation andinterpretation.2.5 The problem of ellipsis(R6) is missing a noun, and in (R7), ?the firstone,?
the ordinal ?first?
appears without a grad-6Characterizing adjectives set-theoretically, (Siegel,1976; Partee, 1995) contrasted intersective and subsectivemeanings.
Unlike intersective adjectives, the subsectiveadjectives cannot be defined independently of their nouns.7The two words ?second biggest?
are treated as a sin-gle modifier: just as adjectives can modify nouns, ordinalslike ?second?
modify superlatives like ?biggest,?
changing itsmeaning so that it skips over the first biggest.able adjective.
We take these to be instances ofellipsis: when the meaning of a word is presentbut its surface form is omitted.
In our view, theseexpressions should be interpreted as:(R6?)
the biggest [oneNN ](R7?)
the first [leftmostJJS] oneFor planning-based approaches to REI, accom-modating the phenomenon of ellipsis involvesinferring missing actions?interleaving the par-tially8 observed actions of the speaker with abduc-tively inferred actions of the listener (Hobbs et al1993; Benotti, 2010).
For a REG, this means thatthe speaker can decide to elide some surface formsunder certain conditions?such as if the listener isexpected to infer it from context.3 AIGRE: a belief-state planningapproach to REI and REGWe used these problematic referring expressionsto guide the design of our belief-state planner, AI-GRE.
Both REG and REI tasks begin with an ini-tial belief state about a referential domain.
In ad-dition, the REI task is given a referring expressionas input, and the REG task is given a target set.3.1 Representing states (interpretations) asbeliefsWe draw an analogy between the representationfor an interpretation in a reference task and theconcept of a belief state from artificial intelli-gence.
A belief state characterizes a state ofuncertainty about some lower layer, such as theworld or another belief state.
The standard repre-sentation of a belief state is the power set of thestates in the lower layer, b = P(W), containing2|W| members, or more generally as a probabilitydistribution, b = p(W), representing degree of be-lief.Given a referential domain, R, REG systemsthat can refer to sets (van Deemter, 2000; Stone,2000; Horacek, 2004) explore a hypothesis spacecontaining 2|R|?1 denotations, which is represen-tationally equivalent to a belief state about the hy-pothesis space of only singleton referents.
In our8The actions are not fully observed because of ellipsisand, as we have seen with vagueness and ambiguity, differentsenses of a word can produce the same surface form of thelexical unit.64case, we want to be able to represent multiple in-terpretations about sets (due to unspecific descrip-tions, vagueness and ambiguity) so our hypothesisspace contains 22|R|?1 ?
1 interpretations.
Thisstate-space grows large quick: for the CIRCLE do-main, where |R| = 3, there are 127 denotations;while for KINDLE, where |R| = 5, there are overtwo billion.Fortunately, there are ways to avoid this double-exponent.
First, a belief state uses lazy evalua-tion to generate its contents: the members of thepower set of the referential domain that are consis-tent with its intensional description and arity con-straints (more details in section 3.1.1).Second, the base exponent is avoided altogether,as we derive it by aggregating states from the plan-ning graph.
The initial belief state, one of com-plete uncertainty, implicitly represents 2|R| ?
1possible target sets: it is the branching of non-deterministic actions that gives rise to the first ex-ponent (due to lexical ambiguity and vagueness;see 3.2).
This gives a clear way to distinguishunspecific interpretations (when the listener has achoice over multiple targets) from the other mu-tually exclusive targets (choices that were artifactsof the interpretation process): If two candidate tar-get sets belong to the same belief state, then theyare the result of unspecificity; whereas, if they arein different belief states, then they are mutuallyexclusive.
For example, a REI procedure may pro-duce two belief states as results: bx = {t1}?{t2}?
{t3} and by = {t1, t2, t3}.
From this, we concludeits denotation is: ({t1}?{t2}?{t3})?
{t1, t2, t3}.In the field of automated planning, belief-state planning using heuristic search (Bonet andGeffner, 2000; Hoffmann and Brafman, 2005) hasbeen used to relax some assumptions of classicalplanning, such as the requirement that the probleminstance contains a single (known) initial state,and that each action in the planning domain onlychanges the state in a single (deterministic) way.Belief state planners allow one action to have mul-tiple effects, and instead of finding linear plans,they output plan trees that describe which actionthe agent should take contingent upon each ac-tion?s possible outcomes.Furthermore, because a belief state representsan interpretation, we can stop and inspect thesearch procedure at any point and we will have acomplete interpretation; thus, achieving the incre-mental property we desired.3.1.1 Belief state implementation detailsThe key responsibilities of a belief state are to rep-resent and detect equivalent or inconsistent infor-mation at the intensional level.
Its function is toaggregate all actions?
informational content anddetect whether a partial information update is in-consistent or would cause the interpretation to beinvalid (i.e., have no members).
In AIGRE, be-lief states are represented as a collection of ob-jects, called cells,9 which hold partial informa-tion and manage the consistency of informationupdates.
AIGRE?s belief states contain the fol-lowing components:?
target an attribute-value matrix describing propertiesthat a referent in the domain must entail to be consid-ered consistent with the belief state.?
distractor an attribute-value matrix describing proper-ties that a referent in the domain must not entail to beconsidered consistent with the belief state.
This allowsAIGRE to represent negative assertions, such as ?thenot big one?
or ?all but the left one.??
target arity an interval (initially [0,?))
representingthe valid sizes of a target set.?
contrast arity an interval (initially [0,?))
represent-ing the valid sizes of the difference in the sizes of atarget set and the set containing all consistent referents.?
part of speech a symbol (initially S) representing theprevious action?s part of speech.?
deferred effects a list (initially empty) that holds ef-fect functions and the trigger part of speech symbolthat indicates when the function will be executed on thebelief state.A belief state does not have to store all 2|R| ?
1target sets; it can lazily produce its full denota-tion only when needed.
It does this by generatingthe power set of all elements in the referential do-main that entail the target description, do not en-tail the distractor, and are consistent with two ar-ity constraints: The target arity property requiresthe target set?s size to be within its interval, andit is used to model number agreement and cardinalmodifiers.
The contrast arity requires that the dif-ference between a given target set and the largesttarget set in the belief state (the number of con-sistent referents) is a size within its interval, andis used to model the semantics of determiners andqualifiers.Actions operate on AIGRE?s belief states, yetthe belief state influences much of the behavior of9The idea behind cells comes from the propagatorframework of (Radul and Sussman, 2009) and our Pythonlibrary is available from http://eventteam.github.io/beliefs/65the action?s effects.
As we will see in the next sec-tion, the contents of a belief state determine thenumber of effects an action will yield, the specificvalues within the effect?s belief (using late bind-ing), and whether or not the update is valid.3.2 Representing context-dependent actionsAIGRE?s lexicon is comprised of lexical units?actions that can change belief states.
Each ac-tion/word is an instantiation of an action class andhas (1) a syntactic category (part of speech), (2) alexical unit, (3) a specific semantic contribution?determined in part by its syntactic category, (4)a fixed lexical cost, and (5) a computed effectcost.
Actions are defined by instantiating class in-stances, for example:GradableAdj(?big?, attr=?size?
)CrispAdj(?big?, attr=?size?, val=[5,?
))When instantiating an action, the first argument isits lexeme in its root form; the class?
initializa-tion method uses the root lexeme to also instan-tiate variant actions for each derivative lexical unit(e.g.
plural, comparative, superlative, etc).3.2.1 Actions yield effect functions, not statesActions in AIGRE receive a belief state as inputand lazily generate 0 or more effect functions asoutput, depending on the contents of the beliefstate.
Unlike conventional planners, actions pro-duce effect functions rather than successor statesbecause (1) it allows us to defer the execution ofan effect, as we describe in 3.2.3, (2) generat-ing effect functions is fast; copying belief statesis slow, and (3) actions can annotate the yieldedeffect functions with an estimated cost, giving thesearch process an additional degree of control overwhat successor state is created next.
We view anaction that does not yield any effects to be analo-gous to a traditional planning domain?s action thatdoes not having its preconditions satisfied; unliketraditional domains, an action?s behavior is opaqueuntil it is explicitly applied to a belief state.3.2.2 Ambiguity and vagueness usingnon-deterministic actionsGradable adjectives yield an effect for each same-named attribute10 (lexical ambiguity) for eachvalue (vagueness) in the parent belief state?s con-sistent referents.
For example, given the ac-tion BIGJJ applied to an initial belief state aboutthe KINDLE referential domain, b0, the action10Ordered by breadth-first traversal of targets?
properties.yields a separate effect for each unique value ofeach unique attribute-path that terminates withsize for all consistent referents.
In this case,the referents have two size properties, size andhard drive.size, each with 3 distinct values, sothe BIGJJ action applied to b0 yields 6 effects intotal: BIG(b0) ?
e0, e1 .
.
.
e6.
When executed ona belief state, e0 would add the nested propertysize to its target property (if it doesn?t alreadyexist) and then attempt to merge it with an intervalbeginning at the largest size value11 of a referentconsistent with b0: [7,?
).Effects for vague and ambiguous actions prolif-erate: if the adjective BIG has s senses, and thereare r referents compatible with the belief state,then it can yield as many as s?
r effect functions.In section 3.3.1, we will show how the search al-gorithm can mitigate this complexity by conserva-tively generating effects.3.2.3 Effects can be deferred until a triggerWe view subsective adjectives (see 2.4) as havingtheir context-specific meaning evaluated withinthe scope of the noun?s meaning (i.e., after eval-uating the noun).
To achieve this without chang-ing the words?
surface orderings, each adjective?seffects are deferred until a syntactic trigger: whenthe belief state?s part of speech indicates it hasreached a noun state.
Deferred effect functionsare stored in the belief state?s deferred effectsqueue along with a trigger.
This solution makesthe search harder: deferred actions have no imme-diate effect on the belief state, and so (in the eyesof the search algorithm) they do not move the be-lief toward the search goal.3.3 Controlling search through belief statesA heuristic search planner must specify how to de-termine which state to expand next, and how to de-termine when a search process has succeeded, i.e.,a goal test function.
AIGRE approaches the firstissue in a variety of ways: by (a) using a heuristicfunction to rank the candidate nodes so that themost promising nodes are expanded first (b) usingan action proposal function to restrict the actionsused to expand the current node (c) using a greedysearch algorithm that does not generate all suc-cessor nodes.Note that although both REG and REI tasks in-volve choosing belief-changing actions that map11Gradable (vague) values are represented with intervals,where one extreme is the standard.66an initial belief state onto a target belief state, thetwo search processes are subject to very differentconstraints.
With generation, the desired seman-tic content is fixed and the linguistic choices areopen; while for interpretation, the linguistic con-tents are relatively fixed and the semantic possi-bilities are open.
We use these differences to cre-ate task-specific heuristics, action proposal mech-anisms, and goal-test functions; and find that theinterpretation task tends to search a much smallerspace than that of generation.3.3.1 Heuristic functionsFor REI, the action proposal function is so restric-tive that we can generate and test the entire searchspace; therefore, no heuristic is necessary.For REG, the heuristic function characterizes itscommunicational objective: to describe the tar-get(s) and none of the distractors.
For this weuse the F1 score (F-measure) from information re-trieval, because it rewards inclusion of targets (re-call) and penalizes inclusion of distractors (preci-sion).
Given a belief state, s, and the intended tar-get set, t?
:h(s) = maxF1(t?, t) ?
t ?
s (1)This heuristic iterates over each target set, t, in abelief state to find the biggest set difference ac-cording to the F1 score.
By taking the worst pos-sible score of any target, it always is greater thanor equal to the true distance.3.3.2 Goal test functionsFor REI, a goal state is one in which all obser-vations have been accounted for, and the beliefstate?s part of speech is a noun.
For REG, a goalstate is one in which only the targets are described(i.e.
its heuristic, Equation 1, returns 0), and thebelief state?s part of speech is a noun.Both goal test functions impose a syntactic con-straint: the requirement that plans terminate in anoun state.
This all-or-nothing constraint, alongwith the language model in the action proposalfunction, forces the generated expressions to besyntactically well-formed English expressions.3.3.3 Action proposal functionsWhile expanding a search state, instead of gener-ating effects for every action in the lexicon, theaction proposal restricts the set of actions that areconsidered.
It is passed the parent belief state,whose part of speech property tells the syntac-tic category of the last action that changed it.
Ac-tions are proposed only if they are consistent witha language model that describes valid transitionsbetween syntactic categories.
Our (limited) lan-guage model is expressed in a regular language:DT?
CD?
(ORD?
JJS)* JJ* (NN|NNS)+.For the problem of REI, we are licensed to makethe action proposal function even more restric-tive.
AIGRE restricts those whose lexical unitscan produce the text that appears in the remainingobservation sequence.In addition to enforcing syntactic constraints,the action proposal function gives us a nice way tohandle omitted actions.
During interpretation, AI-GRE allows default actions, representing elidedwords or conventional implictures, to be inferredat a cost, but only under rare circumstances.
Adesignated subset of actions are marked as defaultactions, indicating that they can be assumed eventhough their lexical unit is not present.
A defaultaction is only suggested if (1) none of the other ac-tions have matched the remaining observed inputtext and (2) its precondition is met.For example, the language model forbids theORD?NN transition and the goal test function re-quires that all noun phrases terminate with anoun.
Consequently, ?the second?
is interpretedas ?theDT secondORD [leftmostJJS] [oneNN ]?,assuming the default actions LEFTMOSTJJS andONENN .
For (R6), the requirement of ending witha noun allows the subsective meaning of ?biggest?to be evaluated: its deferred effect is triggered af-ter ONENN .3.3.4 Search strategiesBecause the action proposal function is so restric-tive for REI, the entire search space can be ex-plored usually under a second.
For REG, expand-ing the complete planning graph to a depth of 5using ?
100 actions takes several minutes.To complete the REG task efficiently, we haveexperimented with search strategies and found op-timal A* search to be too slow.
Although theygive up guarantees of optimality and complete-ness, hillclimbing-based approaches rescue theREG task from having to expand every relevant ac-tion?s effect by committing to the first effect whosesuccessor shows an improvement over the currentstate.
Because we do not want the same resultseach time (non-deterministic output is character-istic of human reference generation (van Deemter67et al 2011)), AIGRE randomly chooses effectswith a probability inversely proportional to the ac-tion?s lexical cost, which is a kind of stochastichillclimbing.
The results are promising: non-deterministic outputs can be generated in usuallyless than a second (see Figure 4).4 AIGRE?s Output for REI and REGIn lieu of a formal evaluation, we have includedexamples of AIGRE?s output for several tasks in-volving the CIRCLE and KINDLE reference do-mains: see Table 1 for output of the REG task;and Figures 5 and 6 for outputs of REI tasks.AIGRE?s word costs were derived from theirinverse token frequencies in the Open AmericanNational Corpus (Ide and Macleod, 2001).
Theyare only a approximation and clearly do not accu-rately quantify the costs of human linguistic de-cisions.
With this in mind, the referring expres-sion?s denotations?
relative likelihoods, which arederived from costs, should not be given much cre-dence.
Our point here is that this large hypothesisspace can be represented and searched efficiently.0.0 0.5 1.0Relative likelihood of denotationa kindle touchthe inexpensive onesthe big oneNet Interpretations for KINDLE domain{k2}{k3}{k4}{k5}{k1, k2}{k1, k2, k3}{k1, k2, k3, k5}{k1, k2, k3, k4, k5}?Figure 3: REI results for R1, R2 and R3 in theKINDLE domain.
Each color represents a differenttarget set, and more than one color in a bar indi-cates the interpretation is uncertain.5 An example trace of a REI taskThe interpretation task begins with an initial statecontaining the belief state b0 about the KINDLEreferring domain12 (figure 1) and the referring ex-pression, ?any two cheap ones.?
The search pro-cedure begins by selecting actions to transform b0into successor states.
The actions are sorted byhow much of the prefix of the observed text they12To AIGRE, each Kindle is an attribute-values matrixrather than a visual image.0.0 0.5 1.0Relative likelihood of denotationthe first onethe biggestthe second biggest green circlethe biggest green shapeNet Interpretations for CIRCLE domain{c1}{c2}{c3}?Figure 4: REI for R4-R7 in the CIRCLE domain.match; and for ?any two cheap ones,?
the first ac-tion is ANYDT and it transforms b0 into b1:b0 =????????
?TARGET ARITY [0,?
)CONTRAST ARITY [0,?
)TARGET []DISTRACTOR []PART OF SPEECH SDEFERRED EFFECTS []?????????
(Note: For lack of space, we just show the parts of the beliefstate that change)b1 =[CONTRAST ARITY [1,?
)PART OF SPEECH DT]The contrast arity property allows AIGRE torepresent the notion of conveying a choice fromalternatives, as with the indefinite meanings of?some?
or ?any,?
as well as the fact that definitedescriptions take the maximal set.13Applying the effect of the action, TWOCD, forthe word ?two?
transforms b1 into b2:b2 =[TARGET ARITY [2, 2]PART OF SPEECH CD]To be concrete, the initial belief state, b0,models all 31 groupings of referents: b0 |={k1} , {k3, k5} .
.
.
; the belief state b1 contains 30sets?all but the set containing all 5 kindles; andb2 represents(52)= 10 alternative sets.The action CHEAPJJ corresponding to the grad-able adjective ?cheap?
is non-deterministic: ityields a different effect for each distinct attributes?values, starting with the lowest price, $79.00.
This13The power set of the belief state?s referents forms a lat-tice under the subset operator, and for the definite article?the?
we only want the top row.
We model its meaning witha deferred effect that sets contrast arity to [0,0] after a noun.The indefinite article ?a?
sets contrast arity to [1,?)
andtarget arity to 1; ?a?
has the same meaning as ?any one.
?68TARGET SECONDS REFERRING EXPRESSIONS (AND COSTS){c1} 0.66?
0.3 the small one (2.3), the left one (2.4), the smaller one (2.4), the smallest one (2.4), the leftmost one (2.4) .
.
.
{c2} 1.05?
0.5 the center one (2.4), the medium-sized one (2.4), the center circle (2.4), the green big one (3.4){c3} 1.63?
1.1 the blue one (2.3), the right one (2.3), the big one (2.3), the large one (2.4), the larger one (2.4).
.
.
{c1, c2} 0.37?
0.1 the green ones (2.3), the green circles (2.3), the 2 green ones (3.4), the small ones (3.4){c1, c3} 0.52?
0.1 the 2 not center ones (4.5), the 2 not center circles (4.5), the 2 not medium-sized ones (4.5){c2, c3} 0.41?
0.1 the right ones (3.4), the 2 right ones (4.4), the 2 right circles (4.4), the 2 big ones (4.5){c1, c2, c3} 0.19?
0.1 the ones (1.2), the circles (1.2), the 3 ones (2.3){k1} 3.24?
2.0 the left one (2.4), the light one (2.4), the small cheap one (3.5), the small cheapest one (3.5){k2} 0.94?
0.2 the left touch (3.4), the small center one (3.5), the small center touch (3.6), the small center cheap one (4.7){k3} 1.11?
1.0 the center one (2.4), the small heavy one (3.5), the small heavier one (3.5), the small heaviest touch (3.6) .
.
.
{k4} 0.20?
0.2 the kindle dx (1.2), the big one (2.3), the big kindle dx (2.4){k5} 0.19?
0.1 the kindle fire (1.2), the right one (2.3), the right kindle fire (2.4)Table 1: AIGRE?s outputs for REG tasks (each repeated for 20 trials).
If the output is bold, it meansthat when we fed the referring expression back to AIGRE as a REI task, it was able to derive multiplealternative interpretations and the referring expression is uncertain.anycost: 1.08 twocost: 2.16ones2cost: 11.65cheap 1(price)standard:(?
?, 149]cost: 6.56ones2cost: 7.65cheap1 (price)standard: (?
?, 379]cost: 18.56cheap1 (price)standard: (?
?, 199]cost: 10.56 ones2cost: 19.65b0size:31 b1size:30 b2size:10b5size:3b6size:6b7size:10b8size:3b9size:6b10size:10Figure 5: The planning graph for interpreting, ?any two cheap ones.?
Search proceeds from the initialstate b0 rightward toward goal states (diamonds).
The labeled edges represent the actions, and containthe cumulative path costs.
Only intermediate states that lead to a goal are shown?even though CHEAPJJinitially had 5 successors, two were invalid belief states because they had 0 members.effect adds a new attribute target.price to the be-lief state and sets its value to be the open inter-val (?
?, 79.00].
The action?s next effect createsa separate belief state for the second lowest pricefrom the referents, $99.00, and so on, all the wayup to the most expensive price, $379.00.b3 =[TARGET[PRICE (?
?, 79.00]]]b4 =[TARGET[PRICE (?
?, 99.00]]]b5 =[TARGET[PRICE (?
?, 149.00]]].
.
.The last word, ?ones,?
invokes an ac-tion ONESNNS whose effect adds the tar-get.type=entity property to the belief state andthen merges targetset arity with [2,?)
becauseit is plural (though its value doesn?t change).0.0 0.5 1.0Relative p of denotationonescheaptwoanyIncremental REI for ?any two cheap ones?
Possible Targets{k1, k2}{k1, k3}{k1, k4}{k1, k5}{k2, k3}{k2, k4}{k2, k5}{k3, k4}{k3, k5}{k4, k5}Figure 6: All denotation?s relative likelihoods.Each row corresponds to a column of the planninggraph in Figure 5: the first row, ?any,?
is just nodeb1 and the last row is the aggregate of the beliefstates b8, b9 and b10?derived by summing all thedenotations?
inverted costs.69ReferencesGerry Altmann and Mark Steedman.
1988.
Interac-tion with context during human sentence processing.Cognition.Douglas E Appelt.
1985.
Planning English referringexpressions.
Artificial Intelligence.Chris L Baker, Joshua B Tenenbaum, and Rebecca RSaxe.
2007.
Goal inference as inverse planning.Proceedings of the 29th annual meeting of the cog-nitive science society.Luciana Benotti.
2010.
Implicature as an InteractiveProcess.
Ph.D. Thesis.Bernd Bohnet and Robert Dale.
2005.
Viewing refer-ring expression generation as search.
Proc.
IJCAI-05.Blai Bonet and Hector Geffner.
2000.
Planning withIncomplete Information as Heuristic Search in Be-lief Space.
AIPS 2000: Proceedings of the Confer-ence on Artificial Intelligence Planning Systems.Blai Bonet and Hector Geffner.
2001.
Planning asheuristic search: New results.
Artificial Intelligence.Blai Bonet, Ga?bor Loerincs, and Hector Geffner.
1997.A Robust and Fast Action Selection Mechanism forPlanning.
In Proceedings of AAAI-1997.Robert Dale and Ehud Reiter.
1995.
Computationalinterpretations of the Gricean maxims in the genera-tion of referring expressions.
Cognitive Science.Laurence Danlos and Fiammetta Namer.
1988.
Mor-phology and cross dependencies in the synthesis ofpersonal pronouns in Romance languages.
In COL-ING ?88: Proceedings of the 12th conference onComputational linguistics.Stefan Edelkamp and Stefan Schroedl.
2011.
HeuristicSearch.
Morgan Kaufmann.Konstantina Garoufi and Alexander Koller.
2010.
Au-tomated planning for situated natural language gen-eration.
Proceedings of the 48th Annual Meeting ofthe Association for Computational Linguistics.Konstantina Garoufi and Alexander Koller.
2011.Combining symbolic and corpus-based approachesfor the generation of successful referring expres-sions.
In ENLG ?11: Proceedings of the 13th Eu-ropean Workshop on Natural Language Generation.Christopher W Geib and Mark Steedman.
2006.
OnNatural Language Processing and Plan Recognition.Proceedings of the 20th International Joint Confer-ence on Artificial Intelligence.Malik Ghallab, Dana Nau, and Paolo Traverso.
2004.Automated Planning.
Morgan Kaufmann.Peter A Heeman and Graeme Hirst.
1995.
Collabo-rating on referring expressions.
Computational Lin-guistics.Jerry R Hobbs, Mark E Stickel, Douglas E Appelt, andPaul Martin.
1993.
Interpretation as abduction.
Ar-tificial Intelligence.Jo?rg Hoffmann and Ronen Brafman.
2005.
ContingentPlanning via Heuristic Forward Search with ImplicitBelief States .Joerg Hoffmann.
2001.
FF: The Fast-Forward Plan-ning System.
AI Magazine.Helmut Horacek.
2004.
On Referring to Sets of Ob-jects Naturally.
In Natural Language Generation.Nancy Ide and Catherine Macleod.
2001.
The amer-ican national corpus: A standardized resource ofamerican english.
In Proceedings of Corpus Lin-guistics 2001, volume 3.Alexander Koller and Jo?rg Hoffmann.
2010.
Wakingup a sleeping rabbit: On natural-language sentencegeneration with FF.
In Proceedings of AAAI 2010.Alexander Koller and Ronald P A Petrick.
2011.
Ex-periences with planning for natural language gener-ation.
Computational Intelligence.Alexander Koller and Matthew Stone.
2007.
Sentencegeneration as a planning problem.
Annual Meetingof the Association of Computational Linguistics.Alexander Koller, Andrew Gargett, and KonstantinaGaroufi.
2010.
A scalable model of planning per-locutionary acts.
In Proceedings of the 14th Work-shop on the Semantics nd Pragmatics of Dialogue.Emiel Krahmer and Marie?t Theune.
2002.
Efficientgeneration of descriptions in context.
Proceedingsof the ESSLLI workshop on the generation of nomi-nals.Emiel Krahmer and Kees van Deemter.
2012.
Com-putational Generation of Referring Expressions: ASurvey.
Computational Linguistics.Barbara Partee.
1995.
Lexical semantics and compo-sitionality.
An invitation to cognitive science: Lan-guage.Alexey Radul and Gerald Jay Sussman.
2009.
The Artof the Propagator.
Technical Report MIT-CSAIL-TR-2009-002, MIT Computer Science and Artificial In-telligence Laboratory.Miquel J Ram?
?rez and Hector Geffner.
2010.
Prob-abilistic plan recognition using off-the-shelf classi-cal planners.
Proceedings of the Conference of theAssociation for the Advancement of Artificial Intel-ligence (AAAI 2010).Ehud Reiter.
1994.
Has a consensus NL generationarchitecture appeared, and is it psycholinguisticallyplausible?
Proceedings of the Seventh InternationalWorkshop on Natural Language Generation (INLG1994).70Muffy E A Siegel.
1976.
Capturing the adjective.PhD.
Thesis.
University of Massachusetts Amherst.Matthew Stone and Bonnie Webber.
1998.
TextualEconomy through Close Coupling of Syntax and Se-mantics.
arXiv.org.Matthew Stone, Christine Doran, Bonnie L. Webber,Tonia Bleam, and Martha Palmer.
2003.
Microplan-ning with communicative intentions: The spud sys-tem.
Computational Intelligence, 19(4):311?381.Matthew Stone.
2000.
On identifying sets.
In INLG?00: Proceedings of the first international confer-ence on Natural language generation.Michael K Tanenhaus.
2007.
Spoken language com-prehension: Insights from eye movements.
Oxfordhandbook of psycholinguistics.Kees van Deemter, Albert Gatt, Roger P G van Gom-pel, and Emiel Krahmer.
2011.
Toward a Compu-tational Psycholinguistics of Reference Production.Topics in Cognitive Science.Kees van Deemter.
2000.
Generating vague descrip-tions.
In INLG ?00: Proceedings of the first interna-tional conference on Natural language generation.Kees van Deemter.
2010.
Not Exactly: In Praise ofVagueness.
Oxford University Press.71
