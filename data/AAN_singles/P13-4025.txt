Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 145?150,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsParaQuery: Making Sense of Paraphrase CollectionsLili KotlermanBar-Ilan UniversityIsraellili.dav@gmail.comNitin Madnani and Aoife CahillEducational Testing ServicePrinceton, NJ, USA{nmadnani,acahill}@ets.orgAbstractPivoting on bilingual parallel corpora is apopular approach for paraphrase acquisi-tion.
Although such pivoted paraphrasecollections have been successfully used toimprove the performance of several dif-ferent NLP applications, it is still difficultto get an intrinsic estimate of the qual-ity and coverage of the paraphrases con-tained in these collections.
We presentParaQuery, a tool that helps a user inter-actively explore and characterize a givenpivoted paraphrase collection, analyze itsutility for a particular domain, and com-pare it to other popular lexical similarityresources ?
all within a single interface.1 IntroductionParaphrases are widely used in many Natural Lan-guage Processing (NLP) tasks, such as informa-tion retrieval, question answering, recognizingtextual entailment, text simplification etc.
For ex-ample, a question answering system facing a ques-tion ?Who invented bifocals and lightning rods?
?could retrieve the correct answer from the text?Benjamin Franklin invented strike terminationdevices and bifocal reading glasses?
given the in-formation that ?bifocal reading glasses?
is a para-phrase of ?bifocals?
and ?strike termination de-vices?
is a paraphrase of ?lightning rods?.There are numerous approaches for automati-cally extracting paraphrases from text (Madnaniand Dorr, 2010).
We focus on generating para-phrases by pivoting on bilingual parallel corporaas originally suggested by Bannard and Callison-Burch (2005).
This technique operates by attempt-ing to infer semantic equivalence between phrasesin the same language by using a second languageas a bridge.
It builds on one of the initial steps usedto train a phrase-based statistical machine transla-tion system.
Such systems rely on phrase tables ?a tabulation of correspondences between phrasesin the source language and phrases in the targetlanguage.
These tables are usually extracted by in-ducing word alignments between sentence pairs ina parallel training corpus and then incrementallybuilding longer phrasal correspondences from in-dividual words and shorter phrases.
Once such atabulation of bilingual correspondences is avail-able, correspondences between phrases in one lan-guage may be inferred simply by using the phrasesin the other language as pivots, e.g., if both ?man?and ?person?
correspond to ?personne?
in French,then they can be considered paraphrases.
Eachparaphrase pair (rule) in a pivoted paraphrase col-lection is defined by a source phrase e1, the targetphrase e2 that has been inferred as its paraphrase,and a probability score p(e2|e1) obtained from theprobability values in the bilingual phrase table.1Pivoted paraphrase collections have been suc-cessfully used in different NLP tasks includingautomated document summarization (Zhou et al2006), question answering (Riezler et al 2007),and machine translation (Madnani, 2010).
Yet, itis still difficult to get an estimate of the intrinsicquality and coverage of the paraphrases containedin these collections.
To remedy this, we proposeParaQuery ?
a tool that can help explore and ana-lyze pivoted paraphrase collections.2 ParaQueryIn this section we first briefly describe how to setup ParaQuery (?2.1) and then demonstrate its usein detail for interactively exploring and character-izing a paraphrase collection, analyzing its util-ity for a particular domain, and comparing it withother word-similarity resources (?2.2).
Detaileddocumentation will be included in the tool.1There may be other values associated with each pair, butwe ignore them for the purposes of this paper.1452.1 Setting upParaQuery operates on pivoted paraphrase collec-tions and can accept collections generated usingany set of tools that are preferred by the user, aslong as the collection is stored in a pre-definedplain-text format containing the source and targetphrases, the probability values, as well as informa-tion on pivots (optional but useful for pivot-drivenanalysis, as shown later).
This format is com-monly used in the machine translation and para-phrase generation community.
In this paper, weadapt the Thrax and Joshua (Ganitkevitch et al2012) toolkits to generate a pivoted paraphrasecollection using the English-French EuroParl par-allel corpus, which we use as our example col-lection for demonstrating ParaQuery.
Once a piv-oted collection is generated, ParaQuery needs toconvert it into an SQLite database against whichqueries can be run.
This is done by issuing theindex command at the ParaQuery command-lineinterface (described in ?2.2.1).2.2 Exploration and AnalysisIn order to provide meaningful exploration andanalysis, we studied various scenarios in whichparaphrase collections are used, and found that thefollowing issues typically interest the developersand users of such collections:1.
Semantic relations between the paraphrasesin the collection (e.g.
synonymy, hyponymy)and their frequency.2.
The frequency of inaccurate paraphrases,possible ways of de-noising the collection,and the meaningfulness of scores (betterparaphrases should be scored higher).3.
The utility of the collection for a specific do-main, i.e.
whether domain terms of interestare present in the collection.4.
Comparison of different collections based onthe above dimensions.We note that paraphrase collections are used inmany tasks with different acceptability thresholdsfor semantic relations, noisy paraphrases etc.
Wedo not intend to provide an exhaustive judgmentof paraphrase quality, but instead allow users tocharacterize a collection, enabling an analysis ofthe aforesaid issues and providing information forthem to decide whether a given collection is suit-able for their specific task and/or domain.2.2.1 Command line interfaceParaQuery allows interactive exploration andanalysis via a simple command line interface, byprocessing user issued queries such as:show <query>: display the rules which satisfythe conditions of the given query.show count <query>: display the number ofsuch rules.explain <query>: display information about thepivots which yielded each of these rules.analyze <query>: display statistics about theserules and save a report to an output file.The following information is stored in theSQLite database for each paraphrase rule:2?
The source and the target phrases, and theprobability score of the rule.?
Are the source and the target identical??
Do the source and the target have the samepart of speech?3?
Length of the source and the target, and thedifference in their lengths.?
Number of pivots and the list of pivots.?
Are both the source and the target found inWordNet (WN)?
If yes, the WN relation be-tween them (synonym, derivation, hypernym,hyponym, co-hyponym, antonym, meronym,holonym, pertainym) or the minimal dis-tance, if they are not connected directly.Therefore, all of the above can be used, alone orin combination, to constrain the queries and de-fine the rule(s) of interest.
Figure 1 presents sim-ple queries processed by the show command: thefirst query displays top-scoring rules with ?man?as their source phrase, while the second adds re-striction on the rules?
score.
By default, the tooldisplays the 10 best-scoring rules per query, butthis limit can be changed as shown.
For eachrule, the corresponding score and semantic rela-tion/distance is displayed.2Although some of this information is available in theparaphrase collection that was indexed, the remaining is auto-matically computed and injected into the database during theindexing process.
Indexing the French-pivoted paraphrasecollection (containing 3,633,015 paraphrase rules) used inthis paper took about 6 hours.3We use the simple parts of speech provided by WordNet(nouns, verbs, adjectives and adverbs).146The queries provide a flexible way to define andwork with the rule set of interest, starting from fil-tering low-scoring rules till extracting specific se-mantic relations or constraining on the number ofpivots.
Figure 2 presents additional examples ofqueries.
The tool also enables filtering out targetterms with a recurrent lemma, as illustrated in thesame figure.
Note that ParaQuery also contains abatch mode (in addition to the interactive mode il-lustrated so far) to automatically extract the outputfor a set of queries contained in a batch script.Figure 1: Examples of the show command and theprobability constraint.2.2.2 Analyzing pivot informationIt is well known that pivoted paraphrase collec-tions contain a lot of noisy rules.
To understandthe origins of such rules, an explain query can beused, which displays the pivots that yielded eachparaphrase rule, and the probability share of eachpivot in the final probability score.
Figure 3 showsan example of this command.We see that noisy rules can originate from stop-word pivots, e.g.
?l?.
It is common to filter rulescontaining stop-words, yet perhaps it is also im-portant to exclude stop-word pivots, which wasnever considered in the past.
We can use Para-Query to further explore whether discarding stop-word pivots is a good idea.
Figure 4 presentsa more complex query showing paraphrase rulesthat were extracted via a single pivot ?l?.
We seethat the top 5 such rules are indeed noisy, indicat-ing that perhaps all of the 5,360 rules satisfyingthe query can be filtered out.2.2.3 Analysis of rule setsIn order to provide an overall analysis of a rule setor a complete collection, ParaQuery includes theFigure 2: Restricting the output of the show com-mand using WordNet relations and distance, andthe unique lemma constraint.Figure 3: An example of the explain command.analyze command.
Figure 5 shows the typical in-formation provided by this command.
In addition,a report is generated to a file, including the anal-ysis information for the whole rule set and for itsthree parts: top, middle and bottom, as defined bythe scores of the rules in the set.
The output to thefile is more detailed and expands on the informa-tion presented in Figure 5.
For example, it alsoincludes, for each part, rule samples and score dis-tributions for each semantic relation and differentWordNet distances.The information contained in the report can be147Figure 4: Exploring French stop-word pivots using the pivots condition of the show command.Figure 5: An example of the analyze command (full output not shown for space reasons).148TOP BOTTOMfinest?
better approach?
eloutdoors?
external effect?
parliamentunsettled?
unstable comment?
speak upintelligentsia?
intelligence propose?
allottedcaretaker?
provisional prevent?
aimedluckily?
happily energy?
subject matterTable 1: A random sample of undefined relationrules from our collection?s top and bottom parts.easily used for generating graphs and tables.
Forexample, Figure 6 shows the distribution of se-mantic relations in the three parts of our exam-ple paraphrase collection.
The figure character-izes the collection in terms of semantic relationsit contains and illustrates the fact that the scoresagree with their desired behavior: (1) the collec-tion?s top-scoring part contains significantly moresynonyms than its middle and bottom parts, (2)similar trends hold for derivations and hypernyms,which are more suitable for paraphrasing than co-hyponyms and other relations not defined in Word-Net (we refer to these relations as undefined rela-tions), (3) such undefined relations have the high-est frequency in the collection?s bottom part, andare least frequent in its top part.
Among otherconclusions, the figure shows, that discarding thelower-scoring middle and bottom parts of the col-lection would allow retaining almost all the syn-onyms and derivations, while filtering out most ofthe co-hyponyms and a considerable number ofundefined relations.Yet from Figure 6 we see that undefined rela-tions constitute the majority of the rules in the col-lection.
To better understand this, random rulesamples provided in the analysis output can beused, as shown in Table 1.
From this table, we seethat the top-part rules are indeed mostly valid forparaphrasing, unlike the noisy bottom-part rules.The score distributions reported as part of the anal-ysis can be used to further explore the collec-tion and set sound thresholds suitable for differenttasks and needs.2.2.4 Analysis of domain utilityOne of the frequent questions of interest iswhether a given collection is suitable for a specificdomain.
To answer this question, ParaQuery al-lows the user to run the analysis from ?2.2.3 overrules whose source phrases belong to a specificdomain, by means of the analyze <query> us-ing <file> command.
The file can hold either alist of domain terms or a representative domaintext, from which frequent terms and term collo-cations will be automatically extracted, presentedto the user, and utilized for analysis.
The analysisincludes the coverage of the domain terms in theparaphrase collection, and can also be restricted totop-K rules per source term, a common practice inmany NLP applications.
We do not show an exam-ple of this command due to space considerations.2.2.5 Comparison with other collectionsThe output of the analyze command can also beused to compare different collections, either ingeneral or for a given domain.
Although Para-Query is designed for pivoted paraphrase collec-tions, it allows comparing them to non-pivotedparaphrase collections as well.
Next we present anexample of such a comparative study, performedusing ParaQuery via several analyze commands.Table 2 compares three different collections:the French pivoted paraphrase collection, a dis-tributional similarity resource (Kotlerman et al2010) and a Wikipedia-based resource (Shnarch etal., 2009).
The table shows the collection sizes,as well as the number of different (unique) sourcephrases in them and, correspondingly, the averagenumber of target phrases per source.
From thetable we can see that the distributional similarityresource contains a lot of general language termsfound in WordNet, while the Wikipedia resourceincludes only a small amount of such terms.
Asample of rules from the Wikipedia collection ex-plains this behavior, e.g.
?Yamaha SR500 ?
mo-torcycle?.
The table provides helpful informationto decide which collection is (more) suitable forspecific tasks, such as paraphrase recognition andgeneration, query expansion, automatic generationof training data for different supervised tasks, etc.3 Conclusions and Future WorkWe presented ParaQuery?a tool for interactiveexploration and analysis of pivoted paraphrasecollections?and showed that it can be used toestimate the intrinsic quality and coverage of theparaphrases contained in these collections, a taskthat is still somewhat difficult.
ParaQuery can alsobe used to answer the questions that users of suchcollections are most interested in.
We plan to re-lease ParaQuery under an open-source license, in-cluding our code for generating paraphrase col-lections that can then be indexed and analyzed by1490%20%40%60%80% Top Middle Bottom22% 11% 8% 4% 8% 0%45%6% 1% 4% 4%17%0%68%1% 0% 1% 1% 11% 0%86%Synonym Derivation Hypernym Hyponym Co-hyponym Antonym UndefinedFigure 6: Distribution of semantic relations in the top, middle and bottom parts of the example collection.The parts are defined by binning the scores of the rules in the collection.Collection Size (rules) In WordNet Unique Src Avg.
Tgts per Src davg for URPivoted (FR) 3,633,015 757,994 (21%) 188,898 16.064 2.567Dist.Sim.
7,298,321 3,252,967 (45%) 113,444 64.334 6.043Wikipedia 7,880,962 295,161 (4%) 2,727,362 2.890 8.556Table 2: Comparing the French-pivoted paraphrase collection to distributional-similarity based andWikipedia-based similarity collections, in terms of total size, percentage of rules in WordNet, numberof unique source phrases, average number of target phrases per source phrase, and the average WordNetdistance between the two sides of the undefined relation (UR) rules.ParaQuery.
We also plan to include pre-generatedparaphrase collections in the release so that usersof ParaQuery can use it immediately.In the future, we plan to use this tool for analyz-ing the nature of pivoted paraphrases.
The qualityand coverage of these paraphrases is known to de-pend on several factors, including (a) the genre ofthe bilingual corpus, (b) the word-alignment algo-rithm used during bilingual training, and (c) thepivot language itself.
However, there have beenno explicit studies designed to measure such vari-ations.
We believe that ParaQuery is perfectlysuited to conducting such studies and moving thefield of automated paraphrase generation forward.AcknowledgmentsThis work was partially supported by the European Commu-nity?s Seventh Framework Programme (FP7/2007-2013) un-der grant agreement no.
287923 (EXCITEMENT).ReferencesColin Bannard and Chris Callison-Burch.
2005.
Paraphras-ing with Bilingual Parallel Corpora.
In Proceedings ofACL, pages 597?604.Juri Ganitkevitch, Yuan Cao, Jonathan Weese, Matt Post, andChris Callison-Burch.
2012.
Joshua 4.0: Packing, PRO,and Paraphrases.
In Proceedings of WMT, pages 283?291.Lili Kotlerman, Ido Dagan, Idan Szpektor, and MaayanZhitomirsky-Geffet.
2010.
Directional DistributionalSimilarity for Lexical Inference.
Natural Language En-gineering, 16(4):359?389.Nitin Madnani and Bonnie J. Dorr.
2010.
GeneratingPhrasal and Sentential Paraphrases: A Survey of Data-driven Methods.
Computational Linguistics, 36(3):341?387.Nitin Madnani.
2010.
The Circle of Meaning: From Trans-lation to Paraphrasing and Back.
Ph.D. thesis, Depart-ment of Computer Science, University of Maryland Col-lege Park.Stefan Riezler, Alexander Vasserman, Ioannis Tsochan-taridis, Vibhu O. Mittal, and Yi Liu.
2007.
StatisticalMachine Translation for Query Expansion in Answer Re-trieval.
In Proceedings of ACL, pages 464?471.Eyal Shnarch, Libby Barak, and Ido Dagan.
2009.
Extractinglexical reference rules from Wikipedia.
In Proceedings ofACL-IJCNLP, pages 450?458.Liang Zhou, Chin-Yew Lin, Dragos Stefan Muntenau, andEduard Hovy.
2006.
ParaEval: Using Paraphrases toEvaluate Summaries Automatically.
In Proceedings ofHLT-NAACL, pages 447?454.150
