Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 304?313,Baltimore, Maryland, USA, June 23-25 2014. c?2014 Association for Computational LinguisticsAn Empirical Study on the Effect of Negation Words on SentimentXiaodan Zhu, Hongyu Guo, Saif Mohammad and Svetlana KiritchenkoNational Research Council Canada1200 Montreal RoadOttawa, K1A 0R6, ON, Canada{Xiaodan.Zhu,Hongyu.Guo,Saif.Mohammad,Svetlana.Kiritchenko}@nrc-cnrc.gc.caAbstractNegation words, such as no and not, playa fundamental role in modifying sentimentof textual expressions.
We will refer to anegation word as the negator and the textspan within the scope of the negator as theargument.
Commonly used heuristics toestimate the sentiment of negated expres-sions rely simply on the sentiment of ar-gument (and not on the negator or the ar-gument itself).
We use a sentiment tree-bank to show that these existing heuristicsare poor estimators of sentiment.
We thenmodify these heuristics to be dependent onthe negators and show that this improvesprediction.
Next, we evaluate a recentlyproposed composition model (Socher etal., 2013) that relies on both the negatorand the argument.
This model learns thesyntax and semantics of the negator?s ar-gument with a recursive neural network.We show that this approach performs bet-ter than those mentioned above.
In ad-dition, we explicitly incorporate the priorsentiment of the argument and observe thatthis information can help reduce fitting er-rors.1 IntroductionMorante and Sporleder (2012) define negation tobe ?a grammatical category that allows the chang-ing of the truth value of a proposition?.
Nega-tion is often expressed through the use of nega-tive signals or negators?words like isn?t and never,and it can significantly affect the sentiment ofits scope.
Understanding the impact of negationon sentiment is essential in automatic analysis ofsentiment.
The literature contains interesting re-search attempting to model and understand thebehavior (reviewed in Section 2).
For example,Figure 1: Effect of a list of common negatorsin modifying sentiment values in Stanford Senti-ment Treebank.
The x-axis is s(~w), and y-axisis s(wn, ~w).
Each dot in the figure correspondsto a text span being modified by (composed with)a negator in the treebank.
The red diagonal linecorresponds to the sentiment-reversing hypothesisthat simply reverses the sign of sentiment values.a simple yet influential hypothesis posits that anegator reverses the sign of the sentiment valueof the modified text (Polanyi and Zaenen, 2004;Kennedy and Inkpen, 2006).
The shifting hypoth-esis (Taboada et al, 2011), however, assumes thatnegators change sentiment values by a constantamount.
In this paper, we refer to a negation wordas the negator (e.g., isn?t), a text span being mod-ified by and composed with a negator as the ar-gument (e.g., very good), and entire phrase (e.g.,isn?t very good) as the negated phrase.The recently available Stanford Sentiment Tree-bank (Socher et al, 2013) renders manually anno-tated, real-valued sentiment scores for all phrasesin parse trees.
This corpus provides us with thedata to further understand the quantitative behav-ior of negators, as the effect of negators can nowbe studied with arguments of rich syntactic and se-mantic variety.
Figure 1 illustrates the effect of acommon list of negators on sentiment as observed304on the Stanford Sentiment Treebank.1 Each dot inthe figure corresponds to a negated phrase in thetreebank.
The x-axis is the sentiment score of itsargument s(~w) and y-axis the sentiment score ofthe entire negated phrase s(wn, ~w).We can see that the reversing assumption (thered diagonal line) does capture some regularity ofhuman perception, but rather roughly.
Moreover,the figure shows that same or similar s(~w) scores(x-axis) can correspond to very different s(wn, ~w)scores (y-axis), which, to some degree, suggeststhe potentially complicated behavior of negators.2This paper describes a quantitative study ofthe effect of a list of frequent negators on sen-timent.
We regard the negators?
behavior as anunderlying function embedded in annotated data;we aim to model this function from different as-pects.
By examining sentiment compositions ofnegators and arguments, we model the quantita-tive behavior of negators in changing sentiment.That is, given a negated phrase (e.g., isn?t verygood) and the sentiment score of its argument(e.g., s(?very good??)
= 0.5), we focus on un-derstanding the negator?s quantitative behavior inyielding the sentiment score of the negated phrases(?isn?t very good??
).We first evaluate the modeling capabilities oftwo influential heuristics and show that they cap-ture only very limited regularity of negators?
ef-fect.
We then extend the models to be dependenton the negators and demonstrate that such a sim-ple extension can significantly improve the per-formance of fitting to the human annotated data.Next, we evaluate a recently proposed composi-tion model (Socher, 2013) that relies on both thenegator and the argument.
This model learns thesyntax and semantics of the negator?s argumentwith a recursive neural network.
This approachperforms significantly better than those mentionedabove.
In addition, we explicitly incorporate theprior sentiment of the argument and observe thatthis information helps reduce fitting errors.1The sentiment values have been linearly rescaled fromthe original range [0, 1] to [-0.5, 0.5]; in the figure a negativeor positive value corresponds to a negative or a positive sen-timent respectively; zero means neutral.
The negator list willbe discussed later in the paper.2Similar distribution is observed in other data such asTweets (Kiritchenko et al, 2014).2 Related workAutomatic sentiment analysis The expression ofsentiment is an integral component of human lan-guage.
In written text, sentiment is conveyed withword senses and their composition, and in speechalso via prosody such as pitch (Mairesse et al,2012).
Early work on automatic sentiment anal-ysis includes the widely cited work of (Hatzivas-siloglou and McKeown, 1997; Pang et al, 2002;Turney, 2002), among others.
Since then, there hasbeen an explosion of research addressing variousaspects of the problem, including detecting sub-jectivity, rating and classifying sentiment, label-ing sentiment-related semantic roles (e.g., targetof sentiment), and visualizing sentiment (see sur-veys by Pang and Lee (2008) and Liu and Zhang(2012)).Negation modeling Negation is a general gram-matical category pertaining to the changing of thetruth values of propositions; negation modeling isnot limited to sentiment.
For example, paraphraseand contradiction detection systems rely on detect-ing negated expressions and opposites (Harabagiuet al, 2006).
In general, a negated expression andthe opposite of the expression may or may not con-vey the same meaning.
For example, not alive hasthe same meaning as dead, however, not tall doesnot always mean short.
Some automatic methodsto detect opposites were proposed by Hatzivas-siloglou and McKeown (1997) and Mohammad etal.
(2013).Negation modeling for sentiment An early yetinfluential reversing assumption conjectures that anegator reverses the sign of the sentiment valueof the modified text (Polanyi and Zaenen, 2004;Kennedy and Inkpen, 2006), e.g., from +0.5 to -0.5, or vice versa.
A different hypothesis, calledthe shifting hypothesis in this paper, assumes thatnegators change the sentiment values by a con-stant amount (Taboada et al, 2011; Liu and Sen-eff, 2009).
Other approaches to negation modelinghave been discussed in (Jia et al, 2009; Wiegandet al, 2010; Lapponi et al, 2012; Benamara et al,2012).In the process of semantic composition, the ef-fect of negators could depend on the syntax andsemantics of the text spans they modify.
The ap-proaches of modeling this include bag-of-word-based models.
For example, in the work of(Kennedy and Inkpen, 2006), a feature not goodwill be created if the word good is encountered305within a predefined range after a negator.There exist different ways of incorporatingmore complicated syntactic and semantic infor-mation.
Much recent work considers sentimentanalysis from a semantic-composition perspec-tive (Moilanen and Pulman, 2007; Choi andCardie, 2008; Socher et al, 2012; Socher et al,2013), which achieved the state-of-the-art perfor-mance.
Moilanen and Pulman (2007) used a col-lection of hand-written compositional rules to as-sign sentiment values to different granularities oftext spans.
Choi and Cardie (2008) proposed alearning-based framework.
The more recent workof (Socher et al, 2012; Socher et al, 2013) pro-posed models based on recursive neural networksthat do not rely on any heuristic rules.
Such mod-els work in a bottom-up fashion over the parsetree of a sentence to infer the sentiment label ofthe sentence as a composition of the sentiment ex-pressed by its constituting parts.
The approachleverages a principled method, the forward andbackward propagation, to learn a vector represen-tation to optimize the system performance.
Inprinciple neural network is able to fit very compli-cated functions (Mitchell, 1997), and in this paper,we adapt the state-of-the-art approach described in(Socher et al, 2013) to help understand the behav-ior of negators specifically.3 Negation models based on heuristicsWe begin with previously proposed methods thatleverage heuristics to model the behavior of nega-tors.
We then propose to extend them to considerlexical information of the negators themselves.3.1 Non-lexicalized assumptions andmodelingIn previous research, some influential, widelyadopted assumptions posit the effect of negatorsto be independent of both the specific negators andthe semantics and syntax of the arguments.
In thispaper, we call a model based on such assumptionsa non-lexicalized model.
In general, we can sim-ply define this category of models in Equation 1.That is, the model parameters are only based onthe sentiment value of the arguments.s(wn, ~w)def= f(s(~w)) (1)3.1.1 Reversing hypothesisA typical model falling into this category is thereversing hypothesis discussed in Section 2, wherea negator simply reverses the sentiment score s(~w)to be ?s(~w); i.e., f(s(~w)) = ?s(~w).3.1.2 Shifting hypothesisBasic shifting Similarly, a shifting based modeldepends on s(~w) only, which can be written as:f(s(~w)) = s(~w) ?
sign(s(~w)) ?
C (2)where sign(.)
is the standard sign functionwhich determines if the constant C should beadded to or deducted from s(wn): the constant isadded to a negative s(~w) but deducted from a pos-itive one.Polarity-based shifting As will be shown in ourexperiments, negators can have different shiftingpower when modifying a positive or a negativephrase.
Thus, we explore the use of two differentconstants for these two situations, i.e., f(s(~w)) =s(~w)?sign(s(~w))?C(sign(s(~w))).
The constantC now can take one of two possible values.
Wewill show that this simple modification improvesthe fitting performance statistically significantly.Note also that instead of determining these con-stants by human intuition, we use the training datato find the constants in all shifting-based modelsas well as for the parameters in other models.3.2 Simple lexicalized assumptionsThe above negation hypotheses rely on s(~w).
Asintuitively shown in Figure 1, the capability of thenon-lexicalized heuristics might be limited.
Fur-ther semantic or syntactic information from eitherthe negators or the phrases they modify could behelpful.
The most straightforward way of expand-ing the non-lexicalized heuristics is probably tomake the models to be dependent on the negators.s(wn, ~w)def= f(wn, s(~w)) (3)Negator-based shifting We can simply extend thebasic shifting model above to consider the lexi-cal information of negators: f(s(~w)) = s(~w) ?sign(s(~w)) ?C(wn).
That is, each negator has itsown C .
We call this model negator-based shift-ing.
We will show that this model also statisticallysignificantly outperforms the basic shifting with-out overfitting, although the number of parametershave increased.306Combined shifting We further combine thenegator-based shifting and polarity-based shift-ing above: f(s(~w)) = s(~w) ?
sign(s(~w)) ?C(wn, sign(s(~w))).
This shifting model isbased on negators and the polarity of the textthey modify: constants can be different for eachnegator-polarity pair.
The number of parametersin this model is the multiplication of numberof negators by two (the number of sentimentpolarities).
This model further improves the fittingperformance on the test data.4 Semantics-enriched modelingNegators can interact with arguments in complexways.
Figure 1 shows the distribution of the ef-fect of negators on sentiment without consideringfurther semantics of the arguments.
The questionthen is that whether and how much incorporatingfurther syntax and semantic information can helpbetter fit or predict the negation effect.
Above, wehave considered the semantics of the negators.
Be-low, we further make the models to be dependenton the arguments.
This can be written as:s(wn, ~w)def= f(wn, s(~w), r(~w)) (4)In the formula, r(~w) is a certain type of repre-sentation for the argument ~w and it models the se-mantics or/and syntax of the argument.
There ex-ist different ways of implementing r(~w).
We con-sider two models in this study: one drops s(~w) inEquation 4 and directly models f(wn, r(~w)).
Thatis, the non-uniform information shown in Figure 1is not directly modeled.
The other takes into ac-count s(~w) too.For the former, we adopt the recursive neu-ral tensor network (RNTN) proposed recently bySocher et al (2013), which has showed to achievethe state-of-the-art performance in sentiment anal-ysis.
For the latter, we propose a prior sentiment-enriched tensor network (PSTN) to take into ac-count the prior sentiment of the argument s(~w).4.1 RNTN: Recursive neural tensor networkA recursive neural tensor network (RNTN) isa specific form of feed-forward neural networkbased on syntactic (phrasal-structure) parse treeto conduct compositional sentiment analysis.
Forcompleteness, we briefly review it here.
More de-tails can be found in (Socher et al, 2013).As shown in the black portion of Figure 2, eachinstance of RNTN corresponds to a binary parseFigure 2: Prior sentiment-enriched tensor network(PSTN) model for sentiment analysis.tree of a given sentence.
Each node of the parsetree is a fixed-length vector that encodes composi-tional semantics and syntax, which can be used topredict the sentiment of this node.
The vector of anode, say p2in Figure 2, is computed from the d-dimensional vectors of its two children, namely aand p1(a, p1?
Rd?1), with a non-linear function:p2= tanh([ap1]TV[1:d][ap1]+ W[ap1]) (5)where, W ?
Rd?
(d+d) and V ?
R(d+d)?
(d+d)?dare the matrix and tensor for the composition func-tion.
A major difference of RNTN from the con-ventional recursive neural network (RRN) (Socheret al, 2012) is the use of the tensor V in orderto directly capture the multiplicative interaction oftwo input vectors, although the matrix W implic-itly captures the nonlinear interaction between theinput vectors.
The training of RNTN uses conven-tional forward-backward propagation.4.2 PSTN: Prior sentiment-enriched tensornetworkThe non-uniform distribution in Figure 1 hasshowed certain correlations between the sentimentvalues of s(wn, ~w) and s(~w), and such informa-tion has been leveraged in the models discussed inSection 3.
We intend to devise a model that imple-ments Equation 4.
It bridges between the modelswe have discussed above that use either s(~w) orr(~w).We extend RNTN to directly consider the senti-ment information of arguments.
Consider the nodep2in Figure 2.
When calculating its vector, weaim to directly engage the sentiment informationof its right child, i.e., the argument.
To this end,we make use of the sentiment class information of307p1, noted as psen1.
As a result, the vector of p2iscalculated as follows:p2= tanh([ap1]TV[1:d][ap1]+ W[ap1](6)+[apsen1]TVsen[1:d][apsen1]+ Wsen[apsen1])As shown in Equation 6, for the node vectorp1?
Rd?1, we employ a matrix, namely W sen ?Rd?
(d+m) and a tensor, V sen ?
R(d+m)?
(d+m)?d,aiming at explicitly capturing the interplays be-tween the sentiment class of p1, denoted as psen1(?Rm?1), and the negator a.
Here, we assume thesentiment task has m classes.
Following the ideaof Wilson et al (2005), we regard the sentiment ofp1as a prior sentiment as it has not been affectedby the specific context (negators), so we denoteour method as prior sentiment-enriched tensor net-work (PSTN).
In Figure 2, the red portion showsthe added components of PSTN.Note that depending on different purposes, psen1can take the value of the automatically predictedsentiment distribution obtained in forward propa-gation, the gold sentiment annotation of node p1,or even other normalized prior sentiment value orconfidence score from external sources (e.g., sen-timent lexicons or external training data).
Thisis actually an interesting place to extend the cur-rent recursive neural network to consider extrinsicknowledge.
However, in our current study, we fo-cus on exploring the behavior of negators.
As wehave discussed above, we will use the human an-notated sentiment for the arguments, same as inthe models discussed in Section 3.With the new matrix and tensor, we then have?
= (V, Vsen,W,Wsen,Wlabel, L) as the PSTNmodel?s parameters.
Here, L denotes the vectorrepresentations of the word dictionary.4.2.1 Inference and LearningInference and learning in PSTN follow a forward-backward propagation process similar to that in(Socher et al, 2013), and for completeness, wedepict the details as follows.
To train the model,one first needs to calculate the predicted sentimentdistribution for each node:pseni= Wlabelpi, pseni?
Rm?1and then compute the posterior probability overthe m labels:yi= softmax(pseni)During learning, following the method used bythe RNTN model in (Socher et al, 2013), PSTNalso aims to minimize the cross-entropy error be-tween the predicted distribution yi ?
Rm?1 atnode i and the target distribution ti ?
Rm?1 at thatnode.
That is, the error for a sentence is calculatedas:E(?)
=?i?jtijlogyij+ ?
??
?2 (7)where, ?
represents the regularization hyperpa-rameters, and j ?
m denotes the j-th element ofthe multinomial target distribution.To minimize E(?
), the gradient of the objec-tive function with respect to each of the param-eters in ?
is calculated efficiently via backprop-agation through structure, as proposed by Gollerand Kchler (1996).
Specifically, we first computethe prediction errors in all tree nodes bottom-up.After this forward process, we then calculate thederivatives of the softmax classifiers at each nodein the tree in a top-down fashion.
We will discussthe gradient computation for the V sen and W senin detail next.
Note that the gradient calculationsfor the V,W,W label, L are the same as that of pre-sented in (Socher et al, 2013).In the backpropogation process of the training,each node (except the root node) in the tree car-ries two kinds of errors: the local softmax errorand the error passing down from its parent node.During the derivative computation, the two errorswill be summed up as the complement incomingerror for the node.
We denote the complete incom-ing error and the softmax error vector for node ias ?i,com ?
Rd?1 and ?i,s ?
Rd?1, respectively.With this notation, the error for the root node p2can be formulated as follows.
?p2,com= ?p2,s= (WT(yp2?
tp2)) ?
f?
([a; p1]) (8)where ?
is the Hadamard product between the twovectors and f ?
is the element-wise derivative off = tanh.
With the results from Equation 8, wethen can calculate the derivatives for the W sen atnode p2using the following equation:?Ep2Wsen= ?p2,com([a; psen1])TSimilarly, for the derivative of each slice k(k =3081, .
.
.
, d) of the V sen tensor, we have the follow-ing:?Ep2Vsen[k]= ?p2,comk[apsen1] [apsen1]TNow, let?s form the equations for computing theerror for the two children of the p2node.
The dif-ference for the error at p2and its two children isthat the error for the latter will need to compute theerror message passing down from p2.
We denotethe error passing down as ?p2,down, where the leftchild and the right child of p2take the 1st and 2ndhalf of the error ?p2,down, namely ?p2,down[1 : d]and ?p2,down[d + 1 : 2d], respectively.
Follow-ing this notation, we have the error message forthe two children of p2, provided that we have the?p2,down:?p1,com= ?p1,s+ ?p2,down[d + 1 : 2d]= (WT(yp1?
tp1)) ?
f?
([b; c])+ ?p2,down[d + 1 : 2d]The incoming error message of node a can becalculated similarly.
Finally, we can finish theabove equations with the following formula forcomputing ?p2,down:?p2,down= (WT?p2,com) ?
f?
([a; p1]) + ?tensorwhere?tensor= [?V[1 : d] + ?Vsen[1 : d], ?V[d + 1 : 2d]]=d?k=1?p2,comk(V[k]+ (V[k])T)?
f?
([a; p1])[1 : d]+d?k=1?p2,comk(Vsen[k]+ (Vsen[k])T)?
f?
([a; psen1])[1 : d]+d?k=1?p2,comk(V[k]+ (V[k])T)?
f?
([a; p1])[d + 1 : 2d]After the models are trained, they are applied topredict the sentiment of the test data.
The orig-inal RNTN and the PSTN predict 5-class senti-ment for each negated phrase; we map the out-put to real-valued scores based on the scale thatSocher et al (2013) used to map real-valued senti-ment scores to sentiment categories.
Specifically,we conduct the mapping with the formula: preali=yi?
[0.1 0.3 0.5 0.7 0.9]; i.e., we calculate the dotproduct of the posterior probability yi and the scal-ing vector.
For example, if yi = [0.5 0.5 0 0 0],meaning this phrase has a 0.5 probability to bein the first category (strong negative) and 0.5 forthe second category (weak negative), the resultingprealiwill be 0.2 (0.5*0.1+0.5*0.3).5 Experiment set-upData As described earlier, the Stanford SentimentTreebank (Socher et al, 2013) has manually anno-tated, real-valued sentiment values for all phrasesin parse trees.
This provides us with the trainingand evaluation data to study the effect of negatorswith syntax and semantics of different complex-ity in a natural setting.
The data contain around11,800 sentences from movie reviews that wereoriginally collected by Pang and Lee (2005).
Thesentences were parsed with the Stanford parser(Klein and Manning, 2003).
The phrases at alltree nodes were manually annotated with one of 25sentiment values that uniformly span between thepositive and negative poles.
The values are nor-malized to the range of [0, 1].In this paper, we use a list of most frequentnegators that include the words not, no, never, andtheir combinations with auxiliaries (e.g., didn?t).We search these negators in the Stanford Senti-ment Treebank and normalize the same negators toa single form; e.g., ?is n?t?, ?isn?t?, and ?is not?are all normalized to ?is not?.
Each occurrence ofa negator and the phrase it is directly composedwith in the treebank, i.e., ?wn, ~w?, is considereda data point in our study.
In total, we collected2,261 pairs, including 1,845 training and 416 testcases.
The split of training and test data is same asspecified in (Socher et al, 2013).Evaluation metrics We use the mean absolute er-ror (MAE) to evaluate the models, which mea-sures the averaged absolute offsets between thepredicted sentiment values and the gold stan-dard.
More specifically, MAE is calculated as:MAE =1N?
?wn, ~w?|(s?
(wn, ~w) ?
s(wn, ~w))|,where s?
(wn, ~w) denotes the gold sentiment valueand s(wn, ~w) the predicted one for the pair?wn, ~w?, and N is the total number of test in-stances.
Note that mean square error (MSE) is an-other widely used measure for regression, but it isless intuitive for out task here.6 Experimental resultsOverall regression performance Table 1 showsthe overall fitting performance of all models.
Thefirst row of the table is a random baseline, which309simply guesses the sentiment value for each testcase randomly in the range [0,1].
The table showsthat the basic reversing and shifting heuristics docapture negators?
behavior to some degree, as theirMAE scores are higher than that of the baseline.Making the basic shifting model to be dependenton the negators (model 4) reduces the predictionerror significantly as compared with the error ofthe basic shifting (model 3).
The same is truefor the polarity-based shifting (model 5), reflect-ing that the roles of negators are different whenmodifying positive and negative phrases.
Mergingthese two models yields additional improvement(model 6).Assumptions MAEBaseline(1) Random 0.2796Non-lexicalized(2) Reversing 0.1480*(3) Basic shifting 0.1452*Simple-lexicalized(4) Negator-based shifting 0.1415?
(5) Polarity-based shifting 0.1417?
(6) Combined shifting 0.1387?Semantics-enriched(7) RNTN 0.1097**(8) PSTN 0.1062?
?Table 1: Mean absolute errors (MAE) of fittingdifferent models to Stanford Sentiment Treebank.Models marked with an asterisk (*) are statisti-cally significantly better than the random baseline.Models with a dagger sign (?)
significantly outper-form model (3).
Double asterisks ** indicates astatistically significantly different from model (6),and the model with the double dagger ?
?is signif-icantly better than model (7).
One-tailed pairedt-test with a 95% significance level is used here.Furthermore, modeling the syntax and seman-tics with the state-of-the-art recursive neural net-work (model 7 and 8) can dramatically improvethe performance over model 6.
The PSTN model,which takes into account the human-annotatedprior sentiment of arguments, performs the best.This could suggest that additional external knowl-edge, e.g., that from human-built resources or au-tomatically learned from other data (e.g., as in(Kiritchenko et al, 2014)), including sentimentthat cannot be inferred from its constituent expres-sions, might be incorporated to benefit the currentis_neverwill_notis_notdoes_notbarelywas_notcould_notnotdid_notunlikelydo_notcan_notnohas_notsuperficialwould_notshould_not0.050.100.150.200.250.30Figure 3: Effect of different negators in shiftingsentiment values.neural-network-based models as prior knowledge.Note that the two neural network based modelsincorporate the syntax and semantics by represent-ing each node with a vector.
One may considerthat a straightforward way of considering the se-mantics of the modified phrases is simply memo-rizing them.
For example, if a phrase very goodmodified by a negator not appears in the train-ing and test data, the system can simply memorizethe sentiment score of not very good in trainingand use this score at testing.
When incorporatingthis memorizing strategy into model (6), we ob-served a MAE score of 0.1222.
It?s not surprisingthat memorizing the phrases has some benefit, butsuch matching relies on the exact reoccurrences ofphrases.
Note that this is a special case of what theneural network based models can model.Discriminating negators The results in Table 1has demonstrated the benefit of discriminatingnegators.
To understand this further, we plot inFigure 3 the behavior of different negators: thex-axis is a subset of our negators and the y-axisdenotes absolute shifting in sentiment values.
Forexample, we can see that the negator ?is never?on average shifts the sentiment of the argumentsby 0.26, which is a significant change consideringthe range of sentiment value is [0, 1].
For eachnegator, a 95% confidence interval is shown bythe boxes in the figure, which is calculated withthe bootstrapping resampling method.
We can ob-serve statistically significant differences of shift-ing abilities between many negator pairs such asthat between ?is never?
and ?do not?
as well asbetween ?does not?
and ?can not?.Figure 3 also includes three diminishers (the310is_not(nn)is_not(np)does_not(nn)does_not(np)not(nn)not(np)do_not(nn)do_not(np)no(nn)no(np)0.150.200.250.30Figure 4: The behavior of individual negators innegated negative (nn) and negated positive (np)context.white bars), i.e., barely, unlikely, and superficial.By following (Kennedy and Inkpen, 2006), we ex-tracted 319 diminishers (also called understate-ment or downtoners) from General Inquirer3.
Wecalculated their shifting power in the same man-ner as for the negators and found three diminish-ers having shifting capability in the shifting rangeof these negators.
This shows that the boundarybetween negators and diminishers can by fuzzy.In general, we argue that one should always con-sider modeling negators individually in a senti-ment analysis system.
Alternatively, if the model-ing has to be done in groups, one should considerclustering valence shifters by their shifting abili-ties in training or external data.Figure 4 shows the shifting capacity of negatorswhen they modify positive (blue boxes) or nega-tive phrases (red boxes).
The figure includes fivemost frequently used negators found in the sen-timent treebank.
Four of them have significantlydifferent shifting power when composed with pos-itive or negative phrases, which can explain whythe polarity-based shifting model achieves im-provement over the basic shifting model.Modeling syntax and semantics We have seenabove that modeling syntax and semantics throughthe-state-of-the-art neural networks help improvethe fitting performance.
Below, we take a closerlook at the fitting errors made at different depthsof the sentiment treebank.
The depth here is de-fined as the longest distance between the root of anegator-phrase pair ?wn, ~w?
and their descendant3http://www.wjh.harvard.edu/ inquirer/Figure 5: Errors made at different depths in thesentiment tree bank.leafs.
Negators appearing at deeper levels of thetree tend to have more complicated syntax and se-mantics.
In Figure 5, the x-axis corresponds todifferent depths and y-axis is the mean absoluteerrors (MAE).The figure shows that both RNTN and PSTNperform much better at all depths than the model6 in Table 1.
When the depths are within 4,the RNTN performs very well and the (humanannotated) prior sentiment of arguments usedin PSTN does not bring additional improvementover RNTN.
PSTN outperforms RNTN at greaterdepths, where the syntax and semantics are morecomplicated and harder to model.
The errors madeby model 6 is bumpy, as the model considersno semantics and hence its errors are not depen-dent on the depths.
On the other hand, the er-rors of RNTN and PSTN monotonically increasewith depths, indicating the increase in the task dif-ficulty.7 ConclusionsNegation plays a fundamental role in modifyingsentiment.
In the process of semantic compo-sition, the impact of negators is complicated bythe syntax and semantics of the text spans theymodify.
This paper provides a comprehensiveand quantitative study of the behavior of negatorsthrough a unified view of fitting human annota-tion.
We first measure the modeling capabilities oftwo influential heuristics on a sentiment treebankand find that they capture some effect of negation;however, extending these non-lexicalized modelsto be dependent on the negators improves the per-311formance statistically significantly.
The detailedanalysis reveals the differences in the behavioramong negators, and we argue that they should al-ways be modeled separately.
We further make themodels to be dependent on the text being modi-fied by negators, through adaptation of a state-of-the-art recursive neural network to incorporate thesyntax and semantics of the arguments; we dis-cover this further reduces fitting errors.ReferencesFarah Benamara, Baptiste Chardon, Yannick Mathieu,Vladimir Popescu, and Nicholas Asher.
2012.
Howdo negation and modality impact on opinions?
InProceedings of the ACL-2012 Workshop on Extra-Propositional Aspects of Meaning in ComputationalLinguistics, pages 10?18, Jeju, Republic of Korea.Yejin Choi and Claire Cardie.
2008.
Learning withcompositional semantics as structural inference forsubsentential sentiment analysis.
In Proceedings ofthe Conference on Empirical Methods in NaturalLanguage Processing, EMNLP ?08, pages 793?801,Honolulu, Hawaii.Christoph Goller and Andreas Kchler.
1996.
Learn-ing task-dependent distributed representations bybackpropagation through structure.
In In Proc.
ofthe ICNN-96, pages 347?352, Bochum, Germany.IEEE.Sanda Harabagiu, Andrew Hickl, and Finley Lacatusu.2006.
Negation, contrast and contradiction in textprocessing.
In AAAI, volume 6, pages 755?762.Vasileios Hatzivassiloglou and Kathleen R. McKeown.1997.
Predicting the semantic orientation of adjec-tives.
In Proceedings of the 8th Conference of Euro-pean Chapter of the Association for ComputationalLinguistics, EACL ?97, pages 174?181, Madrid,Spain.Lifeng Jia, Clement Yu, and Weiyi Meng.
2009.
Theeffect of negation on sentiment analysis and retrievaleffectiveness.
In Proceedings of the 18th ACM Con-ference on Information and Knowledge Manage-ment, CIKM ?09, pages 1827?1830, Hong Kong,China.
ACM.Alistair Kennedy and Diana Inkpen.
2006.
Senti-ment classification of movie reviews using contex-tual valence shifters.
Computational Intelligence,22(2):110?125.Svetlana Kiritchenko, Xiaodan Zhu, and Saif Moham-mad.
2014.
Sentiment analysis of short informaltexts.
(to appear) Journal of Artificial IntelligenceResearch.Dan Klein and Christopher D. Manning.
2003.
Ac-curate unlexicalized parsing.
In Proceedings of the41st Annual Meeting on Association for Computa-tional Linguistics - Volume 1, ACL ?03, pages 423?430, Sapporo, Japan.
Association for ComputationalLinguistics.Emanuele Lapponi, Jonathon Read, and Lilja Ovre-lid.
2012.
Representing and resolving negationfor sentiment analysis.
In Jilles Vreeken, CharlesLing, Mohammed Javeed Zaki, Arno Siebes, Jef-frey Xu Yu, Bart Goethals, Geoffrey I. Webb, andXindong Wu, editors, ICDM Workshops, pages 687?692.
IEEE Computer Society.Jingjing Liu and Stephanie Seneff.
2009. Review sen-timent scoring via a parse-and-paraphrase paradigm.In EMNLP, pages 161?169, Singapore.Bing Liu and Lei Zhang.
2012.
A survey of opin-ion mining and sentiment analysis.
In Charu C. Ag-garwal and ChengXiang Zhai, editors, Mining TextData, pages 415?463.
Springer US.Franc?ois Mairesse, Joseph Polifroni, and GiuseppeDi Fabbrizio.
2012.
Can prosody inform sentimentanalysis?
experiments on short spoken reviews.
InICASSP, pages 5093?5096, Kyoto, Japan.Tom M Mitchell.
1997.
Machine learning.
1997.
BurrRidge, IL: McGraw Hill, 45.Saif M. Mohammad, Bonnie J. Dorr, Graeme Hirst, andPeter D. Turney.
2013.
Computing lexical contrast.Computational Linguistics, 39(3):555?590.Karo Moilanen and Stephen Pulman.
2007.
Senti-ment composition.
In Proceedings of RANLP 2007,Borovets, Bulgaria.Roser Morante and Caroline Sporleder.
2012.
Modal-ity and negation: An introduction to the special is-sue.
Computational linguistics, 38(2):223?260.Bo Pang and Lillian Lee.
2005.
Seeing stars: Ex-ploiting class relationships for sentiment categoriza-tion with respect to rating scales.
In Proceedings ofthe Annual Meeting of the Association for Computa-tional Linguistics, ACL ?05, pages 115?124.Bo Pang and Lillian Lee.
2008.
Opinion mining andsentiment analysis.
Foundations and Trends in In-formation Retrieval, 2(1?2):1?135.Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.2002.
Thumbs up?
sentiment classification us-ing machine learning techniques.
In Proceedings ofEMNLP, pages 79?86, Philadelphia, USA.Livia Polanyi and Annie Zaenen.
2004.
Contextualvalence shifters.
In Exploring Attitude and Affect inText: Theories and Applications (AAAI Spring Sym-posium Series).Richard Socher, Brody Huval, Christopher D. Man-ning, and Andrew Y. Ng.
2012.
Semantic composi-tionality through recursive matrix-vector spaces.
In312Proceedings of the Conference on Empirical Meth-ods in Natural Language Processing, EMNLP ?12,Jeju, Korea.
Association for Computational Linguis-tics.Richard Socher, Alex Perelygin, Jean Y. Wu, JasonChuang, Christopher D. Manning, Andrew Y. Ng,and Christopher Potts.
2013.
Recursive deep mod-els for semantic compositionality over a sentimenttreebank.
In Proceedings of the Conference on Em-pirical Methods in Natural Language Processing,EMNLP ?13, Seattle, USA.
Association for Compu-tational Linguistics.Maite Taboada, Julian Brooke, Milan Tofiloski, Kim-berly Voll, and Manfred Stede.
2011.
Lexicon-based methods for sentiment analysis.
Computa-tional Linguistics, 37(2):267?307.Peter Turney.
2002.
Thumbs up or thumbs down?
se-mantic orientation applied to unsupervised classifi-cation of reviews.
In ACL, pages 417?424, Philadel-phia, USA.Michael Wiegand, Alexandra Balahur, Benjamin Roth,Dietrich Klakow, and Andre?s Montoyo.
2010.
Asurvey on the role of negation in sentiment analysis.In Proceedings of the Workshop on Negation andSpeculation in Natural Language Processing, NeSp-NLP ?10, pages 60?68, Stroudsburg, PA, USA.
As-sociation for Computational Linguistics.Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.2005.
Recognizing contextual polarity in phrase-level sentiment analysis.
In Proceedings of the Con-ference on Human Language Technology and Em-pirical Methods in Natural Language Processing,HLT ?05, pages 347?354, Stroudsburg, PA, USA.Association for Computational Linguistics.313
