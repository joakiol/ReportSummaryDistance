Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 187?192,Baltimore, Maryland, USA, June 23-25 2014.c?2014 Association for Computational LinguisticsAutomatically Detecting Corresponding Edit-Turn-Pairs in WikipediaJohannes Daxenberger?and Iryna Gurevych???
Ubiquitous Knowledge Processing LabDepartment of Computer Science, Technische Universit?at Darmstadt?
Information Center for EducationGerman Institute for Educational Research and Educational Informationhttp://www.ukp.tu-darmstadt.deAbstractIn this study, we analyze links betweenedits in Wikipedia articles and turns fromtheir discussion page.
Our motivation isto better understand implicit details aboutthe writing process and knowledge flow incollaboratively created resources.
Basedon properties of the involved edit andturn, we have defined constraints for corre-sponding edit-turn-pairs.
We manually an-notated a corpus of 636 corresponding andnon-corresponding edit-turn-pairs.
Fur-thermore, we show how our data can beused to automatically identify correspond-ing edit-turn-pairs.
With the help of su-pervised machine learning, we achieve anaccuracy of .87 for this task.1 IntroductionThe process of user interaction in collaborativewriting has been the topic of many studies in re-cent years (Erkens et al, 2005).
Most of the re-sources used for collaborative writing do not ex-plicitly allow their users to interact directly, so thatthe implicit effort of coordination behind the ac-tual writing is not documented.
Wikipedia, as oneof the most prominent collaboratively created re-sources, offers its users a platform to coordinatetheir writing, the so called talk or discussion pages(Vi?egas et al, 2007).
In addition to that, Wikipediastores all edits made to any of its pages in a revi-sion history, which makes the actual writing pro-cess explicit.
We argue that linking these two re-sources helps to get a better picture of the collabo-rative writing process.
To enable such interaction,we extract segments from discussion pages, calledturns, and connect them to corresponding edits inthe respective article.
Consider the following snip-pet from the discussion page of the article ?Boron?in the English Wikipedia.
On February 16th of2011, user JCM83 added the turn:Shouldn?t borax be wikilinked in the?etymology?
paragraph?Roughly five hours after that turn was issuedon the discussion page, user Sbharris addeda wikilink to the ?History and etymology?
sec-tion of the article by performing the followingedit:'' borax''?
[[borax]]This is what we define as a corresponding edit-turn-pair.
More details follow in Section 2.
Tothe best of our knowledge, this study is the firstattempt to detect corresponding edit-turn-pairs inthe English Wikipedia fully automatically.Our motivation for this task is two-fold.
First,an automatic detection of corresponding edit-turn-pairs in Wikipedia pages might help users of theencyclopedia to better understand the developmentof the article they are reading.
Instead of having toread through all of the discussion page which canbe an exhausting task for many of the larger arti-cles in the English Wikipedia, users could focuson those discussions that actually had an impacton the article they are reading.
Second, assumingthat edits often introduce new knowledge to an ar-ticle, it might be interesting to analyze how muchof this knowledge was actually generated withinthe discourse on the discussion page.The detection of correspondence between editsand turns is also relevant beyond Wikipedia.
Manycompanies use Wikis to store internal informationand documentation (Arazy et al, 2009).
An align-ment between edits in the company Wiki and is-sues discussed in email conversations, on mailinglists, or other forums, can be helpful to track theflow or generation of knowledge within the com-pany.
This information can be useful to improvecommunication and knowledge sharing.187In the limited scope of this paper, we will fo-cus on two research questions.
First, we want tounderstand the nature of correspondence betweenWikipedia article edits and discussion page turns.Second, we want to know the distinctive propertiesof corresponding edit-turn-pairs and how to usethese to automatically detect corresponding pairs.2 Edit-Turn-PairsIn this section, we will define the basic units of ourtask, namely edits and turns.
Furthermore, we willexplain the kind of correspondence between editsand turns we are interested in.Edits To capture a fine-grained picture ofchanges to Wikipedia article pages, we rely on thenotion of edits defined in our previous work (Dax-enberger and Gurevych, 2012).
Edits are coherentmodifications based on a pair of adjacent revisionsfrom Wikipedia article pages.
To calculate edits,a line-based diff comparison between the old re-vision and the new revision is made, followed byseveral post-processing steps.
Each pair of adja-cent revisions found in the edit history of an arti-cle consists of one or more edits, which describeeither inserted, deleted, changed or relocated text.Edits are associated with metadata from the revi-sion they belong to, this includes the comment (ifpresent), the user name and the time stamp.Turns Turns are segments from Wikipedia dis-cussion pages.
To segment discussion pages intoturns, we follow a procedure proposed by Fer-schke et al (2012).
With the help of the JavaWikipedia Library (Zesch et al, 2008), we ac-cess discussion pages from a database.
Discus-sion pages are then segmented into topics basedupon the structure of the page.
Individual turnsare retrieved from topics by considering the revi-sion history of the discussion page.
This proce-dure successfully segmented 94 % of all turns ina corpus from the Simple English Wikipedia (Fer-schke et al, 2012).
Along with each turn, we storethe name of its user, the time stamp, and the nameof the topic to which the turn belongs.Corresponding Edit-Turn-Pairs An edit-turn-pair is defined as a pair of an edit from a Wikipediaarticle?s revision history and a turn from the dis-cussion page bound to the same article.
If an arti-cle has no discussion page, there are no edit-turn-pairs for this article.A definition of correspondence is not straight-forward in the context of edit-turn-pairs.
Ferschkeet al (2012) suggest four types of explicit perfor-matives in their annotation scheme for dialog actsof Wikipedia turns.
Due to their performative na-ture, we assume that these dialog acts make theturn they belong to a good candidate for a cor-responding edit-turn-pair.
We therefore define anedit-turn-pair as corresponding, if: i) The turn isan explicit suggestion, recommendation or requestand the edit performs this suggestion, recommen-dation or request, ii) the turn is an explicit refer-ence or pointer and the edit adds or modifies thisreference or pointer, iii) the turn is a commitmentto an action in the future and the edit performs thisaction, and iv) the turn is a report of a performedaction and the edit performs this action.
We defineall edit-turn-pairs which do not conform to the up-per classification as non-corresponding.3 CorpusWith the help of Amazon Mechanical Turk1, wecrowdsourced annotations on a corpus of edit-turn-pairs from 26 random English Wikipedia ar-ticles in various thematic categories.
The searchspace for corresponding edit-turn-pairs is quitebig, as any edit to an article may correspond to anyturn from the article?s discussion page.
Assumingthat most edit-turn-pairs are non-corresponding,we expect a heavy imbalance in the class distribu-tion.
It was important to find a reasonable amountof corresponding edit-turn-pairs before the actualannotation could take place, as we needed a cer-tain amount of positive seeds to keep turkers fromsimply labeling pairs as non-corresponding all thetime.
In the following, we explain the step-by-stepapproach we chose to create a suitable corpus forthe annotation study.Filtering We applied various filters to avoid an-notating trivial content.
Based on an automaticclassification using the model presented in our pre-vious work (Daxenberger and Gurevych, 2013),we excluded edits classified as Vandalism, Revertor Other.
Furthermore, we removed all edits whichare part of a revision created by bots, based on theWikimedia user group2scheme.
To keep the classimbalance within reasonable margins, we limitedthe time span between edits and turns to 86,0001www.mturk.com2http://meta.wikimedia.org/wiki/User_classes188seconds (about 24 hours).
The result is a set of13,331 edit-turn-pairs, referred to as ETP-all.Preliminary Annotation Study From ETP-all,a set of 262 edit-turn-pairs have been annotatedas corresponding as part of a preliminary annota-tion study with one human annotator.
This step isintended to make sure that we have a substantialnumber of corresponding pairs in the data for thefinal annotation study.
However, we still expecta certain amount of non-corresponding edit-turn-pairs in this data, as the annotator judged the cor-respondence based on the entire revision and notthe individual edit.
We refer to this 262 edit-turn-pairs as ETP-unconfirmed.Mechanical Turk Annotation Study Finally,for the Mechanical Turk annotation study, we se-lected 500 random edit-turn-pairs from ETP-allexcluding ETP-unconfirmed.
Among these, weexpect to find mostly non-corresponding pairs.From ETP-unconfirmed, we selected 250 ran-dom edit-turn-pairs.
The resulting 750 pairs haveeach been annotated by five turkers.
The turk-ers were presented the turn text, the turn topicname, the edit in its context, and the edit comment(if present).
The context of an edit is defined asone preceding and one following paragraph of theedited paragraph.
Each edit-turn-pair could be la-beled as ?corresponding?, ?non-corresponding?
or?can?t tell?.
To select good turkers and to blockspammers, we carried out a pilot study on a smallportion of manually confirmed corresponding andnon-corresponding pairs, and required turkers topass a qualification test.The average pairwise percentage agreementover all pairs is 0.66.
This was calculated as1N?Ni=1?Cc=1vciC, where N = 750 is the overallnumber of annotated edit-turn-pairs, C =R2?R2isthe number of pairwise comparisons, R = 5 is thenumber of raters per edit-turn-pair, and vci= 1 if apair of raters c labeled edit-turn-pair i equally, and0 otherwise.
The moderate pairwise agreement re-flects the complexity of this task for non-experts.Gold Standard To rule out ambiguous cases,we created the Gold Standard corpus with the helpof majority voting.
We counted an edit-turn-pairas corresponding, if it was annotated as ?corre-sponding?
by least three out of five annotators,and likewise for non-corresponding pairs.
Further-more, we deleted 21 pairs for which the turn seg-?1 2-6 7-11 12-16 17-210204060time span in hours%ofpairscorresponding non-correspondingFigure 1: Percentage of (non-)corresponding edit-turn-pairs for various time intervals in ETP-gold.mentation algorithm clearly failed (e.g.
when theturn text was empty).
This resulted in 128 corre-sponding and 508 non-corresponsing pairs, or 636pairs in total.
We refer to this dataset as ETP-gold.To assess the reliability of these annotations, oneof the co-authors manually annotated a randomsubset of 100 edit-turn-pairs contained in ETP-gold as corresponding or non-corresponding.
Theinter-rater agreement between ETP-gold (major-ity votes over Mechanical Turk annotations) andour expert annotations on this subset is Cohen?s?
= .72.
We consider this agreement high enoughto draw conclusions from the annotations (Artsteinand Poesio, 2008).Obviously, this is a fairly small dataset whichdoes not cover a representative sample of articlesfrom the English Wikpedia.
However, given thehigh price for a new corresponding edit-turn-pair(due to the high class imbalance in random data),we consider it as a useful starting point for re-search on edit-turn-pairs in Wikipedia.
We makeETP-gold freely available.3As shown in Figure 1, more than 50% of allcorresponding edit-turn-pairs in ETP-gold occurwithin a time span of less than one hour.
In our24 hours search space, the probability to find acorresponding edit-turn-pair drops steeply for timespans of more than 6 hours.
We therefore expectto cover the vast majority of corresponding edit-turn-pairs within a search space of 24 hours.4 Machine Learning withEdit-Turn-PairsWe used DKPro TC (Daxenberger et al, 2014)to carry out the machine learning experiments onedit-turn-pairs.
For each edit, we stored both theedited paragraph and its context from the old re-vision as well as the edited paragraph and con-text from the new revision.
We used Apache3http://www.ukp.tu-darmstadt.de/data/edit-turn-pairs189OpenNLP4for the segmentation of edit and turntext.
Training and testing the classifier has beencarried out with the help of the Weka Data MiningSoftware (Hall et al, 2009).
We used the Swebleparser (Dohrn and Riehle, 2011) to remove Wikimarkup.4.1 FeaturesIn the following, we list the features extractedfrom preprocessed edits and turns.
The edit textis composed of any inserted, deleted or relocatedtext from both the old and the new revision.
Theedit context includes the edited paragraph and onepreceding and one following paragraph.
The turntext includes the entire text from the turn.Similarity between turn and edit text We pro-pose a number of features which are purely basedon the textual similarity between the text of theturn, and the edited text and context.
We used thecosine similarity, longest common subsequence,and word n-gram similarity measures.
Cosine sim-ilarity was applied on binary weighted term vec-tors (L2norm).
The word n-gram measure (Lyonet al, 2004) calculates a Jaccard similarity coeffi-cient on trigrams.
Similarity has been calculatedbetween i) the plain edit text and the turn text, ii)the edit and turn text after any wiki markup hasbeen removed, iii) the plain edit context and turntext, and iv) the edit context and turn text after anywiki markup has been removed.Based on metadata of edit and turn Several ofour features are based on metadata from both theedit and the turn.
We recorded whether the nameof the edit user and the turn user are equal, theabsolute time difference between the turn and theedit, and whether the edit occurred before the turn.Cosine similarity, longest common subsequence,and word n-gram similarity were also applied tomeasure the similarity between the edit commentand the turn text as well as the similarity betweenthe edit comment and the turn topic name.Based on either edit or turn Some features arebased on the edit or the turn alone and do not takeinto account the pair itself.
We recorded whetherthe edit is an insertion, deletion, modification orrelocation.
Furthermore, we measured the lengthof the edit text and the length of the turn text.
The1,000 most frequent uni-, bi- and trigrams from theturn text are represented as binary features.4http://opennlp.apache.orgBaseline R. Forest SVMAccuracy .799 ?.031 .866 ?.026?
.858 ?.027?F1mac.NaN .789 ?.032 .763 ?.033Precisionmac.NaN .794 ?.031 .791 ?.032Recallmac..500 ?.039 .785 ?.032?
.736 ?.034?F1non-corr..888 ?.025 .917 ?.021 .914 ?.022F1corr.NaN .661 ?.037 .602 ?.038Table 1: Classification results from a 10-foldcross-validation experiment on ETP-gold with95% confidence intervals.
Non-overlapping inter-vals w.r.t.
the majority baseline are marked by ?.4.2 Classification ExperimentsWe treat the automatic classification of edit-turn-pairs as a binary classification problem.
Given thesmall size of ETP-gold, we did not assign a fixedtrain/test split to the data.
For the same reason, wedid not further divide the data into train/test anddevelopment data.
Rather, hyperparameters wereoptimized using grid-search over multiple cross-validation experiments, aiming to maximize accu-racy.
To deal with the class imbalance problem,we applied cost-sensitive classification.
In corre-spondence with the distribution of class sizes inthe training data, the cost for false negatives wasset to 4, and for false positives to 1.
A reduction ofthe feature set as judged by a ?2ranker improvedthe results for both Random Forest as well as theSVM, so we limited our feature set to the 100 bestfeatures.In a 10-fold cross-validation experiment, wetested a Random Forest classifier (Breiman, 2001)and an SVM (Platt, 1998) with polynomial ker-nel.
Previous work (Ferschke et al, 2012; Bronnerand Monz, 2012) has shown that these algorithmswork well for edit and turn classification.
As base-line, we defined a majority class classifier, whichlabels all edit-turn-pairs as non-corresponding.4.3 Discussion and Error AnalysisThe classification results for the above configura-tion are displayed in Table 1.
Due to the highclass imbalance in the data, the majority classbaseline sets a challenging accuracy score of .80.Both classifiers performed significantly better thanthe baseline (non-overlapping confidence inter-vals, see Table 1).
With an overall macro-averagedF1 of .79, Random Forest yielded the best results,both with respect to precision as well as recall.The low F1 on corresponding pairs is likely dueto the small number of training examples.190To understand the mistakes of the classifier, wemanually assessed error patterns within the modelof the Random Forest classifier.
Some of the falsepositives (i.e.
non-corresponding pairs classifiedas corresponding) were caused by pairs where therevision (as judged by its comment or the edit con-text) is related to the turn text, however the specificedit in this pair is not.
This might happen, whensomebody corrects a spelling error in a paragraphthat is heavily disputed on the discussion page.Among the false negatives, we found errors causedby a missing direct textual overlap between editand turn text.
In these cases, the correspondencewas indicated only (if at all) by some relationshipbetween turn text and edit comment.5 Related WorkBesides the work by Ferschke et al (2012) whichis the basis for our turn segmentation, there areseveral studies dedicated to discourse structure inWikipedia.
Vi?egas et al (2007) propose 11 di-mensions to classify discussion page turns.
Themost frequent dimensions in their sample are re-quests for coordination and requests for informa-tion.
Both of these may be part of a correspondingedit-turn-pair, according to our definition in Sec-tion 2.
A subsequent study (Schneider et al, 2010)adds more dimensions, among these an explicit ca-tegory for references to article edits.
This dimen-sion accounts for roughly 5 to 10% of all turns.Kittur and Kraut (2008) analyze correspondencebetween article quality and activity on the discus-sion page.
Their study shows that both implicitcoordination (on the article itself) and explicit co-ordination (on the discussion page of the article)play important roles for the improvement of arti-cle quality.
In the present study, we have analyzedcases where explicit coordination lead to implicitcoordination and vice versa.Kaltenbrunner and Laniado (2012) analyze thedevelopment of discussion pages in Wikipediawith respect to time and compare dependences be-tween edit peaks in the revision history of the arti-cle itself and the respective discussion page.
Theyfind that the development of a discussion page isoften bound to the topic of the article, i.e.
arti-cles on time-specific topics such as events growmuch faster than discussions about timeless, ency-clopedic content.
Furthermore, they observed thatthe edit peaks in articles and their discussion pagesare mostly independent.
This partially explains thehigh number of non-corresponding edit-turn-pairsand the consequent class imbalance.While there are several studies which analyzethe high-level relationship between discussion andedit activity in Wikipedia articles, very few haveinvestigated the correspondence between edits andturns on the textual level.
Among the latter, Fer-ron and Massa (2014) analyze 88 articles and theirdiscussion pages related to traumatic events.
Inparticular, they find a correlation between the arti-cle edits and their discussions around the anniver-saries of the events.6 ConclusionThe novelty of this paper is a computational analy-sis of the relationship between the edit history andthe discussion of a Wikipedia article.
As far aswe are aware, this is the first study to automati-cally analyze this relationship involving the tex-tual content of edits and turns.
Based on the typesof turn and edit in an edit-turn-pair, we have oper-ationalized the notion of corresponding and non-corresponding edit-turn-pairs.
The basic assump-tion is that in a corresponding pair, the turn con-tains an explicit performative and the edit corre-sponds to this performative.
We have presenteda machine learning system to automatically detectcorresponding edit-turn-pairs.
To test this system,we manually annotated a corpus of correspondingand non-corresponding edit-turn-pairs.
Trainedand tested on this data, our system shows a sig-nificant improvement over the baseline.With regard to future work, an extension of themanually annotated corpus is the most importantissue.
Our classifier can be used to bootstrap theannotation of additional edit-turn-pairs.AcknowledgmentsThe authors would like to give special thanks toViswanathan Arunachalam and Dat Quoc Nguyen,who carried out initial experiments and the pre-liminary annotation study, and to Emily Jamison,who set up the Mechanical Turk task.
This workhas been supported by the Volkswagen Founda-tion as part of the Lichtenberg-Professorship Pro-gram under grant No.
I/82806, and by the Hessianresearch excellence program ?Landes-Offensivezur Entwicklung Wissenschaftlich-?okonomischerExzellenz?
(LOEWE) as part of the research cen-ter ?Digital Humanities?.
We thank the anony-mous reviewers for their helpful suggestions.191ReferencesOfer Arazy, Ian Gellatly, Soobaek Jang, and RaymondPatterson.
2009.
Wiki deployment in corporatesettings.
IEEE Technology and Society Magazine,28(2):57?64.Ron Artstein and Massimo Poesio.
2008.
Inter-CoderAgreement for Computational Linguistics.
Compu-tational Linguistics, 34(4):555?596.Leo Breiman.
2001.
Random Forests.
Machine Learn-ing, 45(1):5?32.Amit Bronner and Christof Monz.
2012.
User EditsClassification Using Document Revision Histories.In European Chapter of the Association for Compu-tational Linguistics (EACL 2012), pages 356?366,Avignon, France.Johannes Daxenberger and Iryna Gurevych.
2012.
ACorpus-Based Study of Edit Categories in Featuredand Non-Featured Wikipedia Articles.
In Proceed-ings of the 24th International Conference on Com-putational Linguistics, pages 711?726, Mumbai, In-dia.Johannes Daxenberger and Iryna Gurevych.
2013.Automatically Classifying Edit Categories inWikipedia Revisions.
In Proceedings of the Con-ference on Empirical Methods in Natural LanguageProcessing, pages 578?589, Seattle, WA, USA.Johannes Daxenberger, Oliver Ferschke, IrynaGurevych, and Torsten Zesch.
2014.
DKPro TC:A Java-based Framework for Supervised LearningExperiments on Textual Data.
In Proceedings ofthe 52nd Annual Meeting of the Association forComputational Linguistics.
System Demonstrations,page (to appear), Baltimore, MD, USA.Hannes Dohrn and Dirk Riehle.
2011.
Design and im-plementation of the Sweble Wikitext parser.
In Pro-ceedings of the International Symposium on Wikisand Open Collaboration (WikiSym ?11), pages 72?81, Mountain View, CA, USA.Gijsbert Erkens, Jos Jaspers, Maaike Prangsma, andGellof Kanselaar.
2005.
Coordination processes incomputer supported collaborative writing.
Comput-ers in Human Behavior, 21(3):463?486.Michela Ferron and Paolo Massa.
2014.
Beyond theencyclopedia: Collective memories in Wikipedia.Memory Studies, 7(1):22?45.Oliver Ferschke, Iryna Gurevych, and Yevgen Chebo-tar.
2012.
Behind the Article: Recognizing DialogActs in Wikipedia Talk Pages.
In Proceedings of the13th Conference of the European Chapter of the As-sociation for Computational Linguistics, pages 777?786, Avignon, France.Mark Hall, Eibe Frank, Geoffrey Holmes, BernhardPfahringer, Peter Reutemann, and Ian Witten.
2009.The WEKA Data Mining Software: An Update.SIGKDD Explorations, 11(1):10?18.Andreas Kaltenbrunner and David Laniado.
2012.There is No Deadline - Time Evolution of WikipediaDiscussions.
In Proceedings of the Annual Interna-tional Symposium on Wikis and Open Collaboration,Linz, Austria.Aniket Kittur and Robert E. Kraut.
2008.
Harnessingthe wisdom of crowds in wikipedia: quality throughcoordination.
In Proceedings of the 2008 ACM Con-ference on Computer Supported Cooperative Work,pages 37?46, San Diego, CA, USA.C.
Lyon, R. Barrett, and J. Malcolm.
2004.
A theoret-ical basis to the automated detection of copying be-tween texts, and its practical implementation in theFerret plagiarism and collusion detector.
In Plagia-rism: Prevention, Practice and Policy Conference,Newcastle, UK.John C. Platt.
1998.
Fast training of support vec-tor machines using sequential minimal optimization.In Bernhard Sch?olkopf, Christopher J. C. Burges,and Alexander J. Smola, editors, Advances in KernelMethods: Support Vector Learning, pages 185?208.MIT Press.Jodi Schneider, Alexandre Passant, and John G. Bres-lin.
2010.
A Content Analysis: How WikipediaTalk Pages Are Used.
In Proceedings of the 2nd In-ternational Conference of Web Science, pages 1?7,Raleigh, NC, USA.Fernanda B. Vi?egas, Martin Wattenberg, Jesse Kriss,and Frank Ham.
2007.
Talk Before You Type: Co-ordination in Wikipedia.
In Proceedings of the 40thAnnual Hawaii International Conference on SystemSciences, pages 78?78, Big Island, HI, USA.Torsten Zesch, Christof M?uller, and Iryna Gurevych.2008.
Extracting Lexical Semantic Knowledgefrom Wikipedia and Wiktionary.
In Proceedings ofthe 6th International Conference on Language Re-sources and Evaluation, Marrakech, Morocco.192
