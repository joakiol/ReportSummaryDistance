Proceedings of the 6th Workshop on Statistical Machine Translation, pages 207?216,Edinburgh, Scotland, UK, July 30?31, 2011. c?2011 Association for Computational LinguisticsA Minimally Supervised Approach for Detecting and Ranking DocumentTranslation PairsKriste Krstovski David A. SmithDepartment of Computer Science  Department of Computer ScienceUniversity of Massachusetts Amherst University of Massachusetts AmherstAmherst, MA 01003, USA Amherst, MA 01003, USAkriste@cs.umass.edu dasmith@cs.umass.eduAbstractWe describe an approach for generating aranked list of candidate document transla-tion pairs without the use of bilingual dic-tionary or machine translation system.
Wedeveloped this approach as an initial, filter-ing step, for extracting parallel text fromlarge, multilingual?but non-parallel?corpora.
We represent bilingual documentsin a vector space whose basis vectors arethe overlapping tokens found in both lan-guages of the collection.
Using this repre-sentation, weighted by tf?idf, we computecosine document similarity to create aranked list of candidate document transla-tion pairs.
Unlike cross-language informa-tion retrieval, where a ranked list in thetarget language is evaluated for each sourcequery, we are interested in, and evaluate,the more difficult task of finding translateddocument pairs.
We first perform a feasi-bility study of our approach on parallel col-lections in multiple languages, representingmultiple language families and scripts.
Theapproach is then applied to a large bilingualcollection of around 800k books.
To avoidthe computational cost of )( 2nO documentpair comparisons, we employ locality sen-sitive hashing (LSH) approximation algo-rithm for cosine similarity, which reducesour time complexity to )log( nnO .1 IntroductionA dearth of parallel data has been, and still is, amajor problem for developing highly reliable sta-tistical machine translation systems in many lan-guages and domains.
There have been manyproposed approaches for alleviating this problemby utilizing techniques for creating and extractingparallel documents, sentences or phrases fromcomparable bilingual data available on the openweb (Resnik and Smith, 2003), such as Wikipediaarticles (Smith et.
al, 2010), to name a few, orthrough digitized archives from various sources(Zhao and Vogel, 2002), (Munteanu and Marcu,2005).In general, in the process of utilizing comparablecorpora to obtain sentence-aligned bilingual text,the first step involves performing initial filteringwhere text entities from both language collectionsare compared to each other and based on compari-son score they are matched and grouped as poten-tial translation candidate pairs.
After this initialstep, text entity pairs or tuples are further analyzedin order to extract parallel sentence pairs.
In thispaper we only focus on this initial step.
We presenta novel exploration of approaches that retrieve ac-tual document translation pairs without the use ofany bilingual resources such as lexicons or sen-tence aligned bitext.Rather than solving separate retrieval or translationproblems for each source language document, weretrieve translation pairs from the space of all pos-sible bilingual document pairs.
Most machine207translation (MT) and information retrieval (IR)systems rely on conditional probabilities; in con-trast, we require comparable scores or probabilitiesover all document pairs.
To avoid directly comput-ing the similarity of all pairs, we use a randomizedapproximation algorithm based on locality sensi-tive hashing (LSH).For this joint approach, we represent each docu-ment in both languages using an n-dimensionalfeature vector template which consists of the set ofintersecting words which are found across alldocuments in both language collections.
For eachdimension i.e.
word, in the feature vector templatewe calculate tf?idf score for the given document.Unlike other approaches, where documents or theirword representations are first translated from for-eign language to English using bilingual dictionary(Fung and Cheung, 2004), (Munteanu and Marcu,2005) and (Uszkoreit et.
al., 2010) in our approachwe don?t utilize any existing MT type artifact.
Inother words, for a given language pair we don?t usetranslation lexicon by training an existing statisti-cal machine translation system using sentencealigned parallel bilingual data in the same languageor existing translation lexicon.
Earlier work doneby Enright and Kondrak (2007) uses only hapaxwords to represent and rank (based on the overlapnumber) translation documents pair in a parallelbilingual collection which is an easier task toevaluation due to the presence of a one-to-onematching among the bilingual documents.
Mostrecently, Patry and Langlais (2011) show an im-provement over this method by using an IR systemto first retrieve translation document candidatesand then identify translation document pairs bytraining a classifier.We start off by giving detailed explanation of theabove mentioned data representation.
We then testthe feasibility of our approach using aligned paral-lel document data from three different bilingualcollections in several languages and writing sys-tems.
Results from these tests are given in section3.
The goal of developing our approach was to util-ize it as an initial filtering step in developing paral-lel corpora from large, multilingual collections,such as the collection of more than 800K Englishand German books we describe in section 4.
Sincewe start with no information on the possible trans-lation pairs in our large collection and in order toverify the potential of our method, we first showresults on retrieving 17 known parallel book pairsembedded in a small randomly selected subset of1K books (section 4.1).
Since performing cosinesimilarity across all document pairs is computa-tionally expensive with time complexity of)( 2nO we utilize the LSH based approximationalgorithm for the cosine similarity measurementbased on the work by Ravichandran et.
al (2005).A brief overview of this approach is given in Sec-tion 5, which is followed by our implementationresults explained and analyzed in section 6.
Toconclude the paper, we give a brief outlook on fu-ture work.2 Document RepresentationIn Figure 1, we depict the process that we use torepresent documents from bilingual collections invector space and perform similarity measurements.We start by computing a word frequency count foreach of the documents in our collection and creat-ing a word frequency list.
For each language, wetake a union of the words in each document?s fre-quency list to construct a global word list for thegiven language.
The two global word lists are thenintersected, and a list of overlapping words is cre-ated.
From the initial list of overlapping words inboth languages, we remove stop words by usingstop word lists (words with high document fre-quency).
The space-separated tokens extracted inthis process are not necessarily words in the lin-guistic sense; therefore, we further refine the over-lapping word list by removing tokens that containnon-alphanumeric characters.
We make one excep-tion for tokens (such as might appear in a time/dateformat) that contain hyphens, backslashes, apos-trophes, and periods so long as these characters donot occur at the beginning or at the end of the to-ken.We call this list of overlapping tokens a featurevector template, where each token in the list is onefeature.
Using this feature vector template we goback and represent each document in the bilingualcollection using the template vector by computingthe tf?idf value for each token in the template vec-tor over each particular document.
Now that wehave the original documents from both languagesrepresented in a language-independent space, wecompute vector similarity across all documentpairs in order to come up with a single ranked list.We talk more in detail about the similarity metrics208that we have considered and decided to use in thefollowing section.Figure 1.
Process of creating and representing eachdocument of a bilingual collection in an independ-ent vector space.3 Motivational Experiments3.1 Evaluation CollectionsWe start off by evaluating the above proposed ap-proach of determining candidate document transla-tion pairs using three different parallel collections:Europarl, created by Koehn (2005), UN ArabicEnglish Parallel Text (LDC2004E13) and the Ara-bic News Translation Part 1 (LDC2004T17).
Thepurposes of first testing our approach using theEuroparl corpus were twofold: This collection con-tains parallel documents (sessions of the EuropeanParliament) that are further aligned at the speechand sentence level, which allows us to test align-ment accuracy at several levels of granularity.
Sec-ond, this collection contains parallel data fromdifferent groups of languages (Germanic, Ro-mance, Slavic, Hellenic, etc.)
and therefore is use-ful to observe the performance of our approachacross different language families, which in turnare important to observe the difference in the cog-nate rates and the size of the overlapping words.
Inaddition to the Europarl corpus we use the twoEnglish-Arabic parallel collections to test our ap-proach across various alphabets (Arabic in additionto the Latin, Greek and Cyrillic found in the Eu-roparl collection).
Shown in Table 1 are basic sta-tistics for all 3 corpora on the language pairsconsidered.
We give min, max and median valuesover the number of words in each document.Collection # doc.
Pairs Lang.
Min Max  MedianEn 92 109030 46800.5Europarlen-de 654 De 95 99753 43161.0En 4872 59284 10706.5Europarlen-bg 430 Bg 4771 56907 10167.0En 92 109793 46790.5Europarlen-es 642 Es 104 114770 48989.0En 92 93886 21290.0Europarlen-gr 412 Gr 103 93304 21122.0En 66 47784 691.5Newswireen-ar 230 Ar 62 34272 560.0En 17672 71594 23027.0UN en-ar 430 Ar 15478 62448 19682.0Table 1.
Document length statistics over 6 ParallelCollections.From the Europarl collection we sentence alignedsessions in the following four language pairs wherethe English language is the source language: Eng-lish-German, English-Spanish, English-Bulgarianand English-Greek.
The foreign language in allfour language pairs is selected from a differentlanguage group (Germanic, Romanic, Slavic), withGreek being a more isolated branch.
For the Arabiclanguage we used two parallel document collec-tions in different domains ?
newswire and docu-ments published by the United Nations.
TheNewswire parallel collection consisted of 1526news stories which we combined based on thenews story publication date and obtained 230 par-allel documents.
The purpose of combining thenews articles is to increase the number of wordspresent in each document since the original size of209the news articles was not at a level to be treated asa document as in the case of the remaining twocollections.
The UN parallel collection consists of34,575 document pairs.3.2 Similarity MetricsWe considered five similarity metrics proposed atone time or another for vector space models in IR:Cosine (shown below), Dice, Product, Jaccard andEuclidean.?
?
?22iiiiyxyx                        (1)Document similarity using the cosine metric relieson the angle between the vector representationsand it is length invariant.
The Dice metric relies onthe number of common tokens between the twodocuments.
Euclidean computes the similarity as apoint distance between the two vector representa-tions and is not normalized by the vector lengthwhich does not make it vector invariant.
Jaccarddistance is the ratio of the intersection and the un-ion of the two vector representations while theproduct coefficient is simply the inner product ofthe two vectors.
While there is no clear evidenceacross the literature whether one similarity metricis more useful across a range of tasks compared toanother, the cosine similarity metric is mostly pre-ferred.
Shown in Figure 2 are the precision vs. re-call plots of the above similarity measurementswhen used with our method.
Tests were done onour set of 654 English-German sessions from theEuroparl collections.
To test the impact of thedocument length on the performance of the metricwe performed two types of tests across all 5 met-rics.
In the first type we performed similarityanalysis on the full document length (marked as100%) and on the final 10% of each document(marked as 10%).
We deliberately omitted the toppart of the document to avoid any inadvertent in-clusion of session date, topic, title, etc.
(As itturned out, this was not a problem in our data.)
Weperform similarity measurements across all docu-ment pairs, and we generate a single ranked list.
Ascan be seen from the plot, all five metrics yieldbetter performance when all words in documentsare considered compared to only considering 10%.The performance ranking of all five metrics wasidentical on both versions of the document set.Even though depicted in the above plot, the Jac-card distance performed pretty much the same asthe Dice distance and therefore there is no visibledifference between the two.
While on the 10% ver-sion of the collection, the Euclidean distance hasthe worst precision, it could still be explored as ametric to obtain document translation pairs withthe original collection with a modest to moderaterecall range for P=1.
The Jaccard distance alongwith the Dice distance yield the highest precisionvalues across all recall values but they achieve thesame recall range for P=1 as the Cosine metric.Since we are only interested in top-N documentpairs that have P=1 and furthermore there are ap-proximate algorithms for the Cosine similaritymetrics we decided to further utilize this metric.The same metric has been previously used in de-termining potential translation candidates on sen-tence level by Munteanu and Marcu (2005) and inour case we are extending it to perform pair-wisedocument similarity.Figure 2.
Precision vs. recall plot using varioussimilarity measurements on the Europarl English-German collection.When run on the same English-German collection,Enright?s and Kondrak?s (2007) approach achievesmean reciprocal rank (MRR) of 0.989 when usingdocument specific hapax words and MRR=0.795when using collection specific hapax words.
Withthe above explained approach we obtainMRR=0.995.2103.3 Post Filtering ApproachesTo further improve the precision of our approachwe tested out two types of filtering the initial re-sults.
Since we threat documents as ?bag of words?and since the Cosine metric uses the angle betweenthe vector representations and is length invariantthere may be instances of source documents thatwould yield high cosine coefficients over all targetdocuments.
In these instances, multiple documentpairs with the same source document may beranked high.
To alleviate this problem, we considertwo types of filtering the initial results.
We go overthe single ranked list and we only keep the top fivedocument pairs for a given source document, thusintroducing ?diversity?
in the ranked list.
The sec-ond filter is motivated by the basic assumptionused in the machine translation field that the lengthof the target sentence is in a given length range ofthe source sentence.
We extend this assumption ona document level and we filter out all documentpairs from the ranked list that are not in the ?20%range of the source document length.
Both of theabove values were selected based on empiricalevidence without detailed explanation.
Shown inFigure 3 are the effects of these two simple filter-ing techniques.Figure 3.
Diversity and length based filtering ef-fects on the English-German Europarl collection.Compared to the diversity filter, the length basedfilter yields better gain in precision while a combi-nation of both methods achieves the highest recallrange for P=1.3.4 Target Languages and Writing SystemsShown in Figure 4 are the precision/recall resultson all six collections explained in Section 3.1.Post-filtering steps explained in the previous sec-tion were not utilized on these results.
Our ap-proach yields best precision on the Arabic NewsTranslation Part 1 collection while the worst per-formance is on the UN Arabic English ParallelText.
While the performance on the English-German and English-Spanish collections is some-what the same, out of all 4 Europarl collections weachieve best results on the Greek collection andworst results on the Bulgarian target language.Figure 4.
Precision vs. recall on 5 different lan-guage pairs using cosine similarity distance metric.In Table 2, we give the vector template length foreach collection.Collection # of overlapping tokensEuroparl en-de 37785Europarl en-es 36476Europarl en-bg 29360Europarl en-gr 17220UN en-ar 3945Newswire en-ar 1262Table 2.
Number of overlapping words (vectortemplate length) in the six parallel collections.Unsurprisingly, due to the difference in script andlanguage family, the feature vector templates forthe English-Arabic collections have the smallestlengths.211Shown in Figure 5 are effects of the trivial diver-sity and length based filtering on the above preci-sion vs. recall results.
Bulgarian has improvesubstantially and so has the UN Arabic, but recallon the Arabic newswire is truncated on reachingP=0.4.Figure 5.
Precision vs. recall on 6 collections usingdiv=5 and length filtering with ?20%.3.5 Randomly Selected DocumentsWhile useful to evaluate the feasibility of our ap-proach, the previous parallel bilingual collectionsare unrealistic because there is, by the corpus?
de-sign, a translation for each document.
To observethe performance on a bilingual document collec-tion where there is no a priori information on trans-lation pairs we created ten random subsets from theEuroparl English-German collection.
These subsetswere created by randomly selecting 50% (328documents) of the English and 5% (33 documents)of the German documents for each subset collec-tion.
Shown in  is interpolated average precisionover the ten subsets.
The Mean Average Precision(MAP) obtained was 0.986.4 Multilingual Book CollectionOur multilingual book collection consists ofaround 800k books in German and English lan-guages.
It is a subset of a larger Internet Archive1collection of books in over 200 languages.
Thewhole collection consists of OCRed books incor-porating a small number of human transcribed1 http://www.archive.org/details/texts/books from Project Gutenberg2.
The collection wasinitially annotated with author and language infor-mation using the existing database obtained fromthe Internet Archive.
This database originally con-tained incorrect language metadata.
Using thefreely available language identifier TextCat (Cav-nar and Trenkle, 2005) we tagged the whole bookcollection and extracted 705692 English and 96752German books.
This process had the additionalbenefit of cleaning the German book collection ofbooks written in the Fraktur script due to the badOCR output.
(Incredibly noisy OCR was simplyrecognized as ?not German?
by the character n-gram models.)
Shown in Table 3 are word lengthstatistics over the books in the collection.Language # of books# of uniq.words Min MaxMe-dianGerman 96752 5030095 33 2372278 109820English 705692 20001702 37 5155032 75016Table 3.
Bilingual book collection statistics.Figure 6.
Average precision interpolated at 11points over ten randomly created subsets consistingof 50% English and 10% German documents fromthe English-German Europarl collection.4.1 Development SetMoving onto our book collection, we start off byevaluating the method on a smaller randomly se-lected subset of 1000 books in both languages.Since it is not feasible to perform a full recall2 http://www.gutenberg.org212evaluation on the whole book set we include 17known book translation pairs in the 1000 randombilingual book collection.
The 17 book translationpairs were constructed by hand by running a previ-sion version of our full algorithm and indentifyingtranslation pairs.
Shown in Figure 7 is the preci-sion vs. recall plot on the 17 book pairs.
As in thecase of the 10 randomly selected Europarl subsets,we also performed diversity and length based fil-tering of the initial results prior to computing pre-cision vs. recall.Figure 7.
Precision vs. recall running our methodon a 1000 randomly selected bilingual book subsetwith 17 book translation pairs inserted.5 LSH Based Approximate Algorithm forCosine SimilarityDue to the collection size and length of each bookit is infeasible to perform cosine similarity over allpossible book pairs, i.e.
approximately 68.2B com-parisons.
This brute force approach has time com-plexity of )( 2knO  where n is the number of booksin the collection and k is the vector templatelength.
We therefore employ a fast cosine similar-ity calculation approach developed by Charikar(2002) and utilized by Ravichandran et.
al (2005)for creating similarity lists of nouns in  large col-lection.
In this section we give a summary of thisapproach and explain how it was applied for ourtask.Locality Sensitive Hashing (LSH), initially intro-duced by Idyik and Motwani (1998), is used forfinding approximate nearest neighbors in high di-mensional spaces.
In general, their approachhashes query vectors into bins where the probabil-ity of collision is higher due to the fact that vectorsin the same bin share the same locality.
Their ap-proach reduces the approximate nearest neighborproblem on the Hamming space.Charikar expanded this approach and showed thatthe probability of collision of hashed vectors forappropriately chosen hash function h is related tothe angle between the vectors as:??
),(1)]()(Pr[ yxyhxh ???
(2)This is closely related to the cosine function.
Fromthe above equation we thus have:})])()(Pr[1cos{()),(cos( ??
yhxhyx ???
(3)Charikar uses a hash function based on randomhyperplanes and creates a fingerprint for eachoriginal vector using the following approach:Generate d, k-dimensional random vectors from astandard normal (Gaussian) distribution:{ 1r , 2r ,?..
}dr .
For each original vector x use thefollowing hash function to generate a fingerprint ofd bits:????????
?
?0100)(iiiir rxifrxifxh   (4)By doing this we represent each vector in ouroriginal vector set into a bit stream that reduces ourvector space representation from k to d dimensions,where d << k. Having bit stream as our data repre-sentation, the probability of hash collision, i.e.
theprobability of two vectors being equal)]()(Pr[ yhxh ?
, is equivalent to the Hammingdistance between the two bit streams:Pr[h(x) ?
h(y)] ?
HDd   (5)Therefore, performing fast cosine similarity boilsdown to finding the Hamming distance betweenthe two bit streams.Now that we have an approximate method of find-ing the cosine similarity between two vectors, weuse Ravichandran?s (2005) formulation of the fast213search algorithm developed by Charikar, which inturn used Indyk and Motwani?s orginal PLEB(Point Location in Equal Balls) algorithm as astarting point.
The steps of this algorithm are out-lined in the next subsection.
For more detailed ex-planation of this algorithm the reader is referred toSection 5 of Charikar?s work (2002).5.1 Nearest Neighbor Search AlgorithmWe now outline the steps of the fast search algo-rithm.
For more detailed explanation of the algo-rithmic implementation users are referred toSection 3 of Ravichandran?s work (2005):?
For all m documents represented in the vectorspace using the template vector, compute LSHd-bit signature using the formula given in (4).?
Generate q permutations of length d.?
For each of the q permutations, generate mpermuted LSH signatures.?
For each of the q permutation bins,lexicographically sort the m permutated bitvectors.?
For each lexicographically sorted bin, go overthe m bit streams and compute the Hammingdistance between the current bit stream and thesubsequent b bit streams in the sorted list start-ing from the top.?
If the Hamming distance is above a previouslyset threshold, output the book pair along withthe Hamming distance result.Compared to Ravichandran?s algorithm for creat-ing noun similarity lists, in our approach we dealwith two distinct groups of documents: those ineach language.
We start off by creating a single listof documents and we represent each document inthis list using the LSH based fingerprint.
We thengenerate q permutation vector bins, and welexicographically sort each bin.
In our beam searchapproach, since we have documents in two differ-ent languages, we only consider documents thathave a different language.
The results of the beamsearch for each bin are then combined.
Since ineach beam the same permutation is performed overall fingerprints, the Hamming distance across allbins for a given document pair would be the same.Therefore after combining the results we removeduplicate document pairs and sort by the Hammingdistance to obtain the final ranked list.
The run-time of this algorithm is dominated by theO(qn logn)  step of sorting the permuted bit vec-tors in each of the bins.6 Detecting and Ranking Book Transla-tion Pairs in a Large Book CollectionUsing the previously explained method we proc-essed the large book collection by first computingthe vector template.
For the large book collection,the vector template size k, i.e.
the number of over-lapping tokens obtained, was 638,005.
After re-moving stop words and unwanted tokens(explained in Section 2) the template vector lengthwas reduced to 563,053.
Shown in Table 4 are sta-tistics over the number of vector template tokenswhose tf?idf values are greater than zero across thetwo languages.Language Min Max MedianGerman 7 7212 229English 11 6637 585Table 4.
Statistics over the number of tokens in thevector representation of each book whose tf?idf aregreater than zero.Once processed and represented in vector space,we proceed with computing the approximate co-sine similarity across the bilingual collection.
Weprecompute the Hamming distance based on a co-sine similarity threshold of 0.18 which is equiva-lent to different Hamming distance valuesdepending on the length of the LSH based finger-print.
For the book collection we experimentedwith 4 different sets of values for the number ofhyperplane based hash functions, the number ofpermutations and the length of the beam search.For each of these parameters in our setup we cre-ated ranked lists as explained in Section 5.1.
Wethen went over the top 300 book pairs in each listand annotated the correct book translations.
Basedon the human annotation we then computed aver-age precision over the ranked list.
Shown in Table5 are the results for LSH based fingerprint of sized=500.
Due to the randomness introduced by thepermutations, there is not a monotonic increase inaccuracy, but in general more permutations andwider beams show substantial improvements.214q\b AP Time [hrs]b=25 0.307 24.9b=50 0.213 41.1q=25b=100 0.280 67.2b=25 0.488 99.6b=50 0.388 164.4q=100b=100 0.461 269.1b=25 0.357 199.2b=50 0.412 328.8q=200b=100 0.455 538.2b=25 0.489 498.1b=50 0.490 822.0q=500b=100 0.493 1345.5Table 5.
Average precision on the large English-German book collection across various parametersof the LSH based search algorithm.For the above given results for d=500, we calcu-lated an estimated time that it would take to per-form the fast cosine similarity if the algorithmwere to be run in serial fashion.
Shown in Figure 8is a scatter plot of the time vs. the average preci-sion obtained.Figure 8.
Estimated serial time vs. average preci-sion with d=500 dimensional LSH based finger-prints.In summary, while increasing the number of per-mutations and the beam search over different val-ues increases the average precision the time costrequired is significantly larger especially for in-creasing the number of permutations.7 Future WorkIn the future we plan on experimenting with largerdimensionality d for the LSH fingerprint, the num-ber of random permutations q i.e.
bins and thebeam search parameter b.
In order to further im-prove the average precision we would also like toexperiment with different longest common subse-quence (LCS) based approaches for re-ranking thecosine based ranked lists.
Furthermore, we plan onexploring more accurate joint models of transla-tion.
It would also be interesting to observe theperformance of our system on other language pairs,such as English-Chinese and languages withresource-poor bilingual collections.8 ConclusionThis paper presents and evaluates a new approachto detecting and ranking document translationpairs.
We showed that this simple method achieveshigh precision vs. recall on parallel bilingual col-lections where there is one document translationfor each source document.
We also showed that themethod is capable of detecting document transla-tions in random subsets where no known documenttranslation information is available.
Using an ap-proximation algorithm for cosine similarity, weshowed that this method is useful for detecting andranking document translation pairs in a largebilingual collection with hundreds of thousands ofbooks and billions of possible book pairs.
Thismethod is conceivable to be used for other lan-guages and collection genres and also on othertypes of translation methods such as transliteration.While in some instances other simple methods ofaligning the dictionaries might be needed, as in thecase of the Chinese language.AcknowledgmentsThis work was supported in part by the Center forIntelligent Information Retrieval and in part byNSF grant #IIS-0910884.
Any opinions, findingsand conclusions or recommendations expressed inthis material are the authors' and do not necessarilyreflect those of the sponsor.ReferencesAlexandre Patry and Philippe Langlais, 2011.
Identify-ing Parallel Documents from a Large Bilingual Col-lection of Texts: Application to Parallel Article215Extraction in Wikipedia.
Proceedings of the 4thWorkshop on Building and Using Comparable Cor-pora, pages 87-95, Portland, OR.Bing Zhao and Stephan Vogel.
2002.
Adaptive ParallelSentences Mining from Web Bilingual News Collec-tion.
Proceedings of IEEE International Conferenceon Data Mining, pages 745-750.
Maebashi City, Ja-pan.Deepak Ravichandran, Patrick Pantel, and EduardHovy.
2005.
Randomized Algorithms and NLP: Us-ing Locality Sensitive Hash Function for High SpeedNoun Clustering.
Proceedings of the 43rd AnnualMeeting on Association for Computational Linguis-tics, pages 622?629, Morristown, NJ.Dragos Stefan Munteanu and Daniel Marcu.
2005.
Im-proving Machine Translation Performance by Ex-ploiting Non-Parallel Corpora.
ComputationalLinguistics, 31(4): 477-504.Jacob Uszkoreit, Jay Ponte, Ashok Popat and MosheDubiner, 2010.
Large Scale Parallel Document Min-ing for Machine Translation.
Proceedings of the 23rdInternational Conference on Computational Linguis-tics (Coling 2010), pp.
1101-1109.
Beijing, China.Jason R. Smith, Chris Quirk, and Kristina Toutanova,2010.
Extracting Parallel Sentences from Compara-ble Corpora using Document Level Alignment, Pro-ceedings of Human Language Technologies: The2010 Annual Conference of the North AmericanChapter of the ACL (HLT NAACL?10), Los Ange-les, California.Jessica Enright and Grzegorz Kondrak 2007.
A FastMethod for Parallel Document Identification, Pro-ceedings of Human Language Technologies: TheConference of the North American Chapter of theAssociation for Computational Linguistics (HLT-NAACL?07) companion volume, pages 29-32, Roch-ester, NY.Matthew Snover, Bonnie Dorr, and Richard Schwartz.2008.
Language and Translation Model Adaptationusing Comparable Corpora.
Proceedings of Confer-ence on Empirical Methods in Natural LanguageProcessing (EMNLP?08), pages 856?865, Honolulu,HI.Moses S. Charikar.
2002.
Similarity estimation tech-niques from rounding algorithms.
In Proceedings ofthe thiry-fourth annual ACM symposium on Theoryof computing (STOC?02), pages 380?388, NewYork, NY.Pascale Fung and Percy Cheung.
2004.
Mining Very-Non-Parallel Corpora: Parallel Sentence and LexiconExtraction via Bootstrapping and EM.
In Proceedingsof Conference on Empirical Methods in Natural Lan-guage Processing (EMNLP?04), Barcelona, Spain.Philip Resnik and Noah Smith.
2003.
The Web as aParallel Corpus.
Computational Linguistics, 29(3):349-380.Philipp Koehn, 2005.
Europarl: A Parallel Corpus forStatistical Machine Translation.
MT Summit 2005.Phuket, Thailand.Piotr Indyk and Rajeev Motwani.
1998.
Approximatenearest neighbors: towards removing the curse of di-mensionality.
In Proceedings of the thirtieth annualACM symposium on Theory of computing (STOC?98), pages 604?613, New York, NY.William B. Cavnar and John M. Trenkle.
1994.
N-Gram-Based Text Categorization.
Proceedings of theThird Annual Symposium on Document Analysisand Information Retrieval, pages 161-175, Las Ve-gas, NV.216
