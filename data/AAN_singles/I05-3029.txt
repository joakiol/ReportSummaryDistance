Maximal Match Chinese Segmentation Augmented by ResourcesGenerated from a Very Large Dictionary for Post-ProcessingKa-Po Chow  Andy C. Chin Wing Fu TsoiLanguage Information Sciences Research CentreCity University of Hong KongTat Chee Avenue, Kowloon, Hong Kong{kapo.chow,cochin,rlwftsoi}@cityu.edu.hkAbstractWe used a production segmentationsystem, which draws heavily on a largedictionary derived from processing alarge amount (over 150 million Chinesecharacters) of synchronous textual datagathered from various Chinese speechcommunities, including Beijing, HongKong, Taipei, and others.
We run thissystem in two tracks in the Second In-ternational Chinese Word Segmenta-tion Bakeoff, with Backward MaximalMatching (right-to-left) as the primarymechanism.
We also explored the useof a number of supplementary featuresoffered by the large dictionary in post-processing, in an attempt to resolveambiguities and detect unknown words.While the results might not havereached their fullest potential, theynevertheless reinforced the importanceand usefulness of a large dictionary as abasis for segmentation, and the impli-cation of following a uniform standardon the segmentation performance ondata from various sources.1 IntroductionOur team has participated in two tracks of theACL SIGHAN-sponsored Second InternationalChinese Word Segmentation Bakeoff, namelyAcademia Sinica open (ASo) and Peking Uni-versity open (PKo).
The production segmenta-tion system we used draws heavily on a largedictionary derived from processing a very largeamount of synchronous textual data.
In Section2, our segmentation flow for the current Bakeoffwill be described, and in Section 3, the resultswill be evaluated and analysed.
Errors will beanalysed and implications discussed in Section 4,followed by a conclusion in Section 5.2 Segmentation FrameworkThe major resource of our segmentation systemis a large dictionary.
In the following, we de-scribe the main segmentation mechanism basedon maximal matching, and other supplementaryfeatures for post-processing attempted in thecurrent Bakeoff.2.1 Dictionary-based SegmentationThe primary mechanism of segmentation makesuse of a large dictionary derived from process-ing a large amount (over 150 million Chinesecharacters) of synchronous textual data, mostlyprinted news, gathered from various Chinesespeech communities, including Beijing, HongKong, Taipei, and others, following a uniformsegmentation standard.
The dictionary has nowgrown to a size of over 800,000 word types,with frequencies of each entry being trackedclosely.
For this Bakeoff, additional items fromthe respective training data were also included inthe existing dictionary for segmentation.
Thusunsegmented texts will first go through a proc-ess of Backward Maximal Matching (BMM)segmentation equipped with the combined dic-tionary.2.2 Supplementary Features2.2.1 Rule DevelopmentAccording to specific divergence of the segmen-tation standard of each test corpus from our pro-duction standard, a set of general adaptationrules were applied to transform the texts toachieve ?standard complacency?
as much aspossible.
The adaptation rules vary in nature,176depending on how intense the segmentationstandard differences are between each test cor-pus and our own.
Hence some rules are based onlinguistic structures while others are based onparticular treatment of elements like numeralsand units.These adaptation rules are coupled with a setof heuristic segmentation disambiguation rulesderived from our long-term and extensive proc-essing of text data.
Such rules are based onBMM, and amount to around 20,000 at the timeof writing.
Each rule has gone through carefulconsideration before putting to real productionuse, to ensure that they produce correct results inmost cases without overgeneralisation.2.2.2 Statistical BMM/FMM Comparisonand ReplacementAfter texts were segmented by BMM, the for-ward counterpart (Forward Maximal Matching,FMM) was also done for comparison, as the dis-crepancies between the two segmented texts of-ten indicate potential ambiguities.
Statisticalinformation such as the frequency distributionsof the segmented units in question were obtainedfrom our large dictionary.
By comparing theindependent joint likelihood of the two combi-nations, segmented units with exceptionally lowfrequency are likely to be disregarded, allowingus to choose the correct segmentation.
For ex-ample, in the test data, the phrase ???
issegmented as ?
/??
by the backward ap-proach, whereas ??
/?
will be obtained ifsegmented forwardly.
The latter segmented al-ternative, ?
?/?, is more likely to appear inthe text.2.2.3 Unknown Word DetectionOne of the most challenging issues in Chineseword segmentation is the treatment of unknownwords which can be further divided into twocategories: new words (NWs) and named enti-ties (NEs).
In our treatment of unknown words,a slight distinction was made between ChineseNEs and other NWs including foreign names.The detection processes are similar but statisti-cal data were gathered from different portions ofour textual data.
When a sequence of singlecharacters is hit, windows of two and three char-acters (only nominal morphemes were consid-ered) were extracted to form ?potential NE/NWcandidates?.
The likelihood of these charactersbeing monosyllabic words (i.e.
out-word) andthat of being part of multi-syllabic words (i.e.in-word) were compared to make the best guesswhether they should be combined or segmented.For NE detection, the in-word statistics wasbased on all the multi-syllabic named entities inthe Taipei portion from our dictionary and theout-word statistics on the rest of it.
The in-wordfrequency of a given character is thus the num-ber of times the character appears within amulti-syllabic named entity.
The in-word prob-ability is the in-word frequency divided by thetotal number of times the character appears in allour textual data.
The independent joint in-wordand out-word probabilities were computed andcompared for each candidate, which would becombined as a word if the in-word probability isgreater than the out-word probability and thefirst character in the candidate is within a list ofChinese surnames, again collected from all tex-tual data.For NW detection, the in-word statistics wasbased on all the multi-syllabic words in our dic-tionary.
For every newly combined word,neighbouring prefixes and suffixes (according tothose provided in the segmentation standard)were also detected and combined, if any.
A listof foreign names and all the characters appear-ing in them was also extracted from our diction-ary.
When a new word is detected, itsneighbouring words would be scanned andwould be combined if they are within this for-eign name list, thus enabling the identificationof names like???
?.3 Results and AnalysisThe results of the different stages of segmenta-tion are shown in Table 1 and Table 2.In both test corpora, the primary dictionary-based segmentation alone has achieved a sig-nificant percentage (over 95% in recall and over90% in precision).
This exemplifies that the richvocabulary we have offers a useful resource forlanguage engineering, and provides a solid plat-form for further enhancement.Post-processing with supplementary featuresfrom the dictionary shows consistent incre-mental improvement in segmentation.
Thescores (F-measure) due to FMM and BMM withheuristic rules demonstrate a relatively substan-tial gap at the very beginning, largely because ofthe heuristic rules developed and accumulated177through the precise and systematic processing ofour sizable textual data.Operation R P F ROOV RIVFMM only 0.953 0.903 0.927 0.658 0.966BMM, plusheuristic rules 0.960 0.915 0.937 0.661 0.974Comparison andreplacement 0.964 0.921 0.942 0.663 0.978Unknown worddetection 0.966 0.931 0.948 0.715 0.977Official results* 0.943 0.931 0.937 0.531 0.962Table 1: Results for ASo using combined dic-tionaryOperation R P F ROOV RIVFMM only 0.957 0.928 0.942 0.842 0.964BMM, plusheuristic rules 0.967 0.947 0.957 0.849 0.974Comparison andreplacement 0.969 0.951 0.960 0.851 0.977Official results* 0.952 0.951 0.951 0.784 0.962Table 2: Results for PKo using combined dic-tionaryThe performance of unknown word detectioncan be seen from the leap in ROOV after the op-eration.
It increases remarkably from 0.663 to0.715, offsetting the fall in RIV, which drops by0.001 and this may be due to the concatenationof some monosyllabic morphemes which aresupposed to be independent words.The results of the comparison between FMMand BMM are summarized in Table 3 and Table4.
A noticeable drawback of such comparison isthat some phrases will be mis-segmented in ei-ther direction.
For example, the phrase ?????
will be segmented backwardly into ?/??/??
but ??/??/?
forwardly.
The cor-rect segmentation, ??/?/?
?, cannot be at-tained in both cases.
Hence as an experiment,for any combination of five characters which aresegmented into 1/2/2 pattern by BMM and 2/2/1pattern by FMM, the 2/1/2 pattern will be alsotested against the overall probabilities.
For theformer example, ??/?/??
will override theother two.Table 3 shows that the number of correct re-placements from FMM is 399 in the AS testcorpus, combining the gain from the reshuffling* The reported figures differ from those computed on ourplatform, probably due to system differences.
The officialscorer program is publicly available and described in(Sproat and Emerson, 2003).of 5-character strings, the total is 408.
Since thedefault choice is the BMM segmented texts, thesum 408 is the total gain from this BMM/FMMcomparison, while 77 correct segmented textshave been mis-replaced, the gain/loss ratio is5.30.
This means that our system only loses 1correct segmentation in exchange of gaining 5.3correct ones.Likewise in the case of the PK test corpus inTable 4, the gain/loss ratio is 4.67.
The ratio issmaller than that for the AS test corpus.
It is thusevident that the comparison and replacement bymeans of BMM and FMM offers a substantialachievement in the accuracy of the segmentationprocess.BMM FMM Re-shuffle TotalCorrect Replacement 1124 399 9 1532Incorrect Replace-ment 281 267 0548Mis-replaced CorrectSegmentation 77 78 / 155Table 3: Analysis of BMM/FMM comparisonfor ASoBMM FMM Re-shuffle TotalCorrect Replacement 1097 254 3 1354Incorrect Replace-ment 131 117 2 250Mis-replaced CorrectSegmentation 55 33 / 88Table 4: Analysis of BMM/FMM comparisonfor PKoWe are aware that the performance of re-placement may be improved by using probabili-ties of n-grams, conditional probabilitiesinvolving the boundary words, and perhaps byconsidering all possibilities of segmentations forthe same string of texts, as in some other seg-mentation systems.
On the semantic level, theoverall message of a paragraph can be examinedas well by gathering statistics of collocatingwords.
The ordering of applying these algo-rithms, however, should be important, and howthey interplay with one another will be an arenato explore.Although we have not incorporated such en-hancement measures into our system in this ex-ercise, the dictionary can nevertheless supportsuch extension with the necessary statistical data.All previous results are based on the first-stageof segmentation with a large dictionary.
Since178we had processed texts from different Chinesespeech communities including Beijing, HongKong, Taipei, and others, the dictionary used forsegmentation also consists of all words appear-ing in any of these communities.
In order to in-vestigate the effect of locality on the dictionaryused in segmentation, two independent diction-aries have been generated from the Beijing por-tion and Taipei portion, and all the above stageswere repeated for the two test corpora, with re-sults shown below in Table 5 and Table 6.Operation R P F ROOV RIVFMM only 0.942 0.891 0.916 0.602 0.957BMM, plusheuristic rules 0.948 0.901 0.924 0.603 0.964Comparison andreplacement 0.951 0.907 0.929 0.605 0.967Table 5: Results for ASo using Taipei dictionaryOperation R P F ROOV RIVFMM only 0.954 0.923 0.938 0.800 0.963BMM, plusheuristic rules 0.969 0.941 0.955 0.814 0.978Comparison andreplacement 0.971 0.946 0.958 0.815 0.981Table 6: Results for PKo using Beijing diction-aryThe results show that dictionaries derivedfrom specific communities alone yield slightlysmaller F-measures than that derived from allplaces together.
The largest difference lies inROOV where it is 0.605 and 0.663 for ASo and0.815 and 0.851 for PKo, confirming the signifi-cance of adopting a large and all-rounded dic-tionary in word segmentation.4 Error AnalysisWe have examined the discrepancies betweenthe gold standard files and our resultant seg-mented files, and it is found that the segmenta-tion errors can be basically classified intoseveral categories.The errors due to standard divergence havethe most impact.
For example, ?/??
is con-sidered the correct segmentation in the AS testcorpus while ???
is one word in our largedictionary.Inconsistencies within the same corpus (bothtraining and test corpora) also give rise to per-formance fluctuations.
There are cases where thesame phrase is segmented differently.
For ex-ample, in the AS training corpus, both ??/??/?
and ??/???
are found.
Similar casesare also found in the test corpus, e.g.
?0??0?
vs.?0??
?.Another factor that affects the segmentationperformance over the PK corpus is encodingconversion.
Our production system is basedprimarily on materials which are in BIG5 encod-ing, specifically traditional Chinese characters inthe BIG5 encoding space.
Since the given testdata are in simplified Chinese characters, aprocess of encoding conversion to BIG5 is inplace.
Such a conversion is a one-to-many map-ping and thus some original words will be dis-torted, influencing segmentation correctness.5 ConclusionWe have reported our results on two open tracksof the Second International Chinese Word Seg-mentation Bakeoff, based on a production seg-mentation system, which draws heavily on alarge and unique dictionary.
The dictionary isderived from processing a very large amount ofsynchronous textual data gathered from variousChinese speech communities, based on a uni-form segmentation standard.
It is shown that theprimary dictionary-based BMM segmentationalone contribute the most in our segmentationsystem, with over 95% in recall and over 90% inprecision, attributable to the large size of thedictionary, although our uniform segmentationstandard may not have realized its full potentialgiven the test corpora with different and chang-ing standards.
We also explored supplementaryfeatures offered by the large dictionary in post-processing, and results incrementally improve.Hence our large dictionary derived from ouruniform treatment of synchronous data providesa useful resource and provides a good platformfor further extension in various aspects of lan-guage engineering.ReferencesRichard Sproat and Tom Emerson.
2003.
The FirstInternational Chinese Word Segmentation Bakeoff.In proceedings of the Second SIGHAN Workshopon Chinese Language Processing, July 11-12,2003, Sapporo, Japan.179
