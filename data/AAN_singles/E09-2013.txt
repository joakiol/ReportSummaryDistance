Proceedings of the EACL 2009 Demonstrations Session, pages 49?52,Athens, Greece, 3 April 2009. c?2009 Association for Computational LinguisticsMatching Readers?
Preferences and Reading Skills with Appropriate WebTextsEleni MiltsakakiUniversity of PennsylvaniaPhiladelphia, U.S.A.elenimi@seas.upenn.eduAbstractThis paper describes Read-X, a system designed toidentify text that is appropriate for the reader givenhis thematic choices and the reading ability asso-ciated with his educational background.
To ourknowledge, Read-X is the first web-based systemthat performs real-time searches and returns resultsclassified thematically and by reading level withinseconds.
To facilitate educators or students search-ing for reading material at specific reading levels,Read-X extracts the text from the html, pdf, doc,or xml format and makes available a text editor forviewing and editing the extracted text.1 IntroductionThe automatic analysis and categorization of webtext has witnessed a booming interest due to in-creased text availability of different formats (txt,ppt, pdf, etc), content, genre and authorship.
Theweb is witnessing an unprecedented explosion intext variability.
Texts are contributed by users ofvaried reading and writing skills as opposed to theearlier days of the Internet when text was mostlypublished by companies or institutions.
The agerange of web users has also widened to includevery young school and sometimes pre-school agedreaders.
In schools the use of the Internet isnow common to many classes and homework as-signments.
However, while the relevance of websearch results to given keywords has improvedsubstantially over the past decade, the appropri-ateness of the results is uncatered for.
On a key-word search for ?snakes?
the same results will begiven whether the user is a seven year old elemen-tary school kid or a snake expert.Prior work on assessing reading level includes(Heilman et al, 2007) who experiment with a sys-tem that employs grammatical features and vocab-ulary to predict readability.
The system is part ofthe the REAP tutor, designed to help ESL learn-ers improve their vocabulary skills.
REAP?s infor-mation retrieval system (Collins-Thompson andCallan, 2004) is based on web data that have beenannotated and indexed off-line.
Also, relatedly,(Schwarm and Ostendorf, 2005) use a statisticallanguage model to train SVM classifiers to clas-sify text for grade levels 2-5.
The classifier?s pre-cision ranges from 38%- 75% depending on thegrade level.In this demo, we present Read-X, a system de-signed to evaluate if text retrieved from the webis appropriate for the intended reader.
Our sys-tem analyzes web text and returns the thematicarea and the expected reading difficulty of the re-trieved texts.
1 To our knowledge, Read-X is thefirst system that performs in real time a)keywordsearch, b)thematic classification and c)analysis ofreading difficulty.
Search results and analyses arereturned within a few seconds to a maximum of aminute or two depending on the speed of the con-nection.
Read-X is enhanced with an added com-ponent which predicts difficult vocabulary giventhe user?s educational level and familiarity withspecific thematic areas.2 Web search and text classificationInternet search.
Read-X uses Yahoo!
Web Ser-vices to execute the keyword search.
When thesearch button is clicked or the enter key depressedafter typing in a keyword, Read-X sends a searchrequest to Yahoo!
including the keywords and, op-tionally, the number of results to return.Text extraction.
The html, xml, doc or pdf doc-uments stored at each URL are then extracted in acleaned-up, tag-free, text format.
At this stage adecision is made as to whether a web page con-tains reading material and not ?junk?.
This is anon-trivial task.
(Petersen and Ostendorf, 2006)use a classifier for this task with moderate success.We ?read?
the structure of the html text to decide ifthe content is appropriate and when in doubt, we1A demo video can be accessed at the blogsitewww.eacl08demo.blogspot.com.49Figure 1: Search results and analysis of readabilityerr on the side of throwing out potentially usefulcontent.Readability analysis.
For printed materials,there are a number of readability formulas usedto measure the difficulty of a given text; the NewDale-Chall Readability Formula, The Fry Read-ability Formula, the Gunning-Fog Index, the Au-tomated Readability Index, and the Flesch Kin-caid Reading Ease Formula are a few examples(see (DuBay, 2007) for an overview and refer-ences).
Usually, these formulas count the numberof syllables, long sentences, or difficult words inrandomly selected passages of the text.
To auto-mate the process of readability analysis, we chosethree Readability algorithms: Lix, RIX, see (An-derson, 1983), and Coleman-Liau, (Coleman andLiau, 1975), which were best suited for fast cal-culation and provide the user with either an ap-proximate grade level for the text or a readabilityclassification of very easy, easy, standard, difficultor very difficult.
When each text is analyzed, thefollowing statistics are computed: total numberof sentences, total number of words, total numberof long words (seven or more characters), and to-tal number of letters in the text.
Steps have beentaken to develop more sophisticated measures forfuture implementations.
Our current research aimsat implementing more sophisticated reading diffi-culty measures, including reader?s familiarity withthe topic, metrics of propositional density and dis-course coherence, without compromising speed ofFormula r3 r4 r5Lix 10.2 (9-11) 11.7 (10-13) 11.1 (9-12)RIX 10.2 (8-13) 12.3 (10-13) 11.5 (10-13)Coleman-Liau 11.65 (9.2-13.3) 12.67 (12.2-13.1) 12.6 (11.4-14.1)All 10.6 12.3 11.7Table 1: Comparison of scores from three read-ability formulae.processing.To evaluate the performance of the readingscores we used as groundtruth a corpus of web-texts classified for readability levels r3, r4, r5 cor-responding to grade levels 7-8, 9-10, and 11-13 re-spectively.2 The content of the corpus is a collec-tion of web-sites with educational content, pickedby secondary education teachers.
For 90 docu-ments, randomly selected from levels 3-5 (30 perlevel), we computed the scores predicted by Lix,RIX and Coleman-Liau.The average scores assigned by the three formu-las are shown in Table (1).
The numbers in paren-theses show the range of scores assigned by eachformula for the collection of documents undereach reading level.
The average score of all formu-las for r3 is 10.6 which is sufficiently differentiatedfrom the average 12.3. for r4.
The average score ofall formulas for r5, however, is 11.7, which cannotbe used to differentiate r4 from r5.
These resultsindicate that at least by comparison to the data in2With the exception of Spache and Powers-Sumner-Kearltest, all other readability formulas are not designed for lowgrade readability levels.50Classifier Basic categories SubcategoriesNaive Bayes 66% 30%MaxEnt 78% 66%MIRA 76% 58%Table 2: Performance of text classifiers.our corpus, the formulas can make reasonable dis-tinctions between middle school and high schoolgrades but they cannot make finer distinctions be-tween different high-school grades.
A more reli-able form of evaluation is currently underway.
Wehave designed self-paced reading experiments fordifferent readability scores produced by five for-mulas (RIX, Lix, Coleman-Liau, Flesch-Kincaidand Dale-Chall).
Formulas whose predictions willmore closely reflect reading times for text compre-hension will be preferred and form the basis fora better metric in the future.
In the current im-plementation, Read-X reports the scores for eachformula in a separate column.
Other readabilityfeatures modeling aspects of discourse coherence(e.g.,(Miltsakaki and Kukich, 2004), (Barzilay andLapata, 2008), (Bruss et al, 2004), (Pitler andNenkova, 2008)) can also be integrated after psy-cholinguistic evaluation studies are completed andtheir computation of such features can be made inreal time.Text classification For the text classificationtask, we a) built a corpus of prelabeled thematiccategories and b) compared the performance ofthree classifiers to evaluate their suitability for the-matic classification task.3We collected a corpus of approximately 3.4 mil-lion words.
The corpus contains text extractedfrom web-pages that were previously manuallyclassified per school subject area by educators.We organized it into a small thematic hierarchy,with three sets of labels: a) labels for supercat-egories, b) labels for basic categories and c) la-bels for subcategories.
There are 3 supercategories(Literature, Science, Sports), 8 basic categories(Arts, Career and Business, Literature, Philosophyand Religion, Science, Social studies, Sports andhealth, Technology) and 41 subcategories (e.g.,the subcategories for Literature are Art Criticism,Art History, Dance, Music, Theater).The performance of the classifiers trained on thebasic categories and subcategories data is shown3We gratefully acknowledge MALLET, a collection ofstatistical NLP tools written in Java, publicly available athttp://mallet.cs.umass.edu and Mark Dredze forhis help installing and running MIRA on our data.in Table (2).
All classifiers perform reasonablywell in the basic categories classification task butare outperformed by the MaxEnt classifier in boththe basic categories and subcategories classifica-tions.
The supercategories classification by Max-Ent (not shown in the Table) is 93%.
As expected,the performance of the classifiers deteriorates sub-stantially for the subcategories task.
This is ex-pected due to the large number of labels and thesmall size of data available for each subcategory.We expect that as we collect more data the perfor-mance of the classifiers for this task will improve.In the demo version, Read-X uses only the Max-Ent classifier to assign thematic labels and reportsresults for the super categories and basic cate-gories, which have been tested and shown to bereliable.3 Predicting difficult words givenreader?s backgroundThe analysis of reading difficulty based on stan-dard readability formulas gives a quick and easyway to measure reading difficulty but these formu-las lack sophistication and sensitivity to the abili-ties and background of readers.
They are reason-ably good at making rough distinctions between-standardly defined- middle, high-school or col-lege levels but they fall short in predicting readingease or difficulty for specific readers.
For exam-ple, a reader who is familiar with literary texts willhave less difficulty reading new literary text thana reader, with a similar educational background,who has never read any literary works.
In thissection, we discuss the first step we have takentowards making more reliable evaluations of textreadability given the profile of the reader.Readers who are familiar with specific thematicareas, are more likely to know vocabulary that isrecurring in these areas.
So, if we have vocab-ulary frequency counts per thematic area, we arein a better position to predict difficult words forspecific readers given their reading profiles.
Vo-cabulary frequency lists are often used by test de-velopers as an indicator of text difficulty, based onthe assumption that less frequent words are morelikely to be unknown.
However, these lists arebuilt from a variety of themes and cannot be cus-tomized for the reader.
We have computed vocab-ulary frequencies for all the basic thematic cate-gories in our corpus.
The top 10 most frequentwords per supercategory are shown in Table (3).51Arts Career and Business Literature Philosophy Science Social Studies Sports, Health TechnologyWord Freq Word Freq Word Freq Word Freq t Word Freq Word Freq Word Freq Word Freqmusical 166 product 257 seemed 1398 argument 174 trees 831 behavior 258 players 508 software 584leonardo 166 income 205 myself 1257 knowledge 158 bacteria 641 states 247 league 443 computer 432instrument 155 market 194 friend 1255 augustine 148 used 560 psychoanalytic 222 player 435 site 333horn 149 price 182 looked 1231 belief 141 growth 486 social 198 soccer 396 video 308banjo 128 cash 178 things 1153 memory 130 acid 476 clemency 167 football 359 games 303american 122 analysis 171 caesar 1059 truth 130 years 472 psychology 157 games 320 used 220used 119 resources 165 going 1051 logic 129 alfalfa 386 psychotherapy 147 teams 292 systems 200nature 111 positioning 164 having 1050 things 125 crop 368 united 132 national 273 programming 174artist 104 used 153 asked 1023 existence 115 species 341 society 131 years 263 using 172wright 98 sales 151 indeed 995 informal 113 acre 332 court 113 season 224 engineering 170Table 3: 10 top most frequent words per thematic category.Vocabulary frequencies per grade level have alsobeen computed but they are not shown here.We have added a special component to theRead-X architecture, which is designed to pre-dict unknown vocabulary given the reader?s ed-ucational background or familiarity with one (ormore) of the basic themes.
The interface al-lows you to select a web search result for furtheranalysis.
The user can customize vocabulary dif-ficulty predictions by selecting the desired gradeor theme.
Then, the text is analyzed and, in afew seconds, it returns the results of the analysis.The vocabulary evaluator checks the vocabularyfrequency of the words in the text and highlightsthe words that do not rank high in the vocabularyfrequency index for the chosen categories (gradeor theme).
The highlighted words are clickable.When they are clicked, the entry information fromWordNet appears on the right panel.
The systemhas not been evaluated yet so some tuning willbe required to determine the optimal cut-off fre-quency point for highlighting words.4 Future workA major obstacle in developing better readabilitymodels is the lack of reliable ?groundtruth?
data.Annotated data are very scarce but even such dataare only partially useful as it is not known if inter-annotator agreement for readability levels wouldbe high.
To address this issue we are currentlyrunning a battery of self-paced reading and eye-tracking experiments a) to evaluate which, if any,readability formulas accurately predict differencesin reading times b)to test new hypotheses aboutpossible factors affecting the perceived difficultyof a text, including vocabulary familiarity, propo-sitional density and discourse coherence.AcknowledgmentsAudrey Troutt developed the software for Read-X under a GAPSA Provost?s Award for Interdisci-plinary Innovation, University of Pennsylvania.ReferencesJonathan Anderson.
1983.
Lix and rix: Variations of a little-known readability index.
Journal of Reading, 26(6):490?496.Regina Barzilay and Mirella Lapata.
2008.
Modeling lo-cal coherence: An entity-based approach.
ComputationalLinguistics.M.
Bruss, M. J. Albers, and D. S.McNamara.
2004.
Changesin scientific articles over two hundred years: A coh-metrixanalysis.
In Proceedings of the 22nd Annual InternationalConference on Design of Communication: the Engineer-ing of Quality Documentation, pages 104?109.
New York:ACM Press.M Coleman and T. Liau.
1975.
A computer readability for-mula designed for machine scoring.
Journal of AppliedPsychology, 60:283?284.K.
Collins-Thompson and J. Callan.
2004.
Information re-trieval for language tutoring: An overview of the REAPproject.
In Proceedings of the Twenty Seventh Annual In-ternational ACM SIGIR Conference on Research and De-velopment in Information Retrieval (poster descritpion.William DuBay.
2007.
Smart Language: Readers, Read-ability, and the Grading of Text.
BookSurge Publishing.overview of readability formulas and references.M.
Heilman, K. Collins-Thompson, J. Callan, and M. Eske-nazi.
2007.
Combining lexical and grammatical featuresto improve readability measures for first and second lan-guage texts.
In Proceedings of the Human Language Tech-nology Conference.
Rochester, NY.Eleni Miltsakaki and Karen Kukich.
2004.
Evaluation of textcoherence for electronic essay scoring systems.
NaturalLanguage Engineering, 10(1).Sarah Petersen and Mari Ostendorf.
2006.
Assessing thereading level of web pages.
In Proceedings of Interspeech2006 (poster), pages 833?836.Emily Pitler and Ani Nenkova.
2008.
Revisiting readabil-ity: A unified framework for predicting text quality.
InProceedings of EMNLP, 2008.Sarah E. Schwarm and Mari Ostendorf.
2005.
Reading levelassessment using support vector machines and statisticallanguage models.
In ACL ?05: Proceedings of the 43rdAnnual Meeting on Association for Computational Lin-guistics, pages 523?530.52
