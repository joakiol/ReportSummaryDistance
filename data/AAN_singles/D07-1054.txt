Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and ComputationalNatural Language Learning, pp.
514?523, Prague, June 2007. c?2007 Association for Computational LinguisticsBilingual Cluster Based Models for Statistical Machine TranslationHirofumi YamamotoNational Institute of Informationand Communications Technology/ 2-2-2 Hikaridai Seika-choSoraku-gun Kyoto Japanand ATR Spoken LanguageCommunication Research Labs.hirofumi.yamamoto@nict.go.jpEiichiro SumitaNational Institute of Informationand Communications Technology/ 2-2-2 Hikaridai Seika-choSoraku-gun Kyoto Japanand ATR Spoken LanguageCommunication Research Labs.eiichiro.sumita@nict.go.jpAbstractWe propose a domain specific model forstatistical machine translation.
It is well-known that domain specific language mod-els perform well in automatic speech recog-nition.
We show that domain specific lan-guage and translation models also benefitstatistical machine translation.
However,there are two problems with using domainspecific models.
The first is the data sparse-ness problem.
We employ an adaptationtechnique to overcome this problem.
Thesecond issue is domain prediction.
In or-der to perform adaptation, the domain mustbe provided, however in many cases, thedomain is not known or changes dynami-cally.
For these cases, not only the trans-lation target sentence but also the domainmust be predicted.
This paper focuses onthe domain prediction problem for statisti-cal machine translation.
In the proposedmethod, a bilingual training corpus, is au-tomatically clustered into sub-corpora.
Eachsub-corpus is deemed to be a domain.
Thedomain of a source sentence is predicted byusing its similarity to the sub-corpora.
Thepredicted domain (sub-corpus) specific lan-guage and translation models are then usedfor the translation decoding.
This approachgave an improvement of 2.7 in BLEU (Pa-pineni et al, 2002) score on the IWSLT05Japanese to English evaluation corpus (im-proving the score from 52.4 to 55.1).
This isa substantial gain and indicates the validityof the proposed bilingual cluster based mod-els.1 IntroductionStatistical models, such as n-gram models, arewidely used in natural language processing, for ex-ample in speech recognition and statistical machinetranslation (SMT).
The performance of a statisticalmodel has been shown to improve when domain spe-cific models are used, since similarity of statisticalcharacteristics between model and target is higher.For utilize of domain specific models, a trainingdata sparseness and target domain estimation prob-lems must be resolved.
In this paper, we try to es-timate target domain sentence by sentence, consid-ering cases where the domain changes dynamically.After sentence by sentence domain estimation, do-main specific models are used for translation usingthe adaptation technique(Seymore et al, 1997).In order to train a classifier to predict the domain,we used an unsupervised clustering technique on anunlabelled bilingual training corpus.
We regardedeach cluster (sub-corpus) as a domain.
Prior to trans-lation, the domain of the source sentence is first pre-dicted and this prediction is then used for model se-lection.
The most similar sub-corpus to the transla-tion source sentence is used to represent its domain.After the prediction is made, domain specific lan-guage and translation models are used for the trans-lation.In Section 2 we present the formal basis for ourdomain specific translation method.
In Section 3 weprovide a general overview of the two sub-tasks ofdomain specific translation: domain prediction, anddomain specific decoding.
Section 4 presents thedomain prediction task in depth.
Section 5 offersa more detailed description of the details of domainspecific decoding.
Section 6 gives details of the ex-periments and presents the results.
Finally, Section5147 offers a summary and some concluding remarks.2 Domain Specific Models in SMTThe purpose of statistical machine translation is tofind the most probable translation in the target lan-guage e of a given source language sentence f .
Thissearch process can be expressed formally by:argmaxeP (e|f) (1)In this formula, the target word sequence (sentence)e is determined only by the source language wordsequence f .
However, e is heavily dependent onnot only on f but also on the domain D. When thedomain D is given, formula (1) can be rewritten asthe following formula with the introduction of a newprobabilistic variable D.argmaxeP (e|f,D) (2)This formula can be re-expressed using Bayes?
Law.argmaxeP (e|D)P (f |e,D) (3)Here, P (f |e,D) represents the domain D specifictranslation model and P (e|D) represents the domainD specific language model.When the domain D is known, domain specificmodels can be created and used in the translation de-coding process.
However, in many cases, domain Dis unknown or changes dynamically.
In these cases,both the translation target language sentence e andthe domain D must be dynamically predicted at thesame time.
The following equation represents theprocess of domain specific translation when the do-main D is being dynamically predicted.argmaxe,DP (e,D|f)= argmaxe,DP (D|f)P (e|f,D) (4)The major difference between this equation and for-mula (3) is that the probabilistic variable D is theprediction target in equation (4).
In this equa-tion, P (D|f) represents the domain prediction andP (e|f,D) represents the domain specific transla-tion.3 Outline of the Proposed MethodOur method can be analysed into two processes: anoff-line process and an on-line process.
The pro-cesses are depicted in figure 1.
In the off-line pro-cess, bilingual sub-corpora are created by clusteringand these clusters represent domains.
Domain spe-cific models are then created from the data containedin the sub-corpora in a batch process.
In the on-lineprocess, the domain of the source sentence is firstpredicted and following this the sentence is trans-lated using models built on data from the appropriatedomain.3.1 Off-line processIn this process, the training corpus is clustered tosub-corpora, which are regarded as domains.
InSMT, a bilingual corpus is used to create the trans-lation model, and typically, bilingual data togetherwith additional monolingual corpora are used tocreate the language model.
In our method, boththe bilingual and monolingual corpora are clustered.After clustering, cluster dependent (domain specific)language and translation models are created from thedata in the clusters.1.
A bilingual corpus which is comprised of thetraining data for the translation model, orequivalently the bilingual part of the trainingdata for the language model is clustered (seeSection 4.2).2.
Each sentence of the additional monolingualcorpora (if any) is assigned to a bilingual clus-ter (see Section 4.3).3.
For each cluster, the domain specific (clusterdependent) language models are created.4.
The domain specific translation model is cre-ated using only the clusters formed from clus-tering bilingual data.3.2 On-line processThis process is comprised of domain prediction andthe domain specific translation components.
Thefollowing steps are taken for each source sentence.1.
Select the cluster to which the source sentencebelongs.5152.
Translate the source sentence using the appro-priate domain specific language and translationmodels.4 Domain PredictionThis section details the domain prediction process.To satisfy equation (4), both the domain D andthe translation target word sequence e, which max-imizes both P (D|f) and P (e|f,D) must be cal-culated at the same time.
However, it is difficultto make the calculations without an approximation.Therefore, in the first step, we find the best candi-dates for D given the input sentence f .
In the nextstep, P (e|f,D) is maximized over the candidatesfor D using the following formula.argmaxeP (e|f, argmaxDP (D|f)) (5)Equation (5) is approximation of following equa-tion in that can D is regarded as a hidden variable.argmaxe?DP (D|f)P (e|D)P (f |e,D)) (6)When the following assumptions are introduced toequation (6), equation (5) is obtained as an approxi-mation.
For only one domain Di, P (Di|f) is nearlyequal to one.
For other domains, P (D|f) are almostzero.
P (D|f) can be re-written as following equa-tion.P (D|f)= P (D, f)/P (f)= P (f,D)/P (D) ?
P (D)/P (f)= P (f |D)P (D)/P (f) (7)Therefore, we can confirm reasonability of this as-sumption by calculating P (f |D)P (D) all domains(P (f) is constant).4.1 Domain DefinitionWhen the domain is known in advance, it is usu-ally expressible, for example it could be a topicthat matches a human-defined category like ?sport?.On the other hand, when the domain is delimitedin an unsupervised manner, it is used only as aprobabilistic variable and does not need to be ex-pressed.
Equation (4) illustrates that a good modelwill provide high probabilities to P (D|f)P (e|f,D)for bilingual sentence pairs (f, e).
For the samereason, a good domain definition will lead to ahigher probability for the term: P (D|f)P (e|f,D).Therefore, we define the domain D as that whichmaximizes P (D|f)P (e|D) (an approximation ofP (D|f)P (e|f,D)).
This approximation ensuresthat the domain definition is optimal for only thelanguage model rather than both the language andtranslation models.
P (D|f)P (e|D) can be re-written as the following equation using Bayes?
Law.P (D|f)P (e|D)= P (e|D)P (f |D)P (D)/P (f) (8)Here, P (f) is independent of domain D. Further-more, we assume P (D) to be constant.
The follow-ing formula embodies the search for the optimal do-main.argmaxDP (e|D)P (f |D) (9)This formula ensures that the search for the domainmaximizes the domain specific probabilities of bothe and f simultaneously.4.2 Clustering of the bilingual corpusAs mentioned above, we maximize the domain spe-cific probabilities of e and f to ascertain the domain.We define our domains as sub-corpora of the bilin-gual corpus, and these sub-corpora are formed byclustering bilingually by entropy reduction.
For thisclustering, the following extension of monolingualcorpus clustering is employed (Carter 1994).1.
The total number of clusters (domains) is givenby the user.2.
Each bilingual sentence pair is randomly as-signed to a cluster.3.
For each cluster, language models for e and fare created using the bilingual sentence pairsthat belong to the cluster.4.
For each cluster, the entropy for e and f is cal-culated by applying the language models fromthe previous step to the sentences in the clus-ter.
The total entropy is defined as the total sumof entropy (for both source and target) for eachcluster.516TranslationmodelsTargetlanguage modelsSourcelanguage modelsOff-line process Bilingual corpusOn-line processInput sourcesentenceDecoding TranslationresultSourcelanguageDomainselectionMonolingual corpusTargetlanguageDomain Specific   Models General ModelsBilingualclusterFigure 1: Outline of the Proposed Method5.
Each bilingual sentence pair is re-assigned to acluster such that the assignment minimizes thetotal entropy.6.
The process is repeated from step (3) untilthe entropy reduction is smaller than a giventhreshold.4.3 Clustering the monolingual corpusAny additional monolingual corpora used to trainthe language model are also clustered.
For this clus-tering, the following process is used.1.
First, bilingual clusters are created using theabove process.2.
For each monolingual sentence its entropy iscalculated using all the bilingual cluster depen-dent language models and also the general lan-guage model (see Figure 1 for a description ofthe general language model).3.
If the entropy of the general language modelis the lowest, this sentence is not used in thecluster dependent language models.4.
Otherwise, the monolingual sentence is addedto the bilingual cluster that results in the lowestentropy.4.4 Domain predictionIn the process described in the previous section wedescribe how clusters are created, and we define ourdomains in terms of these clusters.
In this step, do-main D is predicted using the given source sentencef .
This prediction is equivalent to finding the D thatmaximizes P (D|f).
P (D|f) can be re-written asP (f |D)P (D)/P (f) using Bayes?
law.
Here, P (f)is a constant, and if P (D) is assumed to be constant(this approximation is also used in the clustering ofthe bilingual corpus), maximizing the target is re-duced to the maximization of P (f |D).
To maximizeP (f |D) we simply select the cluster D, that givesthe highest likelihood of a given source sentence f .5 Domain specific decodingAfter domain prediction, domain specific decodingto maximize P (e|f,D), is conducted.
P (e|f,D)can be re-written as the following equation usingBayes?
law.P (e|f,D)= P (f |e,D)P (e,D)/P (f,D)517= P (f |e,D)P (e|D)P (D)/P (f,D) (10)Here, f is a given constant and D has alreadybeen selected by the domain prediction process.Therefore, maximizing P (f |e,D)P (e|D) is equiv-alent to maximizing the above equation.
InP (f |e,D)P (e|D), P (f |e,D) is the domain specifictranslation model and P (e|D) is the domain specificlanguage model.
Equation (10) represents the wholeprocess of translation of f into e using domain Dspecific models P (f |e,D) and P (e|D).5.1 Differences from previous methods5.1.1 Cluster language modelHasan et al (2005) proposed a cluster languagemodel for finding the domain D. This method hasthree steps.
In the first step, the translation targetlanguage corpus is clustered using human-definedregular expressions.
In the second step, a regularexpression is created from the source sentence f .
Inthe last step, the cluster that corresponds to the ex-tracted regular expression is selected, and the clusterspecific language model built from the data in thiscluster is used for the translation.
The points of dif-ference are:?
In the cluster language model, clusters are de-fined by human-defined regular expressions.On the other hand, with the proposed method,clusters are automatically (without humanknowledge) defined and created by the entropyreduction based method.?
In the cluster language model, only the trans-lation target language corpus is clustered.
Inthe proposed method, both the translationsource and target language corpora are clus-tered (bilingual clusters).?
In the cluster language model, only a domain(cluster) specific language model is used.
Inthe proposed method, both a domain specificlanguage model and a domain specific transla-tion model are used.5.1.2 Sentence mixture language modelIn equation (6), D is regarded as a hidden vari-able.
Furthermore, when P (D|f) is approximatedas P (D) = D?, and the general translation modelP (f |e) is used instead of the domain specific trans-lation model P (f |e,D), this equation represents theprocess of translation using sentence mixture lan-guage models (Iyer et al, 1993) as follows:argmaxe?DD?P (e|D)P (f |e) (11)The points that differ from the proposed method areas follows:?
In the sentence mixture model, the mixtureweight parameters D?
are constant.
On theother hand, in the proposed method, weight pa-rameters P (D|f) are estimated separately foreach sentence.?
In the sentence mixture model, the probabili-ties of all cluster dependent language modelsare summed.
In the proposed model, only thecluster that gives the highest probability is con-sidered as approximation.?
In the proposed method, a domain specifictranslation model is also used.6 Experiments6.1 Japanese to English translation6.1.1 Experimental corpusTo evaluate the proposed model, we conductedexperiments based on a travel conversation task cor-pus.
The experimental corpus was the travel ar-rangements task of the BTEC corpus (Takezawa etal., 2002),(Kikui et al, 2003) and the language pairwas Japanese and English.
The training, develop-ment, and evaluation corpora are shown in Table1.
The development and evaluation corpora eachhad sixteen reference translations for each sentence.This training corpus was also used for the IWSLT06Evaluation Campaign on Spoken Language Transla-tion (Paul 2006) J-E open track, and the evaluationcorpus was used as the IWSLT05 evaluation set.6.1.2 Experimental conditionsFor bilingual corpus clustering, the sentence en-tropy must be calculated.
Unigram language modelswere used for this calculation.
The translation mod-els were pharse-based (Zen et al, 2002) created us-ing the GIZA++ toolkit (Och et al, 2003).
The lan-guage models for the domain prediction and transla-tion decoding were word trigram with Good-Turing518Table 1: Japanese to English experimental corpus# of sentence Total words # of word entryJapanese Training 40K 355K 12.5KEnglish Training 40K 315K 9.2KJapanese Development 510 3,525 918English Development 510?16 57,388 2,118Japanese Evaluation 506 3,647 951backoff (Katz 1987).
Ten cluster specific source lan-guage models and a general language model wereused for the domain prediction.
If the general lan-guage model provided the lowest perplexity for aninput sentence, the domain specific models were notused for this sentence.
The SRI language model-ing toolkit (Stolcke) was used for the creation of alllanguage models.
The PHARAOH phrase-based de-coder (Koehn 2004) was used for the translation de-coding.For tuning of the decoder?s parameters, includingthe language model weight, minimum error train-ing (Och 2003) with respect to the BLEU score us-ing was conducted using the development corpus.These parameters were used for the baseline condi-tions.
During translation decoding, the domain spe-cific language model was used as an additional fea-ture in the log-linear combination according to thePHARAOH decoder?s option.
That is, the generaland domain specific language models are combinedby log-linear rather than linear interpolation.
Theweight parameters for the general and domain spe-cific language models were manually tuned usingthe development corpus.
The sum of these languagemodel weights was equal to the language modelweight in the baseline.
For the translation model,the general translation model (phrase table) and do-main specific translation model were linearly com-bined.
The interpolation parameter was again man-ually tuned using the development corpus.6.1.3 Experimental resultsIn our bilingual clustering, the number of clus-ters must be fixed in advance.
Based on the resultsof preliminary experiments to estimate model order,ten clusters were used.
If less than ten clusters wereused, domain specific characteristics cannot be rep-resented.
If more than ten clusters were used, datasparseness problems are severe, especially in trans-lation models.
The amount of sentences in eachcluster is not so different, therefore the approxima-tion that P (D) is reasonable.
Two samples of bilin-gual clusters are recorded in the appendix ?Sampleof Cluster?.
The cluster A.1 includes many interrog-ative sentences.
The reason is that special words ?  (desu ka)?
or ?
  (masu ka)?
are usedat the end of Japanese sentence with no correspond-ing word used in English.
The cluster A.2 includesnumeric expressions in both English and Japanese.Next, we confirm the reasonability of the assump-tion used in equation(5).
For this confirmation, wecalculate P (D|f) for all D for each f (P(D) is ap-proximated as constant).
For almost f , only onedomain Di has a vary large value compared withother domains.
Therefore, this approximation isconfirmed to be reasonable.In this experiments, we compare three ways of de-ploying our domain specific models to a baseline.
Inthe first method, only the domain specific languagemodel is used.
The ratio of the weight parameter forthe general model to the domain specific model was6:4 for all the domain specific language models.
Inthe second method, only the domain specific transla-tion model was used.
The ratio of the interpolationparameter of the general model to the domain spe-cific model was 3:7 for all the domain specific mod-els.
In the last method, both the domain specific lan-guage and translation models (LM+TM) were used.The weights and interpolation parameters were thesame as in the first and second methods.
The experi-mental results are shown in Table 2.
Under all of theconditions and for all of the evaluation measures, theproposed domain specific models gave better perfor-mance than the baseline.
The highest performancecame from the system that used both the domain spe-cific language and translation models, resulting in a5192.7 point BLEU score gain over the baseline.
It is avery respectable improvement.
Appendix ?Sampleof Different Translation Results?
recodes samples ofdifferent translation results with and without the do-main specific language and translation models.
Inmany cases, better word order is obtained in withthe domain specific models.6.2 Translation of ASR outputIn this experiment, the source sentence used as in-put to the machine translation system was the directtextual output from an automatic speech recognition(ASR) decoder that was a component of a speech-to-speech translation system.
The input to our sys-tem therefore contained the kinds of recognition er-rors and disfluencies typically found in ASR output.This experiment serves to determine the robustnessof the domain prediction to real-world speech input.The speech recognition process in this experimenthad a word accuracy of 88.4% and a sentence ac-curacy of 67.2% .
The results shown in Table 3clearly demonstrate that the proposed method is ableto improve the translation performance, even whenspeech recognition errors are present in the inputsentence.6.3 Comparison with previous methodsIn this section we compare the proposed methodto other comtemporary methods: the cluster lan-guage model (CLM) and the sentence mixture model(SMix).
The experimental results for these meth-ods were reported by RWTH Aachen University inIWSLT06 (Mauser et al, 2006).
We evaluated ourmethod using the same training and evaluation cor-pora.
These corpora were used as the training anddevelopment corpora in the IWSLT06 Chinese toEnglish open track, the details are given in Table4.
The English side of the training corpus was thesame as that used in the earlier Japanese to Englishexperiments reported in this paper.
Each sentencein the evaluation corpus had seven reference trans-lations.
Our baseline performance was slightly dif-ferent from that reported in the RWTH experiments(21.9 BLEU socre for RWTH?s system and 21.7 forour system).
Therefore, their improved baseline isshown for comparison.
The results are shown inTable 5.
The improvements over the baseline ofour method in both BLEU and NIST (Doddington2002) score were greater than those for both CLMand SMix.
In particular, our method showed im-provent in both the BLEU and NIST scores, this is incontrast to the CLM and SMix methods which bothdegraded the translation performance in terms of theNIST score.Table 5: Comparison results with previous methodsBLEU NIST WER PERRWTH 21.9 6.31 66.4 50.8Our 21.7 6.79 70.9 51.2CLM +0.6 -0.22 -2.7 -1.1SMix +0.2 -0.06 -1.1 -0.9Proposed +1.1 +0.17 -1.1 -0.56.4 Clustering of the monolingual corpusFinally, we evaluated the proposed method whenan additional monolingual corpus was incorporated.For this experiment, we used the Chinese and En-glish bilingual corpora that were used in the NISTMT06 evaluation (NIST 2006).
The size of the bilin-gual training corpus was 2.9M sentence pairs.
Forthe language model training, an additional monolin-gual corpus of 1.5M English sentences was used.NIST 2006 development (evaluation set for NIST2005) is used for evaluation.
In this experiment,the test set language model perplexity of a modelbuilt on only the monolingual corpus was consider-ably lower than that of a model built from only thetarget language sentences from the bilingual corpus.Therefore, we would expect the use of this monolin-gual corpus to be an important factor affecting thequality of the translation system.
These perplexi-ties were 299.9 for the model built on only the bilin-gual corpus, 200.1 for the model built on only themonolingual corpus, and 192.5 for the model builton a combination of the bilingual and monolingualcorpora.
For the domain specific models, 50 clus-ters were created from the bilingual and monolin-gual corpora.
In this experiment, only the domainspecific language model was used.
The experimen-tal results are shown in Table 6.
The results in thetable show that the incorporation of the additionalmonolingual data has a pronounced beneficial effecton performance, the performance improved accord-ing to all of the evaluation measures.520Table 2: Japanese to English translation evaluation scoresBLEU NIST WER PER Meteor TERBaseline 52.38 9.316 42.87 33.21 70.63 35.46Domain Specific LM 53.66 9.349 41.73 32,27 71.39 34.17Domain Specific TM 54.30 9.333 41.64 32.50 71.77 33.80Domain Specific LM+TM 55.09 9.451 41.05 31.63 72.09 33.20Table 3: Evaluation using ASR outputBLEU NIST WER PER Meteor TERBaseline 48.17 8.892 47.05 36.86 67.40 39.36Domain Specific LM 48.94 8.900 46.26 36.37 67.98 38.42Domain Specific TM 49.11 8.842 45.78 36.55 68.01 37.88Domain Specific LM+TM 50.12 9.001 45.26 35.80 68.05 37.227 ConclusionWe have proposed a technique that utilizes domainspecific models based on bilingual clustering for sta-tistical machine translation.
It is well-known thatdomain specific modeling can result in better perfor-mance.
However, in many cases, the target domainis not known or can change dynamically.
In suchcases, domain determination and domain specifictranslation must be performed simultaneously dur-ing the translation process.
In the proposed method,a bilingual corpus was clustered using an entropy re-duction based method.
The resulting bilingual clus-ters are regarded as domains.
Domain specific lan-guage and translation models are created from thedata within each bilingual cluster.
When a sourcesentence is to be translated, its domain is first pre-dicted.
The domain prediction method selects thecluster that assigns the lowest language model per-plexity to the given source sentence.
Translationthen proceeds using a language model and transla-tion model that are specific to the domain predictedfor the source sentence.In our experiments we used a corpus from thetravel domain (the subset of the BTEC corpus thatwas used in IWSLT06).
Our experimental resultsclearly demonstrate the effectiveness of our method.In the Japanese to English translation experiments,the use of our proposed method improved the BLEUscore by 2.7 points (from 52.4 to 55.1).
We com-pared our approach to two previous methods, thecluster language model and sentence mixture model.In our experiments the proposed method yieldedhigher scores than either of the competitive meth-ods in terms of both BLEU and NIST.
Moreover, ourmethod may also be augmented when an additionalmonolingual corpus is avaliable for building the lan-guage model.
Using this approach we were able tofurther improve translation performance on the datafrom the NIST MT06 evaluation task.A Sample of ClusterA.1 Cluster 1?
E: do you do alterationsJ:  	   (naoshi wa shi teimasu ka)?
E: what?s the newest color in this seasonJ:      (kotoshi noshinshoku wa dore desu ka)?
E: are there any baseball games todayJ:	fiff ffifl    (kyouyakyu no shiai wa ari masu ka)?
E: where?s the nearest perfumeryJ: !#"$%&fi'(ffi)+*    (moyorino kousui ten wa doko desu ka)?
E: how much is the breakfastJ: ,	-./ 021    (choshoku wa ikuradesu ka)521Table 4: Training and evaluation corpora used for comparison with previous methods# of sentence Total words Vocabulary sizeEnglish Training 40K 315K 9.2KChinese Training 40K 304K 18.7KChinese Evaluation 489 5,110 1.3KTable 6: Experimental results with monolingual corpusBLEU NIST WER PER Meteor TERBaseline 24.39 7.918 86.51 61.65 53.36 68.21Proposed 24.95 8.030 85.89 61.27 53.86 67.48A.2 Cluster 2?
E: mr. aoki yes a single room for two nightsJ:     ffflfi   	 (aoki san desu ne ee shingu-rurumu de 2 haku desu ne)?
E: may i have the key to room two fifteenJ:ffi!
"$# %$&'  (2 1 5 goushitsu no kagi o kudasai)?
E: i?d like extension twenty four pleaseJ: (*),+.-%0/21    (naisen 24o o begai shi masu)?
E: the flight number is se one o three to tokyoon the second of aprilJ: 354687:9<;=?>@BA0C0D5E6FffiGIH'JLK-MflK   (furaitonanbawa tokyo iki s e 1 0 3 bin 4 gatsu futsuka no bindesu)?
E: delta airlines flight one one two boarding isdelayedJ: NOQPSRTffiUffi$K0VXWffY?Z	   (derutakouku 1 1 2 bin wa tojo ga okuretei masu)B Sample of Different Translation Results1.
Ref: your room is number two tenBase: your room this is room two o oneLM: your room is this is room two one zeroTM: your room is room two o oneLM+TM: your room is this is room two onezero2.
Ref: where is a spot where there are a lot of fishBase: i?m spot where is the lot of fishLM: where is the spot are a lot of fishTM: i?m spot where is the lot of fishLM+TM: where is the spot are a lot of fish3.
Ref: i don?t like the designBase: design i don?t like itLM: i don?t like it designTM: i don?t like the designLM+TM: i don?t like the design4.
Ref: where can i contact youBase: where contact if i mayLM: where contact if i canTM: where can i contactLM+TM: where can i contact5.
Ref: where is a police station where japanese isunderstoodBase: japanese where?s the police stationLM: japanese where?s the police stationTM: where?s the police station where someoneunderstands japaneseLM+TM: where?s the police station wheresomeone understands japanese522ReferencesK.
Seymore, R. Rosenfeld, ?Using Story Topics for Lan-guage Model Adaptation,?
Proc.
EUROSPEECH, pp.1987-1990, 1997.David Carter, ?Improving Language Models by Cluster-ing Training Sentences,?
Proc.
ACL, pp.
59-64, 1994.S.
Hasan, H. Ney, ?Clustered Language Models Basedon Regular Expressions for SMT,?
Proc.
EAMT, Bu-dapest, Hungary, May 2005.R.
M. Iyer and M. Ostendorf, ?Modeling Long DistanceDependence in Language: Topic mixture versus dy-namic cache models,?
IEEE Transactions on Speechand Audio Processing, 1994.T.
Takezawa, E. Sumita, F. Sugaya, H. Yamamoto, S. Ya-mamoto, ?Toward a broad-coverage bilingual corpusfor speech translation of travel conversations in the realworld,?
Proc.
Conference on Language Resource andEvaluation, May 2002.Genichiro Kikui, Eiichiro Sumita, Toshiyuki Takezawa,Seiichi Yamamoto, ?Creating Corpora for Speech-to-Speech Translation,?
Proc.
EUROSPEECH, pp.
381-384, 2003.M.
Paul, ?Overview of the IWSLT 2006 Evaluation Cam-paign,?
IWSLT 2006, Nov. 2006.R.
Zens, F. J. Och, H. Ney, ?Phrase-based statistical ma-chine translation,?
25th German Conference on Artifi-cial Inteligence, Sep 2002.F.
J. Och, H. Ney, ?A Systematic Comparison of VariousStatistical Alignment Models,?
Computational Lin-guistics, No.
1, Vol.
29, pp.
19-51, 2003.S.
M. Katz, ?Estimation of Probabilities from SparseData for Language Model Component of a SpeechRecognizer,?
IEEE Trans.
on Acoustics, Speech, andSignal Processing, pp.
400-401, 1987.A.
Stolcke, ?SRILM - An Extensible Language ModelToolkit,?
http://www.speech.sri.com/projects/srilm/P.
Koehn, ?PHARAOH: A beam search decoder forphrase-based statistical machine translation models,?http://www.isi.edu/publications/licensed-sw/pharaoh/F.
J. Och, ?Minimum error rate training for statistical ma-chine trainslation,?
Proc.
ACL, 2003.K.
Papineni, S. Roukos, T. Ward, W.-J.
Zhu, ?Bleu: amethod for automatic evaluation of machine transla-tion,?
Proc.
ACL, 2002.A.
Mauser, R. Zens, E. Matusov, S. Hasan, H. Ney, ?TheRWTH Statistical Machine Translation System forIWSLT 2006 Evaluation,?
IWSLT 2006, Nov. 2006.G.
Doddington, ?Automatic evaluation of machine trans-lation quality using n-gram co-occurrence statistics,?Proc.
ARPA Workshop on Human Language Technol-ogy, 2002.NIST 2006 Machine Translation Evaluation,http://www.nist.gov/speech/tests/mt/mt06eval official results.html523
