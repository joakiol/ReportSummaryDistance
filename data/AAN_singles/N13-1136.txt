Proceedings of NAACL-HLT 2013, pages 1163?1173,Atlanta, Georgia, 9?14 June 2013. c?2013 Association for Computational LinguisticsTowards Coherent Multi-Document SummarizationJanara Christensen, Mausam, Stephen Soderland, Oren EtzioniComputer Science & EngineeringUniversity of WashingtonSeattle, WA 98195, USA{janara,mausam,soderlan,etzioni}@cs.washington.eduAbstractThis paper presents G-FLOW, a novel systemfor coherent extractive multi-document sum-marization (MDS).1 Where previous work onMDS considered sentence selection and or-dering separately, G-FLOW introduces a jointmodel for selection and ordering that balancescoherence and salience.
G-FLOW?s core rep-resentation is a graph that approximates thediscourse relations across sentences based onindicators including discourse cues, deverbalnouns, co-reference, and more.
This graph en-ables G-FLOW to estimate the coherence of acandidate summary.We evaluate G-FLOW on Mechanical Turk,and find that it generates dramatically bet-ter summaries than an extractive summarizerbased on a pipeline of state-of-the-art sentenceselection and reordering components, under-scoring the value of our joint model.1 IntroductionThe goal of multi-document summarization (MDS)is to produce high quality summaries of collectionsof related documents.
Most previous work in ex-tractive MDS has studied the problems of sentenceselection (e.g., (Radev, 2004; Haghighi and Vander-wende, 2009)) and sentence ordering (e.g., (Lapata,2003; Barzilay and Lapata, 2008)) separately, butwe believe that a joint model is necessary to producecoherent summaries.
The intuition is simple: if thesentences in a summary are first selected?withoutregard to coherence?then a satisfactory ordering ofthe selected sentences may not exist.1System and data at http://knowitall.cs.washington.edu/gflow/doc1: Bomb-ing inJerusalemdoc1: Angerfrom Israelisdoc1: Suspen-sion of peaceaccord due tobombingdoc2: Hamasclaims respon-sibilitydoc5: Pales-tinians con-demn attackdoc4: Mubarakurges peaceaccorddoc5: Pales-tinians urgepeace accorddoc3: Clintonurges peaceaccordFigure 1: An example of a discourse graph covering abombing and its aftermath, indicating the source docu-ment for each node.
A coherent summary should beginwith the bombing and then describe the reactions.
Sen-tences are abbreviated for compactness.An extractive summary is a subset of the sen-tences in the input documents, ordered in someway.2 Of course, most possible summaries are in-coherent.
Now, consider a directed graph where thenodes are sentences in the collection, and each edgerepresents a pairwise ordering constraint necessaryfor a coherent summary (see Figure 1 for a samplegraph).
By definition, any coherent summary mustobey the constraints in this graph.Previous work has constructed similar graphs au-tomatically for single document summarization andmanually for MDS (see Section 2).
Our system,G-FLOW extends this research in two importantways.
First, it tackles automatic graph constructionfor MDS, which requires novel methods for identi-fying inter-document edges (Section 3).
It uses this2We focus exclusively on extractive summaries, so we dropthe word ?extractive?
henceforth.1163State-of-the-art MDS system G-FLOW?
The attack took place Tuesday near Cailaco in East Timor, aformer Portuguese colony, according to a statement issued by thepro-independence Christian Democratic Union of East Timor.?
The United Nations does not recognize Indonesian claims to EastTimor.?
In a decision welcomed as a landmark by Portugal, European Unionleaders Saturday backed calls for a referendum to decide the fate of EastTimor, the former Portuguese colony occupied by Indonesia since 1975.?
Indonesia invaded East Timor in 1975 and annexed it the followingyear.?
Bhichai Rattakul, deputy prime minister and president of theBangkok Asian Games Organizing Committee, asked the ForeignMinistry to urge the Saudi government to reconsider withdrawingits 105-strong team.?
The games will be a success.?
Thailand won host rights for the quadrennial games in 1995, butsetbacks in preparations led officials of the Olympic Council of Asia latelast year to threaten to move the games to another country.?
Thailand showed its nearly complete facilities for the Asian Games toa tough jury Thursday - the heads of the organizing committees from the43 nations competing in the December event.Table 1: Pairs of sentences produced by a pipeline of a state-of-the-art sentence extractor (Lin and Bilmes, 2011) andsentence orderer (Li et al 2011a), and by G-FLOW.graph to estimate coherence of a candidate summary.Second, G-FLOW introduces a novel methodologyfor joint sentence selection and ordering (Section 4).It casts MDS as a constraint optimization problemwhere salience and coherence are soft constraints,and redundancy and summary length are hard con-straints.
Because this optimization problem is NP-hard, G-FLOW uses local search to approximate it.We report on a Mechanical Turk evaluation thatdirectly compares G-FLOW to state-of-the-art MDSsystems.
Using DUC?04 as our test set, we com-pare G-FLOW against a combination of an extractivesummarization system with state-of-the-art ROUGEscores (Lin and Bilmes, 2011) followed by a state-of-the-art sentence reordering scheme (Li et al2011a).
We also compare G-FLOW to a combina-tion of an extractive system with state-of-the-art co-herence scores (Nobata and Sekine, 2004) followedby the reordering system.
In both cases participantssubstantially preferred G-FLOW.
Participants choseG-FLOW 54% of the time when compared to Lin,and chose Lin?s system 22% of the time.
When com-pared to Nobata, participants chose G-FLOW 60%of the time, and chose Nobata only 20% of the time.The remainder of the cases were judged equivalent.A further analysis shows that G-FLOW?s sum-maries are judged superior along several dimensionssuggested in the DUC?04 evaluation (including co-herence, repetitive text, and referents).
A compar-ison against manually written, gold standard sum-maries, reveals that while the gold standard sum-maries are preferred in direct comparisons, G-FLOWhas nearly equivalent scores on almost all dimen-sions suggested in the DUC?04 evaluation.The paper makes the following contributions:?
We present G-FLOW, a novel MDS system thatjointly solves the sentence selection and order-ing problems to produce coherent summaries.?
G-FLOW automatically constructs a domain-independent graph of ordering constraints oversentences in a document collection, based onsyntactic cues and redundancy across docu-ments.
This graph is the backbone for estimat-ing the coherence of a summary.?
We perform human evaluation on blind testsets and find that G-FLOW dramatically outper-forms state-of-the-art MDS systems.2 Related WorkMost existing research in multi-document summa-rization (MDS) focuses on sentence selection for in-creasing coverage and does not consider coherenceof the summary (Section 2.1).
Although coherencehas been used in ordering of summary sentences(Section 2.2), this work is limited by the quality ofsummary sentences given as input.
In contrast, G-FLOW incorporates coherence in both selection andordering of summary sentences.G-FLOW can be seen as an instance of discourse-driven summarization (Section 2.3).
There is priorwork in this area, but primarily for summarization ofsingle documents.
There is some preliminary workon the use of manually-created discourse models inMDS.
Our approach is fully automated.2.1 Subset Selection in MDSMost extractive summarization research aims to in-crease the coverage of concepts and entities whilereducing redundancy.
Approaches include the use ofmaximum marginal relevance (Carbonell and Gold-stein, 1998), centroid-based summarization (Sag-gion and Gaizauskas, 2004; Radev et al 2004), cov-1164ering weighted scores of concepts (Takamura andOkumura, 2009; Qazvinian et al 2010), formula-tion as minimum dominating set problem (Shen andLi, 2010), and use of submodularity in sentence se-lection (Lin and Bilmes, 2011).
Graph centrality hasalso been used to estimate the salience of a sentence(Erkan and Radev, 2004).
Approaches to contentanalysis include generative topic models (Haghighiand Vanderwende, 2009; Celikyilmaz and Hakkani-Tur, 2010; Li et al 2011b), and discriminative mod-els (Aker et al 2010).These approaches do not consider coherence asone of the desiderata in sentence selection.
More-over, they do not attempt to organize the selectedsentences into an intelligible summary.
They areoften evaluted by ROUGE (Lin, 2004), which iscoherence-insensitive.
In practice, these approachesoften result in incoherent summaries.2.2 Sentence ReorderingA parallel thread of research has investigated takinga set of summary sentences as input and reorderingthem to make the summary fluent.
Various algo-rithms use some combination of topic-relatedness,chronology, precedence, succession, and entity co-herence for reordering sentences (Barzilay et al2001; Okazaki et al 2004; Barzilay and Lapata,2008; Bollegala et al 2010).
Recent work has alsoused event-based models (Zhang et al 2010) andcontext analysis (Li et al 2011a).The hypothesis in this research is that a pipelinedcombination of subset selection and reordering willproduce high-quality summaries.
Unfortunately,this is not true in practice, because sentences are se-lected primarily for coverage without regard to co-herence.
This methodology often leads to an inad-vertent selection of a set of disconnected sentences,which cannot be put together in a coherent sum-mary, irrespective of how the succeeding algorithmreorders them.
In our evaluation, reordering had lim-ited impact on the quality of the summaries.2.3 Coherence Models and SummarizationResearch on discourse analysis of documents pro-vides a basis for modeling coherence in a docu-ment.
Several theories have been developed formodeling discourse, e.g., Centering Theory, Rhetor-ical Structure Theory (RST), Penn Discourse Tree-Bank (Grosz and Sidner, 1986; Mann and Thomp-son, 1988; Wolf and Gibson, 2005; Prasad et al2008).
Numerous discourse-guided summariza-tion algorithms have been developed (Marcu, 1997;Mani, 2001; Taboada and Mann, 2006; Barzilay andElhadad, 1997; Louis et al 2010).
However, theseapproaches have been applied to single documentsummarization and not to MDS.Discourse models have seen some application tosummary generation in MDS, for example, using adetailed semantic representation of the source texts(McKeown and Radev, 1995; Radev and McKe-own, 1998).
A multi-document extension of RSTis Cross-document Structure Theory (CST), whichhas been applied to MDS (Zhang et al 2002; Jorgeand Pardo, 2010).
However, these systems requirea stronger input, such as a manual CST-annotationof the set of documents.
Our work can be seen asan instance of summarization based on lightweightCST.
However, a key difference is that our proposedalgorithm is completely automated and does not re-quire any additional human annotation.
Addition-ally, while incorporating coherence into selection,this work does not attempt to order the sentencescoherently, while our approach performs joint selec-tion and ordering.Discourse models have also been used for evalu-ating summary quality (Barzilay and Lapata, 2008;Louis and Nenkova, 2009; Pitler et al 2010).
Fi-nally, there is work on generating coherent sum-maries in specific domains, such as scientific articles(Saggion and Lapalme, 2002; Abu-Jbara and Radev,2011) using domain-specific cues like citations.
Incontrast, our work generates summaries without anydomain-specific knowledge.
Other research has fo-cused on identifying coherent threads of documentsrather than sentences (Shahaf and Guestrin, 2010).3 Discourse GraphAs described in Section 1, our goal is to identifypairwise ordering constraints over a set of input sen-tences.
These constraints specify a multi-documentdiscourse graph, which is used by G-FLOW to eval-uate the coherence of a candidate summary.In this graph G, each vertex is a sentence and anedge from si to sj indicates that sj can be placedright after si in a coherent summary.
In other words,the two share a discourse relationship.
In the fol-1165lowing three sentences (from possibly different doc-uments) there should be an edge from s1 to s2, butnot between s3 and the other sentences:s1 Militants attacked a market in Jerusalem.s2 Arafat condemned the bombing.s3 The Wye River Accord was signed in Oct.Discourse theories have proposed a variety of re-lationships between sentences such as backgroundand interpretation.
RST has 17 such relations (Mannand Thompson, 1988) and PDTB has 16 (Prasad etal., 2008).
While we seek to identify pairs of sen-tences that have a relationship, we do not attempt tolabel the edges with the exact relation.We use textual cues from the discourse literaturein combination with the redundancy inherent in re-lated documents to generate edges.
Because thismethodology is noisy, the graph used by G-FLOW isan approximation, which we refer to as an approx-imate discourse graph (ADG).
We first describe theconstruction of this graph, and then discuss the useof the graph for summary generation (Section 4).3.1 Deverbal Noun ReferenceOften, the main description of an event is mentionedin a verbal phrase and subsequent references usedeverbal nouns (nominalization of verbs) (e.g., ?at-tacked?
and ?the attack?).
In this example, the nounis derivationally related to the verb, but that is not al-ways the case.
For example, ?bombing?
in s2 aboverefers to ?attacked?
in s1.We identify verb-noun pairs with this relationshipas follows.
First, we locate a set of candidate pairsfrom WordNet: for each verb v, we determine po-tential noun references n using a path length of up totwo in WordNet (moving from verb to noun is pos-sible via WordNet?s ?derivationally related?
links).This set captures verb-noun pairs such as (?to at-tack?, ?bombing?
), but also includes generic pairssuch as (?to act?, ?attack?).
To filter such errorswe score the candidate references.
Our goal is toemphasize common pairs and to deemphasize pairswith common verbs or verbs that map to manynouns.
To this end, we score pairs by (c/p) ?
(c/q),where c is the number of times the pair (v, n) ap-pears in adjacent sentences, p is the number of timesthe verb appears, and q is the number of times thatv appears with a different noun.
We generate thesestatistics over a background corpus of 60,000 arti-cles from the New York Times and Reuters, andfilter out candidate pairs scoring below a thresholdidentified over a small training set.We construct edges in the ADG between pairs ofsentences containing these verb to noun mappings.To our knowledge, we are the first to use deverbalnouns for summarization.3.2 Event/Entity ContinuationOur second indicator is related to lexical chains(Barzilay and Lapata, 2008).
We add an edge inthe ADG from a sentence si to sj if they containthe same event or entity and the timestamp of si isless than or equal to the timestamp of sj (timestampsgenerated with (Chang and Manning, 2012)).3.3 Discourse MarkersWe use 36 explicit discourse markers (e.g., ?but?,?however?, ?moreover?)
to identify edges betweentwo adjacent sentences of a document (Marcu andEchihabi, 2002).
This indicator lets us learn an edgefrom s4 to s5 below:s4 Arafat condemned the bombing.s5 However, Netanyahu suspended peace talks.3.4 Inferred EdgesWe exploit the redundancy of information in MDSdocuments to infer edges to related sentences.
Anedge (s, s??)
can be inferred if there is an existingedge (s, s?)
and s?
and s??
express similar informa-tion.
As an example, the edge (s6, s7) can be in-ferred based on edge (s4, s5):s6 Arafat condemned the attack.s7 Netanyahu has suspended the talks.To infer edges we need an algorithm to identifysentences expressing similar information.
To iden-tify these pairs, we extract Open Information Extrac-tion (Banko et al 2007) relational tuples for eachsentence, and we mark any pair of sentences withan equivalent relational tuple as redundant (see Sec-tion 4.3).
The inferred edges allow us to propagatewithin-document discourse information to sentencesfrom other documents.3.5 Co-referent MentionsA sentence sj will not be clearly understood in iso-lation and may need another sentence si in its con-text, if sj has a general reference (e.g., ?the presi-1166dent?)
pointing to a specific entity or event in si (e.g.,?President Bill Clinton?).
We construct edges basedon coreference mentions, as predicted by Stanford?scoreference system (Lee et al 2011).
We are ableto identify syntactic edge (s8, s9):s8 Pres.
Clinton expressed sympathy for Israel.s9 He said the attack should not derail the deal.3.6 Edge WeightsWe weight each edge in the ADG by adding thenumber of distinct indicators used to construct thatedge ?
if sentences s and s?
have an edge becauseof a discourse marker and a deverbal reference, theedge weight wG(s, s?)
will be two.
We also includenegative edges in the ADG.
wG(s, s?)
is negative ifs?
contains a deverbal noun reference, a discoursemarker, or a co-reference mention that is not fulfilledby s. For example, if s?
contains a discourse marker,and s is neither the sentence directly preceding s?and there is no inferred discourse link between s ands?, then we will add a negative edge wG(s, s?
).3.7 Preliminary Graph EvaluationWe evaluated the quality of the ADG used by G-FLOW, which is important not only for its use inMDS, but also because the ADG may be used forother applications like topic tracking and decompos-ing an event into sub-events.
One author randomlychose 750 edges and labeled an edge correct if thepair of sentences did have a discourse relationshipbetween them and incorrect otherwise.
62% of theedges accurately reflected a discourse relationship.Our ADG has on average 31 edges per sentence fora dataset in which each document cluster has on av-erage 253 sentences.
This evaluation includes onlythe positive edges.4 Summary GenerationWe denote a candidate summary X to be a sequenceof sentences ?x1, x2, .
.
.
, x|X|?.
G-FLOW?s summa-rization algorithm searches through the space of or-dered summaries and scores each candidate sum-mary along the dimensions of coherence (Section4.1), salience (Section 4.2) and redundancy (Section4.3).
G-FLOW returns the summary that maximizesa joint objective function (Section 4.4).weight feature-0.037 position in document0.033 from first three sentences-0.035 number of people mentions0.111 contains money0.038 sentence length > 200.137 length of sentence0.109 #sentences verbs appear in (any form)0.349 #sentences common nouns appear in0.355 #sentences proper nouns appear inTable 2: Linear regression features for salience.4.1 CoherenceG-FLOW estimates coherence of a candidate sum-mary via the ADG.
We define coherence as the sumof edge weights between successive summary sen-tences.
For disconnected sentence pairs, the edgeweight is zero.Coh(X) =?i=1..|X|?1wG+(xi, xi+1) + ?wG?
(xi, xi+1)wG+ represents positive edges and wG?
representsnegative edge weights.
?
is a tradeoff coefficient forpositive and negative weights, which is tuned usingthe methodology described in Section 4.4.4.2 SalienceSalience is the inherent value of each sentence tothe documents.
We compute salience of a summary(Sal(X)) as the sum of the saliences of individualsentences (?i Sal(xi)).To estimate salience of a sentence, G-FLOW usesa linear regression classifier trained on ROUGEscores over the DUC?03 dataset.
The classifier usessurface features designed to identify sentences thatcover important concepts.
The complete list of fea-tures and learned weights is in Table 2.
The clas-sifier finds a sentence more salient if it mentionsnouns or verbs that are present in more sentencesacross the documents.
The highest ranked featuresare the last three ?
number of other sentences thatmention a noun or a verb in the given sentence.
Weuse the same procedure as in deverbal nouns for de-tecting verb mentions that appear as nouns in othersentences (Section 3.1).4.3 RedundancyWe also wish to avoid redundancy.
G-FLOW firstprocesses each sentence with a state-of-the-art OpenInformation extractor OLLIE (Mausam et al 2012),which converts a sentence into its component re-lational tuples of the form (arg1, relational phrase,1167arg2).3 For example, it finds (Militants, bombed, amarketplace) as a tuple from sentence s12.Two sentences will express redundant informationif they both contain the same or synonymous com-ponent fact(s).
Unfortunately, detecting synonymyeven at relational tuple level is very hard.
G-FLOWapproximates this synonymy by considering two re-lational tuples synonymous if the relation phrasescontain verbs that are synonyms of each other, haveat least one synonymous argument, and are times-tamped within a day of each other.
Because the in-put documents cover related events, these relativelyweak rules provide good performance.
The samealgorithm is used for inferring edges for the ADG(Section 3.4).
This algorithm can detect that the fol-lowing sentences express redundant information:s12 Militants bombed a marketplace in Jerusalem.s13 He alerted Arafat after assailants attacked thebusy streets of Mahane Yehuda.4.4 Objective FunctionThe objective function needs to balance coherence,salience and redundancy and also honor the givenbudget, i.e., maximum summary lengthB.
G-FLOWtreats redundancy and budget as hard constraints andcoherence and salience as soft.
Coherence is neces-sarily soft as the graph is approximate.
While previ-ous MDS systems specifically maximized coverage,in preliminary experiments on a development set, wefound that adding a coverage term did not improveG-FLOW?s performance.
We optimize:maximize: F (x) , Sal(X) + ?Coh(X)?
?|X|s.t.
?i=1..|X| len(xi) < B?xi, xj ?
X : redundant(xi, xj) = 0Here len refers to the sentence length.
We add |X|term (the number of sentences in the summary) toavoid picking many short sentences, which may in-crease coherence and salience scores at the cost ofoverall summary quality.The parameters ?, ?
and ?
(see Section 4.1) aretuned automatically using a grid search over a de-velopment set as follows.
We manually generate ex-tractive summaries for each document cluster in ourdevelopment set (DUC?03) and choose the parame-ter setting that minimizes |F (XG-FLOW) ?
F (X?
)|3Available from http://ollie.cs.washington.edusummed over all document clusters.
F is the objec-tive function, XG-FLOW is the summary produced byG-FLOW and X?
is the manual summary.This constraint optimization problem is NP hard,which can be shown by using a reduction of thelongest path problem.
For this reason, G-FLOW useslocal search to reach an approximation of the opti-mum.
G-FLOW employs stochastic hill climbingwith random restarts as the base search algorithm.At each step, the search either adds a sentence, re-moves a sentence, replaces a sentence by another, orreorders a pair of sentences.
The initial summary forrandom restarts is constructed as follows.
We firstpick the highest salience sentence with no incomingnegative edges as the first sentence.
The followingsentences are probabilistically added one at a timebased on the summary score up to that sentence.
Theinitial summary is complete when there are no possi-ble sentences left to fit within the budget.
Intuitively,this heuristic chooses a good starting point by se-lecting a first sentence that does not rely on contextand subsequent sentences that build a high scoringsummary.
As with all local search algorithms, thisalgorithm is highly scalable and can easily apply tolarge collections of related documents, but does notguarantee global optima.5 ExperimentsBecause summaries are intended for human con-sumption we focused on human evaluations.
Wehired workers on Amazon Mechanical Turk (AMT)to evaluate the summaries.
Our evaluation addressesthe following questions: (1) how do G-FLOW sum-maries compare against the state-of-the-art in MDS(Section 5.2)?
(2) what is G-FLOW?s performancealong important summarization dimensions such ascoherence and redundancy (Section 5.3)?
(3) howdoes G-FLOW perform on coverage as measuredby ROUGE (Section 5.3.1)?
(4) how much do thecomponents of G-FLOW?s objective function con-tribute to performance (Section 5.4)?
(5) how do G-FLOW?s summaries compare to human summaries?5.1 Data and SystemsWe evaluated the systems on the Task 2 DUC?04multi-document summarization dataset.
This datasetconsists of 50 clusters of related documents, each ofwhich contains 10 documents.
Each cluster of doc-1168uments also includes four gold standard summariesused for evaluation.
As in the DUC?04 competition,we allowed 665 bytes for each summary includingspaces and punctuation.
We used DUC?03 as ourdevelopment set, which contains 30 document clus-ters, again with approximately 10 documents each.We compared G-FLOW against four systems.
Thefirst is a recent MDS extractive summarizer, whichwe choose for its state-of-the-art ROUGE scores(Lin and Bilmes, 2011).4 The second is a pipelineof Lin?s system followed by a reimplementation ofa state-of-the-art sentence reordering system (Li etal., 2011a).
We refer to these systems as LIN andLIN-LI, respectively.
This second baseline allowsus to quantify the advantage of using coherence as afactor in both sentence extraction and ordering.We also compare against the system that had thehighest coherence ratings at DUC?04 (Nobata andSekine, 2004), which we refer to as NOBATA.
Asthis system did not preform sentence ordering on itsoutput, we also compare against a pipeline of No-bata?s system and the sentence reordering system.We refer to this system as NOBATA-LI.Lastly, to evaluate how well the system performsagainst human generated summaries, we compareagainst the gold standard summaries provided byDUC.5.2 Overall Summary QualityFollowing (Haghighi and Vanderwende, 2009) and(Celikyilmaz and Hakkani-Tur, 2010), to compareoverall summary quality, we asked AMT workersto compare two candidate system summaries.
Theworkers first read a gold standard summary, fol-lowed by the two system summaries, and were thenasked to choose the better summary from the pair.The system summaries were shown in a random or-der to remove any bias.To ensure that workers provided high quality datawe added two quality checks.
First, we restrictedto workers who have an overall approval rating ofover 95% on AMT.
Second, we asked the workersto briefly describe the main events of the summary.We manually filtered out work where this descrip-tion was incorrect.4We thank Lin and Bilmes for providing us with their code.Unfortunately, we were unable to obtain other recent MDS sys-tems from their authors.Six workers compared each pair of summaries.We recorded the scores for each cluster, and reportthree numbers: the percentages of clusters where asystem is more often preferred over the other and thepercentage where the two systems are tied.
G-FLOWis preferred almost three times as often as LIN:G-FLOW Indifferent LIN56% 24% 20%Next, we compared G-FLOW and LIN-LI.
Sen-tence reordering improves performance, but G-FLOW is still overwhelmingly preferred:G-FLOW Indifferent LIN-LI54% 24% 22%These results suggest that incorporating coher-ence in sentence extraction adds significant value toa summarization system.
In these experiments, LINand LIN-LI are preferred in some cases.
We an-alyzed those summaries more carefully, and foundthat occasionally, G-FLOW will sacrifice a smallamount of coverage for coherence, resulting in lowerperformance in those cases (see Section 5.3.1).We also compared LIN and LIN-LI, and foundthat reordering does not improve performance bymuch.LIN-LI Indifferent LIN32% 38% 30%While the scores presented above represent com-parisons between G-FLOW and a summarizationsystem with state-of-the-art ROUGE scores, wealso compared against a summarization system withstate-of-the-art coherence scores ?
the system withthe highest coherence scores from DUC?04, (No-bata and Sekine, 2004).
We found that G-FLOW wasagain preferred:G-FLOW Indifferent NOBATA68% 10% 22%Adding in sentence ordering again improved thescores for the comparison system somewhat:G-FLOW Indifferent NOBATA-LI60% 20% 20%While these scores show a significant improve-ment over previous sytems, they do not convey howwell G-FLOW compares to the gold standard ?
man-ually generated summaries.
As a final experiment,we compared G-FLOW and a second, manually gen-erated summary:1169G-FLOW Indifferent Gold14% 18% 68%While we were pleased that in 32% of the cases,Turkers either preferred G-FLOW or were indiffer-ent, there is clearly a lot of room for improvementdespite the gains reported over previous sytems.5.3 Comparison along Summary DimensionsA high quality summary needs to be good along sev-eral dimensions.
We asked AMT workers to ratesummaries using the quality questions enumeratedin DUC?04 evaluation scheme.5 These questionsconcern: (1) coherence, (2) useless, confusing, orrepetitive text, (3) redundancy, (4) nouns, pronouns,and personal names that are not well-specified (5)entities rementioned in an overly explicit way, (6)ungrammatical sentences, and (7) formatting errors.We evaluated G-FLOW LIN-LI and NOBATA-LIagainst the gold standard summaries, using the sameAMT scheme as in the previous section.
To assessautomated performance with respect to the standardsset by human summaries, we also evaluated a (dif-ferent) gold standard summary for each documentcluster, using the same Mechanical Turk scheme asin the previous section.
The 50 summaries producedby each system were evaluated by four workers.
Theresults are shown in Figure 2.G-FLOW was rated significantly better than LIN-LI in all categories except ?Redundancy?
and signif-icant better than NOBATA-LI on ?Coherence?
and?Referents?.
The ratings for ?Coherence?, ?Refer-ents?, and ?OverlyExplicit?
are not surprising givenG-FLOW?s focus on coherence.
The results for?UselessText?
may also be due to G-FLOW?s focuson coherence which ideally prevents it from gettingoff topic.
Lastly, G-FLOW may perform better on?Grammatical?
and ?Formatting?
because it tends tochoose longer sentences than other systems, whichare less likely to be sentence segmentation errors.There may also be some bleeding from one dimen-sion to the other ?
if a worker likes one summary shemay score it highly for many dimensions.Finally, somewhat surprisingly, we find G-FLOW?s performance to be nearly that of humansummaries.
G-FLOW is rated statistically signifi-cantly lower than the gold summaries on only ?Re-5http://duc.nist.gov/duc2004/quality.questions.txtSystem R FNOBATA 30.44 34.36Best system in DUC-04 38.28 37.94Takamura and Okumura (2009) 38.50 -LIN 39.35 38.90G-FLOW 37.33 37.43Gold Standard Summaries 40.03 40.03Table 3: ROUGE-1 recall and F-measure results (%) onDUC-04.
Some values are missing because not all sys-tems reported both F-measure and recall.dundancy?.
Given the results from the previous sec-tion, G-FLOW is likely performing worse on cate-gories not conveyed in these scores, such as Cover-age, which we examine next.5.3.1 Coverage Evaluation using ROUGEMost recent research has focused on the ROUGEevaluation, and thus implicitly on coverage of in-formation in a summary.
To estimate the coverageof G-FLOW, we compared the systems on ROUGE(Lin, 2004).
We calculated ROUGE-1 scores forG-FLOW, LIN, and NOBATA.6 As sentence order-ing does not matter for ROUGE, we do not includeLIN-LI or NOBATA-LI in this evaluation.
Becauseour algorithm does not explicitly maximize coveragewhile LIN does, we expected G-FLOW to performslightly worse than LIN.The ROUGE-1 scores for G-FLOW, LIN, NO-BATA and other recent MDS systems are listed in Ta-ble 3.
We also include the ROUGE-1 scores for thegold summaries (compared to the other gold sum-maries).
G-FLOW has slightly lower scores thanLIN and the gold standard summaries, but muchhigher scores than NOBATA.
G-FLOW only scoressignificantly lower than LIN and the gold standardsummaries.We can conclude that good summaries have boththe characteristics listed in the quality dimensions,and good coverage.
The gold standard summariesoutperform G-FLOW on both ROUGE scores andthe quality dimension scores, and therefore, out-perform G-FLOW on overall comparison.
How-ever, G-FLOW is preferred to LIN-LI in addition toNOBATA-LI indicating that its quality scores out-weigh its ROUGE scores in that comparison.
Animprovement to G-FLOW may focus on increasing6ROUGE version 1.5.5 with options: -a -c 95 -b 665 -m -n4 -w 1.21170Coherence UselessText Redundancy Referents OverlyExplicit Grammatical FormattingRating01234GoldG?FlowNobata?LiLin?LiFigure 2: Ratings for the systems.
0 is the lowest possible score and 4 is the highest possible score.
G-FLOW is ratedsignificantly higher than LIN-LI on all categories, except for ?Redundancy?, and significantly higher than NOBATA-LIon ?Coherence?
and ?Referents?.
G-FLOW is only significantly lower than the gold standard on ?Redundancy?.coverage while retaining strengths such as coher-ence.5.4 Ablation ExperimentsIn this ablation study, we evaluated the contributionof the main components of G-FLOW ?
coherenceand salience.
The details of the experiments are thesame as in the experiment described in Section 5.2.We first measured the importance of coherence insummary generation.
This system G-FLOW-SAL isidentical to the full system except that it does notinclude the coherence term in the objective function(see Section 4.4).
The results show that coherence isvery important to G-FLOW?s performance:G-FLOW Indifferent G-FLOW-SAL54% 26% 20%Similarly, we evaluated the contribution ofsalience.
This system G-FLOW-COH does not in-clude the salience term in the objective function:G-FLOW Indifferent G-FLOW-COH60% 20% 20%Without salience, the system produces readable,but highly irrelevant summaries.5.5 Agreement of Expert & AMT WorkersBecause summary evaluation is a relatively complextask, we compared AMT workers?
annotations withexpert annotations from DUC?04.
We randomlyselected ten summaries from each of the sevenDUC?04 annotators, and asked four Turk workersto annotate them on the DUC?04 quality questions.For each DUC?04 annotator, we selected all pairsof summaries where one summary was judged morethan one point better than the other summary.
Wecompared whether the workers (voting as in Sec-tion 5.2) likewise judged that summary better thanthe second summary.
We found that the annotationsagreed in 75% of cases.
When we looked only atpairs more than two points different, the agreementwas 80%.
Thus, given the subjective nature of thetask, we feel reasonably confident that the AMT an-notations are informative, and that the dramatic pref-erence of G-FLOW over the baseline systems is dueto a substantial improvement in its summaries.6 ConclusionIn this paper, we present G-FLOW, a multi-document summarization system aimed at generat-ing coherent summaries.
While previous MDS sys-tems have focused primarily on salience and cov-erage but not coherence, G-FLOW generates an or-dered summary by jointly optimizing coherence andsalience.
G-FLOW estimates coherence by usingan approximate discourse graph, where each nodeis a sentence from the input documents and eachedge represents a discourse relationship betweentwo sentences.
Manual evaluations demonstrate thatG-FLOW generates substantially better summariesthan a pipeline of state-of-the-art sentence selec-tion and reordering components.
ROUGE scores,which measure summary coverage, show that G-FLOW sacrifices a small amount of coverage foroverall readability and coherence.
Comparisons togold standard summaries show that G-FLOW mustimprove in coverage to equal the quality of manu-ally written summaries.
We believe this research hasapplications to other areas of summarization such asupdate summarization and query based summariza-tion, and we are interested in investigating these top-ics in future work.1171AcknowledgementsWe thank Luke Zettlemoyer, Lucy Vanderwende, HalDaume III, Pushpak Bhattacharyya, Chris Quirk, ErikFrey, Tony Fader, Michael Schmitz, Alan Ritter, MelissaWinstanley, and the three anonymous reviewers for help-ful conversations and feedback on earlier drafts.
We alsothank Lin and Bilmes for providing us with the code fortheir system.
This research was supported in part by NSFgrant IIS-0803481, ONR grant N00014-11-1-0294, andDARPA contract FA8750-13-2-0019, and carried out atthe University of Washington?s Turing Center.
This pa-per was also supported in part by the Intelligence Ad-vanced Research Projects Activity (IARPA) via Air ForceResearch Laboratory (AFRL) contract number FA8650-10-C-7058.
The U.S. Government is authorized to repro-duce and distribute reprints for Governmental purposesnotwithstanding any copyright annotation thereon.
Theviews and conclusions contained herein are those of theauthors and should not be interpreted as necessarily rep-resenting the official policies or endorsements, either ex-pressed or implied, of IARPA, AFRL, or the U.S. Gov-ernment.ReferencesAmjad Abu-Jbara and Dragomir R. Radev.
2011.
Coher-ent citation-based summarization of scientific papers.In Proceedings of ACL 2011, pages 500?509.Ahmet Aker, Trevor Cohn, and Robert Gaizauskas.
2010.Multi-document summarization using A * search anddiscriminative training.
In Proceedings of EMNLP2010.Michele Banko, Michael Cafarella, Stephen Soderland,Matt Broadhead, and Oren Etzioni.
2007.
Open in-formation extraction from the web.
In Proceedings ofIJCAI 2007, pages 68?74.Regina Barzilay and Michael Elhadad.
1997.
Using lex-ical chains for text summarization.
In Proceedings ofthe ACL Workshop on Intelligent Scalable Text Sum-marization, pages 10?17.Regina Barzilay and Mirella Lapata.
2008.
Modelinglocal coherence: An entity-based approach.
Computa-tional Linguistics, 34(1):1?34.Regina Barzilay, Noemie Elhadad, and Kathleen R McK-eown.
2001.
Sentence ordering in multidocumentsummarization.
In Proceedings of HLT 2001, pages1?7.Danushka Bollegala, Naoaki Okazaki, and MitsuruIshizuka.
2010.
A bottom-up approach to sentenceordering for multi-document summarization.
Informa-tion Process Management, 46(1):89?109.Jaime Carbonell and Jade Goldstein.
1998.
The use ofMMR, diversity-based reranking for reordering docu-ments and producing summaries.
In Proceedings ofSIGIR 1998, pages 335?336.Asli Celikyilmaz and Dilek Hakkani-Tur.
2010.
A hy-brid hierarchical model for multi-document summa-rization.
In Proceedings of ACL 2010, pages 815?824.Angel Chang and Christopher Manning.
2012.
SU-TIME: A library for recognizing and normalizing timeexpressions.
In Proceedings of LREC 2012.Gunes Erkan and Dragomir R Radev.
2004.
LexRank:Graph-based centrality as salience in text summa-rization.
Journal of Artificial Intelligence Research,22(1):457?479.Barbara Grosz and Candace Sidner.
1986.
Attention,intentions, and the structure of discourse.
Computa-tional Linguistics, 12(3):175?204.Aria Haghighi and Lucy Vanderwende.
2009.
Explor-ing content models for multi-document summariza-tion.
Proceedings of NAACL 2009, pages 362?370.Maria Lucia Castro Jorge and Thiago Alexan-dre Salgueiro Pardo.
2010.
Multi-DocumentSummarization: Content Selection based on CSTModel (Cross-document Structure Theory).
Ph.D.thesis, Nu?cleo Interinstitucional de Lingu??
?sticaComputacional (NILC).Mirella Lapata.
2003.
Probabilistic text structuring: Ex-periments with sentence ordering.
In Proceedings ofACL 2003, pages 545?552.Heeyoung Lee, Yves Peirsman, Angel Chang, NathanaelChambers, Mihai Surdeanu, and Dan Jurafsky.
2011.Stanford?s multi-pass sieve coreference resolution sys-tem at the CoNLL-2011 shared task.
In CoNLL 2011Shared Task.Peifeng Li, Guangxi Deng, and Qiaoming Zhu.
2011a.Using context inference to improve sentence orderingfor multi-document summarization.
In Proceedings ofIJCNLP 2011, pages 1055?1061.Peng Li, Yinglin Wang, Wei Gao, and Jing Jiang.
2011b.Generating aspect-oriented multi-document summa-rization with event-aspect model.
In Proceedings ofEMNLP 2011, pages 1137?1146.Hui Lin and Jeff Bilmes.
2011.
A class of submodularfunctions for document summarization.
In Proceed-ings of ACL 2011, pages 510?520.Chin-Yew Lin.
2004.
ROUGE: A package for auto-matic evaluation of summaries.
In Text SummarizationBranches Out: Proceedings of the ACL-04 Workshop,pages 74?81.Annie Louis and Ani Nenkova.
2009.
Automatic sum-mary evaluation without using human models.
In Pro-ceedings of EMNLP 2009, pages 306?314.Annie Louis, Aravind Joshi, Rashmi Prasad, and AniNenkova.
2010.
Using entity features to classify im-plicit discourse relations.
In Proceedings of SIGDIAL2010, pages 59?62.1172Inderjeet Mani.
2001.
Automatic Summarization.
JohnBenjamins Publishing Co, Amsterdam/Philadelphia.William C. Mann and Sandra A. Thompson.
1988.Rhetorical structure theory: Toward a functional the-ory of text organization.
Text, 8(3):243?281.Daniel Marcu and Abdessamad Echihabi.
2002.
Anunsupervised approach to recognizing discourse rela-tions.
In Proceedings of ACL 2002, pages 368?375.Daniel Marcu.
1997.
From discourse structures to textsummaries.
In Proceedings of the ACL Workshop onIntelligent Scalable Text Summarization, pages 82?88.Mausam, Michael Schmitz, Robert Bart, Stephen Soder-land, and Oren Etzioni.
2012.
Open language learningfor information extraction.
In Proceedings of EMNLP2012, pages 523?534.Kathleen McKeown and Dragomir Radev.
1995.
Gen-erating summaries of multiple news articles.
In Pro-ceedings of SIGIR 1995, pages 74?82.Chikashi Nobata and Satoshi Sekine.
2004.
Crl/nyusummarization system at duc-2004.
In Proceedings ofDUC 2004.Naoaki Okazaki, Yutaka Matsuo, and Mitsuru Ishizuka.2004.
Improving chronological sentence ordering byprecedence relation.
In Proceedings of COLING 2004,pages 750?756.Emily Pitler, Annie Louis, and Ani Nenkova.
2010.Automatic evaluation of linguistic quality in multi-document summarization.
In Proceedings of ACL2010, pages 544?554.Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Milt-sakaki, Livio Robaldo, Aravind Joshi, and BonnieWebber.
2008.
The Penn Discourse TreeBank 2.0.In Proceedings of LREC 2008.Vahed Qazvinian, Dragomir R. Radev, and ArzucanO?zgu?r.
2010.
Citation summarization throughkeyphrase extraction.
In Proceedings of COLING2010, pages 895?903.Dragomir R. Radev and Kathleen R. McKeown.
1998.Generating natural language summaries from mul-tiple on-line sources.
Computational Linguistics,24(3):469?500.Dragomir R. Radev, Hongyan Jing, Malgorzata Stys, andDaniel Tam.
2004.
Centroid-based summarizationof multiple documents.
Information Processing andManagement, 40(6):919?938.Dragomir R. Radev.
2004.
LexRank: Graph-based lexi-cal centrality as salience in text summarization.
Jour-nal of Artificial Intelligence Research, 22(1):457?479.Horacio Saggion and Robert Gaizauskas.
2004.
Multi-document summarization by cluster/profile relevanceand redundancy removal.
In Proceedings of DUC2004.Horacio Saggion and Guy Lapalme.
2002.
Generatingindicative-informative summaries with sumUM.
Com-putational Linguistics, 28(4):497?526.Dafna Shahaf and Carlos Guestrin.
2010.
Connecting thedots between news articles.
In Proceedings of KDD2010, pages 623?632.Chao Shen and Tao Li.
2010.
Multi-document summa-rization via the minimum dominating set.
In Proceed-ings of Coling 2010, pages 984?992.Maite Taboada and William C. Mann.
2006.
Applica-tions of rhetorical structure theory.
Discourse Studies,8(4):567?588.Hiroya Takamura and Manabu Okumura.
2009.
Textsummarization model based on maximum coverageproblem and its variant.
In Proceedings of EACL 2009,pages 781?789.Florian Wolf and Edward Gibson.
2005.
Representingdiscourse coherence: A corpus-based study.
Compu-tational Linguistics, 31(2):249?288.Zhu Zhang, Sasha Blair-Goldensohn, and Dragomir R.Radev.
2002.
Towards CST-enhanced summarization.In Proceedings of AAAI 2002, pages 439?445.Renxian Zhang, Li Wenjie, and Lu Qin.
2010.
Sen-tence ordering with event-enriched semantics and two-layered clustering for multi-document news summa-rization.
In Proceedings of COLING 2010, pages1489?1497.1173
