DATE: A Dialogue Act Tagging Scheme for Evaluation ofSpoken Dialogue SystemsMarilyn Walker and Rebecca PassonneauAT&T Shannon Labs180 Park Ave.Florham Park, N.J. 07932 fwalker,beckyg@research.att.comABSTRACTThis paper describes a dialogue act tagging scheme developed forthe purpose of providing finer-grained quantitative dialogue met-rics for comparing and evaluating DARPA COMMUNICATOR spo-ken dialogue systems.
We show that these dialogue act metrics canbe used to quantify the amount of effort spent in a dialogue main-taining the channel of communication or, establishing the framefor communication, as opposed to actually carrying out the travelplanning task that the system is designed to support.
We show thatthe use of these metrics results in a 7% improvement in the fit inmodels of user satisfaction.
We suggest that dialogue act metricscan ultimately support more focused qualitative analysis of the roleof various dialogue strategy parameters, e.g.
initiative, across di-alogue systems, thus clarifying what development paths might befeasible for enhancing user satisfaction in future versions of thesesystems.1.
INTRODUCTIONRecent research on dialogue is based on the assumption that di-alogue acts provide a useful way of characterizing dialogue behav-iors in human-human dialogue, and potentially in human-computerdialogue as well [16, 27, 11, 7, 1].
Several research efforts haveexplored the use of dialogue act tagging schemes for tasks suchas improving recognition performance [27], identifying importantparts of a dialogue [12], and as a constraint on nominal expres-sion generation [17].
This paper reports on the development anduse of a dialogue act tagging scheme for a rather different task:the evaluation and comparison of spoken dialogue systems in thetravel domain.
We call this scheme DATE: Dialogue Act Taggingfor Evaluation.Our research on the use of dialogue act tagging for evaluationfocuses on the corpus of DARPA COMMUNICATOR dialogues col-lected in the June 2000 data collection [28].
This corpus consists of662 dialogues from 72 users calling the nine different COMMUNI-CATOR travel planning systems.
Each system implemented a log-file standard for logging system behaviors and calculating a set ofcore metrics.
Each system utterance and each recognizer result waslogged, and user utterances were transcribed and incorporated into.the logfiles.
The logfile standard supported the calculation of met-rics that were hypothesized to potentially affect the user?s percep-tion of the system; these included task duration, per turn measures,response latency measures and ASR performance measures.
Eachdialogue was also hand labelled for task completion.The hypothesis underlying our approach is that a system?s di-alogue behaviors have a strong effect on the user?s perception ofthe system.
Yet the core metrics that were collected via the logfilestandard represent very little about dialogue behaviors.
For exam-ple, the logging counts system turns and tallies their average length,but doesn?t distinguish turns that reprompt the user, or give in-structions, from those that present flight information.
Furthermore,each COMMUNICATOR system had a unique dialogue strategy and aunique way of achieving particular communicative goals.
Thus, inorder to explore our hypothesis about the differential effect of thesestrategies, we needed a way to characterize system dialogue behav-iors that would capture such differences yet be applied uniformly toall nine systems.
While some sites logged system dialogue behav-iors using site-specific dialogue act naming schemes, there existedno scheme that could be applied across sites.Our goal was thus to develop a dialogue act tagging scheme thatwould capture important distinctions in this set of dialogues; thesedistinctions must be useful for testing particular hypotheses aboutdifferences among dialogue systems.
We also believed that it wasimportant for our tagging scheme to allow for multiple views ofeach dialogue act.
This would allow us, for example, to investigatewhat part of the task an utterance contributes to separately fromwhat speech act function it serves.
A central claim of the paper isthat these goals require a tagging scheme that makes distinctionswithin three orthogonal dimensions of utterance classification: (1)a SPEECH-ACT dimension; (2) a TASK-SUBTASK dimension; and(3) a CONVERSATIONAL-DOMAIN dimension.
Figure 1 shows aCOMMUNICATOR dialogue with each system utterance classifiedon these three dimensions.
The labels on each utterance are fullydescribed in the remainder of the paper.Sections 2, 3, and 4, describe the three dimensions of DATE.
Inthese sections, we describe two aspects of our annotation schemethat are not captured in existing tagging schemes, which we be-lieve are important for characterizing how much effort in a dialogueis devoted to the task versus different kinds of dialogue mainte-nance.
Section 5 describes how the dialogue act labels are assignedto system utterances and section 6 discusses results showing thatthe DATE dialogue act metrics improve models of user satisfactionby an absolute 7% (an increase from 38% to 45%).
The dialogueueact metrics that are important predictors of user satisfaction are var-ious kinds of meta-dialogue, apologies and acts that may be land-marks for achieving particular dialogueue subtasks.
In section 7 wesummarize the paper, discuss our claim that a dialogue annotationscheme is a partial model of a natural class of dialogues, and dis-cuss the ways in which the DATE scheme may be generalizable toother dialogue corpora.2.
CONVERSATIONAL DOMAINSThe CONVERSATIONAL-DOMAIN dimension characterizes eachutterance as primarily belonging to one of three arenas of conver-sational action.
The first arena is the domain task, which in thiscase is air travel booking, and which we refer to below as ABOUT-TASK.
The second domain of conversational action is the manage-ment of the communication channel, which we refer to as ABOUT-COMMUNICATION.
This distinction has been widely adopted [19,2, 9].
In addition, we identify a third domain of talk that we referto as ABOUT-SITUATION-FRAME.
This domain is particularly rel-evant for distinguishing human-computer from human-human dia-logues, and for distinguishing dialogue strategies across the 9 COM-MUNICATOR systems.
Each domain is described in this section.2.1 About-TaskThe ABOUT-TASK domain reflects the fact that many utterancesin a task-oriented dialogue originate because the goal of the dia-logue is to complete a particular task to the satisfaction of bothparticipants.
Typically an about-task utterance directly asks for orpresents task-related information, or offers a solution to a task goal.As Figure 1 shows, most utterances are in the ABOUT-TASK di-mension, reflecting the fact that the primary goal of the dialogueis to collaborate on the task of making travel arrangements.
Thetask column of Figure 1 specifies the subtask that each task-relatedutterance contributes to.
DATE includes a large inventory of sub-tasks in the task/subtask dimension in order to make fine-graineddistinctions regarding the dialogue effort devoted to the task or itssubcomponents.
Section 4 will describe the task model in moredetail.2.2 About-CommunicationThe ABOUT-COMMUNICATION domain reflects the system goalof managing the verbal channel and providing evidence of whathas been understood [29, 8, 25].
Although utterances of this typeoccur in human-human dialogue, they are more frequent in human-computer dialogue, where they are motivated by the need to avoidpotentially costly errors arising from imperfect speech recognition.In the COMMUNICATOR corpus, many systems use a conserva-tive strategy of providing feedback indicating the system?s under-standing of the information provided by the user after each userturn.
A typical example is the repetition of the origin and des-tination cities in Figures 1 and 6.
This type of repetition is theIMPLICIT-CONFIRMATION speech-act (see Section 3 below).
Somesystems used a variable confirmation strategy where some informa-tion items may be confirmed as they are understood, but the systemrequests explicit confirmation of all task parameters before search-ing the database for matching flights.
An example is in Figure 2.Here the system asks for explicit confirmation in SYS3 before go-ing to the database.
This is the first opportunity that the user hasfor making a correction, which he does in USER3.
The systemthen again asks for explicit confirmation of its new understanding,which the user provides in USER4.
After the user informs the sys-tem that it is a one-way flight in USER6, the system accesses thedatabase.
These explicit confirmations have the goal of avoidinga costly database lookup, where the retrieval is conditioned on thewrong parameters.All implicit and explicit confirmation speech-acts are catego-rized as ABOUT-COMMUNICATION because they are motivated bythe potential errors that the system might make in understandingSpeaker UtteranceSYS1 ....What are your travel plans?
?USER1 I WISH TO FLY FROM LEXICON KENTUCKY TOSPRINGFIELD MISSOURI THE MORNING OF OC-TOBER FIFTHSYS2 do you have a preferred airline?USER2 NOSYS3 I have you going from Kentucky to Gainesville Missourion October fifth .
Is that correct?USER3 IT?S LEXINGTON KENTUCKY TO SPRINGFIELDMISSOURISYS4 I have you going from Lexington to Springfield Missourion October fifth, Is that correct?USER4 YESSYS5 Will you return to Lexington from Springfield?USER5 NOSYS6 Is Springfield your final destination?USER6 YESSYS7 Hold on while I check availability..... Three options werereturned.
Option one has a fare of four hundred and thirtythree dollars.....Figure 2: Dialogue Illustrating Variable Confirmation Strategythe caller, or in diagnosing the causes of misunderstandings.
Ingeneral, any utterance that reflects the system?s understanding ofsomething the user said is classified as ABOUT-COMMUNICATION.A second set of ABOUT-COMMUNICATION utterances are APOLO-GIES that the system makes for misunderstandings (see Section 3below), i.e.
utterances such as I?m sorry.
I?m having trouble under-standing you., or My mistake again.
I didn?t catch that.
or I can seeyou are having some problems.The last category of ABOUT-COMMUNICATION utterances arethe OPENINGS/CLOSINGS by which the system greets or says good-bye to the caller.
(Again, see Section 3 below.
)2.3 About Situation-FrameThe SITUATION-FRAME domain pertains to the goal of manag-ing the culturally relevant framing expectations.
The term is in-spired by Goffman?s work on the organization and maintenance ofsocial interaction [13, 14].
An obvious example of a framing as-sumption is that the language of the interaction will be English [13,14].
Another is that there is an asymmetry between the knowledgeand/or agency of the system (or human travel agent) and that of theuser (or caller): the user cannot issue an airline ticket.In developing the DATE tagging scheme, we compared human-human travel planning dialogues collected by CMU with the human-machine dialogues of the June 2000 data collection and noticeda striking difference in the ABOUT-FRAME dimension.
Namely,very few ABOUT-FRAME utterances occur in the human-human di-alogues, whereas they occur frequently enough in human-computerdialogues that to ignore them is to risk obscuring significant differ-ences in habitability of different systems.
In other words, certaindifferences in dialogue strategies across sites could not be fully rep-resented without such a distinction.
Figure 3 provides examplesmotivating this dimension.Dialogue acts that are ABOUT-FRAME are cross-classified as oneof three types of speech-acts, PRESENT-INFO, INSTRUCTION orAPOLOGY.
They are not classified as having a value on the TASK-SUBTASK dimension.
Most of the ABOUT-FRAME dialogue actsfall into the speech-act category of INSTRUCTIONS, utterances di-rected at shaping the user?s behavior and expectations about how tointeract with a machine.
Sites differ regarding how much instruc-tion is provided up-front versus within the dialogue; most sites havedifferent utterance strategies for dialogue-initial versus dialogue-Speech-Act ExamplePRESENT-INFOYou are logged in as a guest user of A T and T Commu-nicator.PRESENT-INFOI?ll enroll you temporarily as a guest user.PRESENT-INFOI know about the top 150 cities worldwide.PRESENT-INFOThis call is being recorded for development purposes,and may be shared with other researchers.PRESENT-INFOI cannot handle rental cars or hotels yet.
Please restrictyour requests to air travel.PRESENT-INFOI heard you ask about fares.
I can only price anitinerary.
I cannot provide information on publishedfares for individual flights.INSTRUCTION First, always wait to hear the beep before you say any-thingINSTRUCTION You can always start over again completely just by say-ing: start over.INSTRUCTION Before we begin, let?s go over a few simple instructions.INSTRUCTION Please remember to speak after the tone.
If you get con-fused at any point you can say start over to cancel yourcurrent itinerary.APOLOGY Sorry, an error has occurred.
We?ll have to start over.APOLOGY I am sorry I got confused.
Thanks for your patience.
Letus try again.APOLOGY Something is wrong with the flight retrieval.APOLOGY I have trouble with my script.Figure 3: Example About-Frame Utterancesmedial instructions.
One site gives minimal up-front framing in-formation; further, the same utterances that can occur up-front alsooccur dialogue-medially.
A second site gives no up-front fram-ing information, but it does provide framing information dialogue-medially.
Yet a third site gives framing information dialogue-initially,but not dialogue-medially.
The remaining sites provide differentkinds of general instructions dialogue-initially, e.g.
(Welcome.
...Youmay say repeat, help me out, start over, or, that?s wrong, you canalso correct and interrupt the system at any time.)
versus dialogue-medially: (Try changing your departure dates or times or a nearbycity with a larger airport.)
This category also includes statementsto the user about the system?s capabilities.
These occur in responseto a specific question or task that the system cannot handle: I can-not handle rental cars or hotels yet.
Please restrict your requeststo air travel.
See Figure 3.Another type of ABOUT-FRAME utterance is the system?s at-tempt to disambiguate the user?s utterance; in response to the userspecifying Springfield as a flight destination, the system indicatesthat this city name is ambiguous (I know of three Springfields, inMissouri, Illinois and Ohio.
Which one do you want?).
The sys-tem?s utterance communicates to the user that Springfield is am-biguous, and goes further than a human would to clarify that thereare only three known options.
It is important for evaluation pur-poses to distinguish the question and the user?s response from asimple question-answer sequence establishing a destination.
A di-rect question, such as What city are you flying to?, functions as aREQUEST-INFO speech act and solicits information about the task.The context here contrasts with a direct question in that the systemhas already asked for and understood a response from the callerabout the destination city.
Here, the function of the system turn isto remediate the caller?s assumptions about the frame by indicatingthe system?s confusion about the destination.
Note that the questionwithin this pattern could easily be reformulated as a more typicalinstruction statement, such as Please specify which Springfield youmean, or Please say Missouri, Illinois or Ohio..3.
THE SPEECH-ACT DIMENSIONThe SPEECH-ACT dimension characterizes the utterance?s com-municative goal, and is motivated by the need to distinguish thecommunicative goal of an utterance from its form.
As an exam-ple, consider the functional category of a REQUEST for information,found in many tagging schemes that annotate speech-acts [24, 18,6].
Keeping the functional category of a REQUEST separate fromthe sentence modality distinction between question and statementmakes it possible to capture the functional similarity between ques-tion and statement forms of requests, e.g., Can you tell me whattime you would like to arrive?
versus Please tell me what time youwould like to arrive.In DATE, the speech-act dimension has ten categories.
We usefamiliar speech-act labels, such as OFFER, REQUEST-INFO, PRESENT-INFO, ACKNOWLEDGMENT, and introduce new ones designed tohelp us capture generalizations about communicative behavior inthis domain, on this task, given the range of system and humanbehavior we see in the data.
One new one, for example, is STATUS-REPORT, whose speech-act function and operational definition arediscussed below.
Examples of each speech-act type are in Figure 4.Speech-Act ExampleREQUEST-INFO And, what city are you flying to?PRESENT-INFO The airfare for this trip is 390 dollars.OFFER Would you like me to hold this option?ACKNOWLEDGMENT I will book this leg.STATUS-REPORT Accessing the database; this might take a few sec-onds.EXPLICIT-CONFIRMYou will depart on September 1st.
Is that correct?IMPLICIT-CONFIRM Leaving from Dallas.INSTRUCTION Try saying a short sentence.APOLOGY Sorry, I didn?t understand that.OPENINGS/CLOSINGS Hello.
Welcome to the C M U Communicator.Figure 4: Example Speech ActsIn this domain, the REQUEST-INFO speech-acts are designed tosolicit information about the trip the caller wants to book, such asthe destination city (And what city are you flying to?
), the desireddates and times of travel (What date would you like to travel on), orinformation about ground arrangements, such as hotel or car rental(Will you need a hotel in Chicago?
).The PRESENT-INFO speech-acts also often pertain directly to thedomain task of making travel arrangements: the system presentsthe user with a choice of itinerary (There are several flights fromDallas Fort Worth to Salisbury Maryland which depart betweeneight in the morning and noon on October fifth.
You can fly onAmerican departing at eight in the morning or ten thirty two in themorning, or on US Air departing at ten thirty five in the morning.
),as well as a ticket price (Ticket price is 495 dollars), or hotel or caroptions.OFFERS involve requests by the caller for a system action, suchas to pick a flight (I need you to tell me whether you would like totake this particular flight) or to confirm a booking (If this itinerarymeets your needs, please press one; otherwise, press zero.)
Theytypically occur after the prerequisite travel information has beenobtained, and choices have been retrieved from the database.The ACKNOWLEDGMENT speech act characterizes system utter-ances that follow a caller?s acceptance of an OFFER, e.g.
I will bookthis leg or I am making the reservation.The STATUS-REPORT speech-act is used to inform the user aboutthe status of the part of the domain task pertaining to the databaseretrieval, and can include apologies, mollification, requests to bepatient, and so on.
Their function is to let the user know what ishappening with the database lookup, whether there are problemswith it, and what types of problems.
While the form of these actsare typically statements, their communication function is differentthan typical presentations of information; they typically function tokeep the user apprised of progress on aspects of the task that theuser has no direct information about, e.g.
Accessing the database;this might take a few seconds.
There is also a politeness functionto utterances like Sorry this is taking so long, please hold., andthey often provide the user with error diagnostics: The date youspecified is too far in advance.
; or Please be aware that the returndate must be later than the departure date.
; or No records satisfyyour request.
; or There don?t seem to be any flights from Boston.The speech-act inventory also includes two types of speech actswhose function is to confirm information that has already been pro-vided by the caller.
In order to identify and confirm the parametersof the trip, systems may ask the caller direct questions, as in SYS3and SYS4 in Figure 2.
These EXPLICIT-CONFIRM speech acts aresometimes triggered by the system?s belief that a misunderstand-ing may have occurred.
A typical example is Are you travelingto Dallas?.
An alternative form of the same EXPLICIT-CONFIRMspeech-act type asserts the information the system has understoodand asks for confirmation in an immediately following question: Ihave you arriving in Dallas.
Is that correct?
In both cases, thecaller is intended to provide a response.A less intrusive form of confirmation, which we tag as IMPLICIT-CONFIRM, typically presents the user with the system?s understand-ing of one travel parameter immediately before asking about thenext parameter.
Depending on the site, implicit information can ei-ther precede the new request for information, as in Flying to Tokyo.What day are you leaving?, or can occur within the same utter-ance, as in What day do you want to leave London?
More rarely,an implicit confirmation is followed by PRESENT-INFO: a flighton Monday September 25.
Delta has a flight departing Atlanta atnine thirty.
One question about the use of implicit confirmationstrategy is whether the caller realizes they can correct the systemwhen necessary [10].
Although IMPLICIT-CONFIRMS typically oc-cur as part of a successful sequence of extracting trip informationfrom the caller, they can also occur in situations where the systemis having trouble understanding the caller.
In this case, the systemmay attempt to instruct the user on what it is doing to remediatethe problem in between an IMPLICIT-CONFIRM and a REQUEST-INFO: So far, I have you going from Tokyo.
I am trying to assembleenough information to pick a flight.
Right now I need you to tell meyour destination.We have observed that INSTRUCTIONS are a speech-act typethat distinguishes these human-computer travel planning dialoguesfrom corresponding human-human travel planning dialogues.
In-structions sometimes take the form of a statement or an imperative,and are characterized by their functional goal of clarifying the sys-tem?s own actions, correcting the user?s expectations, or changingthe user?s future manner of interacting with the system.
Dialoguesystems are less able to diagnose a communication problem thanhuman travel agents, and callers are less familiar with the capa-bilities of such systems.
As noted above, some systems resort toexplicit instructions about what the system is doing or is able to do,or about what the user should try in order to assist the system: Tryasking for flights between two major cities; or You can cancel theSan Antonio, Texas, to Tampa, Florida flight request or change it.To change it, you can simply give new information such as a newdeparture time.
Note that INSTRUCTIONS, unlike the preceding di-alogue act types, do not directly involve a domain task.Like the INSTRUCTION speech-acts, APOLOGIES do not addressa domain task.
They typically occur when the system encoun-ters problems, for example, in understanding the caller (I?m sorry,I?m having trouble understanding you), in accessing the database(Something is wrong with the flight retrieval), or with the connec-tion (Sorry, we seem to have a bad connection.
Can you please callme back later?
).The OPENING/CLOSING speech act category characterizes utter-ances that open and close the dialogue, such as greetings or good-byes [26].
Most of the dialogue systems open the interactions withsome sort of greeting?Hello, welcome to our Communicator flighttravel system, and end with a sign-off or salutation?Thank youvery much for calling.
This session is now over.
We distinguishthese utterances from other dialogue acts, but we do not tag open-ings separate from closings because they have a similar function,and can be distinguished by their position in the discourse.
We alsoinclude in this category utterances in which the systems survey thecaller as to whether s/he got the information s/he needed or washappy with the system.4.
THE TASK-SUBTASK DIMENSIONThe TASK-SUBTASK dimension refers to a task model of the do-main task that the system is designed to support and captures dis-tinctions among dialogue acts that reflect the task structure.1 Ourdomain is air travel reservations, thus the main communicative taskis to specify information pertaining to an air travel reservation, suchas the destination city.
Once a flight has been booked, ancillarytasks such as arranging for lodging or a rental car become relevant.The fundamental motivation for the TASK-SUBTASK dimension inthe DATE scheme is to derive metrics related to subtasks in order toquantify how much effort a system expends on particular subtasks.2This dimension distinguishes among 13 subtasks, some of whichcan also be grouped at a level below the top level task.
The subtasksand examples are in Figure 5.
The TOP-LEVEL-TRIP task describesthe task which contains as its subtasks the ORIGIN, DESTINATION,DATE, TIME, AIRLINE, TRIP-TYPE, RETRIEVAL and ITINERARYtasks.
The GROUND task includes both the HOTEL and CAR sub-tasks.Typically each COMMUNICATOR dialogue system acts as thoughit utilizes a task model, in that it has a particular sequence in whichit will ask for task information if the user doesn?t take the initia-tive to volunteer this information.
For example, most systems askfirst for the origin and destination cities, then for the date and time.Some systems ask about airline preference and others leave it to thecaller to volunteer this information.
A typical sequence of tasks forthe flight planning portion of the dialogue is illustrated in Figure 6.As Figure 6 illustrates, any subtask can involve multiple speechacts.
For example, the DATE subtask can consist of acts requesting,or implicitly or explicitly confirming the date.
A similar exam-ple is provided by the subtasks of CAR (rental) and HOTEL, whichinclude dialogue acts requesting, confirming or acknowledging ar-rangements to rent a car or book a hotel room on the same trip.1This dimension is used as an elaboration of each speech-act typein other tagging schemes [24].2It is tempting to also consider this dimension as a means of in-ferring discourse structure on the basis of utterance level labels,since it is widely believed that models of task structure drive thebehavior of dialogue systems [23, 3, 22], and the relationship be-tween discourse structure and task structure has been a core topicof research since Grosz?s thesis [15].
However, we leave the infer-ence of discourse structure as a topic for future work because themultifunctionality of many utterances suggests that the correspon-dence between task structure and dialogue structure may not be asstraightforward as has been proposed in Grosz?s work [30].Task ExampleTOP-LEVEL-TRIPWhat are your travel plans?ORIGIN And, what city are you leaving from?DESTINATION And, where are you flying to?DATE What day would you like to leave?TIME Departing at what time?.AIRLINE Did you have an airline preference?TRIP-TYPE Will you return to Boston from San Jose?RETRIEVAL Accessing the database; this might take a few seconds.ITINERARY The airfare for this trip is 390 dollars.GROUND Did you need to make any ground arrangements?.HOTEL Would you like a hotel near downtown or near the air-port?.CAR Do you need a car in San Jose?Figure 5: Example Utterances for each SubtaskSpeaker Utterance TaskSYS Welcome .... What trip would you like to take?
TOP-LEVEL-TRIPUSER STARTING FROM ATLANTA GEORGIA TOLONDON ENGLANDSYS flying from atlanta to london.
ORIGIN,DESTINA-TIONSYS What day are you leaving Atlanta?
DATEUSER MONDAY SEPTEMBER TWENTY FIVESYS on monday, september twenty fifth.
DATESYS About what time do you want to leave?
TIMEUSER [UH] DAYTIMESYS Leaving in the daytime.
TIMESYS Please stand by while I look up the flight sched-ules on the web.RETRIEVALSYS OK, got them.
I have 13 flights.
The first flightis on American at six fifty nine eh M, arriving atten forty five PM, with a connection in Chicago.. Is that OK?ITINERARYUSER [UH] YES OKAYSYS Do you want a return flight from London to At-lanta?TRIP-TYPEUSER [UH] YESSYS Returning from london to atlanta.
TRIP-TYPESYS What day are you leaving London?
DATEUSER [UH] LEAVING [UM] MONDAY OCTOBERTHE SECONDSYS on monday, october second.
DATESYS About what time do you want to leave?
TIMEUSER ANY TIME?S OKAYSYS Please stand by while I look up the flight sched-ules on the web... OK, got them.RETRIEVAL,ITINERARYFigure 6: Dialogue Illustrating a Typical Task SequenceThere are also differences in how each site?s dialogue strategyreflects it conceptualization of the travel planning task.
For exam-ple, some systems ask the user explicitly for their airline prefer-ences whereas others do not (the systems illustrated in Figures 1and 6 do not, wherase the one in Figure 2 does).
Another differ-ence is whether the system asks the user explicitly whether s/hewants a round-trip ticket.
Some systems ask this information earlyon, and search for both the outbound and the return flights at thesame time.
Other systems do not separately model round-trip andmulti-leg trips.
Instead they ask the user for information leg by leg,and after requesting the user to select an itinerary for one leg ofthe flight, they ask whether the user has an additional destination.A final difference was that, in the June 2000 data collection, somesystems such as the one illustrated in Figure 1 included the groundarrangements subtasks, and others did not.5.
IMPLEMENTATIONOur focus in this work is in labelling the system side of the di-alogue; our goal was to develop a fully automatic 100% correctdialogue parser for the limited range of utterances produced by the9 COMMUNICATOR systems.
While we believe that it would beuseful to be able to assign dialogue acts to both sides of the con-versation, we expect that to require hand-labelling [1].
We alsobelieve that in many cases the system behaviors are highly corre-lated with the user behaviors of interest; for example when a userhas to repeat himself because of a misunderstanding, the systemhas probably prompted the user multiple times for the same item ofinformation and has probably apologized for doing so.
Thus thisaspect of the dialogue would also be likely to be captured by theAPOLOGY dialogue act and by counts of effort expended on theparticular subtask.We implemented a pattern matcher that labels the system sideof each dialogue.
An utterance or utterance sequence is identifedautomatically from a database of patterns that correspond to the di-alogue act classification we arrived at in cooperation with the sitedevelopers.
Where it simplifies the structure of the dialogue parser,we assign two adjacent utterances that are directed at the same goalthe same DATE label, thus ignoring the utterance level segmenta-tion, but we count the number of characters used in each act.
Sincesome utterances are generated via recursive or iterative routines,some patterns involve wildcards.The current implementation labels the utterances with tags thatare independent of any particular markup-language or representa-tion format.
We have written a transducer that takes the labelleddialogues and produces HTML output for the purpose of visual-izing the distribution of dialogue acts and meta-categories in thedialogues.
An additional summarizer program is used to produce asummary of the percentages and counts of each dialogue act as wellas counts of meta-level groupings of the acts related to the differentdimensions of the tagging scheme.
We intend to use our currentrepresentation to generate ATLAS compliant representations [4].6.
RESULTSOur primary goal was to achieve a better understanding of thequalitative aspects of each system?s dialogue behavior.
We canquantify the extent to which the dialogue act metrics have the po-tential to improve our understanding by applying the PARADISEframework to develop a model of user satisfaction and then exam-ining the extent to which the dialogue act metrics improve thesemodels [31].
In other work, we show that given the standard met-rics collected for the COMMUNICATOR dialogue systems, the bestmodel accounts for 38% of the variance in user satisfaction [28].When we retrain these models with the dialogue act metrics ex-tracted by our dialogue parser, we find that many metrics are signif-icant predictors of user satisfaction, and that the model fit increasesfrom 38% to 45%.
When we examine which dialogue metrics aresignificant, we find that they include several types of meta-dialoguesuch as explicit and implicit confirmations of what the user said,and acknowledgments that the system is going to go ahead and dothe action that the user has requested.
Significant negative predic-tors include apologies.
On interpretation of many of the significantpredictors is that they are landmarks in the dialogue for achieve-ment of particular subtasks.
However the predictors based on thecore metrics included a ternary task completion metric that capturessuccinctly whether any task was achieved or not, and whether theexact task that the user was attempting to accomplish was achieved.A plausible explanation for the increase in the model fits is that usersatisfaction is sensitive to exactly how far through the task the usergot, even when the user did not in fact complete the task.
Therole of the other significant dialogue metrics are plausibly inter-preted as acts important for error minimization.
As with the task-related dialogue metrics, there were already metrics related to ASRperformance in the core set of metrics.
However, several of theimportant metrics count explicit confirmations, one of the desireddate of travel, and the other of all information before searching thedatabase, as in utterances SYS3 and SYS4 in Figure 2.7.
DISCUSSIONThis paper has presented DATE, a dialogue act tagging schemedeveloped explicitly for the purpose of comparing and evaluatingspoken dialogue systems.
We have argued that such a scheme needsto make three important distinctions in system dialogue behaviorsand we are investigating the degree to which any given type of dia-logue act belongs in a single category or in multiple categories.We also propose the view that a tagging scheme be viewed as apartial model of a natural class of dialogues.
It is a model to the de-gree that it represents claims about what features of the dialogue areimportant and are sufficiently well understood to be operationallydefined.
It is partial in that the distributions of the features andtheir relationship to one another, i.e., their possible manifestationsin dialogues within the class, are an empirical question.The view that a dialogue tagging scheme is a partial model of aclass of dialogues implies that a pre-existing tagging scheme can bere-used on a different research project, or by different researchers,only to the degree that it models the same natural class with respectto similar research questions, is sufficient for expressing observa-tions about what actually occurs within the current dialogues ofinterest, and is sufficiently well-defined that high reliability withinand across research sites can be achieved.
Thus, our need to modifyexisting schemes was motivated precisely to the degree that exist-ing schemes fall short of these requirements.
Other researchers whobegan with the goal of re-utilizing existing tagging schemes havealso found it necessary to modify these schemes for their researchpurposes [11, 18, 7].The most substantial difference between our dialogue act tag-ging scheme and others that have been proposed is in our expan-sion of the two-way distinction between dialogue tout simple vs.meta-dialogue, into a three-way distinction among the immediatedialogue goals, meta-dialogue utterances, and meta-situation utter-ances.
Depending on further investigation, we might decide thesethree dimensions have equal status within the overall tagging scheme(or within the overall dialogue-modeling enterprise), or that thereare two types of meta-dialogue: utterances devoted to maintainingthe channel, versus utterances devoted to establishing/maintainingthe frame.
Further, in accord with our view that a tagging schemeis a partial model, and that it is therefore necessarily evolving asour understanding of dialogue evolves, we also believe that our for-mulation of any one dimension, such as the speech-act dimension,will necessarily differ from other schemes that model a speech-actdimension.Furthermore, because human-computer dialogue is at an earlystage of development, any such tagging scheme must be a movingtarget, i.e., the more progress is made, the more likely it is we mayneed to modify along the way the exact features used in an annota-tion scheme to characterize what is going on.
In particular, as sys-tem capabilities become more advanced in the travel domain, it willprobably be necessary to elaborate the task model to capture differ-ent aspects of the system?s problem solving activities.
For example,our task model does not currently distinguish between different as-pects of information about an itinerary, e.g.
between presentationof price information and presentation of schedule information.We also expect that some domain-independent modifications arelikely to be necessary as dialogue systems become more success-ful, for example to address the dimension of ?face?, i.e.
the posi-tive politeness that a system shows to the user [5].
As an example,consider the difference between the interpretation of the utterance,There are no flights from Boston to Boston, when produced by asystem vs. when produced by a human travel agent.
If a humansaid this, it would be be interpretable by the recipient as an in-sult to their intelligence.
However when produced by a system, itfunctions to identify the source of the misunderstanding.
Anotherdistinction that we don?t currently make which might be useful isbetween the initial presentation of an item of information and itsre-presentation in a summary.
Summaries arguably have a differ-ent communicative function [29, 7].
Another aspect of functionour representation doesn?t capture is rhetorical relations betweenspeech acts [20, 21].While we developed DATE to answer particular research ques-tions in the COMMUNICATOR dialogues, there are likely to be as-pects of DATE that can be applied elsewhere.
The task dimensiontagset reflects our model of the domain task.
The utility of a taskmodel may be general across domains and for this particular do-main, the categories we employ are presumably typical of traveltasks and so, may be relatively portable.The speech act dimension includes categories typically found inother classifications of speech acts, such as REQUEST-INFO, OF-FER, and PRESENT-INFO.
We distinguish information presented tothe user about the task, PRESENT-INFO, from information providedto change the user?s behavior, INSTRUCTION, and from informationpresented in explanation or apology for an apparent interruption inthe dialogue, STATUS-REPORT.
The latter has some of the flavorof APOLOGIES, which have an inter-personal function, along withOPENINGS/CLOSINGS.
We group GREETINGS and SIGN-OFFS intothe single category of OPENINGS/CLOSINGS on the assumption thatpoliteness forms make less contribution to perceived system suc-cess than the system?s ability to carry out the task, to correct mis-understandings, and to coach the user.Our third dimension, conversational-domain, adds a new cate-gory, ABOUT-SITUATION-FRAME, to the more familiar distinctionbetween utterances directed at a task goal vs. utterances directedat a maintaining the communication.
This distinction supports theseparate classification of utterances directed at managing the user?sassumptions about how to interact with the system on the air traveltask.
As we mention above, the ABOUT-SITUATION-FRAME utter-ances that we find in the human-computer dialogues typically didnot occur in human-human air travel dialogues.
In addition, as wenote above, one obvious difference in the dialogue strategies im-plemented at different sites had to do with whether these utterancesoccurred upfront, within the dialogue, or both.In order to demonstrate the utility of dialogue act tags as metricsfor spoken dialogue systems, we show that the use of these metricsin the application of PARADISE [31] improves our model of usersatisfaction by an absolute 7%, from 38% to 45%.
This is a largeincrease, and the fit of these models are very good for models ofhuman behavior.
We believe that we have only begun to discoverthe ways in which the output of the dialogue parser can be used.
Infuture work we will examine whether other representations derivedfrom the metrics we have applied, such as sequences or structuralrelations between various types of acts might improve our perfor-mance model further.
We are also collaborating with other mem-bers of the COMMUNICATOR community who are investigating theuse of dialogue act and initiative tagging schemes for the purposeof comparing human-human to human-computer dialogues [1].8.
ACKNOWLEDGMENTSThis work was supported under DARPA GRANT MDA 972 99 30003 to AT&T Labs Research.
Thanks to Payal Prabhu and Sung-bok Lee for their assistance with the implementation of the dia-logue parser.
We also appreciate the contribution of J. Aberdeen,E.
Bratt, S. Narayanan, K. Papineni, B. Pellom, J. Polifroni, A.Potamianos, A. Rudnicky, S. Seneff, and D. Stallard who helpedus understand how the DATE classification scheme applied to theirCOMMUNICATOR systems?
dialogues.9.
REFERENCES[1] J. Aberdeen and C. Doran.
Human-computer andhuman-human dialogues.
DARPA Communicator PrincipleInvestigators Meeting (Philadelphia, PA USA).http://www.dsic-web.net/ito/meetings/communicatorsep2000/, September, 2000.
[2] J. Allen and M. Core.
Draft of DAMSL: Dialog act markupin several layers.
Coding scheme developed by theMultiParty group, 1st Discourse Tagging Workshop,University of Pennsylvania, March 1996, 1997.
[3] J. F. Allen.
Recognizing intentions from natural languageutterances.
In M. Brady and R. Berwick, editors,Computational Models of Discourse.
MIT Press, 1983.
[4] S. Bird and M. Liberman.
A formal framework for linguisticannotation.
Speech Communication, 33(1,2):23?60, 2001.
[5] P. Brown and S. Levinson.
Politeness: Some universals inlanguage usage.
Cambridge University Press, 1987.
[6] J. C. Carletta, A. Isard, S. Isard, J. C. Kowtko,G.
Dowerty-Sneddon, and A. H. Anderson.
The reliability ofa dialogue structure coding scheme.
ComputationalLinguistics, 23-1:13?33, 1997.
[7] R. Cattoni, M. Danieli, A. Panizza, V. Sandrini, and C. Soria.Building a corpus of annotated dialogues: the ADAMexperience.
In Proc.
of the ConferenceCorpus-Linguistics-2001, Lancaster, U.K., 2001.
[8] H. H. Clark and E. F. Schaefer.
Contributing to discourse.Cognitive Science, 13:259?294, 1989.
[9] S. L. Condon and C. G. Cech.
Functional comparison offace-to-face and computer-mediated decision-makinginteractions.
In S. Herring, editor, Computer-MediatedConverstaion.
John Benjamins, 1995.
[10] M. Danieli and E. Gerbino.
Metrics for evaluating dialoguestrategies in a spoken language system.
In Proceedings of the1995 AAAI Spring Symposium on Empirical Methods inDiscourse Interpretation and Generation, pages 34?39,1995.
[11] B.
Di Eugenio, P. W. Jordan, J. D. Moore, and R. H.Thomason.
An empirical investigation of collaborativedialogues.
In ACL-COLING98, Proceedings of theThirty-sixth Conference of the Association forComputational Linguistics, 1998.
[12] M. Finke, M. Lapata, A. Lavie, L. Levin, L. M. Tomokiyo,T.
Polzin, K. Ries, A. Waibel, and K. Zechner.
Clarity:Inferring discourse structure from speech.
In AmericanAssociation for Artificial Intelligence (AAAI) Symposium onApplying Machine Learning to Discourse ProcessingProceedings, Stanford, California, March 1998.
[13] E. Goffman.
Frame Analysis: An Essay on the Organizationof Experience.
Harper and Row, New York, 1974.
[14] E. Goffman.
Forms of Talk.
University of PennsylvaniaPress, Philadelphia, Pennsylvania, USA, 1981.
[15] B. J. Grosz.
The representation and use of focus in dialogueunderstanding.
Technical Report 151, SRI International, 333Ravenswood Ave, Menlo Park, Ca.
94025, 1977.
[16] A. Isard and J. C. Carletta.
Replicability of transaction andaction coding in the map task corpus.
In M. Walker andJ.
Moore, editors, AAAI Spring Symposium: EmpiricalMethods in Discourse Interpretation and Generation, pages60?67, 1995.
[17] P. W. Jordan.
Intentional Influences on Object Redescriptionsin Dialogue: Evidence from an Empirical Study.
PhD thesis,Intelligent Systems Program, University of Pittsburgh, 2000.
[18] D. Jurafsky, E. Shriberg, and D. Biasca.
Swbd-damsllabeling project coder?s manual.
Technical report, Universityof Colorado, 1997. available ashttp://stripe.colorado.edu/ jurafsky/manual.august1.html.
[19] D. Litman.
Plan recognition and discourse analysis: Anintegrated approach for understanding dialogues.
TechnicalReport 170, University of Rochester, 1985.
[20] D. Marcu.
Perlocutions: The achilles?
heel of speech acttheory.
Journal of Pragmatics, 1999.
[21] M. G. Moser, J. Moore, and E. Glendening.
Instructions forcoding explanations: Identifying segments, relations andminimal units.
Technical Report 96-17, University ofPittsburgh, Department of Computer Science, 1996.
[22] R. Perrault and J. Allen.
A plan-based analysis of indirectspeech acts.
American Journal of Computational Linguistics,6:167?182, 1980.
[23] R. Power.
A Computer Model of Conversation.
PhD thesis,University of Edinburgh, 1974.
[24] N. Reithinger and E. Maier.
Utilizing statistical speech actprocessing in verbmobil.
In ACL 95, 1995.
[25] D. R.Traum and E. A. Hinkelman.
Conversation acts intask-oriented spoken dialogue.
Computational Intelligence,8(3):575?599, 1992.
[26] E. A. Schegloff and H. Sacks.
Opening up closings.Semiotica, 8:289?327, 1977.
[27] E. Shriberg, P. Taylor, R. Bates, A. Stolcke, K. Ries,D.
Jurafsky, N. Coccaro, R. Martin, M. Meteer, and C. V.Ess-Dykema.
Can prosody aid the automatic classification ofdialog acts in conversational speech.
Language and Speech:Special Issue on Prosody and Conversation, 2000.
[28] M. Walker, J. Aberdeen, J. Boland, E. Bratt, J. Garofolo,L.
Hirschman, A.
Le, S. Lee, S. Narayanan, K. Papineni,B.
Pellom, J. Polifroni, A. Potamianos, P. Prabhu,A.
Rudnicky, G. Sanders, S. Seneff, D. Stallard, andS.
Whittaker.
Darpa communicator dialog travel planningsystems: The june 2000 data collection.
In Submitted toEUROSPEECH 2001, 2001.
[29] M. A. Walker.
Redundancy in collaborative dialogue.
InFourteenth International Conference on ComputationalLinguistics, pages 345?351, 1992.
[30] M. A. Walker.
Limited attention and discourse structure.Computational Linguistics, 22-2:255?264, 1996.
[31] M. A. Walker, C. A. Kamm, and D. J. Litman.
Towardsdeveloping general models of usability with PARADISE.Natural Language Engineering: Special Issue on BestPractice in Spoken Dialogue Systems, 2000.Speaker Utterance Speech Act Task C-DomainSYS Welcome.
opening/closing nil taskYou are logged in as a guest user.
instruct nil frameYou may say repeat, help me out, start over, or, that?s wrong, instruct nil frameyou can also correct and interrupt the system at any time.
instruct nil frameWhat airport woodja like to fly out of?
request-info origin taskUSER MIAMI FLORIDASYS Leaving from Miami, implicit-conf origin communicationAnd, what city are you flying to?
request-info dest taskUSER MINNEAPOLIS MINNESOTASYS Flying from Miami to Minneapolis, implicit-conf origin, dest communicationWhat date would you like to fly?
request-info date taskUSER UH MONDAY OCTOBER TWENTY THIRDSYS Leaving on the 23rd of October, implicit-conf date communicationAnd what time didja wanna leave?
request-info time taskUSER UH LATE MORNINGSYS From Minneapolis.
implicit-conf origin communicationAre you returning to Miami?
request-info trip-type taskUSER UMSYS Are you going back to Miami?
request-info trip-type taskPlease say yes or no.
instruct nil frameUSER NOSYS Okay, it will just take a moment while I look.
status-report retrieval taskSYS I found 3 flights from Miami to Minneapolis on October 23rd .
For option one I have aflight with United departing at 10 A M and arriving at 3 P M with one stopover andpresent-info itinerary taskTicket price is 390 dollars.
present-info price taskPlease say next option, or, flight details, or, I?ll take it.
offer itinerary taskUSER NEXT OPTIONSYS For option two I have a flight with Delta departing at 12 and arriving at 4 P M non-stop.
present-info itinerary taskTicket price is 450 dollars.
present-info itinerary taskWould you like me to hold this option?
offer itinerary taskUSER NEXT OPTIONSYS For the last option I have a flight with Northwest departing at 2 P M and arriving at 7 P Mwith 1 stopover andpresent-info itinerary taskTicket price is 470 dollars.
present-info itinerary tasksay next option, or, flight details, or, I?ll take it.
offer itinerary taskUSER NEXT OPTIONSYS Here is your third option again.
a flight with Northwest departing at 2 P M and arriving at7 P M with 1 stopover andpresent-info itinerary taskTicket price is 470 dollars.
present-info itinerary tasksay next option, or, flight details, or, I?ll take it.
offer itinerary taskUSER I?LL TAKE ITSYS Great!
I am adding this flight to your itinerary.
acknowledge booking taskOkay, Is Minneapolis your final destination?
request-info trip-type taskUSER YES IT ISSYS Would you like to make any ground arrangements?
offer ground taskUSER NOSYS Now, would you like to hear a summary of your itinerary?
offer itinerary taskUSER YES PLEASESYS Okay, Here?s your itinerary.
On October 23rd Northwest Flight 123 departs Miami at 2 PM, arrives Pittsburgh at 4 30 P M connecting to Northwest Flight 146 that departs Pittsburghat 5 P M and arrives Minneapolis at 7 P M.present-info itinerary taskFigure 1: Dialogue Illustrating the Speech Act, Task-Subtask and Conversational Domain Dimensions of DATE
