Proceedings of the SIGDIAL 2013 Conference, pages 70?77,Metz, France, 22-24 August 2013. c?2013 Association for Computational LinguisticsGenerating More Specific Questions for Acquiring Attributes ofUnknown Concepts from UsersTsugumi Otsuka?, Kazunori Komatani?, Satoshi Sato?, Mikio Nakano??
Graduate School of Engineering, Nagoya University, Nagoya, Aichi 464?8603, Japan?
Honda Research Institute Japan Co., Ltd., Wako, Saitama 351?0114, Japan{t ootuka,komatani,ssato}@nuee.nagoya-u.ac.jp, nakano@jp.honda-ri.comAbstractOur aim is to acquire the attributes of con-cepts denoted by unknown words fromusers during dialogues.
A word unknownto spoken dialogue systems can appear inuser utterances, and systems should be ca-pable of acquiring information on it fromthe conversation partner as a kind of self-learning process.
As a first step, we pro-pose a method for generating more spe-cific questions than simple wh-questionsto acquire the attributes, as such ques-tions can narrow down the variation ofthe following user response and accord-ingly avoid possible speech recognition er-rors.
Specifically, we obtain an appropri-ately distributed confidence measure (CM)on the attributes to generate more specificquestions.
Two basic CMs are defined us-ing (1) character and word distributions inthe target database and (2) frequency ofoccurrence of restaurant attributes on Webpages.
These are integrated to comple-ment each other and used as the final CM.We evaluated distributions of the CMs byaverage errors from the reference.
Re-sults showed that the integrated CM out-performed the two basic CMs.1 IntroductionIn most spoken dialogue systems, knowledgebases for the systems are constructed off-line.
Inother words, they are not updated during dia-logues.
On the other hand, humans update theirknowledge not only by reading books but alsothrough interaction with other people.
When theyencounter an unknown word during conversations,humans notice that it is new to them and acquireknowledge about it by asking their conversationalpartner.
This self-learning process is one of theTell me about ?Osteria Liu?.
I don?t know that restaurant.Is it ?Italian?
?Tell me about?Toyo?.
I don?t know that restaurant.What type of cuisine is it?SystemUserFigure 1: Example of simple and specific ques-tions.most intelligent features of humans.
We think thatapplying this intelligent feature to spoken dialoguesystems will make them more usable.We present a method that generates appropri-ate questions in order to acquire the attributes ofa concept that an unknown word denotes when itappears in a user utterance.
Here, we define un-known words as those whose attributes necessaryfor generating responses were not defined by thesystem developer; that is, unknown to the responsegeneration module in the spoken dialogue system.The system cannot reply to user utterances includ-ing such words even if they are correctly recog-nized by its automatic speech recognition (ASR)module.Questions to the user to acquire the attributeshould be specific.
In spoken dialogue sys-tems, specific questions are far preferable to wh-questions because they can narrow down varia-tions of the following user response.
Such ques-tions lead to a better ASR performance of the re-sponse and reduce the risk that it includes newother unknown words.Two example dialogues are shown in Figure 1.Since our target task is restaurant database re-trieval, we set the unknown words as restaurantnames and the attribute as their cuisine in ourrestaurant database.
In the examples shown, thesystem uses a simple wh-question (the upper part)and a specific Yes-No question (the lower part) toobtain cuisine types.
Here, ?Toyo?
and ?OsteriaLiu?
are restaurant names.
We assume that the70Table 1: Question types according to the number of cuisines (num).num Question form Example1 Yes-No question Is it cuisine c1?2 Alternative question Which cuisine is it, c1 or c2?3 3-choice question Which cuisine is it, c1, c2, or c3?
?4 Wh-question What cuisine is it?system already knows these are restaurant namesbut does not know its attributes such as its cuisinetype.
The system uses a wh-question for ?Toyo?since no clue is obtained for it.
In contrast, since?Osteria Liu?
contains information on cuisines inthe name itself, a concrete Yes-No question is usedto ask whether the cuisine is ?Italian?.We propose a method for providing a well-distributed confidence measure (CM) to generatemore specific questions.
For this purpose, we esti-mate the cuisine type of a restaurant from its name,which is assumed to be unknown to the system.There have been many previous studies that esti-mate word and character attributes using Web in-formation (Pasca et al 2006; Yoshinaga and Tori-sawa, 2007).
Our two estimation methods are rel-atively simpler than these studies, since our mainfocus is to generate more concrete questions on thebasis of appropriate CMs.
That is, the CMs shouldbe high when the system seems to correctly esti-mate a cuisine type and low when the estimationseems difficult.We assume a restaurant name as the input; thatis, we suppose that the system can recognize therestaurant name in the user?s utterance correctlyby its ASR module and understand it is a restau-rant name by its LU module.
Nevertheless, itstill remains unknown to its response generationmodule.
This is a feasible problem when usinga large vocabulary continuous speech recognition(LVCSR) engine containing over several millionwords (Jyothi et al 2012) and a statistical namedentity (NE) tagger (Tjong Kim Sang and Meul-der, 2003; Zhou and Su, 2002; Ratinov and Roth,2009).The problem we tackle in this paper is differ-ent from trying to estimate the NE class of an un-known word (Takahashi et al 2002; Meng et al2004).
We assume the system already knows thatit is a restaurant name.
Rather, we try to acquirethe attribute (e.g., cuisine type) of the concept ofthe unknown word, which is required for generat-ing responses about the restaurant in subsequentdialogues.2 Generating Questions Based on CMThe system determines a question type on the ba-sis of CM.
The CM is estimated for each cuisinetype cj in the target database.
In this paper, thenumber of cuisine types is 16, all of which arein our restaurant database; that is, cj ?
C and|C| = 16.Table 1 shows the four question types and theirexamples.
These are determined by parameternum, which is the number of cuisine types thatshould be included in the question.
If the sys-tem obtains one cuisine type that it is very con-fident about and thus has a high CM, it shouldgenerate the most specific question, i.e., a Yes-No question; in this case, the number should be1.
In contrast, if unreliable cuisine types are ob-tained, which means lower CMs, the system gen-erates questions including several cuisine types.The num can be determined by Equation (1):num = min(n) s.t.n?j=1CM(cj) > ?, (1)where CM(cj) is a confidence measure for cui-sine type cj in its descending order.
?
is a constantand can be manually decided considering the dis-tribution of CM(cj).
This equation means that ifonly the CM(c1) is greater than ?
(i.e., n = 1),the system generates a specific question includ-ing only cuisine type c1, while if the total fromCM(c1) toCM(c4) is smaller than ?
(i.e., n = 4),the system does not use estimated cuisine typesand instead generates a wh-question.If the CM on the cuisine type is well-distributed,the system can generate appropriate questions.
Inthe following section, methods to obtain such CMsare explained.3 Estimating Cuisine Types andCalculating CMThe final CM is obtained by integrating two ba-sic CMs.
The system then uses this final CM to71Feature?selec?n?by?mutual?informa?on?Trainingdata??????
?DBJapanese pubSushi Goichi (??
??
)Koikoi (????
)Japanese restaurantTanaka Sushi (????
)?Maru Sushi (????
)Japanese restaurantJapanese restaurantRestaurant nameCuisine.
.
.
.. .
.
.Quinci CENTRAREItalianHyakuraku (??
)Chinese restaurant?C?s ave cafeCafeClassifier:?Maximum?entropy?(ME)?model?Azuma?Sushi??(???)Input:?
?Restaurant?nameOutput:?CMDJapanese restaurantJapanese pubCafe.
.
.
.
.
: 0.9: 0.05: 0.0006Figure 3: Overview of CMD calculation.WebEs?ma?on?from?DB?Es?ma?on?from?Web?
CM?Integra?on?DBCMW?Restaurant?name?CMI?CMD?Question generationbased on CMFigure 2: Process overview.generate questions.
The two basic CM estimationmethods are:1.
Using word and character distribution in thetarget database2.
Using frequency of the restaurant attributeson the WebA process overview of the proposed method isshown in Figure 2.
Its input to the system is anunknown restaurant name and its output is the es-timated CMs.
The system generates questions onthe basis of the estimated CMs, which are calcu-lated for each cuisine type.3.1 Attribute Estimation Using Word andCharacter Distribution in DatabaseWe estimate the cuisine types of an unknownrestaurant by using the word and character distri-bution in the target database.
The target databasecontains many pairs of restaurant names and cui-sine types.
The estimation is performed by us-ing supervised machine learning trained with thepairs.
The overview of calculating CMD is shownin Figure 3.
This approach is based on our in-tuition that some cuisine types can be estimatedfrom restaurant names on the basis of their char-acter types or typical character sequences theycontain.
For example, a restaurant name com-posed of only katakana1 is probably a French orItalian restaurant because words imported fromother countries to Japan are called ?katakana loan-words?
and are written in katakana characters(Kay, 1995).We use the maximum entropy (ME) model(Berger et al 1996) as a classifier.
Its posteriorprobability p(cj |si) is used as a CMD denotingthe CM estimated using a database.
CMD is cal-culated asCMD(si, cj) = p(cj |si)= 1Z exp[~?
(cj) ?
~?
(si)], (2)where si is a restaurant name, cj (?
C) is acuisine type, ~?
(si) is a feature vector obtainedfrom a restaurant name, ~?
(cj) is a weight vector,and Z is a normalization coefficient that ensures?cj CMD(si, cj) = 1.We use three types of feature vectors obtainedfrom each restaurant name:?
Character n-grams (n = 1, 2, 3)?
Words?
Character typesThe feature values of the character n-gram and theword are scored as 1 if such features are containedin the restaurant name.
The Japanese morpholog-ical analyzer Mecab (Kudo et al 2004) with theIPADIC dictionary is used to segment restaurantnames into word sequences.
The character type1Katakana is a Japanese syllabary.
There are three kindsof characters in Japanese.
Kanji (Chinese character) are lo-gograms and hiragana and katakana are syllabaries.
Katakanais mainly used for writing imported words and hiragana isused for writing original Japanese words.72Web?pageCuisine?frequency?Japanese restaurantItalian restaurantWestern-style restaurant74  times8   times1  timeOutput:?CMWJapanese restaurantItalian restaurantWestern-style restaurant.
.
.
.??0.8??0.11??0.0009Azuma?Sushi?(???)Input:??Restaurant?name?Obtaining?related?pages??about?target?restaurant1.???Calcula?ng?Pfreq(cj)2.??Scaling?Pfreq(cj)3.Yahoo!?Web?search?API?Azuma?Sushi????Aichi???restaurant?(????????????
)?Ranking:  2ndSearch?query?
?Number ofcuisine types:3Figure 4: Overview of CMW calculation.is represented by the four character types used inthe Japanese writing system: hiragana, katakana,kanji (Chinese characters), and romaji (Roman let-ters).
For example, the restaurant name ?MaruSushi (????)?
includes two character types:?Maru (??)?
is written in hiragana and ?Sushi(??)?
is written in kanji.
Therefore, the fea-ture values for hiragana and kanji are both 1, whilethose for katakana and romaji are 0.
Another ex-ample is shown using the restaurant ?IB cafe (IB???
)?, in which the ?IB?
part is romaji and the?cafe (???)?
part is katakana.
Therefore, in thiscase, the feature values of katakana and romaji are1 and those of hiragana and kanji are 0.We perform feature selection for the obtainedfeatures set (Guyon and Elisseeff, 2003).
The clas-sifier needs to be built without overfitting becausewe assume that a restaurant name as the input tothis module is unknown and does not exist in thedatabase.
We use the mutual information (Penget al 2005; Yang and Pedersen, 1997) betweeneach feature and the set of cuisine types as its cri-terion.
This represents how effective each featureis for the classification.
For example, in the fea-tures obtained from the restaurant name ?????
?, which is a Japanese restaurant, the 2-gramfeature ????
frequently co-occurs with the cui-sine type ?Japanese restaurant?.
This is an effec-tive feature for the cuisine type estimation.
In con-trast, the 2-gram feature ????
is not effective be-cause its co-occurrence with cuisine types is infre-quent.
Mutual information is calculated asI(fk;C) =?cj?Cp(fk, cj) logp(fk, cj)p(fk)p(cj), (3)where p(fk) is an occurrence probability of featurefk in the database, p(cj) is an occurrence probabil-ity of cuisine type cj (?
C), and p(fk, cj) is a jointprobability of the feature and the cuisine type.Features having lower mutual information val-ues are removed until we deem that overfitting hasbeen avoided, specifically, when the estimationaccuracies become almost the same between theclosed and open tests.
We confirm this by cross-validations (CV) instead of open tests.3.2 Estimation Using the WebWe estimate a restaurant?s cuisine type and calcu-late CMs by using its frequency on the Web asCMW .
This is based on an assumption that arestaurant?s name appears with its cuisine type onWeb pages.
CMW is calculated in the followingsteps, as shown in Figure 4.1.
Obtaining related Web pages:Twenty pages per search query were ob-tained, as this was the limit of the number ofpages when this experiment was performed.We used the Yahoo!
Web search API2.
Thequery is formed with the target restaurantname and the following two words: ?Aichi(??)?
and ?restaurant (?????)?.
Thetwo are added to narrow down the search re-sult since our domain is a restaurant searchin Aichi prefecture.
For example, the queryis ?<rest>????????
for the targetrestaurant name <rest>.2http://developer.yahoo.co.jp/webapi/search/websearch/v2/web search.html732.
Calculating Pfreq(cj):We count the frequency of each cuisine typecj in the i-th Web pages, which are rankedby the Web search API.
We then sum up thefrequency through all the obtained pages andcalculate its posterior probability.Pfreq(cj) =?i wi ?
freqi(cj)?cj?i wi ?
freqi(cj)(4)Here, freqi(cj) is the frequency of cj in thei-th page.
Weight wi is calculated using twofactors, rank(i) and cuisine(i):wi =1rank(i) ?
cuisine(i) (5)(a) rank(i): The ranking of pages in theWeb search APIWe assume that a Web page is more re-lated to the target restaurant if the Websearch API ranks it higher.
(b) cuisine(i): The number of cuisinetypes in the i-th Web pageWe assume that a Web page contain-ing many different cuisine types doesnot indicate one particular cuisine.
Forexample, a page on which only ?Chi-nese restaurant?
appears is more reliablethan that on which more cuisine types(?Chinese restaurant?, ?Japanese restau-rant?, ?Japanese pub?, and ?Western-style restaurant?, for example) appear,as a page indicating a ?Chinese restau-rant?.3.
Scaling Pfreq(cj):CMW is calculated by scaling eachPfreq(cj) with the corresponding ?j .
?jis a scaling coefficient that emphasizes thedifferences among CMW : ?j is equal toor smaller than 1 and becomes smaller as jincreases.CMW (cj) =?jPfreq(cj)?cj ?jPfreq(cj)(6)?j = Pfreq(cj)/Pfreq(c1) (7)3.3 Integration of CMsWe define CMI by integrating the two basic CMs:CMD and CMW .
Specifically, we integrate themby the logistic regression (Hosmer Jr. et al 2013)shown in Equation (8).
The optimal parameters,i.e., weights for the CMs, are determined using adata set with reference labels.
The teacher signalis 1 if the estimated cuisine type is correct and 0otherwise.CMI(cj) =11 + exp(?f(cj))(8)f(cj) = wDCMD(cj) + wWCMW (cj) + w0Here, wD and wW are the weights for CMD andCMW , and w0 is a constant.4 ExperimentWe evaluate our method to obtain the CMs fromthree aspects.
First, we evaluate the effect of fea-ture selection based on mutual information.
Sec-ond, we evaluate how the CMs were distributedand whether they were appropriate measures forquestion generation.
Third, we determine the ef-fectiveness of integrating the two basic CMs.
Inthis paper, we used a restaurant database in Aichiprefecture containing 2,398 restaurants with 16cuisine types.4.1 Effect of Feature Selection Based onMutual InformationWe determined whether overfitting could beavoided by feature selection based on mutual in-formation in the estimation using a database.
Weregard overfitting to be avoided when estimationaccuracies become almost the same between theclosed and open tests.
For the closed test, estima-tion accuracy was calculated for all 2,398 restau-rants in the database by using a classifier that wastrained with the same 2,398 restaurants.
For theopen test, it was calculated by 10-fold CV for the2,398 restaurants.
This experiment is not for de-termining a feature set but rather for determininga feature selection ratio.
That is, the feature se-lection result is kept not as a feature set but as aratio.
The resulting ratio is applied to the num-ber of features appearing in another training data(e.g., that in Section 4.2) and then the feature setis determined.Figure 5 shows the estimation accuracy of theclosed test and the 10-fold CV when the featureselection was applied.
The horizontal axis denotesratios of features used to train the classifier out of20,679 features in total.
They were selected in de-scending order of mutual information.
The ver-tical axis denotes the estimation accuracy of the740.60.70.80.911 10 100Estimationaccuracy (%)Feature selection ratio (%)Closed10-fold CVFigure 5: Estimation accuracies of closed test and10-fold CV.cuisine types.
Figure 5 shows that, at first, over-fitting occurs if all features were used for training;that is, the feature selection ratio = 100%.
Thiscan be seen by the difference in estimation accu-racies, which was 28.1% between the closed testand the 10-fold CV.
The difference decreased asthe number of used features decreased, and almostdisappeared at feature selection ratio = 0.8%.
Inthese selected features, as an example, the 2-gram?gyoza (??
)?, which seems intuitively effectivefor cuisine type estimation is, included3.4.2 Evaluation for Distribution of CMsWe evaluate the distribution of CMs obtained withthe estimation results.
Specifically, we evaluatedthree types of distributions: CMD, CMW , andCMI .
We extracted 400 restaurants from thedatabase and used them as evaluation data.
Theremaining 1,998 restaurants were used as trainingdata for the classifier to calculate CMD.
In allfeatures obtained from these 1,998 restaurants, theME classifier uses 0.8% of them, which is the fea-ture selection ratio based on the mutual informa-tion determined in Section 4.1.
That is, the featureset itself obtained in the feature selection is not de-livered into the evaluation in this section.We used average distances between each CMscore and its reference as the criterion to evalu-ate the distribution of the CMs.
Generally, CMsshould be as highly scored as possible when theestimation is correct and as lowly scored as possi-ble otherwise.
We calculate the distances over the3?Gyoza (??)?
is a kind of dumplings and one of themost popular Chinese foods.
It often appears in Chineserestaurant names in Japan.Table 3: Evaluation against each CM.eval(CMx) MB(CMx)CMD 0.31 0.37CMW 0.28 0.32CMI 0.25 0.28400 estimation results.eval(CMx) =?Ni |CM ix ?
?ix|N (9)Here, N is the total number of the estimation re-sult, so N = 400 in this paper.
?ix for CM ix isdefined as?ix ={1, If estimation result i is correct0, Otherwise (10)Note that ?x depends on CMx because estimationresults differ depending on the CMx used.We also set the majority baseline as Equation(11).
Here, all CMs are regarded as 0 or 1 in Equa-tion (9).
Because there were more correct estima-tion results than incorrect ones, as shown in Table2, we used 1 for the majority baseline, asMB(CMx) =?Ni |1 ?
?ix|N .
(11)The results are shown in Table 3.
A compar-ison of the three eval(CMx) demonstrates thatthe integrated CMI is the most appropriate in ourevaluation criterion because it is the lowest of thethree.
The relative error reduction rates fromCMIagainst CMD and CMW were 16% and 37%, re-spectively.
Each eval(CMx) outperformed thecorresponding majority baseline.4.3 Effectiveness of Integrated CMWe verify the effectiveness of the CM integrationfrom another viewpoint.
Specifically, we confirmwhether the number of correct estimation resultsincreases by integration.First, we show the distribution of the three CMsand whether they were correct or not in Table 2.The bottom row of the table shows that CMI ob-tained correct estimation results for 297 restau-rants, which is the highest of the three CMs.More specifically, we investigated how manyestimation results changed by using the threeCMs.
Here, an estimation result means the cui-sine type that is given the highest confidence.
Thisresult is shown in Table 4, where C denotes a case75Table 2: Distribution of estimation results by CM values.CMD CMW CMICM range Correct Incorrect Correct Incorrect Correct Incorrect0.0 ?
0.1 0 0 0 32 2 100.1 ?
0.2 0 0 0 11 9 150.2 ?
0.3 1 16 14 22 15 180.3 ?
0.4 6 19 28 19 10 80.4 ?
0.5 11 25 29 21 13 120.5 ?
0.6 21 29 56 9 13 120.6 ?
0.7 22 28 85 7 15 70.7 ?
0.8 41 16 42 3 17 60.8 ?
0.9 21 9 19 1 19 90.9 ?
1.0 131 4 1 1 184 10Total 254 146 274 124 297 103Table 4: Estimation results by three CMs.CMD / CMWI / I I / C C / I C / CC 0 51 33 213CMI I 85 10 8 0C: correct, I: incorrectwhen a cuisine type was correctly estimated and Idenotes that it was not.
The four columns with ?/?denote the numbers of estimation results forCMDand CMW .
For example, the C/I column denotesthat estimation results based on the database werecorrect and those using the Web were incorrect,that is, the I/C and C/I columns mean that thetwo estimation results differed.
The table showsthat 102 of 400 restaurants corresponded to thesecases, that is, either of the two estimation resultswas incorrect.
It also shows that estimation resultsfor 84 of the 102 (82%) restaurants became correctby the integration.Two examples are shown for which the esti-mation results became correct by the integration.First, ?Kaya (??)?
is a restaurant name whosecuisine type is ?Japanese-style pancake?.
Its cui-sine type was correctly estimated by CMW whileit was incorrectly estimated as ?Japanese pub?
byCMD.
This was because, in Japanese, ?Kaya (??)?
has no special meaning associated with spe-cific cuisine types.
Thus, it is natural that its cui-sine type was incorrectly estimated from the wordand character distribution of the name.
On theother hand, when Web pages about it were found,?Japanese-style pancake?
co-occurs frequently inthe obtained pages, and thus it was correctly es-timated by CMW .
Second, ?Tama-Sushi Imaike(???
??)?
is a restaurant name whose cui-sine type is ?Japanese restaurant?.
Its cuisine typewas estimated correctly by CMD while it was in-correctly estimated as ?Japanese pub?
by CMW .CMD was effective in this case because the partof ?Sushi (??)?
indicates a Japanese cuisine.
NoWeb pages for it were found indicating its cuisinetype correctly, and thus CMW failed to estimateit.5 ConclusionOur aim is to acquire the attributes of an unknownword?s concept from the user through dialogue.Specifically, we set restaurant cuisine type as theattribute to obtain and showed how to generatespecific questions based on the estimated CM.
Weuse two estimation methods: one based on the tar-get database and the other on the Web.
A moreappropriate CM was generated in terms of its dis-tribution and estimation accuracy by integratingthese two CMs.There is little prior research on obtaining andupdating system knowledge through dialogues,with the notable exception of the knowledge au-thoring system of (Knott and Wright, 2003).
Theirsystem also uses the user?s text input for construct-ing the system knowledge from scratch, which isused to generate simple stories.
Our study is dif-ferent in two points: (1) we focus on generatingseveral kinds of questions because we use ASR,and (2) we try to handle unknown words, whichwill be stored in the target database to be used infuture dialogues.We should point out that these kinds of ques-tions can be generated only when the types of un-known concepts are given.
We assume the typeof unknown concepts is already known and thusthe attributes to be asked are also known.
Morespecifically, we assume that the concept denotedby an unknown word is a restaurant name and itsattributes are also known.
The cuisine type hasbeen estimated as one of the attributes.
However,76when the type is unknown, the system first needsto identify its attributes to ask.
That is, the sys-tem first needs to ask about its supertype and thento ask about attributes that are typical for objectsof this type.
This issue needs to be addressed inorder for the system to acquire arbitrary new con-cepts.
This paper has shown the first step for ob-taining concepts through dialogues by generatingquestions.
Many issues remain in this field for fu-ture work.ReferencesAdam L. Berger, Vincent J. Della Pietra, and StephenA.
Della Pietra.
1996.
A maximum entropy ap-proach to natural language processing.
Computa-tional Linguistics, 22(1):39?71.Isabelle Guyon and Andre?
Elisseeff.
2003.
An intro-duction to variable and feature selection.
The Jour-nal of Machine Learning Research, 3:1157?1182.David W. Hosmer Jr., Stanley Lemeshow, and Rod-ney X. Sturdivant.
2013.
Applied logistic regres-sion.
Wiley.
com.Preethi Jyothi, Leif Johnson, Ciprian Chelba, and BrianStrope.
2012.
Large-scale discriminative languagemodel reranking for voice search.
In Proceedingsof the NAACL-HLT 2012 Workshop: Will We EverReally Replace the N-gram Model?
On the Futureof Language Modeling for HLT, pages 41?49.Gillian Kay.
1995.
English loanwords in Japanese.World Englishes, 14(1):67?76.Alistair Knott and Nick Wright.
2003.
A dialogue-based knowledge authoring system for text genera-tion.
In AAAI Spring Symposium on Natural Lan-guage Generation in Spoken and Written Dialogue,Stanford, CA, pages 71?78.Taku Kudo, Kaoru Yamamoto, and Yuji Matsumoto.2004.
Applying conditional random fields toJapanese morphological analysis.
In Proceedings ofConference on Empirical Methods in Natural Lan-guage Processing (EMNLP-2004), pages 230?237.Helen Meng, P. C. Ching, Shuk Fong Chan, Yee FongWong, and Cheong Chat Chan.
2004.
ISIS:An adaptive, trilingual conversational system withinterleaving interaction and delegation dialogs.ACM Transactions on Computer-Human Interac-tion, 11(3):268?299.Marius Pasca, Dekang Lin, Jeffrey Bigham, AndreiLifchits, and Alpa Jain.
2006.
Organizing andsearching the World Wide Web of facts - step one:the one-million fact extraction challenge.
In Pro-ceedings of the 21st National Conference on Artifi-cial intelligence - Volume 2, AAAI ?06, pages 1400?1405.
AAAI Press.Hanchuan Peng, Fuhui Long, and Chris Ding.
2005.Feature selection based on mutual information cri-teria of max-dependency, max-relevance, and min-redundancy.
IEEE Transactions on Pattern Analysisand Machine Intelligence, 27(8):1226?1238.Lev Ratinov and Dan Roth.
2009.
Design challengesand misconceptions in named entity recognition.
InProceedings of the Thirteenth Conference on Com-putational Natural Language Learning, pages 147?155.Yasuhiro Takahashi, Kohji Dohsaka, and KiyoakiAikawa.
2002.
An efficient dialogue controlmethod using decision tree-based estimation of out-of-vocabulary word attributes.
In Proc.
Int?l Conf.Spoken Language Processing (ICSLP), pages 813?816.Erik F. Tjong Kim Sang and Fien De Meulder.2003.
Introduction to the CoNLL-2003 shared task:Language-independent named entity recognition.
InProceedings of the seventh conference on Naturallanguage learning at HLT-NAACL 2003-Volume 4,pages 142?147.Yiming Yang and Jan O Pedersen.
1997.
A compara-tive study on feature selection in text categorization.In ICML, volume 97, pages 412?420.Naoki Yoshinaga and Kentaro Torisawa.
2007.Open-domain attribute-value acquisition from semi-structured texts.
In Proceedings of the Workshopof OntoLex07 - From Text to Knowledge: The Lexi-con/Ontology Interface, pages 55?66.Guo Dong Zhou and Jian Su.
2002.
Named entityrecognition using an HMM-based chunk tagger.
InProceedings of the 40th Annual Meeting of the As-sociation for Computational Linguistics, pages 473?480.77
