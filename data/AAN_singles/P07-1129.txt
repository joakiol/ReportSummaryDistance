Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 1024?1031,Prague, Czech Republic, June 2007. c?2007 Association for Computational LinguisticsTopic Analysis for Psychiatric Document RetrievalLiang-Chih Yu*?, Chung-Hsien Wu*, Chin-Yew Lin?, Eduard Hovy?
and Chia-Ling Lin**Department of CSIE, National Cheng Kung University, Tainan, Taiwan, R.O.C.
?Microsoft Research Asia, Beijing, China?Information Sciences Institute, University of Southern California, Marina del Rey, CA, USAliangchi@isi.edu,{chwu,totalwhite}@csie.ncku.edu.tw,cyl@microsoft.com,hovy@isi.eduAbstractPsychiatric document retrieval attempts tohelp people to efficiently and effectivelylocate the consultation documents relevantto their depressive problems.
Individualscan understand how to alleviate their symp-toms according to recommendations in therelevant documents.
This work proposesthe use of high-level topic information ex-tracted from consultation documents to im-prove the precision of retrieval results.
Thetopic information adopted herein includesnegative life events, depressive symptomsand semantic relations between symptoms,which are beneficial for better understand-ing of users' queries.
Experimental resultsshow that the proposed approach achieveshigher precision than the word-based re-trieval models, namely the vector spacemodel (VSM) and Okapi model, adoptingword-level information alone.1 IntroductionIndividuals may suffer from negative or stressfullife events, such as death of a family member, ar-gument with a spouse and loss of a job.
Suchevents play an important role in triggering depres-sive symptoms, such as depressed moods, suicideattempts and anxiety.
Individuals under these cir-cumstances can consult health professionals usingmessage boards and other services.
Health profes-sionals respond with suggestions as soon as possi-ble.
However, the response time is generally sev-eral days, depending on both the processing timerequired by health professionals and the number ofproblems to be processed.
Such a long responsetime is unacceptable, especially for patients suffer-ing from psychiatric emergencies such as suicideattempts.
A potential solution considers the prob-lems that have been processed and the correspond-ing suggestions, called consultation documents, asthe psychiatry web resources.
These resources gen-erally contain thousands of consultation documents(problem-response pairs), making them a usefulinformation resource for mental health care andprevention.
By referring to the relevant documents,individuals can become aware that they are notalone because many people have suffered from thesame or similar problems.
Additionally, they canunderstand how to alleviate their symptoms ac-cording to recommendations.
However, browsingand searching all consultation documents to iden-tify the relevant documents is time consuming andtends to become overwhelming.
Individuals needto be able to retrieve the relevant consultationdocuments efficiently and effectively.
Therefore,this work presents a novel mechanism to automati-cally retrieve the relevant consultation documentswith respect to users' problems.Traditional information retrieval systems repre-sent queries and documents using a bag-of-wordsapproach.
Retrieval models, such as the vectorspace model (VSM) (Baeza-Yates and Ribeiro-Neto, 1999) and Okapi model (Robertson et al,1995; Robertson et al, 1996; Okabe et al, 2005),are then adopted to estimate the relevance betweenqueries and documents.
The VSM represents eachquery and document as a vector of words, andadopts the cosine measure to estimate their rele-vance.
The Okapi model, which has been used onthe Text REtrieval Conference (TREC) collections,developed a family of word-weighting functions1024for relevance estimation.
These functions considerword frequencies and document lengths for wordweighting.
Both the VSM and Okapi models esti-mate the relevance by matching the words in aquery with the words in a document.
Additionally,query words can further be expanded by the con-cept hierarchy within general-purpose ontologiessuch as WordNet (Fellbaum, 1998), or automati-cally constructed ontologies (Yeh et al, 2004).However, such word-based approaches onlyconsider the word-level information in queries anddocuments, ignoring the high-level topic informa-tion that can help improve understanding of users'queries.
Consider the example consultation docu-ment in Figure 1.
A consultation document com-prises two parts: the query part and recommenda-tion part.
The query part is a natural language text,containing rich topic information related to users'depressive problems.
The topic information in-cludes negative life events, depressive symptoms,and semantic relations between symptoms.
As in-dicated in Figure 1, the subject suffered from alove-related event, and several depressive symp-toms, such as <Depressed>, <Suicide>, <Insom-nia> and <Anxiety>.
Moreover, there is a cause-effect relation holding between <Depressed> and<Suicide>, and a temporal relation holding be-tween <Depressed> and <Insomnia>.
Differenttopics may lead to different suggestions decided byexperts.
Therefore, an ideal retrieval system forconsultation documents should consider such topicinformation so as to improve the retrieval precision.Natural language processing (NLP) techniquescan be used to extract more precise informationfrom natural language texts (Wu et al, 2005a; Wuet al, 2005b; Wu et al, 2006; Yu et al, 2007).This work adopts the methodology presented in(Wu et al 2005a) to extract depressive symptomsand their relations, and adopts the pattern-basedmethod presented in (Yu et al, 2007) to extractnegative life events from both queries and consul-tation documents.
This work also proposes a re-trieval model to calculate the similarity between aquery and a document by combining the similari-ties of the extracted topic information.The rest of this work is organized as follows.Section 2 briefly describes the extraction of topicinformation.
Section 3 presents the retrieval model.Section 4 summarizes the experimental results.Conclusions are finally drawn in Section 5.2 Framework of Consultation DocumentRetrievalFigure 2 shows the framework of consultationdocument retrieval.
The retrieval process beginswith receiving a user?s query about his depressiveproblems in natural language.
The example queryis shown in Figure 1.
The topic information is thenextracted from the query, as shown in the center ofFigure 2.
The extracted topic information is repre-Consultation DocumentQuery:It's normal to feel this way when going through these kinds of struggles, but overtime your emotions should level out.
Suicide doesn't solve anything; think abouthow it would affect your family........
There are a few things you can try to helpyou get to sleep at night, like drinking warm milk, listening to relaxing music.......Recommendation:After that, it took me a long time to fall asleep at night.<Depressed><Suicide><Insomnia><Anxiety>cause-effect temporalI broke up with my boyfriend.I often felt like crying and felt pain every day.So, I tried to kill myself several times.In recent months, I often lose my temper for no reason.Figure 1.
Example of a consultation document.
The bold arrowed lines denote cause-effect relations; ar-rowed lines denote temporal relations; dashed lines denote temporal boundaries, and angle brackets de-note depressive symptoms1025sented by the sets of negative life events, depres-sive symptoms, and semantic relations.
Each ele-ment in the event set and symptom set denotes anindividual event and symptom, respectively, whileeach element in the relation set denotes a symptomchain to retain the order of symptoms.
Similarly,the query parts of consultation documents are rep-resented in the same manner.
The relevance esti-mation then calculates the similarity between theinput query and the query part of each consultationdocument by combining the similarities of the setsof events, symptoms, and relations within them.Finally, a list of consultation documents ranked inthe descending order of similarities is returned tothe user.In the following, the extraction of topic informa-tion is described briefly.
The detailed process isdescribed in (Wu et al 2005a) for symptom andrelation identification, and in (Yu et al, 2007) forevent identification.1) Symptom identification: A total of 17 symp-toms are defined based on the Hamilton De-pression Rating Scale (HDRS) (Hamilton,1960).
The identification of symptoms is sen-tence-based.
For each sentence, its structure isfirst analyzed by a probabilistic context freegrammar (PCFG), built from the Sinica Tree-bank corpus developed by Academia Sinica,Taiwan (http://treebank.sinica.edu.tw), to gen-erate a set of dependencies between word to-kens.
Each dependency has the format (modi-fier, head, relmodifier,head).
For instance, the de-pendency (matters, worry about, goal) meansthat "matters" is the goal to the head of the sen-tence "worry about".
Each sentence can thenbe associated with a symptom based on theprobabilities that dependencies occur in allsymptoms, which are obtained from a set oftraining sentences.2) Relation Identification: The semantic rela-tions of interest include cause-effect and tem-poral relations.
After the symptoms are ob-tained, the relations holding between symp-toms (sentences) are identified by a set of dis-course markers.
For instance, the discoursemarkers "because" and "therefore" may signalcause-effect relations, and "before" and "after"may signal temporal relations.3) Negative life event identification: A total of 5types of events, namely <Family>, <Love>,<School>, <Work> and <Social> are definedbased on Pagano et als (2004) research.
Theidentification of events is a pattern-based ap-proach.
A pattern denotes a semantically plau-sible combination of words, such as <parents,divorce> and <exam, fail>.
First, a set of pat-terns is acquired from psychiatry web corporaby using an evolutionary inference algorithm.The event of each sentence is then identifiedby using an SVM classifier with the acquiredpatterns as features.3 Retrieval ModelThe similarity between a query and a document,( , )Sim q d , is calculated by combining the similari-ties of the sets of events, symptoms and relationswithin them, as shown in (1).ConsultationDocumentsRankingRelevanceEstimationQuery(Figure 1)Topic InformationSymptomIdentificationNegative Life EventIdentificationRelationIdentificationD S AD S Cause-EffectD I ATemporalIS I A<Love>Topic AnalysisFigure 2.
Framework of consultation document retrieval.
The rectangle denotes a negative life event re-lated to love relation.
Each circle denotes a symptom.
D: Depressed, S: Suicide, I: Insomnia, A: Anxiety.1026( , )( , ) ( , ) (1 ) ( , ),Evn Sym RelSim q dSim q d Sim q d Sim q d?
?
?
?=+ + ?
?
(1)where ( , )EvnSim q d , ( , )SymSim q d  and ( , )RelSim q d ,denote the similarities of the sets of events, symp-toms and relations, respectively, between a queryand a document, and ?
and ?
denote the combi-nation factors.3.1 Similarity of events and symptomsThe similarities of the sets of events and symptomsare calculated in the same method.
The similarityof the event set (or symptom set) is calculated bycomparing the events (or symptoms) in a querywith those in a document.
Additionally, only theevents (or symptoms) with the same type areconsidered.
The events (or symptoms) withdifferent types are considered as irrelevant, i.e., nosimilarity.
For instance, the event <Love> isconsidered as irrelevant to <Work>.
The similarityof the event set is calculated by( , )1( , ) cos( , ) .,( )Evnq d q dq d e q dSim q dType e e e e constN Evn Evn ?
?= +?
?
(2)where qEvn  and dEvn  denote the event set in aquery and a document, respectively; qe  and dedenote the events; ( )q dN Evn Evn?
denotes thecardinality of the union of qEvn  and dEvn  as anormalization factor, and ( , )q dType e e  denotes anidentity function to check whether two events havethe same type, defined as1     ( ) ( )( , ) .0    otherwiseq dq dType e Type eType e e=?
?= ???
(3)The cos( , )q de e  denotes the cosine angle betweentwo vectors of words representing qe  and de , asshown below.
( ) ( )12 21 1cos( , ) ,q dq dT i ie eiq dT Ti ie ei iw we ew w== == ??
?
(4)where w denotes a word in a vector, and T denotesthe dimensionality of vectors.
Accordingly, whentwo events have the same type, their similarity isgiven as cos( , )q de e  plus a constant, const.. Addi-tionally, cos( , )q de e  and const.
can be consideredas the word-level and topic-level similarities, re-spectively.
The optimal setting of const.
is deter-mined empirically.3.2 Similarity of relationsWhen calculating the similarity of relations, onlythe relations with the same type are considered.That is, the cause-effect (or temporal) relations in aquery are only compared with the cause-effect (ortemporal) relations in a document.
Therefore, thesimilarity of relation sets can be calculated as,1( , ) ( , ) ( , ),q dRel q d q dr rSim q d Type r r Sim r rZ= ?
(5)( ) ( ) ( ) ( ),C q C d T q T dZ N r N r N r N r= +   (6)where qr and dr denote the relations in a query anda document, respectively; Z denotes the normaliza-tion factor for the number of relations; ( , )q dType e edenotes an identity function similar to (3), and( )CN i   and ( )TN i  denote the numbers of cause-effect and temporal relations.Both cause-effect and temporal relations are rep-resented by symptom chains.
Hence, the similarityof relations is measured by the similarity of symp-tom chains.
The main characteristic of a symptomchain is that it retains the cause-effect or temporalorder of the symptoms within it.
Therefore, theorder of the symptoms must be considered whencalculating the similarity of two symptom chains.Accordingly, a sequence kernel function (Lodhi etal., 2002; Cancedda et al, 2003) is adopted to cal-culate the similarity of two symptom chains.
Asequence kernel compares two sequences of sym-bols (e.g., characters, words) based on the subse-quences within them, but not individual symbols.Thereby, the order of the symptoms can be incor-porated into the comparison process.The sequence kernel calculates the similarity oftwo symptom chains by comparing their sub-symptom chains at different lengths.
An increasingnumber of common sub-symptom chains indicatesa greater similarity between two symptom chains.For instance, both the two symptom chains1 2 3 4s s s s  and 3 2 1s s s  contain the same symptoms 1s ,2s  and 3s , but in different orders.
To calculate thesimilarity between these two symptom chains, thesequence kernel first calculates their similarities atlength 2 and 3, and then averages the similarities atthe two lengths.
To calculate the similarity at1027length 2, the sequence kernel compares their sub-symptom chains of length 2, i.e.,1 2 1 3 1 4 2 3 2 4 3 4{ , , , , , }s s s s s s s s s s s s  and 3 2 3 1 2 1{ , , }s s s s s s .Similarly, their similarity at length 3 is calculatedby comparing their sub-symptom chains of length3, i.e., 1 2 3 1 2 4 1 3 4 2 3 4{ ,  ,  ,  }s s s s s s s s s s s s  and 3 2 1{ }s s s .Obviously, no similarity exists between 1 2 3 4s s s sand 3 2 1s s s , since no sub-symptom chains arematched at both lengths.
In this example, the sub-symptom chains of length 1, i.e., individual symp-toms, do not have to be compared because theycontain no information about the order of symp-toms.
Additionally, the sub-symptom chains oflength 4 do not have to be compared, because thetwo symptom chains share no sub-symptom chainsat this length.
Hence, for any two symptom chains,the length of the sub-symptom chains to be com-pared ranges from two to the minimum length ofthe two symptom chains.
The similarity of twosymptom chains can be formally denoted as1 21 21 22( , ) ( , )( , )1( , ),1N Nq d q dN Nq dNN Nn q dnSim r r Sim sc scK sc scK sc scN =?== ?
?
(7)where 1Nqsc  and 2Ndsc  denote the symptom chainscorresponding to qr  and dr , respectively; 1N  and2N  denote the length of 1Nqsc  and 2Ndsc , respec-tively; (  ,   )K i i  denotes the sequence kernel forcalculating the similarity between two symptomchains; (  ,   )nK i i  denotes the sequence kernel forcalculating the similarity between two symptomchains at length n, and N is the minimum length ofthe two symptom chains, i.e., 1 2min( , )N N N= .The sequence kernel 1 2( , )N Nn i jK sc sc  is defined as211 21 21 21 1 2 2( )( )( , )( ) ( )( ) ( ),( ) ( ) ( ) ( )nn nNNn jN N n in i j N Nn i n jN Nu i u ju SCN N N Nu i u j u i u ju SC u SCscscK sc scsc scsc scsc sc sc sc?
??
?
?
???
???=?
?=??
?i(8)where 1 2( , )N Nn i jK sc sc  is the normalized innerproduct of vectors 1( )Nn isc?
and 2( )Nn jsc?
; ( )n?
idenotes a mapping that transforms a given symp-tom chain into a vector of the sub-symptom chainsof length n; ( )u?
i  denotes an element of the vector,representing the weight of a sub-symptom chain u ,and nSC  denotes the set of all possible sub-symptom chains of length n. The weight of a sub-symptom chain, i.e., ( )u?
i , is defined as1111       is a contiguous sub-symptom chain ofis a non-contiguous sub-symptom chain( )with  skipped symptoms0       does not appear in ,NiNu iNiu scuscu sc???
???
?= ????
(9)where [0,1]??
denotes a decay factor that isadopted to penalize the non-contiguous sub-symptom chains occurred in a symptom chainbased on the skipped symptoms.
For instance,1 2 2 31 2 3 1 2 3( ) ( ) 1s s s ss s s s s s?
?= =  since 1 2s s  and 2 3s sare considered as contiguous in 1 2 3s s s , and1 311 2 3( )s s s s s?
?=  since 1 3s s  is a non-contiguoussub-symptom chain with one skipped symptom.The decay factor is adopted because a contiguoussub-symptom chain is preferable to a non-contiguous chain when comparing two symptomchains.
The setting of the decay factor is domaindependent.
If 1?
= , then no penalty is applied forskipping symptoms, and the cause-effect and tem-poral relations are transitive.
The optimal setting ofFigure 3.
Illustrative example of relevance com-putation using the sequence kernel function.1028?
is determined empirically.
Figure 3 presents anexample to summarize the computation of thesimilarity between two symptom chains.4 Experimental Results4.1 Experiment setup1) Corpus: The consultation documents werecollected from the mental health website of theJohn Tung Foundation (http://www.jtf.org.tw)and the PsychPark (http://www.psychpark.org),a virtual psychiatric clinic, maintained by agroup of volunteer professionals of TaiwanAssociation of Mental Health Informatics (Baiet al 2001).
Both of the web sites providevarious kinds of free psychiatric services andupdate the consultation documents periodically.For privacy consideration, all personal infor-mation has been removed.
A total of 3,650consultation documents were collected forevaluating the retrieval model, of which 20documents were randomly selected as the testquery set, 100 documents were randomly se-lected as the tuning set to obtain the optimalparameter settings of involved retrieval models,and the remaining 3,530 documents were thereference set to be retrieved.
Table 1 shows theaverage number of events, symptoms and rela-tions in the test query set.2) Baselines: The proposed method, denoted asTopic, was compared to two word-based re-trieval models: the VSM and Okapi BM25models.
The VSM was implemented in termsof the standard TF-IDF weight.
The OkapiBM25 model is defined as(1) 3123( 1)( 1)| | ,t Qk qtfk tf avdl dlw k QK tf k qtf avdl dl?++ ?++ + +?
(10)where t denotes a word in a query Q; qtf and tfdenote the word frequencies occurring in aquery and a document, respectively, and  (1)wdenotes the Robertson-Sparck Jones weight oft (without relevance feedback), defined as(1) 0.5log ,0.5N nwn?
+= +             (11)where N denotes the total number of docu-ments, and n denotes the number of documentscontaining t. In (10), K is defined as1((1 ) / ),K k b b dl avdl= ?
+ ?
(12)where dl and avdl denote the length and aver-age length of a document, respectively.
Thedefault values of 1k , 2k , 3k  and b are describein (Robertson et al, 1996), where 1k  rangesfrom 1.0 to 2.0; 2k  is set to 0; 3k  is set to 8,and b ranges from 0.6 to 0.75.
Additionally,BM25 can be considered as BM15 and BM11when b is set to 1 and 0, respectively.3) Evaluation metric: To evaluate the retrievalmodels, a multi-level relevance criterion wasadopted.
The relevance criterion was dividedinto four levels, as described below.z Level 0: No topics are matched between aquery and a document.z Level 1: At least one topic is partiallymatched between a query and a document.z Level 2: All of the three topics are partiallymatched between a query and a document.z Level 3: All of the three topics are partiallymatched, and at least one topic is exactlymatched between a query and a document.To deal with the multi-level relevance, the dis-counted cumulative gain (DCG) (Jarvelin andKekalainen, 2000) was adopted as the evalua-tion metric, defined as[1],                                   1     [ ][ 1] [ ]/ log , otherwisecG if iDCG iDCG i G i i=?
?= ?
?
+??
(13)where i denotes the i-th document in the re-trieved list; G[i] denotes the gain value, i.e.,relevance levels, of the i-th document, and cdenotes the parameter to penalize a retrieveddocument in a lower rank.
That is, the DCGsimultaneously considers the relevance levels,and the ranks in the retrieved list to measurethe retrieval precision.
For instance, let<3,2,3,0,0> denotes the retrieved list of fivedocuments with their relevance levels.
If nopenalization is used, then the DCG values forTopic Avg.
NumberNegative Life Event 1.45Depressive Symptom 4.40Semantic Relation 3.35Table 1.
Characteristics of the test query set.1029the retrieved list are <3,5,8,8,8>, and thusDCG[5]=8.
Conversely, if c=2, then the docu-ments retrieved at ranks lower than two are pe-nalized.
Hence, the DCG values for the re-trieved list are <3,5,6.89,6.89,6.89>, andDCG[5]=6.89.The relevance judgment was performed bythree experienced physicians.
First, the poolingmethod (Voorhees, 2000) was adopted to gen-erate the candidate relevant documents foreach test query by taking the top 50 rankeddocuments retrieved by each of the involvedretrieval models, namely the VSM, BM25 andTopic.
Two physicians then judged each can-didate document based on the multilevel rele-vance criterion.
Finally, the documents withdisagreements between the two physicianswere judged by the third physician.
Table 2shows the average number of relevant docu-ments for the test query set.4) Optimal parameter setting: The parametersettings of BM25 and Topic were evaluated us-ing the tuning set.
The optimal setting ofBM25 were k1 =1 and b=0.6.
The other two pa-rameters were set to the default values, i.e.,2 0k =  and 3 8k = .
For the Topic model, theparameters required to be evaluated include thecombination factors, ?
and ?
, described in(1); the constant const.
described in (2), andthe decay factor, ?
, described in (9).
The op-timal settings were 0.3?
= ; 0.5?
= ;const.=0.6 and 0.8?
= .4.2 Retrieval resultsThe results are divided into two groups: the preci-sion and efficiency.
The retrieval precision wasmeasured by DCG values.
Additionally, a paired,two-tailed t-test was used to determine whether theperformance difference was statistically significant.The retrieval efficiency was measure by the queryprocessing time, i.e., the time for processing all thequeries in the test query set.Table 3 shows the comparative results of re-trieval precision.
The two variants of BM25,namely BM11 and BM15, are also considered incomparison.
For the word-based retrieval models,both BM25 and BM11 outperformed the VSM, andBM15 performed worst.
The Topic modelachieved higher DCG values than both the BM-series models and VSM.
The reasons are three-fold.First, a negative life event and a symptom can eachbe expressed by different words with the same orsimilar meaning.
Therefore, the word-based mod-els often failed to retrieve the relevant documentswhen different words were used in the input query.Second, a word may relate to different events andsymptoms.
For instance, the term "worry about" isRelevance Level Avg.
NumberLevel 1 18.50Level 2 9.15Level 3 2.20Table 2.
Average number of relevant documentsfor the test query set.DCG(5) DCG(10) DCG(20) DCG(50) DCG(100)Topic 4.7516* 6.9298 7.6040* 8.3606* 9.3974*BM25 4.4624 6.7023 7.1156 7.8129 8.6597BM11 3.8877 4.9328 5.9589 6.9703 7.7057VSM 2.3454 3.3195 4.4609 5.8179 6.6945BM15 2.1362 2.6120 3.4487 4.5452 5.7020Table 3.
DCG values of different retrieval models.
* Topic vs BM25 significantly different (p<0.05)Retrieval Model Avg.
Time (seconds)Topic 17.13VSM 0.68BM25 0.48Table 4.
Average query processing time of differ-ent retrieval models.1030a good indicator for both the symptoms <Anxiety>and <Hypochondriasis>.
This may result in ambi-guity for the word-based models.
Third, the word-based models cannot capture semantic relationsbetween symptoms.
The Topic model incorporatesnot only the word-level information, but also moreuseful topic information about depressive problems,thus improving the retrieval results.The query processing time was measured usinga personal computer with Windows XP operatingsystem, a 2.4GHz Pentium IV processor and512MB RAM.
Table 4 shows the results.
The topicmodel required more processing time than bothVSM and BM25, since identification of topics in-volves more detailed analysis, such as semanticparsing of sentences and symptom chain construc-tion.
This finding indicates that although the topicinformation can improve the retrieval precision,incorporating such high-precision features reducesthe retrieval efficiency.5 ConclusionThis work has presented the use of topic informa-tion for retrieving psychiatric consultation docu-ments.
The topic information can provide moreprecise information about users' depressive prob-lems, thus improving the retrieval precision.
Theproposed framework can also be applied to differ-ent domains as long as the domain-specific topicinformation is identified.
Future work will focus onmore detailed experiments, including the contribu-tion of each topic to retrieval precision, the effectof using different methods to combine topic infor-mation, and the evaluation on real users.ReferencesBaeza-Yates, R. and B. Ribeiro-Neto.
1999.
ModernInformation Retrieval.
Addison-Wesley, Reading,MA.Cancedda, N., E. Gaussier, C. Goutte, and J. M. Renders.2003.
Word-Sequence Kernels.
Journal of MachineLearning Research, 3(6):1059-1082.Fellbaum, C. 1998.
WordNet: An Electronic LexicalDatabase.
MIT Press, Cambridge, MA.Hamilton, M. 1960.
A Rating Scale for Depression.Journal of Neurology, Neurosurgery and Psychiatry,23:56-62Jarvelin, K. and J. Kekalainen.
2000.
IR EvaluationMethods for Retrieving Highly Relevant Documents.In Proc.
of the 23rd Annual International ACMSIGIR Conference on Research and Development inInformation Retrieval, pages 41-48.Lodhi, H., C. Saunders, J. Shawe-Taylor, N. Cristianini,and C. Watkins.
2002.
Text Classification UsingString Kernels.
Journal of Machine Learning Re-search, 2(3):419-444.Okabe, M., K. Umemura and S. Yamada.
2005.
QueryExpansion with the Minimum User Feedback byTransductive Learning.
In Proc.
of HLT/EMNLP,Vancouver, Canada, pages 963-970.Pagano, M.E., A.E.
Skodol, R.L.
Stout, M.T.
Shea, S.Yen, C.M.
Grilo, C.A.
Sanislow, D.S.
Bender, T.H.McGlashan, M.C.
Zanarini, and J.G.
Gunderson.2004.
Stressful Life Events as Predictors of Function-ing: Findings from the Collaborative LongitudinalPersonality Disorders Study.
Acta Psychiatrica Scan-dinavica, 110: 421-429.Robertson, S. E., S. Walker, S. Jones, M. M. Hancock-Beaulieu, and M.Gatford.
1995.
Okapi at TREC-3.
InProc.
of the Third Text REtrieval Conference (TREC-3), NIST.Robertson, S. E., S. Walker, M. M. Beaulieu, andM.Gatford.
1996.
Okapi at TREC-4.
In Proc.
of thefourth Text REtrieval Conference (TREC-4), NIST.Voorhees, E. M. and D. K. Harman.
2000.
Overview ofthe Sixth Text REtrieval Conference (TREC-6).
In-formation Processing and Management, 36(1):3-35.Wu, C. H., L. C. Yu, and F. L. Jang.
2005a.
Using Se-mantic Dependencies to Mine Depressive Symptomsfrom Consultation Records.
IEEE Intelligent System,20(6):50-58.Wu, C. H., J. F. Yeh, and M. J. Chen.
2005b.
Domain-Specific FAQ Retrieval Using Independent Aspects.ACM Trans.
Asian Language Information Processing,4(1):1-17.Wu, C. H., J. F. Yeh, and Y. S. Lai.
2006.
SemanticSegment Extraction and Matching for Internet FAQRetrieval.
IEEE Trans.
Knowledge and Data Engi-neering, 18(7):930-940.Yeh, J. F., C. H. Wu, M. J. Chen, and L. C. Yu.
2004.Automated Alignment and Extraction of BilingualDomain Ontology for Cross-Language Domain-Specific Applications.
In Proc.
of the 20th COLING,Geneva, Switzerland, pages 1140-1146.Yu, L. C., C. H. Wu, Yeh, J. F., and F. L. Jang.
2007.HAL-based Evolutionary Inference for Pattern Induc-tion from Psychiatry Web Resources.
Accepted byIEEE Trans.
Evolutionary Computation.1031
