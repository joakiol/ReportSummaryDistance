Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 591?599,Honolulu, October 2008. c?2008 Association for Computational LinguisticsSeeded Discovery of Base Relations in Large CorporaNicholas AndrewsBBN Technologies?noa@bbn.comNaren RamakrishnanVirginia Technaren@cs.vt.eduAbstractRelationship discovery is the task of iden-tifying salient relationships between namedentities in text.
We propose novel approachesfor two sub-tasks of the problem: identifyingthe entities of interest, and partitioningand describing the relations based on theirsemantics.
In particular, we show that termfrequency patterns can be used effectivelyinstead of supervised NER, and that the p-median clustering objective function naturallyuncovers relation exemplars appropriate fordescribing the partitioning.
Furthermore, weintroduce a novel application of relationshipdiscovery: the unsupervised identification ofprotein-protein interaction phrases.1 IntroductionRelationship extraction (RE) is the task of extractingnamed relationships between entities in text givensome information about the relationships of interest.Relationship discovery (RD), on the other hand, isthe task of finding which relations exist in a corpuswithout any prior knowledge.
The discovered rela-tionships can then be used to bootstrap RE, which iswhy RD has also been called unsupervised relationextraction (Rosenfeld and Feldman, 2006).
RD gen-erally involves three sub-tasks: entities of interestare either supplied or recognized in the corpus; sec-ond, of all phrases in which entities co-occur, thosewhich express a relation are picked out; finally, theserelationship phrases are partitioned based on theirsemantics and described.
This work considers onlybinary relations (those between exactly two entities).Finding entities of interest has involved eithernamed entity recognition (NER) or general noun?This work was conducted while author was at VirginiaTech.phrase (NP) chunking, to create the initial poolof candidate entities.
In Section 2, we describe acorpus statistics approach, previously applied forweb mining (Davidov and Rappoport, 2006), whichwe extend for relation discovery.
Unlike supervisedmachine learning methods, this algorithm doesnot need training, is computationally efficient, andrequires as input only the raw corpus and a small setof seed entities (as few as two).
The result is a setof entities likely to be related to the seeds.An assumption commonly held in RD work isthat frequently co-occurring entity tuples are likelyto stand in some fixed relation (Hasegawa et al,2004; Shinyama and Sekine, 2006; Rosenfeld andFeldman, 2006; Rosenfeld and Feldman, 2007).Tuples which share similar contexts (the exactdefinition of context varies) are then groupedtogether in clusters of relations using variants of hi-erarchical agglomerate clustering (HAC).
However,to our knowledge, no prior work has satisfactorilyaddressed the problem of describing the resultingclusters.
In Section 3, we propose an approachwhich incorporates this requirement directly intothe clustering objective: to find relation clusterswhich are well-described by a single exemplar.In Section 4, we apply RD to recognize protein-protein interaction (PPI) sentences, using proteinsas seeds for the entity discovery phase.
We compareour results against special-purpose methods in termsof precision and recall on standard data sets.The remainder of this paper is outlined below:Section 2 describes how a small number of inputwords (the entities of interest) are used as seedsfor unsupervised entity discovery.
Section 3 de-scribes how discovered entities are used to discoverrelationships.
Section 4 describes evaluationmethodology and results.
Section 5 describesrelated work.
Section 6 concludes and discusses591directions for future work.2 Entity discoveryFor a corpus C, each sentence s ?
C with wordss = (w1, w2, ..., wn), is mapped to the sequences?= f(s).
The function f maps each word w ?
sto a symbol based on its frequency in C as follows:f(w) =??
?S if w is a seed wordH otherwise if w is a frequent wordX otherwiseFor example, the sentence:A and B are usually mediated by anoverproduced C.might be mapped to the sequence(S,H,X,H,H,X,H,H,X,X), which we willwrite as SHXHHXHHXX for brevity.
In thiscase, A is a seed term, while B and C are not.
Theunderlying assumption is that content words canbe distinguished from other words based on theirfrequency in the corpus.2.1 Pattern inductionIn the example sentence, ?A and B are usuallymediated by an overproduced C?, ?and?
is a goodindicator that A,B share some aspect of theirsemantics; in this case, that they are both me-diated by an overproduced C, and are thereforealso likely to belong to same family or type ofentities.
The indicators ?and?
and ?or?
have togetherbeen used to discover word categories in lexicalacquisition (Dorow et al, 2005).
However, therecan be many other such indicators, many discourseor corpus specific.
To discover them, we use aslightly modified version of the method presentedin (Davidov and Rappoport, 2006).
In particular, inthis work we consider named entities of arbitrarylength (i.e., longer than a single token).The corpus is searched for all instances of thefrequency pattern H1S1H2S2H3, for seed wordsS1, S2, and pattern (H1, H2, H3).
Of all these pat-tern instances, we keep those which also appear asH1S2H2S1H3.
If seed words appear on either sideof the pattern, it is a good indication that the sym-metric pattern expresses some sort of a conjunction,often domain specific.
This procedure is repeated forvariations of HSHSH with the goal of capturingdifferent forms of speech; for example, HSHSHwill capture ?
; A , B and?, while HSHHSH willcapture ?
; A but not B ,?
and so on.
We enforce thatfrequent words appear before and after (i.e., sur-round) the two seed words to ensure they are stand-alone entities, and not part of a longer noun phrase.For example, the phrase ?IFN-gamma mRNA andIL-6 are?
maps to XXHSH , and therefore ?mRNA?would (correctly) not be added to the entity pool.New entities are added to the initial set of seedby matching symmetric patterns.
If a seed wordS is found to occur with an infrequent word X inany discovered symmetric pattern (as HSHXH orHXHSH), then we add X to the pool of entities.This process can be bootstrapped as needed.2.2 ChunkingIn Section 3.1, sentences in which entities co-occurare clustered based on a measure of pairwise simi-larity.
The features used in this similarity calculationare based on the surrounding or connecting wordsin the sentence in which entities co-occur.
To ensurethe context is not polluted with words which actuallybelong the entity NP (such as ?IFN-gamma mRNA?
)rather than the context, we use frequency patternsto search the corpus for common NP chunks.In each sentence in which entities occur, we forma candidate chunk by matching the regular expres-sion HX?SX?H , which returns all content-wordsX bracketing the entity S. Of all candidate chunks,we keep those which occur frequently enough tosignificantly affect the similarity calculations.
Theremaining chunks are pruned based on the entropyof the words appearing immediately before and afterthe chunk in the corpus; if a given chunk appearsin a variety of contexts, it is more likely to expressa meaningful collocation (Shimohata et al, 1997).Therefore, as an efficient filter on the candidatechunks, we discard those which tend to occur in thesame contexts (where the context is H...H).3 Identifying relation phrasesOnce the pool of entities has been recognized in thecorpus, those which frequently co-occur are takenas likely to stand in a relation.
Order matters in thatS1..S2 is considered a different entity co-occurrence(and therefore potential relation) than S2..S1.The effect of the co-occurrence threshold on theresulting relations is investigated in Section 4.3.1 Clustering relation phrasesPartitioning the candidate relationships serves toidentify groups of differently expressed relation-ships of similar semantics.
The resulting clustersshould cover the most important relations in a cor-pus between the entities of interest.
The phrases in592each cluster are expected to capture most syntacticvariation in the expression of a given relationship.Therefore, the largest clusters are well suitedas positive examples for training a relationshipextractor (Rosenfeld and Feldman, 2006).We take the context of a co-occurring tuple tobe the terms connecting the two entities withinthe sentence in which they appear, and call theconnecting terms a relation phrase (RP).
Each RP istreated separately in the similarity calculations andthe clustering.
Relations are modeled using a vectorspace model.
Each relation is treated as a vector ofterm frequencies (tf) weighted by tf ?
idf.
RPs arepreprocessed by filtering stopwords1.
However, wedo not stem the remaining words, as suffixes can behighly discriminative in determining the semanticsof a relation (e.g., ?production?
vs ?produced?).
Af-ter normalizing vectors to unit length, we compute asimilarity matrix by computing the dot product be-tween the vectors for each distinct RP pair.
The sim-ilarity matrix is then used as input for the clustering.3.2 p-Median clusteringPrior approaches to relationship discovery haveused HAC to identify relation clusters.
HAC isattractive in unsupervised applications since thenumber of clusters is not required a priori, butcan be determined from the resulting dendogram.On the other hand, a typical HAC implementationruns in ?
(N2 log(N)), which can be prohibitive onlarger data sets2.A further feature of HAC, and many other par-titional clustering algorithms such as k-means andspectral cuts, is that the resulting clusters are notnecessarily well-described by single instance.
Re-lations, however, typically have a base or root formwhich would be desirable to uncover to describe therelation clusters.
For example, in the following RPs:induced transient increases ininduced biphasic increases ininduced an increase ininduced an increase in bothinduced a further increase inthe phrase ?induced an increase in?
is well suitedas a base form of the relation and a descriptor forthe cluster.
The p-median clustering objective is tofind p clusters which are well-described by a single1We use the English stopword list from the Snowballproject, available at http://snowball.tartarus.org/2An optimization to ?
(N2) is possible for single-linkageHAC.exemplar.
Formally, given an N ?
N similaritymatrix, the goal is to select p columns such that thesum of the maximum values within each row of theselected columns are maximized.Note that an exemplar can also be chosen aposteriori using some heuristic; for example, themost frequently occurring instance in a cluster canbe taken as the exemplar.
However, the p-medianclustering objective is robust, and ensures that onlythose clusters which are well described by a singleexemplar appear in the resulting partition of therelations.
This means that the optimal number ofclusters for the p-median clustering objective in agiven data set will usually be quite different (usuallyhigher) than the optimal number of groups accordingto the HAC, k-means, or normalized cut objectives.Affinity propagation (AP) is the most efficientapproximation for the p-median problem that we areaware of, which also has the property of not requir-ing the number of clusters as an explicit input (Freyand Dueck, 2007).
Runtime is linear in the numberof similarities, which in the worst case is N2 (forN relations), but in practice many relations shareno words in common, and therefore do not need tohave their similarity considered in the clustering.AP is an iterative message-passing procedurein which the objects being clustered compete toserve as cluster exemplars by exchanging two typesof messages.
The responsibility r(x,m), sentfrom object x ?
X (for set X of objects to beclustered) to candidate exemplar m ?
X , denoteshow well-suited m is of being the exemplar for x byconsidering all other potential exemplars m?
of x:s(x,m)?
maxm?
?X ,m?
6=ma(x,m?)
+ s(x,m?
)where s(x,m) is the similarity between x,m.
Theavailability a(x,m) of each object x ?
X is initiallyset to zero.
Availabilities, sent from candidateexemplar m to object x, increase as evidence for mto serve as the exemplar for x increases:min??
?0, r(m,m) +?x?
?X ,x?
6?
{x,m}max{0, r(x?,m)}??
?Each object to be clustered is assigned an initialpreference of becoming a cluster exemplar.
If thereare no a priori preferences for cluster exemplars, thepreferences are set to the median similarity (whichcan be thought of as the ?knee?
of the objectivefunction graph vs. number of clusters), and exem-plars emerge from the message passing procedure.However, shorter RP are more likely to contain base593forms of relations (because longer phrases likelycontain additional words specific to the sentence).Therefore, we include a slight scaling factor in thepreferences, which assigns shorter RP higher initialvalues (up to 1.5?
the median similarity).3.3 Pruning clustersAfter clustering relation phrases with AP, we prunethe resulting partition by evaluating the numberof different relation instances appearing in eachcluster, as well as the entities involved.
In ourexperiments, we discard all clusters smaller than acertain threshold, since we ultimately wish to usethe clustering to train RE, and small clusters donot provide enough positive examples for training(we investigate the effect of this threshold in Sec-tion 4.2).
We further assume that for a relationshipto be useful, a number of different entities shouldstand in this relation.
In particular, we inspect theset of left and right arguments in the cluster, which(in English) usually correspond to the subject andobject of the sentence.
If a single entity constitutesmore than two thirds (23 ) of the left or right argu-ments of a cluster, then this cluster is discarded fromthe results.
Our assumption is that these clustersdescribe relations too specific to be useful.4 EvaluationRD systems are usually evaluated based on their re-sults for a particular task such as RE (Rosenfeld andFeldman, 2006), or by a manual inspection of theirresults (Davidov et al, 2007; Rosenfeld and Feld-man, 2007; Hasegawa et al, 2004), but we are notaware of any which examines the effects of parame-ters on performance exhaustively.
In this section wetest several hypotheses of RD using data sets whichare already labeled for sentences which containentities of a particular type and in a fixed relation ofsome kind.
In particular, we adapt the output of thediscovery phase to identify phrases which expressPPIs.
While this task is traditionally performedusing supervised algorithms such as support vectormachines (Erkan et al, 2007), we show that RDis capable of achieving similar levels of precisionwithout any manually annotated training data.4.1 MethodWe construct a corpus of 87300 abstracts by query-ing the PubMed database with the proteins shown inTable 1.
The 60 most frequent words are considereddefinite non-entities; all remaining words are can-didate entities.
This corpus serves as input for theTable 1: Proteins queried to create the evaluation corpus.Seed entities (proteins)c-cbl AmpC CD18 CD54 CD5CD59 CK c-myc CNP DMEBNA GSH IL-8 IL-1beta JNK1p38 PABP PCNA PP1 PP2aPPAR PSM TAT TNF-alpha TPOrelationship discovery.
As seeds, we use the same25 proteins used to query the database.
Since allseeds are proteins, we expect the entities discoveredto be proteins.
The pattern induction found roughly200 symmetric extraction patterns, which yield4402 unique entities after 1 pass through the corpus.Depending on the frequency of the seeds in thecorpus, more passes through the corpus might beneeded (bootstrapping with the discovered entitiesafter each pass).
We retain all chunks that appearat least 10 times in the corpus, yielding 3282additional entities after entropy pruning.A PPI denotes a broad class of bio-medicalrelationships between two proteins.
One exampleof an interaction is where the two proteins bindtogether to form a structural complex of cellularmachinery such as signal transduction machinery.
Asecond example is when one protein binds upstreamof the DNA sequence encoding a gene which en-codes the second protein.
A final example is whenproteins serve as enzymes catalyzing successivesteps of a biochemical reaction.
More categoriesof interactions are continually being cataloguedand hence unsupervised identification of PPIs isimportant in biomedical text mining.4.2 Experiment 1: PPI sentence identificationMethod: To evaluate the performance of our sys-tem, we measure how well the relationships discov-ered compare with manually selected PPI sentences.To do so, we follow the same procedure and datasets used to evaluate semi-supervised classificationof PPI sentences (Erkan et al, 2007).
The two datasets are AIMED and CB, which have been markedfor protein entities and interaction phrases3.For each sentence in which n proteins appear,we build(n2)phrases.
Each phrase consists ofthe words between each entity combination, and islabeled as positive if it describes a PPI, or negativeotherwise.
This results in 4026 phrases for the3Available in preprocessed form at http://belabog.si.umich.edu/biocreative594AIMED data set (951 positive, 3075 negative), and4056 phrases for the CB data set (2202 positive,1854 negative).The output of the discovery phase is a clusteringof RPs.
For purpose of this experiment, we ignorethe partition and treat the phrases in aggregate.
Aphrase in the evaluation data set is classified aspositive (describing a PPI) if any substring of thephrase matches an RP in our output.
For example,if the phrase is:A significantly inhibited Band the string ?inhibited?
appears as a relation inour output, then this phrase is marked positive.Otherwise, the phrase is marked negative.Performance is evaluated using standard metricsof precision (P ), recall (R), and F-measure (F1),defined as:P =TPTP + FP; R =TPTP + FNwhere TP is the number of phrases correctlyidentified as describing a PPI, FP is the number ofphrases incorrectly classified as describing a rela-tion, and FN is the number of interaction phrases(positives) marked negative.
F1 is defined as:F1 =2PRP + RWe calculate P , R, and F1 for three parametersaffecting which phrases are identified as expressinga relation:?
the minimum co-occurrence threshold that con-trols which entity tuples are kept as likely to standin some fixed relation?
the minimum cluster size that controls whichgroups of relations are discarded?
the minimum RP length that controls the smallestnumber of words appearing in relationsThe threshold on the length of the relations can bethought of as controlling the amount of contextualinformation expressed.
A single term relationwill be very general, while longer RPs express arelation very specific to the context in which theyare written.
The results are reported in Figures 1through 6.
Odd numbered figures use the AIMEDcorpus; even numbered figures the CB corpus.Results: Discarding clusters below a certain sizehad no significant effect on precision.
However, thisstep is still necessary for bootstrapping RE, sincemachine learning approaches require a sufficientnumber of positive examples to train the extractor.Table 2: Comparison with supervised methods?AIMEDcorpusMethod P R F1RD-F1 30.08 60.67 40.22RD-P 55.17 5.04 9.25(Yakushiji et al, 2005) 33.70 33.10 33.40(Mitsumori et al, 2006) 54.20 42.60 47.70(Erkan et al, 2007) 59.59 60.68 59.96Table 3: Comparison with supervised methods?CBcorpusMethod P R F1RD-F1 65.03 69.16 67.03RD-P 86.27 2.00 3.91(Erkan et al, 2007) 85.62 84.89 85.22On the other hand, our results confirm theobservation that frequently co-occurring pairs ofentities are likely to stand in a fixed relation.
Onthe CB corpus, precision ranges from 0.63 to 0.86for phrases between entities co-occurring at least50 times.
On the AIMED corpus, precision rangesfrom 0.29 to 0.55 in the same threshold range.The minimum phrase length had the most impacton performance, which was particularly evident inthe CB corpus: this corpus reached perfect precisiondiscarding all RPs of fewer than 3 words.
Lowerthresholds result in significantly more relations, atthe cost of precision.The generally lower performance on the AIMEDcorpus suggests that our training data (retrieved fromthe seed proteins) provided less coverage for thoseinteractions than for the those in the CB corpus.Table 2 and Table 3 compare our results at fixedparameter settings with supervised approaches.RD-F1 reports parameters which give highest recalland RD-P highest precision.
Specifically, bothRD-F1 and RD-P use a minimum RP length of1, RD-F1 uses a co-occurrence threshold of 10,and RD-P uses a co-occurrence threshold of 50.As expected, RD alone does not match combinedprecision and recall of state-of-the-art supervisedsystems.
However, we show better performancethan expected.
RD-F1 outperforms the best resultsof (Yakushiji et al, 2005).
RD-P settings out-perform or match the precision of top-performingsystems on both datasets.595AIMED corpus CB corpus00.20.40.60.81RatioRatio5 10 15 20 25Cluster size thresholdPrecisionRecallF-Measure00.20.40.60.81RatioRatio5 10 15 20 25Cluster size thresholdPrecisionRecallF-MeasureFigures 1 & 2: Performance as minimum cluster size is adjusted00.20.40.60.81RatioRatio10 20 30 40 50Co-occurence thresholdPrecisionRecallF-Measure00.20.40.60.81RatioRatio10 20 30 40 50Co-occurence thresholdPrecisionRecallF-MeasureFigures 3 & 4: Performance as co-occurrence threshold is adjusted00.20.40.60.81RatioRatio0 0.5 1 1.5 2 2.5 3Minimum phrase lengthPrecisionRecallF-Measure00.20.40.60.81RatioRatio0 0.5 1 1.5 2 2.5 3Minimum phrase lengthPrecisionRecallF-MeasureFigures 5 & 6: Performance as minimum phrase length is adjusted5964.3 Experiment 2: clustering relationsMethod: We evaluate the appropriateness of thep-median clustering as follows.
For each cluster,we take the cluster exemplar as defining the baserelation.
If the base relation does not expresssomething meaningful, then we mark each mem-ber of the cluster incorrect.
Otherwise, we labeleach member of the cluster either as semanticallysimilar to the exemplar (correct) or different thanthe exemplar (incorrect).
Thus, clusters withinappropriate exemplars are heavily penalized.These results are reported in Table 4.
For purposeof this experiment, we use the same parametersas for RD-P , and evaluate the 20 largest clusters.Results: In the 20 largest clusters, each cluster ex-emplar expressed something meaningful.
3 of thecluster exemplars were not representative of theirother members.
We found that most error was due tostopwords not being considered in our similarity cal-culations.
For example, ?detected by?
and ?detectedin?
express the same relationship in our similaritycalculations; however, they are clearly quite differ-ent.
Another source of error evident in Table 4 aremistakes in the pattern and entropy based chunking.The exemplar ?mrna expression in?
includes the to-ken ?mrna?, which belongs with the left protein NPin the relation chosen as an exemplar.5 Related workRD is a relatively new area of research.
Existingmethods differ primarily in the amount of super-vision required and in how contextual features aredefined and used.
(Hasegawa et al, 2004) use NER to identifyfrequently co-occurring entities as likely relationphrases.
As in this work, they use the vector modeland cosine similarity to define a measure of simi-larity between relations, but build relation vectorsout of all instances of each frequently co-occurringentity pair.
Therefore, each mention of the sameco-occurring pair is assumed to express the samerelationship.
These aggregate feature vectors areclustered using complete-linkage HAC, and clusterexemplars are determined by manual inspectionfor evaluation purposes.
(Shinyama and Sekine,2006) rely further on supervised methods, definingfeatures over a full syntactic parse, and exploitmultiple descriptions of the same event in newswireto identify useful relations.
(Rosenfeld and Feldman, 2006) consider the useof RD for unsupervised relation extraction, and useTable 4: Base relations identified using RP-P parametersExemplar Size P (%)by activation of 33 87.9was associated with 28 92.9was induced by 24 83.3was detected by 24 83.3as compared with the 25 92.0were measured with 23 87.0mrna expression in 21 9.5in response to 21 95.23was determined by 21 90.4with its effect in 19 10.5was correlated with 18 100.0by induction of 16 93.8for binding to 16 75.0is mediated by 16 93.8was observed by 16 50.0is an important 15 66.6increased expression of 15 60.0related to the 15 93.3protein production as well as 15 33.3dependent on 14 85.7Median precision: 86.35a more complex pattern-learning approach to definefeature vectors to cluster candidate relations, report-ing gains in accuracy compared with the tf ?
idfweighed features used in (Hasegawa et al, 2004)and in this work.
They also use HAC, and do notaddress the description of the relations.
Arbitrarynoun phrases obtained through shallow parsing areused as entities.
(Rosenfeld and Feldman, 2007) usea feature ranking scheme using separability-basedscores, and compare the performance of differentvariants of HAC (finding single-linkage to performbest).
The complexity of the feature ranking-schemedescribed can be greater than the clustering itself; incontrast, while we use simple features, our approachis much more efficient.
(Davidov et al, 2007) introduce the use ofterm frequency patterns for relationship discovery.However, they search for a specific type of relation-ship; namely, attributes common to all entities ofa particular type (for example, all countries havethe attribute capital), and use a special purposeset of filters rather than entity co-occurrence andclustering.
Our work can be seen as a generalizationof theirs to relationships of any kind, and we extendthe use of frequency patterns to finding generaln-gram entities rather than single word entities.
(Madkour et al, 2007) give an excellent overview597of biomedical NER and RE.
They propose a statis-tical system for RE, but rely on NER, POS tagging,and the creation of a dictionary for each domain ofapplication.
Also, they do not cluster relationshipsinto semantically related groups.6 ConclusionOur work makes a series of important improvementsto the state-of-the-art in relationship discovery.First, by incorporating entity discovery into the rela-tionship discovery pipeline, our method does not re-quire distinct training phases to accommodate differ-ent entity types, relations, or discourse types.
Sec-ond, p-median clustering effectively uncovers thebase form of relations present in the corpus, address-ing an important limitation in usability.
In terms ofspecific hypotheses, we have tested and confirmedthat co-occurrence can be a good indicator of thepresence of a relationship but the size of a clusteris not necessarily a good indicator of the importanceor strength of the discovered relationship.
Further-more, we have shown that longer RPs with morecontext give higher precision (at the cost of reducedcoverage).
Finally, the integration of ideas in ourapproach?unsupervisedness, efficiency, flexibility(in application), and specificity?is novel in itself.In future work, we seek to expand upon our RDmethods in three directions.
First, we would liketo generalize the scope of our discovery pipelinebeyond binary relations and with richer considera-tions of context, even across sentences.
Second, wehope to achieve greater tunability of performance,to account for additional discovery metrics besidesprecision.
Finally, we intend to induce entire con-cept maps from text using the discovered relationsto bootstrap an RE phase, where the underlyingproblem is not just of inferring multiple types ofrelations, but to have sufficient co-ordination amongthe discovered relations to ensure connectednessamong the resulting concepts.While our method requires no supervision in theform of manually annotated entities or relations,the effectiveness of the system relies on the carefultuning of a number of parameters.
Nevertheless,the results reported in Section 4.2 suggest that thetwo parameters that most significantly affect perfor-mance exhibit predictable precision/recall behavior.Of the parameters not considered in Section 4.2,we would like to further investigate the benefits ofchunking entities on the resulting base relations, ex-perimenting with different measures of collocation.AcknowledgementsWe would like to thank our anonymous reviewersfor their thought-provoking questions.
This workwas supported in part by the Institute for CriticalTechnology and Applied Science (ICTAS), VirginiaTech.ReferencesDmitry Davidov and Ari Rappoport.
2006.
Efficientunsupervised discovery of word categories usingsymmetric patterns and high frequency words.
In ACL?06: Proceedings of the 21st International Conferenceon Computational Linguistics and the 44th annualmeeting of the ACL, pages 297?304, Morristown, NJ,USA.
Association for Computational Linguistics.Dmitry Davidov, Ari Rappoport, and Moshe Koppel.2007.
Fully unsupervised discovery of concept-specific relationships by web mining.
In Proceedingsof the 45th Annual Meeting of the Association ofComputational Linguistics, pages 232?239, Prague,Czech Republic, June.
Association for ComputationalLinguistics.Beate Dorow, Dominic Widdows, Katarina Ling, Jean-Pierre Eckmann, Danilo Sergi, and Elisha Moses.2005.
Using curvature and markov clustering ingraphs for lexical acquisition and word sense discrim-ination.
In MEANING 05: 2nd workshop organizedby the MEANING Project, Trento, Italy, February.Gunes Erkan, Arzucan Ozgur, and Dragomir R. Radev.2007.
Semi-supervised classification for extractingprotein interaction sentences using dependency pars-ing.
In Proceedings of the 2007 Joint Conference onEmpirical Methods in Natural Language Processingand Computational Natural Language Learning(EMNLP-CoNLL), pages 228?237.Brendan J. Frey and Delbert Dueck.
2007.
Clusteringby passing messages between data points.
Science,315:972?976.Takaaki Hasegawa, Satoshi Sekine, and Ralph Grishman.2004.
Discovering relations among named entitiesfrom large corpora.
In ACL ?04: Proceedings of the42nd Annual Meeting on Association for Computa-tional Linguistics, page 415, Morristown, NJ, USA.Association for Computational Linguistics.Amgad Madkour, Kareem Darwish, Hany Hassan,Ahmed Hassan, and Ossama Emam.
2007.
Bionoc-ulars: Extracting protein-protein interactions frombiomedical text.
In Biological, translational, andclinical language processing, pages 89?96, Prague,Czech Republic, June.
Association for ComputationalLinguistics.598T.
Mitsumori, M. Murata, Y. Fukuda, K. Doi, and H. Doi.2006.
Extracting protein-protein interaction informa-tion from biomedical text with svm.
IEICE Transac-tions on Information and Systems, 89(8):2464?2466.Benjamin Rosenfeld and Ronen Feldman.
2006.
High-performance unsupervised relation extraction fromlarge corpora.
In ICDM ?06: Proceedings of theSixth International Conference on Data Mining, pages1032?1037, Washington, DC, USA.
IEEE ComputerSociety.Benjamin Rosenfeld and Ronen Feldman.
2007.
Cluster-ing for unsupervised relation identification.
In CIKM?07: Proceedings of the sixteenth ACM conference onConference on information and knowledge manage-ment, pages 411?418, New York, NY, USA.
ACM.Sayori Shimohata, Toshiyuki Sugio, and Junji Nagata.1997.
Retrieving collocations by co-occurrences andword order constraints.
In In Proceedings of the 35thAnnual Meeting of the Association for ComputationalLinguistics, pages 476?481.Yusuke Shinyama and Satoshi Sekine.
2006.
Preemptiveinformation extraction using unrestricted relationdiscovery.
In Proceedings of the Human LanguageTechnology Conference of the NAACL, Main Con-ference, pages 304?311, New York City, USA, June.Association for Computational Linguistics.A.
Yakushiji, Y. Miyao, Y. Tateisi, and J. Tsujii.
2005.Biomedical information extraction with predicate-argument structure patterns.
In Proceedings of theeleventh annual meeting of the association for naturallanguage processing, pages 93?96.599
