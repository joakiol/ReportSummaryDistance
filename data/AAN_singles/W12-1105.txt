JEP-TALN-RECITAL 2012, Atelier DEFT 2012: D?fi Fouille de Textes, pages 41?48,Grenoble, 4 au 8 juin 2012. c?2012 ATALA & AFCPD?tection de mots-cl?s par approches au grain caract?re et augrain motGa?lle Doualan, Mathieu Boucher, Romain Brixtel, Ga?l Lejeune, Ga?l Dias?quipe HULTECH (GREYC, Universit?
de Caen), Bd Mar?chal juin, 14032 Caen Cedexprenom.nom@unicaen.frR?SUM?Nous pr?sentons dans cet article les m?thodes utilis?es par l?
?quipe HULTECH pour sa partici-pation au D?fi Fouille de Textes 2012 (Deft 2012).
La t?che de cette ?dition du d?fi consiste ?retrouver dans des articles scientifiques, les mots-cl?s choisis par les auteurs.
Nous nous appuyonssur la d?tection de cha?nes r?p?t?es maximales (rst rmax), au grain caract?re et au grain mot.
Lam?thode d?velopp?e est simple et non supervis?e.
Elle a permis ?
notre syst?me d?atteindre la 3eplace (sur 10 ?quipes) sur la premi?re piste du d?fi.ABSTRACTKeywords extraction by repeated string analysisWe present here the HULTECH(Human Language Technology) team approach for the Deft 2012(french text mining challenge).
The aim of the challenge is to retrieve the keywords given bythe authors of scientific articles.
Our method relies on a text algorithmics technic : detection ofmaximal repeated strings.
This technic is applied at character level and word level.
We achievedthe third rank (over 10) of the first track.MOTS-CL?S : Recherche d?information, extraction de mots-cl?s, algorithmique du texte.KEYWORDS: Information retrieval, keywords extraction, string algorithmics.1 IntroductionLa t?che propos?e dans le cadre du D?fi Fouille de Textes 2012 consiste ?
retrouver dans desarticles de sciences humaines les mots-cl?s propos?s par les auteurs.
Le corpus de travail estscind?
en deux pistes, la premi?re comportant 140 articles et la seconde 141.
Une terminologiequi regroupe tous les mots-cl?s des articles est propos?e avec la premi?re piste.
Dans cet articlenous proposerons deux approches : une bas?e sur la connaissance de la terminologie, une autreadapt?e ?
l?absence de cette terminologie.
Ce sera pour nous l?occasion de comparer les deuxapproches et leurs r?sultats.
Nos deux approches s?appuient sur un algorithme de recherchede cha?nes r?p?t?es maximales, ci-apr?s rst rmax 1.
Dans la premi?re approche, bas?e sur laterminologie, nous prenons comme grain d?analyse le caract?re.
Dans la seconde approche nousprenons comme grain d?analyse le mot graphique, sans appui sur la terminologie ni pour lapiste 1 ni pour la piste 2.
Dans la section 2, nous proc?dons ?
une analyse du corpus qui nouspermet d?appr?hender le mat?riau sur lequel nous travaillons.
Dans la section 3, nous d?taillons1.
L?implantation en python utilis?e est disponible ?
l?url suivante : code.google.com/p/py-rstr-max41nos deux approches.
Ensuite, nous pr?senterons les r?sultats dans la section 4et proposons uneconfrontation de ces deux approches dans la section 5.2 Description du corpusLe corpus utilis?
comporte des articles de sciences humaines provenant de quatre revues diffus?essur le site Erudit 2.
Nous pr?senterons ici plus pr?cis?ment les articles2.1 ?
traiter et les mots-cl?squi leur sont associ?s2.2.2.1 Les articles du corpus DEFT 2012Le corpus DEFT 2012 est constitu?
de 300 articles r?partis sur 4 revues de sciences humaines :?
Anthropologie et Soci?t?
(AS)?
Revue des Sciences de l?Education (RSE)?
Traduction, Terminologie et R?daction (TTR)?
M?ta : journal des traducteurs (META)2.1.1 Configuration des articlesLes articles sont au format xml.
Ils sont constitu?s d?un identifiant, de la liste des mots-cl?sfournis par l?auteur, d?un r?sum?
et du corps de l?article lui-m?me.
Le nom de la revue n?appara?tpas dans le fichier xml mais dans le nom du fichier.
De m?me, le nom de l?auteur et le titre del?article ne figurent pas dans le fichier xml.
Ceci a rendu plus complexe la recherche des mots-cl?snotamment du fait que le nom de l?auteur figurait syst?matiquement parmi les mots-cl?s desarticles de la revue Anthropologie et Soci?t?.Nous pr?sentons dans la figure 1 un exemple d?article du corpus afin de montrer sa configurationet sa structure, notons que les titres et sous-titres des articles n?
?taient pas disponibles.2.1.2 Statistiques sur les articlesNous avons effectu?
des statistiques sur les articles afin de pouvoir mieux les appr?hender(Tableau 2).Nombre de documents Taille moyenne en paragraphes Taille moyenne en caract?resPiste 1 94 67,8 41235Piste 2 93 80,2 39153Tableau 1 ?
Statistiques sur les documents du corpus d?
?valuationLe nombre moyen de paragraphes ne varie pas particuli?rement en fonction de la revue, ?l?exception de certains articles de META pour lequel le d?coupage en paragraphes ?tait mauvais.2.
http://www.erudit.org42< ?xml version="1.0" encoding="UTF-8" ?>-<doc id="0001">-<motscles><nombre>4</nombre><mots>Labrecque ;?conomie politique ;f?minisme ;ethnographie</mots></motscles>-<article>-<resume><p>Tout en poursuivant l?objectif de la pr?sentation du num?ro,.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.la consolidation de la th?orie.</p></resume>-<corps><p>Qui sape l?ethnographie ?branle la th?orie.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.d?une anthropologie engag?e, d?autre part.</p></corps></article></doc>FIGURE 1 ?
Un exemple d?article du jeu d?entra?nement432.2 Les mots-cl?sNous avons remarqu?
que les articles ne comportent pas le m?me nombre de mots-cl?s : enmoyenne 5,4 95,2 sur la piste 2 et 5,7 sur la piste 1).
Mais une grande disparit?
peut existerd?un texte ?
l?autre, l?
?tendue ?tant de 9 (1 ?
10 mots cl?s par article).
Nous avons not?
que lepremier mot-cl?
est syst?matiquement le nom de l?auteur de l?article pour la revue Anthropologieet Soci?t?.
C?est dans un tel cas que la mention du nom de l?auteur dans le fichier nous aurait ?t?utile.2.2.1 Nature des mots-cl?s?
Noms propres : nom de l?auteur (ex : Labrecque), auteur faisant l?objet de l?article (ex : JackKerouac), lieu g?ographique (ex : Japon)?
Noms communs : des noms communs seuls ou parfois accompagn?s d?adjectifs, mais jamais deverbes ni d?adverbes (ex : f?minisme, ?conomie politique)?
Parfois les noms sont compl?t?s par des compl?ments du noms, formant des motifs tels quecelui-ci : N de art N (ex : traitement de l?information sociale)?
Cas particuliers : des noms coordonn?s (ex : traduction scientifique et technique)Nous avons remarqu?
que plus les mots-cl?s ?taient longs, moins on avait de chances de lesretrouver tels quels dans le texte.
Lorsque l?on a la chance de les rencontrer dans le texte, ils ysont peu fr?quents.
Globalement 79% des mots-cl?s sont pr?sents tels quels dans le corps dutexte, 44,5% dans le r?sum?
et 42% et dans le corps et dans le r?sum?.3 Description des approchesNotre premi?re approche bas?e sur le grain caract?re utilise la terminologie afin de s?attaquer ?
lapiste 1.
Notre seconde approche n?utilise pas la terminologie et a ?t?
utilis?e sur les deux pistes.3.1 Approche au grain caract?reNous reprenons ici les principes de la m?thode utilis?e pour le Deft 2011 (Lejeune et al, 2011).On suppose que les segments communs entre le r?sum?
et le reste du texte constituent de bonsdescripteurs.
Pour s?lectionner les descripteurs pertinents nous nous fondons sur leur proximit?avec des ?l?ments terminologie, technique utilis?e dans le domaine de l?Extraction d?Informationmultilingue (Lejeune et al, 2010).La m?thode rst rmax L?analyse au grain caract?re est effectu?
en recherchant des motifs sanstrous (ci-apr?s motifs) tels que d?finis par (Ukkonen, 2009).
Ces motifs sont des sous-cha?nes dutexte ayant les caract?ristiques suivantes 3 :r?p?t?s : les motifs apparaissent au moins deux fois ;maximaux : les motifs ne sont pas inclus dans des motifs plus grands et de m?me effectif3.
Pour une description plus formelle voir code.google.com/p/py-rstr-max44Nous comparons les deux segments textuels(r?sum?
et corps) et l?ensemble de la terminologieen une seule op?ration.
Nous conservons les rst r ?max apparaissant dans ces deux segments etdans un ?l?ment de la terminologie.
Seuls les motifs respectant un crit?re de longueur donn?sont consid?r?s comme pertinents.
Pour tenir compte des variations morphologiques du fran?ais,nous avons fix?
la proximit?
minimale entre un motif trouv?
et un ?l?ment de la terminologie ?0.9.
Autrement dit, un ?l?ment t de la terminologie est consid?r?
comme mot-cl?
du texte s?ilexiste une cha?ne c telle que :?
c est pr?sent dans le r?sum?
et dans le corps de l?article?
c est une sous cha?ne de t?
len(c)len(t) ?
910 avec len le nombre de caract?res dans c et tNous n?avons pas appliqu?
cette m?thode ?
la seconde piste car la s?lection de cha?nes decaract?res adapt?es ?
l?
?valuation ?tait malais?e.
Il aurait fallu un grand nombre d?heuristiquespour retrouver des mots-cl?s comparables ?
la r?f?rence.
Nous avons pr?f?r?
garder la "puret?
"de cette m?thode.
En effet le seul pr?-traitement effectu?
est le d?coupage en deux segmentstextuels (r?sum?
et corps).
Aucun outillage linguistique (lemmatisation, ?tiquetage.
.
.)
n?estn?cessaire.
Par ailleurs, aucun post-traitement n?est effectu?.3.2 Approche au grain motPour notre seconde approche, nous proc?dons ?
un d?coupage plus classique en mots.
Cettem?thode est con?ue pour fonctionner en l?absence de terminologie de r?f?rence.
Nous appliquonsl?algorithme de d?tection des rst rmax (section : 3.1) mais en l?appliquant cette fois sur des mots.L?algorithme rst rmax est appliqu?
?
tout ce qui est compris entre les balises <article> ce quicorrespond au r?sum?
et au corps de l?article.
Nous consid?rons le tout comme une cha?ne.
Nousobtenons ainsi un ensemble de cha?nes de mots r?p?t?es et maximales.
Un grand nombre demotifs sont d?tect?s dont certains sont partiellement redondants.
Par exemple, on a les motifABC D et BC DF et on souhaite souvent ne garder que la partie centrale BC D. Pour am?liorer lapr?cision, nous appliquons donc une seconde fois rst rmax sur la liste des cha?nes obtenues.3.2.1 IDFPour am?liorer la pr?cision de nos r?sultats, nous voulons r?duire encore le nombre de cha?nesobtenues.
Cependant, il nous faut conserver un rappel correct.
Pour ce faire nous avons choiside calculer l?IDF (Inverse Document Frequency) de chaque cha?ne.
Cette mesure fait ressortirles cha?nes sp?cifiques ?
un texte par rapport au corpus.
L?IDF est l?inverse de la fr?quence dela cha?ne dans un ensemble de documents.
Cette mesure est g?n?ralement coupl?e avec le TF(term frequency ou effectif du mot dans un document) en Voici comment se calcule le T F ?
I DFd?une cha?ne C dans un document D 4 :T F ?
I DF = f req(C ,D)t(D) ??
log2 nd(C)N45Avec :?
freq(C,D) le nombre de fois que la cha?ne C appara?t dans le document D?
t(D) le nombre de mots du document D?
nd(C) le nombre de documents contenant C dans le corpus?
N la taille du corpus en documentsCependant, nous ne conservons que l?IDF.
Dans notre cas, il n?
?tait pas n?cessaire l?appliquer leTF.
En effet, gr?ce ?
la m?thode rst rmax , nous obtenons les cha?nes maximales r?p?t?es, ce quisignifie qu?elles ont d?j?
une certaine fr?quence dans le document.
Par ailleurs, le TF a tendance?
privil?gier les cha?nes tr?s fr?quentes d?un texte, autrement dit des mots vides peu susceptiblesd?
?tre des mots-cl?s.Pour calculer l?IDF, nous consid?rons l?ensemble des articles d?une piste.
Cela nous permet decaract?riser un article par rapport ?
une piste.
Cela se justifie si nous nous repla?ons dansle s?mantique textuelle de Fran?ois Rastier : " le texte pour une linguistique ?volu?e l?unit?minimale, et le corpus l?ensemble dans lequel cette unit?
prend son sens "(Rastier, 2002).
Ainsi,un article ne prend son sens que dans le corpus de travail si bien que nous devons caract?riserces cha?nes et ces mots-cl?s par rapport ?
l?ensemble du corpus.
Lorsque nous calculons l?IDF descha?nes nous obtenons des r?sultats compris entre 0 et 5.
Nous classons les cha?nes en ordred?croissant de leur IDF.
Le but ?tant de r?duire le nombre de cha?nes, nous ne conservons quecelles dans l?IDF est sup?rieure ?
2.3.2.2 Pond?ration des cha?nesL?IDF constitue un premier filtrage par pond?ration mais ce n?est pas suffisant.
Nous proc?donsdonc ?
un second filtrage par pond?ration en attribuant un poids aux cha?nes restantes enfonction des crit?res suivants :?
IDF?
fr?quence de la cha?ne dans l?article?
fr?quence de la cha?ne dans le r?sum??
longueur de la cha?ne?
pr?sence de la cha?ne dans le premier paragraphe (a priori : introduction?
pr?sence de la cha?ne dans la dernier paragraphe (a priori : conclusion)A chacune de ces mesures est attribu?
un coefficient qui pond?re leur importance.
Nous avonseffectu?
des statistiques sur le corpus afin d?anticiper les places occup?es par les mots-cl?s dansles articles.
Ainsi, si une cha?ne est fr?quente dans le r?sum?, elle a davantage de chance d?
?treun mot-cl?
qu?une autre cha?ne.
Nous attribuons donc un certain poids ?
ces mesures en fonctionde leur capacit?
?
traduire le comportement des mots-cl?s.
Notons que l?absence des titres dansles documents analys?s rend difficile la d?tection des segments introductifs et conclusifs .
Lescha?nes sont rang?es en ordre d?croissant de poids et nous s?lectionnons les 7 premi?res cha?nesen guise de mots-cl?s.
Ce seuil a ?t?
fix?
?
partir des meilleurs r?sultats obtenus sur le corpusd?entra?nement.464 R?sultatsR?sultat piste 1 R?sultat piste 2Approche 1 : rst rmax au grain caract?re 0.44, 3e/10 Approche 2 : rst rmax au grain mot 0,12 0,13, 7e/9Baseline : tf-idf simple 0,08 0,07Tableau 2 ?
R?sultats et rangs pour nos 2 approches et notre baselineLa premi?re approche donne de bons r?sultats en raison de l?appui de la terminologie, bienmeilleurs qu?avec l?approche par poids.
Sans doute ces r?sultats auraient pu ?tre am?lior?s avecquelques heuristiques, par exemple : chercher ?
affecter chaque mot-cl?
de la terminologie ?
aumoins un document.
Mais nous n?avons pas souhait?
complexifier la proc?dure utilis?e.Concernant la seconde approche, elle aurait sans doute eu de meilleurs r?sultats sur la piste 1 ens?appuyant sur la terminologie mais nous avons souhait?
pour les deux pistes conserver l?aspect?sans ressources externes".5 DiscussionNous avons opt?
pour des m?thodes simples ?
mettre en place et peu co?teuses en temps,peut ?tre au d?triment de la qualit?
des r?sultats.
La premi?re approche se voulait avant toutind?pendante de la langue consid?r?e.
Travailler sur le grain caract?re permet de d?passerles probl?mes de d?coupage des textes en mots.
Toutefois pour se conformer aux modalit?sd?
?valuation, le soutien de la terminologie s?est av?r?
n?cessaire.
La seconde approche se voulaitind?pendante de tout support ext?rieur.
En effet, ne pas utiliser la terminologie permet d?extrairedes informations nouvelles ?
partir d?un document brut.Nos deux approches ont en commun l?utilisation d?une m?thode d?algorithmique du texte :rst rmax .
L?algorithme recherche des cha?nes r?p?t?es maximales, suppos?es caract?ristiques d?untexte.
Nos approches diff?rent par le grain d?analyse : caract?re pour l?une, mot pour l?autre.La premi?re m?thode pr?sente l?avantage de la simplicit?, elle ne n?cessite aucun param?tre maise base sur la terminologie.
La seconde m?thode ne n?cessite pas de terminologie mais imposedes traitements suppl?mentaires.Nos deux m?thodes pr?sentent par ailleurs l?avantage de d?tecter facilement des unit?s multi-mots, souvent plus pertinentes pour des t?ches d?indexation documentaire et de recherched?information.Enfin, nos deux approches sont ind?pendantes de tout module d?analyse linguistique (lemma-tisation, ?tiquetage.
.
.)
ce qui les rend a priori moins sensibles ?
une utilisation sur d?autreslangues que le fran?ais.
Il serait donc int?ressant d?exp?rimenter ces techniques sur des corpusmultilingues.47R?f?rencesLEJEUNE, G., BRIXTEL, R., GIGUET, E. et LUCAS, N. (2011).
Deft2011 : appariement de r?sum?s etd?articles scientifiques fond?
sur les cha?nes de caract?res.
In D?fi Fouille de Textes/TALN 2011,pages 53?64.LEJEUNE, G., DOUCET, A., YANGARBER, R. et LUCAS, N. (2010).
Filtering news for epidemicsurveillance : towards processing more languages with fewer resources.
In 4th Workshop onCross Lingual Information Access, pages 3?10.RASTIER, F. (2002).
Enjeux ?pist?mologiques de la linguistique de corpus.
In 2?me journ?es de lalinguistique de corpus.UKKONEN, E. (2009).
Maximal and minimal representations of gapped and non-gapped motifsof a string.
Theor.
Comput.
Sci., 410(43):4341?4349.48
