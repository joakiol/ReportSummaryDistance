NAACL HLT Demonstration Program, pages 29?30,Rochester, New York, USA, April 2007. c?2007 Association for Computational LinguisticsText Comparison Using Machine-Generated NuggetsLiang ZhouInformation Sciences InstituteUniversity of Southern California4676 Admiralty WayMarina del Rey, CA 90292liangz@isi.eduAbstractThis paper describes a novel text com-parison environment that facilities textcomparison administered through assess-ing and aggregating information nuggetsautomatically created and extracted fromthe texts in question.
Our goal in design-ing such a tool is to enable and improveautomatic nugget creation and present itsapplication for evaluations of variousnatural language processing tasks.
Duringour demonstration at HLT, new users willable to experience first hand text analysiscan be fun, enjoyable, and interesting us-ing system-created nuggets.1 IntroductionIn many natural language processing (NLP) tasks,such as question answering (QA), summarization,etc., we are faced with the problem of determiningthe appropriate granularity level for informationunits in order to conduct appropriate and effectiveevaluations.
Most commonly, we use sentences tomodel individual pieces of information.
However,more and more NLP applications require us to de-fine text units smaller than sentences, essentiallydecomposing sentences into a collection ofphrases.
Each phrase carries an independent pieceof information that can be used as a standaloneunit.
These finer-grained information units areusually referred to as nuggets.Previous work shows that humans can createnuggets in a relatively straightforward fashion.
Aserious problem in manual nugget creation is theinconsistency in human decisions (Lin and Hovy,2003).
The same nugget will not be marked consis-tently with the same words when sentences con-taining multiple instances of it are presented tohuman annotators.
And if the annotation is per-formed over an extended period of time, the con-sistency is even lower.Given concerns over these issues, we have setout to design an evaluation toolkit to address threetasks in particular: 1) provide a consistent defini-tion of what a nugget is; 2) automate the nuggetextraction process systematically; and 3) utilizeautomatically extracted nuggets for text compari-son and aggregation.The idea of using semantic equivalent nuggetsto compare texts is not new.
QA and summariza-tion evaluations (Lin and Demner-Fushman, 2005;Nenkova and Passonneau, 2004) have been carriedout by using a set of manually created nuggets andthe comparison procedure itself is either automaticusing n-gram overlap counting or manually per-formed.
We envisage the nuggetization processbeing automated and nugget comparison and ag-gregation being performed by humans.
It?s crucialto still involve humans in the process because rec-ognizing semantic equivalent text units is not atrivial task.
In addition, since nuggets are system-produced and can be imperfect, annotators are al-lowed to reject and re-create them.
We provideeasy-to-use editing functionalities that allow man-ual overrides.
Record keeping on edits over erro-neous nuggets is conducted in the background sothat further improvements can be made for nuggetextraction.292  Nugget DefinitionBased on our manual analysis and computationalmodeling of nuggets, we define them as follows:Definition:?
A nugget is predicated on either an event  oran entity .?
Each nugget consists of two parts: the an-chor and the content.The anchor is either:?
the head noun of the entity, or?
the head verb of the event, plus the headnoun of its associated entity (if more thanone entity is attached to the verb, then itssubject).The content is a coherent single piece of infor-mation associated with the anchor.
Each anchormay have several separate contents.
When thenugget contains nested sentences, this definition isapplied recursively.3  Nugget ExtractionWe use syntactic parse trees produced by theCollins parser (Collins, 1999) to obtain the struc-tural representation of sentences.
Nuggets are ex-tracted by identifying subtrees that are descriptionsfor entities and events.
For entities, we examinesubtrees headed by ?NP?
; for events, subtreesheaded by ?VP?
are examined and their corre-sponding subjects (siblings headed by ?NP?)
areinvestigated as possible entity attachments for theverb phrases.
Figure 1 shows an example wherewords in brackets represent corresponding nug-gets?
anchors.4  Comparing TextsWhen comparing multiple texts, we present theannotator with each text?s sentences along withnuggets extracted from individual sentences (seeAppendix A).
Annotators can select multiple nug-gets from sentences across texts to indicate theirsemantic equivalence.
Equivalent nuggets aregrouped into nugget groups.
There is a frequencyscore, the number of texts it appeared in, for eachnugget group.
We allow annotators to modify thenugget groups?
contents, thus creating a new label(or can be viewed as a super-nugget) for each nug-get group.
Record keeping is conducted in thebackground automatically each time a nuggetgroup is created.
When the annotator changes thecontent of a nugget group, it indicates that eitherthe system-extracted nuggets are not perfect or asuper-nugget is created for the group (see Appen-dix B and C).
These editing changes are recorded.The recorded information affords us the opportu-nity to improve the nuggetizer and perform subse-quence study phrase-level paraphrasing, textentailment, etc.5  Hardware RequirementOur toolkit is written in Java and can be run on anymachine with the latest Java installed.ReferencesCollins, M. 1999.
Head-driven statistical modelsfor natural language processing.
Ph D Disserta-tion , University of Pennsylvania.Lin, C.Y.
and E. Hovy.
2003.
Automatic evalua-tion of summaries using n-gram co-occurrencestatistics.
In Proceedings of N A A CL- H LT  2 0 0 3 .Lin, J. and D. Demner-Fushman.
2005.
Automati-cally evaluating answers to definition questions.In Pr o ceedings of  H LT - E MN L P 2 0 0 5 .Nenkova, A. and R. Passonneau.
2004.
Evaluatingcontent selection in summarization: the pyramidmethod.
In Proceedings of NAACL-HLT 2004.Sentence:The girl working at the bookstore in Hollywoodtalked to the diplomat living in Britain.Nuggets are:[girl] working at the bookstore in Hollywood[girl] working at the bookstore[bookstore] in Hollywoodgirl [talked] to the diplomat living in Britaingirl [talked] to the diplomat[diplomat] living in BritianFigure 1.
Nugget example.
(words in brackets arethe anchors).30
