Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 98?102,Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational LinguisticsUsing collocation segmentation to augment the phrase tableCarlos A. Henr?quez Q.?, Marta R.
Costa-juss?
?, Vidas Daudaravicius?Rafael E.
Banchs?, Jos?
B.
Mari?o?
?TALP Research Center, Universitat Polit?cnica de Catalunya, Barcelona, Spain{carlos.henriquez,jose.marino}@upc.edu?Barcelona Media Innovation Center, Barcelona, Spain{marta.ruiz,rafael.banchs}@barcelonamedia.org?Faculty of Informatics, Vytautas Magnus University, Kaunas, Lithuaniavidas@donelaitis.vdu.ltAbstractThis paper describes the 2010 phrase-basedstatistical machine translation system de-veloped at the TALP Research Center ofthe UPC1in cooperation with BMIC2andVMU3.
In phrase-based SMT, the phrasetable is the main tool in translation.
It iscreated extracting phrases from an alignedparallel corpus and then computing trans-lation model scores with them.
Performinga collocation segmentation over the sourceand target corpus before the alignmentcauses that different and larger phrasesare extracted from the same original doc-uments.
We performed this segmentationand used the union of this phrase set withthe phrase set extracted from the non-segmented corpus to compute the phrasetable.
We present the configurations con-sidered and also report results obtainedwith internal and official test sets.1 IntroductionThe TALP Research Center of the UPC1in coop-eration with BMIC2and VMU3participated in theSpanish-to-English WMT task.
Our primary sub-mission was a phrase-based SMT system enhancedwith POS tags and our contrastive submission wasan augmented phrase-based system using colloca-tion segmentation (Costa-juss?
et al, 2010), whichmainly is a way of introducing new phrases in thetranslation table.
This paper presents the descrip-tion of both systems together with the results thatwe obtained in the evaluation task and is organizedas follows: first, Section 2 and 3 present a brief de-scription of a phrase-based SMT, followed by a gen-eral explanation of collocation segmentation.
Sec-tion 4 presents the experimental framework, corpusused and a description of the different systems builtfor the translation task; the section ends showingthe results we obtained over the official test set.
Fi-nally, section 5 presents the conclusions obtainedfrom the experiments.1Universitat Polit?cnica de Catalunya2Barcelona Media Innovation Center3Vytautas Magnus University2 Phrase-based SMTThis approach to SMT performs the translationsplitting the source sentence in segments and as-signing to each segment a bilingual phrase froma phrase-table.
Bilingual phrases are translationunits that contain source words and target words,e.g.
< unidad de traduccio?n | translation unit >,and have different scores associated to them.
Thesebilingual phrases are then sorted in order to max-imize a linear combination of feature functions.Such strategy is known as the log-linear model(Och and Ney, 2003) and it is formally defined as:e?
= arg maxe[M?m=1?mhm (e, f)](1)where hm are different feature functions withweights ?m.
The two main feature functionsare the translation model (TM) and the targetlanguage model (LM).
Additional models includePOS target language models, lexical weights, wordpenalty and reordering models among others.3 Collocation segmentationCollocation segmentation is the process of de-tecting boundaries between collocation segmentswithin a text (Daudaravicius and Marcinkeviciene,2004).
A collocation segment is a piece of text be-tween boundaries.
The boundaries are establishedin two steps using two different measures: the Dicescore and a Average Minimum Law (AML).The Dice score is used to measure the associa-tion strength between two words.
It has been usedbefore in the collocation compiler XTract (Smadja,1993) and in the lexicon extraction system Cham-pollion (Smadja et al, 1996).
It is defined as fol-lows:Dice (x; y) =2f (x, y)f (x) + f (y)(2)where f (x, y) is the frequency of co-occurrence ofx and y, and f (x) and f (y) the frequencies ofoccurrence of x and y anywhere in the text.
It giveshigh scores when x and y occur in conjunction.The first step then establishes a boundary between98two adjacent words when the Dice score is lowerthan a threshold t = exp (?8).
Such a thresholdwas established following the results obtained in(Costa-juss?
et al, 2010), where an integration ofthis technique and a SMT system was performedover the Bible corpus.The second step of the procedure uses the AML.It defines a boundary between words xi?1 and xiwhen:Dice (xi?2;xi?1) +Dice (xi;xi+1)2> Dice (xi?1;xi)(3)That is, the boundary is set when the Dice valuebetween words xi and xi?1 is lower than the aver-age of preceding and following values.4 Experimental FrameworkAll systems were built using Moses (Koehn et al,2007), a state-of-the-art software for phrase-basedSMT.
For preprocessing Spanish, we used Freeling(Atserias et al, 2006), an open source library ofnatural language analyzers.
For English, we usedTnT (Brants, 2000) and Moses' tokenizer.
Thelanguage models were built using SRILM (Stolcke,2002).4.1 CorpusThis year, the translation task provided four dif-ferent sources to collect corpora for the Spanish-English pair.
Bilingual corpora included version 5of the Europarl Corpus (Koehn, 2005), the NewsCommentary corpus and the United Nations cor-pus.
Additional English corpora was available fromthe News corpus.
The organizers also allowed theuse of the English Gigaword Third and Fourth Edi-tion, released by the LDC.
As for developmentand internal test, the test sets from 2008 and 2009translation tasks were available.For our experiments, we selected as training datathe union of the Europarl and the News Commen-tary.
Development was performed with a sectionof the 2008 test set and the 2009 test set was se-lected as internal test.
We deleted all empty lines,removed pairs that were longer than 40 words, ei-ther in Spanish or English; and also removed pairswhose ratio between number of words were biggerthan 3.As a preprocess, all corpora were lower-casedand tokenized.
The Spanish corpus was tokenizedand POS tags were extracted using Freeling, whichsplit clitics from verbs and also separated wordslike del into de el.
In order to build a POS tar-get language model, we also obtained POS tagsfrom the English corpus using the TnT tagger.Statistics of the selected corpus can be seen in Ta-ble 1.Corpora Spanish EnglishTraining sent 1, 180, 623 1, 180, 623Running words 26, 454, 280 25, 291, 370Vocabulary 118, 073 89, 248Development sent 1, 729 1, 729Running words 37, 092 34, 774Vocabulary 7, 025 6, 199Internal test sent 2, 525 2, 525Running words 69, 565 65, 595Vocabulary 10, 539 8, 907Official test sent 2, 489 -Running words 66, 714 -Vocabulary 10, 725 -Table 1: Statistics for the training, developmentand test sets.Internal test Official testAdjectives 137 72Common nouns 369 188Proper nouns 408 2, 106Verbs 213 128Others 119 168Total 1246 2662Table 2: Unknown words found in internal andofficial test setsIt is important to notice that neither the UnitedNations nor the Gigaword corpus were used forbilingual training.
Nevertheless, the English partfrom the United Nations and the monolingualNews corpus were used to build the language modelof our systems.4.1.1 Unknown wordsWe analyzed the content from the internal and of-ficial test and realized that they both containedmany words that were not seen in the training data.Table 2 shows the number of unknown words foundin both sets, classified according to their POS.In average, we may expect an unknown wordevery two sentences in the internal test and morethan one per sentence in the official test set.
It canalso be seen that most of those unknown words areproper nouns, representing 32% and 79% of theunknown sets, respectively.
Common nouns werethe second most frequent type of unknown words,followed by verbs and adjectives.4.2 SystemsWe submitted two different systems for the trans-lation task.
First a baseline using the training datamentioned before; and then an augmented system,where the baseline-extracted phrase list was ex-tended with additional phrases coming from a seg-mented version of the training corpus.We also considered an additional system built99with two different decoding path, a standard pathfrom words to words and POS and an alternativepath from stems to words and POS in the targetside.
At the end, we did not submit this systemto the translation task because it did not providebetter results than the previous two in our internaltest.The set of feature functions used include: source-to-target and target-to-source relative frequen-cies, source-to-target and target-to-source lexicalweights, word and phrase penalties, a target lan-guage model, a POS target language model, and alexicalized reordering model (Tillman, 2004).4.2.1 Considering stems as an alternatedecoding path.Using Moses' framework for factored translationmodels we defined a system with two decodingpaths: one decoding path using words and theother decoding path using stems in the source lan-guage and words in the target language.
Both de-coding paths only had a single translation step.The possibility of using multiple alternative decod-ing path was developed by Birch et.
al.
(2007).This system tried to solve the problem with theunknown words.
Because Spanish is morphologi-cally richer than English, this alternative decodingpath allowed the decoder translate words that werenot seen in the training data and shared the sameroot with other known words.4.2.2 Expanding the phrase table usingcollocation segmentation.In order to build the augmented phrase table withthe technique mentioned in section 3, we seg-mented each language of the bilingual corpus in-dependently and then, using the collocation seg-ments as words, we aligned the corpus and ex-tracted the phrases from it.
Once the phrases wereextracted, the segments of each phrase were splitagain in words to have standard phrases.
Finally,we use the union of this phrases and the phrasesextracted from the baseline system to compute thefinal phrase table.
A diagram of the whole proce-dure can be seen in figure 1.The objective of this integration is to add newphrases in the translation table and to enhancethe relative frequency of the phrases that were ex-tracted from both methods.4.2.3 Language model interpolation.Because SMT systems are trained with a bilingualcorpus, they ended highly tied to the domain thecorpus belong to.
Therefore, when the documentswe want to translate belong to a different domain,additional domain adaptation techniques are rec-ommended to build the system.
Those techniquesusually employ additional corpora that correspondto the domain we want to translate from.internal testbaseline 24.25baseline+stem 23.45augmented 23.9Table 3: Internal test results.test testcased?detokbaseline 26.1 25.1augmented 26.1 25.1Table 4: Results from translation taskThe test set for this translation task comes fromthe news domain, but most of our bilingual cor-pora belonged to a political domain, the Europarl.Therefore we use the additional monolingual cor-pus to adapt the language model to the news do-main.The strategy used followed the experiment per-formed last year in (R. Fonollosa et al, 2009).We used SRILM during the whole process.
Alllanguage models were order five and used modi-fied Kneser-Ney discount and interpolation.
First,we build three different language models accord-ing to their domain: Europarl, United Nations andnews; then, we obtained the perplexity of each lan-guage model over the News Commentary develop-ment corpus; next, we used compute-best-mix toobtain weights for each language model that di-minish the global perplexity.
Finally, the modelswere combined using those weights.In our experiments all systems used the resultinglanguage model, therefore the difference obtainedin our results were cause only by the translationmodel.4.3 ResultsWe present results from the three systems devel-oped this year.
First, the baseline, which includedall the features mentioned in section 4.2; then, thesystem with an alternative decoding path, calledbaseline+stem; and finally the augmented system,which integrated collocation segmentation to thebaseline.
Internal test results can be seen in table3.
Automatic scores provided by the WMT 2010organizers for the official test can be found in ta-ble 4.
All BLEU scores are case-insensitive andtokenized except for the official test set which alsocontains case-sensitive and non-tokenized score.We obtained a BLEU score of 26.1 and 25.1 forour case-insensitive and sensitive outputs, respec-tively.
The highest score was obtained by Uni-versity of Cambridge, with 30.5 and 29.1 BLEUpoints.100Figure 1: Example of the expansion of the phrase table using collocation segmentation.
New phrasesadded by the collocation-based system are marked with a ?
?.4.3.1 Comparing systemsOnce we obtained the translation outputs from thebaseline and the augmented system, we performeda manual comparison of them.
Even though wedid not find any significant advantages of the aug-mented system over the baseline, the collocationsegmentation strategy chose a better morphologi-cal structures in some cases as can be seen in Table5 (only sentence sub-segments are shown):5 ConclusionWe presented two different submissions for theSpanish-English language pair.
The languagemodel for both system was built interpolating twobig out-of-domain language models and one smallerin-domain language model.
The first system was abaseline with POS target language model; and thesecond one an augmented system, that integratesthe baseline with collocation segmentation.
Re-sults over the official test set showed no differencein BLEU between these two, even though internalresults showed that the baseline obtained a betterscore.We also considered adding an additional decod-ing path from stems to words in the baseline butinternal tests showed that it did not improve trans-lation quality either.
The high number of unknownwords found in Spanish suggested us that consider-ing in parallel the simple form of stems could helpus achieve better results.
Nevertheless, a deeperstudy of the unknown set showed us that mostof those words were proper nouns, which do nothave inflection and therefore cannot benefited fromstems.Finally, despite that internal test did not showedan improvement with the augmented system, wesubmitted it as a secondary run looking for theeffect these phrases could have over human evalu-ation.AcknowledgmentThe research leading to these results has receivedfunding from the European Community's SeventhFramework Programme (FP7/2007-2013) undergrant agreement number 247762, from the Span-ish Ministry of Science and Innovation through theBuceador project (TEC2009-14094-C04-01) andthe Juan de la Cierva fellowship program.
Theauthors also wants to thank the Barcelona MediaInnovation Centre for its support and permissionto publish this research.ReferencesJordi Atserias, Bernardino Casas, ElisabetComelles, Meritxell Gonz?lez, Llu?s Padr?, andMuntsa Padr?.
2006.
FreeLing 1.3: Syntacticand semantic services in an open-source NLP101Original: sabiendo que est?
recibiendo el premioBaseline: knowing that it receive the prizeAugmented: knowing that he is receiving the prizeOriginal: muchos de mis amigos prefieren no separarla.Baseline: many of my friends prefer not to separate them.Augmented: many of my friends prefer not to separate it.Original: Los estadounidenses contar?n con un tel?fono m?vilBaseline: The Americans have a mobile phoneAugmented: The Americans will have a mobile phoneOriginal: es plenamente consciente del camino m?s largo que debe emprenderBaseline: is fully aware of the longest journey must undertakeAugmented: is fully aware of the longest journey that need to be takenTable 5: Comparison between baseline and augmented outputslibrary.
In Proceedings of the fifth interna-tional conference on Language Resources andEvaluation (LREC 2006), ELRA, Genoa, Italy,May.Alexandra Birch, Miles Osborne, and PhilippKoehn.
2007.
Ccg supertags in factored statis-tical machine translation.
In StatMT '07: Pro-ceedings of the Second Workshop on StatisticalMachine Translation, pages 916, Morristown,NJ, USA.
Association for Computational Lin-guistics.Thorsten Brants.
2000.
TnT  a statistical part-of-speech tagger.
In Proceedings of the SixthApplied Natural Language Processing (ANLP-2000), Seattle, WA.Marta R.
Costa-juss?, Vidas Daudaravicius, andRafael E. Banchs.
2010.
Integration of statisti-cal collocation segmentations in a phrase-basedstatistical machine translation system.
In 14thAnnual Conference of the European Associationfor Machine Translation.Vidas Daudaravicius and Ruta Marcinkeviciene.2004.
Gravity counts for the boundaries of col-locations.
International Journal of Corpus Lin-guistics, 9:321348(28).Philipp Koehn, Hieu Hoang, Alexandra Birch,Chris Callison-Burch, Marcello Federico, NicolaBertoldi, Brooke Cowan, Wade Shen, ChristineMoran, Richard Zens, Chris Dyer, Ond?ej Bojar,Alexandra Constantin, and Evan Herbst.
2007.Moses: Open Source Toolkit for Statistical Ma-chine Translation.
In ACL '07: Proceedings ofthe 45th Annual Meeting of the ACL on Interac-tive Poster and Demonstration Sessions, pages177180, Morristown, NJ, USA.
Association forComputational Linguistics.Philipp Koehn.
2005.
Europarl: A Parallel Corpusfor Statistical Machine Translation.
In MachineTranslation Summit.Franz Josef Och and Hermann Ney.
2003.
A Sys-tematic Comparison of Various Statistical Align-ment Models.
Computational Linguistics, 29:1951.Jos?
A. R. Fonollosa, Maxim Khalilov, Marta R.Costa-juss?, Jos?
B. Mari?o, Carlos A. Hen-r?quez Q., Adolfo Hern?ndez H., and Rafael E.Banchs.
2009.
The TALP-UPC phrase-basedtranslation system for EACL-WMT 2009.
InProceedings of the Fourth Workshop on Statis-tical Machine Translation, pages 8589, Athens,Greece, March.
Association for ComputationalLinguistics.Frank A. Smadja, Kathleen McKeown, andVasileios Hatzivassiloglou.
1996.
Translatingcollocations for bilingual lexicons: A statisticalapproach.
Computational Linguistics, 22(1):138.Frank Smadja.
1993.
Retrieving collocations fromtext: Xtract.
Comput.
Linguist., 19(1):143177.Andreas Stolcke.
2002.
SRILM  an extensiblelanguage modeling toolkit.
pages 901904.Christoph Tillman.
2004.
A Unigram OrientationModel for Statistical Machine Translation.
InHLT-NAACL.102
