Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 450?459,Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational LinguisticsOptimal Head-Driven Parsing Complexityfor Linear Context-Free Rewriting SystemsPierluigi CrescenziDip.
di Sistemi e InformaticaUniversita` di FirenzeDaniel GildeaComputer Science Dept.University of RochesterAndrea MarinoDip.
di Sistemi e InformaticaUniversita` di FirenzeGianluca RossiDip.
di MatematicaUniversita` di Roma Tor VergataGiorgio SattaDip.
di Ingegneria dell?InformazioneUniversita` di PadovaAbstractWe study the problem of finding the best head-driven parsing strategy for Linear Context-Free Rewriting System productions.
A head-driven strategy must begin with a specifiedrighthand-side nonterminal (the head) and addthe remaining nonterminals one at a time inany order.
We show that it is NP-hard to findthe best head-driven strategy in terms of eitherthe time or space complexity of parsing.1 IntroductionLinear Context-Free Rewriting Systems (LCFRSs)(Vijay-Shankar et al, 1987) constitute a very generalgrammatical formalism which subsumes context-free grammars (CFGs) and tree adjoining grammars(TAGs), as well as the synchronous context-freegrammars (SCFGs) and synchronous tree adjoin-ing grammars (STAGs) used as models in machinetranslation.1 LCFRSs retain the fundamental prop-erty of CFGs that grammar nonterminals rewriteindependently, but allow nonterminals to generatediscontinuous phrases, that is, to generate morethan one span in the string being produced.
Thisimportant feature has been recently exploited byMaier and S?gaard (2008) and Kallmeyer and Maier(2010) for modeling phrase structure treebanks withdiscontinuous constituents, and by Kuhlmann andSatta (2009) for modeling non-projective depen-dency treebanks.The rules of a LCFRS can be analyzed in termsof the properties of rank and fan-out.
Rank is the1To be more precise, SCFGs and STAGs generate languagescomposed by pair of strings, while LCFRSs generate string lan-guages.
We can abstract away from this difference by assumingconcatenation of components in a string pair.number of nonterminals on the right-hand side (rhs)of a rule, while fan-out is the number of spans ofthe string generated by the nonterminal in the left-hand side (lhs) of the rule.
CFGs are equivalent toLCFRSs with fan-out one, while TAGs are one typeof LCFRSs with fan-out two.
Rambow and Satta(1999) show that rank and fan-out induce an infi-nite, two-dimensional hierarchy in terms of gener-ative power; while CFGs can always be reduced torank two (Chomsky Normal Form), this is not thecase for LCFRSs with any fan-out greater than one.General algorithms for parsing LCFRSs build adynamic programming chart of recognized nonter-minals bottom-up, in a manner analogous to theCKY algorithm for CFGs (Hopcroft and Ullman,1979), but with time and space complexity that aredependent on the rank and fan-out of the gram-mar rules.
Whenever it is possible, binarization ofLCFRS rules, or reduction of rank to two, is there-fore important for parsing, as it reduces the timecomplexity needed for dynamic programming.
Thishas lead to a number of binarization algorithms forLCFRSs, as well as factorization algorithms thatfactor rules into new rules with smaller rank, with-out necessarily reducing rank all the way to two.Kuhlmann and Satta (2009) present an algorithmfor binarizing certain LCFRS rules without increas-ing their fan-out, and Sagot and Satta (2010) showhow to reduce rank to the lowest value possible forLCFRS rules of fan-out two, again without increas-ing fan-out.
Go?mez-Rodr?
?guez et al (2010) showhow to factorize well-nested LCFRS rules of arbi-trary fan-out for efficient parsing.In general there may be a trade-off requiredbetween rank and fan-out, and a few recent pa-pers have investigated this trade-off taking gen-450eral LCFRS rules as input.
Go?mez-Rodr?
?guez etal.
(2009) present an algorithm for binarization ofLCFRSs while keeping fan-out as small as possi-ble.
The algorithm is exponential in the resultingfan-out, and Go?mez-Rodr?
?guez et al (2009) mentionas an important open question whether polynomial-time algorithms to minimize fan-out are possible.Gildea (2010) presents a related method for bina-rizing rules while keeping the time complexity ofparsing as small as possible.
Binarization turns outto be possible with no penalty in time complexity,but, again, the factorization algorithm is exponen-tial in the resulting time complexity.
Gildea (2011)shows that a polynomial time algorithm for factor-izing LCFRSs in order to minimize time complexitywould imply an improved approximation algorithmfor the well-studied graph-theoretic property knownas treewidth.
However, whether the problem of fac-torizing LCFRSs in order to minimize time com-plexity is NP-hard is still an open question in theabove works.Similar questions have arisen in the context ofmachine translation, as the SCFGs used to modeltranslation are also instances of LCFRSs, as alreadymentioned.
For SCFG, Satta and Peserico (2005)showed that the exponent in the time complexityof parsing algorithms must grow at least as fast asthe square root of the rule rank, and Gildea and?Stefankovic?
(2007) tightened this bound to be lin-ear in the rank.
However, neither paper provides analgorithm for finding the best parsing strategy, andHuang et al (2009) mention that whether finding theoptimal parsing strategy for an SCFG rule is NP-hard is an important problem for future work.In this paper, we investigate the problem of rulebinarization for LCFRSs in the context of head-driven parsing strategies.
Head-driven strategies be-gin with one rhs symbol, and add one nontermi-nal at a time.
This rules out any factorization inwhich two subsets of nonterminals of size greaterthan one are combined in a single step.
Head-drivenstrategies allow for the techniques of lexicalizationand Markovization that are widely used in (projec-tive) statistical parsing (Collins, 1997).
The statis-tical LCFRS parser of Kallmeyer and Maier (2010)binarizes rules head-outward, and therefore adoptswhat we refer to as a head-driven strategy.
How-ever, the binarization used by Kallmeyer and Maier(2010) simply proceeds left to right through the rule,without considering the impact of the parsing strat-egy on either time or space complexity.
We examinethe question of whether we can efficiently find thestrategy that minimizes either the time complexityor the space complexity of parsing.
While a naivealgorithm can evaluate all r!
head-driven strategiesin time O(n ?
r!
), where r is the rule?s rank and nis the total length of the rule?s description, we wishto determine whether a polynomial-time algorithmis possible.Since parsing problems can be cast in terms oflogic programming (Shieber et al, 1995), we notethat our problem can be thought of as a type ofquery optimization for logic programming.
Queryoptimization for logic programming is NP-completesince query optimization for even simple conjunc-tive database queries is NP-complete (Chandra andMerlin, 1977).
However, the fact that variables inqueries arising from LCFRS rules correspond to theendpoints of spans in the string to be parsed meansthat these queries have certain structural properties(Gildea, 2011).
We wish to determine whether thestructure of LCFRS rules makes efficient factoriza-tion algorithms possible.In the following, we show both the the time- andspace-complexity problems to be NP-hard for head-driven strategies.
We provide what is to our knowl-edge the first NP-hardness result for a grammar fac-torization problem, which we hope will aid in under-standing parsing algorithms in general.2 LCFRSs and parsing complexityIn this section we briefly introduce LCFRSs and de-fine the problem of optimizing head-driven parsingcomplexity for these formalisms.
For a positive in-teger n, we write [n] to denote the set {1, .
.
.
, n}.As already mentioned in the introduction,LCFRSs generate tuples of strings over some finitealphabet.
This is done by associating each produc-tion p of a grammar with a function g that takes asinput the tuples generated by the nonterminals in p?srhs, and rearranges their string components into anew tuple, possibly adding some alphabet symbols.Let V be some finite alphabet.
We write V ?
forthe set of all (finite) strings over V .
For natural num-bers r ?
0 and f, f1, .
.
.
, fr ?
1, consider a func-451tion g : (V ?
)f1 ?
?
?
?
?
(V ?
)fr ?
(V ?
)f defined byan equation of the formg(?x1,1, .
.
.
, x1,f1?, .
.
.
, ?xr,1, .
.
.
, xr,fr?)
= ~?
.Here the xi,j?s denote variables over strings in V ?,and ~?
= ?
?1, .
.
.
, ?f ?
is an f -tuple of strings overg?s argument variables and symbols in V .
We saythat g is linear, non-erasing if ~?
contains exactlyone occurrence of each argument variable.
We call rand f the rank and the fan-out of g, respectively,and write r(g) and f(g) to denote these quantities.Example 1 g1(?x1,1, x1,2?)
= ?x1,1x1,2?
takes asinput a tuple with two strings and returns a tuplewith a single string, obtained by concatenating thecomponents in the input tuple.
g2(?x1,1, x1,2?)
=?ax1,1b, cx1,2d?
takes as input a tuple with twostrings and wraps around these strings with sym-bols a, b, c, d ?
V .
Both functions are linear, non-erasing, and we have r(g1) = r(g2) = 1, f(g1) = 1and f(g2) = 2.
2A linear context-free rewriting system is a tupleG = (VN , VT , P, S), where VN and VT are finite,disjoint alphabets of nonterminal and terminal sym-bols, respectively.
Each A ?
VN is associated witha value f(A), called its fan-out.
The nonterminal Sis the start symbol, with f(S) = 1.
Finally, P is aset of productions of the formp : A ?
g(A1, A2, .
.
.
, Ar(g)) , (1)where A,A1, .
.
.
, Ar(g) ?
VN , and g : (V ?T )f(A1)?
?
?
??
(V ?T )f(Ar(g)) ?
(V ?T )f(A) is a linear, non-erasing function.Production (1) can be used to transform ther(g) string tuples generated by the nonterminalsA1, .
.
.
, Ar(g) into a tuple of f(A) strings gener-ated by A.
The values r(g) and f(g) are called therank and fan-out of p, respectively, written r(p) andf(p).
Given that f(S) = 1, S generates a set ofstrings, defining the language L(G).Example 2 Let g1 and g2 be as in Example 1, andlet g3() = ?
?, ??.
Consider the LCFRS G defined bythe productions p1 : S ?
g1(A), p2 : A ?
g2(A)and p3 : A ?
g3().
We have f(S) = 1, f(A) =f(G) = 2, r(p3) = 0 and r(p1) = r(p2) = r(G) =1.
We have L(G) = {anbncndn |n ?
1}.
For in-stance, the string a3b3c3d3 is generated by meansfan-out strategy4 ((A1 ?A4) ?A3)?
?A23 (A1 ?A4)?
?
(A2 ?A3)3 ((A1 ?A2)?
?A4) ?A32 ((A?2 ?A3) ?A4) ?A1Figure 1: Some parsing strategies for production p in Ex-ample 3, and the associated maximum value for fan-out.Symbol ?
denotes the merging operation, and superscript?
marks the first step in the strategy in which the highestfan-out is realized.of the following bottom-up process.
First, the tuple?
?, ??
is generated by A through p3.
We then iteratethree times the application of p2 to ?
?, ?
?, resultingin the tuple ?a3b3, c3d3?.
Finally, the tuple (string)?a3b3c3d3?
is generated by S through application ofp1.
2Existing parsing algorithms for LCFRSs exploitdynamic programming.
These algorithms computepartial parses of the input string w, represented bymeans of specialized data structures called items.Each item indexes the boundaries of the segmentsof w that are spanned by the partial parse.
In thespecial case of parsing based on CFGs, an item con-sists of two indices, while for TAGs four indices arerequired.In the general case of LCFRSs, parsing of a pro-duction p as in (1) can be carried out in r(g) ?
1steps, collecting already available parses for nonter-minals A1, .
.
.
, Ar(g) one at a time, and ?merging?these into intermediate partial parses.
We refer to theorder in which nonterminals are merged as a pars-ing strategy, or, equivalently, a factorization of theoriginal grammar rule.
Any parsing strategy resultsin a complete parse of p, spanning f(p) = f(A)segments of w and represented by some item with2f(A) indices.
However, intermediate items ob-tained in the process might span more than f(A)segments.
We illustrate this through an example.Example 3 Consider a linear non-erasing functiong(?x1,1, x1,2?, ?x2,1, x2,2?, ?x3,1, x3,2?, ?x4,1, x4,2?
)= ?x1,1x2,1x3,1x4,1, x3,2x2,2x4,2x1,2?, and a pro-duction p : A ?
g(A1, A2, A3, A4), where all thenonterminals involved have fan-out 2.
We couldparse p starting from A1, and then merging with A4,452v1v2v3 v4e1e3e2e4Figure 2: Example input graph for our construction of anLCFRS production.A3, and A2.
In this case, after we have collected thefirst three nonterminals, we have obtained a partialparse having fan-out 4, that is, an item spanning 4segments of the input string.
Alternatively, we couldfirst merge A1 and A4, then merge A2 and A3, andfinally merge the two obtained partial parses.
Thisstrategy is slightly better, resulting in a maximumfan-out of 3.
Other possible strategies can be ex-plored, displayed in Figure 1.
It turns out that thebest parsing strategy leads to fan-out 2.
2The maximum fan-out f realized by a parsingstrategy determines the space complexity of theparsing algorithm.
For an input string w, items willrequire (in the worst-case) 2f indices, each takingO(|w|) possible values.
This results in space com-plexity of O(|w|2f ).
In the special cases of parsingbased on CFGs and TAGs, this provides the well-known space complexity of O(|w|2) and O(|w|4),respectively.It can also be shown that, if a partial parse hav-ing fan-out f is obtained by means of the combi-nation of two partial parses with fan-out f1 and f2,respectively, the resulting time complexity will beO(|w|f+f1+f2) (Seki et al, 1991; Gildea, 2010).
Asan example, in the case of parsing based on CFGs,nonterminals as well as partial parses all have fan-out one, resulting in the standard time complexity ofO(|w|3) of dynamic programming methods.
Whenparsing with TAGs, we have to manipulate objectswith fan-out two (in the worst case), resulting in timecomplexity of O(|w|6).We investigate here the case of general LCFRSproductions, whose internal structure is consider-ably more complex than the context-free or the treeadjoining case.
Optimizing the parsing complexityfor a production means finding a parsing strategythat results in minimum space or time complexity.We now turn the above optimization problemsinto decision problems.
In the MIN SPACE STRAT-EGY problem one takes as input an LCFRS produc-tion p and an integer k, and must decide whetherthere exists a parsing strategy for p with maximumfan-out not larger than k. In the MIN TIME STRAT-EGY problem one is given p and k as above and mustdecide whether there exists a parsing strategy forp such that, in any of its steps merging two partialparses with fan-out f1 and f2 and resulting in a par-tial parse with fan-out f , the relation f+f1+f2 ?
kholds.In this paper we investigate the above problems inthe context of a specific family of linguistically mo-tivated parsing strategies for LCFRSs, called head-driven.
In a head-driven strategy, one always startsparsing a production p from a fixed nonterminal inits rhs, called the head of p, and merges the remain-ing nonterminals one at a time with the partial parsecontaining the head.
Thus, under these strategies,the construction of partial parses that do not includethe head is forbidden, and each parsing step involvesat most one partial parse.
In Figure 1, all of the dis-played strategies but the one in the second line arehead-driven (for different choices of the head).3 NP-completeness resultsFor an LCFRS production p, let H be its head non-terminal, and let A1, .
.
.
, An be all the non-headnonterminals in p?s rhs, with n + 1 = r(p).
A head-driven parsing strategy can be represented as a per-mutation pi over the set [n], prescribing that the non-head nonterminals in p?s rhs should be merged withH in the order Api(1), Api(2), .
.
.
, Api(n).
Note thatthere are n!
possible head-driven parsing strategies.To show that MIN SPACE STRATEGY is NP-hard under head-driven parsing strategies, we reducefrom the MIN CUT LINEAR ARRANGEMENT prob-lem, which is a decision problem over (undirected)graphs.
Given a graph M = (V,E) with set of ver-tices V and set of edges E, a linear arrangementof M is a bijective function h from V to [n], where|V | = n. The cutwidth of M at gap i ?
[n?
1] andwith respect to a linear arrangement h is the numberof edges crossing the gap between the i-th vertex andits successor:cw(M,h, i) = |{(u, v) ?
E |h(u) ?
i < h(v)}| .453p : A ?
g(H,A1, A2, A3, A4)g(?xH,e1 , xH,e2 , xH,e3 , xH,e4?, ?xA1,e1,l, xA1,e1,r, xA1,e3,l, xA1,e3,r?, ?xA2,e1,l, xA2,e1,r, xA2,e2,l, xA2,e2,r?,?xA3,e2,l, xA3,e2,r, xA3,e3,l, xA3,e3,r, xA3,e4,l, xA3,e4,r?, ?xA4,e4,l, xA4,e4,r?)
=?
xA1,e1,lxA2,e1,lxH,e1xA1,e1,rxA2,e1,r, xA2,e2,lxA3,e2,lxH,e2xA2,e2,rxA3,e2,r,xA1,e3,lxA3,e3,lxH,e3xA1,e3,rxA3,e3,r, xA3,e4,lxA4,e4,lxH,e4xA3,e4,rxA4,e4,r ?Figure 3: The construction used to prove Theorem 1 builds the LCFRS production p shown, when given as input thegraph of Figure 2.The cutwidth of M is then defined ascw(M) = minhmaxi?
[n?1]cw(M,h, i) .In the MIN CUT LINEAR ARRANGEMENT problem,one is given as input a graph M and an integer k, andmust decide whether cw(M) ?
k. This problem hasbeen shown to be NP-complete (Gavril, 1977).Theorem 1 The MIN SPACE STRATEGY problemrestricted to head-driven parsing strategies is NP-complete.PROOF We start with the NP-hardness part.
LetM = (V,E) and k be an input instance forMIN CUT LINEAR ARRANGEMENT, and let V ={v1, .
.
.
, vn} and E = {e1, .
.
.
, eq}.
We assumethere are no self loops in M , since these loops do notaffect the value of the cutwidth and can therefore beremoved.
We construct an LCFRS production p andan integer k?
as follows.Production p has a head nonterminal H and a non-head nonterminal Ai for each vertex vi ?
V .
We letH generate tuples with a string component for eachedge ei ?
E. Thus, we have f(H) = q. Accord-ingly, we use variables xH,ei , for each ei ?
E, todenote the string components in tuples generated byH .For each vi ?
V , let E(vi) ?
E be the set ofedges impinging on vi; thus |E(vi)| is the degreeof vi.
We let Ai generate a tuple with two stringcomponents for each ej ?
E(vi).
Thus, we havef(Ai) = 2 ?
|E(vi)|.
Accordingly, we use variablesxAi,ej ,l and xAi,ej ,r , for each ej ?
E(vi), to de-note the string components in tuples generated byAi (here subscripts l and r indicate left and rightpositions, respectively; see below).We set r(p) = n + 1 and f(p) = q, anddefine p by A ?
g(H,A1, A2, .
.
.
, An), withg(tH , tA1 , .
.
.
, tAn) = ?
?1, .
.
.
, ?q?.
Here tH is thetuple of variables for H and each tAi , i ?
[n], is thetuple of variables for Ai.
Each string ?i, i ?
[q], isspecified as follows.
Let vs and vt be the endpointsof ei, with vs, vt ?
V and s < t. We define?i = xAs,ei,lxAt,ei,lxH,eixAs,ei,rxAt,ei,r .Observe that whenever edge ei impinges on vertexvj , then the left and right strings generated by Ajand associated with ei wrap around the string gen-erated by H and associated with the same edge.
Fi-nally, we set k?
= q + k.Example 4 Given the input graph of Figure 2, ourreduction constructs the LCFRS production shownin Figure 3.
Figure 4 gives a visualization of how thespans in this production fit together.
For each edgein the graph of Figure 2, we have a group of fivespans in the production: one for the head nontermi-nal, and two spans for each of the two nonterminalscorresponding to the edge?s endpoints.
2Assume now some head-driven parsing strategypi for p. For each i ?
[n], we define Dpii to be thepartial parse obtained after step i in pi, consistingof the merge of nonterminals H,Api(1), .
.
.
, Api(i).Consider some edge ej = (vs, vt).
We observe thatfor any Dpii that includes or excludes both nontermi-nals As and At, the ?j component in the definitionof p is associated with a single string, and thereforecontributes with a single unit to the fan-out of thepartial parse.
On the other hand, if Dpii includes onlyone nonterminal between As and At, the ?j compo-nent is associated with two strings and contributeswith two units to the fan-out of the partial parse.We can associate with pi a linear arrangement hpiof M by letting hpi(vpi(i)) = i, for each vi ?
V .From the above observation on the fan-out of Dpii ,454xA1,e1,lxA2,e1,l xH,e1 xA1,e1,rxA2,e1,r xA2,e2,lxA3,e2,l xH,e2 xA2,e2,rxA3,e2,r xA1,e3,lxA3,e3,l xH,e3 xA1,e3,rxA3,e3,r xA3,e4,lxA4,e4,l xH,e4 xA3,e4,rxA4,e4,rHA1A2A3A4Figure 4: A visualization of how the spans for each nonterminal fit together in the left-to-right order defined by theproduction of Figure 3.we have the following relation, for every i ?
[n?1]:f(Dpii ) = q + cw(M,hpi, i) .We can then conclude that M,k is a positive instanceof MIN CUT LINEAR ARRANGEMENT if and onlyif p, k?
is a positive instance of MIN SPACE STRAT-EGY.
This proves that MIN SPACE STRATEGY isNP-hard.To show that MIN SPACE STRATEGY is in NP,consider a nondeterministic algorithm that, given anLCFRS production p and an integer k, guesses aparsing strategy pi for p, and tests whether f(Dpii ) ?k for each i ?
[n].
The algorithm accepts or rejectsaccordingly.
Such an algorithm can clearly be im-plemented to run in polynomial time.
We now turn to the MIN TIME STRATEGY prob-lem, restricted to head-driven parsing strategies.
Re-call that we are now concerned with the quantityf1 + f2 + f , where f1 is the fan-out of some partialparse D, f2 is the fan-out of a nonterminal A, and fis the fan out of the partial parse resulting from themerge of the two previous analyses.We need to introduce the MODIFIED CUTWIDTHproblem, which is a variant of the MIN CUT LIN-EAR ARRANGEMENT problem.
Let M = (V,E) besome graph with |V | = n, and let h be a linear ar-rangement for M .
The modified cutwidth of M atposition i ?
[n] and with respect to h is the numberof edges crossing over the i-th vertex:mcw(M,h, i) = |{(u, v) ?
E |h(u) < i < h(v)}| .The modified cutwidth of M is defined asmcw(M) = minhmaxi?
[n]mcw(M,h, i) .In the MODIFIED CUTWIDTH problem one is givenas input a graph M and an integer k, and mustdecide whether mcw(M) ?
k. The MODIFIEDCUTWIDTH problem has been shown to be NP-complete by Lengauer (1981).
We strengthen thisresult below; recall that a cubic graph is a graphwithout self loops where each vertex has degreethree.Lemma 1 The MODIFIED CUTWIDTH problem re-stricted to cubic graphs is NP-complete.PROOF The MODIFIED CUTWIDTH problem hasbeen shown to be NP-complete when restricted tographs of maximum degree three by Makedon et al(1985), reducing from a graph problem known asbisection width (see also Monien and Sudborough(1988)).
Specifically, the authors construct a graphG?
of maximum degree three and an integer k?
froman input graph G = (V,E) with an even number nof vertices and an integer k, such that mcw(G?)
?
k?if and only if the bisection width bw(G) of G is notgreater than k, wherebw(G) = minA,B?V|{(u, v) ?
E |u ?
A ?
v ?
B}|with A ?B = ?, A ?B = V , and |A| = |B|.The graph G?
has vertices of degree two and threeonly, and it is based on a grid-like gadget R(r, c); seeFigure 5.
For each vertex of G, G?
includes a com-ponent R(2n4, 8n4+8).
Moreover, G?
has a compo-nent called an H-shaped graph, containing left andright columns R(3n4, 12n4 + 12) connected by amiddle bar R(2n4, 12n4 + 9); see Figure 6.
Fromeach of the n vertex components there is a sheaf of2n2 edges connecting distinct degree 2 vertices inthe component to 2n2 distinct degree 2 vertices in455xx x1x2x3x4x5x x1 x2x5x3x4Figure 5: The R(5, 10) component (left), the modification of its degree 2 vertex x (middle), and the correspondingarrangement (right).the middle bar of the H-shaped graph.
Finally, foreach edge (vi, vj) of G there is an edge in G?
con-necting a degree 2 vertex in the component corre-sponding to the vertex vi with a degree 2 vertex inthe component corresponding to the vertex vj .
Theinteger k?
is set to 3n4 + n3 + k ?
1.Makedon et al (1985) show that the modifiedcutwidth of R(r, c) is r ?
1 whenever r ?
3 andc ?
4r + 8.
They also show that an optimal lin-ear arrangement for G?
has the form depicted in Fig-ure 6, where half of the vertex components are tothe left of the H-shaped graph and all the other ver-tex components are to the right.
In this arrangement,the modified cutwidth is attested by the number ofedges crossing over the vertices in the left and rightcolumns of the H-shaped graph, which is equal to3n4 ?
1 + n22n2 + ?
= 3n4 + n3 + ?
?
1 (2)where ?
denotes the number of edges connectingvertices to the left with vertices to the right of theH-shaped graph.
Thus, bw(G) ?
k if and only ifmcw(G?)
?
k?.All we need to show now is how to modify thecomponents of G?
in order to make it cubic.Modifying the vertex components All verticesx of degree 2 of the components corresponding toa vertex in G can be transformed into a vertex ofdegree 3 by adding five vertices x1, .
.
.
, x5 con-nected as shown in the middle bar of Figure 5.
Ob-serve that these five vertices can be positioned inthe arrangement immediately after x in the orderx1, x2, x5, x3, x4 (see the right part of the figure).The resulting maximum modified cutwidth can in-crease by 2 in correspondence of vertex x5.
Sincethe vertices of these components, in the optimalarrangement, have modified cutwidth smaller than2n4 + n3 + n2, an increase by 2 is still smaller thanthe maximum modified cutwidth of the entire graph,which is 3n4 + O(n3).Modifying the middle bar of the H-shaped graphThe vertices of degree 2 of this part of the graph canbe modified as in the previous paragraph.
Indeed, inthe optimal arrangement, these vertices have mod-ified cutwidth smaller than 2n4 + 2n3 + n2, andan increase by 2 is still smaller than the maximumcutwidth of the entire graph.Modifying the left/right columns of the H-shapedgraph We replace the two copies of componentR(3n4, 12n4 + 12) with two copies of the newcomponent D(3n4, 24n4 + 16) shown in Figure 7,which is a cubic graph.
In order to prove that rela-tion (2) still holds, it suffices to show that the modi-fied cutwidth of the component D(r, c) is still r ?
1whenever r ?
3 and c = 8r + 16.We first observe that the linear arrangement ob-tained by visiting the vertices of D(r, c) from top tobottom and from left to right has modified cutwidthr?
1.
Let us now prove that, for any partition of thevertices into two subsets V1 and V2 with |V1|, |V2| ?4r2, there exist at least r disjoint paths between ver-tices of V1 and vertices of V2.
To this aim, we dis-tinguish the following three cases.?
Any row has (at least) one vertex in V1 and onevertex in V2: in this case, it is easy to see thereexist at least r disjoint paths between verticesof V1 and vertices of V2.?
There exist at least 3r ?mixed?
columns, that is,columns with (at least) one vertex in V1 and onevertex in V2.
Again, it is easy to see that thereexist at least r disjoint paths between vertices456Figure 6: The optimal arrangement of G?.of V1 and vertices of V2 (at least one path everythree columns).?
The previous two cases do not apply.
Hence,there exists a row entirely formed by verticesof V1 (or, equivalently, of V2).
The worst caseis when this row is the smallest one, that is, theone with (c?3?1)2 + 1 = 4r + 7 vertices.
Sinceat most 3r ?
1 columns are mixed, we havethat at most (3r ?
1)(r ?
2) = 3r2 ?
7r +2 vertices of V2 are on these mixed columns.Since |V2| ?
4r2, this implies that at least rcolumns are fully contained in V2.
On the otherhand, at least 4r+7?
(3r?1) = r+8 columnsare fully contained in V1.
If the V1-columnsinterleave with the V2-columns, then there existat least 2(r?1) disjoint paths between verticesof V1 and vertices of V2.
Otherwise, all the V1-columns precede or follow all the V2-columns(this corresponds to the optimal arrangement):in this case, there are r disjoint paths betweenvertices of V1 and vertices of V2.Observe now that any linear arrangement partitionsthe set of vertices in D(r, c) into the sets V1, consist-ing of the first 4r2 vertices in the arrangement, andV2, consisting of all the remaining vertices.
Sincethere are r disjoint paths connecting V1 and V2, theremust be at least r?1 edges passing over every vertexin the arrangement which is assigned to a positionbetween the (4r2 + 1)-th and the position 4r2 + 1from the right end of the arrangement: thus, themodified cutwidth of any linear arrangement of thevertices of D(r, c) is at least r ?
1.We can then conclude that the original proofof Makedon et al (1985) still applies, according torelation (2).
Figure 7: The D(5, 10) component.We can now reduce from the MODIFIEDCUTWIDTH problem for cubic graphs to the MINTIME STRATEGY problem restricted to head-drivenparsing strategies.Theorem 2 The MIN TIME STRATEGY problem re-stricted to head-driven parsing strategies is NP-complete.PROOF We consider hardness first.
Let M and kbe an input instance of the MODIFIED CUTWIDTHproblem restricted to cubic graphs, where M =(V,E) and V = {v1, .
.
.
, vn}.
We construct anLCFRS production p exactly as in the proof of The-orem 1, with rhs nonterminals H,A1, .
.
.
, An.
Wealso set k?
= 2 ?
k + 2 ?
|E| + 9.Assume now some head-driven parsing strategy pifor p. After parsing step i ?
[n], we have a partialparse Dpii consisting of the merge of nonterminalsH,Api(1), .
.
.
, Api(i).
We write tc(p, pi, i) to denotethe exponent of the time complexity due to step i.As already mentioned, this quantity is defined as thesum of the fan-out of the two antecedents involvedin the parsing step and the fan-out of its result:tc(p, pi, i) = f(Dpii?1) + f(Api(i)) + f(Dpii ) .Again, we associate with pi a linear arrangementhpi of M by letting hpi(vpi(i)) = i, for each vi ?
V .As in the proof of Theorem 1, the fan-out of Dpiiis then related to the cutwidth of the linear arrange-457ment hpi of M at position i byf(Dpii ) = |E| + cw(M,hpi, i) .From the proof of Theorem 1, the fan-out of nonter-minal Api(i) is twice the degree of vertex vpi(i), de-noted by |E(vpi(i))|.
We can then rewrite the aboveequation in terms of our graph M :tc(p, pi, i) = 2 ?
|E| + cw(M,hpi, i?
1) ++ 2 ?
|E(vpi(i))| + cw(M,hpi, i) .The following general relation between cutwidthand modified cutwidth is rather intuitive:mcw(M,hpi, i) =12?
[cw(M,hpi, i?
1) +?
|E(vpi(i))| + cw(M,hpi, i)] .Combining the two equations above we obtain:tc(p, pi, i) = 2 ?
|E| + 3 ?
|E(vpi(i))| ++ 2 ?mcw(M,hpi, i) .Because we are restricting M to the class of cubicgraphs, we can write:tc(p, pi, i) = 2 ?
|E| + 9 + 2 ?mcw(M,hpi, i) .We can thus conclude that there exists a head-drivenparsing strategy for p with time complexity notgreater than 2 ?
|E| + 9 + 2 ?
k = k?
if and onlyif mcw(M) ?
k.The membership of MODIFIED CUTWIDTH in NPfollows from an argument similar to the one in theproof of Theorem 1.
We have established the NP-completeness of boththe MIN SPACE STRATEGY and the MIN TIMESTRATEGY decision problems.
It is now easy to seethat the problem of finding a space- or time-optimalparsing strategy for a LCFRS production is NP-hardas well, and thus cannot be solved in polynomial (de-terministic) time unless P = NP.4 Concluding remarksHead-driven strategies are important in parsingbased on LCFRSs, both in order to allow statisticalmodeling of head-modifier dependencies and in or-der to generalize the Markovization of CFG parsersto parsers with discontinuous spans.
However, thereare n!
possible head-driven strategies for an LCFRSproduction with a head and n modifiers.
Choosingamong these possible strategies affects both the timeand the space complexity of parsing.
In this paperwe have shown that optimizing the choice accordingto either metric is NP-hard.
To our knowledge, ourresults are the first NP-hardness results for a gram-mar factorization problem.SCFGs and STAGs are specific instances ofLCFRSs.
Grammar factorization for synchronousmodels is an important component of current ma-chine translation systems (Zhang et al, 2006), andalgorithms for factorization have been studied byGildea et al (2006) for SCFGs and by Nesson et al(2008) for STAGs.
These algorithms do not resultin what we refer as head-driven strategies, although,as machine translation systems improve, lexicalizedrules may become important in this setting as well.However, the results we have presented in this pa-per do not carry over to the above mentioned syn-chronous models, since the fan-out of these modelsis bounded by two, while in our reductions in Sec-tion 3 we freely use unbounded values for this pa-rameter.
Thus the computational complexity of opti-mizing the choice of the parsing strategy for SCFGsis still an open problem.Finally, our results for LCFRSs only apply whenwe restrict ourselves to head-driven strategies.
Thisis in contrast to the findings of Gildea (2011), whichshow that, for unrestricted parsing strategies, a poly-nomial time algorithm for minimizing parsing com-plexity would imply an improved approximation al-gorithm for finding the treewidth of general graphs.Our result is stronger, in that it shows strict NP-hardness, but also weaker, in that it applies only tohead-driven strategies.
Whether NP-hardness can beshown for unrestricted parsing strategies is an im-portant question for future work.AcknowledgmentsThe first and third authors are partially supportedfrom the Italian PRIN project DISCO.
The sec-ond author is partially supported by NSF grants IIS-0546554 and IIS-0910611.458ReferencesAshok K. Chandra and Philip M. Merlin.
1977.
Op-timal implementation of conjunctive queries in rela-tional data bases.
In Proc.
ninth annual ACM sympo-sium on Theory of computing, STOC ?77, pages 77?90.Michael Collins.
1997.
Three generative, lexicalisedmodels for statistical parsing.
In Proc.
35th AnnualConference of the Association for Computational Lin-guistics (ACL-97), pages 16?23.F.
Gavril.
1977.
Some NP-complete problems on graphs.In Proc.
11th Conf.
on Information Sciences and Sys-tems, pages 91?95.Daniel Gildea and Daniel ?Stefankovic?.
2007.
Worst-casesynchronous grammar rules.
In Proc.
2007 Meetingof the North American chapter of the Association forComputational Linguistics (NAACL-07), pages 147?154, Rochester, NY.Daniel Gildea, Giorgio Satta, and Hao Zhang.
2006.Factoring synchronous grammars by sorting.
InProc.
International Conference on ComputationalLinguistics/Association for Computational Linguistics(COLING/ACL-06) Poster Session, pages 279?286.Daniel Gildea.
2010.
Optimal parsing strategies for Lin-ear Context-Free Rewriting Systems.
In Proc.
2010Meeting of the North American chapter of the Associa-tion for Computational Linguistics (NAACL-10), pages769?776.Daniel Gildea.
2011.
Grammar factorization by tree de-composition.
Computational Linguistics, 37(1):231?248.Carlos Go?mez-Rodr?
?guez, Marco Kuhlmann, GiorgioSatta, and David Weir.
2009.
Optimal reduction ofrule length in Linear Context-Free Rewriting Systems.In Proc.
2009 Meeting of the North American chap-ter of the Association for Computational Linguistics(NAACL-09), pages 539?547.Carlos Go?mez-Rodr?
?guez, Marco Kuhlmann, and Gior-gio Satta.
2010.
Efficient parsing of well-nested linearcontext-free rewriting systems.
In Proc.
2010 Meetingof the North American chapter of the Association forComputational Linguistics (NAACL-10), pages 276?284, Los Angeles, California.John E. Hopcroft and Jeffrey D. Ullman.
1979.
Intro-duction to Automata Theory, Languages, and Compu-tation.
Addison-Wesley, Reading, MA.Liang Huang, Hao Zhang, Daniel Gildea, and KevinKnight.
2009.
Binarization of synchronouscontext-free grammars.
Computational Linguistics,35(4):559?595.Laura Kallmeyer and Wolfgang Maier.
2010.
Data-driven parsing with probabilistic linear context-freerewriting systems.
In Proc.
23rd International Con-ference on Computational Linguistics (Coling 2010),pages 537?545.Marco Kuhlmann and Giorgio Satta.
2009.
Treebankgrammar techniques for non-projective dependencyparsing.
In Proc.
12th Conference of the EuropeanChapter of the ACL (EACL-09), pages 478?486.Thomas Lengauer.
1981.
Black-white pebbles and graphseparation.
Acta Informatica, 16:465?475.Wolfgang Maier and Anders S?gaard.
2008.
Treebanksand mild context-sensitivity.
In Philippe de Groote,editor, Proc.
13th Conference on Formal Grammar(FG-2008), pages 61?76, Hamburg, Germany.
CSLIPublications.F.
S. Makedon, C. H. Papadimitriou, and I. H. Sudbor-ough.
1985.
Topological bandwidth.
SIAM J. Alg.Disc.
Meth., 6(3):418?444.B.
Monien and I.H.
Sudborough.
1988.
Min cut is NP-complete for edge weighted trees.
Theor.
Comput.Sci., 58:209?229.Rebecca Nesson, Giorgio Satta, and Stuart M. Shieber.2008.
Optimal k-arization of synchronous tree adjoin-ing grammar.
In Proc.
46th Annual Meeting of theAssociation for Computational Linguistics (ACL-08),pages 604?612.Owen Rambow and Giorgio Satta.
1999.
Independentparallelism in finite copying parallel rewriting sys-tems.
Theor.
Comput.
Sci., 223(1-2):87?120.Beno?
?t Sagot and Giorgio Satta.
2010.
Optimal rank re-duction for linear context-free rewriting systems withfan-out two.
In Proc.
48th Annual Meeting of the Asso-ciation for Computational Linguistics, pages 525?533,Uppsala, Sweden.Giorgio Satta and Enoch Peserico.
2005.
Some com-putational complexity results for synchronous context-free grammars.
In Proceedings of Human Lan-guage Technology Conference and Conference onEmpirical Methods in Natural Language Processing(HLT/EMNLP), pages 803?810, Vancouver, Canada.H.
Seki, T. Matsumura, M. Fujii, and T. Kasami.
1991.On multiple context-free grammars.
Theoretical Com-puter Science, 88:191?229.Stuart M. Shieber, Yves Schabes, and Fernando C. N.Pereira.
1995.
Principles and implementation of de-ductive parsing.
The Journal of Logic Programming,24(1-2):3?36.K.
Vijay-Shankar, D. L. Weir, and A. K. Joshi.
1987.Characterizing structural descriptions produced byvarious grammatical formalisms.
In Proc.
25th An-nual Conference of the Association for ComputationalLinguistics (ACL-87), pages 104?111.Hao Zhang, Liang Huang, Daniel Gildea, and KevinKnight.
2006.
Synchronous binarization for machinetranslation.
In Proc.
2006 Meeting of the North Ameri-can chapter of the Association for Computational Lin-guistics (NAACL-06), pages 256?263.459
