Proceedings of the 4th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 108?114,Atlanta, Georgia, 14 June 2013. c?2013 Association for Computational LinguisticsSentence-Level Subjectivity Detection Using Neuro-Fuzzy ModelsSamir Rustamov Mark A. ClementsGeorgia Institute of Technology Georgia Institute of Technology225 North Avenue NW 225 North Avenue NWAtlanta, GA 30332, USA Atlanta, GA 30332, USAsamir.rustamov@gmail.com clements@ece.gatech.eduAbstractIn this work, we attempt to detect sentence-level subjectivity by means of two supervisedmachine learning approaches: a Fuzzy ControlSystem and Adaptive Neuro-Fuzzy InferenceSystem.
Even though these methods are popu-lar in pattern recognition, they have not beenthoroughly investigated for subjectivity analy-sis.
We present a novel ?Pruned ICFWeighting Coefficient,?
which improves theaccuracy for subjectivity detection.
Our fea-ture extraction algorithm calculates a featurevector based on the statistical occurrences ofwords in a corpus without any lexicalknowledge.
For this reason, these machinelearning models can be applied to any lan-guage; i.e., there is no lexical, grammatical,syntactical analysis used in the classificationprocess.1 IntroductionThere has been a growing interest, in recent years,in identifying and extracting subjective infor-mation from Web documents that contain opinions.Opinions are usually subjective expressions thatdescribe people's sentiments, appraisals, or feel-ings.
Subjectivity detection seeks to identifywhether the given text expresses opinions (subjec-tive) or reports facts (objective) (Lin et al 2011).Automatic subjectivity analysis methods have beenused in a wide variety of text processing and natu-ral language  applications.
In many natural lan-guage processing tasks, subjectivity detection hasbeen used as a first phase of filtering to generatemore informative data.The goal of our research is to develop learningmethods to create classifiers that can distinguishsubjective from objective sentences.
In this paper,we achieve sentence-level subjectivity classifica-tion using language independent feature weighting.As a test problem, we employed a subjectivity da-tabase from the "Rotten Tomatoes" movie reviews(see http://www.cs.cornell.edu/people/pabo/movie-review-data).We present two supervised machine learningapproaches in our development of sentence-levelsubjectivity detection: Fuzzy Control System(FCS), and Adaptive Neuro-Fuzzy Inference Sys-tem (ANFIS).
Even though these methods are pop-ular in pattern recognition, they have not beenthoroughly investigated for subjectivity analysis.We present a novel ?Pruned ICF Weighting Coef-ficient,?
which improves the accuracy for subjec-tivity detection.
Our feature extraction algorithmcalculates a feature vector based on statistical oc-currences of words in the corpus without any lexi-cal knowledge.
For this reason, the machinelearning models can be applied to any language;i.e., there is no lexical, grammatical, syntacticalanalysis used in the classification process.2 Related workIn recent years, several different supervised andunsupervised learning algorithms were investigatedfor defining subjective information in text orspeech.Riloff and Wiebe (2003) presented a bootstrap-ping method to learn subjectivity classifiers from acollection of non-annotated texts.
Wiebe andRiloff (2005) used a similar method, but they alsolearned objective expressions apart from subjectiveexpressions.Pang and Lee (2004) proposed a MinCut basedalgorithm to classify each sentence as being sub-jective or objective.
The goal of this research wasto remove objective sentences from each review toimprove document-level sentiment classification(82.8% improved to 86.4%).108Grefenstette et al(2004) presented a Web min-ing method for identifying subjective adjectives.Wilson et al(2004) and Kim et al(2005) pre-sented methods of classifying the strength of opin-ion being expressed in individual clauses (orsentences).Riloff et al(2006) defined subsumption rela-tionships among unigrams, n -grams, and lexico-syntactic patterns.
They found that if a feature issubsumed by another, the subsumed feature is notneeded.
The subsumption hierarchy reduces a fea-ture set and reduced feature sets can improve clas-sification performance.Raaijmakers et al2008) investigated the use ofprosodic features, word n -grams, character n -grams, and phoneme n -grams for subjectivityrecognition and polarity classification of dialogacts in multiparty conversation.
They found thatfor subjectivity recognition, a combination of pro-sodic, word-level, character-level, and phoneme-level information yields the best performance andfor polarity classification, the best performance isachieved with a combination of words, charactersand phonemes.Murray and Carenini (2009) proposed to learnsubjective patterns from both labeled and unla-beled data using n -gram word sequences withvarying level of lexical instantiation.
They showedthat learning subjective trigrams with varying in-stantiation levels from both annotated and raw datacan improve subjectivity detection and polaritylabeling for meeting speech and email threads.Martineau and Finin (2009) presented DeltaTFIDF, an intuitive general purpose technique, toefficiently weight word scores beforeclassification.
They compared SVM Difference ofTFIDFs and SVM Term Count Baseline results forsubjectivity classification.
As a result, they showedthat SVM based on Delta TFIDF gives highaccuracy and low variance.Barbosa and Feng (2010) classified the subjec-tivity of tweets (postings on Twitter) based on twokind of features: meta-information about the wordson tweets and characteristics of how tweets arewritten.Yulan He (2010) proposed subjLDA for sen-tence-level subjectivity detection by modifying thelatent Dirichlet alcation (LDA) model throughadding an additional layer to model sentence-levelsubjectivity labels.Benamara et al(2011) proposed subjectivityclassification at the segment level for discourse-based sentiment analysis.
They classified eachsegment into four classes, S, OO, O and SN, whereS segments are segments that contain explicitlylexicalized subjective and evaluative expressions,OO segments are positive or negative opinion im-plied in an objective segment, O segments containneither a lexicalized subjective term nor an impliedopinion, SN segments are subjective, though non-evaluative, segments that are used to introduceopinions.Remus (2011) showed that by using readabilityformulae and their combinations as features inaddition to already well-known subjectivity cluesleads to significant accuracy improvements insentence-level subjectivity classification.Lin et al(2011) presented a hierarchical Bayes-ian model based on latent Dirichlet alcation,called subjLDA, for sentence-level subjectivitydetection, which automatically identifies whether agiven sentence expresses opinion or states facts.All the aforementioned work focused on Englishdata and most of them used an English subjectivitydictionary.
Recently, there has been some work onsubjectivity classification of sentences in Japanese(Kanayama et al 2006), Chinese (Zagibalov et al2008; Zhang et al 2009), Romanian (Banea et al2008; Mihalcea et al 2007), Urdu (Mukund andSrihari, 2010), Arabic (Abdul-Mageed et al 2011)and others based on different machine learningalgorithms using general and language specificfeatures.Mihalcea et al (2007) and Banea et al (2008)investigated methods to automatically generateresources for subjectivity analysis for a new targetlanguage by leveraging the resources and toolsavailable for English.
Another approach (Banea etal., 2010) used a multilingual space with meta clas-sifiers to build high precision classifiers for subjec-tivity classification.Recently, there has been some work focused onfinding features that can be applied to any lan-guage.
For example, Mogadala and Varma (2012)presented sentence-level subjectivity classificationusing language independent feature weighting andperformed experiments on 5 different languagesincluding English and a South Asian language(Hindi).109Rustamov et.
al., (2013) applied hybrid Neuro-Fuzzy and HMMs to document level sentimentanalysis of movie reviews.In the current work, our main goal is to applysupervised methods based on language independ-ent features for classification of subjective and ob-jective sentences.3 Feature ExtractionMost language independent feature extraction al-gorithms are based on the presence or occurrencestatistics within the corpus.
We describe such analgorithm which is intuitive, computationally effi-cient, and does not require either additional humanannotation or lexical knowledge.We use a subjectivity dataset 1v.0: 5000 subjec-tive and 5000 objective processed sentences inmovie reviews [Pang/Lee ACL 2004].As our target does not use lexical knowledge,we consider every word as one code word.
In ouralgorithm we do not combine verbs in differenttenses, such as present and past  ("decide" vs "de-cided") nor nouns as singular or plural ("fact" vs"facts").
Instead, we consider them as the differentcode words.Below, we describe some of the parameters:?
N  is the number of classes ( in our problemN=2: i.e.
subjective and objective classes);?
M is the number of different words (terms)in the corpus;?
R is the number of observed sequences inthe training process;?
?
?rTrrr roooO ,...,, 21?
are the sentences in thetraining dataset, whererT  is the length of r-th sentence, Rr ,...,2,1?
;?ji ,?
describes the association between i-thterm (word) and the j-th class?
?NjMi ,...,2,1;,...,1 ??
;?jic ,is the number of times i-th term oc-curred in the j-th class;???
j jii ct ,denotes the occurrence times ofthe i-th term in the corpus;?
frequency of the i -th term in the j -th classijiji tcc ,, ?
;We present a new weighting coefficient, whichaffects the accuracy of the system, so that insteadof the number of documents we take the number ofclasses in the well-known IDF (Inverse-DocumentFrequency) formula.
Similar to IDF, we call itPruned ICF (Inverse-Class Frequency)????????
?ii dNNICF 2log,where i  is a term, idN  is the number of classescontaining the term i , which qc ji ?, , whereNq ??
?1 .The value of  ?
is found empirically with4.1??
being best for the corpus investigated.The membership degree of the terms (ji,? )
forappropriate classes can be estimated by experts orcan be calculated by analytical formulas.
Since amain goal is to avoid using human annotation orlexical knowledge, we calculated the membershipdegree of each term by an analytical formula asfollows ?
?NjMi ,...,2,1;,...,1 ??
:TF:???
Nvvijijicc1,,,?
;   (1)ICFTF ?
:?????
NvvvijjijiICFcICFc1,,,?
;  (2)4 Subjectivity detection using Fuzzy Con-trol SystemWe use a statistical approach for estimation of themembership function, instead of expert knowledge,at the first stage.
Then we apply fuzzy operationsand modify parameters by the back-propagationalgorithm.We now introduce our algorithm ( Rr ,...,2,1?
).1.
The membership degree of terms (r ji ,? )
of ther -th sentence are calculated from formulas (1)-(2).2.
Maximum membership degree is found withrespect to the  classes for every term of the r-thsentence.,...,1,maxarg,,1,,Mij rviNrjirji?????????(3)3.
Means of maxima are calculated for all clas-ses:110?
?.,...,1,max:,,1,,NjiZTrviNrjirjrZkrjkrjrj?????????????
(4)We use the Center of Gravity Defuzzification(CoGD) method for the defuzzification operation.Objective and subjective sentences selected ac-cording to classes are trained by a fuzzy controlmodel.
The objective function is defined as follows(Aida-zade et.
al, 2012):?
?NRyRrrNjrjNjjrjdyyE??????????????????????
min211211?
?,    (5)?
?Nyyyy ,...,, 21?
, ?
?Ndr ,...,2,1?
desired output.The partial derivatives of this function arecalculated in following form:?
?????????????????????????
RrrNjrjNjjrjNjrjrttdyyyE1111????
, N1,2,...,t ?
.Function (5) is minimized by the conjugategradient method with the defined optimal values of*y .Rounding of y  shows the index of the classesobtained in the result:????
?NjjNjjj yy11*??.
(6)Acceptance strategy (s):?
????
???????
otherwiserejectiiyifIis sss ,,, 11,wheresi  is the index of the appropriate class,?
?NI ,...,2,1?
.
Here ?
?5.0;01??
is the main quan-tity, which influences the reliability of the system.It is straightforward to check which feature vec-tor gives the best results for FCS.
Table 1. showsaverage accuracy over 10 fold cross validation ofFCS based on (1)-(2) features in the  non-restrictedcase.
Note that these results depend on the classifi-cation method these results might be different fordifferent classifiers.Features Accuracy (%)TF 89.87ICFTF ?
91.3Table 1.
Results of  FCS based on TF andICFTF ?
features.We also checked FCS based on Delta TFIDFfeatures (Martineau and Finin, 2009).
As DeltaIDFweighting coefficients of both classes are the same,application of DeltaIDF weighting does not changethe accuracy of the FCS.
As we see from Table 1.,the accuracy of the method increases after applica-tion of Pruned ICF weighting.We show results of subjectivity detection byFCS with different values of1?
based on ICFTF ?in Table 2.
It can be seen that the rejection per-centage is 0.01 for 5.01 ??
.
In the testing process0.01% of the sentences have such words, whichafter pruned ICF weighting, becomes 0 and thesystem rejects such sentences.Correct(%)Rejection(%)Error(%)3.01 ??
76.41 20.86 2.734.01 ??
85.11 10.14 4.755.01 ??
91.3 0.01 8.69Table 2.
Average results of 10 folds cross vali-dation accuracy of FCS based on ICFTF ?
featurewith different value of1?
.5 Subjectivity detection using AdaptiveNeuro Fuzzy Inference SystemFig.
1 illustrates the general structure of Adap-tive Neuro Fuzzy Inference System.
In response tolinguistic statements, the fuzzy interface blockprovides an input vector to a Multilayer ArtificialNeural Network (MANN) (Fuller, 1995).We used statistical estimation of membershipdegree of terms by (2) instead of linguistic state-ments at the first stage.
Then we applied fuzzy op-erations (3) and (4).111Fig.
1.
The structure of ANFIS.MANN was applied to the output of the fuzzyfi-cation operation.
The input vector of neural net-work is taken from the output vector of thefuzzyfication operation (fig.
2).
Outputs of MANNare taken as indexes of classes appropriate to thesentences.
MANN is trained by the back-propagation algorithm.Fig.
2.
The structure of MANN in ANFIS.We set two boundary conditions for the  ac-ceptance decision:1)2?
?ky ,2)3~ ???
pk yy,where y  is the output vector of MANN,  ky andpy~are two successive maximum elements of thevector y , i.e.iNik yy ???
1max,iNi yk ???
1maxarg,iNikkip yy ???????
1;11 max~.There is shown results of subjectivity detectionin  movie reviews by ANFIS with different valuesof2?
and 3?
in Table 3.Correct(%)Rejection(%)Error(%)5.0;8.0 32 ????
78.66 18.84 2.55.0;5.0 32 ????
85.77 8.62 5.61No restriction 91.66 0.01 8.33Table 3.
Average results of 10 folds cross valida-tion accuracy ANFIS based on ICFTF ?
for sub-jectivity detection in movie reviews.The accuracy of the ANFIS (91.66%) is higherthan that of FCS (91.3%) at the cost of additionalvariables being required in the middle layer of theneural network.6 ConclusionWe have described two different classification sys-tem structures, FCS, ANFIS, and applied them tosentence-level subjectivity detection in a moviereview data base.
We have specifically shown howto train and test these methods  for classification ofsentences as being either objective or subjective.
Agoal of the research was to formulate methods thatdid not depend on linguistic knowledge and there-fore would be applicable to any language.
An im-portant component of these  methods is the featureextraction process.
We focused on analysis of  in-formative features that improve the accuracy of thesystems with no language-specific constraints.
Asa result,  a novel  "Pruned ICF Weighting Func-tion" was devised with a parameter specificallyestimated for the subjectivity data set.When comparing the current system with others,it is necessary to emphasize that the use of linguis-tic knowledge does improve accuracy.
Since we donot use such  knowledge, our results should onlybe compared with other methods having similarconstraints, such as those which use features basedon bags of words that are tested on the same dataset.
Examples include studies by  Pang and Lee(2004) and Martineau and Finin (2009).
Pang andLee report 92% accuracy on sentence-level subjec-tivity classification using Na?ve Bayes classifiersand 90% accuracy using SVMs on the same dataset.
Martineau and Finin (2009) reported 91.26%accuracy using SVM Difference of TFIDFs.
Thecurrently reported results: FCS (91.3%), ANFIS(91.7%) are similar.
However, our presented meth-ods have some advantages.
Because the function(5) is minimized only with respect to?
?Nyyyy ,...,, 21?
(in the defined problem N=2),FCS is the fastest algorithm among supervised ma-chine learning methods.
At the cost of additionalvariables added within the middle layer of the neu-ral network, ANFIS is able to improve accuracy a112small amount.
It is anticipated that when IF-THENrules and expert knowledge are inserted intoANFIS and FCS, accuracy will improve to a levelcommensurate with human judgment.ReferencesAditya Mogadala.
Vasudeva Varma.
2012.
Lan-guage Independent Sentence-Level SubjectivityAnalysis with Feature Selection.
Proceedings ofthe 26th Pacific Asia Conference on Lan-guage,Information and Computation, pages171?180.Alina Andreevskaia and Sabine Bergler.
2006.Mining wordnet for fuzzy sentiment: Sentimenttag extraction from WordNet glosses.
In Pro-ceedings of EACL 2006.Bing Liu.
Sentiment Analysis and Opinion Mining.2012.
Synthesis Lectures on Human LanguageTechnologies.Bo Pang and Lillian Lee.
2004.
A sentimental edu-cation: Sentiment analysis using subjectivitysummarization based on minimum cuts.
In Pro-ceedings of the 42nd Annual Meeting on Associ-ation for Computational Linguistics (ACL), pp.271-278.Bo Pang and Lillian Lee.
2008.
Opinion Miningand Sentiment Analysis.
Now Publishers Inc.Carmen Banea, Rada Mihalcea, and Janyce Wiebe.2010.
Multilingual subjectivity: are more lan-guages better.
Proceedings of the 23rd Interna-tional Conference on Computational Linguistics(Coling 2010), pp.
28?36.Carmen Banea, Rada Mihalcea, Janyce Wiebe andSamer Hassan.
2008.
Multilingual subjectivityanalysis using machine translation.
Proceedingsof the Conference on Empirical Methods in Nat-ural Language Processing, pp.
127?135.Chenghua Lin, Yulan He and Richard Everson.2011.
Sentence Subjectivity Detection withWeakly-Supervised Learning.
Proceedings ofthe 5th International Joint Conference on Natu-ral Language Processing, pp.
1153?1161.Ellen Riloff and Janyce Wiebe.
2003.
LearningExtraction Patterns for Subjective Expressions.In: Proceedings of the Conference on EmpiricalMethods in Natural Language Processing, pp.105?112.Ellen Riloff, Siddharth Patwardhan, and JanyceWiebe.
Feature subsumption for opinion analy-sis.
2006.
In Proceedings of the Conference onEmpirical Methods in Natural Language Pro-cessing (EMNLP-2006).Farah Benamara, Baptiste Chardon, YannickMathieu, and Vladimir Popescu.
2011.
TowardsContext-Based Subjectivity Analysis.
In Pro-ceedings of the 5th International Joint Confer-ence on Natural Language Processing (IJCNLP-2011).Gabriel Murray and Giuseppe Carenini.
2009.Predicting subjectivity in multimodal conversa-tions.
In Proceedings of the Conference on Em-pirical Methods in Natural LanguageProcessing (EMNLP), pages 1348?1357.Gregory Grefenstette, Yan Qu, David A. Evans,and James G. Shanahan.
2006.
Validating theCoverage of Lexical Resources for Affect Anal-ysis and Automatically Classifying New Wordsalong Semantic Axes.
In: Proceedings of AAAISpring Symposium on Exploring Attitude andAffect in Text: Theories and Applications, pp.93?107.Hiroshi Kanayama and Tetsuya Nasukawa.
2006.Fully automatic lexicon expansion for domain-oriented sentiment analysis.
Proceedings of the2006 Conference on Empirical Methods in Nat-ural Language Processing, pages 355?363.Janyce Wiebe and Ellen Riloff.
2005.
Creatingsubjective and objective sentence classifiersfrom unannotated texts.
Computational Linguis-tics and Intelligent Text Processing, Springer,pp.
486?497.Justin Martineau, and Tim Finin.
2009.
DeltaTFIDF: An Improved Feature Space forSentiment Analysis.
In Proceedings of the 3rdAAAI International Conference on Weblogs andSocial Media.Kamil Aida-zade, Samir Rustamov, Elshan Mustafayev,and Nigar Aliyeva, 2012.
Human-Computer Dia-logue Understanding Hybrid System.
IEEE  Xplore,International Symposium on Innovations in Intelli-gent Systems and Applications.
Trabzon, Turkey, pp.1-5.Luciano Barbosa and Junlan Feng.
2010.
Robustsentiment detection on twitter from biased andnoisy data.
In Proceedings of the InternationalConference on Computational Linguistics (COLING-2010).Muhammad Abdul-Mageed, Mona T. Diab, andMohammed Korayem.
2011.
Subjectivity andsentiment analysis of modern standard Arabic,In Proceedings of the 49th Annual Meeting of113the Association for Computational Linguistics:short papers, pages 587?591.Rada Mihalcea, Carmen Banea and Janyce Wiebe.2007.
Learning multilingual subjective languagevia cross-lingual projections.
Proceedings of the45th Annual Meeting of the Association of Com-putational Linguistics, pages 976?983.Robert Fuller.
Neural Fuzzy Systems, 1995.Robert Remus.
2011.
Improving Sentence-levelSubjectivity Classification through ReadabilityMeasurement.
NODALIDA-2011 ConferenceProceedings, pp.
168?174.Samir Rustamov, Elshan Mustafayev, MarkClements.
2013.
Sentiment Analysis usingNeuro-Fuzzy and Hidden Markov Models ofText.
IEEE Southeastcon 2013, Jacksonvilla,Florida,USA.Smruthi Mukund and Rohini K. Srihari.
2010.
Avector space model for subjectivity classifica-tion in Urdu aided by co-training.
In Proceed-ings of Coling 2010: Poster Volume, pages 860?868.Soo-Min Kim and Eduard Hovy.
2005.
AutomaticDetection of Opinion Bearing Words and Sen-tences.
In: Companion Volume to the Proceed-ings of the International Joint Conference onNatural Language Processing, pp.
61?66.Stephan Raaijmakers, Khiet Truong, and TheresaWilson.
2008.
Multimodal subjectivity analysisof multiparty conversation.
In Proceedings ofthe Conference on Empirical Methods in Natu-ral Language Processing (EMNLP), pages 466?474.Taras Zagibalov and John Carroll.
2008.
Unsuper-vised classification of sentiment and objectivityin Chinese text.
In Proceedings of InternationalJoint Conference on Natural Language Pro-cessing (IJCNLP-2008), pp.
304?311.Theresa Wilson, Janyce Wiebe, Rebecca Hwa.2004.
Just How Mad Are You?
Finding Strongand Weak Opinion Clauses.
In: Proceedings ofthe National Conference on Artificial Intelli-gence, pp.
761?769.Yulan He.
2010.
Bayesian Models for Sentence-Level Subjectivity Detection.
Technical ReportKMI-10-02,  June 2010.Ziqiong Zhang, Qiang Ye, Rob Law, and Yijun Li.2009.
Automatic Detection of Subjective SentencesBased on Chinese Subjective Patterns.
Proceedingsof 20th International Conference, MCDM-2009,pp.
29-36.114
