Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1489?1499,Edinburgh, Scotland, UK, July 27?31, 2011. c?2011 Association for Computational LinguisticsTraining dependency parsers by jointly optimizing multiple objectivesKeith Hall Ryan McDonald Jason Katz-Brown Michael RinggaardGoogle Research{kbhall|ryanmcd|jasonkb|ringgaard}@google.comAbstractWe present an online learning algorithm fortraining parsers which allows for the inclusionof multiple objective functions.
The primaryexample is the extension of a standard su-pervised parsing objective function with addi-tional loss-functions, either based on intrinsicparsing quality or task-specific extrinsic mea-sures of quality.
Our empirical results showhow this approach performs for two depen-dency parsing algorithms (graph-based andtransition-based parsing) and how it achievesincreased performance on multiple target tasksincluding reordering for machine translationand parser adaptation.1 IntroductionThe accuracy and speed of state-of-the-art depen-dency parsers has motivated a resumed interest inutilizing the output of parsing as an input to manydownstream natural language processing tasks.
Thisincludes work on question answering (Wang et al,2007), sentiment analysis (Nakagawa et al, 2010),MT reordering (Xu et al, 2009), and many othertasks.
In most cases, the accuracy of parsers de-grades when run on out-of-domain data (Gildea,2001; McClosky et al, 2006; Blitzer et al, 2006;Petrov et al, 2010).
But these accuracies are mea-sured with respect to gold-standard out-of-domainparse trees.
There are few tasks that actually dependon the complete parse tree.
Furthermore, when eval-uated on a downstream task, often the optimal parseoutput has a model score lower than the best parseas predicted by the parsing model.
While this meansthat we are not properly modeling the downstreamtask in the parsers, it also means that there is someinformation from small task or domain-specific datasets which could help direct our search for optimalparameters during parser training.
The goal beingnot necessarily to obtain better parse performance,but to exploit the structure induced from human la-beled treebank data while targeting specific extrinsicmetrics of quality, which can include task specificmetrics or external weak constraints on the parsestructure.One obvious approach to this problem is to em-ploy parser reranking (Collins, 2000).
In such asetting, an auxiliary reranker is added in a pipelinefollowing the parser.
The standard setting involvestraining the base parser and applying it to a devel-opment set (this is often done in a cross-validatedjack-knife training framework).
The reranker canthen be trained to optimize for the downstream orextrinsic objective.
While this will bias the rerankertowards the target task, it is limited by the oracleperformance of the original base parser.In this paper, we propose a training algorithm forstatistical dependency parsers (Ku?bler et al, 2009)in which a single model is jointly optimized for aregular supervised training objective over the tree-bank data as well as a task-specific objective ?
ormore generally an extrinsic objective ?
on an ad-ditional data set.
The case where there are bothgold-standard trees and a task-specific objective forthe entire training set is a specific instance of thelarger problem that we address here.
Specifically,the algorithm takes the form of an online learnerwhere a training instance is selected and the param-1489eters are optimized based on the objective functionassociated with the instance (either intrinsic or ex-trinsic), thus jointly optimizing multiple objectives.An update schedule trades-off the relative impor-tance of each objective function.
We call our algo-rithm augmented-loss training as it optimizes mul-tiple losses to augment the traditional supervisedparser loss.There have been a number of efforts to exploitweak or external signals of quality to train better pre-diction models.
This includes work on generalizedexpectation (Mann and McCallum, 2010), posteriorregularization (Ganchev et al, 2010) and constraintdriven learning (Chang et al, 2007; Chang et al,2010).
The work of Chang et al (2007) on constraintdriven learning is perhaps the closest to our frame-work and we draw connections to it in Section 5.In these studies the typical goal is to use the weaksignal to improve the structured prediction modelson the intrinsic evaluation metrics.
For our settingthis would mean using weak application specific sig-nals to improve dependency parsing.
Though weexplore such ideas in our experiments, in particularfor semi-supervised domain adaptation, we are pri-marily interested in the case where the weak signalis precisely what we wish to optimize, but also de-sire the benefit from using both data with annotatedparse structures and data specific to the task at handto guide parser training.In Section 2 we outline the augmented-loss algo-rithm and provide a convergence analysis.
In Sec-tion 3 and 4 we present a set of experiments defin-ing diffent augmented losses covering a task-specificextrinsic loss (MT reordering), a domain adapta-tion loss, and an alternate intrinsic parser loss.
Inall cases we show the augmented-loss frameworkcan lead to significant gains in performance.
InSection 5 we tie our augmented-loss algorithm toother frameworks for encoding auxiliary informa-tion and/or joint objective optimization.2 MethodologyWe present the augmented-loss algorithm in the con-text of the structured perceptron.
The structuredperceptron (Algorithm 1) is an on-line learning al-gorithm which takes as input: 1) a set of trainingexamples di = (xi, yi) consisting of an input sen-Algorithm 1 Structured Perceptron{Input data sets: D = {d1 = (x1, y1) .
.
.
dN = (xN , yN )}}{Input 0/1 loss: L(F?
(x), y) = [F?
(x) 6= y ?
1 : 0]}{Let: F?
(x) = arg maxy?Y ?
?
?
(y)}{Initialize model parameters: ?
= ~0}repeatfor i = 1 .
.
.
N do{Compute structured loss}y?i = F?
(xi)if L(y?i, yi) > 0 then{Update model Parameters}?
= ?
+ ?(yi)?
?
(y?i)end ifend foruntil converged{Return model ?
}tence xi and an output yi; and 2) a loss-function,L(y?, y), that measures the cost of predicting out-put y?
relative to the gold standard y and is usu-ally the 0/1 loss (Collins, 2002).
For dependencyparser training, this set-up consists of input sen-tences x and the corresponding gold dependencytree y ?
Yx, where Yx is the space of possibleparse trees for sentence x.
In the perceptron setting,F?
(x) = arg maxy?Yx ?
??
(y) where ?
is mappingfrom a parse tree y for sentence x to a high dimen-sional feature space.
Learning proceeds by predict-ing a structured output given the current model, andif that structure is incorrect, updating the model: re-warding features that fire in the gold-standard ?
(yi),and discounting features that fire in the predictedoutput, ?
(y?i).The structured perceptron, as given in Algo-rithm 1, only updates when there is a positive loss,meaning that there was a prediction mistake.
Forthe moment we will abstract away from details suchas the precise definition of F (x) and ?(y).
Wewill show in the next section that our augmented-loss method is general and can be applied to any de-pendency parsing framework that can be trained bythe perceptron algorithm, such as transition-basedparsers (Nivre, 2008; Zhang and Clark, 2008) andgraph-based parsers (McDonald et al, 2005).2.1 Augmented-Loss TrainingThe augmented-loss training algorithm that we pro-pose is based on the structured perceptron; however,the augmented-loss training framework is a general1490mechanism to incorporate multiple loss functions inonline learner training.
Algorithm 2 is the pseudo-code for the augmented-loss structured perceptronalgorithm.
The algorithm is an extension to Algo-rithm 1 where there are 1) multiple loss functionsbeing evaluated L1, .
.
.
, LM ; 2) there are multipledatasets associated with each of these loss functionsD1, .
.
.
,DM ; and 3) there is a schedule for pro-cessing examples from each of these datasets, whereSched(j, i) is true if the jth loss function should beupdated on the ith iteration of training.
Note thatfor data point dji = (x, y), which is the ith traininginstance of the jth data set, that y does not neces-sarily have to be a dependency tree.
It can eitherbe a task-specific output of interest, a partial tree, oreven null, in the case where learning will be guidedstrictly by the loss Lj .
The training algorithm is ef-fectively the same as the perceptron, the primary dif-ference is that if Lj is an extrinsic loss, we cannotcompute the standard updates since we do not nec-essarily know the correct parse (the line indicated by?).
Section 2.2 shows one method for updating theparser parameters for extrinsic losses.In the experiments in this paper, we only considerthe case where there are two loss functions: a super-vised dependency parsing labeled-attachment loss;and an additional loss, examples of which are pre-sented in Section 3.2.2 Inline Ranker TrainingIn order to make Algorithm 2 more concrete, weneed a way of defining the loss and resulting pa-rameter updates for the case when Lj is not a stan-dard supervised parsing loss (?
from Algorithm 2).Assume that we have a cost function C(xi, y?, yi)which, given a training example (xi, yi) will give ascore for a parse y?
?
Yxi relative to some outputyi.
While we can compute the score for any parse,we are unable to determine the features associatedwith the optimal parse, as yi need not be a parsetree.
For example, consider a machine translation re-ordering system which uses the parse y?
to reorder thewords of xi, the optimal reordering being yi.
ThenC(xi, y?, yi) is a reordering cost which is large if thepredicted parse induces a poor reordering of xi.We propose a general purpose loss function whichis based on parser k-best lists.
The inline rerankeruses the currently trained parser model ?
to parseAlgorithm 2 Augmented-Loss Perceptron{Input data sets}:D1 = {d11 = (x11, y11) .
.
.
d1N1 = (x1N1 , y1N1)},.
.
.DM = {dM1 = (xM1 , yM1 ) .
.
.
dMNM = (xMNM , yMNM )}{Input loss functions: L1 .
.
.
LM}{Initialize indexes: c1 .
.
.
cM = ~0}{Initialize model parameters: ?
= ~0}i = 0repeatfor j = 1 .
.
.M do{Check whether to update Lj on iteration i}if Sched(j, i) then{Compute index of instance ?
reset if cj ?
N j}cj = [(cj ?
N j) ?
0 : cj + 1]{Compute structured loss for instance}if Lj is intrinsic loss theny?
= F?
(xjcj )if Lj(y?, yjcj ) > 0 then?
= ?
+ ?
(yjcj )?
?(y?)
{yjcj is a tree}end ifelse if Lj is an extrinsic loss then{See Section 2.2}?end ifend ifend fori = i+ 1until converged{Return model ?
}the external input, producing a k-best set of parses:Fk-best?
(xi) = {y?1, .
.
.
, y?k}.
We can compute thecost function C(xi, y?, yi) for all y?
?
Fk-best?
(xi).
Ifthe 1-best parse, y?1, has the lowest cost, then there isno lower cost parse in this k-best list.
Otherwise, thelowest-cost parse in Fk-best?
(xi) is taken to be thecorrect output structure yi, and the 1-best parse istaken to be an incorrect prediction.
We can achievethis by substituting the following into Algorithm 2at line ?.Algorithm 3 Reranker Loss{y?1, .
.
.
, y?k} = Fk-best?
(xi)?
= min?
C(xjcj , y??
, yjcj ) {?
is min const index}Lj(y?1, yjcj ) = C(xjcj , y?1, yjcj )?
C(xjcj , y??
, yjcj )if Lj(y?1, yjcj ) > 0 then?
= ?
+ ?(y??
)?
?
(y?1)end ifAgain the algorithm only updates when there isan error ?
when the 1-best output has a higher costthan any other output in the k-best list ?
resulting1491in positive Lj .
The intuition behind this method isthat in the presence of only a cost function and ak-best list, the parameters will be updated towardsthe parse structure that has the lowest cost, whichover time will move the parameters of the model toa place with low extrinsic loss.We exploit this formulation of the general-purpose augmented-loss function as it allows one toinclude any extrinsic cost function which is depen-dent of parses.
The scoring function used does notneed to be factored, requiring no internal knowledgeof the function itself.
Furthermore, we can apply thisto any parsing algorithm which can generate k-bestlists.
For each parse, we must retain the featuresassociated with the parse (e.g., for transition-basedparsing, the features associated with the transitionsequence resulting in the parse).There are two significant differences from the in-line reranker loss function and standard rerankertraining.
First, we are performing this decision perexample as each data item is processed (this is donein the inner loop of the Algorithm 2).
Second, thefeedback function for selecting a parse is based onan external objective function.
The second point isactually true for many minimum-error-rate trainingscenarios, but in those settings the model is updatedas a post-processing stage (after the base-model istrained).2.3 Convergence of Inline Ranker TrainingA training setD is loss-separable with margin ?
> 0if there exists a vector u with ?u?
= 1 such thatfor all y?, y??
?
Yx and (x, y) ?
D, if L(y?, y) <L(y?
?, y), then u??(y?)?u??(y??)
?
?.
Furthermore,let R ?
||?(y)?
?(y?
)||, for all y, y?.Assumption 1.
Assume training set D is loss-separable with margin ?.Theorem 1.
Given Assumption 1.
Letm be the num-ber of mistakes made when training the perceptron(Algorithm 2) with inline ranker loss (Algorithm 3)on D, where a mistake occurs for (x, y) ?
D withparameter vector ?
when ?y?j ?
F k-best?
(x) wherey?j 6= y?1 and L(y?j , y) < L(y?1, y).
If training is runindefinitely, then m ?
R2?2 .Proof.
Identical to the standard perceptron proof,e.g., Collins (2002), by inserting in loss-separabilityfor normal separability.Like the original perceptron theorem, this impliesthat the algorithm will converge.
However, unlikethe original theorem, it does not imply that it willconverge to a parameter vector ?
such that for all(x, y) ?
D, if y?
= arg maxy?
?
??(y?)
then L(y?, y) =0.
Even if we assume for every x there exists an out-put with zero loss, Theorem 1 still makes no guar-antees.
Consider a training set with one instance(x, y).
Now, set k = 2 for the k-best output list andlet y?1, y?2, and y?3 be the top-3 scoring outputs andlet L(y?1, y) = 1, L(y?2, y) = 2 and L(y?3, y) = 0.In this case, no updates will ever be made and y?1will remain unchanged even though it doesn?t haveminimal loss.
Consider the following assumption:Assumption 2.
For any parameter vector ?
that ex-ists during training, either 1) for all (x, y) ?
D,L(y?1, y) = 0 (or some optimal minimum loss),or 2) there exists at least one (x, y) ?
D where?y?j ?
F k-best?
(x) such that L(y?j , y) < L(y?1, y).Assumption 2 states that for any ?
that existsduring training, but before convergence, there is atleast one example in the training data where k islarge enough to include one output with a lower losswhen y?1 does not have the optimal minimal loss.
Ifk = ?, then this is the standard perceptron as itguarantees the optimal loss output to be in the k-bestlist.
But we are assuming something much weakerhere, i.e., not that the k-best list will include the min-imal loss output, only a single output with a lowerloss than the current best guess.
However, it is strongenough to show the following:Theorem 2.
Given Assumption 1 and Assumption 2.Training the perceptron (Algorithm 2) with inlineranker loss (Algorithm 3) on D 1) converges in fi-nite time, and 2) produces parameters ?
such thatfor all (x, y) ?
D, if y?
= arg maxy?
?
?
?(y?)
thenL(y?, y) = 0 (or equivalent minimal loss).Proof.
It must be the case for all (x, y) ?
D thatL(y?1, y) = 0 (and y?1 is the argmax) after a finiteamount of time.
Otherwise, by Assumption 2, thereexists some x, such that when it is next processed,there would exist an output in the k-best list thathad a lower loss, which will result in an additionalmistake.
Theorem 1 guarantees that this can notcontinue indefinitely as the number of mistakes isbounded.1492Thus, the perceptron algorithm will converge tooptimal minimal loss under the assumption that kis large enough so that the model can keep improv-ing.
Note that this does not mean k must be largeenough to include a zero or minimum loss output,just large enough to include a better output thanthe current best hypothesis.
Theorem 2, when cou-pled with Theorem 1, implies that augmented-losslearning will make at most R2/?2 mistakes at train-ing, but does not guarantee the rate at which thesemistakes will be made, only that convergence is fi-nite, providing that the scheduling time (defined bySched()) between seeing the same instance is alwaysfinite, which is always true in our experiments.This analysis does not assume anything about theloss L. Every instance (x, y) can use a different loss.It is only required that the loss for a specific input-output pair is fixed throughout training.
Thus, theabove analysis covers the case where some traininginstances use an extrinsic loss and others an intrin-sic parsing loss.
This also suggests more efficienttraining methods when extracting the k-best list isprohibitive.
One can parse with k = 2, 4, 8, 16, .
.
.until an k is reached that includes a lower loss parse.It may be the case that for most instances a smallk is required, but the algorithm is doing more workunnecessarily if k is large.3 Experimental Set-up3.1 Dependency ParsersThe augmented-loss framework we present is gen-eral in the sense that it can be combined with anyloss function and any parser, provided the parser canbe parameterized as a linear classifier, trained withthe perceptron and is capable of producing a k-bestlist of trees.
For our experiments we focus on twodependency parsers.?
Transition-based: An implementation of thetransition-based dependency parsing frame-work (Nivre, 2008) using an arc-eager transi-tion strategy and are trained using the percep-tron algorithm as in Zhang and Clark (2008)with a beam size of 8.
Beams with varyingsizes can be used to produce k-best lists.
Thefeatures used by all models are: the part-of-speech tags of the first four words on the bufferand of the top two words on the stack; the wordidentities of the first two words on the bufferand of the top word on the stack; the word iden-tity of the syntactic head of the top word on thestack (if available); dependency arc label iden-tities for the top word on the stack, the left andrightmost modifier of the top word on the stack,and the left most modifier of the first word inthe buffer (if available).
All feature conjunc-tions are included.?
Graph-based: An implementation of graph-based parsing algorithms with an arc-factoredparameterization (McDonald et al, 2005).
Weuse the non-projective k-best MST algorithm togenerate k-best lists (Hall, 2007), where k = 8for the experiments in this paper.
The graph-based parser features used in the experimentsin this paper are defined over a word, wi at po-sition i; the head of this word w?
(i) where ?
(i)provides the index of the head word; and part-of-speech tags of these words ti.
We use thefollowing set of features similar to McDonaldet al (2005):isolated features: wi, ti, w?
(i), t?
(i)word-tag pairs: (wi, ti); (w?
(i), t?
(i))word-head pairs: (wi, w?
(i)), (ti, t?
(i))word-head-tag triples: (t?
(i), wi, ti)(w?
(i), wi, ti)(w?
(i), t?
(i), ti)(w?
(i), t?
(i), wi)tag-neighbourhood: (t?
(i), t?
(i)+1, ti?1, ti)(t?
(i), t?
(i)+1, ti+1, ti)(t?
(i), t?
(i)?1, ti?1, ti)(t?
(i), t?
(i)?1, ti+1, ti)between features: ?j i < j < ?
(i) || ?
(i) < j < i(t?
(i), tj , ti)arc-direction/length : (i?
?
(i) > 0, |i?
?
(i)|)3.2 Data and TasksIn the next section, we present a set of scoring func-tions that can be used in the inline reranker lossframework, resulting in a new augmented-loss foreach one.
Augmented-loss learning is then appliedto target a downstream task using the loss functionsto measure gains.
We show empirical results for twoextrinsic loss-functions (optimizing for the down-stream task): machine translation and domain adap-tation; and for one intrinsic loss-function: an arc-length parsing score.
For some experiments we also1493measure the standard intrinsic parser metrics unla-beled attachment score (UAS) and labeled attach-ment score (LAS) (Buchholz and Marsi, 2006).In terms of treebank data, the primary trainingcorpus is the Penn Wall Street Journal Treebank(PTB) (Marcus et al, 1993).
We also make useof the Brown corpus, and the Question Treebank(QTB) (Judge et al, 2006).
For PTB and Brownwe use standard training/development/testing splitsof the data.
For the QTB we split the data intothree sections: 2000 training, 1000 development,and 1000 test.
All treebanks are converted to de-pendency format using the Stanford converter v1.6(de Marneffe et al, 2006).4 Experiments4.1 Machine Translation Reordering ScoreAs alluded to in Section 2.2, we use a reordering-based loss function to improve word order in a ma-chine translation system.
In particular, we use a sys-tem of source-side reordering rules which, given aparse of the source sentence, will reorder the sen-tence into a target-side order (Collins et al, 2005).In our experiments we work with a set of English-Japanese reordering rules1 and gold reorderingsbased on human generated correct reordering of analigned target sentences.
We use a reordering scorebased on the reordering penalty from the METEORscoring metric.
Though we could have used a fur-ther downstream measure like BLEU, METEOR hasalso been shown to directly correlate with translationquality (Banerjee and Lavie, 2005) and is simpler tomeasure.reorder-score = 1?
# chunks?
1# unigrams matched?
1reorder-cost = 1?
reorder-scoreAll reordering augmented-loss experiments arerun with the same treebank data as the baseline(the training portions of PTB, Brown, and QTB).The extrinsic reordering training data consists of10930 examples of English sentences and their cor-rect Japanese word-order.
We evaluate our results onan evaluation set of 6338 examples of similarly cre-ated reordering data.
The reordering cost, evaluation1Our rules are similar to those from Xu et al (2009).Exact Reordertrans?PTB + Brown + QTB 35.29 76.49trans?0.5?aug.-loss 38.71 78.19trans?1.0?aug.-loss 39.02 78.39trans?2.0?aug.-loss 39.58 78.67graph?PTB + Brown + QTB 25.71 69.84graph?0.5?
aug.-loss 28.99 72.23graph?1.0?aug.-loss 29.99 72.88graph?2.0?aug.-loss 30.03 73.15Table 1: Reordering scores for parser-based reordering(English-to-Japanese).
Exact is the number of correctlyreordered sentences.
All models use the same treebank-data (PTB, QTB, and the Brown corpus).
Results forthree augmented-loss schedules are shown: 0.5 where forevery two treebank updates we make one augmented-lossupdate, 1 is a 1-to-1 mix, and 2 is where we make twiceas many augmented-loss updates as treebank updates.criteria and data used in our experiments are basedon the work of Talbot et al (2011).Table 1 shows the results of using the reorderingcost as an augmented-loss to the standard treebankobjective function.
Results are presented as mea-sured by the reordering score as well as a coarseexact-match score (the number of sentences whichwould have correct word-order given the parse andthe fixed reordering rules).
We see continued im-provements as we adjust the schedule to process theextrinsic loss more frequently, the best result beingwhen we make two augmented-loss updates for ev-ery one treebank-based loss update.4.2 Semi-supervised domain adaptationAnother application of the augmented-loss frame-work is to improve parser domain portability in thepresence of partially labeled data.
Consider, for ex-ample, the case of questions.
Petrov et al (2010)observed that dependency parsers tend to do quitepoorly when parsing questions due to their lim-ited exposure to them in the news corpora fromthe PennTreebank.
Table 2 shows the accuracyof two parsers (LAS, UAS and the F1 of the rootdependency attachment) on the QuestionBank testdata.
The first is a parser trained on the standardtraining sections of the PennTreebank (PTB) andthe second is a parser trained on the training por-tion of the QuestionBank (QTB).
Results for both1494LAS UAS Root-F1trans?PTB 67.97 73.52 47.60trans?QTB 84.59 89.59 91.06trans?aug.-loss 76.27 86.42 83.41graph?PTB 65.27 72.72 43.10graph?QTB 82.73 87.44 91.58graph?aug.-loss 72.82 80.68 86.26Table 2: Domain adaptation results.
Table shows (forboth transition and graph-based parsers) the labeled ac-curacy score (LAS), unlabeled accuracy score (UAS)and Root-F1 for parsers trained on the PTB and QTBand tested on the QTB.
The augmented-loss parsers aretrained on the PTB but with a partial tree loss on QTBthat considers only root dependencies.transition-based parsers and graph-based parsers aregiven.
Clearly there is significant drop in accu-racy for a parser trained on the PTB.
For example,the transition-based PTB parser achieves a LAS of67.97% relative to 84.59% for the parser trained onthe QTB.We consider the situation where it is possible toask annotators a single question about the target do-main that is relatively easy to answer.
The questionshould be posed so that the resulting answer pro-duces a partially labeled dependency tree.
Root-F1scores from Table 2 suggest that one simple ques-tion is ?what is the main verb of this sentence??
forsentences that are questions.
In most cases this taskis straight-forward and will result in a single depen-dency, that from the root to the main verb of the sen-tence.
We feel this is a realistic partial labeled train-ing setting where it would be possible to quickly col-lect a significant amount of data.To test whether such weak information can signif-icantly improve the parsing of questions, we trainedan augmented-loss parser using the training set ofthe QTB stripped of all dependencies except the de-pendency from the root to the main verb of the sen-tence.
In other words, for each sentence, the parsermay only observe a single dependency at trainingfrom the QTB ?
the dependency to the main verb.Our augmented-loss function in this case is a simplebinary function: 0 if a parse has the correct root de-pendency and 1 if it does not.
Thus, the algorithmwill select the first parse in the k-best list that has thecorrect root as the proxy to a gold standard parse.2The last row in each section of Table 2 shows theresults for this augmented-loss system when weight-ing both losses equally during training.
By simplyhaving the main verb annotated in each sentence ?the sentences from the training portion of the QTB?
the parser can eliminate half of the errors of theoriginal parser.
This is reflected by both the Root-F1 as well as LAS/UAS.
It is important to point outthat these improvements are not limited to simplybetter root predictions.
Due to the fact that parsingalgorithms make many parsing decisions jointly attest time, all such decisions influence each other andimprovements are seen across the board.
For exam-ple, the transition-based PTB parser has an F1 scoreof 41.22% for verb subjects (nsubj), whereas theaugmented-loss parser has an F1 of 73.52%.
Clearlyimproving just a single (and simple to annotate) de-pendency leads to general parser improvements.4.3 Average Arc Length ScoreThe augmented-loss framework can be used to in-corporate multiple treebank-based loss functions aswell.
Labeled attachment score is used as our basemodel loss function.
In this set of experiments weconsider adding an additional loss function whichweights the lengths of correct and incorrect arcs, theaverage (labeled) arc-length score:ALS =?i ?(?
?i, ?i)(i?
?i)?i(i?
?i)For each word of the sentence we compute the dis-tance between the word?s position i and the posi-tion of the words head ?i.
The arc-length score isthe summed length of all those with correct head as-signments (?(?
?i, ?i) is 1 if the predicted head andthe correct head match, 0 otherwise).
The score isnormalized by the summed arc lengths for the sen-tence.
The labeled version of this score requires thatthe labels of the arc are also correct.
Optimizingfor dependency arc length is particularly importantas parsers tend to do worse on longer dependencies(McDonald and Nivre, 2007) and these dependen-cies are typically the most meaningful for down-stream tasks, e.g., main verb dependencies for tasks2For the graph-based parser one can also find the higest scor-ing tree with correct root by setting the score of all competingarcs to ?
?.1495LAS UAS ALStrans?PTB 88.64 91.64 82.96trans?unlabeled aug.-loss 88.74 91.91 83.65trans?labeled aug.-loss 88.84 91.91 83.46graph?PTB 85.75 88.70 73.88graph?unlabeled aug.-loss 85.80 88.81 74.26graph?labeled aug.-loss 85.85 88.93 74.40Table 3: Results for both parsers on the development setof the PTB.
When training with ALS (labeled and unla-beled), we see an improvement in UAS, LAS, and ALS.Furthermore, if we use a labeled-ALS as the metric foraugmented-loss training, we also see a considerable in-crease in LAS.like information extraction (Yates and Etzioni, 2009)and textual entailment (Berant et al, 2010).In Table 3 we show results for parsing with theALS augmented-loss objective.
For each parser, weconsider two different ALS objective functions; onebased on unlabeled-ALS and the other on labeled-ALS.
The arc-length score penalizes incorrect long-distance dependencies more than local dependen-cies; long-distance dependencies are often more de-structive in preserving sentence meaning and can bemore difficult to predict correctly due to the largercontext on which they depend.
Combining this withthe standard attachment scores biases training to fo-cus on the difficult head dependencies.For both experiments we see that by adding theALS augmented-loss we achieve an improvement inLAS and UAS in addition to ALS.
The augmented-loss not only helps us improve on the longer depen-dencies (as reflected in the increased ALS), but alsoin the main parser objective function of LAS andUAS.
Using the labeled loss function provides betterreinforcement as can be seen in the improvementsover the unlabeled loss-function.
As with all experi-ments in this paper, the graph-based parser baselinesare much lower than the transition-based parser dueto the use of arc-factored features.
In these experi-ments we used an inline-ranker loss with 8 parses.We experimented with larger sizes (16 and 64) andfound very similar improvements: for example, thetransition parser?s LAS for the labeled loss is 88.68and 88.84, respectively).We note that ALS can be decomposed locally andcould be used as the primary objective function forparsing.
A parse with perfect scores under ALSand LAS will match the gold-standard training tree.However, if we were to order incorrect parses of asentence, ALS and LAS will suggest different order-ings.
Our results show that by optimizing for lossesbased on a combination of these metrics we train amore robust parsing model.5 Related WorkA recent study by Katz-Brown et al (2011) also in-vestigates the task of training parsers to improve MTreordering.
In that work, a parser is used to firstparse a set of manually reordered sentences to pro-duce k-best lists.
The parse with the best reorderingscore is then fixed and added back to the training setand a new parser is trained on resulting data.
Themethod is called targeted self-training as it is simi-lar in vein to self-training (McClosky et al, 2006),with the exception that the new parse data is targetedto produce accurate word reorderings.
Our methoddiffers as it does not statically fix a new parse, butdynamically updates the parameters and parse selec-tion by incorporating the additional loss in the innerloop of online learning.
This allows us to give guar-antees of convergence.
Furthermore, we also evalu-ate the method on alternate extrinsic loss functions.Liang et al (2006) presented a perceptron-basedalgorithm for learning the phrase-translation param-eters in a statistical machine translation system.Similar to the inline-ranker loss function presentedhere, they use a k-best lists of hypotheses in order toidentify parameters which can improve a global ob-jective function: BLEU score.
In their work, theyare interested in learning a parameterization overtranslation phrases (including the underlying word-alignment) which optimizes the BLEU score.
Theirgoal is considerably different; they want to incor-porate additional features into their model and de-fine an objective function which allows them to doso; whereas, we are interested in allowing for mul-tiple objective functions in order to adapt the parsermodel parameters to downstream tasks or alternativeintrinsic (parsing) objectives.The work that is most similar to ours is thatof Chang et al (2007), who introduced the Con-straint Driven Learning algorithm (CODL).
Their al-gorithm specifically optimizes a loss function with1496the addition of constraints based on unlabeled data(what we call extrinsic datasets).
For each unla-beled example, they use the current model alongwith their set of constraints to select a set of k au-tomatically labeled examples which best meet theconstraints.
These induced examples are then addedto their training set and, after processing each unla-beled dataset, they perform full model optimizationwith the concatenation of training data and newlygenerated training items.
The augmented-loss al-gorithm can be viewed as an online version of thisalgorithm which performs model updates based onthe augmented-loss functions directly (rather thanadding a set of examples to the training set).
Un-like the CODL approach, we do not perform com-plete optimization on each iteration over the unla-beled dataset; rather, we incorporate the updates inour online learning algorithm.
As mentioned earlier,CODL is one example of learning algorithms thatuse weak supervision, others include Mann and Mc-Callum (2010) and Ganchev et al (2010).
Again,these works are typically interested in using the ex-trinsic metric ?
or, in general, extrinsic information?
to optimize the intrinsic metric in the absence ofany labeled intrinsic data.
Our goal is to optimizeboth simultaneously.The idea of jointly training parsers to optimizemultiple objectives is related to joint learning and in-ference for tasks like information extraction (Finkeland Manning, 2009) and machine translation (Bur-kett et al, 2010).
In such works, a large search spacethat covers both the space of parse structures andthe space of task-specific structures is defined andparameterized so that standard learning and infer-ence algorithms can be applied.
What sets our workapart is that there is still just a single parameter setthat is being optimized ?
the parser parameters.
Ourmethod only uses feedback from task specific objec-tives in order to update the parser parameters, guid-ing it towards better downstream performance.
Thisis advantageous for two reasons.
First, it decouplesthe tasks, making inference and learning more effi-cient.
Second, it does not force arbitrary paraemterfactorizations in order to define a joint search spacethat can be searched efficiently.Finally, augmented-loss training can be viewedas multi-task learning (Caruana, 1997) as the modeloptimizes multiple objectives over multiple data setswith a shared underlying parameter space.6 DiscussionThe empirical results show that incorporating anaugmented-loss using the inline-ranker loss frame-work achieves better performance under metrics as-sociated with the external loss function.
For the in-trinsic loss, we see that the augmented-loss frame-work can also result in an improvement in parsingperformance; however, in the case of ALS, this isdue to the fact that the loss function is very closelyrelated to the standard evaluation metrics of UASand LAS.Although our analysis suggests that this algorithmis guaranteed to converge only for the separablecase, it makes a further assumption that if there isa better parse under the augmented-loss, then theremust be a lower cost parse in the k-best list.
The em-pirical evaluation presented here is based on a veryconservative approximation by choosing lists withat most 8 parses.
However, in our experiments, wefound that increasing the size of the lists did not sig-nificantly increase our accuracy under the externalmetrics.
If we do have at least one improvementin our k-best lists, the analysis suggests that this isenough to move in the correct direction for updatingthe model.
The assumption that there will alwaysbe an improvement in the k-best list if there is somebetter parse breaks down as training continues.
Wesuspect that an increasing k, as suggested in Sec-tion 2.3, will allow for continued improvements.Dependency parsing, as presented in this pa-per, is performed over (k-best) part-of-speech tagsand is therefore dependent on the quality of thetagger.
The experiments presented in this papermade use of a tagger trained on the source treebankdata which severely limits the variation in parses.The augmented-loss perceptron algorithm presentedhere can be applied to any online learning prob-lem, including part-of-speech tagger training.
Tobuild a dependency parser which is better adaptedto a downstream task, one would want to performaugmented-loss training on the tagger as well.7 ConclusionWe introduced the augmented-loss training algo-rithm and show that the algorithm can incorporate1497additional loss functions to adapt the model towardsextrinsic evaluation metrics.
Analytical results arepresented that show that the algorithm can opti-mize multiple objective functions simultaneously.We present an empirical analysis for training depen-dency parsers for multiple parsing algorithms andmultiple loss functions.The augmented-loss framework supports both in-trinsic and extrinsic losses, allowing for both com-binations of objectives as well as multiple sourcesof data for which the results of a parser can be eval-uated.
This flexibility makes it possible to tune amodel for a downstream task.
The only requirementis a metric which can be defined over parses of thedownstream data.
Our dependency parsing resultsshow that we are not limited to increasing parserperformance via more data or external domain adap-tation techniques, but that we can incorporate thedownstream task into parser training.Acknowledgements: We would like to thank Kuz-man Ganchev for feedback on an earlier draft of thispaper as well as Slav Petrov for frequent discussionson this topic.ReferencesS.
Banerjee and A. Lavie.
2005.
METEOR: An auto-matic metric for MT evaluation with improved corre-lation with human judgments.
In Proceedings of theACL Workshop on Intrinsic and Extrinsic EvaluationMeasures for Machine Translation and/or Summariza-tion.J.
Berant, I. Dagan, and J. Goldberger.
2010.
Globallearning of focused entailment graphs.
In Proc.
ofACL.J.
Blitzer, R. McDonald, and F. Pereira.
2006.
Domainadaptation with structural correspondence learning.
InProc.
of EMNLP.S.
Buchholz and E. Marsi.
2006.
CoNLL-X sharedtask on multilingual dependency parsing.
In Proc.
ofCoNLL.D.
Burkett, J. Blitzer, and D. Klein.
2010.
Joint parsingand alignment with weakly synchronized grammars.In Proc.
of NAACL.R.
Caruana.
1997.
Multitask learning.
Machine Learn-ing, 28(1):41?75.M.W.
Chang, L. Ratinov, and D. Roth.
2007.
Guidingsemi-supervision with constraint-driven learning.
InProc.
of ACL.M.
Chang, D. Goldwasser, D. Roth, and V. Srikumar.2010.
Structured output learning with indirect super-vision.
In Proc.
of ICML.M.
Collins, P. Koehn, and I. Kuc?erova?.
2005.
Clause re-structuring for statistical machine translation.
In Proc.of ACL.Michael Collins.
2000.
Discriminative reranking for nat-ural language parsing.
In Proc.
of ICML.M.
Collins.
2002.
Discriminative training methods forhidden markov models: Theory and experiments withperceptron algorithms.
In Proc.
of ACL.M.C.
de Marneffe, B. MacCartney, and C. Manning.2006.
Generating typed dependency parses fromphrase structure parses.
In Proc.
of LREC, Genoa,Italy.J.R.
Finkel and C.D.
Manning.
2009.
Joint parsing andnamed entity recognition.
In Proc.
of NAACL.K.
Ganchev, J. Grac?a, J. Gillenwater, and B. Taskar.2010.
Posterior regularization for structured latentvariable models.
Journal of Machine Learning Re-search.D.
Gildea.
2001.
Corpus variation and parser perfor-mance.
In Proc.
of EMNLP.K.
Hall.
2007. k-best spanning tree parsing.
In Proc.
ofACL, June.J.
Judge, A. Cahill, and J.
Van Genabith.
2006.
Question-bank: Creating a corpus of parse-annotated questions.In Proc.
of ACL, pages 497?504.J.
Katz-Brown, S. Petrov, R. McDonald, D. Talbot,F.
Och, H. Ichikawa, M. Seno, and H. Kazawa.
2011.Training a parser for machine translation reordering.In Proc.
of EMNLP.S.
Ku?bler, R. McDonald, and J. Nivre.
2009.
Depen-dency parsing.
Synthesis Lectures on Human Lan-guage Technologies.
Morgan & Claypool Publishers.P.
Liang, A. Bouchard-Ct, D. Klein, and B. Taskar.
2006.An end-to-end discriminative approach to machinetranslation.
In Proc.
of COLING/ACL.G.S.
Mann and A. McCallum.
2010.
Generalized Ex-pectation Criteria for Semi-Supervised Learning withWeakly Labeled Data.
The Journal of Machine Learn-ing Research, 11:955?984.M.
Marcus, B. Santorini, and M.A.
Marcinkiewicz.1993.
Building a large annotated corpus of en-glish: The penn treebank.
Computational Linguistics,19:313?330.D.
McClosky, E. Charniak, and M. Johnson.
2006.Reranking and self-training for parser adaptation.
InProc.
of ACL.R.
McDonald and J. Nivre.
2007.
Characterizing theerrors of data-driven dependency parsing models.
InProc.
of EMNLP-CoNLL.1498R.
McDonald, K. Crammer, and F. Pereira.
2005.
Onlinelarge-margin training of dependency parsers.
In Proc.of ACL.T.
Nakagawa, K. Inui, and S. Kurohashi.
2010.
De-pendency tree-based sentiment classification using crfswith hidden variables.
In Proc.
of NAACL.J.
Nivre.
2008.
Algorithms for deterministic incremen-tal dependency parsing.
Computational Linguistics,34(4):513?553.S.
Petrov, P.C.
Chang, M. Ringgaard, and H. Alshawi.2010.
Uptraining for accurate deterministic questionparsing.
In Proc.
of EMNLP, pages 705?713.D.
Talbot, H. Kazawa, H. Ichikawa, J. Katz-Brown,M.
Seno, and F. Och.
2011.
A lightweight evalu-ation framework for machine translation reordering.In Proc.
of the Sixth Workshop on Statistical MachineTranslation.M.
Wang, N.A.
Smith, and T. Mitamura.
2007.
What isthe Jeopardy model?
A quasi-synchronous grammarfor QA.
In Proc.
of EMNLP-CoNLL.P.
Xu, J. Kang, M. Ringgaard, and F. Och.
2009.
Us-ing a dependency parser to improve SMT for Subject-Object-Verb languages.
In Proc.
of NAACL.A.
Yates and O. Etzioni.
2009.
Unsupervised meth-ods for determining object and relation synonyms onthe web.
Journal of Artificial Intelligence Research,34(1):255?296.Y.
Zhang and S. Clark.
2008.
A Tale of TwoParsers: Investigating and Combining Graph-basedand Transition-based Dependency Parsing.
In Proc.of EMNLP, pages 562?571.1499
