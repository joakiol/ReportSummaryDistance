Automatic Construction of Weighted String Similarity MeasuresJ S rg  T iedemannDepartment  of LinguisticsUppsala Universityjoerg@stp.l ing, uu.seAbst rac tString similarity metrics are used for several pur-poses in text-processing.
One task is the extractionof cognates from bilingual text.
In this paper threeapproaches tothe automatic generation of languagedependent s ring matching functions are presented.1 In t roduct ionString similarity metrics are extensively used in theprocessing of textual data for several purposes uchas the detection and correction of spelling errors(Kukich, 1992), for sentence and word alignments(Church, 1993; Simard et al, 1992; Melamed, 1995),and the extraction of information from monolingnalas well as multi-lingual text (Resnik and Melamed,1997; Borin, 1998; Tiedemann, 1998a).
One im-portant task is the identification of so-called cog-nates, token pairs with a significant similarity be-tween them, in bilingual text.A commonly used technique for measuring stringsimilarity is to look for the longest common subse-quence (LCS) of characters in two strings; the char-acters in this sequence do not necessarily need to becontiguous in the original strings (Wagner and Fis-cher, 1974; Stephen, 1992).
The length of the LCS isusually divided by the length of the longer string ofthe two original tokens in order to obtain a normal-ized value.
This score is called the longest commonsubsequence ratio- LCSR (Melamed, 1995).However, when it comes to different languages, asimple comparison of characters i usually not sat-isfactory to indicate the total correspondence b -tween words.
Different languages tend to modifyloan words derived from the same origin in differentways.
Swedish and English are an example for twolanguages with a close etymological relation but adifferent way of spelling for a large set of cognates.The spelling usually follows certain language specificrules, e.g.
the letter 'c' in English words correspondsto the letter 'k' in Swedish in most cases of cognates.Rules like this can be used for the recognition ofcognates from specific language pairs.
In this pa-per three approaches tothe automatic generation oflanguage pair specific string matching functions axeintroduced.
They include comparisons at the levelof characters and n-grams with dynamic length.All the three approaches presume linguistic sim-ilarities between two languages.
In this study theywere applied to word pairs from a Swedish/Englishtext corpus and experimental results are presentedfor each of them.2 ResourcesTwo types of textual resources were used in thisstudy:* reference l xicons for the automatic generationof string matching functions?
bilingual word pairs to be investigated with re-gard to string similarityA collection of bilingual word pairs is easy toproduce.
Similarity metrics should be applicableto every possible word pair from this set.
How-ever, some restrictions can be imposed on the choiceof appropriate pairs.
In this study, all word pairswere derived from sentence aligned corpora of tech-nical texts which were collected in the PLUG corpus(Tiedemann, 1998b) as part of the PLUG project 1(Ahrenberg et al, 1998).Technical texts are suitable for investigations onstring similarity.
The text collection which is ex-amined comprises about 180,000 words per languageand includes a large amount of technical expressions.Therefore, a comprehensive list of cognates can beexpected from this corpus.Some further constraints were set in order to re-strict the set of bilingual word pairs to be investi-gated:minimal  token length: Each token should con-tain at least a certain amount of characters.Very short strings do not represent reliablesources for string comparison.
The minimallength of tokens used in this study was set tofour characters.1The PLUG project is a cooperative project funded by"The Swedish Council for Research in the Humanities andSocial Sciences" HSFR and the "Swedish National Board forIndustrial and Technical Development" NUTEK.213maximal  d istance:  Token pairs were taken fromsentence aligned bi-text.
The position of eachtoken in its sentence can be used to reduce thenumber of potential candidate pairs.
One pos-sibility is to set a maximum for the difference inposition for each token pair.
In this study theposition difference may not exceed 10 token.min imal  length  d i f ference rat io:  Cognatesshould be of comparable length.
Therefore, itis appropriate to restrict the set of candidatesto strings whose length difference does notexceed a certain value.
The quotient of thelength of the shorter string and the lengthof the longer string can be used to calculatea ratio for measuring this difference.
In thisstudy the set of candidates were restricted totoken pairs whose length difference ratio doesnot exceed a value of 0.7.Using these three restrictions a set of 308,362 can-didate pairs were obtained from parts of the PLUGcorpus.The selection of reference l xicons hould be donewith care.
These lists of word pairs are decisive forthe quality of the string matching function whichwill be produced.
For availability reasons it was de-cided to use bilingual word lists which were producedin an automatic word alignment process.
This is notthe perfect solution because they contain quite a fewerrors and therefore they degrade the quality of theresults to be produced.The reference lexicons were generated by wordalignment based on statistic measures and empiri-cal investigations.
The software which was used forthe extraction is the Uppsala word alignment ool(Tiedemann, 1997; Tiedemann, 1999).
The follow-ing two word lists were investigated:GordSVEN:  A list of 2,431 Swedish/English wordalignments derived from the English/Swedishbi-text 'A Guest of Honour' by NadineGordimer with an estimated precision of about95.8%.Scan iaSVEN:  A list of 2,223 Swedish/Englishword alignments derived from theSwedish/English bi-texts in the Scania95corpus (Sca, 1998) by measuring LCSR scores 2with an estimated precision of about 92.5%.Both bi-texts are part of the PLUG corpus.3 Bas ic  Techn iquesDynamic  P rogrammingA common technique for computing the lengthof the longest common subsequence for two given2LCSR scores were calculated for tokens containing at leastone alphabetic haracter and a threshold of 0.7 was used tofilter the resulting list.b a 1 a n c e a r mFigure 1: Calculating the length of the LCS of 'bal-ance arm' and 'balansarmens' using Dynamic Pro-gramming.strings is to apply a dynamic programming algo-rithm (Stephen, 1992).
If n is the length of stringx and m is the length of string y an (0..n, 0..re)-matrix L describes the array of correspondences forthese two strings.
The initial column and the ini-tial line of this matrix is set to 0.
Now, a charactermatching function m has to be defined.
The follow-ing definition for m is used to calculate the lengthof the LCS:m(xi ,y j )  = 1 Vxi,yj : xi = ffjm(xi,y j )  = 0 Vzi,yj  : Zi <> yjNow, the matrix can be filled dynamically startingwith the origin and using the following constraint:Vi<nVj<m : l i j  = max(l i - l , j ,  l i j -1, l i - l , j - l+m(xi ,  yj))Finally, the last field in this matrix contains thelength of the LCS for the given strings.
Note, thatmatching is defined for each element of the alphabetof characters including special symbols and whitespaces.
Consider the example in figure 1.This algorithm can be modified by changing thecharacter matching function.
One possibility is toset priorities for specific matches by defining weightsfor the corresponding character.
Now, the functionm has to be modified to ra(x, y) = w(x) in all casesof x = y where w(x) is a weight for the characterx z.
Another possibility is to define a complete char-acter matching function for all elements from thealphabet.
That means, each m(x, y) defines an in-dependent matching value for the pair Ix, y\]4.3A function that follows this definition will be referred toas weighted matching function.4A function like this will be referred to as independentmatching function in the further descriptions.214After this modifications the final value of the dy-namic algorithm described above will be changed ac-cording to the new matching function.
The resultdoes not determine the length of the LCS anymoreand therefore it will be considered as the highestscore of correspondence (HSC).Furthermore, the string segmentation can be mod-ified.
The algorithm above does not require a seg-mentation into characters.
Dynamic programmingcan be applied to string pairs which were split intolarger units than single characters.
The only require-ment for this is an adequate definition of the stringmatching function for all possible pairs of stringunits.String SegmentationThere is a common segmentation problem with unitslarger than one element.
The problem arises in caseof overlapping units within the string.
A simple ap-proach is to parse the string from left to right andto find the longest possible segment starting at thecurrent position.
The segmentation process startsagain at the position directly after the last positionof the previous egment.
This approach was used forstring segmentation i  this study.Co-occur rence  StatisticsCo-occurrence can be measured by different statis-tical metrics.
They can be estimated by frequencycounts for the elements to be considered.
The valueof f (a)  refers to the overall frequency counted forelement a and the value of f (x,  y) refers to the co-occurrence frequency of the elements x and y in thecollection of N aligned units.The following formulas describe approximations oftwo commonly used metrics, Mutual Information (I)and the Dice coefficient (Dice) (Smadja et al, 1996;Church et al, 1991):I(x,y)Dice(x,y)Estimated Position?
f(x, y) .
N,,~ 2 Yx,yf~+fyThe proposed approaches to the generation ofmatching functions are based on the calculation ofco-occurrence statistics.
String units have to bematched at certain positions in order to measureco-occurrence frequencies.
A so-called estimated po-sition can be used to determine the position of thecorresponding string unit.
The following formula re-turns this value for the string pair Ix, y\] and the ithelement in y:t ngth(y)P(Yi) = r?und i " length(x) \]Case Folding and  A lphabet  RestrictionsCase folding can be used to neutralize capitalizationat the beginning of sentences.
This can be usefulfor investigations of string similarity.
However, valu-able information can be lost especially when it comesto weighted matching functions.
A higher priorityfor matching capitals would be desirable in cases ofproper nouns.
Furthermore, a reduced score mightbe useful when matching capitals with lower casecharacters.
However, in this study case folding wasapplied.Furthermore, the alphabet of the elements whichshall be considered in the generation of the stringmatching function can be restricted.
Results can beinfluenced strongly by wrong scores for special sym-bols and low frequent elements.
This phenomenonappears especially in the case of independent match-ing functions, implying e.g.
automatically generatedm-functions may include matches for non-identicaldigits.4 Generat ing  the  St r ing  Match ingFunct ion4.1 Approach  1: Map Characters  (VCchar)The aim of this approach is to produce an indepen-dent matching function m based on a segmentationat the character level.
The following heuristic isused:Pairs of vowels and consonants, respec-tively, which co-occur more frequently inthe reference lexicon get a higher value inthe m-function than lower frequency pairs.Pairs which do not co-occur at all get thefunction value 0.In this approach the matching function is gener-ated in three steps: First, all vowels at similar es-timated positions in word pairs from the referencelexicon are mapped to each other.
Consonants areprocessed in a similar manner.
Second, the frequen-cies for all elements in the alphabet are counted onboth sides and the frequency of each unique charac-ter mapping determines the co-occurrence frequencyfor each pair of characters.
Finally, the Dice coef-ficient is used to calculate a value for each pair ofcharacters in the list of character mappings.
Thisvalue is used for the corresponding pair of charactersin the final string matching function m. The Dicecoefficient was chosen because it produces values be-tween 0 and 1.
In this way, the resulting similarityscore remains a value in the range of 0 and 1 whichis to prefer.One problem arises with the definition of the setof vowels and consonants because the usage of letterscan be context sensitive.
For simplicity it was chosento use a static disjunct definition of both sets (e.g.
'y' has been used as vowel only).215Dice score freq Swedish English0.6667 1 6 60.597 20 x x0.5189 261 m m0.5039 873 e e0.4925 736 a a0.4793 551 i i0.4702 402 o o0.2981 182 k c0.2292 413 a e0.2176 63 v w0.1812 273 a i0.1691 244 r s0.1656 238 e i0.1179 168 e a0.0681 40 ?
o0.0617 44 ~ a0.1019 111 ~ e0.0914 34 ~ u0.1032 112 5 e0.0982 64 5 oFigure 2: Approach 1: The top seven character map-pings, the first seven non-identical character map-pings, and the first two mappings for each Swedishdiacritic in the Swedish/English VCchar matchingfunction.The resulting list (sorted after descending Dicescores) contains mainly pairs of identical etters onthe top.
Figure 2 shows, besides the seven high-est rankings of pairs in the list, the first seven non-identical pairs, and mappings of Swedish diacriticswhich were obtained from the application to theSwedish/English reference lexicon GordSVEN.There are mappings of non-identical characterswhich are hard to retrace, e.g.
the relation between'a' and 'i'.
However, most of the highest rankings ofnon-identical pairs reflect interesting connections be-tween different characters in Swedish/English wordpairs.
Relations between 'k' and 'c' ('korrekt' -'correctly', 'kopia' - 'copy'), 'a' and 'e' ('beskriva'- 'describe', 'deformerad' - 'deformed'), 'v' and 'w'('vatten' ?
'water', 'tv~' - 'two') can be recognizedeasily.
Furthermore, the algorithm provides inter-esting weights for pairs of identical characters.
Thefunction shows that infrequent letters like '6' and 'x'can be matched with high confidence.
In contrastwith this, higher frequent characters with larger in-consistency like 'k', 'c', and 'w' obtain a lower valuein this function, e.g.
the match of the character 'c'in Swedish with the identical character 'c' in Englishwill be scored with only 0.1123 points.The automatically generated m-function formatching character pairs was applied for string simi-larity calculation to the list of Swedish/English can-didates from parts of the PLUG corpus.
The pro-gram returned 1,449 alignment candidates with anestimated precision of 96.8% when using a thresholdof 0.354.2 Approach 2: Map Vowel andConsonant  Sequences  (VCseq)The goal in this approach is to generate a functionfor matching pairs of vowel sequences and pairs ofconsonant sequences.
The motivation for this studyis to extend the segmentation of strings from thecharacter level to an n-gram model.
Similarly toapproach 1 a reference lexicon is used to calculateco-occurrence statistics for pairs of elements fromthe alphabet of string units.
However, the segmen-tation of strings has been changed.
Each stringfrom the lexicon is split into vowel sequences fol-lowed by consonant sequences and the other wayaround.
Furthermore, these sequences may be in-terrupted by character sequences from the set of re-maining elements in the alphabet (characters whichare neither in the set of vowels nor in the set of con-sonants).
Now, all vowel sequences and consonantsequences, respectively, at identical estimated posi-tions are mapped to each other and the frequencyof each unique mapping is counted.
Similarly to ap-proach 1, Dice scores are estimated by using overallfrequencies for each character sequence and the fre-quencies of each pair in the list of mappings.
Fig-ure 3 shows some mappings from the applicationof this algorithm to the Swedish/English word listGordSVEN.Again, the pairs with the highest ranking aremainly identical strings.
In contrast to the VC?char function there are already two non-identicalpairs in the top-seven of the list.
However,the co-occurrence frequency for them is very low(4 respective 2) and therefore the statistics arenot very reliable.
The value for the pair 'np'and 'dj' is due to four dictionary entries withmorphological variants of ( 'anpassa', 'adjust') and('anpassning','adjustment') and the low overall fre-quencies of 'np' and 'dj'.
Similarly, the link between'ktt' and 'bs' is due to three word pairs with vari-ants of ' iakttagare' and 'observer' in the referencelexicon.
A higher threshold for the co-occurrencefrequency can be used to remove these pairs.
How-ever, a lot of interesting links would be lost in thisway as well.The mappings for Swedish diacritics are not veryreliable as reflected in their scores.
These values willnot influence the similarity measurements a lot.The program returned 651 candidates when ap-plied to word pairs from the PLUG corpus with a5The threshold value has to be much lower compared toother string similarity metrics like LCSR because token pairsobtain a much lower score in average.216Dice score freq Swedish English1 10 eo eo1 4 sr sr1 4 np dj1 2 dgs dgs1 2 lsj lzh1 2 rsp rsp1 2 schw schw1 4 np dj1 2 lsj lzh0.8 4 ktr ctr0.8 2 gsn dg0.7368 7 skr scr0.6667 3 ktt bs.0.6316 6 tj tw0.0648 7 ?
ou0.064 27 ?
o0.1256 25 ~ ea0.0899 25 ~ u0.1183 23 5 ea0.1024 50 5 oFigure 3: Approach 2: The top sevenvowel/consonant-sequence mappings, the first sevennon-identical pairs, and the first two mappingsfor each Swedish diacritic in the Swedish/EnglishVCseq matching function.threshold of 0.15.
The result yielded an estimatedprecision of 92.9%.4.3 Approach  3: Map Non-Match ing  Par ts(NMmap)The last approach which will be discussed here dif-fers from the other two by its general principle.
Incontrast to the other approaches the goal of the thirdapproach is to extend a common matching functionwith some additional values for specific pairs.
Thebasic matching function is represented by the m-function for LCS calculation (see section 3).
Simi-larly to the other approaches a reference lexicon istaken to generate matching values for some specificpairs.
Dynamic programming and a best trace com-putation can be used to identify non-matching partsof two strings.
Now, these parts can be analyzed inorder to find language pair specific correspondences.A simple idea is to match corresponding parts fromthe lists of non-matching strings to each other if theydo not exceed a certain length.
In this study a lengthof three character was chosen as a threshold.
Con-sider figure 4 for an example of the mapping of non-matching parts for the Swedish/English word pair(kritiska,critical).Now, a weight for each pair of non-matchingstrings \[x, y\] can be calculated by dividing its fre-quency by the total number of non-matching map-ks?urcestrin  Ikk I r Ji It li Isk I al Itarget string c r i t i c a 1non-matching pairs: 'k' --+ 'c''sk' --4 'a t" -4 'l'Figure 4: Approach 3: An example for mapping non-matching parts.nm-weight freq Swedish English1 6 ska c0.942 162 k c0.875 21 sk c0.714 5 ras d0.545 6 v w0.532 25 e a0.5 9 g aFigure 5: Approach 3: The top seven non-matchingpair mappings in the Swedish/English matchingfunction with a frequency higher than four.pings for the source string x.
Figure 5 shows theseven non-matching pairs with the highest rankingand a frequency of more than four which were com-puted from the Swedish/English list of cognates Sca-niaSVEN.The mappings reflect some typical differencesin the writing of similar words in these two lan-guages.
The relation between 'ska' and 'c' can beseen in word pairs like (asymmetriska,asymmetric)and (automatiska,automatic).
Correspondencesbetween 'k' and 'c' are common in a lot ofSwedish/English pairs, e.g.
in (korrekt,correct) and(funktion,function).
The mapping of 'sk' and 'c' ap-pears similarly to the mapping of 'ska' to 'c' but forindefinite singular forms of Swedish adjectives.
Theconnection between 'ras' and 'd' can be found in pas-sive voice constructions, e.g.
in (rekommenderas,arerecommended).
The mapping of 'v' and 'w' is dueto the fact that the letter 'w' does not exist inSwedish in practice.
Finally, the change of vowelsis quite common.
The relation between 'e' and 'a'can be seen for example in pairs like (sida,side) and(lina,line).
Furthermore, Swedish diacritics are rep-resented by other characters in English.
The muta-tion of '~i' to 'a' can be seen for example in the pair(m~k,mark)  but as reflected in the correspondingmatching value this is not as reliable as the matchof e.g.
'k' and 'c'.The program returned 2,006 pairs with a scorehigher than 0.7 when applied to the Swedish/Englishword list which were obtained from parts of thePLUG corpus.
This represents a gain of about 21%217additional inks compared to the number of pairswhich were obtained by calculating the basic LCSRscores and using the same threshold of 0.7.
Even theestimation for the precision shows an improvementfrom 92.5% for LCSR extraction to 95.5% for theapproach including non-matching scores.5 Conc lus ionIn this paper three approaches were introduced withthe common goal of generating language dependentstring matching functions automatically in order toimprove the recognition of string similarity.
How-ever, the first two approaches differ from the thirdone with regard to their general principle.Both the first and the second approach producean independent s ring matching function which doesnot rely on the comparison of characters itself.Therefore, these approaches are independent fromthe character sets which are used in each language.The difference between the first and the second ap-proach concerns egmentation.
While approach 1uses a simple segmentation i to sequences of char-acters the second approach groups vowels and con-sonants into n-grams.
Because of the large variety ofpossible n-grams it is much less probable to get a hitwhen matching word pairs.
Therefore, a much lowerthreshold has to be used in approach 2 in order toobtain cognate candidates.
The problem with this isa much higher risk of finding wrong candidates es-pecially for short strings.
However, both approachesproduce results with high precision between 92% and97%.
The recall is lower than the value which canbe reached by means of LCSR scores.
Compared ata similar level of precision the first approach returnsroughly 87% and the second approach 39% as manycandidates as LCSR extraction.The third approach is based on LCS calculations.The goal is to add matching values for common on-identical characters and n-grams.
It is not so flexiblewhen applied to languages with different charactersets, but it does produce the best result in the exper-iments that were carried out with Swedish/Englishword pairs.
The basic set of cognates obtained byLCSR extraction was extended by about 21%.
Eventhe precision for the resulting list could be estimatedwith a slight improvement from 92.5% for LCSR ex-traction to 95.5% 6.
Therefore, the third approachis by far the best of the three methods if languageswith a fairly common character set are considered.Re ferencesLars Ahrenberg, Magnus Merkel, KatarinaMfihlenbock, Daniel Ridings, Anna S?gvallHein, and JSrg Tiedemann.
1998.
Par-allel corpora in LinkSping, Uppsala and6The same threshold of 0.7 was used for both approaches.GSteborg.
Project application, available athttp://stp.ling.uu.se/~corpora/plug/.Lars Borin.
1998.
Linguistics isn't always the an-swer: Word comparison in computational linguis-tics.
In Proceedings of the 11th Nordic Conferenceon Computational Linguistics NODALI98, Centerof Sprogteknologi and Department of General andApplied Linguistics, University of Copenhagen.Kenneth W. Church, William Gale, Patrick Hanks,and Donald Hindle.
1991.
Using Statistics in Lex-ical Analysis.
In Uri Zernik, editor, Lexical Ac-quistition: Using on-line resources to build a lexi-con.
Lawrence Erlbaum.Kenneth W. Church.
1993.
Char_align: A Programfor Aligning Parallel Texts at the Character Level.In Proceedings of the Workshop on Very LargeCorpora: Academic and Industrial Perspectives,A CL.
Association for Computational Linguistics.Karen Kukich.
1992.
Techniques for automaticallycorrecting words in text.
A CM Computer Surveys.I.
Dan Melamed.
1995.
Automatic Evaluationand Uniform Filter Cascades for Inducing N-best Translation Lexicons.
In Proceedings ofthe 3rd Workshop on Very Large Corpora,Boston/Massachusetts.Philip Resnik and Dan I. Melamed.
1997.
Semi-automatic aquisition of domain-specific transla-tion lexicons.
In Proceedings of the Conferenceon Applied Natural Language Processing, Wash-ington, D.C.1998.
The Scania project.http://stp.ling.uu.se/..~corpora/scania/.Michael Simard, George F. Foster, and Pierre Is-abelle.
1992.
Using Cognates to Align Sen-tences in Bilingual Corpora.
In Proceedings ofthe ~th International Conference on Theoreticaland Methodological Issues in Machine Transla-tion, Montreal/Canada.Frank Smadja, Kathleen R. McKeown, and VasileiosHatzivassiloglou.
1996.
Translation Collocationsfor Bilingual Lexicons: A Statistical Approach.Computational Linguistics, 2P(1).Graham A. Stephen.
1992.
String search.
Technicalreport, School of Electronic Engineering Science,University College of North Wales, Gwynedd.JSrg Tiedemann.
1997.
Automatical Lexicon Ex-traction from Aligned Bilingual Corpora.
Diplomathesis, Otto-von-Guericke-University, Magdeburg,Department of Computer Science.JSrg Tiedemann.
1998a.
Extraction of translationequivalents from parallel corpora.
In Proceedingsof the 11th Nordic Conference on ComputationalLinguistics NODALI98, Center for Sprogteknologiand Department of General and Applied Linguis-tics, University of Copenhagen.JSrg Tiedemann.
1998b.
Parallel corpora inLinkSping, Uppsala and GSteborg (PLUG).
work218package 1.
Technical report, Department of Lin-guistics, University of Uppsala.JSrg Tiedemann.
1999.
Uplug - a modular corpustool for parallel corpora.
In Proceedings of theSymposium on Parallel Corpora, Department ofLinguistics, Uppsala University, Sweden.R.
A. Wagner and M. J. Fischer.
1974.
Thestring-to-string correction problem.
Journal of theACM, Vol.
21(I).219
