Modeling Topic Coherence for Speech RecognitionSatosh i  Sek ineComputer  Scion(:(; \ ] )e I )a i ' tmcntNew York  Un ivers i ty715 Broadway,  7th  f loorNew York,  NY  10003, USAsek ine@cs ,  nyu .
eduAbst rac tSt, atist,ical angmtge models play a ma-jor role in current spee~(:h re.cognition sys-tems.
Most of these models have ti)-cussed on relatively local interactions be-tween words.
R(.
'(:ently, however, |her('.have been sevcr;d attempts to incorpo-rate other knowlcdg(; source.s, in par-ticular long(x-range word (tet)(;nden(:ies,in order to improve.
Sl)(.~ech r(;(:ognize.rs.We will 1)rcs(~.nt one.
such m('.t;ho(l, whichtries to autonmticatly utilize t)rolmri;icsof topic continuity.
Whim a l)asc-linc.spee.ch re.
(x)gnil;ion sysl;em gencra, l;('.s a.\[-ternativ(', hypothe.s(~s for a senl;enc( L wewill ul~ilize the word prefercn(:(~s basedon topic coherence to sele(:t tim b(;st hy~pothesis.
In our experiment, we achi(weda 0.65% imI)rovenmn|; in the wor(1 ei-ror rat(', on top of t;h(; base-lin(!
sysi;em.It corre.sponds to 10A0% (if tlm possit)leword error improvement.1 I n t roduct ionStatistical anguage models play ~ major role.
incurrent language i)rocessing applications.
Mostof these models have fbcussed on r('~lative.ly ocalinteractions betwe.en words, in t~articular, large.vocabulary sl)eech recognition systems have.
usedprimarily bi-gram and tri~grmn language mod('.ls.Recently, howev(;r, there have been several at-te.mt)t,s to incorl)orate other knowl(~dge.
SOlll'C(~,8~and in pa.rticular longer-range word (tepe.nd(mcies,in order l;o improve speech recognizers, th'.rc,'loi~ger-range d(~tienden(:ics' me,ms dependenciesextending beyoiM several words or beyond sen-l;(mce boundmies.There have be.en several al;l;eml)l;s in the lastfew years to make use of these prot)erti('~s.
Oneof them is the "cache language mode.l" (Kulm,1988) (aelinek et al, 1.991) (Kul,icc, 1989).
Thisis a dynamic language model which ul,ilizes thepartially dictated document ("cache.")
in order topredict the next word.
In essence, it is based onthe ol)se.rvation l;ll&(; ;~ wor(t whi(:h has ah'cady al)-1)care(1 in a (locum(.,nt has ;m incr(;ased i)rol)abilityof r(;at)ticaring.
Jelind?
showed tim usefuhmss ofthis method in terms of spe(;ch re.
(:ognii;ion quality.For  sllorI; (locllIll(.~II~,s~ how('.v(w~ SllCh ~)~s lieWSt)3I)crf~rl;icl(;s, th('.
mnnl)cr of words whi(;h can 1)e a(:--cunml~t(;(t fi'om tim l/rior text will be small andaccordingly the b(;nelit of |;tie niethod will gen('x-ally tie small.l~os('.nti'M proliosed t;he %rigger model" to tryto ov('.r(:om(~' this limitation (RosentbM, 1992).
lieused a large (:orpus to build a s('.t of "trigger tmirs",each of which consists of it l)a.ir of words al)t)('.ar-big in a single (to(:um(mt ot: a liirg(~ corpus.
Th(~sepairs ar('.
used as a (:omI)oncnl; in th('~ t)rot)nt)ilisti(:mo(M. If a particular word w apt)('.ars in the 1)re-ceding t('~xt of do(:mncnt, the model will 1)red|(:( a.lmightened t)rot)al)ility not just for w t)ut  also forall th(; wor(ls related to w through a trigger I/a.ir.Our apt)roa(:h can b(; briefly summarize(l asfollows.
The topic or sut)jecl; matter of ;m m-title influcn(:(;s its linguistic l)rot)eri;i(;s, su(:h asword (;hoic(~ and (:o-oc(:m'ren(:e patt(~rns; in ctl'(~ctit giv('.s rise |,o a very Sl)ccializc(l "sublmlguag(~"for th;tt topic.
We try to find the sul)languag(~to which t,h(', art|el(; 1Mongs based on the sen-tences already recognized.
At a cert;fin stag(; ofthe st)ee(:h recognition processing of an art|el('.,words  in |;hi; pr(;viotls ll|;|;(2r~rlic(?s &ro s(~.le(;i;(Rt ~)~skeywords.
Then, based on the keywords, simi-lm' arti('.h.
's are retri('.ved from a large corpus t)ya nmthod similar to that used iil information re-trieval.
They are asseml)l('~d into a subla.nguag(',"mini-cortms" for tim mti(:h',.
Then wc analyze themini-(:orlms in or(lcr to d(~tc, rminc word l)rcf(;rcn(:cwhi(:h will l)e used in analyzing the following sen-t(mcc.
The &;tails (if e, ach stet) will be describedlat(~u'.Our work is similar to I;ll~I; using trigger t)~firs.ltowever, the triggea' |);fir approach does a. v(uybroad s('~a.rch, retrieving m'ti(:h;s which have anyword in common wil;h the, 1)rior discourse'.
()llr ap-pro~,ch, in contrast, makes a Inllch lnorc  fOCllSSe(tsear(:h, taking only a small set of articles mostsimilar to the prior discourse.
This may allow usto make, sharper t)redictions in the case of well-913defined topics or sublanguages, and reduce theproblems due to homographs by searching for a(:onjunction of words.
(Rosenfeld has indicatedthat it may be t)ossible to achieve similar resultsby an enhancement to trigger pairs which usesmultiple triggers (Rosenfeht, 1992).)
In addition,our approach needs less machine power.
Thiswas one of tile major problems of Rosenfeld's ap-proach.Sekine has reported on the effectiveness of sub-language identification measured in terms of theDequency of overlapping words between an arti-cle and the extracted sublanguage corpus (Sekine,1994).
In this paper, we report on its practicalbenefits for speech recognition.2 Speech  Recogn i t ion  SystemThis research is being done in collaboration wittlSRI, which is providing the base of the com-bined speech recognition system.
(Digalakis et.al.,1995).
We use the N-best hypotheses producedby the Sill system, alon G with their acoustic andlanguage model scores.
There are two acousticscores and four language scores.
Language scoresare namely the word trigram model, two kinds ofpart of speech 5-gram model and the number oftokens.
Note that none of their language modelstake long-range dependencies into account.
Wecombine these scores with the score produced byour sublanguage (:omponent an(1 our cache inodelscore, and then select the hypothesis with the,highest combined score as the output of our sys-tem.
The system structure is shown in Figure 1.The relative weights of the eight scores are deter-mined by an optimization procedure on a train-ing data set, which was produced under the sameconditions as our evaluation data set, trot has nooverlap with tile evaluation data set.
The actualconditions will be presented later.SRI Speech ~ __~YU IRecognizer 1 N-best / hi(Ii-grain scoresCombine sco icBest hypothesisLanguag( tModels /,anguage scoreFigure 1: Structure of the system3 Sub language ComponentThe sublanguage component performs the follow-ing four steps:1.
Select keywords from previously uttered sen-tellces2.
Collect silnilar articles flom a large corlmsbased tm the keywords3.
Extract sublanguage words fl'om the similararticles4.
Compute scores of N-best hypotheses basedon tile sublanguage wor(lsA sublanguage analysis is performed separatelyfor each sentence in an artieh; (afl;er the first sen-tence).
There are several parameters in these pro~eesses, and the values of the parameters we usetlfor this experiment will be summarized at the endof each section below.
We generally tried severalparameter values and tile vahles shown in this pa-per are the best ones on our training data set;.We used a large corpus in the experiment asthe source for similar articles.
This corpus in-cludes 146,000 articles, or 76M tokens, from Jan-uary 1992 to .hfly 1995 of North American Busi-ness News which consists of Dow Jones Informa-tion Services, New York Times, Reuters NorthAmerican Business Report, Los Angeles Times,and Washington Post.
This corpus has no overlapwith the evaluation data set, which is drawn fromAugust 1995 North American Business News.Now, each step of our sublanguage componentwill be described in detail.Select KeywordsThe keywords which will be used in retrieving sim-ilar articles are selected from previously dictatedsentences.
Tile system we will describe here is anincremental adal)tation system, which uses onlythe inlbrmation the syst;em has acquired from tileprevious utterances.
St) it does not know the cor-rect transcriptions of prior sentences or any infor-mation about subsequent sentences in the article.Not all of l, he words from the prior sentencesare used as keywords for retrieving similar arti-cles.
As is the practice in information retrieval,we filtered out several types of words.
First ofall, we know that closed class words and high fre-quency words appear in most of the documents re-gardless of the topic, st) it is not useflfl to includethese as keywords.
On the other hand, very lowfrequency words soinetimes introduce noise intothe retrieval process because of their peculiarity.Only open-class words of intermediate flequeney(actually frequency from 6 to 100000 in tile corpusof 146,000 articles) are retained as keywords andused in finding the similar articlem Also, becausethe N-best sentences inevitably contain errors, weset at threshold for the appearance of words in tileN-best sentences.
Specifically, we require that a914word aptiear at least 15 tilnes ill the tilt) 20 N-besl;senten(;es (as ranke,(l /y Sl{.\['s (:ore) 1;o (luali(y asa keyword for retriewd.~ Pat"anmq,er ?
-VahmMax freqnen(:y of a keywor(l | 100000 IM in f requeneyofakeyword  (i0 /N-best for ke.ywor(1 sele(:tionMin word ai)pearanees in N-1)est i 15 ?Col lect  S imi lar  Ar t ic lesThe sex of keywords is used in order to retrievesimilar artMes a.c(:ording to the folh)wing formu-las.
Ilere Weigh,;('w) is the weight of word w,F'('w) is the, frequency of w(ird 'W in the 20 N-best senten(:es, M is the total Itumb(_!\]' ()\[' t()kensin the corpus, t/(w) is the Dequen(:y of word w inthe corpllS, AScorc(a) is artMe seorc of a.rtMe a,which indicates the similarity between the set ofkeywords an(l the artMe, and n(a) is the mmfl)erof tokens in article a.Mw,.,::jh~.
(.,,,) : 1.
'(.,,,) ?
1,,:j(~76,,~) (0mgoo,.(~(.)
-- F.,,,~,, w,@h.4,,,) lo.
( , ,( .))
(2)Fm, ch keyword is weighted by t;he l)rodu(:t of twofactors.
One (if them is the fr(;(luen(:y of the wor(tin the 20 N-1lest senten(:es, and the other is thelog of the inverse t)robability ()f the wor(l in thelarge eortms.
This is a standard metric ()f infermation retrieval based on the assumption dmt thehigher fre(luency w(irds provide less intormationabout topics (Si)arck-Jones, 1973).
Article scores(AScore) for all articles in the large (:ortms are(:oInputed as the sum of the weighted scores ofthe selecte(t keywords in each arti(:le, an(1 are n(ir-realized t)y the log of the size of each article.
Thiss(:ore in(li(:ates the similarity b(!tween the set, ofkeywords and the article.
We (:olleet the mostsimilar 50 artMes D()m the corpus.
These forlnthe.
"sift)language.
set", whi(:h will I)e use(l in ana-lyzing the f()llowing sentenc4; in the test m'ti(:le.I w l"e Iumber of artMes ill sublanguage setExt rac t  Snb language wordsSublanguage words are extra(:ted from the col-lected sublanguage artMes.
This extraction wasdone ill order to filter out tot)i(:-um'elated words.ltere, we exehtde flmetion WOl'dS, as we did for key-word selection, 1)eta,use flm(:don words are gener-ally coInIllOll throughout (ti\[thrent sul)languages.Next, to find strongly tot)ie related words, we ex-tracl;ed words which apl/ear in at least 3 (lilt (if the50 sublmlguage articles.
Also, the do(:tnnent De-quen(:y in sublanguage articles has to be at least3 times the word Dequency in the large corpus:D t/('w) /50 > 3 (3)F(w) /MItere, DF(w) is the number of do(:uments in whi(:hthe wor(l apl)ears.
We (:m~ expe(:t hat these me;h-e(Is eliminate, less topi(: relate(l words, s() dtat onlystr(mgly tot)i(: related wor(ts are extra(:ted as thesul)language words.I'al'a,~,ete,' - \[ ~ i l .~  \]Min ' lumof ( l ( /eumentswi th thew' )7 ' ( l \ [  33 lThr(!shol(1 ratio of wor(1in the set and in generalCompute  Scores  of  N -best  HypothesesFinally, we ('omput(,.
scores of the N-best hypothe-s(;s gen('.rnted l)y the speech recognizer.
'Fhe top100 N-t)(;st hypotheses (ae(:ording to SIH's score)are r(>s(:or(~(l. The sul)language score we assign t;()each word is the logarithm of the ratio of d()cu-nlent h'e(lueal(:y in the sublanguage m'ticles to theword frequen(:y of the word in tile large corpus.The larger this s(:ore of a word, tile more stronglythe word is related to the sublmlguage we foundthrough the tirior discourse,.The s(:ore \['or ea(:h sentenc(; is eal(:ulated by a(:-(:unmlating the score of 1he sele(:te(l wor(ls ill thehyt)othesis, tlere l\[Sco'rc(h) is the sut)languagescore of hypothesis h., ../oF(,.
O/so, tls'(~.o,.
(,(h) = ~ ,(,~ F~;,))X7 ~ (4)w in hThis formula can be motivated by the fact thatdie sublanguage score will be combilm(t linearlywith general anguage nlo(M s(:ores, whMl mainlyconsist of the logarithm of the tri-gram 1)robabil-ides.
The denominator of the log in Formula 4 isthe unigram probability of wor(t w. Sin(:e it is the(h!nonlinator ()f a logarithm, it; winks to reduce theeffect of the general laltgl iage model whMl may be(:;robed(led in the trigranl language mo(M score.The nmnerat()r is a pure sublanguage score and itworks to ad(l tim s(;or(~ of the sublanguage mo(Mto the ()ther s(:ores.4 Cache mode lA cache model was also used in o/lr (;xpetilll(!ilt.We (lid not use all the words in tile previous ul>teran(:e, but rather filtered out several types ofwords in order to retain only lopi(: relate(1 words.We, actually used all of the "selected keywor(ls" asexplained in the last section for our ca(:he model.Seo~'es for the words iil (:~ehe (CS,:o,',<,,,)) a,e(xmq)ut(;d in a similar way to that for sublanguagewords.
Here, N' is the number of tokens in thepreviously uttere(t N-best sentences.1,"(,,,)/:v' cs',~o.,.,..(1,.)--_.
~, l o~(  .
.
.
.  )
Is),,, i, .
.
.
.
.
I.. F (w) /M5 Exper imentThe speech recognition experiment has been con-ducted as a part of the 1995 AI1,PA continuous915speech recognition evaluation under the supervi-sion of NIST(NIST, 1996).
The conditions of theexperiment are:?
The input is read speech of unlimited vocab-ulary texts, selected from several sources ofNorth American Business (NAB) news fromthe period 1-31 August 1995?
Three non-close talking microphones are usedanonymously for each article?
All speech is recorded in a room with back-ground noise in the range of 47 to 61 dB (Aweighted)?
The test involves 20 speakers and eachspeaker eads 15 sentences which are takenin sequence from a single article?
Speaker gender iv unknownThe SRI system, which we used as the base sys-tem, produces N-bent (with N=I.00) sentences andsix kinds of scores, as they are explained before.We produce two additional scores based on thesublanguage model and the cache model.
Thetwo scores are linearly combined with SRI's sixscores.
The weights of the eight scores are deter-mined by minimizing the word error on the train-ing data set.
The training data set, has speechdata recorded under the same conditions as theevaluation data set.
The training data set con-sists of 256 sentences, 17 articles (a part of theARPA 1995 CSR "dev test" data distributed byNIST) and does not overlap the evaluation dataset.The evaluation is clone with the tuned pa-rameters of the sublanguage component and theweights of the eight scores decided by the trainingoptimization.
Then the evaluation is conductedusing 300 sentences, 20 articles, (the ARPA 1995CSR "eval test" distributed by NIST) disjointfl'om the dev test and training corpus.
The eval-uation of the sublanguage method has to be doneby comparing the word error rate (WER) of thesystem with sublanguage scores to that of the SRIsystem without sublanguage scores.Inevitably, this evaluation is affected by the per-formance of the base system.
In particular, thenumber of errors for the base system and the min-immn number of errors obtainable by choosingthe N-best hypotheses with minimmn error, areimportant.
(We will call the latter kinds of er-ror "MNE" for "minimal N-best errors".)
Thedifference of these nmnbers indicates the possibleimprovement we (:an achieve by restoring the hy-potheses using additional components.We can't expect our sublanguage model to fixall of the 375 word errors (non-MNE).
For onething, there are a lot of word errors unrelated tothe article topic, for exmnple function word re-placement ("a" replaced by "the"), or deletionor insertion of topic unrelated words (missingNum.
of error WERSRI system 1522 25.37 %MNE 1147 19.12 %Possiblehnprovement 375 6.25 %Figure 2: Word Error of the base system and MNE"over").
Also, the word errors in the first sen-tence of each article are not withii~ our means totlX.
\]6 Resu l tThe absolute improvement using the sublanguagecomponent over SRI's system is 0.65%, from25.37% to 24.72%, as shown in Table 3.
That is,the number of word errors is reduced froin 1522to 1483.
This means that 1.0.40% of the possibleimprovement was achieved (39 out; of 375).
TheSystemSRISRI+SLWEB.25.37 %24.72 %Num.
ofError15221483Improveexel.
MNE10.40%Figure 3: Word Error Rateabsolute improvement looks tiny, however, the reJ-ative improvement excluding MNE, 10.40 %, isquite impressive, becmlse there are several typesof error which can not be corrected by the sublan-guage model, as was explained before.The following is an example of the actual outtmtof the system.
(This is a relatively badly recog-nized example.)....
Example ....in recent weeks hyundai corporation andfujitsu limited announced plans formemory chip plants in oregon at projectedcosts of over one bi l l ion dollars eachin recent weeks CONTINENTAL VERSIONSUGGESTS ONLY limited announced plans forMEMBERSHIP FINANCING FOR IT HAD projectedCOST of one DAY eachin recent weeks CONTINENTAL VERSIONSUGGESTS ONLY limited announced plans formemory chip plants in WORTHINGTON PROJECTCOST of one MILLION each1Note that, in our experiment, a few errors in tat-tim sentences were corrected, because of the weightoptimization based oil the eight scores which includesall of the SRI's scores.
But it; is very minor and theseimprovements are offset by a similar number of dis-improvements caused by tile same reason.916The first sentence is the correct transeriI)tion, thesecond one is SRI's best scored hypothesis, andthe third one is the hypothesis with the highestcombined score of SRI and our models.
This sen-tence is the 15th in an article on memory chipproduction.
As you can see, a mistake in SRI's hy-pothesis, membership nstead of memory and chip,was replaced by the correct wor(ts.
Ilowever, otherparts of the sentence, like hyundai corporat ionand fuj itsu, were not amended.
V~Te lkmnd thatthis particular error is one (If the MNE, for whichthere is no ?
'orreet candidate in the N-best hy-potheses.
Another error, mi l l i on  or day insteadof b i l l i on ,  is not a MNE.
There exist some hy-potheses which have b i l l i on  at the right spot,(the 47th ean(lidate is the top candidate whichhas the word).
Our sublanguage model works toreplace word day by mi l l i on ,  but this was notthe correct word.7 D iscuss ionAlthough the actual improvement in word errorrate is relatively small, partially because of fa(:-tors we (:ould not control, of which the probleni ofMNE is the most important, the results suggestthat the sul)language technique may lie useful inimproving the si)eeeh recognition system.
One ofthe methods for increasing the t)ossibility (if im-provement is to make N (of N-best) larger, thusincluding more.
corre(:t hypotheses in the.
N-best.We tried this, becmlse SRI actually provided uswith 2000 N-best hypotheses.
However, parame-ter optimization showed us that 100 is the oi)ti-real numl)er for this parmneter.
This result canbe explained by the folh)wing statistic.
Table 4describes the nuinber of MNE as a function of Nfor the training data set; and evaluation (lata set:.Also in parentheses, the numl)er of possit)le im-proveinents for each case is shown.
Ae('or(ling toN MNE MNE(evaluation) (training)1 152250 1163 (359)100 1147 (375)200 \] 134 (388)500 1116 (406)1000 1109 (41.3)2000 1107 (415)1258991 (2(~7)960 (298)947 (311)935 (323)93() (328)929(329)Figure 4: N and Word Errorthe table, the number of MNE decreases rapidlyfor N up to 100; however, after that point, thenumber decreases only slightly.
For example, inthe ewduation data set, increasing N fl'om 500 to2000 introduces only 9 new possible word error im-provements.
We believe this small number givesour colnponent greater opt)ortunity to include er-rors rather than improvenlents.Improvements will no doubt be possible throughbetter adjustment of the parameter settings.There are parameters involved in the similaritycalculation, the size of the sublanguage set, theratio threshold, etc.
To date, we have tuned themby manual optimization using a relatively smallmnnt)er of trials and a very small training set (the20 articles for which we have N-best transcrit)-dons).
We will need to use automatic optimiza-tion methods and a substantially larger trainingset;.
Since we do not have a much larger set ofarticles with speech data, one possibility is to op-timize the systeln in terlns of perplexity using annlch larger text corpus for training, and applythe optimized parameters to the speech recogni-tion system.
With regard to the size of sublan-guagc set, a constant size may not be optimal.Sekine (Sekine, 1994) reported on an extmrimentwhich selects the size automatically by seeking theininimum ratio ()\[ the docunlent set, perple.xity to|;lie estimated t)erplexity of randomly schooled oc-ument sets of that size.
This approach can beapplit'abh'~ to our systeln.Wc may also need to reconsider the strategyfor incorporating the sublanguage component intothe speech recognition system.
For example, itmight be worthwhile to reconsider how to mix ourscore with SRI's language model score.
SRI pro-vides language model scores for each hyi)othesis,not for words.
However, we can imagine that, iftheir language score can be computed with highconfidence for a particular word, then our modelshould have.
relatively little weight.
On the otherhand, if the language model has low confidence,sublanguage should have strong weight.
In otherwords, the combination of the scores should not bedone by linear combination at the sentence level,but should be done at the word level.Also there are several things we need to re-ewduate regm:ding our sublanguage model.
()lieof thenl is the threshold method we adopt here,which introduces undesirable discontinuities intoour la.nguage model.
The method for retrievingsimilar articles may also need to be modified.
We.used a silnple technique whit:h is conunoil in in-formation retrieval research.
However, the pur~pose of our system is slightly different from thatof in format ion retrieval systems.
So, one fllturedirection is to look for a more suitable retrievalmethod for our purpose.in closing, we wish to mention that the sub-language technique we have described is a gen-eral approach to enhancing a statistical languagemodel, and is therefore applicable to tasks be-sides speech recognition, such as optical (:haracterrecognition and machine translation.
For exam-lflC, if a machine translation system uses a statis-tical model for target language word choice, our917approach could improve word choice by selectingmore topic related words.8 AcknowledgmentThe work reported here was supported by the Ad-vanced Research Projects Agency under contractDABT63-93-C-0058 from the Department of theArmy.
We would like to thank the collaborationpartners at SRI, in particular Mr.Ananth Sankarand Mr.Victor S. Abrash.
Also we thank for use-ful discussions and suggestions Prof. Grishmanand Slava Katz.ReferencesSatoshi Sekine, John Sterling and Ralph Grish-mail 1995 NYU/BBN 1994 CSR evaluationIn Proceedings of the ARPA Spoken LanguageSystems Technology Worksh, opR Kuhn.
1988 Speech Recognition and the Fre-quency of Recently Used Words: A ModifiedMarkov Model for Natural Language In Pro-ceedings o:f I2th International Conference onComputational LinguisticF Jelinek, B Merialdo, S Roukos, and M Strauss.1991 A Dynamic Language Model for SpeechRecognition In Proceedings of Speech and Nat-ural Language DARPA WorkshopJ Kupiec.
1989 Probabilistic Models of Short andLong Distance Word Dependencies in RunningText In Proceedings of Speech and Natural Lan-guage DARPA WorkshopRonald Rosenfeld and Xuedong Huang.
1992 Im-provements in Stochastic Language ModelingIn Proceedings of DARPA Speech and NaturalLanguage WorkshopSatoshi Sekine 1994 A New Direction for Sub-language NLP In Prvcecdings of Internationalconference on New Mcthods in Language Pro-cessingK Sparck-Jones.
1973 Index Term Weighting InInformation Storage and Retrieval, Vol.9, p619-633Vassilios Digalakis, Mitch Weintraub, AnanthSankar, Horaeio Franco, Leonardo Neumeyer,and Hy Murveit 1995 Continuous Speech Dic-tation on ARPA's North Business News Domainin Proceedings of the ARPA Spoken LanguageSystems Technology Workshop, p88-93David S. Pallett et.al, to appear 1995 BenchmarkTest for the ARPA Spoken Language ProgramIn Proceedings of the ARPA Spoken LanguagcSystems Technology Workshop918
