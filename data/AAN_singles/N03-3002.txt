The Importance of Prosodic Factors in Phoneme Modeling withApplications to Speech RecognitionSarah BorysDepartment of Electrical and Computer EngineeringUniversity of Illinois at Urbana-Champaign, Urbana, IL 61901AbstractThis paper tests speech recognition usingprosody dependent allophone models.
Thelog likehoods of various prosodicallylabeled phonemes are calculated usingBaum-Welsh re-estimation.
These loglikehoods are then compared to loglikehoods of non-prosodically labeledphonemes.
Based on the comparison ofthese log likehoods, it can be concluded thatmodeling all prosodic information directlyin the vowel model leads to improvement inthe model.
Consonants, on the other hand,split naturally into three categories,strengthened, lengthened and neutral.1.
IntroductionProsody is an important factor in how humans interpretspeech.
The same word string can have differentmeanings depending on the way it is said.
Manylinguists have performed extensive studies of prosodyand of the effects of prosodic factors on spokenlanguage.In his dissertation, Cho (2001) investigateshow phonetic features are conditioned by prosodicfactors by examining pre-boundary, post-boundary, andaccented syllables.
Cho reports that boundary inducedarticulatory strengthening occurs in phrase final vowelpositions and phrase initial consonant positions.
Phraseinitial vowels are also more susceptible to coarticulationthan phrase final vowels.
Cho also hypothesizes thataccented syllables are characterized primarily bysonority expansion.
An accented vowel is usually notaffected by coarticulation with a neighboring vowel.Strengthening effects caused by boundaries and accentscannot be considered the same and Cho discussesseveral differences between boundary and accentstrengthening effects.In a study performed by Edwards et al(1991),the effect of final lengthening at prosodic boundarieswas examined by studying articulator movementpatterns.
It was found that decreasing intragesturalstiffness slows down the syllable, affecting the tempo ofthe spoken word, causing the syllable to be lengthened.The changing of intergestural phrasing also affects thesyllable duration by decreasing the overlap of a vowelgesture with a consonant gesture.
This increases theduration of accented syllables comparatively tounaccented syllables and causes the accented syllable tobe strengthened.De Jong (1994) investigated the supraglottalcorrelates of linguistic prominence in English.
De Jongsuggests that stress involves a localized shift towardhyperarticulated speech.
An increase in the duration inthe closure and in the aspiration of initial voiceless stopswas observed along with an increase in duration ofprevoicing in initial voiced stops in stressed syllables.Fougeron and Keating (1997) report that on theedges of prosodic phrase boundaries, final vowels andinitial consonants have less reduced lingual articulation.The differences in articulation were manifested in thelinguopalatal contact of boundary consonants andvowels.
The linguopalatal contact of both consonantsand vowels relates directly to the type and size of phraseboundary.
Boundary type and size also appear to effectthe acoustic duration of post-boundary consonants.Wightman et al(1992) report that there issegmental lengthening in the rhyme of a syllable thatdirectly precedes a phrase boundary.
Wightmanexamines the effect of duration and pause on boundarywords and shows that speaking rate effects thedistribution of phoneme duration.
The lengtheningeffects of pre-boundary syllables can be used todistinguish several different types of phrase boundaries.These results show that prosody can causevariations not just in pitch, but also in the articulation ofphonetic contrasts in different phonemes.
Thesevariations can be modeled as a part of the phonemedefinition in an automatic speech recognition (ASR)system.
However, the question is whether or notmodeling prosodic factors with phonemes would lead toimprovements in the quality of the phoneme model andthus lead to improvements in both the correctness andaccuracy in an ASR system.Most modern speech recognizers function bybreaking words up into mathematical features.
Therecognizer then determines the most likely occurring setEdmonton, May-June 2003Student Research Workshop , pp.
7-12Proceedings of HLT-NAACL 2003Consonants Vowelsb ch ddh f ghh jh kl m np r ssh t vw y zaa aeah aoaw axay ehel erey ihiy owoy uhuwFigure 1.
This figure contains a chart of the 38different non-prosodically distinguished phonemes usedfor experimentation.of phonemes by comparing these extracted features withits own phoneme models.
Phonemes are usuallymodeled using hidden Markov Models (HMMs).
Oncethe recognizer has identified a set of the most likelyoccurring phonemes, it then uses a dictionary to match aword or group of words to that set.Prosody can be incorporated into the phonememodel by allowing two different HMMs to represent asingle phoneme.
One HMM would need to representthe prosody independent version of the phoneme whilethe other would represent the phoneme in some prosodiccontext.
This could allow the recognizer to do thingssuch as distinguish between accented and unaccentedphonemes or distinguish between boundary and non-boundary phonemes.
Allowing the recognizer to makesuch a distinction may reduce the confusability ofcertain phoneme groups, which in turn could allow forincreased recognition rates.The goal of this research is to not onlydetermine if the inclusion of prosody in the phonememodel causes improvement in the model, but also todetermine which prosodic factors to model and the bestway to model them.
This will be accomplished by firstsplitting phonemes into different prosodically varyinggroups and then by comparing the log probability of theoccurrence of each phoneme in those different groups.Because prosody causes noticeable variations in speech,a phoneme model that includes prosodic factors shoulddiffer from models of the same phoneme that do not.This difference will prove to be significant enough toshow that prosodic factors should be taken into accountfor a more accurate phoneme model.2.
The DatabaseBoston University?s Radio News Corpus (1995) wasused for all experiments.
The speakers from this corpusthat were analyzed were F1A, F2B, and M2B.
Theusable data from these three speakers consisted of 259phn       :  phrase medialphn!
:  phrase medial, accentedphnB4   :  phrase final, unaccentedphnB4!
:  phrase final, accentedB4phn   :  phrase initial, unaccentedB4phn!
:  phrase initial, accentedFigure 2.
The different prosodic labels.
?Phn?represents some generic phoneme.wav files containing 18270 words.
All the wav filesthat were used were accompanied by two types ofprosodic transcription files, .brk and .ton files.The corpus was labeled according to the ToBIstandard.
Silverman et al(1992) explain the labelingsystem in detail.
It will not be described in this paper.The .brk files specify a ToBI  break index (0-4)for every spoken word in the associated wav file.
Forthe experiments, the only boundary distinguished wasthe intonational phrase boundary (ToBI index 4).
Allother boundary types (indices 0-3) were groupedtogether.
There were 3855 intonational phraseboundaries in the data set.The .ton files label the times in which anaccented vowel occurs.
The most abundant accent labelwas H* which occurs in a ratio of about 10 H* for everysingle L*.
Other accent types do occur, but mostinclude H* in bitonal accent.3.
Prosodic AnnotationThe set of 38 different phonemes, shown in figure 1,were used in the experiments.3.1 Allophone ModelingRecognition experiments were preformed for fourdifferent allophone sets:?
Tied?
Accent?
Boundary?
UntiedThe Tied set contained no prosodically labeleddata.The Accent set contained monophones that weresplit into two groups, accented and unaccented.Phonemes were not distinguished on the basis of phraseposition.Tied Accent Boundary UntiedAllCons.AllCons.All Cons.
AllCons.AfterVowelAfterVowelAfterVowelAfterVowelBeforeVowelBeforeVowelBeforeVowelBeforeVowel MonophoneGroupVowels Vowels Vowels VowelsFigure 3.
The sixteen experimental conditionsThe Boundary set modeled monophones as phraseinitial, phrase medial, or phrase final.
Accentedphonemes were not distinguished from unaccentedphonemes.The Untied set distinguish phonemes by bothphrasal position and accentuation.
A monophone in thisgroup could be labeled as phrase medial, phrase medialaccented, phrase initial, phrase initial accented, phrasefinal or phrase final accented.3.2 Allophone DefinitionsFigure 2 contains the six different labels used torepresent the allophones of a single imaginary phoneme?phn.
?A phrase final phoneme was considered to beany phoneme that occurred in the nucleus or coda of thefinal syllable of a word directly preceding anintonational phrase boundary.
Phrase initial phonemes,on the other hand, were considered to be any phonemein the onset or nucleus of the initial syllable of a wordthat followed an intonational phrase boundary.
Phasemedial phonemes were considered to be any otherphoneme.An accented vowel was the lexically stressedvowel in a word containing a transcribed pitch accent.Because accented consonants are not clearly defined,three different labeled sets of accented  consonants weredeveloped:?
All Consonants?
After Vowel?
Before VowelAll Consonants considered every consonant in a syllablewith an accented vowel to also be accented.
AfterVowel considered as accented only the coda consonants.Before Vowel recognized only the onset consonants ofthe accented syllable as being accented.
Accents wereconsidered to be limited to a single syllable.Because there were three different groups ofaccented consonants and because there is only one waya vowel can be labeled as accented, vowels werebeyond b iy y aa n dbeyond!
b iy y aa!
n!
d!beyondB4 b iy y aaB4 nB4 dB4beyondB4!
b iy y aaB4!
nB4!
dB4!B4beyond B4b B4iy y aa n dB4beyond!
B4b B4iy y aa!
n!
d!Figure 4.
An example of each of the six word typesdefined with Untied allophones for the After Vowelexperimental condition.
Boundary allophones couldonly be used to define three distinct word types, Accentonly two, and Tied only one.a.0 370000 B4in370000 760000 nineteen!760000 1150000 seventy1150000 1680000 sixB41680000 2310000 B4democratic!2310000 2680000 governorb.600000 1600000 w1600000 2400000 aa!2400000 2900000 n!2900000 3800000 t3800000 4900000 axB44900000 5300000 dB4Figure 5a.
An example Untied word level transcriptionb.
An example Untied phone level transcription for theAfter Vowel accent condition.
The transcribed word is?wanted.
?separated into a fourth group of their own, entitledVowels.
The four groups along with the four differentallophone models lead to the sixteen experimentalconditions illustrated in figure 3.3.3 Dictionaries and Transcription TypesEach experimental condition required its own dictionaryand transcription.
Just as each phoneme had six distinctallophones, each word had six distinct types.
A wordcould be phrase initial, medial or final and accented orunaccented.
Each word type had its own definition.An example dictionary is shown in figure 4.Every experimental condition had both a wordlevel transcription and a phone level transcription.Figure 5 shows an example of the two different levels oftranscription files.4.
ExperimentsAll Consonants After Vowel Before Vowel VowelsMerge Separate Merge Separate Merge Separate Merge SeparatechdB4,B4ddhB4B4dhfB4B4fgB4B4gjhB4kB4B4klB4mB4B4mpB4B4psB4B4stB4vB4wzbB4bddhfghhjhjhB4klmnnB4prrB4B4rsshttB4vB4B4vwyzB4dhB4gB4jhB4kB4lB4mB4nB4pB4pB4sB4shtB4vbchddB4dhffB4gjhklmnprrB4sshtvB4yzzB4B4dB4fB4gB4kB4mB4nB4pB4sB4wzbB4bchddhfghhB4hhjhklmnprB4rsshtB4tvwyaoB4axB4ehB4eyB4owuhuhB4B4uhB4uwaaaaB4B4aaaeaeB4B4aeahahB4aoaoB4awayayB4ehehB4eyeyB4ihihB4B4ihiyiyB4B4iyowowB4oyuwuwB4Experiments were performed using the HiddenMarkov Toolkit (HTK), which is distributed by theUniversity of Cambridge (2002).
Phonemes weremodeled using a three-state HMM with no emitting startand end states.
Each emitting state consisted of threemixture Gaussians and no state skipping was allowed.4.1 Experimental ProcedureThe Radio News Corpus data was divided into 2 sets: atraining set and a test set.
The test set wasapproximately 10% of the size of the training set.
Theexperimental procedure was completed for sixteenexperimental conditions.The experimental procedure can be dividedinto two steps.
In step one, the training data was used tore-estimate the HMM definitions for each phoneme.Re-estimation was performed with the HTK tool HRest,which uses Baum-Welsh re-estimation described indetail in the HTK book available from CambridgeUniversity (2002).
HMM parameters were re-estimateduntil either the log likehood converged or HRest hadperformed 100 iterations of the re-estimation algorithm.In the second step of the experiments, HRestwas used to perform a single iteration of the re-estimation algorithm on the test data using the HMMdefinitions that were updated from the re-estimation ofthe training set.
During re-estimation, the log likehoodsof each phoneme were output and saved for latercomparisons.4.2 Post ProcessingOnce all the log likehoods had been recorded, theUntied allophone sets were used as a basis to determineif the considered monophones were better modeled asprosody independent or prosody dependent.
Todetermine the best modeling strategy for a particularmonophone, six different weighted averages (WA?s)were calculated from the Untied log likehoods andcompared to the computed log likehoods of theBoundary, Accent and Tied models.Table 1.
The results ofexperiments for the Accentedallophone sets.
The "Merge"column lists phonemes withWA ?
LL.
The "Separate"column indicates phonemeswhere WA < LL.
Due to therelatively small size of thedata set, several phonemesare missing from the table.a.Initial Medial FinalAccented 1  3Unaccented  2b.Initial Medial FinalAccented 1 2 3Unaccented 4 5 6Figure 6a.
The proposed modeling of consonants.1 = Strengthened, 2 = Neutral, 3 = Lengthenedb.
The proposed modeling of Vowels.
Numbers 1-6indicate six different distinguishable prosodic typesThe following three formulas were used to calculate theWA?s of the Untied set for comparison with theBoundary set computed value:WAPM = LphnWphn + L phn!Wphn!WAPI = LB4phnWB4phn + LB4phn!WB4phn!WAPF = L phnB4WphnB4 + LphnB4!WphnB4!where PM, PI, and PF stand for phrase medial, initialand final, respectively.
Lx represents the computed loglikehood of the allophone label x in the Untiedallophone set, and Wx represents the frequency of that x.Wx, where x is representative of any of the sixtypes of prosodically labeled monophones, is computedby the following formula:Wx = numx / TOTALwhere numx represents the number of examples of thetoken x, and TOTAL is the sum of all the differentphoneme tokens being taken into account for thecomputation of WA of some set of phonemes.The two formulas used in calculating the WA?sfor comparison with the Accent allophone set are asfollows:WAU = LphnWphn + LB4phnWB4phn + LphnB4WphnB4WAA = Lphn!Wphn!
+ LB4phn!WB4phn!
+ LphnB4!WphnB4!where WAU and WAA are the weighted averages of loglikehoods for the accented and unaccented tokensrespectively.The WA compared to the Tied set wascomputed as follows:WAT = Lphn!Wphn!
+ LB4phn!WB4phn!
+ LphnB4!WphnB4!
+LphnWphn + LB4phnWB4phn + LphnB4WphnB4where WAT is the weighted average of all of thephonemes in the Untied model.The weighted averages were then compared tothe log likehoods using the following algorithm:if (WA < LL), then split using prosodic labelsif (WA ?
LL), then do not split using prosodic labelsLL is the log likehood computed using HRest.5.
ResultsFor each prosodic variable (phrasal position or accent),tables were constructed listing the preferred tying ofphonemes based on the log likehood results.
Table 1,for example, lists all phonemes that should be tied onthe basis of accent and those that should not.
Similartables exist for phrasal position and for the combinationof both  accent and phrasal position.
Examples ofcertain phonemes are not present due to the relativelysmall size of the data set.Experimental results varied greatly betweenconsonants and vowels.
For consonants, there appearedto be an improvement in the model when phonemes aredistinguished by phrasal position.
Separation ofaccented and unaccented phrase initial consonantsyielded no improvement to the model for mostconsonants.
This implies that phrase initial accentedand phrase initial unaccented phonemes should bemerged into a single token.
Accented consonants arealso not benefited by positional information.
Resultsindicate that phrase initial, medial and final accentedphonemes can be merged together.
Figure 6a illustratesa proposed model for the prosodic labeling ofconsonants based on these results.For vowels, a model showed improvementwhen the phoneme was separated into phrase initial,medial and final tokens.
Vowel phoneme models alsoshowed improvement when separated by accent.
Theaccent on a vowel appears to be important regardless ofphrasal position.
These results suggest a six-waydistinction should be used when modeling vowels andthe proposed model is illustrated in figure 6b.6.
ConclusionWhile the data used for these experiments was sparsefor certain phonemes, many of the phoneme modelstested showed improvement when prosody wasincorporated directly into the HMM definition.Analysis of experimental results led to two differentproposals for the modeling of consonants and vowels.Verifying that the proposed models are indeed animprovement over standard phoneme modeling will be agoal of future work.AcknowledgementsThis work could not have been completed without thehelp and guidance of Professor Mark Hasegawa-Johnson and Professor Jennifer Cole.7.
ReferencesCho, T. 2001 Effects of Prosody on Articulation inEnglish.
Ph.D. dissertation, UCLA.De Jong, Kenneth (1995) ?The supraglottal articulationof prominence in English: Linguistic stress as localizedhyperarticulation,?
JASA, vol.97(1), pp.
491-504.Edwards, Jan.  Beckman, Mary, & Fletcher, Janet.
1991?The articulatory kinematics of final lengthening,?JASA 89(1), pp.
369-382.Fougeron, P. & Keating, P. 1997  ?Articulatorystrengthening at edges of prosodic domains,?
JASA101(6), pp.
3728-3740.Ostendorf, M., Price, P.J., Shattuck-Hufnagel, S.
1995.?The Boston University Radio News Corpus,?
BostonUniversity Technical Report No ECS-95-001,<http://ssli.ee.Washington.edu/papers/radionews-tech.ps>.Silverman, K., Beckman, M., Pitrelli, J., Ostendorf, M.Wighnman, C. Price, P., Pierrehumbert, J., Hirschberg,J., 1992,  ?ToBI, a standard for labeling English?ICSLP, vol.
2, pp867-870The University of Cambridge Engineering Department,2002.
?http://htk.eng.cam.ac.uk/?.Wightman, C. W., Shattuck-Hufnagel, S., Ostendorf,M., & Price, P. J.
1992.
?Segmental durations in thevicinity of prosodic phrase boundaries,?
J. Acoust.
Soc.Am., vol.
91, no.
3, pp 1707-17
