Proceedings of NAACL-HLT 2015 Student Research Workshop (SRW), pages 57?63,Denver, Colorado, June 1, 2015.c?2015 Association for Computational LinguisticsInitial Steps for Building a Lexicon of Adjectives with ScalematesBryan WilkinsonDept.
of Computer Science and Electrical EngineeringUniversity of Maryland, Baltimore County1000 Hilltop CircleBaltimore, MD 21250bryan.wilkinson@umbc.eduAbstractThis paper describes work in progress touse clustering to create a lexicon of wordsthat engage in the lexico-semantic relationshipknown as grading.
While other resources likethesauri and taxonomies exist detailing rela-tionships such as synonymy, antonymy, andhyponymy, we do not know of any thoroughresource for grading.
This work focuses onidentifying the words that may participate inthis relationship, paving the way for the cre-ation of a true grading lexicon later.1 IntroductionMany common adjectives, like small and tiny, canbe defined in terms of intensities of other adjec-tives.
These relations, known as grading, intensifi-cation, magnification and others, are hypothesizedto be one of the more important types in a lexicon(Evens, 1980).
This type of relationship has appli-cations in question answering and ontological rep-resentations (de Marneffe et al, 2010; Raskin andNirenburg, 1996).While the existence of this relationship is widelyagreed upon, the study of it has fallen far behind thatof synonymy, antonymy, and hyponymy, especiallyin the computational linguistics community.
Recentwork has brought renewed attention to this area ofresearch, but there is still no large resource of wordsthat participate in this relationship (van Miltenburg,2015; Ruppenhofer et al, 2014).The phenomenon of grading is not the sameas gradability, although there is significant overlapamong the adjectives that have it.
Gradability refersto an adjective?s ability to be combined with ad-verbs like very or be used in comparative expres-sions.
It is possible that words like lukewarm, whichare not considered gradable by most linguists, stillhave the lexico-semantic relation of grading.
Simi-larly, a word like spotted, which is gradable, and infact can be viewed on its own scale, does not expressthe relationship of grading with any other words inEnglish.There is no agreement on what types of adjectivesexpress this relationship.
Paradis and Kennedy &McNally propose two similar views that were influ-ential to this work.
Kennedy andMcNally (2005) fo-cus on the structure of scales, whether they are openat both ends (tall, short), closed at both ends (vis-ible, invisible), or a combination of the two (bent,straight and safe, dangerous).
Paradis (1997) on theother hand, defines three classes of gradable adjec-tives, limit adjectives, extreme adjectives, and scalaradjectives.
For her, dead and alive are gradable ad-jectives but of the limit variety, meaning there is adefinite boundary between the two.
Extreme andscalar adjectives, such as terrible and good respec-tively, are both conceptualized as being on a scale,although extreme adjectives share some propertieswith limit adjectives as well.
Paradis also points outthat many adjectives can easily have a scalar inter-pretation, such as someone being very Swedish.The study of grading has focused on a small num-ber of adjectives (van Tiel et al, 2014).
Many pre-vious approaches of automatically learning the rela-tion have relied on existing ontologies such asWord-Net and FrameNet to choose which words occur onscales (Sheinman et al, 2013; Ruppenhofer et al,572014).
The issues with using ontologies like theseas starting points are pointed out by Van Miltenburg(2015).
He notes that words like difficult and im-possible are not grouped together and that limitingscales to WordNet networks prevents ad-hoc scalesas introduced by Hirschenberg (1985) from beingstudied.
To this we can add our own observation thatmany times an ontology can be too broad, includingpuffy, rangy, and large-mouthed under size along-side expected senses of big, small, and others.
West-ney investigated what might be necessary for a wordto be on a scale while recent work in cognitive sci-ence has focused on the acquisition of scalar impli-catures in children (Westney, 1986; Verbuk, 2007).We demonstrate work in progress to cluster ad-jectives into those that participate in grading andthose that do not.
While our metrics do not currentlymatch the supervised solution of (HatzivassiloglouandWiebe, 2000), the lack of large amounts of train-ing data encourages us to continue to pursue the un-supervised approach.
Clustering the adjectives is acritical first step to support further research into se-mantic intensities of adjectives, which is outlined insection 2.1.1 Adverb TypesAs shown above, adverbs can play a large role inthe study of adjectives.
Many types of adverbs havebeen recognized in the literature, with many stud-ies being derived from the classification of Quirk(1985).
Many of these studies have been done withan emphasis on adverbs?
interactions with verbs.Moryzcki (2008) has noted that at least the sub-ject oriented class (deliberately, purposely, willfully,etc.)
and what he terms ?remarkably adverbs?
(as-toundingly, disappointingly, remarkably, etc.)
occurwith adjectives as well.The group of adverbs that have received the mostattention in regards to their combinations with ad-jectives has been degree adverbs.
In addition toKennedy and McNally?s use of co-occurrence withdegree adverbs to arrive at the scale structures men-tioned earlier, Paradis (1997) performed detailed re-search on this class of adverbs.
She found thatcertain adverbs combine only with certain types ofgradable adjectives.
Adverbs she terms scalar mod-ifiers (fairly, slightly, very, etc.)
combine only withscalar adjectives while maximizer adverbs like ab-rather prettyhigh 175929.0 42533.0long 141152.0 31229.0low 161944.0 22953.0odd 55147.0 3424.0short 119977.0 8251.0bad 30308.0 127592.0funny 13350.0 19563.0good 79737.0 817421.0hard 87502.0 110704.0tough 9620.0 37633.0Table 1: Co-occurrence matrix from Google syntacticngrams corpussolutely combine with extreme adjectives.This type of pattern of co-occurrence has not onlybeen observed between the classes of adjectives andadverbs but also within them.
Desaguilier (2014)showed that rather combined more often with wordslike long and high while pretty combined more oftenwith words like good and stupid, yet both are consid-ered not only scalar modifiers, but a subtype knownas moderators according to (Paradis, 1997).
This ef-fect can be seen in the co-occurrence matrix shownin Table 1.2 Related WorkWhile this is the first attempt we know of to create ageneral lexicon of adjectives that participate in grad-ing, several related studies have occurred.
We firstdiscuss work on defining gradable and non-gradableadjectives and then discuss several recent works onautomatically ordering adjectives.Using the intuition that gradability is a good in-dicator of subjectivity Hatzivassiloglou and Wiebe(2000) use the co-occurrence of adjectives with ad-verbs as well as a word?s ability to be inflected forgradability in a classification task.
They classifiedall adjectives that occurred more than 300 times inthe 1987 WSJ corpus as gradable or non-gradable,for a total of 496 adjectives.
When counting the co-occurrence with adverbs, they used only two fea-tures, the number of times an adjective occurredwith any of the degree modifiers from a manuallycreated list of 73, and the number of times it oc-curred with any other type of adverb.
The classifier58was trained on 100 randomly selected subsets of 300adjectives and tested on randomly selected subsetsof 100 adjectives.Since Hatzivassiloglou and Wiebe was published,a great number of corpora have been produced.
Oneissue we now face is that the class of degree adverbsis generally agreed to be a closed class in English,while other adverbs are not.
This means we can rea-sonably expect the number of non-modifier adverbswould dominate the other features in an unsuper-vised situation.
Additionally, while the degree ad-verb class is considered closed, we have not founda comprehensive list of all of them, leading to fur-ther reservations about simply counting adverbs asdegree modifying and non degree modifying basedon a list.Several works have looked at automatically order-ing a group of adjectives by intensity given that theyoccur on the same scale.
Van Miltenburg (van Mil-tenburg, 2015) uses patterns to find scalemates froma large corpus.
He is particularly interested in pairsof words for use in reasoning about scalar implica-tures.
The candidate pairs generated by the patternsare then validated by using various similarity mea-sures, such as LSA or being under the same attributein WordNet.
This pattern based approach has alsobeen taken by Sheinman (Sheinman et al, 2013), al-though she starts out with the words on a scale fromWordNet and uses the patterns to order the words.As pointed out by (Ruppenhofer et al, 2014), pat-tern based approaches do not have wide applicabil-ity, a fact backed up by the results of vanMiltenburg.Out of 32470 pairs identified, only 121 occur in 4 ormore of the 6 patterns used.Ruppenhoffer (2014) has also investigated the au-tomatic ordering of adjectives on a scale.
Using ad-jectives taken from FrameNet, they compare the oc-currence of adjectives with 3 ?end-of-scale?
modi-fiers and 3 ?normal?
modifiers, using (Kennedy andMcNally, 2005) as a guide.
They achieve good cor-relations to human standards on the 4 scales theychose to investigate using this method, though itshould be noted that once these co-occurrence met-rics were computed, the scale was constructed man-ually.Shivade, et al (2015) use a combination of clus-tering and patterns in their approach to orderingnot only adjectives, but adverbs as well.
To deter-mine scale membership, they cluster 256 adjectivesknown to occur on scales by their co-occurrencewith nouns.
They then match patterns of parse treesrather than at string level to derive features for order-ing.
The order is computed using Mixed Linear In-teger Programming as done in (de Melo and Bansal,2013).
Our contribution can be seen as a precursorto their pipeline, providing a list of adjectives thatare known to participate in grading to the clusteringalgorithm.3 MethodologyWhile the group of gradable adjectives and thosethat participate in grading do not entirely overlap, itis a good starting point to build a lexicon of gradedadjectives.
There are rare cases, like lukewarm, butit is not believed there are many other words thatwould be missed by this assumption.For a given set of adjectives that we wish to de-rive a lexicon from, we first build a co-occurrencematrix using the Google syntactic ngrams to selectadverbs that are dependent on adjectives (Goldbergand Orwant, 2013).
We used the arc relations in thisdataset that represent a direct dependency betweentwo words.
The adverbs were required to participatein the advmod dependency with the adjective.
Toensure a wide representation of adverbs, we use thedegree modifiers discussed by Paradis (1997), theremarkably adverbs discussed by Moryzcki (2008),the subject oriented adverbs discussed by Moryzckiand enumerated by Quirk (1985), and the viewpointand time adverbs from Quirk as our features.
Thisgives us a total of 84 features, which we call theManual feature set in Table 2.
We also produce avariation of the feature set with only five features,where the adjectives are grouped together by typeas defined above, denoted by Manual Collapsed inTable 2.
A third feature set we investigated was the1000 most frequent adverbs in the corpus, regardlessof their occurrence with adjectives, denoted by Top1000 Advs.The matrix is weighted with PPMI as imple-mented in DISSECT (Dinu et al, 2013).
We thenrun k-means(k=2) clustering to split the adjectivesinto a group of gradable adjectives and a group ofnon-gradable adjectives.As previously discussed, being gradable does not59guarantee an adjective participates in the gradinglexico-semantic relation.
As an approximation offinding only adjectives that occur on the same scaleas others, we run anomaly detection on the adjec-tives which were clustered into the gradable group.We used local outlier factor (LOF) due to its abil-ity to find anomalies locally, rather than on a globalscale, better approximating adjectives without scale-mates (Breunig et al, 2000).4 EvaluationAs Hatzivassiloglou and Wiebe did, we use theCollins COBUILD Dictionary for our evaluation(Sinclair et al, 1987).
The dictionary classifies ad-jectives as either classifying or qualitative whichcorrespond approximately to non-gradable and grad-able.
The distinction here is the narrow sense ofgradable, meaning the adjectives can be modified byonly scalar modifiers, not maximizers or approxima-tors.
This is the best resource we know of at thistime however, and it allows comparisons to earlierwork.
We follow Hatzivassiloglou and Wiebe in re-moving adjectives from the dataset that we could notreliably label as classifying or qualitative when dif-ferent senses had conflicting labels.We ran the clustering and anomaly detection onthe 500 and 1000 most common adjectives in theGoogle syntactic ngrams corpus, removing any thatwere not labeled as an adjective by COBUILD.This gives of datasets of length 427 (237 gradableand 190 non-gradable) and 838 (461 gradable and377 non-gradable) respectively.
Due to many ofthe words having conflicting senses, we ran anotherdataset consisting of only the words for which allsenses unanimously chose the same classification.The results of evaluating the clustering can beseen in Table 2.
The data set that should be com-pared to (Hatzivassiloglou and Wiebe, 2000) whoreport a precision of .9355, recall of .8224, and ac-curacy of .8797, is the 500 most frequent adjectives.While we don?t achieve as high a precision, our re-call is much higher.
Partial reasons for this couldbe that using COBUILD is a flawed choice, as it as-signs words like far to the classifying class of adjec-tives in all senses, even though it can be inflectedas farther and farthest.
The words that were la-beled by COBUILD as non-gradable but clustered asable above absolute actual additional aliveavailable average based central chief chroniccomprehensive constant contemporarycontinuous corresponding criminal currentdead dear double east entire equivalenteternal everyday extreme facial far fatalfellow few fewer free front fundamentalfuture gay giant global horizontal identicalillegal induced inevitable intermediateknown lateral left like logical natural neutralobjective occasional ongoing operationaloverall parallel particular past positivepossible potential present previous principalproper pure ready real related responsibleright same separate silent single solid specialspecific subject subsequent sufficienttemporary top total traditional ultimateunable unique universal unknown up usualvarious vertical very wholeFigure 1: Words labeled by COBUILD as non-gradable,but clustered with gradable words in our datagradable by our method from the 500 words datasetusing the 1000 most frequent adverbs are shownin figure 1.
While some of the words are true er-rors, words like dead and alive are commonly dis-cussed in linguistic literature, with many consider-ing them gradable (Kennedy and McNally, 2005).Other words that were misclustered can easily beplaced on a scale, such as silent or everyday.
Ulti-mately we are using a broader definition of gradablethan COBUILD.
Additionally it is more likely fora word not traditionally viewed as gradable to ap-pear in gradable context rather than vice-versa.
Thisleads to a high recall due to the fact that the gradableadjectives rarely appear in non-gradable contexts.The most interesting outcome is that the use ofmanual features does not provide an advantage.
Thisis promising for future work, especially for applica-tions in other languages.
Constructing manual fea-tures requires the existence of detailed descriptivegrammars for the language in question.Testing against only the words that were assignedone label in the dictionary performed the worst un-der all conditions.
This may be because the distri-bution of these terms is heavily skewed towards the60Data Set Feature Set Precision Recall F1Accuracy1000 Manual .7061 .9696 .8171 .7613Manual Collapsed .7154 .9652 .8217 .7697Top 1000 Advs .6931 .9848 .8136 .7517500 Manual .7030 .9789 .8183 7587Manual Collapsed .7285 .8945 .8030 .7564Top 1000 Advs .7005 .9873 .8196 .7587Unanimous Manual .6493 .9765 .78 .7417Manual Collapsed .6445 .9843 .7789 .7380Top 1000 Advs .6791 .9921 .8063 .7765(Hatzivassiloglou and Wiebe, 2000) Custom Features .9355 .8224 .8753 .8797Table 2: Evaluation against COBUILD classificationsless frequent words of the top 1000, rather than anyeffect from the classification itself.One group of words that is reliably identified asnot having any scalemates are demonyms like Amer-ican and Swedish.
As another heuristic on our al-gorithm, we use the list of denonymic names fromWikipedia1.
We found that 100% of these were cor-rectly excluded from the final list for all feature sets.While we have no evaluation for the effective-ness of the anomaly detection, the words with the10 highest LOF are shown in Table 3.
Of these, ableand logical are identified by COBUILD as classi-fying adjectives.
If we assume that the synonymsand antonyms given by COBOUILD could be scale-mates for these words, we find that only consistentand historic do not have scalemates in the dataset.This suggests that at least LOF is not a good esti-mate of words sharing a scale, and possibly anomalydetection in general.5 Future WorkThere are many areas for improvement.
In themethodology, we feel that there is currently toomuch manual selection of the features.
This includesboth the selection of adverbs that apply to a widerrange of adjectives as well as the ability to automat-ically group the adverbs into classes similar to thosedefined in section 2.1.While using more semantically related featuresets revealed no large improvement, we still believe1http://en.wikipedia.org/wiki/List_of_adjectival_and_demonymic_forms_for_countries_and_nationsword LOFable 34.78consistent 4.98realistic 3.42loyal 2.92better 2.57historic 2.56hungry 2.50logical 2.46attractive 2.43extensive 2.41Table 3: Top 10 Highest LOFthis could be a productive avenue of further work.One possible source of inspiration for this would bebiclustering often used in biology.
This works on theassumption that the underlying data has a checker-board pattern.
The problem with this assumption isthat this may actually separate the related adjectivesand adverbs more.
The idea of of grouping the ad-verbs and adjectives simultaneously is an attractiveone however.Once the adjectives have been placed into prelim-inary groupings, we need to determine which of thewords to not have any scalemates.
It was shownabove that LOF does not appear to be a viable so-lution.
Several promising solutions to this are stillavailable for exploration.
Hypernym identificationas performed in (Lenci and Benotto, 2012) has tradi-tionally been used on nouns to build taxonomies, butmay have some applications to adjective taxonomies61as well.
Additionally, (Kanzaki et al, 2004) haveexploited the relationship between abstract nounsand adjectives to build a hierarchy of adjectives inJapanese.Another area of improvement is the need for a bet-ter evaluation.
In addition to the issue of COBUILDusing a narrower version of gradability than us, thereis no resource to reliably check if the words pro-duced do in fact have scalemates.
Work by (van Mil-tenburg, 2015) on finding pairs of scalemates usedin scalar implicature is a possible solution but notesthat their techniques also face evaluation issues.The relationship between gradability, subjectivityand the lexical relationship we investigate in this pa-per needs to be further explored.
While we do notbelieve they are the same, they may serve as re-sources for both the creation of our lexicon as wellas evaluation.Beyond the creation of the lexicon, it will havemany potential uses once created.
For linguists, itwill provide new data on which to test theoreticalmodels of scales, scale structures, and gradability.For the NLP community, it will serve as a resourcein investigations into scalar implicature as well asthe automatic ordering of adjectives.6 ConclusionIn this paper we discuss a method to automaticallybuild a lexicon of words that appear on a scale.Our clustering step achieved F1scores between .78and .82.
While these are not as high as the thoseachieved by (Hatzivassiloglou and Wiebe, 2000),we have demonstrated that using an unsupervisedmethod comes close to a supervised one.
In addi-tion, we have pointed out many potential flaws withthe current evaluation, and provided several futuredirections on which to further improve the lexicon.ReferencesMarkus Breunig, Hans-Peter Kriegel, Raymond Ng, andJ?org Sander.
2000.
LOF: Identifying density-basedlocal outliers.
SIGMOD Rec., 29(2):93?104, May.Marie-Catherine de Marneffe, Christopher D Manning,and Christopher Potts.
2010.
Was it good?
it wasprovocative.
learning the meaning of scalar adjectives.In Proceedings of the 48th Annual Meeting of the Asso-ciation for Computational Linguistics, pages 167?176.Association for Computational Linguistics.Gerard de Melo and Mohit Bansal.
2013.
Good, great,excellent: Global inference of semantic intensities.Transactions of the Association for ComputationalLinguistics, 1:279?290.Guillaume Desagulier.
2014.
Visualizing distances ina set of near-synonyms.
Corpus Methods for Seman-tics: Quantitative studies in polysemy and synonymy,43:145.Georgiana Dinu, Nghia The Pham, and Marco Baroni.2013.
Dissect: Distributional semantics compositiontoolkit.
In Proceedings of the System Demonstrationsof ACL 2013 (51st Annual Meeting of the Associationfor Computational Linguistics), East Stroudsburg PA.Association for Computational Linguistics.Martha W Evens.
1980.
Lexical-semantic relations : acomparative survey.
Linguistic Research, Carbondale[Ill.].Yoav Goldberg and Jon Orwant.
2013.
A dataset ofsyntactic-ngrams over time from a very large corpusof english books.
In Second Joint Conference on Lexi-cal and Computational Semantics (* SEM), volume 1,pages 241?247.Vasileios Hatzivassiloglou and Janyce Wiebe.
2000.
Ef-fects of adjective orientation and gradability on sen-tence subjectivity.
In Proceedings of the 18th Confer-ence on Computational Linguistics, volume 1 of COL-ING ?00, pages 299?305, Stroudsburg, PA, USA.
As-sociation for Computational Linguistics.Julia Hirschberg.
1985.
A theory of scalar implicature.Ph.D.
thesis, University of Pennsylvania.Kyoko Kanzaki, Eiko Yamamoto, Hitoshi Isahara, andQing Ma.
2004.
Construction of an objective hierar-chy of abstract concepts via directional similarity.
InProceedings of the 20th international conference onComputational Linguistics, page 1147.
Association forComputational Linguistics.Chris Kennedy and Louise McNally.
2005.
Scale struc-ture, degree modification, and the semantics of grad-able predicates.
Language, 81(2):345?381.Alessandro Lenci and Giulia Benotto.
2012.
Iden-tifying hypernyms in distributional semantic spaces.In Proceedings of First Joint Conference on Lexicaland Computational Semantics (*SEM), pages 75?79,Stroudsburg, PA, USA.
Association for ComputationalLinguistics.Marcin Morzycki.
2008.
Adverbial modification in AP:Evaluatives and a little beyond.
In Johannes D?ollingand Tatjana Heyde-Zybatow, editors, Event Structuresin Linguistic Form and Interpretation, pages 103?126.Walter de Gruyter, Berlin.Carita Paradis.
1997.
Degree modifiers of adjectives inspoken British English, volume 92 of Lund studies inEnglish.
Lund University Press.62Randolph Quirk, Sidney Greenbaum, Geoffrey Leech,and Jan Svartvik.
1985.
A Comprehensive Grammarof the English Language (General Grammar).
Long-man, 2nd revised edition edition.Victor Raskin and Sergei Nirenburg.
1996.
Adjecti-val modification in text meaning representation.
InProceedings of the 16th conference on ComputationalLinguistics, volume 2, pages 842?847.
Association forComputational Linguistics.Josef Ruppenhofer, Michael Wiegand, and Jasper Bran-des.
2014.
Comparing methods for deriving intensityscores for adjectives.
In Proceedings of the 14th Con-ference of the European Chapter of the Association forComputational Linguistics, pages 117?122.
Associa-tion for Computational Linguistics.Vera Sheinman, Christiane Fellbaum, Isaac Julien, Pe-ter Schulam, and Takenobu Tokunaga.
2013.
Large,huge or gigantic?
identifying and encoding intensityrelations among adjectives in WordNet.
Language Re-sources and Evaluation, 47(3):797?816, 1 September.Chaitanya Shivade, Marie-Catherine de Marneffe, EricFolser-Lussier, and Albert Lai.
2015.
Corpus-baseddiscovery of semantic intensity scales.
In In Proceed-ings of NAACL-HTL 2015, Denver, CO. Associationfor Computational Linguistics.John Sinclair, Patrick Hanks, Gwyneth Fox, RosamundMoon, Penny Stock, et al 1987.
Collins COBUILDEnglish language dictionary.
Collins London.Emiel van Miltenburg.
2015.
Detecting and orderingadjectival scalemates.
In MAPLEX, Yamagata, Japan.Bob van Tiel, Emiel van Miltenburg, Natalia Zevakhina,and Bart Geurts.
2014.
Scalar diversity.
Journal ofSemantics, 23 December.Anna Verbuk.
2007.
Acquisition of scalar implicatures.Ph.D.
thesis, University of Massachusetts Amherst.Paul Westney.
1986.
Notes on scales.
Lingua,69(4):333?354, August.63
