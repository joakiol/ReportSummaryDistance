Proceedings of the ACL-08: HLT Demo Session (Companion Volume), pages 5?8,Columbus, June 2008. c?2008 Association for Computational LinguisticsGenerating research websites using summarisation techniquesAdvaith Siddharthan & Ann CopestakeNatural Language and Information Processing GroupComputer Laboratory, University of Cambridge{as372,aac10}@cl.cam.ac.ukAbstractWe describe an application that generates webpages for research institutions by summarisingterms extracted from individual researchers?publication titles.
Our online demo covers allresearchers and research groups in the Com-puter Laboratory, University of Cambridge.We also present a novel visualisation interfacefor browsing collaborations.1 IntroductionMany research organisations organise their websitesas a tree (e.g., department pages ?
research grouppages ?
researcher pages).
Individual researcherstake responsibility for maintaining their own webpages and, in addition, researchers are organisedinto research groups that also maintain a web page.In this framework, information easily gets outdated,and publications lists generally stay more up-to-datethan research summaries.
Also, as individuals main-tain their own web pages, connections between re-searchers in the organisation are often hard to find;a surfer then needs to move up and down the treehierarchy to browse the profiles of different peo-ple.
Browsing is also diffcult because individualweb pages are organised differently, since standard-ised stylesheets are often considered inappropriatefor diverse organisations.Research summary pages using stylesheets canoffer alternative methods of information access andbrowsing, aiding navigation and providing differentviews for different user needs, but these are time-consuming to create and maintain by hand.
We areexploring the idea of automatically generated andupdated web pages that accurately reflect the re-search interests being pursued within a research in-stitution.
We take as input existing personal pagesfrom the Computer Laboratory, University of Cam-bridge, that contain publication lists in html.
Inour automatically generated pages, content (a re-search summary) is extracted from publication ti-tles, and hence stays up-to-date provided individ-ual researchers maintain their publication lists.
Notethat publication information is increasingly avail-able through other sources, such as Google Scholar.We aim to format information in a way that facil-itates browsing; a screen shot is shown in Figure 1for the researcher Frank Stajano, who is a memberof the Security and DTG research groups.
The leftof the page contains links to researchers of the sameresearch groups and the middle contains a researchprofile in the form of lists of key phrases presentedin five year intervals (by publication date).
In addi-tion, the right of the page contains a list of recom-mendations: other researchers with similar researchinterests.
Web pages for research groups are createdby summarising the research profiles of individualmembers.
In addition, we present a novel interactivevisualisation that we have developed for displayingcollaborations with the rest of the world.In this paper we describe our methodology foridentifying terms, clustering them and then creatingresearch summaries (?2) and a generative sum-mariser of collaborations (?4) that plugs into a novelvisualisation (?3).
An online demo is available at:http://www.cl.cam.ac.uk/research/nl/webpage-demo/NLIP.html2 Summarising research outputOur program starts with a list of publications ex-tracted from researcher web pages; for example:?
S. Teufel.
2007.
An Overview of evaluation meth-ods in TREC Ad-hoc Information Retrieval and TRECQuestion Answering.
In Evaluation of Text and SpeechSystems.
L. Dybkjaer, H. Hemsen, W. Minker (Eds.
)Springer, Dordrecht (The Netherlands).5From each publication entry such as that above,the program extracts author names, title and year ofpublication.
This is the only information used.
Wedo not use the full paper, as pdfs are not available forall papers in publication pages (due to copyright andother issues).
The titles are then parsed using theRASP parser (Briscoe and Carroll, 2002) and key-phrases are extracted by pattern matching.
From thepublication entry above, the extracted title:?An overview of evaluation methods in TREC ad-hocinformation retrieval and TREC question answering?produces five key-phrases:?evaluation methods?, ?evaluation methods in TRECad-hoc information retrieval?, ?TREC ad-hoc infor-mation retrieval?, ?TREC question answering?, ?infor-mation retrieval?Figure 1: Screenshot: researcher web page.http://www.cl.cam.ac.uk/research/nl/webpage-demo/Frank Stajano.htmlFigure 2: Screenshot: research group web page.http://www.cl.cam.ac.uk/research/nl/webpage-demo/DTG.html2.1 Individual researcher summariesTo create a web page for an individual researcher,the key-phrases extracted from all the paper titlesauthored by that researcher are clustered togetherbased on similarity - an example cluster is shownbelow (from Karen Sparck Jones?
profile):?automatic classification for information retrieval?,?intelligent automatic information retrieval?, ?infor-mation retrieval test collections?, ?information re-trieval system?, ?automatic classification?, ?intelligentretrieval?, ?information retrieval?, ?information sci-ence?, ?test collections?, ?mail retrieval?, ?trec ad-hocinformation retrieval?A representative phrase (most similar to others inthe cluster) is selected from each cluster (?informa-tion retrieval?
from the above) and this phrase islinked with all the publication dates for papers theterms in the cluster come from.
These extracted key-phrases are enumerated as lists in five year intervals;for example (from Karen Sparck Jones?
profile):1990?1994: ?information retrieval?
; ?document re-trieval?
; ?video mail retrieval?
; ?automatic summari-sation?
; ?belief revision?
; ?discourse structure?
; ?cam-bridge/olivetti retrieval system?
; ?system architec-ture?
; ?agent interaction?
; ?better NLP system evalua-tion?
; ?early classification work?
; ?text retrieval?
; ?dis-course modelling?...
;2.2 Recommendations (related people)Recommendations for related people are generatedby comparing the terms extracted between 2000 and2008 for each researcher in the Computer Labora-tory.
The (at most) seven most similar researchersare shown in tabular form along with a list of termsfrom their profiles that are relevant to the researcherbeing viewed.
These term lists inform the user as towhy they might find the related people relevant.2.3 Research Group PagesGroup pages are produced by summarising the pagesof members of the group.
Terms from individualresearch profiles are clustered according to who isworking on them (gleaned from the author lists ofthe the associated paper title).
The group page is pre-sented as a list of clusters.
This presentation showshow group members collaborate, and for each termshows the relevant researchers, making navigation6easier.
Two clusters for the Graphics and Interaction(Rainbow) Group are show below to illustrate:?histogram warping?
; ?non-uniform b-spline subdi-vision?
; ?stylised rendering?
; ?multiresolution im-age representation?
; ?human behaviour?
; ?subdivi-sion schemes?
; ?minimising gaussian curvature vari-ation near extraordinary vertices?
; ?sampled cp sur-faces?
; ?bounded curvature variants?
: Neil Dodgson;Thomas Cashman; Ursula Augsdorfer;?text for multiprojector tiled displays?
; ?tabletop in-terface?
; ?high-resolution tabletop applications?
; ?dis-tributed tabletops?
; ?remote review meetings?
; ?rapidprototyping?
: Peter Robinson; Philip Tuddenham;3 VisualisationScalable Vector Graphics (SVG)1 is a language fordescribing two-dimensional graphics and graphicalapplications in XML.
Interactive images such asthose in Figure 3 are produced by an XSLT scriptthat transforms an input XML data file containinginformation about collaborations and latitudes andlongitudes of cities and countries into an SVG rep-resentation2 .
This can be viewed through an AdobeBrowser Plugin3.
In the map, circles indicate the lo-cations of co-authors of members of the NLIP re-search group, their size being proportional to thenumber of co-authors at that location.
The map canbe zoomed into, and at sufficient zoom, place namesare made visible.
Clicking on a location (circle) pro-vides a summary of the collaboration (the summari-sation is described in ?4), while clicking on a coun-try (oval) provides a contrywise overview such as:In the Netherlands, the NLIP Group has collabora-tors in Philips Research (Eindhoven), University ofTwente (Enschede), Vrije Universiteit (VU) (Amster-dam) and University of Nijmegen.4 Summarising collaborationsOur summarisation module slots into the visualisa-tion interface; an example is shown in Figure 4.
Theaim is to summarise the topics that members of theresearch group collaborate with the researchers in1http://www.w3.org/Graphics/SVG/2Author Affiliations and Latitudes/Longitudes are semi-automatically extracted from the internet and hand corrected.The visualisation is only available for some research groups.3http://www.adobe.com/svg/viewer/install/main.htmlFigure 3: Screenshot: Visualisation of Collaboration be-tween the NLIP Group and the rest of the worldFigure 4: Screenshot: Visualisation of Collaborations ofARG Group; zoomed into Europe and having clicked onCatonia (Italy) for a popup summaryeach location on.
The space constraints are dic-tated by the interface.
To keep the visualisationclean, we enforce a four sentence limit for the sum-maries.
There are four elements that each sentencecontains?
names of researchers in research group,names of researchers at location, terms that sum-marise the collaboration, and years of collaboration.Our summaries are produced by an iterative pro-cess of clustering and summarising.
In the first step,terms (key phrases) are extracted from all the papersthat have co-authors in the location.
Each term istagged with the year(s) of publication and the namesof researchers involved.
These terms are then clus-tered based on the similarity of words in the termsand the similarity of their authors.
Each such clus-ter contributes one sentence to the summary.
Theclustering process is pragmatic; the four sentenceper summary limit means that at most four clustersshould be formed.
This means coarser clustering(fewer and larger clusters) for locations with manycollaborations and finer-grained (more and smallerclusters) for locations with fewer collaborations.The next step is to generate a sentence from eachcluster.
In this step, the terms in a sentence clus-ter are reclustered according to their date tag.
theneach time period is realised separately within thesentence, for example:7Lawrence C Paulson collaborated with CristianoLongo and Giampaolo Bella from 1997 to 2003 on?formal verification?, ?industrial payment and non-repudiation protocol?, ?kerberos authentication sys-tem?
and ?secrecy goals?
and in 2006 on ?cardholderregistration in Set?
and ?accountability protocols?.To make the summaries more readable, lists ofconjunctions are restricted to a maximum length offour.
Terms are incorporated into the list in decreas-ing order of frequency of occurrence.
Splitting thesentence above into two time periods allows for theinclusion of more terms, without violating the re-striction on list length.
This form of sentence split-ting is also pragmatic and is performed more aggres-sively in summaries with fewer sentences, havingthe effect of making short summaries slightly longer.Another method for increasing the number of termsis by aggregating similar terms.
In the example be-low, three terms (video mail retrieval, informationretrieval and document retrieval) are aggregated intoone term.
Thus six terms have made it to the clause,while keeping to the four terms per list limit.In the mid 1990s, K Sparck Jones, S J Young andM G Brown collaborated with J T Foote on ?videomail, information and document retrieval?, ?cam-bridge/olivetti retrieval system?, ?multimedia docu-ments?
and ?broadcast news?.The four word limit is also enforced on lists ofpeople.
If there are too many people, the programrefers to them by affiliation; for example:Joe Hurd collaborated with University of Utah on?theorem proving?, ?encryption algorithms?, ?func-tional correctness proofs?
and ?Arm verification?.5 Discussion and ConclusionsOur summarisation strategy mirrors the multi-document summarisation strategy of Barzilay(2003), where sentences in the input documents areclustered according to their similarity.
Larger clus-ters represent information that is repeated more of-ten; hence the size of a cluster is indicative of im-portance.
The novelty of our application is that thisstrategy has been used at a sub-sentential level, tosummarise terms that are then used to generate sen-tences.
While there has been research on generativesummarisation, much of this has been focused onsentence extraction followed by some rewrite oper-ation (e.g., sentence shortening (Vanderwende et al,2007; Zajic et al, 2006; Conroy et al, 2004), ag-gregation (Barzilay, 2003) or reference regeneration(Siddharthan et al, 2004; Nenkova and McKeown,2003)).
In contrast, our system does not extract sen-tences at all; rather, it extracts terms from paper ti-tles and our summaries are produced by clustering,summarising, aggregating and generalising over setsof terms and people.
Our space constraints are dic-tated by by our visualisation interface, and our pro-gram employs pragmatic clustering and generalisa-tion based on the amount of information it needs tosummarise.AcknowledgementsThis work was funded by the Computer Labora-tory, University of Cambridge, and the EPSRC(EP/C010035/1 and EP/F012950/1).ReferencesR.
Barzilay.
2003.
Information Fusion for Multidoc-ument Summarization: Paraphrasing & Generation.Ph.D.
thesis, Columbia University.E.J.
Briscoe and J. Carroll.
2002.
Robust accurate statis-tical annotation of general text.
In Proceedings of the3rd International Conference on Language Resourcesand Evaluation, pages 1499?1504, Las Palmas, GranCanaria.J.M.
Conroy, J.D.
Schlesinger, J. Goldstein, and D.P.O?Leary.
2004.
Left-brain/right-brain multi-document summarization.
Proceedings of DUC 2004.A.
Nenkova and K. McKeown.
2003.
References tonamed entities: a corpus study.
Companion pro-ceedings of HLT-NAACL 2003?short papers-Volume 2,pages 70?72.A.
Siddharthan, A. Nenkova, and K. McKeown.
2004.Syntactic simplification for improving content selec-tion in multi-document summarization.
In Proceed-ings of the 20th International Conference on Compu-tational Linguistics (COLING 2004), pages 896?902,Geneva, Switzerland.L.
Vanderwende, H. Suzuki, C. Brockett, andA.
Nenkova.
2007.
Beyond SumBasic: Task-focused summarization with sentence simplificationand lexical expansion.
Information Processing andManagement, 43(6):1606?1618.D.
Zajic, B. Dorr, J. Lin, and R. Schwartz.
2006.Sentence Compression as a Component of a Multi-Document Summarization System.
Proceedings of the2006 Document Understanding Workshop, New York.8
