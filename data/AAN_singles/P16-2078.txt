Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 479?485,Berlin, Germany, August 7-12, 2016.c?2016 Association for Computational LinguisticsImproving Argument Overlap for Proposition-Based SummarisationYimai Fang and Simone TeufelUniversity of Cambridge Computer Laboratory15 JJ Thomson AvenueCambridge CB3 0FD, United Kingdom{yf261,sht25}@cam.ac.ukAbstractWe present improvements to our in-cremental proposition-based summariser,which is inspired by Kintsch and vanDijk?s (1978) text comprehension model.Argument overlap is a central concept inthis summariser.
Our new model replacesthe old overlap method based on distribu-tional similarity with one based on lex-ical chains.
We evaluate on a new cor-pus of 124 summaries of educational texts,and show that our new system outper-forms the old method and several state-of-the-art non-proposition-based summar-isers.
The experiment also verifies thatthe incremental nature of memory cyclesis beneficial in itself, by comparing it to anon-incremental algorithm using the sameunderlying information.1 IntroductionAutomatic summarisation is one of the big artifi-cial intelligence challenges in a world of informa-tion overload.
Many summarisers, mostly extract-ive, have been developed in recent years (Radevet al, 2004; Mihalcea and Tarau, 2004; Wong etal., 2008; Celikyilmaz and Hakkani-T?ur, 2011).Research is moving beyond extraction in variousdirections: One could perform text manipulationsuch as compression as a separate step after extrac-tion (Knight and Marcu, 2000; Cohn and Lapata,2008), or alternatively, one could base a summaryon an internal semantic representation such as theproposition (Lehnert, 1981; McKeown and Radev,1995).One summarisation model that allows manip-ulation of semantic structures of texts was pro-posed by Kintsch and van Dijk (1978, henceforthKvD).
It is a model of human text processing,where the text is turned into propositions andprocessed incrementally, sentence by sentence.The final summary is based on those propositionswhose semantic participants (arguments) are well-connected to others in the text and hence likely tobe remembered by a human reading the text, underthe assumption of memory limitations.Such a deep model is attractive because itprovides the theoretical possibility of perform-ing inference and generalisation over propositions,even if current NLP technology only supportsshallow versions of such manipulations.
Thisgives it a clear theoretical advantage over non-propositional extraction systems whose informa-tion units are individual words and their connec-tions, e.g.
centroids or random-walk models.We present in this paper a new KvD-basedsummariser that is word sense-aware, unlike ourearlier implementation (Fang and Teufel, 2014).
?2 explains the KvD model with respect to sum-marisation.
?3 and ?4 explain why and how weuse lexical chains to model argument overlap, aphenomenon which is central to KvD-style sum-marisation.
?6 presents experimental evidencethat our model of argument overlap is superiorto the earlier one.
Our summariser additionallybeats several extractive state-of-the-art summar-isers.
We show that this advantage does not comefrom our use of lexical chains alone, but also fromKvD?s incremental processing.Our second contribution concerns a new cor-pus of educational texts, presented in ?5.
Partof the reason why we prefer a genre other thannews is the vexingly good performance of the leadbaseline in the news genre.
Traditionally, manysummarisers struggled to beat this baseline (Linand Hovy, 2003).
We believe that the problem ispartly due to the journalistic style, which calls foran abstract-like lead.
If we want to measure thecontent selection ability of summarisers, alternat-479InputSentencesPropositionsparseattachSummaryPropositionscountSummarySentences?generate??forget??recall?ForgottenPropositions??
?Memory Cycle?
?
?
?????
????
?Figure 1: The KvD-inspired incremental summarisation model.ive data sets are needed.
Satisfyingly, we find thaton our corpus the lead baseline is surpassable byintelligent summarisers.2 The KvD ModelThe KvD model is a cognitive account of humantext comprehension.
In our KvD-inspired model(Figure 1), the summariser constructs a list of pro-positions as a meaning representation from a syn-tactic parse of the input text.
A batch of new pro-positions (?
in the figure) are processed for eachsentence.
At the beginning of a memory cycle,these new propositions are added to a coherencetree, which represents the working memory.
Theyattach to the existing propositions on the tree withwhich they have the strongest overlap in argu-ments.
At the end of a cycle, as a simulation oflimited memory, only a few important proposi-tions are carried over to the next cycle, while theothers are ?forgotten?
(represented by?).
This se-lection is based on the location of propositions inthe tree, using the so-called leading edge strategy;propositions that are on more recent edges, or thatare attached higher, are more likely to be retained.The model attempts all future attachments usingonly the propositions in working memory, and al-lows to reuse forgotten ones only if this strategyruns into problems (when a new proposition couldnot otherwise be attached).KvD suggest that the decision whether a pro-position should be included in the final summarydepends on three factors: a) the number of cycleswhere it was retained in working memory, b)whether it is a generalisation, and c) whether it isa meta-statement (or macro-proposition).For its explanatory power and simplicity, themodel has been well-received not only in the fieldsof cognitive psychology (Paivio, 1990; Lave,1988) and education (Gay et al, 1976), but alsoin the summarisation community (Moens et al,2003; Uyttendaele et al, 1998; Hahn and Reimer,1984).We presented the first computational prototypeof the model that follows the proposition-centricprocessing closely (Fang and Teufel, 2014).
Ofthe factors mentioned above, only the first is mod-elled in this summariser (called FT14).
That is, weuse the frequency of a proposition being retainedin memory as the only indicator of its summary-worthiness.
This is a simplification due to the factthat robust inference is beyond current NLP cap-ability.
Additionally, macro-propositions dependon domain-specific schema, whereas our systemaims to be domain-independent.Zhang et al (2016) presented a summar-iser based on a later cognitive model by Kintsch(1998).
Instead of modelling importance of pro-positions directly, their summariser computes theimportance of words by spreading activation cyc-lically, but extracts at proposition level.Although the summariser presented in the cur-rent paper, a newer version of FT14, is capableof sub-sentential content selection, we present itsoutput in the form of extracted sentences that con-tain the most summary-worthy propositions.
Thisis different from FT14, where we used a token-based extraction method.
A better output wouldof course be an abstract based on the selected pro-positions, but we currently do not have a languagegeneration module and can therefore evaluate onlythe content selection ability of our summariser.3 Argument OverlapThe central mechanism of the KvD model is ar-gument overlap of propositions, and it is key tosuccessful content selection.
This is because thereare often multiple propositions on the tree wherea new proposition could attach, of varying attract-iveness.
The task therefore boils down to rankingattachments, for instance by the strength of over-lap, and the position in the tree.Figure 2 is an example of competing attachment480Subtree 1:DELIVER (GIFT, in: FORM)RANDOMLY (DELIVER)of (FORM, LIGHTNING)of (FORM, FOREST FIRE)of (FORM, LAVA)BURNING (LAVA)Subtree 2:REVOLUTIONISE (DISCOVERY, FIRE-LIGHTING)of (DISCOVERY, ELEMENT)Subtree 3:BE (IRON PYRITES, COMPOUND)CONTAIN (COMPOUND, SULPHUR)New:TIP (PAPER, with: PHOSPHORUS)PAPER: FORM?PHOSPHORUS: ELEMENT?PHOSPHORUS: SULPHUR?Figure 2: Possible attachments of a new proposition.sites.
Three subtrees in the working memory areshown, containing propositions that correspond tothe text pieces 1) [fire was] a gift randomly de-livered in the form of lightning, forest fire or burn-ing lava, 2) fire-lighting was revolutionised bythe discovery of the element, and 3) iron pyrites,a compound that contains sulphur, respectively.The new proposition corresponds to the text papertipped with phosphorus.
It can attach in subtree2, because phosphorus is a kind of element; it canalso attach in subtree 3, because both phosphorusand sulphur are chemicals.The definition of argument overlap is conceptu-ally simple, namely reference of the arguments tothe same concept, which can be an entity, an event,or a class of things.
In KvD?s manual demonstra-tion of the algorithm, the resolution of textual ex-pressions to concepts relies on human intelligence.A ?perfect?
coreference resolver is arguably allwe need, but coreference as currently defined ex-cludes generics, abstract concepts, paraphrases,bridging connections (Weischedel et al, 2007) andseveral other relevant linguistic phenomena.
Thismeans an insufficient number of possible overlapsare found by current coreference systems, if nofurther information is used.
How exactly to modelargument overlap for a KvD summariser is there-fore open to exploration.We use other sources of information that ad-dresses topicality and semantic relatedness, incombination with coreference resolution.
In FT14,that source was the distributional similarity ofwords, normalised with respect to their distract-ors in context to achieve numerically comparableoverlap scores.
In this paper, we argue that us-ing the shared membership in lexical chains as theother source provides a better basis for ranking ar-gument overlap.FT14?s overlap detection runs into problems inthe situation above (Figure 2).
Under FT14?sdefinition of argument overlap as distributional se-mantic distance, the link between paper and formis as strong as the other possibilities, which leadsto the attachment of the new proposition as a childnode of the root proposition of subtree 1 due tohigher tree level.
This attachment uses the wrongsense of the polysemous word form (?form/8 ?
aprinted document with spaces in which to write?
).In our new ranking of attachment sites, lexicalchains enable us to reject the spurious attachment,as we will now explain.4 Our Lexical Chain-Based SystemIn our new model, argument overlap is computedusing lexical chains (Barzilay and Elhadad, 1997),a construct that combines the ideas of topicalityand word sense clusters.
A lexical chain is anequivalence class of expressions found in the textwhose presumed senses in context are related tothe same concept or topic.
For the example inthe last section, in our system form is correctly re-solved to sense 2, not sense 8, and as form/2and paper/1 are not members of the same lex-ical chain, the wrong attachment is prevented.Lexical chain algorithms typically use Word-Net (Miller, 1995) to provide the lexical relationsneeded, whereby each synset (synonym set) rep-resents a concept.
Hypernyms and hyponyms arerelated to the same topic, and they may be in acoreference relationship with the concept.
To alesser extent, the potential for coreference alsoholds for siblings of a concept.
WordNet relationstherefore give information about concept identityand topical relatedness, both of which are aspectsof argument overlap.We implemented Galley andMcKeown?s (2003,henceforth GM03) chaining algorithm, which im-481proves over Barzilay and Elhadad?s and Silber andMcCoy?s (2002) chain definition by introducingthe limitation of ?one sense per discourse?, i.e.
byenforcing that all occurrences of the same wordtake the same sense in one document.
Initiallydesigned to improve word sense disambiguationaccuracy, GM03?s method has been shown to im-prove summarisation quality as well (Ercan andCicekli, 2008).In GM03, the edge weight between possibleword senses of two word occurrences dependson the lexical relation and the textual distancebetween them.
Each word is disambiguated bychoosing the sense that maximises the sum ofweights of the edges leaving all its occurrences.Edges that are based on non-selected senses arethen discarded.
Once the entire text has been pro-cessed, each connected component of the graphrepresents a lexical chain.As far as nouns1are concerned, we followGM03?s edge weights, but unlike GM03, we alsoallow verbs to enter into chains.
We do this inorder to model nominalised event references, andto provide a sufficient number of possible connec-tions.
Table 1 provides the distance of relations;weights of verb and derivation relations equal tothe weights of noun relations on the same row.
In-stead of assigning an overlap value of 1 to all pairsof words in the same chain, the extent of overlap isgiven as a?e?Ede, where E is the set of edges in theshortest path between the two words in the graphof lexical relations, dethe distance of the lexicalrelation of e, and a an attenuation factor we setat 0.7.
This models the transition from conceptsameness to broader relatedness.
We found empir-ically that the introduction of verbs and the gradedoverlap value using relation distance improves theperformance of our KvD summariser.Lexical coverage of this algorithm is good:WordNet covers 98.3% of all word occurrences al-lowed into our lexical chains in the experiment in?6, excluding those POS-tagged as proper nouns.For unknown words, the system?s backoff strategyis to form overlap only if the surface strings match.The structuring of information in a memory treeand the incremental addition of information, in-cluding the concept of ?forgetting?, are key claimsof the KvD model.
But do these manipulations ac-tually add any value beyond the information con-1Following Silber and McCoy (2002), we create an addi-tional chain for each named entity, in addition to those chainsdefined by WordNet synsets.Distance Noun Verb Derivation0 synonymy1 hypernymy synonymy noun-to-verb2 sibling hypernymyTable 1: Distance of lexical relations.tained in a global network representing all connec-tions between all propositions in the text?
In sucha network without forgetting or discourse struc-ture, standard graph algorithms could be used todetermine central propositions.
This hypothesis istested in ?6.5 New Corpus of Texts and SummariesWe introduce new evaluation materials, createdfrom the reading sections of Academic Tests of theOfficial IELTS Practice Materials (British Councilet al, 2012).The IELTS is a standardised test of English pro-ficiency for non-native speakers.
The texts covervarious general topics, and resemble popular sci-ence or educational articles.
They are carefullychosen to be of the same difficulty level, andunderstandable by people of any cultural back-ground.
Unlike news text, they also presup-pose less external knowledge, such as US politics,which makes it easier to demonstrate the essenceof proposition-based summarisation.Out of all 108 texts of volumes 1?9, we ran-domly sampled 31.
We then elicited 4 summar-ies summary for each, written by 14 members ofour university, i.e., a total of 124 summaries.2Weasked the summarisers to create natural-soundingtext, keeping the length strictly to 100?
2 words.They were allowed but not encouraged to para-phrase text.6 Experiment6.1 Systems and BaselinesWe test 7 automatic summarisers against eachother on this evaluation corpus.
Our summariser(O) runs the KvD memory cycles and uses lexicalchains to determine argument overlap.
It is notdirectly comparable to FT14 due to the differencein generation method, described in ?2.
In orderto be able to compare to FT14 nevertheless, wecreated a version that uses our new sentence ex-traction module together with an argument over-2Max number of summaries per person 31, min num-ber 2.
The summaries are available for download at http://www.cl.cam.ac.uk/?sht25.482O D C M LR TR L1 .376 .349 .351 .343 .341 .343 .3412 .122 .094 .088 .092 .100 .094 .100L .345 .320 .318 .308 .314 .309 .314SU4 .154 .131 .129 .128 .132 .130 .132Table 2: ROUGE F-scores by four metrics.lap module very similar to FT14 but with an evenstronger model for semantic similarity, the cosinesimilarity of word embeddings pre-trained usingword2vec (Mikolov et al, 2013) on part of theGoogle News dataset (?
100 billion words), andwe call this system D.Another variant, C, tests the hypothesis thatthe recurrent KvD processing is not superior thansimpler network analysis.
Summariser C con-structs only one graph, where every two propos-itions are connected by an edge whose length isthe reciprocal of their argument overlap, and usesbetweenness centrality to determine propositionimportance.
We choose betweenness centrality be-cause we found it to outperform other graph al-gorithms, including closeness centrality and ei-genvector centrality.We also test against the lead baseline (L) andthree well-known lexical similarity-based singledocument summarisers: MEAD (Radev et al,2004, M), TextRank (Mihalcea and Tarau, 2004,TR), and LexRank (Erkan and Radev, 2004, LR).Because the evaluation tool we use is sensit-ive to text length, fair evaluation demands equallength of all summaries tested.
We obtain outputof exactly 100?
2 words from each summariserby iteratively requesting longer summaries, andunless this results in a sentence break within 2tokens of the 100-word limit, we cut the imme-diately longer output to exactly 100 words.6.2 ResultsFor automated evaluation, we use ROUGE (Lin,2004), which evaluates a summary by compar-ing it against several gold standard summaries.Table 2 shows our results in terms of ROUGE-1, 2, L and SU4.3The metrics are based on theco-occurrence of unigrams, bigrams, longest com-mon subsequences, and skip-bigrams (within dis-tance of 4 and including unigrams), respectively.Our summariser outperforms all other summar-isers,4and is the only summariser that beats the3The scores of L and LR are very close, but not identical.4We use the paired Wilcoxon test (two-tailed).
Differ-ences between O and each other summariser at p< 0.01.
Alllead baseline.The fact that our summariser beats D, our KvDsummariser using FT14-style distributional se-mantics for argument overlap, is clear evidencethat our method of lexical chaining provides a su-perior model of argument overlap.
On this genre,D performs indistinguishably from the other sum-marisers.
This is in line with our earlier find-ings for FT14 on DUC (Over and Liggett, 2002)news texts, where the token extraction-based sum-mariser was comparable to extractive summarisersbut was outperformed by MEAD.
In a qualitat-ive analysis, we found that a main source of er-ror in FT14?s system was that it favoured relatedbut semantically and pragmatically incompatibleterms over compatible paraphrases.
This is a side-effect of the use of co-occurrence, which relieson syntagmatic rather than paradigmatic similar-ities, and which is insensitive to word senses.
Asa result, context-unaware distributional semanticsallows too many spurious overlaps.The fact that summariser C is significantlyworse than our summariser shows that the ideaof incrementally maintaining a KvD-style struc-tured memory is effective for summarisation, des-pite the simplifications we had to make.
This nat-urally points to the direction of modelling incre-mental memory updates for summarisation, whichalso makes modelling with a recurrent neural net-work plausible in the future.The current experiment can be seen as a demon-stration of the superiority of KvD proposition-based content selection on a genre of common-sense, naturally occurring texts.
This was the caseeven with a inferior ?generation?
method, namelysentence extraction.
Reading through the propos-itions, we had the impression that they manageto capture relevant information about the text ina much shorter and more modular form than ex-tracted sentences, although this cannot be demon-strated with a surface-based methodology such asROUGE.
Content selection is of course only thefirst step of summarisation; we are currently work-ing on a grammar-based re-generation from the se-lected propositions.AcknowledgmentsThe CSC Cambridge International Scholarship forthe first author is gratefully acknowledged.differences between all summarisers other than O are insig-nificant (p> 0.05).483ReferencesRegina Barzilay and Michael Elhadad.
1997.
Usinglexical chains for text summarization.
Proceedingsof the ACL Workshop on Intelligent Scalable TextSummarization.British Council, IDP Education Australia, and Univer-sity of Cambridge Local Examinations Syndicate.2012.
Official IELTS Practice Materials Volume 1.Paperback with CD.
Klett Ernst /Schulbuch.Asli Celikyilmaz and Dilek Hakkani-T?ur.
2011.
Dis-covery of topically coherent sentences for extractivesummarization.
In Proceedings of the 49th AnnualMeeting of the Association for Computational Lin-guistics: Human Language Technologies-Volume 1,pages 491?499.
Association for Computational Lin-guistics.Trevor Cohn and Mirella Lapata.
2008.
Sentencecompression beyond word deletion.
In Proceedingsof the 22nd International Conference on Computa-tional Linguistics-Volume 1, pages 137?144.
Asso-ciation for Computational Linguistics.Gonenc Ercan and Ilyas Cicekli.
2008.
Lexical co-hesion based topic modeling for summarization.
InComputational Linguistics and Intelligent Text Pro-cessing, pages 582?592.
Springer.G?unes Erkan and Dragomir R Radev.
2004.
Lexrank:Graph-based lexical centrality as salience in textsummarization.
Journal of Artificial IntelligenceResearch, pages 457?479.Yimai Fang and Simone Teufel.
2014.
A summar-iser based on human memory limitations and lexicalcompetition.
EACL 2014, page 732.Michel Galley and Kathleen McKeown.
2003.
Im-proving Word Sense Disambiguation in LexicalChaining.
In IJCAI, pages 1486?1488.Lorraine R Gay, Geoffrey E Mills, and Peter W Air-asian.
1976.
Educational research: Competenciesfor analysis and application.
Merrill Columbus,OH.Udo Hahn and Ulrich Reimer.
1984.
Computing textconstituency: An algorithmic approach to the gener-ation of text graphs.
In Proceedings of the 7th An-nual International ACM SIGIR Conference on Re-search and Development in Information Retrieval,SIGIR ?84, pages 343?368, Swinton, UK.
BritishComputer Society.Walter Kintsch and Teun A. van Dijk.
1978.
Toward amodel of text comprehension and production.
Psy-chological review, 85(5):363?394.Walter Kintsch.
1998.
Comprehension: A paradigmfor cognition.
Cambridge university press.Kevin Knight and Daniel Marcu.
2000.
Statistics-based summarization-step one: Sentence compres-sion.
In AAAI/IAAI, pages 703?710.Jean Lave.
1988.
Cognition in practice: Mind, math-ematics and culture in everyday life.
CambridgeUniversity Press.Wendy G Lehnert.
1981.
Plot units and narrative sum-marization.
Cognitive Science, 5(4):293?331.Chin-Yew Lin and Eduard Hovy.
2003.
The poten-tial and limitations of automatic sentence extrac-tion for summarization.
In Proceedings of the HLT-NAACL 03 on Text summarization workshop-Volume5, pages 73?80.
Association for Computational Lin-guistics.Chin-Yew Lin.
2004.
ROUGE: A package for auto-matic evaluation of summaries.
In Text Summar-ization Branches Out: Proceedings of the ACL-04Workshop, pages 74?81.Kathleen McKeown and Dragomir R Radev.
1995.Generating summaries of multiple news articles.
InProceedings of the 18th annual international ACMSIGIR conference on Research and development ininformation retrieval, pages 74?82.
ACM.Rada Mihalcea and Paul Tarau.
2004.
Textrank:Bringing order into texts.
In EMNLP 2004.
Asso-ciation for Computational Linguistics.Tomas Mikolov, Kai Chen, Greg Corrado, and Jef-frey Dean.
2013.
Efficient estimation of wordrepresentations in vector space.
arXiv preprintarXiv:1301.3781.George A Miller.
1995.
WordNet: a lexical data-base for English.
Communications of the ACM,38(11):39?41.Marie-Francine Moens, Roxana Angheluta, and RikDe Busser.
2003.
Summarization of texts found onthe world wide web.
In Knowledge-Based Inform-ation Retrieval and Filtering from the Web, pages101?120.
Springer.Paul Over and W Liggett.
2002.
Introduction to duc:an intrinsic evaluation of generic news text summar-ization systems.
Proc.
DUC.
http://wwwnlpir.
nist.gov/projects/duc/guidelines/2002.
html.Allan Paivio.
1990.
Mental representations.
OxfordUniversity Press.Dragomir Radev, Timothy Allison, Sasha Blair-Goldensohn, John Blitzer, Arda Celebi, Stanko Di-mitrov, Elliott Drabek, Ali Hakim, Wai Lam, DanyuLiu, et al 2004.
MEAD ?
a platform for multidoc-ument multilingual text summarization.
In Proceed-ings of LREC.H.
Gregory Silber and Kathleen F. McCoy.
2002.
Effi-ciently Computed Lexical Chains as an IntermediateRepresentation for Automatic Text Summarization.Computational Linguistics, 28(4):487?496, Decem-ber.484Caroline Uyttendaele, Marie-Francine Moens, and JosDumortier.
1998.
Salomon: automatic abstractingof legal cases for effective access to court decisions.Artificial Intelligence and Law, 6(1):59?79.Ralph Weischedel, Sameer Pradhan, Lance Ram-shaw, Michelle Franchini, Mohammed El-bachouti,Martha Palmer, Mitchell Marcus, Ann Taylor, CraigGreenberg, Eduard Hovy, Robert Belvin, and AnnHouston.
2007.
Co-reference Guidelines for Eng-lish OntoNotes.
Technical report, Linguistic DataConsortium.Kam-Fai Wong, Mingli Wu, and Wenjie Li.
2008.Extractive summarization using supervised andsemi-supervised learning.
In Proceedings of the22nd International Conference on ComputationalLinguistics-Volume 1, pages 985?992.
Associationfor Computational Linguistics.Renxian Zhang, Wenjie Li, Naishi Liu, and DehongGao.
2016.
Coherent narrative summarization witha cognitive model.
Computer Speech & Language,35:134?160.485
