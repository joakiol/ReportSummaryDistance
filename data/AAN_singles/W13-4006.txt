Proceedings of the SIGDIAL 2013 Conference, pages 41?50,Metz, France, 22-24 August 2013. c?2013 Association for Computational LinguisticsTopic Independent Identification ofAgreement and Disagreement in Social Media DialogueAmita Misra & Marilyn A. WalkerNatural Language and Dialogue Systems LabComputer Science DepartmentUniversity of California, Santa Cruzmaw|amitamisra@soe.ucsc.eduAbstractResearch on the structure of dialogue hasbeen hampered for years because large di-alogue corpora have not been available.This has impacted the dialogue researchcommunity?s ability to develop better the-ories, as well as good off-the-shelf toolsfor dialogue processing.
Happily, an in-creasing amount of information and opin-ion exchange occur in natural dialogue inonline forums, where people share theiropinions about a vast range of topics.
Inparticular we are interested in rejectionin dialogue, also called disagreement anddenial, where the size of available dia-logue corpora, for the first time, offersan opportunity to empirically test theo-retical accounts of the expression and in-ference of rejection in dialogue.
In thispaper, we test whether topic-independentfeatures motivated by theoretical predic-tions can be used to recognize rejection inonline forums in a topic-independent way.Our results show that our theoretically mo-tivated features achieve 66% accuracy, animprovement over a unigram baseline ofan absolute 6%.1 IntroductionResearch on the structure of dialogue has beenhampered for years because large dialogue corporahave not been publicly available.
This has im-pacted the dialogue research community?s abilityto develop better theories, as well as good off-the-shelf tools for dialogue processing that account forthe richness of human dialogue.
Happily, an in-creasing amount of information and opinion ex-change occurs in natural dialogue in online fo-rums, where people can express their opinion ona vast range of topics from Should there be morestringent gun laws?
to Are school uniforms a goodidea?
(Walker et al 2012a).
For example, con-sider the dialogic exchange in Fig.
1.Post P, Response RP1: Can the government force abortion clinics to carryanti-abortion articles and papers?
Or maybe force themprovide a sonogram?
Force them to have a psychologiston staff?
Force them to have 3x3 foot posters of abortedbabies on the wall?
Seems like it makes more sense for astate to restrict something from the people rather than forcethe people to have something.
No?R1: I don?t see why this matters.
Could you please elab-orate a little more, and in that elaboration, could you ad-dress why the government may require a private companyto provide this commonly recommended medical remedy(plan b) when it does not do so with countless other com-mon medically recommended remedies?Figure 1: Disagreement from 4forums.com.
Pos-sible features in bold.In particular we are interested in the phe-nomenon of REJECTION in dialogue (Horn, 1989;Walker, 1996a), also called disagreement and de-nial.
Our data show that the amount of disagree-ment in online ideological dialogues ranges from80% to 90% across topic.
Such data provides arich resource for testing theoretical accounts of re-jection, as well as for developing computationalmodels of how to recognize rejection in dialogue.To date, rejection has received relatively little at-tention in computational models of discourse be-cause of its rareness in task-oriented, tutorial orSwitchBoard style dialogue.
Computational mod-els of argumentative discourse do not typically at-tempt to account for rejection in dialogue, focus-ing instead on monologic sources displaying legalreasoning, logical accounts of rejection, or how toproduce good arguments using natural languagegeneration (Zukerman et al 2000; Carenini andMoore, 2000; Wiley, 2005; Sadock, 1977).Moreover, the theoretical literature stronglysuggests that there should be topic-independent in-dicators of rejection.
In work on politeness the-ory, rejection is a dispreferred response, predict-ing that rejection should be associated with mark-ers of dispreferred responses such as disfluenciesand hedging (Brown and Levinson, 1987).
Workon negation specifies markers of negation and con-trast such as but or only for different types of re-jection, and work on discourse relations and their41Type Context RejectionDENIAL Pigs can fly.
No, you idiot, pigs can?t fly!
(Horn?s 29)LOGICAL CONTRADICTION Kim and Lee have been partners since1989.But Lee said they met in 1990.IMPLICIT DENIAL Julia?s daughter is a genius.
Julia doesn?t have any children.REFUSAL Come and play ball with me.
No, I don?t want to.
(Horn?s 33)IMPLICATURE REJECTION There?s a man in the garage.
There?s something in the garage.
(Walker?s 6)DENYING BELIEF TRANSFER B: Well ah he uh ... he belongs to amoney market fund now and uh theywill do that for him.
H: The moneymarket fund will invest it in govern-ment securities as part of their individ-ual retirement account ?
is that whatyou?re saying?
B: Right.H: I?m not so sure of that.
(Walker?s 31)INCONSISTENT PAST BELIEF H: Then they are remiss in not sendingit to you because that money is taxablesir.M: I know it?s taxable, but I thought theywould wait until the end of the 30 months.CITING CONTRADICTORYAUTHORITYH: No sir.... R: That?s what they told me.Figure 2: Classification and Examples of the Types of Rejections.markers suggests that DENIAL is a type of COM-PARISON relation (Horn, 1989; Groen et al 2010;Webber and Prasad, 2008).
These observations,among others, suggest a range of theoretically mo-tivated features for the classification of rejection inonline dialogue, e.g.
phrases such as I think, but, Idon?t see, and Can you.
See Fig.
1.Our aim is to test whether theoretical predic-tions and topic-independent features motivated bythem can be used to recognize rejection in onlineforums.
We generalize our topic independent fea-tures using a development set on the topic Evolu-tion.
We then test a rejection (disagreement) clas-sifier trained on Evolution on 1757 posts coveringa collection of other topics, and compare our re-sults to a ngram model trained on Evolution andtested on the same test set.
See Table 1.We first describe our corpus in Sec.
2, and thenreview previous work characterizing the theoreti-cal basis of rejection in dialogue in Sec.
3.
Sec.
4describes our method for classifying rejectionsand Sec.
5 presents our results, showing that ourtheoretically motivated rejection cues are reliableacross topic.
We show that cue words, polarity,punctuation, denial and claim features motivatedby the theoretical literature provide a significantimprovement over a 50% baseline, and that allof the theoretically motivated features combinedachieve 66% accuracy as compared to a unigramaccuracy of 60%.
We delay reviewing previouscomputational work rejection to Sec.
6 when wecan compare it with our own work.2 CorpusWe utilize the publicly available Internet Ar-gument Corpus (IAC), an annotated collec-Topic Agr DisAgr TotalEvolution 460 460 920Abortion 250 280 530Climate Change 17 10 27Communism vs. Capitalism 10 13 23Death Penalty 15 19 34Existence Of God 53 48 101Gay Marriage 173 134 307Gun Control 334 331 665HealthCare 21 37 58Marijuana Legalization 6 6 12All Topics (test set) 879 878 1757Table 1: Distribution of (Dis)Agreement by Topic.The Evolution topic is for development and train-ing.
The test set of other topics is balanced overall,but not by topic.tion of 109,553 forum posts (11,216 discussionthreads)(Walker et al 2012a).
We use theportion of the IAC containing dialogues fromhttp://4forums.com.
On 4forums, a personstarts a discussion by posting a topic or a questionin a particular category, such as society, politics,or religion.
Forum participants can then post theiropinions, choosing whether to respond directly toa previous post or to the top level topic (start anew thread).
Conversants may simply agree or dis-agree with a previous post or they may provide areasoned argument.The corpus contains posts on topics such asAbortion, Evolution, Existence of God, Gay Mar-riage and Gun control along with a range of use-ful annotations.
First, there are annotations thatcollapse different discussions into a single topicfor 14 topics.
For example, the Evolution andGun Control topics include discussions initiatedwith the range of titles in Table 2, which guaran-42First Post (P), Response (R)DisagreementsP1: No I didn?t miss it, I was hoping you?d actually put forward an argument against what I said, not what you think Isaid.
See what I actually said was the tautology.
Then make your argument.
Note Post 30 He said evolution is a tautology.I said that Darwin preferred a tautology to ?Natural Selection?
You may have mixed up who it is you?re arguing against.R1: I?m wondering.
What do we call someone who debates feverishly on scientific theories, yet admittedly does notunderstand the concepts they are arguing against?
Is it productive to debate something that you don?t understandthe concepts of when it?s a fairly involved theory based on scientific evidence?
What if you convinced someone NOTto believe in it, but you did so using falsifiable reasons, since you aren?t an expert and might not know any better?Irresponsible, is one such word, that comes to mind.P2: What in Vishnu?s name does this have ANYTHING to do with evolution vs creation??
?R2: Well, many have argued that if you don?t except a literal Genesis, you?re damned.
Perhaps not in this particularthread, but the arguments are essentially the same.
I believe that the theological implications of that position are fairgame for discussing the validity of creationism.P4: You have this backwards.
The word theory was originally a scientific word, and then it was adapted into commonspeech to mean a range of things not originally designated to that word.
Words like evolve, gravity and congruent havedifferent meanings within the realm of science than they have outside.
If you can?t appreciate the difference betweenthe definition of a word in the context of science as opposed to the context of common speech, then maybe you have nobusiness in science.R4: When it comes to all the examples that Behe had provided in both his first book, and his second book , it has beenshown to be able to evolve naturally.
That means, in principle, IC systems can evolve.
If you don?t believe so, bring forththe I.C.
system of your choice.
To say ?you don?t know all the answers?
is just the logical fallacy known as ?argumentfrom ignorance?.
Behe brings a system up that he claims is IC.
the pathway for evolution is discovered, and Behe trysanother one.
How dishonest can you get?
The concept is falsified.P5: Well, Genesis has God making all the animals ?and their kind?, and then when he?s done with that he makes humans.So I would assume that humans don?t fit into the ?kind?
schema, or perhaps are a kind unto themselves........R5: : So we can?t base our definition of ?kind?
on mere appearances?
I mean if we are going to put things intocategories and call the category ?kind?, we should do this by common appearances.
A penguin is in the same kind as ahummingbird, but is a lobster in the same kind as an oyster?
........AgreementsP6: I think its nonsense interpretation developed by people who were afraid that if they fought for guns as valiantly asthey did for free speech, they wouldn?t receive any donations.R6: I think you are entirely correct.
From the page VOR linked: There is no evidence ANYWHERE that the secondamendment is a collective right.
We have been over this multiple times, and the evidence simply does not exist, and anorganization like the ACLU should be well aware of this.P7: Correction: If one isn?t a fundementalist, literal christian, jew or muslim, then marc considers them a atheist.
He?snever going to deal with the fact that he?s quite wrong on that subject.
It?s obvious to everyone that he?s constantlyavoiding it even when asked point blank several times.
A sign of argumental failure is constant avoidance of a simplequestion.R7: Quite right.
My mistake.
Once again, quite right...P8: thats pretty neat.
Did they finish up the feeder?R8: yeah, this is clearly the best thread on these forums in probably the past year....give us some more pics length)P9: This is probably the most rational site in all of the creationist?s online arguments.
Arguments we think creationistsshould NOT useR9: Thanks, DuoMax, for this link.
How delightful to see here mention of this solid gesture, on the part of a majorcreationist organization, in the direction of intellectual integrity..... ....Each time a Christian stands in the pulpit and poursout poor argument, s/he loses ground for the faith.
Thanks again.Figure 3: Disagreements and Agreements from 4forums.com.
Theoretically motivated features are inbold.Evolution Evolution in school, Dinosaurs and Hu-man Footprints, Can Evolution & Reli-gion Coexist, Did Charles Darwin Re-cant, Shrinking Sun, Bombardier beetle,Moon Dust, Second Law of Thermody-namics, Magnetic Field, Nebraska ManGun Control Gun Control, Trigger Locks, Guns in theHome, Right to Carry, Assault Weapons,One gun a month, Gun Buy Back, Gun-Seizure Laws, Plastic Guns, Does gunownership deter crime, Second Amend-ment, Enforced Gun Control Laws?,Gun Registration, Armor piercing bul-lets, Background Checks at Gun ShowsTable 2: Discussions Mapped to the Evolution andGun Control Topics.tees variation in the focus of the discussion evenwithin topic.
The topics we use are in Table 1.Each discussion is threaded so that we can iden-tify direct responses.
Discussions may have a tree-like structure, so a post may have multiple di-rect responses.
In addition to the adjacency pairsyielded by threading, 4forums also provides aquote/response Q/R mechanism where a post mayinclude a quote of part or all of a previous post.We do not use the Q/R pairs here.The IAC also includes annotations collected viaMechanical Turk on these dialogue pairs.
Thereare 20,000 pairs from threads of 3 posts P1,P2,P3with annotations for (dis)agreement for pairs (P1,P2) and (P2, P3).
Agreement was a scalar judg-43ment on an 11 point scale [-5,5] implemented witha slider.
The annotators were also able to signaluncertainty with a CAN?T TELL option.
Each ofthe pairs was annotated by 5-7 annotators, in re-sponse to the annotation question Does the respon-dent agree or disagree with the prior post?.
Anno-tators achieved high agreement on dis(agreement)annotation with an ?
of 0.62.
We used thresholdsof 1 and -1 on the mean agreement judgment to de-termine agreement and disagreement respectively.We omitted dialogue adjacency pairs with meanannotator judgment in the (-1,1) range.
Table 1provides the distribution of topics for the 1757posts in the test set.3 Theories of Rejection in DialogueA common view of dialogue is that the conversa-tional record is part of the COMMON GROUND ofthe conversants.
As conversants A and B partici-pate in a dialogue, A and B communicate throughdialogue speech acts such as PROPOSALS, ASSER-TIONS, ACCEPTANCES and REJECTIONS.
If Aasserts a proposition ?
and B accepts A?s asser-tion, the ?
becomes a mutual belief in the com-mon ground.
If B rejects A?s assertion or proposal,the common ground remains as it was (Stalnaker,1978).
For conversants to remain coordinated(Thomason, 1990), they must monitor whethertheir utterances are accepted or rejected by theirconversational partners.Computational models of dialogue also musttrack what is in the common ground (Traum, 1994;Stent, 2002).
This would be simple if conversantsalways explicitly indicated rejection with formssuch as I reject your assertion.
However recog-nizing rejection typically relies on making infer-ences.
Horn categorizes rejections into: DENIALa straightforward negation of the other?s assertion;LOGICAL CONTRADICTION following from logi-cal inference; IMPLICIT DENIAL where B deniesa presupposition of A?s; and REFUSAL, also calledREJECTION where B refuses an offer or proposalof A?s (Horn, 1989).
See Fig.
2.
All of Horn?sforms can be identified as rejections by recogniz-ing logical inconsistency either directly from whatwas said, or via an inferential chain.However subsequent work by Walker on theHarry Gross Corpus (henceforth HGC) of advice-giving dialogues (Pollack et al 1982) demon-strated that REJECTION IMPLICATURES as seen inthe 5th row of Fig.
2, are common in natural di-alogue (Walker, 1996a).
A number of similar ex-amples can also be found in (Hirschberg, 1985).Here, the proposition realized by the response fol-lows from the original assertion as an entailmentvia existential generalization.
Thus the REJEC-TION IMPLICATURE is logically consistent withthe original assertion.Walker argues that the fact that an implicaturecan function as a rejection clearly indicates thatinference rules about what gets added to the com-mon ground must have the same logical status asimplicatures, i.e.
they must be default rules ofinference that can be defeated by context.
Shethen goes on to identify additional types of rejec-tions in HGC that rely on detecting conflicts inthe default inferences triggered by the epistemicinference rules used in speech act theory.
Walkeruses a compressed version of rules from (Perrault,1990; Appelt and Konolige, 1988), assuming thatconflicting defaults can arise between these in-ferences and implicature inferences (Hirschberg,1985).
The first rule is given in 1:(1) BELIEF TRANSFER RULE:Say(A,B,p)?
Bel (B,p)The Belief Transfer Rule states that if one agentA makes an assertion that p then by default anotheragent B will come to believe that p. The secondrule is in 2:(2) BELIEF PERSISTENCE RULE:Bel (B,p,t0)?
Bel (B,p,t1)The Belief Persistence Rule states that if anagent B believes p at time t0 then by default agentB still believes p at a later time t1.
These rules pro-vide the basis for inferring three additional typesof rejections:?
DENYING BELIEF TRANSFER: Agent B candeny the consequent of the Belief TransferRule by negatively evaluating A?s assertion orexpressing doubt as to its truth.?
INCONSISTENT PAST BELIEF: Inferring thatB?s expression of an inconsistent past beliefis a type of rejection relies on detecting con-flicting defaults with the Belief Transfer Ruleand the Belief Persistence Rule.
The two be-liefs may directly conflict, or the conflict mayarise via an inferential chain.?
CITING CONTRADICTORY AUTHORITY: In-ferring that citing a contradictory authorityis a type of rejection relies on recognizingtwo inconsistent instantiations of the BeliefTransfer rule.
For example, agent A1 as-serted p and agent A2 asserted ?p, leavingB in an inconsistent belief state caused by theconflicting defaults generated by the alternateinstantiations of the Belief Transfer Rule.44Fig.
2 provides Walker?s examples of thesenew types of rejection and Fig.
3 illustrates dis-agreements and agreements in the IAC corpus.1While we see many instances of the rejectiontypes in Fig.
2 in IAC, especially CITING CON-TRADICTORY AUTHORITY and DENYING BELIEFTRANSFER, we also find new types such as ad-hominem attacks on the other speaker as thesource of particular propositions (e.g.
R1 in Fig.
3,which would not have occurred in HGC talk showcontext.
Other cases that we have noted are adifferent type of DENYING BELIEF TRANSFER,which occurs when a previous speaker?s assertedproposition is marked by the hearer as hypotheti-cal using a conditional, e.g.
If capital punishmentis a deterrent, then .....
In future work we aim toexpand the taxonomy of rejections using IAC.4 Empirical MethodOur primary hypothesis is that certain expres-sions and phrases are reliable cues to the auto-matic identification of the speech acts of REJEC-TION and ACCEPTANCE, i.e.
(dis)agreement, in-dependently of the topic.
We assume that it willnot always be possible to get annotated data for aparticular topic, given the ever-burgeoning rangeof topics discussed online.
We use the Evolu-tion topic as our development set, and ask: given(dis)agreement annotations for only one topic, is itpossible to develop features that perform well onanother arbitrary topic?There is limited previous research on disagree-ment, thus it is an open issue what types of fea-tures might be useful.
One line of previous worksuggests that various pragmatic features mighthelp (Galley et al 2004).
Another line suggeststhat disagreement is subtype of the COMPARISON(CONTRAST) discourse relation, in the Penn Dis-course TreeBank taxonomy, suggesting that fea-tures for identifying COMPARISON, such as polar-ity and discourse cues might also be useful (Hahnet al 2006; Prasad et al 2010; Louis et al 2010).We began by selecting and manually inspecting460 agreements and 460 disagreements from theEvolution topic, and extracting their most frequentunigrams, bigrams and trigrams.
This showed thatfeatures suggested by theoretical work on rejec-tion were indeed highly frequent: our aim wasto generalize what we observed in the Evolutiondataset and then test whether the generalized fea-tures can distinguish agreements from disagree-ments.
We first observed that very few unigrams1Since participants are not generally making plans to-gether in these dialogues, we leave aside Walker?s classifi-cation of rejections of proposals.were useful for disagreements, e.g.
liar, no, don?t,while bigrams such as I don?t, How can, If I, howcould, show me seemed to be better indicators.Furthermore, trigrams such as I don?t agree, howcan you, point is that, and I do not understandare even stronger indicators of disagreement, butof course these higher order ngrams are less fre-quent and are more likely to contain topic-specificwords.
In order to provide better generalization,we generalized the ngrams that we observed, e.g.an instance such as how can you would also resultin how can we and how can they being added to thesame feature set.
We also generalized over hedgesand other categories of features on the basis of thetheoretical literature.
The total set of features wedeveloped are grouped into the sets in Table 3 dis-cussed in detail below.Feature Description ExamplesAgreement Ngrams in-dicative ofacceptingothers claim.right, yes, yeah, correct,accepted, thanks, good,agree, acknowledgeCue Words Cues as Ngramsand their LIWCCogMech gen-eralizationsoh, so, uh, yes, no, dont,cogmech, claim, i, yeah,because, well, just, and,you, you mean, i see, iCOGMECHDenial Ngrams indica-tive of denyinganother?s claimYou don?t know, Thatdoes not, I don?t think,what is, This has noth-ing, I don?t see, Youdo not, do you mean,I don?t know, we don?thave, Problem withthat, I do not, Does not,why do, But I don?t,how canHedges Unigrams,bigrams, andtrigrams thatinclude hedgeterms.Im wondering, I amwondering, whatever,somewhat, may be,possibly, anyway, itseems to me, my view,actually, my opinion,essentially, somewhat,my perspective, rather,although, really, Isuppose, perhapsDuration Sentence, word and post lengthsPolarity Means of positive and negative polarityterms.Punctuation Counts of question marks and exclamationpoints.Table 3: Feature Sets, Descriptions, and Exam-ples.
The unigrams features are our baseline case;these features are not theoretically motivated.Unigrams.
Results of previous work on stanceidentification in argumentative discourse suggestthat a unigram baseline can be difficult to beat(Thomas et al 2006; Somasundaran and Wiebe,2010).
Thus we test our theoretically moti-vated features against unfiltered unigrams and un-45igrams+bigrams as baselines.Agreement and Denial.
As described above weused Evolution to manually develop generaliza-tions of the observed unigrams, bigrams and tri-grams that were consistent with theoretical pre-dictions.
We split the indicator features into twocategories Agreement and Denial.
See Table 3.Our manual analysis suggested that agreementshave few topic independent markers.
Unigramssuch as agree correct and right were also presentin disagreements, and trigrams such as I agreebut, You may be correct however I do not agree,I don?t agree were better indicators of disagree-ment.
Our agreement markers are thus a smallcategory where we check that the keywords agree,correct and right are not preceded by a negationmarker and not followed by discourse markerssuch as but, yet, or however.
However, the denialcategory at present has more than 300 ngrams ex-tracted and generalized from the Evolution topic.Pitler et al(2009) also used ngrams consisting ofthe first and last three words for recognition of thePDTB COMPARISON relation.
Other work on thePDTB also suggests that DENIAL can be indicatedby contrast (Webber and Prasad, 2008).Cue Words.
Both psychological research on dis-course processes (Fox Tree and Schrock, 1999;Groen et al 2010) and computational work onagreement and discourse markers (Galley et al2004; Louis et al 2010) indicate that discoursemarkers are strongly associated with particularpragmatic functions such as stating a personalopinion (Asher et al 2008; Webber and Prasad,2008).
Based on manual inspection of the Evo-lution devset we selected 18 items for the CUEWORDS feature set, as in Table 3.
Examples arewell in R2 and so and but in R5.Durational Features.
Brown and Levinson?s the-ory of politeness would suggest that disagree-ments are dispreferred responses and thus that thelength of the post could indicate disagreement; itpredicts that people will elaborate more and pro-vide reasons and justifications for disagreement(Brown and Levinson, 1987).
Our durational fea-tures measure the length of the utterance in termsof characters, words and sentences.Hedges.
In Brown and Levinson?s theory of po-liteness, hedges are one of many possible strate-gies for mitigating a face-threatening act (Brownand Levinson, 1987; Lakoff, 1973).
Hedges can beused to be deliberately vague or simply to softena claim.
We see many examples of hedges in on-line dialogue, e.g.
the speaker of R2 in Fig.
3 usesthe hedges Perhaps and essentially, and I mean inR5.
Thus hedges are hypothesized to be usefulfeature for distinguishing (dis)agreement, yieldingthe hedge features in Table 3.Polarity.
Work on discourse relations in the PDTBalso suggests that differences in polarity acrossadjacent utterances might be an indicator of theCOMPARISON relation.
In addition, Horn?s classesof REJECTIONS shown in Fig.
2 all include mark-ers of negation.
Thus to capture the overall senti-ment of the post we used the MPQA subjectivitylexicon (Wiebe et al 2003; Wilson et al 2005).Each word is POS tagged and then categorized asstrongly or weakly subjective.
The positive po-larity feature is the sum of the strongly subjectivewords of positive polarity, and the negative polar-ity feature represents the sum of strongly subjec-tive words of negative polarity.Punctuation.
Another indication of DENYINGBELIEF TRANSFER rejections are the questionmarks and exclamation marks that conversants fre-quently use to express their disbelief and doubtabout another conversant?s claim.
For example,R1 and R5 in Fig.
3 have a high frequency of ques-tion marks.5 ResultsOur aim was to test how well we can distinguishagreements and disagreements in IAC using clas-sifiers trained with theoretically motivated fea-tures.
As described above, we developed our fea-tures by manual inspection of (dis)agreements in920 posts on the topic Evolution.
We do not trainon a mixture of topics for any feature set, includ-ing unigrams, because we assume that in general,new topics are always arising so there will not beannotated data for every topic.
We evaluate theperformance of all types of features on classify-ing (dis)agreements on other topics combined.
Wedo not report per-topic results because our test setbaseline accuracies vary a great deal by topic as dothe size of the topic sets.
See Table 1.Features Random Forest J 48ALL-TM 63.1 66.0Unigram 56.6 59.8Bigram 59.3 60.1Table 4: Accuracies for Theoretically MotivatedFeatures (ALL-TM), Unigrams and Bigrams withRandom Forest and J48 Trees over a 50% base-line.
No interesting differences observed in preci-sion and recall.Table 3 summarizes our theoretically-motivaedtopic-independent features, and Table 4 comparesthe accuracies of classifiers using these features tounigrams and bigrams when we train on Evolu-46tion and then test on our mixed-topic test set, usingthe Weka learners for Random forest and J48 Tree.Although unigrams and unigram+bigram achievesapproximately 60% accuracy over a 50% baseline,paired t-tests on the result vectors show that thedifferences in accuracies are statistically signifi-cant when we compare ALL-TM features with un-igrams and unigram+bigrams: Random Forest (p= .004) and J48 Trees (p < .0001).Ngram NFeatsAcc Feats SelectedUni 2K 62.5 understand, fail, never,nothing, catholic, gene,irrelevant, acceptable, show,didn?t, geologist, creationistBigram 4k 62.7 ?
you, do we, understandthat, ?
just, really?, is based,well said, ?
did, can the, thenature, the church, failed to,then whatTable 5: Accuracy when fitting to test set for num-ber of features selected for ngrams, with samplefeatures.Moreover even if we optimize on the test setby examining the variations in performance as afunction of the number of features selected, ALL-TM still beats both unigram and unigram+bigram,when features are selected according to ranking byGain Ratio.
ALL-TM is significantly more accu-rate when compared to unigrams (p = .003) bestaccuracy of 62.5 with 2000 features, and betterthan unigram+bigram best accuracy of 62.7 for4000 features (p = .007).
See Table 5.More interestingly though, if we look at whatfeatures get selected ( Table 5), we see many fea-tures reminiscent of our theoretically motivatedfeatures.
Features highly ranked by the Gain Ra-tio were topic-independent cues for disagreementsuch as understand, fail, nothing, never and Bi-grams such as ?
how, perhaps you, would you,never said.
However there were few high rankedunigrams and bigrams for agreement.
Also notethat topic specific cues such as gene, catholic, cre-ationist, geologist and the church are selected overany topic-independent cues for agreement.
Thiscorroborates our manual construction of a com-bined denial category with more than 300 wordsand a very limited agreement category.To test which features make the most difference,we also conducted ablation experiments (Table 6),as well as tests with individual features (Table 7).Table 6 shows that the CUE WORDS (p = .0008)and PUNCTUATION features (p = .01) have thebiggest impact on performance.
The decrease inperformance when ablating agreement features isAblated Feature Random Forest J 48No Agreement 62.2 65.0No Cue Words 59.1 62.1No Denial 63.3 66.0No Duration 63.6 66.3No Hedges 64.2 66.5No Polarity 64.4 66.8No Punctuation 60.3 61.6Table 6: Accuracy when Ablating each Theoreti-cally Motivated Feature with Random Forest andJ48 Trees over a 50% baseline .not statistically significant (p = .20).Feature Acc Prec RecallAgreement 54.4 .55 .54Cue words 62.5 .63 .62Denial 52.0 .54 .52Duration 53.6 .54 .53Hedges 50.4 .51 .50Polarity 53.4 .53 .53Punctuation 65.3 .65 .65Table 7: Results for Individual Features for J48Trees over a 50% baseline .Since the J48 learner performs consistently bet-ter, we restrict our comparison of individual fea-tures in Table 7 to that learner.
Table 7 showsthat PUNCTUATION and CUE WORDS features bythemselves provide significant performance im-provements over the unigram baseline, and thatthe POLARITY, AGREEMENT, DENIAL and DU-RATION feature sets provide significant improve-ments on their own over the majority class base-line of 50%.
A paired t-test shows these differ-ences are significant at p =.02.
To our surprise,the HEDGE feature was not effective, and we planfurther refinements of it.
These results support thehypothesis that there are clearly markers for agree-ment and disagreement that are suggested by thetheoretical literature and which are not topic spe-cific.6 Discussion and Future WorkWe develop topic-independent features for classi-fying (dis)agreement in online dialogue, and showthat we can beat an unfiltered unigram baselineby 6%, and even beat the best feature-selectionngram-based classifers fitted to the test set.Features we didn?t use from previous work in-clude word pairs as introduced by (Marcu andEchihabi, 2002), and used subsequently by (Pitleret al 2009) and (Biran and Rambow, 2011).
Theissue of whether word pairs are topic-dependenthas never been addressed, but the examples givenin previous work suggest that they may indicatetopic-specific comparisons.
Previous work also47suggests that context might be helpful in recog-nizing disagreement (Walker et al 2012b), but wedid not test the effect of context.The most similar work to our own trains a dis-agreement classifier for Q/R response pairs in on-line forums (Abbott et al 2011).
Their work usedngrams, MPQA opinion words (Stoyanov et al2005), LIWC (Pennebaker et al 2001), and a dif-ferent dataset (Q/R instead of P1,P2 datasets), anddoes not aim to develop a classifier that workswell independently of topic.
Their best accuracyis about 68% for a feature set called BothLocalfor the JRip classifier using ?2 feature selection.BothLocal includes unigrams, bigrams, trigrams,LIWC, punctuation, cue words, dependency fea-tures, generalized dependency features and utter-ance length measures, and it is unclear whetherthese features are specific to topic.
It is also dif-ficult to directly compare the results because theydo not report accuracies for individual feature setsor ablated feature experiments.
For example, theirunigram accuracy of 63% includes cue words, andis reported for training and testing on a mixture oftopics without any held-out topics.Other work on disagreement recognition in-cludes that of (Wang et al 2011) who de-scribe conditional random field model for detect-ing (dis)agreement between speakers in Englishbroadcast conversations.
They use sampling andprosodic features such as pause, duration andspeech rate on an unbalanced dataset.
They re-port an increase in F-measure of 4.5% for agree-ment and 4.7% for disagreement over a baseline oflexical, structural, and durational features.
(Hahnet al 2006) show that a contrast classifier im-proves the accuracy of dis(agreement) classifica-tion in the ICSI meetings corpus, and that their re-sults are less affected by imbalanced data.
Theyimprove the F-measure to .755 over a baselineSVM with F-measure .726.
(Yin et al 2012)use sentiment, emotion and durational features for(dis)agreement classification in online forums, andthey show that aggregating local positions overposts yields 3 to 4% better performance than non-aggregating baselines.While recognizing (dis)agreement can be use-ful in its own right, it has also been shown tobe useful for the identification of stance (Gawronet al 2012; Hassan et al 2010; Thomas et al2006; Bansal et al 2008; Murakami and Ray-mond, 2010; Agrawal et al 2003).
Work thatfocuses on the social network structure of on-line forums as a way to improve stance classifi-cation has either assumed that adjacent posts al-ways disagree, or used simple rules for identify-ing agreement based on patterns in the reply post(Murakami and Raymond, 2010; Agrawal et al2003).
Previous work by Somasundaran & Wiebe(2009, 2010) develops positive and negative argu-ing features for the classification of stance, thatat least in motivation, resemble our denial fea-tures .
They show that arguing features are help-ful in stance classification.
Work by (Galley etal., 2004) on detecting disagreement in meetingscorpora similarly shows that pragmatic featuresare useful for detecting disagreement using mod-els based on Bayesian Networks.
(Walker et al2012b) use a number of linguistic features such asunigrams, bigrams, and repeated punctuation andproposed a supervised model for stance classifica-tion in online debates.
Related work by (Hassan etal., 2010) focuses on identifying the attitude of theparticipants towards one another in online debates.They relate the polarity of words to the second per-son pronoun for classification, while related workby (Abu-Jbara et al 2012) uses the polarity ofexpressions and named entity recognition to iden-tify a subgroup of participants, where participantswithin a subgroup are inclined to agree with oneanother.
Methods for stance classification in con-gressional debates do not separately evaluate theaccuracy of (dis)agreement classification (Thomaset al 2006; Bansal et al 2008; Awadallah et al2010; Burfoot, 2008).In future work, we plan to develop more de-tailed patterns based on LIWC categories and syn-tactic parses (Thelen and Riloff, 2002).
For ex-ample, an error analysis suggests that sometimestwo people mutually reject the proposal or claimof a third person, e.g.
How can they say that....In such cases our classifier finds the disagreementmarker how can and classifies it as disagreement.More detailed syntactic processing would allow usto refine our patterns to identify particular classesof targets such as third person vs. first person.Similarly, here we extended patterns by hand, e.g.generalizations over pronouns such as I can?t, wecan?t, can you, can we.
In future we aim to gen-eralize such patterns automatically using tagsets.We expect that more general patterns should im-prove the accuracy of the topic-independent fea-ture sets.
We also plan to carry out further annota-tion of the IAC corpus using the classes of rejec-tions summarized in Fig.
2 to determine whetherthere are forms for indicating each type that arenot represented by our features, and to determinethe frequency across a sample of our corpus of thedifferent types.48ReferencesR.
Abbott, M. A. Walker, J. E. Fox Tree, P. Anand, R.Bowmani, and J.
King.
2011.
How can you saysuch things?!?
: Recognizing Disagreement in Infor-mal Political Argument.
In Proc.
of the ACL Work-shop on Language in Social Media.A.
Abu-Jbara, M. Diab, P. Dasigi, and D. Radev.
2012.Subgroup detection in ideological discussions.
InProc.
of the 50th Annual Meeting of the Associationfor Computational Linguistics, ACL ?12, p. 399?409.ACL.R.
Agrawal, S. Rajagopalan, R. Srikant, and Y. Xu.2003.
Mining newsgroups using networks arisingfrom social behavior.
In Proc.
of the 12th interna-tional conference on World Wide Web, p. 529?535.ACM.D.
Appelt and K. Konolige.
1988.
A practical non-monotonic theory for reasoning about speech acts.In Proc.
of the 26th Annual Meeting of the Associa-tion for Computational Linguistics.N.
Asher, F. Benamara, and Y. Yannick Mathieu.
2008.Distilling opinion in discourse: A preliminary study.In COLING 2008, p. 7?10.R.
Awadallah, M. Ramanath, and G. Weikum.
2010.Language-model-based pro/con classification of po-litical text.
In Proc.
of the 33rd international ACMSIGIR conference on Research and development ininformation retrieval, p. 747?748.
ACM.M.
Bansal, C. Cardie, and L. Lee.
2008.
The power ofnegative thinking: Exploiting label disagreement inthe min-cut classification framework.
Proc.
of COL-ING: Companion volume: Posters, p. 13?16.O.
Biran and O. Rambow.
2011.
Identifying justifica-tions in written dialogs.
In 2011 Fifth IEEE Interna-tional Conference on Semantic Computing (ICSC),p. 162?168.
IEEE.Penelope Brown and Steve Levinson.
1987.
Polite-ness: Some universals in language usage.
Cam-bridge University Press.C.
Burfoot.
2008.
Using multiple sources of agree-ment information for sentiment classification of po-litical transcripts.
In Australasian Language Tech-nology Association Workshop 2008, v.6, p. 11?18.G.
Carenini and J. Moore.
2000.
A strategy for gener-ating evaluative arguments.
In Proc.
of the 1st Inter-national Conference on Natural Language Genera-tion (INLG-00).J.E.
Fox Tree and J.C. Schrock.
1999.
DiscourseMarkers in Spontaneous Speech: Oh What a Dif-ference an Oh Makes.
Journal of Memory and Lan-guage, 40(2):280?295.M.
Galley, K. McKeown, J. Hirschberg, andE.
Shriberg.
2004.
Identifying agreement anddisagreement in conversational speech: Use ofbayesian networks to model pragmatic dependen-cies.
In Proc.
of the 42nd Annual Meeting on Asso-ciation for Computational Linguistics, p. 669.
ACL.J.M.
Gawron, D. Gupta, K. Stephens, M.H.
Tsou,B.
Spitzberg, and L. An.
2012.
Using group mem-bership markers for group identification in web logs.In The 6th International AAAI Conference on We-blogs and Social Media (ICWSM 2012).M.
Groen, J. Noyes, and F. Verstraten.
2010.
TheEffect of Substituting Discourse Markers on TheirRole in Dialogue.
Discourse Processes: A Multidis-ciplinary Journal, 47(5):33.S.
Hahn, R. Ladner, and M. Ostendorf.
2006.
Agree-ment/disagreement classification: exploiting unla-beled data using contrast classifiers.
In Proc.
ofthe Human Language Technology Conference of theNAACL, NAACL06, p. 53?56.
ACL.A.
Hassan, V. Qazvinian, and D. Radev.
2010.
What?swith the attitude?
: identifying sentences with atti-tude in online discussions.
In Proc.
of the 2010 Con-ference on Empirical Methods in Natural LanguageProcessing, p 1245?1255.
ACL.J.B.
Hirschberg.
1985.
A Theory of Scalar Implicature.Ph.D.
thesis, University of Pennsylvania, Computerand Information Science.L.
R. Horn.
1989.
A natural history of negation.Chicago University Press.G.
Lakoff.
1973.
Hedges: A study in meaning criteriaand the logic of fuzzy concepts.
Journal of Philo-sophical Logic, 2(4):458?508.A.
Louis, A. Joshi, R. Prasad, and A. Nenkova.
2010.Using entity features to classify implicit relations.In Proc.
of the 11th Annual SIGdial Meeting on Dis-course and Dialogue, Tokyo, Japan.D.
Marcu and A. Echihabi.
2002.
An unsupervised ap-proach to recognizing discourse relations.
In Proc.of the 40th Annual Meeting on Association for Com-putational Linguistics, p. 368?375.
ACL.A.
Murakami and R. Raymond.
2010.
Support or Op-pose?
Classifying Positions in Online Debates fromReply Activities and Opinion Expressions.
In Proc.of the 23rd International Conference on Computa-tional Linguistics: Posters, p. 869?875.
ACL.B.
Pang and L. Lee.
2008.
Opinion mining and senti-ment analysis.
Foundations and Trends in Informa-tion Retrieval, 2(1-2):1?135.J.
W. Pennebaker, L. E. Francis, and R. J. Booth, 2001.LIWC: Linguistic Inquiry and Word Count.49R.
Perrault.
1990.
An application of default logic tospeech-act theory.
In Philip Cohen, Jerry Morgan,and Martha Pollack, editors, Intentions in Commu-nication, p. 161?187.
MIT Press.E.
Pitler, A. Louis, and A. Nenkova.
2009.
Automaticsense prediction for implicit discourse relations intext.
In Proc.
of the Joint Conference of the 47th An-nual Meeting of the ACL: Vol.
2, p. 683?691.
ACL.M.
Pollack, J. Hirschberg, and B. Webber.
1982.
Userparticipation in the reasoning process of expert sys-tems.
In Proc.
First National Conference on Artifi-cial Intelligence, pages pp.
358?361.R.
Prasad, A. Joshi, and B. Webber.
2010.
Exploitingscope for shallow discourse parsing.
In LanguageResources and Evaluation Conference.E.
Riloff and J. Wiebe.
2003.
Learning extraction pat-terns for subjective expressions.
In Proc.
of the 2003conference on Empirical methods in Natural Lan-guage Processing-Vol.10, p. 105?112.
ACL.J.
M. Sadock.
1977.
Modus brevis: The truncated ar-gument.
In Papers from the 13th meeting of the CLS.Chicago Linguistic Society.S.
Somasundaran and J. Wiebe.
2009.
Recognizingstances in online debates.
In Proc.
of the Joint Con-ference of the 47th Annual Meeting of the ACL, p.226?234.
ACL.S.
Somasundaran and J. Wiebe.
2010.
Recognizingstances in ideological on-line debates.
In Proc.
ofthe NAACL HLT 2010 Workshop on ComputationalApproaches to Analysis and Generation of Emotionin Text, p. 116?124.
ACL.R.
C. Stalnaker.
1978.
Assertion.
In Peter Cole, editor,Syntax and Semantics, Vol.
9: Pragmatics, p. 315?332.
Academic Press.A.
Stent.
2002.
A conversation acts model for gen-erating spoken dialogue contributions.
ComputerSpeech and Language: Special Issue on SpokenLanguage Generation.V.
Stoyanov, C. Cardie, and J. Wiebe.
2005.
Multi-perspective question answering using the MPQAcorpus.
In Proc.
of the conference on Human Lan-guage Technology and Empirical Methods in Nat-ural Language Processing, HLT ?05, p. 923?930,ACL.M.
Thelen and E. Riloff.
2002.
A bootstrappingmethod for learning semantic lexicons using extrac-tion pattern contexts.
In Proc.
of the ACL-02 con-ference on Empirical methods in Natural LanguageProcessing.
Vol.
10, p. 214?221.
ACL.M.
Thomas, B. Pang, and L. Lee.
2006.
Get out thevote: Determining support or opposition from Con-gressional floor-debate transcripts.
In Proc.
of the2006 conference on empirical methods in naturallanguage processing, p. 327?335.
ACL.R.
Thomason.
1990.
Propagating epistemic coordi-nation through mutual defaults i.
In R. Parikh, ed-itor, Proc.
of the Third Conference on TheoreticalAspects of Reasoning about Knowledge, p. 29?39.D.
Traum.
1994.
A Computational Model of Ground-ing in Natural Language Conversation.
Ph.D. the-sis, University of Rochester.M.
Walker, P. Anand, R. Abbott, and J. E. Fox Tree.2012a.
A corpus for research on deliberation and de-bate.
In Language Resources and Evaluation Con-ference, LREC2012.M.A.
Walker, P. Anand, R. Abbott, and R. Grant.2012b.
Stance classification using dialogic proper-ties of persuasion.
In Meeting of the North AmericanAssociation for Computational Linguistics.
NAACL-HLT12.M.
A. Walker.
1996a.
Inferring acceptance and rejec-tion in dialogue by default rules of inference.
Lan-guage and Speech, 39-2:265?304.W.
Wang, S. Yaman, K. Precoda, C. Richey, and G.Raymond.
2011.
Detection of agreement and dis-agreement in broadcast conversations.
In The 49thAnnual Meeting of the Association for Computa-tional Linguistics, p. 374?378.
ACL.B.
Webber and R. Prasad.
2008.
Sentence-initial dis-course connectives, discourse structure and seman-tics.
In Proc.
of the Workshop on Formal and Ex-perimental Approaches to Discourse Particles andModal Adverbs, Hamburg, Germany.J.
Wiebe, E. Breck, C. Buckley, C. Cardie, P. Davis,B.
Fraser, D. Litman, D. Pierce, E. Riloff, T. Wil-son, et al2003.
Recognizing and organizingopinions expressed in the world press.
In WorkingNotes-New Directions in Question Answering (AAAISpring Symposium Series).J.
Wiley.
2005.
A fair and balanced look at the news:What affects memory for controversial arguments?Journal of Memory and Language, 53(1):95?109.T.
Wilson, P. Hoffmann, S. Somasundaran, J. Kessler,J.
Wiebe, Y. Choi, C. Cardie, E. Riloff, and S. Pat-wardhan.
2005.
Opinionfinder: A system for sub-jectivity analysis.
In Proc.
of HLT/EMNLP on Inter-active Demonstrations, p. 34?35.
ACL.J.
Yin, P. Thomas, N. Narang, and C. Paris.
2012.
Uni-fying local and global agreement and disagreementclassification in online debates.
In Proc.
of the 3rdWorkshop in Computational Approaches to Subjec-tivity and Sentiment Analysis, WASSA ?12, p. 61?69, ACL.I.
Zukerman, R. McConachy, and K. Korb.
2000.
Us-ing argumentation strategies in automated argumentgeneration.
In Proc.
of the 1st International NaturalLanguage Generation Conference, p. 55?62.50
