Proceedings of the ACL 2007 Student Research Workshop, pages 79?84,Prague, June 2007. c?2007 Association for Computational LinguisticsSemantic Classification of Noun Phrases UsingWeb Counts and Learning AlgorithmsPaul NultySchool of Computer Science and InformaticsUniversity College DublinBelfield, Dublin 4, Irelandpaul.nulty@ucd.ieAbstractThis paper investigates the use of machinelearning algorithms to label modifier-nouncompounds with a semantic relation.
Theattributes used as input to the learning algo-rithms are the web frequencies for phrasescontaining the modifier, noun, and a prepo-sitional joining term.
We compare andevaluate different algorithms and differentjoining phrases on Nastase and Szpako-wicz?s (2003) dataset of 600 modifier-nouncompounds.
We find that by using a Sup-port Vector Machine classifier we can ob-tain better performance on this dataset thana current state-of-the-art system; even witha relatively small set of prepositional join-ing terms.1 IntroductionNoun-modifier word pairs occur frequently inmany languages, and the problem of semantic dis-ambiguation of these phrases has many potentialapplications in areas such as question-answeringand machine translation.
One very common ap-proach to this problem is to define a set of seman-tic relations which capture the interaction betweenthe modifier and the head noun, and then attemptto assign one of these semantic relations to eachnoun-modifier pair.
For example, the phrase ?fluvirus?
could be assigned the semantic relation?causal?
(the virus causes the flu); the relation for?desert storm?
could be ?location?
(the storm islocated in the desert).There is no consensus as to which set of seman-tic relations best captures the differences in mean-ing of various noun phrases.
Work in theoreticallinguistics has suggested that noun-noun com-pounds may be formed by the deletion of a predi-cate verb or preposition (Levi 1978).
However,whether the set of possible predicates numbers 5 or50, there are likely to be some examples of nounphrases that fit into none of the categories andsome that fit in multiple categories.Modifier-noun phrases are often used inter-changeably with paraphrases which contain themodifier and the noun joined by a preposition orsimple verb.
For example, the query ?morning ex-ercise?
returns 133,000 results from the Yahoosearch engine, and a query for the phrase ?exercisein the morning?
returns 47,500 results.
Sometimespeople choose to use a modifier-noun compoundphrase to describe a concept, and sometimes theychoose to use a paraphrase which includes a prepo-sition or simple verb joining head noun and themodifier.
One method for deducing semantic rela-tions between words in compounds involves gath-ering n-gram frequencies of these paraphrases,containing a noun, a modifier and a ?joining term?that links them.
Some algorithm can then be usedto map from joining term frequencies to semanticrelations and so find the correct relation for thecompound in question.
This is the approach we usein our experiments.
We choose two sets of joiningterms, based on the frequency with which they oc-cur in between nouns in the British National Cor-79pus (BNC).
We experiment with three differentlearning algorithms; Nearest Neighbor, Multi-Layer Perceptron and Support Vector Machines(SVM).2 MotivationThe motivation for this paper is to discover whichjoining terms are good predictors of a semanticrelation, and which learning algorithms performbest at the task of mapping from joining terms tosemantic relations for modifier-noun compounds.2.1 Joining TermsChoosing a set of joining terms in a principledmanner in the hope of capturing the semantic rela-tion between constituents in the noun phrase is dif-ficult, but there is certainly some correlation be-tween a prepositional term or short linking verband a semantic relation.
For example, the preposi-tion ?during?
indicates a temporal relation, whilethe preposition ?in?
indicates a locative relation,either temporal or spatial.In this paper, we are interested in whether thefrequency with which a joining term occurs be-tween two nouns is related to how it indicates asemantic interaction.
This is in part motivated byZipf?s theory which states that the more frequentlya word occurs in a corpus the more meanings orsenses it is likely to have (Zipf 1929).
If this istrue, we would expect that very frequent preposi-tions, such as ?of?, would have many possiblemeanings and therefore not reliably predict a se-mantic relation.
However, less frequent preposi-tions, such as ?while?
would have a more limitedset of senses and therefore accurately predict a se-mantic relation.2.2 Machine Learning AlgorithmsWe are also interested in comparing the perform-ance of machine learning algorithms on the task ofmapping from n-gram frequencies of joining termsto semantic relations.
For the experiments we useWeka, (Witten and Frank, 1999) a machine learn-ing toolkit which allows for fast experimentationwith many standard learning algorithms.
In Section5 we present the results obtained using the nearest-neighbor, neural network (i.e.
multi-layer percep-tron) and SVM.
The mechanisms of these differentlearning approaches will be discussed briefly inSection 4.3 Related Work3.1   Web MiningMuch of the recent work conducted on the problemof assigning semantic relations to noun phrases hasused the web as a corpus.
The use of hit countsfrom web search engines to obtain lexicalinformation was introduced by Turney (2001).
Theidea of searching a large corpus for specific lexico-syntactic phrases to indicate a semantic relation ofinterest was first described by Hearst (1992).A lexical pattern specific enough to indicate aparticular semantic relation is usually not veryfrequent, and using the web as a corpus alleviatesthe data sparseness problem.
However, it alsointroduces some problems.?
The query language permitted by the largesearch engines is somewhat limited.?
Two of the major search engines (Google andYahoo) do not provide exact frequencies, butgive rounded estimates instead.?
The number of results returned is unstable asnew pages are created and deleted all the time.Nakov and Hearst (2005) examined the use ofweb-based n-gram frequencies for an NLP task andconcluded that these issues do not greatly impactthe interpretation of the results.
Keller and Lapata(2003) showed that web frequencies correlatereliably with standard corpus frequencies.Lauer (1995) tackles the problem of semanticallydisambiguating noun phrases by trying to find thepreposition which best describes the relationbetween the modifier and head noun.
His methodinvolves searching a corpus for occurrencesparaphrases of the form ?noun prepositionmodifier?.
Whichever preposition is most frequentin this context is chosen.
Lapata and Keller (2005)improved on Lauer's results at the same task byusing the web as a corpus.
Nakov and Hearst(2006) use queries of the form ?noun that *modifier?
where '*' is a wildcard operator.
Byretrieving the words that most commonly occurredin the place of the wildcard they were able toidentify very specific predicates that are likely torepresent the relation between noun and modifier.803.2 Machine Learning ApproachesThere have been two main approaches used whenapplying machine learning algorithms to the se-mantic disambiguation of modifier-noun phrases.The first approach is to use semantic properties ofthe noun and modifier words as attributes, using alexical hierarchy to extract these properties.
Thisapproach was used by Rosario and Hearst (2001)within a specific domain ?
medical texts.
Using anontology of medical terms they train a neural net-work to semantically classify nominal phrases,achieving 60% accuracy over 16 classes.Nastase and Szpakowicz (2003) use the positionof the noun and modifier words within general se-mantic hierarchies (Roget's Thesaurus and Word-Net) as attributes for their learning algorithms.They experiment with various algorithms and con-clude that a rule induction system is capable ofgeneralizing to characterize the noun phrases.Moldovan et al(2004) also use WordNet.
Theyexperiment with a Bayesian algorithm, decisiontrees, and their own algorithm; semantic scattering.There are some drawbacks to the technique of us-ing semantic properties extracted from a lexicalhierarchy.
Firstly, it has been noted that the distinc-tions between word senses in WordNet are veryfine-grained, making the task of word-sense dis-ambiguation tricky.
Secondly, it is usual to use arule-based learning algorithm when the attributesare properties of the words rather than n-gram fre-quency counts.
As Nastase and Szpakowicz (2003)point out, a large amount of labeled data is re-quired to allow these rule-based learners to effec-tively generalize, and manually labeling thousandsof modifier-noun compounds would be a time-consuming task.Table 1: Examples for each of the five relationsThe second approach is to use statistical informa-tion about the occurrence of the noun and modifierin a corpus to generate attributes for a machinelearning algorithm.
This is the method we will de-scribe in this paper.
Turney and Littman (2005)use a set of 64 short prepositional and conjunctivephrases they call ?joining terms?
to generate exactqueries for AltaVista of the form ?noun joiningterm modifier?, and ?modifier joining term noun?.These hit counts were used with a nearestneighbor algorithm to assign the noun phrases se-mantic relations.
Over the set of 5 semantic rela-tions defined by Nastase and Szpakowicz (2003),they achieve an accuracy of 45.7% for the task ofassigning one of 5 semantic relations to each of the600 modifier-noun phrases.4   MethodThe method described in this paper is similar tothe work presented in Turney and Littman (2005).We collect web frequencies for queries of the form?head joining term modifier?.
We did not collectqueries of the form ?modifier joining term head?
;in the majority of paraphrases of noun phrases thehead noun occurs before the modifying word.
Aswell as trying to achieve reasonable accuracy, wewere interested in discovering what kinds of join-ing phrases are most useful when trying to predictthe semantic relation, and which machine learningalgorithms perform best at the task of using vectorsof web-based n-gram frequencies to predict thesemantic relation.For our experiments we used the set of 600 la-beled noun-modifier pairs of Nastase and Szpako-wicz (2003).
This data was also used by Turneyand Littman (2005).
Of the 600 modifier-nounphrases, three contained hyphenated or two-wordmodifier terms, for example ?test-tube baby?.
Weomitted these three examples from our experi-ments, leaving a dataset of 597 examples.The data is labeled with two different sets ofsemantic relations: one set of 30 relations withfairly specific meanings, and another set of 5 rela-tions with more abstract meanings.
For our ex-periments we focused on the set of 5 relations.
Onereason for this is that dividing a set of 600 in-stances into 30 classes results in a fairly sparse anduneven dataset.
Table 1 is a list of the relationsused and examples of compounds that are labeledwith each relation.4.1 Collecting Web FrequenciesIn order to collect the n-gram frequencies, we usedthe Yahoo Search API.
Collecting frequencies forcausal flu virus, onion teartemporal summer travel, morning classspatial west coast, home remedyparticipant mail sorter, blood donorquality rice paper, picture book81600 noun-modifier pairs, using 28 different joiningterms required 16,800 calls to the search engine.We will discuss our choice of the joining terms inthe next section.When collecting web frequencies we took advan-tage of the OR operator provided by the searchengine.
For each joining term, we wanted to sumthe number of hits for the term on its own, the termfollowed by 'a' and the term followed by 'the'.
In-stead of conducting separate queries for each ofthese forms, we were able to sum the results withjust one search.
For example, if the noun phrasewas ?student invention?
and the joining phrase was?by?
; one of the queries would be:?invention by student?
OR ?invention by a student?
OR?invention by the student?This returns the sum of the number of pagesmatched by each of these three exact queries.
Theidea is that these sensible paraphrases will returnmore hits than nonsense ones, such as:?invention has student?
OR ?invention has a student?OR ?invention has the student?It would be possible to construct a set of hand-coded rules to map from joining terms to semanticrelations; for example ?during?
maps to temporal,?by?
maps to causal and so on.
However, we hopethat the classifiers will be able to identify combina-tions of prepositions that indicate a relation.4.2 Choosing a Set of Joining TermsPossibly the most difficult problem with thismethod is deciding on a set of joining terms whichis likely to provide enough information about thenoun-modifier pairs to allow a learning algorithmto predict the semantic relation.
Turney and Litt-man (2005) use a large and varied set of joiningterms.
They include the most common preposi-tions, conjunctions and simple verbs like ?has?,?goes?
and ?is?.
Also, they include the wildcardoperator '*' in many of their queries; for example?not?, ?
* not?
and ?but not?
are all separate que-ries.
In addition, they include prepositions bothwith and without the definite article as separatequeries, for example ?for?
and ?for the?.The joining terms used for the experiments in thispaper were chosen by examining which phrasesmost commonly occurred between two nouns inthe BNC.
We counted the frequencies with whichphrases occurred between two nouns and chose the28 most frequent of these phrases as our joiningterms.
We excluded conjunctions and determinersfrom the list of the most frequent joining terms.We excluded conjunctions on the basis that in mostcontexts a conjunction merely links the two nounstogether for syntactic purposes; there is no realsense in which one of the nouns modifies anothersemantically in this context.
We excluded deter-miners on the basis that the presence of a deter-miner does not affect the semantic properties of theinteraction between the head and modifier.4.3 Learning AlgorithmsThere were three conditions experimented withusing three different algorithms.
For the first con-dition, the attributes used by the learning algo-rithms consisted of vectors of web hits obtainedusing the 14 most frequent joining terms found inthe BNC.
The next condition used a vector of webhits obtained using the joining terms that occurredTable 2: Joining terms ordered by the frequencywith which they occurred between two nouns inthe BNC.from position 14 to 28 in the list of the most fre-quent terms found in the BNC.
The third conditionused all 28 joining terms.
The joining terms arelisted in Table 2.
We used the log of the webcounts returned, as recommended in previous work(Keller and Lapata, 2003).The first learning algorithm we experimentedwith was the nearest neighbor algorithm ?IB1?, as1-14 15-28ofintoforonwithatisfromasbybetweenabouthasagainstwithinduringthroughovertowardswithoutacrossbecausebehindafterbeforewhileunder82implemented in Weka.
This algorithm considersthe vector of n-gram frequencies as a multi-dimensional space, and chooses the label of thenearest example in this space as the label for eachnew example.
Testing for this algorithm was doneusing leave-one-out cross validation.The next learning algorithm we used was themulti-layer perceptron, or neural network.
Thenetwork was trained using the backpropagation oferror technique implemented in Weka.
For the firsttwo sets of data we used a network with 14 inputnodes, one hidden layer with 28 nodes, and 5 out-put nodes.
For the final condition, which uses thefrequencies for all 28 joining terms, we used 28input nodes, one hidden layer with 56 nodes, andagain 5 outputs, one for each class.
We used 20-fold cross validation with this algorithm.The final algorithm we tested was an SVMtrained with the Sequential Minimal Optimizationmethod provided by Weka.
A support vector ma-chine is a method for creating a classification func-tion which works by trying to find a hypersurfacein the space of possible inputs that splits the posi-tive examples from the negative examples for eachclass.
For this test we again used 20-fold crossvalidation.5.
ResultsThe accuracy of the algorithms on each of the con-ditions is illustrated below in Table 3.
Since thelargest class in the dataset accounts for 43% of theexamples, the baseline accuracy for the task(guessing ?participant?
all the time) is 43%.The condition containing the counts for the lessfrequent joining terms performed slightly betterthan that containing the more frequent ones, butthe best accuracy resulted from using all 28 fre-quencies.
The Multi-Layer Perceptron performedbetter than the nearest neighbor algorithm on allthree conditions.
There was almost no difference inaccuracy between the first two conditions, andagain using all of the joining terms produced thebest results.The SVM algorithm produced the best accuracyof all, achieving 50.1% accuracy using the com-bined set of joining terms.
The less frequent join-ing terms achieve slightly better accuracy using theNearest Neighbor and SVM algorithms, and veryslightly worse accuracy using the neural network.Using all of the joining terms resulted in a signifi-cant improvement in accuracy for all algorithms.The SVM consistently outperformed the baseline;neither of the other algorithms did so.6.
Discussion and Future WorkOur motivation in this paper was twofold.
Firstly,we wanted to compare the performance of differentmachine learning algorithms on the task of map-ping from a vector of web frequencies of para-phrases containing joining terms to semantic rela-tions.
Secondly, we wanted to discover whether thefrequency of joining terms was related to their ef-fectiveness at predicting a semantic relation.6.1 Learning AlgorithmsThe results suggest that the nearest neighbor ap-proach is not the most effective algorithm for theclassification task.
Turney and Littman (2005)achieve an accuracy of 45.7%, where we achieve amaximum accuracy of 38.1% on this dataset usinga nearest neighbor algorithm.
However, their tech-nique uses the cosine of the angle between the vec-tors of web counts as the similarity metric, whilethe nearest neighbor implementation in Weka usesthe Euclidean distance.Also, they use 64 joining terms and gathercounts for both the forms ?noun joining term modi-fier?
and ?modifier joining term noun?
(128 fre-quencies in total); while we use only the formerconstruction with 28 joining terms.
By using theSVM classifier, we were able to achieve a higheraccuracy than Turney and Littman (50.1% versus45.7%) with significantly fewer joining terms (28versus 128).
However, one issue with the SVM isTable 3:  Accuracy for each algorithm using each set of joining terms on the Nastase and Szpako-wicz test set of modifier-noun compounds.Joining Terms 1-14 Joining terms 15-28 All 28 Joining termsNearest Neighbor 32.6 34.7 38.1Multi Layer Perceptron 37.6 37.4 42.2Support Vector Machine 44.2 45.9 50.183that it never predicted the class ?causal?
for any ofthe examples.
The largest class in our dataset is?participant?, which is the label for 43% of theexamples; the smallest is ?temporal?, which labels9% of the examples.
?Causal?
labels 14% of thedata.
It is difficult to explain why the algorithmfails to account for the ?causal?
class; a useful taskfor future work would be to conduct a similar ex-periment with a more balanced dataset.6.2 Joining TermsThe difference in accuracy achieved by the twosets of joining terms is quite small, although fortwo of the algorithms the less frequent terms didachieve slightly better results.
The difficulty is thatthe task of deducing a semantic relation from aparaphrase such as ?storm in the desert?
requiresmany different types of information.
It requiresknowledge about the preposition ?in?
; i.e.
that itindicates a location.
It requires knowledge aboutthe noun ?desert?, i.e.
that it is a location in spacerather than time, and it requires the knowledge thata ?storm?
may refer both to an event in time and anentity in space.
It may be that a combination ofsemantic information from an ontology and statis-tical information about paraphrases could be usedtogether to achieve better performance on this task.Another interesting avenue for future work inthis area is investigation into exactly how ?joiningterms?
relate to semantic relations.
Given Zipf'sobservation that high frequency words are moreambiguous than low frequency words, it is possiblethat there is a relationship between the frequencyof the preposition in a paraphrase such as ?stormin the desert?
and the ease of understanding thatphrase.
For example, the preposition 'of' is veryfrequent and could be interpreted in many ways.Therefore, the ?of?
may be used in phrases wherethe semantic relation can be easily deduced fromthe nominals in the phrase alone.
Less common(and therefore more informative) prepositions suchas ?after?
or ?because?
may be used more often inphrases where the nominals alone do not containenough information to deduce the relation, or therelation intended is not the most obvious one giventhe two nouns.ReferencesMarti A. Hearst.
1992.
Automatic Acquisition of Hypo-nyms from Large Text Corpora.
COLING 92: (2) pp.539-545, Nantes, France,Frank Keller and Mirella Lapata.
2003.
Using the Webto Obtain Frequencies for Unseen Bigrams.
Compu-tational Linguistics, 29: pp 459-484.Mirella Lapata and Frank Keller.
2005.
Web-BasedModels for Natural Language Processing.
ACMTransactions on Speech and Language Processing2:1, pp 1-31.Mark Lauer.
1995.
Designing Statistical LanguageLearners: Experiments on Noun Compounds.
PhDthesis, Macquarie University, NSW 2109, Australia.Judith Levi.
1978.
The Syntax and Semantics of Com-plex Nominals, Academic Press, New York, NY.Dan Moldovan, Adriana Badulescu, Marta Tatu, DanielAntohe and Roxana Girju.
2004.
Models for the Se-mantic Classification of Noun Phrases.
In Proceed-ings of the HLT/NAACL Workshop on ComputationalLexical Semantics.
pp 60-67  Boston , MA.Preslav Nakov and Marti Hearst.
2006.
Using Verbs toCharacterize Noun-Noun Relations.
In Proceedingsof AIMSA 2006,  pp 233-244, Varne, Bulgaria.Preslav Nakov and Marti Hearst.
2005.
Using the Webas an Implicit Training Set: Application to StructuralAmbiguity Resolution.
In Proceedings ofHLT/EMNLP'05.
pp 835-842, Vancouver, Canada.Vivi Nastase and Stan Szpakowicz.
2003.
ExploringNoun-Modifier Semantic Relations.
In Fifth Interna-tional Workshop on Computational Semantics, pp285-301.
Tillburg, Netherlands.Barbara Rosario and Marti A. Hearst.
2001.
Classifyingthe semantic relations in noun compounds via a do-main-specific lexical hierarchy.
In Proceedings ofEMNLP 2001, pp 82-90, Pittsburgh, PA, USA.Peter D. Turney.
2001.
Mining the web for synonyms:PM-IR vs LSA on TOEFL.
Proceedings ofECML'01.
pp 491-502.
Freiburg, Germany.Peter D. Turney and Michael L. Littman.
2005.
Corpus-based learning of analogies and semantic relations.Machine Learning, 60(1?3):251?278.Ian H. Witten and Eibe Frank.
1999.
Data Mining:Practical Machine Learning Tools and Techniqueswith Java Implementations.
Morgan Kaufmann.George K. Zipf.
1932.
Selected Studies of the Principleof Relative Frequency in Language.
Cambridge, MA.84
