Semantic classification of Chinese unknown wordsHuihsin TsengLinguisticsUniversity of Coloradoat Bouldertseng@colorado.eduAbstractThis paper describes a classifier that assigns se-mantic thesaurus categories to unknown Chinesewords (words not already in the CiLin thesaurusand the Chinese Electronic Dictionary, but in theSinica Corpus).
The focus of the paper differs intwo ways from previous research in this particulararea.Prior research in Chinese unknown words mostlyfocused on proper nouns (Lee 1993, Lee, Lee andChen 1994, Huang, Hong and Chen 1994, Chenand Chen 2000).
This paper does not addressproper nouns, focusing rather on common nouns,adjectives, and verbs.
My analysis of the SinicaCorpus shows that contrary to expectation, most ofunknown words in Chinese are common nouns,adjectives, and verbs rather than proper nouns.Other previous research has focused on featuresrelated to unknown word contexts (Caraballo 1999;Roark and Charniak 1998).
While context isclearly an important feature, this paper focuses onnon-contextual features, which may play a key rolefor unknown words that occur only once and hencehave limited context.
The feature I focus on, fol-lowing Ciaramita (2002), is morphological similar-ity to words whose semantic category is known.My nearest neighbor approach to lexical acquisi-tion computes the distance between an unknownword and examples from the CiLin thesaurus basedupon its morphological structure.
The classifierimproves on baseline semantic categorization per-formance for adjectives and verbs, but not fornouns.1 IntroductionThe biggest problem for assigning semantic cate-gories to words lies in the incompleteness of dic-tionaries.
It is impractical to construct a dictionarythat will contain all words that may occur in somepreviously unseen corpora.
This issue is particu-larly problematic for natural language processingapplications that work with Chinese texts.
Specifi-cally, for the Sinica Corpus1, Bai, Chen and Chen(1998) found that articles contain on average3.51% words that were not listed in the ChineseElectronic Dictionary2 of 80,000 words.
Becausenovel words are created daily, it is impossible tocollect them all.
Furthermore, across most of thecorpora, many of these newly coined words seemto be used only once, and thus they may not evenbe worth collecting.
However, the occurrence ofunknown words makes a number of NLP (NaturalLanguage Processing) tasks such as segmentationand word sense disambiguation more difficult.Consequently, it would be valuable to have somemeans of automatically assigning meaning to un-known words.
This paper describes a classifier thatassigns semantic thesaurus categories to unknownChinese words.The Caraballo (1999)?s system adopted the contex-tual information to assign nouns to their hyponyms.Roark and Charniak (1998) used the co-occurrenceof words as features to classify nouns.
While con-text is clearly an important feature, this paper fo-cuses on non-contextual features, which may playa key role for unknown words that occur only once1 The Sinica Corpus is a balanced corpus contained fivemillion part-of-speech words in Mandarin Chinese.2The Chinese Electronic Dictionary is from theComputational Linguistics Society of R.O.C.and hence have limited context.
The feature I focuson, following Ciaramita (2002), is morphologicalsimilarity to words whose semantic category isknown.
Ciaramita (2002) boosted the lexical ac-quisition system by simple morphological rulesand found a significant improvement.
Such a find-ing suggests that a reliable source of semantic in-formation lies in the morphology used to constructthe unknown words.In Chinese morphology, the two ways to generatenew words are compounding and affixation.Orthographically, such compounding and affixa-tion is represented by combinations of characters,and as a result, the character combinations and themorpho-syntactic relationship used to link themtogether can be clues for classification.
Further-more, my analysis of the Sinica Corpus indicatesthat only 49.68% monosyllabic3 words have oneword class, but 91.67% multisyallabic words haveone word class in Table 1.
Once characters mergetogether, only 8.33% words remain ambiguous.
Itimplies that as characters are combined together,the degree of ambiguity tends to decrease.Word Class4 Monosyllabic Multisyllabic1 49.68% 91.67%2 21.94% 7.30%3 10.94% 0.82%4 6.55% 0.15%more than 4 10.89% 0.06%Table 1 The ambiguity distribution of monosyllabic andmultisyllabic wordsThe remainder of this paper is organized in the fol-lowing manner: section 2 introduces the CiLin the-saurus, section 3 provides an analysis of unknownwords in the Sinica Corpus, and section 4 detailsthe algorithm used for the semantic classificationand explains the results.3 ?Monosyllabic word?
means a word with only a char-acter, and ?multisynllabic word?
means a word withmore than one character.4 ?Word Class?
means the number of each word?s wordclass.2 The CiLin thesaurusThe CiLin (Mei et al1986) is a thesaurus that con-tains 12 main categories: A-human, B-object, C-time and space, D-abstract, E-attribute, F-action,G-mental action, H-activity, I-state, J-association,K-auxiliary, and L-respect.
The majority of wordsin the A-D categories are nouns, while the majorityin the F-J categories are verbs.
As shown in Figure1, the main categories are further subdivided intomore specific subcategories in a three-tier hierar-chy.B Object0.1636Bn Building0.0174Bm Material0.0128Bl Excrement0.0036Bk The wholebody0.0135BjMicroorganism0.0013Bi Animal0.0179Bh Plant0.0064Bh07 Fruit0.0003Bh06Vegetable0.0003Bh01 Tree0.0005Fanqie(tomato)Hamigua(hami melon)Word levelConcept level1Concept level 2Concept level 3Figure 1 The taxonomy of the CiLin with the probabil-ity (partial)3 Corpus analysis of Chinese unknownwords3.1 Definition of unknown wordsUnknown words are the Sinica Corpus lexiconsthat are not listed in the Chinese Electronic Dic-tionary of 80,000 lexicons and the CiLin.
The 5million word Sinica Corpus contains 77,866 un-known words consisting of 1.59% adjectives,33.73% common nouns, 25.18% proper nouns,12.48% location nouns, 2.98% time nouns, and24.04% verbs as shown in Table 2.The focus of most other Chinese unknown wordresearch is on identification of proper nouns suchas proper names (Lee 1993), personal names (Lee,Lee and Chen 1994), abbreviation (Huang, Hongand Chen 1994), and organization names (Chen &Chen 2000).
Unknown words in categories outsidethe class of proper nouns are seldom mentioned.One of the few examples of multiple class wordprediction is Chen, Bai and Chen?s 1997 work em-ploying statistical methods based on the prefix-category and suffix-category associations to pre-dict the syntactic function of unknown words.
Al-though proper nouns may contain lots of useful andvaluable information in a sentence, the majority ofunknown words in Chinese are lexical words, andconsequently, it is also important to classify lexicalwords.
If not, the remaining 70% of unknownwords5 will be an obstacle to Chinese NLP, where24.04% of verbs are unknown can be a major prob-lem for parsers.Class Unknown words Corpus lexicons6Adjective 1.59% 1.49%Common noun 33.73% 37.12%Proper noun7 25.18% 16.53%Location noun8 12.48% 10.38%Time noun9 2.98% 2.36%Verb 24.04% 32.11%Table 2 The distribution of unknown words and all lexi-cons of the Sinica Corpus in 6 classes3.2 Types of unknown wordsIn Chinese morphology, the two ways to generatenew words are compounding and affixation.CompoundsA compound is a word made up of other words.
Ingeneral, Chinese compounds are made up of words5 Part of location noun still contains some proper nounslike country names.6 It contains both known and unknown words.7 Proper noun contains two classes: 1) formal name,such as personal names, races, titles of magazines andso on.
2) Family name, such as Chen and Lee.8 Location noun contains 4 subclasses: 1) country names,such as China.
2) common location noun, such as?
?/youju ?post office?
and?
?/xuexiao ?school?.
3) noun+ position, such as?
?/haiwei ?oversea?.
4) directionnoun, such as?/shang ?up?
and?/xia ?down?.9 Time noun contains 3 classes: 1) historical event andrecursive time noun, such as?/Qing dynasty and?
?/yiyue ?January?.
2) noun + position, such as?
?/wanjian ?in the evening?, 3) adverbial time noun, suchas?
?/jianglai ?in the future?.that are linked together by morpho-syntactic rela-tions such as modifier-head, verb-object, and so on(Chao 1968, Li and Thompson 1981).
For example,??
?/guanghuanjue LIGHT-ILLUSION ?opticalillusion?, consists of ?/guang ?light?
and  ?
?/huanjue ?illusion?, and the relation is modifier-head.
??
?/ guangguomin LIGHT-ALLERGY?photosensitization?
is made up of?/ guang ?light?and ??
/ guomin ?allergy?, and the relation ismodifier-head.AffixationA word is formed by affixation when a stem iscombined with a prefix or a suffix morpheme.
Forexample English suffixes such as -ian and -ist areused to create words referring to a person with aspecialty, such as `musician' and `scientist'.
Suchsuffixes can give very specific evidence for thesemantic class of the word.
Chinese has suffixeswith similar meanings to -ian or -ist, such as theChinese suffix -jia.
But the Chinese affix is a muchweaker cue to the semantic category of the wordthan English -ist or -ian, because it is more am-biguous.
The suffix ?jia contains three major con-cepts: 1) expert, such as ?
?
?
/kexuejiaSCIENCE-EXPERT ?scientist?
and ?
?
?
/yinyuejia MUSIC-EXPERT ?musician?, 2) familyand home, such as ?
?
/quanjia WHOLE-FAMILY ?whole family?
and ???
/fuguijiaRICH-FAMILY ?rich family?, 3) house, such as ??
/banjia MOVE-HOUSE ?to move house?.
InEnglish, the meaning of an unknown word with thesuffix ?ian or ?ist is clear, but in Chinese an un-known word with the suffix ?jia could have multi-ple interpretations.
Another example of ambiguoussuffix, ?xing, has three main concepts: 1) gender,such as ?
?/nuxing FEMALE-SEX ?female?, 2)property, such as ?
?
/yaoxing MEDICINE-PROPERTY ?property of a medicine?, 3) a charac-teristic, ????
/shishachengxing LIKE-KILL-AS-HABIT ?a characteristic of being bloodthirsty?.Even though Chinese also has morphological suf-fixes to generate unknown words, they do not de-termine meaning and syntactic category as clearlyas they do in English.4 Semantic classificationFor the task of classifying unknown words, twoalgorithms are evaluated.
The first algorithm uses asimple heuristic where the semantic category of anunknown word is determined by the head of theunknown word.
The second algorithm adopts amore sophisticated nearest neighbor approach suchthat the distance between an unknown word andexamples from the CiLin thesaurus computedbased upon its morphological structure.
The firstalgorithm serves to provide a baseline againstwhich the performance of the second can be evalu-ated.4.1 BaselineThe baseline method is to assign the semanticcategory of the morphological head to each word.4.2 An example-base semantic classificationThe algorithm for the nearest neighbor classifier isas follows:1) An unknown word is parsed by a morphologicalanalyzer (Tseng and Chen 2002).
The analyzer a)segments a word into a sequence of morphemes, b)tags the syntactic categories of morphemes, and c)predicts morpho-syntactic relationships betweenmorphemes, such as modifier-head, verb-objectand resultative verbs as shown as in Table 3.
Forexample, if ???
/wudaojia DANCE-EXPERT?dancer?
is an unknown word, the morphologicalsegmentation is ?
?/wudao DANCE ?dance?
and?/jia EXPERT ?expert?, and the relation is modi-fier-head.2) The CiLin thesaurus is then searched for entries(examples) that are similar to the unknown word.A list of words sharing at least one morpheme withthe unknown word, in the same position, is con-structed.
In the case of ??
?/wudaojia, such alist would include ?
?
?
/gechangjia SING-EXPERT ?singer?, ??
/huijia GO-HOME ?gohome?, ??
?/fuguijia RICH-FAMILY ?rich fam-ily?
and so on.WordClassThe morpho-syntactic relationsNoun Modifier-head10?
?/lanqieBASKET-BALL `baseketball?Verb 1) Verb-object :?
?/chifanEAT-RICE ?to eat`2) Modifier-head:?
?/qinglie CLEAR-LIST ?clearly list?3) Resultative Verb?
?/chibao EAT-FULL ?to have eaten?4) Head-suffix:?
?/biancheng CHANG-TO ?become?5) Modifier-head (suffix):??
?/zidonghuaAUTOMATIC-BECOME ?automatize?6) Directional resultative compound andreduplication??
?/paoshanglaiRUN-UP-TO ?run up to?Adjective An: modifier-head??
?/zhongguoshiCHINESE-STYLE ?Chinese stylish?Av: verb-object and modifier-head?
?/yuminFOOL-PEOPLE ?keeping the people unin-formed?Table 3 The morpho-syntactic relations3) The examples that do not have the same mor-pho-syntactic relationships but shared morphemebelongs to the unknown word?s modifier arepruned away.
If no examples are found, the systemfalls back to the baseline classification method.4) The semantic similarity metric used to computethe distance between the unknown word and theselected examples from the CiLin thesaurus isbased upon a method first proposed by Chen andChen (1997).They assume that similarity of two semantic cate-gories is the information content of their parent?s10There are still a very small number of coordinate rela-tion compounds that is both of the morphemes in acompound are heads.
Since either one of the morphemescan be the meaning of the whole compound, in order tosimplify the system, words that have coordinate rela-tions are categorized as modifier head relation.node.
For instance, the similarity of ??
?/hamigua ?hami melon?
(Bh07) and ??
/fanqie?tomato?
(Bh06) is based on the information con-tent of the node of their least common ancestor Bh.The CiLin thesaurus can be used as an informationsystem, and the information content of each se-mantic category is defined ascategory) manticEntropy(Sestem)Entropy(Sy ?The similarity of two words is the least commonancestor information content(IC), and hence, thehigher the information content is, the more similartwo the words are.
The information content isnormalized by Entropy(system) in order to keepthe similarity between 0 and 1.
To simplify thecomputation, the probabilities of all leaf nodes areassumed equal.
For example, the probability of Bhis .0064 and the information content of Bh is ?log(.0064).
Hence, the similarity between??
?/hamigua and ?
?/ fanqie is .61.
( ) ( )( )( )( )( ) )1(             SystemEntropyPlogSystemEntropyIC Sim 2122121WWWWWW III ?==fanqie) ofcategory  (the Bh06hamihua), ofcategory  (the Bh07CiLin,SystemLet21===WW( ) ( )( )( )( )( )0.6111.947.290.0026log-0.0064log-CiLinEntropyBhPlogCiLinEntropyBh06Bh07 ICBh06Bh07 Sim222===?== IIResnik (1995, 1998 and 2000) and Lin (1998) alsoproposed information content algorithms for simi-larity measurement.
The Chen and Chen (1997)algorithm is a simplification of the Resnik algo-rithm, which makes the simplifying assumptionthat the occurrence probability of each leaf node isequal.One problem for this algorithm is the insufficientcoverage of the CiLin (CiLin may not cover allmorphemes).
The backup method is to run the clas-sifier recursively to predict the possible categoriesof the unlisted morphemes.
If a morpheme of anunknown word or of an unknown word?s exampleis not listed in the CiLin, the similarity measure-ment will suspend measuring the similarity be-tween the unknown word and the examples and runthe classifier to predict he semantic category of themorpheme first.
After the category of the mor-pheme is known, the classifier will continue tomeasure the similarity between the unknown wordand its examples.
The probability of adopting thisbackup method in my experiment is on the averageof 3%.Here is an example of the recursive semanticmeasurement.
???
/paomatou RUN-WHARF?wharf-worker?
is an example of an unknown word??
?/paohanchuan RUN-DRY BOAT ?folk ac-tivities?.
The morphological analyzer breaks thetwo words into ?
?
?/pao matou and ?
?
?/pao hanchuan.
The measurement function willcompute the similarity between?
?/matou and?
?/hanchuan, but in this case, ?
?/hanchuan isnot listed in the CiLin.
The next approach is thento run the semantic classifier to guess the possiblecategory of??/hanchuan.
Based on the predictedcategory, it then goes on to compute the similarityfor ?
?/matuo and ??/hanchuan.
By applyingthis method, there will not be any words without asimilarity measurement.5) After the distances from the unknown word toeach of the selected examples from the CiLin the-saurus are determined, the average distance to theK nearest neighbors from each semantic categoryis computed.
The category with the lowest distanceis assigned to the unknown word.The similarity of ?
?/wudao and ?
?/gechangis .87, of ?
?/wudao and ?/hui is .26, and of ??
/wudao and ??
/fugui is 0.
Thus, ??
?/wudaojia is more similar to ???
/gechangjiathan?
?/huijia or???/fuguijia.
The category of??
?/wudaojia is thus most likely to be ??
?/gechangjia.The semantic category is predicted as the categorythat gets the highest score in formula (2).
The lexi-cal similarity and frequency of examples of eachcategory are considered as the most important fea-tures to decide a category.In formula (2), RankScore(Ci) includes SS(Ci) andFS(Ci).
The score of SS(Ci) is a lexical similarityscore, which is from the maximum score of Simi-larity (W1,W2) in the category of W2.
FS(Ci) is afrequency score to show how many examples thereare in a category.
?
and (1-?)
are respectivelyweights for the lexical similarity score and the fre-quency score.
)Taxonomy  nA...L(CiLiCiLin   thein  definedcategory  semantic  whosewordwordunknownLet  1===iWWi( ) ( ) ( ) ( )( )( )( )( ) ( )( )(4)FreqFreqFS(3)                                           ,SimmaxargSS2)(                                FS?1SS?RankscoreLAi1A...LiC?==?==?
?+?=iiiiCWiiiiCCCWWCCCCii5 Experiment5.1 DataThere are 56,830 words in the CiLin.
For experi-ments, CiLin lexicons are divided into 2 sets: atraining set of 80% CiLin words, a developmentset of 10% of CiLin words, and a test set of 10%CiLin words.
All words in the test set are assumedto be unknown, which means the semantic catego-ries in both sets are unknown.
Nevertheless, themorphological structures of proper nouns are dif-ferent from lexical words.
Their identificationmethods are also different and will be out of thescope of this paper.
The correct category of theunknown word is the semantic category in theCiLin, and if an unknown word is ambiguous,which means it contains more than one category,the system then chooses only one possible category.In evaluation, any one of the categories of an am-biguous word is considered correct.5.2 ResultOn the test set, the baseline predicts 53.50% ofadjectives, 70.84% of nouns and 47.19% of verbscorrectly.
The classifier reaches 64.20% in adjec-tives, 71.77% in nouns and 53.47% in verbs, when?
is 0.5 and K is five.Word classBaselineaccuracySemantic classificationaccuracyAdjective 53.50% 64.20%Noun 70.84% 71.77%Verb 47.19% 53.47%Table 4 The accuracy of the baseline and semantic clas-sification in the development setWord classBaselineaccuracySemantic classificationaccuracyAdjective 52.92% 65.76%Noun 70.89% 71.39%Verb 44.10% 52.84%Table 5 The accuracy of the baseline and semantic clas-sification in the test setTable 4 and table 5 show a comparison of the base-line and the classifier.
Generally, nouns are easierto predict than the other categories, because theirmorpho-syntactic relation is not as complex asverbs and adjectives.
The classifier improves onbaseline semantic categorization performance foradjectives and verbs, but not for nouns.
The lack ofa performance increase for nouns is most likelybecause nouns only have one kind of morpho-syntactic relation.
The advantage of the classifier isto filter out examples in different relations and tofind out the most similar example in morphemesand morpho-syntactic relation.
The classifier pre-dicts better than the baseline in word classes withmultiple relations, such as adjectives and verbs.For example, ???
/kaikuaiche OPEN-FASTCAR ?drive fast?
is a verb-object verb.
The base-line wrongly predicted it due to the verb, ?/kaiOPEN ?open?.
However, the semantic classifiergrouped it to the category of its similar example,??
?/kaiyeche OPEN-NIGHT CAR ?drive dur-ing the night?.5.3 Error analysisError sources can be grouped into two types: dataerrors and the classifier errors.
The testing data isfrom the CiLin.
Some of testing data are not se-mantically transparent such as idioms, metaphors,and slang.
The meaning of such words is differentfrom the literal meaning.
For instance, the literalmeaning of ??
?/kanmengou WATCH-DOOR-DOG is a door-watching dog, and in fact it refersto a person with the belittling meaning.
??
?/mulaohu FEMALE-TIGER is a female tiger liter-ally, and it refers to a mean woman.
These wordsdo not carry the meaning of their head anymore.An unknown word will be created such as ??
?/kanmenmao WATCH-DOOR-CAT ?a door-watching cat?, but it is impossible for unknownwords to carry similar meaning of words as??
?/kanmengou.The classifier errors are due primarily to three fac-tors: a lack of examples, the preciseness of thesimilarity measurement, and the taxonomy of theCiLin.First, some errors occur when there are not enoughexamples in training data.
For example, ??
?/tielangan IRON-POLE ?iron pole` does not haveany similar examples after the classifier filters outexamples whose relations are different and whoseshared morphemes are not head.
??
?/tielanganis segmented as ?
/tie IRON ?iron?
and ?
?/langan POLE ?pole?.
There are examples of thefirst morpheme, ?/tie, but no similar examples ofthe second,??
/langan.
Since ???
/tielanganhas modifier-head relation and ?
?/langan is thehead of the compound, then the classifier filters outthe examples of?/tie.
There are hence not enoughexamples.
Filtering examples in different structuresis performed to make the remaining examplesmore similar since the similarity measurement maynot be able to distinguish slight differences.
How-ever, the cost of this filtering of different structureexamples is that sometimes this leaves no exam-ples.Second, the similarity measurement is sometimesnot powerful enough.
?
?
?
/yundongchangSPORT-SPACE ?a sports ground` has a sufficientnumber of examples, but has problems with thesimilarity measurement.
The head ?/chang is am-biguous.
?/chang has two senses and both meanspace.
One of them means abstract space and theother means physical space.
Hence, in the CiLinthesaurus ?/chang can be found in C (time andspace) and D (abstract).
Words in C such as ?
?/shangchang BUSINESS-SPACE ?a market?, ???
/tuzaichang BUTCHER-SPACE ?a slaughterhouse?
, ??
/huichang MEETING-SPACE ?theplace of a meeting?, and in D are ?
?/ qiuchangBALL-SPACE ?a court?, ?
?
?
/tiyuchangPHYSICAL TRAINING-SPACE ?a stadium?.
??
?/yundongchang should be more similar to ??
?/tiyuchang than other space nouns, but the simi-larity score does not show that they are related andC group has more examples.
Thus, the systemchooses C incorrectly.Third, the taxonomy of the thesaurus is ambiguous.For instance, ??
?/tichaofang GYMNASTICS?ROOM ?gymnastics room?
has similar examples inboth B (object) and D (abstract).
These two groupsare very similar.
Words in B group include ?
?/xingfan PUNISHMENT-ROOM ?punishmentroom?, ?
?/shufan BOOK-ROOM ?study room?,?
?/anfan DARK-ROOM ?dark room?, and ?
?/chufan KITCHEN-ROOM ?kitchen?.
Words in Dare such as ?
?/laofan PRISON-ROOM ?a jail?and ???
/danzifan BILLIARD-ROOM ?a bil-liard room?.
There are no obvious features to dis-tinguish between these examples.
According to theCiLin, ???
/tichaofang belongs to D, but theclassifier predicts it as B class which does not ac-tually differ much with D. Such problems may oc-cur with any semantic taxonomy.6 ConclusionThe paper presents an algorithm for classifying theunknown words semantically.
The classifier adoptsa nearest neighbor approach such that the distancebetween an unknown word and examples from theCiLin thesaurus is computed based upon its mor-phological structure.
The main contributions of thesystem are: first, it is the first attempt in addingsemantic knowledge to Chinese unknown words.Since over 70% of unknown words are lexicalwords, the inability to resolve their meaning is amajor obstacle to Chinese NLP such as semanticparsers.
Second, without contextual information,the system can still successfully classify 65.76% ofadjectives, 71.39% of nouns and 52.84% of verbs.Future work will explore the use of the contextualinformation of the unknown words and the contex-tual information of the lexicons in the predictedcategory of the unknown words to boost predictivepower.AcknowledgmentThanks to S. Bethard, D. Cer, K. J. Chen, D. Juraf-sky and to the anonymous reviewers for manyhelpful suggestions.
This research was partiallysupported by the NSF via a KDD extension to NSFIIS-9978025 (Dan Jurafsky, PI) and by the CKIPgroup, Institute of Information Science, AcademiaSinica.ReferencesBai, M. H., C.J.
Chen, and K. J. Chen.
1998.
?????????????
?
<???????????????>???????????????????
47-60?Caraballo, S. 1999.
Automatic acquisition of ahypemymlabeled noun hierarchy from text, inProceedings of the 37th ACL.Ciaramita.
M. 2002.
Boosting automatic lexical acquisi-tion with morphological information", in Proceedingsof the Workshop on Unsupervised Lexical Acquisi-tion, ACL-02.Chao, Y. R. 1968.
A grammar of spoken Chinese.Berkeley:University of California Press.Chen, C. J., M. H. Bai and K. J. Chen.
1997.
CategoryGuessing for Chinese Unknown Words, in Proceed-ings of the Natural Language Processing Pacific RimSymposium, 35-40.Lee, J. C. 1993.
?????
??????????????????????????????????
?Lee, J. C., Y. H. Lee and H. H. Chen.
1994.
??????????????????????????????<??????????????>??203-222?Chen.
K. J. and C. J Chen.
1997.
??????????<??????????????????>?????????????????????????????????
283-305????????
?Chen, K. J. and M. H. Bai.
1998.
Unknown WordDetection for Chinese by a Corpus-based LearningMethod, in Computational Linguistics and ChineseLanguage Processing vol3 no.
1, 27-44.Chen, C. J. and K. J. Chen.
2002.
Knowledge Extractionfor Identification of Chinese Organization Names, inProceedings of the second Chinese Language Proc-essing Workshop, 15-21.Huang, C. R., W. M. Hong and K. J. Chen.
1994.
AnIntroduction Based Lexical of Abbreviation, in Pro-ceedings of the 2th Pacific Asia Conference on For-mal and Computational Linguistics, 49-52.Huang, C. R. and K. J. Chen.
1995.
????
????
?????????????????????
?Li, C. and S. A. Thompson.
1981.
Mandarin Chinese.Berkeley: University of California Press.Lin, D.. 1998.
An information-theoretic definition ofsimilarity, in Proceedings 15th International Conf.
onMachine Learning, p 296?304.Lin, D. and P. Pantel.. 2001.
Induction of SemanticClasses from Natural Language Text, In Proceedingsof ACM SIGKDD Conference on Knowledge Dis-covery and Data Mining 2001, 317-322.Mei, J., Y.
Zhu., Y. Gao, and H. Ying.
1986.
??????????????????1986??????????????????
?Resnik, P.. 1995.
Using Information Content to Evalu-ate Semantic Similarity in a Taxonomy.
Proceedingsof the 14th International Joint Conference on Artifi-cial Intelligence, pp.
448-453.---.
1998.
Semantic Similarity in a Taxonomy: An In-formation-Based Measure and its Application toProblems of Ambiguity in Natural Language, inJournal of Artificial Intelligence Research (11), 95-130.Resnik, P. and M. Diab.
2000.
Measuring Verbal Simi-larity.
Technical Report: LAMP-TR-047//UMIACS-TR-2000-40/CS-TR-4149/MDA-9049-6C-1250.University of Maryland, College Park.Roark, B. and E. Charniak.
1998.
Noun-phrase co-occurrence statistics from semi-automatic semanticlexicon construction, in Proceedins of the 36th ACL.Tseng, H and K. J. Chen.
2002.
Design of ChineseMorphological Analyzer.
SigHan Workshop on Chi-nese Language Processing, Taipei.
