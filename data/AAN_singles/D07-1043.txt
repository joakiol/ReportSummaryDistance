Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and ComputationalNatural Language Learning, pp.
410?420, Prague, June 2007. c?2007 Association for Computational LinguisticsV-Measure: A conditional entropy-based external cluster evaluationmeasureAndrew Rosenberg and Julia HirschbergDepartment of Computer ScienceColumbia UniversityNew York, NY 10027{amaxwell,julia}@cs.columbia.eduAbstractWe present V-measure, an external entropy-based cluster evaluation measure.
V-measure provides an elegant solution tomany problems that affect previously de-fined cluster evaluation measures includ-ing 1) dependence on clustering algorithmor data set, 2) the ?problem of matching?,where the clustering of only a portion of datapoints are evaluated and 3) accurate evalu-ation and combination of two desirable as-pects of clustering, homogeneity and com-pleteness.
We compare V-measure to a num-ber of popular cluster evaluation measuresand demonstrate that it satisfies several de-sirable properties of clustering solutions, us-ing simulated clustering results.
Finally, weuse V-measure to evaluate two clusteringtasks: document clustering and pitch accenttype clustering.1 IntroductionClustering techniques have been used successfullyfor many natural language processing tasks, suchas document clustering (Willett, 1988; Zamir andEtzioni, 1998; Cutting et al, 1992; Vempala andWang, 2005), word sense disambiguation (Shin andChoi, 2004), semantic role labeling (Baldewein etal., 2004), pitch accent type disambiguation (Levow,2006).
They are particularly appealing for tasksin which there is an abundance of language dataavailable, but manual annotation of this data isvery resource-intensive.
Unsupervised clusteringcan eliminate the need for (full) manual annotationof the data into desired classes, but often at the costof making evaluation of success more difficult.External evaluation measures for clustering canbe applied when class labels for each data point insome evaluation set can be determined a priori.
Theclustering task is then to assign these data points toany number of clusters such that each cluster con-tains all and only those data points that are membersof the same class Given the ground truth class la-bels, it is trivial to determine whether this perfectclustering has been achieved.
However, evaluatinghow far from perfect an incorrect clustering solutionis a more difficult task (Oakes, 1998) and proposedapproaches often lack rigor (Meila, 2007).In this paper, we describe a new entropy-basedexternal cluster evaluation measure, V-MEASURE1 ,designed to address the problem of quantifying suchimperfection.
Like all external measures, V-measurecompares a target clustering ?
e.g., a manually an-notated representative subset of the available data ?against an automatically generated clustering to de-termine now similar the two are.
We introduce twocomplementary concepts, completeness and homo-geneity, to capture desirable properties in clusteringtasks.In Section 2, we describe V-measure and how itis calculated in terms of homogeneity and complete-ness.
We describe several popular external clusterevaluation measures and draw some comparisons toV-measure in Section 3.
In Section 4, we discusshow some desirable properties for clustering are sat-isfied by V-measure vs. other measures.
In Sec-tion 5, we present two applications of V-measure, ondocument clustering and on pitch accent type clus-tering.2 V-Measure and Its CalculationV-measure is an entropy-based measure which ex-plicitly measures how successfully the criteria of ho-mogeneity and completeness have been satisfied.
V-measure is computed as the harmonic mean of dis-tinct homogeneity and completeness scores, just as1The ?V?
stands for ?validity?, a common term used to de-scribe the goodness of a clustering solution.410precision and recall are commonly combined intoF-measure (Van Rijsbergen, 1979).
As F-measurescores can be weighted, V-measure can be weightedto favor the contributions of homogeneity or com-pleteness.For the purposes of the following discussion, as-sume a data set comprising N data points, and twopartitions of these: a set of classes, C = {ci|i =1, .
.
.
, n} and a set of clusters, K = {ki|1, .
.
.
,m}.Let A be the contingency table produced by the clus-tering algorithm representing the clustering solution,such that A = {aij} where aij is the number of datapoints that are members of class ci and elements ofcluster kj .To discuss cluster evaluation measures we intro-duce two criteria for a clustering solution: homo-geneity and completeness.
A clustering result sat-isfies homogeneity if all of its clusters contain onlydata points which are members of a single class.
Aclustering result satisfies completeness if all the datapoints that are members of a given class are elementsof the same cluster.
The homogenity and complete-ness of a clustering solution run roughly in opposi-tion: Increasing the homogeneity of a clustering so-lution often results in decreasing its completeness.Consider, two degenerate clustering solutions.
Inone, assigning every datapoint into a single cluster,guarantees perfect completeness ?
all of the datapoints that are members of the same class are triv-ially elements of the same cluster.
However, thiscluster is as unhomogeneous as possible, since allclasses are included in this single cluster.
In an-other solution, assigning each data point to a dis-tinct cluster guarantees perfect homogeneity ?
eachcluster trivially contains only members of a singleclass.
However, in terms of completeness, this so-lution scores very poorly, unless indeed each classcontains only a single member.
We define the dis-tance from a perfect clustering is measured as theweighted harmonic mean of measures of homogene-ity and completeness.Homogeneity:In order to satisfy our homogeneity criteria, aclustering must assign only those datapoints that aremembers of a single class to a single cluster.
That is,the class distribution within each cluster should beskewed to a single class, that is, zero entropy.
We de-termine how close a given clustering is to this idealby examining the conditional entropy of the classdistribution given the proposed clustering.
In theperfectly homogeneous case, this value, H(C|K),is 0.
However, in an imperfect situation, the size ofthis value, in bits, is dependent on the size of thedataset and the distribution of class sizes.
There-fore, instead of taking the raw conditional entropy,we normalize this value by the maximum reductionin entropy the clustering information could provide,specifically, H(C).Note that H(C|K) is maximal (and equals H(C))when the clustering provides no new information ?the class distribution within each cluster is equal tothe overall class distribiution.
H(C|K) is 0 wheneach cluster contains only members of a single class,a perfectly homogenous clustering.
In the degen-erate case where H(C) = 0, when there is only asingle class, we define homogeneity to be 1.
For aperfectly homogenous solution, this normalization,H(C|K)H(C) , equals 0.
Thus, to adhere to the conventionof 1 being desirable and 0 undesirable, we define ho-mogeneity as:h ={1 if H(C,K) = 01?
H(C|K)H(C) else(1)whereH(C|K) = ?|K|?k=1|C|?c=1ackN logack?|C|c=1 ackH(C) = ?|C|?c=1?|K|k=1 ackn log?|K|k=1 acknCompleteness:Completeness is symmetrical to homogeneity.
Inorder to satisfy the completeness criteria, a cluster-ing must assign all of those datapoints that are mem-bers of a single class to a single cluster.
To eval-uate completeness, we examine the distribution ofcluster assignments within each class.
In a perfectlycomplete clustering solution, each of these distribu-tions will be completely skewed to a single cluster.We can evaluate this degree of skew by calculat-ing the conditional entropy of the proposed clusterdistribution given the class of the component dat-apoints, H(K|C).
In the perfectly complete case,H(K|C) = 0.
However, in the worst case scenario,411each class is represented by every cluster with a dis-tribution equal to the distribution of cluster sizes,H(K|C) is maximal and equals H(K).
Finally, inthe degenerate case where H(K) = 0, when thereis a single cluster, we define completeness to be 1.Therefore, symmetric to the calculation above, wedefine completeness as:c ={1 if H(K,C) = 01 ?
H(K|C)H(K) else(2)whereH(K|C) = ?|C|?c=1|K|?k=1ackN logack?|K|k=1 ackH(K) = ?|K|?k=1?|C|c=1 ackn log?|C|c=1 acknBased upon these calculations of homogeneityand completeness, we then calculate a clusteringsolution?s V-measure by computing the weightedharmonic mean of homogeneity and completeness,V?
= (1+?)?h?c(?
?h)+c .
Similarly to the familiar F-measure, if ?
is greater than 1 completeness isweighted more strongly in the calculation, if ?
is lessthan 1, homogeneity is weighted more strongly.Notice that the computations of homogeneity,completeness and V-measure are completely inde-pendent of the number of classes, the number ofclusters, the size of the data set and the clustering al-gorithm used.
Thus these measures can be applied toand compared across any clustering solution, regard-less of the number of data points (n-invariance), thenumber of classes or the number of clusters.
More-over, by calculating homogeneity and completenessseparately, a more precise evaluation of the perfor-mance of the clustering can be obtained.3 Existing Evaluation MeasuresClustering algorithms divide an input data set intoa number of partitions, or clusters.
For tasks wheresome target partition can be defined for testing pur-poses, we define a ?clustering solution?
as a map-ping from each data point to its cluster assignmentsin both the target and hypothesized clustering.
In thecontext of this discussion, we will refer to the targetpartitions, or clusters, as CLASSES, referring only tohypothesized clusters as CLUSTERS.Two commonly used external measures for as-sessing clustering success are Purity and Entropy(Zhao and Karypis, 2001), defined as,Purity = ?kr=1 1n maxi(nir)Entropy = ?kr=1 nrn (?
1log q?qi=1nirnr lognirnr )where q is the number of classes, k the numberof clusters, nr is the size of cluster r, and nir is thenumber of data points in class i clustered in clusterr.Both these approaches represent plausable waysto evaluate the homogeneity of a clustering solution.However, our completeness criterion is not mea-sured at all.
That is, they do not address the ques-tion of whether all members of a given class are in-cluded in a single cluster.
Therefore the Purity andEntropy measures are likely to improve (increasedPurity, decreased Entropy) monotonically withthe number of clusters in the result, up to a degen-erate maximum where there are as many clusters asdata points.
However, clustering solutions rated highby either measure may still be far from ideal.Another frequently used external clustering eval-uation measure is commonly refered to as ?cluster-ing accuracy?.
The calculation of this accuracy isinspired by the information retrieval metric of F-Measure (Van Rijsbergen, 1979).
The formula forthis clustering F-measure as described in (Fung etal., 2003) is shown in Figure 3.Let N be the number of data points, C the set of classes, Kthe set of clusters and nij be the number of members of classci ?
C that are elements of cluster kj ?
K.F (C, K) =Xci?C|ci|N maxkj?K{F (ci, kj)} (3)F (ci, kj) =2 ?
R(ci, kj) ?
P (ci, kj)R(ci, kj) + P (ci, kj)R(ci, kj) =nij|ci|P (ci, kj) =nij|kj |Figure 1: Calculation of clustering F-measureThis measure has a significant advantage overPurity and Entropy, in that it does measure boththe homogeneity and the completeness of a cluster-ing solution.
Recall is calculated as the portion ofitems from class i that are present in cluster j, thusmeasuring how complete cluster j is with respect toclass i.
Similarly, Precision is calculated as the por-412Solution A Solution BF-Measure=0.5 F-Measure=0.5V-Measure=0.14 V-Measure=0.39Solution C Solution DF-Measure=0.6 F-Measure=0.6V-Measure=0.30 V-Measure=0.41Figure 2: Examples of the Problem of Matchingtion of cluster j that is a member of class i, thus mea-suring how homogenous cluster j is with respect toclass i.Like some other external cluster evaluation tech-niques (misclassification index (MI) (Zeng et al,2002), H (Meila and Heckerman, 2001), L (Larsenand Aone, 1999), D (van Dongen, 2000), micro-averaged precision and recall (Dhillon et al, 2003)),F-measure relies on a post-processing step in whicheach cluster is assigned to a class.
These techniquesshare certain problems.
First, they calculate thegoodness not only of the given clustering solution,but also of the cluster-class matching.
Therefore, inorder for the goodness of two clustering solutions tobe compared using one these measures, an identicalpost-processing algorithm must be used.
This prob-lem can be trivially addressed by fixing the class-cluster matching function and including it in the def-inition of the measure as in H .
However, a secondand more critical problem is the ?problem of match-ing?
(Meila, 2007).
In calculating the similarity be-tween a hypothesized clustering and a ?true?
cluster-ing, these measures only consider the contributionsfrom those clusters that are matched to a target class.This is a major problem, as two significantly differ-ent clusterings can result in identical scores.In figure 2, we present some illustrative examplesof the problem of matching.
For the purposes of thisdiscussion we will be using F-Measure as the mea-sure to describe the problem of matching, however,these problems affect any measure which requires amapping from clusters to classes for evaluation.In the figures, the shaded regions represent CLUS-TERS, the shapes represent CLASSES.
In a perfectclustering, each shaded region would contain all andonly the same shapes.
The problem of matchingcan manifest itself either by not evaluating the en-tire membership of a cluster, or by not evaluatingevery cluster.
The former situation is presented inthe figures A and B in figure 2.
The F-Measure ofboth of these clustering solutions in 0.6.
(The preci-sion and recall for each class is 35 .)
That is, for eachclass, the best or ?matched?
cluster contains 3 of 5elements of the class (Recall) and 3 of 5 elements ofthe cluster are members of the class (Precision).
Themake up of the clusters beyond the majority class isnot evaluated by F-Measure.
Solution B is a betterclustering solution than solution A, in terms of bothhomogeneity (crudely, ?each cluster contains fewer2classes?)
and completeness (?each class is containedin fewer clusters?).
Indeed, the V-Measure of so-lution B (0.387) is greater than that of solution A(0.135).
Solutions C and D represent a case in whichnot every cluster is considered in the evaluation ofF-Measure.
In this example, the F-Measure of bothsolutions is 0.5 (the harmonic mean of 35 and 37 ).
Thesmall ?unmatched?
clusters are not measured at allin the calculation of F-Measure.
Solution D is a bet-ter clustering than solution C ?
there are no incorrectclusterings of different classes in the small clusters.V-Measure reflects this, solution C has a V-measureof 0.30 while the V-measure of solution D is 0.41.A second class of clustering evaluation techniquesis based on a combinatorial approach which exam-ines the number of pairs of data points that are clus-tered similarly in the target and hypothesized clus-tering.
That is, each pair of points can either be 1)clustered together in both clusterings (N11), 2) clus-tered separately in both clusterings (N00), 3) clus-tered together in the hypothesized but not the tar-get clustering (N01) or 4) clustered together in thetarget but not in the hypothesized clustering (N10).Based on these 4 values, a number of measures havebeen proposed, including Rand Index (Rand, 1971),2Homogeneity is not measured by V-measure as a count ofthe number of classes contained by a cluster but ?fewer?
is anacceptable way to conceptualize this criterion for the purposesof these examples.413Adjusted Rand Index (Hubert and Arabie, 1985), ?statistic (Hubert and Schultz, 1976), Jaccard (Mil-ligan et al, 1983), Fowlkes-Mallows (Fowlkes andMallows, 1983) and Mirkin (Mirkin, 1996).
We il-lustrate this class of measures with the calculation ofRand Index.
Rand(C,K) = N11+N00n(n?1)/2 Rand Indexcan be interpreted as the probability that a pair ofpoints is clustered similarly (together or separately)in C and K .Meila (2007) describes a number of poten-tial problems of this class of measures posed by(Fowlkes and Mallows, 1983) and (Wallace, 1983).The most basic is that these measures tend not tovary over the interval of [0, 1].
Transformations likethose applied by the adjusted Rand Index and a mi-nor adjustment to the Mirkin measure (see Section4) can address this problem.
However, pair match-ing measures also suffer from distributional prob-lems.
The baseline for Fowlkes-Mallows varies sig-nificantly between 0.6 and 0 when the ratio of datapoints to clusters is greater than 3 ?
thus includ-ing nearly all real-world clustering problems.
Simi-larly, the Adjusted Rand Index, as demonstrated us-ing Monte Carlo simulations in (Fowlkes and Mal-lows, 1983), varies from 0.5 to 0.95.
This variancein the measure?s baseline prompts Meila to ask if theassumption of linearity following normalization canbe maintained.
If the behavior of the measure is sounstable before normalization can users reasonablyexpect stable behavior following normalization?A final class of cluster evaluation measures arebased on information theory.
These measures an-alyze the distribution of class and cluster member-ship in order to determine how successful a givenclustering solution is or how different two parti-tions of a data set are.
We have already examinedone member of this class of measures, Entropy.From a coding theory perspective, Entropy is theweighted average of the code lengths of each clus-ter.
Our V-measure is a member of this class of clus-tering measures.
One significant advantage that in-formation theoretic evaluation measures have is thatthey provide an elegant solution to the ?problem ofmatching?.
By examining the relative sizes of theclasses and clusters being evaluated, these measuresall evaluate the entire membership of each cluster ?not just a ?matched?
portion.Dom?s Q0 measure (Dom, 2001) uses conditionalentropy, H(C|K) to calculate the goodness of aclustering solution.
That is, given the hypothesizedpartition, what is the number of bits necessary torepresent the true clustering?However, this term ?
like the Purity andEntropy measures ?
only evaluates the homogene-ity of a solution.
To measure the completeness of thehypothesized clustering, Dom includes a model costterm calculated using a coding theory argument.
Theoverall clustering quality measure presented is thesum of the costs of representing the data (H(C|K))and the model.
The motivation for this approachis an appeal to parsimony: Given identical condi-tional entropies, H(C|K), the clustering solutionwith the fewest clusters should be preferred.
Domalso presents a normalized version of this term, Q2,which has a range of (0, 1] with greater scores beingrepresenting more preferred clusterings.Q0(C,K) = H(C|K)+1n|K|?k=1log(h(k) + |C| ?
1|C| ?
1)where C is the target partition, K is the hypothe-sized partition and h(k) is the size of cluster k.Q2(C,K) =1n?|C|c=1 log(h(c)+|C|?1|C|?1)Q0(C,K)We believe that V-measure provides two significantadvantages over Q0 that make it a more useful diag-nostic tool.
First, Q0 does not explicitly calculate thedegree of completeness of the clustering solution.The cost term captures some of this information,since a partition with fewer clusters is likely to bemore complete than a clustering solution with moreclusters.
However, Q0 does not explicitly addressthe interaction between the conditional entropy andthe cost of representing the model.
While this isan application of the minimum description length(MDL) principle (Rissanen, 1978; Rissanen, 1989),it does not provide an intuitive manner for assessingour two competing criteria of homogeneity and com-pleteness.
That is, at what point does an increase inconditional entropy (homogeneity) justify a reduc-tion in the number of clusters (completeness).Another information-based clustering measureis variation of information (V I) (Meila, 2007),V I(C,K) = H(C|K)+H(K|C).
V I is presented414as a distance measure for comparing partitions (orclusterings) of the same data.
It therefore does notdistinguish between hypothesized and target cluster-ings.
V I has a number of useful properties.
First,it satisfies the metric axioms.
This quality allowsusers to intuitively understand how V I values com-bine and relate to one another.
Secondly, it is ?con-vexly additive?.
That is to say, if a cluster is split,the distance from the new cluster to the original isthe distance induced by the split times the size ofthe cluster.
This property guarantees that all changesto the metric are ?local?
: the impact of splitting ormerging clusters is limited to only those clusters in-volved, and its size is relative to the size of theseclusters.
Third, VI is n-invariant: the number ofdata points in the cluster do not affect the value ofthe measure.
V I depends on the relative sizes of thepartitions of C and K , not on the number of pointsin these partitions.
However, V I is bounded by themaximum number of clusters in C or K , k?.
With-out manual modification however, k?
= n, whereeach cluster contains only a single data point.
Thus,while technically n-invariant, the possible values ofV I are heavily dependent on the number of datapoints being clustered.
Thus, it is difficult to com-pare V I values across data sets and clustering algo-rithms without fixing k?, as V I will vary over differ-ent ranges.
It is a trivial modification to modify V Isuch that it varies over [0,1].
Normalizing, V I bylog n or 1/2 log k?
guarantee this range.
However,Meila (2007) raises two potential problems with thismodification.
The normalization should not be ap-plied if data sets of different sizes are to be com-pared ?
it negates the n-invariance of the measure.Additionally, if two authors apply the latter normal-ization and do not use the same value for k?, theirresults will not be comparable.While V I has a number of very useful distanceproperties when analyzing a single data set across anumber of settings, it has limited utility as a generalpurpose clustering evaluation metric for use acrossdisparate clusterings of disparate data sets.
Ourhomogeneity (h) and completeness (c) terms bothrange over [0,1] and are completely n-invariant andk?-invariant.
Furthermore, measuring each as a ra-tio of bit lengths has greater intuitive appeal than amore opportunistic normalization.V-measure has another advantage as a clusteringevaluation measure over V I and Q0.
By evaluat-ing homogeneity and completeness in a symmetri-cal, complementary manner, the calculation of V-measure makes their relationship clearly observable.Separate analyses of homogeneity and complete-ness are not possible with any other cluster evalu-ation measure.
Moreover, by using the harmonicmean to combine homogeneity and completeness,V-measure is unique in that it can also prioritize onecriterion over another, depending on the clusteringtask and goals.4 Comparing Evaluation MeasuresDom (2001) describes a parametric technique forgenerating example clustering solutions.
He thenproceeds to define five ?desirable properties?
thatclustering accuracy measures should display, basedon the parameters used to generate the clustering so-lution.
To compare V-measure more directly to alter-native clustering measures, we evaluate V-measureand other measures against these and two additionaldesirable properties.The parameters used in generating a clustering so-lution are as follows.?
|C| The number of classes?
|K| The number of clusters?
|Knoise| Number of ?noise?
clusters;|Knoise| < |K|?
|Cnoise| Number of ?noise?
classes; |Cnoise| <|C|?
?
Error probability; ?
= ?1 + ?2 + ?3.?
?1 The error mass within ?useful?
class-clusterpairs?
?2 The error mass within noise clusters?
?3 The error mass within noise classesThe construction of a clustering solution beginswith a matching of ?useful?
clusters to ?useful?classes3.
There are |Ku| = |K| ?
|Knoise| ?useful?clusters and |Cu| = |C| ?
|Cnoise| ?useful?
classes.The claim is useful classes and clusters are matchedto each other and matched pairs contain more datapoints than unmatched pairs.
Probability mass of1 ?
?
is evenly distributed across each match.
Er-ror mass of ?1 is evenly distributed across each pair3The operation of this matching is omitted in the interest ofspace.
Interested readers should see (Dom, 2001).415of non-matching useful class/cluster pairs.
Noiseclusters are those that contain data points equallyfrom each cluster.
Error mass of ?2 is distributedacross every ?noise?-cluster/ ?useful?-class pair.
Weextend the parameterization technique described in(Dom, 2001) in with |Cnoise| and ?3.
Noise classesare those that contain data points equally from eachcluster.
Error mass of ?3 is distributed across every?useful?-cluster/?noise?-class pair.
An example so-lution, along with its generating parameters is givenin Figure 3.C1 C2 C3 Cnoise1K1 12 12 2 3K2 2 2 12 3Knoise1 4 4 4 0Figure 3: Sample parametric clustering solutionwith n = 60, |K| = 3, |Knoise| = 1, |C| =3, |Cnoise| = 1, ?1 = .1, ?2 = .2, ?3 = .1The desirable properties proposed by Dom aregiven as P1-P5 in Table 1.
We include two addi-tional properties (P6,P7) relating the examined mea-sure value to the number of ?noise?
classes and ?3.P1 For |Ku| < |C| and ?|Ku| ?
(|C| ?
|Ku|),?M?|Ku| > 0P2 For |Ku| ?
|C|, ?M?|Ku| < 0P3 ?M?|Knoise| < 0, if ?2 > 0P4 ?M?
?1 ?
0, with equality only if |Ku| = 1P5 ?M?
?2 ?
0, with equality only if |Knoise| = 0P6 ?M?|Cnoise| < 0, if ?3 > 0P7 ?M?
?3 ?
0, with equality only if |Cnoise| = 0Table 1: Desirable Properties of a cluster evaluationmeasure MTo evaluate how different clustering measures sat-isfy each of these properties, we systematically var-ied each parameter, keeping |C| = 5 fixed.?
|Ku|: 10 values: 2, 3,. .
.
, 11?
|Knoise|: 7 values: 0, 1,. .
.
, 6?
|Cnoise|: 7 values: 0, 1,. .
.
, 6?
?1: 4 values: 0, 0.033, 0.066, 0.1?
?2: 4 values: 0, 0.066, 0.133, 0.2?
?3: 4 values: 0, 0.066, 0.133, 0.2We evaluated the behavior of V-Measure, Rand,Mirkin, Fowlkes-Mallows, Gamma, Jaccard, VI,Q0, F-Measure against the desirable properties P1-P74.
Based on the described systematic modificationof each parameter, only V-measure, VI and Q0 em-pirically satisfy all of P1-P7 in all experimental con-ditions.
Full results reporting how frequently eachevaluated measure satisfied the properties based onthese experiments can be found in table 2.All evaluated measures satisfy P4 and P7.
How-ever, Rand, Mirkin, Fowlkes-Mallows, Gamma, Jac-card and F-Measure all fail to satisfy P3 and P6 inat least one experimental configuration.
This indi-cates that the number of ?noise?
classes or clusterscan be increased without reducing any of these mea-sures.
This implies a computational obliviousness topotentially significant aspects of an evaluated clus-tering solution.5 Applying V-measureIn this section, we present two clustering experi-ments.
We describe a document clustering experi-ment and evaluate its results using V-measure, high-lighting the interaction between homogeneity andcompleteness.
Second, we present a pitch accenttype clustering experiment.
We present results fromboth of these experiments in order to show how V-measure can be used to drawn comparisons acrossdata sets.5.1 Document ClusteringClustering techniques have been used widely to sortdocuments into topic clusters.
We reproduce suchan experiment here to demonstrate the usefulnessof V-measure.
Using a subset of the TDT-4 cor-pus (Strassel and Glenn, 2003) (1884 English newswire and broadcast news documents manually la-beled with one of 12 topics), we ran clusteringexperiments using k-means clustering (McQueen,1967) and evaluated the results using V-Measure,VI and Q0 ?
those measures that satisfied the de-sirable properties defined in section 4.
The top-ics and relative distributions are as follows: Acts4The inequalities in the desirable properties are inverted inthe evaluation of VI, Q0 and Mirkin as they are defined as dis-tance, as opposed to similarity, measures.416Property Rand Mirkin Fowlkes ?
Jaccard F-measure Q0 VI V-MeasureP1 0.18 0.22 1.0 1.0 1.0 1.0 1.0 1.0 1.0P2 1.0 1.0 0.76 1.0 0.89 0.98 1.0 1.0 1.0P3 0.0 0.0 0.30 0.19 0.21 0.0 1.0 1.0 1.0P4 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0P5 0.50 0.57 1.0 1.0 1.0 1.0 1.0 1.0 1.0P6 0.20 0.20 0.41 0.26 0.52 0.87 1.0 1.0 1.0P7 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0Table 2: Rates of satisfaction of desirable propertiesof Violence/War (22.3%), Elections (14.4%), Diplo-matic Meetings (12.9%), Accidents (8.75%), Natu-ral Disasters (7.4%), Human Interest (6.7%), Scan-dals (6.5%), Legal Cases (6.4%), Miscellaneous(5.3%), Sports (4.7), New Laws (3.2%), Science andDiscovery (1.4%).We employed stemmed (Porter, 1980), tf*idf-weighted term vectors extracted for each documentas the clustering space for these experiments, whichyielded a very high dimension space.
To reducethis dimensionality, we performed a simple featureselection procedure including in the feature vectoronly those terms that represented the highest tf*idfvalue for at least one data point.
This resulted in afeature vector containing 484 tf*idf values for eachdocument.
Results from k-means clustering are areshown in Figure 4.00.10.20.30.40.51  10  100  100033.544.555.5V-measureandQ2valuesVIvaluesnumber of clustersV-MeasureVIQ2Figure 4: Results of document clustering measuredby V-Measure, VI and Q2The first observation that can be drawn from theseresults is the degree to which VI is dependent on thenumber of clusters (k).
This dependency severelylimits the usefulness of VI: it is inappropriate in se-lecting an appropriate parameter for k or for evalu-ating the distance between clustering solutions gen-erated using different values of k.V-measure and Q2 demonstrate similar behaviorin evaluating these experimental results.
They bothreach a maximal value with 35 clusters, however, Q2shows a greater descent as the number of clusters in-creases.
We will discuss this quality in greater detailin section 5.2.5.2 Pitch Accent ClusteringPitch accent is how speakers of many languagesmake a word intonational prominent.
In mostpitch accent languages, words can also be ac-cented in different ways to convey different mean-ings (Hirschberg, 2002).
In the ToBI labeling con-ventions for Standard American English (Silvermanet al, 1992), for example, there are five different ac-cent types (H*, L*, H+!H*, L+H*, L*+H).We extracted a number of acoustic features fromaccented words within the read portion of the BostonDirections Corpus (BDC) (Nakatani et al, 1995) andexamined how well clustering in these acoustic di-mensions correlates to manually annotated pitch ac-cent types.
We obtained a very skewed distribution,with a majority of H* pitch accents.5 We there-fore included only a randomly selected 10% sampleof H* accents, providing a more even distributionof pitch accent types for clustering: H* (54.4%),L*(32.1%), L+H* (26.5%), L*+H (2.8%), H+!H*(2.1%).We extracted ten acoustic features from each ac-cented word to serve as the clustering space forthis experiment.
Using Praat?s (Boersma, 2001) GetPitch (ac)... function, we calculated the mean F0and ?F0, as well as z-score speaker normalized ver-sions of the same.
We included in the feature vectorthe relative location of the maximum pitch value inthe word as well as the distance between this max-5Pitch accents containing a high tone may also be down-stepped, or spoken in a compressed pitch range.
Here we col-lapsed all DOWNSTEPPED instances of each pitch accent withthe corresponding non-downstepped instances.417imum and the point of maximum intensity.
Finally,we calculated the raw and speaker normalized slopefrom the start of the word to the maximum pitch, andfrom the maximum pitch to the end of the word.Using this feature vector, we performed k-meansclustering and evaluate how successfully these di-mensions represent differences between pitch accenttypes.
The resulting V-measure, VI and Q0 calcula-tions are shown in Figure 5.00.050.10.150.21  10  100  10002345678V-measureandQ2valuesVIvaluesnumber of clustersVIV-measureQ2Figure 5: Results of pitch accent clustering mea-sured by V-Measure, VI and Q0In evaluating the results from these experiments,Q2 and V-measure reveal considerably different be-haviors.
Q2 shows a maximum at k = 10, and de-scends at k increases.
This is an artifact of the MDLprinciple.
Q2 makes the claim that a clustering so-lution based on fewer clusters is preferable to oneusing more clusters, and that the balance betweenthe number of clusters and the conditional entropy,H(C|K), should be measured in terms of codinglength.
With V-measure, we present a different argu-ment.
We contend that the a high value of k does notinherently reduce the goodness of a clustering solu-tion.
Using these results as an example, we find thatat approximately 30 clusters an increase of clusterstranslates to an increase in V-Measure.
This is due toan increased homogeneity (H(C|K)H(C) ) and a relativelystable completeness (H(K|C)H(K) ).
That is, inclusion ofmore clusters leads to clusters with a more skewedwithin-cluster distribution and a equivalent distribu-tion of cluster memberships within classes.
This isintuitively preferable ?
one criterion is improved, theother is not reduced ?
despite requiring additionalclusters.
This is an instance in which the MDL prin-ciple limits the usefulness of Q2.
We again (see sec-tion 5.1) observe the close dependency of VI and k.Moreover, in considering figures 5 and 4, simulta-neously, we see considerably higher values achievedby the document clustering experiments.
Given thena?
?ve approaches taken in these experiments, this isexpected ?
and even desired ?
given the previouswork on these tasks: document clustering has beennotably more successfully applied than pitch accentclustering.
These examples allow us to observe howtransparently V-measure can be used to compare thebehavior across distinct data sets.6 ConclusionWe have presented a new external cluster evaluationmeasure, V-measure, and compared it with existingclustering evaluation measures.
V-measure is basedupon two criteria for clustering usefulness, homo-geneity and completeness, which capture a cluster-ing solution?s success in including all and only data-points from a given class in a given cluster.
We havealso demonstrated V-measure?s usefulness in com-paring clustering success across different domainsby evaluating document and pitch accent cluster-ing solutions.
We believe that V-measure addressessome of the problems that affect other cluster mea-sures.
1) It evaluates a clustering solution indepen-dent of the clustering algorithm, size of the data set,number of classes and number of clusters.
2) It doesnot require its user to map each cluster to a class.Therefore, it only evaluates the quality of the cluster-ing, not a post-hoc class-cluster mapping.
3) It eval-uates the clustering of every data point, avoiding the?problem of matching?.
4) By evaluating the criteriaof both homogeneity and completeness, V-measureis more comprehensive than those that evaluate onlyone.
5) Moreover, by evaluating these criteria sepa-rately and explicitly, V-measure can serve as an el-egant diagnositic tool providing greater insight intoclustering behavior.AcknowledgmentsThe authors thank Kapil Thadani, Martin Janscheand Sasha Blair-Goldensohn and for their feedback.This work was funded in part by the DARPA GALEprogram under a subcontract to SRI International.418ReferencesUlrike Baldewein, Katrin Erk, Sebastian Pado, and DetlefPrescher.
2004.
Semantic role labelling with similarity-based generalization using EM-based clustering.
In Pro-ceedings of Senseval?04, Barcelona.Paul Boersma.
2001.
Praat, a system for doing phonetics bycomputer.
Glot International, 5(9-10):341?345.Douglass R. Cutting, Jan O. Pedersen, David Karger, andJohn W. Tukey.
1992.
Scatter/gather: A cluster-based ap-proach to browsing large document collections.
In Proceed-ings of the Fifteenth Annual International ACM SIGIR Con-ference on Research and Development in Information Re-trieval, pages 318?329.I.
S. Dhillon, S. Mallela, and D. S. Modha.
2003.
Information-theoretic co-clustering.
In Proceedings of The Ninth ACMSIGKDD International Conference on Knowledge Discoveryand Data Mining(KDD-2003), pages 89?98.Byron E. Dom.
2001.
An information-theoretic externalcluster-validity measure.
Technical Report RJ10219, IBM,October.E.
B. Fowlkes and C. L. Mallows.
1983.
A method for com-paring two hierarchical clusterings.
Journal of the AmericanStatistical Association, 78:553?569.Benjamin C. M. Fung, Ke Wang, and Martin Ester.
2003.
Hi-erarchical document clustering using frequent itemsets.
InProc.
of the SIAM International Conference on Data Min-ing.Julia Hirschberg.
2002.
The pragmatics of intonational mean-ing.
In Proc.
Speech Prosody, pages 65?68.L.
Hubert and P. Arabie.
1985.
Comparing partitions.
Journalof Classification, 2:193?218.L.
Hubert and J. Schultz.
1976.
Quadratic assignment as a gen-eral data analysis strategy.
British Journal of Mathematicaland Statistical Psychology, 29:190?241.Bjornar Larsen and Chinatsu Aone.
1999.
Fast and effectivetext mining using linear-time document clustering.
In KDD?99: Proceedings of the fifth ACM SIGKDD internationalconference on Knowledge discovery and data mining, pages16?22, New York, NY, USA.
ACM Press.Gina-Anne Levow.
2006.
Unsupervised and semi-supervisedlearning of tone and pitch accent.
In Proceedings of the mainconference on Human Language Technology Conference ofthe North American Chapter of the Association of Compu-tational Linguistics, pages 224?231, Morristown, NJ, USA.Association for Computational Linguistics.J.
McQueen.
1967.
Some methods for classification and analy-sis of multivariate observations.
In Proc.
of the Fifty Berke-ley Symposium on Mathematical Statistics and Probability,pages 281?297.Marina Meila and David Heckerman.
2001.
An experimen-tal comparison of model-based clustering methods.
Mach.Learn., 42(1/2):9?29.Marina Meila.
2007.
Comparing clusterings ?
an informationbased distance.
Journal of Multivariate Analysis, 98:873?895.G.
W. Milligan, S. C. Soon, and L. M. Sokol.
1983.
The ef-fect of cluster size, dimensionality and the number of clusteson recovery of true cluster structure.
IEEE Transactions onPattern Analysis and Machine Intelligence, 5:40?47.Boris G. Mirkin.
1996.
Mathematical classification and clus-tering.
Kluwer Academic Press.Christine Nakatani, Julia Hirschberg, and Barbara Grosz.
1995.Discourse structure in spoken language: Studies on speechcorpora.
In Working Notes of AAAI-95 Spring Symposiomon Empirical Methods in Discourse Interpretation.Michael P. Oakes.
1998.
Statistics for Corpus Linguistics.
Ed-inburgh University Press.M.
Porter.
1980.
An algorithm for suffix stripping.
Program,14(3):130?137.William M. Rand.
1971.
Objective criteria for the evaluationof clustering methods.
Journal of the American StatisticalAssociation, 66(336):846?850, Dec.J.
Rissanen.
1978.
Modeling by shortest data description.
Au-tomatica, 14:465?471.J.
Rissanen.
1989.
Stochastic complexity in statistical inquiry.World Scientific Series in Computer Science, 15.Sa-Im Shin and Key-Sun Choi.
2004.
Automatic word senseclustering using collocation for sense adaptation.
In The Sec-ond Global Wordnet Conference.K.
Silverman, M. Beckman, J. Pitrelli, M. Ostendorf, C. Wight-man, P. Price, J. Pierrehumbert, and J. Hirschberg.
1992.Tobi: A standard for labeling english prosody.
In Proc.
ofthe 1992 International Conference on Spoken Language Pro-cessing, volume 2, pages 12?16.S.
Strassel and M. Glenn.
2003.
Creatingthe annotated tdt-4 y2003 evaluation corpus.http://www.nist.gov/speech/tests/tdt/tdt2003/papers/ldc.ppt.Stijn van Dongen.
2000.
Performance criteria for graph cluster-ing and markov cluster experiments.
Technical report, CWI(Centre for Mathematics and Computer Science), Amster-dam, The Netherlands, The Netherlands.C.
J.
Van Rijsbergen.
1979.
Information Retrieval, 2nd edition.Dept.
of Computer Science, University of Glasgow.Santosh Vempala and Grant Wang.
2005.
The benefit ofspectral projection for document clustering.
In Workshopon Clustering High Dimensional Data and its ApplicationsHeld in conjunction with Fifth SIAM International Confer-ence on Data Mining (SDM 2005).D.
L. Wallace.
1983.
Comment.
Journal of the American Sta-tistical Association, 78:569?576.Peter Willett.
1988.
Recent trends in hierarchic document clus-tering: a critical review.
Inf.
Process.
Manage., 24(5):577?597.419Oren Zamir and Oren Etzioni.
1998.
Web document clustering:A feasibility demonstration.
In Research and Developmentin Information Retrieval, pages 46?54.Yujing Zeng, Jianshan Tang, Javier Garcia-Frias, and Guang R.Gao.
2002.
An adaptive meta-clustering approach: Com-bining the information from different clustering results.
csb,00:276.Ying Zhao and George Karypis.
2001.
Criterion functions forducument clustering: Experiments and analysis.
TechnicalReport TR 01?40, Department of Computer Science, Uni-versity of Minnesota.420
