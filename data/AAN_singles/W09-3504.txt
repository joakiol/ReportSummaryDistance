Proceedings of the 2009 Named Entities Workshop, ACL-IJCNLP 2009, pages 28?31,Suntec, Singapore, 7 August 2009. c?2009 ACL and AFNLPDIRECTL: a Language-Independent Approach to TransliterationSittichai Jiampojamarn, Aditya Bhargava, Qing Dou, Kenneth Dwyer, Grzegorz KondrakDepartment of Computing ScienceUniversity of AlbertaEdmonton, AB, T6G 2E8, Canada{sj,abhargava,qdou,dwyer,kondrak}@cs.ualberta.caAbstractWe present DIRECTL: an online discrimi-native sequence prediction model that em-ploys a many-to-many alignment betweentarget and source.
Our system incorpo-rates input segmentation, target charac-ter prediction, and sequence modeling ina unified dynamic programming frame-work.
Experimental results suggest thatDIRECTL is able to independently dis-cover many of the language-specific reg-ularities in the training data.1 IntroductionIn the transliteration task, it seems intuitively im-portant to take into consideration the specifics ofthe languages in question.
Of particular impor-tance is the relative character length of the sourceand target names, which vary widely depending onwhether languages employ alphabetic, syllabic, orideographic scripts.
On the other hand, faced withthe reality of thousands of potential language pairsthat involve transliteration, the idea of a language-independent approach is highly attractive.In this paper, we present DIRECTL: a translit-eration system that, in principle, can be applied toany language pair.
DIRECTL treats the transliter-ation task as a sequence prediction problem: givenan input sequence of characters in the source lan-guage, it produces the most likely sequence ofcharacters in the target language.
In Section 2,we discuss the alignment of character substringsin the source and target languages.
Our transcrip-tion model, described in Section 3, is based onan online discriminative training algorithm thatmakes it possible to efficiently learn the weightsof a large number of features.
In Section 4, weprovide details of alternative approaches that in-corporate language-specific information.
Finally,in Section 5 and 6, we compare the experimentalresults of DIRECTL with its variants that incor-porate language-specific pre-processing, phoneticalignment, and manual data correction.2 Transliteration alignmentIn the transliteration task, training data consist ofword pairs that map source language words towords in the target language.
The matching be-tween character substrings in the source word andtarget word is not explicitly provided.
These hid-den relationships are generally known as align-ments.
In this section, we describe an EM-basedmany-to-many alignment algorithm employed byDIRECTL.
In Section 4, we discuss an alternativephonetic alignment method.We apply an unsupervised many-to-many align-ment algorithm (Jiampojamarn et al, 2007) to thetransliteration task.
The algorithm follows the ex-pectation maximization (EM) paradigm.
In theexpectation step shown in Algorithm 1, partialcounts ?
of the possible substring alignments arecollected from each word pair (xT , yV ) in thetraining data; T and V represent the lengths ofwords x and y, respectively.
The forward prob-ability ?
is estimated by summing the probabili-ties of all possible sequences of substring pairingsfrom left to right.
The FORWARD-M2M procedureis similar to lines 5 through 12 of Algorithm 1, ex-cept that it uses Equation 1 on line 8, Equation 2on line 12, and initializes ?0,0 := 1.
Likewise, thebackward probability ?
is estimated by summingthe probabilities from right to left.
?t,v += ?
(xtt?i+1, ?
)?t?i,v (1)?t,v += ?
(xtt?i+1, yvv?j+1)?t?i,v?j (2)The maxX and maxY variables specify themaximum length of substrings that are permittedwhen creating alignments.
Also, for flexibility, weallow a substring in the source word to be alignedwith a ?null?
letter (?)
in the target word.28Algorithm 1: Expectation-M2M alignmentInput: xT , yV ,maxX,maxY, ?Output: ??
:= FORWARD-M2M (xT , yV ,maxX,maxY )1?
:= BACKWARD-M2M (xT , yV ,maxX,maxY )2if (?T,V = 0) then3return4for t = 0 .
.
.
T , v = 0 .
.
.
V do5if (t > 0) then6for i = 1 .
.
.maxX st t?
i ?
0 do7?
(xtt?i+1, ?)
+=?t?i,v?(xtt?i+1,?
)?t,v?T,V8if (v > 0 ?
t > 0) then9for i = 1 .
.
.maxX st t?
i ?
0 do10for j = 1 .
.
.
maxY st v ?
j ?
0 do11?
(xtt?i+1, yvv?j+1) +=?t?i,v?j?
(xtt?i+1,yvv?j+1)?t,v?T,V12In the maximization step, we normalize the par-tial counts ?
to the alignment probability ?
usingthe conditional probability distribution.
The EMsteps are repeated until the alignment probability?
converges.
Finally, the most likely alignment foreach word pair in the training data is computedwith the standard Viterbi algorithm.3 Discriminative trainingWe adapt the online discriminative training frame-work described in (Jiampojamarn et al, 2008) tothe transliteration task.
Once the training data hasbeen aligned, we can hypothesize that the ith let-ter substring xi ?
x in a source language wordis transliterated into the ith substring yi ?
y inthe target language word.
Each word pair is rep-resented as a feature vector ?(x,y).
Our featurevector consists of (1) n-gram context features, (2)HMM-like transition features, and (3) linear-chainfeatures.
The n-gram context features relate theletter evidence that surrounds each letter xi to itsoutput yi.
We include all n-grams that fit withina context window of size c. The c value is deter-mined using a development set.
The HMM-liketransition features express the cohesion of the out-put y in the target language.
We make a first orderMarkov assumption, so that these features are bi-grams of the form (yi?1, yi).
The linear-chain fea-tures are identical to the context features, exceptthat yi is replaced with a bi-gram (yi?1, yi).Algorithm 2 trains a linear model in this fea-ture space.
The procedure makes k passes overthe aligned training data.
During each iteration,the model produces the nmost likely output wordsY?j in the target language for each input word xjin the source language, based on the current pa-Algorithm 2: Online discriminative trainingInput: Data {(x1,y1), (x2,y2), .
.
.
, (xm,ym)},number of iterations k, size of n-best list nOutput: Learned weights ??
:= ~01for k iterations do2for j = 1 .
.
.m do3Y?j = {y?j1, .
.
.
, y?jn} = argmaxy[?
?
?
(xj ,y)]4update ?
according to Y?j and yj5return ?6rameters ?.
The values of k and n are deter-mined using a development set.
The model param-eters are updated according to the correct outputyj and the predicted n-best outputs Y?j , to makethe model prefer the correct output over the in-correct ones.
Specifically, the feature weight vec-tor ?
is updated by using MIRA, the Margin In-fused Relaxed Algorithm (Crammer and Singer,2003).
MIRA modifies the current weight vector?o by finding the smallest changes such that thenew weight vector ?n separates the correct and in-correct outputs by a margin of at least ?
(y, y?
), theloss for a wrong prediction.
We define this loss tobe 0 if y?
= y; otherwise it is 1 + d, where d isthe Levenshtein distance between y and y?.
Theupdate operation is stated as a quadratic program-ming problem in Equation 3.
We utilize a functionfrom the SVMlight package (Joachims, 1999) tosolve this optimization problem.min?n ?
?n ?
?o ?subject to ?y?
?
Y?
:?n ?
(?
(x,y) ?
?
(x, y?))
?
?
(y, y?
)(3)The argmax operation is performed by an exactsearch algorithm based on a phrasal decoder (Zensand Ney, 2004).
This decoder simultaneouslyfinds the l most likely substrings of letters x thatgenerate the most probable output y, given thefeature weight vector ?
and the input word xT .The search algorithm is based on the following dy-namic programming recurrence:Q(0, $) = 0Q(t, p) = maxp?,p,t?maxX?t?<t{?
?
?
(xtt?+1, p?, p) +Q(t?, p?
)}Q(T+1, $) = maxp?{?
?
?
($, p?, $) +Q(T, p?
)}To find the n-best predicted outputs, the tableQ records the top n scores for each output sub-string that has the suffix p substring and is gen-erated by the input letter substring xt1; here, p?
is29a sub-output generated during the previous step.The notation ?
(xtt?+1, p?, p) is a convenient wayto describe the components of our feature vector?(x,y).
The n-best predicted outputs Y?
can bediscovered by backtracking from the end of the ta-ble, which is denoted by Q(T + 1, $).4 Beyond DIRECTL4.1 Intermediate phonetic representationWe experimented with converting the original Chi-nese characters to Pinyin as an intermediate repre-sentation.
Pinyin is the most commonly knownRomanization system for Standard Mandarin.
Itsalphabet contains the same 26 letters as English.Each Chinese character can be transcribed pho-netically into Pinyin.
Many resources for Pinyinconversion are available online.1 A small percent-age of Chinese characters have multiple pronunci-ations represented by different Pinyin representa-tions.
For those characters (about 30 characters inthe transliteration data), we manually selected thepronunciations that are normally used for names.This preprocessing step significantly reduces thesize of target symbols from 370 distinct Chinesecharacters to 26 Pinyin symbols which enables oursystem to produce better alignments.In order to verify whether the addition oflanguage-specific knowledge can improve theoverall accuracy, we also designed intermediaterepresentations for Russian and Japanese.
Wefocused on symbols that modify the neighbor-ing characters without producing phonetic outputthemselves: the two yer characters in Russian,and the long vowel and sokuon signs in Japanese.Those were combined with the neighboring char-acters, creating new ?super-characters.
?4.2 Phonetic alignment with ALINEALINE (Kondrak, 2000) is an algorithm thatperforms phonetically-informed alignment of twostrings of phonemes.
Since our task requiresthe alignment of characters representing differentwriting scripts, we need to first replace every char-acter with a phoneme that is the most likely to beproduced by that character.We applied slightly different methods to thetest languages.
In converting the Cyrillic scriptinto phonemes, we take advantage of the factthat the Russian orthography is largely phonemic,which makes it a relatively straightforward task.1For example, http://www.chinesetopinyin.com/In Japanese, we replace each Katakana characterwith one or two phonemes using standard tran-scription tables.
For the Latin script, we simplytreat every letter as an IPA symbol (InternationalPhonetic Association, 1999).
The IPA contains asubset of 26 letter symbols that tend to correspondto the usual phonetic value that the letter repre-sents in the Latin script.
The Chinese charactersare first converted to Pinyin, which is then handledin the same way as the Latin script.Similar solutions could be engineered for otherscripts.
We observed that the transcriptions do notneed to be very precise in order for ALINE to pro-duce high quality alignments.4.3 System combinationThe combination of predictions produced by sys-tems based on different principles may lead to im-proved prediction accuracy.
We adopt the follow-ing combination algorithm.
First, we rank the in-dividual systems according to their top-1 accuracyon the development set.
To obtain the top-1 pre-diction for each input word, we use simple voting,with ties broken according to the ranking of thesystems.
We generalize this approach to handle n-best lists by first ordering the candidate translitera-tions according to the highest rank assigned by anyof the systems, and then similarly breaking ties byvoting and system ranking.5 EvaluationIn the context of the NEWS 2009 MachineTransliteration Shared Task (Li et al, 2009), wetested our system on six data sets: from English toChinese (EnCh) (Li et al, 2004), Hindi (EnHi),Russian (EnRu) (Kumaran and Kellner, 2007),Japanese Katakana (EnJa), and Korean Hangul(EnKo); and from Japanese Name to JapaneseKanji (JnJk)2.
We optimized the models?
param-eters by training on the training portion of theprovided data and measuring performance on thedevelopment portion.
For the final testing, wetrained the models on all the available labeled data(training plus development data).
For each dataset, we converted any uppercase letters to lower-case.
Our system outputs the top 10 candidate an-swers for each input word.Table 1 reports the performance of our systemon the development and final test sets, measuredin terms of top-1 word accuracy (ACC).
For cer-tain language pairs, we tested variants of the base2http://www.cjk.org/30Task Model Dev TestEnCh DIRECTL 72.4 71.7INT(M2M) 73.9 73.4INT(ALINE) 73.8 73.2COMBINED 74.8 74.6EnHi DIRECTL 41.4 49.8DIRECTL+MC 42.3 50.9EnJa DIRECTL 49.9 50.0INT(M2M)?
49.6 49.2INT(ALINE) 48.3 51.0COMBINED?
50.6 50.5EnKo DIRECTL 36.7 38.7EnRu DIRECTL 80.2 61.3INT(M2M) 80.3 60.8INT(ALINE) 80.0 60.7COMBINED?
80.3 60.8JnJk DIRECTL 53.5 56.0Table 1: Top-1 word accuracy on the developmentand test sets.
The asterisk denotes the results ob-tained after the test reference sets were released.system described in Section 4.
DIRECTL refersto our language-independent model, which usesmany-to-many alignments.
The INT abbreviationdenotes the models operating on the language-specific intermediate representations described inSection 4.1.
The alignment algorithm (ALINE orM2M) is given in brackets.In the EnHi set, many names consisted of mul-tiple words: we assumed a one-to-one correspon-dence between consecutive English words andconsecutive Hindi words.
In Table 1, the results inthe first row (DIRECTL) were obtained with an au-tomatic cleanup script that replaced hyphens withspaces, deleted the remaining punctuation and nu-merical symbols, and removed 43 transliterationpairs with a disagreement between the number ofsource and target words.
The results in the sec-ond row (DIRECTL+MC) were obtained when thecases with a disagreement were individually ex-amined and corrected by a Hindi speaker.We did not incorporate any external resourcesinto the models presented in Table 1.
In orderto emphasize the performance of our language-independent approach, we consistently used theDIRECTL model for generating our ?standard?runs on all six language pairs, regardless of its rel-ative performance on the development sets.6 DiscussionDIRECTL, our language-independent approach totransliteration achieves excellent results, espe-cially on the EnCh, EnRu, and EnHi data sets,which represent a wide range of language pairsand writing scripts.
Both the many-to-manyand phonetic alignment algorithms produce high-quality alignments.
The former can be applied di-rectly to the training data without the need for anintermediate representation, while the latter doesnot require any training.
Surprisingly, incorpo-ration of language-specific intermediate represen-tations does not consistently improve the perfor-mance of our system, which indicates that DI-RECTL may be able to discover the structures im-plicit in the training data without additional guid-ance.
The EnHi results suggest that manual clean-ing of noisy data can yield noticeable gains in ac-curacy.
On the other hand, a simple method ofcombining predictions from different systems pro-duced clear improvement on the EnCh set, butmixed results on two other sets.
More research onthis issue is warranted.AcknowledgmentsThis research was supported by the Alberta Inge-nuity, Informatics Circle of Research Excellence(iCORE), and Natural Sciences of EngineeringResearch Council of Canada (NSERC).ReferencesKoby Crammer and Yoram Singer.
2003.
Ultracon-servative online algorithms for multiclass problems.Journal of Machine Learning Research, 3:951?991.International Phonetic Association.
1999.
Handbookof the International Phonetic Association.
Cam-bridge University Press.Sittichai Jiampojamarn, Grzegorz Kondrak, and TarekSherif.
2007.
Applying many-to-many alignmentsand Hidden Markov Models to letter-to-phonemeconversion.
In Proc.
HLT-NAACL, pages 372?379.Sittichai Jiampojamarn, Colin Cherry, and GrzegorzKondrak.
2008.
Joint processing and discriminativetraining for letter-to-phoneme conversion.
In Proc.ACL, pages 905?913.Thorsten Joachims.
1999.
Making large-scale SVMlearning practical.
Advances in kernel methods:support vector learning, pages 169?184.
MIT Press.Grzegorz Kondrak.
2000.
A new algorithm for thealignment of phonetic sequences.
In Proc.
NAACL,pages 288?295.A.
Kumaran and Tobias Kellner.
2007.
A genericframework for machine transliteration.
In Proc.
SI-GIR, pages 721?722.Haizhou Li, Min Zhang, and Jian Su.
2004.
A jointsource channel model for machine transliteration.
InProc.
ACL, pages 159?166.Haizhou Li, A Kumaran, Min Zhang, and VladimirPervouchine.
2009.
Whitepaper of NEWS 2009machine transliteration shared task.
In Proc.
ACL-IJCNLP Named Entities Workshop.Richard Zens and Hermann Ney.
2004.
Improvementsin phrase-based statistical machine translation.
InProc.
HLT-NAACL, pages 257?264.31
