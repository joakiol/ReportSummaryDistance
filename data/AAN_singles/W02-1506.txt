Adapting Existing Grammars: The XLE ExperienceRonald M. Kaplan and Tracy Holloway King and John T. Maxwell IIIPalo Alto Research CenterPalo Alto, CA 94304 USAkaplan, thking, maxwell @parc.comAbstractWe report on the XLE parser and grammar develop-ment platform (Maxwell and Kaplan, 1993) and de-scribe how a basic Lexical Functional Grammar forEnglish has been adapted to two different corpora(newspaper text and copier repair tips).1 IntroductionLarge-scale grammar development platforms shouldbe able to be used to develop grammars for a widevariety of purposes.
In this paper, we report on thethe XLE system (Maxwell and Kaplan, 1993), aparser and grammar development platform for Lex-ical Functional Grammars.
We describe some of thestrategies and notational devices that enable the ba-sic English grammar developed for the ParGramproject (Butt et al, 1999; Butt et al, 2002) to beadapted to two corpora with different properties.1.1 The CorporaThe STANDARD Pargram English grammar coversthe core phenomena of English (e.g., main and sub-ordinate clauses, noun phrases, adjectives and ad-verbs, prepositional phrases, coordination; see (Buttet al, 1999)).
We have built two different specializedgrammars on top of this: the EUREKA grammar andthe WSJ grammar.The EUREKA grammar parses the Eureka cor-pus of copier repair tips, a collection of documentsoffering suggestions for how to diagnose and fixparticular copier malfunctions.
These informal andunedited documents were contributed by copier re-pair technicians, and the corpus is characterized bya significant amount of ungrammatical input (e.g.,typos, incorrect punctuation, telegraphic sentences)and much technical terminology (1).
The goal ofparsing this corpus is to provide input to a semanticsand world-knowledge reasoning application (Ev-erett et al, 2001).
(1) a.
(SOLUTION 27032 70) If exhibiting 10-132 faults replace the pre-fuser transportsensor (Q10-130).b.
(SOLUTION 27240 80) 4.
Enter into themachine log, the changes that have beenmade.The WSJ grammar covers the UPenn Wall StreetJournal (WSJ) treebank sentences (Marcus et al,1994).
This corpus is characterized by long sen-tences with many direct quotes and proper names,(2a).
In addition, for evaluation and training pur-poses we also parsed a version of this corpus markedup with labeled brackets and part-of-speech tags, asin (2b).
Riezler et al (2002) report on our WSJ pars-ing experiments.
(2) a.
But since 1981, Kirk Horse Insurance Inc.of Lexington, Ky. has grabbed a 20% stakeof the market.b.
But since 1981, [NP-SBJ Kirk Horse In-surance Inc. of Lexington, Ky.] has/VBZgrabbed/VBN [NP a 20% stake of the mar-ket].2 Priority-based Grammar SpecializationThe XLE system is designed so that the grammarwriter can build specialized grammars by both ex-tending and restricting another grammar (in our casethe base grammar is the STANDARD Pargram En-glish grammar).
An LFG grammar is presented tothe XLE system in a priority-ordered sequence offiles containing phrase-structure rules, lexical en-tries, abbreviatory macros and templates, featuredeclarations, and finite-state transducers for tok-enization and morphological analysis.
XLE is ap-plied to a single root file holding a CONFIGURA-TION that identifies all the other files containing rel-evant linguistic specifications, that indicates howthose components are to be assembled into a com-plete grammar, and that specifies certain parametersthat control how that grammar is to be interpreted.A key idea is that there can be only one definitionof an item of a given type with a particular name(e.g., there can be only one NP rule although that sin-gle rule can have many alternative expansions), anditems in a higher priority file override lower priorityitems of the same type with the same name.
This setup is similar to the priority-override scheme of theearlier LFG Grammar Writer?s Workbench (Kaplanand Maxwell, 1996).This arrangement makes it relatively easy to con-struct a specialized grammar from a pre-existingstandard.
The specialized grammar is defined bya CONFIGURATION in its own root file that speci-fies the relevant STANDARD grammar files as wellas the new files for the specialized grammar.
Thefiles for the specialized grammar can also containitems of different types (phrase-structure rules, lex-ical entries, templates, etc.
), and they are orderedwith higher priority than the STANDARD files.Consider the configuration for the EUREKA gram-mar.
It specifies all of the STANDARD grammar filesas well as its own rule, template, lexicon, and mor-phology files.
A part of this configuration is shownin (3) (the notationtemplates.lfg are shared by all thelanguages?
grammars, not just English).
(3) FILES ../standard/english-lexicons.lfg../standard/english-rules.lfg../standard/english-templates.lfg../../common/notationtemplates.lfgenglish-eureka-morphconfigeureka-lexicons.lfgeureka-rules.lfgeureka-templates.lfgThis configuration specifies that the EUREKA rules,templates, and lexical entries are given priorityover the STANDARD items by putting the spe-cial EUREKA files at the end of the list.
Thus, ifthe ../standard/english-rules.lfg and eureka-rules.lfgfiles both contain a rule expanding the NP category,the one from the STANDARD file will be discarded infavor of the EUREKA rule.In the following subsections, we provide severalillustrations of how simple overriding has been usedfor the EUREKA and WSJ grammar extensions.2.1 RulesThe override convention makes it possible to: addrules (e.g., for new or idiosyncratic constructions);delete rules (e.g., to block constructions not found inthe new corpus); and modify rules to allow differentdaughter sequences.Rules may need to be added to allow for corpus-specific constructions.
This is illustrated in the EU-REKA corpus by the identifier information that pre-cedes each sentence, as in (1).
In order to parse thissubstring, a new category (FIELD) was defined withan expansion that covers the identifier informationfollowed by the usual ROOT category of the STAN-DARD grammar.
The top-level category is one ofthe parameters of a configuration, and the EUREKACONFIGURATION specifies that FIELD instead of theSTANDARD ROOT is the start-symbol of the gram-mar.
Thus the EUREKA grammar produces the treein (4) and functional-structure in (5) for (1a).
(4) FIELDLP EURHEAD ID SUB-ID RP ROOT( SOLUTION 27032 70 )(5) PRED replace SUBJ, OBJSUBJ [ ]OBJ [ ]FIELD solutionTIP-ID 27032SUB-TIP-ID 70It is unusual in practice to need to delete a rule,i.e., to eliminate completely the possibility of ex-panding a given category of the STANDARD gram-mar.
This is generally only motivated when the spe-cialized grammar applies to a domain where certainconstructions are rarely encountered, if at all.
Al-though there has been no need to delete rules for theEUREKA and WSJ corpora, the override conventionalso provides a natural way of achieving this effect.For example, topicalization is extremely rare in thethe Eureka corpus and the STANDARD topicalizationrule sometimes introduces parsing inefficiency.
Thiscan be avoided by having the high priority EUREKAfile replace the STANDARD rule with the one in (6).
(6) CPtop .This vacuous rule expands the CPtop category to theempty language, the language containing no strings;so, this category is effectively removed from thegrammar.Perhaps the most common change is to makemodifications to the behavior of existing rules.
Themost direct way of doing this is simply to define anew, higher priority expansion of the same left-handcategory.
Since XLE only allows a single rule for agiven category, the old rule is discarded and the newone comes into play.
The new rule can be arbitrar-ily different from the STANDARD one, but this is nottypically the case.
It is much more common that thespecialized version incorporates most of the behav-ior of the original, with minor extensions or restric-tions.
One way of producing the modified behavioris to create a new rule that includes a copy of someor all of the STANDARD rule?s right side along withnew material, and to give the new definition higherpriority than the old.
For example, plurals in the Eu-reka corpus can be formed by the addition of ?s in-stead of the usual s, as in (7).
(7) (CAUSE 27416 10) A 7mfd inverter motor ca-pacitor was installed on an unknown number ofUDH?s.In order to allow for this, the N rule was rewritten toallow a PL marker to optionally occur after any N,as in (8).
(8) N copy of STANDARD N rule(PL)As a result of this rule modification, UDH?s in (7)will have the tree and functional-structure in (9).
(9) a. NPART PLUDH ?sb.PRED UDHNUM plCopying material from one version to another isperhaps reasonable for relatively stable and simplerules, like the N rule, but this can cause maintainabil-ity problems with complicated rules in the STAN-DARD grammar that are updated frequently.
An al-ternative strategy is to move the body of the STAN-DARD N rule to a different rule, e.g., Nbody, whichin turn is called by the N rule in both the STANDARDand EUREKA grammars.
The Nbody category can besupressed in the tree structure by invoking this ruleas a macro (notationally indicated as @Nbody).
(10) N @Nbody (PL).Often the necessary modification can be madesimply by redefining a macro that existing rules al-ready invoke.
Consider the ROOT rule, in (11).
(11) ROOT @DECL-BODY @DECL-PUNCT@INT-BODY @INT-PUNCT@HEADER .In the STANDARD grammar, the DECL-PUNCTmacro is defined as in (12a).
However, this mustbe modified in the EUREKA grammar because thepunctuation is much sloppier and often does notoccur at all; the EUREKA version is shown in (12b).
(12) a. DECL-PUNCT = PERIODEXCL-POINT .b.
DECL-PUNCT = ( PERIODEXCL-POINTCOLONSEMI-COLON ).The modular specifications that macros and tem-plates provide allow rule behavior to be modifiedwithout having to copy the parts of the rule that donot change.XLE also has a mechanism for systemati-cally modifying the behavior of all rules: theMETARULEMACRO.
For example, in order toparse labeled bracketed input, as in (2b), the WSJgrammar was altered so that constituents couldoptionally be surrounded by the appropriatelylabeled brackets.
The METARULEMACRO is appliedto each rule in the grammar and produces as outputa modified version of that rule.
This is used inthe STANDARD grammar for coordination and toallow quote marks to surround any constituent.
TheMETARULEMACRO is redefined for the WSJ to addthe labeled bracketing possibilities for each rule, asshown in (13).
(13) METARULEMACRO( CAT BASECAT RHS) =LSB LABEL[ BASECAT] CAT RSBcopy of STANDARD coordinationcopy of STANDARD surrounding quote .The CAT, BASECAT, and RHS are arguments tothe METARULEMACRO that are instantiated to dif-ferent values for each rule.
RHS is instantiated tothe right-hand side of the rule, i.e., the rule expan-sion.
CAT and BASECAT are two ways of repre-senting the left-hand side of the rule.
For simple cat-egories the CAT and BASECAT are the same (e.g.NP for the NP rule).
XLE also allows for complexcategory symbols to specialize the expansion of par-ticular categories in particular contexts.
For exam-ple, the VP rule is parameterized for the form of itscomplement and its own form, so that VP[perf,fin]is one of the complex VP categories.
When theMETARULEMACRO applies to rules with complexleft-side categories, CAT refers to the category in-cluding the parameters and the BASECAT refers tothe category without the parameters.
For the VP ex-ample, CAT is VP[perf,fin] and BASECAT is VP.In the definition in (13), LSB and RSB parse thebrackets themselves, while the LABEL[ BASECAT]parses the label in the bracketing and matches it tothe label in the tree (NP in (2b)); the consituent itselfis the CAT.
Thus, a label-bracketed NP is assignedthe structure in (14).
(14) NPLSB LABEL[NP] NP RSB[ NP-SBJ Kirk Horse ]These examples illustrate how the prioritized re-definition of rules and macros has enabled us to in-corporate the STANDARD rules in grammars that aretuned to the special properties of the EUREKA andWSJ corpora.2.2 Lexical EntriesJust as for rules, XLE?s override conventions makeit possible to: add new lexical items or new part-of-speech subentries for existing lexical items; deletelexical items; and modify lexical items.
In additionto the basic priority overrides, XLE provides for?edit lexical entries?
(Kaplan and Newman, 1997)that give finer control over the construction of thelexicon.
Edit entries were introduced as a way of rec-onciling information from lexical databases of vary-ing degrees of quality, but they are also helpful intailoring a STANDARD lexicon to a specialized cor-pus.
When working on specialized corpora, such asthe Eureka corpus, modifications to the lexicon areextremely important for correctly handling techni-cal terminology and eliminating word senses that arenot appropriate for the domain.Higher-priority edit lexical entries provide for op-erators that modify the definitions found in lower-priority entries.
The operators can: add a subentry(+); delete a subentry ( ); replace a subentry (!
);or retain existing subentries (=).
For example, theSTANDARD grammar might have an entry for buttonas in (15).
(15) button !V @(V-SUBJ-OBJ %stem);!N @(NOUN %stem);ETC.However, the EUREKA grammar might not need theV entry but might require a special partname N en-try.
Assuming that the EUREKA lexicons are givenpriority over the STANDARD lexicons, the entry in(16) would accomplish this.
(16) button V ;+N @(PARTNAME %stem);ETC.Note that the lexical entries in (15) and (16) end withETC.
This is also part of the edit lexical entry sys-tem.
It indicates that other lower-priority definitionsof that lexical item will be retained in addition tothe new entries.
For example, if in another EUREKAlexicon there was an adjective entry for button withETC, the V, N, and A entries would all be used.
Thealternative to ETC is ONLY which indicates that onlythe new entry is to be used.
In our button example, ifan adjective entry was added with ONLY, the V andN entries would be removed, assuming that the ad-jective entry occurred in the highest priority lexicon.This machinery provides a powerful tool for build-ing specialized lexicons without having to alter theSTANDARD lexicons.The EUREKA corpus contains a large number ofnames of copier parts.
Due to their particular syn-tax and to post-syntactic processing requirements, aspecial lexical entry is added for each part name.
Inaddition, the regular noun parse of these entries isdeleted because whenever they occur in the corpusthey are part names.
A sample lexical is shown in(17); the ?
is the escape character for the space.
(17) separator?
finger!PART-NAME @(PART-NAME %stem);N;ETC.The first line in (17) states that separator finger canbe a PART NAME and when it is, it calls a templatePART-NAME that provides relevant information forthe functional-structure.
The second line removesthe N entry, if any, as signalled by the before thecategory name.Because of the non-context free nature of LexicalFunctional Grammar, it sometimes happens that ex-tensions in one part of the grammar require a cor-responding adjustment in other rules or lexical en-tries.
Consider again the EUREKA ?s plurals.
Thepart-name UDH is singular when it appears with-out the ?s and thus the morphological tag +Sg is ap-pended to it.
In the STANDARD grammar, the tag +Sghas a lexical entry as in (18a) which states that +Sg isof category NNUM and assigns sg to its NUM.
How-ever, if this is used in the EUREKA grammar, the sgNUM specification will clash with the pl NUM spec-ification when UDH appears with ?s, as seen in (7).Thus, a new entry for +Sg is needed which has sgas a default value, as in (18b).
The first line of (18b)states that NUM must exist but does not specify avalue, while the second line optionally supplies a sgvalue to NUM; when the ?s is used, this option doesnot apply since the form already has a pl NUM value.
(18) a.
+Sg NNUM ( NUM)=sgb.
+Sg NNUM ( NUM)(( NUM)=sg)3 Tokenizing and Morphological AnalysisTokenization and morphological analysis in XLEare carried out by means of finite state transductions.The STANDARD tokenizing transducer encodes thepunctuation conventions of normal English text,which is adequate for many applications.
However,the Eureka and WSJ corpora include strings that mustbe tokenized in non-standard ways.
The Eureka partidentifiers have internal punctuation that would nor-mally cause a string to be broken up (e.g.
the hyphenin PL1-B7), and the WSJ corpus is marked up withlabeled brackets and part-of-speech tags that mustalso receive special treatment.
An example of theWSJ mark-up is seen in (19).
(19) [NP-SBJ Lloyd?s, once a pillar of the worldinsurance market,] is/VBZ being/VBGshaken/VBN to its very foundation.Part-of-speech tags appear in a distinctive format,beginning with a / and ending with a , with the in-tervening material indicating the content of the tag(VBZ for finite 3rd singular verb, VBG for a progres-sive, VBN for a passive, etc.).
The tokenizing trans-ducer must recognize this pattern and split the tagsoff as separate tokens.
The tag-tokens must be avail-able to filter the output of the morphological ana-lyzer so that only verbal forms are compatible withthe tags in this example and the adjectival reading ofshaken is therefore blocked.XLE tokenizing transducers are compiled fromspecifications expressed in the sophisticated Xeroxfinite state calculus (Beesley and Karttunen, 2002).The Xerox calculus includes the composition, ig-nore, and substitution operator discussed by Kaplanand Kay (1994) and the priority-union operator ofKaplan and Newman (1997).
The specialized tok-enizers are constructed by using these operators tocombine the STANDARD specification with expres-sions that extend or restrict the standard behavior.For example, the ignore operator is applied to allowthe part-of-speech information to be passed throughto the morphology without interrupting the standardpatterns of English punctuation.XLE also allows separately compiled transduc-ers to be combined at run-time by the operationsof priority-union, composition, and union.
Priority-union was used to supplement the standard morphol-ogy with specialized ?guessing?
transducers that ap-ply only to tokens that would otherwise be unrec-ognized.
Thus, a finite-state guesser was added toidentify Eureka fault numbers (09-425), adjustmentnumbers (12-23), part numbers (606K2100), part listnumbers (PL1-B7), repair numbers (2.4), tag num-bers (P-102), and diagnostic code numbers (dC131).Composition was used to apply the part-of-speechfiltering transducer to the output of the morpholog-ical analyzer, and union provided an easy way ofadding new, corpus-specific terminology.4 Optimality MarksXLE supports a version of Optimality Theory (OT)(Prince and Smolensky, 1993) which is used to rankan analysis relative to other possible analyses (Franket al, 2001).
In general, this is used within a specificgrammar to prefer or disprefer a construction.
How-ever, it can also be used in grammar extensions todelete or include rules or parts of rules.The XLE implementation of OT works as fol-lows.1 OT marks are placed in the grammar and areassociated with particular rules, parts of rules, orlexical entries.
These marks are then ranked in thegrammar CONFIGURATION.
In addition to a simpleranking of constraints which states that a construc-tion with a given OT mark is (dis)prefered to one1The actual XLE OT implementation is more complicatedthan this, allowing for UNGRAMMATICAL and STOPPOINTmarks as well.
Only OT marks that are associated with NO-GOOD are of interest here.
For a full description, see (Frank etal., 2001).without it, XLE allows the marks to be specified asNOGOOD.
A rule or rule disjunct which has a NO-GOOD OT mark associated with it will be ignoredby XLE.
This can be used for grammar extensionsin that it allows a standard grammar to anticipate thevariations required by special corpora without usingthem in normal circumstances.Consider the example of the EUREKA ?s pluralsdiscussed in section 2.1.
Instead of rewriting the Nrule in the EUREKA grammar, it would be possibleto modify it in the STANDARD grammar and includean OT mark, as in (20).
(20) N original STANDARD N rules(PL: @(OT-MARK EUR-PLURAL)).The CONFIGURATION files of the STANDARD andEUREKA grammars would differ in that the STAN-DARD grammar would rank the EUR-PLURAL OTmark as NOGOOD, as in (21a), while the EUREKAgrammar would simply not rank the mark, as in(21b).
(21) a.
STANDARD optimality order:EUR-PLURAL NOGOODb.
EUREKA optimality order:NOGOODGiven the OT marks, it would be possible to haveone large grammar that is specialized by differentOT rankings to produce the STANDARD, EUREKA,and WSJ variants.
However, from a grammar writ-ing perspective this is not a desirable solution be-cause it becomes difficult to keep track of whichconstructions belong to standard English and areshared among all the specializations and which arecorpus-specific.
In addition, it does not distinguish acore set of slowly changing linguistic specificationsfor the basic patterns of the language, and thus doesnot provide a stable foundation that the writers ofmore specialized grammars can rely on.5 Maintenance with Grammar ExtensionsMaintenance is a serious issue for any large-scalegrammar development activity, and the maintenanceproblems are compounded when multiple versionsare being created perhaps by several different gram-mar writers.
Our STANDARD grammar is now quitemature and covers all the linguistically significantconstructions and most other constructions that wehave encountered in previous corpus analysis.
How-ever, every now and then, a new corpus, even a spe-cialized one, will evidence a standard constructionthat has not previously been accounted for.
If spe-cialized grammars were written by copying all theSTANDARD files and then modifying them, the im-plementation of new standard constructions wouldtend to appear only in the specialized grammar.
Ourtechniques for minimizing the amount of copyingencourages us to implement new constructions in theSTANDARD grammar and this makes them availableto all other specializations.If a new version of a rule for a specialized gram-mar is created by copying the corresponding STAN-DARD rule, changes later made to the special rulewill not automatically be reflected in the STANDARDgrammar, and vice versa.
This is the desired behav-ior when adding unusual, corpus-specific construc-tions.
However, if the non-corpus specific parts ofthe new rule are modified, these modifications willnot migrate to the STANDARD grammar.
To avoidthis problem, the smallest rule possible should bemodified in the specialized grammar, e.g., modify-ing the N head rule instead of the entire NP.
Forthis reason, having highly modularized rules and us-ing macros and templates helps in grammar mainte-nance both within a grammar and across specializedgrammar extensions.As seen above, the XLE grammar developmentplatform provides a number of mechanisms to allowfor grammar extensions without altering the core(STANDARD) grammar.
However, there are still ar-eas that could use improvement.
For example, asmentioned in section 2, the CONFIGURATION filestates which other files the grammar includes andhow they are prioritized.
The CONFIGURATION con-tains other information such as declarations of thegovernable grammatical functions, the distributivefeatures, etc.
As this information rarely changeswith grammar extensions, it would be helpful foran extension configuration to incorporate by refer-ence such additional parameters of the STANDARDconfiguration.
Currently these declarations must becopied into each CONFIGURATION.6 Discussion and ConclusionAs a result of the strategies and notational devicesoutlined above, our specialized grammars sharesubstantial portions of the pre-existing STANDARDgrammar.
The statistics in table (22) give an indica-tion of the size of the STANDARD grammar and ofthe additional material required for the EUREKA andWSJ specializations.
As can be seen from this table,the specialized grammars require a relatively smallnumber of rules compared to the rules in the STAN-DARD grammar.
The number of lines that the rulesand lexical entries take up also provides a measure ofthe relative size of the specifications.
The WSJ lexi-cons include many titles and proper nouns that mayultimately be moved to the STANDARD files.
The ta-ble also shows the number of files called by the CON-FIGURATION, as another indication of the size of thespecifications.
This number is somewhat arbitrary asseparate files can be combined into a single multi-sectioned file, although this is likely to reduce main-tainability and readability.
(22)STANDARD EUREKA WSJrules 310 32 14lines:rules 6,539 425 894lexicons 44,879 5,565 15,135files 14 5 8The grammars compile into a collection of finite-state machines with the number of states and arcslisted in table (23).
The WSJ grammar compiles intothe largest data structures, mainly because of its abil-ity to parse labeled bracketed strings and part-of-speech tags, (2b).
This size increase is the result ofadding one disjunct in the METARULEMACRO andhence reflects only a minor grammar change.
(23)STANDARD EUREKA WSJstates 4,935 5,132 8,759arcs 13,268 13,639 19,695In sum, the grammar specialization system usedin XLE has been quite sucessful in developing cor-pus specific grammars using the STANDARD Englishgrammar as a basis.
A significant benefit comes frombeing able to distinguish truly unusual constructionsthat exist only in the specialized grammar from thosethat are (or should be) in the STANDARD grammar.This allows idiosyncratic information to remain in aspecialized grammar while all the specialized gram-mars benefit from and contribute to the continuingdevelopment of the STANDARD grammar.ReferencesK.
Beesley and L. Karttunen.
2002.
Finite-StateMorphology: Xerox Tools and Techniques.
Cam-bridge University Press.
To Appear.M.
Butt, T.H.
King, M.-E. Nin?o, and F. Segond.1999.
A Grammar Writer?s Cookbook.
CSLIPublications, Stanford, CA.M.
Butt, H. Dyvik, T.H.
King, H. Masuichi, andC.
Rohrer.
2002.
The parallel grammar project.In Proceedings of COLING 2002.
Workshop onGrammar Engineering and Evaluation.J.
Everett, D. Bobrow, R. Stolle, R. Crouch,V.
de Paiva, C. Condoravdi, M. van den Berg,and L. Polanyi.
2001.
Making ontologies workfor resolving redundancies across documents.Communications of the ACM, 45:55?60.A.
Frank, T. H. King, J. Kuhn, and J. T. Maxwell III.2001.
Optimality theory style constraint rank-ing in large-scale LFG grammars.
In Peter Sells,editor, Formal and Empirical Issues in Optimal-ity Theoretic Syntax.
CSLI Publications, Stanford,CA.R.
Kaplan and M. Kay.
1994.
Regular models ofphonological rule systems.
Computational Lin-guistics, 20:331?378.R.
Kaplan and J. Maxwell.
1996.
LFG Gram-mar Writer?s Workbench.
System documentationmanual; available on-line at PARC.R.
Kaplan and P. Newman.
1997.
Lexical resourceconciliation in the Xerox Linguistic Environment.In Proceedings of the ACL Workshop on Com-putational Environments for Grammar Develop-ment and Engineering.M.
Marcus, G. Kim, M. A. Marcinkiewicz, R. Mac-Intyre, A. Bies, M. Ferguson, K. Katz, andB.
Schasberger.
1994.
The Penn treebank: An-notative predicate argument structure.
In ARPAHuman Language Technology Workshop.J.
Maxwell and R. Kaplan.
1993.
The interface be-tween phrasal and functional constraints.
Compu-tational Lingusitics, 19:571?589.A.
Prince and P. Smolensky.
1993.
Optimality the-ory: Constraint interaction in generative gram-mar.
RuCCS Technical Report #2, Rutgers Uni-versity.S.
Riezler, T.H.
King, R. Kaplan, D. Crouch, J. T.Maxwell, III, and M. Johnson.
2002.
Parsingthe Wall Street Journal using a lexical-functionalgrammar and discriminative estimation tech-niques.
In Proceedings of the Annual Meeting ofthe Association for Computational Linguistics,University of Pennsylvania.
