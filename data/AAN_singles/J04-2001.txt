c?
2004 Association for Computational LinguisticsInferable Centers, Centering Transitions,and the Notion of CoherenceLaurel Fais?NTT Communication Science LaboratoriesA centering analysis of the corpus of Japanese e-mail that is examined in this article relies heavilyon the inclusion of inferable centers.
However, utilizing this type of center results in a high level ofindeterminacy in labeling transitions and thus in characterizing the coherence of the corpus.
Thedifficulty lies in the requirement of identity of discourse entities in the definitions of transitionstates.
Lexical cohesion is proposed as a well-defined notion to replace the intuitions captured bythe use of inferable centers.
Two new transitions, based on lexical relatedness instead of identity,supplement the standard definitions and more adequately characterize coherence in this corpus.Implications and extensions of the proposal are discussed.1.
IntroductionCentering has been proposed as a model of the local attentional states of speakers andhearers involved in the mutual construction of conversation (Brennan, Friedman, andPollard 1987; Grosz and Sidner 1986, 1998; Walker 1998).
Centering mechanisms aredesigned to model the coherence of discourse by characterizing transitions betweenutterances in terms of their inferential load and hence their naturalness.
These char-acterizations are intended to capture intuitions about the ?flow?
(Chafe 1979) or the?ongoing process of meaning?
(Halliday 1994) in discourse.In this work, we examine a corpus of Japanese e-mail to investigate the mecha-nisms by which coherence is achieved.
Because this corpus contains a high numberof discourse elements that are inferable from the discourse context, we have an op-portunity to examine the interplay between standard centering transition definitionsand the presence of inferable discourse entities.
We claim on the basis of intuitions ofnative speakers that the actual level of coherence in the corpus is much higher thanthe centering account implies, primarily by virtue of the fact that transitions involvinginferable entities are often difficult to specify.
We conclude that the standard centeringaccount cannot accurately model the coherence in this corpus.
Detailed analysis re-veals that one major problem lies in the requirement of identity of discourse elementsin adjacent utterances in order for those elements to contribute to coherence.
We de-scribe this problem and propose two additions to the usual repertoire of transitionsthat enable a more authentic account of coherence in this corpus, while remainingwithin a centering framework.The article is organized as follows.
In Section 2, we briefly describe centeringmechanisms and their role in modeling coherence.
We go on to outline the featuresof the corpus in Section 3 and illustrate how standard centering mechanisms charac-terize transitions and coherence in this corpus, suggesting that these mechanisms arenot adequate for the task.
In Section 4, we describe more general problems with the?
Infant Studies Centre, University of British Columbia, Room 1401, 2136 West Mall, Vancouver, BritishColumbia, V6T 1Z4 Canada.
E-mail: jwlab@psych.ubc.ca.120Computational Linguistics Volume 30, Number 2inclusion of inferable discourse entities in centering theory and propose a revision tothe standard set of transitions that more accurately describes the corpus.
In this sec-tion as well, we explore the implications of this proposal for other areas of discourseanalysis.
In Section 5, we outline some possibilities for improvement and extension ofthe proposal, and we conclude in the final section.2.
Centering MechanismsThe central intuitions of centering concern the relationships among the discourse en-tities appearing or represented in adjacent utterances in a discourse (Walker, Joshi,and Prince 1998).
Each utterance Ui in a discourse is considered to contain a set ofdiscourse entities called forward-looking centers, or Cfs.
These entities are ranked inthe Cf list for each utterance according to language-specific ranking principles.
Wefollow, in general, the ordering principles for Japanese given in Walker, Iida, and Cote(1994) (with some adjustments for possessive phrases as noted in example (1)):Cf ranking for Japanese:(Grammatical OR ?)
topic > empathy > subject > object2 > object > othersA special member of the Cf list, the backward-looking center, or Cb, representsthe ?topic?1 of Ui and is the highest-ranked Cf on the Cf list of Ui?1 which is realizedin Ui.
In addition, the preferred center of Ui, or Cp, is the highest-ranked Cf in Ui.Given Ui and Ui?1, then, there are four different ways in which their Cbs and Cpsmay be related; each of these is defined as a type of transition state (Table 1).There are two rules in a centering approach:Rule 1: If some entity in the Cf list for Ui?1 is realized as a pronoun in Ui, thenso is the Cb for Ui.Rule 2: Transition states are ordered such that CONTINUE is most preferred, fol-lowed in order by RETAIN, SMOOTH SHIFT, and ROUGH SHIFT (Walker, Joshi, and Prince1998).Rule 2 captures the centering intuitions concerning coherence: Utterances that CON-TINUE the topic of a previous utterance in a prominent position impose a lower infer-ential load, and are thus more coherent, than utterances which relegate the topic toless prominent positions or which change the topic.The vast majority of the sentences in our corpus are complex sentences.
Thus,the question of how to interpret centering principles in complex sentences cannot beignored.
We will consider the basic utterance unit of centering to be the tensed clauseTable 1Transition definitions.Cb(Ui) = Cb(Ui?1) OR Cb(Ui) = ?
Cb(Ui) = Cb(Ui?1)Cb(Ui) = Cp(Ui) CONTINUE SMOOTH SHIFTCb(Ui) = Cp(Ui) RETAIN ROUGH SHIFT1 Whenever the word topic is used in this article, we mean the general notion of topic as the subject of adiscourse unit, not the specialized meaning of topic/comment.121Fais Transitions and Coherenceand will assume that these clauses form a flat, linear sequence of discourse units, suchthat the centering output of the first clause in the sentence is the input to the next,and so on, in the spirit of Kameyama (1998) and Suri and McCoy (1994).2Because the notion of backward-looking center will be critical to the discussion thatfollows, we look at this notion in greater detail here.
According to Grosz, Joshi, andWeinstein (1986, quoted in Walker, Joshi, and Prince [1998]), a center is realized inan utterance U if it ?is an element of the situation described by U or the semanticinterpretation of some subpart of U?
(page 4).
As Walker, Joshi, and Prince (1998)point out, this covers ?pronouns, zero pronouns, explicitly realized discourse entities,and.
.
.
entities inferable from the discourse situation?
(page 4).
The definition pro-posed by Grosz, Joshi, and Weinstein allows inferable entities, that is, entities that arenot expressed at the surface level of the utterance or immediately recoverable fromthe subcategorization properties of the verb (as, for example, zero pronouns are) toconstitute centers of an utterance.
However, the theory does not make explicit theparameters within which to characterize the class of permissible inferable elements orthe constraints on doing so.
We will return to this difficulty later.3.
The Corpus3.1 The Nature of the CorpusThe data examined consist of a collection of 32 e-mail messages exchanged amongfive employees of a Japanese company from June 5 to June 16, 1995.
The messagesconstitute a collective attempt to schedule a sports-watching outing convenient forand interesting to all five in the group.
Thus, the tone is usually casual.
The authorscombine standard aspects of written text with various strategies for encoding speech-like information in the messages: nonstandard uses of punctuation, katakana (thesyllabary for writing foreign words), and English; nonstandard spelling; emoticons;discourse markers, sentence-final particles, tense, and formality typical of speech; andfillers (Fais 2001; Fais and Yamura-Takei 2003).
Quantitative information for the corpusis given in Table 2.Table 2Number of messages, paragraphs, sentences, clauses, and charactersper author.Authors Messages Paragraphs Sentences Clauses CharactersH 5 9 20 60 880I 10 46 50 122 1,904M 5 27 39 84 1,268R 5 29 56 125 1,805U 7 35 60 127 2,015Total 32 146 225 518 7,8722 Kameyama (1998) also mentions two cases in which a hierarchical interpretation is warranted: reportedspeech and nonreport complements.
Our corpus does not contain examples of these kinds ofutterances.
On the other hand, it does contain tensed clauses acting as ?relative clauses?
and as verbalcomplements.
We have not separated these from their heads or matrix clauses.
This has no effect onthe analysis presented in this article, except for the fact that had we separated these clauses, it wouldhave made the problematic situation we describe later even more marked.
The status of these clausesvis-a`-vis centering is a topic in need of extensive investigation.122Computational Linguistics Volume 30, Number 23.2 Inferables and Transition States in the CorpusExample (1) illustrates how centering mechanisms apply to the beginning of one ofthe messages and how the CONTINUE and RETAIN transitions can model coherence:1a.
3 18watashi wa 18nichi no yakuluto-yokohamasen wame TOP 18th on Swallows vs. Baystars game TOPCb = (beginning)Cf = Swallowsvs.
Baystars game,418th, enthusiasmmotomoto noriki datta nodeactually enthusiasm was sinceCONTINUE1b.?
OK desu?
OK is?As for me, since I?m really up for the Swallows vs.Baystars game on 18th, that is OK with me.
?Cb = SvsB game ?Cf = SvsB game ?RETAIN1c.
U-demo tekondoh ni kyoumishinshin datta U-san yabut taekwondo in keen interest was U-san andCb = it = Swallowsvs.
Baystars gameCf = U-san, M-san, it,interest, taekwondoM-M-san wa koredeiindeshoukaM-san TOP I?m wondering if it is ok?But I?m wondering if it is ok for U-san and M-san, who haveshown a keen interest in taekwondo.
?Clause (1a) has no Cb, since it occurs at the beginning of the message.
The Cp of (1a) isSwallows vs. Baystars game, by virtue of the fact that it is topic-marked.
The subject of thecopular desu in (1b) is omitted; rule 1 implies that the referent for this zero argumentis Swallows vs. Baystars game, which is a correct assignment.
A similar process resolvesthe referent for kore ?this?
in (1c).
Note that the CONTINUE and RETAIN transitions do, infact, capture the intuition that this segment of the message is coherent and is ?about?the Swallows vs. Baystars game.Example (2) is much more typical of the messages in the corpus and is not aswell behaved as (1).
Notice that all the Cbs in this example are inferable ?from thediscourse situation?
of Ui?1.
The preponderance of inferable Cbs is typical; out of330 Cbs in the corpus, 250 (more than 75%) are entities other than pronouns, zero3 We will ignore first-person arguments in this analysis, since centering is intended to handle onlythird-person arguments.
How topic-marked first-person arguments affect attentional states in discourseis an interesting question, though beyond the scope of this article.We use the following abbreviations for Japanese case markers in this article: TOP, topic; SUBJ,subject; OBJ, object.4 There is no consensus as to the ordering of the arguments in a Japanese A no B construction (roughlyequivalent to possessives; Tetreault 2001; Matsui 1999; but see Fais 2002).
We have listed the argumentsin the order suggested in Fais (2002); this has little effect on the present discussion.123Fais Transitions and Coherencearguments, or explicitly realized entities.5 This raises a question undiscussed in thecentering literature: How do we interpret inferable Cbs in the context of assigningtransition types?
Example (2) illustrates the problems involved:2a.tokorode enseki nan desugaby the way restaurant isCb = ?Cf = restaurant2b.sendagaya kinpen ni sake wo nomerusendagaya neighborhood in alcohol OBJ can drinkCb = ?Cf = soba shop,Sendagayaneighborhood, alcoholumai sobaya ga aruto miminishimashitagood soba shop SUBJ is have heard?By the way, about the restaurant, I?ve heard there is a goodsoba shop, which also serves alcohol, around Sendagaya.
?CONTINUE?SMOOTH SHIFT?2c.heiten jikoku ga hayaisounanodeshop closing time SUBJ early seems becauseCb = shop closing time(inferable)Cf = shop closing timeSMOOTH SHIFT2d.?
chotto mazui kamoshiremasen ga?
a little bad might be butCb = choosing thisrestaurant ?
(inferable)Cf = choosing thisrestaurant ?2e.
I-I-sanatari gozonjidewa naideshoukaI-san information haveROUGH SHIFTCb = information?Choosing this restaurant may not be good because it closesearly.
I-san, do you have information about this restaurant??
(about restaurant)(inferable)Cf = I-san, information(about restaurant)The Cb of (2a) is null, since that clause is the first in the discourse segment.
Clause(2b) has three centers, listed in the Cf list.
All three of these entities are inferable fromthe discourse context of (2a).
We mentioned previously that there is no principled wayto determine the list of inferables of an utterance; it is even more difficult, then, to5 In the subsequent discussion, for the sake of simplicity, we will refer to this group as ?explicit?
centers,realizing that zero arguments are not precisely ?explicit,?
but setting them off in this way frominferable centers.124Computational Linguistics Volume 30, Number 2Table 3Transitions occurring in the corpus, by type.Transition type Number PercentageCONTINUE 54 16.4RETAIN 22 6.7SMOOTH SHIFT 2 0.6ROUGH SHIFT 2 0.6Transition to inferable Cb 138 41.8NULL 112 33.9Total 330determine the order in which inferables should be listed on a Cf list.
Therefore, wecannot say which of the Cfs in (2b) is the ?highest ranked?
and thus the Cb for (2b).Since we cannot determine which is the Cb, we likewise cannot determine whetherthe Cb of (2b) is the same as its Cp, and so we cannot label the transition at all.The fact that there is only one Cf for (2c) simplifies the problem somewhat.
ThatCf, which is inferable from (2b), must also be the Cb of (2c), but since we could notascertain the Cb of (2b), we do not know if the transition from (2b) to (2c) is a CONTINUEor a SMOOTH SHIFT.
Again, the presence of only one Cf in (2d) makes matters easier;we are able to label the transition from (2c) to (2d) a SMOOTH SHIFT.We surmise that I-san may not be inferable from the discourse context,6 thoughinformation (about the restaurant) is, and thus the latter becomes the Cb of (2e).
Becausethis Cb is neither the same as the Cb of (2d) nor the same as its own Cp, the transitionfrom (2d) to (2e) is a ROUGH SHIFT.Using the standard centering definitions, supplemented with the notion of NULLtransitions to label transitions to utterances that contain no Cb, we hand-tabulatedthe number of transitions of each type occurring in the corpus (Table 3).
The figuresfor CONTINUE, RETAIN, SMOOTH SHIFT, and ROUGH SHIFT are those for transitions toutterances containing either explicit, pronominal, or zero-argument Cbs.
Given thedifficulties in accurately labeling transitions to utterances containing inferable Cbs, wegrouped these latter together separately from transitions to utterances with explicit,pronominal, or zero-argument Cbs.There are two points of special interest in Table 3.
First, of course, is the particularlyhigh number of transitions to utterances containing inferable Cbs and the number ofNULL transitions.
At over 40%, the utterances involved in transitions to utterancescontaining inferable Cbs make up a substantial portion of the corpus.
Second are therelative proportions of CONTINUE, RETAIN, SMOOTH SHIFT, and ROUGH SHIFT transitions.Note that, considering just these transitions to utterances containing explicitly realizedcenters, these proportions are roughly what we expect of coherent text: Most of theshifts are CONTINUE, followed by a respectable number of RETAINs, and a very fewSHIFTs.6 Of course, in the absence of any principled way to determine this, this is merely conjecture.
In fact,because I-san is a part of the ongoing e-mail exchange, he could possibly be considered part of thediscourse context.
The difficulty is, of course, the lack of any rigorous way to determine what theelements in the discourse context are.125Fais Transitions and Coherence4.
Lexical Cohesion and Discourse Coherence: A Revision of Standard TransitionTypes4.1 Inferable Centers in Centering TheoryWe saw in Section 3.2 that the introduction of inferable centers into a centering anal-ysis leads to indeterminate transition identification.
We also saw that transitions toutterances with inferable centers make up a large proportion (over 40%) of the tran-sitions in this corpus.
It is important, then, if a centering analysis is to represent thenature of coherence in this corpus accurately, that we make principled provisions forthe notion captured by inferable centers in the theory.Only rarely are inferable entities actually listed in analyses in the literature, andthen usually when their presence is supported by previous explicit mention and by aclear, tight semantic or syntactic relationship between the entities involved, as in (3),taken from (17) in Kameyama (1998):3a.
It is the apparent intention of the Republi-can Party to campaign on the carcass of whatthey call Eisenhower Republicanism.Cb = Republican Party3b.
but the heart stopped beating Cb = Republican Party (inferablePossessor of the heart)3c.
and the lifeblood congealed Cb = Republican Party (inferablePossessor of the lifeblood)Note that (3) avoids at least one of the difficulties we encountered in (2); when thereis only one center to deal with, as there is in (2c) and (2d) and (3b) and (3c), thechoice of Cb is trivial.
However, in cases such as (2a) and (2e), or in (3b) if it had beensomething like but the heart and lifeblood stopped pumping, we cannot determine whatthe Cb should be.
Further, in these cases, it is impossible to identify the appropriatetransition to the following utterance; when the Cb of Ui?1 is undetermined (as it isfor (2b)), the transition to Ui (in this case, (2c)) is undeterminable.4.2 Logical Difficulties with Inferable CentersThere are further problems resulting from taking the use of inferable centers to itslogical extreme.
In our analysis so far, we have been concerned with explicit entitiesin Ui that realize centers in Ui?1 that are inferable from the discourse context.
To beaccurate, those inferable centers need to be listed in the Cf list for Ui?1.
However, ifwe process discourse incrementally, this leads to the conclusion that since we do notknow which inferable entity from Ui?1 will be evoked in Ui, we need to list everyinferable entity in the Cf list of Ui?1.
This is both computationally untenable and,in view of the lack of any parameters for determining what constitutes an allowableinferable Cb, impossible.
Even if it were possible and desirable, how could we definefor inferable entities the type of grammatical-role information essential to determiningthe placement of these entities on a Cf list?Again taking the definition of inferable centers to its extreme, we note anotherproblem.
Every utterance, not just Ui?1, evokes inferable centers.
There is nothing inthe theory to preclude a situation such as that shown in (4) (a version of (2) simplifiedfor illustrative purposes) (implicit inferable centers are given in italics):126Computational Linguistics Volume 30, Number 24a.sendagaya kinpen nisendagaya neighborhood inCb = ?Cf = soba shop,Sendagayaneighborhood,umai sobaya ga aruto miminishimashitagood soba shop SUBJ is have heard?I?ve heard there is a good soba shop around Sendagaya.
?udon shop, sakeshop, shop clerk,menu, food,customers.
.
.4b.demo heiten jikoku ga hayaisounandesubut shop closing time SUBJ is early?But the shop closes early.
?Cb = shop clerkCf = shop closing time,shop opening time,shop, shop clerk,door.
.
.In (4), an inferable center from the Cf list of (4b) matches an inferable center from theCf list of (4a) and is chosen as the Cb.
Of course, there could be numerous identicalinferable centers on the Cf lists of Ui and Ui?1, all ?vying?
for Cb of Ui.
Althoughthis is obviously an absurd extension of the inclusion of inferable centers in centeringtheory, there is nothing, unfortunately, in the theory itself to rule it out.4.3 Possible Solutions to the Problems of Inferable Centers4.3.1 Inferable Centers as Bridging References.
Inferable centers are similar to bridg-ing references (Clark 1977); they have a conceptual relationship to entities in a previousutterance.
There is a sense that bridging references should participate in the creation ofcoherence in a discourse (Hahn, Markert, and Strube 1996).
But the work on bridgingreferences characterizes this relationship as referential or anaphoric; this can be seenin the various terms under which this phenomenon is discussed: bridging references,indirect anaphora, functional anaphora, and partial anaphora.
Bridging references,however, unlike the usual case of anaphora, may be mediated not only by a strictidentity condition, but also by any number of other semantic relationships (is-a, has-a,made-of, at-time, etc.
).Unfortunately, the establishment of the semantic relationship between an anchorand its bridging reference is notoriously difficult.
Poesio et al (2000), even afterseverely restricting the types of relationships to be labeled, had extremely poor inter-labeler reliability on a first pass.
Every account in which bridging references are ad-dressed restricts allowable relationships to a small, relatively well-defined set (Vieiraand Poesio 2001; Poesio et al 2000; Murata, Isahara, and Nagao 1999; Strube andHahn 1999).
Cote (1998) proposes the use of lexical-conceptual primitives instead ofgrammatical relations in Cf templates and suggests that the conceptual informationthat this approach provides might be rich enough to supply part-whole informationnecessary to the resolution of bridging references.
She points out as well, however, thata number of other types of semantic relationships manifested in bridging referenceswould not be identifiable from lexical-conceptual information.
Thus, although workon bridging references has attempted to provide a characterization of the possible se-mantic relationships involved, what success has been achieved is limited to a smallsubset of cases.127Fais Transitions and Coherence4.3.2 Restrictions on the Notion of Inferable Center.
One possible way around thelogical problems introduced by inferable centers is to take into account only inferablecenters that are explicitly realized in an utterance when determining the Cb of thatutterance.
This would mean, for example, considering soba shop, Sendagaya neighborhood,and alcohol from (2b) in choosing the Cb for (2c).
But how do we make the choiceamong these possibilities?
Any of these three different, explicit, inferable centers couldbe chosen to be the Cb.
But this is exactly the difficulty: We have no principled wayto make such a choice.
We have no way of knowing which of these inferable centersis ranked highest in the Cf list for (2a) so that we can select that Cf to be the Cb of(2b).A second possibility is to allow only explicitly realized (i.e., noninferable) centers.This seems to be the approach taken by Passonneau (1998); her definition of a nullCb seems to imply that a Cb must be (noninferable and) explicitly realized, and hernull Cbs constitute the cases in which there is no explicit Cb.
In her examinationof the Pear Stories (recordings of people describing to another person a movie theyhad seen; Chafe 1980), NULL transitions (transitions to an utterance with a null Cb)represent the majority of transitions.
Although her concern is discourse segmentation,Passonneau does note that the patterning of transition types does not accurately reflectthe coherence of the stories.Allowing only explicit centers would mean, for the corpus studied in this article,that inferable Cbs become null Cbs and the proportion of NULL transitions becomes75.7%.
Under this assumption, this corpus would be characterized as extremely in-coherent, a claim belied both by native-speaker intuitions (an acceptable level of co-herency for these texts was confirmed by three native speakers) and also by the factthat the task that was the central concern of these messages was successfully com-pleted; the group exchanged a number of opinions and pieces of information andcame to a consensus regarding their sports outing, with no message showing confu-sion about information contained in previous messages.
Thus, the solution of allowingonly explicit centers does not yield an accurate characterization of the coherence ofthis corpus.Hurewitz (1998) chose to define allowable inferable Cbs fairly narrowly in herEnglish data, requiring functional dependency or a poset relationship to hold in orderfor a Cb to be recognized.
Even with this definition, which is more constrained thanwe have taken ?inferable?
to be in our previous discussion, she finds that 21% ofthe Brown corpus (a variety of written texts) and 28% of the switchboard corpus(taped telephone conversations) consist of what she calls a no-Cb condition.
Poesio etal.
(2000) report a similarly high proportion of nonexplicit Cbs in their English textcorpora.
They test a number of configurations of parameters of centering theory toattempt to minimize the number of null Cbs (reasoning that the best configuration ofparameters would result in the fewest violations of the constraints of the theory, inthis case, the constraint that all utterances in the discourse except for the first have atleast one Cb).
One way in which they are able to improve their results significantly isby allowing a restricted set of three types of nonidentity relationships between centers,that is, by recognizing three types of well-defined inferables.
However, simply limitingthe type of inferables allowed still does not address the issue of the indeterminacy oftransitions to utterances containing inferable Cbs.
And the central question raisedby the high number of nonexplicit Cbs found in naturally occurring texts remainsunaddressed: How can we characterize coherence in a text in which Cbs are so ofteninferable and thus in which transition types are often indeterminate?The crux of the problem lies in the application of standard centering processes toinferable centers.
In a nonproblematic case, a Cb in Ui is recognized by virtue of its128Computational Linguistics Volume 30, Number 2identity to a Cf in Ui?1.
This is (relatively) straightforward in the case of explicit centers.But now apply this process to inferable centers.
In a standard centering approach, aCb in Ui can also be recognized by virtue of its identity to an inferable center in Ui?1.This implies that we must somehow make available all the possible inferable centersin Ui?1 in order to recognize (possibly) one of them as the Cb for Ui.
We have alreadynoted that this position is untenable.
Even if we recognize the inferable centers ofUi?1 a posteriori by considering only those that appear in Ui, it is still impossibleto select which of these centers is highest ranked in Ui.
What we need, instead, is away to recognize a Cb in Ui not by virtue of its identity with a preestablished list of(explicit and inferable) centers, but by virtue of a relationship, other than identity, withthe explicit centers of Ui?1.
We propose the relationship of lexical cohesion to fill thisfunction.
The recognition of a lexically cohesive relationship, then, admits inferablecenters without allowing the virtually uncontrollable proliferation of hard-to-defineinferable centers in the Cf lists for utterances.
We propose a principled way to definethis relationship that not only avoids the problems discussed above but also moreaccurately characterizes the coherence of this corpus.4.4 Coherence and CohesionHalliday (1994) characterizes cohesion in text as the establishment of ?relations withinthe text that are not subject to [grammatical] limitations; relations that may involveelements of any extent, both smaller and larger than clauses, from single words tolengthy passages of text; and that may hold across gaps of any extent.
.
.without regardto the nature of whatever intervenes?
(page 309).7 Cohesion is that aspect ?whereby theflow of meaning is channelled into a traceable current of discourse instead of spillingout formlessly in every possible direction?
(page 311).
It is this ?traceable current ofdiscourse?
that centering is meant to model.Lexical cohesion contributes to textual coherence.
In other words, strong semanticand structural relationships among words in a text help to make that piece of text?make sense.?
Coherence is a property of discourse; cohesion is a property of dis-course elements.
Centering models coherence by characterizing relationships betweenelements of discourse.
We claim that it is not only the continuation of identical explicitdiscourse elements that creates coherence, but also strong cohesion among discourseelements.8Halliday identifies four features of text that create cohesion among discourse el-ements: conjunction, reference, ellipsis, and lexical cohesion.
Insights concerning con-junction types and their interactions with the processes of referent resolution havebeen elaborated in a number of works (Nariyama 2000; Nakaiwa and Shirai 1996;Kuno 1973) but have not been well integrated into the centering approach.
Referenceand ellipsis are, of course, some of the mainstays of centering research.
Lexical cohe-sion, however, is an aspect of text coherence that has had only a trivial applicationin a centering approach, although it has been incorporated into other aspects of natu-ral language processing (see subsequent discussion).
?Lexical cohesion,?
according toHalliday, ?comes about through the selection of items that are related in some wayto those that have gone before?
(page 330).
In centering, that relationship has been7 We follow Halliday in assuming that ?
[f]or a text to be coherent, it must be cohesive; but it must bemore besides.?
He characterizes the ?more?
as being socially, semantically, and structurallyappropriate.
We will not deal with these elements here but rather will limit ourselves to thecontribution of lexical cohesion to coherence.8 Of course it is possible to have cohesion without coherence and vice versa; Morris and Hirst (1991)give some nice examples.
However, as they assert, ?most sentences that relate coherently do exhibitcohesion as well?
(page 26).129Fais Transitions and Coherenceassumed to be one of identity of centers; an element in Ui is required to be the sameas an element in Ui?1 (or in its discourse context) in order for it to be considered aCb.
However, earlier we saw the difficulties of admitting inferables and the inabilityof a centering approach to characterize coherence for inferable centers.
Applying thenotion of lexical relatedness to cases involving inferables allows us to capture whatseems intuitively to constitute the relationship between clauses containing inferablecenters.A number of other accounts provide relevant information concerning lexical cohe-sion in text.
These accounts are based upon the characterization of semantic relationsamong discourse elements by reference to semantic information contained in WordNet(Harabagiu 1998, 1999), thesauruses (Harabagiu 1998; Morris and Hirst 1991; Okumuraand Honda 1994), or dictionaries (Kasahara et al 1996; Kozima 1993; Kozima and Fu-rugori 1993).
In all of these approaches, the semantic distance or similarity between(or among) words is computed, and in most of these accounts, the results are appliedto the segmentation of discourse.The intuition behind the importance of lexical relatedness has been applied to anumber of other tasks in natural language processing and analysis as well.
Lotfipour-Saedi (1997) uses lexical cohesion to develop a rigorous notion of ?translation equiv-alence?
; Boguraev and Neff (2000) to improve document summarization techniques;Sack (1999) to create ?diagrams of social cohesion?
for newsgroup postings; and Oku-mura and Honda (1994) to disambiguate word senses.Halliday asserts that ?this interaction between lexical cohesion and reference.
.
.
isthe principal means for tracking a participant through the discourse?
(page 332), thatis, for modeling focus.
Centering has provided us with a principled way of character-izing the tracking of reference; the addition of the notion of lexical cohesion allowscentering to function in an even more empirically comprehensive way, by makingpossible the principled inclusion of what have been called inferable centers.
In thenext section, we outline how lexical cohesion can be incorporated into a centeringtheory.4.5 COHESIVE Transition and COMPLETE SHIFTWith the use of the sorts of techniques to establish semantic distance described in theworks cited earlier, it is possible to be precise about the notion of lexical cohesion.In this section, we discuss how semantic distance is established using one of thesetechniques, a semantic similarity measure derived from the Gainen Base (?ConceptDatabase?)
(Kasahara et al 1996).
We then indicate how semantic distance can be usedto define the notion of lexical cohesion as a crucial element in the creation of twonew types of transition: COHESIVE and COMPLETE SHIFT, which allow us to adequatelycharacterize coherence in a corpus containing a high proportion of nonexplicit Cbs.The Gainen Base is a knowledge base built from machine-readable dictionaries ofJapanese.
Each word in the knowledge base is defined by a list of weighted keywordsextracted from the dictionary definition of the word.
The number of times a keywordappears in the word?s definitions determines the weight for the keyword.
Keywordsare standardized to take into account the presence of semantically similar words inthe definitions, and their weights are normalized to take into account the differinglengths of definitions in the dictionaries.
The semantic distance between two wordsis calculated as a function of the nearness of the two words in a vector space.9 For9 Each Wordi is defined by a list of standardized, weighted keywords from which is generated avectorized-Wordi.
More specifically, then, semantic similarity is measured by a function R that satisfies130Computational Linguistics Volume 30, Number 2Table 4Transition definitions.Cb(Ui) = Cb(Ui?1)OR Cb(Ui?1) = ?
Cb(Ui) = Cb(Ui?1) Cb (Ui) = ?and Cb(Ui) = ?Cb(Ui) = Cp(Ui) CONTINUE SMOOTH SHIFT COHESIVE ?Cf(Ui) ?
Cf(Ui?1)Cb(Ui) = Cp(Ui) RETAIN ROUGH SHIFT COMPLETE SHIFT ?
(?Cf(Ui) ?
Cf(Ui?1))our present purposes, then, we say that there is lexical cohesion between Ui andUi?1 when Cf(Ui) is semantically close to Cf(Ui?1) as determined using a well-definedsemantic similarity measure over the Gainen Base.10 We will examine in more detailin Section 4.6 whether semantic similarity is best viewed as holding between the setsof Cfs of utterances or between individual discourse entities in those utterances.
Fornow, we will talk equally of lexical cohesion between utterances and lexical cohesionamong the Cfs that participate in defining cohesion for those utterances.
We definethe relation ?
as indicating strong lexical cohesion, with a lexical cohesion factor ofone indicating identity.We supplement the standard table of transition states, shown in the left side ofTable 4, with transitions defined in the right side.
The sense of this table is as follows.We assume all centers to be explicit, that is, pronouns, zero arguments, or explicitlyrealized entities.
The left portion of Table 4 allows us to model transition states inwell-behaved explicit contexts, tracking the focus of the discourse in a specific, localway.
It includes the cases in which the Cb of Ui?1 might be ??,?
that is, that Ui?1 mightbe the discourse-initial utterance or might simply have no Cb, while Ui does have (anexplicit) Cb.
However, where there is not strict identity between any (explicit) elementin Ui and any (explicit) element in Ui?1, we have the situation in which Cb(Ui) = ?.
Wepropose a new interpretation for these cases, described in the right portion of Table 4.Table 4 defines two new types of shift to utterances that do not contain an explicitCb.
If there is at least one Cf in Ui that has a high lexical cohesion value with someCf(s) in Ui?1, then the transition from Ui?1 to Ui is a COHESIVE transition.
This situationis illustrated in clauses (2b), (2c), (2d), and (2e) of example (2).
The transitions tothese clauses, under the present proposal, are reanalyzed as COHESIVE, as shown in areanalyzed version of example (2) (entities claimed to bear close semantic relationshipsto one another are shown in boldface here and in subsequent examples):the following conditions:0 ?
R(Worda, Wordb) ?
1R(Worda, Wordb) = R(Wordb, Worda)R(Worda, Worda) = 1Wordb is more similar to Wordc than to Worda if R(Worda, Wordb)?
R(Wordc, Wordb)The function R = cosine A, where A is the angle defined by the vectors for Worda and Wordb, satisfiesthese conditions and is therefore chosen as the function to define the similarity between Worda andWordb.We refer the reader to Kasahara et al (1996) for a full discussion of the algorithms used to weightand normalize keywords and to calculate semantic distance.10 What constitutes ?semantically close?
is an issue we will discuss briefly in Section 5.4; exactly howsemantic distance is measured is elaborated in Section 4.6.131Fais Transitions and Coherence2a.tokorode enseki nan desugaby the way restaurant isCb = ?Cf = restaurantCOHESIVE2b.sendagaya kinpen ni sake wo nomerusendagaya neighborhood in alcohol OBJ can drinkCb = ?Cf = soba shop,Sendagayaneighborhood,alcoholumai sobaya ga aruto miminishimashitagood soba shop SUBJ is have heard?By the way, about the restaurant, I?ve heard there is a goodsoba shop, which also serves alcohol, around Sendagaya.?
COHESIVE2c.heiten jikoku ga hayaisounanodeshop closing time SUBJ early seems becauseCb = ?Cf = shopclosing timeCOHESIVE2d.?
chotto mazui kamoshiremasen ga?
a little bad might be butCb = ?Cf = choosing thisrestaurant ?COHESIVE2e.
I-I-sanatari gozonjidewa naideshoukaI-san information haveCb = ?Cf = I-san,information (aboutrestaurant)?Choosing this restaurant may not be good because it closesearly.
I-san, do you know about this restaurant?
?Each COHESIVE transition in the modified version of (2) is justified by the presenceof a strong semantic relation between at least one Cf in Ui and at least one Cf in theprevious utterance.
For example, soba shop in (2b) is semantically related to restaurantin (2a), as is alcohol, probably to a lesser extent, and Sendagaya (if our database includesthe information that this is the name of a restaurant).
Note that the transition from (2d)to (2e) in this interpretation is a COHESIVE one, rather than a ROUGH SHIFT.
Certainly theCp changes from restaurant to I-san, but since restaurant is still present in the Cf list for(2e), the transition is by no means as abrupt as the designation ROUGH SHIFT implies.The presence of a null Cb in and of itself, then, is not necessarily indicative ofincoherence.
The level of coherence is captured instead by the proportions of thevarious transition states present in a corpus, including COHESIVE transitions.Not all utterances containing null Cbs are felt to be cohesive with previous utter-ances, of course.
If there is no explicit Cb and no Cf in Ui such that it has strong lexicalcohesion with a Cf in Ui?1, then the shift is considered COMPLETE.
This is illustratedin example (5), which shows the continuation of example (1):132Computational Linguistics Volume 30, Number 25a.
U-demo tekondoh ni kyoumishinshin datta U-san yabut taekwondo in keen interest was U-san andCb = it = gameCf = U-san,M-san, it,taekwondo,interestM-M-san wa koredeiindeshoukaM-san TOP I?m wondering if it is OK?But I?m wondering if it is OK for U-san and M-san, who haveshown a keen interest in taekwondo.
?COMPLETE SHIFT5b.douyara tsuyuiri shitarashii toiu sengenmodetasomehow rainy season has come declarationCb = ?Cf = rain, today,declaration,beginning of rainyseasonyoude kyou mo shikkari ame ga futteimasuwith today also heavily rain SUBJ is raining?With the declaration that the rainy season has come, it israining heavily today.?RETAIN5c.
1818nichi ga ame toiu kakuritsu mo taka soudesuyone18th SUBJ rain probability high seems?There seems to be a high probability that it will rain on the 18th.
?Cb = rainCf = 18th,probability, rainThere is very low cohesion between the Cfs of (5b), that is, today, rain, declaration, andbeginning of rainy season, and those of (5a), namely, U-san, M-san, game, taekwondo, andinterest.
Thus, we designate the transition from (5a) to (5b) as a COMPLETE SHIFT, whichmatches our intuition that, in fact, the topic of the message has changed.
This is furthercorroborated by the fact that (5c) RETAINs the Cp of (5b) as its Cb; in other words, itgoes on to develop the new topic begun in (5b).Since the two sides of Table 4 are complementary, it is perfectly possible for co-herence to be characterized by various combinations of the transitions in the table.Example (6) illustrates the interaction between the two sides of Table 4:6a.konouchi jinguu no hou wa 17 nichi to 18 nichiof these Jingu TOP 17th and 18thCONTINUE, fromaboveCb = these11Cf = these, JinguStadium,Yokohama133Fais Transitions and Coherenceno yokohamasen ga iikato omotteimasu gagame versus Yokohama SUBJ is good suppose butgame, 17th, 18thCOHESIVE6b.J-rihgu no hou wa kahdo nadoJ-league TOP match-ups and othersCb = ?Cf = J-league,match-upinformationkuwashiikoto ga fumei nanodefurther information SUBJ unknown sinceRETAIN6c.?
wakaru hito wa ?
oshiete kudasaihave information someone TOP let me know pleaseCb = match-upinformationCf = person,match-upinformation ?
?Of these, for Jingu Stadium I suppose the game versus Yoko-hama on the 17th or the 18th would be good.
As for J-league,since I don?t have further information such as the match-ups,please let me know if you have any information.
?COHESIVE6d.bokushingu wa kongetsu wa ii kahdo ga nai nodeboxing TOP this month TOP good matches SUBJ no sinceCb = ?Cf = boxing,this month,match-upsCONTINUE6e.watashi wa ?
pasu shitaiI TOP skip would likeCb = boxingCf = boxing?Since there are no good boxing match-ups in this month, Iwould like to skip it this time.
?The transition from (6a) to (6b) is COHESIVE, since (6b) has no Cb and yet the Cfsof the two utterances are semantically related.
(6c) RETAINs match-up information from(6b), which is then COHESIVE with match-ups and boxing in (6d).
Since (6e) does in facthave an explicit Cb identical both to the Cb of (6d) and to its own Cp, the transition to(6e) is CONTINUE.
This latter transition is an example of a non-discourse-initial utterance11 It is a departure from the standard Cf template for Japanese to designate these as the Cb instead of thetopic-marked Jingu Stadium; however, this pronominal form comes immediately after the mention oftwo options in the previous clause and so seems to be the Cb regardless of its lack of marking.
Thischoice of Cb has no bearing on the point of this example.134Computational Linguistics Volume 30, Number 2without a Cb that licenses a CONTINUE transition by virtue of the second part of theOR disjunction in the second column of Table 4, namely, that the Cb(Ui?1) = ?
andCb(Ui) = ?.
(Note that (5) also demonstrates the interaction between the two sides ofTable 4, with a RETAIN transition following a COMPLETE SHIFT.
)The proposal to include COHESIVE and COMPLETE SHIFT in centering theory is moti-vated by concerns about having to specify two identical entities in adjacent utterancesin order for those utterances to exhibit coherence.
The requirement of identity leadsto the need to allow inferable entities to play a part.
However, it is often impossibleto characterize transition states to utterances containing inferable Cbs.
By includingthe notion of COHESIVE transitions, we capture the relatedness of two entities withoutthe need to invoke inferable centers, and we can far better characterize the apparentcoherence in this corpus.4.5.1 Transition States in the Corpus, Revisited.
Given the inclusion of COHESIVEand COMPLETE SHIFTs, we reinterpreted the labeling of transitions in the corpus (asrepresented in Table 3) and hand-tabulated a revised distribution of transition types(Table 5).
The decision to designate transitions to inferable Cbs and NULL transitionsas COHESIVE or COMPLETE SHIFT was made on the basis of an intuitive assessment ofthe possible semantic relations between entities in adjacent utterances.
However, apossible method for automatic determination is described in the next section.4.6 A Preliminary Implementation4.6.1 Preparation of the Corpus.
In order to explore the computational feasibility ofCOHESIVE and COMPLETE SHIFT, we subjected the corpus to an analysis of semanticdistance using the Gainen Base.
Before implementing the analysis, we processed thecorpus so that it contained only the canonical forms of the words in each utterance,the forms accepted by the Gainen Base algorithms.
The first step in this procedure wasto run the corpus through a morphological analyzer, ALT-JAWS (Nippon Telegraphand Telephone Corporation 1996), which rendered all word forms in their canonical(usually kanji [Chinese character]) form.
This is a necessary and standard preprocess-ing step for most computational analyses of Japanese text, which contains no spacesbetween word forms to indicate their morphological structure.
In addition, writers ofe-mail may use hiragana or katakana (the two syllabaries used for writing primarilyfunction words and foreign words, respectively) even for words that have standardkanji forms (Fais and Yamura-Takei 2003).
These words need to be rendered in kanjias well.
The results of this analysis were checked and corrected by native speakers ofJapanese in order to eliminate cases in which the analyzer chose the incorrect kanjiform for a homophonous hiragana representation.Table 5Reanalysis of transitions occurring in thecorpus, by type.Transition type Number PercentageCONTINUE 54 16.4RETAIN 22 6.7SMOOTH SHIFT 2 0.6ROUGH SHIFT 2 0.6COHESIVE 138 41.8COMPLETE SHIFT 112 33.9Total 330135Fais Transitions and CoherenceThe next step was to delete all but noun forms from the corpus.
This step substan-tiates the notion that the central factors in the centering approach are the discourseentities of utterances (we will return to this in Section 5.3).
Further, the antecedentsof all pronominal and zero-argument references were made explicit in the text.12 Thiswas done by inserting the kanji forms for these antecedents, as they appeared in thetext, into the utterance in which the pronominal or zero-argument form appeared.
An-tecedents were determined by a native speaker of Japanese.
The same native speakerassisted in dividing the text into clauses.
Both of these steps, identifying antecedentsand parsing sentences into clauses, can be completed, in theory, by automatic, compu-tational methods (Huls, Bos, and Claassen 1995; Nakaiwa and Shirai 1996; Paul andSumita 2001; Yamura-Takei et al 2002), but the success rate of these approaches is nothigh enough to rely on them for completely accurate analyses of this type of corpus atthis time.
Because our intent is to examine the effectiveness of the use of the GainenBase in determining lexical cohesion, and not to implement a fully automatic process,we did not attempt to use entirely automatic methods in the preprocessing of the text.4.6.2 Determining Semantic Similarity with the Gainen Base: The Problem of Cov-erage.
Of the 670 types of nouns present in the e-mail corpus, only 235 are found inthe machine-readable dictionaries with which the Gainen Base was constructed.
Whatmakes this ratio even more problematic is that a number of these missing words (e.g.,supo-tsu kansen, ?sports-watching event,?
rakurosu, ?lacrosse,?
and the names of sportsteams) are high-frequency words in this corpus.The problem of coverage in automatic language-processing systems is a commonone (Hutchins 1995; Sag et al 2002; Fujita and Bond 2002).
At the level of coverageprovided by the Gainen Base, however, we cannot usefully assess how well semanticsimilarity characterizes coherence in this corpus as a whole.
However, we can makethis assessment for those clauses in which every noun can be found in the Gainen Base.In order to get an accurate assessment of lexical cohesion between adjacent clausesthat fall into this subset of the corpus, we included those cases in which all the nounsin the clause itself as well as those in the clause before it were found the Gainen Base.Out of an original 443 clauses, there are 66 clauses that meet these two criteria.We measured semantic similarity between adjacent clauses in two ways.
In thefirst, we measured the semantic distance between the group of nouns in Ui?1 and thegroup of nouns in Ui.
In the second, we measured the semantic distances betweeneach individual noun in Ui and the group of nouns in Ui?1.13 The first method is far?lighter?
computationally, but the second method gives us useful information aboutthe contribution of each noun in Ui to the lexical cohesion between utterances.
We willcompare the information derived from these two approaches hereafter.4.6.3 Evaluation of the Use of Semantic Similarity.
We assessed in three ways howwell semantic similarity can define COHESIVE transitions and thus contribute to thecharacterization of coherence in the text.
First, in the 66 clauses with full coverageby the Gainen Base, we examined the 18 instances of what we had, on the basis ofintuitive human judgment, designated COHESIVE transitions.
In particular, we focused12 We did not, however, include the entities involved in event deixis; the identity of these entities is muchharder to determine, both for human judges and for automatic language-processing systems.13 We actually measured semantic similarity in a third way as well, that is, between every possiblecombination of the individual nouns in Ui?1 and those in Ui.
This yielded the same results as theindividual-to-group method reported on here and, of course, is much ?heavier?
computationally, so wehave restricted our discussion to the first two methods.136Computational Linguistics Volume 30, Number 2on the noun(s) we had singled out in our revised hand-tabulation of the corpus (Ta-ble 5) as providing the lexical cohesion in these transitions.14 Using results from theindividual measures of semantic similarity (the second method described earlier), wedetermined the noun in Ui with the highest level of semantic similarity to the nounsin Ui?1.
We then compared the nouns picked out by human judgment as providinglexical cohesion with those determined computationally to see if they matched.
Weeliminated three cases in which there was only one noun in Ui and thus only onepossible choice for the lexically cohering entity, which would, by default, have hadthe highest semantic similarity to the preceding utterance.
Out of the 15 remaining ex-amples of COHESIVE transitions, in 13 cases, or 87% of the time, the human judgmentsand the computationally determined choices matched.The other two assessments of the results are based on centering claims for the rela-tive ease of processing of the different transitions, claims captured in rule 2: CONTINUEtransitions impose the lowest inferential load on processors, ROUGH SHIFTs the highest.Since COHESIVE transitions act like CONTINUE transitions but replace the identity con-dition on Cbs with a similarity condition, we conjecture that they place only a slightlyhigher load on processing than CONTINUE transitions.
Likewise, since COMPLETE SHIFTsrepresent an even greater discontinuity than ROUGH SHIFTs (there being not only noCb in the utterance, but also no entity even similar to entities in the previous ut-terance), we conjecture that COMPLETE SHIFTs impose a higher processing load thanROUGH SHIFTs.We reason that greater semantic similarity corresponds to a lower processingload.15 Granted this assumption, then, utterances that are connected by CONTINUEtransitions have the highest semantic similarity, since CONTINUE represents the lowestprocessing load; those connected by COMPLETE SHIFTs, the lowest semantic similar-ity, since COMPLETE SHIFT has the highest processing load.
Although the particularranking of RETAIN, SMOOTH, ROUGH, and COHESIVE transitions is problematic, we aresaved from having to make an exact determination by the fact that, among the 66clauses with full coverage, only CONTINUE, COHESIVE, and COMPLETE SHIFT transitionsare well-represented (we simply note the results for the two RETAIN transitions, sincethis is hardly a large enough sample to be meaningful).
Our reasoning then predictsthat CONTINUE transitions have the highest semantic similarity measures, followed byCOHESIVE SHIFTs, followed by COMPLETE SHIFTs.16In our first assessment of this prediction, we averaged semantic measures for eachtransition type over the 66 clauses with full coverage by the Gainen Base.
Table 6gives the averages obtained for both the groupwise and individual analyses.
Theseresults support the ranking of transitions for processing load predicted on the basisof similarity measures.
However, averaging over all messages provides only a grossapproximation of the values for each transition type.
To get a more detailed look atthis claim, we examined the semantic distances between entities involved in each typeof transition within messages.The 66 clauses with full coverage include six messages with only one clause andfour messages with only one transition type represented; this resulted in the elimina-14 Where there was more than one noun, as, for example in (2b), we chose the one that seemed,intuitively, to have the strongest semantic connection to a center in the previous utterance.15 This claim must, of course, be tested empirically and independently supported.
However, it seems areasonable assumption and allows us to further evaluate the characterization of coherence by semanticsimilarity.16 We do not have nearly enough data to determine absolute values for each transition type (or even todetermine whether this would be a desirable course of action), and so we base our evaluation onrelative values for transition types (see Section 5.4 for further discussion).137Fais Transitions and CoherenceTable 6Average similarity measures for each transition type, for both groupwiseand individual analyses.Groupwise analysis Individual analysisTransition type Number Average similarity Average similarityCONTINUE 10 0.605 0.639RETAIN 2 0.530 0.496COHESIVE 18 0.204 0.231COMPLETE SHIFT 36 0.068 0.069Total 66tion of 19 clauses (since it is impossible to determine relative values of transitions ineither of these cases), leaving us with a total of 47 clauses grouped into 12 messages.We sorted the types of transitions to these clauses within each message by similaritymeasure.
For each transition, we ascertained whether it fulfilled the prediction forranking transitions by inferential load that was made on the basis of our earlier as-sumptions concerning semantic distance.
We assigned two scores for each transition:whether it was appropriately positioned with respect to the preceding transition andwith respect to the following transition in the sort.
Those transitions with the highestand the lowest semantic measures were scored only with respect to the following andthe preceding transitions, respectively, and thus received just one score.
Two consecu-tive identical transitions were scored ?correct.
?Table 7 gives an example of how this scoring was performed for the clauses fromone representative message that have full coverage in the Gainen Base.
It lists thetype of transition to each clause, the semantic distance to the previous clause, and thescores designating whether that transition is appropriately positioned with respect tothe previous and following transitions.
(Recall that the predicted order is CONTINUE,COHESIVE, COMPLETE.)
So, for example, the CONTINUE transition to clause 235 fulfillsthe ranking prediction with respect to both the previous and the following clauses; itssemantic measure is lower than that of only one other clause, which is also a CONTINUE,and is higher than that of a COHESIVE transition.
The COMPLETE SHIFT to clause 227,on the other hand, fulfills the prediction vis-a`-vis the previous transition on the listTable 7Ranking transitions in a representative message by similarity measure.Semantic measure (semanticClause Transition to clause distance to previous clause) Score220 CONTINUE 0.44113 Correct v235 CONTINUE w/?
0.13974 Correct ?Correct v228 COHESIVE 0.06226 Correct ?Correct v227 COMPLETE 0.03922 Correct ?Incorrect v216 COHESIVE 0.01370 Incorrect ?Correct v234 COMPLETE 0.00000 Correct ?138Computational Linguistics Volume 30, Number 2Table 8Evaluation of relative similarity measures for transition types.Transition type Groupwise analysis Individual analysisNumber Percentage Number PercentageCONTINUE 12/12 100 11/12 92RETAIN Ranked before cohesive shift Ranked before cohesive shiftCOHESIVE 26/29 90 25/29 86COMPLETE SHIFT 25/28 89 24/28 89Total 63/69a 91 60/69a 87aSince we make no claim as to whether the placement of RETAIN is correct ornot, we do not count it in these totals.
(i.e., its semantic measure is lower than that of a COHESIVE transition) but violates theprediction with respect to the following transition (i.e., its semantic measure is higherthan that of another COHESIVE transition).
For 47 clauses over 12 messages, then, thetotal number of such scores was 70: 24 scores for the transitions having the highest andlowest measures in each message, and two each for the remaining 23 transitions, onefor their positions relative to the transitions above, and the other for their positionsrelative to the transitions below them.Recall that we determined similarity in two different ways: first, for the groupof nouns in Ui?1 and the group of nouns in Ui, and second, for the group of nounsin Ui?1 and each individual noun in Ui.17 Table 8 reports the total number and per-centage of correct and incorrect scores for each transition type in both the groupwiseand the individual analyses (the measure taken for Ui in the latter case is the maxi-mum similarity measure out of the measures for all the nouns in Ui).
The results inthis table suggest that similarity scores can accurately represent relative coherence ascharacterized by the transitions in this small sample.
That is, the similarity scores wehave examined here reflect the relative load on processing imposed by each type oftransition with between 86% and 100% accuracy, with groupwise scores being slightlymore accurate than those based on the highest individual score.
In addition, similaritymeasures never predict a CONTINUE transition with a higher processing load (i.e., lowersimilarity score) than a COMPLETE SHIFT.
That is, the relative positions of CONTINUE andCOMPLETE SHIFT are always correct.We examined the cases in which similarity scores make an incorrect predictionabout relative placement in the scale of processing load.
The one incorrect predictionconcerning a CONTINUE (in the individual-analysis method) involves an example inwhich Ui?1 contains eight nouns; the similarity of each individual noun in Ui to thegroup of nouns in Ui?1 is ?diluted?
by the high number of nouns in Ui in this case(the average number of nouns per clause in the corpus is 2.3).The remaining incorrect predictions involve the assignment of lower similarityscores to COHESIVE transitions than to COMPLETE SHIFTs.
Some of these lower scores forCOHESIVE transitions are the result of the fact that world knowledge is necessary toinfer a connection between the two clauses.
This is the case, for example, in (7):17 Table 7 reported groupwise scores.139Fais Transitions and Coherence7a.toode demo Toukyo ni modotte kitatokorodeat a distance though Tokyo to come backCb = ?
(fromprevious clause)Cf = distance,TokyoCOHESIVE7b.enkai taimu niwa choudo iidesuyonedrinking party time for TOP exact rightCb = ?Cf = party, time?Even if it?s far we can come back to Tokyo just the righttime for a drinking party.
?It requires world knowledge to understand that there is a connection between how faraway something is and the time that it will take to travel there.
Although humans canmake this inference intuitively, that understanding is not represented in the GainenBase.18Other incorrect judgments are the result of how the database handles determiningthe similarity scores, ?quirks?
that don?t seem to match our intuitive judgments, as in(8):8a.jikantekiniwa choudo taimingu wa iidarou shitimewise TOP exact timing TOP seems good andCb = ?
(fromprevious clause)Cf = time, timingCOHESIVE8b.
?chiritekini mo tookuwa naindegeographically too far TOP notCb = ?Cf = night game ?,geography?Timewise, the timing seems good, and the night game is not faraway either.
?The Gainen Base yielded a relatively low score for the similarity between jiken, ?time,?and yoru, ?night,?
despite our strong sense that these two words should be closelyrelated.19Overall, however, similarity scores seem to provide a fairly accurate measure ofthe relative coherence of this subset of the corpus.
This result, coupled with the high18 Recall that in 13 out of 15 cases, the Cf judged by humans to license a COHESIVE transition and the Cfpicked out by the similarity measure matched.
(7a) is one of the two clauses in which thehuman-chosen Cf did not match that chosen by the Gainen Base (the second is given in (8)).
Theprevious clause is If it is a day game.
The discourse entity tode, ?at a distance,?
was the Cf chosen byhuman judgment to license the COHESIVE transition, since a human can make the connection that it isthe day game that is at a distance (as evidenced in the translation).
However, the use of the Gainen Basedetermined Tokyo to be more semantically similar to day game, with a score of 0.105 as compared to0.005 for tode.19 This is the second of the two cases in which human judgment and computational choice for lexicallycohering entity did not match.140Computational Linguistics Volume 30, Number 2level of correlation discussed earlier between lexically cohesive entities designated byhuman judgment and those determined by semantic similarity, supports our proposalthat lexical cohesion, as measured by semantic distance, can feasibly be included as awell-defined notion to capture crucial aspects of text coherence.4.7 Exploring the Implications of the COHESIVE Transition and COMPLETE SHIFT4.7.1 The Need to Identify Relation Type.
The usefulness of relaxing the notion ofidentity for Cbs has been recognized by Poesio et al (2000) and others (Hahn, Markert,and Strube 1996; Murata, Isahara, and Nagao 1999).
Poesio et al supplemented theidentity relation with three different possible semantic relations between Cfs in theutterances: set membership, subset, and ?generalized possession.?
Murata, Ishara, andNagao induced a number of possible relations between bridging reference and anchorusing a verb case frame dictionary and a corpus of Japanese A no B expressions (whereA and B are nominal arguments and the A no B construction encodes a wide variety ofsemantic relations between the two nominal arguments [Shimazu, Naito, and Nomura1987]).As noted in Section 4.3.1, however, in all of these approaches, only a small subsetof examples of bridging relations can be handled, because they all attempt to identifysome particular relation existing between two elements.
This is a necessary move forresolving bridging references and building text understanding systems, but neitherof those is our aim here.
We merely need to identify the level of semantic closenessor similarity between Cfs in Ui and Cfs in Ui?1.
Utilizing instead the more generalsemantic-distance measure proposed here, then, has several advantages over the ex-plicit choice of particular relation labels.
First, it avoids the need to make choices aboutwhich relations can or cannot, should or should not be included, as well as the dif-ficulties with interlabeler reliability that Poesio et al note, since there is no labelingin our approach.
This is actually closely tied to another advantage: There is no needto limit the types of semantic relationships into which the Cfs can enter.
Thus, thereis no need to restrict our analysis to a subset of the phenomenon; our account willhandle inferable centers having any kind of semantic relationship to the centers in theprevious utterance.4.7.2 Overestimation of COMPLETE SHIFTs.
In examining Table 5, we see a high numberof COMPLETE SHIFTs.
Is this number an accurate estimation of the (in)coherence in thiscorpus?
Of course, as we saw in (5), when a message makes a shift in topic, weexpect a COMPLETE SHIFT to occur.
The writers of the messages in this corpus made 146paragraphs (see Table 2); although we know that there is no guarantee that writers?paragraphing will coincide with shifts in cohesion, this number at least gives us ageneral estimation of a possible maximal number of COMPLETE SHIFTs (we would expectwriters to err on the side of more paragraphs than topics rather than on the side ofmore topics than paragraphs).
The number of COMPLETE SHIFTs is comfortably withinthat range.But there are two confounding factors that make this number higher than is ac-tually appropriate for the nature of the corpus.
The first is the inability of a centeringapproach to handle event deixis (Fais and Yamura-Takei 2003).
Consider (9):9a.
U-kyukyo U-sanno shigotonotsugou jou 17nichi nourgent U-san business because of 17th onCb = ?Cf = U-san, business,17th, match-up141Fais Transitions and Coherencedou kahdo ni henkoushitai tonokotodesusame match-up to want to change thing is?Because of U-san?s urgent business, she would like tochange to the same match-up on the 17th.
?COMPLETE SHIFT9b.watashi wa ?
OKnan desu game TOP ?
OK is but?That?s OK with me.
?Cb = ?Cf = that ?RETAIN W/?9c.minna wa doudeshoueveryone TOP how isCb = that ?Cf = everyone, that ?
?How is it for everyone else?
?The zero argument translated as that in (9b) is an example of event deixis.
Whenwe examine the Cf list for (9a) to ascertain the Cb of (9b), we do not encounter thator its referent.
In fact, we cannot encounter that.
It is not possible for the discourseelement represented by that to have appeared in the Cf list in (9a); clauses do notcontain self-referential discourse elements.
Thus, it is impossible to recognize, withinthe theory, that the discourse element that in (9b) is functioning as a strong cohesiveelement in the discourse.
This is a problem to be resolved within centering theoryregardless of whether COHESIVE transitions and COMPLETE SHIFTs are countenanced.However, sentential deixis does contribute to a slight skewing of the proportion ofCOMPLETE SHIFTs found in this corpus, for example, the COMPLETE SHIFT resulting fromthis problem in (9a)?
(9b) and similar examples in the corpus.The second confounding factor is actually simply a byproduct of the nature of thecorpus.
Example (10), which is an entire message, illustrates:10a.
I-I-sanno teian de subete OK desuI-san?s proposal all OK are?All of I-san?s proposals are OK with me.
?Cb = ?Cf = all, I-sansuggestionCOMPLETE SHIFT10b.1ruigawademo ruigawademo kamaimasenfirst-base side third-base side don?t mind?I don?t mind the first-base side or the third-base side.
?Cb = ?Cf = first-base side,third-base sideCOMPLETE SHIFT10c.sendagayanara ?
tashou osokunattemo heikidesuneSendagaya if ?
quite late even if don?t careCb = ?Cf = Sendagaya,party?, lack of caring?If it?s Sendagaya, we don?t have to care even if the party goeslate.
?142Computational Linguistics Volume 30, Number 2The COMPLETE SHIFTs in this passage are perfectly appropriate; there is no cohesionamong any of the discourse entities in this message.
Why would anyone send a mes-sage that was completely, by this account, incoherent?
In fact, the statements in (10)refer to the outcomes of various discussions held in the course of exchanging the mes-sages in this corpus.
This message occurs toward the end of the exchange of messages,as resolution of the questions of what sports event to go to, where to sit, and whatrestaurant to go to afterward is in sight.
This writer is simply adding his opinionson each of these apparently unrelated topics.
The relationship among them all holdsonly in the understanding of the coparticipants in the message exchange.
Althoughwe might be able to imagine the sorts of mechanisms required to model this level ofunderstanding, we are a very long way from realizing them.4.7.3 Lexical Cohesion and Text Understanding.
The incorporation of a COHESIVEtransition into our centering account gives us a flexibility that is important for full-text understanding of the discourse.
Consider example (11):11a.watashi mo ?
terebi de shika mitakotowanai nodeI too ?
TV on only have seen sinceCb = ?Cf = lacrosse ?,20 TV11b.namade kansen shitaikimosuru nodesu galive game watching feel like because butCb = ?Cf = live gamewatching11c.?
25 nichi dato?
25th is ifCb = live gamewatching ?Cf = live gamewatching ?, 25th11d.
M- H-M-san H-san ga ?
sanka dekinai desuneM-san H-san SUBJ ?
join cannot isn?t itCb = ?M-san, H-san,game ?
?Since I have seen it only on TV, I feel like watching a livegame, but if it is on the 25th, M-san and H-san cannotjoin us for the game, can they?
?Lacrosse in (11a), (some) live game watching in (11b) and (11c), and (a) game (on the 25th) in(11d) are actually semantically distinct elements, and recognizing their distinctivenessis important for full-text understanding or summarizing.
However, maintaining thesedistinctions in a standard account means characterizing the transitions between theutterances containing them as NULL SHIFTs.
(It is not clear that we would even wantto say that (a) game (on the 25th) was an inferable center from (some) live game watching.
)Being able to designate these transitions as COHESIVE allows us both to maintain the20 The message that this is taken from constitutes a sort of lesson on lacrosse from one of the authors toall the others.
The ?
in (11a) refers to this global topic; however, neither lacrosse nor TV appears in thepreceding utterance, and so (11a) has no Cb.143Fais Transitions and Coherencesemantic distinctiveness of the discourse elements and to capture the coherence in thisportion of the discourse.4.7.4 Lexical Cohesion and Discourse Segmentation.
As we saw earlier, the useof some notion of lexical cohesion to delineate discourse structure is fairly well re-searched.
In the lexical chain approach (Morris and Hirst 1991), a new discourse seg-ment is hypothesized where the chain ?breaks,?
that is, where subsequent entitiesdo not bear a semantic relationship to previous entities that would allow them to beadded to the chain.
Kozima (1993) provides an algorithm for determining where, onthe graph of semantic cohesion values of words in a text, likely topic breaks occur andvalidates that determination against human judgment.
We would say, then, that oncea chain breaks or a significant dip in the semantic cohesion value graph occurs, theutterance following such a break is considered the first utterance of a new discoursesegment.In terms of semantic distance as determined by the Gainen Base, we suggest thata sufficiently low similarity measure might characterize both COMPLETE SHIFTs and thebeginning of a new discourse segment.
Once again, ?sufficiently?
must be defined; inlight of the preliminary results we saw previously, we conjecture that the definitionof ?low?
will be relative to the measures for similarity in the message under scrutinyand not an absolute value (see Section 5.4).In addition, examination of the particular entities contributing to high levels ofsemantic similarity might also allow us to characterize the notion of ?global topic,?albeit in a differentiated way.
That is, if we determine not just one semantic distancemeasure for the sets of entities in two adjacent utterances, but the individual distancesfor each combination of those entities (as briefly described in note 13), we can deter-mine those entities that are contributing the greatest amount of semantic similarity tothe measure and identify a cluster of entities that can be taken to represent a globaltopic.This concept is worth examining more closely, since it bears on some of the veryfoundations of centering theory.
The Cb of an utterance ?represents the discourseentity that the utterance Ui most centrally concerns, similar to what is elsewhere calledthe ?topic??
(Walker, Joshi, and Prince 1998, page 3).
The presence of a Cb is takento be both a necessary and a sufficient condition for topic coherence.
However, inour account, utterances that have a coherent relationship to the immediate contextof discourse may nonetheless have no Cb; that is, the presence of a Cb is, in ourapproach, only a sufficient condition.
Our claim, then, is that this more accuratelyreflects the nature of how coherence is maintained in discourse: not only through theexplicit repetition of a central entity, but also through the successive use of entitiesthat are closely related semantically.
In our account, Cbs are recognized and functionjust as in standard centering theory, but their absence, a common situation in at leastsome kinds of discourse, does not signal a breakdown in coherence.
Coherence maybe maintained as well by semantically similar entities, which can become Cbs in theirown right, as match-up information and boxing do in (6).
Using an individuated approachto determining semantic similarity, we can identify these particular entities.5.
Future Work5.1 Refinement of the COHESIVE TransitionThere are a number of aspects of the proposal that need further scrutiny.
Note thatwe have defined the COHESIVE transition by reference to any Cf in Ui.
It might be thecase, in fact, that there is motivation to define two different COHESIVE transitions: a144Computational Linguistics Volume 30, Number 2?CONTINUE COHESIVE,?
in which the Cp(Ui) has the highest similarity measure withrespect to Cf(Ui?1), and a ?RETAIN COHESIVE,?
in which some other Cf has the highestsimilarity to Cf(Ui?1).
In our preliminary implementation with this corpus, the entityin Ui with the maximum semantic similarity to Ui?1 was the Cp of Ui 55% of the time.Whether such a distinction is a necessary or meaningful one is a completely openquestion.In a similar vein, we might suggest that the Cf in Ui with the highest similarity tothe Cfs in Ui?1 be designated as a type of Cb (say, Cb?).
So, for example, if soba shopin (2b) had the highest level of similarity to restaurant in (2a), soba shop would be theCb?
of that utterance.21 What would be the ramifications of this move for the theory?Certainly there would be far fewer utterances with Cb = ?.
In terms of trackingfocus in the discourse, one of the major aims of the centering approach, this is a positiveresult.
However, if the Cb?
is chosen simply on the basis of semantic similarity, we loseanother major insight of centering theory, namely, that focus is not dependent uponsemantics (Hudson-D?Zmura and Tanenhaus 1998) or upon word order (Gordon et al1999; but see also Gordon, Grosz, and Gilliom 1993), but upon the grammatical rolesplayed by the Cfs.
It is possible that for any given language, speakers tend to placeCfs that have strong semantic ties to the previous utterance in grammatical roles highon the Cf template, but this is an empirical question that we do not have the data toanswer here.5.2 ScalabilityThe incorporation of scalable considerations into a centering account provides enor-mous flexibility.
It remains to be seen how best to use this added capability.
Forexample, some COHESIVE transitions seem more cohesive than others.
Compare theCOHESIVE transition in (12) with the COHESIVE transitions in (13):12a.douyara tsuyuiri shitarashii toiurainy season beginning has happenedCb = ?Cf = beginningof rainy season,declarationsengenmodeta youdedeclaration withCOHESIVE12b.kyou mo shikkari ame ga futteimasutoday heavily rain SUBJ is rainingCb = ?Cf = rain, today?With the declaration that the rainy season has come, it is rainingheavily today.
?21 We can?t corroborate this, because sobaya is not in the Gainen Base.145Fais Transitions and Coherence13a.watashi wa naniyorihitsuyounamono wame TOP more important than anything else TOPCb = ?Cf = feeling,most importantthing, strength!
!tairyoku nari toiukoto wo misetsukerareta younaphysical strength OBJ was shownki ga shitanodesu gafeeling SUBJ got but COHESIVE13b.
??
mita kata ga itarawatched person SUBJ if existsCb = ?Cf = person,game ?COHESIVE13c.kansou wo kikasetekudasaiimpression OBJ let me knowCb = ?Cf =impressions?That gave me a strong impression that PHYSICAL STRENGTHIS MORE IMPORTANT THAN ANYTHING ELSE.
If someoneelse watched (that game), please let me know your impressions.
?We have the intuition that the COHESIVE transition in (12) can be characterized as?more?
COHESIVE than the ones in (13).
Both of these examples come from the samemessage, and the semantic similarity measures for each of these examples confirmsour intuitions: The measure for the COHESIVE transition between (12a) and (12b) is0.583; for that between (13a) and (13b), 0.166; and for that between (13b) and (13c),0.011.22 It is not clear to what use we might put this more detailed information aboutthe varying levels of strength of connection among utterances; however, it parallels theobservation in Fais (2001) that some e-mail authors make hierarchical distinctions inmarking paragraphs in their messages, using line breaks to separate utterance clustershaving some semantic connection and full spaces to separate utterance clusters havingweak or no semantic connection.Recall, too, that lexical cohesion, as measured by semantic distance, is only oneaspect of coherence.
Merging this measure with information provided by conjunctions,22 We chose examples from the same message because comparison of raw measures across messages maynot be informative (see Section 5.4).
However, we expect that measures within messages can becompared with one another usefully.The very low measure for the transition between (13b) and (13c) is consistent with the observationthat the cohesion between these two clauses actually may not reside in the similarity between personand impressions, but in our intuitive understanding of a relationship between game and impressions (ofthe game).146Computational Linguistics Volume 30, Number 2referential form, and other aspects of discourse would allow a more comprehensiveaccount of coherence.5.3 Beyond Simplex NominalsThe ramifications of exploiting lexical cohesion within a centering theory are exciting.Up to this point, we have considered only the cohesion exhibited by discourse entities.But not only (simplex) nominal arguments enter into cohesive relationships.
Consider(14), in which the recognition of the contribution of the verb to the cohesion of theexcerpt could allow us to account more accurately for the coherence in the passage:14a.watashi wa asuno doyoubi wa shusshashinai nodeI TOP tomorrow Saturday TOP won?t go to work sinceCb = ?Cf = tomorrow,SaturdayCOHESIVE14b.chiketto ya shuugoubasho nado watickets and meeting place and so on TOPCb = ?Cf = ticket,meetingplace, discussion,Mondaygetsuyoubi ni soudan toiukotoni shitaindesugaMonday on discuss would like to COMPLETE SHIFT14c.hataraku hito gomennasaiworking people sorry(Cb = ?Cf = workingpeople)?Since I won?t go to the office tomorrow (Saturday), I?d like todiscuss tickets and a meeting place on Monday (sorry to thosewho are working).
?The first transition shown is COHESIVE by virtue of the Cfs tomorrow and Saturday in(14a) and Monday in (14b).
But considering only the discourse entities appearing inthe Cf lists, working people in (14c) is not cohesive with any of the other elements inthis passage, although the inclusion of (14c) in this portion of the message seems quitecoherent and natural.
However, if we allow verbal elements to contribute to cohesion,working people then shows cohesion with shusshashinai, ?won?t go to work,?
and we canexplain why the passage seems coherent.In a similar vein, the incorporation of an adequate analysis for complex nominalswould allow us to refine our measurement of cohesion as well.
Recall (2), in whichlexical cohesion exists among the entities enseki ?restaurant,?
sake ?alcohol,?
and sobaya,?soba shop.?
While the recognition of this cohesion allows us to characterize the co-herence in the message, in fact, we probably underestimate the cohesion present if webase our measures on the individual lexical items listed.
If we could calculate lexicalcohesion not just for simplex nominals, but for complex nominals as well, we wouldcalculate cohesion for enseki and for the entire phrase sake wo nomeru umai sobaya, ?a147Fais Transitions and Coherencegood soba shop, which also serves alcohol,?
possibly a much stronger cohesive con-nection than that among the individual items.235.4 Improving ImplementationWe demonstrated in Section 4.6 that semantic distance as measured by the GainenBase provides a feasible basis for a rigorous definition of lexical cohesion.
In order forthis or any similar implementation of semantic distance measure to be fully effective,however, two major areas need to be addressed.
The first is coverage; while the lack ofcomplete coverage of the corpus by the Gainen Base does not prevent us from makingan assessment of the Gainen Base?s effectiveness over a subset of the data, it does makeit impossible to characterize cohesion over the corpus as a whole.
The second area thatneeds to be addressed has to do with definitions of distance for each transition type.Throughout our discussion we have examined semantic distances as relative strengthswithin messages; it would be useful to determine empirically whether it is possibleto set definitive, independent levels for each transition type.
These levels might beabsolute (e.g., SMOOTH SHIFTs are those transitions having a semantic measure of 0.15?0.3) or, what seems more likely, relative, such that a portion of the range of semanticdistance in a particular message is defined for each transition type (e.g., in a messagein which semantic distances measure from 0.005 to 0.875, SMOOTH SHIFTs correspondto distances falling between 15% and 25% of the total range of 0.87, that is, from 0.13to 0.22, for that message).6.
ConclusionUpon subjecting a corpus of Japanese e-mail data to a centering analysis, it becameclear that a centering description of these messages had to rely heavily on inferable cen-ters and was not adequate to capture the coherence this corpus displays.
We couchedthe notion of connectedness that inferable centers were intended to capture in terms ofthe more principled and explicit relation of lexical relatedness.
We used this relation,then, to supplement the standard inventory of transitions with well-defined transitiontypes that more accurately characterize the nature of coherence in this corpus anddemonstrated the computational feasibility of this approach in a preliminary imple-mentation.
The proposed transition types provide a characterization of a previouslyunaccounted-for situation in centering theory, namely, the coherence of sequences ofutterances containing inferable Cbs.
This is a crucial improvement over the standardmodel because of the high number of nonexplicit Cbs in this corpus (and others; seePassonneau 1998).
The inclusion of a COHESIVE transition and COMPLETE SHIFT allowsus to characterize the 76% of the corpus in which nonexplicit Cbs play a part, a portionof the corpus undescribed in the standard approach, while maintaining the standardoperation of the usual transition states of centering theory in cases in which explicitCbs are present.It may be the case that lexical cohesion and the notion of a COHESIVE transi-tion can make other contributions to discourse analysis as well, such as allowingus to characterize coherence in a discourse while still recognizing referentially dis-tinct discourse elements.
Further, these notions can augment the definition of thetopic of a discourse segment by virtue of the semantic information contained in acohesion analysis.
Finally, such an analysis can provide clues to discourse segmentboundaries.23 I would like to thank an anonymous reviewer for pointing this out.148Computational Linguistics Volume 30, Number 2The incorporation of the notion of lexical cohesion has been shown to be crucialto the characterization of the coherence in this corpus.
In addition, it can make avariety of further contributions to discourse analysis.
And finally, it opens the door toa number of useful related strategies that can allow us to come closer to understandingand comprehensively modeling coherence in discourse.AcknowledgmentsI would like to thank Mitsuko Yamura-Takeifor critical observations concerning themajor points in this work, Francis Bond forhis insightful and gentle comments, and ananonymous translator for the translations.
Iwould also like to acknowledge theunflagging aid of Shigeaki Amano, KanameKasahara, Takashi Hamo, TomokoKawaguchi, and Yuuko Kanasugi inproviding the Gainen Base analysis.ReferencesBoguraev, Branimir K. and Mary S. Neff.2000.
Lexical cohesion, discoursesegmentation, and documentsummarization.
Paper presented atRIAO-2000, Paris.Brennan, Susan E., Marilyn W. Friedman,and Carl J. Pollard.
1987.
A centeringapproach to pronouns.
In Proceedings of the25th Annual Meeting of the Association forComputational Linguistics, pages 155?162,Stanford, CA.Chafe, Wallace.
1979.
The flow of thoughtand the flow of language.
In Talmy Givon,editor, Syntax and Semantics: Discourse andSyntax, volume 12.
Academic Press, NewYork, pages 159?182.Chafe, Wallace.
1980.
The Pear Stories:Cognitive, Cultural and Linguistic Aspects ofNarrative Productions.
Ablex, Norwood,NJ.Clark, Herbert H. 1977.
Inferences incomprehension.
In David LaBerge and S.Jay Samuels, editors, Basic Processes inReading: Perception and Comprehension.Erlbaum, Mahwah, NJ, pages 83?112.Cote, Sharon.
1998.
Rankingforward-looking centers.
In Marilyn A.Walker, Aravind K. Joshi, and Ellen F.Prince, editors, Centering Theory inDiscourse.
Clarendon, Oxford, pages55?69.Fais, Laurel.
2001.
Discourse issues in thetranslation of Japanese email.
InProceedings of PACLING 2001, pages93?102, Kitakyushu, Fukuoka, Japan.Fais, Laurel.
2002.
The Japanese A no Bconstruction and centering.
In Proceedings,Eighth Annual Meeting of the Association forNatural Language Processing (NLP 2002),pages 603?606, Keihanna, Japan.Fais, Laurel and Mitsuko Yamura-Takei.2003.
The nature of referent resolution inJapanese email.
Discourse Processes,36(3):167?204.Fujita, Sanae and Francis Bond.
2002.
Amethod of adding new entries to avalency dictionary by exploiting existinglexical resources.
In Proceedings of the NinthInternational Conference on Theoretical andMethodological Issues in Machine Translation(TMI-2002), pages 45?52, Keihanna, Japan.Gordon, Peter C., Barbara J. Grosz, andLaura A. Gilliom.
1993.
Pronouns, names,and the centering of attention indiscourse.
Cognitive Science, 17:311?347.Gordon, Peter C., Randall Hendrick, KerryLedoux, and Chin Lung Yang.
1999.Processing of reference and the structureof grammar: An analysis of complexnoun phrases.
Language and CognitiveProcesses, 14(4):353?379.Grosz, Barbara J. and Candace L. Sidner.1986.
Attention, intentions, and thestructure of discourse.
ComputationalLinguistics, 12(3):175?204.Grosz, Barbara J. and Candace L. Sidner.1998.
Lost intuitions and forgottenintentions.
In Marilyn A. Walker, AravindK.
Joshi, and Ellen F. Prince, editors,Centering Theory in Discourse.
Clarendon,Oxford, pages 39?51.Hahn, Udo, Katja Markert, and MichaelStrube.
1996.
A conceptual reasoningapproach to textual ellipsis.
In Proceedingsof the 12th European Conference on ArtificialIntelligence, pages 572?576, Budapest.Halliday, Michael A. K. 1994.
An Introductionto Functional Grammar.
Arnold, London.Harabagiu, Sanda M. 1998.
WordNet?basedinference of textual cohesion andcoherence.
In Proceedings of FLAIRS-98,Sanibel Island, FL, pages 265?269.Harabagiu, Sanda M. 1999.
From lexicalcohesion to textual coherence: A datadriven perspective.
Journal of PatternRecognition and Artificial Intelligence,13(2):241?265.Hudson-D?Zmura, Susan and Michael K.Tanenhaus.
1998.
Assigning antecedentsto ambiguous pronouns: The role of thecenter of attention as the defaultassignment.
In Marilyn A. Walker,Aravind K. Joshi, and Ellen F. Prince,149Fais Transitions and Coherenceeditors, Centering Theory in Discourse.Clarendon, Oxford, pages 199?226.Huls, Carla, Edwin Bos, and Wim Claassen.1995.
Automatic referent resolution ofdeictic and anaphoric expressions.Computational Linguistics, 21(1):59?79.Hurewitz, Felicia.
1998.
A quantitative lookat discourse coherence.
In Marilyn A.Walker, Aravind K. Joshi, and Ellen F.Prince, editors, Centering Theory inDiscourse.
Clarendon, Oxford, pages273?291.Hutchins, John.
1995.
Reflections on thehistory and present state of machinetranslation.
In The MT Summit VProceedings, pages 89?96, Luxembourg.Kameyama, Megumi.
1998.
Intrasententialcentering: A case study.
In Marilyn A.Walker, Aravind K. Joshi, and Ellen F.Prince, editors, Centering Theory inDiscourse.
Clarendon, Oxford, pages89?112.Kasahara, Kaname, Kazumitsu Matsuzawa,Tsutomu Ishikawa, and TsukasaKawaoka.
1996.
Viewpoint-basedmeasurement of semantic similaritybetween words.
In Douglas H. Fisher andHans Lenz, editors, Learning from Data: AIand Statistics V. Springer-Verlag, NewYork, pages 433?442.Kozima, Hideki.
1993.
Text segmentationbased on similarity between words.
InProceedings of the 31st Annual Meeting of theAssociation for Computational Linguistics,pages 286?288, Columbus, OH.Kozima, Hideki and Teiji Furugori.
1993.Similarity between words computed byspreading activation on an Englishdictionary.
In Proceedings of the SixthConference of the European Chapter,Association for Computational Linguistics,pages 232?239, Utrecht, the Netherlands.Kuno, Susumu.
1973.
The Structure of theJapanese Language.
MIT Press, Cambridge,MA.Lotfipour-Saedi, Kazem.
1997.
Lexicalcohesion and translation equivalence.Meta, 42(1):185?192.Matsui, Tomoko.
1999.
On the role ofcontext in relevance-based accessibilityranking of candidate referents.
In PaoloBouquet, Luciano Serafini, PatrickBrezillon, Massimo Benerecetti, andFrancesca Castellani, editors, CONTEXT?99 (Springer Lecture Notes in ArtificialIntelligence, no.
1688), pages 228?241.Morris, Jane and Graeme Hirst.
1991.Lexical cohesion computed by thesauralrelations as an indicator of the structure oftext.
Computational Linguistics, 17(1):21?48.Murata, Masaki, Hitoshi Isahara, andMakoto Nagao.
1999.
Resolution ofindirect anaphora in Japanese sentencesusing examples ?X no Y (Y of X).?
InProceedings of the ACL99 Workshop onCoreference and Its Applications, CollegePark, MD.Nakaiwa, Hiromi, and Satoshi Shirai.
1996.Anaphora resolution of Japanese zeropronouns with deictic reference.
InProceedings of COLING-96, pages 812?817.Nariyama, Shigeko.
2000.
ReferentIdentification for Ellipted Arguments inJapanese.
Ph.D. thesis, University ofMelbourne, Melbourne, Australia.Nippon Telegraph and TelephoneCorporation, Communication ScienceLaboratories.
1996.
Reference Manual forMorphological Analysis Program ALT-JAWS.Keihanna, Japan: Nippon Telegraph andTelephone.Okumura, Manabu, and Takeo Honda.
1994.Word sense disambiguation and textsegmentation based on lexical cohesion.In Proceedings of the 15th InternationalConference on Computational Linguistics,pages 755?761, Kyoto, Japan.Passonneau, Rebecca J.
1998.
Interaction ofdiscourse structure with explicitness ofdiscourse anaphoric noun phrases.
InMarilyn A. Walker, Aravind K. Joshi, andEllen F. Prince, editors, Centering Theory inDiscourse.
Clarendon, Oxford, pages327?358.Paul, Michael and Eiichiro Sumita 2001.
Atrainable method for pronominalanaphora resolution using shallowinformation.
Shizen Gengo Shori [Journal ofNatural Language Processing], 8(3):59?85.Poesio, Massimo, Hua Cheng, RenateHenschel, Janet Hitzeman, Rodger Kibble,and Rosemary Stevenson.
2000.Specifying the parameters of centeringtheory: A corpus-based evaluation usingtext from application-oriented domains.In Proceedings of the 38th Annual Meeting ofthe Association for Computational Linguistics,Hong Kong, pages 400?407.Sack, Warren.
1999.
Diagrams of socialcohesion.
In Proceedings of the 37th AnnualMeeting of the Association for ComputationalLinguistics, Hong Kong.Sag, Ivan A., Timothy Baldwin, FrancisBond, Ann Copestake, and DanFlickinger.
2002.
Multiword expressions:A pain in the neck for NLP.
In AlexanderGelbuk, editor, Computational Linguisticsand Intelligent Text Processing: ThirdInternational Conference (CICLing-2002),Springer-Verlag, Heidelberg/Berlin, pages1?15.Shimazu, Akira, Shozo Naito, and Hirosato150Computational Linguistics Volume 30, Number 2Nomura.
1987.
Semantic structure analysisof Japanese noun phrases with adnominalparticles.
In Proceedings of the 25th AnnualMeeting of the Association for ComputationalLinguistics, pages 123?130, Stanford, CA.Strube, Michael, and Udo Hahn.
1999.Functional centering?Groundingreferential coherence in informationstructure.
Computational Linguistics,25(3):309?344.Suri, Linda Z. and Kathleen F. McCoy.
1994.RAFT/RAPR and centering: Acomparison and discussion of problemsrelated to processing complex sentences.Computational Linguistics, 20(2):301?317.Tetreault, Joel R. 2001.
A corpus-basedevaluation of centering and pronounresolution.
Computational Linguistics,27(4):507?520.Vieira, Renata, and Massimo Poesio.
2001.An empirically based system forprocessing definite descriptions.Computational Linguistics, 26(4):539?593.Walker, Marilyn A.
1998.
Centeringanaphora resolution, and discoursestructure.
In Marilyn A. Walker, AravindK.
Joshi, and Ellen F. Prince, editors,Centering Theory in Discourse.
Clarendon,Oxford, pages 401?435.Walker, Marilyn A., Masayo Iida, andSharon Cote.
1994.
Japanese discourseand the process of centering.Computational Linguistics, 20(2):193?231.Walker, Marilyn A., Aravind Joshi, andEllen F. Prince.
1998.
Centering innaturally occurring discourse: Anoverview.
In Marilyn A. Walker, AravindK.
Joshi, and Ellen F. Prince, editors,Centering Theory in Discourse.
Clarendon,Oxford, pages 1?28.Yamura-Takei, Mitsuko, Miho Fujiwara,Makoto Yoshie, and Teruaki Aizawa.
2002.Automatic linguistic analysis for languageteachers: The case of zeros.
In Proceedingsof the 19th International Conference onComputational Linguistics (COLING ?2002),pages 1114?1120, Taipei, Taiwan.
