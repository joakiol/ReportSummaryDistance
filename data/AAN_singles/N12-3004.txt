Proceedings of the NAACL-HLT 2012: Demonstration Session, pages 13?16,Montre?al, Canada, June 3-8, 2012. c?2012 Association for Computational LinguisticsSurfShop: combing a product ontology with topic model results for onlinewindow-shopping.Zofia Stankiewicz and Satoshi SekineRakuten Institute of Technology, New York215 Park Avenue SouthNew York, NY 10003, USA{zofia.stankiewicz,satoshi.b.sekine}@mail.rakuten.comAbstractAt present, online shopping is typically asearch-oriented activity where a user gains ac-cess to products which best match their query.Instead, we propose a surf-oriented onlineshopping paradigm, which links associatedproducts allowing users to ?wander around?the online store and enjoy browsing a varietyof items.
As an initial step in creating this ex-perience, we constructed a prototype of an on-line shopping interface which combines pro-duct ontology information with topic modelresults to allow users to explore items from thefood and kitchen domain.
As a novel task fortopic model application, we also discuss pos-sible approaches to the task of selecting thebest product categories to illustrate the hiddentopics discovered for our product domain.1 IntroductionQuery based search remains the primary method ofaccess to large collections of data.
However, new in-terfacing options offered by mobile and touchscreenapplications lead to decreased reliance on typedsearch queries.
This trend further fuels the need fortechnologies which allow users to browse and ex-plore large amounts of data from a variety of view-points.
Online store product databases are a repre-sentative example of such a data source.
At present,online shopping is typically a search-oriented ac-tivity.
Aside from suggestions of closely matchingproducts from a recommender system, internet shop-pers have little opportunity to look around an onlinestore and explore a variety of related items.
This ob-servation led us to define a novel task of creating asurf-oriented online shopping interface which facil-itates browsing and access to multiple types of prod-ucts.
We created the prototype SurfShop applicationin order to test whether we can combine knowledgefrom a product ontology with topic modeling for abetter browsing experience.Our aim is to design an application which offersaccess to a variety of products, while providing a co-herent and interesting presentation.
While the pro-duct ontology provides information on product typeswhich are semantically close (for example spaghettiand penne), it does not provide information aboutassociations such as pasta and tomato sauce, whichmay be mentioned implicitly in product descrip-tions.
In order to obtain semantically varied productgroupings from the data we integrated topic modelresults into the application to display products whichare related through hidden topics.The data used for this project consists of a snap-shot from the product database of a Japanese Inter-net shopping mall Rakuten Ichiba obtained in April20111.
We limited our prototype application tothe food and kitchen domain consisting of approx-imately 4 million products.
The textual informationavailable for each product includes a title and a shortdescription.
Furthermore, each product is assignedto a leaf category in the product hierarchy tree.We use standard LDA (Blei et al, 2003) as thetopic model and our prototype can be treated asan example of applied topic modeling.
Althoughthere exist browsers of document collections based1For a version of Rakuten product data made available forresearch purposes see http://rit.rakuten.co.jp/rdr/index en.html.13on topic modeling 2, they have been constructed asdirect model result visualizations.
In contrast, weincorporate the LDA results into the output by com-bining them with product category information andsearch to produce a full blown application with atopic model serving as one of its components.
Weprovide a more detailed overview of the entire sys-tem in section 2.In LDA literature, the topics discovered by themodel are typically represented by top n most prob-able words for a given topic.
In integrating topicmodel results into our application we faced a chal-lenge of creating theme pages which correspondto hidden topics, and selecting product categorieswhich best illustrate a given topic.
In section 3we discuss a preliminary evaluation of the applica-tion?s theme pages which suggests that combiningtopic knowledge with ontology structure can lead tomore coherent product category groupings, and thattopic interpretation and labeling based solely on topn words may not be sufficient for some applied tasks.We conclude by summarizing plans for further de-velopment of our prototype.2 System overviewThe initial input to the SurfShop system consists of aproduct database and a product ontology with nodelabels.
All products were indexed for fast retrievalby the application3.
A chart of application compo-nents is presented in Figure1.Raw product descriptions from our data wouldconstitute a large corpus including meta-data suchas shipping or manufacturer information, which arenot relevant to our task.
Thus, fitting a topic modelover this corpus is not guaranteed to provide use-ful information about related product types.
There-fore, we decided to aggregate the product informa-tion into a collection of product category documents,where each document corresponds to a node in theproduct ontology tree (1088 nodes total).
Each doc-ument consists of sentences extracted from productdescriptions which potentially describe its relation-ship to other product categories (based on the oc-currence of category name labels).
We can then use2For an example see http://www.sccs.swarthmore.edu/users/08/ajb/tmve/wiki100k/browse/topic-list.html.3We used an Apache Solr index and a JavaScript Ajax-Solrlibrary from https://github.com/evolvingweb/ajax-solr.Figure 1: System overviewthis artificially constructed corpus as input to LDAto discover hidden topics in the collection4.The topic model results, as well as product ontol-ogy information are combined with product searchin order to build pages for our SurfShop application.In the prototype the user can move between search,browsing related categories, as well as browsing the-matic product groupings.
In the search mode, we usethe query and the top n search results to infer whichproduct category is most relevant to the query.
Thisallows us to display links to related category groupsnext to the search results.Given a product category, the users can also ex-plore a related category map, such as the one shownin Figure 2 for cheese.
They can browse exampleproducts in each related category by clicking on thecategory to load product information into the rightcolumn on the page.
To provide example products, aquery is issued under the relevant ontology node us-ing the product category label and topic keywords, toensure that we display items relevant to the currentpage.
The product browsing functionality is simi-lar for theme pages which are discussed in the nextsection.4For LDA we used the Lingpipe package (http://alias-i.com/lingpipe/).14Figure 2: Related category page example.
Category andtheme labels have been translated into English.3 Theme pagesAn example of a breakfast theme page view is shownin Figure 3.
It includes clusters of product categorieswhich exemplify the page theme, such as bread andjam or cheese and dairy.
Each theme page corre-sponds to a hidden topic discovered by the LDAmodel5.
Human interpretation of topic models hasbeen a focus of some recent work (Chang et al,2009; Newman et al, 2010; Mimno et al, 2010).However, previous approaches concentrate on repre-senting a topic by its top n most probable words.
Incontrast, our goal is to illustrate a topic by choosingthe most representative documents from the collec-tion, which also correspond to product categories as-sociated with the topic.
Since this is a novel task, wedecided to concentrate on the issue of building andevaluating theme pages before conducting broaderuser studies of the prototype.There are a few possible ways to select documentswhich best represent a topic.
The simplest would beto consider the rank of this topic in the document.Alternatively, since the model provides an estimateof topic probability given a document, the proba-bility that a product category document belongs toa topic could be calculated straightforwardly usingthe Bayes rule6.
Yet another option for finding cat-5We empirically set the number of topics to 100.
We re-moved top 10% most general topics, as defined by the numberof documents which include the topic in its top 10.6We made an additional simplifying assumption that all doc-uments are equiprobable.Figure 3: Theme page fragment.
Category and themelabels have been translated into English.egories related to a given topic would be to assigna score based on KL divergence between the topicword multinomial and a product category multino-mial, with the probability of each word w in the vo-cabulary defined as follows for a given category:P (w) =?t(P (w|ti) ?
P (ti|cj)) (1)Finally, we hypothesized that product ontologystructure may be helpful in creating the theme pages,since if one product category is representative ofthe topic, its sibling categories are also likely to be.Conversely, if a category is the only candidate for agiven topic among its neighbors in the tree, it is lesslikely to be relevant.
Therefore, we clustered thetopic category candidates based on their distance inthe ontology, and retained only the clusters with thehighest average scores.To evaluate which of the above methods is moreeffective, we gave the following task to a group ofthree Japanese annotators.
For each topic we createda list of category candidates which included productcategories where the topic ranked 1-3 (methods 1-3in Table 1), top 25 Bayes score and KL divergencescore categories (methods 4 and 5), as well as thecategories based on ontology distance clusters com-bined with the Bayes score averages for cluster reli-ability (method 6).
Each annotator was given a listof top ten keywords for each of the topics and askedto choose a suitable label based on the keywords.Subsequently, they were asked to select product cat-15Scoring method Precision Recall F-score1.Rank1 73.83% 43.21% 54.16%2.Rank1+2 50.91% 59.56% 54.54%3.Rank1+2+3 41.71% 73.08% 52.77%4.Top25 KL 53.54% 70.44% 60.45%5.Top25 Bayes 53.56% 71.25% 60.76%6.Bayes+Ont 66.71% 69.17% 67.48%Table 1: Result average for three annotators on Task 1.egories from the candidate list which fit the topiclabel they decided on.In this manner, each annotator created their own?golden standard?
of best categories which allowedus to compare the performance of different ap-proaches to category selection.
The amount of ac-cepted categories varied, however a performancecomparison of candidate sets showed consistenttrends across annotators, which allows us to presentaverages over annotator scores in Table 1.
Rankbased selection increases in recall as lower ranksare included but the precision of the results de-creases.
KL divergence and Bayes rule based scoresare comparable.
Finally, combining the ontologyinformation with Bayes scoring improves the pre-cision, while retaining the recall similar to that ofthe top 25 Bayes score approach.
We chose this lastmethod to create theme pages.We also wanted to verify how the presence of toptopic words affects topic interpretation.
In anothertask, shown in Table 2, the same group of annota-tors was presented only with product category listswhich combined method 5 and method 6 candidatesfrom the previous task.
They were asked to assign atopic label which summarized the majority of thosecategories, as well as mark the categories which didnot fit the topic.
Even though the annotators hadpreviously seen the same data, they tended to as-sign broader labels than those based on the top topicwords, and included more categories as suitable fora given topic.
For example, for the breakfast themeshown in Figure 3, one annotator labeled the topicdairy products based on topic words, and bread anddairy products based on the product category exam-ples.
The results of Task 2 led us to use manuallyassigned theme page labels based on the product cat-egory groupings rather than the topic keywords.Scoring method Precision Recall F-score5.Top25 Bayes 71.28% 81.83% 76.03%6.Bayes+Ont 84.11% 75.46% 79.38%Table 2: Result average for three annotators on Task 2.The differences in results between Task 1 andTask 2 indicate that, while top topic keywords aidinterpretation, they may suggest a narrower themethan the documents selected to represent the topicand thus may not be optimal for some applications.This underscores the need for further research on hu-man evaluation methods for topic models.4 Future workWe demonstrated a prototype SurfShop systemwhich employs product ontology structure and LDAmodel results to link associated product types andprovide an entertaining browsing experience.In the future we plan to replace the LDA compo-nent with a model which can directly account for thelinks found through the product ontology tree, sucha version of the relational topic model (Chang andBlei, 2009).
In addition, we hope that further explo-ration of theme page construction can contribute tothe development of topic visualization and evalua-tion methods.ReferencesDavid M. Blei, Andrew Y. Ng, and Michael I. Jordan.2003.
Latent dirichlet alocation.
J. Mach.
Learn.
Res.3, 993-1022.Jonathan Chang and David Blei.
2009.
Relational topicmodels for document networks.
Proc.
of Conf.
on AIand Statistics, 81-88.J.
Chang, J. Boyd-Graber, S. Gerrish, C. Wang, and D.Blei.
2009.
Reading tea leaves: How humans interprettopic models.
NIPS, 1-9.David Mimno, Hanna Wallach, Edmund Talley, MiriamLeenders, and Andrew McCallum 2011.
Optimizingsemantic coherence in topic models.
EMNLP, 2011.David Newman, Jey Han Lau, Karl Grieser, and TimothyBaldwin.
2010.
Automatic evaluation of topic coher-ence.
Human Language Technologies: The 2010 An-nual Conference of the North American Chapter of theAssociation for Computational Linguistics, 100-108.16
