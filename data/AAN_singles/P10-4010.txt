Proceedings of the ACL 2010 System Demonstrations, pages 54?59,Uppsala, Sweden, 13 July 2010. c?2010 Association for Computational LinguisticsHunting for the Black Swan: Risk Mining from TextJochen L. Leidner and Frank SchilderThomson Reuters CorporationResearch & Development610 Opperman Drive, St. Paul, MN 55123 USAFirstName.LastName@ThomsonReuters.comAbstractIn the business world, analyzing and dealing withrisk permeates all decisions and actions.
However,to date, risk identification, the first step in the riskmanagement cycle, has always been a manual activ-ity with little to no intelligent software tool support.In addition, although companies are required to listrisks to their business in their annual SEC filingsin the USA, these descriptions are often very high-level and vague.In this paper, we introduce Risk Mining, which isthe task of identifying a set of risks pertaining to abusiness area or entity.
We argue that by combiningWeb mining and Information Extraction (IE) tech-niques, risks can be detected automatically beforethey materialize, thus providing valuable businessintelligence.We describe a system that induces a risk taxonomywith concrete risks (e.g., interest rate changes) at itsleaves and more abstract risks (e.g., financial risks)closer to its root node.
The taxonomy is inducedvia a bootstrapping algorithms starting with a fewseeds.
The risk taxonomy is used by the system asinput to a risk monitor that matches risk mentions infinancial documents to the abstract risk types, thusbridging a lexical gap.
Our system is able to au-tomatically generate company specific ?risk maps?,which we demonstrate for a corpus of earnings re-port conference calls.1 IntroductionAny given human activity with a particular in-tended outcome is bound to face a non-zero like-lihood of failure.
In business, companies are ex-posed to market risks such as new competitors,disruptive technologies, change in customer at-titudes, or a changes in government legislationthat can dramatically affect their profitability orthreaten their business model or mode of opera-tion.
Therefore, any tool to assist in the elicita-tion of otherwise unforeseen risk factors carriestremendous potential value.However, it is very hard to identify risks ex-haustively, and some types (commonly referredto as the unknown unknowns) are especially elu-sive: if a known unknown is the established knowl-edge that important risk factors are known, but it isunclear whether and when they become realized,then an unknown unknown is the lack of aware-ness, in practice or in principle, of circumstancesthat may impact the outcome of a project, for ex-ample.
Nassim Nicholas Taleb calls these ?blackswans?
(Taleb, 2007).Companies in the US are required to disclosea list of potential risks in their annual Form 10-KSEC fillings in order to warn (potential) investors,and risks are frequently the topic of conferencephone calls about a company?s earnings.
Theserisks are often reported in general terms, in par-ticular, because it is quite difficult to pinpoint theunknown unknown, i.e.
what kind of risk is con-cretely going to materialize.
On the other hand,there is a stream of valuable evidence available onthe Web, such as news messages, blog entries, andanalysts?
reports talking about companies?
perfor-mance and products.
Financial analysts and riskofficers in large companies have not enjoyed anytext analytics support so far, and risk lists devisedusing questionnaires or interviews are unlikely tobe exhaustive due to small sample size, a gapwhich we aim to address in this paper.To this end, we propose to use a combinationof Web Mining (WM) and Information Eextrac-tion (IE) to assist humans interested in risk (withrespect to an organization) and to bridge the gapbetween the general language and concrete risks.We describe our system, which is divided in twomain parts: (a) an offline Risk Miner that facili-tates the risk identification step of the risk manage-ment process, and an online (b)RiskMonitor thatsupports the risk monitoring step (cf.
Figure 2).
Inaddition, a Risk Mapper can aggregate and visu-alize the evidence in the form of a risk map.
Ourrisk mining algorithm combines Riloff hyponympatterns with recursive Web pattern bootstrappingand a graph representation.We do not know of any other implemented end-to-end system for computer-assisted risk identifi-cation/visualization using text mining technology.542 Related WorkFinancial IE.
IE systems have been applied to thefinancial domain on Message Understanding Con-test (MUC) like tasks, ranging from named en-tity tagging to slot filling in templates (Costantino,1992).Automatic Knowledge Acquisition.
(Hearst,1992) pioneered the pattern-based extraction ofhyponyms from corpora, which laid the ground-work for subsequent work, and which included ex-traction of knowledge from to the Web (e.g.
(Et-zioni et al, 2004)).
To improve precision was themission of (Kozareva et al, 2008), which was de-signed to extract hyponymy, but they did so at theexpense of recall, using longer dual anchored pat-terns and a pattern linkage graph.
However, theirmethod is by its very nature unable to deal withlow-frequency items, and their system does notcontain a chunker, so only single term items canbe extracted.
De Saenger et al (De Saeger et al,2008) describe an approach that extracts instancesof the ?trouble?
or ?obstacle?
relations from theWeb in the form of pairs of fillers for these bi-nary relations.
Their approach, which is describedfor the Japanese language, uses support vector ma-chine learning and relies on a Japanese syntac-tic parser, which permits them to process nega-tion.
In contrast, and unlike their method, we pur-sue a more general, open-ended search process,which does not impose as much a priori knowl-edge.
Also, they create a set of pairs, whereas ourapproach creates a taxonomy tree as output.
Mostimportantly though, our approach is not driven byfrequency, and was instead designed to work es-pecially with rare occurrences in mind to permit?black swan?-type risk discovery.Correlation of Volatility and Text.
(Kogan et al,2009) study the correlation between share pricevolatility, a proxy for risk, and a set of triggerwords occurring in 60,000 SEC 10-K filings from1995-2006.
Since the disclosure of a company?srisks is mandatory by law, SEC reports providea rich source.
Their trigger words are selected apriori by humans; in contrast, risk mining as ex-ercised in this paper aims to find risk-indicativewords and phrases automatically.Kogan and colleagues attempt to find a regres-sion model using very simple unigram featuresbased on whole documents that predicts volatility,whereas our goal is to automatically extract pat-terns to be used as alerts.Speculative Language & NLP.
Light et al (Lightet al, 2004) found that sub-string matching of14 pre-defined string literals outperforms an SVMclassifier using bag-of-words features in the taskof speculative language detection in medical ab-stracts.
(Goldberg et al, 2009) are concerned withautomatic recognition of human wishes, as ex-pressed in human notes for Year?s Eve.
They use abi-partite graph-based approach, where one kindof node (content node) represents things peoplewish for (?world peace?)
and the other kind ofnode (template nodes) represent templates that ex-tract them (e.g.
?I wish for ___?).
Wishescan be seen as positive Q, in our formalization.3 DataWe apply the mined risk extraction patterns to acorpus of financial documents.
The data originatesfrom the StreetEvents database and was kindlyprovided to us by Starmine, a Thomson Reuterscompany.
In particular, we are dealing with 170kearning calls transcripts, a text type that containsmonologue (company executives reporting abouttheir company?s performance and general situa-tion) as well as dialogue (in the form of ques-tions and answers at the end of each conferencecall).
Participants typically include select businessanalysts from investment banks, and the calls arepublished afterwards for the shareholders?
bene-fits.
Figure 1 shows some example excerpts.
Werandomly took a sample of N=6,185 transcripts touse them in our risk alerting experiments.14 Method4.1 SystemThe overall system is divided into two core parts:(a) Risk Mining and (b) Risk Monitoring (cf.
Fig-ure 2).
For demonstration purposes, we add a (c)Risk Mapper, a visualization component.
We de-scribe how a variety of risks can be identified givena normally very high-level description of risks,as one can find in earnings reports, other finan-cial news, or the risk section of 10-K SEC filings.Starting with rather abstract descriptions such asoperational risks and hyponym-inducing pattern"< RISK > such as *", we use the Web tomine pages from which we can harvest additional,1We could also use this data for risk mining, but did nottry this due to the small size of the dataset compared to theWeb.55CEO: As announced last evening, during our third quarter, we will take the difficult but necessary step to seize [cease]manufacturing at our nearly 100 year old Pennsylvania House casegood plant in Lewisburg, Pennsylvania as well as the nearbyPennsylvania House dining room chair assembly facility in White Deer.
Also, the three Lewisburg area warehouses will beconsolidated as we assess the logistical needs of the casegood group?s existing warehouse operations at an appropriate time in thefuture to minimize any disruption of service to our customers.
This will result in the loss of 425 jobs or approximately 15% of thecasegood group?s current employee base.Analyst: Okay, so your comments ?
and I guess I don?t know ?
I can figure out, as you correctly helped me through, whatdollar contribution at GE.
I don?t know the net equipment sales number last quarter and this quarter.
But it sounded like fromyour comments that if you exclude these fees, that equipment sales were probably flattish.
Is that fair to say?CEO: We?re not breaking out the origination fee from the equipment fee, but I think in total, I would say flattish to slightly up.Figure 1: Example sentences from the earnings conference call dataset.
Top: main part.
Bottom: Q&A.and eventually more concrete, candidates, and re-late them to risk types via a transitive chain of bi-nary IS-A relations.
Contrary to the related work,we use a base NP chunker and download the fullpages returned by the search engine rather thansearch snippets in order to be able to extract riskphrases rather than just terms, which reduces con-textual ambiguity and thus increases overall preci-sion.
The taxonomy learning method described inthe following subsection determines a risk taxon-omy and new risks patterns.Web MinerTaxonomyInducerSeed Patterns"* <RISK> suchas *"Search Engine Web PagesBusinessReportsRisk AlertingNotificationRiskTaxonomyRisk MiningforRisk IdentificationInformation ExtractionforRisk MonitoringFigure 2: The risk mining and monitoring systemarchitectureThe second part of the system, the Risk Mon-itor, takes the risks from the risk taxonomy anduses them for monitoring financial text streamssuch as news, SEC filings, or (in our use case)earnings reports.
Using this, an analyst is then ableto identify concrete risks in news messages andlink them to the high-level risk descriptions.
Heor she may want to identify operational risks suchas fraud for a particular company, for instance.The risk taxonomy can also derive further risksin this category (e.g., faulty components, brakes)for exploration and drill-down analysis.
Thus,news reports about faulty breaks in (e.g.
Toyota)or volcano outbreaks (e.g.
Iceland) can be directlylinked to the risk as stated in earnings reports orsecurity filings.Our Risk Miner and Risk Monitor are imple-mented in Perl, with the graph processing of thetaxonomy implemented in SWI-Prolog, whereasthe Risk Mapper exists in two versions, a staticimage generator for R2 and, alternatively, an in-teractive Web page (DHTML, JavaScript, and us-ing Google?s Chart API).
We use the Yahoo Websearch API.4.2 Taxonomy induction methodUsing frequency to compute confidence in a pat-tern does not work for risk mining, however, be-cause mention of particular risks might be rare.
In-stead of frequency based indicators (n-grams, fre-quency weights), we rely on two types of struc-tural confidence validation, namely (a) previouslyidentified risks and (b) previously acquired struc-tural patterns.
Note, however, that we can still usePageRank, a popularity-based graph algorithm,because multiple patterns might be connected toa risk term or phrase, even in the absence of fre-quency counts for each (i.e., we interpret popular-ity as having multiple sources of support).1.
Risk Candidate Extraction Step.
The firststep is used to extract a list of risks based on highprecision patterns.
However, it has been shownthat the use of such patterns (e.g., such as) quicklylead to an decrease in precision.
Ideally, we wantto retrieve specific risks by re-applying the the ex-tract risk descriptions:2http://www.r-project.org56Figure 3: A sample IS-A and Pattern network withsample PageRank scores.
(a) Take a seed, instantiate "< SEED > suchas *" pattern with seed, extract candidates:Input: risksMethod: apply pattern "< SEED > suchas < INSTANCE > ", where< SEED > = risksOutput: list of instances (e.g., faulty compo-nents)(b) For each candidate from the list of instances,we find a set of additional candidate hy-ponyms.Input: faulty componentsMethod: apply pattern "< SEED > suchas < INSTANCE > ", where< SEED > = faulty componentsOutput: list of instances (e.g., brake)2.
Risk Validation.
Since the Risk Candidateextraction step will also find many false positives,we need to factor in information that validates thatthe extracted risk is indeed a risk.
We do this byconstructing a possible pattern containing this newrisk.
(a) Append "* risks" to the output of 1(b) inorder to make sure that the candidate occursin a risk context.Input: brake(s)Pattern: "brake(s) * risk(s)"Output: a list of patterns (e.g., minimizesuch risks, raising the risk)(b) extract new risk pattern by substituting therisk candidate with < RISK > ; creating alimited number of variationsInput: list of all patterns mined from step 2(a)Method: create more pattern variations,such as "< RISK > minimize suchrisks", "raising the riskof < RISK > " etc.Output: list of new potential risks (e.g., de-flation), but also many false positives(e.g., way, as in The best way to mini-mize such risks).In order to benefit from any human observationsof system errors in future runs, we also extendedthe system so as to read in a partial list of pre-defined risks at startup time, which can guide therisk miner; while technically different from activelearning, this approach was somewhat inspired byit (but our feedback is more loose).3.
Constructing Risk Graph.
We have nowreached the point where we constructed a graphwith risks and patterns.
Risks are connected viaIS-A links; risks and patterns are connected viaPATTERN links.
Note that there are links fromrisks to patterns and from patterns to risks; somerisks back-pointed by a pattern may actually notbe a risk (e.g., people).
However, this node is alsonot connected to a more abstract risk node andwill therefore have a low PageRank score.
Risksthat are connected to patterns that have a high au-thority (i.e., pointing to by many other links) arehighly ranked within PageRank (Figure 3).
Therisk black Swan, for example, has only one pat-tern it occurs in, but this pattern can be filled bymany other risks (e.g., fire, regulations).
Hence,the PageRank score of the black swan is high sim-ilar to well known risks, such as fraud.4.3 Risk alerting methodWe compile the risk taxonomy into a trie automa-ton, and create a second trie for company namesfrom the meta-data of our corpus.
The Risk Mon-itor reads the two tries and uses the first to de-tect mentions of risks in the earning reports andthe second one to tag company names, both usingcase-insensitive matching for better recall.
Op-tionally, we can use Porter stemming during trieconstruction and matching to trade precision foreven higher recall, but in the experiments reportedhere this is not used.
Once a signal term or phrasematches, we look up its risk type in a hash table,take a note of the company that the current earn-ings report is about, and increase the frequency57liquidity IS-A financial riskscredit IS-A financial risksdirect risks IS-A financial risksfraud IS-A financial risksirregular activity IS-A operational risksprocess failure IS-A operational riskshuman error IS-A operational riskslabor strikes IS-A operational riskscustomer acceptance IS-A IT market risksinterest rate changes IS-A capital market risksuncertainty IS-A market risksvolatility IS-A mean reverting market riskscopyright infringement IS-A legal risksnegligence IS-A other legal risksan unfair dismissal IS-A the legal risksSarbanes IS-A legal risksgovernment changes IS-A global political riskscrime IS-A Social and political risksstate intervention IS-A political risksterrorist acts IS-A geopolitical risksearthquakes IS-A natural disaster risksfloods IS-A natural disaster risksglobal climate change IS-A environmental riskssevere and extreme weather IS-A environmental risksinternal cracking IS-A any technological risksGM technologies IS-A tech risksscalability issues IS-A technology risksviruses IS-A the technical risksFigure 4: Selected financial risk tuples after Webvalidation.count for this ?company; risk type?
tuple, whichwe use for graphic rendering purposes.4.4 Risk mapping methodTo demonstrate the method presented here, we cre-ated a visualization that displays a risk map, whichis a two dimensional table showing companies andthe types of risk they are facing, together with bub-ble sizes proportional to the number of alerts thatthe RiskMonitor could discover in the corpus.
Thesecond option also permits the user to explore thedetected risk mentions per company and by risktype.5 ResultsFrom the Web mining process, we obtain a setof pairs (Figure 4), from which the taxonomy isconstructed.
In one run with only 12 seeds (justthe risk type names with variants), we obtained ataxonomy with 280 validated leave nodes that areconnected transitively to the risks root node.Our resulting system produces visualizationswe call ?risk maps?, because they graphicallypresent the extracted risk types in aggregatedform.
A set of risk types can be selected for pre-sentation as well as a set of companies of interest.A risk map display is then generated using eitherR (Figure 5) or an interactive Web page, depend-ing on the user?s preference.Qualitative error analysis.
We inspected theoutput of the risk miner and observed the follow-Figure 5: An Example Risk Map.ing classes of issues: (a) chunker errors: if phrasalboundaries are placed at the wrong position, thetaxonomy will include wrong relations.
For exam-ple, deictic determiners such as ?this?
were a prob-lem (e.g.
that IS-A indirect risks) be-fore we introduced a stop word filter that discardscandidate tuples that contain no content words.Another prominent example is ?short term?
in-stead of the correct ?short term risk?
; (b) seman-tic drift3: due to polysemy, words and phrasescan denote risk and non-risk meanings, depend-ing on context.
Talking about risks even a spe-cific pattern such as ?such as?
[sic] is used by au-thors to induce a variety of perspectives on thetopic of risk, and after several iterations negativeeffects of type (a) errors compound; (c) off-topicrelations: the seeds are designed to induce a tax-onomy specific to risk types.
As a side effect,many (correct or incorrect) irrelevant relationsare learned, e.g.
credit and debit cardsis-a money transfer.
We currently dis-card these by virtue of ignoring all relations nottransitively connected with the root node risks,so no formalized domain knowledge is required;(d) overlap: the concept space is divided up dif-ferently by different writers, both on the Weband in the risk management literature, and thisis reflected by multiple category membership ofmany risks (e.g.
is cash flow primarily an oper-ational risk or a financial risk?).
Currently, wedo not deal with this phenomenon automatically;(e) redundant relations: at the time of writing, wedo not cache all already extracted and validatedrisks/non-risks.
This means there is room for im-provement w.r.t.
runtime, because we make moreWeb queries than strictly necessary.
While wehave not evaluated this system yet, we found by in-3to use a term coined by Andy Lauriston58specting the output that our method is particularlyeffective for learning natural disasters and med-ical conditions, probably because they are well-covered by news sites and biomedical abstracts onthe Web.
We also found that some classes containmore noise than others, for example operationalrisk was less precise than financial risk, proba-bly due to the lesser specificity of the former risktype.6 Summary, Conclusions & Future WorkSummary of Contributions.In this paper, we introduced the task of risk min-ing, which produces patterns that are useful in an-other task, risk alerting.
Both tasks provide com-putational assistance to risk-related decision mak-ing in the financial sector.
We described a special-purpose algorithm for inducing a risk taxonomyoffline, which can then be used online to analyzeearning reports in order to signal risks.
In do-ing so, we have addressed two research questionsof general relevance, namely how to extract rarepatterns, for which frequency-based methods fail,and how to use the Web to bridge the vocabularygap, i.e.
how to match up terms and phrases infinancial news prose with the more abstract lan-guage typically used in talking about risk in gen-eral.We have described an implemented demonstratorsystem comprising an offline risk taxonomyminer,an online risk alerter and a visualization compo-nent that creates visual risk maps by company andrisk type, which we have applied to a corpus ofearnings call transcripts.Future Work.
Extracted negative and also pos-itive risks can be used in many applications, rang-ing from e-mail alerts to determinating credit rat-ings.
Our preliminary work on risk maps can beput on a more theoretical footing (Hunter, 2000).After studying further how output of risk alert-ing correlates4 with non-textual signals like shareprice, risk detection signals could inform humanor trading decisions.Acknowledgments.
We are grateful to Khalid Al-Kofahi,Peter Jackson and James Powell for supporting this work.Thanks to George Bonne, Ryan Roser, and Craig D?Alessioat Starmine, a Thomson Reuters company, for sharing theStreetEvents dataset with us, and to David Rosenblatt for dis-cussions and to Jack Conrad for feedback on this paper.4Our hypothesis is that risk patterns can outperform bagof words (Kogan et al, 2009).ReferencesMarco Costantino.
1992.
Financial information extrac-tion using pre-defined and user-definable templates in theLOLITA system.
Proceedings of the Fifteenth Interna-tional Conference on Computational Linguistics (COL-ING 1992), vol.
4, pages 241?255.Stijn De Saeger, Kentaro Torisawa, and Jun?ichi Kazama.2008.
Looking for trouble.
In Proceedings of the 22ndInternational Conference on Computational Linguistics(COLING 2008), pages 185?192, Morristown, NJ, USA.Association for Computational Linguistics.Oren Etzioni, Michael J. Cafarella, Doug Downey, StanleyKok, Ana-Maria Popescu, Tal Shaked, Stephen Soderland,Daniel S. Weld, and Alexander Yates.
2004.
Web-scaleinformation extraction in KnowItAll: preliminary results.In Stuart I. Feldman, Mike Uretsky, Marc Najork, andCraig E. Wills, editors, Proceedings of the 13th interna-tional conference on World Wide Web (WWW 2004), NewYork, NY, USA, May 17-20, 2004, pages 100?110.
ACM.Andrew B. Goldberg, Nathanael Fillmore, David Andrzejew-ski, Zhiting Xu, Bryan Gibson, and Xiaojin Zhu.
2009.May all your wishes come true: A study of wishes andhow to recognize them.
In Proceedings of Human Lan-guage Technologies: The 2009 Annual Conference of theNorth American Chapter of the Association for Compu-tational Linguistics, pages 263?271, Boulder, Colorado,June.
Association for Computational Linguistics.Marti Hearst.
1992.
Automatic acquisition of hyponymsfrom large text corpora.
In Proceedings of the FourteenthInternational Conference on Computational Linguistics(COLING 1992).Anthony Hunter.
2000.
Ramification analysis using causalmapping.
Data and Knowledge Engineering, 32:200?227.Shimon Kogan, Dimitry Levin, Bryan R. Routledge, Jacob S.Sagi, and Noah A. Smith.
2009.
Predicting risk fromfinancial reports with regression.
In Proceedings of theJoint International Conference on Human Language Tech-nology and the Annual Meeting of the North AmericanChapter of the Association for Computational Linguistics(HLT-NAACL).Zornitsa Kozareva, Ellen Riloff, and Eduard Hovy.
2008.Semantic class learning from the web with hyponym pat-tern linkage graphs.
In Proceedings of ACL-HLT, pages1048?1056, Columbus, OH, USA.
Association for Com-putational Linguistics.Marc Light, Xin Ying Qiu, and Padmini Srinivasan.
2004.The language of bioscience: Facts, speculations, and state-ments in between.
In BioLINK 2004: Linking BiologicalLiterature, Ontologies and Databases, pages 17?24.
ACL.Nassim Nicholas Taleb.
2007.
The Black Swan: The Impactof the Highly Improbable.
Random House.59
