Proceedings of the 2009 Named Entities Workshop, ACL-IJCNLP 2009, pages 61?64,Suntec, Singapore, 7 August 2009. c?2009 ACL and AFNLPLearning Multi Character Alignment Rules and Classification of trainingdata for TransliterationDipankar BoseDept.
of Computer Science and Engg.Indian Institute of TechnologyKharagpur, West BengalIndia - 721302dipankarcsiit@gmail.comSudeshna SarkarDept.
of Computer Science and Engg.Indian Institute of TechnologyKharagpur, West BengalIndia - 721302shudeshna@gmail.comAbstractWe address the issues of transliteration be-tween Indian languages and English, es-pecially for named entities.
We use anEM algorithm to learn the alignment be-tween the languages.
We find that thereare lot of ambiguities in the rules map-ping the characters in the source languageto the corresponding characters in the tar-get language.
Some of these ambiguitiescan be handled by capturing context bylearning multi-character based alignmentsand use of character n-gram models.
Weobserved that a word in the source scriptmay have actually originated from differ-ent languages.
Instead of learning onemodel for the language pair, we proposethat one may use multiple models and aclassifier to decide which model to use.
Acontribution of this work is that the modelsand classifiers are learned in a completelyunsupervised manner.
Using our systemwe were able to get quite accurate translit-eration models.1 IntroductionTransliteration is the practice of transcribing aword or text written in one writing system into an-other writing system which may have a differentscript (wikipedia 1).
The rules are often quite am-biguous, and they are often related with the pro-nunciation of the word.Many applications like Machine Transla-tion (MT), Cross Language Information Re-trieval (CLIR), Question Answering (QA) require1http://www.wikipedia.orgtransliteration of named entities, which are the ma-jor component of out-of-vocabulary (OOV) words,and they are most often transliterated and nottranslated, in any cross language system.
For ex-ample ,?Europe?
is transliterated as ?iuropa?
and?Michael?
transliterates to ?maaikela?
in Bengali.2In this paper we develop a scheme of translit-eration, which captures context by creating a dic-tionary of multi-character transliteration rules.
Wehave tested our system for English and several In-dian languages.
For Indian Languages, we have anadditional preprocessor which enhances the per-formance.2 Related WorkBrown et al (1993) have come up with their revo-lutionary IBM alignment models, and the Giza++(Och and Ney, 2000) is a well appreciated imple-mentation which work with parallel data in twolanguages.
Though originally designed for ma-chine translation, the package can as well be usedfor transliteration, where the alignment is betweenthe characters in the languages.
Moses further en-hances the accuracy by using phrase based decod-ing, which can capture context.
We have Moses3as our baseline system.Li et al (2004) have pointed out the prob-lems of using language information.
Apart fromthe difficulty of collecting the language informa-tion, they pointed out that, although written inthe same script, the origin of the source namesmay vary widely.
For example French and Eng-lish names may vary a lot.
But it is difficultto collect information for each and every lan-guage.
They came up with a joint source chan-2above Bengali words are scripted using ITrans, insteadof traditional Bengali script.3http://www.statmt.org/moses/61nel model, to transliterate foreign names to Chi-nese, Korean, and Japanese, which uses, direct or-thographic mapping (DOM), between two differ-ent languages, to find out how the source and tar-get words can be generated simultaneously.
Ekbalet al (2006) also used this model for English-Bengali Transliteration.
Ganesh et al (2008)used Hidden Markov Model (HMM) alignmentand Conditional Random Field (CRF), a discrim-inative model together.
Surana et al (2008) usedfuzzy string matching algorithms to identify theorigin of the source word, and then apply rules oftransliteration accordingly.
However the classifiermakes use of labeled training data, which is oftennot available.3 IssuesTransliteration is ambiguous.
Firstly, the translit-eration rules depend on the context.
For exam-ple, ?a?
in English may transliterate to ?a?
or ?A?in Hindi, but ?aa?
almost definitely maps to ?A?.Secondly, there can be multiple transliterationsof the same source word.
For example ?abhi-jIta?
may transliterate to ?abhijit?
and ?abhijeet?
aswell.
Thirdly, the transliteration rules also vary,depending on the origin of the word.
For exam-ple, when considering Hindi to English translitera-tion the English characters used vary depending onwhether the word originated from Arabic or fromSanskrit.
We elaborate more on this in the sectionon classification of corpus.4 ApproachOur method is primarily based on IBM modelsused in machine translation based on the EM al-gorithm.
But before we move on to the IBM mod-els, we first preprocess the training data.
Otherthan marking the ?Start?
and ?End?, for each of theparallel words, we can do further preprocessing ifany of the scripts is Indian.
All Indian languagescripts consist of a set of consonants and vowels.Independent vowels and their corresponding dia-critic markers (Matra) are considered as the samecharacter in the standard analysis of words intotheir constituent characters (varna vishleshhana).Unlike ITrans, Unicode assigns different codes tothem.
We found in our experiment that treatingthem as one, improves the accuracy of the system.Our preprocessor thus transforms Unicode data toITrans format.
We have seen that preprocessor im-proves the accuracy by around 10-15%.After preprocessing, we align the letters us-ing the expectation maximization (EM) algorithmof IBM model 1, using the parallel corpus ofnamed entities as input.
We use only the IBMmodel 1; the subsequent models are omitted sincein transliteration we need not consider the re-ordering of letters.
Both Unicode and transliter-ated text are in phonetic order, and re-ordering ofletters are rarely observed.
As an output of the EMlearner we get a table of translation probabilitiesTP , of source letters to target letters.
If, si andtj are source and target letters, ?si, tj , TP si,tj ?
[0, 1], denotes the corresponding translation prob-ability.
For example after EM learning, the valuesof TPbha,v and TPbha,b will be much more thanTPbha,k, since ?bha?
rarely transliterates to ?k?.4.1 Learning Phrase MappingsWe now move on to capture context.
For eachword in the parallel data, we compute an align-ment array, Ae, where e ?
[0, E], and I and Eare the corresponding lengths of the words in In-dian and English script respectively.
So, we have,?e ?
[0, E], Ae ?
[0, I].
Following is an example:Let, source word be: Start s1 s2 s3 End, targetword be: Start t1 t2 t3 t4 End, and Alignment ar-ray be: 0 1 1 2 3 4.
This means that s1 maps tot1 and t2; s2 maps to t3 and so on.
We furtherenforce Ae1 ?
Ae2 iff e1 ?
e2, since we neglectre-ordering of letters.
The aim is to figure out nullmappings, filter out noises in the TP-table, and fi-nally create a phrase to phrase mapped dictionary.Using the TP-table values, we propose an iterativealgorithm to find the alignment array A. WL[i] de-notes the ith letter of a word in language ?L?.
Ini-tially Ai = 0 if i = 0, Ai = I?1 if i < E, otherwiseAi = I .
The first and last characters are always the?Start?
and ?End?
tags, in all the words.Initially letters are allowed a larger window tofit to.
After each iteration, the window size de-creases and thus the margins are made more strin-gent.
Using iterations we are being less greedy indeciding the alignment, so that noises in the TP-table are filtered out.
Finally after 5 iterations,we freeze the alignment array.
It may happen that?i ?
[0, I], such that ?j ?
[0, E], Aj 6= i. Itmeans that the letter, WInd[i] maps to ?null?
in thiscase, and thus it is a ?Schwa?
character.4.2 Scoring the alignmentIn spite of all our attempts, it may happen that thewords are not well aligned; the reason may be a62Algorithm 1 Method to compute Alignmentfor window = 5 to 1 dofor e = 1 to E ?
1 doleft = Max(1, Ae?1 ?
window + 1)right = Min(I, Ae+1 + window)Ae = s : s ?
[left, right] such thatTPWInd[s],WEng[e] ?
(1?
|s/I ?
e/E|)is maximumend forfor e = 1 to E ?
1 doif ?
(Ae?1 ?
Ae ?
Ae+1) then{try to smooth out anomalies}Ae = (Ae?1 +Ae+1)/2end ifend forend fordeficiency in the Algorithm 1, or a badly transliter-ated parallel word as input.
For example the train-ing data may contain ?mississippi river?
translit-erated to Bengali as ?misisipi nadI?.
In this casewe see that the second word is translated and nottransliterated.
Retaining this in the training setwill introduce noise in the model.
There may alsobe typographical errors also.
We have developeda filtering mechanism, so that we can eliminatethese words, otherwise we will end up learningspurious mappings.
We find the score of an align-ment,SA = ?N?1e=1 (TPWInd[Ae],WEng [e] ?
(1?
|Ae/I ?e/E|).We were trying to maximize SA under certainconstraints in algorithm 1.
The value of SA isan estimate of how good our alignment is.
Nextwe set thresholds to distinguish between different?Classes?
of alignments.4.3 Classifying the training corpusThe training corpus may consist of words fromvaried origins.
Though they are written inthe same script, pronunciation varies widely.For example Urdu origin names like Farooque(pharUka), Razzaq (rajjAka) tend to replace ?q?
inplace of ?ka?, but Hindi names like Latika (latika),Nakul (nakula), tend to replace ?k?
for ?ka?.
UnlikeSurana et al (2008) who extracted 5-gram modelsfrom labeled data in different languages, we pro-pose Algorithm 2, to classify the parallel corpusinto groups, which does not need any labeled data.We define, Classes C1, C2, ..., CN , where Ci con-sists of a set of parallel words < Ij , Ej >, (Ij ,Ej being the jth word in Indian and English lan-guage, in the training corpus), such that the align-ment score of the word pairs, lie between the pre-defined thresholds, thi+1 and thi.
Let us assumethat C1 is initialized with the parallel training cor-pus from input.Algorithm 2 Classify the Corpusfor i = 1 to N doSet threshold, thi for Class Ci: thi ?
thi?1while size of Class Ci does not decrease doCompute TP-table using IBM model 1. onCifor each parallel word pair < Ij , Ej > inCi doCompute Alignment using Algorithm 1.Compute Score of Alignment, SA.if Score < thi then{Move the word pair to the nextclass}Ci+1 = Ci+1?
< Ij , Ej >Ci = Ci\ < Ij , Ej >end ifend forend while{move on to next Class}end forWe continuously discard word pairs from aclass until there is no word pair to be discarded.We use IBM Model 1 to re-learn the TP-table, onthe latest content of the class.
Since the poor wordpairs have been removed, learning the TP-tableafresh, helps in improving the TPsi,tj values.
Ithelps in removing the bad word pairs yet left, inthe subsequent iterations.
It is to be noted that CNconsists of word pairs, which are of no use, and wediscard them completely.
We had 5 useful classes,and the thresholds of C1 to C5 were 0.4, 0.35, 0.3,0.25, 0.2 respectively.
In each class, for each wordpair, we extract all possible ngrams on Indian lan-guage side and collect their corresponding Englishcharacters, using the alignment array.
We keep fre-quency counts of these ngram mappings, and usethis score in decoding.
We use a language model,which uses Good Turing smoothing technique.
Wehave used greedy beam search based decoder.All that remains is to guess the class of an un-known word.
Given a test word, in source scriptwe calculate probability Pi of it being in class,Ci, based on ngram similarities.
The decoders ofeach of the classes returns a list of feasible translit-eration candidates along with their ?local scores?63Language Accuracy in Top1 Mean F-Score MRR MAPref MAP10 MAPsysEn2Ta 0.404 0.883 0.539 0.398 0.182 0.182En2Hi 0.366 0.854 0.493 0.360 0.164 0.164En2Ka 0.335 0.856 0.457 0.328 0.154 0.154Table 1: Transliteration Accuracies.
En2Ta: English to Tamil, En2Hi: English to Hindi, En2Ka: Englishto Kannada(score according to that class), We denote the lo-cal score of a candidate from Class Ci as LS[Ci].We calculate the global score, GS for each candi-date, using GS= ?N?1i=1 (LS[Ci]?Pi).
The candi-dates are sorted in decreasing order of their globalscores and top ?K?
of them produced as output.5 ResultsWe have evaluated our system, against datasetswith Hindi, Tamil, Kannada and English parallelnamed entities (Kumaran and Kellner, 2007).
Theresults are in Table 1.
The data consists of namedentities from varied origins: almost all Indian lan-guages and English.
We combined the training anddevelopment sets to create the new training set.There are about 9000 parallel words in the train-ing sets and 1000 words for testing.Algorithm 2 classifies the training corpus, into5 sets of corpus.
Following are some details af-ter classifying the Tamil-English dataset.
Corpus1, consists of Sanskrit derived words mostly; theyget perfectly aligned and Schwa deletions rarelyoccur; Ex: Keena, Asiya, Nehra, Hemaraaj, Vi-jendra.
This corpus contains 2167 words.
Cor-pus 2 also is mostly comprised of Sanskrit de-rived words and also English words which eas-ily align; like Wilton, Natesh, Raghu, Gerry,Achintya, Amaanat.
Schwa deletions does occur,and hence the alignment scores are a little low.Size of this corpus is 2168.Corpus 3 consists more of Urdu origin andEnglish words, which are not fit for the normaltransliteration rules.
The corpus consists of wordslike Tarzan, Anoife, Sevier, Zahid Fazal, Floriane,where letters like ?q?, ?zz?, ?y?
are more likely than?k?, ?j?, ?i?
respectively.
The size of Corpus 3 is1835.
Corpus 4 & 5 consists largely of Englishorigin words, like Lucky number, Ian Healy, Clea-vant, Fort Vancouver, Virginia Reel, Bundesver-dienstkreuz.
These words need completely differ-ent set of rules, and moreover if these words werein any other class, it would corrupt their learningrules.
Size of these corpora are 1234 and 1455 re-spectively.6 ConclusionOur system is robust in the sense that it can filterout noise in the training corpus, can handle wordsof different origins by classifying them into dif-ferent classes.
Our classifying algorithm improvesthe accuracy, but we believe that there is scope offurther improvement and we are working on it.ReferencesAsif Ekbal, Sudip Kumar Naskar, Sivaji Bandyopad-hyay.
2006.
A modified joint source-channelmodel for transliteration.
Proceedings of theCOLING/ACL on Main conference poster ses-sions.Sydney, Australia.Harshit Surana and A. K. Singh 2008.
A More Dis-cerning and Adaptable Multilingual TransliterationMechanism for Indian Languages.
The Third In-ternational Joint Conference on Natural LanguageProcessing (IJCNLP).
Hyderabad, India.Kumaran A. and Kellner Tobias.
2007.
A genericframework for machine transliteration SIGIR ?07:Proceedings of the 30th annual international ACMSIGIR conference on Research and development ininformation retrieval, pages 721?722.Li Haizhou, Zhang Min, Su Jian.
2004.
A jointsource-channel model for machine transliteration.Proceedings of the 42nd Annual Meeting on As-sociation for Computational Linguistics.
Barcelona,Spain.Och Franz Josef and Hermann Ney.
2000.
ImprovedStatistical Alignment Models.
Proc.
of the 38th An-nual Meeting of the Association for ComputationalLinguistics, pp.
440-447, Hong Kong, China.Peter F. Brown, Vincent J. Delta Pietra, Stephen A.Delta Pietra and Robert L. Mercer.
1993.
The math-ematics of statistical machine translation: parame-ter estimation.
MIT Press Cambridge, MA, USA.Surya Ganesh, Sree Harsha, Prasad Pingali, VasudevaVerma.
2008.
Statistical Transliteration for CrossLanguage Information Retrieval using HMM align-ment model and CRF.
CLIA-2008, 2nd Internationalworkshop on Cross Language Information Access,3rd International Joint Conference on Natural Lan-guage Processing (IJCNLP 2008), January 7-12,2008, Hyderabad, India.64
