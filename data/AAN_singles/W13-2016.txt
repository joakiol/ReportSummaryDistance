Proceedings of the BioNLP Shared Task 2013 Workshop, pages 116?120,Sofia, Bulgaria, August 9 2013. c?2013 Association for Computational LinguisticsUZH in the BioNLP 2013 GENIA Shared TaskGerold Schneider, Simon Clematide, Tilia Ellendorff, Don Tuggener, Fabio Rinaldi,{rinaldi,gschneid,siclemat,ellendorff,tuggener}@cl.uzh.chInstitute of Computational Linguistics, University of Zurich, SwitzerlandGintare?
Grigonyte?Stockholm University, Department of Linguistics, Section for Computational Linguisticsgintare@ling.su.seAbstractWe describe a biological event detec-tion method implemented for the GeniaEvent Extraction task of BioNLP 2013.The method relies on syntactic depen-dency relations provided by a general NLPpipeline, supported by statistics derivedfrom Maximum Entropy models for can-didate trigger words, for potential argu-ments, and for argument frames.1 IntroductionThe OntoGene team at the University of Zurichhas developed text mining applications based ona combination of deep-linguistic analysis and ma-chine learning techniques (Rinaldi et al 2012b;Clematide and Rinaldi, 2012; Rinaldi et al 2010).Our approaches have proven competitive in sev-eral shared task evaluations (Rinaldi et al 2013;Clematide et al 2011; Rinaldi et al 2008).
Addi-tionally, we have developed advanced systems forthe curation of the biomedical literature (Rinaldiet al 2012a).Our participation in the Genia Event Extractiontask of BioNLP 2013 (Kim et al 2013) was moti-vated by the desire of testing our technologies ona more linguistically motivated task.
In the courseof our participation we revised several modules ofour document processing pipeline, however we didnot have sufficient resources to completely revisethe final module which generates the event struc-tures, and we still relied on a module which wehad developed for our previous participation to theBioNLP shared task.The final submission was composed by ourstandard preprocessing module (described brieflyin section 2) and novel probability models (section3), combined within the old event generator (sec-tion 4).2 PreprocessingThe OntoGene environment is based on a pipelineof several NLP tools which all operate on a com-mon XML representation of the original docu-ment.Briefly, the pipeline includes modules forsentence-splitting, tokenization, part-of-speechtagging, lemmatization, stemming, term-recognition (not used for the BioNLP sharedtask), chunking, dependency-parsing and eventgeneration.
Different variants of those moduleshave been used in different instantiations of thepipeline.
For the BioNLP 2013 participation,lingpipe was used for sentence splitting, tok-enization and PoS tagging, morpha (Minnen etal., 2001) was used for lemmatization, a pythonimplementation of the Porter stemmer for stem-ming, LTTT (Grover et al 2000), was used forchunking, and the Pro3Gres parser (Schneider,2008) for dependency analysis.As we have made good experiences with arule based system for anaphora resolution in theBioNLP 2011 shared task (Tuggener et al 2011),we implemented a similar approach that resolvesanaphors to terms identified during preprocessing.Rules contain patterns like ?X such as Y?
or ?Xis a Y?, and pronouns are resolved to the nearestgrammatical subject or object.
Anaphora resolu-tion led to an improvement of 0.2% recall on thedevelopment set, while precision was hardly af-fected.3 Probability modelsSeveral probability models have been computedfrom the training data in order to be used to scoreand filter candidate events generated by the sys-tem.
The following models played a role in thefinal submission:P (eventType | trigger candidate) (1)116P (frame ?
eventType | trigger candidate) (2)P (role ?
eventType | protein) (3)P (role(t, d) | synpath(t, d)) (4)For all of them we computed global MaximumLikelihood Estimations (MLE), using the trainingand development datasets from the 2013 and 2011challenges.
For all of the models above, exceptfor the last one, we also estimated the probabili-ties by a Maximum Entropy (ME) approach.
TheMegaM tool (Daume?
III, 2004) allows for a super-vised training of binary classifiers where the classprobability is optimized by adjusting the featureweights and not just the binary classification deci-sion itself.
This helps to deal with the imbalancedclasses such as the distribution of true or false trig-gerword candidates.For the classification of trigger candidates(Equation 1), a binary ME classifier for each eventtype is separately trained, based on local andglobal features as described below.
The trigger-word candidates are collected from the trainingdata using their stemmed representation as a selec-tion criterion.
We generally exclude triggerwordcandidates that occur in less than 1% as true trig-gers in the training set.
Within the data, we foundthat triggers that consist of more than one word arerather rare (less than 5% of all triggers, most ofthem occurring once).
However, we transformedthese multiword triggers to singleword triggers,replacing them by their first content word.The choice of ME features, partly inspired by(Ekbal et al 2013), can be grouped into featuresderived from the triggerword itself (word), fea-tures from the sentence of the triggerword (con-text), and features from article-wide information(global).Word features: (1) The text, lemma, part ofspeech (PoS), stem and local syntactic dependencyof the triggerword candidate as computed by thePro3Gres parser.
(2) Information whether a trig-gerword candidate is head of a chunk as well aswhether the chunk is nominal or verbalContext features: Unigrams and bigrams in awindow of variable size to left and right of the trig-gerword candidate; three types of uni- and bigramsare used: PoS, lemmas and stems; for unigrams wealso include the lower-cased words; for bigrams,the triggerword candidate itself is included in thefirst bigram to either side.Global features: (1) Presence or absence of aprotein in a window of a given size around thetriggerword candidate (Boolean feature); only themost frequent proteins of an article are considered.
(2) The zone in an article where the triggerwordcandidate appears, e.g.
Title/Abstract, Introduc-tion, Background, Material and Methods, Resultsand Discussion, Caption and Conclusion.Feature engineering was done by testing differ-ent combinations of settings (window size, thresh-olds) with the aim of finding an optimal overallME model which reaches the lowest error rates forall event types.
The error rate of the candidate setwas measured as the cumulative error mass com-puted from the assigned class probability as fol-lows: if the trigger candidate is a true positive, theerror is 1 minus the probability assigned by theclassifier.
If the candidate is a false positive, theerror is the probability assigned by the classifier.Our approach does not allow us to compute an er-ror rate for false negatives, because we simply relyon the set of trigger words seen in the training dataas possible candidates.In these experiments, we discovered that formost event types an optimal setting for the contextfeatures considers a wide span of about 20 tokensto the left and right of the triggerword.
Includ-ing bigrams of lemmas, stems and PoS deliveredthe best results compared to including only one ortwo of these bigram types.
Context features can beparameterized according to how much positionalinformation they contain: the distance of a wordto the right and left of the trigger, only the direc-tion (left or right) or no position information at all(bag of unigrams/bigrams).
We found that the ex-act positional information is only important for thefirst word to the left and right (adjacent to the trig-gerword), whereas for all words that are furtheraway it is favorable to only use the direction in re-lation to the trigger.
A window size of 10 wordswithin which proteins are found in the context ofa triggerword gave the best results.
The optimalnumber of the most frequent proteins consideredwithin this window was found to be the 10 mostfrequent proteins within an article.The second type of ME classifier (Equation 2)has the purpose of calculating the probabilities ofevent frames for all event types given a triggerword.
We use the term frame for a combination ofarguments that an event is able to accept as themeand cause and whether these arguments are real-117ized as proteins or subevents.For the classification of proteins (Equation 3),again separate binary ME classifiers were built inorder to estimate the probability that a protein hasa role (theme or cause) in an event of a given type.4 Event GenerationWe tested two independent event generation mod-ules, one based on a revision of our previous 2009submission (Kaljurand et al 2009) and one whichis a totally new implementation.
We could do onlypreliminary tests with the second module, whichhowever showed promising results, in particularwith much better recall than the older module (upto 65.23%), despite the very little time that wecould invest in its development.
The best F-scorethat we could reach was still slightly inferior to theone of the old module at the deadline for submis-sion of results.
In the rest of this paper we willdescribe only the module which was used in theofficial submission.The event extraction process consists of threephases.
First, event candidates are generated,based on trigger words and their context, using theME and MLE probabilities pT (equation 1).Second, individual arguments of an event aregenerated.
We calculate the MLE probability pRof an argument role (e.g.
Theme) to occur as partof a given event type, as follows:pR(Role |EventType) =f(Role ?
EventType)f(EventType)(5)We obtained the best results on the developmentcorpus when combining the probabilities as:pA =pT ?
pT ?
pRpT + pT + pR(6)We generate arguments, using an MLE syntac-tic path and an ME argument model, as follows.The syntactic path between the trigger word andevery term (protein or subordinate event) is con-sidered.
If they are syntactically connected, andif the probability of a syntactic path to express anevent is above a threshold, it is selected.
As this isa filtering step, it negatively affects recall.We calculate the MLE probability ppath thata syntactic configuration fills an argument slot.Syntactic configurations consist of the head word(trigger) HWord, the head event type HType, thedependent word DWord, the dependent event typeDType, and the syntactic path Path between them.In order to deal with sparse data, we use asmoothed model.ppath(Arg |HWord, HType, DWord, DType, Path) =1w1+w2+w3?
(w1 ?f(HWord, HType, DWord, DType, Path?Arg)f(HWord, HType, DWord, DType, Path) +w2 ?f(HType, DType, Path?Arg)f(HType, DType, Path) +w3 ?f(HType, DType?Arg)f(HType, DType) ) (7)The weights were emprically set as w1 = 4,w2 = 2 and w3 = 1.5.
The fact that the weightsdecrease approximates a back-off model.
The finalprobability had to be larger than 0.2.We have also used an ME model which deliversthe probability parg that a term is the argument ofa specific event, see formula 3.
If this ME modelpredicts with a probability of above 80% that theterm is not an argument, the search fails.
Other-wise, the probabilities are combined.
On the de-velopment corpus, we achieved best results whenusing the harmonic mean:pargument = 2 ?ppath ?
pargppath + parg(8)As a last step, the several arguments of an eventare combined into a frame.
We have tested mod-els predicting an entire frame directly, and modelscombining the individual arguments generated inthe previous step.
The latter approach performedbetter.
Any permutation of the argument candi-dates could constitute a frame.
Only frames seenin the training corpus for a given event type areconsidered.
We have again used an ME and anMLE model for predicting frames.The ME model predicts pframe.ME , see for-mula 2.
We have also used two MLE models:the first one delivers the probability pframe.MLEbased on the event type only, the second onepframeword.MLE also considers the trigger wordand is much sparser (a low default is thus used forunseen words).
The probability of the individualarguments also needs to be taken into considera-tion.
We used the mean of the individual argu-ments?
probabilities (pargs?mean).5 EvaluationIn our analysis of errors, we noticed that frameswith more than one argument are created ex-tremely rarely.
The problem is that frames withseveral arguments are rarer because the contextoften does not offer the possibility to attach sev-eral arguments.
Therefore, we consistently un-dergenerated with pargs?mean as outlined above.118Event Class gold (match) answer (match) recall prec.
fscoreSVT-TOTAL 1117 ( 619) 851 ( 619) 55.42 72.74 62.91EVT-TOTAL 1490 ( 698) 1103 ( 698) 46.85 63.28 53.84REG-TOTAL 1694 ( 168) 618 ( 168) 9.92 27.18 14.53All events total 3184 ( 866) 1721 ( 866) 27.20 50.32 35.31Table 1: Results on the development set, measured using ?strict equality?.Event Class gold (match) answer (match) recall prec.
fscoreGene expression 619 (400) 497 (400) 64.62 80.48 71.68Transcription 101 (26) 100 (26) 25.74 26.00 25.87Protein catabolism 14 (10) 15 (10) 71.43 66.67 68.97Localization 99 (34) 39 (34) 34.34 87.18 49.28=[SIMPLE ALL]= 833 (470) 651 (470) 56.42 72.20 63.34Binding 333 (74) 264 (74) 22.22 28.03 24.79Protein modification 1 (0) 0 (0) 0.00 0.00 0.00Phosphorylation 160 (119) 168 (119) 74.38 70.83 72.56Ubiquitination 30 (0) 0 (0) 0.00 0.00 0.00Acetylation 0 (0) 0 (0) 0.00 0.00 0.00Deacetylation 0 (0) 0 (0) 0.00 0.00 0.00=[PROT-MOD ALL]= 191 (119) 168 (119) 62.30 70.83 66.30Regulation 288 (23) 84 (23) 7.99 27.38 12.37Positive regulation 1130 (129) 444 (129) 11.42 29.05 16.39Negative regulation 526 (54) 166 (54) 10.27 32.53 15.61=[REGULATION ALL]= 1944 (206) 694 (206) 10.60 29.68 15.62==[EVENT TOTAL]== 3301 (869) 1777 (869) 26.33 48.90 34.23Table 2: Results on the test data, measured using ?strict equality?.We have added a number of heuristics to boostmulti-argument frames.
Multiplying the probabil-ity of a frame by its cubed length (giving two-argument slots 9 times higher probability), andgiving Cause-slots 50% higher scores globally ledto best results.We mainly trained and evaluated using the?strict equality?
evaluation criteria as our refer-ence.
The results on the development data areshown in table 1.
With more relaxed equality def-initions, the results were always a few percentagepoints better.
Our results in the official test run areshown in table 2.
In sum, our submitted systemhas good performance for simple events, bad per-formance for Binding events, and a bias towardsprecision due to a syntactic-based filtering step.6 Conclusions and Future workOur participation in the 2013 BioNLP shared taskwas a useful opportunity to revise components ofthe OntoGene pipeline and begin the implemen-tation of a novel event generator.
Due to lack oftime, it was not completed in time for the officialsubmission.
We will continue its development anduse the BioNLP datasets.AcknowledgmentsThis research is partially funded by theSwiss National Science Foundation (grant105315 130558/1).References[Clematide and Rinaldi2012] Simon Clematide andFabio Rinaldi.
2012.
Ranking relations betweendiseases, drugs and genes for a curation task.Journal of Biomedical Semantics, 3(Suppl 3):S5.
[Clematide et al011] Simon Clematide, Fabio Ri-naldi, and Gerold Schneider.
2011.
Ontogene atcalbc ii and some thoughts on the need of document-wide harmonization.
In Proceedings of the CALBCII workshop, EBI, Cambridge, UK, 16-18 March.[Daume?
III2004] Hal Daume?
III.
2004.
Notes onCG and LM-BFGS optimization of logistic regres-sion.
Paper available at http://pub.hal3.name#daume04cg-bfgs, implementation avail-able at http://hal3.name/megam/, August.
[Ekbal et al013] Asif Ekbal, Sriparna Saha, andSachin Girdhar.
2013.
Evolutionary approach forclassifier ensemble: An application to bio-molecularevent extraction.
In Ajith Abraham and Sabu MThampi, editors, Intelligent Informatics, volume 182of Advances in Intelligent Systems and Computing,pages 9?15.
Springer Berlin Heidelberg.119[Grover et al000] Claire Grover, Colin Matheson, An-drei Mikheev, and Marc Moens.
2000.
Lt ttt - a flex-ible tokenisation tool.
In Proceedings of Second In-ternational Conference on Language Resources andEvaluation (LREC 2000).
[Kaljurand et al009] Kaarel Kaljurand, GeroldSchneider, and Fabio Rinaldi.
2009.
UZurich in theBioNLP 2009 Shared Task.
In Proceedings of theBioNLP workshop, Boulder, Colorado.
[Kim et al013] Jin-Dong Kim, Yue Wang, and Ya-mamoto Yasunori.
2013.
The genia event extractionshared task, 2013 edition - overview.
In Proceedingsof BioNLP Shared Task 2013 Workshop, Sofia, Bul-garia, August.
Association for Computational Lin-guistics.
[Minnen et al001] Guido Minnen, John Carroll, andDarren Pearce.
2001.
Applied morphological pro-cessing of English.
Natural Language Engineering,7(3):207?223.
[Rinaldi et al008] Fabio Rinaldi, Thomas Kappeler,Kaarel Kaljurand, Gerold Schneider, Manfred Klen-ner, Simon Clematide, Michael Hess, Jean-Marcvon Allmen, Pierre Parisot, Martin Romacker, andTherese Vachon.
2008.
OntoGene in BioCreativeII.
Genome Biology, 9(Suppl 2):S13.
[Rinaldi et al010] Fabio Rinaldi, Gerold Schneider,Kaarel Kaljurand, Simon Clematide, Therese Va-chon, and Martin Romacker.
2010.
OntoGene inBioCreative II.5.
IEEE/ACM Transactions on Com-putational Biology and Bioinformatics, 7(3):472?480.
[Rinaldi et al012a] Fabio Rinaldi, Simon Clematide,Yael Garten, Michelle Whirl-Carrillo, Li Gong,Joan M. Hebert, Katrin Sangkuhl, Caroline F. Thorn,Teri E. Klein, and Russ B. Altman.
2012a.
UsingODIN for a PharmGKB re-validation experiment.Database: The Journal of Biological Databases andCuration.
[Rinaldi et al012b] Fabio Rinaldi, Gerold Schneider,and Simon Clematide.
2012b.
Relation mining ex-periments in the pharmacogenomics domain.
Jour-nal of Biomedical Informatics, 45(5):851?861.
[Rinaldi et al013] Fabio Rinaldi, Simon Clematide,Simon Hafner, Gerold Schneider, GintareGrigonyte, Martin Romacker, and Therese Va-chon.
2013.
Using the ontogene pipeline forthe triage task of biocreative 2012.
The Journalof Biological Databases and Curation, OxfordJournals.
[Schneider2008] Gerold Schneider.
2008.
Hy-brid Long-Distance Functional Dependency Pars-ing.
Doctoral Thesis, Institute of ComputationalLinguistics, University of Zurich.
[Tuggener et al011] D Tuggener, M Klenner,G Schneider, S Clematide, and F Rinaldi.
2011.
Anincremental model for the coreference resolutiontask of bionlp 2011.
In BioNLP 2011, pages 151?152.
Association for Computational Linguistics(ACL), June.120
