Multi-View Co-training of Transliteration ModelJin-Shea Kuo Haizhou LiChung-Hwa Telecomm.Laboratories, Taiwand8807302@gmail.comInstitute for Infocomm Research,Singapore 119613hli@i2r.a-star.edu.sgAbstractThis paper discusses a new approach totraining of transliteration model fromunlabeled data for transliteration extraction.We start with an inquiry into theformulation of transliteration model byconsidering different transliterationstrategies as a multi-view problem, whereeach view exploits a natural division oftransliteration features, such as phoneme-based, grapheme-based or hybrid features.Then we introduce a multi-view Co-training algorithm, which leveragescompatible and partially uncorrelatedinformation across different views toeffectively boost the model from unlabeleddata.
Applying this algorithm totransliteration extraction, the results showthat it not only circumvents the need of datalabeling, but also achieves performanceclose to that of supervised learning, wheremanual labeling is required for all trainingsamples.1 IntroductionNamed entities are important content words in textdocuments.
In many applications, such as cross-language information retrieval (Meng et al, 2001;Virga and Khudanpur, 2003) and machinetranslation (Knight and Graehl, 1998; Chen et al,2006), one of the fundamental tasks is to identifythese words.
Imported foreign proper namesconstitute a good portion of such words, which arenewly translated into Chinese by transliteration.Transliteration is a process of translating a foreignword into the native language by preserving itspronunciation in the original language, otherwiseknown as translation-by-sound.As new words emerge everyday, no lexicon isable to cover all transliterations.
It is desirable tofind ways to harvest transliterations from realworld corpora.
In this paper, we are interested inthe learning of English to Chinese (E-C)transliteration model for transliteration extractionfrom the Web.A statistical transliteration model is typicallytrained on a large amount of transliteration pairs,also referred to a bilingual corpus.
Thecorrespondence between a transliteration pair maybe described by the mapping of different basicpronunciation units (BPUs) such as phoneme-based1, or grapheme-based one, or both.
We cansee each type of BPU mapping as a natural divisionof transliteration features, which represents a viewto the phonetic mapping problem.
By usingdifferent BPUs, we approach the transliterationmodeling and extraction problems from differentviews.This paper is organized as follows.
In Section 2,we briefly introduce previous work.
In Section 3,we conduct an inquiry into the formulation oftransliteration model or phonetic similarity model(PSM) and consider it as a multi-view problem.
InSection 4, we propose a multi-view Co-trainingstrategy for PSM training and transliterationextraction.
In Section 5, we study the effectivenessof proposed algorithms.
Finally, we conclude inSection 6.2 Related WorkStudies on transliteration have been focused ontransliteration modeling and transliterationextraction.
The transliteration modeling approachdeduces either phoneme-based or grapheme-basedmapping rules using a generative model that is1 Both phoneme and syllable based approaches arereferred to as phoneme-based in this paper.373trained from a large bilingual corpus.
Most of theworks are devoted to phoneme-based transliterationmodeling (Knight and Graehl, 1998; Lee, 1999).Suppose that EW is an English word and CW is itsChinese transliteration.
EW and CW form an E-Ctransliteration pair.
The phoneme-based approachfirst converts EW into an intermediate phonemicrepresentation p, and then converts p into itsChinese counterpart CW.
The idea is to transformboth source and target words into comparablephonemes so that the phonetic similarity betweentwo words can be measured easily.Recently the grapheme-based approach hasattracted much attention.
It was proposed by Jeonget al (1999), Li et al (2004) and many others (Ohet al, 2006b), which is also known as directorthography mapping.
It treats the transliteration asa statistical machine translation problem undermonotonic constraint.
The idea is to obtain thebilingual orthographical correspondence directly toreduce the possible errors introduced in multipleconversions.
However, the grapheme-basedtransliteration model has more parameters thanphoneme-based one does, thus expects a largertraining corpus.Most of the reported works have been focusedon either phoneme- or grapheme-based approaches.Bilac and Tanaka (2004) and Oh et al (2006a;2006b) recently proposed using a mix of phonemeand grapheme features, where both features arefused into a single learning process.
The featurefusion was shown to be effective.
However, theirmethods hinge on the availability of a labeledbilingual corpus.In transliteration extraction, mining translationsor transliterations from the ever-growingmultilingual Web has become an active researchtopic, for example, by exploring query logs (Brill etal., 2001) and parallel (Nie et al, 1999) orcomparable corpora (Sproat et al, 2006).Transliterations in such a live corpus are typicallyunlabeled.
For model-based transliterationextraction, recent progress in machine learningoffers different options to exploit unlabeled data,that include active learning (Lewis and Catlett,1994) and Co-training (Nigam and Ghani, 2000;T?r et al 2005).Taking the prior work a step forward, this paperexplores a new way of fusing phoneme andgrapheme features through a multi-view Co-training algorithm (Blum and Mitchell, 1998),which starts with a small number of labeled data tobootstrap a transliteration model to automaticallyharvest transliterations from the Web.3 Phonetic Similarity Model withMultiple ViewsMachine transliteration can be formulated as agenerative process, which takes a character stringin source language as input and generates acharacter string in the target language as output.Conceptually, this process can be regarded as a 3-step decoding: segmentation of both source andtarget strings into basic pronunciation units (BPUs),relating the source BPUs with target units byresolving different combinations of alignments andunit mappings in finding the most probable BPUpairs.
A BPU can be defined as a phonemesequence, a grapheme sequence, or a part of them.A transliteration model establishes the phoneticrelationship between BPUs in two languages tomeasure their similarity, therefore, it is also knownas the phonetic similarity model (PSM).To introduce the multi-view concept, weillustrate the BPU transfers in Figure 1, where eachtransfer is represented by a direct path withdifferent line style.
There are altogether fourdifferent paths: the phoneme-based path V1(T1?T2?T3), the grapheme-based path V4 (T4),and their variants, V2(T1?T5) and V3(T6?T3).
Thelast two paths make use of the intermediate BPUmappings between phonemes and graphemes.
Eachof the paths represents a view to the mappingproblem.
Given a labeled bilingual corpus, we areable to train a transliteration model for each vieweasily.Figure 1.
Multiple views for establishingtransliteration correspondence.The E-C transliteration has been studiedextensively in the paradigm of noisy channel modelSourcePhonemeTargetPhonemeSourceWordTargetWordT1T2T4T3T5 T6374(Manning and Scheutze, 1999), with EW as theobservation and CW as the input to be recovered.Applying Bayes rule, the transliteration can bedescribed by Eq.
(1),( | ) ( )( | ) ,( )P EW CW P CWP CW EWP EW?=               (1)where we need to deal with two probabilitydistributions: P(EW|CW), the probability oftransliterating CW to EW, also known as the unitmapping rules, and P(CW), the probabilitydistribution of CW, known as the target languagemodel.Representing EW in English BPUsequence 1{ ,... ,... }= m MEP ep ep ep  and CW inChinese one, 1{ ,... ,... }= n NCP cp cp cp , a typicaltransliteration probability can be expressed as,( | ) ( | ) ( | ) ( | ).P EW CW P EW EP P EP CP P CP CW?
?
?
(2)The language model, P(CW), can be represented byChinese characters n-gram statistics (Manning andScheutze, 1999) and expressed in Eq.
(3).
In thecase of bigram, we have,1 12( ) ( ) ( | )Nn nnP CW P c P c c ?=?
?
(3)We next rewrite Eq.
(2) for the four different viewsdepicted in Figure 1 in a systematic manner.3.1 Phoneme-based ApproachThe phoneme-based approach approximates thetransliteration probability distribution byintroducing an intermediate phonemicrepresentation.
In this way, we convert the words inthe source language, say 1 2, ... KEW e e e= , intoEnglish syllables ES , then Chinese syllables CSand finally the target language, say Chinese1 2, ... KCW c c c=  in sequence.
Eq.
(2) can berewritten by replacing EP and CP with ES and CS,respectively, and expressed by Eq.
(4).
( | ) ( | ) ( | ) ( | )P EW CW P EW ES P ES CS PCS CW?
?
?
(4)The three probabilities correspond to the three-stepmapping in V1 path.The phoneme-based approach suffers frommultiple step mappings.
This could compromiseoverall performance because none of the threesteps guarantees a perfect conversion.3.2 Grapheme-based ApproachThe grapheme-based approach is inspired by thetransfer model (Vauqois, 1988) in machinetranslation that estimates ( | )P EW CW  directlywithout interlingua representation.
This methodaims to alleviate the imprecision introduced by themultiple transfers in phoneme-based approach.In practice, a grapheme-based approach convertsthe English graphemes to Chinese graphemes inone single step.
Suppose that we have1 2, ... KEW e e e= and 1 2, ... KCW c c c= where ke  andkc are aligned grapheme units.Under the noisy channel model, we can estimate( | )P EW CW  based on the alignment statisticswhich is similar to the lexical mapping in statisticalmachine translation.1( | ) ( | )K k kkP EW CW P e c=??
(5)Eq.
(5) is a grapheme-based alternative to Eq.
(2).3.3 Hybrid ApproachA tradeoff between the phoneme- and grapheme-based approaches is to take shortcuts to themapping between phonemes and graphemes of twolanguages via V2 or V3, where only two steps ofmapping are involved.
For V3, we rewrite Eq.
(2) asEq.
(6):( | ) ( | ) ( | ),= ?P EW CW P EW CS P CS CW         (6)where ( | )P EW CS  translates Chinese sounds intoEnglish words.
For V2, we rewrite Eq.
(2) as Eq.
(7):( | ) ( | ) ( | ),= ?P EW CW P EW ES P ES CW         (7)where ( | )P ES CW translates Chinese words intoEnglish sounds.Eqs.
(4) ?
(7) describe the four paths oftransliteration.
In a multi-view problem, onepartitions the domain?s features into subsets, eachof which is sufficient for learning the targetconcept.
Here the target concept is the label oftransliteration pair.
Given a collection of E-C paircandidates, the transliteration extraction task can beformulated as a hypothesis test, which makes abinary decision as to whether a candidate E-C pairis a genuine transliteration pair or not.
Given an E-C pair X={EW,CW}, we have 0H , which375hypothesizes that EW  and CW  form a genuine E-C pair, and 1H , which hypothesizes otherwise.
Thelikelihood ratio is given as 0 1( | ) / ( | )P X H P X H?
= ,where 0( | )P X H and 0( | )P X H  are derived fromP(EW|CW).
By comparing ?
with a threshold ?
,we make the binary decision as that in (Kuo et al,2007).As discussed, each view takes a distinct path thathas its own advantages and disadvantages in termsof model expressiveness and complexity.
Eachview represents a weak learner achievingmoderately good performance towards the targetconcept.
Next, we study a multi-view Co-trainingprocess that leverages the data of different viewsfrom each other in order to boost the accuracy of aPSM model.4 Multi-View Learning FrameworkThe PSM can be trained in a supervised mannerusing a manually labeled corpus.
The advantage ofsupervised learning is that we can establish a modelquickly as long as labeled data are available.However, this method suffers from some practicalconstraints.
First, the derived model can only be asgood as the data it sees.
Second, the labeling ofcorpus is labor intensive.To circumvent the need of manual labeling, herewe study three adaptive strategies cast in themachine learning framework, namely unsupervisedlearning, Co-training and Co-EM.4.1 Unsupervised LearningUnsupervised learning minimizes humansupervision by probabilistically labeling datathrough an Expectation and Maximization (EM)(Dempster et al, 1977) process.
The unsupervisedlearning strategy can be depicted in Figure 2 bytaking the dotted path, where the extraction processaccumulates all the acquired transliteration pairs ina repository for training a new PSM.
A new PSM isin turn used to extract new transliteration pairs.
Theunsupervised learning approach only needs a fewlabeled samples to bootstrap the initial model forfurther extraction.
Note that the training samplesare noisy and hence the quality of initial PSMtherefore has a direct impact on the finalperformance.4.2 Co-training and Co-EMThe multi-view setting (Muslea et al, 2002)applies to learning problems that have a naturalway to divide their features into different views,each of which is sufficient to learn the targetconcept.
Blum and Mitchell (1998) proved that fora problem with two views, the target concept canbe learned based on a few labeled and manyunlabeled examples, provided that the views arecompatible and uncorrelated.
Intuitively, thetransliteration problem has compatible views.
If anE-C pair forms a transliteration, then this is trueacross all different views.
However, it is arguablethat the four views in Figure 1 are uncorrelated.Studies (Nigam and Ghani, 2000; Muslea et al,2002) shown that the views do not have to beentirely uncorrelated for Co-training to take effect.This motivates our attempt to explore multi-viewCo-training for learning models in transliterationextraction.Figure 2.
Diagram of unsupervised/multi-view Co-training for transliteration extraction.To simplify the discussion, here we take a two-view (V1 and V2) example to show how Co-training can potentially help.
To start with, one canlearn a weak hypothesis PSM1 using V1 based on afew labeled examples and then apply PSM1 to allunlabeled examples.
If the views are uncorrelated,or at least partially uncorrelated, these newlylabeled examples seen from V1 augment thetraining set for V2.
These newly labeled examplesStop StartIterateFinalPSMInitialPSMSearch &RankingPSM LearnerLexicon The WebTrainingRepositoryPSMEvaluation & StopCriterionUnsupervisedCo-trainingPSM Learner 1TrainingRepositoryPSM Learner n376present new information from the V2 point of view,from which one can in turn update the PSM2.
Asthe views are compatible, both V1 and V2 label thesamples consistently according to the sameprobabilistic transliteration criteria.
In this way,PSMs are boosted each other through such aniterative process between two different views.Table 1.
Co-training with two learners.Extending the two-view to multi-view, one candevelop multiple learners from several subsets offeatures, each of which approaches the problemfrom a unique perspective, called a view whentaking the Co-training path in Figure 2.
Finally, weuse outputs from multi-view learners toapproximate the manual labeling.
The multi-viewlearning is similar to unsupervised learning in thesense that the learning alleviates the need oflabeling and starts with very few labeled data.However, it is also different from the unsupervisedlearning because the latter does not leverage thenatural split of compatible and uncorrelatedfeatures.
Two variants of two-view learningstrategy can be summarized in Table 1 and Table 2,where the algorithm in Table 1 is referred to as Co-training and the one in Table 2 as Co-EM (Nigamand Ghani.
2000; Muslea et al, 2002).In Co-training, Learners A and B are trained onthe same training data and updated simultaneously.In Co-EM, Learners A and B are trained on labeledset predicted by each other?s view, with theirmodels being updated in sequence.
In other words,the Co-EM algorithm interchanges the probabilisticlabels generated in the view of each other before anew EM iteration.
In both cases, the unsupervised,multi-view algorithms use the hypotheses learnedto probabilistically label the examples.Table 2.
Co-EM with two learners.The extension of algorithms in Table 1 and 2 tothe multi-view transliteration problem isstraightforward.
After an ensemble of learners aretrained, the overall PSM can be expressed as alinear combination of the learners,1( | ) ( | ),n i iiP EW CW w P EW CW==?
(8)where iw is the weight of ith learner ( | )iP EW CW ,which can be learnt by using a development corpus.5 ExperimentsTo validate the effectiveness of the learningframework, we conduct a series of experiments intransliteration extraction on a development corpusdescribed later.
First, we repeat the experiment in(Kuo et al, 2006) to train a PSM using PSA andGSA feature fusion in a supervised manner, whichserves as the upper bound of Co-training or Co-EMsystem performance.
We then train the PSMs withsingle view V1, V2, V3 and V4 alone in anunsupervised manner.
The performance achievedby each view alone can be considered as thebaseline for multi-view benchmarking.
Then, werun two-view Co-training for differentcombinations of views on the same developmentcorpus.
We expect to see positive effects with themulti-view training.
Finally, we run theexperiments using two-view Co-training and Co-EM and compare the results.A 500 MB development corpus is constructed bycrawling pages from the Web for the experiments.We first establish a gold standard for performanceevaluation by manually labeling the corpus basedon the following criteria: (i) if an EW is partlyGivena).
A small set of labeled samples and a set ofunlabeled samples.b).
Learner A is trained on a labeled set topredict the labels of the unlabeled data.1) Loop for k iterationsa).
Learner B is trained on data labeled byLearner A to predict the labels of theunlabeled data;b).
Learner A is trained on data labeled  byLearner B to predict the labels of theunlabeled data;2) Combine models from Learners A and B.Given:a).
A small set of labeled samples and a setof unlabeled samples.b).
Two learners A and B are trained on thelabeled set.1) Loop for k iterations:a).
Learners A and B predict the labels ofthe unlabeled data to augment the labeledset;b).
Learners A and B are trained on theaugmented labeled set.2) Combine models from Learners A and B.377translated phonetically and partly translatedsemantically, only the phonetic transliterationconstituent is extracted to form a transliterationpair; (ii) multiple E-C pairs can appear in onesentence; (iii) an EW can have multiple validChinese transliterations and vice versa.We first derive 80,094 E-C pair candidates fromthe 500 MB corpus by spotting the co-occurrenceof English and Chinese words in the samesentences.
This can be done automatically withouthuman intervention.
Then, the manual labelingprocess results in 8,898 qualified E-C pairs, alsoreferred to as Distinct Qualified TransliterationPairs (DQTPs).To establish comparison, we first train a PSMusing all 8,898 DQTPs in a supervised manner andconduct a closed test as reported in Table 3.
Wefurther implement three PSM learning strategiesand conduct a systematic series of experiments byfollowing the recognition followed by validationstrategy proposed in (Kuo et al, 2007).Precision Recall F-measureClosed test 0.834 0.663 0.739Table 3.
Performance with PSM trained in thesupervised manner.For performance benchmarking, we define theprecision as the ratio of extracted number ofDQTPs over that of total extracted pairs, recall asthe ratio of extracted number of DQTPs over thatof total DQTPs, and F-measure as in Eq.
(9).
Theyare collectively referred to as extractionperformance.2 recall precisionF measurerecall precision?
??
=+(9)5.1 Unsupervised LearningAs formulated in Section 4.1, first, we derive aninitial PSM using randomly selected 100 seedDQTPs for each learner and simulate the Web-based learning process: (i) extract E-C pairs usingthe PSM; (ii) add all of the extracted E-C pairs tothe DQTP pool; (iii) re-estimate the PSM for eachview by using the updated DQTP pool.
Thisprocess is also known as semi-supervised EM(Muslea et al, 2002).As shown in Figure 3, the unsupervised learningalgorithm consistently improves the initial PSMusing in all four views.
To appreciate theeffectiveness of each view, we report the F-measures on each individual view V1, V2, V3 andV4, as 0.680, 0.620, 0.541 and 0.520, respectively atthe 6th iteration.
We observe that V1, the phoneme-based path, achieves the best result.00.10.20.30.40.50.60.70.81 2 3 4 5 6#IterationF-measureSupervisedV1V2V3V4Figure 3.
F-measure over iterations usingunsupervised learning with individual view.5.2 Co-training (CT)We report three typical combinations of two co-working learners or two-view Co-training.
Like inunsupervised learning, we start with the same 100seed DQTPs and an initial PSM model byfollowing the algorithm in Table 1 over 6 iterations.With two-view Co-training, we obtain 0.726,0.705, 0.590 and 0.716 in terms of F-measures forV1+V2, V2+V3, V3+V4 and V1+V4 at the 6thiteration, as shown in Figure 4.
Comparing Figure3 and 4, we find that Co-training consistentlyoutperforms unsupervised learning by exploitingcompatible information across different views.
TheV1+V2 Co-training outperforms other Co-trainingcombinations, and surprisingly achieves closeperformance to that of supervised learning.00.10.20.30.40.50.60.70.81 2 3 4 5 6#IterationF-measureSupervisedV1V1+V2V2+V3V3+V4V1+V4Figure 4.
F-measure over iterations using Co-training algorithm3785.3 Co-EM (CE)Next we start with the same 100 seed DQTPs byinitializing the training pool and carry out Co-EMon the same corpus.
We build PSM1 for Learner Aand PSM2 for Learner B.
To start with, PSM1 islearnt from the initial labeled set.
We then followthe algorithm in Table 2 by looping in thefollowing two steps over 6 iterations: (i) estimatethe PSM2 from the samples labeled by Learner A(V1) to extract the high confident E-C pairs andaugment the DQTP pool with the probabilisticallylabeled E-C pairs; (ii) estimate the PSM1 from thesamples labeled by Learner B (V2) to extract thehigh confident E-C pairs and augment the DQTPpool with the probabilistically labeled E-C pairs.We report the results in Figure 5.0.50.60.70.81 2 3 4 5 6#IterationF-measureSupervisedCT-V1+V2CE-V1+V2Figure 5.
Comparing F-measure over iterationsbetween Co-training (CT) and Co-EM (CE).To summarize, we compare the performance ofsix learning methods studied in this paper in Table4.
The Co-training and Co-EM learning approacheshave alleviated the need of manual labeling, yetachieving performance close to supervised learning.The multi-view learning effectively leveragesmultiple compatible and partially uncorrelatedviews.
It reduces the need of labeled samples from80,094 to just 100.We also compare the multi-view learningalgorithm with active learning on the samedevelopment corpus using same features.
Weinclude the results from previously reported work(Kuo et al, 2006) into Table 4 (see Exp.
2) wheremultiple features are fused in a single activelearning process.
In Exp.
2, PSA feature is theequivalent of V1 feature in Exp.
4; GSA feature isthe equivalent of V4 feature in Exp.
4.
In Exp.
4,we carry out V1+V4 two-view Co-training.
It isinteresting to find that the multi-view learning inthis paper achieves better results than activelearning in terms of F-measure while reducing theneed of manual labeling from 8,191 samples to just100.Exp.
Learning algorithm F-measure# ofsamplesto label1 Supervised 0.739 80,0942 Active Learning(Kuo et al, 2006) 0.710 8,1913 Unsupervised (V1) 0.680 1004 Co-training (V1+V4) 0.716 1005 Co-training (V1+V2) 0.726 1006 Co-EM (V1+V2) 0.725 100Table 4.
Comparison of six learning strategies.6 ConclusionsFusion of phoneme and grapheme features intransliteration modeling was studied in manyprevious works.
However, it was done through thecombination of phoneme and grapheme similarityscores (Bilac and Tanaka, 2004), or by poolingphoneme and grapheme features together into asingle-view training process (Oh and Choi, 2006b).This paper presents a new approach that leveragesthe information across different views toeffectively boost the learning from unlabeled data.We have shown that both Co-training and Co-EM not only outperform the unsupervised learningof single view, but also alleviate the need of datalabeling.
This reaffirms that multi-view is a viablesolution to the learning of transliteration model andhence transliteration extraction.
Moving forward,we believe that contextual feature in documentspresents another compatible, uncorrelated, andcomplementary view to the four views.We validate the effectiveness of the proposedalgorithms by conducting experiments ontransliteration extraction.
We hope to extend thework further by investigating the possibility ofapplying the multi-view learning algorithms tomachine translation.ReferencesS.
Bilac and H. Tanaka.
2004.
Improving back-transliteration by combining information sources, InProc.
of Int?l Joint Conf.
on Natural LanguageProcessing, pp.
542-547.379S.
Blum and T. Mitchell.
1998.
Combining Labeled andUnlabeled Data with Co-training, In Proc.
of 11thConference on Computational Learning Theory, pp.92-100.E.
Brill, G. Kacmarcik and C. Brockett.
2001.Automatically Harvesting Katakana-English TermPairs from Search Engine Query Logs, In Proc.
ofNatural Language Processing Pacific RimSymposium (NLPPRS), pp.
393-399.H.-H. Chen, W.-C. Lin, C.-H. Yang and W.-H. Lin.2006, Translating-Transliterating Named Entities forMultilingual Information Access, Journal of theAmerican Society for Information Science andTechnology, 57(5), pp.
645-659.A.
P. Dempster, N. M. Laird and D. B. Rubin.
1977.Maximum Likelihood from Incomplete Data via theEM Algorithm, Journal of the Royal StatisticalSociety, Ser.
B. Vol.
39, pp.
1-38.K.
S. Jeong, S. H. Myaeng, J. S. Lee and K.-S. Choi.1999.
Automatic Identification and Back-transliteration of Foreign Words for InformationRetrieval, Information Processing and Management,Vol.
35, pp.
523-540.K.
Knight and J. Graehl.
1998.
Machine Transliteration,Computational Linguistics, Vol.
24, No.
4, pp.
599-612.J.-S. Kuo, H. Li and Y.-K. Yang.
2006.
LearningTransliteration Lexicons from the Web, In Proc.
of44th ACL, pp.
1129-1136.J.-S. Kuo, H. Li and Y.-K. Yang.
2007.
A PhoneticSimilarity Model for Automatic Extraction ofTransliteration Pairs, ACM Transactions on AsianLanguage Information Processing.
6(2), pp.
1-24.J.-S. Lee.
1999.
An English-Korean Transliteration andRetransliteration Model for Cross-LingualInformation Retrieval, PhD Thesis, Department ofComputer Science, KAIST.D.
D. Lewis and J. Catlett.
1994.
HeterogeneousUncertainty Sampling for Supervised Learning, InProc.
of Int?l Conference on Machine Learning(ICML), pp.
148-156.H.
Li, M. Zhang and J. Su.
2004.
A Joint SourceChannel Model for Machine Transliteration, In Proc.of 42nd ACL, pp.
159-166.C.
D. Manning and H. Scheutze.
1999.
Fundamentals ofStatistical Natural Language Processing, The MITPress.H.
M. Meng, W.-K.
Lo, B. Chen and T. Tang.
2001.Generate Phonetic Cognates to Handle Name Entitiesin English-Chinese Cross-Language SpokenDocument Retrieval, In Proceedings of AutomaticSpeech Recognition Understanding (ASRU), pp.
311-314.I.
Muslea, S. Minton and C. A. Knoblock.
2002.
Active+ Semi-supervised learning = Robust Multi-ViewLearning, In Proc.
of the 9th Int?l Conference onMachine Learning, pp.
435-442.J.-Y.
Nie, P. Isabelle, M. Simard and R. Durand.
1999.Cross-language Information Retrieval based onParallel Texts and Automatic Mining of Parallel Textfrom the Web, In Proc.
of 22nd ACM SIGIR, pp 74-81.K.
Nigam and R. Ghani.
2000.
Analyzing theEffectiveness and Applicability of Co-training, InProc.
of the 9th Conference in Information andKnowledge and Management, pp.
86-93.J.-H. Oh, K.-S. Choi and H. Isahara.
2006a.
A MachineTransliteration Model based on Graphemes andPhonemes, ACM TALIP, Vol.
5, No.
3, pp.
185-208.J.-H. Oh and K.-S. Choi.
2006b.
An Ensemble ofTransliteration Models for Information Retrieval, InInformation Processing and Management, Vol.
42, pp.980-1002.R.
Sproat, T. Tao and C. Zhai.
2006.
Named EntityTransliteration with Comparable Corpora, In Proc.
of44th ACL, pp.
73-80.G.
T?r, D. Hakkani-T?r and R. E. Schapire.
2005.Combining Active and Semi-supervised Learning forSpoken Language Understanding, SpeechCommunication, 45, pp.
171-186.B.
Vauqois.
1988.
A Survey of Formal Grammars andAlgorithms for Recognition and Transformation inMachine Translation, IFIP Congress-68, reprintedTAO: Vingtcinq Ans de Traduction Automatique -Analectes in C. Boitet, Ed., Association Champollin,Grenoble, pp.201-213P.
Virga and S. Khudanpur.
2003.
Transliteration ofProper Names in Cross-Lingual Information Retrieval,In Proceedings of 41st ACL Workshop onMultilingual and Mixed Language Named EntityRecognition, pp.
57-64.380
