Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on SemanticEvaluation (SemEval 2013), pages 455?459, Atlanta, Georgia, June 14-15, 2013. c?2013 Association for Computational LinguisticsExperiments with DBpedia, WordNet and SentiWordNet as re-sources for sentiment analysis in micro-bloggingAbstractSentiment Analysis in Twitter has become animportant task due to the huge user-generatedcontent published over such media.
Suchanalysis could be useful for many domainssuch as Marketing, Finance, Politics, and So-cial.
We propose to use many features in orderto improve a trained classifier of Twitter mes-sages; these features extend the feature vectorof uni-gram model by the concepts extractedfrom DBpedia, the verb groups and the similaradjectives extracted from WordNet, the Senti-features extracted using SentiWordNet andsome useful domain specific features.
We alsobuilt a dictionary for emotion icons, abbrevia-tion and slang words in tweets which is usefulbefore extending the tweets with different fea-tures.
Adding these features has improved thef-measure accuracy 2% with SVM and 4%with NaiveBayes.1 IntroductionIn recent years, the explosion of social media haschanged the relation between the users and theweb.
The world has become closer and more ?real-time?
than ever.
People have increasingly been partof virtual society where they have created theircontent, shared it, interacted with others in differ-ent ways and at a very increasingly rate.
Twitter isone of the most important social media, with 1billion tweets1 posted per week and 637 millionusers2.1http://blog.kissmetrics.com/twitter-statistics/2http://twopcharts.com/twitter500million.phpWith the availability of such content, it attractsthe attention from who want to understand theopinion and interestingness of individuals.
Thus, itwould be useful in various domains such as poli-tics, financing, marketing and social.
In this con-text, the efficacy of sentiment analysis of twitterhas been demonstrated at improving prediction ofbox-office revenues of movies in advance of theirrelease (Asur and Huberman, 2010).
SentimentAnalysis has been used to study the impact of 13twitter accounts of celebrated person on their fol-lowers (Bae and Lee, 2012) and for forecasting theinteresting tweets which are more probably to bereposted by the followers many times (Naveed,Gottron et al 2011).However, sentiment analysis of microblogsfaces several challenges, the limited size of posts(e.g., maximum 140 characters in Twitter), theinformal language of such content containing slangwords and non-standard expressions (e.g.
gr8 in-stead of great, LOL instead of laughing out loud,goooood etc.
), and the high level of noise in theposts due to the absence of correctness verificationby user or spelling checker tools.Three different approaches can be identified inthe literature of Sentiment Analysis, the first ap-proach is the  lexicon based  which uses specifictypes of lexicons to derive the polarity of a text,this approach is suffering from the limited size oflexicon and requires human expertise to build thelexicon (Joshi, Balamurali et al 2011).
Thesecond one is machine learning approach whichuses annotated texts with a given label to learn astatistical model and an early work was done on amovie review dataset (Pang, Lee et al 2002).
Bothlexicon and machine learning approaches can beHussam Hamdan*,**,*** Frederic B?chet** Patrice Bellot*,***hussam.hamdan@lsis-.orgfrederic.bechet@lif-.univ-mrs.frpatrice.bellot@lsis-.org*LSISAix-Marseille Universit?
CNRSAv.
Esc.
Normandie Niemen,13397 Marseille Cedex 20,France**LIFAix-Marseille Universit?
CNRSAvenue de Luminy13288 Marseille Cedex 9,France***OpenEditionAix-Marseille Universit?
CNRS3 pl.
V. Hugo, case n?8613331 Marseille Cedex 3,France455combined to achieve a better performance (Khuc,Shivade et al2012).
The third one is social ap-proach which exploits social network propertiesand data for enhancing the accuracy of the classifi-cation (Speriosu, Sudan et al 2011; Tan, Lee et al2011; Hu, Tang et al 2013) (Hu, Tang et al2013) (Tan, Lee et al 2011).In this paper, we employ machine learning.
Eachtext is represented by a vector in which the featureshave to be selected carefully.
They can be thewords of the text, their POS tags (part of speech),or any other syntactic or semantic features.We propose to exploit some additional features(section 3) for sentiment analysis that extend therepresentation of tweets by:?
the concepts extracted from DBpedia3,?
the related adjectives and verb groups ex-tracted from WordNet4,?
some ?social?
features such as the numberof happy and bad emotion icons,?
the number of exclamation and questionmarks,?
the existence of URL (binary feature),?
if the tweet is re-tweeted (binary feature),?
the number of symbols the tweet contains,?
the number of uppercase words,?
some other senti-features extracted fromSentiWordNet5 such as the number ofpositive, negative and neutral words thatallow estimating a score of the negativity,positivity and objectivity of the tweets,their polarity and subjectivity.We extended the unigram model with thesefeatures (section 4.2).
We also constructed a dic-tionary for the abbreviations and the slang wordsused in Twitter in order to overcome the ambiguityof the tweets.We tested various combinations (section 4.2) ofthese features, and then we chose the one that gavethe highest F-measure for negative and positiveclasses (submission for Tweet subtask B of senti-ment analysis in twitter task of SemEval2013(Wilson, Kozareva et al2013)).
We tested differ-ent machine learning models: Na?ve Bayes, SVM,IcsiBoost6 but the submitted runs exploited SVMonly6.3http://dbpedia.org/About4http://wordnet.princeton.edu/5http://sentiwordnet.isti.cnr.it/6http://code.google.com/p/icsiboost/The rest of this paper is organized as follows.Section 2 outlines existing work of sentiment anal-ysis over Twitter.
Section 3 presents the featureswe used for training a classifier.
Our experimentsare described in section 4 and future work is pre-sented in section 5.2 Related WorkWe can identify three main approaches for senti-ment analysis in Twitter.
The lexicon based ap-proaches which depend on dictionaries of positiveand negative words and calculate the polarity ac-cording to the positive and negative words in thetext.
Many dictionaries have been created manual-ly such as ANEW (Aaffective Norms for EnglishWords) or automatically such as SentiWordNet(Baccianella, Esuli et al2010).
Four lexicon dic-tionaries were used to overcome the lack of wordsin each one (Joshi, Balamurali et al2011; Mukher-jee, Malu et al2012).
Automatically constructionof a Twitter lexicon was implemented by Khuc,Shivade et al(2012).Machine learning approaches were employedfrom annotated tweets by using Naive Bayes, Max-imum Entropy MaxEnt and Support Vector Ma-chines (SVM) (Go, Bhayani et al2009).
Go et al(2009) reported that SVM outperforms other clas-sifiers.
They tried a unigram and a bigram model inconjunction with parts-of-speech (POS) features;they noted that the unigram model outperforms allother models when using SVM and that POS fea-tures decline the results.
N-gram with lexicon fea-tures and microbloging features were useful butPOS features were not (Kouloumpis, Wilson et al2011).
In contrast, Pak & Paroubek (2010) re-ported that POS and bigrams both help.
Barbosa &Feng (2010) proposed the use of syntax features oftweets like retweet, hashtags, link, punctuation andexclamation marks in conjunction with featureslike prior polarity of words and POS of words,Agarwal et al(2011) extended their approach byusing real valued prior polarity and by combiningprior polarity with POS.
They build models forclassifying tweets into positive, negative and neu-tral sentiment classes and three models were pro-posed: a unigram model, a feature based model anda tree kernel based model which presented a newtree representation for tweets.
Both combiningunigrams with their features and combining thefeatures with the tree kernel outperformed the uni-456gram baseline.
Saif et al(2012) proposed to usethe semantic features, therefore they extracted thehidden concepts in the tweets.
They demonstratedthat incorporating semantic features extracted us-ing AlchemyAPI7 improves the accuracy of senti-ment classification through three different tweetcorpuses.The third main approach takes into account theinfluence of users on their followers and the rela-tion between the users and the tweets they wrote.Using the Twitter follower graph might improvethe polarity classification.
Speriosu, Sudan et al(2011) demonstrated that using label propagationwith Twitter follower graph improves the polarityclassification.
Tan, Lee et al(2011) employedsocial relation for user-level sentiment analysis.Hu, Tang et al(2013) proposed a sociologicalapproach to handling the noisy and short text(SANT) for supervised sentiment classification,they reported that social theories such as SentimentConsistency and Emotional Contagion could behelpful for sentiment analysis.3 Feature ExtractionWe used different types of features in order toimprove the accuracy of sentiment classification.?
Bag of words (uni-gram)The most commonly used features in text analysisare the bag of words which represent a text as un-ordered set of words.
It assumes that words areindependent from each other and also disregardstheir order of appearance.
We used these featuresas a baseline model.?
Domain specific featuresWe extracted some domain specific features oftweets which are: presence of an URL or not, thetweet was retweeted or not, the number of ?Not?,the number of happy emotion icons, the number ofsad emotion icons, exclamation and questionmarks, the number of words starting by a capitalletter, the number of @.?
DBpedia featuresWe used the DBpedia Spotlight8 Web service toextract the concepts of each tweet.
For example,7http://www.alchemyapi.com/8http://dbpedia-spotlight.github.io/for the previous tweet, the DBpedia concepts forChapel Hill are (Settlement, PopulatedPlace,Place).
Therefore, if we suppose that people postpositively about settlement, it would be more prob-able to post positively about Chapel Hill.?
WordNet featuresWe used WordNet for extracting the synonyms ofnouns, verbs and adjectives, the verb groups (thehierarchies in which the verb synsets are arranged),the similar adjectives (synset) and the concepts ofnouns which are related by the relation is-a inWordNet.We chose the first synonym set for each noun,adjective and verb, then the concepts of the firstnoun synonym set, the similar adjectives of thefirst adjective synonym set and the verb group ofthe first verb synonym set.
We think that thosefeatures would improve the accuracy because theycould overcome the ambiguity and the diversity ofthe vocabulary.- Senti-featuresWe used SentiWordNet for extracting the numberand the scores of positive, negative and neutralwords in tweets, the polarity (the number of posi-tive words divided by the number of negative onesincremented by one) and subjectivity (the numberof positive and negative words divided by the neu-tral ones incremented by one).4 Evaluations4.1 Data collectionWe used the data set provided in SemEval 2013 forsubtask B of sentiment analysis in Twitter (Wilson,Kozareva et al2013).
The participants were pro-vided with training tweets annotated positive, neg-ative or neutral.
We downloaded these tweets usingthe given script.
Among 9646 tweets, we couldonly download 8498 of them because of protectedprofiles and deleted tweets.
Then, we used thedevelopment set containing 1654 tweets for eva-luating our methods.
The method which gave thehighest accuracy for the average of positive andnegative classes was chosen for the submitted runs.Lastly, we combined the development set withtraining set and built a new model which predictedthe labels of the 3813 tweets in the test set.4574.2 ExperimentsWe have done various experiments using the fea-tures presented in Section 3 with SVM model us-ing linear kernel and the following parameters:weighting value=1, degree=3, cost=1, nu=0.5 andseed=1.
We firstly constructed feature vector oftweet terms which gave 0.52% for f-measure of thenegative and positive classes.
Then, we augmentedthis vector by the similar adjectives of WordNetwhich improves a little the f-measure, particularlyfor the positive class.
After that, we added the con-cepts of DBpedia which also improved the qualityof the positive class and declined the negative one.Finally, we added all the verb groups, senti-features and domain specific features which im-proved the f-measure for both negative and posi-tive classes but particularly for the positive one.Table 1 presents the results for each kind of featurevector.FeaturevectorUni-gram+adjectives+DBpedia+verbgroups+syntactic+senti-featuresf-measurePositive 0.603 0.619 0.622 0.637Negative 0.443 0.436 0.417 0.440Neutral 0.683 0.685 0.691 0.689Avg neg+pos 0.523 0.527 0.520 0.538Table 1.
The results of different feature vectors using linearSVM model (degree=3, weight=1, nu=0.5)FeaturevectorUni-gram+adjectives+DBpedia+verbgroups+syntactic+senti-featuresf-measurePositive 0.514 0.563 0.562 0.540Negative 0.397 0.422 0.427 0.424Neutral 0.608 0.652 0.648 0.636Avg neg+pos 0.456 0.493 0.495 0.482Table 2.
The results of different feature vectors using aNaiveBayes approach.We remark that the DBpedia concepts improvedthe accuracy, and just the similar adjectives andgroup verbs of  WordNet improved it, but the othersynonyms and concepts declined it.
The reasonmay be linked to a perturbation added by the syn-onyms.
Moreover, the first synonym set is not ne-cessary to be the most suitable one.
Many domainspecific and Senti-WordNet features improved theaccuracy, but others did not, such as the number ofneutral words, whether the tweet is reposted or not,the number of @ and the number of #.
So we ex-cluded the features that declined the accuracy.We have done some experiments using Naive-Bayes (Table 2).
Na?ve Bayes improved the accu-racy of the negative and positive classes, and thehighest f-measure was obtained by adding the ad-jectives and the DBpedia concepts.
Using suchfeatures improved the f-measure for the positiveand negative classes: about 2% with SVM and 4%with NaiveBayes.
The improvement given bymeans of the Na?ve Bayes model was more signifi-cant than the one obtained with SVM and neededfewer features, but the higher accuracy was ob-tained by SVM.5 Discussion and Future WorkIn this paper we experimented the value of usingDBpedia, WordNet and SentiWordNet for the sen-timent classification of tweets.
We extended thefeature vector of tweets by the concepts of DBpe-dia, verb groups and similar adjectives fromWordNet, the senti-features from SentiWordNetand other domain specific features.
We think thatusing other lexicon dictionaries with SentiWord-Net is more useful, we did not use POS Tagger fordetecting the part of speech.
We augmented thefeature vector by all these features.
In fact, forsome tweets this expansion is not the best strategy.However, it will be important to find out a way forselecting only the features that improve the accura-cy.We verified that the adjectives are useful fea-tures and we should now focus on extracting thesuitable and similar adjectives.
For the abbrevia-tion LOL (loud of laughing), it might be more use-ful to replace it by funny or by another adjectivethat reflects the sentiment of the writer.
However,we could enhance our dictionary by these adjec-tives.
We could handle the emotion icons in a simi-lar way.We also plan to combine the results of differentclassifiers for improving the total accuracy.458ReferencesAgarwal, A., B. Xie, et al(2011).
Sentiment analysis ofTwitter data.Proceedings of the Workshop on Lan-guages in Social Media.
Portland, Oregon, Associa-tion for Computational Linguistics: 30-38.Asur, S. and B.
A. Huberman (2010).
Predicting theFuture with Social Media.
Proceedings of the 2010IEEE/WIC/ACM International Conference on WebIntelligence and Intelligent Agent Technology - Vo-lume 01, IEEE Computer Society: 492-499.Baccianella, S., A. Esuli, et al(2010).
SentiWordNet3.0: An Enhanced Lexical Resource for SentimentAnalysis and Opinion Mining.
Proceedings of theSeventh Conference on International Language Re-sources and Evaluation (LREC'10), European Lan-guage Resources Association (ELRA).Bae, Y. and H. Lee (2012).
"Sentiment analysis of twit-ter audiences: Measuring the positive or negative in-fluence of popular twitterers."
J.
Am.
Soc.
Inf.
Sci.Technol.63(12): 2521-2535.Barbosa, L. and J. Feng (2010).
Robust sentiment detec-tion on Twitter from biased and noisy da-ta.Proceedings of the 23rd International Conferenceon Computational Linguistics: Posters.
Beijing, Chi-na, Association for Computational Linguistics: 36-44.Go, A., R. Bhayani, et al(2009).
Twitter SentimentClassification using Distant Supervision.Hu, X., L. Tang, et al(2013).
Exploiting social rela-tions for sentiment analysis in microblogging.
Pro-ceedings of the sixth ACM international conferenceon Web search and data mining.Rome, Italy, ACM:537-546.Joshi, A., A. R. Balamurali, et al(2011).
C-Feel-It: asentiment analyzer for micro-blogs.
Proceedings ofthe 49th Annual Meeting of the Association forComputational Linguistics: Human Language Tech-nologies: Systems Demonstrations.
Portland, Oregon,Association for Computational Linguistics: 127-132.Khuc, V. N., C. Shivade, et al(2012).
Towards build-ing large-scale distributed systems for twitter senti-ment analysis.
Proceedings of the 27th Annual ACMSymposium on Applied Computing.
Trento, Italy,ACM: 459-464.Kouloumpis, E., T. Wilson, et al(2011).Twitter Senti-ment Analysis: The Good the Bad and the OMG!Fifth International AAAI Conference on Weblogsand Social Media.Mukherjee, S., A. Malu, et al(2012).TwiSent: a multis-tage system for analyzing sentiment in twitter.
Pro-ceedings of the 21st ACM international conferenceon Information and knowledge management.Maui,Hawaii, USA, ACM: 2531-2534.Naveed, N., T. Gottron, et al(2011).
Bad News TravelsFast: A Content-based Analysis of Interestingness onTwitter.
Proc.
Web Science Conf.Pak, A. and P. Paroubek (2010).
Twitter as a corpus forsentiment analysis and opinion mining.Pang, B., L. Lee, et al(2002).
Thumbs up?
: sentimentclassification using machine learning techniques.Proceedings of the ACL-02 conference on Empiricalmethods in natural language processing - Volume 10,Association for Computational Linguistics: 79-86.Saif, H., Y.
He, et al(2012).Semantic sentiment analy-sis of twitter.Proceedings of the 11th internationalconference on The Semantic Web - Volume Part I.Boston, MA, Springer-Verlag: 508-524.Speriosu, M., N. Sudan, et al(2011).
Twitter polarityclassification with label propagation over lexicallinks and the follower graph.
Proceedings of the FirstWorkshop on Unsupervised Learning in NLP.
Edin-burgh, Scotland, Association for Computational Lin-guistics: 53-63.Tan, C., L. Lee, et al(2011).
User-level sentiment anal-ysis incorporating social networks.
Proceedings ofthe 17th ACM SIGKDD international conference onKnowledge discovery and data mining.
San Diego,California, USA, ACM: 1397-1405.Khuc, V. N., C. Shivade, et al(2012).
Towards build-ing large-scale distributed systems for twitter senti-ment analysis.
Proceedings of the 27th Annual ACMSymposium on Applied Computing.
Trento, Italy,ACM: 459-464.Wilson, T., Z. Kozareva, et al(2013).
"SemEval-2013Task 2: Sentiment Analysis in Twitter."
Proceedingsof the 7th International Workshop on Semantic Eval-uation.
Association for Computational Linguistics.459
