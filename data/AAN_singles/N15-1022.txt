Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 211?217,Denver, Colorado, May 31 ?
June 5, 2015.c?2015 Association for Computational LinguisticsAligning Sentences from Standard Wikipedia to Simple WikipediaWilliam Hwang, Hannaneh Hajishirzi, Mari Ostendorf, and Wei Wu{wshwang, hannaneh, ostendor, weiwu}@u.washington.eduUniversity of WashingtonAbstractThis work improves monolingual sentencealignment for text simplification, specificallyfor text in standard and simple Wikipedia.We introduce a method that improves overpast efforts by using a greedy (vs. ordered)search over the document and a word-level se-mantic similarity score based on Wiktionary(vs. WordNet) that also accounts for struc-tural similarity through syntactic dependen-cies.
Experiments show improved perfor-mance on a hand-aligned set, with the largestgain coming from structural similarity.
Re-sulting datasets of manually and automaticallyaligned sentence pairs are made available.1 IntroductionText simplification can improve accessibility of textsfor both human readers and automatic text process-ing.
Although simplification (Wubben et al, 2012)could benefit from data-driven machine translation,paraphrasing, or grounded language acquisitiontechniques, e.g.
(Callison Burch and Osborne, 2003;Fung and Cheung, 2004; Munteanu and Marcu,2005; Smith et al, 2010; Ganitkevitch et al, 2013;Hajishirzi et al, 2012; Kedziorski et al, 2014), workhas been limited because available parallel corporaare small (Petersen and Ostendorf, 2007) or auto-matically generated are noisy (Kauchak, 2013).Wikipedia is potentially a good resource for textsimplification (Napoles and Dredze, 2010; Mederoand Ostendorf, 2009), since it includes standard ar-ticles and their corresponding simple articles in En-glish.
A challenge with automatic alignment is thatstandard and simple articles can be written indepen-dently so they are not strictly parallel, and have verydifferent presentation ordering.
A few studies useeditor comments attached to Wikipedia edit logs toextract pairs of simple and difficult words (Yatskaret al, 2010; Woodsend and Lapata, 2011).
Othermethods use text-based similarity techniques (Zhuet al, 2010; Coster and Kauchak, 2011; Kauchak,2013), but assume sentences in standard and simplearticles are ordered relatively.In this paper, we align sentences in standard andsimple Wikipedia using a greedy method that, forevery simple sentence, finds the corresponding sen-tence (or sentence fragment) in standard Wikipedia.Unlike other methods, we do not make any assump-tions about the relative order of sentences in stan-dard and simple Wikipedia articles.
We also con-strain the many-to-one matches to cover sentencefragments.
In addition, our method takes advan-tage of a novel word-level semantic similarity mea-sure that is built on top of Wiktionary (vs. WordNet)which incorporates structural similarity representedin syntactic dependencies.
The Wiktionary-basedsimilarity measure has the advantage of greater wordcoverage than WordNet, while the use of syntacticdependencies provides a simple mechanism for ap-proximating semantic roles.Here, we report the first manually annotateddataset for evaluating alignments for text simplifica-tion, develop and assess a series of alignment meth-ods, and automatically generate a dataset of sentencepairs for standard and simple Wikipedia.
Experi-ments show that our alignment method significantlyoutperforms previous methods on the hand-aligned211Good Apple sauce or applesauce is a puree made of apples.
Applesauce (or applesauce) is a sauce that is made fromstewed or mashed apples.GoodPartialCommercial versions of applesauce are really availablein supermarketsIt is easy to make at home, and it is also sold alreadymade in supermarkets as a common food.Partial Applesauce is a sauce that is made from stewed andmashed apples.Applesauce is made by cooking down apples with wateror apple cider to the desired level.Table 1: Annotated examples: the matching regions for partial and good partial are italicized.set of standard and simple Wikipedia article pairs.The datasets are publicly available to facilitate fur-ther research on text simplification.2 BackgroundGiven comparable articles, sentence alignment isachieved by leveraging the sentence-level similarityscore and the sequence-level search strategy.Sentence-Level Scoring: There are two main ap-proaches for sentence-level scoring.
One approach,used in Wikipedia alignment (Kauchak, 2013), com-putes sentence similarities as the cosine distancebetween vector representations of tf.idf scores ofthe words in each sentence.
Other approaches relyon word-level ?(w,w?)
semantic similarity scoress(W,W?)
=1Z?w?Wmaxw??W??(w,w?
)idf(w).Previous work use WordNet-based similarity (Wuand Palmer, 1994; Mohler and Mihalcea, 2009; Hos-seini et al, 2014), distributional similarity (Guo andDiab., 2012), or discriminative similarity (Hajishirziet al, 2010; Rastegari et al, 2015).In this paper, we leverage pairwise word similar-ities, and introduce two novel word-level semanticsimilarity metrics and show that they outperform theprevious metrics.Sequence-Level Search: There are severalsequence-level alignment strategies (Shieber andNelken, 2006).
In (Zhu et al, 2010), sentence align-ment between simple and standard articles is com-puted without constraints, so every sentence can bematched to multiple sentences in the other docu-ment.
Two sentences are aligned if their similarityscore is greater than a threshold.
An alternative ap-proach is to compute sentence alignment with a se-quential constraint, i.e.
using dynamic programming(Coster and Kauchak, 2011; Barzilay and Elhadad,2003).
Specifically, the alignment is computed by arecursive function that optimizes alignment of one ortwo consecutive sentences in one article to sentencesin the other article.
This method relies on consis-tent ordering between two articles, which does notalways hold for Wikipedia articles.3 Simplification DatasetsWe develop datasets of aligned sentences in standardand simple Wikipedia.
Here, we describe the man-ually annotated dataset and leave the details of theautomatically generated dataset to Section 5.2.Manually Annotated: For every sentence in astandard Wikipedia article, we create an HTML sur-vey that lists sentences in the corresponding sim-ple article and allow the annotator to judge eachsentence pair as a good, good partial, partial, orbad match (examples in Table 1): Good: The se-mantics of the simple and standard sentence com-pletely match, possibly with small omissions (e.g.,pronouns, dates, or numbers).
Good Partial: A sen-tence completely covers the other sentence, but con-tains an additional clause or phrase that has infor-mation which is not contained within the other sen-tence.
Partial: The sentences discuss unrelated con-cepts, but share a short related phrase that does notmatch considerably.
Bad: The sentences discuss un-related concepts.The annotators were native speaker, hourly paid,undergraduate students.
We randomly selected 46article pairs from Wikipedia (downloaded in June2012) that started with the character ?a?.
In total,67,853 sentence pairs were annotated (277 good,281 good partial, 117 partial, and 67,178 bad).
Thekappa value for interannotator agreement is 0.68(13% of articles were dual annotated).
Most dis-agreements between annotators are confusions be-tween ?partial?
and ?good partial?
matches.
Themanually annotated dataset is used as a test set forevaluating alignment methods as well as tuning pa-rameters for generating automatically aligned pairsacross standard and simple Wikipedia.2124 Sentence Alignment MethodWe use a sentence-level similarity score that buildson a new word-level semantic similarity, describedbelow, together with a greedy search over the article.4.1 Word-Level SimilarityWord-level similarity functions return a similarityscore ?
(w1, w2) between words w1and w2.
We in-troduce two novel similarity metrics: Wiktionary-based similarity and structural semantic similarity.WikNet Similarity: The Wiktionary-based se-mantic similarity measure leverages synonym in-formation in Wiktionary as well as word-definitioncooccurrence, which is represented in a graph andreferred to as WikNet.
In our work, each lexicalcontent word (noun, verb, adjective and adverb) inthe English Wiktionary is represented by one nodein WikNet.
If word w2appears in any of the sensedefinitions of word w1, one edge between w1andw2is added, as illustrated in Figure 1.
We prunethe WikNet using the following steps: i) morpho-logical variations are mapped to their baseforms; ii)atypical word senses (e.g.
?obsolete,?
?JamaicanEnglish?)
are removed; and iii) stopwords (deter-mined based on high definition frequency) are re-moved.
After pruning, there are roughly 177k nodesand 1.15M undirected edges.
As expected, our Wik-tionary based similarity metric has a higher coverageof 71.8% than WordNet, which has a word coverageof 58.7% in our annotated dataset.Motivated by the fact that the WikNet graph struc-ture is similar to that of many social networks (Wattsand Strogatz, 1998; Wu, 2012), we characterize se-mantic similarity with a variation on a link-basednode similarity algorithm that is commonly appliedfor person relatedness evaluations in social networkstudies, the Jaccard coefficient (Salton and McGill,1983), by quantifying the number of shared neigh-bors for two words.
More specifically, we use the ex-tended Jaccard coefficient, which looks at neighborswithin an n-step reach (Fogaras and Racz, 2005)with an added term to indicate whether the wordsare direct neighbors.
In addition, if the words ortheir neighbors have synonym sets in Wiktionary,then the shared synonyms are used in the extendedJaccard measure.
If the two words are in eachother?s synonym lists, then the similarity is set toboy:?????sense1:?a?young?male?man??????????sense2:???lad?young?
boy?man?male?lad:?????sense1:?a?boy?or?a?young?man????sense2:??
?Figure 1: Part of WikNetwith words ?boy?
and ?lad?.1 otherwise, ?wk(w1, w2) =?nl=0Jsl(w1, w2), forJsl(w1, w2) =?l(w1)?syn?l(w2)?l(w1)?
?l(w2)where ?l(wi) is thel-step neighbor set of wi, and ?synaccounts forsynonyms if any.
We precomputed similarities be-tween pairs of words in WikNet to make the align-ment algorithm more efficient.
The WikNet is avail-able at http://ssli.ee.washington.edu/tial/projects/simplification/.Structural Semantic Similarity: We extend theword-level similarity metric to account for both se-mantic similarity between words, as well as thedependency structure between the words in a sen-tence.
We create a triplet for each word using Stan-ford?s dependency parser (de Marneffe et al, 2006).Each triplet tw= (w, h, r) consists of the givenword w, its head word h (governor), and the de-pendency relationship (e.g., modifier, subject, etc)between w and h. The similarity between wordsw1and w2combines the similarity between thesethree features in order to boost the similarity scoreof words whose head words are similar and appearin the same dependency structure: ?sswk(w1, w2) =?wk(w1, w2) + ?wk(h1, h2)?r(r1, r2) where ?wkisthe WikNet similarity and ?r(r1, r2) represents de-pendency similarity between relations r1and r2such that ?r= 0.5 if both relations fall into the samecategory, otherwise ?r= 0.4.2 Greedy Sequence-level AlignmentTo avoid aligning multiple sentences to the samecontent, we require one-to-one matches betweensentences in standard and simple Wikipedia articlesusing a greedy algorithm.
We first compute simi-larities between all sentences Sjin the simple ar-ticle and Aiin standard article using a sentence-level similarity score.
Then, our method iterativelyselects the most similar sentence pair S?, A?=arg max s(Sj, Ai) and removes all other pairs asso-ciated with the respective sentences, repeating un-til all sentences in the shorter document are aligned.The cost of aligning sentences in two articles S,A isO(mn) where m,n are the number of sentences in213Figure 2: Precision-recall curve forour method vs.baselines.articles S and A, respectively.
The run time of ourmethod using WikNet is less than a minute for thesentence pairs in our test set.Many simple sentences only match with a frag-ment of a standard sentence.
Therefore, we ex-tend the greedy algorithm to discover good partialmatches as well.
The intuition is that two sentencesare good partial matches if a simple sentence hashigher similarity with a fragment of a standard sen-tence than the complete sentence.
We extract frag-ments for every sentence from the Stanford syntac-tic parse tree (Klein and Manning, 2003).
The frag-ments are generated based on the second level of thesyntactic parse tree.
Specifically, each fragment is aS, SBAR, or SINV node at this level.
We then cal-culate the similarity between every simple sentenceSjwith every standard sentence Aias well as frag-ments of the standard sentenceAki.
The same greedyalgorithm is then used to align simple sentences withstandard sentences or their fragments.5 ExperimentsWe test our method on all pairs of standard and sim-ple sentences for each article in the hand-annotateddata (no training data is used).
For our experiments,we preprocess the data by removing topic names, listmarkers, and non-English words.
In addition, thedata was tokenized, lemmatized, and parsed usingStanford CoreNLP (Manning et al, 2014).5.1 ResultsComparison to Baselines: The baselines are ourimplementations of previous work: UnconstrainedWordNet (Mohler and Mihalcea, 2009), which usesan unconstrained search for aligning sentences andWordNet semantic similarity (in particular Wu-Palmer (1994)); Unconstrained Vector Space (ZhuGood vs. Others Max F1 AUCGreedy Struc.
WikNet (simG, ?sswk) 0.712 0.694Unconst.
WordNet (simUC, ?wd) 0.636 0.651Ordered Vec.
Space (simDP, scos) 0.564 0.495Unconst.
Vec.
Space (simUC, scos) 0.550 0.509Good & Good Partial vs. OthersGreedy Struc.
WikNet (simG, ?sswk) 0.607 0.529Unconst.
WordNet (simUC, ?wd) 0.515 0.499Ordered Vec.
Space (simDP, scos) 0.415 0.387Unconst.
Vec.
Space (simUC, scos) 0.431 0.391Table 2: Max F1, AUC for identifying good matches andidentifying good & good partial matches.et al, 2010), which uses a vector space repre-sentation and an unconstrained search for aligningsentences; and Ordered Vector Space (Coster andKauchak, 2011), which uses dynamic programmingfor sentence alignment and vector space scoring.We compare our method (Greedy StructuralWikNet) that combines the novel Wiktionary-basedstructural semantic similarity score with a greedysearch to the baselines.
Figure 2 and Table 2 showthat our method achieves higher precision-recall,max F1, and AUC compared to the baselines.
Theprecision-recall score is computed for good pairs vs.other pairs (good partial, partial, and bad).From error analysis, we found that most mistakesare caused by missing good matches (lower recall).As shown by the graph, we obtain high precision(about .9) at recall 0.5.
Thus, applying our methodon a large dataset yields high quality sentence align-ments that would benefit data-driven learning in textsimplification.Table 2 also shows that our method outperformsthe baselines in identifying good and good partialmatches.
Error analysis shows that our fragmentgeneration technique does not generate all possibleor meaningful fragments, which suggests a directionfor future work.
We list a few qualitative examplesin Table 3.Ablation Study: Table 4 shows the results ofablating each component of our method, sequence-level alignments and word-level similarity.Sequence-level Alignment: We study the contribu-tion of the greedy approach in our method by us-ing word-level structural semantic WikNet similar-ity ?ss(wk)and replacing the sequence-level greedysearch strategy with dynamic programming and un-214Good The castle was later incorporated into the construction ofAshtown Lodge which was to serve as the official residenceof the Under Secretary from 1782.After the building was made bigger and improved,it was used as the house for the Under Secretary ofIreland from 1782.GoodPartialMozart?s Clarinet Concerto and Clarinet Quintet are both inA major, and generally Mozart was more likely to use clar-inets in A major than in any other key besides E-flat majorMozart used clarinets in A major often.Table 3: Qualitative examples of the good and good partial matches identified by our method.Sequence-level Max F1 AUCGreedy (simG, ?sswk) 0.712+0.694+Ordered (simDP, ?sswk) 0.656+0.610+Unconstrained (simUC, ?sswk) 0.689 0.689Word-level Max F1 AUCStructural WikNet (simG, ?sswk) 0.712+0.694+WordNet (simG, ?wd) 0.665+0.663+Structural WordNet (simG, ?sswd) 0.685 0.679WikNet (simG, ?wk) 0.697 0.669Table 4: Max F1, AUC for ablation study on word-leveland sequence-level similarity scores.
Values with the+superscript are significant with p<0.05.constrained approaches.
As expected, the dynamicprogramming approach used in previous work doesnot perform as well as our method, even with thestructural semantic WikNet similarity, because thesimple Wikipedia articles are not explicit simplifica-tions of standard articles.Word-level Alignment: Table 4 also shows the con-tribution of the structural semantic WikNet similar-ity measure ?sswkvs.
other word-level similarities(WordNet similarity ?wd, structural semantic Word-Net similarity ?sswd, and WikNet similarity ?wk).In all the experiments, we use the sequence-levelgreedy alignment method.
The structural semanticsimilarity measures improve over the correspondingsimilarity measures for both WordNet and WikNet.Moreover, WikNet similarity outperforms WordNet,and the structural semantic WikNet similarity mea-sure achieves the best performance.5.2 Automatically Aligned DataWe develop a parallel corpus of aligned sentencepairs between standard and simple Wikipedia, to-gether with their similarity scores.
In particular, weuse our best case method to align sentences from 22kstandard and simple articles, which were downloadin April 2014.
To speed up our method, we indexthe similarity scores of frequent words and distributecomputations over multiple CPUs.We release a dataset of aligned sentence pairs,with a scaled threshold greater than 0.45.1Based onthe precision-recall data, we choose a scaled thresh-old of 0.67 (P = 0.798, R = 0.599, F1 = 0.685)for good matches, and 0.53 (P = 0.687, R = 0.495,F1 = 0.575) for good partial matches.
The se-lected thresholds yield around 150k good matches,130k good partial matches, and 110k uncategorizedmatches.
In addition, around 51.5 million potentialmatches, with a scaled score below 0.45, are prunedfrom the dataset.6 Conclusion and Future WorkThis work introduces a sentence alignment methodfor text simplification using a new word-level sim-ilarity measure (using Wiktionary and dependencystructure) and a greedy search over sentences andsentence fragments.
Experiments on comparablestandard and simple Wikipedia articles outperformcurrent baselines.
The resulting hand-aligned andautomatically aligned datasets are publicly avail-able.Future work involves developing text simplifica-tion techniques using the introduced datasets.
Inaddition, we plan to improve our current alignmenttechnique with better text preprocessing (e.g., coref-erence resolution (Hajishirzi et al, 2013)), learningsimilarities, as well as phrase alignment techniquesto obtain better partial matches.Acknowledgments This research was supportedin part by grants from the NSF (IIS-0916951) and(IIS-1352249).
The authors also wish to thank AlexTan and Hayley Garment for annotations, and theanonymous reviewers for their valuable feedback.1http://ssli.ee.washington.edu/tial/projects/simplification/215References[Barzilay and Elhadad2003] Regina Barzilay and NoemieElhadad.
2003.
Sentence alignment for monolingualcomparable corpora.
In Proceedings of the Conferenceon Empirical Methods in Natural Language Process-ing (EMNLP).
[Callison Burch and Osborne2003] Chris Callison Burchand Miles Osborne.
2003.
Bootstrapping parallel cor-pora.
In Proceedings of the Human Language Tech-nologies - North American Chapter of the Associationfor Computational Linguistics Workshop on Build-ing and Using Parallel Texts: Data Driven MachineTranslation and Beyond - Volume 3 (HLT NAACL PAR-ALLEL).
[Coster and Kauchak2011] William Coster and DavidKauchak.
2011.
Simple english Wikipedia: A newtext simplification task.
In Proceedings of the Confer-ence of the North American Chapter of the Associa-tion for Computational Linguistics: Human LanguageTechnologies (NAACL HLT).
[de Marneffe et al2006] Marie-Catherine de Marneffe,Bill MacCartney, and Christopher D. Manning.
2006.Generating typed dependency parses from phrasestructure parses.
In Proceedings of the InternationalConference on Language Resources and Evaluation(LREC).
[Fogaras and Racz2005] Daniel Fogaras and Balazs Racz.2005.
Scaling link-based similarity search.
In Pro-ceedings of the International Conference on WorldWide Web (WWW), pages 641?650.
[Fung and Cheung2004] Pascale Fung and Percy Cheung.2004.
Mining Very-Non-Parallel Corpora: Paral-lel Sentence and Lexicon Extraction via Bootstrap-ping and EM.
In Proceedings of the Conference onEmpirical Methods in Natural Language Processing(EMNLP).
[Ganitkevitch et al2013] Juri Ganitkevitch, BenjaminVan Durme, and Chris Callison-Burch.
2013.
PPDB:The paraphrase database.
In Proceedings of theConference of the North American Chapter of theAssociation for Computational Linguistics: Hu-man Language Technologies (NAACL HLT), pages758?764, Atlanta, Georgia, June.
Association forComputational Linguistics.
[Guo and Diab.2012] Weiwei Guo and Mona Diab.
2012.Modeling semantic textual similarity in the latentspace.
In Proceedings of the Conference of the As-sociation for Computational Linguistics (ACL).
[Hajishirzi et al2010] Hannaneh Hajishirzi, Wen-tau Yih,and Aleksander Kolcz.
2010.
Adaptive near-duplicatedetection via similarity learning.
In Proceedings of theAssociation for Computing Machinery Special InterestGroup in Information Retrieval(ACM SIGIR), pages419?426.
[Hajishirzi et al2012] Hannaneh Hajishirzi, MohammadRastegari, Ali Farhadi, and Jessica Hodgins.
2012.Semantic understanding of professional soccer com-mentaries.
In Proceedings of the Conference on Un-certainty in Artificial Intelligence (UAI).
[Hajishirzi et al2013] Hannaneh Hajishirzi, Leila Zilles,Daniel S Weld, and Luke S Zettlemoyer.
2013.
Jointcoreference resolution and named-entity linking withmulti-pass sieves.
In Proceedings of the Conferenceon Empirical Methods in Natural Language Process-ing (EMNLP).
[Hosseini et al2014] Mohammad Javad Hosseini, Han-naneh Hajishirzi, Oren Etzioni, and Nate Kushman.2014.
Learning to solve arithmetic word problemswith verb categorization.
In Proceedings of the Con-ference on Empirical Methods in Natural LanguageProcessing (EMNLP).
[Kauchak2013] David Kauchak.
2013.
Improving textsimplification language modeling using unsimplifiedtext data.
In Proceedings of the Conference of the As-sociation for Computational Linguistics (ACL).
[Kedziorski et al2014] Rik Koncel Kedziorski, Han-naneh Hajishirzi, and Ali Farhadi.
2014.
Multi-resolution language grounding with weak supervision.In Proceedings of the Conference on Empirical Meth-ods in Natural Language Processing (EMNLP), pages386?396.
[Klein and Manning2003] Dan Klein and Christopher D.Manning.
2003.
Accurate unlexicalized parsing.
InProceedings of the Conference of the Association forComputational Linguistics (ACL), pages 423?430.
[Manning et al2014] Christopher D. Manning, MihaiSurdeanu, John Bauer, Jenny Finkel, Steven J.Bethard, and David McClosky.
2014.
The StanfordCoreNLP natural language processing toolkit.
In Pro-ceedings of the Conference of the Association for Com-putational Linguistics: System Demonstrations (ACL),pages 55?60.
[Medero and Ostendorf2009] Julie Medero and Mari Os-tendorf.
2009.
Analysis of vocabulary difficulty usingwiktionary.
In Proceedings of the Speech and Lan-guage Technology in Education Workshop (SLaTE).
[Mohler and Mihalcea2009] Michael Mohler and RadaMihalcea.
2009.
Text-to-text semantic similarity forautomatic short answer grading.
In Proceedings of theConference of the European Chapter of the Associa-tion for Computational Linguistics (EACL).
[Munteanu and Marcu2005] Dragos Stefan Munteanuand Daniel Marcu.
2005.
Improving machine transla-tion performance by exploiting non-parallel corpora.Computational Linguistics.216[Napoles and Dredze2010] Courtney Napoles and MarkDredze.
2010.
Learning simple wikipedia: a cogi-tation in ascertaining abecedarian language.
In Pro-ceedings of the North American Chapter of the Asso-ciation for Computational Linguistics: Human Lan-guage Technologies Workshop on Computation Lin-guistics and Writing: Writing Processes and Author-ing Aids (NAACL HLT).
[Petersen and Ostendorf2007] Sarah Petersen and MariOstendorf.
2007.
Text simplification for langaugelearners: A corpus analysis.
In Proceedings of theSpeech and Language Technology in Education Work-shop (SLaTE).
[Rastegari et al2015] Mohammad Rastegari, HannanehHajishirzi, and Ali Farhadi.
2015.
Discriminativeand consistent similarities in instance-level multipleinstance learning.
In Proceedings of Computer Visionand Pattern Recognition (CVPR).
[Salton and McGill1983] Gerard Salton and MichaelMcGill.
1983.
Introduction to Modern InformationRetrieval.
McGraw-Hill.
[Shieber and Nelken2006] Stuart Shieber and RaniNelken.
2006.
Towards robust context-sensitivesentence alignment for monolingual corpora.
InProceedings of the Conference of the Association forComputational Linguistics (ACL).
[Smith et al2010] Jason R. Smith, Chris Quirk, andKristina Toutanova.
2010.
Extracting parallel sen-tences from comparable corpora using document levelalignment.
In Proceedings of the Conference of theNorth American Chapter of the Association for Com-putational Linguistics: Human Language Technolo-gies (NAACL HLT).
[Watts and Strogatz1998] Duncan J. Watts and Steven H.Strogatz.
1998.
Collective dynamics of small-worldnetworks.
Nature, pages 440?442.
[Woodsend and Lapata2011] Kristian Woodsend andMirella Lapata.
2011.
Wikisimple: Automatic sim-plification of wikipedia articles.
In Proceedings of theAssociation for Advancement of Artificial IntelligenceConference on Artificial Intelligence (AAAI), pages927?932, San Francisco, CA.
[Wu and Palmer1994] Zhibiao Wu and Martha Palmer.1994.
Verbs semantics and lexical selection.
In Pro-ceedings of the Conference of the Association for Com-putational Linguistics (ACL).
[Wu2012] Wei Wu.
2012.
Graph-based Algorithms forLexical Semantics and its Applications.
Ph.D. thesis,University of Washington.
[Wubben et al2012] Sander Wubben, Antal VanDen Bosch, and Emiel Krahmer.
2012.
Sentencesimplification by monolingual machine translation.
InProceedings of the Conference of the Association forComputational Linguistics (ACL), pages 1015?1024.
[Yatskar et al2010] Mark Yatskar, Bo Pang, CristianDanescu-Niculescu-Mizil, and Lillian Lee.
2010.
Forthe sake of simplicity: Unsupervised extraction of lex-ical simplifications from wikipedia.
In Proceedingsof the Conference of the North American Chapter ofthe Association for Computational Linguistics: Hu-man Language Technologies (NAACL HLT).
[Zhu et al2010] Zhemin Zhu, Delphine Bernhard, andIryna Gurevych.
2010.
A monolingual tree-basedtranslation model for sentence simplification.
In Pro-ceedings of the International Conference on Computa-tional Linguistics (COLING).217
