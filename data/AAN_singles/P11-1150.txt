Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 1496?1505,Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational LinguisticsAspect Ranking: Identifying Important Product Aspects from OnlineConsumer ReviewsJianxing Yu, Zheng-Jun Zha, Meng Wang, Tat-Seng ChuaSchool of ComputingNational University of Singapore{jianxing, zhazj, wangm, chuats}@comp.nus.edu.sgAbstractIn this paper, we dedicate to the topic of aspectranking, which aims to automatically identifyimportant product aspects from online con-sumer reviews.
The important aspects areidentified according to two observations: (a)the important aspects of a product are usuallycommented by a large number of consumers;and (b) consumers?
opinions on the importantaspects greatly influence their overall opin-ions on the product.
In particular, given con-sumer reviews of a product, we first identifythe product aspects by a shallow dependencyparser and determine consumers?
opinions onthese aspects via a sentiment classifier.
Wethen develop an aspect ranking algorithm toidentify the important aspects by simultane-ously considering the aspect frequency andthe influence of consumers?
opinions given toeach aspect on their overall opinions.
The ex-perimental results on 11 popular products infour domains demonstrate the effectiveness ofour approach.
We further apply the aspectranking results to the application of document-level sentiment classification, and improve theperformance significantly.1 IntroductionThe rapidly expanding e-commerce has facilitatedconsumers to purchase products online.
More than$156 million online product retail sales have beendone in the US market during 2009 (Forrester Re-search, 2009).
Most retail Web sites encourage con-sumers to write reviews to express their opinions onvarious aspects of the products.
This gives rise toFigure 1: Sample reviews on iPhone 3GS producthuge collections of consumer reviews on the Web.These reviews have become an important resourcefor both consumers and firms.
Consumers com-monly seek quality information from online con-sumer reviews prior to purchasing a product, whilemany firms use online consumer reviews as an im-portant resource in their product development, mar-keting, and consumer relationship management.
Asillustrated in Figure 1, most online reviews expressconsumers?
overall opinion ratings on the product,and their opinions on multiple aspects of the prod-uct.
While a product may have hundreds of aspects,we argue that some aspects are more important thanthe others and have greater influence on consumers?purchase decisions as well as firms?
product devel-opment strategies.
Take iPhone 3GS as an exam-ple, some aspects like ?battery?
and ?speed,?
aremore important than the others like ?moisture sen-sor.?
Generally, identifying the important productaspects will benefit both consumers and firms.
Con-sumers can conveniently make wise purchase deci-sion by paying attentions on the important aspects,while firms can focus on improving the quality of1496these aspects and thus enhance the product reputa-tion effectively.
However, it is impractical for peopleto identify the important aspects from the numerousreviews manually.
Thus, it becomes a compellingneed to automatically identify the important aspectsfrom consumer reviews.A straightforward solution for important aspectidentification is to select the aspects that are fre-quently commented in consumer reviews as the im-portant ones.
However, consumers?
opinions onthe frequent aspects may not influence their over-all opinions on the product, and thus not influenceconsumers?
purchase decisions.
For example, mostconsumers frequently criticize the bad ?signal con-nection?
of iPhone 4, but they may still give highoverall ratings to iPhone 4.
On the other hand,some aspects, such as ?design?
and ?speed,?
may notbe frequently commented, but usually more impor-tant than ?signal connection.?
Hence, the frequency-based solution is not able to identify the truly impor-tant aspects.Motivated by the above observations, in this pa-per, we propose an effective approach to automat-ically identify the important product aspects fromconsumer reviews.
Our assumption is that theimportant aspects of a product should be the as-pects that are frequently commented by consumers,and consumers?
opinions on the important aspectsgreatly influence their overall opinions on the prod-uct.
Given the online consumer reviews of a spe-cific product, we first identify the aspects in the re-views using a shallow dependency parser (Wu et al,2009), and determine consumers?
opinions on theseaspects via a sentiment classifier.
We then design anaspect ranking algorithm to identify the importantaspects by simultaneously taking into account theaspect frequency and the influence of consumers?opinions given to each aspect on their overall opin-ions.
Specifically, we assume that consumer?s over-all opinion rating on a product is generated basedon a weighted sum of his/her specific opinions onmultiple aspects of the product, where the weightsessentially measure the degree of importance of theaspects.
A probabilistic regression algorithm is thendeveloped to derive these importance weights byleveraging the aspect frequency and the consistencybetween the overall opinions and the weighted sumof opinions on various aspects.
We conduct ex-periments on 11 popular products in four domains.The consumer reviews on these products are crawledfrom the prevalent forum Web sites (e.g., cnet.comand viewpoint.com etc.)
More details of our reviewcorpus are discussed in Section 3.
The experimen-tal results demonstrate the effectiveness of our ap-proach on important aspects identification.
Further-more, we apply the aspect ranking results to the ap-plication of document-level sentiment classificationby carrying out the term-weighting based on the as-pect importance.
The results show that our approachcan improve the performance significantly.The main contributions of this paper include,1) We dedicate to the topic of aspect ranking,which aims to automatically identify important as-pects of a product from consumer reviews.2) We develop an aspect ranking algorithm toidentify the important aspects by simultaneouslyconsidering the aspect frequency and the influenceof consumers?
opinions given to each aspect on theiroverall opinions.3) We apply aspect ranking results to the applica-tion of document-level sentiment classification, andimprove the performance significantly.There is another work named aspect ranking(Snyder et al, 2007).
The task in this work is differ-ent from ours.
This work mainly focuses on predict-ing opinionated ratings on aspects rather than iden-tifying important aspects.The rest of this paper is organized as follows.
Sec-tion 2 elaborates our aspect ranking approach.
Sec-tion 3 presents the experimental results, while Sec-tion 4 introduces the application of document-levelsentiment classification.
Section 5 reviews relatedwork and Section 6 concludes this paper with futureworks.2 Aspect Ranking FrameworkIn this section, we first present some notations andthen elaborate the key components of our approach,including the aspect identification, sentiment classi-fication, and aspect ranking algorithm.2.1 Notations and Problem FormulationLet R = {r1, ?
?
?
, r|R|} denotes a set of online con-sumer reviews of a specific product.
Each reviewr ?
R is associated with an overall opinion rating1497Or, and covers several aspects with consumer com-ments on these aspects.
Suppose there arem aspectsA = {a1, ?
?
?
, am} involved in the review corpusR, where ak is the k-th aspect.
We define ork as theopinion on aspect ak in review r. We assume thatthe overall opinion rating Or is generated based ona weighted sum of the opinions on specific aspectsork (Wang et al, 2010).
The weights are denoted as{?rk}mk=1, each of which essentially measures thedegree of importance of the aspect ak in review r.Our task is to derive the important weights of as-pects, and identify the important aspects.Next, we will introduce the key components ofour approach, including aspect identification thatidentifies the aspects ak in each review r, aspect sen-timent classification which determines consumers?opinions ork on various aspects, and aspect rankingalgorithm that identifies the important aspects.2.2 Aspect IdentificationAs illustrated in Figure 1, there are usually two typesof reviews, Pros and Cons review and free text re-views on the Web.
For Pros and Cons reviews, theaspects are identified as the frequent noun terms inthe reviews, since the aspects are usually noun ornoun phrases (Liu, 2009), and it has been shownthat simply extracting the frequent noun terms fromthe Pros and Cons reviews can get high accurateaspect terms (Liu el al., 2005).
To identify the as-pects in free text reviews, we first parse each reviewusing the Stanford parser 1, and extract the nounphrases (NP) from the parsing tree as aspect can-didates.
While these candidates may contain muchnoise, we leverage the Pros and Cons reviews toassist identify aspects from the candidates.
In par-ticular, we explore the frequent noun terms in Prosand Cons reviews as features, and train a one-classSVM (Manevitz et al, 2002) to identify aspects inthe candidates.
While the obtained aspects may con-tain some synonym terms, such as ?earphone?
and?headphone,?
we further perform synonym cluster-ing to get unique aspects.
Specifically, we first ex-pand each aspect term with its synonym terms ob-tained from the synonym terms Web site 2, and thencluster the terms to obtain unique aspects based on1http://nlp.stanford.edu/software/lex-parser.shtml2http://thesaurus.comunigram feature.2.3 Aspect Sentiment ClassificationSince the Pros and Cons reviews explicitly expresspositive and negative opinions on the aspects, re-spectively, our task is to determine the opinions infree text reviews.
To this end, we here utilize ProsandCons reviews to train a SVM sentiment classifier.Specifically, we collect sentiment terms in the Prosand Cons reviews as features and represent each re-view into feature vector using Boolean weighting.Note that we select sentiment terms as those appearin the sentiment lexicon provided by MPQA project(Wilson et al, 2005).
With these features, we thentrain a SVM classifier based on Pros and Cons re-views.
Given a free text review, since it may covervarious opinions on multiple aspects, we first locatethe opinionated expression modifying each aspect,and determine the opinion on the aspect using thelearned SVM classifier.
In particular, since the opin-ionated expression on each aspect tends to containsentiment terms and appear closely to the aspect (Huand Liu, 2004), we select the expressions which con-tain sentiment terms and are at the distance of lessthan 5 from the aspect NP in the parsing tree.2.4 Aspect RankingGenerally, consumer?s opinion on each specific as-pect in the review influences his/her overall opin-ion on the product.
Thus, we assume that the con-sumer gives the overall opinion rating Or based onthe weighted sum of his/her opinion ork on each as-pect ak:?mk=1 ?rkork, which can be rewritten as?rTor, where?r and or are the weight and opinionvectors.
Inspired by the work of Wang et al (2010),we viewOr as a sample drawn from aGaussian Dis-tribution, with mean ?rTor and variance ?2,p(Or) =1?2??2exp[?
(Or ?
?rTor)22?2].
(1)To model the uncertainty of the importanceweights ?r in each review, we assume ?r as a sam-ple drawn from a Multivariate Gaussian Distribu-tion, with ?
as the mean vector and?
as the covari-ance matrix,p(?r) =1(2pi)n/2|?|1/2 exp[?12(?r ?
?)T?
?1(?r ?
?)].
(2)1498We further incorporate aspect frequency as a priorknowledge to define the distribution of ?
and ?.Specifically, the distribution of ?
and ?
is definedbased on its Kullback-Leibler (KL) divergence to aprior distribution with a mean vector?0 and an iden-tity covariance matrix I in Eq.3.
Each element in?0is defined as the frequency of the corresponding as-pect: frequency(ak)/?mi=1 frequency(ai).p(?,?)
= exp[??
?KL(Q(?,?
)||Q(?0, I))],(3)where KL(?, ?)
is the KL divergence, Q(?,?)
de-notes a Multivariate Gaussian Distribution, and ?
isa tradeoff parameter.Base on the above definition, the probability ofgenerating the overall opinion rating Or on review ris given as,p(Or|?, r) =?p(Or|?rTor, ?2)?
p(?r|?,?)
?
p(?,?)d?r,(4)where?
= {?,?,?, ?2} are the model parameters.Next, we utilize Maximum Log-likelihood (ML)to estimate the model parameters given the con-sumer reviews corpus.
In particular, we aim to findan optimal ??
to maximize the probability of observ-ing the overall opinion ratings in the reviews corpus.??
= argmax?
?r?Rlog(p(Or|?, r))= argmin?
(|R| ?
1) log det(?)
+?r?R[log ?2+(Or?
?rTor)2?2 + (?r ?
?)T?
?1(?r ?
?)]+(tr(?)
+ (?0 ?
?
)TI(?0 ?
?)).
(5)For the sake of simplicity, we denote the objectivefunction?r?R log(p(Or|?, r)) as ?(?
).The derivative of the objective function with re-spect to each model parameter vanishes at the mini-mizer:??(?)?
?r = ?
(?rTor?Or)or?2 ??
?1(?r ?
?
)= 0;(6)??(?)??
=?r?R[??
?1(?r ?
?)]?
?
?
I(?0 ?
?
)= 0;(7)??(?)??
=?r?R{?(?
?1)T ?
[?(?
?1)T (?r ?
?
)(?r ?
?
)T (?
?1)T ]}+ ?
?[(?
?1)T ?
I]= 0;(8)??(?)?
?2 =?r?R(?
1?2 +(Or?
?rTor)2?4 ) = 0,(9)which lead to the following solutions:?
?r = (ororT?2 +?
?1)?1(Oror?2 +??1?);(10)??
= (|R|?
?1 + ?
?
I)?1(?
?1?r?R?r + ?
?
I?0);(11)??
= {[ 1?
?r?R[(?r ?
?
)(?r ?
?
)T]+( |R|??2?
)2I]1/2 ?
(|R|??)2?
I}T ;(12)?
?2 = 1|R|?r?R(Or ?
?rTor)2.
(13)We can see that the above parameters are involvedin each other?s solution.
We here utilize AlternatingOptimization technique to derive the optimal param-eters in an iterative manner.
We first hold the param-eters ?, ?
and ?2 fixed and update the parameters?r for each review r ?
R. Then, we update theparameters ?, ?
and ?2 with fixed ?r (r ?
R).These two steps are alternatively iterated until theEq.5 converges.
As a result, we obtain the optimalimportance weights ?r which measure the impor-tance of aspects in review r ?
R. We then computethe final importance score ?k for each aspect ak byintegrating its importance score in all the reviews as,?k =1|R|?r?R?rk, k = 1, ?
?
?
,m (14)It is worth noting that the aspect frequency is con-sidered again in this integration process.
Accordingto the importance score ?k, we can identify impor-tant aspects.3 EvaluationsIn this section, we evaluate the effectiveness of ourapproach on aspect identification, sentiment classi-fication, and aspect ranking.3.1 Data and Experimental SettingThe details of our product review data set is givenin Table 1.
This data set contains consumer reviewson 11 popular products in 4 domains.
These reviewswere crawled from the prevalent forum Web sites,including cnet.com, viewpoints.com, reevoo.comand gsmarena.com.
All of the reviews were posted1499between June, 2009 and Sep 2010.
The aspects ofthe reviews, as well as the opinions on the aspectswere manually annotated as the gold standard forevaluations.Product Name Domain Review# Sentence#Canon EOS 450D (Canon EOS) camera 440 628Fujifilm Finepix AX245W (Fujifilm) camera 541 839Panasonic Lumix DMC-TZ7 (Panasonic) camera 650 1,546Apple MacBook Pro (MacBook) laptop 552 4,221Samsung NC10 (Samsung) laptop 2,712 4,946Apple iPod Touch 2nd (iPod Touch) MP3 4,567 10,846Sony NWZ-S639 16GB (Sony NWZ) MP3 341 773BlackBerry Bold 9700 (BlackBerry) phone 4,070 11,008iPhone 3GS 16GB (iPhone 3GS) phone 12,418 43,527Nokia 5800 XpressMusic (Nokia 5800) phone 28,129 75,001Nokia N95 phone 15,939 44,379Table 1: Statistics of the Data Sets, # denotes the size ofthe reviews/sentences.To examine the performance on aspect identifi-cation and sentiment classification, we employedF1-measure, which was the combination of preci-sion and recall, as the evaluation metric.
To evalu-ate the performance on aspect ranking, we adoptedNormalized Discounted Cumulative Gain at top k(NDCG@k) (Jarvelin and Kekalainen, 2002) as theperformance metric.
Given an aspect ranking lista1, ?
?
?
, ak, NDCG@k is calculated byNDCG@k = 1Zk?i=12t(i) ?
1log(1 + i), (15)where t(i) is the function that represents the rewardgiven to the aspect at position i, Z is a normaliza-tion term derived from the top k aspects of a perfectranking, so as to normalize NDCG@k to be within[0, 1].
This evaluation metric will favor the rankingwhich ranks the most important aspects at the top.For the reward t(i), we labeled each aspect as one ofthe three scores: Un-important (score 1), Ordinary(score 2) and Important (score 3).
Three volunteerswere invited in the annotation process as follows.We first collected the top k aspects in all the rank-ings produced by various evaluated methods (maxi-mum k is 15 in our experiment).
We then sampledsome reviews covering these aspects, and providedthe reviews to each annotator to read.
Each reviewcontains the overall opinion rating, the highlightedaspects, and opinion terms.
Afterward, the annota-tors were required to assign an importance score toeach aspect.
Finally, we took the average of theirscorings as the corresponding importance scores ofthe aspects.
In addition, there is only one parameter?
that needs to be tuned in our approach.
Through-out the experiments, we empirically set ?
as 0.001.3.2 Evaluations on Aspect IdentificationWe compared our aspect identification approachagainst two baselines: a) the method proposed byHu and Liu (2004), which was based on the asso-ciation rule mining, and b) the method proposed byWu et al (2009), which was based on a dependencyparser.The results are presented in Table 2.
On average,our approach significantly outperforms Hu?s methodand Wu?
method in terms of F1-measure by over5.87% and 3.27%, respectively.
In particular, ourapproach obtains high precision.
Such results implythat our approach can accurately identify the aspectsfrom consumer reviews by leveraging the Pros andCons reviews.Data set Hu?s Method Wu?s Method Our MethodCanon EOS 0.681 0.686 0.728Fujifilm 0.685 0.666 0.710Panasonic 0.636 0.661 0.706MacBook 0.680 0.733 0.747Samsung 0.594 0.631 0.712iPod Touch 0.650 0.660 0.718Sony NWZ 0.631 0.692 0.760BlackBerry 0.721 0.730 0.734iPhone 3GS 0.697 0.736 0.740Nokia 5800 0.715 0.745 0.747Nokia N95 0.700 0.737 0.741Table 2: Evaluations on Aspect Identification.
* signifi-cant t-test, p-values<0.05.3.3 Evaluations on Sentiment ClassificationIn this experiment, we implemented the follow-ing sentiment classification methods (Pang and Lee,2008):1) Unsupervised method.
We employed one un-supervised method which was based on opinion-ated term counting via SentiWordNet (Ohana et al,2009).2) Supervised method.
We employed three su-pervised methods proposed in Pang et al (2002),including Na?
?ve Bayes (NB), Maximum Entropy(ME), SVM.
These classifiers were trained based onthe Pros and Cons reviews as described in Section2.3.1500The comparison results are showed in Table 3.
Wecan see that supervised methods significantly outper-form unsupervised method.
For example, the SVMclassifier outperforms the unsupervised method interms of average F1-measure by over 10.37%.
Thus,we can deduce from such results that the Pros andCons reviews are useful for sentiment classification.In addition, among the supervised classifiers, SVMclassifier performs the best in most products, whichis consistent with the previous research (Pang et al,2002).Data set Senti NB SVM MECanon EOS 0.628 0.720 0.739 0.726Fujifilm 0.690 0.781 0.791 0.778Panasonic 0.625 0.694 0.719 0.697MacBook 0.708 0.820 0.828 0.797Samsung 0.675 0.723 0.717 0.714iPod Touch 0.711 0.792 0.805 0.791Sony NWZ 0.621 0.722 0.737 0.725BlackBerry 0.699 0.819 0.794 0.788iPhone 3GS 0.717 0.811 0.829 0.822Nokia 5800 0.736 0.840 0.851 0.817Nokia N95 0.706 0.829 0.849 0.826Table 3: Evaluations on Sentiment Classification.
Sentidenotes the method based on SentiWordNet.
* significantt-test, p-values<0.05.3.4 Evaluations on Aspect RankingIn this section, we compared our aspect ranking al-gorithm against the following three methods.1) Frequency-based method.
The method ranksthe aspects based on aspect frequency.2) Correlation-based method.
This method mea-sures the correlation between the opinions on spe-cific aspects and the overall opinion.
It counts thenumber of the cases when such two kinds of opin-ions are consistent, and ranks the aspects based onthe number of the consistent cases.3) Hybrid method.
This method captures both theaspect frequency and correlation by a linear combi-nation, as ??
Frequency-based Ranking + (1 ?
?
)?Correlation-based Ranking, where ?
is set to 0.5.The comparison results are showed in Table 4.
Onaverage, our approach outperforms the frequency-based method, correlation-based method, and hy-brid method in terms of NDCG@5 by over 6.24%,5.79% and 5.56%, respectively.
It improves theperformance over such three methods in terms ofNDCG@10 by over 3.47%, 2.94% and 2.58%, re-spectively, while in terms of NDCG@15 by over4.08%, 3.04% and 3.49%, respectively.
We can de-duce from the results that our aspect ranking algo-rithm can effectively identify the important aspectsfrom consumer reviews by leveraging the aspect fre-quency and the influence of consumers?
opinionsgiven to each aspect on their overall opinions.
Ta-ble 5 shows the aspect ranking results of these fourmethods.
Due to the space limitation, we here onlyshow top 10 aspects of the product iphone 3GS.
Wecan see that our approach performs better than theothers.
For example, the aspect ?phone?
is ranked atthe top by the other methods.
However, ?phone?
isa general but not important aspect.# Frequency Correlated Hybrid Our Method1 Phone Phone Phone Usability2 Usability Usability Usability Apps3 3G Apps Apps 3G4 Apps 3G 3G Battery5 Camera Camera Camera Looking6 Feature Looking Looking Storage7 Looking Feature Feature Price8 Battery Screen Battery Software9 Screen Battery Screen Camera10 Flash Bluetooth Flash Call qualityTable 5: iPhone 3GS Aspect Ranking Results.To further investigate the reasonability of ourranking results, we refer to one of the public userfeedback reports, the ?china unicom 100 customersiPhone user feedback report?
(Chinaunicom Report,2009).
The report demonstrates that the top four as-pects of iPhone product, which users most concernwith, are ?3G Network?
(30%), ?usability?
(30%),?out-looking design?
(26%), ?application?
(15%).All of these aspects are in the top 10 of our rank-ing results.Therefore, we can conclude that our approach isable to automatically identify the important aspectsfrom numerous consumer reviews.4 ApplicationsThe identification of important aspects can supporta wide range of applications.
For example, we can1501Frequency Correlation Hybrid Our MethodData set @5 @10 @15 @5 @10 @15 @5 @10 @15 @5 @10 @15Canon EOS 0.735 0.771 0.740 0.735 0.762 0.779 0.735 0.798 0.742 0.862 0.824 0.794Fujifilm 0.816 0.705 0.693 0.760 0.756 0.680 0.816 0.759 0.682 0.863 0.801 0.760Panasonic 0.744 0.807 0.783 0.763 0.815 0.792 0.744 0.804 0.786 0.796 0.834 0.815MacBook 0.744 0.771 0.762 0.763 0.746 0.769 0.763 0.785 0.772 0.874 0.776 0.760Samsung 0.964 0.765 0.794 0.964 0.820 0.840 0.964 0.820 0.838 0.968 0.826 0.854iPod Touch 0.836 0.830 0.727 0.959 0.851 0.744 0.948 0.785 0.733 0.959 0.817 0.801Sony NWZ 0.937 0.743 0.742 0.937 0.781 0.797 0.937 0.740 0.794 0.944 0.775 0.815BlackBerry 0.837 0.824 0.766 0.847 0.825 0.771 0.847 0.829 0.768 0.874 0.797 0.779iPhone 3GS 0.897 0.836 0.832 0.886 0.814 0.825 0.886 0.829 0.826 0.948 0.902 0.860Nokia 5800 0.834 0.779 0.796 0.834 0.781 0.779 0.834 0.781 0.779 0.903 0.811 0.814Nokia N95 0.675 0.680 0.717 0.619 0.619 0.691 0.619 0.678 0.696 0.716 0.731 0.748Table 4: Evaluations on Aspect Ranking.
@5, @10, @15 denote the evaluation metrics of NDCG@5, NDCG@10,and NDCG@15, respectively.
* significant t-test, p-values<0.05.provide product comparison on the important as-pects to users, so that users can make wise purchasedecisions conveniently.In the following, we apply the aspect ranking re-sults to assist document-level review sentiment clas-sification.
Generally, a review document containsconsumer?s positive/negative opinions on various as-pects of the product.
It is difficult to get the ac-curate overall opinion of the whole review withoutknowing the importance of these aspects.
In ad-dition, when we learn a document-level sentimentclassifier, the features generated from unimportantaspects lack of discriminability and thus may dete-riorate the performance of the classifier (Fang et al,2010).
While the important aspects and the senti-ment terms on these aspects can greatly influence theoverall opinions of the review, they are highly likelyto be discriminative features for sentiment classifica-tion.
These observations motivate us to utilize aspectranking results to assist classifying the sentiment ofreview documents.Specifically, we randomly sampled 100 reviews ofeach product as the testing data and used the remain-ing reviews as the training data.
We first utilized ourapproach to identify the importance aspects from thetraining data.
We then explored the aspect terms andsentiment terms as features, based on which each re-view is represented as a feature vector.
Here, wegive more emphasis on the important aspects andthe sentiment terms that modify these aspects.
Inparticular, we set the term-weighting as 1 + ?
?
?k,where ?k is the importance score of the aspect ak,?
is set to 100.
Based on the weighted features, wethen trained a SVM classifier using the training re-views to determine the overall opinions on the test-ing reviews.
For the performance comparison, wecompared our approach against two baselines, in-cluding Boolean weighting method and frequencyweighting (tf ) method (Paltoglou et al, 2010) thatdo not utilize the importance of aspects.
The com-parison results are shown in Table 6.
We can seethat our approach (IA) significantly outperforms theother methods in terms of average F1-measure byover 2.79% and 4.07%, respectively.
The resultsalso show that the Boolean weighting method out-performs the frequency weighting method in termsof average F1-measure by over 1.25%, which areconsistent with the previous research by Pang et al(2002).
On the other hand, from the IA weight-ing formula, we observe that without using the im-portant aspects, our term-weighting function will beequal to Boolean weighting.
Thus, we can speculatethat the identification of important aspects is ben-eficial to improving the performance of document-level sentiment classification.5 Related WorkExisting researches mainly focused on determiningopinions on the reviews, or identifying aspects fromthese reviews.
They viewed each aspect equallywithout distinguishing the important ones.
In thissection, we review existing researches related to ourwork.Analysis of the opinion on whole review text had1502SVM + Boolean SVM + tf SVM + IAData set P R F1 P R F1 P R F1Canon EOS 0.689 0.663 0.676 0.679 0.654 0.666 0.704 0.721 0.713Fujifilm 0.700 0.687 0.693 0.690 0.670 0.680 0.731 0.724 0.727Panasonic 0.659 0.717 0.687 0.650 0.693 0.671 0.696 0.713 0.705MacBook 0.744 0.700 0.721 0.768 0.675 0.718 0.790 0.717 0.752Samsung 0.755 0.690 0.721 0.716 0.725 0.720 0.732 0.765 0.748iPod Touch 0.686 0.746 0.714 0.718 0.667 0.691 0.749 0.726 0.737Sony NWZ 0.719 0.652 0.684 0.665 0.646 0.655 0.732 0.684 0.707BlackBerry 0.763 0.719 0.740 0.752 0.709 0.730 0.782 0.758 0.770iPhone 3GS 0.777 0.775 0.776 0.772 0.762 0.767 0.820 0.788 0.804Nokia 5800 0.755 0.836 0.793 0.744 0.815 0.778 0.805 0.821 0.813Nokia N95 0.722 0.699 0.710 0.695 0.708 0.701 0.768 0.732 0.750Table 6: Evaluations on Term Weighting methods for Document-level Review Sentiment Classification.
IA denotesthe term weighing based on the important aspects.
* significant t-test, p-values<0.05.been extensively studied (Pang and Lee, 2008).
Ear-lier research had been studied unsupervised (Kim etal., 2004), supervised (Pang et al, 2002; Pang et al,2005) and semi-supervised approaches (Goldberg etal., 2006) for the classification.
For example, Mullenet al (2004) proposed an unsupervised classifica-tion method which exploited pointwise mutual in-formation (PMI) with syntactic relations and otherattributes.
Pang et al (2002) explored several ma-chine learning classifiers, including Na?
?ve Bayes,Maximum Entropy, SVM, for sentiment classifica-tion.
Goldberg et al (2006) classified the sentimentof the review using the graph-based semi-supervisedlearning techniques, while Li el al.
(2009) tackledthe problem using matrix factorization techniqueswith lexical prior knowledge.Since the consumer reviews usually expressedopinions on multiple aspects, some works haddrilled down to the aspect-level sentiment analysis,which aimed to identify the aspects from the reviewsand to determine the opinions on the specific aspectsinstead of the overall opinion.
For the topic of aspectidentification, Hu and Liu (2004) presented the asso-ciation mining method to extract the frequent termsas the aspects.
Subsequently, Popescu et al (2005)proposed their system OPINE, which extracted theaspects based on the KnowItAll Web informationextraction system (Etzioni et al, 2005).
Liu el al.
(2005) proposed a supervised method based on lan-guage pattern mining to identify the aspects in thereviews.
Later, Mei et al (2007) proposed a prob-abilistic topic model to capture the mixture of as-pects and sentiments simultaneously.
Afterwards,Wu et al (2009) utilized the dependency parser toextract the noun phrases and verb phrases from thereviews as the aspect candidates.
They then traineda language model to refine the candidate set, andto obtain the aspects.
On the other hand, for thetopic of sentiment classification on the specific as-pect, Snyder et al (2007) considered the situationwhen the consumers?
opinions on one aspect couldinfluence their opinions on others.
They thus builta graph to analyze the meta-relations between opin-ions, such as agreement and contrast.
And they pro-posed a Good Grief algorithm to leveraging suchmeta-relations to improve the prediction accuracyof aspect opinion ratings.
In addition, Wang et al(2010) proposed the topic of latent aspect ratingwhich aimed to infer the opinion rating on the as-pect.
They first employed a bootstrapping-based al-gorithm to identify the major aspects via a few seedword aspects.
They then proposed a generative La-tent Rating Regression model (LRR) to infer aspectopinion ratings based on the review content and theassociated overall rating.While there were usually huge collection of re-views, some works had concerned the topic ofaspect-based sentiment summarization to combatthe information overload.
They aimed to summa-rize all the reviews and integrate major opinions onvarious aspects for a given product.
For example,Titov et al (2008) explored a topic modeling methodto generate a summary based on multiple aspects.They utilized topics to describe aspects and incor-1503porated a regression model fed by the ground-truthopinion ratings.
Additionally, Lu el al.
(2009) pro-posed a structured PLSA method, which modeledthe dependency structure of terms, to extract the as-pects in the reviews.
They then aggregated opinionson each specific aspects and selected representativetext segment to generate a summary.In addition, some works proposed the topic ofproduct ranking which aimed to identify the bestproducts for each specific aspect (Zhang et al,2010).
They used a PageRank style algorithm tomine the aspect-opinion graph, and to rank the prod-ucts for each aspect.Different from previous researches, we dedicateour work to identifying the important aspects fromthe consumer reviews of a specific product.6 Conclusions and Future WorksIn this paper, we have proposed to identify the im-portant aspects of a product from online consumerreviews.
Our assumption is that the important as-pects of a product should be the aspects that are fre-quently commented by consumers and consumers?opinions on the important aspects greatly influencetheir overall opinions on the product.
Based on thisassumption, we have developed an aspect ranking al-gorithm to identify the important aspects by simulta-neously considering the aspect frequency and the in-fluence of consumers?
opinions given to each aspecton their overall opinions.
We have conducted exper-iments on 11 popular products in four domains.
Ex-perimental results have demonstrated the effective-ness of our approach on important aspects identifi-cation.
We have further applied the aspect rankingresults to the application of document-level senti-ment classification, and have significantly improvedthe classification performance.
In the future, we willapply our approach to support other applications.AcknowledgmentsThis work is supported in part by NUS-Tsinghua Ex-treme Search (NExT) project under the grant num-ber: R-252-300-001-490.
We give warm thanks tothe project and anonymous reviewers for their com-ments.ReferencesP.
Beineke, T. Hastie, C. Manning, and S. Vaithyanathan.An Exploration of Sentiment Summarization.
AAAI,2003.G.
Carenini, R.T. Ng, and E. Zwart.
Extracting Knowl-edge from Evaluative Text.
K-CAP, 2005.G.
Carenini, R.T. Ng, and E. Zwart.
Multi-documentSummarization of Evaluative Text.
ACL, 2006.China Unicom 100 Customers iPhone User FeedbackReport, 2009.Y.
Choi and C. Cardie.
Hierarchical Sequential Learningfor Extracting Opinions and Their Attributes.
ACL,2010.H.
Cui, V. Mittal, and M. Datar.
Comparative Experi-ments on Sentiment Classification for Online ProductReviews.
AAAI, 2006.S.
Dasgupta and V. Ng.
Mine the Easy, Classify the Hard:A Semi-supervised Approach to Automatic SentimentClassification.
ACL, 2009.K.
Dave, S. Lawrence, and D.M.
Pennock.
Opinion Ex-traction and Semantic Classification of Product Re-views.
WWW, 2003.A.
Esuli and F. Sebastiani.
A Publicly Available LexicalResource for Opinion Mining.
LREC, 2006.O.
Etzioni, M. Cafarella, D. Downey, A. Popescu,T.
Shaked, S. Soderland, D. Weld, and A. Yates.
Un-supervised Named-entity Extraction from theWeb: AnExperimental Study.
Artificial Intelligence, 2005.J.
Fang, B.
Price, and L. Price.
Pruning Non-InformativeText Through Non-Expert Annotations to ImproveAspect-Level Sentiment Classification.
COLING,2010.O.
Feiguina and G. Lapalme.
Query-based Summariza-tion of Customer Reviews.
AI, 2007.Forrester Research.
State of Retailing Online 2009: Mar-keting Report.
http://www.shop.org/soro, 2009.A.
Goldberg and X. Zhu.
Seeing Stars when There aren?tMany Stars: Graph-based Semi-supervised Learningfor Sentiment Categorization.
ACL, 2006.M.
Gamon, A. Aue, S. Corston-Oliver, and E. Ringger.Pulse: Mining Customer Opinions from Free Text.IDA, 2005.M.
Hu and B. Liu.
Mining and Summarizing CustomerReviews.
SIGKDD, 2004.K.
Jarvelin and J. Kekalainen.
Cumulated Gain-basedEvaluation of IR Techniques.
TOIS, 2002.S.
Kim and E. Hovy.
Determining the Sentiment of Opin-ions.
COLING, 2004.J.
Kim, J.J. Li, and J.H.
Lee.
Discovering the Discrimi-native Views: Measuring Term Weights for SentimentAnalysis.
ACL, 2009.1504Kelsey Research and comscore.
Online Consumer-Generated Reviews Have Significant Impact on OfflinePurchase Behavior.K.
Lerman, S. Blair-Goldensohn, and R. McDonald.Sentiment Summarization: Evaluating and LearningUser Preferences.
EACL, 2009.B.
Li, L. Zhou, S. Feng, and K.F.
Wong.
A Unified GraphModel for Sentence-Based Opinion Retrieval.
ACL,2010.T.
Li and Y. Zhang, and V. Sindhwani.
A Non-negativeMatrix Tri-factorization Approach to Sentiment Clas-sification with Lexical Prior Knowledge.
ACL, 2009.B.
Liu, M. Hu, and J. Cheng.
Opinion Observer: Ana-lyzing and Comparing Opinions on the Web.
WWW,2005.B.
Liu.
Handbook Chapter: Sentiment Analysis and Sub-jectivity.
Handbook of Natural Language Processing.Marcel Dekker, Inc. New York, NY, USA, 2009.Y.
Lu, C. Zhai, and N. Sundaresan.
Rated Aspect Sum-marization of Short Comments.
WWW, 2009.L.M.
Manevitz and M. Yousef.
One-class svms for Doc-ument Classification.
The Journal of Machine Learn-ing, 2002.R.
McDonal, K. Hannan, T. Neylon, M. Wells, andJ.
Reynar.
Structured Models for Fine-to-coarse Sen-timent Analysis.
ACL, 2007.Q.Mei, X. Ling, M.Wondra, H. Su, and C.X.
Zhai.
TopicSentiment Mixture: Modeling Facets and Opinions inWeblogs.
WWW, 2007.H.J.
Min and J.C. Park.
Toward Finer-grained SentimentIdentification in Product Reviews Through Linguisticand Ontological Analyses.
ACL, 2009.T.
Mullen and N. Collier.
Sentiment Analysis usingSupport Vector Machines with Diverse InformationSources.
EMNLP, 2004.N.
Nanas, V. Uren, and A.D. Roeck.
Building and Ap-plying a Concept Hierarchy Representation of a UserProfile.
SIGIR, 2003.H.
Nishikawa, T. Hasegawa, Y. Matsuo, and G. Kikui.Optimizing Informativeness and Readability for Senti-ment Summarization.
ACL, 2010.B.
Ohana and B. Tierney.
Sentiment Classification of Re-views Using SentiWordNet.
IT&T Conference, 2009.G.
Paltoglou and M. Thelwall.
A study of InformationRetrieval Weighting Schemes for Sentiment Analysis.ACL, 2010.B.
Pang, L. Lee, and S. Vaithyanathan.
Thumbs up?
Sen-timent Classification using Machine Learning Tech-niques.
EMNLP, 2002.B.
Pang, L. Lee, and S. Vaithyanathan.
A Sentimen-tal Education: Sentiment Analysis using SubjectivitySummarization based on Minimum cuts Techniques.ACL, 2004.B.
Pang and L. Lee.
Seeing stars: Exploiting Class Re-lationships for Sentiment Categorization with Respectto Rating Scales.
ACL, 2005.B.
Pang and L. Lee.
Opinion mining and sentimentanalysis.
Foundations and Trends in Information Re-trieval, 2008.A.-M. Popescu and O. Etzioni.
Extracting Product Fea-tures and Opinions from Reviews.
HLT/EMNLP,2005.R.
Prabowo and M. Thelwall.
Sentiment analysis: ACombined Approach.
Journal of Informetrics, 2009.G.
Qiu, B. Liu, J. Bu, and C. Chen..
Expanding DomainSentiment Lexicon through Double Propagation.
IJ-CAI, 2009.M.
Sanderson and B. Croft.
Document-word Co-regularization for Semi-supervised Sentiment Analy-sis.
ICDM, 2008.B.
Snyder and R. Barzilay.
Multiple Aspect Ranking us-ing the Good Grief Algorithm.
NAACL HLT, 2007.S.
Somasundaran, G. Namata, L. Getoor, and J. Wiebe.Opinion Graphs for Polarity and Discourse Classifica-tion.
ACL, 2009.Q.
Su, X. Xu, H. Guo, X. Wu, X. Zhang, B. Swen, andZ.
Su.
Hidden Sentiment Association in Chinese WebOpinion Mining.
WWW, 2008.C.
Toprak, N. Jakob, and I. Gurevych.
Sentence andExpression Level Annotation of Opinions in User-Generated Discourse.
ACL, 2010.P.
Turney.
Thumbs up or Thumbs down?
Semantic Ori-entation Applied to Unsupervised Classification of Re-views.
ACL, 2002.I.
Titov and R. McDonald.
A Joint Model of Text andAspect Ratings for Sentiment Summarization.
ACL,2008.H.
Wang, Y. Lu, and C.X.
Zhai.
Latent Aspect RatingAnalysis on Review Text Data: A Rating RegressionApproach.
KDD, 2010.B.
Wei and C. Pal.
Cross Lingual Adaptation: An Exper-iment on Sentiment Classifications.
ACL, 2010.T.
Wilson, J. Wiebe, and P. Hoffmann.
RecognizingContextual Polarity in Phrase-level Sentiment Analy-sis.
HLT/EMNLP, 2005.T.
Wilson and J. Wiebe.
Annotating Attributions and Pri-vate States.
ACL, 2005.Y.
Wu, Q. Zhang, X. Huang, and L. Wu.
Phrase Depen-dency Parsing for Opinion Mining.
ACL, 2009.K.
Zhang, R. Narayanan, and A. Choudhary.
Voice ofthe Customers: Mining Online Customer Reviews forProduct Feature-based Ranking.
WOSN, 2010.J.
Zhu, H. Wang, and B.K.
Tsou.
Aspect-based SentenceSegmentation for Sentiment Summarization.
TSA,2009.L.
Zhuang, F. Jing, and X.Y.
Zhu.
Movie Review Miningand Summarization.
CIKM, 2006.1505
