NAACL HLT Demonstration Program, pages 23?24,Rochester, New York, USA, April 2007. c?2007 Association for Computational LinguisticsA Conversational In-car Dialog SystemBaoshi Yan1 Fuliang Weng1 Zhe Feng1 Florin Ratiu2 Madhuri Raya1 Yao Meng1Sebastian Varges2 Matthew Purver2 Annie Lien1 Tobias Scheideck1 Badri Raghunathan1Feng Lin1 Rohit Mishra4 Brian Lathrop4 Zhaoxia Zhang4 Harry Bratt3 Stanley Peters2Research and Technology Center, Robert Bosch LLC, Palo Alto, California1Center for the Study of Language and Information, Stanford University, Stanford, California2Speech Technology and Research Lab, SRI International, Menlo Park, California3Electronics Research Lab, Volkswagen of America, Palo Alto, California4AbstractIn this demonstration we present a con-versational dialog system for automobiledrivers.
The system provides a voice-based interface to playing music, findingrestaurants, and navigating while driving.The design of the system as well as thenew technologies developed will be pre-sented.
Our evaluation showed that thesystem is promising, achieving high taskcompletion rate and good user satisfation.1 IntroductionAs a constant stream of electronic gadgets such asnavigation systems and digital music players en-ters cars, it threatens driving safety by increasingdriver distraction.
According to a 2005 report bythe National Highway Traffic Safety Administration(NHTSA) (NHTSA, 2005), driver distraction andinattention from all sources contributed to 20-25%of police reported crashes.
It is therefore impor-tant to design user interfaces to devices that mini-mize driver distraction, to which voice-based inter-faces have been a promising approach as they keepa driver?s hands on the wheel and eyes on the road.In this demonstration we present a conversationaldialog system, CHAT, that supports music selection,restaurant selection, and driving navigation (Wenget al, 2006).
The system is a joint research effortfrom Bosch RTC, VWERL, Stanford CSLI, and SRISTAR Lab funded by NIST ATP.
It has reached apromising level, achieving a task completion rate of98%, 94%, 97% on playing music, finding restau-rants, and driving navigation respectively.Specifically, we plan to present a number of fea-tures in the CHAT system, including end-pointingwith prosodic cues, robust natural language under-standing, error identification and recovery strate-gies, content optimization, full-fledged reponse gen-eration, flexible multi-threaded, multi-device dialogmanagement, and support for random events, dy-namic information, and domain switching.2 System DescriptionsThe spoken dialog system consists of a number ofcomponents (see the figure on the next page).
In-stead of the hub architecture employed by Commu-nicator projects (Seneff et al, 1998), it is devel-oped in Java and uses flexible event-based, message-oriented middleware.
This allows for dynamic regis-tration of new components.
Among the componentmodules in the figure, we use the Nuance speechrecognition engine with class-based n-grams anddynamic grammars, and the Nuance Vocalizer as theTTS engine.
The Speech Enhancer removes noisesand echo.
The Prosody module will provide addi-tional features to the Natural Language Understand-ing (NLU) and Dialog Manager (DM) modules toimprove their performance.The NLU module takes a sequence of recognizedwords and tags, performs a deep linguistic analysiswith probabilistic models, and produces an XML-based semantic feature structure representation.
Par-allel to the deep analysis, a topic classifier assignsn-best topics to the utterance, which are used in thecases where the dialog manager cannot make anysense of the parsed structure.
The NLU module alsosupports dynamic updates of the knowledge base.The DM module mediates and manages interac-23tion.
It uses an information-state-update approach tomaintain dialog context, which is then used to inter-pret incoming utterances (including fragments andrevisions), resolve NPs, construct salient responses,track issues, etc.
Dialog states can also be used tobias SR expectation and improve SR performance,as has been performed in previous applications ofthe DM.
Detailed descriptions of the DM can befound in (Lemon et al, 2002) (Mirkovic and Cave-don, 2005).The Knowledge Manager (KM) controls accessto knowledge base sources (such as domain knowl-edge and device information) and their updates.
Do-main knowledge is structured according to domain-dependent ontologies.
The current KMmakes use ofOWL, a W3C standard, to represent the ontologicalrelationships between domain entities.The Content Optimization module acts as an in-termediary between the dialog management moduleand the knowledge management module and con-trols the amount of content and provides recommen-dations to user.
It receives queries in the form of se-mantic frames from the DM, resolves possible ambi-guities, and queries the KM.
Depending on the itemsin the query result as well as configurable properties,the module selects and performs an appropriate op-timization strategy (Pon-Barry et al, 2006).The Response Generation module takes query re-sults from the KM or Content Optimizer and gener-ates natural language sentences as system responsesto user utterances.
The query results are convertedinto natural language sentences via a bottom-up ap-proach using a production system.
An alignment-based ranking algorithm is used to select the bestgenerated sentence.The system supports random events and dy-namic external information, for example, the systemprompts users for the next turn when they drive closeto an intersection and dialogs can be carried out interms of the current dynamic situation.
The user canalso switch among the three different applicationseasily by explicitly instructing the system which do-main to operate in.3 AcknowledgementThis work is partially supported by the NIST Ad-vanced Technology Program.ReferencesOliver Lemon, Alex Gruenstein, and Stanley Peters.2002.
Collaborative activities and multi-tasking indialogue systems.
In Traitement Automatique desLangues (TAL), page 43(2).Danilo Mirkovic and Lawrence Cavedon.
2005.
Prac-tical Plug-and-Play Dialogue Management.
In Pro-ceedings of the 6th Meeting of the Pacific Associa-tion for Computational Linguistics (PACLING), page43(2), Tokyo, Japan.National Highway Traffic Safety AdministrationNHTSA.
2005.
NHTSA Vehicle Safety Rulemakingand Supporting Research Priorities: Calendar Years2005-2009.
January.Heather Pon-Barry, Fuliang Weng, and Sebastian Varges.2006.
Evaluation of content presentation strategiesfor an in-car spoken dialogue system.
In Proceedingsof the 9th International Conference on Spoken Lan-guage Processing (Interspeech/ICSLP), pages 1930?1933, Pittsburgh, PA, September.Stephanie Seneff, Ed Hurley, Raymond Lau, Chris-tine Pao, Philipp Schmid, and Victor Zue.
1998.GALAXY-II: A Reference Architecture for Conversa-tional System Development.
In International Confer-ence on Spoken Language Processing (ICSLP), page43(2), Sydney, Australia, December.Fuliang Weng, Sebastian Varges, Badri Raghunathan,Florin Ratiu, Heather Pon-Barry, Brian Lathrop,Qi Zhang, Tobias Scheideck, Harry Bratt, Kui Xu,Matthew Purver, Rohit Mishra, Annie Lien, Mad-huri Raya, Stanley Peters, Yao Meng, Jeff Russel,Lawrence Cavedon, Liz Shriberg, and Hauke Schmidt.2006.
CHAT: A conversational helper for automo-tive tasks.
In Proceedings of the 9th InternationalConference on Spoken Language Processing (Inter-speech/ICSLP), pages 1061?1064, Pittsburgh, PA,September.24
