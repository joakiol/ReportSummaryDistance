Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 1057?1064,Sydney, July 2006. c?2006 Association for Computational LinguisticsAre These Documents Written from Different Perspectives?
A Test ofDifferent Perspectives Based On Statistical Distribution DivergenceWei-Hao LinLanguage Technologies InstituteSchool of Computer ScienceCarnegie Mellon UniversityPittsburgh, PA 15213 U.S.A.whlin@cs.cmu.eduAlexander HauptmannLanguage Technologies InstituteSchool of Computer ScienceCarnegie Mellon UniversityPittsburgh, PA 15213 U.S.A.alex@cs.cmu.eduAbstractIn this paper we investigate how to auto-matically determine if two document col-lections are written from different per-spectives.
By perspectives we mean apoint of view, for example, from the per-spective of Democrats or Republicans.
Wepropose a test of different perspectivesbased on distribution divergence betweenthe statistical models of two collections.Experimental results show that the test cansuccessfully distinguish document collec-tions of different perspectives from othertypes of collections.1 IntroductionConflicts arise when two groups of people takevery different perspectives on political, socio-economical, or cultural issues.
For example, hereare the answers that two presidential candidates,John Kerry and George Bush, gave during the thirdpresidential debate in 2004 in response to a ques-tion on abortion:(1) Kerry: What is an article of faith for me isnot something that I can legislate on some-body who doesn?t share that article of faith.
Ibelieve that choice is a woman?s choice.
It?sbetween a woman, God and her doctor.
Andthat?s why I support that.
(2) Bush: I believe the ideal world is one inwhich every child is protected in law and wel-comed to life.
I understand there?s great dif-ferences on this issue of abortion, but I be-lieve reasonable people can come togetherand put good law in place that will help re-duce the number of abortions.After reading the above transcripts some readersmay conclude that one takes a ?pro-choice?
per-spective while the other takes a ?pro-life?
perspec-tive, the two dominant perspectives in the abortioncontroversy.Perspectives, however, are not always mani-fested when two pieces of text together are put to-gether.
For example, the following two sentencesare from Reuters newswire:(3) Gold output in the northeast China provinceof Heilongjiang rose 22.7 pct in 1986 from1985?s level, the New China News Agencysaid.
(4) Exco Chairman Richard Lacy told Reutersthe acquisition was being made from Bankof New York Co Inc, which currently holdsa 50.1 pct, and from RMJ partners who holdthe remainder.A reader would not from this pair of examples per-ceive as strongly contrasting perspectives as theKerry-Bush answers.
Instead, as the Reuters an-notators did, one would label Example 3 as ?gold?and Example 4 as ?acquisition?, that is, as two top-ics instead of two perspectives.Why does the contrast between Example 1 andExample 2 convey different perspectives, but thecontrast between Example 3 and Example 4 resultin different topics?
How can we define the impal-pable ?different perspectives?
anyway?
The defi-nition of ?perspective?
in the dictionary is ?subjec-tive evaluation of relative significance,?1 but canwe have a computable definition to test the exis-tence of different perspectives?1The American Heritage Dictionary of the English Lan-guage, 4th ed.
We are interested in identifying ?ideologi-cal perspectives?
(Verdonk, 2002), not first-person or second-person ?perspective?
in narrative.1057The research question about the definition ofdifferent perspectives is not only scientifically in-triguing, it also enables us to develop importantnatural language processing applications.
Sucha computational definition can be used to detectthe emergence of contrasting perspectives.
Me-dia and political analysts regularly monitor broad-cast news, magazines, newspapers, and blogs tosee if there are public opinion splitting.
The hugenumber of documents, however, make the task ex-tremely daunting.
Therefore an automated test ofdifferent perspectives will be very valuable to in-formation analysts.We first review the relevant work in Section 2.We take a model-based approach to develop acomputational definition of different perspectives.We first develop statistical models for the two doc-ument collections, A and B, and then measure thedegree of contrast by calculating the ?distance?between A and B.
How document collections arestatistically modeled and how distribution differ-ence is estimated are described in Section 3.
Thedocument corpora are described in Section 4.
InSection 5, we evaluate how effective the proposedtest of difference perspectives based on statisticaldistribution.
The experimental results show thatthe distribution divergence can successfully sepa-rate document collections of different perspectivesfrom other kinds of collection pairs.
We also in-vestigate if the pattern of distribution difference isdue to personal writing or speaking styles.2 Related WorkThere has been interest in understanding how be-liefs and ideologies can be represented in comput-ers since mid-sixties of the last century (Abelsonand Carroll, 1965; Schank and Abelson, 1977).The Ideology Machine (Abelson, 1973) can simu-late a right-wing ideologue, and POLITICS (Car-bonell, 1978) can interpret a text from conserva-tive or liberal ideologies.
In this paper we takea statistics-based approach, which is very differ-ent from previous work that rely very much onmanually-constructed knowledge base.Note that what we are interested in is to deter-mine if two document collections are written fromdifferent perspectives, not to model individual per-spectives.
We aim to capture the characteristics,specifically the statistical regularities of any pairsof document collections with opposing perspec-tives.
Given a pair of document collections A andB, our goal is not to construct classifiers that canpredict if a document was written from the per-spective of A or B (Lin et al, 2006), but to deter-mine if the document collection pair (A,B) con-vey opposing perspectives.There has been growing interest in subjectivityand sentiment analysis.
There are studies on learn-ing subjective language (Wiebe et al, 2004), iden-tifying opinionated documents (Yu and Hatzivas-siloglou, 2003) and sentences (Riloff et al, 2003;Riloff and Wiebe, 2003), and discriminating be-tween positive and negative language (Turney andLittman, 2003; Pang et al, 2002; Dave et al,2003; Nasukawa and Yi, 2003; Morinaga et al,2002).
There are also research work on automati-cally classifying movie or product reviews as pos-itive or negative (Nasukawa and Yi, 2003; Mullenand Collier, 2004; Beineke et al, 2004; Pang andLee, 2004; Hu and Liu, 2004).Although we expect by its very nature much ofthe language used when expressing a perspectiveto be subjective and opinionated, the task of la-beling a document or a sentence as subjective isorthogonal to the test of different perspectives.
Asubjectivity classifier may successfully identify allsubjective sentences in the document collectionpair A and B, but knowing the number of sub-jective sentences in A and B does not necessarilytell us if they convey opposing perspectives.
Weutilize the subjectivity patterns automatically ex-tracted from foreign news documents (Riloff andWiebe, 2003), and find that the percentages ofthe subjective sentences in the bitterlemons corpus(see Section 4) are similar (65.6% in the Pales-tinian documents and 66.2% in the Israeli docu-ments).
The high but almost equivalent number ofsubjective sentences in two perspectives suggeststhat perspective is largely expressed in subjectivelanguage but subjectivity ratio is not enough to tellif two document collections are written from thesame (Palestinian v.s.
Palestinian) or different per-spectives (Palestinian v.s.
Israeli)2.3 Statistical Distribution DivergenceWe take a model-based approach to measure towhat degree, if any, two document collections aredifferent.
A document is represented as a point2However, the close subjectivity ratio doesn?t mean thatsubjectivity can never help identify document collections ofopposing perspectives.
For example, the accuracy of the testof different perspectives may be improved by focusing ononly subjective sentences.1058in a V -dimensional space, where V is vocabularysize.
Each coordinate is the frequency of a wordin a document, i.e., term frequency.
Although vec-tor representation, commonly known as a bag ofwords, is oversimplified and ignores rich syntacticand semantic structures, more sophisticated rep-resentation requires more data to obtain reliablemodels.
Practically, bag-of-word representationhas been very effective in many tasks, includingtext categorization (Sebastiani, 2002) and infor-mation retrieval (Lewis, 1998).We assume that a collection of N documents,y1, y2, .
.
.
, yN are sampled from the followingprocess,?
?
Dirichlet(?
)yi ?
Multinomial(ni, ?
).We first sample a V -dimensional vector ?
from aDirichlet prior distribution with a hyperparameter?, and then sample a document yi repeatedly froma Multinomial distribution conditioned on the pa-rameter ?, where ni is the document length of theith document in the collection and assumed to beknown and fixed.We are interested in comparing the parameter ?after observing document collections A and B:p(?|A) = p(A|?)p(?
)p(A)= Dirichlet(?|?+?yi?Ayi).The posterior distribution p(?|?)
is a Dirichlet dis-tribution since a Dirichlet distribution is a conju-gate prior for a Multinomial distribution.How should we measure the difference betweentwo posterior distributions p(?|A) and p(?|B)?One common way to measure the difference be-tween two distributions is Kullback-Leibler (KL)divergence (Kullback and Leibler, 1951), definedas follows,D(p(?|A)||p(?|B))=?p(?|A) log p(?|A)p(?|B) d?.
(5)Directly calculating KL divergence according to(5) involves a difficult high-dimensional integral.As an alternative, we approximate KL divergenceusing Monte Carlo methods as follows,1.
Sample ?1, ?2, .
.
.
, ?M from Dirichlet(?|?+?yi?A yi).2.
Return D?
= 1M?Mi=1 log p(?i|A)p(?i|B) as a MonteCarlo estimate of D(p(?|A)||p(?|B)).Algorithms of sampling from Dirichlet distribu-tion can be found in (Ripley, 1987).
As M ?
?,the Monte Carlo estimate will converge to true KLdivergence by the Law of Large Numbers.4 CorporaTo evaluate how well KL divergence between pos-terior distributions can discern a document collec-tion pair of different perspectives, we collect twocorpora of documents that were written or spokenfrom different perspectives and one newswire cor-pus that covers various topics, as summarized inTable 1.
No stemming algorithms is performed;no stopwords are removed.Corpus Subset |D| ?|d| VbitterlemonsPalestinian 290 748.7 10309Israeli 303 822.4 11668Pal.
Editor 144 636.2 6294Pal.
Guest 146 859.6 8661Isr.
Editor 152 819.4 8512Isr.
Guest 151 825.5 88122004Presiden-tialDebateKerry 178 124.7 2554Bush 176 107.8 23931st Kerry 33 216.3 12741st Bush 41 155.3 11952nd Kerry 73 103.8 14722nd Bush 75 89.0 13333rd Kerry 72 104.0 14083rd Bush 60 98.8 1281Reuters-21578ACQ 2448 124.7 14293CRUDE 634 214.7 9009EARN 3987 81.0 12430GRAIN 628 183.0 8236INTEREST 513 176.3 6056MONEY-FX 801 197.9 8162TRADE 551 255.3 8175Table 1: The number of documents |D|, averagedocument length ?|d| , and vocabulary size V ofthe three corpora.The first perspective corpus consists of arti-cles published on the bitterlemons website3 fromlate 2001 to early 2005.
The website is set upto ?contribute to mutual understanding [betweenPalestinians and Israelis] through the open ex-change of ideas?4.
Every week an issue about theIsraeli-Palestinian conflict is selected for discus-sion (e.g., ?Disengagement: unilateral or coordi-nated??
), and a Palestinian editor and an Israelieditor each contribute one article addressing the3http://www.bitterlemons.org/4http://www.bitterlemons.org/about/about.html1059issue.
In addition, the Israeli and Palestinian ed-itors interview a guest to express their views onthe issue, resulting in a total of four articles in aweekly edition.
The perspective from which eacharticle is written is labeled as either Palestinian orIsraeli by the editors.The second perspective corpus consists of thetranscripts of the three Bush-Kerry presidential de-bates in 2004.
The transcripts are from the websiteof the Commission on Presidential Debates5.
Eachspoken document is roughly an answer to a ques-tion or a rebuttal.
The transcript are segmentedby the speaker tags already in the transcripts.
Allwords from moderators are discarded.The topical corpus contains newswire fromReuters in 1987.
Reuters-215786 is one of themost common testbeds for text categorization.Each document belongs to none, one, or more ofthe 135 categories (e.g., ?Mergers?
and ?U.S.
Dol-lars?.)
The number of documents in each categoryis not evenly distributed (median 9.0, mean 105.9).To estimate statistics reliably, we only considercategories with more than 500 documents, result-ing in a total of seven categories (ACQ, CRUDE,EARN, GRAIN, INTEREST, MONEY-FX, andTRADE).5 ExperimentsA test of different perspectives is acute when itcan draw distinctions between document collec-tion pairs of different perspectives and documentcollection pairs of the same perspective and others.We thus evaluate the proposed test of different per-spectives in the following four types of documentcollection pairs (A,B):Different Perspectives (DP) A and B are writ-ten from different perspectives.
For example,A is written from the Palestinian perspectiveand B is written from the Israeli perspectivein the bitterlemons corpus.Same Perspective (SP) A and B are written fromthe same perspective.
For example, A and Bconsist of the words spoken by Kerry.Different Topics (DT) A and B are written ondifferent topics.
For example, A is about5http://www.debates.org/pages/debtrans.html6http://www.ics.uci.edu/?kdd/databases/reuters21578/reuters21578.htmlacquisition (ACQ) and B is about crude oil(CRUDE).Same Topic (ST) A and B are written on thesame topic.
For example, A and B are bothabout earnings (EARN).The effectiveness of the proposed test of differ-ent perspectives can thus be measured by how thedistribution divergence of DP document collectionpairs is separated from the distribution divergenceof SP, DT, and ST document collection pairs.
Thelittle the overlap of the range of distribution di-vergence, the sharper the test of different perspec-tives.To account for large variation in the number ofwords and vocabulary size across corpora, we nor-malize the total number of words in a documentcollection to be the same K, and consider only thetop C% frequent words in the document collectionpair.
We vary the values of K and C , and find thatK changes the absolute scale of KL divergencebut does not change the rankings of four condi-tions.
Rankings among four conditions is consis-tent when C is small.
We only report results ofK = 1000, C = 10 in the paper due to space limit.There are two kinds of variances in the estima-tion of divergence between two posterior distribu-tion and should be carefully checked.
The firstkind of variance is due to Monte Carlo methods.We assess the Monte Carlo variance by calculat-ing a 100?
percent confidence interval as follows,[D?
?
?
?1(?2 )??
?M, D?
+ ??1(1?
?2 )??
?M]where ?
?2 is the sample variance of ?1, ?2, .
.
.
, ?M ,and ?(?
)?1 is the inverse of the standard normalcumulative density function.
The second kind ofvariance is due to the intrinsic uncertainties of datagenerating processes.
We assess the second kindof variance by collecting 1000 bootstrapped sam-ples, that is, sampling with replacement, from eachdocument collection pair.5.1 Quality of Monte Carlo EstimatesThe Monte Carlo estimates of the KL divergencefrom several document collection pair are listed inTable 2.
A complete list of the results is omit-ted due to the space limit.
We can see that the95% confidence interval captures well the MonteCarlo estimates of KL divergence.
Note that KLdivergence is not symmetric.
The KL divergence1060A B D?
95% CIACQ ACQ 2.76 [2.62, 2.89]Palestinian Palestinian 3.00 [3.54, 3.85]Palestinian Israeli 27.11 [26.64, 27.58]Israeli Palestinian 28.44 [27.97, 28.91]Kerry Bush 58.93 [58.22, 59.64]ACQ EARN 615.75 [610.85, 620.65]Table 2: The Monte Carlo estimate D?
and 95%confidence interval (CI) of the Kullback-Leiblerdivergence of several document collection pairs(A,B) with the number of Monte Carlo samplesM = 1000.of the pair (Israeli, Palestinian) is not necessarilythe same as (Palestinian, Israeli).
KL divergence isgreater than zero (Cover and Thomas, 1991) andequal to zero only when document collections Aand B are exactly the same.
Here (ACQ, ACQ) isclose to but not exactly zero because they are dif-ferent samples of documents in the ACQ category.Since the CIs of Monte Carlo estimates are reason-ably tight, we assume them to be exact and ignorethe errors from Monte Carlo methods.5.2 Test of Different PerspectivesWe now present the main result of the paper.We calculate the KL divergence between poste-rior distributions of document collection pairs infour conditions using Monte Carlo methods, andplot the results in Figure 1.
The test of differentperspectives based on statistical distribution diver-gence is shown to be very acute.
The KL diver-gence of the document collection pairs in the DPcondition fall mostly in the middle range, and iswell separated from the high KL divergence of thepairs in DT condition and from the low KL diver-gence of the pairs in SP and ST conditions.
There-fore, by simply calculating the KL divergence ofa document collection pair, we can reliably pre-dict that they are written from different perspec-tives if the value of KL divergence falls in themiddle range, from different topics if the value isvery large, from the same topic or perspective ifthe value is very small.5.3 Personal Writing Styles or Perspectives?One may suspect that the mid-range distributiondivergence is attributed to personal speaking orwriting styles and has nothing to do with differ-ent perspectives.
The doubt is expected becausehalf of the bitterlemons corpus are written by onePalestinian editor and one Israeli editor (see Ta-ble 1), and the debate transcripts come from onlytwo candidates.We test the hypothesis by computing the dis-tribution divergence of the document collectionpair (Israeli Guest, Palestinian Guest), that is, aDifferent Perspectives (DP) pair.
There are morethan 200 different authors in the Israeli Guest andPalestinian Guest collection.
If the distribution di-vergence of the pair with diverse authors falls outof the middle range, it will support that mid-rangedivergence is due to writing styles.
On the otherhand, if the distribution divergence still fall in themiddle range, we are more confident the effectis attributed to different perspectives.
We com-pare the distribution divergence of the pair (IsraeliGuest, Palestinian Guest) with others in Figure 2.ST SP DP Guest DTKLDivergence125102050200500Figure 2: The average KL divergence of documentcollection pairs in the bitterlemons Guest subset(Israeli Guest vs. Palestinian Guest), ST ,SP, DP,DT conditions.
The horizontal lines are the sameas those in Figure 1.The results show that the distribution diver-gence of the (Israeli Guest, Palestinian Guest) pair,as other pairs in the DP condition, still falls in themiddle range, and is well separated from SP andST in the low range and DT in the high range.
Thedecrease in KL divergence due to writing or speak-ing styles is noticeable, and the overall effect dueto different perspectives is strong enough to makethe test robust.
We thus conclude that the test ofdifferent perspectives based on distribution diver-gence indeed captures different perspectives, notpersonal writing or speaking styles.5.4 Origins of DifferencesWhile the effectiveness of the test of different per-spectives is demonstrated in Figure 1, one may10612 5 10 20 50 100 200 500 10000.000.050.100.15KL DivergenceDensitySPSTDPDTFigure 1: The KL divergence of the document collection pairs in four conditions: Different Perspectives(DP), Same Perspective (SP), Different Topics (DT), and Same Topic (ST).
Note that the x axis is in logscale.
The Monte Carlo estimates D?
of the pairs in DP condition are plotted as rugs.
D?
of the pairs inother conditions are omitted to avoid clutter and summarized in one-dimensional density using KernelDensity Estimation.
The vertical lines are drawn at the points with equivalent densities.wonder why the distribution divergence of thedocument collection pair with different perspec-tives falls in the middle range and what causes thelarge and small divergence of the document collec-tion pairs with different topics (DT) and the sametopic (ST) or perspective (SP), respectively.
Inother words where do the differences result from?We answer the question by taking a closer lookat the causes of the distribution divergence in ourmodel.
We compare the expected marginal dif-ference of ?
between two posterior distributionsp(?|A) and p(?|B).
The marginal distribution ofthe i-th coordinate of ?, that is, the i-th word in thevocabulary, is a Beta distribution, and thus the ex-pected value can be easily calculated.
We plot the??
= E[?i|A]?
E[?i|B] against E[?i|A] for eachcondition in Figure 3.How ??
is deviated from zero partially explainsdifferent patterns of distribution divergence in Fig-ure 1.
In Figure 3d we see that the ??
increasesas ?
increases, and the deviance from zero is muchgreater than those in the Same Perspective (Fig-ure 3b) and Same Topic (Figure 3a) conditions.The large ??
not only accounts for large distribu-tion divergence of the document pairs in DT con-ditions, but also shows that words in different top-ics that is frequent in one topic are less likely to befrequent in the other topic.
At the other extreme,document collection pairs of the Same Perspective(SP) or Same Topic (ST) show very little differ-ence in ?, which matches our intuition that docu-ments of the same perspective or the same topicuse the same vocabulary in a very similar way.The manner in which ??
is varied with thevalue of ?
in the Different Perspective (DP) con-dition is very unique.
The ??
in Figure 3c is notas small as those in the SP and ST conditions,but at the same time not as large as those in DTconditions, resulting in mid-range distribution di-vergence in Figure 1.
Why do document collec-tions of different perspectives distribute this way?Partly because articles from different perspectivesfocus on the closely related issues (the Palestinian-Israeli conflict in the bitterlemons corpus, or thepolitical and economical issues in the debate cor-pus), the authors of different perspectives write orspeak in a similar vocabulary, but with emphasison different words.6 ConclusionsIn this paper we develop a computational test ofdifferent perspectives based on statistical distri-bution divergence between the statistical modelsof document collections.
We show that the pro-10620.00 0.01 0.02 0.03 0.04 0.05 0.06?0.04?0.020.000.020.04(a) Same Topic (ST)0.00 0.01 0.02 0.03 0.04 0.05 0.06?0.04?0.020.000.020.04(b) Same Topic (SP)0.00 0.01 0.02 0.03 0.04 0.05 0.06?0.04?0.020.000.020.040.00 0.01 0.02 0.03 0.04 0.05 0.06?0.04?0.020.000.020.04(c) Two examples of Different Perspective (DP)Figure 3: The ??
vs. ?
plots of the typical docu-ment collection pairs in four conditions.
The hori-zontal line is ??
= 0.0.00 0.01 0.02 0.03 0.04 0.05 0.06?0.04?0.020.000.020.040.00 0.01 0.02 0.03 0.04 0.05 0.06?0.04?0.020.000.020.04(d) Two examples of Different Topics (DT)Figure 3: Cont?dposed test can successfully separate document col-lections of different perspectives from other typesof document collection pairs.
The distribution di-vergence falling in the middle range can not sim-ply be attributed to personal writing or speakingstyles.
From the plot of multinomial parameterdifference we offer insights into where the differ-ent patterns of distribution divergence come from.Although we validate the test of different per-spectives by comparing the DP condition with DT,SP, and ST conditions, the comparisons are byno means exhaustive, and the distribution diver-gence of some document collection pairs may alsofall in the middle range.
We plan to investigatemore types of document collections pairs, e.g., thedocument collections from different text genres(Kessler et al, 1997).AcknowledgmentWe would like thank the anonymous reviewers foruseful comments and suggestions.
This materialis based on work supported by the Advanced Re-search and Development Activity (ARDA) undercontract number NBCHC040037.1063ReferencesRobert P. Abelson and J. Douglas Carroll.
1965.
Com-puter simulation of individual belief systems.
TheAmerican Behavioral Scientist, 8:24?30, May.Robert P. Abelson, 1973.
Computer Models of Thoughtand Language, chapter The Structure of Belief Sys-tems, pages 287?339.
W. H. Freeman and Company.Philip Beineke, Trevor Hastie, and ShivakumarVaithyanathan.
2004.
The sentimental factor: Im-proving review classification via human-providedinformation.
In Proceedings of the Association forComputational Linguistics (ACL-2004).Jaime G. Carbonell.
1978.
POLITICS: Automatedideological reasoning.
Cognitive Science, 2(1):27?51.Thomas M. Cover and Joy A. Thomas.
1991.
Elementsof Information Theory.
Wiley-Interscience.Kushal Dave, Steve Lawrence, and David M. Pennock.2003.
Mining the peanut gallery: Opinion extractionand semantic classification of product reviews.
InProceedings of the 12th International World WideWeb Conference (WWW2003).Minqing Hu and Bing Liu.
2004.
Mining and summa-rizing customer reviews.
In Proceedings of the 2004ACM SIGKDD International Conference on Knowl-edge Discovery and Data Mining.Brett Kessler, Geoffrey Nunberg, and Hinrich Schu?tze.1997.
Automatic detection of text genre.
In Pro-ceedings of the 35th Conference on Association forComputational Linguistics, pages 32?38.S.
Kullback and R. A. Leibler.
1951.
On informationand sufficiency.
The Annals of Mathematical Statis-tics, 22(1):79?86, March.David D. Lewis.
1998.
Naive (Bayes) at forty: The in-dependence assumption in information retrieval.
InProceedings of the 9th European Conference on Ma-chine Learning (ECML).Wei-Hao Lin, Theresa Wilson, Janyce Wiebe, andAlexander Hauptmann.
2006.
Which side are youon?
identifying perspectives at the document andsentence levels.
In Proceedings of Tenth Conferenceon Natural Language Learning (CoNLL).S.
Morinaga, K. Yamanishi, K. Tateishi, andT.
Fukushima.
2002.
Mining product reputations onthe web.
In Proceedings of the 2002 ACM SIGKDDInternational Conference on Knowledge Discoveryand Data Mining.Tony Mullen and Nigel Collier.
2004.
Sentiment anal-ysis using support vector machines with diverse in-formation sources.
In Proceedings of the Confer-ence on Empirical Methods in Natural LanguageProcessing (EMNLP-2004).T.
Nasukawa and J. Yi.
2003.
Sentiment analysis:Capturing favorability using natural language pro-cessing.
In Proceedings of the 2nd InternationalConference on Knowledge Capture (K-CAP 2003).Bo Pang and Lillian Lee.
2004.
A sentimental edu-cation: Sentiment analysis using subjectivity sum-marization based on minimum cuts.
In Proceed-ings of the Association for Computational Linguis-tics (ACL-2004).Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.2002.
Thumbs up?
Sentiment classification usingmachine learning techniques.
In Proceedings of theConference on Empirical Methods in Natural Lan-guage Processing (EMNLP-2002).Ellen Riloff and Janyce Wiebe.
2003.
Learning ex-traction patterns for subjective expressions.
In Pro-ceedings of the Conference on Empirical Methods inNatural Language Processing (EMNLP-2003).Ellen Riloff, Janyce Wiebe, and Theresa Wilson.
2003.Learning subjective nouns using extraction patternbootstrapping.
In Proceedings of the 7th Conferenceon Natural Language Learning (CoNLL-2003).B.
D. Ripley.
1987.
Stochastic Simulation.
Wiley.Roger C. Schank and Robert P. Abelson.
1977.
Scripts,plans, goals, and understanding: an inquiry into hu-man knowledge structures.
Lawrene Erlbaum Asso-ciates.Fabrizio Sebastiani.
2002.
Machine learning in au-tomated text categorization.
ACM Computing Sur-veys, 34(1):1?47, March.Peter Turney and Michael L. Littman.
2003.
Mea-suring praise and criticism: Inference of semanticorientation from association.
ACM Transactions onInformation Systems (TOIS), 21(4):315?346.Peter Verdonk.
2002.
Stylistics.
Oxford UniversityPress.Janyce Wiebe, Theresa Wilson, Rebecca Bruce,Matthew Bell, and Melanie Martin.
2004.
Learn-ing subjective language.
Computational Linguistics,30(3).Hong Yu and Vasileios Hatzivassiloglou.
2003.
To-wards answering opinion questions: Separating factsfrom opinions and identifying the polarity of opin-ion sentences.
In Proceedings of the Conference onEmpirical Methods in Natural Language Processing(EMNLP-2003).1064
