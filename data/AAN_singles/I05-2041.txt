Tree Annotation Tool using Two-phase Parsingto Reduce Manual Effort for BuildingaTreebankSo-Young Park, Yongjoo Cho, Sunghoon Son,College of Computer Software & Media TechnologySangMyung University7 Hongji-dong, Jongno-guSEOUL, KOREA{ssoya,ycho,shson}@smu.ac.krUi-Sung Song and Hae-Chang RimDept.
of CSEKorea University,5-ka 1, Anam-dong, Seongbuk-kuSEOUL, KOREA{ussong,rim}@nlp.korea.ac.krAbstractIn this paper, we propose a tree annota-tion tool using a parser in order to builda treebank.
For the purpose of mini-mizing manual effort without any mod-ification of the parser, it performs two-phase parsing for the intra-structure ofeach segment and the inter-structure af-ter segmenting a sentence.
Experimen-tal results show that it can reduce man-ual effort about 24.5% as comparedwith a tree annotation tool without seg-mentation because an annotation?s in-tervention related to cancellation andreconstruction remarkably decrease al-though it requires the annotator to seg-ment some long sentence.1 IntroductionA treebank is a corpus annotated with syntacticinformation, and the structural analysis of eachsentence is represented as a bracketed tree struc-ture.
This kind of corpus has served as an ex-tremely valuable resource for computational lin-guistics applications such as machine translationand question answering (Lee et al, 1997; Choi,2001), and has also proved useful in theoreticallinguistics research (Marcus et al, 1993).However, for the purpose of building the tree-bank, an annotator spends a lot of time and man-ual effort.
Furthermore, it is too difficult to main-tain the consistency of the treebank based on onlythe annotator (Hindle, 1989; Chang et al, 1997).Therefore, we require a tree annotation tool to re-duce manual effort by decreasing the frequencyof the human annotators?
intervention.
Moreover,the tool can improve the annotating efficiency,and help maintain the consistency of the treebank(Kwak et al, 2001; Lim et al, 2004).In this paper, we propose a tree annotation toolusing a parser in order to reduce manual effort forbuilding a treebank.
Fundamentally, it generates acandidate syntactic structure by utilizing a parser.And then, the annotator cancels the incorrect con-stituents in the candidate syntactic structure, andreconstructs the correct constituents.2 Previous WorksUp to data, several approaches have been devel-oped in order to reduce manual effort for build-ing a treebank.
They can be classified into theapproaches using the heuristics (Hindle, 1989;Chang et al, 1997) and the approaches usingthe rules extracted from an already built treebank(Kwak et al, 2001; Lim et al, 2004).The first approaches are used for Penn Tree-bank (Marcus et al, 1993) and the KAIST lan-guage resource (Lee et al, 1997; Choi, 2001).Given a sentence, the approaches try to assign anunambiguous partial syntactic structure to a seg-ment of each sentence based on the heuristics.The heuristics are written by the grammarians sothat they are so reliable (Hindle, 1989; Chang etal., 1997).
However, it is too difficult to modifythe heuristics, and to change the features used forconstructing the heuristics (Lim et al, 2004).The second approaches are used for SEJONGtreebank (Kim and Kang, 2002).
Like the first238approaches, they also try to attach the partial syn-tactic structure to each sentence according to therules.
The rules are automatically extracted froman already built treebank.
Therefore, the ex-tracted rules can be updated whenever the anno-tator wants (Kwak et al, 2001; Lim et al, 2004).Nevertheless, they place a limit on the manual ef-fort reduction and the annotating efficiency im-provement because the extracted rules are lesscredible than the heuristics.In this paper, we propose a tree annotation toolusing a parser for the purpose of shifting the re-sponsibility of extracting the reliable syntacticrules to the parser.
It is always ready to change theparser into another parser.
However, most parsersstill tend to show low performance on the longsentences (Li et al, 1990; Doi et al, 1993; Kim etal., 2000).
Besides, one of the reasons to decreasethe parsing performance is that the initial syntac-tic errors of a word or a phrase propagates to thewhole syntactic structure.In order to prevent the initial errors from propa-gating without any modification of the parser, theproposed tool requires the annotator to segment asentence.
And then, it performs two-phase pars-ing for the intra-structure of each segment andthe inter-structure.
The parsing methods usingclause-based segmentation have been studied toimprove the parsing performance and the parsingcomplexity (Kim et al, 2000; Lyon and Dicker-son, 1997; Sang and Dejean, 2001).
Nevertheless,the clause-based segmentation can permit a shortsentence to be splitted into shorter segments un-necessarily although too short segments increasemanual effort to build a treebank.For the sake of minimizing manual effort, theproposed tree annotation tool induces the annota-tor to segment a sentence according to few heuris-tics verified by experimentally analyzing the al-ready built treebank.
Therefore, the heuristics canprefer the specific length unit rather than the lin-guistic units such as phrases and clauses.3 Tree Annotation ToolThe tree annotation tool is composed of segmen-tation, tree annotation for intra-structure, and treeannotation for inter-structure as shown in Figure1.Figure 1: tree annotation tool3.1 Sentence SegmentationThe sentence segmentation consists of three steps:segmentation step, examination step, and cancel-lation step.
In the segmentation step, the annota-tor segments a long sentence.
In the examinationstep, the tree annotation tool checks the lengthof each segment.
In the cancellation step, it in-duces the annotator to merge the adjacent shortsegments by cancelling some brackets.
Given ashort sentence, the tree annotation tool skips overthe sentence segmentation.As shown in the top of Figure 2, the annota-tor segments a sentence by clicking the button?)(?
between each pair of words.
Since the toolregards segments as too short given the segmentlength 9, it provides the cancel buttons.
And then,the annotator merges some segments by clickingthe third button, the fifth button, and the sixth but-ton of the middle figure.
The bottom figure doesnot include the fourth button of the middle figurebecause a new segment will be longer than thesegment length 9.
When every segment is suit-able, the annotator exclusively clicks the confirmbutton ignoring the cancel buttons.Segmentation Step:Cancellation Step (1):Cancellation Step (2):Figure 2: Sentence Segmentation239Generation Step:Cancellation Step:Reconstruction Step:Figure 3: Tree Annotation for Intra-Structure3.2 Tree Annotation for Intra-StructureThe tree annotation for intra-structure consists ofthree steps: generation step, cancellation step,and reconstruction step.
In the generation step,the parser generates a candidate intra-structure foreach segment of a sentence.
And then, the treeannotation tool shows the annotator the candidateintra-structure.
In the cancellation step, the an-notator can cancel some incorrect constituents inthe candidate intra-structure.
In the reconstruc-tion step, the annotator reconstructs the correctconstituents to complete a correct intra-structure.For example, the tree annotation tool shows thecandidate intra-structure of a segment as shownin the top of Figure 3.
Assuming that thecandidate intra-structure includes two incorrectconstituents, the annotator cancels the incorrectconstituents after checking the candidate intra-structure as represented in the middle figure.
Andthen, the annotator reconstructs the correct con-stituent, and the intra-structure is completed asdescribed in the bottom of Figure 3.3.3 Tree Annotation for Inter-StructureThe tree annotation for inter-structure also con-sists of three steps: generation step, cancella-tion step, and reconstruction step.
In the gen-eration step, the parser generates a candidateinter-structure based on the given correct intra-structures.
And then, the tree annotation toolshows an annotator the candidate syntactic struc-ture which includes both the intra-structures andthe inter-structure.
In the cancellation step, anGeneration Step:Cancellation Step:Reconstruction Step:Figure 4: Tree Annotation for Inter-Structureannotator can cancel incorrect constituents.
Inthe reconstruction step, the annotator reconstructscorrect constituents to complete a correct syntac-tic structure.For example, the tree annotation tool representsthe candidate syntactic structure of a sentence asillustrated in the top of Figure 4.
Assuming thatthe candidate syntactic structure includes two in-correct constituents, the annotator cancels the in-correct constituents, and reconstructs the correctconstituent.
Finally, the intra-structure is com-pleted as described in the bottom of Figure 3.4 ExperimentsIn order to examine how much the proposed treeannotation tool reduces manual effort for build-ing a Korean treebank, it is integrated with aparser (Park et al, 2004), and then it is evaluatedon the test sentences according to the followingcriteria.
The segment length (Length) indicatesthat a segment of a sentence is splitted when it240is longer than the given segment length.
There-fore, the annotator can skip the sentence segmen-tation when a sentence is shorter than the seg-ment length.
The number of segments (#Seg-ments) indicates the number of segments splittedby the annotator.
The number of cancellations(#Cancellations) indicates the number of incor-rect constituents cancelled by the annotator wherethe incorrect constituents are generated by theparser.
The number of reconstructions (#Recon-structions) indicates the number of constituentsreconstructed by the annotator.
Assume that theannotators are so skillful that they do not can-cel their decision unnecessarily.
On the otherhand, the test set includes 3,000 Korean sentenceswhich never have been used for training the parserin a Korean treebank, and the sentences are thepart of the treebank converted from the KAISTlanguage resource (Choi, 2001).
In this section,we analyze the parsing performance and the re-duction effect of manual effort according to seg-ment length for the purpose of finding the bestsegment length to minimize manual effort.4.1 Parsing Performance According toSegment LengthFor the purpose of evaluating the parsing per-formance given the correct segments, we clas-sify the constituents in the syntactic structuresinto the constituents in the intra-structures of seg-ments and the constituents in the inter-structures.Besides, we evaluate each classified constituentsbased on labeled precision, labeled recall, and dis-tribution ratio.
The labeled precision (LP) indi-cates the ratio of correct candidate constituentsfrom candidate constituents generated by theparser, and the labeled recall (LR) indicates theratio of correct candidate constituents from con-stituents in the treebank (Goodman, 1996).
Also,the distribution ratio (Ratio) indicates the distri-bution ratio of constituents in the intra-structuresfrom all of constituents in the original structure.Table 1 shows that the distribution ratio of theconstituents in the intra-structures increases ac-cording to the longer segment length while thedistribution ratio of the constituents in the inter-structures decreases.
Given the segment length 1,the constituents in the inter-structures of a sen-tence are the same as the constituents of the sen-Table 1: Parsing PerformanceIntra-Structure Inter-StructureLength LP LR Ratio LP LR Ratio1 0.00 0.00 0.00 87.62 86.06 100.002 100.00 93.42 52.25 74.45 74.08 47.753 100.00 97.27 66.61 60.63 58.55 33.394 98.93 96.47 74.27 62.11 59.71 25.735 97.68 96.05 79.47 65.30 63.65 20.536 96.50 95.47 83.24 67.88 66.68 16.767 95.45 94.45 86.12 70.84 69.81 13.888 94.34 93.10 88.47 74.24 73.23 11.539 93.41 92.36 90.40 76.85 76.25 9.6010 92.65 91.47 92.01 78.99 78.31 7.9911 91.91 90.65 93.43 81.53 80.72 6.5712 91.19 89.86 94.59 84.39 83.60 5.4113 90.54 89.23 95.62 86.92 85.97 4.3814 89.87 88.61 96.54 88.82 88.19 3.4615 89.34 87.99 97.30 90.39 89.41 2.7016 88.98 87.65 97.97 90.50 89.86 2.0317 88.64 87.27 98.51 91.64 89.61 1.4918 88.37 86.99 98.98 92.92 90.84 1.0219 88.15 86.76 99.34 92.97 91.30 0.6620 87.98 86.57 99.58 92.00 91.62 0.4221 87.83 86.42 99.76 92.73 92.36 0.2422 87.76 86.36 99.83 93.60 93.20 0.1723 87.74 86.36 99.89 94.46 93.81 0.1124 87.69 86.27 99.94 97.67 94.74 0.0625 87.65 86.26 99.97 100.00 95.45 0.0326 87.63 86.24 99.99 100.00 100.00 0.0127 87.63 86.16 99.99 100.00 100.00 0.0128 87.62 86.06 100.00 0.00 0.00 0.00tence because there is no evaluated constituent onintra-structure of one word.
In the same way, theconstituents in the intra-structures of a sentenceare the same as the constituents of the sentencegiven the segment length 28 because all test sen-tences are shorter than 28 words.As described in Table 1, the labeled preci-sion and the labeled recall decrease on the intra-structures according to the longer segment lengthbecause both the parsing complexity and the pars-ing ambiguity increase more and more.
On theother hand, the labeled precision and the labeledrecall tend to increase on the inter-structures sincethe number of constituents in the inter-structuresdecrease, and it makes the parsing problem ofthe inter-structure easy.
It is remarkable that thelabeled precision and the labeled recall get rel-atively high performance on the inter-structuresgiven the segment length less than 2 because itis so easy that the parser generates the syntacticstructure for 3 or 4 words.4.2 Reduction Effect of Manual EffortIn order to examine the reduction effect of manualeffort according to segment length, we measurethe frequency of the annotator?s intervention onthe proposed tool, and also classify the frequencyinto the frequency related to the intra-structureand the frequency related to the inter-structure.241Figure 5: Reduction of Manual EffortAs shown in Figure 5, the total manual effort in-cludes the number of segments splitted by the an-notator, the number of constituents cancelled bythe annotator, and the number of constituents re-constructed by the annotator.Figure 5 shows that too short segments can ag-gravate the total manual effort since the short seg-ments require too excessive segmentation work.According to longer length, the manual effort onthe intra-structures increase because the numberof the constituents increase and the labeled preci-sion and the labeled recall of the parser decrease.On the other hand, the manual effort on the inter-structures decreases according to longer length onaccount of the opposite reasons.
As presented inFigure 5, the total manual effort is reduced best atthe segment length 9.
It describes that the annota-tion?s intervention related to cancellation and re-construction remarkably decrease although it re-quires the annotator to segment some sentences.Also, Figure 5 describes that we hardly expect theeffect of two-phase parsing based on the long seg-ments while the short segments require too exces-sive segmentation work.4.3 Comparison with Other MethodsIn this experiment, we compare the manual effortof the four methods: the manual tree annotationtool (only human), the tree annotation tool usingthe parser (no segmentation), the tree annotationtool using the parser with the clause-based sen-tence segmentation (clause-based segmentation),and the tree annotation tool using the parser withthe length-based sentence segmentation (length-based segmentation) where the segment length is9 words.As shown in Figure 6, the first method (onlyFigure 6: Comparison with Other Modelshuman) does not need any manual effort relatedto segmentation and cancellation but it requirestoo expensive reconstruction cost.
The secondmethod (no segmentation) requires manual effortrelated to cancellation and reconstruction withoutsegmentation.
As compared with the first method,the rest three methods using the parser can re-duce manual effort by roughly 50% although theparser generates some incorrect constituents.
Fur-thermore, the experimental results of the third andfourth methods shows that the two-phase parsingmethods with sentence segmentation can reducemanual effort more about 9.4% and 24.5% eachas compared with the second method.Now, we compare the third method (clause-based segmentation) and the fourth method(length-based segmentation) in more detail.
Asrepresented in Figure 6, the third method is some-what better than the fourth method on manual ef-fort related to intra-structure.
It show that theparser generates more correct constituents giventhe clause-based segments because the intra-structure of the clause-based segments is moreformalized than the intra-structure of the length-based segments.
However, the third methodis remarkably worse than the fourth method onmanual effort related to inter-structure.
It de-scribes that the third method can split a short sen-tence into shorter segments unnecessarily sincethe third method allows the segment length coversa wide range.
As already described in Figure 5,too short segments can aggravate the manual ef-fort.
Finally, the experimental results shows thatthe length-based segments help the tree annota-tion tool to reduce manual effort rather than theclause-based segments.2425 ConclusionIn this paper, we propose the tree annotation toolwhich performs two-phase parsing for the intra-structure of each segment and the inter-structureafter segmenting a sentence.
The proposed treeannotation tool has the following characteristics.First, it can reduce manual effort to build a tree-bank.
Experimental results show that it can im-prove approximately 60.0% and 24.5% as com-pared with the manual tree annotation tool andthe tree annotation tool using one phase parsing.Second, it can prevent the initial syntactic errorsof a word or a phrase from propagating to thewhole syntactic structure without any modifica-tion of the parser because it takes sentence seg-mentation.
Third, it can shift the responsibility ofextracting the reliable syntactic rules to the parser.For future works, we will try to develop an auto-matic segmentation method to minimize manualeffort.AcknowledgementsThis work was supported by Ministry of Educa-tion and Human Resources Development throughEmbedded Software Open Education ResourceCenter(ESC) at Sangmyung University.ReferencesByung-Gyu Chang, Kong Joo Lee, Gil Chang Kim.1997.
Design and Implementation of Tree TaggingWorkbench to Build a Large Tree Tagged Corpusof Korean.
In Proceedings of Hangul and KoreanInformation Processing Conference, 421-429.Ki-Sun Choi.
2001.
?KAIST Language Resourcesver.
2001.?
The Result of Core SoftwareProject from Ministry of Science and Technology,http://kibs.kaist.ac.kr.
(written in Korean)Shinchi Doi, Kazunori Muraki, Shinichiro Kamei andKiyoshi Yamabana.
1993.
Long sentence analysisby domain-specific pattern grammar.
In Proceed-ings of the 6th Conference on the European Chap-ter of the Association of Computational Linguistics,466.Joshua Goodman.
1996.
Parsing Algorithms and Met-rics.
In Proceedings of the Annual Meeting of theAssociation for Computational Linguistics, pp.177?183.Donald Hindle.
1989.
Acquiring disambiguation rulesfrom text.
In Proceedings of the Annual Meeting ofthe Association for Computational Linguistics, 118-125.Sungdong Kim, Byungtak Zhang and Yungtaek Kim.2000.
Reducing Parsing Complexity by Intra-Sentence Segmentation based on Maximum En-tropy Model.
In Proceedings of the Joint SIGDATConference on Empirical Methods in Natural Lan-guage Processing and Very Large Corpora, 164-171.Ui-Su Kim, and Beom-Mo Kang.
2002.
Principles,Methods and Some Problems in Compiling a Ko-rean Treebank.
In Proceedings of Hangul andKorean Information Processing Conference 1997.155-162.Yong-Jae Kwak, Young-Sook Hwang, Hoo-JungChung, So-Young Park, Hae-Chang Rim.
2001.FIDELITY: A Framework for Context-SensitiveGrammar Development.
In Proceedings of Interna-tional Conference on Computer Processing of Ori-ental Languages, 305-308.Kong Joo Lee, Byung-Gyu Chang, Gil Chang Kim.1997.
Bracketing Guidlines for Korean Syntac-tic Tree Tagged Corpus Version 1.
Technical Re-port CS/TR-976-112, KAIST, Dept.
of ComputerScience.Wei-Chuan Li, Tzusheng Pei, Bing-Huang Lee andChuei-Feng Chiou.
1990.
Parsing long English sen-tences with pattern rules.
In Proceedings of the13th International Conference on ComputationalLinguistics, 410-412.Joon-Ho Lim, So-Young Park, Yong-Jae Kwak, andHae-Chang Rim.
2004.
A Semi-automatic TreeAnnotating Workbench for Building a KoreanTreebank.
Lecture Note in Computer Science,2945:253-257.Caroline Lyon and Bob Dickerson.
1997.
Reducingthe Complexity of Parsing by a Method of Decom-position.
In International Workshop on ParsingTechnology.Mitchell P. Marcus, Beatrice Santorini, and Mary AnnMarcinkiewicz.
Building a Large Annotated Cor-pus of English: the Penn Treebank.
ComputationalLinguistics, 19(2):313-330.So-Young Park, Yong-Jae Kwak, Joon-Ho Lim, Hae-Chang Rim, and Soo-Hong Kim.
2004.
PartiallyLexicalized Parsing Model Utilizing Rich Features.In Proceedings of the 8th International Conferenceon Spoken Language Processing, 3:2201-2204.Erik F. Tjong Kim Sang and Herve Dejean.
2001.
In-troduction to the CoNLL-2001 Shared Task: ClauseIdenti-fication.
In Proceedings of the Conferenceon Natural Language Learning, 53-57.243
