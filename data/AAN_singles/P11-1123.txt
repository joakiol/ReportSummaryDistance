Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 1230?1238,Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational LinguisticsA Statistical Tree Annotator and Its ApplicationsXiaoqiang Luo and Bing ZhaoIBM T.J. Watson Research Center1101 Kitchawan RoadYorktown Heights, NY 10598{xiaoluo,zhaob}@us.ibm.comAbstractIn many natural language applications, thereis a need to enrich syntactical parse trees.
Wepresent a statistical tree annotator augmentingnodes with additional information.
The anno-tator is generic and can be applied to a va-riety of applications.
We report 3 such ap-plications in this paper: predicting functiontags; predicting null elements; and predictingwhether a tree constituent is projectable in ma-chine translation.
Our function tag predictionsystem outperforms significantly published re-sults.1 IntroductionSyntactic parsing has made tremendous progress inthe past 2 decades (Magerman, 1994; Ratnaparkhi,1997; Collins, 1997; Charniak, 2000; Klein andManning, 2003; Carreras et al, 2008), and accu-rate syntactic parsing is often assumed when devel-oping other natural language applications.
On theother hand, there are plenty of language applicationswhere basic syntactic information is insufficient.
Forinstance, in question answering, it is highly desir-able to have the semantic information of a syntacticconstituent, e.g., a noun-phrase (NP) is a person oran organization; an adverbial phrase is locative ortemporal.
As syntactic information has been widelyused in machine translation systems (Yamada andKnight, 2001; Xiong et al, 2010; Shen et al, 2008;Chiang, 2010; Shen et al, 2010), an interestingquestion is to predict whether or not a syntactic con-stituent is projectable1 across a language pair.1A constituent in the source language is projectable if it canbe aligned to a contiguous span in the target language.Such problems can be abstracted as adding addi-tional annotations to an existing tree structure.
Forexample, the English Penn treebank (Marcus et al,1993) contains function tags and many carry seman-tic information.
To add semantic information to thebasic syntactic trees, a logical step is to predict thesefunction tags after syntactic parsing.
For the prob-lem of predicting projectable syntactic constituent,one can use a sentence alignment tool and syntac-tic trees on source sentences to create training databy annotating a tree node as projectable or not.
Ageneric tree annotator can also open the door of solv-ing other natural language problems so long as theproblem can be cast as annotating tree nodes.
Asone such example, we will present how to predictempty elements for the Chinese language.Some of the above-mentioned problems havebeen studied before: predicting function tags werestudied in (Blaheta and Charniak, 2000; Blaheta,2003; Lintean and Rus, 2007a), and results of pre-dicting and recovering empty elements can be foundin (Dienes et al, 2003; Schmid, 2006; Campbell,2004).
In this work, we will show that these seem-ingly unrelated problems can be treated uniformlyas adding annotations to an existing tree structure,which is the first goal of this work.
Second, theproposed generic tree annotator can also be usedto solve new problems: we will show how it canbe used to predict projectable syntactic constituents.Third, the uniform treatment not only simplifies themodel building process, but also affords us to con-centrate on discovering most useful features for aparticular application which often leads to improvedperformances, e.g, we find some features are veryeffective in predicting function tags and our system1230has significant lower error rate than (Blaheta andCharniak, 2000; Lintean and Rus, 2007a).The rest of the paper is organized as follows.
Sec-tion 2 describes our tree annotator, which is a con-ditional log-linear model.
Section 3 describes thefeatures used in our system.
Next, three applicationsof the proposed tree annotator are presented in Sec-tion 4: predicting English function tags, predictingChinese empty elements and predicting Arabic pro-jectable constituents.
Section 5 compares our workwith some related prior arts.2 A MaxEnt Tree Annotator ModelThe input to the tree annotator is a tree T .
WhileT can be of any type, we concentrate on the syntac-tic parse tree in this paper.
The non-terminal nodes,N = {n : n ?
T} of T are associated with anorder by which they are visited so that they can beindexed as n1, n2, ?
?
?
, n|T |, where |T | is the num-ber of non-terminal nodes in T .
As an example,Figure 1 shows a syntactic parse tree with the pre-fix order (i.e., the number at the up-right corner ofeach non-terminal node), where child nodes are vis-ited recursively from left to right before the parentnode is visited.
Thus, the NP-SBJ node is visitedfirst, followed by the NP spanning duo action,followed by the PP-CLR node etc.With a prescribed tree visit order, our tree annota-tor model predicts a symbol li, where li takes valuefrom a predefined finite set L, for each non-terminalnode ni in a sequential fashion:P (l1, ?
?
?
, l|T ||T )=|T |?i=1P (li|l1, ?
?
?
, li?1, T ) (1)The visit order is important since it determines whatare in the conditioning of Eq.
(1).P (li|l1, ?
?
?
, li?1, T ) in this work is a conditionallog linear (or MaxEnt) model (Berger et al, 1996):P (li|l1, ?
?
?
, li?1, T )= exp(?k ?kgk(li?11 , T, li))Z(li?11 , T )(2)whereZ(li?11 , T ) =?x?Lexp(?k?kgk(li?11 , T, x))3VBZ TO NN NNJJNewsnight     returns        to           duo       action       tonightNPVPSNP?TMP2456NP?SBJ1PP?CLRNNPFigure 1: A sample tree: the number on the upright cornerof each non-terminal node is the visit order.is the normalizing factor to ensure thatP (li|l1, ?
?
?
, li?1, T ) in Equation (2) is a prob-ability and {gk(li?11 , T, li)} are feature functions.There are efficient training algorithms to find op-timal weights relative to a labeled training data setonce the feature functions {gk(li?11 , T, li)} are se-lected (Berger et al, 1996; Goodman, 2002; Malouf,2002).
In our work, we use the SCGIS training al-gorithm (Goodman, 2002), and the features used inour systems are detailed in the next section.Once a model is trained, at testing time it is ap-plied to input tree nodes by the same order.
Figure 1highlights the prediction of the function tag for node3(i.e., PP-CLR-node in the thickened box) after 2shaded nodes (NP-SBJ node and NP node) are pre-dicted.
Note that by this time the predicted valuesare available to the system, while unvisited nodes(nodes in dashed boxes in Figure 1) can not providesuch information.3 FeaturesThe features used in our systems are tabulated in Ta-ble 1.
Numbers in the first column are the feature in-dices.
The second column contains a brief descrip-tion of each feature, and the third column containsthe feature value when the feature at the same rowis applied to the PP-node of Figure 1 for the task ofpredicting function tags.Feature 1 through 8 are non-lexical features in thatall of them are computed based on the labels or POStags of neighboring nodes (e.g., Feature 4 computesthe label or POS tag of the right most child), or thestructure information (e.g., Feature 5 computes thenumber of child nodes).1231Feature 9 and 10 are computed from past pre-dicted values.
When predicting the function tag forthe PP-node in Figure 1, there is no predicted valuefor its left-sibling and any of its child node.
That?swhy both feature values are NONE, a special sym-bol signifying that a node does not carry any func-tion tag.
If we were to predict the function tag forthe VP-node, the value of Feature 9 would be SBJ,while Feature 10 will be instantiated twice with onevalue being CLR, another being TMP.No.
Description Value1 current node label PP2 parent node label VP3 left-most child label/tag TO4 right-most child label/tag NP5 number of child nodes 26 CFG rule PP->TO NP7 label/tag of left sibling VBZ8 label/tag of right sibling NP9 predicted value of left-sibling NONE10 predicted value of child nodes NONE11 left-most internal word to12 right-most internal word action13 left neighboring external word returns14 right neighboring external word tonight15 head word of current node to16 head word of parent node returns17 is current node the head child false18 label/tag of head child TO19 predicted value of the head child NONETable 1: Feature functions: the 2nd column contains thedescriptions of each feature, and the 3rd column the fea-ture value when it is applied to the PP-node in Figure 1.Feature 11 to 19 are lexical features or computedfrom head nodes.
Feature 11 and 12 compute thenode-internal boundary words, while Feature 13 and14 compute the immediate node-external boundarywords.
Feature 15 to 19 rely on the head informa-tion.
For instance, Feature 15 computes the headword of the current node, which is to for the PP-node in Figure 1.
Feature 16 computes the same forthe parent node.
Feature 17 tests if the current nodeis the head of its parent.
Feature 18 and 19 computethe label or POS tag and the predicted value of thehead child, respectively.Besides the basic feature presented in Table 1, wealso use conjunction features.
For instance, applyingthe conjunction of Feature 1 and 18 to the PP-nodein Figure 1 would yield a feature instance that cap-tures the fact that the current node is a PP node andits head child?s POS tag is TO.4 Applications and ResultsA wide variety of language problems can be treatedas or cast into a tree annotating problem.
In thissection, we present three applications of the statisti-cal tree annotator.
The first application is to predictfunction tags of an input syntactic parse tree; the sec-ond one is to predict Chinese empty elements; andthe third one is to predict whether a syntactic con-stituent of a source sentence is projectable, meaningif the constituent will have a contiguous translationon the target language.4.1 Predicting Function TagsIn the English Penn Treebank (Marcus et al, 1993)and more recent OntoNotes data (Hovy et al,2006), some tree nodes are assigned a function tag,which is of one of the four types: grammatical,form/function, topicalization and miscellaneous.
Ta-ble 2 contains a list of function tags used in theEnglish Penn Treebank (Bies et al, 1995).
The?Grammatical?
row contains function tags markingthe grammatical role of a constituent, e.g., DTV fordative objects, LGS for logical subjects etc.
Manytags in the ?Form/function?
row carry semantic in-formation, e.g., LOC is for locative expressions, andTMP for temporal expressions.Type Function TagsGrammatical (52.2%) DTV LGS PRDPUT SBJ VOCForm/function (36.2%) ADV BNF DIREXT LOC MNRNOM PRP TMPTopicalization (2.2%) TPCMiscellaneous (9.4%) CLF CLR HLN TTLTable 2: Four types of function tags and their relativefrequency4.1.1 Comparison with Prior ArtsIn order to have a direct comparison with (Blahetaand Charniak, 2000; Lintean and Rus, 2007a), weuse the same English Penn Treebank (Marcus et al,1993) and partition the data set identically: Section12322-21 of Wall Street Journal (WSJ) data for trainingand Section 23 as the test set.
We use all features inTable 1 and build four models, each of which pre-dicting one type of function tags.
The results aretabulated in Table 3.As can be seen, our system performs much betterthan both (Blaheta and Charniak, 2000) and (Lin-tean and Rus, 2007a).
For two major categories,namely grammatical and form/function which ac-count for 96.84% non-null function tags in the testset, our system achieves a relative error reduction of77.1% (from (Blaheta and Charniak, 2000)?s 1.09%to 0.25%) and 46.9%(from (Blaheta and Charniak,2000)?s 2.90% to 1.54%) , respectively.
The per-formance improvements result from a clean learn-ing framework and some new features we intro-duced: e.g., the node-external features, i.e., Feature13 and 14 in Table 1, can capture long-range statis-tical dependencies in the conditional model (2) andare proved very useful (cf.
Section 4.1.2).
As far aswe can tell, they are not used in previous work.Type Blaheta00 Lintean07 OursGrammar 98.91% 98.45% 99.75%Form/Func 97.10% 95.15% 98.46%topic 99.92% 99.87% 99.98%Misc 98.65% 98.54% 99.41%Table 3: Function tag prediction accuracies on gold parsetrees: breakdown by types of function tags.
The 2nd col-umn is due to (Blaheta and Charniak, 2000) and 3rd col-umn due to (Lintean and Rus, 2007a).
Our results on the4th column compare favorably with theirs.4.1.2 Relative Contributions of FeaturesSince the English WSJ data set contains newswiretext, the most recent OntoNotes (Hovy et al, 2006)contains text from a more diversified genres suchas broadcast news and broadcast conversation, wedecide to test our system on this data set as well.WSJ Section 24 is used for development and Sec-tion 23 for test, and the rest is used as the trainingdata.
Note that some WSJ files were not included inthe OntoNotes release and Section 23 in OntoNotescontains only 1640 sentences.
The OntoNotes datastatistics is tabulated in Table 4.
Less than 2% ofnodes with non-empty function tags were assignedmultiple function tags.
To simplify the system build-ing, we take the first tag in training and testing andreport the aggregated accuracy only in this section.#-sents #-nodes #-funcNodestraining 71,186 1,242,747 280,755test 1,640 31,117 6,778Table 4: Statistics of OntoNotes: #-sents ?
numberof sentences; #-nodes ?
number of non-terminal nodes;#-funcNodes ?
number of nodes containing non-emptyfunction tags.We use this data set to test relative contributionsof different feature groups by incrementally addingfeatures into the system, and the results are reportedin Table 5.
The dummy baseline is predicting themost likely prior ?
the empty function tag, whichindicates that there are 78.21% of nodes without afunction tag.
The next line reflects the performanceof a system with non-lexical features only (Feature1 to 8 in Table 1), and the result is fairly poor withan accuracy 91.51%.
The past predictions (Feature8 and 9) helps a bit by improving the accuracy to92.04%.
Node internal lexical features (Feature 11and 12) are extremely useful: it added more than 3points to the accuracy.
So does the node external lex-ical features (Feature 13 and 14) which added an ad-ditional 1.52 points.
Features computed from headwords (Feature 15 to 19) carry information comple-mentary to the lexical features and it helps quite abit by improving the accuracy by 0.64%.
When allfeatures are used, the system reached an accuracy of97.34%.From these results, we can conclude that, unlikesyntactic parsing (Bikel, 2004), lexical informationis extremely important for predicting and recover-ing function tags.
This is not surprising since manyfunction tags carry semantic information, and moreoften than not, the ambiguity can only be resolvedby lexical information.
E.g., whether a PP is locativeor temporal PP is heavily influenced by the lexicalchoice of the NP argument.4.2 Predicting Chinese Empty ElementsAs is well known, Chinese is a pro-drop language.This and its lack of subordinate conjunction com-plementizers lead to the ubiquitous use of empty el-ements in the Chinese treebank (Xue et al, 2005).Predicting or recovering these empty elements istherefore important for the Chinese language pro-1233Feature Set Accuracyprior (guess NONE) 78.21%Non-lexical labels only 91.52%+past prediction 92.04%+node-internal lexical 95.17%+node-external lexical 96.70%+head word 97.34%Table 5: Effects of feature sets: the second row containsthe baseline result when always predicting NONE; Row 3through 8 contain results by incrementally adding featuresets.cessing.
Recently, Chung and Gildea (2010) hasfound it useful to recover empty elements in ma-chine translation.Since empty elements do not have any surfacestring representation, we tackle the problem by at-taching a pseudo function tag to an empty element?slowest non-empty parent and then removing the sub-tree spanning it.
Figure 2 contains an exampletree before and after removing the empty element*pro* and annotating the non-empty parent witha pseudo function tag NoneL.
The transformationprocedure is summarized in Algorithm 1.In particular, line 2 of Algorithm 1 find the lowestparent of an empty element that spans at least onenon-trace word.
In the example in Figure 2, it wouldfind the top IP-node.
Since *pro* is the left-mostchild, line 4 of Algorithm 1 adds the pseudo functiontag NoneL to the top IP-node.
Line 9 then removesits NP child node and all lower children (i.e., shadedsubtree in Figure 2(1)), resulting in the tree in Fig-ure 2(2).Line 4 to 8 of Algorithm 1 indicate that there are3 types of pseudo function tags: NoneL, NoneM,and NoneR, encoding a trace found in the left, mid-dle or right position of its lowest non-empty parent.It?s trivial to recover a trace?s position in a sentencefrom NoneL, and NoneR, but it may be ambiguousfor NoneM.
The problem could be solved either us-ing heuristics to determine the position of a middleempty element, or encoding the positional informa-tion in the pseudo function tag.
Since here we justwant to show that predicting empty elements can becast as a tree annotation problem, we leave this op-tion to future research.With this transform, the problem of predictinga trace is cast into predicting the correspondingJJNN NNNNNPNPVPVP(1) Original tree with a trace (the left?most child of the top IP?node)NPNPVPVPNN NN NNAD VE JJ VVIPIP?NoneLran2hou4  you3  zhuan3men2  dui4wu3  jin4xing2  jian1du1  jian3cha2(2) After removing trace and its parent node (shaded subtree in (1))NPNONE ADIPIPVVVE*pro*    ran2hou4  you3  zhuan3men2  dui4wu3  jin4xing2  jian1du1  jian3cha2Figure 2: Transform of traces in a Chinese parse tree byadding pseudo function tags.Algorithm 1 Procedure to remove empty elementsand add pseudo function tags.Input: An input treeOutput: a tree after removing traces (and theirempty parents) and adding pseudo function tags toits lowest non-empty parent node1:Foreach trace t2: Find its lowest ancestor node p spanning at leastone non-trace word3: if t is p?s left-most child4: add pseudo tag NoneL to p5: else if t is p?s right-most child6: add pseudo tag NoneR to p7: else8: add pseudo tag NoneM to p9: Remove p?s child spanning the trace t and all itschildren1234pseudo function tag and the statistical tree annota-tor can thus be used to solve this problem.4.2.1 ResultsWe use Chinese Treebank v6.0 (Xue et al, 2005)and the broadcast conversation data from CTBv7.0 2.
The data set is partitioned into training, de-velopment and blind test as shown in Table 6.
Thepartition is created so that different genres are wellrepresented in different subsets.
The training, de-velopment and test set have 32925, 3297 and 3033sentences, respectively.Subset File IDsTraining0001-0325, 0400-0454, 0600-08400500-0542, 2000-3000, 0590-05961001-1120, cctv,cnn,msnbc, phoenix 00-06Dev 0841-0885, 0543-0548, 3001-30751121-1135, phoenix 07-09Test 0900-0931,0549-0554, 3076-31451136-1151, phoenix 10-11Table 6: Data partition for CTB6 and CTB 7?s broadcastconversation portionWe then apply Algorithm 1 to transform trees andpredict pseudo function tags.
Out of 1,100,506 non-terminal nodes in the training data, 80,212 of themcontain pseudo function tags.
There are 94 nodescontaining 2 pseudo function tags.
The vast major-ity of pseudo tags ?
more then 99.7% ?
are attachedto either IP, CP, or VP: 50971, 20113, 8900, respec-tively.We used all features in Table 1 and achieved anaccuracy of 99.70% on the development data, and99.71% on the test data on gold trees.To understand why the accuracies are so high, welook into the 5 most frequent labels carrying pseudotags in the development set, and tabulate their per-formance in Table 7.
The 2nd column contains thenumber of nodes in the reference; the 3rd column thenumber of nodes of system output; the 4th columnthe number of nodes with correct prediction; and the5th column F-measure for each label.From Table 7, it is clear that CP-NoneL andIP-NoneL are easy to predict.
This is not sur-prising, given that the Chinese language lacks of2Many files are missing in LDC?s early 2010 release of CTB7.0, but broadcast conversation portion is new and is used in oursystem.Label numRef numSys numCorr F1CP-NoneL 1723 1724 1715 0.995IP-NoneL 3874 3875 3844 0.992VP-NoneR 660 633 597 0.923IP-NoneM 440 432 408 0.936VP-NoneL 135 107 105 0.868Table 7: 5 most frequent labels carrying pseudo tags andtheir performancescomplementizers for subordinate clauses.
In otherwords, left-most empty elements under CP are al-most unambiguous: if a CP node has an immediateIP child, it almost always has a left-most empty el-ement; similarly, if an IP node has a VP node asthe left-most child (i.e., without a subject), it almostalways should have a left empty element (e.g., mark-ing the dropped pro).
Another way to interpret theseresults is as follows: when developing the Chinesetreebank, there is really no point to annotate left-most traces for CP and IP when tree structures areavailable.On the other hand, predicting the left-most emptyelements for VP is a lot harder: the F-measure isonly 86.8% for VP-NoneL.
Predicting the right-most empty elements under VP and middle emptyelements under IP is somewhat easier: VP-NoneRand IP-NoneM?s F-measures are 92.3% and 93.6%,respectively.4.3 Predicting Projectable ConstituentsThe third application is predicting projectable con-stituents for machine translation.
State-of-the-artmachine translation systems (Yamada and Knight,2001; Xiong et al, 2010; Shen et al, 2008; Chi-ang, 2010; Shen et al, 2010) rely heavily on syn-tactic analysis.
Projectable structures are impor-tant in that it is assumed in CFG-style translationrules that a source span can be translated contigu-ously.
Clearly, not all source constituents can betranslated this way, but if we can predict whethera non-terminal source node is projectable, we canavoid translation errors by bypassing or discourag-ing the derivation paths relying on non-projectableconstituents, or using phrase-based approaches fornon-projectable constituents.We start from LDC?s bilingual Arabic-Englishtreebank with source human parse trees and align-ments, and mark source constituents as either pro-1235NOUNb# sbb ""l# Alms&wlthe Iraqi official ?s sudden obligations ".tAr}pAltzAmAtPREPBecause of "NOUNSPP#NP#1NP#2NPPPNPAlErAqy .PUNC PREP DET+NOUN DET+ADJADJ PUNCPUNCFigure 3: An example to show how a source tree is annotated with its alignment with the target sentence.jectable or non-projectable.
The binary annotationscan again be treated as pseudo function tags and theproposed tree annotator can be readily applied to thisproblem.As an example, the top half of Figure 3 con-tains an Arabic sentence with its parse tree; the bot-tom is its English translation with the human word-alignment.
There are three non-projectable con-stituents marked with ?#?
: the top PP# spanningthe whole sentence except the final stop, and NP#1and NP#2.
The PP# node is not projectable dueto an inserted stop from outside; NP#1 is not pro-jectable because it is involved in a 2-to-2 alignmentwith the token b# outside NP#1; NP#2 is alignedto a span the Iraqi official ?s suddenobligations ., in which Iraqi officialbreaks the contiguity of the translation.
It is clearthat a CFG-like grammar will not be able to gener-ate the translation for NP#2.The LDC?s Arabic-English bilingual treebankdoes not mark if a source node is projectable ornot, but the information can be computed from wordalignment.
In our experiments, we processed 16,125sentence pairs with human source trees for training,and 1,151 sentence pairs for testing.
The statisticsof the training and test data can be found in Table 8,where the number of sentences, the number of non-terminal nodes and the number of non-projectablenodes are listed in Column 2 through 4, respectively.Data Set #Sents #nodes #NonProjTraining 16,125 558,365 121,201Test 1,151 40,674 8,671Table 8: Statistics of the data for predicting projectableconstituentsWe get a 94.6% accuracy for predicting pro-jectable constituents on the gold trees, and an 84.7%F-measure on the machine-generated parse trees.This component has been integrated into our ma-chine translation system (Zhao et al, 2011).5 Related WorkBlaheta and Charniak (2000) used a feature treemodel to predict function tags.
The work waslater extended to use the voted perceptron (Blaheta,2003).
There are considerable overlap in terms offeatures used in (Blaheta and Charniak, 2000; Bla-heta, 2003) and our system: for example, the label ofcurrent node, parent node and sibling nodes.
How-ever, there are some features that are unique in ourwork, e.g., lexical features at a constituent bound-aries (node-internal and node-external words).
Table2 of (Blaheta and Charniak, 2000) contains the ac-1236curacies for 4 types of function tags, and our resultsin Table 3 compare favorably with those in (Blahetaand Charniak, 2000).
Lintean and Rus (2007a; Lin-tean and Rus (2007b) also studied the function tag-ging problem and applied naive Bayes and decisiontree to it.
Their accuracy results are worse than(Blaheta and Charniak, 2000).
Neither (Blaheta andCharniak, 2000) nor (Lintean and Rus, 2007a; Lin-tean and Rus, 2007b) reported the relative usefulnessof different features, while we found that the lexicalfeatures are extremely useful.Campbell (2004) and Schmid (2006) studied theproblem of predicting and recovering empty cate-gories, but they used very different approaches: in(Campbell, 2004), a rule-based approach is usedwhile (Schmid, 2006) used a non-lexical PCFG sim-ilar to (Klein and Manning, 2003).
Chung andGildea (2010) studied the effects of empty cate-gories on machine translation and they found thateven with noisy machine predictions, empty cate-gories still helped machine translation.
In this paper,we showed that empty categories can be encoded aspseudo function tags and thus predicting and recov-ering empty categories can be cast as a tree anno-tating problem.
Our results also shed light on someempty categories can almost be determined unam-biguously, given a gold tree structure, which sug-gests that these empty elements do not need to beannotated.Gabbard et al (2006) modified Collins?
parser tooutput function tags.
Since their results for predict-ing function tags are on system parses, they are notcomparable with ours.
(Gabbard et al, 2006) alsocontains a second stage employing multiple clas-sifiers to recover empty categories and resolve co-indexations between an empty element and its an-tecedent.As for predicting projectable constituent, it is re-lated to the work described in (Xiong et al, 2010),where they were predicting translation boundaries.A major difference is that (Xiong et al, 2010) de-fines projectable spans on a left-branching deriva-tion tree solely for their phrase decoder and models,while translation boundaries in our work are definedfrom source parse trees.
Our work uses more re-sources, but the prediction accuracy is higher (mod-ulated on a different test data): we get a F-measure84.7%, in contrast with (Xiong et al, 2010)?s 71%.6 Conclusions and Future WorkWe proposed a generic statistical tree annotator inthe paper.
We have shown that a variety of naturallanguage problems can be tackled with the proposedtree annotator, from predicting function tags, pre-dicting empty categories, to predicting projectablesyntactic constituents for machine translation.
Ourresults of predicting function tags compare favor-ably with published results on the same data set, pos-sibly due to new features employed in the system.We showed that empty categories can be representedas pseudo function tags, and thus predicting emptycategories can be solved with the proposed tree an-notator.
The same technique can be used to predictprojectable syntactic constituents for machine trans-lation.There are several directions to expand the workdescribed in this paper.
First, the results for predict-ing function tags and Chinese empty elements wereobtained on human-annotated trees and it would beinteresting to do it on parse trees generated by sys-tem.
Second, predicting projectable constituents isfor improving machine translation and we are inte-grating the component into a syntax-based machinetranslation system.AcknowledgmentsThis work was partially supported by the DefenseAdvanced Research Projects Agency under contractNo.
HR0011-08-C-0110.
The views and findingscontained in this material are those of the authorsand do not necessarily reflect the position or policyof the U.S. government and no official endorsementshould be inferred.We are also grateful to three anonymous reviewersfor their suggestions and comments for improvingthe paper.ReferencesAdam L. Berger, Stephen A. Della Pietra, and VincentJ.
Della Pietra.
1996.
A maximum entropy approachto natural language processing.
Computational Lin-guistics, 22(1):39?71, March.Ann Bies, Mark Ferguson, and karen Katz.
1995.
Brack-eting guidelines for treebank II-style penn treebankproject.
Technical report, Linguistic Data Consortium.Daniel M. Bikel.
2004.
A distributional analysis of alexicalized statistical parsing model.
In Dekang Lin1237and Dekai Wu, editors, Proceedings of EMNLP 2004,pages 182?189, Barcelona, Spain, July.
Associationfor Computational Linguistics.Don Blaheta and Eugene Charniak.
2000.
Assigningfunction tags to parsed text.
In Proceedings of the 1stMeeting of the North American Chapter of the Associ-ation for Computational Linguistics, pages 234?240.Don Blaheta.
2003.
Function Tagging.
Ph.D. thesis,Brown University.Richard Campbell.
2004.
Using linguistic principlesto recover empty categories.
In Proceedings of the42nd Meeting of the Association for ComputationalLinguistics (ACL?04), Main Volume, pages 645?652,Barcelona, Spain, July.Xavier Carreras, Michael Collins, and Terry Koo.
2008.TAG, dynamic programming, and the perceptron forefficient, feature-rich parsing.
In Proceedings ofCoNLL.E.
Charniak.
2000.
A maximum-entropy-inspired parser.In Proceedings of NAACL, Seattle.David Chiang.
2010.
Learning to translate with sourceand target syntax.
In Proc.
ACL, pages 1443?1452.Tagyoung Chung and Daniel Gildea.
2010.
Effects ofempty categories on machine translation.
In Proceed-ings of the 2010 Conference on Empirical Methods inNatural Language Processing, pages 636?645, Cam-bridge, MA, October.
Association for ComputationalLinguistics.Michael Collins.
1997.
Three generative, lexicalisedmodels for statistical parsing.
In Proc.
Annual Meet-ing of ACL, pages 16?23.Peter Dienes, P Eter Dienes, and Amit Dubey.
2003.
An-tecedent recovery: Experiments with a trace tagger.
InIn Proceedings of the Conference on Empirical Meth-ods in Natural Language Processing, pages 33?40.Ryan Gabbard, Mitchell Marcus, and Seth Kulick.
2006.Fully parsing the Penn Treebank.
In Proceedings ofHuman Language Technology Conference of the NorthAmer- ican Chapter of the Association of Computa-tional Linguistics.Joshua Goodman.
2002.
Sequential conditional general-ized iterative scaling.
In Pro.
of the 40th ACL.Eduard Hovy, Mitchell Marcus, Martha Palmer, LanceRamshaw, and Ralph Weischedel.
2006.
Ontonotes:The 90% solution.
In Proceedings of the Human Lan-guage Technology Conference of the NAACL, Com-panion Volume: Short Papers, pages 57?60, New YorkCity, USA, June.
Association for Computational Lin-guistics.Dan Klein and Christopher D. Manning.
2003.
Accu-rate unlexicalized parsing.
In Erhard Hinrichs and DanRoth, editors, Proceedings of the 41st Annual Meet-ing of the Association for Computational Linguistics,pages 423?430.Mihai Lintean and V. Rus.
2007a.
Large scale exper-iments with function tagging.
In Proceedings of theInternational Conference on Knowledge Engineering,pages 1?7.Mihai Lintean and V. Rus.
2007b.
Naive Bayes and deci-sion trees for function tagging.
In Proceedings of theInternational Conference of the FLAIRS-2007.David M. Magerman.
1994.
Natural Language ParsingAs Statistical Pattern Recognition.
Ph.D. thesis, Stan-ford University.Robert Malouf.
2002.
A comparison of algorithms formaximum entropy parameter estimation.
In the SixthConference on Natural Language Learning (CoNLL-2002), pages 49?55.M.
Marcus, B. Santorini, and M. Marcinkiewicz.
1993.Building a large annotated corpus of English: the Penntreebank.
Computational Linguistics, 19(2):313?330.Adwait Ratnaparkhi.
1997.
A Linear Observed TimeStatistical Parser Based on Maximum Entropy Mod-els.
In Second Conference on Empirical Methods inNatural Language Processing, pages 1 ?
10.Helmut Schmid.
2006.
Trace prediction and recov-ery with unlexicalized PCFGs and slash features.
InProceedings of the 21st International Conference onComputational Linguistics and 44th Annual Meet-ing of the Association for Computational Linguistics,pages 177?184, Sydney, Australia, July.
Associationfor Computational Linguistics.Libin Shen, Jinxi Xu, and Ralph Weischedel.
2008.
Anew string-to-dependency machine translation algo-rithm with a target dependency language model.
InProceedings of ACL.Libin Shen, Bing Zhang, Spyros Matsoukas, Jinxi Xu,and Ralph Weischedel.
2010.
Statistical machinetranslation with a factorized grammar.
In Proceedingsof the 2010 Conference on Empirical Methods in Natu-ral Language Processing, pages 616?625, Cambridge,MA, October.
Association for Computational Linguis-tics.Deyi Xiong, Min Zhang, and Haizhou Li.
2010.
Learn-ing translation boundaries for phrase-based decoding.In NAACL-HLT 2010.Nianwen Xue, Fei Xia, Fu-Dong Chiou, and MarthaPalmer.
2005.
The Penn Chinese TreeBank: Phrasestructure annotation of a large corpus.
Natural Lan-guage Engineering, 11(2):207?238.Kenji Yamada and Kevin Knight.
2001.
A syntax-basedstatistical translation model.
In Proc.
Annual Meetingof the Association for Computational Linguistics.Bing Zhao, , Young-Suk Lee, Xiaoqiang Luo, and LiuLi.
2011.
Learning to transform and select elementarytrees for improved syntax-based machine translations.In Proc.
of ACL.1238
