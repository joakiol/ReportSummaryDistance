Proceedings of the 2010 Named Entities Workshop, ACL 2010, pages 29?38,Uppsala, Sweden, 16 July 2010. c?2010 Association for Computational LinguisticsWhitepaper of NEWS 2010 Shared Task onTransliteration MiningA Kumaran Mitesh M. Khapra Haizhou LiMicrosoft Research IndiaBangalore, IndiaIndian Institute of Technology-BombayMumbai, IndiaInstitute for InfocommResearch, SingaporeAbstractTransliteration is generally defined as phonetictranslation of names across languages.
Ma-chine Transliteration is a critical technology inmany domains, such as machine translation,cross-language information retriev-al/extraction, etc.
Recent research has shownthat high quality machine transliteration sys-tems may be developed in a language-neutralmanner, using a reasonably sized good qualitycorpus (~15-25K parallel names) between agiven pair of languages.
In this shared task,we focus on acquisition of such good qualitynames corpora in many languages, thus com-plementing the machine transliteration sharedtask that is concurrently conducted in the sameNEWS 2010 workshop.
Specifically, this taskfocuses on mining the Wikipedia paired enti-ties data (aka, inter-wiki-links) to producehigh-quality transliteration data that may beused for transliteration tasks.1 Task DescriptionThe task is to develop a system for mining singleword transliteration pairs from the standard Wi-kipedia paired topics (aka, Wikipedia Inter-Language Links, or WIL1) in one or more of thespecified language pairs.
The WIL?s link articleson the same topic in multiple languages, and aretraditionally used as a parallel language resourcefor many NLP applications, such as MachineTranslation, Crosslingual Search, etc.
SpecificWIL?s of interest for our task are those that con-tain proper names ?
either wholly or partly ?which can yield rich transliteration data.Each WIL consists of a topic in the source andthe language pair, and the task is to identify partsof the topic (in the respective language titles) thatare transliterations of each other.
A seed data set(of about 1K transliteration pairs) would be pro-vided for each language pair, and are the onlyresource to be used for developing a mining sys-tem.
The participants are expected to produce a1Wikipedia?s Interlanguage Links:http://en.wikipedia.org/wiki/Help:Interlanguage_links.paired list of source-target single word namedentities, for every WIL provided.
At the evalua-tion time, a random subset of WIL?s (about 1KWIL?s) in each language pair that are hand la-beled would be used to test the results producedby the participants.Participants may use only the 1K seed dataprovided by the organizers to produce ?standard?results; this restriction is imposed to provide ameaningful way of comparing the effective me-thods and approaches.
However, ?non-standard?runs would be permitted where participants mayuse more seed data or any language-specific re-source available to them.2 Important DatesSHARED TASK SCHEDULESRegistration Opens  1-Feb-2010Registration Closes   13-Mar-2010Training Data Release  26 -Feb-2010Test Data Release  13-Mar-2010Results Submission Due  20-Mar-2010Evaluation Results An-nouncement 27-Mar-2010Short Papers Due  5-Apr-2010Workshop Paper Sub-mission Closes  5-Apr-2010Workshop & Task Pa-pers Acceptance  6-May-2010CRC Due  15-May-2010Workshop Date   16-Jul-20103 Participation1.
Registration (1 Feb 2010)a.
Prospective participants are to register tothe NEWS-2010 Workshop homepage, forthis specific task.2.
Training Data Release (26 Feb 2010)a.
Registered participants are to obtain seedand Wikipedia data from the Shared Taskorganizers.293.
Evaluation Script (1 March 2010)a.
A sample submission and an evaluationscript will be released in due course.b.
The participants must make sure that theiroutput is produced in a way that the evalua-tion script may run and produce the ex-pected output.c.
The same script (with held out test data andthe user outputs) would be used for finalevaluation.4.
Testing data (13 March 2010)a.
The test data would be a held out data ofapproximately 1K ?gold-standard?
mineddata.b.
The submissions (up to 10) would be testedagainst the test data, and the results pub-lished.5.
Results (27 March 2010)a.
On the results announcement date, theevaluation results would be published onthe Workshop website.b.
Note that only the scores (in respective me-trics) of the participating systems on eachlanguage pairs would be published, but noexplicit ranking of the participating sys-tems.c.
Note that this is a shared evaluation taskand not a competition; the results are meantto be used to evaluate systems on commondata set with common metrics, and not torank the participating systems.
While theparticipants can cite the performance oftheir systems (scores on metrics) from theworkshop report, they should not use anyranking information in their publications.d.
Further, all participants should agree not toreveal identities of other participants in anyof their publications unless you get permis-sion from the other respective participants.If the participants want to remain anonym-ous in published results, they should informthe organizers at the time of registration.Note that the results of their systems wouldstill be published, but with the participantidentities masked.
As a result, in this case,your organization name will still appear inthe web site as one of participants, but it isnot linked explicitly with your results.6.
Short Papers on Task (5 April 2010)a.
Each submitting site is required to submit a4-page system paper (short paper) for itssubmissions, including their approach, dataused and the results.b.
All system short papers will be included inthe proceedings.
Selected short papers willbe presented in the NEWS 2010 workshop.Acceptance of the system short-paperswould be announced together with that ofother papers.4 Languages InvolvedThe task involves transliteration mining in thelanguage pairs summarized in the following ta-ble.Source Lan-guageTarget Lan-guageTrack IDEnglish  Chinese  WM-EnCnEnglish  Hindi  WM-EnHiEnglish  Tamil WM-EnTaEnglish  Russian  WM-EnRuEnglish Arabic WM-EnArTable 1: Language Pairs in the shared task5 Data Sets for the TaskThe following datasets are used for each lan-guage pair, for this task.Training Data  Size RemarksSeed Data (Pa-rallel)~1K Paired names be-tween source andtarget languages.To-be-minedWikipedia Inter-Wiki-Link Data(Noisy)Vari-ablePaired named entitiesbetween source andtarget languages ob-tained directly fromWikipediaTest Data~1K This is a subset ofWikipedia Inter-Wiki-Link data,which will be handlabeled.Table 2: Datasets for the shared taskThe first two sets would be provided by the or-ganizers to the participants, and the third will beused for evaluation.To-Mine-Data WIL data:  All WIL?s from anappropriate download from Wikipedia would beprovided.
The WIL data might look like thesamples shown in Tables 3 and 4, with the sin-30gle-word transliterations highlighted.
Note thatthere could be 0, 1 or more single-word translite-rations from each WIL.# English WikipediaTitleHindi WikipediaTitle1 Indian National Congress ??????
?????????
????????
?2 University of Oxford ?????????????????????
?3 Indian Institute of Science ??????
??????????????
?4 Jawaharlal Nehru Univer-sity????????
?????????????????
?Table 3: Sample English-Hindi Wikipedia titlepairs# English WikipediaTitleRussian WikipediaTitle1 Mikhail Gorbachev ???????
?, ??????????????
?2 George Washington ????????
?, ?????
?3 Treaty of Versailles ???????????
??????
?4 French Republic ??????
?Table 4: Sample English-Russian Wikipedia titlepairsSeed transliteration data:  In addition we pro-vide approximately 1K parallel names in eachlanguage pair as seed data to develop any metho-dology to identify transliterations.
For standardrun results, only this seed data could be used,though for non-standard runs, more data or otherlinguistics resources may be used.English Names Hindi NamesVillage ????
?Linden ??????
?Market ????
?Mysore ????
?Table 5: Sample English-Hindi seed dataEnglish Names Russian NamesGregory ???????
?Hudson ?????
?Victor ?????
?baranowski ??????????
?Table 6: Sample English-Russian seed dataTest set:  We plan to randomly select ~1000 wi-kipedia links (from the large noisy Inter-wiki-links) as test-set, and manually extract the singleword transliteration pairs associated with each ofthese WILs.
Please note that a given WIL canprovide 0, 1 or more single-word transliterationpairs.
To keep the task simple, we consider ascorrect transliterations only those that are cleartransliterations word-per-word (morphologicalvariations one or both sides are not consideredtransliterations) These 1K test set will be a subsetof Wikipedia data provided to the user.
The golddataset might look like the following (assumingthe items 1, 2, 3 and 4 in Tables 3 and 4 wereamong the randomly selected WIL?s from To-Mine-Data).WIL# English Names Hindi Names1 Congress ????????
?2 Oxford ????????
?3 <Null> <Null>4 Jawaharlal ???????
?4 Nehru ????
?Table 7: Sample English-Hindi transliterationpairs mined from Wikipedia title pairsWIL# English Names Russian Names1 Mikhail ?????
?1 Gorbachev ???????
?2 George ?????
?2 Washington ????????
?3 Versailles ??????????
?4 <Null> <Null>Table 8: Sample English-Russian translitera-tion pairs mined from Wikipedia title pairsEvaluation: The participants are expected tomine such single-word transliteration data forevery specific WIL, though the evaluation wouldbe done only against the randomly selected,hand-labeled test set.
At evaluation time, thetask organizers check every WIL in test set fromamong the user-provided results, to evaluate thequality of the submission on the 3 metrics de-scribed later.Additional information on data use:1.
Seed data may have ownership and appropri-ate licenses may need to be procured for use.2.
To-be-mined Wikipedia data is extractedfrom Wikipedia (in Jan/Feb 2010), and dis-tributed as-is.
No assurances that they arecorrect, complete or consistent.31Figure 1: Overview of the mining task and evaluation3.
The hand-labeled test set is created byNEWS shared task organizers, and will beused for computing the metrics for a givensubmission.4.
We expect that the participants to use onlythe seed data (parallel names) provided bythe Shared Task for a standard run to ensurea fair evaluation and a meaningful compari-son between the effectiveness of approachestaken by various systems.
At least one suchrun (using only the data provided by theshared task) is mandatory for all participantsfor a given task that they participate in.5.
If more data (either parallel names data ormonolingual data), or any language-specificmodules were used, then all such runs usingextra data or resources must be marked as?Non-standard?.
For such non-standardruns, it is required to disclose the size andcharacteristics of the data or the nature oflanguages resources used, in their paper.6.
A participant may submit a maximum of 10runs for a given language pair (including oneor more ?standard?
run).
There could bemore standard runs, without exceeding 10(including the non-standard runs).6 Paper FormatAll paper submissions to NEWS 2010 shouldfollow the ACL 2010 paper submission policy(http://acl2010.org/papers.html), including paperformat, blind review policy and title and authorformat convention.
Shared task system short pa-pers are also in two-column format without ex-ceeding four (4) pages plus any extra page forreferences.
However, there is no need for double-blind requirements, as the users may refer totheir runs and metrics in the published results.7 Evaluation MetricsWe plan to measure the quality of the miningtask using the following measures:1.
PrecisionCorrectTransliterations (PTrans)2.
RecallCorrectTransliteration (RTrans)3.
F-ScoreCorrectTransliteration (FTrans).Please refer to the following figures for the ex-planations:A = True Positives (TP) = Pairs that were identi-fied as "Correct Transliterations" by the partici-pant and were indeed "Correct Transliterations"as per the gold standardB = False Positives (FP) = Pairs that were identi-fied as "Correct Transliterations" by the partici-pant but they were "Incorrect Transliterations" asper the gold standard.C = False Negatives (FN) = Pairs that were iden-tified as "Incorrect Transliterations" by the par-ticipant but were actually "Correct Translitera-tions" as per the gold standard.32D = True Negatives (TN) = Pairs that were iden-tified as "Incorrect Transliterations" by the par-ticipant and were indeed "Incorrect Translitera-tions" as per the gold standard.1.
RecallCorrectTransliteration  (RTrans)The recall is going to be computed using thesample as follows:??????
=????
+ ??=??
+ ?=??2.
PrecisionCorrectTransliteration  (PTrans)The precision is going to be computed using thesample as follows:??????
=????
+ ??=??
+ ?3.
F-Score (F)?
=2 ?
??????
?
????????????
+ ?????
?8 Contact UsIf you have any questions about this share taskand the database, please contact one of the orga-nizers below:Dr. A. KumaranMicrosoft Research IndiaBangalore 560080 INDIAa.kumaran@microsoft.comMitesh KhapraIndian Institute of Technology-BombayMumbai, INDIAMKhapra@cse.iitb.ac.in.Dr Haizhou LiInstitute for Infocomm ResearchSingapore, SINGAPORE 138632hli@i2r.a-star.edu.sg.33Appendix A: Seed Parallel Names Data?
File Naming Conventions:o NEWS09_Seed_XXYY_1K.xml,?
XX: Source Language?
YY: Target Language?
1K: number of parallel names?
File Formats:o All data would be made available in XML formats (Appendix A).?
Data Encoding Formats:o The data would be in Unicode, in UTF-8 encoding.
The results are expected to besubmitted in UTF-8 format only, and in the XML format specified.File: NEWS2009_Seed_EnHi_1000.xml<?xml version="1.0" encoding="UTF-8"?><SeedCorpusCorpusID = "NEWS2009-Seed-EnHi-1K"SourceLang = "English"TargetLang = "Hindi"CorpusType = "Seed"CorpusSize = "1000"CorpusFormat = "UTF8"><Name ID=?1?><SourceName>eeeeee1</SourceName><TargetName ID="1">hhhhhh1_1</TargetName><TargetName ID="2">hhhhhh1_2</TargetName>...<TargetName ID="n">hhhhhh1_n</TargetName></Name><Name ID=?2?><SourceName>eeeeee2</SourceName><TargetName ID="1">hhhhhh2_1</TargetName><TargetName ID="2">hhhhhh2_2</TargetName>...<TargetName ID="m">hhhhhh2_m</TargetName></Name>...<!-- rest of the names to follow -->...</SeedCorpus>Appendix B: Wikipedia InterwikiLinks Data?
File Naming Conventions:o NEWS09_Wiki_XXYY_nnnn.xml,?
XX: Source Language?
YY: Target Language?
nnnn: size of paired entities culled from Wikipedia (?25K?, ?10000?, etc.)?
File Formats:o All data would be made available in XML formats (Appendix A).?
Data Encoding Formats:o The data would be in Unicode, in UTF-8 encoding.
The results are expected to besubmitted in UTF-8 format only, and in the XML format specified.34File: NEWS2009_Wiki_EnHi_10K.xml<?xml version="1.0" encoding="UTF-8"?><WikipediaCorpusCorpusID = "NEWS2009-Wiki-EnHi-10K"SourceLang = "English"TargetLang = "Hindi"CorpusType = "Wiki"CorpusSize = "10000"CorpusFormat = "UTF8"><Title ID=?1?><SourceEntity>e1 e2 ?
en</SourceEntity><TargetEntity>h1 h2 ?
hm</TargetEntity></Title><Title ID=?2?><SourceEntity>e1 e2 ?
ei</SourceEntity><TargetEntity>h1 h2 ?
hj</TargetEntity></Title>...<!-- rest of the titles to follow -->...</ WikipediaCorpus>Appendix C: Results Submission - Format?
File Naming Conventions:o NEWS09_Result_XXYY_gggg_nn_description.xml?
XX: Source?
YY: Target?
gggg: Group ID?
nn: run ID.?
description: Description of the run?
File Formats:o All results would be submitted in XML formats (Appendix B).?
Data Encoding Formats:o The data would be in Unicode, in UTF-8 encoding.
The results are expected to besubmitted in UTF-8 format only.Example: NEWS2009_EnHi_TUniv_01_HMMBased.xml<?xml version="1.0" encoding="UTF-8"?><WikipediaMiningTaskResultsSourceLang = "English"TargetLang = "Hindi"GroupID = "Trans University"RunID = "1"RunType = "Standard"Comments = "SVD Run with params: alpha=xxx beta=yyy"><Title ID="1"><MinedPair ID="1"><SourceName>e1</SourceName><TargetName>h1</TargetName></MinedPair><MinedPair ID="2"><SourceName>e2</SourceName><TargetName>h2</TargetName></MinedPair><!
?followed by other pairs mined from this title--></Title><Title ID="2"><MinedPair ID="1"><SourceName>e1</SourceName><TargetName>h1</TargetName></MinedPair>35<MinedPair ID="2"><SourceName>e2</SourceName><TargetName>h2</TargetName></MinedPair><!
?followed by other pairs mined from this title--></Title>...<!-- All titles in the culled data to follow -->...</WikipediaMiningTaskResults>Appendix D: Sample Eng-Hindi Interwikilink Data<?xml version="1.0" encoding="UTF-8"?><WikipediaCorpus CorpusID = "NEWS2009-Wiki-EnHi-Sample"SourceLang = "English"TargetLang = "Hindi"CorpusType = "Wiki" CorpusSize = "3"CorpusFormat = "UTF8"><Title ID="1"><SourceEntity>Indian National Congress</SourceEntity><TargetEntity>??????
?????????
????????
?</TargetEntity></Title><!-- {Congress, ?????????}
should be identified by the paricipants--><Title ID="2"><SourceEntity>University of Oxford</SourceEntity><TargetEntity>?????????
????????????
?</TargetEntity></Title><!-- {Oxford, ?????????}
should be identified by the paricipants--><Title ID="3"><SourceEntity>Jawaharlal Nehru University</SourceEntity><TargetEntity>????????
?????
????????????
?</TargetEntity></Title><!-- {Jawaharlal, ????????}
and {Nehru, ?????}
should beidentified by the paricipants--><Title ID="4"><SourceEntity>Indian Institute Of Science</SourceEntity><TargetEntity>??????
???????
???????
?</TargetEntity></Title><!--There are no transliteration pairs here --></WikipediaCorpus>Appendix E: Eng-Hindi Gold Mined Data (wrt the above WIL Data)<?xml version="1.0" encoding="UTF-8"?><WikipediaMiningTaskResultsSourceLang = "English"TargetLang = "Hindi"GroupID = "Gold-Standard"RunID = ""RunType = ""Comments = ""><Title ID="1"><MinedPair ID="1"><SourceName>Congress</SourceName><TargetName> ????????
?</TargetName></MinedPair></Title><Title ID="2"><MinedPair ID="1">36<SourceName>Oxford</SourceName><TargetName> ????????
?</TargetName></MinedPair></Title><Title ID="3"><MinedPair ID="1"><SourceName>Jawaharlal</SourceName><TargetName> ???????
?</TargetName></MinedPair><MinedPair ID="2"><SourceName>Nehru</SourceName><TargetName> ????
?</TargetName></MinedPair></Title><Title ID="4"></Title></WikipediaMiningTaskResults>Appendix F: English-Hindi Sample Submission and Evaluation<?xml version="1.0" encoding="UTF-8"?><WikipediaMiningTaskResultsSourceLang = "English"TargetLang = "Hindi"GroupID = "Gold-Standard"RunID = ""RunType = ""<Title ID="1"><MinedPair ID="1"><SourceName>Congress</SourceName><TargetName> ????????
?</TargetName></MinedPair>The participant mined all correct transliteration pairs</Title><Title ID="2"><MinedPair ID="1"><SourceName>Oxford</SourceName><TargetName> ????????
?</TargetName></MinedPair><MinedPair ID="1"><SourceName>University</SourceName><TargetName>????????????
?</TargetName></MinedPair>The participant mined an incorrect transliteration pair {University,?????????????
}</Title><Title ID="3"><MinedPair ID="1"><SourceName>Jawaharlal</SourceName><TargetName> ???????
?</TargetName></MinedPair>The participant missed the correct transliteration pair {Nehru, ?????
}</Title><Title ID="4"><MinedPair ID="1"><SourceName>Indian</SourceName><TargetName>?????
?</TargetName></MinedPair>The participant mined an incorrect transliteration pair {Indian, ??????
}</Title></WikipediaMiningTaskResults>37Sample EvaluationT = |{(Congress, ?????????
), (Oxford, ?????????
), (Jawaharlal, ????????
),(Nehru, ?????)}
| = 4A = TP = | {(Congress, ?????????
), (Oxford, ?????????
), (Jawaharlal, ????????
)}| = 3B = FP = |{(Indian, ??????
), (University, ?????????????)
}| = 2C = FN = |{(Nehru, ?????
)}| = 1??????
=????
+ ??=??
+ ?=?
?=34= 0.75??????
=????+??=?
?+?=35= 0.60?
=2 ?
??????
?
????????????
+ ?????
?=2 ?
0.6 ?
0.750.6 + 0.75=  0.6738
