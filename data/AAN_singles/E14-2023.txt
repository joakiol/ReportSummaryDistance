Proceedings of the Demonstrations at the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 89?92,Gothenburg, Sweden, April 26-30 2014.c?2014 Association for Computational LinguisticsRelationFactory: A Fast, Modular and Effective System for KnowledgeBase PopulationBenjamin Roth?Tassilo Barth?Grzegorz Chrupa?a*Martin Gropp?Dietrich Klakow?
?Spoken Language Systems, Saarland University, 66123 Saarbr?ucken, Germany*Tilburg University, PO Box 90153, 5000 LE Tilburg, The Netherlands?
{beroth|tbarth|mgropp|dietrich.klakow}@lsv.uni-saarland.de*g.chrupala@uvt.nlAbstractWe present RelationFactory, a highly ef-fective open source relation extraction sys-tem based on shallow modeling tech-niques.
RelationFactory emphasizes mod-ularity, is easily configurable and uses atransparent pipelined approach.The interactive demo allows the user topose queries for which RelationFactory re-trieves and analyses contexts that containrelational information about the query en-tity.
Additionally, a recall error analy-sis component categorizes and illustratescases in which the system missed a correctanswer.1 Introduction and OverviewKnowledge base population (KBP) is thetask of finding relational information in largetext corpora, and structuring and tabulariz-ing that information in a knowledge base.Given an entity (e.g.
of type PERSON) withan associated relational schema (a set of re-lations, e.g.
city of birth(PERSON,CITY), schools attended(PERSON,ORGANIZATION), spouse(PERSON,PERSON)), all relations about the entity thatare expressed in a text corpus would be rele-vant, and the correct answers would have to beextracted.The TAC KBP benchmarks1are an effort to for-malize this task and give researchers in the fieldthe opportunity to evaluate their algorithms on aset of currently 41 relations.
In TAC KBP, thetask and evaluation setup is established by well-defined information needs about query entities oftypes PERSON and ORGANIZATION (e.g.
who isthe spouse of a person, how many employees1http://www.nist.gov/tac/about/does an organization have).
A perfect systemwould have to return all relevant information (andonly this) contained in the text corpus.
TAC KBPaims at giving a realistic picture of not only pre-cision but also recall of relation extraction sys-tems on big corpora, and is therefore an advance-ment over many other evaluations done for rela-tion extraction that are often precision oriented(Suchanek et al., 2007) or restrict the gold key toanswers from a fixed candidate set (Surdeanu etal., 2012) or to answers contained in a data base(Riedel et al., 2010).
Similar to the classical TRECevaluation campaigns in document retrieval, TACKBP aims at approaching a true recall estimate bypooling, i.e.
merging the answers of a timed-outmanual search with the answers of all participat-ing systems.
The pooled answers are then evalu-ated by human judges.It is a big advantage of TAC KBP that the end-to-end setup (from the query, through retrieval ofcandidate contexts and judging whether a relationis expressed, to normalizing answers and puttingthem into a knowledge base) is realistic.
At thesame time, the task is very complex and may in-volve too much work overhead for researchersonly interested in a particular step in relation ex-traction such as matching and disambiguation ofentities, or judging relational contexts.
We there-fore introduce RelationFactory, a fast, modularand effective relation extraction system, to the re-search community as open source software.2Rela-tionFactory is based on distantly supervised classi-fiers and patterns (Roth et al., 2013), and was top-ranked (out of 18 systems) in the TAC KBP 2013English Slot-filling benchmark (Surdeanu, 2013).In this demo, we give potential users the possi-bility to interact with the system and to get a feelfor use cases, strengths and limitations of the cur-rent state of the art in knowledge base population.2https://github.com/beroth/relationfactory89The demo illustrates how RelationFactory arrivesat its conclusions and where future potentials inrelation extraction lie.
We believe that Relation-Factory provides an easy start for researchers in-terested in relation extraction, and we hope thatit may serve as a baseline for new advances inknowledge base population.2 System Philosophy and DesignPrinciplesThe design principles of RelationFactory conformto what is known as the Unix philosophy.3For Re-lationFactory this philosophy amounts to a set ofmodules that solve a certain step in the pipelineand can be run (and tested) independently of theother modules.
For most modules, input and out-put formats are column-based text representationsthat can be conveniently processed with standardLinux tools for easy diagnostics or prototyping.Data representation is compact: the system is de-signed in a way that each module ideally outputsone new file.
Because of modularization and sim-ple input and output formats, RelationFactory al-lows for easy extensibility, e.g.
for research thatfocuses solely on novel algorithms at the predic-tion stage.The single modules are connected by a make-file that controls the data flow and allows for easyparallelization.
RelationFactory is highly config-urable: new relations can be added without chang-ing any of the source code, only by changing con-figuration files and adding or training respectiverelational models.Furthermore, RelationFactory is designed to behighly scalable: Thanks to feature hashing, largeamounts of training data can be used in a memory-friendly way.
Predicting relations in real-time ispossible using shallow representations.
Surfacepatterns, ngrams and skip-ngrams allow for highlyaccurate relational modeling (Roth et al., 2013),without incurring the cost of resource-intensiveprocessing, such as parsing.3One popular set of tenets (Gancarz, 2003) summarizesthe Unix philosophy as:1.
Small is beautiful.2.
Make each program do one thing well.3.
Build a prototype as soon as possible.4.
Choose portability over efficiency.5.
Store data in flat text files.6.
Use software leverage to your advantage.7.
Use shell scripts to increase leverage and portability.8.
Avoid captive user interfaces.9.
Make every program a filter.Figure 1: TAC KBP: Given a set of queries, returna correct, complete and non-redundant responsewith relevant information extracted from the textcorpus.Figure 2: Data flow of the relation extraction sys-tem: The candidate generation stage retrieves pos-sible relational contexts.
The candidate validationstage predicts whether relations actually hold andproduces a valid response.3 Component OverviewA simplified input and output to RelationFactoryis shown in Figure 1.
In general, the pipelineis divided in a candidate generation stage, wheredocuments are retrieved and candidate sentencesare identified, and the candidate validation stage,which predicts and generates a response from theretrieved candidates (see Figure 2).In a first step, the system generates aliases forthe query using statistical and rule-based expan-sion methods, for example:Query ExpansionAdam Gadahn Azzam the American, Adam Yahiye Gadahn, GadahnSTX Finland Kvaerner Masa Yards, Aker Finnyards, STX Finland LtdThe expansions are used for retrieving docu-ments from a Lucene index.
All those sen-90tences are retained where the query (or one ofthe query aliases) is contained and the named-entity tagger has identified another entity withthe type of a potential answer for one of thesought relations.
The system is easily con-figurable to include matching of non-standardnamed-entity types from lists.
RelationFac-tory uses lists obtained from Freebase (www.freebase.com) to match answer candidatesfor the types CAUSE-OF-DEATH, JOB-TITLE,CRIMINAL-CHARGES and RELIGION.The candidate sentences are output line-by-lineand processed by one of the validation modules,which determine whether actually one of the rela-tions is expressed.
RelationFactory currently usesthree standard validation modules: One based onSVM classifiers, one based on automatically in-duced and scored patterns, and one based on man-ually crafted patterns.
The validation modulesfunction as a filter to the candidates file.
Theydo not have to add a particular formatting or con-form to other requirements of the KBP task suchas establishing non-redundancy or finding the cor-rect offsets in the text corpus.
This is done byother modules in the pipeline, most notably inthe post-processing step, where statistical meth-ods and heuristics are applied to produce a well-formed TAC KBP response.4 User PerspectiveFrom a user perspective, running the system is aseasy as calling:./run.sh system.configThe configuration file contains all informationabout the general run configuration of the system,such as the query file to use, the format of the re-sponse file (e.g.
TAC 2012 or TAC 2013 format),the run directory that will contain the response,and the Lucene index with the corpus.
Optionalconfiguration can control non-standard validationmodules, and special low or high-recall query ex-pansion schemes.The relevant parts of the configuration file for astandard 2013 TAC KBP run would look like thefollowing:query /TAC_EVAL/2013/query.xmlgoal response2013rundir /TAC_RUNS/run2013/index /TAC_CORPORA/2013/indexrellist /CFG/rellist2013relations.config /CFG/relations2013.configThe last two lines refer to relation-specific con-figuration files: The list of relations to use and in-formation about them.
Changing these files (andadding respective models) allows for inclusion offurther relations.
The relation-specific configura-tion file contains information about the query en-tity type, the expected answer named-entity tagand whether a list of answers is expected (com-pared to relations with just one correct answer):per:religion enttype PERper:religion argtag RELIGIONper:religion listtype falseorg:top_members_employees enttype ORGorg:top_members_employees argtag PERSONorg:top_members_employees listtype trueRelationFactory comes with batteries included:The models and configurations for TAC KBP 2013work out-of-the-box and can easily be used as arelation extraction module in a bigger setting or asa baseline for new experiments.45 Illustrating RelationFactoryIn TAC KBP 2013, 6 out of 18 systems achievedan F1 score of over 30%.
RelationFactory asthe top-performing system achieved 37.28% com-pared to 68.49% achieved by human control an-notators (Surdeanu, 2013).
These numbers clearlyshow that current systems have just gone halfwaytoward achieving human-like performance on anend-to-end relation extraction task.The aim of the RelationFactory demo is to il-lustrate what the current challenges in TAC KBPare.
The demonstration interface therefore notonly shows the answers generated for populatinga potential knowledge base, but also what text wasused to justify the extraction.The real-time performance of RelationFactoryallows for trying arbitrary queries and changingthe configuration files and immediately seeing theeffects.
Different expansion schemes, validationmodules and patterns can be turned on and off, andintuitions can be obtained about the bottlenecksand error sources of relation extraction.
The demoalso allows for seeing the effect of extracting infor-mation from different corpora: a Wikipedia corpusand different TAC KBP corpora, such as newswireand web text.4Training models for new relations requires is a biggereffort and includes generation of distant supervision train-ing data by getting argument pairs from relational patternsor a knowledge base like Freebase.
RelationFactory includessome training scripts but since they are typically run onceonly, they are significantly less documented.91Figure 3: Screenshot of the RelationFactory demo user interface.RelationFactory contains a number of diagnos-tic tools: With a gold key for a set of queries, errorclasses can be broken down and examples for cer-tain error classes can be shown.
For example, thediagnostic tool for missed recall performs the fol-lowing checks:1.
Is document retrieved?2.
Is query matched?
This determines whether a sen-tence is considered for further processing.3.
Is answer in query sentence?
Whether the answer isin one of the sentences with the query.
Our system onlycan find answers when this is the case, as there is no co-reference module included.4.
Do answer tags overlap with gold answer?5.
Do they overlap exactly?6.
Other (validation).
If all previous checks are passed,the candidate has correctly been generated by the can-didate generation stage, but the validation moduleshave failed to predict the relation.On the TAC KBP 2013 queries, the resulting re-call error analysis is:error class missing recallDoc not retrieved 5.59%Query not matched 10.37%Answer not in query sentence 16.63%Answer tag inexact 5.36%Answer not tagged 24.85%Other (validation) 37.17%The demonstration tool allows for inspection ofinstances of each of the error classes.6 ConclusionThis paper illustrates RelationFactory, a modularopen source knowledge-base population system.We believe that RelationFactory will become es-pecially valuable for researchers in the field of re-lation extraction that focus on one particular prob-lem of knowledge-base-population (such as entityexpansion or relation prediction) and want to inte-grate their algorithms in an end-to-end setting.AcknowledgmentsBenjamin Roth is a recipient of the Google EuropeFellowship in Natural Language Processing, andthis research is supported in part by this GoogleFellowship.
Tassilo Barth was supported in partby IARPA contract number W911NF-12-C-0015.ReferencesMike Gancarz.
2003.
Linux and the Unix philosophy.Digital Press.Sebastian Riedel, Limin Yao, and Andrew McCal-lum.
2010.
Modeling relations and their men-tions without labeled text.
In Machine Learning andKnowledge Discovery in Databases, pages 148?163.Springer.Benjamin Roth, Tassilo Barth, Michael Wiegand, Mit-tul Singh, and Dietrich Klakow.
2013.
Effective slotfilling based on shallow distant supervision methods.In Proceedings of the Sixth Text Analysis Conference(TAC 2013).Fabian M Suchanek, Gjergji Kasneci, and GerhardWeikum.
2007.
Yago: a core of semantic knowl-edge.
In Proceedings of the 16th international con-ference on World Wide Web, pages 697?706.
ACM.Mihai Surdeanu, Julie Tibshirani, Ramesh Nallapati,and Christopher D Manning.
2012.
Multi-instancemulti-label learning for relation extraction.
In Pro-ceedings of the 2012 Conference on Empirical Meth-ods in Natural Language Processing and NaturalLanguage Learning (EMNLP-CoNLL), pages 455?465.
ACL.Mihai Surdeanu.
2013.
Overview of the tac2013knowledge base population evaluation: English slotfilling and temporal slot filling.
In Proceedings ofthe Sixth Text Analysis Conference (TAC 2013).92
