Proceedings of the Ninth International Workshop on Parsing Technologies (IWPT), pages 202?203,Vancouver, October 2005. c?2005 Association for Computational Linguisticsk-NN for Local Probability Estimation in Generative Parsing ModelsDeirdre HoganDepartment of Computer ScienceTrinity College DublinDublin 2, Irelanddhogan@cs.tcd.ieAbstractWe describe a history-based generativeparsing model which uses a k-nearestneighbour (k-NN) technique to estimatethe model?s parameters.
Taking theoutput of a base n-best parser we use ourmodel to re-estimate the log probability ofeach parse tree in the n-best list forsentences from the Penn Wall StreetJournal treebank.
By furtherdecomposing the local probabilitydistributions of the base model, enrichingthe set of conditioning features used toestimate the model?s parameters, andusing k-NN as opposed to the Witten-Bellestimation of the base model, we achievean f-score of 89.2%, representing a 4%relative decrease in f-score error over the1-best output of the base parser.1 IntroductionThis paper describes a generative probabilisticmodel for parsing, based on Collins (1999), whichre-estimates the probability of each parse generatedby an initial base parser (Bikel, 2004) usingmemory-based techniques to estimate localprobabilities.We used Bikel?s re-implementation of theCollins parser (Bikel, 2004) to produce the n-bestparses of sentences from the Penn treebank.
Wethen recalculated the probability of each parse treeusing a probabilistic model very similar to Collins(1999) Model 1.
In addition to the local estimationtechnique used, our model differs from Collins(1999) Model 1 in that we extend the feature setsused to predict parse structure to include morefeatures from the parse history, and we furtherdecompose some of the model?s parameter classes.2 Constraint Features for Training SetRestrictionWe use the same k-NN estimation technique asToutonava et al(2003) however we also found thatrestricting the number of examples in the trainingset used in a particular parameter estimation helpedboth in terms of accuracy and speed.
We restrictedthe training sets by making use of constraintfeatures whereby the training set is restricted toonly those examples which have the same value forthe constraint feature as the query instance.We carried out experiments using differentsets of constraint features, some more restrictivethan others.
The mechanism we used is as follows:if the number of examples in the training set,retrieved using a particular set of constraintfeatures, exceeds a certain threshold value then usea higher level of restriction i.e.
one which usesmore constraint features.
If, using the higher levelof restriction, the number of samples in the trainingset falls below a minimum threshold value then?back-off?
to the less restricted set of trainingsamples.3 ExperimentsOur model is trained on sections 2 to 21 inclusiveof the Penn WSJ treebank and tested on section 23.We used sections 0, 1, 22 and 24 for validation.We re-estimated the probability of eachparse using our own baseline model, which is areplication of Collins Model 1.
We tested k-NNestimation on the head generation parameter class202and the parameter classes for generating modifyingnonterminals.
We further decomposed the twomodifying nonterminal parameter classes.
Table 1outlines the parameter classes estimated using k-NN in the final model settings and shows thefeature sets used for each parameter class as wellas the constraint feature settings.ParameterClassHistory ContraintFeaturesP(CH |?)
Cp, CH, wp,tp, tgp{Cp}P(ti |?)
dir, Cp, CH,wp, tp, dist, ti-1, t i-2, Cgp{dir, Cp}, {dir, Cp,CH }P(Ci |?)
dir, ti, Cp CH,wp, tp, dist, ti-1,ti-2, Cgp{dir,ti},{dir, ti, Cp}P(coord,punc|?)
dir, Ci, ti, Cp,CH, wp, ,tp{dir, Ci, ti}P(Ci ti | Cp=NPB?
)dir, CH, wp,Ci-2, wi-2, Ci-3, wi-3, Cgp,Cggp, Cgggp{dir, CH }P(punc| Cp=NPB?
)dir, ti, Ci, CH,wp,tp, t i-2, t i-3{dir, ti}Table 1:  The parameter classes estimated using k-NN inthe final model.
CH is the head child label, Cp the parentconstituent label, wp the head word, tp the head part-of-speech (POS) tag.
Ci, wi and ti are the modifier?s label,head word and head POS tag.
tgp  is the grand-parentPOS tag, Cgp, Cggp, Cgggp are the labels of the grand-parent, great-grandparent and great-great-grandparentnodes.
dir is a flag which indicates whether themodifier being generated is to the left or the right of thehead child.
dist is the distance metric used in theCollins parser.
coord, punc are the coordination andpunctuation flags.
NPB stands for base noun phrase.We extend the original feature sets by increasingthe order of both horizontal and verticalmarkovization.
From each constituent node in thevertical or horizontal history we chose featuresfrom among the constituent?s nonterminal label, itshead word and the head word?s part-of-speech tag.We found for all parameter classes 000,10k  or000,20k  worked best.
Distance weightingfunction that worked best were the inverse distanceweighting functions either (1/(d+1))6 or (1/(d+1))7.Model LR LPWB Baseline 88.2% 88.5%CO99 M1 87.9% 88.2%CO99 M2 88.5% 88.7%Bikel 1-best 88.7% 88.7%k-NN 89.1% 89.4%Table 2:  Results for sentences of less than or equal to40 words, from section 23 of the Penn treebank.
LP/LR=Labelled Precision/Recall.
CO99 M1 and M2 are(Collins 1999) Models 1 and 2 respectively.
Bikel 1-best is (Bikel, 2004).
k-NN is our final k-NN model.With our k-NN model we achieve LR/LR of89.1%/89.4% on sentences  40 words.
Theseresults show an 8% relative reduction in f-scoreerror over our Model 1 baseline and a 4% relativereduction in f-score error over the Bikel parser.We compared the results of our k-NN modelagainst the Bikel 1-best parser results using thepaired T test where the data points being comparedwere the scores of each parse in the two differentsets of parses.
The 95% confidence interval for themean difference between the scores of the pairedsets of parses is [0.029, 0.159] with P< .005.Following (Collins 2000) the score of a parse takesinto account the number of constituents in the goldstandard parse for this sentence.
These resultsshow that using the methods presented in thispaper can produce significant improvements inparser accuracy over the baseline parser.ReferencesDaniel M. Bikel.
2004.
On the Parameter Space ofGenerative Lexicalized Statistical Parsing  Models.PhD thesis, University of Pennsylvania.Michael Collins.
1999.
Head-driven statistical modelsfor natural language processing.
PhD  thesis,University of Pennsylvania.Michael Collins.
2000.
Discriminative reranking fornatural language parsing.
In Proceedings of the 7thICML.Kristina Toutanova, Mark Mitchell and ChristopherManning.
2003.
Optimizing Local ProbabilityModels for Statistical Parsing.
In Proceedings of 14thECML.203
