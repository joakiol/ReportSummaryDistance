SEMANTIC CLASSES AND SYNTACTIC AMBIGUITYPhilip Resnik*Department  o f  Computer  and In format ion Sc ienceUnivers i ty of  Pennsy lvaniaPhi ladelphia, PA 19104resnik @ linc.cis.upenn.eduABSTRACTIn this paper we propose to define selectional preference and se-mantic similarity as information-theoretic relationships involvingconceptual c asses, and we demonstrate the applicability of thesedefinitions to the resolution of syntactic ambiguity.
The space ofclasses is defined using WordNet \[8\], and conceptual relationshipsare determined by means of statistical nalysis using parsed text inthe Penn Treebank.1.
INTRODUCTIONThe problem of syntactic ambiguity is a pervasive one.
AsChurch and Patil \[2\] point out, the class of"every way ambigu-ous" constructions - -  those for which the number of analysesis the number of binary trees over the terminal elementsincludes uch frequent constructions a prepositional phrases,coordination, and nominal compounds.
They suggest hatuntil it has more useful constraints for resolving ambiguities,a parser can do little better than to efficiently record all thepossible attachments and move on.In general, itmay be that such constraints can only be suppliedby analysis of the context, domain-dependent k owledge, orother complex inferential processes.
However, we will sug-gest that in many cases, syntactic ambiguity can be resolvedwith the help of an extremely imited form of semantic knowl-edge, closely tied to the lexical items in the sentence.We focus on two relationships: electional preference and se-mantic similarity.
From one perspective, the proposals herecan be viewed as an attempt to provide new formalizationsfor familiar but seldom carefully defined linguistic notions;elsewhere we demonstrate the utility of this approach in lin-guistic explanation \[11\].
From another perspective, the workreported here can be viewed as an attempt to generalize statisti-cal natural language techniques based on lexical associations,using knowledge-based rather than distributionally derivedword classes.
* This research as been supported by an IBM graduate f llowship and byDARPA grant N00014-90-J-1863.
The comments ofEric Bnll, Marti Hearst,Jarnie Henderson, Aravind Joshi, Mark Liberman, Mitch Marcus, MichaelNiv, and David Yarowsky are gratefully acknowledged.2.
CLASS-BASED STAT IST ICSA number of researchers have explored using lexical co-occurrences in text corpora to induce word classes \[ 1,5, 9, 12\],with results that are generally evaluated by inspecting the se-mantic ohesiveness of the distributional classes that result.
Inthis work, we are investigating the alternative of using Word-Net, an explicitly semantic, broad coverage lexical database,to define the space of semantic lasses.
Although Word-Net is subject o the attendant disadvantages of any hand-constructed knowledge base, we have found that it providesan acceptable foundation upon which to build corpus-basedtechniques \[10\].
This affords us a clear distinction betweendomain-independent andcorpus-specific sources of informa-tion, and a well-understood taxonomic representation forthedomain-independent knowledge.Although WordNet includes data for several parts of speech,and encodes numerous emantic relationships (meronymy,antonymy, verb entailment, etc.
), in this work we use onlythe noun taxonomy - -  specifically, the mapping from wordsto word classes, and the traditional IS-A relationship be-tween classes.
For example, the word newspaper belongsto the classes (newsprint) and (paper), among others, andthese are immediate subclasses of (material) and (publisher),respectively, tClass frequencies are estimated on the basis of lexical frequen-cies in text corpora.
The frequency of a class c is estimatedusing the lexical frequencies of its members, as follows:freq(c) = Z freq(n) (1){nln is subsumed by c)The class probabilities used in the section that follows canthen be estimated by simply normalizing (MLE) or by othermethods uch as Good-Turing \[3\].
21For expository convenience we identify WordNet noun classes using asingle descriptive word in angle brackets.
However, the internal representa-tion assigns each class a unique identifier.2We use Good-Tudng.
Note, however, that WordNet classes are notnecessarily disjoint; space limitations preclude further discussion of thiscomplication here.2783.
CONCEPTUAL RELATIONSHIPS3.1.
Selectional PreferenceThe term "selectional preference" has been used by linguiststo characterize the source of anomaly in sentences uch as(lb), and more generally to describe a class of restrictions onco-occurrence that is orthogonal to syntactic onstraints.
(1) a. John admires sincerity.b.
Sincerity admires John.
(2) a. Mary drank some wine.b.
Mary drank some gasoline.c.
Mary drank some pencils.d.
Mary drank some sadness.Although selectional preference is traditionally formalized interms of feature agreement using notations like \[+Animate\],such formalizations often fail to specify the set of allowablefeatures, or to capture the gradedness of qualitative differencessuch as those in (2).As an alternative, we have proposed the following formaliza-tion of selectional preference \[11\]:Definition.
The selectional preference of w for C is therelative ntropy (Kullback-I.,eibler distance) between the priordistribution Pr(C) and the posterior distribution Pr(C \] w).
(clw) D(Pr(Clw) II Pr(C)) = Pr(clw)log Pr(c) (2)= (3)CHere w is a word with selectional properties, C ranges oversemantic lasses, and co-occurrences are counted with respectto a particular argument - -  e.g.
verbs and direct objects,nominal modifiers and the head noun they modify, and soforth.
Intuitively, this definition works by comparing thedistribution of argument classes without knowing what theword is (e.g., the a priori likelihood of classes in direct objectposition), to the distribution with respect o the word.
Ifthese distributions are very different, as measured by relativeentropy, then the word has a strong influence on what can orcannot appear in that argument position, and we say that it hasa strong selectional preference for that argument.The "goodness of fit" between a word and a particular classof arguments i captured by the following definition:Definition.
The selectional association of w with c is thecontribution c makes to the selectional preference of w.?
Pr(elw'~ Pr(clw ) logA(w,c) = D(Pr(Clw ) II Pr(C)) (4)The selectional association A(wl, w2) of two words is takento be the maximum of A(wl, e) over all classes c to which w2belongs.VERB, ARGUMENT "BEST" ARGUMENT CLASS A \]drink wine (beverage) 0.088drink gasoline (substance) 0.075drink pencil (object) 0.030dnnk sadness {psychological_feature) -0.001The above table illustrates how this definition captures thequalitative differences in example (2).
The "best" class foran argument is the class that maximizes electional associ-ation.
Notice that finding that class represents a form ofsense disambiguation using local context (cf.
\[15\]): of all theclasses to which the noun wine belongs - -  including (alcohol),(substance), (red), and (color), among others - -  the class(beverage) is the sense of wine most appropriate as a directobject for drink.3.2.
Semantic SimilarityAny number of factors influence judgements of semantic sim-ilarity between two nouns.
Here we propose to use only onesource of information: the relationship between classes in theWordNet IS-A taxonomy.
Intuitively, two noun classes can beconsidered similar when there is a single, specific class thatsubsumes them both - -  if you have to travel very high in thetaxonomy to find a class that subsumes both classes, in the ex-treme case all the way to the top, then they cannot have all thatmuch in common.
For example, (nickel)and (dime) are bothimmediately subsumed by (coin), whereas the most specificsuperclass that (nickel) and (mortgage) share is (possession).The difficulty, of course, is how to determine which superclassis "most specific."
Simply counting IS-A links in the taxonomycan be misleading, since a single link can represent a fine-grained distinction in one part of the taxonomy (e.g.
(zebra)IS-A (equine)) and a very large distinction elsewhere (e.g.
(carcinogen) IS-A (substance)).Rather than counting links, we use the information contentof a class to measure its specificity (i.e., - log Pr(c)); thispermits us to define noun similarity as follows:Definition.
The semantic similarity of nl and n2 iss im(nl,n2) = Za i \ [ - logPr (c i ) \ ] ,  (5)iwhere {el} is the set of classes dominating both nl and n2.The ai,  which sum to 1, are used to weight the contribu-tion of each class - -  for example, in accordance with wordsense probabilities.
In the absence of word sense constraintswe can compute the "globally" most specific class simplyby setting c~i to 1 for the class maximizing \ [ -  log Pr(c)\],279and 0 otherwise.
For example, according to that "global"measure, sim(nickel,dime) = 12.71 (= - log  Pr((coin))) andsim(nickel,mortgage) = 7.61 (= - log Pr( (posse ssion ) )).4.
SYNTACTIC  AMBIGUITY4.1 .
Coord inat ion  and  Nomina l  CompoundsHaving proposed formalizations of selectional preference andsemantic: similarity as information-theoretic relationships in-volving conceptual classes, we now turn to the application ofthese ideas to the resolution of syntactic ambiguity.Ambiguous coordination is a common source of parsing dif-ficulty.
In this study, we investigated the application of class-based statistical methods to a particular subset of coordina-tions, noun phrase conjunctions of the form nounl and noun2noun3, as in (3):(3) a. a (bank and warehouse) guardb.
a (policeman) and (park guard)Such structures admit two analyses, one in which nounl andnoun2 are the two heads being conjoined (3a) and one inwhich the conjoined heads are noun1 and noun3 (3b).As pointed out by Kurohashi and Nagao \[7\], similarity of formand similarity of meaning are important cues to conjoinability.In English, similarity of form is to a great extent captured byagreement in number:(4) a. several business and university groupsb.
several businesses and university groupsSemantic similarity of the conjoined heads also appears toplay an important role:(5) a. a television and radio personalityb.
a psychologist and sex researcherIn addition, for this particular construction, the appropriate-ness of noun-noun modification for noun1 and noun3 is rele-vant:(6) a. mail and securities fraudb.
corn and peanut butterWe investigated the roles of these cues by conducting a dis-ambiguation experiment using the definitions in the previ-ous section.
Two sets of 100 noun phrases of the form\[NP noun1 and noun2 noun3\] were extracted from the WallStreet Journal (WSJ) corpus in the Penn Treebank and dis-ambiguated by hand, with one set to be used for developmentand the other for testing.
3 A set of simple transformationswere applied to all WSJ data, including the mapping of all3Hand isambiguation was necessary because the Penn Treebank doesnot encode NP-internal structure.
These phrases were disambiguated usingthe full sentence in which they occurred, plus the previous and followingsentence, ascontext.proper names to the token someone, the expansion of monthabbreviations, and the reduction of all nouns to their rootforms.Similarity of form, defined as agreement ofnumber, was deter-mined using a simple analysis of suffixes in combination withWordNet's database of nouns and noun exceptions.
Similar-ity of meaning was determined "globally" as in equation (5)and the example that followed; noun class probabilities wereestimated using a sample of approximately 800,000 noun oc-currences in Associated Press newswire stories.
4 For the pur-pose of determining semantic similarity, nouns not in WordNetwere treated as instances of the class (thing).
Appropriatenessof noun-noun modification was determined using selectionalassociation as defined in equation (4), with co-occurrence fre-quencies calculated using a sample of approximately 15,000noun-noun compounds extracted from the WSJ corpus.
(Thissample did not include the test data.)
Both selection of themodifier for the head and selection of the head for the modifierwere considered.Each of the three sources of information - -  form similar-ity, meaning similarity, and modification relationships-- wasused alone as a disambiguation strategy, as follows:?
Form:- If noun 1 and noun2 match in numberand noun 1 and noun3 do notthen conjoin nounl and noun2;- if nounl and noun3 match in numberand noun 1 and noun2 do notthen conjoin nounl and noun3;- otherwise remain undecided.?
Meaning:- If sim(nounl,noun2) > sim(nounl,noun3)then conjoin nounl and noun2;- ifsim(nounl,noun3) > sim(nounl,noun2)then conjoin nounl and noun3;- otherwise remain undecided.?
Modification:- If A(nounl,noun3) > r, a threshold, orif A(noun3,nounl) > r,then conjoin nounl and noun3;- If A(nounl,noun3) < ?r and A(noun3,nounl) < ~rthen conjoin nounl and noun2;- otherwise remain undecided.
5In addition, we investigated several methods for combiningthe three sources of information.
These included: (a) "back-ing off" (i.e., given the form, modification, and meaning4I am grateful tO Donald Hindle for making these data vailable.5Thresholds ~-and a were fixed before valuating the test data.280strategies in that order, use the first strategy that isn't un-decided); (b) taking a "vote" among the three strategies andchoosing the majority; (c) classifying using the results of alinear regression; and (d) constructing a decision tree classi-fier.The training set contained a bias in favor of conjoining nounland noun2, so a "default" strategy - -  always choosing thatbracketing - -  was used as a baseline.
The results are asfollows:STRATEGY ANSWERED (%)Default 100.0Form 53.0PRECISION (%)66.090.6Modification 75.0 69.3Meaning 66.0 71.2Backing off 95.0 81.1Voting 89.0 78.7Regression 100.0 79.0ID3 Tree 100.0 80.0Not surprisingly, the individual strategies perform reasonablywell on the instances they can classify, but recall is poor; thestrategy based on similarity of form is highly accurate, butarrives at an answer only half the time.
Of the combinedstrategies, the "backing off'' approach succeeds in answering95 % of the time and achieving 81.1% precision - -  a reductionof 44.4% in the baseline rror rate.We have recently begun to investigate the disam-biguation of more complex coordinations of the form\[NP noun1 noun2 and noun3 noun4\], which permit five pos-sible bracketings:(7) a. freshman ((business and marketing) major)b.
(food (handling and storage)) proceduresc.
((mail fraud) and bribery) chargesd.
Clorets (gum and (breath mints))e. (baby food) and (puppy chow)These bracketings comprise two groups, those that conjoinnoun2 and noun3 (a-c) and those that conjoin noun2 andnoun4 (d-e).
Rather than tackling the five-way disambigua-tion problem immediately, we began with an experimentaltask of classifying anoun phrase as belonging to one of thesetwo groups.We examined three classification strategies.
First, we usedthe form-based strategy described above.
Second, as before,we used a strategy based on semantic similarity; this time,however, selectional ssociation was used to determine the cziin equation (5), incorporating modifier-head relationships intothe semantic similarity strategy.
Third, we used "backing off"(from form similarity to semantic similarity) to combine thetwo individual strategies.
As before, one set of items was usedfor development, and another set (89 items) was set aside fortesting.
As a baseline, results were evaluated against asimpledefault strategy of always choosing the group that was morecommon in the development set.STRATEGY I ANSWERED (%) PRECISION (%) IDefault I 100.0 44.9 IForm I 40.4 80.6Meaning I 69.7 77.4Backing off I 85.4 81.6 IIn this case, the default strategy defined using the developmentset was misleading, leading to worse than chance precision.However, even if default choices were made using the biasfound in the test set, precision would be only 55.1%.
Theresults in the above table make it clear that the strategies usingform and meaning are far more accurate, and that combiningthem leads to good coverage and precision.The pattern of results in these two experiments demonstratesa significant reduction in syntactic misanalyses for this con-struction as compared to the simple baseline, and it confirmsthat form, meaning, and modification relationships all playa role in disambiguation.
In addition, these results confirmthe effectiveness of the proposed efinitions of selectionalpreference and semantic similarity.4.2.
Prepositional Phrase Attachment 6Prepositional phrase attachment represents another importantform of parsing ambiguity.
Empirical investigation \[ 14\] sug-gests that lexical preferences play an important role in disam-biguation, and Hindle and Rooth \[5\] have demonstrated thatthese preferences can be acquired and utilized using lexicalco-occurrence statistics.
(8) a.
They foresee little progress in exports.b.
\[VP foresee \[NP little progress \[PP in exports\]\]\]c. \[VP foresee \[NP little progress\] \[PP in exports\]\]Given an example such as (8a), Hindle and Rooth's "lexi-cal association" strategy chooses between bracketings (8b)and (8c) by comparing Pr(in~foresee) with Pr(inlprogress )and evaluating the direction and significance of the differencebetween the two conditional probabilities.
The object of thepreposition is ignored, presumably because the data would befar too sparse if it were included.As Hearst and Church \[4\] observe, however, the object of thepreposition can provide crucial information for determiningattachment, asillustrated in (9):(9) a. Britain reopened its embassy in December.b.
Britain reopened its embassy in Teheran.6This section reports work done in collaboration with Marti A. Hearst.281Hoping to overcome the sparseness problem and use this infor-mation, we formulated a strategy of"conceptual ssociation,"according to which the objects of the verb and preposition aretreated as members of semantic lasses and the two potentialattachment sites are evaluated using class-based rather thanlexical statistics.The alternative attachment sites-- verb-attachment a d noun-attachment - - were evaluated according to the followingcriteria:vscore = freq(v, PP)I(v;PP) (6)nscore = freq(classl,PP)I(classl;PP) (7)where PP is an abbreviation for (preposition,class2), andclass 1 and class2 are classes to which the object of the verb andobject of the preposition belong, respectively.
These scoreswere used rather than conditional probabilities Pr(PP \[ v) andPr(PP \] class 1) because, given a set of possible classes to useas class2 (e.g.
export is a member of (export), (commerce),(group_action), and (human_action)), conditional probabilitywill always favor the most general class.
In contrast, com-paring equations (6) and (7) with equation (4), the verb- andnoun-attachment scores resemble the selectional ssociationof the verb and noun with the prepositional phrase.Because nouns belong to many classes, we required someway to combine scores obtained under different classifica-tions.
Rather than considering the entire cross-product ofclassifications for the object of the verb and the object of thepreposition, we chose to first consider all possible classifi-cations of the object of the preposition, and then to classifythe object of the verb by choosing classl so as to maximizeI(classl ;PP).
For example, sentence (8a) yields the followingclassifications:CLASS1(situation)(rise)(advance)(advance)\[ PP NSCORE VSCORE \[in (export) 67.4 39.8in (commerce) 178.3 23.8in (group-action) 104.9 19.9in (act) 149.5 40.6The "conceptual ssociation" strategy merges evidence fromalternative classifications in an extremely simple way: byperforming a paired samples t-test on the nscores and vscores,and preferring attachment to the noun if t is positive, and tothe verb if negative.
A combined strategy uses this preferenceif t is significant at p < .
1, and otherwise uses the lexicalassociation preference.
For example (8a), t(3) = 3.57, p <.05, with (8b) being the resulting choice of bracketing.We evaluated this technique using the Penn Treebank WallStreet Journal corpus, comparing the performance of lexicalassociation alone (LA), conceptual ssociation alone (CA), andthe combined strategy (COMBINED) on a held-out set of 174ambiguous cases.
The results were as follows:I \[ LA \[ CA \[ COMBINED I1% C?rrect 181"6177"6\] 82.2 IWhen the individual strategies were constrained to answeronly when confident (Itl > 2.1 for lexical association, p < .1for conceptual ssociation), they performed as follows:I STRATEGY \[ Answered (%)I Precision (%)\[LA 192.8 I CA 67.2 84.6Despite the fact that this experiment used an order of mag-nitude less training data than Hindle and Rooth's, their lex-ical association strategy performed quite a bit better than inthe experiments reported in \[5\], presumably because this ex-periment used hand-disambiguated rather than heuristicallydisambiguated training data.In this experiment, the bottom-line performance of the con-ceptual association strategy is worse than that of lexical asso-ciation, and the combined strategy ields at best a marginalimprovement.
However, several observations are in order.First, the coverage and precision achieved by conceptual s-sociation demonstrate some utility of Class information, sincethe lexical data are impossibly sparse when the object of thepreposition is included.
Second, a qualitative valuation ofwhat conceptual ssociation actually did shows that it is cap-turing relevant relationships for disambiguation.
(10) To keep his schedule on track, he flies two per-sonal secretaries in from Little Rock to augmenthis staff in Dallas.For example, augment and in never co-occur in the train-ing corpus, and neither do staff and in; as a result, the lexicalassociation strategy makes an incorrect choice for the ambigu-ous verb phrase in (10).
However, the conceptual ssociationstrategy makes the correct choice on the basis of the followingclassifications:CLASS1 PP(gathering) in (dallas)(people) in (urban_area)in (region) (personnel)(personnel) in (geographical.area)in (city)in (location)NSCORE \] VSCORE38.18 45.541200.21 28.46314.62 23.38106.05 26.801161.22 28.61320.85 22.83(people)(personnel)Third, mutual information appears to be a successful way toselect appropriate classifications for the direct object, given aclassification of the object of the preposition.
For example,despite the fact that staff belongs to 25 classes in WordNet- -  including (musical_notation) and (rod), for instance-- theclasses to which it is assigned in the above table seem contex-tually appropriate.
Finally, it is clear that in many instances282the paired t-test, which effectively takes an unweighted av-erage over multiple classifications, is a poor way to combinesources of evidence.In two additional experiments, we examined the effect ofsemantic lasses on robustness, ince presumably a domain-independent source of noun classes hould be able to mitigatethe effects of a mismatch between training data and test data.In the first of these experiments, we used the WSJ trainingmaterial, and tested on 173 instances from Associated Pressnewswire, with the following results:\[ I LA \[CA COMBINED \]I% Correct 169.9172.3 72.8 II STRATEGY I ANSWERED (%) PRECISION (%)LA I 31.8 80.0CA I 49.7 77.9In the second experiment, we retained the test material fromthe WSJ corpus, but trained on the Brown corpus material inthe Penn Treebank.
The results were as follows:I I LA I CA I c?M INED II% Correct I 77.6 I 73.6 I 79.3 ISTRATEGY I ANSWERED (%) I PRECISION(%) ILA 35.6 85.5 II CA 59.2 81.6These additional experiments demonstrate large increases incoverage when confident (55-65%) with only moderate de-creases in precision (< 5%).
Overall, the results of the threeexperiments seem promising, and suggest hat further workon conceptual association will yield improvements to disam-biguation strategies using lexical association alone.5.
ConclusionsIn this paper, we have used a knowledge-based conceptualtaxonomy, together with corpus-based lexical statistics, toprovide new formalizations of selectional preference and se-mantic similarity.
Although a complete characterization fthese and other semantic notions may ultimately turn out torequire a full-fledged theory of meaning, lexical-conceptualrepresentation, and inference, we hope to have shown that agreat deal can be accomplished using a simple semantic rep-resentation combined with appropriate information-theoreticideas.
Conversely, we also hope to have shown the utilityof knowledge-based semantic lasses in arriving at a statis-tical characterization f linguistic phenomena, s comparedto purely distributional methods.
A detailed comparison ofknowledge-based and distributionally-derived word classes isneeded in order to assess the advantages and disadvantages ofeach approach.
"Every way ambiguous" constructions form a natural class ofpractical problems to investigate using class-based statisticaltechniques.
The present results are promising, and we are ex-ploring improvements tothe particular algorithms and resultsillustrated here.
In future work we hope to investigate otherambiguous constructions, and to explore the implications ofselectional preference for word-sense disambiguation.References1.
Brown, E, V. Della Pietra, E deSouza, J. Lai, and R. Mercer,"Class-based N-gram Models of Natural Language," Compu-tational Linguistics 18(4), December, 1992.2.
Church, K. W. and R. Patil, "Coping with Syntactic Ambiguityor How to Put the Block in the Box on the Table," AmericanJoumal of Computational Linguistics, 8(3-4), 1982.3.
Good, I.J., "The Population Frequencies of Species and theEstimation of Population Parameters," Biometrika 40(3 and4), pp.
237-264, (1953).4.
Hearst, M. A. and K. W. Church, "An Investigation ofthe Useof Lexical Associations for Prepositional Phrase Attachment,"in preparation.5.
Hindle, D., "Noun Classification from Predicate-ArgumentStructures," Proceedings of the 28th Annual Meeting of theAssocation of Computational Linguistics, 1990.6.
Hindle, D. and M. Rooth, "Structural Ambiguity and LexicalRelations," Proceedings of the 29th Annual Meeting of theAssociation for Computational Linguistics, 1991.7.
Kurohashi, S. and M. Nagao, "Dynamic Programming Methodfor Analyzing Conjunctive Structures in Japanese," Proceed-ings of COLING-92, Nantes, France, August, 1992.8.
Miller, G. A., "WordNet: An On-Line I.,exical Database," In-ternational Journal of Lexicography 3(4), 1990.9.
Pereira, Femando and Naftali Tishby, "Distributional Similar-ity, Phase Transitions and Hierarchical Clustering," presentedat the AAAI Fall Symposium on Probabilistic Approaches toNatural Language, Cambridge, Massachusetts, October, 1992.10.
Resnik, Philip, "WordNet and Distributional Analysis: AClass-based Approach to Lexical Discovery," AAAI Workshopon Statistically-based NLP Techniques, San Jose, California,July, 1992.11.
Resnik, Philip, "Selectional Preference and Implicit Ob-jects," CUNY Sentence Processing Conference, Amherst, Mas-sachusetts, March, 1993.12.
Schuetze, Hinnch, "Word Space," in Hanson, S. J., J. D.Cowan, and C. L. Giles (eds.)
Advances in Neural Informa-tion Processing Systems 5,Morgan Kaufmann, to appear.13.
Weischedel, R., M. Meteer, R. Schwartz, and J. Palmucci,"Coping with Ambiguity and Unknown Words through Proba-bilistic Models," DARPA workshop, 1989.14.
Whittemore, G., K. Ferrara,and H. Brunet, "Empirical Studyof Predictive Powers of Simple AttachmentSchemes for Post-modifier Prepositional Phrases," Proceedings of the 28th An-nual Meeting of the Assocation of Computational Linguistics,1990.15.
Yarowsky, David, "One Sense Per Collocation," this volume.16.
Zemik, Uri, ed., Lexical Acquisition: Using On-line Resourcesto Build a Lexicon, Lawrence Erlbaum, 1991.283
