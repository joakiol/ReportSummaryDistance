Orthographic Co-Reference Resolution Between Proper NounsThrough the Calculation of the Relation of "Replicancia"Pedro AMO, Francisco L. FERRERAS, Fernando CRUZ and Saturnino MALDONADODpto.
de Teorfa de la Serial y ComunicacionesUniversidad e Alcal~iCrta.
Madrid-Barcelona km.
33,600Alcalfi de Henares-Madrid, SPAIN{ pedro.amo, tsflf, femando.cruz } @alcala.es; smbascon @euitt.upm.esAbstractNowadays there is a growing researchactivity centred in automated processing oftexts on electronic form.
One of the mostcommon problems in this field is co-reference resolution, i.e.
the way of knowingwhen, in one or more texts, differentdescriptions refer to the same entity.A full co-reference r solution is difficult toachieve and too computationallydemanding; moreover, in many applicationsit is enough to group the majority of co-referential expressions (expressions with thesame referent) by means of a partialanalysis.
Our research is focused in co-reference resolution restricted to propernames, and we part from the definition of anew relation called "replicancia".Though replicancia relation does notcoincide extensionally nor intensionallywith identity, attending to the tests we havecarried out, the error produced when we takethe replicantes as co-referents i admissiblein those applications which need systemswhere a very high speed of processing takespriority.1 IntroductionThe proliferation of texts on electronic formduring the last two decades has livened up theinterest in Information Retrieval and given rise tonew disciplines uch as Information Extraction orautomatic summarization.
These three disciplineshave in common the operation of NaturalLanguage Processing techniques (Jacobs andRau, 1993), which thus can evolve synergically.Identification and treatment of noun phrases isone of the fields of interest shared both byInformation Retrieval and Information Extraction.Such interest must be understood within the trendto carry out only partial analysis of texts so as toprocess them in a reasonable time (Chinchor etal., 1993).The present work proposes a new instrumentdesigned for the treatment of proper nouns andother simple noun phrases in texts written inSpanish language.
The tool can be used both inInformation Retrieval and Information Extractionsystems.1.1 Information Retrieval.Information Retrieval systems aim to discriminatebetween the documents which form the system'sentry, according to the information eed posed bythe user.
In the field of Information Retrieval wecan find two different approaches: informationfiltering -or routing- and retrospective, also"known as ad hoc.
In the first modality, theinformation need remains fixed and thedocuments which form the entry are always new.The ad hoc modality retrieves relevant texts froma relative static set of documents but, in contrast,admits changing information eeds (Oard, 1996).Information Retrieval systems make uprepresentations of the texts and compare themwith the representation of the information needraised by the user.
The representation form mostcommonly used is a vector whose coordinatesdepend on the terms' frequency of occurrence,where such "terms" are elements of the textrepresented which can coincide with words,stems or words associations (n-grams) (Evansand Zhai, 1996).At the present ime designers try to enrich thesets of terms used in the representations with61noun phrases or parts of them as, for example,proper names.
Thompson and Dozier conclude in(Thompson and Dozier, 1997) that: first, therecognition of proper nouns in the texts can bedone with remarkable effectiveness; second,proper nouns occur frequently enough as well asin queries ~to warrant heir separate treatment indocument retrieval, at least when working withcase law documents or press news; third, theinclusion of proper nouns as terms in thedocuments' representations can improveinformation retrieval when proper nouns appearin the query.As Gerald Salton has noted (Salton and Allan,1995), in the field of information retrieval todetermine the meaning of words is not asimportant as to ascertain if the meaning of theterms within the detection eed coincide or notwith the meaning of the terms in each document.When the terms are proper nouns we shall nottalk about meaning but of reference, so that it willbe interesting to know if the referents of theproper nouns included in the query coincide ornot with the referents of the proper nouns whichappear in each document.Referents' resolution can not be done withoutan additional context (Thompson and Dozier,1997).
Nonetheless, in an Information Retrievalprocess we can not count on the additionalinformation of a data base register, such aspersonal identification number, profession or age.Nor can we make a linguistic analysis asthorough as can be done in a languageunderstanding system or in an InformationExtraction system.
Because of these reasons, theidentification of proper nouns as co-references isusually confined to verify if the superficial formsof the two nouns under examination are closeenough as to suppose that both of them refer tothe same individual or entity.1.2 A im of the WorkCo-reference resolution is difficult because itdemands the establishment of relationshipsbetween linguistic expressions -for example,proper names- and the entitys denoted.
So as toestablish the co-reference between twoexpressions, we must identify first the referent ofeach one of them and then check if both coincide.1 "Query" is the translation of the user's informationneed into a format appropriate for the system.In this work we propose a tool to resolve propernouns co-reference, based only on the exam ofthose nouns' superficial form.
To carry out thisexam we have defined, in Section Two, therelation of replicancia.
This relation links pairs ofnouns -replicantes- which show certainresemblance between their superficial forms anduse to have the same referent.
In Section Threewe propose an algorithm for the calculation ofreplicancia.
This algorithm has the ability to learnpairs of replicantes and also allows to manuallyintroduce pairs of proper nouns with the samereferent and which register a high frequency ofoccurrence, although their orthographic forms donot bear any similarity at all.
Section Fourcontains the results of the evaluation of co-reference resolution between proper nouns usingonly the relation of replicancia.
Finally, inSection Five we draw some conclusions.2.1 Definition of Replicancia2.2 AntecedentThe need to develop an algorithm capable toresolve in a simple way to resolve proper nounsco-reference has been pointed-out by severalauthors.
Among them, we can quote:Dragomir Radev, in (Radev and McKeown,1997), includes, between the forthcomingextensions of PROFILE system, an algorithm"...that will match different instances of the sameentity appearing in different syntactic forms -e.g.to establish that 'PLO' is an alias for de 'PalestineLiberation Organization'..."The second antecedent is (Bikel et al, 1998),where Bikel and his collaborators say about thefuture improvements of their own system:"... We would like to incorporate the followinginto the current model: ...an aliasing algorithm,which dynamically updates the model (where e.g.IBM is an alias of International BusinessMachines)..."2.2 DefinitionWe call replicancia to the relation which linksproper nouns which presumably refer to the sameentity if we attend exclusively to the nounsthemselves, without paying attention to theirrespective contexts nor to which their actualreferents may be.
We shall call replicantes thenouns which maintain a relation of replicanciabetween them.
We also assign the label62rep l i cante  2 to the predicate which resolves thereplicancia relation.Replicancia is a diadic, reflexive, simetric, butnot necessarily transitive relation.
It is reflexivebecause every noun is a replicante of itself;simetric because if noun A is a replicante of nounB, noun B will also be a replicante of noun A; itis not transitive because the replicancia relation isestablished attending only to the nouns form, notto their referents, and it is possible that the samenoun denotes two or more entities depending onits context of utilization.
For example, let us saythat noun A designates to Jos6 Salazar Fernfindez,noun B to JSF and name C to Juan SfinchezFigueroa; in this case A is a replicante of B and Ba replicante of C, but A is not a replicante of C.Not being a transitive relation, the replicancia isneither an equivalence relation and does notinduce a set of equivalence classes as it had beendesirable (Hirsman, 1997).We do not ask the predicate replicante torecognize as replicantes the pseudonyms,diminutives, nicknames, abreviations and familiarnames, although the most frequent tokens can bemanually introduced as if they had previouslybeen learned by the system.Two proper nouns are replicantes whenany of the following assumptions i satisfied:a) Both nouns or their canonic forms areidenticaP, as in Josd Maria Aznar and JoseMaria Aznar.b) One of them coincides with the initials ofthe other, be it in singular as in Uni6nEuropea and UE, or in plural as EstadosUnidos and EE UU.
We also admit nounswith nexus as in the case of Boletin Oficialdel Estado and BOE.c) The shorter noun is contained in the longerone and among the lexemes not shared thereare no nexes.
Under this rule it is admittedthat Julio P6rez de Lucas is a replicante ofPgrez de Lucas; nevertheless, Caja deMadrid is not a replicante of Madridbecause the part not shared, Caja de,includes the nexus de.d) Every word of the shorter noun, N2, is aversion of some word included in the longernoun, N1, in the same relative order,although there can be words in N1 whichhave no version in N2.
A word P2 is aversion of another word P1 when theircanonic forms are identical, when P2 is theinitial of P1 or when the initials of bothcoincide 4.
According to this fourth rule, thenoun JM Pacheco is a replicante of JuanManuel Pacheco Fern6ndez; to verify it wecompare the lexemes of the longer noun, oneby one, with the lexemes which form thesecond name.
In the comparison of Juanwith JM Pacheco we identify the letter J asa version of Juan, after which remains MPacheco as a rest.
In the comparisonbetween Manuel and M Pacheco we identifythe letter M as a version of Manuel, afterwhich remains Pacheco as the new rest thatcan be identified with the same lexeme inthe first noun.
As the new rest is empty, wedecide that both names are replicantes ofeachother although in the first noun there arelexemes left unmatched.This definition of replicante makes itpossible to identify the following list of nouns asreplicantes of the first:\[Jos~ Luis Martfnez L6pez, JL Marffnez, J.L.Martfnez, J Martfnez, Luis Martlnez, Jos~Marffnez, Martfnez, JL M L\]3 Replicancia Calculation AlgorithmOnce the replicancia relation is defined, we are ina position to present the algorithm devised tocalculate it.
Although the algorithm has beendeveloped in Prolog, we are going to expose it ina pseudocode, similar to that used in PASCAL,which uses the following notation: the symbols",", "/" and "7" represent the conjunction,disjunction and negation of terms, respectively;the brackets "(...)" delimitate optional units;braces "{... }" are used to establish the prelation oflogical operators; "::=" is the symbol chosen for2 We will use Courier New font to write the names ofthe predicates defined in Prolog which take part inthe replicancia calculation algorythm.3 The canonic form of a proper noun is itsrepresentation in small letters without accentuation.4 In the last case the whole word P1 in the longernoun is assimilated to only the initial ' of P2.
The restof the letters in P2 must have some correspondencein the first noun so that we can consider both nounsas replicantes.63the definition and ":=" refers to the assignation ofvalues.The calculation of the replicancia relation canimpose a heavy computation burden if it is notsomehow limited.
The variety of forms in whichtwo nouns can be mutually replicantes forces usto cover a long distance before being able todecide that two candidates are linked by suchrelation.
That is why we have provided ouralgorithm with two instruments to reduce thecomputation burden; the first is its ability to learn,which permits the automatic reation of a database of pairs of proper nouns mutuallyreplicantes; the second is a filter which, based ina fast analysis of the initials of the nouns undercomparison, reject most of the pairs of nouns thatare not mutually replicantes.
The main predicatecan be expressed as follows:rep l i cante(N i ,N2)  ::=N lc  = N2c /rep l i cante_guardado(N i ,N2) /f i l t ro (N I ,N2) ,res to_ rep l i cante(N i ,N2) ,guarda_rep l i cante(N i ,N2) .where Nxc represents the canonic form of nounNx and predicate res to  rep l i cante  is definedby:res to_ rep l i cante(N i ,N2)  ::=s ig las (N I ,N2)  /s in_prep(D l2 ) ,{N2 = N1 - DI2vers ion(N i ,N2)}  /supr ime_nexos(N i ,N ls ) ,  {N2N ls  - D I2  / vers ion(N ls ,N2)} ./where Nx-Ny represents he lexemes equency ofnoun Nx not present in noun Ny and D12 is NI-N2; predicate sin_prep(Nx) is true for the nounsNx which do not include prepositions; suprime-nexos is the result of eliminating the noun of thelexemes in N1 which do not begin with a capitalletter; finally, predicate version(Nx,Ny) issatisfied if every lexeme of Ny is aversion_palabra of any of the lexemes of Nxwithout any alteration in the relative order ofoccurrence of each homologous lexeme, as wehave already indicated in section 2.In order to evaluate this algorithm we havedesigned the experiment described in Section 4.4 Experiment and ResultsWe have defined the replicancia relation as aninstrument for the resolution of co-referencebetween proper nouns, although we are perfectlyaware of its limitations to identify as co-referentials nouns which are not linked by anorthographic relation, as occurs with nicknamesand familiar names (Josd and Pepe, for example).In order not to conceal this limitations we havedesigned an experiment o evaluate the co-reference between proper nouns instead ofevaluating the algorithm for the replicanciaresolution, because this relation is only usefulinasmuch it is capable to resolve co-referencebetween proper nouns.In the context of natural anguage processingsystems evaluation is very important o decidewhich collection of texts is going to be used.
Thecurrent trend is not to use texts specificallyprepared for the evaluation, but normal texts, thatis to say, similar to the texts which the systemwill use in its normal operation.
We have chosendocuments available in the World Wide Web.In our evaluation we will use a corpusmanually processed composed by 100 documentswith an extension scarcely over 1 MB, HTMLcode included.
The documents come from fivedifferent newspapers, all of them spanish andavailable on electronic form.
The newspapers, inalphabetical order, are: ABCe, El Mundo, E1 PalsDigital, El Perirdico On Line and LaVanguardia Electrrnica.
The extension of thedocuments varies between 4kB and 25 kB, beingthe average around 10kB.
The utilisation of thesevariety of sources to obtain the documents whichform the Corpus is very advisable, because peoplewho work for the same newspaper tend to writesimilarly; the choosing of different documentsources brings us closer to the style diversitycharacteristic of the texts available in the WorldWide Web.The result of co-reference resolution is thegrouping of the document's selected objects -theproper nouns- in classes.
The human analystdesigns a template which includes the differentinstances of the same entity present in thedocument, and then compares it with the system'sresponse, being this another grouping of objectsin classes of co-reference.
From this comparisonwe draw the system's quality evaluation.The evaluation proceeding chosen is based onthe measures used in MUC conferences (MUC-7,641997) (Chinchor, 1997) (Hirschman, 1997).
InMUC evaluations, the results of co-referenceanalysis are classified according to threecategories:COR - Correct.
A result is correct when thereis full coincidence between the contents of thetemplate and the system's response.MIS  - Missing.
We consider a result absentwhen it appears in the template but not in theanswer.SPU - Spurious.
We consider a result spuriouswhen it does not appear in the templatealthough it is found in the system's response.With the cardinals of these three classes weobtain two intermediate magnitudes which will beuseful to calculate merit figures.
Thesemagnitudes areS:POS - Possible.
The number of elementscontained in the template that contribute to thefinal scoring.
It is calculated through thefollowing expression:POS = COR + MISACT - Actual.
The number of elementsincluded in the system's response.
It iscalculated as follows:ACT = COR + SPUOnce we have gathered the data relative to theclasses of responses, we are prepared to calculatethe measures of the system's quality.
The metricschosen are the ones normally used in InformationRetrieval systems:REC - Recall.
A quantity measure of theelements of the answer-key included in theresponse of the system.
Its expression is:REC -COR+O,5.PARPOSPRE - Precision.
A measure of the quantity ofelements of the response included also in thetemplate.
Its expression is:PRE = COR + 0,5.
PARACTF Measure - A compound measure introducedby van Rijsbergen (Rijsbergen, 1980).
We useit with the control parameter B= 1 toguarantee the same weight for recall andprecision.
Its general expression is:F = (\[3z + 1).
PRE.
RECf l z .PRE+RECFrom the cardinals of classes COR, MIS andSPU we obtain measures REC, PREy  F, the lastone with parameter B= 1.
With all these data wefill in table I- 1 of Annex I, where each line showsthe metrics and data of a document.
Table 4.1shows overall results.We have carried out the evaluation of thecalculation of replicantes bearing in mind the usewe intend to make of that relation.
We havecounted the cardinals of the co-reference classesamong the proper nouns included in the text onlyin those classes whose elements adopted morethan one form.
Let us think, for example, in a textwhich had three classes of co-reference formedby the names6:\[(Madrid, 2)\]\[(Jos6 Maria Aznar, 1), (Aznar, 3)\]\[(Sumo Pontffice, 2)\], (Juan Pablo(Karol Wojtyla, 1)\]II, 2),The first class refers to the entity in a singleway; the second class includes two ways ofreferring to the entity and the third one three.
Forthe evaluation of co-reference between ouns weconsider that there are four references to thesecond entity and five to the third, which makes atotal of nine nouns, although we know that thesystem is not prepared to identify as co-referentials the elements included in the thirdclass.
So, the result of the evaluation would be:5 When the names of these measures appear inarithmetical expressions, they must be taken as thecardinals of the respective classes.6 Each name shows the number of times it appears inthe relevant text.65POS =9, ACT=9, COR=6, MIS=3, SPU=3 because of the nine elements subject ofconsideration, (POS), the system has recognizedTable 4.1.
Summary of proper nouns core terence analysisDOCUMENT POS ACT COR MIS SPUAB1501 9 8 7 2 1ZEDILLO 20 20 18 2 2TOTAL 1523 1512 1296 227 21615 1512 12,512,93 13362 352181 181434 432350 354196 19313 210 112 3,3288 74158 23377 57289 61184 12MeanMedianStd.
DeviationABCEl MundoEl PalsEl Peri6dicoLa VanguardiaREC PRE F77,8 87,5 82,490,0 90,0 90,085,1 85,7 85,42!
84,6 86,21 93,3 943,3 20,2 18,664 79,6 81,823' 87,3 87,355 86,9 87,365 82,6 81,69 93,9 95,385,093,3319,1980,787,387,182,194,6nine (ACT) -six of them correctly located in theirrespective classes (COR), three located in twospurious classes (SPU) and three missing fromtheir correct classes (MIS).Briefly, we evaluate the resolution of co-reference between proper names without takinginto account how the problem is solved by ouralgorithm; this way, the evaluation does notreflect the quality of the algorithm in calculatingthe replicancia, but the resolution of thecoreference between proper nouns instead, whichis the aim pursued.5 ConclusionThe algorithm conceived oes not calculate theco-reference, but the replicancia between propernames instead.
Replicancia nd co-reference donot coincide neither extensionally norintensionally.
As a consequence, referents ofnouns linked by the replicancia relation are notbound by an identity relation, among other thingsbecause replicancia i s  not an equivalencerelation, meanwhile coreference it is.
The result isthat one class of replicancia may contain nameswhich refer to different entities and, however, notcontain names which refer to the entity associatedto the class.Despite what it has been said, as thecalculation of replicancia is much more simplethan the calculation of coreferences, it isinteresting, and even convenient, to calculatereplicancia between ouns in limited contexts.Table I-1 in Annex I shows the results of theexperiment.
Under the line showing the totalfigures, we have added three lines with theaverage, median and mean deviation of the dataobtained with each of the 100 documentsanalyzed.
We can notice that the median takevalues between eight and nine points aboveaverage, which means that in most documents theco-reference between proper nouns issuccessfully decided.
The negative burden comesfrom the variance, close to 25% of the recall andprecision total values, which, along with thedifference between average and median, forces usto think that most of mistakes are concentrated insome documents, in which precision and recallcan be much smaller than expected.In Figure 5.1 we have represented thehistogram of the group of values obtained for Fmeasure, values included in the right column intable I-1.
It can be noted that more than half ofthe documents ubject o evaluation obtain an F-measure over 0.9, and more than two thirds areover 0.8.The statistical analysis of the system's qualitymeasures is not enough to guarantee therepresentativity of the sample.
It is also necessaryto analyze its composition.
The 100 documents ofthe sample were obtained aleatorily (randomchoice) during January 1998.
The five sourcesused are different but all of them are relevantnewspapers.
Moreover, we have selected newsunder two different sections: domestic andinternational.
The diversity of the documentswhich form the sample and the homogeneity ofthe measures obtained strengthen the hypothesiswhich states the results validity.66603020100 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.5 15 25 35 45 55 65 75 85 95Figure 5.
1 Histogram of the values ofF-measureThe last five linles of table I-1, Annex I, registerthe total results distributed according to thedocuments origin.The mistakes detected are mainly due to twocauses: the presence of co-referents which are notreplicantes and the presence of replicantes whichare not co-referents, as sometimes it occurs withinitials.
Other errors, not attributable to thealgorithm, are due to faults in the automaticsystem we have used for the extraction of propernouns.ReferencesBikel, D., Miller, S., Schwartz, R. and Weischedel,R.
(1998): "Nymble: a High-Performance L arningName-finder".
March 1998.
In http://xxx.lanl.gov/ps/cmp-lg/9803003Chinchor, N. (1997): MUC-7 Named Entity TaskDefinition.
Dry Run Version.
Versi6n 3.5.
Sep.1997.
In http://www.muc.saic.corn/Chinchor, N., Hirschman, L. and Lewis, D. (1993):"Evaluating Message Understanding Systems: AnAnalysis of the ~Third Message UnderstandingConference (MUC-3)".
Computational Linguistics,1993, Vol.
19, 1~.
3.Evans, D. and Zhai, C. (1996): "Noun-PhraseAnalysis in Unrestricted Text for InformationRetrieval".
May 1996.
In http://xxx.lanl.gov/ps/cmp-lg/9605019Hirschman, L. (1997): MUC-7 Coreference TaskDefinition.
Versi6n 3.0.
Julio 1997.
Inhttp://www.muc.saic.com/Jacobs, P. and Rau, L. (1990): "SCISOR: ExtractingInformation from On-line News".
Communicationsof the ACM, noviembre 1990, Vol.
33, N'-'.
11.MUC-7 CFP(1997): "Seventh Message Under-standing System and Message Under-standingConference (MUC-7).
Call For Partici-pation".1997.
In ftp://ftp.muc, saic.com/pub/MUC/participation/call-for-participationOard, D. W. (1996): Adaptive Vector Space TextFiltering for Monolingual and Cross-LanguageApplications.
PhD thesis, University of Maryland,College Park, August 1996. http://www.ee.umd.edu/medlab/filter/papers/thesis.ps.gz.Radev, D. and McKeown, K. (1997): "Building aGeneration K.nowledge Source using Internet-Accessible Newswire".
Feb. 1997.
Enhttp://xxx.lanl.gov/ps/cmp-lg/9702014Rijsbergen, C. (1980): Information Retrieval.Butterworths.
Londres, 1980.Salton, G. and Allan, J.
(1995): "Selective Text, Utilization and Text Traversal".
Int.
J. Human-Computer Studies (1995) 43, pp 483-497.Thompson, P. and Dozier, C. (1997): "NameSearching and Information Retrieval".
June 1997.In http://xxx.lanl.gov/ps/cmp-lg/970601767Appendix  I. Evaluat ion dataTable I- 1 Resu l ts  o f  co - re fer ,r )  pos  I ACT.COR iMt~qlsPt tlrE(71PRF.I F1 92 31 293 94 0.5_ .
.
.
.
.
.
.
0 .
.
.
.
.
.o6 47 0 08 l l  109 2 2l g_  .
.
.
!
J _  .
.
.
.
1_!11 16 1512 15 1513 12 12114 7 51_5!
.
.
.
.
.
_4_ .
.
.
.
.
_416 517 15 1518 25 2519 5 4.29 .
.
.
.
.
!_8_ .
.
.
.
1._821 21 2122 5 523 i 9 924 18 20.2_5_.
~ .
.
.
_2_4.
.
.
2_426 12 1327 17 1728 19 1929  4 439 .. .
.
.
.
_5_ .. .
.
.31 15 1532 15 1533 22 2434 15 143_5_ .
.
.
.
.
.4_4____4__5.36 31 32373839.49.
.__1._5 .
.
.
.
1__5414243444.5_ .
.
.
.
.
.1.0_ .
.
.
.
1..e~6~7~8~950.
29 3(8 7 2 1 77.8 87.5 82.,124 7 5 77,4 82,~ 80,C9 8 1 1 88,9 885 88S.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.. .
.
.
.
.
.
.
.
.
.
.
.
.
.
\] _ _ _1 1 3 13 25,0 100 40.
(7 4 3 63,6 70,0 66,7 I0 13' 100 100 100J#.
.
.
.
.
.
!
.
.
.
.
.
1 .9_9.
,9 .
.
99,9_.
9_0,9_7~ 14 13 12,5 13,3 12,915 0 ?
100 100 10010 2 ~ 83,3 83,3 83,34 3 1 57,1 80,13166,7.
.4  .
.
.
.
9.  .
.
.
.
O_._J_OP___!_O_~ __1_0_05 0 0 100 1013 101315 0 0 100 lOC 101312 13 13 48,0 48?
48?2 3 2 40,0 50?
44A18 0 13 100 10( 10(~/i - -6  .
.
.
.
6 - - - i66 - i i56  - i iS~5 0 13 100 100 10(0 el 100 100 10(1"~ 1 3 94,4 85,0 89,.*.~f.
.
.
.
.
_4 .
.
.
.
4 .
.83 ,3__83 ,3 .
.83?1( 2 3 83,3 76,9 80,(17 0 ?
100 100 10(18 1 1 94,7 94,7 94,~3 1 1 75,0 75,13 75,(_.3 .
.
.
.
2_ .
.
.
.
_2_ .
.6_ 02_  _ 69  g 60_,(15 0 0 100 IOC 10(15 0 0 100 lOC lO(15 7 9 68,2 62,5 65513 2 1 86,7 92,9 89,;3#_ .
.
.
.
_9_ _ .
.
_1_0_ .
.7 9~_5.
.
7_7_ ,~.
7_8_ ~26 5 6 83,9 81,2  82248 48 47 18 8 8 029 27 1~ 10. .
.
.
.
.
.
.
.
.
.
.
.
J_-'.
.
.
.
.
9.16 18 1( 019 19i.
11( ~ 419 19 318 18 16 2. .
.
.
.
.
.
.
.
.
.
.
.
.
6 .
.
.
.
.4.11 8 8 35 ~ 4 120 2( 20 07 7 6 10.
27.
21 97,9 97, g 97,!13 100 100 1018 65,5 70,4 672._ JO_O__.
l.O_O., l_OJ2 100 88,9 94,4 78,9 78,9 78,!3 84,2 84,2 84,12 88,9 88,9 88,!.6_0 ,9 .
.
69 ,0 .
_690( 72.7 1013 84.:1' 80,0 80,13 80,10 100 1013 1011 85,7 85,7 85,3.
93,1 90,?.91,between proper  names  reso lu t ion  7D IpONIACT ICORIMtS I ,gptT I rF .C lp rF .
F u1 12 121 q 3 75.0 75.0 '5~2 10 1~ c 1 90,0 90,0 t0.0I ' 1 83,3 83,3 t3,31 3 6 6 2~ "4 23 23 100 1013 1001 90,0 10C )4,715_ .
.
.
.
_1_o_ .
.
.
.
.
_91 .
.
.
.
.
~ - - - i i - - - i :  .
.
.
.
.
.
.
-~6~ io .o  6 20 201 ~ 40.07 19 17' 1 :7  63,2 70,( 56.7i8 27 271 2z 3 3!
88,9 88,9 ~8.919 6 6 ( 0 0 100 10( 100.0_ .
.
.
.
1_2_ .... _1_2. "
q ..... _5 ..... 5_ .
_ 5_ .8 , 3_ _ _5_ 8, ~ 5.8,3!1 15 16 ( 9 lO 40,0 37,5 38,72 2 2 ; 0 0 100 100 1003 6 6 ?
0 0 100 100 100.41 29 29 2( 9 9 69,0 69,0 59,0.5 ~ 32 32 3: 0 13 100 100 100I 'i 95,5 95,5 95,5 ;9 \[ 14 151 8 42,9 40,t3 41,4'_0__\]__._2_3_ .... _2_3\] 2 2 91,3 91,3 91,3'1 / 35  351- - J :  .
.
.
.
2 .
.
.
.
.
.
.
9~f , -~- -9L~ ~:,,~-'2 7 7 0 0 100 IOC 10(r3 7 8 0 1 100 87,5 93,2'4 21 20 11 11 10 47,6 50,( 48,~'5  .
.
.
.
_36 .
.
.
.
_37.
___2, .
.
.
.
!Q___!_1._7_2_,2__7_02.7__1,7Y6 30 30 2 2 2 93,3 93,3 932Y7 50 50 4 3 3 94,0 94,0 94,(v8 30 28 2 2 13 93,3 100 96,(T9 26 26 2 1 96,2 96,2 965~0__ __ J2  .
.
.
.
!
.
.
.
.
.
1_ .
.
.
.
!
.
.
.
.
.
.
9 !
,7 .
.
.
J _0_0  9_5_,'_,~1 2 2 0 C lO0 lO0 lO(~2 12 12 1 0 C 100 100 10(~4 2 2 1 75,0 75,13 75,(g5 1 66,7 66,7 66,;i#  --\]4 .... i~ .... i .... 6 .... ( --ibO---fOC -\]-Oig7 13 13\] 0 ( 100 lOC 10(g8 4 Z 2 ( 50,0 IOC 66,"g9 8 8 ~ 0 0 100 10?
101~_0_ .
.
.
.
.
9 ..... _9.
.
.
.
.
.
.
.
.
Q ..... Q ._tO_O_.. lgf  _ Jg!0 0 100 10( 1010 0 100 100 1010 0 100 100 1010 0 100 100 101. .
.
.
Q_ .
.
.
.
0 l_O_O___l_O__O __l_O_q0 13 100 100 10~0 13 100 100 1010 13 100 100 1010 C 100 1013 1012 90,0 90,13i 90,'91 6 692 4 493 2 294 17 17 1.95_ .
.
.
.
J9  .
.
.
.
!9.
.
.
.
.
!96 8 897 16 16 198 2 299 510t 20 2 17 Each line stands for a docucment68
