Proceedings of the 53rd Annual Meeting of the Association for Computational Linguisticsand the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 237?242,Beijing, China, July 26-31, 2015. c?2015 Association for Computational LinguisticsWord-based Japanese typed dependency parsing with grammaticalfunction analysisTakaaki Tanaka Nagata MasaakiNTT Communication Science Laboratories, NTT Corporation2-4, Hikaridai, Seika-cho, Soraku-gun, Kyoto, 619-0237, Japan{tanaka.takaaki,nagata.masaaki}@lab.ntt.co.jpAbstractWe present a novel scheme for word-based Japanese typed dependency parserwhich integrates syntactic structure analy-sis and grammatical function analysis suchas predicate-argument structure analysis.Compared to bunsetsu-based dependencyparsing, which is predominantly used inJapanese NLP, it provides a natural wayof extracting syntactic constituents, whichis useful for downstream applications suchas statistical machine translation.
It alsomakes it possible to jointly decide de-pendency and predicate-argument struc-ture, which is usually implemented as twoseparate steps.
We convert an existingtreebank to the new dependency schemeand report parsing results as a baselinefor future research.
We achieved a bet-ter accuracy for assigning function labelsthan a predicate-argument structure ana-lyzer by using grammatical functions asdependency label.1 IntroductionThe goal of our research is to design a Japanesetyped dependency parsing that has sufficient lin-guistically derived structural and relational infor-mation for NLP applications such as statisticalmachine translation.
We focus on the Japanese-specific aspects of designing a kind of Stanfordtyped dependencies (de Marneffe et al, 2008).Syntactic structures are usually represented asdependencies between chunks called bunsetsus.
Abunsetsu is a Japanese grammatical and phono-logical unit that consists of one or more con-tent words such as a noun, verb, or adverb fol-lowed by a sequence of zero or more functionwords such as auxiliary verbs, postpositional par-ticles, or sentence-final particles.
Most publiclyavailable Japanese parsers, including CaboCha 1(Kudo et al, 2002) and KNP 2 (Kawahara et al,2006), return bunsetsu-based dependency as syn-tactic structure.
Such parsers are generally highlyaccurate and have been widely used in variousNLP applications.However, bunsetsu-based representations alsohave two serious shortcomings: one is the discrep-ancy between syntactic and semantic units, and theother is insufficient syntactic information (Butleret al, 2012; Tanaka et al, 2013).Bunsetsu chunks do not always correspond toconstituents (e.g.
NP, VP), which complicates thetask of extracting semantic units from bunsetsu-based representations.
This kind of problem of-ten arises in handling such nesting structures ascoordinating constructions.
For example, thereare three dependencies in a sentence (1): a co-ordinating dependency b2 ?
b3 and ordinary de-pendencies b1 ?
b3 and b3 ?
b4.
In extractingpredicate-argument structures, it is not possible todirectly extract a coordinated noun phrase ?????
?wine and sake?
as a direct object of theverb ???
?drank?.
In other words, we needan implicit interpretation rule in order to extractNP in coordinating construction: head bunsetsub3 should be divided into a content word ?
anda function word ?, then the content word shouldbe merged with the dependent bunsetsu b2.(1)b1???nondadrank|b2???wainwine?toCONJ|b3?sakesake?noGEN|b4??
?risutolist?A list of wine and sake that (someone) drank?Therefore, predicate-argument structure analysisis usually implemented as a post-processor ofbunsetsu-based syntactic parser, not just for as-signing grammatical functions, but for identifyingconstituents, such as an analyzer SynCha 3 (Iida1http://taku910.github.io/cabocha/.2http://nlp.ist.i.kyoto-u.ac.jp/EN/index.php?KNP.3http://www.cl.cs.titech.ac.jp/?ryu-i/syncha/.237?
/???
?
??
?
?
/?
/??
/??
??
/?fish / fry -ACC eat -PAST may calico / cat?the calico cat that may have eaten fried fish?SUW NN / NN PCS VB AUX P / P / VB / AUX NN / NNLUW NN PCS VB AUX AUX NNFigure 1: A tokenized and chunked sentence.et al, 2011), which uses the parsing results fromCaboCha.
We assume that using a word as a pars-ing unit instead of a bunsetsu chunk helps to main-tain consistency between syntactic structure anal-ysis and predicate-argument structure analysis.Another problem is that linguistically differentconstructions share the same representation.
Thedifference of a gapped relative clause and a gaplessrelative clause is a typical example.
In sentences(2) and (3), we cannot discriminate the two rela-tions between bunsetsus b2 and b3 using unlabeleddependency: the former is a subject-predicate con-struction of the noun ?
?cat?
and the verb ???
?eat?
(subject gap relative clause) while the lat-ter is not a predicate-argument construction (gap-less relative clause).(2)b1?sakanafish?oACC|b2?
?tabeeat?taPAST|b3?nekocat?the cat that ate fish?(3)b1?sakanafish?oACC|b2?
?tabeeat?taPAST|b3?hanashistory?the story about having eaten fish?We aim to build a Japanese typed depen-dency scheme that can properly deal with syn-tactic constituency and grammatical functions inthe same representation without implicit interpre-tation rules.
The design of Japanese typed depen-dencies is described in Section 3, and we presentour evaluation of the dependency parsing resultsfor a parser trained with a dependency corpus inSection 4.2 Related workMori et al (2014) built word-based dependencycorpora in Japanese.
The reported parsingachieved an unlabeled attachment score of over90%; however, there was no information onthe syntactic relations between the words in thiscorpus.
Uchimoto et al (2008) also proposedthe criteria and definitions of word-level depen-dency structure mainly for annotation of a sponta-neous speech corpus, the Corpus of SpontaneousJapanese (CSJ) (Maekawa et al, 2000), and theydo not make a distinction between detailed syntac-tic functions either..NP..NN.??
?calico cat..IP-REL sbj..AUX.??????may..VP..AUX.?-PAST.VP..VB.??eat.PP-OBJ..PCS.?-ACC.NN.???
?fried fishdobjpobj aux auxrcmod nsubjHead Final type 1 (HF1).NP..NN.??
?calico cat..IP-REL sbj..VP..AUX.??????may..VP..PCS.?-PAST.VB.??eat..PP-OBJ..PCS.?-ACC.NN.???
?fried fishdobjpobj aux aux rcmod nsubjHead Final type 2 (HF2).NP..NN.??
?calico cat..IP-REL sbj..VP..AUX.??????may..VP..AUX.?-PAST.VB.??eat..PP-OBJ..PCS.?-ACC.NN.???
?fried fishdobjpobj auxauxrcmod nsubjPredicate Content words Head type (PCH)?
the calico cat that may have eaten fried fish.
?Figure 2: Example structures in three dependencyschemes.
Boldface words are content words thatmay be predicates or arguments.
Thick lines de-note dependencies with types related to predicate-argument structures.238Category Dep.
typecase (argument) nsubj subjectdobj direct objectiobj indirect objectcase (adjunct) tmod temporallmod locativegapped relative clause rcmod nsubj subject gap relative clausercmod dobj direct object gap relative clausercmod iobj indirect object gap relative clauseadnominal clause ncmod gapless relative clauseadverbial clause advclcoordinating construction conjapposition apposfunction word relation aux relation between an auxiliaryverb and other wordpobj relation between a particleand other wordTable 1: Dependency types (excerpt).We proposed a typed dependency scheme basedon the well-known and widely used Stanford typeddependencies (SD), which originated in Englishand has since been extended to many languages,but not to Japanese.
The Universal dependencies(UD) (McDonald et al, 2013; de Marneffe et al,2014) has been developed based on SD in order todesign the cross-linguistically consistent treebankannotation 4.
The UD for Japanese has also beendiscussed, but no treebanks have been providedyet.
We focus on the feasibility of word-basedJapanese typed dependency parsing rather than oncross-linguistic consistency.
We plan to examinethe conversion between UD and our scheme in thefuture.3 Typed dependencies in JapaneseTo design a scheme of Japanese typed depen-dencies, there are three essential points: whatshould be used as parsing units, which dependencyscheme is appropriate for Japanese sentence struc-ture, and what should be defined as dependencytypes.3.1 Parsing unitDefining a word unit is indispensable for word-based dependency parsing.
However, this is nota trivial question, especially in Japanese, wherewords are not segmented by white spaces in its or-thography.
We adopted two types of word unitsdefined by NINJL 5 for building the BalancedCorpus of Contemporary Written Japanese (BC-CWJ) (Maekawa et al, 2014; Den et al, 2008):Short unit word (SUW) is the shortest token con-veying morphological information, and the longunit word (LUW) is the basic unit for parsing, con-sisting of one or more SUWs.
Figure 1 shows ex-4http://universaldependencies.github.io/docs/.5National Institute for Japanese Language and Linguistics.ample results from the preprocessing of parsing.In the figure, ?/?
denotes a border of SUWs in anLUW, and ???
denotes a bunsetsu boundary.3.2 Dependency schemeBasically, Japanese dependency structure is re-garded as an aggregation of pairs of a left-side dependent word and a right-side head word,i.e.
right-headed dependency, since Japanese is ahead-final language.
However, how to analyze apredicate constituent is a matter of debate.
We de-fine two types of schemes depending on the struc-ture related to the predicate constituent: first con-joining predicate and arguments, and first conjoin-ing predicate and function words such as auxiliaryverbs.As shown in sentence (4), a predicate bunsetsuconsists of a main verb followed by a sequenceof auxiliary verbs in Japanese.
We consider twoways of constructing a verb phrase (VP).
One isfirst conjoining the main verb and its arguments toconstruct VP as in sentence (4a), and the other isfirst conjoining the main verb and auxiliary verbsas in sentence (4b).
These two types correspond tosentences (5a) and (5b), respectively, in English.
(4) ?cat?NOM?fish?ACC??eat?PAST?????
?may?the cat may have eaten the fish?a.
[ [ [VP??S??O??
]V?
]aux??????
]auxb.
[ ??
[S??
[VPO??V?aux??????
]]]aux(5) a.
[ TheScat [ mayauxhaveaux[VPeatenVthe fish] ] ] .Ob.
[ TheScat [ [VPmayauxhaveauxeaten]Vthe fish] ] .OThe structures in sentences (4a) and (5a) aresimilar to a structure based on generative gram-mar.
On the other hand, the structures in sentences(4b) and (5b) are similar to the bunsetsu structure.We defined two dependency schemes Head Fi-nal type 1 (HF1) and Head Final type 2 (HF2) asshown in Figure 2, which correspond to structuresof sentences (4a) and (4b), respectively.
Addi-tionally, we introduced Predicate Content wordHead type (PCH), where a content word (e.g.verb) is treated as a head in a predicate phrase so asto link the predicate to its argument more directly.3.3 Dependency typeWe defined 35 dependency types for Japanesebased on SD, where 4-50 types are assigned forsyntactic relations in English and other languages.239LUW (Long Unit Word) sourcel FORM form LUW chunkerl LEMMA lemma LUW chunkerl UPOS POS LUW chunkerl INFTYPE inflection type LUW chunkerl INFFORM inflection form LUW chunkerl CPOS non-terminal symbol ?l SEMCLASS semantic class thesaurus?
?l PNCLASS NE class thesaurus?
?SUW (Short Unit Word)s FORM R form (rightmost) tokenizers FORM L form (leftmost) tokenizers LEMMA R lemma (rightmost) tokenizers LEMMA L lemma (leftmost) tokenizers UPOS R POS tokenizers CPOS R non-terminal symbol ?s SEMCLASS R semantic class thesaurus?
?s PNCLASS R NE class thesaurus?
?Table 2: Word attributes used for parser features.?
26 non-terminal symbols (e.g.
NN, VB) are employed ascoarse POS tags (CPOS) from an original treebank.
??
Se-mantic classes SEMCLASS and PNCLASS are used for gen-eral nouns and proper nouns, respectively from a Japanesethesaurus (Ikehara et al, 1997) to generalize the nouns.Table 1 shows the major dependency types.
Todiscriminate between a gapped relative clause anda gapless relative clause as described in Section1, we assigned two dependency types rcmod andncmod respectively.
Moreover, we introduced gapinformation by subdividing rcmod into three typesto extract predicate-argument relations, while theoriginal SD make no distinction between them.The labels of case and gapped relative clauseenable us to extract predicate-argument struc-tures by simply tracing dependency paths.In the case of HF1in Figure 2, we find twopaths between content words: ????
?friedfish?(NN)?pobj?dobj?
??
?eat?
(VB) and??
(VB)?aux?aux?rcmod nsubj?
???
?calico cat?(NN).
By marking the dependencytypes dobj and rcmod nsubj, we can extract thearguments for predicate??
?, i.e., ????
asa direct object and???
as a subject.4 EvaluationWe demonstrated the performance of the typed de-pendency parsing based on our scheme by usingthe dependency corpus automatically convertedfrom a constituent treebank and an off-the-selfparser.4.1 ResourcesWe used a dependency corpus that was convertedfrom the Japanese constituent treebank (Tanaka etal., 2013) built by re-annotating the Kyoto Uni-versity Text Corpus (Kurohashi et al, 2003) withphrase structure and function labels.
The Kyotocorpus consists of approximately 40,000 sentencesfrom newspaper articles, and from these 17,953sentences have been re-annotated.
The treebank isdesigned to have complete binary trees, which canbe easily converted to dependency trees by adapt-ing head rules and dependency-type rules for eachpartial tree.
We divided this corpus into 15,953sentences (339,573 LUWs) for the training set and2,000 sentences (41,154 LUWs) for the test set.4.2 Parser and featuresIn the analysis process, sentences are first tok-enized into SUW and tagged with SUW POS bythe morphological analyzer MeCab (Kudo et al,2004).
The LUW analyzer Comainu (Kozawa etal., 2014) chunks the SUW sequences into LUWsequences.
We used the MaltParser (Nivre et al,2007), which marked over 81 % in labeled attach-ment score (LAS), for English SD.
Stack algo-rithm (projective) and LIBLINEAR were chosenas the parsing algorithm and the learner, respec-tively.
We built and tested the three types of pars-ing models with the three dependency schemes.Features of the parsing model are made bycombining word attributes as shown in Table2.
We employed SUW-based attributes as wellas LUW-based attributes because LUW containsmany multiword expressions such as compoundnouns, and features combining LUW-based at-tributes tend to be sparse.
The SUW-based at-tributes are extracted by using the leftmost orrightmost SUW of the target LUW.
For instance,for LUW ????
in Figure 1, the SUW-basedattributes are s LEMMA L (the leftmost SUW?slemma ?
?fish?)
and s LEMMA R (the rightmostSUW?s lemma???
?fry?
).4.3 ResultsThe parsing results for the three dependencyschemes are shown in Table 3 (a).
The depen-dency schemes HF1and HF2are comparable, butPCH is slightly lower than them, which is prob-ably because PCH is a more complicated struc-ture, having left-to-right dependencies in the pred-icate phrase, than the head-final types HF1andHF2.
The performances of the LUW-based pars-ings are considered to be comparable to the resultsof a bunsetsu-dependency parser CaboCha on thesame data set, i.e.
a UAS of 92.7%, although wecannot directly compare them due to the differencein parsing units.
Table 3 (b) shows the results foreach dependency type.
The argument types (nsubj,240Scheme UAS LASHF194.09 89.49HF294.21 89.66PCH 93.53 89.22(a) Overall resultsF1scoredep.
type HF1HF2PCHnsubj 80.47 82.12 81.08dobj 92.06 90.28 92.29iobj 82.05 80.22 81.89tmod 55.54 56.01 54.09lmod 52.10 53.56 48.48rcmod nsubj 60.38 61.10 62.95rcmod dobj 28.07 33.33 39.46rcmod iobj 32.65 33.90 36.36ncmod 82.81 83.07 82.94advcl 65.28 66.70 60.69conj 70.78 70.68 69.53appos 51.11 57.45 46.32(b) Results for each dependency typeTable 3: Parsing results.Scheme Precision Recall F1scoreHF182.1 71.4 76.4HF281.9 67.0 73.7PCH 82.5 72.4 77.1SynCha 76.6 65.3 70.5Table 4: Predicate-argument structure analysis.dobj and iobj) resulted in relatively high scoresin comparison to the temporal (tmod) and locative(lmod) cases.
These types are typically labeled asbelonging to the postpositional phrase consistingof a noun phrase and particles, and case particlessuch as?
?ga?, ?
?o?
and?
?ni?
strongly sug-gest an argument by their combination with verbs,while particles?
and?
?de?
are widely used out-side the temporal and locative cases.Predicate-argument structure We ex-tracted predicate-argument structure informa-tion as triplets, which are pairs of predicatesand arguments connected by a relation, i.e.
(pred , rel , arg), from the dependency parsing re-sults by tracing the paths with the argument andgapped relative clause types.
pred in a triplet isa verb or an adjective, arg is a head noun of anargument, and rel is nsubj, dobj or iobj.The gold standard data is built by convertingpredicate-argument structures in NAIST Text Cor-pus (Iida et al, 2007) into the above triples.
Ba-sically, the cases ?ga?, ?o?
and ?ni?
in the corpuscorrespond to ?nsubj?, ?dobj?
and ?iobj?, respec-tively, however, we should apply the alternativeconversion to passive or causative voice, since theannotation is based on active voice.
The conver-sion for case alternation was manually done foreach triple.
We filtered out the triples includingzero pronouns or arguments without the direct de-pendencies on their predicates from the convertedtriples, finally 6,435 triplets remained.Table 4 shows the results of comparing the ex-tracted triples with the gold data.
PCH marks thehighest score here in spite of getting the lowestscore in the parsing results.
It is assumed that thecharacteristics of PCH, where content words tendto be directly linked, are responsible.
The tablealso contains the results of the predicate-argumentstructure analyzer SynCha.
Note that we focus ononly the relations between a predicate and its de-pendents, while SynCha is designed to deal withzero anaphora resolution in addition to predicate-argument structure analysis over syntactic depen-dencies.
Since SynCha uses the syntactic pars-ing results of CaboCha in a cascaded process, theparsing error may cause conflict between syntac-tic structure and predicate-argument structure.
Atypical example is that case where a gapped rel-ative clause modifies a noun phrase A ?
B ?Bof A?, e.g., [VP ?
??
??
?]
[NP ?
?
??]
?footprints of the cat that escaped from agarden.?
If the noun A is an argument of a mainpredicate in a relative clause, the predicate is a de-pendent of the noun A; however, this is not actu-ally reliable because two analyses are separatelyprocessed.
There are 75 constructions of this typein the test set; the LUW-based dependency pars-ing captured 42 correct predicate-argument rela-tions (and dependencies), while the cascaded pars-ing was limited to obtaining 6 relations.5 ConclusionWe proposed a scheme of Japanese typed-dependency parsing for dealing with constituentsand capturing the grammatical function as a de-pendency type that bypasses the traditional lim-itations of bunsetsu-based dependency parsing.The evaluations demonstrated that a word-baseddependency parser achieves high accuracies thatare comparable to those of a bunsetsu-based de-pendency parser, and moreover, provides detailedsyntactic information such as predicate-argumentstructures.
Recently, discussion has begun towardUniversal Dependencies, including Japanese.
Thework presented here can be viewed as a feasibilitystudy of UD for Japanese.
We are planning to portour corpus and compare our scheme with UD tocontribute to the improvement of UD for Japanese.241ReferencesAlastair Butler, Zhen Zhou and Kei Yoshimoto.
2012.Problems for successful bunsetsu based parsing andsome solutions.
In Proceedings of the EighteenthAnnual Meeting on the Association for Natural Lan-guage Processing, pp.
951?954.Marie-Catherine de Marneffe and Christopher D. Man-ning.
2008.
The Stanford typed dependencies rep-resentation.
In Proceedings of COLING 2008 Work-shop on Cross-framework and Cross-domain ParserEvaluation.Marie-Catherine de Marneffe, Natalia Silveira, Tim-othy Dozat, Katri Haverinen, Filip Ginter, JoakimNivre, and Christopher D. Manning.
2014.
Uni-versal Stanford Dependencies: A cross-linguistic ty-pology.
In Proceedings of the Ninth InternationalConference on Language Resources and Evaluation(LREC-2014).Yasuharu Den, Junpei Nakamura, Toshinobu Ogiso andHideki Ogura.
2008.
A proper approach to Japanesemorphological analysis: Dictionary, model and eval-uation.
In Proceedings of the Sixth InternationalConference on Language Resources and Evaluation(LREC-2008).Ryu Iida, Mamoru Komachi, Kentaro Inui and YujiMatsumoto.
2007.
Annotating a Japanese Text Cor-pus with Predicate-argument and Coreference Rela-tions.
In Proceedings of the the Linguistic Annota-tion Workshop (LAW ?07), pp.
132?139.Ryu Iida and Massimo Poesio.
2011.
A Cross-LingualILP Solution to Zero Anaphora Resolution.
In Pro-ceedings of the 49th Annual Meeting of the Associ-ation for Computational Linguistics: Human Lan-guage Technologies (ACL-HLT 2011), pp.
804-813.Satoru Ikehara, Masahiro Miyazaki, Satoshi Shirai,Akio Yokoo, Kentaro Ogura, Yoshifumi Ooyamaand Yoshihiko Hayashi.
1998.
Nihongo Goitaikei.Iwanami Shoten, In Japanese.Daisuke Kawahara and Sadao Kurohashi.
2006.
Afully-lexicalized probabilistic model for Japanesesyntactic and case structure analysis.
In Proceedingsof the Human Language Technology Conference ofthe North American Chapter of the Association ofComputational Linguistics (HLT-NAACL 2006), pp.176?183.Shunsuke Kozawa, Kiyotaka Uchimoto and YasuharuDen.
2014.
Adaptation of long-unit-word analysissystem to different part-of-speech tagset.
In Journalof Natural Language Processing, Vol.
21, No.
2, pp.379?401 (in Japanese).Taku Kudo, Kaoru Yamamoto and Yuji Matsumoto.2004.
Applying conditional random fields toJapanese morphological analysis.
In Proceedingsof the Conference on Empirical Methods in NaturalLanguage Processing (EMNLP-2004), pp.
230?237.Taku Kudo and Yuji Matsumoto.
2002.
Japanese de-pendency analysis using cascaded chunking.
In Pro-ceedings of the 6th Conference on Natural LanguageLearning (CoNLL-2002), Volume 20, pp.
1?7.Sadao Kurohashi and Makoto Nagao.
2003.
Building aJapanese parsed corpus ?
while improving the pars-ing system.
In Abeille (ed.
), Treebanks: Buildingand Using Parsed Corpora, Chap.
14, pp.
249?260.Kluwer Academic Publishers.Kikuo Maekawa, Hanae Koiso, Sasaoki Furui, HitoshiIsahara.
2000.
Spontaneous Speech Corpus ofJapanese.
In Proceedings of the Second Interna-tional Conference on Language Resources and Eval-uation (LREC-2000), pp.
947?952.Kikuo Maekawa, Makoto Yamazaki, ToshinobuOgiso, Takehiko Maruyama, Hideki Ogura, WakakoKashino, Hanae Koiso, Masaya Yamaguchi, MakiroTanaka and Yasuharu Den.
2014.
Balanced Corpusof Contemporary Written Japanese.
Language Re-sources and Evaluation, Vol.
48, pp.
345?371.Ryan McDonald, Joakim Nivre, Yvonne Quirmbach-Brundage, Yoav Goldberg, Dipanjan Das, KuzmanGanchev, Keith Hall, Slav Petrov, Hao Zhang, Os-car Ta?ckstro?m, Claudia Bedini, Nu?ria BertomeuCastello?, and Jungmee Lee.
2013.
Universal De-pendency Annotation for Multilingual Parsing.
InProceedings of the 51st Annual Meeting of the ACL(ACL 2013).Shunsuke Mori, Hideki Ogura and Teturo Sasada.2014.
A Japanese word dependency corpus.
In Pro-ceedings of the Ninth International Conference onLanguage Resources and Evaluation (LREC-2014),pp.
753?758.Joakim Nivre, Johan Hall, Jens Nilsson, AtanasChanev, Gu?ls?en Eryig?it, Sandra Ku?bler, SvetoslavMarinov and Erwin Marsi.
2007.
MaltParser: Alanguage-independent system for data-driven depen-dency parsing, In Journal of Natural Language En-gineering, Vol.
13, No.
2, pp.
95?135.Takaaki Tanaka and Masaaki Nagata.
2013.
Construct-ing a Practical Constituent Parser from a JapaneseTreebank with Function Labels.
In Proceedingsof the Fourth Workshop on Statistical Parsing ofMorphologically-Rich Languages, pp.
108?118.Kiyotaka Uchimoto and Yasuharu Den .
2008.
Word-level Dependency-structure Annotation to Corpusof Spontaneous Japanese and its Application.
InProceedings of the International Conference onLanguage Resources and Evaluation (LREC 2008),pp.3118?3122.242
