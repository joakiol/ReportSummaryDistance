Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 382?390,Honolulu, October 2008. c?2008 Association for Computational LinguisticsA Casual Conversation System Using Modality and Word AssociationsRetrieved from the WebShinsuke Higuchi Rafal RzepkaGraduate School of Information Science and TechnologyHokkaido University , Sapporo Japan 060-0814{shin h,kabura,araki}@media.eng.hokudai.ac.jpKenji ArakiAbstractIn this paper we present a textual dialoguesystem that uses word associations retrievedfrom the Web to create propositions.
We alsoshow experiment results for the role of modal-ity generation.
The proposed system automat-ically extracts sets of words related to a con-versation topic set freely by a user.
After theextraction process, it generates an utterance,adds a modality and verifies the semantic re-liability of the proposed sentence.
We evalu-ate word associations extracted form the Web,and the results of adding modality.
Over 80%of the extracted word associations were evalu-ated as correct.
Adding modality improved thesystem significantly for all evaluation criteria.We also show how our system can be used asa simple and expandable platform for almostany kind of experiment with human-computertextual conversation in Japanese.
Two exam-ples with affect analysis and humor generationare given.1 IntroductionMany task-oriented dialogue systems (Liu et al,2003; Reitter et al, 2006) have been developped.Research on non-task-oriented dialogue systems likecasual conversation dialogue systems (?chatbots?)
ison the other hand not very common, perhaps due tothe many amateurs who try to build naturally talkingsystems using sometimes very clever, but rather un-scientific methods although there are systems withchatting abilities as (Bickmore and Cassell, 2001)but concentrate on applying strategies to casual con-versation rather than their automatic generation ofthose conversations.
However, we believe that themain reason is that an unrestricted domain is dispro-portionately difficult compared to the possible usesuch a system could have.
It is for example very hardto predict the contents and topics of user utterances,and therefore it is almost impossible to prepare con-versational scenarios.
Furthermore, scenarios needmore or less specific goals to be useful.
Howeverin our opinion, sooner or later non-task-oriented di-alogue systems will have to be combined with taskoriented systems and used after recognizing that theuser?s utterance does not belong to a given task.
Thiswould lead to more natural interfaces for e.g.
infor-mation kiosks or automatic guides placed in publicplaces where anyone can talk to them about anything(Gustafson and Bell, 2000; Kopp et al, 2005) re-gardless of the role the developers intended.
For thisreason we have also started implementing emotive-ness recognition and joke generation modules thatare presented later in the paper.Well-known examples of non-task-oriented dia-logue systems are ELIZA (Weizenbaum, 1966) andA.L.I.C.E 1, though the former was built to parody aRogerian therapist which can be regarded as a task.Both systems and their countless imitators 2 use alot of rules coded by hand.
ELIZA is able to makea response to any input, but these responses are onlyinformation requests without providing any new in-formation to the user.
In the case of A.L.I.C.E,1Wallace, R. The Anatomy of A.L.I.C.E.http://www.alicebot.org/anatomy.html.2Many of them have been quite successful in the Loeb-ner Prize and the Chatterbox Challenge (competitions only forEnglish-speaking bots) but explanations of their algorithms arenot available.382the knowledge resource is limited to the existingdatabase.
Creating such databases is costly anda programmer must learn the AIML mark-up lan-guage to build it.
Although there have been attemptsat updating AIML databases automatically (Pietro etal., 2005), the scale was rather limited.As mentioned above, these examples and manyother ?chatbots?
need hand-crafted rules, and arethus often ignored by computer scientists and rarelybecome a research topic.
However, they have provedto be useful for e-learning (Pietro et al, 2005) andmachine learning (Araki and Kuroda, 2006) support.Building a system using automatic methods, likewe do, seems to be the most realistic way for unre-stricted domains.
Considering the large cost of de-veloping a program that can talk about any topic, itis appealing to turn to the huge and cheap textualsource that is the Internet.In this very moment millions of people (Kumar etal, 2003) are updating their blogs and writing articleson every possible topic.
These are available on theWeb which we can access any time, and in a fasterand faster manner, the search engines grow more andmore efficient.
Thus, the Web is well suited to ex-tracting word associations triggered by words fromuser utterances made in a topic-free dialogue sys-tem.. We present a system making use of this typeof information.
It automatically extracts word asso-ciation lists using all keywords in a given utterancewithout choosing a specific one (which most othersystems that ignore the context do) then generates areply using the only one strongest association fromthe nouns, verbs and adjectives association groups.Modality is then added to the reply, and then it isoutput.Our system is built upon the idea that human utter-ances consist of a proposition and a modality (Nittaet al, 1989).
In this paper we present an algorithmfor extracting word associations from the Web anda method for adding modality to statements.
Weevaluate both the word associations and the use ofmodality.
We also suggest some future possible ex-tensions of the system and show a small experimentwith adding humor to the system.In this paper, the system described works forJapanese and uses text as input and output.
Thoughthe final goal of our research is to help developingfreely talking car navigation systems that by theirchatting abilities can help to avoid drowsiness whiledriving and so on.
in this part of the development weconcentrate on proposition generation and modalityprocessing.
Therefore, we work only with text now.We plan to combine this project with research on incar voice recognition and generation.2 Extracting Word AssociationsIn this chapter, we present a method for automaticextraction of word associations based on keywordsfrom user utterances.
We use the Google3 searchengine snippets to extract word associations in realtime without using earlier prepared resources, suchas off-line databases.2.1 Extracting Word Associations from theWebIn the first step, the system analyzed user utterancesusing the morphological analyzer MeCab4 in orderto spot query keywords for extracting word associ-ations lists.
We define nouns, verbs, adjectives, andunknown words as query keywords.
The reason wechose these word classes is that these word classescan be treated as important and, to some extent, de-scribe the context.
We define a noun as the longestset of nouns in a compound noun.
For example,the compound noun shizen gengo shori5 (naturallanguage processing) is treated by MeCab as threewords: (shizen - natural), (gengo - language) and(shori - processing).
Our system, however, threatsit as one noun.In the next step, the system uses these keywordsas query words for the Google search engine.
Thesystem extracts the nouns from the search results andsorts them in frequency order.
This process is basedon the idea that words which co-occur frequentlywith the input words are of high relevance to them.The number of extracted snippets is 500.
This valuewas set experimentally, taking the processing timeand output quality into account.
The top ten wordsof a list are treated as word associations, see Table 1for an example.3Google, http://www.google.co.jp/4MeCab: Yet Another Part-of-Speech and MorphologicalAnalyzer, http://mecab.sourceforge.jp/5All Japanese transcriptions will be written in italics.383Table 1: Examples of noun associations triggered by auser utteranceSapporo wa samui.
(Sapporo city is cold.
)Association frequency ranking:1 yuki (snow) 522 fuyu (winter) 503 kion (temperature) 164 jiki (season) 125 Tokyo (Tokyo) 126 tenki (weather) 117 chiiki (area) 108 heya (room) 102.2 EvaluationWe asked volunteers to use our system and to eval-uate the correctness of word lists generated by thesystem.
First, a participant freely inputs an utter-ance, for which the system retrieves ten associationwords.
Next, a participant rated these words using ascale of one to three with 3 meaning ?perfectly cor-rect?, 2 -?partially correct?
and 1 - ?incorrect?.
Inthis experiment we consider words that receive a 2or 3 as usable.
The reason associations rated 2 or 3are considered as usable is that the definition of whatmakes a good word association here is difficult tospecify.
When it comes to topic-free conversationswe have observed that associations have an effecton a certain context.
Three volunteers repeated theexperiment ten times, so the final amount of evalu-ated words was 300.
Table 2 shows the results of thetop 10 words, sorted by the frequency of appearance.Table 3 shows the results of the top 5 words.What constitutes a correct word association wasleft to each volunteer to decide subjectively since ina casual conversation setting associations are hard todefine strictly.Table 2: Top 10 word associationsscore participant(A?B?C) total3 40?52?57 1492 37?17?27 811 23?31?16 70usability (%) 77?69?84 77As shown in Table 2 approximately 77% of theword associations were judged as usable but thereTable 3: Top 5 word associationsscore participant?A?B?C?
total3 20?29?36 852 17?9?10 361 13?12?4 29usability (%) 74?76?92 81were individual differences between the evaluators.This shows that the definition of word associationsis different for each participant.
Table 3 shows thatapproximately 80% of the word associations werejudged as usable.
It is thus highly likely that the topwords from the frequency lists are correct associa-tions.
The results show that automatic extracting ofword associations using a Web search engine is fea-sible.
The main reason for extracting word associa-tions from the Web is that thanks to this method, thesystem can handle new information, proper names,technical terms and so on.
by using only the snip-pets from the search engine.
The word associationextraction takes no more than few seconds.
For theevaluation we used only nouns but we expect al-though verbs and adjectives are often more abstractthan nouns, the word associations for them will im-prove the results.3 General Description of the SystemThe system generates replies in the following way:?
extraction of keywords from user utterance?
extraction of word associations from the Web?
generation of sentence proposition using theextracted associations?
addition of modality to the sentence proposi-tion3.1 Extraction of Keywords from UserUtterancesThe system applies morphological analysis to theuse utterances in the same way as described in sec-tion 2.1 and extracts keywords based on part ofspeech.384   fffi fifl ffffi !
" #%$&(') * fi+ffff 	,,-  !+.fffffifi fi -/0/1/23-4 5fi-(6    5#ff,, !75fi-(6   5fifl-	fl (ffi  8	fi#fi*6 9 .
,.
! *.fi !fi	:,.ff.-ff*.
  	Figure 1: System flow3.2 Extraction of Words Association from theWebThe system performs a Google search using the ex-tracted keywords as a query.
The system sorts theresults obtained from the query by their frequencyas in section 2.1.
In section 2.1 only nouns wereextracted but here we also extract verbs and adjec-tives.
After sorting all words in adjective, verb andnoun lists the system uses the ones with the highestfrequency as word associations.3.3 Generation of Proposition Using WordAssociationsUsing the associations, the system generates theproposition of a sentence to be used as a reply tothe user input.
A proposition is an expression rep-resenting an objective statement.
The proposition isgenerated by applying associations to a propositiontemplate like [(noun) (topic indicating particle wa)(adjective)].
We prepared 8 proposition templatesmanually (see Table 4).
The templates were cho-sen subjectively after examining statistics from IRC6 chat logs.
Our criteria for choosing templates fromthe chat logs was that they should belong to the 20most frequent modality patterns and to be flexibleenough to fit a range of grammatical constructions,for example in English, ?isn?t it?
cannot follow verbswhile ?I guess?
can follow nouns, adjectives, andverbs.
The proposition templates are applied in a6Internet Relay Chat Protocol,http://www.irchelp.org/irchelp/rfc/rfc.htmlpredetermined order: for example, first a template?
(noun) (wa) (adjective)?
is used; next a template?
(noun) (ga) (adjective)?
is used.
However, since thegenerated proposition is not always a natural state-ment, the system uses exact matching searches ofthe whole phrases in a search engine to check thenaturalness of each proposition.
If the frequency ofoccurrence of the proposition is low, it is definedas unnatural and deleted.
This processing is basedon the idea that the phrases existing on the Web inlarge numbers are most probably correct grammat-ically and semantically.
If an unnatural propositionis generated, the system generates another proposi-tion in the same way.
In this experiment the sys-tem used propositions for which the hit number ex-ceeded 1,000 hits using Google.
Thus, the process-ing proceeds as follows.
The system first selects thetop noun, top verb, and top adjective word associa-tions.
These are applied to the templates in a prede-termined order.
If a generated proposition is judgedas valid (using Google, occurrence on the web indi-cates validity), it is used.
If not, another template istried until a valid proposition is found.
The reasonfor not trying every possible combination of associ-ated words is prohibitively long processing time.Table 4: Proposition templates(noun) (wa) (adjective)(noun) (ga) (adjective)(noun) (ga) (verb)(noun) (wa) (verb)(so-re) (wa) (verb)(noun)(adjective)(verb)3.4 Adding Modality to the PropositionsFinally, the system adds modality to the generatedproposition.
By modality we mean a set of grammat-ical and pragmatic rules to express subjective judg-ments and attitudes.
In our system, modality is real-ized through adverbs at the end of a sentence whichis common in Japanese (Nitta et al, 1989).
In oursystem, a pair of sentence head and sentence endauxiliary verb are defined as ?modality?.3853.4.1 Extracting ModalityThere is no standard definition of what consti-tutes modality in Japanese.
In this paper modality ofcasual conversation is classified into questions andinformative expressions.
Questions are expressionsthat request information from the user.
Informativeexpressions are expressions that transmit informa-tion to the user.
Patterns for these modalities are ex-tracted automatically from IRC chat logs (100,000utterances) in advance.
Modality patterns are ex-tracted in these ways:?
pairs of grammatical particles and an auxiliaryverbs placed at the end of sentences are definedas ending patterns?
sentences with question marks are defined asquestions?
adverbs, emotive words, and connectives at thebeginning of sentences are defined as informa-tive expressions?
candidate patterns thus obtained are sorted byfrequencyFirst the system extracts sentence ending patternsfrom IRC chat logs.
If an expression contains ques-tion marks, it is classified as a question.
Next, thesystem extracts adverbs, emotive words, and con-nectives from the beginning and end of sentencesfrom the IRC logs.
These pairs (beginning and end)of expressions are classified as ?informative expres-sions?.
For example question expression ?desu-ka?
?is extracted from a human utterance like ?Kyou-wasamui desu-ka??
(Is it cold today?).
An informativeexpression ?maa *** kedo?
is extracted from a hu-man utterance as ?Maa sore-wa ureshii kedo?
(Well,I?m glad, but you know...).685 patterns were obtained for informative ex-pressions.
550 of these informative expression pat-terns were considered by authors as correct (80%).For questions 396 patterns were obtained, and 292patterns (73%) were evaluated as correct.
We sortedthese candidates in frequency order.
The wordsappearing at the top of the list were correct, buteven the ones appearing only once were still deemedas usable.
For example, the question expression?janakatta deshita-kke??
is a correct expression,but appeared only once in the 100,000 utterances.Hence, we confirmed that chat logs include variousmodality expressions, and only a few of them areincorrect.
Tables 5 and 6 show some examples ofmodality patterns.Table 5: Examples of informative expression modalityinformative expression frequencymaa - kedo 21(Well , it can be said - but -)maa - dana 16(Well , it can be said -)maa - desu-ga 16(Well , it appears that -)soko-de - desu-yo 15(Here , it is said that -)maa - da-ga 14(Well , it can be said - but -)maa - desu-yo 12(Well , it is that -)Table 6: Examples of question modality sentence endingsquestion freqency...desuka?
232(Is it that ...
?)...kana?
90(Maybe ...
?)...da-kke?
87(Is it right that ...
?)...masu-ka?
69(Is it that ...
?)...nano?
68(Is it that ...
?)...toka?
55( ... , isn?t it ?
)3.4.2 Adding ModalityThe system adds the modality from section 3.4.1to the proposition from section 3.3 to generate thesystem output.
This process is based on the idea thathuman utterance consists of proposition and modal-ity.
A modality pattern is selected randomly.
For ex-ample, if the system generates the proposition ?fuyuwa samui (Winter is cold.)?
and selects the modal-ity ?iyaa ... desu-yo (Ooh ... isn?t it?
)?, the gen-386erated output will be ?iyaa, fuyu-wa samui desu-yo(Winter is cold, you know)?.
However, there is apossibility that the system generates unnatural out-put like ?fuyu-wa samui dayo-ne (Winter is cold,arent?t it?
)?, depending on the pair of propositionand modality.
To this problem, the system uses theGoogle search engine to filter out unnatural output.The system performs a phrase search on the end ofthe sentence.
If the number of search hits is higherthan threshold, the output is judged as correct.
If thenumber of a search hits is lower than the threshold,the output is judged as incorrect and discarded, anda new reply is generated.
Here, we experimentallyset the threshold to 100 hits.4 Experimental ResultsWe used system ?, generating only the proposi-tion, and system ?, generating both proposition andmodality.
5 participants used each systems for con-versations of 10 turns and evaluated the conversa-tions on a 5-point scale.
Evaluation criteria were?will to continue the conversation?
(A), ?grammati-cal naturalness of dialogues?
(B), ?semantical nat-uralness of dialogues?
(C), ?vocabulary richness?
(D), ?knowledge richness?
(E), and ?humanity ofthe system?
(F).
Table 7 shows average scores forthe evaluations of each system.
System ?
that usesmodality scored much higher than system ?.
Table8 shows examples of actual dialogue.
In the eval-uation, the participants expressed the opinion thatan utterance like (xx ha yy) is unnatural and usinga modality like (maa)(?well?
), (moo)(?anyway?)
isvery natural.
Thus we can say that the modality ex-pressions make the utterances of the system seemmore natural.5 The System as a PlatformThe simplicity, real-time processing capabilities andpromising results showing that users do not getbored so quickly encouraged us to perform trialswith other ongoing projects and experiment with thesystem working as a platform for adding variousmodules and algorithms.
By using our system it ispossible to perform tests to see if a new idea willsupport or improve human-computer interaction ornot.
Here we will briefly describe two such trials- one on guessing emotive values of utterances andTable 8: Examples of dialogues with system ?user: Nanika suki-na tabemono aru?
(What food do you like ?
)system: Maa, tabemono-wa oishii desu.
(Well, food tastes good.
)user: Saikin-wa osake-mosuki-ni natte-kita-n-da.
(Recently, I begin to like alcohol, too.
)system: Demo, sake-wa yowai-no-yo-ne.
(But, I can?t drink much.
)user: Yowai-n-da... Sugu yochau-no?(Really...
?Do you get drunkquickly?
)system: Maa, sore-wa sugoi-wa-ne.
(Whow, that?s amazing.
)user: Boku-wa wari-to osake-watsuyoi hou-nan-da.
(I have a rather hightolerance for alcohol.
)system: Iya, sore-wa tsuyoi-n-de.
(Well, it is strong, I can say.
)user: Kyou-wa sukoshi hadazamui-yo-ne.Natsu-nanoni.
(It is a little cold today.Even though it is summer.
)system: Asa-wa hadazamui-toka ?
(Isn?t it chilly in morning?
)user: Asa-kara hadazamukatta-ne.
(It was chilly since morning.
)system: Aa kyou-wa hayai-na.
(Ah, it?s early.
)one on improving the system?s overall evaluation byadding a pun generator.5.1 Testing Affect AnalysisPtaszynski et al(Ptaszynski et al, 2008) have devel-oped a method for affect analysis of Japanese text.Their method is based on cross-referencing lexicalemotive elements with emotive expressions appear-ing in text.
In the process of analysis first a gen-eral emotive context is determined and then the spe-cific types of emotional states conveyed in an utter-ance are extracted.
They support this method with a387Table 7: Evaluation ResultsSystem ??proposition?
system ?
?proposition + modality?Evaluation criteria A B C D E F A B C D E FParticipant a 1 3 2 2 4 2 4 4 3 4 3 5Participant b 1 3 1 2 1 1 4 4 4 5 4 3Participant c 1 2 1 2 1 1 1 2 1 2 1 1Participant d 1 3 1 3 1 2 4 3 1 3 3 4Oarticipant e 1 4 1 1 2 1 3 2 2 4 5 4Average 1.0 3.0 1.2 2.0 1.8 1.4 3.2 3.0 2.2 3.6 3.2 3.4Web-mining technique to improve the performanceof the emotional state type extraction.
A systemconstructed on the basis of their method achievedhuman level performance in determining the emo-tiveness of utterances, and 65% of human level per-formance in extracting the specific types of emo-tions.
Also, the supporting Web mining techniqueimproved the performance of the emotional statetype extraction to 85% of the human level (Shi et al2008).
As these are very promising figures we arecurrently in the phase of implementing their ideasin our system and testing how emotion recognitioncan influence speech act analysis and the automaticchoice of proper modality.5.2 Improving the System Using HumorIn this trial, an experiment showing that humor canimprove a non-task oriented conversational system?soverall performance was conducted.5.2.1 Implementing PUNDA systemBy using a simplified version of Dybala?sPUNDA system (Dybala et al, 2008), a pun-generation was added to our baseline system.
ThePUNDA algorithm consists of two parts: A Can-didate Selection Algorithm and a Sentence Integra-tion Engine.
The former generates a candidate for apun analyzing an input utterance and selects wordsor phrases that could be transformed into a pun byone of four generation patterns: homophony, ini-tial mora addition, internal mora addition or finalmora addition.
The latter part generates a sentenceincluding the candidate extracted in the previousstep.
To make the system?s response more relatedto the user?s input, each sentence that included ajoke started with the pattern ?
[base phrase] to ieba?
(?Speaking of [base phrase]?).
The remaining partof the sentence was extracted from the Web and thecandidate was used as a query word and the list ofsentences including this word was retrieved.
Thenthe shortest sentence with an exclamation mark is se-lected as most jokes convey some emotions.
Whenthe candidate list was empty, the system selected onerandom pun from a pun database.5.2.2 Experiment resultsIn the first experiment, 5 participants were askedto perform a 10-turn dialogue with two systems.After using both systems (baseline and humor-equipped), users were asked to evaluate both sys-tems?s performances by answering the followingquestions: A) Do you want to continue the dia-logue?
; B) Was the system?s utterances grammati-cally natural?
; C) Was the system?s utterances se-mantically natural?
; D) Was the system?s vocabu-lary rich?
; E) Did you get an impression that thesystem possesses any knowledge?
; F) Did you getan impression that the system was human-like?
; G)Do you think the system tried to make the dialoguemore funny and interesting?
and H) Did you findthe system?s utterances interesting and funny?
An-swers were given on a 5-point scale and the resultsare shown in Table 9.A third-person evaluation experiment was alsoperformed and again the humor-equipped systemscored higher than the non-humor one.
The ques-tion asked in this evaluation was: ?Which dialoguedo you find most interesting and funny??.
Evalu-ators could choose between 3 options: Dialogue 1(Baseline system first 3 turns), Dialogue 2 (Humor-equipped system, first 3 turns with system?s third re-sponse replaced by pun generator?s output) and Dia-388Table 9: Results of humor experimentsEvaluation Criteria A B C D E F G HBaseline System 3.0 2.2 2.4 2.4 2.0 2.8 2.2 2.8With pun generator 3.2 3.0 2.8 2.8 2.2 3.0 3.4 3.6logue 3 (the first 3 turns of the baseline system withjoking ability).
Dialogue 1 and Dialogue 2 have thesame input.
Among 25 evaluators, only 5 (20%) re-sponded that Dialogue 1 was most interesting andfunny.
10 chose Dialogue 2 and the other 10 choseDialogue 3 (40% respectively).
This means thateach of humor equipped dialogues received evalu-ations two times higher than non-humor dialogue.5.3 A Toolkit for Conversation-RelatedExperimentsOur system can be also disassembled into a set offlexible tools which help students to experiment withdialogue processing.
By using simple web-miningtechniques we described, this dialogue engine is ca-pable of automatic retrieval of associations whichcan be used to produce a whole range of utterances- for example by using the bottom, not the top of theassociations list, one can examine how interestingor provocative the dialogue becomes.
As the sys-tem has a cgi interface, the experiments are easy andany new feature (for instance a speech act choicemenu) can be easily added.
Such toolkit gives stu-dents an opportunity to experiment on a given aspectof dialogue processing without the need of build-ing a conversation system from the scratch.
Thereis also no need of laborious knowledge input and,as such open-domain oriented system generates new?on topic?
utterances, experiment subjects do not getbored quickly, which is always a problem while col-lecting conversation logs of human-machine inter-action.
A programmer also can freely choose be-tween thousands of IRC logs utterances and Internetresources for the statistical trials, grammar patternsretrieval, speech acts analysis.6 Conclusion and Future WorkIn this research we investigated if word associationsextracted automatically from the Web are reasonable(semantically on topic) and if they can be success-fully used in non-task-oriented dialogue systems.We also implemented such a system extraction mod-ule.
It is able to automatically generate in real-timeresponses to user utterances by generating a propo-sition and adding modality retrieved from IRC chatlogs.
We conducted evaluation experiments on theoverall influence of the modality usage and it im-proved the system.
Therefore we showed that itis possible to construct a dialogue system that au-tomatically generates understandable on-topic utter-ances without the need of creating vast amounts ofrules and data beforehand.
We also confirmed thatour system can be used as a experimental platformwhich can be easily used by other researchers to testtheir algorithms with a more unpredictible (and lessboring) ?chatbot?, an important factor for long tir-ing sessions of human-computer conversation.
Cur-rently there are several projects which use the sys-tem described here as a platform for experiments andwe introduced two of them - on joke generation andaffect analysis.There is still a lot of work left to be done.
It isnecessary for a non-task-oriented dialogue system toobtain not only word associations, but also differentkinds of knowledge - of user?s preferences or of di-alogue itself - for example conversational strategies.At this moment the system generates utterances byapplying word associations to the proposition tem-plates and adding modality.
We also need to moredeeply consider semantics, speech acts and contextto create a more advanced system.
Finally, the sys-tem needs to recognize not only keywords, but alsouser?s modality.
We assume that the affect recog-nition mentioned above will help us to achieve thisgoal in near future and this is our next step.
Byopening the system?s code and giving others the op-portunity of adding their own modules and changeswe hope to solve remaining problems.
In this pa-per we focus on the impact of adding modality to asystem.
Comparing the system to Japanese versionsof ELIZA (already available) and ALICE (not avail-able in Japanese yet) is also one of our next steps.389AcknowledgmentsThis work was partially supported by the ResearchGrant from the Nissan Science Foundation.ReferencesBei Liu, Limin Du, Shuiyuan Yu.
2003 The methodof building expectation model in task-oriented dia-logue systems and its realization algorithms.
Proceed-ings of Natural Language Processing and KnowledgeEngineering:174-179David Reitter, Johanna D. Moore, and Frank Keller.2006.
Priming of syntactic rules in task-oriented di-alogue and spontaneous conversation.
In Proc.
28thAnnual Conference of the Cognitive Science Society(CogSci), Vancouver, Canada.Timothy Bickmore and Justine Cassell.
2001 RelationalAgents: A Model and Implementation of BuildingUser Trust.
Proceedings of Human Factors ComputingSystems (SIGCHI?01): 396?403.Joakim Gustafson and Linda Bell.
2000.
Speech technol-ogy on trial: Experiences from the August system.
InNatural Language Engineering, 1(1):1-15.Stefan Kopp, Lars Gesellensetter, Nicole C. Kramer, andIpke Wachsmuth.
2005.
A Conversational Agent asMuseum Guide?
Design and Evaluation of a Real-World Application.
Intelligent Virtual Agents, LNAI3661:329-343.Joseph Weizenbaum.
1966.
ELIZA - computer pro-gram for the study of natural language communica-tion between man and machine.
Commun.
ACM, vol.9,no.1:36-45.Orlando De Pietro, Maurizio De Rose, and GiovanniFrontera.
2005.
Automatic Update of AIML Knowl-edge Base in E-Learning Environment.
In Proceedingsof Computers and Advanced Technology in Education., Oranjestad, Aruba, August:29-31.Kenji Araki and Michitomo Kuroda.
2006.
Gener-ality of a Spoken Dialogue System Using SeGA-IL for Different Languages, Proceedings of theIASTED International Conference COMPUTERINTELLIGENCE:70-75.Ravi Kumar, Jasmine Novak, Prabhakar Raghavan, andAndrew Tomkins.
2003.
On the Bursty Evolution ofBlogspace.
Proceedings of The Twelfth InternationalWorld Wide Web Conference:568-257Yoshio Nitta and Takashi Masuoka, Japanese modal-ity(Nihongo no modality) Kuroshio.Michal Ptaszynski, Pawel Dybala, Rafal Rzepka, andKenji Araki.
2008.
Double Standpoint EvaluationMethod for Affect Analysis System.
The 22nd AnnualConference of Japanese Society for Artificial Intelli-gence (JSAI 2008).Wenhan Shi, Rafal Rzepka and Kenji Araki.
2008.
Emo-tive Information Discovery from User Textual In-put Using Causal Associations from the Internet (inJapanese)?, Proceedings of the 7th Forum of Informa-tion Technology(Vol2):267-268Pawel Dybala, Michal Ptaszynski, Rafal Rzepka andKenji Araki.
2008.
Extracting Dajare Candidates fromthe Web - Japanese Puns Generating System as aPart of Humor Processing Research.
Proceedings ofLIBM?08 First International Workshop on Laughter inInteraction and Body Movement:46-51.390
