Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1220?1229,Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational LinguisticsGlobal Learning of Focused Entailment GraphsJonathan BerantTel-Aviv UniversityTel-Aviv, Israeljonatha6@post.tau.ac.ilIdo DaganBar-Ilan UniversityRamat-Gan, Israeldagan@cs.biu.ac.ilJacob GoldbergerBar-Ilan UniversityRamat-Gan, Israelgoldbej@eng.biu.ac.ilAbstractWe propose a global algorithm for learn-ing entailment relations between predi-cates.
We define a graph structure overpredicates that represents entailment rela-tions as directed edges, and use a globaltransitivity constraint on the graph to learnthe optimal set of edges, by formulatingthe optimization problem as an IntegerLinear Program.
We motivate this graphwith an application that provides a hierar-chical summary for a set of propositionsthat focus on a target concept, and showthat our global algorithm improves perfor-mance by more than 10% over baseline al-gorithms.1 IntroductionThe Textual Entailment (TE) paradigm (Dagan etal., 2009) is a generic framework for applied se-mantic inference.
The objective of TE is to recog-nize whether a target meaning can be inferred froma given text.
For example, a Question Answer-ing system has to recognize that ?alcohol affectsblood pressure?
is inferred from ?alcohol reducesblood pressure?
to answer the question ?What af-fects blood pressure?
?TE systems require extensive knowledge of en-tailment patterns, often captured as entailmentrules: rules that specify a directional inference re-lation between two text fragments (when the ruleis bidirectional this is known as paraphrasing).
Animportant type of entailment rule refers to propo-sitional templates, i.e., propositions comprisinga predicate and arguments, possibly replaced byvariables.
The rule required for the previous ex-ample would be ?X reduce Y ?
X affect Y?.
Be-cause facts and knowledge are mostly expressedby propositions, such entailment rules are centralto the TE task.
This has led to active researchon broad-scale acquisition of entailment rules forpredicates, e.g.
(Lin and Pantel, 2001; Sekine,2005; Szpektor and Dagan, 2008).Previous work has focused on learning each en-tailment rule in isolation.
However, it is clear thatthere are interactions between rules.
A prominentexample is that entailment is a transitive relation,and thus the rules ?X ?
Y ?
and ?Y ?
Z?
implythe rule ?X ?
Z?.
In this paper we take advantageof these global interactions to improve entailmentrule learning.First, we describe a structure termed an entail-ment graph that models entailment relations be-tween propositional templates (Section 3).
Next,we show that we can present propositions accord-ing to an entailment hierarchy derived from thegraph, and suggest a novel hierarchical presenta-tion scheme for corpus propositions referring to atarget concept.
As in this application each graphfocuses on a single concept, we term those focusedentailment graphs (Section 4).In the core section of the paper, we present analgorithm that uses a global approach to learn theentailment relations of focused entailment graphs(Section 5).
We define a global function and lookfor the graph that maximizes that function undera transitivity constraint.
The optimization prob-lem is formulated as an Integer Linear Program(ILP) and solved with an ILP solver.
We show thatthis leads to an optimal solution with respect tothe global function, and demonstrate that the algo-rithm outperforms methods that utilize only localinformation by more than 10%, as well as meth-ods that employ a greedy optimization algorithmrather than an ILP solver (Section 6).2 BackgroundEntailment learning Two information types haveprimarily been utilized to learn entailment rulesbetween predicates: lexicographic resources anddistributional similarity resources.
Lexicographic1220resources are manually-prepared knowledge basescontaining information about semantic relationsbetween lexical items.
WordNet (Fellbaum,1998), by far the most widely used resource, spec-ifies relations such as hyponymy, derivation, andentailment that can be used for semantic inference(Budanitsky and Hirst, 2006).
WordNet has alsobeen exploited to automatically generate a trainingset for a hyponym classifier (Snow et al, 2005),and we make a similar use of WordNet in Section5.1.Lexicographic resources are accurate but tendto have low coverage.
Therefore, distributionalsimilarity is used to learn broad-scale resources.Distributional similarity algorithms predict a se-mantic relation between two predicates by com-paring the arguments with which they occur.
Quitea few methods have been suggested (Lin and Pan-tel, 2001; Bhagat et al, 2007; Yates and Etzioni,2009), which differ in terms of the specifics of theways in which predicates are represented, the fea-tures that are extracted, and the function used tocompute feature vector similarity.
Details on suchmethods are given in Section 5.1.Global learning It is natural to describe en-tailment relations between predicates by a graph.Nodes represent predicates, and edges represententailment between nodes.
Nevertheless, using agraph for global learning of entailment betweenpredicates has attracted little attention.
Recently,Szpektor and Dagan (2009) presented the resourceArgument-mapped WordNet, providing entailmentrelations for predicates in WordNet.
Their re-source was built on top of WordNet, and makessimple use of WordNet?s global graph structure:new rules are suggested by transitively chaininggraph edges, and verified against corpus statistics.The most similar work to ours is Snow et al?s al-gorithm for taxonomy induction (2006).
Snow etal.
?s algorithm learns the hyponymy relation, un-der the constraint that it is a transitive relation.Their algorithm incrementally adds hyponyms toan existing taxonomy (WordNet), using a greedysearch algorithm that adds at each step the set ofhyponyms that maximize the probability of the ev-idence while respecting the transitivity constraint.In this paper we tackle a similar problem oflearning a transitive relation, but we use linear pro-gramming.
A Linear Program (LP) is an optimiza-tion problem, where a linear function is minimized(or maximized) under linear constraints.
If thevariables are integers, the problem is termed an In-teger Linear Program (ILP).
Linear programminghas attracted attention recently in several fields ofNLP, such as semantic role labeling, summariza-tion and parsing (Roth and tau Yih, 2005; Clarkeand Lapata, 2008; Martins et al, 2009).
In thispaper we formulate the entailment graph learningproblem as an Integer Linear Program, and findthat this leads to an optimal solution with respectto the target function in our experiment.3 Entailment GraphThis section presents an entailment graph struc-ture, which resembles the graph in (Szpektor andDagan, 2009).The nodes of an entailment graph are propo-sitional templates.
A propositional template is apath in a dependency tree between two argumentsof a common predicate1 (Lin and Pantel, 2001;Szpektor and Dagan, 2008).
Note that in a de-pendency parse, such a path passes through thepredicate.
We require that a variable appears in atleast one of the argument positions, and that eachsense of a polysemous predicate corresponds to aseparate template (and a separate graph node): Xsubj???
treat#1obj???
Y and Xsubj???
treat#1obj???
nau-sea are propositional templates for the first senseof the predicate treat.
An edge (u, v) representsthe fact that template u entails template v. Notethat the entailment relation transcends beyond hy-ponymy.
For example, the template X is diagnosedwith asthma entails the template X suffers fromasthma, although one is not a hyponoym of theother.
An example of an entailment graph is givenin Figure 1, left.Since entailment is a transitive relation, an en-tailment graph is transitive, i.e., if the edges (u, v)and (v, w) are in the graph, so is the edge (u,w).This is why we require that nodes be sense-specified, as otherwise transitivity does not hold:Possibly a ?
b for one sense of b, b ?
c for an-other sense of b, but a9 c.Because graph nodes represent propositions,which generally have a clear truth value, we canassume that transitivity is indeed maintained alongpaths of any length in an entailment graph, as en-tailment between each pair of nodes either occursor doesn?t occur with very high probability.
Wesupport this further in section 4.1, where we show1We restrict our discussion to templates with two argu-ments, but generalization is straightforward.1221X-related-to-nausea X-associated-with-nauseaX-prevent-nausea X-help-with-nauseaX-reduce-nausea X-treat-nausearelated to nauseaheadacheOxicontinehelp with nauseaprevent nauseaacupuncturegingerreduce nausearelaxationtreat nauseadrugsNabiloneLorazepamFigure 1: Left: An entailment graph.
For clarity, edges that can be inferred by transitivity are omitted.
Right: A hierarchicalsummary of propositions involving nausea as an argument, such as headache is related to nausea, acupuncture helps withnausea, and Lorazepam treats nausea.that in our experimental setting the length of pathsin the entailment graph is relatively small.Transitivity implies that in each strong connec-tivity component2 of the graph, all nodes are syn-onymous.
Moreover, if we merge every strongconnectivity component to a single node, thegraph becomes a Directed Acyclic Graph (DAG),and the graph nodes can be sorted and presentedhierarchically.
Next, we show an application thatleverages this property.4 Motivating ApplicationIn this section we propose an application that pro-vides a hierarchical view of propositions extractedfrom a corpus, based on an entailment graph.Organizing information in large collections hasbeen found to be useful for effective informationaccess (Kaki, 2005; Stoica et al, 2007).
It allowsfor easier data exploration, and provides a compactview of the underlying content.
A simple form ofstructural presentation is by a single hierarchy, e.g.
(Hofmann, 1999).
A more complex approach ishierarchical faceted metadata, where a number ofconcept hierarchies are created, corresponding todifferent facets or dimensions (Stoica et al, 2007).Hierarchical faceted metadata categorizes con-cepts of a domain in several dimensions, but doesnot specify the relations between them.
For ex-ample, in the health-care domain we might havefacets for categories such as diseases and symp-toms.
Thus, when querying about nausea, onemight find it is related to vomitting and chickenpox, but not that chicken pox is a cause of nausea,2A strong connectivity component is a subset of nodes inthe graph where there is a path from any node to any othernode.while nausea is often accompanied by vomitting.We suggest that the prominent informationin a text lies in the propositions it contains,which specify particular relations between theconcepts.
Propositions have been mostly pre-sented through unstructured textual summaries ormanually-constructed ontologies, which are ex-pensive to build.
We propose using the entail-ment graph structure, which describes entailmentrelations between predicates, to naturally presentpropositions hierarchically.
That is, the entailmenthierarchy can be used as an additional facet, whichcan improve navigation and provide a compact hi-erarchical summary of the propositions.Figure 1 illustrates a scenario, on which weevaluate later our learning algorithm.
Assume auser would like to retrieve information about a tar-get concept such as nausea.
We can extract the setof propositions where nausea is an argument auto-matically from a corprus, and learn an entailmentgraph over propositional templates derived fromthe extracted propositions, as illustrated in Figure1, left.
Then, we follow the steps in the processdescribed in Section 3: merge synonymous nodesthat are in the same strong connectivity compo-nent, and turn the resulting DAG into a predicatehierarchy, which we can then use to present thepropositions (Figure 1, right).
Note that in allpropositional templates one argument is the tar-get concept (nausea), and the other is a variablewhose corpus instantiations can be presented ac-cording to another hierarchy (e.g.
Nabilone andLorazepam are types of drugs).Moreover, new propositions are inferred fromthe graph by transitivity.
For example, from theproposition ?relaxation reduces nausea?
we can in-1222fer the proposition ?relaxation helps with nausea?.4.1 Focused entailment graphsThe application presented above generates entail-ment graphs of a specific form: (1) Propositionaltemplates have exactly one argument instantiatedby the same entity (e.g.
nausea).
(2) The predicatesense is unspecified, but due to the rather smallnumber of nodes and the instantiating argument,each predicate corresponds to a unique sense.Generalizing this notion, we define a focusedentailment graph to be an entailment graph wherethe number of nodes is relatively small (and con-sequently paths in the graph are short), and predi-cates have a single sense (so transitivity is main-tained without sense specification).
Section 5presents an algorithm that given the set of nodesof a focused entailment graph learns its edges, i.e.,the entailment relations between all pairs of nodes.The algorithm is evaluated in Section 6 using ourproposed application.
For brevity, from now onthe term entailment graph will stand for focusedentailment graph.5 Learning Entailment Graph EdgesIn this section we present an algorithm for learn-ing the edges of an entailment graph given its setof nodes.
The first step is preprocessing: We usea large corpus and WordNet to train an entail-ment classifier that estimates the likelihood thatone propositional template entails another.
Next,we can learn on the fly for any input graph: giventhe graph nodes, we employ a global optimiza-tion approach that determines the set of edges thatmaximizes the probability (or score) of the entiregraph, given the edge probabilities (or scores) sup-plied by the entailment classifier and the graphconstraints (transitivity and others).5.1 Training an entailment classifierWe describe a procedure for learning an entail-ment classifier, given a corpus and a lexicographicresource (WordNet).
First, we extract a large set ofpropositional templates from the corpus.
Next, werepresent each pair of propositional templates witha feature vector of various distributional similar-ity scores.
Last, we use WordNet to automaticallygenerate a training set and train a classifier.Template extraction We parse the corpus witha dependency parser and extract all propositionaltemplates from every parse tree, employing theprocedure used by Lin and Pantel (2001).
How-ever, we only consider templates containing apredicate term and arguments3.
The arguments arereplaced with variables, resulting in propositionaltemplates such as Xsubj???
affectobj???
Y.Distributional similarity representation Weaim to train a classifier that for an input templatepair (t1, t2) determines whether t1 entails t2.
Atemplate pair is represented by a feature vectorwhere each coordinate is a different distributionalsimilarity score.
There are a myriad of distribu-tional similarity algorithms.
We briefly describethose used in this paper, obtained through varia-tions along the following dimensions:Predicate representation Most algorithms mea-sure the similarity between templates with twovariables (binary templates) such as Xsubj???
af-fectobj???
Y (Lin and Pantel, 2001; Bhagat et al,2007; Yates and Etzioni, 2009).
Szpketor and Da-gan (2008) suggested learning over templates withone variable (unary templates) such as Xsubj???
af-fect, and using them to estimate a score for binarytemplates.Feature representation The features of a tem-plate are some representation of the terms that in-stantiated the argument variables in a corpus.
Tworepresentations are used in our experiment (seeSection 6).
Another variant occurs when using bi-nary templates: a template may be represented bya pair of feature vectors, one for each variable (Linand Pantel, 2001), or by a single vector, where fea-tures represent pairs of instantiations (Szpektor etal., 2004; Yates and Etzioni, 2009).
The formervariant reduces sparsity problems, while Yates andEtzioni showed the latter is more informative andperforms favorably on their data.Similarity function We consider two similarityfunctions: The Lin (2001) similarity measure, andthe Balanced Inclusion (BInc) similarity measure(Szpektor and Dagan, 2008).
The former is asymmetric measure and the latter is asymmetric.Therefore, information about the direction of en-tailment is provided by the BInc measure.We then generate for any (t1, t2) features thatare the 12 distributional similarity scores using allcombinations of the dimensions.
This is reminis-cent of Connor and Roth (2007), who used the out-put of unsupervised classifiers as features for a su-pervised classifier in a verb disambiguation task.3Via a simple heuristic, omitted due to space limitations1223Training set generation Following the spirit ofSnow et al (2005), WordNet is used to automati-cally generate a training set of positive (entailing)and negative (non-entailing) template pairs.
LetT be the set of propositional templates extractedfrom the corpus.
For each ti ?
T with two vari-ables and a single predicate word w, we extractfrom WordNet the set H of direct hypernyms andsynonyms of w. For every h ?
H , we generate anew template tj from ti by replacing w with h. Iftj ?
T , we consider (ti, tj) to be a positive exam-ple.
Negative examples are generated analogously,by looking at direct co-hyponyms of w instead ofhypernyms and synonyms.
This follows the no-tion of ?contrastive estimation?
(Smith and Eisner,2005), since we generate negative examples thatare semantically similar to positive examples andthus focus the classifier?s attention on identifyingthe boundary between the classes.
Last, we filtertraining examples for which all features are zero,and sample an equal number of positive and neg-ative examples (for which we compute similarityfeatures), since classifiers tend to perform poorlyon the minority class when trained on imbalanceddata (Van Hulse et al, 2007; Nikulin, 2008).5.2 Global learning of edgesOnce the entailment classifier is trained we learnthe graph edges given its nodes.
This is equiv-alent to learning all entailment relations betweenall propositional template pairs for that graph.To learn edges we consider global constraints,which allow only certain graph topologies.
Sincewe seek a global solution under transitivity andother constraints, linear programming is a naturalchoice, enabling the use of state of the art opti-mization packages.
We describe two formulationsof integer linear programs that learn the edges: onemaximizing a global score function, and anothermaximizing a global probability function.Let Iuv be an indicator denoting the event thatnode u entails node v. Our goal is to learn theedges E over a set of nodes V .
We start by formu-lating the constraints and then the target functions.The first constraint is that the graph must re-spect transitivity.
Our formulation is equivalent tothe one suggested by Finkel and Manning (2008)in a coreference resolution task:?u,v,w?V Iuv + Ivw ?
Iuw ?
1In addition, for a few pairs of nodes we havestrong evidence that one does not entail the otherand so we add the constraint Iuv = 0.
Combinedwith the constraint of transitivity this implies thatthere must be no path from u to v. This is done inthe following two scenarios: (1) When two nodesu and v are identical except for a pair of words wuand wv, and wu is an antonym of wv, or a hyper-nym of wv at distance ?
2.
(2) When two nodesu and v are transitive opposites, that is, if u =Xsubj???
wobj???
Y and v = Xobj???
wsubj???
Y ,for any word w4.Score-based target function We assume an en-tailment classifier estimating a positive score Suvif it believes Iuv = 1 and a negative score other-wise (for example, an SVM classifier).
We lookfor a graph G that maximizes the sum of scoresover the edges:G?
= argmaxGS(G)= argmaxG???u6=vSuvIuv???
?|E|where ?|E| is a regularization term reflectingthe fact that edges are sparse.
Note that this con-stant needs to be optimized on a development set.Probabilistic target function Let Fuv be thefeatures for the pair of nodes (u, v) and F =?u6=vFuv.
We assume an entailment classifier es-timating the probability of an edge given its fea-tures: Puv = P (Iuv = 1|Fuv).
We look for thegraph G that maximizes the posterior probabilityP (G|F ):G?
= argmaxGP (G|F )Following Snow et al, we make two inde-pendence assumptions: First, we assume eachset of features Fuv is independent of other setsof features given the graph G, i.e., P (F |G) =?u6=v P (Fuv|G).
Second, we assume the featuresfor the pair (u, v) are generated by a distributiondepending only on whether entailment holds for(u, v).
Thus, P (Fuv|G) = P (Fuv|Iuv).
Last,for simplicity we assume edges are independentand the prior probability of a graph is a productof the prior probabilities of the edge indicators:4We note that in some rare cases transitive verbs are in-deed reciprocal, as in ?X marry Y?, but in the grand ma-jority of cases reciprocal activities are not expressed usinga transitive-verb structure.1224P (G) =?u6=v P (Iuv).
Note that although weassume edges are independent, dependency is stillexpressed using the transitivity constraint.
We ex-press P (G|F ) using the assumptions above andBayes rule:P (G|F ) ?
P (G)P (F |G)=?u6=v[P (Iuv)P (Fuv|Iuv)]=?u6=vP (Iuv)P (Iuv|Fuv)P (Fuv)P (Iuv)?
?u6=vP (Iuv|Fuv)=?
(u,v)?EPuv ??(u,v)/?E(1?
Puv)Note that the prior P (Fuv) is constant with re-spect to the graph.
Now we look for the graph thatmaximizes logP (G|F ):G?
= argmaxG?
(u,v)?ElogPuv +?(u,v)/?Elog(1?
Puv)= argmaxG?u6=v[Iuv ?
logPuv+ (1?
Iuv) ?
log(1?
Puv)]= argmaxG?u6=vlogPuv1?
Puv?
Iuv(in the last transition we omit the constant?u6=v log(1?Puv)).
Importantly, while the score-based formulation contains a parameter ?
that re-quires optimization, this probabilistic formulationis parameter free and does not utilize a develop-ment set at all.Since the variables are binary, both formula-tions are integer linear programs with O(|V |2)variables and O(|V |3) transitivity constraints thatcan be solved using standard ILP packages.Our work resembles Snow et al?s in that bothtry to learn graph edges given a transitivity con-straint.
However, there are two key differencesin the model and in the optimization algorithm.First, Snow et al?s model attempts to determinethe graph that maximizes the likelihood P (F |G)and not the posterior P (G|F ).
Therefore, theirmodel contains an edge prior P (Iuv) that has tobe estimated, whereas in our model it cancels out.Second, they incrementally add hyponyms to alarge taxonomy (WordNet) and therefore utilize agreedy algorithm, while we simultaneously learnall edges of a rather small graph and employ in-teger linear programming, which is more soundtheoretically, and as shown in Section 6, leads toan optimal solution.
Nevertheless, Snow et al?smodel can also be formulated as a linear programwith the following target function:argmaxG?u6=vlogPuv ?
P (Iuv = 0)(1?
Puv) ?
P (Iuv = 1)IuvNote that if the prior inverse odds k =P (Iuv=0)P (Iuv=1)= 1, i.e., P (Iuv = 1) = 0.5, thenthis is equivalent to our probabilistic formulation.We implemented Snow et als model and optimiza-tion algorithm and in Section 6.3 we compare ourmodel and optimization algorithm to theirs.6 Experimental EvaluationThis section presents our evaluation, which isgeared for the application proposed in Section 4.6.1 Experimental settingA health-care corpus of 632MB was harvestedfrom the web and parsed with the Minipar parser(Lin, 1998).
The corpus contains 2,307,585sentences and almost 50 million word tokens.We used the Unified Medical Language System(UMLS)5 to annotate medical concepts in the cor-pus.
The UMLS is a database that maps nat-ural language phrases to over one million con-cept identifiers in the health-care domain (termedCUIs).
We annotated all nouns and noun phrasesthat are in the UMLS with their possibly multi-ple CUIs.
We extracted all propositional templatesfrom the corpus, where both argument instantia-tions are medical concepts, i.e., annotated with aCUI (?50,000 templates).
When computing dis-tributional similarity scores, a template is repre-sented as a feature vector of the CUIs that instan-tiate its arguments.To evaluate the performance of our algo-rithm, we constructed 23 gold standard entailmentgraphs.
First, 23 medical concepts, representingtypical topics of interest in the medical domain,were manually selected from a list of the most fre-quent concepts in the corpus.
For each concept,nodes were defined by extracting all propositional5http://www.nlm.nih.gov/research/umls1225Using a development set Not using a development setEdges Propositions Edges PropositionsR P F1 R P F1 R P F1 R P F1LP 46.0 50.1 43.8 67.3 69.6 66.2 48.7 41.9 41.2 67.9 62.0 62.3Greedy 45.7 37.1 36.6 64.2 57.2 56.3 48.2 41.7 41.0 67.8 62.0 62.4Local-LP 44.5 45.3 38.1 65.2 61.0 58.6 69.3 19.7 26.8 82.7 33.3 42.6Local1 53.5 34.9 37.5 73.5 50.6 56.1 92.9 11.1 19.7 95.4 18.6 30.6Local2 52.5 31.6 37.7 69.8 50.0 57.1 63.2 24.9 33.6 77.7 39.3 50.5Local?1 53.5 38.0 39.8 73.5 54.6 59.1 92.6 11.3 20.0 95.3 18.9 31.1Local?2 52.5 32.1 38.1 69.8 50.6 57.4 63.1 25.5 34.0 77.7 39.9 50.9WordNet - - - - - - 10.8 44.1 13.2 39.9 72.4 47.3Table 1: Results for all experimentstemplates for which the target concept instanti-ated an argument at least K(= 3) times (averagenumber of graph nodes=22.04, std=3.66, max=26,min=13).Ten medical students constructed the gold stan-dard of graph edges.
Each concept graph wasannotated by two students.
Following RTE-5practice (Bentivogli et al, 2009), after initial an-notation the two students met for a reconcili-ation phase.
They worked to reach an agree-ment on differences and corrected their graphs.Inter-annotator agreement was calculated usingthe Kappa statistic (Siegel and Castellan, 1988)both before (?
= 0.59) and after (?
= 0.9) rec-onciliation.
882 edges were included in the 23graphs out of a possible 10,364, providing a suf-ficiently large data set.
The graphs were randomlysplit into a development set (11 graphs) and a testset (12 graphs)6.
The entailment graph fragmentin Figure 1 is from the gold standard.The graphs learned by our algorithm were eval-uated by two measures, one evaluating the graphdirectly, and the other motivated by our applica-tion: (1) F1 of the learned edges compared to thegold standard edges (2) Our application providesa summary of propositions extracted from the cor-pus.
Note that we infer new propositions by prop-agating inference transitively through the graph.Thus, we compute F1 for the set of propositionsinferred from the learned graph, compared to theset inferred based on the gold standard graph.
Forexample, given the proposition from the corpus?relaxation reduces nausea?
and the edge ?X re-duce nausea?
X help with nausea?, we evaluatethe set {?relaxation reduces nausea?, ?relaxationhelps with nausea?}.
The final score for an algo-rithm is a macro-average over the 12 graphs of the6Test set concepts were: asthma, chemotherapy, diarrhea,FDA, headache, HPV, lungs, mouth, salmonella, seizure,smoking and X-ray.test set.6.2 Evaluated algorithmsLocal algorithms We described 12 distributionalsimilarity measures computed over our corpus(Section 5.1).
For each measure we computed foreach template t a list of templates most similar tot (or entailing t for directional measures).
In ad-dition, we obtained similarity lists learned by Linand Pantel (2001), and replicated 3 similarity mea-sures learned by Szpektor and Dagan (2008), overthe RCV1 corpus7.
For each distributional similar-ity measure (altogether 16 measures), we learned agraph by inserting any edge (u, v), when u is in thetop K templates most similar to v. We also omit-ted edges for which there was strong evidence thatthey do not exist, as specified by the constraintsin Section 5.2.
Another local resource was Word-Net where we inserted an edge (u, v) when v wasa direct hypernym or synonym of u.
For all algo-rithms, we added all edges inferred by transitivity.Global algorithms We experimented with all6 combinations of the following two dimensions:(1) Target functions: score-based, probabilisticand Snow et al?s (2) Optimization algorithms:Snow et al?s greedy algorithm and a standard ILPsolver.
A training set of 20,144 examples was au-tomatically generated, each example representedby 16 features using the distributional similaritymeasures mentioned above.
SVMperf (Joachims,2005) was used to train an SVM classifier yield-ing Suv, and the SMO classifier from WEKA (Hallet al, 2009) estimated Puv.
We used the lpsolve8package to solve the linear programs.
In all re-sults, the relaxation ?u,v0 ?
Iuv ?
1 was used,which guarantees an optimal output solution.
In7http://trec.nist.gov/data/reuters/reuters.html.
The simi-larity lists were computed using: (1) Unary templates andthe Lin function (2) Unary templates and the BInc function(3) Binary templates and the Lin function8http://lpsolve.sourceforge.net/5.5/1226Global=T/Local=F Global=F/Local=TGS= T 50 143GS= F 140 1087Table 2: Comparing disagreements between the best localand global algorithms against the gold standardall experiments the output solution was integer,and therefore it is optimal.
Constructing graphnodes and learning its edges given an input con-cept took 2-3 seconds on a standard desktop.6.3 Results and analysisTable 1 summarizes the results of the algorithms.The left half depicts methods where the develop-ment set was needed to tune parameters, and theright half depicts methods that do not require a(manually created) development set at all.
Hence,our score-based LP (tuned-LP), where the param-eter ?
is tuned, is on the left, and the probabilis-tic LP (untuned-LP) is on the right.
The rowGreedy is achieved by using the greedy algorithminstead of lpsolve.
The row Local-LP is achievedby omitting global transitivity constraints, makingthe algorithm completely local.
We omit Snow etal.
?s formulation, since the optimal prior inverseodds k was almost exactly 1, which conflates withuntuned-LP.The rows Local1 and Local2 present the bestdistributional similarity resources.
Local1 isachieved using binary templates, the Lin function,and a single vector with feature pairs.
Local2 isidentical but employs the BInc function.
Local?1and Local?2 also exploit the local constraints men-tioned above.
Results on the left were achievedby optimizing the top-K parameter on the devel-opment set, and on the right by optimizing on thetraining set automatically generated from Word-Net.The global methods clearly outperform localmethods: Tuned-LP outperforms significantly alllocal methods that require a development set bothon the edges F1 measure (p<.05) and on thepropositions F1 measure (p<.01)9.
The untuned-LP algorithm also significantly outperforms all lo-cal methods that do not require a developmentset on the edges F1 measure (p<.05) and onthe propositions F1 measure (p<.01).
Omittingthe global transitivity constraints decreases perfor-mance, as shown by Local-LP.
Last, local meth-9We tested significance using the two-sided Wilcoxonrank test (Wilcoxon, 1945)GlobalX-treat-headacheX-prevent-headacheX-reduce-headacheX-report-headacheX-suffer-from-headacheX-experience-headacheFigure 2: Subgraph of tuned-LP output for ?headache?GlobalX-treat-headacheX-prevent-headacheX-reduce-headacheX-report-headacheX-suffer-from-headacheX-experience-headacheFigure 3: Subgraph of Local?1 output for?headache?ods are sensitive to parameter tuning and in theabsence of a development set their performancedramatically deteriorates.To further establish the merits of global algo-rithms, we compare (Table 2) tuned-LP, the bestglobal algorithm, with Local?1, the best local al-gorithm.
The table considers all edges where thetwo algorithms disagree, and counts how manyare in the gold standard and how many are not.Clearly, tuned-LP is superior at avoiding wrongedges (false positives).
This is because tuned-LP refrains from adding edges that subsequentlyinduce many undesirable edges through transitiv-ity.
Figures 2 and 3 illustrate this by compar-ing tuned-LP and Local?1 on a subgraph of theHeadache concept, before adding missing edgesto satisfy transitivity to Local?1 .
Note that Local?1inserts a single wrong edge X-report-headache?X-prevent-headache, which leads to adding 8 morewrong edges.
This is the type of global considera-tion that is addressed in an ILP formulation, but isignored in a local approach and often overlookedwhen employing a greedy algorithm.
Figure 2 alsoillustrates the utility of a local entailment graph forinformation presentation.
Presenting informationaccording to this subgraph distinguishes betweenpropositions dealing with headache treatments and1227propositions dealing with headache risk groups.Comparing our use of an ILP algorithm tothe greedy one reveals that tuned-LP significantlyoutperforms its greedy counterpart on both mea-sures (p<.01).
However, untuned-LP is practicallyequivalent to its greedy counterpart.
This indicatesthat in this experiment the greedy algorithm pro-vides a good approximation for the optimal solu-tion achieved by our LP formulation.Last, when comparing WordNet to local distri-butional similarity methods, we observe low recalland high precision, as expected.
However, globalmethods achieve much higher recall than WordNetwhile maintaining comparable precision.The results clearly demonstrate that a global ap-proach improves performance on the entailmentgraph learning task, and the overall advantage ofemploying an ILP solver rather than a greedy al-gorithm.7 ConclusionThis paper presented a global optimization algo-rithm for learning entailment relations betweenpredicates represented as propositional templates.We modeled the problem as a graph learning prob-lem, and searched for the best graph under a globaltransitivity constraint.
We used Integer LinearProgramming to solve the optimization problem,which is theoretically sound, and demonstratedempirically that this method outperforms local al-gorithms as well as a greedy optimization algo-rithm on the graph learning task.Currently, we are investigating a generalizationof our probabilistic formulation that includes aprior on the edges, and the relation of this priorto the regularization term introduced in our score-based formulation.
In future work, we would liketo learn general entailment graphs over a largenumber of nodes.
This will introduce a challengeto our current optimization algorithm due to com-plexity issues, and will require careful handling ofpredicate ambiguity.
Additionally, we will inves-tigate novel features for the entailment classifier.This paper used distributional similarity, but othersources of information are likely to improve per-formance further.AcknowledgmentsWe would like to thank Roy Bar-Haim, DavidCarmel and the anonymous reviewers for theiruseful comments.
We also thank Dafna Berantand the nine students who prepared the gold stan-dard data set.
This work was developed underthe collaboration of FBK-irst/University of Haifaand was partially supported by the Israel ScienceFoundation grant 1112/08.
The first author isgrateful to the Azrieli Foundation for the award ofan Azrieli Fellowship, and has carried out this re-search in partial fulllment of the requirements forthe Ph.D. degree.ReferencesLuisa Bentivogli, Ido Dagan, Hoa Trang Dang, DaniloGiampiccolo, and Bernarde Magnini.
2009.
Thefifth Pascal recognizing textual entailment chal-lenge.
In Proceedings of TAC-09.Rahul Bhagat, Patrick Pantel, and Eduard Hovy.
2007.LEDIR: An unsupervised algorithm for learning di-rectionality of inference rules.
In Proceedings ofEMNLP-CoNLL.Alexander Budanitsky and Graeme Hirst.
2006.
Eval-uating wordnet-based measures of lexical semanticrelatedness.
Computational Linguistics, 32(1):13?47.James Clarke and Mirella Lapata.
2008.
Global in-ference for sentence compression: An integer linearprogramming approach.
Journal of Artificial Intelli-gence Research, 31:273?381.Michael Connor and Dan Roth.
2007.
Context sensi-tive paraphrasing with a single unsupervised classi-fier.
In Proceedings of ECML.Ido Dagan, Bill Dolan, Bernardo Magnini, and DanRoth.
2009.
Recognizing textual entailment: Ratio-nal, evaluation and approaches.
Natural LanguageEngineering, 15(4):1?17.Christiane Fellbaum, editor.
1998.
WordNet: An Elec-tronic Lexical Database (Language, Speech, andCommunication).
The MIT Press.Jenny Rose Finkel and Christopher D. Manning.
2008.Enforcing transitivity in coreference resolution.
InProceedings of ACL-08: HLT, Short Papers.Mark Hall, Eibe Frank, Geoffrey Holmes, BernhardPfahringer, Peter Reutemann, and Ian H. Witten.2009.
The WEKA data mining software: An up-date.
SIGKDD Explorations, 11(1).Thomas Hofmann.
1999.
The cluster-abstractionmodel: Unsupervised learning of topic hierarchiesfrom text data.
In Proceedings of IJCAI.Thorsten Joachims.
2005.
A support vector method formultivariate performance measures.
In Proceedingsof ICML.1228Mika Kaki.
2005.
Findex: Search results categorieshelp users when document ranking fails.
In Pro-ceedings of CHI.Dekang Lin and Patrick Pantel.
2001.
Discovery of in-ference rules for question answering.
Natural Lan-guage Engineering, 7(4):343?360.Dekang Lin.
1998.
Dependency-based evaluation ofMinipar.
In Proceedings of the Workshop on Evalu-ation of Parsing Systems at LREC.Andre Martins, Noah Smith, and Eric Xing.
2009.Concise integer linear programming formulationsfor dependency parsing.
In Proceedings of ACL.Vladimir Nikulin.
2008.
Classification of imbalanceddata with random sets and mean-variance filtering.IJDWM, 4(2):63?78.Dan Roth and Wen tau Yih.
2005.
Integer linear pro-gramming inference for conditional random fields.In Proceedings of ICML, pages 737?744.Satoshi Sekine.
2005.
Automatic paraphrase discoverybased on context and keywords between ne pairs.
InProceedings of IWP.Sideny Siegel and N. John Castellan.
1988.
Non-parametric Statistics for the Behavioral Sciences.McGraw-Hill, New-York.Noah Smith and Jason Eisner.
2005.
Contrastive es-timation: Training log-linear models on unlabeleddata.
In Proceedings of ACL.Rion Snow, Daniel Jurafsky, and Andrew Y. Ng.
2005.Learning syntactic patterns for automatic hypernymdiscovery.
In Proceedings of NIPS.Rion Snow, Daniel Jurafsky, and Andrew Y. Ng.
2006.Semantic taxonomy induction from heterogenousevidence.
In Proceedings of ACL.Emilia Stoica, Marti Hearst, and Megan Richardson.2007.
Automating creation of hierarchical facetedmetadata structures.
In Proceedings of NAACL-HLT.Idan Szpektor and Ido Dagan.
2008.
Learning entail-ment rules for unary templates.
In Proceedings ofCOLING.Idan Szpektor and Ido Dagan.
2009.
Augmentingwordnet-based inference with argument mapping.In Proceedings of TextInfer-2009.Idan Szpektor, Hristo Tanev, Ido Dagan, and Bonaven-tura Coppola.
2004.
Scaling web-based acquisitionof entailment relations.
In Proceedings of EMNLP.Jason Van Hulse, Taghi Khoshgoftaar, and AmriNapolitano.
2007.
Experimental perspectives onlearning from imbalanced data.
In Proceedings ofICML.Frank Wilcoxon.
1945.
Individual comparisons byranking methods.
Biometrics Bulletin, 1:80?83.Alexander Yates and Oren Etzioni.
2009.
Unsuper-vised methods for determining object and relationsynonyms on the web.
Journal of Artificial Intelli-gence Research, 34:255?296.1229
