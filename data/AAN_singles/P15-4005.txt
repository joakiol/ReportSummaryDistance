Proceedings of ACL-IJCNLP 2015 System Demonstrations, pages 25?30,Beijing, China, July 26-31, 2015.c?2015 ACL and AFNLPMulti-modal Visualization and Search for Text and Prosody AnnotationsMarkus G?artner Katrin Schweitzer Kerstin Eckart Jonas KuhnInstitute for Natural Language ProcessingUniversity of Stuttgart{markus.gaertner,kati,eckartkn,kuhn}@ims.uni-stuttgart.deAbstractWe present ICARUS for intonation, an in-teractive tool to browse and search au-tomatically derived descriptions of fun-damental frequency contours.
It offersaccess to tonal features in combinationwith other annotation layers like part-of-speech, syntax or coreference and visual-izes them in a highly customizable graphi-cal interface with various playback func-tions.
The built-in search allows multi-level queries, the construction of whichcan be done graphically or textually, andincludes the ability to search F0contoursbased on various similarity measures.1 IntroductionIn this paper we present ICARUS for intonation,a new module for the query and visualization toolICARUS by G?artner et al.
(2013).1So far, ICARUS included modules for the han-dling of dependency treebanks (G?artner et al.,2013) and coreference data (G?artner et al., 2014),thus supporting typical annotation layers from theprocessing of written data.
However, the graphi-cal query builder and the intuitive example-basedsearch could prove just as expedient for othertypes of data, such as speech corpora, transcribedand annotated for sub word features.
This also al-lows combined research on speech and text data,e.g.
the analysis of different tonal realizations of acertain syntactic structure.ICARUS for intonation allows to importsyllable-based prosodic features into ICARUS,which can then be visualized and queried either1ICARUS for intonation is written in Java and istherefore platform independent.
It is open source (un-der GNU GPL) and we provide both sources and binariesfor download on http://www.ims.uni-stuttgart.de/data/icarus.htmlindividually or in a combined search with e.g.
syn-tactic features or coreference information.
Thelatter targets several user groups: speech data ex-perts can adjust fine-grained settings on pitch ac-cent shapes in their queries and can easily add con-straints on part-of-speech or syntax information,while an expert user of dependency treebanks canget a simple visualization of the intonation contourof a sentence.Furthermore ICARUS focuses on automatic an-notations to allow for search on large data sets.Thus ICARUS for intonation?s main features forprosodic search are based on PaIntE, a parametricintonation model (M?ohler, 1998; M?ohler, 2001).So far, most data in intonation research is man-ually annotated, which is a very time consumingtask: the time for annotating speech data is manytimes higher than the real time of the audio record-ing.
For example the Tones and Break Indices(ToBI) system for American English (Beckmanand Hirschberg, 1999) takes experienced annota-tors about 100-200 times the real time (Syrdal etal., 2001).
While manual annotations for pitchaccents and prosodic phrase boundaries can alsobe imported, our main goal with this module isto provide intonation researchers with a customiz-able tool to conduct thorough studies on very largesets of only automatically annotated speech data.In Sections 2 and 3 we introduce the PaIntEmodel and describe the current input format forthe data importer.
Section 4 demonstrates severalvisualization functionalities, and Section 5 dis-cusses the search facilities, including dependencyand intonation as well as coreference and intona-tion queries.
After discussing some related workin Section 6 we conclude in Section 7.2 The PaIntE ModelThe PaIntE model (M?ohler, 1998; M?ohler, 2001)approximates a peak in the F0contour by em-ploying a model function operating on a 3-syllable25a1a2Hztime (syllable?normalized)Figure 1: The PaIntE model function and its pa-rameters.
Figure adapted from (M?ohler, 2001).window.
There are 6 free parameters in the func-tion term which are set by the model so that theactual F0shape is fit best.
They are linguisticallymeaningful: parameter b locates the peak withinthe 3-syllable window, parameter d encodes its ab-solute height.
The remaining parameters specifythe steepness and amplitude of the rise before, andthe fall after the peak (parameters a1 and a2 forthe steepness and c1/c2 for the amplitude).Figure 1 illustrates the function.
It displays thesyllable for which the parametrization is carriedout (??)
and its immediate neighbors.
The x-axisindicates time (normalized for syllable duration,the current syllable spans from 0 to 1) and the y-axis displays the fundamental frequency in Hertz.The PaIntE model has been used for the model-ing of different languages, e.g.
Norwegian, Ital-ian, German and English (Cosi et al., 2002; Kellyand Schweitzer, in press; Schweitzer et al., 2015).3 Data RepresentationICARUS for intonation ships with reader imple-mentations for two very different formats.
Oneis an extended version of the format used for the2011 and 2012 CoNLL shared tasks (Pradhan etal., 2011; Pradhan et al., 2012) with a number ofadditional columns to accommodate features forthe syllable level.
This format stores all annota-tions corresponding to a word token in one lineand packs syllable features into a list separatedby pipe-characters (?|?).
To address syllable cen-tric data like the typical output of speech process-ing systems, a second flexible tabular format wasspecified where each line of text corresponds to asingle syllable and a global header describes thecontent of all columns and how to read and mapthem to the internal data model of ICARUS.Figure 2: PaIntE Editor currently displaying 2curves and their respective parameters.
The lowersection shows saved and named prototypes.To enable audio playback functionalityICARUS for intonation requires access to theappropriate sound files.
In both formats describedabove, special properties define the name of asound file to be used for playback.
Timestampvalues on various levels (syllable, word, sentenceor document) point to the respective section in theaudio data, which currently is required to be in theWaveform Audio File Format (*.wav files).4 VisualizationSince the ICARUS for intonation module is buildon the data model used for corpora with corefer-ence annotations in ICARUS, existing visualiza-tions for coreference data can be used.
However,they make no use of syllable level features anddo not provide playback functionality.
Thereforea couple of new visualizations have been imple-mented, adding visual information about PaIntEcurves in several levels of granularity.4.1 PaIntE EditorTo get familiar with the visualization of PaIntE pa-rameters the PaIntE Editor (Figure 2) offers userswith little or no knowledge about PaIntE a startingpoint to directly see the impact of changes to cer-tain parameters.
In this editor the user can definemultiple PaIntE curves either from scratch or byimporting them from real examples in a corpus.Changes to individual parameters can be appliedvia sliders or input fields and are displayed in real-time.
Additionally a persistent storage of PaIntEcurves is provided where the user can save param-eter sets that are of interest to him along with adescription and identifier, the latter of which canbe used when searching (see Section 5).4.2 Curve PreviewFor all visualizations dealing with PaIntE curvesICARUS for intonation provides a compact ?pre-26view?
on the sentence level (lower parts of Fig-ures 3 and 4b).
Instead of drawing the full curvesfor all syllables, only syllables in which a peakwas found (based on the peak?s timing encoded inthe PaIntE parameter b) are displayed.
The visual-ization of the curve then only uses the amplitudesof rise and fall and the absolute height of the peak(c1, c2 and d).
Since the user can freely customizethe filter window for the peak this curve previewoffers a fast way to spot interesting parts of the F0contour when exploring data manually.4.3 Document OutlineFigure 3 shows parts of the main entry point formanual exploration in ICARUS for intonation.Having selected a section of the corpus the userwishes to inspect (with sentences grouped intodocuments in the left section of the figure) he thengets a detailed outline of the contents of that doc-ument using one of several available presentationmodes.
The default visualization for data holdingPaIntE annotations arranges the document?s con-tent one sentence per line, making use of the abovementioned curve preview to provide the user witha very compact overview of an entire document.For each sentence a detail panel can be unfoldedwhich renders the complete PaIntE curves abovethe preview area.
Several aspects of the visualiza-tion are highly customizable (like the number ofwords to show detailed curves for) and the usercan select the content of the detail panel by mov-ing a slider through the sentence.An important feature of the Document Outlineis the fine-grained playback functionality.
Theuser is free to play a variety of sections of thesound data linked to the document currently beingdisplayed.
Speaker buttons at the left border playpredefined parts of the sound data like sentences orthe current content of a detail panel.
By clickingon individual word or syllable labels in the detailpanel the playback can be selected even finer.4.4 Sentence OutlineWhen only single sentences are visualized,ICARUS for intonation displays a more detailedoutline showing the PaIntE curves for all syllablesin the sentence grouped by the surrounding words.In Figure 4b part of a sentence is visualized in thisway (the screenshot also contains visual highlight-ing as its content is the result of a search).In contrast to the more condensed documentoutline, this visualization offers a great deal morespace for additional information on the syllablelevel to be displayed.
As for playback function-ality it offers granularity similar to the documentoutline, allowing the user to play the entire sen-tence or restrict it to individual words or syllables.4.5 Label PatternsBoth formats currently read by ICARUS for in-tonation can contain more information on thesyllable and word level than can be presentedto the user without overloading the visualiza-tion.
Therefore the two visualizations describedabove make heavy use of so called label pat-terns to produce the actual text displayed at var-ious locations.
A label pattern is a string de-scribing a format according to which a certaintext should be created.
Expressions of the form?{<level>:<property>}?
define where informa-tion extracted from the visualized data should beinserted.
The <level> specifies the level of datato query ({syl,word,sent,doc} for the syllable,word, sentence and document levels).
For examplethe default pattern ?
{word:form}\n{word:pos}?,used in the Document Outline (see Section 4.3) todisplay the text for a sentence, extracts the surfaceform and part-of-speech tag for a word and placesthem below each other as shown in Figure 3.
Theuser can freely define the default patterns for anumber of locations as well as change the patternsused for the active visualization on the fly.
Besidesdirectly extracting data and displaying it as text,patterns offer additional options that define how toconvert e.g.
numerical values into strings or howto post process or aggregate generated texts.
How-ever, going into details of the pattern engine is be-yond the scope of this paper.5 SearchICARUS for intonation augments both the coref-erence and dependency search facilities alreadyavailable in ICARUS by adding access to vari-ous syllable features and implementing multiplespecialized search constraints based on the PaIntEmodel.
For example the user can search for prede-fined F0contours (rise, fall, rise-fall orunaccented) based on customizable criteria oruse one of several similarity measures available,like Euclidean distance or cosine similarity.Sets of PaIntE parameters can either be definedexplicitly by listing all values or by referencing apreviously saved prototype from the PaIntE Editor27Figure 3: Visualization of the first few sentences in a document with preview curves painted above theraw text outline.
The top sentence has its detail panel unfolded, showing PaIntE curves for all syllablesof a selected number of words.by name (see Section 4.1).
The ICARUS searchengine allows queries to be created either graphi-cally (by creating nodes and attaching constraintsto them) or textually via a simple query language(G?artner et al., 2013).The following two sections outline some exam-ple use cases that combine prosodic features withstructural information on different layers for anal-ysis and Section 5.3 shows some of the similar-ity measures used for searching.
Example data inthose sections is taken from the DIRNDL corpus(Eckart et al., 2012) with coreference information(Bj?orkelund et al., 2014) and some added features.5.1 Syntax and IntonationAs part of a recent study (Riester and Pio-ntek, in press) adjective-noun sequences from theDIRNDL corpus have been analyzed based ontheir tonal realization.
Of interest in this studyconcerning relative givenness (Wagner, 2006)were those adjective-noun sequences where theadjective was tonally more prominent than the ad-jacent noun.
An example of how to find them isshown in Figure 4.
The query (Figure 4a) willmatch adjectives (ADJA) adjacent to a followingnoun (NN) which must not have another dependentthat is either a modifying noun or name (NE).
Theresults are presented to the user using the detailedSentence Outline (Figure 4b) from Section 4.4.5.2 Coreference and IntonationBesides finding exact matches in a data set thesearch engine in ICARUS can be used to analyzevalue distributions for an annotation.
Using thequery in Figure 5a the search engine is asked tolook for mentions the size of up to 2 words thatare not the root of a coreference chain.
The spe-cial grouping operator <*> results in the creationof a frequency list (Figure 5b) over the Booleantonal prominence property (which purely relies onthe peak excursion with a customizable threshold)of the head word of each mention that was foundbased on the above constraints.
By clicking on oneof the entries in this list the user will then be pre-sented with all the instances that contributed to therespective frequency for further exploration.5.3 Similarity SearchThe continuous nature of the PaIntE parametersmakes using absolute values to search for curveforms very impractical.
Therefore ICARUS forintonation provides a collection of similarity mea-sures and other constraints that can be used to findsyllables with PaIntE curves similar to a given pro-totype.
Most of them are customizable by the userand investigation and refinement of the availablesimilarity measures is subject of ongoing work.Figure 6 shows an example of using co-sine similarity to find instances in the dataset that are similar to a defined prototypecurve.
In this case the first syllable of theaccented word ?Steinmeier?
was found to beof interest and saved in the PaIntE editor withthe identifier prototype stein.
The query[painteAngle$"$prototype stein"<="5.0"]then looks for PaIntE curves which do not differfrom the prototype by more than 5 degrees.When using PaIntE curves as part of a search28(a) graphical query(b) result outline with highlightingFigure 4: Example search query combining syntax and intonation constraints and an excerpt of thecorresponding result outline.
(a)(b)Figure 5: Simple search combining coreferenceand intonation features.
It is meant to investigatethe distribution of ?tonally prominent?
mentionsthat are given (already introduced) in a discourse.
(a)(b)Figure 6: Prototype of a PaIntE curve as found inthe data and an example result of a search usingcosine similarity.constraint the corresponding result visualizationwill render those curves when highlighting resultinstances as can be seen on the first peak (dashedblue curve) in Figures 6b.
This provides the userwith accurate information on how ?visually close?a match is towards the used constraints.6 Related WorkA number of well established tools exist for visual-ization of text corpora annotated with dependencyor coreference, many of which have been dis-cussed in other ICARUS related papers (G?artneret al., 2013; G?artner et al., 2014).
In terms ofsearch functionality those tools offer a broad rangeof complexity, ranging from string-searching onsurface forms2up to queries on multi-level anno-2http://code.google.com/p/whatswrong/tations (Zeldes et al., 2009; Pajas and?St?ep?anek,2009).
However, they do not support a dedicatedsearch and visualization for prosodic syllable levelannotations.
Tools like ELAN (Wittenburg et al.,2006) provide an interface for adding (flat) anno-tations to multi-modal corpora, but focus on audioand video data.
More importantly, ICARUS forintonation is so far the first tool using the PaIntEmodel for F0contour visualizations, a task pre-viously worked around via general curve plottingtools like R3and also is first to provide a collectionof search constraints dedicated to PaIntE curves.Eckart et al.
(2010) describe a database thatserves as a generic query tool for multiple anno-tation layers.
It allows to take annotations of tonalfeatures into account and has also been tested withthe DIRNDL corpus.
However, this database hasbeen designed as an expert system, e.g.
for inter-nal use in projects that create annotations.
It doesnot provide any visualization or query functionsbesides basic SQL queries and no sound playback.The focus on preprocessed or completely anno-tated data in ICARUS distinguishes it from typicaltools in the domain of Spoken Document Retrieval(SDR) or Spoken Term Detection (STD).
Theseuse automatic speech recognition and informationretrieval technologies in order to prepare and pro-cess audio data (Garofolo et al., 2000).7 ConclusionWe presented ICARUS for intonation, a flexiblevisualization and search tool for multi-modal (textand speech) data.
The tool augments existing vi-sualization and search features of ICARUS to han-dle prosodic annotations and introduces a collec-3http://www.r-project.org29tion of novel visualizations and search functional-ities.
In addition to the highly customizable visu-alizations it allows for a very fine-grained play-back of speech data for displayed sections of acorpus directly from within the graphical user in-terface.
The built-in search engine lets the usercombine prosodic constraints with constraints ofother annotation layers like syntax or coreference,thereby supporting complex search queries, and itfeatures aggregated result views.
Being based onthe ICARUS platform?s plugin-engine, the modulecan be extended to cover additional data formats.AcknowledgmentsThis work was funded by the German FederalMinistry of Education and Research (BMBF) viaCLARIN-D, No.
01UG1120F and the GermanResearch Foundation (DFG) via the SFB 732,project INF.ReferencesMary Beckman and Julia Hirschberg.
1999.
The ToBIAnnotation Conventions.
http://www.ling.ohio-state.edu/?tobi/ame_tobi/annotation_conventions.html.Anders Bj?orkelund, Kerstin Eckart, Arndt Riester,Nadja Schauffler, and Katrin Schweitzer.
2014.
TheExtended DIRNDL Corpus as a Resource for Coref-erence and Bridging Resolution.
In LREC.P.
Cosi, C. Avesani, F. Tesser, R. Gretter, and F. Pi-anesi.
2002.
A modified ?PaIntE?
model for Ital-ian TTS.
In Speech Synthesis, 2002.
Proceedings of2002 IEEE Workshop on, pages 131 ?
134.Kerstin Eckart, Kurt Eberle, and Ulrich Heid.
2010.An Infrastructure for More Reliable Corpus Analy-sis.
In LREC: Workshop on Web Services and Pro-cessing Pipelines in HLT, pages 8?14, Valletta.Kerstin Eckart, Arndt Riester, and Katrin Schweitzer.2012.
A Discourse Information Radio NewsDatabase for Linguistic Analysis.
In ChristianChiarcos, Sebastian Nordhoff, and Sebastian Hell-mann, editors, Linked Data in Linguistics, pages 65?75.
Springer, Heidelberg.John S. Garofolo, Cedric G. P. Auzanne, and Ellen M.Voorhees.
2000.
The TREC Spoken Document Re-trieval Track: A Success Story.
In in Text RetrievalConference (TREC) 8, pages 16?19.Markus G?artner, Gregor Thiele, Wolfgang Seeker, An-ders Bj?orkelund, and Jonas Kuhn.
2013.
ICARUS?
An Extensible Graphical Search Tool for Depen-dency Treebanks.
In ACL: System Demonstrations,pages 55?60, Sofia, Bulgaria.Markus G?artner, Anders Bj?orkelund, Gregor Thiele,Wolfgang Seeker, and Jonas Kuhn.
2014.
Visualiza-tion, Search, and Error Analysis for Coreference An-notations.
In ACL: System Demonstrations, pages7?12, Baltimore, Maryland.Niamh Kelly and Katrin Schweitzer.
in press.
Examin-ing Lexical Tonal Contrast in Norwegian Using Into-nation Modelling.
In Proceedings of the 18th Inter-national Congress of Phonetic Sciences, Glasgow,UK.Gregor M?ohler.
1998.
Describing intonation with aparametric model.
In ICSLP, volume 7, pages 2851?2854.Gregor M?ohler.
2001.
Improvements of the PaIntEmodel for F0parametrization.
Technical report, In-stitute of Natural Language Processing, Universityof Stuttgart.
Draft version.Petr Pajas and Jan?St?ep?anek.
2009.
System forQuerying Syntactically Annotated Corpora.
In ACL-IJCNLP: Software Demonstrations, pages 33?36,Suntec, Singapore.Sameer Pradhan, Lance Ramshaw, Mitchell Marcus,Martha Palmer, Ralph Weischedel, and NianwenXue.
2011.
CoNLL-2011 Shared Task: ModelingUnrestricted Coreference in OntoNotes.
In CoNLL:Shared Task, pages 1?27, Portland, Oregon, USA.Sameer Pradhan, Alessandro Moschitti, Nianwen Xue,Olga Uryupina, and Yuchen Zhang.
2012.
CoNLL-2012 Shared Task: Modeling Multilingual Unre-stricted Coreference in OntoNotes.
In EMNLP-CoNLL: Shared Task, pages 1?40, Jeju Island, Ko-rea.Arndt Riester and J?orn Piontek.
in press.
Anarchy inthe NP.
When new nouns get deaccented and givennouns don?t.
Lingua.Katrin Schweitzer, Michael Walsh, Sasha Calhoun,Hinrich Sch?utze, Bernd M?obius, Antje Schweitzer,and Grzegorz Dogil.
2015.
Exploring the relation-ship between intonation and the lexicon: Evidencefor lexicalised storage of intonation.
Speech Com-munication, 66(0):65?81.Ann K. Syrdal, Julia Hirschberg, Julie McGory, andMary Beckman.
2001.
Automatic ToBI Predic-tion and Alignment to Speed Manual Labeling ofProsody.
Speech Commun., 33(1-2):135?151.Michael Wagner.
2006.
Givenness and Locality.In Masayuki Gibson and Jonathan Howell, editors,Proceedings of SALT XVI, pages 295?312.P.
Wittenburg, H. Brugman, A. Russel, A. Klassmann,and H. Sloetjes.
2006.
ELAN: a ProfessionalFramework for Multimodality Research.
In LREC.Amir Zeldes, Julia Ritz, Anke L?udeling, and ChristianChiarcos.
2009.
ANNIS: A Search Tool for Multi-Layer Annotated Corpora.
In Proceedings of Cor-pus Linguistics.30
