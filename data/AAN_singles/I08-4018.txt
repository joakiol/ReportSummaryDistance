An Agent-Based Approach to Chinese Word SegmentationSamuel W.K.
ChanDept.
of Decision SciencesThe Chinese University of Hong KongHong Kong, Chinaswkchan@cuhk.edu.hkMickey W.C. ChongDept.
of Decision SciencesThe Chinese University of Hong KongHong Kong, Chinamickey@baf.msmail.cuhk.edu.hkAbstractThis paper presents the results of our sys-tem that has participated in the word seg-mentation task in the Fourth SIGHANBakeoff.
Our system consists of several ba-sic components which include the pre-processing, token identification and thepost-processing.
An agent-based approachis introduced to identify the weak segmen-tation points.
Our system has participatedin two open and five closed tracks in fivemajor corpora.
Our results have attainedtop five in most of the tracks in the bakeoff.In particular, it is ranked first in the opentrack of the corpus from Academia Sinica,second in the closed track of the corpusfrom City University of Hong Kong, thirdin two closed tracks of the corpora fromState Language Commission of P.R.C.
andAcademia Sinica.1 IntroductionOur word segmentation system consists of threemajor components, namely, the pre-processing,token identification and the post-processing.
In thispaper, an overview of our system is briefly intro-duced and the structure of the paper is as follows.Section 2 presents the system description.
An agentbased approach is introduced in the system.
Asso-ciated to each agent in the system, a vote is cast toindicate the certainty by each agent in the system.In Section 3, we describe the experimental resultsof our system, followed by the conclusion.2 System Description2.1 PreprocessingIn the preprocessing, the traditional Chinese char-acters, punctuation marks and other symbols arefirst identified.
Instead of training all these sym-bols with the traditional Chinese characters in anagent-based system, an initial, but rough, segmen-tation points (SPr) are first inserted to distinguishthe symbols and Chinese characters.
For example,for the input sentence shown in Figure 1, segmen-tation points are first assumed in the sentence asshown in the Figure 2, where ?/?
indicates the pres-ence of a segmentation point.
This roughly seg-mented sentence is then subject to an agent-basedlearning algorithm to have the token identification.??
6 ?
05 ??????????????????????????
?Figure 1: Original sentence for the process?
?/ 6/ ?/ 05/ ???????????????????
?/ ?/ ???
?/ ?/ ?Figure 2: Rough segmented sentence from pre-processing2.2 Token IdentificationIn this stage, a learning algorithm is first devisedand implemented.
The algorithm is based on anagent based model which is a computational modelfor simulating the actions and interactions of anorchestra of autonomous agents in the determina-tion of the possible segmentation points (SPl)(Weiss, 1999; Wooldridge, 2002).
Each agent will112Sixth SIGHAN Workshop on Chinese Language Processingmake its own decision, i.e., either true or false, forthe insertion of ?/?
between the two characters.Moreover, associated with each decision, there is avote that reflects the certainty of the decision.
Foreach training corpus, we have trained more than200 intelligent agents, each of which exhibits cer-tain aspects of segmentation experience and lan-guage behaviors.
In making the final verdict, thesystem will consult all the related agents by sum-ming up their votes.
For example, as shown in Ta-ble 1, the vote that supports there is a segmentationpoint between the characters ?
and ?
is zerowhile 57.33 votes recommend that there shouldhave no break point.
All these votes are logged forthe further post-processing.C1 C2 Vote(T) Vote(F) ND Outcome?
?
0 57.33 1.000 false?
?
44.52 6.54 0.744 true?
?
0 57.74 1.000 false?
?
64.61 0 1.000 true?
?
0 60.23 1.000 false?
?
56.29 0.99 0.965 true?
?
0.58 58.22 0.980 false?
?
58.21 0 1.000 true?
?
57.80 0 1.000 true?
?
0 51.34 1.000 false?
?
48.70 0 1.000 true?
?
60.04 0 1.000 true?
?
0 53.97 1.000 false?
?
46.19 2.00 0.917 true?
?
0 58.32 1.000 false?
?
62.44 0 1.000 true?
?
59.16 0 1.000 true?
?
4.89 40.81 0.786 false?
?
45.83 3.41 0.862 true?
?
0 60.91 1.000 false?
?
0 59.39 1.000 false?
?
54.44 0.48 0.983 true?
?
11.98 27.94 0.400 falseTable 1: Votes from agents and the ND of the cor-responding segment point.?
?/ 6 / ?/ 05 / ?/ ?
?/ ?
?/ ?
?/ ?/ ?
?/ ?/ ?
?/ ?
?/ ?/ ?
?/ ?
?/ ?/?
?/ ?
?/ ?/ ?Figure 3: Segmented sentence based on the votesfrom all agents.2.3 Post-processingIn our experience, our system is most likely togenerate over-segmented sentences.
Several tech-niques have implemented in our post-processing tomerge several tokens into ones.
As shown in theprevious steps, we have introduced two main typesof segmentation points, SPr and SPl.
In the type SPr,segmentation points are pre-inserted between sym-bol and Chinese characters.
For example, the token6 ?
will become 6/ ?
in the early beginning.Obviously, this kind of errors should be identifiedand the segmentation points should be removed.Similarly, in SPl, segmentation points are decidedby the votes.
Our post-processing is to identify theweak segmentation points which are having tie-break votes.
A normalized difference (ND) is de-fined for the certainty of the segmentation.falsetruefalsetrueVoteVoteVoteVoteND +?=  Eqn.
(1)The smaller the value of the ND, the lesser the cer-tainty of the segmentation point.
We define thesegmentation point as weak if the value of ND issmaller than a threshold.
For a weak segmentationpoint, the system will consult a dictionary andsearch for the presence of the token in the diction-ary.
The segmentation point will be removed iffound.
Otherwise, the system will leave as it is.
Asshown in the Table 1, almost all segmentationpoints with the ND value equal to 1.
This showsthat all the votes from the agents support the samedecision.
However, it seems that not all agentshave the same decision to the last characters pair???
?, with ND equal to 0.4.
If the threshold isset to be 0.4, the segmentation point will be re-examined in our post-processing.Our dictionary is constructed by tokens from thetraining corpus and the local context of the textthat is being segmented.
That is to say, besides thecorpus, the tokens from the previous segmentedtext will also contribute to the construction of thedictionary.
On the other hand, Chinese idiomshould be in one token as found in most dictionar-ies.
However, idiom sometimes would be identi-fied as a short phrase and segmented into severalpieces.
In this case, we tend to merge these smallfragments into one long token.
On the other hand,different training sources may produce differentsegmentation rules and, thus, produce different113Sixth SIGHAN Workshop on Chinese Language Processingsegmentation results.
In the open tracks, somehandlers are tailor-made for different testing data.These include handlers for English characters, date,time, organization.?
?/ 6 ?/ 05 ?/ ?
?/ ?
?/ ?
?/ ?/ ?
?/ ?/ ?
?/ ?
?/ ?/ ?
?/ ?
?/ ?/ ?
?/ ?
?/ ?/ ?Figure 4: Final result of the segmentation3 Experiments and ResultsWe have participated in five closed tracks and twoopen tracks in the bakeoff.
While we have built adictionary from each training data set for theclosed tracks, a dictionary of more than 150,000entries is maintained for the open tracks.
Table 2shows the size of the training data sets.Source of training data SizeAcademia Sinica (CKIP) 721,551City University of Hong Kong (CityU) 1,092,687University of Colorado (CTB) 642,246State Language Commission of P.R.C.
(NCC)917,255Shanxi University (SXU) 528,238Table 2: Size of the training data in the bakeoff.Tables 3 and 4 show the recall (R), precision (P),F-score (F) and our ranking in the bakeoff.
All therankings are produced based on the best run of theparticipating teams in the tracks.R P F RankCityU 0.9513 0.9430 0.9471 2ndCKIP 0.9455 0.9371 0.9413 3rdNCC 0.9365 0.9365 0.9365 3rdSXU 0.9558 0.9552 0.9555 5thTable 3: Performance of our system in the closedtracks of word segmentation task in the bakeoff.R P F RankCKIP 0.9586 0.9541 0.9563 1stNCC 0.9440 0.9517 0.9478 4thTable 4: Performance of our system in the opentracks of word segmentation task in the bakeoff.From the above tables, we have the following ob-servations:y First, our system is performing well if it is asufficient large set of training data.
This isevidenced by the results found in the trainingdata from CKIP, CityU and NCC.y Second, the dictionaries play an importantrole in our open tracks.
While we have main-tained a dictionary with 150,000 traditionalChinese words, no such a device is for oursimplified characters corpora.
Certainly, thereis a room for our further improvement.4 ConclusionIn this paper, we have presented the general over-view of our segmentation system.
Even though, itis our first time to participate the bakeoff, the ap-proach is promising.
Further exploration is neededto enhance the system.AcknowledgementThe work described in this paper was partiallysupported by the grants from the Research GrantsCouncil of the Hong Kong Special AdministrativeRegion, China (Project Nos.
CUHK4438/04H andCUHK4706/05H).ReferencesWeiss, G. (1999) Multiagent Systems, A ModernApproach to Distributed Artificial Intelligence, MITPress.Wooldridge, M. (2002).
An Introduction to MultiAgentSystems, John Wiley.114Sixth SIGHAN Workshop on Chinese Language Processing
