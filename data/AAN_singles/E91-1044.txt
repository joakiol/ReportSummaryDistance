AN ALGORITHM FOR GENERATINGNON-REDUNDANT QUANTIFIER SCOPINGSEspen J. VestreDepartment of MathematicsUniversity of OsloP.O.
Box 1053 BlindernN-0316 OSLO 3, NorwayInternet: espen@math.uio.noABSTRACTThis paper describes an algorithm for generat-ing quantifier scopings.
The algorithm is designed togenerate only logically non-redundant scopings andto partially order the scopings with a given :defaultscoping first.
Removing logical redundancy is notonly interesting per se, but also drastically reducesthe processing time.
The input and output formatsare described through a few access and construc-tion functions.
Thus, the algorithm is interesting for amodular linguistic theory, which is flexible with re-spect o syntactic and semantic framework.INTRODUCTIONNatural anguage sentences like the notorious(1) Every man loves a woman,are usually regarded to be scope ambiguous.There have been two ways to attack this problem:To generate the most probable scoping and ignorethe rest, or to generate all theoretically possiblescopings.Choosing the first alternative is actually not abad solution, since any sample piece of tex t usuallycontains few possibilities for (real) scope ambiguity,and since reasonable heuristics in most cases pickout the intended reading.
However, there are caseswhich seem to be genuinely ambiguous, or wherethe selection of the intended reading requires exten-sive world knowledge.If the second alternative is chosen, there arebasically two possible approaches: To integrate thegeneration of scopings into the grammar (like e.g.
inJohnson and Kay (90) or Halvorsen and?
Kaplan(88)), or to devise a procedure that generates thescopings from the parse output (like in Hobbs andShieber (87)).
In both cases, only structurally im-possible scopings are ruled out, like the reading of(2) Every representative of a company sawmost samplesin which "most samples" is outscoped by "everyrepresentative" but outscopes "a company" (Hobbsand Shieber (87)).Logically equivalent readings are not ruled out oneither of these proposals.
Hobbs and Shieber arguethat"When we move beyond the two first-order quantifiers to deal with the so-calledgeneralized quantifiers, such as "most",these logical redundancies become quiterare".Theoretically, they become rare.
But it mayvery well be that sentences with several occur-rences of non-first-order generalized quantifiers arenot very commonly used.
On the other hand, sen-tences with several occurrences of existential oruniversal quantifiers may be quite common.
Whatkinds of expressions that really resemble first-orderquantifiers i of course a controversial question.
Butworking natural anguage systems, with inferencemechanisms that are based on f'trst-order logic, oftenhave to simplify the interpretation process by inter-preting broad classes of expressions as plain univer-sal or existential quantifiers.
Thus, the gain of gen-erating only non-equivalent scopings may be quitesignificant in practical systems.Ordering of the scopings according to preferenceis also not treated on approaches like that of Hobbs& Shieber (87) or Johnson & Kay (90).
Hobbs &Shieber (87) are quite aware of this, and give somesuggestions on how to build ordering heuristics intothe algorithm.
On the approach of Johnson & Kay(90), scopings are generated with a DCG grammaraugmented with procedure calls for "shuffling" andapplying the quantifiers 1.
The program will returnnew scopings by backtracking.
Because of the re-cursive inside-out nature of the algorithm, it seemsdifficult to preserve generation-by-backtracking ifone wants to order the scopings.IThe quantifier shuffling method is essentially the same asin Pereira & Shieber (87), but correctly avoids the"structurally impossible" seopings mentioned above.- 251 -Scope islands: In English, only existential quanti-tiers may be extracted out of relative clauses.Notice the difference between(3a) An owner of every company attended themeeting.
(3b) A man who owns every company attendedthe meeting.A scoping algorithm must ake this into account,since it will be very difficult to filter out such read-ings at a later stage.
In the algorithm of Johnson &Kay (90), adding such a mechanism seems to bequite easy, since the shuffling and application ofquantifiers are handled in the: grammar rules.
In thealgorithm of Hobbs & Shieber (87), it is a bit moredifficult, since the language of the input forms doesnot distinguish between relative clauses and otherkinds of NP modifiers.In general, any working scoping algorithmshould meet as many linguistic constraints on scopegeneration as possible.Modularity: The main concern of Johnson & Kay(90) is to build a grammar that is independent of se-mantic formalism.
This is done by a DCG grammarusing "curly bracket notation" to include calls toformalism-dependent constructor functions.It is tempting to take this approach one step fur-ther, and let the generation Of scopings be: indepen-dent on both the syntactic and semantic theory cho-sen.A MODULAR APPROACHThe algorithm I propose provides solutions tothe four problems mentioned above simultaneously.It is an extension and generalisation f the algorithmpresented in Vestre (87)2.In the following I will make the (commonlymade) assumption that quantified formulas are 4-part objects.
I will occasionally use a simple lan-guage of generalized quantifiers, where the formulaformat isDET(x,~(x .... ) ,?
(x  .... ))for determiners DET and formulas ~, ~.
DET willbe referred to as the determiner of the quantifier, xis its variable, ~ its restriction, and V is its scope.The term quantifier will usually refer to the deter-miner with variable and restriction.2This paper is in Norwegian, I'm afraid.
An Englishoverview of the work is included in Fenstad, Langholm andVestre (89), but the details of the seoping algorithm are notdescribed there.Treating quantifiers in this way, it is easy to rule?
out the "structurally impossible" scopings men-tioned above because the formulas corresponding tothe "impossible scopings" will contain free vari-ables.
For instance, in sentence (2), the variable of"a company" (say, y) will also occur in the restrictorof "every representative".
So in order to avoid anunbound occurrence of that variable, "a company"must either have wider scope than "every represen-tative" or be bound inside its restrictor.The algorithm presupposes that a few accessfunctions are included for the type of input structure sused.
Further, a:few constructor functions must beincluded to define the format of the logical formsgenerated.The role of the main access function, get-quants, is to pick out the parts of the input structurethat are quantifiers, and to return them as a list,where the list order gives the default quantificationorder.
There are almost no limits to what kinds ofinput structures that may be used, but the quantifiersthat are returned by the access functions must con-tain their restri0tors as a substructure.
Of course,using input structures that already contain such listsof quantifiers as substructures will make the imple-mentation of get.-.quants almost rivial.In the following, I will give some rather informaldescriptions of the main functions involved.
The al-gorithm has been implemented in Common Lisp.AN OUTSIDE-IN ALGORITHMThe usual way to generate scopings is to do itinside-out: Quantifiers of a subformula re eitherapplied to the subformula or lifted to be applied at ahigher level.On the approach presented here, generation isdone outside-ini i.e.
by first choosing the outermostquantifier of the formula to be generated.
The moti-vation behind this unorthodox move is rather prag-matic: It makes it possible, as we shall see below, toimplement nonredundancy and sorting in an easyand understandable way.
It is also easy to treat ex-amples like the following, presented by Hobbs &Shieher (87):(4) Every man:i know a child of has arrivedwhere "a child of..
."
cannot be scoped outside of"Every man", since it (presumably) contains a vari-able that "Every man" binds.
Building formulasoutside-in, it is trivial to check that a formula onlycontains variables that are already bound.3The input structure will typically be output from a parser.- 252 -There may be other good reasons for choosingan outside-in approach; e.g.
if anaphora resolution isgoing to be integrated into the algorithm, or if scopegeneration is to be done incrementally: Usually, thefirst NP of a sentence contains the quantifier th~tt bydefault has the widest scope, so an outside-in algo-rithm is just the right match for an incrementalparser.The outside-in generation works in this way:1.
Select one of the quantifiers returned byget-quants.2.
Generate all possible restrictions of thisquantifier by recursively scoping the re-strictions.3.
Recursively generate all possible scopesof the quantifier by applying the scopingfunction to the input structure with theselected quantifier (and thereby thequantifiers in its restriction) removed.Note that get-quants is called anew foreach subscoping, but it will only findquantifiers which have not yet been :ap-plied.4.
Finally, construct a set of formulas: bycombining the quantifier with all the pos-sible restrictions and scopes.THE BASIC ALGORITHMI will not formulate a precise definition of the al-gorithm in some formal programming language, but Iwill in the following give a half-formal clef'tuition ofthe main functions of the algorithm as it works in itsbasic version, i.e.
with neither emoval of logical re'-dundancy nor ordering of scopings integrated intothe algorithm:The main function is scopings which takes an in.put form of (almos0 any format and returns a set ofscoped formulas:scopings(form) =\[ build-main(form) }, if form is quantifier f ee\[ build-quant(q,r,s) I q ~ get-quants(form),r ~ scope-restrictions(q),s ?
scopings(form(get-var(q)lq)) }otherwisewhere form(get-var(q)/q) means form with get-vat(q) substituted for q.
The purpose of this substi-tution is to mark the quantifier as "already bound"by replacing it with the variable it binds.
The vari-able is then used by build-main in the main formula.The function scope-restrictions is defined byscope-restrictions( quant ) =combine-restrictions({ copings(r) :r ~ get-restrictions(q)})where the role of combine-restrictions is to combinescopings when there are several restrictions to aquantifier, e.g.
both a relative clause and a preposi-tional phrase.
Roughly, combine-restrictions worksby using the application-deFined function build-con-junction to conjoin one element from each of thesets in its argument set.This is the whole algorithm in its most basic vet,sion 4, provided of course, that the functions build.main, build-quant, build-conjunction, get-quant&get-vat and get-restrictions are defined.
These maybe defined to fit almost any kind of input and outputstructure sREMOVING LOGICALREDUNDANCYWe now turn to the enhancements which arethe main concern of this paper.
We first look at themost important, he removal of logically redundantscopings.
To give a precise formulation of the kindof logical redundancy that we want to avoid, wefirst need some definitions:DefinitionA determiner DET is scope-commutativeif (for all suitable formulas) the following isequivalent:(1) DET(x, Rt(x), nET(y, R2(y), S(x, y)))(2) DET(y, R2(y), DET(x, Rt(x), S(x, y)))A determiner DET is restrictor-commuta-ave if (for all suitable formulas) the follow-hag is equivalent:(1) DET(x, Rl(x) & DET(y, R2(y), S2(x, y)),St(x))(2) DET(y, R2(y),DET(x, Rl(x) & S2(x, y), St(x)))4In this basic version, the algorithm does exacdy what thealgorithm of Hobbs & Shieber (87) does when "opaqueoperatm's" are left out.~In the actual Common Lisp implementation, substitution ofvariables for quantifiers is done by destructive listmanipulation.
This ~ s  that quanfifiers must be cons.ceils, and that the occurrence of a quantifier in the listreturned by get-quants(form) must share with theoccurrence of the same quantifier in form.- 253  -It is easily seen that both existential nd univer-sal determiners are scope-commutative, and thatexistential, but not universal, determiners are re-strictor-commutative.
In natural language, thismeans that e.g.
A representative of a company ar-rived is not ambiguous, in contrast to Every repre-sentative of every company arrived.
Typical gen-eralized quantifiers like most are neither estrictor-commutative nor scope-commutative~.Since quantifiers are selected outsideAn, it isnow easy to equip the algorithm with a mechanismto remove redundant scopings:If the surrounding quantifier had a scope-commutative determiner, quantifiers withthe same determiner and which precedethe surrounding quantifier in the defaultordering are not selected.For example, this means that in Every man lovesevery woman, "every man" has to be selected be-fore "every woman".
The algorithm will also try"every woman" as the first quantifier, but will thendiscard that alternative because "every man" can-not be selected in the next step - it precedes "everywoman" in the default ordering.
For more complexsentences, this discarding may give a significanttime saving, which will be discussed below.The algorithm also takes care of the restrictor-commutativity of existential determiners by usingthe same technique of comparing with the surround-ing quantifier when restrictions on quantifiers are re-cursively scoped.PARTIALLY ORDERING THESCOPINGSGenerating outside-in, one has a "global" viewof the generation process, which may be an advan-tage when trying to integrate ordering of scopingaccording to preference into the algorithm.
As anexample, the implemented algorithm provides a verysimple kind of preference ordering: A scoping isconsidered "better" than another scoping ff thenumber of quantifiers occurring in a non-defaultposition is lower.It is supposed that the input comes with a de-fault ordering, and that the application-specific func-tion get-quants takes care of this.
This default ordermay reflect several heuristics for scope generation;e.g.
that the of-complements of NPs usually takescope over the whole NP (and thus should be liftedby default).The trick is now to assign a "penalty" number toevery sub-scoping.
Every time several quantifierscan be chosen at a given step, the penalty is in-creased by 1 if aquantifier different from the defaultone is chosen.
And every time a quantifier is contstructed, its penalty is set to the sum of the penaltiesof the restrictor and scope subformulas.
Thus, thepenalty counts the number of quantifier displace,ments (compared to the default scoping).
The mainfunction of the Common Lisp implementation thuslooks like thisT:(defun scoplngs (form)(let (((\]list (get-quants form)))(if qllst(prefer (use-quant (car qlist) form)(use-quants (cdr qllst) form))(list (cons 0 (build-main form))))))Here prefer is a function which increases thepenalty of each Of the scopings in its second list, andcalls merge-scopings on the two lists.
Merge-scop-ings merges thetwo lists with the penalty as order-ing criterion.
This function is used whenever neededby the algorithm, such that one never needs to re-order the scoping list.
From the last function-callabove, one can also see how the coding of penaltiesis done: Atomic formulas are marked with a zero intheir car.
This number is later removed, the penaltyis always stored only in the car of the whole scopedformula.SCOPE OF RELATIVE CLAUSEQUANTIFIERSWhether it ,is a general constraint on Englishmay be questionable, but at least for practical pur-poses it seems reasonable to assume that no otherquantifiers than the existential quantifier may beextracted out of  a relative clause.The algorithm makes it easy to implement sucha constraint.
Since the quantifiers that can be usedat a given step are given by the application-definedfunction get-quants, it is easy for any implementa-tion of get.quants to filter out all non-existentialquantifiers when looking for quantifiers inside a rela-tive clause.
Here some of the burden is put on thegrammar:.
The parts of the input structures that cor-respond to relative clauses must be marked to bedistinguishable from e.g.
PP complements'.61"o prove non-scope-commutativity of most, construct anactual example where Most men love most women holds,but Most women are loved by most men does not hold (withthe default seopings)I7For clarity, the mechanism for removing logical redundancyis left out hero.SOne could also put all the burden on the grammar, if onewanted the structures to contain the quantifier list as a- 254 -THE NUMBER OF  SCOPINGSHobbs and Shieber (87) point out that just byavoiding those scopings that are structurally impos-sible, the number of scopings generated is signifi-cantly lower than n!.
For the following sentence, thereduction is from 81 = 40320 to "only" 2988:(5) A representative of  a department of  acompany gave a friend of a director of acompany a sample of a product.Of course, the sentence has only one "real"scoping!
Since the algorithm presented here avoidslogical non-redundancy b  looking at the defaultorder already when a quantifier is selected for thegeneration of a subformula, the gain for sentenceslike (5) is Iremendous 9.The above suggests that complexity for scopingalgorithms i a function of both the number of quan-tifiers in the input, and of the structure of the input.The highest number of scopings is obtained whenthe input contains n quantifiers, none of which arecontained in a restriction to one of the others.
Anexample of this is Most women give most men af lower.
In such cases, no quantifier permutationscan be sorted out on structural grounds, so the num-ber of scopings is n!.For more complex sentences, the picture isfairly complex.
The easiest ask is to look at thecase where the lowest number of scopings are ob-tained (disregarding logical redundancy), when allquantifiers are nested inside each other, e.g.
(6) Most representatives of  most depart-ments of most companies of most citiessighed.It is easy to see that if N is the function thatcounts the number of scopings in such a sentence,thennN(n) = EN(n  - k)N (k - I )k f lHere N(n - k)N (k - 1 ) is the number of sub-scopings generated if quantifier number k is selectedas the outermost, the factors are the number ofsubstructure.
This seems difficult to do with a pureunification grammar, however.9Fx)r this particular sentence, the single seeping isgenerated in less than 1/200 of the time required togenerate the 2988 scopings of the same sentence with'most' substituted for 'a'.scopings of the restriction and scope of that quanti-fier, respectively.
Of course, N(0) = 1.It can be shown that 0(2n) tN(n) - nt(n + 1 ) !Further, estimating by Stirlings formula for n/we getthe following (rough) estimate:4 n Jr(n) (,;+ lThe important observation here, is that that thenumber of scopings of the completely nested sen-tences no longer is of faculty order, but of"only" ex-ponential order.
This gives us a mathematical con-f'm~nation f the suspicion that the number of scop,ings of such sentences i  significantly lower than thenumber of permutations of quantifiers.
For sen~tences which contain two argument NPs and therest of the quantifiers nested inside each of these,the number of scopings is also N(n).
For sentenceswith three argument NPs, it is somewhat higher, butstill of exponential order.COMPUTATIONAL COMPLEXITYWhat is the optimal way to generate (an explicitrepresentation f) the n!
scopings of the worst case?The absolute lower bound of the time complexity:will necessarily be at least as bad as the lowerbound on space complexity.
And the absolute lowerbound on space complexity is given by the size of anoptimally structure-sharing direct representation fthe n!
scopings.
Such a representation will only con~tain one instance of each possible subscoping, but ithas to contain all subscopings as substructures.
Thismakes a total of n + n.(n-1)+...+n!
subscopings.Factoring out n!, we get n!
(1 + 1/1!
+ 1/2!+...+l/(n-1)!).
Readers trained in elementary cabculus, will recognize the latter sum as the Taylorpolynomial of degree n-1 around 0 of the exponentialfunction, applied to argument 1, i.e.
the sum con.verges to the number e. This means that the totalnumber of subscopings - and hence the lower boundon space complexity - is of order n!.Without any structure-sharing, the number ofsubscopings generated will of course be n.n!.
This isexactly what happens here: The algorithm pre,sented is O(n2.n!)
in time and space (provided thatno redundancy occurs).
This estimate presupposesthat get-quants i  of order n in both time and space,even when less than n quantifiers are left(presumably this figure will be better for some ira-10See .g.
Jacobsen (51), p. 19.- 255  -plementations of get-quants).
By comparison, theHobbs & Shieber algorithm is O(n!
), by using opti-mal structure sharing.Does this mean that the outside-in approachshould be rejected?
Note that we above only con-sidered the non-nested case.
In the nested case, thealgorithm presented here gains somewhat, while theHobbs&Shieber algorithm loses somewhat.
In bothcases, scoping of restrictions has to be redone forevery new application of the quantifier they restrictThis means that in the general case, the Hobbs &Shieber algorithm no longer provides optimal struc-ture sharing, while the algorithm presented hereprovides a modest structure sharing.
Now, both al-gorithms can of course be equipped with a hashtable (or even a plain array) for storing sets of sub-scopings (by the qnantifiers left to be bound).
Thishas been successfully tried out with the algorithmpresented here.
It brings the complexity down to theoptimal: O(n!)
in the worst :case, and similarly toO(4nn "3/2) in the completely nested ease.
So, thereis, at least in theory, nothing to be lost in efficiencyby using an outside-in algorithm.THE SINGLE-SCOPING CASEWhat about he promised reduction of complex-ity due to redundancy checking?
We consider thecase where a sentence contains n un-nested exis-tential quantifiers.
Then the complexity is given bythe number of times the algorithm tries to generate asubscoping, multiplied by the complexity of get-quants.
When quantifier number k is selected as theoutermost, n-k quantifiers are left applicable in theresulting recursive call to the algorithm.
Let S be thefunction that counts the number of subscopingsconsidered.
We have:nS(n) = 1 + ES(n"  k) = 2" -  1k=lThus, in the single-scoping case the algorithm isO(n-2") for input with un-nested qnantifiers (andeven lower for nested quantifiers).Although the savings will be somewhat lessspectacular for sentences wiih more than 1 scoping,this nevertheless hows that removing logical redun-dancy not only is of its own right, but also gives asignificant reduction of the complexity of the algo-rithm.MODULAR THEORIES OFLINGUISTICSThe algorithm presented here is related to thework of Johnson & Kay (90) by its modular nature.As mentioned, the intcrfacel with the syntax (parseoutput) is through a small set of access functions(set-quants, get-restrictions, get-var, and quant-type) and the interface with the semantics (the out-put of the algorithm) is through a small set of con.structor functions (build-conjuction, build-main andbuild-quant).
The implementation thus is a conve,nient "software glue" which allows a high degree offreedom in the choice of both syntactic and semanticframework.This approach is not as "nice" as that ofJohnson & Kay (90) or Halvorsen & Kaplan (88),and may on such :grounds be rejected as a theory ofthe syntactic/semantic interface.
But the question iswhether it is possible to state any relationship be.tween syntax and semantics which satisfies my fourinitial requirements (non-redundancy, ordering,special treatment of sub-clauses and modularity),and which still is "beautiful" or "simple" accordingto some standard:,REFERENCESFenstad, J.E.i Langholm, T. and Vestre, E.(1989): Representations and Interpretations.Cosmos Report no.
09, Department of Mathematics,University of Oslo.Halvorsen, PiK.
and Kaplan, R.M.
(1988):Projections and Semantic Description in Lexical-Functional Grammar, Proceedings of FGCS'88,Tokyo, Japan.
Tokyo: Institute for New GenerationSystems; 1988; Volume 3:1116-1122.Hobbs, J.R. and Shiebex, S.M.
(1987): AnAlgorithm for Generating Quantifier Scope.Computational Linguistics, Volume 13, Numbers 1-2, January-June 1987.Jacobson, N, (1951): Lectures in AbstractAlgebra.
D. van Nostrand Comp.
Ltd., New York.Johnson, M.:and Kay, M. (1990): SemanticAbstraction and Anaphora.
Proceedings ofCOLING 90.Pereira, F.C.N.
and Shieber, S.M.
(1987):Prolog and Nat~al-language Analysis.
CSLILecture Notes No.
10, CSLI, Stanford.Vestre, E. (i987): Representasjon avdirektesp?rsradl, Can& Scient.
thesis (unpublished, innor-wegian)- 256  -
