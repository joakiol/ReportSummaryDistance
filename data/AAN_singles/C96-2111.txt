Top-Down Predictive Linking and Complex-Feature-Based FormalismsJames KilburySeminar ftir Allgemeine SprachwissenschaftHeinrich-Heine-Universit~it Dt sseldorfUniversit~itsstraf3e 1D-40225 Dtisseldorf, Germanykilbury@ling.uni-duesseldorf.deAbstractAutomatic ompilation of the linking relationemployed in certain parsing algorithms for con-text-free languages is examined.
Special pro-blems arise in the extension of these algorithmsto the possibly infinite domain of feature struc-tures.
A technique is proposed which is design-ed specifically for left-recursive categories andis based on the generalization ftheir occurren-ces in a derivation.
Particular attention isdrawnto the top-down predictive character of the link-ing relation and to its significance not only asa filter for increasing the efficiency of syntacticanalysis but as a device for the top-down in-stantiation of information, which then serves asa key to the directed analysis of inflected formsas well as "unknown" or "new" words.1 IntroductionComplex-feature-based formalisms are under-stood here as equivalent to unification-basedformalisms as exemplified by PATR-II, HPSG,and others (cf Shieber 1986, Carpenter 1992).Such formalisms typically include a context-free (CF) base, which allows the use of parsingalgorithms designed for CF languages despitethe fact that complex-feature-based formalismsare essentially more powerful than CF gram-mars.
However, such an adaptation of CF algo-rithms involves their extension to possibly infi-nite nonterminal domains, which, as Shieber(1985) and Haas (1989) have shown, is nontriv-ial.Various CF algorithms make use of a binaryrelation between a goal category and the cate-gory of a constituent (phrase or word) whicheither has just been parsed or is to be parsednext.
Different erms have been used to desig-nate this relation; Kay (1980) speaks of reach-ability, while Pereira/Shieber (1987) and othersbefore them use the term linking for the rela-tion.Whatever term one takes, an important aspectof the relation is that it can be used to reducethe search space of possible syntactic analysesat an earlier point in parsing and thus serves toimprove the efficiency of a parser.
Shieber(1985, 1992) follows established terminologyin speaking of top-down filtering in connectionwith the prediction step of the Earley algo-rithm.
His central notion of restriction, wherebya restrictor is a finite subset of the paths speci-fied in a feature structure, is related to the tech-nique we introduce here, since both guaranteethe finiteness of an otherwise possibly infinitedomain of complex categories, but Shieber's re-strictors are specified manually.We propose ageneral algorithmic method ofcompilation that avoids manual specification.The focus of this discussion is on the linkingrelation used to extend left-corner parsers, rath-er than on the prediction step of the Earleyalgorithm as with Shieber, although the resultscarry over.Whereas Shieber et al (1990) have discussedsimilar techniques in the context of semantic-head-driven generation, we are concerned herewith parsing.
We view the linking relation notsimply as a filter to increase fficiency withinthe domain of syntactic analysis--this aspect isstressed by Shieber (1985) and other investiga-tors such as Bouma (1991)--but rather as adevice for the top-down predictive instantiationof information, as Shieber et al (1990) haveshown for semantic-head-driven g eration.
Inthis paper we are concerned especially withmorphosyntactic information and illustrate therelevance of predictive linking for morphologi-cal analysis and for the analysis of "unknown"or "new" lexical items.6582 Left-Corner Parsing and Linking2.1 The Left-Corner Parsing AlgorithmThe so-called left-corner (LC) parsing algo-rithm is generally credited to Rosenkrantz/Lewis (1970).
It has been presented so oftensince and is now so welbknown that a briefinformal statement of the algorithm should suf-rice here:The algorithm applies to CF grammars ingeneral; it is both correct and, with the excep-tion of derivations of the form A --+* A, whereA is a nonterminal, is complete.
It can be usedeither to compile a given CF grammar into aparser or to interpret it.The principle is simple.
To parse a string, thecurrent word form is first parsed, i.e.
looked upin the lexicon.
Whenever a constituent, be it aword form or a phrase, is successfully parsed,the syntax rules are chosen which have thecategory of the identified constituent as theirleft corner, i.e.
the left-most category in theright-hand side of the rule.
If the remainingsister categories of the left corner can beparsed, then the mother category of the rule isthe result tbr the corresponding substring, andthe algorithm continues recursively until theentire string is covered by a category; if thecategory of an expectation was specified, itmust match the category found.2.2 The Linking RelationIt was soon noted that the efficiency of thealgorithm could be improved significantlythrough the use of a reachability or linkingrelation compiled out of the grammar beforeparsing; this consists of the reflexive and transi-tive closure of the relation defined by the pairsof mother and LC categories specified in the setof syntax rules of the grammar.
Whenever alexical entry is found that assigns a category Cto a given word form, the linking relation isused to determine whether C can be useful inreaching the goal category C', i.e.
whether C isa (transitive) left corner of C'; this test is car-ried out before the parser looks for rules havingC as the left corner.
Of course, C may itself bethe category C' sought, hence the reflexive clo-sure.
Likewise, when a rule is found in whichC is the left corner, the relation tests whetherthe mother Co of C can be used to reach thegoal C' before an attempt is made to parse thesisters of C.Computation of the linking relation from aset of CF syntax rules is straightforward.
Sincethe nonterminal symbols are atomic, one merelyneeds to check for left recursive symbols sothat the computation terminates.2.3 Complex-Feature-Based FormalismsAs noted above, the extension of the LC algo-rithm to a potentially infinite nonterminal do-main, i.e.
complex feature structures, is nontriv-ial.
An example of the pitfalls awaiting naiveattempts at such an extension is provided by thegrammars illustrating the list technique for sub-categorization i troduced by Shieber (1986: 32,77-78); also see the similar example of Haas(1989: 227).
We quote Shieber's yntax rulesfor his second analysis of subcategorization(p.84), in which the subject of a verb appearsas the first element of the subcategorization list:S - - ->  NP VP : <S head> : <VP head><S head  fo rm> : f in i te<VP subcat  f i r s t> = <NP><VP subcat  res t> = end.VP  - - ->  V : <VP head> = <V head><VP subcat> == <V subcat>.VP  i - - ->  VP  2 X :- <VP 1 head> : <VP 2 head><VP-2  subcat  f i r s t> :-<VP \] subcat  f i r s t><VP 2 s~bcat  res t  f i r s t> = <X><VP--2 subcat  res t  res t> =<VP 1 subcat  res t>.The difficulties clearly lie in the last syntaxrule: VP (or VP_I and VP2) seems to be leftrecursive--whatever we may mean by that atthis point--so perhaps no link arises at all fromthis rule.
On the other hand, the two featurestructures are unifiable, but their unificationproduces acyclic feature structure, which raisesadditional problems for the definition of linkingand possibly for implementation.
The difficulty,of course, is that VP 1 and VP 2 are schematicand that these rules recursively generate a de-numerably infinite set of VP-type categories, allof which may give rise to distinct elements inthe linking relation.
Whether this is linguistical-ly important, which is improbable, or merely amathematical game is beside the point: the for-real problem is there, and we cannot individ-ually specify infinitely many links.659Consider the LC analysis of the sentenceJohn loves Mary.
After analyzing \[John\]Np, theparser expects a VP\[1\], where VP\[n\] is used asan informal alias for a VP that subcategorizesfor n complements.
Now, there is an entry for\[loves\]v, so a link <VP\[1\], V\[2\]> is neededsince loves subcategorizes for a subject and anobject.
Indeed, since the grammar allows verbsto subcategorize for any finite number of com-plements, we need an infinite number of linksbetween VP\[1\] and V\[n\] categories.
Moreover,once we have these links we need the samenumber between VP\[1\] and VP\[n\] categoriessince the first VP expansion simply unifies thesubcategorization f the Vdaughter with that ofthe VP mother.Other problems arise in grammars with indi-rect left recursion.
This is linguistically plausi-ble in the following example, where both NPand Det are indirectly left recursive:S - - -> NP VP : <NP agr> = <VP agr>.NP - - -> Det N : <NP agr> = <N agr><NP agr> = <Det  agr>.Det - - -> NP Posess ive  MarkerThe rules account for sentences like The child'sfather sleeps.
We must take care not to excludeA mother's children sleep, which will happenif the linking relation is defined so that any de-terminer--also in a possessive construction--must have the same agreement features as thesentence subject of which it is a left corner.2.4 Top-Down Predictive LinkingThe aim of our proposal is to define equiva-lence relations that keep the linking relationfinite while also preventing it from being toorestrictive; this turns the linking relation into aweakpredietion table in the sense of Haas (19-89: 227ff).
Like Shieber (1985, 1992) with thenotion of restriction, we confine our attentionto a subset of specifications; in particular, wecan define a feature structure that subsumes allVP-type feature structures of Shieber's recursivesubcategorization rules.
But unlike Shieber, ourrestrictors are computed automatically by build-ing the generalization of the occurrences ofleft-recursive categories in a grammar.The intuitive idea is that we consider catego-ries to be left recursive if their tokens can beunified (rather than being identical, as in thecase of atoms); we then use their generaliza-tion, or greatest lower bound, as a commondenominator defining an equivalence relation.We shall say that two categories build a left-recursive link, i.e.
<X, X'> e L 1 iffon the basisof the given grammar there is a derivation A-->* A't~' (where o~'is a string of categories andterminal symbols)such t at the unification A uA' exists, whether or not it is cyclic, and thereis no A" such that A --->' A" t~" -->' A' t~', whereA u A" and A" u A' exist.
Let Age, be the gene-ralization A rq A' of A and A'; then we define Xand X' as distinct copies of Ag~, such that forevery path n where A@n = A '@~, it also holdsthat X@n = X'@n, where F@n is "the value ofthe feature structure F at some path n at whichit is defined" (Carpenter 1992:38) and '=' de-notes token identity.
We thus expressly allowreentrancies between the distinct feature struc-tures X and X'; as we shall see below, this isessential in order for us to use the linking rela-tion to instantiate information during parsing.A second relation, corresponding directly tothe conventional notion of links as compileddirectly from rules, can now be defined: twocategories build a rule link, i.e.
<Ao', A ,~ ~ L 2iff on the basis of the given grammar there isa finite derivation A o --> AIo~ ~ ... A,,vo~,v ---> A,t~,with 1 < n such that for all i with 1 _< i < n itis the case that A o u Aj is undefined (i.e.
thederivation is nonrecursive), and for all i with 0< i < n it is the case that if <X, X~> ~ L 1 andA i u X exists, then A/also exists and is the ex-tension X'E A/ that  arises when A~ is unifiedwith X.
Intuitively, L 2 is given by the set ofnonrecursive derivations licensed by the gram-mar, where each left-recursive l ft-most catego-ry in the derivation is replaced by (i.e.
restrict-ed to) the generalization of the instances of thatleft-recursive category.The overall inking relation L is then definedso that <B, B~> E L iff(1) there is a <X, X'>(L~ u L2) such that B u X and B' m X' exist, orelse (2) B u B' exists (the reflexive case whereB' satisfies the parse goal B).Moore and Alshawi (1992: 134ff) describea similar algorithm that compiles the linkingrelation for complex-feature-based formalisms.But rather than computing the generalization ofleft-recursive categories to avoid the possibilityof generating an infinite relation, they instead"impose a cutoff after two nested occurrencesof the same functor in a feature specification,660substituting new unique variables for the argu-ments of the inner occurrence of the functor, sothat any constituent with a more complex fea-ture description will be accepted."
Moreover,they discuss linking only with regard to filter-ing.Our use of the linking relation with destruc-tive unification in parsing requires pecial com-ment.
I fB is a goal and B' is a parsed left cor-ner such that <X, X'> e L and B u X and B' uX' exist, then there is a link between B and B';we can stop here with a mere test of unificationif we only want to use linking as a filter toreduce the search space.
But if B and B' areactually unified with X and X', respectively,information may become shared between B andB'.
In the reflexive case of linking for comple-tion, B and B' are unified with each other.Since the information that becomes hared viaL 1 is subsumed by that of the reflexive case,completion works correctly for left-recursivecategories, but B and B' must still be unified inthe actual completion step.We have employed generalization in the defi-nition of linking to make a kind of mask allow-ing just the appropriate information to becomeshared between B and B'.
Thus, linking ceasesto be a mere test or filter and can instead func-tion as an independent device for the transmis-sion of information in parsing.Returning to Shieber's rules for subcategori-zation, the definition of L given here allowsinstantiated head features of a VP goal to bepassed top-down to a verb.
Moreover, since thetreatment ofsubcategorization of Shieber (1986:84) is adopted in which the subject NP appearsconsistently as thefirst element of the subcate-gorization list in all projections of V, then in-stantiated agreement features and other infor-mation about the subject can be passed top-down as well.
The linking relation compiledfrom the grammar in (2.3) above is listed here:ll(\[cat:vp,head:A, subcat:\[first:B, rest:C\]\],\[cat:vp,head:A, subcat:\[first:B, rest:D\]\]).12(\[cat:s\], \[cat:np\]).12(\[cat:vp,head:A, subcat:\[first:B, rest:C\]\],\[cat:v, head:A, subcat:\[first:B, rest:D\]\]).Finally, we list the linking relation compiledfrom the example with left-recursive categoriesDet and NP:iiii12121212\[cat:np\], \[cat:np\]).\[cat:det\], \[cat:det\]).\[cat:s\], \[cat:np\]).\[cat:np\], \[cat:det\]).\[cat:det\], \[cat:np\]).\[cat:s\], \[cat:det\]).In contrast to the previous example, agreementspecifications have been compiled out of therelation, but no additional convention wherebyeat specifications define a context-free skeletonis involved here.2.5 Notes on Implementation in PrologImplementation f the LC algorithm in Prologhas been discussed by Matsumoto et al (1982)for the BUP system, by Pereira/Shieber (1987),Kilbury (1990), and Covington (1994).
Here wepresent, with minor changes, the LC-based in-terpreter with linking for a modified DCG for-malism as formulated by Pereira/Shieber (1987:180ff); note that the interpreter itself is encodedas a DCG:parse(NT) --> leaf(LC, NT), ic(LC, NT).leaf(Cat,NT) --> \[Word\],{lex(Word,Cat), link(NT,Cat)}.Ic(LC, NT) -->ic(LC, NT) -->\[\], {unify(LC, NT)}.
{CO ---> \[CllCats\],unify(LC, Cl),link(NT,C0)},right(Cats),Ic(C0,NT).right(\[\]\] --> \[\].right(\[Cat\[Cs\]) --> parse(Cat), right(Cs).Our version stated here tranfers the call tolink from the definition of parse to that ofleaf; the motivation for this change steins fromour use of top-down information in the mor-phological analysis and in the treatment of mis-sing lexical entries.Moreover, our implementation uses the openProlog lists of Eisele/D6rre (1986) to encodethe feature structures of PATR-II (also seeGazdar/Mellish 1989: 228ff).
Since simple vari-able sharing does not capture the unification ofthese objects, we instead employ unify/2.The transitive subset of the linking relationcan be implemented as follows:link(C0,C\] :- (II(X,Y) ; 12(X,Y)),unify(X,C0), unify(Y,C).661Of course, such clauses lead to a highly ineffi-cient search for Prolog.
A better solution, whichwe have adopted from Kilbury (1990), is tointroduce rule numbers, which are then used todefine a purely filtering linking relation.
Thisamounts to the simplest case of the restrictiontechnique of Shieber (1985).
Only when a linkbetween umerical pointers is first found is thelinking relation between feature structures usedto instantiate information.3 Consequences of Predictive LinkingWhat is the advantage of predictive linking asdiscussed above in (2)?
In the previous parsingliterature attention has been drawn mainly tolinking as a filter employed to reduce thesearch space as early as possible in a syntacticanalysis.
But we have seen that linking as de-fined above in terms of feature structures andused in parsing with destructive unificationleads to the top-down instantiation of informa-tion.
This has far-reaching consequences for theanalysis of inflectional morphology and lexicalitems for which no entry at all or no adequateentry is found in the parser's lexicon.
We brief-ly address these areas separately.3.1 Inflectional MorphologyIf we ignore capitalization, the German wordform runden 'round' can be assigned the cate-gory N, A, or V; the corresponding inflectedforms are too numerous to list here but includee.g.
accusative plural for N, genitive singularweak inflection for A, and first person pluralpresent indicative for V. The facts of Germaninflection lead to massively disjunctive analysesin conventional systems of morphological nal-ysis that simply take an isolated inflected wordform and consider what it might be.
But if weare given a top-down prediction or expectationof the lexical category from the linking relation,then we can first find a lexical entry for thestem, use linking to confirm the appropriatenessof the entry (in our example, the appropriate-ness of the category N, A, or V) for the context,simultaneously use linking to further instantiatefeatures (in particular for agreement) on thecategory, and then check the given inflectionwithin a highly restricted search space.
Thiscaptures our intuition that an inflection like -nin German in itself bears practically no infor-mation and is functional only because we nor-mally have expectations and can greatly reducethe range of inflections possible in a given con-text.3.2 Analysis of Unknown WordsA fundamental issue for parsing lies in the areaof "unknown" or "new" words.
This involvescases where no entry at all is found for a givenword form, but also cases where an entry forthe form is found, which, however, does not fitthe given context; the missing lexical entriesmay simply have been omitted from the lexiconof a system, or may reflect novel lexical cre-ations.
The theoretical nd practical significanceof such unknown forms is great; see the discus-sion in Kilbury/Barg/Renz (1994).Even without he linking relation, unification,together with backtracking through a space ofpossible analyses (or corresponding use of achart) gives us information for the missing en-try; this in itself is not novel.
But simple exten-sions of well-known parsing algorithms presup-pose a random search through the space ofopen lexical classes to get the candidate catego-ry.
The procedure is roughly as follows: (1)once it is established that no appropriate ntryis in the lexicon, (2) arbitrarily select a catego-ry for an open lexical class, (3) check whetherit fits the given context, and (4) if it fits, takethe final feature structure for the form which isinstantiated in the course of a successfully com-pleted parse.in contrast, top-down predictive linking pro-vides for a directed search since top-down in-stantiation can propose a category.
The effi-ciency can be further increased by partitioningthe linking relation according to lexical andphrasal categories for the left corner and,among the lexical left corners, open and closedlexical classes.In implementation, missing lexical entriescan be dealt with in a first approximation byextending the interpreter with a second clausein the definition of leaf:leaf(Cat,NT) --> \[Word\],((setof(C, lex(Word, C),Cs), !
; Cs = \[\]),\+ (member(Old, Cs), l ink(NT,Old)),open lexical l ink(NT,Cat),new word(Wor~,Cat\]}.662Obviously, more needs to be said about thecontrol strategy of the modified interpretersince garden paths and structural ambiguitymust be dealt with before new entries are pos-tulated, but that goes beyond the scope of thispaper.4 ConclusionWe have presented a technique based on theoperation of generalization that provides for theautomatic computation of a linking relation foruse with complex-feature based grammar for-malisms of the kind that are currently favoredin computational linguistics.
Although our pro-posal was developed lbr left-corner parsingwith backtracking, it obviously carries over toother parsers with top-down prediction.
A fur-ther goal of this paper is to motivate a shift ofattention from linking as a mere filter to genu-inely predictive linking as a valuable device forthe top-down transport of information essentialfor other aspects of natural anguage parsing.AcknowledgementsThe research project Dynamische Erweiterungdes Lexikons (DYNALEX) is supported by theGerman Research Foundation (DFG) in theSonderfbrschungsbereich 282 lheorie des Lexi-kons.
1 wish to thank Petra Barg, ChristofRumpf, Sebastian Varges and anonymous refer-ees for their comments and suggestions.ReferencesAlshawi, Hiyan (ed.)
(1992) The Core Lan-guage Engine.
Cambridge, Mass.
& London:MIT Press.Bouma, Gosse (1991) Prediction in ChartParsing Algorithms for Categorial UnificationGrammar, Proceedings of the 5th EACL Con-terence, 179-184.Carpenter, Bob (1992) The Logic of TypedFeature Structures.
Cambridge: CUP.Covington, Michael A.
(1994) Natural Lan-guage Processing for Prolog Programmers.Englewood Cliffs: Prentice-Hall.Eisele, Andreas / Jochen DOrre (1986) ALexical Functional Grammar System in Prolog,Proceedings' of COLING-86, 551-553.Gazdar, Gerald / Chris Mellish (1989) Natu-ral Language Processing in Prolog.
An Intro-duction to Computational Linguistics.
Woking-ham et al: Addison-Wesley.l laas, Andrew (1989) A Parsing Algoritlmafor Unification Grammar.
Computational Lin-guistics 15: 219-232.Kay, Martin (1980) Algorithm Schemata ndData Structures in Syntactic Processing (= Re-port CSL-80-12).
Palo Alto: Xerox Corp.Kilbury, James (1990) QPATR and Cons-traint Threading, Proceedings of COLING-90,Vol.
3, 282-284.Kilbury, James / Petra Barg / lngrid Renz(1994) Simulation lexikalischen Erwerbs, S. W.Felix / Chr.
Habel / G. Rickheit (eds), Kogniti-ve Linguistik: Reprgisentation u d Prozesse,251-271.
Opladen: Westdeutscher Verlag.Matsumoto, Y.
/ H. Tanaka / It.
tlirakawa /H.
Miyoshi / tl.
Yasukawa (1983) BUP: ABottom-Up Parser Embedded in Prolog.
NewGeneration Computing 1: 145-158.Moore, Robert C. / Alshawi, Hiyan (1992)Syntactic and Semantic Processing, in Alshawi(1992), 129-148.Pereira, Fernando C. N. / Stuart M. Shieber(l 987) Prolog and Natural-Language Analysis(= CSLI Lecture Notes 10).
Stanford: CSLI.Rosenkrantz, D. J / P. M. Lewis (1970) l)e-terministic Left Corner Parser, IEEE Con\[er-ence Record of the l l th Annual Symposium onSwitching and Automata Theory, 139-152.Shieber, Stuart M. (1985) Using Restrictionto Extend Parsing Algorithms for Complex-Fea-ture-Based Formalisms, Proceedings of the23rd ACL Conference, 145-152.Shieber, Stuart M. (1986)An Introduction toUnification-Based Approaches to Grammar (=CSLI Lecture Notes 4).
Stanford: CSLI.Shieber, Stuart M. (1992) Constraint-BasedGrammar Formalisms.
Cambridge, Mass.
&London: M|T Press.Shieber, Stuart M. / Gertjan van Noord /Fernando C. N. Pereira / Robert C. Moore(1990) Semantic-Head-Driven Generation.Computational Linguistics 16: 30-42.663
