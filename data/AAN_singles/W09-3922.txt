Proceedings of SIGDIAL 2009: the 10th Annual Meeting of the Special Interest Group in Discourse and Dialogue, pages 148?151,Queen Mary University of London, September 2009. c?2009 Association for Computational LinguisticsAutomatic Generation of Information State Update Dialogue Systems thatDynamically Create Voice XML, as Demonstrated on the iPhoneHelen Hastie, Xingkun Liu and Oliver LemonSchool of InformaticsUniversity of Edinburgh{hhastie,xliu4,olemon}@inf.ed.ac.ukAbstractWe demonstrate DUDE1 (Dialogueand Understanding Development En-vironment), a prototype developmentenvironment that automatically generatesdialogue systems from business-userresources and databases.
These generatedspoken dialogue systems (SDS) are thendeployed on an industry standard VoiceXML platform.
Specifically, the deployedsystem works by dynamically generatingcontext-sensitive Voice XML pages.
Thedialogue move of each page is determinedin real time by the dialogue manager,which is an Information State Updateengine.
Firstly, we will demonstrate thedevelopment environment which includesautomatic generation of speech recogni-tion grammars for robust interpretation ofspontaneous speech, and uses the appli-cation database to generate lexical entriesand grammar rules.
A simple graphicalinterface allows users (i.e.
developers) toeasily and quickly create and the modifySDS without the need for expensiveservice providers.
Secondly, we willdemonstrate the deployed system whichenables participants to call up and speakto the SDS recently created.
We will alsoshow a pre-built application running onthe iPhone and Google Android phone forsearching for places such as restaurants,hotels and museums.1Patent Pending1 IntroductionWith the advent of new mobile platforms such asthe iPhone and Google Android, there is a need fora new way to interact with applications and searchfor information on the web.
Google Voice Searchis one such example.
However, we believe thatthis simple ?one-shot?
search using speech recog-nition is not optimal for the user.
A service thatallows the user to have a dialogue via their phoneopens up a wider set of possibilities.
For exam-ple, the user may be visiting a foreign city andwould like to have a discussion about the typesof restaurants, their cuisine, their price-range andeven ask for recommendations from the system ortheir friends on social networking sites.
The Di-alogue Understanding Development Environmentor DUDE makes this possible by providing a flex-ible, natural, mixed initiative dialogue using an in-formation state update dialogue engine (Bos et al,2003).Currently, if a company wishes to deploy sucha spoken dialogue system, they have to employa costly service provider with a long turn aroundtime for any changes to the system, even minorones such as a special promotion offer.
In addi-tion, there is steep competition on application sitessuch as Google Market Place and Apple App Storewhich are populated with very cheap applications.DUDE?s Development Environment takes existingbusiness-user resources and databases and auto-matically generates the dialogue system.
This re-duces development time and, therefore, costs andopens up the technology to a wider user-base.
Inaddition, the DUDE environment is so easy to usethat it gives the control back into the business-userand away from independent services providers.In this paper, we describe the architecture and148technology of the DUDE Development Environ-ment and then discuss how the deployed systemworks on a mobile platform.2 The DUDE Development EnvironmentFigure 1 shows the DUDE Development Envi-ronment architecture whereby the main algorithmtakes the business-user resources and databases asinput and uses these to automatically generate thespoken dialogue system which includes a VoiceXML generator.
Advantages of using business-user resources such as Business Process Mod-els (BPM) (Williams, 1967) include the fact thatgraphical interfaces and authoring environmentsare widely available (e.g.
Eclipse).
In addition,business-user resources can contain a lot of addi-tional information as well as call flow includingcontext, multi-media and multiple customer inter-actions.Figure 1: The DUDE Architecture2.1 Spoken Dialogue System GenerationMany sophisticated research systems are devel-oped for specific applications and cannot be eas-ily transferred to another, even very similar task ordomain.
The problem of components being do-main specific is especially prevalent in the corearea of dialogue management.
For example MIT?sPegasus and Mercury systems (Seneff, 2002) havedialogue managers (DM) that use approximately350 domain-specific hand-coded rules each.
Thesheer amount of labour required to construct sys-tems prevents them from being more widely andrapidly deployed.
We present a solution wherebyBPMs and related authoring tools are used to spec-ify domain-specific dialogue interactions whichare combined with domain-general dialogue man-agers.
Specifically, the DM consults the BPM todetermine what task-based steps to take next, suchas asking for price range after establishing pre-ferred cuisine type.
General aspects of dialogue,such as confirmation and clarification strategies,are handled by the domain-general DM.
Valuesfor constraints on transitions and branching in theBPM, for example ?present insurance offer if theuser is business-class?, are compiled into domain-specific parts of the Information State.
XML for-mat is used for BPMs, and they are compiled intofinite state machines consulted by the spoken dia-logue system.
The domain-general dialogue man-ager was mostly abstracted from the TALK system(Lemon et al, 2006).Using DUDE, developers do not have to writea single line of grammar code.
There are threetypes of grammars: (1) a core grammar, (2) agrammar generated from the database and BPM,and (3) dynamically generated grammars createdduring the dialogue.
The core grammar (1) wasdeveloped to cover basic information-seeking in-teractions.
In addition (2), the system com-piles relevant database entries and their proper-ties into the appropriate ?slot-filling?
parts of aSRGS GRXML (Speech Recognition GrammarSpecification) grammar for each specific BPMnode.
Task level grammars are used to allow alevel of mixed initiative, for example, if the sys-tem asks ?what type of cuisine??
the user canreply with cuisine and also any other slot type,such as, ?cheap Italian?.
The dynamically gen-erated grammars (3), such as for restaurants cur-rently being recommended, minimizes grammarsize and makes the system more efficient.
In ad-dition to the above-mentioned grammars, devel-opers are able to provide task spotter phrases andsynonyms reflecting how users might respond byusing the DUDE Development Environment.
Ifthese are not already covered by the existing gram-mar, DUDE automatically generates rules to coverthem.The generated SRGS GRXML grammars areused to populate the Voice XML pages and conse-quently used by the Voice XML Platform Speechrecogniser.
In this case, we deploy our system tothe Voxeo Platform (http://www.voxeo.com).
Aswell as the W3C standard SRGS GRXML, DUDEis able to generate alternative grammar specifica-tions such as SRGS ABNF (Augmented Backus-Naur Form), JSGF ABNF (Java Speech GrammarFormat) and Nuance?s GSL (Grammar Specifica-149Figure 2: Example: using the DUDE Development Environment to define spotter phrases and otherinformation for the different BPM taskstion Language).2.2 The Development EnvironmentAs mentioned above, the DUDEDevelopment En-vironment can be used to define system promptsand add task spotter phrases and synonyms to thegrammars.
Figure 2 shows the GUI with the BPMon the left hand side and the properties pane forthe restaurants task on the right hand side.
In thispane the developer can define the system prompt,the information to be presented to the user and thespotter phrases.
Here the developer is associatingthe phrases ?restaurants, restaurant, somewhere toeat....?
with the restaurant task.
This means thatif the user says ?I want somewhere to eat?, therestaurant part of the BPM will be triggered.
Notethat multi-word phrases may also be defined.
Thedefined spotters are automatically compiled intothe grammar for parsing and speech recognition.By default all the lexical entries for answer-typesfor the subtasks will already be present as spotterphrases.
DUDE checks for possible ambiguities,for example if ?pizza?
is a spotter for both cui-sine type for a restaurant task and food type for ashopping task, the system uses a clarification sub-dialogue to resolve them at runtime.Figure 3 shows the developer specifying the re-quired linguistic information to automate the cui-sine subtask of the restaurants task.
Here the de-veloper specifies the system prompt ?What typeof cuisine do you want??
and a phrase for im-plicit confirmation of provided values, e.g.
?a [X]restaurant?, where [X] is a variable that will bereplaced with the semantics of the speech recogni-tion hypothesis for the user input.
The developeralso specifies here the answer type that will resolvethe system prompt.
There are predefined answer-types extracted from the databases, and the devel-oper can select and/or edit these, adding phrasesand synonyms.
In addition, they have the abilityto define their own answer-types.Figure 3: Example: using the DUDE Develop-ment Environment to define prompts, answer sets,and database mappings for the cuisine subtask1503 Deployment of the Generated SpokenDialogue SystemThe second part of the demonstration showsa pre-built multimodal application running onthe iPhone (http://www.apple.com) and GoogleAndroid phone (http://code.google.com//android).This application allows the user to have a dialogueabout places of interest using The List website(http://www.list.co.uk).
Figure 4 shows screen-shots of the iPhone, firstly with The List home-page and then a page with content on Bar Roma,an ?italian restaurant in Edinburgh?
as requestedby the user through spoken dialogue.Figure 4: DUDE-generated iPhone List Applica-tion pushing relevant web contentFigure 5 shows the architecture of this systemwhereby the DUDE server runs the spoken dia-logue system (as outputted from the DUDEDevel-opment Environment).
This system dynamicallygenerates Voice XML pages whose dialogue moveand grammar is determined by the InformationState Update Dialogue Model.
These Voice XMLpages are sent in real time to the Voice XML plat-form (in our case Voxeo) which the user talks to byplacing a regular phone call.
In addition, DUDEcommunicates the relevant URL via a server con-nection.4 SummaryThis paper describes a demonstration of theDUDE Development Environment and its result-ing spoken dialogue systems as deployed on a mo-bile phone, specifically the iPhone and GoogleAndroid.
With the emergence of web-enabledsmart-phones, a new and innovative interactivemethod is needed that combines web-surfing andFigure 5: Architecture of deployed DUDE Appli-cation on a mobile phone (e.g.
the iPhone)dialogue in order to get the user exactly the infor-mation required in real time.5 AcknowledgementThis project is funded by a Scottish EnterpriseProof of Concept Grant (project number 8-ELM-004).
We gratefully acknowledge The List for giv-ing us data for our prototype application.ReferencesJohan Bos, Ewan Klein, Oliver Lemon, and TetsushiOka.
2003.
DIPPER: Description and Formalisa-tion of an Information-State Update Dialogue Sys-tem Architecture.
In 4th SIGdial Workshop on Dis-course and Dialogue, pages 115?124, Sapporo.Adam Cheyer and David Martin.
2001.
The OpenAgent Architecture.
Journal of Autonomous Agentsand Multi-Agent Systems, 4(1/2):143?148.Oliver Lemon, Kallirroi Georgila, James Henderson,and Matthew Stuttle.
2006.
An ISU dialogue sys-tem exhibiting reinforcement learning of dialoguepolicies: generic slot-filling in the TALK in-car sys-tem.
In Proceedings of EACL, pages 119?122.Stephanie Seneff.
2002.
Response Planning and Gen-eration in the Mercury Flight Reservation System.Computer Speech and Language, 16.S Williams.
1967. Business process modeling im-proves administrative control.
Automation, pages44?50.151
