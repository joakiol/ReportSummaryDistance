Proceedings of the Analyzing Conversations in Text and Speech (ACTS) Workshop at HLT-NAACL 2006, pages 50?57,New York City, New York, June 2006. c?2006 Association for Computational LinguisticsChAT: A Time-Linked System for Conversational AnalysisMichelle L. Gregory Douglas Love Stuart Rose Anne SchurPacific Northwest National Laboratory609 Battelle BlvdRichland, WA 99354{michelle.gregory;douglas.love;stuart.rose;anne.schur}@pnl.govAbstractWe present a system for analyzing conver-sational data.
The system includes state-of-the-art natural language processing compo-nents that have been modified to accom-modate the unique nature of conversationaldata.
In addition, we leverage the addedrichness of conversational data by analyz-ing various aspects of the participants andtheir relationships to each other.
Our toolprovides users with the ability to easilyidentify topics or persons of interest, in-cluding who talked to whom, when, entitiesthat were discussed, etc.
Using this tool,one can also isolate more complex net-works of information: individuals who mayhave discussed the same topics but nevertalked to each other.
The tool includes a UIthat plots information over time, and a se-mantic graph that highlights relationshipsof interest.1 IntroductionThe ability to extract and summarize content fromdata is a fundamental goal of computational lin-guistics.
As such, a number of tools exist to auto-matically categorize, cluster, and extractinformation from documents.
However, these toolsdo not transfer well to data sources that are moreconversational in nature, such as multi-party meet-ings, telephone conversations, email, chat rooms,etc.
Given the plethora of these data sources, thereis a need to be able to quickly and accurately ex-tract and process pertinent information from thesesources without having to cull them manually.Much of the work on computational analysis ofdialogue has focused on automatic topic segmenta-tion of conversational data, and in particular, usingfeatures of the discourse to aid in segmentation(Galley et al 2003; Stolcke et al, 1999;Hirschberg & Hakatani, 1996.).
Detailed discourseand conversational analytics have been the focus ofmuch linguistic research and have been used by thecomputational community for creating models ofdialogue to aid in natural language understandingand generation (Allen & Core, 1997; Carletta et al,1997; van Deemter et al, 2005; Walker et al,1996).
However, there has been much less focus oncomputational tools that can aid in either the analy-sis of conversations themselves, or in renderingconversational data in ways such that it can beused with traditional data mining techniques thathave been successful for document understanding.This current work is most similar to the NITEXML Toolkit (Carletta & Kilgour, 2005) whichwas designed for annotating conversational data.NITE XML is system in which transcripts of con-versations are viewable and time aligned with theiraudio transcripts.
It is especially useful for addingannotations to multi-modal data formats.
NITEXML is not analysis tool, however.
Annotationsare generally manually added.
In this paper, wepresent a Conversational Analysis Tool (ChAT)which integrates several language processing tools(topic segmentation, affect scoring, named entityextraction) that can be used to automatically anno-tate conversational data.
The processing compo-nents have been specially adapted to deal withconversational data.ChAT is not an annotation tool, however, it isanalysis tool.
It includes a UI that combines a vari-ety of data sources onto one screen that enablesusers to progressively explore conversational data.For example, one can explore who was present in a50given conversation, what they talked about, and theemotional content of the data.
The data can beviewed by time slice or in a semantic graph.
Thelanguage processing components in ChAT are ver-satile in that they were developed in modular, opendesigns so that they can be used independently orbe integrated into other analytics tools.
We presentChAT architecture and processing components inSection 2.
In section 3 we present the UI , with adiscussion following in section 4.2 ChAT ArchitectureChAT is a text processing tool designed to aid inthe analysis of any kind of threaded dialogue, in-cluding meeting transcripts, telephone transcripts,usenet groups, chat room, email or blogs.
Figure 1illustrates the data processing flow in ChAT.Figure 1: ChAT Architecture.Data is ingested via an ingest engine, then thecentral processing engine normalizes the format(time stamp, speaker ID, utterance; one utteranceper line).
Processing components are called by thecentral processing engine which provides the inputto each component, and collects the output to sendto the UI.We designed the system to be general enough tohandle multiple data types.
Thus, with the excep-tion of the ingest engine, the processing compo-nents are domain and source independent.
Forexample, we did not want the topic segmentationto rely on features specific to a dataset, such asacoustic information from transcripts.
Addition-ally, all processing components have been built asindependent plug-ins to the processing engine: Theinput of one does not rely on the output of the oth-ers.
This allows for a great deal of flexibility inthat a user can choose to include or exclude vari-ous processes to suit their needs, or even exchangethe components with new tools.
We describe eachof the processing components in the next section.2.1 Ingest EngineThe ingest engine is designed to input multipledata sources and transform them into a uniformstructure which includes one utterance per line,including time stamp and participant information.So far, we have ingested three data sources.
TheICSI meeting corpus (Janin et al, 2003) is a corpusof text transcripts of research meetings.
There are75 meetings in the corpus, lasting 30 minutes to1.5 hours in duration, with 5-8 participants in eachmeeting.
A subset of these meetings were handcoded for topic segments (Galley, et al, 2003).
Wealso used telephone transcripts from the August 14,2003 power grid failure that resulted in a regionalblackout1.
These data consist of files containingtranscripts of multiple telephone conversations be-tween multiple parties.
Lastly, we employed a chatroom dataset that was built in-house by summerinterns who were instructed to play a murder mys-tery game over chat.
Participants took on a charac-ter persona as their login and content was based ona predefined scenario, but all interactions were un-scripted beyond that.1http://energycommerce.house.gov/108/Hearings/09032003hearing1061/hearing.htmIngest Engine User InterfaceCentral Processing EngineProcessing ComponentsTopic SegmentationParticipantInformationNamed EntityExtractionAffect51Figure 2.
Plot of WindowDiff evaluation metric for LCseg and WLM on meeting corpus.
p-value =0.032121 for two-sample equal variance t-test.2.2 Topic SegmentationThe output of the ingest process is a list of utter-ance that include a time (or sequence) stamp, aparticipant name, and an utterance.
Topic segmen-tation is then performed on the utterances to chunkthem into topically cohesive units.
Traditionally,algorithms for segmentation have relied on textualcues (Hearst, 1997; Miller et al 1998; Beefermanet al 1999; Choi, 2000).
These techniques haveproved useful in segmenting single authoreddocuments that are rich in content and where thereis a great deal of topic continuity.
Topic segmenta-tion of conversational data is much more difficultdue to often sparse content, intertwined topics, andlack of topic continuity.Topic segmentation algorithms generally rely ona lexical cohesion signal that requires smoothing inorder to eliminate noise from changes of wordchoices in adjoining statements that do not indicatetopic shifts (Hearst, 1997; Barzilay and Elhadad,1997).
Many state of the art techniques use a slid-ing window for smoothing (Hearst, 1997; Miller etal.
1998; Galley et al, 2003).
We employ a win-dowless method (WLM) for calculating a suitablecohesion signal which does not rely on a slidingwindow to achieve the requisite smoothing for aneffective segmentation.
Instead, WLM employs aconstrained minimal-spanning tree (MST) algo-rithm to find and join pairs of elements in a se-quence.
In most applications, the nearest-neighborsearch used by an MST involves an exhaustive,O(N2), search throughout all pairs of elements.However since WLM only requires information onthe distance between adjoining elements in the se-quence the search space for finding the two closestadjoining elements is linear, O(N), where N is thenumber of elements in the sequence.
We can there-fore take advantage of the hierarchical summarystructure that an MST algorithm affords while notincurring the performance penalty.Of particular interest for our research was thesuccess of WLM on threaded dialogue.
We evalu-ated WLM?s performance on the ICSI meetingcorpus (Janin et al 2003) by comparing our seg-mentation results to the results obtained by imple-menting LCSeg (Galley et al, 2003).
Using the 25hand segmented meetings, our algorithm achieveda significantly better segmentation for 20 out of 25documents.
Figure 2 shows the hypothesized seg-ments from the two algorithms on the ICSI Meet-ing Corpus.Topic segmentation of conversational data canbe aided by employing features of the discourse orspeech environment, such as acoustic cues, etc.
(Stolcke et al, 1999; Galley et al, 2003).
In thiswork, we have avoided using data dependent (the52integration of acoustic cues for speech transcripts,for example) features to aid in segmentation be-cause we wanted our system to be as versatile aspossible.
This approach provides the best segmen-tation possible for a variety of data sources, regard-less of data type.2.3 Named Entity ExtractionIn addition to topics, ChAT also has integratedsoftware to extract the named entities.
We useCicero Lite from the Language Computer Corpora-tion (LCC) for our entity detection (for a productdescription and evaluation, see Harabagiu et al,2003).
Using a combination of semantic represen-tations and statistical approaches, Cicero Lite iso-lates approximately 80 entity types.
ChATcurrently makes use of only a handful of thesecategories, but can easily be modified to includemore.
Because named entity extraction relies oncross-utterance dependencies, the main processingengine sends all utterance from a conversation atonce rather than an utterance at a time.2.4 Sentiment AnalysisIn addition to topic and entity extraction, conversa-tions can also be analyzed by who participated inthem and their relationship to one another and theirattitude toward topics they discuss.
In an initialattempt to capture participant attitude, we haveincluded a sentiment analysis, or affect, compo-nent.
Sentiment analysis is conducted via a lexicalapproach.
The lexicon we employed is the GeneralInquirer (GI) lexicon developed for content analy-ses of textual data (Stone, 1977).
It includes anextensive lexicon of over 11,000 hand coded wordstems, and 182 categories, but our implementationis limited to positive (POS) and negative (NEG)axes.
In ChAT, every utterance is scored for thenumber of positive and negative words it contains.We make use of this data by keeping track of theaffect of topics in general, as well as the generalmood of the participants.2.5 Participant RolesAnalyzing conversations consists of more thananalyzing the topics within them.
Inherent to thenature of conversational data are the participants.Using textual cues, one can gain insight into therelationships of participants to each other and thetopics.
In ChAT we have integrated several simplemetrics as indicators of social dynamics amongstthe participants.
Using simple speaker statistics,such as number of utterances, number of words,etc., we can gain insight to the level of engagementof participants in the conversation.
Features we useinclude:?
The number of utterance?
Proportion of questions versus state-ments?
Proportion of ?unsolicited?
statements(ones not preceded by a question mark)Additionally, we use the same lexical resourcesas we use for sentiment analysis for indications ofpersonality type.
We make use of the lexical cate-gories of strong, weak, power cooperative, andpower conflict as indicators of participant roles inthe conversational setting.
Thus far, we have notconducted any formal evaluation on the sentimentanalysis with this data, but our initial studies of ourpos and neg categories show a 73% agreementwith hand tagged positive and negative segmentson a different data set.3 User InterfaceAs described in Section 2 on ChAT architecture,the processing components are independent of theUI, but we do have a built-in UI that incorporatesthe processing components that is designed to aidin analyzing conversations.53Figure 3.
Screen shot of the main UI for ChATThe components of the system are all linkedthrough the X-axis, representing time, as seen inFigure 3.
Depending on the dataset, positions alongthe time axis  are based on either the time stamp orsequential position of the utterance.
The defaulttime range is the whole conversation or chat roomsession, but a narrower range can be selected bydragging in the interval panel at the top of the UI.Note that all of the values for each of the compo-nents are recalculated based on the selected timeinterval.
Figure 4 shows that a time selection re-sults in a finer grained subset of the data, allowingone to drill down to specific topics of inter-est.Figure 4: Time Selection.54The number of utterance for a given time frameis indicated by the number inside the box corre-sponding to the time frame.
The number is recalcu-lated as different time frames are selected.3.1.1 TopicsThe central organizing unit in the UI is topics.
Thetopic panel, detailed in Figure 5, consists of threeparts: the color key, affect scores, and topic labels.Once a data file is imported into the UI, topic seg-mentation is performed on the dataset according tothe processes outline in Section 3.2.
Topic labelsare assigned to each topic chunk.
Currently, we usethe most prevalent word tokens as the label, andthe user can control the number of words per label.Each topic segment is assigned a color, which isindicated by the color key.
The persistence of acolor throughout the time axis indicates whichtopic is being discussed at any given time.
Thisallows a user to quickly see the distribution of top-ics of a meeting, for example.
It also allows a userto quickly see the participants who discussed agiven topic.Figure 5.
Topic Labels in the Topic Panel.3.1.2 AffectAffect scores are computed for each topic bycounting the number of POS or NEG affect wordsin each utterance that comprises a topic within theselected time interval.
Affect is measured by theproportion of POS to NEG words in the selectedtime frame.
If the proportion is greater than 0, thescore is POS (represented by a +), if it is less than0, it is NEG (-).
The degree of sentiment is indi-cated by varying shades of color on the + or ?symbol.Note that affect is computed for both topics andparticipants.
An affect score on the topic panel in-dicates overall affect contained in the utterancespresent in a given time frame, whereas the affectscore in the participant panel indicates overall af-fect in a given participant?s utterances for that timeframe.3.1.3 ParticipantsThe participant panel (Figure 6) consists of threeparts:  speaker labels, speaker contribution bar, andaffect score.
The speaker label is displayed in al-phabetical order and is grayed out if there are noutterances containing the topic in the selected timeframe.
The speaker contribution bar, displayed as ahorizontal histogram, shows the speaker?s propor-tion of utterances during the time frame.
Non ques-tion utterances are displayed in red whileutterances containing questions are displayed ingreen as seen.
For example, in Figure 6, we can seethat speaker me011 did most of the talking (andwas generally negative), but speaker me018 had ahigher proportion of questions.Figure 6.
Participant Panel.3.1.4 Named EntitiesIn the current implementation, the named entitypanel consists of only list of entity labels present ina given time frame.
We do not list each named en-tity because of space constraints, but plan to inte-grate a scroll bar so that we can display individualentities as opposed to the category labels.553.2 Semantic GraphData that is viewed in the main UI can be sent to asemantic graph for further analysis.
The graph al-lows a user to choose to highlight the relationshipsassociated with a topic, participant, or individualnamed entity.
The user selects objects of interestfrom a list (see Figure 7), then the graph functionorganizes a graph according to the chosen object,see Figure 8, that extracts the information from thetime-linked view and represent it in a more abstractview that denotes relationships via links and nodes.Figure 7.
Semantic Graph Node Selection.The semantic graph can help highlight relation-ships that might be hard to view in the main UI.For example, Figure 8 represents a subset of theBlackout data in which three participants, indicatedby blue, all talked about the same named entity,indicated by green, but never talked to each other,indicated by the red conversation nodes.Figure 8.
Graph of the Relationship between Three Par-ticipants.4 DiscussionIn this paper, we have presented ChAT, a systemdesigned to aid in the analysis of any kind ofthreaded dialogue.
Our system is designed to beflexible in that the UI and processing componentswork with multiple data types.
The processingcomponents can be used independently, or withinthe UI.
The UI aids users in in-depth analysis ofindividual conversations.
The components can berun independent of the UI and in batch, resulting inan xml document containing the original tran-scripts and the metadata added by the processingcomponents.
This functionality allows the data tobe manipulated by traditional text mining tech-niques, or to be viewed in any other visualization.We have not performed user evaluation on theinterface.
Our topic segmentation performs betterthan the current state of the art, and named-entityextraction we have integrated is commercial grade.We are currently working on an evaluation of theaffect scoring.
While our topic segmentation isgood, we are working to improve the labels we usefor the topics.
Most importantly, we plan on ad-dressing the usefulness of the UI with user studies.ReferencesR.
Barzilay and M. Elhadad.
Using lexical chains fortext summarization.
In Proc.of the Intelligent Scal-able Text Summarization Workshop (ISTS?97), ACL,1997.D.
Beeferman, A. Berger, and J. Lafferty.
1999.
Statisti-calmodels for text segmentation.
Machine Learning,34(1?3):177?210.Carletta, J.C. and Kilgour, J.
(2005) The NITE XMLToolkit Meets the ICSI Meeting Corpus: Import, An-notation, and Browsing.
MLMI'04: Proceedings ofthe Workshop on Machine Learning for MultimodalInteraction.
Samy Bengio and Herve Bourlard, eds.Springer-Verlag Lecture Notes in Computer ScienceVolume 3361.F.
Choi.
2000.
Advances in domain independent lineartext segmentation.
In Proc.
of NAACL?00.van Deemter, Emiel Krahmer & Mari?t Theune.
2005.Real versus template-based Natural Language Gen-eration: a false opposition?
Computational Linguis-tics 31(1), pages 15-24.M.
Galley, Kathleen McKeown, Eric Fosler-Lussier,Hongyan Jing.
Discourse Segmentation of Multi-56party Conversation.
In Proceedings of the 41st An-nual Meeting of the Association for ComputationalLinguistics (ACL-03).
July 2003.
Sapporo, Japan.S.
Harabagiu, D. Moldovan, C. Clark, M. Bowden, J.Williams, and J. Bensley.
2003.
Answer Mining byCombining Extraction Techniques with AbductiveReasoning, Proceedings of the Twelfth Text RetrievalConference (TREC ):375.M.
A. Hearst.
TexTiling: Segmenting text info multi-paragraph subtopic passages.
Computational Linguis-tics, 23(1):33?64, 1997.J.
Hirschberg and C. Nakatani.
A prosodic analysis ofdiscourse segments in direction-giving monologues.In Proc.
ACL, pp.
286?293, Santa Cruz, CA, 1996.A.
Janin, D. Baron, J. Edwards, D. Ellis, D. Gelbart,N.Morgan, B. Peskin, T. Pfau, E. Shriberg, A. Stolcke,and C. Wooters.
2003.
The ICSI meeting corpus.
InProc.
of ICASSP-03, Hong KongN.
E. Miller, P. Wong, M. Brewster, and H. Foote.TOPIC ISLANDS - A wavelet-based text visualiza-tion system.
In David Ebert, Hans Hagen, and HollyRushmeier, editors, IEEE Visualization '98, pages189-196, 1998.A.
Stolcke, E. Shriberg, D. Hakkani-Tur, G. Tur, Z.Rivlin, K. Sonmez (1999), Combining Words andSpeech Prosody for Automatic Topic Segmentation.Proc.
DARPA Broadcast News Workshop, pp.
61-64,Herndon, VA.P.
Stone, 1977.
Thematic text analysis: new agendas foranalyzing text content.
in Text Analysis for the SocialSciences ed.
Carl Roberts.
Lawrence Erlbaum Asso-ciates.57
