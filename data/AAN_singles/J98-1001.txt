Introduction to the Special Issueon Word Sense Disambiguation:The State of the ArtNancy Ide"Vassar CollegeJean V6ronis*Universit4 de Provence1.
IntroductionThe automatic disambiguation of word senses hasbeen an interest and concern sincethe earliest days of computer treatment of language in the 1950s.
Sense disambiguationis an "intermediate ask" (Wilks and Stevenson 1996), which is not an end in itself, butrather is necessary at one level or another to accomplish most natural anguage pro-cessing tasks.
It is obviously essential for language understanding applications, uchas message understanding and man-machine communication; it is at least helpful, andin some instances required, for applications whose aim is not language understanding:?
machine translation: sense disambiguation is essential for the propertranslation of words such as the French grille, which, depending on thecontext, can be translated as railings, gate, bar, grid, scale, schedule, etc.
(see, for instance Weaver \[1955\], Yngve \[1955\]).?
information retrieval and hypertext navigation: when searching for specifickeywords, it is desirable to eliminate occurrences in documents wherethe word or words are used in an inappropriate sense; for example,when searching for judicial references, it is desirable to eliminatedocuments containing the word court as associated with royalty, ratherthan with law (see, for instance, Salton \[1968\], Salton and McGill \[1983\],Krovetz and Croft \[1992\], Voorhees \[1993\], Schfitze and Pedersen \[1995\]).?
content and thematic analysis: a common approach to content and thematicanalysis is to analyze the distribution of predefined categories ofwords--i.e., words indicative of a given concept, idea, theme,etc.--across a text.
The need for sense disambiguation i  such analysis,in order to include only those instances of a word in its proper sense, haslong been recognized (see, for instance, Stone et al \[1966\], Stone \[1969\],Kelly and Stone \[1975\]; for a more recent discussion see Litowski \[1997\]).?
grammatical analysis: sense disambiguation is useful for part-of-speechtagging for example, in the French sentence L'~tag~re plie sous les livres('The shelf is bending under \[the weight of\] the books'), it is necessary todisambiguate the sense of livres (which can mean 'books' or 'pounds'* Department of Computer Science, Vassar College, Poughkeepsie, New York 12604-0520.
E-mail:ide@cs.vassar.edu~ Laboratoire Parole t Langage, ESA 6057 CNRS, Universit~ de Provence, 29 Avenue Robert Schuman,13621 Aix-en-Provence C dex 1, France.
E-mail: Jean.Veronis@lpl.univ-aix.fr(~) 1998 Association for Computational LinguisticsComputational Linguistics Volume 24, Number 1and is masculine in the former sense, feminine in the latter) to properlytag it as a masculine noun.
Sense disambiguation is also necessary forcertain syntactic analyses, such as prepositional phrase attachment(Jensen and Binot 1987; Whittemore, Ferrara, and Brunner 1990; Hindleand Rooth 1993), and, in general, restricts the space of competing parses(Alshawi and Carter 1994).speech processing: sense disambiguation is required for correctphonetization of words in speech synthesis, for example, the wordconjure in He conjured up an image or in I conjure you to help me (Sproat,Hirschberg, and Yarowsky 1992; Yarowsky 1997), and also for wordsegmentation and homophone discrimination in speech recognition(Connine 1990; Seneff 1992).text processing: sense disambiguation is necessary for spelling correction(for example, to determine when diacritics hould be inserted, such as inFrench, changing comte to comte \[Yarowsky 1994a, 1994b\]); for casechanges (HE READ THE TIMES ~ He read the Times); for lexical access ofSemitic languages (in which vowels are not written), etc.The problem of word sense disambiguation (WSD) has been described as "AI-complete,"that is, a problem which can be solved only by first resolving all the difficult problemsin artificial intelligence (AI), such as the representation f common sense and encyclo-pedic knowledge.
The inherent difficulty of sense disambiguation was a central pointin Bar-Hillel's well-known treatise on machine translation (Bar-Hillel 1960), where heasserted that he saw no means by which the sense of the word pen in the sentenceThe box is in the pen could be determined automatically.
Bar-Hillel's argument laid thegroundwork for the ALPAC report (ALPAC 1966), which is generally regarded as thedirect cause for the abandonment of most research on machine translation in the early1960s.At about the same time, considerable progress was being made in the area ofknowledge representation, especially the emergence of semantic networks, which wereimmediately applied to sense disambiguation.
Work on word sense disambiguationcontinued throughout he next two decades in the framework of AI-based naturallanguage understanding research, as well as in the fields of content analysis, stylistic ?and literary analysis, and information retrieval.
In the past ten years, attempts toautomatically disambiguate word senses have multiplied, due, like much other similaractivity in the field of computational linguistics, to the availability of large amountsof machine-readable text and the corresponding development of statistical methods toidentify and apply information about regularities in this data.
Now that other problemsamenable to these methods, such as part-of-speech disambiguation and alignment ofparallel translations, have been fairly thoroughly addressed, the problem of word sensedisambiguation has taken center stage, and it is frequently cited as one of the mostimportant problems in natural anguage processing research today.Given the progress that has been recently made in WSD research and the rapiddevelopment of methods for solving the problem, it is appropriate at this time to standback and assess the state of the field and to consider the next steps that need to betaken.
To this end, this paper surveys the major, well-known approaches to word sensedisambiguation and considers the open problems and directions of future research.Ide and V4ronis Introduction2.
Survey of WSD MethodsIn general terms, word sense disambiguation involves the association of a given wordin a text or discourse with a definition or meaning (sense) which is distinguishable fromother meanings potentially attributable to that word.
The task therefore necessarilyinvolves two steps: (1) the determination of all the different senses for every wordrelevant (at least) to the text or discourse under consideration; and (2) a means toassign each occurrence of a word to the appropriate sense.Much recent work on WSD relies on predefined senses for step (1), including:?
a list of senses, such as those found in everyday dictionaries;?
a group of features, categories, or associated words (e.g., synonyms, as ina thesaurus);?
an entry in a transfer dictionary, which includes translations in anotherlanguage;The precise definition of a sense is, however, a matter of considerable debate withinthe community.
The variety of approaches todefining senses has raised concern aboutthe comparability of much WSD work, and given the difficulty of the problem ofsense definition, no definitive solution is likely to be found soon (see Section 3.2).However, since the earliest days of WSD work, there has been general agreement thatthe problems of morpho-syntactic disambiguation a d sense disambiguation can bedisentangled (see, e.g., Kelly and Stone \[1975\]).
That is, for homographs with differ-ent parts of speech (e.g., play as a verb and noun), morphosyntactic disambiguationaccomplishes sense disambiguation, and therefore (especially since the developmentof reliable part-of-speech taggers), WSD work has focused largely on distinguishingsenses among homographs belonging to the same syntactic ategory.Step (2), the assignment of words to senses, is accomplished by reliance on twomajor sources of information:?
the context of the word to be disambiguated, in the broad sense: thisincludes information contained within the text or discourse in which theword appears, together with extra-linguistic information about the text,such as situation, etc.;?
external knowledge sources, including lexical, encyclopedic, etc.
resources,as well as hand-devised knowledge sources, which provide data usefulto associate words with senses.All disambiguation work involves matching the context of the instance of the wordto be disambiguated with either information from an external knowledge source(knowledge-driven WSD), or information about the contexts of previously disam-biguated instances of the word derived from corpora (data-driven or corpus-basedWSD).
Any of a variety of association methods is used to determine the best matchbetween the current context and one of these sources of information, in order to as-sign a sense to each word occurrence.
The following sections urvey the approachesapplied to date.2.1 Early WSD Work in MTThe first attempts at automated sense disambiguation were made in the context ofmachine translation (MT).
In his famous memorandum (available mimeographed inComputational Linguistics Volume 24, Number 11949, but not printed until 1955) Weaver discusses the need for WSD in machinetranslation and outlines the basis of an approach to WSD that underlies all subsequentwork on the topic:If one examines the words in a book, one at a time as through anopaque mask with a hole in it one word wide, then it is obviouslyimpossible to determine, one at a time, the meaning of the words .
.
.
.But if one lengthens the slit in the opaque mask, until one can see notonly the central word in question but also say N words on either side,then if N is large enough one can unambiguously decide the meaningof the central word .
.
.
.
The practical question is: "What minimumvalue of N will, at least in a tolerable fraction of cases, lead to thecorrect choice of meaning for the central word?"
(1955, 20)A well-known early experiment by Kaplan (1950) attempted to answer this questionat least in part, by presenting ambiguous words in their original context and in avariant context providing one or two words on either side to seven translators.
Ka-plan observed that sense resolution given two words on either side of the word wasnot significantly better or worse than when given the entire sentence.
The same phe-nomenon has been reported by several researchers since Kaplan's work appeared: e.g.,Masterman (1962), Koutsoudas and Korfhage (1956) on Russian, and Gougenheim andMich6a (1961) and Choueka nd Lusignan (1985) on French.Reifler's (1955) "semantic oincidences" between a word and its context quicklybecame the determining factor in WSD.
The complexity of the context, and in particularthe role of syntactic relations, was also recognized; for example, Reifler (1955) says:Grammatical structure can also help disambiguate, as, for instance,the word keep, which can be disambiguated by determining whetherits object is gerund (He kept eating), adjectival phrase (He kept calm), ornoun phrase (He kept a record).The goal of MT was initially modest, focused primarily on the translation of techni-cal texts and in all cases dealing with texts from particular domains.
Weaver discussesthe role of the domain in sense disambiguation, making a point that was reiteratedseveral decades later by Gale, Church, and Yarowsky (1992c):In mathematics, to take what is probably the easiest example, onecan very nearly say that each word, within the general context of amathematical article, has one and only one meaning.
(1955, 20)Following directly from this observation, much effort in the early days of machinetranslation was devoted to the development of specialized ictionaries or "micro-glossaries" (Oswald 1952, 1957; Oswald and Lawson 1953; Oettinger 1955; Dostert1955; Gould 1957; Panov 1960).
Such microglossaries contain only the meaning of agiven word relevant for texts in a particular domain of discourse; e.g., a microglossaryfor the domain of mathematics would contain only the relevant definition of triangle,and not the definition of triangle as a musical instrument.The need for knowledge representation for WSD was also acknowledged fromthe outset: Weaver concludes by noting the "tremendous amount of work \[needed\] inthe logical structure of languages" (1995, 23).
Several researchers attempted to deviseIde and V~ronis Introductionan "interlingua" based on logical and mathematical principles that would solve thedisambiguation problem by mapping words in any language to a common seman-tic/conceptual representation.
Among these efforts, those of Richens and Mastermaneventually led to the notion of the "semantic network" (Richens \[1958\], Masterman\[1962\]; see Section 2.2.1); following on this, the first machine-implemented knowledgebase was constructed from Roget's Thesaurus (Masterman 1957).
Masterman applied thisknowledge base to the problem of WSD: in an attempt o translate Virgil's Georgics bymachine, she looked up, for each Latin word stem, the translation in a Latin-Englishdictionary and then looked up this word in the word-to-head index of Roget's.
Inthis way, each Latin word stern was associated with a list of Roget head numbersassociated with its English equivalents.
The numbers for words appearing in the samesentence were then examined for overlaps.
Finally, English words appearing underthe multiply-occurring head categories were chosen for the translation.
~ Masterman'smethodology is strikingly similar to that underlying much of the knowledge-basedWSD accomplished recently (see Section 2.3).It is interesting to note that Weaver's text also outlined the statistical approach tolanguage analysis prevalent now, nearly fifty years later:This approach brings into the foreground an aspect of the matter thatprobably is absolutely basic--namely, the statistical character of theproblem ... .
And it is one of the chief purposes of this memorandumto emphasize that statistical semantic studies should be undertaken,as a necessary primary step.
(1955, 22)Several authors followed this approach in the early days of machine translation(e.g., Richards 1953; Yngve 1955; Parker-Rhodes 1958).
Estimations of the degree ofpolysemy in texts and dictionaries were made: Harper, working on Russian texts,determined the number of polysemous words in an article on physics to be approx-imately 30% (Harper 1957a) and 43% in another sample of scientific writing (Harper1957b); he also found that Callaham's Russian-English dictionary provides, on aver-age, 8.6 English equivalents for each Russian word, of which 5.6 are quasi-synonyms,thus yielding approximately three distinct English equivalents for each Russian word.Bel'skaja (1957) reports that in the first computerized Russian dictionary, 500 out of2,000 words are polysemous.
Pimsleur (1957) introduced the notion of levels of depthfor a translation: level 1 uses the most frequent equivalent (e.g., German schwer =heavy), producing a text where 80% of the words are correctly translated; level 2 dis-tinguishes additional meanings (e.g., schwer = difficult), producing a translation whichis 90% correct; etc.
Although the terminology is different, this is very similar to the no-tion of baseline tagging used in modern work (see, e.g., Gale, Church, and Yarowsky\[1992b\]).A convincing implementation of many of these ideas was made several yearslater, paradoxically at the moment when MT began its decline.
Madhu and Lytle(1965), working from the observation that domain constrains ense, calculated sensefrequency for texts in different domains and applied a Bayesian formula to determinethe probability of each sense in a given context--a technique similar to that applied inmuch later work and which yielded a similar 90% correct disambiguation result (seeSection 2.4).1 For a detailed accounting ofMasterman's methodology, see Wilks, Slator, and Guthrie (1996).
Otherresearchers have discussed the use of thesauri for disambiguation n the context of early MT work, e.g.Gentilhomme and Tabory (1960).Computational Linguistics Volume 24, Number 1The striking fact about this early work on WSD is the degree to which the funda-mental problems and approaches to the problem were foreseen and developed at thattime.
However, without large-scale resources, most of these ideas remained untestedand to a large extent, forgotten, until several decades later.2.2 AI-based MethodsAI methods began to flourish in the early 1960s and began to attack the problem oflanguage understanding.
As a result, WSD in AI work was typically accomplished inthe context of larger systems intended for full language understanding.
In the spiritof the times, such systems were almost always grounded in some theory of humanlanguage understanding that they attempted to model, and often involved the useof detailed knowledge about syntax and semantics to perform their task, which wasexploited for WSD.2.2.1 Symbolic Methods.
As mentioned above, semantic networks were developedin the late 1950s and were immediately applied to the problem of representing wordmeanings.
2 Masterman (1962), working in the area of machine translation, used a se-mantic network to derive the representation f sentences in an interlingua comprisedof fundamental language concepts; sense distinctions are implicitly made by choosingrepresentations that reflect groups of closely related nodes in the network.
She devel-oped a set of 100 primitive concept ypes (THING, DO, etc.
), in terms of which hergroup built a 15,000-entry concept dictionary, where concept ypes are organized ina lattice with inheritance of properties from superconcepts o subconcepts.
Buildingon this and on work on semantic networks by Richens (1958), Quillian (1961, 1962a,1962b, 1967, 1968, 1969) built a network that includes links among words (tokens) andconcepts (types), in which links are labeled with various semantic relations or simplyindicate associations between words.
The network is created starting from dictionarydefinitions, but is enhanced by human knowledge that is hand-encoded.
When twowords are presented to the network, Quillian's program simulates the gradual activa-tion of concept nodes along a path of links originating from each input word by meansof marker passing; disambiguation is accomplished because only one concept nodeassociated with a given input word is likely to be involved in the most direct pathfotmd between the two input words.
Quillian's work informed later dictionary-basedapproaches to WSD (see Section 2.3.1).Subsequent AI-based approaches exploited the use of frames containing informa-tion about words and their roles and relations to other words in individual sentences.For example, Hayes (1976, 1977a, 1977b, 1978) uses a combination of a semantic net-work and case frames.
The network consists of nodes representing noun senses andlinks represented by verb senses; case frames impose IS-A and PART-OF relationson the network.
As in Quillian's system, the network is traversed to find chains ofconnections between words.
Hayes work shows that homonyms can be fairly accu-rately disambiguated using this approach, but it is less successful for other kindsof polysemy.
Hirst (1987) also uses a network of frames and, again following Quil-lian, marker passing to find minimum-length paths of association between frames forsenses of words in context in order to choose among them.
He introduces "polaroidwords," a mechanism which progressively eliminates inappropriate senses based on2 Semantic networks derive from much earlier work on knowledge representation using graphs, such asPierce's "existential graphs" (see Roberts \[1973\]) and the graphs of the psychologist Selz (1913, 1922)which represent patterns of concepts and inheritance of properties.6Ide and V~ronis Introductionsyntactic evidence provided by the parser, together with semantic relations found inthe frame network.
Eventually only one sense remains; however, Hirst reports thatin cases where some word (including words other than the target) in the sentence isused metaphorically, metonymically, or in an unknown sense, the polaroids often endby eliminating all possible senses, and fail.Wilks' preference semantics (\[1968, 1969, 1973, 1975a, 1975b, 1975c, 1975d\]; see thesurvey by Wilks and Fass \[1990\]), which uses Masterman's primitives, is essentially acase-based approach to natural language understanding and one of the first specificallydesigned to deal with the problem of sense disambiguation.
Preference semanticsspecifies electional restrictions for combinations of lexical items in a sentence that canbe relaxed when a word with the preferred restrictions does not appear, thus enabling,especially, the handling of metaphor (as in My car drinks gasoline, where the restrictionson drink prefer an animate subject but allow an inanimate one).
Boguraev (1979) showsthat preference semantics i inadequate odeal with polysemous verbs and attempts toimprove on Wilks' method by using a combination of evidence, including selectionalrestrictions, preferences, case frames, etc.
He integrates semantic disambiguation withstructural disambiguation to enable judgments about he semantic coherence of a givensense assignment.
Like many other systems of the era, these systems are sentence-based and do not account for phenomena atother levels of discourse, such as topicaland domain information.
The result is that some kinds of disambiguation are difficultor impossible to accomplish.A rather different approach to language understanding, which contains a sub-stantial sense discrimination component, is the Word Expert Parser (Small 1980, 1983;Small and Reiger 1982; Adriaens 1986, 1987, 1989; Adriaens and Small 1988).
Theapproach derives from the somewhat unconventional theory that human knowledgeabout language is organized primarily as knowledge about words rather than rules.Their system models what its authors feel is the human language understanding pro-cess: a co-ordination of information exchange among word experts about syntax andsemantics as each determines its involvement in the environment under question.
Eachexpert contains a discrimination net for all senses of the word, which is traversed onthe basis of information supplied by the context and other word experts, ultimatelyarriving at a unique sense, which is then added to a semantic representation f thesentence.
The well-known drawback of the system is that the word experts need tobe extremely large and complex to accomplish the goal, which is admittedly greaterthan sense disambiguation.
3Dahlgren's (1988) language understanding system includes a sense disambigua-tion component that uses a variety of types of information: fixed phrases, syntac-tic information (primarily, selectional restrictions), and commonsense r asoning.
Thereasoning module, because it is computationally intensive, is invoked only in caseswhere the other two methods fail to yield a result.
Although her original assumptionwas that much disambiguation could be accomplished based on paragraph topic, shefound that half of the disambiguation was actually accomplished using fixed phraseand syntactic information, while the other half was accomplished using commonsensereasoning.
Reasoning often involves traversing an ontology to find common ancestorsfor words in context; her work anticipates Resnik's (1993a, 1993b, 1995a) results bydetermining that ontological similarity, involving a common ancestor in the ontology,is a powerful disambiguator.
She also notices that verb selectional restrictions are an3 It is interesting to compare the word experts with the procedures of Kelly and Stone (1975), whichsimilarly involve procedures for individual words, although t eir goal was only to disambiguate senses.Computational Linguistics Volume 24, Number 1important source of disambiguation i formation for nouns--another result that hasbeen subsequently tested and noted.2.2.2 Connectionist Methods.
Work in psycholinguistics in the 1960s and 1970s estab-lished that semantic priming--a process in which the introduction of a certain conceptwill influence and facilitate the processing of subsequently introduced concepts thatare semantically related--plays a role in disambiguation by humans (see, e.g., Meyerand Schvaneveldt \[1971\]).
This idea is realized in spreading activation models (seeCollins and Loftus \[1975\]; Anderson \[1976, 1983\]), where concepts in a semantic net-work are activated upon use, and activation spreads to connected nodes.
Activation isweakened as it spreads, but certain odes may receive activation from several sourcesand be progressively reinforced.
McClelland and Rumelhart (1981) added to the modelby introducing the notion of inhibition among nodes, where the activation of a nodemight suppress, rather than activate, certain of its neighbors (see also Feldman andBallard \[1982\]).
Applied to lexical disambiguation, this approach assumes that acti-vating a node corresponding to, say, the concept THROW will activate the "physicalobject" sense of ball, whose activation would in turn inhibit the activation of othersenses of ball, such as "social event.
"Quillian's semantic network, described above, is the earliest implementation f aspreading activation etwork used for word sense disambiguation.
A similar modelis implemented by Cottrell and Small (1983); see also Cottrell (1985).
In both of thesemodels, each node in the network represents a specific word or concept.
4 Waltz andPollack (1985) and Bookman (1987) hand-encode s ts of semantic "microfeatures," cor-responding to fundamental semantic distinctions (animate/inanimate, edible/inedible,threatening/safe, etc.
), characteristic durations of events (second, minute, hour, day,etc.
), locations (city, country, continent, etc.
), and other similar distinctions, in their net-works.
In Waltz and Pollack (1985), sets of microfeatures have to be manually primedby a user to activate a context for disambiguating a subsequent input word, but Book-man (1987) describes a dynamic process in which the microfeatures are automaticallyactivated by the preceding text, thus acting as a short-term context memory.
In ad-dition to these local models (i.e., models in which one node corresponds to a singleconcept), distributed models have also been proposed (see, for example, Kawamoto\[1988\]).
However, whereas local models can be constructed a priori, distributed modelsrequire a learning phase using disambiguated xamples, which limits their practicality.The difficulty of hand-crafting the knowledge sources required for AI-based sys-tems restricted them to "toy" implementations handling only a tiny fraction of thelanguage.
Consequently, disambiguation procedures embedded in such systems aremost usually tested on only a very small test set in a limited context (most often, asingle sentence), making it impossible to determine their effectiveness on real texts.For less obvious reasons, many of the AI-based disambiguation results involve highlyambiguous words and fine sense distinctions (e.g., ask, idea, hand, move, use, work, etc.
)and unlikely test sentences (The astronomer married the star), which make the resultseven less easy to evaluate in the light of the now-known difficulties of discriminatingeven gross sense distinctions.4 Note, however, that, symbolic methods uch as Quillian's implement propagation via mechanisms suchas marker passing, whereas the neural network models developed in the late 1970s and early 1980s usenumeric activation, inspired by the neural models of McCulloch and Pitts (1943) and Hebb's (1949)work on neurological development, which saw its first full development in Rosenblatt's (1958)"perceptrons.
"8Ide and V~ronis Introduction2.3 Knowledge-based MethodsThe AI-based work of the 1970s and 1980s was theoretically interesting but not at allpractical for language understanding in any but extremely limited domains.
A signifi-cant roadblock to generalizing WSD work was the difficulty and cost of hand-craftingthe enormous amounts of knowledge required for WSD: the so-called "knowledgeacquisition bottleneck" (Gale, Church, and Yarowsky 1993).
Work on WSD reacheda turning point in the 1980s when large-scale lexical resources, such as dictionaries,thesauri, and corpora, became widely available.
Attempts were made to automaticallyextract knowledge from these sources (Sections 2.3.1 and 2.3.2) and, more recently, toconstruct large-scale knowledge bases by hand (Section 2.3.3).
A corresponding shiftaway from methods based in linguistic theories and towards empirical methods alsooccurred at this time, as well as a decrease in emphasis on do-all systems in favor of"intermediate" tasks such as WSD.2.3.1 Machine-Readable Dictionaries.
Machine-readable dictionaries (MRDs) becamea popular source of knowledge for language-processing tasks following Amsler's(1980) and Michiel's (1982) theses.
5 A primary area of activity during the 1980s in-volved attempts to automatically extract lexical and semantic knowledge bases fromMRDs (Michiels, Mullenders, and No61 1980; Calzolari 1984; Chodorow, Byrd, andHeidon 1985; Markowitz, Ahlswede, and Evens 1986; Byrd et al 1987; Nakamuraand Nagao 1988; Klavans, Chodorow, and Wacholder 1990; Wilks et al 1990).
Thiswork contributed significantly to lexical semantic studies, but it appears that the ini-tial goalmthe automatic extraction of large knowledge bases--was not fully achieved:the only currently widely available large-scale lexical knowledge base (WordNet, seebelow) was created by hand.
We have elsewhere demonstrated the difficulties of auto-matically extracting relations as simple as hyperonymy (V~ronis and Ide 1991; Ide andV~ronis 1993a, 1993b), in large part due to the inconsistencies in dictionaries them-selves (well-known to lexicographers, cf.
Atkins and Levin \[1988\], Kilgarriff \[1994\])as well as the fact that dictionaries are created for human use, and not for machineexploitation.Despite its shortcomings, the machine-readable dictionary provides a ready-madesource of information about word senses and therefore rapidly became a staple ofWSD research.
The methods employed attempt o avoid the problems cited aboveby using the text of dictionary definitions directly, together with methods ufficientlyrobust to reduce or eliminate the effects of a given dictionary's inconsistencies.
All ofthese methods (and many of those cited elsewhere in this paper) rely on the notionthat the most plausible sense to assign to multiple co-occurring words is the one thatmaximizes the relatedness among the chosen senses.Lesk (1986) created a knowledge base that associated with each sense in a dictio-nary a "signature "6 composed of the list of words appearing in the definition of thatsense.
Disambiguation was accomplished by selecting the sense of the target wordwhose signature contained the greatest number of overlaps with the signatures ofneighboring words in its context.
The method achieved 50-70% correct disambigua-tion, using a relatively fine set of sense distinctions uch as those found in a typicallearner's dictionary.
Lesk's method is very sensitive to the exact wording of each deft-5 The first freely available machine-readable dictionaries were the Merriam-Webster Seventh CollegiateDictionary and the Merriam-Webster New Pocket Dictionary, typed from printed versions under thedirection of Olney and Ziff of the System Development Corporation in 1966-68 (Olney 1968).
Urdang(1984) describes a similar enterprise during the same period at Random House.6 Lesk does not use this term.Computational Linguistics Volume 24, Number 1nition: the presence or absence of a given word can radically alter the results.
However,Lesk's method has served as the basis for most subsequent MRD-based disambigua-tion work.Wilks et al (1990) attempted to improve the knowledge associated with each senseby calculating the frequency of co-occurrence for the words in definition texts, fromwhich they derive several measures of the degree of relatedness among words.
Thismetric is then used with the help of a vector method that relates each word and itscontext.
In experiments on a single word (bank), the method achieved 45% accuracy onsense identification, and 90% accuracy on homograph identification.
Lesk's method hasbeen extended by creating a neural network from definition texts in the Collins EnglishDictionary (CED), in which each word is linked to its senses, which are themselveslinked to the words in their definitions, which are in turn linked to their senses, etc.
(V6ronis and Ide 1990).
7 Experiments on 23 ambiguous words, each in six contexts(138 pairs of words), produced correct disambiguation, using the relatively fine sensedistinctions in the CED, in 71.7% of the cases (three times better than chance: 23.6%)(Ide and V6ronis 1990b); in later experiments, improving the parameters and onlydistinguishing homographs enabled a rate of 85% (vs. chance: 39%) (V6ronis and Ide1995).
Applied to the task of mapping the senses of the CED and OALD for the same 23words (59 senses in all), this method obtained a correct correspondence in 90% of thecases at the sense level, and 97% at the level of homographs (Ide and V6ronis 1990a).Sutcliffe and Slater (1995) replicated this method on full text (samples from Orwell'sAnimal Farm) and found similar results (72% correct sense assignment, compared witha 33% chance baseline, and 40% using Lesk's method).Several authors (for example, Krovetz and Croft \[1989\], Guthrie et al \[1991\], Sla-tor \[1992\], Cowie, Guthrie, and Guthrie \[1992\], Janssen \[1992\], Braden-Harder \[1993\],Liddy and Paik \[1993\]) have attempted to improve results by using supplementaryfields of information in the electronic version of the Longman Dictionary of Contempo-rary English (LDOCE), in particular, the box codes and subject codes provided foreach sense.
Box codes include primitives such as ABSTRACT, ANIMATE, HUMAN,etc., and encode type restrictions on nouns and adjectives and on the arguments ofverbs.
Subject codes use another set of primitives to classify senses of words by sub-ject (ECONOMICS, ENGINEERING, etc.).
Guthrie et al (1991) demonstrate a typicaluse of this information: in addition to using the Lesk-based method of counting over-laps between definitions and contexts, they impose a correspondence of subject codesin an iterative process.
No quantitative valuation of this method is available, butCowie, Guthrie, and Guthrie (1992) improve the method using simulated anneal ingand report results of 47% for sense distinctions and 72% for homographs.
The useof LDOCE box codes, however, is problematic: the codes are not systematic (see, forexample, Fontenelle \[1990\]); in later work, Braden-Harder (1993) showed that simplymatching box or subject codes is not sufficient for disambiguation.
For example, in Itipped the driver, the codes for several senses of the words in the sentence satisfy thenecessary constraints (e.g., tip-money +human object or tip-tilt + movable solid object).7 Note that the assumptions underlying this method are very similar to Quillian's (1968):Thus one may think of a full concept analogically as consisting of all the information onewould have if he looked up what will be called the "patriarch" word in a dictionary, thenlooked up every word in each of its definitions, then looked up every word found in each ofthese, and so on, continually branching outward... (p. 238).However, Quillian's network also keeps track of semantic relationships among the words encounteredalong the path between two words, which are encoded in his semantic network; the neural networkavoids the overhead of creating the semantic network but loses this relational information.10Ide and V~ronis IntroductionIn many ways, the supplementary information in the LDOCE, and in particular thesubject codes, is similar to that in a thesaurus, which, however, is more systematicallystructured.Inconsistencies in dictionaries, noted earlier, are not the only and perhaps notthe major source of their limitations for WSD.
While dictionaries provide detailedinformation at the lexical level, they lack pragmatic information that enters into sensedetermination (see, e.g., Hobbs \[1987\]).
For example, the link between ash and tobacco,cigarette, or tray in a network such as Quillian's is very indirect, whereas in the Browncorpus, the word ash co-occurs frequently with one of these words.
It is therefore notsurprising that corpora have become a primary source of information for WSD; thisdevelopment is outlined below in Section 2.3.2.3.2 Thesauri.
Thesauri provide information about relationships among words, mostnotably synonymy.
Roget's International Thesaurus, which was put into machine-tractableform in the 1950s and has been used in a variety of applications including machinetranslation (Masterman 1957), information retrieval (Sparck-Jones 1964, 1986), and con-tent analysis (Sedelow and Sedelow \[1969\], see also Sedelow and Sedelow \[1986, 1992\]),also supplies an explicit concept hierarchy consisting of up to eight increasingly re-fined levels/Typically, each occurrence of the same word under different categories ofthe thesaurus represents different senses of that word; i.e., the categories correspondroughly to word senses (Yarowsky 1992).
A set of words in the same category aresemantically related.The earliest known use of Roget's for WSD is the work of Masterman (1957),described above in Section 2.1.
Several years later, Patrick (1985) used Roget~ to dis-criminate among verb senses, by examining semantic lusters formed by "e-chains"derived from the thesaurus (Bryan \[1973, 1974\]; see also Sedelow and Sedelow \[1986\]).He uses "word-strong neighborhoods," comprising word groups in low-level semi-colon groups, which are the most closely related semantically in the thesaurus, andwords connected to the group via chains.
He is able, he claims, to discriminate thecorrect sense of verbs such as inspire (to raise the spirits vs. to inhale, breathe in, sniff,etc.
), and question (to doubt vs. to ask a question) with high reliability.
Bryan's earlierwork had already demonstrated that homographs can be distinguished by applying ametric based on relationships defined by his chains (Bryan 1973, 1974).
Similar workis described in Sedelow and Mooney (1988).Yarowsky (1992) derives classes of words by starting with words in common cat-egories in Roget's (4th edition).
A 100-word context of each word in the category isextracted from a corpus (the 1991 electronic text of Grolier's Encyclopedia), nd a mutual-information-like statistic is used to identify words most likely to co-occur with thecategory members.
The resulting classes are used to disambiguate new occurrencesof a polysemous word: the 100-word context of the polysemous occurrence is exam-ined for words in various classes, and Bayes' Rule is applied to determine the classmost likely to be that of the polysemous word.
Since class is assumed by Yarowsky torepresent a particular sense of a word, assignment to a class identifies the sense.
Hereports 92% accuracy on a mean three-way sense distinction.
Yarowsky notes that hismethod is best for extracting topical information, which is in turn most successful fordisambiguating nouns (see Section 3.1.2).
He uses the broad category distinctions up-plied by Roget's, although e points out that the lower-level information may provide8 The work of Masterman (1957) and Sparck-Jones (1964) relied on a version of Roget's that washand-punched onto cards in the 1950s; the Sedelows' (1969) work relied on a machine-readable versionof the 3rd edition.
Roget's i now widely available via anonymous ftp from various ites.11Computational Linguistics Volume 24, Number 1rich information for disambiguation.
Patrick's much earlier study, on the other hand,exploits the lower levels of the concept hierarchy, in which words are more closelyrelated semantically, aswell as connections among words within the thesaurus itself;however, despite its promise this work has not been built upon since.Like machine-readable dictionaries, a thesaurus i a resource created for humansand is therefore not a source of perfect information about word relations.
It is widelyrecognized that the upper levels of its concept hierarchy are open to disagreement(although this is certainly true for any concept hierarchy), and that they are so broad asto be of little use in establishing meaningful semantic ategories.
Nonetheless, thesauriprovide a rich network of word associations and a set of semantic categories potentiallyvaluable for language-processing work; however, Roget's and other thesauri have notbeen used extensively for WSD.
92.3.3 Computational Lexicons.
In the mid-1980s, work began on the construction oflarge-scale knowledge bases by hand, for example, WordNet (Miller et al 1990; Fell-baum forthcoming-a), CyC (Lenat and Guha 1990), ACQUILEX (Briscoe 1991), COM-LEX (Grishman, Macleod, and Meyers 1994; Macleod, Grishman, and Myers, forthcom-ing).
There exist two fundamental pproaches tothe construction of semantic lexicons:the enumerative approach, wherein senses are explicitly provided, and the generativeapproach, in which semantic information associated with given words is underspec-ified, and generation rules are used to derive precise sense information (Fellbaum,forthcoming-b).Enumerative L xicons.
Among enumerative l xicons, WordNet (Miller et al 1990; Fell-baum, forthcoming-a, forthcoming-b) is at present he best-known and the most uti-lized resource for word sense disambiguation in English.
WordNet versions for severalwestern and eastern European languages are currently under development (Vossen,forthcoming; Sutcliffe et al, An Interactive Approach, 1996, Sutcliffe et al, IWNR, 1996).WordNet combines the features of many of the other resources commonly ex-ploited in disambiguation work: it includes definitions for individual senses of wordswithin it, as in a dictionary; it defines "synsets" of synonymous words represent-ing a single lexical concept, and organizes them into a conceptual hierarchy, l?
likea thesaurus; and it includes other links among words according to several semanticrelations, including hyponymy/hyperonymy, antonymy, and meronymy.
As such, itcurrently provides the broadest set of lexical information i  a single resource.
Another,possibly more compelling, reason for WordNet's widespread use is that it is the firstbroad-coverage lexical resource that is freely and widely available; as a result, what-ever its limitations, WordNet's ense divisions and lexical relations are likely to impactthe field for several years to come.
11Some of the earliest attempts to exploit WordNet for sense disambiguation are inthe field of information retrieval.
Using the hyponomy links for nouns in WordNet,Voorhees (1993) defines aconstruct called a hood in order to represent sense categories,much as Roget's categories are used in the methods outlined above.
A hood for a givenword w is defined as the largest connected subgraph that contains w. For each content9 Other thesauri have been used for WSD, e.g., the German Hallig-Wartburg (see Schmidt \[1988, 1991\])and the Longman Lexicon of Contemporary English (LLOCE) (Chen and Chang, this volume).10 Note that the structure is not a perfect hierarchy since some of the synsets have more than one parent.11 A recent workshop to set up common evaluations mechanisms for word sense disambiguationacknowledged the fact that, due to its availability, WordNet is, at present, the most used lexicalresource for disambiguation i English, and therefore determined that WordNet senses hould form thebasis for a common sense inventory (Kilgarriff 1997).12Ide and Vdronis Introductionword in a document collection, Voorhees computes the number of times each synsetappears above that word in the WordNet noun hierarchy, which gives a measure of theexpected activity (global counts); she then performs the same computation for wordsoccurring in a particular document or query (local counts).
The sense correspondingto the hood root for which the difference between the global and local counts is thegreatest is chosen for that word.
Her results, however, indicate that her technique isnot a reliable method for distinguishing WordNet's fine-grained sense distinctions.
In asimilar study, Richardson and Smeaton (1994) create aknowledge base from WordNet'shierarchy and apply a semantic similarity function (developed by Resnik--see below)to accomplish disambiguation, also for the purposes of information retrieval.
Theyprovide no formal evaluation but indicate that their results are "promising.
"Sussna (1993) computes a semantic distance metric for each of a set of input textterms (nouns) in order to disambiguate hem.
He assigns weights based on the relationtype (synonymy, hyperonymy, etc.)
to WordNet links, and defines a metric that takesaccount of the number of arcs of the same type leaving a node and the depth of agiven edge in the overall "tree."
This metric is applied to arcs in the shortest pathbetween odes (word senses) to compute semantic distance.
The hypothesis i thatfor a given set of terms occurring near each other in a text, choosing the senses thatminimize the distance among them selects the correct senses.
SuSsna's disambiguationresults are demonstrated to be significantly better than chance.
His work is particularlyinteresting because it is one of the few to date that utilizes not only WordNet's IS-Ahierarchy, but other relational links as well.Resnik (1995a) draws on his body of earlier work on WordNet, in which he ex-plores a measure of semantic similarity for words in the WordNet hierarchy (Resnik1993a, 1993b, 1995a).
He computes the shared information content of words, whichis a measure of the specificity of the concept hat subsumes the words in the Word-Net IS-A hierarchy--the more specific the concept hat subsumes two or more words,the more semantically related they are assumed to be.
Resnik contrasts his method ofcomputing similarity to those which compute path length (e.g., Sussna 1993), arguingthat the links in the WordNet axonomy do not represent uniform distances (cf.
Resnik1995b).
Resnik's method, applied using WordNet's fine-grained sense distinctions andmeasured against the performance ofhuman judges, approaches human accuracy.
Likethe other studies cited here, his work considers only nouns.WordNet is not a perfect resource for word sense disambiguation.
The most fre-quently cited problem is the fine-grainedness of WordNet's ense distinctions, whichare often well beyond what may be needed in many language-processing applications(see Section 3.2).
Voorhees' (1993) hood construct isan attempt to access ense distinc-tions that are less fine-grained than WordNet's ynsets, and less coarse-grained thanthe 10 WordNet noun hierarchies; Resnik's (1995a) method allows for detecting sensedistinctions at any level of the WordNet hierarchy.
However, it is not clear what thedesired level of sense distinction should be for WSD (or if it is the same for all wordcategories, all applications, etc.
), or if this level is even captured in WordNet's hier-archy.
Discussion within the language-processing community is beginning to addressthese issues, including the most difficult one of defining what we mean by "sense"(see Section 3.2).Generative Lexicons.
Most WSD work to date has relied upon enumerative s nse distinc-tions as found in dictionaries.
However, there has been recent work on WSD which hasexploited generative l xicons (Pustejovsky 1995), in which related senses (i.e., system-atic polysemy, as opposed to homonymy) are not enumerated but rather are generatedfrom rules that capture regularities in sense creation, as for metonymy, meronymy, etc.13Computational Linguistics Volume 24, Number 1As outlined in Buitelaar (1997), sense disambiguation i the generative context startswith a semantic tagging that points to a complex knowledge representation reflectingall of a word's systematically related senses, after which semantic processing may de-rive a discourse-dependent interpretation containing more precise sense informationabout the occurrence.
Buitelaar (1997) describes the use of CORELEX for underspeci-fled semantic tagging (see also Pustejovsky, Boguraev, and Johnston \[1995\]).Viegas, Mahesh, and Nirenburg (forthcoming) describe a similar approach to WSDundertaken i  the context of their work on machine translation (see also Mahesh et al\[1997\] and Mahesh, Nirenburg, and Beale \[1997\]).
They access a large syntactic and se-mantic lexicon that provides detailed information about constraints, uch as selectionalrestrictions, for words in a sentence, and then search a richly connected ontology todetermine which senses of the target word best satisfy these constraints.
They reporta success rate of 97%.
Like CORELEX, both the lexicon and the ontology are manuallyconstructed, and therefore still limited, although much larger than the resources usedin earlier work.
However, Buitelaar (1997) describes means to automatically generateCORELEX entries from corpora in order to create domain-specific semantic lexicons,thus demonstrating the potential to access larger-scale resources of this kind.2.4 Corpus-based Methods2.4.1 Growth, Decline, and Re-emergence of Empirical Methods.
Since the end ofthe nineteenth century, the manual analysis of corpora has enabled the study of wordsand graphemes (Kaeding 1897-1898, Estoup 1902, Zipf 1935) and the extraction of listsof words and collocations for the study of language acquisition or language teaching(Thorndike 1921; Fries and Traver 1940; Thorndike and Lorge 1938, 1944; Gougenheimet al 1956; etc.).
Corpora have been used in linguistics since the first half of thetwentieth century (e.g., Boas 1940; Fries 1952).
Some of this work concerns word senses,and it is often strikingly modern: for example, Palmer (1933) studied collocations inEnglish; Lorge (1949) computed sense frequency information for the 570 most commonEnglish words; Eaton (1940) compared the frequency of senses in four languages;and Thorndike (1948) and Zipf (1945) determined that there is a positive correlationbetween the frequency and the number of synonyms of a word, the latter of which isan indication of semantic richness (the more polysemous a word, the more synonymsit has).A corpus provides a bank of samples that enable the development of numericallanguage models, and thus the use of corpora goes hand-in-hand with empirical meth-ods.
Although quantitative/statistical methods were embraced in early MT work, inthe mid-1960s interest in statistical treatment of language waned among linguists dueto the trend toward the discovery of formal linguistic rules sparked by the theoriesof Zellig Harris (1951) and bolstered most notably by the transformational theoriesof Noam Chomsky (1957).
12 Instead, attention turned toward full linguistic analysisand hence toward sentences rather than texts, and toward contrived examples andartificially limited domains instead of general anguage.
During the following 10 to12 Not all linguists completely abandoned the empirical approach at this time; consider, for instance,Pendergraft's (1967) comment:It would be difficult, indeed, in the face of today's activity, not to acknowledge the triumphof the theoretical pproach, more precisely, of formal rules as the preferred successor oflexical and syntactic search algorithms in linguistic description.
At the same time, commonsense should remind us that hypothesis-making is not the whole of science, and thatdiscipline will be needed if the victory is to contribute more than a haven from the rigors ofexperimentation (p. 313).14Ide and V~ronis Introduction15 years, only a handful of linguists continued to work with corpora, most oftenfor pedagogical or lexicographic ends (e.g., Quirk 1960; Mich6a 1964).
Despite this,several important corpora were developed uring this period, including the BrownCorpus (Kucera and Francis 1967), the Tr~sor de la Langue Fran?aise (Imbs 1971), and theLancaster-Oslo-Bergen (LOB) corpus (Johansson 1980).
In the area of natural anguageprocessing, the ALPAC report (1966) recommended intensification of corpus-based re-search for the creation of broad-coverage rammars and lexicons, but because of theshift away from empiricism, little work was done in this area until the 1980s.
Untilthen, the use of statistics for language analysis was almost the exclusive property ofresearchers in the fields of literary and humanities computing, information retrieval,and the social sciences.
Within these fields, work on WSD continued, most notablyin the Harvard "disambiguation project" for content analysis (Stone et al 1966; Stone1969), and also in the work of Iker (1974, 1975), Choueka and Dreizin (1976) andChoueka and Goldberg (1979).In the context of the shift away from the use of corpora and empirical methods,the work of Weiss (1973) and Kelley and Stone (1975) on the automatic extraction ofknowledge for word sense disambiguation seems especially innovative.
Weiss (1973)demonstrated that disambiguation rules can be learned from a manually sense-taggedcorpus.
Despite the small size of his study (five words, a training set of 20 sentencesfor each word, and 30 test sentences for each word), Weiss's results are encouraging(90% correct).
Kelley and Stone's (1975) work, which grew out of the Harvard "disam-biguation project" for content analysis, is on a much larger scale; they extract KWICconcordances for 1,800 ambiguous words from a corpus of a half-million words.
Theconcordances serve as a basis for the manual creation of disambiguation rules ("wordtests") for each sense of the 1,800 words.
The tests--also very sophisticated for thetime examine the target word context for clues on the basis of collocational infor-mation, syntactic relations with context words, and membership in common semanticcategories.
Their rules perform even better than Weiss's, achieving 92% accuracy forgross homographic sense distinctions.In the 1980s, interest in corpus linguistics was revived (see, for example, Aarts\[1990\] and Leech \[1991\]).
Advances in technology enabled the creation and storage ofcorpora larger than had been previously possible, enabling the development of newmodels most often utilizing statistical methods.
These methods were rediscovered firstin speech processing (e.g., Jelinek \[1976\]; see the overview by Church and Mercer \[1993\]and the collection of reprints by Waibel and Lee \[1990\]) and were immediately appliedto written language analysis (e.g., in the work of Bahl and Mercer \[1976\], Debili \[1977\],etc.).
For a discussion, see Ide and Walker (1992).In the area of word sense disambiguation, Black (1988) developed a model basedon decision trees using a corpus of 22 million tokens, after manually sense-tagging ap-proximately 2,000 concordance lines for five test words.
Since then, supervised learn-ing from sense-tagged corpora has since been used by several researchers: Zernik(1990, 1991), Hearst (1991), Leacock, Towell, and Voorhees (1993), Gale, Church, andYarowsky (1992d, 1993), Bruce and Wiebe (1994), Miller et al (1994), Niwa and Nitta(1994), Lehman (1994), among others.
However, despite the availability of increas-ingly large corpora, two major obstacles impede the acquisition of lexical knowledgefrom corpora: the difficulties of manually sense-tagging a training corpus, and datasparseness.2.4.2 Automatic Sense-Tagging.
Manual sense-tagging of a corpus is extremely costly,and, at present, very few sense-tagged corpora are available.
Several efforts to createsense-tagged corpora have been or are being made: the Linguistic Data Consortium15Computational Linguistics Volume 24, Number 1distributes a corpus of approximately 200,000 sentences from the Brown Corpus andthe Wall Street Journal in which all occurrences of 191 words are hand-tagged with theirWordNet senses (see Ng and Lee \[1996\]).
Also, the Cognitive Science Laboratory atPrinceton has undertaken the hand-tagging of 1,000 words from the Brown Corpuswith WordNet senses (Miller et al 1993) (so far, 200,000 words are available via ftp),and hand-tagging of 25 verbs in a small segment of the Wall Street Journal (12,925sentences), is also underway (Wiebe et al 1997).
However, these corpora re far smallerthan those typically used with statistical methods.Several efforts have been made to automatically sense-tag a training corpus viabootstrapping methods.
Hearst (1991) proposed an algorithm (CatchWord) that in-cludes a training phase during which each occurrence of a set of nouns to be dis-ambiguated is manually sense-tagged in several occurrences.
13 Statistical informationextracted from the context of these occurrences i  then used to disambiguate other oc-currences.
If another occurrence can be disambiguated with certitude, the system auto-matically acquires additional statistical information from these newly disambiguatedoccurrences, thus improving its knowledge incrementally.
Hearst indicates that aninitial set of at least 10 occurrences i necessary for the procedure, and that 20 or3{) occurrences are necessary for high precision.
This overall strategy is more or lessthat of most subsequent work on bootstrapping.
Recently, a class-based bootstrappingmethod for semantic tagging in specific domains has been proposed (Basili et al 1997).Sch~tze (1992, 1993) proposes amethod that avoids tagging each occurrence in thetraining corpus.
Using letter fourgrams within a 1,001-character window, his method,building on the vector-space model from information retrieval (see Salton, Wong, andYang \[1975\]), automatically clusters the words in the text (each target word is rep-resented by a vector); a sense is then assigned manually to each cluster, rather thanto each occurrence.
Assigning a sense demands examining 10 to 20 members of eachcluster, and each sense may be represented by several clusters.
This method reducesthe amount of manual intervention but still requires the examination of a hundredor so occurrences for each ambiguous word.
A more serious issue for this method isthat it is not clear what the senses derived from the clusters correspond to (see, forexample Pereira, Tishby, and Lee \[1993\]); moreover, the senses are not directly usableby other systems, since they are derived from the corpus itself.Brown et al (1991) and Gale, Church, and Yarowsky, (1992a, 1993) propose theuse of bilingual corpora to avoid hand-tagging of training data.
Their premise is thatdifferent senses of a given word often translate differently in another language (forexample, pen in English is stylo in French for its 'writing implement' sense, and en-clos for its 'enclosure' sense).
By using a parallel aligned corpus, the translation ofeach occurrence of a word such as pen can be used to automatically determine itssense.
This method has some limitations, ince many ambiguities are preserved in thetarget language (e.g., French souris--English mouse); furthermore, the few availablelarge-scale parallel corpora are very specialized (for example, the Hansard corpus ofCanadian Parliamentary Debates), which skews the sense representation.
14 Dagan, Itai,and Schwall (1991) and Dagan and Itai (1994) propose a similar method, but instead ofa parallel corpus use two monolingual corpora and a bilingual dictionary.
This solves,in part, the problems of availability and specificity of domain that plague the parallelcorpus approach, since monolingual corpora, including corpora from diverse domainsand genres, are much easier to obtain than parallel corpora.13 This study involves only nouns.14 For example, Gale, Church, and Yarowsky (1993) remark that it is difficult to find any sense other thanthe financial sense for the word bank in the Hansard corpus.16Ide and V~ronis IntroductionOther methods attempt o avoid entirely the need for a tagged corpus, such asmany of those cited in the section below (e.g., Yarowsky \[1992\] who attacks both thetagging and data sparseness problems imultaneously).
However, it is likely that, asnoted for grammatical tagging (M6rialdo 1994), even a minimal phase of supervisedlearning improves radically on the results of unsupervised methods.
Research intomeans to facilitate and optimize tagging is ongoing; for example, an optimizationtechnique called committee-based sample selection has recently been proposed (En-gelson and Dagan 1996), which, based on the observation that a substantial portionof manually tagged examples contribute little to performance, nables avoiding thetagging of examples that carry more or less the same information.
Such methods arepromising, although to our knowledge they have not been applied to the problem oflexical disambiguation.2.4.3 Overcoming Data Sparseness.
The problem of data sparseness, which is commonfor much corpus-based work, is especially severe for work in WSD.
First, enormousamounts of text are required to ensure that all senses of a polysemous word arerepresented, given the vast disparity in frequency among senses.
For example, in theBrown Corpus (one million words), the relatively common word ash occurs only eighttimes, and only once in its sense as tree.
The sense ashes = remains of cremated body,although common enough to be included in learner's dictionaries such as the LDOCEand the OALD, does not appear, and it would be nearly impossible to find the dozenor so senses in many everyday dictionaries such as the CED.
In addition, the manypossible co-occurrences for a given polysemous word are unlikely to be found in evena very large corpus, or they occur too infrequently to be significant.
15Smoothing is used to get around the problem of infrequently occurring events,and in particular to ensure that non-observed events are not assumed to have a prob-ability of zero.
The best-known smoothing methods are that of Turing-Good (Good1953), which hypothesizes a binomial distribution of events, and that of Jelinek andMercer (1985), which combines estimated parameters on distinct subparts of the train-ing corpus.
16 However, these methods do not enable distinguishing between eventswith the same frequency, such as the ash-cigarette and ash-room example given in foot-note 15.
Church and Gale (1991) have proposed a means to improve methods forthe estimation of bigrams, which could be extended to co-occurrences: they take intoaccount he frequency of the individual words that compose the bigram and makethe hypothesis that each word appears independently of the others.
However, thishypothesis contradicts hypotheses of disambiguation based on co-occurrence, whichrightly assume that some associations are more probable than others.Class-based models attempt o obtain the best estimates by combining observa-tions of classes of words considered to belong to a common category.
Brown et al(1992), Pereira and Tishby (1992), and Pereira, Tishby, and Lee (1993) propose meth-ods that derive classes from the distributional properties of the corpus itself, whileother authors use external information sources to define classes: Resnik (1992) usesthe taxonomy of WordNet; Yarowsky (1992) uses the categories of Roget's Thesaurus,Slator (1992) and Liddy and Paik (1993) use the subject codes in the LDOCE; Luk(1995) uses conceptual sets built from the LDOCE definitions.
Class-based methodsanswer in part the problem of data sparseness and eliminate the need for pretagged15 For example, ina window of five words to each side of the word ash in the Brown corpus, commonlyassociated words uch asfire, cigar, volcano, etc., do not appear.
The words cigarette and tobacco co-occurwith ash only once, with the same frequency aswords uch as room, bubble, and house.16 See the survey of methods inChen and Goodman (1996).17Computational Linguistics Volume 24, Number 1data.
However, there is some information loss with these methods because the hy-pothesis that all words in the same class behave in a similar fashion is too strong.For example, residue is a hypernym of ash in WordNet; its hyponyms form the class{ash, cotton(seed) cake, dottle}.
Obviously the members of this set of words behave verydifferently in context: volcano is strongly related to ash, but has little or no relation tothe other words in the set.Similarity-based methods Dagan, Marcus, and Markovitch 1993, Dagan, Pereira,and Lee 1994, and Grishman and Sterling 1993 exploit the same idea of groupingobservations for similar words, but without regrouping them into fixed classes.
Eachword has a potentially different set of similar words.
Like many class-based meth-ods, such as Brown et al (1992), similarity-based methods exploit a similarity metricbetween patterns of co-occurrence.
Dagan, Marcus, and Markovitch (1993) give thefollowing example: the pair (chapter, describes) does not appear in their corpus; how-ever, chapter is similar to book, introduction, and section, which are paired with describesin the corpus.
On the other hand, the words similar to book are books, documentation,and manuals (see their Figure 1).
Dagan, Marcus, and Markovitch's (1993) evaluationseems to show that similarity-based methods perform better than class-based methods.Karov and Edelman (this volume) propose an extension to similarity-based methodsby means of an iterative process at the learning stage, which gives results that are92% accurate on four test words--approximately thesame as the best results cited inthe literature to date.
These results are particularly impressive given that the trainingcorpus contains only a handful of examples for each word, rather than the hundredsof examples required by most methods.3.
Open ProblemsWe have already noted various problems faced in current WSD research related tospecific methodologies.
Here, we discuss issues and problems that all approaches toWSD must face and suggest some directions for further work.3.1 The Role of ContextContext is the only means to identify the meaning of a polysemous word.
Therefore,all work on sense disambiguation relies on the context of the target word to provideinformation to be used for its disambiguation.
For data-driven methods, context alsoprovides the prior knowledge with which current context is compared to achievedisambiguation.Broadly speaking, context is used in two ways:Bag-of-words approach: context is considered as words in some windowsurrounding the target word, regarded as a group without considerationfor their relationships to the target in terms of distance, grammaticalrelations, etc.Relational information: context is considered in terms of some relation tothe target, including distance from the target, syntactic relations,selectional preferences, orthographic properties, phrasal collocation,semantic ategories, etc.Information from microcontext, topical context, and domain contributes to senseselection, but the relative roles and importance of information from the different con-texts, and their interrelations, are not well understood.
Very few studies have used18Ide and V4ronis Introductioninformation of all three types, and the focus in much recent work is on microcontextalone.
This is another area where systematic study is needed for WSD.3.1.1 Microcontext.
Most disambiguation work uses the local context of a word occur-rence as a primary information source for WSD.
Local or "micro" context is generallyconsidered to be some small window of words surrounding a word occurrence in atext or discourse, from a few words of context o the entire sentence in which thetarget word appears.Context is very often regarded as all words or characters falling within somewindow of the target, with no regard for distance, syntactic structure, or other elations.Early corpus-based work, such as that of Weiss (1973) used this approach; spreadingactivation and dictionary-based approaches also do not usually differentiate contextinput on any basis other than occurrence in a window.
Schtitze's vector space method(this volume) is a recent example of an approach that ignores adjacency information.Overall, the bag-of-words approach as been shown to work better for nouns thanfor verbs (cf.
Schtitze, this volume), and to be in general less effective than methodsthat take other relations into consideration.
However, as demonstrated in Yarowsky's(1992) work, the approach is cheaper than those requiring more complex processingand can achieve sufficient disambiguation for some applications.
We examine belowsome of the other parameters.Distance.
It is obvious from the quotation in Section 2.1 from Weaver's memorandumthat the notion of examining a context of a few words around the target o disam-biguate has been fundamental toWSD work since its beginnings: it has been the basisof WSD work in MT, content analysis, AI-based disambiguation, and dictionary-basedWSD, as well as the more recent statistical, neural network, and symbolic machinelearning, approaches.
However, following Kaplan's early experiments (Kaplan 1950),there have been few systematic attempts to answer Weaver's question concerning theoptimal value of N. A notable xception is the study of Choueka nd Lusignan (1985),who verified Kaplan's finding that 2-contexts are highly reliable for disambiguation,and even 1-contexts are reliable in 8 out of 10 cases.
However, despite these findings,the value of N has continued to vary over the course of WSD work more or lessarbitrarily.Yarowsky (1993, 1994a, 1994b) examines different windows of microcontext, in-cluding 1-contexts, k-contexts, and words pairs at offsets -1 and -2, -1 and +1, and+1 and +2, and sorts them using a log-likelihood ratio to find the most reliable evi-dence for disambiguation.
Yarowsky makes the observation that the optimal value ofk varies with the kind of ambiguity: he suggests that local ambiguities need only awindow of k = 3 or 4, while semantic or topic-based ambiguities require a larger win-dow of 20-50 words (see Section 3.1.2).
No single best measure is reported, suggestingthat for different ambiguous words, different distance relations are more efficient.
Fur-thermore, because Yarowsky also uses other information (such as part of speech), itis difficult o isolate the impact of window-size alone.
Leacock, Chodorow, and Miller(this volume) use a local window of ?3 open-class words, arguing that this numbershowed best performance in previous tests.Col locat ion.
The term "collocation" has been used variously in WSD work.
The termwas popularized by J. R. Firth in his 1951 paper "Modes of meaning": "One ofthe meanings of ass is its habitual collocation with an immediately preceding yous i l ly  .
.
.
.  "
He emphasizes that collocation is not simple co-occurrence but is "habitual"19Computational Linguistics Volume 24, Number 1or "usual.
''17 Halliday's (1961) definition of collocation as "the syntagmatic associationof lexical items, quantifiable, textually, as the probability that there will occur at nremoves (a distance of n lexical items) from an item x, the items a, b, c .
.
."
is moreworkable in computational terms.Based on this definition, a significant collocation can be defined as a syntagmaticassociation among lexical items, where the probability of item x co-occurring withitems a, b, c .
.
.
is greater than chance (Berry-Rogghe 1973).
It is in this sense that mostWSD work uses the term.
There is some psychological evidence that collocations aretreated ifferently from other co-occurrences.
For example, Kintsch and Mross (1985)show that priming words that enter frequent collocations with test words (i.e., iron-steel,which they call associative context) activate these test words in lexical decision tasks.Conversely, priming words that are in the thematic ontext (i.e., relations determinedby the situation, scenario, or script such as plane-gate) do not facilitate the subjects'lexical decisions (see also Fischler \[1977\], Seidenberg et al \[1982\], De Groot \[1983\],Lupker \[1984\]).Yarowsky (1993) explicitly addresses the use of collocations in WSD work, butadmittedly adapts the definition to his purpose as "the co-occurrence of two words insome defined relation."
As noted above, he examines a variety of distance relations, butalso considers adjacency by part of speech (e.g., first noun to the left).
He determinesthat in cases of binary ambiguity, there exists one sense per collocation, that is, in agiven collocation, a word is used with only one sense with 90-99% probability.Syntactic Relations.
Earl (1973) used syntax exclusively for disambiguation in machinetranslation.
In most WSD work to date, syntactic information is used in conjunctionwith other information.
The use of selectional restrictions weighs heavily in AI-basedwork that relies on full parsing, frames, semantic networks, the application of se-lectional preferences, etc.
(Hayes 1977a, 1997b; Wilks 1973 and 1975b; Hirst 1987).In other work, syntax is combined with frequent collocation information: Kelley andStone (1975), Dahlgren (1988), and Atkins (1987) combine collocation information withrules for determining, for example, the presence or absence of determiners, pronouns,noun complements, aswell as prepositions, ubject-verb and verb-object relations.More recently, researchers have avoided complex processing by using shallow orpartial parsing.
In her disambiguation work on nouns, Hearst (1991) segments textinto noun phrases, prepositional phrases, and verb groups, and discards all other syn-tactic information.
She examines items that are within i3  phrase segments from thetarget and combines yntactic evidence with other kinds of evidence, such as capital-ization.
Yarowsky (1993) determines various behaviors based on syntactic ategory; forexample, that verbs derive more disambiguating information from their objects thanfrom their subjects, adjectives derive almost all disambiguating information from thenouns they modify, and nouns are best disambiguated by directly adjacent adjectivesor nouns.
In recent work, syntactic information most often is simply part of speech,used invariably in conjunction with other kinds of information (McRoy 1992; Bruceand Wiebe 1994; Leacock, Chodorow, and Miller, this volume).Evidence suggests that different kinds of disambiguation procedures are neededdepending on the syntactic ategory and other characteristics of the target word(Yarowsky 1993; Leacock, Chodorow, and Miller, this volume)--an idea reminiscentof the word expert approach.
However, to date there has been little systematic study17 Later, several ttempts were made to define the term more precisely inthe framework ofmodernlinguistic theory.
See, for example, Haas (1966), Halliday (1961, 1966), Lyons (1966), McIntosh (1966),Sinclair (1966), van Buren (1967).2.0Ide and V~ronis Introductionof the contribution of different information types for different ypes of target words.It is likely that this is a next necessary step in WSD work.3.1.2 Topical Context.
Topical context includes ubstantive words that co-occur witha given sense of a word, usually within a window of several sentences.
Unlike micro-context, which has played a role in disambiguation work since the early 1950s, topicalcontext has been less consistently used.
Methods relying on topical context exploitredundancy in a text--that is, the repeated use of words that are semantically relatedthroughout a text on a given topic.
Thus, base is ambiguous, but its appearance in adocument containing words such as pitcher, and ball is likely to isolate a given sensefor that word (as well as the others, which are also ambiguous).
Work involving topicalcontext ypically uses the bag-of-words approach, in which words in the context areregarded as an unordered set.The use of topical context has been discussed in the field of information retrievalfor several years (Anthony 1954; Salton 1968).
Recent WSD work has exploited topicalcontext: Yarowsky (1992) uses a 100-word window, both to derive classes of relatedwords and as context surrounding the polysemous target, in his experiments usingRoget's Thesaurus (see Section 2.3.2).
Voorhees, Leacock, and Towell (1995) experimentwith several statistical methods using a two-sentence window; Leacock, Towell, andVoorhees (1993, 1996) have similarly explored topical context for WSD.
Gale, Church,and Yarowsky (1993), looking at a context of ?50 words, indicate that while words clos-est to the target contribute most to disambiguation, they improved their results from86% to 90% by expanding context from ?6 (a typical span when only microcontext isconsidered) to ~50 words around the target.
In a related study, they make a claim thatfor a given discourse, ambiguous words are used in a single sense with high probability("one sense per discourse") (Gale, Church, and Yarowsky 1992c).
Leacock, Chodorow,and Miller (this volume) challenge this claim in their work combining topical andlocal context, which shows that both topical and local context are required to achieveconsistent results across polysemous words in a text (see also Towell and Voorhees,this volume).
Yarowsky's (1993) study indicates that while information within a largewindow can be used to disambiguate nouns, for verbs and adjectives the size of theusable window drops off dramatically with distance from the target word.
This sup-ports the claim that both local and topical context are required for disambiguation,and points to the increasingly accepted notion that different disambiguation methodsare appropriate for different kinds of words.Methods utilizing topical context can be ameliorated by dividing the text underanalysis into subtopics.
The most obvious way to divide a text is by sections (Brownand Yule 1983), but this is only a gross division; subtopics evolve inside sections, oftenin unified groups of several paragraphs.
Automatic segmentation f texts into suchunits would obviously be helpful for WSD methods that use topical context.
It has beennoted that the repetition of words within successive segments or sentences i  a strongindicator of the structure of discourse (Skorochod'ko 1972; Morris 1988; Morris andHirst 1991); methods exploiting this observation to segment a text into subtopics arebeginning to emerge (see, for example, Hearst \[1994\], van der Eijk \[1994\], Richmond,Smith, and Amitay \[1997\]).In this volume, Leacock, Chodorow, and Miller consider the role of microcontextvs.
topical context and attempt to assess the contribution of each.
Their results indicatethat for a statistical c assifier, microcontext is superior to topical context as an indicatorof sense.
However, although a distinction is made between microcontext and topicalcontext in current WSD work, it is not clear that this distinction is meaningful.
It maybe more useful to regard the two as lying along a continuum, and to consider the role21Computational Linguistics Volume 24, Number 1and importance of contextual information as a function of distance from the target.3.1.3 Domain.
The use of domain for WSD is first evident in the microglossariesdeveloped in early MT work (see Section 2.1).
The notion of disambiguating sensesbased on domain is implicit in various AI-based approaches, uch as Schank's criptapproach to natural anguage processing (Schank and Abelson 1977), which matchedwords to senses based on the context or "script" activated by the general topic ofthe discourse.
This approach, which activates only the sense of a word relevant o thecurrent discourse domain, demonstrates its limitations of this approach when used inisolation; in the famous example The lawyer stopped at the bar for a drink, the incorrectsense of bar will be assumed if one relies only on the information in a script concernedwith law.
TMGale, Church, and Yarowsky's (1992c) claim for one sense per discourse is dis-putable.
Dahlgren (1988) observes that domain does not eliminate ambiguity for somewords: she remarks that the noun hand has 16 senses (or so) and retains 10 of themin almost any text.
The influence of domain likely depends on factors such as thetype of text (how technical the text is, etc.
), the relation among the senses of the targetword (strongly or weakly polarized, common vs. specialized usage, etc.).
For example,in the French Encyclopaedia Universalis, the word intdrOt ("interest") appears 62 timesin the article on INTEREST--FINANCE, in all cases in its financial sense; the wordappears 139 times in the article INTEREST--PHILOSOPHY AND HUMANITIES inits common, nonfinancial, sense.
However, in the article THIRD WORLD, the wordint~r~t appears two times in each of these senses.3.2 Sense D iv is ion3.2.1 The Bank Model.
Most researchers in WSD are currently relying on the sensedistinctions provided by established lexical resources, uch as machine-readable dictio-naries or WordNet (which uses the OALD's senses), because they are widely available.The dominant model in these studies is the "bank" model, which attempts to extendthe clear delineation between bank-money and bank-riverside to all sense distinctions.However, it is clear that this convenient delineation is by no means applicable to allor even most other words.
Although there is some psychological validity to the notionof senses (Simpson and Burgess 1988; Jorgensen 1990), lexicographers themselves arewell aware of the lack of agreement on senses and sense divisions (see, for example,Malakhovski \[1987\], Robins \[1987\], Ayto \[1983\], Stock \[1983\]).
The problem of sensedivision has been an object of discussion since antiquity: Aristotle 19 devoted a sectionof his Topics to this subject in 350 B.C.
Since then, philosophers and linguists have con-tinued to discuss the topic at length (see Quine \[1960\], Asprejan \[1974\], Lyons \[1977\],Weinrich \[1980\], Cruse \[1986\]), but the lack of resolution over 2,000 years is striking.3.2.2 Granularity.
One of the foremost problems for WSD is to determine the appropri-ate degree of sense granularity.
Several authors (for example, Slator and Wilks \[1987\])have remarked that the sense divisions one finds in dictionaries are often too finefor the purposes of NLP work.
Overly fine sense distinctions create practical difficul-18 An interesting development based on Schank's approach is described in Granger (1977), where heutilizes information in scripts and conceptual dependency representations of entences todeterminethe meaning of entirely unknown words encountered in text.
The approach, which examines domainand contextual evidence to determine meaning, is similar to that employed in much AI-based work ondisambiguation.19 One of the reviewers for this special issue remarked humorously that if Aristotle had had a PC, hewould have probably worked on word sense disambiguation!22Ide and VOronis Introductionties for automated WSD: they introduce significant combinatorial effects (for example,Slator and Wilks \[1987\] note that the sentence There is a huge envelope of air around thesurface of the earth has 284,592 different potential combined sense assignments usingthe moderately-sized LDOCE); they require making sense choices that are extremelydifficult, even for expert lexicographers; and they increase the amount of data requiredfor supervised methods to unrealistic proportions.
In addition, the sense distinctionsmade in many dictionaries are sometimes beyond those which human readers them-selves are capable of making.
In a well-known study, Kilgarriff (1992, 1993) showsthat it is impossible for human readers to assign many words to a unique sense inLDOCE (see, however, the discussion in Wilks \[forthcoming\]).
Recognizing this, Dolan(1994) proposes a method for "ambiguating" dictionary senses by combining them tocreate grosser sense distinctions.
Others have used the grosser sense divisions of the-sauri such as Roget's; however, it is often difficult to assign a unique sense, or evenfind an appropriate one among the options (see, for example, Yarowsky \[1992\]).
Chenand Chang (this volume) propose an algorithm that combines enses in a dictionary(LDOCE) and links them to the categories of a thesaurus (LLOCE).Combining dictionary senses does not solve the problem.
First of all, the degreeof granularity required is task dependent.
Only homograph distinction is necessaryfor tasks such as speech synthesis or restoration of accents in text, while tasks suchas machine translation require fine sense distinctions--in some cases finer than whatmonolingual dictionaries provide (see, for example, ten Hacken \[1990\]).
For example,the English word river is translated as fleuve in French when the river flows into theocean, and otherwise as rivi~re.
There is not, however, a strict correspondence b tweena given task and the degree of granularity required.
For example, as noted earlier, theword mouse, although it has two distinct senses (animal, device), translates into Frenchin both cases to souris.
On the other hand, for information retrieval the distinctionbetween these two senses of mouse is important, whereas it is difficult to imaginea reason to distinguish river (sense yqeuve) - river (sense rivi~re).
Second, and moregenerally, it is unclear when senses hould be combined or split.
Even lexicographersdo not agree: Fillmore and Atkins (1991) identify three senses of the word risk but findthat most dictionaries fail to list at least one of them.
In many cases, meaning is bestconsidered as a continuum along which shades of meaning fall (see, for example, Cruse\[1986\]), and the points at which senses are combined or split can vary dramatically.3.2.3 Senses or usages?
The Aristotelian idea that words correspond to specific objectsand concepts was displaced in the twentieth century by the ideas of Saussure andothers (Meillet \[1926\], Hjemslev \[1953\], Martinet \[1960\], etc.).
For Antoine Meillet, forexample, the sense of a word is defined only by the average of its linguistic uses.Wittgenstein takes a similar position in his Philosophische Utersuchungen 2?
in assertingthat there are no senses, but only usages:"For a large class of cases--though not for all--in which we employthe word 'meaning' it can be defined thus: the meaning of a word isits use in the language" (1953, Sect.
43).Similar views are apparent in more recent heories of meaning, for example, Bloomfield(1933) and Harris (1954), for whom meaning is a function of distribution; and inBarwise and Perry's (1953) situation semantics, where the sense or senses of a wordare seen as an abstraction of the role that it plays systematically in the discourse.20 Note that Wittgenstein had first defended the Aristotelian view in his Tractatus.23Computational Linguistics Volume 24, Number 1The COBUILD project (Sinclair 1987) adopts this view of meaning by attemptingto anchor dictionary senses in current usage by creating sense divisions on the basisof clusters of citations in a corpus.
Atkins (1987) and Kilgarriff (forthcoming) alsoimplicitly adopt the view of Harris (1954), according to which each sense distinctionis reflected in a distinct context.
A similar view underlies the class-based methodscited in Section 2.4.3 (Brown et al 1992; Pereira and Tishby 1992; Pereira, Tishby, andLee 1993).
In this volume, Schiitze continues in this vein and proposes a techniquethat avoids the problem of sense distinction altogether: he creates ense clusters froma corpus rather than relying on a pre-established sense list.3.2.4 Enumerat ion or generation?
The development of generative lexicons (Puste-jovsky 1995) provides a view of word senses that is very different from that of almostall WSD work to date.
The enumerative approach assumes an a priori, establishedset of senses that exist independent of context--fundamentally the Aristotelian view.The generative approach develops a discourse-dependent representation f sense, as-suming only underspecified sense assignments until context is taken into account, andbears closer relation to distributional nd situational views of meaning.Considering the difficulties of determining an adequate and appropriate set ofsenses for WSD, it is surprising that little attention has been paid to the potential ofthe generative view in WSD research.
As larger and more complete generative l xiconsbecome available, there is merit to exploring this approach to sense assignment.3.3 EvaluationGiven the variety in the studies cited throughout the previous urvey, it is obviousthat it is very difficult to compare one set of results, and consequently one method,with another.
The lack of comparability results from substantial differences in testconditions from study to study.
For instance, different ypes of texts are involved,including both highly technical or domain-specific texts where sense use is limitedand general texts where sense use may be more variable.
It has been noted that ina commonly used corpus such as the Wall Street Journal, certain senses of typical testwords such as line are absent entirely.
21When different corpora containing differentsense inventories and very different levels of frequency for a given word and/or senseare used, it becomes futile to attempt to compare results.Test words themselves differ from study to study, including not only words whoseassignment toclearly distinguishable s nses varies considerably orwhich exhibit verydifferent degrees of ambiguity (e.g., bank vs. line), but also words across different partsof speech and words that tend to appear more frequently in metaphoric, metonymic,and other nonliteral usages (e.g., bank vs. head).
More seriously, the criteria for eval-uating the correctness of sense assignment vary.
Different studies employ differentdegrees of sense granularity (see Section 3.2 above), ranging from identification ofhomographs to fine sense distinctions.
In addition, the means by which correct senseassignment is finally judged are typically unclear.
Human judges must ultimately de-cide, but the lack of agreement among human judges is well documented: Amsler andWhite (1979) indicate that while there is reasonable consistency in sense assignmentfor a given expert on successive sense assignments (84%), agreement is significantlylower among experts.
Ahlswede (1995) reports between 63.3% and 90.2% agreementamong judges on his Ambiguity Questionnaire; when faced with on-line sense assign-21 For example, the common sense of line as in the sentence, Hegave me a line of bologna, is not present inthe Wall Street Journal corpus.24Ide and V~ronis Introductionment in a large corpus, agreement among judges is far less, and in some cases worsethan chance (see also Ahlswede \[1992, 1993\], Ahlswede and Lorand \[1993\]).
Jorgensen(1990) found the level of agreement in her experiment using data from the BrownCorpus to be about 68%.The difficulty of comparing results in WSD research as recently become a concernwithin the community, and efforts are underway to develop strategies for evaluationof WSD.
Gale, Church, and Yarowsky (1992b) attempt o establish lower and upperbounds for evaluating the performance ofWSD systems; their proposal for overcomingthe problem of agreement among human judges in order to establish an upper boundprovides a starting point, but it has not been widely discussed or implemented.
Arecent discussion at a workshop sponsored by the ACL Special Interest Group on theLexicon (SIGLEX) on "Evaluating Automatic SemanticTaggers" (Resnik and Yarowsky\[1997a\[; see also Resnik and Yarowsky \[1997b\], Kilgarriff \[1997\]) has sparked the forma-tion of an evaluation effort for WSD (SENSEVAL), in the spirit of previous evaluationefforts such as the ARPA-sponsored Message Understanding Conferences (e.g., ARPA\[1993\]), and Text Retrieval Conferences (e.g.
Harman \[1993, 1995\]).
SENSEVAL will seeits first results at a subsequent SIGLEX workshop to be held at Herstmonceux Castle,England in September, 1998.As noted above, WSD is not an end in itself but rather an "intermediate ask" thatcontributes to an overall task such as information retrieval or machine translation.
Thisopens the possibility of two types of evaluation for WSD work (using terminology bor-rowed from biology): in vitro evaluation, where WSD systems are tested independentof a given application, using specially constructed benchmarks; and evaluation in vivo,where, rather than being evaluated in isolation, results are evaluated in terms of theircontribution to the overall performance of a system designed for a particular applica-tion, such as machine translation.3.3.1 Evaluation In Vitro.
In vitro evaluation, despite its artificiality, enables closeexamination of the problems plaguing a given task.
In its most basic form, this typeof evaluation (also called variously performance evaluation: Hirschman and Thompson\[1996\]; assessment: Bimbot, Chollet, and Paoloni \[1994\]; or declarative valuation: Arnold,Sadler, and Humphreys \[1993\]) involves comparison of the output of a system for agiven input, using measures such as precision and recall.
SENSEVAL currently envis-ages this type of evaluation for WSD results.
Alternatively, in vitro evaluation can focuson study of the behavior and performance of systems on a series of test suites repre-senting the range of linguistic problems likely to arise in attempting WSD (diagnosticevaluation: Hirschman and Thompson \[1996\]; or typological evaluation: Arnold, Sadler,and Humphreys 1993).
Considerably deeper understanding of the factors involvedin the disambiguation task is required before appropriate test suites for typologicalevaluation of WSD results can be devised.
Basic questions uch as the role of partof speech in WSD, the treatment of metaphor, metonymy, and the like in evaluation,and how to deal with words of differing degrees and types of polysemy, must firstbe resolved.
SENSEVAL will likely take us a step closer to this understanding; at theleast, it will force consideration of what can be meaningfully regarded as an isolatablesense distinction and provide some measure of the distance between the performanceof current systems and a predefined standard.The in vitro evaluation envisaged for SENSEVAL demands the creation of a man-ually sense-tagged reference corpus containing an agreed-upon set of sense distinc-tions.
The difficulties of attaining sense agreement, even among experts, have alreadybeen outlined.
Resnik and Yarowsky (1997b) have proposed that for WSD evaluation,25Computational Linguistics Volume 24, Number 1it may be practical to retain only those sense distinctions that are lexicalized cross-linguistically.
This proposal has the merit of being immediately usable, but in viewof the types of problems cited in the previous section, systematic study of interlan-guage relations will be required to determine its viability and generality.
At present,the apparent best source of sense distinctions is assumed to be on-line resources uchas LDOCE or WordNet, although the problems of utilizing such resources are wellknown, and their use does not address issues of more complex semantic tagging thatgoes beyond the typical distinctions made in dictionaries and thesauri.Resnik and Yarowsky (1997b) also point out that a binary evaluation (correct/incor-rect) for WSD is not sufficient, and propose that errors be penalized according to adistance matrix among senses based on a hierarchical organization.
For example, fail-ure to identify homographs of bank (which would appear higher in the hierarchy)would be penalized more severely than failure to distinguish bank as an institutionfrom bank as a building (which would appear lower in the hierarchy).
However, de-spite the obvious appeal of this approach, it runs up against the same problem ofthe lack of an established, agreed-upon hierarchy of senses.
Aware of this problem,Resnik and Yarowsky suggest creating the sense distance matrix based on results inexperimental psychology such as Miller and Charles (1991) or Resnik (1995b).
Evenignoring the cost of creating such a matrix, the psycholinguistic literature has madeclear that these results are highly influenced by experimental conditions and the taskimposed on the subjects (see, for example, Tabossi \[1989, 1991\], Rayner and Morris\[1991\]); in addition, it is not clear that psycholinguistic data can be of help in WSDaimed toward practical use in NLP systems.In general, WSD evaluation confronts difficulties of criteria that are similar to,but orders of magnitude greater than, those facing other tasks such as part-of-speechtagging, due to the elusive nature of semantic distinctions.
It may be that at best wecan hope to find practical solutions that will serve particular needs; this is consideredmore fully in the next section.3.3.2 Evaluation In Vivo.
Another approach to evaluation is to consider esults inso-far as they contribute to the overall performance in a particular application, such asmachine translation, information retrieval, or speech recognition.
This approach (alsocalled adequacy evaluation: Hirschman and Thompson \[1996\]; or operational evaluation:Arnold, Sadler, and Humphreys \[1993\]), although it does not assure the general appli-cability of a method nor contribute to a detailed understanding of problems, does notdemand agreement on sense distinctions or the establishment of a pretagged corpus.Only the final result is taken into consideration, subjected to evaluation appropriateto the task at hand.Methods for WSD have evolved largely independently of particular applications,especially in the recent past.
It is interesting to note that few, if any, systems formachine translation have incorporated recent methods developed for WSD, despite theimportance of WSD for MT noted by Weaver almost 50 years ago.
The most obviouseffort to incorporate WSD methods into larger applications i in the field of informationretrieval, and the results are ambiguous: Krovetz and Croft (1992) report only a slightimprovement in retrieval using WSD methods; Voorhees (1993) and Sanderson (1994)indicate that retrieval degrades if disambiguation is not sufficiently precise.
Sparck-Jones (forthcoming) questions the utility of any NLP technique for document retrieval.On the other hand, Sch~tze and Pedersen (1995) show a marked improvement inretrieval (14.4%) using a method that combines earch-by-word and search-by-sense.It remains to be seen to what extent WSD can improve results in particular ap-26Ide and V4ronis Introductionplications.
However, if meaning is largely a function of use, it may be that the onlyrelevant evaluation of WSD results is achievable in the context of specific tasks.4.
Summary and ConclusionWork on automatic WSD has a history as long as automated language processinggenerally.
Looking back, it is striking to note that most of the problems and the basicapproaches to solving them were recognized at the outset.
Since so much of the earlywork on WSD is reported in relatively obscure books and articles across several fieldsand disciplines, it is not surprising that recent authors are often unaware of it.
Whatis surprising is that in the broad sense, relatively little progress eems to have beenmade in nearly 50 years.
Even though much recent work cites results at the 90% levelor better, these studies typically involve very few words, most often only nouns, andfrequently concern only broad sense distinctions.In a sense, WSD work has come full circle, returning most recently to empiricalmethods and corpus-based analyses that characterize some of the earliest attempts tosolve the problem.
With sufficiently greater esources and enhanced statistical methodsat their disposal, researchers in the 1990s have obviously improved on earlier results,but it appears that we may nearly have reached the limit of what can be achievedin the current framework.
For this reason, it is especially timely to assess the state ofWSD and consider, in the context of its entire history, the next directions of research.This paper is an attempt o provide that context, at least in part, by bringing WSDinto the perspective of the past 50 years of work on the topic.
While we are awarethat much more could be added to what is presented here, we have made an attemptto cover at least the major areas of work and sketch the broad lines of developmentin the field.
22Of course, WSD is problematic in part because of the inherent difficulty of deter-mining or even defining word sense, and this is not an issue that is likely to be solvedin the near future.
Nonetheless, it seems clear that current WSD research could benefitfrom a more comprehensive consideration of theories of meaning and work in thearea of lexical semantics.
One of the obvious stumbling blocks in much recent WSDwork is the rather narrow view of sense that comes hand-in-hand with the attemptto use sense distinctions in everyday dictionaries, which cannot, and are not intendedto, represent meaning in context.
A different sort of view, one more consistent withcurrent linguistic theory, is required; here, we see the recent work using generativelexicons as providing at least a point of departure.Another goal of this paper is to provide a starting point for the growing numberof researchers working in various areas of computational linguistics who want to learnabout WSD.
There is renewed interest in WSD as it contributes to various applications,such as machine translation and document retrieval.
WSD as "intermediate task,"while interesting in its own right, is difficult and perhaps ultimately impossible toassess in the abstract; incorporation of WSD methods into larger applications willtherefore hopefully inform and enhance future work.Finally, if a lesson is to be learned from a review of the history of WSD, it is thatresearch can be very myopic and, as a result, tends to revisit many of the same issuesover time.
This is especially true when work on a problem has been cross-disciplinary.There is some movement oward more merging of research from various areas, at22 There are several important topics we have not been able to treat except in a cursory way, includinglexical semantic theory, work in psycholinguistics, and statistical methods and results from literary andlinguistic analysis.27Computational Linguistics Volume 24, Number 1least as far as language processing is concerned, spurred by the practical problems ofinformation access that we are facing as a result of rapid technological development.Hopefully, this will contribute to further progress on WSD.ReferencesAarts, Jan. 1990.
Corpus linguistics: Anappraisal.
In Jacqueline Hammesse andAntonio Zampolli, editors, Computers inLiterary and Linguistic Research.
ChampionSlatkine, Paris-Geneve, pages 13-28.Adriaens, Geert.
1986.
Word expert parsing:A natural anguage analysis programrevised and applied to Dutch.
LeuvenscheBijdragen, 75(1):73-154.Adriaens, Geert.
1987.
WEP (word expertparsing) revised and applied to Dutch.
InProceedings ofthe 7th European Conference onArti~'cial Intelligence, ECAI'86,pages 222-235, Brighton, UnitedKingdom, July.
Reprinted in B. DuBoulay, D. Hogg, L. Steels, editors,Advances in Artij~'cial Intelligence II,pages 403-416, Elsevier.Adriaens, Geert.
1989.
The parallel expertparser: A meaning-oriented, lexicallyguided, parallel-interactive model ofnatural anguage understanding.
InProceedings ofthe International Workshop onParsing Technologies, pages 309-319,Carnegie-Mellon University.Adriaens, Geert and Steven L. Small.
1988.Word expert revisited in a cognitivescience perspective.
In Steven Small,Garrison W. Cottrell, and MichaelK.
Tanenhaus, editors, Lexical AmbiguityResolution: Perspectives fromPsycholinguistics, Neuropsychology, andArtiJicial Intelligence.
Morgan Kaufman,San Mateo, CA, pages 13-43.Ahlswede, Thomas E. 1992.
Issues in theDesign of Test Data for LexicalDisambiguation by Humans andMachines.
In Proceedings ofthe FourthMidwest Arti~'cial Intelligence and CognitiveScience Society Conference, pages 112-116,Starved Rock, IL.Ahlswede, Thomas E. 1993.
SenseDisambiguation Strategies for Humansand Machines.
In Proceedings ofthe 9thAnnual Conference on the New OxfordEnglish Dictionary, pages 75-88, Oxford,UK, September.Ahlswede, Thomas E. 1995.
Word SenseDisambiguation by Human Informants.
InProceedings ofthe Sixth Midwest ArtificialIntelligence and Cognitive Society Conference,pages 73-78, Carbondale, IL, April.Ahlswede, Thomas E. and David Lorand.1993.
The Ambiguity Questionnaire: AStudy of Lexical Disambiguation byHuman Informants.
In Proceedings oftheFifth Midwest Artiyqcial Intelligence andCognitive Society Conference, pages 21-25,Chesterton, IN.ALPAC.
1966.
Language and Machine:Computers in Translation and Linguistics.National Research Council AutomaticLanguage Processing AdvisoryCommittee, Washington, DC.Alshawi, Hiyan and David Carter.
1994.Training and scaling preference functionsfor disambiguation.
ComputationalLinguistics, 20(4):635-648.Amsler, Robert A.
1980.
The Structure of theMerriam-Webster Pocket Dictionary.
Ph.
D.thesis, University of Texas at Austin,Austin, TX.Amsler, Robert A. and John S. White.
1979.Development of a computationalmethodology for deriving naturallanguage semantic structures via analysisof machine-readable dictionaries.
Finalreport on NSF project MCS77-01315.University of Texas at Austin, Austin, TX.Anderson, John Robert.
1976.
Language,Memory, and Thought.
Lawrence Erlbaumand Associates, Hillsdale, NJ.Anderson, John Robert.
1983.
A spreadingactivation theory of memory.
Journal ofVerbal Learning and Verbal Behavior,22(3):261-95.Anthony, Edward.
1954.
An exploratoryinquiry into lexical clusters.
AmericanSpeech, 29(3):175-180.Arnold, Doug, Louisa Sadler, and R. LeeHumphreys.
1993.
Evaluation: Anassessment.
Machine Translation,8(1-2):1-24.
Special issue on evaluation ofMT systems.ARPA.
1993.
Proceedings ofthe Fifth MessageUnderstanding Conference, Baltimore, MD,August.
Morgan Kaufmann.Asprejan, Jurij D. 1974.
Regular polysemy.Linguistics, 142:5-32.Atkins, Beryl T. S. 1987.
Semantic ID tags:Corpus evidence for dictionary senses.
InProceedings ofthe Third Annual Conference ofthe UW Center for the New OED,pages 17-36, Waterloo, Canada.Atkins, Beryl T. S. and Beth Levin.
1988.Admitting impediments.
In Proceedings ofthe 4th Annual Conference ofthe UW Centerfor the New OED, Oxford, UK.Ayto, John R. 1983.
On specifying meaning.In R. R. K. Hartmann, editor, Lexicography:28Ide and V4ronis IntroductionPrinciples and Practice.
Academic Press,London, pages 89-98.Bahl, Lalit R. and Robert L. Mercer.
1976.Part of speech assignment by a statisticaldecision algorithm.
In Proceedings oftheIEEE International Symposium onInformation Theory, pages 88-89, Ronneby.Bar-Hillel, Yehoshua.
1960.
AutomaticTranslation of Languages.
In Franz Alt,A.
Donald Booth, and R. E. Meagher,editors, Advances in Computers.
AcademicPress, New York.Barwise, Jon and John R. Perry.
1983.Situations and Attitudes.
MIT Press,Cambridge, MA.Basili, Roberto, Michelangelo Della Rocca,and Maria Tereza Pazienza.
1997.
Towardsa bootstrapping framework for corpussemantic tagging.
In Proceedings oftheACL-SIGLEX Workshop "Tagging Text withLexical Semantics: Why, What, and How?
"pages 66-73, Washington, DC, April.Bel'skaja, Izabella K. 1957.
Machinetranslation of languages.
Research, 10(10).Berry-Rogghe, Godelieve.
1973.
Thecomputation of collocations and theirrelevance to lexical studies.
In AdamJ.
Aitken, Richard W. Bailey, and NeilHamilton-Smith, editors, The Computer andLiterary Studies.
Edinburgh UniversityPress, Edinburgh, UK, pages 103-112.Bimbot, Frederic, GErard Chollet, andA.
Paoloni.
1994.
Assessmentmethodology for speaker identificationand verification systems: An overview ofSAM-A Esprit project 6819-Task 2500.
InProceedings ofthe ESCA Workshop onAutomatic Speaker Recognition Identifi'cationand Verification, pages 75-82.Black, Ezra.
1988.
An experiment incomputational discrimination ofenglishword senses.
IBM Journal ofResearch and Development, 32(2):185-194.Bloomfield, Leonard.
1933.
Language.
Holt,New York.Boas, Franz.
1940.
Race, Language andCulture.
Macmillan, New York.Boguraev, Branimir.
1979.
AutomaticResolution of Linguistic Ambiguities.
Ph.D.thesis, Computer Laboratory, Universityof Cambridge, August.
(Available asTechnical Report 11.
)Bookman, Lawrence A.
1987.
A microfeaturebased scheme for modelling semantics.
InProceedings ofthe lOth International JointConference on ArtiJ~'cial Intelligence, IJCAI'87,pages 611-614, Milan, Italy.Braden-Harder, Lisa.
1993.
Sensedisambiguation using on-line dictionaries.In Karen Jensen, George E. Heidorn, andStephen D. Richardson, editors, NaturalLanguage Processing: The PLNLP Approach.Kluwer Academic Publishers, Dordrecht,pages 247-261.Briscoe, Edward J.
1991.
Lexical issues innatural anguage processing.
InEwan H. Klein and Frank Veltman,editors, Natural Language and Speech.Proceedings ofthe Symposium on NaturalLanguage and Speech, pages 39-68,Springer-Verlag, Berlin.Brown, Gillian and George Yule, 1983.Discourse Analysis.
Cambridge Textbooksin Linguistics Series.
CambridgeUniversity Press, Cambridge, UK.Brown, Peter E, Stephen Della Pietra,Vincent J. Della Pietra, and RobertL.
Mercer.
1991.
Word sensedisambiguation using statistical methods.In Proceedings ofthe 29th Annual Meeting,pages 264-270, Berkeley, CA.
Associationfor Computational Linguistics.Brown, Peter E, Vincent J. Della Pietra,Peter V. deSouza, Jennifer C. Lai, andRobert L. Mercer.
1992.
Class-basedn-gram models of natural anguage.Computational Linguistics, 18(4):467-479.Bruce, Rebecca nd Janyce Wiebe.
1994.Word-sense disambiguation usingdecomposable models.
In Proceedings ofthe32nd Annual Meeting, pages 139-145, LasCruces, NM.
Association forComputational Linguistics.Bryan, Robert M. 1973.
Abstract hesauriand graph theory applications tothesaurus research.
In Sally YeatesSedelow, editor, Automated LanguageAnalysis, 1972-3.
University of KansasPress, Lawrence, KS, pages 45-89.Bryan, Robert M. 1974.
Modelling inthesaurus research.
In Sally YeatesSedelow et al, editor, Automated LanguageAnalysis, 1973-4.
University of KansasPress, Lawrence, KS, pages 44-59.Buitelaar, Paul.
1997.
A lexicon forunderspecified semantic tagging.
InProceedings ofthe ACL-SIGLEX Workshop"Tagging Text with Lexical Semantics: Why,What, and How?
", pages 25-33,Washington, DC, April.Byrd, Roy J., Nicoletta Calzolari, MartinS.
Chodorov, Judith L. Klavans, MaryS.
Neff, and Omneya Rizk.
1987.
Toolsand methods for computationallinguistics.
Computational Linguistics,13(3/4):219-240.Calzolari, Nicoletta.
1984.
Detecting patternsin a lexical data base.
In Proceedings ofthel Oth International Conference onComputational Linguistics, COLING'84,pages 170-173, Stanford University, CA,July.29Computational Linguistics Volume 24, Number 1Chen, Stanley E and Joshua Goodman.1996.
An empirical study of smoothingtechniques for language modeling.
InProceedings ofthe 34th Annual Meeting,pages 310-318, University of California,Santa Cruz, CA, June.Chodorow, Martin S., Roy J. Byrd, andGeorge E. Heidorn.
1985.
Extractingsemantic hierarchies from a large on-linedictionary.
In Proceedings ofthe 23rd AnnualMeeting, pages 299-304, University ofChicago, Chicago, IL.
Association forComputational Linguistics.Chomsky, Noam.
1957.
Syntactic Structures.Mouton, The Hague.Choueka, Yaacov, and F. Dreizin.
1976.Mechanical resolution of lexicalambiguity in a coherent text.
InProceedings ofthe International Conference onComputational Linguistics, COLING'76.Choueka, Yaacov and D. Goldberg.
1979.Mechanical resolution of lexicalambiguity--A combinatorial pproach.
InZvi Malachi, editor, Proceedings oftheInternational Conference on Literary andLinguistic Computing, pages 149-165, TheKatz Research Institute for HebrewLiterature, Tel-Aviv University, Israel,April.Choueka, Yaacov and Serge Lusignan.
1985.Disambiguation by short contexts.Computers and the Humanities, 19:147-158.Church, Kenneth W. and William A. Gale.1991.
A comparison of enhancedGood-Turing and deleted estimationmethods for estimating probabilities ofEnglish bigrams.
Computer, Speech andLanguage, 5:19-54.Church, Kenneth W. and Robert L. Mercer.1993.
Introduction to the special issue oncomputational linguistics using largecorpora.
Computational Linguistics,19(1):1-24.Collins, Allan M. and Elisabeth E Loftus.1975.
A spreading activation theory ofsemantic processing.
Psychological Review,82(6):407-428.Connine, Cynthia.
1990.
Effects of sentencecontext and lexical knowledge in speechprocessing.
In Gerry T. Altmann, editor,Cognitive models in speech processing.
MITPress, Cambridge, MA.Cottrell, Garrison W. and Steven L. Small.1983.
A connectionist cheme formodelling word sense disambiguation.Cognition and Brain Theory, 6:89-120.Cottrell, Garrisson W. 1985.
A ConnectionistApproach to Word-Sense Disambiguation.Ph.D.
thesis.
Department of ComputerScience, University of Rochester.Cowie, Jim, Joe A. Guthrie, and LouiseGuthrie.
1992.
Lexical disambiguationusing simulated annealing.
In Proceedingsof the 14th International Conference onComputational Linguistics, COLING'92,volume 1, pages 359-365, Nantes, France,August.Cruse, D. A.
1986.
Lexical Semantics.Cambridge University Press, Cambridge,UK.Dagan, Ido and Alon Itai.
1994.
Word sensedisambiguation using a second languagemonolingual corpus.
ComputationalLinguistics, 20(4):563-596.Dagan, Ido, Alon Itai, and Ulrike Schwall.1991.
Two languages are moreinformative than one.
In Proceedings ofthe29th Annual Meeting, pages 130-137,Berkeley, CA.
Association forComputational Linguistics.Dagan, Ido, Shaul Marcus, and ShaulMarkovitch.
1993.
Contextual wordsimilarity and estimation from sparsedata.
In Proceedings ofthe 31st AnnualMeeting, Columbus, OH, June.
Associationfor Computational Linguistics.Dagan, Ido, Fernando Peireira, and LilianLee.
1994.
Similarity-based stimation ofword cooccurrence probabilities.
InProceedings ofthe 32nd Annual Meeting,pages 272-278, Las Cruces, NM.Association for ComputationalLinguistics.Dahlgren, Kathleen G. 1988.
Naive Semanticsfor Natural Language Understanding.Kluwer Academic Publishers, Boston.Debili, Fathi.
1977.
Traitements syntaxiquesutilisant des matrices de prdcddencefrdquentielles construites automatiquement parapprentissage.
Th~se de Docteur-Ing4nieur,Universit4 de Paris VII, U.E.R.
dePhysique.De Groot, Annette M. B.
1983.
The range ofautomatic spreading activation in wordpriming.
Journal of Verbal learning andVerbal Behavior, 22(4):417-436.Dolan, William B.
1994.
Word senseambiguation: Clustering related senses.
InProceedings ofthe 15th InternationalConference on Computational Linguistics,COLING'94, pages 712-716, Kyoto, Japan,August.Dostert, Leon E. 1955.
TheGeorgetown-I.B.M.
experiment.
InWilliam N. Locke and A. Donald Booth,editors, Machine Translation of Languages.John Wiley & Sons, New York,pages 124-135.Earl, Lois L. 1973.
Use of word governmentin resolving syntactic and semanticambiguities.
Information Storage andRetrieval, 9:639-664.30Ide and V~ronis IntroductionEaton, Helen S. 1940.
Semantic Frequency Listfor English, French, German and Spanish.Chicago University Press, Chicago.Engelson, Sean P. and Ido Dagan.
1996.Minimizing manual annotation cost insupervised training from corpora.
InProceedings ofthe 34th Annual Meeting,pages 319-326, University of California,Santa Cruz, CA.
Association forComputational Linguistics.Estoup, Jean-Baptiste.
1902.
Gammesst~nographiques.
Paris.Feldman, Jerome A. and Dana H. Ballard.1982.
Connectionist models and theirproperties.
Cognitive Science, 6(3):205-254.Fellbaum, Christiane, editor.
Forthcoming-a.WordNet: An Electronic Lexical Database.MIT Press, Cambridge, MA.Fellbaum, Christiane.
Forthcoming-b.
Theorganization of verbs and verb conceptsin a semantic net.
In Patrick Saint-Dizier,editor, Predicative Forms in NaturalLanguage and Lexical Knowledge Bases.
Text,Speech and Language Technology Series.Kluwer Academic Publishers, Dordrecht.Fillmore, Charles J. and Beryl T. S. Atkins.1991.
Invited lecture.
Presented at the29th Annual Meeting of the Associationfor Computational Linguistics, Berkeley,CA, June.Firth, J. R. 1951.
Modes of meaning.
Papersin Linguistics 1934-51, pages 190-215,Oxford University Press, Oxford, UK.Fischler, Ira.
1977.
Semantic facilitationwithout association i  a lexical decisiontask.
Memory and Cognition, 5(3):335-339.Fontenelle, Thierry.
1990.
Automaticextraction of lexical-semantic relationsfrom dictionary definitions.
In Proceedingsof the 4th International Congress onLexicography, EURALEX'90, pages 89-103,Benalm~dena, Spain.Fries, Charles.
1952.
The Structure of English:An Introduction to the Construction ofSentences.
Harcourt & Brace, New York.Fries, Charles and Aileen Traver.
1940.English Word Lists: A Study of theirAdaptability and Instruction.
AmericanCouncil of Education, Washington, DC.Gale, William A., Kenneth W. Church, andDavid Yarowsky.
1992a.
Using bilingualmaterials to develop word sensedisambiguation methods.
In Proceedings ofthe International Conference on Theoreticaland Methodological Issues in MachineTranslation, pages 101-112.Gale, William A., Kenneth W. Church, andDavid Yarowsky.
1992b.
Estimating upperand lower bounds on the performance ofword-sense disambiguation programs.
InProceedings ofthe 30th Annual Meeting,pages 249-256, University of Delaware,Newark, DE, July.
Association forComputational Linguistics.Gale, William A., Kenneth W. Church, andDavid Yarowsky.
1992c.
One sense perdiscourse.
In Proceedings ofthe Speech andNatural Language Workshop, ages 233-237,San Francisco, Morgan Kaufmann.Gale, William A., Kenneth W. Church, andDavid Yarowsky.
1992d.
Work onstatistical methods for word sensedisambiguation.
I  Probabilistic Approachesto Natural Language: Papers from the 1992AAAI Fall Symposium, pages 54--60,Cambridge, MA, October.Gale, William A., Kenneth W. Church, andDavid Yarowsky.
1993.
A method fordisambiguating word senses in a largecorpus.
Computers and the Humanities,26:415-439.Gentilhomme, Yves and Ren4 Tabory.
1960.Le probl@me des vraies polys~mies etlam4thode du param~tre conceptuel.
LaTraduction Automatique, 1(1):9-14.Good, Irwin J.
1953.
The populationfrequencies of species and the distributionof population parameters.
Biometrika,40(3/4):237-264.Gougenheim, Georges and Rend Mich~a.1961.
Sur la d~termination du sens d'unmot au moyen du contexte.
La TraductionAutomatique, 2(1):16-17.Gougenheim, Georges, Ren~ Mich~a, PaulRivenc, and Aur~lien Sauvageot.
1956.L'daboration du ffran~ais ~l~mentaire.
Didier,Paris.Gould, R. 1957.
Multiple correspondence.Mechanical Translation, 4(1/2):14-27.Granger, Richard.
1977.
FOUL-UP: Aprogram that figures out meanings ofwords from context.
In Proceedings oftheInternational Joint Conference on ArtiJ~'cialIntelligence, IJCAI'77, pages 172-178.Grishman, Ralph, Catherine MacLeod, andAdam Meyers.
1994.
COMLEX syntax:Building a computational lexicon.
InProceedings ofthe 15th InternationalConference on Computational Linguistics,COLING'94, pages 268-272, Kyoto, Japan,August.Grishman, Ralph and John Sterling.
1993.Smoothing of automatically generatedselectional constraints.
In Human LanguageTechnology.
Morgan Kaufmann,pages 254-259.Guthrie, Joe A., Louise Guthrie, YorickWilks, and Homa Aidinejad.
1991.Subject-dependent co-occurrence andword sense disambiguation.
I  Proceedingsof the 29th Annual Meeting, pages 146-152,Berkeley, CA, June.
Association for31Computational Linguistics Volume 24, Number 1Computational Linguistics.Haas, W. 1966.
Linguistic relevance.
InC. E. Bazell et al, editors, In Memory ofJ.
R. Firth.
Longman, London,pages 116-148.Halliday, M. A. K. 1961.
Categories of thetheory of grammar.
Word, 17:241-292.Halliday, M. A. K. 1966.
Lexis as a linguisticlevel.
In C. E. Bazell et al, editors, InMemory of J. R. Firth.
Longman, London,pages 148-163.Harman, Donna, editor.
1993.
NationalInstitute of Standards and TechnologySpecial Publication No.
500-207 on theFirst Text Retrieval Conference (TREC-1),Washington, DC.
National Institute ofStandards and Technology, U.S.Department of Commerce, U.S.Government Printing Office.Harman, Donna, editor.
1995.
InformationProcessing and Managemen t, 31(3).
SpecialIssue on The Second Text RetrievalConference (TREC-2).Harper, Kenneth E. 1957a.
Semanticambiguity.
Mechanical Translation,4(3):68-69.Harper, Kenneth E. 1957b.
Contextualanalysis.
Mechanical Translation, 4(3):70-75.Harris, Zellig S. 1951.
Methods in StructuralLinguistics.
The University of ChicagoPress, Chicago.Harris, Zellig S. 1954.
Distributionalstructure.
Word, 10:146-162.Hayes, Philip J.
1976.
A process toimplement some word-sensedisambiguation.
Working paper 23.Institut pour les Etudes S~mantiques tCognitives, Universit~ de Gen~ve.Hayes, Philip J.
1977a.
On semantic nets,frames and associations.
In Proceedings ofthe 5th International Joint Conference onArti~'cial Intelligence, pages 99-107,Cambridge, MA.Hayes, Philip J.
1977b.
Some Association-basedTechniques for Lexical Disambiguation byMachine.
Doctoral dissertation,D4partement de Math4matiques, EcolePolytechnique F4d4rale de Lausanne.Hayes, Philip J.
1978.
Mapping input intoschemas.
Technical Report 29, Departmentof Computer Science, University ofRochester.Hearst, Marti A.
1991.
Noun homographdisambiguation using local context inlarge corpora.
In Proceedings ofthe SeventhAnnual Conference ofthe Centre for the NewOED and Text Research: Using Corpora,pages 1-22, Oxford, UK.Hearst, Marti.
A.
1994.
Multiparagraphsegmentation f expository text.
InProceedings ofthe 32nd Annual Meeting,pages 9-16, Las Cruces, NM.
Associationfor Computational Linguistics.Hebb, Donald O.
1949.
The Organisation ofBehavior: A Neuropsychological Approach.John Wiley & Sons, New York.Hindle, Donald and Mats Rooth.
1993.Structural Ambiguity and lexical relations.Computational Linguistics, 19(1):103-120.Hirschman, Lynette and Henry S. Thomson.1996.
Overview of evaluation in speechand natural anguage processing.
InRonald A. Cole, editor, Survey of theState of the Art in Human LanguageTechnology.
Section 13.1.
URL: http://www.cse.ogi.edu/CSLU/HLTsurvey/Hirst, Graeme.
1987.
Semantic Interpretationand the Resolution of Ambiguity.
Studies inNatural Language Processing.
CambridgeUniversity Press, Cambridge, UK.Hjemslev, Louis.
1953.
Prolegomena to aTheory of Language.
Translated fromDanish.
Indiana University, Bloomington,IN.Hobbs, Jerry R. 1987.
World knowledge andword meaning.
In Proceedings ofthe ThirdWorkshop on Theoretical Issues in NaturalLanguage Processing, TINLAP-3, pages20-25, Las Cruces, NM.Ide, Nancy and Jean V~ronis.
1990a.
Verylarge neural networks for word sensedisambiguation.
In Proceedings ofthe 9thEuropean Conference on Artiyqcial Intelligence,ECAI'90, pages 366-368, Stockholm.Ide, Nancy and Jean V4ronis.
1990b.Mapping dictionaries: A spreadingactivation approach.
In Proceedings oftheSixth Annual Conference ofthe UW Centre forthe New Oxford English Dictionary, pages52-64, Waterloo, Canada.Ide, Nancy and Jean V~ronis.
1993a.Refining taxonomies extracted frommachine-readable dictionaries.
In SusanHockey and Nancy Ide, editor, Research inHumanities Computing II.
OxfordUniversity Press, pages 145-159.Ide, Nancy and Jean V~ronis.
1993b.Knowledge xtraction frommachine-readable dictionaries:An evaluation.
Presented at the ThirdInternational EAMT Workshop "MachineTranslation and the Lexicon," Heidelberg,Germany, April.
In Machine Translation andthe Lexicon.
See Steffens 1995.Ide, Nancy and Donald Walker.
1992.Common methodologies in humanitiescomputing and computational linguistics.Computers and the Humanities,26(5/6):327-331.Iker, H. P. 1974.
SELECT: A computerprogram to identify associationally richwords for content analysis.
I. Statistical32Ide and V~ronis Introductionresults.
Computers and the Humanities,8:313-319.Iker, H. P. 1975.
SELECT: A computerprogram to identify associationally richwords for content analysis.
II.
Substantiveresults.
Computers and the Humanities,9:3-12.Imbs, Paul.
1971.
Trdsor de la LangueFran?aise.
Dictionnaire de la langue du XIX~et du XXb si~cles (1989-1960).
Editions duCentre National de la RechercheScientifique, Paris.Janssen, Sylvia.
1992.
Tracing cohesiverelations in corpora samples usingdictionary data.
In Gerhard Leitner,editor, New Directions in English LanguageCorpora, Mouton de Gruyter, Berlin.Jelinek, Frederick.
1976.
Continuous peechrecognition by statistical methods.
IEEE,64(4):532-556.Jelinek, Frederick and Robert L. Mercer.1985.
Probability distribution estimationfrom sparse data.
IBM Technical DisclosureBulletin, 28:2591-2594.Jensen, Karen and Jean-Louis Binot.
1987.Disambiguating prepositional phraseattachments by using on-line dictionarydefinitions.
Computational Linguistics,13(3/4):251-260.Johansson, Stig.
1980.
The LOB corpus ofBritish English texts: Presentation andcomments.
ALLC Journal, 1(1):25-36.Jorgensen, Julia.
1990.
The psychologicalreality of word senses.
Journal ofPsycholinguistic Research, 19:167-190.Kaeding, E W. 1897-1898.Hdufigkeitsw~rterbuch der deutschen Sprache.Festgestellt durch Arbeitsausschliss derdeutschen Stenographie-System.Selbstverlag, Steglitz bei Berlin.Kaplan, Abraham.
1950.
An experimentalstudy of ambiguity and context.Mimeographed.
(Published 1955 inMechanical Translation, 2(2):39-46.
)Kawamoto, Alan H. 1988.
Distributedrepresentations of ambiguous words andtheir resolution in a connectionistnetwork.
In Steven Small, Garrison W.Cottrell, and Michael K. Tanenhaus,editors, Lexical Ambiguity Resolution:Perspectives from Psycholinguistics,Neuropsychology, and Artificial Intelligence.Morgan Kaufman, San Mateo, CA, pages195-228.Kelly, Edward F. and Philip J.
Stone.
1975.Computer Recognition of English WordSenses.
North-Holland, Amsterdam.Kilgarriff, Adam.
1992.
Polysemy.
Ph.D.thesis.
University of Sussex, UK.Kilgarriff, Adam.
1993.
Dictionary wordsense distinctions: An enquiry into theirnature.
Computers and the Humanities,26:365-387.Kilgarriff, Adam.
1994.
The myth ofcompleteness and some problems withconsistency (the role of frequency indeciding what goes in the dictionary).
InProceedings ofthe 6th International Congresson Lexicography, EURALEX'94, pages101-106, Amsterdam, Holland.Kilgarriff, Adam.
1997.
Evaluation of wordsense disambiguation programs.
SALTClub Workshop "Evaluation in Speech andLanguage Technology," Sheffield University,Sheffield, UK, June.Kilgarriff, Adam.
Forthcoming.
I don'tbelieve in word senses.
Computers and theHumanities.Kintsch, Walter and Ernest E Mross.
1985.Context effects in word identification.Journal of Memory and Language,24(3):336-349.Klavans, Judith, Martin Chodorow, andNina Wacholder.
1990.
From dictionary toknowledge base via taxonomy.
InProceedings ofthe 6th Conference ofthe UWCentre for the New OED, pages 110-132,Waterloo, Canada.Koutsoudas, Andreas K. and R. Korfhage.1956.
M.T.
and the problem of multiplemeaning.
Mechanical Translation,2(2):46-51.Krovetz, Robert and William Bruce Croft.1989.
Word sense disambiguation usingmachine-readable dictionaries.
InProceedings ofthe 12th Aanual InternationalACM-SIGIR Conference on Research andDevelopment in Information Retrieval,SIGIR'89, pages 127-136, Cambridge, MA.Krovetz, Robert and William Bruce Croft.1992.
Lexical Ambiguity and InformationRetrieval.
ACM Transactions on InformationSystems, 10(2):115-141.Kucera, Henri and Winthrop N. Francis.1967.
Computational Analysis of Present-DayAmerican English, Brown University Press,Providence.Leacock, Claudia, Geoffrey Towell, andEllen Voorhees.
1993.
Corpus-basedstatistical sense resolution.
In Proceedingsof the ARPA Human Language TechnologyWorkshop, San Francisco, MorganKaufman.Leacock, Claudia, Geoffrey Towell, andEllen M. Voorhees.
1996.
Towardsbuilding contextual representations ofword senses using statistical models.
InBranimir Boguraev and JamesPustejovsk~ editors, Corpus Processing forLexical Acquisition.
MIT Press, Cambridge,MA, pages 97-113.Leech, Geoffrey.
1991.
The state of the art in33Computational Linguistics Volume 24, Number 1corpus linguistics.
In K. Aijmer andB.
Altenberg, editors, English CorpusLinguistics.
Longman, London, pages 8-29.Lehman, Jill Fain.
1994.
Toward the essentialnature of statistical knowledge in senseresolution.
In Proceedings ofthe 12 thInternational Conference on ArtiJicialIntelligence, AAAI'94, pages 734-741,Seattle, Washington, July/August.Lenat, Douglas B. and Ramanathan V.Guha.
1990.
Building Large Knowledge-basedSystems.
Addison-Wesley, Reading, MA.Lesk, Michael.
1986.
Automated sensedisambiguation using machine-readabledictionaries: How to tell a pine cone froman ice cream cone.
In Proceedings ofthe1986 SIGDOC Conference, pages 24-26,Toronto, Canada, June.Liddy, Elisabeth D. and Woojin Paik.
1993.Statistically-guided word sensedisambiguation.
I  Proceedings ofthe AAAIFall Symposium Series, pages 98-107.Litowski, Kenneth C. 1997.
Desiderata fortagging with WordNet sysnsets or MCAAcategories.
In Proceedings oftheACL-SIGLEX Workshop "Tagging Text withLexical Semantics: Why, What, and How?
"pages 12-17, Washington, DC, April.Lorge, Irving.
1949.
Semantic Content of the570 Commonest English Words.
ColumbiaUniversity Press, New York.Luk, Alpha K. 1995.
Statistical sensedisambiguation with relatively smallcorpora using dictionary definitions.
InProceedings ofthe 33rd Annual Meeting,pages 181-188.
Cambridge, MA.Association for ComputationalLinguistics.Lupker, Stephen J.
1984.
Semantic primingwithout association: A second look.Journal of Verbal Learning and VerbalBehavior, 23(6):709-733.Lyons, John.
1966.
Firth's theory ofmeaning.
In C. E. Bazell et al, editors, InMemory of J. R. Firth.
Longman, London,pages 288-302.Lyons, John.
1977.
Semantics.
CambridgeUniversity Press, Cambridge, UK.Macleod, Catherine, Ralph Grishman, andAdam Meyers.
Forthcoming.
A largesyntactic dictionary for natural anguageprocessing.
Computers and the Humanities.Madhu, Swaminathan and Dean W. Lytle.1965.
A figure of merit technique for theresolution of non-grammatical ambiguity.Mechanical translation, 8(2):9-13.Mahesh, Kavi, Sergei Nirenburg, andStephen Beale.
1997.
If you have it, flauntit: Using full ontological knowledge forword sense disambiguation.
I  Proceedingsof the 7th International Conference onTheoretical nd Methodological Issues inMachine Translation, pages 1-9, Sante Fe,NM, July.Mahesh, Kavi, Sergei Nirenburg, StephenBeale, Evelyne Viegas, Victor Raskin, andBoyan Onyshkevych.
1997.
Word SenseDisambiguation: Why statistics when wehave these numbers?
In Proceedings ofthe7th International Conference on Theoreticaland Methodological Issues in MachineTranslation, pages 151-159, Santa Fe, NM,July.Malakhovski, L. V. 1987.
Homonyms inEnglish dictionaries.
In R. W. Burchfield,editor, Studies in Lexicography.
OxfordUniversity Press, Oxford, UK, pages36-51.Markowitz, Judith, Thomas Ahlswede, andMartha Evens.
1986.
Semanticallysignificant patterns in dictionarydefinitions.
In Proceedings ofthe 24thAnnual Meeting, pages 112-119,Association for ComputationalLinguistics.Martinet, AndrE.
1960.
ElEments delinguistique g~n4rale.
Armand Colin,Paris.Masterman, Margaret.
1957.
The thesaurusin syntax and semantics.
MechanicalTranslation, 4:1-2.Masterman, Margaret.
1962.
Semanticmessage detection for machinetranslation, using an interlingua.
In 1961International Conference on MachineTranslation of Languages and AppliedLanguage Analysis.
Her Majesty'sStationery Office, London, pages 437-475.McClelland, James L. and David E.Rumelhart.
1981.
An interactive activationof context effects in letter perception:Part 1.
An account of basic findings.Psychological Review, 88:375-407.McCulloch, Warren S. and Walter Pitts.1943.
A logical calculus of the ideasimminent in nervous activity.
Bulletin ofMathematical Biophysics, 5:115-133.McIntosh, A.
1966.
Patterns and ranges.
InPapers in General, Descriptive, and AppliedLinguistics.
Longman, London, pages183-199.McRoy, Susan W. 1992.
Using multipleknowledge sources for word sensediscrimination.
Computational Linguistics,18(1):1-30.Meillet, Antoine.
1926.
Linguistique historiqueet linguistique g~ndrale.
Volume 1.
Secondedition.
Champion, Paris.M4rialdo, Bernard.
1994.
Tagging text with aprobabilistic model.
ComputationalLinguistics, 20(2):155-172.Meyer, David E. and Roger W.34Ide and V4ronis IntroductionSchvaneveldt.
1971.
Facilitation inrecognizing pairs of words: Evidence of adependence between retrieval operations.Journal of Experimental Psychology,90(2):227-234.Mich~a, Ren~.
1964.
Les vocabulairesfondamentaux.
Recherche ettechniquesnouvelles au service de l'enseignement deslangues vivantes, Universit4 de Strasbourg,Strasbourg, 21-36.Michiels, Archibald, Jacques Mullenders,and Jacques Noel.
1980.
Exploiting a largedatabase by Longman.
In Proceedings ofthe8th International Conference onComputational Linguistics, COLING'80,pages 374-382, Tokyo, Japan.Michiels, Archibald.
1982.
Exploiting aLargeDictionary Data Base.
Ph.D. thesis,Universit4 de Liege, Liege, Belgium.Miller, George A., Richard T. Beckwith,Christiane D. Fellbaum, Derek Gross, andKatherine J. Miller.
1990.
WordNet: Anon-line lexical database.
InternationalJournal of Lexicography, 3(4):235-244.Miller, George A., Martin Chodorow, ShariLandes, Claudia Leacock, and Robert G.Thomas.
1994.
Using a semanticconcordance for sense identification.
InProceedings ofthe ARPA Workshop on HumanLanguage Technology, pages 240-243,Plainsboro, NJ.Miller, George A., Claudia Leacock, RandeeTengi, and Ross Bunker.
1993.
A semanticconcordance.
In Proceedings ofthe 3rdDARPA Workshop on Human LanguageTechnology, pages 303-308, Plainsboro, NJ,March.Miller, George A. and Walter G. Charles.1991.
Contextual correlates of semanticsimilarity.
Language and Cognitive Processes,6(1):1-28.Morris, Jane.
1988.
Lexical cohesion, thethesaurus, and the structure of text.Technical Report CSRI 219, ComputerSystems Research Institute, University ofToronto, Toronto, Canada.Morris, Jane and Graeme Hirst.
1991.Lexical cohesion computed by thesauralrelations as an indicator of the structure oftext.
Computational Linguistics, 17(1):21-48.Nakamura, Jun-Ichi and Makoto Nagao.1988.
Extraction of semantic informationfrom an ordinary English dictionary andits evaluation.
In Proceedings ofthe 12thInternational Conference on ComputationalLinguistics, COLING'88, pages 459-464,Budapest, Hungary, August.Ng, Hwee Tou and Hian Beng Lee.
1996.Integrating multiple knowledge sourcesto disambiguate word sense:An examplar-based approach.
InProceedings ofthe 34th Annual Meeting,University of California, Santa Cruz, CA,June.
Association for ComputationalLinguistics.Niwa, Yoshiki and Yoshihiko Nitta.
1994.Coocurrence vectors from corpora vsdistance vectors from dictionaries.
InProceedings ofthe 15th InternationalConference on Computational Linguistics,COLING'94, pages 304-309, Kyoto, Japan,August.Oettinger, Anthony G. 1955.
The design ofan automatic Russian-English technicaldictionary.
In William N. Locke andA.
Donald Booth, editors, MachineTranslation of Languages.
John Wiley &Sons, New York, pages 47-65.Olney, John C. 1968.
To all interested in theMerriam-Webster transcripts and dataderived from them.
Technical ReportL-13579, System DevelopmentCorporation, Santa Monica, CA, October.Oswald, Victor A. Jr. 1952.
Microsemantics.Presented at the first M.I.T.
conference onMechanical Translation, 17-20 June 1952.Mimeographed.
(Available on microfilmat M.I.T., Papers on MechanicalTranslation, roll 799.
)Oswald, Victor A. Jr. 1957.
The rationale ofthe idioglossary technique.
In Leon E.Dostert, editor, Research inMachineTranslation.
Georgetown University Press,Washington, DC, pages 63-69.Oswald, Victor A. Jr. and Richard H.Lawson.
1953.
An idioglossary formechanical translation.
Modern LanguageForum, 38(3/4):1-11.Palmer, H. 1933.
Second Interim Report onEnglish Collocations.
Institute for Researchin English Teaching, Tokyo.Panov, D. 1960.
La traduction m4canique tl'humanit~.
Impact, 10(1):17-25.Parker-Rhodes, Arthur F. 1958.
The use ofstatistics in language research.
MechanicalTranslation, 5(2):67-73.Patrick, Archibald B.
1985.
An Exploration ofAbstract Thesaurus Instantiation.
M. Sc.thesis, University of Kansas, Lawrence,KS.Pendergraft, Eugene.
1967.
Translatinglanguages.
In Harold Borko, editor,Automated Language Processing.
John Wiley& Sons, New York.Pereira, Fernando and Naftali Tishby.
1992.Distributional similarity, phase transitionsand hierarchical clustering.
Working Notesof the AAAI Symposium on ProbabilisticApproaches toNatural Language, pages108-112, Cambridge, MA, October.Pereira, Fernando, Naftali Tishby, and LilianLee.
1993.
Distributional clustering of35Computational Linguistics Volume 24, Number 1English.
In Proceeedings of the 31st AnnualMeeting, pages 183-190, Ohio StateUniversity, Colombus, OH, June.Association for ComputationalLinguistics.Pimsleur, P. 1957.
Semantic frequencycounts.
Mechanical Translation,4(1-2):11-13.Pustejovsky, James.
1995.
The GenerativeLexicon.
MIT Press, Cambridge, MA.Pustejovsky, James, Branimir Boguraev, andMichael Johnston.
1995.
A core lexicalengine: The contextual determination ofword sense.
Technical Report, Departmentof Computer Science, Brandeis University.Quillian, M. Ross.
1961.
A design for anunderstanding machine.
Presented at theSemantic Problems in Natural Languagecolloquium, King's College, CambridgeUniversity, Cambridge, UK, September.Quillian, M. Ross.
1962a.
A revised designfor an understanding machine.
MechanicalTranslation, 7(1):17-29.Quillian, M. Ross.
1962b.
A semantic odingtechnique for mechanical Englishparaphrasing.
Internal memorandum ofthe Mechanical Translation Group,Research Laboratory of Electronics, MIT,August.Quillian, M. Ross.
1967.
Word concepts: Atheory and simulation of some basicsemantic apabilities.
Behavioral Science,12:410-430.Quillian, M. Ross.
1968.
Semantic memory.In M. Minsky, editor, Semantic InformationProcessing.
MIT Press, Cambridge, MA,pages 227-270.Quillian, M. Ross.
1969.
The teachablelanguage comprehender: A simulationprogram and theory of language.Communications of the ACM, 12(8):459-476.Quine, Willard V. 1960.
Word and Object.
MITPress, Cambridge, MA.Quirk, Randolph.
1960.
Towards adescription of English usage.
Transactionsof the Philological Society, pages 40-61.Rayner, Keith and R. K. Morris.
1991.Comprehension processes in readingambiguous entences: Reflections fromeye movements.
In G. Simpson, editor,Understanding Word and Sentence.North-Holland, Amsterdam.
pages175-198.Reifler, Erwin.
1955.
The mechanicaldetermination of meaning.
In William N.Locke and A. Donald Booth, editors,Machine Translation of Languages.
JohnWiley & Sons, New York, pages 136-164.Resnik, Philip.
1992.
WordNet anddistributional nalysis: A class-basedapproach to statistical discovery.
InProceedings ofthe AAAI Workshop onStatistically-based Natural LanguageProcessing Techniques, pages 48-56.
SanJose, CA.Resnik, Philip.
1993a.
Selection andInformation: A Class-based Approach toLexical Relationships.
Ph.D. thesis,University of Pennsylvania.
AlsoUniversity of Pennsylvania TechnicalReport 93-42.Resnik, Philip.
1993b.
Semantic lasses andsyntactic ambiguity.
In Proceedings oftheARPA Workshop on Human LanguageTechnology, pages 278-283.Resnik, Philip.
1995a.
Disambiguating noungroupings with respect o WordNetsenses.
In Proceedings ofthe Third Workshopon Very Large Corpora, pages 54-68,Cambridge, MA.Resnik, Philip.
1995b.
Using informationcontent o evaluate semantic similarity ina taxonomy.
In Proceedings ofthe 14thInternational Joint Conference on ArtificialIntelligence, IJCAI'95, pages 448-453,Montreal, Canada.?
Resnik, Philip and David Yarowsky.
1997a.Evaluating automatic semantic taggers.
InProceedings ofthe ACL-SIGLEX Workshop"Tagging Text with Lexical Semantics: Why,What, and How?
', page 91, Washington,DC, April.Resnik, Philip and David Yarowsky.
1997b.A perspective on word sensedisambiguation methods and theirevaluation.
In Proceedings oftheACL-SIGLEX Workshop "Tagging Text withLexical Semantics: Why, What, and How?
",pages 79-86, Washington, DC, April.Richards, I.
A.
1953.
Towards a theory oftranslation.
In Studies in Chinese Thought,University of Chicago Press, Chicago.Richardson, Ray and Alan F. Smeaton.
1994.Automatic word sense disambiguation ia KBIR application.
Working paperCA-0595, School of ComputerApplications, Dublin City University,Dublin, Ireland.Richens, Richard H. 1958.
Interlingualmachine translation.
Computer Journal,1(3):144-147.Richmond, Korin, Andrew Smith, and EinatAmitay.
1997.
Detecting SubjectBoundaries Within Text: A LanguageIndependent S atistical Approach.
InProceedings ofthe Second Conference onEmpirical Methods in Natural LanguageProcessing, EMNLP-2, pages 47-54, BrownUniversity, Providence, RI, August.Roberts, D. D. 1973.
The Existential Graphs ofCharles S. Pierce, Mouton, The Hague.Robins, R. H. 1987.
Polysemy and the36Ide and V~ronis Introductionlexicographer.
In R. W. Burchfield, editor,Studies in Lexicography.
Oxford UniversityPress, Oxford, UK, pages 52-75.Rosenblatt, Frank.
1958.
The perceptron: Aprobabilistic model for informationstorage and organization i  the brain.Psychological Review, 65:386-408.Salton, Gerard.
1968.
Automatic InformationOrganization and Retrieval.
McGraw-Hill,New York.Salton, Gerard and M. McGill.
1983.Introduction to Modern Information Retrieval.McGraw-Hill, New York.Salton, Gerard, A. Wong, and C. S. Yang.1975.
A vector space for informationretrieval.
Communications of the ACM,18(11):613-620.Sanderson, Mark.
1994.
Word sensedisambiguation a d information retrieval.In W. Bruce Croft and C. J. vanRijsbergen, editors, Proceedings ofthe 17thAnnual International ACM/SIGIR Conferenceon Research and Development i  InformationRetrieval, pages 161-175, Las Vegas.Schank, Roger C. and Robert P. Abelson.1977.
Scripts, Plans, Goals andUnderstanding.
Lawrence Erlbaum,Hillsdale, NJ.Schmidt, Klaus M. 1988.
Der Beitrag derbegriffsorientierten Lexicographie zuesystematischen Erfassung vonSprachwandel und das BegriffwOrterbuchzur wdh.
Epik.
In W. Bachofer, editor,Mittelhochdeutches W6rterbuch inderDiskussion.
Max Niemeyer, Tubingen,pages 25-49.Schmidt, Klaus M. 1991.
Eindatabanksystem f~ir dasBegriffw6rterbuch MittelhochdeutcherEpik und Fortschritte bie derautomatischen Disambiguierung.
InK.
G~rtner, P. Sappler, and M. Trauth,editors, Maschinelle Verarbeitungaltdeutscher Text IV.
Max Niemeyer,Tubingen, pages 192-204.Schfitze, Hinrich.
1992.
Dimensions ofmeaning.
In Proceedings ofSupercomputing'92, pages 787-796.
LosAlamitos, CA.Schfitze, Hinrich.
1993.
Word space.
InStephen J. Hanson, Jack D. Cowan, andC.
Lee Giles, editors, Advances in NeuralInformation Processing Systems 5.MorganKauffman, San Mateo, CA, pages 895-902.Sch~itze, Hinrich and Jan Pedersen.
1995.Information retrieval based on wordsenses.
In Proceedings ofSDAIR'95, LasVegas, Nevada, April.Sedelow, Sally Yeates and Donna WeirMooney.
1988.
Knowledge retrieval fromdomain-transcendent xpert systems:II.
Research results.
In Proceedings oftheAmerican Society for Information Science(ASIS) Annual Meeting, pages 209-212,Knowledge Industry Publications, WhitePlains, New York.Sedelow, Sally Yeates and Walter.
A.Sedelow Jr. 1969.
Categories andprocedures for content analysis in thehumanities.
In George Gerbner, OleHolsti, Klaus Krippendorf, William J.Paisley, and Philip J.
Stone, editors, TheAnalysis of Communication Content.
JohnWiley & Sons, New York, pages 487--499.Sedelow, Sally Yeates and Walter.
A.Sedelow Jr. 1986.
Thesaural knowledgerepresentation.
I  Proceedings oftheUniversity of Waterloo Conference onLexicology, pages 29--43, Waterloo, Canada.Sedelow, Sally Yeates and Waiter.
A.Sedelow Jr. 1992.
Recent model-based andmodel-related studies of a large-scalelexical resource (Roget's Thesaurus.
InProceedings ofthe 14th InternationalConference on Computational Linguistics,COLING'92, pages 1223-1227, Nantes,France, August.Seidenberg, Mark S., Michael K. Tanenhaus,James M. Leiman, and Marie A.Bienkowski.
1982.
Automatic access of themeaning of ambiguous words in context:Some limitations of knowledge-basedprocessing.
Cognitive Psychology,14(4):489-537.Selz, O.
1913.
Uber die Gesetze des GeornetenDenkberlaufs, Spemman, Stuttgart.Selz, O.
1922.
Zue Psychologie des produktiveDenkens un des Irrtums, Friedrich Cohen,Bonn.Seneff, Stephanie.
1992.
TINA, A naturallanguage system for spoken languageapplications.
Computational Linguistics,18(1):61-86.Simpson, Greg B. and Curt Burgess.
1989.Implications of lexical ambiguityresolution for word recognition andcomprehension.
I  Steven Small, GarrisonW.
Cottrell, and Michael K. Tanenhaus,editors, Lexical Ambiguity Resolution:Perspectives from Psycholinguistics,Neuropsychology, and Arti~'cial Intelligence.Morgan Kaufman, San Mateo, CA, pages271-288.Sinclair, John.
1966.
Beginning the study oflexis.
In C. E. Bazell et al, editors, InMemory of J. R. Firth.
Longman, London,pages 410-431.Sinclair, John, editor.
1987.
Looking Up: AnAccount of the COBUILD Project in LexicalComputing.
Collins, London.Skorochod'ko, E. F. 1972.
Adaptativemethods of automatic abstracting and37Computational Linguistics Volume 24, Number 1indexing.
In C. V. Freiman, editor,Information Processing 71: Proceedings oftheIFIP Congress 71, pages 1179-1182, NorthHolland Publishing Company.Slator, Brian M. 1992.
Sense and preference.Computer and Mathematics with Applications,23(6/9):391-402.Slator, Brian M. and Yorick A. Wilks.
1987.Towards emantic structures fromdictionary entries.
In Proceedings ofthe 2ndAnnual Rocky Mountain Conference onArtificial Intelligence, pages 85-96, Boulder,CO.Small, Steven L. 1980.
Word Expert Parsing:A Theory of Distributed Word-based NaturalLanguage Understanding.
Ph.D. thesis,Department of Computer Science,University of Maryland, September.Available as Technical Report 954.Small, Steven L. 1983.
Parsing ascooperative distributed inference.
InMargaret King, editor, Parsing NaturalLanguage.
Academic Press, London.Small, Steven L., Garrison W. Cottrell, andMichael K. Tanenhaus, editors.
1988.Lexical Ambiguity Resolution: Perspectivesfrom Psycholinguistics, Neuropsychology, andArtiJicial Intelligence.
Morgan Kaufman,San Mateo, CA.Small, Steven L. and Charles Rieger.
1982.Parsing and comprehending with wordexperts (a theory and its realization).
InWendy Lenhert and Martin Ringle,editors, Strategies for Natural LanguageProcessing.
Lawrence Erlbaum andAssociates, Hillsdale, NJ, pages 89-147.Sparck-Jones, Karen.
1964.
Synonymy andSemantic ClassiJication.
Ph.D. thesis,University of Cambridge, Cambridge, UK.Sparck-Jones, Karen.
1986.
Synonymy andSemantic ClassiJ~'cation.
Edinburgh,Edinburgh University Press, UK.Sparck-Jones, Karen.
Forthcoming.
What isthe role of NLP in Text Retrieval?
InTomek Strzalkowski, editor, NaturalLanguage Information Retrieval.
Text, Speechand Language Technology Series.
KluwerAcademic Publishers, Dordrecht.Sproat, Richard, Julia Hirschberg, andDavid Yarowsky.
1992.
A corpus-basedsynthesizer.
In Proceedings oftheInternational Conference on Spoken LanguageProcessing, Banff, Alberta, Canada,October.Steffens, Petra, editor.
1995.
MachineTranslation and the Lexicon.
Lecture Notesin Artificial Intelligence 898.Springer-Verlag, Berlin.Stock, Penelope F. 1983.
Polysemy.
InProceedings ofthe Exeter LexicographyConference, 131-140.Stone, Philip J.
1969.
Improved quality ofcontent analysis categories:Computerized-disambiguation rulesforhigh-frequency English words.
In GeorgeGerbner, Ole Holsti, Klaus Krippendorf,William J. Paisley, and Philip J. Stone,editors, The Analysis of CommunicationContent.
John Wiley & Sons, New York,pages 199-221.Stone, Philip J., Dexter C. Dunphy, MarshallS.
Smith, and Daniel M. Ogilvie, editors.1966.
The General Inquirer: A ComputerApproach to Content Analysis.
MIT Press,Cambridge, MA.Sussna, Michael.
1993.
Word sensedisambiguation for free-text indexingusing a massive semantic network.
InProceedings ofthe Second InternationalConference on Information and KnowledgeBase Management, CIKM'93, pages 67-74,Arlington, VA.Sutcliffe, Richard F. E., A. McElligott,D.
O'Sullivan, A.
A. Polikarpov,L.
A. Kuzmin, G. O'Neill, and J. V4ronis.1996.
An Interactive Approach to theCreation of a Multilingual ConceptOntology for Language Engineering.
InProceedings ofthe Workshop "Multilingualityin the Software Industry," EuropeanConference on Arti~'cial Intelligence, ECAI'96,Budapest University of Economics,Budapest, Hungary, August.Sutcliffe, Richard F. E., D. O'Sullivan,A.
A. Polikarpov, L. A. Kuzmin,A.
McElligott, and J. V~ronis.
1996.IWNR--Extending a public multilingualtaxonomy to Russian.
In Proceedings oftheWorkshop "Multilinguality in the Lexicon,"AISB Second Tutorial and Workshop Series,pages 14-25, University of Sussex,Brighton, UK, March/April.Sutcliffe, Richard E E. and Bronwyn E. A.Slater.
1995.
Disambiguation byassociation as a practical method:Experiments and findings.
Journal ofQuantitative Linguistics, 2(1):43-52.Tabossi, Patricia.
1989.
What's in a context?In D. Gorfein, editor, Resolving SemanticAmbiguity.
Springer-Verlag, New York,pages 25-39.Tabossi, Patricia.
1991.
Understandingwords in context.
In G. Simpson, editor,Understanding Word and Sentence.North-Holland, Amsterdam, pages 1-22.ten Hacken, Pius.
1990.
Reading distinctionin machine translation.
In Proceedings ofthe 12th International Conference onComputational Linguistics, COLING'90,volume 2, pages 162-166, Helsinki,Finland, August.Thorndike, Edward L. 1921.
A Teacher's Word38Ide and V~ronis IntroductionBook.
Columbia Teachers College, NewYork.Thorndike, Edward L. 1948.
On thefrequency of semantic hanges in modernEnglish.
Journal of General Psychology,66:319-327.Thorndike, Edward L. and Irving Lorge.1938.
Semantic counts of English Words,Columbia University Press, New York.Thorndike, Edward L. and Irving Lorge.1944.
The Teacher's Word Book of 30,O00Words.
Columbia University Press, NewYork.Urdang, Laurence.
1984.
A lexicographer'sadventures in computing.
Datamation,30(3):185-194.van Buren, P. 1967.
Preliminary aspects ofmechanisation i  lexis.
CahLex, 11:89-112;12:71-84.van der Eijk, Pim.
1994.
Comparativediscourse analysis of parallel texts.
SecondAnnual Workshop on Very Large Corpora(WVLC2), pages 143-159, Kyoto, Japan,August.V4ronis, Jean and Nancy Ide.
1990.
Wordsense disambiguation with very largeneural networks extracted from machinereadable dictionaries.
In Proceedings ofthe13th International Conference onComputational Linguistics, COLING'90,volume 2, pages 389-394, Helsinki,Finland.V4ronis, Jean and Nancy Ide.
1991.
Anassessment of information automaticallyextracted from machine readabledictionaries.
In Proceedings ofthe FifthConference ofthe European Chapter of theAssociation for Computational Linguistics,pages 227-232, Berlin, Germany.V~ronis, Jean and Nancy Ide.
1995.
Largeneural networks for the resolution oflexical ambiguity.
In Patrick Saint-Dizierand Evelyne Viegas, editors,Computational Lexical Semantics.
NaturalLanguage Processing Series.
CambridgeUniversity Press, Cambridge, UnitedKingdom, pages 251-269.Viegas, Evelyne, Kavi Mahesh, and SergeiNirenburg.
Forthcoming.
Semantics inaction.
In Patrick Saint-Dizier, editor,Predicative Forms in Natural Language andLexical Knowledge Bases.
Text, Speech andLanguage Technology Series.
KluwerAcademic Publishers, Dordrecht.Voorhees, Ellen M. 1993.
Using WordNet todisambiguate word senses for textretrieval.
In Proceedings ofthe 16th AnnualInternational ACM SIGIR Conference onResearch and Development i  InformationRetrieval, pages 171-180, Pittsburgh, PA,June/July.Voorhees, Ellen M., Claudia Leacock, andGeoffrey Towel|.
1995.
Learning context odisambiguate word senses.
In ThomasPetsche, Stephen Jos4 Hanson, and JudeShavlik, editors, Computational LearningTheory and Natural Learning Systems.
MITPress, Cambridge, MA.Vossen, Piek.
Forthcoming.
Introduction toEuroWordNet.
To appear in a SpecialIssue of Computers and the Humanities onEuroWordNet.Waibel, Alex and Kai-Fu Lee, editors.
1990.Readings in Speech Recognition.
MorganKaufmann, San Mateo, CA.Waltz, David L. and Jordan B. Pollack.
1985.Massively parallel parsing: A stronglyinteractive model of natural anguageinterpretation.
Cognitive Science, 9:51-74.Weaver, Warren.
1955.
Translation.
In WilliamN.
Locke and A. Donald Booth, editors,Machine Translation of Languages.
JohnWiley & Sons, New York, pages 15-23.
(Reprint of mimeographed version, 1949.
)Weibe, Janyce, Julie Maples, Lee Duan, andRebecca Bruce.
1997.
Experience inWordNet sense tagging in the Wall StreetJournal.
In Proceedings ofthe ACL-SIGLEXWorkshop "Tagging Text with LexicalSemantics: Why, What, and How?
', pages8-11, Washington, DC, April.Weinreich, Uriel.
1980.
On Semantics.University of Pennsylvania Press.Weiss, S. 1973.
Learning to disambiguate.Information Storage and Retrieval, 9:33-41.Whittemore, Greg, Kathleen Ferrara, andHans Brunner.
1990.
Empirical studies ofpredictive powers of simple attachmentschemes for post-modifier prepositionalphrases.
In Proceedings ofthe 28th AnnualMeeting of Association for ComputationalLinguistics, pages 23-30, Pittsburgh, PA,June.Wilks, Yorick A.
1968.
On-line semanticanalysis of English texts.
MechanicalTranslation, 11(3-4):59-72.Wilks, Yorick A.
1969.
Getting meaning intothe machine.
New Society, 361:315-317.Wilks, Yorick A.
1973.
An artificialintelligence approach to machinetranslation.
In Roger Schank and KennethColby, editors, Computer Models of Thoughtand Language.
W. H. Freeman, SanFrancisco, pages 114-151.Wilks, Yorick A.
1975a.
Primitives andwords.
In Proceedings ofthe InterdisciplinaryWorkshop on Theoretical Issues in NaturalLanguage Processing, pages 42-45,Cambridge, MA, June.Wilks, Yorick A.
1975b.
Preferencesemantics.
In E. L. Keenan III, editor,Formal Semantics ofNatural Language.39Computational Linguistics Volume 24, Number 1Cambridge University Press, pages329-348.Wilks, Yorick A.
1975c.
An intelligentanalyzer and understander of English.Communications of the ACM, 18(5):264-274.Wilks, Yorick A.
1975d.
A preferential,pattern-seeking semantics for naturallanguage inference.
Artbqcial Intelligence,6:53-74.Wilks, Yorick A.
Forthcoming.
Senses andtexts.
Computers and the Humanities.Wilks, Yorick A. and Dan Fass.
1990.Preference semantics: A family history.Report MCCS-90-194, ComputingResearch Laboratory, New Mexico StateUniversity, Las Cruces, NM.Wilks, Yorick A., Dan Fass, Cheng-MingGuo, James E. MacDonald, Tony Plate,and Brian A. Slator.
1990.
Providingmachine tractable dictionary tools.
InJames Pustejovsky, editor, Semantics andthe Lexicon.
MIT Press, Cambridge, MA.Wilks, Yorick A., Brian A. Slator, and LouiseM.
Guthrie.
1996.
Electric Words:Dictionaries, Computers, and Meanings.
ABradford Book.
MIT Press, Cambridge,MA.Wilks, Yorick and Mark Stevenson.
1996.The grammar of sense: Is word sensetagging much more than part-of-speechtagging?
Technical Report CS-96-05,University of Sheffield, Sheffield, UK.Wittgenstein, Ludwig.
1953.
PhilosophicalInvestigations.
Translated by G. E. M.Anscombe.
Basil Blackwell, Oxford.Yarowsky, David.
1992.
Word sensedisambiguation using statistical models ofRoget's categories trained on largecorpora.
Proceedings ofthe 14th InternationalConference on Computational Linguistics,COLING'92, pages 454-460, Nantes,France, August.Yarowsky, David.
1993.
One sense percollocation.
In Proceedings ofARPA HumanLanguage Technology Workshop, pages266-271, Princeton, NJ.Yarowsky, David.
1994a.
Decision lists forlexical ambiguity resolution: Applicationto accent restoration i  Spanish andFrench.
In Proceedings ofthe 32nd AnnualMeeting, pages 88-95, Las Cruces, NM.Association for ComputationalLinguistics.Yarowsky, David.
1994b.
A comparison ofcorpus-based techniques for restoringaccents in Spanish and French text.
InProceedings ofthe 2nd Annual Workshop onVery Large Text Corpora, pages 19-32, LasCruces, NM.Yarowsky, David.
1995.
Unsupervised wordsense disambiguation rivaling supervisedmethods.
In Proceedings ofthe 33rd AnnualMeeting, pages 189-196, Cambridge, MA,June.
Association for ComputationalLinguistics.Yarowsky, David.
1997.
Homographdisambiguation i  text-to-speechsynthesis.
In Jan T. H. van Santen,Richard Sproat, Joseph P. Olive, and JuliaHirschberg, editors, Progress in SpeechSynthesis.
Springer-Verlag, New York,pages 157-172.Yngve, Victor H. 1955.
Syntax and theproblem of multiple meaning.
In WilliamN.
Locke and A. Donald Booth, editors,Machine Translation of Languages.
JohnWiley & Sons, New York, pages 208-226.Zernik, Uri.
1990.
Tagging word senses in acorpus: The needle in the haystackrevisited.
In P. Jacobs, editor, Text-basedIntelligent Systems: Current Research in TextAnalysis, Information Extraction andRetrieval.
GE Research and DevelopmentCenter, Schenectady, New York.Zernik, Uri.
1991.
Train1 vs. Train2: Taggingword senses in a corpus.
In Proceedings ofIntelligent Text and Image Handling,RIAO'91, pages 567-585, Barcelona, Spain.Zipf, George K. 1935.
The Psycho-biology ofLanguage: An Introduction to DynamicBiology.
MIT Press, Cambridge, MA.Zipf, George K. 1945.
Themeaning-frequency relationship of words.Journal of General Psychology, 33:251-266.40
