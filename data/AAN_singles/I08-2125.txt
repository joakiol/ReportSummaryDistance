Large Scale Diagnostic Code Classification for Medical Patient RecordsLucian Vlad Lita and Shipeng Yu and Stefan Niculescu and Jinbo BiSiemens Medical Solutionsfirstname.lastname@siemens.comAbstractA critical, yet not very well studied problemin medical applications is the issue of accu-rately labeling patient records according todiagnoses and procedures that patients haveundergone.
This labeling problem, known ascoding, consists of assigning standard medi-cal codes (ICD9 and CPT) to patient records.Each patient record can have several corre-sponding labels/codes, many of which arecorrelated to specific diseases.
The cur-rent, most frequent coding approach involvesmanual labeling, which requires considerablehuman effort and is cumbersome for largepatient databases.
In this paper we viewmedical coding as a multi-label classificationproblem, where we treat each code as a labelfor patient records.
Due to government regu-lations concerning patient medical data, pre-vious studies in automatic coding have beenquite limited.
In this paper, we compare twoefficient algorithms for diagnosis coding on alarge patient dataset.1 IntroductionIn order to be reimbursed for services provided to pa-tients, hospitals need to provide proof of the proce-dures that they performed.
Currently, this is achievedby assigning a set of CPT (Current Procedural Ter-minology) codes to each patient visit to the hospi-tal.
Providing these codes is not enough for receiv-ing reimbursement: in addition, hospitals need to jus-tify why the corresponding procedures have been per-formed.
In order to do that, each patient visit needs tobe coded with the appropriate diagnosis that requirethe above procedures.
There are several standardizedsystems for patient diagnosis coding, with ICD9 (In-ternational Classification of Diseases, (Organization,1997)) being the official version.
Usually a CPT codeis represented by a five digit integer whereas an ICD9code is a real number consisting of a 2-3 digit dis-ease category followed by 1-2 decimal subcategory.For example, a CPT code of 93307 is used for anEcho Exam.
An ICD9 code of 428 represents HeartFailure (HF) with subcategories 428.0 (CongestiveHF, Unspecified), 428.1 (Left HF), 428.2 (SystolicHF), 428.3 (Diastolic HF), 428.4(Combined HF) and428.9 (HF, Unspecified).The coding approach currently used in hospi-tals relies heavily on manual labeling performed byskilled and/or not so skilled personnel.
This is avery time consuming process, where the person in-volved reads the patient chart and assigns the appro-priate codes.
Moreover, this approach is very er-ror prone given the huge number of CPT and ICD9codes.
A recent study (Benesch et al, 1997) suggeststhat only 60%-80% of the assigned ICD9 codes re-flect the exact patient medical diagnosis.
This canbe partly explained by the fact that coding is doneby medical abstractors who often lack the medicalexpertise to properly reach a diagnosis.
Two situa-tions are prevalent: ?over-coding?
(assigning a codefor a more serious condition than it is justified) and?under-coding?
(missing codes for existing proce-dures/diagnoses).
Both situations translate into sig-nificant financial loses: for insurance companies inthe first case and for hospitals in the second case.Additionally, accurate coding is extremely importantbecause ICD9 codes are widely used in determiningpatient eligibility for clinical trials as well as in quan-tifying hospital compliance with quality initiatives.Another recent study (Sonel et al, 2006) stressesthe importance of developing automated methods forpatient record information extraction by demonstrat-ing how an automated system performed with 8%better accuracy than a human abstractor on a task ofidentifying guideline compliance for unstable anginapatients.
In the study, differences between the auto-mated system and the human abstractor were adjudi-877cated by an expert based on the evidence provided.In this paper we compare several data mining tech-niques for automated ICD9 diagnosis coding.
Ourmethods are able to predict ICD9 codes by model-ing this task as a classification problem in the naturallanguage processing framework.
We demonstrate ouralgorithms in section 4 on a task of ICD9 coding of alarge population of patients seen at a cardiac hospital.2 Related WorkClassification under supervised learning setting hasbeen a standard problem in machine learning ordata mining area, which learns to construct inferencemodels from data with known assignments, and thenthe models can be generalized to unseen data for codeprediction.
However, it has been rarely employedin the domain for automatic assignment of medi-cal codes such as ICD9 codes to medical records.Part of the reason is that the data and labels are dif-ficult to obtain.
Hospitals are usually reluctant toshare their patient data with research communities,and sensitive information (e.g.
patient name, date ofbirth, home address, social security number) has toby anonymized to meet HIPAA (Health InsurancePortability and Accountability Act) (hip, ) standards.Another reason is that the code classification task isitself very challenging.
The patient records containa lot of noise (misspellings, abbreviations, etc), andunderstanding the records correctly is very importantto make correct code predictions.Most of the ICD9 code assignment systemswork with a rule-based engine as, for in-stance, the one available online from the sitehttp://www.icd9coding.com/, or the one described in(reb, ), which displays different ICD9 codes for atrained medical abstractor to look at and manuallyassign proper codes to patient records.A health care organization can significantly im-prove its performance by implementing an automatedsystem that integrates patients documents, tests withstandard medical coding system and billing systems.Such a system offers large health care organizationsa means to eliminate costly and inefficient man-ual processing of code assignments, thereby improv-ing productivity and accuracy.
Early efforts dedi-cated to automatic or semi-automatic assignments ofICD9 codes (Larkey and Croft, 1995; Lovis et al,1995) demonstrate that simple machine learning ap-proaches such as k-nearest neighbor, relevance feed-back, or Bayesian independence classifiers can beused to acquire knowledge from already-coded train-ing documents.
The identified knowledge is then em-ployed to optimize the means of selecting and rank-ing candidate codes for the test document.
Often acombination of different classifiers produce better re-sults than any single type of classifier.
Occasionally,human interaction is still needed to enhance the codeassignment accuracy (Lovis et al, 1995).Similar work was performed to automatically cat-egorize patients documents according to meaningfulgroups and not necessarily in terms of medical codes(de Lima et al, 1998; Ruch, 2003; Freitas-Junior etal., 2006; Ribeiro-Neto et al, 2001).
For instance, in(de Lima et al, 1998), classifiers were designed andevaluated using a hierarchical learning approach.
Re-cent works (Halasz et al, 2006) also utilize NGramtechniques to automatically create Chief Complaintsclassifiers based on ICD9 groupings.In (Rao et al, ), the authors present a small scaleapproach to assigning ICD9 codes of Diabetes andAcute Myocardial Infarction (AMI) on a small popu-lation of patients.
Their approach is semi-automatic,consisting of association rules implemented by an ex-pert, which are further combined in a probabilisticfashion.
However, given the high degree of humaninteraction involved, their method will not be scal-able to a large number of medical conditions.
More-over, the authors do not further classify the subtypeswithin Diabetes or AMI.Very recently, the Computation Medicine Centerwas sponsoring an international challenge task onthis type of text classification problem.1 About 2, 216documents are carefully extracted (including trainingand testing), and 45 ICD9 labels (with 94 distinctcombinations) are used for these documents.
Morethan 40 groups submitted their results, and the bestmacro and micro F1 measures are 0.89 and 0.77, re-spectively.
The competition is a worthy effort in thesense that it provides a test bed to compare differentalgorithms.
Unfortunately, public datasets are to datemuch smaller than the patient records in even a smallhospital.
Moreover, many of the documents are verysimple (one or two sentences).
It is difficult to train1http://www.computationalmedicine.org/challenge/index.php878good classifiers based on such a small data set (eventhe most common label 786.2 (for ?Cough?)
has only155 reports to train on), and the generalizability ofthe obtained classifiers is also problematic.3 ApproachThis section describes the two data mining algo-rithms used in section 4 for assigning ICD9 codes topatient visits as well as the real world dataset used inour experiments.3.1 Data: ICD-9 Codes & Patient RecordsWe built a 1.3GB corpus using medical patientrecords extracted from a real single-institution pa-tient database.
This is important since most pub-lished previous work was performed on very smalldatasets.
Due to privacy concerns, since the databasecontains identified patient information, it cannot bemade publicly available.
Each document consists ofa full hospital visit record for a particular patient.Each patient may have several hospital visits, some ofwhich may not be documented if they choose to visitmultiple hospitals2 .
Our dataset consists of 96557patient visits, each of them being labeled with a oneor more ICD9 codes.
We have encountered 2618 dis-tinct ICD9 codes associated with these visits, with thetop five most frequent summarized in table 1.
Givensufficient patient records supporting a code, this pa-per investigates the performance of statistical classifi-cation techniques.
This paper focuses on correct clas-sification of high-frequency diagnosis codes.Automatic prediction of the ICD9 codes is a chal-lenging problem.
During each hospital visit, a patientmight be subjected to several tests, have different labresults and undergo various treatments.
For the ma-jority of these events, physicians and nurses generatefree text data either by typing the information them-selves or by using a local or remote speech-to-textengine.
The input method also affects text qualityand therefore could impact the performance of clas-sifiers based on this data.
In addition to these obsta-cles for the ICD9 classification task, patient recordsoften include medical history (i.e.
past medical con-ditions, medications etc) and family history (i.e.
par-ents?
chronic diseases).
By embedding unstructured2Currently, there is a movement to more portable electronichealth recordsmedical information that does not directly describe apatient?s state, the data becomes noisier.A significant difference between medical patientrecord classification and general text classification(e.g.
news domain) is word distribution.
Depend-ing on the type of institution, department profile, andpatient cohort, phrases such as ?discharge summary?,?chest pain?, and ?ECG?
may be ubiquitous in cor-pus and thus not carry a great deal of informationfor a classification task.
Consider the phrase ?chestpain?
: intuitively, it should correlate well with theICD-9 code 786.50, which corresponds to the con-dition chest pain.
However, through the nature ofthe corpus, this phrase appears in well over half ofthe documents, many of which do not belong to the786.50 category.3.2 Support Vector MachinesThe first classification method consists of supportvector machines (SVM), proven to perform wellon textual data (Rogati and Yang, 2002).
Theexperiments presented use the SVM Light toolkit(Joachims, 2002) with a linear kernel and a tar-get positive-to-negative example ratio defined by thetraining data.
We experiment with a cost functionthat assigns equal value to all classes, as well as witha target class cost equal to the ratio of negative to pos-itive examples.
The results shown in this paper corre-spond to SVM classifiers trained using the latter costfunction.
Note that better results may be obtained bytuning such parameters on a validation set.3.3 Bayesian Ridge RegressionThe second method we have tried on this problem is aprobabilistic approach based on Gaussian processes.A Gaussian process (GP) is a stochastic processthat defines a nonparametric prior over functions inBayesian statistics (Rasmussen and Williams, 2006).In the linear case, i.e.
the function has linear formf(x) = w>x, the GP prior on f is equivalent toa Gaussian prior on w, which takes the form w ?N (?w,?w), with mean ?w and covariance ?w.Then the likelihood of labels y = [y1, .
.
.
, yn]> isP (y) =?
n?i=1P (yi|w>xi)P (w|?w,?w) dw (1)with P (yi|w>xi) the probability that document xitakes label yi.879ICD9 Freq Coverage Description786.50 59957 0.621 Chest pain, unspecified401.9 28232 0.292 Essential hypertension, unspecified414.00 27872 0.289 Unspecified type of vessel, native or graft427.31 15269 0.158 Atrial fibrillation414.01 13107 0.136 Coronary atherosclerosis of native coronary arteryTable 1: Statistics of the top five ICD-9 codes most frequent in the patient record database.
Frequency of ICD-9 code in corpus andthe corresponding coverage (i.e.
fraction of documents in the corpus that were coded with the particular ICD-9 code).In general we fix ?w = 0, and ?w = I withI the identity matrix.
Based on past experience wesimply choose P (yi|w>xi) to be a Gaussian, yi ?N (w>xi, ?2), with ?2 a model parameter.
Sinceeverything is Gaussian here, the a posteriori dis-tribution of w conditioned on the observed labels,P (w|y, ?2), is also a Gaussian, with mean?
?w =(X>X + ?2I)?1X>y, (2)where X = [x1, .
.
.
,xn]> is a n?d matrix.
The onlymodel parameter ?2 can also be optimized by maxi-mizing the likelihood (1) with respect to ?2.
Finallyfor a test document x?, we predict its label as ?
?>wx?with the optimal ?2.
We can also estimate the vari-ance of this prediction, but describing this is beyondthe scope of this paper.This model is sometimes called the Bayesian ridgeregression, since the log-likelihood (i.e., the loga-rithm of (1)) is the negation of the ridge regressioncost up to a constant factor (see, e.g., (Tikhonov andArsenin, 1977; Bishop, 1995)):`(y,w,X) = ?y ?Xw?2 + ?
?w?2,with ?
= ?2.
One advantage of Bayesian ridge re-gression is that there is a systematic way of optimiz-ing ?
from the data.
Feature selection is done prior tocalculation (2) to ensure the matrix inverse is feasi-ble.
Cholesky factorization is used to speed up calcu-lation.
Though the task here is classification, we treatthe classification labels as regression labels and nor-malize them before learning (i.e., subtract the meansuch that?i yi = 0).4 ExperimentsIn this section we describe our experimental setupand results using the previously mentioned datasetand approaches.
Each document in the patientdatabase represents an event in the patient?s hospi-tal stay: e.g.
radiology note, personal physician note,lab tests etc.
These documents are combined to cre-ate a hospital visit profile and are subsequently pre-processed for the classification task.
No stemming isperformed for the experiments in this paper.We limit our experiments on hospital visits withless than 200 doctor?s notes.
As a first pre-processingstep, we eliminate redundancy at a paragraph leveland we perform tokenization and sentence splitting.In addition, tokens go through a number and pro-noun classing smoothing process, in which all num-bers are replaced with the same token, and all personpronouns are replaced with a similar token.
Furtherclassing could be performed: e.g.
dates, entity class-ing etc, but were not considered in these experiments.As a shared pre-processing for all classifiers, viablefeatures are considered all unigrams with a frequencyof occurrence greater or equal to 10 that do not appearin a standard lists of function words.After removing consolidating patient visits frommultiple documents, our corpus consists of near100, 000 data points.
We then randomly split thevisits into training, validation, and test sets whichcontain 70%, 15%, and 15% of the corpus respec-tively.
The classifiers were tested on an 15% unseentest set.
Thus, the training set consists of approxi-mately 57, 000 data points (patient visits), which isa more realistic dataset compared to the previouslyused datasets ?
e.g.
the medical text dataset used inthe Computation Medicine Center competition.This paper presents experiments with the five mostfrequent ICD9 codes.
This allows for more in-depthexperiments with only a few labels and also ensuressufficient training and testing data for our experi-ments.
From a machine learning perspective, most ofthe ICD9 codes are unbalanced: i.e.
much less thanhalf of the documents in the corpus actually have agiven label.
From a text processing perspective, this880Average F1 MeasureMicro MacroSVM 0.683 0.652BRR 0.688 0.667Table 3: F1 measure for the ICD-9 classification experimentsis a normal multi-class classification setting.Prior to training the classifiers on our dataset, weperformed feature selection using ?2.
The top 1, 500features with the highest ?2 values were selected tomake up the feature vector.
The previous step inwhich the vocabulary was drastically reduced wasnecessary, since the ?2 measure is unstable (Yang andPedersen, 1997) when infrequent features are used.To generate the feature vectors, the ?2 values werenormalized into the ?
coefficient and then each vec-tor was normalized to an Euclidean norm of 1.In these experiments, we have employed twoclassification approaches: support vector machine(SVM) and Bayesian ridge regression (BRR), foreach of the ICD9 codes.
We used the validation set totune the specific parameters parameters for these ap-proaches ?
all the final results are reported using theunseen test set.
For the Bayesian ridge regression, thevalidation set is used to determine the ?
parameter aswell as the best cutting point for positive versus nega-tive predictions in order to optimize the F1 measure.Training is very fast for both methods when 1, 500features are selected using ?2.We evaluate our models using Precision, Recall,AUC (Area under the Curve) and F1 measure.
Theresults on the top five codes for both classification ap-proaches are shown in Table 2.
For the same exper-iments, the receiver operating characteristic (ROC)curves of prediction are shown in Figure 1 and inFigure 2.
The support vector machine and Bayesianridge regression methods obtain comparable resultson these independent ICD9 classification problems.The Bayesian ridge regression method obtains aslightly better performance.It is important to note that the results presented inthis section may considerably underestimate the trueperformance of our classifiers.
Our classifiers aretested on ICD9 codes labeled by the medical abstrac-tors, who, according to (Benesch et al, 1997), onlyhave a 60%-80% accuracy.
A better performance es-timation can be obtained by adjudicating the differ-0 0.2 0.4 0.6 0.8 100.20.40.60.81414.00786.50414.01427.31401.9Figure 1: ROC curve for the SVM ICD9 classification0 0.2 0.4 0.6 0.8 100.20.40.60.81414.00786.50414.01427.31401.9Figure 2: ROC curve for the BRR ICD9 classificationences using a medical expert (as the small scale ap-proach presented in (Sonel et al, 2006)), but we didnot have access to such a resource.5 Conclusions & Future WorkCode classification for medical patient records is be-coming a critical task in the healthcare industry.
Thispaper presents two automatic code classification ap-proaches and applies them on a real, large hospi-tal dataset.
We view this problem as a multi-labelclassification problem and seek automatic solutions,specifically targeting ICD9 code classification.
Wehave tested two state-of-the-art classification algo-rithms: support vector machines and Bayesian ridgeregression) with promising performance.The data set in our study contains more than90,000 patient visits, and is by far the largest corpusfor research purpose to the best of our knowledge.The features extracted from patient visits were se-lected for individual ICD9 codes based on ?2 score.Low and high-frequency features were filtered out.Several other feature selection methods were consid-ered (including information gain), yielding compara-tively moderate performance levels.881ICD9 Support Vector Machine Bayesian Ridge RegressionPrec Rec F1 AUC Prec Rec F1 AUC786.50 0.620 0.885 0.729 0.925 0.657 0.832 0.734 0.921401.9 0.447 0.885 0.594 0.910 0.512 0.752 0.609 0.908414.00 0.749 0.814 0.784 0.826 0.784 0.763 0.772 0.827427.31 0.444 0.852 0.584 0.936 0.620 0.625 0.623 0.931414.01 0.414 0.906 0.568 0.829 0.575 0.742 0.648 0.836Table 2: Top five ICD-9 codes most frequent in the patient record database showing the performance of support vector machine-based method (SVM) and of bayesian ridge regression-based method (BRR).Both Support Vector Machines and Bayesian ridgeregression methods are fast to train and achieve com-parable results.
The F1 measure performance on theunseen test data is between 0.6 to 0.75 for the testedICD9 codes, and the AUC scores are between 0.8 to0.95.
These results support the conclusion that au-tomatic code classification is a promising researchdirection and offers the potential to change clinicalcoding dramatically.Current approaches are still an incipient step to-wards more complex, flexible and robust codingmodels for classifying medical patient records.
Incurrent and future work we plan to employ morepowerful models, extract more complex features, andexplore inter-code correlations.Patient record data exhibits strong correlationsamong certain ICD9 codes.
For instance the code forfever 780.6 is very likely to co-occur with the codefor cough 786.2.
Currently we do not consider inter-code correlations and train separate classifier for in-dividual codes.
We are currently exploring methodsthat can take advantage of inter-code correlations andobtain a better, joint model for all ICD9 codes.ReferencesC.
Benesch, D.M.
Witter Jr, A.L.
Wilder, P.W.
Duncan, G.P.Samsa, and D.B.
Matchar.
1997.
Inaccuracy of the interna-tional classification of diseases (icd-9-cm) in identifying thediagnosis of ischemic cerebrovascular disease.
Neurology.C.
M. Bishop.
1995.
Neural Networks for Pattern Recognition.Oxford University Press.Luciano R. S. de Lima, Alberto H. F. Laender, and Berthier A.Ribeiro-Neto.
1998.
A hierarchical approach to the auto-matic categorization of medical documents.
In CIKM.H.
R. Freitas-Junior, B.
A. Ribeiro-Neto, R. De Freitas-Vale, A. H. F. Laender, and L. R. S. De Lima.
2006.Categorization-driven cross-language retrieval of medical in-formation.
JASIST.S.
Halasz, P. Brown, C. Goodall, D. G. Cochrane, and J. R. Al-legra.
2006.
The NGram cc classifier: A novel method of au-tomatically creating cc classifiers based on ICD9 groupings.Advances in Disease Surveillance, 1(30).Health insurance portability and accountability act.
2003.http://www.hhs.gov/ocr/hipaa.T.
Joachims.
2002.
Learning to Classify Text Using SupportVector Machines.
Dissertation.
Kluwer.L.
Larkey and W. Croft.
1995.
Automatic assignment of icd9codes to discharge summaries.Christian Lovis, P. A. Michel, Robert H. Baud, and Jean-RaoulScherrer.
1995.
Use of a conceptual semi-automatic icd-9encoding system in a hospital environment.
In AIME, pages331?339.World Health Organization.
1997.
Manual of the internationalstatistical classification or diseases, injuries, and causes ofdeath.
World Health Organization, Geneva.R.B.
Rao, S. Sandilya, R.S.
Niculescu, C. Germond, and H. Rao.Clinical and financial outcomes analysis with existing hospi-tal patient records.
SIGKDD.C.
E. Rasmussen and C. K. I. Williams.
2006.
Gaussian Pro-cesses for Machine Learning.
MIT Press.PhyCor of Corsicana.
In Book Chapter of Information Technol-ogy for the Practicing Physician.
Springer London.B.
A. Ribeiro-Neto, A. H. F. Laender, and L. R. S. De-Lima.2001.
An experimental study in automatically categorizingmedical documents.
JASIST.Monica Rogati and Yiming Yang.
2002.
High-performing fea-ture selection for text classification.
CIKM.P.
Ruch.
2003.
Applying natural language processing toinformation retrieval in clinical records and biomedicaltexts.
Ph.D. thesis, Department of Informatics, Universite DeGene?ve.A.F.
Sonel, C.B.
Good, H. Rao, A. Macioce, L.J.
Wall, R.S.Niculescu, S. Sandilya, P. Giang, S. Krishnan, P. Aloni, andR.B.
Rao.
2006.
Use of remind artificial intelligence softwarefor rapid assessment of adherence to disease specific manage-ment guidelines in acute coronary syndromes.
AHRQ.A.
N. Tikhonov and V. Y. Arsenin.
1977.
Solutions of Ill-PosedProblems.
Wiley, New York.Yiming Yang and Jan O. Pedersen.
1997.
A comparative studyon feature selection in text categorization.
ICML.882
