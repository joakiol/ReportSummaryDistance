Scru f fy  Text Unders tand ing :Des ign  and Imp lementat ion  of 'Tolerant'  Unders tandersR ichard  H. GrangerAr t i f i c ia l  In te l l igence  Pro jectComputer  Sc ience Depar tmentUn ivers i ty  of Ca l i fo rn iaI rv ine,  Ca l i fo rn ia  92717AB STRACTMost large text-understanding systems havebeen designed under the assumption that the inputtext will be in reasonably "neat" form, e.g.,newspaper stories and other edited texts.
However,a great deal of natural language texts e.g.~ memos,rough drafts, conversation transcripts~ etc., havefeatures that differ significantly from "neat"texts, posing special problems for readers, such asmisspelled words, missing words, poor syntacticconstructlon, missing periods, etc.
Our solutionto these problems is to make use of exoectations,based both on knowledge of surface English and onworld knowledge of the situation being described.These syntactic and semantic expectations can beused to figure out unknown words from context,constrain the possible word-senses of words withmultiple meanings (ambiguity), fill in missingwords (elllpsis), and resolve referents (anaphora).This method of using expectations to aid the un-derstanding of "scruffy" texts has been incorp-orated into a working computer program calledNOMAD, which understands scruffy texts in the do-main of Navy messages.1.0 IntroductionConsider the following (scribbled) message,left by a computer science professor on acolleague's desk:\[i\] Met w/chrmn agreed on changes to prposl nxtmtg 3 Feb.A good deal of informal text such as everyday mes-sages like the one above are very ill-formed gram-matically and contain misspellings, ad hoc abbre-viations and lack of important punctuation such asperiods between sentences.
Yet people seem toeasily understand such messages, and in fact mostpeople would probably understand the above messagejust as readily as they would a more '~ell-formed"version:"I met with the chairman, and we agreed on whatchanges had to be made to the proposal.
Our nextmeeting will be on Feb.
3.
"This research was supported in part by the NavalOcean Systems Center under contractN-00123-81-C-I078.No extra information seems to be conveyed by thislonger version, and message-writers appear to takeadvantage of this fact by writing extremely tersemessages such as \[I\], apparently counting on read-ers" ability to analyze them in spite of theirmessiness.If "scruffy" messages such as this one wereonly intended for a readership of one, therewouldn't be a real problem.
However, this informaltype of "memo" message is commonly used for infor-mation transfer in many businesses, universities,government offices, etc.
An extreme case of suchan organization is the Navy, which every hour re-ceives many thousands of short messages, each ofwhich must be encoded into computer-readable formfor entry into a database.
Currently, these mes-sages come in in very scruffy form, and a growingnumber of man-hours is spent on the encoding-by-hand process.
Hence there is an obvious benefit topartially automating this encoding process.
Theproblem is that most existing text-understandingsystems (e.g.
ELI \[Riesbeck and Schank 76\], SAM\[Cullingford 77\], FRUMP \[DeJong 79\], IPP \[Lebowitz80\]) would fai?
to successfully analyze ill-formedtexts like \[i\], because they have been designedunder the assumption that they will receive"heater" input, e.g., edited input such as is foundin newspapers or books.This paper briefly outlines some of the prop-erties of texts like \[i\], that allow readers tounaerstand it in spite of its scruffiness; andsome of the knowledge and mechanisms that seem tounderlle readers" ability to understand such texts.A text-processing system called NOMAD is discussedwhich makes use of the theories described here toprocess scruffy text in the domain of everyday Navymessages.
NOMAD's operation is based on the use ofexpectations during understanding, based both onknowledge of surface English and on world knowledgeof the s~tuation being described.
These syntacticand semantic expectations can be used to aidnaturally in the solution of a wide range of prob-lems that arise in understanding both "scruffy"texts and pre-edited texts, such as figuring outunknown words from context, constraining the pos-sible word-senses of words with multiple meanings(ambiguity), filling in missing words (ellipsis),and resolving unknown referents (anaphora).1572.0 Background: Tolerant text processing2.1 FOUL-UP figured out unknown words from contextThe FOUL-UP program (Figuring Out UnknownLexemes in the Understanding Process) \[Granger1977\] was the first program that could figure outmeanings of unknown words encountered during textunderstanding.
FOUL-UP was an attempt to model thecorresponding human ability commonly known as"f~guring out a word from context".
FOUL-UP workedwith the SAM system \[Cullingford 1977\], using theexpectations generated by scr ipts  \[Schank andAbelson 19771 to restrict the possible meanings ofa word, based on what object or action would haveoccurred in that position according to the scriptfor the story.For instance, consider the following excerptfrom a newspaper report of a car accident:\[2\] Friday, a car swerved off Route 69.
Thevehicle struck an embankment.The word "embankment" was unknown to the SAM sys-tem, but  it had encoded predictions about certainattributes of the expected conceptual object of thePROPEL action (the object that the vehicle struck);namely, that it would be a physical object, andwould function as an "obstruction" in thevehicle-accident script.
(In addition, the con-ceptual analyzer (ELI - \[Riesbeck and Schank 1976\])had the expectation that the word in that sentenceposition would be a noun.
)Hence, when the unknown word was encountered,FOUL-UP would make use of those expected attributesto construct a memory entry for the word"embankment", indicating that it was a noun, aphysical object, and an "obstruction" in vehicle-accident situatlons.
It would then create a dic-tionary definition that the system would use fromthen on whenever the word was encountered in thiscontext.2.2 Blame Assignment in the NOMAD systemBut even if the SAM system had known the word"embankment", it would not have been able to handlea less edited version of the story, such as this:\[3\] Vehcle act Rt69; car strck embankment; drivrdead one psngr in,; ser dmg to car full rptfrtncmng.While human readers would have little difficultyunderstanding this text, no existing computer pro-grams could do so.The scope of this problem is wide; examplesof texts that present "scruffy" difficulties toreaders are completely unedited texts, such asmessages composed in a hurry, with little or nore-writlng, rough drafts, memos, transcripts ofconversatzons, etc.
Such texts may contain missingwords, ad hoc abbreviations of words, poor syntax,confusing order of presentation of ideas, mis-spellzngs, lack of punctuation, etc.
Even editedtexts such as newspaper stories often contain mis-spellzngs, words unknown to the reader, and am-biguities; and even apparently very simple textsmay contain alternative possible interpretations,which can cause a reader to construct erroneousinitial inferences that must later be corrected(see \[Granger 1980,1981\]).The following sections describe the NOMADsystem, which incorporates FOUL-UP's abilities aswell as significantly extended abilities to usesyntactic and semantic expectations to resolvethese difficulties, in the context of Naval mes-sages.3.0 How NOMAD Recognizes and Corrects Errors3.1 IntroductionNOMAD incorporates  ideas from, and bu i lds  on,ear l ie r  work on conceptual  ana lys i s  (e .g .
,\[Riesbeck and Schank 1976\], \[Birnbaum and Selfridge1979\]); situation and intention inference (e.g.,\[Cullingford 1977|, \[Wilensky 1978\]); and Englishgeneratlon (e.g.
\[Goldman 1973\], \[McGuire 1980\]).What differentiates NOMAD significantly from itspredecessors are its error recognition and errorcorrection abilities, which enable it to read textsmore complex than those that can be handled byother text understanding systems.We have so far identified the following fivetypes of problems that occur often in scruffy un-edited texts.
Each problem is illustrated by anexample from the domain of Navy messages.
The nextsection will then describe how NOMAD deals witheach type of error.I.
Unknown words (e.g., Enemy "scudded" bombs atus.
-- the verb is unknown to the system);2.
Missing subject, object, etc.
of sentences.
(e.g., Sighted enemy ship.
Fired -- the actorwho fired is not explicitly stated);3.
Missing sentence and clause boundaries.
(e.g.,Locked on opened fire.
-- two actions, aimingand firing);4.
Missing situational (scripty) events.
(e.g.,Midway lost contact on Kashin.
-- no previouscontact mentioned);5.
Ambiguous word usage.
(e.g., Returned bombs toKashin.
-- "returned" in the sense of re-tal~ation after a previous attack, or "return-ed" in the sense of "peaceably delivered to"?
)When these problems arise in a message, NOMAD mustfirst recognize what the problem is (which is oftendifficult to do), and then attempt t~ ~orrect theerror.
These two processes are briefly describedin the fnllowing sections.1583.2 Recognizing and correcting errorsFor each of the above examples of problemsencountered, NOMAD's method of recognizing andcorrecting the problem are described here, alongwith actual English input and output from NOMAD.I.
INPUT:ENEMY SCUDDED BOMBS AT US.Problem: Unknown word.
The unknown word "scudded"is trivial to recognize, since it is the only wordwithout a dictionary entry.
Once it has beenrecognized, NOMAD checks it to see if it could be(a) a misspelllng, (b) an abbreviation or (c) aregular verb-tense of some known word.Solution: Use expectations to figure out wordmeaning from context.
When the spelling checkersfail, a FOUL-UP mechanisms is called which usesknowledge of what actions can be done by an enemyactor, to a weapon object, directed at us.
It in-fers that the action is probably a propel.
Again,this is only an educated guess by the system, andmay have to be corrected later on the basis offuture information.NOMAD OUTPUT:An enemy ship fired bombs at our ship.2.
INPUT:MIDWAY SIGHTED ENEMY.
FIRED.Problem: Missing subject and objects.
"Fired"builds a PROPEL, and expects a subject and objectsto play the conceptual roles of ACTOR (who did thePROPELing), OBJECT (what got PROPELed) and RECIPI-ENT (who got PROPELed at).
However, no surfacesubjects or objects are presented here.Solution: Use expectations to fill in conceptualcases.
NOMAD uses situational expectations fromthe known typical sequence of events in an "ATTACK"(which consists of a movement (PTRANS), a sighting(ATTEND) and firing (PROPEL)).
Those expectationssay (among other things) that the actor and recip-ient of the PROPEL will be the same as the actorand direction of the ATTEND, and that the OBJECTthat got PROPELed will be some kind of projectile,which is not further specified here.NOMAD OUTPUT:We sighted an enemy ship.
We fired at the ship.3.
INPUT:LOCKED ON OPENED FIRE.Problem: Missing sentence boundaries.
NOMAD hasno expectations for a new verb ("opened") to appearimmediately after the completed clause "locked on".It tries but fails to connect "opened" to thephrase "locked on".Solution: Assume the syntactic expectations failedbecause a clause boundary was not adequately markedin the message; assume such a boundary is there.NOMAD assumes that there may have been an intendedsentence separation before "opened", since noexpectations can account for the word in this sen-tence position.
Hence, NOMAD saves "locked on" asone sentence, and continues to process the rest ofthe text as a new sentence.NOMAD OUTPUT:We aimed at an unknown object.object.We fired at the4.
INPUT:LOST CONTACT ON ENEMY SHIP.Problem: Missing event in event sequence.
NOMAD"sknowledge of the "Tracking" situation cannot un-derstand a ship losing contact until some contacthas been gained.Solution: Use situational expectations to infermissing events.
NOMAD assumes that the messageimplies the previous event of gaining contact withthe enemy ship, based on the known sequence ofevents in the "Tracking" situation.NOMAD OUTPUT:We sighted an enemy ship.
Then we lost radarvisual contact with the ship.or5.
INPUT:RETURNED BOMBS TO ENEMY SHIP.Prob!em: Ambiguous interpretation of action.NOMAD cannot tell whether the action here is "re-turning" fire to the enemy, i.e., firing back atthem (after they presumably had fired at us), orpeaceably delivering bombs, with no firing implied.Solution: Use expectations of probable goals ofactors.
NOMAD first interprets the sentence as"peaceably delivering" some bombs to the ship.However, NOMAD contains the knowledge that enemiesdo not give weapons, information, personnel, etc.,to each other.
Hence it attempts to find an al-ternative interpretation of the sentence, in thiscase finding the "returned fire" interpretation,which does not violate any of NOMAD's knowledgeabout goals.
It then infers, as in the above ex-ample, that the enemy ship must have previouslyfired on us.NOMAD OUTPUT:An unknown enemy ship fired on us.bombs at them.Then we fired4.0 ConclusionsThe ability to understand text is dependent onthe ability to understand what is being describedin the text.
Hence, a reader of, say, English textmust have applicable knowledge of both the situa-tions that may be described in texts (e.g., ac-tions, states, sequences of events, goals, methodsof achieving goals, etc.)
and the the surfacestructures that appear in the language, i.e., therelatlons between the surface order of appearanceof words and phrases, and their correspondin~meaning structures.159The process of text understanding is the com-bined applicatlon of these knowledge sources as areader proceeds through a text.
This fact becomesclearest when we investigate the understanding oftexts that present particular problems to a reader.Human understanding is inherently tolerant; peopleare naturally able to ignore many types of errors,omissions, poor constructions, etc., and getstraight to the meaning of the text.Our theories have tried to take this abilityinto account by including knowledge and mechanismsof error noticing and correcting as implicit partsof our process models of language understanding.The NOMAD system is the latest in a line of"tolerant" language understanders, beginning withFOUL-UP, all based on the use of knowledge of syn-tax, semantics and pragmatics at all stages of theunderstanding process to cope with errors.5.0 ReferencesSchank, R.C., and Abelson, R. 1977 Scripts, P~ans,Goals ~nd Understanding.
Lawrence ErlbaumAssociates, Hillsdale, N.J.Wilensky, R. 1978.
Understanding Goal-BasedStories.
Computer Science Technical Report 140,Yale University.Birnbaum, L. and Selfridge, M. 1980.
ConceptualAnalysis of Natural Language, in R. Schank andC.
Riesbeck, eds., Inside Computer Understanding.Lawrence Erlbaum Associates, Hillsdale, N.J.Cullingford, R. 1977.
Controlling Inferences inStory Understanding.
P;oceedin~s of ~he F~thInternational Joint Conference onArtificialIntelllgence ~IJCAI), Cambridge, Mass.DeJong, G. 1979.
Skimming Stories in Real Time: AnExperiment in Integrated Understanding.
Ph.D.Thesis, Yale Computer Science Dept.Goldman, N. 1973.
The generation of English Sen-tences from a deep conceptual base.
Ph.D. Thesis,Stanford University.Granger, R. 1977.
FOUL-UP: A program that figuresout meanings of words from context.
Proceedings ofthe Fifth IJCAI, Cambridge, Mass.Granger, R.H. 1980.
When expectation fails: Towardsa self-correcting inference system.
In Proceedingsof the First National Conference on ArtificialIntelllgence, Stanford University.Granger, R.H. 1981.
Directing and re-directing in-ference pursuit: Extra-textual influences on textinterpretation.
In Proceedings of the SeventhInternatlonal Joint Conference on ArtificialIntelllgence (IJCAI), Vancouver, British Columbia.Lebowitz, M. 1981.
Generalization and Memory in anIntegrated Understanding System.
Computer ScienceResearch Report 186, Yale University.McGuire, R. 1980.
Political Primaries and Words ofPain.
Unpublished ms., Dept.
of Computer Science,Yale University.Riesbeck, C. and Schank, R. 1976.
Comprehension bycomputer: Expectation-based analysis of sentencesin context.
Computer Science Research Report 78,Yale University.160
