CHINESE INFORMATION EXTRACTION AND RETRIEVALSean Boisen, Michael Crystal, Erik Peterson, and Ralph WeischedelBBN Corporat ion70 Fawcett  StreetCambridge,  MA 02138weischedel  @bbn.com617-873-3496John Broglio, Jamie Callan, Bruce CroftUniversity o f  MassachusettsAmherst,  MATheresa Hand, Thomas Keenan, Mary Ellen OkurowskiDepartment o f  DefenseFort Meade, MD0.
ABSTRACTThis paper provides a summary of the followingtopics:I. what was learned from porting the INQUERYinformation retrieval engine and theINFINDER term finder to Chinese2.
experiments atthe University of Massachusettsevaluating INQUERY performance on Chinesenewswire (Xinhua),3. what was learned from porting selectedcomponents of PLUM to Chinese4.
experiments evaluating the POST part ofspeech tagger and named entity recognition onChinese.5.
program issues in technology development.1.
BACKGROUNDAs a reinvention laboratory, the TIPSTER Programoffers the Government ot only an opportunity to fosterlarge scale research and development, but also avenuesto deploy the resulting enhanced technologies.
Theprimary focus of TIPSTER Phase One was to advancethe state-of-the-art in document detection andinformation extraction through multiple contract awardsfor different algorithmic approaches.
Large scale textcollections were tackled by the detection contractors,while domain and language portability were thechallenge for the extraction contractors.
The TextRetrieval Conference (TREC) and the MessageUnderstanding Conferences (MUC) evaluated andbaselined the technology developments.
In contrast,TIPSTER Phase Two focused on creating anarchitecture to integrate the two technologies, and ondeploying these technologies at multiple Governmentagencies.
The deployments were called demonstrationsystems because their success in daily use woulddemonstrate the capabilities of the technologies to end-users.As a demonstration system, the goal was to portPhase One technologies toChinese.
The University ofMassachusetts ported their INQUERY system with thedevelopment of HanQuery.
BBN ported many of themajor components of PLUM to Chinese and createdNamed Entity Identification capabilities.
This paperdescribes program and technical issues identified unngthe joint Government-contractor effort and shareslessons learned in these two areas.2.
TECHNOLOGY ISSUES2.
I Building a Chinese RetrievalSystem2.1 .
I  General IssuesInformation retrieval in a foreign language requiresmodification to text and user interfaces.
Stemming,word boundary identification, punctuation and stopwordidentification must all be modified; appropriate inputand presentation methods must be provided.
But oncethese interface issues are resolved, the retrieval modeland enhancement techniques operate qually effectivelyin all the languages we have worked with.Text and user interface issues:Writing style varies according to language,including right-left, left-right, or top to bottomstarting on the right.109The fundamental concept of what is an indexableword (or term) changes from language to language,as does the concept of a word stem or root.
Somelanguages, like Chinese and Japanese, are writtencontinuously, with no spaces between words.In Chinese, artificial intelligence becomes a fourcharacter phrase, which could be translated literallyas man-made-cognition-able.
How many words dowe have here: one, two or three?In Semitic languages, words are classically viewedas consonant stems with the addition of prefixesand suffixes.
The stems undergo changes invowels or doubling of consonants.
Finding a termstem for indexing can generate a lot of falserelations between words.other systems (e.g., DOS) there are two-byte seven-bitencodings of these display character sets.One problem that must be handled is a query in onecharacter set retrieving documents encoded in differentcharacter sets.
The query must be transcoded forretrieval from each database and the documents retrievedmust then be transcoded into the input set for display.There will be information loss due to incompleteconversion tables or due to local expressions that haveno equivalent in the another writing.2.1.3 Indexing and Segmentation.Our experience with both Japanese and Chinese hasshown that character-based in exing is the most flexibleapproach to take for Chinese.
Indexing each Chinesecharacter as a term ensures that no information is lost.In agglutinative languages, a single printed wordcan express the lexical semantics of a complexnoun phrase or even a whole sentence.Character encoding:A given language may have multiple non-ASCIIcharacter encodings.
Occasionally, as in SJIS, JISand EUC for Japanese, there is a comparativelysimple algorithmic mapping from one encoding toanother.
More typically, as in Chinese, differentconversion tables use different character order andare not in one-to-one relation with each other.Expectations:Users have different expectations.
For example,although research indicates that a bigram model forlanguages like Chinese may be very effective, ausermay be disconcerted tosee the second character ofone word juxtaposed with the first character of thefollowing word as a search item.2.1.2 Character EncodingsThe ASCH encoding was evolved and standardized onthe English language, so input and display of any otherlanguage presents problems for ASCU-odented isplaytechnology and languages uch as C, where even thedatatype char is ambiguous and not guaranteed tosupport more than 7-bit ASCII.
Because of this, manyforeign languages have alternative character encodings.Languages that do not use the Roman alphabet mayhave any number of competing encodings in use bydifferent agencies or in different countries or on differentplatforms.Modem Chinese has two graphic haracter sets: PRC(simplified) characters and Taiwan (traditional)characters.
(Classical Chinese has additional graphiccharacter styles.).
In the UNIX world, these two displaysets are encoded by the GB (GuoBiao - PRC) and Big5(Taiwan) two-byte eight-bit encodings, although onAlthough it is possible to segment he documentsinto words automatically and index each word as a term,this can cause well-posed queries to fail for two reasons:Words can be improperly joined by the automaticsegmentation.There are different understandings of the definitionof a word.
For example, the Chinese expression forBeijing Institute of Physics may be legitimatelyrepresented in a Chinese lexicon as a single wordand a Chinese-speaking user may also perceive it asa word.
But if this expression is stored as a singleterm, then perfectly reasonable queries such asPhysics institutes in China or Beijing technicalinstitutes would fail to match that term.
For thesame reason, query-time segmentation shouldinclude the raw characters or at least he bigrams inthe query.When the document index is character-based, thenquery-processing can determine proximity constraintsbased on word and phrase formation.
A user may hand-segment the query, the query may be segmentedautomatically or adjacent bigrams from the query maybe used.Automatic segmentation in Chinese raises the specialproblem of name recognition.
Foreign names arerepresented phonetically in Chinese by a small set ofChinese characters.
These characters may appearindividually in Chinese words, but when they arecombined to sound out non-Chinese names they formsequences that are not otherwise part of a Chineselexicon.Chinese names present a different problem.
There isa relatively small number of traditional Chinesesurnames, but given names are essentially unrestrictedcombinations of two-character sequences.
A Chinesename recognizer must look for sequences ofunsegmented (or poorly segmented) characters, and tryto identify a traditional family name, followed by two110characters that could be a given name (i.e., nototherwise segmentable asa word or part of a word.
)Ideally name recognition should be efficientlyinterleaved with segmentation, so that whensegmentation fails on a short sequence, the namerecognizers can be called.
A makeshift substitute forthis interaction is to run the name segmenter to identifyguaranteed names (from name lexicon), run thesegmenter, and then run the name recognizer again, thistime to identify possible names from the stillunsegmented characters.2.1.4 Query ProcessingThere are several issues in query processing besidesthose encountered by the user interface.?
The input character representation must be matchedto the document collection representation, andconverted if necessary.?
Characters which carry no meaning, such aspunctuation or grammatical particles, should bediscarded.?
Groupings of characters that represent words shouldbe identified, either manually or automatically.This may include the special problem of Chineseand foreign name recognition.?
Query expansion methods.
We relied on anautomatic collection-driven concept-relationtechnology called InFinder described below and in\[Jing\].In our first version of the Chinese IR system, weconvert between whatever character sets are representedin our document database and whichever encoding theuser has requested.
We relied on user hand-segmentationto identify words.
Our second version of the system hasan automatic segmentation component.
Where the userhas indicated a preferred segmentation, however, it willbe respected by the automatic component.A future modification will be to combine thesegmented query with the raw-character query, andpossibly to break long words into their bigramsubcomponents.Query Expansion with Related TermsOne of the objectives of information retrieval withrespect o the user is to render the technology moreaccessible by diminishing the gap between the retrievalperformance of an expert or trained user and that of anovice or casual user.
The InFinder technology shows alot of promise in this area.
The goal was to offerautomatic or user-guided query expansion by supplyingterms which are related in meaning to the query terms.In the past, this has been attempted with a general-purpose thesaurus or with a keyword list or topicnavigation outline.
The general purpose thesaurus fallsby bringing in terms which are unrelated to the usage orthe context at hand, and by neglecting other termswhich are germane to a query term in context.
Thetopic navigation and keyword lists are very expensive toconstruct and fail in heterogeneous collections or indomains which change rapidly.The InFinder technology constructs an automaticrelated-term database which attacks the two problems ofcurrency relevance with the same mechanism.
Anautomatic catalog is constructed from a collection basedon word co-occurrence.
Taking any word or phrase as aconcept, the InFinder program collects and filtersfrequency information on  the words that are mostfrequently found within two or three sentences of theconcept of interest.
Since all the information isgathered from the text collection at hand, the termrelations are relevant to the text.
The resulting databaseis an INQUERY database which can be updated asdesired, so that as new usages appear in the text, theycan be added automatically tothe InFinder database.When a query is submitted to the InFinder databasefor expansion, concepts which are contextually relatedto the query terms will be retrieved.
Some number ofthe top terms can be automatically added to the originalquery to add coverage and specificity, or the user can beprompted to select which terms to add to the originalquery.
In the user-guided approach, the user gets theadded benefit of immediate feedback as to whichconcepts in the collection are related to the query.
Thisinformation can lead to selection of a differentcollection, or modification of the original query to altera term that has a domain-specific meaning not intendedby the user.
For the demonstration system, user-guidedexpansion was supported.2.1.5 Relevance FeedbackIn relevance feedback, selected documents areprocessed by the system, and terms which are suggestedby those documents are added to the original query.Since the Chinese indexing is character-based, therelevance feedback approach treated characters as queryenhancement terms.
Since this did not produce goodresults, we modified the feedback selection techniques toselect significant pairs of adjacent characters from therelevant documents (bigram model).
This modelappears to produce very good results, although the termsadded are occasionally disconcerting for the user, sincethey represent parts of words, or characters from twodifferent words that commonly appear together in aphrase.We could segment the relevant documents so that wecan use actual words in the feedback query.
This willproduce a more "readable" query, but ongoing researchsuggests that the results may be the same or worse thanthose produced by the bigram model.
It is possible thata combination of bigram treatment with segmentationwould produce consistently good results.1112.1.6 User InterfaceTo enable query input to the Chinese languageversion of INQUERY, it was desirable to have agraphical user interface platform that would allow theinput and display of Chinese characters.
While there isa great deal of grassroots support in the UNIX world fordisplay of Chinese and Japanese (kterm, cxterm),documentation a d stability are unreliable and they donot support sophisticated pointer-driven or menu-basedinteraction.
The best candidate for a platform for a userinterface was the New Mexico State UniversityCompuing Research Laboratory XAT library of widgetsbased on the Motif library for the X Window System.The XAT library supports display of several differentlanguages, and two important characters encodings forChinese: the traditional or Big5 encoding, and thesimplified or GuoBiao (GB) encoding.
In addition, forboth character sets, the XAT library supports severaldifferent input methods for both character sets, includingboth PRC and Cantonese pinyin and the StandardTelegraphic Code (STC) 4-digit numericrepresentation.The XAT library would allow input of Chinese text,which could then be communicated to a program.
Itpermits the program to display Chinese text byincluding an opening and closing annotation whichindicated which character-encoding the text was using.It was often the case that collections were in thesimplified character set, while the client users might bemore familiar with the STC input method and/or thetraditional character encoding and display.
Therefore itwas necessary to have the XAT library receive STC orBig5 encodings and display traditional characters, and tohave INQUERY translate the traditional encodings intosimplified characters to relrieve documents from a textcollection.
For this purpose, we used conversionprograms provided freely on the network (GB-BIG5) orcreated at CIIR (STC).2.2 Evaluation of the PrototypeSystem2.2.1 Evaluation MethodologyThe purpose of evaluation is to assess retrievaleffectiveness against some standards of expectedperformance.
For information retrieval evaluations, areasonably large set of documents i collected, a set ofqueries is prepared by domain experts, or collected fromusers, and the relevance of each document to each queryis judged.
In practice, the thoroughness of relevancejudgments will vary.
Only an extremely smallcollection of documents can be judged completely.
Forreasonably arge sets, a subset of documents i identifiedand judged for each query.
Then the performance of asystem can be evaluated based on the subset of judgeddocuments.
This is an expensive and time-consumingprocedure when done properly, requinng many monthsof work assembling queries and judging retrieveddocuments by domain experts.A given system's performance will be reported interms of recall and precision: recall indicates whatpercentage of all the relevant documents were retrievedat a given point; precision indicates what percentage ofthe documents retrieved were relevant.
As recallincreases to 100%, precision will decreasecorrespondingly.The INQUERY technology has been formallyevaluated in TIPSTER and TREC trials in English,Spanish and Japanese with outstanding results andcomparable performance in each language.
Since thereis as yet no TREC track for a complete valuation ofChinese IR systems, we have conducted an in-houseevaluation with limited resources to determine if thequality of retrieval appeared to be in line with ourperformance in other languages.We assembled thirty "natural language" queries,modeled on a current set of TREC queries, a typicalquery being: "Investment prospects in China forAmerican companies".
For each query we had aChinese language expert examine and judge the tendocuments ranked most highly by Chinese INQUERY.The queries were submitted in three differentexperimental sets: raw characters and two sets of word-based queries: hand segmented and automaticallysegmented.The database used was the Chinese Peoples Dailycollection containing more than 100 megabytes of text.A second stage of the experiment tested relevancefeedback on the same queries.
Relevant documents wereselected and two-character sequences common to therelevant documents were automatically added to theoriginal query.
The modified query was resubmitted tothe system and the first ten documents returned wereevaluated for relevance.2.2.2 Evaluation ResultsAs the precision figures for the thirty queries in Table1 show, even the unsegmented character-based queriesgive respectable r sults.
On the average six out of thefirst ten documents will be relevant o a given query.Interpreted another way, the first document listed will berelevant in eight queries out of ten.Hand segmentation requires the user to insert spacesbetween the Chinese words when entering the text ofthe query.
As the table shows, this gives an averageimprovement in performance of about 10% over theunsegmented query.
Automatic segmentation gives asimilar increase in performance.
The difference betweenthe two segmentation methods is largely due thepresence of proper names in the queries.
Although wehave developed a Chinese and foreign name recognizer,it was not used in the segmentation for this experiment.As a result names were interpreted as a series ofcharacters.112The relevance feedback stage of the experiment wasbased on a bigram model, which means that a numberof two-character sequences from the relevant documentswere selected for query expansion.
We have previouslyobserved that two-character sequences perform muchbetter than single-character selection in relevancefeedback.
It would also be possible to automaticallysegment the relevant documents for feedback analysis,but it is not clear that this method would produce ameasurable difference within the parameters of thisexperiment.As the table shows, relevance feedback gives aperformance increase of 10-20%.
Relevance feedbackexpands the original query, so the difference observed inthe feedback experiment are due to the influence of theoriginal segmented orunsegmented query terms.2 .2 .3  Evaluat ion Conclus ions.within the limitation of the evaluation methods, wecan conclude that the performance of ChineseINQUERY is quite satisfactory and conforms to that ofINQUERY in other languages.Based on work in English and Japanese, it is expectedthat a combination method, combining a word-basedquery with its character-based raw text, would performbest.
Based on the quality of our bigram-basedrelevance f edback, we also intend to experiment with abigram method of segmentation.
This would be fasterand simpler than lexicon-based segmentation..
If usedin a combination query, it is possible that the resultswould equal or surpass the more expensive automaticsegmentation performance.2.3  Extract ion2 .3 .1  Porting Components of  thePLUM Information Extract ion Systemto ChineseThe PLUM architecture is presented in Figure 1.Ovals represent declarative knowledge bases; rectanglesrepresent processing modules.
Gray elements are not yetavailable for Chinese.
A more detailed description ofthe language-independent system components, theirTable 1Top N Raw QueryDocs No_Se 8 Hand_Seg1 83.3 93.3(12.05%)2 75.0 83.3 (11.11%)3 76.7 78.9 (2.91%)4 72.5 76.7 (5.84%)5 69.3 74.0 (6.83%)6 66.7 71.1 (6.64%)7 64.3 68.9 (7.2%)8 60.8 66.3 (9.09%)9 59.2 64.8 (9.5%)10 57.0 62.0 (8.82%)Auto_Seg90.0 (8.09%)81.7 (8.98%)76.7 (0.00%)75.0 (3.49%)74.0 (6.83%)72.2 (8.29%)70.0 (8.91%)68.8 (13.2%)65.9(11.36%)63.0 (10.57%)individual outputs (with examples for English), andtheir knowledge bases is presented in BBN's paper tothe Sixth Message Understanding Conference (MUC-6).The processing modules are briefly described below.Message Reader.
The input to the PLUM systemis the text of a document from the document manager,i.e., a "message".
The message wader moduledetermines message boundaries, identifies the messageheader information, and determines paragraph andsentence boundaries.Morphological Analyzer.
The first phase ofprocessing is the Chinese segmenter developed andsupported by New Mexico State University.
Thesequences of words found by the segmenter for eachsentence is then assigned a part of speech, e.g., propernoun, verb, adjective, etc.
In BBN's part-of-speechtagger POST, a bi-gram probability model andfrequency models for known words (derived from largecorpora) are employed to assign a part of speech to allwords of the sentence in context.Lexical Pattern Matcher.
The Lexical PatternMatcher was developed in 1992 to deal withgrammatical forms, such as names in English andJapanese.
It applies finite state patterns to the input,which consists of word tokens with part-of-speech.
Inparticular, word groups that are important to the domainand that may be detectable with only local syntacticanalysis can be treated here.
For NE, namedorganizations, named persons, dates and times,monetary amounts, and percentages are found here.When a pattern is matched, a semantic form is assignedby the pattern.The set of recognized entities is used by the outputfunctions to SGML-mark the input.Fast Partial Parser (FPP) .
The ultimateinformation extraction system for Chinese wouldinclude a grammar.
No Chinese grammar is yetavailable for PLUM.The FPP is a near-deterministic parser whichgenerates one or more non-overlapping parse fragmentsWith" Relevanc'e ' Feedback '"No_Se 8 Hand_Seg Auto_Se 896.7(16.13%) 100 (20.09%) 100 (20.09%)96.7(28.98%) 93.3(24.44%) 91.7(22.31%)87.8 (14.52%) 90.0(17.39%) 88.9 (15.95%)83.3 (14.94%) 87.5(20.:73%) 85.8 (18.39%)78.0 (12.6%) 82.7 (19.38%) 82.7 (19.38%)74.4 (11.59%) 80.0 (19.99%) 78.9 (18.34%)69.5 (8.13%) 78.6 (22.28%) 76.2 (18.55%)67.5 (11.06%) 75.4 (24.06%) 74.2 (22.08%)65.5 (10.69%) 73.7 (24.54%) 73.3 (23.86%)64.0 (12.33%) 71.3 (25.13%) 70.0 (22.85%)113spanning the input sentence, deferring any difficultdecisions on attachment ambiguities.
When cases ofpermanent, predictable ambiguity arise, the parserfinishes the analysis of the current phrase and begins theanalysis of a new phrase.
Therefore, the entitiesmentioned and some relations between them areprocessed in every sentence, whether syntactically ill-formed, complex, novel, or straightforward.Furthermore, this parsing is done using essentiallydomain-independent syntactic information.Semantic Interpreter.
Since no grammar isincluded, no semantic interpretation rules were written.The semantic interpreter contains two sub-components: a rule-based fragment interpreter and apattern-based sentence interpreter.
The rule-basedfragment interpreter applies semantic rules to eachfragment produced by FPP in a bottom-up,compositional fashion.
Semantic rules are matchedbased on general syntactic patterns, using wildcards andsimilar mechanisms toprovide robustness.
A semanticrule creates a semantic representation of the phrasestored with the syntactic parse.Discourse Processing.
Even without a grammar,semantic entities and relationships are still recognizedand created by the lexical pattern matcher.
Thesesemantic representation are the input to the discoursecomponent.PLUM's discourse component creates a meaning forthe whole message from the meaning of each sentence.The message level representation is a list of discoursedomain objects (DDOs) for the top-level events ofinterest in the message (e.g., SUCCESSION events inthe MUC-6 domain).
The semantic representation f aphrase in the text only includes information containednearby; the discourse module must infer other long-distance or indirect relations not explicitly found earlierand resolve any references in the text.The discourse component creates two primarystructures: adiscourse predicate database and the DDOs.The database contains all the predicates mentioned in thesemantic representation of the message.
Any otherinferences are also added to the database.To create the DDOs, the discourse componentprocesses each semantic form produced by theinterpreter, adding its information to the database.
Thediscourse component then applies inference rules thatmay add more semantic information to the discoursepredicate database.
When a semantic form for an eventof interest is encountered, a DDO is generated and anyslots already found by the interpreter are filled in.
Thediscourse processor then tries to merge the new DDOwith a previous DDO, in order to account for thepossibility that the new DDO might be a repeatedreference to an earlier one.Once all the semantic forms have been processed,heuristic rules are applied to fill any empty slots fromthe text surrounding the forms that triggered a givenDDO.
Each filler found in the text is assigned aconfidence score based on distance from trigger.
Fillersfound nearby are of high confidence, while those fartheraway receive worse scores (low numbers represent highconfidence; high numbers low confidence; thus 0 is the"highest" confidence score).114Template Generat ion.
For named entities,SGML is inserted into a copy of the message text.For full template output, the output generator takesthe DDOs produced by discourse processing and fills outthe application-specific templates.
Clearly, much ofthis process is governed by the specific requirements ofthe application, considerations which have little to dowith linguistic processing.
The template generatormust address any arbitrary constraints, as well as dealwith the basic details of formatting.The template generator uses a combination of data-driven and expectation-driven strategies.
First theDDOs found by the discourse module are used toproduce template objects.
Next, the slots in thoseobjects are filled using information in the DDO, thediscourse predicate database, other sources ofinformation such as the message header (e.g., documentnumber), or from heuristics (e.g., in MUC-6 terms, thetype of an organization object is most likely to beCOMPANY).2.3.2 Porting Named Entity Extractionto ChineseImpact of segmentat ion.
One of the majorchallenges for Chinese named-entity extraction is thelack of explicit word boundaries in Chinese text.
For aword-based named entity system like the one used bythe TIPSTER demonstration system, this necessitatesthe use of a segmenter to preprocess the text.
Thisdependence means that segmenter errors will greatlylower extraction accuracy.
Unfortunately, the class ofwords most difficult to segment correctly are propernouns such as person names and locations.Furthermore, a segmentation for a given text that isconsidered correct by one set of criteria may not be thesegmentation most useful for named entity extraction.Looking forward, an interesting project would be tocombine the segmentation a d extraction steps into oneprocess, since many of the tasks of a segmenter (e.g.parsing out names of people and locations) dovetailnicely with named entity extraction.Rules for a l iases .
Just as English abbreviationsand aliases for named entities are formed by selectingletters or subsets of words from the phrase making upthe entity name, Chinese aliases are also formed byselecting one of more characters from the entity.
Forlocations this is generally just the first character of thelocation ame.
Aliases for person names are also fairlystraight forward.
For organizations, the alias isgenerally formed by selecting a character f om each wordMessageMessage ReadertMorphological AnalyzertLexical Pattern MatcherFast Partial Parser,1Semantic Interpretertentence-Level Pattern MatcherIlDiscourseTemplate GeneratorlJOutputI'1 IIFormat & SGML handlingInitial identification of entitiesGrouping words into meaningful phrasesEstablish relationships (within sentences)Establish relationships overallOutput entities and relationshipsFigure 1: Ultimate Chinese PLUM System: Rectangles represent domain-independent, language-independent algorithms; ovals represent knowledge bases.
Gray elements are not yet available for Chinese.115of the full organization ame.
However, the characterspicked can and often do occur anywhere in the word, andno easy algorithm exists to determine which charactersthese are.recognizing native Chinese first names.
These arefrequently common words with no capitalization toindicate whether the word is being used as a name ornot.2.3.3 Assessment of the Merit of theTechnical Approach and LessonsLearnedPrior to this effort, the PLUM information extractionsystem had been applied to several domains in Englishand to two domains in Japanese.
Though that wasvaried experience, it was still limited experience with ahigh risk, high payoff technology.2.3.3.1  Difficulties Posed by ChineseChinese appears to be much harder than many otherlanguages where information extraction has beenattempted.
Almost all data detection algorithms (fordocument storage and retrieval) and informationextraction algorithms are word-based, i.e., they assumewords for higher level processing.
In many writtenlanguages, word boundaries are clearly marked byspaces.
Chinese and Japanese, on the other hand, haveno explicit indication of word boundaries; a reader mustdetermine the writer's intended sequence of words, aprocess called word segmentation.
Chinesesegmentation seems inherently harder than Japanese,based on our experience.
For instance, in Japanese, anychange from Kanji characters to kana or to Romajireliably signals a word boundary.
Chinese has oneuniform character set, and therefore does not provide asmany easy boundaries.
As a second example, considerforeign names.
In Japanese, foreign names are typicallytransliterated into a sequence of easily identified kanacharacters, making recognition of foreign names rathereasier than in Chinese, where foreign names aretransliterated into the same character set as those usedfor common words.The current PLUM architecture for Chinese separatessegmentation, part-of-speech analysis, and nameextraction into 3 pipelined modules.
There areambiguities in segmentation that probably can't beresolved without including more context in the decision.Combining these three modules into a single integratedmodel might improve performance, since similarinformation is used in all three decisions.A second technical challenge in Chinese is inA third problem is the lack of non-proprietaryresources for Chinese.
This suggests the need todevelop resources uch as lists of word plus part ofspeech, grammars, lexicons with syntactic features andat least high level semantic categories (person,organization, product, event, state of affairs, etc.
).2.3 .3 .2  Lack of Linguistic ResourcesOne of the unexpected costs in this effort arose fromthe lack of linguistic resources.
In our experience withJapanese, both a grammar and a list of roughly 35,000words with their parts of speech were available.
A listof words with their parts of speech is invaluable tohaving at least minimal syntactic/semantic informationabout words; it is presumed by any grammar.
Agrammar makes higher level processing possible.Developing either from scratch is quite timeconsuming.A consequence of this was that more data labeled bypart of speech (and word segmentation) was needed toprocess newswire than in any previous language wehave worked on (English, German, Japanese, andSpanish).
See the table below.
Three factors seemcritical: the amount of part of speech training data,whether the written language supports "endinganalysis", and the size of the list of words plus theirparts of speech.
Note that the error rate can be wellunder 10% if either the spelling of the languagesupports ending analysis or there is a sizable list ofwords and their parts of speech (e.g., a dictionary listingpart of speech for each entry).
Neither was available inChinese, where the error rate has been much worse thanin any previous language we have worked on.Whereas acorpus of 80,000 words marked in contextby part of speech was adequate to give less than a 10%error rate in Japanese, in Chinese, with a corpus of100,000 words marked, the error rate on newswire wasstill well over 10%, predominantly due to the fact thatthe error rate on unknown words in newswire was near50%.The high error rate on unknown words in Chinese isconsistent with our expedenee with English; if endingLanguage Part of Speech EndingTraining AnalysisJapanese 80,000 NoSpanish 50,000 YesEnglish 4,000,000 YesChinese 100,000 NoSize of Word + ErrorPoS List Rate> 35,000 3-4%0 8%40,000 3-4%0 12-15%Figure 2: Factors determining part-of-speech error rate.116analysis and capitalization are not employed the errorrate on unknown words is roughly 50%.
(By "endinganalysis," we mean evidence of a word's part of speechgiven its spelling, e.g., the probability that a word is anoun, given it ends in "tion".
)Consider Spanish, which has a small phoneticalphabet, typical endings representing syllables canprovide additional evidence as to the part of speech of anunknown word.
With a corpus of roughly 60,00 wordsmarked by part of speech, the overall error rate onnewswire was below 10% (even though without a largelist of words plus parts of speech), and the error rate onunknown words was only half that of Chinese.Since neither capitalization or ending analysis areavailable in Chinese, the only alternative to reducingthe error rate in Chinese newswire is reducing thenumber of unknown words, e.g., by developing a list ofwords plus parts of speech.In addition to the need for additional linguisticresources, clearer guidelines for developing theseresources are needed.
For example, the granularity ofsegmentation and the part-of-speech tag set must beappropriate for the applications and capabilities of thesystem modules that require them.
For thedemonstration system, part-of-speech data which wasprepared early in the project, before all the requirementsfor downstream odules were clear, often had to berevised.
Better software tools and procedures to supportquality control are also needed, given the inherentdifficulties in manually tagging large amounts of data.2.3 .3 .3  Lessons LearnedWe believe the following can be learned from thiseffort:1.
Basic linguistic resources.
Given ourassessment of the difficulty of processingChinese, this suggests the need fordevelopment of basic resources for non-European languages, e.g., segmenters, word +part of speech lists, lexicons, and grammars.2.
Linguistic expertise.
Personnel with linguisticexpertise who are also programmers may berare for some languages.
In such cases, adevelopment environment for non-programmers is highly desirable.
Looking tothe future, approaches to learning extractionrules from examples i research with very highpayoff.3.
System software.
System software to supportlanguages other than English is still minimal,especially for languages not representable asASCII characters, uch as Chinese.
As aresult, underlying software, such as operatingsystems, programming languages, text editors,and user interfaces, require substantial effort foreach new language; the associated costs toobtain them, install them, learn them, andwork around their limitations are not goingdown.3.
PROGRAM ISSUESSimply porting the components of TIPSTERadvanced text processing technology is insufficientproof that a technology will actually perform asexpected in a given language.
Porting to a newlanguage introduces an array of challenges.3.
I Problem DefinitionOne way to reduce the risk of technology transfer isselecting a well-defined problem and scope itappropriately in the development and protototype stage.In the initial stages of development, i  is tempting toselect a problem that best matches the known technicalcapability of the systems.
In order to create a usefulsystem, however, the system implementor must workclosely with future customers to identify a problem,while at the same time, bearing in mind thatuncertainties in the technology extension process cancomplicate finding a match between an applicationproblem and the technical capabilities.
Even though thecontract would have benefited from a joint Governmentand contractor requirements analysis, the centralproblem was not in understanding requirements butrather prototyping developing technologies.The developer and system implementor mustunderstand and agree on the risks involved indevelopment, especially in the situation when advancedtechnology is being applied to a completely newdomain or language.
Are there sufficient resourcesavailable to support moving the technology to a newarea?
Is there language xpertise available to interpretand explain the novel characteristics of the language?All of the involved parties must evaluate the severity ofthe risks on a successful system outcome.
Positiveexperience in Phase One with Japanese led theGovernment and contractors to downplay the port toChinese as a risk factor.3.2 Evaluation of CapabilitiesAll involved parties hould agree, in advance, on whatconstitutes a successful system development.
If thecomponents of the text technology successfully processforeign languages text, is that a sufficient est?
Shouldthe results of an empirical evaluation be similar toprevious results in similar languages?
Should rigorousevaluation metrics by employed?
For thedemonstration, the baseline valuation metrics of MUCand TREC for Information Extraction and InformationRetrieval, respectively, had not previously been appliedto Chinese information technology.
Text retrievalevaluation for Chinese will not be baselined untilTREC-5, in 1997 and Chinese extractions results werenot baselined until Spring 1996.
Data preparation oftopic descriptions for information retrieval andtemplates for information extraction is costly, but117without defined evaluation data how is agreementreached on an acceptable vel of performance.
How dowe manage xpectations in an unknown situation?
Allmust agree on the minimum accepted systemperformance todetermine its success.3.3 Software IntegrationOne of the key goals of the TIPSTER Phase II effortwas to foster sharing of resources, including code reuse.The demonstration project was very ambitious in itssupport of this goal.
The demonstration systemsinclude software components developed under othercontracts by New Mexico State University, including anearly version of the TIPSTER Document Manager(TDM), a Chinese Segmenter, and a multi-lingualMotif text widget.
The use of TDM was the primarymeans of demonstrating TIPSTER compliancy, anotherPhase l/goal.
Unfortunately, the original governmenttime estimate for architecture definition was low, and aconcrete definition of the architecture were not availableduring the demonstration design phase.
Although oneof the purposes of the demonstration systems was toprovide valuable feedback in the iterative design cycleof the TIPSTER architecture development, this strategy,in retrospect, was detrimental to successful systemdevelopment.
Adherence to evolving architecturestandards and commitment to reusing shared softwareimpacted negatively on the demonstration systems.
Inaddition, the shared software was immature, but thedevelopment schedules necessitated that it be robust.3.4 Resource IdentificationSystem planning necessitates identification andacquisition of essential resources, such as supportingdata and software development tools.
Developers mustidentify what types of resources are reqtfired forsuccessful development, whether they are currentlyavailable or must be developed, and how soon in thedevelopment cycle they must be available.
If thecritical path of the system schedule depends on thetimely acquisition or development of new resources, theschedule must allow for this.
For many foreignlanguages, oftware tools are not readily available.
Thisis especially true for languages which are nottraditionally the focus of natural anguage or computerapplications.
The lack of availability of basicdevelopment tools, such as multi-lingual editors andfonts, can have a serious impact on developmentschedule.
In order to minimize impact on the systemdeployment schedule, all reqtfired resources hould beacquired prior to system development.
Many delayswere introduced into the effort by unavailability ofinfrastructure sources.An additional resource issue is personnel managementamong multiple contract sites and the Government site.New combinations of technical expertise and create newopportunities from past contract experiences where allwork is done by the contractor.
How these resources aremanaged most effectively provides new challenges toboth the Government and contract groups.3.5 ScheduleThe developer and the Government must devise aschedule that indicates approximate system deliverydates.
These delivery dates should be adhered to, to theextent possible, and any slippages should bedocumented and the cause for the slippage understood.The developer should identify any dependencies in theschedule for system deployment.
Developers need tomanage "requirements crop" and identify potentialnegative impacts on scheduling initiatives.
Fortechnologies being ported to a new language, with aheavy dependence on creation of new resources,developers hould track incremental progress to morereadily identify problem areas and potential scheduleslippage.3.6 SupportLife cycle support of advanced natural languagetechnology is still beyond the ability of most softwarecenters, which creates an unrealistic support requirementon contractors that focus primarily on research andtechnology development.
The support structure forsuch a system must be developed and refined as thetechnology matures in order to be able to handle anyfuture problems.While the goal of sharable systems across multipleGovernment agencies is admirable, all participatingagencies must commit to providing support andinfrastructure sources to maintain the resulting systemwithin each office.
Common system development willprovide benefits to the Government in the long term,however it requires substantial initial investment andcustomer buy in.3.7 Lessons LearnedThe design and development of the demonstrationsystem was a valuable learning experience, which willpositively impact the success of future technologyefforts.
Among the most relevant lessons:?
Keep the scope of technology al developmentefforts small, until an advanced technology isproven to work for a given language.?
Do not rely on baseline valuation results topredict he success of a technology effort in anew language.
Anticipate that unforeseenchallenges of a new language will probably drivesystem performance down to some degree.?
Determine reasonable, cost effective means forevaluating new capabilities in existingtechnologies.118?
Do not rely on evolving standards as a corecomponent of a system.Avoid depending on component software stillunder development without including support forcoordination between main system andcomponent developers.Include support for any component software as aseparate task for project scheduling and budgetingpurposes.Begin technology development only after thesupport infrastructure is identified.
Developeffective management mechanisms for multiplesite coordination with the Government.Track incremental progress during the course ofsystem development.
This will allow the systemintegrators and customers to more easily identifypotential problem areas.Expect hat systems hareable across Governmentagencies require interagency investment farbeyond the initial definition of an architecture.The TIPSTER demonstration system allowed us totest implementation f TIPSTER technology in a newlanguage, and gave us a more complete understanding ofrisks involved in undertaking such an effort.
Hopefullythis increased understanding will benefit us in futureTIPSTER advanced technology transfer efforts.
[Jing] Jing, Y.; Croft, W.B.
(1994) An associationthesaurus for information retrieval.
Proceedings ofRIA O 94, 146-160.119
